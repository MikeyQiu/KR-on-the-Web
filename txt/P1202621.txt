Robust Image Segmentation Using Contour-guided Color Palettes

Xiang Fu1, Chien-Yi Wang1, Chen Chen1, Changhu Wang2∗, C.-C. Jay Kuo1
1University of Southern California, Los Angeles, California, USA
2Microsoft Research, Beijing, China
{xiangfu, chienyiw, chen80}@usc.edu, chw@microsoft.com, cckuo@sipi.usc.edu

Abstract

The contour-guided color palette (CCP) 1 is proposed
for robust image segmentation. It efﬁciently integrates con-
tour and color cues of an image. To ﬁnd representative
colors of an image, color samples along long contours be-
tween regions, similar in spirit to machine learning method-
ology that focus on samples near decision boundaries, are
collected followed by the mean-shift (MS) algorithm in the
sampled color space to achieve an image-dependent color
palette. This color palette provides a preliminary segmen-
tation in the spatial domain, which is further ﬁne-tuned by
post-processing techniques such as leakage avoidance, fake
boundary removal, and small region mergence. Segmenta-
tion performances of CCP and MS are compared and an-
alyzed. While CCP offers an acceptable standalone seg-
mentation result, it can be further integrated into the frame-
work of layered spectral segmentation to produce a more
robust segmentation. The superior performance of CCP-
based segmentation algorithm is demonstrated by experi-
ments on the Berkeley Segmentation Dataset.

1. Introduction

Automatic image segmentation is a fundamental prob-
lem in computer vision. It plays an important role in di-
verse applications, such as object detection, scene parsing,
and image retrieval. It partitions an image into a small num-
ber of disjointed coherent regions with low-level features,
with the goal of minimizing intra-variance and maximizing
inter-variance among regions. It is desired that the segmen-
tation result is close to human semantic understanding and
not sensitive to parameter setting and/or image content.

To segment an image, pixel (or superpixel) grouping in
the spatial and spectral domains were performed in the lit-
erature. Typically, spatial-domain pixel grouping is guided
by contours [2, 7] while spectral-domain pixel grouping is

∗Corresponding Author
1The MATLAB code of CCP Segmentation can be downloaded at

https://github.com/fuxiang87/MCL_CCP.

achieved by clustering in a color space [17, 4, 5, 8, 11, 12,
18]. Thus, contours and colors are two widely used features
in image segmentation, yet each of them has its own limita-
tions. For example, contours are not reliable if they are short
and fragmented. They might fail to separate two regions if
parts of their common boundaries are blurred and/or with
a low contrast. The color feature is not effective to han-
dle regions with textures or gradual color transition, lead-
ing to over-segmentation. One common challenge in these
methods is the selection of proper parameters, such as the
color clustering bandwidth. In general, these optimal pa-
rameters are image dependent and difﬁcult to determine. In
this work, we integrate contour and color cues under one
uniﬁed framework, and propose the contour-guided color
palette (CCP) for robust image segmentation. That is, it has
only one key parameter and its performance is stable when
the parameter lies in a suitable range.

The basic idea of CCP is described as follows. To ﬁnd
representative colors of a given image, we collect color
samples from both sides of long contours, and conduct the
mean-shift (MS) algorithm [4] in the sampled color space to
deﬁne an image-speciﬁc color palette. This scheme reduces
color complexity of the original image, yet keeps a sufﬁ-
cient number of representative colors to separate distinctive
regions and yield a preliminary segmentation. This result
is further reﬁned by post-processing techniques in the spa-
tial domain, which leads to a robust standalone segmenta-
tion. The CCP result can be applied to any superpixel-based
segmentation algorithm by replacing the over-segmentation
layer, such as mean-shift (MS) [4], Felzenszwalb and Hut-
tenlocher’s graph-based (FH) [8], and SLIC [1] superpix-
els. Furthermore, it can be integrated into the layered spec-
tral segmentation framework, such as multi-layer spectral
segmentation (MLSS) [11] and segmentation by aggregat-
ing superpixels (SAS) [12], and used as a coarse layer in
this context for a more robust segmentation. The supe-
rior performance of CCP-based segmentation algorithms
are demonstrated in the experiments on the Berkeley Seg-
mentation Dataset (BSDS) [13].

The rest of this paper is organized as follows. Related

11618

Contour Map

Long Contours

Original

Denoised

Color Palette 
Generation

Leakage 
Avoidance

Fake 
Boundary 
Removal

Small 
Region 
Mergence

CCP

Image Pre-Processing

Initial Segmentation

Segment Post-Processing

Figure 1. The block diagram of the proposed contour-guided color palette (CCP) method.

work is reviewed in Sec. 2. The CCP method is described
in detail in Sec. 3. The advantages of CCP over MS are an-
alyzed in Sec. 4. Then, the integration of CCP with layered
spectral segmentation is introduced in Sec. 5. Experimental
results are shown in Sec. 6. Finally, concluding remarks are
given in Sec. 7.

2. Related Work

According to the studies on human visual perception
[10, 3], people pay more attention to dissimilarities between
two regions and lean to group similar regions in appear-
ance, which correspond to the contour (1D) and regional
(2D) cues, respectively. Both of the two cues are needed for
a better image segmentation. Regional cues are contributed
by color and texture. Most image segmentation algorithms
can be classiﬁed into two categories, i.e., region-based and
contour-based methods.

Region-based methods ﬁnd the similarity among spa-
tially connected pixels and group them together using sur-
face properties such as luminance and color. Representative
approaches include watershed [17], k-means, mean-shift
(MS) [4], normalized cuts (NCut) [5, 18], Felzenszwalb
and Huttenlocher’s graph-based (FH) [8], multi-layer spec-
tral segmentation (MLSS) [11], and segmentation by ag-
gregating superpixels (SAS) [12]. However, these meth-
ods might neglect obvious discontinuities between two re-
gions. To overcome this limitation, contour-based methods,
such as gPb-OWT-UCM [2], and saliency driven total vari-
ation (SDTV) [7] were developed to ﬁnd connected regions
blocked by detected contours. However, it is still challeng-
ing to detect closed contours in low-contrast or blurred re-
gions for segmentation.

One can combine region and contour cues to overcome
their individual limitations, and several ideas were intro-
duced in [9, 16]. For example, one can take the contour cue
as a post-processing step to correct region-based segmen-

tation results or treat the contour as a barrier in an afﬁnity
measure.

In this work, a new method called CCP is proposed to ef-
fectively integrate contour and color cues. Unlike the other
methods, we take the contour cue as guidance to form an
image-dependent color palette. It reduces color complexity
of the original image, yet keeps a sufﬁcient number of rep-
resentative colors to separate distinctive regions. The CCP
method is detailed in the following section.

3. Contour-guided Color Palette Method

3.1. System Overview

The basic idea of the CCP method can be simply stated
as follows. Long contours play an important role in image
segmentation since they provide useful spatial-domain in-
formation in region partition. However, they may not form
a closed region due to weak boundaries in some parts, lead-
ing to the leakage problem. To assist contour-guided seg-
mentation, we use the color information as an auxiliary cue.
That is, we collect color samples along both sides of each
long contour and perform clustering in the sampled color
space for color quantization. Once color is quantized, we
get a number of closed regions with long contours as their
boundaries. This initial segmentation can be further reﬁned
by post-processing techniques in the spatial domain. Fig. 1
shows the block diagram of the CCP method, which mainly
consists of three modules: (1) image pre-processing, (2)
contour-guided color palette generation for an initial seg-
mentation, and (3) segment post-processing.

The image pre-processing module includes denoising
and contour extraction. There are many standard algorithms
to select for this module. In our implementation, we adopt
the bilateral ﬁltering scheme [19] for denoising. And, we
apply the structured edge detection [6] method to the origi-
nal input image to obtain a contour map with pixel value in-

1619

δ
δ

Δ 

(a)

(c)

(b)

(d)

Figure 2. Illustration of banded region of interest (B-ROI) for color
palette generation. (a) shows a B-ROI with a bandwidth of 2δ.
Pixels are sampled from both sides of the contour with a uniform
stepsize ∆. (b) is an example image overlaid with detected long
contours. Long contours are indicated by different colors. (c) and
(d) are the zoom-in of two local B-ROI’s of (b). In (c), the colors of
the pixels labeled in red along one side of the B-ROI look similar
without an obvious jump. In (d), the colors of the pixels labeled in
red change with one large jump.

dicating the probability of being a contour point. Then, long
contours are selected from the contour map. The contour in-
formation will be used to generate the desired color palette,
based on which the initial segmentation result is directly ob-
tained (module 2), followed by an effective post-processing
step (module 3). Both modules 2 and 3 are guided by the
contour information.

3.2. Color Palette Generation

The well-known color clustering algorithms, such as k-
means and MS [4] clustering, consider the color distribu-
tion of all pixels or superpixels in an image. However, not
all pixels and their associated colors are equally important
for the segmentation purpose as illustrated by the following
two examples. First, the strong color-varying pixels inside
a texture region (e.g., a large number of ﬂowers in a garden
in Fig. 3(a)), where the complexity of the color represen-
tation increases, are actually of less importance. Second,
the pixels of similar colors inside a homogeneous region
(e.g., a large near-white building in Fig. 3(e)), that gives
many redundant color samples in the color space, are also
not that important. A relatively minor variation in these
images (e.g., the ﬂower density and the wall size, respec-
tively) will affect the color-based segmentation. Generally
speaking, these algorithms are sensitive to their parameter
settings, and it is challenging to automatically ﬁnd a good
parameter set for an arbitrary image.

To develop a robust segmentation algorithm, we attempt
to reduce the inﬂuence of color variations in an image by
selecting a set of representative colors. To achieve this,

(a)

(c)

(e)

(b)

(d)

(f)

Figure 3. Comparison of CCP segmentation results before and af-
ter post-processing. Please focus on the squared regions in red: (a)
shows a long contour straddled by two regions with similar colors;
(c) shows the fake boundary in the sky due to gradual color transi-
tion; (e) shows small segments in the background building region.
(b), (d), and (f) are the post-processed results of (a), (c), and (e),
respectively.

we focus on key regions and obtain color samples accord-
ingly. For image segmentation, one would like to have large
segments and ignore small ones. Since large segments are
enclosed by long contours, we can deﬁne a banded region
of interest (B-ROI) for each long contour and its neighbor-
hood. The B-ROI is centered at the contour location with
a bandwidth of 2δ as shown in Fig. 2(a). After obtaining
the B-ROI, we sample pixels from both sides of the con-
tour with a uniform stepsize ∆ and have their colors in the
Lab color space [21] to form a set of representative colors.
In the implementation, we used the structured edge detec-
tion algorithm [6] to extract the contour and set δ = 2 and
∆ = 1 pixels, respectively.

We observe two typical cases for pixels along one side
of the B-ROI for different images. First, the color remains
about the same or changes gradually without an obvious
jump. Second, the color changes with one or several large
jumps, yet each interval between two jumps does have a
similar color. These two cases are shown in Figs. 2(b)-(d),
where Fig. 2(b) is an illustrative image overlaid with long
contours while Figs. 2(c) and (d) provide the zoom-in im-
ages of two local regions of Fig. 2(b) and correspond to the
two cases, respectively. For Case 1, as shown in Fig. 2(c),
color samples can be further reduced to their average color.
For Case 2, we need to select multiple color samples, each

1620

of which represents the color in one interval. As shown in
Fig. 2(d), the B-ROI goes through the deer body at one side
and two background regions at the other side. In this case,
we need to split the color samples into two groups and each
group is represented by its average color.

Further color simpliﬁcation required by Case 1 and 2 can
be achieved by MS clustering with bandwidth parameter hr
in the spectral domain. Another is to adopt MS clustering
with different bandwidth parameters for sampled colors lo-
cated in different regions of the image. Since the object
of interest is usually in the central region while the back-
ground is in the boundary region of an image, we adopt two
bandwidth parameters, i.e., a smaller one and a larger one
(hrc, hrb), for sampled colors in the central and boundary
regions, respectively. The ﬁnal representative color set is
called the color palette of the input image. Then, a color-
quantized image can be obtained by replacing the color of
each pixel with its most similar color in the color palette. In
this way, an initial segmentation result is obtained.

3.3. Segment Post Processing

Three post-processing techniques are proposed to better
the segmentation result: 1) leakage avoidance by contours,
2) fake boundary removal, and 3) small region mergence, as
illustrated in Fig. 3.

The ﬁrst problem arises when there is a long contour
straddled by two regions with similar colors. One such ex-
ample is given in Fig. 3(a), where the white fence and the
white collar are close in color but separated by a long con-
tour. After color quantization, the fence is mingled with the
collar to yield complicated patterns and, as a result, these
two regions are blurred. This is known as the leakage prob-
lem. To avoid this, we check the regions along each side of
the contour in the B-ROI. After color quantization, even if
both sides of the contour are quantized into the same color,
they are still separated by the long contour.

The second problem occurs when there is a smooth color
transition over a large region. For example, the sky color in
Fig. 3(c) changes smoothly and it is split into multiple re-
gions due to color quantization. This fake boundary can
be removed by checking the common boundary of adjacent
regions. We consider the ratio of the length of the com-
mon boundary and the minimum perimeter of the two re-
gions, which indicates the relative signiﬁcance of the com-
mon boundary. If the common boundary is signiﬁcant and
not overlaid much with detected long contours, these two
regions will be merged. By this criterion, isolated regions
have a high priority to be merged when there is not a long
contour around them.

The third problem occurs in the textured area such as the
background building with small windows in Fig. 3(e). They
are merged to the closest “effective neighbors” for simplic-
ity. This can be implemented by merging a small region to

its neighbor region of a similar color but without a contour
in between.

Since region aggregation is irreversible, we need to pay
special attention to the order of fake boundary removal and
small region mergence. In the beginning, region sizes are
relatively small. The small region mergence process might
merge two similar regions in the dark or blurred area, lead-
ing to the leakage problem. However, the fake boundary re-
moval process does not have this side effect. For this reason,
we conduct fake boundary removal before small region re-
moval. Fake boundary removal and small region mergence
can be conducted iteratively to achieve better performance.
We conduct the iteration twice in the implementation. The
post-processed results of Figs. 3(a), (c) and (e) are shown
in Figs. 3(b), (d) and (f), respectively.

4. Comparison of MS and CCP

In Fig. 4, we compare in detail the segmentation results
of mean-shift (MS) method and our CCP method for three
typical images, denoted as #1, #2 and #3 from the left to the
right. For MS, we select three best spectral bandwidth (BW)
parameters from all the odd numbers between 5 and 25, re-
sulting in 7 (small), 13 (medium) and 19 (large); for CCP,
we select the spectral BW parameters as hr = 5 (small),
(hrc, hrb) = (5, 7) (medium) and hr = 7 (large) in the
color palette generation process. The spatial BW param-
eter is set to 7 in all MS results while no spatial BW pa-
rameter is required by CCP. We can see that CCP provides
simpliﬁed segmentation results, which are more consistent
with human perception and can serve as standalone solu-
tions. In contrast, MS gives highly over-segmented images
that are not acceptable to human eyes even if the spectral
BW parameter is large enough. Similar conclusions were
drawn from all the 300 images in the Berkeley Segmenta-
tion Dataset (BSDS) [13]. It is no doubt that CCP visually
outperforms MS by a signiﬁcant margin.

Selection of proper spectral and spatial BW parameters
for MS is actually a challenging task. The quality of the
MS segmentation result is sensitive to these two parameters.
They are not only image dependent but also region depen-
dent. To the best of our knowledge, there is no automatic
mechanism to select good BW parameters. For compari-
son, CCP only demands one BW parameter, and its results
are stable over a range of BW values as illustrated in Fig. 4.
This avoids the huge burden of performance ﬁne-tuning.

To explain the superior performance of CCP over MS,
we list the representative color numbers and the boundary
F-measures (harmonic mean of precision and recall, deﬁned
in [14]) under three spectral BW parameters for the three
images in Table 1. We also provide the average results of the
entire BSDS300 dataset. A smaller spectral BW parameter
usually generates more representative colors as illustrated
by the numbers in the same column in the upper half of the

1621

original

Image 
#1

Image 
#2

Image 
#3

BW

MS

CCP

MS

CCP

MS

CCP

small

medium

large

Figure 4. Comparisons of segmentation results by MS and CCP for three typical images, with different spectral BW parameters.

table. The corresponding number of representative colors
of CCP is signiﬁcantly less than those of MS, although the
three BW parameters of CCP are smaller than their coun-
terparts of MS. In addition, CCP can achieve much better
boundary F-measures than MS, as shown in the lower half
of the table. This indicates a better boundary adherence
with respect to human ground-truth boundaries. These two
comparisons show the power of color sampling along the
contours adopted by CCP. Through color sampling, we can
eliminate color samples in regions of little signiﬁcance and
merge these regions with other important ones, as shown in
the mountain, branch and tree regions of image #1, #2 and
#3, respectively. Furthermore, because CCP yields fewer
color samples in the color space, we can adopt a smaller
BW parameter without increasing the number of represen-
tative colors too much. In this way, CCP can reduce the risk
to make two colors along a signiﬁcant contour get mixed,
and thus avoid a severe leakage problem which usually oc-
curs in the MS method. For comparisons, please look at the
boundaries between the bridge and the sky, those between
the bird and the sky, and those between the face and the
building in Fig. 4.

For a segmented image, we count the number of pix-
els for a speciﬁc representative color and sort the color in-
dex according to the number of associated pixels in a de-
scending order. Then, we plot the cumulative normalized
histogram as a function of the representative color index,
as shown in Fig. 5. The curve reaches 100% when all
representative colors are used. Let us use Image #1 as an
example. The blue, green and red curves are obtained us-
ing large, medium, and small spectral BW parameters. The
three curves of CCP reach 100% at color index #54, #68 and

Table 1. Comparisons of the numbers of representative colors (up-
per) and the boundary F-measures (lower) by MS and CCP under
three BW parameters for the three typical images. We also provide
the average results of the entire BSDS300 dataset.

BW

s.
m.
l.
s.
m.
l.

MS

CCP

#1
116
100
98
0.70
0.69
0.68

#2
116
117
113
0.67
0.64
0.60

#3
217
218
215
0.72
0.75
0.76

All
192
178
173
0.59
0.60
0.60

#1
66
68
54
0.75
0.75
0.74

#2
83
85
75
0.75
0.75
0.74

#3
118
122
107
0.78
0.80
0.78

All
81
77
63
0.68
0.68
0.68

#66 while those of MS reach 100% at color index #98, #100
and #116, respectively, as indicated by the data in Table 1.
Meanwhile, CCP can achieve around 10% higher bound-
ary F-measures than MS. There are a few dominant colors
in simple images such as Images #1 and #2, which can be
caught by both CCP and MS. CCP reaches a higher percent-
age than MS with these dominant colors. Image #3 is more
complicated in its content and more representative colors
are needed. In all three cases, along with better boundary
adherence, the CCP curves are closer to the upper-left cor-
ner of the ﬁgure than MS. This indicates that CCP can use
fewer colors to represent a larger region of an image and
provide a more simpliﬁed result. Similar conclusions were
drawn from all 300 images in the BSDS dataset.

5. Layered Afﬁnity Models using CCP

Spectral segmentation has received a lot of attention in
recent years due to its impressive performance [5, 18]. It
begins with a graph representation of a given image, where

1622

1

0.5

1

0.5

1

0.5

m
a
r
g
o
t
s
H
e
v
i
t

 

i

l

a
u
m
u
C

i

m
a
r
g
o
t
s
H
 
e
v
i
t
a
u
m
u
C

l

i

m
a
r
g
o
t
s
H
 
e
v
i
t
a
u
m
u
C

l

1

0.5

1

0.5

1

0.5

m
a
r
g
o
t
s
H
e
v
i
t

 

i

l

a
u
m
u
C

i

m
a
r
g
o
t
s
H
 
e
v
i
t
a
u
m
u
C

l

i

m
a
r
g
o
t
s
H
 
e
v
i
t
a
u
m
u
C

l

0
0
Representative Color Index

100

50

0
0
Representative Color Index

100

50

(a) MS, Image #1

(b) CCP, Image #1

0
0
Representative Color Index

100

50

0
0
Representative Color Index

100

50

(c) MS, Image #2

(d) CCP, Image #2

0
0
200
100
Representative Color Index

0
0
200
100
Representative Color Index

(e) MS, Image #3

(f) CCP, Image #3

Figure 5. Plots of the cumulative histogram versus representative
color indices for MS and CCP on three typical images, where the
blue, green and red curves are obtained using large, medium and
small spectral BW parameters.

each pixel is a node. Then, a sparse afﬁnity matrix is cre-
ated to measure the similarity between nearby nodes, while
ignoring the connection among distant nodes even if they
are in the same homogeneous region; say, two distant nodes
in the same sky region. The simpliﬁcation of sparse afﬁn-
ity matrices often leads to over-segmentation. To overcome
this problem, a layered afﬁnity model was introduced to al-
low more connections, such as the full pairwise afﬁnity in
MLSS [11] and the bipartite graph partitioning in SAS [12].
These methods share one common idea, namely, building a
graph model consisting of multiple layers. The ﬁnest one is
the pixel layer as constructed by the standard spectral seg-
mentation method. Then, one can add a couple of coarse
layers on top of the pixel layer, where each coarse layer
uses superpixels as its nodes and deﬁnes an afﬁnity ma-
trix accordingly. Typically, these superpixel layers are con-
structed using the MS [4] and the FH graph-based [8] meth-
ods. Finally, nodes between different layers are connected
by an across-afﬁnity matrix. Although these methods share
the same basic idea, they differ in the details of the layered

afﬁnity matrix implementation.

To further improve the segmentation result of CCP, we
can leverage the two layered afﬁnity models proposed in
MLSS and SAS. The integrated methods are called CCP-
LAM (where LAM denotes “layer-afﬁnity by MLSS”) and
CCP-LAS (where LAS denotes “layer-afﬁnity by SAS”),
respectively. CCP-LAM and CCP-LAS can be easily ob-
tained by replacing the superpixel layers in MLSS and SAS,
respectively, by the CCP segmentations as described in Sec.
3, with the pixel layer kept as the ﬁnest layer.

It was observed in [11] and [12] that the ﬁnal image seg-
mentation result can beneﬁt from the diversity of multiple
coarse layers. Following this line of thought, we create mul-
tiple CCP segmentations by varying bandwidth parameter
hr or (hrc, hrb) of the MS algorithm in the color palette
generation process, which has been discussed in Sec. 3.2.

6. Experimental Results

In this section, we evaluate the performance of three
CCP segmentation results by consider three parameter set-
tings: 1) CCP-1, hr = 5; 2) CCP-2, (hrc, hrb) = (5, 7);
and 3) CCP-3, hr = 7. Furthermore, we take CCP-1,
CCP-2 and CCP-3 as three coarse layers in the context of
spectral segmentation with two layered afﬁnity models (i.e.,
LAM and LAS) to result in CCP-LAM and CCP-LAS meth-
ods. To achieve the optimal performance of CCP-LAM and
CCP-LAS, we follow the procedure stated in [11, 12] to
manually select the best segment number using the LAM or
LAS graph.

We compare the performance of CCP-1, CCP-2, CCP-
3, CCP-LAM and CCP-LAS with several benchmarking
methods on the Berkeley Segmentation Dataset (BSDS)
[13] in Table 2. The BSDS benchmark consists of 300 color
images of size 481×321 pixels displayed either horizontally
or vertically, and several hand-labeled segmentations were
collected from different human subjects for each image.
The benchmarking methods include NCut [18], MNCut [5],
MS [4], FH [8], SDTV [7], RIS-HL [22], MLSS [11], and
SAS [12]. Their numbers are taken from [7, 11, 12, 22].

As shown in Table 2, ﬁve performance metrics (e.g.,
[7, 11, 12, 22]) are used for quantitative evaluation. They
are: 1) Segmentation Covering (Cov) [2], which measures
the region-wise covering of the ground truth by a segmenta-
tion; 2) Probabilistic Rand Index (PRI) [20], which counts
the likelihood of pixel pairs whose labels are consistent be-
tween a segmentation and the ground truth; 3) Variation
of Information (VoI) [15], which measures the amount of
randomness in one segmentation that cannot be contained
by the other; 4) Global Consistency Error (GCE) [13],
which measures the extent to which one segmentation can
be viewed as a reﬁnement of the other; 5) Boundary Dis-
placement Error (BDE) [9], which measures the average
displacement error of boundary pixels between two seg-

1623

mented images. The segmentation result is better if Cov
and PRI are larger while the other three criteria (VoI, GCE
and BDE) are smaller. The best and the second best results
in Table 2 are highlighted in red and blue, respectively.

We draw the following conclusions from Table 2. First,
CCP-LAM and CCP-LAS achieved the best performance
in terms of all ﬁve metrics by a large margin. Second, all
the three CCP methods had outstanding performance in the
GCE and BDE metrics. This means that CCP yields an
excellent segmentation with better boundary adherence and
less displacement error with respect to the ground truth. It is
worthwhile to emphasize that no image-dependent param-
eter was used in CCP-1, CCP-2 and CCP-3. The same pa-
rameter setting is applied to all the images. In contrast, a set
of experiments were run in all other benchmarking methods,
and the best result for each image was selected and used in
performance computation.

Table 2. Performance comparison of several segmentation meth-
ods on the BSDS300 Dataset, where the best two results are high-
lighted in red (best) and blue (second best).
VoI
Cov
2.9061
0.44
2.4701
0.44
1.9725
0.54
3.3949
0.51
1.8165
0.57
1.8232
0.59
1.8545
0.53
1.6849
0.62
2.8502
0.47
2.7835
0.48
2.4723
0.53
1.5715
0.68
1.5871
0.68

Algorithm
NCut [18]
MNCut [5]
MS [4]
FH [8]
SDTV [7]
RIS-HL [22]
MLSS [11]
SAS [12]
CCP-1
CCP-2
CCP-3
CCP-LAM
CCP-LAS

PRI
0.7242
0.7559
0.7958
0.7139
0.7758
0.8137
0.8146
0.8319
0.7900
0.7932
0.8014
0.8404
0.8442

GCE
0.2232
0.1925
0.1888
0.1746
0.1768
0.1805
0.1809
0.1779
0.1046
0.1077
0.1270
0.1635
0.1582

BDE
17.15
15.10
14.41
16.67
16.24
13.07
12.21
11.29
11.26
11.17
11.29
10.20
10.46

Furthermore, Fig. 6 shows the segmentation results of
ten images by MLSS, SAS, CCP-LAM and CCP-LAS for
visual comparison. Again, CCP-LAM and CCP-LAS pro-
duced signiﬁcantly better and meaningful segmentation re-
sults over MLSS and SAS in terms of visual appearance.

7. Conclusions

The contour-guided color palette (CCP) was proposed
for robust image segmentation. This method effectively in-
tegrated the contour and color cues of an image, reduced its
color complexity, and kept a sufﬁcient number of distinc-
tive colors to achieve the desired segmentation task. Based
on the image-speciﬁc color palette, a preliminary segmen-
tation was obtained and it was further ﬁne-tuned by post-
processing techniques. The CCP method produced an ac-
ceptable standalone segmentation result, which could be
further integrated with layered afﬁnity models for spectral
segmentation. The superior performance of the proposed

CCP-LAM and CCP-LAS methods over existing state-of-
the-art methods was demonstrated by extensive experimen-
tal results.

References

[1] R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, and
S. Ssstrunk. Slic superpixels compared to state-of-the-art su-
perpixel methods. IEEE Trans. Pattern Anal. Mach. Intell.,
pages 2274–2282, 2012.

[2] P. Arbelaez, M. Maire, C. Fowlkes, and J. Malik. Contour
detection and hierarchical image segmentation. IEEE Trans.
Pattern Anal. Mach. Intell., 33(5):898–916, May 2011.
[3] V. Bruce, M. A. Georgeson, and P. R. Green. Visual Per-
ception: Physiology, Psychology and Ecology. Psychology
Press, 4th edition, 2003.

[4] D. Comaniciu and P. Meer. Mean Shift: A robust approach
IEEE Trans. Pattern Anal.

toward feature space analysis.
Mach. Intell., 24(5):603–619, May 2002.

[5] T. Cour, F. Benezit, and J. Shi. Spectral segmentation with
multiscale graph decomposition. In CVPR’05, pages 1124–
1131, 2005.

[6] P. Dollr and C. L. Zitnick. Structured forests for fast edge

detection. In ICCV’13, pages 1841–1848, 2013.

[7] M. Donoser, M. Urschler, M. Hirzer, and H. Bischof.
In ICCV’09,

Saliency driven total variation segmentation.
pages 817–824, 2009.

[8] P. F. Felzenszwalb and D. P. Huttenlocher.

Efﬁcient
Int. J. Comput. Vision,

graph-based image segmentation.
59(2):167–181, Sept. 2004.

[9] J. Freixenet, X. Mu˜noz, D. Raba, J. Mart´ı, and X. Cuf´ı. Yet
another survey on image segmentation: Region and bound-
In ECCV’02, pages 408–422,
ary information integration.
2002.

[10] J. J. Gibson. The perception of the visual world. Houghton

Mifﬂin, 1950.

[11] T. H. Kim, K. M. Lee, and S. U. Lee. Learning full pair-
wise afﬁnities for spectral segmentation. IEEE Trans. Pat-
tern Anal. Mach. Intell., 35(7):1690–1703, July 2013.
[12] Z. Li, X.-M. Wu, and S.-F. Chang. Segmentation Using
Superpixels: A bipartite graph partitioning approach.
In
CVPR’12, pages 789–796, 2012.

[13] D. Martin, C. Fowlkes, D. Tal, and J. Malik. A database
of human segmented natural images and its application to
evaluating segmentation algorithms and measuring ecologi-
cal statistics. In ICCV’01, pages 416–423, 2001.

[14] D. R. Martin, C. C. Fowlkes, and J. Malik. Learning to de-
tect natural image boundaries using local brightness, color,
and texture cues. IEEE Trans. Pattern Anal. Mach. Intell.,
26(5):530–549, May 2004.

[15] M. Meilˇa. Comparing Clusterings: An axiomatic view. In

ICML’05, pages 577–584, 2005.

[16] X. Mu˜noz, J. Freixenet, X. Cuf´ı, and J. Mart´ı. Strategies for
image segmentation combining region and boundary infor-
mation. Pattern Recogn. Lett., 24(1-3):375–392, Jan. 2003.
[17] J. B. Roerdink and A. Meijster. The watershed transform:
Deﬁnitions, algorithms and parallelization strategies. Fun-
dam. Inf., 41(1,2):187–228, Apr. 2000.

1624

(a) Original

(b) Ground Truths

(c) MLSS [11]

(d) SAS [12]

(e) CCP-LAM

(f) CCP-LAS

Figure 6. Visual comparisons of segmentation results of CCP-LAM and CCP-LAS against two state-of-the-art methods MLSS and SAS.
For more result comparisons, please refer to the supplementary material.

[18] J. Shi and J. Malik. Normalized cuts and image segmenta-
IEEE Trans. Pattern Anal. Mach. Intell., 22(8):888–

Trans. Pattern Anal. Mach. Intell., 29(6):929–944, June
2007.

tion.
905, Aug. 2000.

[19] C. Tomasi and R. Manduchi. Bilateral ﬁltering for gray and

color images. In ICCV ’98, pages 839–846, 1998.

[20] R. Unnikrishnan, C. Pantofaru, and M. Hebert. Toward ob-
jective evaluation of image segmentation algorithms. IEEE

[21] Wikipedia. Lab color space - Wikipedia, the free encyclope-

dia, 2015 (accessed April-2015).

[22] J. Wu, J. Zhu, and Z. Tu. Reverse image segmentation: A
high-level solution to a low-level task. In Proceedings of the
British Machine Vision Conference. BMVA Press, 2014.

1625

Robust Image Segmentation Using Contour-guided Color Palettes

Xiang Fu1, Chien-Yi Wang1, Chen Chen1, Changhu Wang2∗, C.-C. Jay Kuo1
1University of Southern California, Los Angeles, California, USA
2Microsoft Research, Beijing, China
{xiangfu, chienyiw, chen80}@usc.edu, chw@microsoft.com, cckuo@sipi.usc.edu

Abstract

The contour-guided color palette (CCP) 1 is proposed
for robust image segmentation. It efﬁciently integrates con-
tour and color cues of an image. To ﬁnd representative
colors of an image, color samples along long contours be-
tween regions, similar in spirit to machine learning method-
ology that focus on samples near decision boundaries, are
collected followed by the mean-shift (MS) algorithm in the
sampled color space to achieve an image-dependent color
palette. This color palette provides a preliminary segmen-
tation in the spatial domain, which is further ﬁne-tuned by
post-processing techniques such as leakage avoidance, fake
boundary removal, and small region mergence. Segmenta-
tion performances of CCP and MS are compared and an-
alyzed. While CCP offers an acceptable standalone seg-
mentation result, it can be further integrated into the frame-
work of layered spectral segmentation to produce a more
robust segmentation. The superior performance of CCP-
based segmentation algorithm is demonstrated by experi-
ments on the Berkeley Segmentation Dataset.

1. Introduction

Automatic image segmentation is a fundamental prob-
lem in computer vision. It plays an important role in di-
verse applications, such as object detection, scene parsing,
and image retrieval. It partitions an image into a small num-
ber of disjointed coherent regions with low-level features,
with the goal of minimizing intra-variance and maximizing
inter-variance among regions. It is desired that the segmen-
tation result is close to human semantic understanding and
not sensitive to parameter setting and/or image content.

To segment an image, pixel (or superpixel) grouping in
the spatial and spectral domains were performed in the lit-
erature. Typically, spatial-domain pixel grouping is guided
by contours [2, 7] while spectral-domain pixel grouping is

∗Corresponding Author
1The MATLAB code of CCP Segmentation can be downloaded at

https://github.com/fuxiang87/MCL_CCP.

achieved by clustering in a color space [17, 4, 5, 8, 11, 12,
18]. Thus, contours and colors are two widely used features
in image segmentation, yet each of them has its own limita-
tions. For example, contours are not reliable if they are short
and fragmented. They might fail to separate two regions if
parts of their common boundaries are blurred and/or with
a low contrast. The color feature is not effective to han-
dle regions with textures or gradual color transition, lead-
ing to over-segmentation. One common challenge in these
methods is the selection of proper parameters, such as the
color clustering bandwidth. In general, these optimal pa-
rameters are image dependent and difﬁcult to determine. In
this work, we integrate contour and color cues under one
uniﬁed framework, and propose the contour-guided color
palette (CCP) for robust image segmentation. That is, it has
only one key parameter and its performance is stable when
the parameter lies in a suitable range.

The basic idea of CCP is described as follows. To ﬁnd
representative colors of a given image, we collect color
samples from both sides of long contours, and conduct the
mean-shift (MS) algorithm [4] in the sampled color space to
deﬁne an image-speciﬁc color palette. This scheme reduces
color complexity of the original image, yet keeps a sufﬁ-
cient number of representative colors to separate distinctive
regions and yield a preliminary segmentation. This result
is further reﬁned by post-processing techniques in the spa-
tial domain, which leads to a robust standalone segmenta-
tion. The CCP result can be applied to any superpixel-based
segmentation algorithm by replacing the over-segmentation
layer, such as mean-shift (MS) [4], Felzenszwalb and Hut-
tenlocher’s graph-based (FH) [8], and SLIC [1] superpix-
els. Furthermore, it can be integrated into the layered spec-
tral segmentation framework, such as multi-layer spectral
segmentation (MLSS) [11] and segmentation by aggregat-
ing superpixels (SAS) [12], and used as a coarse layer in
this context for a more robust segmentation. The supe-
rior performance of CCP-based segmentation algorithms
are demonstrated in the experiments on the Berkeley Seg-
mentation Dataset (BSDS) [13].

The rest of this paper is organized as follows. Related

11618

Contour Map

Long Contours

Original

Denoised

Color Palette 
Generation

Leakage 
Avoidance

Fake 
Boundary 
Removal

Small 
Region 
Mergence

CCP

Image Pre-Processing

Initial Segmentation

Segment Post-Processing

Figure 1. The block diagram of the proposed contour-guided color palette (CCP) method.

work is reviewed in Sec. 2. The CCP method is described
in detail in Sec. 3. The advantages of CCP over MS are an-
alyzed in Sec. 4. Then, the integration of CCP with layered
spectral segmentation is introduced in Sec. 5. Experimental
results are shown in Sec. 6. Finally, concluding remarks are
given in Sec. 7.

2. Related Work

According to the studies on human visual perception
[10, 3], people pay more attention to dissimilarities between
two regions and lean to group similar regions in appear-
ance, which correspond to the contour (1D) and regional
(2D) cues, respectively. Both of the two cues are needed for
a better image segmentation. Regional cues are contributed
by color and texture. Most image segmentation algorithms
can be classiﬁed into two categories, i.e., region-based and
contour-based methods.

Region-based methods ﬁnd the similarity among spa-
tially connected pixels and group them together using sur-
face properties such as luminance and color. Representative
approaches include watershed [17], k-means, mean-shift
(MS) [4], normalized cuts (NCut) [5, 18], Felzenszwalb
and Huttenlocher’s graph-based (FH) [8], multi-layer spec-
tral segmentation (MLSS) [11], and segmentation by ag-
gregating superpixels (SAS) [12]. However, these meth-
ods might neglect obvious discontinuities between two re-
gions. To overcome this limitation, contour-based methods,
such as gPb-OWT-UCM [2], and saliency driven total vari-
ation (SDTV) [7] were developed to ﬁnd connected regions
blocked by detected contours. However, it is still challeng-
ing to detect closed contours in low-contrast or blurred re-
gions for segmentation.

One can combine region and contour cues to overcome
their individual limitations, and several ideas were intro-
duced in [9, 16]. For example, one can take the contour cue
as a post-processing step to correct region-based segmen-

tation results or treat the contour as a barrier in an afﬁnity
measure.

In this work, a new method called CCP is proposed to ef-
fectively integrate contour and color cues. Unlike the other
methods, we take the contour cue as guidance to form an
image-dependent color palette. It reduces color complexity
of the original image, yet keeps a sufﬁcient number of rep-
resentative colors to separate distinctive regions. The CCP
method is detailed in the following section.

3. Contour-guided Color Palette Method

3.1. System Overview

The basic idea of the CCP method can be simply stated
as follows. Long contours play an important role in image
segmentation since they provide useful spatial-domain in-
formation in region partition. However, they may not form
a closed region due to weak boundaries in some parts, lead-
ing to the leakage problem. To assist contour-guided seg-
mentation, we use the color information as an auxiliary cue.
That is, we collect color samples along both sides of each
long contour and perform clustering in the sampled color
space for color quantization. Once color is quantized, we
get a number of closed regions with long contours as their
boundaries. This initial segmentation can be further reﬁned
by post-processing techniques in the spatial domain. Fig. 1
shows the block diagram of the CCP method, which mainly
consists of three modules: (1) image pre-processing, (2)
contour-guided color palette generation for an initial seg-
mentation, and (3) segment post-processing.

The image pre-processing module includes denoising
and contour extraction. There are many standard algorithms
to select for this module. In our implementation, we adopt
the bilateral ﬁltering scheme [19] for denoising. And, we
apply the structured edge detection [6] method to the origi-
nal input image to obtain a contour map with pixel value in-

1619

δ
δ

Δ 

(a)

(c)

(b)

(d)

Figure 2. Illustration of banded region of interest (B-ROI) for color
palette generation. (a) shows a B-ROI with a bandwidth of 2δ.
Pixels are sampled from both sides of the contour with a uniform
stepsize ∆. (b) is an example image overlaid with detected long
contours. Long contours are indicated by different colors. (c) and
(d) are the zoom-in of two local B-ROI’s of (b). In (c), the colors of
the pixels labeled in red along one side of the B-ROI look similar
without an obvious jump. In (d), the colors of the pixels labeled in
red change with one large jump.

dicating the probability of being a contour point. Then, long
contours are selected from the contour map. The contour in-
formation will be used to generate the desired color palette,
based on which the initial segmentation result is directly ob-
tained (module 2), followed by an effective post-processing
step (module 3). Both modules 2 and 3 are guided by the
contour information.

3.2. Color Palette Generation

The well-known color clustering algorithms, such as k-
means and MS [4] clustering, consider the color distribu-
tion of all pixels or superpixels in an image. However, not
all pixels and their associated colors are equally important
for the segmentation purpose as illustrated by the following
two examples. First, the strong color-varying pixels inside
a texture region (e.g., a large number of ﬂowers in a garden
in Fig. 3(a)), where the complexity of the color represen-
tation increases, are actually of less importance. Second,
the pixels of similar colors inside a homogeneous region
(e.g., a large near-white building in Fig. 3(e)), that gives
many redundant color samples in the color space, are also
not that important. A relatively minor variation in these
images (e.g., the ﬂower density and the wall size, respec-
tively) will affect the color-based segmentation. Generally
speaking, these algorithms are sensitive to their parameter
settings, and it is challenging to automatically ﬁnd a good
parameter set for an arbitrary image.

To develop a robust segmentation algorithm, we attempt
to reduce the inﬂuence of color variations in an image by
selecting a set of representative colors. To achieve this,

(a)

(c)

(e)

(b)

(d)

(f)

Figure 3. Comparison of CCP segmentation results before and af-
ter post-processing. Please focus on the squared regions in red: (a)
shows a long contour straddled by two regions with similar colors;
(c) shows the fake boundary in the sky due to gradual color transi-
tion; (e) shows small segments in the background building region.
(b), (d), and (f) are the post-processed results of (a), (c), and (e),
respectively.

we focus on key regions and obtain color samples accord-
ingly. For image segmentation, one would like to have large
segments and ignore small ones. Since large segments are
enclosed by long contours, we can deﬁne a banded region
of interest (B-ROI) for each long contour and its neighbor-
hood. The B-ROI is centered at the contour location with
a bandwidth of 2δ as shown in Fig. 2(a). After obtaining
the B-ROI, we sample pixels from both sides of the con-
tour with a uniform stepsize ∆ and have their colors in the
Lab color space [21] to form a set of representative colors.
In the implementation, we used the structured edge detec-
tion algorithm [6] to extract the contour and set δ = 2 and
∆ = 1 pixels, respectively.

We observe two typical cases for pixels along one side
of the B-ROI for different images. First, the color remains
about the same or changes gradually without an obvious
jump. Second, the color changes with one or several large
jumps, yet each interval between two jumps does have a
similar color. These two cases are shown in Figs. 2(b)-(d),
where Fig. 2(b) is an illustrative image overlaid with long
contours while Figs. 2(c) and (d) provide the zoom-in im-
ages of two local regions of Fig. 2(b) and correspond to the
two cases, respectively. For Case 1, as shown in Fig. 2(c),
color samples can be further reduced to their average color.
For Case 2, we need to select multiple color samples, each

1620

of which represents the color in one interval. As shown in
Fig. 2(d), the B-ROI goes through the deer body at one side
and two background regions at the other side. In this case,
we need to split the color samples into two groups and each
group is represented by its average color.

Further color simpliﬁcation required by Case 1 and 2 can
be achieved by MS clustering with bandwidth parameter hr
in the spectral domain. Another is to adopt MS clustering
with different bandwidth parameters for sampled colors lo-
cated in different regions of the image. Since the object
of interest is usually in the central region while the back-
ground is in the boundary region of an image, we adopt two
bandwidth parameters, i.e., a smaller one and a larger one
(hrc, hrb), for sampled colors in the central and boundary
regions, respectively. The ﬁnal representative color set is
called the color palette of the input image. Then, a color-
quantized image can be obtained by replacing the color of
each pixel with its most similar color in the color palette. In
this way, an initial segmentation result is obtained.

3.3. Segment Post Processing

Three post-processing techniques are proposed to better
the segmentation result: 1) leakage avoidance by contours,
2) fake boundary removal, and 3) small region mergence, as
illustrated in Fig. 3.

The ﬁrst problem arises when there is a long contour
straddled by two regions with similar colors. One such ex-
ample is given in Fig. 3(a), where the white fence and the
white collar are close in color but separated by a long con-
tour. After color quantization, the fence is mingled with the
collar to yield complicated patterns and, as a result, these
two regions are blurred. This is known as the leakage prob-
lem. To avoid this, we check the regions along each side of
the contour in the B-ROI. After color quantization, even if
both sides of the contour are quantized into the same color,
they are still separated by the long contour.

The second problem occurs when there is a smooth color
transition over a large region. For example, the sky color in
Fig. 3(c) changes smoothly and it is split into multiple re-
gions due to color quantization. This fake boundary can
be removed by checking the common boundary of adjacent
regions. We consider the ratio of the length of the com-
mon boundary and the minimum perimeter of the two re-
gions, which indicates the relative signiﬁcance of the com-
mon boundary. If the common boundary is signiﬁcant and
not overlaid much with detected long contours, these two
regions will be merged. By this criterion, isolated regions
have a high priority to be merged when there is not a long
contour around them.

The third problem occurs in the textured area such as the
background building with small windows in Fig. 3(e). They
are merged to the closest “effective neighbors” for simplic-
ity. This can be implemented by merging a small region to

its neighbor region of a similar color but without a contour
in between.

Since region aggregation is irreversible, we need to pay
special attention to the order of fake boundary removal and
small region mergence. In the beginning, region sizes are
relatively small. The small region mergence process might
merge two similar regions in the dark or blurred area, lead-
ing to the leakage problem. However, the fake boundary re-
moval process does not have this side effect. For this reason,
we conduct fake boundary removal before small region re-
moval. Fake boundary removal and small region mergence
can be conducted iteratively to achieve better performance.
We conduct the iteration twice in the implementation. The
post-processed results of Figs. 3(a), (c) and (e) are shown
in Figs. 3(b), (d) and (f), respectively.

4. Comparison of MS and CCP

In Fig. 4, we compare in detail the segmentation results
of mean-shift (MS) method and our CCP method for three
typical images, denoted as #1, #2 and #3 from the left to the
right. For MS, we select three best spectral bandwidth (BW)
parameters from all the odd numbers between 5 and 25, re-
sulting in 7 (small), 13 (medium) and 19 (large); for CCP,
we select the spectral BW parameters as hr = 5 (small),
(hrc, hrb) = (5, 7) (medium) and hr = 7 (large) in the
color palette generation process. The spatial BW param-
eter is set to 7 in all MS results while no spatial BW pa-
rameter is required by CCP. We can see that CCP provides
simpliﬁed segmentation results, which are more consistent
with human perception and can serve as standalone solu-
tions. In contrast, MS gives highly over-segmented images
that are not acceptable to human eyes even if the spectral
BW parameter is large enough. Similar conclusions were
drawn from all the 300 images in the Berkeley Segmenta-
tion Dataset (BSDS) [13]. It is no doubt that CCP visually
outperforms MS by a signiﬁcant margin.

Selection of proper spectral and spatial BW parameters
for MS is actually a challenging task. The quality of the
MS segmentation result is sensitive to these two parameters.
They are not only image dependent but also region depen-
dent. To the best of our knowledge, there is no automatic
mechanism to select good BW parameters. For compari-
son, CCP only demands one BW parameter, and its results
are stable over a range of BW values as illustrated in Fig. 4.
This avoids the huge burden of performance ﬁne-tuning.

To explain the superior performance of CCP over MS,
we list the representative color numbers and the boundary
F-measures (harmonic mean of precision and recall, deﬁned
in [14]) under three spectral BW parameters for the three
images in Table 1. We also provide the average results of the
entire BSDS300 dataset. A smaller spectral BW parameter
usually generates more representative colors as illustrated
by the numbers in the same column in the upper half of the

1621

original

Image 
#1

Image 
#2

Image 
#3

BW

MS

CCP

MS

CCP

MS

CCP

small

medium

large

Figure 4. Comparisons of segmentation results by MS and CCP for three typical images, with different spectral BW parameters.

table. The corresponding number of representative colors
of CCP is signiﬁcantly less than those of MS, although the
three BW parameters of CCP are smaller than their coun-
terparts of MS. In addition, CCP can achieve much better
boundary F-measures than MS, as shown in the lower half
of the table. This indicates a better boundary adherence
with respect to human ground-truth boundaries. These two
comparisons show the power of color sampling along the
contours adopted by CCP. Through color sampling, we can
eliminate color samples in regions of little signiﬁcance and
merge these regions with other important ones, as shown in
the mountain, branch and tree regions of image #1, #2 and
#3, respectively. Furthermore, because CCP yields fewer
color samples in the color space, we can adopt a smaller
BW parameter without increasing the number of represen-
tative colors too much. In this way, CCP can reduce the risk
to make two colors along a signiﬁcant contour get mixed,
and thus avoid a severe leakage problem which usually oc-
curs in the MS method. For comparisons, please look at the
boundaries between the bridge and the sky, those between
the bird and the sky, and those between the face and the
building in Fig. 4.

For a segmented image, we count the number of pix-
els for a speciﬁc representative color and sort the color in-
dex according to the number of associated pixels in a de-
scending order. Then, we plot the cumulative normalized
histogram as a function of the representative color index,
as shown in Fig. 5. The curve reaches 100% when all
representative colors are used. Let us use Image #1 as an
example. The blue, green and red curves are obtained us-
ing large, medium, and small spectral BW parameters. The
three curves of CCP reach 100% at color index #54, #68 and

Table 1. Comparisons of the numbers of representative colors (up-
per) and the boundary F-measures (lower) by MS and CCP under
three BW parameters for the three typical images. We also provide
the average results of the entire BSDS300 dataset.

BW

s.
m.
l.
s.
m.
l.

MS

CCP

#1
116
100
98
0.70
0.69
0.68

#2
116
117
113
0.67
0.64
0.60

#3
217
218
215
0.72
0.75
0.76

All
192
178
173
0.59
0.60
0.60

#1
66
68
54
0.75
0.75
0.74

#2
83
85
75
0.75
0.75
0.74

#3
118
122
107
0.78
0.80
0.78

All
81
77
63
0.68
0.68
0.68

#66 while those of MS reach 100% at color index #98, #100
and #116, respectively, as indicated by the data in Table 1.
Meanwhile, CCP can achieve around 10% higher bound-
ary F-measures than MS. There are a few dominant colors
in simple images such as Images #1 and #2, which can be
caught by both CCP and MS. CCP reaches a higher percent-
age than MS with these dominant colors. Image #3 is more
complicated in its content and more representative colors
are needed. In all three cases, along with better boundary
adherence, the CCP curves are closer to the upper-left cor-
ner of the ﬁgure than MS. This indicates that CCP can use
fewer colors to represent a larger region of an image and
provide a more simpliﬁed result. Similar conclusions were
drawn from all 300 images in the BSDS dataset.

5. Layered Afﬁnity Models using CCP

Spectral segmentation has received a lot of attention in
recent years due to its impressive performance [5, 18]. It
begins with a graph representation of a given image, where

1622

1

0.5

1

0.5

1

0.5

m
a
r
g
o
t
s
H
e
v
i
t

 

i

l

a
u
m
u
C

i

m
a
r
g
o
t
s
H
 
e
v
i
t
a
u
m
u
C

l

i

m
a
r
g
o
t
s
H
 
e
v
i
t
a
u
m
u
C

l

1

0.5

1

0.5

1

0.5

m
a
r
g
o
t
s
H
e
v
i
t

 

i

l

a
u
m
u
C

i

m
a
r
g
o
t
s
H
 
e
v
i
t
a
u
m
u
C

l

i

m
a
r
g
o
t
s
H
 
e
v
i
t
a
u
m
u
C

l

0
0
Representative Color Index

100

50

0
0
Representative Color Index

100

50

(a) MS, Image #1

(b) CCP, Image #1

0
0
Representative Color Index

100

50

0
0
Representative Color Index

100

50

(c) MS, Image #2

(d) CCP, Image #2

0
0
200
100
Representative Color Index

0
0
200
100
Representative Color Index

(e) MS, Image #3

(f) CCP, Image #3

Figure 5. Plots of the cumulative histogram versus representative
color indices for MS and CCP on three typical images, where the
blue, green and red curves are obtained using large, medium and
small spectral BW parameters.

each pixel is a node. Then, a sparse afﬁnity matrix is cre-
ated to measure the similarity between nearby nodes, while
ignoring the connection among distant nodes even if they
are in the same homogeneous region; say, two distant nodes
in the same sky region. The simpliﬁcation of sparse afﬁn-
ity matrices often leads to over-segmentation. To overcome
this problem, a layered afﬁnity model was introduced to al-
low more connections, such as the full pairwise afﬁnity in
MLSS [11] and the bipartite graph partitioning in SAS [12].
These methods share one common idea, namely, building a
graph model consisting of multiple layers. The ﬁnest one is
the pixel layer as constructed by the standard spectral seg-
mentation method. Then, one can add a couple of coarse
layers on top of the pixel layer, where each coarse layer
uses superpixels as its nodes and deﬁnes an afﬁnity ma-
trix accordingly. Typically, these superpixel layers are con-
structed using the MS [4] and the FH graph-based [8] meth-
ods. Finally, nodes between different layers are connected
by an across-afﬁnity matrix. Although these methods share
the same basic idea, they differ in the details of the layered

afﬁnity matrix implementation.

To further improve the segmentation result of CCP, we
can leverage the two layered afﬁnity models proposed in
MLSS and SAS. The integrated methods are called CCP-
LAM (where LAM denotes “layer-afﬁnity by MLSS”) and
CCP-LAS (where LAS denotes “layer-afﬁnity by SAS”),
respectively. CCP-LAM and CCP-LAS can be easily ob-
tained by replacing the superpixel layers in MLSS and SAS,
respectively, by the CCP segmentations as described in Sec.
3, with the pixel layer kept as the ﬁnest layer.

It was observed in [11] and [12] that the ﬁnal image seg-
mentation result can beneﬁt from the diversity of multiple
coarse layers. Following this line of thought, we create mul-
tiple CCP segmentations by varying bandwidth parameter
hr or (hrc, hrb) of the MS algorithm in the color palette
generation process, which has been discussed in Sec. 3.2.

6. Experimental Results

In this section, we evaluate the performance of three
CCP segmentation results by consider three parameter set-
tings: 1) CCP-1, hr = 5; 2) CCP-2, (hrc, hrb) = (5, 7);
and 3) CCP-3, hr = 7. Furthermore, we take CCP-1,
CCP-2 and CCP-3 as three coarse layers in the context of
spectral segmentation with two layered afﬁnity models (i.e.,
LAM and LAS) to result in CCP-LAM and CCP-LAS meth-
ods. To achieve the optimal performance of CCP-LAM and
CCP-LAS, we follow the procedure stated in [11, 12] to
manually select the best segment number using the LAM or
LAS graph.

We compare the performance of CCP-1, CCP-2, CCP-
3, CCP-LAM and CCP-LAS with several benchmarking
methods on the Berkeley Segmentation Dataset (BSDS)
[13] in Table 2. The BSDS benchmark consists of 300 color
images of size 481×321 pixels displayed either horizontally
or vertically, and several hand-labeled segmentations were
collected from different human subjects for each image.
The benchmarking methods include NCut [18], MNCut [5],
MS [4], FH [8], SDTV [7], RIS-HL [22], MLSS [11], and
SAS [12]. Their numbers are taken from [7, 11, 12, 22].

As shown in Table 2, ﬁve performance metrics (e.g.,
[7, 11, 12, 22]) are used for quantitative evaluation. They
are: 1) Segmentation Covering (Cov) [2], which measures
the region-wise covering of the ground truth by a segmenta-
tion; 2) Probabilistic Rand Index (PRI) [20], which counts
the likelihood of pixel pairs whose labels are consistent be-
tween a segmentation and the ground truth; 3) Variation
of Information (VoI) [15], which measures the amount of
randomness in one segmentation that cannot be contained
by the other; 4) Global Consistency Error (GCE) [13],
which measures the extent to which one segmentation can
be viewed as a reﬁnement of the other; 5) Boundary Dis-
placement Error (BDE) [9], which measures the average
displacement error of boundary pixels between two seg-

1623

mented images. The segmentation result is better if Cov
and PRI are larger while the other three criteria (VoI, GCE
and BDE) are smaller. The best and the second best results
in Table 2 are highlighted in red and blue, respectively.

We draw the following conclusions from Table 2. First,
CCP-LAM and CCP-LAS achieved the best performance
in terms of all ﬁve metrics by a large margin. Second, all
the three CCP methods had outstanding performance in the
GCE and BDE metrics. This means that CCP yields an
excellent segmentation with better boundary adherence and
less displacement error with respect to the ground truth. It is
worthwhile to emphasize that no image-dependent param-
eter was used in CCP-1, CCP-2 and CCP-3. The same pa-
rameter setting is applied to all the images. In contrast, a set
of experiments were run in all other benchmarking methods,
and the best result for each image was selected and used in
performance computation.

Table 2. Performance comparison of several segmentation meth-
ods on the BSDS300 Dataset, where the best two results are high-
lighted in red (best) and blue (second best).
VoI
Cov
2.9061
0.44
2.4701
0.44
1.9725
0.54
3.3949
0.51
1.8165
0.57
1.8232
0.59
1.8545
0.53
1.6849
0.62
2.8502
0.47
2.7835
0.48
2.4723
0.53
1.5715
0.68
1.5871
0.68

Algorithm
NCut [18]
MNCut [5]
MS [4]
FH [8]
SDTV [7]
RIS-HL [22]
MLSS [11]
SAS [12]
CCP-1
CCP-2
CCP-3
CCP-LAM
CCP-LAS

PRI
0.7242
0.7559
0.7958
0.7139
0.7758
0.8137
0.8146
0.8319
0.7900
0.7932
0.8014
0.8404
0.8442

GCE
0.2232
0.1925
0.1888
0.1746
0.1768
0.1805
0.1809
0.1779
0.1046
0.1077
0.1270
0.1635
0.1582

BDE
17.15
15.10
14.41
16.67
16.24
13.07
12.21
11.29
11.26
11.17
11.29
10.20
10.46

Furthermore, Fig. 6 shows the segmentation results of
ten images by MLSS, SAS, CCP-LAM and CCP-LAS for
visual comparison. Again, CCP-LAM and CCP-LAS pro-
duced signiﬁcantly better and meaningful segmentation re-
sults over MLSS and SAS in terms of visual appearance.

7. Conclusions

The contour-guided color palette (CCP) was proposed
for robust image segmentation. This method effectively in-
tegrated the contour and color cues of an image, reduced its
color complexity, and kept a sufﬁcient number of distinc-
tive colors to achieve the desired segmentation task. Based
on the image-speciﬁc color palette, a preliminary segmen-
tation was obtained and it was further ﬁne-tuned by post-
processing techniques. The CCP method produced an ac-
ceptable standalone segmentation result, which could be
further integrated with layered afﬁnity models for spectral
segmentation. The superior performance of the proposed

CCP-LAM and CCP-LAS methods over existing state-of-
the-art methods was demonstrated by extensive experimen-
tal results.

References

[1] R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, and
S. Ssstrunk. Slic superpixels compared to state-of-the-art su-
perpixel methods. IEEE Trans. Pattern Anal. Mach. Intell.,
pages 2274–2282, 2012.

[2] P. Arbelaez, M. Maire, C. Fowlkes, and J. Malik. Contour
detection and hierarchical image segmentation. IEEE Trans.
Pattern Anal. Mach. Intell., 33(5):898–916, May 2011.
[3] V. Bruce, M. A. Georgeson, and P. R. Green. Visual Per-
ception: Physiology, Psychology and Ecology. Psychology
Press, 4th edition, 2003.

[4] D. Comaniciu and P. Meer. Mean Shift: A robust approach
IEEE Trans. Pattern Anal.

toward feature space analysis.
Mach. Intell., 24(5):603–619, May 2002.

[5] T. Cour, F. Benezit, and J. Shi. Spectral segmentation with
multiscale graph decomposition. In CVPR’05, pages 1124–
1131, 2005.

[6] P. Dollr and C. L. Zitnick. Structured forests for fast edge

detection. In ICCV’13, pages 1841–1848, 2013.

[7] M. Donoser, M. Urschler, M. Hirzer, and H. Bischof.
In ICCV’09,

Saliency driven total variation segmentation.
pages 817–824, 2009.

[8] P. F. Felzenszwalb and D. P. Huttenlocher.

Efﬁcient
Int. J. Comput. Vision,

graph-based image segmentation.
59(2):167–181, Sept. 2004.

[9] J. Freixenet, X. Mu˜noz, D. Raba, J. Mart´ı, and X. Cuf´ı. Yet
another survey on image segmentation: Region and bound-
In ECCV’02, pages 408–422,
ary information integration.
2002.

[10] J. J. Gibson. The perception of the visual world. Houghton

Mifﬂin, 1950.

[11] T. H. Kim, K. M. Lee, and S. U. Lee. Learning full pair-
wise afﬁnities for spectral segmentation. IEEE Trans. Pat-
tern Anal. Mach. Intell., 35(7):1690–1703, July 2013.
[12] Z. Li, X.-M. Wu, and S.-F. Chang. Segmentation Using
Superpixels: A bipartite graph partitioning approach.
In
CVPR’12, pages 789–796, 2012.

[13] D. Martin, C. Fowlkes, D. Tal, and J. Malik. A database
of human segmented natural images and its application to
evaluating segmentation algorithms and measuring ecologi-
cal statistics. In ICCV’01, pages 416–423, 2001.

[14] D. R. Martin, C. C. Fowlkes, and J. Malik. Learning to de-
tect natural image boundaries using local brightness, color,
and texture cues. IEEE Trans. Pattern Anal. Mach. Intell.,
26(5):530–549, May 2004.

[15] M. Meilˇa. Comparing Clusterings: An axiomatic view. In

ICML’05, pages 577–584, 2005.

[16] X. Mu˜noz, J. Freixenet, X. Cuf´ı, and J. Mart´ı. Strategies for
image segmentation combining region and boundary infor-
mation. Pattern Recogn. Lett., 24(1-3):375–392, Jan. 2003.
[17] J. B. Roerdink and A. Meijster. The watershed transform:
Deﬁnitions, algorithms and parallelization strategies. Fun-
dam. Inf., 41(1,2):187–228, Apr. 2000.

1624

(a) Original

(b) Ground Truths

(c) MLSS [11]

(d) SAS [12]

(e) CCP-LAM

(f) CCP-LAS

Figure 6. Visual comparisons of segmentation results of CCP-LAM and CCP-LAS against two state-of-the-art methods MLSS and SAS.
For more result comparisons, please refer to the supplementary material.

[18] J. Shi and J. Malik. Normalized cuts and image segmenta-
IEEE Trans. Pattern Anal. Mach. Intell., 22(8):888–

Trans. Pattern Anal. Mach. Intell., 29(6):929–944, June
2007.

tion.
905, Aug. 2000.

[19] C. Tomasi and R. Manduchi. Bilateral ﬁltering for gray and

color images. In ICCV ’98, pages 839–846, 1998.

[20] R. Unnikrishnan, C. Pantofaru, and M. Hebert. Toward ob-
jective evaluation of image segmentation algorithms. IEEE

[21] Wikipedia. Lab color space - Wikipedia, the free encyclope-

dia, 2015 (accessed April-2015).

[22] J. Wu, J. Zhu, and Z. Tu. Reverse image segmentation: A
high-level solution to a low-level task. In Proceedings of the
British Machine Vision Conference. BMVA Press, 2014.

1625

