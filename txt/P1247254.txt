Patterns for Learning with Side Information

Rico Jonschkowski1, Sebastian H¨ofer1, Oliver Brock
{RICO.JONSCHKOWSKI, SEBASTIAN.HOEFER, OLIVER.BROCK}@TU-BERLIN.DE
Robotics and Biology Laboratory, Technische Universit¨at Berlin, Berlin, Germany

6
1
0
2
 
b
e
F
 
0
1
 
 
]

G
L
.
s
c
[
 
 
5
v
9
2
4
6
0
.
1
1
5
1
:
v
i
X
r
a

Abstract
Supervised, semi-supervised, and unsupervised
learning estimate a function given input/output
samples. Generalization of the learned function
to unseen data can be improved by incorporating
side information into learning. Side information
are data that are neither from the input space nor
from the output space of the function, but include
useful information for learning it. In this paper
we show that learning with side information sub-
sumes a variety of related approaches, e.g. multi-
task learning, multi-view learning and learning
using privileged information. Our main contri-
butions are (i) a new perspective that connects
these previously isolated approaches, (ii) insights
about how these methods incorporate different
types of prior knowledge, and hence implement
different patterns, (iii) facilitating the application
of these methods in novel tasks, as well as (iv) a
systematic experimental evaluation of these pat-
terns in two supervised learning tasks.

1. Introduction

An important branch of machine learning research focuses
on supervised learning, estimating functions based on in-
put/output samples with the goal of predicting the correct
output for new inputs. However, generalization to unseen
samples always requires prior knowledge (which we re-
fer to as priors) about the target function (Mitchell, 1980;
Schaffer, 1994; Wolpert, 1996). By incorporating stronger
priors, we can learn from less input/output samples or solve
more challenging problems. But discovering useful priors
that generalize over a wide range of tasks is difﬁcult, es-
pecially if we only consider to deﬁne such priors over the
target function, its input, and its output.

For many problems, there are additional data z available
that are neither the input x nor the output y of function f
but that carry valuable information about how f maps x to
y, as illustrated in Fig. 1.

1The ﬁrst two authors contributed equally to this work.

We refer to this kind of data as
side information (Chen et al., 2012),
also known as privileged informa-
tion (Vapnik & Vashist, 2009). Ex-
amples for side information are (i)
intermediate results computed by the
true underlying f , (ii) output of a
related function (with input x) that
shares computations with f , (iii) in-
put of a related function (with out-
put y) that shares computations with f , or (iv) relations
between inputs xi and xj or between outputs yi and yj.

Figure 1. Side
information z is
related to function
f (x) = y.

Example: Suppose we want to estimate a function from
the input/output samples: 3 (cid:55)→ 14, 5 (cid:55)→ 30, and 2 (cid:55)→ 9. From
looking at these data, it is not immediately obvious what
the true underlying function is. However, if we provide
side information and the prior that they correspond to in-
termediate values that f computes, in this case 3 (cid:55)→ 9 (cid:55)→ 14,
5 (cid:55)→ 25 (cid:55)→ 30, and 2 (cid:55)→ 4 (cid:55)→ 9, we see that the function ﬁrst
squares its input and then adds ﬁve to the intermediate re-
sult, f (x) = x2 + 5. Side information together with a prior
about how they relate to f reveal the underlying function.

Incorporating priors about how z relates to f is what we
call learning with side information. By enforcing consis-
tency with these priors, we regularize learning which im-
proves generalization. Note that we use side information
only during training, not for prediction. There are a num-
ber of approaches in the literature that (often implicitly)
follow the paradigm of learning with side information and
demonstrate impressive results. This paper connects these
lines of work, makes the underlying paradigm explicit, and
attributes the improved generalization to the use of priors
enabled by side information.

1.1. Prior Knowledge in Machine Learning

As mentioned before, machine learning incorporates priors
about the target function f to generalize beyond observed
data. Although not always stated explicitly, priors about
f are reﬂected in every component of a machine learning
approach: in the hypothesis space (e.g. by deﬁning fea-
tures, kernels, neural network structure), in the generation
of training data (e.g. by data augmentation), in the learn-

Patterns for Learning with Side Information

ing procedure (e.g. by following a curriculum or decaying
the learning rate), and in the learning objective (e.g. by
including a regularization loss).

Learning with side information provides an effective way
to incorporate priors into the learning objective by exploit-
ing data that are neither input nor output data of the target
function f and are only required during training time. Note
the difference to unsupervised and semi-supervised learn-
ing which only consider additional input data.

1.2. Contribution

This paper, for the ﬁrst time, systematically analyzes how
to exploit side information for improving generalization. It
makes four main contributions:

The ﬁrst contribution is a new perspective on machine learn-
ing problems. This perspective connects approaches from
the literature such as multi-task learning, multi-view learn-
ing, slow feature analysis, learning using privileged infor-
mation, as well as several recent works in deep learning. By
connecting these lines of work, which previously did not
reference each other, we enable a new exchange of ideas
between them. To facilitate communication, we provide
a unifying formalization of learning with side information
(Sec. 2).

Our second contribution is a number of insights about these
methods. First, they form a small set of patterns (Sec. 3)
that correspond to different relationships between side in-
formation and target function (i-iv, second paragraph of the
introduction). Second, the pattern’s effectiveness in gener-
alization is a result of incorporating priors about these rela-
tionships. Since patterns incorporate different priors, their
effectiveness must depend on whether the learning task and
side information match the prior. We, therefore, hypothe-
size that different patterns work for different tasks.

As our third contribution, we demonstrate how our insights
advance learning with side information. First, we use the
presented patterns to systematically compare different ways
to use side information. Second, we present a new pattern
that has not been studied in the literature (Sec. 3.3). Third,
we facilitate the practical application of learning with side
information by giving a broad overview of successful ap-
plications in the literature (Appendix2 C) and by making
our implementation publicly available3.

The fourth contribution is a systematic experimental eval-
uation methods for learning with side information (Sec. 4).
Our experiments conﬁrm results from the literature by show-
ing that learning with side information greatly improves

2The appendix can be found in the supplementary material.
3Our code for learning with side information is available at

https://github.com/tu-rbo/concarne

generalization. Moreover, the results support our hypothe-
sis from contribution two, showing that a pattern’s perfor-
mance strongly depends on the given task and the available
side information.

2. Learning with Side Information

In learning with side information, we estimate a function
f : x → y and optionally an auxiliary function β by mini-
mizing two objective functions, the main objective Lf and
the side objective Lz:

argminf Lf (f | {xi, yi}N
i=1),
argminf,β Lz(f, β | {xi, yi}N

i=1, {zj}M

j=1).

To deﬁne Lf , we assume a supervised learning setting,
in which the goal is to estimate a function f : x → y
from a set of N input/output pairs {xi, yi}N
i=1. Then, Lf
corresponds to a standard supervised learning objective,
e.g. mean-squared error for regression, and hinge loss for
classiﬁcation.

The side objective is captured by Lz, which depends on
side information z and can include the auxiliary function
β. The exact form of Lz, z and β depends on the pattern
applied (Sec. 3). For all patterns, z are data that are neither
from the input space nor from the output space of f but
carry valuable information about f , and are only needed
for learning, not for prediction. Hence, the training data
include M side information samples in addition to the N
input/output pairs, D = ({xi, yi}N
j=1). Each of
the side information samples relates to one or more in-
put/output samples, commonly M = N or M = N 2.

i=1, {zj}M

To exploit z for learning f , we formulate priors about how
z relates to f in the side objective Lz. To express Lz, many
patterns require f to be split into two functions, φ and ψ,
where φ maps x to an intermediate representation s, and ψ
predicts y based on s, hence y = f (x) = ψ(φ(x)) = ψ(s).
This split exposes the representation s and facilitates the
formulation of Lz by relating s and z, possibly using β.
Often it allows us to omit ψ and y from Lz, i.e. to deﬁne
Lz(φ, β | {x}, {z}). For example, in the multi-task pat-
tern (Sec. 3.2) the intermediate representation s is shared
amongst the main task of predicting y with function ψ(s)
and an auxiliary task of predicting z with β(s). The aux-
iliary task regularizes the shared function φ and improves
generalization for the main task.

Note that we intentionally kept this formalization narrow
to improve readability. It is straightforward to extend the
ideas presented here to a reinforcement learning setting, to
multiple types of side information, to multiple intermediate
representations, and to more than one side objective.

Patterns for Learning with Side Information

2.1. Training Procedures

Since learning with side information requires us to opti-
mize multiple learning objectives affected by different sub-
sets of training data and functions, we need appropriate
training procedures. We have identiﬁed three common train-
ing procedures that differ with respect to the order in which
they (i) optimize the two objectives and (ii) modify the
functions f and β:

Simultaneous learning jointly trains f and β by optimiz-
ing a weighted sum of the two learning objectives Lf and
Lz (Weston et al., 2012). This procedure introduces the
need to ﬁnd a good weighting of the different learning ob-
jectives, which might be difﬁcult if the gradients of the
objectives differ by orders of magnitude and vary during
learning.

If we split f into φ and ψ, as described in the previous sec-
tion, we can choose among two additional procedures. In
the decoupled procedure, we ﬁrst optimize the side objec-
tive Lz(φ, β | {x}, {z}), while adapting φ and β to learn
the intermediate representation s. Then, we optimize the
main objective Lf (φ, ψ | {x, y}), while keeping φ (and
β) ﬁxed. This simple procedure is only applicable if the
side objective provides enough guidance to learn a task-
relevant representation s, whereas the simultaneous proce-
dure is also applicable for “weak” side objectives Lz. To
alleviate this problem, the pre-train and ﬁnetune proce-
dure ﬁrst applies the decoupled procedure, but then opti-
mizes Lf (φ, ψ | {x, y}) while adapting φ, too, in order to
ﬁne-tune s for the task. This strategy is popular in deep
learning as unsupervised pre-training (Erhan et al., 2010)
and can be applied analogously for learning with side in-
formation. For this procedure to have an effect, Lf must
not be convex (otherwise, the pre-training step would be
unlearned).

3. Patterns for Learning with Side

Information

We will now present different approaches for learning with
side information, which we have grouped into patterns. We
describe for each pattern the general idea, the underlying
prior, the side information z, the side objective Lz, and the
auxiliary function β. We point to successful applications
of each pattern (summarized in Appendix C) and visualize
the patterns with schemas as in Fig. 2.

How to read the schemas: The schemas represent compu-
tation ﬂow graphs where functions (drawn as arrows) con-
nect variables (represented as nodes), both of which follow
the deﬁnitions from Section 2. Predictions of variables are
indicated by ˆ·. The target function is depicted in black.
Additional elements that are only required at training time
and can be omitted during prediction are shown in gray,

except for side information and the corresponding learning
objectives, which are highlighted in green. Learning ob-
jectives are visualized by connecting variables with ∼ to
denote that the objective enforces similarity between these
variables. The =-sign (see Fig. 7) indicates that a function
is replicated (e.g. by weight sharing).

Note that these graphs are not probabilistic graphical mod-
els (PGMs). We provide PGMs as a complementary visual-
ization of causal dependencies in Appendix A. In contrast,
the computation ﬂow graphs are advantageous for the pur-
pose of this paper since (i) they discriminate between vari-
ables and functions, (ii) they expose the sequence of com-
putation, (iii) they visualize the learning objectives, and
thus (iv) are easily converted into neural networks, which
are employed by most of the related works reviewed in this
paper.

3.1. Direct Pattern

The direct pattern leverages known, intermediate results of
the computation performed by f . Given these intermediate
results as side information z, we can learn a function φ that
transforms x into the representation s such that s ∼ z, as
shown in Fig. 2. No auxiliary function β is required. The
pattern is only applicable if z makes it easier to predict y,
and if x contains enough information to predict z. The
example in Section 1 is an instance of this pattern.

To formalize this pattern,
we use a suitable supervised
learning side objective Lz =
Ldirect(φ | {x, z}) that en-
forces the representation s to
be equal to the side information z.

Figure 2. Direct pattern

Applications: Machine learning approaches in computa-
tional biology frequently use this pattern to combine un-
derstanding from biology research with learning. For ex-
ample, in contact prediction, the goal is to predict which
parts of a folded protein are close to each other based on
the DNA sequence that describes the protein. Virtually all
learning-based approaches to this problem ﬁrst predict in-
termediate representations s, such as secondary structures
(local 3D structure categories), and then use s to predict
contacts (Cheng & Baldi, 2007). The representation s can
be reliably estimated which greatly facilitates learning φ.

Knowledge transfer (Vapnik & Izmailov, 2015) uses this
pattern, but includes an additional step of extracting fea-
tures β(z) from the side information. Function φ is then
learned by regression, such that s ∼ β(z). They also sug-
gest augmenting s with the original input x. Similarly,
Chen et al. (2012) suggest to reconstruct only highly pre-
dictive features of z using a modiﬁed version of AdaBoost.

Patterns for Learning with Side Information

3.2. Multi-Task Pattern

Figure 3. Multi-task pattern

This pattern applies when the
side information z are out-
puts of a related function
(with input x) that shares
computations with the func-
tion we want to estimate. As illustrated in Fig. 3, the pattern
assumes that the target function f = ψ ◦ φ and the related
function β ◦ φ share φ and therefore have the same inter-
mediate representation s = φ(x). By training the represen-
tation to predict both y using ψ, and z using the auxiliary
learnable function β : s → z, we incorporate the prior that
related tasks share intermediate representations. This pat-
tern corresponds to multi-task learning (Caruana, 1997), a
type of transfer learning (Pan & Yang, 2010).

To apply the multi-task pattern, we can use any suitable
learning objective from supervised learning in order to learn
to predict z from x, i.e. Lz = Lmulti-task(φ, β | {x, z}).

Applications: Multi-task learning has been successfully
applied in a wide variety of tasks (Caruana, 1997; Pan &
Yang, 2010). Recently, Zhao & Itti (2015) proposed to use
object pose information to improve object recognition in a
convolutional deep neural network. Similarly, Levine et al.
(2015) use image classiﬁcation and pose prediction as side
information to teach a robot remarkable vision-based ma-
nipulation skills, such as stacking lego blocks or screwing
caps onto bottles.

3.2.1. IRRELEVANCE PATTERN

Figure 4. Exploiting irrelevant side
information.

A special case of the
multi-task patterns ex-
ploits knowledge about
unrelated tasks, by en-
forcing the prediction
of the side informa-
tion to be orthogonal to the main task (Romera-Paredes
et al., 2012). This idea is formalized by forcing ψ to be or-
thogonal to the auxiliary prediction function β (see Fig. 4),
which allows to use knowledge about irrelevant distractors
present in the input data. However, it is unclear how to ef-
ﬁciently formulate the orthogonality constraints between ψ
and β for the non-linear case.

3.3. Multi-View Pattern

The multi-view pattern is complementary to the multi-task
pattern, treating side information as input instead of out-
put. It applies when z are inputs of a related function (with
output y) that share computations with f . This pattern cor-
responds to multi-view learning (Sun, 2013).

When we treat z as auxiliary input, we can use it in two
different ways: explicitly by correlating it with the original

input x (Fig. 5), or implicitly by predicting the target output
(Fig. 6). In both cases, we learn functions φ : x (cid:55)→ s and
β : z (cid:55)→ s(cid:48), such that s ∼ s(cid:48).

The multi-view (correlation) pattern assumes that corre-
lated representations computed from related inputs are a
useful intermediate representation for predicting the tar-
get output. It can be formalized with a learning objective
that enforces the correlation between φ(x) and β(z), e.g.
the mean squared error Lz = Lmulti-view(φ, β | {x, z}) =
(cid:80)
If we apply the decoupled train-
ing procedure, i.e. only optimize the objective, we have to
add constraints, e.g. unit variance, to Lmulti-view in order to
avoid the trivial solution of having a constant intermediate
representation. In case φ and β are linear, Lmulti-view with
unit variance corresponds to Canonical Correlation Analy-
sis (CCA).

i ||φ(xi) − β(zi)||2.

(b) Labeled z data

(a) Labeled x data

Applications: The pattern
is often employed in multi-
modal scenarios (Sun, 2013).
Chen et al. (2014) show how
to enhance object recogni-
tion from RGB-only images
by leveraging depth data as
side information during train-
ing. In computational neuro-
science, the pattern is widely
used to learn from multiple
modalities (e.g., EEG and
fMRI) or across subjects (D¨ahne et al., 2014). The pat-
tern can also be applied for clustering (Feyereisl & Aicke-
lin, 2012). The idea is to repeatedly cluster on both {xi}
and {zj} and then return the clustering of x with the high-
est agreement with z.
In a recent article, Wang et al.
(2015) suggest and compare deep architectures that com-
bine multi-task and multi-view learning, and show that a
deep canonically correlated auto-encoder gives superior re-
sults for visual, speech, and language learning.

Figure 5. Multi-view (cor-
relation) pattern

The multi-view prediction
pattern is based on the prior
that predicting the target out-
put
from related inputs re-
quires similar intermediate
representations. It trains the
functions φ : x (cid:55)→ s and
β : z (cid:55)→ s(cid:48) such that both s and s(cid:48) map to the target out-
put using the same prediction function ψ, e.g. using weight
sharing. Since s and s(cid:48) are coupled to y via the main ob-
jective, we do not only regularize φ, but also ψ.

Figure 6. Multi-view
prediction pattern

Despite their similarities, we are not aware of any system-
atic comparison of multi-view and multi-task learning. Nei-
ther have we found applications of the prediction pattern
in the literature. Our experiments provide a ﬁrst empirical

Patterns for Learning with Side Information

comparison of these patterns (Sec. 4).

3.4. Pairwise Patterns

Pairwise patterns use side
information zij that carry
information about the rela-
tionship between samples i
and j to shape the inter-
mediate representation, e.g.
the difference between their intermediate representations
(Fig. 7, the = indicates weight sharing).

Figure 7. Pairwise pattern

3.4.1. PAIRWISE SIMILARITY/DISSIMILARITY

PATTERN

If the side information gives information about similarity
of samples with respect to the task, we can impose the
prior that samples that are similar (dissimilar) according to
their side information should have similar (dissimilar) in-
termediate representations. Such side information is often
available as information about local neighborhoods of sam-
ples (Tenenbaum et al., 2000). Another powerful source
of similarity information are time sequences, since tempo-
rally subsequent samples often have similar task-relevant
properties, as exploited by slow feature analysis (SFA) and
temporal coherence (Wiskott & Sejnowski, 2002; Weston
et al., 2012). Additionally, an intelligent teacher can pro-
vide information about which samples are similar (Vapnik
& Izmailov, 2015).

Similarity can be enforced with a squared loss on the dis-
tance between similar samples:

Lsim.(φ | {x, z}) =

||φ(xi) − φ(xj)||2 1(zij = sim.),

where 1 denotes the indicator function. Solely using this
objective might lead to trivial solutions where all samples
are mapped to a constant. We can resolve this problem
by imposing additional balancing constraints on s (Weston
et al., 2012) or selectively push samples apart that are dis-
similar according to the side information (or optionally ac-
cording to the labels y):
(cid:88)

σ(||φ(xi) − φ(xj)||) 1(zij = dis.),

Ldis.(φ | {x, z}) =

where σ is a function that measures the proximity of dis-
similar samples in representation s. Candidates for σ are
the margin-based σ(d) = max(0, m − d2) for some pre-
deﬁned margin m (Hadsell et al., 2006), the exponential of
the negative distance σ(d) = e−d (Jonschkowski & Brock,
2014), or the Gaussian function σ(d) = e−d2
(Jonschkowski
& Brock, 2015). Another way to avoid trivial solutions is
to impose an input-reconstruction objective, e.g. by using
an auto-encoder (Watter et al., 2015).

(cid:88)

i,j

i,j

Vapnik & Izmailov (2015) incorporate similarity informa-
tion into support vector machines by replacing the free slack
variables with a function of z. This method incorporates
the prior that slack variables should be similar for samples
with similar side information.

Applications: This pattern has been shown to successfully
guide the learner in identifying task-relevant properties of
x. Hadsell et al. (2006) show how to learn a lighting in-
variant pose representation of objects in the NORB dataset.
Weston et al. (2012) show that regularizing a convolutional
network with a temporal coherence objective outperforms
pure supervised object classiﬁcation in the COIL-100 dataset
by 20% in terms of recognition accuracy.

Recent works show how to apply this pattern to reinforce-
ment learning settings. Watter et al. (2015) exploit the
time sequence to jointly learn a state representation and
the world dynamics from raw observations for a variety of
standard tasks, such as cart-pole balancing. Jonschkowski
& Brock (2015) apply the pattern in a robot navigation task,
and show how leveraging temporal and robot action infor-
mation enable the robot to learn a state representation from
raw observations, despite the presence of visual distractors.

Note that this pattern only preserves local similarities be-
tween samples. If the side information provides a global
distance metric, Weston et al. (2012) propose to formulate
side objectives for learning a distance-preserving mapping
of x to z, e.g. based on multi-dimensional scaling (Kruskal,
1964). Alternatively, the distance metric can be learned us-
ing side information (Fouad et al., 2013).

3.4.2. PAIRWISE TRANSFORMATION PATTERN

Instead of exploiting only binary similarity information be-
tween samples, the pairwise transformation pattern exploits
continuous information about the relative transformations
between samples, to make the internal representation (or
parts of it) consistent or equivariant with the known rela-
tive transformations. Such side information is often avail-
able in robot and reinforcement learning settings.

Consistency with the transformations z can be enforced in
different ways: (a) Hinton et al. (2011) require the transfor-
mation z to affect s in a known way, and suggest the trans-
forming autoencoder model shown in Fig. 8(a) to learn such
an s. The idea is to learn to reconstruct the transformed in-
put from the original input and the known transformation.
(b) If the transformations in s are unknown, Jayaraman &
Grauman (2015) suggest to learn these transformations as
an auxiliary task using the pattern depicted in Fig. 8(b).
(c) We can also turn this approach around and try to pre-
dict the transformation based on the original and the trans-
formed representation (Agrawal et al., 2015) as depicted
in Fig. 8(c). All three variants (a)-(c) enforce equivariance

Patterns for Learning with Side Information

of s with respect to the relative transformations, and can
be trained using supervised side objectives. (d) Instead of
optimizing for equivariance, we can also enforce that the
same transformation has the same effect, when applied to
different samples (Fig. 8(d)). When transformations are
discrete, we formalize this by penalizing the squared differ-
ence of the change in internal representation after applying
the same transformation:

Ltransf.(φ | {x, z}) =

||∆φ(xi) − ∆φ(xj)||21(zi= zj),

(cid:88)

i,j

where ∆ denotes the change caused by the transformation,
i.e. ∆φ(xi) = φ(xi+1) − φ(xi) for sequential data. This
objective can be extended to continuous transformations by
replacing the indicator function with a similarity function
σ(zi− zj) from Section 3.4.1. Variants of this pattern al-
low to enforce only locally consistent transformations, by
multiplying σ(φ(xi) − φ(xj)), or to enforce only consis-
tent magnitudes of change by comparing norms ||∆φ(xi)||
(Jonschkowski & Brock, 2015).

(b) Predicting representation

(c) Predicting transformation

(a) Predicting transformed input

Applications: Many
results in the literature
demonstrate the useful-
ness of
the pairwise
transformation pattern.
Agrawal et al. (2015) re-
port
that using rela-
tive pose information as
side information can re-
duce the error rate on
MNIST by half with
respect to pure super-
vised learning. They
also demonstrate the
approach for scene recog-
nition on the SUN dataset,
and show that pre-training
using limited of relative
pose side information is
almost as good class-
based supervision. Ja-
yaraman & Grauman
(2015) demonstrate a
recognition accuracy of
≈ 50% on the KITTI
dataset, outperforming pure supervised learning (41.81%
accuracy) and SFA (47.04%). Interestingly, both works en-
force learning a pose equivariant representation, although
the classiﬁcation task they address requires invariance. It
is still unclear why equivariant representations help in such
tasks (Lenc & Vedaldi, 2014).

(d) Comparing pairs of transfor-
mations

Figure 8. Pairwise transf. patterns

3.4.3. LABEL DISTANCE PATTERN

not

(see

samples

The label distance pattern is a special case of the pairwise
pattern, where the side information deﬁnes distances be-
tween
9).
labels,
An instance of this pat-
tern, often used in struc-
tured prediction, is hier-
archical multi-class learn-
ing (Silla Jr & Freitas, 2010), where a hierarchy is imposed
on the labels to penalize misclassiﬁcations between sam-
ples with similar classes less severely.

Figure 9. Label distances

Fig.

4. Experiments

The related work, discussed in the previous section, demon-
strated that learning with side information greatly improves
generalization. In our experiments, we provide, for the ﬁrst
time, a systematic comparison of the different patterns in
two supervised learning tasks. We outline the experimen-
tal rationale and results here, and refer to Appendix B for
details.

4.1. Synthetic Task

In the ﬁrst, synthetic, experiment the goal is to predict the
position of a randomly moving agent in a 1-dimensional
state space s. The learner cannot perceive s directly, but
gets an observation x, which embeds s and a set of dis-
tractor signals in a high-dimensional space. The learned
functions are linear (φ and β), and logistic functions (ψ),
respectively. We study the effect of different combinations
of (i) side information, (ii) patterns, and (iii) training proce-
dures on prediction accuracy. The side information are ei-
ther a noisy variant of the real state (direct side information,
Fig. 10(a)), a second noisy high-dimensional observation
(embedded, Fig. 10(b)), or a noisy variant of the agent’s ac-
tions, i.e. the agent’s relative motion (pairwise, Fig. 10(c)).
We apply the direct, multi-view, multi-task, and pairwise
transformation patterns, and perform training using the de-
coupled and simultaneous procedure (pre-training is futile
with linear functions). We compare to supervised and semi-
supervised baselines.

Results: While none of the baselines are able to solve the
task with the given amount of training data, for each form
of side information, at least one pattern achieves close to
optimal performance. For the simple direct side informa-
tion (Fig. 10(a)) all patterns except the multi-view predic-
tion pattern are applicable; the reason is that the direct data
correspond to the real state, and thus make solving the task
almost trivial. This does not hold true for the embedded
side information (Fig. 10(b)). Here, the simultaneously
trained multi-view correlation pattern clearly outperforms
all other methods. The reason is that the embedded side in-

Patterns for Learning with Side Information

formation exactly matches the prior of the multi-view pat-
tern. The pairwise transformation pattern, when applied
to pairwise side information (Fig. 10(c)), is as effective as
learning from direct side information. Overall, the experi-
ments conﬁrm our hypothesis that the effectiveness of each
pattern strongly depends on the type of side information.

4.2. Handwritten Character Recognition

In this experiment, we test learning with side information
for handwritten character recognition in images (see Fig. 11),
where we use the pen trajectory as side information. As
in the previous experiment, we vary (i) the representation
of the side information, either as continuous vectors or dis-
crete categories; (ii) the pattern: direct, multi-task, or multi-
view; and (iii) the training procedure: decoupled, pre-train
and ﬁnetune, or simultaneous. In all our experiments, we
keep the number of unlabeled data and side information
ﬁxed and examine how the accuracy of the main task is
affected by changing the number of labeled data. All ap-
proaches use the same convolutional neural network archi-
tecture. As baselines we use purely supervised learning and
unsupervised pre-training (deep auto-encoder).

Figure 11. Sample input
the 20 single-stroke-
for each of
characters in this task: a, b, c, d, e, g, h, l, m, n, o, p, q, r, s,
u, v, w, y, z. Variations like the added random lines make this task
challenging.

Results: First, we see that learning with side informa-
tion can dramatically improve generalization, achieving the
same performance using 5 labels per class as the baselines
achieve with 100 (see Fig. 12(b)). Second, for this task,
only the multi-task pattern exhibits this signiﬁcant increase
in performance. However, we also note that the effective-
ness of learning with side information does not only depend
on the pattern, but also on the representation of the side in-
formation (compare Figs. 12(a) and 12(b)): When we use
the vector of pen coordinates as side information, the direct
pattern provides some improvement over the baselines, but
the multi-task and multi-view patterns do not improve the
performance by large amounts (see Fig. 12(a)). However,
when discretizing the trajectories into a small number of
categories and applying the multi-task pattern for predict-
ing these categories, we drastically reduce the number of
labels required to solve this task (see Fig. 12(b)). This is
not the case if we use other patterns. Moreover, we see that
multi-task learning applied to the discretized side informa-
tion is not signiﬁcantly inﬂuenced by the training proce-
dure (compare to direct pattern). This shows how—in this
task—the multi-task pattern is able to ﬁnd a good inter-
mediate representation independently of the main objective
(Fig. 12(c)). These results conﬁrm our hypothesis that the
available side information must match the prior imposed by
the applied pattern in order to improve generalization.

(a) Direct side information

(b) Embedded side information

(c) Pairwise side information

Figure 10. Results for the synthetic task, averaged over 10 runs.
The most suitable patterns outperform supervised and semi-
supervised baselines and generalize better with much less data.

Patterns for Learning with Side Information

tasks, we hypothesize that the performance of these pat-
terns will vary strongly depending on the applicability of
the corresponding prior. Our experiments conﬁrm this hy-
pothesis and also show that learning with side information
can substantially improve generalization.

Our perspective of learning with side information can be
helpful in a number of ways. First of all, the patterns that
we have presented allow researchers and practitioners to
exploit side information in novel tasks in a systematic fash-
ion. Applying the patterns in novel tasks is facilitated by
our publicly available implementation and a broad overview
of existing methods and applications in this paper. Our lit-
erature review provides a formalization that uniﬁes differ-
ent lines of research, which currently seem to be unaware
of the strong similarities among them. This common view
will allow researchers to exchange ideas more easily, to ﬁnd
novel patterns for using side information, and to effectively
combine patterns to exploit multiple sources of side infor-
mation.

Moreover, we expect learning with side information to be
very effective beyond supervised learning settings. In par-
ticular, reinforcement learning can beneﬁt signiﬁcantly be-
cause of the strong relationship between the different data
sources (observations, actions, and rewards over time). By
formulating priors over their relationships, we can exploit
this rich side information in order to learn better state, ac-
tion, and policy representations. This stands in contrast
to most datasets available in machine learning, which are
shaped according to the supervised learning paradigm and
thus only consist of input/output samples. We, therefore,
suggest to construct and augment datasets with relevant
side information.

Although the utility of the view that we have presented can
ultimately only be estimated in hindsight, we strongly be-
lieve that unifying ideas and providing new perspectives is
vital to scientiﬁc progress, as exempliﬁed by Bengio et al.
(2013). We hope that the presented perspective of learn-
ing with side information triggers further research in that
direction that generates new insights in our ﬁeld.

ACKNOWLEDGMENTS

We gratefully acknowledge the funding provided by the
European Commission (SOMA project, H2020-ICT-645599),
the German Research Foundation (Exploration Challenge,
BR 2248/3-1), and the Alexander von Humboldt founda-
tion (funded by the German Federal Ministry of Education
and Research). We would like to thank Marc Toussaint and
the University of Stuttgart for granting us access to their
GPU cluster, and Sven D¨ahne, George Konidaris, Johannes
Kulick, Tobias Lang, Robert Lieck, Ingmar Posner, and
Michael Schneider for fruitful discussions and comments
on this manuscript.

(a) Continuous side information

(b) Discretized side information

(c) Training procedures

Figure 12. Results for handwritten character recognition task. (a)
uses continuous side information. (b) and (c) use the discretized
side information. Line styles denote the training procedure (solid
= pretrain/ﬁnetune, dashed = decoupled training, dotted lines =
simultaneous training).

5. Conclusion and Discussion

In this paper, we show how learning with side information
provides a new perspective on machine learning, and com-
plements existing paradigms such as supervised learning,
representation learning, and deep learning. This new per-
spective allows us to connect various methods in the liter-
ature that (implicitly) use side information. It also enables
us to systematically analyze these methods and extract pat-
terns from them that show how they incorporate different
priors about how side information relates to the target func-
tion. Since different priors coincide with different learning

Patterns for Learning with Side Information

References

Agrawal, Pulkit, Carreira, Joao, and Malik, Jitendra.
Learning to See by Moving. arXiv:1505.01596 [cs],
May 2015.

Ando, Rie Kubota and Zhang, Tong. A Framework for
Learning Predictive Structures from Multiple Tasks and
Unlabeled Data. Journal of Machine Learning Research,
6:1817–1853, November 2005.

Bastien, Fr´ed´eric, Lamblin, Pascal, Pascanu, Razvan,
Bergstra, James, Goodfellow, Ian, Bergeron, Arnaud,
Bouchard, Nicolas, Warde-Farley, David, and Bengio,
Yoshua. Theano: new features and speed improvements.
In NIPS 2012 deep learning workshop, 2012.

Baxter, Jonathan. A model of inductive bias learning. J.

Artif. Intell. Res.(JAIR), 12:149–198, 2000.

Bengio, Yoshua, Courville, Aaron, and Vincent, Pascal.
Representation Learning: A Review and New Perspec-
tives. Pattern Analysis and Machine Intelligence, IEEE
Transactions on, 35(8):1798–1828, 2013.

Blum, Avrim and Mitchell, Tom. Combining labeled and
unlabeled data with co-training. In Proceedings of the
eleventh annual conference on Computational learning
theory, pp. 92–100. ACM, 1998.

Caruana, R. Multitask learning. Machine learning, 28(1):

41–75, 1997.

Chen, Jixu, Liu, Xiaoming, and Lyu, Siwei. Boosting
with Side Information. In Lee, Kyoung Mu, Matsushita,
Yasuyuki, Rehg, James M., and Hu, Zhanyi (eds.),
Computer Vision - ACCV 2012, number 7724 in Lec-
ture Notes in Computer Science, pp. 563–577. Springer
Berlin Heidelberg, November 2012.

Chen, Lin, Li, Wen, and Xu, Dong. Recognizing RGB
Images by Learning from RGB-D Data. In 2014 IEEE
Conference on Computer Vision and Pattern Recognition
(CVPR), pp. 1418–1425, June 2014.

Evgeniou, Theodoros and Pontil, Massimiliano. Regular-
In Proceedings of the Tenth
ized Multi-task Learning.
ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, KDD ’04, pp. 109–117,
New York, NY, USA, 2004. ACM.

Farquhar,

Jason, Hardoon, David, Meng, Hongying,
Shawe-taylor, John S., and Szedmak, Sandor. Two view
In Advances
learning: SVM-2k, theory and practice.
in neural information processing systems, pp. 355–362,
2005.

Feyereisl, Jan and Aickelin, Uwe. Privileged information
for data clustering. Information Sciences, 194:4–23, July
2012.

Fouad, S., Tino, P., Raychaudhury, S., and Schneider,
P. Incorporating Privileged Information Through Metric
Learning. IEEE Transactions on Neural Networks and
Learning Systems, 24(7):1086–1098, July 2013.

Hadsell, Raia, Chopra, Sumit, and LeCun, Yann. Dimen-
sionality Reduction by Learning an Invariant Mapping.
In Proc. Computer Vision and Pattern Recognition Con-
ference (CVPR’06). IEEE Press, 2006.

Hinton, Geoffrey E., Krizhevsky, Alex, and Wang, Sida D.
In Artiﬁcial Neural Net-
Transforming auto-encoders.
works and Machine Learning-ICANN 2011, pp. 44–51.
Springer, 2011.

Jayaraman, Dinesh and Grauman, Kristen.

Learn-
ing image representations equivariant to ego-motion.
arXiv:1505.02206 [cs, stat], May 2015.

Jonschkowski, Rico and Brock, Oliver. State Representa-
tion Learning in Robotics: Using Prior Knowledge about
In Robotics Science and Systems
Physical Interaction.
(RSS) X, Berkeley, USA, 2014.

Jonschkowski, Rico and Brock, Oliver. Learning state rep-
resentations with robotic priors. Autonomous Robots, 39
(3):407–428, July 2015.

Cheng, Jianlin and Baldi, Pierre. Improved residue contact
prediction using support vector machines and a large fea-
ture set. BMC Bioinformatics, 8(1):113, April 2007.

Kingma, Diederik P. and Welling, Max. Auto-Encoding
In International Conference on
Variational Bayes.
Learning Representations (ICLR), Banff, Canada, 2014.

D¨ahne, Sven, Nikulin, Vadim V., Ram´ırez, David, Schreier,
Peter J., M¨uller, Klaus-Robert, and Haufe, Stefan. Find-
ing brain oscillations with power dependencies in neu-
roimaging data. NeuroImage, 96:334–348, August 2014.

Erhan, Dumitru, Bengio, Yoshua, Courville, Aaron, Man-
zagol, Pierre-Antoine, Vincent, Pascal, and Bengio,
Samy. Why Does Unsupervised Pre-training Help Deep
J. Mach. Learn. Res., 11:625–660, March
Learning?
2010.

Kruskal, J. B. Multidimensional scaling by optimizing
goodness of ﬁt to a nonmetric hypothesis. Psychome-
trika, 29(1):1–27, March 1964.

Legenstein, Robert, Wilbert, Niko, and Wiskott, Lau-
renz. Reinforcement Learning on Slow Features of High-
Dimensional Input Streams. PLoS Comput Biol, 6(8):
e1000894, 2010.

Patterns for Learning with Side Information

Lenc, Karel and Vedaldi, Andrea. Understanding im-
age representations by measuring their equivariance and
equivalence. arXiv:1411.5908 [cs], November 2014.

Wang, Wei and Zhou, Zhi-Hua. A new analysis of co-
training. In Proceedings of the 27th International Con-
ference on Machine Learning (ICML-10), 2010.

Levine, Sergey, Finn, Chelsea, Darrell, Trevor, and Abbeel,
Pieter. End-to-End Training of Deep Visuomotor Poli-
cies. arXiv:1504.00702 [cs], April 2015.

Wang, Weiran, Arora, Raman, Livescu, Karen, and Bilmes,
Jeff. On Deep Multi-View Representation Learning.
2015.

Watter, Manuel, Springenberg, Jost, Boedecker, Joschka,
and Riedmiller, Martin. Embed to control: A locally lin-
ear latent dynamics model for control from raw images.
In Advances in Neural Information Processing Systems,
pp. 2728–2736, 2015.

Weston, Jason, Ratle, Fr´ed´eric, Mobahi, Hossein, and Col-
lobert, Ronan. Deep Learning via Semi-supervised Em-
bedding. In Montavon, Gr´egoire, Orr, Genevive B., and
M¨uller, Klaus-Robert (eds.), Neural Networks: Tricks of
the Trade, number 7700 in Lecture Notes in Computer
Science, pp. 639–655. Springer Berlin Heidelberg, 2012.

Williams, Ben H., Toussaint, Marc, and Storkey, Amos J.
A Primitive Based Generative Model to Infer Timing In-
formation in Unpartitioned Handwriting Data. In IJCAI,
pp. 1119–1124, 2007.

Wiskott, Laurenz and Sejnowski, Terrence J. Slow Feature
Analysis: Unsupervised Learning of Invariances. Neural
Computation, 14(4):715–770, April 2002.

Wolpert, David H. The Lack of A Priori Distinctions Be-
tween Learning Algorithms. Neural Computation, 8(7):
1341–1390, October 1996.

Zhao, Jiaping and Itti, Laurent. Improved Deep Learning

of Object Category using Pose Information. 2015.

Maurer, Andreas. Bounds for Linear Multi-Task Learning.

J. Mach. Learn. Res., 7:117–139, December 2006.

Mitchell, Tom M. The need for biases in learning general-
izations. Department of Computer Science, Laboratory
for Computer Science Research, Rutgers Univ., 1980.

Ngiam, Jiquan, Khosla, Aditya, Kim, Mingyu, Nam,
Juhan, Lee, Honglak, and Ng, Andrew Y. Multimodal
deep learning. In Proceedings of the 28th international
conference on machine learning (ICML-11), pp. 689–
696, 2011.

Pan, Sinno Jialin and Yang, Qiang. A Survey on Transfer
Learning. IEEE Transactions on Knowledge and Data
Engineering, 22(10):1345–1359, October 2010.

Romera-Paredes,

Argyriou,

Andreas,
Bernardino,
Ex-
Berthouze, Nadia, and Pontil, Massimiliano.
ploiting unrelated tasks in multi-task learning.
In
International Conference on Artiﬁcial Intelligence and
Statistics, pp. 951–959, 2012.

Schaffer, C. A conservation law for generalization perfor-
mance. In Proceedings of the Eighth International Ma-
chine Learning Conference, pp. 259–265. Morgan Kauf-
mann, 1994.

Silla Jr, Carlos N. and Freitas, Alex A. A survey of hi-
erarchical classiﬁcation across different application do-
mains. Data Mining and Knowledge Discovery, 22(1-2):
31–72, April 2010.

Sun, Shiliang. A survey of multi-view machine learn-
ing. Neural Computing and Applications, 23(7-8):2031–
2038, February 2013.

Tenenbaum, Joshua B., Silva, Vin de, and Langford,
John C. A Global Geometric Framework for Nonlinear
Dimensionality Reduction. Science, 290(5500):2319–
2323, December 2000.

Vapnik, Vladimir and Izmailov, Rauf. Learning Using Priv-
ileged Information: Similarity Control and Knowledge
Transfer. Journal of Machine Learning Research, 16:
2023–2049, 2015.

Vapnik, Vladimir and Vashist, Akshay. A new learning
paradigm: Learning using privileged information. Neu-
ral Networks, 22(5-6):544–557, July 2009.

Patterns for Learning with Side Information

A. Patterns as Probabilistic Graphical Models

To complement the computation ﬂow schemas of the pat-
terns used throughout the paper, we provide an interpreta-
tion of the main patterns as probabilistic graphical models
(PGMs). These models treat the variables and functions
introduced in Sec. 2 as random variables, represented as
nodes. Arrows between these random variables indicate
causal relationships. Gray nodes indicate observable, and
white nodes latent random variables. The latent functions
can be learned by performing inference in these models.

turally similar and only differ on whether z depends on s
and β or whether s depends on z and β.
In this regard,
they are equivalent to their corresponding computation ﬂow
schemas apart from the fact that the PGM for the multi-
view pattern conceals how the variables x and z belong to
the functions φ and β.

Finally, the prototypical pairwise pattern is shown in Fig. 13(a)
(computation ﬂow graph: Fig. 7). Notice that here sj is
conditioned on zi,j and si, reﬂecting the fact that zi,j is
information about how sj relates to si.

ψ

y

D

yi

yj

β

x

xi

xj

φ

s

z

si

sj

zij

Several interesting research questions arise from the prob-
abilistic view on learning with side information. The ma-
jority of the reviewed literature uses non-probabilistic loss
functions, mostly for training neural networks. Translat-
ing them into probabilistic ones is an interesting, but non-
trivial research question, as the recent work on variational
auto-encoders (which are a probabilistic version of auto-
encoders) shows (Kingma & Welling, 2014). A similar
question arises on the relationship of the side objectives and
prior probability distributions on φ, ψ, β and s. It would
be interesting to investigate whether certain side objectives
can be shown to be equivalent to priors in the Bayesian
sense, similar to the well-known fact that L2 regularization
is equivalent to a Gaussian prior.

B. Experimental Methods

The implementation of our experiments is based on Theano (Bastien
et al., 2012) and Lasagne4. We have made our code pub-
licly available at: [url removed for double-blind review]

(a) Direct pattern

(b) Multi-task pattern

φ

ψ

x

β

x

φ

s

φ

s

z

ψ

y

D

ψ

y

D

B.1. Synthetic Task

Pairs (i, j) ∈ D

(c) Multi-view pattern

(d) Pairwise pattern

Figure 13. Probabilistic graphical models for patterns

The PGMs for the four main patterns are shown in Fig. 13.
The variables x, s, z and y are observable random variables
and are part of the training data D. The functions φ, ψ and
β have become latent random variables, which the observed
variables are conditioned on. We now discuss aspects of
individual patterns.

The direct pattern is shown in Fig. 13(a). In comparison
to its computation ﬂow graph (Fig. 2), the side information
z is considered as drawn from the distribution over s, and
therefore z does not appear in the graphical model of the
direct pattern.

Fig. 13(b) and Fig. 13(c) show the PGM for the multi-
task and multi-view pattern, respectively (computation ﬂow
graphs: Fig. 3 and Fig. 5). We see that they are struc-

Task: The task consists of an agent moving randomly
through a 1-dimensional state space st ∈ R where t de-
notes the time index. The space is split into two regions
O1 = {s | s > 0} and O2 = {s | s < 0} and the
goal of the learner is to determine in which of the two re-
gions the agent is located. However, the learner cannot ob-
serve the state space directly, it only gets d-dimensional ob-
servations which are obfuscated by d − 1 distractors u(i)
,
t
i ∈ {1, . . . , d − 1}: the observation is generated by ap-
plying a random rotation R to the concatenated state and
distractor vector: xt = R [st, u(1)
]. In every
time step, both the state as well as the distractor dimensions
t + ε(i)
change randomly: st+1 = st + ε(s)
,
t
where ε(s)
t ∼ N (0, 1). In addition the agent receives a
supervised signal y which is 0 if the agent is in region O1
and 1 in zero O2.

, . . . , u(d−1)
t

t+1 = u(i)

, u(i)

, ε(i)

t

t

t

Baselines: We compare different variants of learning with

4https://github.com/Lasagne/Lasagne

Patterns for Learning with Side Information

side information to a supervised method (logistic regres-
sion mapping x directly to y) and to two semi-supervised
methods. For the semi-supervised baselines we apply ei-
ther PCA or SFA to learn a 1-dimensional s, and then train a
logistic regression mapping from s to y. For the logistic re-
gression, we use L2 regularization with C ∈ {0.001, 0.01,
0.1, 1.0, ∞} and choose the result with the lowest test error.
(We do not apply L2 regularization for variants of learning
with side information.)

pervised methods fail to extract a good state representation
since the real hidden s neither exhibits high variance, nor
a slower trajectory than the distractors. Pure supervised lo-
gistic regression works better, but even when doubling the
number of (x, y) pairs, it does not reach the performance
of the methods that use side information. We believe that
the multi-view-prediction pattern works badly because it
does not propagate enough information from the learned ψ
to regularize φ.

1+e

1
−wT
ψ

Patterns: We implemented the four principal patterns from
Section 3, using a linear function for φ(x) = wT
φ x = s and
a logistic function for ψ(s) =
s . We apply Stochas-
tic Gradient Descent with Nesterov momentum with value
0.9 to learn φ and ψ using a logistic regression loss in ad-
dition to the side objective. We train each pattern using
the decoupled and simultaneous training procedures (pre-
train/ﬁne-tune is futile due since φ and ψ are linear, and
both the target and the side objectives are convex; see Sec-
tion 2.1).
For the direct pattern, we learn φ directly by performing
a linear regression on z, using the mean squared error loss.
When training simultaneously, we weigh the main and the
side objective equally.
We implement the multi-task pattern by using a linear
function β(s) = wT
β s for the auxiliary task and optimize it
using linear regression. Again, we weigh the main and the
side objective equally.
We implement two versions of the multi-view pattern:
ﬁrst, the correlation variant, using β(z) = wT
β z = s(cid:48), op-
timizing for s ≈ s(cid:48), secondly, the prediction variant. For
the correlation pattern we have to give weight 0.99 to the
supervised and 0.01 to the side objective, since the gradi-
ents from the side objective (MSE loss) and the supervised
softmax loss differ by several orders of magnitude.
Finally, we implement the pairwise pattern, in form of the
transformation pattern. We use a simpliﬁed version of the
variant depicted in Fig. 8(c) with a ﬁxed auxiliary function
β(si, sj) = si − sj. Again, we weigh the main and the side
objective equally.

We evaluate subsets of the implemented patterns with three
types of side information. In each experiment, we use dif-
ferent amounts of (x, y, z) triplets for learning, and test the
prediction accuracy in the main task for a test set of size
50000. The dimensionality of x is set to 50. We average
the results over 10 independently generated training and
test sets.

Direct Side Information: First, we provide the learner
with very informative data in the form of a noisy variant
of the real state: z(s)
t ∼ N (0, 0.05).
Figure 10(a) shows that all variants of learning with side in-
formation except for the multi-view-prediction pattern gen-
eralize well, even given low amounts of data. The unsu-

t = st + ε(s)

, with ε(s)

t

t

t ∼ N (0, 0.05).

Embedded Side Information: In the second experiment,
we provide side information corresponding to an additional,
noisy sensor view by mapping the state into a different e-
, v(1)
dimensional observation space, z(v)
t = Q [st + ε(v)
,
t
. . . , v(e−1)
] with distractors v(i)
, random rotation matrix
t
t
Q and ε(v)
In the experiments, we set
e = d
2 . Figure 10(b) shows that most variants of learn-
ing with side information still outperform the supervised
method, but need more data to generalize well due to the
less informative side information. The multi-view method
performs best, whereas the multi-task performs even worse
than logistic regression. Moreover, we see that the simulta-
neous training procedures outperform the decoupled vari-
ants, most drastically in the multi-view pattern.

Relative Side Information: The last type of data corre-
sponds to a noisy variant of the “actions”, z(a)
t = st −
st−1 + ε(a)
t ∼ N (0, 0.05). Fig. 10(c) shows
clearly that this side information is highly useful, and al-
lows to learn from few samples.

t with ε(a)

B.2. Handwritten Character Recognition

Dataset and task: The dataset for this experiment is based
on the character trajectories dataset5, which consists of time
series of pen velocities in x and y direction and pen tip
force (more details in Williams et al. (2007)). The dataset
includes 20 characters that can be written in a single stroke.
Based on this dataset, we generate monochrome images of
size 32 × 32 pixels. During image generation, we add dif-
ferent variations to make this task more challenging. We
trace the character trajectories with varying pen width, we
translate the characters randomly, and we overlay distract-
ing lines that connect three random points in the image (see
Fig. 11). These images form the input x for this task. Addi-
tionally, we generate side information in the form of coor-
dinates of 32 points along the character trajectory making
up a 64D vector z. Unlike the input images, these points
are not translated. The task is to recognize which of the 20
characters is in the given image. The training data consist
of 100 input/side information pairs per character, a random
subset of which are labeled. In our experiment, we vary the

5https://archive.ics.uci.edu/ml/datasets/

Character+Trajectories

number of labels per character from 1 to 100.

C. Overview of Related Work

Patterns for Learning with Side Information

In the following table, we summarize related works that
apply learning with side information. Since an exhaustive
list of references for each pattern is beyond the scope of
this paper, we include works that span a wide variety of
instantiations of the proposed patterns and refer to survey
articles if available.

Abbreviations: AE=auto-encoder, CCA=canonical correlation anal-
ysis, ED=eigen decomposition, GMLVQ=generalized matrix learn-
ing vector quantization, kNN=k-nearest-neighbors, LBP=locally
binary pattern, MMD=maximum mean discrepancy, NN=neural
network, RBM=restricted Boltzmann machine, RL=reinforcement
learning, SGD=stochastic gradient descent, SL=supervised learn-
ing (classiﬁcation unless stated otherwise), SVM=support vector
machine, UL=unsupervised learning

Neural network structure and training: We use a con-
volutional neural network (CNN) with rectiﬁed linear units
(ReLU). We ﬁrst apply a convolution with 32 ﬁlters of size
5 × 5 followed by ReLU non-linearity and max-pooling.
The same sequence is repeated, followed by 50% dropout
and a fully connected layer of 32 ReLUs (the intermedi-
ate representation s). This is again followed by a 50%
dropout and 20 softmax output units. The entire network
has 52756 parameters. The supervised task is formulated
using the categorical crossentropy loss and optimized us-
ing Nesterov momentum with learning rate 0.003, momen-
tum 0.9, and batch size 20 for 100 epochs, followed by 10
epochs with learning rate 0.0003. All experiments are re-
peated 10 times.

In the experiment, we test two different
Discretization:
representations of the side information. The original con-
tinuous vector representation and a discretization into 32
classes, which we obtain with k-means clustering. The
rationale behind the discretization is that the exact trajec-
tory cannot be recovered from the image (because it is not
clear from the image where the character trajectory starts).
We tested the same discretization on the image in the semi-
supervised baseline.

Applied patterns: We compare the direct pattern, the
multi-task pattern, and the multi-view pattern. The direct
pattern uses a mean-squared-error objective to enforce the
intermediate representation to be equal to a 32D version
of the pen trajectory or the one-hot-vector that corresponds
to the discretized trajectory. The multi-task pattern incor-
porates an additional network layer to predict the side in-
formation, either a linear layer with mean-squared-error
loss to predict the trajectory or a softmax layer with cross-
entropy loss to predict its discretization. The multi-view
pattern uses two ReLU-layers with 32 units and dropout to
compute the intermediate representation s(cid:48) which we tie to
s with a mean-squared-error objective. Since this objective
creates trivial solutions if trained independently, we opti-
mize it simultaneously with the main objective (weighing
them with 0.05 and 0.95, respectively). All other patterns
are trained using the pretrain/ﬁnetune procedure unless in-
dicated otherwise. For simultaneous training of the multi-
task pattern, we used uniform weighting.

Baselines: We compare against supervised learning on the
labeled data and semi-supervised baselines: In the contin-
uous case, we reconstruct the image using a convolutional
autoencoder that mirrors the structure of the convolutional
network. In the discrete case we use a similar structure as
for multi-task learning but predict the discretized image in-
stead of the discretized trajectory.

Patterns for Learning with Side Information

Pattern

Side Objective

Articles

Direct
(Fig. 2)

SVM loss

Regression on highly
predictive features of side
information

Cheng & Baldi
(2007)

Chen et al.
(2012)

Method,
Train. Procedure

Application:
Task, Input, Dataset

SVM (decoupl.)

SL: Contact prediction on sequences

AdaBoost+ (simul.)

SL on images: Digit (Vapnik &
Vashist, 2009), facial expression
(Cohn-Kanade)

SL on images
Theoretical analysis: learning using
privileged information

Regression loss

Vapnik &
Izmailov (2015)

SVM with knowledge
transfer (decoupl.)

Multi-task
(Fig. 3)

Various supervised: hinge,
MSE, softmax

Caruana (1997)

NN (simul.)

SL: pneumonia detection

Multi-view
(Fig. 5)

Kernel CCA+soft margin
SVM hinge loss

SVM (simul.)

Evgeniou &
Pontil (2004)
Levine et al.
(2015)
Zhao & Itti
(2015)
Pan & Yang
(2010)
Baxter (2000); Ando & Zhang (2005)
Maurer (2006)

Survey

Conv. NN (simul.)

SL: exam score prediction

One task per school

Conv. NN (decoupl.)

RL on RGB-D: robot manipulation

SL on images (YYY-20M)

Object pose

SL, UL

Theoretical analysis of
multi-task learning

-

-

Farquhar et al.
(2005)
Ngiam et al.
(2011)
Feyereisl &
Aickelin (2012)

Chen et al.
(2014)

D¨ahne et al.
(2014)

Wang et al.
(2015)

Wiskott &
Sejnowski
(2002);
Legenstein et al.
(2010)

Hadsell et al.
(2006)

Weston et al.
(2012)
Watter et al.
(2015)

Sun (2013)
Blum & Mitchell (1998)
Wang & Zhou (2010)

AE reconstruction error

Adjusted rand index,
mutual information

Kernel CCA [+MMD for
domain adaption]

SPoC (non-linear CCA)

CCA+AE reconstruction
error

-
-

Slowness (ﬁrst equation in
Sec. 3.4.1 with
zij = 1{j = i + 1} and
covariance constraints).

Equations in Sec. 3.4.1
with margin-based σ(d)
(see Section 3.4.1)

State predictability
+variational AE

Adapted SVM loss

k-means

UL on images: MNIST

Poetic descriptions

SVM-2K (simul.)

SL on images (PASCAL-VOC)

RBM / NN (simul.)

SL on video/audio (various, e.g.
CUAVE, AVLetters)

Kernel SVM on kernel
descriptor features

Linear/quadratic, ED
(decoupl.)
Deep Canonically
Correlated AE and
others (simul.)
Survey

SL on RGB: gender (EURECOM,
LFW-a), object (RGB-D O.D.,
Catech-256)

SL: Mental state prediction

SL on images (MNIST), speech
(XRMB), word embedding
(WMT2011)
SL, UL
Theoretical analysis of
multi-view learning

Linear/quadratic, ED
(decoupl.)

RL on images: Navigation (physical
simulation)

Time index

Conv. NN, (decoupl.)

UL on images: dimensionality
reduction (MNIST, NORB)

Conv. NN (simul.)

SL on images (MNIST, COIL100)

CNN (simul.)

RL: inverted pendulum, cart-pole,
robot arm

Vapnik &
Vashist (2009)

SVM with similarity
control (simul.)

SL: protein classiﬁcation, ﬁnance
market prediction, digit recognition

Distance metric learning

Hierarchical multi-class
loss

Fouad et al.
(2013)
Silla Jr & Freitas
(2010)

GMLVQ/kNN
(decoupl.)

SL: images (MNIST); galaxy
morphology

Survery on hierarchical classiﬁcation (SL)

Softmax (?)

Hinton et al.
(2011)

NN; transforming AE
(simul.)

SL for pose prediction (MNIST, 3D
simulation)

Relative pose

Pairwise
Similarity
(Fig. 7)

(Fig. 9)

Pairwise
Transforma-
tion
(Fig. 8(a))

(Fig. 8(b))

See (Hadsell et al., 2006)

SL on images (NORB, KITTI, SUN)

(Fig. 8(c))

Softmax

Various

Irrelevance
(Fig. 4)

L ≈ ||ψT β||2
linear, || · ||2
norm.

F , with ψ, β

F Frobenius

Jayaraman &
Grauman (2015)

Siamese-style conv.
NN (simul.)

Agrawal et al.
(2015)

Jonschkowski &
Brock (2015)

Siamese-style conv.
NN
(pre-train/ﬁne-tune)
Linear, SGD
(decoupl.)

SL on images (MNIST, SF, KITTI)

RL: control, navigation,

Romera-Paredes
et al. (2012)

Linear, orthogonal
matrix factorization

SL on images: emotion detection
(JAFFE)

Side Information

Secondary (3D)
structure categories
Holistic image
descriptions, LBP
features from
high-res images

Image sections

Hematocrit, white
blood cell count,
potassium

Image class, object
pose

Keypoint features
(SIFT)

Video/audio

RGB-D

EEG diff. subject

Noisy images,
articulations, 2nd
language
-
-

3D protein structure,
future events, textual
description
Poetic descriptions;
spectral features

Label similarity

Relative pose
(discretized; with
k-means)
Relative pose
(discretized;
uniformly)
Actions, rewards,
time

Subject identity

Patterns for Learning with Side Information

Rico Jonschkowski1, Sebastian H¨ofer1, Oliver Brock
{RICO.JONSCHKOWSKI, SEBASTIAN.HOEFER, OLIVER.BROCK}@TU-BERLIN.DE
Robotics and Biology Laboratory, Technische Universit¨at Berlin, Berlin, Germany

6
1
0
2
 
b
e
F
 
0
1
 
 
]

G
L
.
s
c
[
 
 
5
v
9
2
4
6
0
.
1
1
5
1
:
v
i
X
r
a

Abstract
Supervised, semi-supervised, and unsupervised
learning estimate a function given input/output
samples. Generalization of the learned function
to unseen data can be improved by incorporating
side information into learning. Side information
are data that are neither from the input space nor
from the output space of the function, but include
useful information for learning it. In this paper
we show that learning with side information sub-
sumes a variety of related approaches, e.g. multi-
task learning, multi-view learning and learning
using privileged information. Our main contri-
butions are (i) a new perspective that connects
these previously isolated approaches, (ii) insights
about how these methods incorporate different
types of prior knowledge, and hence implement
different patterns, (iii) facilitating the application
of these methods in novel tasks, as well as (iv) a
systematic experimental evaluation of these pat-
terns in two supervised learning tasks.

1. Introduction

An important branch of machine learning research focuses
on supervised learning, estimating functions based on in-
put/output samples with the goal of predicting the correct
output for new inputs. However, generalization to unseen
samples always requires prior knowledge (which we re-
fer to as priors) about the target function (Mitchell, 1980;
Schaffer, 1994; Wolpert, 1996). By incorporating stronger
priors, we can learn from less input/output samples or solve
more challenging problems. But discovering useful priors
that generalize over a wide range of tasks is difﬁcult, es-
pecially if we only consider to deﬁne such priors over the
target function, its input, and its output.

For many problems, there are additional data z available
that are neither the input x nor the output y of function f
but that carry valuable information about how f maps x to
y, as illustrated in Fig. 1.

1The ﬁrst two authors contributed equally to this work.

We refer to this kind of data as
side information (Chen et al., 2012),
also known as privileged informa-
tion (Vapnik & Vashist, 2009). Ex-
amples for side information are (i)
intermediate results computed by the
true underlying f , (ii) output of a
related function (with input x) that
shares computations with f , (iii) in-
put of a related function (with out-
put y) that shares computations with f , or (iv) relations
between inputs xi and xj or between outputs yi and yj.

Figure 1. Side
information z is
related to function
f (x) = y.

Example: Suppose we want to estimate a function from
the input/output samples: 3 (cid:55)→ 14, 5 (cid:55)→ 30, and 2 (cid:55)→ 9. From
looking at these data, it is not immediately obvious what
the true underlying function is. However, if we provide
side information and the prior that they correspond to in-
termediate values that f computes, in this case 3 (cid:55)→ 9 (cid:55)→ 14,
5 (cid:55)→ 25 (cid:55)→ 30, and 2 (cid:55)→ 4 (cid:55)→ 9, we see that the function ﬁrst
squares its input and then adds ﬁve to the intermediate re-
sult, f (x) = x2 + 5. Side information together with a prior
about how they relate to f reveal the underlying function.

Incorporating priors about how z relates to f is what we
call learning with side information. By enforcing consis-
tency with these priors, we regularize learning which im-
proves generalization. Note that we use side information
only during training, not for prediction. There are a num-
ber of approaches in the literature that (often implicitly)
follow the paradigm of learning with side information and
demonstrate impressive results. This paper connects these
lines of work, makes the underlying paradigm explicit, and
attributes the improved generalization to the use of priors
enabled by side information.

1.1. Prior Knowledge in Machine Learning

As mentioned before, machine learning incorporates priors
about the target function f to generalize beyond observed
data. Although not always stated explicitly, priors about
f are reﬂected in every component of a machine learning
approach: in the hypothesis space (e.g. by deﬁning fea-
tures, kernels, neural network structure), in the generation
of training data (e.g. by data augmentation), in the learn-

Patterns for Learning with Side Information

ing procedure (e.g. by following a curriculum or decaying
the learning rate), and in the learning objective (e.g. by
including a regularization loss).

Learning with side information provides an effective way
to incorporate priors into the learning objective by exploit-
ing data that are neither input nor output data of the target
function f and are only required during training time. Note
the difference to unsupervised and semi-supervised learn-
ing which only consider additional input data.

1.2. Contribution

This paper, for the ﬁrst time, systematically analyzes how
to exploit side information for improving generalization. It
makes four main contributions:

The ﬁrst contribution is a new perspective on machine learn-
ing problems. This perspective connects approaches from
the literature such as multi-task learning, multi-view learn-
ing, slow feature analysis, learning using privileged infor-
mation, as well as several recent works in deep learning. By
connecting these lines of work, which previously did not
reference each other, we enable a new exchange of ideas
between them. To facilitate communication, we provide
a unifying formalization of learning with side information
(Sec. 2).

Our second contribution is a number of insights about these
methods. First, they form a small set of patterns (Sec. 3)
that correspond to different relationships between side in-
formation and target function (i-iv, second paragraph of the
introduction). Second, the pattern’s effectiveness in gener-
alization is a result of incorporating priors about these rela-
tionships. Since patterns incorporate different priors, their
effectiveness must depend on whether the learning task and
side information match the prior. We, therefore, hypothe-
size that different patterns work for different tasks.

As our third contribution, we demonstrate how our insights
advance learning with side information. First, we use the
presented patterns to systematically compare different ways
to use side information. Second, we present a new pattern
that has not been studied in the literature (Sec. 3.3). Third,
we facilitate the practical application of learning with side
information by giving a broad overview of successful ap-
plications in the literature (Appendix2 C) and by making
our implementation publicly available3.

The fourth contribution is a systematic experimental eval-
uation methods for learning with side information (Sec. 4).
Our experiments conﬁrm results from the literature by show-
ing that learning with side information greatly improves

2The appendix can be found in the supplementary material.
3Our code for learning with side information is available at

https://github.com/tu-rbo/concarne

generalization. Moreover, the results support our hypothe-
sis from contribution two, showing that a pattern’s perfor-
mance strongly depends on the given task and the available
side information.

2. Learning with Side Information

In learning with side information, we estimate a function
f : x → y and optionally an auxiliary function β by mini-
mizing two objective functions, the main objective Lf and
the side objective Lz:

argminf Lf (f | {xi, yi}N
i=1),
argminf,β Lz(f, β | {xi, yi}N

i=1, {zj}M

j=1).

To deﬁne Lf , we assume a supervised learning setting,
in which the goal is to estimate a function f : x → y
from a set of N input/output pairs {xi, yi}N
i=1. Then, Lf
corresponds to a standard supervised learning objective,
e.g. mean-squared error for regression, and hinge loss for
classiﬁcation.

The side objective is captured by Lz, which depends on
side information z and can include the auxiliary function
β. The exact form of Lz, z and β depends on the pattern
applied (Sec. 3). For all patterns, z are data that are neither
from the input space nor from the output space of f but
carry valuable information about f , and are only needed
for learning, not for prediction. Hence, the training data
include M side information samples in addition to the N
input/output pairs, D = ({xi, yi}N
j=1). Each of
the side information samples relates to one or more in-
put/output samples, commonly M = N or M = N 2.

i=1, {zj}M

To exploit z for learning f , we formulate priors about how
z relates to f in the side objective Lz. To express Lz, many
patterns require f to be split into two functions, φ and ψ,
where φ maps x to an intermediate representation s, and ψ
predicts y based on s, hence y = f (x) = ψ(φ(x)) = ψ(s).
This split exposes the representation s and facilitates the
formulation of Lz by relating s and z, possibly using β.
Often it allows us to omit ψ and y from Lz, i.e. to deﬁne
Lz(φ, β | {x}, {z}). For example, in the multi-task pat-
tern (Sec. 3.2) the intermediate representation s is shared
amongst the main task of predicting y with function ψ(s)
and an auxiliary task of predicting z with β(s). The aux-
iliary task regularizes the shared function φ and improves
generalization for the main task.

Note that we intentionally kept this formalization narrow
to improve readability. It is straightforward to extend the
ideas presented here to a reinforcement learning setting, to
multiple types of side information, to multiple intermediate
representations, and to more than one side objective.

Patterns for Learning with Side Information

2.1. Training Procedures

Since learning with side information requires us to opti-
mize multiple learning objectives affected by different sub-
sets of training data and functions, we need appropriate
training procedures. We have identiﬁed three common train-
ing procedures that differ with respect to the order in which
they (i) optimize the two objectives and (ii) modify the
functions f and β:

Simultaneous learning jointly trains f and β by optimiz-
ing a weighted sum of the two learning objectives Lf and
Lz (Weston et al., 2012). This procedure introduces the
need to ﬁnd a good weighting of the different learning ob-
jectives, which might be difﬁcult if the gradients of the
objectives differ by orders of magnitude and vary during
learning.

If we split f into φ and ψ, as described in the previous sec-
tion, we can choose among two additional procedures. In
the decoupled procedure, we ﬁrst optimize the side objec-
tive Lz(φ, β | {x}, {z}), while adapting φ and β to learn
the intermediate representation s. Then, we optimize the
main objective Lf (φ, ψ | {x, y}), while keeping φ (and
β) ﬁxed. This simple procedure is only applicable if the
side objective provides enough guidance to learn a task-
relevant representation s, whereas the simultaneous proce-
dure is also applicable for “weak” side objectives Lz. To
alleviate this problem, the pre-train and ﬁnetune proce-
dure ﬁrst applies the decoupled procedure, but then opti-
mizes Lf (φ, ψ | {x, y}) while adapting φ, too, in order to
ﬁne-tune s for the task. This strategy is popular in deep
learning as unsupervised pre-training (Erhan et al., 2010)
and can be applied analogously for learning with side in-
formation. For this procedure to have an effect, Lf must
not be convex (otherwise, the pre-training step would be
unlearned).

3. Patterns for Learning with Side

Information

We will now present different approaches for learning with
side information, which we have grouped into patterns. We
describe for each pattern the general idea, the underlying
prior, the side information z, the side objective Lz, and the
auxiliary function β. We point to successful applications
of each pattern (summarized in Appendix C) and visualize
the patterns with schemas as in Fig. 2.

How to read the schemas: The schemas represent compu-
tation ﬂow graphs where functions (drawn as arrows) con-
nect variables (represented as nodes), both of which follow
the deﬁnitions from Section 2. Predictions of variables are
indicated by ˆ·. The target function is depicted in black.
Additional elements that are only required at training time
and can be omitted during prediction are shown in gray,

except for side information and the corresponding learning
objectives, which are highlighted in green. Learning ob-
jectives are visualized by connecting variables with ∼ to
denote that the objective enforces similarity between these
variables. The =-sign (see Fig. 7) indicates that a function
is replicated (e.g. by weight sharing).

Note that these graphs are not probabilistic graphical mod-
els (PGMs). We provide PGMs as a complementary visual-
ization of causal dependencies in Appendix A. In contrast,
the computation ﬂow graphs are advantageous for the pur-
pose of this paper since (i) they discriminate between vari-
ables and functions, (ii) they expose the sequence of com-
putation, (iii) they visualize the learning objectives, and
thus (iv) are easily converted into neural networks, which
are employed by most of the related works reviewed in this
paper.

3.1. Direct Pattern

The direct pattern leverages known, intermediate results of
the computation performed by f . Given these intermediate
results as side information z, we can learn a function φ that
transforms x into the representation s such that s ∼ z, as
shown in Fig. 2. No auxiliary function β is required. The
pattern is only applicable if z makes it easier to predict y,
and if x contains enough information to predict z. The
example in Section 1 is an instance of this pattern.

To formalize this pattern,
we use a suitable supervised
learning side objective Lz =
Ldirect(φ | {x, z}) that en-
forces the representation s to
be equal to the side information z.

Figure 2. Direct pattern

Applications: Machine learning approaches in computa-
tional biology frequently use this pattern to combine un-
derstanding from biology research with learning. For ex-
ample, in contact prediction, the goal is to predict which
parts of a folded protein are close to each other based on
the DNA sequence that describes the protein. Virtually all
learning-based approaches to this problem ﬁrst predict in-
termediate representations s, such as secondary structures
(local 3D structure categories), and then use s to predict
contacts (Cheng & Baldi, 2007). The representation s can
be reliably estimated which greatly facilitates learning φ.

Knowledge transfer (Vapnik & Izmailov, 2015) uses this
pattern, but includes an additional step of extracting fea-
tures β(z) from the side information. Function φ is then
learned by regression, such that s ∼ β(z). They also sug-
gest augmenting s with the original input x. Similarly,
Chen et al. (2012) suggest to reconstruct only highly pre-
dictive features of z using a modiﬁed version of AdaBoost.

Patterns for Learning with Side Information

3.2. Multi-Task Pattern

Figure 3. Multi-task pattern

This pattern applies when the
side information z are out-
puts of a related function
(with input x) that shares
computations with the func-
tion we want to estimate. As illustrated in Fig. 3, the pattern
assumes that the target function f = ψ ◦ φ and the related
function β ◦ φ share φ and therefore have the same inter-
mediate representation s = φ(x). By training the represen-
tation to predict both y using ψ, and z using the auxiliary
learnable function β : s → z, we incorporate the prior that
related tasks share intermediate representations. This pat-
tern corresponds to multi-task learning (Caruana, 1997), a
type of transfer learning (Pan & Yang, 2010).

To apply the multi-task pattern, we can use any suitable
learning objective from supervised learning in order to learn
to predict z from x, i.e. Lz = Lmulti-task(φ, β | {x, z}).

Applications: Multi-task learning has been successfully
applied in a wide variety of tasks (Caruana, 1997; Pan &
Yang, 2010). Recently, Zhao & Itti (2015) proposed to use
object pose information to improve object recognition in a
convolutional deep neural network. Similarly, Levine et al.
(2015) use image classiﬁcation and pose prediction as side
information to teach a robot remarkable vision-based ma-
nipulation skills, such as stacking lego blocks or screwing
caps onto bottles.

3.2.1. IRRELEVANCE PATTERN

Figure 4. Exploiting irrelevant side
information.

A special case of the
multi-task patterns ex-
ploits knowledge about
unrelated tasks, by en-
forcing the prediction
of the side informa-
tion to be orthogonal to the main task (Romera-Paredes
et al., 2012). This idea is formalized by forcing ψ to be or-
thogonal to the auxiliary prediction function β (see Fig. 4),
which allows to use knowledge about irrelevant distractors
present in the input data. However, it is unclear how to ef-
ﬁciently formulate the orthogonality constraints between ψ
and β for the non-linear case.

3.3. Multi-View Pattern

The multi-view pattern is complementary to the multi-task
pattern, treating side information as input instead of out-
put. It applies when z are inputs of a related function (with
output y) that share computations with f . This pattern cor-
responds to multi-view learning (Sun, 2013).

When we treat z as auxiliary input, we can use it in two
different ways: explicitly by correlating it with the original

input x (Fig. 5), or implicitly by predicting the target output
(Fig. 6). In both cases, we learn functions φ : x (cid:55)→ s and
β : z (cid:55)→ s(cid:48), such that s ∼ s(cid:48).

The multi-view (correlation) pattern assumes that corre-
lated representations computed from related inputs are a
useful intermediate representation for predicting the tar-
get output. It can be formalized with a learning objective
that enforces the correlation between φ(x) and β(z), e.g.
the mean squared error Lz = Lmulti-view(φ, β | {x, z}) =
(cid:80)
If we apply the decoupled train-
ing procedure, i.e. only optimize the objective, we have to
add constraints, e.g. unit variance, to Lmulti-view in order to
avoid the trivial solution of having a constant intermediate
representation. In case φ and β are linear, Lmulti-view with
unit variance corresponds to Canonical Correlation Analy-
sis (CCA).

i ||φ(xi) − β(zi)||2.

(b) Labeled z data

(a) Labeled x data

Applications: The pattern
is often employed in multi-
modal scenarios (Sun, 2013).
Chen et al. (2014) show how
to enhance object recogni-
tion from RGB-only images
by leveraging depth data as
side information during train-
ing. In computational neuro-
science, the pattern is widely
used to learn from multiple
modalities (e.g., EEG and
fMRI) or across subjects (D¨ahne et al., 2014). The pat-
tern can also be applied for clustering (Feyereisl & Aicke-
lin, 2012). The idea is to repeatedly cluster on both {xi}
and {zj} and then return the clustering of x with the high-
est agreement with z.
In a recent article, Wang et al.
(2015) suggest and compare deep architectures that com-
bine multi-task and multi-view learning, and show that a
deep canonically correlated auto-encoder gives superior re-
sults for visual, speech, and language learning.

Figure 5. Multi-view (cor-
relation) pattern

The multi-view prediction
pattern is based on the prior
that predicting the target out-
put
from related inputs re-
quires similar intermediate
representations. It trains the
functions φ : x (cid:55)→ s and
β : z (cid:55)→ s(cid:48) such that both s and s(cid:48) map to the target out-
put using the same prediction function ψ, e.g. using weight
sharing. Since s and s(cid:48) are coupled to y via the main ob-
jective, we do not only regularize φ, but also ψ.

Figure 6. Multi-view
prediction pattern

Despite their similarities, we are not aware of any system-
atic comparison of multi-view and multi-task learning. Nei-
ther have we found applications of the prediction pattern
in the literature. Our experiments provide a ﬁrst empirical

Patterns for Learning with Side Information

comparison of these patterns (Sec. 4).

3.4. Pairwise Patterns

Pairwise patterns use side
information zij that carry
information about the rela-
tionship between samples i
and j to shape the inter-
mediate representation, e.g.
the difference between their intermediate representations
(Fig. 7, the = indicates weight sharing).

Figure 7. Pairwise pattern

3.4.1. PAIRWISE SIMILARITY/DISSIMILARITY

PATTERN

If the side information gives information about similarity
of samples with respect to the task, we can impose the
prior that samples that are similar (dissimilar) according to
their side information should have similar (dissimilar) in-
termediate representations. Such side information is often
available as information about local neighborhoods of sam-
ples (Tenenbaum et al., 2000). Another powerful source
of similarity information are time sequences, since tempo-
rally subsequent samples often have similar task-relevant
properties, as exploited by slow feature analysis (SFA) and
temporal coherence (Wiskott & Sejnowski, 2002; Weston
et al., 2012). Additionally, an intelligent teacher can pro-
vide information about which samples are similar (Vapnik
& Izmailov, 2015).

Similarity can be enforced with a squared loss on the dis-
tance between similar samples:

Lsim.(φ | {x, z}) =

||φ(xi) − φ(xj)||2 1(zij = sim.),

where 1 denotes the indicator function. Solely using this
objective might lead to trivial solutions where all samples
are mapped to a constant. We can resolve this problem
by imposing additional balancing constraints on s (Weston
et al., 2012) or selectively push samples apart that are dis-
similar according to the side information (or optionally ac-
cording to the labels y):
(cid:88)

σ(||φ(xi) − φ(xj)||) 1(zij = dis.),

Ldis.(φ | {x, z}) =

where σ is a function that measures the proximity of dis-
similar samples in representation s. Candidates for σ are
the margin-based σ(d) = max(0, m − d2) for some pre-
deﬁned margin m (Hadsell et al., 2006), the exponential of
the negative distance σ(d) = e−d (Jonschkowski & Brock,
2014), or the Gaussian function σ(d) = e−d2
(Jonschkowski
& Brock, 2015). Another way to avoid trivial solutions is
to impose an input-reconstruction objective, e.g. by using
an auto-encoder (Watter et al., 2015).

(cid:88)

i,j

i,j

Vapnik & Izmailov (2015) incorporate similarity informa-
tion into support vector machines by replacing the free slack
variables with a function of z. This method incorporates
the prior that slack variables should be similar for samples
with similar side information.

Applications: This pattern has been shown to successfully
guide the learner in identifying task-relevant properties of
x. Hadsell et al. (2006) show how to learn a lighting in-
variant pose representation of objects in the NORB dataset.
Weston et al. (2012) show that regularizing a convolutional
network with a temporal coherence objective outperforms
pure supervised object classiﬁcation in the COIL-100 dataset
by 20% in terms of recognition accuracy.

Recent works show how to apply this pattern to reinforce-
ment learning settings. Watter et al. (2015) exploit the
time sequence to jointly learn a state representation and
the world dynamics from raw observations for a variety of
standard tasks, such as cart-pole balancing. Jonschkowski
& Brock (2015) apply the pattern in a robot navigation task,
and show how leveraging temporal and robot action infor-
mation enable the robot to learn a state representation from
raw observations, despite the presence of visual distractors.

Note that this pattern only preserves local similarities be-
tween samples. If the side information provides a global
distance metric, Weston et al. (2012) propose to formulate
side objectives for learning a distance-preserving mapping
of x to z, e.g. based on multi-dimensional scaling (Kruskal,
1964). Alternatively, the distance metric can be learned us-
ing side information (Fouad et al., 2013).

3.4.2. PAIRWISE TRANSFORMATION PATTERN

Instead of exploiting only binary similarity information be-
tween samples, the pairwise transformation pattern exploits
continuous information about the relative transformations
between samples, to make the internal representation (or
parts of it) consistent or equivariant with the known rela-
tive transformations. Such side information is often avail-
able in robot and reinforcement learning settings.

Consistency with the transformations z can be enforced in
different ways: (a) Hinton et al. (2011) require the transfor-
mation z to affect s in a known way, and suggest the trans-
forming autoencoder model shown in Fig. 8(a) to learn such
an s. The idea is to learn to reconstruct the transformed in-
put from the original input and the known transformation.
(b) If the transformations in s are unknown, Jayaraman &
Grauman (2015) suggest to learn these transformations as
an auxiliary task using the pattern depicted in Fig. 8(b).
(c) We can also turn this approach around and try to pre-
dict the transformation based on the original and the trans-
formed representation (Agrawal et al., 2015) as depicted
in Fig. 8(c). All three variants (a)-(c) enforce equivariance

Patterns for Learning with Side Information

of s with respect to the relative transformations, and can
be trained using supervised side objectives. (d) Instead of
optimizing for equivariance, we can also enforce that the
same transformation has the same effect, when applied to
different samples (Fig. 8(d)). When transformations are
discrete, we formalize this by penalizing the squared differ-
ence of the change in internal representation after applying
the same transformation:

Ltransf.(φ | {x, z}) =

||∆φ(xi) − ∆φ(xj)||21(zi= zj),

(cid:88)

i,j

where ∆ denotes the change caused by the transformation,
i.e. ∆φ(xi) = φ(xi+1) − φ(xi) for sequential data. This
objective can be extended to continuous transformations by
replacing the indicator function with a similarity function
σ(zi− zj) from Section 3.4.1. Variants of this pattern al-
low to enforce only locally consistent transformations, by
multiplying σ(φ(xi) − φ(xj)), or to enforce only consis-
tent magnitudes of change by comparing norms ||∆φ(xi)||
(Jonschkowski & Brock, 2015).

(b) Predicting representation

(c) Predicting transformation

(a) Predicting transformed input

Applications: Many
results in the literature
demonstrate the useful-
ness of
the pairwise
transformation pattern.
Agrawal et al. (2015) re-
port
that using rela-
tive pose information as
side information can re-
duce the error rate on
MNIST by half with
respect to pure super-
vised learning. They
also demonstrate the
approach for scene recog-
nition on the SUN dataset,
and show that pre-training
using limited of relative
pose side information is
almost as good class-
based supervision. Ja-
yaraman & Grauman
(2015) demonstrate a
recognition accuracy of
≈ 50% on the KITTI
dataset, outperforming pure supervised learning (41.81%
accuracy) and SFA (47.04%). Interestingly, both works en-
force learning a pose equivariant representation, although
the classiﬁcation task they address requires invariance. It
is still unclear why equivariant representations help in such
tasks (Lenc & Vedaldi, 2014).

(d) Comparing pairs of transfor-
mations

Figure 8. Pairwise transf. patterns

3.4.3. LABEL DISTANCE PATTERN

not

(see

samples

The label distance pattern is a special case of the pairwise
pattern, where the side information deﬁnes distances be-
tween
9).
labels,
An instance of this pat-
tern, often used in struc-
tured prediction, is hier-
archical multi-class learn-
ing (Silla Jr & Freitas, 2010), where a hierarchy is imposed
on the labels to penalize misclassiﬁcations between sam-
ples with similar classes less severely.

Figure 9. Label distances

Fig.

4. Experiments

The related work, discussed in the previous section, demon-
strated that learning with side information greatly improves
generalization. In our experiments, we provide, for the ﬁrst
time, a systematic comparison of the different patterns in
two supervised learning tasks. We outline the experimen-
tal rationale and results here, and refer to Appendix B for
details.

4.1. Synthetic Task

In the ﬁrst, synthetic, experiment the goal is to predict the
position of a randomly moving agent in a 1-dimensional
state space s. The learner cannot perceive s directly, but
gets an observation x, which embeds s and a set of dis-
tractor signals in a high-dimensional space. The learned
functions are linear (φ and β), and logistic functions (ψ),
respectively. We study the effect of different combinations
of (i) side information, (ii) patterns, and (iii) training proce-
dures on prediction accuracy. The side information are ei-
ther a noisy variant of the real state (direct side information,
Fig. 10(a)), a second noisy high-dimensional observation
(embedded, Fig. 10(b)), or a noisy variant of the agent’s ac-
tions, i.e. the agent’s relative motion (pairwise, Fig. 10(c)).
We apply the direct, multi-view, multi-task, and pairwise
transformation patterns, and perform training using the de-
coupled and simultaneous procedure (pre-training is futile
with linear functions). We compare to supervised and semi-
supervised baselines.

Results: While none of the baselines are able to solve the
task with the given amount of training data, for each form
of side information, at least one pattern achieves close to
optimal performance. For the simple direct side informa-
tion (Fig. 10(a)) all patterns except the multi-view predic-
tion pattern are applicable; the reason is that the direct data
correspond to the real state, and thus make solving the task
almost trivial. This does not hold true for the embedded
side information (Fig. 10(b)). Here, the simultaneously
trained multi-view correlation pattern clearly outperforms
all other methods. The reason is that the embedded side in-

Patterns for Learning with Side Information

formation exactly matches the prior of the multi-view pat-
tern. The pairwise transformation pattern, when applied
to pairwise side information (Fig. 10(c)), is as effective as
learning from direct side information. Overall, the experi-
ments conﬁrm our hypothesis that the effectiveness of each
pattern strongly depends on the type of side information.

4.2. Handwritten Character Recognition

In this experiment, we test learning with side information
for handwritten character recognition in images (see Fig. 11),
where we use the pen trajectory as side information. As
in the previous experiment, we vary (i) the representation
of the side information, either as continuous vectors or dis-
crete categories; (ii) the pattern: direct, multi-task, or multi-
view; and (iii) the training procedure: decoupled, pre-train
and ﬁnetune, or simultaneous. In all our experiments, we
keep the number of unlabeled data and side information
ﬁxed and examine how the accuracy of the main task is
affected by changing the number of labeled data. All ap-
proaches use the same convolutional neural network archi-
tecture. As baselines we use purely supervised learning and
unsupervised pre-training (deep auto-encoder).

Figure 11. Sample input
the 20 single-stroke-
for each of
characters in this task: a, b, c, d, e, g, h, l, m, n, o, p, q, r, s,
u, v, w, y, z. Variations like the added random lines make this task
challenging.

Results: First, we see that learning with side informa-
tion can dramatically improve generalization, achieving the
same performance using 5 labels per class as the baselines
achieve with 100 (see Fig. 12(b)). Second, for this task,
only the multi-task pattern exhibits this signiﬁcant increase
in performance. However, we also note that the effective-
ness of learning with side information does not only depend
on the pattern, but also on the representation of the side in-
formation (compare Figs. 12(a) and 12(b)): When we use
the vector of pen coordinates as side information, the direct
pattern provides some improvement over the baselines, but
the multi-task and multi-view patterns do not improve the
performance by large amounts (see Fig. 12(a)). However,
when discretizing the trajectories into a small number of
categories and applying the multi-task pattern for predict-
ing these categories, we drastically reduce the number of
labels required to solve this task (see Fig. 12(b)). This is
not the case if we use other patterns. Moreover, we see that
multi-task learning applied to the discretized side informa-
tion is not signiﬁcantly inﬂuenced by the training proce-
dure (compare to direct pattern). This shows how—in this
task—the multi-task pattern is able to ﬁnd a good inter-
mediate representation independently of the main objective
(Fig. 12(c)). These results conﬁrm our hypothesis that the
available side information must match the prior imposed by
the applied pattern in order to improve generalization.

(a) Direct side information

(b) Embedded side information

(c) Pairwise side information

Figure 10. Results for the synthetic task, averaged over 10 runs.
The most suitable patterns outperform supervised and semi-
supervised baselines and generalize better with much less data.

Patterns for Learning with Side Information

tasks, we hypothesize that the performance of these pat-
terns will vary strongly depending on the applicability of
the corresponding prior. Our experiments conﬁrm this hy-
pothesis and also show that learning with side information
can substantially improve generalization.

Our perspective of learning with side information can be
helpful in a number of ways. First of all, the patterns that
we have presented allow researchers and practitioners to
exploit side information in novel tasks in a systematic fash-
ion. Applying the patterns in novel tasks is facilitated by
our publicly available implementation and a broad overview
of existing methods and applications in this paper. Our lit-
erature review provides a formalization that uniﬁes differ-
ent lines of research, which currently seem to be unaware
of the strong similarities among them. This common view
will allow researchers to exchange ideas more easily, to ﬁnd
novel patterns for using side information, and to effectively
combine patterns to exploit multiple sources of side infor-
mation.

Moreover, we expect learning with side information to be
very effective beyond supervised learning settings. In par-
ticular, reinforcement learning can beneﬁt signiﬁcantly be-
cause of the strong relationship between the different data
sources (observations, actions, and rewards over time). By
formulating priors over their relationships, we can exploit
this rich side information in order to learn better state, ac-
tion, and policy representations. This stands in contrast
to most datasets available in machine learning, which are
shaped according to the supervised learning paradigm and
thus only consist of input/output samples. We, therefore,
suggest to construct and augment datasets with relevant
side information.

Although the utility of the view that we have presented can
ultimately only be estimated in hindsight, we strongly be-
lieve that unifying ideas and providing new perspectives is
vital to scientiﬁc progress, as exempliﬁed by Bengio et al.
(2013). We hope that the presented perspective of learn-
ing with side information triggers further research in that
direction that generates new insights in our ﬁeld.

ACKNOWLEDGMENTS

We gratefully acknowledge the funding provided by the
European Commission (SOMA project, H2020-ICT-645599),
the German Research Foundation (Exploration Challenge,
BR 2248/3-1), and the Alexander von Humboldt founda-
tion (funded by the German Federal Ministry of Education
and Research). We would like to thank Marc Toussaint and
the University of Stuttgart for granting us access to their
GPU cluster, and Sven D¨ahne, George Konidaris, Johannes
Kulick, Tobias Lang, Robert Lieck, Ingmar Posner, and
Michael Schneider for fruitful discussions and comments
on this manuscript.

(a) Continuous side information

(b) Discretized side information

(c) Training procedures

Figure 12. Results for handwritten character recognition task. (a)
uses continuous side information. (b) and (c) use the discretized
side information. Line styles denote the training procedure (solid
= pretrain/ﬁnetune, dashed = decoupled training, dotted lines =
simultaneous training).

5. Conclusion and Discussion

In this paper, we show how learning with side information
provides a new perspective on machine learning, and com-
plements existing paradigms such as supervised learning,
representation learning, and deep learning. This new per-
spective allows us to connect various methods in the liter-
ature that (implicitly) use side information. It also enables
us to systematically analyze these methods and extract pat-
terns from them that show how they incorporate different
priors about how side information relates to the target func-
tion. Since different priors coincide with different learning

Patterns for Learning with Side Information

References

Agrawal, Pulkit, Carreira, Joao, and Malik, Jitendra.
Learning to See by Moving. arXiv:1505.01596 [cs],
May 2015.

Ando, Rie Kubota and Zhang, Tong. A Framework for
Learning Predictive Structures from Multiple Tasks and
Unlabeled Data. Journal of Machine Learning Research,
6:1817–1853, November 2005.

Bastien, Fr´ed´eric, Lamblin, Pascal, Pascanu, Razvan,
Bergstra, James, Goodfellow, Ian, Bergeron, Arnaud,
Bouchard, Nicolas, Warde-Farley, David, and Bengio,
Yoshua. Theano: new features and speed improvements.
In NIPS 2012 deep learning workshop, 2012.

Baxter, Jonathan. A model of inductive bias learning. J.

Artif. Intell. Res.(JAIR), 12:149–198, 2000.

Bengio, Yoshua, Courville, Aaron, and Vincent, Pascal.
Representation Learning: A Review and New Perspec-
tives. Pattern Analysis and Machine Intelligence, IEEE
Transactions on, 35(8):1798–1828, 2013.

Blum, Avrim and Mitchell, Tom. Combining labeled and
unlabeled data with co-training. In Proceedings of the
eleventh annual conference on Computational learning
theory, pp. 92–100. ACM, 1998.

Caruana, R. Multitask learning. Machine learning, 28(1):

41–75, 1997.

Chen, Jixu, Liu, Xiaoming, and Lyu, Siwei. Boosting
with Side Information. In Lee, Kyoung Mu, Matsushita,
Yasuyuki, Rehg, James M., and Hu, Zhanyi (eds.),
Computer Vision - ACCV 2012, number 7724 in Lec-
ture Notes in Computer Science, pp. 563–577. Springer
Berlin Heidelberg, November 2012.

Chen, Lin, Li, Wen, and Xu, Dong. Recognizing RGB
Images by Learning from RGB-D Data. In 2014 IEEE
Conference on Computer Vision and Pattern Recognition
(CVPR), pp. 1418–1425, June 2014.

Evgeniou, Theodoros and Pontil, Massimiliano. Regular-
In Proceedings of the Tenth
ized Multi-task Learning.
ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, KDD ’04, pp. 109–117,
New York, NY, USA, 2004. ACM.

Farquhar,

Jason, Hardoon, David, Meng, Hongying,
Shawe-taylor, John S., and Szedmak, Sandor. Two view
In Advances
learning: SVM-2k, theory and practice.
in neural information processing systems, pp. 355–362,
2005.

Feyereisl, Jan and Aickelin, Uwe. Privileged information
for data clustering. Information Sciences, 194:4–23, July
2012.

Fouad, S., Tino, P., Raychaudhury, S., and Schneider,
P. Incorporating Privileged Information Through Metric
Learning. IEEE Transactions on Neural Networks and
Learning Systems, 24(7):1086–1098, July 2013.

Hadsell, Raia, Chopra, Sumit, and LeCun, Yann. Dimen-
sionality Reduction by Learning an Invariant Mapping.
In Proc. Computer Vision and Pattern Recognition Con-
ference (CVPR’06). IEEE Press, 2006.

Hinton, Geoffrey E., Krizhevsky, Alex, and Wang, Sida D.
In Artiﬁcial Neural Net-
Transforming auto-encoders.
works and Machine Learning-ICANN 2011, pp. 44–51.
Springer, 2011.

Jayaraman, Dinesh and Grauman, Kristen.

Learn-
ing image representations equivariant to ego-motion.
arXiv:1505.02206 [cs, stat], May 2015.

Jonschkowski, Rico and Brock, Oliver. State Representa-
tion Learning in Robotics: Using Prior Knowledge about
In Robotics Science and Systems
Physical Interaction.
(RSS) X, Berkeley, USA, 2014.

Jonschkowski, Rico and Brock, Oliver. Learning state rep-
resentations with robotic priors. Autonomous Robots, 39
(3):407–428, July 2015.

Cheng, Jianlin and Baldi, Pierre. Improved residue contact
prediction using support vector machines and a large fea-
ture set. BMC Bioinformatics, 8(1):113, April 2007.

Kingma, Diederik P. and Welling, Max. Auto-Encoding
In International Conference on
Variational Bayes.
Learning Representations (ICLR), Banff, Canada, 2014.

D¨ahne, Sven, Nikulin, Vadim V., Ram´ırez, David, Schreier,
Peter J., M¨uller, Klaus-Robert, and Haufe, Stefan. Find-
ing brain oscillations with power dependencies in neu-
roimaging data. NeuroImage, 96:334–348, August 2014.

Erhan, Dumitru, Bengio, Yoshua, Courville, Aaron, Man-
zagol, Pierre-Antoine, Vincent, Pascal, and Bengio,
Samy. Why Does Unsupervised Pre-training Help Deep
J. Mach. Learn. Res., 11:625–660, March
Learning?
2010.

Kruskal, J. B. Multidimensional scaling by optimizing
goodness of ﬁt to a nonmetric hypothesis. Psychome-
trika, 29(1):1–27, March 1964.

Legenstein, Robert, Wilbert, Niko, and Wiskott, Lau-
renz. Reinforcement Learning on Slow Features of High-
Dimensional Input Streams. PLoS Comput Biol, 6(8):
e1000894, 2010.

Patterns for Learning with Side Information

Lenc, Karel and Vedaldi, Andrea. Understanding im-
age representations by measuring their equivariance and
equivalence. arXiv:1411.5908 [cs], November 2014.

Wang, Wei and Zhou, Zhi-Hua. A new analysis of co-
training. In Proceedings of the 27th International Con-
ference on Machine Learning (ICML-10), 2010.

Levine, Sergey, Finn, Chelsea, Darrell, Trevor, and Abbeel,
Pieter. End-to-End Training of Deep Visuomotor Poli-
cies. arXiv:1504.00702 [cs], April 2015.

Wang, Weiran, Arora, Raman, Livescu, Karen, and Bilmes,
Jeff. On Deep Multi-View Representation Learning.
2015.

Watter, Manuel, Springenberg, Jost, Boedecker, Joschka,
and Riedmiller, Martin. Embed to control: A locally lin-
ear latent dynamics model for control from raw images.
In Advances in Neural Information Processing Systems,
pp. 2728–2736, 2015.

Weston, Jason, Ratle, Fr´ed´eric, Mobahi, Hossein, and Col-
lobert, Ronan. Deep Learning via Semi-supervised Em-
bedding. In Montavon, Gr´egoire, Orr, Genevive B., and
M¨uller, Klaus-Robert (eds.), Neural Networks: Tricks of
the Trade, number 7700 in Lecture Notes in Computer
Science, pp. 639–655. Springer Berlin Heidelberg, 2012.

Williams, Ben H., Toussaint, Marc, and Storkey, Amos J.
A Primitive Based Generative Model to Infer Timing In-
formation in Unpartitioned Handwriting Data. In IJCAI,
pp. 1119–1124, 2007.

Wiskott, Laurenz and Sejnowski, Terrence J. Slow Feature
Analysis: Unsupervised Learning of Invariances. Neural
Computation, 14(4):715–770, April 2002.

Wolpert, David H. The Lack of A Priori Distinctions Be-
tween Learning Algorithms. Neural Computation, 8(7):
1341–1390, October 1996.

Zhao, Jiaping and Itti, Laurent. Improved Deep Learning

of Object Category using Pose Information. 2015.

Maurer, Andreas. Bounds for Linear Multi-Task Learning.

J. Mach. Learn. Res., 7:117–139, December 2006.

Mitchell, Tom M. The need for biases in learning general-
izations. Department of Computer Science, Laboratory
for Computer Science Research, Rutgers Univ., 1980.

Ngiam, Jiquan, Khosla, Aditya, Kim, Mingyu, Nam,
Juhan, Lee, Honglak, and Ng, Andrew Y. Multimodal
deep learning. In Proceedings of the 28th international
conference on machine learning (ICML-11), pp. 689–
696, 2011.

Pan, Sinno Jialin and Yang, Qiang. A Survey on Transfer
Learning. IEEE Transactions on Knowledge and Data
Engineering, 22(10):1345–1359, October 2010.

Romera-Paredes,

Argyriou,

Andreas,
Bernardino,
Ex-
Berthouze, Nadia, and Pontil, Massimiliano.
ploiting unrelated tasks in multi-task learning.
In
International Conference on Artiﬁcial Intelligence and
Statistics, pp. 951–959, 2012.

Schaffer, C. A conservation law for generalization perfor-
mance. In Proceedings of the Eighth International Ma-
chine Learning Conference, pp. 259–265. Morgan Kauf-
mann, 1994.

Silla Jr, Carlos N. and Freitas, Alex A. A survey of hi-
erarchical classiﬁcation across different application do-
mains. Data Mining and Knowledge Discovery, 22(1-2):
31–72, April 2010.

Sun, Shiliang. A survey of multi-view machine learn-
ing. Neural Computing and Applications, 23(7-8):2031–
2038, February 2013.

Tenenbaum, Joshua B., Silva, Vin de, and Langford,
John C. A Global Geometric Framework for Nonlinear
Dimensionality Reduction. Science, 290(5500):2319–
2323, December 2000.

Vapnik, Vladimir and Izmailov, Rauf. Learning Using Priv-
ileged Information: Similarity Control and Knowledge
Transfer. Journal of Machine Learning Research, 16:
2023–2049, 2015.

Vapnik, Vladimir and Vashist, Akshay. A new learning
paradigm: Learning using privileged information. Neu-
ral Networks, 22(5-6):544–557, July 2009.

Patterns for Learning with Side Information

A. Patterns as Probabilistic Graphical Models

To complement the computation ﬂow schemas of the pat-
terns used throughout the paper, we provide an interpreta-
tion of the main patterns as probabilistic graphical models
(PGMs). These models treat the variables and functions
introduced in Sec. 2 as random variables, represented as
nodes. Arrows between these random variables indicate
causal relationships. Gray nodes indicate observable, and
white nodes latent random variables. The latent functions
can be learned by performing inference in these models.

turally similar and only differ on whether z depends on s
and β or whether s depends on z and β.
In this regard,
they are equivalent to their corresponding computation ﬂow
schemas apart from the fact that the PGM for the multi-
view pattern conceals how the variables x and z belong to
the functions φ and β.

Finally, the prototypical pairwise pattern is shown in Fig. 13(a)
(computation ﬂow graph: Fig. 7). Notice that here sj is
conditioned on zi,j and si, reﬂecting the fact that zi,j is
information about how sj relates to si.

ψ

y

D

yi

yj

β

x

xi

xj

φ

s

z

si

sj

zij

Several interesting research questions arise from the prob-
abilistic view on learning with side information. The ma-
jority of the reviewed literature uses non-probabilistic loss
functions, mostly for training neural networks. Translat-
ing them into probabilistic ones is an interesting, but non-
trivial research question, as the recent work on variational
auto-encoders (which are a probabilistic version of auto-
encoders) shows (Kingma & Welling, 2014). A similar
question arises on the relationship of the side objectives and
prior probability distributions on φ, ψ, β and s. It would
be interesting to investigate whether certain side objectives
can be shown to be equivalent to priors in the Bayesian
sense, similar to the well-known fact that L2 regularization
is equivalent to a Gaussian prior.

B. Experimental Methods

The implementation of our experiments is based on Theano (Bastien
et al., 2012) and Lasagne4. We have made our code pub-
licly available at: [url removed for double-blind review]

(a) Direct pattern

(b) Multi-task pattern

φ

ψ

x

β

x

φ

s

φ

s

z

ψ

y

D

ψ

y

D

B.1. Synthetic Task

Pairs (i, j) ∈ D

(c) Multi-view pattern

(d) Pairwise pattern

Figure 13. Probabilistic graphical models for patterns

The PGMs for the four main patterns are shown in Fig. 13.
The variables x, s, z and y are observable random variables
and are part of the training data D. The functions φ, ψ and
β have become latent random variables, which the observed
variables are conditioned on. We now discuss aspects of
individual patterns.

The direct pattern is shown in Fig. 13(a). In comparison
to its computation ﬂow graph (Fig. 2), the side information
z is considered as drawn from the distribution over s, and
therefore z does not appear in the graphical model of the
direct pattern.

Fig. 13(b) and Fig. 13(c) show the PGM for the multi-
task and multi-view pattern, respectively (computation ﬂow
graphs: Fig. 3 and Fig. 5). We see that they are struc-

Task: The task consists of an agent moving randomly
through a 1-dimensional state space st ∈ R where t de-
notes the time index. The space is split into two regions
O1 = {s | s > 0} and O2 = {s | s < 0} and the
goal of the learner is to determine in which of the two re-
gions the agent is located. However, the learner cannot ob-
serve the state space directly, it only gets d-dimensional ob-
servations which are obfuscated by d − 1 distractors u(i)
,
t
i ∈ {1, . . . , d − 1}: the observation is generated by ap-
plying a random rotation R to the concatenated state and
distractor vector: xt = R [st, u(1)
]. In every
time step, both the state as well as the distractor dimensions
t + ε(i)
change randomly: st+1 = st + ε(s)
,
t
where ε(s)
t ∼ N (0, 1). In addition the agent receives a
supervised signal y which is 0 if the agent is in region O1
and 1 in zero O2.

, . . . , u(d−1)
t

t+1 = u(i)

, u(i)

, ε(i)

t

t

t

Baselines: We compare different variants of learning with

4https://github.com/Lasagne/Lasagne

Patterns for Learning with Side Information

side information to a supervised method (logistic regres-
sion mapping x directly to y) and to two semi-supervised
methods. For the semi-supervised baselines we apply ei-
ther PCA or SFA to learn a 1-dimensional s, and then train a
logistic regression mapping from s to y. For the logistic re-
gression, we use L2 regularization with C ∈ {0.001, 0.01,
0.1, 1.0, ∞} and choose the result with the lowest test error.
(We do not apply L2 regularization for variants of learning
with side information.)

pervised methods fail to extract a good state representation
since the real hidden s neither exhibits high variance, nor
a slower trajectory than the distractors. Pure supervised lo-
gistic regression works better, but even when doubling the
number of (x, y) pairs, it does not reach the performance
of the methods that use side information. We believe that
the multi-view-prediction pattern works badly because it
does not propagate enough information from the learned ψ
to regularize φ.

1+e

1
−wT
ψ

Patterns: We implemented the four principal patterns from
Section 3, using a linear function for φ(x) = wT
φ x = s and
a logistic function for ψ(s) =
s . We apply Stochas-
tic Gradient Descent with Nesterov momentum with value
0.9 to learn φ and ψ using a logistic regression loss in ad-
dition to the side objective. We train each pattern using
the decoupled and simultaneous training procedures (pre-
train/ﬁne-tune is futile due since φ and ψ are linear, and
both the target and the side objectives are convex; see Sec-
tion 2.1).
For the direct pattern, we learn φ directly by performing
a linear regression on z, using the mean squared error loss.
When training simultaneously, we weigh the main and the
side objective equally.
We implement the multi-task pattern by using a linear
function β(s) = wT
β s for the auxiliary task and optimize it
using linear regression. Again, we weigh the main and the
side objective equally.
We implement two versions of the multi-view pattern:
ﬁrst, the correlation variant, using β(z) = wT
β z = s(cid:48), op-
timizing for s ≈ s(cid:48), secondly, the prediction variant. For
the correlation pattern we have to give weight 0.99 to the
supervised and 0.01 to the side objective, since the gradi-
ents from the side objective (MSE loss) and the supervised
softmax loss differ by several orders of magnitude.
Finally, we implement the pairwise pattern, in form of the
transformation pattern. We use a simpliﬁed version of the
variant depicted in Fig. 8(c) with a ﬁxed auxiliary function
β(si, sj) = si − sj. Again, we weigh the main and the side
objective equally.

We evaluate subsets of the implemented patterns with three
types of side information. In each experiment, we use dif-
ferent amounts of (x, y, z) triplets for learning, and test the
prediction accuracy in the main task for a test set of size
50000. The dimensionality of x is set to 50. We average
the results over 10 independently generated training and
test sets.

Direct Side Information: First, we provide the learner
with very informative data in the form of a noisy variant
of the real state: z(s)
t ∼ N (0, 0.05).
Figure 10(a) shows that all variants of learning with side in-
formation except for the multi-view-prediction pattern gen-
eralize well, even given low amounts of data. The unsu-

t = st + ε(s)

, with ε(s)

t

t

t ∼ N (0, 0.05).

Embedded Side Information: In the second experiment,
we provide side information corresponding to an additional,
noisy sensor view by mapping the state into a different e-
, v(1)
dimensional observation space, z(v)
t = Q [st + ε(v)
,
t
. . . , v(e−1)
] with distractors v(i)
, random rotation matrix
t
t
Q and ε(v)
In the experiments, we set
e = d
2 . Figure 10(b) shows that most variants of learn-
ing with side information still outperform the supervised
method, but need more data to generalize well due to the
less informative side information. The multi-view method
performs best, whereas the multi-task performs even worse
than logistic regression. Moreover, we see that the simulta-
neous training procedures outperform the decoupled vari-
ants, most drastically in the multi-view pattern.

Relative Side Information: The last type of data corre-
sponds to a noisy variant of the “actions”, z(a)
t = st −
st−1 + ε(a)
t ∼ N (0, 0.05). Fig. 10(c) shows
clearly that this side information is highly useful, and al-
lows to learn from few samples.

t with ε(a)

B.2. Handwritten Character Recognition

Dataset and task: The dataset for this experiment is based
on the character trajectories dataset5, which consists of time
series of pen velocities in x and y direction and pen tip
force (more details in Williams et al. (2007)). The dataset
includes 20 characters that can be written in a single stroke.
Based on this dataset, we generate monochrome images of
size 32 × 32 pixels. During image generation, we add dif-
ferent variations to make this task more challenging. We
trace the character trajectories with varying pen width, we
translate the characters randomly, and we overlay distract-
ing lines that connect three random points in the image (see
Fig. 11). These images form the input x for this task. Addi-
tionally, we generate side information in the form of coor-
dinates of 32 points along the character trajectory making
up a 64D vector z. Unlike the input images, these points
are not translated. The task is to recognize which of the 20
characters is in the given image. The training data consist
of 100 input/side information pairs per character, a random
subset of which are labeled. In our experiment, we vary the

5https://archive.ics.uci.edu/ml/datasets/

Character+Trajectories

number of labels per character from 1 to 100.

C. Overview of Related Work

Patterns for Learning with Side Information

In the following table, we summarize related works that
apply learning with side information. Since an exhaustive
list of references for each pattern is beyond the scope of
this paper, we include works that span a wide variety of
instantiations of the proposed patterns and refer to survey
articles if available.

Abbreviations: AE=auto-encoder, CCA=canonical correlation anal-
ysis, ED=eigen decomposition, GMLVQ=generalized matrix learn-
ing vector quantization, kNN=k-nearest-neighbors, LBP=locally
binary pattern, MMD=maximum mean discrepancy, NN=neural
network, RBM=restricted Boltzmann machine, RL=reinforcement
learning, SGD=stochastic gradient descent, SL=supervised learn-
ing (classiﬁcation unless stated otherwise), SVM=support vector
machine, UL=unsupervised learning

Neural network structure and training: We use a con-
volutional neural network (CNN) with rectiﬁed linear units
(ReLU). We ﬁrst apply a convolution with 32 ﬁlters of size
5 × 5 followed by ReLU non-linearity and max-pooling.
The same sequence is repeated, followed by 50% dropout
and a fully connected layer of 32 ReLUs (the intermedi-
ate representation s). This is again followed by a 50%
dropout and 20 softmax output units. The entire network
has 52756 parameters. The supervised task is formulated
using the categorical crossentropy loss and optimized us-
ing Nesterov momentum with learning rate 0.003, momen-
tum 0.9, and batch size 20 for 100 epochs, followed by 10
epochs with learning rate 0.0003. All experiments are re-
peated 10 times.

In the experiment, we test two different
Discretization:
representations of the side information. The original con-
tinuous vector representation and a discretization into 32
classes, which we obtain with k-means clustering. The
rationale behind the discretization is that the exact trajec-
tory cannot be recovered from the image (because it is not
clear from the image where the character trajectory starts).
We tested the same discretization on the image in the semi-
supervised baseline.

Applied patterns: We compare the direct pattern, the
multi-task pattern, and the multi-view pattern. The direct
pattern uses a mean-squared-error objective to enforce the
intermediate representation to be equal to a 32D version
of the pen trajectory or the one-hot-vector that corresponds
to the discretized trajectory. The multi-task pattern incor-
porates an additional network layer to predict the side in-
formation, either a linear layer with mean-squared-error
loss to predict the trajectory or a softmax layer with cross-
entropy loss to predict its discretization. The multi-view
pattern uses two ReLU-layers with 32 units and dropout to
compute the intermediate representation s(cid:48) which we tie to
s with a mean-squared-error objective. Since this objective
creates trivial solutions if trained independently, we opti-
mize it simultaneously with the main objective (weighing
them with 0.05 and 0.95, respectively). All other patterns
are trained using the pretrain/ﬁnetune procedure unless in-
dicated otherwise. For simultaneous training of the multi-
task pattern, we used uniform weighting.

Baselines: We compare against supervised learning on the
labeled data and semi-supervised baselines: In the contin-
uous case, we reconstruct the image using a convolutional
autoencoder that mirrors the structure of the convolutional
network. In the discrete case we use a similar structure as
for multi-task learning but predict the discretized image in-
stead of the discretized trajectory.

Patterns for Learning with Side Information

Pattern

Side Objective

Articles

Direct
(Fig. 2)

SVM loss

Regression on highly
predictive features of side
information

Cheng & Baldi
(2007)

Chen et al.
(2012)

Method,
Train. Procedure

Application:
Task, Input, Dataset

SVM (decoupl.)

SL: Contact prediction on sequences

AdaBoost+ (simul.)

SL on images: Digit (Vapnik &
Vashist, 2009), facial expression
(Cohn-Kanade)

SL on images
Theoretical analysis: learning using
privileged information

Regression loss

Vapnik &
Izmailov (2015)

SVM with knowledge
transfer (decoupl.)

Multi-task
(Fig. 3)

Various supervised: hinge,
MSE, softmax

Caruana (1997)

NN (simul.)

SL: pneumonia detection

Multi-view
(Fig. 5)

Kernel CCA+soft margin
SVM hinge loss

SVM (simul.)

Evgeniou &
Pontil (2004)
Levine et al.
(2015)
Zhao & Itti
(2015)
Pan & Yang
(2010)
Baxter (2000); Ando & Zhang (2005)
Maurer (2006)

Survey

Conv. NN (simul.)

SL: exam score prediction

One task per school

Conv. NN (decoupl.)

RL on RGB-D: robot manipulation

SL on images (YYY-20M)

Object pose

SL, UL

Theoretical analysis of
multi-task learning

-

-

Farquhar et al.
(2005)
Ngiam et al.
(2011)
Feyereisl &
Aickelin (2012)

Chen et al.
(2014)

D¨ahne et al.
(2014)

Wang et al.
(2015)

Wiskott &
Sejnowski
(2002);
Legenstein et al.
(2010)

Hadsell et al.
(2006)

Weston et al.
(2012)
Watter et al.
(2015)

Sun (2013)
Blum & Mitchell (1998)
Wang & Zhou (2010)

AE reconstruction error

Adjusted rand index,
mutual information

Kernel CCA [+MMD for
domain adaption]

SPoC (non-linear CCA)

CCA+AE reconstruction
error

-
-

Slowness (ﬁrst equation in
Sec. 3.4.1 with
zij = 1{j = i + 1} and
covariance constraints).

Equations in Sec. 3.4.1
with margin-based σ(d)
(see Section 3.4.1)

State predictability
+variational AE

Adapted SVM loss

k-means

UL on images: MNIST

Poetic descriptions

SVM-2K (simul.)

SL on images (PASCAL-VOC)

RBM / NN (simul.)

SL on video/audio (various, e.g.
CUAVE, AVLetters)

Kernel SVM on kernel
descriptor features

Linear/quadratic, ED
(decoupl.)
Deep Canonically
Correlated AE and
others (simul.)
Survey

SL on RGB: gender (EURECOM,
LFW-a), object (RGB-D O.D.,
Catech-256)

SL: Mental state prediction

SL on images (MNIST), speech
(XRMB), word embedding
(WMT2011)
SL, UL
Theoretical analysis of
multi-view learning

Linear/quadratic, ED
(decoupl.)

RL on images: Navigation (physical
simulation)

Time index

Conv. NN, (decoupl.)

UL on images: dimensionality
reduction (MNIST, NORB)

Conv. NN (simul.)

SL on images (MNIST, COIL100)

CNN (simul.)

RL: inverted pendulum, cart-pole,
robot arm

Vapnik &
Vashist (2009)

SVM with similarity
control (simul.)

SL: protein classiﬁcation, ﬁnance
market prediction, digit recognition

Distance metric learning

Hierarchical multi-class
loss

Fouad et al.
(2013)
Silla Jr & Freitas
(2010)

GMLVQ/kNN
(decoupl.)

SL: images (MNIST); galaxy
morphology

Survery on hierarchical classiﬁcation (SL)

Softmax (?)

Hinton et al.
(2011)

NN; transforming AE
(simul.)

SL for pose prediction (MNIST, 3D
simulation)

Relative pose

Pairwise
Similarity
(Fig. 7)

(Fig. 9)

Pairwise
Transforma-
tion
(Fig. 8(a))

(Fig. 8(b))

See (Hadsell et al., 2006)

SL on images (NORB, KITTI, SUN)

(Fig. 8(c))

Softmax

Various

Irrelevance
(Fig. 4)

L ≈ ||ψT β||2
linear, || · ||2
norm.

F , with ψ, β

F Frobenius

Jayaraman &
Grauman (2015)

Siamese-style conv.
NN (simul.)

Agrawal et al.
(2015)

Jonschkowski &
Brock (2015)

Siamese-style conv.
NN
(pre-train/ﬁne-tune)
Linear, SGD
(decoupl.)

SL on images (MNIST, SF, KITTI)

RL: control, navigation,

Romera-Paredes
et al. (2012)

Linear, orthogonal
matrix factorization

SL on images: emotion detection
(JAFFE)

Side Information

Secondary (3D)
structure categories
Holistic image
descriptions, LBP
features from
high-res images

Image sections

Hematocrit, white
blood cell count,
potassium

Image class, object
pose

Keypoint features
(SIFT)

Video/audio

RGB-D

EEG diff. subject

Noisy images,
articulations, 2nd
language
-
-

3D protein structure,
future events, textual
description
Poetic descriptions;
spectral features

Label similarity

Relative pose
(discretized; with
k-means)
Relative pose
(discretized;
uniformly)
Actions, rewards,
time

Subject identity

