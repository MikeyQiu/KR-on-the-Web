8
1
0
2
 
r
a

M
 
9
1
 
 
]
L
M

.
t
a
t
s
[
 
 
2
v
5
3
7
8
0
.
2
0
8
1
:
v
i
X
r
a

Published as a conference paper at ICLR 2018

A DIRT-T APPROACH TO UNSUPERVISED DOMAIN
ADAPTATION

Rui Shu†∗, Hung H. Bui‡, Hirokazu Narui†, & Stefano Ermon†
†Stanford University
‡DeepMind
†

@stanford.edu

‡

ruishu,hirokaz2,ermon
{
@google.com
buih
}
{

}

ABSTRACT

Domain adaptation refers to the problem of leveraging labeled data in a source
domain to learn an accurate model in a target domain where labels are scarce or
unavailable. A recent approach for ﬁnding a common representation of the two
domains is via domain adversarial training (Ganin & Lempitsky, 2015), which
attempts to induce a feature extractor that matches the source and target feature
distributions in some feature space. However, domain adversarial training faces
two critical limitations: 1) if the feature extraction function has high-capacity, then
feature distribution matching is a weak constraint, 2) in non-conservative domain
adaptation (where no single classiﬁer can perform well in both the source and
target domains), training the model to do well on the source domain hurts perfor-
mance on the target domain. In this paper, we address these issues through the lens
of the cluster assumption, i.e., decision boundaries should not cross high-density
data regions. We propose two novel and related models: 1) the Virtual Adver-
sarial Domain Adaptation (VADA) model, which combines domain adversarial
training with a penalty term that punishes violation of the cluster assumption; 2)
the Decision-boundary Iterative Reﬁnement Training with a Teacher (DIRT-T)1
model, which takes the VADA model as initialization and employs natural gradient
steps to further minimize the cluster assumption violation. Extensive empirical re-
sults demonstrate that the combination of these two models signiﬁcantly improve
the state-of-the-art performance on the digit, trafﬁc sign, and Wi-Fi recognition
domain adaptation benchmarks.

1

INTRODUCTION

The development of deep neural networks has enabled impressive performance in a wide variety of
machine learning tasks. However, these advancements often rely on the existence of a large amount
of labeled training data. In many cases, direct access to vast quantities of labeled data for the task
of interest (the target domain) is either costly or otherwise absent, but labels are readily available
for related training sets (the source domain). A notable example of this scenario occurs when the
source domain consists of richly-annotated synthetic or semi-synthetic data, but the target domain
consists of unannotated real-world data (Sun & Saenko, 2014; Vazquez et al., 2014). However, the
source data distribution is often dissimilar to the target data distribution, and the resulting signiﬁcant
covariate shift is detrimental to the performance of the source-trained model when applied to the
target domain (Shimodaira, 2000).

Solving the covariate shift problem of this nature is an instance of domain adaptation (Ben-David
et al., 2010b). In this paper, we consider a challenging setting of domain adaptation where 1) we
are provided with fully-labeled source samples and completely-unlabeled target samples, and 2) the
existence of a classiﬁer in the hypothesis space with low generalization error in both source and
target domains is not guaranteed. Borrowing approximately the terminology from Ben-David et al.
(2010b), we refer to this setting as unsupervised, non-conservative domain adaptation. We note

∗Work was done during ﬁrst author’s internship at Adobe Research.
1Pronounce as “dirty.” Implementation available at https://github.com/RuiShu/dirt-t

1

Published as a conference paper at ICLR 2018

that this is in contrast to conservative domain adaptation, where we assume our hypothesis space
contains a classiﬁer that performs well in both the source and target domains.

To tackle unsupervised domain adaptation, Ganin & Lempitsky (2015) proposed to constrain the
classiﬁer to only rely on domain-invariant features. This is achieved by training the classiﬁer to
perform well on the source domain while minimizing the divergence between features extracted
from the source versus target domains. To achieve divergence minimization, Ganin & Lempitsky
(2015) employ domain adversarial training. We highlight two issues with this approach: 1) when the
feature function has high-capacity and the source-target supports are disjoint, the domain-invariance
constraint is potentially very weak (see Section 3), and 2) good generalization on the source domain
hurts target performance in the non-conservative setting.

Saito et al. (2017) addressed these issues by replacing domain adversarial training with asymmetric
tri-training (ATT), which relies on the assumption that target samples that are labeled by a source-
trained classiﬁer with high conﬁdence are correctly labeled by the source classiﬁer. In this paper,
we consider an orthogonal assumption: the cluster assumption (Chapelle & Zien, 2005), that the
input distribution contains separated data clusters and that data samples in the same cluster share the
same class label. This assumption introduces an additional bias where we seek decision boundaries
that do not go through high-density regions. Based on this intuition, we propose two novel mod-
els: 1) the Virtual Adversarial Domain Adaptation (VADA) model which incorporates an additional
virtual adversarial training (Miyato et al., 2017) and conditional entropy loss to push the decision
boundaries away from the empirical data, and 2) the Decision-boundary Iterative Reﬁnement Train-
ing with a Teacher (DIRT-T) model which uses natural gradients to further reﬁne the output of the
VADA model while focusing purely on the target domain. We demonstrate that

1. In conservative domain adaptation, where the classiﬁer is trained to perform well on the
source domain, VADA can be used to further constrain the hypothesis space by penalizing
violations of the cluster assumption, thereby improving domain adversarial training.

2. In non-conservative domain adaptation, where we account for the mismatch between the
source and target optimal classiﬁers, DIRT-T allows us to transition from a joint (source and
target) classiﬁer (VADA) to a better target domain classiﬁer. Interestingly, we demonstrate
the advantage of natural gradients in DIRT-T reﬁnement steps.

We report results for domain adaptation in digits classiﬁcation (MNIST-M, MNIST, SYN DIGITS,
SVHN), trafﬁc sign classiﬁcation (SYN SIGNS, GTSRB), general object classiﬁcation (STL-10,
CIFAR-10), and Wi-Fi activity recognition (Youseﬁ et al., 2017). We show that, in nearly all experi-
ments, VADA improves upon previous methods and that DIRT-T improves upon VADA, setting new
state-of-the-art performances across a wide range of domain adaptation benchmarks. In adapting
MNIST

SVHN, a very challenging task, we out-perform ATT by over 20%.

→

2 RELATED WORK

Given the extensive literature on domain adaptation, we highlight several works most relevant to
our paper. Shimodaira (2000); Mansour et al. (2009) proposed to correct for covariate shift by
re-weighting the source samples such that the discrepancy between the target distribution and re-
weighted source distribution is minimized. Such a procedure is problematic, however, if the source
and target distributions do not contain sufﬁcient overlap. Huang et al. (2007); Long et al. (2015);
Ganin & Lempitsky (2015) proposed to instead project both distributions into some feature space
and encourage distribution matching in the feature space. Ganin & Lempitsky (2015) in particular
encouraged feature matching via domain adversarial training, which corresponds approximately
to Jensen-Shannon divergence minimization (Goodfellow et al., 2014). To better perform non-
conservative domain adaptation, Saito et al. (2017) proposed to modify tri-training (Zhou & Li,
2005) for domain adaptation, leveraging the assumption that highly-conﬁdent predictions are cor-
rect predictions (Zhu, 2005). Several of aforementioned methods are based on Ben-David et al.
(2010a)’s theoretical analysis of domain adaptation, which states the following,

2

Published as a conference paper at ICLR 2018

Theorem 1 (Ben-David et al., 2010a) Let
H
be the two domains and their corresponding generalization error functions. Then for any h

be the hypothesis space and let (Xs, (cid:15)s) and (Xt, (cid:15)t)

,

(cid:15)t(h)

1
2

≤

dH∆H(Xs, Xt) + (cid:15)s(h) + min
h(cid:48)∈H

(cid:15)t(h(cid:48)) + (cid:15)s(h(cid:48)),

where dH∆H denotes the

∆

H
dH∆H = 2 sup

H

h,h(cid:48)∈H |

-distance between the domains Xs and Xt,
= h(cid:48)(x)]

Ex∼Xs [h(x)

Ex∼Xt [h(x)

−

= h(cid:48)(x)]
|

.

∈ H

(1)

(2)

Intuitively, dH∆H measures the extent to which small changes to the hypothesis in the source domain
can lead to large changes in the target domain. It is evident that dH∆H relates intimately to the
complexity of the hypothesis space and the divergence between the source and target domains. For
inﬁnite-capacity models and domains with disjoint supports, dH∆H is maximal.

A critical component to our paper is the cluster assumption, which states that decision boundaries
should not cross high-density regions (Chapelle & Zien, 2005). This assumption has been exten-
sively studied and leveraged for semi-supervised learning, leading to proposals such as conditional
entropy minimization (Grandvalet & Bengio, 2005) and pseudo-labeling (Lee, 2013). More recently,
the cluster assumption has led to many successful deep semi-supervised learning algorithms such as
semi-supervised generative adversarial networks (Dai et al., 2017), virtual adversarial training (Miy-
ato et al., 2017), and self/temporal-ensembling (Laine & Aila, 2016; Tarvainen & Valpola, 2017).
Given the success of the cluster assumption in semi-supervised learning, it is natural to consider
its application to domain adaptation. Indeed, Ben-David & Urner (2014) formalized the cluster as-
sumption through the lens of probabilistic Lipschitzness and proposed a nearest-neighbors model
for domain adaptation. Our work extends this line of research by showing that the cluster assump-
tion can be applied to deep neural networks to solve complex, high-dimensional domain adaptation
problems. Independently of our work, French et al. (2017) demonstrated the application of self-
ensembling to domain adaptation. However, our work additionally considers the application of the
cluster assumption to non-conservative domain adaptation.

3 LIMITATION OF DOMAIN ADVERSARIAL TRAINING

◦

−

X → Z

1)-simplex (denote as

and embedding classiﬁer gθ :

Before describing our model, we ﬁrst highlight that domain adversarial training may not be sufﬁcient
for domain adaptation if the feature extraction function has high-capacity. Consider a classiﬁer hθ,
parameterized by θ, that maps inputs to the (K
), where K is the number
of classes. Suppose the classiﬁer h = g
f can be decomposed as the composite of an embedding
function fθ :
Ds be
Z → C
the joint distribution over input x and one-hot label y and let Xs be the marginal input distribution.
Dt, Xt) are analogously deﬁned for the target domain. Let (
(
Ls,
Ds) = Ex,y∼Ds
Dt) = sup
where the supremum ranges over discriminators D :
objective and D is a domain discriminator. Domain adversarial training minimizes the objective

Ex∼Ds [ln D(fθ(x))] + Ex∼Dt [ln(1

Ld) be the loss functions

Ly is the cross-entropy

. For the source domain, let

(cid:2)y(cid:62) ln hθ(x)(cid:3)

Ly(θ;
Ds,

D(fθ(x)))] ,

(0, 1). Then

Ld(θ;

Z →

(4)

(3)

−

C

D

θ Ly(θ;
min.

Ds) + λdLd(θ;

Ds,

Dt),

(5)

Ld encourages the learning of a feature extractor f
where λd is a weighting factor. Minimization of
for which the Jensen-Shannon divergence between f (Xs) and f (Xt) is small.2 Ganin & Lempitsky
(2015) suggest that successful adaptation tends to occur when the source generalization error and
feature divergence are both small.

It is easy, however, to construct situations where this suggestion fails. In particular, if f has inﬁnite-
capacity and the source-target supports are disjoint, then f can employ arbitrary transformations to
the target domain so as to match the source feature distribution (see Appendix E for formalization).

2In practice, the minimization of Ld requires solving a mini-max optimization problem. We discuss this in

more detail in Appendix C

3

Published as a conference paper at ICLR 2018

We verify empirically that, for sufﬁciently deep layers, jointly achieving small source generalization
error and feature divergence does not imply high accuracy on the target task (Table 5). Given the
limitations of domain adversarial training, we wish to identify additional constraints that one can
place on the model to achieve better, more reliable domain adaptation.

4 CONSTRAINING VIA CONDITIONAL ENTROPY MINIMIZATION

Figure 1: VADA improves upon domain adversarial training by additionally penalizing violations
of the cluster assumption.

In this paper, we apply the cluster assumption to domain adaptation. The cluster assumption states
that the input distribution X contains clusters and that points in the same cluster come from the same
class. This assumption has been extensively studied and applied successfully to a wide range of
classiﬁcation tasks (see Section 2). If the cluster assumption holds, the optimal decision boundaries
should occur far away from data-dense regions in the space of
(Chapelle & Zien, 2005). Following
Grandvalet & Bengio (2005), we achieve this behavior via minimization of the conditional entropy
with respect to the target distribution,

X

Lc(θ;

Dt) =

−

Ex∼Dt

(cid:2)hθ(x)(cid:62) ln hθ(x)(cid:3) .

Intuitively, minimizing the conditional entropy forces the classiﬁer to be conﬁdent on the unlabeled
target data, thus driving the classiﬁer’s decision boundaries away from the target data (Grandvalet
& Bengio, 2005).
In practice, the conditional entropy must be empirically estimated using the
available data. However, Grandvalet & Bengio (2005) note that this approximation breaks down
if the classiﬁer h is not locally-Lipschitz. Without the locally-Lipschitz constraint, the classiﬁer is
allowed to abruptly change its prediction in the vicinity of the training data points, which 1) results
in a unreliable empirical estimate of conditional entropy and 2) allows placement of the classiﬁer
decision boundaries close to the training samples even when the empirical conditional entropy is
minimized. To prevent this, we propose to explicitly incorporate the locally-Lipschitz constraint via
virtual adversarial training (Miyato et al., 2017) and add to the objective function the additional term

(cid:20)

Lv(θ;

D

) = Ex∼D

max
(cid:107)r(cid:107)≤(cid:15)

DKL(hθ(x)

(cid:21)
hθ(x + r))
(cid:107)

,

which enforces classiﬁer consistency within the norm-ball neighborhood of each sample x. Note that
virtual adversarial training can be applied with respect to either the target or source distributions. We
can combine the conditional entropy minimization objective and domain adversarial training to yield
Dt) + λsLv(θ;
a basic combination of domain adversarial training and semi-supervised training objectives. We
refer to this as the Virtual Adversarial Domain Adaptation (VADA) model. Empirically, we ob-
served that the hyperparameters (λd, λs, λt) are easy to choose and work well across multiple tasks
(Appendix B).

Ds) + λdLd(θ;

θ Ly(θ;
min.

Ds) + λt [

Dt) +

Lv(θ;

Lc(θ;

Dt)] ,

Ds,

(8)

∆

-Distance Minimization. VADA aligns well with the theory of domain adaptation provided

H
in Theorem 1. Let the loss,

H

(6)

(7)

(9)

Lt(θ) =

Lv(θ;

Dt) +

Lc(θ; Dt),

4

Published as a conference paper at ICLR 2018

denote the degree to which the target-side cluster assumption is violated. Modulating λt enables
VADA to trade-off between hypotheses with low target-side cluster assumption violation and hy-
potheses with low source-side generalization error. Setting λt > 0 allows rejection of hypotheses
with high target-side cluster assumption violation. By rejecting such hypotheses from the hypothesis
, VADA reduces dH∆H and yields a tighter bound on the target generalization error. We
space
verify empirically that VADA achieves signiﬁcant improvements over existing models on multiple
domain adaptation benchmarks (Table 1).

H

5 DECISION-BOUNDARY ITERATIVE REFINEMENT TRAINING

Figure 2: DIRT-T uses VADA as initialization. After removing the source training signal, DIRT-
T minimizes cluster assumption violation in the target domain through a series of natural gradient
steps.

In non-conservative domain adaptation, we assume the following inequality,

(cid:15)t(h) < (cid:15)t(ha) where ha = arg min

(cid:15)s(h) + (cid:15)t(h),

(10)

min
h∈H

h∈H

where ((cid:15)s, (cid:15)t) are generalization error functions for the source and target domains. This means that,
for a given hypothesis class
, the optimal classiﬁer in the source domain does not coincide with
the optimal classiﬁer in the target domain.

H

We assume that the optimality gap in Eq. (10) results from violation of the cluster assumption.
In other words, we suppose that any source-optimal classiﬁer drawn from our hypothesis space
necessarily violates the cluster assumption in the target domain. Insofar as VADA is trained on the
source domain, we hypothesize that a better hypothesis is achievable by introducing a secondary
training phase that solely minimizes the target-side cluster assumption violation.

Under this assumption, the natural solution is to initialize with the VADA model and then further
minimize the cluster assumption violation in the target domain. In particular, we ﬁrst use VADA
to learn an initial classiﬁer hθ0 . Next, we incrementally push the classiﬁer’s decision boundaries
away from data-dense regions by minimizing the target-side cluster assumption violation loss
Lt in
Eq. (9). We denote this procedure Decision-boundary Iterative Reﬁnement Training (DIRT).

5.1 DECISION-BOUNDARY ITERATIVE REFINEMENT TRAINING WITH A TEACHER

Stochastic gradient descent minimizes the loss
following objective,

Lt by selecting gradient steps ∆θ according to the

∆θ Lt(θ + ∆θ)
min.
∆θ
s.t.
(cid:15),

(cid:107)

(cid:107) ≤

5

(11)

(12)

Published as a conference paper at ICLR 2018

which deﬁnes the neighborhood in the parameter space. This notion of neighborhood is sensitive
to the parameterization of the model; depending on the parameterization, a seemingly small step
∆θ may result in a vastly different classiﬁer. This contradicts our intention of incrementally and
locally pushing the decision boundaries to a local conditional entropy minimum, which requires
that the decision boundaries of hθ+∆θ stay close to that of hθ. It is therefore important to deﬁne a
neighborhood that is parameterization-invariant. Following Pascanu & Bengio (2013), we instead
select ∆θ using the following objective,

∆θ Lt(θ + ∆θ)
min.
s.t. Ex∼Dt [DKL(hθ(x)
hθ+∆θ(x))]
(cid:107)

(13)
Each optimization step now solves for a gradient step ∆θ that minimizes the conditional entropy,
subject to the constraint that the Kullback-Leibler divergence between hθ(x) and hθ+∆θ(x) is small
∼ Xt. The corresponding Lagrangian suggests that one can instead minimize a sequence of
for x
optimization problems

≤

(cid:15).

min.
θn

λtLt(θn) + βtE (cid:2)DKL(hθn−1(x)

hθn (x))(cid:3) ,
(cid:107)

(14)

that approximates the application of a series of natural gradient steps.

In practice, each of the optimization problems in Eq. (14) can be solved approximately via a ﬁnite
number of stochastic gradient descent steps. We denote the number of steps taken to be the reﬁne-
ment interval B. Similar to Tarvainen & Valpola (2017), we use the Adam Optimizer with Polyak
averaging (Polyak & Juditsky, 1992). We interpret hθn−1 as a (sub-optimal) teacher for the student
model hθn, which is trained to stay close to the teacher model while seeking to reduce the cluster
assumption violation. As a result, we denote this model as Decision-boundary Iterative Reﬁnement
Training with a Teacher (DIRT-T).

Weakly-Supervised Learning. This sequence of optimization problems has a natural interpretation
that exposes a connection to weakly-supervised learning. In each optimization problem, the teacher
model hθn−1 pseudo-labels the target samples with noisy labels. Rather than naively training the
student model hθn on the noisy labels, the additional training signal
Lt allows the student model to
place its decision boundaries further from the data. If the clustering assumption holds and the initial
noisy labels are sufﬁciently similar to the true labels, conditional entropy minimization can improve
the placement of the decision boundaries (Reed et al., 2014).

Domain Adaptation. An alternative interpretation is that DIRT-T is the recursive extension of
VADA, where the act of pseudo-labeling of the target distribution constructs a new “source” domain
(i.e. target distribution Xt with pseudo-labels). The sequence of optimization problems can then
be seen as a sequence of non-conservative domain adaptation problems in which Xs = Xt but
ps(y
x) is the true conditional label
|
distribution in the target domain. Since dH∆H is strictly zero in this sequence of optimization
problems, domain adversarial training is no longer necessary. Furthermore, if
Lt minimization does
improve the student classiﬁer, then the gap in Eq. (10) should get smaller each time the source
domain is updated.

x) = hθn−1(x) and pt(y

x), where ps(y

= pt(y

x)

|

|

|

6 EXPERIMENTS

In principle, our method can be applied to any domain adaptation tasks so long as one can deﬁne a
reasonable notion of neighborhood for virtual adversarial training (Miyato et al., 2016). For com-
parison against Saito et al. (2017) and French et al. (2017), we focus on visual domain adaptation
and evaluate on MNIST, MNIST-M, Street View House Numbers (SVHN), Synthetic Digits (SYN
DIGITS), Synthetic Trafﬁc Signs (SYN SIGNS), the German Trafﬁc Signs Recognition Benchmark
(GTSRB), CIFAR-10, and STL-10. For non-visual domain adaptation, we evaluate on Wi-Fi activity
recognition.

6.1

IMPLEMENTATION DETAIL

Architecture We use a small CNN for the digits, trafﬁc sign, and Wi-Fi domain adaptation exper-
iments, and a larger CNN for domain adaptation between CIFAR-10 and STL-10. Both architec-
tures are available in Appendix A. For fair comparison, we additionally report the performance of

6

Published as a conference paper at ICLR 2018

source-only baseline models and demonstrate that the signiﬁcant improvements are attributable to
our proposed method.

Replacing gradient reversal. In contrast to Ganin & Lempitsky (2015), which proposed to im-
plement domain adversarial training via gradient reversal, we follow Goodfellow et al. (2014) and
instead optimize via alternating updates to the discriminator and encoder (see Appendix C).

Instance normalization. We explored the application of instance normalization as an image pre-
processing step. This procedure makes the classiﬁer invariant to channel-wide shifts and rescaling
of pixel intensities. A discussion of instance normalization for domain adaptation is provided in
Appendix D. We show in Figure 3 the effect of applying instance normalization to the input image.

Figure 3: Effect of applying instance normalization to the input image.
In clockwise direction:
MNIST-M, GTSRB, SVHN, and CIFAR-10. In each quadrant, the top row is the original image,
and the bottom row is the instance-normalized image.

Hyperparameters. For each task, we tuned the four hyperparameters (λd, λs, λt, β) by randomly
selecting 1000 labeled target samples from the training set and using that as our validation set. We
observed that extensive hyperparameter-tuning is not necessary to achieve state-of-the-art perfor-
mance. In all experiments with instance-normalized inputs, we restrict our hyperparameter search
. We ﬁxed β = 10−2. Note that
for each task to λd =
, λt =
{
the decision to turn (λd, λs) on or off that can often be determined a priori. A complete list of the
hyperparameters is provided in Appendix B.

10−2, 10−1
{

0, 10−2

0, 1
}

, λs =

}

{

}

6.2 MODEL EVALUATION

Source
SVHN
MNIST
Target MNIST-M MNIST

MNIST
SVHN

DIGITS
SVHN

SIGNS
GTSRB

CIFAR
STL

STL
CIFAR

MMD (Long et al., 2015)
DANN (Ganin & Lempitsky, 2015)
DRCN (Ghifary et al., 2016)
DSN (Bousmalis et al., 2016b)
kNN-Ad (Sener et al., 2016)
PixelDA (Bousmalis et al., 2016a)
ATT (Saito et al., 2017)
Π-model (aug) (French et al., 2017)

Source-Only
VADA
DIRT-T

Source-Only
VADA
DIRT-T

Without Instance-Normalized Input:

76.9
81.5
-
83.2
86.7
98.2
94.2
-

58.5
97.7
98.9

59.9
95.7
98.7

71.1
71.1
82.0
82.7
78.8
-
86.2
92.0

77.0
97.9
99.4

82.4
94.5
99.4

-
35.7
40.1
-
40.3
-
52.8
71.4

27.9
47.5
54.5

40.9
73.3
76.5

88.0
90.3
-
91.2
-
-
92.9
94.2

86.9
94.8
96.1

88.6
94.9
96.2

91.1
88.7
-
93.1
-
-
96.2
98.4

79.6
98.8
99.5

86.2
99.2
99.6

-
-
66.4
-
-
-
-
76.3

76.3
80.0
-

77.0
78.3
-

-
-
58.7
-
-
-
-
64.2

63.6
73.5
75.3

62.6
71.4
73.3

With Instance-Normalized Input:

Table 1: Test set accuracy on visual domain adaptation benchmarks. In all settings, both VADA and
DIRT-T achieve state-of-the-art performance in all settings.

MNIST
constructed by blending MNIST digits with random color patches from the BSDS500 dataset.

MNIST-M. We ﬁrst evaluate the adaptation from MNIST to MNIST-M. MNIST-M is

→

↔

MNIST
SVHN. The distribution shift is exacerbated when adapting between MNIST and SVHN.
Whereas MNIST consists of black-and-white handwritten digits, SVHN consists of crops of colored,
street house numbers. Because MNIST has a signiﬁcantly lower intrinsic dimensionality that SVHN,
SVHN is especially challenging when the input is not pre-processed
the adaptation from MNIST

→

7

Published as a conference paper at ICLR 2018

via instance normalization. When instance normalization is applied, we achieve a strong state-of-
the-art performance 76.5% and an equally impressive margin-of-improvement over source-only of
35.6%. Interestingly, by reducing the reﬁnement interval B and taking noisier natural gradient steps,
we were occasionally able to achieve accuracies as high as 87%. However, due to the high-variance
associated with this, we omit reporting this conﬁguration in Table 1.

SVHN. The adaptation from SYN DIGITS

SYN DIGITS
SVHN reﬂect a common adaptation
problem of transferring from synthetic images to real images. The SYN DIGITS dataset consist of
500000 images generated from Windows fonts by varying the text, positioning, orientation, back-
ground, stroke color, and the amount of blur.

→

→

SYN SIGNS
thetic images to real images. Unlike SYN DIGITS
classes instead of 10.

GTSRB. This setting provides an additional demonstration of adapting from syn-
GTSRB contains 43

SVHN, SYN SIGNS

→

→

→

↔

STL
CIFAR. Both STL-10 and CIFAR-10 are 10-class image datasets. These two datasets
contain nine overlapping classes. Following the procedure in French et al. (2017), we removed the
non-overlapping classes (“frog” and “monkey”) and reduce to a 9-class classiﬁcation problem. We
achieve state-of-the-art performance in both adaptation directions. In STL
CIFAR, we achieve a
11.7% margin-of-improvement and a performance accuracy of 73.3%. Note that because STL-10
contains a very small training set, it is difﬁcult to estimate the conditional entropy, thus making
DIRT-T unreliable for CIFAR

STL.

→

→

Source
Target

Room A
Room B

With Instance-Normalized Input:

Source-Only
DANN
VADA
DIRT-T

35.7
38.0
53.0
53.0

Table 2: Results of the domain adaptation experiments on Wi-Fi Activity Recognition Task

Wi-Fi Activity Recognition. To evaluate the performance of our models on a non-visual domain
adaptation task, we applied VADA and DIRT-T to the Wi-Fi Activity Recognition Dataset (Youseﬁ
et al., 2017). The Wi-Fi Activity Recognition Dataset is a classiﬁcation task that takes the Wi-
Fi Channel State Information (CSI) data stream as input x to predict motion activity within an
indoor area as output y. Domain adaptation is necessary when the training and testing data are
collected from different rooms, which we denote as Rooms A and B. Table 2 shows that VADA
signiﬁcantly improves classiﬁcation accuracy compared to Source-Only and DANN by 17.3% and
15% respectively. However, DIRT-T does not lead to further improvements on this dataset. We
perform experiments in Appendix F which suggests that VADA already achieves strong clustering in
the target domain for this dataset, and therefore DIRT-T is not expected to yield further performance
improvement.

Source
SVHN
MNIST
Target MNIST-M MNIST

MNIST
SVHN

DIGITS
SVHN

SIGNS
GTSRB

CIFAR
STL

STL
CIFAR

ATT
Π-model (aug)
DIRT-T
DIRT-T (W.I.N.I.)

37.1
-
40.4
38.8

16.1
3.7
22.4
17.0

17.9
18.1
26.6
35.6

9.0
10.6
9.2
7.6

20.5
1.0
19.9
13.4

-
4.5
-
-

-
7.4
11.7
10.7

Table 3: Additional comparison of the margin of improvement computed by taking the reported
performance of each model and subtracting the reported source-only performance in the respective
papers. W.I.N.I. indicates “with instance-normalized input.”

Overall. We achieve state-of-the-art results across all tasks. For a fairer comparison against ATT
and the Π-model, Table 3 provides the improvement margin over the respective source-only per-
formance reported in each paper. In four of the tasks (MNIST
MNIST,
MNIST
CIFAR), we achieve substantial margin of improvement compared to
previous models. In the remaining three tasks, our improvement margin over the source-only model

MNIST-M, SVHN

SVHN, STL

→

→

→

→

8

Published as a conference paper at ICLR 2018

is competitive against previous models. Our closest competitor is the Π-model. However, unlike the
Π-model, we do not perform data augmentation.

It is worth noting that DIRT-T consistently improves upon VADA. Since DIRT-T operates by in-
crementally pushing the decision boundaries away from the target domain data, it relies heavily
on the cluster assumption. DIRT-T’s empirical success therefore demonstrates the effectiveness of
leveraging the cluster assumption in unsupervised domain adaptation with deep neural networks.

6.3 ANALYSIS OF VADA AND DIRT-T

6.3.1 ROLE OF VIRTUAL ADVERSARIAL TRAINING

To study the relative contribution of the virtual adversarial training in the VADA and DIRT-T ob-
jectives (Eq. (8) and Eq. (14) respectively), we perform an extensive ablation analysis in Table 4.
The removal of the virtual adversarial training component is denoted by the “no-vat” subscript. Our
results show that VADAno-vat is sufﬁcient for out-performing DANN in all but one task. The further
ability for DIRT-Tno-vat to improve upon VADAno-vat demonstrates the effectiveness of conditional
entropy minimization. Ultimately, in six of the seven tasks, both virtual adversarial training and
conditional entropy minimization are essential for achieving the best performance. The empirical
importance of incorporating virtual adversarial training shows that the locally-Lipschitz constraint
is beneﬁcial for pushing the classiﬁer decision boundaries away from data.

SVHN
MNIST
Source
Target MNIST-M MNIST

MNIST
SVHN

DIGITS
SVHN

SIGNS
GTSRB

CIFAR
STL

STL
CIFAR

With Instance-Normalized Input:

Source-Only
DANN (our implementation)

VADAno-vat
VADAno-vat → DIRT-Tno-vat
VADAno-vat → DIRT-T

VADA
VADA → DIRT-T

59.9
94.6

93.8
94.8
98.3

95.7
98.7

82.4
68.3

83.1
96.3
99.4

94.5
99.4

40.9
60.6

66.8
68.6
69.8

73.3
76.5

88.6
90.1

93.4
94.4
95.3

94.9
96.2

86.2
97.5

98.4
99.1
99.6

99.2
99.6

77.0
78.1

79.1
-
-

78.3
-

62.6
62.7

68.6
69.2
71.0

71.4
73.3

Table 4: Test set accuracy in ablation experiments, starting from the DANN model. The “no-vat”
subscript denote models where the virtual adversarial training component is removed.

6.3.2 ROLE OF TEACHER MODEL IN DIRT-T

(a) SVHN → MNIST

(b) STL → CIFAR

9

Figure 4: Comparing model behavior with and without the application of the KL-term. At iteration
0, we begin with the VADA initialization and apply the DIRT-T algorithm.

Published as a conference paper at ICLR 2018

When considering Eq. (14), it is natural to ask whether deﬁning the neighborhood with respect to the
classiﬁer is truly necessary. In Figure 4, we demonstrate in SVHN
CIFAR
that removal of the KL-term negatively impacts the model. Since the MNIST data manifold is
low-dimensional and contains easily identiﬁable clusters, applying naive gradient descent (Eq. (12))
can also boost the test accuracy during initial training. However, without the KL constraint, the
classiﬁer can sometimes deviate signiﬁcantly from the neighborhood of the previous classiﬁer, and
the resulting spikes in the KL-term correspond to sharp drops in target test accuracy. In STL
→
CIFAR, where the data manifold is much more complex and contains less obvious clusters, naive
gradient descent causes immediate decline in the target test accuracy.

MNIST and STL

→

→

6.3.3 VISUALIZATION OF REPRESENTATION

(a) Source-Only

(b) VADA

(c) DIRT-T

Figure 5: T-SNE plot of the last hidden layer for MNIST (blue)
without instance normalization to highlight the further improvement that DIRT-T provides.

SVHN (red). We used the model

→

We further analyze the behavior of VADA and DIRT-T by showing T-SNE embeddings of the last
hidden layer of the model trained to adapt from MNIST
SVHN. In Figure 5, source-only train-
ing shows strong clustering of the MNIST samples (blue) and performs poorly on SVHN (red).
VADA offers signiﬁcant improvement and exhibits signs of clustering on SVHN. DIRT-T begins
with the VADA initialization and further enhances the clustering, resulting in the best performance
on MNIST

SVHN.

→

6.4 DOMAIN ADVERSARIAL TRAINING: LAYER ABLATION

→

Layer

L − 0
L − 1
L − 2
L − 3
L − 4
L − 5
L − 6
L − 7

DANN
JSD ≥ Source Accuracy

Target Accuracy

VADA
JSD ≥ Source Accuracy

Target Accuracy

0.001
0.002
0.353
0.036
0.012
0.235
0.486
0.644

78.0
98.6
16.4
94.8
97.0
99.3
99.2
99.0

24.7
35.0
10.3
33.8
40.0
57.9
60.3
52.5

0.001
0.007
0.383
0.034
0.020
0.244
0.509
0.608

24.9
12.0
11.5
67.8
96.8
99.4
99.3
99.1

18.4
11.6
9.9
37.1
61.5
73.3
70.4
70.5

Table 5: Comparison of model behavior when domain adversarial training is applied to various
layers. We denote the very last (simplex) layer of the neural network as L and ablatively domain
adversarial training to the last eight layers. A lower bound on the Jensen-Shannon Divergence is
computed by training a logistic regression model to predict domain origin when given the layer
embeddings.

−

2 and L

In Table 5, we applied domain adversarial training to various layers of a Domain Adversarial Neu-
ral Network (Ganin & Lempitsky, 2015) trained to adapt MNIST
SVHN. With the exception
0, which experienced training instability, the general observation is that
of layers L
as the layer gets deeper, the additional capacity of the corresponding embedding function allows
better matching of the source and target distributions without hurting source generalization accu-
racy. This demonstrates that the combination of low divergence and high source accuracy does not
imply better adaptation to the target domain. Interestingly, when the classiﬁer is regularized to be
locally-Lipschitz via VADA, the combination of low divergence and high source accuracy appears
to correlate more strongly with better adaptation.

→

−

10

Published as a conference paper at ICLR 2018

7 CONCLUSION

In this paper, we presented two novel models for domain adaptation inspired by the cluster as-
sumption. Our ﬁrst model, VADA, performs domain adversarial training with an added term that
penalizes violations of the cluster assumption. Our second model, DIRT-T, is an extension of VADA
that recursively reﬁnes the VADA classiﬁer by untethering the model from the source training signal
and applying approximate natural gradients to further minimize the cluster assumption violation.
Our experiments demonstrate the effectiveness of the cluster assumption: VADA achieves strong
performance across several domain adaptation benchmarks, and DIRT-T further improves VADA
performance. Our proposed models open up several possibilities for future work. One possibility is
to apply DIRT-T to weakly supervised learning; another is to improve the natural gradient approx-
imation via K-FAC (Martens & Grosse, 2015) and PPO (Schulman et al., 2017). Given the strong
performance of our models, we also recommend them for other downstream domain adaptation
applications.

We gratefully acknowledge funding from Adobe, NSF (grants #1651565, #1522054, #1733686),
Toyota Research Institute, Future of Life Institute, and Intel. We also thank Daniel Levy, Shengjia
Zhao, and Jiaming Song for insightful discussions, and the anonymous reviewers for their helpful
comments and suggestions.

ACKNOWLEDGMENTS

REFERENCES

Shai Ben-David and Ruth Urner. Domain adaptation–can quantity compensate for quality? Annals

of Mathematics and Artiﬁcial Intelligence, 70(3):185–202, 2014.

Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wort-
man Vaughan. A theory of learning from different domains. Machine learning, 79(1):151–175,
2010a.

Shai Ben-David, Tyler Lu, Teresa Luu, and D´avid P´al. Impossibility theorems for domain adap-
tation. In Proceedings of the Thirteenth International Conference on Artiﬁcial Intelligence and
Statistics, pp. 129–136, 2010b.

Konstantinos Bousmalis, Nathan Silberman, David Dohan, Dumitru Erhan, and Dilip Krishnan.
Unsupervised pixel-level domain adaptation with generative adversarial networks. arXiv preprint
arXiv:1612.05424, 2016a.

Konstantinos Bousmalis, George Trigeorgis, Nathan Silberman, Dilip Krishnan, and Dumitru Erhan.
Domain separation networks. In Advances in Neural Information Processing Systems, pp. 343–
351, 2016b.

Olivier Chapelle and Alexander Zien. Semi-supervised classiﬁcation by low density separation. In

AISTATS, pp. 57–64, 2005.

Zihang Dai, Zhilin Yang, Fan Yang, William W Cohen, and Ruslan Salakhutdinov. Good semi-

supervised learning that requires a bad gan. arXiv preprint arXiv:1705.09783, 2017.

William Fedus, Mihaela Rosca, Balaji Lakshminarayanan, Andrew M Dai, Shakir Mohamed, and
Ian Goodfellow. Many paths to equilibrium: Gans do not need to decrease adivergence at every
step. arXiv preprint arXiv:1710.08446, 2017.

Geoffrey French, Michal Mackiewicz, and Mark Fisher. Self-ensembling for domain adaptation.

arXiv preprint arXiv:1706.05208, 2017.

Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In

International Conference on Machine Learning, pp. 1180–1189, 2015.

Muhammad Ghifary, W Bastiaan Kleijn, Mengjie Zhang, David Balduzzi, and Wen Li. Deep
In European Con-

reconstruction-classiﬁcation networks for unsupervised domain adaptation.
ference on Computer Vision, pp. 597–613. Springer, 2016.

11

Published as a conference paper at ICLR 2018

Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural infor-
mation processing systems, pp. 2672–2680, 2014.

Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In Ad-

vances in neural information processing systems, pp. 529–536, 2005.

Jiayuan Huang, Arthur Gretton, Karsten M Borgwardt, Bernhard Sch¨olkopf, and Alex J Smola.
Correcting sample selection bias by unlabeled data. In Advances in neural information processing
systems, pp. 601–608, 2007.

Samuli Laine and Timo Aila. Temporal ensembling for semi-supervised learning. arXiv preprint

arXiv:1610.02242, 2016.

Dong-Hyun Lee. Pseudo-label: The simple and efﬁcient semi-supervised learning method for deep
neural networks. In Workshop on Challenges in Representation Learning, ICML, volume 3, pp.
2, 2013.

Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. Learning transferable features with
deep adaptation networks. In International Conference on Machine Learning, pp. 97–105, 2015.

Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh. Domain adaptation: Learning bounds

and algorithms. arXiv preprint arXiv:0902.3430, 2009.

James Martens and Roger Grosse. Optimizing neural networks with kronecker-factored approximate

curvature. In International Conference on Machine Learning, pp. 2408–2417, 2015.

Takeru Miyato, Andrew M Dai, and Ian Goodfellow. Virtual adversarial training for semi-supervised

text classiﬁcation. stat, 1050:25, 2016.

Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual adversarial train-
arXiv preprint

ing: a regularization method for supervised and semi-supervised learning.
arXiv:1704.03976, 2017.

Razvan Pascanu and Yoshua Bengio. Revisiting natural gradient for deep networks. arXiv preprint

arXiv:1301.3584, 2013.

Boris T Polyak and Anatoli B Juditsky. Acceleration of stochastic approximation by averaging.

SIAM Journal on Control and Optimization, 30(4):838–855, 1992.

Scott Reed, Honglak Lee, Dragomir Anguelov, Christian Szegedy, Dumitru Erhan, and Andrew
Rabinovich. Training deep neural networks on noisy labels with bootstrapping. arXiv preprint
arXiv:1412.6596, 2014.

Kuniaki Saito, Yoshitaka Ushiku, and Tatsuya Harada. Asymmetric tri-training for unsupervised

domain adaptation. arXiv preprint arXiv:1702.08400, 2017.

John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy

optimization algorithms. arXiv preprint arXiv:1707.06347, 2017.

Ozan Sener, Hyun Oh Song, Ashutosh Saxena, and Silvio Savarese. Learning transferrable repre-
sentations for unsupervised domain adaptation. In Advances in Neural Information Processing
Systems, pp. 2110–2118, 2016.

Hidetoshi Shimodaira. Improving predictive inference under covariate shift by weighting the log-

likelihood function. Journal of statistical planning and inference, 90(2):227–244, 2000.

Baochen Sun and Kate Saenko. From virtual to reality: Fast adaptation of virtual object detectors to

real domains. In BMVC, volume 1, pp. 3, 2014.

Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consis-

tency targets improve semi-supervised deep learning results. 2017.

Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky. Instance normalization: The missing in-

gredient for fast stylization. arXiv preprint arXiv:1607.08022, 2016.

12

Published as a conference paper at ICLR 2018

David Vazquez, Antonio M Lopez, Javier Marin, Daniel Ponsa, and David Geronimo. Virtual and
real world adaptation for pedestrian detection. IEEE transactions on pattern analysis and machine
intelligence, 36(4):797–809, 2014.

Siamak Youseﬁ, Hirokazu Narui, Sankalp Dayal, Stefano Ermon, and Shahrokh Valaee. A survey
on behavior recognition using wiﬁ channel state information. IEEE Communications Magazine,
55(10):98–104, 2017.

Zhi-Hua Zhou and Ming Li. Tri-training: Exploiting unlabeled data using three classiﬁers. IEEE

Transactions on knowledge and Data Engineering, 17(11):1529–1541, 2005.

Xiaojin Zhu. Semi-supervised learning literature survey. 2005.

13

Published as a conference paper at ICLR 2018

A ARCHITECTURES

Layer Index

Small CNN

Large CNN

L − 18

L − 17

L − 16
L − 15
L − 14

L − 13
L − 12
L − 11

L − 10
L − 9
L − 8

L − 7
L − 6
L − 5

L − 4
L − 3
L − 2

L − 1

L − 0

32 × 32 × 3 Image

Instance Normalization (optional)

3 × 3 conv. 64 lReLU
3 × 3 conv. 64 lReLU
3 × 3 conv. 64 lReLU

3 × 3 conv. 96 lReLU
3 × 3 conv. 96 lReLU
3 × 3 conv. 96 lReLU

3 × 3 conv. 64 lReLU 3 × 3 conv. 192 lReLU
3 × 3 conv. 64 lReLU 3 × 3 conv. 192 lReLU
3 × 3 conv. 64 lReLU 3 × 3 conv. 192 lReLU

2 x 2 max-pool, stride 2
dropout, p = 0.5
Gaussian noise, σ = 1

2 x 2 max-pool, stride 2
dropout, p = 0.5
Gaussian noise, σ = 1

3 × 3 conv. 64 lReLU 3 × 3 conv. 192 lReLU
3 × 3 conv. 64 lReLU 3 × 3 conv. 192 lReLU
3 × 3 conv. 64 lReLU 3 × 3 conv. 192 lReLU

global average pool

10 dense, softmax

Domain Discriminator

Layer L − 5 Output

100 dense, ReLU

1 dense, sigmoid

Table 7: Domain discriminator architecture.

Table 6: Small and Large CNN architectures. Leaky ReLU parameter a = 0.1. All convolutional
and dense layers in the classiﬁer are pre-activation batch-normalized. All images are resized to 32
32
in which we observed that domain adversarial training appears to contract the feature space.

×
3. Note the use of additive Gaussian noise: this addition was motivated by initial experiments

×

14

Published as a conference paper at ICLR 2018

B HYPERPARAMETERS

We observed that extensive hyperparameter-tuning is not necessary to achieve state-of-the-art per-
formance. To demonstrate this, we restrict our hyperparameter search for each task to λd =
0, 10−2
, in all experiments with instance-normalized inputs.
{
We ﬁxed β = 10−2. Note that the decision to turn (λd, λs) on or off that can often be determined
a priori based on prior belief regarding the extent to covariate shift. In the absence of such prior
belief, a reliable choice is (λd = 10−2, λs = 1, λt = 10−2, β = 10−2).

10−2, 10−1
{

0, 1
}

, λs =

, λt =

}

{

}

Task

Instance-Normalized

λs

MNIST → MNIST-M
SVHN → MNIST
MNIST → SVHN
MNIST → SVHN
DIGITS → SVHN
SIGNS → GTSRB
CIFAR → STL
STL → CIFAR
Room A → B

Yes, No
Yes, No
Yes
No
Yes, No
Yes, No
Yes, No
Yes, No
Yes

λd
10−2
10−2
10−2
10−2
10−2
10−2
0
0
0

λt
10−2
10−2
10−2
10−2
10−1
10−2
10−1
10−1
10−2

β

10−2
10−2
10−2
10−3
10−2
10−2
10−2
10−2
10−2

0
0
1
1
1
1
1
0
0

Table 8: Hyperparameters for each task, both with and without instance-normalized input. The
SVHN without instance-normalized input. In this speciﬁc case, dH∆H
only exception is MNIST
is sufﬁciently large that conditional entropy minimization quickly ﬁnds a degenerate solution in
the target domain. To counter this, we remove conditional entropy minimization (but keep the
target-side virtual adversarial training) only during VADA. We apply target-side conditional entropy
minimization and virtual adversarial training during DIRT-T. To compensate, we use a lower β
during the DIRT-T phase to allow for larger natural gradient steps.

→

When the target domain is MNIST/MNIST-M, the task is sufﬁciently simple that we only allocate
B = 500 iterations to each optimization problem in Eq. (14). In all other cases, we set the reﬁnement
interval B = 5000. We apply Adam Optimizer (learning rate = 0.001, β1 = 0.5, β2 = 0.999)
with Polyak averaging (more accurately, we apply an exponential moving average with momentum
= 0.998 to the parameter trajectory). VADA was trained for 80000 iterations and DIRT-T takes
VADA as initialization and was trained for
iterations, with number
of iterations chosen as hyperparameter.

20000, 40000, 60000, 80000

}

{

C REPLACING GRADIENT REVERSAL

D(fθ(x))) is tends to have
We note from Goodfellow et al. (2014) that the gradient of
−∇θ ln D(fθ(x)) during initial training since the latter rescales the gradient by
smaller norm than
1/D(fθ(x)). Following this observation, we replace the gradient reversal procedure with alternating
minimization of

∇θ ln(1

−

min
D −
min

θ −

Ex∼Ds [ln D(fθ(x))]
Ex∼Dt [ln D(fθ(x))]

Ex∼Dt [ln 1
Ex∼Ds [ln 1

−

−

D(fθ(x))]

D(fθ(x))] .

−

−

The choice of using gradient reversal versus alternating minimization reﬂects a difference in choice
of approximating the mini-max using saturating versus non-saturating optimization (Fedus et al.,
2017). In some of our initial experiments, we observed the replacement of gradient reversal with al-
ternating minimization stabilizes domain adversarial training. However, we encourage practitioners
to try either optimization strategy when applying VADA.

D INSTANCE NORMALIZATION FOR DOMAIN ADAPTATION

Theorem 1 suggests that we should identify ways of constraining the hypothesis space without hurt-
ing the global optimal classiﬁer for the joint task. We propose to further constrain our model by

15

Published as a conference paper at ICLR 2018

introducing instance normalization as an image pre-processing step for the input data.
normalization was proposed for style transfer Ulyanov et al. (2016) and applies the operation

Instance

(cid:96)(x(i)) =

x(i)

µ(x(i))

−
σ(x(i))

,

∈

RH×W ×C denotes the ith sample with (H, W, C) corresponding to the height, width,
where x(i)
and channel dimensions, and where µ, σ : RH×W ×C
RC are functions that compute the mean
and standard deviation across the spatial dimensions. A notable property of instance normalization
is that it is invariant to channel-wide scaling and shifting of the input elements. Formally, consider
scaling and shift variables γ, β

0 and σ(x(i))

RC. If γ

0, then

→

∈

(cid:31)

(cid:31)
(cid:96)(x(i)) = (cid:96)(γx(i) + β).

For visual data the application of instance normalization to the input layer makes the classiﬁer in-
variant to channel-wide shifts and scaling of the pixel intensities. For most visual tasks, sensitivity to
channel-wide pixel intensity changes is not critical to the success of the classiﬁer. As such, instance
normalization of the input may help reduce dH∆H without hurting the globally optimal classiﬁer.
Interestingly, Figure 3 shows that input instance normalization is not equivalent to gray-scaling,
since color is partially preserved. To test the effect of instance normalization, we report results both
with and without the use of instance-normalized inputs.

E LIMITATION OF DOMAIN ADVERSARIAL TRAINING

We denote the source and target distributions respectively as ps(x, y) and pt(x, y). Let the source
covariate distribution ps(x) deﬁne the random variable Xs that have support supp(Xs) =
Xs and
Xt are subsets of Rn. Let
let (Xt,
ps(y) and pt(y) deﬁne probabilities over the support
. We consider any embedding
function f : Rn
, where

Xs and
}
1)-simplex. We denote a classiﬁer h = g

1, . . . , K
=
{
Rm, where Rm is the embedding space, and any embedding classiﬁer g : Rm

Xt) be analogously deﬁned for the target domain. Both

→
f has the composite of an

→
is the (K

Y

C
−
embedding function with an embedding classiﬁer.

C

◦

For simplicity, we restrict our analysis to the simple case where K = 2, i.e. where
Furthermore, we assume that for any δ
∈
We impose a similar condition on pt(x).

[0, 1], there exists a subset Ω

Y
Rn where ps(x

⊆

∈

=

0, 1
.
{
}
Ω) = δ.

For a joint distribution p(x, y), we denote the generalization error of a classiﬁer as
(cid:15)p(h) = E

h(x)

y

.

Note that for a given classiﬁer h : Rn
1
{

. We further deﬁne the set Ω
h(x) > 0.5
}

→
⊆

−

p(x,y) |
[0, 1], the corresponding hard classiﬁer is k(x) =
Rn such that

|

In a slight abuse of notation, we deﬁne the generalization error (cid:15)(Ω) with respect to Ω as

Ω =

x
{

∈

Rn

|

k(x) = 1

} ⇐⇒

k(x) = 1
{

x

Ω

.

}

∈

An optimal Ω∗

p is a partitioning of Rn

(cid:15)p(Ω) = E

p(x,y)1

Ω

= (cid:15)(k).

x
{

∈

}

(cid:15)p(Ω∗

p) = min
Ω⊆Rn

(cid:15)p(Ω)

such that generalization error under the distribution p(x, y) is minimized.

E.1 GOOD TARGET-DOMAIN ACCURACY IS NOT GUARANTEED

Domain adversarial training seeks to ﬁnd a single classiﬁer h used for both the source ps and target
pt distributions. To do so, domain adversarial training sets up the objective

(15)

(16)

(17)

(18)

(19)

(20)

(21)

(22)

min
f ∈F ,g∈G

(cid:15)ps(g

f )

◦
s.t. g(Xs) = g(Xt),

16

Published as a conference paper at ICLR 2018

G

F

and

where
are the hypothesis spaces for the embedding function and embedding classiﬁer. In-
tuitively, domain adversarial training operates under the hypothesis that good source generalization
error in conjunction with source-target feature matching implies good target generalization error.
We shall see, however, that if
is sufﬁciently complex, this implication does not
necessarily hold.

Xs ∩ Xt = ∅ and

F

contain all functions mapping Rn

Rm, i.e.

has inﬁnite capacity. Suppose

contains

F

Let
the function g(z) = 1
∗ = (cid:8)g

H

z = 1m}
{
g
f
| ∃

∈ G

◦

and

, f

→

F
Xs ∩ Xt = ∅. We consider the set
f )
◦
∈ F

(cid:15)ps(Ω∗
ps

s.t. (cid:15)ps (g

≤

), f (Xs) = f (Xt)(cid:9) .

(23)

G

Such a set of classiﬁers satisﬁes the feature-matching constraint while achieving source general-
∗
ization error no worse than the optimal source-domain hard classiﬁer. It sufﬁces to show that
includes hypotheses that perform poorly in the target domain.

H

∗ is not an empty set by constructing an element of this set. Choose a partitioning

We ﬁrst show
Ω where

H

Consider the embedding function

pt(x

Ω) = ps(x

∈

Ω∗
ps

).

∈

fΩ(x) =

(cid:26)1m if (x

0m otherwise.

∈ Xs ∩

Ω∗
ps

)

(x

∨

∈ Xt ∩

Ω)

Let g(z) = 1

z = 1m}
{

. It follows that the composite classiﬁer hΩ = g

fΩ is an element of

◦

Next, we show that a classiﬁer h
Consider the partitioning ˆΩ which solves the following optimization problem

∗ does not necessarily achieve good target generalization error.

∈ H

Such a partitioning ˆΩ is the worst-case partitioning subject to the probability mass constraint. It
follows that worse case h(cid:48)

max
Ω⊆Rn

(cid:15)pt(Ω)

s.t. pt(x

Ω) = ps(x

∈

Ω∗
ps

).

∈

∈ H

∗ has generalization error
(cid:15)pt(h(cid:48)) = max
h∈H∗

(cid:15)pt(h)

≥

(cid:15)pt(h ˆΩ).

To provide intuition that (cid:15)pt(h(cid:48)) is potentially very large, consider hypothetical source and target
Ω∗
) = 0.5. The worst-case partitioning
) = ps(x
domains where
ps
subject to the probability mass constraint is simply ˆΩ = Rn
pt (which ﬂips the labels) and
consequently,

Xs ∩ Xt = ∅ and pt(x
∗ contains solutions

Ω∗
pt

Ω∗

∈

∈

\

H

no better than the worst-case partitioning of the target domain.

max
h∈H∗

(cid:15)pt(h)

1

≥

−

(cid:15)pt(Ω∗
pt

)

E.2 CONNECTION TO THEOREM 1

Let
the function g(z) = 1

F

contain all functions mapping Rn

Rm, i.e.

has inﬁnite capacity. Suppose

contains

G

and

z = 1m}
{
=
g
H
◦
{
¯
H

=

◦

g

f

f

→

F
Xs ∩ Xt = ∅. We consider the sets
g
∈ G
g
| ∃

s.t. f (Xs) = f (Xt)

∈ F}

∈ F

∈ G

, f

, f

|

.

{
A justiﬁcation for domain adversarial training is that the ¯
H

-divergence term is smaller than the
-divergence, thus yielding a tighter upper bound for Theorem 1. However, we shall see that
∆ ¯
H

-divergence term is in fact maximal.

∆ ¯
H

}

∆
H
H
the ¯
H
Choose partitionings Ωs, Ωt ⊆

Rn such that

(24)

(25)

∗.

H

(26)

(27)

(28)

(29)

(30)

(31)

(32)

ps(x

Ωs) = pt(x

Ωt) = 0.5.

∈

∈

17

Published as a conference paper at ICLR 2018

(33)

(34)

◦

(35)
(36)

Deﬁne the embedding functions

∈ Xs ∩

Ωs)

(x

Ωt)

∈ Xt ∩

f (x) =

f (cid:48)(x) =

(cid:26)1m if (x

0m otherwise.

(cid:26)1m if (x

0m otherwise.

∨

∨

∈ Xs ∩

Ωs)

(x

∈ Xt ∩

(Rn

Ωt))

\

Let g(cid:48)(z) = g(z) = 1
{
are elements of ¯
H

.

z = 1m}

From the deﬁnition of dH∆H, we see that

. It follows that the composite classiﬁers h = g

f and h(cid:48) = g(cid:48)

f (cid:48)

◦

2
d ¯H∆ ¯H ≥
= 2

Ex∼Xs [h(x)
|
= 2.
1
0
|
· |

−
-divergence thus achieves the maximum value of 2.

= h(cid:48)(x)]

Ex∼Xt [h(x)

−

= h(cid:48)(x)]
|

The ¯
H

∆ ¯
H

E.3

IMPLICATIONS

Our analysis assumes inﬁnite capacity embedding functions and the ability to solve optimization
problems exactly. The empirical success of domain adversarial training suggests that the use of
ﬁnite-capacity convolutional neural networks combined with stochastic gradient-based optimization
provides the necessary regularization for domain adversarial training to work. The theoretical char-
acterization of domain adversarial training in the case ﬁnite-capacity convolutional neural networks
and gradient-based learning remains a challenging but important open research problem.

F NON-VISUAL DOMAIN ADAPTATION TASK

To evaluate the performance of our models on a non-visual domain adaptation task, we applied
VADA and DIRT-T to the Wi-Fi Activity Recognition Dataset (Youseﬁ et al., 2017). The Wi-Fi
Activity Recognition Dataset is a classiﬁcation task that takes the Wi-Fi Channel State Information
(CSI) data stream as input x to predict motion activity within an indoor area as output y. The dataset
collected the CSI data stream samples associated with seven activities, denoted as “bed”, “fall”,
“walk”, “pick up”, “run”, “sit down”, and “stand up”.

However, the joint distribution over the CSI data stream and motion activity changes depending
on the room in which the data was collected. Since the data was collected for multiple rooms,
we selected two rooms (denoted here as Room A and Room B) and constructed the unsupervised
domain adaptation task by using Room A as the source domain and Room B as the target domain.
We compare the performance of DANN, VADA, and DIRT-T on the Wi-Fi domain adaptation task
in Table 2, using the hyperparameters (λd = 0, λs = 0, λt = 10−2, β = 10−2).
Table 2 shows that VADA signiﬁcantly improves classiﬁcation accuracy compared to Source-Only
and DANN. However, DIRT-T does not lead to further improvements on this dataset. We believe this
is attributable to VADA successfully pushing the decision boundary away from data-dense regions
in the target domain. As a result, further application of DIRT-T would not lead to better decision
boundaries. To validate this hypothesis, we visualize the t-SNE embeddings for VADA and DIRT-T
in Figure 6 and show that VADA is already capable of yielding strong clustering in the target domain.
To verify that the decision boundary indeed did not change signiﬁcantly, we additionally provide the
confusion matrix between the VADA and DIRT-T predictions in the target domain (Fig. 7).

18

Published as a conference paper at ICLR 2018

(a) VADA

(b) DIRT-T

Figure 6: T-SNE plot of the last hidden layer for Room A (blue)

Room B (red)

→

Figure 7: Confusion matrix between VADA and and DIRT-T prediction labels.

19

8
1
0
2
 
r
a

M
 
9
1
 
 
]
L
M

.
t
a
t
s
[
 
 
2
v
5
3
7
8
0
.
2
0
8
1
:
v
i
X
r
a

Published as a conference paper at ICLR 2018

A DIRT-T APPROACH TO UNSUPERVISED DOMAIN
ADAPTATION

Rui Shu†∗, Hung H. Bui‡, Hirokazu Narui†, & Stefano Ermon†
†Stanford University
‡DeepMind
†

@stanford.edu

‡

ruishu,hirokaz2,ermon
{
@google.com
buih
}
{

}

ABSTRACT

Domain adaptation refers to the problem of leveraging labeled data in a source
domain to learn an accurate model in a target domain where labels are scarce or
unavailable. A recent approach for ﬁnding a common representation of the two
domains is via domain adversarial training (Ganin & Lempitsky, 2015), which
attempts to induce a feature extractor that matches the source and target feature
distributions in some feature space. However, domain adversarial training faces
two critical limitations: 1) if the feature extraction function has high-capacity, then
feature distribution matching is a weak constraint, 2) in non-conservative domain
adaptation (where no single classiﬁer can perform well in both the source and
target domains), training the model to do well on the source domain hurts perfor-
mance on the target domain. In this paper, we address these issues through the lens
of the cluster assumption, i.e., decision boundaries should not cross high-density
data regions. We propose two novel and related models: 1) the Virtual Adver-
sarial Domain Adaptation (VADA) model, which combines domain adversarial
training with a penalty term that punishes violation of the cluster assumption; 2)
the Decision-boundary Iterative Reﬁnement Training with a Teacher (DIRT-T)1
model, which takes the VADA model as initialization and employs natural gradient
steps to further minimize the cluster assumption violation. Extensive empirical re-
sults demonstrate that the combination of these two models signiﬁcantly improve
the state-of-the-art performance on the digit, trafﬁc sign, and Wi-Fi recognition
domain adaptation benchmarks.

1

INTRODUCTION

The development of deep neural networks has enabled impressive performance in a wide variety of
machine learning tasks. However, these advancements often rely on the existence of a large amount
of labeled training data. In many cases, direct access to vast quantities of labeled data for the task
of interest (the target domain) is either costly or otherwise absent, but labels are readily available
for related training sets (the source domain). A notable example of this scenario occurs when the
source domain consists of richly-annotated synthetic or semi-synthetic data, but the target domain
consists of unannotated real-world data (Sun & Saenko, 2014; Vazquez et al., 2014). However, the
source data distribution is often dissimilar to the target data distribution, and the resulting signiﬁcant
covariate shift is detrimental to the performance of the source-trained model when applied to the
target domain (Shimodaira, 2000).

Solving the covariate shift problem of this nature is an instance of domain adaptation (Ben-David
et al., 2010b). In this paper, we consider a challenging setting of domain adaptation where 1) we
are provided with fully-labeled source samples and completely-unlabeled target samples, and 2) the
existence of a classiﬁer in the hypothesis space with low generalization error in both source and
target domains is not guaranteed. Borrowing approximately the terminology from Ben-David et al.
(2010b), we refer to this setting as unsupervised, non-conservative domain adaptation. We note

∗Work was done during ﬁrst author’s internship at Adobe Research.
1Pronounce as “dirty.” Implementation available at https://github.com/RuiShu/dirt-t

1

Published as a conference paper at ICLR 2018

that this is in contrast to conservative domain adaptation, where we assume our hypothesis space
contains a classiﬁer that performs well in both the source and target domains.

To tackle unsupervised domain adaptation, Ganin & Lempitsky (2015) proposed to constrain the
classiﬁer to only rely on domain-invariant features. This is achieved by training the classiﬁer to
perform well on the source domain while minimizing the divergence between features extracted
from the source versus target domains. To achieve divergence minimization, Ganin & Lempitsky
(2015) employ domain adversarial training. We highlight two issues with this approach: 1) when the
feature function has high-capacity and the source-target supports are disjoint, the domain-invariance
constraint is potentially very weak (see Section 3), and 2) good generalization on the source domain
hurts target performance in the non-conservative setting.

Saito et al. (2017) addressed these issues by replacing domain adversarial training with asymmetric
tri-training (ATT), which relies on the assumption that target samples that are labeled by a source-
trained classiﬁer with high conﬁdence are correctly labeled by the source classiﬁer. In this paper,
we consider an orthogonal assumption: the cluster assumption (Chapelle & Zien, 2005), that the
input distribution contains separated data clusters and that data samples in the same cluster share the
same class label. This assumption introduces an additional bias where we seek decision boundaries
that do not go through high-density regions. Based on this intuition, we propose two novel mod-
els: 1) the Virtual Adversarial Domain Adaptation (VADA) model which incorporates an additional
virtual adversarial training (Miyato et al., 2017) and conditional entropy loss to push the decision
boundaries away from the empirical data, and 2) the Decision-boundary Iterative Reﬁnement Train-
ing with a Teacher (DIRT-T) model which uses natural gradients to further reﬁne the output of the
VADA model while focusing purely on the target domain. We demonstrate that

1. In conservative domain adaptation, where the classiﬁer is trained to perform well on the
source domain, VADA can be used to further constrain the hypothesis space by penalizing
violations of the cluster assumption, thereby improving domain adversarial training.

2. In non-conservative domain adaptation, where we account for the mismatch between the
source and target optimal classiﬁers, DIRT-T allows us to transition from a joint (source and
target) classiﬁer (VADA) to a better target domain classiﬁer. Interestingly, we demonstrate
the advantage of natural gradients in DIRT-T reﬁnement steps.

We report results for domain adaptation in digits classiﬁcation (MNIST-M, MNIST, SYN DIGITS,
SVHN), trafﬁc sign classiﬁcation (SYN SIGNS, GTSRB), general object classiﬁcation (STL-10,
CIFAR-10), and Wi-Fi activity recognition (Youseﬁ et al., 2017). We show that, in nearly all experi-
ments, VADA improves upon previous methods and that DIRT-T improves upon VADA, setting new
state-of-the-art performances across a wide range of domain adaptation benchmarks. In adapting
MNIST

SVHN, a very challenging task, we out-perform ATT by over 20%.

→

2 RELATED WORK

Given the extensive literature on domain adaptation, we highlight several works most relevant to
our paper. Shimodaira (2000); Mansour et al. (2009) proposed to correct for covariate shift by
re-weighting the source samples such that the discrepancy between the target distribution and re-
weighted source distribution is minimized. Such a procedure is problematic, however, if the source
and target distributions do not contain sufﬁcient overlap. Huang et al. (2007); Long et al. (2015);
Ganin & Lempitsky (2015) proposed to instead project both distributions into some feature space
and encourage distribution matching in the feature space. Ganin & Lempitsky (2015) in particular
encouraged feature matching via domain adversarial training, which corresponds approximately
to Jensen-Shannon divergence minimization (Goodfellow et al., 2014). To better perform non-
conservative domain adaptation, Saito et al. (2017) proposed to modify tri-training (Zhou & Li,
2005) for domain adaptation, leveraging the assumption that highly-conﬁdent predictions are cor-
rect predictions (Zhu, 2005). Several of aforementioned methods are based on Ben-David et al.
(2010a)’s theoretical analysis of domain adaptation, which states the following,

2

Published as a conference paper at ICLR 2018

Theorem 1 (Ben-David et al., 2010a) Let
H
be the two domains and their corresponding generalization error functions. Then for any h

be the hypothesis space and let (Xs, (cid:15)s) and (Xt, (cid:15)t)

,

(cid:15)t(h)

1
2

≤

dH∆H(Xs, Xt) + (cid:15)s(h) + min
h(cid:48)∈H

(cid:15)t(h(cid:48)) + (cid:15)s(h(cid:48)),

where dH∆H denotes the

∆

H
dH∆H = 2 sup

H

h,h(cid:48)∈H |

-distance between the domains Xs and Xt,
= h(cid:48)(x)]

Ex∼Xs [h(x)

Ex∼Xt [h(x)

−

= h(cid:48)(x)]
|

.

∈ H

(1)

(2)

Intuitively, dH∆H measures the extent to which small changes to the hypothesis in the source domain
can lead to large changes in the target domain. It is evident that dH∆H relates intimately to the
complexity of the hypothesis space and the divergence between the source and target domains. For
inﬁnite-capacity models and domains with disjoint supports, dH∆H is maximal.

A critical component to our paper is the cluster assumption, which states that decision boundaries
should not cross high-density regions (Chapelle & Zien, 2005). This assumption has been exten-
sively studied and leveraged for semi-supervised learning, leading to proposals such as conditional
entropy minimization (Grandvalet & Bengio, 2005) and pseudo-labeling (Lee, 2013). More recently,
the cluster assumption has led to many successful deep semi-supervised learning algorithms such as
semi-supervised generative adversarial networks (Dai et al., 2017), virtual adversarial training (Miy-
ato et al., 2017), and self/temporal-ensembling (Laine & Aila, 2016; Tarvainen & Valpola, 2017).
Given the success of the cluster assumption in semi-supervised learning, it is natural to consider
its application to domain adaptation. Indeed, Ben-David & Urner (2014) formalized the cluster as-
sumption through the lens of probabilistic Lipschitzness and proposed a nearest-neighbors model
for domain adaptation. Our work extends this line of research by showing that the cluster assump-
tion can be applied to deep neural networks to solve complex, high-dimensional domain adaptation
problems. Independently of our work, French et al. (2017) demonstrated the application of self-
ensembling to domain adaptation. However, our work additionally considers the application of the
cluster assumption to non-conservative domain adaptation.

3 LIMITATION OF DOMAIN ADVERSARIAL TRAINING

◦

−

X → Z

1)-simplex (denote as

and embedding classiﬁer gθ :

Before describing our model, we ﬁrst highlight that domain adversarial training may not be sufﬁcient
for domain adaptation if the feature extraction function has high-capacity. Consider a classiﬁer hθ,
parameterized by θ, that maps inputs to the (K
), where K is the number
of classes. Suppose the classiﬁer h = g
f can be decomposed as the composite of an embedding
function fθ :
Ds be
Z → C
the joint distribution over input x and one-hot label y and let Xs be the marginal input distribution.
Dt, Xt) are analogously deﬁned for the target domain. Let (
(
Ls,
Ds) = Ex,y∼Ds
Dt) = sup
where the supremum ranges over discriminators D :
objective and D is a domain discriminator. Domain adversarial training minimizes the objective

Ex∼Ds [ln D(fθ(x))] + Ex∼Dt [ln(1

Ld) be the loss functions

Ly is the cross-entropy

. For the source domain, let

(cid:2)y(cid:62) ln hθ(x)(cid:3)

Ly(θ;
Ds,

D(fθ(x)))] ,

(0, 1). Then

Ld(θ;

Z →

(4)

(3)

−

C

D

θ Ly(θ;
min.

Ds) + λdLd(θ;

Ds,

Dt),

(5)

Ld encourages the learning of a feature extractor f
where λd is a weighting factor. Minimization of
for which the Jensen-Shannon divergence between f (Xs) and f (Xt) is small.2 Ganin & Lempitsky
(2015) suggest that successful adaptation tends to occur when the source generalization error and
feature divergence are both small.

It is easy, however, to construct situations where this suggestion fails. In particular, if f has inﬁnite-
capacity and the source-target supports are disjoint, then f can employ arbitrary transformations to
the target domain so as to match the source feature distribution (see Appendix E for formalization).

2In practice, the minimization of Ld requires solving a mini-max optimization problem. We discuss this in

more detail in Appendix C

3

Published as a conference paper at ICLR 2018

We verify empirically that, for sufﬁciently deep layers, jointly achieving small source generalization
error and feature divergence does not imply high accuracy on the target task (Table 5). Given the
limitations of domain adversarial training, we wish to identify additional constraints that one can
place on the model to achieve better, more reliable domain adaptation.

4 CONSTRAINING VIA CONDITIONAL ENTROPY MINIMIZATION

Figure 1: VADA improves upon domain adversarial training by additionally penalizing violations
of the cluster assumption.

In this paper, we apply the cluster assumption to domain adaptation. The cluster assumption states
that the input distribution X contains clusters and that points in the same cluster come from the same
class. This assumption has been extensively studied and applied successfully to a wide range of
classiﬁcation tasks (see Section 2). If the cluster assumption holds, the optimal decision boundaries
should occur far away from data-dense regions in the space of
(Chapelle & Zien, 2005). Following
Grandvalet & Bengio (2005), we achieve this behavior via minimization of the conditional entropy
with respect to the target distribution,

X

Lc(θ;

Dt) =

−

Ex∼Dt

(cid:2)hθ(x)(cid:62) ln hθ(x)(cid:3) .

Intuitively, minimizing the conditional entropy forces the classiﬁer to be conﬁdent on the unlabeled
target data, thus driving the classiﬁer’s decision boundaries away from the target data (Grandvalet
& Bengio, 2005).
In practice, the conditional entropy must be empirically estimated using the
available data. However, Grandvalet & Bengio (2005) note that this approximation breaks down
if the classiﬁer h is not locally-Lipschitz. Without the locally-Lipschitz constraint, the classiﬁer is
allowed to abruptly change its prediction in the vicinity of the training data points, which 1) results
in a unreliable empirical estimate of conditional entropy and 2) allows placement of the classiﬁer
decision boundaries close to the training samples even when the empirical conditional entropy is
minimized. To prevent this, we propose to explicitly incorporate the locally-Lipschitz constraint via
virtual adversarial training (Miyato et al., 2017) and add to the objective function the additional term

(cid:20)

Lv(θ;

D

) = Ex∼D

max
(cid:107)r(cid:107)≤(cid:15)

DKL(hθ(x)

(cid:21)
hθ(x + r))
(cid:107)

,

which enforces classiﬁer consistency within the norm-ball neighborhood of each sample x. Note that
virtual adversarial training can be applied with respect to either the target or source distributions. We
can combine the conditional entropy minimization objective and domain adversarial training to yield
Dt) + λsLv(θ;
a basic combination of domain adversarial training and semi-supervised training objectives. We
refer to this as the Virtual Adversarial Domain Adaptation (VADA) model. Empirically, we ob-
served that the hyperparameters (λd, λs, λt) are easy to choose and work well across multiple tasks
(Appendix B).

Ds) + λdLd(θ;

θ Ly(θ;
min.

Ds) + λt [

Dt) +

Lv(θ;

Lc(θ;

Dt)] ,

Ds,

(8)

∆

-Distance Minimization. VADA aligns well with the theory of domain adaptation provided

H
in Theorem 1. Let the loss,

H

(6)

(7)

(9)

Lt(θ) =

Lv(θ;

Dt) +

Lc(θ; Dt),

4

Published as a conference paper at ICLR 2018

denote the degree to which the target-side cluster assumption is violated. Modulating λt enables
VADA to trade-off between hypotheses with low target-side cluster assumption violation and hy-
potheses with low source-side generalization error. Setting λt > 0 allows rejection of hypotheses
with high target-side cluster assumption violation. By rejecting such hypotheses from the hypothesis
, VADA reduces dH∆H and yields a tighter bound on the target generalization error. We
space
verify empirically that VADA achieves signiﬁcant improvements over existing models on multiple
domain adaptation benchmarks (Table 1).

H

5 DECISION-BOUNDARY ITERATIVE REFINEMENT TRAINING

Figure 2: DIRT-T uses VADA as initialization. After removing the source training signal, DIRT-
T minimizes cluster assumption violation in the target domain through a series of natural gradient
steps.

In non-conservative domain adaptation, we assume the following inequality,

(cid:15)t(h) < (cid:15)t(ha) where ha = arg min

(cid:15)s(h) + (cid:15)t(h),

(10)

min
h∈H

h∈H

where ((cid:15)s, (cid:15)t) are generalization error functions for the source and target domains. This means that,
for a given hypothesis class
, the optimal classiﬁer in the source domain does not coincide with
the optimal classiﬁer in the target domain.

H

We assume that the optimality gap in Eq. (10) results from violation of the cluster assumption.
In other words, we suppose that any source-optimal classiﬁer drawn from our hypothesis space
necessarily violates the cluster assumption in the target domain. Insofar as VADA is trained on the
source domain, we hypothesize that a better hypothesis is achievable by introducing a secondary
training phase that solely minimizes the target-side cluster assumption violation.

Under this assumption, the natural solution is to initialize with the VADA model and then further
minimize the cluster assumption violation in the target domain. In particular, we ﬁrst use VADA
to learn an initial classiﬁer hθ0 . Next, we incrementally push the classiﬁer’s decision boundaries
away from data-dense regions by minimizing the target-side cluster assumption violation loss
Lt in
Eq. (9). We denote this procedure Decision-boundary Iterative Reﬁnement Training (DIRT).

5.1 DECISION-BOUNDARY ITERATIVE REFINEMENT TRAINING WITH A TEACHER

Stochastic gradient descent minimizes the loss
following objective,

Lt by selecting gradient steps ∆θ according to the

∆θ Lt(θ + ∆θ)
min.
∆θ
s.t.
(cid:15),

(cid:107)

(cid:107) ≤

5

(11)

(12)

Published as a conference paper at ICLR 2018

which deﬁnes the neighborhood in the parameter space. This notion of neighborhood is sensitive
to the parameterization of the model; depending on the parameterization, a seemingly small step
∆θ may result in a vastly different classiﬁer. This contradicts our intention of incrementally and
locally pushing the decision boundaries to a local conditional entropy minimum, which requires
that the decision boundaries of hθ+∆θ stay close to that of hθ. It is therefore important to deﬁne a
neighborhood that is parameterization-invariant. Following Pascanu & Bengio (2013), we instead
select ∆θ using the following objective,

∆θ Lt(θ + ∆θ)
min.
s.t. Ex∼Dt [DKL(hθ(x)
hθ+∆θ(x))]
(cid:107)

(13)
Each optimization step now solves for a gradient step ∆θ that minimizes the conditional entropy,
subject to the constraint that the Kullback-Leibler divergence between hθ(x) and hθ+∆θ(x) is small
∼ Xt. The corresponding Lagrangian suggests that one can instead minimize a sequence of
for x
optimization problems

≤

(cid:15).

min.
θn

λtLt(θn) + βtE (cid:2)DKL(hθn−1(x)

hθn (x))(cid:3) ,
(cid:107)

(14)

that approximates the application of a series of natural gradient steps.

In practice, each of the optimization problems in Eq. (14) can be solved approximately via a ﬁnite
number of stochastic gradient descent steps. We denote the number of steps taken to be the reﬁne-
ment interval B. Similar to Tarvainen & Valpola (2017), we use the Adam Optimizer with Polyak
averaging (Polyak & Juditsky, 1992). We interpret hθn−1 as a (sub-optimal) teacher for the student
model hθn, which is trained to stay close to the teacher model while seeking to reduce the cluster
assumption violation. As a result, we denote this model as Decision-boundary Iterative Reﬁnement
Training with a Teacher (DIRT-T).

Weakly-Supervised Learning. This sequence of optimization problems has a natural interpretation
that exposes a connection to weakly-supervised learning. In each optimization problem, the teacher
model hθn−1 pseudo-labels the target samples with noisy labels. Rather than naively training the
student model hθn on the noisy labels, the additional training signal
Lt allows the student model to
place its decision boundaries further from the data. If the clustering assumption holds and the initial
noisy labels are sufﬁciently similar to the true labels, conditional entropy minimization can improve
the placement of the decision boundaries (Reed et al., 2014).

Domain Adaptation. An alternative interpretation is that DIRT-T is the recursive extension of
VADA, where the act of pseudo-labeling of the target distribution constructs a new “source” domain
(i.e. target distribution Xt with pseudo-labels). The sequence of optimization problems can then
be seen as a sequence of non-conservative domain adaptation problems in which Xs = Xt but
ps(y
x) is the true conditional label
|
distribution in the target domain. Since dH∆H is strictly zero in this sequence of optimization
problems, domain adversarial training is no longer necessary. Furthermore, if
Lt minimization does
improve the student classiﬁer, then the gap in Eq. (10) should get smaller each time the source
domain is updated.

x) = hθn−1(x) and pt(y

x), where ps(y

= pt(y

x)

|

|

|

6 EXPERIMENTS

In principle, our method can be applied to any domain adaptation tasks so long as one can deﬁne a
reasonable notion of neighborhood for virtual adversarial training (Miyato et al., 2016). For com-
parison against Saito et al. (2017) and French et al. (2017), we focus on visual domain adaptation
and evaluate on MNIST, MNIST-M, Street View House Numbers (SVHN), Synthetic Digits (SYN
DIGITS), Synthetic Trafﬁc Signs (SYN SIGNS), the German Trafﬁc Signs Recognition Benchmark
(GTSRB), CIFAR-10, and STL-10. For non-visual domain adaptation, we evaluate on Wi-Fi activity
recognition.

6.1

IMPLEMENTATION DETAIL

Architecture We use a small CNN for the digits, trafﬁc sign, and Wi-Fi domain adaptation exper-
iments, and a larger CNN for domain adaptation between CIFAR-10 and STL-10. Both architec-
tures are available in Appendix A. For fair comparison, we additionally report the performance of

6

Published as a conference paper at ICLR 2018

source-only baseline models and demonstrate that the signiﬁcant improvements are attributable to
our proposed method.

Replacing gradient reversal. In contrast to Ganin & Lempitsky (2015), which proposed to im-
plement domain adversarial training via gradient reversal, we follow Goodfellow et al. (2014) and
instead optimize via alternating updates to the discriminator and encoder (see Appendix C).

Instance normalization. We explored the application of instance normalization as an image pre-
processing step. This procedure makes the classiﬁer invariant to channel-wide shifts and rescaling
of pixel intensities. A discussion of instance normalization for domain adaptation is provided in
Appendix D. We show in Figure 3 the effect of applying instance normalization to the input image.

Figure 3: Effect of applying instance normalization to the input image.
In clockwise direction:
MNIST-M, GTSRB, SVHN, and CIFAR-10. In each quadrant, the top row is the original image,
and the bottom row is the instance-normalized image.

Hyperparameters. For each task, we tuned the four hyperparameters (λd, λs, λt, β) by randomly
selecting 1000 labeled target samples from the training set and using that as our validation set. We
observed that extensive hyperparameter-tuning is not necessary to achieve state-of-the-art perfor-
mance. In all experiments with instance-normalized inputs, we restrict our hyperparameter search
. We ﬁxed β = 10−2. Note that
for each task to λd =
, λt =
{
the decision to turn (λd, λs) on or off that can often be determined a priori. A complete list of the
hyperparameters is provided in Appendix B.

10−2, 10−1
{

0, 10−2

0, 1
}

, λs =

}

{

}

6.2 MODEL EVALUATION

Source
SVHN
MNIST
Target MNIST-M MNIST

MNIST
SVHN

DIGITS
SVHN

SIGNS
GTSRB

CIFAR
STL

STL
CIFAR

MMD (Long et al., 2015)
DANN (Ganin & Lempitsky, 2015)
DRCN (Ghifary et al., 2016)
DSN (Bousmalis et al., 2016b)
kNN-Ad (Sener et al., 2016)
PixelDA (Bousmalis et al., 2016a)
ATT (Saito et al., 2017)
Π-model (aug) (French et al., 2017)

Source-Only
VADA
DIRT-T

Source-Only
VADA
DIRT-T

Without Instance-Normalized Input:

76.9
81.5
-
83.2
86.7
98.2
94.2
-

58.5
97.7
98.9

59.9
95.7
98.7

71.1
71.1
82.0
82.7
78.8
-
86.2
92.0

77.0
97.9
99.4

82.4
94.5
99.4

-
35.7
40.1
-
40.3
-
52.8
71.4

27.9
47.5
54.5

40.9
73.3
76.5

88.0
90.3
-
91.2
-
-
92.9
94.2

86.9
94.8
96.1

88.6
94.9
96.2

91.1
88.7
-
93.1
-
-
96.2
98.4

79.6
98.8
99.5

86.2
99.2
99.6

-
-
66.4
-
-
-
-
76.3

76.3
80.0
-

77.0
78.3
-

-
-
58.7
-
-
-
-
64.2

63.6
73.5
75.3

62.6
71.4
73.3

With Instance-Normalized Input:

Table 1: Test set accuracy on visual domain adaptation benchmarks. In all settings, both VADA and
DIRT-T achieve state-of-the-art performance in all settings.

MNIST
constructed by blending MNIST digits with random color patches from the BSDS500 dataset.

MNIST-M. We ﬁrst evaluate the adaptation from MNIST to MNIST-M. MNIST-M is

→

↔

MNIST
SVHN. The distribution shift is exacerbated when adapting between MNIST and SVHN.
Whereas MNIST consists of black-and-white handwritten digits, SVHN consists of crops of colored,
street house numbers. Because MNIST has a signiﬁcantly lower intrinsic dimensionality that SVHN,
SVHN is especially challenging when the input is not pre-processed
the adaptation from MNIST

→

7

Published as a conference paper at ICLR 2018

via instance normalization. When instance normalization is applied, we achieve a strong state-of-
the-art performance 76.5% and an equally impressive margin-of-improvement over source-only of
35.6%. Interestingly, by reducing the reﬁnement interval B and taking noisier natural gradient steps,
we were occasionally able to achieve accuracies as high as 87%. However, due to the high-variance
associated with this, we omit reporting this conﬁguration in Table 1.

SVHN. The adaptation from SYN DIGITS

SYN DIGITS
SVHN reﬂect a common adaptation
problem of transferring from synthetic images to real images. The SYN DIGITS dataset consist of
500000 images generated from Windows fonts by varying the text, positioning, orientation, back-
ground, stroke color, and the amount of blur.

→

→

SYN SIGNS
thetic images to real images. Unlike SYN DIGITS
classes instead of 10.

GTSRB. This setting provides an additional demonstration of adapting from syn-
GTSRB contains 43

SVHN, SYN SIGNS

→

→

→

↔

STL
CIFAR. Both STL-10 and CIFAR-10 are 10-class image datasets. These two datasets
contain nine overlapping classes. Following the procedure in French et al. (2017), we removed the
non-overlapping classes (“frog” and “monkey”) and reduce to a 9-class classiﬁcation problem. We
achieve state-of-the-art performance in both adaptation directions. In STL
CIFAR, we achieve a
11.7% margin-of-improvement and a performance accuracy of 73.3%. Note that because STL-10
contains a very small training set, it is difﬁcult to estimate the conditional entropy, thus making
DIRT-T unreliable for CIFAR

STL.

→

→

Source
Target

Room A
Room B

With Instance-Normalized Input:

Source-Only
DANN
VADA
DIRT-T

35.7
38.0
53.0
53.0

Table 2: Results of the domain adaptation experiments on Wi-Fi Activity Recognition Task

Wi-Fi Activity Recognition. To evaluate the performance of our models on a non-visual domain
adaptation task, we applied VADA and DIRT-T to the Wi-Fi Activity Recognition Dataset (Youseﬁ
et al., 2017). The Wi-Fi Activity Recognition Dataset is a classiﬁcation task that takes the Wi-
Fi Channel State Information (CSI) data stream as input x to predict motion activity within an
indoor area as output y. Domain adaptation is necessary when the training and testing data are
collected from different rooms, which we denote as Rooms A and B. Table 2 shows that VADA
signiﬁcantly improves classiﬁcation accuracy compared to Source-Only and DANN by 17.3% and
15% respectively. However, DIRT-T does not lead to further improvements on this dataset. We
perform experiments in Appendix F which suggests that VADA already achieves strong clustering in
the target domain for this dataset, and therefore DIRT-T is not expected to yield further performance
improvement.

Source
SVHN
MNIST
Target MNIST-M MNIST

MNIST
SVHN

DIGITS
SVHN

SIGNS
GTSRB

CIFAR
STL

STL
CIFAR

ATT
Π-model (aug)
DIRT-T
DIRT-T (W.I.N.I.)

37.1
-
40.4
38.8

16.1
3.7
22.4
17.0

17.9
18.1
26.6
35.6

9.0
10.6
9.2
7.6

20.5
1.0
19.9
13.4

-
4.5
-
-

-
7.4
11.7
10.7

Table 3: Additional comparison of the margin of improvement computed by taking the reported
performance of each model and subtracting the reported source-only performance in the respective
papers. W.I.N.I. indicates “with instance-normalized input.”

Overall. We achieve state-of-the-art results across all tasks. For a fairer comparison against ATT
and the Π-model, Table 3 provides the improvement margin over the respective source-only per-
formance reported in each paper. In four of the tasks (MNIST
MNIST,
MNIST
CIFAR), we achieve substantial margin of improvement compared to
previous models. In the remaining three tasks, our improvement margin over the source-only model

MNIST-M, SVHN

SVHN, STL

→

→

→

→

8

Published as a conference paper at ICLR 2018

is competitive against previous models. Our closest competitor is the Π-model. However, unlike the
Π-model, we do not perform data augmentation.

It is worth noting that DIRT-T consistently improves upon VADA. Since DIRT-T operates by in-
crementally pushing the decision boundaries away from the target domain data, it relies heavily
on the cluster assumption. DIRT-T’s empirical success therefore demonstrates the effectiveness of
leveraging the cluster assumption in unsupervised domain adaptation with deep neural networks.

6.3 ANALYSIS OF VADA AND DIRT-T

6.3.1 ROLE OF VIRTUAL ADVERSARIAL TRAINING

To study the relative contribution of the virtual adversarial training in the VADA and DIRT-T ob-
jectives (Eq. (8) and Eq. (14) respectively), we perform an extensive ablation analysis in Table 4.
The removal of the virtual adversarial training component is denoted by the “no-vat” subscript. Our
results show that VADAno-vat is sufﬁcient for out-performing DANN in all but one task. The further
ability for DIRT-Tno-vat to improve upon VADAno-vat demonstrates the effectiveness of conditional
entropy minimization. Ultimately, in six of the seven tasks, both virtual adversarial training and
conditional entropy minimization are essential for achieving the best performance. The empirical
importance of incorporating virtual adversarial training shows that the locally-Lipschitz constraint
is beneﬁcial for pushing the classiﬁer decision boundaries away from data.

SVHN
MNIST
Source
Target MNIST-M MNIST

MNIST
SVHN

DIGITS
SVHN

SIGNS
GTSRB

CIFAR
STL

STL
CIFAR

With Instance-Normalized Input:

Source-Only
DANN (our implementation)

VADAno-vat
VADAno-vat → DIRT-Tno-vat
VADAno-vat → DIRT-T

VADA
VADA → DIRT-T

59.9
94.6

93.8
94.8
98.3

95.7
98.7

82.4
68.3

83.1
96.3
99.4

94.5
99.4

40.9
60.6

66.8
68.6
69.8

73.3
76.5

88.6
90.1

93.4
94.4
95.3

94.9
96.2

86.2
97.5

98.4
99.1
99.6

99.2
99.6

77.0
78.1

79.1
-
-

78.3
-

62.6
62.7

68.6
69.2
71.0

71.4
73.3

Table 4: Test set accuracy in ablation experiments, starting from the DANN model. The “no-vat”
subscript denote models where the virtual adversarial training component is removed.

6.3.2 ROLE OF TEACHER MODEL IN DIRT-T

(a) SVHN → MNIST

(b) STL → CIFAR

9

Figure 4: Comparing model behavior with and without the application of the KL-term. At iteration
0, we begin with the VADA initialization and apply the DIRT-T algorithm.

Published as a conference paper at ICLR 2018

When considering Eq. (14), it is natural to ask whether deﬁning the neighborhood with respect to the
classiﬁer is truly necessary. In Figure 4, we demonstrate in SVHN
CIFAR
that removal of the KL-term negatively impacts the model. Since the MNIST data manifold is
low-dimensional and contains easily identiﬁable clusters, applying naive gradient descent (Eq. (12))
can also boost the test accuracy during initial training. However, without the KL constraint, the
classiﬁer can sometimes deviate signiﬁcantly from the neighborhood of the previous classiﬁer, and
the resulting spikes in the KL-term correspond to sharp drops in target test accuracy. In STL
→
CIFAR, where the data manifold is much more complex and contains less obvious clusters, naive
gradient descent causes immediate decline in the target test accuracy.

MNIST and STL

→

→

6.3.3 VISUALIZATION OF REPRESENTATION

(a) Source-Only

(b) VADA

(c) DIRT-T

Figure 5: T-SNE plot of the last hidden layer for MNIST (blue)
without instance normalization to highlight the further improvement that DIRT-T provides.

SVHN (red). We used the model

→

We further analyze the behavior of VADA and DIRT-T by showing T-SNE embeddings of the last
hidden layer of the model trained to adapt from MNIST
SVHN. In Figure 5, source-only train-
ing shows strong clustering of the MNIST samples (blue) and performs poorly on SVHN (red).
VADA offers signiﬁcant improvement and exhibits signs of clustering on SVHN. DIRT-T begins
with the VADA initialization and further enhances the clustering, resulting in the best performance
on MNIST

SVHN.

→

6.4 DOMAIN ADVERSARIAL TRAINING: LAYER ABLATION

→

Layer

L − 0
L − 1
L − 2
L − 3
L − 4
L − 5
L − 6
L − 7

DANN
JSD ≥ Source Accuracy

Target Accuracy

VADA
JSD ≥ Source Accuracy

Target Accuracy

0.001
0.002
0.353
0.036
0.012
0.235
0.486
0.644

78.0
98.6
16.4
94.8
97.0
99.3
99.2
99.0

24.7
35.0
10.3
33.8
40.0
57.9
60.3
52.5

0.001
0.007
0.383
0.034
0.020
0.244
0.509
0.608

24.9
12.0
11.5
67.8
96.8
99.4
99.3
99.1

18.4
11.6
9.9
37.1
61.5
73.3
70.4
70.5

Table 5: Comparison of model behavior when domain adversarial training is applied to various
layers. We denote the very last (simplex) layer of the neural network as L and ablatively domain
adversarial training to the last eight layers. A lower bound on the Jensen-Shannon Divergence is
computed by training a logistic regression model to predict domain origin when given the layer
embeddings.

−

2 and L

In Table 5, we applied domain adversarial training to various layers of a Domain Adversarial Neu-
ral Network (Ganin & Lempitsky, 2015) trained to adapt MNIST
SVHN. With the exception
0, which experienced training instability, the general observation is that
of layers L
as the layer gets deeper, the additional capacity of the corresponding embedding function allows
better matching of the source and target distributions without hurting source generalization accu-
racy. This demonstrates that the combination of low divergence and high source accuracy does not
imply better adaptation to the target domain. Interestingly, when the classiﬁer is regularized to be
locally-Lipschitz via VADA, the combination of low divergence and high source accuracy appears
to correlate more strongly with better adaptation.

→

−

10

Published as a conference paper at ICLR 2018

7 CONCLUSION

In this paper, we presented two novel models for domain adaptation inspired by the cluster as-
sumption. Our ﬁrst model, VADA, performs domain adversarial training with an added term that
penalizes violations of the cluster assumption. Our second model, DIRT-T, is an extension of VADA
that recursively reﬁnes the VADA classiﬁer by untethering the model from the source training signal
and applying approximate natural gradients to further minimize the cluster assumption violation.
Our experiments demonstrate the effectiveness of the cluster assumption: VADA achieves strong
performance across several domain adaptation benchmarks, and DIRT-T further improves VADA
performance. Our proposed models open up several possibilities for future work. One possibility is
to apply DIRT-T to weakly supervised learning; another is to improve the natural gradient approx-
imation via K-FAC (Martens & Grosse, 2015) and PPO (Schulman et al., 2017). Given the strong
performance of our models, we also recommend them for other downstream domain adaptation
applications.

We gratefully acknowledge funding from Adobe, NSF (grants #1651565, #1522054, #1733686),
Toyota Research Institute, Future of Life Institute, and Intel. We also thank Daniel Levy, Shengjia
Zhao, and Jiaming Song for insightful discussions, and the anonymous reviewers for their helpful
comments and suggestions.

ACKNOWLEDGMENTS

REFERENCES

Shai Ben-David and Ruth Urner. Domain adaptation–can quantity compensate for quality? Annals

of Mathematics and Artiﬁcial Intelligence, 70(3):185–202, 2014.

Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wort-
man Vaughan. A theory of learning from different domains. Machine learning, 79(1):151–175,
2010a.

Shai Ben-David, Tyler Lu, Teresa Luu, and D´avid P´al. Impossibility theorems for domain adap-
tation. In Proceedings of the Thirteenth International Conference on Artiﬁcial Intelligence and
Statistics, pp. 129–136, 2010b.

Konstantinos Bousmalis, Nathan Silberman, David Dohan, Dumitru Erhan, and Dilip Krishnan.
Unsupervised pixel-level domain adaptation with generative adversarial networks. arXiv preprint
arXiv:1612.05424, 2016a.

Konstantinos Bousmalis, George Trigeorgis, Nathan Silberman, Dilip Krishnan, and Dumitru Erhan.
Domain separation networks. In Advances in Neural Information Processing Systems, pp. 343–
351, 2016b.

Olivier Chapelle and Alexander Zien. Semi-supervised classiﬁcation by low density separation. In

AISTATS, pp. 57–64, 2005.

Zihang Dai, Zhilin Yang, Fan Yang, William W Cohen, and Ruslan Salakhutdinov. Good semi-

supervised learning that requires a bad gan. arXiv preprint arXiv:1705.09783, 2017.

William Fedus, Mihaela Rosca, Balaji Lakshminarayanan, Andrew M Dai, Shakir Mohamed, and
Ian Goodfellow. Many paths to equilibrium: Gans do not need to decrease adivergence at every
step. arXiv preprint arXiv:1710.08446, 2017.

Geoffrey French, Michal Mackiewicz, and Mark Fisher. Self-ensembling for domain adaptation.

arXiv preprint arXiv:1706.05208, 2017.

Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In

International Conference on Machine Learning, pp. 1180–1189, 2015.

Muhammad Ghifary, W Bastiaan Kleijn, Mengjie Zhang, David Balduzzi, and Wen Li. Deep
In European Con-

reconstruction-classiﬁcation networks for unsupervised domain adaptation.
ference on Computer Vision, pp. 597–613. Springer, 2016.

11

Published as a conference paper at ICLR 2018

Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural infor-
mation processing systems, pp. 2672–2680, 2014.

Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In Ad-

vances in neural information processing systems, pp. 529–536, 2005.

Jiayuan Huang, Arthur Gretton, Karsten M Borgwardt, Bernhard Sch¨olkopf, and Alex J Smola.
Correcting sample selection bias by unlabeled data. In Advances in neural information processing
systems, pp. 601–608, 2007.

Samuli Laine and Timo Aila. Temporal ensembling for semi-supervised learning. arXiv preprint

arXiv:1610.02242, 2016.

Dong-Hyun Lee. Pseudo-label: The simple and efﬁcient semi-supervised learning method for deep
neural networks. In Workshop on Challenges in Representation Learning, ICML, volume 3, pp.
2, 2013.

Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. Learning transferable features with
deep adaptation networks. In International Conference on Machine Learning, pp. 97–105, 2015.

Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh. Domain adaptation: Learning bounds

and algorithms. arXiv preprint arXiv:0902.3430, 2009.

James Martens and Roger Grosse. Optimizing neural networks with kronecker-factored approximate

curvature. In International Conference on Machine Learning, pp. 2408–2417, 2015.

Takeru Miyato, Andrew M Dai, and Ian Goodfellow. Virtual adversarial training for semi-supervised

text classiﬁcation. stat, 1050:25, 2016.

Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual adversarial train-
arXiv preprint

ing: a regularization method for supervised and semi-supervised learning.
arXiv:1704.03976, 2017.

Razvan Pascanu and Yoshua Bengio. Revisiting natural gradient for deep networks. arXiv preprint

arXiv:1301.3584, 2013.

Boris T Polyak and Anatoli B Juditsky. Acceleration of stochastic approximation by averaging.

SIAM Journal on Control and Optimization, 30(4):838–855, 1992.

Scott Reed, Honglak Lee, Dragomir Anguelov, Christian Szegedy, Dumitru Erhan, and Andrew
Rabinovich. Training deep neural networks on noisy labels with bootstrapping. arXiv preprint
arXiv:1412.6596, 2014.

Kuniaki Saito, Yoshitaka Ushiku, and Tatsuya Harada. Asymmetric tri-training for unsupervised

domain adaptation. arXiv preprint arXiv:1702.08400, 2017.

John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy

optimization algorithms. arXiv preprint arXiv:1707.06347, 2017.

Ozan Sener, Hyun Oh Song, Ashutosh Saxena, and Silvio Savarese. Learning transferrable repre-
sentations for unsupervised domain adaptation. In Advances in Neural Information Processing
Systems, pp. 2110–2118, 2016.

Hidetoshi Shimodaira. Improving predictive inference under covariate shift by weighting the log-

likelihood function. Journal of statistical planning and inference, 90(2):227–244, 2000.

Baochen Sun and Kate Saenko. From virtual to reality: Fast adaptation of virtual object detectors to

real domains. In BMVC, volume 1, pp. 3, 2014.

Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consis-

tency targets improve semi-supervised deep learning results. 2017.

Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky. Instance normalization: The missing in-

gredient for fast stylization. arXiv preprint arXiv:1607.08022, 2016.

12

Published as a conference paper at ICLR 2018

David Vazquez, Antonio M Lopez, Javier Marin, Daniel Ponsa, and David Geronimo. Virtual and
real world adaptation for pedestrian detection. IEEE transactions on pattern analysis and machine
intelligence, 36(4):797–809, 2014.

Siamak Youseﬁ, Hirokazu Narui, Sankalp Dayal, Stefano Ermon, and Shahrokh Valaee. A survey
on behavior recognition using wiﬁ channel state information. IEEE Communications Magazine,
55(10):98–104, 2017.

Zhi-Hua Zhou and Ming Li. Tri-training: Exploiting unlabeled data using three classiﬁers. IEEE

Transactions on knowledge and Data Engineering, 17(11):1529–1541, 2005.

Xiaojin Zhu. Semi-supervised learning literature survey. 2005.

13

Published as a conference paper at ICLR 2018

A ARCHITECTURES

Layer Index

Small CNN

Large CNN

L − 18

L − 17

L − 16
L − 15
L − 14

L − 13
L − 12
L − 11

L − 10
L − 9
L − 8

L − 7
L − 6
L − 5

L − 4
L − 3
L − 2

L − 1

L − 0

32 × 32 × 3 Image

Instance Normalization (optional)

3 × 3 conv. 64 lReLU
3 × 3 conv. 64 lReLU
3 × 3 conv. 64 lReLU

3 × 3 conv. 96 lReLU
3 × 3 conv. 96 lReLU
3 × 3 conv. 96 lReLU

3 × 3 conv. 64 lReLU 3 × 3 conv. 192 lReLU
3 × 3 conv. 64 lReLU 3 × 3 conv. 192 lReLU
3 × 3 conv. 64 lReLU 3 × 3 conv. 192 lReLU

2 x 2 max-pool, stride 2
dropout, p = 0.5
Gaussian noise, σ = 1

2 x 2 max-pool, stride 2
dropout, p = 0.5
Gaussian noise, σ = 1

3 × 3 conv. 64 lReLU 3 × 3 conv. 192 lReLU
3 × 3 conv. 64 lReLU 3 × 3 conv. 192 lReLU
3 × 3 conv. 64 lReLU 3 × 3 conv. 192 lReLU

global average pool

10 dense, softmax

Domain Discriminator

Layer L − 5 Output

100 dense, ReLU

1 dense, sigmoid

Table 7: Domain discriminator architecture.

Table 6: Small and Large CNN architectures. Leaky ReLU parameter a = 0.1. All convolutional
and dense layers in the classiﬁer are pre-activation batch-normalized. All images are resized to 32
32
in which we observed that domain adversarial training appears to contract the feature space.

×
3. Note the use of additive Gaussian noise: this addition was motivated by initial experiments

×

14

Published as a conference paper at ICLR 2018

B HYPERPARAMETERS

We observed that extensive hyperparameter-tuning is not necessary to achieve state-of-the-art per-
formance. To demonstrate this, we restrict our hyperparameter search for each task to λd =
0, 10−2
, in all experiments with instance-normalized inputs.
{
We ﬁxed β = 10−2. Note that the decision to turn (λd, λs) on or off that can often be determined
a priori based on prior belief regarding the extent to covariate shift. In the absence of such prior
belief, a reliable choice is (λd = 10−2, λs = 1, λt = 10−2, β = 10−2).

10−2, 10−1
{

0, 1
}

, λs =

, λt =

}

{

}

Task

Instance-Normalized

λs

MNIST → MNIST-M
SVHN → MNIST
MNIST → SVHN
MNIST → SVHN
DIGITS → SVHN
SIGNS → GTSRB
CIFAR → STL
STL → CIFAR
Room A → B

Yes, No
Yes, No
Yes
No
Yes, No
Yes, No
Yes, No
Yes, No
Yes

λd
10−2
10−2
10−2
10−2
10−2
10−2
0
0
0

λt
10−2
10−2
10−2
10−2
10−1
10−2
10−1
10−1
10−2

β

10−2
10−2
10−2
10−3
10−2
10−2
10−2
10−2
10−2

0
0
1
1
1
1
1
0
0

Table 8: Hyperparameters for each task, both with and without instance-normalized input. The
SVHN without instance-normalized input. In this speciﬁc case, dH∆H
only exception is MNIST
is sufﬁciently large that conditional entropy minimization quickly ﬁnds a degenerate solution in
the target domain. To counter this, we remove conditional entropy minimization (but keep the
target-side virtual adversarial training) only during VADA. We apply target-side conditional entropy
minimization and virtual adversarial training during DIRT-T. To compensate, we use a lower β
during the DIRT-T phase to allow for larger natural gradient steps.

→

When the target domain is MNIST/MNIST-M, the task is sufﬁciently simple that we only allocate
B = 500 iterations to each optimization problem in Eq. (14). In all other cases, we set the reﬁnement
interval B = 5000. We apply Adam Optimizer (learning rate = 0.001, β1 = 0.5, β2 = 0.999)
with Polyak averaging (more accurately, we apply an exponential moving average with momentum
= 0.998 to the parameter trajectory). VADA was trained for 80000 iterations and DIRT-T takes
VADA as initialization and was trained for
iterations, with number
of iterations chosen as hyperparameter.

20000, 40000, 60000, 80000

}

{

C REPLACING GRADIENT REVERSAL

D(fθ(x))) is tends to have
We note from Goodfellow et al. (2014) that the gradient of
−∇θ ln D(fθ(x)) during initial training since the latter rescales the gradient by
smaller norm than
1/D(fθ(x)). Following this observation, we replace the gradient reversal procedure with alternating
minimization of

∇θ ln(1

−

min
D −
min

θ −

Ex∼Ds [ln D(fθ(x))]
Ex∼Dt [ln D(fθ(x))]

Ex∼Dt [ln 1
Ex∼Ds [ln 1

−

−

D(fθ(x))]

D(fθ(x))] .

−

−

The choice of using gradient reversal versus alternating minimization reﬂects a difference in choice
of approximating the mini-max using saturating versus non-saturating optimization (Fedus et al.,
2017). In some of our initial experiments, we observed the replacement of gradient reversal with al-
ternating minimization stabilizes domain adversarial training. However, we encourage practitioners
to try either optimization strategy when applying VADA.

D INSTANCE NORMALIZATION FOR DOMAIN ADAPTATION

Theorem 1 suggests that we should identify ways of constraining the hypothesis space without hurt-
ing the global optimal classiﬁer for the joint task. We propose to further constrain our model by

15

Published as a conference paper at ICLR 2018

introducing instance normalization as an image pre-processing step for the input data.
normalization was proposed for style transfer Ulyanov et al. (2016) and applies the operation

Instance

(cid:96)(x(i)) =

x(i)

µ(x(i))

−
σ(x(i))

,

∈

RH×W ×C denotes the ith sample with (H, W, C) corresponding to the height, width,
where x(i)
and channel dimensions, and where µ, σ : RH×W ×C
RC are functions that compute the mean
and standard deviation across the spatial dimensions. A notable property of instance normalization
is that it is invariant to channel-wide scaling and shifting of the input elements. Formally, consider
scaling and shift variables γ, β

0 and σ(x(i))

RC. If γ

0, then

→

∈

(cid:31)

(cid:31)
(cid:96)(x(i)) = (cid:96)(γx(i) + β).

For visual data the application of instance normalization to the input layer makes the classiﬁer in-
variant to channel-wide shifts and scaling of the pixel intensities. For most visual tasks, sensitivity to
channel-wide pixel intensity changes is not critical to the success of the classiﬁer. As such, instance
normalization of the input may help reduce dH∆H without hurting the globally optimal classiﬁer.
Interestingly, Figure 3 shows that input instance normalization is not equivalent to gray-scaling,
since color is partially preserved. To test the effect of instance normalization, we report results both
with and without the use of instance-normalized inputs.

E LIMITATION OF DOMAIN ADVERSARIAL TRAINING

We denote the source and target distributions respectively as ps(x, y) and pt(x, y). Let the source
covariate distribution ps(x) deﬁne the random variable Xs that have support supp(Xs) =
Xs and
Xt are subsets of Rn. Let
let (Xt,
ps(y) and pt(y) deﬁne probabilities over the support
. We consider any embedding
function f : Rn
, where

Xs and
}
1)-simplex. We denote a classiﬁer h = g

1, . . . , K
=
{
Rm, where Rm is the embedding space, and any embedding classiﬁer g : Rm

Xt) be analogously deﬁned for the target domain. Both

→
f has the composite of an

→
is the (K

Y

C
−
embedding function with an embedding classiﬁer.

C

◦

For simplicity, we restrict our analysis to the simple case where K = 2, i.e. where
Furthermore, we assume that for any δ
∈
We impose a similar condition on pt(x).

[0, 1], there exists a subset Ω

Y
Rn where ps(x

⊆

∈

=

0, 1
.
{
}
Ω) = δ.

For a joint distribution p(x, y), we denote the generalization error of a classiﬁer as
(cid:15)p(h) = E

h(x)

y

.

Note that for a given classiﬁer h : Rn
1
{

. We further deﬁne the set Ω
h(x) > 0.5
}

→
⊆

−

p(x,y) |
[0, 1], the corresponding hard classiﬁer is k(x) =
Rn such that

|

In a slight abuse of notation, we deﬁne the generalization error (cid:15)(Ω) with respect to Ω as

Ω =

x
{

∈

Rn

|

k(x) = 1

} ⇐⇒

k(x) = 1
{

x

Ω

.

}

∈

An optimal Ω∗

p is a partitioning of Rn

(cid:15)p(Ω) = E

p(x,y)1

Ω

= (cid:15)(k).

x
{

∈

}

(cid:15)p(Ω∗

p) = min
Ω⊆Rn

(cid:15)p(Ω)

such that generalization error under the distribution p(x, y) is minimized.

E.1 GOOD TARGET-DOMAIN ACCURACY IS NOT GUARANTEED

Domain adversarial training seeks to ﬁnd a single classiﬁer h used for both the source ps and target
pt distributions. To do so, domain adversarial training sets up the objective

(15)

(16)

(17)

(18)

(19)

(20)

(21)

(22)

min
f ∈F ,g∈G

(cid:15)ps(g

f )

◦
s.t. g(Xs) = g(Xt),

16

Published as a conference paper at ICLR 2018

G

F

and

where
are the hypothesis spaces for the embedding function and embedding classiﬁer. In-
tuitively, domain adversarial training operates under the hypothesis that good source generalization
error in conjunction with source-target feature matching implies good target generalization error.
We shall see, however, that if
is sufﬁciently complex, this implication does not
necessarily hold.

Xs ∩ Xt = ∅ and

F

contain all functions mapping Rn

Rm, i.e.

has inﬁnite capacity. Suppose

contains

F

Let
the function g(z) = 1
∗ = (cid:8)g

H

z = 1m}
{
g
f
| ∃

∈ G

◦

and

, f

→

F
Xs ∩ Xt = ∅. We consider the set
f )
◦
∈ F

(cid:15)ps(Ω∗
ps

s.t. (cid:15)ps (g

≤

), f (Xs) = f (Xt)(cid:9) .

(23)

G

Such a set of classiﬁers satisﬁes the feature-matching constraint while achieving source general-
∗
ization error no worse than the optimal source-domain hard classiﬁer. It sufﬁces to show that
includes hypotheses that perform poorly in the target domain.

H

∗ is not an empty set by constructing an element of this set. Choose a partitioning

We ﬁrst show
Ω where

H

Consider the embedding function

pt(x

Ω) = ps(x

∈

Ω∗
ps

).

∈

fΩ(x) =

(cid:26)1m if (x

0m otherwise.

∈ Xs ∩

Ω∗
ps

)

(x

∨

∈ Xt ∩

Ω)

Let g(z) = 1

z = 1m}
{

. It follows that the composite classiﬁer hΩ = g

fΩ is an element of

◦

Next, we show that a classiﬁer h
Consider the partitioning ˆΩ which solves the following optimization problem

∗ does not necessarily achieve good target generalization error.

∈ H

Such a partitioning ˆΩ is the worst-case partitioning subject to the probability mass constraint. It
follows that worse case h(cid:48)

max
Ω⊆Rn

(cid:15)pt(Ω)

s.t. pt(x

Ω) = ps(x

∈

Ω∗
ps

).

∈

∈ H

∗ has generalization error
(cid:15)pt(h(cid:48)) = max
h∈H∗

(cid:15)pt(h)

≥

(cid:15)pt(h ˆΩ).

To provide intuition that (cid:15)pt(h(cid:48)) is potentially very large, consider hypothetical source and target
Ω∗
) = 0.5. The worst-case partitioning
) = ps(x
domains where
ps
subject to the probability mass constraint is simply ˆΩ = Rn
pt (which ﬂips the labels) and
consequently,

Xs ∩ Xt = ∅ and pt(x
∗ contains solutions

Ω∗
pt

Ω∗

∈

∈

\

H

no better than the worst-case partitioning of the target domain.

max
h∈H∗

(cid:15)pt(h)

1

≥

−

(cid:15)pt(Ω∗
pt

)

E.2 CONNECTION TO THEOREM 1

Let
the function g(z) = 1

F

contain all functions mapping Rn

Rm, i.e.

has inﬁnite capacity. Suppose

contains

G

and

z = 1m}
{
=
g
H
◦
{
¯
H

=

◦

g

f

f

→

F
Xs ∩ Xt = ∅. We consider the sets
g
∈ G
g
| ∃

s.t. f (Xs) = f (Xt)

∈ F}

∈ F

∈ G

, f

, f

|

.

{
A justiﬁcation for domain adversarial training is that the ¯
H

-divergence term is smaller than the
-divergence, thus yielding a tighter upper bound for Theorem 1. However, we shall see that
∆ ¯
H

-divergence term is in fact maximal.

∆ ¯
H

}

∆
H
H
the ¯
H
Choose partitionings Ωs, Ωt ⊆

Rn such that

(24)

(25)

∗.

H

(26)

(27)

(28)

(29)

(30)

(31)

(32)

ps(x

Ωs) = pt(x

Ωt) = 0.5.

∈

∈

17

Published as a conference paper at ICLR 2018

(33)

(34)

◦

(35)
(36)

Deﬁne the embedding functions

∈ Xs ∩

Ωs)

(x

Ωt)

∈ Xt ∩

f (x) =

f (cid:48)(x) =

(cid:26)1m if (x

0m otherwise.

(cid:26)1m if (x

0m otherwise.

∨

∨

∈ Xs ∩

Ωs)

(x

∈ Xt ∩

(Rn

Ωt))

\

Let g(cid:48)(z) = g(z) = 1
{
are elements of ¯
H

.

z = 1m}

From the deﬁnition of dH∆H, we see that

. It follows that the composite classiﬁers h = g

f and h(cid:48) = g(cid:48)

f (cid:48)

◦

2
d ¯H∆ ¯H ≥
= 2

Ex∼Xs [h(x)
|
= 2.
1
0
|
· |

−
-divergence thus achieves the maximum value of 2.

= h(cid:48)(x)]

Ex∼Xt [h(x)

−

= h(cid:48)(x)]
|

The ¯
H

∆ ¯
H

E.3

IMPLICATIONS

Our analysis assumes inﬁnite capacity embedding functions and the ability to solve optimization
problems exactly. The empirical success of domain adversarial training suggests that the use of
ﬁnite-capacity convolutional neural networks combined with stochastic gradient-based optimization
provides the necessary regularization for domain adversarial training to work. The theoretical char-
acterization of domain adversarial training in the case ﬁnite-capacity convolutional neural networks
and gradient-based learning remains a challenging but important open research problem.

F NON-VISUAL DOMAIN ADAPTATION TASK

To evaluate the performance of our models on a non-visual domain adaptation task, we applied
VADA and DIRT-T to the Wi-Fi Activity Recognition Dataset (Youseﬁ et al., 2017). The Wi-Fi
Activity Recognition Dataset is a classiﬁcation task that takes the Wi-Fi Channel State Information
(CSI) data stream as input x to predict motion activity within an indoor area as output y. The dataset
collected the CSI data stream samples associated with seven activities, denoted as “bed”, “fall”,
“walk”, “pick up”, “run”, “sit down”, and “stand up”.

However, the joint distribution over the CSI data stream and motion activity changes depending
on the room in which the data was collected. Since the data was collected for multiple rooms,
we selected two rooms (denoted here as Room A and Room B) and constructed the unsupervised
domain adaptation task by using Room A as the source domain and Room B as the target domain.
We compare the performance of DANN, VADA, and DIRT-T on the Wi-Fi domain adaptation task
in Table 2, using the hyperparameters (λd = 0, λs = 0, λt = 10−2, β = 10−2).
Table 2 shows that VADA signiﬁcantly improves classiﬁcation accuracy compared to Source-Only
and DANN. However, DIRT-T does not lead to further improvements on this dataset. We believe this
is attributable to VADA successfully pushing the decision boundary away from data-dense regions
in the target domain. As a result, further application of DIRT-T would not lead to better decision
boundaries. To validate this hypothesis, we visualize the t-SNE embeddings for VADA and DIRT-T
in Figure 6 and show that VADA is already capable of yielding strong clustering in the target domain.
To verify that the decision boundary indeed did not change signiﬁcantly, we additionally provide the
confusion matrix between the VADA and DIRT-T predictions in the target domain (Fig. 7).

18

Published as a conference paper at ICLR 2018

(a) VADA

(b) DIRT-T

Figure 6: T-SNE plot of the last hidden layer for Room A (blue)

Room B (red)

→

Figure 7: Confusion matrix between VADA and and DIRT-T prediction labels.

19

