8
1
0
2
 
n
u
J
 
6
2
 
 
]

G
L
.
s
c
[
 
 
1
v
9
1
9
9
0
.
6
0
8
1
:
v
i
X
r
a

Tangent-Space Regularization for Neural-Network Models of Dynamical Systems

Fredrik Bagge Carlson

Rolf Johansson

Anders Robertsson

Abstract— This work introduces the concept of tan-
gent space regularization for neural-network models
of dynamical systems. The tangent space to the dy-
namics function of many physical systems of interest
in control applications exhibits useful properties, e.g.,
smoothness, motivating regularization of the model
Jacobian along system trajectories using assumptions
on the tangent space of the dynamics. Without as-
large amounts of training data are re-
sumptions,
quired for a neural network to learn the full non-linear
dynamics without overﬁtting. We compare diﬀerent
network architectures on one-step prediction and sim-
ulation performance and investigate the propensity of
diﬀerent architectures to learn models with correct
input-output Jacobian. Furthermore, the inﬂuence
of L2 weight regularization on the learned Jacobian
eigenvalue spectrum, and hence system stability, is
investigated.

I. Introduction

Dynamical control systems are often described in
continuous time by diﬀerential state equations on the
form

˙x(t) = fc

(cid:0)x(t), u(t)(cid:1)

where x is a Markovian state-vector, u is the input and
fc is a function that maps the current state and input to
the state time-derivative. An example of such a model is
a rigid-body dynamical model of a robot

¨x = −M −1(x)(cid:0)C(x, ˙x) ˙x + G(x) + F ( ˙x) − u(cid:1)

(1)

where M, C, G and F model phenomena such as inertia,
Coriolis, gravity and friction.

In the discrete time domain, we may consider models

on the form

xt+1 = f (cid:0)xt, ut

(cid:1)

(2)

where f is a function that maps the current state and
input to the state at the next time-instance. Learning a
globally valid dynamics model ˆf of an arbitrary non-
linear system f with little or no prior information
is a challenging problem. Although in principle, any
suﬃciently complex function approximator, such as a
deep neural network (DNN), could be employed, high
demands are put on the amount of data required to
prevent overﬁtting and obtain a faithful representation
of the dynamics over the entire state space.

In many applications, the linearization of f is im-
portant, a typical example being linear control design.

Open-source implementations of all presented methods and
examples in this paper are made available at [1]. The authors are
members of the LCCC Linnaeus Center and the eLLIIT Excellence
Center at Lund University, Dept Automatic Control, Lund Sweden
Fredrik.Bagge_Carlson@control.lth.se

Identiﬁcation of f must thus not only yield a good
model for prediction/simulation, but also the Jacobian
J ˆf of ˆf must be close to the true system Jacobian J. In
applications such as iterative learning control (ILC) and
trajectory centric, episode-based reinforcement learning
(TCRL), the linearization of the nonlinear dynamics along
a trajectory is often all that is needed for optimization.
Linear time-varying (LTV) models on the form

xt+1 = Atxt + Btut

(3)

where the matrices A and B constitute the output
Jacobian, can be learned (data-)eﬃciently, in special cases
extremely (time-)eﬃciently using dynamic programming
[2]. A problem with learning an LTV model around a ﬁnite
length trajectory is insuﬃcient excitation provided by the
control input. Prior knowledge regarding the evolution
of the dynamics, encoded in form of carefully designed
regularization, is required in order to obtain a well-posed
optimization problem and a meaningful result. When
model identiﬁcation is a sub task in an outer algorithm
that optimizes a control-signal trajectory or a feedback
policy, excessive noise added for identiﬁcation purposes
may be undesirable, making regularization solely over
time as in [2] insuﬃcient.

The discussion so far indicates two issues open for
future work. 1) Complex non-linear models have the
potential to be valid globally, but may suﬀer from
overﬁtting and thus not learn a function with the correct
linearization. 2) LTV models can be learned eﬃciently
and can represent the linearized dynamics well, but are
time-based and valid only locally.

In this work, we make use of the regularization methods
detailed in [2] for incremental learning of a general, non-
linear black-box model, ˆf . We further develop a method
to perform sampled tangent-space regularization for use
with deep-learning frameworks without support for higher-
order derivatives. To this end, we consider an episode-
based setting where the dynamical model is updated
after each episode. Each episode, a new trajectory τi =
{xt, ut}T
t=1 is obtained, to which we ﬁt an LTV model, li,
on the form (3) using the methods presented in [2]1 – this
model will provide the regularization for the non-linear
model. We then update the non-linear state-space model
ˆf by adding τi to the set of training data for ˆf , while using
li, which we assume have learned a good approximation
of J along τi, for tangent-space regularization of J ˆf .

We proceed to introduce the problem of learning a
dynamics model ˆf in Section II. We then introduce tan-

1github.com/baggepinnen/LTVModels.jl

gent space regularization in Section III and ﬁnally discuss
the inﬂuence of weight decay on diﬀerent formulations
of the learning problem before conducting numerical
evaluations.

II. Estimating the global model

To frame the learning problem we let the dynamics of
a system be described by a neural-network ˆf to be ﬁtted
to input-output data τ according to

Learning Objective 1:

xt+1 = ˆf (xt, ut) ∈ Rn

which we will frequently write on the form x+ = ˆf (x, u) by
omitting the time index t and letting ·+ indicate ·t+1. We
further consider the linearization of ˆf around a trajectory

To gain insight into how this seemingly trivial change
in representation may aﬀect performance, we note that
this transformation will alter the Jacobian according to
Jg = (cid:2)A − In B(cid:3)

(7)

with a corresponding unit reduction of the eigenvalues
of A. For systems with integrators, or slow dynamics in
general, this transformation leads to a better conditioned
estimation problem [4]. In Section V we investigate
whether or not this transformation leads to a better
prediction/simulation result and whether modern neural
network training techniques such as the ADAM optimizer
[5] and batch normalization [6] render this transformation
superﬂuous. We further investigate how weight decay
aﬀects the eigenvalue spectrum of the Jacobian of f and
g and hence, system stability.

xt+1 = Atxt + Btut
kt = vec ((cid:2)AT
t BT
t

(cid:3))

(4)

A. Optimization landscape

where the matrices A and B constitute the input-output
Jacobian Jf of f

Jf =






∇xf T
...
∇xf T

1 ∇uf T
1
...
n ∇uf T
n


 ∈ Rn×(n+m) = (cid:2)A B(cid:3)


(5)

Our estimate ˆf (x, u, w) of f (x, u) will be parameterized
by a vector w. The distinction between f and ˆf will,
however, be omitted unless required for clarity.

We frame the learning problem as an optimization
problem with the goal of adjusting the parameters w of
ˆf to minimize a cost function V (w) by means of gradient
descent. The cost function V (w) can take many forms,
but we will limit the scope of this article to quadratic
loss functions of the one-step prediction error, i.e.,

V (w) =

(cid:0)x+ − ˆf (x, u, w)(cid:1)T(cid:0)x+ − ˆf (x, u, w)(cid:1) (6)

1
2

X

t

It is well known that the Jacobian of the discrete-
time model f has eigenvalues diﬀerent from that of
the continuous-time counterpart fc. In particular, if the
sample rate is high, most eigenvalues2 of fc are close
to 0. The eigenvalues for the discrete-time f however
tend to cluster around 1 when sample rate is high.
Another formulation of the discrete-time model, which
we introduce as a new learning objective, is

Learning Objective 2:

x+ − x = ∆x = g(x, u)
f (x, u) = g(x, u) + x
with the second form being equivalent to the ﬁrst, but
highlighting a convenient implementation form that does
not require transformation of the data. Classical theory for
sampling of linear systems indicates that the eigenvalues
of g tend to those of fc as sample rate increases [3].

2We take the eigenvalues of a function to refer to the eigenvalues

of the function Jacobian.

To gain insight into the training of f and g, we analyse
the expressions for the gradients and Hessians of the cost
functions. For a linear model x+ = Ax + Bu and a least-
squares cost-function V (θ) = 1
2 (y − Φθ)T(y − Φθ), where
the linear model is written on regressor form y = Φθ with
all parameters of A and B concatenated into the vector
θ, the gradient and the Hessian are given by

∇θV = −ΦT(y − Φθ)
∇2

θV = ΦTΦ

(8)

(9)

The Hessian is clearly independent of both the output y
and the parameters θ and diﬀerentiating the output does
not have any major impact on gradient-based learning.
For a nonlinear model, this is not necessarily the case:

V (w) =

(cid:0)x+ − f (x, u, w)(cid:1)T(cid:0)x+ − f (x, u, w)(cid:1) (10)

∇wV =

−(cid:0)x+

i − fi(x, u, w)(cid:1)∇wfi

∇2

wV =

∇wfi∇wf T

i − (cid:0)x+

i − fi(x, u, w)(cid:1)∇2

wfi

In this case, the Hessian depends on both the parameters
and the target x+. The transformation from f to g
changes the gradients and Hessians according to

∇wV =

−(cid:0)∆xi − gi(x, u, w)(cid:1)∇w(gi)

(13)

∇2

wV =

∇wgi∇wgT

i − (cid:0)∆xi − gi(x, u, w)(cid:1)∇2

wgi

Since the output of g is closer to zero compared to f
for systems of lowpass character, i.e., where (cid:13)
(cid:13) is
small, the transformation can be seen as preconditioning
the problem by decreasing the inﬂuence of the term

(cid:13)∆x(cid:13)

1
2

X

t

T
X

n
X

t=1
T
X

i=1
n
X

t=1

i=1

T
X

n
X

t=1
T
X

i=1
n
X

t=1

i=1

(11)

(12)

(14)

wg = ∇2

∇2
wf in the Hessian.3 With only the positive semi-
deﬁnite term ∇w(g)∇w(g)T = ∇w(f )∇w(f )T correspond-
ing to ΦTΦ in the linear case remaining, the optimization
problem becomes easier. Similarly, g starts out closer to
a critical point ∇wV = 0, making convergence rapid.

III. Tangent-space regularization

For systems where the function f is known to be
smooth, the Jacobian Jf (t) will vary slowly. In the rigid-
body dynamical model (1), for instance, the intertial and
gravitational forces are changing smoothly with the joint
conﬁguration. A natural addition to the cost function of
the optimization problem would thus be a tangent-space
regularization term on the form

X

(cid:13)
(cid:13) ˆJt+1 − ˆJt

(cid:13)
(cid:13)

t

(15)

which penalizes change in the input-output Jacobian of
the model over time, a strategy we refer to as Jacobian
propagation. A somewhat related strategy was proposed
in [7], where a tangent-dependent term in the cost
function was successfully used to enforce invariance of an
image classiﬁer to rotations and translations of the input
image.

Taking the gradient of terms depending on the model
Jacobian requires calculation of higher order derivatives.
Depending on the framework used for optimization, this
can limit the applicability of the method. We thus
proceed to describe a sampled version of tangent space
regularization requiring only ﬁrst order gradients.

(cid:13)
(cid:13)J ˆf (t) − ˆJf (t)
(cid:13)

Estimation of an LTV model with the regularization
term (15) is straightforward and is the subject of [2].
Given a good estimate ˆJf (t) provided by an LTV model,
one may regularize the learning of f by penalizing
(cid:13)
P
(cid:13)
(cid:13). An approximation to Jacobian prop-
t
agation is obtained by augmenting the dataset with input
data perturbed in the direction of the Jacobian. For the
regression task at hand, we can implement such a strategy
by perturbing the input data {˜x, ˜u} = {x + (cid:15)x, u + (cid:15)u} by
some small noise terms (cid:15), and generating a new target4
x+ using the LTV model ˜x+ = A˜x + B ˜u. If this was
done for each component of x and u separately, this
would correspond exactly to ﬁnite-diﬀerence Jacobian
propagation. However, due to the smoothness assumption
of f together with the smooth inductive bias of neural
networks, we get reasonable results by only perturbing
each input instance by a small Gaussian random vector.
We refer to this strategy as sampled Jacobian propagation.
Section V demonstrates how this approach enables learn-
ing of neural-network models with high-ﬁdelity Jacobians.
The procedure is summarized in Algorithm 1.

3In the beginning of learning, the output of ˆg is small due to the

initialization of w.

4New targets can be sampled each epoch.

Algorithm 1 An algorithm for eﬃcient learning of a
nonlinear neural-network dynamics model. The sampling
of a rollout may entail using the estimated models for,
e.g., iterative learning control, trajectory optimization or
reinforcement learning.
Initialize a model ˆf .
loop

Sample rollout trajectory τi = {xt, ut}T
Fit LTV model li using method in [2]
Generate perturbed trajectories ˜τi = {˜xt, ˜ut} using li.
Fit ˆf to τi and ˜τi
(Optimize controller or control signal trajectory)

t=1

end loop

IV. Weight decay

Weight decay is commonly an integral part of model
ﬁtting used to combat overﬁtting, and can be thought of as
either penalizing complexity of the model or as encoding
prior knowledge about the size of the model coeﬃcients.
L2 weight decay is, however, a blunt weapon. While often
eﬀective at mitigating overﬁtting, the procedure might
introduce a bias in the estimate. Since the bias always
is directed towards smaller weights, it can have diﬀerent
consequences depending on what small weights imply
for a particular model architecture. For a discrete-time
model f , small weights imply small eigenvalues and a
small output. For x+ = g(x, u) + x, on the other hand,
small weights imply eigenvalues closer to 1. Weight decay
thus has a vastly diﬀerent eﬀect on learning f and g, and
since a high sample rate implies eigenvalues closer to 1,
weight decay is likely to bias the result of learning g in a
milder way as compared to when learning f . We explore
the eﬀect of weight decay in the next section by ﬁtting
models to data generated by linear systems.

A natural question to ask is if weight decay can bias the
eigenvalues of the learned function to arbitrary chosen
locations. A generalized form of model formulation is
x+ − Ax − Bu = h(x, u) where A and B can be seen
as a nominal linear model around which we learn the
nonlinear behavior. Weight decay will for this formulation
bias the Jacobian towards A and B which can be chosen
arbitrarily. Obviously, choosing a nominal linear model
is not always easy, and may in some cases not make
sense. One can however limit the scope to formulations
like x+ − τ x = h(x, u), where τ is a scalar or a diagonal
matrix that shifts the nominal eigenvalues along the real
axis to, e.g., encourage stability.

V. Evaluation

The previously described methods were evaluated on
two benchmarks problems. We compared performance on
one-step prediction as well as simulation from a known
initial condition. We further compared the ﬁdelity of
the Jacobian of the estimated models, an important
property for optimization algorithms making use of the
models. The benchmarks consist of a simulated robot
arm with two revolute joints, friction and gravity and

Algorithm 2 Generation of random, stable linear sys-
tems.

0 skew-symmetric = pure imaginary eigenvalues

A0 = 10 × 10 matrix of random coeﬃcients
A = A0 − AT
A = A − ∆t I make ’slightly’ stable
A = exp(∆t A) discrete time, sample time ∆t
B = random coeﬃcients

randomized, stable linear systems. Code to reproduce
results are presented in the online repository.

We initially describe a baseline neural network approx-
imator used in the experimental evaluation which we
use to draw conclusions regarding the diﬀerent learning
objectives. We describe how deviations from this baseline
model alter the conclusions drawn in Appendix II. The
ﬁrst examples demonstrate the eﬀectiveness of tangent-
space regularization, whereas later examples demonstrate
the inﬂuence of weight decay.

A. Nominal model

Both functions f and g are modeled as ensembles,
E, of 4 distinct single-layer neural networks with 20
neurons each. The 4 networks in the ensemble are trained
on the same data with the same objective function,
but with diﬀerent random initializations of the weights
and diﬀerent non-linear activation functions.5 After a
comparative study of 6 diﬀerent activation functions,
presented in Appendix I, we selected networks with the
activation functions elu, sigmoid, tanh and swish to form
the components of the ensemble E. We train the models
using the ADAM optimizer with a ﬁxed step-size and ﬁxed
number of epochs, 2000 for f and 1000 for g. The entire
framework including all simulation experiments reported
in this article is published at [1] and is implemented in
the Julia programming language [8] and the Flux machine
learning library.6

When training with tangent-space regularization, a

single perturbed trajectory was added with

{(cid:15)x, (cid:15)u} ∼ N (cid:0)0, (cid:8)0.12 diag Σx, 0.12 diag Σu

(cid:9) (cid:1)

and the network was trained for half the number of epochs
compared to the nominal baseline model.

B. Randomized linear system

To assess the eﬀectiveness of sampled Jacobian propa-
gation we create random, stable linear systems according
to Algorithm 2 and evaluate the Jacobian of the learned
model for points sampled randomly in the state space. The
results are illustrated in Fig. 1. During training, the model
trained without tangent-space regularization reaches far
lower training error, but validation data indicate that
overﬁtting has occurred. The model trained with tangent-
space regularization learns better Jacobians and produces
smaller prediction- and simulation errors.

5The variation in the ensemble predictions may serve as a

bootstrap estimate of the variance of the estimator.

6github.com/FluxML/Flux.jl

Fig. 1. Learned Jacobian eigenvalues of g for randomly sampled
points in the state-space (blue) together with the eigenvalues of
the true model (red). Tangent-space regularization (right) leads
to better estimation of the Jacobian with eigenvalues in a tighter
cluster around the true eigenvalues close to the unit circle.

The eﬀect of weight decay on the learned Jacobian is
illustrated in Fig. 2. Due to overparamterization, heavy
overﬁtting is expected without adequate regularization.
Not only is it clear that learning of g has been more
successful than learning of f in the absence of weight
decay, but we also see that weight decay has had a
deteriorating eﬀect on learning f , whereas it has been
beneﬁcial in learning g. This indicates that the choice of
architecture interacts with the use of standard regulariza-
tion techniques and must be considered while modeling.

Fig. 2. Eigenvalues of learned Jacobians for the linear system task.
The top/bottom rows shows models trained without/with weight
decay, left/right columns show f /g. Weight decay has deteriorating
eﬀect on learning f , pulling the eigenvalues towards 0, while being
beneﬁcial for learning g, keeping the eigenvalues close to 1 on the unit
circle. All models are trained with sampled Jacobian propagration.

C. Robot task

The robot has non-linear dynamics and thus a changing
Jacobian7 along a trajectory. This task demonstrates the
utility of tangent-space regularization for systems where
the regularization term is not the theoretically perfect
choice, as was the case with the linear system. We simulate

7We are referring to the Jacobian of the dynamics, as opposed to

the Jacobian of the forward kinematic encountered in robotics.

Standard

Jacobian Propagation

Jacobian error (validation data)

Standard
Jacobian Propagation

)
S
M
R
n
o
i
t
c
i
d
e
r
P
(
g
o
l

0.0
-0.2
-0.4
-0.6
-0.8

)
S
M
R
n
o
i
t
a
l
u
m
i
S
(
g
o
l

1.5
1.0
0.5
0.0
-0.5

f

g

f

g

Fig. 3. Distribution of prediction and simulation errors on the
validation data for the robot task. Each violin represents 35 Monte-
Carlo runs. The ﬁgure indicates that tangent-space regularization
through tangent-space regularization stabilizes learning and reduces
both one-step prediction error and simulation error.

the system with a low-pass ﬁltered random input and
compare prediction and simulation error as well as the
error in the estimated Jacobian.

The prediction and simulation errors for validation
data,
i.e., trajectories not seen during training, are
shown in Fig. 3. The results indicate that tangent-space
regularization leads to reduced prediction and simulation
errors compared to baseline, with lower mean error
and smaller spread, indicating more robust learning. In
particular, divergence of the state was encountered during
some simulations of the baseline model, a behavior which
was not encountered for models trained with tangent-
space regularization.

To assess the ﬁdelity of the learned Jacobian, we
average the input-output Jacobian over the ensemble
E and compare it to the ground-truth Jacobian of the
simulator. We display the distribution of errors in the
estimated Jacobians over 35 Monte-Carlo runs8 in Fig. 4.
The error was calculated as the mean over time steps
of the Frobenius norm of the diﬀerence in coeﬃcients
between the true Jacobian and the ensemble average
Jacobian:

v
u
u
t

1
T

(cid:13)
(cid:13)
(cid:13)
(cid:13)

X

t

Jt −

1
|E|

P
E

ˆJt

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

F

(16)

The results show a signiﬁcant beneﬁt of tangent-space
regularization over baseline, with a reduction of the mean
error as well as a smaller spread of errors, indicating a
more stable and reliable training.

VI. Discussion

We note that g generally trains faster and reaches a
lower value of the objective function compared to f . The
structure of g resembles that of a residual network [9],
where a skip connection is added between the input and a
layer beyond the ﬁrst adjacent layer, in our case, directly
to the output. While skip connections have helped to
enable successful training of very deep architectures for
tasks such as image recognition, we motivated the beneﬁt
of the skip connection with classical theory for sampling

8The number was chosen based on the number of cores available.

S
M
R
n
a
i
b
o
c
a
J

0.18

0.15

0.12

0.09

f

g

Fig. 4. Distribution of errors in estimated Jacobians (Eq. (16)).
Each violin represents 35 Monte-Carlo runs. Networks trained with
tangent-space regularization exhibit signiﬁcantly less error in the
estimated Jacobians compared to networks trained the conventional
way.

of continuous-time systems [3] and an analysis of the
model Hessian. Exploring the similarities with residual
networks remains an interesting avenue for future work.
The scope of this article was limited to settings where a
state-sequence is known. In a more general setting, learn-
ing the transformation of past measurements and inputs
to a state-representation is required and networks with
recurrence (RNNs) are required. Initial results indicate
that the conclusions drawn regarding the formulation (f
vs. g) of the model and the eﬀect of weight decay remains
valid in the RNN setting, but a more detailed analysis is
the target of future work.

VII. Conclusions

We have demonstrated how tangent-space regulariza-
tion by means of sampled Jacobian propagation can be
used to regularize the learning of a neural network model
of a dynamical system with an increase in prediction and
simulation performance as well as increasing the ﬁdelity
of the learned Jacobians as result.

We investigated diﬀerent architectures of the NN model
and found that the relationship between sample time
and system bandwidth aﬀects the preferred choice of
architecture, where one approximator architecture (g)
train faster and generally generalize better in terms of all
metrics if the sample rate is high. An analysis of gradient
and Hessian expressions motivated the diﬀerence and
conclusions were reinforced by experiment with diﬀerent
sample rates.

The eﬀect of including L2 weight decay was investigated
and shown to vary greatly with the model architecture.
Implications on the stability and eigenvalues of the learned
model highlights the need to consider the architecture
choice carefully.

Appendix I
Comparison of activation functions

Figure 5 displays the distribution of prediction errors
over 200 Monte-Carlo runs with diﬀerent random seeds

1.0
0.0
-1.0
-2.0

1.0
0.0
-1.0
-2.0

f

g

σ

relu

tanh

elu

swish

leakyrelu

σ

relu

tanh

elu

swish

leakyrelu

σ

relu

tanh

elu

swish

leakyrelu

Fig. 5. Distributions (cropped at extreme values) of log-prediction errors on the validation data after 20, 500 and 1500 (left, middle, right)
epochs of training for diﬀerent activation functions. Every violin is representing 200 Monte-Carlo runs and is independently normalized
such that the width is proportional to the density, with a ﬁxed maximum width.

and diﬀerent activation functions. The results indicate
that the relu and leaky relu functions are worse suited
for the considered task and are thus left out from the set
of selected bootstrap ensemble activation functions.

Appendix II
Deviations from the nominal model

Sample rate: The sample rate determines the location
of the eigenvalues of the Jacobian for a discrete-time
dynamical system. Faster sampling moves the eigenvalues
closer to 1, with implications for numerical accuracy
for very small sampling times [4]. Faster sampling also
leads to a function g closer to zero and f closer to 1.
With 5 times slower sampling, the diﬀerence between f
and g in prediction performance was less pronounced
for the validation data and both methods performed
comparably with respect to the estimated Jacobians. With
5 times faster sampling, method g performs much better
on prediction and Jacobian estimation but much worse
on simulation.

Number of neurons: Doubling or halving the number

of neurons generally led to worse performance.

Number of layers: Adding a fully connected layer
with the same number of neurons did not change any
conclusions.

Dropout: Inclusion of dropout (20%) increases predic-
tion and simulation performance for g while performance
is decreased for f . Performance on Jacobian estimation
was in general worse.

Layer normalization: Prediction and simulation per-
formance remained similar or slightly worse, whereas
Jacobian estimation broke down completely.

Measurement noise: Although not a hyper parameter,
we investigate the inﬂuence of measurement noise on the
identiﬁcation results. Increasing degree of measurement
noise degrades all performance metrics in predictable
ways and does not change any qualitative conclusions.

Ensemble size: A three times larger ensemble of network
yields marginally better performance on all metrics, with
a three times longer training time.

Number of perturbed trajectories for sampled Jacobian
propagation: We found that sampling a single trajectory
was suﬃcient and adding additional samples did not alter
the performance signiﬁcantly. A larger state dimension
might require more samples, although we have not
quantiﬁed this.

Optimizer, Batch normalization, Batch size: Neither of
these modiﬁcations altered the performance signiﬁcantly.

References

[1] F. Bagge Carlson, “Jacprop.jl,” 2018.

[Online]. Available:

https://github.com/baggepinnen/JacProp.jl

[2] F. Bagge Carlson, A. Robertsson, and R. Johansson, “Identiﬁ-
cation of LTV dynamical models with smooth or discontinuous
time evolution by means of convex optimization,” in IEEE
International Conference on Control and Automation (ICCA),
Anchorage, 2018.

[3] R. Middleton and G. Goodwin, “Improved ﬁnite word length
characteristics in digital control using delta operators,” IEEE
Transactions on Automatic Control, 1986.

[4] K. J. Åström and B. Wittenmark, Computer-controlled systems:

theory and design. Dover, New York, 2011.

[5] D. Kingma and J. Ba, “Adam: A method for stochastic opti-

mization,” arXiv preprint arXiv:1412.6980, 2014.

[6] S. Ioﬀe and C. Szegedy, “Batch normalization: Accelerating
deep network training by reducing internal covariate shift,” in
International Conference on Machine Learning, 2015, pp. 448–
456.

[7] P. Simard, Y. LeCun, J. Denker, and B. Victorri, “Transforma-
tion invariance in pattern recognition – tangent distance and
tangent propagation,” Neural networks: tricks of the trade, pp.
549–550, 1998.

[8] J. Bezanson, A. Edelman, S. Karpinski, and V. B. Shah, “Julia: A
fresh approach to numerical computing,” SIAM Review, vol. 59,
no. 1, pp. 65–98, 2017.

[9] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning
for image recognition,” in IEEE Conf. on Computer Vision and
Pattern Recognition, 2016, pp. 770–778.

