Optimizing groups of colluding strong attackers in mobile urban communication networks
with evolutionary algorithms(cid:73)

Doina Bucura, Giovanni Iaccab, Marco Gaudesic, Giovanni Squilleroc, Alberto Tondad

aJohann Bernoulli Institute, University of Groningen, Nijenborgh 9, 9747 AG Groningen, The Netherlands
bINCAS3, Dr. Nassaulaan 9, 9401 HJ, Assen, The Netherlands
cPolitecnico di Torino, Corso Duca degli Abruzzi 24, 10129, Torino, Italy
dINRA UMR 782 GMPA, 1 Avenue Lucien Br´etigni`eres, 78850, Thiverval-Grignon, France

8
1
0
2
 
t
c
O
 
5
 
 
]
E
N
.
s
c
[
 
 
1
v
3
1
7
2
0
.
0
1
8
1
:
v
i
X
r
a

Abstract

In novel forms of the Social Internet of Things, any mobile user within communication range may help routing messages for another
user in the network. The resulting message delivery rate depends both on the users’ mobility patterns and the message load in the
network. This new type of conﬁguration, however, poses new challenges to security, amongst them, assessing the eﬀect that a
group of colluding malicious participants can have on the global message delivery rate in such a network is far from trivial. In this
work, after modeling such a question as an optimization problem, we are able to ﬁnd quite interesting results by coupling a network
simulator with an evolutionary algorithm. The chosen algorithm is speciﬁcally designed to solve problems whose solutions can be
decomposed into parts sharing the same structure. We demonstrate the eﬀectiveness of the proposed approach on two medium-sized
Delay-Tolerant Networks, realistically simulated in the urban contexts of two cities with very diﬀerent route topology: Venice and
San Francisco. In all experiments, our methodology produces attack patterns that greatly lower network performance with respect
to previous studies on the subject, as the evolutionary core is able to exploit the speciﬁc weaknesses of each target conﬁguration.

Keywords: Cooperative Co-Evolution, Delay-Tolerant Network, Evolutionary Algorithms, Network Security, Routing

1. Introduction

The so-called Social Internet of Things calls for nearly ubiq-
uitous communicating devices. There is today a need to inte-
grate low-cost, low-power devices to support networking ser-
vices in more eﬀective and eﬃcient ways. In such a scenario,
new solutions are continuously developed and deployed, while
approaches that just a few decades ago were used only in highly
complex, niche applications are now literally brought down to
earth — Delay-Tolerant Networks (DTNs) are a technology
originally developed for space communications that, over the
years, made its way down to quite mundane applications [1].

Emerging technologies and applications are posing serious
problems to designers. In most cases there is not enough time to
thoroughly validate them, or even to simply analyze their pos-
sible failures and problems. Engineers are forced to resort to
their experience to choose heuristics that look reasonable, and
then observe the actual outcome from real applications. Secu-

(cid:73)This paper is an extended, improved version of the paper Black Holes
and Revelations: Using Evolutionary Algorithms to Uncover Vulnerabilities
in Disruption-Tolerant Networks presented at EvoComNet2015 and published
in: Applications of Evolutionary Computing, Proceedings of 18th European
Conference, EvoApplications 2015, Copenhagen, Denmark, April 8-10, 2015,
LNCS 9028, pp. 29-41, Springer, 2015.

Email addresses: d.bucur@rug.nl (Doina Bucur),

giovanniiacca@incas3.eu (Giovanni Iacca),
marco.gaudesi@polito.it (Marco Gaudesi),
giovanni.squillero@polito.it (Giovanni Squillero),
alberto.tonda@grignon.inra.fr (Alberto Tonda)

Preprint submitted to Applied Soft Computing Journal

rity in DTNs is a paradigmatic case: such networks need to re-
main open to all willing participants, and few malicious partic-
ipants may try to disrupt communications, for instance, routing
no messages to other nodes or injecting large number of mes-
sages into the network. While such a risk is plausible, precisely
assessing DTNs’ vulnerabilities is hard.

This paper focuses precisely on evaluating the amount of
damage that can be caused to a DTN by a group of synchro-
nized attackers with deep knowledge about the network. Given
a scenario, we propose to optimize attackers for minimizing the
performances of the network using a heuristic methodology. It
is important to note that the adoption of such methodology is
more a necessity than a choice: determining the most eﬀective
attack for a given network was proven to be NP-hard [2], the
complexity and number of variables involved in the problem
preclude the use of formal techniques and the size of the sce-
narios prevent exhaustive analyses.

The idea of using heuristic methods to disprove a property of
a system when formally proving it is not possible, is not a nov-
elty in itself. The simplest approach, namely random sampling
of the parameter space, is often used under the assumption that
the eﬀort employed failing to ﬁnd a counter example may be
sensibly linked to the degree of conﬁdence that a counter ex-
ample does not actually exist.

Repeated random sampling has also be used as a means to es-
timate numerical quantities when complexity and dimensional-
ity of a problem impedes the application of analytic analyses. In
the speciﬁc case of DTNs performance, it has been considered

October 8, 2018

in [3], although limited only to small networks and attackers
with no information about the environment. However, random
sampling is unlikely to provide any interesting result when the
goal is to detect a very speciﬁc corner-case scenario, such as
the damage caused by specialized attackers that are fully aware
of the network characteristics. Finally, when the search space
is too vast, even the eﬀort required to get a signiﬁcant sampling
could be excessive.

In this work, we move forward from random sampling by us-
ing an evolutionary algorithm (EA) to optimize the attackers’
parameters in order to inﬂict the maximum possible damage to
the network. We overcome the limitations of random sampling
by using the capability of the EA to drive random search to-
wards speciﬁc regions of large search spaces. Furthermore, we
extend the features of a classical evolutionary algorithm to en-
able it to ﬁnd a team of colluding attackers. As the members
of such a team cooperate in order to maximize the cumulative
damage, even at the expense of the damage caused by each sin-
gle attacker, the approach is a form of cooperative co-evolution,
an open area of research for which very few successful strate-
gies have been found so far.

We tested the proposed methodology on medium-sized net-
works describing urban scenarios with diﬀerent topologies,
where a number of agents, i.e., the network nodes, move re-
alistically. The results clearly demonstrate the eﬃcacy of the
approach: we found scenarios where even few (up to 10% of
the total network size), highly optimized attackers can reduce
the global data delivery in the network by over 90%, when
compared to the network with no attackers. We also observed
that the composition of the attacker team obtained by evolution
changed when cooperative co-evolution is used, demonstrating
that such scheme leads to synergistic solutions not found by
classical evolutionary algorithm.

The rest of the paper is organized as follows: the next section
summarizes the research background; Section 4 details the pro-
posed methodology; Section 5 reports the experimental eval-
uation; Section 3 surveys the related work; ﬁnally, Section 6
concludes the paper.

2. Background

This section ﬁrst gives an overview of the application do-
main of Delay-Tolerant Networks. Sections 2.1-2.2 describe the
paradigm of routing in DTNs, and First Contact, the DTN pro-
tocol under study. Section 2.3 summarizes the mobility model
that an urban DTN node follows, from the literature. Sec-
tion 2.4 describes the two main types of security attacks rele-
vant: black hole and ﬂooding attacks. Finally, Section 2.5 gives
an overview of the EA ﬁeld.

a mixed terrestrial-and-space network where some of the nodes
are Low-Earth Orbiting Satellites, and the rest are ground users;
this was the application for which DTN-speciﬁc routing proto-
cols were originally designed [4]. More recently, DTNs have
also been proposed in scenarios with nearly unpredictable con-
nectivity. This is the case of animal-tracking applications [5]
and opportunistic urban networks. An example of the latter is
the 30-bus experimental DieselNet [2], in which urban vehicles
constrained to city roads act as mobile message routers. It is
urban scenarios with unpredictable connectivity that we study
in this paper.

Given an application scenario, the main performance factors
for a DTN message-routing protocol quantify the protocol’s
ability to route messages in that scenario, and the timeliness
of the routing:

Delivery rate The percentage of messages injected in the net-
work by nodes which were successfully delivered to their
destination nodes.

Message delay The average time interval between a message

injection in the network until its delivery.

2.2. DTN routing: the First Contact protocol

A DTN routing protocol essentially implements a logic to
achieve message routing in the mobile network, end-to-end
from the source of a message to its destination, over a con-
nectivity graph which varies in time and is by nature discon-
nected. Given these scenarios, the protocol logic cannot be
based on standard distributed algorithms for computing short-
est paths end-to-end in a graph: the routing can not converge on
correct routes when the network graph is highly dynamic. In-
stead, DTN message communication on a path between source
and destination include long-term storage of the message in the
nodes’ (ﬁnite) node buﬀers, until an opportunity for further de-
livery of the message arises. This ability to safely delay the
forwarding of a message is typical of DTN routing protocols.

DTN protocol design follows a simple taxonomy based on

the following features:

Network knowledge A protocol aiming to compute optimal
paths at a node would be helped if the node is able to pre-
dict the future network conditions: the pattern of contact
with other nodes, the set of nodes with congested buﬀers,
and the pattern of traﬃc demands. While network knowl-
edge may be acquired in practice by an attacker via mon-
itoring the network, many protocols cannot assume any
(i.e., are zero-knowledge).

2.1. Delay-Tolerant Networks: performance objectives

Delay-Tolerant Networking was designed to cater for mes-
sage routing in practical applications with heavy node mobility.
In such applications, the connectivity pattern between nodes
in the network can be either predictable or unpredictable with
time. An example DTN with predictable connectivity is that of

Message replication Forwarding protocols simply route the
original message through the network. Replicative proto-
cols introduce into the network a number of copies of each
original message, each of which is then forwarded inde-
pendently with the aim that at least one copy reaches the
destination.

2

We study here one of the simplest and most common DTN
routing protocols, namely First Contact (FC) [4]. FC is zero-
knowledge and forwarding; it routes messages opportunisti-
cally using any available contacts with other nodes. A single
copy of each message in the network exists at a time, and it
is forwarded to the ﬁrst available contact (if more contacts are
available, one is chosen randomly among all the current con-
tacts). On simple network topologies, FC was shown to have
performance comparable to partial-knowledge protocols; this
degrades in complex topologies to varying degrees, depending
on the network load.

2.3. Node movement models in DTNs

Models describing realistically [6] the free, stochastic move-
ment in urban environments of nodes of diﬀerent kind (pedes-
trian, cars, buses, etc.) can be used to study an urban DTN
computationally. In a DTN simulation, each movement model
is associated to a diﬀerent map layer. A map layer describes the
areas of the map reachable by the associated kind of nodes. The
building blocks of these node movement patterns are a node’s
points of interest (POIs) located on a map layer.

Nodes in our DTNs follow a classic movement model: ran-
dom waypoint with shortest paths.
In this model, node ran-
domly chooses a destination point from a set of points of inter-
est; travels there at a realistic speed on the shortest path; takes
a break. Then, it repeats the process. This can be considered
realistic: in [3], which evaluated the theoretical resilience of the
real-world DieselNet and Haggle DTN prototypes, the network
logs showed that Haggle nodes mimicked the random-waypoint
model fairly closely.

2.4. Types of security attacks

Like a DTN routing protocol, an attacker also may or may
not have knowledge of the future connectivity patterns in the
network. A strong attacker has full network knowledge, i.e.,
will know:

• The structure of the city map;

• The pattern of network encounters: for example, a statisti-
cal estimation of how many honest nodes will be in prox-
imity at any given map location;

• The statistical pattern of new messages that honest nodes
will forward when encountered, and the statistical pattern
of buﬀer availability at honest nodes.

Furthermore, a group of colluding attackers has the means
necessary to synchronize their individual attacks, rather than
executing an independent logic. Any of the colluding nodes
may adopt one of the following attack logics:

Black hole attacks The attacker drops a percentage of the
packets received: this percentage is 100% in black hole
attacks.

Flooding attacks The attacker executes the same routing pro-
tocol as honest nodes, but attempts a denial-of-service pro-
cedure by injecting a (large) number of (large) messages
into the network.

2.5. Evolutionary Computation

Evolution is the biological theory that animals and plants
have their origin in other types, and that the distinguishable
diﬀerences are due to modiﬁcations in successive generations.
Natural evolution is based on random variations, but it is not a
random process: variations are rejected or preserved according
to objective evaluations, and only changes that are beneﬁcial to
the individuals are likely to spread into subsequent generations.
Darwin called this principle “natural selection” [7]: a determin-
istic process where random variations “aﬀord materials”.

When natural selection causes variations to be accumulated
in one speciﬁc direction the result may strikingly resemble a
deliberate optimization process. However, such optimization
processes only required to assess the eﬀect of random changes
and not the ability to design intelligent modiﬁcations. Several
scholars were inspired by such an outcome and tried to repro-
duce the process for solving practical optimization problems in
various application domains, while others tried to mimic it to
better understand its underlying mechanisms.

Evolutionary Computation (EC) is the oﬀshoot of computer
science focusing on algorithms loosely inspired by the theory of
evolution. The deﬁnition is deliberately vague since the bound-
aries of the ﬁeld are not, and cannot be, sharply deﬁned. EC is
a branch of computational intelligence, and it is also included
into the broad framework of bio-inspired meta-heuristics. EC
does not have a single recognizable origin. Some scholars iden-
tify its starting point in 1950, when Alan Turing drew attention
to the similarities between learning and evolution [8]. Others
pointed out the inspiring ideas that appeared later in the decade,
despite the fact that the lack of computational power impaired
their diﬀusion in the broader scientiﬁc community [9]. More
commonly, the birth of EC is set in the 1960s with the appear-
ance of three independent research lines: John Holland’s ge-
netic algorithms [10]; Lawrence Fogel’s evolutionary program-
ming [11]; Ingo Rechenberg’s and Hans-Paul Schwefel’s evolu-
tion strategies [12]. The three paradigms monopolized the ﬁeld
until the 1990s, when John Koza entered the arena with genetic
programming [13]. Nowadays, all these methods, together with
several variants proposed over the years, have been grouped un-
der the umbrella term of evolutionary algorithms (EAs).

When EAs are used to solve a speciﬁc problem, i.e. optimize
solutions for it, an individual is a single candidate solution, and
its ﬁtness is a measure of its capacity of solving the problem;
the set of all candidate solutions that exists at a particular time
represents the population. Evolution proceeds through discrete
steps called generations.
In each of them, the population is
ﬁrst expanded and then collapsed, mimicking the processes of
breeding and struggling for survival (Figure 1).

Usually, parents are chosen for breeding stochastically, with
the best candidate solutions having higher probabilities to gen-
erate oﬀspring. As a result, new candidate solutions are more
likely to inherit favorable traits. Conversely, the removal of in-
dividuals is usually deterministic: the less ﬁt, and possibly the
oldest ones, are deleted. The mechanisms used to generate the
oﬀspring are collectively named genetic operators. They can be
divided into recombinations and mutations: the former methods

3

aiming to minimize the delivery rate of the network, the sim-
pler quality-of-service metric of total reachability substitutes
it, which in turn can be minimized eﬀectively with heuristics.
This metric is deﬁned as follows. A DTN D = (N, C) is a sin-
gle predeﬁned list of connection events C on the set of honest
nodes N of size n; this can be obtained by monitoring the long-
term execution of a real-world DTN. Two nodes are temporally
connected in D if there exists a (temporally non-decreasing)
sequence of connection events in C. Then, the total reachabil-
ity of D, denoted R(D), is the number of pairs of temporally
connected nodes (excluding reﬂexive pairs). To select k attack-
ers out of the set N while minimizing R(D) on a predeﬁned D,
the greedy heuristic simply selects as the ith attacker that node
which lowers the total reachability of D (excluding the ﬁrst i−1
attacker) the most. While this greedy heuristic is not proven
analytically to be optimal at minimizing R(D), it is shown ex-
perimentally to give similar results as a brute-force method, for
k ≤ 5, on the two DTNs under study.

The greedy heuristic is then shown to outperform a random
selection of nodes when k ≥ n
10 (i.e., at least 3 strong attackers
for n = 30) on the DieselNet DTN, and for any k ≥ 1 on the
Haggle DTN, for black hole attacks and the MaxProp routing
protocol. The heuristic is particularly advantageous for a very
large k; there, the diﬀerence between the delivery rate found
when k = n
2 is 30 − 40% lower on the two DTNs than with
random node selection.

3.3. Bio-inspired Heuristics

Evolutionary computation has been demonstrated a power-
ful means for tackling the inherent complexity of networking.
In [15], Baldi et al. proposed the use of a genetic algorithm
for minimizing the performance of a network, with the ﬁnal
goal to pinpoint potential bottlenecks of the topology. The ap-
proach exploits an accurate network simulator coupled with a
rudimentary evolutionary optimizer written in Perl. It could be
considered a proof of concept, as experimental results do not
show any real application.

A feasibility study of the approach described in the present
work, exploiting a far more conventional EA and tested only on
a reduced set of scenarios, was presented in [16]. In previous
research, we showed the eﬃcacy of an evolutionary algorithm
also in the context of wireless sensor networks (WSN), for
which we tested two kinds of collection tree protocols [17, 18].
We tackled diﬀerent network topologies composed of up to 50
nodes, making use of a real-code simulator, which enables to
analyze the complete software implementation of the protocols
under analysis. Furthermore, the gathered data enabled us to
pinpoint a set of topological factors which correlate with ex-
treme traﬃc under collection routing. In [19], we further en-
hanced such analysis through the use of a multi-objective evo-
lutionary algorithm, in the attempt to explore the WSN search
space from a multi-objective perspective rather than using lexi-
cographic order of ﬁtness functions.

Figure 1: Flowchart of an evolutionary algorithm

mix together the information contained in two or more solutions
to create new ones; the latter ones work by changing the struc-
ture of a single solution. Recombination operators are able to
coalesce good characteristics from diﬀerent solutions, and pro-
vide a very eﬀective mechanism to explore the search space;
mutation operators, on the other hand, allow the ﬁne-tuning of
the candidate solutions. Maintaining a set of solutions, EAs are
resilient to the attraction of local optima [14].

Over the years, EAs were proven capable to solve quite diﬃ-
cult problems with very complex ﬁtness landscapes, including
open problems related to networking and protocols. In partic-
ular, EAs are known to greatly outperform random sampling
for case studies where classical optimization techniques are not
viable [14]. Evolutionary optimizers have been successfully ex-
ploited both in stationary and dynamic situations, and they were
demonstrated able to identify either single optima or Pareto sets
in multi-objective problems, see Section 3 for a summary of rel-
evant prior work.

3. Related Work

3.1. Random Sampling

To the best of our knowledge, the only experimental work on
the assessment of DTN robustness was performed by Burgess et
al.[3], who evaluated the resilience of DTNs of 30 nodes when
running four protocols. Weak attacks (without free range, but
with attackers forced to use the routes previously used by the
honest nodes) were simulated by randomly reassigning some
of the honest nodes as attackers.

3.2. Greedy Heuristic

To generate strong attacks (again, without free range), the
same authors [3] used a greedy heuristic in response to the in-
tractability of the vertex vulnerability problem. First, instead of

4

4. Proposed Methodology

As stated in the introduction, the core idea of this work is
to expose vulnerabilities in a DTN by devising a set of eﬀective
attackers. As a single attacker is unlikely to be able to damage a
DTN network, we seek for teams of colluding malicious nodes.
Both the number of attackers and their type (black hole or ﬂood-
ing) should be optimized in order to create the maximum dam-
age. Attackers are optimized using an advanced evolutionary
algorithm that is based on an recent cooperative co-evolution
approach that is not only able to optimize the parameters of
each individual attacker, but also to optimize the composition
of the team of colluding attackers.

In more detail, we simulate a realistic DTN over an urban
environment deﬁned by a topological map and a set of POIs.
We assume two type of nodes: honest and malicious. As dis-
cussed earlier, for each honest node i the predetermined moving
path PH
is a sequence of random points of interest. For added
i
realism, a small number of these points, such as main tourist at-
tractions, may be given a higher probability of being selected as
next destination. On the contrary, for each malicious node i, the
path PM
is a sequence of points of interest chosen by the evo-
i
lutionary optimizer to cause maximum damage in the network.
Honest nodes execute the FC routing protocol, while malicious
nodes can act either as data ﬂooders or black holes.

In the proposed framework, we use the Opportunistic Net-
work Environment simulator (The ONE) [6]1 coupled with the
evolutionary toolkit µGP [20]2. The reasons for using µGP are
manifold: ﬁrst, the design of this framework is based on the no-
tion of an external evaluator, which simpliﬁes the integration
with an external network simulator; secondly, the algorithm
available in µGP features a built-in support for multiple ﬁtness
functions, that can be evaluated both in a lexicographical order
and in a multi-objective approach; then, the evolutionary en-
gine available in µGP makes use of self-adaptation techniques,
greatly limiting the number of parameters that require to be set.
Finally, µGP provides both a classical EA and a cooperative
co-evolution scheme called Group Evolution (see below).

The resulting evolutionary optimization process, depicted in
Figure 2, can then be summarized as follows: given a DTN of
N total nodes, and any parameters of the urban environment,
ﬁnd a group of attackers of size k < N, each one with its pe-
i (i = 1 . . . k) and its characteristics
culiar movement patterns PM
(movement model and attack type) which would lower the data
delivery rate (DDR) of the DTN the most, while maximizing
also its average latency.

The following section gives details about the evolutionary
core and the Group Evolution scheme, while the internal so-
lution representation and the ﬁtness function deﬁnitions are de-
scribed in Section 4.2 and 4.3, respectively.

4.1. Evolutionary core

A noticeable branch of EC is cooperative co-evolution
(CCE), that is, broadly speaking, the study of evolutionary al-

1The tool is available at http://www.netlab.tkk.fi/tutkimus/dtn/

theone/.

2The tool is available at http://ugp3.sourceforge.net.

Figure 2: Structure of the proposed framework. Candidate solutions and ﬁtness
values are internally represented as text ﬁles.

gorithms whose ﬁnal goal is achieved by a solution composed
of diﬀerent sub-solutions that cooperates to reach the common
goal. The idea of CCE dates back to the origin of EC, yet its
inherent problems are far from being solved: important contri-
butions are appearing regularly in the scientiﬁc literature (e.g.,
[21, 22, 23, 24, 25]). In the last decade, the CCE popularity fur-
ther boasted due to robotics applications where teams of robots
can be asked to perform collective tasks [26].

In CCE, sub-solutions may be heterogeneous or homoge-
neous, and combining them might be more or less trivial. Nev-
ertheless, almost all approaches strive to optimize the single
parts independently, while trying periodically to group them
into an eﬀective set, possibly exploiting heuristics or ad-hoc
tweaks. One of the main challenges in CCE is that optimizing a
single component may not be beneﬁcial to the global solution,
yet the algorithm has to harmonize the two possibly contrasting
selective pressures.

Group evolution (GE) is yet another take on CCE, natively
provided by µGP. In GE, the individual optimization phase and
the group optimization phase are blended into a single seam-
less process [27]. Individuals are merely the parts that can be
assembled to compose the groups, while groups are the actual
candidate solutions. GE stores a population of individuals and
a separate population of groups (see Figure 3), but new individ-
uals and new groups are created with no predeﬁned order: the
evolutionary core may choose the best sequence of operators
acting on individuals, and operators acting on groups. However
the user may still impose a minimum or maximum cardinality
for groups.

Another peculiarity of GE is that single individuals and sets
of individuals (i.e., groups) are evaluated by the very same ob-
jective function (e.g., the loss of performance in a DTN in the
context of this paper). This choice enables both a generaliza-
tion in the ﬁtness calculation and a tighter integration between
the two levels of evolution. The ﬁtness assigned to groups de-
pends on the cumulative eﬀect of the individuals belonging to
it, while the contribution of each single individual is also stored
and used during comparison.

More operatively, each group is a set of references to indi-
viduals in the individual population: so, the same individual
can belong simultaneously to multiple groups. At every gener-

5

Figure 3: A high-level scheme of the two-population approach used by GE.
Groups are sets of individuals taken from the individual population. The same
individual can appear multiple times in the same group or in diﬀerent groups:
for example, individuals 1 and 2 belong to both groups A and B.

ation, once new groups and individuals are created and evalu-
ated, groups are sorted by their ﬁtness function, and the worst
are removed, factually deleting references to certain individu-
als. After this process, orphans, i.e., individuals not belonging
to any group in the current group population, are also deleted.
Interestingly, GE can be used with no modiﬁcation to op-
timize single attackers: when the maximum size of a group
is set to 1, the evolutionary core automatically stops using
group manipulation operators, such as addElementToGroup
and removeElementFromGroup. For the purpose of this work,
we further modiﬁed the original GE available in µGP introduc-
ing a new mechanism for choosing which operators to use in
the current generation, and a strategy for caching the results of
past evaluations [28]. The ﬂowchart of the GE algorithm used
in this work is shown in Figure 4.

4.2. Internal solution representation

In the problem under study, we consider a model of strong
colluding attackers with full network knowledge and free range
of movement. In other words, we consider attacks carried out
by multiple collaborating nodes which are connected via alter-
native communication links. In this context, a candidate solu-
tion represents a group of one or more malicious nodes, each
one characterized by the following properties:

• the attack logic to adopt (e.g., black hole, ﬂooding); we
assume this choice remains unchanged during an attack;

• the movement model (e.g., pedestrian, vehicle), which con-
strains the node to a corresponding map layer and mobility
pattern;

• the route on any given map layer, deﬁned via a list of POIs
on that map layer; free-range strong attackers have full
control when deciding their POIs.

The resulting structure of a candidate solution is thus quite
complex, as each attacker can feature a variable number of
POIs, and each group can have a variable number of attack-
ers. An example of solutions produced by the evolutionary core
is shown in Figure 5.

Figure 4: Flowchart of an evolutionary algorithm using group evolution. Oper-
ations exclusive to GE are depicted in black. New groups and new individuals
are created in a single uniform step, while to evaluate new groups the evaluation
of new individuals is required.

In a classical EA, the individual would then be a (either ﬁxed-
or variable-size) composition of multiple attackers with diﬀer-
ent properties. When GE is applied instead, each individual
models exactly a single attacker, while the organization of such
malicious nodes is delegated to groups, with a ﬁnal result struc-
turally similar to the case where a single individual portrays
several nodes.
In any case, the genetic operators can act on
each node, modifying its movement model, its attack logic, and
adding/removing/replacing POIs in its path, in order to generate
new candidate solutions. In experiments with a variable num-
ber of malicious nodes, the same operations can be performed
on the blocks representing the nodes.

It is important to notice that the same POIs have diﬀerent
meanings depending on the node’s movement: even if a vehi-
cle and a pedestrian pass close to the same coordinates, they
may reach them using diﬀerent paths, causing distinct network
disruptions along the way. Also, since most of the POIs are
accessible by certain types of movement only (e.g., a point in
open water cannot be reached by a pedestrian, nor one on land

6

Mov=vehicle
Attack=black hole
94,39
55,84
...
42,44
1,26

Mov=pedestrian
Attack=flood
22,75
43,15
...
65,61
15,58

Mov=boat
...
...
...
...
...
...

Figure 5: Example of solution for the DTN attack problem, describing multiple
attackers. Each attacker is characterized by its movement model (e.g. boat,
pedestrian, vehicle), its attack logic (black hole or ﬂood), and a series of POIs
it will visit during the simulation, encoded as squares in a grid overlapped to
the city map.

by a boat), for each type we overlap a grid layer onto the city
map layer, and deﬁne the path of an attacker of that type as a set
of grid squares inside that grid. During the simulation, we then
map each grid square to the map point closest to the square; if
a square contains more than one map point, the malicious node
visits them all.

In particular, µGP exploits a user-deﬁned description of solu-
tions in an XML ﬁle. The external representation of candidate
solutions is written to text ﬁles as they are evaluated, while their
internal structure is stored to disk as XML ﬁles, that can be read
in case the evolutionary process is resumed.

4.3. Fitness functions

Movement model, attack logic and POIs to visit are set at the
level of each malicious node, but the objective is to maximize
the global eﬀectiveness of the attack: an optimal set of collud-
ing attackers should lower the performance objectives of the
network the most. The eﬀectiveness of an attack conﬁguration
is thus assessed as an evaluation of an urban network scenario
(see next Section) performed by the network simulator. The
outputs of such simulation (i.e., the ﬁtness values, using the ter-
minology of EC), are:

• ( f1) the data delivery rate (DDR), calculated as the per-
centage of messages originated only from honest nodes,
and which are delivered successfully;

• ( f2) similarly, the average latency of message deliveries (in

seconds).

The two values are considered in lexicographic order, as we
assign more importance to a reduction of the network’s DDR
rather than an increase of latency: optimization-wise, f1 is to
be minimized, while f2 is to be maximized.

5. Experiments

This section ﬁrst summarized the conﬁguration settings for
the experimental campaigns. Sections 5.1 and 5.2 quantify
the parameters used to deﬁne an urban setting and its network
nodes. Section 5.3 summarizes the experimental parameters of
the evolutionary core. Sections 5.4 and 5.5 give the numerical
results and discuss their practical impact.

We make public the city maps, the experimental conﬁgura-

tions, and detailed experimental results, at the URL:
https://github.com/doinab/DTN-security.

5.1. DTN and the cities: San Francisco and Venice

To validate our methodology, we simulate two realistic,
large-scale city environments, each composed of a map and a
large set of honest, randomly moving network nodes of cer-
tain types relevant to a given city. Figures 6 and 7 show the
basic maps of the two urban environments in our experimen-
tal scenarios, namely San Francisco and Venice. These cities
diﬀer in terms of map topology: while the area of San Fran-
cisco has a regular grid structure of routes, the area of Venice
has a complex, hierarchical, irregular structure of main and sec-
ondary waterways travelled by boats, with pedestrians conﬁned
to inner walkways (some along waterways) and bridges. The
Venice map has an additional feature for added realism: on both
map layers, a small number of the map POIs mark the touristic
center, and have a higher probability to be chosen as the next
destination by the honest nodes. Table 1 quantiﬁes the maps
and map layers in terms of size, number of distinct map points,
route segments, and number of nodes.

Figure 6: A 5 km2 area of downtown San Francisco, US, with a grid-based
map topology of streets and the occasional park. The map has two overlapping
layers, constraining the movement of vehicles and pedestrians: the vehicles are
conﬁned to the black streets, while the pedestrians may walk both the green and
the black routes.

5.2. Network simulation and network nodes

In both cities we conﬁgured N = 200 moving network nodes,
divided in two types: pedestrians (75%) and vehicles (25%).
For San Francisco, the vehicles consist of motorized cars; in
Venice, the waterways serve as routes for motorized or unmo-
torized boats. Pedestrians are modelled as carrying commu-
nication devices with relatively limited capabilities: a Blue-
tooth communication interface with a range of 15m and low
bandwidth. Vehicles are awarded more communication capa-
bilities: besides a Bluetooth interface (which allows commu-
nication events to take place between any pedestrian and any
vehicle), a vehicle also has a high-speed, longer-range network
interface allowing vehicle-to-vehicle communication.

7

Table 1: Network parameters: city maps

San Francisco:

Venice:

size:
map layers:
no. of route segments:
no. of map points:
network size:

2416 m × 2253 m
LP (pedestrian walkways), LS (streets)
1728 in LP, 1305 in LS
1210 in LP, 883 in LS
150 pedestrians (constrained to LP), 50 cars (constrained to LS )

size:
map layers:
no. of line segments:
no. of map points:
network size:

2210 m × 2340 m
LP (pedestrian walkways), LW (waterways)
7983 in LP, 1497 in LW
6910 in LP, 1354 in LW
150 pedestrians (constrained to LP), 50 boats (constrained to LW )

an (e.g., pedestrian) attacker then only diﬀers from that of an
honest pedestrian in that the attacker’s next destination point is
randomly chosen from the evolved set of POIs, rather than the
entire map layer.

Honest nodes periodically inject new messages to be routed
by the network; the rate of message injection among all honest
nodes is set at one message every 30 seconds, such that the
network routes 120 honest messages per hour. The honest node
to inject the next message in the network is chosen randomly.
The malicious nodes run one of the two attack logics described
in Section 2.4.

A black hole attacker does not inject any additional messages
in the network. On the other hand, when an attacker executes
a ﬂood, the parameters are chosen to obtain a “heavy” ﬂood of
messages: (1) a ﬂooding node injects messages in the network
at 10 times the frequency of message injection from an honest
node, and (2) the messages injected by a ﬂooder are 10 times as
large as regular messages. Table 3 summarizes these communi-
cation parameters, together with the settings regarding the sizes
of the nodes’ message buﬀers, and the Time To Leave (TTL),
which limits the amount of time that a message is allowed to
be stored in a node’s buﬀer without being forwarded — we set
TTL to be large, and equal to the length of an experiment: 5
hours (simulated time).

5.3. Evolutionary parameters

During all the experiments, µGP has been conﬁgured with
the parameters reported in Table 4. The operators chosen for
the evolution are:

• onePointImpreciseCrossover:

one-point crossover

between two individuals;

• twoPointImpreciseCrossover: crossover with with

two cut points;

• singleParameterAlterationMutation: mutate a sin-
gle coordinate of a POI, the movement model or the attack
logic;

• insertionMutation: add a new random POI;

• removalMutation: remove a randomly selected POI;

• replacementMutation: replace a POI with a randomly

generated one.

8

Figure 7: A 5 km2 area of downtown Venice, IT, with an irregular map topology
of pedestrian pathways (the black map layer) and waterways (the blue layer).
Marked with stars are special POIs in the city’s touristic center.

Each simulation of a DTN in The ONE is stochastic. The
nodes are initially placed randomly on their map layer, and a
1,000-second warm-up simulation period is allowed before the
experiment starts, for the nodes to settle on the “natural” pre-
ferred routes in the city. The next destination POI is also chosen
randomly. Due to this, to smoothen the ﬁtness landscape and
reduce the eﬀect of the random seed of each simulation on the
evaluation of solution, we execute each network simulation 10
times, initialized with diﬀerent random seeds, and report as ﬁt-
ness values the average DDR and latency over the 10 available
repetitions.

The movement model of all nodes follows the general ran-
domized pattern summarized in Section 2.3. A subset of these
200 nodes is assigned a malicious behaviour. For an honest
node, the set of POIs is simply the entire set of map points lo-
cated on the node’s relevant map layer. The node randomly
chooses any destination point from that map layer, travels there
at a certain speed on the shortest path, pauses for an interval,
and repeats the process. The conﬁguration for the nodes’ speed
and pause interval is given by Table 2. For an attacker, the set
of POIs is is a subset of the map points of the relevant map
layer, and is evolved by the evolutionary core as part of each
solution (as described in Section 4.2). The movement model of

Table 2: Network parameters: movement models

Movement model
for nodes in all cities

next point:
path choice:
pedestrian speed:
boat speed:
car speed:
pause interval for all:

chosen randomly from a map layer
shortest path on the map layer to the next point
[0.5 . . . 1.5] m/s
[1.0 . . . 5.0] m/s
[2.7 . . . 13.9] m/s
[0 . . . 120] s at each destination point

Table 3: Network parameters: simulation and node communication settings

Simulation
settings

simulation time:
DTN simulator:

5 h
The ONE [6]

Message
settings

message issued:
message size:
message buﬀer:
message TTL:

every 30 s (by an honest node), every 3 s (by a ﬂooder)
10 kB (issued by an honest node), 100 kB (issued by a ﬂooder)
5 MB (for pedestrian nodes), 50 MB (for car and boat nodes)
5 h

Node
communication
interfaces

Bluetooth:
High-speed:
pedestrians use:
cars and boats use:

range 15 m, speed 250 kBps
range 100 m, speed 10 MBps
Bluetooth
Bluetooth and High-speed

Figure 8: Comparative results: data delivery rate (DDR) from three experimental campaigns using group evolution, a classical EA, and random testing. The DDR
obtained with a random test is shown as the mean and standard deviation among the mean DDR of 150 randomly generated groups, each group simulated 10 times
with diﬀerent random seeds. The DDR obtained with any evolutionary experiment is a single group of top ﬁtness, and is shown as the mean and 95% conﬁdence
interval among 5 simulation repetitions of that group with diﬀerent random seeds.

The activation probabilities of all the operators in the popula-
tion are self-adapted during the run; [28] enables to eﬃciently
alternate phases where individuals are optimized, with phases
where groups are optimized. Self adapting the size of the tour-
nament for selecting parents (τ) enables to optimize the selec-
tive pressure; while self adapting the strength of the mutation
operators (σ) enables to balance between exploration and ex-
ploitation. Every time a mutation is performed, it is executed
again on the same individual if a randomly generated number
in (0, 1) is lower than the current value of σ. For high values
of σ, the algorithm will tend to generate new solutions that are
very diﬀerent from their parents, thus favoring exploration; for
low values of σ, the diﬀerences between parents and oﬀspring

will be smaller, thus entering a phase of exploitation.

During the GE experiments, new operators are added in order

to manipulate groups, namely:

• groupRandomInsertionMutation: add a random indi-

vidual to a group;

vidual from a group;

• groupRandomRemovalMutation: remove a random indi-

• groupBalancedCrossover: crossover that moves the

same number of individuals between two groups;

• groupUnbalancedCrossover: same as above, with no
guarantee of moving the same number of individuals;

9

Table 4: µGP experimental settings

• A GE-based experimental campaign (for the settings

where k > 1);

Parameter Description

τ
σ
α
§

µ
λ

size of the tournament selection
initial strength of the mutation operators
inertia of the self-adapting mechanisms
stagnation threshold (in generations)

Classical EA

individual population size
operators (genetic) applied at every step

Group Evolution

µgroup
νindividual
λ

group population size
initial individual population size
operators (genetic or groups) applied at every step

Value

1.0÷4.0
0.9
0.9
50

30
20

30
50
20

• groupUnionIntersection: returns the union and the in-

tersection of two groups;

• groupDreamTeam: creates a group with some of the best

individuals currently in the population.

As previously detailed, the number of individuals in the GE
paradigm is regulated by the number of groups in the current
population, µgroup. Individuals are removed only when they are
no longer included in any group. The number of individuals
generated at the beginning of the execution, number that can be
later exceeded or reduced, is controlled by parameter νindividual.
Further information on parameters and operators in µGP can be
found in [20].

5.4. Experimental campaigns and results

Given the settings described in Sections 5.1–5.3, which are
common to all experiments, an experiment will be uniquely
identiﬁed by the following two parameters:

City (i.e., San Francisco or Venice)

Number of attackers i.e., the size of the attack group k, in the
range 1 ≤ k ≤ N. We delineate ﬁve practically interesting
ranges:

• k = 1, i.e., a single attacker;
• k = 2, i.e., a pair of attackers;
• k ∈ [1 . . . 5];
• k ∈ [6 . . . 10];
• k ∈ [11 . . . 20], i.e., a group which can reach 10% of

the overall network size of N = 200 nodes.

The ranges for k thus come in two categories: a ﬁxed group
size (when k = 1 or k = 2), or a variable group size (for larger
k). In the latter case, intuitively, the expectation is that the evo-
lutionary algorithm will maximize the group size in the process
of optimizing the ﬁtness functions.

To assess the comparative performance of our method based
on Group Evolution, we ran the following three experimental
campaigns, for each experimental setting (City × Number of
attackers):

• An experimental campaign based on the classical, non-GE
EA applied to the same problem in prior literature [16];

• The testing of groups of a sample of 150 purely randomly

generated groups of attackers.

For each experimental setting, the GE and non-GE experimen-
tal campaigns consist of 5 experiment repetitions, initialized
with diﬀerent random seeds.

The results of the experimental campaigns are summarized
in Figure 8, separately per city. The ﬁrst ﬁtness function, f1,
measuring the global data delivery rate (DDR) in the network,
quantiﬁes the decreasing network performance with an increas-
ing size of the attack group, k. In the ﬁgures, the data points
are presented for the set k ∈ {1, 2, 5, 10, 20}, as the evolution-
ary algorithms found that the lowest ﬁtness is achieved when
the size of the attacker group is maximum. For comparison, the
ﬁgures also include a data point showing the ﬁtness function
with no attack present (i.e., all N = 200 nodes in the network
are honest).

As seen in Figure 8, while the First Contact protocol has only
moderate data delivery in these complex urban settings even
in the absence of attacks, both evolutionary algorithms signif-
icantly outperform random testing, and GE was found to be
advantageous in all the experimental settings. Moreover, a sim-
ilar trend for the performance of the First Contact protocol was
obtained between the two cities: a single attacker was found
suﬃcient to lower the data delivery to half that of the no-attack
setting, and, with a group of 20 attackers, the data delivery in
the network was found to drop close to zero.

To further conﬁrm this trend, we performed a thorough anal-
ysis [29] of the numerical results. The analysis was conducted
as follows: for each city map and attack group size k > 1 (when
k = 1 a group cannot be deﬁned), ﬁrst we aggregated the 150
lowest DDR values obtained by GE and non-GE experiments,
over the 5 available repetitions for each of the two algorithms.
We then performed pairwise comparisons between the two al-
gorithms, and w.r.t.
the DDR of the 150 randomly sampled
attack groups used as baseline. For each pairwise comparison,
we initially verify the normality of the two distributions with
the Shapiro-Wilk test; if both samples are normally distributed,
we then test the homogeneity of their variances (homoscedas-
ticity) with an F-test. If variances are equal, we compare the
two distributions by means of the Student t-test, otherwise we
adopt Welch’s t-test variant. More speciﬁcally, we ﬁrst test the
null-hypothesis of equal distributions (i.e. the two algorithms
under comparison are statistically equivalent from an optimiza-
tion point of view); then, we test the null-hypothesis that the
ﬁtness values obtained with one of the two algorithms, taken
as reference, are statistically smaller than those obtained by the
other algorithm.
In case of non-normal distributions, we in-
stead test the null-hypotheses by means of the non-parametric
Wilcoxon Rank-Sum test. In all the tests, we consider a conﬁ-
dence level of 0.95 (α = 0.05).

10

The statistical analysis is summarized in Table 5. The anal-
ysis conﬁrms that GE and non-GE EA statistically outperform
random sampling, and GE outperforms non-GE in all cases.

Table 5: Summary of the statistical analysis (see the main text for details). Each
column (labeled as X/Y) shows the pairwise comparison between the results
obtained by algorithm X and Y, with X taken as reference. The symbol ’+’
indicates that X statistically outperforms Y, i.e. it obtains attacker groups with
lower network performance (DDR).

San Francisco

GE/Random non-GE/Random

No. attackers
2
1-5
6-10
11-20

No. attackers
2
1-5
6-10
11-20

GE/non-GE
+
+
+
+

GE/non-GE
+
+
+
+

+
+
+
+

+
+
+
+

+
+
+
+

+
+
+
+

Venice

GE/Random non-GE/Random

5.5. Runtimes and discussion of results

In Figure 9 we show the computational cost of running the
evolutionary campaigns, each data point the average of 5 rep-
etitions of an experiment with diﬀerent seeds. The runtime is
shown in core-hours, over computing cores of at least 1.6 GHz
(since we ran the experiments on a number of machines, there
was variation among the computational power allowed among
experiments).

More interestingly, the reason why the GE algorithm shows
an advantage over a classical EA is seen in Figure 10. The ﬁg-
ure ﬁrst selects all the “top” attacker groups obtained by the GE
and non-GE experiments, i.e., those groups which lower net-
work performance to within 2% of the absolute best ﬁtness f1
found by that algorithm. We observed that the number of these
top groups falls between 300 and 6, 000 (depending on the ex-
perimental setting), all of which can be considered successful
attacks. The average composition of this large group sample is
analyzed in terms of how often a type of attacker, i.e., a move-
ment model (that of a pedestrian, or that of a vehicle) and attack
logic (black hole or ﬂooding) appears in a top group.

The best single attacker found by both the GE and non-GE
algorithms is a black hole vehicle:
indeed, 100% of the top
groups found by both algorithms consist of an attacker of this
type. The same is true for pairs of attackers.

For larger group sizes, the two algorithms show a diﬀerence
of results. When k ∈ [11 . . . 20], the non-GE algorithm found an
overall lower top ﬁtness while obtaining top groups for which:
(1) the average group size does not saturate (it reaches an aver-
age of 18.23 out of 20, for the San Francisco setting), and (2)
the average group composition is a mix of attacker types, with
only 50% of the attackers in the top groups matching the type
of the best single attacker (a black hole vehicle).

On the other hand, the GE algorithm likely outperformed the
non-GE in terms of best ﬁtness found due to the fact that it both
maximized the average top group size, and optimized the aver-
age top attacker type, demonstrating that homogeneous groups

Figure 9: Computational overhead of non-GE and GE experiments: the number
of evolutionary generations, the number of solution evaluations, and the wall-
clock runtime per experimental campaign, shown as the average among the 5
experiments conﬁgured with diﬀerent random seeds, per experimental setting.

of black holes are advantageous to exploit the vulnerabilities in
the design of the First Contact protocol, and that faster black
hole attackers also have a clear advantage.

6. Conclusions

In this paper we proposed a heuristic methodology to as-
sess the robustness of First Contact, one of the main routing
protocols used in Delay-Tolerant Networks. To exploit possi-
ble weaknesses of the network, we considered the worst-case
scenario of an attack carried out by a coordinated group of
agents with full network knowledge. The methodology is based
on an evolutionary algorithm using a cooperative co-evolution
scheme called Group Evolution recently introduced in the liter-
ature and here extended for our purposes. The method is able
to optimize groups (either homogeneous or not) of malicious
nodes whose behaviour does not comply with the legitimate
routing protocol used by honest nodes in the network.

We performed an extensive experimental campaign over
medium-sized (i.e., 200 nodes) realistic urban networks run-
ning on two diﬀerent cities with radically diﬀerent map topolo-
gies (San Francisco and Venice). We assessed the scalability of
the approach by evaluating single attackers as well as groups of

11

Figure 10: The average group size and group composition among all top solutions (whose ﬁtness is within 2% of the best ﬁtness). The group composition is shown
in terms of the percentage of ﬂooding vehicles (FV), ﬂooding pedestrians (FP), black hole vehicles (BV), and black hole pedestrians (BP) among these top solutions.

up to 10% malicious nodes. Moreover, we compared results ob-
tained with random sampling and a more classical evolutionary
algorithm.

In all our experiments, the two evolutionary methods clearly
outperformed random sampling, consistently ﬁnding groups of
attackers that produced a larger network damage (reduced data
delivery rate and increased latency). The additional advantage
brought by Group Evolution resulted in an improved attack ef-
fect, optimized group compositions, and more eﬀective move-
ment models.

Overall, the contribution of this work is twofold: on one
hand, we proposed an eﬃcient alternative to random sampling,
that is currently one of the most used approaches for assessing
network robustness; on the other hand, we showed an example
problem that can be naturally described in terms of coopera-
tive co-evolution and for which such an evolutionary scheme is
clearly beneﬁcial.

This work represents then one of the few attempts at ﬁnd-
ing applications of cooperative co-evolution beyond the typical
domain of swarm robotics. In future research, we will seek to
extend this approach to diﬀerent networking applications and,
possibly, new unexplored domains.

[3] J. Burgess, G. D. Bissias, M. D. Corner, B. N. Levine, Surviving attacks
on disruption-tolerant networks without authentication, in: Proceedings
of the 8th ACM International Symposium on Mobile Ad Hoc Networking
and Computing, MobiHoc ’07, ACM, New York, NY, USA, 2007, pp.
61–70.

[4] S. Jain, K. Fall, R. Patra, Routing in a delay tolerant network, in: Pro-
ceedings of the 2004 Conference on Applications, Technologies, Archi-
tectures, and Protocols for Computer Communications, SIGCOMM ’04,
ACM, New York, NY, USA, 2004, pp. 145–158.

[5] P. Sommer, B. Kusy, P. Valencia, R. Dungavell, R. Jurdak, Delay-
arXiv preprint

tracking,

tolerant networking for long-term animal
arXiv:1506.01792 (2015).

[6] A. Ker¨anen, J. Ott, T. K¨arkk¨ainen, The ONE Simulator for DTN Protocol
Evaluation,
in: SIMUTools ’09: Proceedings of the 2nd International
Conference on Simulation Tools and Techniques, ICST, New York, NY,
USA, 2009.

[7] C. Darwin, On the Origin of the Species by Means of Natural Selection:
Or, The Preservation of Favoured Races in the Struggle for Life, John
Murray, 1859.

[8] A. M. Turing, Computing machinery and intelligence, Mind (1950) 433–

[9] D. B. Fogel, Evolutionary computation:

the fossil record, Wiley-IEEE

[10] J. H. Holland, Adaptation in Natural and Artiﬁcial Systems, University of

[11] L. J. Fogel, Autonomous automata, Industrial Research 4 (1962) 14–19.
[12] H.-G. Beyer, H.-P. Schwefel, Evolution Strategies – A comprehensive

introduction, Natural computing 1 (2002) 3–52.

[13] J. R. Koza, Genetic Programming: vol. 1, On the programming of com-
puters by means of natural selection, volume 1, MIT press, 1992.
[14] A. E. Eiben, J. E. Smith, Introduction to evolutionary computing, vol-

[15] M. Baldi, F. Corno, M. Rebaudengo, G. Squillero, GA-based perfor-
mance analysis of network protocols, in: Proc. Ninth IEEE International
Conference on Tools with Artiﬁcial Intelligence, 1997, pp. 118–124.

460.

Press, 1998.

Michigan Press, 1975.

References

[1] K. Fall, S. Farrell, DTN: an architectural retrospective, Selected Areas in

ume 2, Springer Berlin, 2010.

Communications, IEEE Journal on 26 (2008) 828–836.

[2] J. Burgess, B. Gallagher, D. Jensen, B. Levine, MaxProp: Routing for
Vehicle-Based Disruption-Tolerant Networks, in: INFOCOM 2006. 25th
IEEE International Conference on Computer Communications, pp. 1–11.

12

[16] D. Bucur, G. Iacca, G. Squillero, A. Tonda, Black holes and revelations:
Using evolutionary algorithms to uncover vulnerabilities in disruption-
tolerant networks, in: A. M. Mora, G. Squillero (Eds.), Applications of
Evolutionary Computation, volume 9028 of Lecture Notes in Computer
Science, Springer International Publishing, 2015, pp. 29–41.

[17] D. Bucur, G. Iacca, G. Squillero, A. Tonda, The impact of topology on
energy consumption for collection tree protocols: An experimental as-
sessment through evolutionary computation, Applied Soft Computing 16
(2014) 210–222.

[18] D. Bucur, G. Iacca, P.-T. de Boer, Characterizing topological bottlenecks
for data delivery in CTP using simulation-based stress testing with natural
selection, Ad Hoc Networks 30 (2015) 22 – 45.

[19] D. Bucur, G. Iacca, G. Squillero, A. Tonda, The tradeoﬀs between data
delivery ratio and energy costs in wireless sensor networks: A multi-
objective evolutionary framework for protocol analysis, in: Proceedings
of the Sixtienth Annual Conference on Genetic and Evolutionary Com-
putation Conference, GECCO ’14, ACM, New York, NY, USA, 2014.

[20] E. Sanchez, M. Schillaci, G. Squillero, Evolutionary Optimization: the

µGP toolkit, Springer Publishing Company, 1st edition, 2011.

[21] M. Potter, K. De Jong, A cooperative coevolutionary approach to function
optimization, in: Y. Davidor, H.-P. Schwefel, R. Manner (Eds.), Parallel
Problem Solving from Nature PPSN III, volume 866 of Lecture Notes
in Computer Science, Springer Berlin / Heidelberg, 1994, pp. 249–257.
10.1007/3-540-58484-6 269.

[22] E. Dunn, G. Olague, E. Lutton, Parisian camera placement for vision
metrology, Pattern Recognition Letters 27 (2006) 1209 – 1219. Evolu-

tionary Computer Vision and Image Understanding.

[23] R. Thomason, R. Heckendorn, T. Soule, Training time and team compo-
sition robustness in evolved multi-agent systems, in: M. O’Neill, L. Van-
neschi, S. Gustafson, A. Esparcia Alcazar, I. De Falco, A. Della Cioppa,
E. Tarantino (Eds.), Genetic Programming, volume 4971 of Lecture Notes
in Computer Science, Springer Berlin / Heidelberg, 2008, pp. 1–12.
10.1007/978-3-540-78671-9 1.

[24] M. Waibel, L. Keller, D. Floreano, Genetic Team Composition and Level
of Selection in the Evolution of Cooperation, IEEE Transactions on Evo-
lutionary Computation 13 (2009) 648–660.

[25] A. Tonda, E. Lutton, G. Squillero, Lamps: A test problem for cooperative
coevolution, in: Nature Inspired Cooperative Strategies for Optimization
(NICSO 2011), Springer, 2011, pp. 101–120.

[26] L. Panait, S. Luke, Cooperative multi-agent learning: The state of the art,
Autonomous Agents and Multi-Agent Systems 11 (2005) 387–434.
[27] E. Sanchez, G. Squillero, A. Tond, Group evolution: Emerging synergy
through a coordinated eﬀort, in: Evolutionary Computation (CEC), 2011
IEEE Congress on, IEEE, pp. 2662–2668.

[28] G. S. Jany Belluz, Marco Gaudesi, A. Tonda, Searching for the mini-
mum failures that can cause a hazard in a wireless sensor network,
in:
Proceedings of the Fifteenth Annual Conference on Genetic and Evolu-
tionary Computation Conference (to appear), GECCO ’15, ACM, New
York, NY, USA, 2015.

[29] E. L. Lehmann, J. P. Romano, Testing statistical hypotheses, Springer

Texts in Statistics, Springer, New York, third edition, 2005.

13

Optimizing groups of colluding strong attackers in mobile urban communication networks
with evolutionary algorithms(cid:73)

Doina Bucura, Giovanni Iaccab, Marco Gaudesic, Giovanni Squilleroc, Alberto Tondad

aJohann Bernoulli Institute, University of Groningen, Nijenborgh 9, 9747 AG Groningen, The Netherlands
bINCAS3, Dr. Nassaulaan 9, 9401 HJ, Assen, The Netherlands
cPolitecnico di Torino, Corso Duca degli Abruzzi 24, 10129, Torino, Italy
dINRA UMR 782 GMPA, 1 Avenue Lucien Br´etigni`eres, 78850, Thiverval-Grignon, France

8
1
0
2
 
t
c
O
 
5
 
 
]
E
N
.
s
c
[
 
 
1
v
3
1
7
2
0
.
0
1
8
1
:
v
i
X
r
a

Abstract

In novel forms of the Social Internet of Things, any mobile user within communication range may help routing messages for another
user in the network. The resulting message delivery rate depends both on the users’ mobility patterns and the message load in the
network. This new type of conﬁguration, however, poses new challenges to security, amongst them, assessing the eﬀect that a
group of colluding malicious participants can have on the global message delivery rate in such a network is far from trivial. In this
work, after modeling such a question as an optimization problem, we are able to ﬁnd quite interesting results by coupling a network
simulator with an evolutionary algorithm. The chosen algorithm is speciﬁcally designed to solve problems whose solutions can be
decomposed into parts sharing the same structure. We demonstrate the eﬀectiveness of the proposed approach on two medium-sized
Delay-Tolerant Networks, realistically simulated in the urban contexts of two cities with very diﬀerent route topology: Venice and
San Francisco. In all experiments, our methodology produces attack patterns that greatly lower network performance with respect
to previous studies on the subject, as the evolutionary core is able to exploit the speciﬁc weaknesses of each target conﬁguration.

Keywords: Cooperative Co-Evolution, Delay-Tolerant Network, Evolutionary Algorithms, Network Security, Routing

1. Introduction

The so-called Social Internet of Things calls for nearly ubiq-
uitous communicating devices. There is today a need to inte-
grate low-cost, low-power devices to support networking ser-
vices in more eﬀective and eﬃcient ways. In such a scenario,
new solutions are continuously developed and deployed, while
approaches that just a few decades ago were used only in highly
complex, niche applications are now literally brought down to
earth — Delay-Tolerant Networks (DTNs) are a technology
originally developed for space communications that, over the
years, made its way down to quite mundane applications [1].

Emerging technologies and applications are posing serious
problems to designers. In most cases there is not enough time to
thoroughly validate them, or even to simply analyze their pos-
sible failures and problems. Engineers are forced to resort to
their experience to choose heuristics that look reasonable, and
then observe the actual outcome from real applications. Secu-

(cid:73)This paper is an extended, improved version of the paper Black Holes
and Revelations: Using Evolutionary Algorithms to Uncover Vulnerabilities
in Disruption-Tolerant Networks presented at EvoComNet2015 and published
in: Applications of Evolutionary Computing, Proceedings of 18th European
Conference, EvoApplications 2015, Copenhagen, Denmark, April 8-10, 2015,
LNCS 9028, pp. 29-41, Springer, 2015.

Email addresses: d.bucur@rug.nl (Doina Bucur),

giovanniiacca@incas3.eu (Giovanni Iacca),
marco.gaudesi@polito.it (Marco Gaudesi),
giovanni.squillero@polito.it (Giovanni Squillero),
alberto.tonda@grignon.inra.fr (Alberto Tonda)

Preprint submitted to Applied Soft Computing Journal

rity in DTNs is a paradigmatic case: such networks need to re-
main open to all willing participants, and few malicious partic-
ipants may try to disrupt communications, for instance, routing
no messages to other nodes or injecting large number of mes-
sages into the network. While such a risk is plausible, precisely
assessing DTNs’ vulnerabilities is hard.

This paper focuses precisely on evaluating the amount of
damage that can be caused to a DTN by a group of synchro-
nized attackers with deep knowledge about the network. Given
a scenario, we propose to optimize attackers for minimizing the
performances of the network using a heuristic methodology. It
is important to note that the adoption of such methodology is
more a necessity than a choice: determining the most eﬀective
attack for a given network was proven to be NP-hard [2], the
complexity and number of variables involved in the problem
preclude the use of formal techniques and the size of the sce-
narios prevent exhaustive analyses.

The idea of using heuristic methods to disprove a property of
a system when formally proving it is not possible, is not a nov-
elty in itself. The simplest approach, namely random sampling
of the parameter space, is often used under the assumption that
the eﬀort employed failing to ﬁnd a counter example may be
sensibly linked to the degree of conﬁdence that a counter ex-
ample does not actually exist.

Repeated random sampling has also be used as a means to es-
timate numerical quantities when complexity and dimensional-
ity of a problem impedes the application of analytic analyses. In
the speciﬁc case of DTNs performance, it has been considered

October 8, 2018

in [3], although limited only to small networks and attackers
with no information about the environment. However, random
sampling is unlikely to provide any interesting result when the
goal is to detect a very speciﬁc corner-case scenario, such as
the damage caused by specialized attackers that are fully aware
of the network characteristics. Finally, when the search space
is too vast, even the eﬀort required to get a signiﬁcant sampling
could be excessive.

In this work, we move forward from random sampling by us-
ing an evolutionary algorithm (EA) to optimize the attackers’
parameters in order to inﬂict the maximum possible damage to
the network. We overcome the limitations of random sampling
by using the capability of the EA to drive random search to-
wards speciﬁc regions of large search spaces. Furthermore, we
extend the features of a classical evolutionary algorithm to en-
able it to ﬁnd a team of colluding attackers. As the members
of such a team cooperate in order to maximize the cumulative
damage, even at the expense of the damage caused by each sin-
gle attacker, the approach is a form of cooperative co-evolution,
an open area of research for which very few successful strate-
gies have been found so far.

We tested the proposed methodology on medium-sized net-
works describing urban scenarios with diﬀerent topologies,
where a number of agents, i.e., the network nodes, move re-
alistically. The results clearly demonstrate the eﬃcacy of the
approach: we found scenarios where even few (up to 10% of
the total network size), highly optimized attackers can reduce
the global data delivery in the network by over 90%, when
compared to the network with no attackers. We also observed
that the composition of the attacker team obtained by evolution
changed when cooperative co-evolution is used, demonstrating
that such scheme leads to synergistic solutions not found by
classical evolutionary algorithm.

The rest of the paper is organized as follows: the next section
summarizes the research background; Section 4 details the pro-
posed methodology; Section 5 reports the experimental eval-
uation; Section 3 surveys the related work; ﬁnally, Section 6
concludes the paper.

2. Background

This section ﬁrst gives an overview of the application do-
main of Delay-Tolerant Networks. Sections 2.1-2.2 describe the
paradigm of routing in DTNs, and First Contact, the DTN pro-
tocol under study. Section 2.3 summarizes the mobility model
that an urban DTN node follows, from the literature. Sec-
tion 2.4 describes the two main types of security attacks rele-
vant: black hole and ﬂooding attacks. Finally, Section 2.5 gives
an overview of the EA ﬁeld.

a mixed terrestrial-and-space network where some of the nodes
are Low-Earth Orbiting Satellites, and the rest are ground users;
this was the application for which DTN-speciﬁc routing proto-
cols were originally designed [4]. More recently, DTNs have
also been proposed in scenarios with nearly unpredictable con-
nectivity. This is the case of animal-tracking applications [5]
and opportunistic urban networks. An example of the latter is
the 30-bus experimental DieselNet [2], in which urban vehicles
constrained to city roads act as mobile message routers. It is
urban scenarios with unpredictable connectivity that we study
in this paper.

Given an application scenario, the main performance factors
for a DTN message-routing protocol quantify the protocol’s
ability to route messages in that scenario, and the timeliness
of the routing:

Delivery rate The percentage of messages injected in the net-
work by nodes which were successfully delivered to their
destination nodes.

Message delay The average time interval between a message

injection in the network until its delivery.

2.2. DTN routing: the First Contact protocol

A DTN routing protocol essentially implements a logic to
achieve message routing in the mobile network, end-to-end
from the source of a message to its destination, over a con-
nectivity graph which varies in time and is by nature discon-
nected. Given these scenarios, the protocol logic cannot be
based on standard distributed algorithms for computing short-
est paths end-to-end in a graph: the routing can not converge on
correct routes when the network graph is highly dynamic. In-
stead, DTN message communication on a path between source
and destination include long-term storage of the message in the
nodes’ (ﬁnite) node buﬀers, until an opportunity for further de-
livery of the message arises. This ability to safely delay the
forwarding of a message is typical of DTN routing protocols.

DTN protocol design follows a simple taxonomy based on

the following features:

Network knowledge A protocol aiming to compute optimal
paths at a node would be helped if the node is able to pre-
dict the future network conditions: the pattern of contact
with other nodes, the set of nodes with congested buﬀers,
and the pattern of traﬃc demands. While network knowl-
edge may be acquired in practice by an attacker via mon-
itoring the network, many protocols cannot assume any
(i.e., are zero-knowledge).

2.1. Delay-Tolerant Networks: performance objectives

Delay-Tolerant Networking was designed to cater for mes-
sage routing in practical applications with heavy node mobility.
In such applications, the connectivity pattern between nodes
in the network can be either predictable or unpredictable with
time. An example DTN with predictable connectivity is that of

Message replication Forwarding protocols simply route the
original message through the network. Replicative proto-
cols introduce into the network a number of copies of each
original message, each of which is then forwarded inde-
pendently with the aim that at least one copy reaches the
destination.

2

We study here one of the simplest and most common DTN
routing protocols, namely First Contact (FC) [4]. FC is zero-
knowledge and forwarding; it routes messages opportunisti-
cally using any available contacts with other nodes. A single
copy of each message in the network exists at a time, and it
is forwarded to the ﬁrst available contact (if more contacts are
available, one is chosen randomly among all the current con-
tacts). On simple network topologies, FC was shown to have
performance comparable to partial-knowledge protocols; this
degrades in complex topologies to varying degrees, depending
on the network load.

2.3. Node movement models in DTNs

Models describing realistically [6] the free, stochastic move-
ment in urban environments of nodes of diﬀerent kind (pedes-
trian, cars, buses, etc.) can be used to study an urban DTN
computationally. In a DTN simulation, each movement model
is associated to a diﬀerent map layer. A map layer describes the
areas of the map reachable by the associated kind of nodes. The
building blocks of these node movement patterns are a node’s
points of interest (POIs) located on a map layer.

Nodes in our DTNs follow a classic movement model: ran-
dom waypoint with shortest paths.
In this model, node ran-
domly chooses a destination point from a set of points of inter-
est; travels there at a realistic speed on the shortest path; takes
a break. Then, it repeats the process. This can be considered
realistic: in [3], which evaluated the theoretical resilience of the
real-world DieselNet and Haggle DTN prototypes, the network
logs showed that Haggle nodes mimicked the random-waypoint
model fairly closely.

2.4. Types of security attacks

Like a DTN routing protocol, an attacker also may or may
not have knowledge of the future connectivity patterns in the
network. A strong attacker has full network knowledge, i.e.,
will know:

• The structure of the city map;

• The pattern of network encounters: for example, a statisti-
cal estimation of how many honest nodes will be in prox-
imity at any given map location;

• The statistical pattern of new messages that honest nodes
will forward when encountered, and the statistical pattern
of buﬀer availability at honest nodes.

Furthermore, a group of colluding attackers has the means
necessary to synchronize their individual attacks, rather than
executing an independent logic. Any of the colluding nodes
may adopt one of the following attack logics:

Black hole attacks The attacker drops a percentage of the
packets received: this percentage is 100% in black hole
attacks.

Flooding attacks The attacker executes the same routing pro-
tocol as honest nodes, but attempts a denial-of-service pro-
cedure by injecting a (large) number of (large) messages
into the network.

2.5. Evolutionary Computation

Evolution is the biological theory that animals and plants
have their origin in other types, and that the distinguishable
diﬀerences are due to modiﬁcations in successive generations.
Natural evolution is based on random variations, but it is not a
random process: variations are rejected or preserved according
to objective evaluations, and only changes that are beneﬁcial to
the individuals are likely to spread into subsequent generations.
Darwin called this principle “natural selection” [7]: a determin-
istic process where random variations “aﬀord materials”.

When natural selection causes variations to be accumulated
in one speciﬁc direction the result may strikingly resemble a
deliberate optimization process. However, such optimization
processes only required to assess the eﬀect of random changes
and not the ability to design intelligent modiﬁcations. Several
scholars were inspired by such an outcome and tried to repro-
duce the process for solving practical optimization problems in
various application domains, while others tried to mimic it to
better understand its underlying mechanisms.

Evolutionary Computation (EC) is the oﬀshoot of computer
science focusing on algorithms loosely inspired by the theory of
evolution. The deﬁnition is deliberately vague since the bound-
aries of the ﬁeld are not, and cannot be, sharply deﬁned. EC is
a branch of computational intelligence, and it is also included
into the broad framework of bio-inspired meta-heuristics. EC
does not have a single recognizable origin. Some scholars iden-
tify its starting point in 1950, when Alan Turing drew attention
to the similarities between learning and evolution [8]. Others
pointed out the inspiring ideas that appeared later in the decade,
despite the fact that the lack of computational power impaired
their diﬀusion in the broader scientiﬁc community [9]. More
commonly, the birth of EC is set in the 1960s with the appear-
ance of three independent research lines: John Holland’s ge-
netic algorithms [10]; Lawrence Fogel’s evolutionary program-
ming [11]; Ingo Rechenberg’s and Hans-Paul Schwefel’s evolu-
tion strategies [12]. The three paradigms monopolized the ﬁeld
until the 1990s, when John Koza entered the arena with genetic
programming [13]. Nowadays, all these methods, together with
several variants proposed over the years, have been grouped un-
der the umbrella term of evolutionary algorithms (EAs).

When EAs are used to solve a speciﬁc problem, i.e. optimize
solutions for it, an individual is a single candidate solution, and
its ﬁtness is a measure of its capacity of solving the problem;
the set of all candidate solutions that exists at a particular time
represents the population. Evolution proceeds through discrete
steps called generations.
In each of them, the population is
ﬁrst expanded and then collapsed, mimicking the processes of
breeding and struggling for survival (Figure 1).

Usually, parents are chosen for breeding stochastically, with
the best candidate solutions having higher probabilities to gen-
erate oﬀspring. As a result, new candidate solutions are more
likely to inherit favorable traits. Conversely, the removal of in-
dividuals is usually deterministic: the less ﬁt, and possibly the
oldest ones, are deleted. The mechanisms used to generate the
oﬀspring are collectively named genetic operators. They can be
divided into recombinations and mutations: the former methods

3

aiming to minimize the delivery rate of the network, the sim-
pler quality-of-service metric of total reachability substitutes
it, which in turn can be minimized eﬀectively with heuristics.
This metric is deﬁned as follows. A DTN D = (N, C) is a sin-
gle predeﬁned list of connection events C on the set of honest
nodes N of size n; this can be obtained by monitoring the long-
term execution of a real-world DTN. Two nodes are temporally
connected in D if there exists a (temporally non-decreasing)
sequence of connection events in C. Then, the total reachabil-
ity of D, denoted R(D), is the number of pairs of temporally
connected nodes (excluding reﬂexive pairs). To select k attack-
ers out of the set N while minimizing R(D) on a predeﬁned D,
the greedy heuristic simply selects as the ith attacker that node
which lowers the total reachability of D (excluding the ﬁrst i−1
attacker) the most. While this greedy heuristic is not proven
analytically to be optimal at minimizing R(D), it is shown ex-
perimentally to give similar results as a brute-force method, for
k ≤ 5, on the two DTNs under study.

The greedy heuristic is then shown to outperform a random
selection of nodes when k ≥ n
10 (i.e., at least 3 strong attackers
for n = 30) on the DieselNet DTN, and for any k ≥ 1 on the
Haggle DTN, for black hole attacks and the MaxProp routing
protocol. The heuristic is particularly advantageous for a very
large k; there, the diﬀerence between the delivery rate found
when k = n
2 is 30 − 40% lower on the two DTNs than with
random node selection.

3.3. Bio-inspired Heuristics

Evolutionary computation has been demonstrated a power-
ful means for tackling the inherent complexity of networking.
In [15], Baldi et al. proposed the use of a genetic algorithm
for minimizing the performance of a network, with the ﬁnal
goal to pinpoint potential bottlenecks of the topology. The ap-
proach exploits an accurate network simulator coupled with a
rudimentary evolutionary optimizer written in Perl. It could be
considered a proof of concept, as experimental results do not
show any real application.

A feasibility study of the approach described in the present
work, exploiting a far more conventional EA and tested only on
a reduced set of scenarios, was presented in [16]. In previous
research, we showed the eﬃcacy of an evolutionary algorithm
also in the context of wireless sensor networks (WSN), for
which we tested two kinds of collection tree protocols [17, 18].
We tackled diﬀerent network topologies composed of up to 50
nodes, making use of a real-code simulator, which enables to
analyze the complete software implementation of the protocols
under analysis. Furthermore, the gathered data enabled us to
pinpoint a set of topological factors which correlate with ex-
treme traﬃc under collection routing. In [19], we further en-
hanced such analysis through the use of a multi-objective evo-
lutionary algorithm, in the attempt to explore the WSN search
space from a multi-objective perspective rather than using lexi-
cographic order of ﬁtness functions.

Figure 1: Flowchart of an evolutionary algorithm

mix together the information contained in two or more solutions
to create new ones; the latter ones work by changing the struc-
ture of a single solution. Recombination operators are able to
coalesce good characteristics from diﬀerent solutions, and pro-
vide a very eﬀective mechanism to explore the search space;
mutation operators, on the other hand, allow the ﬁne-tuning of
the candidate solutions. Maintaining a set of solutions, EAs are
resilient to the attraction of local optima [14].

Over the years, EAs were proven capable to solve quite diﬃ-
cult problems with very complex ﬁtness landscapes, including
open problems related to networking and protocols. In partic-
ular, EAs are known to greatly outperform random sampling
for case studies where classical optimization techniques are not
viable [14]. Evolutionary optimizers have been successfully ex-
ploited both in stationary and dynamic situations, and they were
demonstrated able to identify either single optima or Pareto sets
in multi-objective problems, see Section 3 for a summary of rel-
evant prior work.

3. Related Work

3.1. Random Sampling

To the best of our knowledge, the only experimental work on
the assessment of DTN robustness was performed by Burgess et
al.[3], who evaluated the resilience of DTNs of 30 nodes when
running four protocols. Weak attacks (without free range, but
with attackers forced to use the routes previously used by the
honest nodes) were simulated by randomly reassigning some
of the honest nodes as attackers.

3.2. Greedy Heuristic

To generate strong attacks (again, without free range), the
same authors [3] used a greedy heuristic in response to the in-
tractability of the vertex vulnerability problem. First, instead of

4

4. Proposed Methodology

As stated in the introduction, the core idea of this work is
to expose vulnerabilities in a DTN by devising a set of eﬀective
attackers. As a single attacker is unlikely to be able to damage a
DTN network, we seek for teams of colluding malicious nodes.
Both the number of attackers and their type (black hole or ﬂood-
ing) should be optimized in order to create the maximum dam-
age. Attackers are optimized using an advanced evolutionary
algorithm that is based on an recent cooperative co-evolution
approach that is not only able to optimize the parameters of
each individual attacker, but also to optimize the composition
of the team of colluding attackers.

In more detail, we simulate a realistic DTN over an urban
environment deﬁned by a topological map and a set of POIs.
We assume two type of nodes: honest and malicious. As dis-
cussed earlier, for each honest node i the predetermined moving
path PH
is a sequence of random points of interest. For added
i
realism, a small number of these points, such as main tourist at-
tractions, may be given a higher probability of being selected as
next destination. On the contrary, for each malicious node i, the
path PM
is a sequence of points of interest chosen by the evo-
i
lutionary optimizer to cause maximum damage in the network.
Honest nodes execute the FC routing protocol, while malicious
nodes can act either as data ﬂooders or black holes.

In the proposed framework, we use the Opportunistic Net-
work Environment simulator (The ONE) [6]1 coupled with the
evolutionary toolkit µGP [20]2. The reasons for using µGP are
manifold: ﬁrst, the design of this framework is based on the no-
tion of an external evaluator, which simpliﬁes the integration
with an external network simulator; secondly, the algorithm
available in µGP features a built-in support for multiple ﬁtness
functions, that can be evaluated both in a lexicographical order
and in a multi-objective approach; then, the evolutionary en-
gine available in µGP makes use of self-adaptation techniques,
greatly limiting the number of parameters that require to be set.
Finally, µGP provides both a classical EA and a cooperative
co-evolution scheme called Group Evolution (see below).

The resulting evolutionary optimization process, depicted in
Figure 2, can then be summarized as follows: given a DTN of
N total nodes, and any parameters of the urban environment,
ﬁnd a group of attackers of size k < N, each one with its pe-
i (i = 1 . . . k) and its characteristics
culiar movement patterns PM
(movement model and attack type) which would lower the data
delivery rate (DDR) of the DTN the most, while maximizing
also its average latency.

The following section gives details about the evolutionary
core and the Group Evolution scheme, while the internal so-
lution representation and the ﬁtness function deﬁnitions are de-
scribed in Section 4.2 and 4.3, respectively.

4.1. Evolutionary core

A noticeable branch of EC is cooperative co-evolution
(CCE), that is, broadly speaking, the study of evolutionary al-

1The tool is available at http://www.netlab.tkk.fi/tutkimus/dtn/

theone/.

2The tool is available at http://ugp3.sourceforge.net.

Figure 2: Structure of the proposed framework. Candidate solutions and ﬁtness
values are internally represented as text ﬁles.

gorithms whose ﬁnal goal is achieved by a solution composed
of diﬀerent sub-solutions that cooperates to reach the common
goal. The idea of CCE dates back to the origin of EC, yet its
inherent problems are far from being solved: important contri-
butions are appearing regularly in the scientiﬁc literature (e.g.,
[21, 22, 23, 24, 25]). In the last decade, the CCE popularity fur-
ther boasted due to robotics applications where teams of robots
can be asked to perform collective tasks [26].

In CCE, sub-solutions may be heterogeneous or homoge-
neous, and combining them might be more or less trivial. Nev-
ertheless, almost all approaches strive to optimize the single
parts independently, while trying periodically to group them
into an eﬀective set, possibly exploiting heuristics or ad-hoc
tweaks. One of the main challenges in CCE is that optimizing a
single component may not be beneﬁcial to the global solution,
yet the algorithm has to harmonize the two possibly contrasting
selective pressures.

Group evolution (GE) is yet another take on CCE, natively
provided by µGP. In GE, the individual optimization phase and
the group optimization phase are blended into a single seam-
less process [27]. Individuals are merely the parts that can be
assembled to compose the groups, while groups are the actual
candidate solutions. GE stores a population of individuals and
a separate population of groups (see Figure 3), but new individ-
uals and new groups are created with no predeﬁned order: the
evolutionary core may choose the best sequence of operators
acting on individuals, and operators acting on groups. However
the user may still impose a minimum or maximum cardinality
for groups.

Another peculiarity of GE is that single individuals and sets
of individuals (i.e., groups) are evaluated by the very same ob-
jective function (e.g., the loss of performance in a DTN in the
context of this paper). This choice enables both a generaliza-
tion in the ﬁtness calculation and a tighter integration between
the two levels of evolution. The ﬁtness assigned to groups de-
pends on the cumulative eﬀect of the individuals belonging to
it, while the contribution of each single individual is also stored
and used during comparison.

More operatively, each group is a set of references to indi-
viduals in the individual population: so, the same individual
can belong simultaneously to multiple groups. At every gener-

5

Figure 3: A high-level scheme of the two-population approach used by GE.
Groups are sets of individuals taken from the individual population. The same
individual can appear multiple times in the same group or in diﬀerent groups:
for example, individuals 1 and 2 belong to both groups A and B.

ation, once new groups and individuals are created and evalu-
ated, groups are sorted by their ﬁtness function, and the worst
are removed, factually deleting references to certain individu-
als. After this process, orphans, i.e., individuals not belonging
to any group in the current group population, are also deleted.
Interestingly, GE can be used with no modiﬁcation to op-
timize single attackers: when the maximum size of a group
is set to 1, the evolutionary core automatically stops using
group manipulation operators, such as addElementToGroup
and removeElementFromGroup. For the purpose of this work,
we further modiﬁed the original GE available in µGP introduc-
ing a new mechanism for choosing which operators to use in
the current generation, and a strategy for caching the results of
past evaluations [28]. The ﬂowchart of the GE algorithm used
in this work is shown in Figure 4.

4.2. Internal solution representation

In the problem under study, we consider a model of strong
colluding attackers with full network knowledge and free range
of movement. In other words, we consider attacks carried out
by multiple collaborating nodes which are connected via alter-
native communication links. In this context, a candidate solu-
tion represents a group of one or more malicious nodes, each
one characterized by the following properties:

• the attack logic to adopt (e.g., black hole, ﬂooding); we
assume this choice remains unchanged during an attack;

• the movement model (e.g., pedestrian, vehicle), which con-
strains the node to a corresponding map layer and mobility
pattern;

• the route on any given map layer, deﬁned via a list of POIs
on that map layer; free-range strong attackers have full
control when deciding their POIs.

The resulting structure of a candidate solution is thus quite
complex, as each attacker can feature a variable number of
POIs, and each group can have a variable number of attack-
ers. An example of solutions produced by the evolutionary core
is shown in Figure 5.

Figure 4: Flowchart of an evolutionary algorithm using group evolution. Oper-
ations exclusive to GE are depicted in black. New groups and new individuals
are created in a single uniform step, while to evaluate new groups the evaluation
of new individuals is required.

In a classical EA, the individual would then be a (either ﬁxed-
or variable-size) composition of multiple attackers with diﬀer-
ent properties. When GE is applied instead, each individual
models exactly a single attacker, while the organization of such
malicious nodes is delegated to groups, with a ﬁnal result struc-
turally similar to the case where a single individual portrays
several nodes.
In any case, the genetic operators can act on
each node, modifying its movement model, its attack logic, and
adding/removing/replacing POIs in its path, in order to generate
new candidate solutions. In experiments with a variable num-
ber of malicious nodes, the same operations can be performed
on the blocks representing the nodes.

It is important to notice that the same POIs have diﬀerent
meanings depending on the node’s movement: even if a vehi-
cle and a pedestrian pass close to the same coordinates, they
may reach them using diﬀerent paths, causing distinct network
disruptions along the way. Also, since most of the POIs are
accessible by certain types of movement only (e.g., a point in
open water cannot be reached by a pedestrian, nor one on land

6

Mov=vehicle
Attack=black hole
94,39
55,84
...
42,44
1,26

Mov=pedestrian
Attack=flood
22,75
43,15
...
65,61
15,58

Mov=boat
...
...
...
...
...
...

Figure 5: Example of solution for the DTN attack problem, describing multiple
attackers. Each attacker is characterized by its movement model (e.g. boat,
pedestrian, vehicle), its attack logic (black hole or ﬂood), and a series of POIs
it will visit during the simulation, encoded as squares in a grid overlapped to
the city map.

by a boat), for each type we overlap a grid layer onto the city
map layer, and deﬁne the path of an attacker of that type as a set
of grid squares inside that grid. During the simulation, we then
map each grid square to the map point closest to the square; if
a square contains more than one map point, the malicious node
visits them all.

In particular, µGP exploits a user-deﬁned description of solu-
tions in an XML ﬁle. The external representation of candidate
solutions is written to text ﬁles as they are evaluated, while their
internal structure is stored to disk as XML ﬁles, that can be read
in case the evolutionary process is resumed.

4.3. Fitness functions

Movement model, attack logic and POIs to visit are set at the
level of each malicious node, but the objective is to maximize
the global eﬀectiveness of the attack: an optimal set of collud-
ing attackers should lower the performance objectives of the
network the most. The eﬀectiveness of an attack conﬁguration
is thus assessed as an evaluation of an urban network scenario
(see next Section) performed by the network simulator. The
outputs of such simulation (i.e., the ﬁtness values, using the ter-
minology of EC), are:

• ( f1) the data delivery rate (DDR), calculated as the per-
centage of messages originated only from honest nodes,
and which are delivered successfully;

• ( f2) similarly, the average latency of message deliveries (in

seconds).

The two values are considered in lexicographic order, as we
assign more importance to a reduction of the network’s DDR
rather than an increase of latency: optimization-wise, f1 is to
be minimized, while f2 is to be maximized.

5. Experiments

This section ﬁrst summarized the conﬁguration settings for
the experimental campaigns. Sections 5.1 and 5.2 quantify
the parameters used to deﬁne an urban setting and its network
nodes. Section 5.3 summarizes the experimental parameters of
the evolutionary core. Sections 5.4 and 5.5 give the numerical
results and discuss their practical impact.

We make public the city maps, the experimental conﬁgura-

tions, and detailed experimental results, at the URL:
https://github.com/doinab/DTN-security.

5.1. DTN and the cities: San Francisco and Venice

To validate our methodology, we simulate two realistic,
large-scale city environments, each composed of a map and a
large set of honest, randomly moving network nodes of cer-
tain types relevant to a given city. Figures 6 and 7 show the
basic maps of the two urban environments in our experimen-
tal scenarios, namely San Francisco and Venice. These cities
diﬀer in terms of map topology: while the area of San Fran-
cisco has a regular grid structure of routes, the area of Venice
has a complex, hierarchical, irregular structure of main and sec-
ondary waterways travelled by boats, with pedestrians conﬁned
to inner walkways (some along waterways) and bridges. The
Venice map has an additional feature for added realism: on both
map layers, a small number of the map POIs mark the touristic
center, and have a higher probability to be chosen as the next
destination by the honest nodes. Table 1 quantiﬁes the maps
and map layers in terms of size, number of distinct map points,
route segments, and number of nodes.

Figure 6: A 5 km2 area of downtown San Francisco, US, with a grid-based
map topology of streets and the occasional park. The map has two overlapping
layers, constraining the movement of vehicles and pedestrians: the vehicles are
conﬁned to the black streets, while the pedestrians may walk both the green and
the black routes.

5.2. Network simulation and network nodes

In both cities we conﬁgured N = 200 moving network nodes,
divided in two types: pedestrians (75%) and vehicles (25%).
For San Francisco, the vehicles consist of motorized cars; in
Venice, the waterways serve as routes for motorized or unmo-
torized boats. Pedestrians are modelled as carrying commu-
nication devices with relatively limited capabilities: a Blue-
tooth communication interface with a range of 15m and low
bandwidth. Vehicles are awarded more communication capa-
bilities: besides a Bluetooth interface (which allows commu-
nication events to take place between any pedestrian and any
vehicle), a vehicle also has a high-speed, longer-range network
interface allowing vehicle-to-vehicle communication.

7

Table 1: Network parameters: city maps

San Francisco:

Venice:

size:
map layers:
no. of route segments:
no. of map points:
network size:

2416 m × 2253 m
LP (pedestrian walkways), LS (streets)
1728 in LP, 1305 in LS
1210 in LP, 883 in LS
150 pedestrians (constrained to LP), 50 cars (constrained to LS )

size:
map layers:
no. of line segments:
no. of map points:
network size:

2210 m × 2340 m
LP (pedestrian walkways), LW (waterways)
7983 in LP, 1497 in LW
6910 in LP, 1354 in LW
150 pedestrians (constrained to LP), 50 boats (constrained to LW )

an (e.g., pedestrian) attacker then only diﬀers from that of an
honest pedestrian in that the attacker’s next destination point is
randomly chosen from the evolved set of POIs, rather than the
entire map layer.

Honest nodes periodically inject new messages to be routed
by the network; the rate of message injection among all honest
nodes is set at one message every 30 seconds, such that the
network routes 120 honest messages per hour. The honest node
to inject the next message in the network is chosen randomly.
The malicious nodes run one of the two attack logics described
in Section 2.4.

A black hole attacker does not inject any additional messages
in the network. On the other hand, when an attacker executes
a ﬂood, the parameters are chosen to obtain a “heavy” ﬂood of
messages: (1) a ﬂooding node injects messages in the network
at 10 times the frequency of message injection from an honest
node, and (2) the messages injected by a ﬂooder are 10 times as
large as regular messages. Table 3 summarizes these communi-
cation parameters, together with the settings regarding the sizes
of the nodes’ message buﬀers, and the Time To Leave (TTL),
which limits the amount of time that a message is allowed to
be stored in a node’s buﬀer without being forwarded — we set
TTL to be large, and equal to the length of an experiment: 5
hours (simulated time).

5.3. Evolutionary parameters

During all the experiments, µGP has been conﬁgured with
the parameters reported in Table 4. The operators chosen for
the evolution are:

• onePointImpreciseCrossover:

one-point crossover

between two individuals;

• twoPointImpreciseCrossover: crossover with with

two cut points;

• singleParameterAlterationMutation: mutate a sin-
gle coordinate of a POI, the movement model or the attack
logic;

• insertionMutation: add a new random POI;

• removalMutation: remove a randomly selected POI;

• replacementMutation: replace a POI with a randomly

generated one.

8

Figure 7: A 5 km2 area of downtown Venice, IT, with an irregular map topology
of pedestrian pathways (the black map layer) and waterways (the blue layer).
Marked with stars are special POIs in the city’s touristic center.

Each simulation of a DTN in The ONE is stochastic. The
nodes are initially placed randomly on their map layer, and a
1,000-second warm-up simulation period is allowed before the
experiment starts, for the nodes to settle on the “natural” pre-
ferred routes in the city. The next destination POI is also chosen
randomly. Due to this, to smoothen the ﬁtness landscape and
reduce the eﬀect of the random seed of each simulation on the
evaluation of solution, we execute each network simulation 10
times, initialized with diﬀerent random seeds, and report as ﬁt-
ness values the average DDR and latency over the 10 available
repetitions.

The movement model of all nodes follows the general ran-
domized pattern summarized in Section 2.3. A subset of these
200 nodes is assigned a malicious behaviour. For an honest
node, the set of POIs is simply the entire set of map points lo-
cated on the node’s relevant map layer. The node randomly
chooses any destination point from that map layer, travels there
at a certain speed on the shortest path, pauses for an interval,
and repeats the process. The conﬁguration for the nodes’ speed
and pause interval is given by Table 2. For an attacker, the set
of POIs is is a subset of the map points of the relevant map
layer, and is evolved by the evolutionary core as part of each
solution (as described in Section 4.2). The movement model of

Table 2: Network parameters: movement models

Movement model
for nodes in all cities

next point:
path choice:
pedestrian speed:
boat speed:
car speed:
pause interval for all:

chosen randomly from a map layer
shortest path on the map layer to the next point
[0.5 . . . 1.5] m/s
[1.0 . . . 5.0] m/s
[2.7 . . . 13.9] m/s
[0 . . . 120] s at each destination point

Table 3: Network parameters: simulation and node communication settings

Simulation
settings

simulation time:
DTN simulator:

5 h
The ONE [6]

Message
settings

message issued:
message size:
message buﬀer:
message TTL:

every 30 s (by an honest node), every 3 s (by a ﬂooder)
10 kB (issued by an honest node), 100 kB (issued by a ﬂooder)
5 MB (for pedestrian nodes), 50 MB (for car and boat nodes)
5 h

Node
communication
interfaces

Bluetooth:
High-speed:
pedestrians use:
cars and boats use:

range 15 m, speed 250 kBps
range 100 m, speed 10 MBps
Bluetooth
Bluetooth and High-speed

Figure 8: Comparative results: data delivery rate (DDR) from three experimental campaigns using group evolution, a classical EA, and random testing. The DDR
obtained with a random test is shown as the mean and standard deviation among the mean DDR of 150 randomly generated groups, each group simulated 10 times
with diﬀerent random seeds. The DDR obtained with any evolutionary experiment is a single group of top ﬁtness, and is shown as the mean and 95% conﬁdence
interval among 5 simulation repetitions of that group with diﬀerent random seeds.

The activation probabilities of all the operators in the popula-
tion are self-adapted during the run; [28] enables to eﬃciently
alternate phases where individuals are optimized, with phases
where groups are optimized. Self adapting the size of the tour-
nament for selecting parents (τ) enables to optimize the selec-
tive pressure; while self adapting the strength of the mutation
operators (σ) enables to balance between exploration and ex-
ploitation. Every time a mutation is performed, it is executed
again on the same individual if a randomly generated number
in (0, 1) is lower than the current value of σ. For high values
of σ, the algorithm will tend to generate new solutions that are
very diﬀerent from their parents, thus favoring exploration; for
low values of σ, the diﬀerences between parents and oﬀspring

will be smaller, thus entering a phase of exploitation.

During the GE experiments, new operators are added in order

to manipulate groups, namely:

• groupRandomInsertionMutation: add a random indi-

vidual to a group;

vidual from a group;

• groupRandomRemovalMutation: remove a random indi-

• groupBalancedCrossover: crossover that moves the

same number of individuals between two groups;

• groupUnbalancedCrossover: same as above, with no
guarantee of moving the same number of individuals;

9

Table 4: µGP experimental settings

• A GE-based experimental campaign (for the settings

where k > 1);

Parameter Description

τ
σ
α
§

µ
λ

size of the tournament selection
initial strength of the mutation operators
inertia of the self-adapting mechanisms
stagnation threshold (in generations)

Classical EA

individual population size
operators (genetic) applied at every step

Group Evolution

µgroup
νindividual
λ

group population size
initial individual population size
operators (genetic or groups) applied at every step

Value

1.0÷4.0
0.9
0.9
50

30
20

30
50
20

• groupUnionIntersection: returns the union and the in-

tersection of two groups;

• groupDreamTeam: creates a group with some of the best

individuals currently in the population.

As previously detailed, the number of individuals in the GE
paradigm is regulated by the number of groups in the current
population, µgroup. Individuals are removed only when they are
no longer included in any group. The number of individuals
generated at the beginning of the execution, number that can be
later exceeded or reduced, is controlled by parameter νindividual.
Further information on parameters and operators in µGP can be
found in [20].

5.4. Experimental campaigns and results

Given the settings described in Sections 5.1–5.3, which are
common to all experiments, an experiment will be uniquely
identiﬁed by the following two parameters:

City (i.e., San Francisco or Venice)

Number of attackers i.e., the size of the attack group k, in the
range 1 ≤ k ≤ N. We delineate ﬁve practically interesting
ranges:

• k = 1, i.e., a single attacker;
• k = 2, i.e., a pair of attackers;
• k ∈ [1 . . . 5];
• k ∈ [6 . . . 10];
• k ∈ [11 . . . 20], i.e., a group which can reach 10% of

the overall network size of N = 200 nodes.

The ranges for k thus come in two categories: a ﬁxed group
size (when k = 1 or k = 2), or a variable group size (for larger
k). In the latter case, intuitively, the expectation is that the evo-
lutionary algorithm will maximize the group size in the process
of optimizing the ﬁtness functions.

To assess the comparative performance of our method based
on Group Evolution, we ran the following three experimental
campaigns, for each experimental setting (City × Number of
attackers):

• An experimental campaign based on the classical, non-GE
EA applied to the same problem in prior literature [16];

• The testing of groups of a sample of 150 purely randomly

generated groups of attackers.

For each experimental setting, the GE and non-GE experimen-
tal campaigns consist of 5 experiment repetitions, initialized
with diﬀerent random seeds.

The results of the experimental campaigns are summarized
in Figure 8, separately per city. The ﬁrst ﬁtness function, f1,
measuring the global data delivery rate (DDR) in the network,
quantiﬁes the decreasing network performance with an increas-
ing size of the attack group, k. In the ﬁgures, the data points
are presented for the set k ∈ {1, 2, 5, 10, 20}, as the evolution-
ary algorithms found that the lowest ﬁtness is achieved when
the size of the attacker group is maximum. For comparison, the
ﬁgures also include a data point showing the ﬁtness function
with no attack present (i.e., all N = 200 nodes in the network
are honest).

As seen in Figure 8, while the First Contact protocol has only
moderate data delivery in these complex urban settings even
in the absence of attacks, both evolutionary algorithms signif-
icantly outperform random testing, and GE was found to be
advantageous in all the experimental settings. Moreover, a sim-
ilar trend for the performance of the First Contact protocol was
obtained between the two cities: a single attacker was found
suﬃcient to lower the data delivery to half that of the no-attack
setting, and, with a group of 20 attackers, the data delivery in
the network was found to drop close to zero.

To further conﬁrm this trend, we performed a thorough anal-
ysis [29] of the numerical results. The analysis was conducted
as follows: for each city map and attack group size k > 1 (when
k = 1 a group cannot be deﬁned), ﬁrst we aggregated the 150
lowest DDR values obtained by GE and non-GE experiments,
over the 5 available repetitions for each of the two algorithms.
We then performed pairwise comparisons between the two al-
gorithms, and w.r.t.
the DDR of the 150 randomly sampled
attack groups used as baseline. For each pairwise comparison,
we initially verify the normality of the two distributions with
the Shapiro-Wilk test; if both samples are normally distributed,
we then test the homogeneity of their variances (homoscedas-
ticity) with an F-test. If variances are equal, we compare the
two distributions by means of the Student t-test, otherwise we
adopt Welch’s t-test variant. More speciﬁcally, we ﬁrst test the
null-hypothesis of equal distributions (i.e. the two algorithms
under comparison are statistically equivalent from an optimiza-
tion point of view); then, we test the null-hypothesis that the
ﬁtness values obtained with one of the two algorithms, taken
as reference, are statistically smaller than those obtained by the
other algorithm.
In case of non-normal distributions, we in-
stead test the null-hypotheses by means of the non-parametric
Wilcoxon Rank-Sum test. In all the tests, we consider a conﬁ-
dence level of 0.95 (α = 0.05).

10

The statistical analysis is summarized in Table 5. The anal-
ysis conﬁrms that GE and non-GE EA statistically outperform
random sampling, and GE outperforms non-GE in all cases.

Table 5: Summary of the statistical analysis (see the main text for details). Each
column (labeled as X/Y) shows the pairwise comparison between the results
obtained by algorithm X and Y, with X taken as reference. The symbol ’+’
indicates that X statistically outperforms Y, i.e. it obtains attacker groups with
lower network performance (DDR).

San Francisco

GE/Random non-GE/Random

No. attackers
2
1-5
6-10
11-20

No. attackers
2
1-5
6-10
11-20

GE/non-GE
+
+
+
+

GE/non-GE
+
+
+
+

+
+
+
+

+
+
+
+

+
+
+
+

+
+
+
+

Venice

GE/Random non-GE/Random

5.5. Runtimes and discussion of results

In Figure 9 we show the computational cost of running the
evolutionary campaigns, each data point the average of 5 rep-
etitions of an experiment with diﬀerent seeds. The runtime is
shown in core-hours, over computing cores of at least 1.6 GHz
(since we ran the experiments on a number of machines, there
was variation among the computational power allowed among
experiments).

More interestingly, the reason why the GE algorithm shows
an advantage over a classical EA is seen in Figure 10. The ﬁg-
ure ﬁrst selects all the “top” attacker groups obtained by the GE
and non-GE experiments, i.e., those groups which lower net-
work performance to within 2% of the absolute best ﬁtness f1
found by that algorithm. We observed that the number of these
top groups falls between 300 and 6, 000 (depending on the ex-
perimental setting), all of which can be considered successful
attacks. The average composition of this large group sample is
analyzed in terms of how often a type of attacker, i.e., a move-
ment model (that of a pedestrian, or that of a vehicle) and attack
logic (black hole or ﬂooding) appears in a top group.

The best single attacker found by both the GE and non-GE
algorithms is a black hole vehicle:
indeed, 100% of the top
groups found by both algorithms consist of an attacker of this
type. The same is true for pairs of attackers.

For larger group sizes, the two algorithms show a diﬀerence
of results. When k ∈ [11 . . . 20], the non-GE algorithm found an
overall lower top ﬁtness while obtaining top groups for which:
(1) the average group size does not saturate (it reaches an aver-
age of 18.23 out of 20, for the San Francisco setting), and (2)
the average group composition is a mix of attacker types, with
only 50% of the attackers in the top groups matching the type
of the best single attacker (a black hole vehicle).

On the other hand, the GE algorithm likely outperformed the
non-GE in terms of best ﬁtness found due to the fact that it both
maximized the average top group size, and optimized the aver-
age top attacker type, demonstrating that homogeneous groups

Figure 9: Computational overhead of non-GE and GE experiments: the number
of evolutionary generations, the number of solution evaluations, and the wall-
clock runtime per experimental campaign, shown as the average among the 5
experiments conﬁgured with diﬀerent random seeds, per experimental setting.

of black holes are advantageous to exploit the vulnerabilities in
the design of the First Contact protocol, and that faster black
hole attackers also have a clear advantage.

6. Conclusions

In this paper we proposed a heuristic methodology to as-
sess the robustness of First Contact, one of the main routing
protocols used in Delay-Tolerant Networks. To exploit possi-
ble weaknesses of the network, we considered the worst-case
scenario of an attack carried out by a coordinated group of
agents with full network knowledge. The methodology is based
on an evolutionary algorithm using a cooperative co-evolution
scheme called Group Evolution recently introduced in the liter-
ature and here extended for our purposes. The method is able
to optimize groups (either homogeneous or not) of malicious
nodes whose behaviour does not comply with the legitimate
routing protocol used by honest nodes in the network.

We performed an extensive experimental campaign over
medium-sized (i.e., 200 nodes) realistic urban networks run-
ning on two diﬀerent cities with radically diﬀerent map topolo-
gies (San Francisco and Venice). We assessed the scalability of
the approach by evaluating single attackers as well as groups of

11

Figure 10: The average group size and group composition among all top solutions (whose ﬁtness is within 2% of the best ﬁtness). The group composition is shown
in terms of the percentage of ﬂooding vehicles (FV), ﬂooding pedestrians (FP), black hole vehicles (BV), and black hole pedestrians (BP) among these top solutions.

up to 10% malicious nodes. Moreover, we compared results ob-
tained with random sampling and a more classical evolutionary
algorithm.

In all our experiments, the two evolutionary methods clearly
outperformed random sampling, consistently ﬁnding groups of
attackers that produced a larger network damage (reduced data
delivery rate and increased latency). The additional advantage
brought by Group Evolution resulted in an improved attack ef-
fect, optimized group compositions, and more eﬀective move-
ment models.

Overall, the contribution of this work is twofold: on one
hand, we proposed an eﬃcient alternative to random sampling,
that is currently one of the most used approaches for assessing
network robustness; on the other hand, we showed an example
problem that can be naturally described in terms of coopera-
tive co-evolution and for which such an evolutionary scheme is
clearly beneﬁcial.

This work represents then one of the few attempts at ﬁnd-
ing applications of cooperative co-evolution beyond the typical
domain of swarm robotics. In future research, we will seek to
extend this approach to diﬀerent networking applications and,
possibly, new unexplored domains.

[3] J. Burgess, G. D. Bissias, M. D. Corner, B. N. Levine, Surviving attacks
on disruption-tolerant networks without authentication, in: Proceedings
of the 8th ACM International Symposium on Mobile Ad Hoc Networking
and Computing, MobiHoc ’07, ACM, New York, NY, USA, 2007, pp.
61–70.

[4] S. Jain, K. Fall, R. Patra, Routing in a delay tolerant network, in: Pro-
ceedings of the 2004 Conference on Applications, Technologies, Archi-
tectures, and Protocols for Computer Communications, SIGCOMM ’04,
ACM, New York, NY, USA, 2004, pp. 145–158.

[5] P. Sommer, B. Kusy, P. Valencia, R. Dungavell, R. Jurdak, Delay-
arXiv preprint

tracking,

tolerant networking for long-term animal
arXiv:1506.01792 (2015).

[6] A. Ker¨anen, J. Ott, T. K¨arkk¨ainen, The ONE Simulator for DTN Protocol
Evaluation,
in: SIMUTools ’09: Proceedings of the 2nd International
Conference on Simulation Tools and Techniques, ICST, New York, NY,
USA, 2009.

[7] C. Darwin, On the Origin of the Species by Means of Natural Selection:
Or, The Preservation of Favoured Races in the Struggle for Life, John
Murray, 1859.

[8] A. M. Turing, Computing machinery and intelligence, Mind (1950) 433–

[9] D. B. Fogel, Evolutionary computation:

the fossil record, Wiley-IEEE

[10] J. H. Holland, Adaptation in Natural and Artiﬁcial Systems, University of

[11] L. J. Fogel, Autonomous automata, Industrial Research 4 (1962) 14–19.
[12] H.-G. Beyer, H.-P. Schwefel, Evolution Strategies – A comprehensive

introduction, Natural computing 1 (2002) 3–52.

[13] J. R. Koza, Genetic Programming: vol. 1, On the programming of com-
puters by means of natural selection, volume 1, MIT press, 1992.
[14] A. E. Eiben, J. E. Smith, Introduction to evolutionary computing, vol-

[15] M. Baldi, F. Corno, M. Rebaudengo, G. Squillero, GA-based perfor-
mance analysis of network protocols, in: Proc. Ninth IEEE International
Conference on Tools with Artiﬁcial Intelligence, 1997, pp. 118–124.

460.

Press, 1998.

Michigan Press, 1975.

References

[1] K. Fall, S. Farrell, DTN: an architectural retrospective, Selected Areas in

ume 2, Springer Berlin, 2010.

Communications, IEEE Journal on 26 (2008) 828–836.

[2] J. Burgess, B. Gallagher, D. Jensen, B. Levine, MaxProp: Routing for
Vehicle-Based Disruption-Tolerant Networks, in: INFOCOM 2006. 25th
IEEE International Conference on Computer Communications, pp. 1–11.

12

[16] D. Bucur, G. Iacca, G. Squillero, A. Tonda, Black holes and revelations:
Using evolutionary algorithms to uncover vulnerabilities in disruption-
tolerant networks, in: A. M. Mora, G. Squillero (Eds.), Applications of
Evolutionary Computation, volume 9028 of Lecture Notes in Computer
Science, Springer International Publishing, 2015, pp. 29–41.

[17] D. Bucur, G. Iacca, G. Squillero, A. Tonda, The impact of topology on
energy consumption for collection tree protocols: An experimental as-
sessment through evolutionary computation, Applied Soft Computing 16
(2014) 210–222.

[18] D. Bucur, G. Iacca, P.-T. de Boer, Characterizing topological bottlenecks
for data delivery in CTP using simulation-based stress testing with natural
selection, Ad Hoc Networks 30 (2015) 22 – 45.

[19] D. Bucur, G. Iacca, G. Squillero, A. Tonda, The tradeoﬀs between data
delivery ratio and energy costs in wireless sensor networks: A multi-
objective evolutionary framework for protocol analysis, in: Proceedings
of the Sixtienth Annual Conference on Genetic and Evolutionary Com-
putation Conference, GECCO ’14, ACM, New York, NY, USA, 2014.

[20] E. Sanchez, M. Schillaci, G. Squillero, Evolutionary Optimization: the

µGP toolkit, Springer Publishing Company, 1st edition, 2011.

[21] M. Potter, K. De Jong, A cooperative coevolutionary approach to function
optimization, in: Y. Davidor, H.-P. Schwefel, R. Manner (Eds.), Parallel
Problem Solving from Nature PPSN III, volume 866 of Lecture Notes
in Computer Science, Springer Berlin / Heidelberg, 1994, pp. 249–257.
10.1007/3-540-58484-6 269.

[22] E. Dunn, G. Olague, E. Lutton, Parisian camera placement for vision
metrology, Pattern Recognition Letters 27 (2006) 1209 – 1219. Evolu-

tionary Computer Vision and Image Understanding.

[23] R. Thomason, R. Heckendorn, T. Soule, Training time and team compo-
sition robustness in evolved multi-agent systems, in: M. O’Neill, L. Van-
neschi, S. Gustafson, A. Esparcia Alcazar, I. De Falco, A. Della Cioppa,
E. Tarantino (Eds.), Genetic Programming, volume 4971 of Lecture Notes
in Computer Science, Springer Berlin / Heidelberg, 2008, pp. 1–12.
10.1007/978-3-540-78671-9 1.

[24] M. Waibel, L. Keller, D. Floreano, Genetic Team Composition and Level
of Selection in the Evolution of Cooperation, IEEE Transactions on Evo-
lutionary Computation 13 (2009) 648–660.

[25] A. Tonda, E. Lutton, G. Squillero, Lamps: A test problem for cooperative
coevolution, in: Nature Inspired Cooperative Strategies for Optimization
(NICSO 2011), Springer, 2011, pp. 101–120.

[26] L. Panait, S. Luke, Cooperative multi-agent learning: The state of the art,
Autonomous Agents and Multi-Agent Systems 11 (2005) 387–434.
[27] E. Sanchez, G. Squillero, A. Tond, Group evolution: Emerging synergy
through a coordinated eﬀort, in: Evolutionary Computation (CEC), 2011
IEEE Congress on, IEEE, pp. 2662–2668.

[28] G. S. Jany Belluz, Marco Gaudesi, A. Tonda, Searching for the mini-
mum failures that can cause a hazard in a wireless sensor network,
in:
Proceedings of the Fifteenth Annual Conference on Genetic and Evolu-
tionary Computation Conference (to appear), GECCO ’15, ACM, New
York, NY, USA, 2015.

[29] E. L. Lehmann, J. P. Romano, Testing statistical hypotheses, Springer

Texts in Statistics, Springer, New York, third edition, 2005.

13

Optimizing groups of colluding strong attackers in mobile urban communication networks
with evolutionary algorithms(cid:73)

Doina Bucura, Giovanni Iaccab, Marco Gaudesic, Giovanni Squilleroc, Alberto Tondad

aJohann Bernoulli Institute, University of Groningen, Nijenborgh 9, 9747 AG Groningen, The Netherlands
bINCAS3, Dr. Nassaulaan 9, 9401 HJ, Assen, The Netherlands
cPolitecnico di Torino, Corso Duca degli Abruzzi 24, 10129, Torino, Italy
dINRA UMR 782 GMPA, 1 Avenue Lucien Br´etigni`eres, 78850, Thiverval-Grignon, France

8
1
0
2
 
t
c
O
 
5
 
 
]
E
N
.
s
c
[
 
 
1
v
3
1
7
2
0
.
0
1
8
1
:
v
i
X
r
a

Abstract

In novel forms of the Social Internet of Things, any mobile user within communication range may help routing messages for another
user in the network. The resulting message delivery rate depends both on the users’ mobility patterns and the message load in the
network. This new type of conﬁguration, however, poses new challenges to security, amongst them, assessing the eﬀect that a
group of colluding malicious participants can have on the global message delivery rate in such a network is far from trivial. In this
work, after modeling such a question as an optimization problem, we are able to ﬁnd quite interesting results by coupling a network
simulator with an evolutionary algorithm. The chosen algorithm is speciﬁcally designed to solve problems whose solutions can be
decomposed into parts sharing the same structure. We demonstrate the eﬀectiveness of the proposed approach on two medium-sized
Delay-Tolerant Networks, realistically simulated in the urban contexts of two cities with very diﬀerent route topology: Venice and
San Francisco. In all experiments, our methodology produces attack patterns that greatly lower network performance with respect
to previous studies on the subject, as the evolutionary core is able to exploit the speciﬁc weaknesses of each target conﬁguration.

Keywords: Cooperative Co-Evolution, Delay-Tolerant Network, Evolutionary Algorithms, Network Security, Routing

1. Introduction

The so-called Social Internet of Things calls for nearly ubiq-
uitous communicating devices. There is today a need to inte-
grate low-cost, low-power devices to support networking ser-
vices in more eﬀective and eﬃcient ways. In such a scenario,
new solutions are continuously developed and deployed, while
approaches that just a few decades ago were used only in highly
complex, niche applications are now literally brought down to
earth — Delay-Tolerant Networks (DTNs) are a technology
originally developed for space communications that, over the
years, made its way down to quite mundane applications [1].

Emerging technologies and applications are posing serious
problems to designers. In most cases there is not enough time to
thoroughly validate them, or even to simply analyze their pos-
sible failures and problems. Engineers are forced to resort to
their experience to choose heuristics that look reasonable, and
then observe the actual outcome from real applications. Secu-

(cid:73)This paper is an extended, improved version of the paper Black Holes
and Revelations: Using Evolutionary Algorithms to Uncover Vulnerabilities
in Disruption-Tolerant Networks presented at EvoComNet2015 and published
in: Applications of Evolutionary Computing, Proceedings of 18th European
Conference, EvoApplications 2015, Copenhagen, Denmark, April 8-10, 2015,
LNCS 9028, pp. 29-41, Springer, 2015.

Email addresses: d.bucur@rug.nl (Doina Bucur),

giovanniiacca@incas3.eu (Giovanni Iacca),
marco.gaudesi@polito.it (Marco Gaudesi),
giovanni.squillero@polito.it (Giovanni Squillero),
alberto.tonda@grignon.inra.fr (Alberto Tonda)

Preprint submitted to Applied Soft Computing Journal

rity in DTNs is a paradigmatic case: such networks need to re-
main open to all willing participants, and few malicious partic-
ipants may try to disrupt communications, for instance, routing
no messages to other nodes or injecting large number of mes-
sages into the network. While such a risk is plausible, precisely
assessing DTNs’ vulnerabilities is hard.

This paper focuses precisely on evaluating the amount of
damage that can be caused to a DTN by a group of synchro-
nized attackers with deep knowledge about the network. Given
a scenario, we propose to optimize attackers for minimizing the
performances of the network using a heuristic methodology. It
is important to note that the adoption of such methodology is
more a necessity than a choice: determining the most eﬀective
attack for a given network was proven to be NP-hard [2], the
complexity and number of variables involved in the problem
preclude the use of formal techniques and the size of the sce-
narios prevent exhaustive analyses.

The idea of using heuristic methods to disprove a property of
a system when formally proving it is not possible, is not a nov-
elty in itself. The simplest approach, namely random sampling
of the parameter space, is often used under the assumption that
the eﬀort employed failing to ﬁnd a counter example may be
sensibly linked to the degree of conﬁdence that a counter ex-
ample does not actually exist.

Repeated random sampling has also be used as a means to es-
timate numerical quantities when complexity and dimensional-
ity of a problem impedes the application of analytic analyses. In
the speciﬁc case of DTNs performance, it has been considered

October 8, 2018

in [3], although limited only to small networks and attackers
with no information about the environment. However, random
sampling is unlikely to provide any interesting result when the
goal is to detect a very speciﬁc corner-case scenario, such as
the damage caused by specialized attackers that are fully aware
of the network characteristics. Finally, when the search space
is too vast, even the eﬀort required to get a signiﬁcant sampling
could be excessive.

In this work, we move forward from random sampling by us-
ing an evolutionary algorithm (EA) to optimize the attackers’
parameters in order to inﬂict the maximum possible damage to
the network. We overcome the limitations of random sampling
by using the capability of the EA to drive random search to-
wards speciﬁc regions of large search spaces. Furthermore, we
extend the features of a classical evolutionary algorithm to en-
able it to ﬁnd a team of colluding attackers. As the members
of such a team cooperate in order to maximize the cumulative
damage, even at the expense of the damage caused by each sin-
gle attacker, the approach is a form of cooperative co-evolution,
an open area of research for which very few successful strate-
gies have been found so far.

We tested the proposed methodology on medium-sized net-
works describing urban scenarios with diﬀerent topologies,
where a number of agents, i.e., the network nodes, move re-
alistically. The results clearly demonstrate the eﬃcacy of the
approach: we found scenarios where even few (up to 10% of
the total network size), highly optimized attackers can reduce
the global data delivery in the network by over 90%, when
compared to the network with no attackers. We also observed
that the composition of the attacker team obtained by evolution
changed when cooperative co-evolution is used, demonstrating
that such scheme leads to synergistic solutions not found by
classical evolutionary algorithm.

The rest of the paper is organized as follows: the next section
summarizes the research background; Section 4 details the pro-
posed methodology; Section 5 reports the experimental eval-
uation; Section 3 surveys the related work; ﬁnally, Section 6
concludes the paper.

2. Background

This section ﬁrst gives an overview of the application do-
main of Delay-Tolerant Networks. Sections 2.1-2.2 describe the
paradigm of routing in DTNs, and First Contact, the DTN pro-
tocol under study. Section 2.3 summarizes the mobility model
that an urban DTN node follows, from the literature. Sec-
tion 2.4 describes the two main types of security attacks rele-
vant: black hole and ﬂooding attacks. Finally, Section 2.5 gives
an overview of the EA ﬁeld.

a mixed terrestrial-and-space network where some of the nodes
are Low-Earth Orbiting Satellites, and the rest are ground users;
this was the application for which DTN-speciﬁc routing proto-
cols were originally designed [4]. More recently, DTNs have
also been proposed in scenarios with nearly unpredictable con-
nectivity. This is the case of animal-tracking applications [5]
and opportunistic urban networks. An example of the latter is
the 30-bus experimental DieselNet [2], in which urban vehicles
constrained to city roads act as mobile message routers. It is
urban scenarios with unpredictable connectivity that we study
in this paper.

Given an application scenario, the main performance factors
for a DTN message-routing protocol quantify the protocol’s
ability to route messages in that scenario, and the timeliness
of the routing:

Delivery rate The percentage of messages injected in the net-
work by nodes which were successfully delivered to their
destination nodes.

Message delay The average time interval between a message

injection in the network until its delivery.

2.2. DTN routing: the First Contact protocol

A DTN routing protocol essentially implements a logic to
achieve message routing in the mobile network, end-to-end
from the source of a message to its destination, over a con-
nectivity graph which varies in time and is by nature discon-
nected. Given these scenarios, the protocol logic cannot be
based on standard distributed algorithms for computing short-
est paths end-to-end in a graph: the routing can not converge on
correct routes when the network graph is highly dynamic. In-
stead, DTN message communication on a path between source
and destination include long-term storage of the message in the
nodes’ (ﬁnite) node buﬀers, until an opportunity for further de-
livery of the message arises. This ability to safely delay the
forwarding of a message is typical of DTN routing protocols.

DTN protocol design follows a simple taxonomy based on

the following features:

Network knowledge A protocol aiming to compute optimal
paths at a node would be helped if the node is able to pre-
dict the future network conditions: the pattern of contact
with other nodes, the set of nodes with congested buﬀers,
and the pattern of traﬃc demands. While network knowl-
edge may be acquired in practice by an attacker via mon-
itoring the network, many protocols cannot assume any
(i.e., are zero-knowledge).

2.1. Delay-Tolerant Networks: performance objectives

Delay-Tolerant Networking was designed to cater for mes-
sage routing in practical applications with heavy node mobility.
In such applications, the connectivity pattern between nodes
in the network can be either predictable or unpredictable with
time. An example DTN with predictable connectivity is that of

Message replication Forwarding protocols simply route the
original message through the network. Replicative proto-
cols introduce into the network a number of copies of each
original message, each of which is then forwarded inde-
pendently with the aim that at least one copy reaches the
destination.

2

We study here one of the simplest and most common DTN
routing protocols, namely First Contact (FC) [4]. FC is zero-
knowledge and forwarding; it routes messages opportunisti-
cally using any available contacts with other nodes. A single
copy of each message in the network exists at a time, and it
is forwarded to the ﬁrst available contact (if more contacts are
available, one is chosen randomly among all the current con-
tacts). On simple network topologies, FC was shown to have
performance comparable to partial-knowledge protocols; this
degrades in complex topologies to varying degrees, depending
on the network load.

2.3. Node movement models in DTNs

Models describing realistically [6] the free, stochastic move-
ment in urban environments of nodes of diﬀerent kind (pedes-
trian, cars, buses, etc.) can be used to study an urban DTN
computationally. In a DTN simulation, each movement model
is associated to a diﬀerent map layer. A map layer describes the
areas of the map reachable by the associated kind of nodes. The
building blocks of these node movement patterns are a node’s
points of interest (POIs) located on a map layer.

Nodes in our DTNs follow a classic movement model: ran-
dom waypoint with shortest paths.
In this model, node ran-
domly chooses a destination point from a set of points of inter-
est; travels there at a realistic speed on the shortest path; takes
a break. Then, it repeats the process. This can be considered
realistic: in [3], which evaluated the theoretical resilience of the
real-world DieselNet and Haggle DTN prototypes, the network
logs showed that Haggle nodes mimicked the random-waypoint
model fairly closely.

2.4. Types of security attacks

Like a DTN routing protocol, an attacker also may or may
not have knowledge of the future connectivity patterns in the
network. A strong attacker has full network knowledge, i.e.,
will know:

• The structure of the city map;

• The pattern of network encounters: for example, a statisti-
cal estimation of how many honest nodes will be in prox-
imity at any given map location;

• The statistical pattern of new messages that honest nodes
will forward when encountered, and the statistical pattern
of buﬀer availability at honest nodes.

Furthermore, a group of colluding attackers has the means
necessary to synchronize their individual attacks, rather than
executing an independent logic. Any of the colluding nodes
may adopt one of the following attack logics:

Black hole attacks The attacker drops a percentage of the
packets received: this percentage is 100% in black hole
attacks.

Flooding attacks The attacker executes the same routing pro-
tocol as honest nodes, but attempts a denial-of-service pro-
cedure by injecting a (large) number of (large) messages
into the network.

2.5. Evolutionary Computation

Evolution is the biological theory that animals and plants
have their origin in other types, and that the distinguishable
diﬀerences are due to modiﬁcations in successive generations.
Natural evolution is based on random variations, but it is not a
random process: variations are rejected or preserved according
to objective evaluations, and only changes that are beneﬁcial to
the individuals are likely to spread into subsequent generations.
Darwin called this principle “natural selection” [7]: a determin-
istic process where random variations “aﬀord materials”.

When natural selection causes variations to be accumulated
in one speciﬁc direction the result may strikingly resemble a
deliberate optimization process. However, such optimization
processes only required to assess the eﬀect of random changes
and not the ability to design intelligent modiﬁcations. Several
scholars were inspired by such an outcome and tried to repro-
duce the process for solving practical optimization problems in
various application domains, while others tried to mimic it to
better understand its underlying mechanisms.

Evolutionary Computation (EC) is the oﬀshoot of computer
science focusing on algorithms loosely inspired by the theory of
evolution. The deﬁnition is deliberately vague since the bound-
aries of the ﬁeld are not, and cannot be, sharply deﬁned. EC is
a branch of computational intelligence, and it is also included
into the broad framework of bio-inspired meta-heuristics. EC
does not have a single recognizable origin. Some scholars iden-
tify its starting point in 1950, when Alan Turing drew attention
to the similarities between learning and evolution [8]. Others
pointed out the inspiring ideas that appeared later in the decade,
despite the fact that the lack of computational power impaired
their diﬀusion in the broader scientiﬁc community [9]. More
commonly, the birth of EC is set in the 1960s with the appear-
ance of three independent research lines: John Holland’s ge-
netic algorithms [10]; Lawrence Fogel’s evolutionary program-
ming [11]; Ingo Rechenberg’s and Hans-Paul Schwefel’s evolu-
tion strategies [12]. The three paradigms monopolized the ﬁeld
until the 1990s, when John Koza entered the arena with genetic
programming [13]. Nowadays, all these methods, together with
several variants proposed over the years, have been grouped un-
der the umbrella term of evolutionary algorithms (EAs).

When EAs are used to solve a speciﬁc problem, i.e. optimize
solutions for it, an individual is a single candidate solution, and
its ﬁtness is a measure of its capacity of solving the problem;
the set of all candidate solutions that exists at a particular time
represents the population. Evolution proceeds through discrete
steps called generations.
In each of them, the population is
ﬁrst expanded and then collapsed, mimicking the processes of
breeding and struggling for survival (Figure 1).

Usually, parents are chosen for breeding stochastically, with
the best candidate solutions having higher probabilities to gen-
erate oﬀspring. As a result, new candidate solutions are more
likely to inherit favorable traits. Conversely, the removal of in-
dividuals is usually deterministic: the less ﬁt, and possibly the
oldest ones, are deleted. The mechanisms used to generate the
oﬀspring are collectively named genetic operators. They can be
divided into recombinations and mutations: the former methods

3

aiming to minimize the delivery rate of the network, the sim-
pler quality-of-service metric of total reachability substitutes
it, which in turn can be minimized eﬀectively with heuristics.
This metric is deﬁned as follows. A DTN D = (N, C) is a sin-
gle predeﬁned list of connection events C on the set of honest
nodes N of size n; this can be obtained by monitoring the long-
term execution of a real-world DTN. Two nodes are temporally
connected in D if there exists a (temporally non-decreasing)
sequence of connection events in C. Then, the total reachabil-
ity of D, denoted R(D), is the number of pairs of temporally
connected nodes (excluding reﬂexive pairs). To select k attack-
ers out of the set N while minimizing R(D) on a predeﬁned D,
the greedy heuristic simply selects as the ith attacker that node
which lowers the total reachability of D (excluding the ﬁrst i−1
attacker) the most. While this greedy heuristic is not proven
analytically to be optimal at minimizing R(D), it is shown ex-
perimentally to give similar results as a brute-force method, for
k ≤ 5, on the two DTNs under study.

The greedy heuristic is then shown to outperform a random
selection of nodes when k ≥ n
10 (i.e., at least 3 strong attackers
for n = 30) on the DieselNet DTN, and for any k ≥ 1 on the
Haggle DTN, for black hole attacks and the MaxProp routing
protocol. The heuristic is particularly advantageous for a very
large k; there, the diﬀerence between the delivery rate found
when k = n
2 is 30 − 40% lower on the two DTNs than with
random node selection.

3.3. Bio-inspired Heuristics

Evolutionary computation has been demonstrated a power-
ful means for tackling the inherent complexity of networking.
In [15], Baldi et al. proposed the use of a genetic algorithm
for minimizing the performance of a network, with the ﬁnal
goal to pinpoint potential bottlenecks of the topology. The ap-
proach exploits an accurate network simulator coupled with a
rudimentary evolutionary optimizer written in Perl. It could be
considered a proof of concept, as experimental results do not
show any real application.

A feasibility study of the approach described in the present
work, exploiting a far more conventional EA and tested only on
a reduced set of scenarios, was presented in [16]. In previous
research, we showed the eﬃcacy of an evolutionary algorithm
also in the context of wireless sensor networks (WSN), for
which we tested two kinds of collection tree protocols [17, 18].
We tackled diﬀerent network topologies composed of up to 50
nodes, making use of a real-code simulator, which enables to
analyze the complete software implementation of the protocols
under analysis. Furthermore, the gathered data enabled us to
pinpoint a set of topological factors which correlate with ex-
treme traﬃc under collection routing. In [19], we further en-
hanced such analysis through the use of a multi-objective evo-
lutionary algorithm, in the attempt to explore the WSN search
space from a multi-objective perspective rather than using lexi-
cographic order of ﬁtness functions.

Figure 1: Flowchart of an evolutionary algorithm

mix together the information contained in two or more solutions
to create new ones; the latter ones work by changing the struc-
ture of a single solution. Recombination operators are able to
coalesce good characteristics from diﬀerent solutions, and pro-
vide a very eﬀective mechanism to explore the search space;
mutation operators, on the other hand, allow the ﬁne-tuning of
the candidate solutions. Maintaining a set of solutions, EAs are
resilient to the attraction of local optima [14].

Over the years, EAs were proven capable to solve quite diﬃ-
cult problems with very complex ﬁtness landscapes, including
open problems related to networking and protocols. In partic-
ular, EAs are known to greatly outperform random sampling
for case studies where classical optimization techniques are not
viable [14]. Evolutionary optimizers have been successfully ex-
ploited both in stationary and dynamic situations, and they were
demonstrated able to identify either single optima or Pareto sets
in multi-objective problems, see Section 3 for a summary of rel-
evant prior work.

3. Related Work

3.1. Random Sampling

To the best of our knowledge, the only experimental work on
the assessment of DTN robustness was performed by Burgess et
al.[3], who evaluated the resilience of DTNs of 30 nodes when
running four protocols. Weak attacks (without free range, but
with attackers forced to use the routes previously used by the
honest nodes) were simulated by randomly reassigning some
of the honest nodes as attackers.

3.2. Greedy Heuristic

To generate strong attacks (again, without free range), the
same authors [3] used a greedy heuristic in response to the in-
tractability of the vertex vulnerability problem. First, instead of

4

4. Proposed Methodology

As stated in the introduction, the core idea of this work is
to expose vulnerabilities in a DTN by devising a set of eﬀective
attackers. As a single attacker is unlikely to be able to damage a
DTN network, we seek for teams of colluding malicious nodes.
Both the number of attackers and their type (black hole or ﬂood-
ing) should be optimized in order to create the maximum dam-
age. Attackers are optimized using an advanced evolutionary
algorithm that is based on an recent cooperative co-evolution
approach that is not only able to optimize the parameters of
each individual attacker, but also to optimize the composition
of the team of colluding attackers.

In more detail, we simulate a realistic DTN over an urban
environment deﬁned by a topological map and a set of POIs.
We assume two type of nodes: honest and malicious. As dis-
cussed earlier, for each honest node i the predetermined moving
path PH
is a sequence of random points of interest. For added
i
realism, a small number of these points, such as main tourist at-
tractions, may be given a higher probability of being selected as
next destination. On the contrary, for each malicious node i, the
path PM
is a sequence of points of interest chosen by the evo-
i
lutionary optimizer to cause maximum damage in the network.
Honest nodes execute the FC routing protocol, while malicious
nodes can act either as data ﬂooders or black holes.

In the proposed framework, we use the Opportunistic Net-
work Environment simulator (The ONE) [6]1 coupled with the
evolutionary toolkit µGP [20]2. The reasons for using µGP are
manifold: ﬁrst, the design of this framework is based on the no-
tion of an external evaluator, which simpliﬁes the integration
with an external network simulator; secondly, the algorithm
available in µGP features a built-in support for multiple ﬁtness
functions, that can be evaluated both in a lexicographical order
and in a multi-objective approach; then, the evolutionary en-
gine available in µGP makes use of self-adaptation techniques,
greatly limiting the number of parameters that require to be set.
Finally, µGP provides both a classical EA and a cooperative
co-evolution scheme called Group Evolution (see below).

The resulting evolutionary optimization process, depicted in
Figure 2, can then be summarized as follows: given a DTN of
N total nodes, and any parameters of the urban environment,
ﬁnd a group of attackers of size k < N, each one with its pe-
i (i = 1 . . . k) and its characteristics
culiar movement patterns PM
(movement model and attack type) which would lower the data
delivery rate (DDR) of the DTN the most, while maximizing
also its average latency.

The following section gives details about the evolutionary
core and the Group Evolution scheme, while the internal so-
lution representation and the ﬁtness function deﬁnitions are de-
scribed in Section 4.2 and 4.3, respectively.

4.1. Evolutionary core

A noticeable branch of EC is cooperative co-evolution
(CCE), that is, broadly speaking, the study of evolutionary al-

1The tool is available at http://www.netlab.tkk.fi/tutkimus/dtn/

theone/.

2The tool is available at http://ugp3.sourceforge.net.

Figure 2: Structure of the proposed framework. Candidate solutions and ﬁtness
values are internally represented as text ﬁles.

gorithms whose ﬁnal goal is achieved by a solution composed
of diﬀerent sub-solutions that cooperates to reach the common
goal. The idea of CCE dates back to the origin of EC, yet its
inherent problems are far from being solved: important contri-
butions are appearing regularly in the scientiﬁc literature (e.g.,
[21, 22, 23, 24, 25]). In the last decade, the CCE popularity fur-
ther boasted due to robotics applications where teams of robots
can be asked to perform collective tasks [26].

In CCE, sub-solutions may be heterogeneous or homoge-
neous, and combining them might be more or less trivial. Nev-
ertheless, almost all approaches strive to optimize the single
parts independently, while trying periodically to group them
into an eﬀective set, possibly exploiting heuristics or ad-hoc
tweaks. One of the main challenges in CCE is that optimizing a
single component may not be beneﬁcial to the global solution,
yet the algorithm has to harmonize the two possibly contrasting
selective pressures.

Group evolution (GE) is yet another take on CCE, natively
provided by µGP. In GE, the individual optimization phase and
the group optimization phase are blended into a single seam-
less process [27]. Individuals are merely the parts that can be
assembled to compose the groups, while groups are the actual
candidate solutions. GE stores a population of individuals and
a separate population of groups (see Figure 3), but new individ-
uals and new groups are created with no predeﬁned order: the
evolutionary core may choose the best sequence of operators
acting on individuals, and operators acting on groups. However
the user may still impose a minimum or maximum cardinality
for groups.

Another peculiarity of GE is that single individuals and sets
of individuals (i.e., groups) are evaluated by the very same ob-
jective function (e.g., the loss of performance in a DTN in the
context of this paper). This choice enables both a generaliza-
tion in the ﬁtness calculation and a tighter integration between
the two levels of evolution. The ﬁtness assigned to groups de-
pends on the cumulative eﬀect of the individuals belonging to
it, while the contribution of each single individual is also stored
and used during comparison.

More operatively, each group is a set of references to indi-
viduals in the individual population: so, the same individual
can belong simultaneously to multiple groups. At every gener-

5

Figure 3: A high-level scheme of the two-population approach used by GE.
Groups are sets of individuals taken from the individual population. The same
individual can appear multiple times in the same group or in diﬀerent groups:
for example, individuals 1 and 2 belong to both groups A and B.

ation, once new groups and individuals are created and evalu-
ated, groups are sorted by their ﬁtness function, and the worst
are removed, factually deleting references to certain individu-
als. After this process, orphans, i.e., individuals not belonging
to any group in the current group population, are also deleted.
Interestingly, GE can be used with no modiﬁcation to op-
timize single attackers: when the maximum size of a group
is set to 1, the evolutionary core automatically stops using
group manipulation operators, such as addElementToGroup
and removeElementFromGroup. For the purpose of this work,
we further modiﬁed the original GE available in µGP introduc-
ing a new mechanism for choosing which operators to use in
the current generation, and a strategy for caching the results of
past evaluations [28]. The ﬂowchart of the GE algorithm used
in this work is shown in Figure 4.

4.2. Internal solution representation

In the problem under study, we consider a model of strong
colluding attackers with full network knowledge and free range
of movement. In other words, we consider attacks carried out
by multiple collaborating nodes which are connected via alter-
native communication links. In this context, a candidate solu-
tion represents a group of one or more malicious nodes, each
one characterized by the following properties:

• the attack logic to adopt (e.g., black hole, ﬂooding); we
assume this choice remains unchanged during an attack;

• the movement model (e.g., pedestrian, vehicle), which con-
strains the node to a corresponding map layer and mobility
pattern;

• the route on any given map layer, deﬁned via a list of POIs
on that map layer; free-range strong attackers have full
control when deciding their POIs.

The resulting structure of a candidate solution is thus quite
complex, as each attacker can feature a variable number of
POIs, and each group can have a variable number of attack-
ers. An example of solutions produced by the evolutionary core
is shown in Figure 5.

Figure 4: Flowchart of an evolutionary algorithm using group evolution. Oper-
ations exclusive to GE are depicted in black. New groups and new individuals
are created in a single uniform step, while to evaluate new groups the evaluation
of new individuals is required.

In a classical EA, the individual would then be a (either ﬁxed-
or variable-size) composition of multiple attackers with diﬀer-
ent properties. When GE is applied instead, each individual
models exactly a single attacker, while the organization of such
malicious nodes is delegated to groups, with a ﬁnal result struc-
turally similar to the case where a single individual portrays
several nodes.
In any case, the genetic operators can act on
each node, modifying its movement model, its attack logic, and
adding/removing/replacing POIs in its path, in order to generate
new candidate solutions. In experiments with a variable num-
ber of malicious nodes, the same operations can be performed
on the blocks representing the nodes.

It is important to notice that the same POIs have diﬀerent
meanings depending on the node’s movement: even if a vehi-
cle and a pedestrian pass close to the same coordinates, they
may reach them using diﬀerent paths, causing distinct network
disruptions along the way. Also, since most of the POIs are
accessible by certain types of movement only (e.g., a point in
open water cannot be reached by a pedestrian, nor one on land

6

Mov=vehicle
Attack=black hole
94,39
55,84
...
42,44
1,26

Mov=pedestrian
Attack=flood
22,75
43,15
...
65,61
15,58

Mov=boat
...
...
...
...
...
...

Figure 5: Example of solution for the DTN attack problem, describing multiple
attackers. Each attacker is characterized by its movement model (e.g. boat,
pedestrian, vehicle), its attack logic (black hole or ﬂood), and a series of POIs
it will visit during the simulation, encoded as squares in a grid overlapped to
the city map.

by a boat), for each type we overlap a grid layer onto the city
map layer, and deﬁne the path of an attacker of that type as a set
of grid squares inside that grid. During the simulation, we then
map each grid square to the map point closest to the square; if
a square contains more than one map point, the malicious node
visits them all.

In particular, µGP exploits a user-deﬁned description of solu-
tions in an XML ﬁle. The external representation of candidate
solutions is written to text ﬁles as they are evaluated, while their
internal structure is stored to disk as XML ﬁles, that can be read
in case the evolutionary process is resumed.

4.3. Fitness functions

Movement model, attack logic and POIs to visit are set at the
level of each malicious node, but the objective is to maximize
the global eﬀectiveness of the attack: an optimal set of collud-
ing attackers should lower the performance objectives of the
network the most. The eﬀectiveness of an attack conﬁguration
is thus assessed as an evaluation of an urban network scenario
(see next Section) performed by the network simulator. The
outputs of such simulation (i.e., the ﬁtness values, using the ter-
minology of EC), are:

• ( f1) the data delivery rate (DDR), calculated as the per-
centage of messages originated only from honest nodes,
and which are delivered successfully;

• ( f2) similarly, the average latency of message deliveries (in

seconds).

The two values are considered in lexicographic order, as we
assign more importance to a reduction of the network’s DDR
rather than an increase of latency: optimization-wise, f1 is to
be minimized, while f2 is to be maximized.

5. Experiments

This section ﬁrst summarized the conﬁguration settings for
the experimental campaigns. Sections 5.1 and 5.2 quantify
the parameters used to deﬁne an urban setting and its network
nodes. Section 5.3 summarizes the experimental parameters of
the evolutionary core. Sections 5.4 and 5.5 give the numerical
results and discuss their practical impact.

We make public the city maps, the experimental conﬁgura-

tions, and detailed experimental results, at the URL:
https://github.com/doinab/DTN-security.

5.1. DTN and the cities: San Francisco and Venice

To validate our methodology, we simulate two realistic,
large-scale city environments, each composed of a map and a
large set of honest, randomly moving network nodes of cer-
tain types relevant to a given city. Figures 6 and 7 show the
basic maps of the two urban environments in our experimen-
tal scenarios, namely San Francisco and Venice. These cities
diﬀer in terms of map topology: while the area of San Fran-
cisco has a regular grid structure of routes, the area of Venice
has a complex, hierarchical, irregular structure of main and sec-
ondary waterways travelled by boats, with pedestrians conﬁned
to inner walkways (some along waterways) and bridges. The
Venice map has an additional feature for added realism: on both
map layers, a small number of the map POIs mark the touristic
center, and have a higher probability to be chosen as the next
destination by the honest nodes. Table 1 quantiﬁes the maps
and map layers in terms of size, number of distinct map points,
route segments, and number of nodes.

Figure 6: A 5 km2 area of downtown San Francisco, US, with a grid-based
map topology of streets and the occasional park. The map has two overlapping
layers, constraining the movement of vehicles and pedestrians: the vehicles are
conﬁned to the black streets, while the pedestrians may walk both the green and
the black routes.

5.2. Network simulation and network nodes

In both cities we conﬁgured N = 200 moving network nodes,
divided in two types: pedestrians (75%) and vehicles (25%).
For San Francisco, the vehicles consist of motorized cars; in
Venice, the waterways serve as routes for motorized or unmo-
torized boats. Pedestrians are modelled as carrying commu-
nication devices with relatively limited capabilities: a Blue-
tooth communication interface with a range of 15m and low
bandwidth. Vehicles are awarded more communication capa-
bilities: besides a Bluetooth interface (which allows commu-
nication events to take place between any pedestrian and any
vehicle), a vehicle also has a high-speed, longer-range network
interface allowing vehicle-to-vehicle communication.

7

Table 1: Network parameters: city maps

San Francisco:

Venice:

size:
map layers:
no. of route segments:
no. of map points:
network size:

2416 m × 2253 m
LP (pedestrian walkways), LS (streets)
1728 in LP, 1305 in LS
1210 in LP, 883 in LS
150 pedestrians (constrained to LP), 50 cars (constrained to LS )

size:
map layers:
no. of line segments:
no. of map points:
network size:

2210 m × 2340 m
LP (pedestrian walkways), LW (waterways)
7983 in LP, 1497 in LW
6910 in LP, 1354 in LW
150 pedestrians (constrained to LP), 50 boats (constrained to LW )

an (e.g., pedestrian) attacker then only diﬀers from that of an
honest pedestrian in that the attacker’s next destination point is
randomly chosen from the evolved set of POIs, rather than the
entire map layer.

Honest nodes periodically inject new messages to be routed
by the network; the rate of message injection among all honest
nodes is set at one message every 30 seconds, such that the
network routes 120 honest messages per hour. The honest node
to inject the next message in the network is chosen randomly.
The malicious nodes run one of the two attack logics described
in Section 2.4.

A black hole attacker does not inject any additional messages
in the network. On the other hand, when an attacker executes
a ﬂood, the parameters are chosen to obtain a “heavy” ﬂood of
messages: (1) a ﬂooding node injects messages in the network
at 10 times the frequency of message injection from an honest
node, and (2) the messages injected by a ﬂooder are 10 times as
large as regular messages. Table 3 summarizes these communi-
cation parameters, together with the settings regarding the sizes
of the nodes’ message buﬀers, and the Time To Leave (TTL),
which limits the amount of time that a message is allowed to
be stored in a node’s buﬀer without being forwarded — we set
TTL to be large, and equal to the length of an experiment: 5
hours (simulated time).

5.3. Evolutionary parameters

During all the experiments, µGP has been conﬁgured with
the parameters reported in Table 4. The operators chosen for
the evolution are:

• onePointImpreciseCrossover:

one-point crossover

between two individuals;

• twoPointImpreciseCrossover: crossover with with

two cut points;

• singleParameterAlterationMutation: mutate a sin-
gle coordinate of a POI, the movement model or the attack
logic;

• insertionMutation: add a new random POI;

• removalMutation: remove a randomly selected POI;

• replacementMutation: replace a POI with a randomly

generated one.

8

Figure 7: A 5 km2 area of downtown Venice, IT, with an irregular map topology
of pedestrian pathways (the black map layer) and waterways (the blue layer).
Marked with stars are special POIs in the city’s touristic center.

Each simulation of a DTN in The ONE is stochastic. The
nodes are initially placed randomly on their map layer, and a
1,000-second warm-up simulation period is allowed before the
experiment starts, for the nodes to settle on the “natural” pre-
ferred routes in the city. The next destination POI is also chosen
randomly. Due to this, to smoothen the ﬁtness landscape and
reduce the eﬀect of the random seed of each simulation on the
evaluation of solution, we execute each network simulation 10
times, initialized with diﬀerent random seeds, and report as ﬁt-
ness values the average DDR and latency over the 10 available
repetitions.

The movement model of all nodes follows the general ran-
domized pattern summarized in Section 2.3. A subset of these
200 nodes is assigned a malicious behaviour. For an honest
node, the set of POIs is simply the entire set of map points lo-
cated on the node’s relevant map layer. The node randomly
chooses any destination point from that map layer, travels there
at a certain speed on the shortest path, pauses for an interval,
and repeats the process. The conﬁguration for the nodes’ speed
and pause interval is given by Table 2. For an attacker, the set
of POIs is is a subset of the map points of the relevant map
layer, and is evolved by the evolutionary core as part of each
solution (as described in Section 4.2). The movement model of

Table 2: Network parameters: movement models

Movement model
for nodes in all cities

next point:
path choice:
pedestrian speed:
boat speed:
car speed:
pause interval for all:

chosen randomly from a map layer
shortest path on the map layer to the next point
[0.5 . . . 1.5] m/s
[1.0 . . . 5.0] m/s
[2.7 . . . 13.9] m/s
[0 . . . 120] s at each destination point

Table 3: Network parameters: simulation and node communication settings

Simulation
settings

simulation time:
DTN simulator:

5 h
The ONE [6]

Message
settings

message issued:
message size:
message buﬀer:
message TTL:

every 30 s (by an honest node), every 3 s (by a ﬂooder)
10 kB (issued by an honest node), 100 kB (issued by a ﬂooder)
5 MB (for pedestrian nodes), 50 MB (for car and boat nodes)
5 h

Node
communication
interfaces

Bluetooth:
High-speed:
pedestrians use:
cars and boats use:

range 15 m, speed 250 kBps
range 100 m, speed 10 MBps
Bluetooth
Bluetooth and High-speed

Figure 8: Comparative results: data delivery rate (DDR) from three experimental campaigns using group evolution, a classical EA, and random testing. The DDR
obtained with a random test is shown as the mean and standard deviation among the mean DDR of 150 randomly generated groups, each group simulated 10 times
with diﬀerent random seeds. The DDR obtained with any evolutionary experiment is a single group of top ﬁtness, and is shown as the mean and 95% conﬁdence
interval among 5 simulation repetitions of that group with diﬀerent random seeds.

The activation probabilities of all the operators in the popula-
tion are self-adapted during the run; [28] enables to eﬃciently
alternate phases where individuals are optimized, with phases
where groups are optimized. Self adapting the size of the tour-
nament for selecting parents (τ) enables to optimize the selec-
tive pressure; while self adapting the strength of the mutation
operators (σ) enables to balance between exploration and ex-
ploitation. Every time a mutation is performed, it is executed
again on the same individual if a randomly generated number
in (0, 1) is lower than the current value of σ. For high values
of σ, the algorithm will tend to generate new solutions that are
very diﬀerent from their parents, thus favoring exploration; for
low values of σ, the diﬀerences between parents and oﬀspring

will be smaller, thus entering a phase of exploitation.

During the GE experiments, new operators are added in order

to manipulate groups, namely:

• groupRandomInsertionMutation: add a random indi-

vidual to a group;

vidual from a group;

• groupRandomRemovalMutation: remove a random indi-

• groupBalancedCrossover: crossover that moves the

same number of individuals between two groups;

• groupUnbalancedCrossover: same as above, with no
guarantee of moving the same number of individuals;

9

Table 4: µGP experimental settings

• A GE-based experimental campaign (for the settings

where k > 1);

Parameter Description

τ
σ
α
§

µ
λ

size of the tournament selection
initial strength of the mutation operators
inertia of the self-adapting mechanisms
stagnation threshold (in generations)

Classical EA

individual population size
operators (genetic) applied at every step

Group Evolution

µgroup
νindividual
λ

group population size
initial individual population size
operators (genetic or groups) applied at every step

Value

1.0÷4.0
0.9
0.9
50

30
20

30
50
20

• groupUnionIntersection: returns the union and the in-

tersection of two groups;

• groupDreamTeam: creates a group with some of the best

individuals currently in the population.

As previously detailed, the number of individuals in the GE
paradigm is regulated by the number of groups in the current
population, µgroup. Individuals are removed only when they are
no longer included in any group. The number of individuals
generated at the beginning of the execution, number that can be
later exceeded or reduced, is controlled by parameter νindividual.
Further information on parameters and operators in µGP can be
found in [20].

5.4. Experimental campaigns and results

Given the settings described in Sections 5.1–5.3, which are
common to all experiments, an experiment will be uniquely
identiﬁed by the following two parameters:

City (i.e., San Francisco or Venice)

Number of attackers i.e., the size of the attack group k, in the
range 1 ≤ k ≤ N. We delineate ﬁve practically interesting
ranges:

• k = 1, i.e., a single attacker;
• k = 2, i.e., a pair of attackers;
• k ∈ [1 . . . 5];
• k ∈ [6 . . . 10];
• k ∈ [11 . . . 20], i.e., a group which can reach 10% of

the overall network size of N = 200 nodes.

The ranges for k thus come in two categories: a ﬁxed group
size (when k = 1 or k = 2), or a variable group size (for larger
k). In the latter case, intuitively, the expectation is that the evo-
lutionary algorithm will maximize the group size in the process
of optimizing the ﬁtness functions.

To assess the comparative performance of our method based
on Group Evolution, we ran the following three experimental
campaigns, for each experimental setting (City × Number of
attackers):

• An experimental campaign based on the classical, non-GE
EA applied to the same problem in prior literature [16];

• The testing of groups of a sample of 150 purely randomly

generated groups of attackers.

For each experimental setting, the GE and non-GE experimen-
tal campaigns consist of 5 experiment repetitions, initialized
with diﬀerent random seeds.

The results of the experimental campaigns are summarized
in Figure 8, separately per city. The ﬁrst ﬁtness function, f1,
measuring the global data delivery rate (DDR) in the network,
quantiﬁes the decreasing network performance with an increas-
ing size of the attack group, k. In the ﬁgures, the data points
are presented for the set k ∈ {1, 2, 5, 10, 20}, as the evolution-
ary algorithms found that the lowest ﬁtness is achieved when
the size of the attacker group is maximum. For comparison, the
ﬁgures also include a data point showing the ﬁtness function
with no attack present (i.e., all N = 200 nodes in the network
are honest).

As seen in Figure 8, while the First Contact protocol has only
moderate data delivery in these complex urban settings even
in the absence of attacks, both evolutionary algorithms signif-
icantly outperform random testing, and GE was found to be
advantageous in all the experimental settings. Moreover, a sim-
ilar trend for the performance of the First Contact protocol was
obtained between the two cities: a single attacker was found
suﬃcient to lower the data delivery to half that of the no-attack
setting, and, with a group of 20 attackers, the data delivery in
the network was found to drop close to zero.

To further conﬁrm this trend, we performed a thorough anal-
ysis [29] of the numerical results. The analysis was conducted
as follows: for each city map and attack group size k > 1 (when
k = 1 a group cannot be deﬁned), ﬁrst we aggregated the 150
lowest DDR values obtained by GE and non-GE experiments,
over the 5 available repetitions for each of the two algorithms.
We then performed pairwise comparisons between the two al-
gorithms, and w.r.t.
the DDR of the 150 randomly sampled
attack groups used as baseline. For each pairwise comparison,
we initially verify the normality of the two distributions with
the Shapiro-Wilk test; if both samples are normally distributed,
we then test the homogeneity of their variances (homoscedas-
ticity) with an F-test. If variances are equal, we compare the
two distributions by means of the Student t-test, otherwise we
adopt Welch’s t-test variant. More speciﬁcally, we ﬁrst test the
null-hypothesis of equal distributions (i.e. the two algorithms
under comparison are statistically equivalent from an optimiza-
tion point of view); then, we test the null-hypothesis that the
ﬁtness values obtained with one of the two algorithms, taken
as reference, are statistically smaller than those obtained by the
other algorithm.
In case of non-normal distributions, we in-
stead test the null-hypotheses by means of the non-parametric
Wilcoxon Rank-Sum test. In all the tests, we consider a conﬁ-
dence level of 0.95 (α = 0.05).

10

The statistical analysis is summarized in Table 5. The anal-
ysis conﬁrms that GE and non-GE EA statistically outperform
random sampling, and GE outperforms non-GE in all cases.

Table 5: Summary of the statistical analysis (see the main text for details). Each
column (labeled as X/Y) shows the pairwise comparison between the results
obtained by algorithm X and Y, with X taken as reference. The symbol ’+’
indicates that X statistically outperforms Y, i.e. it obtains attacker groups with
lower network performance (DDR).

San Francisco

GE/Random non-GE/Random

No. attackers
2
1-5
6-10
11-20

No. attackers
2
1-5
6-10
11-20

GE/non-GE
+
+
+
+

GE/non-GE
+
+
+
+

+
+
+
+

+
+
+
+

+
+
+
+

+
+
+
+

Venice

GE/Random non-GE/Random

5.5. Runtimes and discussion of results

In Figure 9 we show the computational cost of running the
evolutionary campaigns, each data point the average of 5 rep-
etitions of an experiment with diﬀerent seeds. The runtime is
shown in core-hours, over computing cores of at least 1.6 GHz
(since we ran the experiments on a number of machines, there
was variation among the computational power allowed among
experiments).

More interestingly, the reason why the GE algorithm shows
an advantage over a classical EA is seen in Figure 10. The ﬁg-
ure ﬁrst selects all the “top” attacker groups obtained by the GE
and non-GE experiments, i.e., those groups which lower net-
work performance to within 2% of the absolute best ﬁtness f1
found by that algorithm. We observed that the number of these
top groups falls between 300 and 6, 000 (depending on the ex-
perimental setting), all of which can be considered successful
attacks. The average composition of this large group sample is
analyzed in terms of how often a type of attacker, i.e., a move-
ment model (that of a pedestrian, or that of a vehicle) and attack
logic (black hole or ﬂooding) appears in a top group.

The best single attacker found by both the GE and non-GE
algorithms is a black hole vehicle:
indeed, 100% of the top
groups found by both algorithms consist of an attacker of this
type. The same is true for pairs of attackers.

For larger group sizes, the two algorithms show a diﬀerence
of results. When k ∈ [11 . . . 20], the non-GE algorithm found an
overall lower top ﬁtness while obtaining top groups for which:
(1) the average group size does not saturate (it reaches an aver-
age of 18.23 out of 20, for the San Francisco setting), and (2)
the average group composition is a mix of attacker types, with
only 50% of the attackers in the top groups matching the type
of the best single attacker (a black hole vehicle).

On the other hand, the GE algorithm likely outperformed the
non-GE in terms of best ﬁtness found due to the fact that it both
maximized the average top group size, and optimized the aver-
age top attacker type, demonstrating that homogeneous groups

Figure 9: Computational overhead of non-GE and GE experiments: the number
of evolutionary generations, the number of solution evaluations, and the wall-
clock runtime per experimental campaign, shown as the average among the 5
experiments conﬁgured with diﬀerent random seeds, per experimental setting.

of black holes are advantageous to exploit the vulnerabilities in
the design of the First Contact protocol, and that faster black
hole attackers also have a clear advantage.

6. Conclusions

In this paper we proposed a heuristic methodology to as-
sess the robustness of First Contact, one of the main routing
protocols used in Delay-Tolerant Networks. To exploit possi-
ble weaknesses of the network, we considered the worst-case
scenario of an attack carried out by a coordinated group of
agents with full network knowledge. The methodology is based
on an evolutionary algorithm using a cooperative co-evolution
scheme called Group Evolution recently introduced in the liter-
ature and here extended for our purposes. The method is able
to optimize groups (either homogeneous or not) of malicious
nodes whose behaviour does not comply with the legitimate
routing protocol used by honest nodes in the network.

We performed an extensive experimental campaign over
medium-sized (i.e., 200 nodes) realistic urban networks run-
ning on two diﬀerent cities with radically diﬀerent map topolo-
gies (San Francisco and Venice). We assessed the scalability of
the approach by evaluating single attackers as well as groups of

11

Figure 10: The average group size and group composition among all top solutions (whose ﬁtness is within 2% of the best ﬁtness). The group composition is shown
in terms of the percentage of ﬂooding vehicles (FV), ﬂooding pedestrians (FP), black hole vehicles (BV), and black hole pedestrians (BP) among these top solutions.

up to 10% malicious nodes. Moreover, we compared results ob-
tained with random sampling and a more classical evolutionary
algorithm.

In all our experiments, the two evolutionary methods clearly
outperformed random sampling, consistently ﬁnding groups of
attackers that produced a larger network damage (reduced data
delivery rate and increased latency). The additional advantage
brought by Group Evolution resulted in an improved attack ef-
fect, optimized group compositions, and more eﬀective move-
ment models.

Overall, the contribution of this work is twofold: on one
hand, we proposed an eﬃcient alternative to random sampling,
that is currently one of the most used approaches for assessing
network robustness; on the other hand, we showed an example
problem that can be naturally described in terms of coopera-
tive co-evolution and for which such an evolutionary scheme is
clearly beneﬁcial.

This work represents then one of the few attempts at ﬁnd-
ing applications of cooperative co-evolution beyond the typical
domain of swarm robotics. In future research, we will seek to
extend this approach to diﬀerent networking applications and,
possibly, new unexplored domains.

[3] J. Burgess, G. D. Bissias, M. D. Corner, B. N. Levine, Surviving attacks
on disruption-tolerant networks without authentication, in: Proceedings
of the 8th ACM International Symposium on Mobile Ad Hoc Networking
and Computing, MobiHoc ’07, ACM, New York, NY, USA, 2007, pp.
61–70.

[4] S. Jain, K. Fall, R. Patra, Routing in a delay tolerant network, in: Pro-
ceedings of the 2004 Conference on Applications, Technologies, Archi-
tectures, and Protocols for Computer Communications, SIGCOMM ’04,
ACM, New York, NY, USA, 2004, pp. 145–158.

[5] P. Sommer, B. Kusy, P. Valencia, R. Dungavell, R. Jurdak, Delay-
arXiv preprint

tracking,

tolerant networking for long-term animal
arXiv:1506.01792 (2015).

[6] A. Ker¨anen, J. Ott, T. K¨arkk¨ainen, The ONE Simulator for DTN Protocol
Evaluation,
in: SIMUTools ’09: Proceedings of the 2nd International
Conference on Simulation Tools and Techniques, ICST, New York, NY,
USA, 2009.

[7] C. Darwin, On the Origin of the Species by Means of Natural Selection:
Or, The Preservation of Favoured Races in the Struggle for Life, John
Murray, 1859.

[8] A. M. Turing, Computing machinery and intelligence, Mind (1950) 433–

[9] D. B. Fogel, Evolutionary computation:

the fossil record, Wiley-IEEE

[10] J. H. Holland, Adaptation in Natural and Artiﬁcial Systems, University of

[11] L. J. Fogel, Autonomous automata, Industrial Research 4 (1962) 14–19.
[12] H.-G. Beyer, H.-P. Schwefel, Evolution Strategies – A comprehensive

introduction, Natural computing 1 (2002) 3–52.

[13] J. R. Koza, Genetic Programming: vol. 1, On the programming of com-
puters by means of natural selection, volume 1, MIT press, 1992.
[14] A. E. Eiben, J. E. Smith, Introduction to evolutionary computing, vol-

[15] M. Baldi, F. Corno, M. Rebaudengo, G. Squillero, GA-based perfor-
mance analysis of network protocols, in: Proc. Ninth IEEE International
Conference on Tools with Artiﬁcial Intelligence, 1997, pp. 118–124.

460.

Press, 1998.

Michigan Press, 1975.

References

[1] K. Fall, S. Farrell, DTN: an architectural retrospective, Selected Areas in

ume 2, Springer Berlin, 2010.

Communications, IEEE Journal on 26 (2008) 828–836.

[2] J. Burgess, B. Gallagher, D. Jensen, B. Levine, MaxProp: Routing for
Vehicle-Based Disruption-Tolerant Networks, in: INFOCOM 2006. 25th
IEEE International Conference on Computer Communications, pp. 1–11.

12

[16] D. Bucur, G. Iacca, G. Squillero, A. Tonda, Black holes and revelations:
Using evolutionary algorithms to uncover vulnerabilities in disruption-
tolerant networks, in: A. M. Mora, G. Squillero (Eds.), Applications of
Evolutionary Computation, volume 9028 of Lecture Notes in Computer
Science, Springer International Publishing, 2015, pp. 29–41.

[17] D. Bucur, G. Iacca, G. Squillero, A. Tonda, The impact of topology on
energy consumption for collection tree protocols: An experimental as-
sessment through evolutionary computation, Applied Soft Computing 16
(2014) 210–222.

[18] D. Bucur, G. Iacca, P.-T. de Boer, Characterizing topological bottlenecks
for data delivery in CTP using simulation-based stress testing with natural
selection, Ad Hoc Networks 30 (2015) 22 – 45.

[19] D. Bucur, G. Iacca, G. Squillero, A. Tonda, The tradeoﬀs between data
delivery ratio and energy costs in wireless sensor networks: A multi-
objective evolutionary framework for protocol analysis, in: Proceedings
of the Sixtienth Annual Conference on Genetic and Evolutionary Com-
putation Conference, GECCO ’14, ACM, New York, NY, USA, 2014.

[20] E. Sanchez, M. Schillaci, G. Squillero, Evolutionary Optimization: the

µGP toolkit, Springer Publishing Company, 1st edition, 2011.

[21] M. Potter, K. De Jong, A cooperative coevolutionary approach to function
optimization, in: Y. Davidor, H.-P. Schwefel, R. Manner (Eds.), Parallel
Problem Solving from Nature PPSN III, volume 866 of Lecture Notes
in Computer Science, Springer Berlin / Heidelberg, 1994, pp. 249–257.
10.1007/3-540-58484-6 269.

[22] E. Dunn, G. Olague, E. Lutton, Parisian camera placement for vision
metrology, Pattern Recognition Letters 27 (2006) 1209 – 1219. Evolu-

tionary Computer Vision and Image Understanding.

[23] R. Thomason, R. Heckendorn, T. Soule, Training time and team compo-
sition robustness in evolved multi-agent systems, in: M. O’Neill, L. Van-
neschi, S. Gustafson, A. Esparcia Alcazar, I. De Falco, A. Della Cioppa,
E. Tarantino (Eds.), Genetic Programming, volume 4971 of Lecture Notes
in Computer Science, Springer Berlin / Heidelberg, 2008, pp. 1–12.
10.1007/978-3-540-78671-9 1.

[24] M. Waibel, L. Keller, D. Floreano, Genetic Team Composition and Level
of Selection in the Evolution of Cooperation, IEEE Transactions on Evo-
lutionary Computation 13 (2009) 648–660.

[25] A. Tonda, E. Lutton, G. Squillero, Lamps: A test problem for cooperative
coevolution, in: Nature Inspired Cooperative Strategies for Optimization
(NICSO 2011), Springer, 2011, pp. 101–120.

[26] L. Panait, S. Luke, Cooperative multi-agent learning: The state of the art,
Autonomous Agents and Multi-Agent Systems 11 (2005) 387–434.
[27] E. Sanchez, G. Squillero, A. Tond, Group evolution: Emerging synergy
through a coordinated eﬀort, in: Evolutionary Computation (CEC), 2011
IEEE Congress on, IEEE, pp. 2662–2668.

[28] G. S. Jany Belluz, Marco Gaudesi, A. Tonda, Searching for the mini-
mum failures that can cause a hazard in a wireless sensor network,
in:
Proceedings of the Fifteenth Annual Conference on Genetic and Evolu-
tionary Computation Conference (to appear), GECCO ’15, ACM, New
York, NY, USA, 2015.

[29] E. L. Lehmann, J. P. Romano, Testing statistical hypotheses, Springer

Texts in Statistics, Springer, New York, third edition, 2005.

13

Optimizing groups of colluding strong attackers in mobile urban communication networks
with evolutionary algorithms(cid:73)

Doina Bucura, Giovanni Iaccab, Marco Gaudesic, Giovanni Squilleroc, Alberto Tondad

aJohann Bernoulli Institute, University of Groningen, Nijenborgh 9, 9747 AG Groningen, The Netherlands
bINCAS3, Dr. Nassaulaan 9, 9401 HJ, Assen, The Netherlands
cPolitecnico di Torino, Corso Duca degli Abruzzi 24, 10129, Torino, Italy
dINRA UMR 782 GMPA, 1 Avenue Lucien Br´etigni`eres, 78850, Thiverval-Grignon, France

8
1
0
2
 
t
c
O
 
5
 
 
]
E
N
.
s
c
[
 
 
1
v
3
1
7
2
0
.
0
1
8
1
:
v
i
X
r
a

Abstract

In novel forms of the Social Internet of Things, any mobile user within communication range may help routing messages for another
user in the network. The resulting message delivery rate depends both on the users’ mobility patterns and the message load in the
network. This new type of conﬁguration, however, poses new challenges to security, amongst them, assessing the eﬀect that a
group of colluding malicious participants can have on the global message delivery rate in such a network is far from trivial. In this
work, after modeling such a question as an optimization problem, we are able to ﬁnd quite interesting results by coupling a network
simulator with an evolutionary algorithm. The chosen algorithm is speciﬁcally designed to solve problems whose solutions can be
decomposed into parts sharing the same structure. We demonstrate the eﬀectiveness of the proposed approach on two medium-sized
Delay-Tolerant Networks, realistically simulated in the urban contexts of two cities with very diﬀerent route topology: Venice and
San Francisco. In all experiments, our methodology produces attack patterns that greatly lower network performance with respect
to previous studies on the subject, as the evolutionary core is able to exploit the speciﬁc weaknesses of each target conﬁguration.

Keywords: Cooperative Co-Evolution, Delay-Tolerant Network, Evolutionary Algorithms, Network Security, Routing

1. Introduction

The so-called Social Internet of Things calls for nearly ubiq-
uitous communicating devices. There is today a need to inte-
grate low-cost, low-power devices to support networking ser-
vices in more eﬀective and eﬃcient ways. In such a scenario,
new solutions are continuously developed and deployed, while
approaches that just a few decades ago were used only in highly
complex, niche applications are now literally brought down to
earth — Delay-Tolerant Networks (DTNs) are a technology
originally developed for space communications that, over the
years, made its way down to quite mundane applications [1].

Emerging technologies and applications are posing serious
problems to designers. In most cases there is not enough time to
thoroughly validate them, or even to simply analyze their pos-
sible failures and problems. Engineers are forced to resort to
their experience to choose heuristics that look reasonable, and
then observe the actual outcome from real applications. Secu-

(cid:73)This paper is an extended, improved version of the paper Black Holes
and Revelations: Using Evolutionary Algorithms to Uncover Vulnerabilities
in Disruption-Tolerant Networks presented at EvoComNet2015 and published
in: Applications of Evolutionary Computing, Proceedings of 18th European
Conference, EvoApplications 2015, Copenhagen, Denmark, April 8-10, 2015,
LNCS 9028, pp. 29-41, Springer, 2015.

Email addresses: d.bucur@rug.nl (Doina Bucur),

giovanniiacca@incas3.eu (Giovanni Iacca),
marco.gaudesi@polito.it (Marco Gaudesi),
giovanni.squillero@polito.it (Giovanni Squillero),
alberto.tonda@grignon.inra.fr (Alberto Tonda)

Preprint submitted to Applied Soft Computing Journal

rity in DTNs is a paradigmatic case: such networks need to re-
main open to all willing participants, and few malicious partic-
ipants may try to disrupt communications, for instance, routing
no messages to other nodes or injecting large number of mes-
sages into the network. While such a risk is plausible, precisely
assessing DTNs’ vulnerabilities is hard.

This paper focuses precisely on evaluating the amount of
damage that can be caused to a DTN by a group of synchro-
nized attackers with deep knowledge about the network. Given
a scenario, we propose to optimize attackers for minimizing the
performances of the network using a heuristic methodology. It
is important to note that the adoption of such methodology is
more a necessity than a choice: determining the most eﬀective
attack for a given network was proven to be NP-hard [2], the
complexity and number of variables involved in the problem
preclude the use of formal techniques and the size of the sce-
narios prevent exhaustive analyses.

The idea of using heuristic methods to disprove a property of
a system when formally proving it is not possible, is not a nov-
elty in itself. The simplest approach, namely random sampling
of the parameter space, is often used under the assumption that
the eﬀort employed failing to ﬁnd a counter example may be
sensibly linked to the degree of conﬁdence that a counter ex-
ample does not actually exist.

Repeated random sampling has also be used as a means to es-
timate numerical quantities when complexity and dimensional-
ity of a problem impedes the application of analytic analyses. In
the speciﬁc case of DTNs performance, it has been considered

October 8, 2018

in [3], although limited only to small networks and attackers
with no information about the environment. However, random
sampling is unlikely to provide any interesting result when the
goal is to detect a very speciﬁc corner-case scenario, such as
the damage caused by specialized attackers that are fully aware
of the network characteristics. Finally, when the search space
is too vast, even the eﬀort required to get a signiﬁcant sampling
could be excessive.

In this work, we move forward from random sampling by us-
ing an evolutionary algorithm (EA) to optimize the attackers’
parameters in order to inﬂict the maximum possible damage to
the network. We overcome the limitations of random sampling
by using the capability of the EA to drive random search to-
wards speciﬁc regions of large search spaces. Furthermore, we
extend the features of a classical evolutionary algorithm to en-
able it to ﬁnd a team of colluding attackers. As the members
of such a team cooperate in order to maximize the cumulative
damage, even at the expense of the damage caused by each sin-
gle attacker, the approach is a form of cooperative co-evolution,
an open area of research for which very few successful strate-
gies have been found so far.

We tested the proposed methodology on medium-sized net-
works describing urban scenarios with diﬀerent topologies,
where a number of agents, i.e., the network nodes, move re-
alistically. The results clearly demonstrate the eﬃcacy of the
approach: we found scenarios where even few (up to 10% of
the total network size), highly optimized attackers can reduce
the global data delivery in the network by over 90%, when
compared to the network with no attackers. We also observed
that the composition of the attacker team obtained by evolution
changed when cooperative co-evolution is used, demonstrating
that such scheme leads to synergistic solutions not found by
classical evolutionary algorithm.

The rest of the paper is organized as follows: the next section
summarizes the research background; Section 4 details the pro-
posed methodology; Section 5 reports the experimental eval-
uation; Section 3 surveys the related work; ﬁnally, Section 6
concludes the paper.

2. Background

This section ﬁrst gives an overview of the application do-
main of Delay-Tolerant Networks. Sections 2.1-2.2 describe the
paradigm of routing in DTNs, and First Contact, the DTN pro-
tocol under study. Section 2.3 summarizes the mobility model
that an urban DTN node follows, from the literature. Sec-
tion 2.4 describes the two main types of security attacks rele-
vant: black hole and ﬂooding attacks. Finally, Section 2.5 gives
an overview of the EA ﬁeld.

a mixed terrestrial-and-space network where some of the nodes
are Low-Earth Orbiting Satellites, and the rest are ground users;
this was the application for which DTN-speciﬁc routing proto-
cols were originally designed [4]. More recently, DTNs have
also been proposed in scenarios with nearly unpredictable con-
nectivity. This is the case of animal-tracking applications [5]
and opportunistic urban networks. An example of the latter is
the 30-bus experimental DieselNet [2], in which urban vehicles
constrained to city roads act as mobile message routers. It is
urban scenarios with unpredictable connectivity that we study
in this paper.

Given an application scenario, the main performance factors
for a DTN message-routing protocol quantify the protocol’s
ability to route messages in that scenario, and the timeliness
of the routing:

Delivery rate The percentage of messages injected in the net-
work by nodes which were successfully delivered to their
destination nodes.

Message delay The average time interval between a message

injection in the network until its delivery.

2.2. DTN routing: the First Contact protocol

A DTN routing protocol essentially implements a logic to
achieve message routing in the mobile network, end-to-end
from the source of a message to its destination, over a con-
nectivity graph which varies in time and is by nature discon-
nected. Given these scenarios, the protocol logic cannot be
based on standard distributed algorithms for computing short-
est paths end-to-end in a graph: the routing can not converge on
correct routes when the network graph is highly dynamic. In-
stead, DTN message communication on a path between source
and destination include long-term storage of the message in the
nodes’ (ﬁnite) node buﬀers, until an opportunity for further de-
livery of the message arises. This ability to safely delay the
forwarding of a message is typical of DTN routing protocols.

DTN protocol design follows a simple taxonomy based on

the following features:

Network knowledge A protocol aiming to compute optimal
paths at a node would be helped if the node is able to pre-
dict the future network conditions: the pattern of contact
with other nodes, the set of nodes with congested buﬀers,
and the pattern of traﬃc demands. While network knowl-
edge may be acquired in practice by an attacker via mon-
itoring the network, many protocols cannot assume any
(i.e., are zero-knowledge).

2.1. Delay-Tolerant Networks: performance objectives

Delay-Tolerant Networking was designed to cater for mes-
sage routing in practical applications with heavy node mobility.
In such applications, the connectivity pattern between nodes
in the network can be either predictable or unpredictable with
time. An example DTN with predictable connectivity is that of

Message replication Forwarding protocols simply route the
original message through the network. Replicative proto-
cols introduce into the network a number of copies of each
original message, each of which is then forwarded inde-
pendently with the aim that at least one copy reaches the
destination.

2

We study here one of the simplest and most common DTN
routing protocols, namely First Contact (FC) [4]. FC is zero-
knowledge and forwarding; it routes messages opportunisti-
cally using any available contacts with other nodes. A single
copy of each message in the network exists at a time, and it
is forwarded to the ﬁrst available contact (if more contacts are
available, one is chosen randomly among all the current con-
tacts). On simple network topologies, FC was shown to have
performance comparable to partial-knowledge protocols; this
degrades in complex topologies to varying degrees, depending
on the network load.

2.3. Node movement models in DTNs

Models describing realistically [6] the free, stochastic move-
ment in urban environments of nodes of diﬀerent kind (pedes-
trian, cars, buses, etc.) can be used to study an urban DTN
computationally. In a DTN simulation, each movement model
is associated to a diﬀerent map layer. A map layer describes the
areas of the map reachable by the associated kind of nodes. The
building blocks of these node movement patterns are a node’s
points of interest (POIs) located on a map layer.

Nodes in our DTNs follow a classic movement model: ran-
dom waypoint with shortest paths.
In this model, node ran-
domly chooses a destination point from a set of points of inter-
est; travels there at a realistic speed on the shortest path; takes
a break. Then, it repeats the process. This can be considered
realistic: in [3], which evaluated the theoretical resilience of the
real-world DieselNet and Haggle DTN prototypes, the network
logs showed that Haggle nodes mimicked the random-waypoint
model fairly closely.

2.4. Types of security attacks

Like a DTN routing protocol, an attacker also may or may
not have knowledge of the future connectivity patterns in the
network. A strong attacker has full network knowledge, i.e.,
will know:

• The structure of the city map;

• The pattern of network encounters: for example, a statisti-
cal estimation of how many honest nodes will be in prox-
imity at any given map location;

• The statistical pattern of new messages that honest nodes
will forward when encountered, and the statistical pattern
of buﬀer availability at honest nodes.

Furthermore, a group of colluding attackers has the means
necessary to synchronize their individual attacks, rather than
executing an independent logic. Any of the colluding nodes
may adopt one of the following attack logics:

Black hole attacks The attacker drops a percentage of the
packets received: this percentage is 100% in black hole
attacks.

Flooding attacks The attacker executes the same routing pro-
tocol as honest nodes, but attempts a denial-of-service pro-
cedure by injecting a (large) number of (large) messages
into the network.

2.5. Evolutionary Computation

Evolution is the biological theory that animals and plants
have their origin in other types, and that the distinguishable
diﬀerences are due to modiﬁcations in successive generations.
Natural evolution is based on random variations, but it is not a
random process: variations are rejected or preserved according
to objective evaluations, and only changes that are beneﬁcial to
the individuals are likely to spread into subsequent generations.
Darwin called this principle “natural selection” [7]: a determin-
istic process where random variations “aﬀord materials”.

When natural selection causes variations to be accumulated
in one speciﬁc direction the result may strikingly resemble a
deliberate optimization process. However, such optimization
processes only required to assess the eﬀect of random changes
and not the ability to design intelligent modiﬁcations. Several
scholars were inspired by such an outcome and tried to repro-
duce the process for solving practical optimization problems in
various application domains, while others tried to mimic it to
better understand its underlying mechanisms.

Evolutionary Computation (EC) is the oﬀshoot of computer
science focusing on algorithms loosely inspired by the theory of
evolution. The deﬁnition is deliberately vague since the bound-
aries of the ﬁeld are not, and cannot be, sharply deﬁned. EC is
a branch of computational intelligence, and it is also included
into the broad framework of bio-inspired meta-heuristics. EC
does not have a single recognizable origin. Some scholars iden-
tify its starting point in 1950, when Alan Turing drew attention
to the similarities between learning and evolution [8]. Others
pointed out the inspiring ideas that appeared later in the decade,
despite the fact that the lack of computational power impaired
their diﬀusion in the broader scientiﬁc community [9]. More
commonly, the birth of EC is set in the 1960s with the appear-
ance of three independent research lines: John Holland’s ge-
netic algorithms [10]; Lawrence Fogel’s evolutionary program-
ming [11]; Ingo Rechenberg’s and Hans-Paul Schwefel’s evolu-
tion strategies [12]. The three paradigms monopolized the ﬁeld
until the 1990s, when John Koza entered the arena with genetic
programming [13]. Nowadays, all these methods, together with
several variants proposed over the years, have been grouped un-
der the umbrella term of evolutionary algorithms (EAs).

When EAs are used to solve a speciﬁc problem, i.e. optimize
solutions for it, an individual is a single candidate solution, and
its ﬁtness is a measure of its capacity of solving the problem;
the set of all candidate solutions that exists at a particular time
represents the population. Evolution proceeds through discrete
steps called generations.
In each of them, the population is
ﬁrst expanded and then collapsed, mimicking the processes of
breeding and struggling for survival (Figure 1).

Usually, parents are chosen for breeding stochastically, with
the best candidate solutions having higher probabilities to gen-
erate oﬀspring. As a result, new candidate solutions are more
likely to inherit favorable traits. Conversely, the removal of in-
dividuals is usually deterministic: the less ﬁt, and possibly the
oldest ones, are deleted. The mechanisms used to generate the
oﬀspring are collectively named genetic operators. They can be
divided into recombinations and mutations: the former methods

3

aiming to minimize the delivery rate of the network, the sim-
pler quality-of-service metric of total reachability substitutes
it, which in turn can be minimized eﬀectively with heuristics.
This metric is deﬁned as follows. A DTN D = (N, C) is a sin-
gle predeﬁned list of connection events C on the set of honest
nodes N of size n; this can be obtained by monitoring the long-
term execution of a real-world DTN. Two nodes are temporally
connected in D if there exists a (temporally non-decreasing)
sequence of connection events in C. Then, the total reachabil-
ity of D, denoted R(D), is the number of pairs of temporally
connected nodes (excluding reﬂexive pairs). To select k attack-
ers out of the set N while minimizing R(D) on a predeﬁned D,
the greedy heuristic simply selects as the ith attacker that node
which lowers the total reachability of D (excluding the ﬁrst i−1
attacker) the most. While this greedy heuristic is not proven
analytically to be optimal at minimizing R(D), it is shown ex-
perimentally to give similar results as a brute-force method, for
k ≤ 5, on the two DTNs under study.

The greedy heuristic is then shown to outperform a random
selection of nodes when k ≥ n
10 (i.e., at least 3 strong attackers
for n = 30) on the DieselNet DTN, and for any k ≥ 1 on the
Haggle DTN, for black hole attacks and the MaxProp routing
protocol. The heuristic is particularly advantageous for a very
large k; there, the diﬀerence between the delivery rate found
when k = n
2 is 30 − 40% lower on the two DTNs than with
random node selection.

3.3. Bio-inspired Heuristics

Evolutionary computation has been demonstrated a power-
ful means for tackling the inherent complexity of networking.
In [15], Baldi et al. proposed the use of a genetic algorithm
for minimizing the performance of a network, with the ﬁnal
goal to pinpoint potential bottlenecks of the topology. The ap-
proach exploits an accurate network simulator coupled with a
rudimentary evolutionary optimizer written in Perl. It could be
considered a proof of concept, as experimental results do not
show any real application.

A feasibility study of the approach described in the present
work, exploiting a far more conventional EA and tested only on
a reduced set of scenarios, was presented in [16]. In previous
research, we showed the eﬃcacy of an evolutionary algorithm
also in the context of wireless sensor networks (WSN), for
which we tested two kinds of collection tree protocols [17, 18].
We tackled diﬀerent network topologies composed of up to 50
nodes, making use of a real-code simulator, which enables to
analyze the complete software implementation of the protocols
under analysis. Furthermore, the gathered data enabled us to
pinpoint a set of topological factors which correlate with ex-
treme traﬃc under collection routing. In [19], we further en-
hanced such analysis through the use of a multi-objective evo-
lutionary algorithm, in the attempt to explore the WSN search
space from a multi-objective perspective rather than using lexi-
cographic order of ﬁtness functions.

Figure 1: Flowchart of an evolutionary algorithm

mix together the information contained in two or more solutions
to create new ones; the latter ones work by changing the struc-
ture of a single solution. Recombination operators are able to
coalesce good characteristics from diﬀerent solutions, and pro-
vide a very eﬀective mechanism to explore the search space;
mutation operators, on the other hand, allow the ﬁne-tuning of
the candidate solutions. Maintaining a set of solutions, EAs are
resilient to the attraction of local optima [14].

Over the years, EAs were proven capable to solve quite diﬃ-
cult problems with very complex ﬁtness landscapes, including
open problems related to networking and protocols. In partic-
ular, EAs are known to greatly outperform random sampling
for case studies where classical optimization techniques are not
viable [14]. Evolutionary optimizers have been successfully ex-
ploited both in stationary and dynamic situations, and they were
demonstrated able to identify either single optima or Pareto sets
in multi-objective problems, see Section 3 for a summary of rel-
evant prior work.

3. Related Work

3.1. Random Sampling

To the best of our knowledge, the only experimental work on
the assessment of DTN robustness was performed by Burgess et
al.[3], who evaluated the resilience of DTNs of 30 nodes when
running four protocols. Weak attacks (without free range, but
with attackers forced to use the routes previously used by the
honest nodes) were simulated by randomly reassigning some
of the honest nodes as attackers.

3.2. Greedy Heuristic

To generate strong attacks (again, without free range), the
same authors [3] used a greedy heuristic in response to the in-
tractability of the vertex vulnerability problem. First, instead of

4

4. Proposed Methodology

As stated in the introduction, the core idea of this work is
to expose vulnerabilities in a DTN by devising a set of eﬀective
attackers. As a single attacker is unlikely to be able to damage a
DTN network, we seek for teams of colluding malicious nodes.
Both the number of attackers and their type (black hole or ﬂood-
ing) should be optimized in order to create the maximum dam-
age. Attackers are optimized using an advanced evolutionary
algorithm that is based on an recent cooperative co-evolution
approach that is not only able to optimize the parameters of
each individual attacker, but also to optimize the composition
of the team of colluding attackers.

In more detail, we simulate a realistic DTN over an urban
environment deﬁned by a topological map and a set of POIs.
We assume two type of nodes: honest and malicious. As dis-
cussed earlier, for each honest node i the predetermined moving
path PH
is a sequence of random points of interest. For added
i
realism, a small number of these points, such as main tourist at-
tractions, may be given a higher probability of being selected as
next destination. On the contrary, for each malicious node i, the
path PM
is a sequence of points of interest chosen by the evo-
i
lutionary optimizer to cause maximum damage in the network.
Honest nodes execute the FC routing protocol, while malicious
nodes can act either as data ﬂooders or black holes.

In the proposed framework, we use the Opportunistic Net-
work Environment simulator (The ONE) [6]1 coupled with the
evolutionary toolkit µGP [20]2. The reasons for using µGP are
manifold: ﬁrst, the design of this framework is based on the no-
tion of an external evaluator, which simpliﬁes the integration
with an external network simulator; secondly, the algorithm
available in µGP features a built-in support for multiple ﬁtness
functions, that can be evaluated both in a lexicographical order
and in a multi-objective approach; then, the evolutionary en-
gine available in µGP makes use of self-adaptation techniques,
greatly limiting the number of parameters that require to be set.
Finally, µGP provides both a classical EA and a cooperative
co-evolution scheme called Group Evolution (see below).

The resulting evolutionary optimization process, depicted in
Figure 2, can then be summarized as follows: given a DTN of
N total nodes, and any parameters of the urban environment,
ﬁnd a group of attackers of size k < N, each one with its pe-
i (i = 1 . . . k) and its characteristics
culiar movement patterns PM
(movement model and attack type) which would lower the data
delivery rate (DDR) of the DTN the most, while maximizing
also its average latency.

The following section gives details about the evolutionary
core and the Group Evolution scheme, while the internal so-
lution representation and the ﬁtness function deﬁnitions are de-
scribed in Section 4.2 and 4.3, respectively.

4.1. Evolutionary core

A noticeable branch of EC is cooperative co-evolution
(CCE), that is, broadly speaking, the study of evolutionary al-

1The tool is available at http://www.netlab.tkk.fi/tutkimus/dtn/

theone/.

2The tool is available at http://ugp3.sourceforge.net.

Figure 2: Structure of the proposed framework. Candidate solutions and ﬁtness
values are internally represented as text ﬁles.

gorithms whose ﬁnal goal is achieved by a solution composed
of diﬀerent sub-solutions that cooperates to reach the common
goal. The idea of CCE dates back to the origin of EC, yet its
inherent problems are far from being solved: important contri-
butions are appearing regularly in the scientiﬁc literature (e.g.,
[21, 22, 23, 24, 25]). In the last decade, the CCE popularity fur-
ther boasted due to robotics applications where teams of robots
can be asked to perform collective tasks [26].

In CCE, sub-solutions may be heterogeneous or homoge-
neous, and combining them might be more or less trivial. Nev-
ertheless, almost all approaches strive to optimize the single
parts independently, while trying periodically to group them
into an eﬀective set, possibly exploiting heuristics or ad-hoc
tweaks. One of the main challenges in CCE is that optimizing a
single component may not be beneﬁcial to the global solution,
yet the algorithm has to harmonize the two possibly contrasting
selective pressures.

Group evolution (GE) is yet another take on CCE, natively
provided by µGP. In GE, the individual optimization phase and
the group optimization phase are blended into a single seam-
less process [27]. Individuals are merely the parts that can be
assembled to compose the groups, while groups are the actual
candidate solutions. GE stores a population of individuals and
a separate population of groups (see Figure 3), but new individ-
uals and new groups are created with no predeﬁned order: the
evolutionary core may choose the best sequence of operators
acting on individuals, and operators acting on groups. However
the user may still impose a minimum or maximum cardinality
for groups.

Another peculiarity of GE is that single individuals and sets
of individuals (i.e., groups) are evaluated by the very same ob-
jective function (e.g., the loss of performance in a DTN in the
context of this paper). This choice enables both a generaliza-
tion in the ﬁtness calculation and a tighter integration between
the two levels of evolution. The ﬁtness assigned to groups de-
pends on the cumulative eﬀect of the individuals belonging to
it, while the contribution of each single individual is also stored
and used during comparison.

More operatively, each group is a set of references to indi-
viduals in the individual population: so, the same individual
can belong simultaneously to multiple groups. At every gener-

5

Figure 3: A high-level scheme of the two-population approach used by GE.
Groups are sets of individuals taken from the individual population. The same
individual can appear multiple times in the same group or in diﬀerent groups:
for example, individuals 1 and 2 belong to both groups A and B.

ation, once new groups and individuals are created and evalu-
ated, groups are sorted by their ﬁtness function, and the worst
are removed, factually deleting references to certain individu-
als. After this process, orphans, i.e., individuals not belonging
to any group in the current group population, are also deleted.
Interestingly, GE can be used with no modiﬁcation to op-
timize single attackers: when the maximum size of a group
is set to 1, the evolutionary core automatically stops using
group manipulation operators, such as addElementToGroup
and removeElementFromGroup. For the purpose of this work,
we further modiﬁed the original GE available in µGP introduc-
ing a new mechanism for choosing which operators to use in
the current generation, and a strategy for caching the results of
past evaluations [28]. The ﬂowchart of the GE algorithm used
in this work is shown in Figure 4.

4.2. Internal solution representation

In the problem under study, we consider a model of strong
colluding attackers with full network knowledge and free range
of movement. In other words, we consider attacks carried out
by multiple collaborating nodes which are connected via alter-
native communication links. In this context, a candidate solu-
tion represents a group of one or more malicious nodes, each
one characterized by the following properties:

• the attack logic to adopt (e.g., black hole, ﬂooding); we
assume this choice remains unchanged during an attack;

• the movement model (e.g., pedestrian, vehicle), which con-
strains the node to a corresponding map layer and mobility
pattern;

• the route on any given map layer, deﬁned via a list of POIs
on that map layer; free-range strong attackers have full
control when deciding their POIs.

The resulting structure of a candidate solution is thus quite
complex, as each attacker can feature a variable number of
POIs, and each group can have a variable number of attack-
ers. An example of solutions produced by the evolutionary core
is shown in Figure 5.

Figure 4: Flowchart of an evolutionary algorithm using group evolution. Oper-
ations exclusive to GE are depicted in black. New groups and new individuals
are created in a single uniform step, while to evaluate new groups the evaluation
of new individuals is required.

In a classical EA, the individual would then be a (either ﬁxed-
or variable-size) composition of multiple attackers with diﬀer-
ent properties. When GE is applied instead, each individual
models exactly a single attacker, while the organization of such
malicious nodes is delegated to groups, with a ﬁnal result struc-
turally similar to the case where a single individual portrays
several nodes.
In any case, the genetic operators can act on
each node, modifying its movement model, its attack logic, and
adding/removing/replacing POIs in its path, in order to generate
new candidate solutions. In experiments with a variable num-
ber of malicious nodes, the same operations can be performed
on the blocks representing the nodes.

It is important to notice that the same POIs have diﬀerent
meanings depending on the node’s movement: even if a vehi-
cle and a pedestrian pass close to the same coordinates, they
may reach them using diﬀerent paths, causing distinct network
disruptions along the way. Also, since most of the POIs are
accessible by certain types of movement only (e.g., a point in
open water cannot be reached by a pedestrian, nor one on land

6

Mov=vehicle
Attack=black hole
94,39
55,84
...
42,44
1,26

Mov=pedestrian
Attack=flood
22,75
43,15
...
65,61
15,58

Mov=boat
...
...
...
...
...
...

Figure 5: Example of solution for the DTN attack problem, describing multiple
attackers. Each attacker is characterized by its movement model (e.g. boat,
pedestrian, vehicle), its attack logic (black hole or ﬂood), and a series of POIs
it will visit during the simulation, encoded as squares in a grid overlapped to
the city map.

by a boat), for each type we overlap a grid layer onto the city
map layer, and deﬁne the path of an attacker of that type as a set
of grid squares inside that grid. During the simulation, we then
map each grid square to the map point closest to the square; if
a square contains more than one map point, the malicious node
visits them all.

In particular, µGP exploits a user-deﬁned description of solu-
tions in an XML ﬁle. The external representation of candidate
solutions is written to text ﬁles as they are evaluated, while their
internal structure is stored to disk as XML ﬁles, that can be read
in case the evolutionary process is resumed.

4.3. Fitness functions

Movement model, attack logic and POIs to visit are set at the
level of each malicious node, but the objective is to maximize
the global eﬀectiveness of the attack: an optimal set of collud-
ing attackers should lower the performance objectives of the
network the most. The eﬀectiveness of an attack conﬁguration
is thus assessed as an evaluation of an urban network scenario
(see next Section) performed by the network simulator. The
outputs of such simulation (i.e., the ﬁtness values, using the ter-
minology of EC), are:

• ( f1) the data delivery rate (DDR), calculated as the per-
centage of messages originated only from honest nodes,
and which are delivered successfully;

• ( f2) similarly, the average latency of message deliveries (in

seconds).

The two values are considered in lexicographic order, as we
assign more importance to a reduction of the network’s DDR
rather than an increase of latency: optimization-wise, f1 is to
be minimized, while f2 is to be maximized.

5. Experiments

This section ﬁrst summarized the conﬁguration settings for
the experimental campaigns. Sections 5.1 and 5.2 quantify
the parameters used to deﬁne an urban setting and its network
nodes. Section 5.3 summarizes the experimental parameters of
the evolutionary core. Sections 5.4 and 5.5 give the numerical
results and discuss their practical impact.

We make public the city maps, the experimental conﬁgura-

tions, and detailed experimental results, at the URL:
https://github.com/doinab/DTN-security.

5.1. DTN and the cities: San Francisco and Venice

To validate our methodology, we simulate two realistic,
large-scale city environments, each composed of a map and a
large set of honest, randomly moving network nodes of cer-
tain types relevant to a given city. Figures 6 and 7 show the
basic maps of the two urban environments in our experimen-
tal scenarios, namely San Francisco and Venice. These cities
diﬀer in terms of map topology: while the area of San Fran-
cisco has a regular grid structure of routes, the area of Venice
has a complex, hierarchical, irregular structure of main and sec-
ondary waterways travelled by boats, with pedestrians conﬁned
to inner walkways (some along waterways) and bridges. The
Venice map has an additional feature for added realism: on both
map layers, a small number of the map POIs mark the touristic
center, and have a higher probability to be chosen as the next
destination by the honest nodes. Table 1 quantiﬁes the maps
and map layers in terms of size, number of distinct map points,
route segments, and number of nodes.

Figure 6: A 5 km2 area of downtown San Francisco, US, with a grid-based
map topology of streets and the occasional park. The map has two overlapping
layers, constraining the movement of vehicles and pedestrians: the vehicles are
conﬁned to the black streets, while the pedestrians may walk both the green and
the black routes.

5.2. Network simulation and network nodes

In both cities we conﬁgured N = 200 moving network nodes,
divided in two types: pedestrians (75%) and vehicles (25%).
For San Francisco, the vehicles consist of motorized cars; in
Venice, the waterways serve as routes for motorized or unmo-
torized boats. Pedestrians are modelled as carrying commu-
nication devices with relatively limited capabilities: a Blue-
tooth communication interface with a range of 15m and low
bandwidth. Vehicles are awarded more communication capa-
bilities: besides a Bluetooth interface (which allows commu-
nication events to take place between any pedestrian and any
vehicle), a vehicle also has a high-speed, longer-range network
interface allowing vehicle-to-vehicle communication.

7

Table 1: Network parameters: city maps

San Francisco:

Venice:

size:
map layers:
no. of route segments:
no. of map points:
network size:

2416 m × 2253 m
LP (pedestrian walkways), LS (streets)
1728 in LP, 1305 in LS
1210 in LP, 883 in LS
150 pedestrians (constrained to LP), 50 cars (constrained to LS )

size:
map layers:
no. of line segments:
no. of map points:
network size:

2210 m × 2340 m
LP (pedestrian walkways), LW (waterways)
7983 in LP, 1497 in LW
6910 in LP, 1354 in LW
150 pedestrians (constrained to LP), 50 boats (constrained to LW )

an (e.g., pedestrian) attacker then only diﬀers from that of an
honest pedestrian in that the attacker’s next destination point is
randomly chosen from the evolved set of POIs, rather than the
entire map layer.

Honest nodes periodically inject new messages to be routed
by the network; the rate of message injection among all honest
nodes is set at one message every 30 seconds, such that the
network routes 120 honest messages per hour. The honest node
to inject the next message in the network is chosen randomly.
The malicious nodes run one of the two attack logics described
in Section 2.4.

A black hole attacker does not inject any additional messages
in the network. On the other hand, when an attacker executes
a ﬂood, the parameters are chosen to obtain a “heavy” ﬂood of
messages: (1) a ﬂooding node injects messages in the network
at 10 times the frequency of message injection from an honest
node, and (2) the messages injected by a ﬂooder are 10 times as
large as regular messages. Table 3 summarizes these communi-
cation parameters, together with the settings regarding the sizes
of the nodes’ message buﬀers, and the Time To Leave (TTL),
which limits the amount of time that a message is allowed to
be stored in a node’s buﬀer without being forwarded — we set
TTL to be large, and equal to the length of an experiment: 5
hours (simulated time).

5.3. Evolutionary parameters

During all the experiments, µGP has been conﬁgured with
the parameters reported in Table 4. The operators chosen for
the evolution are:

• onePointImpreciseCrossover:

one-point crossover

between two individuals;

• twoPointImpreciseCrossover: crossover with with

two cut points;

• singleParameterAlterationMutation: mutate a sin-
gle coordinate of a POI, the movement model or the attack
logic;

• insertionMutation: add a new random POI;

• removalMutation: remove a randomly selected POI;

• replacementMutation: replace a POI with a randomly

generated one.

8

Figure 7: A 5 km2 area of downtown Venice, IT, with an irregular map topology
of pedestrian pathways (the black map layer) and waterways (the blue layer).
Marked with stars are special POIs in the city’s touristic center.

Each simulation of a DTN in The ONE is stochastic. The
nodes are initially placed randomly on their map layer, and a
1,000-second warm-up simulation period is allowed before the
experiment starts, for the nodes to settle on the “natural” pre-
ferred routes in the city. The next destination POI is also chosen
randomly. Due to this, to smoothen the ﬁtness landscape and
reduce the eﬀect of the random seed of each simulation on the
evaluation of solution, we execute each network simulation 10
times, initialized with diﬀerent random seeds, and report as ﬁt-
ness values the average DDR and latency over the 10 available
repetitions.

The movement model of all nodes follows the general ran-
domized pattern summarized in Section 2.3. A subset of these
200 nodes is assigned a malicious behaviour. For an honest
node, the set of POIs is simply the entire set of map points lo-
cated on the node’s relevant map layer. The node randomly
chooses any destination point from that map layer, travels there
at a certain speed on the shortest path, pauses for an interval,
and repeats the process. The conﬁguration for the nodes’ speed
and pause interval is given by Table 2. For an attacker, the set
of POIs is is a subset of the map points of the relevant map
layer, and is evolved by the evolutionary core as part of each
solution (as described in Section 4.2). The movement model of

Table 2: Network parameters: movement models

Movement model
for nodes in all cities

next point:
path choice:
pedestrian speed:
boat speed:
car speed:
pause interval for all:

chosen randomly from a map layer
shortest path on the map layer to the next point
[0.5 . . . 1.5] m/s
[1.0 . . . 5.0] m/s
[2.7 . . . 13.9] m/s
[0 . . . 120] s at each destination point

Table 3: Network parameters: simulation and node communication settings

Simulation
settings

simulation time:
DTN simulator:

5 h
The ONE [6]

Message
settings

message issued:
message size:
message buﬀer:
message TTL:

every 30 s (by an honest node), every 3 s (by a ﬂooder)
10 kB (issued by an honest node), 100 kB (issued by a ﬂooder)
5 MB (for pedestrian nodes), 50 MB (for car and boat nodes)
5 h

Node
communication
interfaces

Bluetooth:
High-speed:
pedestrians use:
cars and boats use:

range 15 m, speed 250 kBps
range 100 m, speed 10 MBps
Bluetooth
Bluetooth and High-speed

Figure 8: Comparative results: data delivery rate (DDR) from three experimental campaigns using group evolution, a classical EA, and random testing. The DDR
obtained with a random test is shown as the mean and standard deviation among the mean DDR of 150 randomly generated groups, each group simulated 10 times
with diﬀerent random seeds. The DDR obtained with any evolutionary experiment is a single group of top ﬁtness, and is shown as the mean and 95% conﬁdence
interval among 5 simulation repetitions of that group with diﬀerent random seeds.

The activation probabilities of all the operators in the popula-
tion are self-adapted during the run; [28] enables to eﬃciently
alternate phases where individuals are optimized, with phases
where groups are optimized. Self adapting the size of the tour-
nament for selecting parents (τ) enables to optimize the selec-
tive pressure; while self adapting the strength of the mutation
operators (σ) enables to balance between exploration and ex-
ploitation. Every time a mutation is performed, it is executed
again on the same individual if a randomly generated number
in (0, 1) is lower than the current value of σ. For high values
of σ, the algorithm will tend to generate new solutions that are
very diﬀerent from their parents, thus favoring exploration; for
low values of σ, the diﬀerences between parents and oﬀspring

will be smaller, thus entering a phase of exploitation.

During the GE experiments, new operators are added in order

to manipulate groups, namely:

• groupRandomInsertionMutation: add a random indi-

vidual to a group;

vidual from a group;

• groupRandomRemovalMutation: remove a random indi-

• groupBalancedCrossover: crossover that moves the

same number of individuals between two groups;

• groupUnbalancedCrossover: same as above, with no
guarantee of moving the same number of individuals;

9

Table 4: µGP experimental settings

• A GE-based experimental campaign (for the settings

where k > 1);

Parameter Description

τ
σ
α
§

µ
λ

size of the tournament selection
initial strength of the mutation operators
inertia of the self-adapting mechanisms
stagnation threshold (in generations)

Classical EA

individual population size
operators (genetic) applied at every step

Group Evolution

µgroup
νindividual
λ

group population size
initial individual population size
operators (genetic or groups) applied at every step

Value

1.0÷4.0
0.9
0.9
50

30
20

30
50
20

• groupUnionIntersection: returns the union and the in-

tersection of two groups;

• groupDreamTeam: creates a group with some of the best

individuals currently in the population.

As previously detailed, the number of individuals in the GE
paradigm is regulated by the number of groups in the current
population, µgroup. Individuals are removed only when they are
no longer included in any group. The number of individuals
generated at the beginning of the execution, number that can be
later exceeded or reduced, is controlled by parameter νindividual.
Further information on parameters and operators in µGP can be
found in [20].

5.4. Experimental campaigns and results

Given the settings described in Sections 5.1–5.3, which are
common to all experiments, an experiment will be uniquely
identiﬁed by the following two parameters:

City (i.e., San Francisco or Venice)

Number of attackers i.e., the size of the attack group k, in the
range 1 ≤ k ≤ N. We delineate ﬁve practically interesting
ranges:

• k = 1, i.e., a single attacker;
• k = 2, i.e., a pair of attackers;
• k ∈ [1 . . . 5];
• k ∈ [6 . . . 10];
• k ∈ [11 . . . 20], i.e., a group which can reach 10% of

the overall network size of N = 200 nodes.

The ranges for k thus come in two categories: a ﬁxed group
size (when k = 1 or k = 2), or a variable group size (for larger
k). In the latter case, intuitively, the expectation is that the evo-
lutionary algorithm will maximize the group size in the process
of optimizing the ﬁtness functions.

To assess the comparative performance of our method based
on Group Evolution, we ran the following three experimental
campaigns, for each experimental setting (City × Number of
attackers):

• An experimental campaign based on the classical, non-GE
EA applied to the same problem in prior literature [16];

• The testing of groups of a sample of 150 purely randomly

generated groups of attackers.

For each experimental setting, the GE and non-GE experimen-
tal campaigns consist of 5 experiment repetitions, initialized
with diﬀerent random seeds.

The results of the experimental campaigns are summarized
in Figure 8, separately per city. The ﬁrst ﬁtness function, f1,
measuring the global data delivery rate (DDR) in the network,
quantiﬁes the decreasing network performance with an increas-
ing size of the attack group, k. In the ﬁgures, the data points
are presented for the set k ∈ {1, 2, 5, 10, 20}, as the evolution-
ary algorithms found that the lowest ﬁtness is achieved when
the size of the attacker group is maximum. For comparison, the
ﬁgures also include a data point showing the ﬁtness function
with no attack present (i.e., all N = 200 nodes in the network
are honest).

As seen in Figure 8, while the First Contact protocol has only
moderate data delivery in these complex urban settings even
in the absence of attacks, both evolutionary algorithms signif-
icantly outperform random testing, and GE was found to be
advantageous in all the experimental settings. Moreover, a sim-
ilar trend for the performance of the First Contact protocol was
obtained between the two cities: a single attacker was found
suﬃcient to lower the data delivery to half that of the no-attack
setting, and, with a group of 20 attackers, the data delivery in
the network was found to drop close to zero.

To further conﬁrm this trend, we performed a thorough anal-
ysis [29] of the numerical results. The analysis was conducted
as follows: for each city map and attack group size k > 1 (when
k = 1 a group cannot be deﬁned), ﬁrst we aggregated the 150
lowest DDR values obtained by GE and non-GE experiments,
over the 5 available repetitions for each of the two algorithms.
We then performed pairwise comparisons between the two al-
gorithms, and w.r.t.
the DDR of the 150 randomly sampled
attack groups used as baseline. For each pairwise comparison,
we initially verify the normality of the two distributions with
the Shapiro-Wilk test; if both samples are normally distributed,
we then test the homogeneity of their variances (homoscedas-
ticity) with an F-test. If variances are equal, we compare the
two distributions by means of the Student t-test, otherwise we
adopt Welch’s t-test variant. More speciﬁcally, we ﬁrst test the
null-hypothesis of equal distributions (i.e. the two algorithms
under comparison are statistically equivalent from an optimiza-
tion point of view); then, we test the null-hypothesis that the
ﬁtness values obtained with one of the two algorithms, taken
as reference, are statistically smaller than those obtained by the
other algorithm.
In case of non-normal distributions, we in-
stead test the null-hypotheses by means of the non-parametric
Wilcoxon Rank-Sum test. In all the tests, we consider a conﬁ-
dence level of 0.95 (α = 0.05).

10

The statistical analysis is summarized in Table 5. The anal-
ysis conﬁrms that GE and non-GE EA statistically outperform
random sampling, and GE outperforms non-GE in all cases.

Table 5: Summary of the statistical analysis (see the main text for details). Each
column (labeled as X/Y) shows the pairwise comparison between the results
obtained by algorithm X and Y, with X taken as reference. The symbol ’+’
indicates that X statistically outperforms Y, i.e. it obtains attacker groups with
lower network performance (DDR).

San Francisco

GE/Random non-GE/Random

No. attackers
2
1-5
6-10
11-20

No. attackers
2
1-5
6-10
11-20

GE/non-GE
+
+
+
+

GE/non-GE
+
+
+
+

+
+
+
+

+
+
+
+

+
+
+
+

+
+
+
+

Venice

GE/Random non-GE/Random

5.5. Runtimes and discussion of results

In Figure 9 we show the computational cost of running the
evolutionary campaigns, each data point the average of 5 rep-
etitions of an experiment with diﬀerent seeds. The runtime is
shown in core-hours, over computing cores of at least 1.6 GHz
(since we ran the experiments on a number of machines, there
was variation among the computational power allowed among
experiments).

More interestingly, the reason why the GE algorithm shows
an advantage over a classical EA is seen in Figure 10. The ﬁg-
ure ﬁrst selects all the “top” attacker groups obtained by the GE
and non-GE experiments, i.e., those groups which lower net-
work performance to within 2% of the absolute best ﬁtness f1
found by that algorithm. We observed that the number of these
top groups falls between 300 and 6, 000 (depending on the ex-
perimental setting), all of which can be considered successful
attacks. The average composition of this large group sample is
analyzed in terms of how often a type of attacker, i.e., a move-
ment model (that of a pedestrian, or that of a vehicle) and attack
logic (black hole or ﬂooding) appears in a top group.

The best single attacker found by both the GE and non-GE
algorithms is a black hole vehicle:
indeed, 100% of the top
groups found by both algorithms consist of an attacker of this
type. The same is true for pairs of attackers.

For larger group sizes, the two algorithms show a diﬀerence
of results. When k ∈ [11 . . . 20], the non-GE algorithm found an
overall lower top ﬁtness while obtaining top groups for which:
(1) the average group size does not saturate (it reaches an aver-
age of 18.23 out of 20, for the San Francisco setting), and (2)
the average group composition is a mix of attacker types, with
only 50% of the attackers in the top groups matching the type
of the best single attacker (a black hole vehicle).

On the other hand, the GE algorithm likely outperformed the
non-GE in terms of best ﬁtness found due to the fact that it both
maximized the average top group size, and optimized the aver-
age top attacker type, demonstrating that homogeneous groups

Figure 9: Computational overhead of non-GE and GE experiments: the number
of evolutionary generations, the number of solution evaluations, and the wall-
clock runtime per experimental campaign, shown as the average among the 5
experiments conﬁgured with diﬀerent random seeds, per experimental setting.

of black holes are advantageous to exploit the vulnerabilities in
the design of the First Contact protocol, and that faster black
hole attackers also have a clear advantage.

6. Conclusions

In this paper we proposed a heuristic methodology to as-
sess the robustness of First Contact, one of the main routing
protocols used in Delay-Tolerant Networks. To exploit possi-
ble weaknesses of the network, we considered the worst-case
scenario of an attack carried out by a coordinated group of
agents with full network knowledge. The methodology is based
on an evolutionary algorithm using a cooperative co-evolution
scheme called Group Evolution recently introduced in the liter-
ature and here extended for our purposes. The method is able
to optimize groups (either homogeneous or not) of malicious
nodes whose behaviour does not comply with the legitimate
routing protocol used by honest nodes in the network.

We performed an extensive experimental campaign over
medium-sized (i.e., 200 nodes) realistic urban networks run-
ning on two diﬀerent cities with radically diﬀerent map topolo-
gies (San Francisco and Venice). We assessed the scalability of
the approach by evaluating single attackers as well as groups of

11

Figure 10: The average group size and group composition among all top solutions (whose ﬁtness is within 2% of the best ﬁtness). The group composition is shown
in terms of the percentage of ﬂooding vehicles (FV), ﬂooding pedestrians (FP), black hole vehicles (BV), and black hole pedestrians (BP) among these top solutions.

up to 10% malicious nodes. Moreover, we compared results ob-
tained with random sampling and a more classical evolutionary
algorithm.

In all our experiments, the two evolutionary methods clearly
outperformed random sampling, consistently ﬁnding groups of
attackers that produced a larger network damage (reduced data
delivery rate and increased latency). The additional advantage
brought by Group Evolution resulted in an improved attack ef-
fect, optimized group compositions, and more eﬀective move-
ment models.

Overall, the contribution of this work is twofold: on one
hand, we proposed an eﬃcient alternative to random sampling,
that is currently one of the most used approaches for assessing
network robustness; on the other hand, we showed an example
problem that can be naturally described in terms of coopera-
tive co-evolution and for which such an evolutionary scheme is
clearly beneﬁcial.

This work represents then one of the few attempts at ﬁnd-
ing applications of cooperative co-evolution beyond the typical
domain of swarm robotics. In future research, we will seek to
extend this approach to diﬀerent networking applications and,
possibly, new unexplored domains.

[3] J. Burgess, G. D. Bissias, M. D. Corner, B. N. Levine, Surviving attacks
on disruption-tolerant networks without authentication, in: Proceedings
of the 8th ACM International Symposium on Mobile Ad Hoc Networking
and Computing, MobiHoc ’07, ACM, New York, NY, USA, 2007, pp.
61–70.

[4] S. Jain, K. Fall, R. Patra, Routing in a delay tolerant network, in: Pro-
ceedings of the 2004 Conference on Applications, Technologies, Archi-
tectures, and Protocols for Computer Communications, SIGCOMM ’04,
ACM, New York, NY, USA, 2004, pp. 145–158.

[5] P. Sommer, B. Kusy, P. Valencia, R. Dungavell, R. Jurdak, Delay-
arXiv preprint

tracking,

tolerant networking for long-term animal
arXiv:1506.01792 (2015).

[6] A. Ker¨anen, J. Ott, T. K¨arkk¨ainen, The ONE Simulator for DTN Protocol
Evaluation,
in: SIMUTools ’09: Proceedings of the 2nd International
Conference on Simulation Tools and Techniques, ICST, New York, NY,
USA, 2009.

[7] C. Darwin, On the Origin of the Species by Means of Natural Selection:
Or, The Preservation of Favoured Races in the Struggle for Life, John
Murray, 1859.

[8] A. M. Turing, Computing machinery and intelligence, Mind (1950) 433–

[9] D. B. Fogel, Evolutionary computation:

the fossil record, Wiley-IEEE

[10] J. H. Holland, Adaptation in Natural and Artiﬁcial Systems, University of

[11] L. J. Fogel, Autonomous automata, Industrial Research 4 (1962) 14–19.
[12] H.-G. Beyer, H.-P. Schwefel, Evolution Strategies – A comprehensive

introduction, Natural computing 1 (2002) 3–52.

[13] J. R. Koza, Genetic Programming: vol. 1, On the programming of com-
puters by means of natural selection, volume 1, MIT press, 1992.
[14] A. E. Eiben, J. E. Smith, Introduction to evolutionary computing, vol-

[15] M. Baldi, F. Corno, M. Rebaudengo, G. Squillero, GA-based perfor-
mance analysis of network protocols, in: Proc. Ninth IEEE International
Conference on Tools with Artiﬁcial Intelligence, 1997, pp. 118–124.

460.

Press, 1998.

Michigan Press, 1975.

References

[1] K. Fall, S. Farrell, DTN: an architectural retrospective, Selected Areas in

ume 2, Springer Berlin, 2010.

Communications, IEEE Journal on 26 (2008) 828–836.

[2] J. Burgess, B. Gallagher, D. Jensen, B. Levine, MaxProp: Routing for
Vehicle-Based Disruption-Tolerant Networks, in: INFOCOM 2006. 25th
IEEE International Conference on Computer Communications, pp. 1–11.

12

[16] D. Bucur, G. Iacca, G. Squillero, A. Tonda, Black holes and revelations:
Using evolutionary algorithms to uncover vulnerabilities in disruption-
tolerant networks, in: A. M. Mora, G. Squillero (Eds.), Applications of
Evolutionary Computation, volume 9028 of Lecture Notes in Computer
Science, Springer International Publishing, 2015, pp. 29–41.

[17] D. Bucur, G. Iacca, G. Squillero, A. Tonda, The impact of topology on
energy consumption for collection tree protocols: An experimental as-
sessment through evolutionary computation, Applied Soft Computing 16
(2014) 210–222.

[18] D. Bucur, G. Iacca, P.-T. de Boer, Characterizing topological bottlenecks
for data delivery in CTP using simulation-based stress testing with natural
selection, Ad Hoc Networks 30 (2015) 22 – 45.

[19] D. Bucur, G. Iacca, G. Squillero, A. Tonda, The tradeoﬀs between data
delivery ratio and energy costs in wireless sensor networks: A multi-
objective evolutionary framework for protocol analysis, in: Proceedings
of the Sixtienth Annual Conference on Genetic and Evolutionary Com-
putation Conference, GECCO ’14, ACM, New York, NY, USA, 2014.

[20] E. Sanchez, M. Schillaci, G. Squillero, Evolutionary Optimization: the

µGP toolkit, Springer Publishing Company, 1st edition, 2011.

[21] M. Potter, K. De Jong, A cooperative coevolutionary approach to function
optimization, in: Y. Davidor, H.-P. Schwefel, R. Manner (Eds.), Parallel
Problem Solving from Nature PPSN III, volume 866 of Lecture Notes
in Computer Science, Springer Berlin / Heidelberg, 1994, pp. 249–257.
10.1007/3-540-58484-6 269.

[22] E. Dunn, G. Olague, E. Lutton, Parisian camera placement for vision
metrology, Pattern Recognition Letters 27 (2006) 1209 – 1219. Evolu-

tionary Computer Vision and Image Understanding.

[23] R. Thomason, R. Heckendorn, T. Soule, Training time and team compo-
sition robustness in evolved multi-agent systems, in: M. O’Neill, L. Van-
neschi, S. Gustafson, A. Esparcia Alcazar, I. De Falco, A. Della Cioppa,
E. Tarantino (Eds.), Genetic Programming, volume 4971 of Lecture Notes
in Computer Science, Springer Berlin / Heidelberg, 2008, pp. 1–12.
10.1007/978-3-540-78671-9 1.

[24] M. Waibel, L. Keller, D. Floreano, Genetic Team Composition and Level
of Selection in the Evolution of Cooperation, IEEE Transactions on Evo-
lutionary Computation 13 (2009) 648–660.

[25] A. Tonda, E. Lutton, G. Squillero, Lamps: A test problem for cooperative
coevolution, in: Nature Inspired Cooperative Strategies for Optimization
(NICSO 2011), Springer, 2011, pp. 101–120.

[26] L. Panait, S. Luke, Cooperative multi-agent learning: The state of the art,
Autonomous Agents and Multi-Agent Systems 11 (2005) 387–434.
[27] E. Sanchez, G. Squillero, A. Tond, Group evolution: Emerging synergy
through a coordinated eﬀort, in: Evolutionary Computation (CEC), 2011
IEEE Congress on, IEEE, pp. 2662–2668.

[28] G. S. Jany Belluz, Marco Gaudesi, A. Tonda, Searching for the mini-
mum failures that can cause a hazard in a wireless sensor network,
in:
Proceedings of the Fifteenth Annual Conference on Genetic and Evolu-
tionary Computation Conference (to appear), GECCO ’15, ACM, New
York, NY, USA, 2015.

[29] E. L. Lehmann, J. P. Romano, Testing statistical hypotheses, Springer

Texts in Statistics, Springer, New York, third edition, 2005.

13

