SINAI at SemEval-2019 Task 5: Ensemble learning to detect hate speech
against inmigrants and women in English and Spanish tweets

Flor Miriam Plaza-del-Arco, M. Dolores Molina-Gonz´alez,
M. Teresa Mart´ın-Valdivia, L. Alfonso Ure ˜na-L´opez

Department of Computer Science, Advanced Studies Center in ICT (CEATIC)
Universidad de Ja´en, Campus Las Lagunillas, 23071, Ja´en, Spain
{fmplaza, mdmolina, maite, laurena}@ujaen.es

Abstract

Misogyny and xenophobia are some of the
most important social problems. With the in-
crease in the use of social media, this feeling of
hatred towards women and immigrants can be
more easily expressed, therefore it can cause
harmful effects on social media users. For this
reason, it is important to develop systems ca-
pable of detecting hateful comments automat-
ically. In this paper, we describe our system to
analyze the hate speech in English and Spanish
tweets against Immigrants and Women as part
of our participation in SemEval-2019 Task 5:
hatEval. Our main contribution is the integra-
tion of three individual algorithms of predic-
tion in a model based on Vote ensemble classi-
ﬁer.

1

Introduction

With the growing prominence of social media like
Twitter or Facebook, more and more users are
publishing content and sharing their opinions with
others. Unfortunately, the content often contains
hate speech language that can have damaging ef-
fects on social media users. This fact concerns
to social media platforms like Facebook since ac-
cording to an EU’s report, it removes 82 percent
of illegal hate speech on the platform, up from 28
percent in 20161.

Normally, hate speech can be aimed at a per-
son or a group base on some characteristic such
as race, sexuality, color, ethnicity, physical ap-
pearance, religion, among others (Erjavec and
Kovaˇciˇc, 2012). Currently,
two of the targets
most affected by these types of offensive com-
ments are immigrants and women (Waseem and
Hovy, 2016). In particular, when the hate speech is
gender-oriented, and it speciﬁcally targets women,
we refer to it as misogyny (Manne, 2017) and

1https://cnb.cx/2RGmEwel

when the hate speech is against immigrants, we
refer to it as xenophobia (Sanguinetti et al., 2018).
Recently, a growing number of researchers have
started to focus on studying the task of automatic
detection of hateful language online (Fortuna and
Nunes, 2018; Fersini et al., 2018b), moreover,
some academic events and shared tasks have taken
place focusing on this issue (Fersini et al., 2018a).
It is consider as a difﬁcult task for social media
platforms. For example, popular social media such
as Twitter, Instagram or Facebook are not able to
automatically solve this problem and depend on
their community to report hateful speech content.
The severe consequences of this problem, com-
bined with the large amount of data that users pub-
lish daily on the Web, requires the development of
algorithms capable of automatically detecting in-
appropriate online remarks.

In this paper, we describe our participation in
SemEval-2019 Task 5: Multilingual Detection of
Hate Speech Against Immigrants and Women in
Twitter (hatEval) (Basile et al., 2019). In particu-
lar, we participate in task A in English and Span-
ish. It is a binary classiﬁcation task and the objec-
tive is predict whether a tweet with a given target
(women or immigrants) is hateful or not hateful.

The rest of the paper is structured as follows. In
Section 2 we explain the data used in our meth-
ods. Section 3 presents the details of the proposed
systems. In Section 4, we discuss the analysis and
evaluation results for our system. We conclude in
Section 6 with remarks and future work.

2 Data

To run our experiments, we used the Spanish and
English datasets provided by the organizers in Se-
mEval19 Task 5 : HatEval (Basile et al., 2019).
The datasets contain tweets with several ﬁelds.
Each tweet is composed for an identiﬁer (id), the

text of the tweet (text), the mark of hate speech
(HS), being 0 if the text is not hateful and 1 if the
text is hateful, the mark of recipient of text (TR),
being 1 if the target is a single human and 0 if the
target is a group of persons and the last ﬁeld (AG)
is the mark that identiﬁes if the text is aggressive
whose value is 1, else 0 in the case opposite. Dur-
ing pre-evaluation period, we trained our models
on the train set, and evaluated our different ap-
proaches on the dev set. During evaluation period,
we trained our models on the train and dev sets,
and tested the model on the test set. Table 1 shows
the number of tweets used in our experiments for
Spanish and English.

Dataset
Spanish
English

train
4,500
9,000

dev
500
1,000

test
1,600
3,000

Table 1: Number of tweets per HatEval dataset

We only take into account the ﬁelds text and HS
for our experiments because we participate in task
A in English and Spanish.

3 System Description

In this section, we describe the systems developed
for the Hateval task 5, subtask A in English and
Spanish.

3.1 Our classiﬁcation model

In ﬁrst place, we preprocessed the corpus of tweets
provided by the organizers. We applied the follow-
ing preprocessing steps: the documents were tok-
enized using NLTK library 2 and all letters were
converted to lower-case. In second place, an im-
portant step is converting sentences into feature
vectors since it is a focal task of supervised learn-
ing based sentiment analysis method. Therefore,
our chosen statistic feature for the text classiﬁca-
tion was the term frequency (TF) taking into ac-
count unigrams and bigrams because it provided
the best perfomance.

During our experiments, the scikit-learn ma-
chine learning in Python library (Pedregosa et al.,
2011) was used for benchmarking. Our classi-
ﬁcation model based on Vote ensemble classiﬁer
Logis-
combined three individual algorithms:
tic Regression (LR), Decision Tree (DT) and Sup-
port Vector Machines (SVMs). We have tested

2https://www.nltk.org/

with other models such as naive bayes and mul-
tilayer perceptron but we have obtained better re-
sults with the combination of the three algorithms
mentioned above. In Figure 1, it can be seen our
model. We train our model with the train and dev
set and we evaluated it with the test set. There are
many combinations to implement a model when
we apply different classiﬁers with several parame-
ters. Therefore, one of the most important step was
to ﬁnd the best individual classiﬁers for the prob-
lem. After doing several experiments with each
classiﬁer independently, we came up with SVMs,
In order to improve the
LR and DT classiﬁers.
performance of each classiﬁer, we choose the best
optimization of the parameters in each of them.

Figure 1: Systems architecture.

3.2 Classiﬁers

1. Logistic Regression is an statistical method
for prediction binary classes. It computes the
probability of an event occurrence utilizing a
logit function. In order to optimize the pa-
rameters of LR in our English and Spanish
experiments, we used the penalty parameter
equal to l1 regularization.

2. Decision Tree is a ﬂowchart-like tree struc-
ture where an internal node represents fea-
tures, the branch represents a decision rule,
and each leaf node represents the outcome. In
order to optimize the parameters of DT in our
English and Spanish experiments, we leave

User name (r)

francolq2 (1)
luiso.vega (2)
fmplaza (14)
SVC baseline (21)
DA-LD-Hildesheim (40)

Test
R

F1

Acc

0.73
0.73
0.707
0.701
0.493

0.731
0.734
0.711
0.705
0.511

0.741
0.736
0.713
0.707
0.494

P

0.734
0.729
0.707
0.701
0.493

Table 2: System Results per team in subtask A of hatEval task in Spanish.

User name (ranking)

saradhix (1)
amontejo (5)
SVC baseline (35)
fmplaza (40)
sabino (71)

Test
R

F1

Acc

0.679
0.577
0.549
0.555
0.521

0.651
0.519
0.451
0.443
0.35

0.653
0.535
0.492
0.493
0.447

P

0.69
0.601
0.595
0.627
0.652

Table 3: System Results per team in subtask A of hatEval task in English.

the default parameters.

3. Support Vector Machines is a linear learn-
ing technique that ﬁnds an optimal hyper-
plane to separate our two classes (hateful
and not hateful speech). Many researchers
have reported that this classiﬁer is perhaps
the most accurate method for text classiﬁca-
tion (Moraes et al., 2013) and also is widely
used in sentiment analysis (Tsytsarau and
Palpanas, 2012). In order to optimize the pa-
rameters of SVMs in our English and Spanish
experiments, we used the parameter C equal
to 0.6 and the kernel used was linear.

4. Vote is one of the most straightforward en-
semble learning techniques in which per-
forms the decision process by applying sev-
eral classiﬁers. Voting classiﬁer combines
machine learners by using a majority vote or
predicted probabilities for the classiﬁcation
of samples. The predictions made by the sub-
models can be assigned weights. In our case,
the weights are distributed as follows: 2 for
LR and SVM and 1 for DT.

4 Experiments and analysis of results

During the pre-evaluation phase we carried out
several experiments and the best experiments were
taken into account for the evaluation phase. The

system has been evaluated using the ofﬁcial com-
petition metrics, including Accuracy (Acc), Preci-
sion (P), Recall (R) and F1-score (F1). The met-
rics have been computed as follows:

P =

number of correctly predicted instances
number of predicted labels

(1)

(2)

(3)

R =

number of correctly predicted labels
number of labels in the gold standard

F 1 =

2 ∗ P ∗ R
P + R

Acc =

number of correctly predicted instances
total number of instances

(4)
The results of our participation in the subtask
A of hatEval task during the evaluation phase can
be seen in Table 2 for Spanish and in Table 3 for
English.

In relation to Spanish results, it should be noted
that we achieve a high position in the ranking out-
performing the baseline result. Our position in the
ranking is 14th of 41 participating teams. There-
fore, we consider that the chosen individual classi-
ﬁers in the voting system are appropriate to build
the metaclassiﬁer.

Therefore, our chosen statistic feature for the
text classiﬁcation was the term frequency (TF) tak-
ing into account unigrams and bigrams because it
provided the best perfomance. One important fea-
ture to consider is the use of bigrams in TF, be-
cause during the pre-evaluation phase we noted
that our results outperformed when we took into
account the bigrams comparing it only to the uni-
grams.

In relation to English results, using the same
system as for Spanish we achieved worse results
and we did not outperform the baseline. However,
we are ranked 40th out of 71 participating teams.

5 Conclusions

In this paper, we present the system we devel-
oped for our participation in SemEval-2019 Task
5: Multilingual Detection of Hate Speech Against
Immigrants and Women in Twitter (hatEval). Spe-
cially, we have participated in subtask A in Span-
ish and English.

Our system was developed focus on Spanish.
Therefore, we achieve better results in this lan-
guage. On the one hand, one of the reasons could
be the different employment of misogynistic or
xenophobic words in one language with respect to
the other (Can´os, 2018). For example, the word
“puta” in Spanish, can be consider a misogynis-
tic word or in a bigram like “puta madre” can be
similar to the word “fantastic”. On the other hand,
the way to insult women is not the same as the
way to insult immigrants. For these reasons, sys-
tems make mistakes and should be considered dif-
ferent systems for these targets (immigrants and
women).

Another important issue is that the participation
in Spanish subtask is lower than the participation
in English subtask. For this reason, we will con-
tinue developing systems in Spanish since it is one
of the most spoken languages in the world and we
consider a very challenging task.

Acknowledgments

This work has been partially supported by Fondo
Europeo de Desarrollo Regional (FEDER) and
REDES project (TIN2015-65136-C2-1-R) from
the Spanish Government.

References

Valerio Basile, Cristina Bosco, Elisabetta Fersini, Deb-
ora Nozza, Viviana Patti, Francisco Rangel, Paolo
Rosso, and Manuela Sanguinetti. 2019. Semeval-
2019 task 5: Multilingual detection of hate speech
In Pro-
against immigrants and women in twitter.
ceedings of the 13th International Workshop on Se-
mantic Evaluation (SemEval-2019). Association for
Computational Linguistics.

Jose Sebasti´an Can´os. 2018. Misogyny identiﬁcation

through svm at ibereval 2018.

Karmen Erjavec and Melita Poler Kovaˇciˇc. 2012. “you
don’t understand, this is a new war!” analysis of hate
speech in news web sites’ comments. Mass Commu-
nication and Society, 15(6):899–920.

Elisabetta Fersini, Debora Nozza, and Paolo Rosso.
2018a. Overview of the evalita 2018 task on au-
tomatic misogyny identiﬁcation (ami). Proceed-
ings of the 6th evaluation campaign of Natural
Language Processing and Speech tools for Italian
(EVALITA18), Turin, Italy. CEUR. org.

Elisabetta Fersini, Paolo Rosso, and Maria Anzovino.
2018b. Overview of the task on automatic misogyny
identiﬁcation at ibereval 2018.

Paula Fortuna and S´ergio Nunes. 2018. A survey on
automatic detection of hate speech in text. ACM
Computing Surveys (CSUR), 51(4):85.

Kate Manne. 2017. Down girl: The logic of misogyny.

Oxford University Press.

Rodrigo Moraes, Jo˜aO Francisco Valiati, and Wilson
P Gavi˜aO Neto. 2013. Document-level sentiment
classiﬁcation: An empirical comparison between
svm and ann. Expert Systems with Applications,
40(2):621–633.

Fabian Pedregosa, Ga¨el Varoquaux, Alexandre Gram-
fort, Vincent Michel, Bertrand Thirion, Olivier
Grisel, Mathieu Blondel, Peter Prettenhofer, Ron
Weiss, Vincent Dubourg, et al. 2011. Scikit-learn:
Journal of machine
Machine learning in python.
learning research, 12(Oct):2825–2830.

Manuela Sanguinetti, Fabio Poletto, Cristina Bosco,
Viviana Patti, and Stranisci Marco. 2018. An ital-
ian twitter corpus of hate speech against immigrants.
In Language Resources and Evaluation Conference-
LREC 2018, pages 1–8. ELRA.

Mikalai Tsytsarau and Themis Palpanas. 2012. Survey
on mining subjective data on the web. Data Mining
and Knowledge Discovery, 24(3):478–514.

Zeerak Waseem and Dirk Hovy. 2016. Hateful sym-
bols or hateful people? predictive features for hate
In Proceedings of the
speech detection on twitter.
NAACL student research workshop, pages 88–93.

