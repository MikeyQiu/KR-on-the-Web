7
1
0
2
 
l
u
J
 
9
1
 
 
]

M
Q
.
o
i
b
-
q
[
 
 
1
v
7
1
0
6
0
.
7
0
7
1
:
v
i
X
r
a

EnzyNet: enzyme classiﬁcation using 3D convolutional neural
networks on spatial representation

Afshine Amidi1,2, Shervine Amidi2, Dimitrios Vlachakis3, Vasileios Megalooikonomou3,
Nikos Paragios2, and Evangelia I. Zacharaki2,3

1Massachusetts Institute of Technology, Cambridge, United States of America
2Center for Visual Computing, Department of Applied Mathematics, ´Ecole centrale Paris,
CentraleSup´elec, Chˆatenay-Malabry, France
3MDAKM Group, Department of Computer Engineering and Informatics, University of
Patras, Patras, Greece

July 20, 2017

Abstract

During the past decade, with the signiﬁcant progress of computational power as well as
ever-rising data availability, deep learning techniques became increasingly popular due to their
excellent performance on computer vision problems. The size of the Protein Data Bank has
increased more than 15 fold since 1999, which enabled the expansion of models that aim at pre-
dicting enzymatic function via their amino acid composition. Amino acid sequence however is
less conserved in nature than protein structure and therefore considered a less reliable predictor
of protein function. This paper presents EnzyNet, a novel 3D-convolutional neural networks
classiﬁer that predicts the Enzyme Commission number of enzymes based only on their voxel-
based spatial structure. The spatial distribution of biochemical properties was also examined
as complementary information. The 2-layer architecture was investigated on a large dataset of
63,558 enzymes from the Protein Data Bank and achieved an accuracy of 78.4% by exploit-
ing only the binary representation of the protein shape. Code and datasets are available at
https://github.com/shervinea/enzynet.

Introduction

The exponential growth of the number of enzymes registered in the Protein Data Bank urges a need
to propose a fast and reliable procedure to classify every new entry into one of the six standardized
enzyme classes denoted by the Enzyme Classiﬁcation number (EC): Oxidoreductase (EC1), Trans-
ferase (EC2), Hydrolase (EC3), Lyase (EC4), Isomerase (EC5), and Ligase (EC6). Previous work
included the use of traditional machine learning techniques requiring a tedious and crucial feature
extraction step based on amino-acid sequence alignment [13] or using structural descriptors without
relying on sequence alignment [8]. A limitation in the aforementioned approaches is that the features
have to be predeﬁned, the appropriate choice of features aﬀects the prediction accuracy and there
is limited ﬂexibility for model changes or updates (all preprocessing steps have to be repeated).
These drawbacks are overcome by deep learning techniques that take care of extracting the relevant
features seamlessly from the input.

With the common availability of data and an ever-increasing computing power, deep learning
approaches, such as convolutional neural networks (CNNs), proved to be very eﬃcient and outper-
formed traditional approaches. While CNNs have been used to predict protein properties in [15],
Zacharaki [22] proposed a 2D CNN ensemble to classify enzymes and achieved 90.1% accuracy on
a benchmark of 44,661 enzymes from the PDB database. The protein structure was represented
by multiple 2D feature maps characterizing the backbone conformation (torsion angles) and the

1

(pairwise) amino acids distances. The results showed that the purely structural features (torsion
angles) had limited contribution. This may be related to their global nature coming from the 2D
representation, which fails to characterize the local 3D shape.

Recently, architectures directly dealing with 3D structures were tested on various datasets. Mat-
[16] presented a 3D convolutional neural network approach and benchmarked it on
urana et al.
traditional datasets (LiDAR, RGBD, CAD) beating traditional approaches. Hegde et al. [10] pre-
sented two diﬀerent representations of the 3D data representation: one via voxels, and the other one
via projected 2D pixel images.

Materials and methods

Dataset

The dataset used in this study has been retrieved from the RCSB Protein Data Bank1, which
contained 63,558 enzymes in mid-March of 2017. It has been randomly split in training and testing
set with the proportions 80%/20%. Also, 20% of the training set has been put aside for validation
and was later used for model selection. The details of each of those sets have been summed up in
Table 1.

EC1

7,096

1,775

2,323

EC2

EC3 EC4 EC5 EC6 Total

12,081 15,290 2,875 1,703 1,632 40,677

training

2,935

3,717

3,809

4,762

743

858

488

571

419

481

10,169 validation

12,712

testing

11,194 18,733 23,861 4,476 2,762 2,532 63,558

total

Table 1: Structure of the dataset

Occupancy grid

This paper aims at building a model that seamlessly extracts relevant shape features from raw 3D
structures.

For this purpose, enzymes are represented as a binary volumetric shape with volume elements
(voxels) ﬁtted in a cube V of a ﬁxed grid size l with respect to the three dimensions. Continuity
1]]3
between the voxels is achieved by nearest neighbor interpolation, such that for (i, j, k)
a voxel of vertices

[[0; l

−

∈

(i + δx, j + δy, k + δz)

(δx, δy, δz)

|

0, 1

3

}

∈ {

takes the value 1 if the backbone of the enzyme passes through the voxel, and 0 otherwise.

To construct this shape representation, some preprocessing steps are necessary. First, protein
structure is mapped to a grid of predeﬁned resolution. The selection of grid resolution determines
the level of complexity/scale retained for the enzymatic structures. A full resolution is not preferred
due to high data dimensionality and because ﬁne local details are less relevant in characterizing
enzymes’ chemical reactions. Thus, in order to avoid to get trapped into local minima, side chains
are ignored and enzymes are represented exclusively through their ‘backbone’ atoms that are carbon,
nitrogen and calcium.

Additionally, we note that enzymes do not possess any absolute spatial orientation. Unlike
objects such as chairs or boats that appear usually with a speciﬁc orientation, proteins can have any
orientation in 3D conformational space, thus the Cartesian coordinates deﬁned by the model stored
in PDB represent only a frozen in space and time snapshot of an overall highly dynamic structural

1Website (http://www.rcsb.org/)

2

diversity. The orientation is irrelevant to the properties of the protein. This observation underlines
the need of either a rotation invariant representation or of a convention that makes output structures
comparable one to another based on the deﬁnition of an intrinsic coordinate system. We deﬁne as
origin of this intrinsic coordinate system the consensus barycenter of the protein as it is deﬁned by
taking into account only the four atoms of the backbone for each residue, and as axes the principal
directions of each enzyme calculated by principal component analysis. Each structure is rotated
around its center and the three principal directions of the enzyme aligned with the three axes of the
Cartesian coordinate system. Instead of deﬁning a common reference frame and aligning the objects
before building the prediction model, other works [4] [10] [16] applied rotations around relevant axes
for data augmentation. We decided to spatially normalize the data instead of arbitrarily augmenting
them (by random rotations) because the number of samples is already big enough and an adequate
sampling of all possible orientations would lead to an extremely large dataset diﬃcult to handle.
However, similarly to these works the deﬁnition of orientation includes uncertainties about the
direction (left-right, bottom-up), which we tackled also by data augmentation.

Another critical part of the process is to determine how the enzymes should be ﬁt in their
volumes, as those can be of all types of shapes and sizes. Should we scale enzymes separately to make
them ﬁt in their respective volumes? Or on the contrary, should we scale all enzymes in a uniform
manner? We choose to select the second option because of two reasons. First, doing otherwise
would lead enzymes to be represented at diﬀerent resolutions. Second, biological considerations
invite us to make the convolutional network aware of the size diﬀerence between samples, as those
may be an implicit feature regarding class determination. We already know that our source ﬁles
provide the coordinates of the enzymes at a same scale. After all, proteins are comprised of various
combinations of equally sized amino acids. This scaling issue is therefore equivalent to determining
a maximum radius Rmax so that the atom occupancy information contained in the sphere centered
on the barycenter of the enzyme and of radius Rmax ﬁts into V . This situation is illustrated in
Figure 1.

Figure 1: Illustration of the meaning of Rmax with respect to volume V

Rmax has to be large enough so that a suﬃcient number of enzymes ﬁt the most of their volume
inside V . Conversely, it also has to be small enough so that most enzymes are represented at a
satisfactory resolution.
As a result, a homothetic transformation with center S and ratio λ deﬁned by

S center of V

and

λ =

(1)

(cid:22) l

(cid:23)
1

2 −

×

1
Rmax

is performed on all enzymes to scale them to the desired size.

When l is low, the grid is coarse enough so that the voxels of the structure have a contiguous
shape. Conversely, big volumes tend to separate voxels, which engender ‘holes’.
In that case,
consecutive backbone atoms ( (cid:126)Ai, (cid:126)Ai+1) are interpolated by p regularly spaced new points computed
by

×
p + 1
where k varies from 1 to p. The latter parameter is determined empirically beforehand on enzymes
of the training set.

−

×

(2)

(p

k + 1)

(cid:126)Ai + k

(cid:126)Ai+1

3

A last preprocessing step is to remove potential outliers from the volume. This is done by

eliminating voxels that do not have any immediate neighbor.

(a) l = 32

(b) l = 64

(c) l = 96

Figure 2: Illustration of enzyme 2Q3Z for diﬀerent sizes of grid

The illustration of the output volume obtained for diﬀerent grid sizes has been provided in Figure 2.

Data augmentation

As noted earlier, diﬀerences in spatial orientation had to be considered so that volumes can be
comparable one to another.

Keeping the orientation constant, we perform data augmentation by applying transformations
that preserve the principal components along the three axes, i.e. ﬂips and combination of ﬂips. The
number of possible transformations applicable to each protein is 23

1.

−

Architecture

32

We considered shallow architectures in order to develop a framework that can be trained with
common computational means. A grid search of conﬁgurations has been conducted on the training
input volumes of size
set and led us to consider the 2-layer architecture presented in Figure 3:
9 with stride 2. Then,
32
a second convolutional layer of 64 ﬁlters of size 5
5 with stride 1 is used, followed by a max-
pooling layer of size 2
2 with stride 2. Finally, there are two fully connected layers of 128 and
2
6 (the number of classes) hidden units respectively, concluded by a softmax layer that outputs class
probabilities.

32 ﬁrst go through a convolutional layer of 32 ﬁlters of size 9

×

×

×

×

×

×

×

×

9

5

Several components of the VoxNet architecture [16] have also been investigated in our network.
Leaky ReLU with parameter α = 0.1 is used as activation layer after each convolutional layer. The
L2 regularization technique of strength λ = 0.001 is applied on the network’s layers. Overﬁtting is
also tackled using dropout throughout the network.

All in all, this model contains 804, 614 distinct parameters (including biases), which is approxi-

mately 13% less than for the VoxNet architecture [16].
Additionally, the Adam optimizer has been chosen for its computational eﬃciency and low need of
hyper-parameter tuning [12].

The categorical cross entropy is used as loss function, since the latter can be adapted to multiclass
classiﬁcation. Two approaches are considered for computing this loss. The ﬁrst one assesses misclas-
siﬁcation error irrespectively of individual class sizes, whereas the second one takes class imbalance
into account and uses customized penalization weights for each class. In this second approach, the
aim is to compensate the lack of training samples in under-represented classes by providing a greater
penalization to the loss in the event of misclassiﬁcation than for larger classes.
The cross entropy loss is given by

=

L

−

(cid:88)

6
(cid:88)

x∈set

i = 1

wi

δx,i

·

·

log((cid:98)px,i)

4

(3)

Figure 3: Drawing of the architecture selected for our experiments

where (cid:98)px,i is the predicted probability of enzyme x belonging to class ECi, δx,i the quantity equal
to 1 only if enzyme x belongs to class ECi, and wi the weight associated to class ECi. For the
ﬁrst approach, all weights wi are taken equal to 1. For the weighted approach, we chose weights
according to the formula

max
j∈[[1;6]]

wi =

#(ECj training enzymes)

#(ECi training enzymes)

(4)

which increases the contribution of the under-represented classes by an amount inversely proportional
to their size and in respect to the largest class.

Among the various multi-class metrics that have been studied in [19], we selected the most repre-
sentative to assess the model’s performance. The metrics are based on the confusion matrix whose
elements C(i, j) with i, j
[[1, 6]] indicate the number of enzymes that belong to class ECi and are
predicted as belonging to class ECj:

∈

Accuracy which captures the average per-class eﬀectiveness of the classiﬁer:

Accuracy =

6
(cid:88)

i=1
6
(cid:88)

i,j=1

C(i, i)

C(i, j)

Precision, recall and F1 score which are calculated per class ECi:

PrecisionECi =

RecallECi =

C(i, i)
6
(cid:88)

C(i, j)

j=1

F1ECi = 2

PrecisionECi
RecallECi
PrecisionECi + RecallECi

×

×

C(i, i)
6
(cid:88)

C(j, i)

j=1

5

Metrics

•

•

For each class, precision gives us an idea of the proportion of correctly classiﬁed enzymes
among enzymes that have been classiﬁed in that class, while recall highlights the proportion
of correctly classiﬁed enzymes among enzymes that actually belong to that class.

•

Macro precision, recall and F1 score which express average performance over the 6 enzyme
classes:

PrecisionM =

PrecisionECi

RecallM =

RecallECi

1
6

6
(cid:88)

i=1

1
6

6
(cid:88)

i=1

F1M = 2

PrecisionM
RecallM
PrecisionM + RecallM

×

×

Final decision rule

Several approaches are considered for determining an enzyme’s ﬁnal class.

•

•

•

The ﬁrst strategy is to make the prediction based on the model of the 3D shape without any
transformation.

In the second approach, the 23
1 possible combinations of ﬂipped volumes are generated
and introduced to the classiﬁer. The ﬁnal prediction is either the class of maximum total
probability (probability-based decision) or the class selected by majority voting (class-based
decision)

−

The third strategy is also based on fusion of decisions produced for each ﬂipped volume, but
this one weights each decision by a diﬀerent coeﬃcient, such as
δx+δy+δz+1 , which highlights
transformations with the least number of ﬂips.

1

Hyperparameter selection

Radius Rmax and interpolation parameter p

A crucial point in the presented approach is to make a cogent selection of Rmax. As previously
discussed, this parameter controls the trade-oﬀ between the level of information (l) retained in each
volume and the resolution with which they are conveyed (Rmax). Figure 4 shows the analysis of the
dataset from these two perspectives. The graph on the left helps us assess the minimum radius for
which a decent amount of enzymes will be totally included in the volume, whereas the graph on the
right highlights the quantity of information retained by each radius.
In details, from Figure 4a we can see that the majority of enzymes can ﬁt in a sphere with radius
between 25 and 75 ˚A, with a peak around 35 ˚A. In Figure 4b, each point (x, y) on a curve of radius
R shows the percentage y of training enzymes that have at least x points included within radius R
around their respective enzyme barycenter. Based on both graphs, we select a value of Rmax = 40,
that is big enough to capture more than half of enzymes in V , but small enough so that the smallest
enzymes have radii of at least half of Rmax.

Empirical observations show that a grid of l = 32 does not require any atom interpolation.
Therefore, p is set to zero for our computations.For denser grids, e.g. with grid size l = 64 or 96,
appropriate p values were p = 5 and p = 9, respectively.

Random selection of transformations and samples

Regarding data augmentation, the probability of enzyme ﬂip along each axis has been set to 2
10 .
That way for each enzyme, higher numbers of ﬂips have a lower probability of happening. Also
for each pass, approximately half randomly selected enzymes are to be augmented by ﬂips (or a
combination of ﬂips). This process is useful, as it will help us obtaining a robust classiﬁer.

6

(a) Histogram of the radii of training enzymes

(b) Level of information conveyed for each radius

Figure 4: Analysis of the radii distribution on the training set

Results

We trained the model with and without weights adjustment in the loss function. The evolution of
performance with increasing number of epochs is shown in Figure 5. It can be seen that the training
accuracy is almost stabilized after 200 epochs. Thus the learnt weights at 200 epochs were used for
the ﬁnal prediction model during testing. A higher number of epochs is possible to overﬁt the data.

(a) Uniform weights

(b) Adjusted weights

Figure 5: Evolution of various indicators during training process

The testing results are shown in Table 2.

Overall, the model that performs best in terms of both macro accuracy (78.4%) and macro F1
(74.6%) is the one with uniform weights using no data augmentation.

Precision per class on under-represented classes (EC4, 5, 6) is far better on uniformly weighted
models compared to adapted models, with best scores being 97.1%, 97.5% and 97.3%, versus 83.9%,
58.2% and 30.1% respectively. Over-represented classes (EC2, 3) have roughly the same performance
in those two types of model.

It is worth noting that by augmenting the data, the precision per class is noticeably improved on
under-represented classes (EC4, 5, 6) in both uniform and adapted models. In fact, in the uniformly
weighted framework, the best data augmented models achieve 97.1%, 97.5% and 97.3% versus 92.8%
91.8% and 80.7% for the non-augmented one for EC4, 5, 6 respectively. Similarly, in the adapted
framework, they achieve 83.9%, 58.2% and 30.1% versus 69.3%, 46.7% and 27.1% for EC4, 5, 6
respectively.

7

Weights
Decision
Augmentation
Accuracy

Precision

Uniform

Adapted

None

Probabilities
Flips W. ﬂips Flips W. ﬂips

Classes

EC

0.784 0.761

0.781
1 0.846 0.908 0.910
0.750
2 0.757 0.735
3 0.755 0.705
0.729
4 0.928 0.969 0.971
0.970
5 0.918 0.972
0.968
6 0.807 0.951
Macro 0.835 0.873 0.883
1 0.765 0.710
0.740
2 0.798 0.787 0.807
3 0.872 0.897 0.901
0.586
4 0.659 0.541
0.459
5 0.546 0.426
0.310
6 0.407 0.243
0.634
Macro 0.675 0.601
1 0.804 0.797 0.816
2 0.777 0.760 0.778
3 0.809 0.790
0.806
4 0.770 0.694
0.731
5 0.685 0.592
0.623
6 0.541 0.387
0.469
Macro 0.746 0.712
0.738

EC

EC

0.756
0.863
0.715
0.720
0.953
0.975
0.973
0.866
0.724
0.805
0.870
0.516
0.408
0.229
0.592
0.787
0.757
0.788
0.670
0.575
0.370
0.703

0.775
0.892
0.752
0.725
0.958
0.952
0.942
0.870
0.737
0.800
0.896
0.584
0.454
0.306
0.629
0.807
0.775
0.801
0.726
0.614
0.462
0.730

None

Classes

Probabilities
Flips W. ﬂips Flips W. ﬂips
0.714
0.707
0.791
0.766
0.773
0.774
0.791 0.755
0.825
0.693
0.571
0.467
0.286
0.271
0.667
0.627
0.719
0.743
0.644
0.654
0.737
0.774
0.717 0.685
0.680
0.687
0.655 0.730
0.706
0.698
0.753
0.754
0.703
0.709
0.764
0.763
0.749
0.705
0.623
0.554
0.411
0.383
0.686
0.660

0.722
0.708
0.729
0.773
0.719
0.800
0.786 0.753
0.777
0.778
0.764
0.769
0.789
0.839
0.829
0.566
0.579
0.582
0.295
0.301
0.298
0.663
0.659
0.677
0.743
0.740
0.744
0.662
0.653
0.670
0.767
0.751
0.778
0.703
0.676
0.704
0.662 0.695
0.687
0.709
0.721
0.669
0.717 0.692
0.713
0.758
0.729
0.771
0.715
0.699
0.724
0.772
0.757
0.774
0.744
0.749
0.761
0.624
0.618
0.630
0.417
0.415
0.422
0.687
0.675
0.697

Recall

F1

Table 2: Testing results

Recall per class on over-represented classes (EC2, 3) are best using uniformly weighted models,
with 80.7% and 90.1% respectively.
It is worth noting that adapted models outperform uniform
ones on under-represented classes (EC4, 5, 6) with 71.7%, 69.5%, 73.0% recall per class respectively,
compared to 65.9%, 54.6% and 40.7% respectively on uniform models.

Uniformly weighted models perform best in terms of F1 scores, ranging from 54.1% for the

smallest class (EC6) to 81.6% for EC1, with a macro F1 of 74.6%.

Computation time

Our architecture was implemented on Python 3 using Keras [6] on top of a GPU-enabled version of
TensorFlow [2]. Enzyme information has been extracted using the open-source module BioPython,
a fast and easy-to-use tool presented in [7]. The average prediction time of a single enzyme was
about 6 ms without ﬂips, or 50 ms with ﬂips, on an Intel i7 6700K machine with 32 GB of RAM
and a GTX 1080 graphics card.

Discussion

The general trend is that uniformly weighted models perform well in terms of macro accuracy,
macro precision in respect to macro F1 while adapted models are slightly better in macro recall.
More particularly, on under-represented classes (EC4, 5, 6), models perform better in terms of
precision per class when using ﬂip data augmentation, which means that using data augmentation
increases reliability on predictions. This can be explained by the fact that the classiﬁer has more

8

examples at hand, which makes its predictions more robust.
Interestingly, on under-represented
classes, uniform models have the highest precision per class and the lowest recall per class while
adapted models are exactly the opposite: they have the lowest precision per class and the highest
recall per class. The interpretation of this clear trend is that enzymes coming from under-represented
classes are not always recognized by uniform classiﬁers as they are biased towards enzymes from
over-represented class because the classiﬁer does not correct for class imbalance. On the contrary,
enzymes from under-represented classes are well recognized by adapted classiﬁers as they account
for class imbalance, but this comes at a price: by predicting more enzymes as being in those under-
represented classes (false positives), the classiﬁer tends to make a lot more mistakes which leads to
a low precision per class.

Further improvements of the method

In a parallel we investigated possible improvements in the architecture. We introduced batch nor-
malization [1] at several positions of the network and repeated the same experiments as before.
Those were placed after every activation layer, as suggested in [17]. Also, Leaky ReLU activation
layers were replaced by PReLU [9] layers which enable the network to learn adaptively the Leaky
ReLU’s best α parameter. Although these changes led the network to converge faster to a stable
optimum, the ﬁnal performance increase was only marginal and came at a higher computational
cost.

In the following, we considered the transition from a binary representation capturing only shape
information to ”gray-level” representation capturing also information content. Several biological
indicators such as the hydropathy index [14], or isoelectric points [20] can be used to better describe
local properties of amino-acids that are the building blocks of the protein structure. From the
perspective of computational analysis, these attributes can be incorporated into the representation
model by attaching to the shape also appearance information. Figure 6 illustrates this idea showing
the volumetric representation of two diﬀerent attributes (hydropathy on the left and charge on the
right). The diﬀerent attributes, if up to 3, can also be merged into a single structure visualized in
color (RGB) scale. Diﬀerent approaches to handle multi-channel volumetric data (images) by CNNs
have recently been presented [23] [5] [11] [18]. The literature however on the use of deep networks for
3D shapes with multi-channel appearance is limited. As preliminary analysis, we applied EnzyNet
without modiﬁcation on the architecture, but with re-training for the adjustments of the weights of
the convolutional kernels. We introduced to the network either a single attribute (as a binary 3D
image or gray-level 3D image), such as shape, hydropathy and isoelectric points, or a combination
of these diﬀerent attributes. Two other ways of information combination were examined, either
each attribute was introduced as a diﬀerent channel in the convolutional neural network, or the
outputs of the single channel networks were combined through a fusion rule. However, all methods
showed an increase of the order of magnitude of one percent. Further investigation will be required
to appropriately harness this added information.

Furthermore, in the current study a relatively small grid size was selected due to computational
limitations. However, as can be seen in Figure 2 the details of the spatial structure of proteins can be
better diﬀerentiated for higher values of l. The next step of this work would be to adapt the current
architecture accordingly into a similar network that processes higher-resolution volumes. This could
enable the network to capture more subtle features and potentially boost the performance of the
classiﬁer.

Wei et al. [21] present a method that enables 3D convolutional neural nets to deal with multi-
label classiﬁcation problems. This approach is interesting for us as it allows the extension of our
method to the classiﬁcation of multi-label enzymes. The obtained performance could subsequently
be compared to previous work [3].

Other approaches based on the 3D representation of enzymes are also possible. Brock et al. [4]
performed very well on the ModelNet dataset using generative and discriminative modeling. Their
voxel-based autoencoder is helpful for assessing the key features that are correctly learned from
the 3D shapes. We could elaborate this information in order to identify signiﬁcant features in a

9

(a) Hydropathy

(b) Charge

Figure 6: Illustration of several attributes incorporated into the shape model for enzyme 2Q3Z.
Each attribute is illustrated in color for better visualization, but it actually corresponds to a single
channel.

pre-training phase aiming to obtain better prediction performance.

References

[1] 32nd International Conference on Machine Learning. Batch Normalization: Accelerating Deep

Network Training by Reducing Internal Covariate Shift, volume 37. JMLR, 2015.

[2] Martin Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro,
Greg S. Corrado, Andy Davis, Jeﬀrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Good-
fellow, Andrew Harp, Geoﬀrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz
Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Man´e, Rajat Monga, Sherry Moore, Derek
Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal
Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Vi´egas, Oriol Vinyals,
Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow:
Large-Scale Machine Learning on Heterogeneous Systems. http://tensorflow.org, 2015.

[3] Shervine Amidi, Afshine Amidi, Dimitrios Vlachakis, Nikos Paragios, and Evangelia I Zacharaki.
Automatic single- and multi-label enzymatic function prediction by machine learning. PeerJ,
March 2017.

[4] Andrew Brock, Theodore Lim, J.M. Ritchie, and Nick Weston. Generative and Discriminative

Voxel Modeling with Convolutional Neural Networks. arXiv:1608.04236, 2016.

[5] Lijun Cao, Zhi Liu, Xiaofu He, Yankun Cao, and Ke-ning Li. Mental Disease Feature Extraction
In 2016 IEEE
with MRI by 3D Convolutional Neural Network with Multi-channel Input.
International Conference on Smart Cloud, SmartCloud 2016, New York, NY, USA, November
18-20, 2016, pages 224–227, 2016.

[6] Fran¸cois Chollet. Keras. https://github.com/fchollet/keras, 2015.

[7] Peter J.A. Cock, Tiago Antao, Jeﬀrey T. Chang, Brad A. Chapman, Cymon J. Cox, Andrew
Dalke, Iddo Friedberg, Thomas Hamelryck, Frank Kauﬀ, Bartek Wilczynski, and Michiel J.L.
de Hoon. Biopython: freely available Python tools for computational molecular biology and
bioinformatics. Bioinformatics, 25(11):1422–1423, March 2009.

[8] Paul D. Dobson and Andrew J. Doig. Predicting Enzyme Class From Protein Structure Without

Alignments. Journal of Molecular Biology, pages 187–199, 2005.

[9] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectiﬁers: Sur-
passing human-level performance on imagenet classiﬁcation. In International Conference on
Conference Vision, 2015.

10

[10] Vishakh Hegde and Reza Zadeh. FusionNet: 3D Object Classiﬁcation Using Multiple Data

Representations. arXiv:1607.05695v4, November 2016.

[11] Konstantinos Kamnitsas, Christian Ledig, Virginia F. J. Newcombe, Joanna P. Simpson, An-
drew D. Kane, David K. Menon, Daniel Rueckert, and Ben Glocker. Eﬃcient multi-scale 3D
CNN with fully connected CRF for accurate brain lesion segmentation. Medical Image Analysis,
36:61–78, 2017.

[12] Diederik P. Kingma and Jimmy Lei Ba. Adam: A Method for Stochastic Optimization. In

ICLR, 2015. arXiv:1412.6980v8.

[13] Chetan Kumar and Alok Choudhary. A top-down approach to classify enzyme functional classes
and sub-classes using random forest. EURASIP Journal on Bioinformatics and System Biology,
1(1), February 2012.

[14] Jack Kyte and Russel F. Doolittle. A Simple Method for Displaying the Hydropathic Character

of a Protein. Journal of Molecular Biology, pages 105–132, 1982.

[15] Zeming Lin, Jack Lanchantin, and Yanjun Qi. MUST-CNN: A Multilayer Shift-and-Stitch Deep
Convolutional Architecture for Sequence-based Protein Structure Prediction. In Association for
the Advancement of Artiﬁcial Intelligence, 2016.

[16] Daniel Maturana and Sebastian Scherer. VoxNet: A 3D Convolutional Neural Network for

Real-Time Object Recognition. In IROS, 2015.

[17] Dmytro Mishkin, Nikolay Sergievskiy, and Jiri Matas. Systematic evaluation of cnn advances

on the imagenet. Computer Vision and Image Understanding, 2016.

[18] Dong Nie, Han Zhang, Ehsan Adeli, Luyan Liu, and Dinggang Shen. 3D Deep Learning for
Multi-modal Imaging-Guided Survival Time Prediction of Brain Tumor Patients. In Medical
Image Computing and Computer-Assisted Intervention - MICCAI 2016 - 19th International
Conference, Athens, Greece, October 17-21, 2016, pages 212–220, 2016.

[19] Marina Sokolova and Guy Lapalme. A systematic analysis of performance measures for classi-

ﬁcation tasks. Information Processing and Management, pages 427–437, May 2009.

[20] Leroy G. Wade. Organic Chemistry. Prentice Hall, 2002.

[21] Yunchao Wei, Wei Xia, Junshi Huang, Bingbing Ni, Jian Dong, Yao Zhao, and Shuicheng Yan.
HCP: A Flexible CNN Framework for Multi-Label Image Classiﬁcation. IEEE Transactions on
Pattern Analysis and Machine Intelligence, 38:1901–1907, October 2015.

[22] Evangelia I Zacharaki. Prediction of protein function using a deep convolutional neural network

ensemble. PeerJ, 2017.

[23] Wei Zhang, Lei Han, Juanzhen Sun, Hanyang Guo, and Jie Dai. Application of Multi-
channel 3D-cube Successive Convolution Network for Convective Storm Nowcasting. CoRR,
abs/1702.04517, 2017.

11

7
1
0
2
 
l
u
J
 
9
1
 
 
]

M
Q
.
o
i
b
-
q
[
 
 
1
v
7
1
0
6
0
.
7
0
7
1
:
v
i
X
r
a

EnzyNet: enzyme classiﬁcation using 3D convolutional neural
networks on spatial representation

Afshine Amidi1,2, Shervine Amidi2, Dimitrios Vlachakis3, Vasileios Megalooikonomou3,
Nikos Paragios2, and Evangelia I. Zacharaki2,3

1Massachusetts Institute of Technology, Cambridge, United States of America
2Center for Visual Computing, Department of Applied Mathematics, ´Ecole centrale Paris,
CentraleSup´elec, Chˆatenay-Malabry, France
3MDAKM Group, Department of Computer Engineering and Informatics, University of
Patras, Patras, Greece

July 20, 2017

Abstract

During the past decade, with the signiﬁcant progress of computational power as well as
ever-rising data availability, deep learning techniques became increasingly popular due to their
excellent performance on computer vision problems. The size of the Protein Data Bank has
increased more than 15 fold since 1999, which enabled the expansion of models that aim at pre-
dicting enzymatic function via their amino acid composition. Amino acid sequence however is
less conserved in nature than protein structure and therefore considered a less reliable predictor
of protein function. This paper presents EnzyNet, a novel 3D-convolutional neural networks
classiﬁer that predicts the Enzyme Commission number of enzymes based only on their voxel-
based spatial structure. The spatial distribution of biochemical properties was also examined
as complementary information. The 2-layer architecture was investigated on a large dataset of
63,558 enzymes from the Protein Data Bank and achieved an accuracy of 78.4% by exploit-
ing only the binary representation of the protein shape. Code and datasets are available at
https://github.com/shervinea/enzynet.

Introduction

The exponential growth of the number of enzymes registered in the Protein Data Bank urges a need
to propose a fast and reliable procedure to classify every new entry into one of the six standardized
enzyme classes denoted by the Enzyme Classiﬁcation number (EC): Oxidoreductase (EC1), Trans-
ferase (EC2), Hydrolase (EC3), Lyase (EC4), Isomerase (EC5), and Ligase (EC6). Previous work
included the use of traditional machine learning techniques requiring a tedious and crucial feature
extraction step based on amino-acid sequence alignment [13] or using structural descriptors without
relying on sequence alignment [8]. A limitation in the aforementioned approaches is that the features
have to be predeﬁned, the appropriate choice of features aﬀects the prediction accuracy and there
is limited ﬂexibility for model changes or updates (all preprocessing steps have to be repeated).
These drawbacks are overcome by deep learning techniques that take care of extracting the relevant
features seamlessly from the input.

With the common availability of data and an ever-increasing computing power, deep learning
approaches, such as convolutional neural networks (CNNs), proved to be very eﬃcient and outper-
formed traditional approaches. While CNNs have been used to predict protein properties in [15],
Zacharaki [22] proposed a 2D CNN ensemble to classify enzymes and achieved 90.1% accuracy on
a benchmark of 44,661 enzymes from the PDB database. The protein structure was represented
by multiple 2D feature maps characterizing the backbone conformation (torsion angles) and the

1

(pairwise) amino acids distances. The results showed that the purely structural features (torsion
angles) had limited contribution. This may be related to their global nature coming from the 2D
representation, which fails to characterize the local 3D shape.

Recently, architectures directly dealing with 3D structures were tested on various datasets. Mat-
[16] presented a 3D convolutional neural network approach and benchmarked it on
urana et al.
traditional datasets (LiDAR, RGBD, CAD) beating traditional approaches. Hegde et al. [10] pre-
sented two diﬀerent representations of the 3D data representation: one via voxels, and the other one
via projected 2D pixel images.

Materials and methods

Dataset

The dataset used in this study has been retrieved from the RCSB Protein Data Bank1, which
contained 63,558 enzymes in mid-March of 2017. It has been randomly split in training and testing
set with the proportions 80%/20%. Also, 20% of the training set has been put aside for validation
and was later used for model selection. The details of each of those sets have been summed up in
Table 1.

EC1

7,096

1,775

2,323

EC2

EC3 EC4 EC5 EC6 Total

12,081 15,290 2,875 1,703 1,632 40,677

training

2,935

3,717

3,809

4,762

743

858

488

571

419

481

10,169 validation

12,712

testing

11,194 18,733 23,861 4,476 2,762 2,532 63,558

total

Table 1: Structure of the dataset

Occupancy grid

This paper aims at building a model that seamlessly extracts relevant shape features from raw 3D
structures.

For this purpose, enzymes are represented as a binary volumetric shape with volume elements
(voxels) ﬁtted in a cube V of a ﬁxed grid size l with respect to the three dimensions. Continuity
1]]3
between the voxels is achieved by nearest neighbor interpolation, such that for (i, j, k)
a voxel of vertices

[[0; l

−

∈

(i + δx, j + δy, k + δz)

(δx, δy, δz)

|

0, 1

3

}

∈ {

takes the value 1 if the backbone of the enzyme passes through the voxel, and 0 otherwise.

To construct this shape representation, some preprocessing steps are necessary. First, protein
structure is mapped to a grid of predeﬁned resolution. The selection of grid resolution determines
the level of complexity/scale retained for the enzymatic structures. A full resolution is not preferred
due to high data dimensionality and because ﬁne local details are less relevant in characterizing
enzymes’ chemical reactions. Thus, in order to avoid to get trapped into local minima, side chains
are ignored and enzymes are represented exclusively through their ‘backbone’ atoms that are carbon,
nitrogen and calcium.

Additionally, we note that enzymes do not possess any absolute spatial orientation. Unlike
objects such as chairs or boats that appear usually with a speciﬁc orientation, proteins can have any
orientation in 3D conformational space, thus the Cartesian coordinates deﬁned by the model stored
in PDB represent only a frozen in space and time snapshot of an overall highly dynamic structural

1Website (http://www.rcsb.org/)

2

diversity. The orientation is irrelevant to the properties of the protein. This observation underlines
the need of either a rotation invariant representation or of a convention that makes output structures
comparable one to another based on the deﬁnition of an intrinsic coordinate system. We deﬁne as
origin of this intrinsic coordinate system the consensus barycenter of the protein as it is deﬁned by
taking into account only the four atoms of the backbone for each residue, and as axes the principal
directions of each enzyme calculated by principal component analysis. Each structure is rotated
around its center and the three principal directions of the enzyme aligned with the three axes of the
Cartesian coordinate system. Instead of deﬁning a common reference frame and aligning the objects
before building the prediction model, other works [4] [10] [16] applied rotations around relevant axes
for data augmentation. We decided to spatially normalize the data instead of arbitrarily augmenting
them (by random rotations) because the number of samples is already big enough and an adequate
sampling of all possible orientations would lead to an extremely large dataset diﬃcult to handle.
However, similarly to these works the deﬁnition of orientation includes uncertainties about the
direction (left-right, bottom-up), which we tackled also by data augmentation.

Another critical part of the process is to determine how the enzymes should be ﬁt in their
volumes, as those can be of all types of shapes and sizes. Should we scale enzymes separately to make
them ﬁt in their respective volumes? Or on the contrary, should we scale all enzymes in a uniform
manner? We choose to select the second option because of two reasons. First, doing otherwise
would lead enzymes to be represented at diﬀerent resolutions. Second, biological considerations
invite us to make the convolutional network aware of the size diﬀerence between samples, as those
may be an implicit feature regarding class determination. We already know that our source ﬁles
provide the coordinates of the enzymes at a same scale. After all, proteins are comprised of various
combinations of equally sized amino acids. This scaling issue is therefore equivalent to determining
a maximum radius Rmax so that the atom occupancy information contained in the sphere centered
on the barycenter of the enzyme and of radius Rmax ﬁts into V . This situation is illustrated in
Figure 1.

Figure 1: Illustration of the meaning of Rmax with respect to volume V

Rmax has to be large enough so that a suﬃcient number of enzymes ﬁt the most of their volume
inside V . Conversely, it also has to be small enough so that most enzymes are represented at a
satisfactory resolution.
As a result, a homothetic transformation with center S and ratio λ deﬁned by

S center of V

and

λ =

(1)

(cid:22) l

(cid:23)
1

2 −

×

1
Rmax

is performed on all enzymes to scale them to the desired size.

When l is low, the grid is coarse enough so that the voxels of the structure have a contiguous
shape. Conversely, big volumes tend to separate voxels, which engender ‘holes’.
In that case,
consecutive backbone atoms ( (cid:126)Ai, (cid:126)Ai+1) are interpolated by p regularly spaced new points computed
by

×
p + 1
where k varies from 1 to p. The latter parameter is determined empirically beforehand on enzymes
of the training set.

−

×

(2)

(p

k + 1)

(cid:126)Ai + k

(cid:126)Ai+1

3

A last preprocessing step is to remove potential outliers from the volume. This is done by

eliminating voxels that do not have any immediate neighbor.

(a) l = 32

(b) l = 64

(c) l = 96

Figure 2: Illustration of enzyme 2Q3Z for diﬀerent sizes of grid

The illustration of the output volume obtained for diﬀerent grid sizes has been provided in Figure 2.

Data augmentation

As noted earlier, diﬀerences in spatial orientation had to be considered so that volumes can be
comparable one to another.

Keeping the orientation constant, we perform data augmentation by applying transformations
that preserve the principal components along the three axes, i.e. ﬂips and combination of ﬂips. The
number of possible transformations applicable to each protein is 23

1.

−

Architecture

32

We considered shallow architectures in order to develop a framework that can be trained with
common computational means. A grid search of conﬁgurations has been conducted on the training
input volumes of size
set and led us to consider the 2-layer architecture presented in Figure 3:
9 with stride 2. Then,
32
a second convolutional layer of 64 ﬁlters of size 5
5 with stride 1 is used, followed by a max-
pooling layer of size 2
2 with stride 2. Finally, there are two fully connected layers of 128 and
2
6 (the number of classes) hidden units respectively, concluded by a softmax layer that outputs class
probabilities.

32 ﬁrst go through a convolutional layer of 32 ﬁlters of size 9

×

×

×

×

×

×

×

×

9

5

Several components of the VoxNet architecture [16] have also been investigated in our network.
Leaky ReLU with parameter α = 0.1 is used as activation layer after each convolutional layer. The
L2 regularization technique of strength λ = 0.001 is applied on the network’s layers. Overﬁtting is
also tackled using dropout throughout the network.

All in all, this model contains 804, 614 distinct parameters (including biases), which is approxi-

mately 13% less than for the VoxNet architecture [16].
Additionally, the Adam optimizer has been chosen for its computational eﬃciency and low need of
hyper-parameter tuning [12].

The categorical cross entropy is used as loss function, since the latter can be adapted to multiclass
classiﬁcation. Two approaches are considered for computing this loss. The ﬁrst one assesses misclas-
siﬁcation error irrespectively of individual class sizes, whereas the second one takes class imbalance
into account and uses customized penalization weights for each class. In this second approach, the
aim is to compensate the lack of training samples in under-represented classes by providing a greater
penalization to the loss in the event of misclassiﬁcation than for larger classes.
The cross entropy loss is given by

=

L

−

(cid:88)

6
(cid:88)

x∈set

i = 1

wi

δx,i

·

·

log((cid:98)px,i)

4

(3)

Figure 3: Drawing of the architecture selected for our experiments

where (cid:98)px,i is the predicted probability of enzyme x belonging to class ECi, δx,i the quantity equal
to 1 only if enzyme x belongs to class ECi, and wi the weight associated to class ECi. For the
ﬁrst approach, all weights wi are taken equal to 1. For the weighted approach, we chose weights
according to the formula

max
j∈[[1;6]]

wi =

#(ECj training enzymes)

#(ECi training enzymes)

(4)

which increases the contribution of the under-represented classes by an amount inversely proportional
to their size and in respect to the largest class.

Among the various multi-class metrics that have been studied in [19], we selected the most repre-
sentative to assess the model’s performance. The metrics are based on the confusion matrix whose
elements C(i, j) with i, j
[[1, 6]] indicate the number of enzymes that belong to class ECi and are
predicted as belonging to class ECj:

∈

Accuracy which captures the average per-class eﬀectiveness of the classiﬁer:

Accuracy =

6
(cid:88)

i=1
6
(cid:88)

i,j=1

C(i, i)

C(i, j)

Precision, recall and F1 score which are calculated per class ECi:

PrecisionECi =

RecallECi =

C(i, i)
6
(cid:88)

C(i, j)

j=1

F1ECi = 2

PrecisionECi
RecallECi
PrecisionECi + RecallECi

×

×

C(i, i)
6
(cid:88)

C(j, i)

j=1

5

Metrics

•

•

For each class, precision gives us an idea of the proportion of correctly classiﬁed enzymes
among enzymes that have been classiﬁed in that class, while recall highlights the proportion
of correctly classiﬁed enzymes among enzymes that actually belong to that class.

•

Macro precision, recall and F1 score which express average performance over the 6 enzyme
classes:

PrecisionM =

PrecisionECi

RecallM =

RecallECi

1
6

6
(cid:88)

i=1

1
6

6
(cid:88)

i=1

F1M = 2

PrecisionM
RecallM
PrecisionM + RecallM

×

×

Final decision rule

Several approaches are considered for determining an enzyme’s ﬁnal class.

•

•

•

The ﬁrst strategy is to make the prediction based on the model of the 3D shape without any
transformation.

In the second approach, the 23
1 possible combinations of ﬂipped volumes are generated
and introduced to the classiﬁer. The ﬁnal prediction is either the class of maximum total
probability (probability-based decision) or the class selected by majority voting (class-based
decision)

−

The third strategy is also based on fusion of decisions produced for each ﬂipped volume, but
this one weights each decision by a diﬀerent coeﬃcient, such as
δx+δy+δz+1 , which highlights
transformations with the least number of ﬂips.

1

Hyperparameter selection

Radius Rmax and interpolation parameter p

A crucial point in the presented approach is to make a cogent selection of Rmax. As previously
discussed, this parameter controls the trade-oﬀ between the level of information (l) retained in each
volume and the resolution with which they are conveyed (Rmax). Figure 4 shows the analysis of the
dataset from these two perspectives. The graph on the left helps us assess the minimum radius for
which a decent amount of enzymes will be totally included in the volume, whereas the graph on the
right highlights the quantity of information retained by each radius.
In details, from Figure 4a we can see that the majority of enzymes can ﬁt in a sphere with radius
between 25 and 75 ˚A, with a peak around 35 ˚A. In Figure 4b, each point (x, y) on a curve of radius
R shows the percentage y of training enzymes that have at least x points included within radius R
around their respective enzyme barycenter. Based on both graphs, we select a value of Rmax = 40,
that is big enough to capture more than half of enzymes in V , but small enough so that the smallest
enzymes have radii of at least half of Rmax.

Empirical observations show that a grid of l = 32 does not require any atom interpolation.
Therefore, p is set to zero for our computations.For denser grids, e.g. with grid size l = 64 or 96,
appropriate p values were p = 5 and p = 9, respectively.

Random selection of transformations and samples

Regarding data augmentation, the probability of enzyme ﬂip along each axis has been set to 2
10 .
That way for each enzyme, higher numbers of ﬂips have a lower probability of happening. Also
for each pass, approximately half randomly selected enzymes are to be augmented by ﬂips (or a
combination of ﬂips). This process is useful, as it will help us obtaining a robust classiﬁer.

6

(a) Histogram of the radii of training enzymes

(b) Level of information conveyed for each radius

Figure 4: Analysis of the radii distribution on the training set

Results

We trained the model with and without weights adjustment in the loss function. The evolution of
performance with increasing number of epochs is shown in Figure 5. It can be seen that the training
accuracy is almost stabilized after 200 epochs. Thus the learnt weights at 200 epochs were used for
the ﬁnal prediction model during testing. A higher number of epochs is possible to overﬁt the data.

(a) Uniform weights

(b) Adjusted weights

Figure 5: Evolution of various indicators during training process

The testing results are shown in Table 2.

Overall, the model that performs best in terms of both macro accuracy (78.4%) and macro F1
(74.6%) is the one with uniform weights using no data augmentation.

Precision per class on under-represented classes (EC4, 5, 6) is far better on uniformly weighted
models compared to adapted models, with best scores being 97.1%, 97.5% and 97.3%, versus 83.9%,
58.2% and 30.1% respectively. Over-represented classes (EC2, 3) have roughly the same performance
in those two types of model.

It is worth noting that by augmenting the data, the precision per class is noticeably improved on
under-represented classes (EC4, 5, 6) in both uniform and adapted models. In fact, in the uniformly
weighted framework, the best data augmented models achieve 97.1%, 97.5% and 97.3% versus 92.8%
91.8% and 80.7% for the non-augmented one for EC4, 5, 6 respectively. Similarly, in the adapted
framework, they achieve 83.9%, 58.2% and 30.1% versus 69.3%, 46.7% and 27.1% for EC4, 5, 6
respectively.

7

Weights
Decision
Augmentation
Accuracy

Precision

Uniform

Adapted

None

Probabilities
Flips W. ﬂips Flips W. ﬂips

Classes

EC

0.784 0.761

0.781
1 0.846 0.908 0.910
0.750
2 0.757 0.735
3 0.755 0.705
0.729
4 0.928 0.969 0.971
0.970
5 0.918 0.972
0.968
6 0.807 0.951
Macro 0.835 0.873 0.883
1 0.765 0.710
0.740
2 0.798 0.787 0.807
3 0.872 0.897 0.901
0.586
4 0.659 0.541
0.459
5 0.546 0.426
0.310
6 0.407 0.243
0.634
Macro 0.675 0.601
1 0.804 0.797 0.816
2 0.777 0.760 0.778
3 0.809 0.790
0.806
4 0.770 0.694
0.731
5 0.685 0.592
0.623
6 0.541 0.387
0.469
Macro 0.746 0.712
0.738

EC

EC

0.756
0.863
0.715
0.720
0.953
0.975
0.973
0.866
0.724
0.805
0.870
0.516
0.408
0.229
0.592
0.787
0.757
0.788
0.670
0.575
0.370
0.703

0.775
0.892
0.752
0.725
0.958
0.952
0.942
0.870
0.737
0.800
0.896
0.584
0.454
0.306
0.629
0.807
0.775
0.801
0.726
0.614
0.462
0.730

None

Classes

Probabilities
Flips W. ﬂips Flips W. ﬂips
0.714
0.707
0.791
0.766
0.773
0.774
0.791 0.755
0.825
0.693
0.571
0.467
0.286
0.271
0.667
0.627
0.719
0.743
0.644
0.654
0.737
0.774
0.717 0.685
0.680
0.687
0.655 0.730
0.706
0.698
0.753
0.754
0.703
0.709
0.764
0.763
0.749
0.705
0.623
0.554
0.411
0.383
0.686
0.660

0.722
0.708
0.729
0.773
0.719
0.800
0.786 0.753
0.777
0.778
0.764
0.769
0.789
0.839
0.829
0.566
0.579
0.582
0.295
0.301
0.298
0.663
0.659
0.677
0.743
0.740
0.744
0.662
0.653
0.670
0.767
0.751
0.778
0.703
0.676
0.704
0.662 0.695
0.687
0.709
0.721
0.669
0.717 0.692
0.713
0.758
0.729
0.771
0.715
0.699
0.724
0.772
0.757
0.774
0.744
0.749
0.761
0.624
0.618
0.630
0.417
0.415
0.422
0.687
0.675
0.697

Recall

F1

Table 2: Testing results

Recall per class on over-represented classes (EC2, 3) are best using uniformly weighted models,
with 80.7% and 90.1% respectively.
It is worth noting that adapted models outperform uniform
ones on under-represented classes (EC4, 5, 6) with 71.7%, 69.5%, 73.0% recall per class respectively,
compared to 65.9%, 54.6% and 40.7% respectively on uniform models.

Uniformly weighted models perform best in terms of F1 scores, ranging from 54.1% for the

smallest class (EC6) to 81.6% for EC1, with a macro F1 of 74.6%.

Computation time

Our architecture was implemented on Python 3 using Keras [6] on top of a GPU-enabled version of
TensorFlow [2]. Enzyme information has been extracted using the open-source module BioPython,
a fast and easy-to-use tool presented in [7]. The average prediction time of a single enzyme was
about 6 ms without ﬂips, or 50 ms with ﬂips, on an Intel i7 6700K machine with 32 GB of RAM
and a GTX 1080 graphics card.

Discussion

The general trend is that uniformly weighted models perform well in terms of macro accuracy,
macro precision in respect to macro F1 while adapted models are slightly better in macro recall.
More particularly, on under-represented classes (EC4, 5, 6), models perform better in terms of
precision per class when using ﬂip data augmentation, which means that using data augmentation
increases reliability on predictions. This can be explained by the fact that the classiﬁer has more

8

examples at hand, which makes its predictions more robust.
Interestingly, on under-represented
classes, uniform models have the highest precision per class and the lowest recall per class while
adapted models are exactly the opposite: they have the lowest precision per class and the highest
recall per class. The interpretation of this clear trend is that enzymes coming from under-represented
classes are not always recognized by uniform classiﬁers as they are biased towards enzymes from
over-represented class because the classiﬁer does not correct for class imbalance. On the contrary,
enzymes from under-represented classes are well recognized by adapted classiﬁers as they account
for class imbalance, but this comes at a price: by predicting more enzymes as being in those under-
represented classes (false positives), the classiﬁer tends to make a lot more mistakes which leads to
a low precision per class.

Further improvements of the method

In a parallel we investigated possible improvements in the architecture. We introduced batch nor-
malization [1] at several positions of the network and repeated the same experiments as before.
Those were placed after every activation layer, as suggested in [17]. Also, Leaky ReLU activation
layers were replaced by PReLU [9] layers which enable the network to learn adaptively the Leaky
ReLU’s best α parameter. Although these changes led the network to converge faster to a stable
optimum, the ﬁnal performance increase was only marginal and came at a higher computational
cost.

In the following, we considered the transition from a binary representation capturing only shape
information to ”gray-level” representation capturing also information content. Several biological
indicators such as the hydropathy index [14], or isoelectric points [20] can be used to better describe
local properties of amino-acids that are the building blocks of the protein structure. From the
perspective of computational analysis, these attributes can be incorporated into the representation
model by attaching to the shape also appearance information. Figure 6 illustrates this idea showing
the volumetric representation of two diﬀerent attributes (hydropathy on the left and charge on the
right). The diﬀerent attributes, if up to 3, can also be merged into a single structure visualized in
color (RGB) scale. Diﬀerent approaches to handle multi-channel volumetric data (images) by CNNs
have recently been presented [23] [5] [11] [18]. The literature however on the use of deep networks for
3D shapes with multi-channel appearance is limited. As preliminary analysis, we applied EnzyNet
without modiﬁcation on the architecture, but with re-training for the adjustments of the weights of
the convolutional kernels. We introduced to the network either a single attribute (as a binary 3D
image or gray-level 3D image), such as shape, hydropathy and isoelectric points, or a combination
of these diﬀerent attributes. Two other ways of information combination were examined, either
each attribute was introduced as a diﬀerent channel in the convolutional neural network, or the
outputs of the single channel networks were combined through a fusion rule. However, all methods
showed an increase of the order of magnitude of one percent. Further investigation will be required
to appropriately harness this added information.

Furthermore, in the current study a relatively small grid size was selected due to computational
limitations. However, as can be seen in Figure 2 the details of the spatial structure of proteins can be
better diﬀerentiated for higher values of l. The next step of this work would be to adapt the current
architecture accordingly into a similar network that processes higher-resolution volumes. This could
enable the network to capture more subtle features and potentially boost the performance of the
classiﬁer.

Wei et al. [21] present a method that enables 3D convolutional neural nets to deal with multi-
label classiﬁcation problems. This approach is interesting for us as it allows the extension of our
method to the classiﬁcation of multi-label enzymes. The obtained performance could subsequently
be compared to previous work [3].

Other approaches based on the 3D representation of enzymes are also possible. Brock et al. [4]
performed very well on the ModelNet dataset using generative and discriminative modeling. Their
voxel-based autoencoder is helpful for assessing the key features that are correctly learned from
the 3D shapes. We could elaborate this information in order to identify signiﬁcant features in a

9

(a) Hydropathy

(b) Charge

Figure 6: Illustration of several attributes incorporated into the shape model for enzyme 2Q3Z.
Each attribute is illustrated in color for better visualization, but it actually corresponds to a single
channel.

pre-training phase aiming to obtain better prediction performance.

References

[1] 32nd International Conference on Machine Learning. Batch Normalization: Accelerating Deep

Network Training by Reducing Internal Covariate Shift, volume 37. JMLR, 2015.

[2] Martin Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro,
Greg S. Corrado, Andy Davis, Jeﬀrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Good-
fellow, Andrew Harp, Geoﬀrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz
Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Man´e, Rajat Monga, Sherry Moore, Derek
Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal
Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Vi´egas, Oriol Vinyals,
Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow:
Large-Scale Machine Learning on Heterogeneous Systems. http://tensorflow.org, 2015.

[3] Shervine Amidi, Afshine Amidi, Dimitrios Vlachakis, Nikos Paragios, and Evangelia I Zacharaki.
Automatic single- and multi-label enzymatic function prediction by machine learning. PeerJ,
March 2017.

[4] Andrew Brock, Theodore Lim, J.M. Ritchie, and Nick Weston. Generative and Discriminative

Voxel Modeling with Convolutional Neural Networks. arXiv:1608.04236, 2016.

[5] Lijun Cao, Zhi Liu, Xiaofu He, Yankun Cao, and Ke-ning Li. Mental Disease Feature Extraction
In 2016 IEEE
with MRI by 3D Convolutional Neural Network with Multi-channel Input.
International Conference on Smart Cloud, SmartCloud 2016, New York, NY, USA, November
18-20, 2016, pages 224–227, 2016.

[6] Fran¸cois Chollet. Keras. https://github.com/fchollet/keras, 2015.

[7] Peter J.A. Cock, Tiago Antao, Jeﬀrey T. Chang, Brad A. Chapman, Cymon J. Cox, Andrew
Dalke, Iddo Friedberg, Thomas Hamelryck, Frank Kauﬀ, Bartek Wilczynski, and Michiel J.L.
de Hoon. Biopython: freely available Python tools for computational molecular biology and
bioinformatics. Bioinformatics, 25(11):1422–1423, March 2009.

[8] Paul D. Dobson and Andrew J. Doig. Predicting Enzyme Class From Protein Structure Without

Alignments. Journal of Molecular Biology, pages 187–199, 2005.

[9] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectiﬁers: Sur-
passing human-level performance on imagenet classiﬁcation. In International Conference on
Conference Vision, 2015.

10

[10] Vishakh Hegde and Reza Zadeh. FusionNet: 3D Object Classiﬁcation Using Multiple Data

Representations. arXiv:1607.05695v4, November 2016.

[11] Konstantinos Kamnitsas, Christian Ledig, Virginia F. J. Newcombe, Joanna P. Simpson, An-
drew D. Kane, David K. Menon, Daniel Rueckert, and Ben Glocker. Eﬃcient multi-scale 3D
CNN with fully connected CRF for accurate brain lesion segmentation. Medical Image Analysis,
36:61–78, 2017.

[12] Diederik P. Kingma and Jimmy Lei Ba. Adam: A Method for Stochastic Optimization. In

ICLR, 2015. arXiv:1412.6980v8.

[13] Chetan Kumar and Alok Choudhary. A top-down approach to classify enzyme functional classes
and sub-classes using random forest. EURASIP Journal on Bioinformatics and System Biology,
1(1), February 2012.

[14] Jack Kyte and Russel F. Doolittle. A Simple Method for Displaying the Hydropathic Character

of a Protein. Journal of Molecular Biology, pages 105–132, 1982.

[15] Zeming Lin, Jack Lanchantin, and Yanjun Qi. MUST-CNN: A Multilayer Shift-and-Stitch Deep
Convolutional Architecture for Sequence-based Protein Structure Prediction. In Association for
the Advancement of Artiﬁcial Intelligence, 2016.

[16] Daniel Maturana and Sebastian Scherer. VoxNet: A 3D Convolutional Neural Network for

Real-Time Object Recognition. In IROS, 2015.

[17] Dmytro Mishkin, Nikolay Sergievskiy, and Jiri Matas. Systematic evaluation of cnn advances

on the imagenet. Computer Vision and Image Understanding, 2016.

[18] Dong Nie, Han Zhang, Ehsan Adeli, Luyan Liu, and Dinggang Shen. 3D Deep Learning for
Multi-modal Imaging-Guided Survival Time Prediction of Brain Tumor Patients. In Medical
Image Computing and Computer-Assisted Intervention - MICCAI 2016 - 19th International
Conference, Athens, Greece, October 17-21, 2016, pages 212–220, 2016.

[19] Marina Sokolova and Guy Lapalme. A systematic analysis of performance measures for classi-

ﬁcation tasks. Information Processing and Management, pages 427–437, May 2009.

[20] Leroy G. Wade. Organic Chemistry. Prentice Hall, 2002.

[21] Yunchao Wei, Wei Xia, Junshi Huang, Bingbing Ni, Jian Dong, Yao Zhao, and Shuicheng Yan.
HCP: A Flexible CNN Framework for Multi-Label Image Classiﬁcation. IEEE Transactions on
Pattern Analysis and Machine Intelligence, 38:1901–1907, October 2015.

[22] Evangelia I Zacharaki. Prediction of protein function using a deep convolutional neural network

ensemble. PeerJ, 2017.

[23] Wei Zhang, Lei Han, Juanzhen Sun, Hanyang Guo, and Jie Dai. Application of Multi-
channel 3D-cube Successive Convolution Network for Convective Storm Nowcasting. CoRR,
abs/1702.04517, 2017.

11

