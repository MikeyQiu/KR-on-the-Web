JOURNAL OF LATEX CLASS FILES, VOL. 6, NO. 1, JANUARY 2007

1

An Adaptive Parameter Estimation for Guided Filter
based Image Deconvolution

Hang Yang, Zhongbo Zhang, and Yujing Guan

6
1
0
2
 
p
e
S
 
6
 
 
]

V
C
.
s
c
[
 
 
1
v
0
8
3
1
0
.
9
0
6
1
:
v
i
X
r
a

Abstract—Image deconvolution is still to be a challenging ill-
posed problem for recovering a clear image from a given blurry
image, when the point spread function is known. Although
competitive deconvolution methods are numerically impressive
and approach theoretical limits, they are becoming more complex,
making analysis, and implementation difﬁcult. Furthermore,
accurate estimation of the regularization parameter is not easy for
successfully solving image deconvolution problems. In this paper,
we develop an effective approach for image restoration based on
one explicit image ﬁlter - guided ﬁlter. By applying the decouple of
denoising and deblurring techniques to the deconvolution model,
we reduce the optimization complexity and achieve a simple but
effective algorithm to automatically compute the parameter in
each iteration, which is based on Morozov’s discrepancy principle.
Experimental results demonstrate that the proposed algorithm
outperforms many state-of-the-art deconvolution methods in
terms of both ISNR and visual quality.

Keywords—Image deconvolution, guided ﬁlter, edge-preserving,

adaptive parameter estimation.

I.

INTRODUCTION

I MAGE deconvolution is a classical inverse problem existing

in the ﬁeld of computer vision and image processing[1]. For
instance, the image might be captured during the time when
the camera is moved, in which case the image is corrupted
by motion blur. Image restoration becomes necessary, which
aims at estimating the original scene from the blurred and noisy
observation, and it is one of the most important operations for
future processing.
Mathematically,

the model of degradation processing is
often written as the convolution of the original image with
a low-pass ﬁlter

g = Huorig + γ = h ∗ uorig + γ

(1)

where uorig and g are the clear image and the observed image,
respectively. γ is zero-mean additive white Gaussian noise with
variance σ2. h is the point spread function (PSF) of a linear
time-invariant (LTI) system H, and ∗ denotes convolution.

The inversion of the blurring is an ill-condition problem,
even though the blur kernel h is known, restoring coherent
high frequency image details remains be very difﬁcult[2].

It can broadly divide into two classes of image deconvolu-
tion methods. The ﬁrst class comprises of regularized inversion

This work is supported by the National Science Foundation of China under
Grant 61401425. Hang Yang is with Changchun Institute of Optics, Fine
Mechanics and Physics, Chinese Academy of Science, Changchun 130033,
China. (e-mail:yanghang09@mails.jlu.edu.cn)

Zhongbo Zhang and Yujing Guan are with Jilin University.

(e-

mail:zhongbozhang@jlu.edu.cn,guanyj@jllu.edu.cn)

followed by image denoising, and the second class estimates
the desired image based on a variational optimization problem
with some regularity conditions.

The methods of ﬁrst class apply a regularized inversion of
the blur, followed by a denoising approach. In the ﬁrst step,
the inversion of the blur is performed in Fourier domain. This
makes the image sharper, but also has the effect of amplifying
the noise, as well as creating correlations in the noise[3]. Then,
a powerful denoising method is used to remove leaked noise
and artifacts. Many image denoising algorithms have been
employed for this task: for example, multiresolution transform
the shape adaptive discrete cosine
based method [4], [5],
transform (SA-DCT)[7], the Gaussian scale mixture model
(GSM) [6], and the block matching with 3D-ﬁltering(BM3D)
[8].

The Total variation (TV) model[9], [10], L0-ABS[11], and
SURE-LET[12] belong to the second category. The TV model
the l1-norm of the clear image’s gradient is
assumes that
small. It
is well known for its edge-preserving property.
Many algorithms based on this model have been proposed in
[10],[13],[14]. L0-ABS[11] is a sparsity-based deconvolution
method exploiting a ﬁxed transform. SURE-LET[12] method
uses the minimization of a regularized SURE (Steins unbiased
risk estimate) for designing deblurring method expressed as a
linear expansion of thresholds. It has also shown that edge-
preserving ﬁlter based restoration algorithms can also obtain
good results in Refs [15], [16].

In recent years, the self-similarity and the sparsity of images
are usually integrated to obtain better performance [17], [18],
[19], [20]. In [17], the cost function of image decovolution so-
lution incorporates two regularization terms, which separately
characterize self-similarity and sparsity, to improve the image
quality. A nonlocally centralized sparse representation (NCSR)
method is proposed in [18], it centralizes the sparse coding
coefﬁcients of the blurred image to enhance the performance
of image deconvolution. Low-rank modeling based methods
have also achieved great success in image deconvolution[23],
[24], [25]. Since the property of image nonlocal self-similarity,
similar patches are grouped in a low-rank matrix, then the
matrix completion is performed each patch group to recover
the image.

The computation of the regularization parameter is another
essential
issue in our deconvolution process. By adjusting
regularization parameter, a compromise is achieved to preserve
the nature of the restored image and suppress the noise.
There are many methods to select the regularization parameter
for Tikhonov-regularized problems, however, most algorithms
only ﬁx a predetermined regularization parameter for the whole
restoration procsee[9],[26],[27].

JOURNAL OF LATEX CLASS FILES, VOL. 6, NO. 1, JANUARY 2007

Nevertheless,

in recent works, a few methods focus on
the adaptive parameter selection for the restoration prob-
the parameter is estimated by the trial-and-
lem. Usually,
error approach, for instance, the L-curve method [28], the
majorization-minimization (MM) approach [29],
the gener-
alized cross-validation (GCV) method [30],
the variational
Bayesian approach [31], and Morozov’s discrepancy principle
[32], [33],

In this work 1, we propose an efﬁcient patch less approach to
image deconvolution problem by exploiting guided ﬁlter [37].
Derived from a local linear model, guided ﬁlter generates the
ﬁltering output by considering the content of a guidance image.
We ﬁrst integrate this ﬁlter into an iterative deconvolution al-
gorithm. Our method is consisted by two parts: deblurring and
denoising. In the denoising step, two simple cost functions are
designed, and the solutions of them are one noisier estimated
image and a less noisy one. The former will be ﬁltered as input
image and the latter will work as the guidance image respec-
tively in the denoising step. During the denoising process, the
guided ﬁlter will be utilized to the output of last step to reduce
leaked noise and reﬁne the result of last step. Furthermore, the
regularization parameter plays an important role in our method,
and it is essential for successfully solving ill-posed image
deconvolution problems. We apply the Morozov’s discrepancy
principle to automatically compute regularization parameter
at each iteration. Experiments manifest that our algorithm is
effective on ﬁnding a good regularization parameter, and the
proposed algorithm outperforms many competitive methods in
both ISNR and visual quality.

This paper is organized as follows. A brief overview of the
guided ﬁlter is given in Section II. Section III shows how the
guided ﬁlter is applied to regularize the deconvolution problem
and how the regularization parameter is updated. Simulation
results and the effectiveness of choosing regularization param-
eter are given in Section IV. Finally, a succinct conclusion is
drawn in Section V.

II. GUIDED IMAGE FILTERING

Recently,

the technique for edge-perserving ﬁltering has
been a popular research topic in computer vision and image
processing[34]. Edge-aware ﬁlters such as bilateral ﬁlter [35],
and L0 smooth ﬁlter [36] can suppress noise while preserving
important structures. The guided ﬁlter [37][38] is one of the
fastest algorithms for edge-preserving ﬁlters, and it is easy to
implement. In this paper, the guided ﬁlter is ﬁrst applied for
image deconvolution.

Now, we introduce guided ﬁlter, which involves a ﬁltering
input image up, an ﬁltering output image u and a guidance
image uI . Both uI and up are given beforehand according to
the application, and they can be identical.

The key assumption of the guided ﬁlter is a local linear
model between the guidance uI and the ﬁltering output u. It
assumes that u is a linear transform of uI in a window ωk

1It is the extension and improvement of the preliminary version presented
in ICIP’13 [15]. It is worth mentioning that the work [15] was identiﬁed as
falling within the top 10% of all accepted manuscripts.

2

(2)

(4)

(5)

(6)

centered at the pixel k (the size of ωk is w × w.) :

u(i) = akuI (i) + bk

where (ak, bk) are some linear coefﬁcients assumed to be
constant in ωk.

To compute the linear coefﬁcients (ak, bk), it needs con-
straints from the ﬁltering input p. Speciﬁcally, one can mini-
mize the following cost function in the window ωk

E(ak, bk) =

((akuI (i) + bk − up(i))2 + εa2
k)

(3)

(cid:88)

i∈ωk

Here ε is a regularization parameter penalizing large ak. The
solution of Eq.(3) can be written as:

(cid:80)

1
w2

i∈ωk

ak =

bk = ¯pk − akµk

uI (i)up(i) − µk ¯pk
σ2
k + ε

Here, µk and σk are the mean and variance of uI in ωk, and
¯pk is the mean of up in ωk.

However, a pixel i is involved in all the overlapping win-
dows ωk that cover i, so the value of u(i) in Eq.(2) is not
the same when it is computed in different windows. A native
strategy is to average all the possible values of u(i). So, we
compute the ﬁltering output by:

u(i) = ¯aiuI (i) + ¯bi
ak and ¯bi = 1
w2

(cid:80)

where ¯ai = 1
bk are the
w2
average coefﬁcients of all windows overlapping i. More details
and analysis can be found in [38].

k∈ωk

k∈ωk

(cid:80)

We denote Eq.(6) as u = guidﬁlter(uI , up).

III. ALGORITHM

A. Guided Image Deconvolution

In this proposed method, we plan to restore the blurred im-
age by iteratively Fourier regularization and image smoothing
via guided ﬁlter(GF). Fig. 1 summarizes the main processes
of our image deconvolution method based on guided ﬁltering
(GFD). The proposed algorithm relies on two steps: (1) two
cost functions are proposed to obtain a ﬁltering input image
and a guidance image, (2) a sharp image is estimated using a
guided ﬁltering. We will give the detailed description of these
two steps in this section.

In this work, we minimize the following cost function to

estimate the original image:

(cid:107) g − h ∗ u (cid:107)2 +λ (cid:107) u − GF(z, u) (cid:107)2

(7)

min
u

where GF is the guided ﬁlter smoothing opteration[37], and z
is the guidance image. However, directly solving this problem
is difﬁcult because GF(·, ·) is highly nonlinear. So, we found
that the decouple of deblurring and denoising steps can achieve
a good result in practice.

The deblurring step has the positive effect of localizing
it has the negative effect of introducing

information, but

JOURNAL OF LATEX CLASS FILES, VOL. 6, NO. 1, JANUARY 2007

3

Fig. 1. Schematic diagram of the proposed image deconvolution method.

ringing artifacts. In the deblurring step, to obtain a sharper
image from the observation, we propose two cost functions:

Fourier domain

F(uI ) =

uI = arg min

{λ((cid:107) ∂xu − vx (cid:107)2

2 + (cid:107) ∂yu − vy (cid:107)2
2)

+ (cid:107) h ∗ u − g (cid:107)2
2}

u

u

up = arg min

{λ (cid:107) u − v (cid:107)2

2 + (cid:107) h ∗ u − g (cid:107)2
2}

(8)
(9)

where λ > 0 is the regularization parameter, v, vx and
vy are pre-estimated natural image, partial derivation image
in x direction and partial derivation image in y direction ,
respectively.

Alternatively, we diagonalized derivative operators after Fast
Fourier Transform (FFT) for speedup. It can be solved in the

F(h)∗ · F(g)
| F(h) |2 +λ(| F(∂x)|2 + |F(∂y) |2)
F(∂x)∗ · F(vx) + F(∂y)∗ · F(vy)
| F(h) |2 +λ(| F(∂x)|2 + |F(∂y) |2)

λ

+

(10)

(11)

F(up) =

F(h)∗ · F(g) + λF(v)
| F(h) |2 +λ

where F denotes the FFT operator and F(·)∗ is the com-
plex conjugate. The plus, multiplication, and division are all
component-wise operators.

Solving Eq.(11) yields image up that contains useful high-
frequency structures and a special form of distortions. In the
alternating minimization process, the high-frequency image
details are preserved in the denoising step, while the noise
in up is gradually reduced.

The goal of denoising is to suppress the ampliﬁed noise
and artifacts introduced by Eq.(11), the guided ﬁlter is applied
to smooth the up, and uI is used as the guidance image.
Since the guided ﬁlter has shown promising performance, it has

JOURNAL OF LATEX CLASS FILES, VOL. 6, NO. 1, JANUARY 2007

4

good edge-aware smoothing properties near the edges. Also,
it produces distortion free result by removing the gradient
reversals artifacts. Moreover, the guided ﬁlter considers the
intensity information and texture of neighboring pixels in a
window. In terms of edge-preserving smoothing, it is useful
for removing the artifacts. Therefore in our work, the guided
ﬁlter is integrated to the deconvolution mode and obtain a
reliable sharp image:

v = guidﬁlter(uI , up)

(12)

The ﬁltering output v is used as the pre-estimation image in
Eq.(9).

After the regularized inversion in Fourier domain [see
Eq.(10) and (11)], the image up contains more leaked noise
and texture details than uI . So we use up as the ﬁltering input
image and uI as the guidance image to reduce the leaked noise
and recover some details.

Another problem is how to obtain the pre-estimation image
vx and vy in Eq.(8). The ﬁrst term in Eq.(8) uses image
derivatives for reducing ringing artifacts. The regularization
term (cid:107) ∇u (cid:107) prefers u with smooth gradients, as mentioned in
[26]. A simple method is vx = ∂xv, vy = ∂yv which contains
not only high-contrast edges but also enhanced noises. In this
paper, we remove the noise by using the guided image ﬁlter
again. Then, we compute the vx and vy as follows:

vx = guidﬁlter(∂xv, ∂xv)
vy = guidﬁlter(∂yv, ∂yv)

(13)
(14)

The results can perserve most of the useful information (edges)
and ensure spatial consistency of the images, meanwhile
suppress the enhanced noise.

The guided ﬁlter output is a locally linear transform of the
guidance image. This ﬁlter has the edge-preserving smoothing
property like the bilateral ﬁlter, but does not suffer from the
gradient reversal artifacts. So we integrate the guided ﬁlter into
the deconvolution problem, which leads to a powerful method
that produces high quality results.

Meanwhile, the guided ﬁlter has a fast and non-approximate
linear-time operator, whose computational complexity is only
depend on the size of image. It has an O(N 2) time (in the
number of pixels N 2) exact algorithm for both gray-scale and
color images[37].

We summarize the proposed algorithm as follows :
———————————————————
Step 0: Set k = 0, pre-estimated image vk = vk
Step 1: Iterate on k = 1, 2, ..., iter

x = vk

y = 0.

1.1: Use vk, vk

x and vk

p and the guidance image uk

y to obtain the ﬁltering input
I with Eq.(8) and Eq.(9),

image uk
respectively.

1.2: Apply guided ﬁlter to uk
p with the guidance im-
I with Eq.(12), and obtain a ﬁltered output vk+1 =

age uk
guidﬁlter(uk

I , uk

p) .

1.3: Apply guided ﬁlter to ∂xvk and ∂yvk with Eq.(13)
y , respectively, and k = k + 1.

and Eq.(14) to obtain vk
Step 2: Output viter.
——————————————————-
For initialization, v0 is set to be zero (a black image).

x and vk

B. Choose Regularization Parameter

Note that the Fourier-based regularized inverse operator in
Eq.(12) and (13), and the deblurred images depend greatly
on the regularization parameter λ. In this subsection, we pro-
pose a simple but effective method to estimate the parameter
automatically. It depends only on the data and automatically
computes the regularization parameter according to the data.
The Morozov’s discrepancy principle [39] is useful for the
selection of λ when the noise variance is available. Based on
this principle, for an image of N × N size, a good estimation
of the deconvolution problem should lie in set

S = {u; (cid:107) h ∗ u − g (cid:107)2

2≤ c}

(15)

where c = ρN 2σ2, and ρ is a predetermined parameter.

Indeed, it does not exist uniform criterion for estimating
ρ and it is still a pendent problem deserving further study.
For Tikhonov-regularized algorithms, one feasible approach
for selecting ρ is the equivalent degrees of freedom (EDF)
method[33].

Now, we show how to determine the paremeter λ. By

Parseval’s theorem and Eq.(11)

(cid:107) h ∗ up − g (cid:107)2

2 = (cid:107) λ(F (h)·F (v)−F (g))
|F (h)|2+λ
≤ (cid:107) h ∗ v − g (cid:107)2
2

(cid:107)2
2

(16)

If the pre-estimated image v ∈ S, then up ∈ S, so we set λ =
∞, uI = up = v; else, a proper parameter λ can be computed
as follows: in the case when the additive noise variance is
available, a proper regularization parameter λ is computed such
that the restored image up in Eq.(11) satisﬁes

(cid:107) h∗up −g (cid:107)2

2=(cid:107)

λ(F(h) · F(v) − F(g))
|F(h)|2 + λ

2= ρN 2σ2 (17)
(cid:107)2

One can see that

the right-hand side is monotonically
increasing function in λ, hence we can determine the unique
solution via bisection.

In this paper,

the noise variance σ2 is estimated with
the wavelet transform based median rule [40]. Once σ2 is
available, c = ρN 2σ2 is generally used to compute c. ρ = 1
had been a common choice. From Eq.(17), it is clear that the λ
increases with the increase of ρ. In practice, we ﬁnd that a large
λ (ρ = 1) can substantially cut down the noise variance, but it
often causes a noisy image with ringing artifacts. So, we should
select a smaller λ (ρ < 1) which can achieve an edge-aware
image with less noise. Then, our effective ﬁltering approach
based on guided ﬁlter can be employed in the denoising step.
In our opinion, the parameter ρ should satisfy an important
property: the ρ should decrease with the increase of image
variance. For instance, a smooth image which contains few
high-frequency information can not produce the strong ringing
effects with large ρ, and a large ρ could substantially suppress
the noise. That is to say, the parameter ρ should increase with
the decrease of image variance. According to this property, we
set ρ as following:

ρ =

(cid:26)s2,
s,

thresh > τ
thresh ≤ τ

(18)

JOURNAL OF LATEX CLASS FILES, VOL. 6, NO. 1, JANUARY 2007

5

s = 1 −

(cid:107) g − µ(g) (cid:107)2
(cid:107) g (cid:107)2
2

2 −N 2σ2

(cid:115)

thresh =

(cid:107) g − µ(g) (cid:107)2
2 −N 2σ2
N 2σ2 (cid:107) v − µ(v) (cid:107)2
2

(19)

(20)

where µ(g) and µ(v) denote the mean of g and v, respectively.
This method is simple but practical for computing λ, it
slights adjusting the value of λ according to the variance of g.
thresh shows the ratio of the variance of g and the variance
of v. It means that when v becomes clearer, the variance of
v is larger, and the value of thresh is small. So we should
increase the λ, because the weight of v is large in Eq.(10) and
Eq.(11).

In this work, we suggest setting τ = 0.6 in our experiments
and not adjusting the parameters for different types of images.
We ﬁnd that this parameter choosing approach is robust to the
extent towards the variations of the image size and the image
type. There are some similar strategies in some works dealing
with the constrained TV restoration problem [33].

IV. NUMERICAL RESULTS
In this section, some simulation results are conducted to ver-
ify the performance of our algorithm for image deconvolution
application.

We use the BSNR (blurred signal-to-noise ratio) and the
ISNR (improvement in signal-to-noise-ratio) to evaluate the
quality of the observed and the restored images, respectively.
They are deﬁned as follows:

BSN R = 10 log10 V ar(g)/N 2σ2
(cid:107) uorig − g (cid:107)2
2
(cid:107) uorig − ˆu (cid:107)2
2

ISN R = 10 log10(

)

(21)

(22)

where ˆu is the corresponding restored image.

Two 256 × 256 (Cameraman and House) and two
512×512 (Lena and M an) images shown in Fig. 4 are used
in the experiments.

A. Experiment 1 – Choice of ρ

In the ﬁrst experiment, we explain why a suitable upper
bound c = ρN 2σ2 for the discrepancy principle is more at-
tractive in image deconvolution. In particular, we demonstrate
that the proposed method we derived in Eq.(18) is successful
in ﬁnding the λ automatically.

The test images are Cameraman and Lena. The boxcar
blur (9 × 9) and the Gaussian blur (25 × 25 with std =
1.6) are used in this experiment. There are many previous
methods[11][8] for image deconvolution problem have shown
the ISNR performance for these two point spread funcionts.
We add a Gaussian noise to each blurred image such that
the BSNRs of the observed images are 20, 30, and 40 dB,
respectively.

The changes of ISNR against ρ is shown in Fig.1. The
ISNRs obtained by our choice of given in Eq.(18) are marked
by ” • ” and those obtained by the conventional setting of
ρ = 1 are marked by ”♦”. It is clearly shown that, the ISNRs
obtained by our approach are always close to the maximum.
However, for ρ = 1, its ISNRs are far from the maximum.

Fig. 2.
512),M an(512 × 512).

Cameraman(256 × 256),House(256 × 256),Lena(512 ×

B. Experiment 2 – Comparison with the State-of-the-Art

In this subsection, we compare the proposed algorithm with
ﬁve state-of-the-art methods in standard test settings for image
deconvolution.

Table I describes the different point spread functions (PSFs)
and different variances of white Gaussian additive noise. We
remark that these benchmark experiment settings are com-
monly used in many previous works [11][18].

TABLE I.
EXPERIMENT SETTINGS WITH DIFFERENT BLUR KERNELS
AND DIFFERENT VALUES OF NOISE VARIANCE σ2 FOR PIXEL VALUES IN
[0,255].

Scenario
1
2
3
4
5

PSF
1/(1 + i2 + j2), for i, j = −7, ..., 7
1/(1 + i2 + j2), for i, j = −7, ..., 7
9 × 9 uniform kernel (boxcar)
[1 4 6 4 1]T [1 4 6 4 1]/256
25 × 25 Gaussian with std = 1.6

σ2
2
8
≈ 0.3
49
4

In this section, the proposed GFD algorithm is compared
with ﬁve currently state-of-the-art deconvolution algorithms,
i.e., ForWaRD [4], APE-ADMM [33], L0-ABS [11], SURE-
LET [12], and BM3DDEB [8]. The default parameters by
the authors are applied for the developed algorithms. We
the APE-ADMM [33] is also an adaptive
emphasize that
parameter selection method for total variance deconvolution.
The comparison of our test results for different experiments
against the other ﬁve methods in terms of ISNR are shown in
Table II.

From Table II, we can see that our GFD algorithm achieves
highly competitive performance and outperforms the other
leading deconvolution algorithms in the most cases. The high-
est ISNR results in the experiments are labeled in bold.

One can see that ForWaRD method is less competitive for
cartoon-like images than for these less structured images. The

JOURNAL OF LATEX CLASS FILES, VOL. 6, NO. 1, JANUARY 2007

6

Fig. 3. Parameter ρ versus ISNR for Cameraman and Lena images. The images are blurred by a uniform blur of size 9 × 9(ﬁrst row) and a Gaussian blur
of size 25 × 25 with variance 1.6 (second row). The ISNR values obtained by the proposed method and by ρ = 1 are marked by ”♦” and ” • ”, respectively.

TABLE II.

COMPARISON OF THE OUTPUT ISNR(DB) OF THE PROPOSED DEBLURRING ALGORITHM. BSNR(BLURRED SIGNAL-TO-NOISE RATIO) IS

DEFINED AS BSN R = 10 log10 V ar(y)/N 2σ2, WHERE V ar() IS THE VARIANCE.

Method
BSNR
ForWaRD
APE-ADMM
L0-Abs
SURE-LET
BM3DDEB
GFD

Method
BSNR
ForWaRD
APE-ADMM
L0-Abs
SURE-LET
BM3DDEB
GFD

1

31.87
6.76
7.41
7.70
7.54
8.19
8.38

1

29.89
6.05
6.36
6.66
7.71
7.95
8.12

2

4

Scenario
3
Cameraman (256 × 256)
18.53
40.00
25.85
2.40
7.40
5.08
2.57
8.56
5.24
2.93
9.10
5.55
2.67
7.84
5.22
3.34
8.34
6.40
9.73
3.57
6.52
Scenario
2
4
3
Lena (512 × 512)
40.00
6.97
7.87
7.79
7.96
8.06
8.97

23.87
4.90
4.98
5.71
5.88
6.53
6.65

16.47
2.93
3.52
4.09
4.42
4.81
4.77

5

1

29.19
3.14
3.36
3.49
3.27
3.73
4.02

27.18
3.50
3.61
4.22
4.25
4.37
4.95

29.16
7.35
7.98
8.40
8.71
9.32
9.39

29.72
5.15
5.82
5.74
6.01
6.34
6.29

5

1

15.99
3.19
4.49
4.55
4.35
5.13
5.21

23.14
6.03
6.57
7.12
6.90
8.14
7.75

Scenario
2
4
3
House (256 × 256)
40.00
9.56
10.39
11.06
10.72
10.85
12.02
Scenario
2
4
3
Man (512 × 512)
40.00
6.47
7.14
7.19
6.89
6.99
7.67

23.70
3.87
4.28
4.02
4.32
4.81
4.83

16.32
2.19
2.58
2.61
2.75
3.05
3.11

5

26.61
3.85
4.72
4.80
4.26
4.79
5.39

5

27.02
2.71
2.98
3.00
3.01
3.22
3.50

TV model is substantially outperformed by our method for
complicated images like Cameraman and M an with lots
of disordered features and irregular edges, though it is well-
known for its outstanding performance on regularly-structured
images such as Lena and House.

SURE-LET and L0-ABS achieve higher average ISNR than
ForWaRD and APE-ADMM, while our algorithm outperforms
SURE-LET by 1.25 dB for scenario 3 and outperforms L0-
ABS by 0.84 dB for the scenario 2, respectively. But L0-ABS
cannot obtain top performance with all kinds of images and
degradations without suitable for the image sparse representa-
tion and the mode parameters to the observed image. SURE-

LET approach is applicable for periodic boundary conditions,
and can be used in various practical scenarios. But it also loses
some details in the restored images.

BM3DDEB, which achieves the best performance on av-
erage, One can found that our method and BM3DDEB pro-
duce similar results, and achieve signiﬁcant ISNR improve-
ments over other leading methods. In average, our algorithm
outperforms BM3DDEB by (0.095dB, -0.0325dB, 1.04dB,
0.0825dB, 0.46dB) for the ﬁve settings, respectively. In Figures
4∼7, we show the visual comparisons of the deconvolution
algorithms, from which it can be observed that
the GFD
approach produces sharper and cleaner image edges than other

JOURNAL OF LATEX CLASS FILES, VOL. 6, NO. 1, JANUARY 2007

7

Fig. 4. Visual quality comparison of image deblurring on gray image Cameraman (256×256). (a) original image, (b) noisy and blurred image (scenario 3),
(c) the result of ForWaRD (ISNR=7.40dB), (d) the result of APE-ADMM (ISNR=8.56dB), (e) the result of L0-ABS (ISNR=9.10dB), (f) the result of SURE-LET
(ISNR=7.84dB), (g)BM3DDEB result (ISNR = 8.34dB ), and (h) the result of our method (ISNR = 9.73dB).

ﬁve methods.

From Figure 4, one can evaluate the visual quality of
some restored images. It can be observed that our method
is able to provides sharper image edges and suppress the
ringing artifacts better than BM3DDEB. For House image
(Figure 5), the differences between the various methods are
clearly visible: our algorithm introduces fewer artifacts than
the other methods. In Figure 6, our method achieves good
preservation of regularly-sharp edges and uniform areas, while
for M an image (Figure 7), it preserves the ﬁner details of the
irregularly-sharp edges.

In Figure 8, we plotted a few curves of different λ values
versus iteration number, which were obtained from scenario
1 and 4 using Cameraman image, scenario 2 and 3 using
House image, scenario 2 and 3 using Lena image, scenario
1 and 5 using M an image respectively. Hence, we emphasize
that our approach automatically choose the regularization
parameter at each iteration, unlike some of the other deconvo-
lution algorithms such as [10], one has to manually tune the
parameters, e.g., by running the method many times to choose
the best one by error and trial.

C. Experiment 3 – Convergence

Since the guided image ﬁlter is highly nonlinear,

is
difﬁcult to prove the global convergence of our algorithm in
theory. In this section, we only provide empirical evidence to
show the stability of the proposed deconvolution algorithm.

it

In Figure 9, we show the convergence properties of the GFD
algorithm for test images in the cases of scenario 5 (blur kernel
is 25 × 25 Gaussian with std = 1.6, σ = 2) and scenario

Fig. 9. Change of the ISNR with iterations for the different settings of the
proposed algorithm. Left: deblurring of Cameraman and House images,
scenario 5; Right: deblurring of Lena and M an images, scenario 2.

2 (PSF = 1/(1 + i2 + j2), for i, j = −7, ..., 7, σ =
8)
for four test images. One can see that all the ISNR curves
grow monotonically with the increasing of iteration number,
and ﬁnally become stable and ﬂat. One can also found that 30
iterations are typically sufﬁcient.

√

D. Analysis of Computational Complexity

In this work, all the experiments are performed in Matlab
R2010b on a PC with Intel Core (TM) i5 CPU processor (3.30
GHz), 8.0G memory, and Windows 7 operating system.

In MATLAB simulation, we have obtained times per itera-
tion of 0.057 seconds using 256 × 256 image, and about 30
iterations are enough.

The most computationally-intensive part of our algorithm is
guided image ﬁltering (3 times in one iteration). We mention
that the guided ﬁlter can be simply sped up with subsampling,

JOURNAL OF LATEX CLASS FILES, VOL. 6, NO. 1, JANUARY 2007

8

Fig. 5. Visual quality comparison of image deblurring on gray image House (256×256). (a) original image, (b) noisy and blurred image (scenario 5), (c)
the result of ForWaRD (ISNR=3.85dB), (d) the result of APE-ADMM (ISNR=4.72dB), (e) the result of L0-ABS (ISNR=4.80dB), (f) the result of SURE-LET
(ISNR=4.26dB), (g)BM3DDEB result (ISNR = 4.79dB ), and (h) the result of our method (ISNR = 5.39dB).

Fig. 6. Details of the image deconvolution experiment on image Lena (512×512). (a) original image, (b) noisy and blurred image (scenario 1), (c) the
result of ForWaRD (ISNR=6.05dB), (d) the result of APE-ADMM (ISNR=6.36dB), (e) the result of L0-ABS (ISNR=6.66dB), (f) the result of SURE-LET
(ISNR=7.71dB), (g)BM3DDEB result (ISNR = 7.95dB ), and (h) the result of our method (ISNR = 8.12dB).

and this will lead to a speedup of 10 times with almost no
visible degradation[41].

V. CONCLUSION

We have developed an image deconvolution algorithm based
on an explicit image ﬁlter : guided ﬁlter, which has been

JOURNAL OF LATEX CLASS FILES, VOL. 6, NO. 1, JANUARY 2007

9

Fig. 7. Details of the image deconvolution experiment on image M an (512×512). (a) original image, (b) noisy and blurred image (scenario 3), (c) the
result of ForWaRD (ISNR=6.47dB), (d) the result of APE-ADMM (ISNR=7.14dB), (e) the result of L0-ABS (ISNR=7.19dB), (f) the result of SURE-LET
(ISNR=6.89dB), (g)BM3DDEB result (ISNR = 6.99dB ), and (h) the result of our method (ISNR = 7.67dB).

Fig. 8. Regularization parameter versus iterations number. The Cameraman image is tested by Scenario 1 and 4; The House image is tested by Scenario
2 and 3; The Lena image is tested by Scenario 2 and 3; The M an image is tested by Scenario 1 and 5.

proved to be more effective than the bilateral ﬁlter in several
applications. We ﬁrst introduce guided ﬁlter into the image
restoration problem and propose an efﬁcient method, which
obtains high quality results. The simulation results show that
our method outperforms some existing competitive deconvo-
lution method. We ﬁnd remarkable how such a simple method
compares to other much more sophisticated methods. Based on
Morozov’s discrepancy principle, we also propose a simple but
effective method to automatically determine the regularization
parameter at each iteration.

REFERENCES

[1] P. C. Hansen. Rank-Deﬁcient and Discrete Ill-Posed Problems: Numeri-

cal Aspects of Linear Inversion. Philadelphia, PA: SIAM, 1998.

[2] L. Sun, S. Cho, J. Wang, and J.Hays, ”Good Image Priors for Non-
blind Deconvolution: Generic vs Speciﬁc”, In Proc. of the European
Conference on Computer Vision (ECCV), pp.231-246, 2014.

[3] C. Schuler, H.Burger, S.Harmeling, and B. Scholkopf,”A machine learn-
ing approach for non-blind image deconvolution”, In Proc. of Int. Conf.
Comput. Vision and Pattern Recognition (CVPR) , pp.1067-1074., 2013.

[4] R.Neelamani, H.Choi, and R.G.Baraniuk, ”ForWaRD: Fourier-wavelet

JOURNAL OF LATEX CLASS FILES, VOL. 6, NO. 1, JANUARY 2007

10

[26] T. Goldstein and S. Osher, ”The split Bregman method for L1-
Imag. Sci., vol. 2, no. 2, pp.

regularized problems,” SIAM J.
323C343,2009.

[27] C. Wu and X.-C. Tai, ”Augmented Lagrangian method, dual meth-
ods,and split Bregman iteration for ROF, vectorial TV, and high order
models,” SIAM J. Imag. Sci., vol. 3, no. 3, pp. 300C339, 2010.

[28] P. C. Hansen, ”Analysis of discrete ill-posed problems by means of the

[29]

L-curve,” SIAM Rev., vol. 34, no. 4, pp. 561-580, 1992.
J. M. Bioucas-Dias, M. A. T. Figueiredo, and J. P. Oliveira, ”Adap-
tive total variation image deblurring: A majorizationCminimization ap-
proach,” in Proc. EUSIPCO, Florence, Italy, 2006.

[30] H. Liao, F. Li, and M. K. Ng, ”Selection of regularization parameter
in total variation image restoration,” J. Opt. Soc. Amer. A, Opt., Image
Sci., Vis., vol. 26, no. 11, pp. 2311C2320, Nov. 2009.

[31] S. D. Babacan, R. Molina, and A. K. Katsaggelos, ”Parameter estima-
tion in TV image restoration using variational distribution approxima-
tion,” IEEE Trans. Image Process., vol. 17, no. 3, pp. 326-339, Mar.
2008

[32] Y. W. Wen and R. H. Chan, ”Parameter selection for total-variation
based image restoration using discrepancy principle,” IEEE Trans. Image
Process., vol. 21, no. 4, pp. 1770C1781, Apr. 2012.

[33] C. He, C. Hu, W. Zhang, and B.Shi,”A Fast Adaptive Parameter
Estimation for Total Variation Image Restoration”, IEEE Trans. Image
Process., vol. 23, no. 12, pp. 4954C4967, Dec. 2014.

[34] S.Li, X. Kang, and J. Hu, ”Image Fusion with Guided Filtering”, IEEE
Trans. Image Process., vol. 22, no. 7, pp. 2864-2875, Mar. 2013
[35] C.Tomasi, and R.Manduchi. ”Bilateral ﬁltering for grayand color im-
ages.” In IEEE Int. Conf. Comput. Vision, pp. 839-846. IEEE, 1998.
[36] L.Xu, C.Lu, Y.Xu, and J.Jia. ”Image smoothing via L0 gradient mini-
mization.” In ACM Trans. Graphics vol. 30, pp. 174. ACM, 2011.
[37] K. He, J. Sun, X. Tang: ”Guided image ﬁltering”. In Proc. of the
European Conference on Computer Vision , vol.1, pp.1-14, 2010.
[38] K. He, J. Sun, X. Tang, ”Guided Image Filtering”, IEEE Transactions on
Pattern Analysis and Machine Intelligence, vol.35, no.6, pp.1397-1409,
2013.

[39] S. Anzengruber and R. Ramlau,” Morozovs discrepancy principle for
Tikhonov-type functionals with non-linear operators,” Inverse Problems,
vol.26, pp.1-17, 2010.

[40] S. Mallat, A Wavelet Tour of Signal Processing, 2nd ed. San Diego,

CA, USA: Academic, 1999

[41] K.He, J.Sun, ”Fast Guided Filter.” arXiv preprint arXiv:1505.00996,

2015.

regularized deconvolution for ill-conditioned systems,” IEEE Trans.
Signal Process., vol.52, pp.418-433, Feb. 2004.

[5] Hang Yang, Zhongbo Zhang, ”Fusion of Wave Atom-based Wiener
Shrinkage Filter and Joint Non-local Means Filter for Texture-Preserving
Image Deconvolution” Optical Engineering., vol.51, no.6, 67-75, (Jun.
2012).
J. A. Guerrero-Colon, L. Mancera, and J. Portilla. ”Image restoration
using space-variant Gaussian scale mixtures in overcomplete pyramids.”
IEEE Trans. Image Process., vol.17, no.1, pp.27-41, 2007.

[6]

[7] A. Foi, K.Dabov, V.Katkovnik, and K.Egiazarian. ”Shape-adaptive DCT
for denoising and image reconstruction.” In Soc. Photo-Optical Instru-
mentation Engineers, vol 6064, pp 203-214, 2006.

[8] K. Dabove, A.Foi, V.Katkovnik, and K.Egiazarian. ”Image restoration
by sparse 3D transform-domain collaborative ﬁltering.” In Soc. Photo-
Optical Instrumentation Engineers, vol 6812, pp 6, 2008.

[9] L. Rudin, S. Osher, and E. Fatemi. ”Nonlinear total variation based noise

removal algorithms.” Physica D, vol.60, pp.259-268, 1992.

[10] Y. Wang, J. Yang, W. Yin, and Y. Zhang, ”A new alternating minimiza-
tion algorithm for total variation image reconstruction,” SIAM J.Imag.
Sci., vol.1, pp.248-272, 2008.
J. Portilla. ”Image restoration through l0 analysis-based sparse opti-
mization in tight frames.” In IEEE Int. Conf Image Processing (ICIP),
pp.3909-3912. 2009.

[11]

[12] F. Xue, F.Luisier, and T.Blu. ”Multi-Wiener SURE-LET Deconvolu-

tion.” IEEE Trans. Image Process., vol.22, no.5, pp.1954-1968, 2013.

[13] O.V. Michailovich. ”An Iterative Shrinkage Approach to Total-Variation
Image Restoration.” IEEE Trans. Image Process., vol.20, no.5, pp.1281-
1299, 2011.

[14] M. Ng, P. Weiss, and X. Yuan, ”Solving constrained total-variation
image restoration and reconstruction problems via alternating direction
methods,” SIAM J. Sci. Comput.,vol.32, pp.2710-2736, Aug. 2010.
[15] Hang Yang, Ming Zhu, Zhongbo Zhang, Heyan Huang, ”Guided Filter
based Edge-preserving Image Non-blind Deconvolution”,In Proc. 20th
IEEE International Conference on Image Processing (ICIP), Oral, Mel-
bourne, Austraia, 2013.

[16] Hang Yang, Zhongbo Zhang, Ming Zhu, Heyan Huang, ”Edge-
preserving image deconvolution with nonlocal domain transform”, Optics
and Laser Technology, vol.54, pp.128-136, 2013.

[17] W. Dong, L. Zhang, G. Shi, and X. Wu. ”Image deblurring and super-
resolution by adaptive sparse domain selection and adaptive regulariza-
tion.” IEEE Trans. Image Process., vol.20, no.7, pp.1838-1857, 2011.

[18] W. Dong, L. Zhang, G. Shi, and X. Li. Nonlocally centralized sparse
representation for image restoration. IEEE Trans. Image Process., vol.22,
no.4, pp.1620-1630, 2013.

[19]

[20]

J. Mairal, F. Bach, J. Ponce, G. Sapiro, and A. Zisserman. Non-local
sparse models for image restoration. In IEEE Int. Conf. Comput. Vision,
pp. 2272-2279. IEEE, 2009.

J.Zhang, D.Zhao, W.Gao, ”Group-based sparse representation for image
restoration,” IEEE Transactions on Image Processing, vol.23 ,no.8,
pp.3336-3351, 2014.

[21] K. Dabove, A.Foi, V. Katkovnik, and K. Egiazarian. ”Image restora-
tion by sparse 3D transform-domain collaborative ﬁltering.” Proc SPIE
Electronic Image’08. vol.6812, San Jose, 2008.

[22] R. Rubinstein, A. M. Bruckstein, and M. Elad, ”Dictionaries for sparse
representation modeling,” Proc. IEEE, vol.98, pp.1045-1057,Jun. 2010.
[23] W. Dong, G. Shi, and X. Li. ”Nonlocal image restoration with bilateral
variance estimation: A low-rank approach,” IEEE Trans. Image Process.,
vol.22, no.2, pp.700-711, 2013.

[24] H. Ji, C. Liu, Z. Shen, and Y. Xu. ”Robust video denoising using low
rank matrix completion”. In IEEE Int. Conf. Comput. Vision and Pattern
Recognition, pp. 1791-1798, 2010.

[25] H. Yang, G.S. Hu,Y. Q .Wang and X.T.Wu. ”Low-Rank Approach
for Image Non-blind Deconvolution with Variance Estimation.” SPIE.
Journal of Eletrionic Imaging, vol.24, no.6, pp.1122-1142, 2015.

