Dynamic Matrix Factorization with Priors
on Unknown Values

∗
Robin Devooght

†
Nicolas Kourtellis

Amin Mantrach**

robin.devooght@ulb.ac.be, nicolas.kourtellis@telefonica.com, amantrac@yahoo-inc.com
†Telefonica Research
08019 Barcelona, Spain

**Yahoo Labs
08018 Barcelona, Spain

*IRIDIA, ULB
1050 Brussels, Belgium

5
1
0
2
 
l
u
J
 
3
2
 
 
]
L
M

.
t
a
t
s
[
 
 
1
v
2
5
4
6
0
.
7
0
5
1
:
v
i
X
r
a

ABSTRACT
Advanced and eﬀective collaborative ﬁltering methods based
on explicit feedback assume that unknown ratings do not
follow the same model as the observed ones (not missing at
random). In this work, we build on this assumption, and
introduce a novel dynamic matrix factorization framework
that allows to set an explicit prior on unknown values. When
new ratings, users, or items enter the system, we can update
the factorization in time independent of the size of data
(number of users, items and ratings). Hence, we can quickly
recommend items even to very recent users. We test our
methods on three large datasets, including two very sparse
ones, in static and dynamic conditions.
In each case, we
outrank state-of-the-art matrix factorization methods that
do not use a prior on unknown ratings.

1.

INTRODUCTION

Personalizing the user experience is a continuous growing
challenge for various digital applications. This is of particu-
lar importance when recommending releases on the Netﬂix
platform, when digesting latest Yahoo news, or for helping
users to ﬁnd their next musical obsession.

Among the diﬀerent approaches towards personalization,
matrix factorization ranges among the most popular ones
[12, 30]. In this line of work, data is represented in the form
of a user-item matrix, encoding user-item interactions in the
form of binary or real values. Matrix factorization aims at
decomposing a matrix into latent representations designed
to accurately reconstruct observed interaction values. Most
interestingly, these latent features are also used to predict
missing (or unknown) ratings (i.e.
if item j is exposed to
user i, what would be his rating). However, by trying to
predict the unknown ratings based on a model trained on
the observed ratings, the recommender systems implicitly
assume that the distribution of the observed ratings is rep-
resentative of the distribution of the unknown ones. This is
called the missing at random assumption [17], and it is prob-
ably a wrong asumption in most real-world applications. In
the case of a movie recommender system, for example, users
rate movies that they have seen, and their choices are biased
by their interests.

In this work, building on the not missing at random as-

∗This work was carried out while the author was an intern
at Yahoo Labs, Barcelona.
†This work was carried out while the author was with Yahoo
Labs, Barcelona.

sumption [18, 28] we make the hypothesis that it is more
likely for an unknown item to be weakly rated, this due to
the huge amounts of existing items coupled to the limited
number of items a user may be interested in. This translates
into a strong prior suggesting that unknown ratings should
be reconstructed from latent features as small values (i.e.
close to 0). While this assumption may be wrong for spe-
ciﬁc cases, such constraints act as a good regularizer that
helps in signiﬁcantly improving the recommendations.

Our work is not the ﬁrst to propose new interpretation
of the missing data in a matrix factorization framework
[11, 20, 21, 28]. However, to the best of our knowledge, we
are the ﬁrst to propose an online learning mechanism that
sets an explicit prior on unknown values and this, without
any signiﬁcant additional cost. We introduce a method to
update our model each time a new rating is observed with a
time complexity independent of the size of the data (i.e. the
total number of users, items, and ratings). This fast update
mechanism allows keeping the model up to date when a ﬂow
of new users, items and ratings enters the system.
The contributions of this work are as follows:
• We extend the squared loss, the absolute loss and the
generalized Kullback-Liebler divergence to take into ac-
count an explicit prior on unknown values.

• For each loss function, we derive an eﬃcient online learn-
ing algorithm to update the parameters of the model
with a complexity independent of the data size.

• We validate the hypothesis that applying an explicit prior
on missing ratings improves the recommendations in a
static and in a dynamic setting on three public datasets.
• Our methods are easy to implement and we provide an
open-source implementation of the squared loss and ab-
solute loss.

The rest of this paper is organized as follows. Section 2
summarizes the recommendation problem and Section 3 for-
mulates how to apply priors on unknown values in the con-
text of recommendation. Section 4 extends three loss func-
tions and shows how they can be optimized in a static and
dynamic fashion. Section 5 presents our experimental results
and Section 6 discusses works related to our study. Section 7
concludes this paper.

2. THE RECOMMENDATION PROBLEM

Before addressing the challenge of interpreting missing

data, let us state the standard recommendation problem.

We have at our disposal m items rated by n diﬀerent users,
where the rating given by the ith user to the jth item is

denoted by rij. In many real applications, these ratings take
an integer value between 1 and 5. In this work, we assume
that ratings are positive and that an item rated by user i
with a high numerical value is preferred by this user over
items she ranked with lower numerical values. We denote
by R the set of all known ratings, and by Ri• and R•j the
set of known ratings of user i and item j, respectively. If
rij /∈ R we say that the rating is unknown.

For a while, the objective of recommender systems has
been to predict the value of unknown ratings [12]. It is now
widely accepted that a more practical goal is to correctly
rank the unknown ratings for each user, while the actual
value of the rating is of little interest [1, 5, 15, 20]. This
has led to a change in the way methods are evaluated (in
terms of ranking metrics such as NDCG, AUC or MAP,
instead of rating prediction metrics as measured by RMSE).
We embrace that shift towards ranking, and the purpose of
adding a prior on the unknown ratings is not to improve
matrix factorization techniques in terms of RMSE, but in
terms of ranking metrics.

Matrix factorization methods produce for each user and
each item a vector of k (<< n and m) real values that we
call latent features. We denote by wi the row vector con-
taining the k features of the ith user, and hj the row vector,
composed of k features, associated to the jth item. Also, we
denote by W the n × k matrix whose ith row is wi, and H
as the k × m matrix whose jth column is hT
j . Matrix fac-
torization is presented as an optimization problem, whose
general form is:

(cid:88)

(cid:16)

E

rij, wihT
j

(cid:17)

+ R(W, H)

(1)

arg min
W,H

i,j|rij ∈R

where R is a regularization term (often L1 or L2 norms),
and E measures the error that the latent model makes on
the observed ratings. Most often, E is the squared error.

Using a matrix factorization approach for predicting un-
known ratings relies on the hypothesis that a model ac-
curately predicting observed rating generalizes well to un-
known ratings. In the following section, we argue that the
former hypothesis is easily challenged.

3.

INTERPRETING MISSING DATA

LaunchCast is Yahoo’s former music service, where users
could, among other things, rate songs. In a survey of 2006,
users were asked to rate randomly selected songs [18]. The
distribution of ratings of random songs was then compared
to the distribution of voluntary ratings. The experiment
concluded that the distribution of the ratings for random
songs was strongly dominated by low ratings, while the vol-
untary ratings had a distribution close to uniform [18].

Intuitively, a simple process could explain the results: users
chose to rate songs they listen to, and listen to music they
expect to like, while avoiding genres they dislike. Therefore,
most of the songs that would get a bad rating are not volun-
tary rated by the users. Since people rarely listen to random
songs, or rarely watch random movies, we should expect to
observe in many areas a diﬀerence between the distribution
of ratings for random items and the corresponding distribu-
tion for the items selected by the users. This observation
has a direct impact on the presumed capacity of matrix fac-
torization to generalize a model based on observed ratings
to unknown ratings.

Building on the not missing at random assumption [18,
28], we propose to incorporate in the optimization problem
stated in Equation 1 a prior about the unknown ratings,
in order to limit the bias caused by learning on observed
ratings:

(cid:88)

(cid:16)

E

rij, wihT
j

(cid:17)

arg min
W,H

i,j|rij ∈R

+ α

(cid:88)

(cid:16)

E

ˆr0, wihT
j

(cid:17)

+ R(W, H)

(2)

i,j|rij /∈R

The objective function (Equation 2) has now two parts
(besides the regularization): the ﬁrst part ﬁts the model to
the observed ratings, and the second part drives the model
toward a prior estimate ˆr0 on the unknown ratings. In ab-
sence of further knowledge about a speciﬁc dataset, we sug-
gest to use ˆr0 = 0, the worst rating, as a prior estimate. The
coeﬃcient α allows to balance the inﬂuence of the unknown
ratings, and the original formulation is obtained with α = 0.
We expect α to be small to deal with the problem of class
Indeed, in real-life applications the number of
imbalance.
known ratings |R| is very small in comparison to the num-
ber of unknown ratings (nm − |R|), and if α is close to 1, or
larger, the second term of the objective function will com-
pletely dominate the other parts and drive all the users’ and
items’ features to zero. It is therefore important to ﬁnd a
right balance between the inﬂuence of the few known ratings
and of the many unknown ones.

In order to have a more intuitive feeling of the inﬂu-
ence of both parts of the objective function we introduce
ρ = α(nm − |R|)/|R|, which can be interpreted as an inﬂu-
ence ratio between unknown and known ratings. If ρ = 0,
the unknown ratings are ignored, if ρ = 1, both the known
ratings and the unknown ratings have the same global inﬂu-
ence on the objective function, if ρ = 2, the unknown ratings
are twice as important as the known ratings, etc.

A more involved model could assume an adaptive ρ per
user or item, which could lead to additional, albeit small,
gains. However, this implies more parameters to tune, more
cumbersome equations to explain and an involved process
to prove that the complexity of the method remains the
same. Due to limited space, instead, we provide a general
demonstration of the method and leave the adaptive model
for future work.

4. LOSS FUNCTIONS

An obvious diﬃculty raised by the new optimization prob-
lem introduced earlier is the apparent increase in complexity.
The naive complexity of evaluating this objective function is
O(nmk), while it is O(|R|k) for classical matrix factorization
approaches (Equation 1). In this section, we demonstrate
how it is possible to use our new model without the naive
additional cost, and present a way to perform fast updates
to incorporate new ratings in the model.

To this end, we show the applicability of our method when
E is the squared loss in Section 4.1 and the absolute loss in
Section 4.2. For the sake of demonstration, we also discuss
its applicability on the generalized Kullback-Liebler diver-
gence in Section 4.3. Finally, in Section 4.4 we outline how
the method can be enforced in a static setting, and a dy-
namic setting with continuous updates of new ratings, items
and users.

4.1 Squared Loss

By considering E as the squared loss, and R as the L1

regularization, the optimization problem becomes:

(cid:88)

(cid:16)
rij − wihT
j

(cid:17)2

arg min
W,H

i,j|rij ∈R

+ α

(cid:88)

(cid:16)
wihT
j

(cid:17)2

i,j|rij /∈R
(cid:32) n
(cid:88)

i=1

+ λ

||wi||1 +

||hj||1

(cid:33)

m
(cid:88)

j=1

For the sake of simplicity, let us forget about the regu-
larization term of the objective function for now (adding
it to the following development is trivial), and let us call
L(W, H, R) the objective function without regularization.
We want to be able to update the features of one user or
of one item in a time independent of the size of the dataset
(n, m, |R|). In the remainder, we show that it is possible to
compute ∂L/∂wi and ∂L/∂hj with a complexity linear in
the number of ratings provided by user i (|Ri•|) or given to
item j (|R•j|), respectively. On most datasets, and for most
users and items, we have |Ri•| (cid:28) m and |R•j| (cid:28) n, and,
therefore computing the gradient for one user or one item is
fast.

First, let us separate L in n blocks lw

i that contain only

the terms of L depending on wi:

∂L
∂wi

= −2

(cid:88)

(cid:104)

j|rij ∈R

rij − (1 − α)wihT
j

hj + 2αwiSh

(8)

(cid:105)

Symmetrically, if Sw = (cid:80)

i wT

i wi, we have:

(3)

(cid:88)

(cid:104)

lh
j =

i|rij ∈R

(rij − wihT

j )2 − α(wihT

+ αhjSwhT
j

j )2(cid:105)

(9)

(10)

and:

∂L
∂hj

= −2

(cid:88)

(cid:104)
rij − (1 − α)wihT
j

(cid:105)

wi + 2αhjSw

i|rij ∈R

Assuming that Sw is known, the complexity of computing
j or ∂L/∂hj is now O(|R•j|k + k2), and the complexity of
lh
computing it for every j ∈ {1, . . . , m} is O(|R|k + k2).

4.2 Absolute Loss

A similar development can be done when the squared loss
is replaced by the absolute loss. With the absolute loss, L
becomes:

(cid:88)

L =

(cid:12)
(cid:12)rij − wihT
(cid:12)

j

(cid:12)
(cid:12)
(cid:12) + α

(cid:88)

(cid:12)
(cid:12)wihT
(cid:12)

j

(cid:12)
(cid:12)
(cid:12)

i,j|rij ∈R

i,j|rij /∈R

As with the squared loss, we divide L into lw

i and lh
j .

lw
i =

(cid:88)

(cid:16)

rij − wihT
j

(cid:17)2

+ α

(cid:88)

(cid:16)

(cid:17)2

wihT
j

(4)

j|rij ∈R

j|rij /∈R

lw
i =

(cid:88)

(cid:12)
(cid:12)rij − wihT
(cid:12)

j

(cid:12)
(cid:12)
(cid:12) + α

(cid:88)

(cid:12)
(cid:12)wihT
(cid:12)

j

(cid:12)
(cid:12)
(cid:12)

j|rij ∈R

j|rij /∈R

Notice that we have:

L =

(cid:88)

lw
i

and

i

∂L
∂wi

=

∂lw
i
∂wi

If we adopt a naive computation, the second term of Equa-
tion (4) is more time expensive because most items are not
rated by the user. However, the sum on unknown ratings
(i.e. (cid:80)
j|rij /∈R), can be formulated as the diﬀerence between
the sum on all items (i.e. (cid:80)m
j=1) and the sum on rated items
only (i.e. (cid:80)
j|rij ∈R) . By so doing, the sum on unknown rat-
ings disappears from the computations:

(cid:88)

(cid:16)

wihT
j

(cid:17)2

=

(cid:16)
wihT
j

(cid:17)2

−

(cid:88)

(cid:16)

(cid:17)2

wihT
j

m
(cid:88)

j=1

j|rij /∈R

= wiShwT

i −

j|rij ∈R
(cid:16)

(cid:88)

(cid:17)2

wihT
j

j|rij ∈R

(5)

(6)

where we have posed Sh = (cid:80)

j hj, a k × k matrix inde-
pendent of i (i.e. it is the same matrix for all lw
i ). Assuming
that Sh is known, we can now compute lw
i and ∂L/∂wi with
a complexity of O(|Ri•|k + k2). From Equations 4 and 6,
we obtain:

j hT

As with the squared loss, we will change the expression
of lw
to remove the sum over all unknown ratings, but in
i
this case we have to impose non-negativity of the features
to go further. If W, H ≥ 0, we have (cid:12)
j , and
therefore:

(cid:12)
(cid:12) = wihT

(cid:12)wihT
j

(cid:88)

(cid:12)
(cid:12)wihT
(cid:12)

j

(cid:12)
(cid:12)
(cid:12) =

j|rij /∈R

m
(cid:88)

j=1

wihT

j −

(cid:88)

wihT
j

(11)

= wi

hT
j

−

(cid:88)

wihT
j

(12)

(cid:32) m
(cid:88)

j=1

j|rij ∈R
(cid:33)

j|rij ∈R

Here, instead of Sw and Sh, we will deﬁne sw = (cid:80)n
j=1 hj. We can now express lw

i=1 wi
i and ∂L/∂wi

and sh = (cid:80)m
eﬃciently:

lw
i =

(cid:88)

(cid:16)(cid:12)
(cid:12)rij − wihT
(cid:12)

j

(cid:12)
(cid:12) − αwihT
(cid:12)

j

(cid:17)

+ αwisT
h

(13)

j|rij ∈R

so that:

∂L
∂wi

=

j|rij ∈R

(cid:88)

(cid:16)

(cid:16)

sign

wihT

j − rij

− α

hj + αsT
h

(14)

(cid:17)

(cid:17)

(cid:88)

(cid:104)

lw
i =

j|rij ∈R

(rij − wihT

j )2 − α(wihT

+ αwiShwT
i

j )2(cid:105)

(7)

We can easily derive:

where sign(x) = x/|x| if x (cid:54)= 0, and equals 0 otherwise.
Assuming sh is known, the complexity of computing lw
i or
∂L/∂wi is now O(|Ri•|k). The corresponding expression of
lh
j and ∂L/∂hj is trivial, and the complexity to compute
them is O(|R•j|k).

4.3 Generalized Kullback-Leibler Divergence
For the sake of demonstration on other common loss func-
tions in matrix factorization, we show here the applicability
of the sparsity trick on the generalized Kullback-Liebler di-
vergence (GKL) [14, 16]. We do not elaborate further on
this function in the rest of the paper.

The generalized Kullback-Liebler divergence is deﬁned as

follows:

D(rij||wihT

j ) = rij log(

) − rij + wihT
j

(15)

rij
wihT
j

The GKL is not deﬁned when rij = 0. In the following

we extend the GKL by using its limit value:

D(0||wihT

j ) := lim
r→0

D(r||wihT

j ) = wihT
j

(16)

Using Equation 15 and 16, L becomes:

(cid:33)

(cid:33)

(cid:32)

(cid:88)

L =

i,j|rij ∈R

rij log(

) − rij + wihT
j

+ α

rij
wihT
j

(cid:88)

wihT
j

i,j|rij /∈R

We now follow the same development as with the other

losses. We deﬁne lw
i :

lw
i =

rij log(

) − rij + wihT
j

+ α

(cid:32)

(cid:88)

j|rij ∈R

rij
wihT
j

(cid:88)

wihT
j

j|rij /∈R

In the case of the GKL, the process to remove the sum
on unknown ratings is the same as with the absolute loss,
except that in absence of absolute value we do not have to
impose non-negativity of the features:

(cid:88)

wihT

j = wisT

h −

(cid:88)

wihT
j

(17)

j|rij /∈R

j|rij ∈R

This leads to:

(cid:32)

lw
i =

(cid:88)

j|rij ∈R
+ αwisT
h

rij log(

) − rij + (1 − α)wihT
j

rij
wihT
j

(cid:33)

(18)

Now we can easily derive ∂L/∂wi:

∂L
∂wi

=

(cid:32)

(cid:88)

j|rij ∈R

−

rij
wihT
j

(cid:33)

+ (1 − α)

hj + αsT
h

(19)

The corresponding expression of lh

j and ∂L/∂hj is ob-
tained symmetrically. As with the absolute loss, the com-
plexity of computing lw
i or ∂L/∂wi is now O(|Ri•|k) (it is
O(|R•j|k) for lh

j and ∂L/∂hj).

4.4 Static and Dynamic Factorization

We introduce an online algorithm to learn the latent fac-
tors from the input data in a static setting, and show how
it can accommodate updates in a dynamic setting.

Algorithm 1 Randomized block coordinate descent

Require:

– The ratings R.
– The number of features k.

In the case of a user (i) do

1: Initialize W and H.
2: Compute Sw and Sh (sw and sh)
3: while not converged do
4:
5:
6:
7:
8:
9:
10:
11:
end for
12: end while

In the case of an item (j) do

for all user and item, traversed in a random order do

Perform a gradient step on wi using line search
Update Sw (sw)

Perform a gradient step on hj using line search
Update Sh (sh)

4.4.1

Static Factorization

In order to factorize a whole new set of data we propose
to use a randomized block coordinate descent [26]. At each
iteration, all the users and items are traversed in a random
order. For each of them a gradient step is performed on their
features while keeping the other features constant.

We can use a line search [2] to determine the size of the
gradient step because the variation of L for a modiﬁcation
of wi is entirely determined by lw
i and can therefore be com-
puted eﬃciently. Line search allows to avoid the burden of
tuning the step size, proper to stochastic gradient descent
(SGD) methods [7]. Moreover, using line search guaran-
tees the convergence of the value of the objective function.
Indeed, each gradient step decreases (or rather cannot in-
crease) the objective function which is bounded from below.
This implies that the variation of the objective function con-
verges to zero.

The complete procedure for the factorization through ran-
domized block coordinate descent is summarized in Algo-
rithm 1.

Complexity. In the case of the squared loss, the compu-
tation of fast gradient step relies on knowing Sw and Sh.
Their initial value is computed in O(nk2) and O(mk2), re-
spectively, and the cost of updating them after each gradient
step is O(k2). The total complexity of an iteration of our
algorithm is therefore O(|R|k + (n + m)k2), as good as the
best factorization methods that do not use priors on un-
known ratings [9].

In the case of the absolute loss and generalized Kullback-
Liebler divergence, the computation uses sw and sh. Their
initial value is computed in O(nk) and O(mk), while the
cost of updating them is O(k). The total complexity of one
iteration then becomes O(|R|k + (n + m)k), which is lower
than the squared loss’ complexity. However, this usually
comes at a cost on the performance of the results, as we will
show in the experiments in Section 5.

4.4.2 Fast Updates
The expressions of lw

i , lh

j , and their gradients (Equations
(7), (8), (9) and (10)) allow us to compute the latent repre-
sentations of one user or one item in a time independent of
the number of users and items in the system. We can use
that ability to design a simple algorithm for updating an
existing factorization when a new rating is added to R: If

Algorithm 2 Update algorithm

Require:

– The new rating rij.
– The ratings of user i (Ri•) and of item j (R•j).

1: If wi (hj) does not exist, initialize it (for example by

setting a random feature to 1).

2: Add rij to Ri• and R•j.
3: while not converged do
4:
5: Update Sw (sw)
6:
7: Update Sh (sh)
8: end while

Perform a gradient step on wi using line search

Perform a gradient step on hj using line search

user i rates item j, we iteratively perform gradient steps for
wi and hj, keeping all other features constant. This relies
on the assumption that a new rating will only aﬀect signif-
icantly the user and item that are directly concerned with
it. Although this assumption can be disputed, we will show
in our experiments (Section 5.3) that our update algorithm
produces recommendations of stable quality, indicating that
limiting our updates to the directly aﬀected users and items
does not degrade the factorization over time.

When ratings are produced by new users or given to new
items, a new set of features for that user or item is created
before performing the local optimization. Various initializa-
tion strategies could be explored here. However, as we show
in our experimental results, assigning a random value to one
of the features and setting the others to zero performs well in
practice. The update procedure is summarized in Algorithm
2.
Complexity. As mentioned earlier, our update algorithm
is independent of the number of users or items in the sys-
tem, making it suitable for very large datasets. Each itera-
tion of the update algorithm is composed of two gradient
steps (one on the user’s features, and one on the item’s
features).
In particular, the complexity of one iteration
is O((|Ri•| + |R•j|)k + k2) for the squared loss, and only
O((|Ri•| + |R•j|)k) for the absolute loss and the GKL. This
diﬀerence in complexity becomes signiﬁcant when k is large
with regards to the average number of ratings per user and
per item.

Updates based on classic SGD methods have an even smaller

complexity (O(k))), but we will show in Section 5 that our
method produces recommendations of much higher quality,
while still being able to satisfy applications requiring low-
latency updates.

5. EXPERIMENTS

lowing key points:

We perform several experiments to demonstrate the fol-

• Using priors on the unknown values leads to overall im-
proved quality of ranking, in a static or dynamic setting.
• The quality does not degrade with time, i.e., as more
updates are added, the model does not lose accuracy.
• Our methods can outperform traditional techniques on

various large datasets.

In our experiments, we test the performance of the squared
loss (SL) and the absolute loss (AL) with and without prior
on unknown values. In Section 5.1 we describe our exper-

Table 1: Characteristics of the datasets used.

Dataset

Movielens
FineFoods
AmazonMovies

Users

6,040
256,059
889,176

Items

3,706
74,258
253,059

Ratings

1,000,209
568,454
7,831,442

imental setup: the benchmarked datasets used, the perfor-
mance metrics recorded and how we tune the various param-
eters of the models tested during the experiments. Then, in
Sections 5.2 and 5.3 we describe the results of our methods in
a static and dynamic learning setting, respectively, and how
they compare with state-of-the-art methods. In Section 5.4
we illustrate the importance of fast updates by studying the
impact of having a delay between the arrival of new ratings
and the update of the factorization. In Section 5.5 we inves-
tigate in depth the inﬂuence of parameter values selected in
the two loss functions (squared and absolute loss). Finally,
details allowing the reproducibility of the results are given
in Section 5.6.

5.1 Experimental Setup

Here we brieﬂy describe the experimental setup used for
the static and dynamic learning and how the parameters of
the diﬀerent methods are tuned.

5.1.1 Datasets

During the experiments, we use three datasets with dis-
tinct features. Table 1 summarizes the characteristics of
these datasets which provide diﬀerent challenges to the rec-
ommendation task:

• Movielens: This is the well-known movie ratings dataset
produced by the Grouplens project. We use the version
containing 1 million ratings, with at least 20 ratings for
each user.

• FineFoods: This is a collection of ratings about food
products extracted from the Amazon comments [19]. The
dataset is much sparser than Movielens, with most users
having only a handful of ratings, making it a very hard
dataset for the recommendation task.

• AmazonMovies: This is a larger collection of ratings ex-
tracted from the movie section of Amazon [19]. This
dataset is also sparser than Movielens, although not as
sparse as FineFoods.

5.1.2 Evaluation Metrics

We measure two standards metrics used in ranking evalua-
tion: (1) Normalized Discounted Cumulative Gain (NDCG)
[1, 15] and, (2) area under ROC curve (AUC) [20, 23, 27].

NDCG rewards methods that rank items with the highest
observed rating at the top of the ranking. The discounted
aspect of NDCG comes from the fact that relevant items
ranked at low positions of the ranking contribute less to the
ﬁnal score than relevant items at top positions.

In the static experiments, we also report the NDCG com-
puted on the rated items only. This metric does not con-
sider the real world case scenario which consists of ranking
all items since we do not know in advance which item will be
rated or not. Intuitively, by biasing our objective through
the introduction of priors on unknown rating we may loose
performance when ranking rated items only, while perform-

Table 2: List of the parameters of each method, and set of
values tested during the parameters tuning of the squared
loss (SL) and absolute loss (AL), with and without prior
on unknown values, as well as the multiplicative update al-
gorithm (Mult-NMF), Alternating Least Square (ALS-UV),
and Vowpal Wabbit (VW). k: number of features, λ: regu-
larization coeﬃcient, ρ: unknown/known inﬂuence ratio, γ:
learning rate.

Method

Parameter

Tested Values

SL/AL
with prior

SL/AL with-
out prior

ALS-UV

Mult-NMF

VW

k
λ
ρ

k
λ

k
λ

k

k
λ
γ

5, 10, 20, 50, 100, 200
0, 0.01, 0.1, 1, 10
0.3, 0.7, 1, 2

5, 10, 20, 50, 100, 200
0, 0.01, 0.1, 1, 10

20, 50, 100, 200, 500
0, 0.001, 0.01, 0.05, 0.1

20, 50, 100, 200, 500

20, 50, 100, 200, 500
0 1e-5 1e-2
0.01, 0.02, 0.05, 0.1, 0.2

ing better when considering all the items.

We use AUC to evaluate the ability of the diﬀerent meth-
ods to predict which items are going to be rated. AUC mea-
sures whether the items whose ratings were held out during
learning are ranked higher than unrated items. The perfect
ranking has an AUC of 1, while the average AUC for random
ranking is 0.5.

5.1.3 Parameter Tuning

Table 2 shows the parameters of the various models and
the values tested during parameter tuning. For each test,
the parameters’ values producing the best ranking on the
validation sets (measured by NDCG for the static test and
AUC for the dynamic test) were selected to be used. See
Sections 5.2 and 5.3 for the description of the validation
sets.

5.2 Static Learning

Research question. In a static mode, we test to which ex-
tent using a prior on unknown ratings improves the ranking
of items when recommended to users.

Process followed. The test set was constructed by ran-
domly selecting 1000 users, and splitting the ratings of those
users in half, keeping the ﬁrst 50% of the ratings in the
training set, according to timestamp, and the last 50% in
the test set. The same process (selecting 1000 users and
splitting their ratings) was then applied three times on the
training set in order to create three training/validation pairs
of sets. On each run, the parameters producing on average
the best NDCG over the three validation sets were then used
to factorize the full training set, and evaluated on the test
set.

Baseline. We report the results achieved by two traditional
well-known algorithms: UV matrix decomposition solved
with Alternating Least Square (ALS-UV) [30], and non-
negative matrix factorization with the multiplicative update
algorithm (Mult-NMF) [14]. Both ALS-UV and Mult-NMF

Table 3: Comparison of our introduced algorithm in static
learning on the datasets Movielens, FineFoods and Amazon-
Movies. Values in bold hold for the method that outperform
all the other methods according to a Mann-Withney U test
with a conﬁdence level of 1%. Average values are shown
alongside their standard deviation over 10 runs.

NDCG-RI

AUC

Movielens
NDCG

SL w/ prior
SL w/o prior 0.886 ± 0.0015
0.3597 ± 0.0012
AL w/ prior 0.8683 ± 0.0030 0.4452 ± 0.0009
AL w/o prior 0.8794 ± 0.0031 0.3801 ± 0.0106
0.8433 ± 0.0007 0.3758 ± 0.0006
Mult-NMF
0.8332 ± 0.0014 0.3292 ± 0.0004
ALS-UV

0.885 ± 0.0014 0.5046 ± 0.0013 0.8695 ± 0.0012
0.6548 ± 0.0014
0.8134 ± 0.0011
0.6927 ± 0.0322
0.7011 ± 0.0009
0.5839 ± 0.0005

NDCG-RI

FineFoods
NDCG

AUC

0.887 ± 0.0016 0.1237 ± 0.0039 0.8452 ± 0.0074
0.8314 ± 0.0058
0.8412 ± 0.0047
0.7294 ± 0.0143
0.3403 ± 0.0052
0.5485 ± 0.0114

SL w/ prior
SL w/o prior 0.888 ± 0.0158
0.1023 ± 0.0022
AL w/ prior 0.8722 ± 0.0142 0.1026 ± 0.0030
AL w/o prior 0.8730 ± 0.0260 0.0923 ± 0.0008
0.8476 ± 0.0084 0.0830 ± 0.0008
Mult-NMF
0.0873 ± 0.0009
0.8653 ± 0.025
ALS-UV
AmazonMovies
NDCG
0.8992 ± 0.0101 0.1887 ± 0.0088 0.9276 ± 0.0031
0.8656 ± 0.0033
0.8634 ± 0.0045
0.7625 ± 0.0051
0.6330 ± 0.0040
0.6601 ± 0.0061

SL w/ prior
SL w/o prior 0.9035 ± 0.0089 0.1103 ± 0.0008
AL w/ prior 0.8804 ± 0.0077 0.1348 ± 0.0035
AL w/o prior 0.8854 ± 0.0102 0.1002 ± 0.0012
0.8498 ± 0.0026 0.0959 ± 0.0004
Mult-NMF
0.8658 ± 0.0034 0.0906 ± 0.0003
ALS-UV

NDCG-RI

AUC

use the squared loss.
Results. The results, averaged over 10 runs, are shown in
Table 3. We can observe that for both the squared loss and
the absolute loss, and on all datasets, by adding a prior on
the unknown ratings we improve signiﬁcantly the rankings of
the items recommended to users over rankings obtained by
the same techniques when they do not put a prior on the un-
known ratings (and also over rankings obtained by state-of-
the-art approaches ALS-UV and Mult-NMF). In particular,
our implementation of the squared loss with prior outper-
forms all other methods, as conﬁrmed by a Mann-Withney
U test with a conﬁdence level of 1%.

On the Movielens dataset, the results of Mult-NMF and
ALS-UV are, as expected, similar to the ones of our imple-
mentation of the squared loss without prior. Indeed, those
methods optimize the same objective function, and diﬀer
only by their algorithm. Interestingly, on the sparser Fine-
Foods and AmazonMovies dataset, our randomized block co-
ordinate gradient descend method outperforms Mult-NMF
and ALS-UV, even without prior on the unknown ratings.

Furthermore, in the three tested data sets, when only con-
sidering the rated items, the loss in ranking performance is
never signiﬁcant (see NDCG-RI with and without prior in
Table 3).
In other words, while improving on the global
ranking, the performance does not deteriorate when consid-
ering only the subset of rated items.

5.3 Dynamic Learning

Research question. In this section, we target two research
questions:

1. We test whether our update algorithm is able to sus-
tain stable quality of recommendations over time;

2. We test to which extent using priors on unknown rat-
ings improves the ranking of recommended items when

the model is updated each time a new instance is en-
countered. By so doing, the system is evaluated on
more realistic scenarios where the cases of cold items
and users are considered as well.

Process followed. We order the ratings by timestamps
and separate the ratings in three blocks: ﬁrst the training,
then the validation and ﬁnally the test block (see Table 4
for the size of each block in the diﬀerent datasets).

Table 4: Number of ratings in each block for the dynamic
learning.

Dataset

Training Validation

Test

500,000
Movielens
FineFoods
400,000
AmazonMovies 5,000,000

100,000
100,000

100,000
68,000
1,000,000 1,000,000

The evaluation is performed as follows: an initial model is
built based on all the ratings present before the test block,
then, for each rating of the test block, two steps are per-
formed in the following order:

1. The current model is evaluated by computing the AUC
over the new (user, item) pair. Notice that in this case,
computing the AUC means computing the proportion
of items not yet rated by the user that the model ranks
lower than the item that was just rated. An AUC of 1
means that the new item was the top recommendation
of the method for that user.

2. The model is updated using the new rating. It is worth
noticing that the rating may concern a new user or
item, and, therefore, features for that new user/item
have to be added to the model.

Parameter tuning is done as described above, but starting
at the beginning of the validation block and ending before
the test block. The values of parameters tested are the same
as in the static test (see Table 2).
Baseline. We compared our methods to Vowpal Wabbit
(VW). VW is a machine learning framework solving diﬀer-
ent optimization problems for classiﬁcation and ranking, by
implementing a carefully optimized, stochastic gradient de-
scent (SGD) using feature hashing [29] and adaptive gra-
dient steps [7]. We are using the VW’s implementation of
low-rank interactions1 based on factorization machines [22].
Results. Figure 1 shows how the average AUC evolves as
new ratings enter the system. We ﬁrst observe that the
quality of the results does not decrease over time, indicating
that our update algorithm can work for long periods of time
without propagating or amplifying errors. As in the static
experiment, we conﬁrm that adding a prior on unknown
ratings improves the quality of the ranking and, again, this
is maintained across time. Moreover, the SGD approach of
VW is outranked in each dataset by our approach with prior.

5.4 Impact of delayed updates
Research Question. We test the performance of delayed
models produced by our methods in delivering recommen-
dations to users.
1https://github.com/JohnLangford/vowpal_wabbit/
tree/master/demo/movielens

Figure 1: Performance comparison with respect to average
AUC for the various methods tested in dynamic learning on
Movielens, FineFoods and AmazonMovies. Results are aver-
aged over 20 runs.

Process followed. In order to address this question, we
simulate a recommender system that is not able to incor-
porate new ratings in the model as soon as they enter the
system. To do so, we modify the process of dynamic learn-
ing presented in Section 5.3 to impose a delay between the
arrival of a new rating and the update of the factorization.
More precisely, after the ith rating is given by a user, the
model is updated up to the (i − d)th rating (d being the
arbitrary delay). This way, the model is always d ratings
behind the last one arrived (the ratings are sorted by real
time of arrival). In real applications, the delay would prob-
ably vary, depending on the level of activity of the users.
However, this experiment gives a ﬁrst impression of the im-
pact of delays on the recommendation task.

Results. Figure 2 shows the impact of a delay on the av-
erage AUC of the squared loss and absolute loss with prior
for a dense dataset like Movielens and a sparse dataset like
FineFoods. We observe that even a small delay can aﬀect
the quality of the recommendation, depending on the char-
acteristics of the data. For Movielens, if the model is behind
by 5 − 10 ratings, the average AUC drops by 3%, and it goes
down by about 14% when the model is behind by 1000 rat-
ings, and this applies to both loss functions. On the other
hand, for the much sparser FineFoods, the eﬀect is more ap-
parent. With only 5 − 10 ratings behind, the model’s AUC
already drops by 10%.

To show the eﬀect of fast updates on weakly-engaged (or
cold) users, we also report the impact of delays on those
users for both Movielens and FineFoods with the squared
loss which performs best (Figure 2, Cold Users). We deﬁne
such users as the ones that rated at most two items. As
hypothesized, the cost induced by delayed predictions (for
ﬁve ratings delayed) is higher for cold users. We observe a
relative drop in AUC of 11.8% and 13.4% for weakly-engaged
users on Movielens and FineFoods, respectively, while when
considering all the users, the relative drop is 1.1% and 12.9%,

ble here. The reason may be that the role of regularization is
already taken by the prior on unknown ratings. Introducing
the prior seems to have the side eﬀect of making the regu-
larization obsolete (or redundant). In fact, we conﬁrm this
with the results for λ = 0 which demonstrate no impact on
the quality or runtime. Again, we see that setting a prior on
unknown ratings increases the quality of recommendations
without increasing the complexity of the solution. While it
adds a term and a parameter to the objective function, it
allows to remove one and its associated parameters.

Unknown/known inﬂuence ratio. The ratio ρ inﬂuences
the performance of the squared loss algorithm in the follow-
ing way: the AUC increases when a prior on unknown values
is added (ρ > 0), but the exact value of ρ has little inﬂuence
(in the observed range) (Figure 3(c)). The absolute loss is
more sensitive to the value of ρ, with the AUC decreasing
when ρ becomes too large (on Movielens and AmazonMovies).
However, in both cases, and on all datasets, giving the same
weight to the known and unknown ratings (ρ = 1) oﬀers a
signiﬁcant improvement over not using a prior, suggesting
that ρ = 1 can be used as a ﬁrst guideline, avoiding the
burden of further parameter tuning.

The update runtime is also aﬀected by ρ, decreasing when
ρ increases (Figure 3(f)). The explanation can be that the
prior on unknown ratings acts as a regularizer, driving fea-
tures towards 0, and in doing so speeding up the conver-
gence.

Runtime. In general, our technique demonstrates low run-
ning time which is heavily dependent on the number of fea-
tures used, and less on the regularization applied or the ra-
tio of unknown over known values. These results demon-
strate that our method can satisfy applications requiring
low-latency updates.

5.6 Reproducibility of Results

The implementation of the algorithms introduced in Sec-

tion 4 is available on Github:
https://github.com/rdevooght/MF-with-prior-and-updates.

For both ALS-UV and Mult-NMF we use the implementa-
tion of GraphChi, an open source tool for graph computation
with impressive performance [13].

The code and documentation of Vowpal Wabbit is avail-

able on its Github page:
https://github.com/JohnLangford/vowpal_wabbit/wiki.
The Amazon datasets are available on the SNAP webpage:

http://snap.stanford.edu/data/index.html

The Movielens dataset is available on the Grouplens page:

http://www.grouplens.org/datasets/movielens/.

6. RELATED WORK

The problem of recommending products based on the ac-
tions and feedback from other users (rather than based on
content similarity) is often called collaborative ﬁltering, and
dates back 20 years ago, with works such as Tapestry [10]
and Grouplens [25]. The ﬁeld is now dominated by meth-
ods based on matrix factorization, with algorithms such
as ALS [30], the multiplicative update rule [14], and the
stochastic gradient descent method (SGD) [9, 12].

The missing at random assumption has yet to get the
attention it deserves in collaborative ﬁltering. Both [18]
and [28] have validated the hypothesis of ratings missing
not at random. Practical propositions for the interpretation

Figure 2: Average AUC of the squared loss and absolute
loss with prior on Movielens and FineFoods for various delays
d, imposed as a number of ratings that the model is behind
the current rating.

respectively.

In such sparse scenarios, cold users perform only a handful
of actions before deciding to abandon the site or not. There-
fore, it is important to consider cold users in the model as
soon as they arrive, to keep them engaged by fast, eﬃcient
and good recommendations.

5.5 Parameter Analysis

Research Question. We test to which extent the number
of features (k), the weight of the prior (ρ) and the regular-
ization coeﬃcient (λ) aﬀect the AUC and the runtime per
update on our loss functions.

Figure 3 shows the results of this investigation for diﬀer-
ent values of these parameters, for both squared loss and
absolute loss and on each dataset. The results are obtained
using the dynamic learning process.

Number of features. Concerning the quality of ranking
(AUC), we observe the usual overﬁtting/under-ﬁtting trade-
oﬀ (Figure 3(a)). The optimal number of features depends
on the dataset as well as on the loss function used, suggesting
that a careful tuning of that parameter is always needed.

In some cases, speed constraints will force the use a sub-
optimal number of features.
Indeed, the update runtime
heavily depends on the number of features. Figure 3(d) sug-
gests a linear relationship between runtime and number of
features. For both losses there is indeed a linear role of the
number of features in the theoretical complexity (Section
4.4). Notice, however, that the theoretical complexity of the
squared loss also has a quadratic term that becomes domi-
nant for large number of features (with regards to the num-
ber of ratings per users). Also note that while the squared
loss produces better AUC, the absolute loss is able to sus-
tain higher update rates, and can therefore be the loss of
choice when speed is the ﬁrst criterion.

Regularization coeﬃcient. The inﬂuence of λ seems
rather limited, except for high values that cause both the
AUC and the update runtime to drop (Figure3(b) and (e)).
A small regularization is supposed to increase the quality of
the model by reducing overﬁtting, but this eﬀect is not visi-

Figure 3: Inﬂuence of parameter values on the AUC and runtime for the models produced by the squared loss (SL) and
absolute loss (AL). Y-error bars declare a standard deviation on the average value of each metric.

of missing data can be found in the ﬁelds of one-class collab-
orative ﬁltering and collaborative ﬁltering based on implicit
feedback, where the missing at random assumption is often
obviously untenable [11, 20, 21].
[27] oﬀers an interesting
approach where missing ratings are considered as optimiza-
tion variables; they use an EM algorithm to optimize in
turn the factorization and the estimation of missing values.
Unfortunately, that method has a high complexity, and the
proposed approximations that work with large problems re-
move some of the method’s appeal.

None of those works, however, consider the real world, dy-
namic scenario of continuously observing new ratings, users
and items. Other works [8, 24] focus on the dynamic update
of matrix factorization (mainly through the use of SGD),
but those, on the other hand, implicitly rely on the missing
at random assumption, and therefore suﬀer from lower ac-
curacy in predictions. Other state-of-art methods for matrix
factorization scale by relying on stochastic gradient compu-
tation [3, 4], while we rely on exact gradient approach. In
this work, at the diﬀerence of what is mostly seen on scal-
able machine learning techniques nowadays [6], we base our
approach on coordinate random block descent to compute
exact gradient in order to deal with missing data of large
scale matrices.

7. CONCLUSIONS

In this work we proposed a new, simple, and eﬃcient, way
to incorporate a prior on unknown ratings in several loss
functions commonly used for matrix factorization. We ex-
perimentally demonstrated the importance of adding such a
prior to solve the problem of collaborative ranking. We also

tackled the problem of updating the factorization when new
users, items and ratings enter the system. We believe that
this problem is central to real applications of recommenda-
tion systems, because new users constantly enter those sys-
tems and the factorization must be kept up to date to give
them recommendations immediately after their ﬁrst few in-
teractions with the platform. We oﬀer an update algorithm
whose complexity is independent of the size of the data,
making it a good approach for large datasets. In the future,
we would like to explore how our methods perform under
real workloads of updates with variable arrival rates of rat-
ings per user and item. Furthermore, we would like to test
the performance of our methods in platforms built to ana-
lyze streams of data such as Storm, Twitter’s Distributed
Processing Engines platform.

8. ACKNOWLEDGEMENTS

R. Devooght is supported by the Belgian Fonds pour la
Recherche dans l’Industrie et l’Agriculture (FRIA, 1.E041.14).

References
[1] S. Balakrishnan and S. Chopra. Collaborative ranking.
In Proc. of the 5th ACM WSDM, pages 143–152, 2012.

[2] S. Boyd and L. Vandenberghe. Convex optimization.

Cambridge university press, 2009.

[3] W.-S. Chin, Y. Zhuang, Y.-C. Juan, and C.-J. Lin. A
fast parallel stochastic gradient method for matrix fac-
torization in shared memory systems. ACM Transac-

tions on Intelligent Systems and Technology (TIST),
6(1):2, 2015.

[4] W.-S. Chin, Y. Zhuang, Y.-C. Juan, and C.-J. Lin. A
learning-rate schedule for stochastic gradient methods
to matrix factorization. In Advances in Knowledge Dis-
covery and Data Mining, pages 442–455. Springer, 2015.

[5] P. Cremonesi, Y. Koren, and R. Turrin. Performance
of recommender algorithms on top-n recommendation
tasks. In Proc. of the 4th ACM RecSys, pages 39–46,
2010.

[6] J. Dean, G. Corrado, R. Monga, K. Chen, M. Devin,
M. Mao, A. Senior, P. Tucker, K. Yang, Q. V. Le, et al.
Large scale distributed deep networks.
In Advances
in Neural Information Processing Systems, pages 1223–
1231, 2012.

[7] J. Duchi, E. Hazan, and Y. Singer. Adaptive subgra-
dient methods for online learning and stochastic opti-
mization. The Journal of Machine Learning Research,
12:2121–2159, 2011.

[8] J. Gaillard and J.-M. Renders. Time-sensitive collab-
orative ﬁltering through adaptive matrix completion.
In Advances in Information Retrieval, pages 327–332.
Springer, 2015.

[9] R. Gemulla, E. Nijkamp, P. J. Haas, and Y. Sisma-
nis. Large-scale matrix factorization with distributed
stochastic gradient descent. In Proc. of the 17th ACM
SIGKDD, pages 69–77, 2011.

[10] D. Goldberg, D. Nichols, B. M. Oki, and D. Terry.
Using collaborative ﬁltering to weave an information
tapestry. Communications of the ACM, 35(12):61–70,
1992.

[11] Y. Hu, Y. Koren, and C. Volinsky. Collaborative ﬁlter-
ing for implicit feedback datasets. In Proc. of the 8th
IEEE ICDM, pages 263–272, 2008.

[12] Y. Koren, R. Bell, and C. Volinsky. Matrix factoriza-
tion techniques for recommender systems. Computer,
42(8):30–37, 2009.

[13] A. Kyrola, G. E. Blelloch, and C. Guestrin. Graphchi:
Large-scale graph computation on just a pc. In OSDI,
volume 12, pages 31–46, 2012.

[14] D. D. Lee and H. S. Seung. Algorithms for non-negative
matrix factorization. In Advances in neural information
processing systems, pages 556–562, 2000.

[15] J. Lee, S. Bengio, S. Kim, G. Lebanon, and Y. Singer.
Local collaborative ranking. In Proc. of the 23rd ACM
WWW, pages 85–96, 2014.

[16] C.-J. Lin. Projected gradient methods for nonnegative
matrix factorization. Neural computation, 19(10):2756–
2779, 2007.

[17] R. J. Little and D. B. Rubin. Statistical analysis with

missing data. 2002.

[18] B. Marlin, R. S. Zemel, S. Roweis, and M. Slaney. Col-
laborative ﬁltering and the missing at random assump-
tion. In Proc. of the 23rd Conference on Uncertainty in
Artiﬁcial Intelligence, 2007.

[19] J. McAuley and J. Leskovec. Hidden factors and hidden
topics: understanding rating dimensions with review
text. In Proc. of the 7th ACM RecSys, pages 165–172,
2013.

[20] R. Pan and M. Scholz. Mind the gaps: weighting the
unknown in large-scale one-class collaborative ﬁltering.
In Proc. of the 15th ACM SIGKDD, pages 667–676.
ACM, 2009.

[21] R. Pan, Y. Zhou, B. Cao, N. N. Liu, R. Lukose,
M. Scholz, and Q. Yang. One-class collaborative ﬁl-
tering. In Proc. of the 8th IEEE ICDM, pages 502–511,
2008.

[22] S. Rendle. Factorization machines. In Proc. of ICDM

2010, pages 995–1000, 2010.

[23] S. Rendle, C. Freudenthaler, Z. Gantner,

and
L. Schmidt-Thieme. Bpr: Bayesian personalized rank-
ing from implicit feedback. In Proc. of the 25th Con-
ference on Uncertainty in Artiﬁcial Intelligence, pages
452–461. AUAI Press, 2009.

[24] S. Rendle and L. Schmidt-Thieme. Online-updating
regularized kernel matrix factorization models for large-
scale recommender systems. In Proc. of the 2008 ACM
RecSys, pages 251–258, 2008.

[25] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and
J. Riedl. Grouplens: an open architecture for collabora-
tive ﬁltering of netnews. In Proc. of the 1994 ACM con-
ference on Computer supported cooperative work, pages
175–186, 1994.

[26] P. Richt´arik and M. Tak´aˇc. Iteration complexity of ran-
domized block-coordinate descent methods for minimiz-
ing a composite function. Mathematical Programming,
144(1-2):1–38, 2014.

[27] V. Sindhwani, S. S. Bucak, J. Hu, and A. Mojsilovic.
One-class matrix completion with low-density factor-
izations. In Proc. of the 10th IEEE ICDM, pages 1055–
1060, 2010.

[28] H. Steck. Training and testing of recommender systems
on data missing not at random. In Proc. of the 16th
ACM SIGKDD, pages 713–722. ACM, 2010.

[29] K. Weinberger, A. Dasgupta, J. Langford, A. Smola,
and J. Attenberg. Feature hashing for large scale mul-
titask learning. In Proc. of the 26th ACM ICML, pages
1113–1120. ACM, 2009.

[30] Y. Zhou, D. Wilkinson, R. Schreiber, and R. Pan.
Large-scale parallel collaborative ﬁltering for the net-
ﬂix prize. In Algorithmic Aspects in Information and
Management, pages 337–348. Springer, 2008.

Dynamic Matrix Factorization with Priors
on Unknown Values

∗
Robin Devooght

†
Nicolas Kourtellis

Amin Mantrach**

robin.devooght@ulb.ac.be, nicolas.kourtellis@telefonica.com, amantrac@yahoo-inc.com
†Telefonica Research
08019 Barcelona, Spain

**Yahoo Labs
08018 Barcelona, Spain

*IRIDIA, ULB
1050 Brussels, Belgium

5
1
0
2
 
l
u
J
 
3
2
 
 
]
L
M

.
t
a
t
s
[
 
 
1
v
2
5
4
6
0
.
7
0
5
1
:
v
i
X
r
a

ABSTRACT
Advanced and eﬀective collaborative ﬁltering methods based
on explicit feedback assume that unknown ratings do not
follow the same model as the observed ones (not missing at
random). In this work, we build on this assumption, and
introduce a novel dynamic matrix factorization framework
that allows to set an explicit prior on unknown values. When
new ratings, users, or items enter the system, we can update
the factorization in time independent of the size of data
(number of users, items and ratings). Hence, we can quickly
recommend items even to very recent users. We test our
methods on three large datasets, including two very sparse
ones, in static and dynamic conditions.
In each case, we
outrank state-of-the-art matrix factorization methods that
do not use a prior on unknown ratings.

1.

INTRODUCTION

Personalizing the user experience is a continuous growing
challenge for various digital applications. This is of particu-
lar importance when recommending releases on the Netﬂix
platform, when digesting latest Yahoo news, or for helping
users to ﬁnd their next musical obsession.

Among the diﬀerent approaches towards personalization,
matrix factorization ranges among the most popular ones
[12, 30]. In this line of work, data is represented in the form
of a user-item matrix, encoding user-item interactions in the
form of binary or real values. Matrix factorization aims at
decomposing a matrix into latent representations designed
to accurately reconstruct observed interaction values. Most
interestingly, these latent features are also used to predict
missing (or unknown) ratings (i.e.
if item j is exposed to
user i, what would be his rating). However, by trying to
predict the unknown ratings based on a model trained on
the observed ratings, the recommender systems implicitly
assume that the distribution of the observed ratings is rep-
resentative of the distribution of the unknown ones. This is
called the missing at random assumption [17], and it is prob-
ably a wrong asumption in most real-world applications. In
the case of a movie recommender system, for example, users
rate movies that they have seen, and their choices are biased
by their interests.

In this work, building on the not missing at random as-

∗This work was carried out while the author was an intern
at Yahoo Labs, Barcelona.
†This work was carried out while the author was with Yahoo
Labs, Barcelona.

sumption [18, 28] we make the hypothesis that it is more
likely for an unknown item to be weakly rated, this due to
the huge amounts of existing items coupled to the limited
number of items a user may be interested in. This translates
into a strong prior suggesting that unknown ratings should
be reconstructed from latent features as small values (i.e.
close to 0). While this assumption may be wrong for spe-
ciﬁc cases, such constraints act as a good regularizer that
helps in signiﬁcantly improving the recommendations.

Our work is not the ﬁrst to propose new interpretation
of the missing data in a matrix factorization framework
[11, 20, 21, 28]. However, to the best of our knowledge, we
are the ﬁrst to propose an online learning mechanism that
sets an explicit prior on unknown values and this, without
any signiﬁcant additional cost. We introduce a method to
update our model each time a new rating is observed with a
time complexity independent of the size of the data (i.e. the
total number of users, items, and ratings). This fast update
mechanism allows keeping the model up to date when a ﬂow
of new users, items and ratings enters the system.
The contributions of this work are as follows:
• We extend the squared loss, the absolute loss and the
generalized Kullback-Liebler divergence to take into ac-
count an explicit prior on unknown values.

• For each loss function, we derive an eﬃcient online learn-
ing algorithm to update the parameters of the model
with a complexity independent of the data size.

• We validate the hypothesis that applying an explicit prior
on missing ratings improves the recommendations in a
static and in a dynamic setting on three public datasets.
• Our methods are easy to implement and we provide an
open-source implementation of the squared loss and ab-
solute loss.

The rest of this paper is organized as follows. Section 2
summarizes the recommendation problem and Section 3 for-
mulates how to apply priors on unknown values in the con-
text of recommendation. Section 4 extends three loss func-
tions and shows how they can be optimized in a static and
dynamic fashion. Section 5 presents our experimental results
and Section 6 discusses works related to our study. Section 7
concludes this paper.

2. THE RECOMMENDATION PROBLEM

Before addressing the challenge of interpreting missing

data, let us state the standard recommendation problem.

We have at our disposal m items rated by n diﬀerent users,
where the rating given by the ith user to the jth item is

denoted by rij. In many real applications, these ratings take
an integer value between 1 and 5. In this work, we assume
that ratings are positive and that an item rated by user i
with a high numerical value is preferred by this user over
items she ranked with lower numerical values. We denote
by R the set of all known ratings, and by Ri• and R•j the
set of known ratings of user i and item j, respectively. If
rij /∈ R we say that the rating is unknown.

For a while, the objective of recommender systems has
been to predict the value of unknown ratings [12]. It is now
widely accepted that a more practical goal is to correctly
rank the unknown ratings for each user, while the actual
value of the rating is of little interest [1, 5, 15, 20]. This
has led to a change in the way methods are evaluated (in
terms of ranking metrics such as NDCG, AUC or MAP,
instead of rating prediction metrics as measured by RMSE).
We embrace that shift towards ranking, and the purpose of
adding a prior on the unknown ratings is not to improve
matrix factorization techniques in terms of RMSE, but in
terms of ranking metrics.

Matrix factorization methods produce for each user and
each item a vector of k (<< n and m) real values that we
call latent features. We denote by wi the row vector con-
taining the k features of the ith user, and hj the row vector,
composed of k features, associated to the jth item. Also, we
denote by W the n × k matrix whose ith row is wi, and H
as the k × m matrix whose jth column is hT
j . Matrix fac-
torization is presented as an optimization problem, whose
general form is:

(cid:88)

(cid:16)

E

rij, wihT
j

(cid:17)

+ R(W, H)

(1)

arg min
W,H

i,j|rij ∈R

where R is a regularization term (often L1 or L2 norms),
and E measures the error that the latent model makes on
the observed ratings. Most often, E is the squared error.

Using a matrix factorization approach for predicting un-
known ratings relies on the hypothesis that a model ac-
curately predicting observed rating generalizes well to un-
known ratings. In the following section, we argue that the
former hypothesis is easily challenged.

3.

INTERPRETING MISSING DATA

LaunchCast is Yahoo’s former music service, where users
could, among other things, rate songs. In a survey of 2006,
users were asked to rate randomly selected songs [18]. The
distribution of ratings of random songs was then compared
to the distribution of voluntary ratings. The experiment
concluded that the distribution of the ratings for random
songs was strongly dominated by low ratings, while the vol-
untary ratings had a distribution close to uniform [18].

Intuitively, a simple process could explain the results: users
chose to rate songs they listen to, and listen to music they
expect to like, while avoiding genres they dislike. Therefore,
most of the songs that would get a bad rating are not volun-
tary rated by the users. Since people rarely listen to random
songs, or rarely watch random movies, we should expect to
observe in many areas a diﬀerence between the distribution
of ratings for random items and the corresponding distribu-
tion for the items selected by the users. This observation
has a direct impact on the presumed capacity of matrix fac-
torization to generalize a model based on observed ratings
to unknown ratings.

Building on the not missing at random assumption [18,
28], we propose to incorporate in the optimization problem
stated in Equation 1 a prior about the unknown ratings,
in order to limit the bias caused by learning on observed
ratings:

(cid:88)

(cid:16)

E

rij, wihT
j

(cid:17)

arg min
W,H

i,j|rij ∈R

+ α

(cid:88)

(cid:16)

E

ˆr0, wihT
j

(cid:17)

+ R(W, H)

(2)

i,j|rij /∈R

The objective function (Equation 2) has now two parts
(besides the regularization): the ﬁrst part ﬁts the model to
the observed ratings, and the second part drives the model
toward a prior estimate ˆr0 on the unknown ratings. In ab-
sence of further knowledge about a speciﬁc dataset, we sug-
gest to use ˆr0 = 0, the worst rating, as a prior estimate. The
coeﬃcient α allows to balance the inﬂuence of the unknown
ratings, and the original formulation is obtained with α = 0.
We expect α to be small to deal with the problem of class
Indeed, in real-life applications the number of
imbalance.
known ratings |R| is very small in comparison to the num-
ber of unknown ratings (nm − |R|), and if α is close to 1, or
larger, the second term of the objective function will com-
pletely dominate the other parts and drive all the users’ and
items’ features to zero. It is therefore important to ﬁnd a
right balance between the inﬂuence of the few known ratings
and of the many unknown ones.

In order to have a more intuitive feeling of the inﬂu-
ence of both parts of the objective function we introduce
ρ = α(nm − |R|)/|R|, which can be interpreted as an inﬂu-
ence ratio between unknown and known ratings. If ρ = 0,
the unknown ratings are ignored, if ρ = 1, both the known
ratings and the unknown ratings have the same global inﬂu-
ence on the objective function, if ρ = 2, the unknown ratings
are twice as important as the known ratings, etc.

A more involved model could assume an adaptive ρ per
user or item, which could lead to additional, albeit small,
gains. However, this implies more parameters to tune, more
cumbersome equations to explain and an involved process
to prove that the complexity of the method remains the
same. Due to limited space, instead, we provide a general
demonstration of the method and leave the adaptive model
for future work.

4. LOSS FUNCTIONS

An obvious diﬃculty raised by the new optimization prob-
lem introduced earlier is the apparent increase in complexity.
The naive complexity of evaluating this objective function is
O(nmk), while it is O(|R|k) for classical matrix factorization
approaches (Equation 1). In this section, we demonstrate
how it is possible to use our new model without the naive
additional cost, and present a way to perform fast updates
to incorporate new ratings in the model.

To this end, we show the applicability of our method when
E is the squared loss in Section 4.1 and the absolute loss in
Section 4.2. For the sake of demonstration, we also discuss
its applicability on the generalized Kullback-Liebler diver-
gence in Section 4.3. Finally, in Section 4.4 we outline how
the method can be enforced in a static setting, and a dy-
namic setting with continuous updates of new ratings, items
and users.

4.1 Squared Loss

By considering E as the squared loss, and R as the L1

regularization, the optimization problem becomes:

(cid:88)

(cid:16)
rij − wihT
j

(cid:17)2

arg min
W,H

i,j|rij ∈R

+ α

(cid:88)

(cid:16)
wihT
j

(cid:17)2

i,j|rij /∈R
(cid:32) n
(cid:88)

i=1

+ λ

||wi||1 +

||hj||1

(cid:33)

m
(cid:88)

j=1

For the sake of simplicity, let us forget about the regu-
larization term of the objective function for now (adding
it to the following development is trivial), and let us call
L(W, H, R) the objective function without regularization.
We want to be able to update the features of one user or
of one item in a time independent of the size of the dataset
(n, m, |R|). In the remainder, we show that it is possible to
compute ∂L/∂wi and ∂L/∂hj with a complexity linear in
the number of ratings provided by user i (|Ri•|) or given to
item j (|R•j|), respectively. On most datasets, and for most
users and items, we have |Ri•| (cid:28) m and |R•j| (cid:28) n, and,
therefore computing the gradient for one user or one item is
fast.

First, let us separate L in n blocks lw

i that contain only

the terms of L depending on wi:

∂L
∂wi

= −2

(cid:88)

(cid:104)

j|rij ∈R

rij − (1 − α)wihT
j

hj + 2αwiSh

(8)

(cid:105)

Symmetrically, if Sw = (cid:80)

i wT

i wi, we have:

(3)

(cid:88)

(cid:104)

lh
j =

i|rij ∈R

(rij − wihT

j )2 − α(wihT

+ αhjSwhT
j

j )2(cid:105)

(9)

(10)

and:

∂L
∂hj

= −2

(cid:88)

(cid:104)
rij − (1 − α)wihT
j

(cid:105)

wi + 2αhjSw

i|rij ∈R

Assuming that Sw is known, the complexity of computing
j or ∂L/∂hj is now O(|R•j|k + k2), and the complexity of
lh
computing it for every j ∈ {1, . . . , m} is O(|R|k + k2).

4.2 Absolute Loss

A similar development can be done when the squared loss
is replaced by the absolute loss. With the absolute loss, L
becomes:

(cid:88)

L =

(cid:12)
(cid:12)rij − wihT
(cid:12)

j

(cid:12)
(cid:12)
(cid:12) + α

(cid:88)

(cid:12)
(cid:12)wihT
(cid:12)

j

(cid:12)
(cid:12)
(cid:12)

i,j|rij ∈R

i,j|rij /∈R

As with the squared loss, we divide L into lw

i and lh
j .

lw
i =

(cid:88)

(cid:16)

rij − wihT
j

(cid:17)2

+ α

(cid:88)

(cid:16)

(cid:17)2

wihT
j

(4)

j|rij ∈R

j|rij /∈R

lw
i =

(cid:88)

(cid:12)
(cid:12)rij − wihT
(cid:12)

j

(cid:12)
(cid:12)
(cid:12) + α

(cid:88)

(cid:12)
(cid:12)wihT
(cid:12)

j

(cid:12)
(cid:12)
(cid:12)

j|rij ∈R

j|rij /∈R

Notice that we have:

L =

(cid:88)

lw
i

and

i

∂L
∂wi

=

∂lw
i
∂wi

If we adopt a naive computation, the second term of Equa-
tion (4) is more time expensive because most items are not
rated by the user. However, the sum on unknown ratings
(i.e. (cid:80)
j|rij /∈R), can be formulated as the diﬀerence between
the sum on all items (i.e. (cid:80)m
j=1) and the sum on rated items
only (i.e. (cid:80)
j|rij ∈R) . By so doing, the sum on unknown rat-
ings disappears from the computations:

(cid:88)

(cid:16)

wihT
j

(cid:17)2

=

(cid:16)
wihT
j

(cid:17)2

−

(cid:88)

(cid:16)

(cid:17)2

wihT
j

m
(cid:88)

j=1

j|rij /∈R

= wiShwT

i −

j|rij ∈R
(cid:16)

(cid:88)

(cid:17)2

wihT
j

j|rij ∈R

(5)

(6)

where we have posed Sh = (cid:80)

j hj, a k × k matrix inde-
pendent of i (i.e. it is the same matrix for all lw
i ). Assuming
that Sh is known, we can now compute lw
i and ∂L/∂wi with
a complexity of O(|Ri•|k + k2). From Equations 4 and 6,
we obtain:

j hT

As with the squared loss, we will change the expression
of lw
to remove the sum over all unknown ratings, but in
i
this case we have to impose non-negativity of the features
to go further. If W, H ≥ 0, we have (cid:12)
j , and
therefore:

(cid:12)
(cid:12) = wihT

(cid:12)wihT
j

(cid:88)

(cid:12)
(cid:12)wihT
(cid:12)

j

(cid:12)
(cid:12)
(cid:12) =

j|rij /∈R

m
(cid:88)

j=1

wihT

j −

(cid:88)

wihT
j

(11)

= wi

hT
j

−

(cid:88)

wihT
j

(12)

(cid:32) m
(cid:88)

j=1

j|rij ∈R
(cid:33)

j|rij ∈R

Here, instead of Sw and Sh, we will deﬁne sw = (cid:80)n
j=1 hj. We can now express lw

i=1 wi
i and ∂L/∂wi

and sh = (cid:80)m
eﬃciently:

lw
i =

(cid:88)

(cid:16)(cid:12)
(cid:12)rij − wihT
(cid:12)

j

(cid:12)
(cid:12) − αwihT
(cid:12)

j

(cid:17)

+ αwisT
h

(13)

j|rij ∈R

so that:

∂L
∂wi

=

j|rij ∈R

(cid:88)

(cid:16)

(cid:16)

sign

wihT

j − rij

− α

hj + αsT
h

(14)

(cid:17)

(cid:17)

(cid:88)

(cid:104)

lw
i =

j|rij ∈R

(rij − wihT

j )2 − α(wihT

+ αwiShwT
i

j )2(cid:105)

(7)

We can easily derive:

where sign(x) = x/|x| if x (cid:54)= 0, and equals 0 otherwise.
Assuming sh is known, the complexity of computing lw
i or
∂L/∂wi is now O(|Ri•|k). The corresponding expression of
lh
j and ∂L/∂hj is trivial, and the complexity to compute
them is O(|R•j|k).

4.3 Generalized Kullback-Leibler Divergence
For the sake of demonstration on other common loss func-
tions in matrix factorization, we show here the applicability
of the sparsity trick on the generalized Kullback-Liebler di-
vergence (GKL) [14, 16]. We do not elaborate further on
this function in the rest of the paper.

The generalized Kullback-Liebler divergence is deﬁned as

follows:

D(rij||wihT

j ) = rij log(

) − rij + wihT
j

(15)

rij
wihT
j

The GKL is not deﬁned when rij = 0. In the following

we extend the GKL by using its limit value:

D(0||wihT

j ) := lim
r→0

D(r||wihT

j ) = wihT
j

(16)

Using Equation 15 and 16, L becomes:

(cid:33)

(cid:33)

(cid:32)

(cid:88)

L =

i,j|rij ∈R

rij log(

) − rij + wihT
j

+ α

rij
wihT
j

(cid:88)

wihT
j

i,j|rij /∈R

We now follow the same development as with the other

losses. We deﬁne lw
i :

lw
i =

rij log(

) − rij + wihT
j

+ α

(cid:32)

(cid:88)

j|rij ∈R

rij
wihT
j

(cid:88)

wihT
j

j|rij /∈R

In the case of the GKL, the process to remove the sum
on unknown ratings is the same as with the absolute loss,
except that in absence of absolute value we do not have to
impose non-negativity of the features:

(cid:88)

wihT

j = wisT

h −

(cid:88)

wihT
j

(17)

j|rij /∈R

j|rij ∈R

This leads to:

(cid:32)

lw
i =

(cid:88)

j|rij ∈R
+ αwisT
h

rij log(

) − rij + (1 − α)wihT
j

rij
wihT
j

(cid:33)

(18)

Now we can easily derive ∂L/∂wi:

∂L
∂wi

=

(cid:32)

(cid:88)

j|rij ∈R

−

rij
wihT
j

(cid:33)

+ (1 − α)

hj + αsT
h

(19)

The corresponding expression of lh

j and ∂L/∂hj is ob-
tained symmetrically. As with the absolute loss, the com-
plexity of computing lw
i or ∂L/∂wi is now O(|Ri•|k) (it is
O(|R•j|k) for lh

j and ∂L/∂hj).

4.4 Static and Dynamic Factorization

We introduce an online algorithm to learn the latent fac-
tors from the input data in a static setting, and show how
it can accommodate updates in a dynamic setting.

Algorithm 1 Randomized block coordinate descent

Require:

– The ratings R.
– The number of features k.

In the case of a user (i) do

1: Initialize W and H.
2: Compute Sw and Sh (sw and sh)
3: while not converged do
4:
5:
6:
7:
8:
9:
10:
11:
end for
12: end while

In the case of an item (j) do

for all user and item, traversed in a random order do

Perform a gradient step on wi using line search
Update Sw (sw)

Perform a gradient step on hj using line search
Update Sh (sh)

4.4.1

Static Factorization

In order to factorize a whole new set of data we propose
to use a randomized block coordinate descent [26]. At each
iteration, all the users and items are traversed in a random
order. For each of them a gradient step is performed on their
features while keeping the other features constant.

We can use a line search [2] to determine the size of the
gradient step because the variation of L for a modiﬁcation
of wi is entirely determined by lw
i and can therefore be com-
puted eﬃciently. Line search allows to avoid the burden of
tuning the step size, proper to stochastic gradient descent
(SGD) methods [7]. Moreover, using line search guaran-
tees the convergence of the value of the objective function.
Indeed, each gradient step decreases (or rather cannot in-
crease) the objective function which is bounded from below.
This implies that the variation of the objective function con-
verges to zero.

The complete procedure for the factorization through ran-
domized block coordinate descent is summarized in Algo-
rithm 1.

Complexity. In the case of the squared loss, the compu-
tation of fast gradient step relies on knowing Sw and Sh.
Their initial value is computed in O(nk2) and O(mk2), re-
spectively, and the cost of updating them after each gradient
step is O(k2). The total complexity of an iteration of our
algorithm is therefore O(|R|k + (n + m)k2), as good as the
best factorization methods that do not use priors on un-
known ratings [9].

In the case of the absolute loss and generalized Kullback-
Liebler divergence, the computation uses sw and sh. Their
initial value is computed in O(nk) and O(mk), while the
cost of updating them is O(k). The total complexity of one
iteration then becomes O(|R|k + (n + m)k), which is lower
than the squared loss’ complexity. However, this usually
comes at a cost on the performance of the results, as we will
show in the experiments in Section 5.

4.4.2 Fast Updates
The expressions of lw

i , lh

j , and their gradients (Equations
(7), (8), (9) and (10)) allow us to compute the latent repre-
sentations of one user or one item in a time independent of
the number of users and items in the system. We can use
that ability to design a simple algorithm for updating an
existing factorization when a new rating is added to R: If

Algorithm 2 Update algorithm

Require:

– The new rating rij.
– The ratings of user i (Ri•) and of item j (R•j).

1: If wi (hj) does not exist, initialize it (for example by

setting a random feature to 1).

2: Add rij to Ri• and R•j.
3: while not converged do
4:
5: Update Sw (sw)
6:
7: Update Sh (sh)
8: end while

Perform a gradient step on wi using line search

Perform a gradient step on hj using line search

user i rates item j, we iteratively perform gradient steps for
wi and hj, keeping all other features constant. This relies
on the assumption that a new rating will only aﬀect signif-
icantly the user and item that are directly concerned with
it. Although this assumption can be disputed, we will show
in our experiments (Section 5.3) that our update algorithm
produces recommendations of stable quality, indicating that
limiting our updates to the directly aﬀected users and items
does not degrade the factorization over time.

When ratings are produced by new users or given to new
items, a new set of features for that user or item is created
before performing the local optimization. Various initializa-
tion strategies could be explored here. However, as we show
in our experimental results, assigning a random value to one
of the features and setting the others to zero performs well in
practice. The update procedure is summarized in Algorithm
2.
Complexity. As mentioned earlier, our update algorithm
is independent of the number of users or items in the sys-
tem, making it suitable for very large datasets. Each itera-
tion of the update algorithm is composed of two gradient
steps (one on the user’s features, and one on the item’s
features).
In particular, the complexity of one iteration
is O((|Ri•| + |R•j|)k + k2) for the squared loss, and only
O((|Ri•| + |R•j|)k) for the absolute loss and the GKL. This
diﬀerence in complexity becomes signiﬁcant when k is large
with regards to the average number of ratings per user and
per item.

Updates based on classic SGD methods have an even smaller

complexity (O(k))), but we will show in Section 5 that our
method produces recommendations of much higher quality,
while still being able to satisfy applications requiring low-
latency updates.

5. EXPERIMENTS

lowing key points:

We perform several experiments to demonstrate the fol-

• Using priors on the unknown values leads to overall im-
proved quality of ranking, in a static or dynamic setting.
• The quality does not degrade with time, i.e., as more
updates are added, the model does not lose accuracy.
• Our methods can outperform traditional techniques on

various large datasets.

In our experiments, we test the performance of the squared
loss (SL) and the absolute loss (AL) with and without prior
on unknown values. In Section 5.1 we describe our exper-

Table 1: Characteristics of the datasets used.

Dataset

Movielens
FineFoods
AmazonMovies

Users

6,040
256,059
889,176

Items

3,706
74,258
253,059

Ratings

1,000,209
568,454
7,831,442

imental setup: the benchmarked datasets used, the perfor-
mance metrics recorded and how we tune the various param-
eters of the models tested during the experiments. Then, in
Sections 5.2 and 5.3 we describe the results of our methods in
a static and dynamic learning setting, respectively, and how
they compare with state-of-the-art methods. In Section 5.4
we illustrate the importance of fast updates by studying the
impact of having a delay between the arrival of new ratings
and the update of the factorization. In Section 5.5 we inves-
tigate in depth the inﬂuence of parameter values selected in
the two loss functions (squared and absolute loss). Finally,
details allowing the reproducibility of the results are given
in Section 5.6.

5.1 Experimental Setup

Here we brieﬂy describe the experimental setup used for
the static and dynamic learning and how the parameters of
the diﬀerent methods are tuned.

5.1.1 Datasets

During the experiments, we use three datasets with dis-
tinct features. Table 1 summarizes the characteristics of
these datasets which provide diﬀerent challenges to the rec-
ommendation task:

• Movielens: This is the well-known movie ratings dataset
produced by the Grouplens project. We use the version
containing 1 million ratings, with at least 20 ratings for
each user.

• FineFoods: This is a collection of ratings about food
products extracted from the Amazon comments [19]. The
dataset is much sparser than Movielens, with most users
having only a handful of ratings, making it a very hard
dataset for the recommendation task.

• AmazonMovies: This is a larger collection of ratings ex-
tracted from the movie section of Amazon [19]. This
dataset is also sparser than Movielens, although not as
sparse as FineFoods.

5.1.2 Evaluation Metrics

We measure two standards metrics used in ranking evalua-
tion: (1) Normalized Discounted Cumulative Gain (NDCG)
[1, 15] and, (2) area under ROC curve (AUC) [20, 23, 27].

NDCG rewards methods that rank items with the highest
observed rating at the top of the ranking. The discounted
aspect of NDCG comes from the fact that relevant items
ranked at low positions of the ranking contribute less to the
ﬁnal score than relevant items at top positions.

In the static experiments, we also report the NDCG com-
puted on the rated items only. This metric does not con-
sider the real world case scenario which consists of ranking
all items since we do not know in advance which item will be
rated or not. Intuitively, by biasing our objective through
the introduction of priors on unknown rating we may loose
performance when ranking rated items only, while perform-

Table 2: List of the parameters of each method, and set of
values tested during the parameters tuning of the squared
loss (SL) and absolute loss (AL), with and without prior
on unknown values, as well as the multiplicative update al-
gorithm (Mult-NMF), Alternating Least Square (ALS-UV),
and Vowpal Wabbit (VW). k: number of features, λ: regu-
larization coeﬃcient, ρ: unknown/known inﬂuence ratio, γ:
learning rate.

Method

Parameter

Tested Values

SL/AL
with prior

SL/AL with-
out prior

ALS-UV

Mult-NMF

VW

k
λ
ρ

k
λ

k
λ

k

k
λ
γ

5, 10, 20, 50, 100, 200
0, 0.01, 0.1, 1, 10
0.3, 0.7, 1, 2

5, 10, 20, 50, 100, 200
0, 0.01, 0.1, 1, 10

20, 50, 100, 200, 500
0, 0.001, 0.01, 0.05, 0.1

20, 50, 100, 200, 500

20, 50, 100, 200, 500
0 1e-5 1e-2
0.01, 0.02, 0.05, 0.1, 0.2

ing better when considering all the items.

We use AUC to evaluate the ability of the diﬀerent meth-
ods to predict which items are going to be rated. AUC mea-
sures whether the items whose ratings were held out during
learning are ranked higher than unrated items. The perfect
ranking has an AUC of 1, while the average AUC for random
ranking is 0.5.

5.1.3 Parameter Tuning

Table 2 shows the parameters of the various models and
the values tested during parameter tuning. For each test,
the parameters’ values producing the best ranking on the
validation sets (measured by NDCG for the static test and
AUC for the dynamic test) were selected to be used. See
Sections 5.2 and 5.3 for the description of the validation
sets.

5.2 Static Learning

Research question. In a static mode, we test to which ex-
tent using a prior on unknown ratings improves the ranking
of items when recommended to users.

Process followed. The test set was constructed by ran-
domly selecting 1000 users, and splitting the ratings of those
users in half, keeping the ﬁrst 50% of the ratings in the
training set, according to timestamp, and the last 50% in
the test set. The same process (selecting 1000 users and
splitting their ratings) was then applied three times on the
training set in order to create three training/validation pairs
of sets. On each run, the parameters producing on average
the best NDCG over the three validation sets were then used
to factorize the full training set, and evaluated on the test
set.

Baseline. We report the results achieved by two traditional
well-known algorithms: UV matrix decomposition solved
with Alternating Least Square (ALS-UV) [30], and non-
negative matrix factorization with the multiplicative update
algorithm (Mult-NMF) [14]. Both ALS-UV and Mult-NMF

Table 3: Comparison of our introduced algorithm in static
learning on the datasets Movielens, FineFoods and Amazon-
Movies. Values in bold hold for the method that outperform
all the other methods according to a Mann-Withney U test
with a conﬁdence level of 1%. Average values are shown
alongside their standard deviation over 10 runs.

NDCG-RI

AUC

Movielens
NDCG

SL w/ prior
SL w/o prior 0.886 ± 0.0015
0.3597 ± 0.0012
AL w/ prior 0.8683 ± 0.0030 0.4452 ± 0.0009
AL w/o prior 0.8794 ± 0.0031 0.3801 ± 0.0106
0.8433 ± 0.0007 0.3758 ± 0.0006
Mult-NMF
0.8332 ± 0.0014 0.3292 ± 0.0004
ALS-UV

0.885 ± 0.0014 0.5046 ± 0.0013 0.8695 ± 0.0012
0.6548 ± 0.0014
0.8134 ± 0.0011
0.6927 ± 0.0322
0.7011 ± 0.0009
0.5839 ± 0.0005

NDCG-RI

FineFoods
NDCG

AUC

0.887 ± 0.0016 0.1237 ± 0.0039 0.8452 ± 0.0074
0.8314 ± 0.0058
0.8412 ± 0.0047
0.7294 ± 0.0143
0.3403 ± 0.0052
0.5485 ± 0.0114

SL w/ prior
SL w/o prior 0.888 ± 0.0158
0.1023 ± 0.0022
AL w/ prior 0.8722 ± 0.0142 0.1026 ± 0.0030
AL w/o prior 0.8730 ± 0.0260 0.0923 ± 0.0008
0.8476 ± 0.0084 0.0830 ± 0.0008
Mult-NMF
0.0873 ± 0.0009
0.8653 ± 0.025
ALS-UV
AmazonMovies
NDCG
0.8992 ± 0.0101 0.1887 ± 0.0088 0.9276 ± 0.0031
0.8656 ± 0.0033
0.8634 ± 0.0045
0.7625 ± 0.0051
0.6330 ± 0.0040
0.6601 ± 0.0061

SL w/ prior
SL w/o prior 0.9035 ± 0.0089 0.1103 ± 0.0008
AL w/ prior 0.8804 ± 0.0077 0.1348 ± 0.0035
AL w/o prior 0.8854 ± 0.0102 0.1002 ± 0.0012
0.8498 ± 0.0026 0.0959 ± 0.0004
Mult-NMF
0.8658 ± 0.0034 0.0906 ± 0.0003
ALS-UV

NDCG-RI

AUC

use the squared loss.
Results. The results, averaged over 10 runs, are shown in
Table 3. We can observe that for both the squared loss and
the absolute loss, and on all datasets, by adding a prior on
the unknown ratings we improve signiﬁcantly the rankings of
the items recommended to users over rankings obtained by
the same techniques when they do not put a prior on the un-
known ratings (and also over rankings obtained by state-of-
the-art approaches ALS-UV and Mult-NMF). In particular,
our implementation of the squared loss with prior outper-
forms all other methods, as conﬁrmed by a Mann-Withney
U test with a conﬁdence level of 1%.

On the Movielens dataset, the results of Mult-NMF and
ALS-UV are, as expected, similar to the ones of our imple-
mentation of the squared loss without prior. Indeed, those
methods optimize the same objective function, and diﬀer
only by their algorithm. Interestingly, on the sparser Fine-
Foods and AmazonMovies dataset, our randomized block co-
ordinate gradient descend method outperforms Mult-NMF
and ALS-UV, even without prior on the unknown ratings.

Furthermore, in the three tested data sets, when only con-
sidering the rated items, the loss in ranking performance is
never signiﬁcant (see NDCG-RI with and without prior in
Table 3).
In other words, while improving on the global
ranking, the performance does not deteriorate when consid-
ering only the subset of rated items.

5.3 Dynamic Learning

Research question. In this section, we target two research
questions:

1. We test whether our update algorithm is able to sus-
tain stable quality of recommendations over time;

2. We test to which extent using priors on unknown rat-
ings improves the ranking of recommended items when

the model is updated each time a new instance is en-
countered. By so doing, the system is evaluated on
more realistic scenarios where the cases of cold items
and users are considered as well.

Process followed. We order the ratings by timestamps
and separate the ratings in three blocks: ﬁrst the training,
then the validation and ﬁnally the test block (see Table 4
for the size of each block in the diﬀerent datasets).

Table 4: Number of ratings in each block for the dynamic
learning.

Dataset

Training Validation

Test

500,000
Movielens
FineFoods
400,000
AmazonMovies 5,000,000

100,000
100,000

100,000
68,000
1,000,000 1,000,000

The evaluation is performed as follows: an initial model is
built based on all the ratings present before the test block,
then, for each rating of the test block, two steps are per-
formed in the following order:

1. The current model is evaluated by computing the AUC
over the new (user, item) pair. Notice that in this case,
computing the AUC means computing the proportion
of items not yet rated by the user that the model ranks
lower than the item that was just rated. An AUC of 1
means that the new item was the top recommendation
of the method for that user.

2. The model is updated using the new rating. It is worth
noticing that the rating may concern a new user or
item, and, therefore, features for that new user/item
have to be added to the model.

Parameter tuning is done as described above, but starting
at the beginning of the validation block and ending before
the test block. The values of parameters tested are the same
as in the static test (see Table 2).
Baseline. We compared our methods to Vowpal Wabbit
(VW). VW is a machine learning framework solving diﬀer-
ent optimization problems for classiﬁcation and ranking, by
implementing a carefully optimized, stochastic gradient de-
scent (SGD) using feature hashing [29] and adaptive gra-
dient steps [7]. We are using the VW’s implementation of
low-rank interactions1 based on factorization machines [22].
Results. Figure 1 shows how the average AUC evolves as
new ratings enter the system. We ﬁrst observe that the
quality of the results does not decrease over time, indicating
that our update algorithm can work for long periods of time
without propagating or amplifying errors. As in the static
experiment, we conﬁrm that adding a prior on unknown
ratings improves the quality of the ranking and, again, this
is maintained across time. Moreover, the SGD approach of
VW is outranked in each dataset by our approach with prior.

5.4 Impact of delayed updates
Research Question. We test the performance of delayed
models produced by our methods in delivering recommen-
dations to users.
1https://github.com/JohnLangford/vowpal_wabbit/
tree/master/demo/movielens

Figure 1: Performance comparison with respect to average
AUC for the various methods tested in dynamic learning on
Movielens, FineFoods and AmazonMovies. Results are aver-
aged over 20 runs.

Process followed. In order to address this question, we
simulate a recommender system that is not able to incor-
porate new ratings in the model as soon as they enter the
system. To do so, we modify the process of dynamic learn-
ing presented in Section 5.3 to impose a delay between the
arrival of a new rating and the update of the factorization.
More precisely, after the ith rating is given by a user, the
model is updated up to the (i − d)th rating (d being the
arbitrary delay). This way, the model is always d ratings
behind the last one arrived (the ratings are sorted by real
time of arrival). In real applications, the delay would prob-
ably vary, depending on the level of activity of the users.
However, this experiment gives a ﬁrst impression of the im-
pact of delays on the recommendation task.

Results. Figure 2 shows the impact of a delay on the av-
erage AUC of the squared loss and absolute loss with prior
for a dense dataset like Movielens and a sparse dataset like
FineFoods. We observe that even a small delay can aﬀect
the quality of the recommendation, depending on the char-
acteristics of the data. For Movielens, if the model is behind
by 5 − 10 ratings, the average AUC drops by 3%, and it goes
down by about 14% when the model is behind by 1000 rat-
ings, and this applies to both loss functions. On the other
hand, for the much sparser FineFoods, the eﬀect is more ap-
parent. With only 5 − 10 ratings behind, the model’s AUC
already drops by 10%.

To show the eﬀect of fast updates on weakly-engaged (or
cold) users, we also report the impact of delays on those
users for both Movielens and FineFoods with the squared
loss which performs best (Figure 2, Cold Users). We deﬁne
such users as the ones that rated at most two items. As
hypothesized, the cost induced by delayed predictions (for
ﬁve ratings delayed) is higher for cold users. We observe a
relative drop in AUC of 11.8% and 13.4% for weakly-engaged
users on Movielens and FineFoods, respectively, while when
considering all the users, the relative drop is 1.1% and 12.9%,

ble here. The reason may be that the role of regularization is
already taken by the prior on unknown ratings. Introducing
the prior seems to have the side eﬀect of making the regu-
larization obsolete (or redundant). In fact, we conﬁrm this
with the results for λ = 0 which demonstrate no impact on
the quality or runtime. Again, we see that setting a prior on
unknown ratings increases the quality of recommendations
without increasing the complexity of the solution. While it
adds a term and a parameter to the objective function, it
allows to remove one and its associated parameters.

Unknown/known inﬂuence ratio. The ratio ρ inﬂuences
the performance of the squared loss algorithm in the follow-
ing way: the AUC increases when a prior on unknown values
is added (ρ > 0), but the exact value of ρ has little inﬂuence
(in the observed range) (Figure 3(c)). The absolute loss is
more sensitive to the value of ρ, with the AUC decreasing
when ρ becomes too large (on Movielens and AmazonMovies).
However, in both cases, and on all datasets, giving the same
weight to the known and unknown ratings (ρ = 1) oﬀers a
signiﬁcant improvement over not using a prior, suggesting
that ρ = 1 can be used as a ﬁrst guideline, avoiding the
burden of further parameter tuning.

The update runtime is also aﬀected by ρ, decreasing when
ρ increases (Figure 3(f)). The explanation can be that the
prior on unknown ratings acts as a regularizer, driving fea-
tures towards 0, and in doing so speeding up the conver-
gence.

Runtime. In general, our technique demonstrates low run-
ning time which is heavily dependent on the number of fea-
tures used, and less on the regularization applied or the ra-
tio of unknown over known values. These results demon-
strate that our method can satisfy applications requiring
low-latency updates.

5.6 Reproducibility of Results

The implementation of the algorithms introduced in Sec-

tion 4 is available on Github:
https://github.com/rdevooght/MF-with-prior-and-updates.

For both ALS-UV and Mult-NMF we use the implementa-
tion of GraphChi, an open source tool for graph computation
with impressive performance [13].

The code and documentation of Vowpal Wabbit is avail-

able on its Github page:
https://github.com/JohnLangford/vowpal_wabbit/wiki.
The Amazon datasets are available on the SNAP webpage:

http://snap.stanford.edu/data/index.html

The Movielens dataset is available on the Grouplens page:

http://www.grouplens.org/datasets/movielens/.

6. RELATED WORK

The problem of recommending products based on the ac-
tions and feedback from other users (rather than based on
content similarity) is often called collaborative ﬁltering, and
dates back 20 years ago, with works such as Tapestry [10]
and Grouplens [25]. The ﬁeld is now dominated by meth-
ods based on matrix factorization, with algorithms such
as ALS [30], the multiplicative update rule [14], and the
stochastic gradient descent method (SGD) [9, 12].

The missing at random assumption has yet to get the
attention it deserves in collaborative ﬁltering. Both [18]
and [28] have validated the hypothesis of ratings missing
not at random. Practical propositions for the interpretation

Figure 2: Average AUC of the squared loss and absolute
loss with prior on Movielens and FineFoods for various delays
d, imposed as a number of ratings that the model is behind
the current rating.

respectively.

In such sparse scenarios, cold users perform only a handful
of actions before deciding to abandon the site or not. There-
fore, it is important to consider cold users in the model as
soon as they arrive, to keep them engaged by fast, eﬃcient
and good recommendations.

5.5 Parameter Analysis

Research Question. We test to which extent the number
of features (k), the weight of the prior (ρ) and the regular-
ization coeﬃcient (λ) aﬀect the AUC and the runtime per
update on our loss functions.

Figure 3 shows the results of this investigation for diﬀer-
ent values of these parameters, for both squared loss and
absolute loss and on each dataset. The results are obtained
using the dynamic learning process.

Number of features. Concerning the quality of ranking
(AUC), we observe the usual overﬁtting/under-ﬁtting trade-
oﬀ (Figure 3(a)). The optimal number of features depends
on the dataset as well as on the loss function used, suggesting
that a careful tuning of that parameter is always needed.

In some cases, speed constraints will force the use a sub-
optimal number of features.
Indeed, the update runtime
heavily depends on the number of features. Figure 3(d) sug-
gests a linear relationship between runtime and number of
features. For both losses there is indeed a linear role of the
number of features in the theoretical complexity (Section
4.4). Notice, however, that the theoretical complexity of the
squared loss also has a quadratic term that becomes domi-
nant for large number of features (with regards to the num-
ber of ratings per users). Also note that while the squared
loss produces better AUC, the absolute loss is able to sus-
tain higher update rates, and can therefore be the loss of
choice when speed is the ﬁrst criterion.

Regularization coeﬃcient. The inﬂuence of λ seems
rather limited, except for high values that cause both the
AUC and the update runtime to drop (Figure3(b) and (e)).
A small regularization is supposed to increase the quality of
the model by reducing overﬁtting, but this eﬀect is not visi-

Figure 3: Inﬂuence of parameter values on the AUC and runtime for the models produced by the squared loss (SL) and
absolute loss (AL). Y-error bars declare a standard deviation on the average value of each metric.

of missing data can be found in the ﬁelds of one-class collab-
orative ﬁltering and collaborative ﬁltering based on implicit
feedback, where the missing at random assumption is often
obviously untenable [11, 20, 21].
[27] oﬀers an interesting
approach where missing ratings are considered as optimiza-
tion variables; they use an EM algorithm to optimize in
turn the factorization and the estimation of missing values.
Unfortunately, that method has a high complexity, and the
proposed approximations that work with large problems re-
move some of the method’s appeal.

None of those works, however, consider the real world, dy-
namic scenario of continuously observing new ratings, users
and items. Other works [8, 24] focus on the dynamic update
of matrix factorization (mainly through the use of SGD),
but those, on the other hand, implicitly rely on the missing
at random assumption, and therefore suﬀer from lower ac-
curacy in predictions. Other state-of-art methods for matrix
factorization scale by relying on stochastic gradient compu-
tation [3, 4], while we rely on exact gradient approach. In
this work, at the diﬀerence of what is mostly seen on scal-
able machine learning techniques nowadays [6], we base our
approach on coordinate random block descent to compute
exact gradient in order to deal with missing data of large
scale matrices.

7. CONCLUSIONS

In this work we proposed a new, simple, and eﬃcient, way
to incorporate a prior on unknown ratings in several loss
functions commonly used for matrix factorization. We ex-
perimentally demonstrated the importance of adding such a
prior to solve the problem of collaborative ranking. We also

tackled the problem of updating the factorization when new
users, items and ratings enter the system. We believe that
this problem is central to real applications of recommenda-
tion systems, because new users constantly enter those sys-
tems and the factorization must be kept up to date to give
them recommendations immediately after their ﬁrst few in-
teractions with the platform. We oﬀer an update algorithm
whose complexity is independent of the size of the data,
making it a good approach for large datasets. In the future,
we would like to explore how our methods perform under
real workloads of updates with variable arrival rates of rat-
ings per user and item. Furthermore, we would like to test
the performance of our methods in platforms built to ana-
lyze streams of data such as Storm, Twitter’s Distributed
Processing Engines platform.

8. ACKNOWLEDGEMENTS

R. Devooght is supported by the Belgian Fonds pour la
Recherche dans l’Industrie et l’Agriculture (FRIA, 1.E041.14).

References
[1] S. Balakrishnan and S. Chopra. Collaborative ranking.
In Proc. of the 5th ACM WSDM, pages 143–152, 2012.

[2] S. Boyd and L. Vandenberghe. Convex optimization.

Cambridge university press, 2009.

[3] W.-S. Chin, Y. Zhuang, Y.-C. Juan, and C.-J. Lin. A
fast parallel stochastic gradient method for matrix fac-
torization in shared memory systems. ACM Transac-

tions on Intelligent Systems and Technology (TIST),
6(1):2, 2015.

[4] W.-S. Chin, Y. Zhuang, Y.-C. Juan, and C.-J. Lin. A
learning-rate schedule for stochastic gradient methods
to matrix factorization. In Advances in Knowledge Dis-
covery and Data Mining, pages 442–455. Springer, 2015.

[5] P. Cremonesi, Y. Koren, and R. Turrin. Performance
of recommender algorithms on top-n recommendation
tasks. In Proc. of the 4th ACM RecSys, pages 39–46,
2010.

[6] J. Dean, G. Corrado, R. Monga, K. Chen, M. Devin,
M. Mao, A. Senior, P. Tucker, K. Yang, Q. V. Le, et al.
Large scale distributed deep networks.
In Advances
in Neural Information Processing Systems, pages 1223–
1231, 2012.

[7] J. Duchi, E. Hazan, and Y. Singer. Adaptive subgra-
dient methods for online learning and stochastic opti-
mization. The Journal of Machine Learning Research,
12:2121–2159, 2011.

[8] J. Gaillard and J.-M. Renders. Time-sensitive collab-
orative ﬁltering through adaptive matrix completion.
In Advances in Information Retrieval, pages 327–332.
Springer, 2015.

[9] R. Gemulla, E. Nijkamp, P. J. Haas, and Y. Sisma-
nis. Large-scale matrix factorization with distributed
stochastic gradient descent. In Proc. of the 17th ACM
SIGKDD, pages 69–77, 2011.

[10] D. Goldberg, D. Nichols, B. M. Oki, and D. Terry.
Using collaborative ﬁltering to weave an information
tapestry. Communications of the ACM, 35(12):61–70,
1992.

[11] Y. Hu, Y. Koren, and C. Volinsky. Collaborative ﬁlter-
ing for implicit feedback datasets. In Proc. of the 8th
IEEE ICDM, pages 263–272, 2008.

[12] Y. Koren, R. Bell, and C. Volinsky. Matrix factoriza-
tion techniques for recommender systems. Computer,
42(8):30–37, 2009.

[13] A. Kyrola, G. E. Blelloch, and C. Guestrin. Graphchi:
Large-scale graph computation on just a pc. In OSDI,
volume 12, pages 31–46, 2012.

[14] D. D. Lee and H. S. Seung. Algorithms for non-negative
matrix factorization. In Advances in neural information
processing systems, pages 556–562, 2000.

[15] J. Lee, S. Bengio, S. Kim, G. Lebanon, and Y. Singer.
Local collaborative ranking. In Proc. of the 23rd ACM
WWW, pages 85–96, 2014.

[16] C.-J. Lin. Projected gradient methods for nonnegative
matrix factorization. Neural computation, 19(10):2756–
2779, 2007.

[17] R. J. Little and D. B. Rubin. Statistical analysis with

missing data. 2002.

[18] B. Marlin, R. S. Zemel, S. Roweis, and M. Slaney. Col-
laborative ﬁltering and the missing at random assump-
tion. In Proc. of the 23rd Conference on Uncertainty in
Artiﬁcial Intelligence, 2007.

[19] J. McAuley and J. Leskovec. Hidden factors and hidden
topics: understanding rating dimensions with review
text. In Proc. of the 7th ACM RecSys, pages 165–172,
2013.

[20] R. Pan and M. Scholz. Mind the gaps: weighting the
unknown in large-scale one-class collaborative ﬁltering.
In Proc. of the 15th ACM SIGKDD, pages 667–676.
ACM, 2009.

[21] R. Pan, Y. Zhou, B. Cao, N. N. Liu, R. Lukose,
M. Scholz, and Q. Yang. One-class collaborative ﬁl-
tering. In Proc. of the 8th IEEE ICDM, pages 502–511,
2008.

[22] S. Rendle. Factorization machines. In Proc. of ICDM

2010, pages 995–1000, 2010.

[23] S. Rendle, C. Freudenthaler, Z. Gantner,

and
L. Schmidt-Thieme. Bpr: Bayesian personalized rank-
ing from implicit feedback. In Proc. of the 25th Con-
ference on Uncertainty in Artiﬁcial Intelligence, pages
452–461. AUAI Press, 2009.

[24] S. Rendle and L. Schmidt-Thieme. Online-updating
regularized kernel matrix factorization models for large-
scale recommender systems. In Proc. of the 2008 ACM
RecSys, pages 251–258, 2008.

[25] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and
J. Riedl. Grouplens: an open architecture for collabora-
tive ﬁltering of netnews. In Proc. of the 1994 ACM con-
ference on Computer supported cooperative work, pages
175–186, 1994.

[26] P. Richt´arik and M. Tak´aˇc. Iteration complexity of ran-
domized block-coordinate descent methods for minimiz-
ing a composite function. Mathematical Programming,
144(1-2):1–38, 2014.

[27] V. Sindhwani, S. S. Bucak, J. Hu, and A. Mojsilovic.
One-class matrix completion with low-density factor-
izations. In Proc. of the 10th IEEE ICDM, pages 1055–
1060, 2010.

[28] H. Steck. Training and testing of recommender systems
on data missing not at random. In Proc. of the 16th
ACM SIGKDD, pages 713–722. ACM, 2010.

[29] K. Weinberger, A. Dasgupta, J. Langford, A. Smola,
and J. Attenberg. Feature hashing for large scale mul-
titask learning. In Proc. of the 26th ACM ICML, pages
1113–1120. ACM, 2009.

[30] Y. Zhou, D. Wilkinson, R. Schreiber, and R. Pan.
Large-scale parallel collaborative ﬁltering for the net-
ﬂix prize. In Algorithmic Aspects in Information and
Management, pages 337–348. Springer, 2008.

