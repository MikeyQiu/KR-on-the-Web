9
1
0
2
 
n
a
J
 
4
1
 
 
]

V
C
.
s
c
[
 
 
3
v
1
6
4
8
0
.
1
1
6
1
:
v
i
X
r
a

Discriminative Correlation Filter Tracker with
Channel and Spatial Reliability

Alan Lukeˇziˇc1, Tom´aˇs Voj´ıˇr2, Luka ˇCehovin Zajc1, Jiˇr´ı Matas2 and Matej Kristan1
1Faculty of Computer and Information Science, University of Ljubljana, Slovenia
2Faculty of Electrical Engineering, Czech Technical University in Prague, Czech Republic
{alan.lukezic, luka.cehovin, matej.kristan}@fri.uni-lj.si
{vojirtom, matas}@cmp.felk.cvut.cz

Abstract

Short-term tracking is an open and challenging problem
for which discriminative correlation ﬁlters (DCF) have
shown excellent performance. We introduce the channel
and spatial reliability concepts to DCF tracking and pro-
vide a learning algorithm for its efﬁcient and seamless
integration in the ﬁlter update and the tracking process.
The spatial reliability map adjusts the ﬁlter support to
the part of the object suitable for tracking. This both
allows to enlarge the search region and improves track-
ing of non-rectangular objects. Reliability scores reﬂect
channel-wise quality of the learned ﬁlters and are used as
feature weighting coefﬁcients in localization. Experimen-
tally, with only two simple standard feature sets, HoGs
and Colornames, the novel CSR-DCF method – DCF with
Channel and Spatial Reliability – achieves state-of-the-
art results on VOT 2016, VOT 2015 and OTB100. The
CSR-DCF runs close to real-time on a CPU.
Keywords— Visual tracking, Correlation ﬁlters, Channel
reliability, Constrained optimization

1 Introduction

Short-term, model-free visual object tracking is the prob-
lem of continuously localizing a target
in a video-
sequence given a single example of its appearance. It has
received signiﬁcant attention of the computer vision com-
munity which is reﬂected in the number of papers pub-
lished on the topic and the existence of multiple perfor-
mance evaluation benchmarks (Wu et al, 2013; Kristan

et al, 2013, 2014, 2015, 2016c; Liang et al, 2015; Smeul-
ders et al, 2014; Mueller et al, 2016). Diverse factors –
occlusion, illumination change, fast object or camera mo-
tion, appearance changes due to rigid or non-rigid defor-
mations and similarity to the background – make short-
term tracking challenging.

Recent short-term tracking evaluations (Wu et al, 2013;
Kristan et al, 2013, 2014, 2015) consistently conﬁrm the
advantages of semi-supervised discriminative tracking ap-
proaches (Grabner et al, 2006; Babenko et al, 2011; Hare
et al, 2011; Bolme et al, 2010).
In particular, track-
ers based on the discriminative correlation ﬁlter (DCF)
method (Bolme et al, 2010; Danelljan et al, 2014a; Hen-
riques et al, 2015; Li and Zhu, 2014a; Danelljan et al,
2015a) have shown state-of-the-art performance in all
standard benchmarks. Discriminative correlation meth-
ods learn a ﬁlter with a pre-deﬁned response on the train-
ing image. The latter is obtained by slightly extending the
region around the target to include background samples.
The standard formulation of DCF uses circular corre-
lation which allows to implement learning efﬁciently by
Fast Fourier transform (FFT). However, the FFT requires
the ﬁlter and the search region size to be equal which
limits the detection range. Due to the circularity, the ﬁl-
ter is trained on many examples that contain unrealistic,
wrapped-around circularly-shifted versions of the target.
A naive approach to the reduction of the windowing prob-
lems is to learn the ﬁlter from a larger region. However,
due to the large area of the background in the region, the
tracking performance of the DCF drops signiﬁcantly as
shown in Figure 2.

The windowing problems were recently addressed by

1

overcomes both the problems of circular shift enabling an
arbitrary search (and training) region size and the limi-
tations related to the rectangular shape assumption. An
important beneﬁt of a large training region is that back-
ground samples from a wider area around the target are
obtained to improve the ﬁlter discriminative power. The
spatial reliability map is estimated using the output of a
graph labeling problem solved efﬁciently in each frame.
An efﬁcient optimization procedure is applied for learn-
ing a correlation ﬁlter with the support constrained by the
spatial reliability map since the standard closed-form so-
lution cannot be generalized to this case. Figure 2 shows
that tracking performance of our spatially constrained cor-
relation ﬁlter (denoted as S-DCF) does not degrade with
increasing training and search region size as is the case
with the standard DCF. In contrast, the performance of
S-DCF improves from better treatment of training sam-
ples and increased search region size. Experiments show
that the novel ﬁlter optimization procedure outperforms
related approaches for constrained learning in DCFs.

Channel reliability is the second novelty the CSR-
DCF tracker introduces. The reliability is estimated
from the properties of the constrained least-squares so-
lution to ﬁlter design. The channel reliability scores
are used for weighting the per-channel ﬁlter responses
The CSR-DCF shows
in localization (Figure 1).
state-of-the-art performance on standard benchmarks –
OTB100 (Wu et al, 2015), VOT2015 (Kristan et al, 2015)
and VOT2016 (Kristan et al, 2015) while running close
to real-time on a single CPU. The spatial and channel re-
liability formulation is general and can be used in most
modern correlation ﬁlters, e.g. those using deep features.
The remainder of the paper is structured as follows. In
Section 2 we review most closely related work, our ap-
proach is described in Section 3, experimental results are
presented in Section 4 and conclusions are drawn in Sec-
tion 5.

2 Related work

The discriminative correlation ﬁlters for object detection
date back to the 80’s with seminal work of Hester and
Casasent (1980). They have been popularized only re-
cently in the tracking community, starting with the Bolme
et al (2010) MOSSE tracker. Using a gray-scale tem-

Figure 1: Overview of the CSR-DCF approach. An au-
tomatically estimated spatial reliability map restricts the
correlation ﬁlter to the parts suitable for tracking (top)
improving localization within a larger search region and
performance for irregularly shaped objects. Channel reli-
ability weights calculated in the constrained optimization
step of the correlation ﬁlter learning reduce the noise of
the weight-averaged ﬁlter response (bottom).

Kiani Galoogahi et al (2015) who propose zero-padding
the ﬁlter during learning and by Danelljan et al (2015a)
who introduce spatial regularization to penalize ﬁlter val-
ues outside the target boundaries. Both approaches train
from image regions much larger than the target and thus
increase the detection range.

Another limitation of the published DCF methods is the
assumption that the target shape is well approximated by
an axis-aligned rectangle. For irregularly shaped objects
or those with a hollow center, the ﬁlter eventually learns
the background, which may lead to drift and failure. The
same problem appears for approximately rectangular ob-
jects in the case of occlusion. The Kiani Galoogahi et al
(2015) and Danelljan et al (2015a) methods both suffer
from this problem.

In this paper we introduce the CSR-DCF, the Discrim-
inative Correlation Filter with Channel and Spatial Reli-
ability. The spatial reliability map adapts the ﬁlter sup-
port to the part of the object suitable for tracking which

2

get segmentation probability map. Danelljan et al (2016)
addressed a multiple-resolution feature map issue in cor-
relation ﬁlters by formulating ﬁlter learning in continu-
ous space, while Qi et al (2016) proposed a mechanism
to combine correlation responses from multiple convolu-
tional layers. A correlation ﬁlter tracker which is able to
handle drifts in longer sequences was proposed by Wang
et al (2016). It clusters similar target appearances together
and uses the clusters for target localization instead of a
single online learned ﬁlter.

Since most of the correlation ﬁlter trackers represent
the target with a single ﬁlter, it can easily get corrupted
when occlusion or a target deformation happen. In gen-
eral, part-based trackers are better in addressing these is-
sues. Therefore several part-based correlation ﬁlter meth-
ods were proposed. Liu et al (2015) use an efﬁcient
method to combine correlation outputs of multiple parts
and Liu et al (2016) proposed a tracking method for mod-
eling the target structure with multiple parts using multi-
ple correlation ﬁlters. Lukeˇziˇc et al (2017) treat the parts
correlation ﬁlter responses and their constellation con-
straints jointly as an equivalent spring system. They de-
rive a highly efﬁcient optimization to infer the most prob-
able target deformation.

Recently, Kiani Galoogahi et al (2015) addressed the
problem that occurs due to learning with circular correla-
tion from small training regions. They proposed a learn-
ing framework that artiﬁcially increases the ﬁlter size by
implicitly zero padding the ﬁlter. This reduces the bound-
ary artifacts by increasing the number of training exam-
ples in constrained ﬁlter learning. Danelljan et al (2015a)
reformulate the learning cost function to penalize non-
zero ﬁlter values outside the object bounding box. Per-
formance better than (Kiani Galoogahi et al, 2015) is re-
ported, but the learned ﬁlter is still a trade-off between
the correlation response and regularization, and it does
not guarantee that ﬁlter values are zero outside of object
bounding box.

3 Spatially constrained correlation

ﬁlters

The use of multiple channels in correlation ﬁlters (Hen-
riques et al, 2015; Danelljan et al, 2017; Galoogahi et al,

Figure 2: Tracking performance measured by the Ex-
pected Average Overlap (EAO) of the standard DCF and
our spatially constrained DCF (S-DCF) as a function of
search region size, expressed as the multiple of the target
size (right, x-axis). The ﬁlter is learned from a training re-
gion equal in size to the search region. The search region
sizes are visualized by black-white dashed rectangles (left
image) and the target bounding box is shown in yellow.

plate, MOSSE achieved state-of-the-art performance on a
tracking benchmark (Wu et al, 2013) at a remarkable pro-
cessing speed. Signiﬁcant improvements have been made
since and in 2014 the top-performing trackers on a recent
benchmark (Kristan et al, 2014) were all from this class of
trackers. DCF improvements fall into two categories, in-
troduction of new features and conceptual improvements
in ﬁlter learning.

In the ﬁrst group, Henriques et al (2015) replaced the
grayscale templates by HoG (Dalal and Triggs, 2005),
Danelljan et al (2014b) proposed multi-dimensional color
attributes and Li and Zhu (2014b) applied feature combi-
nation. Recently, convolutional network features learned
for object detection have been applied (Ma et al, 2015;
Danelljan et al, 2015b, 2016), leading to a performance
boost, but at a cost of signiﬁcant speed reduction.

Conceptually, the ﬁrst successful theoretical extension
of the standard DCF was the kernelized formulation by
Henriques et al (2015) which achieved remarkable track-
ing performance, but still preserved high speed. Later, a
correlation ﬁlter based scale adaptation was proposed by
Danelljan et al (2014a) introduced a scale-space pyramid
learned within a correlation ﬁlter framework. Zhang et al
(2014) introduced spatio-temporal context learning in the
DCFs. To improve localization with correlation ﬁlters,
Bertinetto et al (2016a) proposed a tracking method that
combines the output of the correlation ﬁlter with the tar-

3

In
2013) has become very popular in visual tracking.
the following we present the main ideas behind learn-
ing these ﬁlters. Given a set of Nc channel features
f = {fd}d=1:Nc and corresponding target templates (ﬁl-
ters) h = {hd}d=1:Nc , the object position is estimated
as the location of the maximum of correlation response
˜g(h),

Nc(cid:88)

˜g(h) =

fd (cid:63) hd.

(1)

d=1
The symbol (cid:63) represents circular correlation between fd ∈
Rcw×ch and hd ∈ Rcw×ch , where cw and ch are the train-
ing/search region width and height, respectively. The op-
timal correlation ﬁlter h is estimated by minimizing

Figure 3: Correlation responses of different feature chan-
nels (27 HoG, 10 colornames and one grayscale channel)
are summed to obtain the ﬁnal (single channel) correlation
response (middle). Note that maximum values of channel
responses may vary by orders of magnitude (right).

ε(h) = (cid:107)˜g(h) − g(cid:107)2 + λ(cid:107)h(cid:107)2,

(2)

where g is the desired output g ∈ Rcw×ch , which is typ-
ically a 2-D Gaussian function centered at the target lo-
cation. Efﬁcient tracking performance is achieved by ex-
pressing the cost (2) into the Fourier domain

ε(h) = (cid:107)

diag(ˆfd)ˆhd − ˆg(cid:107)2 + λ

(cid:107)ˆh(cid:107)2,

(3)

Nc(cid:88)

d=1

Nc(cid:88)

d=1

where the operator ˆa = vec(F[a]) is a Fourier transform
of a reshaped into a column vector, i.e., ˆa ∈ RD×1, with
D = cw · ch, diag(ˆa) being a D × D diagonal matrix
formed from ˆa and (·) is the complex-conjugate operator.
The closed-form solution for d-th ﬁlter channel ˆhd which
minimizes the cost function (3) is equal to

(cid:18)

(cid:19)

ˆhd =

diag(ˆfd)ˆg

(cid:12)−1

diag(ˆfd)ˆf d + λ

,

(4)

(cid:19)

(cid:18) Nc(cid:88)

d=1

where (cid:12)−1 is element-wise division. The solution (4)
considers all feature channels jointly and is used in most
of the recent correlation ﬁlter trackers. Note that the ﬁ-
nal response is obtained as summation over correlation
responses of all channels (1) and the location of the max-
imum in the ﬁnal response represents the new position of
the target.

Note that a ﬁlter for the d-th channel is computed in (4)
by dividing d-th feature with the sum over all feature
channels. This means that the feature scale crucially im-
pacts the level by which a channel contributes to the ﬁnal

response, irrespective of its discriminative power. Since
features (e.g., HoG, colornames and grayscale template)
vary in scale, some channels might suppress the others by
an order of magnitude. This is demonstrated in Figure 3
where each HoG channel on its own contributes to the ﬁ-
nal response very little.

To avoid the issue with different scales we consider
each channel independently. This means that each ﬁlter
channel is optimized to ﬁt the desired output separately.
The cost function is thus deﬁned as

ε(h) =

(cid:107)fd (cid:63) hd − g(cid:107)2 + λ(cid:107)hd(cid:107)2.

(5)

Nc(cid:88)

d=1

Additionally, we introduce channel weights w =
{ ˜wd}d=1:Nc which can be considered as scaling factors
based on the discriminative power of each feature chan-
nel. These weights are called channel reliability weights
in the rest of the paper and they are applied when correla-
tion response is calculated in the target localization stage:

˜g =

fd (cid:63) hd · ˜wd.

(6)

Nc(cid:88)

d=1

We present our method for constrained correlation ﬁlter
learning in Section 3.1. The most reliable parts of the ﬁl-
ter are identiﬁed by introducing the spatial reliability map
(Section 3.2). The method for channel reliability wd esti-
mation is presented in Section 3.3, the proposed tracker is
described in Section 3.4.

4

3.1 Constrained correlation ﬁlter learning

Since ﬁlter learning is independent across the channels
in our formulation (5), we assume only a single channel
in the following derivation (i.e., Nc = 1) and drop the
channel index for clarity.

Let m ∈ {0, 1} be a spatial reliability map with el-
ements either zero or one, that identiﬁes pixels which
should be set to zero in the learned ﬁlter. The constraint
can be formalized as h ≡ m (cid:12) h, where (cid:12) represents
the Hadamard (element-wise) product. Such constraint
does not lead to a closed-form solution, but an iterative ap-
proach akin to Kiani Galoogahi et al (2015) can be derived
In the
for efﬁciently solving the optimization problem.
following we summarize the main steps of our approach
and report the full derivation in Appendix 6.

We start by introducing a dual variable hc and the con-

straint

hc − m (cid:12) h ≡ 0,

leads

which
grangian (Boyd et al, 2011)

the

to

following

augmented La-

λ
2

L(ˆhc, h,ˆl|m) = (cid:107)diag(ˆf )ˆhc − ˆg(cid:107)2 +

(cid:107)hm(cid:107)2 + (8)

[ˆlH (ˆhc − ˆhm) + ˆlH (ˆhc − ˆhm)] + µ(cid:107)ˆhc − ˆhm(cid:107)2,

where ˆl is a complex Lagrange multiplier, µ > 0, and
we use the deﬁnition hm = (m (cid:12) h) for compact no-
tation. The augmented Lagrangian (8) can be iteratively
minimized by the alternating direction method of multi-
pliers, e.g. Boyd et al (2011), which sequentially solves
the following sub-problems at each iteration:

A standard scheme for updating the constraint penalty µ
values (Boyd et al, 2011) is applied, i.e., µi+1 = βµi.

Computations of (12,11) are fully carried out in the fre-
quency domain, the solution for (13) requires a single in-
verse FFT and another FFT to compute the ˆhi+1. A single
optimization iteration thus requires only two calls of the
Fourier transform, resulting in a very fast optimization.
The computational complexity is that of the Fourier trans-
form, i.e., O(D log D). Filter learning is implemented in
less than ﬁve lines of Matlab code and is summarized in
the Algorithm 1.

Algorithm 1 : Constrained ﬁlter optimization.
Require:

Features extracted from training region f , ideal corre-
lation response g,
binary mask m.

Ensure:

(7)

Optimized ﬁlter (cid:98)h.

Procedure:
1: Initialize ﬁlter (cid:98)h0 by ht−1.
2: Initialize Lagrangian coefﬁcients: (cid:98)l0 ← zeros.
3: while stop condition do
Calculate ˆhi+1
4:
c
Calculate hi+1 from ˆhi+1
Update the Lagrangian ˆli+1
hi+1 (11).

and ˆli using (13).
from ˆhi+1

from ˆhi and ˆli using (12).

6:

5:

c

c

7: end while

and

ˆhi+1

c = arg min

L(ˆhc, hi,ˆli|m),

hi+1 = arg min

L(ˆhi+1
c

, h,ˆli|m),

hc

h

and the Lagrange multiplier is updated as

ˆli+1 = ˆli + µ(ˆhi+1

c − ˆhi+1).

Minimizations in (9,10) have at each iteration a closed-
form solution, i.e.,

c = (cid:0)ˆf (cid:12) ˆg + (µˆhi
ˆhi+1

m − ˆli)(cid:1) (cid:12)−1 (cid:0)ˆf (cid:12) ˆf + µi(cid:1), (12)

hi+1 = m (cid:12) F −1(cid:2)ˆli + µi ˆhi+1

c

+ µi(cid:1).

(13)

(cid:3)/(cid:0) λ
2D

(9)

(10)

(11)

5

3.2 Constructing spatial reliability map

Once the target is localized, a training region is extracted
and used to update the ﬁlter. Our constrained ﬁlter learn-
ing (13) requires estimation of spatial reliability map m
(i.e., segmentation) that identiﬁes pixels in the training re-
gion which likely belong to the target (see Figure 4). In
the following we brieﬂy outline the segmentation model
which is used to estimate m.

During tracking,

the object foreground/background
color models are maintained as color histograms c =
i , yx
{cf , cb}. Let yi = [yc
i ] be the observation, i.e., the
color yc
i and position yx
i at i-th pixel in the training re-
gion and let mi ∈ {0, 1} be a random variable denot-
ing the unknown foreground/background label. The joint

Figure 4: Spatial reliability map construction from the training region. From left to right: a training region with
the target bounding box, t the foreground-background color models, the posterior object probability after Markov
random ﬁeld regularization, and the training region masked with the ﬁnal binary reliability map. The probabilities are
color-coded in a blue (0.0) – green (0.5) – yellow (1.0) colormap.

probability of observing yi is deﬁned as

3.2.1

Inference

1
(cid:88)

j=0

1
(cid:88)

j=0

p(yi) =

p(yi|mi = j)p(mi = j) =

(14)

=

p(yc

i |mi = j)p(yx

i |mi = j)p(mi = j),

i |mi = j), p(yx

where p(yc
i |mi = j) and p(mi = j) are
the appearance likelihood, the spatial likelihood and the
foreground/background prior probability. The appearance
likelihood term p(yc
i |mi = j) is computed by Bayes rule
from the object foreground/background color models cf
and cb. The prior probability p(mi = j) is deﬁned by the
ratio between the region sizes for foreground/background
histogram extraction.

The central pixels in axis-aligned approximations of an
elongated rotating, articulated or deformable object are
likely to contain the object regardless of the speciﬁc de-
formation. On the other hand, in the absence of measure-
ments, pixels away from the center belong to the object or
background equally likely. This deformation invariance
of central elements reliability is enforced in our approach
by deﬁning a weak spatial prior

p(yx

i |mi = j) = k(x; σ),

(15)

where k(x; σ) is a modiﬁed Epanechnikov kernel,
k(r; σ) = 1 − (r/σ)2, with size parameter σ equal to the
minor bounding box axis and clipped to interval [0.5, 0.9]
such that the object prior probability at center is 0.9 and
changes to a uniform prior away from the center (Fig-
ure 4).

In practice the likelihood p(yi|mi) is noisy and requires
regularization for our ﬁlter learning. We thus apply a
MRF from (Diplaros et al, 2007; Kristan et al, 2016a),
which treats the prior and posterior label distributions
over pixels as random variables and applies a MRF con-
straint over these. This formulation affords an efﬁcient
inference which avoids hard label assignment during op-
timization and can be implemented as a series of convo-
lutions.

The prior over the i-th pixel is deﬁned compactly
as πi = [πi0, πi1] with πij = p(mi = j) and
a standard approximation is made (Diplaros et al,
2007) that decomposes the joint pdf over priors π =
[π1, ..., πM ] into a product of local conditional distri-
butions p(π) = (cid:81)M
i=1 p(πi|πNi), where M is number
of pixels, πNi is a mixture distribution over the priors
of i-th pixel’s neighbors, i.e., πNi = (cid:80)
j∈Ni,j(cid:54)=i λijπj
and λij are ﬁxed weights satisfying (cid:80)
j λij = 1.
In
Diplaros et al (2007) the weights are ﬁxed to a nor-
malized Gaussian and are shared across all pixel lo-
The potentials in the MRF are deﬁned as
cations.
2 E(πi, πNi)(cid:1),with exponent
p(πi|πNi) ∝ exp (cid:0) − 1
deﬁned as E(πi, πNi ) = D(πi||πNi) + H(πi).The
term D(πi||πNi ) is the Kullback-Leibler divergence
which penalizes the difference between prior distribu-
tions over the neighboring pixels (πi and πNi), while
the term H(πi) is the entropy deﬁned as H(πi) =
− (cid:80)1
j=0 πij log πij,which penalizes uninformative priors
πi.

For smooth solutions Diplaros et al (2007) propose us-

6

ing a similar constraint over the posteriors pi = [pi0, pi1]
with pij being the posterior probability of class j at i-th
pixel, leading to the following energy function

F =

log p(yi) −

E(πi, πNi) + E(pi, pNi)

.

M
(cid:88)

(cid:20)

i=1

(cid:18)

1
2

(cid:19)(cid:21)

(16)
Minimization of the energy (16) w.r.t. π and p is efﬁ-
ciently solved by the solver from Diplaros et al (2007).
The ﬁnal mask m for learning the ﬁlter in Section 3.1 is
obtained by thresholding the posterior at 0.5.

3.3 Channel reliability estimation

Channel reliability ˜wd in (6) reﬂects the importance of
each channel at the target localization stage. In our ap-
proach it consists of two types of reliability measures:
(i) channel learning reliability ˜w(lrn)
, which is calculated
in the ﬁlter learning stage, and (ii) channel detection reli-
ability ˜w(det)
which is calculated in the target localization
stage. The joint channel reliability ˜wd in (6) at target lo-
calization stage is computed as the product of both relia-
bility measures, i.e.,

d

d

˜wd = ˜w(lrn)

d

· ˜w(det)
d

(17)

and normalized s.t. (cid:80)
are described in following paragraphs.

d ˜wd = 1. The reliability measures

Channel learning reliability. Constrained minimiza-
tion of (8) solves a least squares problem averaged over all
circular displacements of the ﬁlter on a feature channel.
A discriminative feature channel fd produces a ﬁlter hd
whose output fd ∗ hd nearly exactly ﬁts the ideal response
g. On the other hand, since the response is highly noisy on
channels with low discriminative power, a global error re-
duction in the least squares signiﬁcantly reduces the max-
imal response. This effect is demonstrated in Figure 5,
which shows correlation responses for a highly discrimi-
native and non-discriminative channels. Thus a straight-
forward measure of channel learning reliability ˜w(lrn)
is
the maximum response value of a learned channel ﬁlter,
which is computed as

d

˜w(lrn)

d = max(fd ∗ hd).

(18)

Figure 5: A ﬁlter is learned on feature channels from a
training region using the constrained optimization with a
binary segmentation mask m. Correlation responses be-
tween the learned ﬁlter and the training region for two
feature channels are shown on the right. On a discrimi-
native feature channel the ﬁlter response is much stronger
and less noisy than on a non-discriminative channel.

Channel detection reliability. The second part of
the channel reliability reﬂects how uniquely each chan-
nel votes for a single target location. Note that Bolme
et al (2010) proposed a similar approach to detect loss
of target. Our measure is based on the ratio between the
second and ﬁrst highest non-adjacent peaks in the chan-
nel response map, i.e., 1 − ρmax2
. The two largest
d
peaks in the response map are obtained as two largest val-
ues after a 3×3 non-maximum suppression. Note that this
ratio penalizes situations in which multiple similar objects
appear in the target vicinity (i.e., response map contains
many well expressed modes), even if the major mode ac-
curately depicts the target position. To mitigate such pe-
nalizations, the ﬁnal values are note allowed to fall below
0.5. The detection reliability of d-th channel is estimated
as

/ρmax1
d

˜w(det)
d

= max(1 − ρmax2

d

/ρmax1
d

, 0.5).

(19)

3.4 Tracking with channel and spatial reli-

ability

A single tracking iteration of the proposed channel and
spatial reliability correlation ﬁlter tracker (CSR-DCF) is
summarized in Algorithm 2 and visualized in Figure 6.
The localization and update steps proceed as follows.

7

Figure 6: The CSR-DCF tracking iteration: localization step is shown on the left and update step on the right side of
the image.

Localization step. Features are extracted from a search
region centered at the target estimated position in the
previous time-step and correlated with the learned ﬁlter
ht−1. The object is localized by summing the corre-
lation responses weighted by the estimated channel re-
liability scores wt−1. The scale is estimated by a sin-
gle scale-space correlation ﬁlter as in Danelljan et al
(2014a). Per-channel ﬁlter responses are used to compute
the corresponding detection reliability values ˜w(det) =
[ ˜w(det)
]T according to (19).
1

, . . . , ˜w(det)

Nc

Update step. The training region is centered at the tar-
get location estimated at localization step. The foreground
and background histograms ˜c are extracted and updated
by exponential moving average with learning rate ηc (step
5 in Algorithm 2). The foreground histogram is extracted
by an Epanechnikov kernel within the estimated object
bounding box and the background is extracted from the
neighborhood twice the object size. The spatial reliability
map m (Sect. 3.2) is constructed and the optimal ﬁlters ˜h
are computed by optimizing (8). The per-channel learning
reliability weights ˜w(lrn) = [ ˜w(lrn)
]T are esti-
mated from the correlation responses (18). Current frame
reliability weights ˜w are computed from detection and

, . . . , ˜w(lrn)

Nc

1

learning reliability (17). The ﬁlters and channel reliability
weights are updated by exponential moving average (cur-
rent and from previous frame) with learning rate η (steps
10 and 11 in the Algorithm 2). Note that we compute
the spatial reliability map in each frame independently to
capture large target appearance changes, e.g. caused by
rotation or deformation.

3.5 Comparison with prior work

Kiani Galoogahi et al (2015) and Danelljan et al (2015a)
have previously considered constrained ﬁlter learning.
Here we highlight the differences of our approach.

The LBCF tracker (Kiani Galoogahi et al, 2015) ad-
dresses the circular boundary effect of the Fourier trans-
form and implicitly increases the ﬁlter search region size.
In contrast, the CSR-DCF primarily reduces the impact
of the background in the ﬁlter. The solution of Kiani Ga-
loogahi et al (2015) is similar to our ﬁlter optimization,
but it is derived for a rectangular mask only. Since ro-
tating and deformable targets are poorly approximated by
an axis-aligned bounding box their ﬁlter is contaminated
by background leading to a reduced performance. The
LBCF updates the auto-spectral and cross-spectral ener-

8

Algorithm 2 : The CSR-DCF tracking algorithm.
Require:

Image It, object position on previous frame pt−1,
scale st−1, ﬁlter ht−1, color histograms ct−1, chan-
nel reliability wt−1.

Ensure:

Position pt, scale st and updated models.

Localization and scale estimation:

1: New target location pt: position of the maximum in
correlation between ht−1 and image patch features f
extracted on position pt−1 and weighted by the chan-
nel reliability scores w (Sect. 3.3).

2: Using per-channel responses, estimate detection reli-

ability ˜w(det) (Sect. 3.3).

3: Using location pt, estimate new scale st.

4: Extract foreground and background histograms ˜cf ,

Update:

˜cb.

5: Update foreground and background histograms
t−1 + ηc˜cf , cb

t = (1 − ηc)cf
cf

t = (1 − ηc)cb

t−1 + ηc˜cb.

6: Estimate reliability map m (Sect. 3.2).
7: Estimate a new ﬁlter ˜h using m (Algorithm 1).
8: Estimate learning channel reliability ˜w(lrn) from h

(Sect. 3.3).

9: Calculate channel reliability ˜w = ˜w(lrn) (cid:12) ˜w(det)
10: Update ﬁlter ht = (1 − η)ht−1 + η ˜h.
11: Update channel reliability wt = (1 − η)wt−1 + η ˜w.

gies (ˆf (cid:12) ˆf and ˆf (cid:12) ˆg in (12)) separately, which approxi-
mates computation of a single ﬁlter from a weighted sum
of errors over past training samples. This adaptation is
reasonable since it is derived for a rectangular mask that
remains constant throughout tracking. The CSR-DCF es-
timates the mask separately for each training sample and
learns a corresponding ﬁlter. For articulated objects in
particular the mask varies signiﬁcantly with time, there-
fore it is beneﬁcial to compute the exact ﬁlter for each
frame. Robustness is increased by moderately averaging
the ﬁlters temporally.

Similarly to our approach, the SRDCF (Danelljan et al,
2015a) uses a spatial map in ﬁlter learning. In contrast
to our approach, their map does not adapt to the target
and is required to be highly smooth for their optimization

to converge. In CSR-DCF the map serves as a hard con-
straint resulting in a ﬁlter with values off the target set
to zero. In contrast, the SRDCF (Danelljan et al, 2015a)
ﬁlter is a compromise between target position regression
and a penalty term that prefers potentially non-zero val-
ues in the ﬁlter center and close-to-zero values away from
the center, but does not guarantee zero values outside the
mask.

4 Experimental analysis

This section presents a comprehensive experimental eval-
uation of the CSR-DCF tracker. Implementation details
are discussed in Section 4.1, convergence of the ﬁlter
optimization method is presented in Section 4.2, Sec-
tion 4.3 reports comparison of the proposed constrained
learning to the related state-of-the-art and the ablation
study is provided in Section 4.4. Tracking performance
on three recent benchmarks: OTB-100 (Wu et al, 2015),
VOT2015 (Kristan et al, 2015) and VOT2016 (Kristan
et al, 2016b) is reported in Sections 4.6, 4.7 and 4.8, re-
spectively. The detailed analysis of the tracker, includ-
ing per-attribute tracking performance is presented in Sec-
tion 4.9 and tracking speed analysis in Section 4.10.

4.1

Implementation details and parameters

A popular implementation Felzenszwalb et al (2010) of
the standard HoG (Dalal and Triggs, 2005) and Color-
names (van de Weijer et al, 2009) features are used in the
correlation ﬁlter and HSV foreground/background color
histograms with 16 bins per color channel are used in re-
liability map estimation with parameter αmin = 0.05. All
the parameters are set to values commonly used in litera-
ture (Danelljan et al, 2015a; Kiani Galoogahi et al, 2015).
Histogram adaptation rate is set to ηc = 0.04, correlation
ﬁlter adaptation rate is set to η = 0.02, and the regu-
larization parameter is set to λ = 0.01. The augmented
Lagrangian optimization parameters are set to µ0 = 5 and
β = 3. All parameters have a straight-forward interpre-
tation, do not require ﬁne-tuning, and were kept constant
throughout all experiments. Our Matlab implementation1

1The CSR-DCF Matlab source is publicly available on:

https://github.com/alanlukezic/csr-dcf

9

runs at 13 frames per second on an Intel Core i7 3.4GHz
standard desktop.

4.2 Convergence of constrained learning

The constrained ﬁlter learning described in Section 3.1 is
an iterative optimization method that minimizes the cost
function (8). This experiment demonstrates how the cost
changes with the number of iterations during ﬁlter opti-
mization.

Figure 7 shows the average squared difference between
the result of the correlation of the ﬁlter constrained by the
spatially constrained function and the ideal output. This
graph was obtained by averaging 60 examples of initial-
izing a ﬁlter on a target (one per VOT2015 sequence) and
scaling each to an interval between zero and one.
It is
clear that the error drops by 80% within the ﬁrst few it-
erations. Already after four iterations, the performance
improvements become negligible, therefore we set num-
ber of iterations to N = 4.

Figure 7: Convergence speed of constrained ﬁlter learning
from Section 3.1 shown as a relative drop of the initial
cost.

4.3

Impact of the boundary constraint for-
mulation

This section compares our proposed boundary constraints
formulation (Sect. 3) with recent state-of-the-art ap-
proaches (Danelljan et al, 2015a; Kiani Galoogahi et al,
2015). In the ﬁrst experiment, three variants of the stan-
dard single-scale HoG-based correlation ﬁlter were im-

10

plemented to emphasize the difference in boundary con-
straints: the ﬁrst uses our spatial reliability boundary con-
straint formulation from Section 3 (TSC) the second ap-
plies the spatial regularization constraint (Danelljan et al,
2015a) (TSR) and the third applies the limited boundaries
constraint (Kiani Galoogahi et al, 2015) (TLB).

The three variants were compared on the challenging
VOT2015 dataset (Kristan et al, 2015) by applying a stan-
dard no-reset one-pass evaluation from OTB (Wu et al,
2013) and computing the AUC on the success plot. The
tracker with our constraint formulation TSC achieved 0.32
AUC, while the alternatives achieved 0.28 (TSR) and 0.16
(TLB). The only difference between these tackers is in the
constraint formulation, which indicates superiority of the
proposed spatial-reliability-based constraints formulation
over the recent alternatives (Kiani Galoogahi et al, 2015;
Danelljan et al, 2015a).

4.3.1 Robustness to non-axis-aligned target initial-

ization

The CSR-DCF tracker from Section 3 was compared
to the original recent state-of-the-art trackers SRDCF
(Danelljan et al, 2015a) and LBCF (Kiani Galoogahi et al,
2015) that apply alternative boundary constraints. For
fair comparison, the source code of SRDCF and LBCF
was obtained from the authors, all three trackers used
only HoG features and tracked on the same single scale.
An experiment was designed to evaluate initialization and
tracking of non axis-aligned targets, which is the case for
most realistic deforming and non-circular objects. Track-
ers were initialized on frames with non-axis aligned tar-
gets and left to track until the sequence end, resulting in a
large number of tracking trajectories.

The VOT2015 dataset (Kristan et al, 2015) contains
non-axis-aligned annotations, which allows automatic
identiﬁcation of tracker initialization frames, i.e., frames
in which the ground truth bounding box signiﬁcantly de-
viates from an axis-aligned approximation. Frames with
overlap (intersection over union of predicted and ground-
truth bounding boxes) of the ground truth and the axis-
aligned approximation lower than 0.5 were identiﬁed and
ﬁltered to obtain a set of initialization frames at least hun-
dred frames apart. This constraint ﬁts half the typical
short-term sequence length (Kristan et al, 2015) and re-
duces the potential correlation across the initializations

Figure 9: Qualitative results for trackers CSR-DCF (red)
tracker, SRDCF (blue) and LBCF (green).

by the average tracking length (number of frames before
the overlap drops to zero) weighted by trajectory lengths.
The weighted average tracking lengths in frames, Γfrm,
and proportions of full trajectory lengths, Γprp, are shown
in Table 1. The CSR-DCF by far outperforms SRDCF and
LBCF in all measures indicating signiﬁcant robustness in
the initialization of challenging targets that deviate from
axis-aligned templates. This improvement is further con-
ﬁrmed by the graph in Figure 8 (top-right) which shows
the OTB success plots (Wu et al, 2013) calculated on these
trajectories and summarized by the AUC values, which
are equal to the average overlaps ( ˇCehovin et al, 2016).
Table 1 shows the average overlaps computed on the orig-
inal ground truth on VOT2015 (Φrot) and on ground truth
approximated by the axis-aligned bounding box (Φaa).
Again, the CSR-DCF by far outperforms the competing
alternatives SRDCF and LBCF. Tracking examples for the
three trackers are shown in Figure 9.

In summary, the results show that the quality of spatial
constraints signiﬁcantly affects the relative tracking per-
formance when a large portion of the training region in
the target vicinity is occupied by background. The rela-
tive performance of LBCF (Kiani Galoogahi et al, 2015)
is lowest among the three trackers since this tracker treats
all pixels within axis-aligned bounding box equally as tar-
get. The SRDCF (Danelljan et al, 2015a) mostly focuses
on the central pixels of the training region and suppresses
the ﬁlter values at the borders, thus outperforming the
LBCF (Kiani Galoogahi et al, 2015). The spatial relia-
bility map in CSR-DCF most successfully reduces the in-

Figure 8: The number of trajectories with tracking suc-
cessful up to frame Θfrm (upper left), the success plots
(upper right) and initialization examples of non-axis-
aligned targets (bottom).

Table 1: Comparison of three most related trackers on
non-axis-aligned initialization experiment: weighted av-
erage tracking length in frames Γfrm and proportions
Γprp, and weighted average overlaps using the original
and axis-aligned ground truth, Φrot and Φaa, respectively.

Tracker
CSR-DCF
SRDCF (ICCV2015)
LBCF (CVPR2015)

Γprp
1 0.58
2 0.31
3 0.12

Γfrm
1 221
95
2
37
3

Φaa
1 0.31
2 0.16
3 0.06

Φrot
1 0.24
2 0.12
3 0.04

(see Figure 8 (bottom) for examples).

Initialization robustness is estimated by counting the
number of trajectories in which the tracker was still track-
ing (overlap with ground truth greater than 0) Θfrm frames
after initialization. The graph in Figure 8 (top-left) shows
these values with increasing the threshold Θfrm. The
CSR-DCF graph is consistently above the SRDCF and
LBCF for all thresholds. The performance is summarized

11

ﬂuence of background in ﬁlter learning resulting in con-
siderable robustness to poor initializations.

4.4 Spatial and channel reliability ablation

study

An ablation study on VOT2016 was conducted to eval-
uate the contribution of spatial and channel reliability in
CSR-DCF. Results of the VOT primary measure expected
average overlap (EAO) and two supplementary measures
accuracy and robustness (A,R) are summarized in Table 2.
For the details of performance measures and evaluation
protocol we refer the reader to the Section 4.7. Perfor-
mance of the various modiﬁcations of CSR-DCF is dis-
cussed in the following.
Channel reliability weights. Setting the channel relia-
bility weights to uniform values (CSR-DCFc− ) is equiv-
alent to treating all channels as independent and equally
important. The performance drop in EAO compared to
CSR-DCF is 12%.
Spatial reliability map. Replacing the spatial reliability
map in CSR-CDF by a constant map with uniform val-
ues within the bounding box and zeros elsewhere (CSR-
DCFsu ), results in a 21% drop in EAO. The other parts
of the tracker remained unchanged in this experiment, in-
cluding the channel reliability. This clearly shows the im-
portance of our segmentation-based spatial reliability map
estimation from Section 3.2.
Channel and spatial reliability. Making both replace-
ments in the original tracker means that this version
(CSR-DCFc−su) does not use channel reliability weights
and it uses uniform spatial reliability map (uniform values
within the bounding box and zeros elsewhere). The per-
formance drops by 24% compared to CSR-DCF. Removal
of the uniform spatial reliability map from CSR-DCFc−su
results in the CSR-DCFc−s− . This version reduces our
tracker to a standard DCF with a large receptive ﬁeld.
Since the learned ﬁlter captures a signiﬁcant amount of
background, the performance drops by over 50%.
ADMM Filter optimization method. To demonstrate
the importance of the constrained optimization method we
modify the proposed tracker as follows. The ﬁlter h is cal-
culated with a naive approach, i.e., a closed-form solution
followed by masking with the spatial reliability map m:
ˆh = F(F −1(ˆh) (cid:12) m). For a fair comparison the tracker,

Table 2: Ablation study of CSR-DCF. The use of channel
reliability is indicated in the Chan. column, the the type
of spatial reliability map in the Spat. column. The Opt.
column indicates whether the constrained optimization is
used.

Tracker
CSR-DCF
CSR-DCFc−
CSR-DCFsu
CSR-DCFc−su
CSR-DCFc−o−
CSR-DCFc−s−

Chan. Spat. Opt. EAO

x
–
x
–
–
–

segm. x
segm. x
x
unif.
unif.
x
segm. –
–

–

Aav

Rav
1 0.338 1 0.85 1 0.51
2 0.297 2 1.08 2 0.51
3 0.264 3 1.18 3 0.49
1.33 2 0.51
1.47 2 0.51
0.47
2.85

0.256
0.251
0.152

denoted as CSR-DCFc−o− , does not use channel reliabil-
ity weights. The performance drop in EAO compared to
CSR-DCFc− is 15%.

4.5 Spatial reliability map quality analysis

In this section we evaluate the quality of our spatial reli-
ability map estimation (Section 3.2) from a visual track-
ing perspective. We compare the CSR-DCF tracker with
the version of CSR-DCF that uses ideal spatial reliabil-
ity map (the tracker is denoted as CSR*-DCF). In the
VOT2016 challenge (Kristan et al, 2016b), the ground
truth bounding boxes were automatically computed by
optimizing coverage over manually segmented targets in
each frame. The VOT2016 has recently made their per-
frame segmentations freely available (Vojir and Matas,
2017). We use these per-frame segmentation masks in
CSR*-DCF as spatial reliability map m.

Results of evaluation on VOT2016 (Kristan et al,
2016b) are reported in Table 3. The performances of the
CSR-DCF and CSR*-DCF are very similar. The track-
ers achieve an equal expected average overlap (EAO) and
average accuracy (Aav). But the CSR*-DCF has a sin-
gle failure less than CSR-DCF on 60 sequences which is
0.02 on average. In Table 3 the average number of fail-
ures is denoted as robustness (Rav). These results show
that our approach for spatial reliability estimation (Sec-
tion 3.2) generates near ideal maps from a tracking per-
spective.

Figure 10 qualitatively compares the spatial reliabil-

12

Table 3: Tracking performance comparison of the two
versions of CSR-DCF on VOT2016.
The proposed
method is denoted as CSR-DCF while the version using
ground-truth segmentation masks instead of color-based
spatial reliability map is denoted as CSR*-DCF.

Tracker
CSR-DCF
CSR*-DCF

EAO
0.338
0.338

Aav
0.51
0.51

Rav
0.85
0.83

the maps are different. But from the perspective of track-
ing they are nearly equivalent since the tracking perfor-
mance remains unchanged. For example, in the case of a
basketball player, the legs are not well segmented by our
approach. But since the legs constantly move, they are in
fact non-informative for object localization from the per-
spective of the correlation ﬁlter template matching and do
not contribute to improved tracking.

4.6 The OTB100 benchmark (Wu et al,

2015)

The OTB100 (Wu et al, 2015) benchmark contains re-
sults of 29 trackers evaluated on 100 sequences by a no-
reset evaluation protocol. Tracking quality is measured by
precision and success plots. The success plot shows the
fraction of frames with the overlap between th epredicted
and ground truth bounding box greater than a threshold
with respect to all threshold values. The precision plot
shows similar statistics on the center error. The results are
summarized by areas under these plots. To reduce clut-
ter, we show here only the results for top-performing re-
cent baselines, i.e., Struck (Hare et al, 2011), TLD (Kalal
et al, 2012), CXT (Dinh et al, 2011), ASLA (Xu Jia,
2012), SCM (Wei Zhong, 2012), LSK (Liu et al, 2011),
CSK (Henriques et al, 2012) and results for recent top-
performing state-of-the-art trackers SRDCF (Danelljan
et al, 2015a) and MUSTER (Hong et al, 2015).

The CSR-DCF is ranked top on the benchmark
(Fig. 11). It signiﬁcantly outperforms the best perform-
ers reported in (Wu et al, 2015) and outperforms the
current state-of-the-art SRDCF (Danelljan et al, 2015a)
and MUSTER (Hong et al, 2015). The average CSR-
DCF performance on success plot is slightly lower than
SRDCF (Danelljan et al, 2015a) due to poorer scale esti-
mation, but yields better performance in the average preci-
sion (center error). Both, precision and success plot, show
that the CSR-DCF tracks on average longer than compet-
ing methods.

4.7 The VOT2015 benchmark (Kristan

et al, 2015)

Figure 10: Qualitative comparison of the spatial reliabil-
ity maps during tracking. The dashed bounding box rep-
resents area from which correlation ﬁlter is obtained. This
is also the area where spatial reliability map is calculated.
In addition, the ground-truth segmentation masks are vi-
sualized on the right side under each frame.

ity maps to the ground-truth segmentation masks on
VOT2016 (Kristan et al, 2016b). Note that at pixel level,

The VOT2015 (Kristan et al, 2015) benchmark contains
results of 63 state-of-the-art trackers evaluated on 60 chal-

13

Figure 11: Evaluation on OTB100 (Wu et al, 2015) bench-
mark.

In contrast to related benchmarks,
lenging sequences.
the VOT2015 dataset was constructed from over 300 se-
quences by an advanced sequence selection methodology
that favors objects difﬁcult to track and maximizes a vi-
sual attribute diversity cost function (Kristan et al, 2015).
This makes it arguably the most challenging sequence set
available. The VOT methodology (Kristan et al, 2016c)
resets a tracker upon failure to fully use the dataset. The
basic VOT measures are the number of failures during
tracking (robustness) and average overlap during the pe-
riods of successful tracking (accuracy), while the primary
VOT2015 measure is the expected average overlap (EAO)
on short-term sequences. The latter can be thought of
as the expected no-reset average overlap (AUC in OTB
methodology), but with reduced bias and the variance as
explained in (Kristan et al, 2015).

Figure 12 shows the VOT EAO plots with the CSR-
DCF and the VOT2015 state-of-the-art approaches con-
sidering the VOT2016 rules that do not consider track-
ers learned on video sequences related to VOT to pre-
vent over-ﬁtting. The CSR-DCF outperforms all track-
ers and achieves the top rank. The CSR-DCF signiﬁ-
cantly outperforms the related correlation ﬁlter trackers
like SRDCF (Danelljan et al, 2015a) as well as trackers
that apply computationally-intesive state-of-the-art deep
features e.g., deepSRDCF (Danelljan et al, 2015b) and
SO-DLT (Wang et al, 2015b). For completeness, detailed
results for the ten top-performing trackers are shown in
Table 4.

Figure 12: Expected average overlap (EAO) plot for
CSR-DSF (#1) and all trackers participating in the VOT
2015 (Kristan et al, 2015) benchmark listed below the plot
in alphabetical order with their numerical codes.

Table 4: The ten top-performing trackers on the VOT2015
benchmark.

Tracker
CSR-DCF
DeepSRDCF
EBT
srdcf
LDP
sPST
scebt
nsamf
struck
rajssc

EAO
1 0.320
2 0.318
3 0.313
0.288
0.278
0.277
0.255
0.254
0.246
0.242

Aav
3 0.55
2 0.56
0.45
3 0.55
0.49
0.54
0.54
0.53
0.46
1 0.57

Rav
2 0.93
3 1.00
1 0.81
1.18
1.30
1.42
1.72
1.45
1.50
1.75

4.8 The VOT2016 benchmark (Kristan

et al, 2016b)

Finally, we assess our tracker on the most recent visual
tracking benchmark, VOT2016 (Kristan et al, 2016b).
The dataset contains 60 sequences from VOT2015 (Kris-

14

performing trackers come from various classes e.g., cor-
relation ﬁlter methods: CCOT (Danelljan et al, 2016),
Staple (Bertinetto et al, 2016a), DDC (Kristan et al,
2016b), deep convolutional network based: TCNN (Kris-
tan et al, 2016b), SSAT (Kristan et al, 2016b; Nam and
Han, 2016), MLDF (Kristan et al, 2016b; Wang et al,
2015a), FastSiamnet (Bertinetto et al, 2016b) and differ-
ent detection-based approaches: EBT (Zhu et al, 2016)
and SRBT (Kristan et al, 2016b).

Figure 13 shows the EAO performance on the
VOT2016. The CSR-DCF outperforms all 70 trackers
with the EAO score equal to 0.338. The CSR-DCF signif-
icantly outperforms correlation ﬁlter approaches that do
not apply deep ConvNets. Even though the CSR-DCF ap-
plies only simple features, it outperforms all trackers that
apply computationally intensive deep features. Detailed
performance scores for the ten top-performing trackers
are shown in Table 5.

4.9 Per-attribute analysis

The VOT2016 (Kristan et al, 2016b) dataset is per-frame
annotated with visual attributes and allows detailed anal-
ysis of per-attribute tracking performance. Figure 14
shows per-attribute plot for ten top-performing trackers on
VOT2016 in EAO. The CSR-DCF is consistently ranked
among top three trackers on ﬁve out of six attributes. In
four attributes (size change, occlusion, camera motion,
unassigned) the tracker is ranked top. The only attribute
on which our CSR-DCF is outperformed by four of the
compared trackers (MLDF, CCOT, SSAT and TCNN) is
illumination change. All of these trackers use deep CNN
features which are much more complex than the features
in CSR-DCF and better handle illumination change.

4.10 Tracking speed analysis

Tracking speed is an important factor of many real-world
tracking problems. Table 6 thus compares several related
and well-known trackers (including the best-performing
tracker on the VOT2016 challenge) in terms of speed and
VOT performance measures. Speed measurements on a
single CPU are computed on Intel Core i7 3.4GHz stan-
dard desktop.

The CSR-DCF performs on par with the VOT2016
best-performing CCOT (Danelljan et al, 2016), which

Figure 13: Expected average overlap (EAO) plot for
CSR-DSF (#1) and all trackers participating in the VOT
2016 (Kristan et al, 2016b) benchmark listed below the
plot in alphabetical order with their numerical codes.

Table 5: The ten top-performing trackers on the VOT2016
benchmark.

Tracker
CSR-DCF
CCOT
TCNN
SSAT
MLDF
Staple
DDC
EBT
SRBT
STAPLEp

EAO
1 0.338
2 0.331
3 0.325
0.321
0.311
0.295
0.293
0.291
0.290
0.286

Aav
0.51
0.52
3 0.54
1 0.57
0.48
3 0.54
0.53
0.44
0.50
2 0.55

Rav
2 0.85
2 0.85
0.96
1.04
1 0.83
1.35
1.23
3 0.90
1.25
1.32

tan et al, 2015) with improved annotations. The bench-
mark evaluated a set of 70 trackers which includes
the recently published and yet unpublished state-of-
the top-
the-art trackers. The set is indeed diverse,

15

Table 6: Speed in frames per second (fps) of correlation
trackers and Struck – a baseline. The EAO, average accu-
racy (Aav) and average failures (Rav) are shown for ref-
erence.

Tracker

ECCV2016

CSR-DCF
CCOT
CCOT* ECCV2016
SRDCF ICCV2015
KCF
DSST
Struck

PAMI2015

PAMI2016

ICCV2011

fps

Aav

Rav

EAO
1 0.338 2 0.51 1 0.85 3
2 0.331 1 0.52 1 0.85
3 0.274 1 0.52 2 1.18
0.247 1 0.52 3 1.50
0.192 3 0.48
0.181 3 0.48
0.42
0.142

13.0
0.6
1.0
7.3
2.03 1 115.7
18.6
2.52 2
8.5
3.37

The average speed of our tracker measured on the VOT
2016 dataset is approximately 13 frames-per-second2 or
77 milliseconds per-frame. Figure 15 shows the process-
ing time required by each step of the CSR-DCF. A track-
ing iteration is divided into two steps: (i) target localiza-
tion and (ii) the visual model update. Target localization
takes in average 35 milliseconds at each frame and is com-
posed of two sub-steps: estimation of object translation
(23ms) and scale change estimation (12ms). The visual
model update step takes on average 42 milliseconds. It
consists of three sub-steps: spatial reliability map estima-
tion (16ms), ﬁlter update (12ms) and scale model update
(14ms). Filter optimization, which is part of the ﬁlter up-
date step, takes on average 7 milliseconds.

4.11 Qualitative evaluation

Figure 16 shows four examples of tracking with the CSR-
DCF. In the following we describe tracking performance
on each sequence.

The ﬁrst example shows tracking of an octopus along
with channel reliability weights.
The ﬁrst eighteen
weights correspond to HoG channels, the 19th weight is
reliability of a grayscale template and the last ten weights
correspond to colornames. Note that the colors in boxes
are not the actual colors of the colornames, because these
features are subspace of original colornames, designed to

2With some basic code optimization and refactoring we speed-up our
algorithm to 19 FPS without signiﬁcant performance drop (only one ad-
ditional failure on VOT2016 dataset).

Figure 14: Expected averaged overlap performance on
different visual attributes on the VOT2016 (Kristan et al,
2016b) benchmark. The CSR-DCF and the top 10 per-
forming trackers from VOT2016 are shown. The scales
of visual attribute axes are shown below the attribute la-
bels.

applies deep ConvNets, with respect to VOT measures,
while being 20 times faster than the CCOT. The CCOT
was modiﬁed by replacing the computationally intensive
deep features with the same simple features used in CSR-
DCF. The resulting tracker, indicated by CCOT*, is still
ten times slower than CSR-DCF, while the performance
drops by over 15%. The CSR-DCF performs twice as
fast as the related SRDCF (Danelljan et al, 2015a), while
achieving approximately 25% better tracking results. The
speed of baseline real-time trackers like DSST (Danelljan
et al, 2014a) and Struck (Hare et al, 2011) is compara-
ble to CSR-DCF, but their tracking performance is signif-
icantly poorer. The fastest compared tracker, KCF (Hen-
riques et al, 2015) runs much faster than real-time, but de-
livers a signiﬁcantly poorer performance than CSR-DCF.
The experiments show that the CSR-DCF tracks com-
parably to the state-of-the-art trackers which apply com-
putationally demanding high-dimensional features, but
runs considerably faster and delivers top tracking perfor-
mance among the real-time trackers.

16

5 Conclusion

The Discriminative Correlation Filter with Channel and
Spatial Reliability (CSR-DCF) was introduced. The spa-
tial reliability map adapts the ﬁlter support to the part
of the object suitable for tracking which overcomes both
the problems of circular shift enabling an arbitrary search
region size and the limitations related to the rectangu-
lar shape assumption. A novel efﬁcient spatial reliability
map estimation method was proposed and an efﬁcient op-
timization procedure was used for learning a correlation
ﬁlter with the support constrained by the estimated map.
The second novelty of CSR-DCF is the channel reliabil-
ity. The reliability is estimated from the properties of the
constrained least-squares solution. The channel reliabil-
ity scores were used for weighting the per-channel ﬁlter
responses in localization.

Experimental comparison with recent related state-of-
the-art boundary-constraints formulations showed signif-
icant beneﬁts of using our formulation. The CSR-DCF
achieves state-of-the-art performance on standard bench-
marks: OTB100 (Wu et al, 2015), VOT2015 (Kristan et al,
2015) and VOT2016 (Kristan et al, 2016b) while run-
ning close to the real-time on a single CPU. Despite using
simple features like HoG and Colornames, the CSR-DCF
performs on par with trackers that apply computationally
complex deep ConvNet, but is signiﬁcantly faster.

To the best of our knowledge, the proposed approach
is the ﬁrst of its kind to introduce constrained ﬁlter learn-
ing with arbitrary spatial reliability map and the use of
channel reliabilities. The spatial and channel reliability
formulation is general and can be used in most modern
correlation ﬁlters, e.g. those using deep features.

6 Appendix 1: Derivation of the
augmented Lagrangian mini-
mizer

This section provides a complete derivation of the rela-
tions (12, 13) in the Section 3.1. The augmented La-

17

Figure 15: A single iteration processing time decomposed
across the main steps of the CSR-DCF.

improve correlation ﬁlter tracking (see (Danelljan et al,
2014b)). Observe that when the octopus changes shape
signiﬁcantly, some channels become more discriminative
than the others – this is particularly evident in the ﬁrst
eighteen channels that represent the HoG features.

Tracking a gymnast is shown in the second example.
The target is deforming and rotating over the sequence
signiﬁcantly, while our tracker is able to successfully
track it. Additionally, the correlation response from the
localization step is shown for each frame. The peak in
the response is well expressed, which means that the ﬁlter
accurately represents the target and that the discrimina-
tive channels overrule the less discriminative ones by our
channel reliability estimation approach.

The third example shows tracking a sprinter. The spa-
tial reliability map is visualized next to each frame. In
the bottom-right corner of each frame the tracking patch
is overlaid with the spatial reliability map. The reliability
maps ﬁt the target well and prevent the ﬁlter from learning
the background.

The last example shows tracking under occlusion, i.e.,
a motorcyclist driving on the road while being repeatedly
occluded by the trees. This example demonstrates that
our tracker is robust to short-term full occlusions and that
it is able to recover and localize the target despite the full
occlusion. This is possible due to the robust learning with
channel and spatial reliability map and the large capture
range that our learning scheme provides.

grangian from Equation (8) is

The partial complex gradients are:

L(ˆhc, h,ˆl) = (cid:107)diag(ˆf )ˆhc − ˆg(cid:107)2 +

(cid:107)hm(cid:107)2 + (20)

λ
2

[ˆlH (ˆhc − ˆhm) + ˆlH (ˆhc − ˆhm)] + µ(cid:107)ˆhc − ˆhm(cid:107)2,

with hm = (m (cid:12) h). For the purposes of derivation we
will rewrite (20) into a fully vectorized form

L(ˆhc, h,ˆl) = (cid:107)diag(ˆf )ˆhc − ˆg(cid:107)2 +
(cid:20)
ˆlH (ˆhc −

DFMh) + ˆlH (ˆhc −
√

√

µ(cid:107)ˆhc −

DFMh(cid:107)2,

λ
2
√

(cid:107)hm(cid:107)2+ (21)
(cid:21)

DFMh)

+

where F denotes D × D orthonormal matrix of Fourier
coefﬁcients, such that the Fourier transform is deﬁned as
ˆx = F(x) =
DFx and M = diag(m). For clearer
representation we denote the four terms in the summation
(21) as

√

L(ˆhc, h,ˆl) = L1 + L2 + L3 + L4,

(22)

where

(cid:16)

L1 =

diag(ˆf )ˆhc − ˆg

diag(ˆf )ˆhc − ˆg

(cid:17)

,

(cid:17)T (cid:16)

L2 =

(cid:107)hm(cid:107)2,

λ
2

∇ˆhc

L1 =

(31)

diag(ˆf )ˆhc − ˆg

(cid:17)(cid:21)

=

=

=

(cid:20)(cid:16)

(cid:17)T (cid:16)

diag(ˆf )ˆhc − ˆg

∂
∂ ˆhc
(cid:20)
∂
c diag(ˆf )H diag(ˆf )ˆhc − ˆhT
ˆhT
∂ ˆhc

ˆgH diag(ˆf )ˆhc + ˆgH ˆg

=

(cid:21)

c diag(ˆf )H ˆg−

= diag(ˆf )H diag(ˆf )ˆhc − diag(ˆf )ˆg,

∇ˆhc

L2 = 0,

∇ˆhc

L3 =

(32)

(33)
(cid:17)(cid:21)

(cid:21)

(cid:20)
ˆlH (cid:16)ˆhc −

√

DFMh

(cid:17)

+ ˆlH

(cid:16)ˆhc −

DFMh

=

(cid:20)
ˆlH ˆhc − ˆlH

√

DFMh + ˆlT ˆhc − ˆlT

DFMh

=

√

√

=

=

∂
∂ ˆhc
∂
∂ ˆhc

= ˆl,

L3 = ˆlH (ˆhc −

√

DFMh) + ˆlH (ˆhc −
√

L4 = µ(cid:107)ˆhc −

DFMh(cid:107)2.

√

DFMh), (25)

=

∂
∂ ˆhc

(cid:20)

(cid:16)ˆhc −
µ

√

DFMh

∇ˆhc

L4 =
(cid:17)T (cid:16)ˆhc −

√

(cid:17)(cid:21)

DFMh

=

(34)

Minimization of Equation (8) in Section 3.1 is an itera-
tive process at which the following minimizations are re-
quired:

ˆhopt

c = arg min

L(ˆhc, h,ˆl),

hopt = arg min

L(ˆhopt
c

, h,ˆl).

hc

h

Minimization w.r.t. to ˆhc is derived by ﬁnding ˆhc at which
the complex gradient of the augmented Lagrangian van-
ishes, i.e.,

∇ˆhc

L1 + ∇ˆhc

L3 + ∇ˆhc

L4 ≡ 0.

L ≡ 0,

∇ˆhc
L2 + ∇ˆhc

=

∂
∂ ˆhc

√

(cid:20)

(cid:16)ˆhH
µ

c

ˆhc − ˆhH
c

√

DFMh−

DhT MFH ˆhc + DhT MFH FMh

(cid:17)(cid:21)

=

√

= µˆhc − µ

DFMh.

√

Note that
inition of ˆhm. Plugging (31-34) into (30) yields

DFMh = ˆhm according to our original def-

diag(ˆf )H diag(ˆf )ˆhc − diag(ˆf )ˆg + ˆl + µˆhc − µˆhm = 0,
(35)

ˆhc =

diag(ˆf )ˆg + µˆhm − ˆl
diag(ˆf )H diag(ˆf ) + µ

,

(23)

(24)

(26)

(27)

(28)

(29)

(30)

18

which can be rewritten into

Plugging (39-43) into (38) yields

ˆhc =

ˆf (cid:12) ˆg + µˆhm − ˆl
ˆf (cid:12) ˆf + µ

.

(36)

Mh −

DMFHˆl − µ

√

λ
2

√

√

DMFH ˆhc + µDMh = 0,
(44)

Next we derive the closed-form solution of (28). The op-
timal h is obtained when the complex gradient w.r.t. h
vanishes, i.e.,

Mh = M

DFH (ˆl + µˆhc)
λ
2 + µD

.

∇hL ≡ 0
∇hL1 + ∇hL2 + ∇hL3 + ∇hL4 ≡ 0.

The partial gradients are

∇hL1 = 0,

∇hL2 =
(cid:21)

T

(Mh)

(Mh)

=

=

∂
∂h

(cid:20) λ
2

∂
∂h

(cid:20) λ
2

(cid:21)
hHMMh
.

Since we deﬁned mask m as a binary mask, the product
MM can be simpliﬁed into M and the result for ∇hL2 is

∇hL2 =

Mh.

λ
2

The remaining gradients are as follows:

√

(cid:20)
ˆlH (cid:16)ˆhc −
(cid:20)
ˆlH ˆhc − ˆlH

√

=

=

∂
∂h
∂
∂h

∇hL3 =
(cid:17)

DFMh

+ ˆlH

(cid:16)ˆhc −

√

DFMh

=

DFMh + ˆlT ˆhc − ˆlT

DFMh

=

√

(cid:21)

√

= −

DMFHˆl,

(37)

(38)

(39)

(40)

(41)

(42)
(cid:17)(cid:21)

Using the deﬁnition of the inverse Fourier transform, i.e.,
F −1(ˆx) = 1√
D

FH ˆx, (44) can be rewritten into

m (cid:12) h = m (cid:12)

(45)

F −1(ˆl + µˆhc)
λ
2D + µ

.

The values in m are either zero or one. Elements in h
that correspond to the zeros in m can in principle not be
recovered from (45) since this would result in division by
zero. But our initial deﬁnition of the problem was to seek
solutions for the ﬁlter that satisﬁes the following relation
h ≡ h(cid:12)m. This means the values corresponding to zeros
in m should be zero in h. Thus the proximal solution
to (45) is

h = m (cid:12)

F −1(ˆl + µˆhc)
λ
2D + µ

.

(46)

Acknownledgements

This work was supported in part by the following re-
search programs and projects: Slovenian research agency
research programs and projects P2-0214, L2-6765 and J2-
8175. Jiˇri Matas and Tom´aˇs Voj´ı˜r were supported by The
Czech Science Foundation Project GACR P103/12/G084
and Toyota Motor Europe. We would also like to thank
dr. Rok ˇZitko for discussion on complex differentiation.

∇hL4 =

√

DFMh

√

(cid:17)T (cid:16)ˆhc −
√

(cid:16)ˆhH
µ

c

ˆhc − ˆhH
c

DFMh−

(cid:17)(cid:21)

DFMh

=

=

(cid:20)

∂
∂h

(cid:16)ˆhc −
µ
(cid:20)

∂
∂h

=

√

DhHMFH ˆhc + DhHMh

√

= −µ

DMFH ˆhc + µDMh.

(cid:17)(cid:21)

=

(43)

References

Babenko B, Yang MH, Belongie S (2011) Robust object
tracking with online multiple instance learning. IEEE
Trans Pattern Anal Mach Intell 33(8):1619–1632

Bertinetto L, Valmadre J, Golodetz S, Miksik O, Torr PHS
(2016a) Staple: Complementary learners for real-time
tracking. In: Comp. Vis. Patt. Recognition, pp 1401–
1409

19

Bertinetto L, Valmadre J, Henriques JF, Vedaldi A, Torr
PH (2016b) Fully-convolutional siamese networks for
object tracking. arXiv preprint arXiv:160609549

Bolme DS, Beveridge JR, Draper BA, Lui YM (2010) Vi-
sual object tracking using adaptive correlation ﬁlters.
In: Comp. Vis. Patt. Recognition, IEEE, pp 2544–2550

Boyd S, Parikh N, Chu E, Peleato B, Eckstein J (2011)
Distributed optimization and statistical learning via the
alternating direction method of multipliers. Founda-
tions and Trends in Machine Learning 3(1):1–122

ˇCehovin L, Leonardis A, Kristan M (2016) Visual object
tracking performance measures revisited. IEEE Trans
Image Proc 25(3):1261–1274

Dalal N, Triggs B (2005) Histograms of oriented gradi-
ents for human detection. In: Comp. Vis. Patt. Recog-
nition, vol 1, pp 886–893

Danelljan M, H¨ager G, Khan FS, Felsberg M (2014a) Ac-
curate scale estimation for robust visual tracking. In:
Proc. British Machine Vision Conference, pp 1–11

Danelljan M, Khan FS, Felsberg M, van de Weijer J
(2014b) Adaptive color attributes for real-time visual
tracking. In: 2014 IEEE Conference on Computer Vi-
sion and Pattern Recognition, CVPR 2014, Columbus,
OH, USA, June 23-28, 2014, pp 1090–1097

Danelljan M, Hager G, Shahbaz Khan F, Felsberg M
(2015a) Learning spatially regularized correlation ﬁl-
ters for visual tracking. In: Int. Conf. Computer Vision,
pp 4310–4318

Danelljan M, H¨ager G, Khan FS, Felsberg M (2015b)
Convolutional features for correlation ﬁlter based vi-
sual tracking. In:
IEEE International Conference on
Computer Vision Workshop (ICCVW), pp 621–629

Danelljan M, Robinson A, Khan FS, Felsberg M (2016)
Beyond correlation ﬁlters: learning continuous convo-
lution operators for visual tracking. In: Proc. European
Conf. Computer Vision, Springer, pp 472–488

Danelljan M, H¨ager G, Khan FS, Felsberg M (2017) Dis-
criminative scale space tracking. IEEE Trans Pattern
Anal Mach Intell 39(8):1561–1575

Dinh TB, Vo N, Medioni G (2011) Context tracker:
Exploring supporters and distracters in unconstrained
environments. In: Comp. Vis. Patt. Recognition, pp
1177–1184

Diplaros A, Vlassis N, Gevers T (2007) A spatially
constrained generative model and an em algorithm
for image segmentation. IEEE Trans Neural Networks
18(3):798 – 808

Felzenszwalb P, Girshick R, McAllester D, Ramanan D
(2010) Object detection with discriminatively trained
part-based models. IEEE Trans Pattern Anal Mach In-
tell 32(9):1627–1645

Galoogahi HK, Sim T, Lucey S (2013) Multi-channel
correlation ﬁlters. In: Int. Conf. Computer Vision, pp
3072–3079

Grabner H, Grabner M, Bischof H (2006) Real-time
tracking via on-line boosting. In: Proc. British Machine
Vision Conference, vol 1, pp 47–56

Hare S, Saffari A, Torr PHS (2011) Struck: Structured
output tracking with kernels. In:
Int. Conf. Com-
puter Vision, IEEE Computer Society, Washington,
DC, USA, pp 263–270

Henriques JF, Caseiro R, Martins P, Batista J (2012) Ex-
ploiting the circulant structure of tracking-by-detection
with kernels. In: Fitzgibbon A, Lazebnik S, Perona P,
Sato Y, Schmid C (eds) Proc. European Conf. Com-
puter Vision, Springer Berlin Heidelberg, Berlin, Hei-
delberg, pp 702–715

Henriques JF, Caseiro R, Martins P, Batista J (2015) High-
speed tracking with kernelized correlation ﬁlters. IEEE
Trans Pattern Anal Mach Intell 37(3):583–596

Hester CF, Casasent D (1980) Multivariant technique
for multiclass pattern recognition. Applied Optics
19(11):1758–1761

Hong Z, Chen Z, Wang C, Mei X, Prokhorov D, Tao
D (2015) Multi-store tracker (muster): A cognitive
psychology inspired approach to object tracking. In:
Comp. Vis. Patt. Recognition, pp 749–758

20

Kalal Z, Mikolajczyk K, Matas J (2012) Tracking-
learning-detection. IEEE Trans Pattern Anal Mach In-
tell 34(7):1409–1422

Liang P, Blasch E, Ling H (2015) Encoding color infor-
mation for visual tracking: Algorithms and benchmark.
IEEE Trans Image Proc 24(12):5630–5644

Kiani Galoogahi H, Sim T, Lucey S (2015) Correlation
ﬁlters with limited boundaries. In: Comp. Vis. Patt.
Recognition, pp 4630–4638

Kristan M, Pﬂugfelder R, Leonardis A, Matas J, Porikli F,
ˇCehovin L, Nebehay G, Fernandez G, Vojir Tea (2013)
The visual object tracking vot2013 challenge results.
In: Vis. Obj. Track. Challenge VOT2013, In conjunc-
tion with ICCV2013, pp 98–111

Kristan M, Pﬂugfelder R, Leonardis A, Matas J, ˇCehovin
L, Nebehay G, Vojir T, et al Fernandez G (2014) The vi-
sual object tracking vot2014 challenge results. In: Proc.
European Conf. Computer Vision, pp 191–217

Kristan M, Matas J, Leonardis A, Felsberg M, ˇCehovin
L, Fernandez G, Vojir T, H¨ager G, Nebehay G,
et al Pﬂugfelder R (2015) The visual object tracking
vot2015 challenge results. In: Int. Conf. Computer Vi-
sion

Kristan M, Kenk VS, Kovaˇciˇc S, Perˇs J (2016a) Fast
image-based obstacle detection from unmanned surface
vehicles. IEEE Transactions on Cybernetics 46(3):641–
654

Kristan M, Leonardis A, Matas J, Felsberg M, Pﬂugfelder
R, ˇCehovin L, Vojir T, H¨ager G, Lukeˇziˇc A, et al Fer-
nandez G (2016b) The visual object tracking vot2016
challenge results. In: Proc. European Conf. Computer
Vision

Kristan M, Matas J, Leonardis A, Vojir T, Pﬂugfelder
R, Fernandez G, Nebehay G, Porikli F, Cehovin L
(2016c) A novel performance evaluation methodol-
ogy for single-target trackers. IEEE Trans Pattern Anal
Mach Intell

Li Y, Zhu J (2014a) A scale adaptive kernel correlation ﬁl-
ter tracker with feature integration. In: Proc. European
Conf. Computer Vision, pp 254–265

Li Y, Zhu J (2014b) A scale adaptive kernel correlation ﬁl-
ter tracker with feature integration. In: Proc. European
Conf. Computer Vision, pp 254–265

Liu B, Huang J, Yang L, Kulikowsk C (2011) Robust
tracking using local sparse appearance model and k-
selection. In: Comp. Vis. Patt. Recognition, pp 1313–
1320

Liu S, Zhang T, Cao X, Xu C (2016) Structural correlation
ﬁlter for robust visual tracking. In: Comp. Vis. Patt.
Recognition, pp 4312–4320

Liu T, Wang G, Yang Q (2015) Real-time part-based vi-
sual tracking via adaptive correlation ﬁlters. In: Comp.
Vis. Patt. Recognition, pp 4902–4912

Lukeˇziˇc A,

ˇC Zajc L, Kristan M (2017) Deformable
parts correlation ﬁlters for robust visual tracking. IEEE
Transactions on Cybernetics PP(99):1–13

Ma C, Huang JB, Yang X, Yang MH (2015) Hierarchical
convolutional features for visual tracking. In: Int. Conf.
Computer Vision, pp 3074–3082

Mueller M, Smith N, Ghanem B (2016) A benchmark and
simulator for uav tracking. In: Proc. European Conf.
Computer Vision

Nam H, Han B (2016) Learning multi-domain convolu-
tional neural networks for visual tracking. In: Comp.
Vis. Patt. Recognition, pp 4293–4302

Qi Y, Zhang S, Qin L, Yao H, Huang Q, Lim J, Yang
MH (2016) Hedged deep tracking. In: CVPR, pp 4303–
4311

Smeulders A, Chu D, Cucchiara R, Calderara S, De-
hghan A, Shah M (2014) Visual tracking: An exper-
imental survey. IEEE Trans Pattern Anal Mach Intell
36(7):1442–1468

Vojir T, Matas J (2017) Pixel-wise object segmenta-
tions for the VOT 2016 dataset. Research Report
CTU–CMP–2017–01, Center for Machine Perception,
K13133 FEE Czech Technical University, Prague,
Czech Republic

21

Wang L, Ouyang W, Wang X, Lu H (2015a) Visual track-
ing with fully convolutional networks. In: Int. Conf.
Computer Vision, pp 3119–3127

Wang N, Li S, Gupta A, Yeung D (2015b) Transfer-
ring rich feature hierarchies for robust visual tracking.
CoRR abs/1501.04587

Wang S, Zhang S, Liu W, Metaxas DN (2016) Visual
tracking with reliable memories. In: Proceedings of the
Twenty-Fifth International Joint Conference on Artiﬁ-
cial Intelligence, pp 3491–3497

Wei Zhong MHY Huchuan Lu (2012) Robust object
tracking via sparsity-based collaborative model. In:
Comp. Vis. Patt. Recognition, pp 1838–1845

van de Weijer J, Schmid C, Verbeek J, Larlus D (2009)
Learning color names for real-world applications. IEEE
Trans Image Proc 18(7):1512–1523

Wu Y, Lim J, Yang MH (2013) Online object tracking: A
benchmark. In: Comp. Vis. Patt. Recognition, pp 2411–
2418

Wu Y, Lim J, Yang MH (2015) Object

tracking
benchmark. IEEE Trans Pattern Anal Mach Intell
37(9):1834–1848

Xu Jia MHY Huchuan Lu (2012) Visual tracking via
adaptive structural local sparse appearance model. In:
Comp. Vis. Patt. Recognition, pp 1822–1829

Zhang K, Zhang L, Liu Q, Zhang D, Yang MH (2014)
Fast visual tracking via dense spatio-temporal context
learning. In: Proc. European Conf. Computer Vision,
Springer International Publishing, pp 127–141

Zhu G, Porikli F, Li H (2016) Beyond local search: Track-
ing objects everywhere with instance-speciﬁc propos-
als. In: The IEEE Conference on Computer Vision and
Pattern Recognition (CVPR), pp 943–951

22

Figure 16: Qualitative results of tracking with the CSR-DCF on four video sequences.

23

9
1
0
2
 
n
a
J
 
4
1
 
 
]

V
C
.
s
c
[
 
 
3
v
1
6
4
8
0
.
1
1
6
1
:
v
i
X
r
a

Discriminative Correlation Filter Tracker with
Channel and Spatial Reliability

Alan Lukeˇziˇc1, Tom´aˇs Voj´ıˇr2, Luka ˇCehovin Zajc1, Jiˇr´ı Matas2 and Matej Kristan1
1Faculty of Computer and Information Science, University of Ljubljana, Slovenia
2Faculty of Electrical Engineering, Czech Technical University in Prague, Czech Republic
{alan.lukezic, luka.cehovin, matej.kristan}@fri.uni-lj.si
{vojirtom, matas}@cmp.felk.cvut.cz

Abstract

Short-term tracking is an open and challenging problem
for which discriminative correlation ﬁlters (DCF) have
shown excellent performance. We introduce the channel
and spatial reliability concepts to DCF tracking and pro-
vide a learning algorithm for its efﬁcient and seamless
integration in the ﬁlter update and the tracking process.
The spatial reliability map adjusts the ﬁlter support to
the part of the object suitable for tracking. This both
allows to enlarge the search region and improves track-
ing of non-rectangular objects. Reliability scores reﬂect
channel-wise quality of the learned ﬁlters and are used as
feature weighting coefﬁcients in localization. Experimen-
tally, with only two simple standard feature sets, HoGs
and Colornames, the novel CSR-DCF method – DCF with
Channel and Spatial Reliability – achieves state-of-the-
art results on VOT 2016, VOT 2015 and OTB100. The
CSR-DCF runs close to real-time on a CPU.
Keywords— Visual tracking, Correlation ﬁlters, Channel
reliability, Constrained optimization

1 Introduction

Short-term, model-free visual object tracking is the prob-
lem of continuously localizing a target
in a video-
sequence given a single example of its appearance. It has
received signiﬁcant attention of the computer vision com-
munity which is reﬂected in the number of papers pub-
lished on the topic and the existence of multiple perfor-
mance evaluation benchmarks (Wu et al, 2013; Kristan

et al, 2013, 2014, 2015, 2016c; Liang et al, 2015; Smeul-
ders et al, 2014; Mueller et al, 2016). Diverse factors –
occlusion, illumination change, fast object or camera mo-
tion, appearance changes due to rigid or non-rigid defor-
mations and similarity to the background – make short-
term tracking challenging.

Recent short-term tracking evaluations (Wu et al, 2013;
Kristan et al, 2013, 2014, 2015) consistently conﬁrm the
advantages of semi-supervised discriminative tracking ap-
proaches (Grabner et al, 2006; Babenko et al, 2011; Hare
et al, 2011; Bolme et al, 2010).
In particular, track-
ers based on the discriminative correlation ﬁlter (DCF)
method (Bolme et al, 2010; Danelljan et al, 2014a; Hen-
riques et al, 2015; Li and Zhu, 2014a; Danelljan et al,
2015a) have shown state-of-the-art performance in all
standard benchmarks. Discriminative correlation meth-
ods learn a ﬁlter with a pre-deﬁned response on the train-
ing image. The latter is obtained by slightly extending the
region around the target to include background samples.
The standard formulation of DCF uses circular corre-
lation which allows to implement learning efﬁciently by
Fast Fourier transform (FFT). However, the FFT requires
the ﬁlter and the search region size to be equal which
limits the detection range. Due to the circularity, the ﬁl-
ter is trained on many examples that contain unrealistic,
wrapped-around circularly-shifted versions of the target.
A naive approach to the reduction of the windowing prob-
lems is to learn the ﬁlter from a larger region. However,
due to the large area of the background in the region, the
tracking performance of the DCF drops signiﬁcantly as
shown in Figure 2.

The windowing problems were recently addressed by

1

overcomes both the problems of circular shift enabling an
arbitrary search (and training) region size and the limi-
tations related to the rectangular shape assumption. An
important beneﬁt of a large training region is that back-
ground samples from a wider area around the target are
obtained to improve the ﬁlter discriminative power. The
spatial reliability map is estimated using the output of a
graph labeling problem solved efﬁciently in each frame.
An efﬁcient optimization procedure is applied for learn-
ing a correlation ﬁlter with the support constrained by the
spatial reliability map since the standard closed-form so-
lution cannot be generalized to this case. Figure 2 shows
that tracking performance of our spatially constrained cor-
relation ﬁlter (denoted as S-DCF) does not degrade with
increasing training and search region size as is the case
with the standard DCF. In contrast, the performance of
S-DCF improves from better treatment of training sam-
ples and increased search region size. Experiments show
that the novel ﬁlter optimization procedure outperforms
related approaches for constrained learning in DCFs.

Channel reliability is the second novelty the CSR-
DCF tracker introduces. The reliability is estimated
from the properties of the constrained least-squares so-
lution to ﬁlter design. The channel reliability scores
are used for weighting the per-channel ﬁlter responses
The CSR-DCF shows
in localization (Figure 1).
state-of-the-art performance on standard benchmarks –
OTB100 (Wu et al, 2015), VOT2015 (Kristan et al, 2015)
and VOT2016 (Kristan et al, 2015) while running close
to real-time on a single CPU. The spatial and channel re-
liability formulation is general and can be used in most
modern correlation ﬁlters, e.g. those using deep features.
The remainder of the paper is structured as follows. In
Section 2 we review most closely related work, our ap-
proach is described in Section 3, experimental results are
presented in Section 4 and conclusions are drawn in Sec-
tion 5.

2 Related work

The discriminative correlation ﬁlters for object detection
date back to the 80’s with seminal work of Hester and
Casasent (1980). They have been popularized only re-
cently in the tracking community, starting with the Bolme
et al (2010) MOSSE tracker. Using a gray-scale tem-

Figure 1: Overview of the CSR-DCF approach. An au-
tomatically estimated spatial reliability map restricts the
correlation ﬁlter to the parts suitable for tracking (top)
improving localization within a larger search region and
performance for irregularly shaped objects. Channel reli-
ability weights calculated in the constrained optimization
step of the correlation ﬁlter learning reduce the noise of
the weight-averaged ﬁlter response (bottom).

Kiani Galoogahi et al (2015) who propose zero-padding
the ﬁlter during learning and by Danelljan et al (2015a)
who introduce spatial regularization to penalize ﬁlter val-
ues outside the target boundaries. Both approaches train
from image regions much larger than the target and thus
increase the detection range.

Another limitation of the published DCF methods is the
assumption that the target shape is well approximated by
an axis-aligned rectangle. For irregularly shaped objects
or those with a hollow center, the ﬁlter eventually learns
the background, which may lead to drift and failure. The
same problem appears for approximately rectangular ob-
jects in the case of occlusion. The Kiani Galoogahi et al
(2015) and Danelljan et al (2015a) methods both suffer
from this problem.

In this paper we introduce the CSR-DCF, the Discrim-
inative Correlation Filter with Channel and Spatial Reli-
ability. The spatial reliability map adapts the ﬁlter sup-
port to the part of the object suitable for tracking which

2

get segmentation probability map. Danelljan et al (2016)
addressed a multiple-resolution feature map issue in cor-
relation ﬁlters by formulating ﬁlter learning in continu-
ous space, while Qi et al (2016) proposed a mechanism
to combine correlation responses from multiple convolu-
tional layers. A correlation ﬁlter tracker which is able to
handle drifts in longer sequences was proposed by Wang
et al (2016). It clusters similar target appearances together
and uses the clusters for target localization instead of a
single online learned ﬁlter.

Since most of the correlation ﬁlter trackers represent
the target with a single ﬁlter, it can easily get corrupted
when occlusion or a target deformation happen. In gen-
eral, part-based trackers are better in addressing these is-
sues. Therefore several part-based correlation ﬁlter meth-
ods were proposed. Liu et al (2015) use an efﬁcient
method to combine correlation outputs of multiple parts
and Liu et al (2016) proposed a tracking method for mod-
eling the target structure with multiple parts using multi-
ple correlation ﬁlters. Lukeˇziˇc et al (2017) treat the parts
correlation ﬁlter responses and their constellation con-
straints jointly as an equivalent spring system. They de-
rive a highly efﬁcient optimization to infer the most prob-
able target deformation.

Recently, Kiani Galoogahi et al (2015) addressed the
problem that occurs due to learning with circular correla-
tion from small training regions. They proposed a learn-
ing framework that artiﬁcially increases the ﬁlter size by
implicitly zero padding the ﬁlter. This reduces the bound-
ary artifacts by increasing the number of training exam-
ples in constrained ﬁlter learning. Danelljan et al (2015a)
reformulate the learning cost function to penalize non-
zero ﬁlter values outside the object bounding box. Per-
formance better than (Kiani Galoogahi et al, 2015) is re-
ported, but the learned ﬁlter is still a trade-off between
the correlation response and regularization, and it does
not guarantee that ﬁlter values are zero outside of object
bounding box.

3 Spatially constrained correlation

ﬁlters

The use of multiple channels in correlation ﬁlters (Hen-
riques et al, 2015; Danelljan et al, 2017; Galoogahi et al,

Figure 2: Tracking performance measured by the Ex-
pected Average Overlap (EAO) of the standard DCF and
our spatially constrained DCF (S-DCF) as a function of
search region size, expressed as the multiple of the target
size (right, x-axis). The ﬁlter is learned from a training re-
gion equal in size to the search region. The search region
sizes are visualized by black-white dashed rectangles (left
image) and the target bounding box is shown in yellow.

plate, MOSSE achieved state-of-the-art performance on a
tracking benchmark (Wu et al, 2013) at a remarkable pro-
cessing speed. Signiﬁcant improvements have been made
since and in 2014 the top-performing trackers on a recent
benchmark (Kristan et al, 2014) were all from this class of
trackers. DCF improvements fall into two categories, in-
troduction of new features and conceptual improvements
in ﬁlter learning.

In the ﬁrst group, Henriques et al (2015) replaced the
grayscale templates by HoG (Dalal and Triggs, 2005),
Danelljan et al (2014b) proposed multi-dimensional color
attributes and Li and Zhu (2014b) applied feature combi-
nation. Recently, convolutional network features learned
for object detection have been applied (Ma et al, 2015;
Danelljan et al, 2015b, 2016), leading to a performance
boost, but at a cost of signiﬁcant speed reduction.

Conceptually, the ﬁrst successful theoretical extension
of the standard DCF was the kernelized formulation by
Henriques et al (2015) which achieved remarkable track-
ing performance, but still preserved high speed. Later, a
correlation ﬁlter based scale adaptation was proposed by
Danelljan et al (2014a) introduced a scale-space pyramid
learned within a correlation ﬁlter framework. Zhang et al
(2014) introduced spatio-temporal context learning in the
DCFs. To improve localization with correlation ﬁlters,
Bertinetto et al (2016a) proposed a tracking method that
combines the output of the correlation ﬁlter with the tar-

3

In
2013) has become very popular in visual tracking.
the following we present the main ideas behind learn-
ing these ﬁlters. Given a set of Nc channel features
f = {fd}d=1:Nc and corresponding target templates (ﬁl-
ters) h = {hd}d=1:Nc , the object position is estimated
as the location of the maximum of correlation response
˜g(h),

Nc(cid:88)

˜g(h) =

fd (cid:63) hd.

(1)

d=1
The symbol (cid:63) represents circular correlation between fd ∈
Rcw×ch and hd ∈ Rcw×ch , where cw and ch are the train-
ing/search region width and height, respectively. The op-
timal correlation ﬁlter h is estimated by minimizing

Figure 3: Correlation responses of different feature chan-
nels (27 HoG, 10 colornames and one grayscale channel)
are summed to obtain the ﬁnal (single channel) correlation
response (middle). Note that maximum values of channel
responses may vary by orders of magnitude (right).

ε(h) = (cid:107)˜g(h) − g(cid:107)2 + λ(cid:107)h(cid:107)2,

(2)

where g is the desired output g ∈ Rcw×ch , which is typ-
ically a 2-D Gaussian function centered at the target lo-
cation. Efﬁcient tracking performance is achieved by ex-
pressing the cost (2) into the Fourier domain

ε(h) = (cid:107)

diag(ˆfd)ˆhd − ˆg(cid:107)2 + λ

(cid:107)ˆh(cid:107)2,

(3)

Nc(cid:88)

d=1

Nc(cid:88)

d=1

where the operator ˆa = vec(F[a]) is a Fourier transform
of a reshaped into a column vector, i.e., ˆa ∈ RD×1, with
D = cw · ch, diag(ˆa) being a D × D diagonal matrix
formed from ˆa and (·) is the complex-conjugate operator.
The closed-form solution for d-th ﬁlter channel ˆhd which
minimizes the cost function (3) is equal to

(cid:18)

(cid:19)

ˆhd =

diag(ˆfd)ˆg

(cid:12)−1

diag(ˆfd)ˆf d + λ

,

(4)

(cid:19)

(cid:18) Nc(cid:88)

d=1

where (cid:12)−1 is element-wise division. The solution (4)
considers all feature channels jointly and is used in most
of the recent correlation ﬁlter trackers. Note that the ﬁ-
nal response is obtained as summation over correlation
responses of all channels (1) and the location of the max-
imum in the ﬁnal response represents the new position of
the target.

Note that a ﬁlter for the d-th channel is computed in (4)
by dividing d-th feature with the sum over all feature
channels. This means that the feature scale crucially im-
pacts the level by which a channel contributes to the ﬁnal

response, irrespective of its discriminative power. Since
features (e.g., HoG, colornames and grayscale template)
vary in scale, some channels might suppress the others by
an order of magnitude. This is demonstrated in Figure 3
where each HoG channel on its own contributes to the ﬁ-
nal response very little.

To avoid the issue with different scales we consider
each channel independently. This means that each ﬁlter
channel is optimized to ﬁt the desired output separately.
The cost function is thus deﬁned as

ε(h) =

(cid:107)fd (cid:63) hd − g(cid:107)2 + λ(cid:107)hd(cid:107)2.

(5)

Nc(cid:88)

d=1

Additionally, we introduce channel weights w =
{ ˜wd}d=1:Nc which can be considered as scaling factors
based on the discriminative power of each feature chan-
nel. These weights are called channel reliability weights
in the rest of the paper and they are applied when correla-
tion response is calculated in the target localization stage:

˜g =

fd (cid:63) hd · ˜wd.

(6)

Nc(cid:88)

d=1

We present our method for constrained correlation ﬁlter
learning in Section 3.1. The most reliable parts of the ﬁl-
ter are identiﬁed by introducing the spatial reliability map
(Section 3.2). The method for channel reliability wd esti-
mation is presented in Section 3.3, the proposed tracker is
described in Section 3.4.

4

3.1 Constrained correlation ﬁlter learning

Since ﬁlter learning is independent across the channels
in our formulation (5), we assume only a single channel
in the following derivation (i.e., Nc = 1) and drop the
channel index for clarity.

Let m ∈ {0, 1} be a spatial reliability map with el-
ements either zero or one, that identiﬁes pixels which
should be set to zero in the learned ﬁlter. The constraint
can be formalized as h ≡ m (cid:12) h, where (cid:12) represents
the Hadamard (element-wise) product. Such constraint
does not lead to a closed-form solution, but an iterative ap-
proach akin to Kiani Galoogahi et al (2015) can be derived
In the
for efﬁciently solving the optimization problem.
following we summarize the main steps of our approach
and report the full derivation in Appendix 6.

We start by introducing a dual variable hc and the con-

straint

hc − m (cid:12) h ≡ 0,

leads

which
grangian (Boyd et al, 2011)

the

to

following

augmented La-

λ
2

L(ˆhc, h,ˆl|m) = (cid:107)diag(ˆf )ˆhc − ˆg(cid:107)2 +

(cid:107)hm(cid:107)2 + (8)

[ˆlH (ˆhc − ˆhm) + ˆlH (ˆhc − ˆhm)] + µ(cid:107)ˆhc − ˆhm(cid:107)2,

where ˆl is a complex Lagrange multiplier, µ > 0, and
we use the deﬁnition hm = (m (cid:12) h) for compact no-
tation. The augmented Lagrangian (8) can be iteratively
minimized by the alternating direction method of multi-
pliers, e.g. Boyd et al (2011), which sequentially solves
the following sub-problems at each iteration:

A standard scheme for updating the constraint penalty µ
values (Boyd et al, 2011) is applied, i.e., µi+1 = βµi.

Computations of (12,11) are fully carried out in the fre-
quency domain, the solution for (13) requires a single in-
verse FFT and another FFT to compute the ˆhi+1. A single
optimization iteration thus requires only two calls of the
Fourier transform, resulting in a very fast optimization.
The computational complexity is that of the Fourier trans-
form, i.e., O(D log D). Filter learning is implemented in
less than ﬁve lines of Matlab code and is summarized in
the Algorithm 1.

Algorithm 1 : Constrained ﬁlter optimization.
Require:

Features extracted from training region f , ideal corre-
lation response g,
binary mask m.

Ensure:

(7)

Optimized ﬁlter (cid:98)h.

Procedure:
1: Initialize ﬁlter (cid:98)h0 by ht−1.
2: Initialize Lagrangian coefﬁcients: (cid:98)l0 ← zeros.
3: while stop condition do
Calculate ˆhi+1
4:
c
Calculate hi+1 from ˆhi+1
Update the Lagrangian ˆli+1
hi+1 (11).

and ˆli using (13).
from ˆhi+1

from ˆhi and ˆli using (12).

6:

5:

c

c

7: end while

and

ˆhi+1

c = arg min

L(ˆhc, hi,ˆli|m),

hi+1 = arg min

L(ˆhi+1
c

, h,ˆli|m),

hc

h

and the Lagrange multiplier is updated as

ˆli+1 = ˆli + µ(ˆhi+1

c − ˆhi+1).

Minimizations in (9,10) have at each iteration a closed-
form solution, i.e.,

c = (cid:0)ˆf (cid:12) ˆg + (µˆhi
ˆhi+1

m − ˆli)(cid:1) (cid:12)−1 (cid:0)ˆf (cid:12) ˆf + µi(cid:1), (12)

hi+1 = m (cid:12) F −1(cid:2)ˆli + µi ˆhi+1

c

+ µi(cid:1).

(13)

(cid:3)/(cid:0) λ
2D

(9)

(10)

(11)

5

3.2 Constructing spatial reliability map

Once the target is localized, a training region is extracted
and used to update the ﬁlter. Our constrained ﬁlter learn-
ing (13) requires estimation of spatial reliability map m
(i.e., segmentation) that identiﬁes pixels in the training re-
gion which likely belong to the target (see Figure 4). In
the following we brieﬂy outline the segmentation model
which is used to estimate m.

During tracking,

the object foreground/background
color models are maintained as color histograms c =
i , yx
{cf , cb}. Let yi = [yc
i ] be the observation, i.e., the
color yc
i and position yx
i at i-th pixel in the training re-
gion and let mi ∈ {0, 1} be a random variable denot-
ing the unknown foreground/background label. The joint

Figure 4: Spatial reliability map construction from the training region. From left to right: a training region with
the target bounding box, t the foreground-background color models, the posterior object probability after Markov
random ﬁeld regularization, and the training region masked with the ﬁnal binary reliability map. The probabilities are
color-coded in a blue (0.0) – green (0.5) – yellow (1.0) colormap.

probability of observing yi is deﬁned as

3.2.1

Inference

1
(cid:88)

j=0

1
(cid:88)

j=0

p(yi) =

p(yi|mi = j)p(mi = j) =

(14)

=

p(yc

i |mi = j)p(yx

i |mi = j)p(mi = j),

i |mi = j), p(yx

where p(yc
i |mi = j) and p(mi = j) are
the appearance likelihood, the spatial likelihood and the
foreground/background prior probability. The appearance
likelihood term p(yc
i |mi = j) is computed by Bayes rule
from the object foreground/background color models cf
and cb. The prior probability p(mi = j) is deﬁned by the
ratio between the region sizes for foreground/background
histogram extraction.

The central pixels in axis-aligned approximations of an
elongated rotating, articulated or deformable object are
likely to contain the object regardless of the speciﬁc de-
formation. On the other hand, in the absence of measure-
ments, pixels away from the center belong to the object or
background equally likely. This deformation invariance
of central elements reliability is enforced in our approach
by deﬁning a weak spatial prior

p(yx

i |mi = j) = k(x; σ),

(15)

where k(x; σ) is a modiﬁed Epanechnikov kernel,
k(r; σ) = 1 − (r/σ)2, with size parameter σ equal to the
minor bounding box axis and clipped to interval [0.5, 0.9]
such that the object prior probability at center is 0.9 and
changes to a uniform prior away from the center (Fig-
ure 4).

In practice the likelihood p(yi|mi) is noisy and requires
regularization for our ﬁlter learning. We thus apply a
MRF from (Diplaros et al, 2007; Kristan et al, 2016a),
which treats the prior and posterior label distributions
over pixels as random variables and applies a MRF con-
straint over these. This formulation affords an efﬁcient
inference which avoids hard label assignment during op-
timization and can be implemented as a series of convo-
lutions.

The prior over the i-th pixel is deﬁned compactly
as πi = [πi0, πi1] with πij = p(mi = j) and
a standard approximation is made (Diplaros et al,
2007) that decomposes the joint pdf over priors π =
[π1, ..., πM ] into a product of local conditional distri-
butions p(π) = (cid:81)M
i=1 p(πi|πNi), where M is number
of pixels, πNi is a mixture distribution over the priors
of i-th pixel’s neighbors, i.e., πNi = (cid:80)
j∈Ni,j(cid:54)=i λijπj
and λij are ﬁxed weights satisfying (cid:80)
j λij = 1.
In
Diplaros et al (2007) the weights are ﬁxed to a nor-
malized Gaussian and are shared across all pixel lo-
The potentials in the MRF are deﬁned as
cations.
2 E(πi, πNi)(cid:1),with exponent
p(πi|πNi) ∝ exp (cid:0) − 1
deﬁned as E(πi, πNi ) = D(πi||πNi) + H(πi).The
term D(πi||πNi ) is the Kullback-Leibler divergence
which penalizes the difference between prior distribu-
tions over the neighboring pixels (πi and πNi), while
the term H(πi) is the entropy deﬁned as H(πi) =
− (cid:80)1
j=0 πij log πij,which penalizes uninformative priors
πi.

For smooth solutions Diplaros et al (2007) propose us-

6

ing a similar constraint over the posteriors pi = [pi0, pi1]
with pij being the posterior probability of class j at i-th
pixel, leading to the following energy function

F =

log p(yi) −

E(πi, πNi) + E(pi, pNi)

.

M
(cid:88)

(cid:20)

i=1

(cid:18)

1
2

(cid:19)(cid:21)

(16)
Minimization of the energy (16) w.r.t. π and p is efﬁ-
ciently solved by the solver from Diplaros et al (2007).
The ﬁnal mask m for learning the ﬁlter in Section 3.1 is
obtained by thresholding the posterior at 0.5.

3.3 Channel reliability estimation

Channel reliability ˜wd in (6) reﬂects the importance of
each channel at the target localization stage. In our ap-
proach it consists of two types of reliability measures:
(i) channel learning reliability ˜w(lrn)
, which is calculated
in the ﬁlter learning stage, and (ii) channel detection reli-
ability ˜w(det)
which is calculated in the target localization
stage. The joint channel reliability ˜wd in (6) at target lo-
calization stage is computed as the product of both relia-
bility measures, i.e.,

d

d

˜wd = ˜w(lrn)

d

· ˜w(det)
d

(17)

and normalized s.t. (cid:80)
are described in following paragraphs.

d ˜wd = 1. The reliability measures

Channel learning reliability. Constrained minimiza-
tion of (8) solves a least squares problem averaged over all
circular displacements of the ﬁlter on a feature channel.
A discriminative feature channel fd produces a ﬁlter hd
whose output fd ∗ hd nearly exactly ﬁts the ideal response
g. On the other hand, since the response is highly noisy on
channels with low discriminative power, a global error re-
duction in the least squares signiﬁcantly reduces the max-
imal response. This effect is demonstrated in Figure 5,
which shows correlation responses for a highly discrimi-
native and non-discriminative channels. Thus a straight-
forward measure of channel learning reliability ˜w(lrn)
is
the maximum response value of a learned channel ﬁlter,
which is computed as

d

˜w(lrn)

d = max(fd ∗ hd).

(18)

Figure 5: A ﬁlter is learned on feature channels from a
training region using the constrained optimization with a
binary segmentation mask m. Correlation responses be-
tween the learned ﬁlter and the training region for two
feature channels are shown on the right. On a discrimi-
native feature channel the ﬁlter response is much stronger
and less noisy than on a non-discriminative channel.

Channel detection reliability. The second part of
the channel reliability reﬂects how uniquely each chan-
nel votes for a single target location. Note that Bolme
et al (2010) proposed a similar approach to detect loss
of target. Our measure is based on the ratio between the
second and ﬁrst highest non-adjacent peaks in the chan-
nel response map, i.e., 1 − ρmax2
. The two largest
d
peaks in the response map are obtained as two largest val-
ues after a 3×3 non-maximum suppression. Note that this
ratio penalizes situations in which multiple similar objects
appear in the target vicinity (i.e., response map contains
many well expressed modes), even if the major mode ac-
curately depicts the target position. To mitigate such pe-
nalizations, the ﬁnal values are note allowed to fall below
0.5. The detection reliability of d-th channel is estimated
as

/ρmax1
d

˜w(det)
d

= max(1 − ρmax2

d

/ρmax1
d

, 0.5).

(19)

3.4 Tracking with channel and spatial reli-

ability

A single tracking iteration of the proposed channel and
spatial reliability correlation ﬁlter tracker (CSR-DCF) is
summarized in Algorithm 2 and visualized in Figure 6.
The localization and update steps proceed as follows.

7

Figure 6: The CSR-DCF tracking iteration: localization step is shown on the left and update step on the right side of
the image.

Localization step. Features are extracted from a search
region centered at the target estimated position in the
previous time-step and correlated with the learned ﬁlter
ht−1. The object is localized by summing the corre-
lation responses weighted by the estimated channel re-
liability scores wt−1. The scale is estimated by a sin-
gle scale-space correlation ﬁlter as in Danelljan et al
(2014a). Per-channel ﬁlter responses are used to compute
the corresponding detection reliability values ˜w(det) =
[ ˜w(det)
]T according to (19).
1

, . . . , ˜w(det)

Nc

Update step. The training region is centered at the tar-
get location estimated at localization step. The foreground
and background histograms ˜c are extracted and updated
by exponential moving average with learning rate ηc (step
5 in Algorithm 2). The foreground histogram is extracted
by an Epanechnikov kernel within the estimated object
bounding box and the background is extracted from the
neighborhood twice the object size. The spatial reliability
map m (Sect. 3.2) is constructed and the optimal ﬁlters ˜h
are computed by optimizing (8). The per-channel learning
reliability weights ˜w(lrn) = [ ˜w(lrn)
]T are esti-
mated from the correlation responses (18). Current frame
reliability weights ˜w are computed from detection and

, . . . , ˜w(lrn)

Nc

1

learning reliability (17). The ﬁlters and channel reliability
weights are updated by exponential moving average (cur-
rent and from previous frame) with learning rate η (steps
10 and 11 in the Algorithm 2). Note that we compute
the spatial reliability map in each frame independently to
capture large target appearance changes, e.g. caused by
rotation or deformation.

3.5 Comparison with prior work

Kiani Galoogahi et al (2015) and Danelljan et al (2015a)
have previously considered constrained ﬁlter learning.
Here we highlight the differences of our approach.

The LBCF tracker (Kiani Galoogahi et al, 2015) ad-
dresses the circular boundary effect of the Fourier trans-
form and implicitly increases the ﬁlter search region size.
In contrast, the CSR-DCF primarily reduces the impact
of the background in the ﬁlter. The solution of Kiani Ga-
loogahi et al (2015) is similar to our ﬁlter optimization,
but it is derived for a rectangular mask only. Since ro-
tating and deformable targets are poorly approximated by
an axis-aligned bounding box their ﬁlter is contaminated
by background leading to a reduced performance. The
LBCF updates the auto-spectral and cross-spectral ener-

8

Algorithm 2 : The CSR-DCF tracking algorithm.
Require:

Image It, object position on previous frame pt−1,
scale st−1, ﬁlter ht−1, color histograms ct−1, chan-
nel reliability wt−1.

Ensure:

Position pt, scale st and updated models.

Localization and scale estimation:

1: New target location pt: position of the maximum in
correlation between ht−1 and image patch features f
extracted on position pt−1 and weighted by the chan-
nel reliability scores w (Sect. 3.3).

2: Using per-channel responses, estimate detection reli-

ability ˜w(det) (Sect. 3.3).

3: Using location pt, estimate new scale st.

4: Extract foreground and background histograms ˜cf ,

Update:

˜cb.

5: Update foreground and background histograms
t−1 + ηc˜cf , cb

t = (1 − ηc)cf
cf

t = (1 − ηc)cb

t−1 + ηc˜cb.

6: Estimate reliability map m (Sect. 3.2).
7: Estimate a new ﬁlter ˜h using m (Algorithm 1).
8: Estimate learning channel reliability ˜w(lrn) from h

(Sect. 3.3).

9: Calculate channel reliability ˜w = ˜w(lrn) (cid:12) ˜w(det)
10: Update ﬁlter ht = (1 − η)ht−1 + η ˜h.
11: Update channel reliability wt = (1 − η)wt−1 + η ˜w.

gies (ˆf (cid:12) ˆf and ˆf (cid:12) ˆg in (12)) separately, which approxi-
mates computation of a single ﬁlter from a weighted sum
of errors over past training samples. This adaptation is
reasonable since it is derived for a rectangular mask that
remains constant throughout tracking. The CSR-DCF es-
timates the mask separately for each training sample and
learns a corresponding ﬁlter. For articulated objects in
particular the mask varies signiﬁcantly with time, there-
fore it is beneﬁcial to compute the exact ﬁlter for each
frame. Robustness is increased by moderately averaging
the ﬁlters temporally.

Similarly to our approach, the SRDCF (Danelljan et al,
2015a) uses a spatial map in ﬁlter learning. In contrast
to our approach, their map does not adapt to the target
and is required to be highly smooth for their optimization

to converge. In CSR-DCF the map serves as a hard con-
straint resulting in a ﬁlter with values off the target set
to zero. In contrast, the SRDCF (Danelljan et al, 2015a)
ﬁlter is a compromise between target position regression
and a penalty term that prefers potentially non-zero val-
ues in the ﬁlter center and close-to-zero values away from
the center, but does not guarantee zero values outside the
mask.

4 Experimental analysis

This section presents a comprehensive experimental eval-
uation of the CSR-DCF tracker. Implementation details
are discussed in Section 4.1, convergence of the ﬁlter
optimization method is presented in Section 4.2, Sec-
tion 4.3 reports comparison of the proposed constrained
learning to the related state-of-the-art and the ablation
study is provided in Section 4.4. Tracking performance
on three recent benchmarks: OTB-100 (Wu et al, 2015),
VOT2015 (Kristan et al, 2015) and VOT2016 (Kristan
et al, 2016b) is reported in Sections 4.6, 4.7 and 4.8, re-
spectively. The detailed analysis of the tracker, includ-
ing per-attribute tracking performance is presented in Sec-
tion 4.9 and tracking speed analysis in Section 4.10.

4.1

Implementation details and parameters

A popular implementation Felzenszwalb et al (2010) of
the standard HoG (Dalal and Triggs, 2005) and Color-
names (van de Weijer et al, 2009) features are used in the
correlation ﬁlter and HSV foreground/background color
histograms with 16 bins per color channel are used in re-
liability map estimation with parameter αmin = 0.05. All
the parameters are set to values commonly used in litera-
ture (Danelljan et al, 2015a; Kiani Galoogahi et al, 2015).
Histogram adaptation rate is set to ηc = 0.04, correlation
ﬁlter adaptation rate is set to η = 0.02, and the regu-
larization parameter is set to λ = 0.01. The augmented
Lagrangian optimization parameters are set to µ0 = 5 and
β = 3. All parameters have a straight-forward interpre-
tation, do not require ﬁne-tuning, and were kept constant
throughout all experiments. Our Matlab implementation1

1The CSR-DCF Matlab source is publicly available on:

https://github.com/alanlukezic/csr-dcf

9

runs at 13 frames per second on an Intel Core i7 3.4GHz
standard desktop.

4.2 Convergence of constrained learning

The constrained ﬁlter learning described in Section 3.1 is
an iterative optimization method that minimizes the cost
function (8). This experiment demonstrates how the cost
changes with the number of iterations during ﬁlter opti-
mization.

Figure 7 shows the average squared difference between
the result of the correlation of the ﬁlter constrained by the
spatially constrained function and the ideal output. This
graph was obtained by averaging 60 examples of initial-
izing a ﬁlter on a target (one per VOT2015 sequence) and
scaling each to an interval between zero and one.
It is
clear that the error drops by 80% within the ﬁrst few it-
erations. Already after four iterations, the performance
improvements become negligible, therefore we set num-
ber of iterations to N = 4.

Figure 7: Convergence speed of constrained ﬁlter learning
from Section 3.1 shown as a relative drop of the initial
cost.

4.3

Impact of the boundary constraint for-
mulation

This section compares our proposed boundary constraints
formulation (Sect. 3) with recent state-of-the-art ap-
proaches (Danelljan et al, 2015a; Kiani Galoogahi et al,
2015). In the ﬁrst experiment, three variants of the stan-
dard single-scale HoG-based correlation ﬁlter were im-

10

plemented to emphasize the difference in boundary con-
straints: the ﬁrst uses our spatial reliability boundary con-
straint formulation from Section 3 (TSC) the second ap-
plies the spatial regularization constraint (Danelljan et al,
2015a) (TSR) and the third applies the limited boundaries
constraint (Kiani Galoogahi et al, 2015) (TLB).

The three variants were compared on the challenging
VOT2015 dataset (Kristan et al, 2015) by applying a stan-
dard no-reset one-pass evaluation from OTB (Wu et al,
2013) and computing the AUC on the success plot. The
tracker with our constraint formulation TSC achieved 0.32
AUC, while the alternatives achieved 0.28 (TSR) and 0.16
(TLB). The only difference between these tackers is in the
constraint formulation, which indicates superiority of the
proposed spatial-reliability-based constraints formulation
over the recent alternatives (Kiani Galoogahi et al, 2015;
Danelljan et al, 2015a).

4.3.1 Robustness to non-axis-aligned target initial-

ization

The CSR-DCF tracker from Section 3 was compared
to the original recent state-of-the-art trackers SRDCF
(Danelljan et al, 2015a) and LBCF (Kiani Galoogahi et al,
2015) that apply alternative boundary constraints. For
fair comparison, the source code of SRDCF and LBCF
was obtained from the authors, all three trackers used
only HoG features and tracked on the same single scale.
An experiment was designed to evaluate initialization and
tracking of non axis-aligned targets, which is the case for
most realistic deforming and non-circular objects. Track-
ers were initialized on frames with non-axis aligned tar-
gets and left to track until the sequence end, resulting in a
large number of tracking trajectories.

The VOT2015 dataset (Kristan et al, 2015) contains
non-axis-aligned annotations, which allows automatic
identiﬁcation of tracker initialization frames, i.e., frames
in which the ground truth bounding box signiﬁcantly de-
viates from an axis-aligned approximation. Frames with
overlap (intersection over union of predicted and ground-
truth bounding boxes) of the ground truth and the axis-
aligned approximation lower than 0.5 were identiﬁed and
ﬁltered to obtain a set of initialization frames at least hun-
dred frames apart. This constraint ﬁts half the typical
short-term sequence length (Kristan et al, 2015) and re-
duces the potential correlation across the initializations

Figure 9: Qualitative results for trackers CSR-DCF (red)
tracker, SRDCF (blue) and LBCF (green).

by the average tracking length (number of frames before
the overlap drops to zero) weighted by trajectory lengths.
The weighted average tracking lengths in frames, Γfrm,
and proportions of full trajectory lengths, Γprp, are shown
in Table 1. The CSR-DCF by far outperforms SRDCF and
LBCF in all measures indicating signiﬁcant robustness in
the initialization of challenging targets that deviate from
axis-aligned templates. This improvement is further con-
ﬁrmed by the graph in Figure 8 (top-right) which shows
the OTB success plots (Wu et al, 2013) calculated on these
trajectories and summarized by the AUC values, which
are equal to the average overlaps ( ˇCehovin et al, 2016).
Table 1 shows the average overlaps computed on the orig-
inal ground truth on VOT2015 (Φrot) and on ground truth
approximated by the axis-aligned bounding box (Φaa).
Again, the CSR-DCF by far outperforms the competing
alternatives SRDCF and LBCF. Tracking examples for the
three trackers are shown in Figure 9.

In summary, the results show that the quality of spatial
constraints signiﬁcantly affects the relative tracking per-
formance when a large portion of the training region in
the target vicinity is occupied by background. The rela-
tive performance of LBCF (Kiani Galoogahi et al, 2015)
is lowest among the three trackers since this tracker treats
all pixels within axis-aligned bounding box equally as tar-
get. The SRDCF (Danelljan et al, 2015a) mostly focuses
on the central pixels of the training region and suppresses
the ﬁlter values at the borders, thus outperforming the
LBCF (Kiani Galoogahi et al, 2015). The spatial relia-
bility map in CSR-DCF most successfully reduces the in-

Figure 8: The number of trajectories with tracking suc-
cessful up to frame Θfrm (upper left), the success plots
(upper right) and initialization examples of non-axis-
aligned targets (bottom).

Table 1: Comparison of three most related trackers on
non-axis-aligned initialization experiment: weighted av-
erage tracking length in frames Γfrm and proportions
Γprp, and weighted average overlaps using the original
and axis-aligned ground truth, Φrot and Φaa, respectively.

Tracker
CSR-DCF
SRDCF (ICCV2015)
LBCF (CVPR2015)

Γprp
1 0.58
2 0.31
3 0.12

Γfrm
1 221
95
2
37
3

Φaa
1 0.31
2 0.16
3 0.06

Φrot
1 0.24
2 0.12
3 0.04

(see Figure 8 (bottom) for examples).

Initialization robustness is estimated by counting the
number of trajectories in which the tracker was still track-
ing (overlap with ground truth greater than 0) Θfrm frames
after initialization. The graph in Figure 8 (top-left) shows
these values with increasing the threshold Θfrm. The
CSR-DCF graph is consistently above the SRDCF and
LBCF for all thresholds. The performance is summarized

11

ﬂuence of background in ﬁlter learning resulting in con-
siderable robustness to poor initializations.

4.4 Spatial and channel reliability ablation

study

An ablation study on VOT2016 was conducted to eval-
uate the contribution of spatial and channel reliability in
CSR-DCF. Results of the VOT primary measure expected
average overlap (EAO) and two supplementary measures
accuracy and robustness (A,R) are summarized in Table 2.
For the details of performance measures and evaluation
protocol we refer the reader to the Section 4.7. Perfor-
mance of the various modiﬁcations of CSR-DCF is dis-
cussed in the following.
Channel reliability weights. Setting the channel relia-
bility weights to uniform values (CSR-DCFc− ) is equiv-
alent to treating all channels as independent and equally
important. The performance drop in EAO compared to
CSR-DCF is 12%.
Spatial reliability map. Replacing the spatial reliability
map in CSR-CDF by a constant map with uniform val-
ues within the bounding box and zeros elsewhere (CSR-
DCFsu ), results in a 21% drop in EAO. The other parts
of the tracker remained unchanged in this experiment, in-
cluding the channel reliability. This clearly shows the im-
portance of our segmentation-based spatial reliability map
estimation from Section 3.2.
Channel and spatial reliability. Making both replace-
ments in the original tracker means that this version
(CSR-DCFc−su) does not use channel reliability weights
and it uses uniform spatial reliability map (uniform values
within the bounding box and zeros elsewhere). The per-
formance drops by 24% compared to CSR-DCF. Removal
of the uniform spatial reliability map from CSR-DCFc−su
results in the CSR-DCFc−s− . This version reduces our
tracker to a standard DCF with a large receptive ﬁeld.
Since the learned ﬁlter captures a signiﬁcant amount of
background, the performance drops by over 50%.
ADMM Filter optimization method. To demonstrate
the importance of the constrained optimization method we
modify the proposed tracker as follows. The ﬁlter h is cal-
culated with a naive approach, i.e., a closed-form solution
followed by masking with the spatial reliability map m:
ˆh = F(F −1(ˆh) (cid:12) m). For a fair comparison the tracker,

Table 2: Ablation study of CSR-DCF. The use of channel
reliability is indicated in the Chan. column, the the type
of spatial reliability map in the Spat. column. The Opt.
column indicates whether the constrained optimization is
used.

Tracker
CSR-DCF
CSR-DCFc−
CSR-DCFsu
CSR-DCFc−su
CSR-DCFc−o−
CSR-DCFc−s−

Chan. Spat. Opt. EAO

x
–
x
–
–
–

segm. x
segm. x
x
unif.
unif.
x
segm. –
–

–

Aav

Rav
1 0.338 1 0.85 1 0.51
2 0.297 2 1.08 2 0.51
3 0.264 3 1.18 3 0.49
1.33 2 0.51
1.47 2 0.51
0.47
2.85

0.256
0.251
0.152

denoted as CSR-DCFc−o− , does not use channel reliabil-
ity weights. The performance drop in EAO compared to
CSR-DCFc− is 15%.

4.5 Spatial reliability map quality analysis

In this section we evaluate the quality of our spatial reli-
ability map estimation (Section 3.2) from a visual track-
ing perspective. We compare the CSR-DCF tracker with
the version of CSR-DCF that uses ideal spatial reliabil-
ity map (the tracker is denoted as CSR*-DCF). In the
VOT2016 challenge (Kristan et al, 2016b), the ground
truth bounding boxes were automatically computed by
optimizing coverage over manually segmented targets in
each frame. The VOT2016 has recently made their per-
frame segmentations freely available (Vojir and Matas,
2017). We use these per-frame segmentation masks in
CSR*-DCF as spatial reliability map m.

Results of evaluation on VOT2016 (Kristan et al,
2016b) are reported in Table 3. The performances of the
CSR-DCF and CSR*-DCF are very similar. The track-
ers achieve an equal expected average overlap (EAO) and
average accuracy (Aav). But the CSR*-DCF has a sin-
gle failure less than CSR-DCF on 60 sequences which is
0.02 on average. In Table 3 the average number of fail-
ures is denoted as robustness (Rav). These results show
that our approach for spatial reliability estimation (Sec-
tion 3.2) generates near ideal maps from a tracking per-
spective.

Figure 10 qualitatively compares the spatial reliabil-

12

Table 3: Tracking performance comparison of the two
versions of CSR-DCF on VOT2016.
The proposed
method is denoted as CSR-DCF while the version using
ground-truth segmentation masks instead of color-based
spatial reliability map is denoted as CSR*-DCF.

Tracker
CSR-DCF
CSR*-DCF

EAO
0.338
0.338

Aav
0.51
0.51

Rav
0.85
0.83

the maps are different. But from the perspective of track-
ing they are nearly equivalent since the tracking perfor-
mance remains unchanged. For example, in the case of a
basketball player, the legs are not well segmented by our
approach. But since the legs constantly move, they are in
fact non-informative for object localization from the per-
spective of the correlation ﬁlter template matching and do
not contribute to improved tracking.

4.6 The OTB100 benchmark (Wu et al,

2015)

The OTB100 (Wu et al, 2015) benchmark contains re-
sults of 29 trackers evaluated on 100 sequences by a no-
reset evaluation protocol. Tracking quality is measured by
precision and success plots. The success plot shows the
fraction of frames with the overlap between th epredicted
and ground truth bounding box greater than a threshold
with respect to all threshold values. The precision plot
shows similar statistics on the center error. The results are
summarized by areas under these plots. To reduce clut-
ter, we show here only the results for top-performing re-
cent baselines, i.e., Struck (Hare et al, 2011), TLD (Kalal
et al, 2012), CXT (Dinh et al, 2011), ASLA (Xu Jia,
2012), SCM (Wei Zhong, 2012), LSK (Liu et al, 2011),
CSK (Henriques et al, 2012) and results for recent top-
performing state-of-the-art trackers SRDCF (Danelljan
et al, 2015a) and MUSTER (Hong et al, 2015).

The CSR-DCF is ranked top on the benchmark
(Fig. 11). It signiﬁcantly outperforms the best perform-
ers reported in (Wu et al, 2015) and outperforms the
current state-of-the-art SRDCF (Danelljan et al, 2015a)
and MUSTER (Hong et al, 2015). The average CSR-
DCF performance on success plot is slightly lower than
SRDCF (Danelljan et al, 2015a) due to poorer scale esti-
mation, but yields better performance in the average preci-
sion (center error). Both, precision and success plot, show
that the CSR-DCF tracks on average longer than compet-
ing methods.

4.7 The VOT2015 benchmark (Kristan

et al, 2015)

Figure 10: Qualitative comparison of the spatial reliabil-
ity maps during tracking. The dashed bounding box rep-
resents area from which correlation ﬁlter is obtained. This
is also the area where spatial reliability map is calculated.
In addition, the ground-truth segmentation masks are vi-
sualized on the right side under each frame.

ity maps to the ground-truth segmentation masks on
VOT2016 (Kristan et al, 2016b). Note that at pixel level,

The VOT2015 (Kristan et al, 2015) benchmark contains
results of 63 state-of-the-art trackers evaluated on 60 chal-

13

Figure 11: Evaluation on OTB100 (Wu et al, 2015) bench-
mark.

In contrast to related benchmarks,
lenging sequences.
the VOT2015 dataset was constructed from over 300 se-
quences by an advanced sequence selection methodology
that favors objects difﬁcult to track and maximizes a vi-
sual attribute diversity cost function (Kristan et al, 2015).
This makes it arguably the most challenging sequence set
available. The VOT methodology (Kristan et al, 2016c)
resets a tracker upon failure to fully use the dataset. The
basic VOT measures are the number of failures during
tracking (robustness) and average overlap during the pe-
riods of successful tracking (accuracy), while the primary
VOT2015 measure is the expected average overlap (EAO)
on short-term sequences. The latter can be thought of
as the expected no-reset average overlap (AUC in OTB
methodology), but with reduced bias and the variance as
explained in (Kristan et al, 2015).

Figure 12 shows the VOT EAO plots with the CSR-
DCF and the VOT2015 state-of-the-art approaches con-
sidering the VOT2016 rules that do not consider track-
ers learned on video sequences related to VOT to pre-
vent over-ﬁtting. The CSR-DCF outperforms all track-
ers and achieves the top rank. The CSR-DCF signiﬁ-
cantly outperforms the related correlation ﬁlter trackers
like SRDCF (Danelljan et al, 2015a) as well as trackers
that apply computationally-intesive state-of-the-art deep
features e.g., deepSRDCF (Danelljan et al, 2015b) and
SO-DLT (Wang et al, 2015b). For completeness, detailed
results for the ten top-performing trackers are shown in
Table 4.

Figure 12: Expected average overlap (EAO) plot for
CSR-DSF (#1) and all trackers participating in the VOT
2015 (Kristan et al, 2015) benchmark listed below the plot
in alphabetical order with their numerical codes.

Table 4: The ten top-performing trackers on the VOT2015
benchmark.

Tracker
CSR-DCF
DeepSRDCF
EBT
srdcf
LDP
sPST
scebt
nsamf
struck
rajssc

EAO
1 0.320
2 0.318
3 0.313
0.288
0.278
0.277
0.255
0.254
0.246
0.242

Aav
3 0.55
2 0.56
0.45
3 0.55
0.49
0.54
0.54
0.53
0.46
1 0.57

Rav
2 0.93
3 1.00
1 0.81
1.18
1.30
1.42
1.72
1.45
1.50
1.75

4.8 The VOT2016 benchmark (Kristan

et al, 2016b)

Finally, we assess our tracker on the most recent visual
tracking benchmark, VOT2016 (Kristan et al, 2016b).
The dataset contains 60 sequences from VOT2015 (Kris-

14

performing trackers come from various classes e.g., cor-
relation ﬁlter methods: CCOT (Danelljan et al, 2016),
Staple (Bertinetto et al, 2016a), DDC (Kristan et al,
2016b), deep convolutional network based: TCNN (Kris-
tan et al, 2016b), SSAT (Kristan et al, 2016b; Nam and
Han, 2016), MLDF (Kristan et al, 2016b; Wang et al,
2015a), FastSiamnet (Bertinetto et al, 2016b) and differ-
ent detection-based approaches: EBT (Zhu et al, 2016)
and SRBT (Kristan et al, 2016b).

Figure 13 shows the EAO performance on the
VOT2016. The CSR-DCF outperforms all 70 trackers
with the EAO score equal to 0.338. The CSR-DCF signif-
icantly outperforms correlation ﬁlter approaches that do
not apply deep ConvNets. Even though the CSR-DCF ap-
plies only simple features, it outperforms all trackers that
apply computationally intensive deep features. Detailed
performance scores for the ten top-performing trackers
are shown in Table 5.

4.9 Per-attribute analysis

The VOT2016 (Kristan et al, 2016b) dataset is per-frame
annotated with visual attributes and allows detailed anal-
ysis of per-attribute tracking performance. Figure 14
shows per-attribute plot for ten top-performing trackers on
VOT2016 in EAO. The CSR-DCF is consistently ranked
among top three trackers on ﬁve out of six attributes. In
four attributes (size change, occlusion, camera motion,
unassigned) the tracker is ranked top. The only attribute
on which our CSR-DCF is outperformed by four of the
compared trackers (MLDF, CCOT, SSAT and TCNN) is
illumination change. All of these trackers use deep CNN
features which are much more complex than the features
in CSR-DCF and better handle illumination change.

4.10 Tracking speed analysis

Tracking speed is an important factor of many real-world
tracking problems. Table 6 thus compares several related
and well-known trackers (including the best-performing
tracker on the VOT2016 challenge) in terms of speed and
VOT performance measures. Speed measurements on a
single CPU are computed on Intel Core i7 3.4GHz stan-
dard desktop.

The CSR-DCF performs on par with the VOT2016
best-performing CCOT (Danelljan et al, 2016), which

Figure 13: Expected average overlap (EAO) plot for
CSR-DSF (#1) and all trackers participating in the VOT
2016 (Kristan et al, 2016b) benchmark listed below the
plot in alphabetical order with their numerical codes.

Table 5: The ten top-performing trackers on the VOT2016
benchmark.

Tracker
CSR-DCF
CCOT
TCNN
SSAT
MLDF
Staple
DDC
EBT
SRBT
STAPLEp

EAO
1 0.338
2 0.331
3 0.325
0.321
0.311
0.295
0.293
0.291
0.290
0.286

Aav
0.51
0.52
3 0.54
1 0.57
0.48
3 0.54
0.53
0.44
0.50
2 0.55

Rav
2 0.85
2 0.85
0.96
1.04
1 0.83
1.35
1.23
3 0.90
1.25
1.32

tan et al, 2015) with improved annotations. The bench-
mark evaluated a set of 70 trackers which includes
the recently published and yet unpublished state-of-
the top-
the-art trackers. The set is indeed diverse,

15

Table 6: Speed in frames per second (fps) of correlation
trackers and Struck – a baseline. The EAO, average accu-
racy (Aav) and average failures (Rav) are shown for ref-
erence.

Tracker

ECCV2016

CSR-DCF
CCOT
CCOT* ECCV2016
SRDCF ICCV2015
KCF
DSST
Struck

PAMI2015

PAMI2016

ICCV2011

fps

Aav

Rav

EAO
1 0.338 2 0.51 1 0.85 3
2 0.331 1 0.52 1 0.85
3 0.274 1 0.52 2 1.18
0.247 1 0.52 3 1.50
0.192 3 0.48
0.181 3 0.48
0.42
0.142

13.0
0.6
1.0
7.3
2.03 1 115.7
18.6
2.52 2
8.5
3.37

The average speed of our tracker measured on the VOT
2016 dataset is approximately 13 frames-per-second2 or
77 milliseconds per-frame. Figure 15 shows the process-
ing time required by each step of the CSR-DCF. A track-
ing iteration is divided into two steps: (i) target localiza-
tion and (ii) the visual model update. Target localization
takes in average 35 milliseconds at each frame and is com-
posed of two sub-steps: estimation of object translation
(23ms) and scale change estimation (12ms). The visual
model update step takes on average 42 milliseconds. It
consists of three sub-steps: spatial reliability map estima-
tion (16ms), ﬁlter update (12ms) and scale model update
(14ms). Filter optimization, which is part of the ﬁlter up-
date step, takes on average 7 milliseconds.

4.11 Qualitative evaluation

Figure 16 shows four examples of tracking with the CSR-
DCF. In the following we describe tracking performance
on each sequence.

The ﬁrst example shows tracking of an octopus along
with channel reliability weights.
The ﬁrst eighteen
weights correspond to HoG channels, the 19th weight is
reliability of a grayscale template and the last ten weights
correspond to colornames. Note that the colors in boxes
are not the actual colors of the colornames, because these
features are subspace of original colornames, designed to

2With some basic code optimization and refactoring we speed-up our
algorithm to 19 FPS without signiﬁcant performance drop (only one ad-
ditional failure on VOT2016 dataset).

Figure 14: Expected averaged overlap performance on
different visual attributes on the VOT2016 (Kristan et al,
2016b) benchmark. The CSR-DCF and the top 10 per-
forming trackers from VOT2016 are shown. The scales
of visual attribute axes are shown below the attribute la-
bels.

applies deep ConvNets, with respect to VOT measures,
while being 20 times faster than the CCOT. The CCOT
was modiﬁed by replacing the computationally intensive
deep features with the same simple features used in CSR-
DCF. The resulting tracker, indicated by CCOT*, is still
ten times slower than CSR-DCF, while the performance
drops by over 15%. The CSR-DCF performs twice as
fast as the related SRDCF (Danelljan et al, 2015a), while
achieving approximately 25% better tracking results. The
speed of baseline real-time trackers like DSST (Danelljan
et al, 2014a) and Struck (Hare et al, 2011) is compara-
ble to CSR-DCF, but their tracking performance is signif-
icantly poorer. The fastest compared tracker, KCF (Hen-
riques et al, 2015) runs much faster than real-time, but de-
livers a signiﬁcantly poorer performance than CSR-DCF.
The experiments show that the CSR-DCF tracks com-
parably to the state-of-the-art trackers which apply com-
putationally demanding high-dimensional features, but
runs considerably faster and delivers top tracking perfor-
mance among the real-time trackers.

16

5 Conclusion

The Discriminative Correlation Filter with Channel and
Spatial Reliability (CSR-DCF) was introduced. The spa-
tial reliability map adapts the ﬁlter support to the part
of the object suitable for tracking which overcomes both
the problems of circular shift enabling an arbitrary search
region size and the limitations related to the rectangu-
lar shape assumption. A novel efﬁcient spatial reliability
map estimation method was proposed and an efﬁcient op-
timization procedure was used for learning a correlation
ﬁlter with the support constrained by the estimated map.
The second novelty of CSR-DCF is the channel reliabil-
ity. The reliability is estimated from the properties of the
constrained least-squares solution. The channel reliabil-
ity scores were used for weighting the per-channel ﬁlter
responses in localization.

Experimental comparison with recent related state-of-
the-art boundary-constraints formulations showed signif-
icant beneﬁts of using our formulation. The CSR-DCF
achieves state-of-the-art performance on standard bench-
marks: OTB100 (Wu et al, 2015), VOT2015 (Kristan et al,
2015) and VOT2016 (Kristan et al, 2016b) while run-
ning close to the real-time on a single CPU. Despite using
simple features like HoG and Colornames, the CSR-DCF
performs on par with trackers that apply computationally
complex deep ConvNet, but is signiﬁcantly faster.

To the best of our knowledge, the proposed approach
is the ﬁrst of its kind to introduce constrained ﬁlter learn-
ing with arbitrary spatial reliability map and the use of
channel reliabilities. The spatial and channel reliability
formulation is general and can be used in most modern
correlation ﬁlters, e.g. those using deep features.

6 Appendix 1: Derivation of the
augmented Lagrangian mini-
mizer

This section provides a complete derivation of the rela-
tions (12, 13) in the Section 3.1. The augmented La-

17

Figure 15: A single iteration processing time decomposed
across the main steps of the CSR-DCF.

improve correlation ﬁlter tracking (see (Danelljan et al,
2014b)). Observe that when the octopus changes shape
signiﬁcantly, some channels become more discriminative
than the others – this is particularly evident in the ﬁrst
eighteen channels that represent the HoG features.

Tracking a gymnast is shown in the second example.
The target is deforming and rotating over the sequence
signiﬁcantly, while our tracker is able to successfully
track it. Additionally, the correlation response from the
localization step is shown for each frame. The peak in
the response is well expressed, which means that the ﬁlter
accurately represents the target and that the discrimina-
tive channels overrule the less discriminative ones by our
channel reliability estimation approach.

The third example shows tracking a sprinter. The spa-
tial reliability map is visualized next to each frame. In
the bottom-right corner of each frame the tracking patch
is overlaid with the spatial reliability map. The reliability
maps ﬁt the target well and prevent the ﬁlter from learning
the background.

The last example shows tracking under occlusion, i.e.,
a motorcyclist driving on the road while being repeatedly
occluded by the trees. This example demonstrates that
our tracker is robust to short-term full occlusions and that
it is able to recover and localize the target despite the full
occlusion. This is possible due to the robust learning with
channel and spatial reliability map and the large capture
range that our learning scheme provides.

grangian from Equation (8) is

The partial complex gradients are:

L(ˆhc, h,ˆl) = (cid:107)diag(ˆf )ˆhc − ˆg(cid:107)2 +

(cid:107)hm(cid:107)2 + (20)

λ
2

[ˆlH (ˆhc − ˆhm) + ˆlH (ˆhc − ˆhm)] + µ(cid:107)ˆhc − ˆhm(cid:107)2,

with hm = (m (cid:12) h). For the purposes of derivation we
will rewrite (20) into a fully vectorized form

L(ˆhc, h,ˆl) = (cid:107)diag(ˆf )ˆhc − ˆg(cid:107)2 +
(cid:20)
ˆlH (ˆhc −

DFMh) + ˆlH (ˆhc −
√

√

µ(cid:107)ˆhc −

DFMh(cid:107)2,

λ
2
√

(cid:107)hm(cid:107)2+ (21)
(cid:21)

DFMh)

+

where F denotes D × D orthonormal matrix of Fourier
coefﬁcients, such that the Fourier transform is deﬁned as
ˆx = F(x) =
DFx and M = diag(m). For clearer
representation we denote the four terms in the summation
(21) as

√

L(ˆhc, h,ˆl) = L1 + L2 + L3 + L4,

(22)

where

(cid:16)

L1 =

diag(ˆf )ˆhc − ˆg

diag(ˆf )ˆhc − ˆg

(cid:17)

,

(cid:17)T (cid:16)

L2 =

(cid:107)hm(cid:107)2,

λ
2

∇ˆhc

L1 =

(31)

diag(ˆf )ˆhc − ˆg

(cid:17)(cid:21)

=

=

=

(cid:20)(cid:16)

(cid:17)T (cid:16)

diag(ˆf )ˆhc − ˆg

∂
∂ ˆhc
(cid:20)
∂
c diag(ˆf )H diag(ˆf )ˆhc − ˆhT
ˆhT
∂ ˆhc

ˆgH diag(ˆf )ˆhc + ˆgH ˆg

=

(cid:21)

c diag(ˆf )H ˆg−

= diag(ˆf )H diag(ˆf )ˆhc − diag(ˆf )ˆg,

∇ˆhc

L2 = 0,

∇ˆhc

L3 =

(32)

(33)
(cid:17)(cid:21)

(cid:21)

(cid:20)
ˆlH (cid:16)ˆhc −

√

DFMh

(cid:17)

+ ˆlH

(cid:16)ˆhc −

DFMh

=

(cid:20)
ˆlH ˆhc − ˆlH

√

DFMh + ˆlT ˆhc − ˆlT

DFMh

=

√

√

=

=

∂
∂ ˆhc
∂
∂ ˆhc

= ˆl,

L3 = ˆlH (ˆhc −

√

DFMh) + ˆlH (ˆhc −
√

L4 = µ(cid:107)ˆhc −

DFMh(cid:107)2.

√

DFMh), (25)

=

∂
∂ ˆhc

(cid:20)

(cid:16)ˆhc −
µ

√

DFMh

∇ˆhc

L4 =
(cid:17)T (cid:16)ˆhc −

√

(cid:17)(cid:21)

DFMh

=

(34)

Minimization of Equation (8) in Section 3.1 is an itera-
tive process at which the following minimizations are re-
quired:

ˆhopt

c = arg min

L(ˆhc, h,ˆl),

hopt = arg min

L(ˆhopt
c

, h,ˆl).

hc

h

Minimization w.r.t. to ˆhc is derived by ﬁnding ˆhc at which
the complex gradient of the augmented Lagrangian van-
ishes, i.e.,

∇ˆhc

L1 + ∇ˆhc

L3 + ∇ˆhc

L4 ≡ 0.

L ≡ 0,

∇ˆhc
L2 + ∇ˆhc

=

∂
∂ ˆhc

√

(cid:20)

(cid:16)ˆhH
µ

c

ˆhc − ˆhH
c

√

DFMh−

DhT MFH ˆhc + DhT MFH FMh

(cid:17)(cid:21)

=

√

= µˆhc − µ

DFMh.

√

Note that
inition of ˆhm. Plugging (31-34) into (30) yields

DFMh = ˆhm according to our original def-

diag(ˆf )H diag(ˆf )ˆhc − diag(ˆf )ˆg + ˆl + µˆhc − µˆhm = 0,
(35)

ˆhc =

diag(ˆf )ˆg + µˆhm − ˆl
diag(ˆf )H diag(ˆf ) + µ

,

(23)

(24)

(26)

(27)

(28)

(29)

(30)

18

which can be rewritten into

Plugging (39-43) into (38) yields

ˆhc =

ˆf (cid:12) ˆg + µˆhm − ˆl
ˆf (cid:12) ˆf + µ

.

(36)

Mh −

DMFHˆl − µ

√

λ
2

√

√

DMFH ˆhc + µDMh = 0,
(44)

Next we derive the closed-form solution of (28). The op-
timal h is obtained when the complex gradient w.r.t. h
vanishes, i.e.,

Mh = M

DFH (ˆl + µˆhc)
λ
2 + µD

.

∇hL ≡ 0
∇hL1 + ∇hL2 + ∇hL3 + ∇hL4 ≡ 0.

The partial gradients are

∇hL1 = 0,

∇hL2 =
(cid:21)

T

(Mh)

(Mh)

=

=

∂
∂h

(cid:20) λ
2

∂
∂h

(cid:20) λ
2

(cid:21)
hHMMh
.

Since we deﬁned mask m as a binary mask, the product
MM can be simpliﬁed into M and the result for ∇hL2 is

∇hL2 =

Mh.

λ
2

The remaining gradients are as follows:

√

(cid:20)
ˆlH (cid:16)ˆhc −
(cid:20)
ˆlH ˆhc − ˆlH

√

=

=

∂
∂h
∂
∂h

∇hL3 =
(cid:17)

DFMh

+ ˆlH

(cid:16)ˆhc −

√

DFMh

=

DFMh + ˆlT ˆhc − ˆlT

DFMh

=

√

(cid:21)

√

= −

DMFHˆl,

(37)

(38)

(39)

(40)

(41)

(42)
(cid:17)(cid:21)

Using the deﬁnition of the inverse Fourier transform, i.e.,
F −1(ˆx) = 1√
D

FH ˆx, (44) can be rewritten into

m (cid:12) h = m (cid:12)

(45)

F −1(ˆl + µˆhc)
λ
2D + µ

.

The values in m are either zero or one. Elements in h
that correspond to the zeros in m can in principle not be
recovered from (45) since this would result in division by
zero. But our initial deﬁnition of the problem was to seek
solutions for the ﬁlter that satisﬁes the following relation
h ≡ h(cid:12)m. This means the values corresponding to zeros
in m should be zero in h. Thus the proximal solution
to (45) is

h = m (cid:12)

F −1(ˆl + µˆhc)
λ
2D + µ

.

(46)

Acknownledgements

This work was supported in part by the following re-
search programs and projects: Slovenian research agency
research programs and projects P2-0214, L2-6765 and J2-
8175. Jiˇri Matas and Tom´aˇs Voj´ı˜r were supported by The
Czech Science Foundation Project GACR P103/12/G084
and Toyota Motor Europe. We would also like to thank
dr. Rok ˇZitko for discussion on complex differentiation.

∇hL4 =

√

DFMh

√

(cid:17)T (cid:16)ˆhc −
√

(cid:16)ˆhH
µ

c

ˆhc − ˆhH
c

DFMh−

(cid:17)(cid:21)

DFMh

=

=

(cid:20)

∂
∂h

(cid:16)ˆhc −
µ
(cid:20)

∂
∂h

=

√

DhHMFH ˆhc + DhHMh

√

= −µ

DMFH ˆhc + µDMh.

(cid:17)(cid:21)

=

(43)

References

Babenko B, Yang MH, Belongie S (2011) Robust object
tracking with online multiple instance learning. IEEE
Trans Pattern Anal Mach Intell 33(8):1619–1632

Bertinetto L, Valmadre J, Golodetz S, Miksik O, Torr PHS
(2016a) Staple: Complementary learners for real-time
tracking. In: Comp. Vis. Patt. Recognition, pp 1401–
1409

19

Bertinetto L, Valmadre J, Henriques JF, Vedaldi A, Torr
PH (2016b) Fully-convolutional siamese networks for
object tracking. arXiv preprint arXiv:160609549

Bolme DS, Beveridge JR, Draper BA, Lui YM (2010) Vi-
sual object tracking using adaptive correlation ﬁlters.
In: Comp. Vis. Patt. Recognition, IEEE, pp 2544–2550

Boyd S, Parikh N, Chu E, Peleato B, Eckstein J (2011)
Distributed optimization and statistical learning via the
alternating direction method of multipliers. Founda-
tions and Trends in Machine Learning 3(1):1–122

ˇCehovin L, Leonardis A, Kristan M (2016) Visual object
tracking performance measures revisited. IEEE Trans
Image Proc 25(3):1261–1274

Dalal N, Triggs B (2005) Histograms of oriented gradi-
ents for human detection. In: Comp. Vis. Patt. Recog-
nition, vol 1, pp 886–893

Danelljan M, H¨ager G, Khan FS, Felsberg M (2014a) Ac-
curate scale estimation for robust visual tracking. In:
Proc. British Machine Vision Conference, pp 1–11

Danelljan M, Khan FS, Felsberg M, van de Weijer J
(2014b) Adaptive color attributes for real-time visual
tracking. In: 2014 IEEE Conference on Computer Vi-
sion and Pattern Recognition, CVPR 2014, Columbus,
OH, USA, June 23-28, 2014, pp 1090–1097

Danelljan M, Hager G, Shahbaz Khan F, Felsberg M
(2015a) Learning spatially regularized correlation ﬁl-
ters for visual tracking. In: Int. Conf. Computer Vision,
pp 4310–4318

Danelljan M, H¨ager G, Khan FS, Felsberg M (2015b)
Convolutional features for correlation ﬁlter based vi-
sual tracking. In:
IEEE International Conference on
Computer Vision Workshop (ICCVW), pp 621–629

Danelljan M, Robinson A, Khan FS, Felsberg M (2016)
Beyond correlation ﬁlters: learning continuous convo-
lution operators for visual tracking. In: Proc. European
Conf. Computer Vision, Springer, pp 472–488

Danelljan M, H¨ager G, Khan FS, Felsberg M (2017) Dis-
criminative scale space tracking. IEEE Trans Pattern
Anal Mach Intell 39(8):1561–1575

Dinh TB, Vo N, Medioni G (2011) Context tracker:
Exploring supporters and distracters in unconstrained
environments. In: Comp. Vis. Patt. Recognition, pp
1177–1184

Diplaros A, Vlassis N, Gevers T (2007) A spatially
constrained generative model and an em algorithm
for image segmentation. IEEE Trans Neural Networks
18(3):798 – 808

Felzenszwalb P, Girshick R, McAllester D, Ramanan D
(2010) Object detection with discriminatively trained
part-based models. IEEE Trans Pattern Anal Mach In-
tell 32(9):1627–1645

Galoogahi HK, Sim T, Lucey S (2013) Multi-channel
correlation ﬁlters. In: Int. Conf. Computer Vision, pp
3072–3079

Grabner H, Grabner M, Bischof H (2006) Real-time
tracking via on-line boosting. In: Proc. British Machine
Vision Conference, vol 1, pp 47–56

Hare S, Saffari A, Torr PHS (2011) Struck: Structured
output tracking with kernels. In:
Int. Conf. Com-
puter Vision, IEEE Computer Society, Washington,
DC, USA, pp 263–270

Henriques JF, Caseiro R, Martins P, Batista J (2012) Ex-
ploiting the circulant structure of tracking-by-detection
with kernels. In: Fitzgibbon A, Lazebnik S, Perona P,
Sato Y, Schmid C (eds) Proc. European Conf. Com-
puter Vision, Springer Berlin Heidelberg, Berlin, Hei-
delberg, pp 702–715

Henriques JF, Caseiro R, Martins P, Batista J (2015) High-
speed tracking with kernelized correlation ﬁlters. IEEE
Trans Pattern Anal Mach Intell 37(3):583–596

Hester CF, Casasent D (1980) Multivariant technique
for multiclass pattern recognition. Applied Optics
19(11):1758–1761

Hong Z, Chen Z, Wang C, Mei X, Prokhorov D, Tao
D (2015) Multi-store tracker (muster): A cognitive
psychology inspired approach to object tracking. In:
Comp. Vis. Patt. Recognition, pp 749–758

20

Kalal Z, Mikolajczyk K, Matas J (2012) Tracking-
learning-detection. IEEE Trans Pattern Anal Mach In-
tell 34(7):1409–1422

Liang P, Blasch E, Ling H (2015) Encoding color infor-
mation for visual tracking: Algorithms and benchmark.
IEEE Trans Image Proc 24(12):5630–5644

Kiani Galoogahi H, Sim T, Lucey S (2015) Correlation
ﬁlters with limited boundaries. In: Comp. Vis. Patt.
Recognition, pp 4630–4638

Kristan M, Pﬂugfelder R, Leonardis A, Matas J, Porikli F,
ˇCehovin L, Nebehay G, Fernandez G, Vojir Tea (2013)
The visual object tracking vot2013 challenge results.
In: Vis. Obj. Track. Challenge VOT2013, In conjunc-
tion with ICCV2013, pp 98–111

Kristan M, Pﬂugfelder R, Leonardis A, Matas J, ˇCehovin
L, Nebehay G, Vojir T, et al Fernandez G (2014) The vi-
sual object tracking vot2014 challenge results. In: Proc.
European Conf. Computer Vision, pp 191–217

Kristan M, Matas J, Leonardis A, Felsberg M, ˇCehovin
L, Fernandez G, Vojir T, H¨ager G, Nebehay G,
et al Pﬂugfelder R (2015) The visual object tracking
vot2015 challenge results. In: Int. Conf. Computer Vi-
sion

Kristan M, Kenk VS, Kovaˇciˇc S, Perˇs J (2016a) Fast
image-based obstacle detection from unmanned surface
vehicles. IEEE Transactions on Cybernetics 46(3):641–
654

Kristan M, Leonardis A, Matas J, Felsberg M, Pﬂugfelder
R, ˇCehovin L, Vojir T, H¨ager G, Lukeˇziˇc A, et al Fer-
nandez G (2016b) The visual object tracking vot2016
challenge results. In: Proc. European Conf. Computer
Vision

Kristan M, Matas J, Leonardis A, Vojir T, Pﬂugfelder
R, Fernandez G, Nebehay G, Porikli F, Cehovin L
(2016c) A novel performance evaluation methodol-
ogy for single-target trackers. IEEE Trans Pattern Anal
Mach Intell

Li Y, Zhu J (2014a) A scale adaptive kernel correlation ﬁl-
ter tracker with feature integration. In: Proc. European
Conf. Computer Vision, pp 254–265

Li Y, Zhu J (2014b) A scale adaptive kernel correlation ﬁl-
ter tracker with feature integration. In: Proc. European
Conf. Computer Vision, pp 254–265

Liu B, Huang J, Yang L, Kulikowsk C (2011) Robust
tracking using local sparse appearance model and k-
selection. In: Comp. Vis. Patt. Recognition, pp 1313–
1320

Liu S, Zhang T, Cao X, Xu C (2016) Structural correlation
ﬁlter for robust visual tracking. In: Comp. Vis. Patt.
Recognition, pp 4312–4320

Liu T, Wang G, Yang Q (2015) Real-time part-based vi-
sual tracking via adaptive correlation ﬁlters. In: Comp.
Vis. Patt. Recognition, pp 4902–4912

Lukeˇziˇc A,

ˇC Zajc L, Kristan M (2017) Deformable
parts correlation ﬁlters for robust visual tracking. IEEE
Transactions on Cybernetics PP(99):1–13

Ma C, Huang JB, Yang X, Yang MH (2015) Hierarchical
convolutional features for visual tracking. In: Int. Conf.
Computer Vision, pp 3074–3082

Mueller M, Smith N, Ghanem B (2016) A benchmark and
simulator for uav tracking. In: Proc. European Conf.
Computer Vision

Nam H, Han B (2016) Learning multi-domain convolu-
tional neural networks for visual tracking. In: Comp.
Vis. Patt. Recognition, pp 4293–4302

Qi Y, Zhang S, Qin L, Yao H, Huang Q, Lim J, Yang
MH (2016) Hedged deep tracking. In: CVPR, pp 4303–
4311

Smeulders A, Chu D, Cucchiara R, Calderara S, De-
hghan A, Shah M (2014) Visual tracking: An exper-
imental survey. IEEE Trans Pattern Anal Mach Intell
36(7):1442–1468

Vojir T, Matas J (2017) Pixel-wise object segmenta-
tions for the VOT 2016 dataset. Research Report
CTU–CMP–2017–01, Center for Machine Perception,
K13133 FEE Czech Technical University, Prague,
Czech Republic

21

Wang L, Ouyang W, Wang X, Lu H (2015a) Visual track-
ing with fully convolutional networks. In: Int. Conf.
Computer Vision, pp 3119–3127

Wang N, Li S, Gupta A, Yeung D (2015b) Transfer-
ring rich feature hierarchies for robust visual tracking.
CoRR abs/1501.04587

Wang S, Zhang S, Liu W, Metaxas DN (2016) Visual
tracking with reliable memories. In: Proceedings of the
Twenty-Fifth International Joint Conference on Artiﬁ-
cial Intelligence, pp 3491–3497

Wei Zhong MHY Huchuan Lu (2012) Robust object
tracking via sparsity-based collaborative model. In:
Comp. Vis. Patt. Recognition, pp 1838–1845

van de Weijer J, Schmid C, Verbeek J, Larlus D (2009)
Learning color names for real-world applications. IEEE
Trans Image Proc 18(7):1512–1523

Wu Y, Lim J, Yang MH (2013) Online object tracking: A
benchmark. In: Comp. Vis. Patt. Recognition, pp 2411–
2418

Wu Y, Lim J, Yang MH (2015) Object

tracking
benchmark. IEEE Trans Pattern Anal Mach Intell
37(9):1834–1848

Xu Jia MHY Huchuan Lu (2012) Visual tracking via
adaptive structural local sparse appearance model. In:
Comp. Vis. Patt. Recognition, pp 1822–1829

Zhang K, Zhang L, Liu Q, Zhang D, Yang MH (2014)
Fast visual tracking via dense spatio-temporal context
learning. In: Proc. European Conf. Computer Vision,
Springer International Publishing, pp 127–141

Zhu G, Porikli F, Li H (2016) Beyond local search: Track-
ing objects everywhere with instance-speciﬁc propos-
als. In: The IEEE Conference on Computer Vision and
Pattern Recognition (CVPR), pp 943–951

22

Figure 16: Qualitative results of tracking with the CSR-DCF on four video sequences.

23

