5
1
0
2
 
g
u
A
 
3
1
 
 
]

G
L
.
s
c
[
 
 
1
v
9
2
3
3
0
.
8
0
5
1
:
v
i
X
r
a

Multi-Task Learning with Group-Speciﬁc Feature
Space Sharing

Niloofar Youseﬁ, Michael Georgiopoulos and Georgios C. Anagnostopoulos

NY, MG: EE & CS Dept., University of Central Florida; GCA: ECE Dept., Florida Institute of Technology

niloofaryouseﬁ@knights.ucf.edu, michaelg@ucf.edu and georgio@ﬁt.edu

Abstract

When faced with learning a set of inter-related tasks from a limited amount of usable data, learning
each task independently may lead to poor generalization performance. Multi-Task Learning (MTL)
exploits the latent relations between tasks and overcomes data scarcity limitations by co-learning all these
tasks simultaneously to oﬀer improved performance. We propose a novel Multi-Task Multiple Kernel
Learning framework based on Support Vector Machines for binary classiﬁcation tasks. By considering
pair-wise task aﬃnity in terms of similarity between a pair’s respective feature spaces, the new framework,
compared to other similar MTL approaches, oﬀers a high degree of ﬂexibility in determining how similar
feature spaces should be, as well as which pairs of tasks should share a common feature space in order to
beneﬁt overall performance. The associated optimization problem is solved via a block coordinate descent,
which employs a consensus-form Alternating Direction Method of Multipliers algorithm to optimize the
Multiple Kernel Learning weights and, hence, to determine task aﬃnities. Empirical evaluation on seven
data sets exhibits a statistically signiﬁcant improvement of our framework’s results compared to the ones
of several other Clustered Multi-Task Learning methods.

Keywords: Multi-task Learning, Kernel Methods, Generalization Bound, Support Vector Machines

1

Introduction

Multi-Task Learning (MTL) is a machine learning paradigm, where several related task are learnt simul-
taneously with the hope that, by sharing information among tasks, the generalization performance of each
task will be improved. The underlying assumption behind this paradigm is that the tasks are related to
each other. Thus, it is crucial how to capture task relatedness and incorporate it into an MTL framework.
Although, many diﬀerent MTL methods [7, 12, 18, 15, 28, 1] have been proposed, which diﬀer in how the
relatedness across multiple tasks is modeled, they all utilize the parameter or structure sharing strategy to
capture the task relatedness.

However, the previous methods are restricted in the sense that they assume all tasks are similarly related
to each other and can equally contribute to the joint learning process. This assumption can be violated in
many practical applications as “outlier” tasks often exist. In this case, the eﬀect of “negative transfer”, i.e.,
sharing information between irrelevant tasks, can lead to a degraded generalization performance.

To address this issue, several methods, along diﬀerent directions, have been proposed to discover the
inherent relationship among tasks. For example, some methods [3, 27, 28, 29], use a regularized probabilistic
setting, where sharing among tasks is done based on a common prior. These approaches are usually compu-
tationally expensive. Another family of approaches, known as the Clustered Multi-Task Learning (CMTL),
assumes that tasks can be clustered into groups such that the tasks within each group are close to each other
according to a notion of similarity. Based on the current literature, clustering strategies can be broadly
classiﬁed into two categories: task-level CMTL and feature-level CMTL.

1

The ﬁrst one, task-level CMTL, assumes that the model parameters used by all tasks within a group are
close to each other. For example, in [2, 13, 17], the weight vectors of the tasks belonging to the same group
are assumed to be similar to each other. However, the major limitations for these methods are: (i) that such
an assumption might be too risky, as similarity among models does not imply that meaningful sharing of
information can occur between tasks, and (ii) for these methods, the group structure (number of groups or
basis tasks) is required to be known a priori.

The other strategy for task clustering, referred to as feature-level CMTL, is based on the assumption
that task relatedness can be modeled as learning shared features among the tasks within each group. For
example, in [19] the tasks are clustered into diﬀerent groups and it is assumed that tasks within the same
group can jointly learn a shared feature representation. The resulting formulation leads to a non-convex
objective, which is optimized using an alternating optimization algorithm converging to local optima, and
suﬀers potentially from slow convergence. Another similar approach has been proposed in [26], which assumes
that tasks should be related in terms of feature subsets. This study also leads to a non-convex co-clustering
structure that captures task-feature relationship. These methods are restricted in the sense that they assume
that tasks from diﬀerent groups have nothing in common with each other. However, this assumption is not
always realistic, as tasks in disjoint groups might still be inter-related, albeit weekly. Hence, assigning tasks
into diﬀerent groups may not take full advantage of MTL. Another feature-level clustering model has been
proposed in [30], in which the cluster structure can vary from feature to feature. While, this model is more
ﬂexible compared to other CMTL methods, it is, however, more complicated and also less general compared
to our framework, as it tries to ﬁnd a shared feature representation for tasks by decomposing each task
parameter into two parts: one to capture the shared structure between tasks and another to capture the
variations speciﬁc to each task. This model is further extended in [16], where a multi-level structure has
been introduced to learn task groups in the context of MTL. Interestingly, it has been shown that there
is an equivalent relationship between CMTL and alternating structure optimization [31], wherein the basic
idea is to identify a shared low-dimensional predictive structure for all tasks.

In this paper, we develop a new MTL model capable of modeling a more general type of task relationship,
where the tasks are implicitly grouped according to a notion of feature similarity. In our framework, the tasks
are not forced to have a common feature space; instead, the data automatically suggests a ﬂexible group
structure, in which a common, similar or even distinct feature spaces can be determined between diﬀerent
pairs of tasks. Additionally, our MTL framework is kernel-based and, thus, may take advantage of the non-
linearity introduced by the feature mapping of the associated Reproducing Kernel Hilbert Space (RKHS)
.
H
Also, to avoid a degradation in generalization performance due to choosing an inappropriate kernel function,
our framework employs a Multiple Kernel Learning (MKL) strategy [21], hence, rendering it a Multi-Task
Multiple Kernel Learning (MT-MKL) approach.

∀

P

t = 0,

M
m=1(µm + λm

It is worth mentioning that a widely adopted practice for combining kernels is to place an Lp-norm
constraint on the combination coeﬃcients θ = [θ1, . . . , θM ], which are learned during training. For example,
a conically combination of task objectives with an Lp-norm feasible region is introduced in [23] and further
extended in [22]. Also, another method introduced in [25] proposes a partially shared kernel function
kt ,
t )km, along with L1-norm constraints on µ and λ. The main advantage of such a
method over the traditional MT-MKL methods, which consider a common kernel function for all tasks (by
letting λm
t, m), is that it allows tasks to have their own task-speciﬁc feature spaces and, potentially,
alleviate the eﬀect of negative transfer. However, popular MKL formulations in the context of MTL, such as
this one, are capable of modeling two types of tasks: those that share a global, common feature space and
those that employ their own, task-speciﬁc feature space. In this work we propose a more ﬂexible framework,
which, in addition to allowing some tasks to use their own speciﬁc feature spaces (to avoid negative transfer
learning), it permits forming arbitrary groups of tasks sharing the same, group-speciﬁc (instead of a single,
global), common feature space, whenever warranted by the data. This is accomplished by considering a
group lasso regularizer applied to the set of all pair-wise diﬀerences of task-speciﬁc MKL weights. For
no regularization penalty, each task is learned independently of each other and will utilize its own feature
space. As the regularization penalty increases, pairs of MKL weights are forced to equal each other leading
the corresponding pairs of tasks to share a common feature space. We demonstrate that the resulting
optimization problem can be solved by employing a 2-block coordinate descent approach, whose ﬁrst block
consists of the Support Vector Machine (SVM) weights for each task and which can be optimized eﬃciently
using existing solvers, while its second block comprises the MKL weights from all tasks and is optimized via

2

a consensus-form, Alternating Direction Method of Multipliers (ADMM)-based step.

The rest of the paper is organized as follows: In Sect. 2 we describe our formulation for jointly learning
the optimal feature spaces and the parameters of all the tasks. Sect. 3 provides an optimization technique
to solve our non-smooth convex optimization problem derived in Sect. 2. Sect. 4 presents a Rademacher
complexity-based generalization bound for the hypothesis space corresponding to our model. Experiments
are provided in Sect. 5, which demonstrate the eﬀectiveness of our proposed model compared to several MTL
methods. Finally, in Sect. 6 we conclude our work and brieﬂy summarize our ﬁndings.

Notation: In what follows, we use the following notational conventions: vectors and matrices are depicted
in bold face. A prime ′ denotes vector/matrix transposition. The ordering symbols
when applied
to vectors stand for the corresponding component-wise relations. If Z+ is the set of postivie integers, for a
given S

Z+, we deﬁne NS ,

. Additional notation is deﬁned in the text as needed.
}

1, . . . , S
{

and

(cid:23)

(cid:22)

∈

2 Formulation

{

1, 1

(xn

t , yn
t )

X × {−

nt
n=1 , t
}

. Here,
}

wt, φt(x)
h

NT , which is sampled from
Assume T supervised learning tasks, each with a training set
denotes the native space of samples for all tasks
an unknown distribution Pt(x, y) on
X
1 are the associated labels. Without loss of generality, we will assume an equal number n of training
and
±
samples per task. The objective is to learn T binary classiﬁcation tasks using discriminative functions
ft(x) ,
NT , where wt is the weight vector associated to task t. Moreover, the
iHt,θ + bt for t
∈
Ht,θ =
feature space of task t is served by

M
t Hm with induced feature mapping φt , [
θm
m=1
· · ·
M
′]′ and endowed with the inner product
m=1 θm
·iHm . The reproducing kernel
,
·iHt,θ =
,
t h·
p
h·
t, xj
t, xj
t, xj
t ) for all xi
t km(xi
function for this feature space is given as kt(xi
In our
t ) =
p
framework, we attempt to learn the wt’s and bt’s jointly with the θt’s via the following regularized risk
minimization problem:

M
m=1 θm
P

t ∈ X

θM
t φM

θ1
t φ1

p
.

L

P

∈

′

min
w∈Ω(w),θ∈Ω(θ),b

T

2

k

wtk
2

+ C

T

n

t=1
X
Ω (w) ,
{
Ω (θ) ,
{

w = (w1,

θ = (θt,

1

tft(xi
yi
t)

+ + λ

(cid:2)

t=1
X

−
i=1
X
(cid:3)
, wT ) : wt ∈ Ht,θ, θ
· · ·
∈
0,
θtk1 ≤
, θT ) : θt (cid:23)
1,

k

s>t
X

t=1
X
Ω (θ)
}
NT }

t
∀

∈

· · ·

T −1

T

θt −

k

θsk2

(1)

where w , (wt,
, wT ) and θ , (θt,
w and θ respectively, and [u]+ = max
non-negative regularization parameters.

· · ·

· · ·
u, 0
{

}

∈

, θT ), Ω (w) and Ω (θ) are the corresponding feasible sets for
R denotes the hinge function. Finally, C and λ are

, u

The last term in Problem 1 is the sum of pairwise diﬀerences between the tasks’ feature weight vectors.
For each pair of (θt, θs), the pairwise penalty
θsk2 may favor a small number of non-identical θt.
Therefore, it ensures that a ﬂexible (common, similar or distinct) feature space, will be selected between
tasks t and s. In this manner, a ﬂexible group structure of shared features across multiple tasks can be
achieved by this framework. It is also worth mentioning that two special cases are covered by the proposed
θt −
model: (i) if λ
0 and, thus,
k
0, the proposed model reduces to T independent
all tasks share a single common feature space. (ii) As λ
classiﬁcation tasks.

(λ is only required to be suﬃciently large), for all task pairs

θsk2 →

θt −

→ ∞

→

k

It is easy to verify that Problem 1 is a convex minimization problem, which can be solved using a block
coordinate descent method alternating between the minimization with respect to θ and the (w, b) pair.
Motivated by the non-smooth nature of the last regularization term, in Sect. 3 we develop a consensus
version of the ADMM to solve the minimization problem with respect to θ.

3 The proposed Consensus Optimization Algorithm

Problem 1 can be formulated as the following equivalent problem, which entails T inter-related SVM training
problems:

3

min
θ,w,b,ξ

m=1
X

t=1
X
s.t. yi
t

T

M

T

n

T −1

T

2
Hm

k

wm
t k
2θm
t

+ C

ξi
t + λ

θt −
k

θsk2

wt, φ(xi
t)
θtk1 ≤
(cid:11)
It can be shown that the primal-dual form of Problem 2 with respect to θ and

(cid:16)(cid:10)
θt (cid:23)

≥
NT

NT , i

(cid:17)
∈

0,

1,

−

Ht

∈

∀

∀

k

t

t

Nn

∈

t=1
X
+ bt

i=1
X
1

t=1
X
t, ξi
ξi
t ≥

s>t
X
0,

min
θt∈Ω(θ)

max
αt∈Ω(α)

T

T

M

′

t1n −
α

1
2

′

θm
t (α

tYtK m

t Ytαt) + λ

T −1

T

w, b, ξ

is given by

{

}

θsk2

θt −
k
NT }

s>t
X
t

∈

′

C1n, α

θtk1 ≤

1,

t=1
X

tyt = 0,
∀
NT }

∈

t

∀

t=1
X
α = (αt,

{

Ω (α) ,
Ω (θ) ,

αt (cid:22)
0,
k
{
where 1n is a vector containing n 1’s, Y t , diag(yt), Km
t ), θt , [θ1
t, xj
given as km(xi
wt, bt, ξt}
.
w.r.t.

t , . . . , θM
t

θ = (θt,

· · ·

· · ·

{

m=1
t=1
X
X
, αT ) : 0
(cid:22)
, θT ) : θt (cid:23)

Rn×n is the kernel matrix, whose (i, j) entry is
]′, and αt is the Lagrangian dual variable for the minimization problem

t ∈

w, b, ξ

It is not hard to verify that the optimal objective value of the dual problem is equal to the optimal
objective value of the primal one, as the strong duality holds for the primal-dual optimization problems
and α respectively. Therefore, a block coordinate descent framework1 can be applied to
w.r.t.
decompose Problem 3 into two subproblems. The ﬁrst subproblem, which is the maximization problem with
respect to α, can be eﬃciently solved via LIBSVM [8], and the second subproblem, which is the minimization
problem with respect to θ, takes the form

}

{

T −1

T

min
θt

λ

t=1
X
0,
s.t. θt (cid:23)
t Ytαt and qt

θt −
k
s>t
X
θtk1 ≤
k
, [q1

T

′

θ

tqt

θsk2 +
t
1,

t=1
X
NT

∈
]′. Due to the non-smooth nature of Problem 4,
where we deﬁned qm
t
we derive a consensus ADMM-based optimization algorithm to solve it eﬃciently. Based on the exposition
provided in Sections 5 and 7 of [6], it is straightforward to verify that Problem 4 can be written in ADMM
form as

∀
t , . . . , qM
t

tYtK m

1
2 α

,

−

′

N

min
s,θ,z

λ

hi(si) + g(θ) + IΩ(θ)(z)

i=1
X
s.t. si −
z
−
, and the local variable si ∈

˜θi = 0, i
θ = 0

∈

NN

2

where N , T (T −1)
R2M consists of two vector variables (si)j and (si)j′ , where
(i, j) maps the jth component of the local variable si to
(si)j = θM(i,j). Note that the index mapping t =
the tth component of the global variable θ. Also, ˜θi can be considered as the global variable’s idea of what
the local variable si should be. Moreover, for each i, the function hi(si) is deﬁned as
k2, and
the objective term g(θ) is given as
tqt. Finally, IΩ(θ)(z) is the indicator function for the constraint
set θ (i.e., IΩ(θ)(z) = 0 for z

Ω (θ), and IΩ(θ)(z) =

(si)j −

Ω (θ)).

T
t=1 θ

(si)j′

M

k

′

The augmented Lagrangian (using scaled dual variables) for Problem 5 is

for z /
∈

∞

∈

P

N

Lρ(s, θ, z, u, v) =λ

hi(si) + g(θ) + IΩ(θ)(z) + (ρ/2)

i=1
X
+ (ρ/2)
k

z

θ + v

2
2,

k

−

1

A MATLABr implementation of our framework is available at

https://github.com/niloofaryouseﬁ/ECML2015

N

i=1
X

si −

k

˜θi + uik

2
2

(2)

(3)

(4)

(5)

(6)

4

where ui and v are the dual variables for the constraints si = ˜θi and z = θ respectively. Applying ADMM
on the Lagrangian function given in (6), the following steps are carried out in the kth iteration

sk+1
i = arg min
si {

λhi(si) + (ρ/2)
k

si −

˜θ

k
i + uk
i k

2
2}

N

θk+1 = arg min
θ {

g(θ) + (ρ/2)

sk+1
i −

k

˜θi + uk
i k

2
2 + (ρ/2)
k

zk

−

θ + vk

2
2}

k

i=1
X
IΩ(θ)(z) + (ρ/2)
k

z

−

θk+1 + vk

2
2}

k

zk+1 = arg min
z {
i + sk+1
uk+1
i = uk
vk+1 = vk + zk+1

i −

k+1
˜θ
i
θk+1

where, for each i
worth mentioning that the s-update is a proximal operator evaluation for

∈

(11)
NN , the s- and u-updates can be carried out independently and in parallel. It is also

−

.

k2 which can be simpliﬁed to

k

where

Sλ/ρ(˜θ
Sκ is the vector-valued soft thresholding (or shrinkage) operator and which is deﬁned as
k2)+a,
a
κ/
k

Sκ(a) , (1

Sκ(0) , 0.

sk+1
i =

NN

i ),

−

∈

∀

i

k
i + uk

Furthermore, as the objective term g is separable in θt, the θ-update can be decomposed into T independent
minimization problems, for which a closed from solution exists

(7)

(8)

(9)

(10)

(12)

(13)

(14)

θk+1

t =

1

−

T

1 

XM(i,j)=t

(cid:0)



(si)k+1

j + (ui)k
j

+

t + vk
zk
t

(cid:1)

(cid:0)

,

t

∀

∈

NT

−

(cid:1)

(1/ρ)qt


Algorithm 1 Algorithm for solving Problem 3.
Input: X 1, . . . , X T , Y 1, . . . , Y T , C, λ
Output: θ1, . . . , θT , α1, . . . , αT
1: Initialize: θ(0)
1 , . . . , θ(0)
2: Calculate: Base kernel matrices K m
3: while not converged do
4: α(r)

T , r = 1

′

arg max α∈Ω(α)
1
2 (α
← −
arg min θ∈Ω(θ) λ

1
T
t=1 α
2
−
t Yt(αt)(r),
t)(r)YtK m
t, m
P
P
∀
T −1
T
θt −
t=1
s>t k

te

′

←
t )(r)

5:

(qm
θ(r)
6:
←
7: end while
8: α∗ = α(r)
9: θ∗ = θ(r)

t using X t’s for the T tasks and the M kernels.

T
t=1

M
m=1(θm

t )(r−1)(α

tYtK m

t Ytαt)

′

P
θsk2 +

′

T
t=1 θ

tq(r)

t using Algorithm 2

P

P

P

In the third step of the ADMM, we project (θk+1

vk) onto the constraint set Ω (θ). Note that, this
set is separable in θ, so the projection step can also be performed independently and in parallel for each
variable zt, i.e.,

−

t + vk
The zt-update can also be seen as the problem of ﬁnding the intersection between two closed convex sets
, which can be handled using Dykstra’s
1,

t = ΠΩ(θ)(θk+1
zk+1

(15)

NT .

t ),

0,

∈

∀

t

t

t

Ω1 (θ) =
∈
alternating projections method [5, 11] as follows

and Ω2 (θ) =

θt (cid:23)

{k

∀

{

θtk1 ≤

NT }

NT }

∀

∈

t = ΠΩ1(θ)(θk+1
yk+1

t + vk

t = ΠΩ2(θ)(yk+1
zk+1
βk+1
t = βk

t + yk+1

t + βk
zk+1
t

,

t −

NT

t

∀

∈

θk+1
t + vk

βk

t ) =

1
t −
2
h
t + βk
t ) = PM (yk+1

t ) +

βk
t

+
i
1M ,

,

t

NT

∀

t

∈
NT

∀

∈

t −
1
M

(16)

(17)

(18)

5

′

where PM ,
projections onto Ω1 (θ) and Ω2 (θ) respectively with dual variables βt ∈
update the dual variables ui and v using the equations given in (10) and (11).

is the centering matrix. Furthermore, the yt- and zt updates are the Euclidean
RM×1, t = 1, . . . , T . Finally, we

IM −
(cid:18)

1M 1
M

(cid:19)

M

1 , . . . , q(r)

T , ρ
1 , . . . , θ(r)

Algorithm 2 Consensus ADMM algorithm to solve optimization Problem 4
Input: q(r)
Output: θ(r)
1: Initialize: ˆθ
2: while not converged do
NT do
3:
k
i + uk
i )

(0)
T , k = 0

1 , . . . , ˆθ

for i

(0)

4:

T

(si)k+1

j + (ui)k
j

+

t + vk
zk
t

(1/ρ)qt

(cid:1)

(cid:0)

−

(cid:1)

i

1

−
ˆθ

M(i,j)=t

NN , t
∈
∈
i ← Sλ/ρ(˜θ
sk+1
k+1
ˆθ
t ←
1
T
k+1
hP
βk
yk+1
1
(cid:0)
t + vk
t −
t
2
+
t + βk
i
h
PM (yk+1
t ) + 1
M 1M
βk
zk+1
t + yk+1
t
t −
k+1
˜θ
i + sk+1
uk
i
i −
k+1
ˆθ
t + zk+1
vk
t
t −

5:

6:

8:

7:

9:

t ←
zk+1
t ←
βk+1
t ←
uk+1
i ←
vk+1
10:
t ←
end for
11:
12: end while
13: θ(r)

ˆθ

(k+1)

←

3.1 Convergence Analysis and Stopping Criteria

Convergence of Algorithm 2 can be derived based on two mild assumptions similar to the standard conver-
gence theory of the ADMM method discussed in [6]; (i) the objective functions h(s) =
k2
and g(θ) =
tqt are closed, proper and convex, which implies that the subproblems arising in the s-
update (7) and θ-update (8) are solvable, and (ii) the augmented Lagrangian (6) for ρ = 0 has a saddle point.
Under these two assumptions, it can be shown that our ADMM-based algorithm satisﬁes the following

(si)j −

N
i=1 k

T
t=1 θ

(si)j′

P

P

′

Convergence of residuals : si

k

˜θ

k
i →

−

Convergence of dual variables: uk
dual optimal points.

i →

0,

i

∀
i
∀

∈

u∗
i ,

NN , and zk

∈
NN , and vk

−

→

θk

→
v∗ as k

0 as k

→ ∞

.
→ ∞
, where u∗ and v∗ are the

Convergence of the objective : h(sk) + g(zk)
converges to its optimal value as the algorithm proceeds.

p∗ as k

→

→ ∞

, which means the objective function (4)

Also, the algorithm is terminated, when the primal and dual residuals satisfy the following stopping

•

•

•

criteria

k

ek
p1k2 ≤
ek
d1k2 ≤

ǫpri
1 ,
ǫdual
1

,

k

ek
p2k2 ≤
ek
d2k2 ≤

ǫpri
2 ,
ǫdual
2

,

ek
p3k2 ≤
k
ek
d3k2 ≤

ǫpri
3
ǫdual
3

k
θk and ek
θk, ek
where the primal residuals of the kth iteration are given as ek
zk.
θk), ek
yk+1)are dual residuals at iteration
Similarly ek
k. Also, the tolerances ǫpri > 0, and ǫdual > 0 can be chosen appropriately using the method described in
Chapter 3 of [6].

k
p1 = sk
d3 = ρ(yk

d1 = ρ(θk+1

zk+1) and ek

d2 = ρ(zk

p3 = yk

p2 = zk

−
−

−

−

−

−

k

(19)

6

3.2 Computational Complexity

Algorithm 1 needs to compute and cache T M kernel matrices; however, they are computed only once in
(T M n2) time. Also, as long as the number of tasks T is not excessive, all the matrices can be computed
O
and stored on a single machine, since (i) the number M of kernels, is typically chosen small (e.g., we chose
M = 10), and (ii) the number n of training samples per task is not usually large; if it were large, MTL
would probably not be able to oﬀer any advantages over training each task independently. For each iteration
(n3) per task. Therefore, if
of Algorithm 1, T independent SVM problems are solved at a time cost of
(T n3 + KM T 2)
Algorithm 2 converges in K iterations, the runtime complexity of Algorithm 1 becomes
per iteration. Note, though, that K is not usually more than a few tens of iterations [6].

O

O

On the other hand, if the number of tasks T is large, the nature of our problem allows our algorithm
to be implemented in parallel. The α-update can be handled as T independent optimization problems,
which can be easily distributed to T subsystems. Each subsystem N needs to compute once and cache M
kernel matrices for each task. Then, for each iteration, one SVM problem is required to be solved by each
(n3) time. Moreover, our ADMM-based algorithm updating the θ parameters
subsystem, which takes
NN . Assuming that exchanging data and updates between
can also be implemented in parallel over i
(KM ) time. Therefore, taking advantage
subsystems consumes negligible time, the ADMM only requires
(n3 + KM ) per iteration.
of a distributed implementation, the complexity of Algorithm 1 is only

O

O

∈

O

4 Generalization Bound based on Rademacher Complexity

In this section, we provide a Rademacher complexity-based generalization bound for the Hypothesis Space
(HS) considered in Problem 1, which can be identiﬁed with the help of the following Proposition 2.

Proposition 1. (Proposition 12 in [20], part (a)) Let
ν > 0, there must exist a η > 0, such that the optimal solution of (20) is also optimal in (21)

and let f, g :

C ⊆ X

C 7→

R be two functions. For any

min
x∈C

f (x) + νg(x)

min
x∈C,g(x)≤η

f (x)

Using Proposition 1, one can show that Problem 1 is equivalent to the following problem

min
′

w∈Ω

(w)

C

T

n

l

wt, φt

xi
t

, yi
t

′

Ω

(w) ,

w = (w1,

{

t=1
X

(cid:0)

i=1
X
, wT ) : wt ∈ Ht,θ, θ

(cid:0)

(cid:1)

(cid:1)
∈

· · ·

′

Ω

(θ) ,

2

wtk

k

≤

Rt, t

NT }

∈

where

′

Ω

(θ) , Ω (θ)

θ = (θt,

, θT ) :

· · ·

∩ (

θt −
k

θsk2 ≤

γ

)

T −1

T

t=1
X

s>t
X

The goal here is to choose the w and θ from their relevant feasible sets, such that the objective function

of (22) is minimized. Therefore, the relevant hypothesis space for Problem 22 becomes

,

F

x

[

w1, φ1i
h

7→

, . . . ,

wT , φT i
]
h

:

twt ∈ Ht,θ,
∀

wtk

k

2

≤

Rt, θ

∈

′

n

′

Ω

(θ)

o

Note that ﬁnding the Empirical Rademacher Complexity (ERC) of
T −1
t=1

T
s>t k

θt −

θsk2 ≤

smooth nature of the constraint
deﬁned in (24); notice that

F

F ⊆ H

.
P

P

is complicated due to the non-

γ. Instead, we will ﬁnd the ERC of the HS

2Note that Proposition 1 here utilizes the ﬁrst part of Proposition 12 in [20] and does not require the strong

duality assumption, which is necessary for the second part of Proposition 12 in [20].

7

(20)

(21)

(22)

(23)

H

(24)

(25)

(26)

(27)

(28)

,

H

x

[

w1, φ1i
h

7→

, . . . ,

wT , φT i
]
h

:

twt ∈ Ht,θ,
∀

wtk

k

2

≤

Rt, θ

∈

′

′′

Ω

(θ)

o

where

n

′′

Ω

(θ) , Ω (θ)

θ = (θt,

, θT ) :

· · ·

∩ (

θt −

k

θsk

2
2 ≤

γ2

)

T −1

T

t=1
X

s>t
X

Using the ﬁrst part of Theorem (12) in [4], it can be shown that the ERC of

of function class
generalization bound for

F

. Thus, the bound derived for

is also valid for

H

F

upper bounds the ERC
. The following theorem provides the

H

.

H

Theorem 1. Let
Then for all f

deﬁned in (24) be the multi-task HS for a class of functions f = (f1, . . . , fT ) :

H
, for δ > 0 and for ﬁxed ρ > 0, with probability at least 1
∈ H

−

δ it holds that

RT .

X 7→

where

R(f )

ˆRρ(f ) +

ˆRS(

) + 3

2
ρ

H

≤

log 1
δ
2T n

s

ˆRS (

)

H

≤

ˆRub (

) =

H

s

√3γRM
nT

where ˆRS(

H

), the ERC of

, is given as

H

ˆRS(

σi
tft(xi
t)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
the ρ-empirical large margin error ˆRρ(f ), for the training sample S =
(cid:12)

sup
f =(f1,...,fT )∈F

t=1
X

i=1
X

) =

Eσ

H

(

(cid:8)

xi
t

(cid:9)
t, yi
xi
t

t∈NT ,i∈Nn )

1
nT

T

n

n,T
i,t=1 is deﬁned as

T

n

ˆRρ(f ) =

1
nT

min

1, [1

tft(xi
yi

−

t=1
X

i=1
X

(cid:0)

(cid:1)(cid:9)

(cid:8)(cid:0)
t)/ρ]+

(cid:1)

Also, R(f ) = Pr[yf (x) < 0] is the expected risk w.r.t. 0-1 loss, n is the number of training samples for each
task, T is the number of tasks to be trained, and M is the number of kernel functions utilized for MKL.

H

The proof of this theorem is omitted due to space constraints. Based on Theorem 1, the second term in
(26), the upper bound for ERC of
, decreases as the number of tasks increases. Therefore, it is reasonable
to expect that the generalization performance to improve, when the number T of tasks or the number n
of training samples increase. Also, due to the formulation’s group lasso (L1/L2-norm) regularizer on the
It is worth mentioning,
pair-wise MKL weight diﬀerences, the ERC in (27) depends on M as
√log M as in [9], if one considers instead a Lp/Lq-norm regularizer,
that, while this could be improved to
(26) allows one to construct data-dependent
we won’t pursue this avenue here. Let us ﬁnally note, that
conﬁdence intervals for the true, pooled (averaged over tasks) misclassiﬁcation rate of the MTL problem
under consideration.

√M .

O

O

5 Experiments

In this section, we demonstrate the merit of the proposed model via a series of comparative experiments. For
reference, we consider two baseline methods referred to as STL and MTL, which present the two extreme
cases discussed in Sect. 2. We also compare our method with ﬁve state-of-the-art methods which, like ours,
fall under the CMTL family of approaches. These methods are brieﬂy described below.

8

•

•

•

•

•

•

•

STL: single-task learning approach used as a baseline, according to which each task is individually
trained via a traditional single-task MKL strategy.

MTL: a typical MTL approach, for which all tasks share a common feature space. An SVM-based
formulation with multiple kernel functions was utilized and the common MKL parameters for all tasks
were learned during training.

CMTL [17]: in this work, the tasks are grouped into disjoint clusters, such that the model parameters
of the tasks belonging to the same group are close to each other.

Whom [19]: clusters the task, into disjoint groups and assumes that tasks of the same group can
jointly learn a shared feature representation.

FlexClus [30]: a ﬂexible clustering structure of tasks is assumed, which can vary from feature to
feature.

CoClus [26]: a co-clustering structure is assumed aiming to capture both the feature and task rela-
tionship between tasks.

MeTaG [16]: a multi-level grouping structure is constructed by decomposing the matrix of tasks’
parameters into a sum of components, each of which corresponds to one level and is regularized with
a L2-norm on the pairwise diﬀerence between parameters of all the tasks.

5.1 Experimental Settings

For all experiments, all kernel-based methods (including STL, MTL and our method) utilized 1 Linear,
1 Polynomial with degree 2, and 8 Gaussian kernels with spread parameters
for MKL. All
k(x, x)k(y, y). Moreover, for CMTL, Whom and
kernel functions were normalized as k(x, y)
CoClus methods, which require the number of task clusters to be pre-speciﬁed, cross-validation over the
set
was used to select the optimal number of clusters. Also, the regularization parameters of
all methods were chosen via cross-validation over the set

2−10, . . . , 210

20, . . . , 27

1, . . . , T /2

k(x, y)/

←

p

(cid:8)

(cid:9)

}

{

.

5.2 Experimental Results

(cid:8)

(cid:9)

We assess the performance of our proposed method compared to the other methods on 7 widely-used data
sets including 3 real-world data sets: Wall-Following Robot Navigation (Robot ), Statlog Vehicle Silhouettes
(Vehicle) and Statlog Image Segmentation (Image) from the UCI repository [14], 2 handwritten digit data
sets, namely MNIST Handwritten Digit (MNIST ) and Pen-Based Recognition of Handwritten Digits (Pen),
as well as Letter and Landmine.

The data sets from the UCI repository correspond to three multi-class problems. In the Robot data set,
each sample is labeled as: “Move-Forward, “SlightRight-Turn”, “Sharp-Right-Turn” and “Slight-Left-Turn”.
These classes are designed to navigate a robot through a room following the wall in a clockwise direction.
The Vehicle data set describes four diﬀerent types of vehicles as “4 Opel”, “SAAB”, “Bus” and “Van”. On
the other hand, the instances of the Image data set were drawn randomly from a database of 7 outdoor
images which are labeled as “Sky”, “Foliage”, “Cement”, “Window”, “Path” and “Grass”.

Also, two multi-class handwritten digit data sets, namely MNIST and Pen, consist of samples of hand-
written digits from 0 to 9. Each example is labeled as one of ten classes. A one-versus-one strategy was
adopted to cast all multi-class learning problems into MTL problems, and the average classiﬁcation accuracy
across tasks was calculated for each data set. Moreover, an equal number of samples from each class was
chosen for training for all ﬁve multi-class problems.

We also compare our method on two widely-used multi-task data sets, namely the Letter and Landmine
data sets. The former one is a collection of handwritten words collected by Rob Kassel of MIT’s spoken
‘G’, ‘I’
Language System Group, and involves eight tasks:
vs. ‘J’, ‘A’ vs. ‘O’, ‘F’ vs. ‘T’ and ‘H’ vs.
‘N’. Each letter is represented by a 8 by 16 pixel image, which
forms a 128 dimensional feature vector per sample. We randomly chose 200 samples for each letter. An
exception is letter J, for which only 189 samples were available. The Landmine data set consists of 29 binary

‘Y’, ‘M’ vs.

‘N’, ‘A’ vs.

‘E’, ‘G’ vs.

‘C’ vs.

9

classiﬁcation tasks collected from various landmine ﬁelds. The objective is to recognize whether there is
a landmine or not based on a region’s characteristics, which are described by four moment-based features,
three correlation-based features, one energy ratio feature, and one spatial variance feature.

In all our experiments, for all methods, we considered training set sizes of 10%, 20% and 50% of the
original data set to investigate the inﬂuence of the data set size on generalization performance. An exception
was the Landmine data set, for which we used 20% and 50% of the data set for training purposes due to its
small size. The rest of data were split into equal sizes for validation and testing.

Table 1: Experimental comparison between our method and seven benchmark methods

STL(7) MTL(5.42) CMTL(6.33) Whom(3.25) FlexClus(4.33) Coclus(4) MetaG(5) Our Method(1.67)

STL(6) MTL(4.43) CMTL(6.14) Whom(3.29) FlexClus(5.57) Coclus(4.57) MetaG(4.71) Our Method(1.14)

10%

Robot
Vehicle
Image
Pen
MNIST
Letter

20%

Robot
Vehicle
Image
Pen
MNIST
Landmine
Letter

84.51(7)
79.73(8)
97.08(7)
98.16(7)
94.09(7)
84.12(6)

87.67(7)
85.88(4)
97.41(6)
98.57(7)
96.13(6)
58.76(8)
88.75(4)

Robot
Vehicle
Image
Pen
MNIST
Landmine
Letter

91.26(5.5)
88.33(3)
98.40(6)
98.77(7)
97.20(6)
63.76(8)
91.18(4)

84.82(6)
80.38(6)
97.43(3)
98.28(5.5)
94.87(4)
83.12(8)

88.23(6)
86.16(3)
98.02(3)
99.01(6)
96.71(4)
61.89(7)
89.98(2)

91.49(3)
88.71(2)
98.43(5)
99.23(5)
97.37(4)
64.98(6)
91.62(2)

84.15(8)
80.23(7)
97.09(6)
95.78(8)
94.49(6)
85.62(3)

85.08(8)
82.29(8)
97.32(7)
96.06(8)
96.56(5)
65.28(2)
88.24(5)

86.26(8)
83.91(8)
97.56(8)
96.17(8)
97.31(5)
66.76(2)
90.97(5)

88.90(1)
83.14(4)
97.27(4)
98.28(5.5)
95.56(3)
86.82(2)

90.76(1)
85.67(6)
98.46(2)
99.14(3)
96.76(3)
62.53(5)
88.88(3)

91.70(2)
87.3(5)
98.58(2)
99.32(4)
97.78(3)
65.57(4)
91.25(3)

88.34(4)
82.45(5)
98.05(2)
98.67(3)
94.59(5)
83.72(7)

90.15(3)
85.29(7)
97.44(5)
99.13(4)
95.04(7)
62.46(6)
83.79(7)

91.26(5.5)
86.72(7)
98.04(7)
99.33(3)
96.60(7)
64.87(7)
86.47(7)

87.83(5)
86.79(1)
97.24(5)
99.26(1)
93.09(8)
85.46(4)

88.43(5)
87.15(2)
97.50(4)
99.30(2)
94.09(8)
63.52(3)
82.26(8)

89.04(7)
87.55(4)
98.52(3)
99.34(2)
95.87(8)
65.15(5)
86.27(8)

88.77(2)
83.53(3)
97.05(8)
98.57(4)
96.13(2)
85.41(5)

89.12(4)
85.78(5)
97.29(8)
99.02(4)
96.84(2)
62.59(4)
87.99(6)

91.27(4)
86.81(6)
98.49(4)
99.21(6)
98.46(2)
66.24(3)
90.66(6)

88.67(3)
84.51(2)
98.19(1)
99.12(2)
96.70(1)
87.41(1)

90.34(2)
87.76(1)
98.54(1)
99.63(1)
97.86(1)
65.82(1)
90.72(1)

92.41(1)
89.83(1)
99.07(1)
99.77(1)
98.64(1)
67.15(1)
92.49(1)

50%

STL(5.64) MTL(3.85) CMTL(6.29) Whom(3.29) FlexClus(6.21) Coclus(5.29) MetaG(4.42) Our Method(1)

In Table 1, we report the average classiﬁcation accuracy over 20 runs of randomly sampled training sets
for each experiment. Note that we utilized the method proposed in [10] for our statistical analysis. More
speciﬁcally, Friedman’s and Holm’s post-hoc tests at signiﬁcance level α = 0.05 were employed to compare
our proposed method with the other methods.

As shown in Table 1, for each data set, Friedman’s test ranks the best performing model as ﬁrst, the
second best as second and so on. The superscript next to each value in Table 1 indicates the rank of the
corresponding model on the relevant data set, while the superscript next to each model reﬂects its average
rank over all data sets for the corresponding training set size. Note that methods depicted in boldface
are deemed statistically similar to our model, since their corresponding p-values are not smaller than the
adjusted α values obtained by Holm’s post-hoc test. Overall, it can be observed that our method dominates
three, six and ﬁve out of seven methods, when trained with 10%, 20% and 50% training set sizes respectively.
Also, in Figure 1, we provide better insight of how the grouping of task feature spaces might be determined
in our framework. For the purpose of visualization, we applied two Gaussian kernel functions with spread
parameters 2 and 28 and used the Letter multi-task data set.

In this ﬁgure, the x and y axes represent the weights of these two kernel functions for each task. From
Figure 1 (a), when a small training size (10%) is chosen, it can be seen that our framework yields a cluster of
3 tasks, namely
that share a common feature space to beneﬁt from
each other’s data. However, as the number n of training samples per task increases, every task is allowed to
employ its own feature space to guarantee good performance. This is shown in Figure 1 (b), which displays

“A” vs “G”, “A” vs “O”, “G” vs “Y”

{

}

10

Table 2: Comparison of our method against the other methods with the Holm test

10%

STL

MTL

CMTL Whom FlexClus Coclus MeTaG

Test statistic
p value
Adjusted α

3.93
0.0005
0.0071

2.13
0.0138
0.0083

3.49
0.0022
0.0100

1.25
0.2869
0.0125

2.40
0.0777
0.01667

2.62
0.1214
0.0250

2.29
0.1214
0.0500

20%

STL

MTL

CMTL Whom FlexClus

Coclus MeTaG

Test statistic
p value
Adjusted α

3.71
0.00021
0.0083

2.51
0.0121
0.0250

3.82
0.0001
0.0071

1.64
0.1017
0.0500

3.38
0.0007
0.0100

2.62
0.0088
0.01667

2.73
0.0064
0.0125

50%

STL MTL

CMTL Whom FlexClus

Coclus MeTaG

Test statistic
p value
Adjusted α

3.55
0.0004
0.0100

2.18
0.0291
0.0250

4.04
0.0001
0.0071

1.75
0.0809
0.0500

3.98
0.0001
0.0083

3.27
0.0011
0.0125

2.61
0.0089
0.01667

the results obtained for a 50% training set size. Note, that the displayed MKL weights lie on the θ1 + θ2 = 1
line due to the framework’s L1 MKL weight constraint.

2

θ

0.7

A vs G, A vs O, G vs Y

2

θ

0.7

1

F vs T

H vs N M vs N

0.9

I vs J

0.8

0.6

0.5

0.4

0

C vs E

0.3

θ1

(a) Traning set size 10%

1

0.9

0.8

0.6

0.5

0.4

0

F vs T

I vs J

M vs N

H vs N

A vs G

A vs O

G vs Y

C vs E

θ1
(b) Traning set size 50%

0.1

0.2

0.4

0.5

0.6

0.1

0.2

0.3

0.4

0.5

0.6

Figure 1: Feature space parameters for Letter multi-task data set

6 Conclusions

In this work, we proposed a novel MT-MKL framework for SVM-based binary classiﬁcation, where a ﬂexible
group structure is determined between each pair of tasks. In this framework, tasks are allowed to have a
common, similar, or distinct feature spaces. Recently, some MTL frameworks have been proposed, which
also consider clustering strategies to capture task relatedness. However, our method is capable of modeling
a more general type of task relationship, where tasks may be implicitly grouped according to a notion of
feature space similarity. Also, our proposed optimization algorithm allows for a distributed implementation,
which can be signiﬁcantly advantageous for MTL settings involving large number of tasks. The performance

11

advantages reported on 7 multi-task SVM-based classiﬁcation problems largely seem to justify our arguments
in favor of our framework.

Acknowledgments

N. Youseﬁ acknowledges support from National Science Foundation (NSF) grants No. 0806931 and No.
1161228. Moreover, M. Georgiopoulos acknowledges partial support from NSF grants No. 0806931, No.
0963146, No. 1200566, No. 1161228, and No. 1356233. Finally, G. C. Anagnostopoulos acknowledges
partial support from NSF grant No. 1263011. Any opinions, ﬁndings, and conclusions or recommendations
expressed in this material are those of the authors and do not necessarily reﬂect the views of the NSF.

References

[1] Andreas Argyriou, St´ephan Cl´emen¸con, and Ruocong Zhang. Learning the graph of relations among
multiple tasks. ICML 2014 workshop on New Learning Frameworks and Models for Big Data, 2013.

[2] Andreas Argyriou, Theodoros Evgeniou, and Massimiliano Pontil. Convex multi-task feature learning.

Machine Learning, 73(3):243–272, 2008.

[3] Bart Bakker and Tom Heskes. Task clustering and gating for bayesian multitask learning. The Journal

of Machine Learning Research, 4:83–99, 2003.

[4] Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and

structural results. The Journal of Machine Learning Research, 3:463–482, 2003.

[5] HH Bauschke and Jonathan M Borwein. Dykstra’s alternating projection algorithm for two sets. Journal

of Approximation Theory, 79(3):418–443, 1994.

[6] Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, and Jonathan Eckstein. Distributed optimization
and statistical learning via the alternating direction method of multipliers. Foundations and Trends in
Machine Learning, 3(1):1–122, January 2011.

[7] Rich Caruana. Multitask learning. Machine learning, 28(1):41–75, 1997.

[8] Chih-Chung Chang and Chih-Jen Lin. LIBSVM: A library for support vector machines. ACM
Software available at

Transactions on Intelligent Systems and Technology, 2:27:1–27:27, 2011.
http://www.csie.ntu.edu.tw/~cjlin/libsvm.

[9] Corinna Cortes, Mehryar Mohri, and Afshin Rostamizadeh. Generalization bounds for learning kernels.
In Proceedings of the 27th International Conference on Machine Learning (ICML-10), pages 247–254,
2010.

[10] Janez Demˇsar. Statistical comparisons of classiﬁers over multiple data sets. The Journal of Machine

Learning Research, 7:1–30, 2006.

[11] Richard L Dykstra. An algorithm for restricted least squares regression. Journal of the American

Statistical Association, 78(384):837–842, 1983.

[12] A Evgeniou and Massimiliano Pontil. Multi-task feature learning. Advances in neural information

processing systems, 19:41, 2007.

[13] Theodoros Evgeniou, Charles A Micchelli, and Massimiliano Pontil. Learning multiple tasks with kernel

methods. In Journal of Machine Learning Research, pages 615–637, 2005.

[14] A. Frank and A. Asuncion.

UCI machine learning repository,

2010.

Available from:

http://archive.ics.uci.edu/ml.

12

[15] Quanquan Gu, Zhenhui Li, and Jiawei Han. Joint feature selection and subspace learning. In IJCAI
Proceedings-International Joint Conference on Artiﬁcial Intelligence, volume 22, page 1294, 2011.

[16] Lei Han and Yu Zhang. Learning multi-level task groups in multi-task learning. Proceedings of the 29th

AAAI Conference on Artiﬁcial Intelligence (AAAI), 2015.

[17] Laurent Jacob, Jean-philippe Vert, and Francis R Bach. Clustered multi-task learning: A convex

formulation. In Advances in neural information processing systems, pages 745–752, 2009.

[18] Ali Jalali, Sujay Sanghavi, Chao Ruan, and Pradeep K Ravikumar. A dirty model for multi-task

learning. In Advances in Neural Information Processing Systems, pages 964–972, 2010.

[19] Zhuoliang Kang, Kristen Grauman, and Fei Sha. Learning with whom to share in multi-task feature
learning. In Proceedings of the 28th International Conference on Machine Learning (ICML-11), pages
521–528, 2011.

[20] Marius Kloft, Ulf Brefeld, S¨oren Sonnenburg, and Alexander Zien. Lp-norm multiple kernel learning.

The Journal of Machine Learning Research, 12:953–997, 2011.

[21] Gert RG Lanckriet, Nello Cristianini, Peter Bartlett, Laurent El Ghaoui, and Michael I Jordan. Learning
the kernel matrix with semideﬁnite programming. The Journal of Machine Learning Research, 5:27–72,
2004.

[22] Cong Li, Michael Georgiopoulos, and Georgios C Anagnostopoulos. Conic multi-task classiﬁcation. In

Machine Learning and Knowledge Discovery in Databases, pages 193–208. Springer, 2014.

[23] Cong Li, Michael Georgiopoulos, and Georgios C. Anagnostopoulos. Pareto-path multitask multiple
kernel learning. Neural Networks and Learning Systems, IEEE Transactions on, 26(1):51–61, Jan 2015.
doi:10.1109/TNNLS.2014.2309939.

[24] Andreas Maurer. Bounds for linear multi-task learning. The Journal of Machine Learning Research,

7:117–139, 2006.

pages 1255–1260, 2009.

[25] Lei Tang, Jianhui Chen, and Jieping Ye. On multiple kernel learning with multiple labels. In IJCAI,

[26] Linli Xu, Aiqing Huang, Jianhui Chen, and Enhong Chen. Exploiting task-feature co-clusters in multi-
task learning. In Proceedings of the Twenty-Ninth AAAI Conference on Artiﬁcial Intelligence (AAAI-
15), 2015.

[27] Ya Xue, Xuejun Liao, Lawrence Carin, and Balaji Krishnapuram. Multi-task learning for classiﬁcation

with dirichlet process priors. The Journal of Machine Learning Research, 8:35–63, 2007.

[28] Yu Zhang and Dit-Yan Yeung. A convex formulation for learning task relationships in multi-task

learning. arXiv preprint arXiv:1203.3536, 2012.

[29] Yu Zhang and Dit-Yan Yeung. A regularization approach to learning task relationships in multitask

learning. ACM Transactions on Knowledge Discovery from Data (TKDD), 8(3):12, 2014.

[30] Wenliang Zhong and James Kwok. Convex multitask learning with ﬂexible task clusters. arXiv preprint

arXiv:1206.4601, 2012.

[31] Jiayu Zhou, Jianhui Chen, and Jieping Ye. Clustered multi-task learning via alternating structure

optimization. In Advances in neural information processing systems, pages 702–710, 2011.

13

Supplementary Materials

A useful lemmas in deriving the generalization bound of Theorem 1 is provided next.

∈
denote the Hadamard (component-wise) matrix product. Then, it holds that

∈

RN ×N and let σ

RN be a vector of independent Rademacher random variables.

Lemma 1. Let A, B
Let

◦

Eσ

(σ′Aσ) (σ′Bσ)
}
{

= trace

A
}

{

trace

B

{

}

+ 2 (trace

AB

trace

{

} −

A
{

B

)
}

◦

Proof. Let [
expectation in question can be written as

·

] denote the Iverson bracket, such that [predicate] = 1, if predicate is true and 0, if false. The

Eσ

(σ′Aσ) (σ′Bσ)
}

{

=

ai,j bk,l E

σiσjσkσl}

{

Xi,j,k,l
1, . . . , N
{

where the indices of the last sum run over the set

Rademacher random variables, it is not diﬃcult to verify the fact that E
four cases:
= k
cases, E

= k
= 0. Therefore, it holds that

i = j, k = l, i
{

i = k, j = l, i

i = l, k = j, i

= l

,
}

,
}

{

. Since the components of σ are independent
}
= 1 only in the following
; in all other
}

σiσj σkσl}
{
i = j, j = k, k = l
and
{

}

{
σiσj σkσl}
{

E

σiσjσkσl}

{

= [i = k][j = l][i

= l] + [i = j][k = l][i

= k]

+ [i = l][k = j][i

= k] + [i = j][j = k][k = l]

Substituting (31) into (30), after some algebraic operations, yields the desired result.

Proof of Theorem 1

By utilizing Theorems 16, 17 in [24], it can be proved that given a multi-task HS
functions f = (f1, . . . , fT ) :
δ the following holds
1

, deﬁnes as a class of
, for δ > 0 and for ﬁxed ρ > 0, with probability at least

RT , for all f

X 7→

∈ F

F

−

where the ERC ˆRS(

) is given as

F

R(f )

ˆRρ(f ) +

ˆRS(

) + 3

2
ρ

F

≤

log 2
δ
2T n

s

ˆRS(

) =

F

1
nT

Eσ

sup
f =(f1,...,fT )∈F

(

T

n

t=1
X

i=1
X

tft(xi
σi
t)

)

and the ρ-empirical large margin error ˆRρ(f ) for the training sample S =

t, yi
xi
t

n,T
i,t=1 is deﬁned as

ˆRρ(f ) =

1
nT

T

n

t=1
X

i=1
X

min

1, [1

tft(xi
yi

−

(cid:1)(cid:9)

(cid:8)(cid:0)
t)/ρ]+

(cid:1)

(cid:0)
Also, from eqs. (1) and (2) in [9], we know that wt =

′

is equivalent to α
deﬁned as ft(xt) =

tK tαt ≤
Rt. Then we can observe that
P
∀
wt, φt(xt)
Ht,θ is equivalent to ft(xt) =
i
h

n

j=1 αj
x

t ) along with constraint

t φt(xj
S and t
∈
t Kt(xj
t , xt), where Kt =

Rt,
1, . . . , T , the decision function
t Km.

M
m=1 θm

wtk

∈
n
j=1 αj

≤

k

2

P

P

(29)

(30)

(31)

(32)

(33)

14

So, based on the deﬁnition of empirical Rademacher complexity given in (33), we will have

ˆRS(

) =

H

sup
(θ),αt∈Ω(α)

′′

θt∈Ω

T

n,n

tαj
σi

t Kt(xi

t, xj
t )

1
nT

1
nT

Eσ 


Eσ

=

"

θt∈Ω

′′

sup
(θ),αt∈Ω(α)

i,j=1
X

t=1
X
T

′

σ

tKtαt

#

t=1
X





where σt = [σ1
M
m=1 θm
as

, αt = [α1
t , . . . , σn
t ]
t, xj
t ), Ω(α) =

t Km(xi

′

′

t , . . . , αn
, Kt ∈
t ]
tKtαt ≤
α
αt |

{

′

t
∀
It can be observed that the maximization problem with respect to αt can be handled as T independent
P
optimization problem, as Ω(α) is separable in terms of αt. Also, it can be shown that using Cauchy-Schwartz
inequality, the optimal value of αt is achieved when K 1/2

t αt is colinear with K 1/2

t σt, which gives

and Ω

}

Rn×n is a kernel matrix whose (i, j)-th elements is deﬁned
Rt,

(θ) is deﬁned as (25).

′′

sup
αt∈Ω(α)

′

σ

tKtαt =

′

σ

tKtσtRt

q

Assuming Rt ≤

∀

R

t, (34) now becomes

ˆRS(

) =

H

√R
nT

Eσ

sup
′′

(

θt∈Ω

(θ)

T

′

σ

tK tσt

)

=

√R
nT

Eσ 


sup
′′

θt∈Ω

(θ)

=

√R
nT

Eσ

sup
′′

θt∈Ω

(θ)


(

′

t=1 q
X
T

M

t=1
X
T

v
u
u
t
θ

m=1
X

′

tut

t=1 q
X
t = σ

′

)

θm
t (σ

′

tK m

t σt)






′

where θt = [θ1

t , . . . , θM
t
bounded. In particular, assuming ωt =
p = 2, r = 1 and y = 1n, we will have

, ut = [u1

t , . . . , uM
t ]
θ

]

′

q

, and um

tK m
tut, and using the H¨older’s inequality

t σt . Note that (35) can also be upper-
xy
kq, for

kr ≤ k

x
kpk

y

k

′

θ

tut =

T

t=1 q
X

T

wt

!

 

t=1
X

=

ω

k

k1 ≤

√T

ω

k2 = √T

k

T

 

t=1
X

(wt)2

!

1/2

= √T

T

′

θ

tut

v
u
u
t

t=1
X

Therefore, we can upper bound the Rademacher complexity (35) as follows

ˆRS(

) =

H

√R
nT

Eσ

sup
′′

(

θt∈Ω

(θ)

T

′

θ

tut

)

≤

=

1
n r

R
T

1
n r

R
T

Eσ 


sup
′′

θt∈Ω

Eσ


(

sup
′′

θt∈Ω

t=1 q
X

T

(θ) v
u
u
t

t=1
X

′

θ

tut


trace


Θ′ U
{

})

arg max

trace

= arg max

trace

Θ′ U
}
{

′

Θ

U

Θ

n

n

oo

Θ

q

(θ) q

∈

15

where Θ = [θ1, . . . , θT ]
proved that

∈

RM×T and U = [u1, . . . , uT ]

RM×T . Also, by contradiction, it can be easily

(34)

(35)

(36)

Using the Lagrangian multiplier method, the optimization w.r.t. Θ yields the optimal value for Θ as

Θ∗ =

1
2αT

UPT

RT ×T is a centering matrix as we deﬁned in Sect. 3. Moreover, α = (1/2γ)

a

(1/T )b,

where PT ∈
a = trace

′
UU

, and b = trace

U1T 1T

′

′
U

.

substituting the optimal value of Θ in (36), ﬁnally yields

o

n

o

n

−

p

By applying Jensen’s inequality twice, we obtain

ˆRS(

)

H

≤

√γR
nT 3/4 Eσ

a
np

−

1/2

(1/T )b

o

ˆRS(

)

H

≤

√γR
nT 3/4

Eσ(a

(1/T )b)

−

np

1/2

o

From the deﬁnition, we can see that both a and b depend on variable σ. If we deﬁne um = [σ

as the row vector of matrix U, and d ,
Lemma 1, it can be shown that

trace

M

m=1 K m

1

. . . trace

M

m=1 Km

T

h

nP

o

nP

oi

′

′

1Km
1 σ1, . . . , σ
then with the help of

′

T K m

T σT ]

′

Eσ(a) = d

d + 2

T

M

[trace

t Km

K m
{

t } −

trace

Km

t ◦

K m
]
t }

{

Eσ(b) = d

1T 1T

d + 2

[trace

Km

t Km

t } −

trace

Km

t ◦

Km
t }

]

{

{

′

′

t=1
X
′

m=1
X
T

M

t=1
X

m=1
X

Considering the fact that trace
Km

Kn
x, t, m, it can be shown that

Km

t ◦

{

1

t (x, x)

t } ≥

≤

∀

0, and trace

Km

t K n

{

t } ≥

∀

0

t, m, n, and assuming that

1
T

−

Eσ(a)

Eσ(b)

T M 2n2

1 +

≤

(cid:26)

2
M

+

2
T M n

≤

(cid:27)

3T M 2n2

Combining (37), and (39) and after some algebra operations, we conclude that, if

ˆRub (

) ,

H

s

√3γRM
nT

then ˆR(

)

ˆRub (

H

≤

H

). This last fact in conjunction with (32) conclude the theorem’s statement.

(37)

(38)

(39)

(40)

16

5
1
0
2
 
g
u
A
 
3
1
 
 
]

G
L
.
s
c
[
 
 
1
v
9
2
3
3
0
.
8
0
5
1
:
v
i
X
r
a

Multi-Task Learning with Group-Speciﬁc Feature
Space Sharing

Niloofar Youseﬁ, Michael Georgiopoulos and Georgios C. Anagnostopoulos

NY, MG: EE & CS Dept., University of Central Florida; GCA: ECE Dept., Florida Institute of Technology

niloofaryouseﬁ@knights.ucf.edu, michaelg@ucf.edu and georgio@ﬁt.edu

Abstract

When faced with learning a set of inter-related tasks from a limited amount of usable data, learning
each task independently may lead to poor generalization performance. Multi-Task Learning (MTL)
exploits the latent relations between tasks and overcomes data scarcity limitations by co-learning all these
tasks simultaneously to oﬀer improved performance. We propose a novel Multi-Task Multiple Kernel
Learning framework based on Support Vector Machines for binary classiﬁcation tasks. By considering
pair-wise task aﬃnity in terms of similarity between a pair’s respective feature spaces, the new framework,
compared to other similar MTL approaches, oﬀers a high degree of ﬂexibility in determining how similar
feature spaces should be, as well as which pairs of tasks should share a common feature space in order to
beneﬁt overall performance. The associated optimization problem is solved via a block coordinate descent,
which employs a consensus-form Alternating Direction Method of Multipliers algorithm to optimize the
Multiple Kernel Learning weights and, hence, to determine task aﬃnities. Empirical evaluation on seven
data sets exhibits a statistically signiﬁcant improvement of our framework’s results compared to the ones
of several other Clustered Multi-Task Learning methods.

Keywords: Multi-task Learning, Kernel Methods, Generalization Bound, Support Vector Machines

1

Introduction

Multi-Task Learning (MTL) is a machine learning paradigm, where several related task are learnt simul-
taneously with the hope that, by sharing information among tasks, the generalization performance of each
task will be improved. The underlying assumption behind this paradigm is that the tasks are related to
each other. Thus, it is crucial how to capture task relatedness and incorporate it into an MTL framework.
Although, many diﬀerent MTL methods [7, 12, 18, 15, 28, 1] have been proposed, which diﬀer in how the
relatedness across multiple tasks is modeled, they all utilize the parameter or structure sharing strategy to
capture the task relatedness.

However, the previous methods are restricted in the sense that they assume all tasks are similarly related
to each other and can equally contribute to the joint learning process. This assumption can be violated in
many practical applications as “outlier” tasks often exist. In this case, the eﬀect of “negative transfer”, i.e.,
sharing information between irrelevant tasks, can lead to a degraded generalization performance.

To address this issue, several methods, along diﬀerent directions, have been proposed to discover the
inherent relationship among tasks. For example, some methods [3, 27, 28, 29], use a regularized probabilistic
setting, where sharing among tasks is done based on a common prior. These approaches are usually compu-
tationally expensive. Another family of approaches, known as the Clustered Multi-Task Learning (CMTL),
assumes that tasks can be clustered into groups such that the tasks within each group are close to each other
according to a notion of similarity. Based on the current literature, clustering strategies can be broadly
classiﬁed into two categories: task-level CMTL and feature-level CMTL.

1

The ﬁrst one, task-level CMTL, assumes that the model parameters used by all tasks within a group are
close to each other. For example, in [2, 13, 17], the weight vectors of the tasks belonging to the same group
are assumed to be similar to each other. However, the major limitations for these methods are: (i) that such
an assumption might be too risky, as similarity among models does not imply that meaningful sharing of
information can occur between tasks, and (ii) for these methods, the group structure (number of groups or
basis tasks) is required to be known a priori.

The other strategy for task clustering, referred to as feature-level CMTL, is based on the assumption
that task relatedness can be modeled as learning shared features among the tasks within each group. For
example, in [19] the tasks are clustered into diﬀerent groups and it is assumed that tasks within the same
group can jointly learn a shared feature representation. The resulting formulation leads to a non-convex
objective, which is optimized using an alternating optimization algorithm converging to local optima, and
suﬀers potentially from slow convergence. Another similar approach has been proposed in [26], which assumes
that tasks should be related in terms of feature subsets. This study also leads to a non-convex co-clustering
structure that captures task-feature relationship. These methods are restricted in the sense that they assume
that tasks from diﬀerent groups have nothing in common with each other. However, this assumption is not
always realistic, as tasks in disjoint groups might still be inter-related, albeit weekly. Hence, assigning tasks
into diﬀerent groups may not take full advantage of MTL. Another feature-level clustering model has been
proposed in [30], in which the cluster structure can vary from feature to feature. While, this model is more
ﬂexible compared to other CMTL methods, it is, however, more complicated and also less general compared
to our framework, as it tries to ﬁnd a shared feature representation for tasks by decomposing each task
parameter into two parts: one to capture the shared structure between tasks and another to capture the
variations speciﬁc to each task. This model is further extended in [16], where a multi-level structure has
been introduced to learn task groups in the context of MTL. Interestingly, it has been shown that there
is an equivalent relationship between CMTL and alternating structure optimization [31], wherein the basic
idea is to identify a shared low-dimensional predictive structure for all tasks.

In this paper, we develop a new MTL model capable of modeling a more general type of task relationship,
where the tasks are implicitly grouped according to a notion of feature similarity. In our framework, the tasks
are not forced to have a common feature space; instead, the data automatically suggests a ﬂexible group
structure, in which a common, similar or even distinct feature spaces can be determined between diﬀerent
pairs of tasks. Additionally, our MTL framework is kernel-based and, thus, may take advantage of the non-
linearity introduced by the feature mapping of the associated Reproducing Kernel Hilbert Space (RKHS)
.
H
Also, to avoid a degradation in generalization performance due to choosing an inappropriate kernel function,
our framework employs a Multiple Kernel Learning (MKL) strategy [21], hence, rendering it a Multi-Task
Multiple Kernel Learning (MT-MKL) approach.

∀

P

t = 0,

M
m=1(µm + λm

It is worth mentioning that a widely adopted practice for combining kernels is to place an Lp-norm
constraint on the combination coeﬃcients θ = [θ1, . . . , θM ], which are learned during training. For example,
a conically combination of task objectives with an Lp-norm feasible region is introduced in [23] and further
extended in [22]. Also, another method introduced in [25] proposes a partially shared kernel function
kt ,
t )km, along with L1-norm constraints on µ and λ. The main advantage of such a
method over the traditional MT-MKL methods, which consider a common kernel function for all tasks (by
letting λm
t, m), is that it allows tasks to have their own task-speciﬁc feature spaces and, potentially,
alleviate the eﬀect of negative transfer. However, popular MKL formulations in the context of MTL, such as
this one, are capable of modeling two types of tasks: those that share a global, common feature space and
those that employ their own, task-speciﬁc feature space. In this work we propose a more ﬂexible framework,
which, in addition to allowing some tasks to use their own speciﬁc feature spaces (to avoid negative transfer
learning), it permits forming arbitrary groups of tasks sharing the same, group-speciﬁc (instead of a single,
global), common feature space, whenever warranted by the data. This is accomplished by considering a
group lasso regularizer applied to the set of all pair-wise diﬀerences of task-speciﬁc MKL weights. For
no regularization penalty, each task is learned independently of each other and will utilize its own feature
space. As the regularization penalty increases, pairs of MKL weights are forced to equal each other leading
the corresponding pairs of tasks to share a common feature space. We demonstrate that the resulting
optimization problem can be solved by employing a 2-block coordinate descent approach, whose ﬁrst block
consists of the Support Vector Machine (SVM) weights for each task and which can be optimized eﬃciently
using existing solvers, while its second block comprises the MKL weights from all tasks and is optimized via

2

a consensus-form, Alternating Direction Method of Multipliers (ADMM)-based step.

The rest of the paper is organized as follows: In Sect. 2 we describe our formulation for jointly learning
the optimal feature spaces and the parameters of all the tasks. Sect. 3 provides an optimization technique
to solve our non-smooth convex optimization problem derived in Sect. 2. Sect. 4 presents a Rademacher
complexity-based generalization bound for the hypothesis space corresponding to our model. Experiments
are provided in Sect. 5, which demonstrate the eﬀectiveness of our proposed model compared to several MTL
methods. Finally, in Sect. 6 we conclude our work and brieﬂy summarize our ﬁndings.

Notation: In what follows, we use the following notational conventions: vectors and matrices are depicted
in bold face. A prime ′ denotes vector/matrix transposition. The ordering symbols
when applied
to vectors stand for the corresponding component-wise relations. If Z+ is the set of postivie integers, for a
given S

Z+, we deﬁne NS ,

. Additional notation is deﬁned in the text as needed.
}

1, . . . , S
{

and

(cid:23)

(cid:22)

∈

2 Formulation

{

1, 1

(xn

t , yn
t )

X × {−

nt
n=1 , t
}

. Here,
}

wt, φt(x)
h

NT , which is sampled from
Assume T supervised learning tasks, each with a training set
denotes the native space of samples for all tasks
an unknown distribution Pt(x, y) on
X
1 are the associated labels. Without loss of generality, we will assume an equal number n of training
and
±
samples per task. The objective is to learn T binary classiﬁcation tasks using discriminative functions
ft(x) ,
NT , where wt is the weight vector associated to task t. Moreover, the
iHt,θ + bt for t
∈
Ht,θ =
feature space of task t is served by

M
t Hm with induced feature mapping φt , [
θm
m=1
· · ·
M
′]′ and endowed with the inner product
m=1 θm
·iHm . The reproducing kernel
,
·iHt,θ =
,
t h·
p
h·
t, xj
t, xj
t, xj
t ) for all xi
t km(xi
function for this feature space is given as kt(xi
In our
t ) =
p
framework, we attempt to learn the wt’s and bt’s jointly with the θt’s via the following regularized risk
minimization problem:

M
m=1 θm
P

t ∈ X

θM
t φM

θ1
t φ1

p
.

L

P

∈

′

min
w∈Ω(w),θ∈Ω(θ),b

T

2

k

wtk
2

+ C

T

n

t=1
X
Ω (w) ,
{
Ω (θ) ,
{

w = (w1,

θ = (θt,

1

tft(xi
yi
t)

+ + λ

(cid:2)

t=1
X

−
i=1
X
(cid:3)
, wT ) : wt ∈ Ht,θ, θ
· · ·
∈
0,
θtk1 ≤
, θT ) : θt (cid:23)
1,

k

s>t
X

t=1
X
Ω (θ)
}
NT }

t
∀

∈

· · ·

T −1

T

θt −

k

θsk2

(1)

where w , (wt,
, wT ) and θ , (θt,
w and θ respectively, and [u]+ = max
non-negative regularization parameters.

· · ·

· · ·
u, 0
{

}

∈

, θT ), Ω (w) and Ω (θ) are the corresponding feasible sets for
R denotes the hinge function. Finally, C and λ are

, u

The last term in Problem 1 is the sum of pairwise diﬀerences between the tasks’ feature weight vectors.
For each pair of (θt, θs), the pairwise penalty
θsk2 may favor a small number of non-identical θt.
Therefore, it ensures that a ﬂexible (common, similar or distinct) feature space, will be selected between
tasks t and s. In this manner, a ﬂexible group structure of shared features across multiple tasks can be
achieved by this framework. It is also worth mentioning that two special cases are covered by the proposed
θt −
model: (i) if λ
0 and, thus,
k
0, the proposed model reduces to T independent
all tasks share a single common feature space. (ii) As λ
classiﬁcation tasks.

(λ is only required to be suﬃciently large), for all task pairs

θsk2 →

θt −

→ ∞

→

k

It is easy to verify that Problem 1 is a convex minimization problem, which can be solved using a block
coordinate descent method alternating between the minimization with respect to θ and the (w, b) pair.
Motivated by the non-smooth nature of the last regularization term, in Sect. 3 we develop a consensus
version of the ADMM to solve the minimization problem with respect to θ.

3 The proposed Consensus Optimization Algorithm

Problem 1 can be formulated as the following equivalent problem, which entails T inter-related SVM training
problems:

3

min
θ,w,b,ξ

m=1
X

t=1
X
s.t. yi
t

T

M

T

n

T −1

T

2
Hm

k

wm
t k
2θm
t

+ C

ξi
t + λ

θt −
k

θsk2

wt, φ(xi
t)
θtk1 ≤
(cid:11)
It can be shown that the primal-dual form of Problem 2 with respect to θ and

(cid:16)(cid:10)
θt (cid:23)

≥
NT

NT , i

(cid:17)
∈

0,

1,

−

Ht

∈

∀

∀

k

t

t

Nn

∈

t=1
X
+ bt

i=1
X
1

t=1
X
t, ξi
ξi
t ≥

s>t
X
0,

min
θt∈Ω(θ)

max
αt∈Ω(α)

T

T

M

′

t1n −
α

1
2

′

θm
t (α

tYtK m

t Ytαt) + λ

T −1

T

w, b, ξ

is given by

{

}

θsk2

θt −
k
NT }

s>t
X
t

∈

′

C1n, α

θtk1 ≤

1,

t=1
X

tyt = 0,
∀
NT }

∈

t

∀

t=1
X
α = (αt,

{

Ω (α) ,
Ω (θ) ,

αt (cid:22)
0,
k
{
where 1n is a vector containing n 1’s, Y t , diag(yt), Km
t ), θt , [θ1
t, xj
given as km(xi
wt, bt, ξt}
.
w.r.t.

t , . . . , θM
t

θ = (θt,

· · ·

· · ·

{

m=1
t=1
X
X
, αT ) : 0
(cid:22)
, θT ) : θt (cid:23)

Rn×n is the kernel matrix, whose (i, j) entry is
]′, and αt is the Lagrangian dual variable for the minimization problem

t ∈

w, b, ξ

It is not hard to verify that the optimal objective value of the dual problem is equal to the optimal
objective value of the primal one, as the strong duality holds for the primal-dual optimization problems
and α respectively. Therefore, a block coordinate descent framework1 can be applied to
w.r.t.
decompose Problem 3 into two subproblems. The ﬁrst subproblem, which is the maximization problem with
respect to α, can be eﬃciently solved via LIBSVM [8], and the second subproblem, which is the minimization
problem with respect to θ, takes the form

}

{

T −1

T

min
θt

λ

t=1
X
0,
s.t. θt (cid:23)
t Ytαt and qt

θt −
k
s>t
X
θtk1 ≤
k
, [q1

T

′

θ

tqt

θsk2 +
t
1,

t=1
X
NT

∈
]′. Due to the non-smooth nature of Problem 4,
where we deﬁned qm
t
we derive a consensus ADMM-based optimization algorithm to solve it eﬃciently. Based on the exposition
provided in Sections 5 and 7 of [6], it is straightforward to verify that Problem 4 can be written in ADMM
form as

∀
t , . . . , qM
t

tYtK m

1
2 α

,

−

′

N

min
s,θ,z

λ

hi(si) + g(θ) + IΩ(θ)(z)

i=1
X
s.t. si −
z
−
, and the local variable si ∈

˜θi = 0, i
θ = 0

∈

NN

2

where N , T (T −1)
R2M consists of two vector variables (si)j and (si)j′ , where
(i, j) maps the jth component of the local variable si to
(si)j = θM(i,j). Note that the index mapping t =
the tth component of the global variable θ. Also, ˜θi can be considered as the global variable’s idea of what
the local variable si should be. Moreover, for each i, the function hi(si) is deﬁned as
k2, and
the objective term g(θ) is given as
tqt. Finally, IΩ(θ)(z) is the indicator function for the constraint
set θ (i.e., IΩ(θ)(z) = 0 for z

Ω (θ), and IΩ(θ)(z) =

(si)j −

Ω (θ)).

T
t=1 θ

(si)j′

M

k

′

The augmented Lagrangian (using scaled dual variables) for Problem 5 is

for z /
∈

∞

∈

P

N

Lρ(s, θ, z, u, v) =λ

hi(si) + g(θ) + IΩ(θ)(z) + (ρ/2)

i=1
X
+ (ρ/2)
k

z

θ + v

2
2,

k

−

1

A MATLABr implementation of our framework is available at

https://github.com/niloofaryouseﬁ/ECML2015

N

i=1
X

si −

k

˜θi + uik

2
2

(2)

(3)

(4)

(5)

(6)

4

where ui and v are the dual variables for the constraints si = ˜θi and z = θ respectively. Applying ADMM
on the Lagrangian function given in (6), the following steps are carried out in the kth iteration

sk+1
i = arg min
si {

λhi(si) + (ρ/2)
k

si −

˜θ

k
i + uk
i k

2
2}

N

θk+1 = arg min
θ {

g(θ) + (ρ/2)

sk+1
i −

k

˜θi + uk
i k

2
2 + (ρ/2)
k

zk

−

θ + vk

2
2}

k

i=1
X
IΩ(θ)(z) + (ρ/2)
k

z

−

θk+1 + vk

2
2}

k

zk+1 = arg min
z {
i + sk+1
uk+1
i = uk
vk+1 = vk + zk+1

i −

k+1
˜θ
i
θk+1

where, for each i
worth mentioning that the s-update is a proximal operator evaluation for

∈

(11)
NN , the s- and u-updates can be carried out independently and in parallel. It is also

−

.

k2 which can be simpliﬁed to

k

where

Sλ/ρ(˜θ
Sκ is the vector-valued soft thresholding (or shrinkage) operator and which is deﬁned as
k2)+a,
a
κ/
k

Sκ(a) , (1

Sκ(0) , 0.

sk+1
i =

NN

i ),

−

∈

∀

i

k
i + uk

Furthermore, as the objective term g is separable in θt, the θ-update can be decomposed into T independent
minimization problems, for which a closed from solution exists

(7)

(8)

(9)

(10)

(12)

(13)

(14)

θk+1

t =

1

−

T

1 

XM(i,j)=t

(cid:0)



(si)k+1

j + (ui)k
j

+

t + vk
zk
t

(cid:1)

(cid:0)

,

t

∀

∈

NT

−

(cid:1)

(1/ρ)qt


Algorithm 1 Algorithm for solving Problem 3.
Input: X 1, . . . , X T , Y 1, . . . , Y T , C, λ
Output: θ1, . . . , θT , α1, . . . , αT
1: Initialize: θ(0)
1 , . . . , θ(0)
2: Calculate: Base kernel matrices K m
3: while not converged do
4: α(r)

T , r = 1

′

arg max α∈Ω(α)
1
2 (α
← −
arg min θ∈Ω(θ) λ

1
T
t=1 α
2
−
t Yt(αt)(r),
t)(r)YtK m
t, m
P
P
∀
T −1
T
θt −
t=1
s>t k

te

′

←
t )(r)

5:

(qm
θ(r)
6:
←
7: end while
8: α∗ = α(r)
9: θ∗ = θ(r)

t using X t’s for the T tasks and the M kernels.

T
t=1

M
m=1(θm

t )(r−1)(α

tYtK m

t Ytαt)

′

P
θsk2 +

′

T
t=1 θ

tq(r)

t using Algorithm 2

P

P

P

In the third step of the ADMM, we project (θk+1

vk) onto the constraint set Ω (θ). Note that, this
set is separable in θ, so the projection step can also be performed independently and in parallel for each
variable zt, i.e.,

−

t + vk
The zt-update can also be seen as the problem of ﬁnding the intersection between two closed convex sets
, which can be handled using Dykstra’s
1,

t = ΠΩ(θ)(θk+1
zk+1

(15)

NT .

t ),

0,

∈

∀

t

t

Ω1 (θ) =
∈
alternating projections method [5, 11] as follows

and Ω2 (θ) =

θt (cid:23)

{k

∀

{

t

θtk1 ≤

NT }

NT }

∀

∈

t = ΠΩ1(θ)(θk+1
yk+1

t + vk

t = ΠΩ2(θ)(yk+1
zk+1
βk+1
t = βk

t + yk+1

t + βk
zk+1
t

,

t −

NT

t

∀

∈

θk+1
t + vk

βk

t ) =

1
t −
2
h
t + βk
t ) = PM (yk+1

t ) +

βk
t

+
i
1M ,

,

t

NT

∀

t

∈
NT

∀

∈

t −
1
M

(16)

(17)

(18)

5

′

where PM ,
projections onto Ω1 (θ) and Ω2 (θ) respectively with dual variables βt ∈
update the dual variables ui and v using the equations given in (10) and (11).

is the centering matrix. Furthermore, the yt- and zt updates are the Euclidean
RM×1, t = 1, . . . , T . Finally, we

IM −
(cid:18)

1M 1
M

(cid:19)

M

1 , . . . , q(r)

T , ρ
1 , . . . , θ(r)

Algorithm 2 Consensus ADMM algorithm to solve optimization Problem 4
Input: q(r)
Output: θ(r)
1: Initialize: ˆθ
2: while not converged do
NT do
3:
k
i + uk
i )

(0)
T , k = 0

1 , . . . , ˆθ

for i

(0)

4:

T

(si)k+1

j + (ui)k
j

+

t + vk
zk
t

(1/ρ)qt

(cid:1)

(cid:0)

−

(cid:1)

i

1

−
ˆθ

M(i,j)=t

NN , t
∈
∈
i ← Sλ/ρ(˜θ
sk+1
k+1
ˆθ
t ←
1
T
k+1
hP
βk
yk+1
1
(cid:0)
t + vk
t −
t
2
+
t + βk
i
h
PM (yk+1
t ) + 1
M 1M
βk
zk+1
t + yk+1
t
t −
k+1
˜θ
i + sk+1
uk
i
i −
k+1
ˆθ
t + zk+1
vk
t
t −

5:

6:

9:

7:

8:

t ←
zk+1
t ←
βk+1
t ←
uk+1
i ←
vk+1
10:
t ←
end for
11:
12: end while
13: θ(r)

ˆθ

(k+1)

←

3.1 Convergence Analysis and Stopping Criteria

Convergence of Algorithm 2 can be derived based on two mild assumptions similar to the standard conver-
gence theory of the ADMM method discussed in [6]; (i) the objective functions h(s) =
k2
and g(θ) =
tqt are closed, proper and convex, which implies that the subproblems arising in the s-
update (7) and θ-update (8) are solvable, and (ii) the augmented Lagrangian (6) for ρ = 0 has a saddle point.
Under these two assumptions, it can be shown that our ADMM-based algorithm satisﬁes the following

(si)j −

N
i=1 k

T
t=1 θ

(si)j′

P

P

′

Convergence of residuals : si

k

˜θ

k
i →

−

Convergence of dual variables: uk
dual optimal points.

i →

0,

i

∀
i
∀

∈

u∗
i ,

NN , and zk

∈
NN , and vk

−

→

θk

→
v∗ as k

0 as k

→ ∞

.
→ ∞
, where u∗ and v∗ are the

Convergence of the objective : h(sk) + g(zk)
converges to its optimal value as the algorithm proceeds.

p∗ as k

→

→ ∞

, which means the objective function (4)

Also, the algorithm is terminated, when the primal and dual residuals satisfy the following stopping

•

•

•

criteria

k

ek
p1k2 ≤
ek
d1k2 ≤

ǫpri
1 ,
ǫdual
1

,

k

ek
p2k2 ≤
ek
d2k2 ≤

ǫpri
2 ,
ǫdual
2

,

ek
p3k2 ≤
k
ek
d3k2 ≤

ǫpri
3
ǫdual
3

k
θk and ek
θk, ek
where the primal residuals of the kth iteration are given as ek
zk.
θk), ek
yk+1)are dual residuals at iteration
Similarly ek
k. Also, the tolerances ǫpri > 0, and ǫdual > 0 can be chosen appropriately using the method described in
Chapter 3 of [6].

k
p1 = sk
d3 = ρ(yk

d1 = ρ(θk+1

zk+1) and ek

d2 = ρ(zk

p3 = yk

p2 = zk

−
−

−

−

−

−

k

(19)

6

3.2 Computational Complexity

Algorithm 1 needs to compute and cache T M kernel matrices; however, they are computed only once in
(T M n2) time. Also, as long as the number of tasks T is not excessive, all the matrices can be computed
O
and stored on a single machine, since (i) the number M of kernels, is typically chosen small (e.g., we chose
M = 10), and (ii) the number n of training samples per task is not usually large; if it were large, MTL
would probably not be able to oﬀer any advantages over training each task independently. For each iteration
(n3) per task. Therefore, if
of Algorithm 1, T independent SVM problems are solved at a time cost of
(T n3 + KM T 2)
Algorithm 2 converges in K iterations, the runtime complexity of Algorithm 1 becomes
per iteration. Note, though, that K is not usually more than a few tens of iterations [6].

O

O

On the other hand, if the number of tasks T is large, the nature of our problem allows our algorithm
to be implemented in parallel. The α-update can be handled as T independent optimization problems,
which can be easily distributed to T subsystems. Each subsystem N needs to compute once and cache M
kernel matrices for each task. Then, for each iteration, one SVM problem is required to be solved by each
(n3) time. Moreover, our ADMM-based algorithm updating the θ parameters
subsystem, which takes
NN . Assuming that exchanging data and updates between
can also be implemented in parallel over i
(KM ) time. Therefore, taking advantage
subsystems consumes negligible time, the ADMM only requires
(n3 + KM ) per iteration.
of a distributed implementation, the complexity of Algorithm 1 is only

O

O

∈

O

4 Generalization Bound based on Rademacher Complexity

In this section, we provide a Rademacher complexity-based generalization bound for the Hypothesis Space
(HS) considered in Problem 1, which can be identiﬁed with the help of the following Proposition 2.

Proposition 1. (Proposition 12 in [20], part (a)) Let
ν > 0, there must exist a η > 0, such that the optimal solution of (20) is also optimal in (21)

and let f, g :

C ⊆ X

C 7→

R be two functions. For any

min
x∈C

f (x) + νg(x)

min
x∈C,g(x)≤η

f (x)

Using Proposition 1, one can show that Problem 1 is equivalent to the following problem

min
′

w∈Ω

(w)

C

T

n

l

wt, φt

xi
t

, yi
t

′

Ω

(w) ,

w = (w1,

{

t=1
X

(cid:0)

i=1
X
, wT ) : wt ∈ Ht,θ, θ

(cid:1)

(cid:0)

(cid:1)
∈

· · ·

′

Ω

(θ) ,

2

wtk

k

≤

Rt, t

NT }

∈

where

′

Ω

(θ) , Ω (θ)

θ = (θt,

, θT ) :

· · ·

∩ (

θt −
k

θsk2 ≤

γ

)

T −1

T

t=1
X

s>t
X

The goal here is to choose the w and θ from their relevant feasible sets, such that the objective function

of (22) is minimized. Therefore, the relevant hypothesis space for Problem 22 becomes

,

F

x

[

w1, φ1i
h

7→

, . . . ,

wT , φT i
]
h

:

twt ∈ Ht,θ,
∀

wtk

k

2

≤

Rt, θ

∈

′

n

′

Ω

(θ)

o

Note that ﬁnding the Empirical Rademacher Complexity (ERC) of
T −1
t=1

T
s>t k

θt −

θsk2 ≤

smooth nature of the constraint
deﬁned in (24); notice that

F

F ⊆ H

.
P

P

is complicated due to the non-

γ. Instead, we will ﬁnd the ERC of the HS

2Note that Proposition 1 here utilizes the ﬁrst part of Proposition 12 in [20] and does not require the strong

duality assumption, which is necessary for the second part of Proposition 12 in [20].

7

(20)

(21)

(22)

(23)

H

(24)

(25)

(26)

(27)

(28)

,

H

x

[

w1, φ1i
h

7→

, . . . ,

wT , φT i
]
h

:

twt ∈ Ht,θ,
∀

wtk

k

2

≤

Rt, θ

∈

′

′′

Ω

(θ)

o

where

n

′′

Ω

(θ) , Ω (θ)

θ = (θt,

, θT ) :

· · ·

∩ (

θt −

k

θsk

2
2 ≤

γ2

)

T −1

T

t=1
X

s>t
X

Using the ﬁrst part of Theorem (12) in [4], it can be shown that the ERC of

of function class
generalization bound for

F

. Thus, the bound derived for

is also valid for

H

F

upper bounds the ERC
. The following theorem provides the

H

.

H

Theorem 1. Let
Then for all f

deﬁned in (24) be the multi-task HS for a class of functions f = (f1, . . . , fT ) :

H
, for δ > 0 and for ﬁxed ρ > 0, with probability at least 1
∈ H

−

δ it holds that

RT .

X 7→

where

R(f )

ˆRρ(f ) +

ˆRS(

) + 3

2
ρ

H

≤

log 1
δ
2T n

s

ˆRS (

)

H

≤

ˆRub (

) =

H

s

√3γRM
nT

where ˆRS(

H

), the ERC of

, is given as

H

ˆRS(

σi
tft(xi
t)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
the ρ-empirical large margin error ˆRρ(f ), for the training sample S =
(cid:12)

sup
f =(f1,...,fT )∈F

t=1
X

i=1
X

) =

Eσ

H

(

(cid:8)

xi
t

(cid:9)
t, yi
xi
t

t∈NT ,i∈Nn )

1
nT

T

n

n,T
i,t=1 is deﬁned as

T

n

ˆRρ(f ) =

1
nT

min

1, [1

tft(xi
yi

−

t=1
X

i=1
X

(cid:0)

(cid:1)(cid:9)

(cid:8)(cid:0)
t)/ρ]+

(cid:1)

Also, R(f ) = Pr[yf (x) < 0] is the expected risk w.r.t. 0-1 loss, n is the number of training samples for each
task, T is the number of tasks to be trained, and M is the number of kernel functions utilized for MKL.

H

The proof of this theorem is omitted due to space constraints. Based on Theorem 1, the second term in
(26), the upper bound for ERC of
, decreases as the number of tasks increases. Therefore, it is reasonable
to expect that the generalization performance to improve, when the number T of tasks or the number n
of training samples increase. Also, due to the formulation’s group lasso (L1/L2-norm) regularizer on the
It is worth mentioning,
pair-wise MKL weight diﬀerences, the ERC in (27) depends on M as
√log M as in [9], if one considers instead a Lp/Lq-norm regularizer,
that, while this could be improved to
(26) allows one to construct data-dependent
we won’t pursue this avenue here. Let us ﬁnally note, that
conﬁdence intervals for the true, pooled (averaged over tasks) misclassiﬁcation rate of the MTL problem
under consideration.

√M .

O

O

5 Experiments

In this section, we demonstrate the merit of the proposed model via a series of comparative experiments. For
reference, we consider two baseline methods referred to as STL and MTL, which present the two extreme
cases discussed in Sect. 2. We also compare our method with ﬁve state-of-the-art methods which, like ours,
fall under the CMTL family of approaches. These methods are brieﬂy described below.

8

•

•

•

•

•

•

•

STL: single-task learning approach used as a baseline, according to which each task is individually
trained via a traditional single-task MKL strategy.

MTL: a typical MTL approach, for which all tasks share a common feature space. An SVM-based
formulation with multiple kernel functions was utilized and the common MKL parameters for all tasks
were learned during training.

CMTL [17]: in this work, the tasks are grouped into disjoint clusters, such that the model parameters
of the tasks belonging to the same group are close to each other.

Whom [19]: clusters the task, into disjoint groups and assumes that tasks of the same group can
jointly learn a shared feature representation.

FlexClus [30]: a ﬂexible clustering structure of tasks is assumed, which can vary from feature to
feature.

CoClus [26]: a co-clustering structure is assumed aiming to capture both the feature and task rela-
tionship between tasks.

MeTaG [16]: a multi-level grouping structure is constructed by decomposing the matrix of tasks’
parameters into a sum of components, each of which corresponds to one level and is regularized with
a L2-norm on the pairwise diﬀerence between parameters of all the tasks.

5.1 Experimental Settings

For all experiments, all kernel-based methods (including STL, MTL and our method) utilized 1 Linear,
1 Polynomial with degree 2, and 8 Gaussian kernels with spread parameters
for MKL. All
k(x, x)k(y, y). Moreover, for CMTL, Whom and
kernel functions were normalized as k(x, y)
CoClus methods, which require the number of task clusters to be pre-speciﬁed, cross-validation over the
set
was used to select the optimal number of clusters. Also, the regularization parameters of
all methods were chosen via cross-validation over the set

2−10, . . . , 210

20, . . . , 27

1, . . . , T /2

k(x, y)/

←

p

(cid:9)

(cid:8)

}

{

.

5.2 Experimental Results

(cid:8)

(cid:9)

We assess the performance of our proposed method compared to the other methods on 7 widely-used data
sets including 3 real-world data sets: Wall-Following Robot Navigation (Robot ), Statlog Vehicle Silhouettes
(Vehicle) and Statlog Image Segmentation (Image) from the UCI repository [14], 2 handwritten digit data
sets, namely MNIST Handwritten Digit (MNIST ) and Pen-Based Recognition of Handwritten Digits (Pen),
as well as Letter and Landmine.

The data sets from the UCI repository correspond to three multi-class problems. In the Robot data set,
each sample is labeled as: “Move-Forward, “SlightRight-Turn”, “Sharp-Right-Turn” and “Slight-Left-Turn”.
These classes are designed to navigate a robot through a room following the wall in a clockwise direction.
The Vehicle data set describes four diﬀerent types of vehicles as “4 Opel”, “SAAB”, “Bus” and “Van”. On
the other hand, the instances of the Image data set were drawn randomly from a database of 7 outdoor
images which are labeled as “Sky”, “Foliage”, “Cement”, “Window”, “Path” and “Grass”.

Also, two multi-class handwritten digit data sets, namely MNIST and Pen, consist of samples of hand-
written digits from 0 to 9. Each example is labeled as one of ten classes. A one-versus-one strategy was
adopted to cast all multi-class learning problems into MTL problems, and the average classiﬁcation accuracy
across tasks was calculated for each data set. Moreover, an equal number of samples from each class was
chosen for training for all ﬁve multi-class problems.

We also compare our method on two widely-used multi-task data sets, namely the Letter and Landmine
data sets. The former one is a collection of handwritten words collected by Rob Kassel of MIT’s spoken
‘G’, ‘I’
Language System Group, and involves eight tasks:
vs. ‘J’, ‘A’ vs. ‘O’, ‘F’ vs. ‘T’ and ‘H’ vs.
‘N’. Each letter is represented by a 8 by 16 pixel image, which
forms a 128 dimensional feature vector per sample. We randomly chose 200 samples for each letter. An
exception is letter J, for which only 189 samples were available. The Landmine data set consists of 29 binary

‘Y’, ‘M’ vs.

‘N’, ‘A’ vs.

‘E’, ‘G’ vs.

‘C’ vs.

9

classiﬁcation tasks collected from various landmine ﬁelds. The objective is to recognize whether there is
a landmine or not based on a region’s characteristics, which are described by four moment-based features,
three correlation-based features, one energy ratio feature, and one spatial variance feature.

In all our experiments, for all methods, we considered training set sizes of 10%, 20% and 50% of the
original data set to investigate the inﬂuence of the data set size on generalization performance. An exception
was the Landmine data set, for which we used 20% and 50% of the data set for training purposes due to its
small size. The rest of data were split into equal sizes for validation and testing.

Table 1: Experimental comparison between our method and seven benchmark methods

STL(7) MTL(5.42) CMTL(6.33) Whom(3.25) FlexClus(4.33) Coclus(4) MetaG(5) Our Method(1.67)

STL(6) MTL(4.43) CMTL(6.14) Whom(3.29) FlexClus(5.57) Coclus(4.57) MetaG(4.71) Our Method(1.14)

10%

Robot
Vehicle
Image
Pen
MNIST
Letter

20%

Robot
Vehicle
Image
Pen
MNIST
Landmine
Letter

84.51(7)
79.73(8)
97.08(7)
98.16(7)
94.09(7)
84.12(6)

87.67(7)
85.88(4)
97.41(6)
98.57(7)
96.13(6)
58.76(8)
88.75(4)

Robot
Vehicle
Image
Pen
MNIST
Landmine
Letter

91.26(5.5)
88.33(3)
98.40(6)
98.77(7)
97.20(6)
63.76(8)
91.18(4)

84.82(6)
80.38(6)
97.43(3)
98.28(5.5)
94.87(4)
83.12(8)

88.23(6)
86.16(3)
98.02(3)
99.01(6)
96.71(4)
61.89(7)
89.98(2)

91.49(3)
88.71(2)
98.43(5)
99.23(5)
97.37(4)
64.98(6)
91.62(2)

84.15(8)
80.23(7)
97.09(6)
95.78(8)
94.49(6)
85.62(3)

85.08(8)
82.29(8)
97.32(7)
96.06(8)
96.56(5)
65.28(2)
88.24(5)

86.26(8)
83.91(8)
97.56(8)
96.17(8)
97.31(5)
66.76(2)
90.97(5)

88.90(1)
83.14(4)
97.27(4)
98.28(5.5)
95.56(3)
86.82(2)

90.76(1)
85.67(6)
98.46(2)
99.14(3)
96.76(3)
62.53(5)
88.88(3)

91.70(2)
87.3(5)
98.58(2)
99.32(4)
97.78(3)
65.57(4)
91.25(3)

88.34(4)
82.45(5)
98.05(2)
98.67(3)
94.59(5)
83.72(7)

90.15(3)
85.29(7)
97.44(5)
99.13(4)
95.04(7)
62.46(6)
83.79(7)

91.26(5.5)
86.72(7)
98.04(7)
99.33(3)
96.60(7)
64.87(7)
86.47(7)

87.83(5)
86.79(1)
97.24(5)
99.26(1)
93.09(8)
85.46(4)

88.43(5)
87.15(2)
97.50(4)
99.30(2)
94.09(8)
63.52(3)
82.26(8)

89.04(7)
87.55(4)
98.52(3)
99.34(2)
95.87(8)
65.15(5)
86.27(8)

88.77(2)
83.53(3)
97.05(8)
98.57(4)
96.13(2)
85.41(5)

89.12(4)
85.78(5)
97.29(8)
99.02(4)
96.84(2)
62.59(4)
87.99(6)

91.27(4)
86.81(6)
98.49(4)
99.21(6)
98.46(2)
66.24(3)
90.66(6)

88.67(3)
84.51(2)
98.19(1)
99.12(2)
96.70(1)
87.41(1)

90.34(2)
87.76(1)
98.54(1)
99.63(1)
97.86(1)
65.82(1)
90.72(1)

92.41(1)
89.83(1)
99.07(1)
99.77(1)
98.64(1)
67.15(1)
92.49(1)

50%

STL(5.64) MTL(3.85) CMTL(6.29) Whom(3.29) FlexClus(6.21) Coclus(5.29) MetaG(4.42) Our Method(1)

In Table 1, we report the average classiﬁcation accuracy over 20 runs of randomly sampled training sets
for each experiment. Note that we utilized the method proposed in [10] for our statistical analysis. More
speciﬁcally, Friedman’s and Holm’s post-hoc tests at signiﬁcance level α = 0.05 were employed to compare
our proposed method with the other methods.

As shown in Table 1, for each data set, Friedman’s test ranks the best performing model as ﬁrst, the
second best as second and so on. The superscript next to each value in Table 1 indicates the rank of the
corresponding model on the relevant data set, while the superscript next to each model reﬂects its average
rank over all data sets for the corresponding training set size. Note that methods depicted in boldface
are deemed statistically similar to our model, since their corresponding p-values are not smaller than the
adjusted α values obtained by Holm’s post-hoc test. Overall, it can be observed that our method dominates
three, six and ﬁve out of seven methods, when trained with 10%, 20% and 50% training set sizes respectively.
Also, in Figure 1, we provide better insight of how the grouping of task feature spaces might be determined
in our framework. For the purpose of visualization, we applied two Gaussian kernel functions with spread
parameters 2 and 28 and used the Letter multi-task data set.

In this ﬁgure, the x and y axes represent the weights of these two kernel functions for each task. From
Figure 1 (a), when a small training size (10%) is chosen, it can be seen that our framework yields a cluster of
3 tasks, namely
that share a common feature space to beneﬁt from
each other’s data. However, as the number n of training samples per task increases, every task is allowed to
employ its own feature space to guarantee good performance. This is shown in Figure 1 (b), which displays

“A” vs “G”, “A” vs “O”, “G” vs “Y”

{

}

10

Table 2: Comparison of our method against the other methods with the Holm test

10%

STL

MTL

CMTL Whom FlexClus Coclus MeTaG

Test statistic
p value
Adjusted α

3.93
0.0005
0.0071

2.13
0.0138
0.0083

3.49
0.0022
0.0100

1.25
0.2869
0.0125

2.40
0.0777
0.01667

2.62
0.1214
0.0250

2.29
0.1214
0.0500

20%

STL

MTL

CMTL Whom FlexClus

Coclus MeTaG

Test statistic
p value
Adjusted α

3.71
0.00021
0.0083

2.51
0.0121
0.0250

3.82
0.0001
0.0071

1.64
0.1017
0.0500

3.38
0.0007
0.0100

2.62
0.0088
0.01667

2.73
0.0064
0.0125

50%

STL MTL

CMTL Whom FlexClus

Coclus MeTaG

Test statistic
p value
Adjusted α

3.55
0.0004
0.0100

2.18
0.0291
0.0250

4.04
0.0001
0.0071

1.75
0.0809
0.0500

3.98
0.0001
0.0083

3.27
0.0011
0.0125

2.61
0.0089
0.01667

the results obtained for a 50% training set size. Note, that the displayed MKL weights lie on the θ1 + θ2 = 1
line due to the framework’s L1 MKL weight constraint.

2

θ

0.7

A vs G, A vs O, G vs Y

2

θ

0.7

1

F vs T

H vs N M vs N

0.9

I vs J

0.8

0.6

0.5

0.4

0

C vs E

0.3

θ1

(a) Traning set size 10%

1

0.9

0.8

0.6

0.5

0.4

0

F vs T

I vs J

M vs N

H vs N

A vs G

A vs O

G vs Y

C vs E

θ1
(b) Traning set size 50%

0.1

0.2

0.4

0.5

0.6

0.1

0.2

0.3

0.4

0.5

0.6

Figure 1: Feature space parameters for Letter multi-task data set

6 Conclusions

In this work, we proposed a novel MT-MKL framework for SVM-based binary classiﬁcation, where a ﬂexible
group structure is determined between each pair of tasks. In this framework, tasks are allowed to have a
common, similar, or distinct feature spaces. Recently, some MTL frameworks have been proposed, which
also consider clustering strategies to capture task relatedness. However, our method is capable of modeling
a more general type of task relationship, where tasks may be implicitly grouped according to a notion of
feature space similarity. Also, our proposed optimization algorithm allows for a distributed implementation,
which can be signiﬁcantly advantageous for MTL settings involving large number of tasks. The performance

11

advantages reported on 7 multi-task SVM-based classiﬁcation problems largely seem to justify our arguments
in favor of our framework.

Acknowledgments

N. Youseﬁ acknowledges support from National Science Foundation (NSF) grants No. 0806931 and No.
1161228. Moreover, M. Georgiopoulos acknowledges partial support from NSF grants No. 0806931, No.
0963146, No. 1200566, No. 1161228, and No. 1356233. Finally, G. C. Anagnostopoulos acknowledges
partial support from NSF grant No. 1263011. Any opinions, ﬁndings, and conclusions or recommendations
expressed in this material are those of the authors and do not necessarily reﬂect the views of the NSF.

References

[1] Andreas Argyriou, St´ephan Cl´emen¸con, and Ruocong Zhang. Learning the graph of relations among
multiple tasks. ICML 2014 workshop on New Learning Frameworks and Models for Big Data, 2013.

[2] Andreas Argyriou, Theodoros Evgeniou, and Massimiliano Pontil. Convex multi-task feature learning.

Machine Learning, 73(3):243–272, 2008.

[3] Bart Bakker and Tom Heskes. Task clustering and gating for bayesian multitask learning. The Journal

of Machine Learning Research, 4:83–99, 2003.

[4] Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and

structural results. The Journal of Machine Learning Research, 3:463–482, 2003.

[5] HH Bauschke and Jonathan M Borwein. Dykstra’s alternating projection algorithm for two sets. Journal

of Approximation Theory, 79(3):418–443, 1994.

[6] Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, and Jonathan Eckstein. Distributed optimization
and statistical learning via the alternating direction method of multipliers. Foundations and Trends in
Machine Learning, 3(1):1–122, January 2011.

[7] Rich Caruana. Multitask learning. Machine learning, 28(1):41–75, 1997.

[8] Chih-Chung Chang and Chih-Jen Lin. LIBSVM: A library for support vector machines. ACM
Software available at

Transactions on Intelligent Systems and Technology, 2:27:1–27:27, 2011.
http://www.csie.ntu.edu.tw/~cjlin/libsvm.

[9] Corinna Cortes, Mehryar Mohri, and Afshin Rostamizadeh. Generalization bounds for learning kernels.
In Proceedings of the 27th International Conference on Machine Learning (ICML-10), pages 247–254,
2010.

[10] Janez Demˇsar. Statistical comparisons of classiﬁers over multiple data sets. The Journal of Machine

Learning Research, 7:1–30, 2006.

[11] Richard L Dykstra. An algorithm for restricted least squares regression. Journal of the American

Statistical Association, 78(384):837–842, 1983.

[12] A Evgeniou and Massimiliano Pontil. Multi-task feature learning. Advances in neural information

processing systems, 19:41, 2007.

[13] Theodoros Evgeniou, Charles A Micchelli, and Massimiliano Pontil. Learning multiple tasks with kernel

methods. In Journal of Machine Learning Research, pages 615–637, 2005.

[14] A. Frank and A. Asuncion.

UCI machine learning repository,

2010.

Available from:

http://archive.ics.uci.edu/ml.

12

[15] Quanquan Gu, Zhenhui Li, and Jiawei Han. Joint feature selection and subspace learning. In IJCAI
Proceedings-International Joint Conference on Artiﬁcial Intelligence, volume 22, page 1294, 2011.

[16] Lei Han and Yu Zhang. Learning multi-level task groups in multi-task learning. Proceedings of the 29th

AAAI Conference on Artiﬁcial Intelligence (AAAI), 2015.

[17] Laurent Jacob, Jean-philippe Vert, and Francis R Bach. Clustered multi-task learning: A convex

formulation. In Advances in neural information processing systems, pages 745–752, 2009.

[18] Ali Jalali, Sujay Sanghavi, Chao Ruan, and Pradeep K Ravikumar. A dirty model for multi-task

learning. In Advances in Neural Information Processing Systems, pages 964–972, 2010.

[19] Zhuoliang Kang, Kristen Grauman, and Fei Sha. Learning with whom to share in multi-task feature
learning. In Proceedings of the 28th International Conference on Machine Learning (ICML-11), pages
521–528, 2011.

[20] Marius Kloft, Ulf Brefeld, S¨oren Sonnenburg, and Alexander Zien. Lp-norm multiple kernel learning.

The Journal of Machine Learning Research, 12:953–997, 2011.

[21] Gert RG Lanckriet, Nello Cristianini, Peter Bartlett, Laurent El Ghaoui, and Michael I Jordan. Learning
the kernel matrix with semideﬁnite programming. The Journal of Machine Learning Research, 5:27–72,
2004.

[22] Cong Li, Michael Georgiopoulos, and Georgios C Anagnostopoulos. Conic multi-task classiﬁcation. In

Machine Learning and Knowledge Discovery in Databases, pages 193–208. Springer, 2014.

[23] Cong Li, Michael Georgiopoulos, and Georgios C. Anagnostopoulos. Pareto-path multitask multiple
kernel learning. Neural Networks and Learning Systems, IEEE Transactions on, 26(1):51–61, Jan 2015.
doi:10.1109/TNNLS.2014.2309939.

[24] Andreas Maurer. Bounds for linear multi-task learning. The Journal of Machine Learning Research,

7:117–139, 2006.

pages 1255–1260, 2009.

[25] Lei Tang, Jianhui Chen, and Jieping Ye. On multiple kernel learning with multiple labels. In IJCAI,

[26] Linli Xu, Aiqing Huang, Jianhui Chen, and Enhong Chen. Exploiting task-feature co-clusters in multi-
task learning. In Proceedings of the Twenty-Ninth AAAI Conference on Artiﬁcial Intelligence (AAAI-
15), 2015.

[27] Ya Xue, Xuejun Liao, Lawrence Carin, and Balaji Krishnapuram. Multi-task learning for classiﬁcation

with dirichlet process priors. The Journal of Machine Learning Research, 8:35–63, 2007.

[28] Yu Zhang and Dit-Yan Yeung. A convex formulation for learning task relationships in multi-task

learning. arXiv preprint arXiv:1203.3536, 2012.

[29] Yu Zhang and Dit-Yan Yeung. A regularization approach to learning task relationships in multitask

learning. ACM Transactions on Knowledge Discovery from Data (TKDD), 8(3):12, 2014.

[30] Wenliang Zhong and James Kwok. Convex multitask learning with ﬂexible task clusters. arXiv preprint

arXiv:1206.4601, 2012.

[31] Jiayu Zhou, Jianhui Chen, and Jieping Ye. Clustered multi-task learning via alternating structure

optimization. In Advances in neural information processing systems, pages 702–710, 2011.

13

Supplementary Materials

A useful lemmas in deriving the generalization bound of Theorem 1 is provided next.

∈
denote the Hadamard (component-wise) matrix product. Then, it holds that

∈

RN ×N and let σ

RN be a vector of independent Rademacher random variables.

Lemma 1. Let A, B
Let

◦

Eσ

(σ′Aσ) (σ′Bσ)
}
{

= trace

A
}

{

trace

B

{

}

+ 2 (trace

AB

trace

{

} −

A
{

B

)
}

◦

Proof. Let [
expectation in question can be written as

·

] denote the Iverson bracket, such that [predicate] = 1, if predicate is true and 0, if false. The

Eσ

(σ′Aσ) (σ′Bσ)
}

{

=

ai,j bk,l E

σiσjσkσl}

{

Xi,j,k,l
1, . . . , N
{

where the indices of the last sum run over the set

Rademacher random variables, it is not diﬃcult to verify the fact that E
four cases:
= k
cases, E

= k
= 0. Therefore, it holds that

i = j, k = l, i
{

i = k, j = l, i

i = l, k = j, i

= l

,
}

,
}

{

. Since the components of σ are independent
}
= 1 only in the following
; in all other
}

σiσj σkσl}
{
i = j, j = k, k = l
and
{

}

{
σiσj σkσl}
{

E

σiσjσkσl}

{

= [i = k][j = l][i

= l] + [i = j][k = l][i

= k]

+ [i = l][k = j][i

= k] + [i = j][j = k][k = l]

Substituting (31) into (30), after some algebraic operations, yields the desired result.

Proof of Theorem 1

By utilizing Theorems 16, 17 in [24], it can be proved that given a multi-task HS
functions f = (f1, . . . , fT ) :
δ the following holds
1

, deﬁnes as a class of
, for δ > 0 and for ﬁxed ρ > 0, with probability at least

RT , for all f

X 7→

∈ F

F

−

where the ERC ˆRS(

) is given as

F

R(f )

ˆRρ(f ) +

ˆRS(

) + 3

2
ρ

F

≤

log 2
δ
2T n

s

ˆRS(

) =

F

1
nT

Eσ

sup
f =(f1,...,fT )∈F

(

T

n

t=1
X

i=1
X

tft(xi
σi
t)

)

and the ρ-empirical large margin error ˆRρ(f ) for the training sample S =

t, yi
xi
t

n,T
i,t=1 is deﬁned as

ˆRρ(f ) =

1
nT

T

n

t=1
X

i=1
X

min

1, [1

tft(xi
yi

−

(cid:1)(cid:9)

(cid:8)(cid:0)
t)/ρ]+

(cid:1)

(cid:0)
Also, from eqs. (1) and (2) in [9], we know that wt =

′

is equivalent to α
deﬁned as ft(xt) =

tK tαt ≤
Rt. Then we can observe that
P
∀
wt, φt(xt)
Ht,θ is equivalent to ft(xt) =
i
h

n

j=1 αj
x

t ) along with constraint

t φt(xj
S and t
∈
t Kt(xj
t , xt), where Kt =

Rt,
1, . . . , T , the decision function
t Km.

M
m=1 θm

wtk

∈
n
j=1 αj

≤

k

2

P

P

(29)

(30)

(31)

(32)

(33)

14

So, based on the deﬁnition of empirical Rademacher complexity given in (33), we will have

ˆRS(

) =

H

sup
(θ),αt∈Ω(α)

′′

θt∈Ω

T

n,n

tαj
σi

t Kt(xi

t, xj
t )

1
nT

1
nT

Eσ 


Eσ

=

"

θt∈Ω

′′

sup
(θ),αt∈Ω(α)

i,j=1
X

t=1
X
T

′

σ

tKtαt

#

t=1
X





where σt = [σ1
M
m=1 θm
as

, αt = [α1
t , . . . , σn
t ]
t, xj
t ), Ω(α) =

t Km(xi

′

′

t , . . . , αn
, Kt ∈
t ]
tKtαt ≤
α
αt |

{

′

t
∀
It can be observed that the maximization problem with respect to αt can be handled as T independent
P
optimization problem, as Ω(α) is separable in terms of αt. Also, it can be shown that using Cauchy-Schwartz
inequality, the optimal value of αt is achieved when K 1/2

t αt is colinear with K 1/2

t σt, which gives

and Ω

}

Rn×n is a kernel matrix whose (i, j)-th elements is deﬁned
Rt,

(θ) is deﬁned as (25).

′′

sup
αt∈Ω(α)

′

σ

tKtαt =

′

σ

tKtσtRt

q

Assuming Rt ≤

∀

R

t, (34) now becomes

ˆRS(

) =

H

√R
nT

Eσ

sup
′′

(

θt∈Ω

(θ)

T

′

σ

tK tσt

)

=

√R
nT

Eσ 


sup
′′

θt∈Ω

(θ)

=

√R
nT

Eσ

sup
′′

θt∈Ω

(θ)


(

′

t=1 q
X
T

M

t=1
X
T

v
u
u
t
θ

m=1
X

′

tut

t=1 q
X
t = σ

′

)

θm
t (σ

′

tK m

t σt)






′

where θt = [θ1

t , . . . , θM
t
bounded. In particular, assuming ωt =
p = 2, r = 1 and y = 1n, we will have

, ut = [u1

t , . . . , uM
t ]
θ

]

′

q

, and um

tK m
tut, and using the H¨older’s inequality

t σt . Note that (35) can also be upper-
xy
kq, for

kr ≤ k

x
kpk

y

k

′

θ

tut =

T

t=1 q
X

T

wt

!

 

t=1
X

=

ω

k

k1 ≤

√T

ω

k2 = √T

k

T

 

t=1
X

(wt)2

!

1/2

= √T

T

′

θ

tut

v
u
u
t

t=1
X

Therefore, we can upper bound the Rademacher complexity (35) as follows

ˆRS(

) =

H

√R
nT

Eσ

sup
′′

(

θt∈Ω

(θ)

T

′

θ

tut

)

≤

=

1
n r

R
T

1
n r

R
T

Eσ 


sup
′′

θt∈Ω

Eσ


(

sup
′′

θt∈Ω

t=1 q
X

T

(θ) v
u
u
t

t=1
X

′

θ

tut


trace


Θ′ U
{

})

arg max

trace

= arg max

trace

Θ′ U
}
{

′

Θ

U

Θ

n

n

oo

Θ

q

(θ) q

∈

15

where Θ = [θ1, . . . , θT ]
proved that

∈

RM×T and U = [u1, . . . , uT ]

RM×T . Also, by contradiction, it can be easily

(34)

(35)

(36)

Using the Lagrangian multiplier method, the optimization w.r.t. Θ yields the optimal value for Θ as

Θ∗ =

1
2αT

UPT

RT ×T is a centering matrix as we deﬁned in Sect. 3. Moreover, α = (1/2γ)

a

(1/T )b,

where PT ∈
a = trace

′
UU

, and b = trace

U1T 1T

′

′
U

.

substituting the optimal value of Θ in (36), ﬁnally yields

o

n

o

n

−

p

By applying Jensen’s inequality twice, we obtain

ˆRS(

)

H

≤

√γR
nT 3/4 Eσ

a
np

−

1/2

(1/T )b

o

ˆRS(

)

H

≤

√γR
nT 3/4

Eσ(a

(1/T )b)

−

np

1/2

o

From the deﬁnition, we can see that both a and b depend on variable σ. If we deﬁne um = [σ

as the row vector of matrix U, and d ,
Lemma 1, it can be shown that

trace

M

m=1 K m

1

. . . trace

M

m=1 Km

T

h

nP

o

nP

oi

′

′

1Km
1 σ1, . . . , σ
then with the help of

′

T K m

T σT ]

′

Eσ(a) = d

d + 2

T

M

[trace

t Km

K m
{

t } −

trace

Km

t ◦

K m
]
t }

{

Eσ(b) = d

1T 1T

d + 2

[trace

Km

t Km

t } −

trace

Km

t ◦

Km
t }

]

{

{

′

′

t=1
X
′

m=1
X
T

M

t=1
X

m=1
X

Considering the fact that trace
Km

Kn
x, t, m, it can be shown that

Km

t ◦

{

1

t (x, x)

t } ≥

≤

∀

0, and trace

Km

t K n

{

t } ≥

∀

0

t, m, n, and assuming that

1
T

−

Eσ(a)

Eσ(b)

T M 2n2

1 +

≤

(cid:26)

2
M

+

2
T M n

≤

(cid:27)

3T M 2n2

Combining (37), and (39) and after some algebra operations, we conclude that, if

ˆRub (

) ,

H

s

√3γRM
nT

then ˆR(

)

ˆRub (

H

≤

H

). This last fact in conjunction with (32) conclude the theorem’s statement.

(37)

(38)

(39)

(40)

16

