Optimization, fast and slow: optimally switching between local and Bayesian
optimization

Mark McLeod 1 Michael A. Osborne 1 2 Stephen J. Roberts 1 2

8
1
0
2
 
y
a
M
 
2
2
 
 
]
L
M

.
t
a
t
s
[
 
 
1
v
0
1
6
8
0
.
5
0
8
1
:
v
i
X
r
a

Abstract

We develop the ﬁrst Bayesian Optimization algo-
rithm, BLOSSOM, which selects between mul-
tiple alternative acquisition functions and tradi-
tional local optimization at each step. This is com-
bined with a novel stopping condition based on ex-
pected regret. This pairing allows us to obtain the
best characteristics of both local and Bayesian op-
timization, making efﬁcient use of function evalu-
ations while yielding superior convergence to the
global minimum on a selection of optimization
problems, and also halting optimization once a
principled and intuitive stopping condition has
been fulﬁlled.

1. Introduction

1.1. Bayesian Optimization with Gaussian Processes

In Bayesian Optimization we are concerned with the global
optimization of a black box function. This function is con-
sidered to be expensive to evaluate, and we are therefore
willing to undertake considerable additional computation
in order to achieve efﬁcient use of evaluations. Bayesian
Optimization has been applied to may problems in machine
learning, including hyperparameter tuning (Snoek et al.,
2012; Hernndez-Lobato et al., 2014), sensor set selection
(Garnett et al., 2010) and tuning robot gait parameters (Ca-
landra et al., 2016; Lizotte et al., 2007; Tesch et al., 2011).
A recent review of the ﬁeld is Shahriari et al. (2016).

To achieve this aim at each iteration we ﬁrst train a model of
the objective conditioned on the data observed so far. This
model is usually a Gaussian Process, a kernel-based model
with particularly useful properties. A full introduction to the
Gaussian Process is given by Rasmussen & Williams (2006).
However, the relevant properties to this work are: that all

1Department of Engineering Science, University of Oxford
2Oxford-Man Institute of Quantitative Finance. Correspondence
to: Mark McLeod <markm@robots.ox.ac.uk>.

To appear in Proceedings of the 35 th International Conference on
Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copy-
right 2018 by the author(s).

posteriors produced by the GP are multivariate Gaussian, so
provide both the estimated value and the uncertainty of that
estimate; and that this joint Gaussian property also extends
to derivatives of the function being modelled.

We next deﬁne an acquisition function over the optimization
domain which states how useful we expect an evaluation at
that location to be. This function is optimized to ﬁnd the
location predicted to be most useful. The true objective is
then evaluated at this location. There are a large number
of acquisition functions available. Two that are relevant to
this work are Expected Improvement (Jones et al., 1998), in
which we choose the point with the greatest improvement in
expectation on the best value observed so far, and Predictive
Entropy Search (PES) (Hernndez-Lobato et al., 2014), in
which we choose the location expected to yield the greatest
change in the information content of the distribution over
our belief about the location of the global minimum.

We contribute a novel algorithm, Bayesian and Local Op-
timisation Sample-wise Switching Optimisation Method,
BLOSSOM1 , which combines the desirable properties of
both local and Bayesian optimization by selecting from mul-
tiple acquisition functions at each iteration. We retain the
evaluation-efﬁcient characteristics of Bayesian optimization,
while also obtaining the superior convergence of local opti-
mization. This is combined with a Bayesian stopping crite-
rion allowing optimization to be terminated once a speciﬁed
tolerance on expected regret has been achieved, removing
the need to pre-specify a ﬁxed budget.

1.2. Requirement for a Stopping Criterion

In the majority of work on Bayesian optimization the prob-
lems considered either ﬁx the number of iterations or, less
often, ﬁx a computational budget. While this is clearly desir-
able for averaging over and comparing multiple repetitions
of the same optimization, it is not desirable in practice: the
number of steps to take (or budget to allow) is now an ad-
ditional parameter that must be selected manually. This
choice requires expert knowledge of Bayesian Optimization
to select a number that hopefully will neither be too small,
resulting in easy improvement being neglected, or too large,

1https://github.com/markm541374/gpbo

Optimization, fast and slow: optimally switching between local and Bayesian optimization

costing additional expensive evaluations for minimal gain.
We are therefore motivated to seek an automatic stopping
criterion.

Early stopping has been considered by Lorenz et al. (2015)
in an application of Bayesian Optimization to brain imaging
experiments. They propose and test early stopping based on
the Euclidean distance between consecutive evaluations of
the objective, and based on the probability of improvement
on the incumbent solution. Both of these criteria provide no-
table improvement on a ﬁxed number of iterations. However,
both these criteria are strictly local quantities with no con-
sideration of the GP model at locations removed from the
incumbent solution and proposed next location. The values
must still be selected by the user so that optimization is not
terminated undesirably early by an incremental exploitative
step while regions of the optimization domain remain unex-
plored. We would prefer a stopping criterion which takes
account of the full model of the objective, and which has a
parameter more easily interpreted in terms of the expected
difference between the proposed and true solutions.

1.3. Convergence Properties

(n− v

Optimization has excellent empirical performance in identi-
fying the minimizer of multi-modal functions with only a
small number of evaluations. Bull (2011) has shown that
d ) convergence, where v is the smoothness of the
O
kernel, can be achieved with a modiﬁed version of Expected
Improvement. However the authors note that this is only
applicable for ﬁxed hyperparameters. We are not aware
of any estimates on convergence for PES, which exhibits
better performance empirically . Furthermore, even given a
guarantee of convergence in theory, details of the implemen-
tation of Bayesian Optimization ensure that the ﬁnal regret
is unlikely to fall to less than a few orders of magnitude
below the scale of the objective function. Firstly, we are
not able to exactly maximize the acquisition function. Con-
straints placed on the number of evaluations available to the
inner optimizer limit our ability to select evaluation points
to a high degree of accuracy. This limit is also relevant
to minimizing the posterior for our ﬁnal recommendation.
Secondly, even in a noiseless setting, we must add diagonal
noise to our covariance matrix to resolve numerical errors in
performing the Cholesky decomposition. This reduces the
rate of convergence available to that of optimizing an objec-
tive with the noise level we have now implicitly imposed.
As we cluster more evaluations closely around the mini-
mum, the conditioning of the covariance matrix degrades
further. The potential loss in performance due to diagonal
noise is illustrated in Figure 1. We therefore also desire to
create an optimization routine which does not suffer from
this ineffective exploitation property.

This convergence issue has been addressed by Dhaenens

Figure 1. True immediate regret and conditioning number of the
covariance matrix under optimization of the Hartman-4D function
using the Predictive Entropy Search acquisition function. The
median and quartiles of 16 repetitions of the optimization are
shown. Rather than adding a ﬁxed diagonal component to the
GP kernel matrix to ensure stability we have added the minimum
value which still allows the Cholesky decomposition to succeed, in
decade increments starting from 10−20. The optimization achieves
a good result quickly, but then as jitter is added there is no further
improvement beyond roughly √jitter .

et al. (2015) who switch from Bayesian Optimization to
CMA-ES once a criteria on probability of improvement
has been achieved. This provides excellent convergence
on the objectives tested. However the switching relies on
a heuristic based on a combination of previous values of
the acquisition function and the number of steps without
improvement of the incumbent. We would prefer to make
use of a Bayesian criterion for any changes in behaviour,
to avoid the need for additional parameters which must be
manually chosen by an expert. By using a non-stationary
kernel which replaces the squared exponential form with a
quadratic kernel in regions around local minima, Wabersich
& Toussaint (2016) also aim to achieve superior conver-
gence. However, they do not show the ﬁnal value achieved
by their method in most experiments, and the use of ﬁxed
pre-trained hyperparameter samples makes their implemen-
tation unsuitable for an online setting.

We now develop our algorithm, which achieves superior
convergence and terminates once a well-deﬁned condition
2 we outline the behaviour of the
has been achieved. In
§
algorithm, which selects between multiple acquisition func-
3 how we approximate
tions on each iteration. We detail in
the numerical quantities required, then in
4 provide results
demonstrating the effectiveness of our new method.

§

§

2. The Algorithm

2.1. Separating Global and Local Regret

In Bayesian Optimization we aim to minimize the differ-
ence between the function value at the ﬁnal recommended

Optimization, fast and slow: optimally switching between local and Bayesian optimization

point, ˆy = f (ˆx) and the value at the true global minimizer
y∗ = f (x∗). This is the regret of selecting the current rec-
ommendation as the ﬁnal solution. We shall now separate
this concept into two distinct components which we treat
separately. Let S be some region of note containing the
incumbent solution. We deﬁne yi as the minimum value of
the objective within S and yo as the minimum value outside
S. We can then write

−

Regret = E(ˆy
= E(ˆy
= E(ˆy
−
= Rlocal + Rglobal ,

y∗)
yi) + E(yi
y∗)
yi) + E(max(yi

−

−

(1)

yo, 0))

−

where we have split the full regret into a local component,
due to the difference between our candidate point and the
associated local minimum, and a global component, due to
the difference between the local and global minima. Both
components are non-negative by deﬁnition, and we expect
both to decrease as we learn about the objective. The local
component represents the difference between our incumbent
and the minimum within S. It is reduced by exploitation of
the objective. The global component represents the differ-
ence between the local minimum and the global minimum.
It will be reduced by exploration, and also by exploitation
of other local minima. There is a ﬁnite probability that
Rglobal = 0, corresponding to the probability that the global
minimum is in fact the minimum of the basin containing our
incumbent.

2.2. Multiple Acquisition Functions

To address the issues identiﬁed above, we split our opti-
mization into four distinct modes, intending to use the most
effective at each iteration. The modes are; Random Initial-
ization, Bayesian Optimization, Global Regret Reduction
and Local Optimization.

Random Initialization is, as usual, only required for the
ﬁrst few iterations. Bayesian Optimization using Predictive
Entropy Search is our default acquisition function if no
relevant conditions to change behaviour have been satisﬁed:
PES provides the usual balance between exploration and
exploitation.

In steps when a distinct candidate minimum can be identi-
ﬁed, we switch to the predominantly explorative strategy
of Global Regret Reduction, intended to reduce the global
regret. By making this change, we avoid the inefﬁcient
convergence of exploitation due to poor conditioning in
Gaussian Processes model when used for Bayesian Opti-
mization. To identify a candidate minimum we require the
existence of a region surrounding the minimum of the
posterior with a high probability of being convex.

GP

Once the predicted global regret has fallen below some
target value we use a purely exploitative Local Optimization
algorithm. In this work, we assume that we have access
to noiseless evaluations of the objective functions so that
we can employ a quasi-Newton local optimization routine,
such as BFGS (Nocedal & Wright, 2006), which delivers
super-linear convergence to the local minimum and is free
of the numerical conditioning problems present in Gaussian
Processes. We note that since we are starting our local
optimization very close to the minimum (in fact we choose
to start only when the
model predicts a convex region),
only a small number of steps should be needed to achieve
any required local regret target. We are then able to stop
optimization, having achieved a target total expected regret.

GP

We now give further detail on the two new modes of op-
timization used by BLOSSOM. The methods used share
many expensive computations with PES, so by reusing these
results we do not incur too large an additional overhead.

2.2.1. GLOBAL REGRET REDUCTION

Once a region around the posterior minimum has been iden-
tiﬁed within which local optimizations are likely to converge
to the same location we do not wish to perform exploitation
within this region with Gaussian Processes, as this leads to
numerical conditioning issues and therefore does not use
evaluations efﬁciently. Instead we wish to set this region
aside for pure exploitation under a local search strategy. We
therefore direct our efforts towards reducing the probability
of any other local minima which might take lower values
than our incumbent solution existing, reduction of the global
regret. We use a modiﬁed form of expected improvement
to achieve this, where instead of taking improvement with
respect to the lowest observed objective value we compare
to the estimated value of yi that would be obtained by start-
ing a local optimization from the current incumbent. The
acquisition function used is therefore

αGRR = (E(yi)

µ)Φ

−

(cid:18) E(yi)
σ

−

(cid:19)

µ

+ σφ

(cid:18) E(yi)
σ

−

(cid:19)

µ

(2)
where µ and σ2 are the
posterior mean and variance, yi
is the minimum value within a deﬁned region around the
posterior minimum and Φ and φ are the unit Normal cdf
and pdf respectively.

GP

2.2.2. LOCAL OPTIMIZATION

Once we have a both sufﬁciently high certainty that the
GP
posterior minimum is close to a minimum of the objective,
and that that minimum is in fact global, we wish to exploit
fully.

We use the BFGS algorithm for local optimization. This is
a second order algorithm which updates an estimate of the

Optimization, fast and slow: optimally switching between local and Bayesian optimization

Random Initialization

Train GP Model

Estimate P.ve
Region Radius

P.ve
Deﬁnite
at xmin

yes

no

no

Maximize PES
Acquisition

Maximize
Global Regret
Acquisition

Estimate
Rglobal

Rglobal

Target

≤

yes

Evaluate Objective

Local Exploitation

Figure 2. Flowchart for acquisition function switching behavior.
Following initialization the acquisition function may switch be-
tween PES and Regret Reduction until RGlobal achieves a sufﬁ-
ciently low value. The ﬁnal steps are then under the local exploita-
tion strategy.

Hessian at each step. By using our estimate of the Hessian
available from the GP model as the initial estimate in BFGS,
we hope to achieve convergence with fewer evaluations
of the objective than otherwise. Rather than modifying the
BFGS algorithm to use this estimate, we rescale the problem
so that the expectation of the Hessian is the identity matrix.
With a local function model

f (x) =

xT Hx + xT g + c

(3)

we deﬁne z = Rx where R−T = C, H = CC T the
Cholesky decomposition of H. This gives us a modiﬁed
function

g(z) =

zT z + zT RT g + c

(4)

as required. Once we have started this process we are no
longer performing Bayesian Optimization and can continue
using BFGS until convergence. By selecting an appropriate
stopping condition for local optimization we can ensure
Rlocal falls below any desired target. We have selected a
gradient estimate of less that 10−6 as our stopping condition,
but any other method could be used.

1
2

1
2

2.3. Switching Between Acquisition Functions

We have speciﬁed that we wish to make decisions on the
basis of the existence of a candidate minimum, and on the
value of the global regret. In Figure 2 we show the decision
making process used. However, we have not yet speciﬁed
these criteria exactly. We choose to consider the existence
of a sphere with non-zero radius, centred on the minimum
of the GP posterior mean, xmin, within which the objective

Figure 3. Two steps of BLOSSOM in an example problem. In the
upper plot the GRR acquisition has a maximum at -0.15. However,
since this falls within the convex region around the minimum of the
posterior mean the next function evaluation is taken at the highest
location outside this region. In the lower plot the estimated Global
Regret is sufﬁciently low that no further Bayesian iterations are
required. The next evaluation is the start of a local optimization
from -0.15.

function has a high probability of being convex at all points.
Local optimization routines have excellent performance on
convex functions, so if our model predicts a convex region
surrounding a local minimum with high conﬁdence we no
longer desire our Bayesian Optimization to recommend inef-
ﬁcient exploitative evaluations in this region. We therefore
switch to the Global Regret Reduction acquisition function,
which will place a high weight on exploration.

We have deﬁned the global regret as the difference between
the objective value at the local minimizer in some region
and the true global minimum. We choose to use the positive
deﬁnite sphere to deﬁne this region. We can then obtain
an estimate of Global Regret. If this estimate falls below
our target value we move to the ﬁnal stage of optimization
and use Local Exploitation, otherwise we continue with
the Global Regret Reduction. This process is illustrated in
Figure 3

3. Estimating Required Quantities

We now detail the procedures used to estimate the quantities
required in our switching criteria. We ﬁrst detail our method
of determining a positive deﬁnite region, then provide a
method for estimating the global regret and expected local
minimum value.

3.1. Identifying a Convex Region

Convexity is characterized by the Hessian matrix of the
objective being positive deﬁnite at all points. For a matrix

Optimization, fast and slow: optimally switching between local and Bayesian optimization

H to be positive deﬁnite we require

xT Hx > 0

as Bernoulli distributed with rate parameter θ, since it is a
deterministic binary output function of H. Taking a uniform
prior on θ the posterior expected value of θ is

(5)

for all x. Given a Gaussian Process model of the objective
we would like to construct:

1. A method to determine, using our GP model, the prob-
ability that the Hessian is positive deﬁnite at any point;
and

2. A method to determine, using our GP model, the largest
region centred on the current posterior minimum with
a required probability of being convex at all points
within that region.

3.1.1. CONVEXITY AT A POINT

We make use of the Cholesky decomposition to determine
if a matrix is positive deﬁnite. A unique real solution to
the Cholesky decomposition of a matrix only exists if the
matrix is positive deﬁnite. Implementations of the routine
commonly return an error rather than computing the com-
plex solution. We can make use of this behaviour to pro-
vide a test for positive deﬁniteness returning a binary result:
D(X) : R d(d+1)
where d is the dimensionality of
the problem.

0, 1
}

→ {

2

Since under a Gaussian Process model there will always be
non-zero probability over all real values of inferred quan-
tities we can never have certainty of positive deﬁniteness.
We therefore wish to determine the probability that the Hes-
sian of our objective at some point x is positive deﬁnite (or
if the point is on the boundary of the domain the Hessian
for the remaining dimensions) under our GP model. All
elements of the Hessian have a joint Normal distribution
(cid:0)Hµ(x), Hσ(x)(cid:1) with mean and variance
H
given by the GP posterior at x (only elements of the upper
triangle need to be included in implementation since the
Hessian is symmetric). The probability of positive deﬁnite-
ness at x is then

x, M

∼ N

|

p(cid:0)D(H)

x, M (cid:1) =

|

(cid:90)

(cid:90)

=

p(cid:0)D(H)

|
D(H)p(cid:0)H

H(cid:1)p(cid:0)H

x, M (cid:1)dH

|

x, M (cid:1)dH

|

= lim
N→∞

1
N

N
(cid:88)

i=1

D(hi)

where M is our GP model and the hi have been drawn from
the multivariate normal p(H

|
As our test of positive deﬁniteness at a point we require
all of some n samples of H to be positive deﬁnite. We
x, M )
treat the positive deﬁniteness of samples from p(H

x, M ).

|

E[θ] =

θp(θ)dθ =

(7)

n + 1
n + 2

.

(cid:90) 1

0

Passing our test for positive deﬁniteness at a point, as de-
scribed in Algorithm 1, can therefore be interpreted as de-
termining that E(θ) = 1
n+2 while failure
implies E(θ) < 1

(cid:15) where (cid:15) = 1

−

(cid:15).

−

←

GP model

Algorithm 1 Positive Deﬁnite Test
Input: location x, tolerance (cid:15)
G
Hmean, Hvar
PVEcount
1
2
n
(cid:15) −
for i = 1...n do

←
0

←

←

G.infer Hessian(x)

←
←

h
h∗
if Cholesky(h∗)
PVEcount

draw Gaussian(Hmean, Hvar)
remove boundary elements(h)
= FAIL then
PVEcount + 1

←

end if
end for
p
Return p

←

P V Ecount+1
n+2

1

(cid:15)

≥

−

3.1.2. RADIUS OF A CONVEX REGION

The method above allows us to effectively test a point for
convexity. We now wish to use this function to ﬁnd a convex
region centred around the posterior minimum (again we
exclude any axes on the boundary of the search domain).
We choose to ﬁnd the hypersphere centred at xmin with the
greatest possible radius Rmax. As before we can not obtain
a certain value. Instead we ﬁnd an estimate, ˆRmax, which is
the minimum distance to a non-positive deﬁnite over a ﬁnite
set of test directions u.

We draw unit vectors, u, uniformly at random, by normaliz-
ing draws from the multivariate normal distribution u = v
|v|
where v
(0, Id). For each direction we obtain the
∼ N
positive deﬁnite radius

Ru(u) = arg max

r

P D(ˆx+ru)=1

(6)

by performing a binary linesearch on r down to a resolution
hr. The ﬁrst search is performed with the radius of the
search domain as the upper limit, subsequent directions use
the previous value of R(u) as the upper limit and test the
outer point ﬁrst, moving on to the next direction if this point
returns a convex result. We thus obtain

ˆRmax = min
u∈U

Ru(u)

(8)

(9)

Optimization, fast and slow: optimally switching between local and Bayesian optimization

which is in the minimum distance from ˆx to the edge of the
positive deﬁnite region out of nu =
random directions
as our estimate of the radius of a convex spherical region
centred on xmin.

U

(cid:107)

(cid:107)

Algorithm 2 Positive Deﬁnite Sphere Radius

random unit vector

dist to domain boundary

Input: center xmin, number of directions, nu tolerance (cid:15)
u
←
xedge
ˆR
xmin
for i = 1...nu do

←
← (cid:107)
if D(x + ˆRu) = 0 then

xedge

−

(cid:107)

binarysearch(u, ˆR)

random unit vector

←

ˆR
end if
u
←
end for
Return ˆR

To obtain an estimate of the global regret we must marginal-
ize over the values of the local and global minima, yo and yi.
We assume independence between these quantities, a rea-
sonable assumption since alternative locations for the global
minimizer are usually in separate basins to the incumbent.
The expectation is therefore

(cid:90) (cid:90)

Rglobal =

max(yi

yo, 0) p(yi)p(yo) dyi dyo

yi×yo

−

(10)
If we consider yi to be well approximated by a Normal
i ) then we can perform the integral
distribution
over yi

(µi, σ2

N

(cid:90)

(cid:90) +∞

Rglobal =

max(yi

yo, 0)p(yi) dyi p(yo)dyo

yo

yi=yo

(cid:90)

=

(cid:20)
(µi

yo

(cid:18) µi

yo)Φ

−

−
σi

−
yo

(cid:19)

(cid:18) µi

(cid:19) (cid:21)

yo

+ σiφ

−
σi

p(yo)dyo

N
(cid:88)

≈

j

(cid:32)

µi

(cid:33)

y(j)
o

(µi

−

y(j)
o )Φ

−
σi

+ σiφ

(cid:32)

µi

(cid:33)

y(j)
o

.

−
σi

(11)
Since we do not have an analytic form for p(yo) we are not
able to perform the second integral. We instead approximate
the marginalization over global regret as a summation.

To evaluate this expression we can draw N samples from our
GP model and ﬁnd the value of yo in each case. This cannot
be performed exactly, and instead we must take draws from
the GP posterior over some set of support points Xs. Half of
these are approximately drawn from the distribution of the
global minimum using the method described by McLeod
et al. (2017) (slice sampling over the Expected Improvement

or LCB as suggested by Hennig & Schuler (2012) could
equivalently be used), while half of them are drawn using
rejection sampling with the GP posterior variance as an
unnormalized distribution, to provide additional support in
high variance regions outside the convex region. To evaluate
µi and σi we can use the same set of draws, considering
this time only points within the convex region, to obtain a
sequence of samples of yi which can be used for a maximum
likelihood estimate of the mean and variance of a normal
distribution.

4. Results

We compare BLOSSOM to Expected improvement with
the PI stopping criteria of Lorenz et al. (2015), and to PES
using the acquisition function value as the stopping criterion.
For each algorithm we test multiple values of the stopping
criteria, shown in the legend as appropriate.

4.1. In-Model Objectives

To demonstrate the effect of changing the target value of
global regret we make use of objective drawn from a GP,
since the effect may not be observable using any single ﬁxed
objective. For example, the Branin function has multiple
equal-valued global minima. We will always achieve the
global minimum, and the target regret only alters the number
of steps required to terminate. We show in Figure 4 the mean
regret over objectives drawn from the Mat´ern 5/2 kernel and
note that we have achieved roughly the values we requested
for expected regret.

4.2. Common Benchmark Functions

−

We now give results for several common test objectives for
global optimization, illustrated in Figure 5. In these tests we
have transformed the objectives by y(cid:48) = log(y
y∗ + 1).
This is unrelated to our contributions, and is done as many
of the functions used take the form of a ﬂat plain surrounded
by steep sides many orders of magnitude greater than the
plain. This shape is extremely dissimilar to draws from the
Mat´ern 5
2 kernel used by our GP model, so yields very poor
results. This is an ad-hoc transformation, and it would be
preferable to either use a kernel more appropriate to the
objective or learn a transform of the output space online as
suggested by Snelson et al. (2004).

Neither the number of steps taken nor the regret achieved
is alone a useful metric for the effectiveness of a stopping
condition (few steps with high regret are obviously undesir-
able, but also a small decrease in regret may not be worth
a much increased number of steps), so in Table 1 we have
also shown the mean product of steps and regret, E[nR].
Equal contours of this metric take the form of y = a
x , so
low values indicate improved performance.

Optimization, fast and slow: optimally switching between local and Bayesian optimization

Figure 4. Comparison of methods on Draws from the Mat´ern 5/2 kernel in 2D (left), and illustration of the effect of changing our stopping
parameter on the mean expected regret (right). Mean regret is heavily inﬂuenced by a few large values. Out of 35 runs there are those
targeting 10−2 regret had 6 non-trivial results, targeting 10−4 yielded 4 non-trivial results, targeting 10−6 achieved the global minimum
on every occasion while with no stopping condition only one failure occurred. Although with a limited number of the mean regret is not
particularly close to the target values the decrease with more stringent stopping conditions is clear. We have also included DIRECT (Jones
et al., 1993) and CMA-ES (?) to illustrate the performance on non-Bayesian methods.

electricity demand during 2015 2. As shown in Figure 6 we
are able to obtain the best absolute result while terminating
within a reasonable number of iterations, avoiding taking
unnecessary further evaluations once the optimum has been
achieved.

As is clear from the median curves in Figure 5, and mean
ﬁnal values in Table 1, we have been successful in achieving
both superior local convergence and early stopping. BLOS-
SOM achieves the lowest mean terminal regret, and mean
product of regret and iterations, for ﬁve of the six test objec-
tives. There is considerable disparity between the plotted
and tabulated results for the Hartman 3D and 4D functions.
However, we argue that this is in fact correct behaviour.
These objectives are characterized by having multiple local
minima of differing values. Usually Bayesian optimiza-
tion will identify the correct basin as the global minimum
and our local optimization converges to the correct value,
as is evident in Figure 5. However, with some non-zero
probability the GP will predict the global minimum and
its surrounding positive deﬁnite region in the wrong loca-
tion. If the estimated global regret is less than our target
value when this occurs, the solution is accepted, leading
to exploitation of a local minimum and a high ﬁnal regret.
This occurs on several runs of our algorithm when using a
value of 10−2 as the target global regret. When the lower
target value of 10−4 is used additional exploration steps are
required to reduce the global regret estimate. These provide
additional opportunities to correctly identify the basin of the
global minimum. This leads to the much greater reliability
observed in Table 1 at the cost of an increased number of
objective evaluations.

4.3. GP Hyperparameter Optimization

Optimizing model hyperparameters is a common problem
in machine learning. We use BLOSSSOM to optimize the
input and output scale hyperparameters of a Gaussian Pro-
cess using 6 months of half hourly measurements of UK

Figure 6. Comparison of stopping criteria optimizing the hyperpa-
rameter log-likelihood of a Gaussian Process. Regret is shown with
respect to the best value achieved by any single optimization, the
median and quartiles of 16 repetitions of each method are shown.
Our method consistently obtains several orders of magnitude better
convergence than PES or EI at termination.

5. Conclusion

We have developed BLOSSOM, a Bayesian Optimization
algorithm making use of multiple acquisition functions in
order to separately consider exploration and exploitation by

2www2.nationalgrid.com/UK/Industry-

information/Electricity-transmission-operational-data/Data-
explorer

Optimization, fast and slow: optimally switching between local and Bayesian optimization

Figure 5. Comparison of various stopping methods. All stopping criteria allow an average saving compared to continuing to run
optimization for many steps past convergence, but our method reliably achieves a low value before stopping. The median and quartiles of
regret are shown. Fraction of optimizations still running after n steps are shown in thin dashed lines.

Objective

BLOSSOM 10−2 BLOSSOM 10−4

PES 10−8

PES 10−10

EI 10−10

EI 10−12

Branin
Camel 3hump
Camel 6hump
Hartmann 3D
Hartmann 4D
Hartmann 6D

Branin
Camel 3hump
Camel 6hump
Hartmann 3D
Hartmann 4D
Hartmann 6D

Branin
Camel 3hump
Camel 6hump
Hartmann 3D
Hartmann 4D
Hartmann 6D

3.32e-14
2.26e-13
2.28e-14
0.107
0.0534
0.00371

74.6
39.6
51.7
67.8
98.5
199

2.39e-12
8.56e-12
1.14e-12
5.98
6.93
1.11

Regret

1.09e-07
4.14e-13
9.41e-11
2.16e-07
0.0534
0.196
Steps

59.6
64.9
49.8
62.8
72.3
196

×

5.69e-06
1.18e-11
4.84e-09
1.35e-05
4.36
37.6

Steps

Regret

5.2e-07
1.79e-13
7.95e-13
1.14e-13
5.21e-14
0.0638

99.8
40.9
139
82.6
122
230

5.15e-05
7.02e-12
2.21e-10
9.41e-12
5.89e-12
19.1

2.9e-09
2.44e-14
1.62e-11
2.16e-07
0.0133
0.157

0.00221
2.12e-12
2.32e-05
6.72e-05
6.06e-05
0.0229

0.00125
1.57e-12
2.35e-05
0.000116
6.44e-06
0.0669

80.4
132
78.6
89.4
134
281

77.4
66.8
61.2
65.1
111
181

81.9
135
64.7
71.1
130
190

2.22e-07
2.73e-12
1.33e-09
1.93e-05
1.95
46.2

0.167
1.07e-10
0.00138
0.00422
0.00527
5.28

0.103
2.31e-10
0.00157
0.00746
0.000853
17.1

Table 1. Performance of selected stopping methods on various common objective functions. For two stopping criterion values for each
algorithm we show the ﬁnal regret, number of steps taken and step-regret product. Our methods have achieved the best regret and
step-regret product on ﬁve of the six objectives used.

Optimization, fast and slow: optimally switching between local and Bayesian optimization

actively selecting between Bayesian and local optimization.
This separation allows us to avoid the poor local conver-
gence of Gaussian Process methods. We are further able to
halt optimization once a speciﬁed value of global regret has
been achieved. This has the potential to save considerable
computation in comparison to manual speciﬁcation of the
number of iterations to perform. We have shown that BLOS-
SOM is able to achieve an improvement in the ﬁnal result of
several orders of magnitude compared to existing methods.

References

Bull, Adam D. Convergence rates of efﬁcient global
Journal of Machine Learn-
optimization algorithms.
ing Research, 12(Oct):2879–2904, 2011. URL http:
//www.jmlr.org/papers/v12/bull11a.html.

Calandra, Roberto, Seyfarth, Andr, Peters, Jan, and Deisen-
roth, Marc Peter. Bayesian optimization for learn-
ing gaits under uncertainty: An experimental compar-
ison on a dynamic bipedal walker. Annals of Mathe-
matics and Artiﬁcial Intelligence, 76(1-2):5–23, Febru-
ary 2016. URL http://link.springer.com/
10.1007/s10472-015-9463-9.

Dhaenens, Clarisse, Jourdan, Laetitia, and Marmion,
Learning and Intelligent
Marie-Elonore (eds.).
Optimization, volume 8994 of Lecture Notes in
Computer Science.
Springer International Publish-
ISBN 978-3-319-19083-9 978-
ing, Cham, 2015.
10.1007/978-3-319-19084-6.
3-319-19084-6.
URL https://link.springer.com/chapter/
10.1007/978-3-319-19084-6 29.

doi:

In Proceedings of

Garnett, Roman, Osborne, Michael A., and Roberts,
Bayesian optimization for sensor set
Stephen J.
the 9th ACM/IEEE
selection.
International Conference on Information Process-
ing in Sensor Networks, pp. 209–219. ACM, 2010.
http://www.robots.ox.ac.uk/˜mosb/
URL
public/pdf/1242/ipsn673-garnett.pdf.

Hennig, Phillipp and Schuler, Christian J.

Entropy
Search for Information-Efﬁcient Global Optimization.
Machine Learning Research, 13(1999):1809–1837, 2012.
http://jmlr.csail.mit.edu/papers/
URL
volume13/hennig12a/hennig12a.pdf.

Hernndez-Lobato, Jos Miguel, Hoffman, Matthew W,
and Ghahramani, Zoubin.
Predictive Entropy
Search for Efﬁcient Global Optimization of Black-
Advances in Neural Information
box Functions.
Processing Systems 28, pp. 1–9, 2014.
URL
https://jmhldotorg.files.wordpress.com/
2014/10/pes-final.pdf.

Jones, D R, Law, Computer, and Law, Computer. Lips-
chitzian Optimization Without the Lipschitz Constant. 79
(1), 1993.

Jones, Donald R, Schonlau, Matthias, and William, J.
Efﬁcient Global Optimization of Expensive Black-
Box Functions. Journal of Global Optimization, 13:
455–492, 1998. URL http://www.ressources-
actuarielles.net/EXT/ISFA/1226.nsf/
0/f84f7ac703bf5862c12576d8002f5259/
$FILE/Jones98.pdf.

Lizotte, Daniel J., Wang, Tao, Bowling, Michael H.,
Automatic Gait Opti-
and Schuurmans, Dale.
In
mization with Gaussian Process Regression.
IJCAI, volume 7, pp. 944–949, 2007. URL http:
//papersdb.cs.ualberta.ca/˜papersdb/
uploaded files/352/additional IJCAI07-
152.pdf.

Lorenz, Romy, Monti, Ricardo P., Violante, Ines R.,
Faisal, Aldo A., Anagnostopoulos, Christoforos, Leech,
Robert, and Montana, Giovanni.
Stopping crite-
ria for boosting automatic experimental design using
arXiv
real-time fMRI with Bayesian optimization.
preprint arXiv:1511.07827, 2015. URL https://
arxiv.org/abs/1511.07827.

McLeod, Mark, Osborne, Michael A., and Roberts,
Practical Bayesian Optimization for
arXiv:1703.04335 [stat],
URL http://arxiv.org/abs/

Stephen J.
Variable Cost Objectives.
March 2017.
1703.04335. arXiv: 1703.04335.

Nocedal, Jorge and Wright, Stephen J. Numerical Opti-
mization. Springer, New York, NY, USA, second edi-
tion, 2006. URL http://www.springer.com/gb/
book/9780387303031.

Rasmussen, Carl Edward and Williams, Christopher K. I.
Gaussian processes for machine learning.
Adap-
tive computation and machine learning. MIT Press,
Cambridge, Mass, 2006.
ISBN 978-0-262-18253-
9. URL http://www.gaussianprocess.org/
gpml/chapters/RW.pdf. OCLC: ocm61285753.

Shahriari, B., Swersky, K., Wang, Z., Adams, R. P., and
Freitas, N. de. Taking the Human Out of the Loop: A
Review of Bayesian Optimization. Proceedings of the
IEEE, 104(1):148–175, January 2016. URL https://
www.cs.ox.ac.uk/people/nando.defreitas/
publications/BayesOptLoop.pdf.

Snelson, Edward, Ghahramani, Zoubin, and Rasmussen,
In Advances
Carl E. Warped gaussian processes.
in neural information processing systems, pp. 337–
344, 2004. URL http://www.gatsby.ucl.ac.uk/
˜snelson/gpwarp.pdf.

Optimization, fast and slow: optimally switching between local and Bayesian optimization

Snoek, Jasper, Larochelle, Hugo, and Adams, Ryan P.
Practical bayesian optimization of machine learn-
In Advances in neural information
ing algorithms.
processing systems, pp. 2951–2959, 2012.
URL
https://papers.nips.cc/paper/4522-
practical-bayesian-optimization-of-
machine-learning-algorithms.pdf.

Tesch, Matthew, Schneider, Jeff, and Choset, Howie. Us-
ing response surfaces and expected improvement to
IEEE Interna-
optimize snake robot gait parameters.
tional Conference on Intelligent Robots and Systems, pp.
1069–1074, 2011. URL https://www.cs.cmu.edu/
˜schneide/IROS11snake.pdf.

Wabersich, Kim Peter and Toussaint, Marc. Advanc-
ing Bayesian Optimization: The Mixed-Global-Local
(MGL) Kernel and Length-Scale Cool Down. arXiv
preprint arXiv:1612.03117, 2016. URL https://
arxiv.org/abs/1612.03117.

