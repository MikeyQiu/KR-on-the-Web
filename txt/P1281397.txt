Lightweight Mask R-CNN for Long-Range Wireless
Power Transfer Systems

Hao Li∗, Aozhou Wu∗, Wen Fang∗, Qingqing Zhang∗, Mingqing Liu∗, Qingwen Liu∗, Wei Chen†
∗Dept. of Computer Science and Technology, Tongji University, Shanghai, China,
†Dept. of Electronic Engineering, Tsinghua University, Beijing, China.
Email: {lihao1101, 1732968, wen.fang, anne, clare, qliu}@tongji.edu.cn,
wchen@tsinghua.edu.cn

targets, the RBC transmitter can charge multiple electronic
devices simultaneously.

0
2
0
2
 
r
p
A
 
9
1
 
 
]

V
C
.
s
c
[
 
 
1
v
1
6
7
8
0
.
4
0
0
2
:
v
i
X
r
a

Abstract—Resonant Beam Charging (RBC) is a wireless charg-
ing technology which supports multi-watt power transfer over
meter-level distance. The features of safety, mobility and simulta-
neous charging capability enable RBC to charge multiple mobile
devices safely at the same time. To detect the devices that need
to be charged, a Mask R-CNN based dection model is proposed
in previous work. However, considering the constraints of the
RBC system, it’s not easy to apply Mask R-CNN in lightweight
hardware-embedded devices because of its heavy model and huge
computation. Thus, we propose a machine learning detection
approach which provides a lighter and faster model based on
traditional Mask R-CNN. The proposed approach makes the
object detection much easier to be transplanted on mobile devices
and reduce the burden of hardware computation. By adjusting
the structure of the backbone and the head part of Mask R-CNN,
we reduce the average detection time from 1.02s per image to
0.6132s, and reduce the model size from 245MB to 47.1MB. The
improved model is much more suitable for the application in the
RBC system.

Index Terms—Resonate beam charging, Mask R-CNN, Mo-

bileNet, Object detection, IoT

I. INTRODUCTION

The rapid development of IoT and machine learning tech-
nology puts higher demands on high bit rate,
low power
consumption and big quantity of data [1]. Meanwhile, ﬁfth-
generation (5G) achieves breakthroughs in high speed, large
capacity and low latency. However, with the growing con-
tradiction between IoT development and power supply bot-
tleneck, a signiﬁcant increasement in the terminal endurance
becomes a new requirement for sixth-generation (6G). Thus,
wireless power transfer technology (WPT) may be a new di-
mension for 6G development [2] [3]. Resonant beam charging
(RBC) system is a WPT which provides meter-level distance,
watt-level power wireless charging services for mobile devices
like smartphones [4]. The RBC system consists of the spatially
separated transmitter and receiver. The transmitter transmits
invisible beam to the receiver, which can then convert the beam
power into electrical power for charging.

Before transmitting beam power to a speciﬁc receiver, the
transmitter should at ﬁrst scan the whole area and determine
the position of the receiver to be charged. Therefore, object
detection method is needed to assist the transmitter to detect
the receiver. Fig. 1 shows an indoor application scenario of
the RBC system. After scanning and determining the charging

Fig. 1. An indoor application scenario of the RBC system.

In [6], the application of Mask R-CNN is applied to assist
the RBC system in detecting the mobile devices to be charged
the ResNet-50 based Mask R-CNN is not
[5]. However,
suitable for lightweight hardware-embedded devices because
of its large parameter quantity and computation.

To reduce the hardware cost and the performance loss of
object detection on embedded devices, the backbone of Mask
R-CNN is changed from ResNet-50 to MobileNet V1 [11] [7].
Meanwhile, the ideas of Light-Head R-CNN are combined in
the head part [8]. Since smartphones are the most widely used
mobile devices and charging smartphones is the most common
application of the RBC system, we choose smartphone as the
detection object. The smartphone dataset built in [6] is used
in the experiments.

We perform comparison experiments on three frameworks:

• ResNet-50 based Mask R-CNN.
• MobileNet V1 based Mask R-CNN, in which we replace
the backbone of Mask R-CNN from ResNet-50 to Mo-
bileNet V1.

• MobileNet V1 based Mask R-CNN with light head, in
which we replace the backbone with MobileNet V1 as
well as adjust the head part based on Mask R-CNN.

The listed three frameworks are tested on the smartphone
dataset. Our proposed approach shows faster detection speed
and smaller model size, although at a compromise of slight
accuracy reduce. After the adjustment, the average detection

TABLE I
COMPUTATION AND PARAMETER QUANTITY OF RESNET-50 AND MOBILENET V1

Layer Name

Conv 1
Conv 2
Conv 3
Conv 4
Conv 5
Total

ResNet-50

MobileNetV1

Computation
1.18, 816, 768
672, 358, 400
953, 344, 000
1, 389, 273, 088
732, 720, 128
3.867GFLOPs

Params
9,664
218,624
1,226,752
7,118,848
14,987,264
23.561M

Computation
41,746,432
83,894,272
80,325,504
288,712,704
77,923,328
0.573GFLOPs

Params
3,648
28,096
105,344
1,490,688
1,601,024
3.229M

time is reduced from 1.02s per image to 0.61s, and the model
size is reduced by about 80%.

greatly reduces the memory size and improve the detection
speed with slightly sacriﬁcing accuracy.

In section II of this paper, we will elaborate the adjustments
of the Mask R-CNN framework. Then,
the experimental
analysis based on the smartphone dataset will be introduced.
In section IV, we will show the improvement of charging
efﬁciency and the trafﬁc saving that the lightweight model
brings to the RBC system. Finally, we will give conclusions
and discuss open issues for further researches.

II. LIGHTWEIGHT ADJUSTMENT OF MASK R-CNN

In this section, we give the implementation details for

building the lightweight object detection model.

Object detection frameworks based on convolutional neutral
network (CNN) have two branches, one-stage framework and
two-stage framework. For two-stage frameworks, the features
of image are extracted through the backbone, and then a
region proposal networks (RPN) layer is followed to generate
candidate regions. Finally, each proposal generated by RPN is
classiﬁed and reﬁned in the head part. Typical representatives
of two-stage framework such as Faster R-CNN and Mask R-
CNN, have higher accuracy but slower speed compared to
one-stage framework [9] [5]. For one-stage framework, the
RPN layer is not required but directly pinpoints and classiﬁes
objects of interest appearing in an image. The ﬁnal results
can be obtained after one detection, so the detection speed
is faster. Typical representatives of one-stage framework are
YOLO, SSD, etc [17] [18]. Although the detection speed of
the one-stage framework is high, the performance is not yet
comparable with two-stage framework.

As two-stage frameworks are designed for multiple classes
detection tasks (e.g., the COCO dataset contains 80 classes), a
large backbone is used to extract ﬁner features and a relatively
heavier head part is used to classify objects. However, in
the RBC system, where a small quantity of mobile devices
need to be identiﬁed, using a backbone like ResNet-50 to
extract features is a bit overweight. Moreover, for lightweight
hardware devices such as RBC transmitters, saving memory
and improving detection speed are more meaningful for saving
hardware costs and improving user experience.

As shown in Fig. 2, we make a lightweight improvement
on the backbone and head parts based on Mask R-CNN, the
backbone of Mask R-CNN is replaced with MobileNet V1,
and the head part is changed to a lighter one. The adjustment

A. Adjustment in Body Architecture

For two-stage frameworks like Faster R-CNN and Mask
R-CNN, the method of extracting the feature map directly
determines the detection speed and the model scale. The idea
of MobileNet V1 that applying depthwise seperable convo-
lution to reduce network capacity, is borrowed to reduce the
parameter quantity and backbone computation [14]. According
to [7], MobileNet uses 3 × 3 depthwise separable convolutions
which cost 8 ∼ 9 times less computation than standard
convolutions at a compromise of little accuracy reduction.

Table I shows the difference of the ﬂoating point operations
(FLOPs) and the quantities of parameters between ResNet-
50 and MobileNet V1. Since MobileNet V1 uses depthwise
seperable convolution to replace standard convolution, and the
number of channels per convolutional layer is smaller than
that of ResNet-50, both quantity of parameters and FLOPs of
MobileNet V1 are much smaller than that of ResNet-50.

TABLE II
ARCHITECTURE OF MOBILENET V1 WHICH IS PROPOSED IN [7]

Layer Name
Origin Picutre

Conv 1

Conv 2

Conv 3

Conv 4

Conv 5

Input
224*224*3
112*112*32
112*112*64
56*56*128
56*56*128
28*28*256
28*28*256
14*14*512
14*14*512
7*7*1024
7*7*1024

Block Operator
Conv2d
DepthWiseConv
DepthwiseConv
DepthwiseConv
DepthwiseConv
DepthwiseConv
DepthwiseConv
DepthwiseConv
DepthwiseConv
DepthwiseConv
-

c
32
64
128
128
256
256
512
512
1024
1024
-

n
1
1
1
1
1
1
1
5
1
1
-

s
2
1
2
1
2
1
2
1
2
1
-

The architecture used in experiments is shown in Table II,
which is proposed in [7]. Each line describes a sequence of one
or more identical (modulo stride) layers, which will repeat n
times. All layers in the same sequence have the same number
c of output channels. The ﬁrst layer of each sequence has a
stride s and the others use stride 1. All spatial convolutions
use 3×3 kernals. Layers Conv1 ∼ 5 are used in RPN network
to get reigon of interests (RoIs) [12].

B. Adjustment in Head Architecture

Classic two-stage framworks such as Faster R-CNN and
Mask R-CNN, use two heavy fully connected (FC) layers

Fig. 2. Overview of the lightweight Mask R-CNN.

for proposal prediction [15]. Moreover, each RoI needs to
be calculated separately, which is time-costing. In addition,
the number of feature channels after RoI pooling is large,
which makes the two FC layers consume a lot of memory
and potentially affects the computational speed.

To reduce the computation and the memory consumption
in the head architecture, we borrow the idea of Light-Head
R-CNN [8]. Light-Head R-CNN is presented on the basis
of R-FCN, which compresses the after-pooling feature maps
of R-FCN to 10 × P × P (P is the followed pooling size)
[10]. The process is equivalent to pressing more than 3900
channels to 490 channels when P equals 7, and a FC layer is
added to output the ﬁnal classiﬁcation result. In this paper, we
generate feature maps with small number of channels (2×7×7
is used in the experiments) and only keep one single FC
layer after the pooling layer. This adjustment greatly reduces
in the head part and the memory
the computational cost
requirements of the detection system. In addition, we reserve
the mask branch proposed in Mask R-CNN to get higher
precision accuracy.

III. EXPERIMENTS

In this section, we introduce the detailed training process
of three different networks on the smartphone dataset. In the
subsection B, the experimental comparison results are shown
to demonstrate that the modiﬁed model is faster and lighter.

A. Model Training

We train and evaluate the model with Tensorﬂow and
Open Source TensorFlow Object Detection API. Since the
smartphone dataset is small, pretrained network parameters
are needed for training. We train the MobileNet V1 based
Mask R-CNN with the COCO 2017 dataset [13], and load the
pre-trained model on the imagenet to assist in training [16].
The NVIDIA GeForce GTX 1070 6G graphics card is used
for training. Fig. 3 shows the detection sample on the trained
model. The model size of the ResNet-50 based Mask R-CNN
is 245M , while the new one with MobileNet V1 is 93M ,
which reﬂects the adjusted model is smaller and easier to be
transplanted on embedded devices.

Fig. 3. Detection sample on the MobileNetV1 based Mask R-CNN framework

Then, we adjust the head architecture and load the pre-
trained model with excluding irrelevant layers. The smart-
phone dataset built in [6] is used to train our model. The
entire dataset contains 3,200 images taken from classrooms,
bedrooms, laboratories and other indoor scenarios. The entire
dataset is divided into three parts, including training set with
1600 images, development set with 800 images, and test set
with 800 images.

The training process is divided into three steps. First, train
the mask branch and the two branches in the head part because
they are completely randomly initialized. Second, ﬁne-tune
layers from layer Conv4 and up. Third, all layers are ﬁne-
tuned with a smaller value of learning rate. At the end of
each epoch during the training process, the ﬁtting results are
observed to prevent over-ﬁtting and under-ﬁtting. A detection
sample on the smartphone test set is shown in Fig. 4.

B. Experimental Analysis

We test the detection speed (average detection time of 500
pictures), model sizes and mean average precisions (mAPs) of
the three frameworks on the smartphone test set to evaluate the
performance of our model. Table III shows the experimental

Fig. 4. Smartphone detection sample

results of the three different frameworks. It can be seen that
the framework with MobileNet V1 and light head reduces the
detection time by about 40% and reduces the model size by
about 80% respectively compared with the ResNet-50 based
Mask R-CNN.

TABLE III
COMPARISON AMONG THREE FRAMEWORKS BASED ON THE SMARTPHONE
DATASETS

Backbone

Head

ResNet-50
MobileNet V1
MobileNet V1

normal
normal
light head

Speed Memory Size mAP
(%)
(MB)
(s/img)
57.66
245
1.02
38.23
91.1
0.6697
47.1
0.6132
36.55

In the experiments, average precision (AP) is used to
evaluate the accuracy of our model. AP of the model is tested
at 10 IoU thresholds (from 0.50 to 0.95 step by 0.05) and
mAP is shown in Fig. 5. It is shown that AP is relatively
high when IoU is around 0.55, and AP decreases linearly as
the IoU increases. Although mAP of the lightweight model is
lower than that of the other two frameworks, a slight decrease
in accuracy with obvious improvement on detection speed and
memory size is acceptable.

To ensure safety under various complex circumstances,
detection precision must be high enough in the applications
such as auto driving. However, common application scenarios
of the RBC system are indoor places. In these indoor scenarios,
it is easy to achieve higher accuracy after the detection model
being optimized. In addition, the RBC trainsmitter attempts to
communicate with the mobile devices before charging. Even
if the target is identiﬁed incorrectly, the RBC transmitter can
perform charging operations by scanning all areas. It means
that false detection will not cause any harm to the human
body. Therefore, the lightweight object detection framework
proposed in this paper is suitable for the RBC system which
do not require strict accuracy. Moreover,
it can be better
applied to the RBC system to assist in object detection with
the computation and time costs cut.

Fig. 5. Average precision vs. Intersection over union.

IV. PERFORMANCE ANALYSIS

Applying object detection to the RBC system can effectively
improve its working efﬁciency. It has been introduced in
[6] that object detection methods can effectively help RBC
transmitter to detect IoT devices. To apply object detection
methods to the RBC system, the key is whether the embedded
device can accommodate and run a large network. There are
three factors limit the application of deep learning methods in
embedded devices:

• The model parameters are large, occupying large memory.
• The computational cost is high.
• The corresponding software implementation of the em-

bedded system is complex.

The model proposed in this paper alleviates the ﬁrst two
problems to a certain extent. For the third problem, there are
some deep learning frameworks for embedded devices, such
as DarkNet, Tiny-DNN, NCNN, MXNet, etc [19].

There are three options for combining the RBC systems

with object detection methods:

• The image is preprocessed locally,

then uploaded to
the server for deep processing, and the ﬁnal result is
processed locally.

• Only the image collection is done locally, all processes
are completed on the server, and then the device receives
the result.

• Completely locally processed.

For complex deep neural networks such as ResNet-50
based Mask R-CNN, because of its huge computation and
model size, it is not suitable for processing captured images
locally. Only the ﬁrst two solutions can be used to assist with
processing. However, the lightweight framework proposed in
this paper has only one-ﬁfth the size of the original model,
which greatly reduces the burden of hardware devices. It
is feasible for RBC transmitters to process images locally
when using the lightweight object detection framwork. The

following subsections introduce the improvement of charging
efﬁciency and trafﬁc saving with the lightweight model.

A. Detection Speed Increment

Compared with the object detection processed on the cloud
server, completely processed locally has obvious advantages
in saving detection time. As shown in Fig. 6, we suppose the
upload speed from the RBC transmitter to the cloud server
is Su, the download speed from the cloud server to the RBC
transmitter is Sd and the network delay is Tdelay. The time
for object detection model to process one image is Tdetect
and the size of each image is Kimage. The total time for
processing one picture locally is Tlocal and the total time for
processing one picture on cloud is Tcloud. For Tlocal, image
capture and object detection are done locally. After detection,
the RBC trainsmitter send the collected information Kinf o to
the cloud server for veriﬁcation, and ﬁnally perform charge
action depends on the veriﬁcation result Kresult2. For Tcloud,
because its object detection is done on cloud, the captured
image needs to be uploaded to the cloud server for detection,
and the cloud server returns the detection result Kresult1. The
rest action is the same as Tlocal. Then Tlocal and Tcloud can
be depicted as:

Tlocal = Tdetect +

Tcloud = Tdetect +

+ 4Tdelay

Kinf o
Su

+

Kresult2
Sd

+ 2Tdelay

Kimage + Kinf o
Su

+

Kresult1 + Kresult2
Sd

(1)

(2)

We assume that ResNet-50 based Mask R-CNN is run on
cloud, and the lightweight model proposed in this paper is
run locally. Each image is 0.1MB. Ignoring Tdelay, Kresult1,
Kinf o and Kresult2, the upload and download speed are all
1MB/s. The speed in Table II is used to substitute Tdetect, and
then we get Tlocal/Tcloud = 0.5475. That means processing
images locally can reduce the process time by nearly half
compared with that on the cloud server.

B. Trafﬁc Saving

In the RBC system, adopting a local-running lightweight
object detection model can save trafﬁc. When object detec-
tion is performed locally, the RBC transmitter processes the
collected picture itself and identify the devices that may need
to be charged. Then the RBC transmitter send the collected
information Kinf o to the cloud for veriﬁcation. Finally, based
on the Kresult2 returned from cloud , the transmitters deter-
mines whether to charge the devices or not. Thus, the trafﬁc
cost Clocal can be depicted as:

Clocal = Kinf o + Kresult2

(3)

If object detection is performed on cloud, the RBC trains-
mitter needs to upload the collected image to get the processed
information Kresult1. Then, the RBC transmitter collect the
device ID of RBC receiver depending on Kresult1. The
remaining steps are the same as that in the local process, the
RBC trainsmitter determines whether to charge the receiver or

Fig. 6. An application scenario of the RBC system

not according to the veriﬁcation result from the cloud server.
In that way, the trafﬁc cost per-detection on cloud Ccloud can
be depicted as:

Ccloud = Kimage + Kresult1 + Kresult2 + Kinf o

(4)

In practical applications, Kresult1 and Kinf o consume
much less trafﬁc compared to Kimage. It can be seen from (3)
and (4) that, for each time the detection is performed, locally
processed can save trafﬁc of more than one image compared
to processed on cloud. Therefore, our proposed approach can
greatly reduce the trafﬁc cost in real applications.

V. CONCLUSION

In this paper, we present a lightweight two-stage object
detection approach, which is easier to be transplanted on
embedded devices to improve charging efﬁciency of the RBC
system. We train the new model on a smartphone dataset. Ex-
perimental results show that the new model is much faster and
lighter than the ResNet-50 based Mask R-CNN. Finally, we
discuss the improvement in detection efﬁciency and trafﬁc cost
that the lightweight detection model bring to the RBC system.
The improvement and application of the model proposed in
this paper can be further studied from the following points:

• The types of mobile devices and the applications identi-
ﬁed currently are still relatively limited. We hope to iden-
tify more mobile devices in more application scenarios in
the future.

• Many lightweight object detection methods can achieve
fast detection speed and high accuracy nowadays. In
future researches, we will study the combination of other
lightweight frameworks with the RBC system.

• The current RBC applications are still based on theoret-
ical researches. Object detection methods can be tested
on real embedded devices for further research.

REFERENCES

[1] T. Wang, S. Wang, and Z. Zhou, “Machine learning for 5G and beyond:
From model-based to data-driven mobile wireless networks,” China Com-
munications, vol. 16, no. 1, pp. 165-175, Jan. 2019.

[2] K. David and H. Berndt, “6G vision and requirements: Is there any need
for beyond 5G?” IEEE Veh. Technol. Mag., vol. 13, no. 3, pp. 7280, July
2018.

[3] K. B. Letaief, W. Chen, Y. Shi, J. Zhang, Y. J. A. Zhang, “The roadmap to
6G – AI empowered wireless networks,” arXiv preprint arXiv:1904.11686,
2019.

[4] Q. Liu, J. Wu, P. Xia, S. Zhao, W. Chen, Y. Yang, and L. Hanzo,
“Charging unplugged: Will distributed laser charging for mobile wireless
power transfer work?” IEEE Vehcular Technology Magzine, vol. 11, no.
4, pp. 36-45, Nov. 2016.

[5] K. He, G. Gkioxari, P. Doll´ar, and R. Girshick, “Mask R-CNN,” in 2017
IEEE International Conference on Computer Vision (ICCV), Dec. 2017,
pp. 2980-2988.

[6] A. Wu, Q. Zhang, W. Fang, H. Deng, S. Jiang, Q. Liu, and P. Xia, “Mask
R-CNN Based Object Detection for Intelligent Wireless Power Transfer,”
in 2018 IEEE Globecom Workshops (GC Wkshps). IEEE, Dec.2018, pp.
1-5.

[7] A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang, T. Weyand,
M. Andreetto, and H. Adam, “Mobilenets: Efcient convolutional neural
networks for mobile vision applications,” arXiv preprint arXiv:1704.04861,
2017.

[8] Z. Li, C. Peng, G. Yu, X. Zhang, Y. Deng, and J. Sun, “Light-
head R-CNN: In defense of two-stage object detector,” arXiv preprint
arXiv:1711.07264, 2017.

[9] S. Ren, K. He, R. Girshick, and J. Sun, “Faster R-CNN: Towards real-time
object detection with region proposal networks,” in Advances in Neural
Information Processing Systems, 2015, pp. 91-99.

[10] Y. Li, K. He, and J. Sun, “R-FCN: Object detection via region-
based fully convolutional networks,” in Advances in Neural Information
Processing Systems, 2016, pp. 379387.

[11] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, 2016, pp.770-778.

[12] R. Girshick, “Fast R-CNN,” in Proceedings of the IEEE International

Conference on Computer Vision, 2015, pp. 14401448.

[13] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P.
Doll´ar, and C. L. Zitnick, “Microsoft COCO: Common objects in context,”
in European Conference on Computer Vision, 2014, pp.740-755.

[14] F. Chollet, “Xception: Deep learning with depthwise separable convo-
lutions,” in Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, July 2017, pp. 1251-1258.

[15] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille,
“Semantic image segmentation with deep convolutional nets and fully
connected crfs,” arXiv preprint arXiv:1412.7062, 2014.

[16] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z.
Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and F. Li,
“Imagenet large scale visual recognition challenge,” International Journal
of Computer Vision, vol. 115, no. 3, pp. 211252, Dec. 2015.

[17] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, “You only look
once: Uniﬁed, real-time object detection,” in Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition, 2016, pp. 779-
788.

[18] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.-Y. Fu, and A.
C. Berg, “SSD: Single shot multibox detector,” in European Conference
on Computer Vision, Sep. 2016, pp. 21-37.

[19] T. Chen, M. Li, Y. Li, M. Lin, N. Wang, M. Wang, T. Xiao, B.
Xu, C. Zhang, and Z. Zhang, “MXNet: A ﬂexible and efﬁcient machine
learning library for heterogeneous distributed systems,” arXiv preprint
arXiv:1512.01274, 2015.

