Yes, but Did It Work?: Evaluating Variational Inference

8
1
0
2
 
l
u
J
 
7
 
 
]
L
M

.
t
a
t
s
[
 
 
2
v
8
3
5
2
0
.
2
0
8
1
:
v
i
X
r
a

Yuling Yao 1 Aki Vehtari 2 Daniel Simpson 3 Andrew Gelman 1

Abstract
While it’s always possible to compute a varia-
tional approximation to a posterior distribution,
it can be difﬁcult to discover problems with this
approximation. We propose two diagnostic al-
gorithms to alleviate this problem. The Pareto-
smoothed importance sampling (PSIS) diagnostic
gives a goodness of ﬁt measurement for joint dis-
tributions, while simultaneously improving the
error in the estimate. The variational simulation-
based calibration (VSBC) assesses the average
performance of point estimates.

1. Introduction

Variational Inference (VI), including a large family of pos-
terior approximation methods like stochastic VI (Hoffman
et al. 2013), black-box VI (Ranganath et al. 2014), automatic
differentiation VI (ADVI, Kucukelbir et al. 2017), and many
other variants, has emerged as a widely-used method for
scalable Bayesian inference. These methods come with few
theoretical guarantees and it’s difﬁcult to assess how well
the computed variational posterior approximates the true
posterior.

Instead of computing expectations or sampling draws from
the posterior p(θ | y), variational inference ﬁxes a fam-
ily of approximate densities Q, and ﬁnds the member q∗
minimizing the Kullback-Leibler (KL) divergence to the
true posterior: KL (q(θ), p(θ | y)) . This is equivalent to
maximizing the evidence lower bound (ELBO):

ELBO(q) =

(log p(θ, y) − log q(θ)) q(θ)dθ.

(1)

(cid:90)

Θ

There are many situations where the VI approximation is
ﬂawed. This can be due to the slow convergence of the

1Department of Statistics, Columbia University, NY, USA
2Helsinki Institute for Information Technology, Department of
Computer Science, Aalto University, Finland 3Department of Sta-
tistical Sciences, University of Toronto, Canada. Correspondence
to: Yuling Yao <yy2618@columbia.edu>.

Proceedings of the 35 th International Conference on Machine
Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018
by the author(s).

optimization problem, the inability of the approximation
family to capture the true posterior, the asymmetry of the
true distribution, the fact that the direction of the KL diver-
gence under-penalizes approximation with too-light tails, or
all these reasons. We need a diagnostic algorithm to test
whether the VI approximation is useful.

There are two levels of diagnostics for variational inference.
First the convergence test should be able to tell if the ob-
jective function has converged to a local optimum. When
the optimization problem (1) is solved through stochastic
gradient descent (SGD), the convergence can be assessed
by monitoring the running average of ELBO changes. Re-
searchers have introduced many convergence tests based on
the asymptotic property of stochastic approximations (e.g.,
Sielken, 1973; Stroup & Braun, 1982; Pﬂug, 1990; Wada &
Fujisaki, 2015; Chee & Toulis, 2017). Alternatively, Blei
et al. (2017) suggest monitoring the expected log predictive
density by holding out an independent test dataset. After
convergence, the optimum is still an approximation to the
truth. This paper is focusing on the second level of VI di-
agnostics whether the variational posterior q∗(θ) is close
enough to the true posterior p(θ|y) to be used in its place.

Purely relying on the objective function or the equivalent
ELBO does not solve the problem. An unknown multi-
plicative constant exists in p(θ, y) ∝ p(θ | y) that changes
with reparametrization, making it meaningless to compare
ELBO across two approximations. Moreover, the ELBO is
a quantity on an uninterpretable scale, that is it’s not clear at
what value of the ELBO we can begin to trust the variational
posterior. This makes it next to useless as a method to assess
how well the variational inference has ﬁt.

In this paper we propose two diagnostic methods that assess,
respectively, the quality of the entire variational posterior for
a particular data set, and the average bias of a point estimate
produced under correct model speciﬁcation.

The ﬁrst method is based on generalized Pareto distribution
diagnostics used to assess the quality of a importance sam-
pling proposal distribution in Pareto smoothed importance
sampling (PSIS, Vehtari et al., 2017). The beneﬁt of PSIS
diagnostics is two-fold. First, we can tell the discrepancy
between the approximate and the true distribution by the
estimated continuous ˆk value. When it is larger than a pre-
speciﬁed threshold, users should be alert of the limitation

Evaluating Variational Inference

of current variational inference computation and consider
further tuning it or turn to exact sampling like Markov chain
Monte Carlo (MCMC). Second, in the case when ˆk is small,
the fast convergence rate of the importance-weighted Monte
Carlo integration guarantees a better estimation accuracy. In
such sense, the PSIS diagnostics could also be viewed as a
post-adjustment for VI approximations. Unlike the second-
order correction Giordano et al. (2017), which relies on an
un-testable unbiasedness assumption, we make diagnostics
and adjustment at the same time.

The second diagnostic considers only the quality of the
median of the variational posterior as a point estimate (in
Gaussian mean-ﬁeld VI this corresponds to the modal es-
timate). This diagnostic assesses the average behavior of
the point estimate under data from the model and can in-
dicate when a systemic bias is present. The magnitude of
that bias can be monitored while computing the diagnostic.
This diagnostic can also assess the average calibration of
univariate functionals of the parameters, revealing if the
posterior is under-dispersed, over-dispersed, or biased. This
diagnostic could be used as a partial justiﬁcation for using
the second-order correction of Giordano et al. (2017).

2. Is the Joint Distribution Good Enough?

If we can draw a sample (θ1, . . . , θS) from p(θ|y), the ex-
pectation of any integrable function Ep[h(θ)] can be esti-
mated by Monte Carlo integration: (cid:80)S
s=1 h(θs)/S S→∞−−−−−→
Ep [h(θ)] . Alternatively, given samples (θ1, . . . , θS) from
a proposal distribution q(θ), the importance sampling (IS)
(cid:17)
s=1 h(θs)rs
s=1 rs, where the impor-
estimate is
tance ratios rs are deﬁned as

(cid:16)(cid:80)S

/(cid:80)S

rs =

p(θs, y)
q(θs)

.

In general, with a sample (θ1, . . . , θS) drawn from the varia-
tional posterior q(θ), we consider a family of estimates with
the form

Ep[h(θ)] ≈

(cid:80)S

s=1 h(θs)ws
(cid:80)S
s=1 ws

,

which contains two extreme cases:

1. When ws ≡ 1, estimate (3) becomes the plain VI esti-
mate that is we completely trust the VI approximation.
In general, this will be biased to an unknown extent
and inconsistent. However, this estimator has small
variance.

2. When ws = rs, (3) becomes importance sampling.
The strong law of large numbers ensures it is consistent

(2)

(3)

as S → ∞, and with small O(1/S) bias due to self-
normalization. But the IS estimate may have a large or
inﬁnite variance.

There are two questions to be answered. First, can we ﬁnd a
better bias-variance trade-off than both plain VI and IS?

Second, VI approximation q(θ) is not designed for an op-
timal IS proposal, for it has a lighter tail than p(θ|y) as a
result of entropy penalization, which lead to a heavy right
tail of rs. A few large-valued rs dominates the summation,
bringing in large uncertainty. But does the ﬁnite sample
performance of IS or stabilized IS contain the information
about the dispensary measure between q(θ) and p(θ|y)?

2.1. Pareto Smoothed Importance Sampling

The solution to the ﬁrst question is the Pareto smoothed
importance sampling (PSIS). We give a brief review, and
more details can be found in Vehtari et al. (2017).

A generalized Pareto distribution with shape parameter k
and location-scale parameter (µ, τ ) has the density

p(y|µ, σ, k) =

(cid:19)(cid:19)− 1

k −1





1
σ
1
σ

(cid:18)

1 + k

(cid:18) y − µ
σ
(cid:19)

,

(cid:18) y − µ
σ

exp

, k (cid:54)= 0.

k = 0.

√

PSIS stabilizes importance ratios by ﬁtting a generalized
Pareto distribution using the largest M samples of ri, where
S). It then reports the
M is empirically set as min(S/5, 3
estimated shape parameter ˆk and replaces the M largest rs
by their expected value under the ﬁtted generalized Pareto
distribution. The other importance weights remain un-
changed. We further truncate all weights at the raw weight
maximum max(rs). The resulted smoothed weights are
denoted by ws, based on which a lower variance estimation
can be calculated through (3).

Pareto smoothed importance sampling can be considered as
Bayesian version of importance sampling with prior on the
largest importance ratios. It has smaller mean square errors
than plain IS and truncated-IS (Ionides, 2008).

2.2. Using PSIS as a Diagnostic Tool
The ﬁtted shape parameter ˆk, turns out to provide the desired
diagnostic measurement between the true posterior p(θ|y)
and the VI approximation q(θ). A generalized Pareto dis-
tribution with shape k has ﬁnite moments up to order 1/k,
thus any positive ˆk value can be viewed as an estimate to

(cid:40)

k = inf

k(cid:48) > 0 : Eq

(cid:19) 1
k(cid:48)

(cid:18) p(θ|y)
q(θ)

(cid:41)

< ∞

.

(4)

Evaluating Variational Inference

ˆk is invariant under any constant multiplication of p or q,
which explains why we can suppress the marginal likeli-
hood (normalizing constant) p(y) and replace the intractable
p(θ|y) with p(θ, y) in (2).

After log transformation, (4) can be interpreted as R´enyi
divergence (R´enyi et al., 1961) with order α between p(θ|y)
and q(θ):

(cid:110)

k = inf

k(cid:48) > 0 : D 1
k(cid:48)

(cid:111)

,

(p||q) < ∞
(cid:90)

where Dα (p||q) =

log

p(θ)αq(θ)1−αdθ.

1
α − 1

Θ

It is well-deﬁned since R´enyi divergence is monotonic in-
creasing on order α. Particularly, when k > 0.5, the χ2
divergence χ(p||q), becomes inﬁnite, and when k > 1,
D1(p||q) = KL(p, q) = ∞, indicating a disastrous VI
approximation, despite the fact that KL(q, p) is always min-
imized among the variational family. The connection to
R´enyi divergence holds when k > 0. When k < 0, it
predicts the importance ratios are bounded from above.
This also illustrates the advantage of a continuous ˆk estimate
in our approach over only testing the existence of second
moment of Eq(q/p)2 (Epifani et al., 2008; Koopman et al.,
2009) – it indicates if the R´enyi divergence between q and p
is ﬁnite for all continuous order α > 0.

Meanwhile, the shape parameter k determines the ﬁnite
sample convergence rate of both IS and PSIS adjusted es-
timate. Geweke (1989) shows when Eq[r(θ)2] < ∞ and
Eq[(cid:0)r(θ)h(θ)(cid:1)2
] < ∞ hold (both conditions can be tested
by ˆk in our approach), the central limit theorem guaran-
tees the square root convergence rate. Furthermore, when
k < 1/3, then the Berry-Essen theorem states faster con-
vergence rate to normality (Chen et al., 2004). Cortes et al.
(2010) and Cortes et al. (2013) also link the ﬁnite sample
convergence rate of IS with the number of existing moments
of importance ratios.

PSIS has smaller estimation error than the plain VI esti-
mate, which we will experimentally verify this in Section
4. A large ˆk indicates the failure of ﬁnite sample PSIS, so it
further indicates the large estimation error of VI approxima-
tion. Therefore, even when the researchers’ primary goal is
not to use variational approximation q as an PSIS proposal,
they should be alert by a large ˆk which tells the discrepancy
between the VI approximation result and the true posterior.

According to empirical study in Vehtari et al. (2017), we set
the threshold of ˆk as follows.

• If ˆk < 0.5, we can invoke the central limit theorem to
suggest PSIS has a fast convergence rate. We conclude
the variational approximation q is close enough to the
true density. We recommend further using PSIS to

Algorithm 1 PSIS diagnostic

1: Input: the joint density function p(θ, y); number of

posterior samples S; number of tail samples M .

2: Run variational inference to p(θ|y), obtain VI approxi-

mation q(θ);

3: Sample (θs, s = 1, . . . , S) from q(θ);
4: Calculate the importance ratio rs = p(θs, y)/q(θs);
5: Fit generalized Pareto distribution to the M largest rs;
6: Report the shape parameter ˆk;
7: if ˆk < 0.7 then
8:

Conclude VI approximation q(θ) is close enough to
the unknown truth p(θ|y);
Recommend further shrinking errors by PSIS.

9:
10: else
11: Warn users that the VI approximation is not reliable.
12: end if

adjust the estimator (3) and calculate other divergence
measures.

• If 0.5 < ˆk < 0.7, we still observe practically useful
ﬁnite sample convergence rates and acceptable Monte
Carlo error for PSIS. It indicates the variational ap-
proximation q is not perfect but still useful. Again, we
recommend PSIS to shrink errors.

• If ˆk > 0.7, the PSIS convergence rate becomes im-
practically slow, leading to a large mean square er-
ror, and a even larger error for plain VI estimate. We
should consider tuning the variational methods (e.g.,
re-parametrization, increase iteration times, increase
mini-batch size, decrease learning rate, et.al.,) or turn-
ing to exact MCMC. Theoretically k is always smaller
than 1, for Eq [p(θ|y)/q(θ)] = p(y) < ∞, while in
practice ﬁnite sample estimate ˆk may be larger than 1,
which indicates even worse ﬁnite sample performance.

The proposed diagnostic method is summarized in Algo-
rithm 1.

2.3. Invariance Under Re-Parametrization

Re-parametrization is common in variational inference. Par-
ticularly, the reparameterization trick (Rezende et al., 2014)
rewrites the objective function to make gradient calculation
easier in Monte Carlo integrations.
A nice property of PSIS diagnostics is that the ˆk quantity is
invariant under any re-parametrization. Suppose ξ = T (θ)
is a smooth transformation, then the density ratio of ξ under
the target p and the proposal q does not change:

p(ξ)
q(ξ)

=

p (cid:0)T −1(ξ)(cid:1) |detJξT −1(ξ)|
q (T −1(ξ)) |detJξT −1(ξ)|

=

p (θ)
q(θ)

Evaluating Variational Inference

Therefore, p(ξ)/q(ξ) and p(θ)/q(θ) have the same distri-
bution under q, making it free to choose any convenient
parametrization form when calculating ˆk.

However, if the re-parametrization changes the approxima-
tion family, then it will change the computation result, and
PSIS diagnostics will change accordingly. Finding the op-
timal parametrization form, such that the re-parametrized
posterior distribution lives exactly in the approximation fam-
ily

p(T (ξ)) = p (cid:0)T −1(ξ)(cid:1) |JξT −1(ξ)| ∈ Q,

can be as hard as ﬁnding the true posterior. The PSIS diag-
nostic can guide the choice of re-parametrization by simply
comparing the ˆk quantities of any parametrization. Section
4.3 provides a practical example.

2.4. Marginal PSIS Diagnostics Do Not Work

As dimension increases, the VI posterior tends to be further
away from the truth, due to the limitation of approximation
families. As a result, k increases, indicating inefﬁciency
of importance sampling. This is not the drawback of PSIS
diagnostics. Indeed, when the focus is the joint distribu-
tion, such behaviour accurately reﬂects the quality of the
variational approximation to the joint posterior.

true and approximate
Denoting the one-dimensional
marginal density of the i-th coordinate θi as p(θi|y) and
q(θi), the marginal k for θi can be deﬁned as

(cid:40)

ki = inf

0 < k(cid:48) < 1 : Eq

(cid:19) 1
k(cid:48)

(cid:18) p(θi|y)
q(θi)

(cid:41)

< ∞

.

The marginal ki is never larger (and usually smaller) than
the joint k in (4).

Proposition 1. For any two distributions p and q with
support Θ and the margin index i, if there is a num-
ber α > 1 satisfying Eq (p(θ)/q(θ))α < ∞,
then
Eq (p(θi)/q(θi))α < ∞.

Proposition 1 demonstrates why the importance sampling
is usually inefﬁcient in high dimensional sample space, in
that the joint estimation is “worse” than any of the marginal
estimation.

Should we extend the PSIS diagnostics to marginal distri-
butions? We ﬁnd two reasons why the marginal PSIS diag-
nostics can be misleading. Firstly, unlike the easy access
to the unnormalized joint posterior distribution p(θ, y), the
true marginal posterior density p(θi|y) is typically unknown,
otherwise one can conduct one-dimensional sampling easily
to obtain the the marginal samples. Secondly, a smaller ˆki
does not necessary guarantee a well-performed marginal
estimation. The marginal approximations in variational in-
ference can both over-estimate and under-estimate the tail

thickness of one-dimensional distributions, the latter situa-
tion gives rise to a smaller ˆki. Section 4.3 gives an example,
where the marginal approximations with extremely small
marginal k have large estimation errors. This does not hap-
pen in the joint case as the direction of the Kullback-Leibler
divergence q∗(θ) strongly penalizes too-heavy tails, which
makes it unlikely that the tails of the variational posterior
are signiﬁcantly heavier than the tails of the true posterior.

3. Assessing the Average Performance of the

Point Estimate

The proposed PSIS diagnostic assesses the quality of the
VI approximation to the full posterior distribution. It is
often observed that while the VI posterior may be a poor
approximation to the full posterior, point estimates that are
derived from it may still have good statistical properties. In
this section, we propose a new method for assessing the
calibration of the center of a VI posterior.

3.1. The Variational Simulation-Based Calibration

(VSBC) Diagnostic

This diagnostic is based on the proposal of Cook et al. (2006)
for validating general statistical software. They noted that if
θ(0) ∼ p(θ) and y ∼ p(y | θ(0)), then

Pr(y,θ(0))

(cid:16)

(cid:17)
Prθ|y(θ < θ(0)) ≤ ·)

= Unif[0,1]([0, ·]).

To use the observation of Cook et al. (2006) to assess the per-
formance of a VI point estimate, we propose the following
procedure. Simulate M > 1 data sets {yj}M
j=1 as follows:
Simulate θ(0)
j ∼ p(θ) and then simulate y(j) ∼ p(y | θ(0)
j ),
where y(j) has the same dimension as y. For each of
these data sets, construct a variational approximation to
p(θ | yj) and compute the marginal calibration probabilities
(cid:17)
pij = Prθ|y(j)
.

θi ≤ [θ(0)

]i

(cid:16)

j

To apply the full procedure of Cook et al. (2006), we would
need to test dim(θ) histograms for uniformity, however this
would be too stringent a check as, like our PSIS diagnostic,
this test is only passed if the variational posterior is a good
Instead, we follow
approximation to the true posterior.
an observation of Anderson (1996) from the probabilistic
forecasting validation literature and note that asymmetry
in the histogram for pi: indicates bias in the variational
approximation to the marginal posterior θi | y.

The VSBC diagnostic tests for symmetry of the marginal cal-
ibration probabilities around 0.5 and either by visual inspec-
tion of the histogram or by using a Kolmogorov-Smirnov
(KS) test to evaluate whether pi: and 1 − pi: have the same
distribution. When θ is a high-dimensional parameter, it
is important to interpret the results of any hypothesis tests

Evaluating Variational Inference

Algorithm 2 VSBC marginal diagnostics

1: Input: prior density p(θ), data likelihood p(y | θ);
number of replications M ; parameter dimensions K;

j

4:
5:

(cid:1) from p(y | θ(0)

2: for j = 1 : M do
Generate θ(0)
from prior p(θ);
3:
Generate a size-n dataset (cid:0)y(j)
Run variational inference using dataset y(j), obtain a
VI approximation distribution qj(·)
for i = 1 : K do
Label θ(0)
Label θ∗
Calculate pij = Pr(θ(0)

ij as the i-th marginal component of θ(0)
j
i as the i-th marginal component of θ∗;

i | θ∗ ∼ qj)

ij < θ∗

j );

6:
7:

;

end for

8:
9:
10: end for
11: for i = 1 : K do
12:
13:

14: end for

Test if the distribution of {pij}M
If rejected, the VI approximation is biased in its i-th
margin.

j=1 is symmetric;

through a multiple testing lens.

3.2. Understanding the VSBC Diagnostic

Unlike the PSIS diagnostic, which focuses on a the perfor-
mance of variational inference for a ﬁxed data set y, the
VSBC diagnostic assesses the average calibration of the
point estimation over all datasets that could be constructed
from the model. Hence, the VSBC diagnostic operates
under a different paradigm to the PSIS diagnostic and we
recommend using both as appropriate.

There are two disadvantages to this type of calibration when
compared to the PSIS diagnostic. As is always the case
when interpreting hypothesis tests, just because something
works on average doesn’t mean it will work for a particular
realization of the data. The second disadvantage is that this
diagnostic does not cover the case where the observed data
is not well represented by the model. We suggest interpret-
ing the diagnostic conservatively: if a variational inference
scheme fails the diagnostic, then it will not perform well on
the model in question. If the VI scheme passes the diagnos-
tic, it is not guaranteed that it will perform well for real data,
although if the model is well speciﬁed it should do well.

With stronger assumptions, The VSBC test can be formal-
ized as in Proposition 2.

Proposition 2. Denote θ as a one-dimensional parameter
that is of interest. Suppose in addition we have: (i) the
VI approximation q is symmetric; (ii) the true posterior
p(θ|y) is symmetric. If the VI estimation q is unbiased, i.e.,
Eθ∼q(θ|y) θ = Eθ∼p(θ|y) θ, then the distribution of VSBC
p-value is symmetric. Otherwise, if the VI estimation is
positively/negatively biased, then the distribution of VSBC
p-value is right/left skewed.

The symmetry of the true posterior is a stronger assumption
than is needed in practice for this result to hold. In the
forecast evaluation literature, as well as the literature on
posterior predictive checks, the symmetry of the histogram
is a commonly used heuristic to assess the potential bias of
the distribution. In our tests, we have seen the same thing
occurs: the median of the variational posterior is close to
the median of the true posterior when the VSBC histogram
is symmetric. We suggest again that this test be interpreted
conservatively: if the histogram is not symmetric, then the
VI is unlikely to have produced a point estimate close to the
median of the true posterior.

4. Applications

Both PSIS and VSBC diagnostics are applicable to any
variational inference algorithm. Without loss of generality,
we implement mean-ﬁeld Gaussian automatic differentiation
variational inference (ADVI) in this section.

4.1. Linear Regression

Consider a Bayesian linear regression y ∼ N(Xβ, σ2) with
prior {βi}K
i=1 ∼ N(0, 1), σ ∼ gamma(.5, .5). We ﬁx sam-
ple size n = 10000 and number of regressors K = 100.

Figure 1 visualizes the VSBC diagnostic, showing the dis-
tribution of VSBC p-values of the ﬁrst two regression coef-
ﬁcients β1, β2 and log σ based on M = 1000 replications.
The two sided Kolmogorov-Smirnov test for p: and 1 − p: is
only rejected for pσ:, suggesting the VI approximation is in
average marginally unbiased for β1 and β2, while σ is over-
estimated as pσ is right-skewed. The under-estimation of
posterior variance is reﬂected by the U-shaped distributions.

The VSBC diagnostic has some advantages compared to
the PSIS diagnostic. It is well understood that, for complex
models, the VI posterior can be used to produce a good point
estimate even when it is far from the true posterior. In this
case, the PSIS diagnostic will most likely indicate failure.
The second advantage is that unlike the PSIS diagnostic, the
VSBC diagnostic considers one-dimensional marginals θi
(or any functional h(θ)), which allows for a more targeted
interrogation of the ﬁtting procedure.

Using one randomly generated dataset in the same problem,
the PSIS ˆk is 0.61, indicating the joint approximation is
close to the true posterior. However, the performance of
ADVI is sensitive to the stopping time, as in any other opti-
mization problems. As displayed in the left panel of Figure
2, changing the threshold of relative ELBO change from
a conservative 10−5 to the default recommendation 10−2
increases ˆk to 4.4, even though 10−2 works ﬁne for many
other simpler problems. In this example, we can also view ˆk

Evaluating Variational Inference

Figure 1. VSBC diagnostics for β1, β2 and log σ in the Bayesian
linear regression example. The VI estimation overestimates σ as
pσ is right-skewed, while β1 and β2 is unbiased as the two-sided
KS-test is not rejected.

Figure 3. In the logistic regression example, as the correlation in
design matrix increase, the correlation in parameter space also
increases, leading to larger ˆk. Such ﬂaw is hard to tell from the
VI log predictive density (lpd), as a larger correlation makes the
prediction easier. ˆk diagnose the discrepancy of VI lpd and true
posterior lpd, with a sharp jump at 0.7.

Figure 2. ADVI is sensitive to the stopping time in the linear re-
gression example. The default 0.01 threshold lead to a fake con-
vergence, which can be diagnosed by monitoring PSIS ˆk. PSIS
adjustment always shrinks the estimation errors.

as a convergence test. The right panel shows ˆk diagnoses es-
timation error, which eventually become negligible in PSIS
adjustment when ˆk < 0.7. To account for the uncertainty
of stochastic optimization and ˆk estimation, simulations are
repeated 100 times.

4.2. Logistic Regression

Next we run ADVI to a logistic regression Y ∼
Bernoulli (cid:0)logit−1(βX)(cid:1) with a ﬂat prior on β. We gener-
ate X = (x1, . . . , xn) from N(0, (1 − ρ)IK×K + ρ1K×K)
such that the correlation in design matrix is ρ, and ρ is
changed from 0 to 0.99. The ﬁrst panel in Figure 3 shows
PSIS ˆk increases as the design matrix correlation increases.
It is not monotonic because β is initially negatively corre-
lated when X is independent. A large ρ transforms into a
large correlation for posterior distributions in β, making it
harder to be approximated by a mean-ﬁeld family, as can
be diagnosed by ˆk. In panel 2 we calculate mean log pre-
dictive density (lpd) of VI approximation and true posterior
using 200 independent test sets. Larger ρ leads to worse
mean-ﬁeld approximation, while prediction becomes eas-
ier. Consequently, monitoring lpd does not diagnose the VI
behavior; it increases (misleadingly suggesting better ﬁt)
as ρ increases. In this special case, VI has larger lpd than
the true posterior, due to the VI under-dispersion and the
model misspeciﬁcation. Indeed, if viewing lpd as a function
h(β), it is the discrepancy between VI lpd and true lpd that
reveals the VI performance, which can also be diagnosed
by ˆk. Panel 3 shows a sharp increase of lpd discrepancy
around ˆk = 0.7, consistent with the empirical threshold we
suggest.

Figure 4. In the logistic regression with varying correlations, the
ˆk diagnoses the root mean square of ﬁrst and second moment
errors. No estimation is reliable when ˆk > 0.7. Meanwhile, PSIS
adjustment always shrinks the VI estimation errors.

Figure 4 compares the ﬁrst and second moment root mean
square errors (RMSE) ||Epβ − Eq∗ β||2 and ||Epβ2 −
Eq∗ β2||2 in the previous example using three estimates:
(a) VI without post-adjustment, (b) VI adjusted by vanilla
importance sampling, and (c) VI adjusted by PSIS.
PSIS diagnostic accomplishes two tasks here: (1) A small ˆk
indicates that VI approximation is reliable. When ˆk > 0.7,
all estimations are no longer reasonable so the user should
be alerted. (2) It further improves the approximation using
PSIS adjustment, leading to a quicker convergence rate and
smaller mean square errors for both ﬁrst and second moment
estimation. Plain importance sampling has larger RMSE for
it suffers from a larger variance.

4.3. Re-parametrization in a Hierarchical Model

The Eight-School Model (Gelman et al., 2013, Section 5.5)
is the simplest Bayesian hierarchical normal model. Each
school reported the treatment effect mean yi and standard
deviation σi separately. There was no prior reason to believe
that any of the treatments were more effective than any other,
so we model them as independent experiments:

yj|θj ∼ N(θj, σ2
µ ∼ N(0, 5),

j ),

θj|µ, τ ∼ N(µ, τ 2),
τ ∼ half−Cauchy(0, 5).

1 ≤ j ≤ 8,

where θj represents the treatment effect in school j, and µ
and τ are the hyper-parameters shared across all schools.

Evaluating Variational Inference

Figure 6. In the eight-school example, the VSBC diagnostic veri-
ﬁes VI estimation of θ1 is unbiased as the distribution of pθ1: is
symmetric. τ is overestimated in the centered parametrization and
underestimated in the non-centered one, as told by the right/ left
skewness of pτ :.

tion. As shown by the top right panel in Figure 5, the joint
ˆk for the non-centered ADVI decreases to 0.64 which indi-
cated the approximation is not perfect but reasonable and
usable. The bottom-right panel demonstrates that the re-
parametrized ADVI posterior is much closer to the truth,
and has smaller biases for both ﬁrst and second moment
estimations.

We can assess the marginal estimation using VSBC diagnos-
tic, as summarized in Figure 6. In the centered parametriza-
tion, the point estimation for θ1 is in average unbiased, as
the two-sided KS-test is not rejected. The histogram for τ
is right-skewed, for we can reject one-sided KS-test with
the alternative to be pτ : being stochastically smaller than
pτ :. Hence we conclude τ is over-estimated in the centered
parameterization. On the contrast, the non-centered τ is
negatively biased, as diagnosed by the left-skewness of pτ :.
Such conclusion is consistent with the bottom-right panel in
Figure 5.

To sum up, this example illustrates how the Gaussian fam-
ily assumption can be unrealistic even for a simple hier-
archical model. It also clariﬁes VI posteriors can be both
over-dispersed and under-dispersed, depending crucially on
the true parameter dependencies. Nevertheless, the recom-
mended PSIS and VSBC diagnostics provide a practical
summary of the computation result.

4.4. Cancer Classiﬁcation Using Horseshoe Priors

We illustrate how the proposed diagnostic methods work
in the Leukemia microarray cancer dataset that contains
D = 7129 features and n = 72 observations. Denote y1:n
as binary outcome and Xn×D as the predictor, the logistic
regression with a regularized horseshoe prior (Piironen &
Vehtari, 2017) is given by

y|β ∼ Bernoulli (cid:0)logit−1 (Xβ)(cid:1) ,
τ ∼ C+(0, τ0),
λj ∼ C+(0, 1),

βj|τ, λ, c ∼ N(0, τ 2˜λ2
j ),
c2 ∼ Inv−Gamma(2, 8).

where τ > 0 and λ > 0 are global and local shrinkage
(cid:1). The regularized
parameters, and ˜λ2

j / (cid:0)c2 + τ 2λ2

j = c2λ2

j

Figure 5. The upper two panels shows the joint and marginal PSIS
diagnostics of the eight-school example. The centered parame-
terization has ˆk > 0.7, for it cannot capture the funnel-shaped
dependency between τ and θ. The bottom-right panel shows the
bias of posterior mean and standard errors of marginal distribu-
tions. Positive bias of τ leads to over-dispersion of θ.

In this hierarchical model, the conditional variance of θ is
strongly dependent on the standard deviation τ , as shown by
the joint sample of µ and log τ in the bottom-left corner in
Figure 5. The Gaussian assumption in ADVI cannot capture
such structure. More interestingly, ADVI over-estimates the
posterior variance for all parameters θ1 through θ8, as shown
by positive biases of their posterior standard deviation in
the last panel. In fact, the posterior mode is at τ = 0, while
the entropy penalization keeps VI estimation away from it,
leading to an overestimation due to the funnel-shape. Since
j + τ −2(cid:1)−1
the conditional expectation E[θi|τ, y, σ] = (cid:0)σ−2
is an increasing function on τ , a positive bias of τ produces
over-dispersion of θ.

The top left panel shows the marginal and joint PSIS di-
agnostics. The joint ˆk is 1.00, much beyond the threshold,
while the marginal ˆk calculated through the true marginal
distribution for all θ are misleadingly small due to the over-
dispersion.
Alerted by such large ˆk, researchers should seek some im-
provements, such as re-parametrization. The non-centered
parametrization extracts the dependency between θ and τ
through a transformation θ∗ = (θ − µ)/τ :

yj|θj ∼ N(µ + τ θ∗

j , σ2

j ),

θ∗
j ∼ N(0, 1).

There is no general rule to determine whether non-centered
parametrization is better than the centered one and there
are many other parametrization forms. Finding the optimal
parametrization can be as hard as ﬁnding the true posterior,
but ˆk diagnostics always guide the choice of parametriza-

Evaluating Variational Inference

horseshoe prior adapts to the sparsity and allows us to spec-
ify a minimum level of regularization to the largest values.

ADVI is computationally appealing for it only takes a few
minutes while MCMC sampling takes hours on this dataset.
However, PSIS diagnostic gives ˆk = 9.8 for ADVI, sug-
gesting the VI approximation is not even close to the true
posterior. Figure 7 compares the ADVI and true posterior
density of β1834, log λ1834 and τ . The Gaussian assumption
makes it impossible to recover the bimodal distribution of
some β.

Figure 7. The comparison of ADVI and true posterior density of
θ1834, log λ1834 and τ in the horseshoe logistic regression. ADVI
misses the right mode of log λ, making β ∝ λ become a spike.

Figure 8. VSBC test in the horseshoe logistic regression. It tells the
positive bias of τ and negative bias of λ1834. β1834 is in average
unbiased for its symmetric prior.

The VSBC diagnostics as shown in Figure 8 tell the neg-
ative bias of local shrinkage λ1834 from the left-skewness
of plog λ1834, which is the consequence of the right-missing
mode. For compensation, the global shrinkage τ is over-
estimated, which is in agreement with the right-skewness
of plog τ . β1834 is in average unbiased, even though it is
strongly underestimated from in Figure 7. This is because
VI estimation is mostly a spike at 0 and its prior is symmet-
ric. As we have explained, passing the VSBC test means the
average unbiasedness, and does not ensure the unbiasedness
for a speciﬁc parameter setting. This is the price that VSBC
pays for averaging over all priors.

5. Discussion

5.1. The Proposed Diagnostics are Local

As no single diagnostic method can tell all problems, the
proposed diagnostic methods have limitations. The PSIS
diagnostic is limited when the posterior is multimodal as
the samples drawn from q(θ) may not cover all the modes
of the posterior and the estimation of k will be indifferent
to the unseen modes. In this sense, the PSIS diagnostic is

a local diagnostic that will not detect unseen modes. For
example, imagine the true posterior is p = 0.8N(0, 0.2) +
0.2N(3, 0.2) with two isolated modes. Gaussian family VI
will converge to one of the modes, with the importance ratio
to be a constant number 0.8 or 0.2. Therefore k is 0, failing
to penalize the missing density. In fact, any divergence
measure based on samples from the approximation such as
KL(q, p) is local.

The bi-modality can be detected by multiple over-dispersed
initialization. It can also be diagnosed by other divergence
measures such as KL(p, q) = Ep log(q/p), which is com-
putable through PSIS by letting h = log(q/p).

In practice a marginal missing mode will typically lead to
large joint discrepancy that is still detectable by ˆk, such as
in Section 4.4.

The VSBC test, however, samples the true parameter from
the prior distribution directly. Unless the prior is too restric-
tive, the VSBC p-value will diagnose the potential missing
mode.

5.2. Tailoring Variational Inference for Importance

Sampling

The PSIS diagnostic makes use of stabilized IS to diag-
nose VI. By contrast, can we modify VI to give a better IS
proposal?

Geweke (1989) introduce an optimal proposal distribution
based on split-normal and split-t, implicitly minimizing
the χ2 divergence between q and p. Following this idea,
we could ﬁrst ﬁnd the usual VI solution, and then switch
Gaussian to Student-t with a scale chosen to minimize the
χ2 divergence.

More recently, some progress is made to carry out varia-
tional inference based on R´enyi divergence (Li & Turner,
2016; Dieng et al., 2017). But a big α, say α = 2, is only
meaningful when the proposal has a much heavier tail than
the target. For example, a normal family does not contain
any member having ﬁnite χ2 divergence to a Student-t dis-
tribution, leaving the optimal objective function deﬁned by
Dieng et al. (2017) inﬁnitely large.

There are several research directions. First, our proposed
diagnostics are applicable to these modiﬁed approximation
methods. Second, PSIS re-weighting will give a more re-
liable importance ratio estimation in the R´enyi divergence
variational inference. Third, a continuous ˆk and the cor-
responding α are more desirable than only ﬁxing α = 2,
as the latter one does not necessarily have a ﬁnite result.
Considering the role ˆk plays in the importance sampling, we
can optimize the discrepancy Dα(q||p) and α > 0 simulta-
neously. We leave this for future research.

Evaluating Variational Inference

Acknowledgements

The authors acknowledge support from the Ofﬁce of Naval
Research grants N00014-15-1-2541 and N00014-16-P-2039,
the National Science Foundation grant CNS-1730414, and
the Academy of Finland grant 313122.

References

Giordano, R., Broderick, T., and Jordan, M. I. Covari-
ances, robustness, and variational Bayes. arXiv preprint
arXiv:1709.02536, 2017.

Hoffman, M. D. and Gelman, A. The No-U-Turn sampler:
adaptively setting path lengths in Hamiltonian Monte
Carlo. Journal of Machine Learning Research, 15(1):
1593–1623, 2014.

Anderson, J. L. A method for producing and evaluating
probabilistic forecasts from ensemble model integrations.
Journal of Climate, 9(7):1518–1530, 1996.

Hoffman, M. D., Blei, D. M., Wang, C., and Paisley, J.
Stochastic variational inference. The Journal of Machine
Learning Research, 14(1):1303–1347, 2013.

Blei, D. M., Kucukelbir, A., and McAuliffe, J. D. Varia-
tional inference: A review for statisticians. Journal of
the American Statistical Association, 112(518):859–877,
2017.

Chee, J. and Toulis, P. Convergence diagnostics for stochas-
tic gradient descent with constant step size. arXiv preprint
arXiv:1710.06382, 2017.

Chen, L. H., Shao, Q.-M., et al. Normal approximation
under local dependence. The Annals of Probability, 32
(3):1985–2028, 2004.

Cook, S. R., Gelman, A., and Rubin, D. B. Validation of
software for Bayesian models using posterior quantiles.
Journal of Computational and Graphical Statistics, 15
(3):675–692, 2006.

Cortes, C., Mansour, Y., and Mohri, M. Learning bounds for
importance weighting. In Advances in neural information
processing systems, pp. 442–450, 2010.

Cortes, C., Greenberg, S., and Mohri, M. Relative deviation
learning bounds and generalization with unbounded loss
functions. arXiv preprint arXiv:1310.5796, 2013.

Dieng, A. B., Tran, D., Ranganath, R., Paisley, J., and
Blei, D. Variational inference via chi upper bound mini-
mization. In Advances in Neural Information Processing
Systems, pp. 2729–2738, 2017.

Epifani, I., MacEachern, S. N., Peruggia, M., et al. Case-
deletion importance sampling estimators: Central limit
theorems and related results. Electronic Journal of Statis-
tics, 2:774–806, 2008.

Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B.,
Vehtari, A., and Rubin, D. B. Bayesian data analysis.
CRC press, 2013.

Ionides, E. L. Truncated importance sampling. Journal of
Computational and Graphical Statistics, 17(2):295–311,
2008.

Koopman, S. J., Shephard, N., and Creal, D. Testing the
assumptions behind importance sampling. Journal of
Econometrics, 149(1):2–11, 2009.

Kucukelbir, A., Tran, D., Ranganath, R., Gelman, A., and
Blei, D. M. Automatic differentiation variational infer-
ence. Journal of Machine Learning Research, 18(14):
1–45, 2017.

Li, Y. and Turner, R. E. R´enyi divergence variational in-
ference. In Advances in Neural Information Processing
Systems, pp. 1073–1081, 2016.

Pﬂug, G. C. Non-asymptotic conﬁdence bounds for stochas-
tic approximation algorithms with constant step size.
Monatshefte f¨ur Mathematik, 110(3):297–314, 1990.

Piironen, J. and Vehtari, A. Sparsity information and reg-
ularization in the horseshoe and other shrinkage priors.
Electronic Journal of Statistics, 11(2):5018–5051, 2017.

Ranganath, R., Gerrish, S., and Blei, D. Black box varia-
tional inference. In Artiﬁcial Intelligence and Statistics,
pp. 814–822, 2014.

R´enyi, A. et al. On measures of entropy and information.
In Proceedings of the Fourth Berkeley Symposium on
Mathematical Statistics and Probability, Volume 1: Con-
tributions to the Theory of Statistics. The Regents of the
University of California, 1961.

Rezende, D. J., Mohamed, S., and Wierstra, D. Stochas-
tic backpropagation and approximate inference in deep
generative models. In Proceedings of the 31st Interna-
tional Conference on Machine Learning (ICML-14), pp.
1278–1286, 2014.

Geweke, J. Bayesian inference in econometric models us-
ing Monte Carlo integration. Econometrica, 57(6):1317–
1339, 1989.

Sielken, R. L. Stopping times for stochastic approximation
procedures. Probability Theory and Related Fields, 26
(1):67–75, 1973.

Evaluating Variational Inference

Stan Development Team. Stan modeling language users
guide and reference manual. http://mc-stan.org,
2017. Version 2.17.

Stroup, D. F. and Braun, H. I. On a new stopping rule
for stochastic approximation. Probability Theory and
Related Fields, 60(4):535–554, 1982.

Vehtari, A., Gelman, A., and Gabry, J. Pareto smoothed
importance sampling. arXiv preprint arXiv:1507.02646,
2017.

Vehtari, A., Gabry, J., Yao, Y., and Gelman, A. loo: Efﬁcient
leave-one-out cross-validation and waic for bayesian mod-
els, 2018. URL https://CRAN.R-project.org/
package=loo. R package version 2.0.0.

Wada, T. and Fujisaki, Y. A stopping rule for stochastic
approximation. Automatica, 60:1–6, 2015. ISSN 0005-
1098.

Supplement to “Yes, but Did It Work?: Evaluating Variational Inference”

A. Sketch of Proofs
A.1. Proof to Proposition 1: Marginal ˆk in PSIS diagnostic

Proposition 1. For any two distributions p and q with support Θ and the margin index i, if there is a number α > 1
satisfying Eq (p(θ)/q(θ))α < ∞, then Eq (p(θi)/q(θi))α < ∞.

Proof. Without loss of generality, we could assume Θ = RK, otherwise a smooth transformation is conducted.
For any 1 ≤ i ≤ K, p(θ−i|θi) and q(θ−i|θi) deﬁne the conditional distribution of (θ1, . . . , θi−1, θi+1, . . . , θK) ∈ RK−1
given θi under the true posterior p and the approximation q separately.

For any given index α > 1, Jensen inequality yields

(cid:90)

RK−1

(cid:19)α

(cid:18) p(θ−i|θi)
q(θ−i|θi)

q(θ−i|θi) ≥

(cid:18)(cid:90)

p(θ−i|θi)
q(θ−i|θi)

RK−1

(cid:19)α

q(θ−i|θi)

= 1

Hence

(cid:90)

RK

(cid:19)α

(cid:18) p(θ)
q(θ)

q(θ)dθ =

(cid:19)α

(cid:90)

RK−1
(cid:18)(cid:90)

(cid:90)

(cid:90)

R

(cid:18) p(θi)p(θ−i|θi)
q(θi)q(θ−i|θi)
(cid:18) p(θ−i|θi)
(cid:19)α
q(θ−i|θi)

=

≥

R

RK−1

(cid:90)

(cid:18) p(θi)
q(θi)

R

(cid:19)α

q(θi)dθi

q(θi)q(θ−i|θi)dθidθ−i

q(θ−i|θi)dθ−i

q(θi)dθi

(cid:19)α

(cid:19) (cid:18) p(θi)
q(θi)

A.2. Proof to Proposition 2: Symmetry in VSBC-Test

Proposition 2. For a one-dimensional parameter θ that is of interest, Suppose in addition we have:
(i) the VI approximation q is symmetric;
(ii) the true posterior p(θ|y) is symmetric.
If the VI estimation q is unbiased, i.e.,

Eθ∼q(θ|y) θ = Eθ∼p(θ|y) θ, ∀y

Then the distribution of VSBC p-value is symmetric.
If the VI estimation is positively/negatively biased, then the distribution of VSBC p-value is right/left skewed.

In the proposition we write q(θ|y) to emphasize that the VI approximation also depends on the observed data.

Proof. First, as the same logic in (Cook et al., 2006), when θ(0) is sampled from its prior p(θ) and simulated data y sampled
from likelihood p(y|θ(0)), (y, θ(0)) represents a sample from the joint distribution p(y, θ) and therefore θ(0) can be viewed
as a draw from p(θ|y), the true posterior distribution of θ with y being observed.

We denote q(θ(0)) as the VSBC p-value of the sample θ(0). Also denote Qx(f ) as the x−quantile (x ∈ [0, 1]) of any
distribution f . To prove the result, we need to show

1 − Pr(q(θ(0)) < x) = Pr(q(θ(0)) < 1 − x), ∀x ∈ [0, 1],

Supplement to “Evaluating Variational Inference”

LHS = Pr

q(θ(0)) > x

(cid:17)

= Pr

θ(0) > Qx (q(θ|y))

(cid:17)

.

(cid:16)

(cid:16)

(cid:17)

RHS = Pr

θ(0) < Q1−x (q(θ|y))

= Pr

θ(0) < 2Eq(θ|y)θ − Qx (q(θ|y))

(cid:16)

(cid:17)

(cid:17)

= Pr

θ(0) < 2Ep(θ|y)θ − Qx (q(θ|y))

= Pr

(cid:16)

(cid:17)
θ(0) > Qx (q(θ|y))

(cid:16)

(cid:16)

= LHS

The ﬁrst equation above uses the symmetry of q(θ|y), the second equation comes from the the unbiasedness condition. The
third is the result of the symmetry of p(θ|y).

If the VI estimation is positively biased, Eθ∼q(θ|y) θ > Eθ∼p(θ|y) θ, ∀y, then we change the second equality sign into a
less-than sign.

B. Details of Simulation Examples

In this section, we give more detailed description of the simulation examples in the manuscript. We use Stan (Stan
Development Team, 2017) to implement both automatic differentiation variational inference (ADVI) and Markov chain
Monte Carlo (MCMC) sampling. We implement Pareto smoothing through R package “loo” (Vehtari et al., 2018). We also
provide all the source code in https://github.com/yao-yl/Evaluating-Variational-Inference.

B.1. Linear and Logistic Regressions

In Section 4.1, We start with a Bayesian linear regression y ∼ N(Xβ, σ2) without intercept. The prior is set as {βi}d
i=1 ∼
N(0, 1), σ ∼ gamma(0.5, 0.5). We ﬁx sample size n = 10000 and number of regressors d = 100. Figure IX displays the
Stan code.

//number of observations, we fix n=10000 in the simulation;

//number of predictor variables,

fix d=100;

// predictors;

// outcome;

,

1 data {
2 int <lower=0> n;
3 int <lower=0> d;
4 matrix [n,d] x ;
5 vector [n] y;
6 }
7 parameters {
8 vector [d] b;
9 real <lower=0> sigma;
10 }
11 model {
12 y ∼ normal(x * b, sigma);
13 b ∼ normal(0,1); // prior for
14 sigma ∼ gamma(0.5,0.5);
15 }
16

// linear regression coefficient;

//linear regression std;

regression coefficient;

// prior for

regression std.

Figure IX. Stan code for linear regressions

We ﬁnd ADVI can be sensitive to the stopping time. Part of the reason is the objective function itself is evaluated through
Monte Carlo samples, producing large uncertainty. In the current version of Stan, ADVI computes the running average and
running median of the relative ELBO norm changes. Should either number fall below a threshold tol rel obj, with the
default value to be 0.01, the algorithm is considered converged.

In Figure 1 of the main paper, we run VSBC test on ADVI approximation. ADVI is deliberately tuned in a conservative way.
The convergence tolerance is set as tol rel obj=10−4 and the learning rate is η = 0.05. The predictor X105×102 is ﬁxed

Supplement to “Evaluating Variational Inference”

in all replications and is generated independently from N(0, 1). To avoid multiple-comparison problem, we pre-register the
ﬁrst and second coefﬁcients β1 β2 and log σ before the test. The VSBC diagnostic is based on M = 1000 replications.

In Figure 2 we independently generate each coordinate of β from N(0, 1) and set a relatively large variance σ = 2. The
predictor X is generated independently from N(0, 1) and y is sampled from the normal likelihood. We vary the threshold
tol rel obj from 0.01 to 10−5 and show the trajectory of ˆk diagnostics. The ˆk estimation, IS and PSIS adjustment are
all calculated from S = 5 × 104 posterior samples. We ignore the ADVI posterior sampling time. The actual running time is
based on a laptop experiment result (2.5 GHz processor, 8 cores).The exact sampling time is based on the No-U-Turn Sampler
(NUTS, Hoffman & Gelman 2014) in Stan with 4 chains and 3000 iterations in each chain. We also calculate the root mean
square errors (RMSE) of all parameters ||Ep[(β, σ)] − Eq[(β, σ)]||L2 , where (β, σ) represents the combined vector of all β
and σ. To account for the uncertainty, ˆk, running time, and RMSE takes the average of 50 repeated simulations.

//number of predictor variables;

// predictors; we vary its correlation during simulations.

,

1

2

3

4

5

6

7

8

9

10

11

12

13

//number of observations;

data {
int <lower=0> n;
int <lower=0> d;
matrix [n,d] x ;
int<lower=0,upper=1> y[n]; // binary outcome;
}
parameters {
vector[d] beta;
}
model {
y ∼ bernoulli_logit(x*beta);
}

Figure X. Stan code for logistic regressions

Figure 3 and 4 in the main paper is a simulation result of a logistic regression
Y ∼ Bernoulli (cid:0)logit−1(βX)(cid:1)

with a ﬂat prior on β. We vary the correlation in design matrix by generating X from N(0, (1 − ρ)Id×d + ρ1d×d), where
1d×d represents the d by d matrix with all elements to be 1. In this experiment we ﬁx a small number n = 100 and d = 2
since the main focus is parameter correlations. We compare ˆk with the log predictive density, which is calculated from
100 independent test data. The true posterior is from NUTS in Stan with 4 chains and 3000 iterations each chain. The
ˆk estimation, IS and PSIS adjustment are calculated from 105 posterior samples. To account for the uncertainty, ˆk, log
predictive density, and RMSE are the average of 50 repeated experiments.

B.2. Eight-School Model

The eight-school model is named after Gelman et al. (2013, section 5.5). The study was performed for the Educational
Testing Service to analyze the effects of a special coaching program on students’ SAT-V (Scholastic Aptitude Test Verbal)
scores in each of eight high schools. The outcome variable in each study was the score of a standardized multiple choice test.
Each school i separately analyzed the treatment effect and reported the mean yi and standard deviation of the treatment
effect estimation σi, as summarized in Table 1.

There was no prior reason to believe that any of the eight programs was more effective than any other or that some were more
similar in effect to each other than to any other. Hence, we view them as independent experiments and apply a Bayesian
hierarchical normal model:

yj|θj ∼ N(θj, σj),
µ ∼ N(0, 5),

θj ∼ N(µ, τ ),
τ ∼ half−Cauchy(0, 5).

1 ≤ j ≤ 8,

where θj represents the underlying treatment effect in school j, while µ and τ are the hyper-parameters that are shared
across all schools.

There are two parametrization forms being discussed: centered parameterization and non-centered parameterization.
Listing XI and XII give two Stan codes separately. The true posterior is from NUTS in Stan with 4 chains and 3000 iterations

Supplement to “Evaluating Variational Inference”

School Index j Estimated Treatment Effect yi Standard Deviation of Effect Estimate σj

1
2
3
4
5
6
7
8

28
8
-3
7
-1
1
8
12

15
10
16
11
9
11
10
18

Table 1. School-level observed effects of special preparation on SAT-V scores in eight randomized experiments. Estimates are based on
separate analyses for the eight experiments.

// number of schools
// estimated treatment

// std

of estimated effect

,

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

data {
int<lower=0> J;
real y[J];
real<lower=0> sigma[J];
}

parameters {
real theta[J];
real mu;
real<lower=0> tau;
}
model {
theta ∼ normal(mu, tau);
y ∼ normal(theta, sigma);
mu ∼ normal(0, 5);
tau ∼ cauchy(0, 5);
}

// treatment effect in school j

// hyper-parameter of mean

// hyper-parameter of sdv

// a non-informative prior

Figure XI. Stan code for centered parametrization in the eight-school model. It leads to strong dependency between tau and theta.

each chain. The ˆk estimation and PSIS adjustment are calculated from S = 105 posterior samples. The marginal ˆk is
calculated by using the NUTS density, which is typically unavailable for more complicated problems in practice.

The VSBC test in Figure 6 is based on M = 1000 replications and we pre-register the ﬁrst treatment effect θ1 and group-level
standard error log τ before the test.

As discussed in Section 3.2, VSBC assesses the average calibration of the point estimation. Hence the result depends on the
choice of prior. For example, if we instead set the prior to be

µ ∼ N(0, 50),

τ ∼ N+(0, 25),

which is essentially ﬂat in the region of interesting part of the likelihood and more in agreement with the prior knowledge,
then the result of VSBC test change to Figure XIII. Again, the skewness of p-values veriﬁes VI estimation of θ1 is in average
unbiased while τ is biased in both centered and non-centered parametrization.

B.3. Cancer Classiﬁcation Using Horseshoe Priors

In Section 4.3 of the main paper we replicate the cancer classiﬁcation under regularized horseshoe prior as ﬁrst introduced
by Piironen & Vehtari (2017).

The Leukemia microarray cancer classiﬁcation dataset 1. It contains n = 72 observations and d = 7129 features Xn×d. X
is standardized before any further process. The outcome y1:n is binary, so we can ﬁt a logistic regression

yi|β ∼ Bernoulli

βjxij + β0



 .


logit−1





d
(cid:88)

j=1





1The Leukemia classiﬁcation dataset can be downloaded from http://featureselectiocn.asu.edu/datasets.php

Supplement to “Evaluating Variational Inference”

// number of schools
// estimated treatment

// std

of estimated effect

// transformation of theta

// hyper-parameter of mean

// hyper-parameter of sd

// original theta

,

1 data {
2 int<lower=0> J;
3 real y[J];
4 real<lower=0> sigma[J];
5 }
6 parameters {
7 vector[J] theta_trans;
8 real mu;
9 real<lower=0> tau;
10 }
11 transformed parameters{
12 vector[J] theta;
13 theta=theta_trans*tau+mu;
14 }
15 model {
16 theta_trans ∼normal (0,1);
17 y ∼ normal(theta, sigma);
18 mu ∼ normal(0, 5);
19 tau ∼ cauchy(0, 5);
20 }
21

// a non-informative prior

Figure XII. Stan code for non-centered parametrization in the eight-school model. It extracts the dependency between tau and theta.

Figure XIII. The VSBC diagnostic of the eight-school example under a non-informative prior µ ∼ N(0, 50), τ ∼ N+(0, 25). The skewness
of p-values veriﬁes VI estimation of θ1 is in average unbiased while τ is biased in both centered and non-centered parametrization.

There are far more predictors than observations, so we expect only a few of predictors to be related and therefore have a
regression coefﬁcient distinguishable from zero. Further, many predictors are correlated, making it necessary to have a
regularization.

To this end, we apply the regularized horseshoe prior, which is a generalization of horseshoe prior.

βj|τ, λ, c ∼ N(0, τ 2˜λ2
λj ∼ Half−Cauchy(0, 1),

j ),

c2 ∼ Inv−Gamma(2, 8),

τ |τ0 ∼ Half−Cauchy(0, τ0).

The scale of the global shrinkage is set according to the recommendation τ0 = 2 (cid:0)n1/2(d − 1)(cid:1)−1
shrink intercept so we put β0 ∼ N(0, 10). The Stan code is summarized in Figure XIV.

There is no reason to

We ﬁrst run NUTS in Stan with 4 chains and 3000 iterations each chain. We manually pick β1834, the coefﬁcient that has the
largest posterior mean. The posterior distribution of it is bi-modal with one spike at 0.

ADVI is implemented using the same parametrization and we decrease the learning rate η to 0.1 and the threshold
tol rel obj to 0.001
The ˆk estimation is based on S = 104 posterior samples. Since ˆk is extremely large, indicating VI is far away from the true
posterior and no adjustment will work, we do not further conduct PSIS.

Supplement to “Evaluating Variational Inference”

,

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

// local shrinkage parameter

// global shrinkage parameter

// number of observations
// number of predictors
// outputs
// inputs
// prior std for the intercept

data {
int<lower=0> n;
int<lower=0> d;
int<lower=0,upper=1> y[n];
matrix[n,d] x;
real<lower=0> scale_icept;
real<lower=0> scale_global; // scale for the half-t prior for tau
real<lower=0> slab_scale;
real<lower=0> slab_df;
}
parameters {
real beta0; // intercept
vector[d] z; // auxiliary parameter
real<lower=0> tau;
vector<lower=0>[d] lambda;
real<lower=0> caux; // auxiliary
}
transformed parameters {
real<lower=0> c;
vector[d] beta;
vector[n] f;
vector<lower=0>[d] lambda_tilde;
c = slab_scale * sqrt(caux);
lambda_tilde = sqrt( cˆ2 * square(lambda) ./ (cˆ2 + tauˆ2* square(lambda)) );
beta = z .* lambda_tilde*tau;
f = beta0 + x*beta;
}
model {
z ∼ normal(0,1);
lambda ∼ cauchy(0,1);
tau ∼ cauchy(0, scale_global);
caux ∼ inv_gamma(0.5*slab_df, 0.5*slab_df);
beta0 ∼ normal(0,scale_icept);
y ∼ bernoulli_logit(f);
}

// regression coefficients

// latent values

Figure XIV. Stan code for regularized horseshoe logistic regression.

In the VSBC test, we pre-register that pre-chosen coefﬁcient β1834, log λ1834 and global shrinkage log τ before the test. The
VSBC diagnostic is based on M=1000 replications.

Yes, but Did It Work?: Evaluating Variational Inference

8
1
0
2
 
l
u
J
 
7
 
 
]
L
M

.
t
a
t
s
[
 
 
2
v
8
3
5
2
0
.
2
0
8
1
:
v
i
X
r
a

Yuling Yao 1 Aki Vehtari 2 Daniel Simpson 3 Andrew Gelman 1

Abstract
While it’s always possible to compute a varia-
tional approximation to a posterior distribution,
it can be difﬁcult to discover problems with this
approximation. We propose two diagnostic al-
gorithms to alleviate this problem. The Pareto-
smoothed importance sampling (PSIS) diagnostic
gives a goodness of ﬁt measurement for joint dis-
tributions, while simultaneously improving the
error in the estimate. The variational simulation-
based calibration (VSBC) assesses the average
performance of point estimates.

1. Introduction

Variational Inference (VI), including a large family of pos-
terior approximation methods like stochastic VI (Hoffman
et al. 2013), black-box VI (Ranganath et al. 2014), automatic
differentiation VI (ADVI, Kucukelbir et al. 2017), and many
other variants, has emerged as a widely-used method for
scalable Bayesian inference. These methods come with few
theoretical guarantees and it’s difﬁcult to assess how well
the computed variational posterior approximates the true
posterior.

Instead of computing expectations or sampling draws from
the posterior p(θ | y), variational inference ﬁxes a fam-
ily of approximate densities Q, and ﬁnds the member q∗
minimizing the Kullback-Leibler (KL) divergence to the
true posterior: KL (q(θ), p(θ | y)) . This is equivalent to
maximizing the evidence lower bound (ELBO):

ELBO(q) =

(log p(θ, y) − log q(θ)) q(θ)dθ.

(1)

(cid:90)

Θ

There are many situations where the VI approximation is
ﬂawed. This can be due to the slow convergence of the

1Department of Statistics, Columbia University, NY, USA
2Helsinki Institute for Information Technology, Department of
Computer Science, Aalto University, Finland 3Department of Sta-
tistical Sciences, University of Toronto, Canada. Correspondence
to: Yuling Yao <yy2618@columbia.edu>.

Proceedings of the 35 th International Conference on Machine
Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018
by the author(s).

optimization problem, the inability of the approximation
family to capture the true posterior, the asymmetry of the
true distribution, the fact that the direction of the KL diver-
gence under-penalizes approximation with too-light tails, or
all these reasons. We need a diagnostic algorithm to test
whether the VI approximation is useful.

There are two levels of diagnostics for variational inference.
First the convergence test should be able to tell if the ob-
jective function has converged to a local optimum. When
the optimization problem (1) is solved through stochastic
gradient descent (SGD), the convergence can be assessed
by monitoring the running average of ELBO changes. Re-
searchers have introduced many convergence tests based on
the asymptotic property of stochastic approximations (e.g.,
Sielken, 1973; Stroup & Braun, 1982; Pﬂug, 1990; Wada &
Fujisaki, 2015; Chee & Toulis, 2017). Alternatively, Blei
et al. (2017) suggest monitoring the expected log predictive
density by holding out an independent test dataset. After
convergence, the optimum is still an approximation to the
truth. This paper is focusing on the second level of VI di-
agnostics whether the variational posterior q∗(θ) is close
enough to the true posterior p(θ|y) to be used in its place.

Purely relying on the objective function or the equivalent
ELBO does not solve the problem. An unknown multi-
plicative constant exists in p(θ, y) ∝ p(θ | y) that changes
with reparametrization, making it meaningless to compare
ELBO across two approximations. Moreover, the ELBO is
a quantity on an uninterpretable scale, that is it’s not clear at
what value of the ELBO we can begin to trust the variational
posterior. This makes it next to useless as a method to assess
how well the variational inference has ﬁt.

In this paper we propose two diagnostic methods that assess,
respectively, the quality of the entire variational posterior for
a particular data set, and the average bias of a point estimate
produced under correct model speciﬁcation.

The ﬁrst method is based on generalized Pareto distribution
diagnostics used to assess the quality of a importance sam-
pling proposal distribution in Pareto smoothed importance
sampling (PSIS, Vehtari et al., 2017). The beneﬁt of PSIS
diagnostics is two-fold. First, we can tell the discrepancy
between the approximate and the true distribution by the
estimated continuous ˆk value. When it is larger than a pre-
speciﬁed threshold, users should be alert of the limitation

Evaluating Variational Inference

of current variational inference computation and consider
further tuning it or turn to exact sampling like Markov chain
Monte Carlo (MCMC). Second, in the case when ˆk is small,
the fast convergence rate of the importance-weighted Monte
Carlo integration guarantees a better estimation accuracy. In
such sense, the PSIS diagnostics could also be viewed as a
post-adjustment for VI approximations. Unlike the second-
order correction Giordano et al. (2017), which relies on an
un-testable unbiasedness assumption, we make diagnostics
and adjustment at the same time.

The second diagnostic considers only the quality of the
median of the variational posterior as a point estimate (in
Gaussian mean-ﬁeld VI this corresponds to the modal es-
timate). This diagnostic assesses the average behavior of
the point estimate under data from the model and can in-
dicate when a systemic bias is present. The magnitude of
that bias can be monitored while computing the diagnostic.
This diagnostic can also assess the average calibration of
univariate functionals of the parameters, revealing if the
posterior is under-dispersed, over-dispersed, or biased. This
diagnostic could be used as a partial justiﬁcation for using
the second-order correction of Giordano et al. (2017).

2. Is the Joint Distribution Good Enough?

If we can draw a sample (θ1, . . . , θS) from p(θ|y), the ex-
pectation of any integrable function Ep[h(θ)] can be esti-
mated by Monte Carlo integration: (cid:80)S
s=1 h(θs)/S S→∞−−−−−→
Ep [h(θ)] . Alternatively, given samples (θ1, . . . , θS) from
a proposal distribution q(θ), the importance sampling (IS)
(cid:17)
s=1 h(θs)rs
s=1 rs, where the impor-
estimate is
tance ratios rs are deﬁned as

(cid:16)(cid:80)S

/(cid:80)S

rs =

p(θs, y)
q(θs)

.

In general, with a sample (θ1, . . . , θS) drawn from the varia-
tional posterior q(θ), we consider a family of estimates with
the form

Ep[h(θ)] ≈

(cid:80)S

s=1 h(θs)ws
(cid:80)S
s=1 ws

,

which contains two extreme cases:

1. When ws ≡ 1, estimate (3) becomes the plain VI esti-
mate that is we completely trust the VI approximation.
In general, this will be biased to an unknown extent
and inconsistent. However, this estimator has small
variance.

2. When ws = rs, (3) becomes importance sampling.
The strong law of large numbers ensures it is consistent

(2)

(3)

as S → ∞, and with small O(1/S) bias due to self-
normalization. But the IS estimate may have a large or
inﬁnite variance.

There are two questions to be answered. First, can we ﬁnd a
better bias-variance trade-off than both plain VI and IS?

Second, VI approximation q(θ) is not designed for an op-
timal IS proposal, for it has a lighter tail than p(θ|y) as a
result of entropy penalization, which lead to a heavy right
tail of rs. A few large-valued rs dominates the summation,
bringing in large uncertainty. But does the ﬁnite sample
performance of IS or stabilized IS contain the information
about the dispensary measure between q(θ) and p(θ|y)?

2.1. Pareto Smoothed Importance Sampling

The solution to the ﬁrst question is the Pareto smoothed
importance sampling (PSIS). We give a brief review, and
more details can be found in Vehtari et al. (2017).

A generalized Pareto distribution with shape parameter k
and location-scale parameter (µ, τ ) has the density

p(y|µ, σ, k) =

(cid:19)(cid:19)− 1

k −1





1
σ
1
σ

(cid:18)

1 + k

(cid:18) y − µ
σ
(cid:19)

,

(cid:18) y − µ
σ

exp

, k (cid:54)= 0.

k = 0.

√

PSIS stabilizes importance ratios by ﬁtting a generalized
Pareto distribution using the largest M samples of ri, where
S). It then reports the
M is empirically set as min(S/5, 3
estimated shape parameter ˆk and replaces the M largest rs
by their expected value under the ﬁtted generalized Pareto
distribution. The other importance weights remain un-
changed. We further truncate all weights at the raw weight
maximum max(rs). The resulted smoothed weights are
denoted by ws, based on which a lower variance estimation
can be calculated through (3).

Pareto smoothed importance sampling can be considered as
Bayesian version of importance sampling with prior on the
largest importance ratios. It has smaller mean square errors
than plain IS and truncated-IS (Ionides, 2008).

2.2. Using PSIS as a Diagnostic Tool
The ﬁtted shape parameter ˆk, turns out to provide the desired
diagnostic measurement between the true posterior p(θ|y)
and the VI approximation q(θ). A generalized Pareto dis-
tribution with shape k has ﬁnite moments up to order 1/k,
thus any positive ˆk value can be viewed as an estimate to

(cid:40)

k = inf

k(cid:48) > 0 : Eq

(cid:19) 1
k(cid:48)

(cid:18) p(θ|y)
q(θ)

(cid:41)

< ∞

.

(4)

Evaluating Variational Inference

ˆk is invariant under any constant multiplication of p or q,
which explains why we can suppress the marginal likeli-
hood (normalizing constant) p(y) and replace the intractable
p(θ|y) with p(θ, y) in (2).

After log transformation, (4) can be interpreted as R´enyi
divergence (R´enyi et al., 1961) with order α between p(θ|y)
and q(θ):

(cid:110)

k = inf

k(cid:48) > 0 : D 1
k(cid:48)

(cid:111)

,

(p||q) < ∞
(cid:90)

where Dα (p||q) =

log

p(θ)αq(θ)1−αdθ.

1
α − 1

Θ

It is well-deﬁned since R´enyi divergence is monotonic in-
creasing on order α. Particularly, when k > 0.5, the χ2
divergence χ(p||q), becomes inﬁnite, and when k > 1,
D1(p||q) = KL(p, q) = ∞, indicating a disastrous VI
approximation, despite the fact that KL(q, p) is always min-
imized among the variational family. The connection to
R´enyi divergence holds when k > 0. When k < 0, it
predicts the importance ratios are bounded from above.
This also illustrates the advantage of a continuous ˆk estimate
in our approach over only testing the existence of second
moment of Eq(q/p)2 (Epifani et al., 2008; Koopman et al.,
2009) – it indicates if the R´enyi divergence between q and p
is ﬁnite for all continuous order α > 0.

Meanwhile, the shape parameter k determines the ﬁnite
sample convergence rate of both IS and PSIS adjusted es-
timate. Geweke (1989) shows when Eq[r(θ)2] < ∞ and
Eq[(cid:0)r(θ)h(θ)(cid:1)2
] < ∞ hold (both conditions can be tested
by ˆk in our approach), the central limit theorem guaran-
tees the square root convergence rate. Furthermore, when
k < 1/3, then the Berry-Essen theorem states faster con-
vergence rate to normality (Chen et al., 2004). Cortes et al.
(2010) and Cortes et al. (2013) also link the ﬁnite sample
convergence rate of IS with the number of existing moments
of importance ratios.

PSIS has smaller estimation error than the plain VI esti-
mate, which we will experimentally verify this in Section
4. A large ˆk indicates the failure of ﬁnite sample PSIS, so it
further indicates the large estimation error of VI approxima-
tion. Therefore, even when the researchers’ primary goal is
not to use variational approximation q as an PSIS proposal,
they should be alert by a large ˆk which tells the discrepancy
between the VI approximation result and the true posterior.

According to empirical study in Vehtari et al. (2017), we set
the threshold of ˆk as follows.

• If ˆk < 0.5, we can invoke the central limit theorem to
suggest PSIS has a fast convergence rate. We conclude
the variational approximation q is close enough to the
true density. We recommend further using PSIS to

Algorithm 1 PSIS diagnostic

1: Input: the joint density function p(θ, y); number of

posterior samples S; number of tail samples M .

2: Run variational inference to p(θ|y), obtain VI approxi-

mation q(θ);

3: Sample (θs, s = 1, . . . , S) from q(θ);
4: Calculate the importance ratio rs = p(θs, y)/q(θs);
5: Fit generalized Pareto distribution to the M largest rs;
6: Report the shape parameter ˆk;
7: if ˆk < 0.7 then
8:

Conclude VI approximation q(θ) is close enough to
the unknown truth p(θ|y);
Recommend further shrinking errors by PSIS.

9:
10: else
11: Warn users that the VI approximation is not reliable.
12: end if

adjust the estimator (3) and calculate other divergence
measures.

• If 0.5 < ˆk < 0.7, we still observe practically useful
ﬁnite sample convergence rates and acceptable Monte
Carlo error for PSIS. It indicates the variational ap-
proximation q is not perfect but still useful. Again, we
recommend PSIS to shrink errors.

• If ˆk > 0.7, the PSIS convergence rate becomes im-
practically slow, leading to a large mean square er-
ror, and a even larger error for plain VI estimate. We
should consider tuning the variational methods (e.g.,
re-parametrization, increase iteration times, increase
mini-batch size, decrease learning rate, et.al.,) or turn-
ing to exact MCMC. Theoretically k is always smaller
than 1, for Eq [p(θ|y)/q(θ)] = p(y) < ∞, while in
practice ﬁnite sample estimate ˆk may be larger than 1,
which indicates even worse ﬁnite sample performance.

The proposed diagnostic method is summarized in Algo-
rithm 1.

2.3. Invariance Under Re-Parametrization

Re-parametrization is common in variational inference. Par-
ticularly, the reparameterization trick (Rezende et al., 2014)
rewrites the objective function to make gradient calculation
easier in Monte Carlo integrations.
A nice property of PSIS diagnostics is that the ˆk quantity is
invariant under any re-parametrization. Suppose ξ = T (θ)
is a smooth transformation, then the density ratio of ξ under
the target p and the proposal q does not change:

p(ξ)
q(ξ)

=

p (cid:0)T −1(ξ)(cid:1) |detJξT −1(ξ)|
q (T −1(ξ)) |detJξT −1(ξ)|

=

p (θ)
q(θ)

Evaluating Variational Inference

Therefore, p(ξ)/q(ξ) and p(θ)/q(θ) have the same distri-
bution under q, making it free to choose any convenient
parametrization form when calculating ˆk.

However, if the re-parametrization changes the approxima-
tion family, then it will change the computation result, and
PSIS diagnostics will change accordingly. Finding the op-
timal parametrization form, such that the re-parametrized
posterior distribution lives exactly in the approximation fam-
ily

p(T (ξ)) = p (cid:0)T −1(ξ)(cid:1) |JξT −1(ξ)| ∈ Q,

can be as hard as ﬁnding the true posterior. The PSIS diag-
nostic can guide the choice of re-parametrization by simply
comparing the ˆk quantities of any parametrization. Section
4.3 provides a practical example.

2.4. Marginal PSIS Diagnostics Do Not Work

As dimension increases, the VI posterior tends to be further
away from the truth, due to the limitation of approximation
families. As a result, k increases, indicating inefﬁciency
of importance sampling. This is not the drawback of PSIS
diagnostics. Indeed, when the focus is the joint distribu-
tion, such behaviour accurately reﬂects the quality of the
variational approximation to the joint posterior.

true and approximate
Denoting the one-dimensional
marginal density of the i-th coordinate θi as p(θi|y) and
q(θi), the marginal k for θi can be deﬁned as

(cid:40)

ki = inf

0 < k(cid:48) < 1 : Eq

(cid:19) 1
k(cid:48)

(cid:18) p(θi|y)
q(θi)

(cid:41)

< ∞

.

The marginal ki is never larger (and usually smaller) than
the joint k in (4).

Proposition 1. For any two distributions p and q with
support Θ and the margin index i, if there is a num-
ber α > 1 satisfying Eq (p(θ)/q(θ))α < ∞,
then
Eq (p(θi)/q(θi))α < ∞.

Proposition 1 demonstrates why the importance sampling
is usually inefﬁcient in high dimensional sample space, in
that the joint estimation is “worse” than any of the marginal
estimation.

Should we extend the PSIS diagnostics to marginal distri-
butions? We ﬁnd two reasons why the marginal PSIS diag-
nostics can be misleading. Firstly, unlike the easy access
to the unnormalized joint posterior distribution p(θ, y), the
true marginal posterior density p(θi|y) is typically unknown,
otherwise one can conduct one-dimensional sampling easily
to obtain the the marginal samples. Secondly, a smaller ˆki
does not necessary guarantee a well-performed marginal
estimation. The marginal approximations in variational in-
ference can both over-estimate and under-estimate the tail

thickness of one-dimensional distributions, the latter situa-
tion gives rise to a smaller ˆki. Section 4.3 gives an example,
where the marginal approximations with extremely small
marginal k have large estimation errors. This does not hap-
pen in the joint case as the direction of the Kullback-Leibler
divergence q∗(θ) strongly penalizes too-heavy tails, which
makes it unlikely that the tails of the variational posterior
are signiﬁcantly heavier than the tails of the true posterior.

3. Assessing the Average Performance of the

Point Estimate

The proposed PSIS diagnostic assesses the quality of the
VI approximation to the full posterior distribution. It is
often observed that while the VI posterior may be a poor
approximation to the full posterior, point estimates that are
derived from it may still have good statistical properties. In
this section, we propose a new method for assessing the
calibration of the center of a VI posterior.

3.1. The Variational Simulation-Based Calibration

(VSBC) Diagnostic

This diagnostic is based on the proposal of Cook et al. (2006)
for validating general statistical software. They noted that if
θ(0) ∼ p(θ) and y ∼ p(y | θ(0)), then

Pr(y,θ(0))

(cid:16)

(cid:17)
Prθ|y(θ < θ(0)) ≤ ·)

= Unif[0,1]([0, ·]).

To use the observation of Cook et al. (2006) to assess the per-
formance of a VI point estimate, we propose the following
procedure. Simulate M > 1 data sets {yj}M
j=1 as follows:
Simulate θ(0)
j ∼ p(θ) and then simulate y(j) ∼ p(y | θ(0)
j ),
where y(j) has the same dimension as y. For each of
these data sets, construct a variational approximation to
p(θ | yj) and compute the marginal calibration probabilities
(cid:17)
pij = Prθ|y(j)
.

θi ≤ [θ(0)

]i

(cid:16)

j

To apply the full procedure of Cook et al. (2006), we would
need to test dim(θ) histograms for uniformity, however this
would be too stringent a check as, like our PSIS diagnostic,
this test is only passed if the variational posterior is a good
Instead, we follow
approximation to the true posterior.
an observation of Anderson (1996) from the probabilistic
forecasting validation literature and note that asymmetry
in the histogram for pi: indicates bias in the variational
approximation to the marginal posterior θi | y.

The VSBC diagnostic tests for symmetry of the marginal cal-
ibration probabilities around 0.5 and either by visual inspec-
tion of the histogram or by using a Kolmogorov-Smirnov
(KS) test to evaluate whether pi: and 1 − pi: have the same
distribution. When θ is a high-dimensional parameter, it
is important to interpret the results of any hypothesis tests

Evaluating Variational Inference

Algorithm 2 VSBC marginal diagnostics

1: Input: prior density p(θ), data likelihood p(y | θ);
number of replications M ; parameter dimensions K;

j

4:
5:

(cid:1) from p(y | θ(0)

2: for j = 1 : M do
Generate θ(0)
from prior p(θ);
3:
Generate a size-n dataset (cid:0)y(j)
Run variational inference using dataset y(j), obtain a
VI approximation distribution qj(·)
for i = 1 : K do
Label θ(0)
Label θ∗
Calculate pij = Pr(θ(0)

ij as the i-th marginal component of θ(0)
j
i as the i-th marginal component of θ∗;

i | θ∗ ∼ qj)

ij < θ∗

j );

6:
7:

;

end for

8:
9:
10: end for
11: for i = 1 : K do
12:
13:

14: end for

Test if the distribution of {pij}M
If rejected, the VI approximation is biased in its i-th
margin.

j=1 is symmetric;

through a multiple testing lens.

3.2. Understanding the VSBC Diagnostic

Unlike the PSIS diagnostic, which focuses on a the perfor-
mance of variational inference for a ﬁxed data set y, the
VSBC diagnostic assesses the average calibration of the
point estimation over all datasets that could be constructed
from the model. Hence, the VSBC diagnostic operates
under a different paradigm to the PSIS diagnostic and we
recommend using both as appropriate.

There are two disadvantages to this type of calibration when
compared to the PSIS diagnostic. As is always the case
when interpreting hypothesis tests, just because something
works on average doesn’t mean it will work for a particular
realization of the data. The second disadvantage is that this
diagnostic does not cover the case where the observed data
is not well represented by the model. We suggest interpret-
ing the diagnostic conservatively: if a variational inference
scheme fails the diagnostic, then it will not perform well on
the model in question. If the VI scheme passes the diagnos-
tic, it is not guaranteed that it will perform well for real data,
although if the model is well speciﬁed it should do well.

With stronger assumptions, The VSBC test can be formal-
ized as in Proposition 2.

Proposition 2. Denote θ as a one-dimensional parameter
that is of interest. Suppose in addition we have: (i) the
VI approximation q is symmetric; (ii) the true posterior
p(θ|y) is symmetric. If the VI estimation q is unbiased, i.e.,
Eθ∼q(θ|y) θ = Eθ∼p(θ|y) θ, then the distribution of VSBC
p-value is symmetric. Otherwise, if the VI estimation is
positively/negatively biased, then the distribution of VSBC
p-value is right/left skewed.

The symmetry of the true posterior is a stronger assumption
than is needed in practice for this result to hold. In the
forecast evaluation literature, as well as the literature on
posterior predictive checks, the symmetry of the histogram
is a commonly used heuristic to assess the potential bias of
the distribution. In our tests, we have seen the same thing
occurs: the median of the variational posterior is close to
the median of the true posterior when the VSBC histogram
is symmetric. We suggest again that this test be interpreted
conservatively: if the histogram is not symmetric, then the
VI is unlikely to have produced a point estimate close to the
median of the true posterior.

4. Applications

Both PSIS and VSBC diagnostics are applicable to any
variational inference algorithm. Without loss of generality,
we implement mean-ﬁeld Gaussian automatic differentiation
variational inference (ADVI) in this section.

4.1. Linear Regression

Consider a Bayesian linear regression y ∼ N(Xβ, σ2) with
prior {βi}K
i=1 ∼ N(0, 1), σ ∼ gamma(.5, .5). We ﬁx sam-
ple size n = 10000 and number of regressors K = 100.

Figure 1 visualizes the VSBC diagnostic, showing the dis-
tribution of VSBC p-values of the ﬁrst two regression coef-
ﬁcients β1, β2 and log σ based on M = 1000 replications.
The two sided Kolmogorov-Smirnov test for p: and 1 − p: is
only rejected for pσ:, suggesting the VI approximation is in
average marginally unbiased for β1 and β2, while σ is over-
estimated as pσ is right-skewed. The under-estimation of
posterior variance is reﬂected by the U-shaped distributions.

The VSBC diagnostic has some advantages compared to
the PSIS diagnostic. It is well understood that, for complex
models, the VI posterior can be used to produce a good point
estimate even when it is far from the true posterior. In this
case, the PSIS diagnostic will most likely indicate failure.
The second advantage is that unlike the PSIS diagnostic, the
VSBC diagnostic considers one-dimensional marginals θi
(or any functional h(θ)), which allows for a more targeted
interrogation of the ﬁtting procedure.

Using one randomly generated dataset in the same problem,
the PSIS ˆk is 0.61, indicating the joint approximation is
close to the true posterior. However, the performance of
ADVI is sensitive to the stopping time, as in any other opti-
mization problems. As displayed in the left panel of Figure
2, changing the threshold of relative ELBO change from
a conservative 10−5 to the default recommendation 10−2
increases ˆk to 4.4, even though 10−2 works ﬁne for many
other simpler problems. In this example, we can also view ˆk

Evaluating Variational Inference

Figure 1. VSBC diagnostics for β1, β2 and log σ in the Bayesian
linear regression example. The VI estimation overestimates σ as
pσ is right-skewed, while β1 and β2 is unbiased as the two-sided
KS-test is not rejected.

Figure 3. In the logistic regression example, as the correlation in
design matrix increase, the correlation in parameter space also
increases, leading to larger ˆk. Such ﬂaw is hard to tell from the
VI log predictive density (lpd), as a larger correlation makes the
prediction easier. ˆk diagnose the discrepancy of VI lpd and true
posterior lpd, with a sharp jump at 0.7.

Figure 2. ADVI is sensitive to the stopping time in the linear re-
gression example. The default 0.01 threshold lead to a fake con-
vergence, which can be diagnosed by monitoring PSIS ˆk. PSIS
adjustment always shrinks the estimation errors.

as a convergence test. The right panel shows ˆk diagnoses es-
timation error, which eventually become negligible in PSIS
adjustment when ˆk < 0.7. To account for the uncertainty
of stochastic optimization and ˆk estimation, simulations are
repeated 100 times.

4.2. Logistic Regression

Next we run ADVI to a logistic regression Y ∼
Bernoulli (cid:0)logit−1(βX)(cid:1) with a ﬂat prior on β. We gener-
ate X = (x1, . . . , xn) from N(0, (1 − ρ)IK×K + ρ1K×K)
such that the correlation in design matrix is ρ, and ρ is
changed from 0 to 0.99. The ﬁrst panel in Figure 3 shows
PSIS ˆk increases as the design matrix correlation increases.
It is not monotonic because β is initially negatively corre-
lated when X is independent. A large ρ transforms into a
large correlation for posterior distributions in β, making it
harder to be approximated by a mean-ﬁeld family, as can
be diagnosed by ˆk. In panel 2 we calculate mean log pre-
dictive density (lpd) of VI approximation and true posterior
using 200 independent test sets. Larger ρ leads to worse
mean-ﬁeld approximation, while prediction becomes eas-
ier. Consequently, monitoring lpd does not diagnose the VI
behavior; it increases (misleadingly suggesting better ﬁt)
as ρ increases. In this special case, VI has larger lpd than
the true posterior, due to the VI under-dispersion and the
model misspeciﬁcation. Indeed, if viewing lpd as a function
h(β), it is the discrepancy between VI lpd and true lpd that
reveals the VI performance, which can also be diagnosed
by ˆk. Panel 3 shows a sharp increase of lpd discrepancy
around ˆk = 0.7, consistent with the empirical threshold we
suggest.

Figure 4. In the logistic regression with varying correlations, the
ˆk diagnoses the root mean square of ﬁrst and second moment
errors. No estimation is reliable when ˆk > 0.7. Meanwhile, PSIS
adjustment always shrinks the VI estimation errors.

Figure 4 compares the ﬁrst and second moment root mean
square errors (RMSE) ||Epβ − Eq∗ β||2 and ||Epβ2 −
Eq∗ β2||2 in the previous example using three estimates:
(a) VI without post-adjustment, (b) VI adjusted by vanilla
importance sampling, and (c) VI adjusted by PSIS.
PSIS diagnostic accomplishes two tasks here: (1) A small ˆk
indicates that VI approximation is reliable. When ˆk > 0.7,
all estimations are no longer reasonable so the user should
be alerted. (2) It further improves the approximation using
PSIS adjustment, leading to a quicker convergence rate and
smaller mean square errors for both ﬁrst and second moment
estimation. Plain importance sampling has larger RMSE for
it suffers from a larger variance.

4.3. Re-parametrization in a Hierarchical Model

The Eight-School Model (Gelman et al., 2013, Section 5.5)
is the simplest Bayesian hierarchical normal model. Each
school reported the treatment effect mean yi and standard
deviation σi separately. There was no prior reason to believe
that any of the treatments were more effective than any other,
so we model them as independent experiments:

yj|θj ∼ N(θj, σ2
µ ∼ N(0, 5),

j ),

θj|µ, τ ∼ N(µ, τ 2),
τ ∼ half−Cauchy(0, 5).

1 ≤ j ≤ 8,

where θj represents the treatment effect in school j, and µ
and τ are the hyper-parameters shared across all schools.

Evaluating Variational Inference

Figure 6. In the eight-school example, the VSBC diagnostic veri-
ﬁes VI estimation of θ1 is unbiased as the distribution of pθ1: is
symmetric. τ is overestimated in the centered parametrization and
underestimated in the non-centered one, as told by the right/ left
skewness of pτ :.

tion. As shown by the top right panel in Figure 5, the joint
ˆk for the non-centered ADVI decreases to 0.64 which indi-
cated the approximation is not perfect but reasonable and
usable. The bottom-right panel demonstrates that the re-
parametrized ADVI posterior is much closer to the truth,
and has smaller biases for both ﬁrst and second moment
estimations.

We can assess the marginal estimation using VSBC diagnos-
tic, as summarized in Figure 6. In the centered parametriza-
tion, the point estimation for θ1 is in average unbiased, as
the two-sided KS-test is not rejected. The histogram for τ
is right-skewed, for we can reject one-sided KS-test with
the alternative to be pτ : being stochastically smaller than
pτ :. Hence we conclude τ is over-estimated in the centered
parameterization. On the contrast, the non-centered τ is
negatively biased, as diagnosed by the left-skewness of pτ :.
Such conclusion is consistent with the bottom-right panel in
Figure 5.

To sum up, this example illustrates how the Gaussian fam-
ily assumption can be unrealistic even for a simple hier-
archical model. It also clariﬁes VI posteriors can be both
over-dispersed and under-dispersed, depending crucially on
the true parameter dependencies. Nevertheless, the recom-
mended PSIS and VSBC diagnostics provide a practical
summary of the computation result.

4.4. Cancer Classiﬁcation Using Horseshoe Priors

We illustrate how the proposed diagnostic methods work
in the Leukemia microarray cancer dataset that contains
D = 7129 features and n = 72 observations. Denote y1:n
as binary outcome and Xn×D as the predictor, the logistic
regression with a regularized horseshoe prior (Piironen &
Vehtari, 2017) is given by

y|β ∼ Bernoulli (cid:0)logit−1 (Xβ)(cid:1) ,
τ ∼ C+(0, τ0),
λj ∼ C+(0, 1),

βj|τ, λ, c ∼ N(0, τ 2˜λ2
j ),
c2 ∼ Inv−Gamma(2, 8).

where τ > 0 and λ > 0 are global and local shrinkage
(cid:1). The regularized
parameters, and ˜λ2

j / (cid:0)c2 + τ 2λ2

j = c2λ2

j

Figure 5. The upper two panels shows the joint and marginal PSIS
diagnostics of the eight-school example. The centered parame-
terization has ˆk > 0.7, for it cannot capture the funnel-shaped
dependency between τ and θ. The bottom-right panel shows the
bias of posterior mean and standard errors of marginal distribu-
tions. Positive bias of τ leads to over-dispersion of θ.

In this hierarchical model, the conditional variance of θ is
strongly dependent on the standard deviation τ , as shown by
the joint sample of µ and log τ in the bottom-left corner in
Figure 5. The Gaussian assumption in ADVI cannot capture
such structure. More interestingly, ADVI over-estimates the
posterior variance for all parameters θ1 through θ8, as shown
by positive biases of their posterior standard deviation in
the last panel. In fact, the posterior mode is at τ = 0, while
the entropy penalization keeps VI estimation away from it,
leading to an overestimation due to the funnel-shape. Since
j + τ −2(cid:1)−1
the conditional expectation E[θi|τ, y, σ] = (cid:0)σ−2
is an increasing function on τ , a positive bias of τ produces
over-dispersion of θ.

The top left panel shows the marginal and joint PSIS di-
agnostics. The joint ˆk is 1.00, much beyond the threshold,
while the marginal ˆk calculated through the true marginal
distribution for all θ are misleadingly small due to the over-
dispersion.
Alerted by such large ˆk, researchers should seek some im-
provements, such as re-parametrization. The non-centered
parametrization extracts the dependency between θ and τ
through a transformation θ∗ = (θ − µ)/τ :

yj|θj ∼ N(µ + τ θ∗

j , σ2

j ),

θ∗
j ∼ N(0, 1).

There is no general rule to determine whether non-centered
parametrization is better than the centered one and there
are many other parametrization forms. Finding the optimal
parametrization can be as hard as ﬁnding the true posterior,
but ˆk diagnostics always guide the choice of parametriza-

Evaluating Variational Inference

horseshoe prior adapts to the sparsity and allows us to spec-
ify a minimum level of regularization to the largest values.

ADVI is computationally appealing for it only takes a few
minutes while MCMC sampling takes hours on this dataset.
However, PSIS diagnostic gives ˆk = 9.8 for ADVI, sug-
gesting the VI approximation is not even close to the true
posterior. Figure 7 compares the ADVI and true posterior
density of β1834, log λ1834 and τ . The Gaussian assumption
makes it impossible to recover the bimodal distribution of
some β.

Figure 7. The comparison of ADVI and true posterior density of
θ1834, log λ1834 and τ in the horseshoe logistic regression. ADVI
misses the right mode of log λ, making β ∝ λ become a spike.

Figure 8. VSBC test in the horseshoe logistic regression. It tells the
positive bias of τ and negative bias of λ1834. β1834 is in average
unbiased for its symmetric prior.

The VSBC diagnostics as shown in Figure 8 tell the neg-
ative bias of local shrinkage λ1834 from the left-skewness
of plog λ1834, which is the consequence of the right-missing
mode. For compensation, the global shrinkage τ is over-
estimated, which is in agreement with the right-skewness
of plog τ . β1834 is in average unbiased, even though it is
strongly underestimated from in Figure 7. This is because
VI estimation is mostly a spike at 0 and its prior is symmet-
ric. As we have explained, passing the VSBC test means the
average unbiasedness, and does not ensure the unbiasedness
for a speciﬁc parameter setting. This is the price that VSBC
pays for averaging over all priors.

5. Discussion

5.1. The Proposed Diagnostics are Local

As no single diagnostic method can tell all problems, the
proposed diagnostic methods have limitations. The PSIS
diagnostic is limited when the posterior is multimodal as
the samples drawn from q(θ) may not cover all the modes
of the posterior and the estimation of k will be indifferent
to the unseen modes. In this sense, the PSIS diagnostic is

a local diagnostic that will not detect unseen modes. For
example, imagine the true posterior is p = 0.8N(0, 0.2) +
0.2N(3, 0.2) with two isolated modes. Gaussian family VI
will converge to one of the modes, with the importance ratio
to be a constant number 0.8 or 0.2. Therefore k is 0, failing
to penalize the missing density. In fact, any divergence
measure based on samples from the approximation such as
KL(q, p) is local.

The bi-modality can be detected by multiple over-dispersed
initialization. It can also be diagnosed by other divergence
measures such as KL(p, q) = Ep log(q/p), which is com-
putable through PSIS by letting h = log(q/p).

In practice a marginal missing mode will typically lead to
large joint discrepancy that is still detectable by ˆk, such as
in Section 4.4.

The VSBC test, however, samples the true parameter from
the prior distribution directly. Unless the prior is too restric-
tive, the VSBC p-value will diagnose the potential missing
mode.

5.2. Tailoring Variational Inference for Importance

Sampling

The PSIS diagnostic makes use of stabilized IS to diag-
nose VI. By contrast, can we modify VI to give a better IS
proposal?

Geweke (1989) introduce an optimal proposal distribution
based on split-normal and split-t, implicitly minimizing
the χ2 divergence between q and p. Following this idea,
we could ﬁrst ﬁnd the usual VI solution, and then switch
Gaussian to Student-t with a scale chosen to minimize the
χ2 divergence.

More recently, some progress is made to carry out varia-
tional inference based on R´enyi divergence (Li & Turner,
2016; Dieng et al., 2017). But a big α, say α = 2, is only
meaningful when the proposal has a much heavier tail than
the target. For example, a normal family does not contain
any member having ﬁnite χ2 divergence to a Student-t dis-
tribution, leaving the optimal objective function deﬁned by
Dieng et al. (2017) inﬁnitely large.

There are several research directions. First, our proposed
diagnostics are applicable to these modiﬁed approximation
methods. Second, PSIS re-weighting will give a more re-
liable importance ratio estimation in the R´enyi divergence
variational inference. Third, a continuous ˆk and the cor-
responding α are more desirable than only ﬁxing α = 2,
as the latter one does not necessarily have a ﬁnite result.
Considering the role ˆk plays in the importance sampling, we
can optimize the discrepancy Dα(q||p) and α > 0 simulta-
neously. We leave this for future research.

Evaluating Variational Inference

Acknowledgements

The authors acknowledge support from the Ofﬁce of Naval
Research grants N00014-15-1-2541 and N00014-16-P-2039,
the National Science Foundation grant CNS-1730414, and
the Academy of Finland grant 313122.

References

Giordano, R., Broderick, T., and Jordan, M. I. Covari-
ances, robustness, and variational Bayes. arXiv preprint
arXiv:1709.02536, 2017.

Hoffman, M. D. and Gelman, A. The No-U-Turn sampler:
adaptively setting path lengths in Hamiltonian Monte
Carlo. Journal of Machine Learning Research, 15(1):
1593–1623, 2014.

Anderson, J. L. A method for producing and evaluating
probabilistic forecasts from ensemble model integrations.
Journal of Climate, 9(7):1518–1530, 1996.

Hoffman, M. D., Blei, D. M., Wang, C., and Paisley, J.
Stochastic variational inference. The Journal of Machine
Learning Research, 14(1):1303–1347, 2013.

Blei, D. M., Kucukelbir, A., and McAuliffe, J. D. Varia-
tional inference: A review for statisticians. Journal of
the American Statistical Association, 112(518):859–877,
2017.

Chee, J. and Toulis, P. Convergence diagnostics for stochas-
tic gradient descent with constant step size. arXiv preprint
arXiv:1710.06382, 2017.

Chen, L. H., Shao, Q.-M., et al. Normal approximation
under local dependence. The Annals of Probability, 32
(3):1985–2028, 2004.

Cook, S. R., Gelman, A., and Rubin, D. B. Validation of
software for Bayesian models using posterior quantiles.
Journal of Computational and Graphical Statistics, 15
(3):675–692, 2006.

Cortes, C., Mansour, Y., and Mohri, M. Learning bounds for
importance weighting. In Advances in neural information
processing systems, pp. 442–450, 2010.

Cortes, C., Greenberg, S., and Mohri, M. Relative deviation
learning bounds and generalization with unbounded loss
functions. arXiv preprint arXiv:1310.5796, 2013.

Dieng, A. B., Tran, D., Ranganath, R., Paisley, J., and
Blei, D. Variational inference via chi upper bound mini-
mization. In Advances in Neural Information Processing
Systems, pp. 2729–2738, 2017.

Epifani, I., MacEachern, S. N., Peruggia, M., et al. Case-
deletion importance sampling estimators: Central limit
theorems and related results. Electronic Journal of Statis-
tics, 2:774–806, 2008.

Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B.,
Vehtari, A., and Rubin, D. B. Bayesian data analysis.
CRC press, 2013.

Ionides, E. L. Truncated importance sampling. Journal of
Computational and Graphical Statistics, 17(2):295–311,
2008.

Koopman, S. J., Shephard, N., and Creal, D. Testing the
assumptions behind importance sampling. Journal of
Econometrics, 149(1):2–11, 2009.

Kucukelbir, A., Tran, D., Ranganath, R., Gelman, A., and
Blei, D. M. Automatic differentiation variational infer-
ence. Journal of Machine Learning Research, 18(14):
1–45, 2017.

Li, Y. and Turner, R. E. R´enyi divergence variational in-
ference. In Advances in Neural Information Processing
Systems, pp. 1073–1081, 2016.

Pﬂug, G. C. Non-asymptotic conﬁdence bounds for stochas-
tic approximation algorithms with constant step size.
Monatshefte f¨ur Mathematik, 110(3):297–314, 1990.

Piironen, J. and Vehtari, A. Sparsity information and reg-
ularization in the horseshoe and other shrinkage priors.
Electronic Journal of Statistics, 11(2):5018–5051, 2017.

Ranganath, R., Gerrish, S., and Blei, D. Black box varia-
tional inference. In Artiﬁcial Intelligence and Statistics,
pp. 814–822, 2014.

R´enyi, A. et al. On measures of entropy and information.
In Proceedings of the Fourth Berkeley Symposium on
Mathematical Statistics and Probability, Volume 1: Con-
tributions to the Theory of Statistics. The Regents of the
University of California, 1961.

Rezende, D. J., Mohamed, S., and Wierstra, D. Stochas-
tic backpropagation and approximate inference in deep
generative models. In Proceedings of the 31st Interna-
tional Conference on Machine Learning (ICML-14), pp.
1278–1286, 2014.

Geweke, J. Bayesian inference in econometric models us-
ing Monte Carlo integration. Econometrica, 57(6):1317–
1339, 1989.

Sielken, R. L. Stopping times for stochastic approximation
procedures. Probability Theory and Related Fields, 26
(1):67–75, 1973.

Evaluating Variational Inference

Stan Development Team. Stan modeling language users
guide and reference manual. http://mc-stan.org,
2017. Version 2.17.

Stroup, D. F. and Braun, H. I. On a new stopping rule
for stochastic approximation. Probability Theory and
Related Fields, 60(4):535–554, 1982.

Vehtari, A., Gelman, A., and Gabry, J. Pareto smoothed
importance sampling. arXiv preprint arXiv:1507.02646,
2017.

Vehtari, A., Gabry, J., Yao, Y., and Gelman, A. loo: Efﬁcient
leave-one-out cross-validation and waic for bayesian mod-
els, 2018. URL https://CRAN.R-project.org/
package=loo. R package version 2.0.0.

Wada, T. and Fujisaki, Y. A stopping rule for stochastic
approximation. Automatica, 60:1–6, 2015. ISSN 0005-
1098.

Supplement to “Yes, but Did It Work?: Evaluating Variational Inference”

A. Sketch of Proofs
A.1. Proof to Proposition 1: Marginal ˆk in PSIS diagnostic

Proposition 1. For any two distributions p and q with support Θ and the margin index i, if there is a number α > 1
satisfying Eq (p(θ)/q(θ))α < ∞, then Eq (p(θi)/q(θi))α < ∞.

Proof. Without loss of generality, we could assume Θ = RK, otherwise a smooth transformation is conducted.
For any 1 ≤ i ≤ K, p(θ−i|θi) and q(θ−i|θi) deﬁne the conditional distribution of (θ1, . . . , θi−1, θi+1, . . . , θK) ∈ RK−1
given θi under the true posterior p and the approximation q separately.

For any given index α > 1, Jensen inequality yields

(cid:90)

RK−1

(cid:19)α

(cid:18) p(θ−i|θi)
q(θ−i|θi)

q(θ−i|θi) ≥

(cid:18)(cid:90)

p(θ−i|θi)
q(θ−i|θi)

RK−1

(cid:19)α

q(θ−i|θi)

= 1

Hence

(cid:90)

RK

(cid:19)α

(cid:18) p(θ)
q(θ)

q(θ)dθ =

(cid:19)α

(cid:90)

RK−1
(cid:18)(cid:90)

(cid:90)

(cid:90)

R

(cid:18) p(θi)p(θ−i|θi)
q(θi)q(θ−i|θi)
(cid:18) p(θ−i|θi)
(cid:19)α
q(θ−i|θi)

=

≥

R

RK−1

(cid:90)

(cid:18) p(θi)
q(θi)

R

(cid:19)α

q(θi)dθi

q(θi)q(θ−i|θi)dθidθ−i

q(θ−i|θi)dθ−i

q(θi)dθi

(cid:19)α

(cid:19) (cid:18) p(θi)
q(θi)

A.2. Proof to Proposition 2: Symmetry in VSBC-Test

Proposition 2. For a one-dimensional parameter θ that is of interest, Suppose in addition we have:
(i) the VI approximation q is symmetric;
(ii) the true posterior p(θ|y) is symmetric.
If the VI estimation q is unbiased, i.e.,

Eθ∼q(θ|y) θ = Eθ∼p(θ|y) θ, ∀y

Then the distribution of VSBC p-value is symmetric.
If the VI estimation is positively/negatively biased, then the distribution of VSBC p-value is right/left skewed.

In the proposition we write q(θ|y) to emphasize that the VI approximation also depends on the observed data.

Proof. First, as the same logic in (Cook et al., 2006), when θ(0) is sampled from its prior p(θ) and simulated data y sampled
from likelihood p(y|θ(0)), (y, θ(0)) represents a sample from the joint distribution p(y, θ) and therefore θ(0) can be viewed
as a draw from p(θ|y), the true posterior distribution of θ with y being observed.

We denote q(θ(0)) as the VSBC p-value of the sample θ(0). Also denote Qx(f ) as the x−quantile (x ∈ [0, 1]) of any
distribution f . To prove the result, we need to show

1 − Pr(q(θ(0)) < x) = Pr(q(θ(0)) < 1 − x), ∀x ∈ [0, 1],

Supplement to “Evaluating Variational Inference”

LHS = Pr

q(θ(0)) > x

(cid:17)

= Pr

θ(0) > Qx (q(θ|y))

(cid:17)

.

(cid:16)

(cid:16)

(cid:17)

RHS = Pr

θ(0) < Q1−x (q(θ|y))

= Pr

θ(0) < 2Eq(θ|y)θ − Qx (q(θ|y))

(cid:16)

(cid:17)

(cid:17)

= Pr

θ(0) < 2Ep(θ|y)θ − Qx (q(θ|y))

= Pr

(cid:16)

(cid:17)
θ(0) > Qx (q(θ|y))

(cid:16)

(cid:16)

= LHS

The ﬁrst equation above uses the symmetry of q(θ|y), the second equation comes from the the unbiasedness condition. The
third is the result of the symmetry of p(θ|y).

If the VI estimation is positively biased, Eθ∼q(θ|y) θ > Eθ∼p(θ|y) θ, ∀y, then we change the second equality sign into a
less-than sign.

B. Details of Simulation Examples

In this section, we give more detailed description of the simulation examples in the manuscript. We use Stan (Stan
Development Team, 2017) to implement both automatic differentiation variational inference (ADVI) and Markov chain
Monte Carlo (MCMC) sampling. We implement Pareto smoothing through R package “loo” (Vehtari et al., 2018). We also
provide all the source code in https://github.com/yao-yl/Evaluating-Variational-Inference.

B.1. Linear and Logistic Regressions

In Section 4.1, We start with a Bayesian linear regression y ∼ N(Xβ, σ2) without intercept. The prior is set as {βi}d
i=1 ∼
N(0, 1), σ ∼ gamma(0.5, 0.5). We ﬁx sample size n = 10000 and number of regressors d = 100. Figure IX displays the
Stan code.

//number of observations, we fix n=10000 in the simulation;

//number of predictor variables,

fix d=100;

// predictors;

// outcome;

,

1 data {
2 int <lower=0> n;
3 int <lower=0> d;
4 matrix [n,d] x ;
5 vector [n] y;
6 }
7 parameters {
8 vector [d] b;
9 real <lower=0> sigma;
10 }
11 model {
12 y ∼ normal(x * b, sigma);
13 b ∼ normal(0,1); // prior for
14 sigma ∼ gamma(0.5,0.5);
15 }
16

// linear regression coefficient;

//linear regression std;

regression coefficient;

// prior for

regression std.

Figure IX. Stan code for linear regressions

We ﬁnd ADVI can be sensitive to the stopping time. Part of the reason is the objective function itself is evaluated through
Monte Carlo samples, producing large uncertainty. In the current version of Stan, ADVI computes the running average and
running median of the relative ELBO norm changes. Should either number fall below a threshold tol rel obj, with the
default value to be 0.01, the algorithm is considered converged.

In Figure 1 of the main paper, we run VSBC test on ADVI approximation. ADVI is deliberately tuned in a conservative way.
The convergence tolerance is set as tol rel obj=10−4 and the learning rate is η = 0.05. The predictor X105×102 is ﬁxed

Supplement to “Evaluating Variational Inference”

in all replications and is generated independently from N(0, 1). To avoid multiple-comparison problem, we pre-register the
ﬁrst and second coefﬁcients β1 β2 and log σ before the test. The VSBC diagnostic is based on M = 1000 replications.

In Figure 2 we independently generate each coordinate of β from N(0, 1) and set a relatively large variance σ = 2. The
predictor X is generated independently from N(0, 1) and y is sampled from the normal likelihood. We vary the threshold
tol rel obj from 0.01 to 10−5 and show the trajectory of ˆk diagnostics. The ˆk estimation, IS and PSIS adjustment are
all calculated from S = 5 × 104 posterior samples. We ignore the ADVI posterior sampling time. The actual running time is
based on a laptop experiment result (2.5 GHz processor, 8 cores).The exact sampling time is based on the No-U-Turn Sampler
(NUTS, Hoffman & Gelman 2014) in Stan with 4 chains and 3000 iterations in each chain. We also calculate the root mean
square errors (RMSE) of all parameters ||Ep[(β, σ)] − Eq[(β, σ)]||L2 , where (β, σ) represents the combined vector of all β
and σ. To account for the uncertainty, ˆk, running time, and RMSE takes the average of 50 repeated simulations.

//number of predictor variables;

// predictors; we vary its correlation during simulations.

,

1

2

3

4

5

6

7

8

9

10

11

12

13

//number of observations;

data {
int <lower=0> n;
int <lower=0> d;
matrix [n,d] x ;
int<lower=0,upper=1> y[n]; // binary outcome;
}
parameters {
vector[d] beta;
}
model {
y ∼ bernoulli_logit(x*beta);
}

Figure X. Stan code for logistic regressions

Figure 3 and 4 in the main paper is a simulation result of a logistic regression
Y ∼ Bernoulli (cid:0)logit−1(βX)(cid:1)

with a ﬂat prior on β. We vary the correlation in design matrix by generating X from N(0, (1 − ρ)Id×d + ρ1d×d), where
1d×d represents the d by d matrix with all elements to be 1. In this experiment we ﬁx a small number n = 100 and d = 2
since the main focus is parameter correlations. We compare ˆk with the log predictive density, which is calculated from
100 independent test data. The true posterior is from NUTS in Stan with 4 chains and 3000 iterations each chain. The
ˆk estimation, IS and PSIS adjustment are calculated from 105 posterior samples. To account for the uncertainty, ˆk, log
predictive density, and RMSE are the average of 50 repeated experiments.

B.2. Eight-School Model

The eight-school model is named after Gelman et al. (2013, section 5.5). The study was performed for the Educational
Testing Service to analyze the effects of a special coaching program on students’ SAT-V (Scholastic Aptitude Test Verbal)
scores in each of eight high schools. The outcome variable in each study was the score of a standardized multiple choice test.
Each school i separately analyzed the treatment effect and reported the mean yi and standard deviation of the treatment
effect estimation σi, as summarized in Table 1.

There was no prior reason to believe that any of the eight programs was more effective than any other or that some were more
similar in effect to each other than to any other. Hence, we view them as independent experiments and apply a Bayesian
hierarchical normal model:

yj|θj ∼ N(θj, σj),
µ ∼ N(0, 5),

θj ∼ N(µ, τ ),
τ ∼ half−Cauchy(0, 5).

1 ≤ j ≤ 8,

where θj represents the underlying treatment effect in school j, while µ and τ are the hyper-parameters that are shared
across all schools.

There are two parametrization forms being discussed: centered parameterization and non-centered parameterization.
Listing XI and XII give two Stan codes separately. The true posterior is from NUTS in Stan with 4 chains and 3000 iterations

Supplement to “Evaluating Variational Inference”

School Index j Estimated Treatment Effect yi Standard Deviation of Effect Estimate σj

1
2
3
4
5
6
7
8

28
8
-3
7
-1
1
8
12

15
10
16
11
9
11
10
18

Table 1. School-level observed effects of special preparation on SAT-V scores in eight randomized experiments. Estimates are based on
separate analyses for the eight experiments.

// number of schools
// estimated treatment

// std

of estimated effect

,

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

data {
int<lower=0> J;
real y[J];
real<lower=0> sigma[J];
}

parameters {
real theta[J];
real mu;
real<lower=0> tau;
}
model {
theta ∼ normal(mu, tau);
y ∼ normal(theta, sigma);
mu ∼ normal(0, 5);
tau ∼ cauchy(0, 5);
}

// treatment effect in school j

// hyper-parameter of mean

// hyper-parameter of sdv

// a non-informative prior

Figure XI. Stan code for centered parametrization in the eight-school model. It leads to strong dependency between tau and theta.

each chain. The ˆk estimation and PSIS adjustment are calculated from S = 105 posterior samples. The marginal ˆk is
calculated by using the NUTS density, which is typically unavailable for more complicated problems in practice.

The VSBC test in Figure 6 is based on M = 1000 replications and we pre-register the ﬁrst treatment effect θ1 and group-level
standard error log τ before the test.

As discussed in Section 3.2, VSBC assesses the average calibration of the point estimation. Hence the result depends on the
choice of prior. For example, if we instead set the prior to be

µ ∼ N(0, 50),

τ ∼ N+(0, 25),

which is essentially ﬂat in the region of interesting part of the likelihood and more in agreement with the prior knowledge,
then the result of VSBC test change to Figure XIII. Again, the skewness of p-values veriﬁes VI estimation of θ1 is in average
unbiased while τ is biased in both centered and non-centered parametrization.

B.3. Cancer Classiﬁcation Using Horseshoe Priors

In Section 4.3 of the main paper we replicate the cancer classiﬁcation under regularized horseshoe prior as ﬁrst introduced
by Piironen & Vehtari (2017).

The Leukemia microarray cancer classiﬁcation dataset 1. It contains n = 72 observations and d = 7129 features Xn×d. X
is standardized before any further process. The outcome y1:n is binary, so we can ﬁt a logistic regression

yi|β ∼ Bernoulli

βjxij + β0



 .


logit−1





d
(cid:88)

j=1





1The Leukemia classiﬁcation dataset can be downloaded from http://featureselectiocn.asu.edu/datasets.php

Supplement to “Evaluating Variational Inference”

// number of schools
// estimated treatment

// std

of estimated effect

// transformation of theta

// hyper-parameter of mean

// hyper-parameter of sd

// original theta

,

1 data {
2 int<lower=0> J;
3 real y[J];
4 real<lower=0> sigma[J];
5 }
6 parameters {
7 vector[J] theta_trans;
8 real mu;
9 real<lower=0> tau;
10 }
11 transformed parameters{
12 vector[J] theta;
13 theta=theta_trans*tau+mu;
14 }
15 model {
16 theta_trans ∼normal (0,1);
17 y ∼ normal(theta, sigma);
18 mu ∼ normal(0, 5);
19 tau ∼ cauchy(0, 5);
20 }
21

// a non-informative prior

Figure XII. Stan code for non-centered parametrization in the eight-school model. It extracts the dependency between tau and theta.

Figure XIII. The VSBC diagnostic of the eight-school example under a non-informative prior µ ∼ N(0, 50), τ ∼ N+(0, 25). The skewness
of p-values veriﬁes VI estimation of θ1 is in average unbiased while τ is biased in both centered and non-centered parametrization.

There are far more predictors than observations, so we expect only a few of predictors to be related and therefore have a
regression coefﬁcient distinguishable from zero. Further, many predictors are correlated, making it necessary to have a
regularization.

To this end, we apply the regularized horseshoe prior, which is a generalization of horseshoe prior.

βj|τ, λ, c ∼ N(0, τ 2˜λ2
λj ∼ Half−Cauchy(0, 1),

j ),

c2 ∼ Inv−Gamma(2, 8),

τ |τ0 ∼ Half−Cauchy(0, τ0).

The scale of the global shrinkage is set according to the recommendation τ0 = 2 (cid:0)n1/2(d − 1)(cid:1)−1
shrink intercept so we put β0 ∼ N(0, 10). The Stan code is summarized in Figure XIV.

There is no reason to

We ﬁrst run NUTS in Stan with 4 chains and 3000 iterations each chain. We manually pick β1834, the coefﬁcient that has the
largest posterior mean. The posterior distribution of it is bi-modal with one spike at 0.

ADVI is implemented using the same parametrization and we decrease the learning rate η to 0.1 and the threshold
tol rel obj to 0.001
The ˆk estimation is based on S = 104 posterior samples. Since ˆk is extremely large, indicating VI is far away from the true
posterior and no adjustment will work, we do not further conduct PSIS.

Supplement to “Evaluating Variational Inference”

,

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

// local shrinkage parameter

// global shrinkage parameter

// number of observations
// number of predictors
// outputs
// inputs
// prior std for the intercept

data {
int<lower=0> n;
int<lower=0> d;
int<lower=0,upper=1> y[n];
matrix[n,d] x;
real<lower=0> scale_icept;
real<lower=0> scale_global; // scale for the half-t prior for tau
real<lower=0> slab_scale;
real<lower=0> slab_df;
}
parameters {
real beta0; // intercept
vector[d] z; // auxiliary parameter
real<lower=0> tau;
vector<lower=0>[d] lambda;
real<lower=0> caux; // auxiliary
}
transformed parameters {
real<lower=0> c;
vector[d] beta;
vector[n] f;
vector<lower=0>[d] lambda_tilde;
c = slab_scale * sqrt(caux);
lambda_tilde = sqrt( cˆ2 * square(lambda) ./ (cˆ2 + tauˆ2* square(lambda)) );
beta = z .* lambda_tilde*tau;
f = beta0 + x*beta;
}
model {
z ∼ normal(0,1);
lambda ∼ cauchy(0,1);
tau ∼ cauchy(0, scale_global);
caux ∼ inv_gamma(0.5*slab_df, 0.5*slab_df);
beta0 ∼ normal(0,scale_icept);
y ∼ bernoulli_logit(f);
}

// regression coefficients

// latent values

Figure XIV. Stan code for regularized horseshoe logistic regression.

In the VSBC test, we pre-register that pre-chosen coefﬁcient β1834, log λ1834 and global shrinkage log τ before the test. The
VSBC diagnostic is based on M=1000 replications.

Yes, but Did It Work?: Evaluating Variational Inference

8
1
0
2
 
l
u
J
 
7
 
 
]
L
M

.
t
a
t
s
[
 
 
2
v
8
3
5
2
0
.
2
0
8
1
:
v
i
X
r
a

Yuling Yao 1 Aki Vehtari 2 Daniel Simpson 3 Andrew Gelman 1

Abstract
While it’s always possible to compute a varia-
tional approximation to a posterior distribution,
it can be difﬁcult to discover problems with this
approximation. We propose two diagnostic al-
gorithms to alleviate this problem. The Pareto-
smoothed importance sampling (PSIS) diagnostic
gives a goodness of ﬁt measurement for joint dis-
tributions, while simultaneously improving the
error in the estimate. The variational simulation-
based calibration (VSBC) assesses the average
performance of point estimates.

1. Introduction

Variational Inference (VI), including a large family of pos-
terior approximation methods like stochastic VI (Hoffman
et al. 2013), black-box VI (Ranganath et al. 2014), automatic
differentiation VI (ADVI, Kucukelbir et al. 2017), and many
other variants, has emerged as a widely-used method for
scalable Bayesian inference. These methods come with few
theoretical guarantees and it’s difﬁcult to assess how well
the computed variational posterior approximates the true
posterior.

Instead of computing expectations or sampling draws from
the posterior p(θ | y), variational inference ﬁxes a fam-
ily of approximate densities Q, and ﬁnds the member q∗
minimizing the Kullback-Leibler (KL) divergence to the
true posterior: KL (q(θ), p(θ | y)) . This is equivalent to
maximizing the evidence lower bound (ELBO):

ELBO(q) =

(log p(θ, y) − log q(θ)) q(θ)dθ.

(1)

(cid:90)

Θ

There are many situations where the VI approximation is
ﬂawed. This can be due to the slow convergence of the

1Department of Statistics, Columbia University, NY, USA
2Helsinki Institute for Information Technology, Department of
Computer Science, Aalto University, Finland 3Department of Sta-
tistical Sciences, University of Toronto, Canada. Correspondence
to: Yuling Yao <yy2618@columbia.edu>.

Proceedings of the 35 th International Conference on Machine
Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018
by the author(s).

optimization problem, the inability of the approximation
family to capture the true posterior, the asymmetry of the
true distribution, the fact that the direction of the KL diver-
gence under-penalizes approximation with too-light tails, or
all these reasons. We need a diagnostic algorithm to test
whether the VI approximation is useful.

There are two levels of diagnostics for variational inference.
First the convergence test should be able to tell if the ob-
jective function has converged to a local optimum. When
the optimization problem (1) is solved through stochastic
gradient descent (SGD), the convergence can be assessed
by monitoring the running average of ELBO changes. Re-
searchers have introduced many convergence tests based on
the asymptotic property of stochastic approximations (e.g.,
Sielken, 1973; Stroup & Braun, 1982; Pﬂug, 1990; Wada &
Fujisaki, 2015; Chee & Toulis, 2017). Alternatively, Blei
et al. (2017) suggest monitoring the expected log predictive
density by holding out an independent test dataset. After
convergence, the optimum is still an approximation to the
truth. This paper is focusing on the second level of VI di-
agnostics whether the variational posterior q∗(θ) is close
enough to the true posterior p(θ|y) to be used in its place.

Purely relying on the objective function or the equivalent
ELBO does not solve the problem. An unknown multi-
plicative constant exists in p(θ, y) ∝ p(θ | y) that changes
with reparametrization, making it meaningless to compare
ELBO across two approximations. Moreover, the ELBO is
a quantity on an uninterpretable scale, that is it’s not clear at
what value of the ELBO we can begin to trust the variational
posterior. This makes it next to useless as a method to assess
how well the variational inference has ﬁt.

In this paper we propose two diagnostic methods that assess,
respectively, the quality of the entire variational posterior for
a particular data set, and the average bias of a point estimate
produced under correct model speciﬁcation.

The ﬁrst method is based on generalized Pareto distribution
diagnostics used to assess the quality of a importance sam-
pling proposal distribution in Pareto smoothed importance
sampling (PSIS, Vehtari et al., 2017). The beneﬁt of PSIS
diagnostics is two-fold. First, we can tell the discrepancy
between the approximate and the true distribution by the
estimated continuous ˆk value. When it is larger than a pre-
speciﬁed threshold, users should be alert of the limitation

Evaluating Variational Inference

of current variational inference computation and consider
further tuning it or turn to exact sampling like Markov chain
Monte Carlo (MCMC). Second, in the case when ˆk is small,
the fast convergence rate of the importance-weighted Monte
Carlo integration guarantees a better estimation accuracy. In
such sense, the PSIS diagnostics could also be viewed as a
post-adjustment for VI approximations. Unlike the second-
order correction Giordano et al. (2017), which relies on an
un-testable unbiasedness assumption, we make diagnostics
and adjustment at the same time.

The second diagnostic considers only the quality of the
median of the variational posterior as a point estimate (in
Gaussian mean-ﬁeld VI this corresponds to the modal es-
timate). This diagnostic assesses the average behavior of
the point estimate under data from the model and can in-
dicate when a systemic bias is present. The magnitude of
that bias can be monitored while computing the diagnostic.
This diagnostic can also assess the average calibration of
univariate functionals of the parameters, revealing if the
posterior is under-dispersed, over-dispersed, or biased. This
diagnostic could be used as a partial justiﬁcation for using
the second-order correction of Giordano et al. (2017).

2. Is the Joint Distribution Good Enough?

If we can draw a sample (θ1, . . . , θS) from p(θ|y), the ex-
pectation of any integrable function Ep[h(θ)] can be esti-
mated by Monte Carlo integration: (cid:80)S
s=1 h(θs)/S S→∞−−−−−→
Ep [h(θ)] . Alternatively, given samples (θ1, . . . , θS) from
a proposal distribution q(θ), the importance sampling (IS)
(cid:17)
s=1 h(θs)rs
s=1 rs, where the impor-
estimate is
tance ratios rs are deﬁned as

(cid:16)(cid:80)S

/(cid:80)S

rs =

p(θs, y)
q(θs)

.

In general, with a sample (θ1, . . . , θS) drawn from the varia-
tional posterior q(θ), we consider a family of estimates with
the form

Ep[h(θ)] ≈

(cid:80)S

s=1 h(θs)ws
(cid:80)S
s=1 ws

,

which contains two extreme cases:

1. When ws ≡ 1, estimate (3) becomes the plain VI esti-
mate that is we completely trust the VI approximation.
In general, this will be biased to an unknown extent
and inconsistent. However, this estimator has small
variance.

2. When ws = rs, (3) becomes importance sampling.
The strong law of large numbers ensures it is consistent

(2)

(3)

as S → ∞, and with small O(1/S) bias due to self-
normalization. But the IS estimate may have a large or
inﬁnite variance.

There are two questions to be answered. First, can we ﬁnd a
better bias-variance trade-off than both plain VI and IS?

Second, VI approximation q(θ) is not designed for an op-
timal IS proposal, for it has a lighter tail than p(θ|y) as a
result of entropy penalization, which lead to a heavy right
tail of rs. A few large-valued rs dominates the summation,
bringing in large uncertainty. But does the ﬁnite sample
performance of IS or stabilized IS contain the information
about the dispensary measure between q(θ) and p(θ|y)?

2.1. Pareto Smoothed Importance Sampling

The solution to the ﬁrst question is the Pareto smoothed
importance sampling (PSIS). We give a brief review, and
more details can be found in Vehtari et al. (2017).

A generalized Pareto distribution with shape parameter k
and location-scale parameter (µ, τ ) has the density

p(y|µ, σ, k) =

(cid:19)(cid:19)− 1

k −1





1
σ
1
σ

(cid:18)

1 + k

(cid:18) y − µ
σ
(cid:19)

,

(cid:18) y − µ
σ

exp

, k (cid:54)= 0.

k = 0.

√

PSIS stabilizes importance ratios by ﬁtting a generalized
Pareto distribution using the largest M samples of ri, where
S). It then reports the
M is empirically set as min(S/5, 3
estimated shape parameter ˆk and replaces the M largest rs
by their expected value under the ﬁtted generalized Pareto
distribution. The other importance weights remain un-
changed. We further truncate all weights at the raw weight
maximum max(rs). The resulted smoothed weights are
denoted by ws, based on which a lower variance estimation
can be calculated through (3).

Pareto smoothed importance sampling can be considered as
Bayesian version of importance sampling with prior on the
largest importance ratios. It has smaller mean square errors
than plain IS and truncated-IS (Ionides, 2008).

2.2. Using PSIS as a Diagnostic Tool
The ﬁtted shape parameter ˆk, turns out to provide the desired
diagnostic measurement between the true posterior p(θ|y)
and the VI approximation q(θ). A generalized Pareto dis-
tribution with shape k has ﬁnite moments up to order 1/k,
thus any positive ˆk value can be viewed as an estimate to

(cid:40)

k = inf

k(cid:48) > 0 : Eq

(cid:19) 1
k(cid:48)

(cid:18) p(θ|y)
q(θ)

(cid:41)

< ∞

.

(4)

Evaluating Variational Inference

ˆk is invariant under any constant multiplication of p or q,
which explains why we can suppress the marginal likeli-
hood (normalizing constant) p(y) and replace the intractable
p(θ|y) with p(θ, y) in (2).

After log transformation, (4) can be interpreted as R´enyi
divergence (R´enyi et al., 1961) with order α between p(θ|y)
and q(θ):

(cid:110)

k = inf

k(cid:48) > 0 : D 1
k(cid:48)

(cid:111)

,

(p||q) < ∞
(cid:90)

where Dα (p||q) =

log

p(θ)αq(θ)1−αdθ.

1
α − 1

Θ

It is well-deﬁned since R´enyi divergence is monotonic in-
creasing on order α. Particularly, when k > 0.5, the χ2
divergence χ(p||q), becomes inﬁnite, and when k > 1,
D1(p||q) = KL(p, q) = ∞, indicating a disastrous VI
approximation, despite the fact that KL(q, p) is always min-
imized among the variational family. The connection to
R´enyi divergence holds when k > 0. When k < 0, it
predicts the importance ratios are bounded from above.
This also illustrates the advantage of a continuous ˆk estimate
in our approach over only testing the existence of second
moment of Eq(q/p)2 (Epifani et al., 2008; Koopman et al.,
2009) – it indicates if the R´enyi divergence between q and p
is ﬁnite for all continuous order α > 0.

Meanwhile, the shape parameter k determines the ﬁnite
sample convergence rate of both IS and PSIS adjusted es-
timate. Geweke (1989) shows when Eq[r(θ)2] < ∞ and
Eq[(cid:0)r(θ)h(θ)(cid:1)2
] < ∞ hold (both conditions can be tested
by ˆk in our approach), the central limit theorem guaran-
tees the square root convergence rate. Furthermore, when
k < 1/3, then the Berry-Essen theorem states faster con-
vergence rate to normality (Chen et al., 2004). Cortes et al.
(2010) and Cortes et al. (2013) also link the ﬁnite sample
convergence rate of IS with the number of existing moments
of importance ratios.

PSIS has smaller estimation error than the plain VI esti-
mate, which we will experimentally verify this in Section
4. A large ˆk indicates the failure of ﬁnite sample PSIS, so it
further indicates the large estimation error of VI approxima-
tion. Therefore, even when the researchers’ primary goal is
not to use variational approximation q as an PSIS proposal,
they should be alert by a large ˆk which tells the discrepancy
between the VI approximation result and the true posterior.

According to empirical study in Vehtari et al. (2017), we set
the threshold of ˆk as follows.

• If ˆk < 0.5, we can invoke the central limit theorem to
suggest PSIS has a fast convergence rate. We conclude
the variational approximation q is close enough to the
true density. We recommend further using PSIS to

Algorithm 1 PSIS diagnostic

1: Input: the joint density function p(θ, y); number of

posterior samples S; number of tail samples M .

2: Run variational inference to p(θ|y), obtain VI approxi-

mation q(θ);

3: Sample (θs, s = 1, . . . , S) from q(θ);
4: Calculate the importance ratio rs = p(θs, y)/q(θs);
5: Fit generalized Pareto distribution to the M largest rs;
6: Report the shape parameter ˆk;
7: if ˆk < 0.7 then
8:

Conclude VI approximation q(θ) is close enough to
the unknown truth p(θ|y);
Recommend further shrinking errors by PSIS.

9:
10: else
11: Warn users that the VI approximation is not reliable.
12: end if

adjust the estimator (3) and calculate other divergence
measures.

• If 0.5 < ˆk < 0.7, we still observe practically useful
ﬁnite sample convergence rates and acceptable Monte
Carlo error for PSIS. It indicates the variational ap-
proximation q is not perfect but still useful. Again, we
recommend PSIS to shrink errors.

• If ˆk > 0.7, the PSIS convergence rate becomes im-
practically slow, leading to a large mean square er-
ror, and a even larger error for plain VI estimate. We
should consider tuning the variational methods (e.g.,
re-parametrization, increase iteration times, increase
mini-batch size, decrease learning rate, et.al.,) or turn-
ing to exact MCMC. Theoretically k is always smaller
than 1, for Eq [p(θ|y)/q(θ)] = p(y) < ∞, while in
practice ﬁnite sample estimate ˆk may be larger than 1,
which indicates even worse ﬁnite sample performance.

The proposed diagnostic method is summarized in Algo-
rithm 1.

2.3. Invariance Under Re-Parametrization

Re-parametrization is common in variational inference. Par-
ticularly, the reparameterization trick (Rezende et al., 2014)
rewrites the objective function to make gradient calculation
easier in Monte Carlo integrations.
A nice property of PSIS diagnostics is that the ˆk quantity is
invariant under any re-parametrization. Suppose ξ = T (θ)
is a smooth transformation, then the density ratio of ξ under
the target p and the proposal q does not change:

p(ξ)
q(ξ)

=

p (cid:0)T −1(ξ)(cid:1) |detJξT −1(ξ)|
q (T −1(ξ)) |detJξT −1(ξ)|

=

p (θ)
q(θ)

Evaluating Variational Inference

Therefore, p(ξ)/q(ξ) and p(θ)/q(θ) have the same distri-
bution under q, making it free to choose any convenient
parametrization form when calculating ˆk.

However, if the re-parametrization changes the approxima-
tion family, then it will change the computation result, and
PSIS diagnostics will change accordingly. Finding the op-
timal parametrization form, such that the re-parametrized
posterior distribution lives exactly in the approximation fam-
ily

p(T (ξ)) = p (cid:0)T −1(ξ)(cid:1) |JξT −1(ξ)| ∈ Q,

can be as hard as ﬁnding the true posterior. The PSIS diag-
nostic can guide the choice of re-parametrization by simply
comparing the ˆk quantities of any parametrization. Section
4.3 provides a practical example.

2.4. Marginal PSIS Diagnostics Do Not Work

As dimension increases, the VI posterior tends to be further
away from the truth, due to the limitation of approximation
families. As a result, k increases, indicating inefﬁciency
of importance sampling. This is not the drawback of PSIS
diagnostics. Indeed, when the focus is the joint distribu-
tion, such behaviour accurately reﬂects the quality of the
variational approximation to the joint posterior.

true and approximate
Denoting the one-dimensional
marginal density of the i-th coordinate θi as p(θi|y) and
q(θi), the marginal k for θi can be deﬁned as

(cid:40)

ki = inf

0 < k(cid:48) < 1 : Eq

(cid:19) 1
k(cid:48)

(cid:18) p(θi|y)
q(θi)

(cid:41)

< ∞

.

The marginal ki is never larger (and usually smaller) than
the joint k in (4).

Proposition 1. For any two distributions p and q with
support Θ and the margin index i, if there is a num-
ber α > 1 satisfying Eq (p(θ)/q(θ))α < ∞,
then
Eq (p(θi)/q(θi))α < ∞.

Proposition 1 demonstrates why the importance sampling
is usually inefﬁcient in high dimensional sample space, in
that the joint estimation is “worse” than any of the marginal
estimation.

Should we extend the PSIS diagnostics to marginal distri-
butions? We ﬁnd two reasons why the marginal PSIS diag-
nostics can be misleading. Firstly, unlike the easy access
to the unnormalized joint posterior distribution p(θ, y), the
true marginal posterior density p(θi|y) is typically unknown,
otherwise one can conduct one-dimensional sampling easily
to obtain the the marginal samples. Secondly, a smaller ˆki
does not necessary guarantee a well-performed marginal
estimation. The marginal approximations in variational in-
ference can both over-estimate and under-estimate the tail

thickness of one-dimensional distributions, the latter situa-
tion gives rise to a smaller ˆki. Section 4.3 gives an example,
where the marginal approximations with extremely small
marginal k have large estimation errors. This does not hap-
pen in the joint case as the direction of the Kullback-Leibler
divergence q∗(θ) strongly penalizes too-heavy tails, which
makes it unlikely that the tails of the variational posterior
are signiﬁcantly heavier than the tails of the true posterior.

3. Assessing the Average Performance of the

Point Estimate

The proposed PSIS diagnostic assesses the quality of the
VI approximation to the full posterior distribution. It is
often observed that while the VI posterior may be a poor
approximation to the full posterior, point estimates that are
derived from it may still have good statistical properties. In
this section, we propose a new method for assessing the
calibration of the center of a VI posterior.

3.1. The Variational Simulation-Based Calibration

(VSBC) Diagnostic

This diagnostic is based on the proposal of Cook et al. (2006)
for validating general statistical software. They noted that if
θ(0) ∼ p(θ) and y ∼ p(y | θ(0)), then

Pr(y,θ(0))

(cid:16)

(cid:17)
Prθ|y(θ < θ(0)) ≤ ·)

= Unif[0,1]([0, ·]).

To use the observation of Cook et al. (2006) to assess the per-
formance of a VI point estimate, we propose the following
procedure. Simulate M > 1 data sets {yj}M
j=1 as follows:
Simulate θ(0)
j ∼ p(θ) and then simulate y(j) ∼ p(y | θ(0)
j ),
where y(j) has the same dimension as y. For each of
these data sets, construct a variational approximation to
p(θ | yj) and compute the marginal calibration probabilities
(cid:17)
pij = Prθ|y(j)
.

θi ≤ [θ(0)

]i

(cid:16)

j

To apply the full procedure of Cook et al. (2006), we would
need to test dim(θ) histograms for uniformity, however this
would be too stringent a check as, like our PSIS diagnostic,
this test is only passed if the variational posterior is a good
Instead, we follow
approximation to the true posterior.
an observation of Anderson (1996) from the probabilistic
forecasting validation literature and note that asymmetry
in the histogram for pi: indicates bias in the variational
approximation to the marginal posterior θi | y.

The VSBC diagnostic tests for symmetry of the marginal cal-
ibration probabilities around 0.5 and either by visual inspec-
tion of the histogram or by using a Kolmogorov-Smirnov
(KS) test to evaluate whether pi: and 1 − pi: have the same
distribution. When θ is a high-dimensional parameter, it
is important to interpret the results of any hypothesis tests

Evaluating Variational Inference

Algorithm 2 VSBC marginal diagnostics

1: Input: prior density p(θ), data likelihood p(y | θ);
number of replications M ; parameter dimensions K;

j

4:
5:

(cid:1) from p(y | θ(0)

2: for j = 1 : M do
Generate θ(0)
from prior p(θ);
3:
Generate a size-n dataset (cid:0)y(j)
Run variational inference using dataset y(j), obtain a
VI approximation distribution qj(·)
for i = 1 : K do
Label θ(0)
Label θ∗
Calculate pij = Pr(θ(0)

ij as the i-th marginal component of θ(0)
j
i as the i-th marginal component of θ∗;

i | θ∗ ∼ qj)

ij < θ∗

j );

6:
7:

;

end for

8:
9:
10: end for
11: for i = 1 : K do
12:
13:

14: end for

Test if the distribution of {pij}M
If rejected, the VI approximation is biased in its i-th
margin.

j=1 is symmetric;

through a multiple testing lens.

3.2. Understanding the VSBC Diagnostic

Unlike the PSIS diagnostic, which focuses on a the perfor-
mance of variational inference for a ﬁxed data set y, the
VSBC diagnostic assesses the average calibration of the
point estimation over all datasets that could be constructed
from the model. Hence, the VSBC diagnostic operates
under a different paradigm to the PSIS diagnostic and we
recommend using both as appropriate.

There are two disadvantages to this type of calibration when
compared to the PSIS diagnostic. As is always the case
when interpreting hypothesis tests, just because something
works on average doesn’t mean it will work for a particular
realization of the data. The second disadvantage is that this
diagnostic does not cover the case where the observed data
is not well represented by the model. We suggest interpret-
ing the diagnostic conservatively: if a variational inference
scheme fails the diagnostic, then it will not perform well on
the model in question. If the VI scheme passes the diagnos-
tic, it is not guaranteed that it will perform well for real data,
although if the model is well speciﬁed it should do well.

With stronger assumptions, The VSBC test can be formal-
ized as in Proposition 2.

Proposition 2. Denote θ as a one-dimensional parameter
that is of interest. Suppose in addition we have: (i) the
VI approximation q is symmetric; (ii) the true posterior
p(θ|y) is symmetric. If the VI estimation q is unbiased, i.e.,
Eθ∼q(θ|y) θ = Eθ∼p(θ|y) θ, then the distribution of VSBC
p-value is symmetric. Otherwise, if the VI estimation is
positively/negatively biased, then the distribution of VSBC
p-value is right/left skewed.

The symmetry of the true posterior is a stronger assumption
than is needed in practice for this result to hold. In the
forecast evaluation literature, as well as the literature on
posterior predictive checks, the symmetry of the histogram
is a commonly used heuristic to assess the potential bias of
the distribution. In our tests, we have seen the same thing
occurs: the median of the variational posterior is close to
the median of the true posterior when the VSBC histogram
is symmetric. We suggest again that this test be interpreted
conservatively: if the histogram is not symmetric, then the
VI is unlikely to have produced a point estimate close to the
median of the true posterior.

4. Applications

Both PSIS and VSBC diagnostics are applicable to any
variational inference algorithm. Without loss of generality,
we implement mean-ﬁeld Gaussian automatic differentiation
variational inference (ADVI) in this section.

4.1. Linear Regression

Consider a Bayesian linear regression y ∼ N(Xβ, σ2) with
prior {βi}K
i=1 ∼ N(0, 1), σ ∼ gamma(.5, .5). We ﬁx sam-
ple size n = 10000 and number of regressors K = 100.

Figure 1 visualizes the VSBC diagnostic, showing the dis-
tribution of VSBC p-values of the ﬁrst two regression coef-
ﬁcients β1, β2 and log σ based on M = 1000 replications.
The two sided Kolmogorov-Smirnov test for p: and 1 − p: is
only rejected for pσ:, suggesting the VI approximation is in
average marginally unbiased for β1 and β2, while σ is over-
estimated as pσ is right-skewed. The under-estimation of
posterior variance is reﬂected by the U-shaped distributions.

The VSBC diagnostic has some advantages compared to
the PSIS diagnostic. It is well understood that, for complex
models, the VI posterior can be used to produce a good point
estimate even when it is far from the true posterior. In this
case, the PSIS diagnostic will most likely indicate failure.
The second advantage is that unlike the PSIS diagnostic, the
VSBC diagnostic considers one-dimensional marginals θi
(or any functional h(θ)), which allows for a more targeted
interrogation of the ﬁtting procedure.

Using one randomly generated dataset in the same problem,
the PSIS ˆk is 0.61, indicating the joint approximation is
close to the true posterior. However, the performance of
ADVI is sensitive to the stopping time, as in any other opti-
mization problems. As displayed in the left panel of Figure
2, changing the threshold of relative ELBO change from
a conservative 10−5 to the default recommendation 10−2
increases ˆk to 4.4, even though 10−2 works ﬁne for many
other simpler problems. In this example, we can also view ˆk

Evaluating Variational Inference

Figure 1. VSBC diagnostics for β1, β2 and log σ in the Bayesian
linear regression example. The VI estimation overestimates σ as
pσ is right-skewed, while β1 and β2 is unbiased as the two-sided
KS-test is not rejected.

Figure 3. In the logistic regression example, as the correlation in
design matrix increase, the correlation in parameter space also
increases, leading to larger ˆk. Such ﬂaw is hard to tell from the
VI log predictive density (lpd), as a larger correlation makes the
prediction easier. ˆk diagnose the discrepancy of VI lpd and true
posterior lpd, with a sharp jump at 0.7.

Figure 2. ADVI is sensitive to the stopping time in the linear re-
gression example. The default 0.01 threshold lead to a fake con-
vergence, which can be diagnosed by monitoring PSIS ˆk. PSIS
adjustment always shrinks the estimation errors.

as a convergence test. The right panel shows ˆk diagnoses es-
timation error, which eventually become negligible in PSIS
adjustment when ˆk < 0.7. To account for the uncertainty
of stochastic optimization and ˆk estimation, simulations are
repeated 100 times.

4.2. Logistic Regression

Next we run ADVI to a logistic regression Y ∼
Bernoulli (cid:0)logit−1(βX)(cid:1) with a ﬂat prior on β. We gener-
ate X = (x1, . . . , xn) from N(0, (1 − ρ)IK×K + ρ1K×K)
such that the correlation in design matrix is ρ, and ρ is
changed from 0 to 0.99. The ﬁrst panel in Figure 3 shows
PSIS ˆk increases as the design matrix correlation increases.
It is not monotonic because β is initially negatively corre-
lated when X is independent. A large ρ transforms into a
large correlation for posterior distributions in β, making it
harder to be approximated by a mean-ﬁeld family, as can
be diagnosed by ˆk. In panel 2 we calculate mean log pre-
dictive density (lpd) of VI approximation and true posterior
using 200 independent test sets. Larger ρ leads to worse
mean-ﬁeld approximation, while prediction becomes eas-
ier. Consequently, monitoring lpd does not diagnose the VI
behavior; it increases (misleadingly suggesting better ﬁt)
as ρ increases. In this special case, VI has larger lpd than
the true posterior, due to the VI under-dispersion and the
model misspeciﬁcation. Indeed, if viewing lpd as a function
h(β), it is the discrepancy between VI lpd and true lpd that
reveals the VI performance, which can also be diagnosed
by ˆk. Panel 3 shows a sharp increase of lpd discrepancy
around ˆk = 0.7, consistent with the empirical threshold we
suggest.

Figure 4. In the logistic regression with varying correlations, the
ˆk diagnoses the root mean square of ﬁrst and second moment
errors. No estimation is reliable when ˆk > 0.7. Meanwhile, PSIS
adjustment always shrinks the VI estimation errors.

Figure 4 compares the ﬁrst and second moment root mean
square errors (RMSE) ||Epβ − Eq∗ β||2 and ||Epβ2 −
Eq∗ β2||2 in the previous example using three estimates:
(a) VI without post-adjustment, (b) VI adjusted by vanilla
importance sampling, and (c) VI adjusted by PSIS.
PSIS diagnostic accomplishes two tasks here: (1) A small ˆk
indicates that VI approximation is reliable. When ˆk > 0.7,
all estimations are no longer reasonable so the user should
be alerted. (2) It further improves the approximation using
PSIS adjustment, leading to a quicker convergence rate and
smaller mean square errors for both ﬁrst and second moment
estimation. Plain importance sampling has larger RMSE for
it suffers from a larger variance.

4.3. Re-parametrization in a Hierarchical Model

The Eight-School Model (Gelman et al., 2013, Section 5.5)
is the simplest Bayesian hierarchical normal model. Each
school reported the treatment effect mean yi and standard
deviation σi separately. There was no prior reason to believe
that any of the treatments were more effective than any other,
so we model them as independent experiments:

yj|θj ∼ N(θj, σ2
µ ∼ N(0, 5),

j ),

θj|µ, τ ∼ N(µ, τ 2),
τ ∼ half−Cauchy(0, 5).

1 ≤ j ≤ 8,

where θj represents the treatment effect in school j, and µ
and τ are the hyper-parameters shared across all schools.

Evaluating Variational Inference

Figure 6. In the eight-school example, the VSBC diagnostic veri-
ﬁes VI estimation of θ1 is unbiased as the distribution of pθ1: is
symmetric. τ is overestimated in the centered parametrization and
underestimated in the non-centered one, as told by the right/ left
skewness of pτ :.

tion. As shown by the top right panel in Figure 5, the joint
ˆk for the non-centered ADVI decreases to 0.64 which indi-
cated the approximation is not perfect but reasonable and
usable. The bottom-right panel demonstrates that the re-
parametrized ADVI posterior is much closer to the truth,
and has smaller biases for both ﬁrst and second moment
estimations.

We can assess the marginal estimation using VSBC diagnos-
tic, as summarized in Figure 6. In the centered parametriza-
tion, the point estimation for θ1 is in average unbiased, as
the two-sided KS-test is not rejected. The histogram for τ
is right-skewed, for we can reject one-sided KS-test with
the alternative to be pτ : being stochastically smaller than
pτ :. Hence we conclude τ is over-estimated in the centered
parameterization. On the contrast, the non-centered τ is
negatively biased, as diagnosed by the left-skewness of pτ :.
Such conclusion is consistent with the bottom-right panel in
Figure 5.

To sum up, this example illustrates how the Gaussian fam-
ily assumption can be unrealistic even for a simple hier-
archical model. It also clariﬁes VI posteriors can be both
over-dispersed and under-dispersed, depending crucially on
the true parameter dependencies. Nevertheless, the recom-
mended PSIS and VSBC diagnostics provide a practical
summary of the computation result.

4.4. Cancer Classiﬁcation Using Horseshoe Priors

We illustrate how the proposed diagnostic methods work
in the Leukemia microarray cancer dataset that contains
D = 7129 features and n = 72 observations. Denote y1:n
as binary outcome and Xn×D as the predictor, the logistic
regression with a regularized horseshoe prior (Piironen &
Vehtari, 2017) is given by

y|β ∼ Bernoulli (cid:0)logit−1 (Xβ)(cid:1) ,
τ ∼ C+(0, τ0),
λj ∼ C+(0, 1),

βj|τ, λ, c ∼ N(0, τ 2˜λ2
j ),
c2 ∼ Inv−Gamma(2, 8).

where τ > 0 and λ > 0 are global and local shrinkage
(cid:1). The regularized
parameters, and ˜λ2

j / (cid:0)c2 + τ 2λ2

j = c2λ2

j

Figure 5. The upper two panels shows the joint and marginal PSIS
diagnostics of the eight-school example. The centered parame-
terization has ˆk > 0.7, for it cannot capture the funnel-shaped
dependency between τ and θ. The bottom-right panel shows the
bias of posterior mean and standard errors of marginal distribu-
tions. Positive bias of τ leads to over-dispersion of θ.

In this hierarchical model, the conditional variance of θ is
strongly dependent on the standard deviation τ , as shown by
the joint sample of µ and log τ in the bottom-left corner in
Figure 5. The Gaussian assumption in ADVI cannot capture
such structure. More interestingly, ADVI over-estimates the
posterior variance for all parameters θ1 through θ8, as shown
by positive biases of their posterior standard deviation in
the last panel. In fact, the posterior mode is at τ = 0, while
the entropy penalization keeps VI estimation away from it,
leading to an overestimation due to the funnel-shape. Since
j + τ −2(cid:1)−1
the conditional expectation E[θi|τ, y, σ] = (cid:0)σ−2
is an increasing function on τ , a positive bias of τ produces
over-dispersion of θ.

The top left panel shows the marginal and joint PSIS di-
agnostics. The joint ˆk is 1.00, much beyond the threshold,
while the marginal ˆk calculated through the true marginal
distribution for all θ are misleadingly small due to the over-
dispersion.
Alerted by such large ˆk, researchers should seek some im-
provements, such as re-parametrization. The non-centered
parametrization extracts the dependency between θ and τ
through a transformation θ∗ = (θ − µ)/τ :

yj|θj ∼ N(µ + τ θ∗

j , σ2

j ),

θ∗
j ∼ N(0, 1).

There is no general rule to determine whether non-centered
parametrization is better than the centered one and there
are many other parametrization forms. Finding the optimal
parametrization can be as hard as ﬁnding the true posterior,
but ˆk diagnostics always guide the choice of parametriza-

Evaluating Variational Inference

horseshoe prior adapts to the sparsity and allows us to spec-
ify a minimum level of regularization to the largest values.

ADVI is computationally appealing for it only takes a few
minutes while MCMC sampling takes hours on this dataset.
However, PSIS diagnostic gives ˆk = 9.8 for ADVI, sug-
gesting the VI approximation is not even close to the true
posterior. Figure 7 compares the ADVI and true posterior
density of β1834, log λ1834 and τ . The Gaussian assumption
makes it impossible to recover the bimodal distribution of
some β.

Figure 7. The comparison of ADVI and true posterior density of
θ1834, log λ1834 and τ in the horseshoe logistic regression. ADVI
misses the right mode of log λ, making β ∝ λ become a spike.

Figure 8. VSBC test in the horseshoe logistic regression. It tells the
positive bias of τ and negative bias of λ1834. β1834 is in average
unbiased for its symmetric prior.

The VSBC diagnostics as shown in Figure 8 tell the neg-
ative bias of local shrinkage λ1834 from the left-skewness
of plog λ1834, which is the consequence of the right-missing
mode. For compensation, the global shrinkage τ is over-
estimated, which is in agreement with the right-skewness
of plog τ . β1834 is in average unbiased, even though it is
strongly underestimated from in Figure 7. This is because
VI estimation is mostly a spike at 0 and its prior is symmet-
ric. As we have explained, passing the VSBC test means the
average unbiasedness, and does not ensure the unbiasedness
for a speciﬁc parameter setting. This is the price that VSBC
pays for averaging over all priors.

5. Discussion

5.1. The Proposed Diagnostics are Local

As no single diagnostic method can tell all problems, the
proposed diagnostic methods have limitations. The PSIS
diagnostic is limited when the posterior is multimodal as
the samples drawn from q(θ) may not cover all the modes
of the posterior and the estimation of k will be indifferent
to the unseen modes. In this sense, the PSIS diagnostic is

a local diagnostic that will not detect unseen modes. For
example, imagine the true posterior is p = 0.8N(0, 0.2) +
0.2N(3, 0.2) with two isolated modes. Gaussian family VI
will converge to one of the modes, with the importance ratio
to be a constant number 0.8 or 0.2. Therefore k is 0, failing
to penalize the missing density. In fact, any divergence
measure based on samples from the approximation such as
KL(q, p) is local.

The bi-modality can be detected by multiple over-dispersed
initialization. It can also be diagnosed by other divergence
measures such as KL(p, q) = Ep log(q/p), which is com-
putable through PSIS by letting h = log(q/p).

In practice a marginal missing mode will typically lead to
large joint discrepancy that is still detectable by ˆk, such as
in Section 4.4.

The VSBC test, however, samples the true parameter from
the prior distribution directly. Unless the prior is too restric-
tive, the VSBC p-value will diagnose the potential missing
mode.

5.2. Tailoring Variational Inference for Importance

Sampling

The PSIS diagnostic makes use of stabilized IS to diag-
nose VI. By contrast, can we modify VI to give a better IS
proposal?

Geweke (1989) introduce an optimal proposal distribution
based on split-normal and split-t, implicitly minimizing
the χ2 divergence between q and p. Following this idea,
we could ﬁrst ﬁnd the usual VI solution, and then switch
Gaussian to Student-t with a scale chosen to minimize the
χ2 divergence.

More recently, some progress is made to carry out varia-
tional inference based on R´enyi divergence (Li & Turner,
2016; Dieng et al., 2017). But a big α, say α = 2, is only
meaningful when the proposal has a much heavier tail than
the target. For example, a normal family does not contain
any member having ﬁnite χ2 divergence to a Student-t dis-
tribution, leaving the optimal objective function deﬁned by
Dieng et al. (2017) inﬁnitely large.

There are several research directions. First, our proposed
diagnostics are applicable to these modiﬁed approximation
methods. Second, PSIS re-weighting will give a more re-
liable importance ratio estimation in the R´enyi divergence
variational inference. Third, a continuous ˆk and the cor-
responding α are more desirable than only ﬁxing α = 2,
as the latter one does not necessarily have a ﬁnite result.
Considering the role ˆk plays in the importance sampling, we
can optimize the discrepancy Dα(q||p) and α > 0 simulta-
neously. We leave this for future research.

Evaluating Variational Inference

Acknowledgements

The authors acknowledge support from the Ofﬁce of Naval
Research grants N00014-15-1-2541 and N00014-16-P-2039,
the National Science Foundation grant CNS-1730414, and
the Academy of Finland grant 313122.

References

Giordano, R., Broderick, T., and Jordan, M. I. Covari-
ances, robustness, and variational Bayes. arXiv preprint
arXiv:1709.02536, 2017.

Hoffman, M. D. and Gelman, A. The No-U-Turn sampler:
adaptively setting path lengths in Hamiltonian Monte
Carlo. Journal of Machine Learning Research, 15(1):
1593–1623, 2014.

Anderson, J. L. A method for producing and evaluating
probabilistic forecasts from ensemble model integrations.
Journal of Climate, 9(7):1518–1530, 1996.

Hoffman, M. D., Blei, D. M., Wang, C., and Paisley, J.
Stochastic variational inference. The Journal of Machine
Learning Research, 14(1):1303–1347, 2013.

Blei, D. M., Kucukelbir, A., and McAuliffe, J. D. Varia-
tional inference: A review for statisticians. Journal of
the American Statistical Association, 112(518):859–877,
2017.

Chee, J. and Toulis, P. Convergence diagnostics for stochas-
tic gradient descent with constant step size. arXiv preprint
arXiv:1710.06382, 2017.

Chen, L. H., Shao, Q.-M., et al. Normal approximation
under local dependence. The Annals of Probability, 32
(3):1985–2028, 2004.

Cook, S. R., Gelman, A., and Rubin, D. B. Validation of
software for Bayesian models using posterior quantiles.
Journal of Computational and Graphical Statistics, 15
(3):675–692, 2006.

Cortes, C., Mansour, Y., and Mohri, M. Learning bounds for
importance weighting. In Advances in neural information
processing systems, pp. 442–450, 2010.

Cortes, C., Greenberg, S., and Mohri, M. Relative deviation
learning bounds and generalization with unbounded loss
functions. arXiv preprint arXiv:1310.5796, 2013.

Dieng, A. B., Tran, D., Ranganath, R., Paisley, J., and
Blei, D. Variational inference via chi upper bound mini-
mization. In Advances in Neural Information Processing
Systems, pp. 2729–2738, 2017.

Epifani, I., MacEachern, S. N., Peruggia, M., et al. Case-
deletion importance sampling estimators: Central limit
theorems and related results. Electronic Journal of Statis-
tics, 2:774–806, 2008.

Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B.,
Vehtari, A., and Rubin, D. B. Bayesian data analysis.
CRC press, 2013.

Ionides, E. L. Truncated importance sampling. Journal of
Computational and Graphical Statistics, 17(2):295–311,
2008.

Koopman, S. J., Shephard, N., and Creal, D. Testing the
assumptions behind importance sampling. Journal of
Econometrics, 149(1):2–11, 2009.

Kucukelbir, A., Tran, D., Ranganath, R., Gelman, A., and
Blei, D. M. Automatic differentiation variational infer-
ence. Journal of Machine Learning Research, 18(14):
1–45, 2017.

Li, Y. and Turner, R. E. R´enyi divergence variational in-
ference. In Advances in Neural Information Processing
Systems, pp. 1073–1081, 2016.

Pﬂug, G. C. Non-asymptotic conﬁdence bounds for stochas-
tic approximation algorithms with constant step size.
Monatshefte f¨ur Mathematik, 110(3):297–314, 1990.

Piironen, J. and Vehtari, A. Sparsity information and reg-
ularization in the horseshoe and other shrinkage priors.
Electronic Journal of Statistics, 11(2):5018–5051, 2017.

Ranganath, R., Gerrish, S., and Blei, D. Black box varia-
tional inference. In Artiﬁcial Intelligence and Statistics,
pp. 814–822, 2014.

R´enyi, A. et al. On measures of entropy and information.
In Proceedings of the Fourth Berkeley Symposium on
Mathematical Statistics and Probability, Volume 1: Con-
tributions to the Theory of Statistics. The Regents of the
University of California, 1961.

Rezende, D. J., Mohamed, S., and Wierstra, D. Stochas-
tic backpropagation and approximate inference in deep
generative models. In Proceedings of the 31st Interna-
tional Conference on Machine Learning (ICML-14), pp.
1278–1286, 2014.

Geweke, J. Bayesian inference in econometric models us-
ing Monte Carlo integration. Econometrica, 57(6):1317–
1339, 1989.

Sielken, R. L. Stopping times for stochastic approximation
procedures. Probability Theory and Related Fields, 26
(1):67–75, 1973.

Evaluating Variational Inference

Stan Development Team. Stan modeling language users
guide and reference manual. http://mc-stan.org,
2017. Version 2.17.

Stroup, D. F. and Braun, H. I. On a new stopping rule
for stochastic approximation. Probability Theory and
Related Fields, 60(4):535–554, 1982.

Vehtari, A., Gelman, A., and Gabry, J. Pareto smoothed
importance sampling. arXiv preprint arXiv:1507.02646,
2017.

Vehtari, A., Gabry, J., Yao, Y., and Gelman, A. loo: Efﬁcient
leave-one-out cross-validation and waic for bayesian mod-
els, 2018. URL https://CRAN.R-project.org/
package=loo. R package version 2.0.0.

Wada, T. and Fujisaki, Y. A stopping rule for stochastic
approximation. Automatica, 60:1–6, 2015. ISSN 0005-
1098.

Supplement to “Yes, but Did It Work?: Evaluating Variational Inference”

A. Sketch of Proofs
A.1. Proof to Proposition 1: Marginal ˆk in PSIS diagnostic

Proposition 1. For any two distributions p and q with support Θ and the margin index i, if there is a number α > 1
satisfying Eq (p(θ)/q(θ))α < ∞, then Eq (p(θi)/q(θi))α < ∞.

Proof. Without loss of generality, we could assume Θ = RK, otherwise a smooth transformation is conducted.
For any 1 ≤ i ≤ K, p(θ−i|θi) and q(θ−i|θi) deﬁne the conditional distribution of (θ1, . . . , θi−1, θi+1, . . . , θK) ∈ RK−1
given θi under the true posterior p and the approximation q separately.

For any given index α > 1, Jensen inequality yields

(cid:90)

RK−1

(cid:19)α

(cid:18) p(θ−i|θi)
q(θ−i|θi)

q(θ−i|θi) ≥

(cid:18)(cid:90)

p(θ−i|θi)
q(θ−i|θi)

RK−1

(cid:19)α

q(θ−i|θi)

= 1

Hence

(cid:90)

RK

(cid:19)α

(cid:18) p(θ)
q(θ)

q(θ)dθ =

(cid:19)α

(cid:90)

RK−1
(cid:18)(cid:90)

(cid:90)

(cid:90)

R

(cid:18) p(θi)p(θ−i|θi)
q(θi)q(θ−i|θi)
(cid:18) p(θ−i|θi)
(cid:19)α
q(θ−i|θi)

=

≥

R

RK−1

(cid:90)

(cid:18) p(θi)
q(θi)

R

(cid:19)α

q(θi)dθi

q(θi)q(θ−i|θi)dθidθ−i

q(θ−i|θi)dθ−i

q(θi)dθi

(cid:19)α

(cid:19) (cid:18) p(θi)
q(θi)

A.2. Proof to Proposition 2: Symmetry in VSBC-Test

Proposition 2. For a one-dimensional parameter θ that is of interest, Suppose in addition we have:
(i) the VI approximation q is symmetric;
(ii) the true posterior p(θ|y) is symmetric.
If the VI estimation q is unbiased, i.e.,

Eθ∼q(θ|y) θ = Eθ∼p(θ|y) θ, ∀y

Then the distribution of VSBC p-value is symmetric.
If the VI estimation is positively/negatively biased, then the distribution of VSBC p-value is right/left skewed.

In the proposition we write q(θ|y) to emphasize that the VI approximation also depends on the observed data.

Proof. First, as the same logic in (Cook et al., 2006), when θ(0) is sampled from its prior p(θ) and simulated data y sampled
from likelihood p(y|θ(0)), (y, θ(0)) represents a sample from the joint distribution p(y, θ) and therefore θ(0) can be viewed
as a draw from p(θ|y), the true posterior distribution of θ with y being observed.

We denote q(θ(0)) as the VSBC p-value of the sample θ(0). Also denote Qx(f ) as the x−quantile (x ∈ [0, 1]) of any
distribution f . To prove the result, we need to show

1 − Pr(q(θ(0)) < x) = Pr(q(θ(0)) < 1 − x), ∀x ∈ [0, 1],

Supplement to “Evaluating Variational Inference”

LHS = Pr

q(θ(0)) > x

(cid:17)

= Pr

θ(0) > Qx (q(θ|y))

(cid:17)

.

(cid:16)

(cid:16)

(cid:17)

RHS = Pr

θ(0) < Q1−x (q(θ|y))

= Pr

θ(0) < 2Eq(θ|y)θ − Qx (q(θ|y))

(cid:16)

(cid:17)

(cid:17)

= Pr

θ(0) < 2Ep(θ|y)θ − Qx (q(θ|y))

= Pr

(cid:16)

(cid:17)
θ(0) > Qx (q(θ|y))

(cid:16)

(cid:16)

= LHS

The ﬁrst equation above uses the symmetry of q(θ|y), the second equation comes from the the unbiasedness condition. The
third is the result of the symmetry of p(θ|y).

If the VI estimation is positively biased, Eθ∼q(θ|y) θ > Eθ∼p(θ|y) θ, ∀y, then we change the second equality sign into a
less-than sign.

B. Details of Simulation Examples

In this section, we give more detailed description of the simulation examples in the manuscript. We use Stan (Stan
Development Team, 2017) to implement both automatic differentiation variational inference (ADVI) and Markov chain
Monte Carlo (MCMC) sampling. We implement Pareto smoothing through R package “loo” (Vehtari et al., 2018). We also
provide all the source code in https://github.com/yao-yl/Evaluating-Variational-Inference.

B.1. Linear and Logistic Regressions

In Section 4.1, We start with a Bayesian linear regression y ∼ N(Xβ, σ2) without intercept. The prior is set as {βi}d
i=1 ∼
N(0, 1), σ ∼ gamma(0.5, 0.5). We ﬁx sample size n = 10000 and number of regressors d = 100. Figure IX displays the
Stan code.

//number of observations, we fix n=10000 in the simulation;

//number of predictor variables,

fix d=100;

// predictors;

// outcome;

,

1 data {
2 int <lower=0> n;
3 int <lower=0> d;
4 matrix [n,d] x ;
5 vector [n] y;
6 }
7 parameters {
8 vector [d] b;
9 real <lower=0> sigma;
10 }
11 model {
12 y ∼ normal(x * b, sigma);
13 b ∼ normal(0,1); // prior for
14 sigma ∼ gamma(0.5,0.5);
15 }
16

// linear regression coefficient;

//linear regression std;

regression coefficient;

// prior for

regression std.

Figure IX. Stan code for linear regressions

We ﬁnd ADVI can be sensitive to the stopping time. Part of the reason is the objective function itself is evaluated through
Monte Carlo samples, producing large uncertainty. In the current version of Stan, ADVI computes the running average and
running median of the relative ELBO norm changes. Should either number fall below a threshold tol rel obj, with the
default value to be 0.01, the algorithm is considered converged.

In Figure 1 of the main paper, we run VSBC test on ADVI approximation. ADVI is deliberately tuned in a conservative way.
The convergence tolerance is set as tol rel obj=10−4 and the learning rate is η = 0.05. The predictor X105×102 is ﬁxed

Supplement to “Evaluating Variational Inference”

in all replications and is generated independently from N(0, 1). To avoid multiple-comparison problem, we pre-register the
ﬁrst and second coefﬁcients β1 β2 and log σ before the test. The VSBC diagnostic is based on M = 1000 replications.

In Figure 2 we independently generate each coordinate of β from N(0, 1) and set a relatively large variance σ = 2. The
predictor X is generated independently from N(0, 1) and y is sampled from the normal likelihood. We vary the threshold
tol rel obj from 0.01 to 10−5 and show the trajectory of ˆk diagnostics. The ˆk estimation, IS and PSIS adjustment are
all calculated from S = 5 × 104 posterior samples. We ignore the ADVI posterior sampling time. The actual running time is
based on a laptop experiment result (2.5 GHz processor, 8 cores).The exact sampling time is based on the No-U-Turn Sampler
(NUTS, Hoffman & Gelman 2014) in Stan with 4 chains and 3000 iterations in each chain. We also calculate the root mean
square errors (RMSE) of all parameters ||Ep[(β, σ)] − Eq[(β, σ)]||L2 , where (β, σ) represents the combined vector of all β
and σ. To account for the uncertainty, ˆk, running time, and RMSE takes the average of 50 repeated simulations.

//number of predictor variables;

// predictors; we vary its correlation during simulations.

,

1

2

3

4

5

6

7

8

9

10

11

12

13

//number of observations;

data {
int <lower=0> n;
int <lower=0> d;
matrix [n,d] x ;
int<lower=0,upper=1> y[n]; // binary outcome;
}
parameters {
vector[d] beta;
}
model {
y ∼ bernoulli_logit(x*beta);
}

Figure X. Stan code for logistic regressions

Figure 3 and 4 in the main paper is a simulation result of a logistic regression
Y ∼ Bernoulli (cid:0)logit−1(βX)(cid:1)

with a ﬂat prior on β. We vary the correlation in design matrix by generating X from N(0, (1 − ρ)Id×d + ρ1d×d), where
1d×d represents the d by d matrix with all elements to be 1. In this experiment we ﬁx a small number n = 100 and d = 2
since the main focus is parameter correlations. We compare ˆk with the log predictive density, which is calculated from
100 independent test data. The true posterior is from NUTS in Stan with 4 chains and 3000 iterations each chain. The
ˆk estimation, IS and PSIS adjustment are calculated from 105 posterior samples. To account for the uncertainty, ˆk, log
predictive density, and RMSE are the average of 50 repeated experiments.

B.2. Eight-School Model

The eight-school model is named after Gelman et al. (2013, section 5.5). The study was performed for the Educational
Testing Service to analyze the effects of a special coaching program on students’ SAT-V (Scholastic Aptitude Test Verbal)
scores in each of eight high schools. The outcome variable in each study was the score of a standardized multiple choice test.
Each school i separately analyzed the treatment effect and reported the mean yi and standard deviation of the treatment
effect estimation σi, as summarized in Table 1.

There was no prior reason to believe that any of the eight programs was more effective than any other or that some were more
similar in effect to each other than to any other. Hence, we view them as independent experiments and apply a Bayesian
hierarchical normal model:

yj|θj ∼ N(θj, σj),
µ ∼ N(0, 5),

θj ∼ N(µ, τ ),
τ ∼ half−Cauchy(0, 5).

1 ≤ j ≤ 8,

where θj represents the underlying treatment effect in school j, while µ and τ are the hyper-parameters that are shared
across all schools.

There are two parametrization forms being discussed: centered parameterization and non-centered parameterization.
Listing XI and XII give two Stan codes separately. The true posterior is from NUTS in Stan with 4 chains and 3000 iterations

Supplement to “Evaluating Variational Inference”

School Index j Estimated Treatment Effect yi Standard Deviation of Effect Estimate σj

1
2
3
4
5
6
7
8

28
8
-3
7
-1
1
8
12

15
10
16
11
9
11
10
18

Table 1. School-level observed effects of special preparation on SAT-V scores in eight randomized experiments. Estimates are based on
separate analyses for the eight experiments.

// number of schools
// estimated treatment

// std

of estimated effect

,

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

data {
int<lower=0> J;
real y[J];
real<lower=0> sigma[J];
}

parameters {
real theta[J];
real mu;
real<lower=0> tau;
}
model {
theta ∼ normal(mu, tau);
y ∼ normal(theta, sigma);
mu ∼ normal(0, 5);
tau ∼ cauchy(0, 5);
}

// treatment effect in school j

// hyper-parameter of mean

// hyper-parameter of sdv

// a non-informative prior

Figure XI. Stan code for centered parametrization in the eight-school model. It leads to strong dependency between tau and theta.

each chain. The ˆk estimation and PSIS adjustment are calculated from S = 105 posterior samples. The marginal ˆk is
calculated by using the NUTS density, which is typically unavailable for more complicated problems in practice.

The VSBC test in Figure 6 is based on M = 1000 replications and we pre-register the ﬁrst treatment effect θ1 and group-level
standard error log τ before the test.

As discussed in Section 3.2, VSBC assesses the average calibration of the point estimation. Hence the result depends on the
choice of prior. For example, if we instead set the prior to be

µ ∼ N(0, 50),

τ ∼ N+(0, 25),

which is essentially ﬂat in the region of interesting part of the likelihood and more in agreement with the prior knowledge,
then the result of VSBC test change to Figure XIII. Again, the skewness of p-values veriﬁes VI estimation of θ1 is in average
unbiased while τ is biased in both centered and non-centered parametrization.

B.3. Cancer Classiﬁcation Using Horseshoe Priors

In Section 4.3 of the main paper we replicate the cancer classiﬁcation under regularized horseshoe prior as ﬁrst introduced
by Piironen & Vehtari (2017).

The Leukemia microarray cancer classiﬁcation dataset 1. It contains n = 72 observations and d = 7129 features Xn×d. X
is standardized before any further process. The outcome y1:n is binary, so we can ﬁt a logistic regression

yi|β ∼ Bernoulli

βjxij + β0



 .


logit−1





d
(cid:88)

j=1





1The Leukemia classiﬁcation dataset can be downloaded from http://featureselectiocn.asu.edu/datasets.php

Supplement to “Evaluating Variational Inference”

// number of schools
// estimated treatment

// std

of estimated effect

// transformation of theta

// hyper-parameter of mean

// hyper-parameter of sd

// original theta

,

1 data {
2 int<lower=0> J;
3 real y[J];
4 real<lower=0> sigma[J];
5 }
6 parameters {
7 vector[J] theta_trans;
8 real mu;
9 real<lower=0> tau;
10 }
11 transformed parameters{
12 vector[J] theta;
13 theta=theta_trans*tau+mu;
14 }
15 model {
16 theta_trans ∼normal (0,1);
17 y ∼ normal(theta, sigma);
18 mu ∼ normal(0, 5);
19 tau ∼ cauchy(0, 5);
20 }
21

// a non-informative prior

Figure XII. Stan code for non-centered parametrization in the eight-school model. It extracts the dependency between tau and theta.

Figure XIII. The VSBC diagnostic of the eight-school example under a non-informative prior µ ∼ N(0, 50), τ ∼ N+(0, 25). The skewness
of p-values veriﬁes VI estimation of θ1 is in average unbiased while τ is biased in both centered and non-centered parametrization.

There are far more predictors than observations, so we expect only a few of predictors to be related and therefore have a
regression coefﬁcient distinguishable from zero. Further, many predictors are correlated, making it necessary to have a
regularization.

To this end, we apply the regularized horseshoe prior, which is a generalization of horseshoe prior.

βj|τ, λ, c ∼ N(0, τ 2˜λ2
λj ∼ Half−Cauchy(0, 1),

j ),

c2 ∼ Inv−Gamma(2, 8),

τ |τ0 ∼ Half−Cauchy(0, τ0).

The scale of the global shrinkage is set according to the recommendation τ0 = 2 (cid:0)n1/2(d − 1)(cid:1)−1
shrink intercept so we put β0 ∼ N(0, 10). The Stan code is summarized in Figure XIV.

There is no reason to

We ﬁrst run NUTS in Stan with 4 chains and 3000 iterations each chain. We manually pick β1834, the coefﬁcient that has the
largest posterior mean. The posterior distribution of it is bi-modal with one spike at 0.

ADVI is implemented using the same parametrization and we decrease the learning rate η to 0.1 and the threshold
tol rel obj to 0.001
The ˆk estimation is based on S = 104 posterior samples. Since ˆk is extremely large, indicating VI is far away from the true
posterior and no adjustment will work, we do not further conduct PSIS.

Supplement to “Evaluating Variational Inference”

,

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

// local shrinkage parameter

// global shrinkage parameter

// number of observations
// number of predictors
// outputs
// inputs
// prior std for the intercept

data {
int<lower=0> n;
int<lower=0> d;
int<lower=0,upper=1> y[n];
matrix[n,d] x;
real<lower=0> scale_icept;
real<lower=0> scale_global; // scale for the half-t prior for tau
real<lower=0> slab_scale;
real<lower=0> slab_df;
}
parameters {
real beta0; // intercept
vector[d] z; // auxiliary parameter
real<lower=0> tau;
vector<lower=0>[d] lambda;
real<lower=0> caux; // auxiliary
}
transformed parameters {
real<lower=0> c;
vector[d] beta;
vector[n] f;
vector<lower=0>[d] lambda_tilde;
c = slab_scale * sqrt(caux);
lambda_tilde = sqrt( cˆ2 * square(lambda) ./ (cˆ2 + tauˆ2* square(lambda)) );
beta = z .* lambda_tilde*tau;
f = beta0 + x*beta;
}
model {
z ∼ normal(0,1);
lambda ∼ cauchy(0,1);
tau ∼ cauchy(0, scale_global);
caux ∼ inv_gamma(0.5*slab_df, 0.5*slab_df);
beta0 ∼ normal(0,scale_icept);
y ∼ bernoulli_logit(f);
}

// regression coefficients

// latent values

Figure XIV. Stan code for regularized horseshoe logistic regression.

In the VSBC test, we pre-register that pre-chosen coefﬁcient β1834, log λ1834 and global shrinkage log τ before the test. The
VSBC diagnostic is based on M=1000 replications.

Yes, but Did It Work?: Evaluating Variational Inference

8
1
0
2
 
l
u
J
 
7
 
 
]
L
M

.
t
a
t
s
[
 
 
2
v
8
3
5
2
0
.
2
0
8
1
:
v
i
X
r
a

Yuling Yao 1 Aki Vehtari 2 Daniel Simpson 3 Andrew Gelman 1

Abstract
While it’s always possible to compute a varia-
tional approximation to a posterior distribution,
it can be difﬁcult to discover problems with this
approximation. We propose two diagnostic al-
gorithms to alleviate this problem. The Pareto-
smoothed importance sampling (PSIS) diagnostic
gives a goodness of ﬁt measurement for joint dis-
tributions, while simultaneously improving the
error in the estimate. The variational simulation-
based calibration (VSBC) assesses the average
performance of point estimates.

1. Introduction

Variational Inference (VI), including a large family of pos-
terior approximation methods like stochastic VI (Hoffman
et al. 2013), black-box VI (Ranganath et al. 2014), automatic
differentiation VI (ADVI, Kucukelbir et al. 2017), and many
other variants, has emerged as a widely-used method for
scalable Bayesian inference. These methods come with few
theoretical guarantees and it’s difﬁcult to assess how well
the computed variational posterior approximates the true
posterior.

Instead of computing expectations or sampling draws from
the posterior p(θ | y), variational inference ﬁxes a fam-
ily of approximate densities Q, and ﬁnds the member q∗
minimizing the Kullback-Leibler (KL) divergence to the
true posterior: KL (q(θ), p(θ | y)) . This is equivalent to
maximizing the evidence lower bound (ELBO):

ELBO(q) =

(log p(θ, y) − log q(θ)) q(θ)dθ.

(1)

(cid:90)

Θ

There are many situations where the VI approximation is
ﬂawed. This can be due to the slow convergence of the

1Department of Statistics, Columbia University, NY, USA
2Helsinki Institute for Information Technology, Department of
Computer Science, Aalto University, Finland 3Department of Sta-
tistical Sciences, University of Toronto, Canada. Correspondence
to: Yuling Yao <yy2618@columbia.edu>.

Proceedings of the 35 th International Conference on Machine
Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018
by the author(s).

optimization problem, the inability of the approximation
family to capture the true posterior, the asymmetry of the
true distribution, the fact that the direction of the KL diver-
gence under-penalizes approximation with too-light tails, or
all these reasons. We need a diagnostic algorithm to test
whether the VI approximation is useful.

There are two levels of diagnostics for variational inference.
First the convergence test should be able to tell if the ob-
jective function has converged to a local optimum. When
the optimization problem (1) is solved through stochastic
gradient descent (SGD), the convergence can be assessed
by monitoring the running average of ELBO changes. Re-
searchers have introduced many convergence tests based on
the asymptotic property of stochastic approximations (e.g.,
Sielken, 1973; Stroup & Braun, 1982; Pﬂug, 1990; Wada &
Fujisaki, 2015; Chee & Toulis, 2017). Alternatively, Blei
et al. (2017) suggest monitoring the expected log predictive
density by holding out an independent test dataset. After
convergence, the optimum is still an approximation to the
truth. This paper is focusing on the second level of VI di-
agnostics whether the variational posterior q∗(θ) is close
enough to the true posterior p(θ|y) to be used in its place.

Purely relying on the objective function or the equivalent
ELBO does not solve the problem. An unknown multi-
plicative constant exists in p(θ, y) ∝ p(θ | y) that changes
with reparametrization, making it meaningless to compare
ELBO across two approximations. Moreover, the ELBO is
a quantity on an uninterpretable scale, that is it’s not clear at
what value of the ELBO we can begin to trust the variational
posterior. This makes it next to useless as a method to assess
how well the variational inference has ﬁt.

In this paper we propose two diagnostic methods that assess,
respectively, the quality of the entire variational posterior for
a particular data set, and the average bias of a point estimate
produced under correct model speciﬁcation.

The ﬁrst method is based on generalized Pareto distribution
diagnostics used to assess the quality of a importance sam-
pling proposal distribution in Pareto smoothed importance
sampling (PSIS, Vehtari et al., 2017). The beneﬁt of PSIS
diagnostics is two-fold. First, we can tell the discrepancy
between the approximate and the true distribution by the
estimated continuous ˆk value. When it is larger than a pre-
speciﬁed threshold, users should be alert of the limitation

Evaluating Variational Inference

of current variational inference computation and consider
further tuning it or turn to exact sampling like Markov chain
Monte Carlo (MCMC). Second, in the case when ˆk is small,
the fast convergence rate of the importance-weighted Monte
Carlo integration guarantees a better estimation accuracy. In
such sense, the PSIS diagnostics could also be viewed as a
post-adjustment for VI approximations. Unlike the second-
order correction Giordano et al. (2017), which relies on an
un-testable unbiasedness assumption, we make diagnostics
and adjustment at the same time.

The second diagnostic considers only the quality of the
median of the variational posterior as a point estimate (in
Gaussian mean-ﬁeld VI this corresponds to the modal es-
timate). This diagnostic assesses the average behavior of
the point estimate under data from the model and can in-
dicate when a systemic bias is present. The magnitude of
that bias can be monitored while computing the diagnostic.
This diagnostic can also assess the average calibration of
univariate functionals of the parameters, revealing if the
posterior is under-dispersed, over-dispersed, or biased. This
diagnostic could be used as a partial justiﬁcation for using
the second-order correction of Giordano et al. (2017).

2. Is the Joint Distribution Good Enough?

If we can draw a sample (θ1, . . . , θS) from p(θ|y), the ex-
pectation of any integrable function Ep[h(θ)] can be esti-
mated by Monte Carlo integration: (cid:80)S
s=1 h(θs)/S S→∞−−−−−→
Ep [h(θ)] . Alternatively, given samples (θ1, . . . , θS) from
a proposal distribution q(θ), the importance sampling (IS)
(cid:17)
s=1 h(θs)rs
s=1 rs, where the impor-
estimate is
tance ratios rs are deﬁned as

(cid:16)(cid:80)S

/(cid:80)S

rs =

p(θs, y)
q(θs)

.

In general, with a sample (θ1, . . . , θS) drawn from the varia-
tional posterior q(θ), we consider a family of estimates with
the form

Ep[h(θ)] ≈

(cid:80)S

s=1 h(θs)ws
(cid:80)S
s=1 ws

,

which contains two extreme cases:

1. When ws ≡ 1, estimate (3) becomes the plain VI esti-
mate that is we completely trust the VI approximation.
In general, this will be biased to an unknown extent
and inconsistent. However, this estimator has small
variance.

2. When ws = rs, (3) becomes importance sampling.
The strong law of large numbers ensures it is consistent

(2)

(3)

as S → ∞, and with small O(1/S) bias due to self-
normalization. But the IS estimate may have a large or
inﬁnite variance.

There are two questions to be answered. First, can we ﬁnd a
better bias-variance trade-off than both plain VI and IS?

Second, VI approximation q(θ) is not designed for an op-
timal IS proposal, for it has a lighter tail than p(θ|y) as a
result of entropy penalization, which lead to a heavy right
tail of rs. A few large-valued rs dominates the summation,
bringing in large uncertainty. But does the ﬁnite sample
performance of IS or stabilized IS contain the information
about the dispensary measure between q(θ) and p(θ|y)?

2.1. Pareto Smoothed Importance Sampling

The solution to the ﬁrst question is the Pareto smoothed
importance sampling (PSIS). We give a brief review, and
more details can be found in Vehtari et al. (2017).

A generalized Pareto distribution with shape parameter k
and location-scale parameter (µ, τ ) has the density

p(y|µ, σ, k) =

(cid:19)(cid:19)− 1

k −1





1
σ
1
σ

(cid:18)

1 + k

(cid:18) y − µ
σ
(cid:19)

,

(cid:18) y − µ
σ

exp

, k (cid:54)= 0.

k = 0.

√

PSIS stabilizes importance ratios by ﬁtting a generalized
Pareto distribution using the largest M samples of ri, where
S). It then reports the
M is empirically set as min(S/5, 3
estimated shape parameter ˆk and replaces the M largest rs
by their expected value under the ﬁtted generalized Pareto
distribution. The other importance weights remain un-
changed. We further truncate all weights at the raw weight
maximum max(rs). The resulted smoothed weights are
denoted by ws, based on which a lower variance estimation
can be calculated through (3).

Pareto smoothed importance sampling can be considered as
Bayesian version of importance sampling with prior on the
largest importance ratios. It has smaller mean square errors
than plain IS and truncated-IS (Ionides, 2008).

2.2. Using PSIS as a Diagnostic Tool
The ﬁtted shape parameter ˆk, turns out to provide the desired
diagnostic measurement between the true posterior p(θ|y)
and the VI approximation q(θ). A generalized Pareto dis-
tribution with shape k has ﬁnite moments up to order 1/k,
thus any positive ˆk value can be viewed as an estimate to

(cid:40)

k = inf

k(cid:48) > 0 : Eq

(cid:19) 1
k(cid:48)

(cid:18) p(θ|y)
q(θ)

(cid:41)

< ∞

.

(4)

Evaluating Variational Inference

ˆk is invariant under any constant multiplication of p or q,
which explains why we can suppress the marginal likeli-
hood (normalizing constant) p(y) and replace the intractable
p(θ|y) with p(θ, y) in (2).

After log transformation, (4) can be interpreted as R´enyi
divergence (R´enyi et al., 1961) with order α between p(θ|y)
and q(θ):

(cid:110)

k = inf

k(cid:48) > 0 : D 1
k(cid:48)

(cid:111)

,

(p||q) < ∞
(cid:90)

where Dα (p||q) =

log

p(θ)αq(θ)1−αdθ.

1
α − 1

Θ

It is well-deﬁned since R´enyi divergence is monotonic in-
creasing on order α. Particularly, when k > 0.5, the χ2
divergence χ(p||q), becomes inﬁnite, and when k > 1,
D1(p||q) = KL(p, q) = ∞, indicating a disastrous VI
approximation, despite the fact that KL(q, p) is always min-
imized among the variational family. The connection to
R´enyi divergence holds when k > 0. When k < 0, it
predicts the importance ratios are bounded from above.
This also illustrates the advantage of a continuous ˆk estimate
in our approach over only testing the existence of second
moment of Eq(q/p)2 (Epifani et al., 2008; Koopman et al.,
2009) – it indicates if the R´enyi divergence between q and p
is ﬁnite for all continuous order α > 0.

Meanwhile, the shape parameter k determines the ﬁnite
sample convergence rate of both IS and PSIS adjusted es-
timate. Geweke (1989) shows when Eq[r(θ)2] < ∞ and
Eq[(cid:0)r(θ)h(θ)(cid:1)2
] < ∞ hold (both conditions can be tested
by ˆk in our approach), the central limit theorem guaran-
tees the square root convergence rate. Furthermore, when
k < 1/3, then the Berry-Essen theorem states faster con-
vergence rate to normality (Chen et al., 2004). Cortes et al.
(2010) and Cortes et al. (2013) also link the ﬁnite sample
convergence rate of IS with the number of existing moments
of importance ratios.

PSIS has smaller estimation error than the plain VI esti-
mate, which we will experimentally verify this in Section
4. A large ˆk indicates the failure of ﬁnite sample PSIS, so it
further indicates the large estimation error of VI approxima-
tion. Therefore, even when the researchers’ primary goal is
not to use variational approximation q as an PSIS proposal,
they should be alert by a large ˆk which tells the discrepancy
between the VI approximation result and the true posterior.

According to empirical study in Vehtari et al. (2017), we set
the threshold of ˆk as follows.

• If ˆk < 0.5, we can invoke the central limit theorem to
suggest PSIS has a fast convergence rate. We conclude
the variational approximation q is close enough to the
true density. We recommend further using PSIS to

Algorithm 1 PSIS diagnostic

1: Input: the joint density function p(θ, y); number of

posterior samples S; number of tail samples M .

2: Run variational inference to p(θ|y), obtain VI approxi-

mation q(θ);

3: Sample (θs, s = 1, . . . , S) from q(θ);
4: Calculate the importance ratio rs = p(θs, y)/q(θs);
5: Fit generalized Pareto distribution to the M largest rs;
6: Report the shape parameter ˆk;
7: if ˆk < 0.7 then
8:

Conclude VI approximation q(θ) is close enough to
the unknown truth p(θ|y);
Recommend further shrinking errors by PSIS.

9:
10: else
11: Warn users that the VI approximation is not reliable.
12: end if

adjust the estimator (3) and calculate other divergence
measures.

• If 0.5 < ˆk < 0.7, we still observe practically useful
ﬁnite sample convergence rates and acceptable Monte
Carlo error for PSIS. It indicates the variational ap-
proximation q is not perfect but still useful. Again, we
recommend PSIS to shrink errors.

• If ˆk > 0.7, the PSIS convergence rate becomes im-
practically slow, leading to a large mean square er-
ror, and a even larger error for plain VI estimate. We
should consider tuning the variational methods (e.g.,
re-parametrization, increase iteration times, increase
mini-batch size, decrease learning rate, et.al.,) or turn-
ing to exact MCMC. Theoretically k is always smaller
than 1, for Eq [p(θ|y)/q(θ)] = p(y) < ∞, while in
practice ﬁnite sample estimate ˆk may be larger than 1,
which indicates even worse ﬁnite sample performance.

The proposed diagnostic method is summarized in Algo-
rithm 1.

2.3. Invariance Under Re-Parametrization

Re-parametrization is common in variational inference. Par-
ticularly, the reparameterization trick (Rezende et al., 2014)
rewrites the objective function to make gradient calculation
easier in Monte Carlo integrations.
A nice property of PSIS diagnostics is that the ˆk quantity is
invariant under any re-parametrization. Suppose ξ = T (θ)
is a smooth transformation, then the density ratio of ξ under
the target p and the proposal q does not change:

p(ξ)
q(ξ)

=

p (cid:0)T −1(ξ)(cid:1) |detJξT −1(ξ)|
q (T −1(ξ)) |detJξT −1(ξ)|

=

p (θ)
q(θ)

Evaluating Variational Inference

Therefore, p(ξ)/q(ξ) and p(θ)/q(θ) have the same distri-
bution under q, making it free to choose any convenient
parametrization form when calculating ˆk.

However, if the re-parametrization changes the approxima-
tion family, then it will change the computation result, and
PSIS diagnostics will change accordingly. Finding the op-
timal parametrization form, such that the re-parametrized
posterior distribution lives exactly in the approximation fam-
ily

p(T (ξ)) = p (cid:0)T −1(ξ)(cid:1) |JξT −1(ξ)| ∈ Q,

can be as hard as ﬁnding the true posterior. The PSIS diag-
nostic can guide the choice of re-parametrization by simply
comparing the ˆk quantities of any parametrization. Section
4.3 provides a practical example.

2.4. Marginal PSIS Diagnostics Do Not Work

As dimension increases, the VI posterior tends to be further
away from the truth, due to the limitation of approximation
families. As a result, k increases, indicating inefﬁciency
of importance sampling. This is not the drawback of PSIS
diagnostics. Indeed, when the focus is the joint distribu-
tion, such behaviour accurately reﬂects the quality of the
variational approximation to the joint posterior.

true and approximate
Denoting the one-dimensional
marginal density of the i-th coordinate θi as p(θi|y) and
q(θi), the marginal k for θi can be deﬁned as

(cid:40)

ki = inf

0 < k(cid:48) < 1 : Eq

(cid:19) 1
k(cid:48)

(cid:18) p(θi|y)
q(θi)

(cid:41)

< ∞

.

The marginal ki is never larger (and usually smaller) than
the joint k in (4).

Proposition 1. For any two distributions p and q with
support Θ and the margin index i, if there is a num-
ber α > 1 satisfying Eq (p(θ)/q(θ))α < ∞,
then
Eq (p(θi)/q(θi))α < ∞.

Proposition 1 demonstrates why the importance sampling
is usually inefﬁcient in high dimensional sample space, in
that the joint estimation is “worse” than any of the marginal
estimation.

Should we extend the PSIS diagnostics to marginal distri-
butions? We ﬁnd two reasons why the marginal PSIS diag-
nostics can be misleading. Firstly, unlike the easy access
to the unnormalized joint posterior distribution p(θ, y), the
true marginal posterior density p(θi|y) is typically unknown,
otherwise one can conduct one-dimensional sampling easily
to obtain the the marginal samples. Secondly, a smaller ˆki
does not necessary guarantee a well-performed marginal
estimation. The marginal approximations in variational in-
ference can both over-estimate and under-estimate the tail

thickness of one-dimensional distributions, the latter situa-
tion gives rise to a smaller ˆki. Section 4.3 gives an example,
where the marginal approximations with extremely small
marginal k have large estimation errors. This does not hap-
pen in the joint case as the direction of the Kullback-Leibler
divergence q∗(θ) strongly penalizes too-heavy tails, which
makes it unlikely that the tails of the variational posterior
are signiﬁcantly heavier than the tails of the true posterior.

3. Assessing the Average Performance of the

Point Estimate

The proposed PSIS diagnostic assesses the quality of the
VI approximation to the full posterior distribution. It is
often observed that while the VI posterior may be a poor
approximation to the full posterior, point estimates that are
derived from it may still have good statistical properties. In
this section, we propose a new method for assessing the
calibration of the center of a VI posterior.

3.1. The Variational Simulation-Based Calibration

(VSBC) Diagnostic

This diagnostic is based on the proposal of Cook et al. (2006)
for validating general statistical software. They noted that if
θ(0) ∼ p(θ) and y ∼ p(y | θ(0)), then

Pr(y,θ(0))

(cid:16)

(cid:17)
Prθ|y(θ < θ(0)) ≤ ·)

= Unif[0,1]([0, ·]).

To use the observation of Cook et al. (2006) to assess the per-
formance of a VI point estimate, we propose the following
procedure. Simulate M > 1 data sets {yj}M
j=1 as follows:
Simulate θ(0)
j ∼ p(θ) and then simulate y(j) ∼ p(y | θ(0)
j ),
where y(j) has the same dimension as y. For each of
these data sets, construct a variational approximation to
p(θ | yj) and compute the marginal calibration probabilities
(cid:17)
pij = Prθ|y(j)
.

θi ≤ [θ(0)

]i

(cid:16)

j

To apply the full procedure of Cook et al. (2006), we would
need to test dim(θ) histograms for uniformity, however this
would be too stringent a check as, like our PSIS diagnostic,
this test is only passed if the variational posterior is a good
Instead, we follow
approximation to the true posterior.
an observation of Anderson (1996) from the probabilistic
forecasting validation literature and note that asymmetry
in the histogram for pi: indicates bias in the variational
approximation to the marginal posterior θi | y.

The VSBC diagnostic tests for symmetry of the marginal cal-
ibration probabilities around 0.5 and either by visual inspec-
tion of the histogram or by using a Kolmogorov-Smirnov
(KS) test to evaluate whether pi: and 1 − pi: have the same
distribution. When θ is a high-dimensional parameter, it
is important to interpret the results of any hypothesis tests

Evaluating Variational Inference

Algorithm 2 VSBC marginal diagnostics

1: Input: prior density p(θ), data likelihood p(y | θ);
number of replications M ; parameter dimensions K;

j

4:
5:

(cid:1) from p(y | θ(0)

2: for j = 1 : M do
Generate θ(0)
from prior p(θ);
3:
Generate a size-n dataset (cid:0)y(j)
Run variational inference using dataset y(j), obtain a
VI approximation distribution qj(·)
for i = 1 : K do
Label θ(0)
Label θ∗
Calculate pij = Pr(θ(0)

ij as the i-th marginal component of θ(0)
j
i as the i-th marginal component of θ∗;

i | θ∗ ∼ qj)

ij < θ∗

j );

6:
7:

;

end for

8:
9:
10: end for
11: for i = 1 : K do
12:
13:

14: end for

Test if the distribution of {pij}M
If rejected, the VI approximation is biased in its i-th
margin.

j=1 is symmetric;

through a multiple testing lens.

3.2. Understanding the VSBC Diagnostic

Unlike the PSIS diagnostic, which focuses on a the perfor-
mance of variational inference for a ﬁxed data set y, the
VSBC diagnostic assesses the average calibration of the
point estimation over all datasets that could be constructed
from the model. Hence, the VSBC diagnostic operates
under a different paradigm to the PSIS diagnostic and we
recommend using both as appropriate.

There are two disadvantages to this type of calibration when
compared to the PSIS diagnostic. As is always the case
when interpreting hypothesis tests, just because something
works on average doesn’t mean it will work for a particular
realization of the data. The second disadvantage is that this
diagnostic does not cover the case where the observed data
is not well represented by the model. We suggest interpret-
ing the diagnostic conservatively: if a variational inference
scheme fails the diagnostic, then it will not perform well on
the model in question. If the VI scheme passes the diagnos-
tic, it is not guaranteed that it will perform well for real data,
although if the model is well speciﬁed it should do well.

With stronger assumptions, The VSBC test can be formal-
ized as in Proposition 2.

Proposition 2. Denote θ as a one-dimensional parameter
that is of interest. Suppose in addition we have: (i) the
VI approximation q is symmetric; (ii) the true posterior
p(θ|y) is symmetric. If the VI estimation q is unbiased, i.e.,
Eθ∼q(θ|y) θ = Eθ∼p(θ|y) θ, then the distribution of VSBC
p-value is symmetric. Otherwise, if the VI estimation is
positively/negatively biased, then the distribution of VSBC
p-value is right/left skewed.

The symmetry of the true posterior is a stronger assumption
than is needed in practice for this result to hold. In the
forecast evaluation literature, as well as the literature on
posterior predictive checks, the symmetry of the histogram
is a commonly used heuristic to assess the potential bias of
the distribution. In our tests, we have seen the same thing
occurs: the median of the variational posterior is close to
the median of the true posterior when the VSBC histogram
is symmetric. We suggest again that this test be interpreted
conservatively: if the histogram is not symmetric, then the
VI is unlikely to have produced a point estimate close to the
median of the true posterior.

4. Applications

Both PSIS and VSBC diagnostics are applicable to any
variational inference algorithm. Without loss of generality,
we implement mean-ﬁeld Gaussian automatic differentiation
variational inference (ADVI) in this section.

4.1. Linear Regression

Consider a Bayesian linear regression y ∼ N(Xβ, σ2) with
prior {βi}K
i=1 ∼ N(0, 1), σ ∼ gamma(.5, .5). We ﬁx sam-
ple size n = 10000 and number of regressors K = 100.

Figure 1 visualizes the VSBC diagnostic, showing the dis-
tribution of VSBC p-values of the ﬁrst two regression coef-
ﬁcients β1, β2 and log σ based on M = 1000 replications.
The two sided Kolmogorov-Smirnov test for p: and 1 − p: is
only rejected for pσ:, suggesting the VI approximation is in
average marginally unbiased for β1 and β2, while σ is over-
estimated as pσ is right-skewed. The under-estimation of
posterior variance is reﬂected by the U-shaped distributions.

The VSBC diagnostic has some advantages compared to
the PSIS diagnostic. It is well understood that, for complex
models, the VI posterior can be used to produce a good point
estimate even when it is far from the true posterior. In this
case, the PSIS diagnostic will most likely indicate failure.
The second advantage is that unlike the PSIS diagnostic, the
VSBC diagnostic considers one-dimensional marginals θi
(or any functional h(θ)), which allows for a more targeted
interrogation of the ﬁtting procedure.

Using one randomly generated dataset in the same problem,
the PSIS ˆk is 0.61, indicating the joint approximation is
close to the true posterior. However, the performance of
ADVI is sensitive to the stopping time, as in any other opti-
mization problems. As displayed in the left panel of Figure
2, changing the threshold of relative ELBO change from
a conservative 10−5 to the default recommendation 10−2
increases ˆk to 4.4, even though 10−2 works ﬁne for many
other simpler problems. In this example, we can also view ˆk

Evaluating Variational Inference

Figure 1. VSBC diagnostics for β1, β2 and log σ in the Bayesian
linear regression example. The VI estimation overestimates σ as
pσ is right-skewed, while β1 and β2 is unbiased as the two-sided
KS-test is not rejected.

Figure 3. In the logistic regression example, as the correlation in
design matrix increase, the correlation in parameter space also
increases, leading to larger ˆk. Such ﬂaw is hard to tell from the
VI log predictive density (lpd), as a larger correlation makes the
prediction easier. ˆk diagnose the discrepancy of VI lpd and true
posterior lpd, with a sharp jump at 0.7.

Figure 2. ADVI is sensitive to the stopping time in the linear re-
gression example. The default 0.01 threshold lead to a fake con-
vergence, which can be diagnosed by monitoring PSIS ˆk. PSIS
adjustment always shrinks the estimation errors.

as a convergence test. The right panel shows ˆk diagnoses es-
timation error, which eventually become negligible in PSIS
adjustment when ˆk < 0.7. To account for the uncertainty
of stochastic optimization and ˆk estimation, simulations are
repeated 100 times.

4.2. Logistic Regression

Next we run ADVI to a logistic regression Y ∼
Bernoulli (cid:0)logit−1(βX)(cid:1) with a ﬂat prior on β. We gener-
ate X = (x1, . . . , xn) from N(0, (1 − ρ)IK×K + ρ1K×K)
such that the correlation in design matrix is ρ, and ρ is
changed from 0 to 0.99. The ﬁrst panel in Figure 3 shows
PSIS ˆk increases as the design matrix correlation increases.
It is not monotonic because β is initially negatively corre-
lated when X is independent. A large ρ transforms into a
large correlation for posterior distributions in β, making it
harder to be approximated by a mean-ﬁeld family, as can
be diagnosed by ˆk. In panel 2 we calculate mean log pre-
dictive density (lpd) of VI approximation and true posterior
using 200 independent test sets. Larger ρ leads to worse
mean-ﬁeld approximation, while prediction becomes eas-
ier. Consequently, monitoring lpd does not diagnose the VI
behavior; it increases (misleadingly suggesting better ﬁt)
as ρ increases. In this special case, VI has larger lpd than
the true posterior, due to the VI under-dispersion and the
model misspeciﬁcation. Indeed, if viewing lpd as a function
h(β), it is the discrepancy between VI lpd and true lpd that
reveals the VI performance, which can also be diagnosed
by ˆk. Panel 3 shows a sharp increase of lpd discrepancy
around ˆk = 0.7, consistent with the empirical threshold we
suggest.

Figure 4. In the logistic regression with varying correlations, the
ˆk diagnoses the root mean square of ﬁrst and second moment
errors. No estimation is reliable when ˆk > 0.7. Meanwhile, PSIS
adjustment always shrinks the VI estimation errors.

Figure 4 compares the ﬁrst and second moment root mean
square errors (RMSE) ||Epβ − Eq∗ β||2 and ||Epβ2 −
Eq∗ β2||2 in the previous example using three estimates:
(a) VI without post-adjustment, (b) VI adjusted by vanilla
importance sampling, and (c) VI adjusted by PSIS.
PSIS diagnostic accomplishes two tasks here: (1) A small ˆk
indicates that VI approximation is reliable. When ˆk > 0.7,
all estimations are no longer reasonable so the user should
be alerted. (2) It further improves the approximation using
PSIS adjustment, leading to a quicker convergence rate and
smaller mean square errors for both ﬁrst and second moment
estimation. Plain importance sampling has larger RMSE for
it suffers from a larger variance.

4.3. Re-parametrization in a Hierarchical Model

The Eight-School Model (Gelman et al., 2013, Section 5.5)
is the simplest Bayesian hierarchical normal model. Each
school reported the treatment effect mean yi and standard
deviation σi separately. There was no prior reason to believe
that any of the treatments were more effective than any other,
so we model them as independent experiments:

yj|θj ∼ N(θj, σ2
µ ∼ N(0, 5),

j ),

θj|µ, τ ∼ N(µ, τ 2),
τ ∼ half−Cauchy(0, 5).

1 ≤ j ≤ 8,

where θj represents the treatment effect in school j, and µ
and τ are the hyper-parameters shared across all schools.

Evaluating Variational Inference

Figure 6. In the eight-school example, the VSBC diagnostic veri-
ﬁes VI estimation of θ1 is unbiased as the distribution of pθ1: is
symmetric. τ is overestimated in the centered parametrization and
underestimated in the non-centered one, as told by the right/ left
skewness of pτ :.

tion. As shown by the top right panel in Figure 5, the joint
ˆk for the non-centered ADVI decreases to 0.64 which indi-
cated the approximation is not perfect but reasonable and
usable. The bottom-right panel demonstrates that the re-
parametrized ADVI posterior is much closer to the truth,
and has smaller biases for both ﬁrst and second moment
estimations.

We can assess the marginal estimation using VSBC diagnos-
tic, as summarized in Figure 6. In the centered parametriza-
tion, the point estimation for θ1 is in average unbiased, as
the two-sided KS-test is not rejected. The histogram for τ
is right-skewed, for we can reject one-sided KS-test with
the alternative to be pτ : being stochastically smaller than
pτ :. Hence we conclude τ is over-estimated in the centered
parameterization. On the contrast, the non-centered τ is
negatively biased, as diagnosed by the left-skewness of pτ :.
Such conclusion is consistent with the bottom-right panel in
Figure 5.

To sum up, this example illustrates how the Gaussian fam-
ily assumption can be unrealistic even for a simple hier-
archical model. It also clariﬁes VI posteriors can be both
over-dispersed and under-dispersed, depending crucially on
the true parameter dependencies. Nevertheless, the recom-
mended PSIS and VSBC diagnostics provide a practical
summary of the computation result.

4.4. Cancer Classiﬁcation Using Horseshoe Priors

We illustrate how the proposed diagnostic methods work
in the Leukemia microarray cancer dataset that contains
D = 7129 features and n = 72 observations. Denote y1:n
as binary outcome and Xn×D as the predictor, the logistic
regression with a regularized horseshoe prior (Piironen &
Vehtari, 2017) is given by

y|β ∼ Bernoulli (cid:0)logit−1 (Xβ)(cid:1) ,
τ ∼ C+(0, τ0),
λj ∼ C+(0, 1),

βj|τ, λ, c ∼ N(0, τ 2˜λ2
j ),
c2 ∼ Inv−Gamma(2, 8).

where τ > 0 and λ > 0 are global and local shrinkage
(cid:1). The regularized
parameters, and ˜λ2

j / (cid:0)c2 + τ 2λ2

j = c2λ2

j

Figure 5. The upper two panels shows the joint and marginal PSIS
diagnostics of the eight-school example. The centered parame-
terization has ˆk > 0.7, for it cannot capture the funnel-shaped
dependency between τ and θ. The bottom-right panel shows the
bias of posterior mean and standard errors of marginal distribu-
tions. Positive bias of τ leads to over-dispersion of θ.

In this hierarchical model, the conditional variance of θ is
strongly dependent on the standard deviation τ , as shown by
the joint sample of µ and log τ in the bottom-left corner in
Figure 5. The Gaussian assumption in ADVI cannot capture
such structure. More interestingly, ADVI over-estimates the
posterior variance for all parameters θ1 through θ8, as shown
by positive biases of their posterior standard deviation in
the last panel. In fact, the posterior mode is at τ = 0, while
the entropy penalization keeps VI estimation away from it,
leading to an overestimation due to the funnel-shape. Since
j + τ −2(cid:1)−1
the conditional expectation E[θi|τ, y, σ] = (cid:0)σ−2
is an increasing function on τ , a positive bias of τ produces
over-dispersion of θ.

The top left panel shows the marginal and joint PSIS di-
agnostics. The joint ˆk is 1.00, much beyond the threshold,
while the marginal ˆk calculated through the true marginal
distribution for all θ are misleadingly small due to the over-
dispersion.
Alerted by such large ˆk, researchers should seek some im-
provements, such as re-parametrization. The non-centered
parametrization extracts the dependency between θ and τ
through a transformation θ∗ = (θ − µ)/τ :

yj|θj ∼ N(µ + τ θ∗

j , σ2

j ),

θ∗
j ∼ N(0, 1).

There is no general rule to determine whether non-centered
parametrization is better than the centered one and there
are many other parametrization forms. Finding the optimal
parametrization can be as hard as ﬁnding the true posterior,
but ˆk diagnostics always guide the choice of parametriza-

Evaluating Variational Inference

horseshoe prior adapts to the sparsity and allows us to spec-
ify a minimum level of regularization to the largest values.

ADVI is computationally appealing for it only takes a few
minutes while MCMC sampling takes hours on this dataset.
However, PSIS diagnostic gives ˆk = 9.8 for ADVI, sug-
gesting the VI approximation is not even close to the true
posterior. Figure 7 compares the ADVI and true posterior
density of β1834, log λ1834 and τ . The Gaussian assumption
makes it impossible to recover the bimodal distribution of
some β.

Figure 7. The comparison of ADVI and true posterior density of
θ1834, log λ1834 and τ in the horseshoe logistic regression. ADVI
misses the right mode of log λ, making β ∝ λ become a spike.

Figure 8. VSBC test in the horseshoe logistic regression. It tells the
positive bias of τ and negative bias of λ1834. β1834 is in average
unbiased for its symmetric prior.

The VSBC diagnostics as shown in Figure 8 tell the neg-
ative bias of local shrinkage λ1834 from the left-skewness
of plog λ1834, which is the consequence of the right-missing
mode. For compensation, the global shrinkage τ is over-
estimated, which is in agreement with the right-skewness
of plog τ . β1834 is in average unbiased, even though it is
strongly underestimated from in Figure 7. This is because
VI estimation is mostly a spike at 0 and its prior is symmet-
ric. As we have explained, passing the VSBC test means the
average unbiasedness, and does not ensure the unbiasedness
for a speciﬁc parameter setting. This is the price that VSBC
pays for averaging over all priors.

5. Discussion

5.1. The Proposed Diagnostics are Local

As no single diagnostic method can tell all problems, the
proposed diagnostic methods have limitations. The PSIS
diagnostic is limited when the posterior is multimodal as
the samples drawn from q(θ) may not cover all the modes
of the posterior and the estimation of k will be indifferent
to the unseen modes. In this sense, the PSIS diagnostic is

a local diagnostic that will not detect unseen modes. For
example, imagine the true posterior is p = 0.8N(0, 0.2) +
0.2N(3, 0.2) with two isolated modes. Gaussian family VI
will converge to one of the modes, with the importance ratio
to be a constant number 0.8 or 0.2. Therefore k is 0, failing
to penalize the missing density. In fact, any divergence
measure based on samples from the approximation such as
KL(q, p) is local.

The bi-modality can be detected by multiple over-dispersed
initialization. It can also be diagnosed by other divergence
measures such as KL(p, q) = Ep log(q/p), which is com-
putable through PSIS by letting h = log(q/p).

In practice a marginal missing mode will typically lead to
large joint discrepancy that is still detectable by ˆk, such as
in Section 4.4.

The VSBC test, however, samples the true parameter from
the prior distribution directly. Unless the prior is too restric-
tive, the VSBC p-value will diagnose the potential missing
mode.

5.2. Tailoring Variational Inference for Importance

Sampling

The PSIS diagnostic makes use of stabilized IS to diag-
nose VI. By contrast, can we modify VI to give a better IS
proposal?

Geweke (1989) introduce an optimal proposal distribution
based on split-normal and split-t, implicitly minimizing
the χ2 divergence between q and p. Following this idea,
we could ﬁrst ﬁnd the usual VI solution, and then switch
Gaussian to Student-t with a scale chosen to minimize the
χ2 divergence.

More recently, some progress is made to carry out varia-
tional inference based on R´enyi divergence (Li & Turner,
2016; Dieng et al., 2017). But a big α, say α = 2, is only
meaningful when the proposal has a much heavier tail than
the target. For example, a normal family does not contain
any member having ﬁnite χ2 divergence to a Student-t dis-
tribution, leaving the optimal objective function deﬁned by
Dieng et al. (2017) inﬁnitely large.

There are several research directions. First, our proposed
diagnostics are applicable to these modiﬁed approximation
methods. Second, PSIS re-weighting will give a more re-
liable importance ratio estimation in the R´enyi divergence
variational inference. Third, a continuous ˆk and the cor-
responding α are more desirable than only ﬁxing α = 2,
as the latter one does not necessarily have a ﬁnite result.
Considering the role ˆk plays in the importance sampling, we
can optimize the discrepancy Dα(q||p) and α > 0 simulta-
neously. We leave this for future research.

Evaluating Variational Inference

Acknowledgements

The authors acknowledge support from the Ofﬁce of Naval
Research grants N00014-15-1-2541 and N00014-16-P-2039,
the National Science Foundation grant CNS-1730414, and
the Academy of Finland grant 313122.

References

Giordano, R., Broderick, T., and Jordan, M. I. Covari-
ances, robustness, and variational Bayes. arXiv preprint
arXiv:1709.02536, 2017.

Hoffman, M. D. and Gelman, A. The No-U-Turn sampler:
adaptively setting path lengths in Hamiltonian Monte
Carlo. Journal of Machine Learning Research, 15(1):
1593–1623, 2014.

Anderson, J. L. A method for producing and evaluating
probabilistic forecasts from ensemble model integrations.
Journal of Climate, 9(7):1518–1530, 1996.

Hoffman, M. D., Blei, D. M., Wang, C., and Paisley, J.
Stochastic variational inference. The Journal of Machine
Learning Research, 14(1):1303–1347, 2013.

Blei, D. M., Kucukelbir, A., and McAuliffe, J. D. Varia-
tional inference: A review for statisticians. Journal of
the American Statistical Association, 112(518):859–877,
2017.

Chee, J. and Toulis, P. Convergence diagnostics for stochas-
tic gradient descent with constant step size. arXiv preprint
arXiv:1710.06382, 2017.

Chen, L. H., Shao, Q.-M., et al. Normal approximation
under local dependence. The Annals of Probability, 32
(3):1985–2028, 2004.

Cook, S. R., Gelman, A., and Rubin, D. B. Validation of
software for Bayesian models using posterior quantiles.
Journal of Computational and Graphical Statistics, 15
(3):675–692, 2006.

Cortes, C., Mansour, Y., and Mohri, M. Learning bounds for
importance weighting. In Advances in neural information
processing systems, pp. 442–450, 2010.

Cortes, C., Greenberg, S., and Mohri, M. Relative deviation
learning bounds and generalization with unbounded loss
functions. arXiv preprint arXiv:1310.5796, 2013.

Dieng, A. B., Tran, D., Ranganath, R., Paisley, J., and
Blei, D. Variational inference via chi upper bound mini-
mization. In Advances in Neural Information Processing
Systems, pp. 2729–2738, 2017.

Epifani, I., MacEachern, S. N., Peruggia, M., et al. Case-
deletion importance sampling estimators: Central limit
theorems and related results. Electronic Journal of Statis-
tics, 2:774–806, 2008.

Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B.,
Vehtari, A., and Rubin, D. B. Bayesian data analysis.
CRC press, 2013.

Ionides, E. L. Truncated importance sampling. Journal of
Computational and Graphical Statistics, 17(2):295–311,
2008.

Koopman, S. J., Shephard, N., and Creal, D. Testing the
assumptions behind importance sampling. Journal of
Econometrics, 149(1):2–11, 2009.

Kucukelbir, A., Tran, D., Ranganath, R., Gelman, A., and
Blei, D. M. Automatic differentiation variational infer-
ence. Journal of Machine Learning Research, 18(14):
1–45, 2017.

Li, Y. and Turner, R. E. R´enyi divergence variational in-
ference. In Advances in Neural Information Processing
Systems, pp. 1073–1081, 2016.

Pﬂug, G. C. Non-asymptotic conﬁdence bounds for stochas-
tic approximation algorithms with constant step size.
Monatshefte f¨ur Mathematik, 110(3):297–314, 1990.

Piironen, J. and Vehtari, A. Sparsity information and reg-
ularization in the horseshoe and other shrinkage priors.
Electronic Journal of Statistics, 11(2):5018–5051, 2017.

Ranganath, R., Gerrish, S., and Blei, D. Black box varia-
tional inference. In Artiﬁcial Intelligence and Statistics,
pp. 814–822, 2014.

R´enyi, A. et al. On measures of entropy and information.
In Proceedings of the Fourth Berkeley Symposium on
Mathematical Statistics and Probability, Volume 1: Con-
tributions to the Theory of Statistics. The Regents of the
University of California, 1961.

Rezende, D. J., Mohamed, S., and Wierstra, D. Stochas-
tic backpropagation and approximate inference in deep
generative models. In Proceedings of the 31st Interna-
tional Conference on Machine Learning (ICML-14), pp.
1278–1286, 2014.

Geweke, J. Bayesian inference in econometric models us-
ing Monte Carlo integration. Econometrica, 57(6):1317–
1339, 1989.

Sielken, R. L. Stopping times for stochastic approximation
procedures. Probability Theory and Related Fields, 26
(1):67–75, 1973.

Evaluating Variational Inference

Stan Development Team. Stan modeling language users
guide and reference manual. http://mc-stan.org,
2017. Version 2.17.

Stroup, D. F. and Braun, H. I. On a new stopping rule
for stochastic approximation. Probability Theory and
Related Fields, 60(4):535–554, 1982.

Vehtari, A., Gelman, A., and Gabry, J. Pareto smoothed
importance sampling. arXiv preprint arXiv:1507.02646,
2017.

Vehtari, A., Gabry, J., Yao, Y., and Gelman, A. loo: Efﬁcient
leave-one-out cross-validation and waic for bayesian mod-
els, 2018. URL https://CRAN.R-project.org/
package=loo. R package version 2.0.0.

Wada, T. and Fujisaki, Y. A stopping rule for stochastic
approximation. Automatica, 60:1–6, 2015. ISSN 0005-
1098.

Supplement to “Yes, but Did It Work?: Evaluating Variational Inference”

A. Sketch of Proofs
A.1. Proof to Proposition 1: Marginal ˆk in PSIS diagnostic

Proposition 1. For any two distributions p and q with support Θ and the margin index i, if there is a number α > 1
satisfying Eq (p(θ)/q(θ))α < ∞, then Eq (p(θi)/q(θi))α < ∞.

Proof. Without loss of generality, we could assume Θ = RK, otherwise a smooth transformation is conducted.
For any 1 ≤ i ≤ K, p(θ−i|θi) and q(θ−i|θi) deﬁne the conditional distribution of (θ1, . . . , θi−1, θi+1, . . . , θK) ∈ RK−1
given θi under the true posterior p and the approximation q separately.

For any given index α > 1, Jensen inequality yields

(cid:90)

RK−1

(cid:19)α

(cid:18) p(θ−i|θi)
q(θ−i|θi)

q(θ−i|θi) ≥

(cid:18)(cid:90)

p(θ−i|θi)
q(θ−i|θi)

RK−1

(cid:19)α

q(θ−i|θi)

= 1

Hence

(cid:90)

RK

(cid:19)α

(cid:18) p(θ)
q(θ)

q(θ)dθ =

(cid:19)α

(cid:90)

RK−1
(cid:18)(cid:90)

(cid:90)

(cid:90)

R

(cid:18) p(θi)p(θ−i|θi)
q(θi)q(θ−i|θi)
(cid:18) p(θ−i|θi)
(cid:19)α
q(θ−i|θi)

=

≥

R

RK−1

(cid:90)

(cid:18) p(θi)
q(θi)

R

(cid:19)α

q(θi)dθi

q(θi)q(θ−i|θi)dθidθ−i

q(θ−i|θi)dθ−i

q(θi)dθi

(cid:19)α

(cid:19) (cid:18) p(θi)
q(θi)

A.2. Proof to Proposition 2: Symmetry in VSBC-Test

Proposition 2. For a one-dimensional parameter θ that is of interest, Suppose in addition we have:
(i) the VI approximation q is symmetric;
(ii) the true posterior p(θ|y) is symmetric.
If the VI estimation q is unbiased, i.e.,

Eθ∼q(θ|y) θ = Eθ∼p(θ|y) θ, ∀y

Then the distribution of VSBC p-value is symmetric.
If the VI estimation is positively/negatively biased, then the distribution of VSBC p-value is right/left skewed.

In the proposition we write q(θ|y) to emphasize that the VI approximation also depends on the observed data.

Proof. First, as the same logic in (Cook et al., 2006), when θ(0) is sampled from its prior p(θ) and simulated data y sampled
from likelihood p(y|θ(0)), (y, θ(0)) represents a sample from the joint distribution p(y, θ) and therefore θ(0) can be viewed
as a draw from p(θ|y), the true posterior distribution of θ with y being observed.

We denote q(θ(0)) as the VSBC p-value of the sample θ(0). Also denote Qx(f ) as the x−quantile (x ∈ [0, 1]) of any
distribution f . To prove the result, we need to show

1 − Pr(q(θ(0)) < x) = Pr(q(θ(0)) < 1 − x), ∀x ∈ [0, 1],

Supplement to “Evaluating Variational Inference”

LHS = Pr

q(θ(0)) > x

(cid:17)

= Pr

θ(0) > Qx (q(θ|y))

(cid:17)

.

(cid:16)

(cid:16)

(cid:17)

RHS = Pr

θ(0) < Q1−x (q(θ|y))

= Pr

θ(0) < 2Eq(θ|y)θ − Qx (q(θ|y))

(cid:16)

(cid:17)

(cid:17)

= Pr

θ(0) < 2Ep(θ|y)θ − Qx (q(θ|y))

= Pr

(cid:16)

(cid:17)
θ(0) > Qx (q(θ|y))

(cid:16)

(cid:16)

= LHS

The ﬁrst equation above uses the symmetry of q(θ|y), the second equation comes from the the unbiasedness condition. The
third is the result of the symmetry of p(θ|y).

If the VI estimation is positively biased, Eθ∼q(θ|y) θ > Eθ∼p(θ|y) θ, ∀y, then we change the second equality sign into a
less-than sign.

B. Details of Simulation Examples

In this section, we give more detailed description of the simulation examples in the manuscript. We use Stan (Stan
Development Team, 2017) to implement both automatic differentiation variational inference (ADVI) and Markov chain
Monte Carlo (MCMC) sampling. We implement Pareto smoothing through R package “loo” (Vehtari et al., 2018). We also
provide all the source code in https://github.com/yao-yl/Evaluating-Variational-Inference.

B.1. Linear and Logistic Regressions

In Section 4.1, We start with a Bayesian linear regression y ∼ N(Xβ, σ2) without intercept. The prior is set as {βi}d
i=1 ∼
N(0, 1), σ ∼ gamma(0.5, 0.5). We ﬁx sample size n = 10000 and number of regressors d = 100. Figure IX displays the
Stan code.

//number of observations, we fix n=10000 in the simulation;

//number of predictor variables,

fix d=100;

// predictors;

// outcome;

,

1 data {
2 int <lower=0> n;
3 int <lower=0> d;
4 matrix [n,d] x ;
5 vector [n] y;
6 }
7 parameters {
8 vector [d] b;
9 real <lower=0> sigma;
10 }
11 model {
12 y ∼ normal(x * b, sigma);
13 b ∼ normal(0,1); // prior for
14 sigma ∼ gamma(0.5,0.5);
15 }
16

// linear regression coefficient;

//linear regression std;

regression coefficient;

// prior for

regression std.

Figure IX. Stan code for linear regressions

We ﬁnd ADVI can be sensitive to the stopping time. Part of the reason is the objective function itself is evaluated through
Monte Carlo samples, producing large uncertainty. In the current version of Stan, ADVI computes the running average and
running median of the relative ELBO norm changes. Should either number fall below a threshold tol rel obj, with the
default value to be 0.01, the algorithm is considered converged.

In Figure 1 of the main paper, we run VSBC test on ADVI approximation. ADVI is deliberately tuned in a conservative way.
The convergence tolerance is set as tol rel obj=10−4 and the learning rate is η = 0.05. The predictor X105×102 is ﬁxed

Supplement to “Evaluating Variational Inference”

in all replications and is generated independently from N(0, 1). To avoid multiple-comparison problem, we pre-register the
ﬁrst and second coefﬁcients β1 β2 and log σ before the test. The VSBC diagnostic is based on M = 1000 replications.

In Figure 2 we independently generate each coordinate of β from N(0, 1) and set a relatively large variance σ = 2. The
predictor X is generated independently from N(0, 1) and y is sampled from the normal likelihood. We vary the threshold
tol rel obj from 0.01 to 10−5 and show the trajectory of ˆk diagnostics. The ˆk estimation, IS and PSIS adjustment are
all calculated from S = 5 × 104 posterior samples. We ignore the ADVI posterior sampling time. The actual running time is
based on a laptop experiment result (2.5 GHz processor, 8 cores).The exact sampling time is based on the No-U-Turn Sampler
(NUTS, Hoffman & Gelman 2014) in Stan with 4 chains and 3000 iterations in each chain. We also calculate the root mean
square errors (RMSE) of all parameters ||Ep[(β, σ)] − Eq[(β, σ)]||L2 , where (β, σ) represents the combined vector of all β
and σ. To account for the uncertainty, ˆk, running time, and RMSE takes the average of 50 repeated simulations.

//number of predictor variables;

// predictors; we vary its correlation during simulations.

,

1

2

3

4

5

6

7

8

9

10

11

12

13

//number of observations;

data {
int <lower=0> n;
int <lower=0> d;
matrix [n,d] x ;
int<lower=0,upper=1> y[n]; // binary outcome;
}
parameters {
vector[d] beta;
}
model {
y ∼ bernoulli_logit(x*beta);
}

Figure X. Stan code for logistic regressions

Figure 3 and 4 in the main paper is a simulation result of a logistic regression
Y ∼ Bernoulli (cid:0)logit−1(βX)(cid:1)

with a ﬂat prior on β. We vary the correlation in design matrix by generating X from N(0, (1 − ρ)Id×d + ρ1d×d), where
1d×d represents the d by d matrix with all elements to be 1. In this experiment we ﬁx a small number n = 100 and d = 2
since the main focus is parameter correlations. We compare ˆk with the log predictive density, which is calculated from
100 independent test data. The true posterior is from NUTS in Stan with 4 chains and 3000 iterations each chain. The
ˆk estimation, IS and PSIS adjustment are calculated from 105 posterior samples. To account for the uncertainty, ˆk, log
predictive density, and RMSE are the average of 50 repeated experiments.

B.2. Eight-School Model

The eight-school model is named after Gelman et al. (2013, section 5.5). The study was performed for the Educational
Testing Service to analyze the effects of a special coaching program on students’ SAT-V (Scholastic Aptitude Test Verbal)
scores in each of eight high schools. The outcome variable in each study was the score of a standardized multiple choice test.
Each school i separately analyzed the treatment effect and reported the mean yi and standard deviation of the treatment
effect estimation σi, as summarized in Table 1.

There was no prior reason to believe that any of the eight programs was more effective than any other or that some were more
similar in effect to each other than to any other. Hence, we view them as independent experiments and apply a Bayesian
hierarchical normal model:

yj|θj ∼ N(θj, σj),
µ ∼ N(0, 5),

θj ∼ N(µ, τ ),
τ ∼ half−Cauchy(0, 5).

1 ≤ j ≤ 8,

where θj represents the underlying treatment effect in school j, while µ and τ are the hyper-parameters that are shared
across all schools.

There are two parametrization forms being discussed: centered parameterization and non-centered parameterization.
Listing XI and XII give two Stan codes separately. The true posterior is from NUTS in Stan with 4 chains and 3000 iterations

Supplement to “Evaluating Variational Inference”

School Index j Estimated Treatment Effect yi Standard Deviation of Effect Estimate σj

1
2
3
4
5
6
7
8

28
8
-3
7
-1
1
8
12

15
10
16
11
9
11
10
18

Table 1. School-level observed effects of special preparation on SAT-V scores in eight randomized experiments. Estimates are based on
separate analyses for the eight experiments.

// number of schools
// estimated treatment

// std

of estimated effect

,

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

data {
int<lower=0> J;
real y[J];
real<lower=0> sigma[J];
}

parameters {
real theta[J];
real mu;
real<lower=0> tau;
}
model {
theta ∼ normal(mu, tau);
y ∼ normal(theta, sigma);
mu ∼ normal(0, 5);
tau ∼ cauchy(0, 5);
}

// treatment effect in school j

// hyper-parameter of mean

// hyper-parameter of sdv

// a non-informative prior

Figure XI. Stan code for centered parametrization in the eight-school model. It leads to strong dependency between tau and theta.

each chain. The ˆk estimation and PSIS adjustment are calculated from S = 105 posterior samples. The marginal ˆk is
calculated by using the NUTS density, which is typically unavailable for more complicated problems in practice.

The VSBC test in Figure 6 is based on M = 1000 replications and we pre-register the ﬁrst treatment effect θ1 and group-level
standard error log τ before the test.

As discussed in Section 3.2, VSBC assesses the average calibration of the point estimation. Hence the result depends on the
choice of prior. For example, if we instead set the prior to be

µ ∼ N(0, 50),

τ ∼ N+(0, 25),

which is essentially ﬂat in the region of interesting part of the likelihood and more in agreement with the prior knowledge,
then the result of VSBC test change to Figure XIII. Again, the skewness of p-values veriﬁes VI estimation of θ1 is in average
unbiased while τ is biased in both centered and non-centered parametrization.

B.3. Cancer Classiﬁcation Using Horseshoe Priors

In Section 4.3 of the main paper we replicate the cancer classiﬁcation under regularized horseshoe prior as ﬁrst introduced
by Piironen & Vehtari (2017).

The Leukemia microarray cancer classiﬁcation dataset 1. It contains n = 72 observations and d = 7129 features Xn×d. X
is standardized before any further process. The outcome y1:n is binary, so we can ﬁt a logistic regression

yi|β ∼ Bernoulli

βjxij + β0



 .


logit−1





d
(cid:88)

j=1





1The Leukemia classiﬁcation dataset can be downloaded from http://featureselectiocn.asu.edu/datasets.php

Supplement to “Evaluating Variational Inference”

// number of schools
// estimated treatment

// std

of estimated effect

// transformation of theta

// hyper-parameter of mean

// hyper-parameter of sd

// original theta

,

1 data {
2 int<lower=0> J;
3 real y[J];
4 real<lower=0> sigma[J];
5 }
6 parameters {
7 vector[J] theta_trans;
8 real mu;
9 real<lower=0> tau;
10 }
11 transformed parameters{
12 vector[J] theta;
13 theta=theta_trans*tau+mu;
14 }
15 model {
16 theta_trans ∼normal (0,1);
17 y ∼ normal(theta, sigma);
18 mu ∼ normal(0, 5);
19 tau ∼ cauchy(0, 5);
20 }
21

// a non-informative prior

Figure XII. Stan code for non-centered parametrization in the eight-school model. It extracts the dependency between tau and theta.

Figure XIII. The VSBC diagnostic of the eight-school example under a non-informative prior µ ∼ N(0, 50), τ ∼ N+(0, 25). The skewness
of p-values veriﬁes VI estimation of θ1 is in average unbiased while τ is biased in both centered and non-centered parametrization.

There are far more predictors than observations, so we expect only a few of predictors to be related and therefore have a
regression coefﬁcient distinguishable from zero. Further, many predictors are correlated, making it necessary to have a
regularization.

To this end, we apply the regularized horseshoe prior, which is a generalization of horseshoe prior.

βj|τ, λ, c ∼ N(0, τ 2˜λ2
λj ∼ Half−Cauchy(0, 1),

j ),

c2 ∼ Inv−Gamma(2, 8),

τ |τ0 ∼ Half−Cauchy(0, τ0).

The scale of the global shrinkage is set according to the recommendation τ0 = 2 (cid:0)n1/2(d − 1)(cid:1)−1
shrink intercept so we put β0 ∼ N(0, 10). The Stan code is summarized in Figure XIV.

There is no reason to

We ﬁrst run NUTS in Stan with 4 chains and 3000 iterations each chain. We manually pick β1834, the coefﬁcient that has the
largest posterior mean. The posterior distribution of it is bi-modal with one spike at 0.

ADVI is implemented using the same parametrization and we decrease the learning rate η to 0.1 and the threshold
tol rel obj to 0.001
The ˆk estimation is based on S = 104 posterior samples. Since ˆk is extremely large, indicating VI is far away from the true
posterior and no adjustment will work, we do not further conduct PSIS.

Supplement to “Evaluating Variational Inference”

,

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

// local shrinkage parameter

// global shrinkage parameter

// number of observations
// number of predictors
// outputs
// inputs
// prior std for the intercept

data {
int<lower=0> n;
int<lower=0> d;
int<lower=0,upper=1> y[n];
matrix[n,d] x;
real<lower=0> scale_icept;
real<lower=0> scale_global; // scale for the half-t prior for tau
real<lower=0> slab_scale;
real<lower=0> slab_df;
}
parameters {
real beta0; // intercept
vector[d] z; // auxiliary parameter
real<lower=0> tau;
vector<lower=0>[d] lambda;
real<lower=0> caux; // auxiliary
}
transformed parameters {
real<lower=0> c;
vector[d] beta;
vector[n] f;
vector<lower=0>[d] lambda_tilde;
c = slab_scale * sqrt(caux);
lambda_tilde = sqrt( cˆ2 * square(lambda) ./ (cˆ2 + tauˆ2* square(lambda)) );
beta = z .* lambda_tilde*tau;
f = beta0 + x*beta;
}
model {
z ∼ normal(0,1);
lambda ∼ cauchy(0,1);
tau ∼ cauchy(0, scale_global);
caux ∼ inv_gamma(0.5*slab_df, 0.5*slab_df);
beta0 ∼ normal(0,scale_icept);
y ∼ bernoulli_logit(f);
}

// regression coefficients

// latent values

Figure XIV. Stan code for regularized horseshoe logistic regression.

In the VSBC test, we pre-register that pre-chosen coefﬁcient β1834, log λ1834 and global shrinkage log τ before the test. The
VSBC diagnostic is based on M=1000 replications.

