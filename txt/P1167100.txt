8
1
0
2
 
y
a
M
 
8
2
 
 
]
E
P
.
o
i
b
-
q
[
 
 
1
v
3
7
0
1
1
.
5
0
8
1
:
v
i
X
r
a

NON-BIFURCATING PHYLOGENETIC TREE INFERENCE VIA THE
ADAPTIVE LASSO

CHENG ZHANG1∗,VU DINH2∗, AND FREDERICK A. MATSEN IV1

Abstract. Phylogenetic tree inference using deep DNA sequencing is reshap-
ing our understanding of rapidly evolving systems, such as the within-host
battle between viruses and the immune system. Densely sampled phyloge-
netic trees can contain special features, including sampled ancestors in which
we sequence a genotype along with its direct descendants, and polytomies
in which multiple descendants arise simultaneously. These features are ap-
parent after identifying zero-length branches in the tree. However, current
maximum-likelihood based approaches are not capable of revealing such zero-
length branches. In this paper, we ﬁnd these zero-length branches by introduc-
ing adaptive-LASSO-type regularization estimators to phylogenetics, deriving
their properties, and showing regularization to be a practically useful approach
for phylogenetics.

Keywords: phylogenetics, (cid:96)1 regularization, adaptive LASSO, sparsity, model se-
lection, consistency, FISTA

1. Introduction

Phylogenetic methods, originally developed to infer evolutionary relationships
among species separated by millions of years, are now widely used in biomedicine
to investigate very short-time-scale evolutionary history. For example, mutations
in viral genomes can inform us about patterns of infection and evolutionary dy-
namics as they evolve in their hosts on a time-scale of years (Grenfell et al., 2004).
Antibody-making B cells diversify in just a few weeks, with a mutation rate around
a million times higher than the typical mutation rate for cell division (Kleinstein
et al., 2003). Although general-purpose phylogenetic methods have proven useful
in these biomedical settings, the basic assumption that evolutionary trees follow a
bifurcating pattern need not hold. Our goal is to develop a penalized maximum-
likelihood approach to infer non-bifurcating trees (Figure 1).

Although our practical interests concern inference for ﬁnite-length sequence data,
some situations in biology will lead to non-bifurcating phylogenetic trees, even in
the theoretical limit of inﬁnite sequence information. For example, a retrovirus
such as HIV incorporates a copy of its genetic material into the host cell upon
infection. This genetic material is then used for many copies of the virus, and
when more than two descendants from this infected cell are then sampled for se-
quencing, the correct phylogenetic tree forms a multifurcation from these multiple
descendants (a.k.a. a polytomy). In other situations we may sample an ancestor
along with a descendant cell, which will appear as a node with a single descendant

∗ Equal contribution, 1Fred Hutchinson Cancer Research Center, 2University of Delaware.
1

2

ZHANG, DINH, AND MATSEN

Figure 1.
(a) A cartoon evolutionary scenario, with sampled an-
cestors (gray dots) and a multifurcation (dashed box). (b) A cor-
responding standard maximum likelihood phylogenetic inference,
without regularization or thresholding.

edge (Figure 1). For example, antibody-making B cells evolve within host in dense
accretions of cells called germinal centers in order to better bind foreign molecules
(Victora and Nussenzweig, 2012). In such settings it is possible to sample a cell
along with its direct descendant. Indeed, upon DNA replication in cell division,
one cell inherits the original DNA of the coding strand, while the other inherits a
copy which may contain a mutation from the original. If we sequence both of these
cells, the ﬁrst cell is the genetic ancestor of the second cell for this coding region.
In this case the correct conﬁguration of the two genotypes is that the ﬁrst cell is a
sampled ancestor of the second cell.

However DNA sequences are ﬁnite and often rather short, limiting the amount
of information available with which to infer phylogenetic trees. Even though entire
genomes are large, the segment of interest for a phylogenetic analysis is frequently
small. For example, B cells evolve rapidly only in the hundreds of DNA sites used
to encode antibodies, and thus sequencing is typically applied only to this region
(Georgiou et al., 2014). Similarly, modern applications of pathogen outbreak anal-
ysis using sequencing (Gardy et al., 2015) frequently observe the same sequence,
indicating that sampling is dense relative to mutation rates. Because genetic recom-
bination and processes such as viral reassortment (Chen and Holmes, 2008) break
the assumption that genetic data has evolved according to a single tree, practition-
ers often restrict analysis to an even shorter region that they believe has evolved
according to a single process.

Inference on these shorter sequences further motivates correct inferences for non-
bifurcating tree inference. Indeed, even if a collection of sequences in fact did diverge
in a bifurcating fashion, if no mutations happened in the sequenced region during
this diversiﬁcation (i.e. a zero-length branch) then a non-bifurcating representation
is appropriate. We thus expect multifurcations and sampled ancestors whenever
the interval between the bifurcations is short compared to the total mutation rate
in the sequenced region.

Non-bifurcating tree inference has thus far been via Bayesian phylogenetics, with
the two deviations from bifurcation in two separate lines of work. For multifurca-
tions, Lewis et al. (2005, 2015) develop a prior on phylogenetic trees with positive
mass on multifurcating trees, and then perform tree estimation using reversible
jump MCMC (rjMCMC) moves between trees. For sampled ancestors, Gavryushk-
ina et al. (2014, 2016) introduce a prior on trees with sampled ancestors and then

NON-BIFURCATING PHYLOGENETIC TREE INFERENCE VIA THE ADAPTIVE LASSO 3

also use rjMCMC for inference. To our knowledge no priors have been deﬁned that
place mass on trees with both multifurcations or sampled ancestors.

Current biomedical applications require a more computationally eﬃcient alter-
native than these Bayesian techniques. Indeed, current methods for real-time phy-
logenetics in the course of a viral outbreak use maximum likelihood (Neher and
Bedford, 2015; Libin et al., 2017), which is orders of magnitude faster than Bayesian
analyses. This is essential because the time between new sequences being added
to the database is shorter than the required execution time for a Bayesian analy-
sis. However, to our knowledge a maximum-likelihood alternative to such rjMCMC
phylogenetic inference for multifurcating trees does not yet exist.

Elsewhere in statistics, researchers ﬁnd zero sets of parameters via penalized
maximum likelihood inference, commonly maximizing the sum of a penalty term
and a log likelihood function. When the penalty term has a nonzero slope as
each variable approaches zero, the penalty will have the eﬀect of “shrinking” that
variable to zero when there is not substantial evidence from the likelihood function
that it should be nonzero. There is now a substantial literature on such estimators,
of which L1 penalized estimators such as LASSO (Tibshirani, 1996) are the most
popular.

In this paper, we introduce such regularization estimators into phylogenetics, de-
rive their properties, and show regularization to be a practically-useful approach for
phylogenetics via new algorithms and experiments. Speciﬁcally, we ﬁrst show con-
sistency: that the LASSO and its adaptive variants ﬁnd all zero-length branches in
the limit of long sequences with an appropriate penalty weight. We also derive new
algorithms for phylogenetic LASSO and show them to be eﬀective via simulation
experiments and application to a Dengue virus data set.

Phylogenetic LASSO is challenging and requires additional new techniques above
those for classical LASSO. First, the phylogenetic log-likelihood function is non-
linear and non-convex. More importantly, unlike the standard settings for model
selection where the variables can receive both positive and negative values, the
branch lengths of a tree are non-negative. Thus, the objective function of phylo-
genetic LASSO can only be deﬁned on a constrained compact space, for which the
“true parameter” lies on the boundary of the domain. Furthermore the behavior of
the phylogenetic log-likelihood on this boundary is untamed: when multiple branch
lengths of a tree approach zero at the same time, the log-likelihood function may
diverge to inﬁnity, even if it is analytic in the inside of the domain of deﬁnition. The
geometry of the subset of the boundary where these singularities happen is non-
trivial, especially in the presence of randomness in data. All of these issues combine
to make theoretical analyses and practical implementation of these estimators an
interesting challenge.

2. Mathematical framework

2.1. Phylogenetic tree. A phylogenetic tree is a tree graph τ such that each leaf
has a unique name, and such that each edge e of the tree is associated with a
non-negative number qe. We will denote by E and V the set of edges and vertices
of the tree, respectively. We will refer to τ and (qe)e∈E as the tree topology and
the vector of branch lengths, respectively. Any edge adjacent to a leaf is called an
pendant edge, and any other edge is called an internal edge. A pendant edge with

4

ZHANG, DINH, AND MATSEN

zero branch length leads to a sampled ancestor while an internal edge with zero
branch length is part of a polytomy.

Throughout this paper, we assume that the topology τ of the tree is known
and we are interested in reconstructing the vector of branch lengths. We allow the
individual branch length qe to be zero, which enables us to consider non-bifurcating
trees. Since the tree topology is ﬁxed, the tree is completely represented by the
vector of branch lengths q. We will consider the set T of all phylogenetic trees
with topology τ and branch lengths bounded from above by some g0 > 0. This
arbitrary upper bound on branch lengths is for mathematical convenience and does
not represent a real constraint for the short-term evolutionary setting of interest
here.

2.2. Phylogenetic likelihood. We will follow the most common setting for likelihood-
based phylogenetics: a reversible continuous-time Markov chain model of substitu-
tion which is IID across sites. Brieﬂy, let Ω denote the set of states and let r = |Ω|;
for convenience, we assume the states have indices 1 to r. We assume that mutation
events occur according to a continuous time Markov chain on states Ω. Speciﬁcally,
the probability of ending in state y after time t given that the site started in state
x is given by the xy-th entry of P (t), where P (t) is the matrix valued function
P = eQt, and the matrix Q is the instantaneous rate matrix of the evolutionary
model. The branch length t of a given edge represents the time during which the
mutation process operates. We assume that the rate matrix Q is reversible with
respect to a stationary distribution π on the set of states Ω.

We will use the term state assignment to refer to a single-site labelling of
the leaf of tree by characters in Ω. For a ﬁxed vector of branch lengths q, the
phylogenetic likelihood is deﬁned as follows and will be denoted by L(p). Let
Yk = (Y(1), Y(2), ..., Y(k)) ∈ ΩN ×k be the observed sequences (with characters in
Ω) of length k over N leaves (i.e., each of the Y(i)’s is a state assignment). The
likelihood of observing Y given the tree has the form

Lk(q) =

k
(cid:89)

(cid:88)

(cid:89)

η(ai
ρ)

i=1

ai

(u,v)∈E

Pai

uai
v

(quv)

where ρ is any internal node of the tree, ai ranges over all extensions of Y(i) to the
u denotes the assigned state of node u by ai, Pxy(t)
internal nodes of the tree, ai
denotes the transition probability from character x to character y across an edge of
length t deﬁned by a given evolutionary model and η is the stationary distribution
of this evolutionary model. The value of the likelihood does not depend on choice
of ρ due to the reversibility assumption.

We will also denote (cid:96)k(q) = log(Lk(q)) and refer to it as the log-likelihood
function given the observed sequence. We allow the likelihood of a tree given data
to be zero, and thus (cid:96)k is deﬁned on T with values in the extended real line [−∞, 0].
We note that (cid:96)k is continuous, that is, for any vector of branch lengths q0 ∈ T , we
have

lim
q→q0

(cid:96)k(q) = (cid:96)k(q0)

even if (cid:96)k(q0) = −∞.

Each vector of branch lengths q generates a distribution on the state assignment

of the leaves, hereafter denoted by Pq. We will make the following assumptions:

NON-BIFURCATING PHYLOGENETIC TREE INFERENCE VIA THE ADAPTIVE LASSO 5

Assumption 2.1 (Model identiﬁability).

Pq = Pq(cid:48)

⇔

q = q(cid:48).

Assumption 2.2. The data Yk are generated on a tree topology τ with vector of
branch lengths q∗ ∈ T according to the above Markov process, where some compo-
nents of q∗ might be zero. We assume further that the tree distance (the sum of
branch lengths) between any pair of leaves of the true tree is strictly positive.

The second criterion ensures that no two leaves will be labeled with identical

sequences as sequence length k becomes long.

2.3. Regularized estimators for phylogenetic inference. Throughout the pa-
per, we consider regularization-type estimators, which are deﬁned as the minimizer
of the phylogenetic likelihood function penalized with various Rk:

(2.1)

qk,Rk = argmin

−

(cid:96)k(q) + λkRk(q).

1
k

q∈T

Here Rk denotes the penalty function and λk is the regularization parameter that
controls how the penalty function impacts the estimates. Diﬀerent forms of the
penalty function will lead to diﬀerent statistical estimators of the generating tree.
The existence of a minimizer as in (2.1) is guaranteed by the following Lemma

(proof in Appendix):

Lemma 2.3. If the penalty Rk is continuous on T , then for λ > 0 and observed
sequences Yk, there exists a q ∈ T minimizing

Zλ,Yk (q) = −

(cid:96)k(q) + λRk(q).

1
k

We are especially interested in the ability of the estimators to detect polytomies
and sampled ancestors. This leads us the following deﬁnition of topological consis-
tency, which in the usual variable selection setting is sometimes called sparsistency.

Deﬁnition 2.4. For any vector of branch lengths q, we denote the index set of zero
entries

A(q) = {i : qi = 0}.

We say a regularized estimator with penalty function Rk is topologically consistent
if for all data-generating branch lengths q∗, we have

P (cid:0)A(qk,Rk ) = A(q∗)(cid:1) = 1.

lim
k→∞

Deﬁnition 2.5 (Phylogenetic LASSO). The phylogenetic LASSO estimator is (2.1)
with the standard LASSO penalty R[0]

k , which in our setting of non-negative qi is

k (q) = λ[0]
R[0]

k

(cid:88)

i∈E

qi.

We will use qk,R[0]

k

to denote the phylogenetic LASSO estimate, namely

qk,R[0]

k = arg min
q∈T

−

1
k

(cid:96)k(q) + λ[0]
k

(cid:88)

i∈E

qi.

6

ZHANG, DINH, AND MATSEN

Deﬁnition 2.6 (Adaptive LASSO (Zou, 2006)). The phylogenetic adaptive LASSO
estimator is (2.1) with penalty function

k (q) = λ[1]
R[1]

k

(cid:88)

i∈E

wk,iqi

where

wk,i =

(cid:19)−γ

(cid:18)
qk,R[0]

k

i

for some γ > 0 and qk,R[0]

k

is the phylogenetic LASSO estimate.

Deﬁnition 2.7 (Multiple-step adaptive LASSO (B¨uhlmann and Meier, 2008)).
The phylogenetic multiple-step LASSO is deﬁned recursively with the phylogenetic
LASSO estimator as the base case (m = 1), and the penalty function in (2.1) at
step m being

k (q) = λ[m]
R[m]

k

wk,iqi

where

wk,i =

(cid:18)

qk,R[m−1]

k

i

(cid:19)−γ

,

(cid:88)

i∈E

is the (m − 1)-step regularized estimator with penalty

where γ > 0 and qk,R[m−1]
function R[m−1]

(q).

k

k

3. Theoretical properties of LASSO-type regularized estimators for

phylogenetic inference

We next show convergence and topological consistency of the LASSO-type phy-
logenetic estimates introduced in the previous section. As described in the intro-
duction, phylogenetic LASSO is a non-convex regularization problem for which the
true estimates lie on the boundary of a space on which the likelihood function is un-
tamed. To circumvent those problems, we take a minor departure from the standard
approach for analysis of non-convex regularization: instead of imposing regularity
conditions directly on the empirical log-likelihood function, we investigate the ex-
pected per-site log likelihood and investigate its regularity. This function enables us
to isolate the singular points and derive a local regularity condition that is similar to
the Restricted Strong Convexity condition (Loh and Wainwright, 2013; Loh, 2017).
This leads us to study the fast-rate generalization of the empirical log-likelihood in
a PAC learning framework (Van Erven et al., 2015; Dinh et al., 2016).

3.1. Deﬁnitions and lemmas. We begin by setting the stage with needed deﬁ-
nitions and lemmas. Most proofs are deferred to the Appendix.

Deﬁnition 3.1. We deﬁne the expected per-site log-likelihood

φ(q) := Eψ∼Pq∗ [log Pq(ψ)]

for any vector of branch lengths q.

Deﬁnition 3.2. For any µ > 0, we denote by T (µ) the set of all branch length
vectors q ∈ T such that log Pq(ψ) ≥ −µ for all state assignments ψ to the leaves.

We have the following result, where (cid:107) · (cid:107)2 is the (cid:96)2-norm in R2N −3.

Lemma 3.3 (Limit likelihood). The vector q∗ is the unique maximizer of φ, and
∀q ∈ T

(3.1)

1
k

(cid:96)k(q) → φ(q)

a.s.

NON-BIFURCATING PHYLOGENETIC TREE INFERENCE VIA THE ADAPTIVE LASSO 7

Moreover, there exist β ≥ 2 and c1 > 0 depending on N, Q, η, g0, µ such that
2 ≤ |φ(q) − φ(q∗)|

1 (cid:107)q − q∗(cid:107)β
cβ

∀q ∈ T (µ).

(3.2)

Proof. The ﬁrst statement follows from the identiﬁability assumption, and (3.1) is
a direct consequence of the Law of Large Numbers. Equation 3.2 follows from the
Lojasiewicz inequality (Ji et al., 1992) for φ on T , which applies because φ is an
analytic function deﬁned on the compact set T with q∗ as its only maximizer in
(cid:3)
T .

Group-based DNA sequence evolution models are a class of relatively simple
models that have transition matrix structure compatible with an algebraic group (Evans
and Speed, 1993). From Lemma 6.1 of Dinh et al. (2016), we have

Remark 3.4. For group-based models, β = 2.

For any µ > 0, we also have the following estimates showing local Lipschitzness

of the log-likelihood functions, recalling that k is the number of sites.

Lemma 3.5. For any µ > 0, there exists a constant c2(N, Q, η, g0, µ) > 0 such
that

(3.3)

and

(3.4)
for all q, q(cid:48) ∈ T (µ).

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
k

(cid:12)
(cid:12)
(cid:96)k(q(cid:48))
(cid:12)
(cid:12)

1
k

(cid:96)k(q) −

≤ c2(cid:107)q − q(cid:48)(cid:107)2

|φ(q) − φ(q(cid:48))| ≤ c2(cid:107)q − q(cid:48)(cid:107)2

Fix an arbitrary µ > 0. For any q ∈ T (µ) we consider the excess loss
1
k

(cid:96)k(q∗) −

Uk(q) =

(cid:96)k(q).

1
k

and derive a PAC lower bound on the deviation of the excess loss from its expected
value on T (µ). First note that since the sites Yk are independent and identically
distributed, we have

E [Uk(q)] = E

(cid:96)k(q∗) −

(cid:96)k(q)

= φ(q∗) − φ(q).

(cid:20) 1
k

(cid:21)

1
k

Moreover, from Lemma 3.5, we have |Uk(q)| ≤ c2(cid:107)q − q∗(cid:107)2. Applying this in the
case k = 1 and noting that Uk(q) is the average of k IID copies of U1(q), we have
that Var[Uk(q)] ≤ c2

2/k. This implies by (3.2) that

2(cid:107)q − q∗(cid:107)2

(3.5)

Var[Uk(q)] ≤

(cid:107)q − q∗(cid:107)2

2 ≤

E [Uk(q)]2/β

c2
2
k

c2
2
kc2
1

for all q ∈ T (µ).

Lemma 3.6. Let Gk be the set of all branch length vectors q ∈ T (µ) such that
E [Uk(q)] ≥ 1/k. Let β ≥ 2 be the constant in Lemma 3.3. For any δ > 0 and
previously speciﬁed variables there exists C(δ, N, Q, η, g0, µ, β) ≥ 1 (independent of
k) such that for any k ≥ 3, we have:

Uk(q) ≥

E[Uk(q)] −

1
2

C log k
k2/β

∀q ∈ Gk

with probability greater than 1 − δ.

8

ZHANG, DINH, AND MATSEN

We also need the following preliminary lemma from (Dinh et al., 2016).

Lemma 3.7. Given 0 < ν < 1, there exist constants C1, C2 > 0 depending only on
ν such that for all x > 0, if x ≤ axν + b then x ≤ C1a1/(1−ν) + C2b.

3.2. Convergence and topological consistency of regularized phylogenet-
ics. We now show convergence and topological consistency of qk,Rk , the regular-
ized estimator (2.1) for various choices of penalty Rk as the sequence length k
increases. For convenience, we will assume throughout this section that the param-
eters N, Q, η, g0, µ and β (deﬁned in the previous section) are ﬁxed.

3.2.1. Convergence. We ﬁrst have the following two lemmas guaranteeing that if µ
is carefully chosen, a neighborhood V of q∗ and the regularized estimator qk,Rk lie
inside T (µ) with high probability.

Lemma 3.8. There exist µ∗ > 0 and an open neighborhood V of q∗ in T such that
V ⊂ T (µ∗).

Lemma 3.9. If the sequence {λkRk(q∗)} is bounded, then for any δ > 0, there
exist µ(δ) > 0 and K(δ) > 0 such that for all k ≥ K, qk,Rk ∈ T (µ) with probability
at least 1 − 2δ.

We are now ready to prove a series of theorems establishing consistency and
topological consistency of phylogenetic adaptive and multi-step adaptive LASSO.
As part of this development we will ﬁrst use as a hypothesis and then establish the
technical condition that there exists a C3 > 0 independent of k such that
|Rk(qk,Rk ) − Rk(q∗)| ≤ C3(cid:107)qk,Rk − q∗(cid:107)2

(3.6)

∀k.

This will form an essential part of our recursive proof. As the ﬁrst step in this
project, choosing µ to satisfy these lemmas, we can use the deviation bound of
Lemma 3.6 to prove

Theorem 3.10. If λkRk(q∗) → 0 then {qk,Rk } converges to q∗ almost surely.

Moreover, letting β ≥ 2 be the constant in Lemma 3.3, for any δ > 0 there exist
C(δ) > 0 and K(δ) > 0 such that for all k ≥ K, with probability at least 1 − δ we
have

(3.7)

(cid:107)qk,Rk − q∗(cid:107)2 ≤ C(δ)

+ λkRk(q∗)

(cid:18) log k
k2/β

(cid:19)1/β

.

If we assume further that there exists a C3 > 0 independent of k satisfying (3.6)
then there exists C (cid:48)(δ) > 0 such that for all k ≥ K,

(cid:107)qk,Rk − q∗(cid:107)2 ≤ C (cid:48)(δ)

(cid:18) log k
k2/β

(cid:19)1/β

+ λβ/(β−1)
k

with probability at least 1 − δ.

Proof. By deﬁnition of the estimator, we have

−

(cid:96)k(qk,Rk ) + λkRk(qk,Rk ) ≤ −

(cid:96)k(q∗) + λkRk(q∗)

1
k

1
k

which is equivalent to Uk(qk,Rk ) ≤ λkRk(q∗) − λkRk(qk,Rk ).

NON-BIFURCATING PHYLOGENETIC TREE INFERENCE VIA THE ADAPTIVE LASSO 9

We have qk,Rk ∈ T (µ) with probability at least 1 − 2δ from Lemma 3.9 for k

suﬃciently large. Therefore by Lemma 3.6,

E[Uk(qk,Rk )] ≤

or

E[Uk(qk,Rk )] ≤ Uk(qk,Rk ) +

1
2

C log k
k2/β

,

with probability at least 1 − 3δ. The second case implies that

1
k

1
2

cβ
1
2

(cid:107)qk,Rk − q∗(cid:107)β

2 ≤

E[Uk(qk,Rk )]

≤ λkRk(q∗) − λkRk(qk,Rk ) +

C log k
k2/β

≤

C log k
k2/β

+ λkRk(q∗)

while for the ﬁrst case, we have

1
k
since β ≥ 2 and C ≥ 1. This demonstrates (3.7).

2 ≤ E[Uk(qk,Rk )] ≤

(cid:107)qk,Rk − q∗(cid:107)β

cβ
1
2

≤

C log k
k2/β

If the additional assumption (3.6) is satisﬁed, we also have

+ λkRk(q∗).

(cid:107)qk,Rk − q∗(cid:107)β

2 ≤

+ C3λk(cid:107)qk,Rk − q∗(cid:107)2.

C (cid:48) log k
k2/β

Using Lemma 3.7 with

ν = 1/β,

x = (cid:107)qk,Rk − q∗(cid:107)β
2 ,

a = C3λk

and

b =

C (cid:48) log k
k2/β

,

we obtain

which implies

x ≤ C1a1/(1−ν) + C2b,

(cid:107)qk,Rk − q∗(cid:107)β

2 ≤ C (cid:48)(δ, C3)

(cid:18) log k
k2/β

+ λβ/(β−1)
k

(cid:19)

.

This completes the proof.

(cid:3)

3.2.2. Topological consistency. The goal of this section is to prove that the phy-
logenetic LASSO is able to detect zero edges, which then give polytomies and
sampled ancestors. Since the estimators are deﬁned recursively, we will establish
these properties of adaptive and multi-step phylogenetic LASSO through an induc-
tive argument. Throughout this section, we will continue to use qk,Rk to denote the
regularized estimator (2.1). We will use qk,Sk to denote the corresponding adaptive
estimator where Sk(q) = (cid:80)
for some γ > 0. We will
use αk to be the regularizing parameter for the second step (regularizing with Sk)
and keep λk as the parameter for the ﬁrst step. These two need not be equal.

i wk,iqi and wk,i =

qk,Rk
i

(cid:17)−γ

(cid:16)

For positive sequences fk, gk, we will use the notation fk (cid:31) gk to mean that
limk→∞ fk/gk = ∞. We have the following result showing consistency of adaptive
LASSO, and setting the stage to show topological consistency of adaptive LASSO.

Theorem 3.11. Assume that λk → 0, Rk(q∗) = O(1) and that

αk → 0,

αk (cid:31)

(cid:18) log k
k2/β

(cid:19)γ/β

,

αk (cid:31) λγ/(β−1)
k

.

We have

(i) Sk(q∗) = O(1) and the estimator qS

k is consistent.

10

ZHANG, DINH, AND MATSEN

(ii) If there exists C3 independent of k satisfying (3.6) then the estimator qS

k is

topologically consistent.

Proof. We ﬁrst note that by Theorem 3.10, the estimator qk,Rk is consistent, which
guarantees limk→∞ qk,Rk = q∗ almost surely. Thus
(q∗

(cid:88)

i )1−γ < ∞.

lim
k→∞

Sk(q∗) = lim
k→∞

q∗
i (cid:54)=0

The hypotheses of this theorem imply that λk → 0 and thus by Theorem 3.10, we
also deduce that qk,Sk is also a consistent estimator. This validates (i).

To establish topological consistency under (ii), we divide the proof into two steps.
As the ﬁrst step, we prove that limk P(A(q∗) ⊂ A(qk,Sk )) = 1. If q∗
= 0 for some
i0

i0, then from Theorem 3.10, we have

qk,Rk
i0

≤ C (cid:48)(δ)

+ λβ/(β−1)
k

∀k

(cid:19)1/β

(cid:18) log k
k2/β

with probability at least 1 − δ. By the deﬁnition of wk,i0, we have

lim
k→∞

αkwk,i0 ≥ lim
k→∞

αk(C (cid:48)(δ))−γ

(cid:18) log k
k2/β

+ λβ/(β−1)
k

(cid:19)−γ/β

= (C (cid:48)(δ))−γ

lim
k→∞

(cid:32)

log k
αβ/γ
k k2/β

(cid:33)−γ/β

+ α−β/γ
k

λβ/(β−1)
k

which goes to inﬁnity since by the hypotheses of the Theorem

αβ/γ

k (cid:31)

log k
k2/β

and

k (cid:31) λβ/(β−1)
αβ/γ

k

.

Since δ > 0 is arbitrary, we deduce that limk→∞ αkwk,i0 = ∞ with probability
one.

Now for any branch length vector q, we deﬁne f (q) as the vector obtained from
q by setting the i0 component of q to 0. By deﬁnition of the estimator qk,Sk , we
have

−

(cid:96)k(qk,Sk ) + αk

wk,iqk,Sk
i

≤ −

(cid:96)k(f (qk,Sk )) + αk

wk,i[f (qk,Sk )]i

1
k

(cid:88)

i

1
k

(cid:88)

i

or equivalently

αkwk,i0qk,Sk

i0

≤

(cid:96)k(qk,Sk ) −

(cid:96)k(f (qk,Sk )).

1
k

Lemma 3.8 establishes that there exist, µ∗ > 0 and a neighborhood V of q∗ in T
such that V ⊂ T (µ∗). Since the estimator qk,Sk is consistent and q∗
= 0, we can
i0
assume that both qk,Sk and f (qk,Sk ) belong to T (µ∗) with k large enough. Thus,
from Lemma 3.5, we have

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
k

1
k

(cid:96)k(qk,Sk ) −

(cid:96)k(f (qk,Sk ))

≤ c2(cid:107)qk,Sk − f (qk,Sk )(cid:107)2 = c2qk,Sk

.

i0

> 0, we deduce that αkwk,i0 is bounded from above by c2, which is a

If qk,Sk
i0
contradiction. This implies that qk,Sk

i0

= 0, and we conclude that

1
k

(cid:12)
(cid:12)
(cid:12)
(cid:12)

P(A(q∗) ⊂ A(qk,Sk )) = 1.

lim
k

NON-BIFURCATING PHYLOGENETIC TREE INFERENCE VIA THE ADAPTIVE LASSO 11

As the second step, we prove that limk P(A(qk,Sk ) ⊂ A(q∗)) = 1. Indeed, the

consistency of qk,Sk guarantees that

qk,Sk = q∗.

lim
k→∞

almost surely. Therefore, if q∗
i0
i0
In other words, we have limk P(A(qk,Sk ) ⊂ A(q∗)) = 1.

> 0 for some i0, then qk,Sk

> 0 for k large enough.

Combing step 1 and step 2, we deduce that the adaptive estimator is topologically
(cid:3)

consistent.

Lemma 3.12. If qk,Sk is topologically consistent and qk,Rk is consistent, then there
exists a C3 independent of k such that

|Sk(qk,Sk ) − Sk(q∗)| ≤ C3(cid:107)qk,Sk − q∗(cid:107)2

∀k.

Proof. Since qk,Sk is topologically consistent and qk,Rk is consistent, we have

A(qk,Sk ) = A(q∗)

and

qk,Rk
i

≥ q∗

i /2

∀i (cid:54)∈ A(q∗)

with probability one for suﬃciently large k. Deﬁning b = mini(cid:54)∈A(q∗) q∗

i , we have

|Sk(qk,Sk ) − Sk(q∗)| =

wk,i(qk,Sk
i

≤

2N − 3 (b/2)−γ (cid:107)qk,Sk − q∗(cid:107)2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:88)

q∗
i (cid:54)=0

√

(cid:12)
(cid:12)
(cid:12)
− q∗
i )
(cid:12)
(cid:12)
(cid:12)

via Cauchy-Schwarz which completes the proof.

(cid:3)

Theorem 3.13. If

λ[m]
k → 0,

λ[m]
k (cid:31)

(cid:19)γ/β

(cid:18) log k
k2/β

,

∀m = 0, . . . , M

and

(3.8)

then

(cid:16)

λ[m]
k (cid:31)

λ[m−1]
k

(cid:17)γ/(β−1)

∀m = 1, . . . , M

(i) The adaptive LASSO and the m-step LASSO are topologically consistent

for all 1 ≤ m ≤ M .

(ii) For all 0 ≤ m ≤ M , the m-step LASSO (including the phylogenetic LASSO
and adaptive LASSO) are consistent. Moreover, for all δ > 0 and 0 ≤ m ≤
M , there exists C [m](δ) > 0 such that for all k ≥ K,

(cid:107)qk,R[m]

k − q∗(cid:107)2 ≤ C [m](δ)

(cid:18) log k
k2/β

(cid:16)

λ[m]
k

+

(cid:17)β/(β−1)(cid:19)1/β

with probability at least 1 − δ. In other words, the convergence of m-step
LASSO is of order

(cid:32)(cid:18) log k
k2/β

OP

(cid:16)

λ[m]
k

+

(cid:17)β/(β−1)(cid:19)1/β(cid:33)

where OP denotes big-O-in-probability.

12

ZHANG, DINH, AND MATSEN

Proof. We note that for the LASSO estimator, R[0]
is uniformly
bounded from above. Hence, the LASSO estimator is consistent. We can then
use this as the base case to prove, by induction, that adaptive LASSO and the
multiple-step LASSO are consistent via Theorem 3.11 (part (i)). Moreover, R[0]
k
is uniformly Lipschitz and satisﬁes (3.6), so using part (ii) of Theorem 3.11, we
deduce that adaptive LASSO (i.e., the estimator with penalty function R[1]
k ) is
topologically consistent.

k (q∗) = (cid:80)

i q∗
i

We will prove that the multiple-step LASSOs are topologically consistent by
induction. Assume that qk,R[m]
is
consistent. From Lemma 3.12, we deduce that there exists C > 0 independent of k
such that

is topologically consistent, and that qk,R[m−1]

k

k

(3.9)

(cid:16)

(cid:12)
(cid:12)R[m]
(cid:12)

k

qk,R[m]

k

(cid:17)

− R[m]

(cid:12)
k (q∗)
(cid:12)
(cid:12) ≤ C

(cid:13)
(cid:13)qk,R[m]
(cid:13)

k − q∗(cid:13)
(cid:13)
(cid:13)2

∀k.

This enables us to use part (ii) of Theorem 3.11 to conclude that qk,R[m+1]
is topo-
logically consistent. This inductive argument proves part (i) of the Theorem. We
can now use (3.9) and Theorem 3.10 to derive the convergence rate of the estima-
(cid:3)
tors.

k

Remark 3.14. If we further assume that γ > β − 1, then the results of Theorem
3.13 are valid if λ[m]
is independent of m. This enables us to keep the regularizing
parameters λk unchanged through successive applications of the multi-step estima-
tor.

k

Similarly, the Theorem applies if γ > β − 1 and

for all m = 1, . . . , M .

k /λ[m−1]
λ[m]

k

→ c[m] > 0

Remark 3.15. Consider the case β = 2 (for example, for group-based models),
(cid:15) > 0 and γ > 1. If we choose λ[m]

k = λk (independent of m) such that

then the convergence of m-step LASSO is of order
(cid:19)

λk ∼

(log k)1/2+(cid:15)
√
k

,

(cid:18) (log k)1/2+(cid:15)
√

.

OP

k

4. Algorithms

In this section, we aim to design a robust solver for the phylogenetic LASSO
problem. Many eﬃcient algorithms have been proposed for the LASSO minimiza-
tion problem

(4.1)

ˆq = arg min

g(q) + λ(cid:107)q(cid:107)1

q

for a variety of objective functions g. When g(q) = (cid:107)Y − Xq(cid:107)2
2, Efron et al.
(2004) introduced least angle regression (LARS) that computes not only the es-
timates but also the solution path eﬃciently.
In more general settings, iterative
shrinkage-thresholding algorithm (ISTA) is a typical proximal gradient method that
utilizes an eﬃcient and sparsity-promoting proximal mapping operator (also known
as soft-thresholding operator) in each iteration. Adopting Nesterov’s acceleration

NON-BIFURCATING PHYLOGENETIC TREE INFERENCE VIA THE ADAPTIVE LASSO 13

technique, Beck and Teboulle (2009) proposed a fast ISTA (FISTA) that has been
proved to signiﬁcantly improve the convergence rate.

These previous algorithms do not directly apply to phylogenetic LASSO. LARS
is mainly designed for regression and does not apply here. Classical proximal gradi-
ent methods are not directly applicable for the phylogenetic LASSO for the follow-
ing reasons: (i) Nonconvexity. The negative log phylogenetic likelihood is usually
non-convex. Therefore, the convergence analysis (which is described brieﬂy in the
following section 4.1) may not hold. Moreover, nonconvexity also makes it much
harder to adapt to local smoothness which could lead to slow convergence. (ii)
ISTA and FISTA also assume there are no constraints while
Bounded domain.
in phylogenetic inference we need the branches to be nonnegative: q ≥ 0.
(iii)
Regions of inﬁnite cost. Unlike normal cost functions, the negative phylogenetic
log-likelihood can be inﬁnite especially when q is sparse as shown in the following
proposition.

Proposition 4.1. Let Y = (y1, y2, . . . , yN ) ∈ ΩN be an observed character vector
on one site. If yi (cid:54)= yj and there is a path (u0, u1), (u1, u2), . . . , (us, us+1), u0 =
i, us+1 = j on the topology τ such that qukuk+1 = 0, k = 0, . . . , s, then

L(Y|q) = 0.

Proof. Let a be any extension of Y to the internal nodes. Since au0 = yi (cid:54)= yj =
aus+1, there must be some 0 ≤ k ≤ s such that auk (cid:54)= auk+1 ⇒ Pauk auk+1
(qukuk+1) =
0. Therefore,

L(Y|q) =

η(aρ)

Pauav (quv) = 0.

(cid:88)

a

(cid:89)

(u,v)∈E

(cid:3)

In what follows, we brieﬂy review the proximal gradient methods (ISTA) and
their accelerations (FISTA), and provide an extension of FISTA to accommodate
the above issues.

4.1. Proximal Gradient Methods. Consider the nonsmooth (cid:96)1 regularized prob-
lem (4.1). Gradient descent generally does not work due to non-diﬀerentiability of
the (cid:96)1 norm. The key insight of the proximal gradient method is to view the gra-
dient descent update as a minimization of a local linear approximation to g plus a
quadratic term. This suggests the following update strategy

q(n+1) = arg min

g(q(n)) + (cid:104)∇g(q(n)), q − q(n)(cid:105) +

(cid:26)

q

q

(cid:26) 1
2tn

(cid:16)

(cid:13)
(cid:13)
(cid:13)q −

1
2tn

(cid:13)
(cid:13)

(cid:13)q − q(n)(cid:13)

2
(cid:13)
(cid:13)
2

(cid:27)

+ λ(cid:107)q(cid:107)1

(cid:27)

(cid:17)(cid:13)
2
(cid:13)
(cid:13)
2

(4.2)

= arg min

q(n) − tn∇g(q(n))

+ λ(cid:107)q(cid:107)1

where (4.2) corresponds to the proximal map of h(q) = (cid:107)q(cid:107)1, which is deﬁned as
follows

(4.3) proxth(p) := arg min

(cid:107)q − p(cid:107)2

2 + th(q)

(cid:26) 1
2

q

(cid:27)

= arg min

q

(cid:26) 1
2t

(cid:107)q − p(cid:107)2

2 + h(q)

(cid:27)

(4.3) is usually easy to solve if the regularization function h is simple. For example,
in case of h(q) = (cid:107)q(cid:107)1, it can be solved by the soft thresholding operator

St(p) = sign(p)(|p| − t)+

14

ZHANG, DINH, AND MATSEN

where x+ = max{x, 0}. Applying this operator to (4.2), we get the ISTA update
formula

(4.4)

q(n+1) = Sλtn (q(n) − tn∇g(q(n))).
Let f = g + λ(cid:107)q(cid:107)1. Assume g is convex and ∇g is Lipschitz continuous with
Lipschitz constant L∇g > 0; if a constant step size is used and tn = t < 1/L∇g,
then ISTA converges at rate

(4.5)

f (q(n)) − f (q∗) ≤

(cid:107)q(0) − q∗(cid:107)2
2

1
2tn

where q∗ is the optimal solution. This means ISTA has sublinear convergence
whenever the stepsize is in the interval (0, 1/L∇g]. Note that ISTA could have
linear convergence if g is strongly convex.

The convergence rate in (4.5) can be signiﬁcantly improved using Nesterov’s
acceleration technique. The acceleration comes from a weighted combination of
the current and previous gradient directions, which is similar to gradient descent
with momentum. This leads to Algorithm 1 which is essentially equivalent to the
fast iterative shrinkage-thresholding algorithm (FISTA) introduced by Beck and
Teboulle (2009). Under the same condition, FISTA enjoys a signiﬁcantly faster
convergence rate

(4.6)

f (q(n)) − f (q∗) ≤

2

t(n + 1)2 (cid:107)q(0) − q∗(cid:107)2
2.

Notice that the above convergence rates both require the stepsize t ≤ 1/L∇g. In
practice, however, the Lipschitz coeﬃcient L∇g is usually unavailable and back-
tracking line search is commonly used.

Algorithm 1 Fast Iterative Shrinkage-Thresholding Algorithm (FISTA)

Input: q(0), t, λ
1: Set q(−1) = q(0), n = 1
2: while not converged do
3:

p ← q(n−1) + n−2
q(n) ← Sλt(p − t∇g(p))
n ← n + 1

4:
5:
6: end while
Output: q∗ ← q(n)

n+1 (q(n−1) − q(n−2))

(cid:46) Nesterov’s Acceleration
(cid:46) Soft-Thresholding Operator

4.2. Projected FISTA. FISTA usually assumes no constraints for the parame-
ters. However, in the phylogenetic case branch lengths are must be non-negative
(q ≥ 0). To address this issue, we combine the projected gradient method (which
can be viewed as proximal gradient as well) with FISTA to assure non-negative
updates. We refer to this hybrid as projected FISTA (pFISTA). Note that a simi-
lar strategy has been adopted by Liu et al. (2016) in tight frames based magnetic
resonance image reconstruction. Let C be a convex feasible set, deﬁne the indicator
function IC of the set C:

(cid:26) 0

IC(q) =

if q ∈ C, and

+∞ otherwise

NON-BIFURCATING PHYLOGENETIC TREE INFERENCE VIA THE ADAPTIVE LASSO 15

With the constraint q ∈ C, we consider the following projected proximal gradient
update

q(n+1) = arg min
q∈C

g(p) + (cid:104)∇g(p), q − p(cid:105) +

(cid:107)q − p(cid:107)2

2 + h(q)

= arg min

g(p) + (cid:104)∇g(p), q − p(cid:105) +

(cid:107)q − p(cid:107)2

2 + h(q) + IC(q)

(cid:27)

(cid:27)

(cid:26)

(cid:26)

q

1
2tn
1
2tn

(4.7)

= proxtnhC (p − tn∇g(p))

where hC = h(q) + IC(q). Using forward-backward splitting (see Combettes and
Wajs, 2006), (4.7) can be approximated as

(4.8)

proxtnhC (p − tn∇g(p)) ≈ ΠC(proxtnh(p − tn∇g(p)))
where ΠC is the Euclidean projection on to C. When h(q) = (cid:107)q(cid:107)1, C = {q : q ≥ 0},
we have the following pFISTA update formula
(cid:16)

q(n+1) = [Sλtn (p+ − tn∇g(p+))]+ .

p = q(n) +

n − 1
n + 2

q(n) − q(n−1)(cid:17)

,

Note that in this case, (4.8) is actually exact. Similarly, we can easily derive the
projected ISTA (pISTA) update formula and we omit it here.

4.3. Restarting. To accommodate non-convexity and possible inﬁnities of the
phylogenetic cost function, we adopt the restarting technique introduced by O’Donoghue
and Candes (2013) where they used it as a heuristic means of improving the con-
In the phylogenetic case, due to
vergence rate of accelerated gradient schemes.
the non-convexity of negative phylogenetic log-likelihood, backtracking line search
would fail to adapt to local smoothness which could lead to ineﬃcient small step
size. Moreover, the LASSO penalty will frequently push us into the “forbidden”
zone {q : g(q) = +∞}, especially when there are a lot of short branches. We
therefore adjust the restarting criteria as follows:

• Small stepsize: restart whenever tn < (cid:15).
• Inﬁnite cost: restart whenever g(p+) = +∞.

Equipping FISTA with projection and adaptive restarting, we obtain an eﬃcient

phylogenetic LASSO solver that we summarize in Algorithm 2.

16

ZHANG, DINH, AND MATSEN

Algorithm 2 Projected FISTA with Restarting

Input: q(0), t, λ, (cid:15), ω ∈ (0, 1)
1: while not converged do
2:
3:

Set q(−1) = q(0), t1 = t, n = 1
while not converged do
p ← q(n−1) + n−2
if g(p+) = +∞ then

4:

n+1 (q(n−1) − q(n−2))

break

(cid:46) Nesterov’s Acceleration
(cid:46) Restarting

end if
tn ← tn−1
Adapt tn through backtracking line search with ω
if tn < (cid:15) then
break

end if
q(n) ← [Sλtn (p+ − tn∇g(p+))]+

(cid:46) Restarting

(cid:46) Projected Soft-Thresholding

5:
6:
7:
8:
9:
10:

11:
12:
13:

14:
15:

Operator

n ← n + 1

end while
Set q(0) = q(n−1)

16:
17: end while
Output: q∗ ← q(n)

Remark 4.2. Note that the adaptive phylogenetic LASSO

(4.9)

ˆqS = arg min

g(q) + λ

wjqj

q

(cid:88)

j

is equivalent to (using / to denote componentwise division)

˜qS = arg min

{g(q/w) + λ(cid:107)q(cid:107)1} ,

ˆqS = ˜qS/w.

q

Therefore, Algorithm 2 can also be used to solve the (multi-step) adaptive phyloge-
netic LASSO.

5. Experiments

In this section, we ﬁrst demonstrate the eﬃciency of the proposed algorithm for
solving the phylogenetic LASSO problem when combined with maximum-likelihood
phylogenetic inference. We then show (non-adaptive) phylogenetic LASSO does not
appear to be strong enough to ﬁnd zero edges on simulated data; adaptive phy-
logenetic LASSO performs much better. We then compare it with simple thresh-
olding and rjMCMC then apply it to some real data sets. For all simulation and
inference, we use the simplest Jukes and Cantor (1969) model of DNA substitu-
tion, in which all substitutions have equal rates. The code is made available at
https://github.com/matsengrp/adaLASSO-phylo.

5.1. Eﬃciency of pFISTA for solving the phylogenetic LASSO. The fast
convergence rate of FISTA (or pFISTA) need not hold when the cost function g
is nonconvex. However, we can expect that g is well approximated by a quadratic

NON-BIFURCATING PHYLOGENETIC TREE INFERENCE VIA THE ADAPTIVE LASSO 17

Figure 2. pISTA vs pFISTA on simulated data sets in terms of
the relative error (f (q(n)) − f ∗)/f ∗, each run with penalty coeﬃ-
cient λ = 1.0. Left panel: simulation 1; Right panel: simulation 2.
In simulation 2, we tried two restarting strategies: restart whenever
g(p+) = +∞ (partial) and restart whenever tn < (cid:15) or g(p+) = +∞
(full). The optimal solution q∗ is obtained from a long run of
pFISTA.

function near the optimal (or some local mode) q∗. That is, there exists a neigh-
borhood of q∗ inside of which

g(q) ≈ g(q∗) +

(q − q∗)T ∇2g(q∗)(q − q∗)

1
2

When we are eventually inside this domain, we will observe behavior consistent
with the convergence analysis in Section 4.1.

To test the eﬃciency of pFISTA in diﬀerent scenarios, we consider various sim-
ulated data sets generated from “sparse” unrooted trees with 100 tips and 50 ran-
domly chosen zero branches as follows. All simulated data sets contain 1000 inde-
pendent observations on the leaf nodes. We set the minimum step size (cid:15) = 5e-08
for restarting.

We use the following simulation setups, in which branch lengths are expressed

in the traditional units of expected number of substitutions per site.

Simulation 1. (No short branches). All nonzero branches have length 0.05. Be-
cause there are no short nonzero branches, branches that are originally nonzero are
less likely to be collapsed to zero and we expect no restarting is needed.
Simulation 2. (A few short branches). For all the nonzero branches, we randomly
choose 15 of them and set their lengths 0.002. All the other branches have length
0.05. In this setting, there are a few short branches that are likely to be shrunken
to zero. As a result, several restarts may be needed before convergence.

We see that when the model does not have very short non-zero branches and
the phylogenetic cost is more regular, pFISTA (and pISTA) ﬁnds the quadratic
domain quickly and performs consistently with the corresponding convergence rate,
even without restarting (Figure 2). When the model does have many very short
branches and the negative phylogenetic log-likelihood is highly nonconvex, pFISTA

18

ZHANG, DINH, AND MATSEN

with restart still manages to arrive at the quadratic domain quickly and exhibits fast
convergence thereafter. Furthermore, we ﬁnd the small stepsize restarting criterion
is useful to adapt to changing local smoothness and facilitate mode exploration. In
both situations, pFISTA performs consistently better than pISTA. As a matter of
fact, pISTA is monotonic so is more likely to get stuck in local minima, and hence
may not be suitable for nonconvex optimization. We, therefore, use pFISTA with
restart as our default algorithm in all the following experiments.

Remark 5.1. Like other non-convex optimization algorithms, pFISTA with restart
may be sensitive to the starting position of the parameters. However, due to the
momentum introduced in Nesterov’s acceleration (which causes the ripples in Figure
2) and adaptive restarting, pFISTA with restart is more likely to escape local minima
and potentially arrive at the global minimum.

5.2. Performance of phylogenetic LASSO. Through simulation we also ﬁnd
that in practice the (non-adaptive) phylogenetic LASSO penalty is not strong
enough to ﬁnd all zero branches. Indeed, we ﬁnd that phylogenetic LASSO only
recovers around 60% of the sparsity found in the true models and larger penalty
does not necessarily give more sparsity (Table 1). This suggests we use the adap-
tive phylogenetic LASSO that has been proven topologically consistent under mild
conditions.

λ

Simulation 1
Simulation 2

1

32
32

5

32
32

10

32
32

20

32
32

40

32
32

80

32
32

160

32
31

Table 1. Number of zero length branches found for diﬀerent
penalty coeﬃcients in both simulation models, each of which have
50 zero length branches.

5.3. Performance of adaptive phylogenetic LASSO. Next, we demonstrate
that the topologically consistent (multistep) adaptive phylogenetic LASSO signiﬁ-
cantly enhances sparsity on simulated data compared to phylogenetic LASSO. We
will use the more diﬃcult simulation 2 that have a combination of zero and very
short branches.
In what follows (and for the rest of this section), we compute
adaptive and multistep adaptive phylogenetic LASSO as described in Section 2.3.
Note that m = 1 (ﬁrst cycle) is the phylogenetic LASSO and m = 2 (second cycle)
corresponds to the adaptive phylogenetic LASSO. Therefore, we can compare all
phylogenetic LASSO estimators by simply running the multistep adaptive phylo-
genetic LASSO with the maximum cycle number M ≥ 2. Since large γ often leads
to severe adaptive weights and hence numerical instability, we use γ = 1 in the
following experiments and put some results for γ > 1 (with guaranteed topological
consistency) in the Appendix.

We run the multistep phylogenetic LASSO with M = 4 cycles. To test the
topological consistency of the estimators, we use diﬀerent initial regularization co-
eﬃcients λ[0] = 10, 20, 30, 40, 50 and update the regularization coeﬃcients according

NON-BIFURCATING PHYLOGENETIC TREE INFERENCE VIA THE ADAPTIVE LASSO 19

Figure 3. Topological consistency comparison of diﬀerent phy-
logenetic LASSO procedures on simulation 2. Left panel: num-
ber of identiﬁed zero branches at diﬀerent cycles (which corre-
sponds to diﬀerent phylogenetic LASSO procedures as aforemen-
tioned). Right panel: the number of misidentiﬁed zero branches
(false alarm) and the number of unidentiﬁed zero branches (miss
detection) for simple thresholding and multistep adaptive phylo-
genetic LASSO at diﬀerent cycles.

to the following formula

λ[m] = λ[m−1] mean((ˆq[m])γ)
mean((ˆq[m−1])γ)

which maintains a relatively stable regularization among the adaptive LASSO steps.
This formula provides reasonably good balance between sparsity and numerical
stability in our experiments.

We ﬁnd that multistep adaptive phylogenetic LASSO does improve sparsity iden-
tiﬁcation while maintaining a relatively low misidentiﬁcation rate. Indeed, as the
cycle number increases, the estimator now is able to identify more zero branches
(Figure 3, left panel). Moreover, unlike the phylogenetic LASSO (m = 1), we do
observe more sparsity (identiﬁed zero branches) when the regularization coeﬃcient
increases at cycles m > 1. As more cycles are run and larger penalty coeﬃcients
are used, we see that multistep adaptive LASSO manages to reduce miss detection
without introducing many extra false alarms (Figure 3, right panel). In contrast,
simple thresholding is more likely to misidentify zero branches when larger thresh-
olds are used to bring down miss detection.

5.4. Short Edge Detection. Previous work has proposed Bayesian approaches
to infer non-bifurcating tree topologies by assigning priors that cover all of the
tree space, including less-resolved (unresolved) tree topologies (Lewis et al., 2005,
2015). Since the numbers of branches (parameters) are diﬀerent among those tree
topologies, reversible-jump MCMC (rjMCMC) is commonly used. Both approaches
provide means of sparsity encouragement that allow us to discover non-bifurcating
tree topologies, which as described in the Introduction make diﬀerent evolutionary

20

ZHANG, DINH, AND MATSEN

Figure 4. Performance of multistep (4 cycle) adaptive phyloge-
netic LASSO and rjMCMC at detecting zero versus short branches.

statements than their resolved counterparts. However, those sparsity encourag-
ing procedures also make it much more diﬃcult to detect relatively short edges.
To investigate how short an edge can be and still be detected by both methods,
we follow Lewis et al. (2005) and simulate a series of data sets using the same
tree as in Simulation 2. All branch lengths are the same as in that simulation
except those for the 15 randomly chosen short branches, each of which we take
to be 0.0, 0.002, 0.004, 0.006, 0.008, 0.010 for the various trials; the nonzero short
branches are meant to be particularly challenging to distinguish from the actual
zero branches. For each of these six lengths, we simulate 100 data sets of the same
size (1000 sites). These values for short branches are multiples of 1/1000, which
provides, on average, one mutation per data set along the branch of interest. Note
that branch lengths represent the expected amount of mutation per site, so a branch
length of 0.001 does not guarantee that a mutation will occur on the branch of in-
terest in every simulated data set. We run multistep adaptive phylogenetic LASSO
with M = 4 cycles and initial regularization coeﬃcient λ[0] = 50, and rjMCMC with
the polytomy prior (with C = 1) for analysis. The detection probabilities of rjM-
CMC are the averaged split posterior probabilities of the corresponding branches
over the 100 independent data sets.

We ﬁnd that multistep adaptive phylogenetic LASSO indeed strikes a better
balance between identifying zero branches and detecting short branches than rjM-
In addition to being slightly better
CMC in this simulation study (Figure 4).
at identifying zero branches than rjMCMC (partly due to a weak polytomy prior
C = 1), multistep adaptive phylogenetic LASSO has a substantially improved detec-
tion probability for short branches. Also note that suﬃciently long branch lengths
(about 10 expected substitution per data set) are usually needed for an edge to be
reliably detected in either methods.

NON-BIFURCATING PHYLOGENETIC TREE INFERENCE VIA THE ADAPTIVE LASSO 21

5.5. Dengue Virus Data. We now compare our adaptive phylogenetic LASSO
methods to others on a real data set. So far, we have tested the performance of
multistep adaptive phylogenetic LASSO on a ﬁxed topology. For real data sets, the
underlying phylogenies are unknown and hence have to be inferred from the data.
We therefore propose to use multistep adaptive phylogenetic LASSO as a sparsity-
enforcing procedure after traditional maximum likelihood based inferences. In what
follows, we use this combined procedure together with bootstrapping to measure
edge support on a real data set of the Dengue genome sequences. In our experiment,
we consider one typical subset of the 4th Dengue serotype (“DENV4”) consisting of
22 whole-genome sequences from Brazil curated by the nextstrain project (Hadﬁeld
et al., 2017) and originally sourced from the LANL hemorrhagic fever virus database
(Kuiken et al., 2012). The sequence alignment of these sequences comprises 10756
nucleotide sites.

Following Lewis et al. (2005), we conduct our analysis using the following meth-
ods: (1) maximum likelihood bootstrapping columns of a sequence alignment; (2) a
conventional MCMC Bayesian inference restricted to fully resolved tree topologies;
(3) a reversible-jump MCMC method moving among fully resolved as well as poly-
tomous tree topologies; (4) two combined procedures, maximum likelihood boot-
strapping plus multistep adaptive phylogenetic LASSO and maximum likelihood
bootstrapping plus thresholding, both allow fully bifurcating and non-bifurcating
tree topologies. Maximum likelihood bootstrap analysis is performed using RAxML
(Stamatakis, 2014) with 1000 replicates. The conventional MCMC Bayesian anal-
ysis is done in MrBayes (Ronquist et al., 2012) where we place a uniform prior on
the fully resolved topology and Exponential (λ = 10) prior on the branch lengths.
The rjMCMC analysis is run in p4 (Foster, 2004), using ﬂat polytomy prior with
C = 1 (C is the ratio of prior mass between trees with successive numbers of
internal nodes as deﬁned in Lewis et al. (2005)). Their code can be found at
https://github.com/Anaphory/p4-phylogeny. For each Bayesian approach, a
single Markov chain was run 8e+06 generations after a 2e+06 generation burn-in
period. Trees and branch lengths are sampled every 1000 generations, yielding 8000
samples. Both combined procedures are implemented based on the bootstrapped
ML trees obtained in (1). For multistep adaptive phylogenetic LASSO, we use
M = 4 cycles and test diﬀerent initial regularization coeﬃcients λ[0] = 150, 300, 450.
We set the thresholds κ = 1e-06, 5e-05, 1e-04 for the simple thresholding method.
Figure 5 shows the consensus tree obtained from the conventional MCMC sam-
ples. Each interior edge has its index number i and its support value (expressed as
percentage) si right above it: {(i) : si}. If an edge has inferred length zero then it
doesn’t count in this bootstrap edge support. We see that many short edges have
support below 50, which indicates the strong preference for non-bifurcating topolo-
gies. Therefore, we re-estimate the support values for all interior edges (splits) on
this MCMC consensus tree using the aforementioned methods and summarize the
results in Table 2. Compared to other methods, sparsity-encouraging methods rjM-
CMC, ML+thresholding+boostrap and ML+adaLASSO+bootstrap tends to better
identify zero edges and gives consistent detection results on edges with exactly zero
support (edges 2, 10, 13 and 15). More interestingly, ML+adaLASSO+bootstrap
is more conservative (in terms of zero edge identiﬁcation) for less supported edges
(see edges 5 and 9 for example) than ML+thresholding+boostrap, which coincides

22

ZHANG, DINH, AND MATSEN

Figure 5. Consensus tree resulting from the conventional MCMC
Bayesian inference on the Brazil clade from DENV4.

Edge

MCMC

ML

rjMCMC

ML+thresholding+bootstrap

ML+adaLASSO+bootstrap

bootstrap

C = 1

κ = 1e-06 κ = 5e-05 κ = 1e-04

λ = 150 λ = 300 λ = 450

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19

100
0
1
100
1
100
20
31
1
0
66
3
0
3
0
100
100
100
24

100
12
54
100
34
100
17
65
34
9
100
17
21
19
21
100
100
100
24

100
7
93
95
38
63
10
52
11
10
61
13
9
23
13
99
94
88
6
Table 2. Comparison on the support values obtained from diﬀer-
ent methods on DENV4 Brazil clade data set. All analysis used
the Jukes-Cantor model.

100
0
66
95
4
63
6
44
2
0
61
3
0
4
0
99
94
88
3

100
0
65
95
0
61
8
44
0
0
56
2
0
2
0
99
94
88
4

100
0
66
95
4
63
6
44
2
0
61
3
0
3
0
99
94
88
3

100
0
58
95
0
61
7
44
0
0
22
0
0
0
0
96
94
88
3

100
0
82
95
0
61
8
45
0
0
57
8
0
9
0
99
94
88
4

100
0
66
95
4
63
6
44
2
0
61
3
0
4
0
99
94
88
3

with our observation in the simulation 2. Overall, we see that (multistep) adap-
tive phylogenetic LASSO is able to reveal non-bifurcating structures comparable
to rjMCMC Bayesian approach when applied to maximum likelihood tree topolo-
gies, and is less likely to misidentify weakly supported edges in contrast to simple
thresholding.

6. Conclusion

We study (cid:96)1-penalized maximum likelihood approaches for phylogenetic infer-
ence, with the goal of recovering non-bifurcating tree topologies. We prove that

NON-BIFURCATING PHYLOGENETIC TREE INFERENCE VIA THE ADAPTIVE LASSO 23

these regularized maximum likelihood estimators are asymptotically consistent un-
der mild conditions. Furthermore, we show that the (multistep) adaptive phy-
logenetic LASSO is topologically consistent and therefore is able to detect non-
bifurcating tree topologies that may contain polytomies and sampled ancestors.
We present an eﬃcient algorithm for solving the corresponding optimization prob-
lem, which is inherently more diﬃcult than standard (cid:96)1-penalized problems with
regular cost functions. The algorithm is based on recent developments on proxi-
mal gradient descent methods and their various acceleration techniques (Beck and
Teboulle, 2009; O’Donoghue and Candes, 2013). As far as we know, this procedure
gives the ﬁrst maximum likelihood based method for non-bifurcating phylogenetic
inference.

We have done a wide range of experiments to demonstrate the eﬃciency and
eﬀectiveness of our method. We show in a synthetic study that although the
(non-adaptive) phylogenetic LASSO has diﬃculty ﬁnding zero-length branches, the
adaptive phylogenetic LASSO provides signiﬁcant improvement on sparsity recovery
which validates its theoretical properties. Although assuming a ﬁxed tree topology
for deriving the statistical consistency, our method can be used to discover non-
bifurcating tree topologies in real data problems when combined with traditional
maximum likelihood phylogenetic inference methods. Our experiments have shown
that the adaptive phylogenetic LASSO performs comparably with other MCMC
based sparsity encouraging procedures (rjMCMC) in terms of sparsity recovery
while being computationally more eﬃcient as an optimization approach. We also
compare our method to a heuristic simple thresholding approach and ﬁnd that
regularization permits more consistent performance. Finally, we show that com-
pared to rjMCMC, the adaptive phylogenetic LASSO is more likely to detect short
branches while identifying zero branches with high accuracy. It is worth mentioning
that while lots of sparsity can be detected by maximizing the likelihood with non-
negative constraints, the adaptive phylogenetic LASSO can be advantageous when
there exist challenging zero-branches in the tree topologies with high likelihoods.
Our results oﬀer new insights into non-bifurcating phylogenetic inference methods
and support the use of (cid:96)1 penalty in statistical modeling with more general settings.
We leave some questions to future work. For the theory, the rate with which we
can allow the number of leaves to go to inﬁnity in terms of the sequence length is not
yet known. We have also not explored the extent to which the optimal penalized
tree is a contraction of the ML unpenalized tree. Also, although we have laid
the algorithmic foundation for eﬃcient penalized inference, there is further work
to be done to make a streamlined implementation that is integrated with existing
phylogenetic inference packages.

7. Acknowledgements

The authors would like to thank Vladimir Minin and Noah Simon for helpful
discussions, and Sidney Bell for helping with the Dengue sequence data. This work
supported by National Institutes of Health grants R01-GM113246, R01-AI120961,
U19-AI117891, and U54-GM111274 as well as National Science Foundation grants
CISE-1561334 and CISE-1564137. The research of Frederick Matsen was supported
in part by a Faculty Scholar grant from the Howard Hughes Medical Institute and
the Simons Foundation.

24

ZHANG, DINH, AND MATSEN

References

Beck, A. and M. Teboulle (2009, January). A fast iterative Shrinkage-Thresholding
algorithm for linear inverse problems. SIAM J. Imaging Sci. 2 (1), 183–202.
B¨uhlmann, P. and L. Meier (2008, August). Discussion: One-step sparse estimates

in nonconcave penalized likelihood models. Ann. Stat. 36 (4), 1534–1541.

Chen, R. and E. C. Holmes (2008, June). The evolutionary dynamics of human

inﬂuenza B virus. J. Mol. Evol. 66 (6), 655–663.

Combettes, P. L. and V. R. Wajs (2006). Signal recovery by proximal forward-

backward splitting. Multiscale Modeling and Simulation 4 (4), 1168–1200.

Dinh, V., L. S. T. Ho, M. A. Suchard, and F. A. Matsen IV (2016, 9 June).
Consistency and convergence rate of phylogenetic inference via regularization.
arXiv; accepted to Annals of Statistics. http://arxiv.org/abs/1606.03059.
Dinh, V. C., L. S. Ho, B. Nguyen, and D. Nguyen (2016). Fast learning rates with
heavy-tailed losses. In Advances in Neural Information Processing Systems, pp.
505–513.

Efron, B., T. Hastie, I. Johnstone, and R. Tibshirani (2004). Least angle regression.

Annals of Statistics 32 (2), 407–499.

Evans, S. N. and T. P. Speed (1993, March). Invariants of some probability models

used in phylogenetic inference. Ann. Stat. 21 (1), 355–377.

Foster, P. G. (2004). Modeling compositional heterogeneity. Syst. Biol. 53, 485–495.
Gardy, J., N. J. Loman, and A. Rambaut (2015, July). Real-time digital pathogen

surveillance — the time is now. Genome Biol. 16 (1), 155.

Gavryushkina, A., T. A. Heath, D. T. Ksepka, T. Stadler, D. Welch, and A. J.
Drummond (2016, August). Bayesian Total-Evidence dating reveals the recent
crown radiation of penguins. Syst. Biol..

Gavryushkina, A., D. Welch, T. Stadler, and A. J. Drummond (2014, December).
Bayesian inference of sampled ancestor trees for epidemiology and fossil calibra-
tion. PLoS Comput. Biol. 10 (12), e1003919.

Georgiou, G., G. C. Ippolito, J. Beausang, C. E. Busse, H. Wardemann, and S. R.
Quake (2014, January). The promise and challenge of high-throughput sequenc-
ing of the antibody repertoire. Nat. Biotechnol..

Grenfell, B. T., O. G. Pybus, J. R. Gog, J. L. N. Wood, J. M. Daly, J. A. Mumford,
and E. C. Holmes (2004, January). Unifying the epidemiological and evolutionary
dynamics of pathogens. Science 303 (5656), 327–332.

Hadﬁeld, J., C. Megill, S. M. Bell, J. Huddleston, B. Potter, C. Callender, P. Sag-
ulenko, T. Bedford, and R. A. Neher (2017, November). Nextstrain: real-time
tracking of pathogen evolution.

Ji, S., J. Koll´ar, and B. Shiﬀman (1992). A global (cid:32)Lojasiewicz inequality for al-
gebraic varieties. Transactions of the American Mathematical Society 329 (2),
813–818.

Jukes, T. H. and C. R. Cantor (1969). Evolution of protein molecules. In H. N.
Munro (Ed.), Mammalian protein metabolism, Volume 3, pp. 21–132. New York:
Academic Press.

Kleinstein, S. H., Y. Louzoun, and M. J. Shlomchik (2003, November). Estimating
hypermutation rates from clonal tree data. J. Immunol. 171 (9), 4639–4649.
Kuiken, C., J. Thurmond, M. Dimitrijevic, and H. Yoon (2012, January). The
LANL hemorrhagic fever virus database, a new platform for analyzing biothreat
viruses. Nucleic Acids Res. 40 (Database issue), D587–92.

NON-BIFURCATING PHYLOGENETIC TREE INFERENCE VIA THE ADAPTIVE LASSO 25

Lewis, P. O., M. T. Holder, and K. E. Holsinger (2005, April). Polytomies and

bayesian phylogenetic inference. Syst. Biol. 54 (2), 241–253.

Lewis, P. O., M. T. Holder, and D. L. Swoﬀord (2015, January). Phycas: Software

for bayesian phylogenetic analysis. Syst. Biol..

Libin, P., E. Vanden Eynden, F. Incardona, A. Now´e, A. Bezenchek, EucoHIV study
group, A. S¨onnerborg, A.-M. Vandamme, K. Theys, and G. Baele (2017, August).
PhyloGeoTool:
interactively exploring large phylogenies in an epidemiological
context. Bioinformatics.

Liu, Y., Z. Zhan, J. F. Cai, D. Guo, Z. Chen, and X. Qu (2016). Projected itera-
tive soft-thresholding algorithm for tight frames in compressed sensing magnetic
resonance imaging. IEEE Trans. Med. Imag. 35 (9), 2130–2140.

Loh, P.-L. (2017). Statistical consistency and asymptotic normality for high-

dimensional robust m-estimators. The Annals of Statistics 45 (2), 866–896.

Loh, P.-L. and M. J. Wainwright (2013). Regularized m-estimators with noncon-
vexity: Statistical and algorithmic theory for local optima. In Advances in Neural
Information Processing Systems, pp. 476–484.

Neher, R. A. and T. Bedford (2015, June). nextﬂu: Real-time tracking of seasonal

inﬂuenza virus evolution in humans. Bioinformatics.

O’Donoghue, B. and E. Candes (2013). Adaptive restart for accelerated gradient

schemes. Foundations of Computational Mathematics 15, 515–732.

Ronquist, F., M. Teslenko, P. van der Mark, D. L. Ayres, A. Darling, S. H¨ohna,
B. Larget, L. Liu, M. A. Suchard, and J. P. Huelsenbeck (2012, 22 February).
MrBayes 3.2: eﬃcient bayesian phylogenetic inference and model choice across a
large model space. Syst. Biol. 61 (3), 539–542.

Stamatakis, A. (2014). Raxml version 8: a tool for phylogenetic analysis and post-
analysis of large phylogenies. Bioinformatics 30 (9), 1312–1313. doi:10.1093/
bioinformatics/btu033.

Tibshirani, R. (1996, January). Regression shrinkage and selection via the lasso. J.

R. Stat. Soc. Series B Stat. Methodol. 58 (1), 267–288.

Van Erven, T., P. D. Gr¨unwald, N. A. Mehta, M. D. Reid, and R. C. Williamson
(2015). Fast rates in statistical and online learning. Journal of Machine Learning
Research 16, 1793–1861.

Victora, G. D. and M. C. Nussenzweig (2012, January). Germinal centers. Annu.

Rev. Immunol. 30, 429–457.

Zou, H. (2006). The adaptive lasso and its oracle properties. Journal of the Amer-

ican statistical association 101 (476), 1418–1429.

8. Appendix

8.1. Lemmas. Here we perform further theoretical development to establish the
main theorems. We remind the reader that we will continue to assume Assump-
tions 2.1 and 2.2. The following lemma allows gives a lower bound on the fraction
of sites with state assignments in a given set. It will prove useful to obtain an upper
bound on the likelihood.

Lemma 8.1. For any non-empty set A of single-site state assignments to the leaves,
we deﬁne

kA = |{i : Yi ∈ A}|

26

ZHANG, DINH, AND MATSEN

There exist c3 > 0, c4(δ, n) > 0 such that for all k, we have
kA
k

≥ c3 −

∀A (cid:54)= ∅

c4√
k

with probability at least 1 − δ.

Proof of Lemma 8.1. Since the tree distance between any pairs of leaves of the true
tree is strictly positive, there exists c3 > 0 such that Pq∗ (ψ) ≥ c3 for all state
assignments ψ.

Using Hoeﬀding’s inequality, for any state assignment ψ, we have

P

(cid:20)(cid:12)
(cid:12)
(cid:12)
(cid:12)

k{ψ}
k

(cid:12)
(cid:12)
− Pq∗ (ψ)
(cid:12)
(cid:12)

(cid:21)

≥ t

≤ 2e−2kt2

.

We deduce that

(cid:20)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
For any given δ > 0, by choosing

∃ψ such that

P

k{ψ}
k

(cid:12)
(cid:12)
− Pq∗ (ψ)
(cid:12)
(cid:12)

(cid:21)

≥ t

≤ 2e−2kt2

· 4N .

and t = c4(δ, N )/

(cid:114)

c4(δ, N ) =

log(1/δ) + (2N + 1) log 2
2

√

k we have
(cid:12)
k{ψ}
(cid:12)
(cid:12)
k
(cid:12)

(cid:12)
(cid:12)
− Pq∗ (ψ)
(cid:12)
(cid:12)

≤

c4(δ, N )
√
k

∀ψ

with probability at least 1 − δ. This proves the Lemma.

(cid:3)

Lemma 8.2 (Chernoﬀ bound). Let X be any bounded random variable with µ =
E[X], σ2 = Var[X]. Let b denote an upper bound of |X|; there exists Cb > 0 such
that

P[X − µ ≤ −t] ≤ exp

−

, ∀t > 0.

and

P[|X − µ| ≥ t] ≤ 2 exp

−

, ∀t > 0.

(cid:18)

(cid:18)

(cid:19)

t2
Cbσ2

(cid:19)

t2
Cbσ2

Proof of Lemma 8.2. Deﬁne

(cid:40)

κ(x) =

(ex − 1 − x)/x2,
1/2

if x > 0
if x = 0.

We have P[|X − µ| ≥ t] = 0 for t > 2b. Hence, we only need to consider the case
when t ≤ 2b. Applying Lemma 5.6 in Van Erven et al. (2015) for λ(X − µ) (which
is bounded from above by a := 2λb), we have

(8.1)

λ2κ(−4λb)σ2 ≤ log E[e−λ(X−µ)] ≤ λ2κ(4λb)σ2, ∀λ > 0.

From Markov’s inequality,

P[X − µ ≤ −t] = P[e−(X−µ) ≥ et] ≤

E[e−λ(X−µ)]
eλt

.

Using (8.1), we deduce that

P[X − µ ≤ −t] ≤ exp (cid:0)λ2κ(4λb)σ2 − λt(cid:1) .

NON-BIFURCATING PHYLOGENETIC TREE INFERENCE VIA THE ADAPTIVE LASSO 27

Note that limλ→0 λκ(4λb) = 0 and limλ→+∞ λκ(4λb) = +∞. Therefore, we can
choose λt,σ2 such that λt,σ2 κ(4λt,σ2b) = t/(2σ2). Since t ≤ 2b and σ2 is bounded,
there exists Cb > 0 such that 4κ(4λt,σ2 b) ≤ Cb for all t ∈ [−b, b]. Thus,
(cid:18)

(cid:18)

(cid:19)

(cid:19)

P[X − µ ≤ −t] ≤ exp(−λt,σ2 t/2) = exp

−

t2
4κ(4λt,σ2b)σ2

≤ exp

−

t2
Cbσ2

.

The argument is similar for the upper bound on P[X − µ ≥ t]. Combining the two
(cid:3)
estimates, we also obtain the second claim of the lemma.

Lemma 8.3 (Generalization bound). There exists a constant C(δ, n, Q, η, g0, µ) >
0 such that for any k ≥ 3, δ > 0, we have:

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
k

(cid:12)
(cid:12)
(cid:96)k(q) − φ(q)
(cid:12)
(cid:12)

≤ C

(cid:18) log k
k

(cid:19)1/2

∀q ∈ T (µ)

with probability greater than 1 − δ.

Proof. Note that for q ∈ T (µ), 0 ≥ (cid:96)k(ψ) ≥ −µ for all state assignment ψ, we
obtain

Var

(cid:96)k(q)

≤

(cid:20) 1
k

(cid:21)

µ2
k

.

Using Lemma 8.2, there exists a c5 such that
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:96)k(q) − φ(q)

≤ 2 exp

≥ y/2

(cid:20)(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
k

−

(cid:18)

P

(cid:21)

y2
4c5 Var[Uk(q)]

(cid:19)

≤ 2 exp

−

(cid:18)

(cid:19)

.

y2k
4c5µ2

For each q ∈ T (µ), k > 0, and y > 0, deﬁne the events

A(q, k, y) =

(cid:26)(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
k

(cid:12)
(cid:12)
(cid:96)k(q) − φ(q)
(cid:12)
(cid:12)

(cid:27)

> y/2

and

(cid:26)

B(q, k, y) =

∃q(cid:48) ∈ T (µ) such that (cid:107)q(cid:48) − q(cid:107)2 ≤

and

y
4c2

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
k

(cid:12)
(cid:12)
(cid:96)k(q) − φ(q)
(cid:12)
(cid:12)

(cid:27)

> y

then B(q, k, y) ⊂ A(q, k, y) by the triangle inequality, (3.3), and (3.4). Let

(cid:114)

y =

C log k
k

Since T (µ) is a subset of R2N −3, there exist C2N −3 ≥ 1 and a ﬁnite set H ⊂ T (µ)
such that

T (µ) ⊂

V (q, (cid:15))

and

|H| ≤ C2N −3/(cid:15)2N −3

(cid:91)

q∈H

where (cid:15) = y/(4c2), V (q, (cid:15)) denotes the open ball centered at q with radius (cid:15), and
|H| denotes the cardinality of H. By a simple union bound, we have

(cid:20)

P

∃q ∈ H :

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
k

(cid:12)
(cid:12)
(cid:96)k(q) − φ(q)
(cid:12)
(cid:12)

> y/2

≤ 2 exp

−

(cid:19)

y2k
4c5µ2

(cid:46)

C2N −3

(cid:15)2N −3.

Using the fact that B(q, k, y) ⊂ A(q, k, y) for all q ∈ H, we deduce

(cid:20)

P

∃q ∈ T (µ) :

(cid:96)k(q) − φ(q)

> y

≤ 2 exp

−

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
k

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:19)

y2k
4c5µ2

(cid:46)

C2N −3

(cid:15)2N −3.

(cid:21)

(cid:21)

(cid:18)

(cid:18)

28

ZHANG, DINH, AND MATSEN

To complete the proof, we need to chose C in such a way that

C2N −3

(cid:32)

√
4
√

kg0c2
C log k

(cid:33)2N −3

× 2 exp

−

(cid:18)

(cid:19)

C log k
4c5µ2

≤ δ.

Since k ≥ 3 and C ≥ 1, the inequality is valid if

C2N −3 (4g0c2)2N −3 × 2k

2N −3

2 − C

4c5µ2 ≤ δ

and

C2N −3 (4g0c2)2N −3 × 2 · 3

2N −3

2 − C

4c5µ2 ≤ δ.

In other words, we need to choose C such that

C ≥ 4c5µ2 (cid:16)

log(1/δ) + log C2N −3 + (2N − 3) log(4

3g0c2)

.

√

(cid:17)

and can be obtained if

2N − 3
2

−

C
4c5µ2 < 0,

This completes the proof.

8.2. Technical proofs.

(cid:3)

Lemma 2.3. If the penalty Rk is continuous on T , then for λ > 0 and observed
sequences Yk, there exists a q ∈ T minimizing

Proof of Lemma 2.3. Let {qn} be a sequence such that

Zλ,Yk (q) = −

(cid:96)k(q) + λRk(q).

1
k

Zλ,Yk (qn) → ν := inf
q

Zλ,Yk (q).

We note that since (cid:96)k(q∗) (cid:54)= −∞ and Rk is continuous on the compact set T , ν is
ﬁnite. Since T is compact, we deduce that a subsequence {qm} converges to some
q0 ∈ T . Since the log likelihood (deﬁned on T with values in the extended real line
[−∞, 0]) and the penalty Rk are continuous, we deduce that q0 is a minimizer of
(cid:3)
Zλ,Yk .

Lemma 3.5. For any µ > 0, there exists a constant c2(N, Q, η, g0, µ) > 0 such
that

(3.3)

and

(3.4)
for all q, q(cid:48) ∈ T (µ).

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
k

(cid:12)
(cid:12)
(cid:96)k(q(cid:48))
(cid:12)
(cid:12)

1
k

(cid:96)k(q) −

≤ c2(cid:107)q − q(cid:48)(cid:107)2

|φ(q) − φ(q(cid:48))| ≤ c2(cid:107)q − q(cid:48)(cid:107)2

Proof of Lemma 3.5. Using the same arguments as in the proof of Lemma 4.2 of
Dinh et al. (2016), we have

(cid:12)
(cid:12)
(cid:12)
(cid:12)
for any state assignment ψ where ς is the element of largest magnitude in the rate
matrix Q. By the Mean Value Theorem, we have

∂Pq(ψ)
∂qi

≤ ς4n

(cid:12)
(cid:12)
(cid:12)
(cid:12)

| log Pq(ψ) − log Pq(cid:48)(ψ)| ≤ c2

2N − 3(cid:107)q − q(cid:48)(cid:107)2

∀q, q(cid:48), ψ

√

where c2 := ς4n/e−µ, and (cid:107) · (cid:107)2 is the (cid:96)2-distance in R2N −3. This implies both (3.3)
(cid:3)
and (3.4).

NON-BIFURCATING PHYLOGENETIC TREE INFERENCE VIA THE ADAPTIVE LASSO 29

Lemma 3.6. Let Gk be the set of all branch length vectors q ∈ T (µ) such that
E [Uk(q)] ≥ 1/k. Let β ≥ 2 be the constant in Lemma 3.3. For any δ > 0 and
previously speciﬁed variables there exists C(δ, N, Q, η, g0, µ, β) ≥ 1 (independent of
k) such that for any k ≥ 3, we have:

Uk(q) ≥

E[Uk(q)] −

1
2

C log k
k2/β

∀q ∈ Gk

with probability greater than 1 − δ.

Proof of Lemma 3.6. The diﬀerence of average likelihoods Uk(q) is bounded by
Lemma 3.5 and the boundedness assumption on T , thus by Lemma 8.2 there exists
c6 > 0 such that

P [Uk(q) − E [Uk(q)] ≤ −y] ≤ exp

−

(cid:18)

y2
c6 Var[Uk(q)]

(cid:19)

.

By choosing y = 1
2
deduce using (3.5) (and the fact that β ≥ 2) that

E [Uk(q)] + t/2, we have y2 ≥ tE [Uk(q)]. For any q ∈ Gk, we

(cid:20)
Uk(q) ≤

P

(cid:21)
E [Uk(q)] − t/2

(cid:18)

≤ exp

−

1
2

1tkE[Uk(q)]
c2
2c6E[Uk(q)]2/β
c2

(cid:19)

(cid:18)

≤ exp

−

(cid:19)

.

c2
1tk2/β
c2
2c6

For each q ∈ Gk, deﬁne the events
(cid:26)

A(q, k, t) =

Uk(q) −

E [Uk(q)] ≤ −t/2

and

(cid:26)

B(q, k, t) =

∃q(cid:48) ∈ Gk such that (cid:107)q(cid:48) − q(cid:107)2 ≤

and Uk(q(cid:48)) −

E [Uk(q(cid:48))] ≤ −t

then B(q, k, t) ⊂ A(q, k, t) by the triangle inequality, (3.3), and (3.4). Let

(cid:27)

1
2

1
2

t
4c2

t =

C log k
k2/β

.

To obtain a union bound and complete the proof, we need to chose C in such a way
that

C2N −3

(cid:18) 4k2/βg0c2
C log k

(cid:19)2N −3

(cid:18)

× 2 exp

−

(cid:19)

c2
1C log k
c2
2c6

≤ δ

where C2N −3 is deﬁned as in the proof of Lemma 8.3. This can be done by choosing

C ≥

2c6

8βc2
9c2
1

(cid:16)

(cid:17)
log(1/δ) + log C2N −3 + (2N − 3) log(4 · 32/βg0c2)

.

(cid:27)

(cid:3)

Lemma 3.8. There exist µ∗ > 0 and an open neighborhood V of q∗ in T such that
V ⊂ T (µ∗).

Proof of Lemma 3.8. Let

µ∗ = −2 min
ψ

log Pq∗ (ψ)

then we have log Pq∗ (ψ) > −µ∗ for all state assignments ψ.

For a ﬁxed value of ψ, log Pq(ψ) is a continuous function of q around q∗. Hence,
there exists an neighborhood Vψ of q∗ such that Vψ is open in T and log Pq(ψ) >

30

ZHANG, DINH, AND MATSEN

−µ∗. Let V = ∩ψVψ. Because the set of all possible labels ψ of the leaves is ﬁnite,
V is open in T and

log Pq(ψ) > −µ∗

∀ψ, ∀q ∈ V.

In other words, we have V ⊂ T (µ∗).

(cid:3)

Lemma 3.9. If the sequence {λkRk(q∗)} is bounded, then for any δ > 0, there
exist µ(δ) > 0 and K(δ) > 0 such that for all k ≥ K, qk,Rk ∈ T (µ) with probability
at least 1 − 2δ.

Proof of Lemma 3.9. We ﬁrst assume that µ > µ∗, where µ∗ is deﬁned in Lemma 3.8.
Thus, we have q∗ ∈ T (µ∗) ⊂ T (µ). By deﬁnition, we have

1
k
which implies via Lemma 8.3 that

−

1
k

(cid:96)k(qk,Rk ) + λkRk(qk,Rk ) ≤ −

(cid:96)k(q∗) + λkRk(q∗)

(8.2)

φ(q∗) − C(δ)

+ λkRk(qk,Rk ) − λkRk(q∗) ≤

(cid:96)k(qk,Rk )

1
k

log k
√
k

with probability at least 1 − δ.

Let c3 and c4(δ, N ) be as in Lemma 8.1, and assume that k is large enough such

that

(8.3)

c3 − c4(δ, N )

> 0.

log k
√
k

Denoting the upper bound of {λkRk(q∗)} by U , we deﬁne

(cid:40)

(cid:18)

µ = max

−2

c3 − c4(δ, N )

φ(q∗) − C(δ)

(cid:19)−1 (cid:18)

log k
√
k

(cid:19)

(cid:41)

− U

, µ∗

.

log k
√
k

If we assume that qk,Rk (cid:54)∈ T (µ), then the set I = {ψ : log Pqk,Rk (ψ) ≤ −µ} is
non-empty. Using Lemma 8.1, we have

(8.4)

(cid:96)k(qk,Rk ) ≤

log Pqk,Rk (Yi) ≤ −µ ·

≤ −µ ·

c3 − c4(δ)

(cid:18)

kI
k

(cid:19)

log k
√
k

1
k

1
k

(cid:88)

Yi∈I

with probability at least 1 − δ.

bounded by U , we obtain

Combining equations (8.2) and (8.4), and using the fact that {λkRk(q∗)} is

φ(q∗) − C(δ)

− U ≤ −µ ·

c3 − c4(δ, N )

(cid:18)

log k
√
k

(cid:19)

.

log k
√
k

This contradicts the choice of µ for k large enough such that (8.3) holds.

We deduce that qk,Rk ∈ T (µ) with probability at least 1 − 2δ.

(cid:3)

8.3. More experimental results. Here we present additional experimental re-
sults for the case of γ > 1.

NON-BIFURCATING PHYLOGENETIC TREE INFERENCE VIA THE ADAPTIVE LASSO 31

Figure S1. Topological consistency comparison of diﬀerent phy-
logenetic LASSO procedures on simulation 2. γ = 1.01.

Figure S2. Topological consistency comparison of diﬀerent phy-
logenetic LASSO procedures on simulation 2. γ = 1.1.

32

ZHANG, DINH, AND MATSEN

Figure S3. Box plot showing performance of multistep adaptive
phylogenetic LASSO and rjMCMC at detecting short branches.
γ = 1.1

