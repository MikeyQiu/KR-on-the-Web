Caffe: Convolutional Architecture
for Fast Feature Embedding∗

Yangqing Jia∗, Evan Shelhamer∗, Jeff Donahue, Sergey Karayev,
Jonathan Long, Ross Girshick, Sergio Guadarrama, Trevor Darrell
UC Berkeley EECS, Berkeley, CA 94702
{jiayq,shelhamer,jdonahue,sergeyk,jonlong,rbg,sguada,trevor}@eecs.berkeley.edu

4
1
0
2
 
n
u
J
 
0
2
 
 
]

V
C
.
s
c
[
 
 
1
v
3
9
0
5
.
8
0
4
1
:
v
i
X
r
a

ABSTRACT
Caﬀe provides multimedia scientists and practitioners with
a clean and modiﬁable framework for state-of-the-art deep
learning algorithms and a collection of reference models.
The framework is a BSD-licensed C++ library with Python
and MATLAB bindings for training and deploying general-
purpose convolutional neural networks and other deep mod-
els eﬃciently on commodity architectures. Caﬀe ﬁts indus-
try and internet-scale media needs by CUDA GPU computa-
tion, processing over 40 million images a day on a single K40
or Titan GPU (≈ 2.5 ms per image). By separating model
representation from actual implementation, Caﬀe allows ex-
perimentation and seamless switching among platforms for
ease of development and deployment from prototyping ma-
chines to cloud environments.

Caﬀe is maintained and developed by the Berkeley Vi-
sion and Learning Center (BVLC) with the help of an ac-
tive community of contributors on GitHub. It powers on-
going research projects, large-scale industrial applications,
and startup prototypes in vision, speech, and multimedia.

Categories and Subject Descriptors
I.5.1 [Pattern Recognition]: [Applications–Computer vi-
sion]; D.2.2 [Software Engineering]:
[Design Tools and
Techniques–Software libraries]; I.5.1 [Pattern Recognition]:
[Models–Neural Nets]

General Terms
Algorithms, Design, Experimentation

Keywords
Open Source, Computer Vision, Neural Networks, Parallel
Computation, Machine Learning
∗Corresponding Authors.
The work was done while
Yangqing Jia was a graduate student at Berkeley. He is
currently a research scientist at Google, 1600 Amphitheater
Pkwy, Mountain View, CA 94043.

.

1.

INTRODUCTION

A key problem in multimedia data analysis is discovery of
eﬀective representations for sensory inputs—images, sound-
waves, haptics, etc. While performance of conventional,
handcrafted features has plateaued in recent years, new de-
velopments in deep compositional architectures have kept
performance levels rising [8]. Deep models have outper-
formed hand-engineered feature representations in many do-
mains, and made learning possible in domains where engi-
neered features were lacking entirely.

We are particularly motivated by large-scale visual recog-
nition, where a speciﬁc type of deep architecture has achieved
a commanding lead on the state-of-the-art. These Con-
volutional Neural Networks, or CNNs, are discriminatively
trained via back-propagation through layers of convolutional
ﬁlters and other operations such as rectiﬁcation and pooling.
Following the early success of digit classiﬁcation in the 90’s,
these models have recently surpassed all known methods for
large-scale visual recognition, and have been adopted by in-
dustry heavyweights such as Google, Facebook, and Baidu
for image understanding and search.

While deep neural networks have attracted enthusiastic
interest within computer vision and beyond, replication of
published results can involve months of work by a researcher
or engineer. Sometimes researchers deem it worthwhile to
release trained models along with the paper advertising their
performance. But trained models alone are not suﬃcient for
rapid research progress and emerging commercial applica-
tions, and few toolboxes oﬀer truly oﬀ-the-shelf deployment
of state-of-the-art models—and those that do are often not
computationally eﬃcient and thus unsuitable for commercial
deployment.

To address such problems, we present Caﬀe, a fully open-
source framework that aﬀords clear access to deep architec-
tures. The code is written in clean, eﬃcient C++, with
CUDA used for GPU computation, and nearly complete,
well-supported bindings to Python/Numpy and MATLAB.
Caﬀe adheres to software engineering best practices, pro-
viding unit tests for correctness and experimental rigor and
speed for deployment. It is also well-suited for research use,
due to the careful modularity of the code, and the clean sep-
aration of network deﬁnition (usually the novel part of deep
learning research) from actual implementation.

In Caﬀe, multimedia scientists and practitioners have an
orderly and extensible toolkit for state-of-the-art deep learn-
ing algorithms, with reference models provided out of the
box. Fast CUDA code and GPU computation ﬁt industry
needs by achieving processing speeds of more than 40 mil-

Framework

License

CPU GPU source Training models

Development

Core
language Binding(s)

Open

Pretrained

Caﬀe

cuda-convnet [7]
Decaf [2]
OverFeat [9]
Theano/Pylearn2 [4] BSD
Torch7 [1]
BSD

BSD

C++

unspeciﬁed C++
BSD
unspeciﬁed

Python
Lua
Python
Lua

Python,
MATLAB
Python

C++,Python

distributed

discontinued
discontinued
centralized
distributed
distributed

Table 1: Comparison of popular deep learning frameworks. Core language is the main library language, while
bindings have an oﬃcially supported library interface for feature extraction, training, etc. CPU indicates
availability of host-only computation, no GPU usage (e.g., for cluster deployment); GPU indicates the GPU
computation capability essential for training modern CNNs.

lion images per day on a single K40 or Titan GPU. The
same models can be run in CPU or GPU mode on a vari-
ety of hardware: Caﬀe separates the representation from the
actual implementation, and seamless switching between het-
erogeneous platforms furthers development and deployment—
Caﬀe can even be run in the cloud.

While Caﬀe was ﬁrst designed for vision, it has been adopted

and improved by users in speech recognition, robotics, neu-
roscience, and astronomy. We hope to see this trend con-
tinue so that further sciences and industries can take advan-
tage of deep learning.

Caﬀe is maintained and developed by the BVLC with the
active eﬀorts of several graduate students, and welcomes
open-source contributions at http://github.com/BVLC/caffe.
We thank all of our contributors for their work!

2. HIGHLIGHTS OF CAFFE

Caﬀe provides a complete toolkit for training, testing,
ﬁnetuning, and deploying models, with well-documented ex-
amples for all of these tasks. As such, it’s an ideal starting
point for researchers and other developers looking to jump
into state-of-the-art machine learning. At the same time,
it’s likely the fastest available implementation of these algo-
rithms, making it immediately useful for industrial deploy-
ment.

Modularity. The software is designed from the begin-
ning to be as modular as possible, allowing easy extension to
new data formats, network layers, and loss functions. Lots
of layers and loss functions are already implemented, and
plentiful examples show how these are composed into train-
able recognition systems for various tasks.

Separation of representation and implementation.
Caﬀe model deﬁnitions are written as conﬁg ﬁles using the
Protocol Buﬀer language. Caﬀe supports network archi-
tectures in the form of arbitrary directed acyclic graphs.
Upon instantiation, Caﬀe reserves exactly as much memory
as needed for the network, and abstracts from its underly-
ing location in host or GPU. Switching between a CPU and
GPU implementation is exactly one function call.

Test coverage. Every single module in Caﬀe has a test,
and no new code is accepted into the project without corre-
sponding tests. This allows rapid improvements and refac-
toring of the codebase, and imparts a welcome feeling of
peacefulness to the researchers using the code.

Python and MATLAB bindings. For rapid proto-
typing and interfacing with existing research code, Caﬀe
provides Python and MATLAB bindings. Both languages

may be used to construct networks and classify inputs. The
Python bindings also expose the solver module for easy pro-
totyping of new training procedures.

Pre-trained reference models. Caﬀe provides (for aca-
demic and non-commercial use—not BSD license) reference
models for visual tasks, including the landmark “AlexNet”
ImageNet model [8] with variations and the R-CNN detec-
tion model [3]. More are scheduled for release. We are
strong proponents of reproducible research: we hope that
a common software substrate will foster quick progress in
the search over network architectures and applications.

2.1 Comparison to related software

We summarize the landscape of convolutional neural net-
work software used in recent publications in Table 1. While
our list is incomplete, we have included the toolkits that are
most notable to the best of our knowledge. Caﬀe diﬀers from
other contemporary CNN frameworks in two major ways:

(1) The implementation is completely C++ based, which
eases integration into existing C++ systems and interfaces
common in industry. The CPU mode removes the barrier of
specialized hardware for deployment and experiments once
a model is trained.

(2) Reference models are provided oﬀ-the-shelf for quick
experimentation with state-of-the-art results, without the
need for costly re-learning. By ﬁnetuning for related tasks,
such as those explored by [2], these models provide a warm-
start to new research and applications. Crucially, we publish
not only the trained models but also the recipes and code
to reproduce them.

3. ARCHITECTURE

3.1 Data Storage

rays called blobs.

Caﬀe stores and communicates data in 4-dimensional ar-

Blobs provide a uniﬁed memory interface, holding batches
of images (or other data), parameters, or parameter updates.
Blobs conceal the computational and mental overhead of
mixed CPU/GPU operation by synchronizing from the CPU
host to the GPU device as needed. In practice, one loads
data from the disk to a blob in CPU code, calls a CUDA
kernel to do GPU computation, and ferries the blob oﬀ to
the next layer, ignoring low-level details while maintaining
a high level of performance. Memory on the host and device
is allocated on demand (lazily) for eﬃcient memory usage.

Figure 1: An MNIST digit classiﬁcation example of a Caﬀe network, where blue boxes represent layers and
yellow octagons represent data blobs produced by or fed into the layers.

Models are saved to disk as Google Protocol Buﬀers1,
which have several important features: minimal-size binary
strings when serialized, eﬃcient serialization, a human-readable
text format compatible with the binary version, and eﬃ-
cient interface implementations in multiple languages, most
notably C++ and Python.

Large-scale data is stored in LevelDB2 databases. In our
test program, LevelDB and Protocol Buﬀers provide a through-
put of 150MB/s on commodity machines with minimal CPU
impact. Thanks to layer-wise design (discussed below) and
code modularity, we have recently added support for other
data sources, including some contributed by the open source
community.

3.2 Layers

A Caﬀe layer is the essence of a neural network layer: it
takes one or more blobs as input, and yields one or more
blobs as output. Layers have two key responsibilities for the
operation of the network as a whole: a forward pass that
takes the inputs and produces the outputs, and a backward
pass that takes the gradient with respect to the output, and
computes the gradients with respect to the parameters and
to the inputs, which are in turn back-propagated to earlier
layers.

Caﬀe provides a complete set of layer types including: con-
volution, pooling, inner products, nonlinearities like rectiﬁed
linear and logistic, local response normalization, element-
wise operations, and losses like softmax and hinge. These are
all the types needed for state-of-the-art visual tasks. Coding
custom layers requires minimal eﬀort due to the composi-
tional construction of networks.

3.3 Networks and Run Mode

Caﬀe does all the bookkeeping for any directed acyclic
graph of layers, ensuring correctness of the forward and
backward passes. Caﬀe models are end-to-end machine learn-
ing systems. A typical network begins with a data layer that
loads from disk and ends with a loss layer that computes the
objective for a task such as classiﬁcation or reconstruction.
The network is run on CPU or GPU by setting a single
switch. Layers come with corresponding CPU and GPU
routines that produce identical results (with tests to prove
it). The CPU/GPU switch is seamless and independent of
the model deﬁnition.

3.4 Training A Network

Caﬀe trains models by the fast and standard stochastic
gradient descent algorithm. Figure 1 shows a typical ex-
ample of a Caﬀe network (for MNIST digit classiﬁcation)
during training: a data layer fetches the images and labels

1https://code.google.com/p/protobuf/
2https://code.google.com/p/leveldb/

Figure 2: An example of the Caﬀe object classiﬁca-
tion demo. Try it out yourself online!

from disk, passes it through multiple layers such as con-
volution, pooling and rectiﬁed linear transforms, and feeds
the ﬁnal prediction into a classiﬁcation loss layer that pro-
duces the loss and gradients which train the whole network.
This example is found in the Caﬀe source code at exam-
ples/lenet/lenet_train.prototxt. Data are processed in
mini-batches that pass through the network sequentially. Vi-
tal to training are learning rate decay schedules, momentum,
and snapshots for stopping and resuming, all of which are
implemented and documented.

Finetuning, the adaptation of an existing model to new
architectures or data, is a standard method in Caﬀe. From
a snapshot of an existing network and a model deﬁnition for
the new network, Caﬀe ﬁnetunes the old model weights for
the new task and initializes new weights as needed. This
capability is essential for tasks such as knowledge transfer
[2], object detection [3], and object retrieval [5].

4. APPLICATIONS AND EXAMPLES

In its ﬁrst six months since public release, Caﬀe has al-
ready been used in a large number of research projects at
UC Berkeley and other universities, achieving state-of-the-
art performance on a number of tasks. Members of Berkeley
EECS have also collaborated with several industry partners
such as Facebook [11] and Adobe [6], using Caﬀe or its direct
precursor (Decaf) to obtain state-of-the-art results.

Object Classiﬁcation Caﬀe has an online demo3 show-
ing state-of-the-art object classiﬁcation on images provided
by the users, including via mobile phone. The demo takes
the image and tries to categorize it into one of the 1,000 Im-
ageNet categories4. A typical classiﬁcation result is shown
in Figure 2.

Furthermore, we have successfully trained a model with
all 10,000 categories of the full ImageNet dataset by ﬁne-
tuning this network. The resulting network has been applied
to open vocabulary object retrieval [5].
3http://demo.caffe.berkeleyvision.org/
4http://www.image-net.org/challenges/LSVRC/2013/

Figure 3: Features extracted from a deep network,
visualized in a 2-dimensional space. Note the clear
separation between categories, indicative of a suc-
cessful embedding.

Learning Semantic Features In addition to end-to-end
training, Caﬀe can also be used to extract semantic features
from images using a pre-trained network. These features
can be used “downstream” in other vision tasks with great
success [2]. Figure 3 shows a two-dimensional embedding
of all the ImageNet validation images, colored by a coarse
category that they come from. The nice separation testiﬁes
to a successful semantic embedding.

Intriguingly, this learned feature is useful for a lot more
than object categories. For example, Karayev et al. have
shown promising results ﬁnding images of diﬀerent styles
such as “Vintage” and “Romantic” using Caﬀe features (Fig-
ure 4) [6].

Ethereal

HDR

Melancholy Minimal

Figure 4: Top three most-conﬁdent positive pre-
dictions on the Flickr Style dataset, using a Caﬀe-
trained classiﬁer.

Object Detection Most notably, Caﬀe has enabled us
to obtain by far the best performance on object detection,
evaluated on the hardest academic datasets: the PASCAL
VOC 2007-2012 and the ImageNet 2013 Detection challenge
[3].

Girshick et al. [3] have combined Caﬀe together with tech-
niques such as Selective Search [10] to eﬀectively perform
simultaneous localization and recognition in natural images.
Figure 5 shows a sketch of their approach.

Beginners’ Guides To help users get started with in-
stalling, using, and modifying Caﬀe, we have provided in-
structions and tutorials on the Caﬀe webpage. The tuto-
rials range from small demos (MNIST digit recognition) to
serious deployments (end-to-end learning on ImageNet).

Although these tutorials serve as eﬀective documentation
of the functionality of Caﬀe, the Caﬀe source code addition-
ally provides detailed inline documentation on all modules.

Figure 5: The R-CNN pipeline that uses Caﬀe for
object detection.

This documentation will be exposed in a standalone web
interface in the near future.

5. AVAILABILITY

Source code is published BSD-licensed on GitHub.5 Project
details, step-wise tutorials, and pre-trained models are on
the homepage.6 Development is done in Linux and OS X,
and users have reported Windows builds. A public Caﬀe
Amazon EC2 instance is coming soon.

6. ACKNOWLEDGEMENTS

We would like to thank NVIDIA for GPU donation, the
BVLC sponsors (http://bvlc.eecs.berkeley.edu/), and
our open source community.

7. REFERENCES

[1] R. Collobert, K. Kavukcuoglu, and C. Farabet. Torch7: A

MATLAB-like environment for machine learning. In
BigLearn, NIPS Workshop, 2011.

[2] J. Donahue, Y. Jia, O. Vinyals, J. Hoﬀman, N. Zhang,
E. Tzeng, and T. Darrell. Decaf: A deep convolutional
activation feature for generic visual recognition. In ICML,
2014.

[3] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich
feature hierarchies for accurate object detection and
semantic segmentation. In CVPR, 2014.

[4] I. Goodfellow, D. Warde-Farley, P. Lamblin, V. Dumoulin,

M. Mirza, R. Pascanu, J. Bergstra, F. Bastien, and
Y. Bengio. Pylearn2: a machine learning research library.
arXiv preprint 1308.4214, 2013.

[5] S. Guadarrama, E. Rodner, K. Saenko, N. Zhang,

R. Farrell, J. Donahue, and T. Darrell. Open-vocabulary
object retrieval. In RSS, 2014.

[6] S. Karayev, M. Trentacoste, H. Han, A. Agarwala,
T. Darrell, A. Hertzmann, and H. Winnemoeller.
Recognizing image style. arXiv preprint 1311.3715, 2013.

[7] A. Krizhevsky. cuda-convnet.

https://code.google.com/p/cuda-convnet/, 2012.
[8] A. Krizhevsky, I. Sutskever, and G. Hinton. ImageNet

classiﬁcation with deep convolutional neural networks. In
NIPS, 2012.

[9] P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus,

and Y. LeCun. Overfeat: Integrated recognition,
localization and detection using convolutional networks. In
ICLR, 2014.

[10] J. Uijlings, K. van de Sande, T. Gevers, and A. Smeulders.

Selective search for object recognition. IJCV, 2013.

[11] N. Zhang, M. Paluri, M. Ranzato, T. Darrell, and

L. Bourdev. Panda: Pose aligned networks for deep
attribute modeling. In CVPR, 2014.

5https://github.com/BVLC/caffe/
6http://caffe.berkeleyvision.org/

