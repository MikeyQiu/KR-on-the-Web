7
1
0
2
 
b
e
F
 
6
1
 
 
]

V
C
.
s
c
[
 
 
1
v
9
6
8
4
0
.
2
0
7
1
:
v
i
X
r
a

Improving automated multiple sclerosis lesion segmentation with a cascaded 3D
convolutional neural network approach

Sergi Valverdea,∗, Mariano Cabezasa, Eloy Rouraa, Sandra Gonz´alez-Vill`aa, Deborah Paretob,
Joan C. Vilanovac, Llu´ıs Rami´o-Torrent`ad, `Alex Rovirab, Arnau Olivera, Xavier Llad´oa

aResearch institute of Computer Vision and Robotics, University of Girona, Spain
bMagnetic Resonance Unit, Dept of Radiology, Vall d’Hebron University Hospital, Spain
cGirona Magnetic Resonance Center, Spain
dMultiple Sclerosis and Neuroimmunology Unit, Dr. Josep Trueta University Hospital, Spain

Abstract

In this paper, we present a novel automated method for White Matter (WM) lesion segmentation of Mul-
tiple Sclerosis (MS) patient images. Our approach is based on a cascade of two 3D patch-wise convolutional
neural networks (CNN). The ﬁrst network is trained to be more sensitive revealing possible candidate lesion
voxels while the second network is trained to reduce the number of misclassiﬁed voxels coming from the
ﬁrst network. This cascaded CNN architecture tends to learn well from small sets of training data, which
can be very interesting in practice, given the diﬃculty to obtain manual label annotations and the large
amount of available unlabeled Magnetic Resonance Imaging (MRI) data. We evaluate the accuracy of the
proposed method on the public MS lesion segmentation challenge MICCAI2008 dataset, comparing it with
respect to other state-of-the-art MS lesion segmentation tools. Furthermore, the proposed method is also
evaluated on two private MS clinical datasets, where the performance of our method is also compared with
diﬀerent recent public available state-of-the-art MS lesion segmentation methods. At the time of writing
this paper, our method is the best ranked approach on the MICCAI2008 challenge, outperforming the rest
of 60 participant methods when using all the available input modalities (T1-w, T2-w and FLAIR), while
still in the top-rank (3rd position) when using only T1-w and FLAIR modalities. On clinical MS data, our
approach exhibits a signiﬁcant increase in the accuracy segmenting of WM lesions when compared with
the rest of evaluated methods, highly correlating (r ≥ 0.97) also with the expected lesion volume.

Keywords: Brain, MRI, multiple sclerosis, automatic lesion segmentation, convolutional neural networks

1. Introduction

Multiple Sclerosis (MS) is the most common
chronic immune-mediated disabling neurological dis-
ease aﬀecting the central nervous system (Steinman,
1996). MS is characterized by areas of
inﬂam-
mation, demyelination, axonal loss, and the pres-
ence of lesions, predominantly in the white matter
(WM) tissue (Compston and Coles, 2008). Nowa-
days, magnetic resonance imaging (MRI) is exten-
sively used in the diagnosis and monitoring of MS
(Polman et al., 2011), due to the sensitivity of struc-

∗Corresponding author. S. Valverde, Ed. P-IV, Campus
Montilivi, University of Girona, 17071 Girona (Spain). e-mail:
svalverde@eia.udg.edu. Phone: +34 972 418878; Fax: +34
972 418976.

tural MRI disseminating WM lesions in time and
space (Rovira et al., 2015; Filippi et al., 2016). Al-
though expert manual annotations of lesions is feasi-
ble in practice, this task is both time-consuming and
prone to inter-observer variability, which has been
led progressively to the development of a wide num-
ber of automated lesion segmentation techniques
(Llad´o et al., 2012; Garc´ıa-Lorenzo et al., 2013).

decision

Among the vast literature in the ﬁeld, recent
techniques proposed for MS lesion segmenta-
tion include supervised learning methods
such
(Geremia et al.,
random forests
as
ensemble meth-
2011; Jesson and Arbel, 2015),
non-local means
ods
neighbors
(Guizard et al.,
2016)
(Steenwijk et al.,

k-nearest
Fartaria et al.,

(Cabezas et al.,

2015),
2013;

2014),

Preprint submitted to Elsevier

February 17, 2017

and combined inference from patient and healthy
populations (Tomas-Fernandez and Warﬁeld, 2015).
Several unsupervised methods have been also
in probabilistic models
proposed, based either
(Harmouche et al.,
2016)
and thresholding methods with post-processing
reﬁnement
2012; Roura et al.,
2015a).

(Schmidt et al.,

Strumia et al.,

2015;

During the last years, a renewed interest in deep
neural networks has been observed. Compared to
classical machine learning approaches, deep neu-
ral networks require lower manual feature engineer-
ing, which in conjunction with the increase in the
available computational power -mostly in graph-
ical processor units (GPU)-, and the amount of
available training data, make these type of tech-
niques very interesting (LeCun et al., 2015). In par-
ticular, convolutional neural networks (CNN) have
demonstrated breaking performance in diﬀerent do-
mains such as computer vision semantic segmenta-
tion (Simonyan and Zisserman, 2014) and natural
language understanding (Sutskever et al., 2014).

CNNs have also gained popularity in brain imag-
ing, specially in tissue segmentation (Zhang et al.,
2015; Moeskops et al., 2016a) and brain tumor seg-
mentation (Kamnitsas et al., 2016; Pereira et al.,
2016; Havaei et al., 2017). However, only a few
number of CNN methods have been introduced
so far to segment WM lesions of MS patients.
Brosch et al. (2016) have proposed a cross-sectional
MS lesion segmentation technique based on deep
three-dimensional (3D) convolutional encoder net-
works with shortcut connections and two intercon-
nected pathways. Furthermore, Havaei et al. (2016)
have also introduced another lesion segmentation
framework with independent image modality convo-
lution pipelines that reduces the eﬀect of missing
modalities of new unseen examples. In both cases,
authors reported a very competitive performance of
their respective methods in public and private data
such as the MS lesion segmentation challenge MIC-
CAI2008 database1, which is nowadays considered
as a performance benchmark between methods.

In this paper, we present a new pipeline for auto-
mated WM lesion segmentation of MS patient im-
ages, which is based on a cascade of two convolu-
tional neural networks. Although similar cascaded
approaches have been used with other machine learn-

1http://www.ia.unc.edu/MSseg

ing techniques in brain MRI (Moeskops et al., 2015;
Wang et al., 2015), and also in the context of CNNs
for coronary calcium segmentation (Wolterink et al.,
2016), to the best of our knowledge this is the
ﬁrst work proposing a cascaded 3D CNN approach
for MS lesion segmentation. Within our approach,
WM lesion voxels are inferred using 3D neigh-
boring patch features from diﬀerent input modali-
ties. The proposed architecture builds on an initial
prototype that we presented at the recent Multi-
ple Sclerosis Segmentation Challenge (MSSEG2016)
(Commowick et al., 2016)2. That particular pipeline
showed very promising results, outperforming the
rest of participant methods in the overall score of
the challenge. However, the method presented here
has been redesigned based on further experiments
to determine optimal patch size, regularization and
post-processing of lesion candidates. As in previous
studies (Roura et al., 2015a; Guizard et al., 2015;
Strumia et al., 2016; Brosch et al., 2016), we vali-
date our approach with both public and private MS
datasets. First, we evaluate the accuracy of our pro-
posed method with the MICCAI2008 public dataset
to compare the performance with respect to state-
of-the-art MS lesion segmentation tools. Secondly,
we perform an additional evaluation on two private
MS clinical datasets, where the performance of our
method is also compared with diﬀerent recent pub-
lic available state-of-the-art MS lesion segmentation
methods.

2. Methods

2.1. Input features

Training features are composed by multi-channel
3D patches sampled from a set of training images,
where a new channel is created for each input image
sequence available in the training database, but not
restricted to. 3D feature patches take advantage of
the spatial contextual information in MRI. 3D fea-
ture patches take advantage of the spatial contextual
information in MRI, which may be beneﬁcial in WM
lesion segmentation due to the 3D shape of WM le-
sions (Rovira et al., 2015). The following steps are
used to select the input features:

i) Each training image is ﬁrst subtracted by its
mean and divided from its variance, in order to

2https://portal.ﬂi-iam.irisa.fr/msseg-challenge/workshop-

day

2

(a) Cascade based pipeline

(b) Proposed CNN architecture

Figure 1: Proposed pipeline for WM lesion segmentation. (a) Cascade based pipeline, where the output of the ﬁrst CNN is
used to select the input features of the second CNN. (b) The proposed 7-layer CNN model is trained using multi-sequence 3D
image patches sampled from a set of training images, where each channel is created from each of the image sequences available
in the training database, but not restricted to. See Table 1 for details about each layer parameters.

normalize image intensities across diﬀerent im-
ages and speed-up training (LeCun et al., 1998).
ii) For each training image, we compute 3D axial
patches of size p centered on the voxel of in-
terest, where p denotes the size in each of the
dimensions.

iii) The set of all computed patches P is stacked as
P = [n × c × p × p × p], where n and c denote the
number of training voxels and available input
modalities, respectively.

In all experiments, input patch size p is set to
p = 11. This value has been empirically selected
after performing diﬀerent optimization experiments
with several patches sizes equal to p = {9, 11, 13,15}.

2.2. Cascade based training

When large amounts of training data are available,
several studies have shown that the addition of more
CNN layers improves the accuracy in neural net-
works classiﬁcation tasks (Simonyan and Zisserman,
2014; He et al., 2015), usually followed by an addi-
tional increase in the number of parameters in com-
parison to shallower networks (Krizhevsky et al.,
2012). However,
in MS lesion segmentation, the
number of available images with labeled data may
be limited by the high number of MRI slices to an-
notate manually (Llad´o et al., 2012). More impor-
tantly, from the entire number of available voxels,
only a very small number of those are lesions (∼ 1.5%

of total brain volume for a patient with 20ml le-
sion volume), which drastically reduces the number
of positive training samples.

These limitations clearly aﬀect the designed ar-
chitecture, as CNNs tends to suﬀer from overﬁtting
when they are not trained with enough data. In this
aspect, our particular approach has been designed to
deal with these two issues. By adequately sampling
the training data and splitting the training proce-
dure into two diﬀerent CNN networks, we design a
pipeline with fewer parameters while not compro-
mising the precision and the accuracy of segmenting
WM lesions. The next points present in detail each
of the necessary steps used by our cascade based
training procedure. For a more graphical explana-
tion, see Figure 1(a).

i) First, the set of input patches P = [n × c ×
p × p × p] is computed from the available train-
ing images and input modalities, as described
in Section 2.1. An additional list of labels Ln
is also computed using the manual expert lesion
annotations, where Ln = 1 if the current voxel
n is a lesion and Ln = 0 afterwards.

ii) From the entire set P , patches where the in-
tensity of the voxel of interest in the FLAIR
channel is (iF LAIR
< 0.5) are removed. WM
lesions are placed in either WM or Gray Mat-
ter (GM) boundaries, so by simply thresholding
voxels on the negative class to signal intensities

n

3

iF LAIR
< 0.5, we increase the chance of more
n
challenging negatives examples after sampling.
iii) In order to deal with data imbalance, we ran-
domly under-sample the negative class in P .
The training feature set F1 is composed by all
positive patches (WM lesion voxels) and the
same number of negative patches (healthy vox-
els) after randomly sampling them.

iv) The network (CN N1) is trained using the bal-
anced training feature set F1. Exact details of
the CNN architecture and training are described
in Sections 2.3 and 2.4, respectively.

v) All patches in P are afterwards evaluated us-
ing the already trained CN N1, obtaining the
probability Y 1
n of each voxel n to belong to the
positive class.
vi) Based on Y 1

n , a new balanced training feature
set F2 is created by using again all positive vox-
els in P and the same number of randomly se-
lected negative examples that have been mis-
classiﬁed in Y 1

n > 0.5 with Ln = 0.

n , so Y 1

vii) Finally,

the second CN N2 is trained from
scratch using the balanced training feature set
F2. The output of the CN N2 is the probability
Y 2
n for each voxel of being part of a WM lesion.

2.3. CNN architecture

Although increasingly deep CNN architectures
have been proposed in brain MRI lately (Chen et al.,
2016; C¸ i¸cek et al., 2016; Moeskops et al., 2016b),
still those tend to be shallower than other computer
vision CNN architectures proposed for object recog-
nition or image segmentation of natural images with
up to 150 layers (He et al., 2015), mostly due to fac-
tors such as a lower number of training samples, im-
age resolution, and a poorer contrast between classes
when compared to natural images. However, com-
pared with the latter, the lower variation in MRI
tissues permits the use of smaller networks, which
tends to reduce overﬁtting, specially in small train-
ing sets. Here, a 7-layer architecture is proposed for
both CN N1 and CN N2 (see Figure 1b). Each net-
work is composed by two stacks of convolution and
max-pooling layers with 32 and 64 ﬁlters, respec-
tively. Convolutional layers are followed by a fully-
connected (FC) layer of size 256 and a soft-max FC
layer of size 2 that returns the probability of each
voxel to belong to the positive and negative class.
Exact parameters of each of the layers are shown in
Table 1.

Table 1: Proposed 7-layer CNN architecture for input image
patch size of 11 × 11 × 11 with c input modalities as channels.
Layer description: 3D convolutional layer (CONV), 3D max-
pooling layer (MP) and fully-convolutional layer (FC). Same
architecture is proposed for both CNNs.

Layer
0
1
2
3
4
5
6

Type
input
CONV
MP
CONV
MP
FC
Softmax

Input size
c × 11 × 11 × 11
c × 11 × 11 × 11
32 × 5 × 5 × 5
64 × 5 × 5 × 5
64 × 2 × 2 × 2
256
2

Maps

Size

Stride

Pad

32
-
64
-
256
2

3

3

3

3

3
2
3
2
1
1

3

3

3

3

1
2
1
2
-
-

3

1
0
3
1
0
-
-

2.4. CNN training

To optimize CNN weights, training data is split
into training and validation sets. The training
set is used to adjust the weights of the neural
network, while the validation set is used to mea-
sure how well the trained CNN is performing af-
ter the epoch, deﬁned as a measure of the num-
ber of times all of the training samples are used
once to update the architecture’s weights. Each
CNN is trained individually without parameter
sharing. The rectiﬁed linear activation function
(ReLU) (Nair and Hinton, 2010) is applied to all
layers. All convolutional layers are initialized using
the method proposed by Glorot and Bengio (2010).
Network parameters are learned using the adap-
tive learning rate method (ADADELTA) proposed
by Zeiler (2012) with batch size of 128 and cate-
gorical cross-entropy as loss cost.
In order to re-
duce over-ﬁtting, batch-normalization regularization
(Ioﬀe and Szegedy, 2015) is used after both convolu-
tional layers, and Dropout (Srivastava et al., 2014)
with (p = 0.5) before the ﬁrst fully-connected layer.
Additionally, the CNN model is implemented with
early stopping, which permits also to prevent over-
ﬁtting by stopping training after a number of epochs
without a decrease in the validation error. Hence, ﬁ-
nal network parameters are taken from the epoch
with the lowest error before stopping.

2.5. Data augmentation

Data augmentation has been shown to be
an eﬀective method to increase the accuracy of
CNN networks in brain MRI (Pereira et al., 2016;
Havaei et al., 2017; Kamnitsas et al., 2016). Fol-
lowing a similar approach, we perform data aug-
mentation on-the-ﬂy at batch time by multiplying
the number of training samples by four following
for each mini-batch, all
the next transformations:

4

patches are ﬁrst rotated with 180 degrees in the ax-
ial plane. From the original and rotated versions of
the patches, new versions are computed by ﬂipping
those horizontally. Other rotations than 180 degrees
are avoided, in order to roughly maintain the sym-
metry of the brain and avoid artiﬁcial rotations of
brain structures.
In our empirical evaluations, ro-
tated patches were found to increase the segmenta-
tion accuracy of the proposed method in ∼ 1.5%
when compared to non-rotated patches.

2.6. CNN Testing

Once the proposed pipeline has been trained, new
unseen images are processed using the same CNN
cascade architecture (see Figure 2). For each new
subject to test, input feature patches for all brain
voxels are obtained using the approach proposed in
Section 2.1. All image patches are then evaluated us-
ing the ﬁrst trained CNN. The ﬁrst network discards
all voxels with low probability to be lesion. The rest
of the voxels are re-evaluated using the second CNN
obtaining the ﬁnal probabilistic lesion mask.

Binary output masks are computed by linear
thresholding tbin of probabilistic lesion masks. After-
wards, an additional false-positive reduction is per-
formed by discarding binary regions with lesion size
below lmin parameter. Both parameters tbin and
lmin are automatically optimized by averaging the
best values for each image used for training. Note
that using this process, tbin and lmin are only com-
puted once after training the network and can be
afterwards applied to an arbitrary number of unseen
testing images.

2.7. Implementation

The proposed method has been implemented in
the Python language3, using Keras4 and Theano5
(Bergstra et al., 2011) libraries. All experiments
have been run on a GNU/Linux machine box run-
ning Ubuntu 14.04, with 32GB RAM memory. CNN
training has been carried out on a single Tesla K-
40c GPU (NVIDIA corp, United States) with 12GB
RAM memory. The proposed method is currently
available for downloading at our research website6.

3https://www.python.org/
4https://keras.io/
5http://deeplearning.net/software/theano/
6https://github.com/NIC-VICOROB/cnn-ms-lesion-

segmentation

Figure 2: Proposed CNN testing procedure. New unseen sub-
jects are evaluated using the same cascade architecture of
trained networks. Voxels with ≥ 0.5 probability of being le-
sion in CN N1 are re-evaluated using the second CN N2. Final
segmentation masks are obtained by thresholding the proba-
bilistic mask obtained from the second CN N2.

3. Experimental Results

3.1. MICCAI 2008 MS lesion segmentation

3.1.1. Data

The MICCAI 2008 MS lesion segmentation chal-
lenge is composed by 45 scans from research subjects
acquired at Children’s Hospital Boston (CHB, 3T
Siemens) and University of North Carolina (UNC,
3T Siemens Alegra) (Styner et al., 2008). For each
subject, T1-w, T2-w and FLAIR image modalities
are provided with isotropic resolution of 0.5 × 0.5 ×
0.5 mm3 in all images. Data is distributed in two
sets:

• 20 training cases (10 CHB and 10 UNC) are pro-
vided with manual expert annotations of WM
lesions from a CHB and UNC expert rater.

5

• 25 testing cases (15 CHB and 10 UNC) provided

3.1.3. Experiment details

without expert lesion segmentation.

3.1.2. Evaluation

The evaluation is done blind for the teams by sub-
mitting the segmentation masks of the 25 testing
cases to the challenge website7. Submitted segmen-
tation masks are compared with manual annotations
of both UNC and CHB raters. The evaluation met-
rics are based on the following scores:

• The % error in lesion volume in terms of the ab-
solute diﬀerence in lesion volume (V D) between
manual annotations masks and output segmen-
tation masks:

V D =

|T Ps − T Pgt|
T Pgt

× 100

(1)

where T Ps and T Pgt denote the number of seg-
mented voxels in the output and manual anno-
tations masks, respectively.

• Sensitivity of the method in terms of the True
Positive Rate (T P R) between manual lesion an-
notations and output segmentation masks, ex-
pressed in %:

T P R =

T Pd
T Pd + F Nd

× 100

(2)

where T Pd and F Nd denote the number of cor-
rectly and missed lesion region candidates, re-
spectively.

• False discovery rate of the method in terms of
the False Positive Rate (F P R) between man-
ual lesion annotations and output segmentation
masks, also expressed in %:

F P R =

F Pd
F Pd + T Pd

× 100

(3)

where F Pd denotes number of lesion region can-
didates incorrectly classiﬁed as lesion.

From these evaluation metrics, a single score is com-
puted to rank each of the participant strategies, be-
ing 90 points comparable to human expert perfor-
mance (Styner et al., 2008).

7http://www.ia.unc.edu/MSseg/about.html

6

Provided FLAIR and T2-w image modalities were
already rigidly co-registered to the T1-w space.
All
images were ﬁrst skull-stripped using BET
(Smith et al., 2002) and intensity normalized us-
ing N3 (Sled et al., 1998) with smoothing dis-
tance parameter to 30-50 mm (Boyes et al., 2008;
Zheng et al., 2009). All training and testing im-
ages were then resampled from 512 × 512 × 512
(0.5 × 0.5 × 0.5mm) to 256 × 256 × 256 (1 × 1 × 1mm)
to reduce the computational training time. In order
to maintain the consistency between image modal-
ities and manual annotation masks, a two-step ap-
proach was followed: each of the modalities was ﬁrst
down-sampled to (256 × 256 × 256) by local aver-
aging. Then, each image modality in the original
space was registered against the same down-sampled
image, using the Statistical Parametric Mapping
(SPM) toolkit (Estimate and reslice), with normal-
ized mutual information as objective function. The
resulting transformation matrix of the FLAIR image
was then used to resample also manual annotations
to (256 × 256 × 256).

For this particular experiment, we trained two dif-

ferent pipelines:

i) one trained using all

input image modalities

available (T1-w, FLAIR and T2-w).

ii) one trained using only T1-w and FLAIR images.

Both pipelines were trained using the 20 available
images provided with manual expert annotations, re-
sulting on a balanced training database of 800.000
patches. 25% of the entire training dataset was set
to validation and the rest to train the network. As
reported in Styner et al. (2008), UNC manual an-
notations were adapted to match closely those from
CHB, so in our experiments only CHB annotations
were used to train the CNNs. The number of maxi-
mum training epochs was set 400 with early-stopping
of 50 for each network of the cascade. Test parame-
ters tbin and lmin were optimized during training to
tbin = 0.8, lmin = 5 and tbin = 0.7, lmin = 5 in the
ﬁrst and second pipeline, respectively.

3.1.4. Results

Table 2 shows the mean V D, T P R, F P R and ﬁ-
nal overall scores of the two proposed pipelines. Our
results are compared with other 10 out of 60 other
online participant strategies. At the time of writ-
ing this paper, our proposed pipeline using all avail-
able modalities (T1-w, FLAIR and T2-w) has been

Table 2: Segmentation results on the MICCAI 2008 MS lesion segmentation test set. Results are shown for 12 out of 60
participant methods. Mean V D, T P R and F P R and ﬁnal scores are shown split by CHB and UNC raters, as in the original
submission website. An overall score of 90 is considered comparable to human performance. The best value for each
score is depicted in bold. For a complete ranking of all the participant methods, please refer to the challenge website
http://www.ia.unc.edu/MSseg/about.html.

Rank Method

- Human rater
1
2,6
3

Proposed method (T1-w, FLAIR, T2-w)
Jesson and Arbel (2015)
Proposed method (T1-w, FLAIR)

4,5 Guizard et al. (2015)

7 Tomas-Fernandez and Warﬁeld (2015)

8,11
Jerman et al. (2016)
Brosch et al. (2016)
10
Strumia et al. (2016)
12
14 Roura et al. (2015a)

UNC rater
VD TPR FPR
-
46.8
32.3
44.1
43.5
44.1
64.7
52.7
34.6
43.2

-
55.5
43.9
50.6
47.0
42.0
59.0
47.1
37.7
44.9

-
62.5
46.9
34.4
46.3
37.8
58.1
63.5
56.9
65.2

CHB rater

VD TPR FPR Score
90.0
87.12
86.93
86.70
86.11
84.46
84.16
84.07
83.92
82.34

-
46.0
24.2
41.8
42.0
45.1
62.8
49.8
30.5
40.5

-
68.7
53.5
60.2
52.7
51.8
71.3
56.0
42.9
55.4

-
40.8
113.4
54.2
51.3
53.4
96.8
52.0
113.7
158.9

ranked in the ﬁrst position of the challenge, out-
performing the rest of participant strategies. More-
over, when only using T1-w and FLAIR images, our
pipeline was still very competitive and it was ranked
in the top three, only outperformed by the approach
proposed by Jesson and Arbel (2015).

In terms of V D, the proposed method returned
the lowest absolute diﬀerence in lesion volume of all
participants for either UNC manual annotations (us-
ing T1-w and FLAIR) or CHB annotations (using
T1-w, FLAIR and T2-w). Additionally, our CNN
approach depicted a very high sensitivity detect-
ing WM lesions (T P R), being only outperformed
by Jerman et al. (2016). As seen in Table 2, other
pipelines with high sensitivity such as the same work
proposed by Jerman et al. (2016) or the CNN pre-
sented in Brosch et al. (2016) tended also to increase
the number of false positives. Compared to these
methods, our proposed pipeline showed a high T P R
while maintaining lower false positive bounds.

3.2. Clinical MS dataset
3.2.1. Data

The MS cohort is composed by 60 patients with
clinically isolated syndrome from the same hospital
center (Hospital Vall d’Hebron, Barcelona, Spain).
In all patients, the initial clinical presentation was
clearly suggestive of MS:

Patients were scanned on a 3T Siemens with
a 12-channel phased-array head coil (Trio Tim,
Siemens, Germany), with acquired input modalities:
1) transverse PD and T2-w fast spin-echo (TR=2500
ms, TE=16-91 ms, voxel size=0.78×0.78×3mm3);
2)
fast T2-FLAIR (TR=9000 ms,
TE=93 ms, TI=2500 ms, ﬂip angle=120◦, voxel

transverse

size=0.49×0.49×3mm3); and 3) sagittal 3D T1 mag-
netization prepared rapid gradient-echo (MPRAGE)
(TR=2300 ms, TE=2 ms, TI=900 ms, ﬂip angle=9◦;
voxel size=1×1×1.2mm3). In 25 out of the 60 sub-
jects, the PD image modality was not available, so
data was separated in two datasets MS1 and MS2 as
follows:

• MS1 dataset:

35 subjects containing T1-
w, FLAIR and PD modalities.
Within
this
dataset, WM lesion masks were
semi-automatically
from PD
delineated
(Xinapse Systems,
using
http://www.xinapse.com/home.php) by an
expert radiologist of the same hospital center.
Mean lesion volume was 2.8 ± 2.5 ml (range
0.1-10.7 ml).

JIM software

• MS2 dataset: 25 patients containing only T1-w
and FLAIR input modalities. WM lesion masks
were also semi-automatically delineated from
FLAIR using JIM software by the same expert
radiologist. Mean lesion volume was 4.1 ± 4.7
ml (range 0.2-18.3 ml).

3.2.2. Evaluation

Evaluation scores proposed in section 3.1 are com-

plemented with the following metrics:

• The overall % segmentation accuracy in terms of
the Dice Similarity Coeﬃcient (DSC) between
manual lesion annotations and output segmen-
tation masks:

DSC =

2 × T Ps
F Ns + F Ps + 2 × T Ps

× 100

(4)

7

where T Ps and F Ps denote the number of voxels
correctly and incorrectly classiﬁed as lesion, re-
spectively, and F N denotes the number of vox-
els incorrectly classiﬁed as non-lesion.

• Precision rate of the method expressed in terms
of the Positive Predictive Value rate (P P V )
between manual lesion annotations and output
segmentation masks, also expressed in %:

P P V =

T Ps
T Ps + F Ps

× 100

(5)

where T Ps and F Ps denote the number of cor-
rectly and incorrectly lesion region candidates,
respectively.

3.2.3. Experiment details

For each dataset, T1-w and FLAIR images were
ﬁrst skull-stripped using BET (Smith et al., 2002)
and intensity normalized using N3 (Sled et al., 1998)
with smoothing distance parameter to 30-50mm.
Then, T1-w and FLAIR images were co-registered
to the T1-w space using also the SPM toolbox, with
normalized mutual information as objective function
and tri-linear interpolation with no warping.

In order to investigate the eﬀect of the training
procedure on the accuracy of the method, two dif-
ferent pipelines were considered:

i) one trained with leave-one-out cross-validation:
for each patient, an independent pipeline was
trained from the rest of the patient images of
the MS1 and MS2 datasets. Testing parameters
Tbin, lmin were computed at global level from all
input images used for training. Final values for
test parameters were set to tbin = 0.8, lmin =
20.

ii) one trained with independent cross training-
testing databases: all images in MS1 were used
to train a single pipeline, which was used to eval-
uate all the images in MS2. Afterwards, the pro-
cess was inverted and MS2 images were used to
train a single pipeline, which was used to evalu-
ate MS1 images. Optimized test parameters tbin
and lmin were set equal to the previous pipeline.

In both experiments, each of the cascaded networks
was trained using FLAIR and T1-w image modalities
for a maximum number of 400 epochs with early-
stopping of 50. For each subject, a training set of
approximately 200.000 patches was generated, where

25% was set to validation and the rest to train the
network. The same modalities were used for testing.

3.2.4. Comparison with other available methods

The accuracy of the proposed method is compared
with two available state-of-the-art MS lesion seg-
mentation approaches such as LST (Schmidt et al.,
2012) and SLS (Roura et al., 2015a). Parameters
for LST and SLS were optimized by grid-search on
the MS1 database. As in Roura et al. (2015a), given
that both MS1 and MS2 images were acquired us-
ing the same scanner, same parameters were used for
MS2. In LST, initial threshold was set to κ = 0.15
and lesion belief map was set to lgm = gm. In the
case of SLS, smoothing distribution parameter was
set to α = 3, the percentage of GM/WM tissue to
λts = 0.6, and percentage of neighboring WM to
λnb = 0.6 in the ﬁrst iteration. In the second itera-
tion, parameters were set to α = 1.7, λts = 0.75 and
λnb = 0.7, respectively.

3.2.5. Results

Table 3 shows the mean DSC, V D, T P R, F P R
and P P V scores for all the evaluated pipelines. As
seen in the Table 3, our proposed approach clearly
outperformed the rest of available MS pipelines by
a large margin in terms of detection (T P R, F P R),
precision (P P V ) and segmentation (V D, DSC).
Furthermore, our method yielded a similar perfor-
mance in both datasets and independently of the
training procedure employed, highlighting the capa-
bility of the network architecture to detect new le-
sions on unseen images.

Figure 3 shows the response operating charac-
teristic (ROC) curves and parameter optimization
plots for the proposed CNN approach on the MS1
database. Compared to the same CNN architecture
without cascading, the proposed approach yielded a
higher sensitivity, lower false negative rates and sig-
niﬁcantly higher DSC overlaps with respect to man-
ual annotations, due to the addition of the second
network, which drastically reduced the number of
misclassiﬁed voxels.

Figure 4 depicts a qualitative evaluation of each
of the evaluated methods for a single subject of
the MS1 dataset. Compared to the SLS and LST
pipelines, both proposed CNN pipelines present a
signiﬁcant increase in the number of detected lesions
(depicted in green). SLS and LST methods are de-
signed to reduce the F P R, so as a counterpart they
exhibit a higher number of missed lesions (depicted

8

Table 3: Mean segmentation results for each of the evaluated
methods on the two MS clinical datasets. Results are shown
for SLS, LST and our proposed approach trained with either
leave-one-out experiments (LOU) or diﬀerent training-testing
dataset. Mean DSC, V D, T P F , F P F and P P V are shown
for each method and database. The best value for each metric
is shown in bold.

Method
SLS (Roura et al., 2015a)
LST (Schmidt et al., 2012)
Proposed method (LOU)
Proposed method (train MS2)

(a) MS1 dataset (n=35)
DSC
33.4
32.2
53.5
50.8

VD TPR FPR PPV
61.7
81.0
58.8
49.7
70.3
30.8
65.3
38.8

38.2
41.2
30.5
35.6

49.5
44.4
77.0
79.1

Method
SLS (Roura et al., 2015a)
LST (Schmidt et al., 2012)
Proposed method (LOU)
Proposed method (train MS1)

(b) MS2 dataset (n=25)
DSC
29.7
27.3
56.0
51.9

VD TPR FPR PPV
53.2
65.1
59.7
59.4
66.1
27.5
73.0
26.1

46.7
40.2
33.6
27.2

35.7
58.9
68.2
63.7

as blue squares). In contrast, the high sensitivity of
the proposed method detecting WM lesions was not
compromised by a remarkably increase in the false
positives (depicted in red), still lower than the rest
of pipelines (see Table 3).

We also compared the correlation between ex-
pected and estimated lesion volume for each of the
evaluated pipelines and datasets. Figure 5 shows
the linear regression models ﬁtted based on the vol-
ume estimations of each method (solid lines). For
each regression model, 95% conﬁdence interval ar-
eas and expected lesion volume (dash lines) were also
shown for comparison. In general, distances between
expected and computed lesion volumes were lower
in CNN architectures when compared to the rest of
pipelines, as shown by the Pearson linear correlation
coeﬃcients obtained (r ≥ 0.97 in all cases). In addi-
tion, conﬁdence intervals for our proposed methods
were distinctively lower in both datasets, specially
in images with higher lesion load, where more vari-
ability was introduced.

4. Discussion

In this paper, we have presented a novel auto-
mated WM lesion segmentation method in brain
MRI with application to MS patient images. The
proposed patch-wise pipeline relies on a cascade of
two identical convolutional neural networks, where
the ﬁrst network is trained to be more sensitive re-
vealing possible candidate lesion voxels while the sec-
ond network is trained to reduce the number of mis-

Figure 3: Receiver Operation Characteristic (ROC) curves
and parameter optimization plots on the MS1 database. First
row: ROC curves with ﬁxed best minimum lesion size (lmin =
20) for both the proposed cascaded approach (solid blue) and
the same architecture using only the network without cascad-
ing (dotted orange). Second row: parameter optimization for
the cascaded CNN (tbin and lmin) against DSC coeﬃcient.
Additionally, the best conﬁguration for the CNN approach
without cascading is also shown for comparison (dotted or-
ange).

classiﬁed voxels coming from the ﬁrst network. Al-
though CNN cascade-based features have been used
in coronary calcium segmentation (Wolterink et al.,
2016), still this approach had been not applied in
In our
the context of MS lesion segmentation.
opinion, the proposed cascaded architecture of two
CNN is an interesting contribution of the present
study. Our experiments have shown that the pro-
posed method outperforms the rest of participant
methods in the MICCAI2008 challenge, which is con-
sidered nowadays a benchmark for new proposed
strategies. Moreover, additional experiments with
two clinical MS datasets also conﬁrms our claims

9

Figure 4: Output segmentation masks for each of the evaluated methods on the ﬁrst subject of the MS1 clinical dataset. (A)
FLAIR image. (B) T1-w image. (C) Manual WM lesion annotation. Output segmentation masks for SLS (D), LST (E) and
our approach when trained using either leave-one-out (F) or the MS2 dataset (E). On all images, true positives are denoted
in green, false positives in red and false negatives with a blue square.

(a) MS1 dataset (n=25)

(b) MS2 dataset (n=35)

10

Figure 5: Correlation between estimated lesion volume and manual WM lesion annotations for each of the evaluated methods
on MS clinical databases MS1 (a) and MS2 (b). The linear regression model relating estimated and manual segmentation are
plotted (solid lines) along with conﬁdence intervals at 95%. Estimated models and conﬁdence intervals are compared with
respect to expect lesion size (dashed line). For each method and dataset, the Pearson’s linear correlations between manual
and estimated masks are also shown (p ≤0.001).

about the accuracy of our proposed method. Com-
pared to other state-of-the-art available methods,
our approach exhibits a signiﬁcant increase in the
detection and segmentation of WM lesions, highly
correlating (r ≥ 0.97) with the expected lesion vol-
ume on clinical MS datasets. Furthermore, the per-
formance of the pipeline is consistent when trained
with diﬀerent image datasets, acquisition protocols
and image modalities, which highlights its robust-
ness in diﬀerent training conditions.

Automated WM lesion segmentation pipelines are
usually designed as a trade-oﬀ between the sensi-
tivity detecting lesions and the capability to avoid
false positives, which may aﬀect expected lesion seg-
mentation.
In all the experiments handled in this
paper, the proposed approach yielded a high sensi-
tivity detecting WM lesions while maintaining the
number of false positives reasonably low. Related
to that, diﬀerences in V D with respect to manual
lesion annotations were in average the lowest when
using our cascade architecture, specially in images
with high lesion size, as seen in the correlation plots
between expected and estimated lesion volume of MS
patients. In our opinion, the obtained results show
the capability of the cascade architecture to reduce
false positives without compromising lesion segmen-
tation, which is relevant, as it can have a direct ben-
eﬁt in several tasks such as automated delineation
of focal lesions for MS diagnosing (Polman et al.,
2011), measuring the impact of a given treatment
on WM lesions (Calabrese et al., 2012) or reduc-
ing the eﬀects of WM lesions in brain volumetry
by reﬁlling WM lesions before tissue segmentation
(Valverde et al., 2014, 2015).

In terms of the network architecture, our pipeline
has been designed to handle with the lack of large
amounts of training data and most importantly, with
the imbalanced nature of MRI images of MS pa-
tients, where lesion voxels are highly underrepre-
sented. The proposed cascade of two identical CNNs
can be also thought as a two-step optimization net-
work, where a more general speciﬁc network learns
to ﬁnd candidate lesions while a second more speciﬁc
network learns to reduce the number of false posi-
tives. At testing time, this means that voxels with a
low probability to belong to WM lesion are easily dis-
carded by the ﬁrst network, while challenging voxels
ﬂow from the ﬁrst to the second network, which has
been explicitly trained to discriminate between le-
sion voxels and these challenging non-lesion voxels.

Each network is trained independently in diﬀerent
portions of the training data, so the reduced size
of each of these networks makes them less prone to
overﬁtting. This makes this particular architecture
suitable for small datasets without massive amounts
of training samples, as there is a relative low number
of parameters to optimize at each of the two steps.

In our proposed design, the sampling procedure
followed to deal with data imbalance is equally im-
portant. In the ﬁrst network, the negative class has
been under-sampled to the same number of existing
lesion voxels, increasing the sensitivity of the net-
work detecting WM lesions at testing time. How-
ever, by under-sampling the negative voxel distribu-
tion, the probability to misclassify healthy voxels as
lesion also increases due to a poorer representation
of the negative class. In order to reduce the num-
ber of misclassiﬁed voxels, the network may be re-
designed to incorporate more layers with the aim to
learn more abstract features. However, a deeper net-
work increases the number of parameters, and more
training data is needed in order to avoid over-ﬁtting.
In contrast, within the designed proposal, false pos-
itives are reduced by re-training an identical CNN
architecture with the most challenging samples de-
rived from the ﬁrst network.

In contrast to other CNN approaches used in brain
MRI (Moeskops et al., 2016a; Brosch et al., 2016),
the training stage is here split into two independent
7-layer CNNs that are exposed to diﬀerent portions
of equal data, so the number of parameters to be op-
timized at each step is remarkably small (< 190000
with input patches of size 113) when compared to
other methods. This can be specially interesting
when training is performed with a cohort of MS pa-
tients with low lesion load, as seen in our experiment
containing only around 200.000 training samples af-
ter balancing equally lesion and non-lesion voxels.
In this aspect, our results suggest that the proposed
pipeline is a valid alternative to train CNN net-
works without the need of large amounts of training
data. In our opinion, this is one of the major con-
tributions of the present study, given the diﬃculty
to obtain labeled MRI data, in comparison to the
huge number of available unlabeled data. This sug-
gests that a similar approach may be useful in other
similar detection problems like automated segmenta-
tion of WM hyperintensities (Griﬀanti et al., 2016),
longitudinal MS lesion segmentation (Cabezas et al.,
2016), Lupus lesion detection (Roura et al., 2015b),

11

traumatic brain injury (Lee and Newberg, 2005) and
brain tumor segmentation (Menze et al., 2015).

The proposed method presents also some limita-
tions. When compared to SLS and LST, although
our CNN approach clearly yields a better accuracy
on the MS dataset, this has to be trained and tested
for each of the datasets evaluated, which is time con-
suming and may require more expertise. Related
to that, the abstract representations learned by the
classiﬁer are most probably provided by the FLAIR
and T2-w image sequences, as these sequences are
more sensitive revealing the majority of MS lesions
when compared with T1-w, for instance. However,
the geometry and image contrast of FLAIR / T2-
w tend to vary considerably within acquisition pro-
tocols. Although changes in intensity scale can be
corrected by the internal regularization of the CNN,
diﬀerences between image domains still may exist,
being the feature representations learned by the clas-
siﬁer highly dependent of the dataset used, which
suggests us to use it only on the same image domain.

5. Conclusions

Automated WM lesion segmentation is still an
open ﬁeld, as shown by the constant number of pro-
posed methods during the last years.
In this pa-
per, we have presented a novel automated WM le-
sion segmentation method with application to MS
patient images that relies on a cascade of two con-
volutional neural networks. Experimental results
presented in this paper have shown the consistent
performance of the proposed method on both pub-
lic and private MS data, outperforming the rest of
participant methods in the MICCAI2008 challenge,
which is considered nowadays as a benchmark for
new proposed strategies. Compared to other avail-
able methods, the performance of our proposed ap-
proach shows a signiﬁcant increase in the sensitivity
while maintaining a reasonable low number of false
positives. As a result, the method exhibits a lower
deviation in the expected lesion volume in manual
lesion annotations with diﬀerent input image modal-
ities and image datasets. In addition, the proposed
cascaded CNN architecture tends to learn well from
small sets of data, which can be very interesting in
practice, given the diﬃculty to obtain manual label
annotations and the amount number of available un-
labeled MRI data.

The obtained results are encouraging, yielding our
CNN architecture closer to human expert inter-rater

variability. However, still more research is needed to
accomplish this task. Meanwhile, we strongly believe
that the proposed method can be a valid alternative
for automated WM lesion segmentation.

Acknowledgements

This work has been partially supported by ”La
Fundaci´o la Marat´o de TV3”, by Retos de Inves-
tigaci´on TIN2014-55710-R, and by the MPC UdG
2016/022 grant. The authors gratefully acknowledge
the support of the NVIDIA Corporation with their
donation of the Tesla K40 GPU used in this research.

References

Bergstra, J., Bastien, F., Breuleux, O., Lamblin, P.,
Pascanu, R., Delalleau, O., Desjardins, G., Warde-
Farley, D., Goodfellow, I., Bergeron, A., and Ben-
gio, Y. (2011). Theano: Deep Learning on GPUs
with Python. Journal of Machine Learning Re-
search, 1:1–48.

Boyes, R. G., Gunter, J. L., Frost, C., Janke, A. L.,
Yeatman, T., Hill, D. L. G., Bernstein, M. A.,
Thompson, P. M., Weiner, M. W., Schuﬀ, N.,
Alexander, G. E., Killiany, R. J., DeCarli, C.,
Jack, C. R., and Fox, N. C. (2008). Intensity non-
uniformity correction using N3 on 3-T scanners
with multichannel phased array coils. NeuroIm-
age, 39:1752–1762.

Brosch, T., Tang, L. Y. W., Yoo, Y., Li, D. K. B.,
Traboulsee, A., and Tam, R. (2016). Deep 3D
convolutional encoder networks with shortcuts for
multiscale feature integration applied to multiple
sclerosis lesion segmentation. 35(5):1229 – 1239.

Cabezas, M., Corral, J. F., Oliver, A., D´ıez, Y., Tin-
tor´e, M., Auger, C., Montalban, X., Llad´o, M.,
Pareto, D., and Rovira, `A. (2016). Improved Au-
tomatic Detection of New T2 Lesions in Multiple
Sclerosis Using Deformation Fields. AJNR. Amer-
ican journal of neuroradiology, pages 1–8.

Cabezas, M., Oliver, A., Valverde, S., Beltran, B.,
Freixenet, J., Vilanova, J. C., Rami´o-Torrent`a, L.,
Rovira, `A., and Llad´o, X. (2014). BOOST: A
supervised approach for multiple sclerosis lesion
segmentation. Journal of Neuroscience Methods,
237:108–117.

12

Calabrese, M., Bernardi, V., Atzori, M., Mattisi, I.,
Favaretto, A., Rinaldi, F., Perini, P., and Gallo,
P. (2012). Eﬀect of disease-modifying drugs on
cortical lesions and atrophy in relapsing-remitting
multiple sclerosis. Multiple Sclerosis, 18(4):418–
424.

Chen, H., Dou, Q., Yu, L., and Heng, P.-A.
(2016).
VoxResNet: Deep Voxelwise Resid-
ual Networks for Volumetric Brain Segmentation.
arXiv:1608.05895v1, (August):1–9.

C¸ i¸cek, ¨O., Abdulkadir, A., Lienkamp, S. S., Brox, T.,
and Ronneberger, O. (2016). 3D U-Net: Learning
Dense Volumetric Segmentation from Sparse An-
notation.

Commowick, O., Cervenansky, F., and Ameli, R.
(2016). MSSEG Challenge Proceedings: Multiple
Sclerosis Lesions Segmentation Challenge Using a
Data Management and Processing Infrastructure.
France.

Compston, A. and Coles, A. (2008). Multiple scle-

rosis. Lancet, 372(9648):1502–17.

Fartaria, M. J., Bonnier, G., Roche, A., Kober, T.,
Meuli, R., Rotzinger, D., Frackowiak, R., Schluep,
M., Du Pasquier, R., Thiran, J.-P., Krueger, G.,
Bach Cuadra, M., and Granziera, C. (2016). Au-
tomated detection of white matter and cortical le-
sions in early stages of multiple sclerosis. Journal
of Magnetic Resonance Imaging, 43:1445–1454/.

Filippi, M., Rocca, M. A., Ciccarelli, O., De Ste-
fano, N., Evangelou, N., Kappos, L., Rovira, A.,
Sastre-Garriga, J., Tintor`e, M., Frederiksen, J. L.,
Gasperini, C., Palace, J., Reich, D. S., Ban-
well, B., Montalban, X., and Barkhof, F. (2016).
MRI criteria for the diagnosis of multiple sclerosis:
MAGNIMS consensus guidelines.

Garc´ıa-Lorenzo, D., Francis, S., Narayanan, S.,
Arnold, D., and Collins, D. (2013). Review of
automatic segmentation methods of multiple scle-
rosis white matter lesions on conventional mag-
netic resonance imaging. Medical Image Analysis,
17(1):1–18.

Glorot, X. and Bengio, Y. (2010). Understanding
the diﬃculty of training deep feedforward neural
networks. Proceedings of the 13th International
Conference on Artiﬁcial Intelligence and Statistics
(AISTATS), 9:249–256.

Griﬀanti, L., Zamboni, G., Khan, A., Li, L., Boni-
facio, G., Sundaresan, V., Schulz, U. G., Kuker,
W., Battaglini, M., Rothwell, P. M., and Jenkin-
son, M. (2016). BIANCA (Brain Intensity AbNor-
mality Classiﬁcation Algorithm): A new tool for
automated segmentation of white matter hyperin-
tensities. NeuroImage, 141:191–205.

Guizard, N., Coup´e, P., Fonov, V., Manj´on, J.,
Arnold, D., and Collins, D. (2015). Rotation-
invariant multi-contrast non-local means for MS
lesion segmentation. NeuroImage: Clinical, 8:376–
389.

Harmouche, R., Subbanna, N., Collins, D., Arnold,
D., and Arbel, T. (2015). Probabilistic multiple
sclerosis lesion classiﬁcation based on modeling re-
gional intensity variability and local neighborhood
IEEE transactions on bio-medical
information.
engineering, 62(5):1281–1292.

Havaei, M., Davy, A., Warde-Farley, D., Biard, A.,
Courville, A., Bengio, Y., Pal, C., Jodoin, P.-M.,
and Larochelle, H. (2017). Brain tumor segmenta-
tion with Deep Neural Networks. Medical Image
Analysis, 35:18–31.

Havaei, M., Guizard, N., Chapados, N., and Ben-
gio, Y. (2016). HeMIS: Hetero-Modal Image Seg-
mentation, pages 469–477. Springer International
Publishing.

He, K., Zhang, X., Ren, S., and Sun, J. (2015). Deep
arXiv

learning for image recognition.

residual
preprint arXiv:1512.03385.

Ioﬀe, S. and Szegedy, C. (2015). Batch Normaliza-
tion: Accelerating Deep Network Training by Re-
ducing Internal Covariate Shift. Journal of Ma-
chine Learning Research, 37.

Geremia, E., Clatz, O., Menze, B., Konukoglu, E.,
Criminisi, A., and Ayache, N. (2011). Spatial de-
cision forests for MS lesion segmentation in multi-
channel magnetic resonance images. NeuroImage,
57(2):378–390.

Jerman, T., Galimzianova, A., Pernuˇs, F., Likar, B.,
and ˇSpiclin, ˇZ. (2016). Combining Unsupervised
and Supervised Methods for Lesion Segmentation,
pages 45–56. Springer International Publishing,
Cham.

13

Jesson, A. and Arbel, T. (2015). Hierarchical MRF
and random forest segmentation of ms lesions and
healthy tissues in brain MRI. pages 1–2.

Kamnitsas, K., Ledig, C., Newcombe, V. F. J., Simp-
son, J. P., Kane, A. D., Menon, D. K., Rueckert,
D., and Glocker, B. (2016). Eﬃcient Multi-Scale
3D {CNN} with fully connected {CRF} for Accu-
rate Brain Lesion Segmentation. Medical Image
Analysis, pages –.

Krizhevsky, A., Sutskever, I., and Hinton, G. (2012).
Imagenet classiﬁcation with deep convolutional
neural networks. In Advances in Neural Informa-
tion Processing Systems, pages 1106 – 1114.

LeCun, Y., Bengio, Y., and Hinton, G. (2015). Deep

learning. Nature, 521(7553):436–444.

LeCun, Y., Bottou, L., Bengio, Y., and Haﬀner,
P. (1998). Gradient-based learning applied to
document recognition. Proceedings of the IEEE,
86(11):2278 – 2324.

Lee, B. and Newberg, A. (2005). Neuroimaging in
traumatic brain imaging. NeuroRx : the journal
of the American Society for Experimental Neu-
roTherapeutics, 2(2):372–383.

Llad´o, X., Oliver, A., Cabezas, M., Freixenet, J., Vi-
lanova, J., Quiles, A., Valls, L., Rami´o-Torrent`a,
L., and Rovira, A. (2012). Segmentation of mul-
tiple sclerosis lesions in brain MRI: A review
of automated approaches. Information Sciences,
186(1):164–185.

Menze, B. H., Jakab, A., Bauer, S., Kalpathy-
Cramer, J., Farahani, K., Kirby, J., Burren, Y.,
Porz, N., Slotboom, J., Wiest, R., Lanczi, L., Ger-
stner, E., Weber, M. A., Arbel, T., Avants, B. B.,
Ayache, N., Buendia, P., Collins, D. L., Cordier,
N., Corso, J. J., Criminisi, A., Das, T., Delingette,
H., Demiralp, a., Durst, C. R., Dojat, M., Doyle,
S., Festa, J., Forbes, F., Geremia, E., Glocker, B.,
Golland, P., Guo, X., Hamamci, A., Iftekharud-
din, K. M., Jena, R., John, N. M., Konukoglu, E.,
Lashkari, D., Mariz, J. A., Meier, R., Pereira, S.,
Precup, D., Price, S. J., Raviv, T. R., Reza, S.
M. S., Ryan, M., Sarikaya, D., Schwartz, L., Shin,
H. C., Shotton, J., Silva, C. A., Sousa, N., Sub-
banna, N. K., Szekely, G., Taylor, T. J., Thomas,
O. M., Tustison, N. J., Unal, G., Vasseur, F., Win-
termark, M., Ye, D. H., Zhao, L., Zhao, B., Zikic,

D., Prastawa, M., Reyes, M., and Van Leemput,
K. (2015). The Multimodal Brain Tumor Image
Segmentation Benchmark (BRATS). IEEE Trans-
actions on Medical Imaging, 34(10):1993–2024.

Moeskops, P., Benders, M. J., Chi, S. M., Kers-
bergen, K. J., Groenendaal, F., de Vries, L. S.,
Viergever, M. A., and Iˇsgum, I. (2015). Automatic
segmentation of MR brain images of preterm in-
fants using supervised classiﬁcation. NeuroImage,
118:628–641.

Moeskops, P., Viergever, M. A., Mendrik, A. M.,
de Vries, L. S., Benders, M. J. N. L., and Is-
gum, I. (2016a). Automatic segmentation of MR
brain images with a convolutional neural network.
35(5):1252 – 1261.

Moeskops, P., Wolterink, J., van der Velden, B.,
Gilhuijs, K., Leiner, T., Viergever, M., and Iˇsgum,
I. (2016b). Deep learning for multi-task medical
image segmentation in multiple modalities, volume
9901 LNCS.

Nair, V. and Hinton, G. E. (2010). Rectiﬁed Linear
Units Improve Restricted Boltzmann Machines.
Proceedings of the 27th International Conference
on Machine Learning, (3):807–814.

Pereira, S., Pinto, A., Alves, V., and Silva, C. A.
(2016). Brain Tumor Segmentation Using Convo-
lutional Neural Networks in MRI Images. IEEE
Transactions on Medical Imaging, 35(5):1240–
1251.

Polman, C., Reingold, S., Banwell, B., Clanet, M.,
Cohen, J. a., Filippi, M., Fujihara, K., Havrdova,
E., Hutchinson, M., Kappos, L., Lublin, F., Mon-
talban, X., O’Connor, P., Sandberg-Wollheim, M.,
Thompson, A., Waubant, E., Weinshenker, B.,
and Wolinsky, J. (2011). Diagnostic criteria for
multiple sclerosis: 2010 revisions to the McDon-
ald criteria. Annals of neurology, 69(2):292–302.

Roura, E., Oliver, A., Cabezas, M., Valverde, S.,
Pareto, D., Vilanova, J., Rami´o-Torrent`a, L.,
Rovira, A., and Llad´o, X. (2015a). A toolbox for
multiple sclerosis lesion segmentation. Neuroradi-
ology, 57(10):1031–1043.

Roura, E., Sarbu, N., Oliver, A., and Valverde, S.
(2015b). Automated detection of Lupus white
matter lesions in MRI images. pages 1–7.

14

Rovira, `A., Wattjes, M. P., Tintor´e, M., Tur, C.,
Yousry, T. a., Sormani, M. P., De Stefano, N.,
Filippi, M., Auger, C., Rocca, M. a., Barkhof, F.,
Fazekas, F., Kappos, L., Polman, C., Miller, D.,
and Montalban, X. (2015). Evidence-based guide-
lines: MAGNIMS consensus guidelines on the use
of MRI in multiple sclerosisclinical implementa-
tion in the diagnostic process. Nature Reviews
Neurology, 11(August):1–12.

Schmidt, P., Gaser, C., Arsic, M., Buck, D.,
F¨orschler, A., Berthele, A., Hoshi, M., Ilg, R.,
Schmid, V., Zimmer, C., Hemmer, B., and
M¨uhlau, M. (2012). An automated tool for detec-
tion of FLAIR-hyperintense white-matter lesions
in Multiple Sclerosis. NeuroImage, 59(4):3774–
3783.

Simonyan, K. and Zisserman, A. (2014). Very
Deep Convolutional Networks for Large-Scale Im-
age Recognition. ImageNet Challenge, pages 1–10.

Sled, J. G., Zijdenbos, a. P., and Evans, a. C. (1998).
A nonparametric method for automatic correction
IEEE
of intensity nonuniformity in MRI data.
Transactions on Medical Imaging, 17(1):87–97.

Smith, S. M., Zhang, Y., Jenkinson, M., Chen, J.,
Matthews, P., Federico, A., and De Stefano, N.
(2002). Accurate, Robust, and Automated Longi-
tudinal and Cross-Sectional Brain Change Analy-
sis . NeuroImage, 17(1):479–489.

Srivastava, N., Hinton, G. E., Krizhevsky, A.,
Sutskever,
I., and Salakhutdinov, R. (2014).
Dropout : A Simple Way to Prevent Neural
Networks from Overﬁtting. Journal of Machine
Learning Research (JMLR), 15:1929–1958.

Steenwijk, M. D., Pouwels, P. J. W., Daams, M.,
van Dalen, J. W., Caan, M. W. a., Richard,
E., Barkhof, F., and Vrenken, H. (2013). Accu-
rate white matter lesion segmentation by k near-
est neighbor classiﬁcation with tissue type priors
(kNN-TTPs). NeuroImage: Clinical, 3:462–9.

Steinman, L. (1996). Multiple Sclerosis: A Coordi-
nated Immunological Attack against Myelin in the
Central Nervous System. Cell, 85(3):299–302.

Strumia, M., Schmidt, F., Anastasopoulos, C.,
Granziera, C., Krueger, G., and Brox, T. (2016).
White Matter MS-Lesion Segmentation Using a

Geometric Brain Model.
medical imaging, PP(99):1.

IEEE transactions on

Styner, M., Lee, J., Chin, B., and Chin, M. (2008).
3D segmentation in the clinic: A grand challenge
II: MS lesion segmentation. Midas, pages 1–6.

Sutskever, I., Vinyals, O., and Le, Q. V. (2014). Se-
quence to sequence learning with neural networks.
Advances in Neural Information Processing Sys-
tems (NIPS), pages 3104–3112.

Tomas-Fernandez, X. and Warﬁeld, S. (2015). A
Model of Population and Subject (MOPS) Inten-
sities with Application to Multiple Sclerosis Le-
sion Segmentation. IEEE transactions on medical
imaging, 0062(c):1–15.

Valverde, S., Oliver, A., and Llad´o, X. (2014). A
white matter lesion-ﬁlling approach to improve
brain tissue volume measurements. NeuroImage:
Clinical, 6:86–92.

Valverde, S., Oliver, A., Roura, E., Pareto, D., Vi-
lanova, J. C., Rami´o-Torrent`a, L., Sastre-Garriga,
J., Montalban, X., Rovira, A., and Llad´o, X.
(2015). Quantifying brain tissue volume in multi-
ple sclerosis with automated lesion segmentation
and ﬁlling. NeuroImage: Clinical, 9:640–647.

Wang, L., Gao, Y., Shi, F., Li, G., Gilmore, J. H.,
Lin, W., and Shen, D. (2015). LINKS: Learning-
based multi-source IntegratioN frameworK for
Segmentation of infant brain images. NeuroIm-
age, 108:160–172.

Wolterink, J. M., Leiner, T., de Vos, B. D., van
Hamersvelt, R. W., Viergever, M. A., and I??gum,
I. (2016). Automatic coronary artery calcium scor-
ing in cardiac CT angiography using paired convo-
lutional neural networks. Medical Image Analysis,
34:123–136.

Zeiler, M. D. (2012). ADADELTA: An Adaptive
Learning Rate Method. ArXiv preprint 1212.5701,
page 6.

Zhang, W., Li, R., Deng, H., Wang, L., Lin, W., Ji,
S., and Shen, D. (2015). Deep convolutional neu-
ral networks for multi-modality isointense infant
brain image segmentation. 108:214 – 224.

15

Zheng, W., Chee, M. W. L., and Zagorodnov, V.
(2009). Improvement of brain segmentation accu-
racy by optimizing non-uniformity correction us-
ing N3. NeuroImage, 48:73–83.

16

