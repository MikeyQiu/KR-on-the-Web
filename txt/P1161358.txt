1

Computer Vision and Image Understanding

journal homepage: www.elsevier.com

Generalizing semi-supervised generative adversarial
networks to regression using feature contrasting

Greg Olmschenka,b,∗∗, Zhigang Zhua,b, Hao Tangc

aThe City College, The City University of New York, 160 Convent Ave, New York, NY 10031, USA
bThe Graduate Center, The City University of New York, 365 5th Ave, New York, NY 10016, USA
cBorough of Manhattan Community College, The City University of New York, 199 Chambers St, New York, NY 10007, USA

ABSTRACT

In this work, we generalize semi-supervised generative adversarial networks (GANs) from classiﬁcation
problems to regression problems. In the last few years, the importance of improving the training of
neural networks using semi-supervised training has been demonstrated for classiﬁcation problems.
We present a novel loss function, called feature contrasting, resulting in a discriminator which can
distinguish between fake and real data based on feature statistics. This method avoids potential biases
and limitations of alternative approaches. The generalization of semi-supervised GANs to the regime
of regression problems of opens their use to countless applications as well as providing an avenue for a
deeper understanding of how GANs function. We ﬁrst demonstrate the capabilities of semi-supervised
regression GANs on a toy dataset which allows for a detailed understanding of how they operate in
various circumstances. This toy dataset is used to provide a theoretical basis of the semi-supervised
regression GAN. We then apply the semi-supervised regression GANs to a number of real-world
computer vision applications: age estimation, driving steering angle prediction, and crowd counting
from single images. We perform extensive tests of what accuracy can be achieved with signiﬁcantly
reduced annotated data. Through the combination of the theoretical example and real-world scenarios,
we demonstrate how semi-supervised GANs can be generalized to regression problems.

© 2019 Elsevier Ltd. All rights reserved.

9
1
0
2
 
p
e
S
 
3
 
 
]

G
L
.
s
c
[
 
 
3
v
9
6
2
1
1
.
1
1
8
1
:
v
i
X
r
a

1. Introduction

Deep learning (LeCun et al., 2015), particularly deep neural

networks (DNNs), has become the dominant focus in many areas

of computer science in recent years. This is especially true in

computer vision, where the advent of convolutional neural net-

works (CNNs) (LeCun et al., 1999) has led to algorithms which

can outperform humans in many vision tasks (Dodge and Karam,

2017). Within the ﬁeld of deep learning, generative models have

become popular for generating data that simulates real datasets.

A generative model is one which learns how to produce samples

∗∗Corresponding author: Tel.: +1-651-366-1814;

e-mail: golmschenk@gradcenter.cuny.edu (Greg Olmschenk)

from a data distribution. In the case of computer vision, this is

often a neural network which learns how to generate images,

possibly with speciﬁed characteristics. Generative models are

particularly interesting because for such a model to generate new

examples of data from a distribution, the model must be able to

distinguish data which belongs to the distribution and that which

does not. In a sense, this distinguishing ability shows that the

network ”understands” a data distribution. Arguably the most

powerful type of generative model is the generative adversarial

network (GAN) (Goodfellow, 2016; Goodfellow et al., 2014).

GANs have been shown to be capable of producing fake data

that appears to be real to human evaluators. For example, GANs

2

can generate fake images of real world objects which a human

The most important contribution is the introduction of the

evaluator can not distinguish from true images (Elsayed et al.,

generalized semi-supervised regression GAN (SR-GAN) for-

2018). Beyond this, GANs have been shown to produce better

mulation using feature contrasting. Nevertheless, while the

results in discriminative tasks using relatively small amounts
of data (Salimans et al., 2016), where equivalent DNNs/CNNs

theoretical solution for applying semi-supervised GANs to re-

gression is provided in the ﬁrst contribution, there are several

would require signiﬁcantly more training data to accomplish the

factors that need to be addressed for this approach to work in

same level of accuracy. As one of the greatest obstacles in deep

practice. Chieﬂy is the stability of training the two competing

learning is acquiring the large amount of labeled data to train

networks in an SR-GAN. This is addressed by designing loss

such models, the ability to train these powerful models with

functions for the SR-GAN whose gradients are well-behaved

much less data is of immense importance.

(neither vanishing nor exploding) in as many situations as pos-

While GANs have already shown signiﬁcant potential in semi-

sible, and preventing cyclical training between the generator

supervised training, they have only been used for a limited

and discriminator by applying penalties and limitations in the

number of cases. In particular, they have almost exclusively

training behavior.

been used for classiﬁcation problems thus far. In this work, we

We provide a number of real world applications where SR-

propose generalizing semi-supervised GANs to regression prob-

GANs are shown to improve the results over traditional CNNs

lems. Though this may initially seem to be a trivial expansion,

and other competing models. Speciﬁcally we will use the SR-

the nature of a GAN’s optimization goals makes the shift from
classiﬁcation to regression problems diﬃcult. Speciﬁcally, the

GAN to predict the age of an individual, estimate the angle

a steering wheel should be turned to given an image of the

two parts of a GAN can be seen as playing a minimax game.

upcoming road segment, and count the size of a crowd from a

The discriminating portion of the GAN must have the objective

single image. The age estimation and steering angle datasets

of labeling the fake data from generating portion as fake. In a

provides relatively simple applications on which the SR-GAN

classiﬁcation semi-supervised GANs, an additional ”fake” class

can be used to reduce the data requirements in a real world

is added to the possible list of classes. However, in regression,

situation, while still being challenging and general enough to

where the data is labeled with real valued numbers, deciding

merit attention. The crowd counting application provides a more

what constitutes a ”fake” labeling is not straight forward.

complex scenario with a wide variety of conditions to show the
method in more diﬃcult circumstances.

1.1. Contributions

In this work, we will present the following contributions:

1.2. Outline

1. A new algorithm with a novel loss function, feature con-

trasting, which allows semi-supervised GANs to be applied

to regression problems, the Semi-supervised Regression

GAN (SR-GAN).

The remainder of the paper is laid out as follows. The work
which our method builds oﬀ of as a starting point and other

related works are examined in Section 2. Section 3 explains

our methods and experimental setup. Section 4 displays the

experimental results and discusses the ﬁndings. Finally, we

2. A set of optimization rules which allows for stable, con-

sistent training when using the SR-GAN, including experi-

conclude in Section 5.

ments demonstrating the importance of these rules.

3. Systematic experiments using the SR-GAN on the real

2. Background and Related Work

world applications of age estimation, driving steering angle

2.1. The Value of Regression Problems

prediction, and crowd counting from single images showing

Regression problems encompass a large pool of applications

the beneﬁts of SR-GANs over existing approaches.

which cannot be solved–or would be poorly solved–by framing

3

them as classiﬁcation problems. The SR-GAN as we deﬁne it

here can be generalized to any such regression problem. Some

examples include crowd counting estimation (Zhang et al., 2015),

weather prediction models (Xingjian et al., 2015), stock index

evaluation (Ding et al., 2015), object distance estimation (Eigen

et al., 2014), age estimation (Niu et al., 2016), data hole ﬁll-
ing (Pathak et al., 2016), curve coeﬃcient estimation, ecolog-
ical biomass prediction (Ali et al., 2015), traﬃc ﬂow density

prediction (Lv et al., 2015), orbital mechanics predictions (Har-

tikainen et al., 2012), electrical grid load prediction (Marino

et al., 2016), stellar spectral analysis (Fabbro et al., 2017), net-

Fig. 1: The structure of a basic GAN. Real and fake images are fed to a discrimi-

nator network, which tries to determine whether the images are real or fake. The

work data load prediction (Oliveira et al., 2016), object ori-

fake images are produced by a generator network.

entation estimation (Schwarz et al., 2015), species population

prediction (Bland et al., 2015), ocean current prediction (Liu

accordance to the other.

and Weisberg, 2005), and countless others. While it is possible

Though GANs are now fairly common, to provide the ground-

to frame each of these problems in terms of classiﬁcation, in

work for our SR-GAN, it is worth deﬁning the details of a GAN

practice, this presents several signiﬁcant problems. For example,

from the viewpoint of probability distributions. Although these

the developer must decide on an arbitrary number of classes

methods work for any prediction application, to give a concrete

for the application. However, more importantly, such a naive

understanding, these explanations are given in terms of com-

classiﬁcation approach results in each incorrect prediction being

puter vision problems, speciﬁcally where the datasets consist of

considered equally as erroneous. In regression applications, the

images. This means an example of real data (and thus the input

true label lies somewhere on a continuous scale, and the closer

of the discriminator) is an image, and the output of the generator

of two predictions should always be considered better than the

is also an image. The structure of a GAN can be seen in Fig. 1.

farther, even if both are inaccurate. If the prediction of a real

number from 0 to 10 was split into 10 discrete classes, a predic-

tion of 8 should be considered better than a prediction of 2 for

a true label of 10. Yet, a naive classiﬁcation network produces

the same loss for each. Depending on the accuracy required

by the application, this approach may be acceptable, but these

problems are more naturally framed as regression problems.

2.2. Generative Adversarial Networks

A Generative Adversarial Network (GAN) consists of two

neural networks which compete against one another. One of the

networks generates fake data; hence we will call it the generator.

The other network attempts to distinguish between real data and

the fake generated data; consequently, this network is called

the discriminator. Both networks are trained together, each

The generator network takes random noise as input (usually

sampled from a normal distribution) and outputs the fake image

data. The discriminator takes as input images and outputs a

binary classiﬁcation of either fake or real data.

Images can

be represented by a vector, with each element representing the

value of a pixel in the image1. In any image, each element

of this vector has a value within a certain range representing

the intensity of that pixel. For this explanation, we will state

the minimum element value (pixel value) as being 0, and the

maximum as being 1. Of course, this vector can be represented

as a point in N dimensional space, where N is the number of

elements in the vector. The possible positions of an image’s point

1One element per pixel is in the case of grayscale images. For RGB images,

there will be three elements in the vector for each pixel, one for each color

continually working to outperform the other and adapting in

channel of the pixel.

4

are restricted to the N dimensional hypercube with a side length

discriminator, the loss function is given by

of 1. Here, it is important to note that real-world images are not

equally spread throughout this cube. That is, most points in the

LD = −Ex∼pdata(x)[logD(x)] − Ex∼p f ake(x)[log(1 − D(x))]

(3)

cube correspond to images that would look like random noise

and the generator’s loss function is given by

to a human. Images from the real world usually have properties

like local consistency in both texture and color, logical relative

positioning of shapes, etc. Real world images lie on a manifold
within the cube (Feﬀerman et al., 2016). Subsets of real-world

L f ake = −Ex∼p f ake(x)[log(D(x))].

(4)

In the case of image data, this approach has led to generative

models which can produce realistic looking images reliably (Rad-

images, such as the set of all images containing a dog, lie on

ford et al., 2015).

yet a smaller manifold. This manifold represents a probability

distribution of the real world images. We can view the real world

2.3. Semi-Supervised GANs for Classiﬁcation

as a data generating probability distribution, with each position

In this section, we will explain a subset of GANs which are

on the manifold having a certain probability based on how likely

used to improve the training of ordinary networks for discrim-

that image is to exist in the real world.

ination and prediction tasks. In this case, both a labeled and

The goal of the generator is then to produce images which

an unlabeled dataset is used, and in addition to distinguishing

match the probability distribution of the manifold as closely as

between real and fake, the discriminator also tries to label a real

possible. Input to the generator is a point sampled from the

input data sample into one of the given classes. The primary

probability distribution of (multidimensional) random normal

goal of this type of GAN is to allow the discriminator’s predic-

noise, and the output is a point in the hypercube–an image.

tion task to be trained with relatively small amounts of labeled

The generator is then a function which transforms a normal

data using unlabeled data to provide the network with additional

distribution into an image data distribution. Formally,

information. As unlabeled data is usually much easier to obtain

p f ake(x) = G(N)

than labeled data, this provides a powerful means to reduce the

(1)

requirements of training neural networks. This semi-supervised

where G represents the generator function, x is a random vari-

able representing an image, N is the normal distribution, and

pG(x) is the probability distribution of the images generated by

the generator. The desired goal of the generator is to minimize
the diﬀerence between the generated distribution and the true

data distribution. One of the most common metrics to mini-
mize this diﬀerence is the Kullback-Leibler (KL) divergence

between the generator distribution and the true data distribution

using maximum likelihood estimation. This is done by ﬁnding

the parameters of the generator, θ, which produce the smallest

divergence,

θ∗ = arg min

DKL(pdata(x) (cid:107) pG(x; θ)).

(2)

θ

To ﬁnd this set of parameters, each of the discriminator and the

GAN structure can be seen in Fig. 2.

Where in a simple GAN the discriminator would be passed

true examples and fake examples, in the semi-supervised GAN

the discriminator is given true labeled examples, true unlabeled

examples, and fake examples. We can better understand why

this is useful by considering the case of image classiﬁcation. In

this case, the discriminator is being trained to predict the correct

class of a true image, which can be one of the K classes that

exist in the dataset. The discriminator is given the additional
goal of attempting to label any fake images with a K + 1th class,

which only exists to label fake data (i.e., does not exist in the

true label dataset). For the case of unlabeled, all we know is
that it must belong to one of the ﬁrst K classes, as the K + 1th

class does not exist in the real data. The discriminator is then
punished for labeling true unlabeled data as the K + 1th class.

generator works toward minimizing a loss function. For the

This is useful because the discriminator cannot simply overﬁt to

data points into categories. To do this, it creates a mapping from

a predictive manifold to a class, with the training warping the

manifold to contain each of the data points for that class. At the

same time, the generator prevents the manifold from warping

too severely to reach data points in arbitrary ways. Intuitively,

this is because severely warping the manifold to reach true data

points can result in the manifold stretching into the area which

does not represent true images. The generator acts a pressure

on the manifold to reduce this. By generating images near the

manifold, the generator forces the discriminator’s manifold not

to wander into areas that don’t contain real images. In this sense,

the generator is a form of regularization for the discriminator,

but one which is based on real-world data.

As originally formulated by Salimans et al. (2016), the dis-

5

(5)

(6)

Fig. 2: The structure of a semi-supervised GAN. Both labeled and unlabeled real

images, as well as fake images, are fed to a discriminator network, which tries to

determine which class each image belongs to (K real classes and one fake class).

The discriminator wishes to label images from the generator as belonging to a

criminator loss function is then deﬁned by

special ”fake” class.

LD = Lsupervised + Lunsupervised

the labeled data, as it still has to accommodate for the unlabeled

Lsupervised =

data. At the same time, the fake data prevents the discriminator

from allowing simple features to be the deciding factor, as the

generator is able to produce such simple features.

To understand what is happening in this semi-supervised learn-

− Ex,y∼plabeled(x,y)log[pmodel(y | x, y < K + 1)]

Lunsupervised =

− Ex∼punlabeled(x)log[1 − pmodel(y = K + 1 | x)]

(7)

ing more intuitively, we can imagine the extreme case of an ideal

− Ex∼p f akelog[pmodel(y = K + 1 | x)].

discriminator and generator. The generator would have to have

As for the generator, the ﬁrst option for a loss function is the

learned to produce data which exactly matches the true data dis-

straight forward one which aims to have the discriminator label

tribution. For this to happen, the discriminator must have forced

the fake images as from real classes. Speciﬁcally,

the generator to learn this (as the generator’s training is entirely

dictated by backpropagation from the discriminator), meaning

LG = −Ex∼p f akelog[pmodel(y < K + 1 | x)].

(8)

the discriminator too ”knows” exactly the data distribution. If
there were any diﬀerence between the true and generated image

However, Salimans et al. (2016) found better results by trying

to have the output activations of an intermediate layer of the

distributions, the discriminator could use this to distinguish be-

discriminator have similar statistics in both the fake and real

tween real and fake, and then the generator could still be trained

image cases. That is, the generator should try to make its images

further toward producing a match of the true distribution.

produce similar features in an intermediate layer as is produced

Viewing this from the perspective of the manifold in data

when true images are input. This can be intuitively understood

space again, there are few labeled data points and many unla-

as making the statistics of the image be the same in both the fake

beled data points which must lie on the manifold. The manifold
has diﬀerent regions (or even separate manifolds) for each class,

and real cases, speciﬁcally, the feature statistics that are used in

deciding a classiﬁcation. The simplest and most useful statistic

but even the unlabeled data has to lie somewhere on the mani-

to try to match is the expected value for each feature. Formally

fold. As the discriminator trains, it learns how to segment the

put, if we denote f (x) as the features output by an intermediate

6

layer in the discriminator, then the loss function for the generator

becomes

LG = (cid:13)(cid:13)(cid:13)Ex∼preal f (x) − Ex∼p f ake f (x)

(cid:13)(cid:13)(cid:13)
2
2.

(9)

ing digit classiﬁcation (Springenberg, 2015; Sricharan et al.,

2017; Salimans et al., 2016), object classiﬁcation (Springen-

berg, 2015; Sricharan et al., 2017; Salimans et al., 2016), facial

attribute identiﬁcation (Sricharan et al., 2017), and image seg-

mentation (per pixel object classiﬁcation) (Souly et al., 2017).

Since their development, semi-supervised GANs have been

Fig. 3: A DG-GAN network splitting the network into solving the two objectives

used to improve training in many areas of classiﬁcation, includ-

independently, rather than using a shared representation. The dashed lines

represent connections which exist but have very low weights. The degree of this

division of learning can vary.

the dataset. This method has two signiﬁcant limitations. 1) If the

full range of the unlabeled dataset is unknown, a correct angle

prediction will be incorrectly labeled as fake data. Rezagholi-

is known. 2) A bias is introduced, as values near the boundary

between fake and real are preferred. This is because a gener-

ator which can exactly duplicate unlabeled data will force the

discriminator to pick a value on the boundary between fake and

real as the best possible answer. Finally, a discrete classiﬁcation

method was presented with each class being the central value of

2.4. Alternative semi-supervised regression GAN methods

radeh and Haidar (2018) assumes the range of the unlabeled data

For regression, Rezagholiradeh and Haidar (2018) provides

two semi-supervised GAN approaches. They have applied their

methods to the driving application, which we compare to in

Section 4.

First, they present a dual goal GAN (DG-GAN) approach,

which they refer to as Reg-GAN Architecture 1. A DG-GAN
outputs two labels: a regression value prediction and a fake/real

the class interval.

classiﬁcation prediction. The idea is that the network must learn

both how to distinguish between real and fake examples, and

2.5. Regression in Conditional GANs

how to predict the correct value for a labeled example. However,

Another distinct category of related work is that of regression

this approach does not enforce that these two predictions be

in conditional GANs. Conditional GANs are a type of GAN

related. Part of the network may learn the task of identifying
real/fake images, while another portion of the network learns

designed to produce realistic examples which have speciﬁc de-

sired properties in the example. Bazrafkan and Corcoran (2018)

the task of predicting regression values. A representation of

provides an approach to generate images with speciﬁc character-

this split learning can be seen in Fig. 3.

If the objective of

istics in a conditional GAN. In particular, they use a regressor in

distinguishing being real and fake examples is weighted strongly

parallel with the discriminator network to provide more variation

enough, the network may devote larger portions of the network to
the real/fake classiﬁcation task, thereby reducing its eﬀectiveness

in the generated examples.

These works are attempting to produce realistic looking gen-

in the regression prediction. We show in our experiments that

erated examples. The produce is not a predictive network for

our proposed method outperforms the DG-GAN, both in our

real examples. In contrast, our approach is designed to improve

own implementation and in that of Rezagholiradeh and Haidar

the predictive capabilities of the discriminator on real examples.

(2018).

Notably, we do not expect our generator to produce realistic

They also present a second which method, Reg-GAN Archi-

looking examples. On the contrary, we expect the examples gen-

tecture 2, which only outputs the single driving angle regression

erated will not look realistic. As noted by Salimans et al. (2016),

value, and then attempts to label this value as fake or real de-

the use of feature matching (which is also used in our work)

pending on if the value lies within the range of real values from

improves discriminator predictive accuracy while reducing the

7

realism of the generated examples. We expect our feature con-

trasting approach will further erode the realism. Furthermore,

works such as Dai et al. (2017) show how a generator which pro-

duces examples that are too realistic may be less advantageous

for improving a discriminator’s predictive abilities.

3. Theory and Design

3.1. SR-GAN Formulation Using Feature Contrasting

The semi-supervised regression GAN (SR-GAN) approaches

regression estimation by comparing the types of available data

(labeled, unlabeled, and fake) as probability distributions rather

than individual examples. In this method, the discriminator does

not attempt to predict a label for the unlabeled data or fake data.

Instead, the statistics of the features within the network for each

criminator seek to make the unlabeled examples have a similar

feature distribution as the labeled examples. The discriminator

also works to have fake examples have a feature distribution

as divergent from the labeled examples distribution as possi-

ble. This forces the discriminator to see both the labeled and

unlabeled examples as coming from the same distribution, and
fake data as coming from a diﬀerent distribution. The generator,

on the other hand, will be trained to produce examples which

type of data is compared. Here is the key idea: We have the dis-

or fake label is assigned.

Fig. 4: The structure of an SR-GAN. Its structure is similar to the semi-
supervised GAN, with the major diﬀerences being in the objective functions and

the output being a regression value. In this network, the discriminator distin-

guishes between fake and real images through feature statistics. No explicit real

contrasting, which is antithetical to feature matching. In this

case, the discriminator attempts to make the features of the real

and fake data as dissimilar as possible, while the generator is

attempting to make these features as similar as possible.

Speciﬁcally, the loss functions as deﬁned for classiﬁcation

(Eqs. (5) to (7)) in the case of regression will become the follow-

ing. First, we separate the loss of the discriminator into several

match the unlabeled example distribution, and because of this,

terms for clarity. This is given by

the generator and discriminator have opposing goals. How a

label is assigned to an example drawn from that distribution

is still decided by based on the labeled examples (as it is in
ordinary DNN/CNN training), but the fact that the unlabeled

examples must lie in the true example distribution forces the

LD = Lsupervised + Lunsupervised

= Llabeled + Lunlabeled + L f ake

.

(10)

What we refer to as the ”labeled loss”, is given by

Llabeled = Ex,y∼pdata(x,y)[(D(x) − y)2].

(11)

discriminator to more closely conform to the true underlying

This loss is similar to an ordinary fully supervised loss (for

data generating distribution. The SR-GAN structure can be seen

regression training). Next, the ”unlabeled loss” causes the dis-

in Fig. 4 with age estimation as an example. For the case of

criminator to attempt to make the feature statistics of the real

training the discriminator to have similar feature statistics for

labeled data and the real unlabeled data be as similar as possible.

both real labeled and real unlabeled data, this approach is re-

This unlabeled loss is given by

lated to the feature matching proposed by Salimans et al. (2016),
except that this is applied for entirely diﬀerent purposes than it

Lunlabeled = (cid:13)(cid:13)(cid:13)Ex∼plabeled f (x) − Ex∼punlabeled f (x)

(cid:13)(cid:13)(cid:13)
2
2.

(12)

was in their work. In the case of training the discriminator with

In contrast, the ”fake loss” causes to the discriminator to attempt

real data and fake data, we propose a novel approach, feature

to make the feature statistics of the real data as dissimilar to the

s
s
o
L

LG
L f ake

−10

−5

0
Feature diﬀerence

5

10

Fig. 5: A comparison of the losses used for feature matching and feature con-

trasting, used in LG and Lunlabeled respectively. The losses have been normalized

for comparison. Shown in the change in loss due to a single feature (due to the

norms used in the functions, multiple features changing together have a slightly
diﬀerent impact). Of particular note, a decreased loss for one necessarily results

in an increased loss for the other.

8

punished, resulting in a network which tries to make all features

similar. Conversely, an L1 norm is used for feature contrasting.

This is because an L2 norm would result in a discriminator which

focuses on the already most dissimilar feature while allowing

all other features to become similar. The L1 norm puts an equal

beneﬁt on contrasting all features. To emphasize this, the L2

norm for L f ake results in problematic backpropagation, as zero
distance feature diﬀerences should result in the largest gradients,

but are instead multiplied by zero.

To summarize, the SR-GAN uses feature matching for the

discriminator loss functions where in previous methods a sep-

arate ”fake” class is deﬁned. Speciﬁcally this can be seen in

the change from the unsupervised loss in Eq. (7) (which uses a

”fake” class in the discriminator) to Eqs. (12) and (13) (which

uses feature layer statistics). This accomplishes two goals:

1. Regression problems have no classes and the previous meth-

ods require a ”fake” class deﬁnition, and the SR-GAN

fake data as possible. This feature contrasting is accomplished

approach allows regression problems to be approached.

with the loss function given by

2. The feature matching does not introduce any bias in the

L f ake = −

(cid:13)(cid:13)(cid:13)(cid:13)log

(cid:16)
|Ex∼p f ake f (x) − Ex∼punlabeled f (x)| + 1

(cid:17)(cid:13)(cid:13)(cid:13)(cid:13)1

.

(13)

discriminator label prediction, as the ﬁnal label output is

not used in the unsupervised loss.

Finally, the generator attempts to make the feature statistics of

Additionally, the SR-GAN approach requires no prior informa-

the real data match those of the fake data. This goal is accom-

tion about the data and requires no manual deﬁnition of goals

plished by the generator loss given by

beyond the original loss function for labeled examples.

LG = (cid:13)(cid:13)(cid:13)Ex∼p f ake f (x) − Ex∼punlabeled f (x)

(cid:13)(cid:13)(cid:13)
2
2.

(14)

3.2. Gradient penalty

Here, Lunlabeled and LG are identical except in which types of

data are being compared. Additionally, the feature contrasting

Of the challenges preventing the use of an SR-GAN, the
greatest is likely the diﬃculty of designing an objective which

in Eq. (13) is in direct opposition to the feature matching in

reliably and consistently converges. GANs can easily fail to

Eq. (14). Notably, there is no possibility for the generator and

converge under various circumstances Barnett (2018). To solve

discriminator to both beneﬁt by a change in these features; A

these general GAN instability issues, we use the gradient penalty

decreased loss for one necessarily results an increased loss for

approach proposed by Arjovsky et al. (2017) and Gulrajani et al.

the other. A comparison of a change in the loss from a single

(2017).

feature can be seen in Fig. 5. We brieﬂy explore some additional

The gradient penalty as deﬁned by Gulrajani et al. (2017) is

loss function options in Section 3.1.

not applicable to our situation, because their gradient penalty is

We note that we choose a diﬀerent norm function for Eq. (13)

based on the ﬁnal output of the discriminator. As the ﬁnal output

compared to Eqs. (11) and (14). The L2 norm in Eqs. (11)

of the discriminator is not used in producing the gradient to the

and (14) causes any non-matching feature to be the most heavily

generator, we use a modiﬁed form of the gradient penalty. This

gradient penalty term is added to the rest of the loss function

controlled and understood environment. These include: what is

9

the right objective which reliably and consistently converges in
training, and how little data is needed to achieve diﬀerent levels

(15)

of prediction accuracy. We will use a dataset of polynomials

resulting in

L = Llabeled + Lunlabeled + L f ake

+ λ Ex∼pinterpolate

max

(cid:107)∇ ˆx( f (x))(cid:107)2

2 − 1

(cid:104)

(cid:16)(cid:16)

(cid:17)

(cid:17)(cid:105)

, 0

.

where pinterpolate examples are generated by αpunlabeled + (1 −

α)p f ake for α ∼ U. The last term basically provides a restriction

on how quickly the discriminator can change relative to the

generator’s output. Our version of the gradient penalty term

is modiﬁed in multiple ways from the original. First, as noted

above, the ﬁnal discriminator output cannot be used, nor should

it, as the discriminator’s interpretation of the generated data only

matter in regard to the feature vector, f (x). Second, the gradient

penalty is normally applied to a term similar to the L f ake term

using the interpolated values. However, our L f ake is based on
the average of a batch of fake examples whose diﬀerence is

itself.

then taken from a batch of real examples. As both the L f ake

term and interpolates are calculated based on the real data, the

resulting gradient penalty is negligible. Instead, we apply the

gradient penalty directly to the mean feature vector of a batch

of interpolated examples and do not apply the feature distance

loss function compared to the mean real feature vector. As this

penalizes the gradient even for mean feature vectors far from the

mean real feature vector, it may slow training. However, near the

real feature vector, it approximates the original gradient penalty

formulation and works well in practice. Lastly, we use the one-

sided version of the gradient penalty described by Gulrajani et al.

(2017). As mentioned in their work, the one-sided penalty more

closely matches the desired discriminator training properties,

and we found this approach to produce higher accuracies than

the two-sided penalty.

4. Experiments and Results

with sampled points on the polynomial, whereas the goal of the
network is to predict coeﬃcients of the polynomial given the

sampled points. Using this simplistic problem, we can show

how the semi-supervised regression GAN works in details, what

variations can inﬂuence its capabilities, and what its limitations

are. Most importantly, this allows us to have complete control

and understanding of the underlying data generating distribu-

tion. This is impossible in any real-world application, as the

underlying data generating distribution there is the real world

The downside to the synthetic dataset is that because we have

complete control over the data generating distribution, we can

deﬁne the data such that our SR-GAN does arbitrarily well com-

pared with a normal DNN. As such, the remaining experimental

setups are real-world applications. The applications of age esti-

mation, driving steering angle prediction, and crowd counting

have been chosen for this purpose. The real world case provides

an area we can show direct improvements in compared to a

non-adversarial CNN.

4.1. Coeﬃcient Estimation

The ﬁrst experimental setup consists of a simple, well-

controlled mathematical model, whose problem can be easily

solved with simple neural networks when given enough exam-
ples. The example chosen is a polynomial coeﬃcient estimation

problem. This problem allows for an environment in which

many properties of the semi-supervised regression GAN can be

shown and their limits tested. In particular, the simple environ-

To demonstrate the capabilities of the semi-supervised regres-

ment allows us to not only demonstrate the properties of the

sion GANs, we use four experimental setups, each of which

semi-supervised regression GAN but also give a clear theoretic

consists of several individual trials and demonstrations.

understanding of why the network exhibits these behaviors. Five

The ﬁrst experimental setup will be of a synthesized dataset

important aspects will be discussed: 1) the dataset; 2) the exper-

problem. This will allow us to demonstrate the details of the theo-

iment setup; 3) estimation with minimal data; 4) loss function

retical issues behind a semi-supervised regression GAN in a well

analysis; and 5) choices of gradient penalty.

10

4.1.1. Polynomial Coeﬃcient Estimation Dataset

For the data of the mathematical model to appropriately repre-

sent the characteristics of a real aggression application, we seek

to create a data generating model that exhibits the following

properties.

lectable.

1. Able to produce any desired number of examples.

2. The distribution of the underlying data properties is se-

1.2

1.0

0.8

0.6

0.4

0.2

0.0

3. The relation between the raw data and the label is abstract,

where the label is a regression value instead of one of a

−1

−0.5

0

0.5

1

ﬁnite number of classes.

4. Able to contain latent properties that eﬀect the relation

between the data and the labels.

5. Most of the data can be made to be irrelevant to the label.

Property 1 allows us to run any number of trials on new data,

and run trials where data is unlimited. Property 2 reveals the

inner workings of the data distribution. This is important, as

we can monitor how closely the generator’s examples match

the true distribution and examine what kinds of distributions

lead to limitations or advantages of the GAN model. Property

3 ensures the ﬁndings on the toy model is relevant real deep

learning applications for regression. That is, deep learning is

Fig. 6: An example of a polynomial as described in Eq. (16) with 10 points
sampled. In this case, a2 = 2, a3 = −1, and a4 = −1, but only a3 is the
coeﬃcient to be estimated.

majority of the input data has little to no relevance for the task

at hand. The network must learn which information should be

relied on and which data should be ignored.

An option of a simplistic mathematical model for this purpose

would be a data generating distribution which is deﬁned as

follows. First, we deﬁne a polynomial,

y = a4x4 + a3x3 + a2x2 + a1 x.

(16)

typically used in cases where input data is complex, and an

We set a1 = 1. With U(r0, r1) representing a uniform dis-

abstract, high-level meaning of that data is desired. When the

tribution over the range from r0 to r1, a3 is randomly cho-

relationship between the data and the label (the regression value)

is too simple, more traditional prediction methods tend to be

sen from U(−1, 1). a2 and a4 are randomly chosen from
b · U(−2, −1) + (1 − b) · U(1, 2) with b being randomly chosen

used. Property 4 is also important because of its relationship

from a standard binomial distribution. Then we sample y for 10

to real applications. Most applications involve cases where a
property which is not the value to be predicted directly eﬀects

xs from linear space from −1 to 1. An example of such a poly-

nomial and the observed points are shown in Fig. 6. This one

the data related to value to be predicted. For example, in the case

polynomial and the observed points constitutes a single example

of age estimation, whether the image of the face is lit from the

in our dataset. The label of this example we choose as a3. That

front or lit from the side drastically changes the data and what

is, our network, when given the 10 observations, should be able

the CNN should be searching for. Finally, Property 5 requires

to predict a3.

that our model is able to ﬁlter which pieces of information are

We can compare the pieces of this data generating distribution

important and which are not. Again, in the case of age estimation,

to the standard image regression problem (think of age estima-

whether the background behind the person is outdoors or indoors

tion from images) to better understand what parts of the toy

should have little or no impact on the prediction of their age.

model represent which parts in a real application model. The 10

In many, if not most, cases of deep learning applications the

observed values from the toy model are analogous to the pixel

DNN
SR-GAN
DG-GAN

SR-GAN
DG-GAN

11

E
A
M

0.14

0.12

0.1

8 · 10−2

6 · 10−2

r
o
r
r
E
e
v
i
t
a
l
e
R
N
N
D
o
t

N
A
G

1.4

1.2

1

0.8

0.6

50

102

103

104

50

102

103

104

Labeled Dataset Size

Labeled Dataset Size

Fig. 7: The resultant inference accuracy of the coeﬃcient estimation network

trained with and without the SR-GAN for various quantities of labeled data.

Fig. 8: The relative error of the GAN model over CNN model for various
quantities of labeled data for the coeﬃcient model.

values in image regression. a3 is equivalent to the object label

on. The same seeds are used for each set of experiments. That

(e.g. age value). Finally, the set of all polynomials obtainable
from Eq. (16), given the restrictions on how the coeﬃcients

is, the SR-GAN compared with the DNN use the same training

data for each individual trial. Additionally, for experiments over

are chosen, is the underlying data generating distribution in the

a changing hyperparameter, the same seeds are used for each

tor is set to 0 for the ﬁrst experiment, 1 for the second, and so

toy case, where this role is played by views of the real world

hyperparameter value.

projected to an image plane in the regression case (such as age

estimation).

In these experiments, we demonstrate the value of the SR-
GAN on polynomial coeﬃcient estimation. Using a simple

This model fulﬁlls all but the last property deﬁned above. To

fully connected neural network architecture, we have tested the

satisfy Property 5, we simply make every example in the dataset
consist of 5 diﬀerent polynomials each chosen and observed as

previously explained. However, for this single example (consist-
ing of 5 polynomials) on the a3 coeﬃcient of the ﬁrst example is

the label. Thus, each example consists of 50 observations, only

DG-GAN and SR-GAN methods compared to a plain DNN on

various quantities of data from the generation process described

above. The results of these experiments can be seen in Fig. 7.

In each of these experiments an unlabeled dataset of 50,000

examples was used, when various quantities (from 50 to 10,000)

10 of which are related to the label. Lastly, we apply noise to

of labeled data were used. Each data point on the plots is the

every observation.

4.1.2. Coeﬃcient Estimation Experimental Setup

average of three training runs randomly seeded to contain dif-

ferent training and test sets on each experiment. The relative

error between the DNN and the GAN methods can be seen in

In the coeﬃcient estimation experiments, both the discrimi-

Fig. 8. We see a signiﬁcant accuracy improvement in lower

nator and generator each consisted of a 4 layer fully connected

labeled data cases for the GAN methods. The SR-GAN error is

neural network. Each layer contained 10 hidden units. All code

68% of what the DNN error is at with 50 labeled examples. With

and hyperparameters can be found at https://github.com/

50 examples, the DG-GAN also has a signiﬁcant advantage with

golmschenk/srgan. The training dataset for each experiment

75% the error the DNN has. However, the DG-GAN quickly

was randomly chosen. The seed for the random number genera-

loses its advantage over the DNN as the data size increases. As

the amount of labeled data becomes very large, SR-GAN does

not perform better than the DNN. This diminishing return is

Loss Functions

expected, as we can consider the case of inﬁnite labeled data,

where unlabeled data could then provide no additional useful
information. We note that for the simple problem of coeﬃcient

estimation, 10,000 examples is a very large dataset for training.

In each of the real world applications we tested our SR-GAN

method in, we did not see a detriment in using the SR-GAN with

larger numbers of labeled examples.

examples.

(cid:16)

(cid:13)(cid:13)(cid:13)(cid:13)log
L f ake = −
(cid:13)(cid:13)(cid:13)
(cid:112)
L f ake = −
(cid:13)(cid:13)(cid:13)d f
L f ake = −

(cid:17)(cid:13)(cid:13)(cid:13)(cid:13)1
d f + 1
(cid:13)(cid:13)(cid:13)1
Lunlabeled = LG = (cid:13)(cid:13)(cid:13)d f
d f + 1
Lunlabeled = LG = (cid:13)(cid:13)(cid:13)d f
(cid:13)(cid:13)(cid:13)1

Lunlabeled = LG = (cid:13)(cid:13)(cid:13)d f
(cid:13)(cid:13)(cid:13)

(cid:13)(cid:13)(cid:13)2

2
2

(cid:13)(cid:13)(cid:13)

2
2

Table 1: A comparison of the SR-GAN method using various loss functions

for feature matching and feature contrasting. Each experiment was run on
the coeﬃcient application with 500 labeled examples and 50,000 unlabeled

12

MAE

0.0578

0.0613

0.0672

4.1.3. Loss Function Analysis on Coeﬃcient Estimation

As noted in Section 3.1 we primarily experimented with the

loss functions given in Eqs. (11), (13) and (14). However, these

are not the only loss functions which could be used for the

feature matching and feature contrasting objectives.

We tested three sets of loss functions. We will refer to the

feature distance vector as

d f = |Ex∼p1 f (x) − Ex∼p2 f (x)|

(17)

4.2. Driving Steering Angle Prediction

This application works to predict the steering angle of a car

given an image from the front of a car. Such an approach allows
for basic partial self-driving/auto-pilot capabilities using a single

image (Pan et al., 2017). The dataset (Chen, 2017) consists of

45,567 images from a dashboard-mounted camera, where for

each image the current rotation angle of the steering wheel was

recorded. The goal of the network is to predict this rotation

angle given the front facing view image, whose primary feature

is the upcoming road segment.

where p1 and p2 are the appropriate labeled, unlabeled, or fake

Rezagholiradeh and Haidar (2018) provides two semi-

data distributions depending on if the d f is being used in the

supervised GAN approaches to train for this application which

Lunlabeled, L f ake, or LG terms. With this, we used the feature

are described in Section 2.4. Additionally, they also provide a

contrasting and feature matching loss functions given in Table 1.

baseline discrete classiﬁcation method with each class being the

The ﬁrst is the set of loss functions given previously, which we

central value of the class interval.

have already given an explanation for. The second set keeps the

Here, we perform the experiments presented by Rezagholi-

same feature matching function but uses a square root as the

radeh and Haidar (2018) using our SR-GAN approach.

In

primary component of the feature contrasting function. This pro-

these experiments, varying numbers of labeled images randomly

vides a stronger incentive for the discriminator to push features

selected from the entire dataset are used for training (up to

which are already far apart, even further apart. This second ap-

7,200 images) and testing (9,000 images). The remaining im-

proach did slightly worse than the ﬁrst, likely because focusing

ages are used as the unlabeled data. We use the DCGAN net-

on contrasting those features which are most similar between

work architecture (Radford et al., 2015), which matches the

the fake and real examples provides a greater improvement. The

architecture presented by Rezagholiradeh and Haidar (2018).

third approach uses linear losses. This is similar to the linear
fake/real losses used in the WGAN implementation by Arjovsky

This network structure (both generator and discriminator) is

shown in Fig. 9. All code and hyperparameters can be found at

et al. (2017). The reason for the decreased accuracy is likely

https://github.com/golmschenk/srgan. We note that we

the same as for the second case, where features which are al-

cannot precisely duplicate the experiments by Rezagholiradeh

ready dissimilar are still given too much priority in the feature

and Haidar (2018), as the images used for training and testing

contrasting.

were randomly chosen. We similarly randomly selected our

13

Fig. 9: The DCGAN structure used for the age estimation experiments. The left
network is the generator and the right is the discriminator/CNN.

(a) Fake steering angle images.

(b) Real steering angle images.

Fig. 10: Examples of real and fake images used/generated during training. We

note that our approach is not intended to produce realistic looking images, and

the fake images are only included for insight.

4.3. Age Estimation

datasets. Our random selections were seeded for reproducibility,

and the code at our repository can be used to retrieve the dataset

selection for our experiments. Examples of the images, both real
and fake, used/generated during training are shown in Fig. 10.

Age estimation is a well-known regression problem in com-

puter vision using deep learning. In particular, well-established

datasets of images of individuals with corresponding ages exist

and are widely used by the computer vision community. The

We also note that an entirely random image selection has

most notable age estimation database is currently the IMDB-

limited evaluation value for this dataset. The images are part of
a video sequence with each image have only minor diﬀerences

WIKI Face Dataset (Rothe et al., 2016).

For our work, having such a well-known dataset is particularly

from the previous image. Even a small percentage of the images,

important as the deep learning community tends to focus on

when randomly chosen, will contain the primary attributes of a

classiﬁcation problems and not regression problems. Due to this,

large portion of the dataset. However, for comparison purposes,

well-known regression datasets—ones known even outside their

we have followed the experimental procedure used by Rezagholi-

domain—tend to be rare. The age estimation dataset is one of

radeh and Haidar (2018). We have additionally provided results

these rare cases. It provides a standard which we can test our

for signiﬁcantly lower numbers of labeled images.

SR-GAN on which is widely tested on.

The evaluation metric used is a normalized mean absolute

error (NAE) given by

4.3.1. Age Estimation Dataset

The IMDB-WIKI dataset includes over 0.5 million annotated

NAE = 1
N

N(cid:88)

i=1

|yi − ˆyi|
ymax − ymin

× 100%.

(18)

images of faces and the corresponding ages of the people thus

imaged. There are 523,051 face images: from 20,284 celebrities,

460,723 face images are from IMDb and 62,328 from Wikipedia.

The results of our method in comparison to the methods pre-

5% of the celebrities have more than 100 photos, and on average

sented by Rezagholiradeh and Haidar (2018) are shown in Ta-

each celebrity has around 23 images.

ble 2. In these experiments, we show that our SR-GAN method

There are likely many mislabeled images included in the

signiﬁcantly outperforms the Reg-GAN method for any number

dataset. The image-label pairs were created by searching the

of labeled examples. As Architecture 2 is the more generalized

top 100,000 actors on IMDb (also known as the ”Internet Movie

approach of Reg-GAN, it provides the comparison of the most

Database). The actors’ IMDb proﬁle and Wikipedia page were

interest.

scraped for images. Face detection was performed on these

14

Method

100

500

1000

2000

4000

7200

Improved-GAN

Reg-GAN (Arch 1)

Reg-GAN (Arch 2)

-

-

-

-

-

-

4.38% 4.22% 4.07% 4.06%

2.43% 2.40% 2.39% 2.36%

3.81% 3.58% 2.23% 2.21%

SR-GAN

3.12% 2.32% 2.02% 1.89% 1.37% 1.16%

Table 2: Steering angle prediction NAE compared to existing approaches for various amounts of labeled training examples.

images, and if a single face detection is found, the image is

assumed to be of the correct individual. The image timestamp

along with the date of birth of the actor is used to label the image

with an age. The image is often a screen capture of a movie,

which may have taken years to produce or the screen capture

may have happened years later. Additionally, the actor may be
purposely made to look a diﬀerent age in the movie. Despite

these many areas of mislabeling, the dataset it thought to consist

(a) Fake age images.

(b) Real age images.

of overwhelmingly correctly labeled images. To minimize the

number of incorrectly labeled images the database is ﬁltered

Fig. 11: Examples of real and fake images used/generated during training. We

note that our approach is not intended to produce realistic looking images, and

based on several criteria. The database includes face detection

the fake images are only included for insight.

scores (certainty of containing a face) and a secondary face score

(containing an additional face). If the ﬁrst face score was too low

the image was excluded. If there was a secondary face detected

it is also excluded (since these are taken from the actor’s IMDb

page, it is only assumed to be a picture of the actor if there is

only one person in the image). Images labeled with an age below

10 or above 95 are also excluded. Primarily, the below 10 ﬁlter

is important as many images included an incorrect age of only
a few years old. Finally, only images of 256×256 resolution

or higher are used. After this ﬁltering, we are left with ∼90K

eters can be found at https://github.com/golmschenk/

srgan. The discriminator of the DCGAN was used alone as

the CNN baseline model. The network structure can be seen

in Fig. 9. The training dataset for each experiment was ran-

domly chosen. The seed is set to 0 for the ﬁrst experiment, 1

for the second, and so on. The same seeds are used for each

set of experiments. That is, the SR-GAN compared with the

CNN use the same training data for each individual trial. This

set of experiments used the second set of loss functions from

images. Both the labeled and unlabeled data is taken from

these images (without overlap), and the labels were not used for

Section 4.1.3.

the unlabeled data. Data was selected randomly for each trial.

Though other face data could be used for the unlabeled data,

for these experiments, we wished to ensure that the labeled and

unlabeled data came from the same data distribution.

The following experiments demonstrate the value of the SR-

GAN on age estimation. Using a DCGAN (Radford et al., 2015)

network architecture, we have tested the SR-GAN method on

various quantities of data from the IMDB-WIKI database. The

results of these experiments can be seen in Fig. 13. In each of

4.3.2. Age Estimation Experimental Setup

these experiments, an unlabeled dataset of 50,000 images was

In the age estimation experiments, the DCGAN network archi-

used, whereas the size of the labeled data samples varies from

tecture (Radford et al., 2015) is used. All code and hyperparam-

10 to 30,000. Each point on this plot is the result of a single

IMDB
WIKI
IMDB-WIKI

15

DNN
GAN

)
s
r
a
e
y
(
E
A
M

e
g
A

16

14

12

10

8

0

20

40

60

80

100

101

102

103

104

3 · 104

Fig. 12: The distribution of ages in the IMDB-WIKI database.

Labeled Dataset Size

randomly seeded training dataset. For each labeled dataset size,

Fig. 13: The resultant inference accuracy of the age estimation network trained

with and without the SR-GAN for various quantities of labeled data. Each dot

5 trials were run. The relative error between the CNN and the

represents a trial with randomized training data, and the line represents the mean

GAN can be seen in Fig. 14. We see a signiﬁcant accuracy

of the trials.

improvement in every case tested. At 100 labeled examples, the

GAN achieves a MAE of 10.6, an accuracy which is not achieved

by the CNN until it has 5000 labeled examples available for

training. At 100 labeled examples, the GAN has 75% the error

that the CNN does.

The advantage of the SR-GAN drops to near zero as the

number of images approaches the number of unlabeled examples

being used. There seem to be two likely causes for this. Either,

there are enough training images that the network is at capacity

(additional images will not further improve the results), or the

ratio of labeled to unlabeled images is too small for the generator

to be of more beneﬁt to the discriminator. Unfortunately, the

number of images available in the IMDB-WIKI dataset make it
diﬃcult to pursue a larger number of training examples further.

4.4. Crowd Counting

The fourth application we consider is the complex problem

are present, their current locations, and the intervals at which

people are present. For security purposes, evacuations planning

and where crowding might be a potential harm to individuals is

dependent on the size of the crowds. In journalistic pursuits, the

size of a crowd attending an event is often used to measure the

signiﬁcance of the event.

We provide the mean absolute count error (MAE), normalized

absolute count error (NAE), and root mean squared count error

(RMSE). These are given by the following equations:

MAE = 1
N

N(cid:88)

i=1

(cid:12)(cid:12)(cid:12) ˆCi − Ci

(cid:12)(cid:12)(cid:12)

NAE = 1
N

(cid:12)(cid:12)(cid:12)

(cid:12)(cid:12)(cid:12) ˆCi − Ci
Ci

N(cid:88)

i=1

RMSE =

( ˆCi − Ci)2

(cid:118)(cid:117)(cid:116)

1
N

N(cid:88)

i=1

(19)

(20)

(21)

of dense crowd counting. Every year, crowds of thousands to

Idrees et al. (2018) showed that a vanilla DenseNet (Huang

millions gather for protests, marathons, pilgrimages, festivals,

et al., 2017) outperformed many application-speciﬁc networks

concerts, and sports events. For each of these events, there is

for crowd counting. Though Idrees et al. (2018) then provides

a myriad of reasons to desire to know how many people are

an application speciﬁc version of DenseNet, we chose to use

present. For those holding the event, both real-time management

the vanilla version of DenseNet201 as the discriminator in our

and future event planning is determined by how many people

experiments. This is done to avoid application speciﬁc nuances

16

Fig. 15: Full image examples from the ShanghaiTech crowd counting dataset.

r
o
r
r
E
e
v
i
t
a
l
e
R
N
N
D
o
t

N
A
G

1

0.9

0.8

0.7

101

102

103

104

3 · 104

Labeled Dataset Size

Fig. 14: The relative error of the GAN model over CNN model for various

quantities of labeled data for age estimation. Each dot represents a trial with

randomized training data, and the line represents the mean of the trials.

that distract from the main focus of our work, while still pro-

viding a network comparable to the state-of-the-art in terms of

accuracy. For the generator, we use the same DCGAN gen-

erator architecture as was used in our age and steering angle

experiments.

(a) Fake crowd counting images.

(b) Real crowd counting images.

The dataset we evaluated our approach on is the ShanghaiTech

dataset (Zhang et al., 2016) part A. The dataset is split into two

Fig. 16: Examples of real and fake images used/generated during training. We

note that our approach is not intended to produce realistic looking images, and

parts, of which we used Part A in our experiments. Part A con-

the fake images are only included for insight.

tains 482 images, 300 for training and 182 for testing. It contains

a total of 241,677 head labelings, with an average of 501.4, a

ments, we can clearly see that the SR-GAN model outperforms

maximum of 3,139, and a minimum of 33. This part contains a

the CNN model consistently across various amounts of labeled

wide range of image sizes, head counts, and perspectives. We

training images (from 50 to 300), on all three measures. Over-

used the training and testing images as prescribed by the dataset

all, SR-GAN advantage increases when more training examples

provider, except we used limited labels for training. A set of

are provided. For example, the decreases of MAE of using the

example images can be seen in Fig. 15. During the training

SR-GAN versus the CNN are 2.6%, 3.4%, 6.0% to 6.4% for

process, patches of the images are used. During testing, a sliding

50, 100, 200 to 300, respectively. This is slightly contrary to

window approach is used to calculate the count for each patch

what we might expect, as we would assume the advantage of

with overlapping patches being averaged. A ﬁnal summing of

the SR-GAN to diminish as the number of examples becomes

the average values produces a count for the entire image. Exam-
ples of the patches, both real and fake, used/generated during

very large. However, the increase is small enough that it may

simply be due to chance from dataset selection. The percentage

training are shown in Fig. 16.

in error decreases are small, but they are comparable to the de-

We compare a CNN with the SR-GAN model in our experi-

crease gained by increasing the size of the labeled dataset. In

ments. These results can be seen in Table 3. From the experi-

many cases, the SR-GAN provides an improved over the CNN

Method

50

100

200

300

6. Acknowledgments

CNN MAE

136.9

127.5

119.2

118.0

SR-GAN MAE

133.3

123.2

112.0

110.5

CNN NAE

0.342

0.354

0.359

0.357

SR-GAN NAE

0.339

0.348

0.321

0.323

CNN RMSE

208.5

185.1

183.2

182.3

SR-GAN RMSE 205.9

178.3

178.2

169.5

Table 3: Crowd counting errors compared various amounts of labeled training

examples.

even with smaller numbers of labeled examples. For example,

the SR-GAN with 200 images outperforms the CNN with 300

images. Such improvements are also found in the RMSE for the

SR-GAN with 100 and 200 labeled examples compared to the

CNN with 200 and 300 examples.

References

5. Conclusions

17

This research was initiated under appointments to the U.S. De-

partment of Homeland Security (DHS) Science & Technology
Directorate Oﬃce of University Programs, administered by the

Oak Ridge Institute for Science and Education (ORISE) through

an interagency agreement between the U.S. Department of En-

ergy (DOE) and DHS. ORISE is managed by ORAU under DOE

contract number DE-AC05-06OR23100 and DE-SC0014664.

All opinions expressed in this paper are the author’s and do

not necessarily reﬂect the policies and views of DHS, DOE,
or ORAU/ORISE. The research is also supported by National

Science Foundation through Awards PFI #1827505 and SCC-

Planning #1737533, and Bentley Systems, Incorporated, through

a CUNY-Bentley Collaborative Research Agreement (CRA).

Ali, I., Greifeneder, F., Stamenkovic, J., Neumann, M., Notarnicola, C., 2015.

Review of machine learning approaches for biomass and soil moisture re-

trievals from remote sensing data. Remote Sensing 7, 16398–16421.

Arjovsky, M., Chintala, S., Bottou, L., 2017. Wasserstein gan. arXiv preprint

arXiv:1701.07875 .

Throughout this work, we have presented a means by which

to train semi-supervised GANs in a regression situation. The

Barnett, S.A., 2018. Convergence problems with generative adversarial networks

(gans). arXiv preprint arXiv:1806.11382 .

Bazrafkan, S., Corcoran, P., 2018. Versatile auxiliary regressor with generative

new SR-GAN algorithm was explained in detail. A set of opti-

adversarial network (var+ gan). arXiv preprint arXiv:1805.10864 .

mization rules which allows for stable, consistent training when

Bland, L.M., Collen, B., Orme, C.D.L., Bielby, J., 2015. Predicting the conser-

using the SR-GAN, including experiments demonstrating the

importance of these rules, were given. We performed systematic

vation status of data-deﬁcient species. Conservation Biology 29, 250–259.

Chen, S., 2017.

Sully Chen Driving Dataset.

https://github.com/

SullyChen/driving-datasets. [Online; accessed 8-February-2019].

experiments using the SR-GAN on the real world applications

Dai, Z., Yang, Z., Yang, F., Cohen, W.W., Salakhutdinov, R.R., 2017. Good

of age estimation,driving steering angle prediction, and crowd

semi-supervised learning that requires a bad gan, in: Advances in Neural

counting, all from single images, showing the beneﬁts of SR-

Information Processing Systems, pp. 6513–6523.

Ding, X., Zhang, Y., Liu, T., Duan, J., 2015. Deep learning for event-driven

GANs over existing approaches. Adding the SR-GAN generator

stock prediction., in: Ijcai, pp. 2327–2333.

and objectives to a CNN when unlabeled data is available almost

Dodge, S., Karam, L., 2017. A study and comparison of human and deep

always increases the predictive accuracy of the CNN.

learning recognition performance under visual distortions. arXiv preprint

arXiv:1705.02498 .

We believe this work demonstrates a way in which semi-

Eigen, D., Puhrsch, C., Fergus, R., 2014. Depth map prediction from a single

supervised GANs can be applied generally to a wide range of

image using a multi-scale deep network, in: Advances in neural information

regression problems with little or no change to the algorithm

processing systems, pp. 2366–2374.

presented here. This work allows such problems to be solved

using deep learning with signiﬁcantly less labeled training data

Elsayed, G., Shankar, S., Cheung, B., Papernot, N., Kurakin, A., Goodfellow, I.,

Sohl-Dickstein, J., 2018. Adversarial examples that fool both computer vision

and time-limited humans, in: Advances in Neural Information Processing

than was previously required.

Systems, pp. 3914–3924.

18

Fabbro, S., Venn, K., O’Briain, T., Bialek, S., Kielty, C., Jahandar, F., Monty,

Rezagholiradeh, M., Haidar, M.A., 2018. Reg-gan: Semi-supervised learning

S., 2017. An application of deep learning in the analysis of stellar spectra.

based on generative adversarial networks for regression, in: 2018 IEEE Inter-

Monthly Notices of the Royal Astronomical Society .

national Conference on Acoustics, Speech and Signal Processing (ICASSP),

Feﬀerman, C., Mitter, S., Narayanan, H., 2016. Testing the manifold hypothesis.

IEEE. pp. 2806–2810.

Journal of the American Mathematical Society 29, 983–1049.

Rothe, R., Timofte, R., Van Gool, L., 2016. Deep expectation of real and

Goodfellow, I., 2016. Nips 2016 tutorial: Generative adversarial networks. arXiv

apparent age from a single image without facial landmarks. International

preprint arXiv:1701.00160 .

Journal of Computer Vision , 1–14.

Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,

Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., Chen,

S., Courville, A., Bengio, Y., 2014. Generative adversarial nets, in: Advances

X., 2016. Improved techniques for training gans, in: Advances in Neural

in neural information processing systems, pp. 2672–2680.

Information Processing Systems, pp. 2234–2242.

Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., Courville, A.C., 2017.

Schwarz, M., Schulz, H., Behnke, S., 2015. Rgb-d object recognition and pose

Improved training of wasserstein gans, in: Advances in Neural Information

estimation based on pre-trained convolutional neural network features, in:

Processing Systems, pp. 5769–5779.

Robotics and Automation (ICRA), 2015 IEEE International Conference on,

Hartikainen, J., Seppanen, M., Sarkka, S., 2012. State-space inference for non-

IEEE. pp. 1329–1335.

linear latent force models with application to satellite orbit prediction. arXiv

Souly, N., Spampinato, C., Shah, M., 2017. Semi and weakly supervised

preprint arXiv:1206.4670 .

semantic segmentation using generative adversarial network. arXiv preprint

Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., 2017. Densely

arXiv:1703.09695 .

connected convolutional networks., in: CVPR, p. 3.

Springenberg, J.T., 2015. Unsupervised and semi-supervised learning with

Idrees, H., Tayyab, M., Athrey, K., Zhang, D., Al-Maadeed, S., Rajpoot, N.,

categorical generative adversarial networks. arXiv preprint arXiv:1511.06390

Shah, M., 2018. Composition loss for counting, density map estimation and

.

localization in dense crowds. arXiv preprint arXiv:1808.01050 .

Sricharan, K., Bala, R., Shreve, M., Ding, H., Saketh, K., Sun, J., 2017. Semi-

LeCun, Y., Bengio, Y., Hinton, G., 2015. Deep learning. Nature 521, 436–444.
LeCun, Y., Haﬀner, P., Bottou, L., Bengio, Y., 1999. Object recognition with

supervised conditional gans. arXiv preprint arXiv:1708.05789 .

Xingjian, S., Chen, Z., Wang, H., Yeung, D.Y., Wong, W.K., Woo, W.c., 2015.

gradient-based learning. Shape, contour and grouping in computer vision ,

Convolutional lstm network: A machine learning approach for precipitation

nowcasting, in: Advances in neural information processing systems, pp.

823–823.

Oceans 110.

Liu, Y., Weisberg, R.H., 2005. Patterns of ocean current variability on the west

802–810.

ﬂorida shelf using the self-organizing map. Journal of Geophysical Research:

Zhang, C., Li, H., Wang, X., Yang, X., 2015. Cross-scene crowd counting via

Lv, Y., Duan, Y., Kang, W., Li, Z., Wang, F.Y., 2015. Traﬃc ﬂow prediction

on Computer Vision and Pattern Recognition, pp. 833–841.

with big data: a deep learning approach. IEEE Transactions on Intelligent

Zhang, Y., Zhou, D., Chen, S., Gao, S., Ma, Y., 2016. Single-image crowd

Transportation Systems 16, 865–873.

counting via multi-column convolutional neural network, in: Proceedings

Marino, D.L., Amarasinghe, K., Manic, M., 2016. Building energy load forecast-

of the IEEE conference on computer vision and pattern recognition, pp.

deep convolutional neural networks, in: Proceedings of the IEEE Conference

ing using deep neural networks, in: Industrial Electronics Society, IECON

589–597.

2016-42nd Annual Conference of the IEEE, IEEE. pp. 7046–7051.

Niu, Z., Zhou, M., Wang, L., Gao, X., Hua, G., 2016. Ordinal regression

with multiple output cnn for age estimation, in: Proceedings of the IEEE

conference on computer vision and pattern recognition, pp. 4920–4928.
Oliveira, T.P., Barbar, J.S., Soares, A.S., 2016. Computer network traﬃc predic-

tion: a comparison between traditional and deep learning neural networks.

International Journal of Big Data Intelligence 3, 28–37.

Pan, X., You, Y., Wang, Z., Lu, C., 2017. Virtual to real reinforcement learning

for autonomous driving. arXiv preprint arXiv:1704.03952 .

Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T., Efros, A.A., 2016. Con-

text encoders: Feature learning by inpainting, in: Proceedings of the IEEE

Conference on Computer Vision and Pattern Recognition, pp. 2536–2544.

Radford, A., Metz, L., Chintala, S., 2015. Unsupervised representation learning

with deep convolutional generative adversarial networks. arXiv preprint

arXiv:1511.06434 .

Biographies of authors

*Biographies of authors

Greg Olmschenk

19

Greg Olmschenk is a PhD candidate in Computer Science at the Graduate Center of the City University

of New York. His focus is deep neural networks, particularly generative adversarial networks and methods

used for computer vision applications.

Zhigang Zhu

Zhigang Zhu received his BE, ME and PhD degrees, all in computer science, from Tsinghua University,

Beijing. He is Herbert G. Kayser Chair Professor of Computer Science, at The City College of New York

(CCNY) and The CUNY Graduate Center, where he directs the City College Visual Computing Laboratory
(CcvcL). His research interests include 3D computer vision, multimodal sensing, virtual/augmented reality,

and various applications in assistive technology, robotics, surveillance and transportation. He has published

over 150 technical papers in the related ﬁelds. He is an Associate Editor of the Machine Vision Applications

Journal, Springer, and the IFAC Mechatronics Journal, Elsevier.

Hao Tang

Hao Tang is an Associate Professor of Computer Science at The Borough of Manhattan Community

College, CUNY. He earned his Ph.D. degree in Computer Science, concentrating in the Computer Vision,

at the Graduate Center of CUNY. His research interests are in the ﬁelds of 3D computer modeling, HCI,

mobile vision and navigation and the applications in surveillance, assistive technology, and education. His

research paper was selected as the best paper ﬁnalist of International Conference on Multimedia and Expo.

