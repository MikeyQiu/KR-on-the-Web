Treebanking by Sentence and Tree Transformation:
Building a Treebank to Support Question Answering in Portuguese

Patr´ıcia Nunes Gonc¸alves, Rita Santos, Ant´onio Branco

University of Lisbon
Edif´ıcio C6, Departamento de Inform´atica
Faculdade de Ciˆencias, Universidade de Lisboa
Campo Grande, 1749-016 Lisboa
{patricia.nunes, rita.santos, antonio.branco}@di.fc.ul.pt

Abstract
This paper presents CINTIL-QATreebank, a treebank composed of Portuguese sentences that can be used to support the development
of Question Answering systems. To create this treebank, we use declarative sentences from the pre-existing CINTIL-Treebank and
manually transform their syntactic structure into a non-declarative sentence. Our corpus includes two clause types:
interrogative
and imperative clauses. CINTIL-QATreebank can be used in language science and techology general research, but it was developed
particularly for the development of automatic Question Answering systems. The non-declarative sentences are annotated with several
layers of linguistic information, namely (i) trees with information on constituency and grammatical function; (ii) sentence type; (iii)
interrogative pronoun; (iv) question type; and (v) semantic type of expected answer. Moreover, these non-declarative sentences are
paired with their declarative counterparts and associated with the expected answer snippets.

Keywords: treebank, question answering, tree transformation

1.

Introduction

A treebank is a corpus of texts in which every sentence has
been annotated with syntactic structure. This resource is
important for the development of advanced tools and appli-
cations in the NLP area.
This paper presents CINTIL-QATreebank, a treebank com-
posed of Portuguese sentences that can be used as input
to Question Answering (QA) systems and by their respec-
tive answers. Though this corpus is open to be used and
explored for general purpose language science and tech-
nology, it´s development was motivated by the intention to
build a dataset that supports the development and evalua-
tion of processing tools (e.g. sentence parsers) which are
important for the deployment of automatic QA systems.
Question Answering is the task of answering a query for-
mulated in natural language. From a query and a set
of documents, a QA system extracts and provides an an-
swer (Pas¸ca, 2003). Though interrogative sentences are the
main object of study in the area of QA, we also include im-
perative clauses in our treebank since they tend to be com-
monly used in QA systems as well.
Most of the research in this area has been focused on En-
glish. For Portuguese, the ﬁeld of QA is expanding and the
systems that have been developed still have much room for
improvement. To the best of our knowledge, there is no
resource like CINTIL-QATreebank for Portuguese, which
combines syntactically annotated sentences with a variety
of information that is speciﬁc for QA tasks.

2. Corpus construction and annotation

CINTIL-QATreebank is built over CINTIL-Treebank, a
corpus composed of sentences from newspaper texts an-
notated with their syntactic constituency trees, further en-
riched with information on grammatical functions and se-

mantic role labels (Branco et al., 2010; Gonc¸alves and
Branco, 2009).
The CINTIL-Treebank annotation is performed by experts
in Linguistics according to the mainstream method of an-
notation that is deemed to ensure a more reliable outcome:
double-blind annotation followed by adjudication.
The annotation work is supported, and its quality and con-
sistency is ensured, by resorting to a computational gram-
mar. Each sentence is automatically analyzed by LX-
Gram (Branco and Costa, 2008), an advanced grammar for
the deep linguistic processing of Portuguese. Once a parse
forest is obtained for a given sentence, independent anno-
tators choose the analysis that each consider to be correct.
In case of divergence between annotators, an adjudicator
makes the ﬁnal decision.
Constituency trees hold the usual relations between syntac-
tic constituents by following a basic X-bar scheme. The
complete guidelines for CINTIL-Treebank annotation can
be found in (Branco et al., 2011).

Sentence selection: The ﬁrst step is the selection of those
declarative sentences that will to be transformed into their
interrogative/imperative counterparts. This selection is
guided by the following criteria:

• Sentence length: Short sentences were discarded. This
is an attempt to remove trivial sentences from the tree-
bank, leaving in only those sentences that display in-
teresting syntactic structure.

• Avoid repetition: In order to obtain a balanced repre-
sentation of the various types of question, we did not
convert several sentences that have syntactic structures
which are already well represented in the treebank.

As a result, we obtained 85 declarative sentences that carry
through to the tree transformation step.

1895

Tree transformation: The second step is the manual
transformation of the declarative sentences into their non-
declarative counterparts. The same design options for
the syntactic representation of the sentences adopted for
CINTIL-Treebank were thus also adopted here for the new
CINTIL-QATreebank. To account for both European and
Brazilian variants of Portuguese, in cases where differ-
ent syntactic options are possible, the non-declarative sen-
tences generated are marked with respect to which variant
they conform to.
In many cases, a single declarative sentence can lead to sev-
eral interrogative sentences. This happens due to two main
reasons: (i) by differences in the language variants for the
same type of non-declarative; but also (ii) by the fact that
it is possible to apply more than one transformation to a
declarative in order to obtain a non-declarative, for exam-
ple:
Original sentence in CINTIL-Treebank:

Washington acompanhou os movimentos de Saddam desde
a primeira hora.
“Washington followed the movements of Saddam since the
beginning.”

New sentences in CINTIL-QATreebank:

QUEM acompanhou os movimentos de Saddam desde a
primeira hora?
“Who followed the movements of Saddam since the
beginning ?”
QUANDO ´e que Washington acompanhou os movimentos
de Saddam?
“When did Washington follow the movements of Sad-
dam?”
Washington acompanhou os movimentos de Saddam,
QUANDO?
“Washington followed the movements of Saddam, when?”

The various transformations applied to the declarative sen-
tences are the following:

A. By just adding an interrogative pronoun to the declar-

ative sentence and a question mark:

Original sentence:
Negociac¸ ˜oes falham em Jerusal´em.
“Negotiations fail in Jerusalem.”
New sentence:
QUE negociac¸ ˜oes falham em Jerusal´em?
“WHICH negotiations fail in Jerusalem?”

S

NP-SJ-ARG1

VP

N

V

PP-M-M

Negociac¸ ˜oes

falham

P

NP-C

em

N

Jerusal´em

⇓

CP

CP

NP-SJ-ARG1

S

PNT

?

INT

NP-SJ-ARG1

VP

Que

N

V

PP-M-M

Negociac¸ ˜oes

falham

P

NP-C

em

N

Jerusal´em

Figure 1: Transformation (A)

B. By adding the interrogative pronoun together with ´e
que (by adding only the interrogative pronoun we get
a question in the Brazilian Portuguese variant).
New sentences:
COMO ´e que as negociac¸ ˜oes falham em Jerusal´em?
“HOW do negotiations fail in Jerusalem?”
PORQUE ´e que as negociac¸ ˜oes falham em Jerusal´em?
“WHY do negotiations fail in Jerusalem?”

CP

CP

NP-SJ-ARG1

S

ADV-M

NP-SJ-ARG1

VP

PNT

?

Como

N

V

PP-M-M

Negociac¸ ˜oes

falham

P

NP-C

em

N

Jerusal´em

Figure 2: Transformation (B)

Note that the interrogative pronoun does not necessar-
ily need to be at the beginning of the sentence:
Original sentence:
O conselho emitiu 17 pareceres.
“The board has issued 17 opinions.”
New sentence:
O conselho emitiu QUANTOS pareceres?
“The board has issued HOW MANY opinions?”

C. By replacing a phrase with an interrogative pronoun,
which creates “echo-interrogatives”. Note that “echo-
interrogatives” are different from regular interroga-
tives by their declarative syntax and rising intona-
tion:
the speaker echoes an attributed utterance and
expresses a questioning attitude to some aspect of

1896

its form or its content. The function of an “echo-
interrogative” is thus rather exclamatory or requiring
(in that it demands a repetition or clariﬁcation) than
interrogative:

Original sentence:
F´abrica de tintas centen´aria ardeu em Vila Nova de
Gaia.
“Centennial ink factory burned in Vila Nova de Gaia.”
New sentence:
F´abrica de tintas centen´aria ardeu ONDE?
“Centennial ink factory burned WHERE?”

But also by replacing a phrase with an interrogative
pronoun and displacing it to the left periphery of the
sentence:
New sentence:
ONDE ardeu a f´abrica de tintas centen´aria?
“WHERE did the centennial ink factory burn?”

New sentence:
Gulbenkian n˜ao suspendeu ﬁnanciamento?
“Did not Gulbenkian suspend ﬁnancing?”

S

NP-SJ-ARG1

VP

N

V’

NP-DO-ARG2

Gulbenkian

ADV-M-ADV

V

N

n˜ao

suspendeu

ﬁnanciamento

⇓

S

S

NP-SJ-ARG1

VP

PNT

?

S

N

V’

NP-DO-ARG2

NP-SJ-ARG1

VP

Gulbenkian

ADV-M-ADV

V

ART-SP o

N

N’

V

PP-M-LOC

n˜ao

suspendeu

ﬁnanciamento

N’

A-M-PRED

ardeu

P

NP-C

Figure 4: Transformation (D)

N

PP-OBL-ARG1

centen´aria

em

N’

F´abrica

P

NP-C

N

N

N

N

de

N

Vila

Nova

de

Gaia

tintas

⇓

S

CP

CP

PNT

ADV-M

?

NP-SJ-ARG1

VP

onde

N’

V

ADV-M

N’

A-M-PRED

ardeu

*GAP*

N

PP-OBL-ARG1

centen´aria

F´abrica

P

NP-C

de

N

tintas

Figure 3: Transformation (C)

D. By just changing the ﬁnal punctuation mark of the sen-
tence to a question mark, generating, as a result, total
interrogatives, which require an afﬁrmative or nega-
tive answer:
Original sentence:
Gulbenkian n˜ao suspendeu ﬁnanciamento.
“Gulbenkian did not suspend ﬁnancing.”

E. By adding a command verb in the imperative mood,
and changing the clause type, from declarative to im-
perative:
Original sentence:
Este investimento ´e superior ao efectuado pela APDL
nos ´ultimos vinte anos.
“This investment is higher than the one made by
APDL in the last twenty years.”
New sentence:
INDIQUE um investimento superior ao efectuado pela
APDL nos ´ultimos vinte anos.
“NAME one investment higher than the one made by
APDL in the last twenty years.”

Note that all transformations were performed manually by
experts in Linguistics, holding a BA degree.
The sentences were manipulated in their labeled bracket
notation. To visualize the outcome of this transformation
in terms of diagrammatic display as trees, and also to con-
ﬁrm and validate it, we used the PhpSyntaxTree tool1. This
is a web application that creates syntax tree graphs from
phrases entered manually in labeled bracket notation.

QA-speciﬁc annotation: The third and last step in the
creation of CINTIL-QATreebank is where the QA-speciﬁc
information is added to each parse tree. This information
consists of:

• the sentence type: indicates whether the sentence is a
partial interrogative, a total interrogative, or a question
in the form of an imperative clause.

• the interrogative pronoun:

information, which only
applies to partial interrogatives, indicates what is the
main interrogative pronoun of the sentence.

1http://ironcreek.net/phpsyntaxtree/

1897

S

NP-SJ-ARG1

VP

DEM-SP

N

V

AP-PRD

Este

investimento

´e

A

PP-OBL-ARG2

superior

P

NP-C

a

ART-SP

N’

o

N

AP-M-PRED

*ELLIPSIS*

AP

PP-M-TMP

V

PP-OBL-ARG1

P

NP-C

efectuado

P

NP-C

em

ART-SP

N’

por

ART-SP

N

os

ORD-M-PRED

N’

a

APDL

´ultimos

CARD-SP

N

⇓

vinte

anos

S

NP-SJ-ARG1

VP

*NULL*

V

NP-DO-ARG2

Indique

ART-SP

N’

um

N

AP-PRD

investimento

A

PP-OBL-ARG2

superior

P

NP-C

a

ART-SP

N’

o

N

AP-M-PRED

*ELLIPSIS*

AP

PP-M-TMP

V

PP-OBL-ARG1

P

NP-C

efectuado

P

NP-C

em

ART-SP

N’

por

ART-SP

N

os

ORD-M-PRED

N’

a

APDL

´ultimos

CARD-SP

N

vinte

anos

Figure 5: Transformation (E)

• the question type:

factual, deﬁnition, yes/no, why-

question

• the expected answer type: states what is the semantic

type we expect for the answer to the question.

Additional details on this QA-speciﬁc information are
given in the Sections 3 and 4.

3. Treebank composition: grammatical

types of questions

Our corpus includes two clause types: on the one hand in-
terrogative clauses, used in asking questions, and on the
other hand imperative clauses, used in issuing orders or di-
rectives.

Grammatically, interrogative clauses can be of two distinct
types: total interrogatives, which typically elicit a conﬁr-
mation or a denial, and partial interrogatives, which typ-
ically elicit open-ended responses. The latter rely on the
introduction of some interrogative pronoun or wh-word.
Total interrogatives can be subdivided into three types:

• afﬁrmative: Negociac¸ ˜oes falham em Jersusal´em? “Do

negotiations fail in Jerusalem?”

• negative: A It´alia n˜ao se apurou para os quartos-ﬁnais
do Europeu? “Didn’t Italy make it to the EURO quar-
terﬁnals?”

• alternative:

A prova pode ser feita com uma
declarac¸ ˜ao da embaixada respectiva ou um atestado

1898

de residˆencia? “Can the exam be done with a dec-
laration form from his embassy or with a residence
certiﬁcate?”.

• Location: ONDE ser´a realizada a eliminat´oria entre
franceses e italianos? “WHERE will the ﬁnal round
between French and Italian be?”;

Partial interrogatives, in turn, may be more complex. Just as
a ﬁrst example, consider the pronoun Que (“What/Which”).
It differs from the rest of the wh- interrogative pronouns
in as much as it may give raise to two different types of
questions: Que (“What”) and Que N (“Which”).
imperative
Finally, despite not being questions per se,
clauses are commonly used in QA systems. The most re-
current verbs used are the following: “mention”, “say”,
“quote”, “indicate”, “name”, “argue”, “discuss”, “demon-
strate”, “determine”, “specify”, “explain”, “consider”, “dis-
close”, “report”, “check”, among others.
Table 1 shows the corpus composition according to the
number of clause and question types:

Clause types
Total
Interrogatives Negative

Question types
Afﬁrmative

• Organization: QUE banco reduz taxa de intervenc¸ ˜ao?
“WHICH bank is reducing the intervention fee?”;

• Explanation: PORQUE ´e que Itamar critica o Gov-
“WHY is Itamar criticizing the

erno brasileiro?
Brazilian Government?”;

• Yes/No: A moeda ´e o espelho da economia? “Is cur-

rency the mirror of the economy?”;

• Miscellaneous (on every occasion none of the above
types ﬁt in): COMO a Prac¸a Lu´ıs Cam˜oes ser´a
embelezada? “HOW will Lu´ıs Cam˜oes Square be
adorned?”.

Table 2 provides an overview of the composition of the cor-
pus in terms of the semantic types of answers expected for
the sentences contained in it:

Partial
Interrogatives Quanto

Alternative
Que N (Which)
Quem (Who)
Onde (Where)
Qual (Which)

How much/many
Quando (When)
Como (How)
O que (What)
Porque (Why)

Answer types Qty
Yes/No
Yes/No
Yes/No
Factual
Factual
Factual
Factual
Factual

8
4
1
17
8
6
7
9

Factual
Factual
Deﬁnition
whyQuestion
Factual

18
9
11
11
2
111

Semantic Answer types Qty
Person
Temporal
Number
Location
Organization
Explanation
Yes/No
Miscellaneous

8
18
9
8
7
11
13
37

Imperatives
Total

Table 2: Distribution of the types of answers for the sen-
tences in the corpus.

Table 1: Distribution of the grammatical types of sentences
in the corpus.

4. Annotation with semantic types of

expected answers

On a par with constituency trees, our corpus includes fur-
ther relevant information for developing the area of QA sys-
tems.
Questions of a given grammatical type may elicit answers
of a range of different semantic types. It is important to
annotate the sentences in the corpus with such information.
When the expected answer is factual, the questions are an-
notated with a label indicating the semantic type of the ex-
pected answer.
The answer types are organized along the following seman-
tic categories:

• Person: QUEM revelou a not´ıcia num debate real-
izado em Alij´o? “WHO exposed the news in a debate
which took place in Alij´o?”;

• Time: QUANDO ´e que Monge toma posse? “WHEN

does Monge come into ofﬁce?”;

• Number: QUANTOS anos ´e que a PSP festeja? “HOW

MANY years is PSP celebrating?”;

5. CINTIL-QATreebank format
The format of a CINTIL-QATreebank uses XML (eXten-
sible Markup Language). XML is used to store different
levels of linguistic annotation, for example, information on
constituency and grammatical function and any extra infor-
mation that the corpus has.
The adopted XML format was XCES2. The goal is to pro-
vide a fully-speciﬁed web-based format that enables max-
imal inter-operability not only among annotations of the
same phenomena, but across annotation types.
The aim to provide an environment in which annotations
can be easily deﬁned and validated. In summary, the XCES
serves as an interface between different types of annota-
tions. Figure 6 shows an excerpt of CINTIL-QATreebank
XML format. The XCES ﬁle has several levels of annota-
tion and extra information. We present below the levels of
annotation:

• struct type: information about sentence type: partial,

total or imperative.

• id: internal identiﬁer of CINTIL-QATreebank.

2http://www.xces.org/

1899

• source: identify the source of information, in this case

CINTIL-Treebank.

• sourceId: identiﬁer in the source of information.

• originalSentence:

original sentence in CINTIL-

• originalTree:

original constituency tree in the

Treebank.

CINTIL-Treebank.

QATreebank.

• sentence:

sentence modiﬁed

for CINTIL-

• tree: constituency tree of interrogative sentence.

• interrogativePronoum:

interrogative pronoun of the
sentence, if the sentence does not have a pronoun is
marked as none.

• questionType: question type can assume the values:

Factual, Deﬁnition, WhyQuestion e Yes/No.

• answerType: answer type, can assume the values: Per-
son, Date, Number, Localization, Organization, Ex-
planation, Yes/No e Miscellaneous.

• answer: the answer of the interrogative sentence.

• variant: language variant (European and Brazilian)

<cesAna>
<struct type="partialInterrogative">
<feat name="id" value="s1"/>
<feat name="source" value="CINTIL-Treebank"/>
<feat name="sourceId" value="b104"/>
<feat name="originalSentence" value="Washington acompanhou os movimentos

<feat name="originalTree" value="[S [S [NP-SJ-ARG1 [N Washington]]

de Saddam desde a primeira hora."/>

[VP [VP [V acompanhou] [NP-DO-ARG2 [ART-SP os] [N’
[N movimentos] [PP-OBL-ARG1 [P de] [NP-C [N Saddam]]]]]]
[PP-M-TMP [P desde] [NP-C [ART-SP a] [N’ [ORD-M-PRED "/>

<feat name="sentence" value="Quem acompanhou os movimentos de Saddam

desde a primeira hora?"/>

<feat name="tree" value="[CP [CP [NP-SJ-ARG1_1 [INT Quem]]

[S [NP-SJ-ARG1_1 *GAP*] [VP [VP [V acompanhou]
[NP-DO-ARG2 [ART-SP os] [N’ [N movimentos] [PP-OBL-ARG1
[P de] [NP-C [N Saddam]]]]]] [PP-M-TMP [P desde] [NP-C
[ART-SP a] [N’ [ORD-M-PRED primeira] [N hora]]]]]]] [PNT ?]]"/>

<feat name="interrogativePronoum" value="Quem"/>
<feat name="questionType" value="Factual"/>
<feat name="answerType" value="Person"/>
<feat name="answer" value="Washington"/>
<feat name="variant" value="Brazilian"/>
</struct>
</cesAna>

Figure 6: An excerpt of the CINTIL-QATreebank format

6. CINTIL-QATreebank in use
In order to test an application of CINTIL-QATreebank,
we performed an experiment in which a statistical parser
was trained over the treebank. We chose the Stanford
Parser (Klein and Manning, 2003), which we had previ-
ously used to create LX-Parser, a parser for Portuguese that
achieved state-of-the-art performance scores (Silva et al.,
2010). The goal of this experiment it to assess to what ex-
tent the performance of the parser over interrogative sen-
tences improves when interrogative sentences are added to
the training data.
For this experiment, we set aside 10% of the sentences in
CINTIL-QATreebank for testing, and added the remain-
ing sentences to CINTIL-Treebank (version 3 with 5422
declarative sentences) in order to form the training corpus.

The results obtained in this experiment were unsatisfactory,
reaching a F-measure score of 66% for bracketing correct-
ness (with and without the interrogative sentences in the
training data), although some improvement was achieved
in tagging accuracy.
An analysis of the results shows that adding CINTIL-
QATreebank to training data does not have a measurable
impact on the performance of a statistical parser. The rea-
son for this is twofold. On the one hand, when building
CINTIL-QATreebank, we tried to create a linguistically in-
teresting dataset (e.g. long sentences with complex struc-
tures), which raise data-sparseness issues; one the other
hand, the dataset is still rather small, having only 111 sen-
tences, which further intensiﬁes those issues.

7. Concluding remarks

In this paper we present CINTIL-QATreebank, a treebank
composed of sentences from Portuguese that can be used to
support the development of Question Answering systems.
This treebank was obtained by manually transforming the
syntactic representation of declarative sentences in an exist-
ing treebank into their interrogative and imperative counter-
parts. We described the methodology used in these trans-
formations as well as the composition of the corpus, in
terms of domain, size and distribution of sentences. We
also describe the several layers of annotation in CINTIL-
QATreebank, which combine syntactically annotated sen-
tences with a variety of information that is speciﬁc to QA
tasks. The annotation contains: trees with information on
constituency and grammatical function, sentence type, in-
terrogative pronoun, question type, and semantic type of
expected answer.
On a par with the construction of the treebank, we per-
formed an experiment where a statistical parser was trained.
The results obtained were unsatisfactory even though some
improvement was achieved in terms of tagging accuracy.
This experiment will be repetead with a larger version of
the treebank that is under construction.
We present the CINTIL-QATreebank XML format. This
format is portable, being easily handled by both humans
and automatic processing, and allows inter-operability
among different levels of information. This format is also
easily extensible, allowing for new layers of linguistic an-
notation that may be incorporated in the future.
The description provided in this paper corresponds to the
current status of the corpus. While the goals and the
methodological approach are deﬁned and the technical
foundations are set up, the development work will now con-
tinue and the corpus will keep on being extended by the in-
clusion of more sentences. The ﬁnal goal is to use the whole
of CINTIL-Treebank to build a new version of CINTIL-
QATreebank. We estimate that the ﬁnal version may have
around 5,000 sentences.
In addition, we are developing a tool to automatically trans-
form the trees of declarative sentences.
In the future we
will train the statistical parser with the complete CINTIL-
QATreebank. This parser will be used to annotate other
interrogative sentences which may be used as a method for
automatic, or semi-automatic, extension of the treebank.

1900

8. References
Ant´onio Branco and Francisco Costa. 2008. Lxgram in
the shared task ”comparing semantic representations” of
step 2008. In Proceedings of the 2008 Conference on Se-
mantics in Text Processing, STEP ’08, pages 299–310,
Stroudsburg, PA, USA. Association for Computational
Linguistics.

Ant´onio Branco, Francisco Costa, Jo˜ao Silva, Sara Sil-
veira, S´ergio Castro, Mariana Avel˜as, Clara Pinto, and
Jo˜ao Grac¸a. 2010. Developing a deep linguistic data-
bank supporting a collection of treebanks:
the cin-
til deepgrambank.
In Nicoletta Calzolari (Conference
Chair), Khalid Choukri, Bente Maegaard, Joseph Mar-
iani, Jan Odijk, Stelios Piperidis, Mike Rosner, and
Daniel Tapias, editors, Proceedings of the Seventh Inter-
national Conference on Language Resources and Eval-
uation (LREC’10), Valletta, Malta, may. European Lan-
guage Resources Association (ELRA).

Ant´onio Branco, Jo˜ao Silva, Francisco Costa, and S´ergio
Castro. 2011. Cintil treebank handbook: Design op-
tions for the representation of syntactic constituency. TR
2011-02, University of Lisbon, Faculty of Sciences, De-
partment of Informatics, Lisbon.

Patricia Gonc¸alves and Ant´onio Branco, 2009. Buscador
Online do CINTIL-Treebank. XXV Encontro Nacional
da Associac¸ ˜ao Portuguesa de Lingu´ıstica (APL), Lisbon,
Portugal.

Dan Klein and Christopher D. Manning. 2003. Fast ex-
act inference with a factored model for natural language
parsing. In Advances in Neural Information Processing
Systems, volume 15. MIT Press.

Marius Pas¸ca. 2003. Open-Domain Question Answering
from Large Text Collections. CSLI Studies in Computa-
tional Linguistics. CSLI.

Jo˜ao Silva, Ant´onio Branco, and Patricia Gonc¸alves.
2010. Top-performing robust constituency parsing of
portuguese: Freely available in as many ways as you
In Nicoletta Calzolari (Conference Chair),
can get it.
Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan
Odijk, Stelios Piperidis, Mike Rosner, and Daniel
Tapias, editors, Proceedings of the Seventh Interna-
tional Conference on Language Resources and Evalu-
ation (LREC’10), Valletta, Malta, may. European Lan-
guage Resources Association (ELRA).

1901

