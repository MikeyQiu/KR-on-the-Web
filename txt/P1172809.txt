6
1
0
2
 
g
u
A
 
6
1
 
 
]

C
O
.
h
t
a
m

[
 
 
1
v
4
4
5
4
0
.
8
0
6
1
:
v
i
X
r
a

Free Lunch for Optimisation under the Universal Distribution

Tom Everitt1, Tor Lattimore2, and Marcus Hutter3

1Stockholm University, Sweden. Email: everitt@math.su.se
2University of Alberta, Edmonton, Canada
3Australian National University, Canberra, Australia

Abstract

Function optimisation is a major challenge in com-
puter science. The No Free Lunch theorems state
that if all functions with the same histogram are
assumed to be equally probable then no algorithm
outperforms any other in expectation. We argue
against the uniform assumption and suggest a uni-
versal prior exists for which there is a free lunch, but
where no particular class of functions is favoured
over another. We also prove upper and lower
bounds on the size of the free lunch.

Keywords: No Free Lunch; Black-box Optimisa-
tion; Universal Distribution; Solomonoﬀ induction;
Kolmogorov complexity

1

Introduction

Finite black-box optimisation is the problem of ﬁnd-
ing an optimal value (usually the maximum or mini-
mum) of a target function f : X → Y where X and
Y are ﬁnite. A wide range of tasks may be formu-
lated in this setting. For instance, drug-design may
be viewed as the task of ﬁnding a mix of chemicals
that maximises recovery chances. Since experimen-
tation is expensive it is crucial that the best drug
be found as soon as possible.

It is desirable to ﬁnd optimisation algorithms
that perform well on a wide variety of target func-
tions, as this minimises the need for ﬁne-tuning the
algorithm to the problem. Indeed, several such algo-
rithms exist and are regularly employed in practice;
examples include hill-climbing and simulated an-
nealing, as well as genetic algorithms. However, the
theoretical understanding of the conditions permit-
ting such “universal” algorithms remains limited
[CO01, Str03, WR06, JC11]. To approach this prob-
lem, we derive bounds for expected optimisation-
performance under assumptions justiﬁed in all (or
virtually all) optimisation settings.

The original No Free Lunch (NFL) theorems
state that when the global performance of an op-
timisation algorithm is measured by taking a uni-
form average of its performance over all functions
from X to Y , then no algorithm is better than ran-
dom (assuming no point is sampled more than once)
[WM97]. The uniform assumption is justiﬁed by
assuming the absence of prior knowledge and the
results are often used to claim that no optimisation
algorithm can be universal.

There is, however, another viewpoint. If we as-
sume that the function f : X → Y to be optimised
is generated by some (unknown) computer program,
then taking a uniform prior over programs is ar-
guably more natural. This is a reasonable assump-
tion based on the commonly held view that the
universe is likely to be (stochastically) computable
[Fre92, Wol02, Hut12]. The distribution on func-
tions induced by this approach is the famous uni-
versal lower-semicomputable semi-distribution1 de-
veloped by Solomonoﬀ and others [LV08]. The uni-
versal distribution satisﬁes many nice properties,
both theoretical and philosophical. It is a natural
choice when formalising Occam’s razor in combi-
nation with Epicurus’ principle of multiple expla-
nations since it favours simplicity over complexity
without disregarding the possibility that the truth
is complex [Hut05, RH11]. The universal distribu-
tion also exhibits a range of other desirable proper-
ties, discussed further in Section 3.

If performance is measured in expectation with
respect to the universal distribution, then the no
free lunch theorems can no longer be applied.
Indeed, under some highly technical conditions
Streeter [Str03] showed that there is a free lunch
for optimisation under Solomonoﬀ’s universal dis-
tribution. Tightly related to the universal distri-
bution is Kolmogorov complexity: Borenstein and

1 The use of lower semicomputable semi-distributions
rather than regular computable distributions is technical
only and may be ignored by the reader unfamiliar with algo-
rithmic information theory.

Published as: pp. 167–174, in Proceedings of 2014 IEEE Congress on Evolutionary Computation (CEC), July 6-11, 2014,
Beijing, China. DOI: 10.1109/CEC.2014.6900546 c(cid:13)2014 IEEE

Poli [BP06] discuss Kolmogorov complexity and op-
timisation, and also give a good account of previ-
ous research in this area (see also [McG06]). Sev-
eral authors report on Kolmogorov complexity not
being perfectly related to searchability [SVW01,
DJW02, BP06], but except for [Str03], implications
for search performance under the universal distri-
bution have not been investigated. The relation be-
tween the universal distribution and the NFL the-
orems for supervised learning has been studied by
Lattimore and Hutter [LH11]. In sequence predic-
tion and reinforcement learning, the universal dis-
tribution has been extensively researched [Hut05].
We ﬁrst improve on [Str03] by presenting the
ﬁrst easily interpretable theorem that there is a
free lunch if performance is measured in expecta-
tion with respect to Solomonoﬀ’s universal distribu-
tion rather than the uniform distribution originally
used by Wolpert and Macready (Section 6). Unfor-
tunately the size of the free lunch turns out to be
somewhat limited. Under only weak assumptions
we show that no computable algorithm can perform
much better than random, even when performance
is averaged with respect to the universal distribu-
tion (Section 7). This result is then extended to
arbitrary (possibly non-computable) optimisation
algorithms for a commonly used performance mea-
sure.

2 Preliminaries

A (ﬁnite binary) string is a ﬁnite sequence x =
b1b2 · · · bn with bi ∈ B = {0, 1} and length ℓ(x) = n.
The set of all ﬁnite binary strings is denoted by
B∗. Strings may be concatenated in the obvious
way. Power notation is used to represent multiple
concatenations: for example, 0140 = 011110.

A problem context is a pair X, Y of ﬁnite subsets
of B∗, both containing at least 0 and 1 (to avoid
degenerate cases). In a problem context X, Y , the
search space is X and the range is Y . We let X
and Y be the sets of all search spaces and all ranges
respectively.

Deﬁnition 1. An optimisation problem is a collec-
tion P = { PXY }, where PXY is a measure over the
ﬁnite set Y X = { f : X → Y } of functions from X
to Y .

A search trace Tn on X, Y is an ordered n-tuple
h(x1, y1), . . . , (xn, yn)i ∈ (X × Y )n, representing a
search history. The empty search trace will be de-
noted hi. Let Tn(X, Y ) be the set of all search traces
|X|
of length n, and let T (X, Y ) := S
i=0 Ti(X, Y )
let
be the set of traces of any length. Further,
T := SX,Y ∈X ×Y T (X, Y ) be the set of search traces

on any context.
then T x

If Tn = h(x1, y1), . . . , (xn, yn)i,

n := hx1, . . . , xni and T y

n := hy1, . . . , yni.

An optimiser is a function a : X × Y × T → X
where a(X, Y, T ) ∈ X − T x for all (X, Y, T ). The
optimiser selects new, unvisited search points in the
search space based on previously seen data and the
problem context. That the optimiser is only per-
mitted to sample unvisited points is standard in
the literature, and non-restrictive in the noise-free
setting considered in this paper.

The setup is this: A problem context X, Y is
ﬁxed, and a target function f : X → Y is sam-
pled from Y X according to the problem distribution
PXY . The optimiser is initialised with the empty
search trace and the problem context, and outputs
a search point x1 ∈ X by a(X, Y, hi) = x1. The
search trace becomes hx1, f (x1)i. The new search
trace is fed to the optimiser, which produces a new
search point x2 via a(X, Y, h(x1, f (x1))i), and so
on. Observe that the search trace is a function of
the optimiser, the problem context and the sam-
pled function f . We write TXY (a, f ) for the “full”
trace of length |X| that a generates on f and X, Y ;
when X, Y is clear from the context, T (a, f ) will suf-
ﬁce. The Y -components T y
XY (a, f ) will be called
the result vector of a on f and X, Y . We will
also use R to denote result vectors. Let R(X, Y )
be the set of all result vectors on X,Y , and let
R = SX,Y ∈X ×Y R(X, Y ).

The performance of an optimiser a on a problem
P is measured in terms of the result vectors it pro-
duces. A function M : X × Y × R → [0, ∞) deﬁnes
a performance measure by the P-expected value of
M for a on each problem context X,Y :

M P

XY (a) := X
f ∈Y X

PXY (f )MXY (T y(a, f ))

(1)

We use JsK for the Iverson bracket that is 1 when
s is true, and 0 otherwise. For any list R, R[i]
extracts its ith element.

3 The universal distribution

We now give a short introduction to Kolmogorov
complexity and the universal distribution. Detailed
references are [LV08] and [Cal02].

Preﬁx codes are central elements in algorithmic
information theory. A preﬁx code is a set of code
words (formally, strings) where no code word is a
preﬁx of another. This makes preﬁx codes uniquely
decodable:
in a sequence of appended code words
it is possible to tell where one code word ends an-
other begins. Kraft’s inequality gives a lower bound
on the length of the code words in a preﬁx code
[LV08, p. 76]. Deﬁnition 2 gives some commonly

2

used preﬁx encodings of strings, numbers, lists and
functions.

Deﬁnition 2 (String encodings). Let x be a binary
string, n a natural number and Z = z1, . . . , zn a
list of strings. Then ¯x := 1ℓ(x)0x, ¯n := 1n0 and
¯Z := ¯n¯z1 · · · ¯zn deﬁnes preﬁx codes for x, n and Z.
The code for lists may be applied recursively to lists
of lists. Target functions f : X → Y are encoded
by lists f (x1), . . . , f (xn) where x1, . . . , xn are the
elements of X in order.

For technical reasons, regular Turing machines
are not suitable for deﬁning the universal distribu-
tion, so preﬁx machines are often used instead.

Deﬁnition 3 (Preﬁx Machines). A preﬁx machine
V is a Turing machine with one unidirectional in-
put tape, one unidirectional output tape, and some
bidirectional work tapes. Input tapes are read only,
output tapes are write only. All tapes are binary
and work tapes are initialised with zeros. We say
V halts with output x on input p given s and write
V (p|s) = x, if ¯sp is to the left of the input head and
x is to the left of the output head when V halts. For
any s ∈ B∗, the inputs on which V (·|s) halts form
a preﬁx code. Also, just as for regular Turing ma-
chines, there are universal preﬁx machines that can
simulate any other preﬁx machine.

Deﬁnition 4 (Preﬁx Complexity). Let x, y ∈ B∗
be ﬁnite binary strings and U a universal preﬁx
machine, then the Kolmogorov complexity of x con-
ditioned on y is the length of the shortest program
that given y outputs x.

KU (x|y) := min{ ℓ(p) : U (p|y) = x }

(2)

A simple but fundamental theorem is that KU de-
pends on U only up to constant factors, so from
now on, as is usual in algorithmic information the-
ory, we ﬁx an arbitrary universal preﬁx machine
as a reference machine and simply write K(x) for
KU (x).

Deﬁnition 5 (Function complexity). Let f : X →
Y , then the complexity of f is K(f |X, Y ), with f
and X, Y encoded by strings according to Deﬁni-
tion 2.

The Martin-L¨of–Chaitin Thesis states that ran-
domness may be deﬁned as
incompressibility
[GTW+11, p. 705]. A target function is incom-
pressible or random if K(f |X, Y ) ≥ |X| log |Y |. A
classical result in algorithmic information theory
shows that almost all functions are (nearly) ran-
dom. Thus, the uniform distribution puts the ma-
jority of its weight on random functions, which is

one explanation for why it is hard to optimise un-
der the uniform distribution. In contrast, the uni-
versal distribution puts more weight on “simple”,
non-random functions:

Deﬁnition 6 (Universal distribution). For each
context X, Y , the universal distribution is deﬁned
as

mXY (f ) := cmXY · 2−K(f |X,Y ),

(3)

where cmXY = 1/ Pf : X→Y 2−K(f |X,Y ) is just a
normalising constant.
In the literature, unnor-
malised versions of m are often considered. Al-
though cmXY may ﬂuctuate with X, Y , there is a
constant cm depending only on the reference ma-
chine such that 1 ≤ cmXY ≤ cm for all X, Y . Note
that m is an optimisation problem, since mXY is a
distribution over Y X for each X, Y .

Somewhat surprisingly, there is an equivalent def-
inition of m as the distribution obtained by feeding
random coin-ﬂips into a universal preﬁx machine
with access to X, Y .

mXY (f ) ≈ X
p∈B∗

2−ℓ(p)JV (p|X, Y ) = f K.

(4)

The approximation holds up to irrelevant multi-
plicative factors, so (4) is often used in place of
(3) as the deﬁnition of the universal distribution.2
Feeding a universal preﬁx-machine random coin-
ﬂips is a natural formalisation of the uniform prior
over computer programs advocated in the introduc-
tion. Thus m may be justiﬁed as a subjective prior
for the assumption that the target function has
been computably generated.3

The bias away from randomness also aligns with
our intuition of how functions “ought to be opti-
mised”. If the ﬁrst hundred observations are pre-
dicted by a simple polynomial, then common sense
(and Occam’s razor) suggests that the best predic-
tion of unseen points is that they follow the polyno-
mial. In general, the “simplest” structure perceiv-
able in the data should be the most likely extrapola-
tion. The universal distribution is consistent with
this intuition. A detailed discussion of the philo-
sophical justiﬁcation for the universal prior can be
found in [RH11].

To summarise, we have argued for the universal

distribution on the following grounds:

2Even the deﬁnition given in (3) depends on the choice

of reference machine up to multiplicative factors.

3 There are also “objective” grounds to prefer m as a
including regrouping invariance [Hut07] and domi-

prior,
nance [LV08]. Neither hold for the uniform distribution.

3

• (Weak assumptions): If the target function is
generated by a computer program, then a uni-
form prior over computer programs is justiﬁed.
Formalised as in (4), this yields the universal
distribution.

• (Downweighs randomness): A uniform prior
over target functions puts the (vast) major-
ity of the weight on (nearly) random func-
tions. The universal distribution concentrates
on structured functions, without favouring any
particular class of functions.

• (Aligns with Occam): Intuition and Occam’s
razor suggests that the best extrapolation is
the continuation of the “simplest” pattern ob-
servable in data, which corresponds well with
the relative probabilities of the universal distri-
bution.

Next we will present some background on the NFL
theorems and introduce our performance measure
Mot, before taking a closer look at optimisation un-
der m.

4 No Free Lunch

The NFL theorems provide important insights into
the possibility of universal optimisation. They show
that for certain distributions PXY all optimisers
perform identically with respect to some (or all)
performance measure(s). This is often phrased as
“there is no free lunch available for PXY ”. For ex-
ample, if NFL holds for a performance measure de-
pending on how many function evaluations are re-
quired to ﬁnd the maximum, then this implies that
in expectation a hill-climbing optimiser will ﬁnd the
maximum as slowly as a hill-descending optimiser.

XY (a) = M P

Deﬁnition 7 (Performance measure-NFL). NFL
holds for a distribution PXY and a performance
measure M if M P
XY (b) for all optimisers
a and b. If NFL holds for all performance measures
M , then NFL simply holds for PXY . If NFL does
not hold for PXY (and M ), then we say that there
is free lunch for PXY (and M ).

The stronger statement that NFL holds for all
performance measures may equivalently be deﬁned
in terms of result vectors. The proof of the equiva-
lence is a straightforward application of the deﬁni-
tions.

Lemma 8 (Result vector-NFL). Let PXY a(R) be
the probability Pf ∈Y X PXY (f )JT y(a, f ) = RK that
an optimiser a generates the result vector R, then
NFL holds for PXY if and only if PXY a(R) =
PXY b(R) for every pair of optimisers a and b and
every result vector R ∈ Y |X|.

4.1 The NFL theorems

Igel and Toussaint [IT04] showed that the precise
condition for NFL is block uniformity of PXY .

Deﬁnition 9 (Block uniformity). A histogram for
a function f is a function hf : Y → N deﬁned as
hf (y) = |f −1(y)|, indicating how many x’s map to
every y. The subset of all functions X → Y with
histogram h is called the base class of h, and is de-
noted Bh. The distribution PXY is block uniform if
for every h it holds that f, g ∈ Bh =⇒ PXY (f ) =
PXY (g).

Theorem 10 (Non-uniform NFL [IT04]). NFL
holds for PXY if and only if PXY is block uniform.

The original NFL theorem by Wolpert and
Macready [WM97] showed that NFL holds when
PXY is uniform on Y X . As uniform distributions
are a special case of block uniform distributions,
Wolpert and Macready’s result follows from Igel
and Toussaint’s.

Another special case is the NFL theorem for uni-
form optimisation problems over function classes
closed under permutation (c.u.p.) by Schumacher
et al.
[SVW01]. A permutation is a bijective
function σ : X → X that permutes functions via
(σf )(x) = f (σ−1(x)). A class F ⊆ Y X is c.u.p.
if f ∈ F =⇒ σf ∈ F for all permutations σ.
The uniform distribution uF over F is deﬁned by
uF (f ) := 1/|F | if f ∈ F and 0 otherwise.

Theorem 11 (NFL for c.u.p. classes [SVW01]). If
PXY is the uniform distribution over a class F ⊆
Y X , then NFL holds for PXY if and only if F is
c.u.p.

A simple consequence of the NFL theorems is
that all optimisers produce the same result vectors.
We state this as a lemma for future reference.

Lemma 12 ([SVW01]). The set of result vectors
{ R ∈ R(X, Y ) : T y(a, f ) = R for some f ∈ Y X }
ever produced by an optimiser a on X, Y is the same
for all optimisers.

The NFL theorems have also been investigated in
inﬁnite and continuous domains. Depending on the
generalisation, free lunches may or may not emerge
in those settings [AT07, RVW09].

5 Performance measures

So far we have only considered problems for which
either NFL holds for all performance measures, or
for which a free lunch is available for some perfor-
mance measures. Often, however, we are interested

4

in performing well under a ﬁxed performance mea-
sure of interest. One natural choice of performance
measure is optimisation time, which in this context
means the number of function evaluations required
to ﬁnd the maximum.4

Deﬁnition 13. The optimisation time perfor-
mance measure Mot is deﬁned as

optimiser. In contrast, under particular measures
such as Mot and Mmax, adaptive optimisers may dif-
fer in performance while all non-adaptive optimis-
ers perform the same. In this sense, “smarter” algo-
rithms may be required for exploiting a free lunch
when using a particular performance measure, com-
pared to when arbitrary performance measures are
permitted.

Mot,XY (R) := min

(R[i] = max Y ) ,

i

M P

ot,XY (a) := X
f ∈Y X

PXY (f )Mot,XY (T y(a, f ))

for result vectors and optimisers, respectively. Un-
der Mot a low score is better than a high score.

A variety of performance measures have been
considered in the literature. Some use properties
of the k ﬁrst function evaluations,
for example
the number of values exceeding a certain thresh-
old [CO01, WR06, JC11], or the probability that
some seen value exceed the threshold [WM97]. Grif-
ﬁths and Orponnen [GO05] use a performance mea-
sure Mmax depending on the size of the greatest
value of the ﬁrst k observations. Others, such as
[BP06, Jan13], use Mot. The main reason we pre-
fer Mot to the other alternatives is that it is better
suited for the asymptotic results we will aim for.

Results about particular performance measures
interest than their
often have greater practical
In addition, par-
arbitrary-measure counterparts.
ticular performance measures may also have theo-
retical interest. Under particular performance mea-
sures, NFL may hold for classes that are not c.u.p.
[GO05]. This does not contradict Theorem 11,
which only claims that for every non-c.u.p. class,
there is some performance measure permitting a
free lunch.
it is unsurprising that NFL
will apply to wider ranges of function classes when
a ﬁxed performance measure is used. The condi-
tions for NFL under Griﬃths and Orponnen’s per-
formance measure Mmax turn out to be signiﬁcantly
more intricate compared to the standard NFL case
[GO05].

Indeed,

Another diﬀerence is found in the “cleverness”
required to exploit a free lunch. Optimisers that
choose the next point to probe irrespective of previ-
ous observations are called non-adaptive; such op-
timisers can only exhibit a limited amount of so-
phistication. Proposition 14 shows that when a
free lunch is available and arbitrary measures are
allowed, then there is free lunch for a non-adaptive

4 In black-box optimisation in general, and evolutionary
algorithms in particular, the evaluation of the target func-
tion typically constitutes the main expense of computation
time. This is the motivation behind the name optimisation
time for the number of target function evaluations.

Proposition 14. If NFL does not hold for a dis-
tribution PXY , then there is free lunch for a non-
adaptive optimiser under some performance mea-
sure.

Proof. Since NFL does not hold for PXY we have by
Theorem 10 that PXY is not block uniform. Hence
there are two functions f and σf in the same base
class Bh such that PXY (f ) > PXY (σf ), where σ is
a permutation on X. Let e and eσ be non-adaptive
optimisers, with e searching X = { x1, . . . , xn } in
order, and eσ searching X in the order of σX =
{ σ(x1), . . . , σ(xn) }. Now e generates the result
vector Rf = hf (x1), . . . , f (xn)i exactly when f
is the true function, and eσ generates Rf exactly
when σf is the true function. An immediate conse-
quence is that PXY e(Rf ) = PXY (f ) > PXY (σf ) =
PXY eσ (Rf ). That is, the non-adaptive algorithms
e and eσ generate Rf with diﬀerent probability,
which means that there is free lunch for some non-
adaptive optimiser under some performance mea-
sure by Lemma 8.

In conclusion, speciﬁc performance measures can
be considered for both practical and theoretical rea-
sons. They are more practically relevant in the
sense that they measure aspects we care about in
practice (such as how long it takes to ﬁnd a max-
imum). But they also have theoretical interest,
as they expose aspects that are invisible from an
arbitrary-measure perspective.

6 Universal Free Lunch

We now turn to the question of whether or not a free
lunch is available under m, which we will answer
in the aﬃrmative for both arbitrary performance
measures and Mot.

The universal distribution solves the induction
problem for sequence prediction [Hut05, RH11].
Black-box optimisation also include an induction
problem in the extrapolation of target-function be-
haviour from the points already evaluated. Al-
though successful inference of the target-function
behaviour may not be strictly necessary, it will typ-
ically enable better choices of future search points.

5

f
g

1

0

0 1

· · ·

k−1 k k+1

· · ·

Figure 1: The function f has complexity bounded
by a constant cf independent of X and Y .
In
contrast, the complexity of g grows logarithmically
with |X|. See the proof of Theorem 15 for details.

There are several important diﬀerences between
sequence prediction and optimisation. First, opti-
misation is an active setting: the choices of the op-
timiser aﬀect both the learning outcome and the
reward. This entails an exploration/exploitation
tradeoﬀ in the choice between potentially informa-
tive points and points likely to mean high perfor-
mance (e.g. points likely to be a maximum). Fur-
ther, optimisation is a ﬁnite setting, which yields
less time to exploit a good model (compared to se-
quence prediction where inﬁnite sequences are con-
sidered). There are also major diﬀerences in the
hypothesis classes and in how performance is mea-
sured.

Section 7 presents a number of results bounding
the amount of free lunch under m. Perhaps surpris-
ingly, only a small amount of free lunch is available
under the universal distribution.

6.1 Free lunch under arbitrary per-

formance measures

Streeter [Str03] showed that there is free lunch for
m under certain technical conditions. We prove a
similar result, but with more interpretable condi-
tions (in terms of the size of X, only). We also use
a diﬀerent proof than Streeter.

Theorem 15 (Universal free lunch). There is free
lunch for the problem m for all problem contexts
with suﬃciently large search space (the required size
depending on the reference machine only).

Proof. It will be shown that mXY is not block uni-
form for problem contexts with suﬃciently large X,
which by Theorem 10 implies that NFL does not
hold.

Pick a problem context X,Y . Consider two func-
tions f and g in the base class Bh ⊆ Y X of functions
with one value 1 and the rest of the values 0. Let

6

f be 1 at x1 and let g be 1 at some point xk cho-
sen so that K(g | X, Y ) ≥ log2|X| − 1 (see Fig. 1).
To see that such a g exists, note that there are |X|
diﬀerent functions in Bh. As the halting programs
for the reference machine constitute a preﬁx code,
there can be at most |X|/2 halting programs of
length ≤ log2|X| − 1 by Kraft’s inequality. Thus
at least one of the Bh-functions must have a short-
est program longer than log2|X| − 1, and therefore
complexity K(g | X, Y ) ≥ log2|X| − 1. Meanwhile,
K(f | X, Y ) ≤ cf for some constant cf independent
of the problem context. So for search spaces with
log2(|X|)−1 > cf , this means that f will have lower
complexity than g, and thus that mXY will assign
diﬀerent probabilities to f and g. As f and g are
elements of the same base class, this shows that m
is not block uniform for search spaces greater than
2cf +1. By Theorem 10, this implies a free lunch for
m under some performance measure.

Indeed, m is not even close to block uniform for
large search spaces in the sense that the functions
of type f and g will receive substantially diﬀerent
weights. However, this does not necessarily imply
a big free lunch, as we shall see in Section 7.

6.2 Free lunch under Mot
As has been discussed, in practice we often care
about a particular performance measure such as
Mot.

Theorem 16. There is free lunch for the problem
m under the performance measure Mot for all prob-
lem contexts with suﬃciently large search space (the
required size depending on the reference machine
only).

The proof is similar to Theorem 15, but more
work is required to ensure a complexity diﬀerence
between two potential maximums, rather than be-
tween two speciﬁc functions. A full proof is in-
cluded in the Appendix.

7 Upper Bounds

Theorems 15 and 16 show that there is free lunch
under the universal distribution. This section will
bound the amount of free lunch available, and show
that it is only possible to outperform random search
by a constant factor. First we show that the per-
formance of computable optimisers deteriorates lin-
early with the worst-case scenario and the size of
the search space. This result applies to decidable
performance measures in general, and has a con-
crete interpretation for Mot, where it implies that

as the size of the domain is increased, a non-zero
fraction of the domain must be probed before a
maximum is found in expectation. This does not
contradict the free lunches above, as the required
fraction may diﬀer between optimisers.

We also consider possible ways to circumvent the
negative result described above by means of incom-
putable search procedures. A further negative re-
sult for Mot is obtained: It does not appear pos-
sible to ﬁnd the maximum with only o(|X|) target
function evaluations. That is, the expected number
of probes required to ﬁnd the maximum grows lin-
early with the size of the search space, but again,
the proportion may diﬀer substantially between op-
timisers.

7.1 Computable optimisers

To bound the amount of free lunch available for
computable optimisers, we will adapt a proof-
technique for showing that average-case complexity
is equal to the worst-case complexity under the uni-
versal distribution [LV08, Section 4.4]. Although no
formal theorem relies on it, we will think of greater
M -values as worse performance.

Lemma 17. A function fbad : X → Y is maxi-
mally bad for an optimiser a on the problem con-
text X,Y with respect to a performance measure
M if MXY (T y(a, fbad)) = maxR∈R(X,Y ) MXY (R).
There always exists a maximally bad function
fbad : X → Y for a with respect to M , regardless
of the performance measure M , the optimiser a and
the problem context X,Y .

Proof. By Lemma 12, all optimisers produce the
same result vectors, so it suﬃces to show that some
optimiser has a maximally bad function. The non-
adaptive optimiser e that searches X in order has
a maximally bad function. To see this, let Rbad be
a maximally bad result vector on X,Y , and let f
be the function satisfying f (xi) = Rbad[i] for all
xi ∈ X. Then e produces Rbad on f .

A performance measure M for which there is an
algorithm deciding whether MXY (R1) < MXY (R2)
for every X,Y and every pair of result vectors
R1, R2 ∈ R(X, Y ) is decidable. For any decid-
able performance measure M , it is possible to cre-
ate a procedure FindWorst(a, X, Y ) that given a
computable optimiser a (speciﬁed by some binary
string) and a context X, Y , returns a maximally
bad function fbad : X → Y for a. FindWorst is a
computable operation since a is computable and M
is decidable: FindWorst need only simulate a on
all possible functions in Y X , and output one that
yields a worst result vector. This shows that for

all decidable performance measures, all computable
optimisers a and all contexts X, Y , there is a max-
imally bad function fbad : X → Y for a with com-
plexity

K(fbad | X, Y ) ≤ ℓ(FindWorst) + ℓ(a) + c , (5)

where the c term depends only on the reference ma-
chine, and absorbs the cost for initialising Find-
Worst with a, X and Y . Pivotally, the bound
is independent of X, Y . This is the central obser-
vation behind the following theorem, which shows
that expected performance always deteriorates lin-
early with the worst-case scenario. The theorem’s
prime relevance is for performance measures whose
worst-case value grows with X.

Theorem 18 (Almost NFL for m). For every de-
cidable performance measure M and every com-
putable optimiser a there exists a constant ca > 0
such that for all X, Y

M

m
XY (a) ≥ ca max

R∈R(X,Y )

MXY (R) .

Proof. Let X,Y be a problem context and fbad be
the output of FindWorst(a, X, Y ), then

M

mXY (f )MXY (T y(Y, a, f ))

m
XY (a) = X
f ∈Y X
≥ cmXY 2−K(fbad|X,Y )MXY (T y(a, fbad)) ,

where we have ﬁrst used the deﬁnition (1) of per-
formance measures, and then that the sum of non-
negatives is greater than all of its terms. But
cmXY 2−K(fbad|X,Y ) ≥ ca for some ca > 0 inde-
pendent of X, Y due to cmXY ≥ 1 and the com-
plexity bound (5). And T y(a, fbad) was a worst
result vector by the construction of FindWorst.
Combined, this gives the bound M m
XY (a) ≥ ca ·
maxR∈R(X,Y ) MXY (R).

This theorem shows that for every performance
measure M , there is only a constant amount of free
lunch available in an asymptotic sense. It has no
impact on performance measures whose worst-case
value does not grow unboundedly with either X or
Y . However, the “semi-assumption” of higher val-
ues being worse is not necessary: If the converse is
the case and high values are better, then the propo-
sition shows that all optimisers will do well. Indeed,
this is also an NFL result, as it implies that random
search (and even optimisers designed to do poorly!)
will perform well.

Applied to the performance measure Mot, The-
orem 18 has a fairly concrete interpretation: For
any computable optimiser a, the expected num-
ber of evaluations to ﬁnd the maximum grows lin-
early with |X|. Corollary 19 follows immediately

7

from Theorem 18 and the observation that for any
context X, Y , the worst-case scenario is to ﬁnd
a maximum only at the very last probe; that is,
maxR∈R(X,Y ) Mot,XY (a) = |X|.

Corollary 19. For every computable optimiser
a there exists a constant ca > 0 such that
M m
ot,XY (a) ≥ ca · |X| for all optimisers a and all
problem contexts X,Y .

The implications of this result should not be over-
stated. The constant ca may be very small; for ex-
ample, if the description of the optimiser a is 100
bits long, then ca becomes of the order 2−100. The
fact that the expected number of probes is forced to
grow linearly with such a constant is mainly of the-
oretical importance. Nonetheless, the result does
illustrate a fundamental hardness of optimisation,
and shows that the universal distribution does not
provide enough bias for eﬃcient (sublinear) maxi-
mum ﬁnding.

that the NIAH-functions all have fairly low com-
plexity (as remarked by [SVW01, BP06]). The
NIAH-functions have low complexity, since to en-
code a NIAH-function one only needs to encode
that it is NIAH (which takes a constant number
of bits) and the position of the needle (which re-
quires at most log2|X| bits). A NIAH-function thus
has complexity of order O(log2|X|); in comparison,
a random function has exponentially greater com-
plexity (above |X|log2|Y |).

The NIAH-measure is computable. This is in-
tuitively obvious, and easily veriﬁed against the
formal deﬁnitions of computable functions. Deﬁ-
nitions of real-valued computable functions can be
found in [LV08]. It is well-known that m dominates
any computable measure in the following sense.

Lemma 21 (m dominates uNIAH). There is a con-
stant cNIAH > 0 such that for all X, Y and all
functions f : X → Y , it holds that mXY (f ) ≥
cNIAH · uNIAH,XY (f ).

7.2 Needle-in-a-haystack functions

7.3

Incomputable optimisers

A problematic class of functions is the class of so-
called needle-in-a-haystack (NIAH) functions. We
will use them to generalise Corollary 19 to incom-
putable optimisers. A NIAH-function is a target
function that is 0 in all points except one where
it equals 1. The exception point is called the nee-
dle. It should be intuitively clear that it is hard to
ﬁnd the maximum of a NIAH-function. Probing a
NIAH-function, the output will generally just turn
out to be 0 and provide no clues to where the needle
might be.

Formally, for any X, Y let NIAHXY be the class
of NIAH functions on X, Y and let uNIAH be the
uniform NIAH problem deﬁned as uNIAH,XY (f ) :=
1/|NIAHXY | if f ∈ NIAHXY and 0 otherwise. The
function class NIAHXY is c.u.p.
for any X, Y , so
NFL holds for uNIAH,XY by Theorem 11. The
expected performance (of any optimiser) on the
uniform NIAH-problem can be calculated from a
general result of Igel and Toussaint [IT03]. They
show that for any c.u.p. problem uF where F only
contains functions with exactly m maxima, the
expected number of probes to ﬁnd a maximum
is (|X| + 1)/(m + 1). The NIAH-functions have
exactly one maximum, which gives the following
lemma.

Lemma 20. Under uNIAH,XY , the expected opti-
misation time is M uNIAH
ot,XY (a) = (|X| + 1)/2 for any
optimiser a.

Theorem 18 and Corollary 19 were proven for com-
putable optimisers. We now show that even incom-
putable optimisers suﬀer a linearly growing loss in
|X| when the performance measure is Mot. Incom-
putable search procedures may seem like remote
objects of concern, but for example the (Bayes-
)optimal procedure for m is incomputable due to
the incomputability of m. Therefore, incomputable
procedures do at least have theoretical interest.

The following theorem generalises Corollary 19
to incomputable search procedures, showing that
they also must search a linearly growing portion of
X to ﬁnd the maximum. The theorem does not gen-
eralise to arbitrary performance measures however,
so the analogous generalisation of Theorem 18 may
not be true.

Theorem 22 (Almost NFL for m and Mot). Un-
der m, the expected optimisation time grows lin-
early with |X|, regardless of the optimisation strat-
egy.

Proof. The dominance of m over uNIAH is used in
(7), between an expansion (6) and a contraction
(8) according to the deﬁnition (1) of performance
measures:

M

m
ot,XY (a) = X
f ∈Y X

≥ cNIAH X
f ∈Y X

mXY (f )Mot,XY (T y(a, f )) (6)

uNIAH,XY (f )Mot,XY (T y(a, f ))

One feature that makes the NIAH-class more
problematic than other c.u.p. function classes is

= cNIAH · M uNIAH

ot,XY (a)

(7)

(8)

8

Lemma 20 established (8) to be cNIAH · (|X| + 1)/2
for all optimisers a. Thus the expected Mot-
performance is always bounded below by cNIAH ·
(|X| + 1)/2, which grows linearly with |X|.

Since optimisation time can never grow faster
than linearly with |X|, the bound is asymptotically
tight. In this sense, Theorem 22 may be viewed as
an asymptotic almost-NFL theorem for the univer-
sal distribution and Mot. The constant cNIAH in the
proof may be very small however, so Theorem 22
does not rule out that expected optimisation time
diﬀer substantially between optimisers.

8 Conclusion

In this paper we investigated the No Free Lunch
theorems when the performance of an algorithm is
measured in expectation with respect to Solomon-
oﬀ’s universal distribution. We showed in Theorem
15 that there is a free lunch with respect to this dis-
tribution.

Somewhat surprisingly, despite the bias away
from randomness exhibited by the universal distri-
bution, the size of the free lunch turns out to be
quite small, at least asymptotically (Theorems 18
and 22). The reason for this is that there are many
functions that are both simple and hard to opti-
mise. Most notably the needle-in-a-haystack func-
tions, which have complexity of at most O(log |X|),
but for which a maximum cannot be found without
O(|X|) probes.

It should be emphasised that there is little need
to be too gloomy about the negative results. The
upper bounds on the size of the free lunch given in
both negative theorems depend on constants that in
practise are likely to be very small. Optimisation is
a hard problem, so we should not be too surprised
if there are some reasonably frequently occurring
functions that cannot be eﬃciently optimised.

The fact that simplicity is not a suﬃcient charac-
terisation of the diﬃculty of optimising a function
is unfortunate. This is not true in other domains
such as supervised learning and sequence prediction
where approaches based on Solomonoﬀ’s universal
prior are theoretically optimal in a certain sense
[Hut05]. One diﬃculty of optimisation lies in the
exploration/exploitation problem, which occurs be-
cause at each time-step an optimisation algorithm
must make a choice between trying to learn the true
function and probing the point that it believes to
be the maximum.

Since Kolmogorov complexity is (by itself) insuf-
ﬁcient for characterising the diﬃculty of optimising
a function, a new criterion is required. We are cur-

rently unsure what this should look like and con-
sider this interesting future research.

References

[AT07]

[BP06]

[Cal02]

[CO01]

[DJW02]

[Fre92]

[GO05]

Anne Auger and Olivier Teytaud.
Continuous lunches are free!
In
GECCO’07, 2007.

Yossi Borenstein and Riccardo Poli.
Kolmogorov complexity, optimization
and hardness. In CEC’06, pages 112–
119, 2006.

Cristian Calude. Information and ran-
domness: an algorithmic perspective.
Springer, 2002.

Steﬀen Christensen and Franz Op-
pacher. What can we learn from no free
lunch? a ﬁrst attempt to characterize
the concept of a searchable function. In
GECCO’01, pages 1219–1226, 2001.

Stefan Droste, Thomas Jansen, and
Ingo Wegener.
Optimization with
randomized search heuristics – the
(A)NFL Theorem, realistic scenarios,
Theoreti-
functions.
and diﬃcult
cal Computer Science, 287(1):131–144,
2002.

Edward Fredkin. Finite nature. XXVI-
Ith Rencotre de Moriond, 1992.

Evan J Griﬃths and Pekka Orponen.
Optimisation, block designs and no free
lunch theorems. Information Process-
ing Letters, 94(2):55–61, 2005.

[GTW+11] Dov M Gabbay, Paul Thagard, John
Woods, Prasanta S Bandyopadhyay,
and Malcolm R Forster. Philosophy of
Statistics. Elsevier, 2011.

Marcus Hutter. Universal Artiﬁcial In-
telligence: Sequential Decisions based
on Algorithmic Probability.
Lecture
Notes in Artiﬁcial Intelligence (LNAI
2167). Springer, 2005.

Marcus Hutter. On Universal Predic-
tion and Bayesian Conﬁrmation. The-
oretical Computer Science, 384(1):33–
48, 2007.

[Hut05]

[Hut07]

9

[Hut12]

[IT03]

[IT04]

[Jan13]

[JC11]

[LH11]

Marcus Hutter. The subjective com-
putable universe. In Hector Zenil, ed-
itor, A Computable Universe: Under-
standing and Exploring Nature as Com-
putation, chapter 21, pages 399–416.
World Scientiﬁc, 2012.

Christian Igel and Marc Toussaint.
Neutrality and self-adaptation. Natu-
ral Computing, 2(2):117–132, 2003.

Christian Igel and Marc Toussaint. A
no-free-lunch theorem for non-uniform
distributions of target functions. Jour-
nal of Mathematical Modelling and Al-
gorithms, 3:312–322, 2004.

[Wol02]

[WR06]

Thomas Jansen. Analyzing Evolution-
ary Algorithms: The Computer Science
Perspective.
Springer Berlin Heidel-
berg, 2013.

Pei Jiang and Ying-ping Chen. Free
lunches on the discrete Lipschitz
class. Theoretical Computer Science,
412(17):1614–1628, April 2011.

Tor Lattimore and Marcus Hutter. No
free lunch versus Occam’s razor in su-
pervised learning. In Proceedings of the
Solomonoﬀ 85th Memorial Conference,
Melbourne, Australia, November 2011.
Springer.

[LV08]

Kol-
Ming Li and Paul Vitanyi.
mogorov Complexity and its Applica-
tions. Springer Verlag, third edition,
2008.

[McG06]

Simon McGregor. No free lunch and al-
gorithmic randomness. In GECCO’06,
pages 2–4, 2006.

[RH11]

Samuel Rathmanner and Marcus Hut-
ter. A philosophical treatise of uni-
versal induction. Entropy, 13(6):1076–
1136, 2011.

[RVW09]

Jonathan E Rowe, Michael D Vose, and
Alden H Wright. Reinterpreting no
free lunch. Evolutionary computation,
17(1):117–129, January 2009.

[Str03]

Matthew J Streeter. Two broad classes
of functions for which a no free lunch
In GECCO’03,
result does not hold.
pages 1418–1430, 2003.

10

[SVW01] Christopher W Schumacher, Michael D
Vose, and L Darrell Whitley. The
no free lunch and problem description
length. In GECCO’01, pages 565–570,
2001.

[WM97]

David H Wolpert and William G
Macready. No free lunch theorems for
optimization.
IEEE Transactions on
Evolutionary Computation, 1(1):270–
283, 1997.

Stephen Wolfram. A New Kind of Sci-
ence. Wolfram Media, 2002.

L Darrell Whitley and Jonathan E
Rowe.
Subthreshold-seeking local
search. Theoretical Computer Science,
361(1):2–17, 2006.

Appendix

We here include a proof of Theorem 16. The proof
builds on the following deﬁnitions and lemmas.

Deﬁnition 23. A point x ∈ X is incompressible
with respect to the context X, Y if K(x|X, Y ) ≥
log(|X|).

At least half of the points of any search space will
be incompressible. Functions that only have incom-
pressible maxima (except, possibly, for a maximum
at x1) will play an important role since they are
guaranteed to have high complexity. The reason
for excluding x1 will be apparent in the proof of
Theorem 16.

Lemma 24. Let X, Y be a problem context, and
let D ⊆ X be a non-empty set of incompressible
points. Let g : X → Y have at least one maximum
in D, and no maximum outside D ∪ {x1}. Then
K(g | X, Y ) ≥ log2(|X|) − c, where c depends only
on the reference machine and not on g, X or Y .

Proof. Let g be as in the Lemma statement, and
let xm ∈ X − {x1} be the ﬁrst maximum of g
not at x1. Then xm can be coded by means of g
with constant length procedure FirstMax(g) that
computes the ﬁrst maximum not at x1 for a given
function g. Hence K(xm | X, Y ) ≤ K(g | X, Y ) +
ℓ(FirstMax) + c. The constant c depends only on
the reference machine, and absorbs the cost of ini-
tialising FirstMax with a provided description of
g.

By assumption xm was

K(xm | X, Y ) ≥ log2|X|.
arranged,

incompressible,
so
Combined and re-
this gives K(g | X, Y ) ≥ log2|X| −

ℓ(FirstMax) − c. The lemma now follows by ab-
sorbing ℓ(FirstMax) into c.

and since the cardinality of G1 is less than |Y |k+1,
(10) is bounded by

≤ 2cf · cmXY · |Y |k+1 · 2−log2|X|+c

=

2cf +c · cmXY · |Y |k+1
|X|

(11)

the last equality by elementary simpliﬁcation.

As cmXY is bounded above by a constant cm for
all X, Y , (11) goes to 0 with growing search space
(and ﬁxed k and Y ). This shows that for large
enough search spaces, x1 is more likely to host a
maximum than xm.

Now all that remains is to use this to create two
algorithms that perform diﬀerently under Mot. Let
a start by searching Q in order. If the perceived
function points are consistent with f (i.e., the event
G is veriﬁed), then a proceeds at x1 and then at xm,
whereafter a searches the remaining points X−Dk−
{x1} in order. If the trace is not consistent with
f , then a directly proceeds to search all remaining
points in order. Deﬁne b the same way, with the
only exception that after Q it searches xm before
x1 in case the trace is consistent with f .

This way, a and b will perform the same except
when encountering a function in G, in which case
a will have a strictly better chance of ﬁnding the
maximum at step |Q| + 1. If neither a nor b ﬁnds
a maximum at step |Q| + 1, then neither x1 nor
xm is a maximum, so neither a nor b will ﬁnd a
maximum at step |Q| + 2 either. Finally, on step
|Q| + 3 and onwards their behaviour will again be
identical, and therefore also their Mot performance.
So a has a strictly better chance at step |Q| + 1 and
a and b’s performance is identical on all other steps
and in all other situations. This shows that there
is a (possibly small) free lunch for Mot on m for
suﬃciently large search spaces.

We are now ready for the proof of Theorem 16
that shows that there is free lunch for Mot on the
problem m. The key idea is to show that there
is a trace after which two unexplored points have
diﬀerent probability of being the maximum.

Theorem 16. There is free lunch for the problem
m under the performance measure Mot for all prob-
lem contexts with suﬃciently large search space (the
required size depending on the reference machine
only).

Proof. Let k ≥ 2 and let X,Y be a problem context
with |X| ≥ 2k. Let Dk ⊆ X be of size k and only
include incompressible points. Let Q = X − Dk −
{x1}. Let G = {g ∈ Y X : x ∈ Q =⇒ g(x) =
0} contain all functions that are 0 on Q. Let f
be 0 everywhere, except at x1, where f is 1. The
complexity of f is upper bounded by a constant cf
independent of X. Since f ∈ G, we get mXY (G) ≥
mXY (f ) ≥ 2−cf .

Let xm ∈ Dk be an incompressible point, and let
Gm = {g ∈ G : g(xm) = max g}. As the functions
in G are all 0 on Q, the cardinality of Gm is at
most |Y ||X−Q| = |Y |k+1. Also, the functions in
Gm all have complexity above log |X| − c for some
c independent of X, Y , by Lemma 24.

We will now show that mXY (Gm|G) tends to
0 with growing |X|, while mXY (f |G) remains
bounded away from 0. This will establish that
provided G, a maximum at x1 is more likely than
a maximum at xm. Provided G, the probability
of a maximum at x1 is always above 2−cf , since
mXY (max at x1|G) ≥ mXY (f | G) ≥ mXY (f ) ≥
2−cf . A maximum at xm, on the other hand, is
less likely since only functions in Gm can have a
maximum there:

mXY (max at xm|G) = mXY (Gm)/mXY (G)

≤ mXY (Gm)/2−cf
= 2cf · cmXY X
g∈Gm

2−K(g | X, Y )

(9)

Using the lower bound on the complexity from
Lemma 24, (9) is bounded by

2−log2|X|+c

≤ 2cf · cmXY X
g∈Gm
= 2cf · cmXY |Gm| · 2−log2|X|+c
(10)

11

