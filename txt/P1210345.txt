Learning to Rank Proposals for Object Detection

Zhiyu Tan1

Xuecheng Nie2

Qi Qian1

Nan Li1

Hao Li1

1Alibaba Group, Beijing, China
2Department of Electrical and Computer Engineering, National University of Singapore, Singapore
{zhiyu.tzy, qi.qian, nanli.ln, lihao.lh}@alibaba-inc.com niexuecheng@u.nus.edu

Abstract

Non-Maximum Suppression (NMS) is an essential step
of modern object detection models for removing duplicated
candidates. The efﬁcacy of NMS heavily affects the ﬁnal
detection results. Prior works exploit suppression criteri-
ons relying on either the objectiveness derived from classi-
ﬁcation or the localization produced by regression, both of
which are heuristically designed and fail to explicitly link
with the suppression rank. To address this issue, in this pa-
per, we propose a novel Learning-to-Rank (LTR) model to
produce the suppression rank via a learning procedure, thus
facilitating the candidate generation and lifting the detec-
tion performance. In particular, we deﬁne a ranking score
based on IoU to indicate the ranks of candidates during the
NMS step, where candidates with high ranking score will
be reserved and the ones with low ranking score will be
eliminated. We design a lightweight network to predict the
ranking score. We introduce a ranking loss to supervise the
generation of these ranking scores, which encourages can-
didates with IoU to the ground-truth to rank higher. To fa-
cilitate the training procedure, we design a novel sampling
strategy via dividing candidates into different levels and se-
lect hard pairs to adopt in the training. During the inference
phase, this module can be exploited as a plugin to current
object detector. The training and inference of the overall
framework is end-to-end. Comprehensive experiments on
benchmarks PASCAL VOC and MS COCO demonstrate the
generality and effectiveness of our model for facilitating ex-
isting object detectors to state-of-the-art accuracy.

1. Introduction

Object detection is a fundamental yet challenging task in
computer vision, It is extensively applied in video/image in-
dexing [29] [24], face recognition [31], autonomous driving
cars [7] [19] and human pose estimation [32].

Existing object detection models heavily rely on the
Non-Maximum Suppression (NMS) algorithm to remove
duplicated bounding boxes via a suppression criterion,

IoU:0.60
Cls conf:0.70
Local conf:0.75
Rank conf:0.81

IoU:0.93
Cls conf:0.62
Local conf:0.73
Rank conf:1.3

IoU:0.92
Cls conf:0.73
Local conf:0.45
Rank conf:0.97

IoU:0.66
Cls conf:0.80
Local conf:0.67
Rank conf:0.22

Figure 1. Motivations for the proposed Learning-to-Rank model
for oject detection. Yellow boxes represent the groundtruth. Read
and green boxes represent the predicted candidates. Existing
works fail to reserve the more accurate green candidates due to
the heuristically designed suppression criterions based on classiﬁ-
cation or localization scores. The proposed LTR model addresses
this problem via producing the suppression rank with a learning
procedure. See text for details.

which is deﬁned either from the objectness derived from
classiﬁcation or localization produced by regression. How-
ever, these existing suppression criterions fail to explicitly
link with the candidate rank in the elimination procedure,
as shown in Figure 1. Inaccurate ranks of candidates will
cause error eliminations and degrades the performance of
object detectors. The suppression criterion still needs to be
improved to facilitate the performance of object detectors.
In this paper, we propose to enhance the suppression cri-
terion in both the training and inference phases of object de-
tectors. We observe existing criterions are either designed
in a heuristic manner or produced in an implicit way. An
explicit ranking score deﬁnition and generation can suc-
cessfully remove the gap between the suppression criterion
and candidate preservation. Motivated by this, we propose
a Learning-To-Rank (LTR) model to predict the ranking
scores of candidates in a learning procedure, thus overcom-
ing the limitations of existing methods and improving the
object detection.

In particular, we deﬁne a ranking score based on IoU
to indicate the ranks of candidates during the NMS step,
where candidates with high ranking score will be reserved
and the ones with low ranking score will be eliminated. We

8273

design a lightweight network to predict the ranking score.
We introduce a ranking loss to supervise the generation of
these ranking scores, which encourages candidates with IoU
to the ground-truth to rank higher. To facilitate the training
procudure, we design a novel sampling strategy via dividing
candidates into different levels and select hard pairs to adopt
in the training. During the inference phase, this module can
be exploited as a plugin to current object detector.

We implement this module with a small convolutional
neural network. The training and inference of the over-
all framework is end-to-end. Comprehensive experiments
on PASCAL VOC [8] and MSCOCO [22] show that
our proposed LTR model achieves outperforming accuracy
including Faster R-
with multiple detection framework,
CNN [11], Mask RCNN [12] and Cascade rcnn [2], without
any bells and whistles. Our contributions can be summa-
rized into three folds: (1) We propose a novel Learning-To-
Rank model to improve the NMS algorithm in both training
and inference phases of object detection. (2) We propose a
novel pair sampling strategy to improve the learning speed.
(3) Our LTR model generally improves the performance of
multiple object detector and sets new state-of-the-art accu-
racy on multiple benchmarks.

2. Related work

Object detection has been extensively studied in the
literature.
Recently, deep learning techniques signiﬁ-
cantly boost the performance of object detection algorithms
over traditional methods based on hand-crafted ones (e.g.,
Haar [35], SIFT [9], HOG [6], etc), due to its strong capa-
bilities to extract power features with Convolution Neural
Networks (CNNs). Existing CNN based methods can be
divided into two categories: one-stage based detectors and
two-stage based ones.

One-stage based detectors, such as SSD [23], Retinanet
[21] and YOLO [25], are mainly focused on computation
efﬁciency, which enables fast object detections.
In term
of accuracy, two-stage based detectors still dominate the
community and usually outperform the single-stage based
ones. In this paper, we aim to improve the two-stage based
detectors, thus further pushing forward the frontier of ob-
ject detection. Current two-stage based object detectors in-
volves two steps: (1) object proposal generation and (2)
object classiﬁcation and bounding box reﬁnement. In this
paradigm, Non-Maximum Suppression (NMS) plays a key
role to produce high quality candidates, which signiﬁcantly
affecting the ﬁnal detection results. However, most of exist-
ing works ignore this important post-processing step. Here,
we propose to improve the NMS, thus lifting the perfor-
mance of two-stage based detectors. In the following, we
mainly review existing NMS algorithms.

In order to remove massive duplicated bounding boxes,
NMS is applied as the post-process procedure in main-

[27]

[11]

stream detection pipeline [9]
[4]. NMS se-
lects the bounding box with the maximum classiﬁcation
conﬁdence and eliminates its nearby boxes using a prede-
ﬁned IoU threshold iteratively. In computer vision, it has
been almost 50 years to take the NMS algorithm as the
post-processing process for most of object detection frame-
work. NMS is still crucial to CNN-based detectors, which
improves performance by removing duplicated results. Al-
though detectors can generate many candidate bounding
boxes with accurate location before NMS, these bounding
boxes will probably be removed because of lower predicted
conﬁdence during NMS. Recently, many effective tech-
niques are proposed to improve NMS. Soft-NMS [1] is a
parameter-free algorithm, where duplicate bounding boxes
removal is replaced by decaying the bounding box scores
with a continuous function. A set of learning-based algo-
rithms have been proposed as alternatives to the parameter-
free NMS and Soft-NMS. Softer NMS [14] averages the
selected boxes in a softer way. Learning NMS [15] uses a
complex neural network to perform NMS using only boxes
and their scores. Fitness NMS [34] introduces the localiza-
tion information of bounding box into ranking conﬁdence.
Relation network [16] uses a sub-network to learn NMS
by mining the visual information of object-object interac-
tions. However, the conﬁdence training of prior works are
all based on classiﬁcation task or regression task, which are
not suitable for NMS algorithm.

Different from existing NMS algorithms, we propose a
novel learning-to-rank model to produce the suppression
score via a learning procedure and explicitly build link to
the suppression rank, thus facilitating the candidate genera-
tion and lifting the detection performance, which is elabo-
rated bellow.

3. Proposed Approach

In this section, we will illustrate the proposed Learning-
to-Rank network model for object detection. An overview
of the LTR model is given in Figure 2. The core of LTR
is the Rank-NMS subnetwork, which is pluggable to the
conventional two-stage object detectors. In particular, the
Rank-NMS subnetwork takes the ROI-Aligned features of
positive bbox candidates from the object detector as in-
put and predicts their ranking scores based on Intersection-
over-Union (IoU) values to the ground-truth. Then, LTR
fuses the ranking scores with the classiﬁcation scores to pro-
duce the ﬁnal ranking conﬁdences, which are used as sup-
pression criterion for the NMS algorithm. In this way, LTR
overcomes limitations of existing heuristically designed cri-
terions for NMS and encourages to reserve bbox candidates
with higher IoU with the ground-truth, thus improving the
object detection accuracy. To train the Rank-NMS subnet-
work, we design a ranking loss as supervision and propose
a sample-pair selection strategy to speed up convergence,

8274

Image

Conv features

Rank-NMS subnetwork

ROI Align

7*7*256

2 fc head

Ranking
scores

ROI Align

7*7*256

2 fc head

Fused scores

Positive bbox

NMS

Detection 
results

Classiﬁcation 
scores

Bboxes

FPN

ROIs

RPN

Figure 2. Overview of the proposed Learnin-to-Rank model for object detections.

details of which are illustrated in the following.

3.1. Ranking Loss

In general,

the higher IoU values the bboxes to the
groundtruth are, the better the localization is. Therefore,
the Rank-NMS subnetwork, denoted as R(·), aims to pre-
dict higher ranking scores for bboxes with higher IoU val-
ues and vice versa. To achieve this goal, we deﬁne the IoU
based ranking as following

R(f (bi)) + α < R(f (bj)), s.t. ρi < ρj,

(1)

where bi and bj denote bbox candidates, and ρi and ρj their
IoU values with groudtruth, respectively. f (·) denotes the
ROI-Aligned operation to extract features for a bbox. α is a
constant to control the ranking margin. Then, we deﬁne the
ranking loss by

L =

1
N X(bi,bj ), ρi≤ρj

max (0, R(f (bi)) − R(f (bj)) + α) ,

(2)
where N is the total number of bbox pairs that satisfy
the ranking condition deﬁned in Eqn. (1). We train the
Rank-NMS subnetwork by minimizing the loss deﬁned in
Eqn. (2). In practice, N is always very large and the pos-
sible bbox pairs contains many easily-ranked ones. To ac-
celerate the training, we propose an effective sample-pair
selection strategy, explained in the next subsection.

3.2. Pair Selection

The selection strategy of training pairs is crucial to learn
the proposed Rank-NMS network model. To reduce the re-
dundant and eliminate the uninformative bbox paris from
Eqn. (1), we propose a sampling-after-splitting strategy to
effectively select valuable training pairs. In particular, we
ﬁrst divide all bboxes into subsets according to their q-
values, which are calculated by the quantization function:

q(ρi) =

max(0, ρi − 0.5)
0.05

.

(cid:25)

(cid:24)

(3)

Algorithm 1 Pair sampling algorithm
Input: The set of ranking scores for n bbox candidates
R={r1, ..., rn} and the set of k quantized subsets
S={S0, ..., Sk};

Output: The set of selected pairs P
1: P ← ∅;
2: for i = 1 to k do
3:
4:
5:

Posi ← Si; // take all positive samples
Ui ← S0 ∪ ... ∪ Si−1; // take all negative samples
Generate a ranked list Li upon Ui in descending or-

der of the predicted ranking score;

6:
7:

Negi ← get top h elements of Li;
Generate the pair set Ci by the Cartesian product of

Posi and Negi;

8: end for
9: P ← Ci ∪ · · · ∪ Ck;
10: return P;

Eqn. (3) quantizes bbox candidates based on their IoU val-
ues with groundtruth and enforces larger IoU values to pro-
duce larger quantization results. Based on Eqn. (3), we
will generate 11 subsets with their indices ranging from 0
to 10. Then, we sample the positive and negative sam-
ples individually for each of quantized subsets following the
same rules—bounding boxes with higher IoU values to the
ground-truth are deﬁned as positive samples while bound-
ing boxes with lower IoU values as negative ones. For the
ith quantization subset, its positive samples are the ones in
itself. While its negative samples are the top-h elements
in the list that ranks the bounding boxes from union of the
quantized subsets with the quantization value smaller than
i in the descending order based on the ranking score. Then,
the training pair set for this quantiation subset is derived by
Cartersian product between its positive and negative sam-
ples. We repeat the above procedure to generate the train-
ing pair set for all the quantization subsets. Algorithm 1
illustrates the pair selection strategy.

8275

3.3. Score Fusion

Prior works always exploits classiﬁcation scores of bbox
candidates as the suppression criterion of NMS algorithm,
which considers the objectiveness and well ﬁlters out neg-
ative candidates. Differently, the ranking score accounts
for the overlapness between bbox candidates and groudtruth
and is good at reserving accurate positive candidate. To de-
rive more reliable suppression criterion, we propose to fuse
the classiﬁcation and ranking scores via their weighted sum:

s = βsr + (1 − β)sc,

(4)

where sr and sc denote the ranking and classiﬁcation
scores, respectively. β is the balance factor, set as 0.15.
s is the ﬁnal score used as the suppression criterion of the
NMS algorithm in both training and inference phases.

4. Experiments

4.1. Experiment setup

Datasets We conduct experiments on two widely used
benchmarks for the object detection task: MSCOCO [22]
dataset and PASCAL VOC [8] dataset.
In particular,
MSCOCO is a large scale dataset with 80 categories of ob-
ject annotations in total. In this paper, we use the 2017 split,
containing 118,000 samples, to train our models. We use the
standard validation split (5,000 samples) and test-dev split
(20,000 samples) for evaluating our proposed method. We
exploit the ofﬁcial Average Precision (AP) as metric. PAS-
CAL VOC is another dataset for extensively evaluating the
object detection algorithms. It provides annotations for 20
object classes and provides two different splits: VOC 2017
and VOC 2012. Here, we follow the conventions to use
the combination of training and validation sets of these two
splits, for model training, including 16,000 images in total.
We evaluate our models on the VOC 2007 test set also with
AP as the metric.

Data augmentation Follow conventions, we only adopt
horizontal ﬂipping in data augmentation to our models for
both MSCOCO and PASCAL VOC datasets.

Training and inference We exploit ResNet [13] as the
network backbone. In the training phase, we exploit the Im-
ageNet pre-trained models to initialize our network for both
MSCOCO and PASCAL VOC datasets. The new adding
layers are randomly initialized with normal distributions,
where the mean is set to 0 and standard deviation 0.01 or
0.001. We set the dimension of features as 1024 for all the
classiﬁcation, regression and ranking tasks. We extract 512
proposals per image from the region proposal network. We
make all the regressors in our model class-agnostic for sim-
plicity. We use a batch size of 16 for training all the models.
We implement the proposed method with MMDetection [3].

Table 1. Ablation analysis on the ranking margin α in the ranking
loss, with β ﬁxed as 0.15 on PASCAL VOC 2007VAL dataset.
AP50 AP60 AP70 AP80 AP90

AP

α

0.0
0.25
0.5
0.75
1.0

54.45
57.92
58.75
58.32
57.22

79.91
79.87
79.98
78.39
76.48

74.76
75.65
75.50
74.63
73.02

61.66
65.39
65.43
65.25
63.89

39.08
46.12
48.00
48.30
47.75

10.73
16.29
18.34
18.47
18.24

We use the SGD as the optimizer for model learning. We
train all models for 12 epochs in total. We set the initial
learning rate as 0.02 and 0.01 for MSCOCO and PASCAL
VOC, respectively. In addition, we drop the learning rate
by a factor of 10 at 8th and 11 epochs, while for PASCAL
VOC, we only drop the learning rate at 9th epoch with the
same factor. We use the Cross-Entropy loss for object clas-
siﬁcation and Smooth L1 loss [10] for bounding box regres-
sion, which are summed with the ranking loss for supervis-
ing the model training. We also adopt linear warming up
strategy to begin the training of our model. For MSCOCO
(PASCAL VOC), We resize the image to make its short edge
as 800 (600) pixels while keeping the long edge no longer
than 1,333 (1,000) pixels, as input to the network for both
training and inference. We perform single-scale testing to
generate all the results.

4.2. Results on PASCAL VOC

4.2.1 Ablation study

We ﬁrst conduct ablation studies on the validation set PAS-
CAL VOC 2007VAL to analyze the effects of some impor-
tant hyper-parameters to the proposed model, including the
ranking margin α in Eqn. 1 and the balance weight β in
Eqn. 4. Results are shown in Table 1 and 2, respectively.

From Table 1, we can see when setting α as 0, which
indicates learning the rank loss without margin, our model
achieves 54.45 AP. While exploiting soft margin (α > 0)
brings obvious performance improvements, e.g., α = 0.5
achieves 7% accuracy gain over α = 0, demonstrating that
soft margin can enlarge the rank gap for proposal pairs and
leading to more discriminative ranking scores. We can also
see that increasing α from 0 to 0.5, the accuracy is consis-
tently raised from 54.45% AP to 58.75% AP, especially for
high IoU metrics, e.g., AP90, due to the improvement to the
error tolerance. However, further increasing α to 1.0 de-
grades the performance, caused by introducing much noise
with too large margin during the ranking process. There-
fore, we set α as 0.5 in our experiments.

Table 2 shows the effects of the balancing weight β on
the detection results, while varying α from 0.25 to 0.75. We
can see that with small ranking margin α = 0.25, prop-
erly increasing β can bring performance improvement, im-
plying that correct ranking score is complementary to the

8276

Table 2. Ablation analysis on the balancing weight β for score
fusion with different α on PASCAL VOC 2007VAL dataset.

β

α

AP AP50 AP60 AP70 AP80 AP90

Table 4. Comparison between the proposed hard-pair sampling
strategy and the full-pair one on PASCAL VOC 2007VAL dataset.
Sampling Strategy AP AP50 AP60 AP70 AP80 AP90

0.5

0.5

0.5

64.64 44.55 15.49
0.05 0.25 57.28 79.94 75.38
65.51 46.56 16.93
58.26 80.29 75.64
0.05
65.56 47.60 17.63
0.05 0.75 58.44 79.56 75.27
58.75 79.98 75.50
65.43 48.00 18.34
0.15
65.29 46.56 16.57
0.25 0.25 58.09 79.65 75.52
65.20 47.55 17.66
58.18 78.74 74.74
0.25
63.28 47.75 18.62
0.25 0.75 56.89 75.78 72.31
65.13 47.14 16.69
0.35 0.25 57.99 79.26 75.13
0.35
63.96 47.29 17.96
57.19 76.93 72.97
0.35 0.75 55.29 73.22 70. 00 61.24 46.57 18.81
0.45 0.25 57.56 78.44 74 3.3 64 5.8 46.82 16.93
0.45
55.96 74.99 71.29 62 37. 46.28 17.81
0.45 0.75 54.08 71.31 68. 32 59 9.1 45.70 18.49

0.5

0.5

Table 3. Ablation analysis on the positive samples ratio on PAS-
CAL VOC 2007VAL dataset.

pos ratio AP AP50 AP60 AP70 AP80 AP90

0.25
0.5
0.75

58.75 79.98 75.50 65.43 48.00 18.34
58.26 79.50 75.40 65.19 47.09 17.36
58.60 79.70 75.24 65.11 47.64 18.48

classiﬁcation conﬁdence and helps to select more suitable
object proposals. However, when using large ranking mar-
gin, larger β causes accuracy drop, due to the introducing
of ranking noise that brings negative effects for generating
proposals. In addition, we ﬁnd that β = 0.15 with α = 0.5
gives the best detection performance, which is utilized de-
fault parameter setting in our experiments.

Next, we conduct experiments to analyze the effects of
the ratio of positive samples in the learning phase with the
proposed ranking loss. Results are shown in Table 3. We
experiment with three different ratios ranging from 0.25
to 0.75. We can see decreasing the positive sample ratio
always improves the performance, indicating less positive
samples can facilitate the model to differentiate correct pro-
posals with erroneous ones, which thereby enhances the
learning of the proposed ranking loss.

Then, we compare the proposed hard-pair sampling
strategy with the full-pair one and show the results in Ta-
ble 4. We can see that the proposed hard-pair sampling
strategy achieves superior performance over the full-pair
one (58.75% AP vs 56.54% AP), demonstrating the effec-
tiveness of mining hard pairs of proposals to facilitate the
learning of the ranking loss. The superiority of the proposed
hard-pair sample strategy can be further observed when us-
ing high IoU metrics, e.g., at AP 90, the hard-pair sampling
strategy lifts the performance from 13.31% AP to 18.34%
AP, which further verifying its efﬁcacy to improve proposal
selection.

Hard-Pair
Full-pair

58.75 79.98 75.50 65.43 48.00 18.34
56.54 79.49 75.09 63.75 43.84 13.31

4.2.2 Comparison with the state-of-the-arts

Table 5 shows the comparisons between the proposed ap-
proach with state-of-the-arts on the full testing dataset of
PASCAL VOC 2017. We evaluate the efﬁcacy of the pro-
posed Rank-NMS on two state-of-the-art object detectors:
Faster R-CNN and Cascade R-CNN. We adopt the ResNet-
FPN as the backbone and vary its depth in 50 and 101.

From Table 5, we can see the proposed Rank-NMS con-
sistently improves the detection accuracy for both Faster
and Cascade R-CNNs. The performance improvement on
Faster R-CNN is obvious, 4.59% AP and 3.35% AP with
the backbone of 50 and 101 layers ResNet-FPN, respec-
tively. These results validate the effectiveness of the pro-
posed Rank-NMS for generating high quality proposals. We
can also ﬁnd that even the baseline Cascade R-CNN already
achieves very high detection accuracy, the proposed Rank-
NMS still raises their performance, which can be more ob-
viously observed at AP 90 (from 21.53% AP to 24.68% AP
and from 25.75% AP to 28.90% AP with ResNet-50/101-
FPN as backbone, respectively.). These results further
demonstrate the effectiveness of the proposed Rank-NMS
to improve the proposal generation for current state-of-the-
art object detectors.

4.3. Results on MSCOCO

In this section, we conduct experiments on MSCOCO
dataset to further evaluate the efﬁcacy of the proposed
Rank-NMS. Details are explained bellow.

4.3.1 Compare with other NMS method

We ﬁrst compare the proposed Rank-NMS with tradition
NMS algorithms: Soft-NMS [1] and IoU-NMS (the stan-
dalone version) [18], on MSCOCO validation set. In par-
ticular, the Soft-NMS is based on the conﬁdence score
from the classiﬁcation while the IoU-NMS the overlap score
from the regression. We conduct experiments with different
objectors, including Faster R-CNN, Cascade R-CNN and
Mask R-CNN, to comprehensively analyzing the effective-
ness of different NMS algorithms. Here, we utilize ResNet-
50 as the backbone for all models. In addition, we also ex-
periment with the combination of the proposed Rank-NMS
and Soft-NMS to verify the compatibility of the proposed
method. Results are shown in Table 6.

We can see, with a ﬁxed object detector, the proposed
Rank-NMS consistently outperforms IoU-NMS and Soft-

8277

Table 5. Comparison with state-of-the-arts on the full testing dataset of PASCAL VOC 2007 .

Backbone

ResNet-50-FPN

ResNet-101-FPN

Method
Faster R-CNN
Faster R-CNN
Cascade R-CNN
Cascade R-CNN

Faster R-CNN
Faster R-CNN
Cascade R-CNN
Cascade R-CNN

Rank-NMS
✗
X
✗
X

✗
X
✗
X

AP
54.16
58.75
60.09
61.32

58.22
61.57
63.37
63.90

AP50 AP60 AP70 AP80 AP90
8.84
61.74
79.79
18.34
65.43
79.98
21.53
65.84
79.98
24.68
67.13
79.71

75.02
75.50
74.66
75.74

39.02
48.00
50.52
52.31

82.1
80.58
81.69
81.14

77.49
76.90
77.30
77.17

66.56
67.70
69.26
69.81

45.70
52.40
55.01
56.08

12.50
22.67
25.75
28.90

Table 6. Comparisons between the proposed Rank-NMS with tradition NMS algorithms on MSCOCO validation set.

Method

+IoU-NMS [18]

+Soft-NMS

+Rank-NMS AP AP50 AP75 APS APM APL

Faster R-CNN

Cascade R-CNN

Mask R-CNN

X

X

X

X

X

X

X

X

X

36.4
37.3
36.9
38.6
38.9

40.3
40.9
41.0
41.0
41.4

37.3
38.1
37.8
39.3
39.6

58.4
56 0
58.4
58.2
58.1

58.6
58.2
58.8
59.1
58.8

59.1
56.4
59.1
58.8
58.7

39.1
-
40.1
41.7
42.4

43.9
-
45.2
44.5
45.5

40.3
-
41.3
42.3
43.1

21.6
-
21.9
22.4
22.5

22.9
-
23.2
23.0
23.2

22.0
-
22.2
22.8
23.0

40.1
-
40.7
42.4
42.8

43.8
-
44.6
44.3
44.9

40.9
-
41 6.
42.7
43.1

46.6
-
47.1
50.9
51.2

53.2
-
54.0
54.8
55.3

48.2
-
48.7
52.2
52.5

X
X

X
X

X
X

NMS. This demonstrates the advantage of the proposed
Rank-NMS over existing classiﬁcation or regression based
NMSs for selecting high quality proposals with the learned
ranking score. We can also see that the performance im-
provement on large objects is more obvious, e.g., with Mask
R-CNN detector, Rank-NMS improves the accuracy from
48.7% APL to 52.2% APL. In addition, we can ﬁnd the pro-
posed Rank-NMS improves all the object detectors, demon-
strating its generality. Moreover, we can observe, combin-
ing the Rank-NMS with Soft-NMS can further achieve per-
formance gain. This result shows that the proposed Rank-
NMS is compatible with existing NMS algorithms and pro-
vides valuable complementary proposals to improve object
detection. For the comparison with Softer-NMS [14], its
map result achieves 39.2 AP on COCO val2017 by length-
ening the learning period. Our Rank-NMS achieves 38.9
AP with only half of the learning period as Softer-NMS and
has the potential to further improve performance by length-
ening the learning period.

For further analyzing the advantages of the proposed
Rank-NMS, we plot the recall curve for different NMS al-

gorithms in Figure 3, with the matching IoU ranging from
0.5 to 1. We can ﬁnd that the proposed Rank-NMS con-
sistently achieves better recall over the traditional NMS al-
gorithms when varying the matching IoU, indicating that it
produces the improved ranking list for proposals. In addi-
tion, we can see that combining Rank-NMS with Soft-NMS
34.5% recall at matching IoU 0.9, where the recall upper-
bound is 41.4%. This results further validate the effective-
ness of the proposed Rank-NMS for preserving higher IoU
proposals.

Similar to PASCAL VOC dataset, we also conduct ex-
periments on MSCOCO validation set to analyze the ef-
fects of the proposed Rank-NMS on different object detec-
tor. In addition, we also report the running speed to analyze
the efﬁciency of Rank-NMS. Results are shown in Table 9.
We can see that the proposed Rank-NMS can consistently
improve the object detection models, including Faster R-
CNN, Cascade R-CNN and Mask R-CNN. We can also see
that the proposed Rank-NMS can improve the object de-
tectors with large network backbone, e.g., Cascade R-CNN
with ResNet-101-FPN. These results further validate the ef-

8278

Table 7. Studies on the effects of classiﬁcation and ranking scores
to the NMS algorithm for object detection task on MSCOCO val5k
dataset.

NMS Score

AP AP50 AP75 APS APL APM

36.4 58.4 39.1 21.6 40.1 46.6
NMS-Cls
NMS-LTR
35.4 51.6 38.7 19.0 39.2 48.4
NMS-Cls+LTR 38.6 58.2 41.7 22.4 42.4 50.9

fectiveness and generality of the proposed Rank-NMS for
improving the proposal selection. In addition, we can see
that using Rank-NMS only brings slight times cost, which
demonstrates the efﬁciency of the proposed Rank-NMS for
object detection.

4.3.2 Performance of individual LTR

We conduct experiments on COCO dataset for Faster FPN
model with ResNet50 to study the effects of the classiﬁ-
cation and ranking scores to the NMS algorithm for ob-
ject detection task. Results are shown in Table 7. We use
NMS-LTR to denote the NMS algorithm with only the rank-
ing score for suppressing bounding boxes while NMS-Cls
the one with only the classiﬁcation score. We use NMS-
Cls+LTR to denote performing NMS algorithm with the fu-
sion of classiﬁcation and ranking scores. We use Faster R-
CNN as the object detector and the other settings are the
same for the experiments. We can see the baseline NMS-
Cls achieves 36.4 AP. While NMS-LTR slightly decreases
the performance to 35.4 AP, since the ranking score is better
at ranking bounding box candidates for the true positives but
it is weaker to distinguish the true negatives than the classi-
ﬁcation score. After fusing the ranking score with classiﬁ-
cation score, we can see NMS-Cls+LTR achieves 38.6 AP,
outperforming both the NMS algorithm with only a single
kind of score. This result veriﬁes that the proposed ranking
score is complementary to the classiﬁcation score, which
can help produce more accurate ranking of bounding box
candidates after ﬁltering the false alarms with the classiﬁ-
cation score. We will add the above experiments and illus-
trations in revision.

4.3.3 Comparison with the state-of-the-arts

Next, we compare the proposed Rank-NMS with state-of-
the-art object detection models on MSCOCO test-dev. We
evaluate the proposed method with three object detectors:
Faster R-CNN, Mask R-CNN and Cascade R-CNN1. We
use ResNet-101-FPN as the backbone. We report the perfor-
mance of all methods with single-model inference for fair
comparison. Results are shown in Table 8.

We can see that with Cascade R-CNN as the object de-
tector, our Rank-NMS sets new state-of-the-art 43.7% AP

1We set positive samples ratio of each stage of Cascade R-CNN as 0.5.

Figure 3. Comparison among the recall curves of different NMS
algorithms with the matching IoU ranging from 0.5 to 1.

bed:0.741

person:0.309

bed:0.837

person:0.431

person:0.994

snowboard:0.308

person:1.049
snowboard:0.511

boat:0.922

boat:0.408

boat:0.879

bear:0.967

bear:0.628

bear:1.027

bear:0.918

Figure 4. Qualitative comparison between the proposed Rank-
NMS and the traditional NMS on MSCOCO dataset. .

on MSCOCO test-dev, demonstrating the superior perfor-
mance of the proposed methods. We can also ﬁnd that when
combining with Soft-NMS, the performance can be further
improved to 43.7% AP, in addition improving all object de-
tectors with Rank-NMS only. These results further verify
the compatibility of the proposed Rank-NMS method.

4.3.4 Qualitative results

Qualitative results for comparison between the proposed
Rank-NMS with traditional NMS algorithms are provided

8279

Table 8. Comparison with the state-of-the-art single-model detectors on MSCOCO test-dev. * denotes using bells and whistles at inference.

Method

YOLOv2 [25]
YOLOv3 [26]
SSD513 [23]
RetinaNet [21]

Backbone

DarkNet-19
Darknet-53
ResNet-101
ResNet-101

AP AP50 AP75 APS APM APL

21.6 44.0 19.2 5.0 22.4 35.5
33.0 57.9 34.4 18.3 35.4 41.9
31.2 50.4 33.3 10.2 34.5 49.8
39.1 59.1 42.3 21.8 42. 7 50.2

Faster R-CNN
Faster R-CNN by G-RMI [17]
Faster R-CNN
Mask R-CNN [12]
Cascade R-CNN [2]
Fitness NMS [34]
Deformable R-FCN [5] *
Deformable R-FCN* + Soft-NMS [1]
IoU-Net [18]

ResNet-101-FPN [20]
Inception-ResNet-v2 [30]

36.2 59.1 39.0 18.2 39.0 48.2
34.7 55.5 36.7 13.5 38.1 52.0
Inception-ResNet-v2-TDM [28] 36.8 57.7 39.2 16.2 39.8 52.1
38.2 60.3 41.7 20.1 41.1 50.2
42.8 62.1 46.3 23.7 45.5 55.2
41.8 60.9 44.9 21.5 45.0 57.5
37.5 58.0 40.8 19.4 40.1 52.5
23.3 43.6 53.3
40.9 62.8
-
40.6 59.0

ResNet-101-FPN
ResNet-101-FPN
DeNet-101 [33]
Aligned-Inception-ResNet
Aligned-Inception-ResNet
ResNet-101-FPN

-
-

-

-

Faster R-CNN +Rank-NMS
Faster R-CNN +Rank-NMS +Soft-NMS
Mask R-CNN +Rank-NMS
Mask R-CNN +Rank-NMS +Soft-NMS
Cascade R-CNN +Rank-NMS
Cascade R-CNN +Rank-NMS +Soft-NMS

ResNet-101-FPN
ResNet-101-FPN
ResNet-101-FPN
ResNet-101-FPN
ResNet-101-FPN
ResNet-101-FPN

41.0 60.8 44.5 23.2 44.5 52.5
41.3 60.7 45.3 23.5 44.9 52.9
41.6 61.3 45.4 23.7 45.1 53.5
42.0 61.1 46.2 23.9 45.5 53.9
43.2 61.8 47.0 24.6 46.2 55.4
43.7 61.6 48.1 24.9 46.8 56.1

Table 9. Analysis for the effects of the proposed Rank-NMS on different object detectors on MSCOCO 2017 validation set. We also report
the running speed, counted on a single Titan P100 GPU, to analyze the efﬁciency of Rank-NMS.

Backbone

ResNet-50-FPN

ResNet-101-FPN

Method
Faster R-CNN
Faster R-CNN
Cascade R-CNN
Cascade R-CNN
Mask R-CNN
Mask R-CNN
Faster R-CNN
Faster R-CNN
Cascade R-CNN
Cascade R-CNN
Mask R-CNN
Mask R-CNN

+Rank-NMS
✗
X
✗
X
✗
X
✗
X
✗
X
✗
X

Inf Time(fps) AP AP50 AP75 APS APM APL
46.6
50.9
53.2
54.8
48.2
52.2
49.8
53.7
57.4
57.2
51.3
55.1

39.1
41.7
43. 9
44.5
40.3
42.3
41.8
43.5
46.6
46.7
43.3
44.7

40.1
42.4
43 8.
44 3.
40.9
42.7
43.2
44.4
46.2
46.3
43.7
45.1

21.6
22.4
22.9
23.0
22.0
22.8
22.3
23.5
23.8
24.9
23.1
23.5

36.4
38.6
40.3
41.0
37.3
39.3
38.6
40.3
42.7
42.8
39.4
41.1

58.4
58.2
58.6
59.1
59.1
58.8
60.4
60.1
61.6
60.9
61.0
60.6

9.3
8.3
6.7
5.8
7.3
6.2
7.6
7.0
5.8
5.5
6.2
5.6

in Figure 4. We can see that the proposed Rank-NMS
can help generate more accurate detection results over tra-
ditional NMS under challenging scenarios, e.g., low-light
conditions (1st row), viewpoint variation (3rd row) and ob-
ject overlapping (5th row). These results further demon-
strate the effectiveness of the proposed Rank-NMS model
for proposal selection.

5. Conclusion

In this paper, we propose a novel Learning-to-Rank
(LTR) model to improve the proposal selection in the NSM

procedure. In particular, LTR introduces the ranking loss to
learn to predict the ranking score for the generated propos-
als from the region proposal networks, which provides more
reliable criterion for ranking the proposals. To facilitate the
training phase, we also propose a novel hard-pair sampling
strategy to select the discriminative proposal pairs for learn-
ing the ranking score. We implement the LTR model with a
small CNN, which can be inserted into current object detec-
tors for end-to-end training and inference. Comprehensive
experiments on multiple benchmarks demonstrate the out-
performing accuracy of the proposed Rank-NMS, together
with its generality to various object detectors.

8280

[21] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and
Piotr Doll´ar. Focal loss for dense object detection. In ICCV,
2017.

[22] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays,
Pietro Perona, Deva Ramanan, Piotr Dollr, and C. Lawrence
In
Zitnick. Microsoft coco: Common objects in context.
ECCV, 2014.

[23] Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian
Szegedy, Scott Reed, Cheng-Yang Fu, and Alexander C.
Berg. SSD: Single shot multibox detector. In ECCV, 2016.
[24] James Philbin, Ondrej Chum, Michael Isard, Josef Sivic, and
Andrew Zisserman. Object retrieval with large vocabularies
and fast spatial matching. In CVPR, 2007.

[25] Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali
Farhadi. You only look once: Uniﬁed, real-time object de-
tection. In CVPR, 2016.

[26] Joseph Redmon and Ali Farhadi. Yolov3: An incremental

improvement. CoRR, abs/1804.02767, 2018.

[27] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
Faster R-CNN: Towards real-time object detection with re-
gion proposal networks. In NIPS, 2015.

[28] Abhinav Shrivastava, Rahul Sukthankar, Jitendra Malik, and
Abhinav Gupta. Beyond skip connections: Top-down modu-
lation for object detection. arXiv preprint arXiv:1612.06851,
2016.

[29] Josef Sivic and Andrew Zisserman. Video Google: A text
In ICCV,

retrieval approach to object matching in videos.
2003.

[30] Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, and
Alex A. Alemi. Inception-v4, inception-resnet and the im-
pact of residual connections on learning. In ICLR Workshop,
2016.

[31] Yaniv Taigman, Ming Yang, Marc’Aurelio Ranzato, and Lior
Wolf. Deepface: Closing the gap to human-level perfor-
mance in face veriﬁcation. In CVPR, 2014.

[32] Alexander Toshev and Christian Szegedy. Deeppose: Human

pose estimation via deep neural networks. In CVPR, 2014.

[33] Lachlan Tychsen-Smith and Lars Petersson. Denet: Scalable
real-time object detection with directed sparse sampling. In
ICCV, 2017.

[34] Lachlan Tychsen-Smith and Lars Petersson. Improving ob-
ject localization with ﬁtness nms and bounded iou loss. In
CVPR, 2018.

[35] Paul Viola, Michael Jones, et al. Rapid object detection using

a boosted cascade of simple features. CVPR, 2001.

References

[1] Navaneeth Bodla, Bharat Singh, Rama Chellappa, and
Larry S. Davis. Soft-nms – improving object detection with
one line of code. In ICCV, 2017.

[2] Zhaowei Cai and Nuno Vasconcelos. Cascade R-CNN: delv-
ing into high quality object detection. In CVPR, 2018.
[3] Kai Chen, Jiangmiao Pang, Jiaqi Wang, Yu Xiong, Xiaox-
iao Li, Shuyang Sun, Wansen Feng, Ziwei Liu, Jianping
Shi, Wanli Ouyang, Chen Change Loy, and Dahua Lin.
mmdetection. https://github.com/open-mmlab/
mmdetection, 2018.

[4] Jifeng Dai, Yi Li, Kaiming He, and Jian Sun. R-fcn: Object
detection via region-based fully convolutional networks. In
NIPS, 2016.

[5] Jifeng Dai, Haozhi Qi, Yuwen Xiong, Yi Li, Guodong
Zhang, Han Hu, and Yichen Wei. Deformable convolutional
networks. In ICCV, 2017.

[6] Navneet Dalal and Bill Triggs. Histograms of oriented gra-

dients for human detection. In CVPR, 2005.

[7] Piotr Doll´ar, Christian Wojek, Bernt Schiele, and Pietro Per-
ona. Pedestrian detection: A benchmark. In CVPR, 2009.
[8] Mark Everingham, Luc Van Gool, Christopher KI Williams,
John Winn, and Andrew Zisserman. The pascal visual object
International journal of computer
classes (voc) challenge.
vision, 88(2):303–338, 2010.

[9] Pedro Felzenszwalb, Ross Girshick, and David McAllester.
Cascade object detection with deformable part models.
In
CVPR, 2010.

[10] Ross Girshick. Fast R-CNN. In ICCV, 2015.
[11] Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra
Malik. Rich feature hierarchies for accurate object detection
and semantic segmentation. In CVPR, 2014.

[12] Kaiming He, Georgia Gkioxari, Piotr Doll´ar, and Ross Gir-

shick. Mask R-CNN. In ICCV, 2017.

[13] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
Deep residual learning for image recognition. CVPR, 2016.
[14] Yihui He, Chenchen Zhu, Jianren Wang, Marios Savvides,
and Xiangyu Zhang. Bounding box regression with uncer-
tainty for accurate object detection. In CVPR, 2019.

[15] Jan Hosang, Rodrigo Benenson, and Bernt Schiele. Learning

non-maximum suppression. In CVPR, 2017.

[16] Han Hu, Jiayuan Gu, Zheng Zhang, Jifeng Dai, and Yichen
Wei. Relation networks for object detection. In CVPR, 2018.
[17] Jonathan Huang, Vivek Rathod, Chen Sun, Menglong Zhu,
Anoop Korattikara, Alireza Fathi, Ian Fischer, Zbigniew Wo-
jna, Yang Song, Sergio Guadarrama, and Kevin Murphy.
Speed/accuracy trade-offs for modern convolutional object
detectors. In CVPR, 2017.

[18] Borui Jiang, Ruixuan Luo, Jiayuan Mao, Tete Xiao, and Yun-
ing Jiang. Acquisition of localization conﬁdence for accurate
object detection. In ECCV, 2018.

[19] Xiaodan Liang, Tairui Wang, Luona Yang, and Eric Xing.
learning for

CIRL: controllable imitative reinforcement
vision-based self-driving. In ECCV, 2018.

[20] Tsung-Yi Lin, Piotr Doll´ar, Ross Girshick, Kaiming He,
Bharath Hariharan, and Serge Belongie. Feature pyramid
networks for object detection. In CVPR, 2017.

8281

