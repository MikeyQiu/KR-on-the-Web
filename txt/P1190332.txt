7
1
0
2
 
r
p
A
 
1
1
 
 
]

V
C
.
s
c
[
 
 
1
v
4
6
2
3
0
.
4
0
7
1
:
v
i
X
r
a

Learning Deep CNN Denoiser Prior for Image Restoration

Kai Zhang1,2, Wangmeng Zuo1, Shuhang Gu2, Lei Zhang2
1School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China
2Dept. of Computing, The Hong Kong Polytechnic University, Hong Kong, China
cskaizhang@gmail.com, wmzuo@hit.edu.cn, shuhanggu@gmail.com, cslzhang@comp.polyu.edu.hk

Abstract

Model-based optimization methods and discriminative
learning methods have been the two dominant strategies for
solving various inverse problems in low-level vision. Typi-
cally, those two kinds of methods have their respective mer-
its and drawbacks, e.g., model-based optimization methods
are ﬂexible for handling different inverse problems but are
usually time-consuming with sophisticated priors for the
purpose of good performance; in the meanwhile, discrim-
inative learning methods have fast testing speed but their
application range is greatly restricted by the specialized
task. Recent works have revealed that, with the aid of vari-
able splitting techniques, denoiser prior can be plugged in
as a modular part of model-based optimization methods to
solve other inverse problems (e.g., deblurring). Such an
integration induces considerable advantage when the de-
noiser is obtained via discriminative learning. However, the
study of integration with fast discriminative denoiser prior
is still lacking. To this end, this paper aims to train a set of
fast and effective CNN (convolutional neural network) de-
noisers and integrate them into model-based optimization
method to solve other inverse problems. Experimental re-
sults demonstrate that the learned set of denoisers not only
achieve promising Gaussian denoising results but also can
be used as prior to deliver good performance for various
low-level vision applications.

1. Introduction

Image restoration (IR) has been a long-standing prob-
lem for its highly practical value in various low-level vision
applications [1, 9, 47].
In general, the purpose of image
restoration is to recover the latent clean image x from its
degraded observation y = Hx + v, where H is a degrada-
tion matrix, v is additive white Gaussian noise of standard
deviation σ. By specifying different degradation matrices,
one can correspondingly get different IR tasks. Three clas-
sical IR tasks would be image denoising when H is an iden-
tity matrix, image deblurring when H is a blurring operator,

image super-resolution when H is a composite operator of
blurring and down-sampling.

Since IR is an ill-posed inverse problem, the prior which
is also called regularization needs to be adopted to con-
straint the solution space [50, 66]. From a Bayesian per-
spective, the solution ˆx can be obtained by solving a Maxi-
mum A Posteriori (MAP) problem,

ˆx = arg max

log p(y|x) + log p(x)

(1)

x

where log p(y|x) represents the log-likelihood of observa-
tion y, log p(x) delivers the prior of x and is independent
of y. More formally, Eqn. (1) can be reformulated as

ˆx = arg min

(cid:107)y − Hx(cid:107)2 + λΦ(x)

(2)

1
2

x

where the solution minimizes an energy function composed
of a ﬁdelity term 1
2 (cid:107)y − Hx(cid:107)2, a regularization term Φ(x)
and a trade-off parameter λ. The ﬁdelity term guarantees
the solution accords with the degradation process, while the
regularization term enforces desired property of the output.
Generally, the methods to solve Eqn. (2) can be divided
into two main categories, i.e., model-based optimization
methods and discriminative learning methods. The model-
based optimization methods aim to directly solve Eqn. (2)
with some optimization algorithms which usually involve a
time-consuming iterative inference. On the contrary, dis-
criminative learning methods try to learn the prior parame-
ters Θ and a compact inference through an optimization of
a loss function on a training set containing degraded-clean
image pairs [2, 13, 51, 55, 57]. The objective is generally
given by

1
2

x

s.t.

min
Θ

(cid:96)(ˆx, x)

ˆx = arg min

(cid:107)y−Hx(cid:107)2+λΦ(x; Θ)
(3)
Because the inference is guided by the MAP estimation, we
refer to such methods as MAP inference guided discrimi-
native learning methods. By replacing the MAP inference
with a predeﬁned nonlinear function ˆx = f (y, H; Θ), one

1

can treat the plain discriminative learning methods as gen-
eral case of Eqn. (3). It can be seen that one obvious dif-
ference between model-based optimization method and dis-
criminative learning method is that, the former is ﬂexible
to handle various IR tasks by specifying degradation matrix
H, whereas the later needs to use the training data with cer-
tain degradation matrices to learn the model. As a conse-
quence, different from model-based optimization methods
which have ﬂexibility to handle different IR tasks, discrimi-
native learning methods are usually restricted by specialized
tasks. For example, model-based optimization methods
such as NCSR [22] are ﬂexible to handle denoising, super-
resolution and deblurring, whereas discriminative learning
methods MLP [8], SRCNN [21], DCNN [62] are designed
for those three tasks, respectively. Even for a speciﬁc task
such as denoising, model-based optimization methods (e.g.,
BM3D [17] and WNNM [29]) can handle different noise
levels, whereas discriminative learning method of [34] sep-
arately train a different model for each level.

With the sacriﬁce of ﬂexibility, however, discriminative
learning methods can not only enjoy a fast testing speed
but also tend to deliver promising performance due to the
joint optimization and end-to-end training. On the con-
trary, model-based optimization methods are usually time-
consuming with sophisticated priors for the purpose of good
performance [27]. As a result, those two kinds of meth-
ods have their respective merits and drawbacks, and thus
it would be attractive to investigate their integration which
leverages their respective merits. Fortunately, with the aid
of variable splitting techniques, such as alternating direc-
tion method of multipliers (ADMM) method [5] and half-
quadratic splitting (HQS) method [28], it is possible to deal
with ﬁdelity term and regularization term separately [44],
and particularly, the regularization term only corresponds
to a denoising subproblem [18, 31, 61]. Consequently, this
enables an integration of any discriminative denoisers into
model-based optimization methods. However, to the best of
our knowledge, the study of integration with discriminative
denoiser is still lacking.

This paper aims to train a set of fast and effective
discriminative denoisers and integrate them into model-
based optimization methods to solve other inverse prob-
lems. Rather than learning MAP inference guided discrim-
inative models, we instead adopt plain convolutional neural
networks (CNN) to learn the denoisers, so as to take ad-
vantage of recent progress in CNN as well as the merit of
GPU computation. Particularly, several CNN techniques,
including Rectiﬁer Linear Units (ReLU) [37], batch nor-
malization [32], Adam [36], dilated convolution [63] are
adopted into the network design or training. As well as pro-
viding good performance for image denoising, the learned
set of denoisers are plugged in a model-based optimization
method to tackle various inverse problems.

The contribution of this work is summarized as follows:

• We trained a set of fast and effective CNN denoisers.
With variable splitting technique, the powerful denois-
ers can bring strong image prior into model-based op-
timization methods.

• The learned set of CNN denoisers are plugged in as
a modular part of model-based optimization methods
to tackle other inverse problems. Extensive experi-
ments on classical IR problems, including deblurring
and super-resolution, have demonstrated the merits of
integrating ﬂexible model-based optimization methods
and fast CNN-based discriminative learning methods.

2. Background

2.1. Image Restoration with Denoiser Prior

There have been several attempts to incorporate denoiser
prior into model-based optimization methods to tackle with
other inverse problems. In [19], the authors used Nash equi-
librium to derive an iterative decoupled deblurring BM3D
(IDDBM3D) method for image debluring. In [24], a simi-
lar method which is equipped with CBM3D denoiser prior
was proposed for single image super-resolution (SISR). By
iteratively updating a back-projection step and a CBM3D
denoising step, the method has an encouraging performance
for its PSNR improvement over SRCNN [21].
In [18],
the augmented Lagrangian method was adopted to fuse the
BM3D denoiser into an image deblurring scheme. With
a similar iterative scheme to [19], a plug-and-play priors
framework based on ADMM method was proposed in [61].
Here we note that, prior to [61], a similar idea of plug-
and-play is also mentioned in [66] where a half quadratic
splitting (HQS) method was proposed for image denois-
ing, deblurring and inpainting.
In [31], the authors used
an alternative to ADMM and HQS, i.e., the primal-dual
algorithm [11], to decouple ﬁdelity term and regulariza-
tion term. Some of the other related work can be found
in [6, 12, 48, 49, 54, 58]. All the above methods have shown
that the decouple of the ﬁdelity term and regularization term
can enable a wide variety of existing denoising models to
solve different image restoration tasks.

We can see that the denoiser prior can be plugged in an
iterative scheme via various ways. The common idea be-
hind those ways is to decouple the ﬁdelity term and reg-
ularization term. For this reason, their iterative schemes
generally involve a ﬁdelity term related subproblem and a
denoising subproblem. In the next subsection, we will use
HQS method as an example due to its simplicity. It should
be noted that although the HQS can be viewed as a gen-
eral way to handle different image restoration tasks, one can
also incorporate the denoiser prior into other convenient and
proper optimization methods for a speciﬁc application.

2

2.2. Half Quadratic Splitting (HQS) Method

3. Learning Deep CNN Denoiser Prior

1
2

x

1
2

Basically, to plug the denoiser prior into the optimiza-
tion procedure of Eqn. (2), the variable splitting technique
is usually adopted to decouple the ﬁdelity term and regular-
ization term. In half quadratic splitting method, by intro-
ducing an auxiliary variable z, Eqn. (2) can be reformulated
as a constrained optimization problem which is given by

ˆx = arg min

(cid:107)y − Hx(cid:107)2 + λΦ(z)

s.t. z = x (4)

Then, HQS method tries to minimize the following cost
function

Lµ(x, z) =

(cid:107)y − Hx(cid:107)2 + λΦ(z) +

(cid:107)z − x(cid:107)2

(5)

µ
2

where µ is a penalty parameter which varies iteratively in a
non-descending order. Eqn. (5) can be solved via the fol-
lowing iterative scheme,




xk+1 = arg min



zk+1 = arg min

(cid:107)y − Hx(cid:107)2 + µ(cid:107)x − zk(cid:107)2 (6a)
µ
2

(cid:107)z − xk+1(cid:107)2 + λΦ(z)

(6b)

x

z

As one can see, the ﬁdelity term and regularization term are
decoupled into two individual subproblems. Speciﬁcally,
the ﬁdelity term is associated with a quadratic regularized
least-squares problem (i.e., Eqn. (6a)) which has various
fast solutions for different degradation matrices. A direct
solution is given by

xk+1 = (HT H + µI)−1(HT y + µzk)

(7)

The regularization term is involved in Eqn. (6b) which can
be rewritten as

zk+1 = arg min

z

1
2((cid:112)λ/µ)2

(cid:107)xk+1 − z(cid:107)2 + Φ(z)

(8)

(9)

According to Bayesian probability, Eqn. (8) corresponds
to denoising the image xk+1 by a Gaussian denoiser with
noise level (cid:112)λ/µ. As a consequence, any Gaussian de-
noisers can be acted as a modular part to solve Eqn. (2). To
address this, we rewrite Eqn. (8) by following
zk+1 = Denoiser(xk+1, (cid:112)λ/µ)
It is worth noting that, according to Eqns. (8) and (9), the
image prior Φ(·) can be implicitly replaced by a denoiser
prior. Such a promising property actually offers several ad-
vantages. First, it enables to use any gray or color denois-
ers to solve a variety of inverse problems. Second, the ex-
plicit image prior Φ(·) can be unknown in solving Eqn. (2).
Third, several complementary denoisers which exploit dif-
ferent image priors can be jointly utilized to solve one spe-
ciﬁc problem. Note that this property can be also em-
ployed in other optimization methods (e.g., iterative shrink-
age/thresholding algorithms ISTA [4, 14] and FISTA [3]) as
long as there involves a denoising subproblem.

3.1. Why Choose CNN Denoiser?

As the regularization term of Eqn. (2) plays a vital role in
restoration performance, the choice of denoiser priors thus
would be pretty important in Eqn. (9). Existing denoiser
priors that have been adopted in model-based optimization
methods to solve other inverse problems include total varia-
tion (TV) [10, 43], Gaussian mixture models (GMM) [66],
K-SVD [25], non-local means [7] and BM3D [17]. Such de-
noiser priors have their respective drawbacks. For example,
TV can create watercolor-like artifacts; K-SVD denoiser
prior suffers high computational burden; non-local means
and BM3D denoiser priors may over-smooth the irregular
structures if the image does not exhibit self-similarity prop-
erty. Thus, strong denoiser prior which can be implemented
efﬁciently is highly demanded.

Regardless of the speed and performance, color image
prior or denoiser is also a key factor that needs to be taken
into account. This is because most of the images acquired
by modern cameras or transmitted in internet are in RGB
format. Due to the correlation between different color chan-
nels, it has been acknowledged that jointly handling the
color channels tends to produce better performance than in-
dependently dealing with each color channel [26]. How-
ever, existing methods mainly focus on modeling gray im-
age prior and there are only a few works concentrating
on modeling color image prior (see, e.g.,
[16, 41, 46]).
Perhaps the most successful color image prior modeling
method is CBM3D [16]. It ﬁrst decorrelates the image into
a luminance-chrominance color space by a hand-designed
linear transform and then applies the gray BM3D method
in each transformed color channels. While CBM3D is
promising for color image denoising, it has been pointed
out that the resulting transformed luminance-chrominance
color channels still remain some correlation [42] and it is
preferable to jointly handle RGB channels. Consequently,
instead of utilizing the hand-designed pipeline, using dis-
criminative learning methods to automatically reveal the un-
derlying color image prior would be a good alternative.

By considering the speed, performance and discrimina-
tive color image prior modeling, we choose deep CNN to
learn the discriminative denoisers. The reasons of using
CNN are four-fold. First, the inference of CNN is very ef-
ﬁcient due to the parallel computation ability of GPU. Sec-
ond, CNN exhibits powerful prior modeling capacity with
deep architecture. Third, CNN exploits the external prior
which is complementary to the internal prior of many ex-
isting denoisers such as BM3D. In other words, a combina-
tion with BM3D is expected to improve the performance.
Fourth, great progress in training and designing CNN have
been made during the past few years and we can take advan-
tage of those progress to facilitate discriminative learning.

3

Figure 1. The architecture of the proposed denoiser network. Note that “s-DConv” denotes s-dilated convolution [63], here s = 1, 2, 3 and
4; “BNorm” represents batch normalization [32]; “ReLU” is the rectiﬁed linear units (max(·, 0)).

3.2. The Proposed CNN Denoiser

The architecture of the proposed CNN denoiser is illus-
It consists of seven layers with three
trated in Figure 1.
different blocks, i.e., “Dilated Convolution+ReLU” block
in the ﬁrst layer, ﬁve “Dilated Convolution+Batch Normal-
ization+ReLU” blocks in the middle layers, and “Dilated
Convolution” block in the last layer. The dilation factors of
(3×3) dilated convolutions from ﬁrst layer to the last layer
are set to 1, 2, 3, 4, 3, 2 and 1, respectively. The number
of feature maps in each middle layer is set to 64. In the fol-
lowing, we will give some important details in our network
design and training.

Using Dilated Filter to Enlarge Receptive Field. It has
been widely acknowledged that the context information fa-
cilitates the reconstruction of the corrupted pixel in image
denoising. In CNN, to capture the context information, it
successively enlarges the receptive ﬁeld through the for-
ward convolution operations. Generally, there are two basic
ways to enlarge the receptive ﬁeld of CNN, i.e., increas-
ing the ﬁlter size and increasing the depth. However, in-
creasing the ﬁlter size would not only introduce more pa-
rameters but also increase the computational burden [53].
Thus, using 3×3 ﬁlter with a large depth is popularized in
existing CNN network design [30, 35, 56]. In this paper,
we instead use the recent proposed dilated convolution to
make a tradeoff between the size of receptive ﬁled and net-
work depth. Dilated convolution is known for its expansion
capacity of the receptive ﬁeld while keeping the merits of
traditional 3×3 convolution. A dilated ﬁlter with dilation
factor s can be simply interpreted as a sparse ﬁlter of size
(2s+1)×(2s+1) where only 9 entries of ﬁxed positions can
be non-zeros. Hence, the equivalent receptive ﬁeld of each
layer is 3, 5, 7, 9, 7, 5 and 3. Consequently, it can be eas-
ily obtained that the receptive ﬁled of the proposed network
is 33×33. If the traditional 3×3 convolution ﬁlter is used,
the network will either have a receptive ﬁled of size 15×15
with the same network depth (i.e., 7) or have a depth of 16
with the same receptive ﬁled (i.e., 33×33). To show the

advantage of our design over the above two cases, we have
trained three different models on noise level 25 with same
training settings. It turns out that our designed model can
have an average PSNR of 29.15dB on BSD68 dataset [50],
which is much better than 28.94dB of 7 layers network with
traditional 3×3 convolution ﬁlter and very close to 29.20dB
of 16 layers network.

Using Batch Normalization and Residual Learning to
Accelerate Training. While advanced gradient optimiza-
tion algorithms can accelerate training and improve the per-
formance, the architecture design is also an important fac-
tor. Batch normalization and residual learning which are
two of the most inﬂuential architecture design techniques
have been widely adopted in recent CNN architecture de-
signs. In particular, it has been pointed out that the combi-
nation of batch normalization and residual learning is par-
ticularly helpful for Gaussian denoising since they are ben-
eﬁcial to each other. To be speciﬁc, it not only enables fast
and stable training but also tends to result in better denois-
ing performance [65]. In this paper, such strategy is adopted
and we empirically ﬁnd it also can enable fast transfer from
one model to another with different noise level.

Using Training Samples with Small Size to Help Avoid
Boundary Artifacts. Due to the characteristic of convolu-
tion, the denoised image of CNN may introduce annoying
boundary artifacts without proper handling. There are two
common ways to tackle with this, i.e., symmetrical padding
and zero padding. We adopt the zero padding strategy and
wish the designed CNN has the capacity to model image
boundary. Note that the dilated convolution with dilation
factor 4 in the fourth layer pads 4 zeros in the boundaries
of each feature map. We empirically ﬁnd that using training
samples with small size can help avoid boundary artifacts.
The main reason lies in the fact that, rather than using train-
ing patches of large size, cropping them into small patches
can enable CNN to see more boundary information. For ex-
ample, by cropping an image patch of size 70×70 into four
small non-overlap patches of size 35×35, the boundary in-

4

formation would be largely augmented. We also have tested
the performance by using patches of large size, we empiri-
cally ﬁnd this does not improve the performance. However,
if the size of the training patch is smaller than the receptive
ﬁeld, the performance would decrease.

Learning Speciﬁc Denoiser Model with Small Interval
Noise Levels. Since the iterative optimization framework
requires various denoiser models with different noise lev-
els, a practical issue on how to train the discriminative mod-
els thus should be taken into consideration. Various studies
have shown that if the exact solutions of subproblems (i.e.,
Eqn. (6a) and Eqn. (6b)) are difﬁcult or time-consuming to
optimize, then using an inexact but fast subproblem solu-
tion may accelerate the convergence [39, 66].
In this re-
spect, their is no need to learn many discriminative denoiser
models for each noise level. On the other hand, although
Eqn. (9) is a denoiser, it has a different goal from the tradi-
tional Gaussian denoising. The goal of traditional Gaussian
denoising is to recover the latent clean image, however, the
denoiser here just acts its own role regardless of the noise
type and noise level of the image to be denoised. There-
fore, the ideal discriminative denoiser in Eqn. (9) should be
trained by current noise level. As a result, there is tradeoff
to set the number of denoisers. In this paper, we trained a
set of denoisers on noise level range [0, 50] and divided it by
a step size of 2 for each model, resulting in a set of 25 de-
noisers for each gray and color image prior modelling. Due
to the iterative scheme, it turns out the noise level range of
[0, 50] is enough to handle various image restoration prob-
lems. Especially noteworthy is the number of the denoisers
which is much less than that of learning different models for
different degradations.

4. Experiments

The Matlab source code of the proposed method can be
downloaded at https://github.com/cszn/ircnn.

4.1. Image Denoising

It is widely acknowledged that convolutional neural net-
works generally beneﬁt from the availability of large train-
ing data. Hence, instead of training on a small dataset con-
sisting of 400 Berkeley segmentation dataset (BSD) images
of size 180×180 [13], we collect a large dataset which in-
cludes 400 BSD images, 400 selected images from valida-
tion set of ImageNet database [20] and 4,744 images of Wa-
terloo Exploration Database [40]. We empirically ﬁnd using
large dataset does not improve the PSNR results of BSD68
dataset [50] but can slightly improve the performance of
other testing images. We crop the images into small patches
of size 35×35 and select N =256×4,000 patches for train-
ing. As for the generation of corresponding noisy patches,
we achieve this by adding additive Gaussian noise to the

Table 1. The average PSNR(dB) results of different methods on
(gray) BSD68 dataset.

Methods
σ = 15
σ = 25
σ = 50

BM3D
31.07
28.57
25.62

WNNM
31.37
28.83
25.87

TNRD
31.42
28.92
25.97

MLP
-
28.96
26.03

Proposed
31.63
29.15
26.19

Table 2. The average PSNR(dB) results of CBM3D and proposed
CNN denoiser on (color) BSD68 dataset.

Noise Level
CBM3D
Proposed

5
40.24
40.36

15
33.52
33.86

25
30.71
31.16

35
28.89
29.50

50
27.38
27.86

clean patches during training. Since the residual learning
strategy is adopted, we use the following loss function,

(cid:96)(Θ) =

(cid:107)f (yi; Θ) − (yi − xi)(cid:107)2
F

(10)

1
2N

N
(cid:88)

i=1

where {(yi, xi)}N
i=1 represents N noisy-clean patch pairs.
To optimize the network parameters Θ,
the Adam
solver [36] is adopted. The step size is started from 1e−3
and then ﬁxed to 1e−4 when the training error stops de-
creasing. The training was terminated if the training error
was ﬁxed in ﬁve sequential epochs. For the other hyper-
parameters of Adam, we use their default setting. The mini-
batch size is set to 256. Rotation or/and ﬂip based data aug-
mentation is used during mini-batch learning. The denoiser
models are trained in Matlab (R2015b) environment with
MatConvNet package [60] and an Nvidia Titan X GPU. To
reduce the whole training time, once a model is obtained,
we initialize the adjacent denoiser with this model. It takes
about three days to train the set of denoiser models.

We compared the proposed denioser with several state-
of-the-art denoising methods, including two model-based
optimization methods (i.e., BM3D [17] and WNNM [29]),
two discriminative learning methods (i.e., MLP [8] and
TNRD [13]). The gray image denoising results of different
methods on BSD68 dataset are shown in Table 1. It can be
seen that WNNM, MLP and TNRD can outperform BM3D
by about 0.3dB in PSNR. However, the proposed CNN de-
noiser can have a PSNR gain of about 0.2dB over those
three methods. Table 2 shows the color image denoising
results of benchmark CBM3D and our proposed CNN de-
noiser, it can be seen that the proposed denoiser consistently
outperforms CBM3D by a large margin. Such a promising
result can be attributed to the powerful color image prior
modeling capacity of CNN.

For the run time, we compared with BM3D and TNRD
due to their potential value in practical applications. Since
the proposed denoiser and TNRD support parallel compu-
tation on GPU, we also give the GPU run time. To make a
further comparison with TNRD under similar PSNR perfor-

5

mance, we additionally provide the run time of the proposed
denoiser where each middle layer has 24 feature maps. We
use the Nvidia cuDNN-v5 deep learning library to acceler-
ate the GPU computation and the memory transfer time be-
tween CPU and GPU is not considered. Table 3 shows the
run times of different methods for denoising images of size
256×256, 512×512 and 1024×1024 with noise level 25.
We can see that the proposed denoiser is very competitive
in both CPU and GPU implementation. It is worth empha-
sizing that the proposed denoiser with 24 feature maps of
each layer has a comparable PSNR of 28.94dB to TNRD but
delivers a faster speed. Such a good compromise between
speed and performance over TNRD is properly attributed to
the following three reasons. First, the adopted 3×3 convo-
lution and ReLU nonlinearity are simple yet effective and
efﬁcient. Second, in contrast to the stage-wise architecture
of TNRD which essentially has a bottleneck in each imme-
diate output layer, ours encourages a ﬂuent information ﬂow
among different layers, thus having larger model capacity.
Third, batch normalization which is beneﬁcial to Gaussian
denoising is adopted. According to the above discussions,
we can conclude that the proposed denoiser is a strong com-
petitor against BM3D and TNRD.

Table 3. Run time (in seconds) of different methods on images of
size 256×256, 512×512 and 1024×1024 with noise level 25.

Size

256×256

512×512

1024×1024

Device
CPU
GPU
CPU
GPU
CPU
GPU

BM3D
0.66
-
2.91
-
11.89
-

TNRD
0.47
0.010
1.33
0.032
4.61
0.116

Proposed24 Proposed64

0.10
0.006
0.39
0.016
1.60
0.059

0.310
0.012
1.24
0.038
4.65
0.146

4.2. Image Deblurring

As a common setting, the blurry images are synthesized
by ﬁrst applying a blur kernel and then adding additive
Gaussian noise with noise level σ. In addition, we assume
the convolution is carried out with circular boundary con-
ditions. Thus, an efﬁcient implementation of Eqn. (7) by
using Fast Fourier Transform (FFT) can be employed. To
make a thorough evaluation, we consider three blur kernels,
including a commonly-used Gaussian kernel with standard
deviation 1.6 and the ﬁrst two of the eight real blur kernels
from [38]. As shown in Table 4, we also consider Gaussian

(a)

(b)

(c)

(d)

(e)

(f)

Figure 2. Six testing images for image deblurring. (a) Cameraman;
(b) House; (c) Lena; (d) Monarch; (e) Leaves; (f) Parrots.

6

noise with different noise levels. For the compared meth-
ods, we choose one discriminative method named MLP [52]
and three model based optimization methods, including ID-
DBM3D [19], NCSR [22] and EPLL. Among the testing
images, apart from three classical gray images as shown
in Figure 2, three color images are also included such that
we can test the performance of learned color denoiser prior.
In the meanwhile, we note that the above methods are de-
signed for gray image deblurring. Specially, NCSR tackles
the color input by ﬁrst transforming it into YCbCr space and
then conducting the main algorithm in the luminance com-
ponent. In the following experiments, we simply plug the
color denoisers into the HQS framework, whereas we sep-
arately handle each color channel for IDDBM3D and MLP.
Note that MLP trained a speciﬁc model for the Gaussian
blur kernel with noise level 2.

Once the denoisers are provided, the subsequent crucial
issue would be parameter setting. From Eqns. (6), we can
note that there involve two parameters, λ and µ, to tune.
Generally, for a certain degradation, λ is correlated with
σ2 and keeps ﬁxed during iterations, while µ controls noise
level of denoiser. Since the HQS framework is denoiser-
based, we instead set the noise level of denoiser in each
iteration to implicitly determine µ. Note that the noise level
of denoiser (cid:112)λ/µ should be set from large to small.
In
our experimental settings, it is decayed exponentially from
49 to a value in [1, 15] depending on the noise level. The
number of iterations is set to 30 as we ﬁnd it is large enough
to obtain a satisfying performance.

The PSNR results of different methods are shown in Ta-
ble 4. As one can see, the proposed CNN denoiser prior
based optimization method achieves very promising PSNR
results. Figure 3 illustrates deblurred Leaves image by dif-
ferent methods. We can see that IDDBM3D, NCSR and
MLP tend to smooth the edges and generate color artifacts.
In contrast, the proposed method can recover image sharp-
ness and naturalness.

Table 4. Deblurring results of different methods.
Leaves

σ
Gaussian blur with standard deviation 1.6

C.man House

Monar.

Lena

Kernel 1 (19×19) [38]

27.08
27.99
27.84
28.12

29.43
32.07
25.33
28.11

29.67
31.69
24.85
27.70

32.41
33.38
33.43
33.80

31.48
35.17
28.19
32.03

32.26
35.04
28.08
31.94

30.28
30.99
31.10
31.17

31.68
33.88
27.37
29.51

31.00
33.53
27.03
29.27

Kernel 2 (17×17) [38]

27.02
28.32
28.87
30.00

28.75
33.62
22.67
29.20

27.53
33.13
21.60
28.73

26.95
27.50
28.91
29.78

27.34
33.92
21.67
29.07

26.75
33.51
21.09
28.63

2

2.55

7.65

2.55

7.65

Methods

IDDBM3D
NCSR
MLP
Proposed

EPLL
Proposed
EPLL
Proposed

EPLL
Proposed
EPLL
Proposed

Parrots

30.15
30.42
31.24
32.07

30.89
35.49
26.08
31.63

30.44
35.17
25.77
31.35

(a) Blurry and noisy image

(b) IDDBM3D (26.95dB)

(c) NCSR (27.50dB)

(d) MLP (28.91dB)

(e) Proposed (29.78dB)

Figure 3. Image deblurring performance comparison for Leaves image (the blur kernel is Gaussian kernel with standard deviation 1.6, the
noise level σ is 2).

4.3. Single Image Super-Resolution

In general, the low-resolution (LR) image can be mod-
eled by a blurring and subsequent down-sampling opera-
tion on a high-resolution one. The existing super-resolution
models, however, mainly focus on modeling image prior
and are trained for speciﬁc degradation process. This makes
the learned model deteriorates seriously when the blur ker-
nel adopted in training deviates from the real one [23, 64].
Instead, our model can handle any blur kernels without re-
training. Thus, in order to thoroughly evaluate the ﬂexibil-
ity of the CNN denoiser prior based optimization method
as well as the effectiveness of the CNN denoisers, follow-
ing [45], this paper considers three typical image degrada-
tion settings for SISR, i.e., bicubic downsampling (default
setting of Matlab function imresize) with two scale fac-
tors 2 and 3 [15, 21] and blurring by Gaussian kernel of size
7×7 with standard deviation 1.6 followed by downsampling
with scale factor 3 [22, 45].

Inspired by the method proposed in [24] which itera-
tively updates a back-projection [33] step and a denoising
step for SISR, we use the following back-projection itera-
tion to solve Eqn. (6a),

xk+1 = xk − α(y − xk ↓sf) ↑sf

bicubic

(11)

where ↓sf denotes the degradation operator with downscal-
ing factor sf, ↑sf
bicubic represents bicubic interpolation opera-
tor with upscaling factor sf, and α is the step size. It is wor-
thy noting that the iterative regularization step of methods
such as NCSR and WNNM actually corresponds to solv-
ing Eqn. (6a). From this viewpoint, those methods are opti-
mized under HQS framework. Here, note that only the bicu-
bic downsampling is considered in [24], whereas Eqn. (11)
is extended to deal with different blur kernels. To obtain a
fast convergence, we repeat Eqn. (11) ﬁve times before ap-
plying the denoising step. The number of main iterations is
set to 30, the step size α is ﬁxed to 1.75 and the noise levels
of denoiser are decayed exponentially from 12×sf to sf.

The proposed deep CNN denoiser prior based SISR
method is compared with ﬁve state-of-the-art methods, in-

cluding two CNN-based discriminative learning methods
(i.e., SRCNN [21] and VDSR [35]), one statistical pre-
diction model based discriminative learning method [45]
which we refer to as SPMSR, one model based optimiza-
tion method (i.e., NCSR [22]) and one denoiser prior based
method (i.e., SRBM3D [24]). Except for SRBM3D, all
the existing methods conducted their main algorithms on Y
channel (i.e., luminance) of transformed YCbCr space. In
order to evaluate the proposed color denoiser prior, we also
conduct experiments on the original RGB channels and thus
the PSNR results of super-resolved RGB images of different
methods are also given. Since the source code of SRBM3D
is not available, we also compare two methods which re-
place the proposed CNN denoiser with BM3D/CBM3D de-
noiser. Those two methods are denoted by SRBM3DG and
SRBM3DC, respectively.

Table 5 shows the average PSNR(dB) results of differ-
ent methods for SISR on Set5 and Set14 [59]. Note that
SRCNN and VDSR are trained with bicubic blur kernel,
thus it is unfair to use their models to super-resolve the
low-resolution image with Gaussian kernel. As a matter of
fact, we give their performances to demonstrate the limita-
tions of such discriminative learning methods. From Ta-
ble 5, we can have several observations. First, although
SRCNN and VDSR achieve promising results to tackle the
case with bicubic kernel, their performance deteriorates se-
riously when the low-resolution image are not generated
by bicubic kernel (see Figure 4). On the other hand, with
the accurate blur kernel, even NCSR and SPMSR outper-
form SRCNN and VDSR for Gaussian blur kernel. In con-
trast, the proposed methods (denoted by ProposedG and
ProposedC) can handle all the cases well. Second, the pro-
posed methods have a better PSNR result than SRBM3DC
and SRBM3DG which indicates good denoiser prior facil-
itates to solve super-resolution problem. Third, both of
the gray and color CNN denoiser prior based optimization
methods can produce promising results. As an example for
the testing speed comparison, our method can super-resolve
the Butterﬂy image in 0.5 second on GPU and 12 seconds
on CPU, whereas NCSR spends 198 seconds on CPU.

7

Table 5. Average PSNR(dB) results of different methods for single image super-resolution on Set5 and Set14.

Dataset

Scale

Kernel

SRBM3DG SRBM3DC ProposedG ProposedC

Set5

Set14

Bicubic

Bicubic

Gaussian

Bicubic

Bicubic

Gaussian

Channel
Y
RGB
Y
RGB
Y
RGB
Y
RGB
Y
RGB
Y
RGB

SRCNN
36.65
34.45
32.75
30.72
30.42
28.50
32.43
30.43
29.27
27.44
27.71
26.02

VDSR
37.56
35.16
33.67
31.50
30.54
28.62
33.02
30.90
29.77
27.85
27.80
26.11

NCSR
-
-
-
-
33.02
30.00
-
-
-
-
29.26
26.98

SPMSR
36.11
33.94
32.31
30.32
32.27
30.02
31.96
30.05
28.93
27.17
28.89
27.01

SRBM3D
37.10
-
33.30
-
-
-
32.80
-
29.60
-
-
-

36.34
34.11
32.62
30.57
32.66
30.31
32.09
30.15
29.11
27.32
29.18
27.24

2

3

3

2

3

3

36.25
34.22
32.54
30.69
32.59
30.74
32.25
30.32
29.27
27.47
29.39
27.60

37.43
35.05
33.39
31.26
33.38
30.92
32.88
30.79
29.61
27.72
29.63
27.59

37.22
35.07
33.18
31.25
33.17
31.21
32.79
30.78
29.50
27.67
29.55
27.70

(a) Ground-truth

(b) Zoomed LR image

(c) SRCNN (24.46dB)

(d) VDSR (24.73dB)

(e) ProposedG (29.32dB)

Figure 4. Single image super-resolution performance comparison for Butterﬂy image from Set5 (the blur kernel is 7×7 Gaussian kernel
with standard deviation 1.6, the scale factor is 3). Note that the comparison with SRCNN and VDSR is unfair. The proposed deep CNN
denoiser prior based optimization method can super-resolve the LR image by tuning the blur kernel and scale factor without training,
whereas SRCNN and VDSR need additional training to deal with such cases. As a result, this ﬁgure is mainly used to show the ﬂexibility
advantage of the proposed deep CNN denoiser prior based optimization method over discriminative learning methods.

5. Conclusion

In this paper, we have designed and trained a set of fast
and effective CNN denoisers for image denoising. Spe-
cially, with the aid of variable splitting technique, we have
plugged the learned denoiser prior into a model-based opti-
mization method of HQS to solve the image deblurring and
super-resolution problems. Extensive experimental results
have demonstrated that the integration of model-based op-
timization method and discriminative CNN denoiser results
in a ﬂexible, fast and effective framework for various image
restoration tasks. On the one hand, different from conven-
tional model-based optimization methods which are usually
time-consuming with sophisticated image priors for the pur-
pose of achieving good results, the proposed deep CNN de-
noiser prior based optimization method can be implemented
effectively due to the plug-in of fast CNN denoisers. On the
other hand, different from discriminative learning methods
which are specialized for certain image restoration tasks,
the proposed deep CNN denoiser prior based optimization
method is ﬂexible in handling various tasks while can pro-
duce very favorable results. In summary, this work high-
lights the potential beneﬁts of integrating ﬂexible model-
based optimization methods and fast discriminative learning
methods. In addition, this work has shown that learning ex-
pressive CNN denoiser prior is a good alternative to model
image prior.

While we have demonstrated various merits of plug-
ging powerful CNN denoiser into model-based optimiza-
tion methods, there also remain room for further study.
Some research directions are listed as follows. First, it will
be interesting to investigate how to reduce the number of
the discriminative CNN denoisers and the number of whole
iterations. Second, extending the proposed CNN denoiser
based HQS framework to other inverse problems such as
inpainting and blind deblurring would be also interesting.
Third, utilizing multiple priors which are complementary
to improve performance is certainly one promising direc-
tion. Finally, and perhaps most interestingly, since the HQS
framework can be treated as a MAP inference, this work
also provides some insights into designing CNN architec-
ture for task-speciﬁc discriminative learning. Meanwhile,
one should be aware that CNN has its own design ﬂexibility
and the best CNN architecture is not necessarily inspired by
MAP inference.

6. Acknowledgements

This work is supported by HK RGC General Research
Fund (PolyU 5313/13E) and National Natural Science
Foundation of China (grant no. 61672446, 61671182). We
gratefully acknowledge the support from NVIDIA Corpora-
tion for providing us the Titan X GPU used in this research.

8

References

[1] H. C. Andrews and B. R. Hunt. Digital image restoration.
Prentice-Hall Signal Processing Series, Englewood Cliffs:
Prentice-Hall, 1977, 1, 1977.

[2] A. Barbu. Training an active random ﬁeld for real-time im-
IEEE Transactions on Image Processing,

age denoising.
18(11):2451–2462, 2009.

[3] A. Beck and M. Teboulle. A fast iterative shrinkage-
thresholding algorithm for linear inverse problems. SIAM
journal on imaging sciences, 2(1):183–202, 2009.

[4] J. M. Bioucas-Dias and M. A. Figueiredo. A new TwIST:
Two-step iterative shrinkage/thresholding algorithms for im-
IEEE Transactions on Image Processing,
age restoration.
16(12):2992–3004, 2007.

[5] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein. Dis-
tributed optimization and statistical learning via the alternat-
ing direction method of multipliers. Foundations and Trends
in Machine Learning, 3(1):1–122, 2011.

[6] A. Brifman, Y. Romano, and M. Elad. Turning a denoiser
In IEEE
into a super-resolver using plug and play priors.
International Conference on Image Processing, pages 1404–
1408, 2016.

[8] H. C. Burger, C. J. Schuler, and S. Harmeling.

[7] A. Buades, B. Coll, and J.-M. Morel. A non-local algorithm
for image denoising. In IEEE Conference on Computer Vi-
sion and Pattern Recognition, volume 2, pages 60–65, 2005.
Image de-
noising: Can plain neural networks compete with BM3D? In
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 2392–2399, 2012.

[9] P. Campisi and K. Egiazarian. Blind image deconvolution:

theory and applications. CRC press, 2016.

[10] A. Chambolle. An algorithm for total variation minimiza-
tion and applications. Journal of Mathematical imaging and
vision, 20(1-2):89–97, 2004.

[11] A. Chambolle and T. Pock. A ﬁrst-order primal-dual al-
gorithm for convex problems with applications to imaging.
Journal of Mathematical Imaging and Vision, 40(1):120–
145, 2011.

[12] S. H. Chan, X. Wang, and O. A. Elgendy. Plug-and-Play
ADMM for image restoration: Fixed-point convergence and
applications. IEEE Transactions on Computational Imaging,
3(1):84–98, 2017.

[13] Y. Chen and T. Pock. Trainable nonlinear reaction diffusion:
A ﬂexible framework for fast and effective image restoration.
IEEE transactions on Pattern Analysis and Machine Intelli-
gence, 2016.

[14] P. L. Combettes and V. R. Wajs. Signal recovery by proximal
forward-backward splitting. Multiscale Modeling & Simula-
tion, 4(4):1168–1200, 2005.

[15] Z. Cui, H. Chang, S. Shan, B. Zhong, and X. Chen. Deep
In European

network cascade for image super-resolution.
Conference on Computer Vision, pages 49–64, 2014.
[16] K. Dabov, A. Foi, V. Katkovnik, and K. Egiazarian. Color
image denoising via sparse 3D collaborative ﬁltering with
grouping constraint in luminance-chrominance space.
In
IEEE International Conference on Image Processing, vol-
ume 1, pages I–313, 2007.

[17] K. Dabov, A. Foi, V. Katkovnik, and K. Egiazarian.

Im-
age denoising by sparse 3-D transform-domain collabora-

tive ﬁltering.
16(8):2080–2095, 2007.

IEEE Transactions on Image Processing,

[18] A. Danielyan, V. Katkovnik, and K. Egiazarian. Image de-
blurring by augmented lagrangian with BM3D frame prior.
In Workshop on Information Theoretic Methods in Science
and Engineering, pages 16–18, 2010.

[19] A. Danielyan, V. Katkovnik, and K. Egiazarian. BM3D
frames and variational image deblurring. IEEE Transactions
on Image Processing, 21(4):1715–1728, 2012.

[20] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-
Fei. Imagenet: A large-scale hierarchical image database. In
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 248–255, 2009.

[21] C. Dong, C. C. Loy, K. He, and X. Tang.

Image
IEEE
super-resolution using deep convolutional networks.
transactions on Pattern Analysis and Machine Intelligence,
38(2):295–307, 2016.

[22] W. Dong, L. Zhang, G. Shi, and X. Li. Nonlocally central-
ized sparse representation for image restoration. IEEE Trans-
actions on Image Processing, 22(4):1620–1630, 2013.
[23] N. Efrat, D. Glasner, A. Apartsin, B. Nadler, and A. Levin.
Accurate blur models vs. image priors in single image super-
resolution. In IEEE International Conference on Computer
Vision, pages 2832–2839, 2013.
[24] K. Egiazarian and V. Katkovnik.

Single image super-
In European Signal

resolution via BM3D sparse coding.
Processing Conference, pages 2849–2853, 2015.

[25] M. Elad and M. Aharon.

Image denoising via sparse
and redundant representations over learned dictionaries.
IEEE Transactions on Image processing, 15(12):3736–3745,
2006.

[26] A. Foi, V. Katkovnik, and K. Egiazarian.

Pointwise
shape adaptive DCT denoising with structure preservation
in luminance-chrominance space. In International Workshop
on Video Processing and Quality Metrics for Consumer Elec-
tronics, 2006.

[27] Q. Gao and S. Roth. How well do ﬁlter-based MRFs model
In Joint DAGM (German Association for
natural images?
Pattern Recognition) and OAGM Symposium, pages 62–72,
2012.

[28] D. Geman and C. Yang. Nonlinear image recovery with half-
quadratic regularization. IEEE Transactions on Image Pro-
cessing, 4(7):932–946, 1995.

[29] S. Gu, L. Zhang, W. Zuo, and X. Feng. Weighted nuclear
norm minimization with application to image denoising. In
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 2862–2869, 2014.

[30] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning
In IEEE Conference on Computer

for image recognition.
Vision and Pattern Recognition, pages 770–778, 2016.
[31] F. Heide, M. Steinberger, Y.-T. Tsai, M. Rouf, D. Pajak,
D. Reddy, O. Gallo, J. Liu, W. Heidrich, K. Egiazarian,
et al. Flexisp: A ﬂexible camera image processing frame-
work. ACM Transactions on Graphics, 33(6):231, 2014.
[32] S. Ioffe and C. Szegedy. Batch normalization: Accelerating
deep network training by reducing internal covariate shift. In
International Conference on Machine Learning, pages 448–
456, 2015.

[33] M. Irani and S. Peleg. Motion analysis for image enhance-

9

Pattern Recognition, pages 2774–2781, 2014.

[52] C. J. Schuler, H. Christopher Burger, S. Harmeling, and
B. Scholkopf. A machine learning approach for non-blind
image deconvolution. In IEEE Conference on Computer Vi-
sion and Pattern Recognition, pages 1067–1074, 2013.
[53] K. Simonyan and A. Zisserman. Very deep convolutional
networks for large-scale image recognition. In International
Conference for Learning Representations, 2015.

[54] S. Sreehari, S. Venkatakrishnan, B. Wohlberg, L. F. Drummy,
J. P. Simmons, and C. A. Bouman. Plug-and-play priors
for bright ﬁeld electron tomography and sparse interpolation.
arXiv preprint arXiv:1512.07331, 2015.

[55] J. Sun and M. F. Tappen. Separable markov random ﬁeld
model and its applications in low level vision. IEEE Trans-
actions on Image Processing, 22(1):402–407, 2013.

[56] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed,
D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich.
In IEEE Conference on
Going deeper with convolutions.
Computer Vision and Pattern Recognition, June 2015.
[57] M. F. Tappen. Utilizing variational optimization to learn
In IEEE Conference on Computer

markov random ﬁelds.
Vision and Pattern Recognition, pages 1–8, 2007.

[58] A. M. Teodoro, J. M. Bioucas-Dias, and M. A. Figueiredo.
Image restoration and reconstruction using variable splitting
and class-adapted image priors. In IEEE International Con-
ference on Image Processing, pages 3518–3522, 2016.
[59] R. Timofte, V. De Smet, and L. Van Gool. A+: Adjusted
anchored neighborhood regression for fast super-resolution.
In Asian Conference on Computer Vision, pages 111–126,
2014.

[60] A. Vedaldi and K. Lenc. MatConvNet: Convolutional neu-
ral networks for matlab. In ACM Conference on Multimedia
Conference, pages 689–692, 2015.

[61] S. V. Venkatakrishnan, C. A. Bouman, and B. Wohlberg.
Plug-and-play priors for model based reconstruction.
In
IEEE Global Conference on Signal and Information Pro-
cessing, pages 945–948, 2013.

[62] L. Xu, J. S. Ren, C. Liu, and J. Jia. Deep convolutional neural
In Advances in Neural

network for image deconvolution.
Information Processing Systems, pages 1790–1798, 2014.

[63] F. Yu and V. Koltun. Multi-scale context aggregation by di-
lated convolutions. arXiv preprint arXiv:1511.07122, 2015.
[64] K. Zhang, X. Zhou, H. Zhang, and W. Zuo. Revisiting sin-
gle image super-resolution under internet environment: blur
kernels and reconstruction algorithms. In Paciﬁc Rim Con-
ference on Multimedia, pages 677–687, 2015.

[65] K. Zhang, W. Zuo, Y. Chen, D. Meng, and L. Zhang. Be-
yond a Gaussian denoiser: Residual learning of deep CNN
for image denoising. IEEE Transactions on Image Process-
ing, 2017.

[66] D. Zoran and Y. Weiss. From learning models of natural
In IEEE Inter-
image patches to whole image restoration.
national Conference on Computer Vision, pages 479–486,
2011.

ment: Resolution, occlusion, and transparency. Journal of
Visual Communication and Image Representation, 4(4):324–
335, 1993.

[34] V. Jain and S. Seung. Natural image denoising with convo-
lutional networks. In Advances in Neural Information Pro-
cessing Systems, pages 769–776, 2009.

[35] J. Kim, J. K. Lee, and K. M. Lee. Accurate image super-
resolution using very deep convolutional networks. In IEEE
Conference on Computer Vision and Pattern Recognition,
pages 1646–1654, 2016.

[36] D. Kingma and J. Ba. Adam: A method for stochastic op-
timization. In International Conference for Learning Repre-
sentations, 2015.

[37] A. Krizhevsky, I. Sutskever, and G. E. Hinton.

Imagenet
In
classiﬁcation with deep convolutional neural networks.
Advances in Neural Information Processing Systems, pages
1097–1105, 2012.

[38] A. Levin, Y. Weiss, F. Durand, and W. T. Freeman. Under-
standing and evaluating blind deconvolution algorithms. In
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 1964–1971, 2009.

[39] Z. Lin, M. Chen, and Y. Ma. The augmented lagrange mul-
tiplier method for exact recovery of corrupted low-rank ma-
trices. arXiv preprint arXiv:1009.5055, 2010.

[40] K. Ma, Z. Duanmu, Q. Wu, Z. Wang, H. Yong, H. Li, and
L. Zhang. Waterloo exploration database: New challenges
for image quality assessment models. IEEE Transactions on
Image Processing, 26(2):1004–1016, 2017.

[41] J. Mairal, M. Elad, and G. Sapiro. Sparse representation for
color image restoration. IEEE Transactions on Image Pro-
cessing, 17(1):53–69, 2008.

[42] T. Miyata. Inter-channel relation based vectorial total varia-
tion for color image recovery. In IEEE International Confer-
ence on Image Processing,, pages 2251–2255, 2015.
[43] S. Osher, M. Burger, D. Goldfarb, J. Xu, and W. Yin. An it-
erative regularization method for total variation-based image
restoration. Multiscale Modeling & Simulation, 4(2):460–
489, 2005.

[44] N. Parikh, S. P. Boyd, et al. Proximal algorithms. Founda-
tions and Trends in optimization, 1(3):127–239, 2014.
[45] T. Peleg and M. Elad. A statistical prediction model based
on sparse representations for single image super-resolution.
IEEE Transactions on Image Processing, 23(6):2569–2582,
2014.

[46] A. Rajwade, A. Rangarajan, and A. Banerjee.

Image de-
noising using the higher order singular value decomposition.
IEEE Transactions on Pattern Analysis and Machine Intelli-
gence, 35(4):849–862, 2013.

[47] W. H. Richardson. Bayesian-based iterative method of image

restoration. JOSA, 62(1):55–59, 1972.

[48] Y. Romano, M. Elad, and P. Milanfar. The little engine that
could regularization by denoising (RED). arXiv preprint
arXiv:1611.02862, 2016.

[49] A. Rond, R. Giryes, and M. Elad. Poisson inverse problems
by the plug-and-play scheme. Journal of Visual Communi-
cation and Image Representation, 41:96–108, 2016.

[50] S. Roth and M. J. Black. Fields of experts.

International

Journal of Computer Vision, 82(2):205–229, 2009.

[51] U. Schmidt and S. Roth. Shrinkage ﬁelds for effective image
In IEEE Conference on Computer Vision and

restoration.

10

7
1
0
2
 
r
p
A
 
1
1
 
 
]

V
C
.
s
c
[
 
 
1
v
4
6
2
3
0
.
4
0
7
1
:
v
i
X
r
a

Learning Deep CNN Denoiser Prior for Image Restoration

Kai Zhang1,2, Wangmeng Zuo1, Shuhang Gu2, Lei Zhang2
1School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China
2Dept. of Computing, The Hong Kong Polytechnic University, Hong Kong, China
cskaizhang@gmail.com, wmzuo@hit.edu.cn, shuhanggu@gmail.com, cslzhang@comp.polyu.edu.hk

Abstract

Model-based optimization methods and discriminative
learning methods have been the two dominant strategies for
solving various inverse problems in low-level vision. Typi-
cally, those two kinds of methods have their respective mer-
its and drawbacks, e.g., model-based optimization methods
are ﬂexible for handling different inverse problems but are
usually time-consuming with sophisticated priors for the
purpose of good performance; in the meanwhile, discrim-
inative learning methods have fast testing speed but their
application range is greatly restricted by the specialized
task. Recent works have revealed that, with the aid of vari-
able splitting techniques, denoiser prior can be plugged in
as a modular part of model-based optimization methods to
solve other inverse problems (e.g., deblurring). Such an
integration induces considerable advantage when the de-
noiser is obtained via discriminative learning. However, the
study of integration with fast discriminative denoiser prior
is still lacking. To this end, this paper aims to train a set of
fast and effective CNN (convolutional neural network) de-
noisers and integrate them into model-based optimization
method to solve other inverse problems. Experimental re-
sults demonstrate that the learned set of denoisers not only
achieve promising Gaussian denoising results but also can
be used as prior to deliver good performance for various
low-level vision applications.

1. Introduction

Image restoration (IR) has been a long-standing prob-
lem for its highly practical value in various low-level vision
applications [1, 9, 47].
In general, the purpose of image
restoration is to recover the latent clean image x from its
degraded observation y = Hx + v, where H is a degrada-
tion matrix, v is additive white Gaussian noise of standard
deviation σ. By specifying different degradation matrices,
one can correspondingly get different IR tasks. Three clas-
sical IR tasks would be image denoising when H is an iden-
tity matrix, image deblurring when H is a blurring operator,

image super-resolution when H is a composite operator of
blurring and down-sampling.

Since IR is an ill-posed inverse problem, the prior which
is also called regularization needs to be adopted to con-
straint the solution space [50, 66]. From a Bayesian per-
spective, the solution ˆx can be obtained by solving a Maxi-
mum A Posteriori (MAP) problem,

ˆx = arg max

log p(y|x) + log p(x)

(1)

x

where log p(y|x) represents the log-likelihood of observa-
tion y, log p(x) delivers the prior of x and is independent
of y. More formally, Eqn. (1) can be reformulated as

ˆx = arg min

(cid:107)y − Hx(cid:107)2 + λΦ(x)

(2)

1
2

x

where the solution minimizes an energy function composed
of a ﬁdelity term 1
2 (cid:107)y − Hx(cid:107)2, a regularization term Φ(x)
and a trade-off parameter λ. The ﬁdelity term guarantees
the solution accords with the degradation process, while the
regularization term enforces desired property of the output.
Generally, the methods to solve Eqn. (2) can be divided
into two main categories, i.e., model-based optimization
methods and discriminative learning methods. The model-
based optimization methods aim to directly solve Eqn. (2)
with some optimization algorithms which usually involve a
time-consuming iterative inference. On the contrary, dis-
criminative learning methods try to learn the prior parame-
ters Θ and a compact inference through an optimization of
a loss function on a training set containing degraded-clean
image pairs [2, 13, 51, 55, 57]. The objective is generally
given by

1
2

x

s.t.

min
Θ

(cid:96)(ˆx, x)

ˆx = arg min

(cid:107)y−Hx(cid:107)2+λΦ(x; Θ)
(3)
Because the inference is guided by the MAP estimation, we
refer to such methods as MAP inference guided discrimi-
native learning methods. By replacing the MAP inference
with a predeﬁned nonlinear function ˆx = f (y, H; Θ), one

1

can treat the plain discriminative learning methods as gen-
eral case of Eqn. (3). It can be seen that one obvious dif-
ference between model-based optimization method and dis-
criminative learning method is that, the former is ﬂexible
to handle various IR tasks by specifying degradation matrix
H, whereas the later needs to use the training data with cer-
tain degradation matrices to learn the model. As a conse-
quence, different from model-based optimization methods
which have ﬂexibility to handle different IR tasks, discrimi-
native learning methods are usually restricted by specialized
tasks. For example, model-based optimization methods
such as NCSR [22] are ﬂexible to handle denoising, super-
resolution and deblurring, whereas discriminative learning
methods MLP [8], SRCNN [21], DCNN [62] are designed
for those three tasks, respectively. Even for a speciﬁc task
such as denoising, model-based optimization methods (e.g.,
BM3D [17] and WNNM [29]) can handle different noise
levels, whereas discriminative learning method of [34] sep-
arately train a different model for each level.

With the sacriﬁce of ﬂexibility, however, discriminative
learning methods can not only enjoy a fast testing speed
but also tend to deliver promising performance due to the
joint optimization and end-to-end training. On the con-
trary, model-based optimization methods are usually time-
consuming with sophisticated priors for the purpose of good
performance [27]. As a result, those two kinds of meth-
ods have their respective merits and drawbacks, and thus
it would be attractive to investigate their integration which
leverages their respective merits. Fortunately, with the aid
of variable splitting techniques, such as alternating direc-
tion method of multipliers (ADMM) method [5] and half-
quadratic splitting (HQS) method [28], it is possible to deal
with ﬁdelity term and regularization term separately [44],
and particularly, the regularization term only corresponds
to a denoising subproblem [18, 31, 61]. Consequently, this
enables an integration of any discriminative denoisers into
model-based optimization methods. However, to the best of
our knowledge, the study of integration with discriminative
denoiser is still lacking.

This paper aims to train a set of fast and effective
discriminative denoisers and integrate them into model-
based optimization methods to solve other inverse prob-
lems. Rather than learning MAP inference guided discrim-
inative models, we instead adopt plain convolutional neural
networks (CNN) to learn the denoisers, so as to take ad-
vantage of recent progress in CNN as well as the merit of
GPU computation. Particularly, several CNN techniques,
including Rectiﬁer Linear Units (ReLU) [37], batch nor-
malization [32], Adam [36], dilated convolution [63] are
adopted into the network design or training. As well as pro-
viding good performance for image denoising, the learned
set of denoisers are plugged in a model-based optimization
method to tackle various inverse problems.

The contribution of this work is summarized as follows:

• We trained a set of fast and effective CNN denoisers.
With variable splitting technique, the powerful denois-
ers can bring strong image prior into model-based op-
timization methods.

• The learned set of CNN denoisers are plugged in as
a modular part of model-based optimization methods
to tackle other inverse problems. Extensive experi-
ments on classical IR problems, including deblurring
and super-resolution, have demonstrated the merits of
integrating ﬂexible model-based optimization methods
and fast CNN-based discriminative learning methods.

2. Background

2.1. Image Restoration with Denoiser Prior

There have been several attempts to incorporate denoiser
prior into model-based optimization methods to tackle with
other inverse problems. In [19], the authors used Nash equi-
librium to derive an iterative decoupled deblurring BM3D
(IDDBM3D) method for image debluring. In [24], a simi-
lar method which is equipped with CBM3D denoiser prior
was proposed for single image super-resolution (SISR). By
iteratively updating a back-projection step and a CBM3D
denoising step, the method has an encouraging performance
for its PSNR improvement over SRCNN [21].
In [18],
the augmented Lagrangian method was adopted to fuse the
BM3D denoiser into an image deblurring scheme. With
a similar iterative scheme to [19], a plug-and-play priors
framework based on ADMM method was proposed in [61].
Here we note that, prior to [61], a similar idea of plug-
and-play is also mentioned in [66] where a half quadratic
splitting (HQS) method was proposed for image denois-
ing, deblurring and inpainting.
In [31], the authors used
an alternative to ADMM and HQS, i.e., the primal-dual
algorithm [11], to decouple ﬁdelity term and regulariza-
tion term. Some of the other related work can be found
in [6, 12, 48, 49, 54, 58]. All the above methods have shown
that the decouple of the ﬁdelity term and regularization term
can enable a wide variety of existing denoising models to
solve different image restoration tasks.

We can see that the denoiser prior can be plugged in an
iterative scheme via various ways. The common idea be-
hind those ways is to decouple the ﬁdelity term and reg-
ularization term. For this reason, their iterative schemes
generally involve a ﬁdelity term related subproblem and a
denoising subproblem. In the next subsection, we will use
HQS method as an example due to its simplicity. It should
be noted that although the HQS can be viewed as a gen-
eral way to handle different image restoration tasks, one can
also incorporate the denoiser prior into other convenient and
proper optimization methods for a speciﬁc application.

2

2.2. Half Quadratic Splitting (HQS) Method

3. Learning Deep CNN Denoiser Prior

1
2

x

1
2

Basically, to plug the denoiser prior into the optimiza-
tion procedure of Eqn. (2), the variable splitting technique
is usually adopted to decouple the ﬁdelity term and regular-
ization term. In half quadratic splitting method, by intro-
ducing an auxiliary variable z, Eqn. (2) can be reformulated
as a constrained optimization problem which is given by

ˆx = arg min

(cid:107)y − Hx(cid:107)2 + λΦ(z)

s.t. z = x (4)

Then, HQS method tries to minimize the following cost
function

Lµ(x, z) =

(cid:107)y − Hx(cid:107)2 + λΦ(z) +

(cid:107)z − x(cid:107)2

(5)

µ
2

where µ is a penalty parameter which varies iteratively in a
non-descending order. Eqn. (5) can be solved via the fol-
lowing iterative scheme,




xk+1 = arg min



zk+1 = arg min

(cid:107)y − Hx(cid:107)2 + µ(cid:107)x − zk(cid:107)2 (6a)
µ
2

(cid:107)z − xk+1(cid:107)2 + λΦ(z)

(6b)

x

z

As one can see, the ﬁdelity term and regularization term are
decoupled into two individual subproblems. Speciﬁcally,
the ﬁdelity term is associated with a quadratic regularized
least-squares problem (i.e., Eqn. (6a)) which has various
fast solutions for different degradation matrices. A direct
solution is given by

xk+1 = (HT H + µI)−1(HT y + µzk)

(7)

The regularization term is involved in Eqn. (6b) which can
be rewritten as

zk+1 = arg min

z

1
2((cid:112)λ/µ)2

(cid:107)xk+1 − z(cid:107)2 + Φ(z)

(8)

(9)

According to Bayesian probability, Eqn. (8) corresponds
to denoising the image xk+1 by a Gaussian denoiser with
noise level (cid:112)λ/µ. As a consequence, any Gaussian de-
noisers can be acted as a modular part to solve Eqn. (2). To
address this, we rewrite Eqn. (8) by following
zk+1 = Denoiser(xk+1, (cid:112)λ/µ)
It is worth noting that, according to Eqns. (8) and (9), the
image prior Φ(·) can be implicitly replaced by a denoiser
prior. Such a promising property actually offers several ad-
vantages. First, it enables to use any gray or color denois-
ers to solve a variety of inverse problems. Second, the ex-
plicit image prior Φ(·) can be unknown in solving Eqn. (2).
Third, several complementary denoisers which exploit dif-
ferent image priors can be jointly utilized to solve one spe-
ciﬁc problem. Note that this property can be also em-
ployed in other optimization methods (e.g., iterative shrink-
age/thresholding algorithms ISTA [4, 14] and FISTA [3]) as
long as there involves a denoising subproblem.

3.1. Why Choose CNN Denoiser?

As the regularization term of Eqn. (2) plays a vital role in
restoration performance, the choice of denoiser priors thus
would be pretty important in Eqn. (9). Existing denoiser
priors that have been adopted in model-based optimization
methods to solve other inverse problems include total varia-
tion (TV) [10, 43], Gaussian mixture models (GMM) [66],
K-SVD [25], non-local means [7] and BM3D [17]. Such de-
noiser priors have their respective drawbacks. For example,
TV can create watercolor-like artifacts; K-SVD denoiser
prior suffers high computational burden; non-local means
and BM3D denoiser priors may over-smooth the irregular
structures if the image does not exhibit self-similarity prop-
erty. Thus, strong denoiser prior which can be implemented
efﬁciently is highly demanded.

Regardless of the speed and performance, color image
prior or denoiser is also a key factor that needs to be taken
into account. This is because most of the images acquired
by modern cameras or transmitted in internet are in RGB
format. Due to the correlation between different color chan-
nels, it has been acknowledged that jointly handling the
color channels tends to produce better performance than in-
dependently dealing with each color channel [26]. How-
ever, existing methods mainly focus on modeling gray im-
age prior and there are only a few works concentrating
on modeling color image prior (see, e.g.,
[16, 41, 46]).
Perhaps the most successful color image prior modeling
method is CBM3D [16]. It ﬁrst decorrelates the image into
a luminance-chrominance color space by a hand-designed
linear transform and then applies the gray BM3D method
in each transformed color channels. While CBM3D is
promising for color image denoising, it has been pointed
out that the resulting transformed luminance-chrominance
color channels still remain some correlation [42] and it is
preferable to jointly handle RGB channels. Consequently,
instead of utilizing the hand-designed pipeline, using dis-
criminative learning methods to automatically reveal the un-
derlying color image prior would be a good alternative.

By considering the speed, performance and discrimina-
tive color image prior modeling, we choose deep CNN to
learn the discriminative denoisers. The reasons of using
CNN are four-fold. First, the inference of CNN is very ef-
ﬁcient due to the parallel computation ability of GPU. Sec-
ond, CNN exhibits powerful prior modeling capacity with
deep architecture. Third, CNN exploits the external prior
which is complementary to the internal prior of many ex-
isting denoisers such as BM3D. In other words, a combina-
tion with BM3D is expected to improve the performance.
Fourth, great progress in training and designing CNN have
been made during the past few years and we can take advan-
tage of those progress to facilitate discriminative learning.

3

Figure 1. The architecture of the proposed denoiser network. Note that “s-DConv” denotes s-dilated convolution [63], here s = 1, 2, 3 and
4; “BNorm” represents batch normalization [32]; “ReLU” is the rectiﬁed linear units (max(·, 0)).

3.2. The Proposed CNN Denoiser

The architecture of the proposed CNN denoiser is illus-
It consists of seven layers with three
trated in Figure 1.
different blocks, i.e., “Dilated Convolution+ReLU” block
in the ﬁrst layer, ﬁve “Dilated Convolution+Batch Normal-
ization+ReLU” blocks in the middle layers, and “Dilated
Convolution” block in the last layer. The dilation factors of
(3×3) dilated convolutions from ﬁrst layer to the last layer
are set to 1, 2, 3, 4, 3, 2 and 1, respectively. The number
of feature maps in each middle layer is set to 64. In the fol-
lowing, we will give some important details in our network
design and training.

Using Dilated Filter to Enlarge Receptive Field. It has
been widely acknowledged that the context information fa-
cilitates the reconstruction of the corrupted pixel in image
denoising. In CNN, to capture the context information, it
successively enlarges the receptive ﬁeld through the for-
ward convolution operations. Generally, there are two basic
ways to enlarge the receptive ﬁeld of CNN, i.e., increas-
ing the ﬁlter size and increasing the depth. However, in-
creasing the ﬁlter size would not only introduce more pa-
rameters but also increase the computational burden [53].
Thus, using 3×3 ﬁlter with a large depth is popularized in
existing CNN network design [30, 35, 56]. In this paper,
we instead use the recent proposed dilated convolution to
make a tradeoff between the size of receptive ﬁled and net-
work depth. Dilated convolution is known for its expansion
capacity of the receptive ﬁeld while keeping the merits of
traditional 3×3 convolution. A dilated ﬁlter with dilation
factor s can be simply interpreted as a sparse ﬁlter of size
(2s+1)×(2s+1) where only 9 entries of ﬁxed positions can
be non-zeros. Hence, the equivalent receptive ﬁeld of each
layer is 3, 5, 7, 9, 7, 5 and 3. Consequently, it can be eas-
ily obtained that the receptive ﬁled of the proposed network
is 33×33. If the traditional 3×3 convolution ﬁlter is used,
the network will either have a receptive ﬁled of size 15×15
with the same network depth (i.e., 7) or have a depth of 16
with the same receptive ﬁled (i.e., 33×33). To show the

advantage of our design over the above two cases, we have
trained three different models on noise level 25 with same
training settings. It turns out that our designed model can
have an average PSNR of 29.15dB on BSD68 dataset [50],
which is much better than 28.94dB of 7 layers network with
traditional 3×3 convolution ﬁlter and very close to 29.20dB
of 16 layers network.

Using Batch Normalization and Residual Learning to
Accelerate Training. While advanced gradient optimiza-
tion algorithms can accelerate training and improve the per-
formance, the architecture design is also an important fac-
tor. Batch normalization and residual learning which are
two of the most inﬂuential architecture design techniques
have been widely adopted in recent CNN architecture de-
signs. In particular, it has been pointed out that the combi-
nation of batch normalization and residual learning is par-
ticularly helpful for Gaussian denoising since they are ben-
eﬁcial to each other. To be speciﬁc, it not only enables fast
and stable training but also tends to result in better denois-
ing performance [65]. In this paper, such strategy is adopted
and we empirically ﬁnd it also can enable fast transfer from
one model to another with different noise level.

Using Training Samples with Small Size to Help Avoid
Boundary Artifacts. Due to the characteristic of convolu-
tion, the denoised image of CNN may introduce annoying
boundary artifacts without proper handling. There are two
common ways to tackle with this, i.e., symmetrical padding
and zero padding. We adopt the zero padding strategy and
wish the designed CNN has the capacity to model image
boundary. Note that the dilated convolution with dilation
factor 4 in the fourth layer pads 4 zeros in the boundaries
of each feature map. We empirically ﬁnd that using training
samples with small size can help avoid boundary artifacts.
The main reason lies in the fact that, rather than using train-
ing patches of large size, cropping them into small patches
can enable CNN to see more boundary information. For ex-
ample, by cropping an image patch of size 70×70 into four
small non-overlap patches of size 35×35, the boundary in-

4

formation would be largely augmented. We also have tested
the performance by using patches of large size, we empiri-
cally ﬁnd this does not improve the performance. However,
if the size of the training patch is smaller than the receptive
ﬁeld, the performance would decrease.

Learning Speciﬁc Denoiser Model with Small Interval
Noise Levels. Since the iterative optimization framework
requires various denoiser models with different noise lev-
els, a practical issue on how to train the discriminative mod-
els thus should be taken into consideration. Various studies
have shown that if the exact solutions of subproblems (i.e.,
Eqn. (6a) and Eqn. (6b)) are difﬁcult or time-consuming to
optimize, then using an inexact but fast subproblem solu-
tion may accelerate the convergence [39, 66].
In this re-
spect, their is no need to learn many discriminative denoiser
models for each noise level. On the other hand, although
Eqn. (9) is a denoiser, it has a different goal from the tradi-
tional Gaussian denoising. The goal of traditional Gaussian
denoising is to recover the latent clean image, however, the
denoiser here just acts its own role regardless of the noise
type and noise level of the image to be denoised. There-
fore, the ideal discriminative denoiser in Eqn. (9) should be
trained by current noise level. As a result, there is tradeoff
to set the number of denoisers. In this paper, we trained a
set of denoisers on noise level range [0, 50] and divided it by
a step size of 2 for each model, resulting in a set of 25 de-
noisers for each gray and color image prior modelling. Due
to the iterative scheme, it turns out the noise level range of
[0, 50] is enough to handle various image restoration prob-
lems. Especially noteworthy is the number of the denoisers
which is much less than that of learning different models for
different degradations.

4. Experiments

The Matlab source code of the proposed method can be
downloaded at https://github.com/cszn/ircnn.

4.1. Image Denoising

It is widely acknowledged that convolutional neural net-
works generally beneﬁt from the availability of large train-
ing data. Hence, instead of training on a small dataset con-
sisting of 400 Berkeley segmentation dataset (BSD) images
of size 180×180 [13], we collect a large dataset which in-
cludes 400 BSD images, 400 selected images from valida-
tion set of ImageNet database [20] and 4,744 images of Wa-
terloo Exploration Database [40]. We empirically ﬁnd using
large dataset does not improve the PSNR results of BSD68
dataset [50] but can slightly improve the performance of
other testing images. We crop the images into small patches
of size 35×35 and select N =256×4,000 patches for train-
ing. As for the generation of corresponding noisy patches,
we achieve this by adding additive Gaussian noise to the

Table 1. The average PSNR(dB) results of different methods on
(gray) BSD68 dataset.

Methods
σ = 15
σ = 25
σ = 50

BM3D
31.07
28.57
25.62

WNNM
31.37
28.83
25.87

TNRD
31.42
28.92
25.97

MLP
-
28.96
26.03

Proposed
31.63
29.15
26.19

Table 2. The average PSNR(dB) results of CBM3D and proposed
CNN denoiser on (color) BSD68 dataset.

Noise Level
CBM3D
Proposed

5
40.24
40.36

15
33.52
33.86

25
30.71
31.16

35
28.89
29.50

50
27.38
27.86

clean patches during training. Since the residual learning
strategy is adopted, we use the following loss function,

(cid:96)(Θ) =

(cid:107)f (yi; Θ) − (yi − xi)(cid:107)2
F

(10)

1
2N

N
(cid:88)

i=1

where {(yi, xi)}N
i=1 represents N noisy-clean patch pairs.
To optimize the network parameters Θ,
the Adam
solver [36] is adopted. The step size is started from 1e−3
and then ﬁxed to 1e−4 when the training error stops de-
creasing. The training was terminated if the training error
was ﬁxed in ﬁve sequential epochs. For the other hyper-
parameters of Adam, we use their default setting. The mini-
batch size is set to 256. Rotation or/and ﬂip based data aug-
mentation is used during mini-batch learning. The denoiser
models are trained in Matlab (R2015b) environment with
MatConvNet package [60] and an Nvidia Titan X GPU. To
reduce the whole training time, once a model is obtained,
we initialize the adjacent denoiser with this model. It takes
about three days to train the set of denoiser models.

We compared the proposed denioser with several state-
of-the-art denoising methods, including two model-based
optimization methods (i.e., BM3D [17] and WNNM [29]),
two discriminative learning methods (i.e., MLP [8] and
TNRD [13]). The gray image denoising results of different
methods on BSD68 dataset are shown in Table 1. It can be
seen that WNNM, MLP and TNRD can outperform BM3D
by about 0.3dB in PSNR. However, the proposed CNN de-
noiser can have a PSNR gain of about 0.2dB over those
three methods. Table 2 shows the color image denoising
results of benchmark CBM3D and our proposed CNN de-
noiser, it can be seen that the proposed denoiser consistently
outperforms CBM3D by a large margin. Such a promising
result can be attributed to the powerful color image prior
modeling capacity of CNN.

For the run time, we compared with BM3D and TNRD
due to their potential value in practical applications. Since
the proposed denoiser and TNRD support parallel compu-
tation on GPU, we also give the GPU run time. To make a
further comparison with TNRD under similar PSNR perfor-

5

mance, we additionally provide the run time of the proposed
denoiser where each middle layer has 24 feature maps. We
use the Nvidia cuDNN-v5 deep learning library to acceler-
ate the GPU computation and the memory transfer time be-
tween CPU and GPU is not considered. Table 3 shows the
run times of different methods for denoising images of size
256×256, 512×512 and 1024×1024 with noise level 25.
We can see that the proposed denoiser is very competitive
in both CPU and GPU implementation. It is worth empha-
sizing that the proposed denoiser with 24 feature maps of
each layer has a comparable PSNR of 28.94dB to TNRD but
delivers a faster speed. Such a good compromise between
speed and performance over TNRD is properly attributed to
the following three reasons. First, the adopted 3×3 convo-
lution and ReLU nonlinearity are simple yet effective and
efﬁcient. Second, in contrast to the stage-wise architecture
of TNRD which essentially has a bottleneck in each imme-
diate output layer, ours encourages a ﬂuent information ﬂow
among different layers, thus having larger model capacity.
Third, batch normalization which is beneﬁcial to Gaussian
denoising is adopted. According to the above discussions,
we can conclude that the proposed denoiser is a strong com-
petitor against BM3D and TNRD.

Table 3. Run time (in seconds) of different methods on images of
size 256×256, 512×512 and 1024×1024 with noise level 25.

Size

256×256

512×512

1024×1024

Device
CPU
GPU
CPU
GPU
CPU
GPU

BM3D
0.66
-
2.91
-
11.89
-

TNRD
0.47
0.010
1.33
0.032
4.61
0.116

Proposed24 Proposed64

0.10
0.006
0.39
0.016
1.60
0.059

0.310
0.012
1.24
0.038
4.65
0.146

4.2. Image Deblurring

As a common setting, the blurry images are synthesized
by ﬁrst applying a blur kernel and then adding additive
Gaussian noise with noise level σ. In addition, we assume
the convolution is carried out with circular boundary con-
ditions. Thus, an efﬁcient implementation of Eqn. (7) by
using Fast Fourier Transform (FFT) can be employed. To
make a thorough evaluation, we consider three blur kernels,
including a commonly-used Gaussian kernel with standard
deviation 1.6 and the ﬁrst two of the eight real blur kernels
from [38]. As shown in Table 4, we also consider Gaussian

(a)

(b)

(c)

(d)

(e)

(f)

Figure 2. Six testing images for image deblurring. (a) Cameraman;
(b) House; (c) Lena; (d) Monarch; (e) Leaves; (f) Parrots.

6

noise with different noise levels. For the compared meth-
ods, we choose one discriminative method named MLP [52]
and three model based optimization methods, including ID-
DBM3D [19], NCSR [22] and EPLL. Among the testing
images, apart from three classical gray images as shown
in Figure 2, three color images are also included such that
we can test the performance of learned color denoiser prior.
In the meanwhile, we note that the above methods are de-
signed for gray image deblurring. Specially, NCSR tackles
the color input by ﬁrst transforming it into YCbCr space and
then conducting the main algorithm in the luminance com-
ponent. In the following experiments, we simply plug the
color denoisers into the HQS framework, whereas we sep-
arately handle each color channel for IDDBM3D and MLP.
Note that MLP trained a speciﬁc model for the Gaussian
blur kernel with noise level 2.

Once the denoisers are provided, the subsequent crucial
issue would be parameter setting. From Eqns. (6), we can
note that there involve two parameters, λ and µ, to tune.
Generally, for a certain degradation, λ is correlated with
σ2 and keeps ﬁxed during iterations, while µ controls noise
level of denoiser. Since the HQS framework is denoiser-
based, we instead set the noise level of denoiser in each
iteration to implicitly determine µ. Note that the noise level
of denoiser (cid:112)λ/µ should be set from large to small.
In
our experimental settings, it is decayed exponentially from
49 to a value in [1, 15] depending on the noise level. The
number of iterations is set to 30 as we ﬁnd it is large enough
to obtain a satisfying performance.

The PSNR results of different methods are shown in Ta-
ble 4. As one can see, the proposed CNN denoiser prior
based optimization method achieves very promising PSNR
results. Figure 3 illustrates deblurred Leaves image by dif-
ferent methods. We can see that IDDBM3D, NCSR and
MLP tend to smooth the edges and generate color artifacts.
In contrast, the proposed method can recover image sharp-
ness and naturalness.

Table 4. Deblurring results of different methods.
Leaves

σ
Gaussian blur with standard deviation 1.6

C.man House

Monar.

Lena

Kernel 1 (19×19) [38]

27.08
27.99
27.84
28.12

29.43
32.07
25.33
28.11

29.67
31.69
24.85
27.70

32.41
33.38
33.43
33.80

31.48
35.17
28.19
32.03

32.26
35.04
28.08
31.94

30.28
30.99
31.10
31.17

31.68
33.88
27.37
29.51

31.00
33.53
27.03
29.27

Kernel 2 (17×17) [38]

27.02
28.32
28.87
30.00

28.75
33.62
22.67
29.20

27.53
33.13
21.60
28.73

26.95
27.50
28.91
29.78

27.34
33.92
21.67
29.07

26.75
33.51
21.09
28.63

2

2.55

7.65

2.55

7.65

Methods

IDDBM3D
NCSR
MLP
Proposed

EPLL
Proposed
EPLL
Proposed

EPLL
Proposed
EPLL
Proposed

Parrots

30.15
30.42
31.24
32.07

30.89
35.49
26.08
31.63

30.44
35.17
25.77
31.35

(a) Blurry and noisy image

(b) IDDBM3D (26.95dB)

(c) NCSR (27.50dB)

(d) MLP (28.91dB)

(e) Proposed (29.78dB)

Figure 3. Image deblurring performance comparison for Leaves image (the blur kernel is Gaussian kernel with standard deviation 1.6, the
noise level σ is 2).

4.3. Single Image Super-Resolution

In general, the low-resolution (LR) image can be mod-
eled by a blurring and subsequent down-sampling opera-
tion on a high-resolution one. The existing super-resolution
models, however, mainly focus on modeling image prior
and are trained for speciﬁc degradation process. This makes
the learned model deteriorates seriously when the blur ker-
nel adopted in training deviates from the real one [23, 64].
Instead, our model can handle any blur kernels without re-
training. Thus, in order to thoroughly evaluate the ﬂexibil-
ity of the CNN denoiser prior based optimization method
as well as the effectiveness of the CNN denoisers, follow-
ing [45], this paper considers three typical image degrada-
tion settings for SISR, i.e., bicubic downsampling (default
setting of Matlab function imresize) with two scale fac-
tors 2 and 3 [15, 21] and blurring by Gaussian kernel of size
7×7 with standard deviation 1.6 followed by downsampling
with scale factor 3 [22, 45].

Inspired by the method proposed in [24] which itera-
tively updates a back-projection [33] step and a denoising
step for SISR, we use the following back-projection itera-
tion to solve Eqn. (6a),

xk+1 = xk − α(y − xk ↓sf) ↑sf

bicubic

(11)

where ↓sf denotes the degradation operator with downscal-
ing factor sf, ↑sf
bicubic represents bicubic interpolation opera-
tor with upscaling factor sf, and α is the step size. It is wor-
thy noting that the iterative regularization step of methods
such as NCSR and WNNM actually corresponds to solv-
ing Eqn. (6a). From this viewpoint, those methods are opti-
mized under HQS framework. Here, note that only the bicu-
bic downsampling is considered in [24], whereas Eqn. (11)
is extended to deal with different blur kernels. To obtain a
fast convergence, we repeat Eqn. (11) ﬁve times before ap-
plying the denoising step. The number of main iterations is
set to 30, the step size α is ﬁxed to 1.75 and the noise levels
of denoiser are decayed exponentially from 12×sf to sf.

The proposed deep CNN denoiser prior based SISR
method is compared with ﬁve state-of-the-art methods, in-

cluding two CNN-based discriminative learning methods
(i.e., SRCNN [21] and VDSR [35]), one statistical pre-
diction model based discriminative learning method [45]
which we refer to as SPMSR, one model based optimiza-
tion method (i.e., NCSR [22]) and one denoiser prior based
method (i.e., SRBM3D [24]). Except for SRBM3D, all
the existing methods conducted their main algorithms on Y
channel (i.e., luminance) of transformed YCbCr space. In
order to evaluate the proposed color denoiser prior, we also
conduct experiments on the original RGB channels and thus
the PSNR results of super-resolved RGB images of different
methods are also given. Since the source code of SRBM3D
is not available, we also compare two methods which re-
place the proposed CNN denoiser with BM3D/CBM3D de-
noiser. Those two methods are denoted by SRBM3DG and
SRBM3DC, respectively.

Table 5 shows the average PSNR(dB) results of differ-
ent methods for SISR on Set5 and Set14 [59]. Note that
SRCNN and VDSR are trained with bicubic blur kernel,
thus it is unfair to use their models to super-resolve the
low-resolution image with Gaussian kernel. As a matter of
fact, we give their performances to demonstrate the limita-
tions of such discriminative learning methods. From Ta-
ble 5, we can have several observations. First, although
SRCNN and VDSR achieve promising results to tackle the
case with bicubic kernel, their performance deteriorates se-
riously when the low-resolution image are not generated
by bicubic kernel (see Figure 4). On the other hand, with
the accurate blur kernel, even NCSR and SPMSR outper-
form SRCNN and VDSR for Gaussian blur kernel. In con-
trast, the proposed methods (denoted by ProposedG and
ProposedC) can handle all the cases well. Second, the pro-
posed methods have a better PSNR result than SRBM3DC
and SRBM3DG which indicates good denoiser prior facil-
itates to solve super-resolution problem. Third, both of
the gray and color CNN denoiser prior based optimization
methods can produce promising results. As an example for
the testing speed comparison, our method can super-resolve
the Butterﬂy image in 0.5 second on GPU and 12 seconds
on CPU, whereas NCSR spends 198 seconds on CPU.

7

Table 5. Average PSNR(dB) results of different methods for single image super-resolution on Set5 and Set14.

Dataset

Scale

Kernel

SRBM3DG SRBM3DC ProposedG ProposedC

Set5

Set14

Bicubic

Bicubic

Gaussian

Bicubic

Bicubic

Gaussian

Channel
Y
RGB
Y
RGB
Y
RGB
Y
RGB
Y
RGB
Y
RGB

SRCNN
36.65
34.45
32.75
30.72
30.42
28.50
32.43
30.43
29.27
27.44
27.71
26.02

VDSR
37.56
35.16
33.67
31.50
30.54
28.62
33.02
30.90
29.77
27.85
27.80
26.11

NCSR
-
-
-
-
33.02
30.00
-
-
-
-
29.26
26.98

SPMSR
36.11
33.94
32.31
30.32
32.27
30.02
31.96
30.05
28.93
27.17
28.89
27.01

SRBM3D
37.10
-
33.30
-
-
-
32.80
-
29.60
-
-
-

36.34
34.11
32.62
30.57
32.66
30.31
32.09
30.15
29.11
27.32
29.18
27.24

2

3

3

2

3

3

36.25
34.22
32.54
30.69
32.59
30.74
32.25
30.32
29.27
27.47
29.39
27.60

37.43
35.05
33.39
31.26
33.38
30.92
32.88
30.79
29.61
27.72
29.63
27.59

37.22
35.07
33.18
31.25
33.17
31.21
32.79
30.78
29.50
27.67
29.55
27.70

(a) Ground-truth

(b) Zoomed LR image

(c) SRCNN (24.46dB)

(d) VDSR (24.73dB)

(e) ProposedG (29.32dB)

Figure 4. Single image super-resolution performance comparison for Butterﬂy image from Set5 (the blur kernel is 7×7 Gaussian kernel
with standard deviation 1.6, the scale factor is 3). Note that the comparison with SRCNN and VDSR is unfair. The proposed deep CNN
denoiser prior based optimization method can super-resolve the LR image by tuning the blur kernel and scale factor without training,
whereas SRCNN and VDSR need additional training to deal with such cases. As a result, this ﬁgure is mainly used to show the ﬂexibility
advantage of the proposed deep CNN denoiser prior based optimization method over discriminative learning methods.

5. Conclusion

In this paper, we have designed and trained a set of fast
and effective CNN denoisers for image denoising. Spe-
cially, with the aid of variable splitting technique, we have
plugged the learned denoiser prior into a model-based opti-
mization method of HQS to solve the image deblurring and
super-resolution problems. Extensive experimental results
have demonstrated that the integration of model-based op-
timization method and discriminative CNN denoiser results
in a ﬂexible, fast and effective framework for various image
restoration tasks. On the one hand, different from conven-
tional model-based optimization methods which are usually
time-consuming with sophisticated image priors for the pur-
pose of achieving good results, the proposed deep CNN de-
noiser prior based optimization method can be implemented
effectively due to the plug-in of fast CNN denoisers. On the
other hand, different from discriminative learning methods
which are specialized for certain image restoration tasks,
the proposed deep CNN denoiser prior based optimization
method is ﬂexible in handling various tasks while can pro-
duce very favorable results. In summary, this work high-
lights the potential beneﬁts of integrating ﬂexible model-
based optimization methods and fast discriminative learning
methods. In addition, this work has shown that learning ex-
pressive CNN denoiser prior is a good alternative to model
image prior.

While we have demonstrated various merits of plug-
ging powerful CNN denoiser into model-based optimiza-
tion methods, there also remain room for further study.
Some research directions are listed as follows. First, it will
be interesting to investigate how to reduce the number of
the discriminative CNN denoisers and the number of whole
iterations. Second, extending the proposed CNN denoiser
based HQS framework to other inverse problems such as
inpainting and blind deblurring would be also interesting.
Third, utilizing multiple priors which are complementary
to improve performance is certainly one promising direc-
tion. Finally, and perhaps most interestingly, since the HQS
framework can be treated as a MAP inference, this work
also provides some insights into designing CNN architec-
ture for task-speciﬁc discriminative learning. Meanwhile,
one should be aware that CNN has its own design ﬂexibility
and the best CNN architecture is not necessarily inspired by
MAP inference.

6. Acknowledgements

This work is supported by HK RGC General Research
Fund (PolyU 5313/13E) and National Natural Science
Foundation of China (grant no. 61672446, 61671182). We
gratefully acknowledge the support from NVIDIA Corpora-
tion for providing us the Titan X GPU used in this research.

8

References

[1] H. C. Andrews and B. R. Hunt. Digital image restoration.
Prentice-Hall Signal Processing Series, Englewood Cliffs:
Prentice-Hall, 1977, 1, 1977.

[2] A. Barbu. Training an active random ﬁeld for real-time im-
IEEE Transactions on Image Processing,

age denoising.
18(11):2451–2462, 2009.

[3] A. Beck and M. Teboulle. A fast iterative shrinkage-
thresholding algorithm for linear inverse problems. SIAM
journal on imaging sciences, 2(1):183–202, 2009.

[4] J. M. Bioucas-Dias and M. A. Figueiredo. A new TwIST:
Two-step iterative shrinkage/thresholding algorithms for im-
IEEE Transactions on Image Processing,
age restoration.
16(12):2992–3004, 2007.

[5] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein. Dis-
tributed optimization and statistical learning via the alternat-
ing direction method of multipliers. Foundations and Trends
in Machine Learning, 3(1):1–122, 2011.

[6] A. Brifman, Y. Romano, and M. Elad. Turning a denoiser
In IEEE
into a super-resolver using plug and play priors.
International Conference on Image Processing, pages 1404–
1408, 2016.

[8] H. C. Burger, C. J. Schuler, and S. Harmeling.

[7] A. Buades, B. Coll, and J.-M. Morel. A non-local algorithm
for image denoising. In IEEE Conference on Computer Vi-
sion and Pattern Recognition, volume 2, pages 60–65, 2005.
Image de-
noising: Can plain neural networks compete with BM3D? In
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 2392–2399, 2012.

[9] P. Campisi and K. Egiazarian. Blind image deconvolution:

theory and applications. CRC press, 2016.

[10] A. Chambolle. An algorithm for total variation minimiza-
tion and applications. Journal of Mathematical imaging and
vision, 20(1-2):89–97, 2004.

[11] A. Chambolle and T. Pock. A ﬁrst-order primal-dual al-
gorithm for convex problems with applications to imaging.
Journal of Mathematical Imaging and Vision, 40(1):120–
145, 2011.

[12] S. H. Chan, X. Wang, and O. A. Elgendy. Plug-and-Play
ADMM for image restoration: Fixed-point convergence and
applications. IEEE Transactions on Computational Imaging,
3(1):84–98, 2017.

[13] Y. Chen and T. Pock. Trainable nonlinear reaction diffusion:
A ﬂexible framework for fast and effective image restoration.
IEEE transactions on Pattern Analysis and Machine Intelli-
gence, 2016.

[14] P. L. Combettes and V. R. Wajs. Signal recovery by proximal
forward-backward splitting. Multiscale Modeling & Simula-
tion, 4(4):1168–1200, 2005.

[15] Z. Cui, H. Chang, S. Shan, B. Zhong, and X. Chen. Deep
In European

network cascade for image super-resolution.
Conference on Computer Vision, pages 49–64, 2014.
[16] K. Dabov, A. Foi, V. Katkovnik, and K. Egiazarian. Color
image denoising via sparse 3D collaborative ﬁltering with
grouping constraint in luminance-chrominance space.
In
IEEE International Conference on Image Processing, vol-
ume 1, pages I–313, 2007.

[17] K. Dabov, A. Foi, V. Katkovnik, and K. Egiazarian.

Im-
age denoising by sparse 3-D transform-domain collabora-

tive ﬁltering.
16(8):2080–2095, 2007.

IEEE Transactions on Image Processing,

[18] A. Danielyan, V. Katkovnik, and K. Egiazarian. Image de-
blurring by augmented lagrangian with BM3D frame prior.
In Workshop on Information Theoretic Methods in Science
and Engineering, pages 16–18, 2010.

[19] A. Danielyan, V. Katkovnik, and K. Egiazarian. BM3D
frames and variational image deblurring. IEEE Transactions
on Image Processing, 21(4):1715–1728, 2012.

[20] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-
Fei. Imagenet: A large-scale hierarchical image database. In
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 248–255, 2009.

[21] C. Dong, C. C. Loy, K. He, and X. Tang.

Image
IEEE
super-resolution using deep convolutional networks.
transactions on Pattern Analysis and Machine Intelligence,
38(2):295–307, 2016.

[22] W. Dong, L. Zhang, G. Shi, and X. Li. Nonlocally central-
ized sparse representation for image restoration. IEEE Trans-
actions on Image Processing, 22(4):1620–1630, 2013.
[23] N. Efrat, D. Glasner, A. Apartsin, B. Nadler, and A. Levin.
Accurate blur models vs. image priors in single image super-
resolution. In IEEE International Conference on Computer
Vision, pages 2832–2839, 2013.
[24] K. Egiazarian and V. Katkovnik.

Single image super-
In European Signal

resolution via BM3D sparse coding.
Processing Conference, pages 2849–2853, 2015.

[25] M. Elad and M. Aharon.

Image denoising via sparse
and redundant representations over learned dictionaries.
IEEE Transactions on Image processing, 15(12):3736–3745,
2006.

[26] A. Foi, V. Katkovnik, and K. Egiazarian.

Pointwise
shape adaptive DCT denoising with structure preservation
in luminance-chrominance space. In International Workshop
on Video Processing and Quality Metrics for Consumer Elec-
tronics, 2006.

[27] Q. Gao and S. Roth. How well do ﬁlter-based MRFs model
In Joint DAGM (German Association for
natural images?
Pattern Recognition) and OAGM Symposium, pages 62–72,
2012.

[28] D. Geman and C. Yang. Nonlinear image recovery with half-
quadratic regularization. IEEE Transactions on Image Pro-
cessing, 4(7):932–946, 1995.

[29] S. Gu, L. Zhang, W. Zuo, and X. Feng. Weighted nuclear
norm minimization with application to image denoising. In
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 2862–2869, 2014.

[30] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning
In IEEE Conference on Computer

for image recognition.
Vision and Pattern Recognition, pages 770–778, 2016.
[31] F. Heide, M. Steinberger, Y.-T. Tsai, M. Rouf, D. Pajak,
D. Reddy, O. Gallo, J. Liu, W. Heidrich, K. Egiazarian,
et al. Flexisp: A ﬂexible camera image processing frame-
work. ACM Transactions on Graphics, 33(6):231, 2014.
[32] S. Ioffe and C. Szegedy. Batch normalization: Accelerating
deep network training by reducing internal covariate shift. In
International Conference on Machine Learning, pages 448–
456, 2015.

[33] M. Irani and S. Peleg. Motion analysis for image enhance-

9

Pattern Recognition, pages 2774–2781, 2014.

[52] C. J. Schuler, H. Christopher Burger, S. Harmeling, and
B. Scholkopf. A machine learning approach for non-blind
image deconvolution. In IEEE Conference on Computer Vi-
sion and Pattern Recognition, pages 1067–1074, 2013.
[53] K. Simonyan and A. Zisserman. Very deep convolutional
networks for large-scale image recognition. In International
Conference for Learning Representations, 2015.

[54] S. Sreehari, S. Venkatakrishnan, B. Wohlberg, L. F. Drummy,
J. P. Simmons, and C. A. Bouman. Plug-and-play priors
for bright ﬁeld electron tomography and sparse interpolation.
arXiv preprint arXiv:1512.07331, 2015.

[55] J. Sun and M. F. Tappen. Separable markov random ﬁeld
model and its applications in low level vision. IEEE Trans-
actions on Image Processing, 22(1):402–407, 2013.

[56] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed,
D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich.
In IEEE Conference on
Going deeper with convolutions.
Computer Vision and Pattern Recognition, June 2015.
[57] M. F. Tappen. Utilizing variational optimization to learn
In IEEE Conference on Computer

markov random ﬁelds.
Vision and Pattern Recognition, pages 1–8, 2007.

[58] A. M. Teodoro, J. M. Bioucas-Dias, and M. A. Figueiredo.
Image restoration and reconstruction using variable splitting
and class-adapted image priors. In IEEE International Con-
ference on Image Processing, pages 3518–3522, 2016.
[59] R. Timofte, V. De Smet, and L. Van Gool. A+: Adjusted
anchored neighborhood regression for fast super-resolution.
In Asian Conference on Computer Vision, pages 111–126,
2014.

[60] A. Vedaldi and K. Lenc. MatConvNet: Convolutional neu-
ral networks for matlab. In ACM Conference on Multimedia
Conference, pages 689–692, 2015.

[61] S. V. Venkatakrishnan, C. A. Bouman, and B. Wohlberg.
Plug-and-play priors for model based reconstruction.
In
IEEE Global Conference on Signal and Information Pro-
cessing, pages 945–948, 2013.

[62] L. Xu, J. S. Ren, C. Liu, and J. Jia. Deep convolutional neural
In Advances in Neural

network for image deconvolution.
Information Processing Systems, pages 1790–1798, 2014.

[63] F. Yu and V. Koltun. Multi-scale context aggregation by di-
lated convolutions. arXiv preprint arXiv:1511.07122, 2015.
[64] K. Zhang, X. Zhou, H. Zhang, and W. Zuo. Revisiting sin-
gle image super-resolution under internet environment: blur
kernels and reconstruction algorithms. In Paciﬁc Rim Con-
ference on Multimedia, pages 677–687, 2015.

[65] K. Zhang, W. Zuo, Y. Chen, D. Meng, and L. Zhang. Be-
yond a Gaussian denoiser: Residual learning of deep CNN
for image denoising. IEEE Transactions on Image Process-
ing, 2017.

[66] D. Zoran and Y. Weiss. From learning models of natural
In IEEE Inter-
image patches to whole image restoration.
national Conference on Computer Vision, pages 479–486,
2011.

ment: Resolution, occlusion, and transparency. Journal of
Visual Communication and Image Representation, 4(4):324–
335, 1993.

[34] V. Jain and S. Seung. Natural image denoising with convo-
lutional networks. In Advances in Neural Information Pro-
cessing Systems, pages 769–776, 2009.

[35] J. Kim, J. K. Lee, and K. M. Lee. Accurate image super-
resolution using very deep convolutional networks. In IEEE
Conference on Computer Vision and Pattern Recognition,
pages 1646–1654, 2016.

[36] D. Kingma and J. Ba. Adam: A method for stochastic op-
timization. In International Conference for Learning Repre-
sentations, 2015.

[37] A. Krizhevsky, I. Sutskever, and G. E. Hinton.

Imagenet
In
classiﬁcation with deep convolutional neural networks.
Advances in Neural Information Processing Systems, pages
1097–1105, 2012.

[38] A. Levin, Y. Weiss, F. Durand, and W. T. Freeman. Under-
standing and evaluating blind deconvolution algorithms. In
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 1964–1971, 2009.

[39] Z. Lin, M. Chen, and Y. Ma. The augmented lagrange mul-
tiplier method for exact recovery of corrupted low-rank ma-
trices. arXiv preprint arXiv:1009.5055, 2010.

[40] K. Ma, Z. Duanmu, Q. Wu, Z. Wang, H. Yong, H. Li, and
L. Zhang. Waterloo exploration database: New challenges
for image quality assessment models. IEEE Transactions on
Image Processing, 26(2):1004–1016, 2017.

[41] J. Mairal, M. Elad, and G. Sapiro. Sparse representation for
color image restoration. IEEE Transactions on Image Pro-
cessing, 17(1):53–69, 2008.

[42] T. Miyata. Inter-channel relation based vectorial total varia-
tion for color image recovery. In IEEE International Confer-
ence on Image Processing,, pages 2251–2255, 2015.
[43] S. Osher, M. Burger, D. Goldfarb, J. Xu, and W. Yin. An it-
erative regularization method for total variation-based image
restoration. Multiscale Modeling & Simulation, 4(2):460–
489, 2005.

[44] N. Parikh, S. P. Boyd, et al. Proximal algorithms. Founda-
tions and Trends in optimization, 1(3):127–239, 2014.
[45] T. Peleg and M. Elad. A statistical prediction model based
on sparse representations for single image super-resolution.
IEEE Transactions on Image Processing, 23(6):2569–2582,
2014.

[46] A. Rajwade, A. Rangarajan, and A. Banerjee.

Image de-
noising using the higher order singular value decomposition.
IEEE Transactions on Pattern Analysis and Machine Intelli-
gence, 35(4):849–862, 2013.

[47] W. H. Richardson. Bayesian-based iterative method of image

restoration. JOSA, 62(1):55–59, 1972.

[48] Y. Romano, M. Elad, and P. Milanfar. The little engine that
could regularization by denoising (RED). arXiv preprint
arXiv:1611.02862, 2016.

[49] A. Rond, R. Giryes, and M. Elad. Poisson inverse problems
by the plug-and-play scheme. Journal of Visual Communi-
cation and Image Representation, 41:96–108, 2016.

[50] S. Roth and M. J. Black. Fields of experts.

International

Journal of Computer Vision, 82(2):205–229, 2009.

[51] U. Schmidt and S. Roth. Shrinkage ﬁelds for effective image
In IEEE Conference on Computer Vision and

restoration.

10

7
1
0
2
 
r
p
A
 
1
1
 
 
]

V
C
.
s
c
[
 
 
1
v
4
6
2
3
0
.
4
0
7
1
:
v
i
X
r
a

Learning Deep CNN Denoiser Prior for Image Restoration

Kai Zhang1,2, Wangmeng Zuo1, Shuhang Gu2, Lei Zhang2
1School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China
2Dept. of Computing, The Hong Kong Polytechnic University, Hong Kong, China
cskaizhang@gmail.com, wmzuo@hit.edu.cn, shuhanggu@gmail.com, cslzhang@comp.polyu.edu.hk

Abstract

Model-based optimization methods and discriminative
learning methods have been the two dominant strategies for
solving various inverse problems in low-level vision. Typi-
cally, those two kinds of methods have their respective mer-
its and drawbacks, e.g., model-based optimization methods
are ﬂexible for handling different inverse problems but are
usually time-consuming with sophisticated priors for the
purpose of good performance; in the meanwhile, discrim-
inative learning methods have fast testing speed but their
application range is greatly restricted by the specialized
task. Recent works have revealed that, with the aid of vari-
able splitting techniques, denoiser prior can be plugged in
as a modular part of model-based optimization methods to
solve other inverse problems (e.g., deblurring). Such an
integration induces considerable advantage when the de-
noiser is obtained via discriminative learning. However, the
study of integration with fast discriminative denoiser prior
is still lacking. To this end, this paper aims to train a set of
fast and effective CNN (convolutional neural network) de-
noisers and integrate them into model-based optimization
method to solve other inverse problems. Experimental re-
sults demonstrate that the learned set of denoisers not only
achieve promising Gaussian denoising results but also can
be used as prior to deliver good performance for various
low-level vision applications.

1. Introduction

Image restoration (IR) has been a long-standing prob-
lem for its highly practical value in various low-level vision
applications [1, 9, 47].
In general, the purpose of image
restoration is to recover the latent clean image x from its
degraded observation y = Hx + v, where H is a degrada-
tion matrix, v is additive white Gaussian noise of standard
deviation σ. By specifying different degradation matrices,
one can correspondingly get different IR tasks. Three clas-
sical IR tasks would be image denoising when H is an iden-
tity matrix, image deblurring when H is a blurring operator,

image super-resolution when H is a composite operator of
blurring and down-sampling.

Since IR is an ill-posed inverse problem, the prior which
is also called regularization needs to be adopted to con-
straint the solution space [50, 66]. From a Bayesian per-
spective, the solution ˆx can be obtained by solving a Maxi-
mum A Posteriori (MAP) problem,

ˆx = arg max

log p(y|x) + log p(x)

(1)

x

where log p(y|x) represents the log-likelihood of observa-
tion y, log p(x) delivers the prior of x and is independent
of y. More formally, Eqn. (1) can be reformulated as

ˆx = arg min

(cid:107)y − Hx(cid:107)2 + λΦ(x)

(2)

1
2

x

where the solution minimizes an energy function composed
of a ﬁdelity term 1
2 (cid:107)y − Hx(cid:107)2, a regularization term Φ(x)
and a trade-off parameter λ. The ﬁdelity term guarantees
the solution accords with the degradation process, while the
regularization term enforces desired property of the output.
Generally, the methods to solve Eqn. (2) can be divided
into two main categories, i.e., model-based optimization
methods and discriminative learning methods. The model-
based optimization methods aim to directly solve Eqn. (2)
with some optimization algorithms which usually involve a
time-consuming iterative inference. On the contrary, dis-
criminative learning methods try to learn the prior parame-
ters Θ and a compact inference through an optimization of
a loss function on a training set containing degraded-clean
image pairs [2, 13, 51, 55, 57]. The objective is generally
given by

1
2

x

s.t.

min
Θ

(cid:96)(ˆx, x)

ˆx = arg min

(cid:107)y−Hx(cid:107)2+λΦ(x; Θ)
(3)
Because the inference is guided by the MAP estimation, we
refer to such methods as MAP inference guided discrimi-
native learning methods. By replacing the MAP inference
with a predeﬁned nonlinear function ˆx = f (y, H; Θ), one

1

can treat the plain discriminative learning methods as gen-
eral case of Eqn. (3). It can be seen that one obvious dif-
ference between model-based optimization method and dis-
criminative learning method is that, the former is ﬂexible
to handle various IR tasks by specifying degradation matrix
H, whereas the later needs to use the training data with cer-
tain degradation matrices to learn the model. As a conse-
quence, different from model-based optimization methods
which have ﬂexibility to handle different IR tasks, discrimi-
native learning methods are usually restricted by specialized
tasks. For example, model-based optimization methods
such as NCSR [22] are ﬂexible to handle denoising, super-
resolution and deblurring, whereas discriminative learning
methods MLP [8], SRCNN [21], DCNN [62] are designed
for those three tasks, respectively. Even for a speciﬁc task
such as denoising, model-based optimization methods (e.g.,
BM3D [17] and WNNM [29]) can handle different noise
levels, whereas discriminative learning method of [34] sep-
arately train a different model for each level.

With the sacriﬁce of ﬂexibility, however, discriminative
learning methods can not only enjoy a fast testing speed
but also tend to deliver promising performance due to the
joint optimization and end-to-end training. On the con-
trary, model-based optimization methods are usually time-
consuming with sophisticated priors for the purpose of good
performance [27]. As a result, those two kinds of meth-
ods have their respective merits and drawbacks, and thus
it would be attractive to investigate their integration which
leverages their respective merits. Fortunately, with the aid
of variable splitting techniques, such as alternating direc-
tion method of multipliers (ADMM) method [5] and half-
quadratic splitting (HQS) method [28], it is possible to deal
with ﬁdelity term and regularization term separately [44],
and particularly, the regularization term only corresponds
to a denoising subproblem [18, 31, 61]. Consequently, this
enables an integration of any discriminative denoisers into
model-based optimization methods. However, to the best of
our knowledge, the study of integration with discriminative
denoiser is still lacking.

This paper aims to train a set of fast and effective
discriminative denoisers and integrate them into model-
based optimization methods to solve other inverse prob-
lems. Rather than learning MAP inference guided discrim-
inative models, we instead adopt plain convolutional neural
networks (CNN) to learn the denoisers, so as to take ad-
vantage of recent progress in CNN as well as the merit of
GPU computation. Particularly, several CNN techniques,
including Rectiﬁer Linear Units (ReLU) [37], batch nor-
malization [32], Adam [36], dilated convolution [63] are
adopted into the network design or training. As well as pro-
viding good performance for image denoising, the learned
set of denoisers are plugged in a model-based optimization
method to tackle various inverse problems.

The contribution of this work is summarized as follows:

• We trained a set of fast and effective CNN denoisers.
With variable splitting technique, the powerful denois-
ers can bring strong image prior into model-based op-
timization methods.

• The learned set of CNN denoisers are plugged in as
a modular part of model-based optimization methods
to tackle other inverse problems. Extensive experi-
ments on classical IR problems, including deblurring
and super-resolution, have demonstrated the merits of
integrating ﬂexible model-based optimization methods
and fast CNN-based discriminative learning methods.

2. Background

2.1. Image Restoration with Denoiser Prior

There have been several attempts to incorporate denoiser
prior into model-based optimization methods to tackle with
other inverse problems. In [19], the authors used Nash equi-
librium to derive an iterative decoupled deblurring BM3D
(IDDBM3D) method for image debluring. In [24], a simi-
lar method which is equipped with CBM3D denoiser prior
was proposed for single image super-resolution (SISR). By
iteratively updating a back-projection step and a CBM3D
denoising step, the method has an encouraging performance
for its PSNR improvement over SRCNN [21].
In [18],
the augmented Lagrangian method was adopted to fuse the
BM3D denoiser into an image deblurring scheme. With
a similar iterative scheme to [19], a plug-and-play priors
framework based on ADMM method was proposed in [61].
Here we note that, prior to [61], a similar idea of plug-
and-play is also mentioned in [66] where a half quadratic
splitting (HQS) method was proposed for image denois-
ing, deblurring and inpainting.
In [31], the authors used
an alternative to ADMM and HQS, i.e., the primal-dual
algorithm [11], to decouple ﬁdelity term and regulariza-
tion term. Some of the other related work can be found
in [6, 12, 48, 49, 54, 58]. All the above methods have shown
that the decouple of the ﬁdelity term and regularization term
can enable a wide variety of existing denoising models to
solve different image restoration tasks.

We can see that the denoiser prior can be plugged in an
iterative scheme via various ways. The common idea be-
hind those ways is to decouple the ﬁdelity term and reg-
ularization term. For this reason, their iterative schemes
generally involve a ﬁdelity term related subproblem and a
denoising subproblem. In the next subsection, we will use
HQS method as an example due to its simplicity. It should
be noted that although the HQS can be viewed as a gen-
eral way to handle different image restoration tasks, one can
also incorporate the denoiser prior into other convenient and
proper optimization methods for a speciﬁc application.

2

2.2. Half Quadratic Splitting (HQS) Method

3. Learning Deep CNN Denoiser Prior

1
2

x

1
2

Basically, to plug the denoiser prior into the optimiza-
tion procedure of Eqn. (2), the variable splitting technique
is usually adopted to decouple the ﬁdelity term and regular-
ization term. In half quadratic splitting method, by intro-
ducing an auxiliary variable z, Eqn. (2) can be reformulated
as a constrained optimization problem which is given by

ˆx = arg min

(cid:107)y − Hx(cid:107)2 + λΦ(z)

s.t. z = x (4)

Then, HQS method tries to minimize the following cost
function

Lµ(x, z) =

(cid:107)y − Hx(cid:107)2 + λΦ(z) +

(cid:107)z − x(cid:107)2

(5)

µ
2

where µ is a penalty parameter which varies iteratively in a
non-descending order. Eqn. (5) can be solved via the fol-
lowing iterative scheme,




xk+1 = arg min



zk+1 = arg min

(cid:107)y − Hx(cid:107)2 + µ(cid:107)x − zk(cid:107)2 (6a)
µ
2

(cid:107)z − xk+1(cid:107)2 + λΦ(z)

(6b)

x

z

As one can see, the ﬁdelity term and regularization term are
decoupled into two individual subproblems. Speciﬁcally,
the ﬁdelity term is associated with a quadratic regularized
least-squares problem (i.e., Eqn. (6a)) which has various
fast solutions for different degradation matrices. A direct
solution is given by

xk+1 = (HT H + µI)−1(HT y + µzk)

(7)

The regularization term is involved in Eqn. (6b) which can
be rewritten as

zk+1 = arg min

z

1
2((cid:112)λ/µ)2

(cid:107)xk+1 − z(cid:107)2 + Φ(z)

(8)

(9)

According to Bayesian probability, Eqn. (8) corresponds
to denoising the image xk+1 by a Gaussian denoiser with
noise level (cid:112)λ/µ. As a consequence, any Gaussian de-
noisers can be acted as a modular part to solve Eqn. (2). To
address this, we rewrite Eqn. (8) by following
zk+1 = Denoiser(xk+1, (cid:112)λ/µ)
It is worth noting that, according to Eqns. (8) and (9), the
image prior Φ(·) can be implicitly replaced by a denoiser
prior. Such a promising property actually offers several ad-
vantages. First, it enables to use any gray or color denois-
ers to solve a variety of inverse problems. Second, the ex-
plicit image prior Φ(·) can be unknown in solving Eqn. (2).
Third, several complementary denoisers which exploit dif-
ferent image priors can be jointly utilized to solve one spe-
ciﬁc problem. Note that this property can be also em-
ployed in other optimization methods (e.g., iterative shrink-
age/thresholding algorithms ISTA [4, 14] and FISTA [3]) as
long as there involves a denoising subproblem.

3.1. Why Choose CNN Denoiser?

As the regularization term of Eqn. (2) plays a vital role in
restoration performance, the choice of denoiser priors thus
would be pretty important in Eqn. (9). Existing denoiser
priors that have been adopted in model-based optimization
methods to solve other inverse problems include total varia-
tion (TV) [10, 43], Gaussian mixture models (GMM) [66],
K-SVD [25], non-local means [7] and BM3D [17]. Such de-
noiser priors have their respective drawbacks. For example,
TV can create watercolor-like artifacts; K-SVD denoiser
prior suffers high computational burden; non-local means
and BM3D denoiser priors may over-smooth the irregular
structures if the image does not exhibit self-similarity prop-
erty. Thus, strong denoiser prior which can be implemented
efﬁciently is highly demanded.

Regardless of the speed and performance, color image
prior or denoiser is also a key factor that needs to be taken
into account. This is because most of the images acquired
by modern cameras or transmitted in internet are in RGB
format. Due to the correlation between different color chan-
nels, it has been acknowledged that jointly handling the
color channels tends to produce better performance than in-
dependently dealing with each color channel [26]. How-
ever, existing methods mainly focus on modeling gray im-
age prior and there are only a few works concentrating
on modeling color image prior (see, e.g.,
[16, 41, 46]).
Perhaps the most successful color image prior modeling
method is CBM3D [16]. It ﬁrst decorrelates the image into
a luminance-chrominance color space by a hand-designed
linear transform and then applies the gray BM3D method
in each transformed color channels. While CBM3D is
promising for color image denoising, it has been pointed
out that the resulting transformed luminance-chrominance
color channels still remain some correlation [42] and it is
preferable to jointly handle RGB channels. Consequently,
instead of utilizing the hand-designed pipeline, using dis-
criminative learning methods to automatically reveal the un-
derlying color image prior would be a good alternative.

By considering the speed, performance and discrimina-
tive color image prior modeling, we choose deep CNN to
learn the discriminative denoisers. The reasons of using
CNN are four-fold. First, the inference of CNN is very ef-
ﬁcient due to the parallel computation ability of GPU. Sec-
ond, CNN exhibits powerful prior modeling capacity with
deep architecture. Third, CNN exploits the external prior
which is complementary to the internal prior of many ex-
isting denoisers such as BM3D. In other words, a combina-
tion with BM3D is expected to improve the performance.
Fourth, great progress in training and designing CNN have
been made during the past few years and we can take advan-
tage of those progress to facilitate discriminative learning.

3

Figure 1. The architecture of the proposed denoiser network. Note that “s-DConv” denotes s-dilated convolution [63], here s = 1, 2, 3 and
4; “BNorm” represents batch normalization [32]; “ReLU” is the rectiﬁed linear units (max(·, 0)).

3.2. The Proposed CNN Denoiser

The architecture of the proposed CNN denoiser is illus-
It consists of seven layers with three
trated in Figure 1.
different blocks, i.e., “Dilated Convolution+ReLU” block
in the ﬁrst layer, ﬁve “Dilated Convolution+Batch Normal-
ization+ReLU” blocks in the middle layers, and “Dilated
Convolution” block in the last layer. The dilation factors of
(3×3) dilated convolutions from ﬁrst layer to the last layer
are set to 1, 2, 3, 4, 3, 2 and 1, respectively. The number
of feature maps in each middle layer is set to 64. In the fol-
lowing, we will give some important details in our network
design and training.

Using Dilated Filter to Enlarge Receptive Field. It has
been widely acknowledged that the context information fa-
cilitates the reconstruction of the corrupted pixel in image
denoising. In CNN, to capture the context information, it
successively enlarges the receptive ﬁeld through the for-
ward convolution operations. Generally, there are two basic
ways to enlarge the receptive ﬁeld of CNN, i.e., increas-
ing the ﬁlter size and increasing the depth. However, in-
creasing the ﬁlter size would not only introduce more pa-
rameters but also increase the computational burden [53].
Thus, using 3×3 ﬁlter with a large depth is popularized in
existing CNN network design [30, 35, 56]. In this paper,
we instead use the recent proposed dilated convolution to
make a tradeoff between the size of receptive ﬁled and net-
work depth. Dilated convolution is known for its expansion
capacity of the receptive ﬁeld while keeping the merits of
traditional 3×3 convolution. A dilated ﬁlter with dilation
factor s can be simply interpreted as a sparse ﬁlter of size
(2s+1)×(2s+1) where only 9 entries of ﬁxed positions can
be non-zeros. Hence, the equivalent receptive ﬁeld of each
layer is 3, 5, 7, 9, 7, 5 and 3. Consequently, it can be eas-
ily obtained that the receptive ﬁled of the proposed network
is 33×33. If the traditional 3×3 convolution ﬁlter is used,
the network will either have a receptive ﬁled of size 15×15
with the same network depth (i.e., 7) or have a depth of 16
with the same receptive ﬁled (i.e., 33×33). To show the

advantage of our design over the above two cases, we have
trained three different models on noise level 25 with same
training settings. It turns out that our designed model can
have an average PSNR of 29.15dB on BSD68 dataset [50],
which is much better than 28.94dB of 7 layers network with
traditional 3×3 convolution ﬁlter and very close to 29.20dB
of 16 layers network.

Using Batch Normalization and Residual Learning to
Accelerate Training. While advanced gradient optimiza-
tion algorithms can accelerate training and improve the per-
formance, the architecture design is also an important fac-
tor. Batch normalization and residual learning which are
two of the most inﬂuential architecture design techniques
have been widely adopted in recent CNN architecture de-
signs. In particular, it has been pointed out that the combi-
nation of batch normalization and residual learning is par-
ticularly helpful for Gaussian denoising since they are ben-
eﬁcial to each other. To be speciﬁc, it not only enables fast
and stable training but also tends to result in better denois-
ing performance [65]. In this paper, such strategy is adopted
and we empirically ﬁnd it also can enable fast transfer from
one model to another with different noise level.

Using Training Samples with Small Size to Help Avoid
Boundary Artifacts. Due to the characteristic of convolu-
tion, the denoised image of CNN may introduce annoying
boundary artifacts without proper handling. There are two
common ways to tackle with this, i.e., symmetrical padding
and zero padding. We adopt the zero padding strategy and
wish the designed CNN has the capacity to model image
boundary. Note that the dilated convolution with dilation
factor 4 in the fourth layer pads 4 zeros in the boundaries
of each feature map. We empirically ﬁnd that using training
samples with small size can help avoid boundary artifacts.
The main reason lies in the fact that, rather than using train-
ing patches of large size, cropping them into small patches
can enable CNN to see more boundary information. For ex-
ample, by cropping an image patch of size 70×70 into four
small non-overlap patches of size 35×35, the boundary in-

4

formation would be largely augmented. We also have tested
the performance by using patches of large size, we empiri-
cally ﬁnd this does not improve the performance. However,
if the size of the training patch is smaller than the receptive
ﬁeld, the performance would decrease.

Learning Speciﬁc Denoiser Model with Small Interval
Noise Levels. Since the iterative optimization framework
requires various denoiser models with different noise lev-
els, a practical issue on how to train the discriminative mod-
els thus should be taken into consideration. Various studies
have shown that if the exact solutions of subproblems (i.e.,
Eqn. (6a) and Eqn. (6b)) are difﬁcult or time-consuming to
optimize, then using an inexact but fast subproblem solu-
tion may accelerate the convergence [39, 66].
In this re-
spect, their is no need to learn many discriminative denoiser
models for each noise level. On the other hand, although
Eqn. (9) is a denoiser, it has a different goal from the tradi-
tional Gaussian denoising. The goal of traditional Gaussian
denoising is to recover the latent clean image, however, the
denoiser here just acts its own role regardless of the noise
type and noise level of the image to be denoised. There-
fore, the ideal discriminative denoiser in Eqn. (9) should be
trained by current noise level. As a result, there is tradeoff
to set the number of denoisers. In this paper, we trained a
set of denoisers on noise level range [0, 50] and divided it by
a step size of 2 for each model, resulting in a set of 25 de-
noisers for each gray and color image prior modelling. Due
to the iterative scheme, it turns out the noise level range of
[0, 50] is enough to handle various image restoration prob-
lems. Especially noteworthy is the number of the denoisers
which is much less than that of learning different models for
different degradations.

4. Experiments

The Matlab source code of the proposed method can be
downloaded at https://github.com/cszn/ircnn.

4.1. Image Denoising

It is widely acknowledged that convolutional neural net-
works generally beneﬁt from the availability of large train-
ing data. Hence, instead of training on a small dataset con-
sisting of 400 Berkeley segmentation dataset (BSD) images
of size 180×180 [13], we collect a large dataset which in-
cludes 400 BSD images, 400 selected images from valida-
tion set of ImageNet database [20] and 4,744 images of Wa-
terloo Exploration Database [40]. We empirically ﬁnd using
large dataset does not improve the PSNR results of BSD68
dataset [50] but can slightly improve the performance of
other testing images. We crop the images into small patches
of size 35×35 and select N =256×4,000 patches for train-
ing. As for the generation of corresponding noisy patches,
we achieve this by adding additive Gaussian noise to the

Table 1. The average PSNR(dB) results of different methods on
(gray) BSD68 dataset.

Methods
σ = 15
σ = 25
σ = 50

BM3D
31.07
28.57
25.62

WNNM
31.37
28.83
25.87

TNRD
31.42
28.92
25.97

MLP
-
28.96
26.03

Proposed
31.63
29.15
26.19

Table 2. The average PSNR(dB) results of CBM3D and proposed
CNN denoiser on (color) BSD68 dataset.

Noise Level
CBM3D
Proposed

5
40.24
40.36

15
33.52
33.86

25
30.71
31.16

35
28.89
29.50

50
27.38
27.86

clean patches during training. Since the residual learning
strategy is adopted, we use the following loss function,

(cid:96)(Θ) =

(cid:107)f (yi; Θ) − (yi − xi)(cid:107)2
F

(10)

1
2N

N
(cid:88)

i=1

where {(yi, xi)}N
i=1 represents N noisy-clean patch pairs.
To optimize the network parameters Θ,
the Adam
solver [36] is adopted. The step size is started from 1e−3
and then ﬁxed to 1e−4 when the training error stops de-
creasing. The training was terminated if the training error
was ﬁxed in ﬁve sequential epochs. For the other hyper-
parameters of Adam, we use their default setting. The mini-
batch size is set to 256. Rotation or/and ﬂip based data aug-
mentation is used during mini-batch learning. The denoiser
models are trained in Matlab (R2015b) environment with
MatConvNet package [60] and an Nvidia Titan X GPU. To
reduce the whole training time, once a model is obtained,
we initialize the adjacent denoiser with this model. It takes
about three days to train the set of denoiser models.

We compared the proposed denioser with several state-
of-the-art denoising methods, including two model-based
optimization methods (i.e., BM3D [17] and WNNM [29]),
two discriminative learning methods (i.e., MLP [8] and
TNRD [13]). The gray image denoising results of different
methods on BSD68 dataset are shown in Table 1. It can be
seen that WNNM, MLP and TNRD can outperform BM3D
by about 0.3dB in PSNR. However, the proposed CNN de-
noiser can have a PSNR gain of about 0.2dB over those
three methods. Table 2 shows the color image denoising
results of benchmark CBM3D and our proposed CNN de-
noiser, it can be seen that the proposed denoiser consistently
outperforms CBM3D by a large margin. Such a promising
result can be attributed to the powerful color image prior
modeling capacity of CNN.

For the run time, we compared with BM3D and TNRD
due to their potential value in practical applications. Since
the proposed denoiser and TNRD support parallel compu-
tation on GPU, we also give the GPU run time. To make a
further comparison with TNRD under similar PSNR perfor-

5

mance, we additionally provide the run time of the proposed
denoiser where each middle layer has 24 feature maps. We
use the Nvidia cuDNN-v5 deep learning library to acceler-
ate the GPU computation and the memory transfer time be-
tween CPU and GPU is not considered. Table 3 shows the
run times of different methods for denoising images of size
256×256, 512×512 and 1024×1024 with noise level 25.
We can see that the proposed denoiser is very competitive
in both CPU and GPU implementation. It is worth empha-
sizing that the proposed denoiser with 24 feature maps of
each layer has a comparable PSNR of 28.94dB to TNRD but
delivers a faster speed. Such a good compromise between
speed and performance over TNRD is properly attributed to
the following three reasons. First, the adopted 3×3 convo-
lution and ReLU nonlinearity are simple yet effective and
efﬁcient. Second, in contrast to the stage-wise architecture
of TNRD which essentially has a bottleneck in each imme-
diate output layer, ours encourages a ﬂuent information ﬂow
among different layers, thus having larger model capacity.
Third, batch normalization which is beneﬁcial to Gaussian
denoising is adopted. According to the above discussions,
we can conclude that the proposed denoiser is a strong com-
petitor against BM3D and TNRD.

Table 3. Run time (in seconds) of different methods on images of
size 256×256, 512×512 and 1024×1024 with noise level 25.

Size

256×256

512×512

1024×1024

Device
CPU
GPU
CPU
GPU
CPU
GPU

BM3D
0.66
-
2.91
-
11.89
-

TNRD
0.47
0.010
1.33
0.032
4.61
0.116

Proposed24 Proposed64

0.10
0.006
0.39
0.016
1.60
0.059

0.310
0.012
1.24
0.038
4.65
0.146

4.2. Image Deblurring

As a common setting, the blurry images are synthesized
by ﬁrst applying a blur kernel and then adding additive
Gaussian noise with noise level σ. In addition, we assume
the convolution is carried out with circular boundary con-
ditions. Thus, an efﬁcient implementation of Eqn. (7) by
using Fast Fourier Transform (FFT) can be employed. To
make a thorough evaluation, we consider three blur kernels,
including a commonly-used Gaussian kernel with standard
deviation 1.6 and the ﬁrst two of the eight real blur kernels
from [38]. As shown in Table 4, we also consider Gaussian

(a)

(b)

(c)

(d)

(e)

(f)

Figure 2. Six testing images for image deblurring. (a) Cameraman;
(b) House; (c) Lena; (d) Monarch; (e) Leaves; (f) Parrots.

6

noise with different noise levels. For the compared meth-
ods, we choose one discriminative method named MLP [52]
and three model based optimization methods, including ID-
DBM3D [19], NCSR [22] and EPLL. Among the testing
images, apart from three classical gray images as shown
in Figure 2, three color images are also included such that
we can test the performance of learned color denoiser prior.
In the meanwhile, we note that the above methods are de-
signed for gray image deblurring. Specially, NCSR tackles
the color input by ﬁrst transforming it into YCbCr space and
then conducting the main algorithm in the luminance com-
ponent. In the following experiments, we simply plug the
color denoisers into the HQS framework, whereas we sep-
arately handle each color channel for IDDBM3D and MLP.
Note that MLP trained a speciﬁc model for the Gaussian
blur kernel with noise level 2.

Once the denoisers are provided, the subsequent crucial
issue would be parameter setting. From Eqns. (6), we can
note that there involve two parameters, λ and µ, to tune.
Generally, for a certain degradation, λ is correlated with
σ2 and keeps ﬁxed during iterations, while µ controls noise
level of denoiser. Since the HQS framework is denoiser-
based, we instead set the noise level of denoiser in each
iteration to implicitly determine µ. Note that the noise level
of denoiser (cid:112)λ/µ should be set from large to small.
In
our experimental settings, it is decayed exponentially from
49 to a value in [1, 15] depending on the noise level. The
number of iterations is set to 30 as we ﬁnd it is large enough
to obtain a satisfying performance.

The PSNR results of different methods are shown in Ta-
ble 4. As one can see, the proposed CNN denoiser prior
based optimization method achieves very promising PSNR
results. Figure 3 illustrates deblurred Leaves image by dif-
ferent methods. We can see that IDDBM3D, NCSR and
MLP tend to smooth the edges and generate color artifacts.
In contrast, the proposed method can recover image sharp-
ness and naturalness.

Table 4. Deblurring results of different methods.
Leaves

σ
Gaussian blur with standard deviation 1.6

C.man House

Monar.

Lena

Kernel 1 (19×19) [38]

27.08
27.99
27.84
28.12

29.43
32.07
25.33
28.11

29.67
31.69
24.85
27.70

32.41
33.38
33.43
33.80

31.48
35.17
28.19
32.03

32.26
35.04
28.08
31.94

30.28
30.99
31.10
31.17

31.68
33.88
27.37
29.51

31.00
33.53
27.03
29.27

Kernel 2 (17×17) [38]

27.02
28.32
28.87
30.00

28.75
33.62
22.67
29.20

27.53
33.13
21.60
28.73

26.95
27.50
28.91
29.78

27.34
33.92
21.67
29.07

26.75
33.51
21.09
28.63

2

2.55

7.65

2.55

7.65

Methods

IDDBM3D
NCSR
MLP
Proposed

EPLL
Proposed
EPLL
Proposed

EPLL
Proposed
EPLL
Proposed

Parrots

30.15
30.42
31.24
32.07

30.89
35.49
26.08
31.63

30.44
35.17
25.77
31.35

(a) Blurry and noisy image

(b) IDDBM3D (26.95dB)

(c) NCSR (27.50dB)

(d) MLP (28.91dB)

(e) Proposed (29.78dB)

Figure 3. Image deblurring performance comparison for Leaves image (the blur kernel is Gaussian kernel with standard deviation 1.6, the
noise level σ is 2).

4.3. Single Image Super-Resolution

In general, the low-resolution (LR) image can be mod-
eled by a blurring and subsequent down-sampling opera-
tion on a high-resolution one. The existing super-resolution
models, however, mainly focus on modeling image prior
and are trained for speciﬁc degradation process. This makes
the learned model deteriorates seriously when the blur ker-
nel adopted in training deviates from the real one [23, 64].
Instead, our model can handle any blur kernels without re-
training. Thus, in order to thoroughly evaluate the ﬂexibil-
ity of the CNN denoiser prior based optimization method
as well as the effectiveness of the CNN denoisers, follow-
ing [45], this paper considers three typical image degrada-
tion settings for SISR, i.e., bicubic downsampling (default
setting of Matlab function imresize) with two scale fac-
tors 2 and 3 [15, 21] and blurring by Gaussian kernel of size
7×7 with standard deviation 1.6 followed by downsampling
with scale factor 3 [22, 45].

Inspired by the method proposed in [24] which itera-
tively updates a back-projection [33] step and a denoising
step for SISR, we use the following back-projection itera-
tion to solve Eqn. (6a),

xk+1 = xk − α(y − xk ↓sf) ↑sf

bicubic

(11)

where ↓sf denotes the degradation operator with downscal-
ing factor sf, ↑sf
bicubic represents bicubic interpolation opera-
tor with upscaling factor sf, and α is the step size. It is wor-
thy noting that the iterative regularization step of methods
such as NCSR and WNNM actually corresponds to solv-
ing Eqn. (6a). From this viewpoint, those methods are opti-
mized under HQS framework. Here, note that only the bicu-
bic downsampling is considered in [24], whereas Eqn. (11)
is extended to deal with different blur kernels. To obtain a
fast convergence, we repeat Eqn. (11) ﬁve times before ap-
plying the denoising step. The number of main iterations is
set to 30, the step size α is ﬁxed to 1.75 and the noise levels
of denoiser are decayed exponentially from 12×sf to sf.

The proposed deep CNN denoiser prior based SISR
method is compared with ﬁve state-of-the-art methods, in-

cluding two CNN-based discriminative learning methods
(i.e., SRCNN [21] and VDSR [35]), one statistical pre-
diction model based discriminative learning method [45]
which we refer to as SPMSR, one model based optimiza-
tion method (i.e., NCSR [22]) and one denoiser prior based
method (i.e., SRBM3D [24]). Except for SRBM3D, all
the existing methods conducted their main algorithms on Y
channel (i.e., luminance) of transformed YCbCr space. In
order to evaluate the proposed color denoiser prior, we also
conduct experiments on the original RGB channels and thus
the PSNR results of super-resolved RGB images of different
methods are also given. Since the source code of SRBM3D
is not available, we also compare two methods which re-
place the proposed CNN denoiser with BM3D/CBM3D de-
noiser. Those two methods are denoted by SRBM3DG and
SRBM3DC, respectively.

Table 5 shows the average PSNR(dB) results of differ-
ent methods for SISR on Set5 and Set14 [59]. Note that
SRCNN and VDSR are trained with bicubic blur kernel,
thus it is unfair to use their models to super-resolve the
low-resolution image with Gaussian kernel. As a matter of
fact, we give their performances to demonstrate the limita-
tions of such discriminative learning methods. From Ta-
ble 5, we can have several observations. First, although
SRCNN and VDSR achieve promising results to tackle the
case with bicubic kernel, their performance deteriorates se-
riously when the low-resolution image are not generated
by bicubic kernel (see Figure 4). On the other hand, with
the accurate blur kernel, even NCSR and SPMSR outper-
form SRCNN and VDSR for Gaussian blur kernel. In con-
trast, the proposed methods (denoted by ProposedG and
ProposedC) can handle all the cases well. Second, the pro-
posed methods have a better PSNR result than SRBM3DC
and SRBM3DG which indicates good denoiser prior facil-
itates to solve super-resolution problem. Third, both of
the gray and color CNN denoiser prior based optimization
methods can produce promising results. As an example for
the testing speed comparison, our method can super-resolve
the Butterﬂy image in 0.5 second on GPU and 12 seconds
on CPU, whereas NCSR spends 198 seconds on CPU.

7

Table 5. Average PSNR(dB) results of different methods for single image super-resolution on Set5 and Set14.

Dataset

Scale

Kernel

SRBM3DG SRBM3DC ProposedG ProposedC

Set5

Set14

Bicubic

Bicubic

Gaussian

Bicubic

Bicubic

Gaussian

Channel
Y
RGB
Y
RGB
Y
RGB
Y
RGB
Y
RGB
Y
RGB

SRCNN
36.65
34.45
32.75
30.72
30.42
28.50
32.43
30.43
29.27
27.44
27.71
26.02

VDSR
37.56
35.16
33.67
31.50
30.54
28.62
33.02
30.90
29.77
27.85
27.80
26.11

NCSR
-
-
-
-
33.02
30.00
-
-
-
-
29.26
26.98

SPMSR
36.11
33.94
32.31
30.32
32.27
30.02
31.96
30.05
28.93
27.17
28.89
27.01

SRBM3D
37.10
-
33.30
-
-
-
32.80
-
29.60
-
-
-

36.34
34.11
32.62
30.57
32.66
30.31
32.09
30.15
29.11
27.32
29.18
27.24

2

3

3

2

3

3

36.25
34.22
32.54
30.69
32.59
30.74
32.25
30.32
29.27
27.47
29.39
27.60

37.43
35.05
33.39
31.26
33.38
30.92
32.88
30.79
29.61
27.72
29.63
27.59

37.22
35.07
33.18
31.25
33.17
31.21
32.79
30.78
29.50
27.67
29.55
27.70

(a) Ground-truth

(b) Zoomed LR image

(c) SRCNN (24.46dB)

(d) VDSR (24.73dB)

(e) ProposedG (29.32dB)

Figure 4. Single image super-resolution performance comparison for Butterﬂy image from Set5 (the blur kernel is 7×7 Gaussian kernel
with standard deviation 1.6, the scale factor is 3). Note that the comparison with SRCNN and VDSR is unfair. The proposed deep CNN
denoiser prior based optimization method can super-resolve the LR image by tuning the blur kernel and scale factor without training,
whereas SRCNN and VDSR need additional training to deal with such cases. As a result, this ﬁgure is mainly used to show the ﬂexibility
advantage of the proposed deep CNN denoiser prior based optimization method over discriminative learning methods.

5. Conclusion

In this paper, we have designed and trained a set of fast
and effective CNN denoisers for image denoising. Spe-
cially, with the aid of variable splitting technique, we have
plugged the learned denoiser prior into a model-based opti-
mization method of HQS to solve the image deblurring and
super-resolution problems. Extensive experimental results
have demonstrated that the integration of model-based op-
timization method and discriminative CNN denoiser results
in a ﬂexible, fast and effective framework for various image
restoration tasks. On the one hand, different from conven-
tional model-based optimization methods which are usually
time-consuming with sophisticated image priors for the pur-
pose of achieving good results, the proposed deep CNN de-
noiser prior based optimization method can be implemented
effectively due to the plug-in of fast CNN denoisers. On the
other hand, different from discriminative learning methods
which are specialized for certain image restoration tasks,
the proposed deep CNN denoiser prior based optimization
method is ﬂexible in handling various tasks while can pro-
duce very favorable results. In summary, this work high-
lights the potential beneﬁts of integrating ﬂexible model-
based optimization methods and fast discriminative learning
methods. In addition, this work has shown that learning ex-
pressive CNN denoiser prior is a good alternative to model
image prior.

While we have demonstrated various merits of plug-
ging powerful CNN denoiser into model-based optimiza-
tion methods, there also remain room for further study.
Some research directions are listed as follows. First, it will
be interesting to investigate how to reduce the number of
the discriminative CNN denoisers and the number of whole
iterations. Second, extending the proposed CNN denoiser
based HQS framework to other inverse problems such as
inpainting and blind deblurring would be also interesting.
Third, utilizing multiple priors which are complementary
to improve performance is certainly one promising direc-
tion. Finally, and perhaps most interestingly, since the HQS
framework can be treated as a MAP inference, this work
also provides some insights into designing CNN architec-
ture for task-speciﬁc discriminative learning. Meanwhile,
one should be aware that CNN has its own design ﬂexibility
and the best CNN architecture is not necessarily inspired by
MAP inference.

6. Acknowledgements

This work is supported by HK RGC General Research
Fund (PolyU 5313/13E) and National Natural Science
Foundation of China (grant no. 61672446, 61671182). We
gratefully acknowledge the support from NVIDIA Corpora-
tion for providing us the Titan X GPU used in this research.

8

References

[1] H. C. Andrews and B. R. Hunt. Digital image restoration.
Prentice-Hall Signal Processing Series, Englewood Cliffs:
Prentice-Hall, 1977, 1, 1977.

[2] A. Barbu. Training an active random ﬁeld for real-time im-
IEEE Transactions on Image Processing,

age denoising.
18(11):2451–2462, 2009.

[3] A. Beck and M. Teboulle. A fast iterative shrinkage-
thresholding algorithm for linear inverse problems. SIAM
journal on imaging sciences, 2(1):183–202, 2009.

[4] J. M. Bioucas-Dias and M. A. Figueiredo. A new TwIST:
Two-step iterative shrinkage/thresholding algorithms for im-
IEEE Transactions on Image Processing,
age restoration.
16(12):2992–3004, 2007.

[5] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein. Dis-
tributed optimization and statistical learning via the alternat-
ing direction method of multipliers. Foundations and Trends
in Machine Learning, 3(1):1–122, 2011.

[6] A. Brifman, Y. Romano, and M. Elad. Turning a denoiser
In IEEE
into a super-resolver using plug and play priors.
International Conference on Image Processing, pages 1404–
1408, 2016.

[8] H. C. Burger, C. J. Schuler, and S. Harmeling.

[7] A. Buades, B. Coll, and J.-M. Morel. A non-local algorithm
for image denoising. In IEEE Conference on Computer Vi-
sion and Pattern Recognition, volume 2, pages 60–65, 2005.
Image de-
noising: Can plain neural networks compete with BM3D? In
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 2392–2399, 2012.

[9] P. Campisi and K. Egiazarian. Blind image deconvolution:

theory and applications. CRC press, 2016.

[10] A. Chambolle. An algorithm for total variation minimiza-
tion and applications. Journal of Mathematical imaging and
vision, 20(1-2):89–97, 2004.

[11] A. Chambolle and T. Pock. A ﬁrst-order primal-dual al-
gorithm for convex problems with applications to imaging.
Journal of Mathematical Imaging and Vision, 40(1):120–
145, 2011.

[12] S. H. Chan, X. Wang, and O. A. Elgendy. Plug-and-Play
ADMM for image restoration: Fixed-point convergence and
applications. IEEE Transactions on Computational Imaging,
3(1):84–98, 2017.

[13] Y. Chen and T. Pock. Trainable nonlinear reaction diffusion:
A ﬂexible framework for fast and effective image restoration.
IEEE transactions on Pattern Analysis and Machine Intelli-
gence, 2016.

[14] P. L. Combettes and V. R. Wajs. Signal recovery by proximal
forward-backward splitting. Multiscale Modeling & Simula-
tion, 4(4):1168–1200, 2005.

[15] Z. Cui, H. Chang, S. Shan, B. Zhong, and X. Chen. Deep
In European

network cascade for image super-resolution.
Conference on Computer Vision, pages 49–64, 2014.
[16] K. Dabov, A. Foi, V. Katkovnik, and K. Egiazarian. Color
image denoising via sparse 3D collaborative ﬁltering with
grouping constraint in luminance-chrominance space.
In
IEEE International Conference on Image Processing, vol-
ume 1, pages I–313, 2007.

[17] K. Dabov, A. Foi, V. Katkovnik, and K. Egiazarian.

Im-
age denoising by sparse 3-D transform-domain collabora-

tive ﬁltering.
16(8):2080–2095, 2007.

IEEE Transactions on Image Processing,

[18] A. Danielyan, V. Katkovnik, and K. Egiazarian. Image de-
blurring by augmented lagrangian with BM3D frame prior.
In Workshop on Information Theoretic Methods in Science
and Engineering, pages 16–18, 2010.

[19] A. Danielyan, V. Katkovnik, and K. Egiazarian. BM3D
frames and variational image deblurring. IEEE Transactions
on Image Processing, 21(4):1715–1728, 2012.

[20] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-
Fei. Imagenet: A large-scale hierarchical image database. In
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 248–255, 2009.

[21] C. Dong, C. C. Loy, K. He, and X. Tang.

Image
IEEE
super-resolution using deep convolutional networks.
transactions on Pattern Analysis and Machine Intelligence,
38(2):295–307, 2016.

[22] W. Dong, L. Zhang, G. Shi, and X. Li. Nonlocally central-
ized sparse representation for image restoration. IEEE Trans-
actions on Image Processing, 22(4):1620–1630, 2013.
[23] N. Efrat, D. Glasner, A. Apartsin, B. Nadler, and A. Levin.
Accurate blur models vs. image priors in single image super-
resolution. In IEEE International Conference on Computer
Vision, pages 2832–2839, 2013.
[24] K. Egiazarian and V. Katkovnik.

Single image super-
In European Signal

resolution via BM3D sparse coding.
Processing Conference, pages 2849–2853, 2015.

[25] M. Elad and M. Aharon.

Image denoising via sparse
and redundant representations over learned dictionaries.
IEEE Transactions on Image processing, 15(12):3736–3745,
2006.

[26] A. Foi, V. Katkovnik, and K. Egiazarian.

Pointwise
shape adaptive DCT denoising with structure preservation
in luminance-chrominance space. In International Workshop
on Video Processing and Quality Metrics for Consumer Elec-
tronics, 2006.

[27] Q. Gao and S. Roth. How well do ﬁlter-based MRFs model
In Joint DAGM (German Association for
natural images?
Pattern Recognition) and OAGM Symposium, pages 62–72,
2012.

[28] D. Geman and C. Yang. Nonlinear image recovery with half-
quadratic regularization. IEEE Transactions on Image Pro-
cessing, 4(7):932–946, 1995.

[29] S. Gu, L. Zhang, W. Zuo, and X. Feng. Weighted nuclear
norm minimization with application to image denoising. In
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 2862–2869, 2014.

[30] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning
In IEEE Conference on Computer

for image recognition.
Vision and Pattern Recognition, pages 770–778, 2016.
[31] F. Heide, M. Steinberger, Y.-T. Tsai, M. Rouf, D. Pajak,
D. Reddy, O. Gallo, J. Liu, W. Heidrich, K. Egiazarian,
et al. Flexisp: A ﬂexible camera image processing frame-
work. ACM Transactions on Graphics, 33(6):231, 2014.
[32] S. Ioffe and C. Szegedy. Batch normalization: Accelerating
deep network training by reducing internal covariate shift. In
International Conference on Machine Learning, pages 448–
456, 2015.

[33] M. Irani and S. Peleg. Motion analysis for image enhance-

9

Pattern Recognition, pages 2774–2781, 2014.

[52] C. J. Schuler, H. Christopher Burger, S. Harmeling, and
B. Scholkopf. A machine learning approach for non-blind
image deconvolution. In IEEE Conference on Computer Vi-
sion and Pattern Recognition, pages 1067–1074, 2013.
[53] K. Simonyan and A. Zisserman. Very deep convolutional
networks for large-scale image recognition. In International
Conference for Learning Representations, 2015.

[54] S. Sreehari, S. Venkatakrishnan, B. Wohlberg, L. F. Drummy,
J. P. Simmons, and C. A. Bouman. Plug-and-play priors
for bright ﬁeld electron tomography and sparse interpolation.
arXiv preprint arXiv:1512.07331, 2015.

[55] J. Sun and M. F. Tappen. Separable markov random ﬁeld
model and its applications in low level vision. IEEE Trans-
actions on Image Processing, 22(1):402–407, 2013.

[56] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed,
D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich.
In IEEE Conference on
Going deeper with convolutions.
Computer Vision and Pattern Recognition, June 2015.
[57] M. F. Tappen. Utilizing variational optimization to learn
In IEEE Conference on Computer

markov random ﬁelds.
Vision and Pattern Recognition, pages 1–8, 2007.

[58] A. M. Teodoro, J. M. Bioucas-Dias, and M. A. Figueiredo.
Image restoration and reconstruction using variable splitting
and class-adapted image priors. In IEEE International Con-
ference on Image Processing, pages 3518–3522, 2016.
[59] R. Timofte, V. De Smet, and L. Van Gool. A+: Adjusted
anchored neighborhood regression for fast super-resolution.
In Asian Conference on Computer Vision, pages 111–126,
2014.

[60] A. Vedaldi and K. Lenc. MatConvNet: Convolutional neu-
ral networks for matlab. In ACM Conference on Multimedia
Conference, pages 689–692, 2015.

[61] S. V. Venkatakrishnan, C. A. Bouman, and B. Wohlberg.
Plug-and-play priors for model based reconstruction.
In
IEEE Global Conference on Signal and Information Pro-
cessing, pages 945–948, 2013.

[62] L. Xu, J. S. Ren, C. Liu, and J. Jia. Deep convolutional neural
In Advances in Neural

network for image deconvolution.
Information Processing Systems, pages 1790–1798, 2014.

[63] F. Yu and V. Koltun. Multi-scale context aggregation by di-
lated convolutions. arXiv preprint arXiv:1511.07122, 2015.
[64] K. Zhang, X. Zhou, H. Zhang, and W. Zuo. Revisiting sin-
gle image super-resolution under internet environment: blur
kernels and reconstruction algorithms. In Paciﬁc Rim Con-
ference on Multimedia, pages 677–687, 2015.

[65] K. Zhang, W. Zuo, Y. Chen, D. Meng, and L. Zhang. Be-
yond a Gaussian denoiser: Residual learning of deep CNN
for image denoising. IEEE Transactions on Image Process-
ing, 2017.

[66] D. Zoran and Y. Weiss. From learning models of natural
In IEEE Inter-
image patches to whole image restoration.
national Conference on Computer Vision, pages 479–486,
2011.

ment: Resolution, occlusion, and transparency. Journal of
Visual Communication and Image Representation, 4(4):324–
335, 1993.

[34] V. Jain and S. Seung. Natural image denoising with convo-
lutional networks. In Advances in Neural Information Pro-
cessing Systems, pages 769–776, 2009.

[35] J. Kim, J. K. Lee, and K. M. Lee. Accurate image super-
resolution using very deep convolutional networks. In IEEE
Conference on Computer Vision and Pattern Recognition,
pages 1646–1654, 2016.

[36] D. Kingma and J. Ba. Adam: A method for stochastic op-
timization. In International Conference for Learning Repre-
sentations, 2015.

[37] A. Krizhevsky, I. Sutskever, and G. E. Hinton.

Imagenet
In
classiﬁcation with deep convolutional neural networks.
Advances in Neural Information Processing Systems, pages
1097–1105, 2012.

[38] A. Levin, Y. Weiss, F. Durand, and W. T. Freeman. Under-
standing and evaluating blind deconvolution algorithms. In
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 1964–1971, 2009.

[39] Z. Lin, M. Chen, and Y. Ma. The augmented lagrange mul-
tiplier method for exact recovery of corrupted low-rank ma-
trices. arXiv preprint arXiv:1009.5055, 2010.

[40] K. Ma, Z. Duanmu, Q. Wu, Z. Wang, H. Yong, H. Li, and
L. Zhang. Waterloo exploration database: New challenges
for image quality assessment models. IEEE Transactions on
Image Processing, 26(2):1004–1016, 2017.

[41] J. Mairal, M. Elad, and G. Sapiro. Sparse representation for
color image restoration. IEEE Transactions on Image Pro-
cessing, 17(1):53–69, 2008.

[42] T. Miyata. Inter-channel relation based vectorial total varia-
tion for color image recovery. In IEEE International Confer-
ence on Image Processing,, pages 2251–2255, 2015.
[43] S. Osher, M. Burger, D. Goldfarb, J. Xu, and W. Yin. An it-
erative regularization method for total variation-based image
restoration. Multiscale Modeling & Simulation, 4(2):460–
489, 2005.

[44] N. Parikh, S. P. Boyd, et al. Proximal algorithms. Founda-
tions and Trends in optimization, 1(3):127–239, 2014.
[45] T. Peleg and M. Elad. A statistical prediction model based
on sparse representations for single image super-resolution.
IEEE Transactions on Image Processing, 23(6):2569–2582,
2014.

[46] A. Rajwade, A. Rangarajan, and A. Banerjee.

Image de-
noising using the higher order singular value decomposition.
IEEE Transactions on Pattern Analysis and Machine Intelli-
gence, 35(4):849–862, 2013.

[47] W. H. Richardson. Bayesian-based iterative method of image

restoration. JOSA, 62(1):55–59, 1972.

[48] Y. Romano, M. Elad, and P. Milanfar. The little engine that
could regularization by denoising (RED). arXiv preprint
arXiv:1611.02862, 2016.

[49] A. Rond, R. Giryes, and M. Elad. Poisson inverse problems
by the plug-and-play scheme. Journal of Visual Communi-
cation and Image Representation, 41:96–108, 2016.

[50] S. Roth and M. J. Black. Fields of experts.

International

Journal of Computer Vision, 82(2):205–229, 2009.

[51] U. Schmidt and S. Roth. Shrinkage ﬁelds for effective image
In IEEE Conference on Computer Vision and

restoration.

10

