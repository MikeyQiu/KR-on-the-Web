8
1
0
2
 
b
e
F
 
6
1
 
 
]
L
M

.
t
a
t
s
[
 
 
1
v
4
1
8
5
0
.
2
0
8
1
:
v
i
X
r
a

Variational Autoencoders for Collaborative Filtering

Dawen Liang
Netflix
Los Gatos, CA
dliang@netflix.com

Matthew D. Hoffman
Google AI
San Francisco, CA
mhoffman@google.com

Rahul G. Krishnan
MIT
Cambridge, MA
rahulgk@mit.edu

Tony Jebara
Netflix
Los Gatos, CA
tjebara@netflix.com

ABSTRACT

1 INTRODUCTION

We extend variational autoencoders (vaes) to collaborative filtering
for implicit feedback. This non-linear probabilistic model enables us
to go beyond the limited modeling capacity of linear factor models
which still largely dominate collaborative filtering research. We
introduce a generative model with multinomial likelihood and use
Bayesian inference for parameter estimation. Despite widespread
use in language modeling and economics, the multinomial likeli-
hood receives less attention in the recommender systems literature.
We introduce a different regularization parameter for the learning
objective, which proves to be crucial for achieving competitive per-
formance. Remarkably, there is an efficient way to tune the parame-
ter using annealing. The resulting model and learning algorithm has
information-theoretic connections to maximum entropy discrimi-
nation and the information bottleneck principle. Empirically, we
show that the proposed approach significantly outperforms several
state-of-the-art baselines, including two recently-proposed neural
network approaches, on several real-world datasets. We also pro-
vide extended experiments comparing the multinomial likelihood
with other commonly used likelihood functions in the latent factor
collaborative filtering literature and show favorable results. Finally,
we identify the pros and cons of employing a principled Bayesian
inference approach and characterize settings where it provides the
most significant improvements.

KEYWORDS

Recommender systems, collaborative filtering, implicit feedback,
variational autoencoder, Bayesian models

ACM Reference Format:
Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara.
2018. Variational Autoencoders for Collaborative Filtering. In Proceedings of
The 2018 Web Conference (WWW 2018). ACM, New York, NY, USA, 10 pages.
https://doi.org/10.1145/3178876.3186150

This paper is published under the Creative Commons Attribution-NonCommercial-
NoDerivs 4.0 International (CC BY-NC-ND 4.0) license. Authors reserve their rights to
disseminate the work on their personal and corporate Web sites with the appropriate
attribution.
WWW 2018, April 23–27, 2018, Lyon, France
© 2018 IW3C2 (International World Wide Web Conference Committee), published
under Creative Commons CC BY-NC-ND 4.0 License.
ACM ISBN 978-1-4503-5639-8/18/04.
https://doi.org/10.1145/3178876.3186150

Recommender systems are an integral component of the web. In
a typical recommendation system, we observe how a set of users
interacts with a set of items. Using this data, we seek to show users
a set of previously unseen items they will like. As the web grows
in size, good recommendation systems will play an important part
in helping users interact more effectively with larger amounts of
content.

Collaborative filtering is among the most widely applied ap-
proaches in recommender systems. Collaborative filtering predicts
what items a user will prefer by discovering and exploiting the
similarity patterns across users and items. Latent factor models
[13, 19, 38] still largely dominate the collaborative filtering research
literature due to their simplicity and effectiveness. However, these
models are inherently linear, which limits their modeling capacity.
Previous work [27] has demonstrated that adding carefully crafted
non-linear features into the linear latent factor models can signif-
icantly boost recommendation performance. Recently, a growing
body of work involves applying neural networks to the collabora-
tive filtering setting with promising results [14, 41, 51, 54].

Here, we extend variational autoencoders (vaes) [24, 37] to col-
laborative filtering for implicit feedback. Vaes generalize linear
latent-factor models and enable us to explore non-linear proba-
bilistic latent-variable models, powered by neural networks, on
large-scale recommendation datasets. We propose a neural gen-
erative model with multinomial conditional likelihood. Despite
being widely used in language modeling and economics [5, 30],
multinomial likelihoods appear less studied in the collaborative
filtering literature, particularly within the context of latent-factor
models. Recommender systems are often evaluated using ranking-
based measures, such as mean average precision and normalized
discounted cumulative gain [21]. Top-N ranking loss is difficult to
optimize directly and previous work on direct ranking loss mini-
mization resorts to relaxations and approximations [49, 50]. Here,
we show that the multinomial likelihoods are well-suited for mod-
eling implicit feedback data, and are a closer proxy to the ranking
loss relative to more popular likelihood functions such as Gaussian
and logistic.

Though recommendation is often considered a big-data problem
(due to the huge numbers of users and items typically present in a
recommender system), we argue that, in contrast, it represents a
uniquely challenging “small-data” problem: most users only inter-
act with a tiny proportion of the items and our goal is to collectively

make informed inference about each user’s preference. To make
use of the sparse signals from users and avoid overfitting, we build
a probabilistic latent-variable model that shares statistical strength
among users and items. Empirically, we show that employing a prin-
cipled Bayesian approach is more robust regardless of the scarcity
of the data.

Although vaes have been extensively studied for image modeling
and generation, there is surprisingly little work applying vaes to
recommender systems. We find that two adjustments are essential
to getting state-of-the-art results with vaes on this task:

• First, we use a multinomial likelihood for the data distribu-
tion. We show that this simple choice realizes models that
outperform the more commonly used Gaussian and logistic
likelihoods.

• Second, we reinterpret and adjust the standard vae objective,
which we argue is over-regularized. We draw connections
between the learning algorithm resulting from our proposed
regularization and the information-bottleneck principle and
maximum-entropy discrimination.

The result is a recipe that makes vaes practical solutions to this im-
portant problem. Empirically, our methods significantly outperform
state-of-the-art baselines on several real-world datasets, including
two recently proposed neural-network approaches.

2 METHOD

We use u ∈ {1, . . . , U } to index users and i ∈ {1, . . . , I } to index
items. In this work, we consider learning with implicit feedback
[19, 34]. The user-by-item interaction matrix is the click1 matrix
X ∈ NU ×I . The lower case xu = [xu1, . . . , xuI ]⊤ ∈ NI is a bag-of-
words vector with the number of clicks for each item from user u.
For simplicity, we binarize the click matrix. It is straightforward to
extend it to general count data.

2.1 Model

The generative process we consider in this paper is similar to the
deep latent Gaussian model [37]. For each user u, the model starts by
sampling a K-dimensional latent representation zu from a standard
Gaussian prior. The latent representation zu is transformed via a
non-linear function fθ (·) ∈ RI to produce a probability distribution
over I items π (zu ) from which the click history xu is assumed to
have been drawn:

zu ∼ N (0, IK ),

π (zu ) ∝ exp{ fθ (zu )},

xu ∼ Mult(Nu , π (zu )).

(1)

The non-linear function fθ (·) is a multilayer perceptron with pa-
rameters θ . The output of this transformation is normalized via a
softmax function to produce a probability vector π (zu ) ∈ SI −1 (an
(I − 1)-simplex) over the entire item set. Given the total number of
clicks Nu = (cid:205)
i xui from user u, the observed bag-of-words vector
xu is assumed to be sampled from a multinomial distribution with
probability π (zu ). This generative model generalizes the latent-
factor model — we can recover classical matrix factorization [38]
by setting fθ (·) to be linear and using a Gaussian likelihood.

The log-likelihood for user u (conditioned on the latent repre-

sentation) is:

log pθ (xu | zu ) c= (cid:213)

xui log πi (zu ).

(2)

i

This multinomial likelihood is commonly used in language models,
e.g., latent Dirichlet allocation [5], and economics, e.g., multino-
mial logit choice model [30]. It is also used in the cross-entropy
loss2 for multi-class classification. For example, it has been used in
recurrent neural networks for session-based sequential recommen-
dation [8, 15, 16, 42, 45] and in feedward neural networks applied
to Youtube recommendation [9]. The multinomial likelihood is less
well studied in the context of latent-factor models such as matrix
factorization and autoencoders. A notable exception is the collab-
orative competitive filtering (CCF) model [53] and its successors,
which take advantage of more fine-grained information about what
options were presented to which users. (If such information is
available, it can also be incorporated into our vae-based approach.)
We believe the multinomial distribution is well suited to mod-
eling click data. The likelihood of the click matrix (Eq. 2) rewards
the model for putting probability mass on the non-zero entries in
xu . But the model has a limited budget of probability mass, since
π (zu ) must sum to 1; the items must compete for this limited budget
[53]. The model should therefore assign more probability mass to
items that are more likely to be clicked. To the extent that it can, it
will perform well under the top-N ranking loss that recommender
systems are commonly evaluated on.

By way of comparison, we present two popular choices of likeli-
hood functions used in latent-factor collaborative filtering: Gauss-
ian and logistic likelihoods. Define fθ (zu ) ≡ [fu1, . . . , fuI ]⊤ as the
output of the generative function fθ (·). The Gaussian log-likelihood
for user u is

log pθ (xu | zu ) c= −

(xui − fui )2.

(3)

(cid:213)

i

cui
2

We adopt the convention in Hu et al. [19] and introduce a “confi-
dence” weight cxui ≡ cui where c1 > c0 to balance the unobserved
0’s which far outnumber the observed 1’s in most click data. This
is also equivalent to training the model with unweighted Gaussian
likelihood and negative sampling. The logistic log-likelihood3 for
user u is
log pθ (xu | zu ) = (cid:213)

xui log σ (fui ) + (1 −xui ) log(1 − σ (fui )), (4)

i

where σ (x) = 1/(1 + exp(−x)) is the logistic function. We compare
multinomial likelihood with Gaussian and logistic in Section 4.

2.2 Variational inference

To learn the generative model in Eq. 1, we are interested in esti-
mating θ (the parameters of fθ (·)). To do so, for each data point we
need to approximate the intractable posterior distribution p(zu | xu ).
We resort to variational inference [22]. Variational inference ap-
proximates the true intractable posterior with a simpler variational

1We use the verb “click” for concreteness; this can be any type of interaction, including
“watch”, “purchase”, or “listen”.

2The cross-entropy loss for multi-class classification is a multinomial likelihood under
a single draw from the distribution.
3Logistic likelihood is also cross-entropy loss for binary classification.

distribution q(zu ). We set q(zu ) to be a fully factorized (diagonal)
Gaussian distribution:

q(zu ) = N (µu , diag{σ 2
The objective of variational inference is to optimize the free varia-
tional parameters {µu , σ 2
u } so that the Kullback-Leiber divergence
KL(q(zu )∥p(zu |xu )) is minimized.

u }).

2.2.1 Amortized inference and the variational autoencoder: With
variational inference the number of parameters to optimize {µu , σ 2
u }
grows with the number of users and items in the dataset. This can be-
come a bottleneck for commercial recommender systems with mil-
lions of users and items. The variational autoencoder (vae) [24, 37]
replaces individual variational parameters with a data-dependent
function (commonly called an inference model):

дϕ (xu ) ≡ [µϕ (xu ), σϕ (xu )] ∈ R2K
parametrized by ϕ with both µϕ (xu ) and σϕ (xu ) being K-vectors
and sets the variational distribution as follows:
qϕ (zu | xu ) = N (µϕ (xu ), diag{σ 2
ϕ

(xu )}).

That is, using the observed data xu as input, the inference model
outputs the corresponding variational parameters of variational
distribution qϕ (zu | xu ), which, when optimized, approximates the
intractable posterior p(zu | xu ).4 Putting qϕ (zu | xu ) and the gen-
erative model pθ (xu | zu ) together in Figure 2c, we end up with
a neural architecture that resembles an autoencoder — hence the
name variational autoencoder.

Vaes make use of amortized inference [12]: they flexibly reuse
inferences to answer related new problems. This is well aligned
with the ethos of collaborative filtering: analyze user preferences
by exploiting the similarity patterns inferred from past experiences.
In Section 2.4, we discuss how this enables us to perform prediction
efficiently.

Learning vaes: As is standard when learning latent-variable
models with variational inference [4], we can lower-bound the log
marginal likelihood of the data. This forms the objective we seek
to maximize for user u (the objective function of the dataset is
obtained by averaging the objective function over all the users):
log p(xu ; θ ) ≥ E

qϕ (zu | xu ) [log pθ (xu | zu )] − KL(qϕ (zu | xu )∥p(zu ))

≡ L(xu ; θ, ϕ)

(5)

This is commonly known as the evidence lower bound (elbo). Note
that the elbo is a function of both θ and ϕ. We can obtain an unbi-
ased estimate of elbo by sampling zu ∼ qϕ and perform stochastic
gradient ascent to optimize it. However, the challenge is that we can-
not trivially take gradients with respect to ϕ through this sampling
process. The reparametrization trick [24, 37] sidesteps this issue: we
sample ϵ ∼ N (0, IK ) and reparametrize zu = µϕ (xu ) + ϵ ⊙ σϕ (xu ).
By doing so, the stochasticity in the sampling process is isolated
and the gradient with respect to ϕ can be back-propagated through
the sampled zu . The vae training procedure is summarized in Al-
gorithm 1.

4In the implementation, the inference model will output the log of the variance of the
variational distribution. We continue to use σϕ (xu ) for notational brevity.

Algorithm 1: VAE-SGD Training collaborative filtering vae
with stochastic gradient descent.

Input: Click matrix X ∈ RU ×I
Randomly initialize θ , ϕ
while not converged do

Sample a batch of users U
forall u ∈ U do

Sample ϵ ∼ N (0, IK ) and compute zu via
reparametrization trick
Compute noisy gradient ∇θ L and ∇ϕ L with zu

Average noisy gradients from batch
Update θ and ϕ by taking stochastic gradient steps

end

end
return θ , ϕ

2.2.2 Alternative interpretation of elbo. We can view elbo de-
fined in Eq. 5 from a different perspective: the first term can be
interpreted as (negative) reconstruction error, while the second
KL term can be viewed as regularization. It is this perspective we
work with because it allows us to make a trade-off that forms the
crux of our method. From this perspective, it is natural to extend
the elbo by introducing a parameter β to control the strength of
regularization:

Lβ (xu ; θ, ϕ) ≡ E

qϕ (zu | xu )[ log pθ (xu | zu )]

−β · KL(qϕ (zu | xu )∥p(zu )).

(6)

While the original vae (trained with elbo in Eq. 5) is a powerful
generative model; we might ask whether we need all the statistical
properties of a generative model for tackling problems in recom-
mender systems. In particular, if we are willing to sacrifice the
ability to perform ancestral sampling, can we improve our perfor-
mance? The regularization view of the elbo (Eq. 6) introduces a
trade-off between how well we can fit the data and how close the
approximate posterior stays to the prior during learning.

(cid:205)

We propose using β (cid:44) 1. This means we are no longer opti-
mizing a lower bound on the log marginal likelihood. If β < 1,
then we are also weakening the influence of the prior constraint
1
u q(z | xu ) ≈ p(z) = N (z; 0, IK ) [18]; this means that the model
U
is less able to generate novel user histories by ancestral sampling.
But ultimately our goal is to make good recommendations, not to
maximize likelihood or generate imagined user histories. Treating
β as a free regularization parameter therefore costs us nothing, and,
as we will see, yields significant improvements in performance.

Selecting β: We propose a simple heuristic for setting β: we
start training with β = 0, and gradually increase β to 1. We linearly
anneal the KL term slowly over a large number of gradient updates
to θ, ϕ and record the best β when its performance reaches the peak.
We found this method to work well and it does not require the need
for training multiple models with different values of β, which can
be time-consuming. Our procedure is inspired by KL annealing [7],
a common heuristic used for training vaes when there is concern
that the model is being underutilized.

Figure 1 illustrates the basic idea (we observe the same trend
consistently across datasets). Here we plot the validation ranking
metric without KL annealing (blue solid) and with KL annealing all
the way to β = 1 (green dashed, β reaches 1 at around 80 epochs).
As we can see, the performance is poor without any KL annealing.
With annealing, the validation performance first increases as the
training proceeds and then drops as β gets close to 1 to a value that
is only slightly better than doing no annealing at all.

Having identified the best β based on the peak validation metric,
we can retrain the model with the same annealing schedule, but stop
increasing β after reaching that value (shown as red dot-dashed in
Figure 1).5 This might be sub-optimal compared to a thorough grid
search. However, it is much more efficient, and gives us competi-
tive empirical performance. If the computational budget is scarce,
then within a single run, we can stop increasing β when we notice
the validation metric dropping. Such a procedure incurs no addi-
tional runtime to learning a standard vae. We denote this partially
regularized vae with multinomial likelihood as Mult-vaepr.

Figure 1: Validation ranking metrics with different anneal-
ing configurations. For the green dashed curve, β reaches 1
at around 80 epochs.

2.2.3 Computational Burden. Previous collaborative filtering
models with neural networks [14, 51] are trained with stochastic
gradient descent where in each step a single (user, item) entry
from the click matrix is randomly sampled to perform a gradient
update. In Algorithm 1 we subsample users and take their entire
click history (complete rows of the click matrix) to update model
parameters. This eliminates the necessity of negative sampling (and
consequently the hyperparameter tuning for picking the number
of negative examples), commonly used in the (user, item) entry
subsampling scheme.

A computational challenge that comes with our approach, how-
ever, is that when the number of items is huge, computing the
multinomial probability π (zu ) could be computationally expensive,
since it requires computing the predictions for all the items for
normalization. This is a common challenge for language model-
ing where the size of the vocabulary is in the order of millions or
more [32]. In our experiments on some medium-to-large datasets
with less than 50K items (Section 4.1), this has not yet come up
as a computational bottleneck. If this becomes a bottleneck when
working with larger item sets, one can easily apply the simple and

effective method proposed by Botev et al. [6] to approximate the
normalization factor for π (zu ).

2.3 A taxonomy of autoencoders

In Section 2.2, we introduced maximum marginal likelihood es-
timation of vaes using approximate Bayesian inference under a
non-linear generative model (Eq. 1). We now describe our work from
the perspective of learning autoencoders. Maximum-likelihood es-
timation in a regular autoencoder takes the following form:

θ AE, ϕAE = arg max

E
δ (zu −дϕ (xu )) [log pθ (xu | zu )]

log pθ (xu | дϕ (xu ))

(7)

(cid:213)

u
(cid:213)

u

θ,ϕ
= arg max
θ,ϕ

There are two key distinctions of note: (1) The autoencoder (and
denoising autoencoder) effectively optimizes the first term in the
vae objective (Eq. 5 and Eq. 6) using a delta variational distribution
qϕ (zu | xu ) = δ (zu − дϕ (xu )) — it does not regularize qϕ (zu | xu )
towards any prior distribution as the vae does. (2) the δ (zu −дϕ (xu ))
is a δ distribution with mass only at the output of дϕ (xu ). Contrast
this to the vae, where the learning is done using a variational
distribution, i.e., дϕ (xu ) outputs the parameters (mean and variance)
of a Gaussian distribution. This means that vae has the ability to
capture per-data-point variances in the latent state zu .

In practice, we find that learning autoencoders is extremely
prone to overfitting as the network learns to put all the probability
mass to the non-zero entries in xu . By introducing dropout [43]
at the input layer, the denoising autoencoder (dae) is less prone
to overfitting and we find that it also gives competitive empirical
results. In addition to the Mult-vaepr, we also study a denoising
autoencoder with a multinomial likelihood. We denote this model
Mult-dae. In Section 4 we characterize the tradeoffs in what is
gained and lost by explicitly parameterizing the per-user variance
with Mult-vaepr versus using a point-estimation in Mult-dae.

To provide a unified view of different variants of autoencoders
and clarify where our work stands, we depict variants of autoen-
coders commonly found in the literature in Figure 2. For each one,
we specify the model (dotted arrows denote a sampling operation)
and describe the training objective used in parameter estimation.
In Figure 2a we have autoencoder. It is trained to reconstruct
input with the same objective as in Eq. 7. Adding noise to the in-
put (or the intermediate hidden representation) of an autoencoder
yields the denoising autoencoder in Figure 2b. The training objec-
tive is the same as that of an autoencoder. Mult-dae belongs to this
model class. Collaborative denoising autoencoder [51] is a variant
of this model class. The vae is depicted in Figure 2c. Rather than
using a delta variational distribution, it uses an inference model
parametrized by ϕ to produce the mean and variance of the approx-
imating variational distribution. The training objective of the vae is
given in Eq. 6. Setting β to 1 recovers the original vae formulation
[24, 37]. Higgins et al. [17] study the case where β > 1. Our model,
Mult-vaepr corresponds to learning vaes with β ∈ [0, 1].

2.4 Prediction

5We found this to give slightly better results than keeping β at the best value through-
out the training.

We now describe how we make predictions given a trained gen-
erative model of the form Eq. 1. For both, Mult-vaepr (Section 2.2)

(a) Autoencoder

(b) Denoising
Autoencoder

(c) Variational
Autoencoder

x

ϕ

z

θ

x

x

ϕ

z

θ

x

ϵ

ϕ

ϕ

µ

σ

ϵ

x

z

θ

x

Figure 2: A taxonomy of autoencoders. The dotted arrows denote a sampling operation.

or Mult-dae (Section 2.3), we make predictions in the same way.
Given a user’s click history x, we rank all the items based on the
un-normalized predicted multinomial probability fθ (z). The latent
representation z for x is constructed as follows: For Mult-vaepr, we
simply take the mean of the variational distribution z = µϕ (x); for
Mult-dae, we take the output z = дϕ (x).

It is easy to see the advantage of using autoencoders. We can
effectively make predictions for users by evaluating two functions
– the inference model (encoder) дϕ (·) and the generative model
(decoder) fθ (·). For most of the latent factor collaborative filtering
model, e.g., matrix factorization [13, 19], when given the click his-
tory of a user that is not present in the training data, normally we
need to perform some form of optimization to obtain the latent
factor for this user. This makes the use of autoencoders particu-
larly attractive in industrial applications, where it is important that
predictions be made cheaply and with low latency.

3 RELATED WORK
Vaes on sparse data. Variational autoencoders (vaes) [24, 37]
have seen much application to images since their inception. Doer-
sch [10] presents a review on different applications of vae to image
data. Miao et al. [31] study vaes on text data. More recent results
from Krishnan et al. [25] find that vaes (trained with Eq. 5) suffer
from underfitting when modeling large, sparse, high-dimensional
data. We notice similar issues when fitting vae without annealing
(Figure 1) or annealing to β = 1. By giving up the ability to perform
ancestral sampling in the model, and setting β ≤ 1, the resulting
model is no longer a proper generative model though for collabora-
tive filtering tasks we always make predictions conditional on users’
click history.

Information-theoretic connection with vae. The regular-
ization view of the elbo in Eq. 6 resembles maximum-entropy
discrimination [20]. Maximum-entropy discrimination attempts to
combine discriminative estimation with Bayesian inference and
generative modeling. In our case, in Eq. 6, β acts as a knob to balance
discriminative and generative aspects of the model.

The procedure in Eq. 6 has information-theoretic connections
described in Alemi et al. [1]. The authors propose the deep varia-
tional information bottleneck, which is a variational approximation
to the information bottleneck principle [46]. They show that as a
special case they can recover the learning objective used by vaes.
They report more robust supervised classification performance with
β < 1. This is consistent with our findings as well. Higgins et al.
[17] proposed β-vae, which leads to the same objective as Eq. 6.

They motivate β-vae for the goal of learning disentangled repre-
sentations from images (basic visual concepts, such as shape, scale,
and color). Their work, however, sets β ≫ 1, effectively imposing a
stronger independent prior assumption on the latent code z. While
their motivations are quite different from ours, it is interesting to
note orthogonal lines of research emerging from exploring the full
spectrum of values for β.

Neural networks for collaborative filtering. Early work on
neural-network-based collaborative filtering models focus on ex-
plicit feedback data and evaluates on the task of rating predictions
[11, 39, 41, 54]. The importance of implicit feedback has been grad-
ually recognized, and consequently most recent research, such as
this work, has focused on it. The two papers that are most closely
related to our approaches are collaborative denoising autoencoder
[51] and neural collaborative filtering [14].

Collaborative denoising autoencoder (cdae) [51] augments the
standard denoising autoencoder, described in Section 2.3, by adding
a per-user latent factor to the input. The number of parameters of
the cdae model grows linearly with both the number of users as
well as the number of items, making it more prone to overfitting. In
contrast, the number of parameters in the vae grows linearly with
the number of items. The cdae also requires additional optimiza-
tion to obtain the latent factor for unseen users to make predicion.
In the paper, the authors investigate the Gaussian and logistic like-
lihood loss functions — as we show, the multinomial likelihood is
significantly more robust for use in recommender systems. Neural
collaborative filtering (ncf) [14] explore a model with non-linear
interactions between the user and item latent factors rather than
the commonly used dot product. The authors demonstrate improve-
ments of ncf over standard baselines on two small datasets. Similar
to cdae, the number of parameters of ncf also grows linearly with
both the number of users as well as items. We find that this becomes
problematic for much larger datasets. We compare with both cdae
and ncf in Section 4.

Asymmetric matrix factorization [35] may also be interpreted
as an autoencoder, as elaborated in Steck [44]. We can recover this
work by setting both fθ (·) and дϕ (·) to be linear.

Besides being applied in session-based sequential recommen-
dation (see Section 2.1), various approaches [2, 28, 47, 48] have
applied neural networks to incorporate side information into col-
laborative filtering models to better handle the cold-start problem.
These approaches are complementary to ours.

Table 1: Attributes of datasets after preprocessing. Interac-
tions are non-zero entries. % of interactions refers to the den-
sity of the user-item click matrix X. # of the held-out users is
the number of validation/test users out of the total number
of users in the first row.

ML-20M Netflix MSD

# of users
# of items
# of interactions
% of interactions

136,677
20,108
10.0M
0.36%

463,435
17,769
56.9M
0.69%

571,355
41,140
33.6M
0.14%

# of held-out users

10,000

40,000

50,000

4 EMPIRICAL STUDY
We evaluate the performance of Mult-vaepr and Mult-dae. We pro-
vide insights into their performance by exploring the resulting fits.
We highlight the following results:

• Mult-vaepr achieves state-of-the-art results on three real-
world datasets when compared with various baselines, in-
cluding recently proposed neural-network-based collabora-
tive filtering models.

• For the denoising and variational autoencoder, the multino-
mial likelihood compares favorably over the more common
Gaussian and logistic likelihoods.

• Both Mult-vaepr and Mult-dae produce competitive empirical
results. We identify when parameterizing the uncertainty
explicitly as in Mult-vaepr does better/worse than the point
estimate used by Mult-dae and list pros and cons for both
approaches.

The source code to reproduce the experimental results is avail-

able on GitHub6.

4.1 Datasets

We study three medium- to large-scale user-item consumption
datasets from various domains:

MovieLens-20M (ML-20M): These are user-movie ratings col-
lected from a movie recommendation service. We binarize the ex-
plicit data by keeping ratings of four or higher and interpret them
as implicit feedback. We only keep users who have watched at least
five movies.

Netflix Prize (Netflix): This is the user-movie ratings data from
the Netflix Prize7. Similar to ML-20M, we binarize explicit data by
keeping ratings of four or higher. We only keep users who have
watched at least five movies.

Million Song Dataset (MSD): This data contains the user-song
play counts released as part of the Million Song Dataset [3]. We
binarize play counts and interpret them as implicit preference data.
We only keep users with at least 20 songs in their listening history
and songs that are listened to by at least 200 users.

Table 1 summarizes the dimensions of all the datasets after pre-

processing.

6https://github.com/dawenl/vae_cf
7http://www.netflixprize.com/

4.2 Metrics

We use two ranking-based metrics: Recall@R and the truncated
normalized discounted cumulative gain (NDCG@R). For each user,
both metrics compare the predicted rank of the held-out items with
their true rank. For both Mult-vaepr and Mult-dae, we get the pre-
dicted rank by sorting the un-normalized multinomial probability
fθ (z). While Recall@R considers all items ranked within the first R
to be equally important, NDCG@R uses a monotonically increasing
discount to emphasize the importance of higher ranks versus lower
ones. Formally, define ω(r ) as the item at rank r , I[·] is the indicator
function, and Iu is the set of held-out items that user u clicked on.

Recall@R for user u is

Recall@R(u, ω) :=

(cid:205)R

I[ω(r ) ∈ Iu ]

r =1
min(M, |Iu |)

.

The expression in the denominator is the minimum of R and the
number of items clicked on by user u. This normalizes Recall@R to
have a maximum of 1, which corresponds to ranking all relevant
items in the top R positions.

Truncated discounted cumulative gain (DCG@R) is

DCG@R(u, ω) :=

R
(cid:213)

2

r =1

I[ω(r )∈Iu ] − 1
log(r + 1)

.

NDCG@R is the DCG@R linearly normalized to [0, 1] after
dividing by the best possible DCG@R, where all the held-out items
are ranked at the top.

4.3 Experimental setup

We study the performance of various models under strong general-
ization [29]: We split all users into training/validation/test sets. We
train models using the entire click history of the training users. To
evaluate, we take part of the click history from held-out (validation
and test) users to learn the necessary user-level representations for
the model and then compute metrics by looking at how well the
model ranks the rest of the unseen click history from the held-out
users.

This is relatively more difficult than weak generalization where
the user’s click history can appear during both training and evalua-
tion. We consider it more realistic and robust as well. In the last row
of Table 1, we list the number of held-out users (we use the same
number of users for validation and test). For each held-out user,
we randomly choose 80% of the click history as the “fold-in” set to
learn the necessary user-level representation and report metrics on
the remaining 20% of the click history.

We select model hyperparameters and architectures by evaluat-
ing NDCG@100 on the validation users. For both Mult-vaepr and
Mult-dae, we keep the architecture for the generative model fθ (·)
and the inference model дϕ (·) symmetrical and explore multilayer
perceptron (mlp) with 0, 1, and 2 hidden layers. We set the dimen-
sion of the latent representation K to 200 and any hidden layer to
600. As a concrete example, recall I is the total number of items, the
overall architecture for a Mult-vaepr/Mult-dae with 1-hidden-layer
mlp generative model would be [I → 600 → 200 → 600 → I ]. We
find that going deeper does not improve performance. The best per-
forming architectures are mlps with either 0 or 1 hidden layers. We
use a tanh non-linearity as the activation function between layers.

Note that for Mult-vaepr, since the output of дϕ (·) is used as the
mean and variance of a Gaussian random variable, we do not apply
an activation function to it. Thus, the Mult-vaepr with 0-hidden-
layer mlp is effectively a log-linear model. We tune the regulariza-
tion parameter β for Mult-vaepr following the procedure described
in Section 2.2.2. We anneal the Kullback-Leibler term linearly for
200,000 gradient updates. For both Mult-vaepr and Mult-dae, we
apply dropout at the input layer with probability 0.5. We apply a
weight decay of 0.01 for Mult-dae. We do not apply weight decay
for any vae models. We train both Mult-vaepr and Mult-dae using
Adam [23] with batch size of 500 users. For ML-20M, we train for
200 epochs. We train for 100 epochs on the other two datasets. We
keep the model with the best validation NDCG@100 and report
test set metrics with it.

4.4 Baselines

We compare results with the following standard state-of-the-art
collaborative filtering models, both linear and non-linear:

Weighted matrix factorization (wmf) [19]: a linear low-rank
factorization model. We train wmf with alternating least squares;
this generally leads to better performance than with SGD. We set the
weights on all the 0’s to 1 and tune the weights on all the 1’s in the
click matrix among {2, 5, 10, 30, 50, 100}, as well as the latent repre-
sentation dimension K ∈ {100, 200} by evaluating NDCG@100 on
validation users.

Slim [33]: a linear model which learns a sparse item-to-item
similarity matrix by solving a constrained ℓ1-regularized optimiza-
tion problem. We grid-search both of the regularization parameters
over {0.1, 0.5, 1, 5} and report the setting with the best NDCG@100
on validation users. We did not evaluate Slim on MSD because the
dataset is too large for it to finish in a reasonable amount of time
(for the Netflix dataset, the parallelized grid search took about two
weeks). We also found that the faster approximation of Slim [26]
did not yield competitive performance.

Collaborative denoising autoencoder (cdae) [51]: augments
the standard denoising autoencoder by adding a per-user latent
factor to the input. We change the (user, item) entry subsampling
strategy in SGD training in the original paper to the user-level
subsampling as we did with Mult-vaepr and Mult-dae. We generally
find that this leads to more stable convergence and better perfor-
mance. We set the dimension of the bottleneck layer to 200, and
use a weighted square loss, equivalent to what the square loss with
negative sampling used in the original paper. We apply tanh activa-
tion at both the bottleneck layer as well as the output layer.8 We
use Adam with a batch size of 500 users. As mentioned in Section 3,
the number of parameters for cdae grows linearly with the num-
ber of users and items. Thus, it is crucial to control overfitting by
applying weight decay. We select the weight decay parameter over
{0.01, 0.1, · · · , 100} by examining the validation NDCG@100.

Neural collaborative filtering (ncf) [14]: explores non-linear
interactions (via a neural network) between the user and item latent
factors. Similar to cdae, the number of parameters for ncf grows
linearly with the number of users and items. We use the publicly
available source code provided by the authors, yet cannot obtain

8Wu et al. [51] used sigmoid activation function but mentioned tanh gave similar
results. We use tanh to be consistent with our models.

competitive performance on the datasets used in this paper — the
validation metrics drop within the first few epochs over a wide
range of regularization parameters. The authors kindly provided
the two datasets (ML-1M and Pinterest) used in the original paper,
as well as the training/test split, therefore we separately compare
with ncf on these two relatively smaller datasets in the empirical
study. In particular, we compare with the hybrid NeuCF model
which gives the best performance in He et al. [14], both with and
without pre-training.

We also experiment with Bayesian personalized ranking (bpr)
[36]. However, the performance is not on par with the other base-
lines above. This is consistent with some other studies with similar
baselines [40]. Therefore, we do not include bpr in the following
results and analysis.

4.5 Experimental results and analysis

In this section, we quantitatively compare our proposed methods
with various baselines. In addition, we aim to answer the following
two questions:

1. How does multinomial likelihood compare with other com-
monly used likelihood models for collaborative filtering?
2. When does Mult-vaepr perform better/worse than Mult-dae?
Quantitative results. Table 2 summarizes the results between
our proposed methods and various baselines. Each metric is av-
eraged across all test users. Both Mult-vaepr and Mult-dae signifi-
cantly outperform the baselines across datasets and metrics. Mult-
vaepr significantly outperforms Mult-dae on ML-20M and Netflix
data-sets. In most of the cases, non-linear models (Mult-vaepr, Mult-
dae, and cdae) prove to be more powerful collaborative filtering
models than state-of-the-art linear models. The inferior results of
cdae on MSD are possibly due to overfitting with the huge number
of users and items, as validation metrics drop within the first few
epochs even though the training objective continues improving.

We compare with ncf on the two relatively smaller datasets used
in Hu et al. [19]: ML-1M (6,040 users, 3,704 items, 4.47% density) and
Pinterest (55,187 users, 9,916 items, 0.27% density). Because of the
size of these two datasets, we use Mult-dae with a 0-hidden-layer
mlp generative model — the overall architecture is [I → 200 → I ].
(Recall Mult-vaepr with a 0-hidden-layer mlp generative model
is effectively a log-linear model with limited modeling capacity.)
Table 3 summarizes the results between Mult-dae and ncf. Mult-
dae significantly outperforms ncf without pre-training on both
datasets. On the larger Pinterest dataset, Mult-dae even improves
over the pre-trained ncf model by a big margin.

How well does multinomial likelihood perform? Despite
being commonly used in language models, multinomial likelihoods
have typically received less attention in the collaborative filtering
literature, especially with latent-factor models. Most previous work
builds on Gaussian likelihoods (square loss, Eq. 3) [19, 33, 51] or
logistic likelihood (log loss, Eq. 4) [14, 51] instead. We argue in
Section 2.1 that multinomial likelihood is in fact a good proxy for
the top-N ranking loss and is well-suited for implicit feedback data.
To demonstrate the effectiveness of multinomial likelihood, we
take the best-performing Mult-vaepr and Mult-dae model on each
dataset and swap the likelihood distribution model for the data
while keeping everything else exactly the same.

Table 2: Comparison between various baselines and our pro-
posed methods. Standard errors are around 0.002 for ML-
20M and 0.001 for Netflix and MSD. Both Mult-vaepr and
Mult-dae significantly outperform the baselines across
datasets and metrics. We could not finish Slim within a rea-
sonable amount of time on MSD.

Table 4: Comparison of Mult-vaepr and Mult-dae with differ-
ent likelihood functions at the output layer on ML-20M. The
standard error is around 0.002 (the results on the other two
datasets are similar.) The multinomial likelihood performs
better than the other two commonly-used likelihoods from
the collaborative filtering literature.

(a) ML-20M

Mult-vaepr
Mult-dae

Recall@20 Recall@50 NDCG@100
0.537
0.524

0.395
0.387

0.426
0.419

wmf
Slim
cdae

0.360
0.370
0.391

0.498
0.495
0.523

0.386
0.401
0.418

(b) Netflix

Mult-vaepr
Mult-dae

Recall@20 Recall@50 NDCG@100
0.444
0.438

0.351
0.344

0.386
0.380

wmf
Slim
cdae

0.316
0.347
0.343

0.404
0.428
0.428

0.351
0.379
0.376

(c) MSD

Mult-vaepr
Mult-dae

Recall@20 Recall@50 NDCG@100
0.364
0.363

0.266
0.266

0.316
0.313

wmf
Slim
cdae

0.211
—
0.188

0.312
—
0.283

0.257
—
0.237

Table 3: Comparison between ncf and Mult-dae with [I →
200 → I ] architecture. We take the results of ncf from He
et al. [14]. Mult-dae model significantly outperforms ncf
without pre-training on both datasets and further improves
on Pinterest even comparing with pre-trained ncf.

ncf

ncf (pre-train) Mult-dae

Recall@10
NDCG@10

0.705
0.426

0.730
0.447

0.722
0.446

(a) ML-1M

(b) Pinterest

ncf

ncf (pre-train) Mult-dae

Recall@10
NDCG@10

0.872
0.551

0.880
0.558

0.886
0.580

Mult-vaepr
Gaussian-vaepr
Logistic-vaepr

Mult-dae
Gaussian-dae
Logistic-dae

Recall@20 Recall@50 NDCG@100
0.537
0.523
0.523
0.524
0.515
0.516

0.395
0.383
0.388
0.387
0.376
0.381

0.426
0.415
0.419
0.419
0.409
0.414

Table 4 summarizes the results of different likelihoods on ML-
20M (the results on the other two datasets are similar.) We tune
the hyperparameters for each likelihood separately.9 The multino-
mial likelihood performs better than the other likelihoods. The gap
between logistic and multinomial likelihood is closer — this is un-
derstandable since multinomial likelihood can be approximated by
individual binary logistic likelihood, a strategy commonly adopted
in language modeling [32, 52].

We wish to emphasize that the choice of likelihood remains data-
dependent. For the task of collaborative filtering, the multinomial
likelihood achieves excellent empirical results. The methodology
behind the partial regularization in Mult-vaepr, however, is a tech-
nique we hypothesize will generalize to other domains.

When does Mult-vaepr perform better/worse than Mult-
dae? In Table 2 we can see that both Mult-vaepr and Mult-dae pro-
duce competitive empirical results with Mult-vaepr being compa-
rably better. It is natural to wonder when a variational Bayesian
inference approach (Mult-vaepr) will win over using a point esti-
mate (Mult-dae) and vice versa.

Intuitively, Mult-vaepr imposes stronger modeling assumptions
and therefore could be more robust when user-item interaction
data is scarce. To study this, we considered two datasets: ML-20M
where Mult-vaepr has the largest margin over Mult-dae and MSD
where Mult-vaepr and Mult-dae have roughly similar performance.
The results on the Netflix dataset are similar to ML-20M. We break
down test users into quintiles based on their activity level in the
fold-in set which is provided as input to the inference model дϕ (·)
to make prediction. The activity level is simply the number of items
each user has clicked on. We compute NDCG@100 for each group
of users using both Mult-vaepr and Mult-dae and plot results in
Figure 3. This summarizes how performance differs across users
with various levels of activity.

In Figure 3, we show performance across increasing user ac-
tivity. Error bars represents one standard error. For each subplot,
a paired t-test is performed and statistical significance is marked.
Although there are slight variations across datasets, Mult-vaepr con-
sistently improves recommendation performance for users who
have only clicked on a small number of items. This is particularly
prominent for ML-20M (Figure 3a). Interestingly, Mult-dae actually

9Surprisingly, partial regularization seems less effective for Gaussian and logistic.

(a) ML-20M

(b) MSD

Figure 3: NDCG@100 breakdown for users with increasing levels of activity (starting from 0%), measured by how many items
a user clicked on in the fold-in set. The error bars represents one standard error. For each subplot, a paired t-test is performed
and * indicates statistical significance at α = 0.05 level, ** at α = 0.01 level, and *** at α = 0.001 level. Although details vary
across datasets, Mult-vaepr consistently improves recommendation performance for users who have only clicked on a small
number of items.

outperforms Mult-vaepr on the most active users. This indicates
the stronger prior assumption could potentially hurt the perfor-
mance when a lot of data is available for a user. For MSD (Figure 3b),
the least-active users have similar performance under both Mult-
vaepr and Mult-dae. However, as we described in Section 4.1, MSD
is pre-processed so that a user has at least listened to 20 songs.
Meanwhile for ML-20M, each user has to watch at least 5 movies.
This means that the first bin of ML-20M has much lower user activ-
ity than the first bin of MSD.

Overall, we find that Mult-vaepr, which may be viewed under
the lens of a principled Bayesian inference approach, is more ro-
bust than the point estimate approach of Mult-dae, regardless of
the scarcity of the data. More importantly, the Mult-vaepr is less
sensitive to the choice of hyperparameters – weight decay is im-
portant for Mult-dae to achieve competitive performance, yet it is
not required for Mult-vaepr. On the other hand, Mult-dae also has
advantages: it requires fewer parameters in the bottleneck layer
— Mult-vaepr requires two sets of parameters to obtain the latent
representation z: one set for the variational mean µϕ (·) and another
for the variational variance σϕ (·) — and Mult-dae is conceptually
simpler for practitioners.

5 CONCLUSION

In this paper, we develop a variant of vae for collaborative filtering
on implicit feedback data. This enables us to go beyond linear factor
models with limited modeling capacity.

We introduce a generative model with a multinomial likelihood
function parameterized by neural network. We show that multino-
mial likelihood is particularly well suited to modeling user-item
implicit feedback data.

Based on an alternative interpretation of the vae objective, we in-
troduce an additional regularization parameter to partially regular-
ize a vae (Mult-vaepr). We also provide a practical and efficient way
to tune the additional parameter introduced using KL annealing.
We compare the results obtained against a denoising autoencoder
(Mult-dae).

Empirically, we show that the both Mult-vaepr and Mult-dae pro-
vide competitive performance with Mult-vaepr significantly outper-
forming the state-of-the-art baselines on several real-world datasets,
including two recently proposed neural-network-based approaches.
Finally, we identify the pros and cons of both Mult-vaepr and Mult-
dae and show that employing a principled Bayesian approach is
more robust.

In future work, we would like to futher investigate the trade-
off introduced by the additional regularization parameter β and
gain more theoretical insight into why it works so well. Extending
Mult-vaepr by condition on side information might also be a way to
improve performance.

REFERENCES
[1] Alexander Alemi, Ian Fischer, Joshua Dillon, and Kevin Murphy. 2017. Deep
Variational Information Bottleneck. In 5th International Conference on Learning
Representations.

[2] Amjad Almahairi, Kyle Kastner, Kyunghyun Cho, and Aaron Courville. 2015.
Learning distributed representations from reviews for collaborative filtering. In
Proceedings of the 9th ACM Conference on Recommender Systems. ACM, 147–154.
[3] Thierry Bertin-Mahieux, Daniel P.W. Ellis, Brian Whitman, and Paul Lamere.

2011. The Million Song Dataset.. In ISMIR, Vol. 2. 10.

[4] David M. Blei, Alp Kucukelbir, and Jon D. McAuliffe. 2017. Variational Inference:
A Review for Statisticians. J. Amer. Statist. Assoc. 112, 518 (2017), 859–877.
[5] David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent dirichlet

allocation. Journal of Machine Learning Research 3, Jan (2003), 993–1022.

[6] Aleksandar Botev, Bowen Zheng, and David Barber. 2017. Complementary
Sum Sampling for Likelihood Approximation in Large Scale Classification. In
Proceedings of the 20th International Conference on Artificial Intelligence and

Statistics. 1030–1038.

[7] Samuel R. Bowman, Luke Vilnis, Oriol Vinyals, Andrew M. Dai, Rafal Jozefowicz,
and Samy Bengio. 2015. Generating sentences from a continuous space. arXiv
preprint arXiv:1511.06349 (2015).

[8] Sotirios Chatzis, Panayiotis Christodoulou, and Andreas S. Andreou. 2017. Recur-
rent Latent Variable Networks for Session-Based Recommendation. In Proceedings
of the 2nd Workshop on Deep Learning for Recommender Systems.

[9] Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep neural networks
for youtube recommendations. In Proceedings of the 10th ACM Conference on
Recommender Systems. ACM, 191–198.

[10] Carl Doersch. 2016. Tutorial on variational autoencoders. arXiv preprint

arXiv:1606.05908 (2016).

[11] Kostadin Georgiev and Preslav Nakov. 2013. A non-IID Framework for Collabo-
rative Filtering with Restricted Boltzmann Machines. In Proceedings of the 30th
International Conference on Machine Learning. 1148–1156.

[12] Samuel Gershman and Noah Goodman. 2014. Amortized inference in probabilistic

reasoning. In Proceedings of the Cognitive Science Society, Vol. 36.

[13] Prem Gopalan, Jake M. Hofman, and David M. Blei. 2015. Scalable Recom-
mendation with Hierarchical Poisson Factorization. In Uncertainty in Artificial
Intelligence.

[14] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng
Chua. 2017. Neural collaborative filtering. In Proceedings of the 26th International
Conference on World Wide Web. 173–182.

[15] Balázs Hidasi and Alexandros Karatzoglou. 2017. Recurrent Neural Networks with
Top-k Gains for Session-based Recommendations. arXiv preprint arXiv:1706.03847
(2017).

[16] Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk.
2015. Session-based recommendations with recurrent neural networks. arXiv
preprint arXiv:1511.06939 (2015).

[17] Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot,
Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. 2017. β -VAE:
Learning Basic Visual Concepts with a Constrained Variational Framework. In
5th International Conference on Learning Representations.

[18] Matthew D. Hoffman and Matthew J. Johnson. 2016. ELBO surgery: yet another
way to carve up the variational evidence lower bound. In Workshop in Advances
in Approximate Bayesian Inference, NIPS.

[19] Yifan Hu, Yehuda Koren, and Chris Volinsky. 2008. Collaborative filtering for im-
plicit feedback datasets. In Data Mining, 2008. ICDM’08. Eighth IEEE International
Conference on. 263–272.

[20] Tommi Jaakkola, Marina Meila, and Tony Jebara. 2000. Maximum entropy dis-
crimination. In Advances in Neural Information Processing Systems. 470–476.
[21] Kalervo Järvelin and Jaana Kekäläinen. 2002. Cumulated gain-based evaluation
of IR techniques. ACM Transactions on Information Systems (TOIS) 20, 4 (2002),
422–446.

[22] Michael I. Jordan, Zoubin Ghahramani, Tommi S. Jaakkola, and Lawrence K. Saul.
1999. An introduction to variational methods for graphical models. Machine
learning 37, 2 (1999), 183–233.

[23] Diederik Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimiza-

tion. arXiv preprint arXiv:1412.6980 (2014).

[24] Diederik P. Kingma and Max Welling. 2013. Auto-encoding variational bayes.

arXiv preprint arXiv:1312.6114 (2013).

[25] Rahul G. Krishnan, Dawen Liang, and Matthew D. Hoffman. 2017. On the
challenges of learning with inference networks on sparse, high-dimensional data.
arXiv preprint arXiv:1710.06085 (2017).

[26] Mark Levy and Kris Jack. 2013. Efficient top-n recommendation by linear regres-

sion. In RecSys Large Scale Recommender Systems Workshop.

[27] Dawen Liang, Jaan Altosaar, Laurent Charlin, and David M. Blei. 2016. Factor-
ization meets the item embedding: Regularizing matrix factorization with item
co-occurrence. In Proceedings of the 10th ACM conference on recommender systems.
59–66.

[28] Dawen Liang, Minshu Zhan, and Daniel P.W. Ellis. 2015. Content-Aware Collab-
orative Music Recommendation Using Pre-trained Neural Networks.. In ISMIR.
295–301.

[29] Benjamin Marlin. 2004. Collaborative filtering: A machine learning perspective.

[30] Daniel McFadden et al. 1973. Conditional logit analysis of qualitative choice

University of Toronto.

behavior. (1973), 105–142 pages.

[31] Yishu Miao, Lei Yu, and Phil Blunsom. 2016. Neural variational inference for text
processing. In International Conference on Machine Learning. 1727–1736.

[32] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S. Corrado, and Jeff Dean. 2013.
Distributed representations of words and phrases and their compositionality. In
Advances in neural information processing systems. 3111–3119.

[33] Xia Ning and George Karypis. 2011. Slim: Sparse linear methods for top-n
recommender systems. In Data Mining (ICDM), 2011 IEEE 11th International
Conference on. 497–506.

[34] Rong Pan, Yunhong Zhou, Bin Cao, Nathan N. Liu, Rajan Lukose, Martin Scholz,
and Qiang Yang. 2008. One-class collaborative filtering. In Data Mining, 2008.
ICDM’08. Eighth IEEE International Conference on. 502–511.

[35] Arkadiusz Paterek. 2007. Improving regularized singular value decomposition
for collaborative filtering. In Proceedings of KDD cup and workshop, Vol. 2007.
5–8.

[36] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme.
2009. BPR: Bayesian personalized ranking from implicit feedback. In Proceedings
of the twenty-fifth conference on uncertainty in artificial intelligence. 452–461.

[37] Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. 2014. Stochastic
Backpropagation and Approximate Inference in Deep Generative Models. In
Proceedings of the 31st International Conference on Machine Learning. 1278–1286.
[38] Ruslan Salakhutdinov and Andriy Mnih. 2008. Probabilistic matrix factorization.

Advances in neural information processing systems (2008), 1257–1264.

[39] Ruslan Salakhutdinov, Andriy Mnih, and Geoffrey Hinton. 2007. Restricted Boltz-
mann machines for collaborative filtering. In Proceedings of the 24th International
Conference on Machine Learning. 791–798.

[40] Suvash Sedhain, Aditya Krishna Menon, Scott Sanner, and Darius Braziunas. 2016.
On the Effectiveness of Linear Models for One-Class Collaborative Filtering.. In
AAAI.

[41] Suvash Sedhain, Aditya Krishna Menon, Scott Sanner, and Lexing Xie. 2015.
Autorec: Autoencoders meet collaborative filtering. In Proceedings of the 24th
International Conference on World Wide Web. 111–112.

[42] Elena Smirnova and Flavian Vasile. 2017. Contextual Sequence Modeling for
Recommendation with Recurrent Neural Networks. In Proceedings of the 2nd
Workshop on Deep Learning for Recommender Systems.

[43] Nitish Srivastava, Geoffrey E. Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan
Salakhutdinov. 2014. Dropout: a simple way to prevent neural networks from
overfitting. Journal of machine learning research 15, 1 (2014), 1929–1958.
[44] Harald Steck. 2015. Gaussian ranking by matrix factorization. In Proceedings of

the 9th ACM Conference on Recommender Systems. ACM, 115–122.

[45] Yong Kiam Tan, Xinxing Xu, and Yong Liu. 2016. Improved recurrent neural
networks for session-based recommendations. In Proceedings of the 1st Workshop
on Deep Learning for Recommender Systems. 17–22.

[46] Naftali Tishby, Fernando Pereira, and William Bialek. 2000. The information

bottleneck method. arXiv preprint physics/0004057 (2000).

[47] Aaron van den Oord, Sander Dieleman, and Benjamin Schrauwen. 2013. Deep
content-based music recommendation. In Advances in Neural Information Pro-
cessing Systems 26. 2643–2651.

[48] Hao Wang, Naiyan Wang, and Dit-Yan Yeung. 2015. Collaborative deep learning
for recommender systems. In Proceedings of the 21th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining. ACM, 1235–1244.

[49] Markus Weimer, Alexandros Karatzoglou, Quoc V Le, and Alex J Smola. 2008.
Cofi rank-maximum margin matrix factorization for collaborative ranking. In
Advances in neural information processing systems. 1593–1600.

[50] Jason Weston, Samy Bengio, and Nicolas Usunier. 2011. Wsabie: Scaling up to

large vocabulary image annotation. In IJCAI, Vol. 11. 2764–2770.

[51] Yao Wu, Christopher DuBois, Alice X. Zheng, and Martin Ester. 2016. Collabora-
tive denoising auto-encoders for top-n recommender systems. In Proceedings of
the Ninth ACM International Conference on Web Search and Data Mining. 153–162.
[52] Puyang Xu, Asela Gunawardana, and Sanjeev Khudanpur. 2011. Efficient subsam-
pling for training complex language models. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing. Association for Computational
Linguistics, 1128–1136.

[53] Shuang-Hong Yang, Bo Long, Alexander J. Smola, Hongyuan Zha, and Zhao-
hui Zheng. 2011. Collaborative competitive filtering: learning recommender
using context of user choice. In Proceedings of the 34th international ACM SIGIR
conference on Research and development in Information Retrieval. ACM, 295–304.
[54] Yin Zheng, Bangsheng Tang, Wenkui Ding, and Hanning Zhou. 2016. A Neural
Autoregressive Approach to Collaborative Filtering. In Proceedings of The 33rd
International Conference on Machine Learning. 764–773.

8
1
0
2
 
b
e
F
 
6
1
 
 
]
L
M

.
t
a
t
s
[
 
 
1
v
4
1
8
5
0
.
2
0
8
1
:
v
i
X
r
a

Variational Autoencoders for Collaborative Filtering

Dawen Liang
Netflix
Los Gatos, CA
dliang@netflix.com

Matthew D. Hoffman
Google AI
San Francisco, CA
mhoffman@google.com

Rahul G. Krishnan
MIT
Cambridge, MA
rahulgk@mit.edu

Tony Jebara
Netflix
Los Gatos, CA
tjebara@netflix.com

ABSTRACT

1 INTRODUCTION

We extend variational autoencoders (vaes) to collaborative filtering
for implicit feedback. This non-linear probabilistic model enables us
to go beyond the limited modeling capacity of linear factor models
which still largely dominate collaborative filtering research. We
introduce a generative model with multinomial likelihood and use
Bayesian inference for parameter estimation. Despite widespread
use in language modeling and economics, the multinomial likeli-
hood receives less attention in the recommender systems literature.
We introduce a different regularization parameter for the learning
objective, which proves to be crucial for achieving competitive per-
formance. Remarkably, there is an efficient way to tune the parame-
ter using annealing. The resulting model and learning algorithm has
information-theoretic connections to maximum entropy discrimi-
nation and the information bottleneck principle. Empirically, we
show that the proposed approach significantly outperforms several
state-of-the-art baselines, including two recently-proposed neural
network approaches, on several real-world datasets. We also pro-
vide extended experiments comparing the multinomial likelihood
with other commonly used likelihood functions in the latent factor
collaborative filtering literature and show favorable results. Finally,
we identify the pros and cons of employing a principled Bayesian
inference approach and characterize settings where it provides the
most significant improvements.

KEYWORDS

Recommender systems, collaborative filtering, implicit feedback,
variational autoencoder, Bayesian models

ACM Reference Format:
Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara.
2018. Variational Autoencoders for Collaborative Filtering. In Proceedings of
The 2018 Web Conference (WWW 2018). ACM, New York, NY, USA, 10 pages.
https://doi.org/10.1145/3178876.3186150

This paper is published under the Creative Commons Attribution-NonCommercial-
NoDerivs 4.0 International (CC BY-NC-ND 4.0) license. Authors reserve their rights to
disseminate the work on their personal and corporate Web sites with the appropriate
attribution.
WWW 2018, April 23–27, 2018, Lyon, France
© 2018 IW3C2 (International World Wide Web Conference Committee), published
under Creative Commons CC BY-NC-ND 4.0 License.
ACM ISBN 978-1-4503-5639-8/18/04.
https://doi.org/10.1145/3178876.3186150

Recommender systems are an integral component of the web. In
a typical recommendation system, we observe how a set of users
interacts with a set of items. Using this data, we seek to show users
a set of previously unseen items they will like. As the web grows
in size, good recommendation systems will play an important part
in helping users interact more effectively with larger amounts of
content.

Collaborative filtering is among the most widely applied ap-
proaches in recommender systems. Collaborative filtering predicts
what items a user will prefer by discovering and exploiting the
similarity patterns across users and items. Latent factor models
[13, 19, 38] still largely dominate the collaborative filtering research
literature due to their simplicity and effectiveness. However, these
models are inherently linear, which limits their modeling capacity.
Previous work [27] has demonstrated that adding carefully crafted
non-linear features into the linear latent factor models can signif-
icantly boost recommendation performance. Recently, a growing
body of work involves applying neural networks to the collabora-
tive filtering setting with promising results [14, 41, 51, 54].

Here, we extend variational autoencoders (vaes) [24, 37] to col-
laborative filtering for implicit feedback. Vaes generalize linear
latent-factor models and enable us to explore non-linear proba-
bilistic latent-variable models, powered by neural networks, on
large-scale recommendation datasets. We propose a neural gen-
erative model with multinomial conditional likelihood. Despite
being widely used in language modeling and economics [5, 30],
multinomial likelihoods appear less studied in the collaborative
filtering literature, particularly within the context of latent-factor
models. Recommender systems are often evaluated using ranking-
based measures, such as mean average precision and normalized
discounted cumulative gain [21]. Top-N ranking loss is difficult to
optimize directly and previous work on direct ranking loss mini-
mization resorts to relaxations and approximations [49, 50]. Here,
we show that the multinomial likelihoods are well-suited for mod-
eling implicit feedback data, and are a closer proxy to the ranking
loss relative to more popular likelihood functions such as Gaussian
and logistic.

Though recommendation is often considered a big-data problem
(due to the huge numbers of users and items typically present in a
recommender system), we argue that, in contrast, it represents a
uniquely challenging “small-data” problem: most users only inter-
act with a tiny proportion of the items and our goal is to collectively

make informed inference about each user’s preference. To make
use of the sparse signals from users and avoid overfitting, we build
a probabilistic latent-variable model that shares statistical strength
among users and items. Empirically, we show that employing a prin-
cipled Bayesian approach is more robust regardless of the scarcity
of the data.

Although vaes have been extensively studied for image modeling
and generation, there is surprisingly little work applying vaes to
recommender systems. We find that two adjustments are essential
to getting state-of-the-art results with vaes on this task:

• First, we use a multinomial likelihood for the data distribu-
tion. We show that this simple choice realizes models that
outperform the more commonly used Gaussian and logistic
likelihoods.

• Second, we reinterpret and adjust the standard vae objective,
which we argue is over-regularized. We draw connections
between the learning algorithm resulting from our proposed
regularization and the information-bottleneck principle and
maximum-entropy discrimination.

The result is a recipe that makes vaes practical solutions to this im-
portant problem. Empirically, our methods significantly outperform
state-of-the-art baselines on several real-world datasets, including
two recently proposed neural-network approaches.

2 METHOD

We use u ∈ {1, . . . , U } to index users and i ∈ {1, . . . , I } to index
items. In this work, we consider learning with implicit feedback
[19, 34]. The user-by-item interaction matrix is the click1 matrix
X ∈ NU ×I . The lower case xu = [xu1, . . . , xuI ]⊤ ∈ NI is a bag-of-
words vector with the number of clicks for each item from user u.
For simplicity, we binarize the click matrix. It is straightforward to
extend it to general count data.

2.1 Model

The generative process we consider in this paper is similar to the
deep latent Gaussian model [37]. For each user u, the model starts by
sampling a K-dimensional latent representation zu from a standard
Gaussian prior. The latent representation zu is transformed via a
non-linear function fθ (·) ∈ RI to produce a probability distribution
over I items π (zu ) from which the click history xu is assumed to
have been drawn:

zu ∼ N (0, IK ),

π (zu ) ∝ exp{ fθ (zu )},

xu ∼ Mult(Nu , π (zu )).

(1)

The non-linear function fθ (·) is a multilayer perceptron with pa-
rameters θ . The output of this transformation is normalized via a
softmax function to produce a probability vector π (zu ) ∈ SI −1 (an
(I − 1)-simplex) over the entire item set. Given the total number of
clicks Nu = (cid:205)
i xui from user u, the observed bag-of-words vector
xu is assumed to be sampled from a multinomial distribution with
probability π (zu ). This generative model generalizes the latent-
factor model — we can recover classical matrix factorization [38]
by setting fθ (·) to be linear and using a Gaussian likelihood.

The log-likelihood for user u (conditioned on the latent repre-

sentation) is:

log pθ (xu | zu ) c= (cid:213)

xui log πi (zu ).

(2)

i

This multinomial likelihood is commonly used in language models,
e.g., latent Dirichlet allocation [5], and economics, e.g., multino-
mial logit choice model [30]. It is also used in the cross-entropy
loss2 for multi-class classification. For example, it has been used in
recurrent neural networks for session-based sequential recommen-
dation [8, 15, 16, 42, 45] and in feedward neural networks applied
to Youtube recommendation [9]. The multinomial likelihood is less
well studied in the context of latent-factor models such as matrix
factorization and autoencoders. A notable exception is the collab-
orative competitive filtering (CCF) model [53] and its successors,
which take advantage of more fine-grained information about what
options were presented to which users. (If such information is
available, it can also be incorporated into our vae-based approach.)
We believe the multinomial distribution is well suited to mod-
eling click data. The likelihood of the click matrix (Eq. 2) rewards
the model for putting probability mass on the non-zero entries in
xu . But the model has a limited budget of probability mass, since
π (zu ) must sum to 1; the items must compete for this limited budget
[53]. The model should therefore assign more probability mass to
items that are more likely to be clicked. To the extent that it can, it
will perform well under the top-N ranking loss that recommender
systems are commonly evaluated on.

By way of comparison, we present two popular choices of likeli-
hood functions used in latent-factor collaborative filtering: Gauss-
ian and logistic likelihoods. Define fθ (zu ) ≡ [fu1, . . . , fuI ]⊤ as the
output of the generative function fθ (·). The Gaussian log-likelihood
for user u is

log pθ (xu | zu ) c= −

(xui − fui )2.

(3)

(cid:213)

i

cui
2

We adopt the convention in Hu et al. [19] and introduce a “confi-
dence” weight cxui ≡ cui where c1 > c0 to balance the unobserved
0’s which far outnumber the observed 1’s in most click data. This
is also equivalent to training the model with unweighted Gaussian
likelihood and negative sampling. The logistic log-likelihood3 for
user u is
log pθ (xu | zu ) = (cid:213)

xui log σ (fui ) + (1 −xui ) log(1 − σ (fui )), (4)

i

where σ (x) = 1/(1 + exp(−x)) is the logistic function. We compare
multinomial likelihood with Gaussian and logistic in Section 4.

2.2 Variational inference

To learn the generative model in Eq. 1, we are interested in esti-
mating θ (the parameters of fθ (·)). To do so, for each data point we
need to approximate the intractable posterior distribution p(zu | xu ).
We resort to variational inference [22]. Variational inference ap-
proximates the true intractable posterior with a simpler variational

1We use the verb “click” for concreteness; this can be any type of interaction, including
“watch”, “purchase”, or “listen”.

2The cross-entropy loss for multi-class classification is a multinomial likelihood under
a single draw from the distribution.
3Logistic likelihood is also cross-entropy loss for binary classification.

distribution q(zu ). We set q(zu ) to be a fully factorized (diagonal)
Gaussian distribution:

q(zu ) = N (µu , diag{σ 2
The objective of variational inference is to optimize the free varia-
tional parameters {µu , σ 2
u } so that the Kullback-Leiber divergence
KL(q(zu )∥p(zu |xu )) is minimized.

u }).

2.2.1 Amortized inference and the variational autoencoder: With
variational inference the number of parameters to optimize {µu , σ 2
u }
grows with the number of users and items in the dataset. This can be-
come a bottleneck for commercial recommender systems with mil-
lions of users and items. The variational autoencoder (vae) [24, 37]
replaces individual variational parameters with a data-dependent
function (commonly called an inference model):

дϕ (xu ) ≡ [µϕ (xu ), σϕ (xu )] ∈ R2K
parametrized by ϕ with both µϕ (xu ) and σϕ (xu ) being K-vectors
and sets the variational distribution as follows:
qϕ (zu | xu ) = N (µϕ (xu ), diag{σ 2
ϕ

(xu )}).

That is, using the observed data xu as input, the inference model
outputs the corresponding variational parameters of variational
distribution qϕ (zu | xu ), which, when optimized, approximates the
intractable posterior p(zu | xu ).4 Putting qϕ (zu | xu ) and the gen-
erative model pθ (xu | zu ) together in Figure 2c, we end up with
a neural architecture that resembles an autoencoder — hence the
name variational autoencoder.

Vaes make use of amortized inference [12]: they flexibly reuse
inferences to answer related new problems. This is well aligned
with the ethos of collaborative filtering: analyze user preferences
by exploiting the similarity patterns inferred from past experiences.
In Section 2.4, we discuss how this enables us to perform prediction
efficiently.

Learning vaes: As is standard when learning latent-variable
models with variational inference [4], we can lower-bound the log
marginal likelihood of the data. This forms the objective we seek
to maximize for user u (the objective function of the dataset is
obtained by averaging the objective function over all the users):
log p(xu ; θ ) ≥ E

qϕ (zu | xu ) [log pθ (xu | zu )] − KL(qϕ (zu | xu )∥p(zu ))

≡ L(xu ; θ, ϕ)

(5)

This is commonly known as the evidence lower bound (elbo). Note
that the elbo is a function of both θ and ϕ. We can obtain an unbi-
ased estimate of elbo by sampling zu ∼ qϕ and perform stochastic
gradient ascent to optimize it. However, the challenge is that we can-
not trivially take gradients with respect to ϕ through this sampling
process. The reparametrization trick [24, 37] sidesteps this issue: we
sample ϵ ∼ N (0, IK ) and reparametrize zu = µϕ (xu ) + ϵ ⊙ σϕ (xu ).
By doing so, the stochasticity in the sampling process is isolated
and the gradient with respect to ϕ can be back-propagated through
the sampled zu . The vae training procedure is summarized in Al-
gorithm 1.

4In the implementation, the inference model will output the log of the variance of the
variational distribution. We continue to use σϕ (xu ) for notational brevity.

Algorithm 1: VAE-SGD Training collaborative filtering vae
with stochastic gradient descent.

Input: Click matrix X ∈ RU ×I
Randomly initialize θ , ϕ
while not converged do

Sample a batch of users U
forall u ∈ U do

Sample ϵ ∼ N (0, IK ) and compute zu via
reparametrization trick
Compute noisy gradient ∇θ L and ∇ϕ L with zu

Average noisy gradients from batch
Update θ and ϕ by taking stochastic gradient steps

end

end
return θ , ϕ

2.2.2 Alternative interpretation of elbo. We can view elbo de-
fined in Eq. 5 from a different perspective: the first term can be
interpreted as (negative) reconstruction error, while the second
KL term can be viewed as regularization. It is this perspective we
work with because it allows us to make a trade-off that forms the
crux of our method. From this perspective, it is natural to extend
the elbo by introducing a parameter β to control the strength of
regularization:

Lβ (xu ; θ, ϕ) ≡ E

qϕ (zu | xu )[ log pθ (xu | zu )]

−β · KL(qϕ (zu | xu )∥p(zu )).

(6)

While the original vae (trained with elbo in Eq. 5) is a powerful
generative model; we might ask whether we need all the statistical
properties of a generative model for tackling problems in recom-
mender systems. In particular, if we are willing to sacrifice the
ability to perform ancestral sampling, can we improve our perfor-
mance? The regularization view of the elbo (Eq. 6) introduces a
trade-off between how well we can fit the data and how close the
approximate posterior stays to the prior during learning.

(cid:205)

We propose using β (cid:44) 1. This means we are no longer opti-
mizing a lower bound on the log marginal likelihood. If β < 1,
then we are also weakening the influence of the prior constraint
1
u q(z | xu ) ≈ p(z) = N (z; 0, IK ) [18]; this means that the model
U
is less able to generate novel user histories by ancestral sampling.
But ultimately our goal is to make good recommendations, not to
maximize likelihood or generate imagined user histories. Treating
β as a free regularization parameter therefore costs us nothing, and,
as we will see, yields significant improvements in performance.

Selecting β: We propose a simple heuristic for setting β: we
start training with β = 0, and gradually increase β to 1. We linearly
anneal the KL term slowly over a large number of gradient updates
to θ, ϕ and record the best β when its performance reaches the peak.
We found this method to work well and it does not require the need
for training multiple models with different values of β, which can
be time-consuming. Our procedure is inspired by KL annealing [7],
a common heuristic used for training vaes when there is concern
that the model is being underutilized.

Figure 1 illustrates the basic idea (we observe the same trend
consistently across datasets). Here we plot the validation ranking
metric without KL annealing (blue solid) and with KL annealing all
the way to β = 1 (green dashed, β reaches 1 at around 80 epochs).
As we can see, the performance is poor without any KL annealing.
With annealing, the validation performance first increases as the
training proceeds and then drops as β gets close to 1 to a value that
is only slightly better than doing no annealing at all.

Having identified the best β based on the peak validation metric,
we can retrain the model with the same annealing schedule, but stop
increasing β after reaching that value (shown as red dot-dashed in
Figure 1).5 This might be sub-optimal compared to a thorough grid
search. However, it is much more efficient, and gives us competi-
tive empirical performance. If the computational budget is scarce,
then within a single run, we can stop increasing β when we notice
the validation metric dropping. Such a procedure incurs no addi-
tional runtime to learning a standard vae. We denote this partially
regularized vae with multinomial likelihood as Mult-vaepr.

Figure 1: Validation ranking metrics with different anneal-
ing configurations. For the green dashed curve, β reaches 1
at around 80 epochs.

2.2.3 Computational Burden. Previous collaborative filtering
models with neural networks [14, 51] are trained with stochastic
gradient descent where in each step a single (user, item) entry
from the click matrix is randomly sampled to perform a gradient
update. In Algorithm 1 we subsample users and take their entire
click history (complete rows of the click matrix) to update model
parameters. This eliminates the necessity of negative sampling (and
consequently the hyperparameter tuning for picking the number
of negative examples), commonly used in the (user, item) entry
subsampling scheme.

A computational challenge that comes with our approach, how-
ever, is that when the number of items is huge, computing the
multinomial probability π (zu ) could be computationally expensive,
since it requires computing the predictions for all the items for
normalization. This is a common challenge for language model-
ing where the size of the vocabulary is in the order of millions or
more [32]. In our experiments on some medium-to-large datasets
with less than 50K items (Section 4.1), this has not yet come up
as a computational bottleneck. If this becomes a bottleneck when
working with larger item sets, one can easily apply the simple and

effective method proposed by Botev et al. [6] to approximate the
normalization factor for π (zu ).

2.3 A taxonomy of autoencoders

In Section 2.2, we introduced maximum marginal likelihood es-
timation of vaes using approximate Bayesian inference under a
non-linear generative model (Eq. 1). We now describe our work from
the perspective of learning autoencoders. Maximum-likelihood es-
timation in a regular autoencoder takes the following form:

θ AE, ϕAE = arg max

E
δ (zu −дϕ (xu )) [log pθ (xu | zu )]

log pθ (xu | дϕ (xu ))

(7)

(cid:213)

u
(cid:213)

u

θ,ϕ
= arg max
θ,ϕ

There are two key distinctions of note: (1) The autoencoder (and
denoising autoencoder) effectively optimizes the first term in the
vae objective (Eq. 5 and Eq. 6) using a delta variational distribution
qϕ (zu | xu ) = δ (zu − дϕ (xu )) — it does not regularize qϕ (zu | xu )
towards any prior distribution as the vae does. (2) the δ (zu −дϕ (xu ))
is a δ distribution with mass only at the output of дϕ (xu ). Contrast
this to the vae, where the learning is done using a variational
distribution, i.e., дϕ (xu ) outputs the parameters (mean and variance)
of a Gaussian distribution. This means that vae has the ability to
capture per-data-point variances in the latent state zu .

In practice, we find that learning autoencoders is extremely
prone to overfitting as the network learns to put all the probability
mass to the non-zero entries in xu . By introducing dropout [43]
at the input layer, the denoising autoencoder (dae) is less prone
to overfitting and we find that it also gives competitive empirical
results. In addition to the Mult-vaepr, we also study a denoising
autoencoder with a multinomial likelihood. We denote this model
Mult-dae. In Section 4 we characterize the tradeoffs in what is
gained and lost by explicitly parameterizing the per-user variance
with Mult-vaepr versus using a point-estimation in Mult-dae.

To provide a unified view of different variants of autoencoders
and clarify where our work stands, we depict variants of autoen-
coders commonly found in the literature in Figure 2. For each one,
we specify the model (dotted arrows denote a sampling operation)
and describe the training objective used in parameter estimation.
In Figure 2a we have autoencoder. It is trained to reconstruct
input with the same objective as in Eq. 7. Adding noise to the in-
put (or the intermediate hidden representation) of an autoencoder
yields the denoising autoencoder in Figure 2b. The training objec-
tive is the same as that of an autoencoder. Mult-dae belongs to this
model class. Collaborative denoising autoencoder [51] is a variant
of this model class. The vae is depicted in Figure 2c. Rather than
using a delta variational distribution, it uses an inference model
parametrized by ϕ to produce the mean and variance of the approx-
imating variational distribution. The training objective of the vae is
given in Eq. 6. Setting β to 1 recovers the original vae formulation
[24, 37]. Higgins et al. [17] study the case where β > 1. Our model,
Mult-vaepr corresponds to learning vaes with β ∈ [0, 1].

2.4 Prediction

5We found this to give slightly better results than keeping β at the best value through-
out the training.

We now describe how we make predictions given a trained gen-
erative model of the form Eq. 1. For both, Mult-vaepr (Section 2.2)

(a) Autoencoder

(b) Denoising
Autoencoder

(c) Variational
Autoencoder

x

ϕ

z

θ

x

x

ϕ

z

θ

x

ϵ

ϕ

ϕ

µ

σ

ϵ

x

z

θ

x

Figure 2: A taxonomy of autoencoders. The dotted arrows denote a sampling operation.

or Mult-dae (Section 2.3), we make predictions in the same way.
Given a user’s click history x, we rank all the items based on the
un-normalized predicted multinomial probability fθ (z). The latent
representation z for x is constructed as follows: For Mult-vaepr, we
simply take the mean of the variational distribution z = µϕ (x); for
Mult-dae, we take the output z = дϕ (x).

It is easy to see the advantage of using autoencoders. We can
effectively make predictions for users by evaluating two functions
– the inference model (encoder) дϕ (·) and the generative model
(decoder) fθ (·). For most of the latent factor collaborative filtering
model, e.g., matrix factorization [13, 19], when given the click his-
tory of a user that is not present in the training data, normally we
need to perform some form of optimization to obtain the latent
factor for this user. This makes the use of autoencoders particu-
larly attractive in industrial applications, where it is important that
predictions be made cheaply and with low latency.

3 RELATED WORK
Vaes on sparse data. Variational autoencoders (vaes) [24, 37]
have seen much application to images since their inception. Doer-
sch [10] presents a review on different applications of vae to image
data. Miao et al. [31] study vaes on text data. More recent results
from Krishnan et al. [25] find that vaes (trained with Eq. 5) suffer
from underfitting when modeling large, sparse, high-dimensional
data. We notice similar issues when fitting vae without annealing
(Figure 1) or annealing to β = 1. By giving up the ability to perform
ancestral sampling in the model, and setting β ≤ 1, the resulting
model is no longer a proper generative model though for collabora-
tive filtering tasks we always make predictions conditional on users’
click history.

Information-theoretic connection with vae. The regular-
ization view of the elbo in Eq. 6 resembles maximum-entropy
discrimination [20]. Maximum-entropy discrimination attempts to
combine discriminative estimation with Bayesian inference and
generative modeling. In our case, in Eq. 6, β acts as a knob to balance
discriminative and generative aspects of the model.

The procedure in Eq. 6 has information-theoretic connections
described in Alemi et al. [1]. The authors propose the deep varia-
tional information bottleneck, which is a variational approximation
to the information bottleneck principle [46]. They show that as a
special case they can recover the learning objective used by vaes.
They report more robust supervised classification performance with
β < 1. This is consistent with our findings as well. Higgins et al.
[17] proposed β-vae, which leads to the same objective as Eq. 6.

They motivate β-vae for the goal of learning disentangled repre-
sentations from images (basic visual concepts, such as shape, scale,
and color). Their work, however, sets β ≫ 1, effectively imposing a
stronger independent prior assumption on the latent code z. While
their motivations are quite different from ours, it is interesting to
note orthogonal lines of research emerging from exploring the full
spectrum of values for β.

Neural networks for collaborative filtering. Early work on
neural-network-based collaborative filtering models focus on ex-
plicit feedback data and evaluates on the task of rating predictions
[11, 39, 41, 54]. The importance of implicit feedback has been grad-
ually recognized, and consequently most recent research, such as
this work, has focused on it. The two papers that are most closely
related to our approaches are collaborative denoising autoencoder
[51] and neural collaborative filtering [14].

Collaborative denoising autoencoder (cdae) [51] augments the
standard denoising autoencoder, described in Section 2.3, by adding
a per-user latent factor to the input. The number of parameters of
the cdae model grows linearly with both the number of users as
well as the number of items, making it more prone to overfitting. In
contrast, the number of parameters in the vae grows linearly with
the number of items. The cdae also requires additional optimiza-
tion to obtain the latent factor for unseen users to make predicion.
In the paper, the authors investigate the Gaussian and logistic like-
lihood loss functions — as we show, the multinomial likelihood is
significantly more robust for use in recommender systems. Neural
collaborative filtering (ncf) [14] explore a model with non-linear
interactions between the user and item latent factors rather than
the commonly used dot product. The authors demonstrate improve-
ments of ncf over standard baselines on two small datasets. Similar
to cdae, the number of parameters of ncf also grows linearly with
both the number of users as well as items. We find that this becomes
problematic for much larger datasets. We compare with both cdae
and ncf in Section 4.

Asymmetric matrix factorization [35] may also be interpreted
as an autoencoder, as elaborated in Steck [44]. We can recover this
work by setting both fθ (·) and дϕ (·) to be linear.

Besides being applied in session-based sequential recommen-
dation (see Section 2.1), various approaches [2, 28, 47, 48] have
applied neural networks to incorporate side information into col-
laborative filtering models to better handle the cold-start problem.
These approaches are complementary to ours.

Table 1: Attributes of datasets after preprocessing. Interac-
tions are non-zero entries. % of interactions refers to the den-
sity of the user-item click matrix X. # of the held-out users is
the number of validation/test users out of the total number
of users in the first row.

ML-20M Netflix MSD

# of users
# of items
# of interactions
% of interactions

136,677
20,108
10.0M
0.36%

463,435
17,769
56.9M
0.69%

571,355
41,140
33.6M
0.14%

# of held-out users

10,000

40,000

50,000

4 EMPIRICAL STUDY
We evaluate the performance of Mult-vaepr and Mult-dae. We pro-
vide insights into their performance by exploring the resulting fits.
We highlight the following results:

• Mult-vaepr achieves state-of-the-art results on three real-
world datasets when compared with various baselines, in-
cluding recently proposed neural-network-based collabora-
tive filtering models.

• For the denoising and variational autoencoder, the multino-
mial likelihood compares favorably over the more common
Gaussian and logistic likelihoods.

• Both Mult-vaepr and Mult-dae produce competitive empirical
results. We identify when parameterizing the uncertainty
explicitly as in Mult-vaepr does better/worse than the point
estimate used by Mult-dae and list pros and cons for both
approaches.

The source code to reproduce the experimental results is avail-

able on GitHub6.

4.1 Datasets

We study three medium- to large-scale user-item consumption
datasets from various domains:

MovieLens-20M (ML-20M): These are user-movie ratings col-
lected from a movie recommendation service. We binarize the ex-
plicit data by keeping ratings of four or higher and interpret them
as implicit feedback. We only keep users who have watched at least
five movies.

Netflix Prize (Netflix): This is the user-movie ratings data from
the Netflix Prize7. Similar to ML-20M, we binarize explicit data by
keeping ratings of four or higher. We only keep users who have
watched at least five movies.

Million Song Dataset (MSD): This data contains the user-song
play counts released as part of the Million Song Dataset [3]. We
binarize play counts and interpret them as implicit preference data.
We only keep users with at least 20 songs in their listening history
and songs that are listened to by at least 200 users.

Table 1 summarizes the dimensions of all the datasets after pre-

processing.

6https://github.com/dawenl/vae_cf
7http://www.netflixprize.com/

4.2 Metrics

We use two ranking-based metrics: Recall@R and the truncated
normalized discounted cumulative gain (NDCG@R). For each user,
both metrics compare the predicted rank of the held-out items with
their true rank. For both Mult-vaepr and Mult-dae, we get the pre-
dicted rank by sorting the un-normalized multinomial probability
fθ (z). While Recall@R considers all items ranked within the first R
to be equally important, NDCG@R uses a monotonically increasing
discount to emphasize the importance of higher ranks versus lower
ones. Formally, define ω(r ) as the item at rank r , I[·] is the indicator
function, and Iu is the set of held-out items that user u clicked on.

Recall@R for user u is

Recall@R(u, ω) :=

(cid:205)R

I[ω(r ) ∈ Iu ]

r =1
min(M, |Iu |)

.

The expression in the denominator is the minimum of R and the
number of items clicked on by user u. This normalizes Recall@R to
have a maximum of 1, which corresponds to ranking all relevant
items in the top R positions.

Truncated discounted cumulative gain (DCG@R) is

DCG@R(u, ω) :=

R
(cid:213)

2

r =1

I[ω(r )∈Iu ] − 1
log(r + 1)

.

NDCG@R is the DCG@R linearly normalized to [0, 1] after
dividing by the best possible DCG@R, where all the held-out items
are ranked at the top.

4.3 Experimental setup

We study the performance of various models under strong general-
ization [29]: We split all users into training/validation/test sets. We
train models using the entire click history of the training users. To
evaluate, we take part of the click history from held-out (validation
and test) users to learn the necessary user-level representations for
the model and then compute metrics by looking at how well the
model ranks the rest of the unseen click history from the held-out
users.

This is relatively more difficult than weak generalization where
the user’s click history can appear during both training and evalua-
tion. We consider it more realistic and robust as well. In the last row
of Table 1, we list the number of held-out users (we use the same
number of users for validation and test). For each held-out user,
we randomly choose 80% of the click history as the “fold-in” set to
learn the necessary user-level representation and report metrics on
the remaining 20% of the click history.

We select model hyperparameters and architectures by evaluat-
ing NDCG@100 on the validation users. For both Mult-vaepr and
Mult-dae, we keep the architecture for the generative model fθ (·)
and the inference model дϕ (·) symmetrical and explore multilayer
perceptron (mlp) with 0, 1, and 2 hidden layers. We set the dimen-
sion of the latent representation K to 200 and any hidden layer to
600. As a concrete example, recall I is the total number of items, the
overall architecture for a Mult-vaepr/Mult-dae with 1-hidden-layer
mlp generative model would be [I → 600 → 200 → 600 → I ]. We
find that going deeper does not improve performance. The best per-
forming architectures are mlps with either 0 or 1 hidden layers. We
use a tanh non-linearity as the activation function between layers.

Note that for Mult-vaepr, since the output of дϕ (·) is used as the
mean and variance of a Gaussian random variable, we do not apply
an activation function to it. Thus, the Mult-vaepr with 0-hidden-
layer mlp is effectively a log-linear model. We tune the regulariza-
tion parameter β for Mult-vaepr following the procedure described
in Section 2.2.2. We anneal the Kullback-Leibler term linearly for
200,000 gradient updates. For both Mult-vaepr and Mult-dae, we
apply dropout at the input layer with probability 0.5. We apply a
weight decay of 0.01 for Mult-dae. We do not apply weight decay
for any vae models. We train both Mult-vaepr and Mult-dae using
Adam [23] with batch size of 500 users. For ML-20M, we train for
200 epochs. We train for 100 epochs on the other two datasets. We
keep the model with the best validation NDCG@100 and report
test set metrics with it.

4.4 Baselines

We compare results with the following standard state-of-the-art
collaborative filtering models, both linear and non-linear:

Weighted matrix factorization (wmf) [19]: a linear low-rank
factorization model. We train wmf with alternating least squares;
this generally leads to better performance than with SGD. We set the
weights on all the 0’s to 1 and tune the weights on all the 1’s in the
click matrix among {2, 5, 10, 30, 50, 100}, as well as the latent repre-
sentation dimension K ∈ {100, 200} by evaluating NDCG@100 on
validation users.

Slim [33]: a linear model which learns a sparse item-to-item
similarity matrix by solving a constrained ℓ1-regularized optimiza-
tion problem. We grid-search both of the regularization parameters
over {0.1, 0.5, 1, 5} and report the setting with the best NDCG@100
on validation users. We did not evaluate Slim on MSD because the
dataset is too large for it to finish in a reasonable amount of time
(for the Netflix dataset, the parallelized grid search took about two
weeks). We also found that the faster approximation of Slim [26]
did not yield competitive performance.

Collaborative denoising autoencoder (cdae) [51]: augments
the standard denoising autoencoder by adding a per-user latent
factor to the input. We change the (user, item) entry subsampling
strategy in SGD training in the original paper to the user-level
subsampling as we did with Mult-vaepr and Mult-dae. We generally
find that this leads to more stable convergence and better perfor-
mance. We set the dimension of the bottleneck layer to 200, and
use a weighted square loss, equivalent to what the square loss with
negative sampling used in the original paper. We apply tanh activa-
tion at both the bottleneck layer as well as the output layer.8 We
use Adam with a batch size of 500 users. As mentioned in Section 3,
the number of parameters for cdae grows linearly with the num-
ber of users and items. Thus, it is crucial to control overfitting by
applying weight decay. We select the weight decay parameter over
{0.01, 0.1, · · · , 100} by examining the validation NDCG@100.

Neural collaborative filtering (ncf) [14]: explores non-linear
interactions (via a neural network) between the user and item latent
factors. Similar to cdae, the number of parameters for ncf grows
linearly with the number of users and items. We use the publicly
available source code provided by the authors, yet cannot obtain

8Wu et al. [51] used sigmoid activation function but mentioned tanh gave similar
results. We use tanh to be consistent with our models.

competitive performance on the datasets used in this paper — the
validation metrics drop within the first few epochs over a wide
range of regularization parameters. The authors kindly provided
the two datasets (ML-1M and Pinterest) used in the original paper,
as well as the training/test split, therefore we separately compare
with ncf on these two relatively smaller datasets in the empirical
study. In particular, we compare with the hybrid NeuCF model
which gives the best performance in He et al. [14], both with and
without pre-training.

We also experiment with Bayesian personalized ranking (bpr)
[36]. However, the performance is not on par with the other base-
lines above. This is consistent with some other studies with similar
baselines [40]. Therefore, we do not include bpr in the following
results and analysis.

4.5 Experimental results and analysis

In this section, we quantitatively compare our proposed methods
with various baselines. In addition, we aim to answer the following
two questions:

1. How does multinomial likelihood compare with other com-
monly used likelihood models for collaborative filtering?
2. When does Mult-vaepr perform better/worse than Mult-dae?
Quantitative results. Table 2 summarizes the results between
our proposed methods and various baselines. Each metric is av-
eraged across all test users. Both Mult-vaepr and Mult-dae signifi-
cantly outperform the baselines across datasets and metrics. Mult-
vaepr significantly outperforms Mult-dae on ML-20M and Netflix
data-sets. In most of the cases, non-linear models (Mult-vaepr, Mult-
dae, and cdae) prove to be more powerful collaborative filtering
models than state-of-the-art linear models. The inferior results of
cdae on MSD are possibly due to overfitting with the huge number
of users and items, as validation metrics drop within the first few
epochs even though the training objective continues improving.

We compare with ncf on the two relatively smaller datasets used
in Hu et al. [19]: ML-1M (6,040 users, 3,704 items, 4.47% density) and
Pinterest (55,187 users, 9,916 items, 0.27% density). Because of the
size of these two datasets, we use Mult-dae with a 0-hidden-layer
mlp generative model — the overall architecture is [I → 200 → I ].
(Recall Mult-vaepr with a 0-hidden-layer mlp generative model
is effectively a log-linear model with limited modeling capacity.)
Table 3 summarizes the results between Mult-dae and ncf. Mult-
dae significantly outperforms ncf without pre-training on both
datasets. On the larger Pinterest dataset, Mult-dae even improves
over the pre-trained ncf model by a big margin.

How well does multinomial likelihood perform? Despite
being commonly used in language models, multinomial likelihoods
have typically received less attention in the collaborative filtering
literature, especially with latent-factor models. Most previous work
builds on Gaussian likelihoods (square loss, Eq. 3) [19, 33, 51] or
logistic likelihood (log loss, Eq. 4) [14, 51] instead. We argue in
Section 2.1 that multinomial likelihood is in fact a good proxy for
the top-N ranking loss and is well-suited for implicit feedback data.
To demonstrate the effectiveness of multinomial likelihood, we
take the best-performing Mult-vaepr and Mult-dae model on each
dataset and swap the likelihood distribution model for the data
while keeping everything else exactly the same.

Table 2: Comparison between various baselines and our pro-
posed methods. Standard errors are around 0.002 for ML-
20M and 0.001 for Netflix and MSD. Both Mult-vaepr and
Mult-dae significantly outperform the baselines across
datasets and metrics. We could not finish Slim within a rea-
sonable amount of time on MSD.

Table 4: Comparison of Mult-vaepr and Mult-dae with differ-
ent likelihood functions at the output layer on ML-20M. The
standard error is around 0.002 (the results on the other two
datasets are similar.) The multinomial likelihood performs
better than the other two commonly-used likelihoods from
the collaborative filtering literature.

(a) ML-20M

Mult-vaepr
Mult-dae

Recall@20 Recall@50 NDCG@100
0.537
0.524

0.395
0.387

0.426
0.419

wmf
Slim
cdae

0.360
0.370
0.391

0.498
0.495
0.523

0.386
0.401
0.418

(b) Netflix

Mult-vaepr
Mult-dae

Recall@20 Recall@50 NDCG@100
0.444
0.438

0.351
0.344

0.386
0.380

wmf
Slim
cdae

0.316
0.347
0.343

0.404
0.428
0.428

0.351
0.379
0.376

(c) MSD

Mult-vaepr
Mult-dae

Recall@20 Recall@50 NDCG@100
0.364
0.363

0.266
0.266

0.316
0.313

wmf
Slim
cdae

0.211
—
0.188

0.312
—
0.283

0.257
—
0.237

Table 3: Comparison between ncf and Mult-dae with [I →
200 → I ] architecture. We take the results of ncf from He
et al. [14]. Mult-dae model significantly outperforms ncf
without pre-training on both datasets and further improves
on Pinterest even comparing with pre-trained ncf.

ncf

ncf (pre-train) Mult-dae

Recall@10
NDCG@10

0.705
0.426

0.730
0.447

0.722
0.446

(a) ML-1M

(b) Pinterest

ncf

ncf (pre-train) Mult-dae

Recall@10
NDCG@10

0.872
0.551

0.880
0.558

0.886
0.580

Mult-vaepr
Gaussian-vaepr
Logistic-vaepr

Mult-dae
Gaussian-dae
Logistic-dae

Recall@20 Recall@50 NDCG@100
0.537
0.523
0.523
0.524
0.515
0.516

0.395
0.383
0.388
0.387
0.376
0.381

0.426
0.415
0.419
0.419
0.409
0.414

Table 4 summarizes the results of different likelihoods on ML-
20M (the results on the other two datasets are similar.) We tune
the hyperparameters for each likelihood separately.9 The multino-
mial likelihood performs better than the other likelihoods. The gap
between logistic and multinomial likelihood is closer — this is un-
derstandable since multinomial likelihood can be approximated by
individual binary logistic likelihood, a strategy commonly adopted
in language modeling [32, 52].

We wish to emphasize that the choice of likelihood remains data-
dependent. For the task of collaborative filtering, the multinomial
likelihood achieves excellent empirical results. The methodology
behind the partial regularization in Mult-vaepr, however, is a tech-
nique we hypothesize will generalize to other domains.

When does Mult-vaepr perform better/worse than Mult-
dae? In Table 2 we can see that both Mult-vaepr and Mult-dae pro-
duce competitive empirical results with Mult-vaepr being compa-
rably better. It is natural to wonder when a variational Bayesian
inference approach (Mult-vaepr) will win over using a point esti-
mate (Mult-dae) and vice versa.

Intuitively, Mult-vaepr imposes stronger modeling assumptions
and therefore could be more robust when user-item interaction
data is scarce. To study this, we considered two datasets: ML-20M
where Mult-vaepr has the largest margin over Mult-dae and MSD
where Mult-vaepr and Mult-dae have roughly similar performance.
The results on the Netflix dataset are similar to ML-20M. We break
down test users into quintiles based on their activity level in the
fold-in set which is provided as input to the inference model дϕ (·)
to make prediction. The activity level is simply the number of items
each user has clicked on. We compute NDCG@100 for each group
of users using both Mult-vaepr and Mult-dae and plot results in
Figure 3. This summarizes how performance differs across users
with various levels of activity.

In Figure 3, we show performance across increasing user ac-
tivity. Error bars represents one standard error. For each subplot,
a paired t-test is performed and statistical significance is marked.
Although there are slight variations across datasets, Mult-vaepr con-
sistently improves recommendation performance for users who
have only clicked on a small number of items. This is particularly
prominent for ML-20M (Figure 3a). Interestingly, Mult-dae actually

9Surprisingly, partial regularization seems less effective for Gaussian and logistic.

(a) ML-20M

(b) MSD

Figure 3: NDCG@100 breakdown for users with increasing levels of activity (starting from 0%), measured by how many items
a user clicked on in the fold-in set. The error bars represents one standard error. For each subplot, a paired t-test is performed
and * indicates statistical significance at α = 0.05 level, ** at α = 0.01 level, and *** at α = 0.001 level. Although details vary
across datasets, Mult-vaepr consistently improves recommendation performance for users who have only clicked on a small
number of items.

outperforms Mult-vaepr on the most active users. This indicates
the stronger prior assumption could potentially hurt the perfor-
mance when a lot of data is available for a user. For MSD (Figure 3b),
the least-active users have similar performance under both Mult-
vaepr and Mult-dae. However, as we described in Section 4.1, MSD
is pre-processed so that a user has at least listened to 20 songs.
Meanwhile for ML-20M, each user has to watch at least 5 movies.
This means that the first bin of ML-20M has much lower user activ-
ity than the first bin of MSD.

Overall, we find that Mult-vaepr, which may be viewed under
the lens of a principled Bayesian inference approach, is more ro-
bust than the point estimate approach of Mult-dae, regardless of
the scarcity of the data. More importantly, the Mult-vaepr is less
sensitive to the choice of hyperparameters – weight decay is im-
portant for Mult-dae to achieve competitive performance, yet it is
not required for Mult-vaepr. On the other hand, Mult-dae also has
advantages: it requires fewer parameters in the bottleneck layer
— Mult-vaepr requires two sets of parameters to obtain the latent
representation z: one set for the variational mean µϕ (·) and another
for the variational variance σϕ (·) — and Mult-dae is conceptually
simpler for practitioners.

5 CONCLUSION

In this paper, we develop a variant of vae for collaborative filtering
on implicit feedback data. This enables us to go beyond linear factor
models with limited modeling capacity.

We introduce a generative model with a multinomial likelihood
function parameterized by neural network. We show that multino-
mial likelihood is particularly well suited to modeling user-item
implicit feedback data.

Based on an alternative interpretation of the vae objective, we in-
troduce an additional regularization parameter to partially regular-
ize a vae (Mult-vaepr). We also provide a practical and efficient way
to tune the additional parameter introduced using KL annealing.
We compare the results obtained against a denoising autoencoder
(Mult-dae).

Empirically, we show that the both Mult-vaepr and Mult-dae pro-
vide competitive performance with Mult-vaepr significantly outper-
forming the state-of-the-art baselines on several real-world datasets,
including two recently proposed neural-network-based approaches.
Finally, we identify the pros and cons of both Mult-vaepr and Mult-
dae and show that employing a principled Bayesian approach is
more robust.

In future work, we would like to futher investigate the trade-
off introduced by the additional regularization parameter β and
gain more theoretical insight into why it works so well. Extending
Mult-vaepr by condition on side information might also be a way to
improve performance.

REFERENCES
[1] Alexander Alemi, Ian Fischer, Joshua Dillon, and Kevin Murphy. 2017. Deep
Variational Information Bottleneck. In 5th International Conference on Learning
Representations.

[2] Amjad Almahairi, Kyle Kastner, Kyunghyun Cho, and Aaron Courville. 2015.
Learning distributed representations from reviews for collaborative filtering. In
Proceedings of the 9th ACM Conference on Recommender Systems. ACM, 147–154.
[3] Thierry Bertin-Mahieux, Daniel P.W. Ellis, Brian Whitman, and Paul Lamere.

2011. The Million Song Dataset.. In ISMIR, Vol. 2. 10.

[4] David M. Blei, Alp Kucukelbir, and Jon D. McAuliffe. 2017. Variational Inference:
A Review for Statisticians. J. Amer. Statist. Assoc. 112, 518 (2017), 859–877.
[5] David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent dirichlet

allocation. Journal of Machine Learning Research 3, Jan (2003), 993–1022.

[6] Aleksandar Botev, Bowen Zheng, and David Barber. 2017. Complementary
Sum Sampling for Likelihood Approximation in Large Scale Classification. In
Proceedings of the 20th International Conference on Artificial Intelligence and

Statistics. 1030–1038.

[7] Samuel R. Bowman, Luke Vilnis, Oriol Vinyals, Andrew M. Dai, Rafal Jozefowicz,
and Samy Bengio. 2015. Generating sentences from a continuous space. arXiv
preprint arXiv:1511.06349 (2015).

[8] Sotirios Chatzis, Panayiotis Christodoulou, and Andreas S. Andreou. 2017. Recur-
rent Latent Variable Networks for Session-Based Recommendation. In Proceedings
of the 2nd Workshop on Deep Learning for Recommender Systems.

[9] Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep neural networks
for youtube recommendations. In Proceedings of the 10th ACM Conference on
Recommender Systems. ACM, 191–198.

[10] Carl Doersch. 2016. Tutorial on variational autoencoders. arXiv preprint

arXiv:1606.05908 (2016).

[11] Kostadin Georgiev and Preslav Nakov. 2013. A non-IID Framework for Collabo-
rative Filtering with Restricted Boltzmann Machines. In Proceedings of the 30th
International Conference on Machine Learning. 1148–1156.

[12] Samuel Gershman and Noah Goodman. 2014. Amortized inference in probabilistic

reasoning. In Proceedings of the Cognitive Science Society, Vol. 36.

[13] Prem Gopalan, Jake M. Hofman, and David M. Blei. 2015. Scalable Recom-
mendation with Hierarchical Poisson Factorization. In Uncertainty in Artificial
Intelligence.

[14] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng
Chua. 2017. Neural collaborative filtering. In Proceedings of the 26th International
Conference on World Wide Web. 173–182.

[15] Balázs Hidasi and Alexandros Karatzoglou. 2017. Recurrent Neural Networks with
Top-k Gains for Session-based Recommendations. arXiv preprint arXiv:1706.03847
(2017).

[16] Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk.
2015. Session-based recommendations with recurrent neural networks. arXiv
preprint arXiv:1511.06939 (2015).

[17] Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot,
Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. 2017. β -VAE:
Learning Basic Visual Concepts with a Constrained Variational Framework. In
5th International Conference on Learning Representations.

[18] Matthew D. Hoffman and Matthew J. Johnson. 2016. ELBO surgery: yet another
way to carve up the variational evidence lower bound. In Workshop in Advances
in Approximate Bayesian Inference, NIPS.

[19] Yifan Hu, Yehuda Koren, and Chris Volinsky. 2008. Collaborative filtering for im-
plicit feedback datasets. In Data Mining, 2008. ICDM’08. Eighth IEEE International
Conference on. 263–272.

[20] Tommi Jaakkola, Marina Meila, and Tony Jebara. 2000. Maximum entropy dis-
crimination. In Advances in Neural Information Processing Systems. 470–476.
[21] Kalervo Järvelin and Jaana Kekäläinen. 2002. Cumulated gain-based evaluation
of IR techniques. ACM Transactions on Information Systems (TOIS) 20, 4 (2002),
422–446.

[22] Michael I. Jordan, Zoubin Ghahramani, Tommi S. Jaakkola, and Lawrence K. Saul.
1999. An introduction to variational methods for graphical models. Machine
learning 37, 2 (1999), 183–233.

[23] Diederik Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimiza-

tion. arXiv preprint arXiv:1412.6980 (2014).

[24] Diederik P. Kingma and Max Welling. 2013. Auto-encoding variational bayes.

arXiv preprint arXiv:1312.6114 (2013).

[25] Rahul G. Krishnan, Dawen Liang, and Matthew D. Hoffman. 2017. On the
challenges of learning with inference networks on sparse, high-dimensional data.
arXiv preprint arXiv:1710.06085 (2017).

[26] Mark Levy and Kris Jack. 2013. Efficient top-n recommendation by linear regres-

sion. In RecSys Large Scale Recommender Systems Workshop.

[27] Dawen Liang, Jaan Altosaar, Laurent Charlin, and David M. Blei. 2016. Factor-
ization meets the item embedding: Regularizing matrix factorization with item
co-occurrence. In Proceedings of the 10th ACM conference on recommender systems.
59–66.

[28] Dawen Liang, Minshu Zhan, and Daniel P.W. Ellis. 2015. Content-Aware Collab-
orative Music Recommendation Using Pre-trained Neural Networks.. In ISMIR.
295–301.

[29] Benjamin Marlin. 2004. Collaborative filtering: A machine learning perspective.

[30] Daniel McFadden et al. 1973. Conditional logit analysis of qualitative choice

University of Toronto.

behavior. (1973), 105–142 pages.

[31] Yishu Miao, Lei Yu, and Phil Blunsom. 2016. Neural variational inference for text
processing. In International Conference on Machine Learning. 1727–1736.

[32] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S. Corrado, and Jeff Dean. 2013.
Distributed representations of words and phrases and their compositionality. In
Advances in neural information processing systems. 3111–3119.

[33] Xia Ning and George Karypis. 2011. Slim: Sparse linear methods for top-n
recommender systems. In Data Mining (ICDM), 2011 IEEE 11th International
Conference on. 497–506.

[34] Rong Pan, Yunhong Zhou, Bin Cao, Nathan N. Liu, Rajan Lukose, Martin Scholz,
and Qiang Yang. 2008. One-class collaborative filtering. In Data Mining, 2008.
ICDM’08. Eighth IEEE International Conference on. 502–511.

[35] Arkadiusz Paterek. 2007. Improving regularized singular value decomposition
for collaborative filtering. In Proceedings of KDD cup and workshop, Vol. 2007.
5–8.

[36] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme.
2009. BPR: Bayesian personalized ranking from implicit feedback. In Proceedings
of the twenty-fifth conference on uncertainty in artificial intelligence. 452–461.

[37] Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. 2014. Stochastic
Backpropagation and Approximate Inference in Deep Generative Models. In
Proceedings of the 31st International Conference on Machine Learning. 1278–1286.
[38] Ruslan Salakhutdinov and Andriy Mnih. 2008. Probabilistic matrix factorization.

Advances in neural information processing systems (2008), 1257–1264.

[39] Ruslan Salakhutdinov, Andriy Mnih, and Geoffrey Hinton. 2007. Restricted Boltz-
mann machines for collaborative filtering. In Proceedings of the 24th International
Conference on Machine Learning. 791–798.

[40] Suvash Sedhain, Aditya Krishna Menon, Scott Sanner, and Darius Braziunas. 2016.
On the Effectiveness of Linear Models for One-Class Collaborative Filtering.. In
AAAI.

[41] Suvash Sedhain, Aditya Krishna Menon, Scott Sanner, and Lexing Xie. 2015.
Autorec: Autoencoders meet collaborative filtering. In Proceedings of the 24th
International Conference on World Wide Web. 111–112.

[42] Elena Smirnova and Flavian Vasile. 2017. Contextual Sequence Modeling for
Recommendation with Recurrent Neural Networks. In Proceedings of the 2nd
Workshop on Deep Learning for Recommender Systems.

[43] Nitish Srivastava, Geoffrey E. Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan
Salakhutdinov. 2014. Dropout: a simple way to prevent neural networks from
overfitting. Journal of machine learning research 15, 1 (2014), 1929–1958.
[44] Harald Steck. 2015. Gaussian ranking by matrix factorization. In Proceedings of

the 9th ACM Conference on Recommender Systems. ACM, 115–122.

[45] Yong Kiam Tan, Xinxing Xu, and Yong Liu. 2016. Improved recurrent neural
networks for session-based recommendations. In Proceedings of the 1st Workshop
on Deep Learning for Recommender Systems. 17–22.

[46] Naftali Tishby, Fernando Pereira, and William Bialek. 2000. The information

bottleneck method. arXiv preprint physics/0004057 (2000).

[47] Aaron van den Oord, Sander Dieleman, and Benjamin Schrauwen. 2013. Deep
content-based music recommendation. In Advances in Neural Information Pro-
cessing Systems 26. 2643–2651.

[48] Hao Wang, Naiyan Wang, and Dit-Yan Yeung. 2015. Collaborative deep learning
for recommender systems. In Proceedings of the 21th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining. ACM, 1235–1244.

[49] Markus Weimer, Alexandros Karatzoglou, Quoc V Le, and Alex J Smola. 2008.
Cofi rank-maximum margin matrix factorization for collaborative ranking. In
Advances in neural information processing systems. 1593–1600.

[50] Jason Weston, Samy Bengio, and Nicolas Usunier. 2011. Wsabie: Scaling up to

large vocabulary image annotation. In IJCAI, Vol. 11. 2764–2770.

[51] Yao Wu, Christopher DuBois, Alice X. Zheng, and Martin Ester. 2016. Collabora-
tive denoising auto-encoders for top-n recommender systems. In Proceedings of
the Ninth ACM International Conference on Web Search and Data Mining. 153–162.
[52] Puyang Xu, Asela Gunawardana, and Sanjeev Khudanpur. 2011. Efficient subsam-
pling for training complex language models. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing. Association for Computational
Linguistics, 1128–1136.

[53] Shuang-Hong Yang, Bo Long, Alexander J. Smola, Hongyuan Zha, and Zhao-
hui Zheng. 2011. Collaborative competitive filtering: learning recommender
using context of user choice. In Proceedings of the 34th international ACM SIGIR
conference on Research and development in Information Retrieval. ACM, 295–304.
[54] Yin Zheng, Bangsheng Tang, Wenkui Ding, and Hanning Zhou. 2016. A Neural
Autoregressive Approach to Collaborative Filtering. In Proceedings of The 33rd
International Conference on Machine Learning. 764–773.

