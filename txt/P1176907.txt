Designing illuminant spectral power distributions for surface classiﬁcation

Henryk Blasinski, Joyce Farrell, Brian Wandell
Department of Electrical Engineering, Stanford University
Stanford, CA
hblasins,joyce_farrell,wandell@stanford.edu

Abstract

There are many scientiﬁc, medical and industrial imag-
ing applications where users have full control of the scene
illumination and color reproduction is not the primary ob-
jective. For example, it is possible to co-design sensors and
spectral illumination in order to classify and detect changes
in biological tissues, organic and inorganic materials, and
In this paper, we propose two
object surface properties.
different approaches to illuminant spectrum selection for
surface classiﬁcation. In the ﬁrst approach, a supervised
framework, we formulate a biconvex optimization problem
where we alternate between optimizing support vector clas-
siﬁer weights and optimal illuminants. In the second ap-
proach, an unsupervised dimensionality reduction, we de-
scribe and apply a new sparse Principal Component Anal-
ysis (PCA) algorithm. We efﬁciently solve the non-convex
PCA problem using a convex relaxation and Alternating Di-
rection Method of Multipliers (ADMM). We compare the
classiﬁcation accuracy of a monochrome imaging sensor
with optimized illuminants to the classiﬁcation accuracy of
conventional RGB cameras with natural broadband illumi-
nation.

1. Introduction

The spectral power distribution of the illumination
source plays a fundamental role in how objects objects are
imaged and analyzed by a digital camera [34]. In consumer
digital photography, the spectral properties of scene illumi-
nation are unknown at capture and the main challenge in
color balancing (white balancing) is estimating the spectral
power of the illuminant [35].

There are many applications where color reproduction
is not the primary goal of imaging systems, for example
laparoscopic surgery, endoscopy, microscopy or industrial
quality control [4, 17]. In these cases the spectrum of light
is a design parameter that can be optimized for tasks such
as detecting object features or classifying surfaces [7]. De-
pending on the application it may be more advantageous to

Convenional
illuminant

Discriminative
illuminant

Figure 1: The spectral power distribution of the illuminant
has a big impact on the data captured by an imaging system.
It can be difﬁcult for a machine learning algorithm to dis-
criminate between a real and fake apple based on the data
from an RGB camera and broadband illumination (left).
In contrast a camera capturing the scene with customized
lights produces better data for discrimination (right) even
though the light optimal for feature discrimination or clas-
siﬁcation may not produce accurate color matching effects.

adjust the spectral power distribution of the illuminant to
enhance the visibility of features of interest, at the expense
of accurate color rendering. Speciﬁcally, scene data cap-
tured under natural, broadband light sources and with con-
ventional RGB cameras can be less useful in classiﬁcation
problems than the data acquired with monochrome cameras
and highly customized, narrowband illuminants (Fig. 1).
The customized set of illuminants will produce a more ro-
bust set of features that can be later leveraged by machine
learning algorithms to improve classiﬁcation performance.
In this paper we describe and evaluate two novel algo-
rithms to effectively and systematically search for spectral
power distributions of optimal lights that improve material
classiﬁcation. The lights are optimized for a particular clas-
siﬁcation task, for example apple classiﬁcation. We formu-
late the problem of illuminant spectral power distribution
selection in two different frameworks: supervised and un-
supervised learning. Our methods are designed to explicitly

2164

estimate spectral power distributions, rather than to select
the best illuminant from a given set. The methods are also
constrained to produce solutions that are physically realiz-
able.

In the supervised context we assume that the reﬂectance
data is labeled and we formulate a penalty function incor-
porating the image formation model, classiﬁer parameters,
and the spectral power distribution of light. Such an objec-
tive function is bi-convex and locally optimal solutions can
be found via alternating minimization.

In the unsupervised context we approach optimal illumi-
nant spectral power distribution design from the dimension-
ality reduction perspective. Here the objective is to project
high dimensional reﬂectance data onto a smaller number
of dimensions that preserve the information necessary for
classiﬁcation. Optimized projection directions better cap-
ture the characteristics of the underlying data preserving
more variance in the projected data set. Larger variance
in the data set generally translates to better performance of
the classiﬁcation algorithms. The classical algorithm for
dimensionality reduction is Principal Component Analysis
(PCA). This algorithm computes a set of orthogonal projec-
tion directions along which the variance in the data set is
the largest [12].

The space of physically realizable spectral power distri-
butions of light is limited by certain physical constraints.
First, light cannot be negative. Second, the shapes of the
spectrum cannot be arbitrary, typically these are smooth
functions. All these restrictions need to be taken into con-
sideration when searching for the optimal illuminant.

In summary, our contributions include:

• Two new algorithms optimizing the spectral power dis-
tributions of illuminants for classiﬁcation tasks and
producing distributions that can be generated with real
light sources.

• A new sparse nonnegative PCA algorithm with a single

tuning parameter.

• A framework for analyzing imaging system classiﬁca-
tion performance using different number and spectra
of optimized illuminants.

2. Related work

There exist few methods that solve the problem dis-
cussed in this paper. The most relevant algorithm is that
of Liu and Guo [21], who used cost function minimization
to select the color, position and intensity of LEDs in their
capture device that enhance material classiﬁcation accuracy.
Unlike the methods we describe, the authors do not analyze
the data in the wavelength domain and do not restrict their
solution to non-negative intensities.

Many other approaches involve brute force selection
strategies using exhaustive search over the entire parame-

ter space [26]. This is tractable for small problems, but the
complexity grows exponentially and thus makes the method
computationally impractical. One way to reduce the solu-
tion space of brute-force methods is to use genetic algo-
rithms [6]. The methods we present involve continuous
valued function minimization rather than search strategies
making them more computationally tractable.

Optimal light spectral power distribution selection shares
many similarities with camera responsivity design. Cam-
era responsivities, however, are most frequently optimized
for color matching tasks [14, 28, 30, 31], low light perfor-
mance [8, 19] or spectral reconstruction [25, 27]. The idea
of adapting camera spectral characteristics to the particular
properties of the imaged scene was presented in [20] where
the authors manually changed the characteristics of a liquid
crystal tunable ﬁlter (LCTF) as a function of the distribution
of scene radiance. In a similar effort [10] describe an adap-
tive spectroscopy algorithm which takes repeated measure-
ments of the scene and adjusts the sensitivity of the spec-
trometer as a function of prior observations. This approach
conditions the shape of optimal responsivity curves on the
results of earlier measurements and thus cannot be used to
derive a ﬁxed set of spectral curves independent of speciﬁc
measurement outcomes.

Dimensionality reduction techniques designed for hyper-
spectral data have been developed in the remote sensing
community [5, 16, 18]. In these applications the weights are
not constrained and are allowed to be negative and therefore
wavelength distributions of those weights do not represent
physically realizable light spectra.

The existing sparse PCA [1, 15, 24] or nonnegative
sparse PCA [32, 36] algorithms cannot be directly used to
design physically realizable illuminants. These methods do
not allow nonnegativity constraints on linearly transformed
variables, which is necessary to assure physical realizabil-
ity of optimized illuminant spectra. Some of the methods
are also impractical due to large numbers of tuning parame-
ters that need to be adjusted. We overcome these limitations
by proposing a new, ﬂexible nonnegative sparse PCA algo-
rithm with a single tuning parameter.

3. Image formation model

The response of a camera’s photodetector mj,k is a linear
function of the scene illuminant xk, surface reﬂectance r
and the spectral responsivity of the jth camera color channel
cj [34]

mj,k =

cj(λ)r(λ)xk(λ)dλ.

(1)

Z

For most natural images, the spectral curves are smooth
and slowly varying, therefore a discretization to n spectral
bands simpliﬁes modeling with little impact on the accuracy

mj,k = ∆λcT

j diag(r)xk = eT

j xk

(2)

2165

where ej = ∆λ(r1cj,1, r2cj,2, . . . .rncj,n), ej ∈ Rn is the
wavelength-wise product between the surface spectral re-
ﬂectance and the camera responsivity function of the jth
channel. In this work, we propose a method to choose the
vector xk, given a set of labeled or unlabeled vectors ej so
that those vectors projected onto a subspace spanned by xk,
k ∈ 1, . . . , K preserve the discriminative information from
e in m. A classiﬁcation algorithm then uses the projected
data m, i.e. pixel intensities, to derive decision boundaries
in this low dimensional subspace.

Spectral curves are often approximated using linear

models

x = Bw,

(3)

where the columns of B ∈ Rn×nb represent model compo-
nents and w ∈ Rnb are the corresponding weights. Model
components can be derived using two different approaches.
The ﬁrst approach takes advantage of the fact that spectrally
smooth curves lie on a low dimensional subspace [23]. The
span of this subspace is described by the columns of B,
which, by deﬁnition, form an orthogonal set, i.e. BT B = I.
This modeling usually aims to simplify the problem by re-
ducing the number of variables used to describe a light spec-
trum.

The second approach is to make columns of B directly
represent a collection of spectral power distributions of all
light sources the user controls. For example B can be cre-
ated from spectral power distributions of all LEDs on offer
by a manufacturer. The task now becomes selection of these
spectra that are optimal. In such cases B forms a dictionary
and often becomes ‘fat‘, i.e. contains more columns than
rows. This means that some of the dictionary entries are
linear combinations of each other, and BT B is no longer
full rank.

We assume that a physically realizable illuminant is non-
negative and that is spanned by the columns of B. Our ap-
proach to ﬁnding the optimal light does not rely on partic-
ular properties of B, speciﬁcally B can be ‘fat‘ and BT B
non-invertible.

We also note that if one could use a large number of il-
luminants (K ≥ n) the optimal strategy would be to pick
monochromatic lights. In this case, acquisition of K images
would correspond to capturing the full spectral characteris-
tic of the surface, as if imaged with a hyperspectral camera.
This means that in general, preferred solutions should have
little overlap across spectral channels, and many zero en-
tries.

4. Supervised framework

Many classical supervised learning algorithms attempt
to ﬁnd a set of hyperplanes that deﬁne boundaries between
points in the feature space representing different classes.

For example, to classify a set of vectors e with labels y, the
parameters describing separating hyperplanes θ are found
by minimizing a cost function f subject to constraints g on
those parameters

minimize f (θ; e, y)
subject to g(θ; e, y) ≤ 0.

(4)

(5)

Often the input data e are not guaranteed to be linearly sep-
arable in the original n dimensional space. The data may
be projected, using operator Φ(e), to a higher dimensional
space in which such linear separability can be achieved

minimize f (θΦ; Φ(e), y)
subject to g(θΦ, Φ(e), y) ≤ 0.

We note that in the context of optimal illumination design
the projection operator Φ naturally arises in the formula-
tion of the image formation model, though it projects data
to a subspace with fewer dimensions. Observe that the mea-
sured pixel intensities satisfy m = X T e = Φ(e), where the
columns of X = [x1, . . . , xK] represent the spectral power
distributions of K illuminants, and e are deﬁned as in (2).
The problem is to ﬁnd such linear projection directions X
that facilitate class separability in the Φ(e) vector space, i.e.
camera pixel measurement space.

To illustrate the approach, consider a classiﬁer where f
and g correspond to a multiclass, one-vs-all, Support Vector
Classiﬁer (SVC) [13]. The linear decision boundaries pt for
each of the t classes are given by a solution to the convex
optimization problem

minimize

kptk2

2 + C

ξt
i

Xt
Xi,t6=yi
yi Φ(ei) + byi ≥ pT
subject to pT
ξt
i ≥ 0,

i = 1, . . . , L,

t Φ(ei) + bt + 2 − ξt
i

t ∈ {1, . . . , T } \ yi,

(6)

where {yi, ei} represent
the label and the reﬂectance-
camera responsivity product of the ith data point respec-
tively with the size of the training set given by L. The scalar
C controls how many data points are allowed to be misclas-
siﬁed during training.

In order to ﬁnd the optimal illuminant spectral power dis-
tributions we re-formulate the SVC problem by replacing
the projection Φ(ei) = (BW )T ei and adding constraints
on the illuminant power distributions BW assuring physical
realizability. The resulting biconvex optimization problem

minimize

kpkk2

2 + C

ξk
i + αz(BW )

(7)

Xi,k6=yi

Xk
yi (BW )T ei + byi ≥ pT
subject to pT
ξk
i = 1, . . . , L,
i ≥ 0,
BW ≥ 0,

k (BW )T ei + bk + 2 − ξk
i
k ∈ {1, . . . , K} \ yi,

2166

can be solved through alternating minimization over p, b, ξ
and b, ξ, W . The matrix W describes the illuminant spec-
tra in terms of the linear basis weights (3). Note that the
cost function has been augmented with a function z, con-
trolled with a tuning parameter α, penalizing certain types
of solutions. We promote sparsity with an l1 penalty

z(X) = kXk1 =

|xi,j|

(8)

Xi,j

where the l1 norm is generalized to matrices and computes
the sum of the absolute values of all matrix entries.

5. Unsupervised framework

Principal Component Analysis (PCA) is a standard tech-
nique used in machine learning to compactly represent a
data set. The PCA algorithm ﬁnds a set of projection vec-
tors along which the original data has the largest variance.
These projections are given by the principal eigenvectors
of the data set covariance matrix. In the context of illumi-
nant spectrum selection, we note that the measured pixel
intensity represents the projection of the reﬂectance-camera
responsivity product onto a vector describing the spectral
distribution of the illuminant.

For convenience, we express PCA as an iterative algo-
rithm. Let Σ ∈ Sn
+ represent the positive semi-deﬁnite sam-
ple covariance matrix of vectors e from (2). The ith optimal
PCA direction is a solution to the problem

where Σ(i−1) is the covariance matrix estimate from the
previous step. Before proceeding to the next iteration Σ
needs to be recomputed to account for the removal of the
solution dimension (i.e. deﬂated).

The iterative PCA algorithm can be modiﬁed to produce
nonnegative and sparse directions by introducing additional
constraints into the optimization problem (9)

i.e. relaxation. For example, using the PCA relaxations de-
scribed in [9, 33], the original nonconvex problem can be
approximated with

maximize
subject to

tr(ΣX) − αkXk1
0 (cid:22) X (cid:22) I,
tr(X) = 1
X ≥ 0

(11)

(we drop the superscript (i − 1) for clarity). The function
tr(X) is the trace operator, i.e. the sum of the entries of
X along the diagonal, and α controls the sparsity enforcing
penalty.

The ﬁrst constraint forces X to be positive, semi-deﬁnite
and X − I to be negative, semi-deﬁnite. The last constraint
restricts the solution to a set of matrices with nonnegative
entries. The optimal projection direction is given by the
principal eigenvector of a solution X ⋆ = x⋆x⋆T . Note that
the matrix entry-wise inequality enforces all the entries of
x⋆ to have the same sign, therefore if x⋆ is a solution so is
−x⋆.

In order to express the PCA problem in terms of the basis
weights, X = xxT = Bw(Bw)T = BW BT is substituted
into (11) yielding

maximize
subject to

tr(ΣBW BT ) − αkBW BT k1
0 (cid:22) BW BT (cid:22) I,
tr(BW BT ) = 1
BW BT ≥ 0,

(12)

The above optimization problem can be efﬁciently
solved using the Alternating Direction Method of Multi-
pliers (ADMM) [3, 33]. The computational steps of this
approach are summarized in Algorithm 1, derivation details
are available in the Supplemental Material. This algorithm
requires the user to provide the desired accuracy ǫ and a
learning rate ρ. Following the recommendation of [33] we
used an update heuristic proposed in [3]. It may happen that
the function computing the largest eigenvector of Y (t+1)
will return a vector with all nonpositive entries. In this case
the sign of such a solution should be reversed.

1

maximize xT Σ(i−1)x
subject to xT x = 1

card(x) ≤ δ
x ≥ 0,

(10)

5.2. Matrix deﬂation

where δ is a sparsity parameter and card(x) speciﬁes the
number of nonzero entries in x. Equation (10) is nonconvex
due to the incorporation of sparsity and nonnegativity con-
straints. Hence, eigen decomposition is no longer a valid
method for ﬁnding a solution.

5.1. Convex relaxation

A useful approach to solving nonconvex problems is to
perform an approximation with a similar convex problem

The iterative approach to PCA makes it necessary to de-
ﬂate the current sample covariance matrix estimate Σ(i−1)
before proceeding to the next iteration. The commonly used
Hotelling’s deﬂation scheme may not preserve the semideﬁ-
niteness of Σ(i) if the projection direction xi is not an eigen-
vector of Σ(i−1) [29]. To avoid such issues we used a gen-
eralized deﬂation algorithm proposed in [22]. Algorithm 2
summarizes this deﬂation method and outlines the steps re-
quired to compute r sparse nonnegative PCA directions for
a particular data set.

maximize xT Σ(i−1)x
subject to xT x = 1,

(9)

where W = wwT .

2167

Algorithm 1 Single nonnegative sparse PCA direction.

function FINDDIRECTION(Σ,B, α, ǫ, ρ)
2 ← 0, U (0)

1 ← 0, Y (0)

Y (0)
1 ← 0, U (0)
repeat

2 ← 0

kBW BT − Y (t)

W (t+1) ← arg min
Y (t+1)
1
U (t+1)
1 ← U (t)
t ← t + 1

(cid:16)
← PF (BW (t+1)BT + U (t)
1 + W (t+1) − Y (t+1)

1

,

1 + U (t)
1 + Σ/ρ),

1 k2

F + kBW BT − Y (t)

2 + U (t)

2 k2
F

(cid:17)

Y (t+1)
2
U (t+1)
2 ← U (t)

← Hα/ρ(BW (t+1)BT + U (t)
2 )

2 + BW (t+1)BT − Y (t+1)

2

until max{kBW (t+1)BT − Y (t+1)

F , ρ2kY (t+1)
k2
corresponding to the largest eigenvalue.

F , kBW (t+1)BT − Y (t+1)
k2

1

1

2

return Eigenvector of Y (t+1)
end function

1

− Y (t)

1 k2

F }, ρ2kY (t+1)

2

− Y (t)

2 k2

F } ≤ ǫ

Algorithm 2 Nonnegative sparse PCA
Require: Σ ∈ Sn

+, α ≥ 0, ǫ ≥ 0, ρ ≥ 0, r ∈ N, B

Q(0) ← I, Σ(0) ← Σ
for t = 1, . . . , r do

xt ← FINDDIRECTION(Σ(t−1),B, α, ǫ, ρ)
qt ← Q(t−1)xt
t )Σ(t−1)(I − qtqT
Σ(t) ← (I − qtqT
t )
Q(t) ← Q(t−1)(I − qtqT
t )
xt ← xt/kxtk

1.4

1.2

1

0.8

0.6

0.4

0.2

0
400

end for
return x1, . . . , xr

6. Experiments

To evaluate the proposed approaches we conducted a set
of experiments where we captured images of known test tar-
gets under different illumination conditions and used stan-
dard machine learning algorithms to classify captured data.
We implemented all computations in Matlab, and our code
repository is available online1.

First, we measured the performance of classiﬁcation al-
gorithms on data captured with conventional RGB cameras
and under a single broadband illuminant. This condition
represents the typical imaging scenario where a color cam-
era with three types of color pixels is used to capture a single
image in natural lighting conditions (i.e. J = 3, K = 1).
Overall, we evaluate the performance of 34 cameras with
different spectral properties (see Supplemental Material for
the list of evaluated camera models). For simplicity we will
refer to this mode of data capture as conventional camera.
Next, we captured the data using a monochrome cam-
era and optimized illuminants.
To make comparisons
between conventional and optimized systems meaning-
ful we projected spectral measurements onto a three-
dimensional space. To obtain this representation with our
optimized setup we captured three successive frames with a

Captured

500

600
Wavelength, nm

Emulated

700

800

Figure 2: A comparison between spectral properties of a
GoPro Hero 5 RGB camera (solid lines) and their approxi-
mation with narrowband lights (dashed lines). For a given
scene, pixel values produced by an RGB camera (inset, cap-
tured) can be reproduced with a mochorome camera and ap-
propriately adjusted narrowband lights that match the spec-
tral responsivities of the camera (inset, emulated).

monochrome camera, each under different, optimized light
(i.e. J = 1, K = 3) derived with either supervised or unsu-
pervised approach. We refer to this capture mode as optimal
camera.

We investigated a simple classiﬁcation task; assigning
labels to image pixels based on raw image data. We origi-
nally designed these algorithms for use with biological mul-
tispectral data, however for presentation clarity we chose
much simpler targets requiring no domain speciﬁc knowl-
edge.
In our tests we used genuine and visually similar
artiﬁcial fruit pairs: apples, pears and lemons. Our goal
was to discriminate between different objects. For this pur-
pose we constructed three test scenes. Two of them con-
tained two pairs of differently colored fruit of the same type;
red and green apples (Apples) and yellow and green pears
(Pears). The Lemons scene contained a single pair of ob-
jects; lemons.

Scenes were assembled in a Thouslite LEDCube2 light
booth. The LEDCube contained three broadband and eight
narrowband LEDs whose intensities could be independently

1https://github.com/hblasins/optIll

2http://www.thouslite.com/show.asp?id=16

2168

s
r
a
e
P

s
e
l
p
p
A

s
n
o
m
e
L

500

600
Wavelength, nm

700

800

500

600
Wavelength, nm

700

800

500

600
Wavelength, nm

700

800

500

600
Wavelength, nm

700

800

1

0.8

0.6

0.4

0.2

0.8

0.6

0.4

0.2

0.8

0.6

0.4

0.2

0
400

1

0
400

1

0
400

(a) RGB Image

(b) RGB
classiﬁcation

(c) Unsupervised
classiﬁcation

(d) Unsupervised
spectra

(e) Supervised
classiﬁcation

500

600
Wavelength, nm

700

800

500

600
Wavelength, nm

700

800

(f) Supervised
spectra

Figure 3: Pixel classiﬁcation accuracy is increased when the scene is illuminated with optimal lights. Columns present the
RGB rendering of the scene (a), pixel classiﬁcation maps for conventional illumination (b), and optimal lights derived with
unsupervised (c) and supervised (e) approaches. Color in (b, c, e) encodes pixels where the SVM classiﬁer assigned correct
labels, all errors are not represented. The spectral power distributions of the optimal illuminants (d, f, thick lines) overlap
with areas of increased variability in the surface spectral reﬂectance (d, f, thin lines).

adjusted thus changing the overall spectrum of the illumi-
nant. The spectral power distributions of the individual
LEDs formed columns in the model matrix B (3).

We measured the surface spectral reﬂectance of all tar-
gets as well as spectral power distributions of the LEDs in
the 400 to 800nm range at 4nm increments using a Spec-
traScan PR715 spectrophotometer. We calibrated the LED-
Cube LED spectra by taking measurements of the light ra-
diance reﬂected from a reference white, Spectralon test tar-
get. Similarly, we estimated the surface spectral reﬂectance
by illuminating the surface of fruits with broadband tung-
sten light, taking 10 radiance measurements followed by
one measurement of a Spectralon sample, and by computing
the ratio between the two at every wavelength [2].

Given a set of reﬂectance curves we used the supervised
and unsupervised approaches to generate optimal illumi-
nants for a particular setting of algorithm tuning parameters.
We then programmed those spectra into the LEDCube and
captured images of the so illuminated target with a Point-
Grey FL3-U3-13Y3M-C, 1.3MP monochrome camera with
a Schneider Optics Xenoplan 1.4/23mm lens. The aperture
was set to f#/11 in order to limit depth of ﬁeld effects.

Next, we manually segmented 100 × 100 (200 × 200 for
binary classiﬁcation) pixel regions of interest (ROI) within
each fruit sample and used this set for classiﬁcation. The
classiﬁers used single pixel intensity data. The data was

split into training (70%) and test (30%) sets using the strati-
ﬁed approach, i.e. preserving the distribution of class labels
[11]. For fairness of comparisons we preserve data separa-
tion across all classiﬁers and conditions. In our evaluations
we used ﬁve standard machine learning classiﬁers: Sup-
port Vector Machines (SVM), K-Nearest Neighbors (KNN),
Linear Discriminant Analysis (DA), Decision Trees (Tree)
and Naive Bayes (NB).

Finally, we repeated the procedure; optimal illuminant
computation followed by image capture and classiﬁer cross
validation, for different settings of illuminant selection al-
gorithms tuning parameters (refer to source code for de-
tails). In all cases training data set was used for training
and parameter selection only, and all performance numbers
we report were calculated using the test set.

Rather than using physical RGB cameras in our evalu-
ations, we instead emulated their spectral properties with
narrowband LEDs from LEDCube and the PointGrey
monochrome camera. We approximated the effective spec-
tral responsivity (i.e. the wavelength-wise product between
spectral responsivity and the illuminant) of red, green and
blue camera channels with an appropriate weighted sum of
the LEDCube LEDs, accounting for the monochrome sen-
sor quantum efﬁciency (see Supplemental Material for de-
tails). Figure 2 shows an example comparison between the
actual responsivity curves and their approximations using

1

0.8

0.6

0.4

0.2

0.8

0.6

0.4

0.2

0.8

0.6

0.4

0.2

0
400

1

0
400

1

0
400

2169

Table 1: Single pixel per cent classiﬁcation accuracy for the
Pears data (four-way classiﬁcation).

Table 2: Single pixel per cent classiﬁcation accuracy for the
Apples data (four-way classiﬁcation).

Camera

RGB (worst)
RGB (avg.)
RGB (best)
Ours (Unsup.)
Ours (Sup.)

Classiﬁer

SVM KNN
92.7
92.3
95.2
94.6
98.4
98.4
97.9
97.2
99.9
99.9

DA
91.2
93.6
97.9
96.9
98.9

Tree
90.7
94.1
97.8
97.8
99.8

NB
66.0
67.8
74.2
82.8
76.6

Camera

RGB (worst)
RGB (avg.)
RGB (best)
Ours (Unsup.)
Ours (Sup.)

Classiﬁer

SVM KNN
78.4
75.2
82.3
84.6
83.3
85.6
89.4
87.1
92.6
91.5

DA
74.9
84.1
85.3
86.4
91.2

Tree
73.6
84.2
85.8
89.2
91.2

NB
66.0
68.7
72.7
83.7
79.5

LEDs. Insets in this ﬁgure present an image of a Macbeth
chart captured with a conventional RGB camera and com-
pares it to a view of the same chart rendered with the data
from the proposed emulation approach.

There are several advantages to using the emulation ap-
proach. First, the geometry of the setup remains ﬁxed
and any differences between various test conditions arise
only from illumination rather than image alignment or re-
sampling between different cameras. Second, the same sen-
sor is used throughout all experiments and so the noise
properties remain ﬁxed. Finally, the resolution and optics
remain constant throughout all experiments.

6.1. Classiﬁcation performance

Figure 3 presents the results of pixel classiﬁcation out-
comes for three test scenes captured under daylight and op-
timized illuminants. Classiﬁcation maps were created by
applying classiﬁers trained on the training data to all pixels
in the image. For clarity we show and label only correctly
identiﬁed pixels.
In general, maps obtained for the opti-
mized illumination cases correctly classify larger number
of pixels. We also observed that those maps have more con-
tiguous object segmentation and less ’salt and pepper’ clas-
siﬁcation noise. However, the optimal illuminant selection
strategies do not always increase the number of correctly
classiﬁed pixels. They can also make some pixels easier to
classify at the expense of others. Take the Apple scene as
an example. Under optimized illuminants the increased ac-
curacy in recognizing the bottom right apple (green label)
is offset by erroneously classifying parts of the bottom left
apple (purple label) that had been correctly classiﬁed by a
conventional camera.

We also present the optimal illuminant spectra derived
for each condition (Fig. 3d and 3f). The curves derived
by supervised and unsupervised approaches differ, but they
share a common characteristic.
In all cases light energy
is concentrated at wavelengths with signiﬁcant amount of
variability in the surface reﬂectance data.
The quantitative performance of

the proposed ap-
proaches is presented in Tables 1, 2 and 3 which summarize
the pixel based classiﬁcation accuracy achieved with the op-

Table 3: Single pixel per cent classiﬁcation accuracy for the
Lemons data (binary classiﬁcation).

Camera

RGB (worst)
RGB (avg.)
RGB (best)
Ours (Unsup.)
Ours (Sup.)

SVM
92.2
97.5
99.9
99.8
100.0

Classiﬁer

KNN
96.4
99.0
100.0
99.8
100.0

DA
90.0
96.3
99.8
99.6
99.9

Tree
85.9
96.6
99.9
98.3
98.8

NB
58.8
62.0
75.6
63.1
70.9

timal and conventional cameras. For every classiﬁcation al-
gorithm, we report the average accuracy computed over 34
RGB cameras as well as the accuracy of the best and worst
performing model for a particular algorithm. The model
of the camera achieving the highest classiﬁcation accuracy
varied across different scenes and classiﬁers. This metric
represents the performance of illuminant spectral power dis-
tributions found using a brute force search algorithm and
serves as a baseline for comparisons with our methods.

We experimented with illuminating our scenes with the
emission spectra of black body radiators at different tem-
peratures; 2000, 4000, 6500, and 10000K. These spectra of-
fer good approximations to light distributions occurring in
natural environments. For a particular classiﬁcation algo-
rithm, performance differences between these illuminants
were minor (see Supplemental Material for details). The
black body emission at 6500K closely resembles the stan-
dard D65 illuminant (daylight), and in general provided
the best, or close second best classiﬁcation accuracy. Fur-
thermore, many conventional RGB cameras are designed
to faithfully reproduce colors speciﬁcally under this illumi-
nant. For these reasons we use this condition as reference
in numerical comparisons.

The imaging system using illuminant spectral power dis-
tributions derived with our supervised method consistently
outperforms conventional RGB cameras and broadband il-
luminants for the SVM, KNN, DA and Tree classiﬁcation
algorithms. It comes second only when the Tree classiﬁer
is applied to the Lemons scene. These gains are due to direct

2170

incorporation of the search for optimal spectra into the clas-
siﬁcation objective function, and are achieved despite non-
convexity of the problem and local optimality of the solu-
tion. Interestingly, the supervised selection method is typ-
ically outperformed by a combination of the Naive Bayes
classiﬁer with the unsupervised approach.

Our unsupervised selection method is better than the av-
erage conventional RGB camera, and its accuracy is typi-
cally on par with that of the best RGB camera. Note that this
selection strategy works best together with a Naive Bayes
classiﬁer. The unsupervised approach is a variant of PCA,
which provides a set of uncorrelated features. In our case
we use a constrained version; it also decorrelates data, but
to a lesser extent. The Naive Bayes classiﬁer implicitly as-
sumes feature conditional independence, which means that
the unsupervised approach provides the type of data the
classiﬁer expects.

6.2. Number of illuminants

We investigated the relationship between classiﬁcation
accuracy and the number of different illuminants under
which a scene is captured. Optimization over the illumi-
nant spectrum offers another system design parameter. For
example, a suitable illuminant could eliminate the need for
a color ﬁlter array thus increasing the effective sensor reso-
lution.

Increasing the number of optimal illuminants from 1 to
10 increases the classiﬁcation performance, irrespective of
the selection method used. Figure 4 presents the classiﬁ-
cation accuracy in the Apples set as a function of the num-
ber of optimal illuminants. The supervised selection algo-
rithm maintains a small advantage over the unsupervised
approach across all conditions. The classiﬁcation accuracy
asymptotes at about 95%, ten percentage points above the
accuracy of the best conventional RGB camera. However,
at about 3–4 illuminants the curves plateau; using more il-
luminants offers modest gains in performance that may not
be worth pursuing given other limitations such as acquisi-
tion time. Note that the classiﬁcation accuracy of an opti-
mal two-illuminant system, i.e. representing pixel data with
two numbers, is comparable to that of the best conventional
RGB camera and a broadband illuminant, which represent
pixel data with three numbers. Both systems achieve about
86% classiﬁcation accuracy. This reduction in data dimen-
sionality can translate to smaller data storage requirements
or fewer processor cycles necessary for computation.

100

95

90

85

80

75

70

%

 
,
y
c
a
r
u
c
c
a
 
n
o
i
t
a
c
i
f
i
s
s
a
C

l

Best RGB camera

Unsupervised
Supervised

1

2

3

4

5

6

7

8

9

10

Number of illuminants

Figure 4: Pixel classiﬁcation accuracy increases when a
scene (Apples) is captured under more optimized illumi-
nants, with supervised selection outperforming the unsu-
pervised algorithm. Using just two optimally chosen lights
allows to achieve the performance level of a conventional,
three channel RGB system.

produce physically realizable distributions that can be gen-
erated using off-the-shelf LEDs.

We evaluated the optimal lights produced by our selec-
tion methods in a simple surface classiﬁcation task through
a series of laboratory experiments using real targets, illumi-
nants, and cameras. In all cases classiﬁer performance on
pixel data obtained under optimized lights is greater than the
performance of the same algorithm on data captured with a
conventional RGB camera and broadband illuminants. We
showed that the supervised selection method achieves the
best performance, but it requires a set of labeled training re-
ﬂectance spectra. In comparison the unsupervised method
is a close second in terms of accuracy, but can work with
unlabeled object spectral reﬂectance curves.

Both algorithms are useful in analyzing the impact of
additional imaging channels on classiﬁcation performance.
This is an important consideration because, we have shown,
under the constraints of physical realizability having more
channels may provide only modest performance gains that
may be deemed not worth pursuing given the increased sys-
tem complexity and other design trade-offs such as speed,
resolution or computation.

Finally, the methodology we present in this work can be
extended to other spectral selection problems in imaging
system design. For example, the same algorithms can be
applied to selecting the responsivity functions of the color
ﬁlter array or could be used to select transmissive ﬁlters for
biological image analysis.

7. Conclusions

Acknowledgements

We presented two new approaches to selecting spectral
power distributions of illuminants used during the image
capture process that increase the accuracy of pixel classi-
ﬁcation algorithms applied to captured data. Our methods

The authors would like to thank Gordon Wetzstein from
Stanford University for helpful comments and discussions
during the preparation of the manuscript. The LEDCube
image booth was a gift from Thouslite.

2171

References

[1] A. Amini and M. Wainwright. High-dimensional analysis of
semideﬁnite relaxations for sparse principal components. In
IEEE International Symposium on Information Theory ISIT,
pages 2454–2458, 2008. 2

[2] H. Blasinski, J. Caves, J. Farrell, B. Wandelt, and P. Wang.
Multispectral imaging of tissue ablation. In IEEE Interna-
tional Symposium on Biomedical Imaging, ISBI, pages 360–
363, April 2016. 6

[3] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein. Dis-
tributed optimization and statistical learning via the alternat-
ing direction method of multipliers. Foundations and Trends
in Machine Learning, 3(1):1–122, 2011. 4

[4] J. Cadeddu, R. Fernandez, M. Desai, R. Bergs, C. Tracy, S.-
J. Tang, P. Rao, M. Desai, and D. Scott. Novel magneti-
cally guided intra-abdominal camera to facilitate laparoen-
doscopic single-site surgery: initial human experience. Sur-
gical endoscopy, 23(8):1894–1899, 2009. 1

[5] C. Chang, Q. Du, T. Sun, and M. Althouse. A joint band pri-
oritization and band decorrelation approach to band selection
IEEE Transactions
for hyperspectral image classiﬁcation.
on Geoscience and Remote Sensing, 37(6):2631–2641, Nov
1999. 2

[6] C. Chi, H. Yoo, and M. Ben-Ezra. Multispectral imaging by
optimized wide band illumination. International Journal of
Computer Vision, 86(2–3):140–151, 2010. 2

[7] J. Choi, S. Park, J. Cho, and E. Yoon. A 3.4-µ w object-
adaptive CMOS image sensor with embedded feature extrac-
tion algorithm for motion-triggered object-of-interest imag-
IEEE Journal of Solid-State Circuits, 49(1):289–300,
ing.
Jan 2014. 1

[8] L. Condat. A new color ﬁlter array with optimal properties
for noiseless and noisy color image acquisition. IEEE Trans-
actions on Image Processing, 20(8):2200–2210, Aug 2011.
2

[9] A. d’Aspremont, L. El Ghaoui, M. Jordan, and G. Lanck-
riet. A direct formulation for sparse PCA using semideﬁnite
In Neural Information Processing Systems,
programming.
volume 16, pages 41–48, 2004. 4

[10] D. Dinakarababu, D. Golish, and M. Gehm. Adaptive fea-
ture speciﬁc spectroscopy for rapid chemical identiﬁcation.
Optics express, 19(5):4595–4610, 2011. 2

[11] G. Forman and M. Scholz. Apples-to-apples in cross-
validation studies: pitfalls in classiﬁer performance measure-
ment. ACM SIGKDD Explorations Newsletter, 12(1):49–57,
2010. 6

[12] T. Hastie, R. Tibshirani, and J. Friedman. The elements of

statistical learning. Springer, 2009. 2

[13] C.-W. Hsu and C.-J. Lin. A comparison of methods for multi-
class support vector machines. IEEE Transactions on Neural
Networks, 13(2):415–425, 2002. 3

[14] F. Imai, S. Quan, M. Rosen, and R. Berns. Digital camera
ﬁlter design for colorimetric and spectral accuracy. In Pro-
ceedings of the 3rd International Conference on Multispec-
tral Color Science, pages 23–26, 2001. 2

[15] M. Journee, Y. Nesterov, P. Richtarik, and R. Sepulchre.
Generalized power method for sparse principal component

analysis.
11:517–553, 2010. 2

The Journal of Machine Learning Research,

[16] N. Keshava. Distance metrics and band selection in hyper-
spectral processing with applications to material identiﬁca-
tion and spectral libraries. IEEE Transactions on Geoscience
and Remote Sensing, 42(7):1552–1565, July 2004. 2
[17] S. Kukkonen, H. Kalviainen, and J. Parkkinen. Color fea-
tures for quality control in ceramic tile industry. Optical En-
gineering, 40(2):170–177, 2001. 1

[18] S. Kumar, J. Ghosh, and M. Crawford. Best-bases fea-
ture extraction algorithms for classiﬁcation of hyperspectral
data. IEEE Transactions on Geoscience and Remote Sensing,
39(7):1368–1379, Jul 2001. 2

[19] H. Kuniba and R. S. Berns. Spectral sensitivity optimization
of color image sensors considering photon shot noise. Jour-
nal of Electronic Imaging, 18(2):023002–023002–14, 2009.
2

[20] A. Lin and F. Imai. Efﬁcient spectral imaging based on imag-
ing systems with scene adaptation using tunable color pixels.
In Color and Imaging Conference, volume 2011, pages 332–
338. Society for Imaging Science and Technology, 2011. 2

[21] C. Liu and J. Gu. Discriminative illumination: Per-pixel clas-
siﬁcation of raw materials based on optimal projections of
IEEE Transactions on Pattern Analysis and
spectral brdf.
Machine Intelligence, 36(1):86–98, 2014. 2

[22] L. Mackey. Deﬂation methods for sparse PCA. In Neural
Information Processing Systems, volume 21, pages 1017–
1024, 2008. 4

[23] L. T. Maloney and B. A. Wandell. Color constancy: a method
for recovering surface spectral reﬂectance. Journal of the
Optical Society of America A, 3(1):29–33, 1986. 3

[24] B. Moghaddam, Y. Weiss, and S. Avidan. Generalized spec-
tral bounds for sparse LDA. In Proceedings of the 23rd in-
ternational conference on Machine learning, pages 641–648.
ACM, 2006. 2

[25] Y. Monno, T. Kitao, M. Tanaka, and M. Okutomi. Optimal
spectral sensitivity functions for a single-camera one-shot
multispectral imaging system. In IEEE International Con-
ference on Image Processing, ICIP, pages 2137–2140, 2012.
2

[26] J. Park, M. Lee, M. D. G., and S. Nayar. Multispectral imag-
In IEEE International
ing using multiplexed illumination.
Conference on Computer Vision, ICCV, pages 1–8, Oct 2007.
2

[27] M. Parmar, S. Lansel, and J. Farrell. An LED-based lighting
In Proc. SPIE,

system for acquiring multispectral scenes.
volume 8299, pages 82990P–82990P–8, 2012. 2

[28] M. Parmar and S. Reeves. Selection of optimal spectral sen-
sitivity functions for color ﬁlter arrays. IEEE Transactions
on Image Processing, 19(12):3190–3203, Dec 2010. 2
[29] Y. Saad. Projection and deﬂation method for partial pole
assignment in linear state feedback. IEEE Transactions on
Automatic Control, 33(3):290–297, 1988. 4

[30] Z. Sadeghipoor, Y. Lu, and S. Susstrunk. Optimum spectral
sensitivity functions for single sensor color imaging. In Proc.
SPIE, volume 8299, pages 829904–829904–14, 2012. 2

2172

[31] H.-L. Shen, H.-G. Zhang, J. Xin, and S.-J. Shao. Optimal se-
lection of representative colors for spectral reﬂectance recon-
struction in a multispectral imaging system. Applied Optics,
47(13):2494–2502, May 2008. 2

[32] C. Sigg and J. Buhmann. Expectation-maximization for
In Proceedings of the 25th
sparse and non-negative PCA.
International Conference on Machine Learning, pages 960–
967, 2008. 2

[33] V. Vu, J. Cho, J. Lei, and K. Rohe. Fantope projection and se-
lection: A near-optimal convex relaxation of sparse PCA. In
Advances in Neural Information Processing Systems, pages
2670–2678, 2013. 4

[34] B. Wandell. Foundations of Vision. Sinauer Associates,

1995. 1, 2

[35] F. Xiao, J. E. Farrell, J. M. DiCarlo, and B. A. Wandell. Pre-
ferred color spaces for white balancing. In Electronic Imag-
ing 2003, pages 342–350. International Society for Optics
and Photonics, 2003. 1

[36] R. Zass and A. Shashua. Nonnegative sparse PCA. Advances
in Neural Information Processing Systems, 19:1561, 2007. 2

2173

Designing illuminant spectral power distributions for surface classiﬁcation

Henryk Blasinski, Joyce Farrell, Brian Wandell
Department of Electrical Engineering, Stanford University
Stanford, CA
hblasins,joyce_farrell,wandell@stanford.edu

Abstract

There are many scientiﬁc, medical and industrial imag-
ing applications where users have full control of the scene
illumination and color reproduction is not the primary ob-
jective. For example, it is possible to co-design sensors and
spectral illumination in order to classify and detect changes
in biological tissues, organic and inorganic materials, and
In this paper, we propose two
object surface properties.
different approaches to illuminant spectrum selection for
surface classiﬁcation. In the ﬁrst approach, a supervised
framework, we formulate a biconvex optimization problem
where we alternate between optimizing support vector clas-
siﬁer weights and optimal illuminants. In the second ap-
proach, an unsupervised dimensionality reduction, we de-
scribe and apply a new sparse Principal Component Anal-
ysis (PCA) algorithm. We efﬁciently solve the non-convex
PCA problem using a convex relaxation and Alternating Di-
rection Method of Multipliers (ADMM). We compare the
classiﬁcation accuracy of a monochrome imaging sensor
with optimized illuminants to the classiﬁcation accuracy of
conventional RGB cameras with natural broadband illumi-
nation.

1. Introduction

The spectral power distribution of the illumination
source plays a fundamental role in how objects objects are
imaged and analyzed by a digital camera [34]. In consumer
digital photography, the spectral properties of scene illumi-
nation are unknown at capture and the main challenge in
color balancing (white balancing) is estimating the spectral
power of the illuminant [35].

There are many applications where color reproduction
is not the primary goal of imaging systems, for example
laparoscopic surgery, endoscopy, microscopy or industrial
quality control [4, 17]. In these cases the spectrum of light
is a design parameter that can be optimized for tasks such
as detecting object features or classifying surfaces [7]. De-
pending on the application it may be more advantageous to

Convenional
illuminant

Discriminative
illuminant

Figure 1: The spectral power distribution of the illuminant
has a big impact on the data captured by an imaging system.
It can be difﬁcult for a machine learning algorithm to dis-
criminate between a real and fake apple based on the data
from an RGB camera and broadband illumination (left).
In contrast a camera capturing the scene with customized
lights produces better data for discrimination (right) even
though the light optimal for feature discrimination or clas-
siﬁcation may not produce accurate color matching effects.

adjust the spectral power distribution of the illuminant to
enhance the visibility of features of interest, at the expense
of accurate color rendering. Speciﬁcally, scene data cap-
tured under natural, broadband light sources and with con-
ventional RGB cameras can be less useful in classiﬁcation
problems than the data acquired with monochrome cameras
and highly customized, narrowband illuminants (Fig. 1).
The customized set of illuminants will produce a more ro-
bust set of features that can be later leveraged by machine
learning algorithms to improve classiﬁcation performance.
In this paper we describe and evaluate two novel algo-
rithms to effectively and systematically search for spectral
power distributions of optimal lights that improve material
classiﬁcation. The lights are optimized for a particular clas-
siﬁcation task, for example apple classiﬁcation. We formu-
late the problem of illuminant spectral power distribution
selection in two different frameworks: supervised and un-
supervised learning. Our methods are designed to explicitly

2164

estimate spectral power distributions, rather than to select
the best illuminant from a given set. The methods are also
constrained to produce solutions that are physically realiz-
able.

In the supervised context we assume that the reﬂectance
data is labeled and we formulate a penalty function incor-
porating the image formation model, classiﬁer parameters,
and the spectral power distribution of light. Such an objec-
tive function is bi-convex and locally optimal solutions can
be found via alternating minimization.

In the unsupervised context we approach optimal illumi-
nant spectral power distribution design from the dimension-
ality reduction perspective. Here the objective is to project
high dimensional reﬂectance data onto a smaller number
of dimensions that preserve the information necessary for
classiﬁcation. Optimized projection directions better cap-
ture the characteristics of the underlying data preserving
more variance in the projected data set. Larger variance
in the data set generally translates to better performance of
the classiﬁcation algorithms. The classical algorithm for
dimensionality reduction is Principal Component Analysis
(PCA). This algorithm computes a set of orthogonal projec-
tion directions along which the variance in the data set is
the largest [12].

The space of physically realizable spectral power distri-
butions of light is limited by certain physical constraints.
First, light cannot be negative. Second, the shapes of the
spectrum cannot be arbitrary, typically these are smooth
functions. All these restrictions need to be taken into con-
sideration when searching for the optimal illuminant.

In summary, our contributions include:

• Two new algorithms optimizing the spectral power dis-
tributions of illuminants for classiﬁcation tasks and
producing distributions that can be generated with real
light sources.

• A new sparse nonnegative PCA algorithm with a single

tuning parameter.

• A framework for analyzing imaging system classiﬁca-
tion performance using different number and spectra
of optimized illuminants.

2. Related work

There exist few methods that solve the problem dis-
cussed in this paper. The most relevant algorithm is that
of Liu and Guo [21], who used cost function minimization
to select the color, position and intensity of LEDs in their
capture device that enhance material classiﬁcation accuracy.
Unlike the methods we describe, the authors do not analyze
the data in the wavelength domain and do not restrict their
solution to non-negative intensities.

Many other approaches involve brute force selection
strategies using exhaustive search over the entire parame-

ter space [26]. This is tractable for small problems, but the
complexity grows exponentially and thus makes the method
computationally impractical. One way to reduce the solu-
tion space of brute-force methods is to use genetic algo-
rithms [6]. The methods we present involve continuous
valued function minimization rather than search strategies
making them more computationally tractable.

Optimal light spectral power distribution selection shares
many similarities with camera responsivity design. Cam-
era responsivities, however, are most frequently optimized
for color matching tasks [14, 28, 30, 31], low light perfor-
mance [8, 19] or spectral reconstruction [25, 27]. The idea
of adapting camera spectral characteristics to the particular
properties of the imaged scene was presented in [20] where
the authors manually changed the characteristics of a liquid
crystal tunable ﬁlter (LCTF) as a function of the distribution
of scene radiance. In a similar effort [10] describe an adap-
tive spectroscopy algorithm which takes repeated measure-
ments of the scene and adjusts the sensitivity of the spec-
trometer as a function of prior observations. This approach
conditions the shape of optimal responsivity curves on the
results of earlier measurements and thus cannot be used to
derive a ﬁxed set of spectral curves independent of speciﬁc
measurement outcomes.

Dimensionality reduction techniques designed for hyper-
spectral data have been developed in the remote sensing
community [5, 16, 18]. In these applications the weights are
not constrained and are allowed to be negative and therefore
wavelength distributions of those weights do not represent
physically realizable light spectra.

The existing sparse PCA [1, 15, 24] or nonnegative
sparse PCA [32, 36] algorithms cannot be directly used to
design physically realizable illuminants. These methods do
not allow nonnegativity constraints on linearly transformed
variables, which is necessary to assure physical realizabil-
ity of optimized illuminant spectra. Some of the methods
are also impractical due to large numbers of tuning parame-
ters that need to be adjusted. We overcome these limitations
by proposing a new, ﬂexible nonnegative sparse PCA algo-
rithm with a single tuning parameter.

3. Image formation model

The response of a camera’s photodetector mj,k is a linear
function of the scene illuminant xk, surface reﬂectance r
and the spectral responsivity of the jth camera color channel
cj [34]

mj,k =

cj(λ)r(λ)xk(λ)dλ.

(1)

Z

For most natural images, the spectral curves are smooth
and slowly varying, therefore a discretization to n spectral
bands simpliﬁes modeling with little impact on the accuracy

mj,k = ∆λcT

j diag(r)xk = eT

j xk

(2)

2165

where ej = ∆λ(r1cj,1, r2cj,2, . . . .rncj,n), ej ∈ Rn is the
wavelength-wise product between the surface spectral re-
ﬂectance and the camera responsivity function of the jth
channel. In this work, we propose a method to choose the
vector xk, given a set of labeled or unlabeled vectors ej so
that those vectors projected onto a subspace spanned by xk,
k ∈ 1, . . . , K preserve the discriminative information from
e in m. A classiﬁcation algorithm then uses the projected
data m, i.e. pixel intensities, to derive decision boundaries
in this low dimensional subspace.

Spectral curves are often approximated using linear

models

x = Bw,

(3)

where the columns of B ∈ Rn×nb represent model compo-
nents and w ∈ Rnb are the corresponding weights. Model
components can be derived using two different approaches.
The ﬁrst approach takes advantage of the fact that spectrally
smooth curves lie on a low dimensional subspace [23]. The
span of this subspace is described by the columns of B,
which, by deﬁnition, form an orthogonal set, i.e. BT B = I.
This modeling usually aims to simplify the problem by re-
ducing the number of variables used to describe a light spec-
trum.

The second approach is to make columns of B directly
represent a collection of spectral power distributions of all
light sources the user controls. For example B can be cre-
ated from spectral power distributions of all LEDs on offer
by a manufacturer. The task now becomes selection of these
spectra that are optimal. In such cases B forms a dictionary
and often becomes ‘fat‘, i.e. contains more columns than
rows. This means that some of the dictionary entries are
linear combinations of each other, and BT B is no longer
full rank.

We assume that a physically realizable illuminant is non-
negative and that is spanned by the columns of B. Our ap-
proach to ﬁnding the optimal light does not rely on partic-
ular properties of B, speciﬁcally B can be ‘fat‘ and BT B
non-invertible.

We also note that if one could use a large number of il-
luminants (K ≥ n) the optimal strategy would be to pick
monochromatic lights. In this case, acquisition of K images
would correspond to capturing the full spectral characteris-
tic of the surface, as if imaged with a hyperspectral camera.
This means that in general, preferred solutions should have
little overlap across spectral channels, and many zero en-
tries.

4. Supervised framework

Many classical supervised learning algorithms attempt
to ﬁnd a set of hyperplanes that deﬁne boundaries between
points in the feature space representing different classes.

For example, to classify a set of vectors e with labels y, the
parameters describing separating hyperplanes θ are found
by minimizing a cost function f subject to constraints g on
those parameters

minimize f (θ; e, y)
subject to g(θ; e, y) ≤ 0.

(4)

(5)

Often the input data e are not guaranteed to be linearly sep-
arable in the original n dimensional space. The data may
be projected, using operator Φ(e), to a higher dimensional
space in which such linear separability can be achieved

minimize f (θΦ; Φ(e), y)
subject to g(θΦ, Φ(e), y) ≤ 0.

We note that in the context of optimal illumination design
the projection operator Φ naturally arises in the formula-
tion of the image formation model, though it projects data
to a subspace with fewer dimensions. Observe that the mea-
sured pixel intensities satisfy m = X T e = Φ(e), where the
columns of X = [x1, . . . , xK] represent the spectral power
distributions of K illuminants, and e are deﬁned as in (2).
The problem is to ﬁnd such linear projection directions X
that facilitate class separability in the Φ(e) vector space, i.e.
camera pixel measurement space.

To illustrate the approach, consider a classiﬁer where f
and g correspond to a multiclass, one-vs-all, Support Vector
Classiﬁer (SVC) [13]. The linear decision boundaries pt for
each of the t classes are given by a solution to the convex
optimization problem

minimize

kptk2

2 + C

ξt
i

Xt
Xi,t6=yi
yi Φ(ei) + byi ≥ pT
subject to pT
ξt
i ≥ 0,

i = 1, . . . , L,

t Φ(ei) + bt + 2 − ξt
i

t ∈ {1, . . . , T } \ yi,

(6)

where {yi, ei} represent
the label and the reﬂectance-
camera responsivity product of the ith data point respec-
tively with the size of the training set given by L. The scalar
C controls how many data points are allowed to be misclas-
siﬁed during training.

In order to ﬁnd the optimal illuminant spectral power dis-
tributions we re-formulate the SVC problem by replacing
the projection Φ(ei) = (BW )T ei and adding constraints
on the illuminant power distributions BW assuring physical
realizability. The resulting biconvex optimization problem

minimize

kpkk2

2 + C

ξk
i + αz(BW )

(7)

Xi,k6=yi

Xk
yi (BW )T ei + byi ≥ pT
subject to pT
ξk
i = 1, . . . , L,
i ≥ 0,
BW ≥ 0,

k (BW )T ei + bk + 2 − ξk
i
k ∈ {1, . . . , K} \ yi,

2166

can be solved through alternating minimization over p, b, ξ
and b, ξ, W . The matrix W describes the illuminant spec-
tra in terms of the linear basis weights (3). Note that the
cost function has been augmented with a function z, con-
trolled with a tuning parameter α, penalizing certain types
of solutions. We promote sparsity with an l1 penalty

z(X) = kXk1 =

|xi,j|

(8)

Xi,j

where the l1 norm is generalized to matrices and computes
the sum of the absolute values of all matrix entries.

5. Unsupervised framework

Principal Component Analysis (PCA) is a standard tech-
nique used in machine learning to compactly represent a
data set. The PCA algorithm ﬁnds a set of projection vec-
tors along which the original data has the largest variance.
These projections are given by the principal eigenvectors
of the data set covariance matrix. In the context of illumi-
nant spectrum selection, we note that the measured pixel
intensity represents the projection of the reﬂectance-camera
responsivity product onto a vector describing the spectral
distribution of the illuminant.

For convenience, we express PCA as an iterative algo-
rithm. Let Σ ∈ Sn
+ represent the positive semi-deﬁnite sam-
ple covariance matrix of vectors e from (2). The ith optimal
PCA direction is a solution to the problem

where Σ(i−1) is the covariance matrix estimate from the
previous step. Before proceeding to the next iteration Σ
needs to be recomputed to account for the removal of the
solution dimension (i.e. deﬂated).

The iterative PCA algorithm can be modiﬁed to produce
nonnegative and sparse directions by introducing additional
constraints into the optimization problem (9)

i.e. relaxation. For example, using the PCA relaxations de-
scribed in [9, 33], the original nonconvex problem can be
approximated with

maximize
subject to

tr(ΣX) − αkXk1
0 (cid:22) X (cid:22) I,
tr(X) = 1
X ≥ 0

(11)

(we drop the superscript (i − 1) for clarity). The function
tr(X) is the trace operator, i.e. the sum of the entries of
X along the diagonal, and α controls the sparsity enforcing
penalty.

The ﬁrst constraint forces X to be positive, semi-deﬁnite
and X − I to be negative, semi-deﬁnite. The last constraint
restricts the solution to a set of matrices with nonnegative
entries. The optimal projection direction is given by the
principal eigenvector of a solution X ⋆ = x⋆x⋆T . Note that
the matrix entry-wise inequality enforces all the entries of
x⋆ to have the same sign, therefore if x⋆ is a solution so is
−x⋆.

In order to express the PCA problem in terms of the basis
weights, X = xxT = Bw(Bw)T = BW BT is substituted
into (11) yielding

maximize
subject to

tr(ΣBW BT ) − αkBW BT k1
0 (cid:22) BW BT (cid:22) I,
tr(BW BT ) = 1
BW BT ≥ 0,

(12)

The above optimization problem can be efﬁciently
solved using the Alternating Direction Method of Multi-
pliers (ADMM) [3, 33]. The computational steps of this
approach are summarized in Algorithm 1, derivation details
are available in the Supplemental Material. This algorithm
requires the user to provide the desired accuracy ǫ and a
learning rate ρ. Following the recommendation of [33] we
used an update heuristic proposed in [3]. It may happen that
the function computing the largest eigenvector of Y (t+1)
will return a vector with all nonpositive entries. In this case
the sign of such a solution should be reversed.

1

maximize xT Σ(i−1)x
subject to xT x = 1

card(x) ≤ δ
x ≥ 0,

(10)

5.2. Matrix deﬂation

where δ is a sparsity parameter and card(x) speciﬁes the
number of nonzero entries in x. Equation (10) is nonconvex
due to the incorporation of sparsity and nonnegativity con-
straints. Hence, eigen decomposition is no longer a valid
method for ﬁnding a solution.

5.1. Convex relaxation

A useful approach to solving nonconvex problems is to
perform an approximation with a similar convex problem

The iterative approach to PCA makes it necessary to de-
ﬂate the current sample covariance matrix estimate Σ(i−1)
before proceeding to the next iteration. The commonly used
Hotelling’s deﬂation scheme may not preserve the semideﬁ-
niteness of Σ(i) if the projection direction xi is not an eigen-
vector of Σ(i−1) [29]. To avoid such issues we used a gen-
eralized deﬂation algorithm proposed in [22]. Algorithm 2
summarizes this deﬂation method and outlines the steps re-
quired to compute r sparse nonnegative PCA directions for
a particular data set.

maximize xT Σ(i−1)x
subject to xT x = 1,

(9)

where W = wwT .

2167

Algorithm 1 Single nonnegative sparse PCA direction.

function FINDDIRECTION(Σ,B, α, ǫ, ρ)
2 ← 0, U (0)

1 ← 0, Y (0)

Y (0)
1 ← 0, U (0)
repeat

2 ← 0

kBW BT − Y (t)

W (t+1) ← arg min
Y (t+1)
1
U (t+1)
1 ← U (t)
t ← t + 1

(cid:16)
← PF (BW (t+1)BT + U (t)
1 + W (t+1) − Y (t+1)

1

,

1 + U (t)
1 + Σ/ρ),

1 k2

F + kBW BT − Y (t)

2 + U (t)

2 k2
F

(cid:17)

Y (t+1)
2
U (t+1)
2 ← U (t)

← Hα/ρ(BW (t+1)BT + U (t)
2 )

2 + BW (t+1)BT − Y (t+1)

2

until max{kBW (t+1)BT − Y (t+1)

F , ρ2kY (t+1)
k2
corresponding to the largest eigenvalue.

F , kBW (t+1)BT − Y (t+1)
k2

2

1

1

return Eigenvector of Y (t+1)
end function

1

− Y (t)

1 k2

F }, ρ2kY (t+1)

2

− Y (t)

2 k2

F } ≤ ǫ

Algorithm 2 Nonnegative sparse PCA
Require: Σ ∈ Sn

+, α ≥ 0, ǫ ≥ 0, ρ ≥ 0, r ∈ N, B

Q(0) ← I, Σ(0) ← Σ
for t = 1, . . . , r do

xt ← FINDDIRECTION(Σ(t−1),B, α, ǫ, ρ)
qt ← Q(t−1)xt
t )Σ(t−1)(I − qtqT
Σ(t) ← (I − qtqT
t )
Q(t) ← Q(t−1)(I − qtqT
t )
xt ← xt/kxtk

1.4

1.2

1

0.8

0.6

0.4

0.2

0
400

end for
return x1, . . . , xr

6. Experiments

To evaluate the proposed approaches we conducted a set
of experiments where we captured images of known test tar-
gets under different illumination conditions and used stan-
dard machine learning algorithms to classify captured data.
We implemented all computations in Matlab, and our code
repository is available online1.

First, we measured the performance of classiﬁcation al-
gorithms on data captured with conventional RGB cameras
and under a single broadband illuminant. This condition
represents the typical imaging scenario where a color cam-
era with three types of color pixels is used to capture a single
image in natural lighting conditions (i.e. J = 3, K = 1).
Overall, we evaluate the performance of 34 cameras with
different spectral properties (see Supplemental Material for
the list of evaluated camera models). For simplicity we will
refer to this mode of data capture as conventional camera.
Next, we captured the data using a monochrome cam-
era and optimized illuminants.
To make comparisons
between conventional and optimized systems meaning-
ful we projected spectral measurements onto a three-
dimensional space. To obtain this representation with our
optimized setup we captured three successive frames with a

Captured

500

600
Wavelength, nm

Emulated

700

800

Figure 2: A comparison between spectral properties of a
GoPro Hero 5 RGB camera (solid lines) and their approxi-
mation with narrowband lights (dashed lines). For a given
scene, pixel values produced by an RGB camera (inset, cap-
tured) can be reproduced with a mochorome camera and ap-
propriately adjusted narrowband lights that match the spec-
tral responsivities of the camera (inset, emulated).

monochrome camera, each under different, optimized light
(i.e. J = 1, K = 3) derived with either supervised or unsu-
pervised approach. We refer to this capture mode as optimal
camera.

We investigated a simple classiﬁcation task; assigning
labels to image pixels based on raw image data. We origi-
nally designed these algorithms for use with biological mul-
tispectral data, however for presentation clarity we chose
much simpler targets requiring no domain speciﬁc knowl-
edge.
In our tests we used genuine and visually similar
artiﬁcial fruit pairs: apples, pears and lemons. Our goal
was to discriminate between different objects. For this pur-
pose we constructed three test scenes. Two of them con-
tained two pairs of differently colored fruit of the same type;
red and green apples (Apples) and yellow and green pears
(Pears). The Lemons scene contained a single pair of ob-
jects; lemons.

Scenes were assembled in a Thouslite LEDCube2 light
booth. The LEDCube contained three broadband and eight
narrowband LEDs whose intensities could be independently

1https://github.com/hblasins/optIll

2http://www.thouslite.com/show.asp?id=16

2168

s
r
a
e
P

s
e
l
p
p
A

s
n
o
m
e
L

500

600
Wavelength, nm

700

800

500

600
Wavelength, nm

700

800

500

600
Wavelength, nm

700

800

500

600
Wavelength, nm

700

800

1

0.8

0.6

0.4

0.2

0.8

0.6

0.4

0.2

0.8

0.6

0.4

0.2

0
400

1

0
400

1

0
400

(a) RGB Image

(b) RGB
classiﬁcation

(c) Unsupervised
classiﬁcation

(d) Unsupervised
spectra

(e) Supervised
classiﬁcation

500

600
Wavelength, nm

700

800

500

600
Wavelength, nm

700

800

(f) Supervised
spectra

Figure 3: Pixel classiﬁcation accuracy is increased when the scene is illuminated with optimal lights. Columns present the
RGB rendering of the scene (a), pixel classiﬁcation maps for conventional illumination (b), and optimal lights derived with
unsupervised (c) and supervised (e) approaches. Color in (b, c, e) encodes pixels where the SVM classiﬁer assigned correct
labels, all errors are not represented. The spectral power distributions of the optimal illuminants (d, f, thick lines) overlap
with areas of increased variability in the surface spectral reﬂectance (d, f, thin lines).

adjusted thus changing the overall spectrum of the illumi-
nant. The spectral power distributions of the individual
LEDs formed columns in the model matrix B (3).

We measured the surface spectral reﬂectance of all tar-
gets as well as spectral power distributions of the LEDs in
the 400 to 800nm range at 4nm increments using a Spec-
traScan PR715 spectrophotometer. We calibrated the LED-
Cube LED spectra by taking measurements of the light ra-
diance reﬂected from a reference white, Spectralon test tar-
get. Similarly, we estimated the surface spectral reﬂectance
by illuminating the surface of fruits with broadband tung-
sten light, taking 10 radiance measurements followed by
one measurement of a Spectralon sample, and by computing
the ratio between the two at every wavelength [2].

Given a set of reﬂectance curves we used the supervised
and unsupervised approaches to generate optimal illumi-
nants for a particular setting of algorithm tuning parameters.
We then programmed those spectra into the LEDCube and
captured images of the so illuminated target with a Point-
Grey FL3-U3-13Y3M-C, 1.3MP monochrome camera with
a Schneider Optics Xenoplan 1.4/23mm lens. The aperture
was set to f#/11 in order to limit depth of ﬁeld effects.

Next, we manually segmented 100 × 100 (200 × 200 for
binary classiﬁcation) pixel regions of interest (ROI) within
each fruit sample and used this set for classiﬁcation. The
classiﬁers used single pixel intensity data. The data was

split into training (70%) and test (30%) sets using the strati-
ﬁed approach, i.e. preserving the distribution of class labels
[11]. For fairness of comparisons we preserve data separa-
tion across all classiﬁers and conditions. In our evaluations
we used ﬁve standard machine learning classiﬁers: Sup-
port Vector Machines (SVM), K-Nearest Neighbors (KNN),
Linear Discriminant Analysis (DA), Decision Trees (Tree)
and Naive Bayes (NB).

Finally, we repeated the procedure; optimal illuminant
computation followed by image capture and classiﬁer cross
validation, for different settings of illuminant selection al-
gorithms tuning parameters (refer to source code for de-
tails). In all cases training data set was used for training
and parameter selection only, and all performance numbers
we report were calculated using the test set.

Rather than using physical RGB cameras in our evalu-
ations, we instead emulated their spectral properties with
narrowband LEDs from LEDCube and the PointGrey
monochrome camera. We approximated the effective spec-
tral responsivity (i.e. the wavelength-wise product between
spectral responsivity and the illuminant) of red, green and
blue camera channels with an appropriate weighted sum of
the LEDCube LEDs, accounting for the monochrome sen-
sor quantum efﬁciency (see Supplemental Material for de-
tails). Figure 2 shows an example comparison between the
actual responsivity curves and their approximations using

1

0.8

0.6

0.4

0.2

0.8

0.6

0.4

0.2

0.8

0.6

0.4

0.2

0
400

1

0
400

1

0
400

2169

Table 1: Single pixel per cent classiﬁcation accuracy for the
Pears data (four-way classiﬁcation).

Table 2: Single pixel per cent classiﬁcation accuracy for the
Apples data (four-way classiﬁcation).

Camera

RGB (worst)
RGB (avg.)
RGB (best)
Ours (Unsup.)
Ours (Sup.)

Classiﬁer

SVM KNN
92.7
92.3
95.2
94.6
98.4
98.4
97.9
97.2
99.9
99.9

DA
91.2
93.6
97.9
96.9
98.9

Tree
90.7
94.1
97.8
97.8
99.8

NB
66.0
67.8
74.2
82.8
76.6

Camera

RGB (worst)
RGB (avg.)
RGB (best)
Ours (Unsup.)
Ours (Sup.)

Classiﬁer

SVM KNN
78.4
75.2
82.3
84.6
83.3
85.6
89.4
87.1
92.6
91.5

DA
74.9
84.1
85.3
86.4
91.2

Tree
73.6
84.2
85.8
89.2
91.2

NB
66.0
68.7
72.7
83.7
79.5

LEDs. Insets in this ﬁgure present an image of a Macbeth
chart captured with a conventional RGB camera and com-
pares it to a view of the same chart rendered with the data
from the proposed emulation approach.

There are several advantages to using the emulation ap-
proach. First, the geometry of the setup remains ﬁxed
and any differences between various test conditions arise
only from illumination rather than image alignment or re-
sampling between different cameras. Second, the same sen-
sor is used throughout all experiments and so the noise
properties remain ﬁxed. Finally, the resolution and optics
remain constant throughout all experiments.

6.1. Classiﬁcation performance

Figure 3 presents the results of pixel classiﬁcation out-
comes for three test scenes captured under daylight and op-
timized illuminants. Classiﬁcation maps were created by
applying classiﬁers trained on the training data to all pixels
in the image. For clarity we show and label only correctly
identiﬁed pixels.
In general, maps obtained for the opti-
mized illumination cases correctly classify larger number
of pixels. We also observed that those maps have more con-
tiguous object segmentation and less ’salt and pepper’ clas-
siﬁcation noise. However, the optimal illuminant selection
strategies do not always increase the number of correctly
classiﬁed pixels. They can also make some pixels easier to
classify at the expense of others. Take the Apple scene as
an example. Under optimized illuminants the increased ac-
curacy in recognizing the bottom right apple (green label)
is offset by erroneously classifying parts of the bottom left
apple (purple label) that had been correctly classiﬁed by a
conventional camera.

We also present the optimal illuminant spectra derived
for each condition (Fig. 3d and 3f). The curves derived
by supervised and unsupervised approaches differ, but they
share a common characteristic.
In all cases light energy
is concentrated at wavelengths with signiﬁcant amount of
variability in the surface reﬂectance data.
The quantitative performance of

the proposed ap-
proaches is presented in Tables 1, 2 and 3 which summarize
the pixel based classiﬁcation accuracy achieved with the op-

Table 3: Single pixel per cent classiﬁcation accuracy for the
Lemons data (binary classiﬁcation).

Camera

RGB (worst)
RGB (avg.)
RGB (best)
Ours (Unsup.)
Ours (Sup.)

SVM
92.2
97.5
99.9
99.8
100.0

Classiﬁer

KNN
96.4
99.0
100.0
99.8
100.0

DA
90.0
96.3
99.8
99.6
99.9

Tree
85.9
96.6
99.9
98.3
98.8

NB
58.8
62.0
75.6
63.1
70.9

timal and conventional cameras. For every classiﬁcation al-
gorithm, we report the average accuracy computed over 34
RGB cameras as well as the accuracy of the best and worst
performing model for a particular algorithm. The model
of the camera achieving the highest classiﬁcation accuracy
varied across different scenes and classiﬁers. This metric
represents the performance of illuminant spectral power dis-
tributions found using a brute force search algorithm and
serves as a baseline for comparisons with our methods.

We experimented with illuminating our scenes with the
emission spectra of black body radiators at different tem-
peratures; 2000, 4000, 6500, and 10000K. These spectra of-
fer good approximations to light distributions occurring in
natural environments. For a particular classiﬁcation algo-
rithm, performance differences between these illuminants
were minor (see Supplemental Material for details). The
black body emission at 6500K closely resembles the stan-
dard D65 illuminant (daylight), and in general provided
the best, or close second best classiﬁcation accuracy. Fur-
thermore, many conventional RGB cameras are designed
to faithfully reproduce colors speciﬁcally under this illumi-
nant. For these reasons we use this condition as reference
in numerical comparisons.

The imaging system using illuminant spectral power dis-
tributions derived with our supervised method consistently
outperforms conventional RGB cameras and broadband il-
luminants for the SVM, KNN, DA and Tree classiﬁcation
algorithms. It comes second only when the Tree classiﬁer
is applied to the Lemons scene. These gains are due to direct

2170

incorporation of the search for optimal spectra into the clas-
siﬁcation objective function, and are achieved despite non-
convexity of the problem and local optimality of the solu-
tion. Interestingly, the supervised selection method is typ-
ically outperformed by a combination of the Naive Bayes
classiﬁer with the unsupervised approach.

Our unsupervised selection method is better than the av-
erage conventional RGB camera, and its accuracy is typi-
cally on par with that of the best RGB camera. Note that this
selection strategy works best together with a Naive Bayes
classiﬁer. The unsupervised approach is a variant of PCA,
which provides a set of uncorrelated features. In our case
we use a constrained version; it also decorrelates data, but
to a lesser extent. The Naive Bayes classiﬁer implicitly as-
sumes feature conditional independence, which means that
the unsupervised approach provides the type of data the
classiﬁer expects.

6.2. Number of illuminants

We investigated the relationship between classiﬁcation
accuracy and the number of different illuminants under
which a scene is captured. Optimization over the illumi-
nant spectrum offers another system design parameter. For
example, a suitable illuminant could eliminate the need for
a color ﬁlter array thus increasing the effective sensor reso-
lution.

Increasing the number of optimal illuminants from 1 to
10 increases the classiﬁcation performance, irrespective of
the selection method used. Figure 4 presents the classiﬁ-
cation accuracy in the Apples set as a function of the num-
ber of optimal illuminants. The supervised selection algo-
rithm maintains a small advantage over the unsupervised
approach across all conditions. The classiﬁcation accuracy
asymptotes at about 95%, ten percentage points above the
accuracy of the best conventional RGB camera. However,
at about 3–4 illuminants the curves plateau; using more il-
luminants offers modest gains in performance that may not
be worth pursuing given other limitations such as acquisi-
tion time. Note that the classiﬁcation accuracy of an opti-
mal two-illuminant system, i.e. representing pixel data with
two numbers, is comparable to that of the best conventional
RGB camera and a broadband illuminant, which represent
pixel data with three numbers. Both systems achieve about
86% classiﬁcation accuracy. This reduction in data dimen-
sionality can translate to smaller data storage requirements
or fewer processor cycles necessary for computation.

100

95

90

85

80

75

70

%

 
,
y
c
a
r
u
c
c
a
 
n
o
i
t
a
c
i
f
i
s
s
a
C

l

Best RGB camera

Unsupervised
Supervised

1

2

3

4

5

6

7

8

9

10

Number of illuminants

Figure 4: Pixel classiﬁcation accuracy increases when a
scene (Apples) is captured under more optimized illumi-
nants, with supervised selection outperforming the unsu-
pervised algorithm. Using just two optimally chosen lights
allows to achieve the performance level of a conventional,
three channel RGB system.

produce physically realizable distributions that can be gen-
erated using off-the-shelf LEDs.

We evaluated the optimal lights produced by our selec-
tion methods in a simple surface classiﬁcation task through
a series of laboratory experiments using real targets, illumi-
nants, and cameras. In all cases classiﬁer performance on
pixel data obtained under optimized lights is greater than the
performance of the same algorithm on data captured with a
conventional RGB camera and broadband illuminants. We
showed that the supervised selection method achieves the
best performance, but it requires a set of labeled training re-
ﬂectance spectra. In comparison the unsupervised method
is a close second in terms of accuracy, but can work with
unlabeled object spectral reﬂectance curves.

Both algorithms are useful in analyzing the impact of
additional imaging channels on classiﬁcation performance.
This is an important consideration because, we have shown,
under the constraints of physical realizability having more
channels may provide only modest performance gains that
may be deemed not worth pursuing given the increased sys-
tem complexity and other design trade-offs such as speed,
resolution or computation.

Finally, the methodology we present in this work can be
extended to other spectral selection problems in imaging
system design. For example, the same algorithms can be
applied to selecting the responsivity functions of the color
ﬁlter array or could be used to select transmissive ﬁlters for
biological image analysis.

7. Conclusions

Acknowledgements

We presented two new approaches to selecting spectral
power distributions of illuminants used during the image
capture process that increase the accuracy of pixel classi-
ﬁcation algorithms applied to captured data. Our methods

The authors would like to thank Gordon Wetzstein from
Stanford University for helpful comments and discussions
during the preparation of the manuscript. The LEDCube
image booth was a gift from Thouslite.

2171

References

[1] A. Amini and M. Wainwright. High-dimensional analysis of
semideﬁnite relaxations for sparse principal components. In
IEEE International Symposium on Information Theory ISIT,
pages 2454–2458, 2008. 2

[2] H. Blasinski, J. Caves, J. Farrell, B. Wandelt, and P. Wang.
Multispectral imaging of tissue ablation. In IEEE Interna-
tional Symposium on Biomedical Imaging, ISBI, pages 360–
363, April 2016. 6

[3] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein. Dis-
tributed optimization and statistical learning via the alternat-
ing direction method of multipliers. Foundations and Trends
in Machine Learning, 3(1):1–122, 2011. 4

[4] J. Cadeddu, R. Fernandez, M. Desai, R. Bergs, C. Tracy, S.-
J. Tang, P. Rao, M. Desai, and D. Scott. Novel magneti-
cally guided intra-abdominal camera to facilitate laparoen-
doscopic single-site surgery: initial human experience. Sur-
gical endoscopy, 23(8):1894–1899, 2009. 1

[5] C. Chang, Q. Du, T. Sun, and M. Althouse. A joint band pri-
oritization and band decorrelation approach to band selection
IEEE Transactions
for hyperspectral image classiﬁcation.
on Geoscience and Remote Sensing, 37(6):2631–2641, Nov
1999. 2

[6] C. Chi, H. Yoo, and M. Ben-Ezra. Multispectral imaging by
optimized wide band illumination. International Journal of
Computer Vision, 86(2–3):140–151, 2010. 2

[7] J. Choi, S. Park, J. Cho, and E. Yoon. A 3.4-µ w object-
adaptive CMOS image sensor with embedded feature extrac-
tion algorithm for motion-triggered object-of-interest imag-
IEEE Journal of Solid-State Circuits, 49(1):289–300,
ing.
Jan 2014. 1

[8] L. Condat. A new color ﬁlter array with optimal properties
for noiseless and noisy color image acquisition. IEEE Trans-
actions on Image Processing, 20(8):2200–2210, Aug 2011.
2

[9] A. d’Aspremont, L. El Ghaoui, M. Jordan, and G. Lanck-
riet. A direct formulation for sparse PCA using semideﬁnite
In Neural Information Processing Systems,
programming.
volume 16, pages 41–48, 2004. 4

[10] D. Dinakarababu, D. Golish, and M. Gehm. Adaptive fea-
ture speciﬁc spectroscopy for rapid chemical identiﬁcation.
Optics express, 19(5):4595–4610, 2011. 2

[11] G. Forman and M. Scholz. Apples-to-apples in cross-
validation studies: pitfalls in classiﬁer performance measure-
ment. ACM SIGKDD Explorations Newsletter, 12(1):49–57,
2010. 6

[12] T. Hastie, R. Tibshirani, and J. Friedman. The elements of

statistical learning. Springer, 2009. 2

[13] C.-W. Hsu and C.-J. Lin. A comparison of methods for multi-
class support vector machines. IEEE Transactions on Neural
Networks, 13(2):415–425, 2002. 3

[14] F. Imai, S. Quan, M. Rosen, and R. Berns. Digital camera
ﬁlter design for colorimetric and spectral accuracy. In Pro-
ceedings of the 3rd International Conference on Multispec-
tral Color Science, pages 23–26, 2001. 2

[15] M. Journee, Y. Nesterov, P. Richtarik, and R. Sepulchre.
Generalized power method for sparse principal component

analysis.
11:517–553, 2010. 2

The Journal of Machine Learning Research,

[16] N. Keshava. Distance metrics and band selection in hyper-
spectral processing with applications to material identiﬁca-
tion and spectral libraries. IEEE Transactions on Geoscience
and Remote Sensing, 42(7):1552–1565, July 2004. 2
[17] S. Kukkonen, H. Kalviainen, and J. Parkkinen. Color fea-
tures for quality control in ceramic tile industry. Optical En-
gineering, 40(2):170–177, 2001. 1

[18] S. Kumar, J. Ghosh, and M. Crawford. Best-bases fea-
ture extraction algorithms for classiﬁcation of hyperspectral
data. IEEE Transactions on Geoscience and Remote Sensing,
39(7):1368–1379, Jul 2001. 2

[19] H. Kuniba and R. S. Berns. Spectral sensitivity optimization
of color image sensors considering photon shot noise. Jour-
nal of Electronic Imaging, 18(2):023002–023002–14, 2009.
2

[20] A. Lin and F. Imai. Efﬁcient spectral imaging based on imag-
ing systems with scene adaptation using tunable color pixels.
In Color and Imaging Conference, volume 2011, pages 332–
338. Society for Imaging Science and Technology, 2011. 2

[21] C. Liu and J. Gu. Discriminative illumination: Per-pixel clas-
siﬁcation of raw materials based on optimal projections of
IEEE Transactions on Pattern Analysis and
spectral brdf.
Machine Intelligence, 36(1):86–98, 2014. 2

[22] L. Mackey. Deﬂation methods for sparse PCA. In Neural
Information Processing Systems, volume 21, pages 1017–
1024, 2008. 4

[23] L. T. Maloney and B. A. Wandell. Color constancy: a method
for recovering surface spectral reﬂectance. Journal of the
Optical Society of America A, 3(1):29–33, 1986. 3

[24] B. Moghaddam, Y. Weiss, and S. Avidan. Generalized spec-
tral bounds for sparse LDA. In Proceedings of the 23rd in-
ternational conference on Machine learning, pages 641–648.
ACM, 2006. 2

[25] Y. Monno, T. Kitao, M. Tanaka, and M. Okutomi. Optimal
spectral sensitivity functions for a single-camera one-shot
multispectral imaging system. In IEEE International Con-
ference on Image Processing, ICIP, pages 2137–2140, 2012.
2

[26] J. Park, M. Lee, M. D. G., and S. Nayar. Multispectral imag-
In IEEE International
ing using multiplexed illumination.
Conference on Computer Vision, ICCV, pages 1–8, Oct 2007.
2

[27] M. Parmar, S. Lansel, and J. Farrell. An LED-based lighting
In Proc. SPIE,

system for acquiring multispectral scenes.
volume 8299, pages 82990P–82990P–8, 2012. 2

[28] M. Parmar and S. Reeves. Selection of optimal spectral sen-
sitivity functions for color ﬁlter arrays. IEEE Transactions
on Image Processing, 19(12):3190–3203, Dec 2010. 2
[29] Y. Saad. Projection and deﬂation method for partial pole
assignment in linear state feedback. IEEE Transactions on
Automatic Control, 33(3):290–297, 1988. 4

[30] Z. Sadeghipoor, Y. Lu, and S. Susstrunk. Optimum spectral
sensitivity functions for single sensor color imaging. In Proc.
SPIE, volume 8299, pages 829904–829904–14, 2012. 2

2172

[31] H.-L. Shen, H.-G. Zhang, J. Xin, and S.-J. Shao. Optimal se-
lection of representative colors for spectral reﬂectance recon-
struction in a multispectral imaging system. Applied Optics,
47(13):2494–2502, May 2008. 2

[32] C. Sigg and J. Buhmann. Expectation-maximization for
In Proceedings of the 25th
sparse and non-negative PCA.
International Conference on Machine Learning, pages 960–
967, 2008. 2

[33] V. Vu, J. Cho, J. Lei, and K. Rohe. Fantope projection and se-
lection: A near-optimal convex relaxation of sparse PCA. In
Advances in Neural Information Processing Systems, pages
2670–2678, 2013. 4

[34] B. Wandell. Foundations of Vision. Sinauer Associates,

1995. 1, 2

[35] F. Xiao, J. E. Farrell, J. M. DiCarlo, and B. A. Wandell. Pre-
ferred color spaces for white balancing. In Electronic Imag-
ing 2003, pages 342–350. International Society for Optics
and Photonics, 2003. 1

[36] R. Zass and A. Shashua. Nonnegative sparse PCA. Advances
in Neural Information Processing Systems, 19:1561, 2007. 2

2173

Designing illuminant spectral power distributions for surface classiﬁcation

Henryk Blasinski, Joyce Farrell, Brian Wandell
Department of Electrical Engineering, Stanford University
Stanford, CA
hblasins,joyce_farrell,wandell@stanford.edu

Abstract

There are many scientiﬁc, medical and industrial imag-
ing applications where users have full control of the scene
illumination and color reproduction is not the primary ob-
jective. For example, it is possible to co-design sensors and
spectral illumination in order to classify and detect changes
in biological tissues, organic and inorganic materials, and
In this paper, we propose two
object surface properties.
different approaches to illuminant spectrum selection for
surface classiﬁcation. In the ﬁrst approach, a supervised
framework, we formulate a biconvex optimization problem
where we alternate between optimizing support vector clas-
siﬁer weights and optimal illuminants. In the second ap-
proach, an unsupervised dimensionality reduction, we de-
scribe and apply a new sparse Principal Component Anal-
ysis (PCA) algorithm. We efﬁciently solve the non-convex
PCA problem using a convex relaxation and Alternating Di-
rection Method of Multipliers (ADMM). We compare the
classiﬁcation accuracy of a monochrome imaging sensor
with optimized illuminants to the classiﬁcation accuracy of
conventional RGB cameras with natural broadband illumi-
nation.

1. Introduction

The spectral power distribution of the illumination
source plays a fundamental role in how objects objects are
imaged and analyzed by a digital camera [34]. In consumer
digital photography, the spectral properties of scene illumi-
nation are unknown at capture and the main challenge in
color balancing (white balancing) is estimating the spectral
power of the illuminant [35].

There are many applications where color reproduction
is not the primary goal of imaging systems, for example
laparoscopic surgery, endoscopy, microscopy or industrial
quality control [4, 17]. In these cases the spectrum of light
is a design parameter that can be optimized for tasks such
as detecting object features or classifying surfaces [7]. De-
pending on the application it may be more advantageous to

Convenional
illuminant

Discriminative
illuminant

Figure 1: The spectral power distribution of the illuminant
has a big impact on the data captured by an imaging system.
It can be difﬁcult for a machine learning algorithm to dis-
criminate between a real and fake apple based on the data
from an RGB camera and broadband illumination (left).
In contrast a camera capturing the scene with customized
lights produces better data for discrimination (right) even
though the light optimal for feature discrimination or clas-
siﬁcation may not produce accurate color matching effects.

adjust the spectral power distribution of the illuminant to
enhance the visibility of features of interest, at the expense
of accurate color rendering. Speciﬁcally, scene data cap-
tured under natural, broadband light sources and with con-
ventional RGB cameras can be less useful in classiﬁcation
problems than the data acquired with monochrome cameras
and highly customized, narrowband illuminants (Fig. 1).
The customized set of illuminants will produce a more ro-
bust set of features that can be later leveraged by machine
learning algorithms to improve classiﬁcation performance.
In this paper we describe and evaluate two novel algo-
rithms to effectively and systematically search for spectral
power distributions of optimal lights that improve material
classiﬁcation. The lights are optimized for a particular clas-
siﬁcation task, for example apple classiﬁcation. We formu-
late the problem of illuminant spectral power distribution
selection in two different frameworks: supervised and un-
supervised learning. Our methods are designed to explicitly

2164

estimate spectral power distributions, rather than to select
the best illuminant from a given set. The methods are also
constrained to produce solutions that are physically realiz-
able.

In the supervised context we assume that the reﬂectance
data is labeled and we formulate a penalty function incor-
porating the image formation model, classiﬁer parameters,
and the spectral power distribution of light. Such an objec-
tive function is bi-convex and locally optimal solutions can
be found via alternating minimization.

In the unsupervised context we approach optimal illumi-
nant spectral power distribution design from the dimension-
ality reduction perspective. Here the objective is to project
high dimensional reﬂectance data onto a smaller number
of dimensions that preserve the information necessary for
classiﬁcation. Optimized projection directions better cap-
ture the characteristics of the underlying data preserving
more variance in the projected data set. Larger variance
in the data set generally translates to better performance of
the classiﬁcation algorithms. The classical algorithm for
dimensionality reduction is Principal Component Analysis
(PCA). This algorithm computes a set of orthogonal projec-
tion directions along which the variance in the data set is
the largest [12].

The space of physically realizable spectral power distri-
butions of light is limited by certain physical constraints.
First, light cannot be negative. Second, the shapes of the
spectrum cannot be arbitrary, typically these are smooth
functions. All these restrictions need to be taken into con-
sideration when searching for the optimal illuminant.

In summary, our contributions include:

• Two new algorithms optimizing the spectral power dis-
tributions of illuminants for classiﬁcation tasks and
producing distributions that can be generated with real
light sources.

• A new sparse nonnegative PCA algorithm with a single

tuning parameter.

• A framework for analyzing imaging system classiﬁca-
tion performance using different number and spectra
of optimized illuminants.

2. Related work

There exist few methods that solve the problem dis-
cussed in this paper. The most relevant algorithm is that
of Liu and Guo [21], who used cost function minimization
to select the color, position and intensity of LEDs in their
capture device that enhance material classiﬁcation accuracy.
Unlike the methods we describe, the authors do not analyze
the data in the wavelength domain and do not restrict their
solution to non-negative intensities.

Many other approaches involve brute force selection
strategies using exhaustive search over the entire parame-

ter space [26]. This is tractable for small problems, but the
complexity grows exponentially and thus makes the method
computationally impractical. One way to reduce the solu-
tion space of brute-force methods is to use genetic algo-
rithms [6]. The methods we present involve continuous
valued function minimization rather than search strategies
making them more computationally tractable.

Optimal light spectral power distribution selection shares
many similarities with camera responsivity design. Cam-
era responsivities, however, are most frequently optimized
for color matching tasks [14, 28, 30, 31], low light perfor-
mance [8, 19] or spectral reconstruction [25, 27]. The idea
of adapting camera spectral characteristics to the particular
properties of the imaged scene was presented in [20] where
the authors manually changed the characteristics of a liquid
crystal tunable ﬁlter (LCTF) as a function of the distribution
of scene radiance. In a similar effort [10] describe an adap-
tive spectroscopy algorithm which takes repeated measure-
ments of the scene and adjusts the sensitivity of the spec-
trometer as a function of prior observations. This approach
conditions the shape of optimal responsivity curves on the
results of earlier measurements and thus cannot be used to
derive a ﬁxed set of spectral curves independent of speciﬁc
measurement outcomes.

Dimensionality reduction techniques designed for hyper-
spectral data have been developed in the remote sensing
community [5, 16, 18]. In these applications the weights are
not constrained and are allowed to be negative and therefore
wavelength distributions of those weights do not represent
physically realizable light spectra.

The existing sparse PCA [1, 15, 24] or nonnegative
sparse PCA [32, 36] algorithms cannot be directly used to
design physically realizable illuminants. These methods do
not allow nonnegativity constraints on linearly transformed
variables, which is necessary to assure physical realizabil-
ity of optimized illuminant spectra. Some of the methods
are also impractical due to large numbers of tuning parame-
ters that need to be adjusted. We overcome these limitations
by proposing a new, ﬂexible nonnegative sparse PCA algo-
rithm with a single tuning parameter.

3. Image formation model

The response of a camera’s photodetector mj,k is a linear
function of the scene illuminant xk, surface reﬂectance r
and the spectral responsivity of the jth camera color channel
cj [34]

mj,k =

cj(λ)r(λ)xk(λ)dλ.

(1)

Z

For most natural images, the spectral curves are smooth
and slowly varying, therefore a discretization to n spectral
bands simpliﬁes modeling with little impact on the accuracy

mj,k = ∆λcT

j diag(r)xk = eT

j xk

(2)

2165

where ej = ∆λ(r1cj,1, r2cj,2, . . . .rncj,n), ej ∈ Rn is the
wavelength-wise product between the surface spectral re-
ﬂectance and the camera responsivity function of the jth
channel. In this work, we propose a method to choose the
vector xk, given a set of labeled or unlabeled vectors ej so
that those vectors projected onto a subspace spanned by xk,
k ∈ 1, . . . , K preserve the discriminative information from
e in m. A classiﬁcation algorithm then uses the projected
data m, i.e. pixel intensities, to derive decision boundaries
in this low dimensional subspace.

Spectral curves are often approximated using linear

models

x = Bw,

(3)

where the columns of B ∈ Rn×nb represent model compo-
nents and w ∈ Rnb are the corresponding weights. Model
components can be derived using two different approaches.
The ﬁrst approach takes advantage of the fact that spectrally
smooth curves lie on a low dimensional subspace [23]. The
span of this subspace is described by the columns of B,
which, by deﬁnition, form an orthogonal set, i.e. BT B = I.
This modeling usually aims to simplify the problem by re-
ducing the number of variables used to describe a light spec-
trum.

The second approach is to make columns of B directly
represent a collection of spectral power distributions of all
light sources the user controls. For example B can be cre-
ated from spectral power distributions of all LEDs on offer
by a manufacturer. The task now becomes selection of these
spectra that are optimal. In such cases B forms a dictionary
and often becomes ‘fat‘, i.e. contains more columns than
rows. This means that some of the dictionary entries are
linear combinations of each other, and BT B is no longer
full rank.

We assume that a physically realizable illuminant is non-
negative and that is spanned by the columns of B. Our ap-
proach to ﬁnding the optimal light does not rely on partic-
ular properties of B, speciﬁcally B can be ‘fat‘ and BT B
non-invertible.

We also note that if one could use a large number of il-
luminants (K ≥ n) the optimal strategy would be to pick
monochromatic lights. In this case, acquisition of K images
would correspond to capturing the full spectral characteris-
tic of the surface, as if imaged with a hyperspectral camera.
This means that in general, preferred solutions should have
little overlap across spectral channels, and many zero en-
tries.

4. Supervised framework

Many classical supervised learning algorithms attempt
to ﬁnd a set of hyperplanes that deﬁne boundaries between
points in the feature space representing different classes.

For example, to classify a set of vectors e with labels y, the
parameters describing separating hyperplanes θ are found
by minimizing a cost function f subject to constraints g on
those parameters

minimize f (θ; e, y)
subject to g(θ; e, y) ≤ 0.

(4)

(5)

Often the input data e are not guaranteed to be linearly sep-
arable in the original n dimensional space. The data may
be projected, using operator Φ(e), to a higher dimensional
space in which such linear separability can be achieved

minimize f (θΦ; Φ(e), y)
subject to g(θΦ, Φ(e), y) ≤ 0.

We note that in the context of optimal illumination design
the projection operator Φ naturally arises in the formula-
tion of the image formation model, though it projects data
to a subspace with fewer dimensions. Observe that the mea-
sured pixel intensities satisfy m = X T e = Φ(e), where the
columns of X = [x1, . . . , xK] represent the spectral power
distributions of K illuminants, and e are deﬁned as in (2).
The problem is to ﬁnd such linear projection directions X
that facilitate class separability in the Φ(e) vector space, i.e.
camera pixel measurement space.

To illustrate the approach, consider a classiﬁer where f
and g correspond to a multiclass, one-vs-all, Support Vector
Classiﬁer (SVC) [13]. The linear decision boundaries pt for
each of the t classes are given by a solution to the convex
optimization problem

minimize

kptk2

2 + C

ξt
i

Xt
Xi,t6=yi
yi Φ(ei) + byi ≥ pT
subject to pT
ξt
i ≥ 0,

i = 1, . . . , L,

t Φ(ei) + bt + 2 − ξt
i

t ∈ {1, . . . , T } \ yi,

(6)

where {yi, ei} represent
the label and the reﬂectance-
camera responsivity product of the ith data point respec-
tively with the size of the training set given by L. The scalar
C controls how many data points are allowed to be misclas-
siﬁed during training.

In order to ﬁnd the optimal illuminant spectral power dis-
tributions we re-formulate the SVC problem by replacing
the projection Φ(ei) = (BW )T ei and adding constraints
on the illuminant power distributions BW assuring physical
realizability. The resulting biconvex optimization problem

minimize

kpkk2

2 + C

ξk
i + αz(BW )

(7)

Xi,k6=yi

Xk
yi (BW )T ei + byi ≥ pT
subject to pT
ξk
i = 1, . . . , L,
i ≥ 0,
BW ≥ 0,

k (BW )T ei + bk + 2 − ξk
i
k ∈ {1, . . . , K} \ yi,

2166

can be solved through alternating minimization over p, b, ξ
and b, ξ, W . The matrix W describes the illuminant spec-
tra in terms of the linear basis weights (3). Note that the
cost function has been augmented with a function z, con-
trolled with a tuning parameter α, penalizing certain types
of solutions. We promote sparsity with an l1 penalty

z(X) = kXk1 =

|xi,j|

(8)

Xi,j

where the l1 norm is generalized to matrices and computes
the sum of the absolute values of all matrix entries.

5. Unsupervised framework

Principal Component Analysis (PCA) is a standard tech-
nique used in machine learning to compactly represent a
data set. The PCA algorithm ﬁnds a set of projection vec-
tors along which the original data has the largest variance.
These projections are given by the principal eigenvectors
of the data set covariance matrix. In the context of illumi-
nant spectrum selection, we note that the measured pixel
intensity represents the projection of the reﬂectance-camera
responsivity product onto a vector describing the spectral
distribution of the illuminant.

For convenience, we express PCA as an iterative algo-
rithm. Let Σ ∈ Sn
+ represent the positive semi-deﬁnite sam-
ple covariance matrix of vectors e from (2). The ith optimal
PCA direction is a solution to the problem

where Σ(i−1) is the covariance matrix estimate from the
previous step. Before proceeding to the next iteration Σ
needs to be recomputed to account for the removal of the
solution dimension (i.e. deﬂated).

The iterative PCA algorithm can be modiﬁed to produce
nonnegative and sparse directions by introducing additional
constraints into the optimization problem (9)

i.e. relaxation. For example, using the PCA relaxations de-
scribed in [9, 33], the original nonconvex problem can be
approximated with

maximize
subject to

tr(ΣX) − αkXk1
0 (cid:22) X (cid:22) I,
tr(X) = 1
X ≥ 0

(11)

(we drop the superscript (i − 1) for clarity). The function
tr(X) is the trace operator, i.e. the sum of the entries of
X along the diagonal, and α controls the sparsity enforcing
penalty.

The ﬁrst constraint forces X to be positive, semi-deﬁnite
and X − I to be negative, semi-deﬁnite. The last constraint
restricts the solution to a set of matrices with nonnegative
entries. The optimal projection direction is given by the
principal eigenvector of a solution X ⋆ = x⋆x⋆T . Note that
the matrix entry-wise inequality enforces all the entries of
x⋆ to have the same sign, therefore if x⋆ is a solution so is
−x⋆.

In order to express the PCA problem in terms of the basis
weights, X = xxT = Bw(Bw)T = BW BT is substituted
into (11) yielding

maximize
subject to

tr(ΣBW BT ) − αkBW BT k1
0 (cid:22) BW BT (cid:22) I,
tr(BW BT ) = 1
BW BT ≥ 0,

(12)

The above optimization problem can be efﬁciently
solved using the Alternating Direction Method of Multi-
pliers (ADMM) [3, 33]. The computational steps of this
approach are summarized in Algorithm 1, derivation details
are available in the Supplemental Material. This algorithm
requires the user to provide the desired accuracy ǫ and a
learning rate ρ. Following the recommendation of [33] we
used an update heuristic proposed in [3]. It may happen that
the function computing the largest eigenvector of Y (t+1)
will return a vector with all nonpositive entries. In this case
the sign of such a solution should be reversed.

1

maximize xT Σ(i−1)x
subject to xT x = 1

card(x) ≤ δ
x ≥ 0,

(10)

5.2. Matrix deﬂation

where δ is a sparsity parameter and card(x) speciﬁes the
number of nonzero entries in x. Equation (10) is nonconvex
due to the incorporation of sparsity and nonnegativity con-
straints. Hence, eigen decomposition is no longer a valid
method for ﬁnding a solution.

5.1. Convex relaxation

A useful approach to solving nonconvex problems is to
perform an approximation with a similar convex problem

The iterative approach to PCA makes it necessary to de-
ﬂate the current sample covariance matrix estimate Σ(i−1)
before proceeding to the next iteration. The commonly used
Hotelling’s deﬂation scheme may not preserve the semideﬁ-
niteness of Σ(i) if the projection direction xi is not an eigen-
vector of Σ(i−1) [29]. To avoid such issues we used a gen-
eralized deﬂation algorithm proposed in [22]. Algorithm 2
summarizes this deﬂation method and outlines the steps re-
quired to compute r sparse nonnegative PCA directions for
a particular data set.

maximize xT Σ(i−1)x
subject to xT x = 1,

(9)

where W = wwT .

2167

Algorithm 1 Single nonnegative sparse PCA direction.

function FINDDIRECTION(Σ,B, α, ǫ, ρ)
2 ← 0, U (0)

1 ← 0, Y (0)

Y (0)
1 ← 0, U (0)
repeat

2 ← 0

kBW BT − Y (t)

W (t+1) ← arg min
Y (t+1)
1
U (t+1)
1 ← U (t)
t ← t + 1

(cid:16)
← PF (BW (t+1)BT + U (t)
1 + W (t+1) − Y (t+1)

1

,

1 + U (t)
1 + Σ/ρ),

1 k2

F + kBW BT − Y (t)

2 + U (t)

2 k2
F

(cid:17)

Y (t+1)
2
U (t+1)
2 ← U (t)

← Hα/ρ(BW (t+1)BT + U (t)
2 )

2 + BW (t+1)BT − Y (t+1)

2

until max{kBW (t+1)BT − Y (t+1)

F , ρ2kY (t+1)
k2
corresponding to the largest eigenvalue.

F , kBW (t+1)BT − Y (t+1)
k2

1

1

2

return Eigenvector of Y (t+1)
end function

1

− Y (t)

1 k2

F }, ρ2kY (t+1)

2

− Y (t)

2 k2

F } ≤ ǫ

Algorithm 2 Nonnegative sparse PCA
Require: Σ ∈ Sn

+, α ≥ 0, ǫ ≥ 0, ρ ≥ 0, r ∈ N, B

Q(0) ← I, Σ(0) ← Σ
for t = 1, . . . , r do

xt ← FINDDIRECTION(Σ(t−1),B, α, ǫ, ρ)
qt ← Q(t−1)xt
t )Σ(t−1)(I − qtqT
Σ(t) ← (I − qtqT
t )
Q(t) ← Q(t−1)(I − qtqT
t )
xt ← xt/kxtk

1.4

1.2

1

0.8

0.6

0.4

0.2

0
400

end for
return x1, . . . , xr

6. Experiments

To evaluate the proposed approaches we conducted a set
of experiments where we captured images of known test tar-
gets under different illumination conditions and used stan-
dard machine learning algorithms to classify captured data.
We implemented all computations in Matlab, and our code
repository is available online1.

First, we measured the performance of classiﬁcation al-
gorithms on data captured with conventional RGB cameras
and under a single broadband illuminant. This condition
represents the typical imaging scenario where a color cam-
era with three types of color pixels is used to capture a single
image in natural lighting conditions (i.e. J = 3, K = 1).
Overall, we evaluate the performance of 34 cameras with
different spectral properties (see Supplemental Material for
the list of evaluated camera models). For simplicity we will
refer to this mode of data capture as conventional camera.
Next, we captured the data using a monochrome cam-
era and optimized illuminants.
To make comparisons
between conventional and optimized systems meaning-
ful we projected spectral measurements onto a three-
dimensional space. To obtain this representation with our
optimized setup we captured three successive frames with a

Captured

500

600
Wavelength, nm

Emulated

700

800

Figure 2: A comparison between spectral properties of a
GoPro Hero 5 RGB camera (solid lines) and their approxi-
mation with narrowband lights (dashed lines). For a given
scene, pixel values produced by an RGB camera (inset, cap-
tured) can be reproduced with a mochorome camera and ap-
propriately adjusted narrowband lights that match the spec-
tral responsivities of the camera (inset, emulated).

monochrome camera, each under different, optimized light
(i.e. J = 1, K = 3) derived with either supervised or unsu-
pervised approach. We refer to this capture mode as optimal
camera.

We investigated a simple classiﬁcation task; assigning
labels to image pixels based on raw image data. We origi-
nally designed these algorithms for use with biological mul-
tispectral data, however for presentation clarity we chose
much simpler targets requiring no domain speciﬁc knowl-
edge.
In our tests we used genuine and visually similar
artiﬁcial fruit pairs: apples, pears and lemons. Our goal
was to discriminate between different objects. For this pur-
pose we constructed three test scenes. Two of them con-
tained two pairs of differently colored fruit of the same type;
red and green apples (Apples) and yellow and green pears
(Pears). The Lemons scene contained a single pair of ob-
jects; lemons.

Scenes were assembled in a Thouslite LEDCube2 light
booth. The LEDCube contained three broadband and eight
narrowband LEDs whose intensities could be independently

1https://github.com/hblasins/optIll

2http://www.thouslite.com/show.asp?id=16

2168

s
r
a
e
P

s
e
l
p
p
A

s
n
o
m
e
L

500

600
Wavelength, nm

700

800

500

600
Wavelength, nm

700

800

500

600
Wavelength, nm

700

800

500

600
Wavelength, nm

700

800

1

0.8

0.6

0.4

0.2

0.8

0.6

0.4

0.2

0.8

0.6

0.4

0.2

0
400

1

0
400

1

0
400

(a) RGB Image

(b) RGB
classiﬁcation

(c) Unsupervised
classiﬁcation

(d) Unsupervised
spectra

(e) Supervised
classiﬁcation

500

600
Wavelength, nm

700

800

500

600
Wavelength, nm

700

800

(f) Supervised
spectra

Figure 3: Pixel classiﬁcation accuracy is increased when the scene is illuminated with optimal lights. Columns present the
RGB rendering of the scene (a), pixel classiﬁcation maps for conventional illumination (b), and optimal lights derived with
unsupervised (c) and supervised (e) approaches. Color in (b, c, e) encodes pixels where the SVM classiﬁer assigned correct
labels, all errors are not represented. The spectral power distributions of the optimal illuminants (d, f, thick lines) overlap
with areas of increased variability in the surface spectral reﬂectance (d, f, thin lines).

adjusted thus changing the overall spectrum of the illumi-
nant. The spectral power distributions of the individual
LEDs formed columns in the model matrix B (3).

We measured the surface spectral reﬂectance of all tar-
gets as well as spectral power distributions of the LEDs in
the 400 to 800nm range at 4nm increments using a Spec-
traScan PR715 spectrophotometer. We calibrated the LED-
Cube LED spectra by taking measurements of the light ra-
diance reﬂected from a reference white, Spectralon test tar-
get. Similarly, we estimated the surface spectral reﬂectance
by illuminating the surface of fruits with broadband tung-
sten light, taking 10 radiance measurements followed by
one measurement of a Spectralon sample, and by computing
the ratio between the two at every wavelength [2].

Given a set of reﬂectance curves we used the supervised
and unsupervised approaches to generate optimal illumi-
nants for a particular setting of algorithm tuning parameters.
We then programmed those spectra into the LEDCube and
captured images of the so illuminated target with a Point-
Grey FL3-U3-13Y3M-C, 1.3MP monochrome camera with
a Schneider Optics Xenoplan 1.4/23mm lens. The aperture
was set to f#/11 in order to limit depth of ﬁeld effects.

Next, we manually segmented 100 × 100 (200 × 200 for
binary classiﬁcation) pixel regions of interest (ROI) within
each fruit sample and used this set for classiﬁcation. The
classiﬁers used single pixel intensity data. The data was

split into training (70%) and test (30%) sets using the strati-
ﬁed approach, i.e. preserving the distribution of class labels
[11]. For fairness of comparisons we preserve data separa-
tion across all classiﬁers and conditions. In our evaluations
we used ﬁve standard machine learning classiﬁers: Sup-
port Vector Machines (SVM), K-Nearest Neighbors (KNN),
Linear Discriminant Analysis (DA), Decision Trees (Tree)
and Naive Bayes (NB).

Finally, we repeated the procedure; optimal illuminant
computation followed by image capture and classiﬁer cross
validation, for different settings of illuminant selection al-
gorithms tuning parameters (refer to source code for de-
tails). In all cases training data set was used for training
and parameter selection only, and all performance numbers
we report were calculated using the test set.

Rather than using physical RGB cameras in our evalu-
ations, we instead emulated their spectral properties with
narrowband LEDs from LEDCube and the PointGrey
monochrome camera. We approximated the effective spec-
tral responsivity (i.e. the wavelength-wise product between
spectral responsivity and the illuminant) of red, green and
blue camera channels with an appropriate weighted sum of
the LEDCube LEDs, accounting for the monochrome sen-
sor quantum efﬁciency (see Supplemental Material for de-
tails). Figure 2 shows an example comparison between the
actual responsivity curves and their approximations using

1

0.8

0.6

0.4

0.2

0.8

0.6

0.4

0.2

0.8

0.6

0.4

0.2

0
400

1

0
400

1

0
400

2169

Table 1: Single pixel per cent classiﬁcation accuracy for the
Pears data (four-way classiﬁcation).

Table 2: Single pixel per cent classiﬁcation accuracy for the
Apples data (four-way classiﬁcation).

Camera

RGB (worst)
RGB (avg.)
RGB (best)
Ours (Unsup.)
Ours (Sup.)

Classiﬁer

SVM KNN
92.7
92.3
95.2
94.6
98.4
98.4
97.9
97.2
99.9
99.9

DA
91.2
93.6
97.9
96.9
98.9

Tree
90.7
94.1
97.8
97.8
99.8

NB
66.0
67.8
74.2
82.8
76.6

Camera

RGB (worst)
RGB (avg.)
RGB (best)
Ours (Unsup.)
Ours (Sup.)

Classiﬁer

SVM KNN
78.4
75.2
82.3
84.6
83.3
85.6
89.4
87.1
92.6
91.5

DA
74.9
84.1
85.3
86.4
91.2

Tree
73.6
84.2
85.8
89.2
91.2

NB
66.0
68.7
72.7
83.7
79.5

LEDs. Insets in this ﬁgure present an image of a Macbeth
chart captured with a conventional RGB camera and com-
pares it to a view of the same chart rendered with the data
from the proposed emulation approach.

There are several advantages to using the emulation ap-
proach. First, the geometry of the setup remains ﬁxed
and any differences between various test conditions arise
only from illumination rather than image alignment or re-
sampling between different cameras. Second, the same sen-
sor is used throughout all experiments and so the noise
properties remain ﬁxed. Finally, the resolution and optics
remain constant throughout all experiments.

6.1. Classiﬁcation performance

Figure 3 presents the results of pixel classiﬁcation out-
comes for three test scenes captured under daylight and op-
timized illuminants. Classiﬁcation maps were created by
applying classiﬁers trained on the training data to all pixels
in the image. For clarity we show and label only correctly
identiﬁed pixels.
In general, maps obtained for the opti-
mized illumination cases correctly classify larger number
of pixels. We also observed that those maps have more con-
tiguous object segmentation and less ’salt and pepper’ clas-
siﬁcation noise. However, the optimal illuminant selection
strategies do not always increase the number of correctly
classiﬁed pixels. They can also make some pixels easier to
classify at the expense of others. Take the Apple scene as
an example. Under optimized illuminants the increased ac-
curacy in recognizing the bottom right apple (green label)
is offset by erroneously classifying parts of the bottom left
apple (purple label) that had been correctly classiﬁed by a
conventional camera.

We also present the optimal illuminant spectra derived
for each condition (Fig. 3d and 3f). The curves derived
by supervised and unsupervised approaches differ, but they
share a common characteristic.
In all cases light energy
is concentrated at wavelengths with signiﬁcant amount of
variability in the surface reﬂectance data.
The quantitative performance of

the proposed ap-
proaches is presented in Tables 1, 2 and 3 which summarize
the pixel based classiﬁcation accuracy achieved with the op-

Table 3: Single pixel per cent classiﬁcation accuracy for the
Lemons data (binary classiﬁcation).

Camera

RGB (worst)
RGB (avg.)
RGB (best)
Ours (Unsup.)
Ours (Sup.)

SVM
92.2
97.5
99.9
99.8
100.0

Classiﬁer

KNN
96.4
99.0
100.0
99.8
100.0

DA
90.0
96.3
99.8
99.6
99.9

Tree
85.9
96.6
99.9
98.3
98.8

NB
58.8
62.0
75.6
63.1
70.9

timal and conventional cameras. For every classiﬁcation al-
gorithm, we report the average accuracy computed over 34
RGB cameras as well as the accuracy of the best and worst
performing model for a particular algorithm. The model
of the camera achieving the highest classiﬁcation accuracy
varied across different scenes and classiﬁers. This metric
represents the performance of illuminant spectral power dis-
tributions found using a brute force search algorithm and
serves as a baseline for comparisons with our methods.

We experimented with illuminating our scenes with the
emission spectra of black body radiators at different tem-
peratures; 2000, 4000, 6500, and 10000K. These spectra of-
fer good approximations to light distributions occurring in
natural environments. For a particular classiﬁcation algo-
rithm, performance differences between these illuminants
were minor (see Supplemental Material for details). The
black body emission at 6500K closely resembles the stan-
dard D65 illuminant (daylight), and in general provided
the best, or close second best classiﬁcation accuracy. Fur-
thermore, many conventional RGB cameras are designed
to faithfully reproduce colors speciﬁcally under this illumi-
nant. For these reasons we use this condition as reference
in numerical comparisons.

The imaging system using illuminant spectral power dis-
tributions derived with our supervised method consistently
outperforms conventional RGB cameras and broadband il-
luminants for the SVM, KNN, DA and Tree classiﬁcation
algorithms. It comes second only when the Tree classiﬁer
is applied to the Lemons scene. These gains are due to direct

2170

incorporation of the search for optimal spectra into the clas-
siﬁcation objective function, and are achieved despite non-
convexity of the problem and local optimality of the solu-
tion. Interestingly, the supervised selection method is typ-
ically outperformed by a combination of the Naive Bayes
classiﬁer with the unsupervised approach.

Our unsupervised selection method is better than the av-
erage conventional RGB camera, and its accuracy is typi-
cally on par with that of the best RGB camera. Note that this
selection strategy works best together with a Naive Bayes
classiﬁer. The unsupervised approach is a variant of PCA,
which provides a set of uncorrelated features. In our case
we use a constrained version; it also decorrelates data, but
to a lesser extent. The Naive Bayes classiﬁer implicitly as-
sumes feature conditional independence, which means that
the unsupervised approach provides the type of data the
classiﬁer expects.

6.2. Number of illuminants

We investigated the relationship between classiﬁcation
accuracy and the number of different illuminants under
which a scene is captured. Optimization over the illumi-
nant spectrum offers another system design parameter. For
example, a suitable illuminant could eliminate the need for
a color ﬁlter array thus increasing the effective sensor reso-
lution.

Increasing the number of optimal illuminants from 1 to
10 increases the classiﬁcation performance, irrespective of
the selection method used. Figure 4 presents the classiﬁ-
cation accuracy in the Apples set as a function of the num-
ber of optimal illuminants. The supervised selection algo-
rithm maintains a small advantage over the unsupervised
approach across all conditions. The classiﬁcation accuracy
asymptotes at about 95%, ten percentage points above the
accuracy of the best conventional RGB camera. However,
at about 3–4 illuminants the curves plateau; using more il-
luminants offers modest gains in performance that may not
be worth pursuing given other limitations such as acquisi-
tion time. Note that the classiﬁcation accuracy of an opti-
mal two-illuminant system, i.e. representing pixel data with
two numbers, is comparable to that of the best conventional
RGB camera and a broadband illuminant, which represent
pixel data with three numbers. Both systems achieve about
86% classiﬁcation accuracy. This reduction in data dimen-
sionality can translate to smaller data storage requirements
or fewer processor cycles necessary for computation.

100

95

90

85

80

75

70

%

 
,
y
c
a
r
u
c
c
a
 
n
o
i
t
a
c
i
f
i
s
s
a
C

l

Best RGB camera

Unsupervised
Supervised

1

2

3

4

5

6

7

8

9

10

Number of illuminants

Figure 4: Pixel classiﬁcation accuracy increases when a
scene (Apples) is captured under more optimized illumi-
nants, with supervised selection outperforming the unsu-
pervised algorithm. Using just two optimally chosen lights
allows to achieve the performance level of a conventional,
three channel RGB system.

produce physically realizable distributions that can be gen-
erated using off-the-shelf LEDs.

We evaluated the optimal lights produced by our selec-
tion methods in a simple surface classiﬁcation task through
a series of laboratory experiments using real targets, illumi-
nants, and cameras. In all cases classiﬁer performance on
pixel data obtained under optimized lights is greater than the
performance of the same algorithm on data captured with a
conventional RGB camera and broadband illuminants. We
showed that the supervised selection method achieves the
best performance, but it requires a set of labeled training re-
ﬂectance spectra. In comparison the unsupervised method
is a close second in terms of accuracy, but can work with
unlabeled object spectral reﬂectance curves.

Both algorithms are useful in analyzing the impact of
additional imaging channels on classiﬁcation performance.
This is an important consideration because, we have shown,
under the constraints of physical realizability having more
channels may provide only modest performance gains that
may be deemed not worth pursuing given the increased sys-
tem complexity and other design trade-offs such as speed,
resolution or computation.

Finally, the methodology we present in this work can be
extended to other spectral selection problems in imaging
system design. For example, the same algorithms can be
applied to selecting the responsivity functions of the color
ﬁlter array or could be used to select transmissive ﬁlters for
biological image analysis.

7. Conclusions

Acknowledgements

We presented two new approaches to selecting spectral
power distributions of illuminants used during the image
capture process that increase the accuracy of pixel classi-
ﬁcation algorithms applied to captured data. Our methods

The authors would like to thank Gordon Wetzstein from
Stanford University for helpful comments and discussions
during the preparation of the manuscript. The LEDCube
image booth was a gift from Thouslite.

2171

References

[1] A. Amini and M. Wainwright. High-dimensional analysis of
semideﬁnite relaxations for sparse principal components. In
IEEE International Symposium on Information Theory ISIT,
pages 2454–2458, 2008. 2

[2] H. Blasinski, J. Caves, J. Farrell, B. Wandelt, and P. Wang.
Multispectral imaging of tissue ablation. In IEEE Interna-
tional Symposium on Biomedical Imaging, ISBI, pages 360–
363, April 2016. 6

[3] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein. Dis-
tributed optimization and statistical learning via the alternat-
ing direction method of multipliers. Foundations and Trends
in Machine Learning, 3(1):1–122, 2011. 4

[4] J. Cadeddu, R. Fernandez, M. Desai, R. Bergs, C. Tracy, S.-
J. Tang, P. Rao, M. Desai, and D. Scott. Novel magneti-
cally guided intra-abdominal camera to facilitate laparoen-
doscopic single-site surgery: initial human experience. Sur-
gical endoscopy, 23(8):1894–1899, 2009. 1

[5] C. Chang, Q. Du, T. Sun, and M. Althouse. A joint band pri-
oritization and band decorrelation approach to band selection
IEEE Transactions
for hyperspectral image classiﬁcation.
on Geoscience and Remote Sensing, 37(6):2631–2641, Nov
1999. 2

[6] C. Chi, H. Yoo, and M. Ben-Ezra. Multispectral imaging by
optimized wide band illumination. International Journal of
Computer Vision, 86(2–3):140–151, 2010. 2

[7] J. Choi, S. Park, J. Cho, and E. Yoon. A 3.4-µ w object-
adaptive CMOS image sensor with embedded feature extrac-
tion algorithm for motion-triggered object-of-interest imag-
IEEE Journal of Solid-State Circuits, 49(1):289–300,
ing.
Jan 2014. 1

[8] L. Condat. A new color ﬁlter array with optimal properties
for noiseless and noisy color image acquisition. IEEE Trans-
actions on Image Processing, 20(8):2200–2210, Aug 2011.
2

[9] A. d’Aspremont, L. El Ghaoui, M. Jordan, and G. Lanck-
riet. A direct formulation for sparse PCA using semideﬁnite
In Neural Information Processing Systems,
programming.
volume 16, pages 41–48, 2004. 4

[10] D. Dinakarababu, D. Golish, and M. Gehm. Adaptive fea-
ture speciﬁc spectroscopy for rapid chemical identiﬁcation.
Optics express, 19(5):4595–4610, 2011. 2

[11] G. Forman and M. Scholz. Apples-to-apples in cross-
validation studies: pitfalls in classiﬁer performance measure-
ment. ACM SIGKDD Explorations Newsletter, 12(1):49–57,
2010. 6

[12] T. Hastie, R. Tibshirani, and J. Friedman. The elements of

statistical learning. Springer, 2009. 2

[13] C.-W. Hsu and C.-J. Lin. A comparison of methods for multi-
class support vector machines. IEEE Transactions on Neural
Networks, 13(2):415–425, 2002. 3

[14] F. Imai, S. Quan, M. Rosen, and R. Berns. Digital camera
ﬁlter design for colorimetric and spectral accuracy. In Pro-
ceedings of the 3rd International Conference on Multispec-
tral Color Science, pages 23–26, 2001. 2

[15] M. Journee, Y. Nesterov, P. Richtarik, and R. Sepulchre.
Generalized power method for sparse principal component

analysis.
11:517–553, 2010. 2

The Journal of Machine Learning Research,

[16] N. Keshava. Distance metrics and band selection in hyper-
spectral processing with applications to material identiﬁca-
tion and spectral libraries. IEEE Transactions on Geoscience
and Remote Sensing, 42(7):1552–1565, July 2004. 2
[17] S. Kukkonen, H. Kalviainen, and J. Parkkinen. Color fea-
tures for quality control in ceramic tile industry. Optical En-
gineering, 40(2):170–177, 2001. 1

[18] S. Kumar, J. Ghosh, and M. Crawford. Best-bases fea-
ture extraction algorithms for classiﬁcation of hyperspectral
data. IEEE Transactions on Geoscience and Remote Sensing,
39(7):1368–1379, Jul 2001. 2

[19] H. Kuniba and R. S. Berns. Spectral sensitivity optimization
of color image sensors considering photon shot noise. Jour-
nal of Electronic Imaging, 18(2):023002–023002–14, 2009.
2

[20] A. Lin and F. Imai. Efﬁcient spectral imaging based on imag-
ing systems with scene adaptation using tunable color pixels.
In Color and Imaging Conference, volume 2011, pages 332–
338. Society for Imaging Science and Technology, 2011. 2

[21] C. Liu and J. Gu. Discriminative illumination: Per-pixel clas-
siﬁcation of raw materials based on optimal projections of
IEEE Transactions on Pattern Analysis and
spectral brdf.
Machine Intelligence, 36(1):86–98, 2014. 2

[22] L. Mackey. Deﬂation methods for sparse PCA. In Neural
Information Processing Systems, volume 21, pages 1017–
1024, 2008. 4

[23] L. T. Maloney and B. A. Wandell. Color constancy: a method
for recovering surface spectral reﬂectance. Journal of the
Optical Society of America A, 3(1):29–33, 1986. 3

[24] B. Moghaddam, Y. Weiss, and S. Avidan. Generalized spec-
tral bounds for sparse LDA. In Proceedings of the 23rd in-
ternational conference on Machine learning, pages 641–648.
ACM, 2006. 2

[25] Y. Monno, T. Kitao, M. Tanaka, and M. Okutomi. Optimal
spectral sensitivity functions for a single-camera one-shot
multispectral imaging system. In IEEE International Con-
ference on Image Processing, ICIP, pages 2137–2140, 2012.
2

[26] J. Park, M. Lee, M. D. G., and S. Nayar. Multispectral imag-
In IEEE International
ing using multiplexed illumination.
Conference on Computer Vision, ICCV, pages 1–8, Oct 2007.
2

[27] M. Parmar, S. Lansel, and J. Farrell. An LED-based lighting
In Proc. SPIE,

system for acquiring multispectral scenes.
volume 8299, pages 82990P–82990P–8, 2012. 2

[28] M. Parmar and S. Reeves. Selection of optimal spectral sen-
sitivity functions for color ﬁlter arrays. IEEE Transactions
on Image Processing, 19(12):3190–3203, Dec 2010. 2
[29] Y. Saad. Projection and deﬂation method for partial pole
assignment in linear state feedback. IEEE Transactions on
Automatic Control, 33(3):290–297, 1988. 4

[30] Z. Sadeghipoor, Y. Lu, and S. Susstrunk. Optimum spectral
sensitivity functions for single sensor color imaging. In Proc.
SPIE, volume 8299, pages 829904–829904–14, 2012. 2

2172

[31] H.-L. Shen, H.-G. Zhang, J. Xin, and S.-J. Shao. Optimal se-
lection of representative colors for spectral reﬂectance recon-
struction in a multispectral imaging system. Applied Optics,
47(13):2494–2502, May 2008. 2

[32] C. Sigg and J. Buhmann. Expectation-maximization for
In Proceedings of the 25th
sparse and non-negative PCA.
International Conference on Machine Learning, pages 960–
967, 2008. 2

[33] V. Vu, J. Cho, J. Lei, and K. Rohe. Fantope projection and se-
lection: A near-optimal convex relaxation of sparse PCA. In
Advances in Neural Information Processing Systems, pages
2670–2678, 2013. 4

[34] B. Wandell. Foundations of Vision. Sinauer Associates,

1995. 1, 2

[35] F. Xiao, J. E. Farrell, J. M. DiCarlo, and B. A. Wandell. Pre-
ferred color spaces for white balancing. In Electronic Imag-
ing 2003, pages 342–350. International Society for Optics
and Photonics, 2003. 1

[36] R. Zass and A. Shashua. Nonnegative sparse PCA. Advances
in Neural Information Processing Systems, 19:1561, 2007. 2

2173

