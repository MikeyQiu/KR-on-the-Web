McDiarmid Drift Detection Methods
for Evolving Data Streams

Ali Pesaranghader 1 ((cid:66)), Herna L. Viktor 1, Eric Paquet 1,2
1 School of Electrical Engineering and Computer Science,
University of Ottawa, Ottawa, ON K1N 6N5, Canada
{apesaran, hviktor}@uottawa.ca

2 National Research Council,
1200 Montreal Roard, Ottawa, ON K1A 0R6, Canada
eric.paquet@nrc-cnrc.gc.ca

8
1
0
2
 
n
a
J
 
7
1
 
 
]
L
M

.
t
a
t
s
[
 
 
2
v
0
3
0
2
0
.
0
1
7
1
:
v
i
X
r
a

Abstract—Increasingly, Internet of Things (IoT) domains, such
as sensor networks, smart cities, and social networks, generate
vast amounts of data. Such data are not only unbounded and
rapidly evolving. Rather, the content thereof dynamically evolves
over time, often in unforeseen ways. These variations are due
to so-called concept drifts, caused by changes in the underlying
data generation mechanisms. In a classiﬁcation setting, concept
drift causes the previously learned models to become inaccurate,
unsafe and even unusable. Accordingly, concept drifts need to
be detected, and handled, as soon as possible. In medical appli-
cations and emergency response settings, for example, change
in behaviours should be detected in near real-time, to avoid
potential loss of life. To this end, we introduce the McDiarmid
Drift Detection Method (MDDM), which utilizes McDiarmid’s
inequality [1] in order to detect concept drift. The MDDM
approach proceeds by sliding a window over prediction results,
and associate window entries with weights. Higher weights are
assigned to the most recent entries, in order to emphasize their
importance. As instances are processed, the detection algorithm
compares a weighted mean of elements inside the sliding window
with the maximum weighted mean observed so far. A signiﬁcant
difference between the two weighted means, upper-bounded by
the McDiarmid inequality, implies a concept drift. Our extensive
experimentation against synthetic and real-world data streams
show that our novel method outperforms the state-of-the-art.
Speciﬁcally, MDDM yields shorter detection delays as well as
lower false negative rates, while maintaining high classiﬁcation
accuracies.

I. INTRODUCTION

Traditionally, machine learning algorithms assume that data
are generated by a stationary distribution and collected prior
to learning. These assumptions are not valid in evolving
environments, where the underlying distributions may change
over time: a phenomenon known as concept drift [2], [3]. As
a consequence, classiﬁcation accuracy decreases as concept
drifts take place. Therefore, adaptation to new distributions
is essential to ensure the efﬁciency of the decision-making
process. An adaptive learning algorithm may utilize a drift
detection method for detecting concept drifts in a data stream
[2]. Once the drift detector signals the presence of a concept
drift,
the learning algorithm updates its current model by
considering the new distribution. For the learning process to be
efﬁcient, the drift detector must detect concept drifts rapidly,

while maintaining low false negative and false positive rates.
In this paper, we introduce the McDiarmid Drift Detection
Method (MDDM) which applies the McDiarmid inequality
[1] and various weighting schemes in order to rapidly and
efﬁciently detect concept drifts. Through numerous experi-
ments, we show that MDDM ﬁnds abrupt and gradual concept
drifts with shorter delays and with lower false negative rates,
compared to the state-of-the-art.

This paper is organized as follows. Data stream classiﬁca-
tion and concept drift are formally deﬁned in Sections II and
III, respectively. Section IV describes adaptive learning as a
form of incremental learning from evolving data streams. Sec-
tion V reviews the state-of-the-art for concept drift detection.
In Section VI, we introduce the McDiarmid Drift Detection
Methods (MDDMs). Next, in Section VII, our approaches are
compared with the start-of-the-art for both synthetic and real-
world data streams. We conclude the paper and discuss future
work in Section VIII.

II. DATA STREAM CLASSIFICATION

The primary objective of data stream classiﬁcation is to
incrementally, using the (current) available
build a model
data, the so-called training data, for predicting the label of
unseen examples. Data stream classiﬁcation may be deﬁned
as follows:

Let a stream S be a sequence of
instances:
(X1, y1), (X2, y2), ..., (Xt, yt) . The pair (Xt, yt) rep-
resents an instance arriving at time t, where Xt is a
vector containing k attributes: Xt = (x1, x2, ..., xk),
while yt is a class label which belongs to a set
of size m, yt ∈ {c1, c2, ..., cm}. Assume a target
function yt = f (Xt) which maps an input vector to
a particular class label. The learning task consists of
incrementally building a model ˜f that approximates
the function f at all time. Naturally, an approxima-
tion which maximizes the classiﬁcation accuracy is
preferred [4].

Bifet et al. [3] recommend that incremental learning algo-
rithms should fulﬁll four essential requirements for data stream
mining: (1) the examples should be processed one-by-one and

only once in the order of their arrival, (2) memory usage
should be constrained as the size of a data stream is typically
substantially larger than the size of the available memory, (3)
all the calculations should be performed in real-time or at least,
in near real-time, and (4) the outcome of the classiﬁcation
process should be available at any time.

III. CONCEPT DRIFT DEFINITION

The Bayesian Decision Theory is commonly employed
in describing classiﬁcation processes based on their prior
i.e. p(y), and the class
probability distribution of classes,
conditional probability distribution, i.e. p(X|y) [2], [5]. The
classiﬁcation decision is related to the posterior probabilities
of the classes. The posterior probability associated with class
ci, given instance X, is obtained by:

p(ci|X) =

p(ci) · p(X|ci)
p(X)

where p(X) = (cid:80)m
i=1 p(ci) · p(X|ci) is the marginal probability
distribution. Formally, if a concept drift occurs in between
time t0 and t1 we have:

∃X : pt0 (X, y) (cid:54)= pt1 (X, y)

(2)

where pt0 and pt1 represent the joint probability distributions
at time t0 and t1, respectively [2]. Eq. (2) implies that the
data distribution at times t0 and t1 are distinct, as their joint
probabilities differ. From Eq. (1), it may be observed that a
concept drift may occur [2]:

• As a result of a change in the class conditional probability

p(y),

distribution p(X|y),

• As a result of a change in the posterior probability dis-
tribution p(y|X), thus affecting the classiﬁcation decision
boundaries.

Gama et al. [2], ˇZliobait˙e [5], and Krempl et al. [6] classify
changes into two types, namely real concept drift and virtual
concept drift. A real concept drift refers to the changes in
p(y|X) which affects the decision boundaries or the target
concept (as shown in Fig. 1 (b)). On the other hand, virtual
drift is the result of a change in p(X), and subsequently in
p(X|y), but not in p(y|X). That is, a virtual drift is a change
in the distribution of the incoming data which implies that
the decision boundaries remain unaffected (as in Fig. 1 (c)).
From a predictive perspective, adaptation is required once a
real concept drift occurs, since the current decision boundary
turns out to be obsolete [2], [6].

A. Concept Drift Patterns

A concept drift may appear in different patterns [5]; as
illustrated in Fig. 2 (Note that colors represent different distri-
butions). An abrupt concept drift results from a sudden change
in the data distribution. On the other hand, a gradual concept
drift results from a slow transition from one data distribution
to the next. That is, the two patterns may coexist concurrently

(a) Original Data

(b) Real Drift

(c) Virtual Drift

Fig. 1: Real Concept Drift vs. Virtual Concept Drift
(Similar to Fig. 1 in [2])

(1)

(Fig. 2 (b)). In an incremental concept drift, a sequence of
data distributions appear during the transition. In re-occurring
concept drift, a previously active concept reappears after some
time, as shown in Fig. 2 (d). In practice, a mixture of different
concept drifts may be present in the stream.

(a) Abrupt

(b) Gradual

Fig. 2: Patterns of Concept Drifts
(Similar to Fig. 2 in [2])

IV. ADAPTIVE DATA STREAM LEARNING
As learning algorithms are often trained in non-stationary
environments, where concept drift is inevitable, they must have
the capacity to adapt to new situations [7]. Gama et al. [2]
deﬁned adaptive learning as a form of advance incremental
learning in which concept drifts are detected while the clas-
siﬁcation models are updated accordingly. Adaptive learning
algorithms must fulﬁll the following requirements in order
to maintain high predictive performances [8], [9], [10]: (1)
Minimum false positive and false negative rates – an adaptive
algorithm must detect concept drifts with a small number
of false positives and false negatives. A high false positive
rate involves more model retraining which in turn requires
more computational resources [11]. On the other hand, a high
false negative rate reduces the classiﬁcation accuracy, as the
current model does not reﬂect the new distribution. (2) Short
drift detection delay – An adaptive learning algorithm should
detect concept drifts rapidly, and update its predictive model in
quasi real-time in order to maintain the classiﬁcation accuracy.
(3) Robustness to noise – adaptive learners must be able to
distinguish concept drift from noise. Indeed, no adaptation is
required if noise is present in a stream.

• As a result of a change in the prior probability distribution

(c) Incremental

(d) Re-occurring

V. CONCEPT DRIFT DETECTION METHODS

Change detection methods refer to techniques and algo-
rithms that detect concept drifts and distributional changes
explicitly. Drift detection methods characterize and quantify
concept drifts by discovering the change points or small time
intervals during which concept drifts occur. Gama et al. [2]
classify concept drift detectors into three groups:

1) Sequential Analysis based Methods sequentially evaluate
prediction results as they become available. They alarm
for concept drifts when a pre-deﬁned threshold is met.
The Cumulative Sum (CUSUM) and its variant Page-
Hinkley (PH) [12] are representatives of this group.
2) Statistical based Approaches analyze statistical parame-
ters such as the mean and the standard deviation associ-
ated with the predicted results in order to detect concept
drifts. The Drift Detection Method (DDM) [13], Early
Drift Detection Method (EDDM) [14], Exponentially
Weighted Moving Average (EWMA) [15], and Reactive
Drift Detection Method (RDDM) [16] are members of
this group.

3) Windows based Methods usually utilize a ﬁxed reference
window for summarizing the past information and a
sliding window for summarizing the most recent infor-
mation. A signiﬁcant difference in between the distri-
butions of these two windows implies the occurrence
of a drift. Statistical tests or mathematical inequalities,
with the null-hypothesis indicating that the distributions
are equal, are employed. The Adaptive Windowing
(ADWIN) [17],
the
Drift Detection Methods based on Hoeffding’s Bound
(HDDMA-test and HDDMW-test) [4], Fast Hoeffding Drift
Detection Method (FHDDM) [9] and its stacking version
(FHDDMS) [19] are members of this family.

the SeqDrift detectors [8], [18],

CUSUM and its variant PageHinkley (PH) are some of
the pioneer methods in the community. DDM, EDDM, and
ADWIN have frequently been considered as benchmarks in the
literature [4], [9], [14], [17], [20]. RDDM, SeqDrift2, HDDMs,
and FHDDM present similar performances. For these reasons,
all these methods are evaluated in our experiments. Due to
page limitations, we do not provide descriptions of these
algorithms; therefore, we refer the interested reader to [2], [19]
for further details. The pros and cons of these approaches are
discussed below.

Discussion – CUSUM and PageHinkley (PH) detect concept
drifts from the deviation of the observed values from their
mean and alarm for a drift when this difference exceeds
a user-deﬁned threshold. These algorithms are sensitive to
the parameter values, resulting in a trade-off between false
alarms and detecting true drifts [2], [3]. DDM and EDDM
require less memory as only a small number of variables is
maintained [2]. On the other hand, the ADWIN and SeqDrift2
approaches necessitate multiple subsets of the stream which
lead to more memory consumption. They may computationally
be expensive, due to the sub-window compression or reservoir
sampling procedures. Barros et al. [16] observed that, RDDM

leads to a higher classiﬁcation accuracy compared to DDM,
especially against datasets with gradual concept drift, despite
an increase in false positives. EDDM may frequently alarm for
concept drift in the early stages of learning if the distances in
between wrong predictions are small. HDDM and FHDDM
employ the Hoeffding inequality [21]. FHDDM differs from
HDDM by sliding a window on prediction results for detecting
concept drifts. Recall that SeqDrift2 employs the Bernstein
inequality [22] in order to detect concept drift. SeqDrift2 uses
the sample variance, and assumes that the sampled data follow
a normal distribution. This assumption may be too restrictive,
in real-world domains. Further, the Bernstein inequality is
conservative and requires a variance parameter, in contrast
to, for instance, the Hoeffding inequality. These shortcomings
may lead to a longer detection delay and a potential loss of
accuracy. In the next section, we introduce McDiarmid Drift
Detection Method (MDDM) for detecting concept drifts faster.

VI. MCDIARMID DRIFT DETECTION METHODS

In a streaming environment, one may assume that old ex-
amples are either obsolete or outdated. Therefore, incremental
learners should rely on the most recent examples for training,
the current situation more adequately.
as the latter reﬂect
Fading or weighting approaches are typically used by online
learning algorithms to increase the weight attributed to the
most recent instances [2]. This is important from an adaptive
learning perspective, especially when a transition between two
contexts is occurring. For instance, Klinkenberg [23] relies on
an exponential weighting scheme wλ(Xi) = exp(−λi), where
λ is a parameter and i is the entry index, to assign lower
weights to old examples. Based on this observation, assigning
higher weights to recent predictions could potentially result
in a faster detection of concept drifts. In this section, we
introduce the McDiarmid Drift Detection Methods (MDDMs)
which utilizes a weighting scheme to ponderate the elements
of its sliding window for faster detection of concept drifts. We
also discuss variants of MDDM as well as the sensitivity of
their parameters.

A. McDiarmid Drift Detection Methods (MDDMs)

The McDiarmid Drift Detection Method (MDDM) applies
McDiarmid’s inequality [1] to detect concept drifts in evolving
data streams. The MDDM algorithm slides a window of size n
over the prediction results. It inserts a 1 into the window if the
prediction result is correct; and 0 otherwise. Each element in
the window is associated with a weight, as illustrated in Fig.
3, where wi < wi+1. While inputs are processed, the weighted
average of the elements of the sliding window is calculated,
i.e. µt
w, as well as the maximum weighted mean observed so
far, i.e. µm

w , as indicated in Eq. (3).

if µm

w < µt

w ⇒ µm

w = µt
w

(3)

Recall that MDDM relies on the assumption that by weight-
ing the prediction results associated with a sliding window,
and by putting more emphasis on the most recent elements,
concept drift could be detected faster and more efﬁciently.

Given the rule wi < wi+1, the elements located at the head
of the window have higher weights than those located at
the tail. Different weighting schemes have been considered
including the arithmetic and the geometric schemes. The
arithmetic scheme is given by wi = 1 + (i − 1) ∗ d, where
d ≥ 0 is the difference between two consecutive weights.
The geometric scheme is given by wi = r(i−1), where
r ≥ 1 is the ratio of two consecutive weights. In addition,
we employ the Euler scheme which is deﬁned by r = eλ
where λ ≥ 0. We have implemented three weighted drift
detection methods based on these three schemes: MDDM-A
(A for arithmetic), MDDM-G (G for geometric), and MDDM-
E (E for Euler)1. All these methods are described below. As
the prediction results are processed one-by-one, the algorithm
calculates the weighted average of the elements inside the
sliding window, and simultaneously updates two variables µt
w
(i.e. the current weighted average) and µm
w (i.e. the maximum
weighted average observed so far). A signiﬁcant difference
between µm
w implies a concept drift.

w and µt

Fig. 3: McDiarmid Drift Detection Method (General Scheme)

On the basis of the PAC learning model [25], the accuracy
should increase or stay constant as the number of instances
increases; otherwise, the possibility of facing drifts increases
[13], [26]. Thus, the value of µm
w should increase or remain
constant as more instances are processed. In other words, the
possibility of facing a concept drift increases if µm
w does not
change and µt
w decreases over time. Finally, as shown by Eq.
(4), a signiﬁcant difference in between µm
w indicates
the occurrence of a drift:

w and µt

∆µ = µm

w − µt

w ≥ εd ⇒ Drift := True

(4)

The McDiarmid inequality [1] is employed to determine if

the difference is deemed signiﬁcant.

Theorem I: McDiarmid’s Inequality – Let X1, X2, ..., Xn
be n independent random variables all taking values in the set
χ. Further, let f : χn (cid:55)→ R be a function of X1, ..., Xn that
satisﬁes ∀i, ∀x1, ..., xn, x(cid:48)

i ∈ χ,

|f (x1, ..., xi, ..., xn) − f (x1, ..., x(cid:48)

i, ..., xn) | ≤ ci.

This implies that replacing the ith coordinate xi by some
arbitrary value changes the function f by at most ci. Then,

1The source codes are available at https://www.github.com/alipsgh/ (One

may use them with the MOA framework [24]).

(5)

(6)

(8)

for all εM > 0, we have:

Pr{E[f ] − f ≥ εM } ≤ exp

−

(cid:18)

(cid:19)

2ε2
M
i=1 c2
i

(cid:80)n

Consequently, for a given conﬁdence level δM , the value of

εM is obtained by:

εM =

(cid:115) (cid:80)n
i=1 c2
i
2

ln

1
δM

Corollary I: MDDM test – In a streaming context, assume
µt
w is the weighted mean of a sequence of n random entries,
at time t, and µm
w is the maximum weighted mean observed
so far. Recall that each entry pi is in {0, 1} and has a weight
of wi. Let ∆µw = µm
w ≥ 0 be the difference between
these two weighted means. Given the conﬁdence level δw, the
McDiarmid inequality detects a drift if ∆µw ≥ εw, where
(cid:115) (cid:80)n
i=1 v2
i
2

w − µt

εw =

(7)

ln

1
δw

and where vi is given by

vi =

wi
i=1 wi

(cid:80)n

All three of our MDDM approaches apply Corollary I in
order to detect concept drift. In addition,
the McDiarmid
inequality allows for comparing the expectation of a function
of the random variables, such as the maximum, with the
function “per se”. This stands in contrast with, for instance
the Hoeffding inequality [21], in which the comparison is
restricted to the expectation of the random variables with their
empirical mean.

The pseudocode for the MDDM algorithm appears in Al-
gorithm 1. Firstly,
the INITIALIZE function initializes the
parameters, including the window size n, conﬁdence level δw,
εw, the sliding window win, and µm
w . As the data stream
examples are processed, the prediction results are pushed into
the window (lines 8-14). The algorithm updates the variables
w and µm
µt
w over time (lines 15-17). Finally, a drift is detected
if (µm
w) ≥ εw (lines 18-21). Recall
that we have
wi = 1+(i−1)∗d for MDDM-A, wi = r(i−1) for MDDM-G,
and wi = eλ(i−1) for MDDM-E.

w − µt

B. Discussion On Variants of MDDM

Recall that the MDDM-A approach employs an arithmetic
scheme wi = 1+(i−1)∗d, where wi+1 −wi = d meaning that
the weights increase linearly. On the the other hand, MDDM-
G applies the geometric scheme wi = r(i−1), indicating that
the weights increase exponentially with wi+1/wi = r (Note
that r = eλ for MDDM-E). The linear or exponential nature
of the weighting scheme affects the detection delay and the
false positive rate. That is, the exponential weighting scheme
often results in a faster concept drift detection, but at the
expense of a higher false positive rate if compared to the
linear weighting scheme. These statements are supported by
experimental results in Section VII.

Algorithm 1 McDiarmid Drift Detection Method

1: function INITIALIZE(windowSize, delta)
(n, δw) ← (windowSize, delta)
2:
εw = CALCULATEEPSILON()
3:
RESET()
4:
5: function RESET()
win = []
6:
µm
w = 0
7:
8: function DETECT(pr)

(cid:46) Creating an empty sliding window.

(cid:46) The pr is 1 for correct predictions, 0

(cid:46) Dropping an element from the tail.
(cid:46) Pushing an element into the head.

w = GETWEIGHTEDMEAN()

otherwise.

9:
10:

if win.size() = n then
win.tail.drop()

else

return False

win.push(pr)
if win.size() < n then

µt
w < µt
if µm
w then
w = µt
µm
w
∆µw = µm
w − µt
w
if ∆µw ≥ εw then

11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24: function CALCULATEEPSILON()
i=1 v2
25:
(cid:113) S

RESET()
return True

return False

S = (cid:80)n
return

else

26:

i

2 ln 1
δw

27: function GETWEIGHTEDMEAN()
i=1(pi × wi)/ (cid:80)n
28:

return (cid:80)n

i=1 wi

(cid:46) Resetting parameters.
(cid:46) Signaling for an alarm.

(cid:46) vi = wi/ (cid:80)n

i=1 wi

C. Parameters Sensitivity Analysis

The parameters n and δw are inversely proportional with
respect to εw. That is, as the value of n increases, the value of
εw decreases. This implies that, as more observations become
available, a more optimistic error bound should be applied.
On the other hand, as the value of δw decreases, the values of
εw increases (i.e. the bound becomes more conservative). The
parameter d in MDDM-A controls the scale of the weights
assigned to the sliding window elements. The value of εw
increases, as the value of d increases. Larger values of d lead
to faster drift detection, since higher weights are assigned to
the element located at the head of the window; however, the
false positive rate may increase. MDDM-G and MDDM-E
behave similarly; the scale of their weight is determined by
their parameters r and λ, respectively. That is, a higher r or
λ leads to a shorter detection delay, but at the expense of a
higher false positive rate. In order to set the default values
of these parameters, we conducted a number of experiments
against various synthetic data streams. We gradually increased
the values of these parameters to ﬁnd the optimal values:
δw = 10−6, d = 0.01, r = 1.01, and λ = 0.01.

VII. EXPERIMENTAL EVALUATION

A. Benchmarking Data Streams

are all widely found in the literature [4], [9], [13], [15],
[16], [27], [28], [29]. Each data stream consists of 100, 000
instances. A class noise of 10% was added to each stream in
order to evaluate the robustness of the drift detectors against
noisy data2. The synthetic data streams are described below.

• SINE1 · with abrupt drift: It has two attributes x and y
uniformly distributed on the interval [0, 1]. The classiﬁ-
cation function is y = sin(x). Instances are classiﬁed as
positive if they are under the curve; otherwise, they are
negative. At a drift point, the classiﬁcation is reversed
[9], [13], [14], [15].

• MIXED · with abrupt drift: The dataset has two numeric
attributes x and y distributed in [0, 1] with two boolean
attributes v and w. The instances are classiﬁed as positive
two of the three following conditions are
if at
satisﬁed: v, w, y < 0.5+0.3∗sin(3πx). The classiﬁcation
is reversed when drift points occur [9], [13], [16].

least

• CIRCLES · with gradual drift: It has two attributes x
and y distributed in [0, 1]. The classiﬁcation function is
the circle equation (x − xc)2 + (y − yc)2 = r2
c where
(xc, yc) and rc are the center and the radius of the circle,
respectively. Instances inside the circle are classiﬁed as
positive. Four different circles are employed in order to
simulate concept drift [9], [13], [14].

• LED · with gradual drift: The objective of this dataset
is to predict the digit on a seven-segment display, where
each digit has a 10% chance of being displayed. The
dataset has 7 class attributes, and 17 irrelevant ones. Con-
cept drift is simulated by interchanging relevant attributes
[4], [28], [29].

Concept Drift Simulation – Following Bifet et al. [28], we
used the sigmoid function to simulate abrupt and gradual
concept drifts. The function determines the probability of
belonging to a new context during a transition between two
concepts. The transition length ζ allows to simulate abrupt
or gradual concept drifts. The value was set to 50 for abrupt
concept drifts, and to 500 for gradual concept drifts in all our
experiments. To summarize, the drifts occur at every 20, 000
instances in SINE1 and MIXED with ζ = 50 for abrupt drift,
and at every 25, 000 instances in CIRCLES and LED with
ζ = 500 for gradual drift.

2) Real-world Data Streams: We extended our experiments
to real-world data streams3; which are frequently employed in
the online learning and adaptive learning literature [4], [9],
[13], [14], [15], [27], [28], [30]. Three data streams were
selected in our comparative study.

• ELECTRICITY · It contains 45, 312 instances, with 8
input attributes, recorded every half hour for two years by
the Australian New South Wales Electricity. The classiﬁer
must predict a rise (Up) or a fall (Down) in the electricity
price. The concept drift may result from changes in
consumption habits or unexpected events [31].

1) Synthetic Data Streams: We generated four synthetic
data streams from SINE1, MIXED, CIRCLES and LED, which

2Available at: https://www.github.com/alipsgh/data streams/.
3Available at: https://moa.cms.waikato.ac.nz/datasets/2013/.

• FOREST COVERTYPE · It consists of 54 attributes with
581, 012 instances describing 7 forest cover types for 30×
30 meter cells obtained from US Forest Service (USFS)
information system, for 4 wilderness areas located in the
Roosevelt National Forest of Northern Colorado [32].
• POKER HAND · It is composed of 1, 000, 000 instances,
where each instance is an example of ﬁve cards drawn
from a standard 52 cards deck. Each card is described by
two attributes (suit and rank), for a total of ten predictive
attributes. The classiﬁer predicts the poker hand [33].

B. Experiment Settings

We used the MOA framework [24] for our experiments.
We selected Hoeffding Tree (HT) [34] and Naive Bayes
(NB) as our incremental classiﬁers; and compared MDDMs
with CUSUM, PageHinkley, DDM, EDDM, RDDM, ADWIN,
SeqDrift2, HDDMs, and FHDDM. The default parameters
were employed for both the classiﬁers and the drift detection
methods. The algorithms were evaluated prequentially which
means that an instance is ﬁrst tested and then used for training
[35].

Pesaranghader et al. [9] introduced the acceptable delay
length notion for measuring detection delay and for determin-
ing true positive (TP), false positive (FP), and false negative
(FN) rates. The acceptable delay length ∆ is a threshold that
determines how far a given alarm should be from the true
location of a concept drift to be considered a true positive.
That is, we maintain three variables to count the numbers of
true positives, false negatives and false positives which are
initially set to zero. Therefore, the number of true positives
is incremented when the drift detector alarm occurs within
the acceptable delay range. Otherwise, the number of false
negatives is incremented as the alarm occurred too late. In
addition, the false positive value is incremented when a false
alarm occurs outside the acceptable delay range. Following
this approach, we set ∆ to 250 for the SINE1, MIXED, and
to 1000 for the CIRCLES and LED data streams. A longer ∆
should be considered for data streams with gradual drifts in
order to avoid a false negative increase.

Following [9], for both MDDMs and FHDDM, the window
size was set to 25 for the SINE1 and MIXED, and to 100 for the
CIRCLES and LED data streams. We used a wider window for
the CIRCLES and LED data streams in order to better detect
gradual concept drifts. These window sizes were chosen in
order to have shorter detection delay, as well as lower false
positive and false negative rates. Experiments were performed
on an Intel Core i5 @ 2.8 GHz with 16 GB of RAM running
Apple OS X Yosemite.

C. Experiments and Discussion

1) Synthetic Data Streams: Our experimental

results
against the synthetic data streams are presented in Tables I
and II. Recall that as we are aware of the locations of drifts
in synthetic data streams, we can evaluate the detection delay,
true positive (TP), false positive (FP) and false negative (FN).
We discuss the experimental results in the following:

Discussion I - SINE1 and MIXED (Abrupt Drift): As
represented in Table I, MDDMs and HDDMW-test detected
concept drifts with shorter delays against SINE1 and MIXED
data streams. MDDM, FHDDM, CUSUM and HDDMA-test
resulted in the lowest false positive rates. This observation may
indicate that MDDM, FHDDM, CUSUM, and HDDMA-test are
more accurate. Although RDDM had shorter detection delays
and false negative rates compared to DDM and EDDM, it
caused higher false positive rates. EDDM had the highest
false positive rates. Moreover, EDDM had the highest false
negative rates since it could not detect concept drifts within the
acceptable delay length. MDDMs showed comparable results
against
the other methods. As shown in Table I, for the
Hoeffding Tree classiﬁer, the highest classiﬁcation accuracies
was obtained with MDDMs and FHDDM, since they detected
drifts with the shortest delays and the lowest false positive
rates. Similar observations apply to the Naive Bayes classiﬁer.
It may be noticed that the false positive rate is lower for
Naive Bayes. This suggests that the Naive Bayes classiﬁer
represented the decision boundaries more accurately for noisy
SINE1 and MIXED data streams.
Discussion II - CIRCLES and LED (Gradual Drift): Table
II shows the results with the Hoeffding Tree and Naive Bayes
classiﬁers against the CIRCLES and LED data streams. The
MDDM algorithms resulted in the shortest concept drift detec-
tion delays, followed by FHDDM and HDDMW-test. Compared
to FHDDM, MDDMs detected concept drifts faster because of
its weighting schemes which favor the most recent elements.
On the other hand, EDDM produced the longest drift detection
delays. It also had the highest false negative rates. MDDMs,
FHDDM, CUSUM, RDDM, and HDDMs had the highest
true positive rates. EDDM showed the highest false positive
rates against the CIRCLES data streams. We achieved higher
accuracies with Hoeffding Tree than with Naive Bayes against
the CIRCLES data stream. In the case of the LED data streams,
ADWIN and SeqDrift2 triggered a relatively large number
of false alarms. Indeed, this could be potentially alleviated
by decreasing their conﬁdence levels, i.e. δ, to make their
tests more restrictive. SeqDrift2 caused fewer false positives
compared to ADWIN, since it applies a more conservative test
(Bernstein’s inequality). Although RDDM outperformed DDM
in all cases, in terms of detection delays and false negative
rates, it showed higher false positive rates. Finally, MDDMs,
FHDDM, and HDDMs led to the highest accuracies with both
classiﬁers.
Discussion III - MDDM Variants: Frequently, MDDM-
G and MDDM-E have shorter drift detection delays than
MDDM-A. The reason is to be found in the fact that they both
utilize an exponential weighting scheme (i.e. more weight is
put on the most recent entries which are the ones required
for faster detection) as opposed to MDDM-A which has a
linear one. The reader will notice that the false positive rates
of these two variants against the two streams with gradual
change, namely CIRCLES and LED, were higher than those
of MDDM-A. This is a consequence of the fact that MDDM-A
put more emphasis on the older entries in the window, which,

TABLE I: Hoeffding Tree and Naive Bayes with Drift Detectors against Synthetic Data Streams with Abrupt Change (ζ = 50)

Delay

Detector

FN
0.00
0.00
0.00
0.00

TP
4.00
4.00
4.00
4.00

MDDM-A 38.60 ± 3.38
MDDM-G 38.56 ± 3.36
MDDM-E 38.56 ± 3.36
CUSUM 86.89 ± 4.47

Hoeffding Tree (HT)
FP
0.21 ± 0.43
0.20 ± 0.42
0.20 ± 0.42
0.24 ± 0.47

Naive Bayes (NB)
Accuracy
FP
Delay
Accuracy
86.08 ± 0.25
0.13 ± 0.34
38.55 ± 3.35
87.07 ± 0.16
86.08 ± 0.25
0.14 ± 0.35
38.47 ± 3.35
87.07 ± 0.16
38.46 ± 3.35
86.08 ± 0.25
0.14 ± 0.35
87.07 ± 0.16
83.27 ± 6.96 3.99 ± 0.10 0.71 ± 0.86 0.01 ± 0.10 85.96 ± 0.25
86.94 ± 0.15
PageHinkley 229.24 ± 13.20 2.30 ± 1.07 1.71 ± 1.08 1.70 ± 1.07 86.06 ± 1.34 175.07 ± 24.72 3.71 ± 0.50 0.35 ± 0.54 0.29 ± 0.50 85.69 ± 0.27
DDM 163.11 ± 22.73 3.36 ± 0.77 3.30 ± 2.20 0.64 ± 0.77 86.06 ± 1.34 179.18 ± 26.83 2.87 ± 0.84 3.09 ± 1.88 1.13 ± 0.84 82.39 ± 4.32
EDDM 243.83 ± 14.25 0.22 ± 0.44 33.90 ± 11.61 3.78 ± 0.44 84.71 ± 0.55 234.28 ± 22.22 0.57 ± 0.64 33.53 ± 11.50 3.43 ± 0.64 83.44 ± 2.87
89.72 ± 16.45 3.99 ± 0.10 3.93 ± 2.91 0.01 ± 0.10 85.98 ± 0.27
RDDM 93.63 ± 7.57
4.72 ± 3.58
85.93 ± 0.23
63.92 ± 0.80 4.00 ± 0.00 3.86 ± 1.09
ADWIN 63.84 ± 1.12 4.00 ± 0.00 7.31 ± 3.18
4.83 ± 1.16
85.59 ± 0.25
4.26 ± 0.58
4.00
88.03 ± 25.73 3.97 ± 0.17 0.35 ± 0.55 0.03 ± 0.17 85.95 ± 0.25
0.71 ± 0.89
86.09 ± 0.25
0.41 ± 0.58
35.52 ± 3.10
0.46 ± 0.68
86.08 ± 0.25
0.04 ± 0.20
40.48 ± 3.37
0.10 ± 0.33

86.79 ± 0.18
86.67 ± 0.21
86.53 ± 0.15
87.01 ± 0.16
87.07 ± 0.15
87.07 ± 0.16

HDDMA-test 57.62 ± 11.81
HDDMW-test 35.70 ± 2.95
FHDDM 40.65 ± 3.15

0.00
0.00
0.00
0.00
0.00
0.00

FN
0.00
0.00
0.00

TP
4.00
4.00
4.00

4.00
4.00
4.00
4.00

SeqDrift2

4.00
4.00

0.00
0.00

0.00
0.00

200.00

200.00

4.00

0.00
0.00
0.00
0.00

4.00
4.00
4.00
4.00

1.11 ± 1.15
1.19 ± 1.21
1.19 ± 1.21
0.32 ± 0.58

MDDM-A 38.38 ± 3.66
MDDM-G 38.28 ± 3.64
MDDM-E 38.28 ± 3.64
CUSUM 90.90 ± 6.13

83.37 ± 0.09
0.69 ± 0.89
38.52 ± 3.81
83.36 ± 0.11
83.37 ± 0.09
0.70 ± 0.89
38.41 ± 3.81
83.36 ± 0.11
38.41 ± 3.81
83.37 ± 0.09
0.70 ± 0.89
83.36 ± 0.11
88.23 ± 8.97 3.99 ± 0.10 0.35 ± 0.54 0.01 ± 0.10 83.27 ± 0.08
83.27 ± 0.12
PageHinkley 229.91 ± 13.27 2.26 ± 0.98 1.74 ± 0.98 1.74 ± 0.98 82.88 ± 0.11 198.79 ± 18.72 3.56 ± 0.65 0.44 ± 0.65 0.44 ± 0.65 82.97 ± 0.10
DDM 195.73 ± 22.12 2.76 ± 1.01 2.91 ± 1.96 1.24 ± 1.01 81.78 ± 2.06 192.99 ± 23.82 2.78 ± 1.00 2.41 ± 1.44 1.22 ± 1.00 80.28 ± 4.11
EDDM 248.46 ± 7.69 0.05 ± 0.22 21.51 ± 7.70 3.95 ± 0.22 80.65 ± 0.82
247.47 ± 8.60 0.11 ± 0.31 20.22 ± 7.66 3.89 ± 0.31 80.30 ± 2.32
RDDM 106.68 ± 11.26 3.99 ± 0.10 3.49 ± 2.47 0.01 ± 0.10 83.16 ± 0.12 104.97 ± 12.06 3.99 ± 0.10 1.86 ± 1.65 0.01 ± 0.10 83.24 ± 0.09
83.28 ± 0.08
ADWIN 64.72 ± 2.79 4.00 ± 0.00 4.84 ± 2.44
64.48 ± 1.90 4.00 ± 0.00 3.47 ± 1.42
4.98 ± 1.20
82.91 ± 0.08
4.39 ± 0.79
4.00
83.71 ± 19.46 3.96 ± 0.20 0.48 ± 0.64 0.04 ± 0.20 83.28 ± 0.09
1.28 ± 1.09
83.36 ± 0.09
1.77 ± 1.39
35.75 ± 3.94
3.23 ± 1.95
83.38 ± 0.08
0.25 ± 0.48
40.56 ± 3.72
0.65 ± 0.94

HDDMA-test 69.42 ± 15.51
HDDMW-test 35.56 ± 3.50
FHDDM 40.55 ± 3.70

83.25 ± 0.12
82.91 ± 0.11
83.31 ± 0.11
83.27 ± 0.12
83.39 ± 0.10

0.00
0.00
0.00
0.00
0.00

4.00
4.00
4.00
4.00

0.00
0.00
0.00

4.00
4.00
4.00

SeqDrift2

0.00
0.00

4.00
4.00

0.00
0.00

200.00

200.00

t
p
u
r
b
A

-

1
E
N
I
S

t
p
u
r
b
A

-

D
E
X
I
M

TABLE II: Hoeffding Tree and Naive Bayes with Drift Detectors against Synthetic Data Streams with Gradual Change (ζ = 500)

Hoeffding Tree (HT)

Naive Bayes (NB)

Delay

Delay

Detector

FN
0.00
0.00
0.00

TP
3.00
3.00
3.00

MDDM-A 71.98 ± 22.19
MDDM-G 69.42 ± 22.09
MDDM-E 69.52 ± 22.12

CUSUM 220.07 ± 31.79 2.99 ± 0.10
PageHinkley 855.37 ± 56.27 1.79 ± 0.45
DDM 487.97 ± 82.24 2.78 ± 0.52

FP
0.27 ± 0.51
0.36 ± 0.61
0.37 ± 0.61
0.04 ± 0.20
1.24 ± 0.47
1.41 ± 1.24

Accuracy
161.25 ± 87.26 2.95 ± 0.22
86.58 ± 0.16
161.73 ± 89.49 2.94 ± 0.24
86.58 ± 0.17
161.74 ± 89.49 2.94 ± 0.24
86.57 ± 0.17
299.78 ± 52.29
0.01 ± 0.10 86.51 ± 0.13
1.21 ± 0.45 85.96 ± 0.15
677.32 ± 76.30 2.11 ± 0.55
0.22 ± 0.52 86.21 ± 0.47 703.59 ± 122.67 1.92 ± 0.72

0.05 ± 0.22 84.14 ± 0.12
0.06 ± 0.24 84.14 ± 0.12
0.06 ± 0.24 84.14 ± 0.12
84.08 ± 0.12
0.89 ± 0.55 83.94 ± 0.13
1.08 ± 0.72 83.18 ± 1.61
EDDM 987.61 ± 54.35 0.07 ± 0.26 24.61 ± 14.48 2.93 ± 0.26 84.89 ± 0.29 938.27 ± 106.60 0.35 ± 0.50 31.09 ± 18.14 2.65 ± 0.50 83.12 ± 0.40
0.01 ± 0.10 84.05 ± 0.11
RDDM 293.80 ± 38.52 2.98 ± 0.14
0.01 ± 0.10 84.12 ± 0.11
ADWIN 236.48 ± 130.94 2.67 ± 0.47
0.08 ± 0.27 84.13 ± 0.14
0.09 ± 0.29 84.09 ± 0.12
0.27 ± 0.44 84.11 ± 0.13
0.04 ± 0.20 84.14 ± 0.13

406.50 ± 69.40 2.99 ± 0.10
222.61 ± 57.00 2.99 ± 0.10
276.67 ± 91.10 2.92 ± 0.27
0.04 ± 0.20 86.52 ± 0.20 306.91 ± 107.78 2.91 ± 0.29
0.02 ± 0.14 86.53 ± 0.18 242.43 ± 134.19 2.73 ± 0.44
166.13 ± 83.84 2.96 ± 0.20

FP
0.63 ± 0.70
0.80 ± 0.73
0.81 ± 0.73
0.40 ± 0.62
0.93 ± 0.53
2.33 ± 1.49

0.02 ± 0.14 86.46 ± 0.16
0.33 ± 0.47 85.62 ± 0.19
86.47 ± 0.14

0.79 ± 1.25
9.74 ± 3.05
3.08 ± 0.90
0.65 ± 0.92
0.73 ± 0.87
0.17 ± 0.40

2.15 ± 1.94
5.56 ± 2.57
2.49 ± 0.97
0.49 ± 0.69
1.59 ± 1.00
0.43 ± 0.60

HDDMA-test 111.96 ± 68.22 2.96 ± 0.20
HDDMW-test 94.03 ± 57.61 2.98 ± 0.14

SeqDrift2 202.67 ± 16.11

FHDDM 79.28 ± 20.64

86.58 ± 0.13

Accuracy

3.00

3.00

3.00

0.00

0.00

0.00

FN

TP

3.00

CUSUM 300.68 ± 50.30

MDDM-A 210.31 ± 73.05 2.98 ± 0.14
MDDM-G 208.65 ± 73.05 2.98 ± 0.14
MDDM-E 208.61 ± 73.05 2.98 ± 0.14

0.02 ± 0.14 89.57 ± 0.04
0.02 ± 0.14 89.57 ± 0.04
0.02 ± 0.14 89.57 ± 0.04
89.57 ± 0.03
0.05 ± 0.26 89.36 ± 0.04
PageHinkley 560.30 ± 79.43 2.95 ± 0.26
0.04 ± 0.20 89.29 ± 1.15
DDM 444.13 ± 79.82 2.97 ± 0.17
2.30 ± 0.73 88.32 ± 0.53
EDDM 954.97 ± 62.98 0.66 ± 0.71
RDDM 321.88 ± 50.94 2.98 ± 0.14
0.02 ± 0.14 89.63 ± 0.04
ADWIN 521.47 ± 239.71 2.40 ± 0.77 474.95 ± 14.12 0.60 ± 0.77 72.25 ± 0.49 521.36 ± 238.56 2.36 ± 0.76 465.41 ± 12.53 0.64 ± 0.76 72.73 ± 0.44
SeqDrift2 426.00 ± 173.31 2.78 ± 0.44 277.0 ± 47.5 0.22 ± 0.44 76.51 ± 2.28 445.33 ± 192.27 2.75 ± 0.46 278.8 ± 47.5 0.25 ± 0.46 76.54 ± 2.25
0.02 ± 0.20 89.58 ± 0.05
0.05 ± 0.26 89.56 ± 0.03
0.03 ± 0.22 89.57 ± 0.04

210.31 ± 73.05 2.98 ± 0.14
208.65 ± 73.05 2.98 ± 0.14
208.61 ± 73.05 2.98 ± 0.14
300.61 ± 50.30
559.27 ± 78.99 2.95 ± 0.26
446.23 ± 82.12 2.96 ± 0.20
949.61 ± 68.94 0.70 ± 0.73
321.80 ± 50.94 2.98 ± 0.14

0.02 ± 0.14 89.56 ± 0.04
0.02 ± 0.14 89.56 ± 0.04
0.02 ± 0.14 89.56 ± 0.04
89.56 ± 0.03
0.05 ± 0.26 89.35 ± 0.04
0.03 ± 0.17 89.47 ± 0.56
2.34 ± 0.71 88.33 ± 0.50
0.02 ± 0.14 89.63 ± 0.04

HDDMA-test 295.03 ± 85.29 2.98 ± 0.20
HDDMW-test 259.18 ± 87.25 2.95 ± 0.26
FHDDM 220.40 ± 76.00 2.97 ± 0.22

0.03 ± 0.17
0.03 ± 0.17
0.03 ± 0.17
0.00
0.04 ± 0.24
0.32 ± 0.58
5.97 ± 1.69
0.61 ± 0.96

0.03 ± 0.17
0.03 ± 0.17
0.03 ± 0.17
0.00
0.04 ± 0.24
0.33 ± 0.58
6.33 ± 1.96
0.61 ± 0.96

295.85 ± 83.23 2.98 ± 0.20
259.17 ± 87.21 2.95 ± 0.26
220.40 ± 76.00 2.97 ± 0.22

0.02 ± 0.20 89.58 ± 0.05
0.05 ± 0.26 89.56 ± 0.04
0.03 ± 0.22 89.56 ± 0.04

0.16 ± 0.44
0.08 ± 0.31
0.03 ± 0.22

0.17 ± 0.47
0.05 ± 0.22
0.03 ± 0.22

0.00

3.00

0.00

l
a
u
d
a
r
G

-

S
E
L
C
R
I

C

l
a
u
d
a
r
G

-

3

.

1

.

3

.

0

D
E
L

in these cases are beneﬁcial to the learning process. All three
variants had comparable levels of accuracy. In general, one
may observe that an exponential-like scheme is beneﬁcial in
scenarios when faster detection is required. It follows that the
optimal shape for the weighting function is data, context and
application dependent.

2) Real-world Data Streams: There is a consensus among
researchers that the locations and/or the presence of concept
drift in the ELECTRICITY, FOREST COVERTYPE, and POKER
HAND data streams are not known [4], [9], [20], [28], [36].

This implies, in turn, that the drift detection delay as well as
the false positive and false negative rates cannot be determined
since the knowledge of the drift locations is necessary in order
to evaluate these quantities. Consequently, our evaluation is
based on the overall accuracy and the number of alarms for
concept drifts issued by each drift detector. We have also
considered blind adaptation and no detection approaches as
benchmarks for our experiments. In the blind adaptation, the
classiﬁer is retrained ab initio at every 100 instances. The
classiﬁers are trained without drift detectors in the case of no

detection. Similar to [9], a window of size 25 was selected
for FHDDM and MDDMs against real-world datasets. Our
experiments have shown that this choice is optimal in terms
of accuracy.

Table III presents the experimental results for ELECTRIC-
ITY, FOREST COVERTYPE, and POKER HAND data streams
with the Hoeffding Tree (HT) and Naive Bayes (NB) classi-
ﬁers. Firstly, the Hoeffding Tree classiﬁer showed higher clas-
siﬁcation accuracies compared to Naive Bayes when executed
without drift detector. This suggests that the Hoeffding Tree
classiﬁer could branch out and adequately reﬂect the new pat-
terns. Secondly, both classiﬁers achieved higher classiﬁcation
accuracies by using drift detection. Although this observation
indicates that using drift detection methods is beneﬁcial com-
pared to the no detection case, it does not necessarily mean
that a drift detector outperforms the others. Indeed, in a recent
study by Bifet et al. [10], it was found that blind detection has
the highest classiﬁcation accuracies, against the ELECTRICITY
and FOREST COVERTYPE data streams. Based on multiple
experiments, Bifet et al. [10] concluded that this behavior
may be explained by the temporal dependencies in between
the instances of the streams. As shown in Table III, a drift
detection method with a higher number of alarms usually led
to a higher classiﬁcation accuracy. In such a case, a classiﬁer
learns from a small portion of the data stream where almost
all instances are labeled with a common label (this refers to
temporal dependencies among examples as stated by Bifet et
al. [10]). To support this observation, as mentioned earlier, we
considered a blind adaptation as a benchmark. As shown in
the same table, the blind adaptation led to the highest or the
second highest classiﬁcation accuracies. We further extended
our experiments by running MDDMs with higher values of
δw. Recall that a higher δ implies that the drift detection
technique is less conservative. As indicated in the table, as

MDDMs became less conservative,
the number of alarms
as well as the classiﬁcation accuracies increased. Therefore,
because of temporal dependencies, both classiﬁers repeatedly
learned from instances presenting the same labels between two
consecutive alarms.

In summary, we concluded that using drift detection meth-
ods against real-world data streams is beneﬁcial. Nevertheless,
we are not in a position to make a strong statement based
solely on the accuracy because (1) the location of the drift
is unknown, and (2) because of the temporal dependencies
in between instances [10]. MDDM consistently led to high
classiﬁcation accuracies. Particularly, MDDM achieved the
highest classiﬁcation accuracies in all cases when the value
of δw increased from 10−6 to 0.001 and 0.01.

VIII. CONCLUSION

Sensor networks, smart houses, intelligent transportation,
autopilots are examples of technologies operating in evolving
environments where experiencing concept drifts over time
is commonplace. In order for the learning process to be
more accurate and efﬁcient in evolving environments, concept
drifts should be detected rapidly with false negative rate as
small as possible. In this research paper, we introduced the
McDiarmid Drift Detection Methods (MDDMs) for detecting
concept drifts with shorter delays and lower false negative
rates. We conducted various experiments to compare MDDMs
against the state-of-the-art. Our experimental results indicated
that MDDMs outperformed existing methods in terms of drift
detection delay, false negative, false positive, and classiﬁcation
accuracy rates.

In this paper, we considered incremental learning against
a single stream while evaluating the drift detection methods
accordingly. We aim to investigate streams with heterogeneous
concept drifts, i.e. streams in which different drift types and

TABLE III: Hoeffding Tree (HT) and Naive Bayes (NB) against Real-world Data Stream

Detector

MDDM-A
MDDM-G
MDDM-E
CUSUM
PageHinkley
DDM
EDDM
RDDM
ADWIN
SeqDrift2
HDDMA-test
HDDMW-test
FHDDM
Blind|W| = 100
No Detection

)
w
δ
(

1
0
0
.
0

)

w
δ
(

1
0
.
0

MDDM-A
MDDM-G
MDDM-E

MDDM-A
MDDM-G
MDDM-E

ELECTRICITY

HT

NB

FOREST COVERTYPE

HT

NB

POKER HAND

HT

NB

Alarms
105
105
105
22
6
169
191
143
65
59
210
117
90

453
—

180
182
182

256
252
252

Acc.
84.60
84.60
84.60
81.71
81.95
85.41
84.91
85.18
83.23
82.83
85.71
85.06
84.59

84.26
79.20

85.79
85.78
85.78

85.86
85.98
85.97

Alarms
126
126
126
28
10
143
203
164
88
60
211
132
109

453
—

208
209
209

265
265
266

Acc.
83.47
83.47
83.47
79.21
78.04
81.18
84.83
84.19
81.03
79.68
84.92
84.09
83.13

84.82
73.36

85.00
85.01
85.01

85.60
85.78
85.77

Alarms
1963
1966
1966
226
90
4301
2466
2671
1062
710
3695
2342
1794

5810
—

3253
3270
3270

3884
3969
3980

Acc.
85.33
85.35
85.35
83.01
81.65
87.35
86.00
86.42
83.36
82.85
87.24
85.97
85.08

87.24
80.31

87.03
87.05
87.06

87.63
87.73
87.73

Alarms
2022
2025
2025
286
117
4634
2416
2733
1151
757
3284
2383
185

5810
—

3221
3231
3234

3791
3856
3864

Acc.
85.38
85.39
85.39
81.55
80.06
88.03
86.08
86.86
83.24
82.44
87.42
86.22
85.09

87.70
60.52

87.27
87.29
87.29

87.95
88.05
88.05

Alarms
2036
2034
2034
617
403
1046
4806
2512
1358
1322
2565
2211
1876

8292
—

4320
4370
4369

6075
6095
6091

Acc.
76.89
76.89
76.89
72.85
71.30
72.74
77.30
76.70
73.84
72.51
76.40
77.11
76.72

77.96
76.07

77.82
77.83
77.83

78.18
78.21
78.21

Alarms
2145
2149
2149
659
489
433
4863
2579
1388
1395
2615
2312
1928

8292
—

4378
4425
4427

6099
6118
6116

Acc.
76.83
76.83
76.83
72.54
70.67
61.97
77.48
76.67
73.69
72.25
76.48
77.11
76.68

78.18
59.55

78.03
78.05
78.06

78.51
78.54
78.54

[18] S. Sakthithasan, R. Pears, and Y. S. Koh, “One pass concept change
detection for data streams,” in Paciﬁc-Asia Conference on Knowledge
Discovery and Data Mining. Springer, 2013, pp. 461–472.

[19] A. Pesaranghader, H. Viktor, and E. Paquet, “Reservoir of diverse
adaptive learners and stacking fast hoeffding drift detection methods
for evolving data streams,” arXiv preprint arXiv:1709.02457, 2017.
[20] D. T. J. Huang, Y. S. Koh, G. Dobbie, and A. Bifet, “Drift detection using
stream volatility,” in Joint European Conference on Machine Learning
and Knowledge Discovery in Databases. Springer, 2015, pp. 417–432.
[21] W. Hoeffding, “Probability inequalities for sums of bounded random
variables,” Journal of the American statistical association, vol. 58, no.
301, pp. 13–30, 1963.

[22] S. Bernstein, “The theory of probabilities,” 1946.
[23] R. Klinkenberg, “Learning drifting concepts: Example selection vs.
example weighting,” Intelligent Data Analysis, vol. 8, no. 3, pp. 281–
300, 2004.

[24] A. Bifet, G. Holmes, R. Kirkby, and B. Pfahringer, “Moa: Massive online
analysis,” Journal of Machine Learning Research, vol. 11, no. May, pp.
1601–1604, 2010.

[25] T. M. Mitchell, “Machine learning,” 1997.
[26] R. Sebasti˜ao, J. Gama, and T. Mendonc¸a, “Fading histograms in de-
tecting distribution and concept changes,” International Journal of Data
Science and Analytics, pp. 1–30, 2017.

[27] A. Pesaranghader, H. L. Viktor, and E. Paquet, “A framework for clas-
siﬁcation in data streams using multi-strategy learning,” in International
Conference on Discovery Science. Springer, 2016, pp. 341–355.
[28] A. Bifet, G. Holmes, B. Pfahringer, R. Kirkby, and R. Gavald`a, “New
ensemble methods for evolving data streams,” in Proceedings of the
15th ACM SIGKDD international conference on Knowledge discovery
and data mining. ACM, 2009, pp. 139–148.

[29] R. S. M. de Barros, J. I. G. Hidalgo, and D. R. de Lima Cabral,
“Wilcoxon rank sum test drift detector,” Neurocomputing, 2017.
[30] T. Escovedo, A. Koshiyama, A. A. da Cruz, and M. Vellasco, “Detecta:
abrupt concept drift detection in non-stationary environments,” Applied
Soft Computing, vol. 62, pp. 119–133, 2018.

ˇZliobait˙e, “How good is the electricity benchmark for evaluating

[31] I.

concept drift adaptation,” arXiv preprint arXiv:1301.3524, 2013.
[32] J. A. Blackard and D. J. Dean, “Comparative accuracies of artiﬁcial neu-
ral networks and discriminant analysis in predicting forest cover types
from cartographic variables,” Computers and electronics in agriculture,
vol. 24, no. 3, pp. 131–151, 1999.

[33] M. K. Olorunnimbe, H. L. Viktor, and E. Paquet, “Dynamic adaptation
of online ensembles for drifting data streams,” Journal of Intelligent
Information Systems, pp. 1–23, 2017.

[34] P. Domingos and G. Hulten, “Mining high-speed data streams,” in
Proceedings of the sixth ACM SIGKDD international conference on
Knowledge discovery and data mining. ACM, 2000, pp. 71–80.
[35] B. Krawczyk, L. L. Minku, J. Gama, J. Stefanowski, and M. Wo´zniak,
“Ensemble learning for data stream analysis: a survey,” Information
Fusion, vol. 37, pp. 132–156, 2017.

[36] V. Losing, B. Hammer, and H. Wersing, “Incremental on-line learning: A
review and comparison of state of the art algorithms,” Neurocomputing,
vol. 275, pp. 1261–1274, 2018.

[37] ——, “Knn classiﬁer with self adjusting memory for heterogeneous
concept drift,” in Data Mining (ICDM), 2016 IEEE 16th International
Conference on.

IEEE, 2016, pp. 291–300.

rates overlap. We are in addition interested to compare the per-
formance of MDDMs with proactive drift detection methods,
such as the DetectA algorithm [30], particularly regarding the
detection delay. Further, we aim to apply the notion of multiple
sliding windows stacking, as introduced by Pesaranghader et
al. [19], to the MDDM approaches. We also plan to investigate
adaptive ensemble approaches and self-adjusting algorithms
[37]. Finally, we will assess the performance of drift detection
methods against time-series data streams.

ACKNOWLEDGMENT

The authors wish to acknowledge ﬁnancial support by the
Canadian Natural Sciences and Engineering Research Council
(NSERC) as well as the Ontario Trillium Scholarship (OTS).

REFERENCES

[1] C. McDiarmid, “On the method of bounded differences,” Surveys in

combinatorics, vol. 141, no. 1, pp. 148–188, 1989.

[2] J. Gama, I. ˇZliobait˙e, A. Bifet, M. Pechenizkiy, and A. Bouchachia, “A
survey on concept drift adaptation,” ACM Computing Surveys (CSUR),
vol. 46, no. 4, p. 44, 2014.

[3] A. Bifet, G. Holmes, R. Kirkby, and B. Pfahringer, “Data stream mining

a practical approach,” 2011.

[4] I. Fr´ıas-Blanco, J. del Campo- ´Avila, G. Ramos-Jim´enez, R. Morales-
Bueno, A. Ortiz-D´ıaz, and Y. Caballero-Mota, “Online and non-
parametric drift detection methods based on hoeffdings bounds,” IEEE
Transactions on Knowledge and Data Engineering, vol. 27, no. 3, pp.
810–823, 2015.

[5] I. ˇZliobait˙e, “Learning under concept drift: an overview,” arXiv preprint

arXiv:1010.4784, 2010.

[6] G. Krempl, I.

ˇZliobaite, D. Brzezi´nski, E. H¨ullermeier, M. Last,
V. Lemaire, T. Noack, A. Shaker, S. Sievi, M. Spiliopoulou et al., “Open
challenges for data stream mining research,” ACM SIGKDD explorations
newsletter, vol. 16, no. 1, pp. 1–10, 2014.

[7] P. Duda, M. Jaworski, and L. Rutkowski, “Convergent time-varying
regression models for data streams: Tracking concept drift by the recur-
sive parzen-based generalized regression neural networks,” International
journal of neural systems, p. 1750048, 2017.

[8] R. Pears, S. Sakthithasan, and Y. S. Koh, “Detecting concept change in
dynamic data streams,” Machine Learning, vol. 97, no. 3, pp. 259–293,
2014.

[9] A. Pesaranghader and H. L. Viktor, “Fast hoeffding drift detection
method for evolving data streams,” in Joint European Conference on
Machine Learning and Knowledge Discovery in Databases. Springer,
2016, pp. 96–111.

[10] A. Bifet, “Classiﬁer concept drift detection and the illusion of progress,”
in International Conference on Artiﬁcial Intelligence and Soft Comput-
ing. Springer, 2017, pp. 715–725.

[11] I. ˇZliobait˙e, M. Budka, and F. Stahl, “Towards cost-sensitive adaptation:
when is it worth updating your predictive model?” Neurocomputing, vol.
150, pp. 240–249, 2015.

[12] E. Page, “Continuous inspection schemes,” Biometrika, vol. 41, no. 1/2,

pp. 100–115, 1954.

[13] J. Gama, P. Medas, G. Castillo, and P. Rodrigues, “Learning with drift
detection,” in Brazilian Symposium on Artiﬁcial Intelligence. Springer,
2004, pp. 286–295.

[14] M. Baena-Garcıa, J. del Campo- ´Avila, R. Fidalgo, A. Bifet, R. Gavalda,
and R. Morales-Bueno, “Early drift detection method,” in Fourth inter-
national workshop on knowledge discovery from data streams, vol. 6,
2006, pp. 77–86.

[15] G. J. Ross, N. M. Adams, D. K. Tasoulis, and D. J. Hand, “Exponentially
weighted moving average charts for detecting concept drift,” Pattern
Recognition Letters, vol. 33, no. 2, pp. 191–198, 2012.

[16] R. S. Barros, D. R. Cabral, S. G. Santos et al., “Rddm: Reactive drift

detection method,” Expert Systems with Applications, 2017.

[17] A. Bifet and R. Gavalda, “Learning from time-changing data with

adaptive windowing,” in SDM, vol. 7. SIAM, 2007, p. 2007.

McDiarmid Drift Detection Methods
for Evolving Data Streams

Ali Pesaranghader 1 ((cid:66)), Herna L. Viktor 1, Eric Paquet 1,2
1 School of Electrical Engineering and Computer Science,
University of Ottawa, Ottawa, ON K1N 6N5, Canada
{apesaran, hviktor}@uottawa.ca

2 National Research Council,
1200 Montreal Roard, Ottawa, ON K1A 0R6, Canada
eric.paquet@nrc-cnrc.gc.ca

8
1
0
2
 
n
a
J
 
7
1
 
 
]
L
M

.
t
a
t
s
[
 
 
2
v
0
3
0
2
0
.
0
1
7
1
:
v
i
X
r
a

Abstract—Increasingly, Internet of Things (IoT) domains, such
as sensor networks, smart cities, and social networks, generate
vast amounts of data. Such data are not only unbounded and
rapidly evolving. Rather, the content thereof dynamically evolves
over time, often in unforeseen ways. These variations are due
to so-called concept drifts, caused by changes in the underlying
data generation mechanisms. In a classiﬁcation setting, concept
drift causes the previously learned models to become inaccurate,
unsafe and even unusable. Accordingly, concept drifts need to
be detected, and handled, as soon as possible. In medical appli-
cations and emergency response settings, for example, change
in behaviours should be detected in near real-time, to avoid
potential loss of life. To this end, we introduce the McDiarmid
Drift Detection Method (MDDM), which utilizes McDiarmid’s
inequality [1] in order to detect concept drift. The MDDM
approach proceeds by sliding a window over prediction results,
and associate window entries with weights. Higher weights are
assigned to the most recent entries, in order to emphasize their
importance. As instances are processed, the detection algorithm
compares a weighted mean of elements inside the sliding window
with the maximum weighted mean observed so far. A signiﬁcant
difference between the two weighted means, upper-bounded by
the McDiarmid inequality, implies a concept drift. Our extensive
experimentation against synthetic and real-world data streams
show that our novel method outperforms the state-of-the-art.
Speciﬁcally, MDDM yields shorter detection delays as well as
lower false negative rates, while maintaining high classiﬁcation
accuracies.

I. INTRODUCTION

Traditionally, machine learning algorithms assume that data
are generated by a stationary distribution and collected prior
to learning. These assumptions are not valid in evolving
environments, where the underlying distributions may change
over time: a phenomenon known as concept drift [2], [3]. As
a consequence, classiﬁcation accuracy decreases as concept
drifts take place. Therefore, adaptation to new distributions
is essential to ensure the efﬁciency of the decision-making
process. An adaptive learning algorithm may utilize a drift
detection method for detecting concept drifts in a data stream
[2]. Once the drift detector signals the presence of a concept
drift,
the learning algorithm updates its current model by
considering the new distribution. For the learning process to be
efﬁcient, the drift detector must detect concept drifts rapidly,

while maintaining low false negative and false positive rates.
In this paper, we introduce the McDiarmid Drift Detection
Method (MDDM) which applies the McDiarmid inequality
[1] and various weighting schemes in order to rapidly and
efﬁciently detect concept drifts. Through numerous experi-
ments, we show that MDDM ﬁnds abrupt and gradual concept
drifts with shorter delays and with lower false negative rates,
compared to the state-of-the-art.

This paper is organized as follows. Data stream classiﬁca-
tion and concept drift are formally deﬁned in Sections II and
III, respectively. Section IV describes adaptive learning as a
form of incremental learning from evolving data streams. Sec-
tion V reviews the state-of-the-art for concept drift detection.
In Section VI, we introduce the McDiarmid Drift Detection
Methods (MDDMs). Next, in Section VII, our approaches are
compared with the start-of-the-art for both synthetic and real-
world data streams. We conclude the paper and discuss future
work in Section VIII.

II. DATA STREAM CLASSIFICATION

The primary objective of data stream classiﬁcation is to
incrementally, using the (current) available
build a model
data, the so-called training data, for predicting the label of
unseen examples. Data stream classiﬁcation may be deﬁned
as follows:

Let a stream S be a sequence of
instances:
(X1, y1), (X2, y2), ..., (Xt, yt) . The pair (Xt, yt) rep-
resents an instance arriving at time t, where Xt is a
vector containing k attributes: Xt = (x1, x2, ..., xk),
while yt is a class label which belongs to a set
of size m, yt ∈ {c1, c2, ..., cm}. Assume a target
function yt = f (Xt) which maps an input vector to
a particular class label. The learning task consists of
incrementally building a model ˜f that approximates
the function f at all time. Naturally, an approxima-
tion which maximizes the classiﬁcation accuracy is
preferred [4].

Bifet et al. [3] recommend that incremental learning algo-
rithms should fulﬁll four essential requirements for data stream
mining: (1) the examples should be processed one-by-one and

only once in the order of their arrival, (2) memory usage
should be constrained as the size of a data stream is typically
substantially larger than the size of the available memory, (3)
all the calculations should be performed in real-time or at least,
in near real-time, and (4) the outcome of the classiﬁcation
process should be available at any time.

III. CONCEPT DRIFT DEFINITION

The Bayesian Decision Theory is commonly employed
in describing classiﬁcation processes based on their prior
i.e. p(y), and the class
probability distribution of classes,
conditional probability distribution, i.e. p(X|y) [2], [5]. The
classiﬁcation decision is related to the posterior probabilities
of the classes. The posterior probability associated with class
ci, given instance X, is obtained by:

p(ci|X) =

p(ci) · p(X|ci)
p(X)

where p(X) = (cid:80)m
i=1 p(ci) · p(X|ci) is the marginal probability
distribution. Formally, if a concept drift occurs in between
time t0 and t1 we have:

∃X : pt0 (X, y) (cid:54)= pt1 (X, y)

(2)

where pt0 and pt1 represent the joint probability distributions
at time t0 and t1, respectively [2]. Eq. (2) implies that the
data distribution at times t0 and t1 are distinct, as their joint
probabilities differ. From Eq. (1), it may be observed that a
concept drift may occur [2]:

• As a result of a change in the class conditional probability

p(y),

distribution p(X|y),

• As a result of a change in the posterior probability dis-
tribution p(y|X), thus affecting the classiﬁcation decision
boundaries.

Gama et al. [2], ˇZliobait˙e [5], and Krempl et al. [6] classify
changes into two types, namely real concept drift and virtual
concept drift. A real concept drift refers to the changes in
p(y|X) which affects the decision boundaries or the target
concept (as shown in Fig. 1 (b)). On the other hand, virtual
drift is the result of a change in p(X), and subsequently in
p(X|y), but not in p(y|X). That is, a virtual drift is a change
in the distribution of the incoming data which implies that
the decision boundaries remain unaffected (as in Fig. 1 (c)).
From a predictive perspective, adaptation is required once a
real concept drift occurs, since the current decision boundary
turns out to be obsolete [2], [6].

A. Concept Drift Patterns

A concept drift may appear in different patterns [5]; as
illustrated in Fig. 2 (Note that colors represent different distri-
butions). An abrupt concept drift results from a sudden change
in the data distribution. On the other hand, a gradual concept
drift results from a slow transition from one data distribution
to the next. That is, the two patterns may coexist concurrently

(a) Original Data

(b) Real Drift

(c) Virtual Drift

Fig. 1: Real Concept Drift vs. Virtual Concept Drift
(Similar to Fig. 1 in [2])

(1)

(Fig. 2 (b)). In an incremental concept drift, a sequence of
data distributions appear during the transition. In re-occurring
concept drift, a previously active concept reappears after some
time, as shown in Fig. 2 (d). In practice, a mixture of different
concept drifts may be present in the stream.

(a) Abrupt

(b) Gradual

Fig. 2: Patterns of Concept Drifts
(Similar to Fig. 2 in [2])

IV. ADAPTIVE DATA STREAM LEARNING
As learning algorithms are often trained in non-stationary
environments, where concept drift is inevitable, they must have
the capacity to adapt to new situations [7]. Gama et al. [2]
deﬁned adaptive learning as a form of advance incremental
learning in which concept drifts are detected while the clas-
siﬁcation models are updated accordingly. Adaptive learning
algorithms must fulﬁll the following requirements in order
to maintain high predictive performances [8], [9], [10]: (1)
Minimum false positive and false negative rates – an adaptive
algorithm must detect concept drifts with a small number
of false positives and false negatives. A high false positive
rate involves more model retraining which in turn requires
more computational resources [11]. On the other hand, a high
false negative rate reduces the classiﬁcation accuracy, as the
current model does not reﬂect the new distribution. (2) Short
drift detection delay – An adaptive learning algorithm should
detect concept drifts rapidly, and update its predictive model in
quasi real-time in order to maintain the classiﬁcation accuracy.
(3) Robustness to noise – adaptive learners must be able to
distinguish concept drift from noise. Indeed, no adaptation is
required if noise is present in a stream.

• As a result of a change in the prior probability distribution

(c) Incremental

(d) Re-occurring

V. CONCEPT DRIFT DETECTION METHODS

Change detection methods refer to techniques and algo-
rithms that detect concept drifts and distributional changes
explicitly. Drift detection methods characterize and quantify
concept drifts by discovering the change points or small time
intervals during which concept drifts occur. Gama et al. [2]
classify concept drift detectors into three groups:

1) Sequential Analysis based Methods sequentially evaluate
prediction results as they become available. They alarm
for concept drifts when a pre-deﬁned threshold is met.
The Cumulative Sum (CUSUM) and its variant Page-
Hinkley (PH) [12] are representatives of this group.
2) Statistical based Approaches analyze statistical parame-
ters such as the mean and the standard deviation associ-
ated with the predicted results in order to detect concept
drifts. The Drift Detection Method (DDM) [13], Early
Drift Detection Method (EDDM) [14], Exponentially
Weighted Moving Average (EWMA) [15], and Reactive
Drift Detection Method (RDDM) [16] are members of
this group.

3) Windows based Methods usually utilize a ﬁxed reference
window for summarizing the past information and a
sliding window for summarizing the most recent infor-
mation. A signiﬁcant difference in between the distri-
butions of these two windows implies the occurrence
of a drift. Statistical tests or mathematical inequalities,
with the null-hypothesis indicating that the distributions
are equal, are employed. The Adaptive Windowing
(ADWIN) [17],
the
Drift Detection Methods based on Hoeffding’s Bound
(HDDMA-test and HDDMW-test) [4], Fast Hoeffding Drift
Detection Method (FHDDM) [9] and its stacking version
(FHDDMS) [19] are members of this family.

the SeqDrift detectors [8], [18],

CUSUM and its variant PageHinkley (PH) are some of
the pioneer methods in the community. DDM, EDDM, and
ADWIN have frequently been considered as benchmarks in the
literature [4], [9], [14], [17], [20]. RDDM, SeqDrift2, HDDMs,
and FHDDM present similar performances. For these reasons,
all these methods are evaluated in our experiments. Due to
page limitations, we do not provide descriptions of these
algorithms; therefore, we refer the interested reader to [2], [19]
for further details. The pros and cons of these approaches are
discussed below.

Discussion – CUSUM and PageHinkley (PH) detect concept
drifts from the deviation of the observed values from their
mean and alarm for a drift when this difference exceeds
a user-deﬁned threshold. These algorithms are sensitive to
the parameter values, resulting in a trade-off between false
alarms and detecting true drifts [2], [3]. DDM and EDDM
require less memory as only a small number of variables is
maintained [2]. On the other hand, the ADWIN and SeqDrift2
approaches necessitate multiple subsets of the stream which
lead to more memory consumption. They may computationally
be expensive, due to the sub-window compression or reservoir
sampling procedures. Barros et al. [16] observed that, RDDM

leads to a higher classiﬁcation accuracy compared to DDM,
especially against datasets with gradual concept drift, despite
an increase in false positives. EDDM may frequently alarm for
concept drift in the early stages of learning if the distances in
between wrong predictions are small. HDDM and FHDDM
employ the Hoeffding inequality [21]. FHDDM differs from
HDDM by sliding a window on prediction results for detecting
concept drifts. Recall that SeqDrift2 employs the Bernstein
inequality [22] in order to detect concept drift. SeqDrift2 uses
the sample variance, and assumes that the sampled data follow
a normal distribution. This assumption may be too restrictive,
in real-world domains. Further, the Bernstein inequality is
conservative and requires a variance parameter, in contrast
to, for instance, the Hoeffding inequality. These shortcomings
may lead to a longer detection delay and a potential loss of
accuracy. In the next section, we introduce McDiarmid Drift
Detection Method (MDDM) for detecting concept drifts faster.

VI. MCDIARMID DRIFT DETECTION METHODS

In a streaming environment, one may assume that old ex-
amples are either obsolete or outdated. Therefore, incremental
learners should rely on the most recent examples for training,
the current situation more adequately.
as the latter reﬂect
Fading or weighting approaches are typically used by online
learning algorithms to increase the weight attributed to the
most recent instances [2]. This is important from an adaptive
learning perspective, especially when a transition between two
contexts is occurring. For instance, Klinkenberg [23] relies on
an exponential weighting scheme wλ(Xi) = exp(−λi), where
λ is a parameter and i is the entry index, to assign lower
weights to old examples. Based on this observation, assigning
higher weights to recent predictions could potentially result
in a faster detection of concept drifts. In this section, we
introduce the McDiarmid Drift Detection Methods (MDDMs)
which utilizes a weighting scheme to ponderate the elements
of its sliding window for faster detection of concept drifts. We
also discuss variants of MDDM as well as the sensitivity of
their parameters.

A. McDiarmid Drift Detection Methods (MDDMs)

The McDiarmid Drift Detection Method (MDDM) applies
McDiarmid’s inequality [1] to detect concept drifts in evolving
data streams. The MDDM algorithm slides a window of size n
over the prediction results. It inserts a 1 into the window if the
prediction result is correct; and 0 otherwise. Each element in
the window is associated with a weight, as illustrated in Fig.
3, where wi < wi+1. While inputs are processed, the weighted
average of the elements of the sliding window is calculated,
i.e. µt
w, as well as the maximum weighted mean observed so
far, i.e. µm

w , as indicated in Eq. (3).

if µm

w < µt

w ⇒ µm

w = µt
w

(3)

Recall that MDDM relies on the assumption that by weight-
ing the prediction results associated with a sliding window,
and by putting more emphasis on the most recent elements,
concept drift could be detected faster and more efﬁciently.

Given the rule wi < wi+1, the elements located at the head
of the window have higher weights than those located at
the tail. Different weighting schemes have been considered
including the arithmetic and the geometric schemes. The
arithmetic scheme is given by wi = 1 + (i − 1) ∗ d, where
d ≥ 0 is the difference between two consecutive weights.
The geometric scheme is given by wi = r(i−1), where
r ≥ 1 is the ratio of two consecutive weights. In addition,
we employ the Euler scheme which is deﬁned by r = eλ
where λ ≥ 0. We have implemented three weighted drift
detection methods based on these three schemes: MDDM-A
(A for arithmetic), MDDM-G (G for geometric), and MDDM-
E (E for Euler)1. All these methods are described below. As
the prediction results are processed one-by-one, the algorithm
calculates the weighted average of the elements inside the
sliding window, and simultaneously updates two variables µt
w
(i.e. the current weighted average) and µm
w (i.e. the maximum
weighted average observed so far). A signiﬁcant difference
between µm
w implies a concept drift.

w and µt

Fig. 3: McDiarmid Drift Detection Method (General Scheme)

On the basis of the PAC learning model [25], the accuracy
should increase or stay constant as the number of instances
increases; otherwise, the possibility of facing drifts increases
[13], [26]. Thus, the value of µm
w should increase or remain
constant as more instances are processed. In other words, the
possibility of facing a concept drift increases if µm
w does not
change and µt
w decreases over time. Finally, as shown by Eq.
(4), a signiﬁcant difference in between µm
w indicates
the occurrence of a drift:

w and µt

∆µ = µm

w − µt

w ≥ εd ⇒ Drift := True

(4)

The McDiarmid inequality [1] is employed to determine if

the difference is deemed signiﬁcant.

Theorem I: McDiarmid’s Inequality – Let X1, X2, ..., Xn
be n independent random variables all taking values in the set
χ. Further, let f : χn (cid:55)→ R be a function of X1, ..., Xn that
satisﬁes ∀i, ∀x1, ..., xn, x(cid:48)

i ∈ χ,

|f (x1, ..., xi, ..., xn) − f (x1, ..., x(cid:48)

i, ..., xn) | ≤ ci.

This implies that replacing the ith coordinate xi by some
arbitrary value changes the function f by at most ci. Then,

1The source codes are available at https://www.github.com/alipsgh/ (One

may use them with the MOA framework [24]).

(5)

(6)

(8)

for all εM > 0, we have:

Pr{E[f ] − f ≥ εM } ≤ exp

−

(cid:18)

(cid:19)

2ε2
M
i=1 c2
i

(cid:80)n

Consequently, for a given conﬁdence level δM , the value of

εM is obtained by:

εM =

(cid:115) (cid:80)n
i=1 c2
i
2

ln

1
δM

Corollary I: MDDM test – In a streaming context, assume
µt
w is the weighted mean of a sequence of n random entries,
at time t, and µm
w is the maximum weighted mean observed
so far. Recall that each entry pi is in {0, 1} and has a weight
of wi. Let ∆µw = µm
w ≥ 0 be the difference between
these two weighted means. Given the conﬁdence level δw, the
McDiarmid inequality detects a drift if ∆µw ≥ εw, where
(cid:115) (cid:80)n
i=1 v2
i
2

w − µt

εw =

(7)

ln

1
δw

and where vi is given by

vi =

wi
i=1 wi

(cid:80)n

All three of our MDDM approaches apply Corollary I in
order to detect concept drift. In addition,
the McDiarmid
inequality allows for comparing the expectation of a function
of the random variables, such as the maximum, with the
function “per se”. This stands in contrast with, for instance
the Hoeffding inequality [21], in which the comparison is
restricted to the expectation of the random variables with their
empirical mean.

The pseudocode for the MDDM algorithm appears in Al-
gorithm 1. Firstly,
the INITIALIZE function initializes the
parameters, including the window size n, conﬁdence level δw,
εw, the sliding window win, and µm
w . As the data stream
examples are processed, the prediction results are pushed into
the window (lines 8-14). The algorithm updates the variables
w and µm
µt
w over time (lines 15-17). Finally, a drift is detected
if (µm
w) ≥ εw (lines 18-21). Recall
that we have
wi = 1+(i−1)∗d for MDDM-A, wi = r(i−1) for MDDM-G,
and wi = eλ(i−1) for MDDM-E.

w − µt

B. Discussion On Variants of MDDM

Recall that the MDDM-A approach employs an arithmetic
scheme wi = 1+(i−1)∗d, where wi+1 −wi = d meaning that
the weights increase linearly. On the the other hand, MDDM-
G applies the geometric scheme wi = r(i−1), indicating that
the weights increase exponentially with wi+1/wi = r (Note
that r = eλ for MDDM-E). The linear or exponential nature
of the weighting scheme affects the detection delay and the
false positive rate. That is, the exponential weighting scheme
often results in a faster concept drift detection, but at the
expense of a higher false positive rate if compared to the
linear weighting scheme. These statements are supported by
experimental results in Section VII.

Algorithm 1 McDiarmid Drift Detection Method

1: function INITIALIZE(windowSize, delta)
(n, δw) ← (windowSize, delta)
2:
εw = CALCULATEEPSILON()
3:
RESET()
4:
5: function RESET()
win = []
6:
µm
w = 0
7:
8: function DETECT(pr)

(cid:46) Creating an empty sliding window.

(cid:46) The pr is 1 for correct predictions, 0

(cid:46) Dropping an element from the tail.
(cid:46) Pushing an element into the head.

w = GETWEIGHTEDMEAN()

otherwise.

9:
10:

if win.size() = n then
win.tail.drop()

else

return False

win.push(pr)
if win.size() < n then

µt
w < µt
if µm
w then
w = µt
µm
w
∆µw = µm
w − µt
w
if ∆µw ≥ εw then

11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24: function CALCULATEEPSILON()
i=1 v2
25:
(cid:113) S

RESET()
return True

return False

S = (cid:80)n
return

else

26:

i

2 ln 1
δw

27: function GETWEIGHTEDMEAN()
i=1(pi × wi)/ (cid:80)n
28:

return (cid:80)n

i=1 wi

(cid:46) Resetting parameters.
(cid:46) Signaling for an alarm.

(cid:46) vi = wi/ (cid:80)n

i=1 wi

C. Parameters Sensitivity Analysis

The parameters n and δw are inversely proportional with
respect to εw. That is, as the value of n increases, the value of
εw decreases. This implies that, as more observations become
available, a more optimistic error bound should be applied.
On the other hand, as the value of δw decreases, the values of
εw increases (i.e. the bound becomes more conservative). The
parameter d in MDDM-A controls the scale of the weights
assigned to the sliding window elements. The value of εw
increases, as the value of d increases. Larger values of d lead
to faster drift detection, since higher weights are assigned to
the element located at the head of the window; however, the
false positive rate may increase. MDDM-G and MDDM-E
behave similarly; the scale of their weight is determined by
their parameters r and λ, respectively. That is, a higher r or
λ leads to a shorter detection delay, but at the expense of a
higher false positive rate. In order to set the default values
of these parameters, we conducted a number of experiments
against various synthetic data streams. We gradually increased
the values of these parameters to ﬁnd the optimal values:
δw = 10−6, d = 0.01, r = 1.01, and λ = 0.01.

VII. EXPERIMENTAL EVALUATION

A. Benchmarking Data Streams

are all widely found in the literature [4], [9], [13], [15],
[16], [27], [28], [29]. Each data stream consists of 100, 000
instances. A class noise of 10% was added to each stream in
order to evaluate the robustness of the drift detectors against
noisy data2. The synthetic data streams are described below.

• SINE1 · with abrupt drift: It has two attributes x and y
uniformly distributed on the interval [0, 1]. The classiﬁ-
cation function is y = sin(x). Instances are classiﬁed as
positive if they are under the curve; otherwise, they are
negative. At a drift point, the classiﬁcation is reversed
[9], [13], [14], [15].

• MIXED · with abrupt drift: The dataset has two numeric
attributes x and y distributed in [0, 1] with two boolean
attributes v and w. The instances are classiﬁed as positive
two of the three following conditions are
if at
satisﬁed: v, w, y < 0.5+0.3∗sin(3πx). The classiﬁcation
is reversed when drift points occur [9], [13], [16].

least

• CIRCLES · with gradual drift: It has two attributes x
and y distributed in [0, 1]. The classiﬁcation function is
the circle equation (x − xc)2 + (y − yc)2 = r2
c where
(xc, yc) and rc are the center and the radius of the circle,
respectively. Instances inside the circle are classiﬁed as
positive. Four different circles are employed in order to
simulate concept drift [9], [13], [14].

• LED · with gradual drift: The objective of this dataset
is to predict the digit on a seven-segment display, where
each digit has a 10% chance of being displayed. The
dataset has 7 class attributes, and 17 irrelevant ones. Con-
cept drift is simulated by interchanging relevant attributes
[4], [28], [29].

Concept Drift Simulation – Following Bifet et al. [28], we
used the sigmoid function to simulate abrupt and gradual
concept drifts. The function determines the probability of
belonging to a new context during a transition between two
concepts. The transition length ζ allows to simulate abrupt
or gradual concept drifts. The value was set to 50 for abrupt
concept drifts, and to 500 for gradual concept drifts in all our
experiments. To summarize, the drifts occur at every 20, 000
instances in SINE1 and MIXED with ζ = 50 for abrupt drift,
and at every 25, 000 instances in CIRCLES and LED with
ζ = 500 for gradual drift.

2) Real-world Data Streams: We extended our experiments
to real-world data streams3; which are frequently employed in
the online learning and adaptive learning literature [4], [9],
[13], [14], [15], [27], [28], [30]. Three data streams were
selected in our comparative study.

• ELECTRICITY · It contains 45, 312 instances, with 8
input attributes, recorded every half hour for two years by
the Australian New South Wales Electricity. The classiﬁer
must predict a rise (Up) or a fall (Down) in the electricity
price. The concept drift may result from changes in
consumption habits or unexpected events [31].

1) Synthetic Data Streams: We generated four synthetic
data streams from SINE1, MIXED, CIRCLES and LED, which

2Available at: https://www.github.com/alipsgh/data streams/.
3Available at: https://moa.cms.waikato.ac.nz/datasets/2013/.

• FOREST COVERTYPE · It consists of 54 attributes with
581, 012 instances describing 7 forest cover types for 30×
30 meter cells obtained from US Forest Service (USFS)
information system, for 4 wilderness areas located in the
Roosevelt National Forest of Northern Colorado [32].
• POKER HAND · It is composed of 1, 000, 000 instances,
where each instance is an example of ﬁve cards drawn
from a standard 52 cards deck. Each card is described by
two attributes (suit and rank), for a total of ten predictive
attributes. The classiﬁer predicts the poker hand [33].

B. Experiment Settings

We used the MOA framework [24] for our experiments.
We selected Hoeffding Tree (HT) [34] and Naive Bayes
(NB) as our incremental classiﬁers; and compared MDDMs
with CUSUM, PageHinkley, DDM, EDDM, RDDM, ADWIN,
SeqDrift2, HDDMs, and FHDDM. The default parameters
were employed for both the classiﬁers and the drift detection
methods. The algorithms were evaluated prequentially which
means that an instance is ﬁrst tested and then used for training
[35].

Pesaranghader et al. [9] introduced the acceptable delay
length notion for measuring detection delay and for determin-
ing true positive (TP), false positive (FP), and false negative
(FN) rates. The acceptable delay length ∆ is a threshold that
determines how far a given alarm should be from the true
location of a concept drift to be considered a true positive.
That is, we maintain three variables to count the numbers of
true positives, false negatives and false positives which are
initially set to zero. Therefore, the number of true positives
is incremented when the drift detector alarm occurs within
the acceptable delay range. Otherwise, the number of false
negatives is incremented as the alarm occurred too late. In
addition, the false positive value is incremented when a false
alarm occurs outside the acceptable delay range. Following
this approach, we set ∆ to 250 for the SINE1, MIXED, and
to 1000 for the CIRCLES and LED data streams. A longer ∆
should be considered for data streams with gradual drifts in
order to avoid a false negative increase.

Following [9], for both MDDMs and FHDDM, the window
size was set to 25 for the SINE1 and MIXED, and to 100 for the
CIRCLES and LED data streams. We used a wider window for
the CIRCLES and LED data streams in order to better detect
gradual concept drifts. These window sizes were chosen in
order to have shorter detection delay, as well as lower false
positive and false negative rates. Experiments were performed
on an Intel Core i5 @ 2.8 GHz with 16 GB of RAM running
Apple OS X Yosemite.

C. Experiments and Discussion

1) Synthetic Data Streams: Our experimental

results
against the synthetic data streams are presented in Tables I
and II. Recall that as we are aware of the locations of drifts
in synthetic data streams, we can evaluate the detection delay,
true positive (TP), false positive (FP) and false negative (FN).
We discuss the experimental results in the following:

Discussion I - SINE1 and MIXED (Abrupt Drift): As
represented in Table I, MDDMs and HDDMW-test detected
concept drifts with shorter delays against SINE1 and MIXED
data streams. MDDM, FHDDM, CUSUM and HDDMA-test
resulted in the lowest false positive rates. This observation may
indicate that MDDM, FHDDM, CUSUM, and HDDMA-test are
more accurate. Although RDDM had shorter detection delays
and false negative rates compared to DDM and EDDM, it
caused higher false positive rates. EDDM had the highest
false positive rates. Moreover, EDDM had the highest false
negative rates since it could not detect concept drifts within the
acceptable delay length. MDDMs showed comparable results
against
the other methods. As shown in Table I, for the
Hoeffding Tree classiﬁer, the highest classiﬁcation accuracies
was obtained with MDDMs and FHDDM, since they detected
drifts with the shortest delays and the lowest false positive
rates. Similar observations apply to the Naive Bayes classiﬁer.
It may be noticed that the false positive rate is lower for
Naive Bayes. This suggests that the Naive Bayes classiﬁer
represented the decision boundaries more accurately for noisy
SINE1 and MIXED data streams.
Discussion II - CIRCLES and LED (Gradual Drift): Table
II shows the results with the Hoeffding Tree and Naive Bayes
classiﬁers against the CIRCLES and LED data streams. The
MDDM algorithms resulted in the shortest concept drift detec-
tion delays, followed by FHDDM and HDDMW-test. Compared
to FHDDM, MDDMs detected concept drifts faster because of
its weighting schemes which favor the most recent elements.
On the other hand, EDDM produced the longest drift detection
delays. It also had the highest false negative rates. MDDMs,
FHDDM, CUSUM, RDDM, and HDDMs had the highest
true positive rates. EDDM showed the highest false positive
rates against the CIRCLES data streams. We achieved higher
accuracies with Hoeffding Tree than with Naive Bayes against
the CIRCLES data stream. In the case of the LED data streams,
ADWIN and SeqDrift2 triggered a relatively large number
of false alarms. Indeed, this could be potentially alleviated
by decreasing their conﬁdence levels, i.e. δ, to make their
tests more restrictive. SeqDrift2 caused fewer false positives
compared to ADWIN, since it applies a more conservative test
(Bernstein’s inequality). Although RDDM outperformed DDM
in all cases, in terms of detection delays and false negative
rates, it showed higher false positive rates. Finally, MDDMs,
FHDDM, and HDDMs led to the highest accuracies with both
classiﬁers.
Discussion III - MDDM Variants: Frequently, MDDM-
G and MDDM-E have shorter drift detection delays than
MDDM-A. The reason is to be found in the fact that they both
utilize an exponential weighting scheme (i.e. more weight is
put on the most recent entries which are the ones required
for faster detection) as opposed to MDDM-A which has a
linear one. The reader will notice that the false positive rates
of these two variants against the two streams with gradual
change, namely CIRCLES and LED, were higher than those
of MDDM-A. This is a consequence of the fact that MDDM-A
put more emphasis on the older entries in the window, which,

TABLE I: Hoeffding Tree and Naive Bayes with Drift Detectors against Synthetic Data Streams with Abrupt Change (ζ = 50)

Delay

Detector

FN
0.00
0.00
0.00
0.00

TP
4.00
4.00
4.00
4.00

MDDM-A 38.60 ± 3.38
MDDM-G 38.56 ± 3.36
MDDM-E 38.56 ± 3.36
CUSUM 86.89 ± 4.47

Hoeffding Tree (HT)
FP
0.21 ± 0.43
0.20 ± 0.42
0.20 ± 0.42
0.24 ± 0.47

Naive Bayes (NB)
Accuracy
FP
Delay
Accuracy
86.08 ± 0.25
0.13 ± 0.34
38.55 ± 3.35
87.07 ± 0.16
86.08 ± 0.25
0.14 ± 0.35
38.47 ± 3.35
87.07 ± 0.16
38.46 ± 3.35
86.08 ± 0.25
0.14 ± 0.35
87.07 ± 0.16
83.27 ± 6.96 3.99 ± 0.10 0.71 ± 0.86 0.01 ± 0.10 85.96 ± 0.25
86.94 ± 0.15
PageHinkley 229.24 ± 13.20 2.30 ± 1.07 1.71 ± 1.08 1.70 ± 1.07 86.06 ± 1.34 175.07 ± 24.72 3.71 ± 0.50 0.35 ± 0.54 0.29 ± 0.50 85.69 ± 0.27
DDM 163.11 ± 22.73 3.36 ± 0.77 3.30 ± 2.20 0.64 ± 0.77 86.06 ± 1.34 179.18 ± 26.83 2.87 ± 0.84 3.09 ± 1.88 1.13 ± 0.84 82.39 ± 4.32
EDDM 243.83 ± 14.25 0.22 ± 0.44 33.90 ± 11.61 3.78 ± 0.44 84.71 ± 0.55 234.28 ± 22.22 0.57 ± 0.64 33.53 ± 11.50 3.43 ± 0.64 83.44 ± 2.87
89.72 ± 16.45 3.99 ± 0.10 3.93 ± 2.91 0.01 ± 0.10 85.98 ± 0.27
RDDM 93.63 ± 7.57
4.72 ± 3.58
85.93 ± 0.23
63.92 ± 0.80 4.00 ± 0.00 3.86 ± 1.09
ADWIN 63.84 ± 1.12 4.00 ± 0.00 7.31 ± 3.18
4.83 ± 1.16
85.59 ± 0.25
4.26 ± 0.58
4.00
88.03 ± 25.73 3.97 ± 0.17 0.35 ± 0.55 0.03 ± 0.17 85.95 ± 0.25
0.71 ± 0.89
86.09 ± 0.25
0.41 ± 0.58
35.52 ± 3.10
0.46 ± 0.68
86.08 ± 0.25
0.04 ± 0.20
40.48 ± 3.37
0.10 ± 0.33

86.79 ± 0.18
86.67 ± 0.21
86.53 ± 0.15
87.01 ± 0.16
87.07 ± 0.15
87.07 ± 0.16

HDDMA-test 57.62 ± 11.81
HDDMW-test 35.70 ± 2.95
FHDDM 40.65 ± 3.15

0.00
0.00
0.00
0.00
0.00
0.00

FN
0.00
0.00
0.00

TP
4.00
4.00
4.00

4.00
4.00
4.00
4.00

SeqDrift2

4.00
4.00

0.00
0.00

0.00
0.00

200.00

200.00

4.00

0.00
0.00
0.00
0.00

4.00
4.00
4.00
4.00

1.11 ± 1.15
1.19 ± 1.21
1.19 ± 1.21
0.32 ± 0.58

MDDM-A 38.38 ± 3.66
MDDM-G 38.28 ± 3.64
MDDM-E 38.28 ± 3.64
CUSUM 90.90 ± 6.13

83.37 ± 0.09
0.69 ± 0.89
38.52 ± 3.81
83.36 ± 0.11
83.37 ± 0.09
0.70 ± 0.89
38.41 ± 3.81
83.36 ± 0.11
38.41 ± 3.81
83.37 ± 0.09
0.70 ± 0.89
83.36 ± 0.11
88.23 ± 8.97 3.99 ± 0.10 0.35 ± 0.54 0.01 ± 0.10 83.27 ± 0.08
83.27 ± 0.12
PageHinkley 229.91 ± 13.27 2.26 ± 0.98 1.74 ± 0.98 1.74 ± 0.98 82.88 ± 0.11 198.79 ± 18.72 3.56 ± 0.65 0.44 ± 0.65 0.44 ± 0.65 82.97 ± 0.10
DDM 195.73 ± 22.12 2.76 ± 1.01 2.91 ± 1.96 1.24 ± 1.01 81.78 ± 2.06 192.99 ± 23.82 2.78 ± 1.00 2.41 ± 1.44 1.22 ± 1.00 80.28 ± 4.11
EDDM 248.46 ± 7.69 0.05 ± 0.22 21.51 ± 7.70 3.95 ± 0.22 80.65 ± 0.82
247.47 ± 8.60 0.11 ± 0.31 20.22 ± 7.66 3.89 ± 0.31 80.30 ± 2.32
RDDM 106.68 ± 11.26 3.99 ± 0.10 3.49 ± 2.47 0.01 ± 0.10 83.16 ± 0.12 104.97 ± 12.06 3.99 ± 0.10 1.86 ± 1.65 0.01 ± 0.10 83.24 ± 0.09
83.28 ± 0.08
ADWIN 64.72 ± 2.79 4.00 ± 0.00 4.84 ± 2.44
64.48 ± 1.90 4.00 ± 0.00 3.47 ± 1.42
4.98 ± 1.20
82.91 ± 0.08
4.39 ± 0.79
4.00
83.71 ± 19.46 3.96 ± 0.20 0.48 ± 0.64 0.04 ± 0.20 83.28 ± 0.09
1.28 ± 1.09
83.36 ± 0.09
1.77 ± 1.39
35.75 ± 3.94
3.23 ± 1.95
83.38 ± 0.08
0.25 ± 0.48
40.56 ± 3.72
0.65 ± 0.94

HDDMA-test 69.42 ± 15.51
HDDMW-test 35.56 ± 3.50
FHDDM 40.55 ± 3.70

83.25 ± 0.12
82.91 ± 0.11
83.31 ± 0.11
83.27 ± 0.12
83.39 ± 0.10

0.00
0.00
0.00
0.00
0.00

4.00
4.00
4.00
4.00

0.00
0.00
0.00

4.00
4.00
4.00

SeqDrift2

0.00
0.00

4.00
4.00

0.00
0.00

200.00

200.00

t
p
u
r
b
A

-

1
E
N
I
S

t
p
u
r
b
A

-

D
E
X
I
M

TABLE II: Hoeffding Tree and Naive Bayes with Drift Detectors against Synthetic Data Streams with Gradual Change (ζ = 500)

Hoeffding Tree (HT)

Naive Bayes (NB)

Delay

Delay

Detector

FN
0.00
0.00
0.00

TP
3.00
3.00
3.00

MDDM-A 71.98 ± 22.19
MDDM-G 69.42 ± 22.09
MDDM-E 69.52 ± 22.12

CUSUM 220.07 ± 31.79 2.99 ± 0.10
PageHinkley 855.37 ± 56.27 1.79 ± 0.45
DDM 487.97 ± 82.24 2.78 ± 0.52

FP
0.27 ± 0.51
0.36 ± 0.61
0.37 ± 0.61
0.04 ± 0.20
1.24 ± 0.47
1.41 ± 1.24

Accuracy
161.25 ± 87.26 2.95 ± 0.22
86.58 ± 0.16
161.73 ± 89.49 2.94 ± 0.24
86.58 ± 0.17
161.74 ± 89.49 2.94 ± 0.24
86.57 ± 0.17
299.78 ± 52.29
0.01 ± 0.10 86.51 ± 0.13
1.21 ± 0.45 85.96 ± 0.15
677.32 ± 76.30 2.11 ± 0.55
0.22 ± 0.52 86.21 ± 0.47 703.59 ± 122.67 1.92 ± 0.72

0.05 ± 0.22 84.14 ± 0.12
0.06 ± 0.24 84.14 ± 0.12
0.06 ± 0.24 84.14 ± 0.12
84.08 ± 0.12
0.89 ± 0.55 83.94 ± 0.13
1.08 ± 0.72 83.18 ± 1.61
EDDM 987.61 ± 54.35 0.07 ± 0.26 24.61 ± 14.48 2.93 ± 0.26 84.89 ± 0.29 938.27 ± 106.60 0.35 ± 0.50 31.09 ± 18.14 2.65 ± 0.50 83.12 ± 0.40
0.01 ± 0.10 84.05 ± 0.11
RDDM 293.80 ± 38.52 2.98 ± 0.14
0.01 ± 0.10 84.12 ± 0.11
ADWIN 236.48 ± 130.94 2.67 ± 0.47
0.08 ± 0.27 84.13 ± 0.14
0.09 ± 0.29 84.09 ± 0.12
0.27 ± 0.44 84.11 ± 0.13
0.04 ± 0.20 84.14 ± 0.13

406.50 ± 69.40 2.99 ± 0.10
222.61 ± 57.00 2.99 ± 0.10
276.67 ± 91.10 2.92 ± 0.27
0.04 ± 0.20 86.52 ± 0.20 306.91 ± 107.78 2.91 ± 0.29
0.02 ± 0.14 86.53 ± 0.18 242.43 ± 134.19 2.73 ± 0.44
166.13 ± 83.84 2.96 ± 0.20

FP
0.63 ± 0.70
0.80 ± 0.73
0.81 ± 0.73
0.40 ± 0.62
0.93 ± 0.53
2.33 ± 1.49

0.02 ± 0.14 86.46 ± 0.16
0.33 ± 0.47 85.62 ± 0.19
86.47 ± 0.14

0.79 ± 1.25
9.74 ± 3.05
3.08 ± 0.90
0.65 ± 0.92
0.73 ± 0.87
0.17 ± 0.40

2.15 ± 1.94
5.56 ± 2.57
2.49 ± 0.97
0.49 ± 0.69
1.59 ± 1.00
0.43 ± 0.60

HDDMA-test 111.96 ± 68.22 2.96 ± 0.20
HDDMW-test 94.03 ± 57.61 2.98 ± 0.14

SeqDrift2 202.67 ± 16.11

FHDDM 79.28 ± 20.64

86.58 ± 0.13

Accuracy

3.00

3.00

3.00

0.00

0.00

0.00

FN

TP

3.00

CUSUM 300.68 ± 50.30

MDDM-A 210.31 ± 73.05 2.98 ± 0.14
MDDM-G 208.65 ± 73.05 2.98 ± 0.14
MDDM-E 208.61 ± 73.05 2.98 ± 0.14

0.02 ± 0.14 89.57 ± 0.04
0.02 ± 0.14 89.57 ± 0.04
0.02 ± 0.14 89.57 ± 0.04
89.57 ± 0.03
0.05 ± 0.26 89.36 ± 0.04
PageHinkley 560.30 ± 79.43 2.95 ± 0.26
0.04 ± 0.20 89.29 ± 1.15
DDM 444.13 ± 79.82 2.97 ± 0.17
2.30 ± 0.73 88.32 ± 0.53
EDDM 954.97 ± 62.98 0.66 ± 0.71
RDDM 321.88 ± 50.94 2.98 ± 0.14
0.02 ± 0.14 89.63 ± 0.04
ADWIN 521.47 ± 239.71 2.40 ± 0.77 474.95 ± 14.12 0.60 ± 0.77 72.25 ± 0.49 521.36 ± 238.56 2.36 ± 0.76 465.41 ± 12.53 0.64 ± 0.76 72.73 ± 0.44
SeqDrift2 426.00 ± 173.31 2.78 ± 0.44 277.0 ± 47.5 0.22 ± 0.44 76.51 ± 2.28 445.33 ± 192.27 2.75 ± 0.46 278.8 ± 47.5 0.25 ± 0.46 76.54 ± 2.25
0.02 ± 0.20 89.58 ± 0.05
0.05 ± 0.26 89.56 ± 0.03
0.03 ± 0.22 89.57 ± 0.04

210.31 ± 73.05 2.98 ± 0.14
208.65 ± 73.05 2.98 ± 0.14
208.61 ± 73.05 2.98 ± 0.14
300.61 ± 50.30
559.27 ± 78.99 2.95 ± 0.26
446.23 ± 82.12 2.96 ± 0.20
949.61 ± 68.94 0.70 ± 0.73
321.80 ± 50.94 2.98 ± 0.14

0.02 ± 0.14 89.56 ± 0.04
0.02 ± 0.14 89.56 ± 0.04
0.02 ± 0.14 89.56 ± 0.04
89.56 ± 0.03
0.05 ± 0.26 89.35 ± 0.04
0.03 ± 0.17 89.47 ± 0.56
2.34 ± 0.71 88.33 ± 0.50
0.02 ± 0.14 89.63 ± 0.04

HDDMA-test 295.03 ± 85.29 2.98 ± 0.20
HDDMW-test 259.18 ± 87.25 2.95 ± 0.26
FHDDM 220.40 ± 76.00 2.97 ± 0.22

0.03 ± 0.17
0.03 ± 0.17
0.03 ± 0.17
0.00
0.04 ± 0.24
0.32 ± 0.58
5.97 ± 1.69
0.61 ± 0.96

0.03 ± 0.17
0.03 ± 0.17
0.03 ± 0.17
0.00
0.04 ± 0.24
0.33 ± 0.58
6.33 ± 1.96
0.61 ± 0.96

295.85 ± 83.23 2.98 ± 0.20
259.17 ± 87.21 2.95 ± 0.26
220.40 ± 76.00 2.97 ± 0.22

0.02 ± 0.20 89.58 ± 0.05
0.05 ± 0.26 89.56 ± 0.04
0.03 ± 0.22 89.56 ± 0.04

0.16 ± 0.44
0.08 ± 0.31
0.03 ± 0.22

0.17 ± 0.47
0.05 ± 0.22
0.03 ± 0.22

0.00

3.00

0.00

l
a
u
d
a
r
G

-

S
E
L
C
R
I

C

l
a
u
d
a
r
G

-

3

.

1

.

3

.

0

D
E
L

in these cases are beneﬁcial to the learning process. All three
variants had comparable levels of accuracy. In general, one
may observe that an exponential-like scheme is beneﬁcial in
scenarios when faster detection is required. It follows that the
optimal shape for the weighting function is data, context and
application dependent.

2) Real-world Data Streams: There is a consensus among
researchers that the locations and/or the presence of concept
drift in the ELECTRICITY, FOREST COVERTYPE, and POKER
HAND data streams are not known [4], [9], [20], [28], [36].

This implies, in turn, that the drift detection delay as well as
the false positive and false negative rates cannot be determined
since the knowledge of the drift locations is necessary in order
to evaluate these quantities. Consequently, our evaluation is
based on the overall accuracy and the number of alarms for
concept drifts issued by each drift detector. We have also
considered blind adaptation and no detection approaches as
benchmarks for our experiments. In the blind adaptation, the
classiﬁer is retrained ab initio at every 100 instances. The
classiﬁers are trained without drift detectors in the case of no

detection. Similar to [9], a window of size 25 was selected
for FHDDM and MDDMs against real-world datasets. Our
experiments have shown that this choice is optimal in terms
of accuracy.

Table III presents the experimental results for ELECTRIC-
ITY, FOREST COVERTYPE, and POKER HAND data streams
with the Hoeffding Tree (HT) and Naive Bayes (NB) classi-
ﬁers. Firstly, the Hoeffding Tree classiﬁer showed higher clas-
siﬁcation accuracies compared to Naive Bayes when executed
without drift detector. This suggests that the Hoeffding Tree
classiﬁer could branch out and adequately reﬂect the new pat-
terns. Secondly, both classiﬁers achieved higher classiﬁcation
accuracies by using drift detection. Although this observation
indicates that using drift detection methods is beneﬁcial com-
pared to the no detection case, it does not necessarily mean
that a drift detector outperforms the others. Indeed, in a recent
study by Bifet et al. [10], it was found that blind detection has
the highest classiﬁcation accuracies, against the ELECTRICITY
and FOREST COVERTYPE data streams. Based on multiple
experiments, Bifet et al. [10] concluded that this behavior
may be explained by the temporal dependencies in between
the instances of the streams. As shown in Table III, a drift
detection method with a higher number of alarms usually led
to a higher classiﬁcation accuracy. In such a case, a classiﬁer
learns from a small portion of the data stream where almost
all instances are labeled with a common label (this refers to
temporal dependencies among examples as stated by Bifet et
al. [10]). To support this observation, as mentioned earlier, we
considered a blind adaptation as a benchmark. As shown in
the same table, the blind adaptation led to the highest or the
second highest classiﬁcation accuracies. We further extended
our experiments by running MDDMs with higher values of
δw. Recall that a higher δ implies that the drift detection
technique is less conservative. As indicated in the table, as

MDDMs became less conservative,
the number of alarms
as well as the classiﬁcation accuracies increased. Therefore,
because of temporal dependencies, both classiﬁers repeatedly
learned from instances presenting the same labels between two
consecutive alarms.

In summary, we concluded that using drift detection meth-
ods against real-world data streams is beneﬁcial. Nevertheless,
we are not in a position to make a strong statement based
solely on the accuracy because (1) the location of the drift
is unknown, and (2) because of the temporal dependencies
in between instances [10]. MDDM consistently led to high
classiﬁcation accuracies. Particularly, MDDM achieved the
highest classiﬁcation accuracies in all cases when the value
of δw increased from 10−6 to 0.001 and 0.01.

VIII. CONCLUSION

Sensor networks, smart houses, intelligent transportation,
autopilots are examples of technologies operating in evolving
environments where experiencing concept drifts over time
is commonplace. In order for the learning process to be
more accurate and efﬁcient in evolving environments, concept
drifts should be detected rapidly with false negative rate as
small as possible. In this research paper, we introduced the
McDiarmid Drift Detection Methods (MDDMs) for detecting
concept drifts with shorter delays and lower false negative
rates. We conducted various experiments to compare MDDMs
against the state-of-the-art. Our experimental results indicated
that MDDMs outperformed existing methods in terms of drift
detection delay, false negative, false positive, and classiﬁcation
accuracy rates.

In this paper, we considered incremental learning against
a single stream while evaluating the drift detection methods
accordingly. We aim to investigate streams with heterogeneous
concept drifts, i.e. streams in which different drift types and

TABLE III: Hoeffding Tree (HT) and Naive Bayes (NB) against Real-world Data Stream

Detector

MDDM-A
MDDM-G
MDDM-E
CUSUM
PageHinkley
DDM
EDDM
RDDM
ADWIN
SeqDrift2
HDDMA-test
HDDMW-test
FHDDM
Blind|W| = 100
No Detection

)
w
δ
(

1
0
0
.
0

)

w
δ
(

1
0
.
0

MDDM-A
MDDM-G
MDDM-E

MDDM-A
MDDM-G
MDDM-E

ELECTRICITY

HT

NB

FOREST COVERTYPE

HT

NB

POKER HAND

HT

NB

Alarms
105
105
105
22
6
169
191
143
65
59
210
117
90

453
—

180
182
182

256
252
252

Acc.
84.60
84.60
84.60
81.71
81.95
85.41
84.91
85.18
83.23
82.83
85.71
85.06
84.59

84.26
79.20

85.79
85.78
85.78

85.86
85.98
85.97

Alarms
126
126
126
28
10
143
203
164
88
60
211
132
109

453
—

208
209
209

265
265
266

Acc.
83.47
83.47
83.47
79.21
78.04
81.18
84.83
84.19
81.03
79.68
84.92
84.09
83.13

84.82
73.36

85.00
85.01
85.01

85.60
85.78
85.77

Alarms
1963
1966
1966
226
90
4301
2466
2671
1062
710
3695
2342
1794

5810
—

3253
3270
3270

3884
3969
3980

Acc.
85.33
85.35
85.35
83.01
81.65
87.35
86.00
86.42
83.36
82.85
87.24
85.97
85.08

87.24
80.31

87.03
87.05
87.06

87.63
87.73
87.73

Alarms
2022
2025
2025
286
117
4634
2416
2733
1151
757
3284
2383
185

5810
—

3221
3231
3234

3791
3856
3864

Acc.
85.38
85.39
85.39
81.55
80.06
88.03
86.08
86.86
83.24
82.44
87.42
86.22
85.09

87.70
60.52

87.27
87.29
87.29

87.95
88.05
88.05

Alarms
2036
2034
2034
617
403
1046
4806
2512
1358
1322
2565
2211
1876

8292
—

4320
4370
4369

6075
6095
6091

Acc.
76.89
76.89
76.89
72.85
71.30
72.74
77.30
76.70
73.84
72.51
76.40
77.11
76.72

77.96
76.07

77.82
77.83
77.83

78.18
78.21
78.21

Alarms
2145
2149
2149
659
489
433
4863
2579
1388
1395
2615
2312
1928

8292
—

4378
4425
4427

6099
6118
6116

Acc.
76.83
76.83
76.83
72.54
70.67
61.97
77.48
76.67
73.69
72.25
76.48
77.11
76.68

78.18
59.55

78.03
78.05
78.06

78.51
78.54
78.54

[18] S. Sakthithasan, R. Pears, and Y. S. Koh, “One pass concept change
detection for data streams,” in Paciﬁc-Asia Conference on Knowledge
Discovery and Data Mining. Springer, 2013, pp. 461–472.

[19] A. Pesaranghader, H. Viktor, and E. Paquet, “Reservoir of diverse
adaptive learners and stacking fast hoeffding drift detection methods
for evolving data streams,” arXiv preprint arXiv:1709.02457, 2017.
[20] D. T. J. Huang, Y. S. Koh, G. Dobbie, and A. Bifet, “Drift detection using
stream volatility,” in Joint European Conference on Machine Learning
and Knowledge Discovery in Databases. Springer, 2015, pp. 417–432.
[21] W. Hoeffding, “Probability inequalities for sums of bounded random
variables,” Journal of the American statistical association, vol. 58, no.
301, pp. 13–30, 1963.

[22] S. Bernstein, “The theory of probabilities,” 1946.
[23] R. Klinkenberg, “Learning drifting concepts: Example selection vs.
example weighting,” Intelligent Data Analysis, vol. 8, no. 3, pp. 281–
300, 2004.

[24] A. Bifet, G. Holmes, R. Kirkby, and B. Pfahringer, “Moa: Massive online
analysis,” Journal of Machine Learning Research, vol. 11, no. May, pp.
1601–1604, 2010.

[25] T. M. Mitchell, “Machine learning,” 1997.
[26] R. Sebasti˜ao, J. Gama, and T. Mendonc¸a, “Fading histograms in de-
tecting distribution and concept changes,” International Journal of Data
Science and Analytics, pp. 1–30, 2017.

[27] A. Pesaranghader, H. L. Viktor, and E. Paquet, “A framework for clas-
siﬁcation in data streams using multi-strategy learning,” in International
Conference on Discovery Science. Springer, 2016, pp. 341–355.
[28] A. Bifet, G. Holmes, B. Pfahringer, R. Kirkby, and R. Gavald`a, “New
ensemble methods for evolving data streams,” in Proceedings of the
15th ACM SIGKDD international conference on Knowledge discovery
and data mining. ACM, 2009, pp. 139–148.

[29] R. S. M. de Barros, J. I. G. Hidalgo, and D. R. de Lima Cabral,
“Wilcoxon rank sum test drift detector,” Neurocomputing, 2017.
[30] T. Escovedo, A. Koshiyama, A. A. da Cruz, and M. Vellasco, “Detecta:
abrupt concept drift detection in non-stationary environments,” Applied
Soft Computing, vol. 62, pp. 119–133, 2018.

ˇZliobait˙e, “How good is the electricity benchmark for evaluating

[31] I.

concept drift adaptation,” arXiv preprint arXiv:1301.3524, 2013.
[32] J. A. Blackard and D. J. Dean, “Comparative accuracies of artiﬁcial neu-
ral networks and discriminant analysis in predicting forest cover types
from cartographic variables,” Computers and electronics in agriculture,
vol. 24, no. 3, pp. 131–151, 1999.

[33] M. K. Olorunnimbe, H. L. Viktor, and E. Paquet, “Dynamic adaptation
of online ensembles for drifting data streams,” Journal of Intelligent
Information Systems, pp. 1–23, 2017.

[34] P. Domingos and G. Hulten, “Mining high-speed data streams,” in
Proceedings of the sixth ACM SIGKDD international conference on
Knowledge discovery and data mining. ACM, 2000, pp. 71–80.
[35] B. Krawczyk, L. L. Minku, J. Gama, J. Stefanowski, and M. Wo´zniak,
“Ensemble learning for data stream analysis: a survey,” Information
Fusion, vol. 37, pp. 132–156, 2017.

[36] V. Losing, B. Hammer, and H. Wersing, “Incremental on-line learning: A
review and comparison of state of the art algorithms,” Neurocomputing,
vol. 275, pp. 1261–1274, 2018.

[37] ——, “Knn classiﬁer with self adjusting memory for heterogeneous
concept drift,” in Data Mining (ICDM), 2016 IEEE 16th International
Conference on.

IEEE, 2016, pp. 291–300.

rates overlap. We are in addition interested to compare the per-
formance of MDDMs with proactive drift detection methods,
such as the DetectA algorithm [30], particularly regarding the
detection delay. Further, we aim to apply the notion of multiple
sliding windows stacking, as introduced by Pesaranghader et
al. [19], to the MDDM approaches. We also plan to investigate
adaptive ensemble approaches and self-adjusting algorithms
[37]. Finally, we will assess the performance of drift detection
methods against time-series data streams.

ACKNOWLEDGMENT

The authors wish to acknowledge ﬁnancial support by the
Canadian Natural Sciences and Engineering Research Council
(NSERC) as well as the Ontario Trillium Scholarship (OTS).

REFERENCES

[1] C. McDiarmid, “On the method of bounded differences,” Surveys in

combinatorics, vol. 141, no. 1, pp. 148–188, 1989.

[2] J. Gama, I. ˇZliobait˙e, A. Bifet, M. Pechenizkiy, and A. Bouchachia, “A
survey on concept drift adaptation,” ACM Computing Surveys (CSUR),
vol. 46, no. 4, p. 44, 2014.

[3] A. Bifet, G. Holmes, R. Kirkby, and B. Pfahringer, “Data stream mining

a practical approach,” 2011.

[4] I. Fr´ıas-Blanco, J. del Campo- ´Avila, G. Ramos-Jim´enez, R. Morales-
Bueno, A. Ortiz-D´ıaz, and Y. Caballero-Mota, “Online and non-
parametric drift detection methods based on hoeffdings bounds,” IEEE
Transactions on Knowledge and Data Engineering, vol. 27, no. 3, pp.
810–823, 2015.

[5] I. ˇZliobait˙e, “Learning under concept drift: an overview,” arXiv preprint

arXiv:1010.4784, 2010.

[6] G. Krempl, I.

ˇZliobaite, D. Brzezi´nski, E. H¨ullermeier, M. Last,
V. Lemaire, T. Noack, A. Shaker, S. Sievi, M. Spiliopoulou et al., “Open
challenges for data stream mining research,” ACM SIGKDD explorations
newsletter, vol. 16, no. 1, pp. 1–10, 2014.

[7] P. Duda, M. Jaworski, and L. Rutkowski, “Convergent time-varying
regression models for data streams: Tracking concept drift by the recur-
sive parzen-based generalized regression neural networks,” International
journal of neural systems, p. 1750048, 2017.

[8] R. Pears, S. Sakthithasan, and Y. S. Koh, “Detecting concept change in
dynamic data streams,” Machine Learning, vol. 97, no. 3, pp. 259–293,
2014.

[9] A. Pesaranghader and H. L. Viktor, “Fast hoeffding drift detection
method for evolving data streams,” in Joint European Conference on
Machine Learning and Knowledge Discovery in Databases. Springer,
2016, pp. 96–111.

[10] A. Bifet, “Classiﬁer concept drift detection and the illusion of progress,”
in International Conference on Artiﬁcial Intelligence and Soft Comput-
ing. Springer, 2017, pp. 715–725.

[11] I. ˇZliobait˙e, M. Budka, and F. Stahl, “Towards cost-sensitive adaptation:
when is it worth updating your predictive model?” Neurocomputing, vol.
150, pp. 240–249, 2015.

[12] E. Page, “Continuous inspection schemes,” Biometrika, vol. 41, no. 1/2,

pp. 100–115, 1954.

[13] J. Gama, P. Medas, G. Castillo, and P. Rodrigues, “Learning with drift
detection,” in Brazilian Symposium on Artiﬁcial Intelligence. Springer,
2004, pp. 286–295.

[14] M. Baena-Garcıa, J. del Campo- ´Avila, R. Fidalgo, A. Bifet, R. Gavalda,
and R. Morales-Bueno, “Early drift detection method,” in Fourth inter-
national workshop on knowledge discovery from data streams, vol. 6,
2006, pp. 77–86.

[15] G. J. Ross, N. M. Adams, D. K. Tasoulis, and D. J. Hand, “Exponentially
weighted moving average charts for detecting concept drift,” Pattern
Recognition Letters, vol. 33, no. 2, pp. 191–198, 2012.

[16] R. S. Barros, D. R. Cabral, S. G. Santos et al., “Rddm: Reactive drift

detection method,” Expert Systems with Applications, 2017.

[17] A. Bifet and R. Gavalda, “Learning from time-changing data with

adaptive windowing,” in SDM, vol. 7. SIAM, 2007, p. 2007.

McDiarmid Drift Detection Methods
for Evolving Data Streams

Ali Pesaranghader 1 ((cid:66)), Herna L. Viktor 1, Eric Paquet 1,2
1 School of Electrical Engineering and Computer Science,
University of Ottawa, Ottawa, ON K1N 6N5, Canada
{apesaran, hviktor}@uottawa.ca

2 National Research Council,
1200 Montreal Roard, Ottawa, ON K1A 0R6, Canada
eric.paquet@nrc-cnrc.gc.ca

8
1
0
2
 
n
a
J
 
7
1
 
 
]
L
M

.
t
a
t
s
[
 
 
2
v
0
3
0
2
0
.
0
1
7
1
:
v
i
X
r
a

Abstract—Increasingly, Internet of Things (IoT) domains, such
as sensor networks, smart cities, and social networks, generate
vast amounts of data. Such data are not only unbounded and
rapidly evolving. Rather, the content thereof dynamically evolves
over time, often in unforeseen ways. These variations are due
to so-called concept drifts, caused by changes in the underlying
data generation mechanisms. In a classiﬁcation setting, concept
drift causes the previously learned models to become inaccurate,
unsafe and even unusable. Accordingly, concept drifts need to
be detected, and handled, as soon as possible. In medical appli-
cations and emergency response settings, for example, change
in behaviours should be detected in near real-time, to avoid
potential loss of life. To this end, we introduce the McDiarmid
Drift Detection Method (MDDM), which utilizes McDiarmid’s
inequality [1] in order to detect concept drift. The MDDM
approach proceeds by sliding a window over prediction results,
and associate window entries with weights. Higher weights are
assigned to the most recent entries, in order to emphasize their
importance. As instances are processed, the detection algorithm
compares a weighted mean of elements inside the sliding window
with the maximum weighted mean observed so far. A signiﬁcant
difference between the two weighted means, upper-bounded by
the McDiarmid inequality, implies a concept drift. Our extensive
experimentation against synthetic and real-world data streams
show that our novel method outperforms the state-of-the-art.
Speciﬁcally, MDDM yields shorter detection delays as well as
lower false negative rates, while maintaining high classiﬁcation
accuracies.

I. INTRODUCTION

Traditionally, machine learning algorithms assume that data
are generated by a stationary distribution and collected prior
to learning. These assumptions are not valid in evolving
environments, where the underlying distributions may change
over time: a phenomenon known as concept drift [2], [3]. As
a consequence, classiﬁcation accuracy decreases as concept
drifts take place. Therefore, adaptation to new distributions
is essential to ensure the efﬁciency of the decision-making
process. An adaptive learning algorithm may utilize a drift
detection method for detecting concept drifts in a data stream
[2]. Once the drift detector signals the presence of a concept
drift,
the learning algorithm updates its current model by
considering the new distribution. For the learning process to be
efﬁcient, the drift detector must detect concept drifts rapidly,

while maintaining low false negative and false positive rates.
In this paper, we introduce the McDiarmid Drift Detection
Method (MDDM) which applies the McDiarmid inequality
[1] and various weighting schemes in order to rapidly and
efﬁciently detect concept drifts. Through numerous experi-
ments, we show that MDDM ﬁnds abrupt and gradual concept
drifts with shorter delays and with lower false negative rates,
compared to the state-of-the-art.

This paper is organized as follows. Data stream classiﬁca-
tion and concept drift are formally deﬁned in Sections II and
III, respectively. Section IV describes adaptive learning as a
form of incremental learning from evolving data streams. Sec-
tion V reviews the state-of-the-art for concept drift detection.
In Section VI, we introduce the McDiarmid Drift Detection
Methods (MDDMs). Next, in Section VII, our approaches are
compared with the start-of-the-art for both synthetic and real-
world data streams. We conclude the paper and discuss future
work in Section VIII.

II. DATA STREAM CLASSIFICATION

The primary objective of data stream classiﬁcation is to
incrementally, using the (current) available
build a model
data, the so-called training data, for predicting the label of
unseen examples. Data stream classiﬁcation may be deﬁned
as follows:

Let a stream S be a sequence of
instances:
(X1, y1), (X2, y2), ..., (Xt, yt) . The pair (Xt, yt) rep-
resents an instance arriving at time t, where Xt is a
vector containing k attributes: Xt = (x1, x2, ..., xk),
while yt is a class label which belongs to a set
of size m, yt ∈ {c1, c2, ..., cm}. Assume a target
function yt = f (Xt) which maps an input vector to
a particular class label. The learning task consists of
incrementally building a model ˜f that approximates
the function f at all time. Naturally, an approxima-
tion which maximizes the classiﬁcation accuracy is
preferred [4].

Bifet et al. [3] recommend that incremental learning algo-
rithms should fulﬁll four essential requirements for data stream
mining: (1) the examples should be processed one-by-one and

only once in the order of their arrival, (2) memory usage
should be constrained as the size of a data stream is typically
substantially larger than the size of the available memory, (3)
all the calculations should be performed in real-time or at least,
in near real-time, and (4) the outcome of the classiﬁcation
process should be available at any time.

III. CONCEPT DRIFT DEFINITION

The Bayesian Decision Theory is commonly employed
in describing classiﬁcation processes based on their prior
i.e. p(y), and the class
probability distribution of classes,
conditional probability distribution, i.e. p(X|y) [2], [5]. The
classiﬁcation decision is related to the posterior probabilities
of the classes. The posterior probability associated with class
ci, given instance X, is obtained by:

p(ci|X) =

p(ci) · p(X|ci)
p(X)

where p(X) = (cid:80)m
i=1 p(ci) · p(X|ci) is the marginal probability
distribution. Formally, if a concept drift occurs in between
time t0 and t1 we have:

∃X : pt0 (X, y) (cid:54)= pt1 (X, y)

(2)

where pt0 and pt1 represent the joint probability distributions
at time t0 and t1, respectively [2]. Eq. (2) implies that the
data distribution at times t0 and t1 are distinct, as their joint
probabilities differ. From Eq. (1), it may be observed that a
concept drift may occur [2]:

• As a result of a change in the class conditional probability

p(y),

distribution p(X|y),

• As a result of a change in the posterior probability dis-
tribution p(y|X), thus affecting the classiﬁcation decision
boundaries.

Gama et al. [2], ˇZliobait˙e [5], and Krempl et al. [6] classify
changes into two types, namely real concept drift and virtual
concept drift. A real concept drift refers to the changes in
p(y|X) which affects the decision boundaries or the target
concept (as shown in Fig. 1 (b)). On the other hand, virtual
drift is the result of a change in p(X), and subsequently in
p(X|y), but not in p(y|X). That is, a virtual drift is a change
in the distribution of the incoming data which implies that
the decision boundaries remain unaffected (as in Fig. 1 (c)).
From a predictive perspective, adaptation is required once a
real concept drift occurs, since the current decision boundary
turns out to be obsolete [2], [6].

A. Concept Drift Patterns

A concept drift may appear in different patterns [5]; as
illustrated in Fig. 2 (Note that colors represent different distri-
butions). An abrupt concept drift results from a sudden change
in the data distribution. On the other hand, a gradual concept
drift results from a slow transition from one data distribution
to the next. That is, the two patterns may coexist concurrently

(a) Original Data

(b) Real Drift

(c) Virtual Drift

Fig. 1: Real Concept Drift vs. Virtual Concept Drift
(Similar to Fig. 1 in [2])

(1)

(Fig. 2 (b)). In an incremental concept drift, a sequence of
data distributions appear during the transition. In re-occurring
concept drift, a previously active concept reappears after some
time, as shown in Fig. 2 (d). In practice, a mixture of different
concept drifts may be present in the stream.

(a) Abrupt

(b) Gradual

Fig. 2: Patterns of Concept Drifts
(Similar to Fig. 2 in [2])

IV. ADAPTIVE DATA STREAM LEARNING
As learning algorithms are often trained in non-stationary
environments, where concept drift is inevitable, they must have
the capacity to adapt to new situations [7]. Gama et al. [2]
deﬁned adaptive learning as a form of advance incremental
learning in which concept drifts are detected while the clas-
siﬁcation models are updated accordingly. Adaptive learning
algorithms must fulﬁll the following requirements in order
to maintain high predictive performances [8], [9], [10]: (1)
Minimum false positive and false negative rates – an adaptive
algorithm must detect concept drifts with a small number
of false positives and false negatives. A high false positive
rate involves more model retraining which in turn requires
more computational resources [11]. On the other hand, a high
false negative rate reduces the classiﬁcation accuracy, as the
current model does not reﬂect the new distribution. (2) Short
drift detection delay – An adaptive learning algorithm should
detect concept drifts rapidly, and update its predictive model in
quasi real-time in order to maintain the classiﬁcation accuracy.
(3) Robustness to noise – adaptive learners must be able to
distinguish concept drift from noise. Indeed, no adaptation is
required if noise is present in a stream.

• As a result of a change in the prior probability distribution

(c) Incremental

(d) Re-occurring

V. CONCEPT DRIFT DETECTION METHODS

Change detection methods refer to techniques and algo-
rithms that detect concept drifts and distributional changes
explicitly. Drift detection methods characterize and quantify
concept drifts by discovering the change points or small time
intervals during which concept drifts occur. Gama et al. [2]
classify concept drift detectors into three groups:

1) Sequential Analysis based Methods sequentially evaluate
prediction results as they become available. They alarm
for concept drifts when a pre-deﬁned threshold is met.
The Cumulative Sum (CUSUM) and its variant Page-
Hinkley (PH) [12] are representatives of this group.
2) Statistical based Approaches analyze statistical parame-
ters such as the mean and the standard deviation associ-
ated with the predicted results in order to detect concept
drifts. The Drift Detection Method (DDM) [13], Early
Drift Detection Method (EDDM) [14], Exponentially
Weighted Moving Average (EWMA) [15], and Reactive
Drift Detection Method (RDDM) [16] are members of
this group.

3) Windows based Methods usually utilize a ﬁxed reference
window for summarizing the past information and a
sliding window for summarizing the most recent infor-
mation. A signiﬁcant difference in between the distri-
butions of these two windows implies the occurrence
of a drift. Statistical tests or mathematical inequalities,
with the null-hypothesis indicating that the distributions
are equal, are employed. The Adaptive Windowing
(ADWIN) [17],
the
Drift Detection Methods based on Hoeffding’s Bound
(HDDMA-test and HDDMW-test) [4], Fast Hoeffding Drift
Detection Method (FHDDM) [9] and its stacking version
(FHDDMS) [19] are members of this family.

the SeqDrift detectors [8], [18],

CUSUM and its variant PageHinkley (PH) are some of
the pioneer methods in the community. DDM, EDDM, and
ADWIN have frequently been considered as benchmarks in the
literature [4], [9], [14], [17], [20]. RDDM, SeqDrift2, HDDMs,
and FHDDM present similar performances. For these reasons,
all these methods are evaluated in our experiments. Due to
page limitations, we do not provide descriptions of these
algorithms; therefore, we refer the interested reader to [2], [19]
for further details. The pros and cons of these approaches are
discussed below.

Discussion – CUSUM and PageHinkley (PH) detect concept
drifts from the deviation of the observed values from their
mean and alarm for a drift when this difference exceeds
a user-deﬁned threshold. These algorithms are sensitive to
the parameter values, resulting in a trade-off between false
alarms and detecting true drifts [2], [3]. DDM and EDDM
require less memory as only a small number of variables is
maintained [2]. On the other hand, the ADWIN and SeqDrift2
approaches necessitate multiple subsets of the stream which
lead to more memory consumption. They may computationally
be expensive, due to the sub-window compression or reservoir
sampling procedures. Barros et al. [16] observed that, RDDM

leads to a higher classiﬁcation accuracy compared to DDM,
especially against datasets with gradual concept drift, despite
an increase in false positives. EDDM may frequently alarm for
concept drift in the early stages of learning if the distances in
between wrong predictions are small. HDDM and FHDDM
employ the Hoeffding inequality [21]. FHDDM differs from
HDDM by sliding a window on prediction results for detecting
concept drifts. Recall that SeqDrift2 employs the Bernstein
inequality [22] in order to detect concept drift. SeqDrift2 uses
the sample variance, and assumes that the sampled data follow
a normal distribution. This assumption may be too restrictive,
in real-world domains. Further, the Bernstein inequality is
conservative and requires a variance parameter, in contrast
to, for instance, the Hoeffding inequality. These shortcomings
may lead to a longer detection delay and a potential loss of
accuracy. In the next section, we introduce McDiarmid Drift
Detection Method (MDDM) for detecting concept drifts faster.

VI. MCDIARMID DRIFT DETECTION METHODS

In a streaming environment, one may assume that old ex-
amples are either obsolete or outdated. Therefore, incremental
learners should rely on the most recent examples for training,
the current situation more adequately.
as the latter reﬂect
Fading or weighting approaches are typically used by online
learning algorithms to increase the weight attributed to the
most recent instances [2]. This is important from an adaptive
learning perspective, especially when a transition between two
contexts is occurring. For instance, Klinkenberg [23] relies on
an exponential weighting scheme wλ(Xi) = exp(−λi), where
λ is a parameter and i is the entry index, to assign lower
weights to old examples. Based on this observation, assigning
higher weights to recent predictions could potentially result
in a faster detection of concept drifts. In this section, we
introduce the McDiarmid Drift Detection Methods (MDDMs)
which utilizes a weighting scheme to ponderate the elements
of its sliding window for faster detection of concept drifts. We
also discuss variants of MDDM as well as the sensitivity of
their parameters.

A. McDiarmid Drift Detection Methods (MDDMs)

The McDiarmid Drift Detection Method (MDDM) applies
McDiarmid’s inequality [1] to detect concept drifts in evolving
data streams. The MDDM algorithm slides a window of size n
over the prediction results. It inserts a 1 into the window if the
prediction result is correct; and 0 otherwise. Each element in
the window is associated with a weight, as illustrated in Fig.
3, where wi < wi+1. While inputs are processed, the weighted
average of the elements of the sliding window is calculated,
i.e. µt
w, as well as the maximum weighted mean observed so
far, i.e. µm

w , as indicated in Eq. (3).

if µm

w < µt

w ⇒ µm

w = µt
w

(3)

Recall that MDDM relies on the assumption that by weight-
ing the prediction results associated with a sliding window,
and by putting more emphasis on the most recent elements,
concept drift could be detected faster and more efﬁciently.

Given the rule wi < wi+1, the elements located at the head
of the window have higher weights than those located at
the tail. Different weighting schemes have been considered
including the arithmetic and the geometric schemes. The
arithmetic scheme is given by wi = 1 + (i − 1) ∗ d, where
d ≥ 0 is the difference between two consecutive weights.
The geometric scheme is given by wi = r(i−1), where
r ≥ 1 is the ratio of two consecutive weights. In addition,
we employ the Euler scheme which is deﬁned by r = eλ
where λ ≥ 0. We have implemented three weighted drift
detection methods based on these three schemes: MDDM-A
(A for arithmetic), MDDM-G (G for geometric), and MDDM-
E (E for Euler)1. All these methods are described below. As
the prediction results are processed one-by-one, the algorithm
calculates the weighted average of the elements inside the
sliding window, and simultaneously updates two variables µt
w
(i.e. the current weighted average) and µm
w (i.e. the maximum
weighted average observed so far). A signiﬁcant difference
between µm
w implies a concept drift.

w and µt

Fig. 3: McDiarmid Drift Detection Method (General Scheme)

On the basis of the PAC learning model [25], the accuracy
should increase or stay constant as the number of instances
increases; otherwise, the possibility of facing drifts increases
[13], [26]. Thus, the value of µm
w should increase or remain
constant as more instances are processed. In other words, the
possibility of facing a concept drift increases if µm
w does not
change and µt
w decreases over time. Finally, as shown by Eq.
(4), a signiﬁcant difference in between µm
w indicates
the occurrence of a drift:

w and µt

∆µ = µm

w − µt

w ≥ εd ⇒ Drift := True

(4)

The McDiarmid inequality [1] is employed to determine if

the difference is deemed signiﬁcant.

Theorem I: McDiarmid’s Inequality – Let X1, X2, ..., Xn
be n independent random variables all taking values in the set
χ. Further, let f : χn (cid:55)→ R be a function of X1, ..., Xn that
satisﬁes ∀i, ∀x1, ..., xn, x(cid:48)

i ∈ χ,

|f (x1, ..., xi, ..., xn) − f (x1, ..., x(cid:48)

i, ..., xn) | ≤ ci.

This implies that replacing the ith coordinate xi by some
arbitrary value changes the function f by at most ci. Then,

1The source codes are available at https://www.github.com/alipsgh/ (One

may use them with the MOA framework [24]).

(5)

(6)

(8)

for all εM > 0, we have:

Pr{E[f ] − f ≥ εM } ≤ exp

−

(cid:18)

(cid:19)

2ε2
M
i=1 c2
i

(cid:80)n

Consequently, for a given conﬁdence level δM , the value of

εM is obtained by:

εM =

(cid:115) (cid:80)n
i=1 c2
i
2

ln

1
δM

Corollary I: MDDM test – In a streaming context, assume
µt
w is the weighted mean of a sequence of n random entries,
at time t, and µm
w is the maximum weighted mean observed
so far. Recall that each entry pi is in {0, 1} and has a weight
of wi. Let ∆µw = µm
w ≥ 0 be the difference between
these two weighted means. Given the conﬁdence level δw, the
McDiarmid inequality detects a drift if ∆µw ≥ εw, where
(cid:115) (cid:80)n
i=1 v2
i
2

w − µt

εw =

(7)

ln

1
δw

and where vi is given by

vi =

wi
i=1 wi

(cid:80)n

All three of our MDDM approaches apply Corollary I in
order to detect concept drift. In addition,
the McDiarmid
inequality allows for comparing the expectation of a function
of the random variables, such as the maximum, with the
function “per se”. This stands in contrast with, for instance
the Hoeffding inequality [21], in which the comparison is
restricted to the expectation of the random variables with their
empirical mean.

The pseudocode for the MDDM algorithm appears in Al-
gorithm 1. Firstly,
the INITIALIZE function initializes the
parameters, including the window size n, conﬁdence level δw,
εw, the sliding window win, and µm
w . As the data stream
examples are processed, the prediction results are pushed into
the window (lines 8-14). The algorithm updates the variables
w and µm
µt
w over time (lines 15-17). Finally, a drift is detected
if (µm
w) ≥ εw (lines 18-21). Recall
that we have
wi = 1+(i−1)∗d for MDDM-A, wi = r(i−1) for MDDM-G,
and wi = eλ(i−1) for MDDM-E.

w − µt

B. Discussion On Variants of MDDM

Recall that the MDDM-A approach employs an arithmetic
scheme wi = 1+(i−1)∗d, where wi+1 −wi = d meaning that
the weights increase linearly. On the the other hand, MDDM-
G applies the geometric scheme wi = r(i−1), indicating that
the weights increase exponentially with wi+1/wi = r (Note
that r = eλ for MDDM-E). The linear or exponential nature
of the weighting scheme affects the detection delay and the
false positive rate. That is, the exponential weighting scheme
often results in a faster concept drift detection, but at the
expense of a higher false positive rate if compared to the
linear weighting scheme. These statements are supported by
experimental results in Section VII.

Algorithm 1 McDiarmid Drift Detection Method

1: function INITIALIZE(windowSize, delta)
(n, δw) ← (windowSize, delta)
2:
εw = CALCULATEEPSILON()
3:
RESET()
4:
5: function RESET()
win = []
6:
µm
w = 0
7:
8: function DETECT(pr)

(cid:46) Creating an empty sliding window.

(cid:46) The pr is 1 for correct predictions, 0

(cid:46) Dropping an element from the tail.
(cid:46) Pushing an element into the head.

w = GETWEIGHTEDMEAN()

otherwise.

9:
10:

if win.size() = n then
win.tail.drop()

else

return False

win.push(pr)
if win.size() < n then

µt
w < µt
if µm
w then
w = µt
µm
w
∆µw = µm
w − µt
w
if ∆µw ≥ εw then

11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24: function CALCULATEEPSILON()
i=1 v2
25:
(cid:113) S

RESET()
return True

return False

S = (cid:80)n
return

else

26:

i

2 ln 1
δw

27: function GETWEIGHTEDMEAN()
i=1(pi × wi)/ (cid:80)n
28:

return (cid:80)n

i=1 wi

(cid:46) Resetting parameters.
(cid:46) Signaling for an alarm.

(cid:46) vi = wi/ (cid:80)n

i=1 wi

C. Parameters Sensitivity Analysis

The parameters n and δw are inversely proportional with
respect to εw. That is, as the value of n increases, the value of
εw decreases. This implies that, as more observations become
available, a more optimistic error bound should be applied.
On the other hand, as the value of δw decreases, the values of
εw increases (i.e. the bound becomes more conservative). The
parameter d in MDDM-A controls the scale of the weights
assigned to the sliding window elements. The value of εw
increases, as the value of d increases. Larger values of d lead
to faster drift detection, since higher weights are assigned to
the element located at the head of the window; however, the
false positive rate may increase. MDDM-G and MDDM-E
behave similarly; the scale of their weight is determined by
their parameters r and λ, respectively. That is, a higher r or
λ leads to a shorter detection delay, but at the expense of a
higher false positive rate. In order to set the default values
of these parameters, we conducted a number of experiments
against various synthetic data streams. We gradually increased
the values of these parameters to ﬁnd the optimal values:
δw = 10−6, d = 0.01, r = 1.01, and λ = 0.01.

VII. EXPERIMENTAL EVALUATION

A. Benchmarking Data Streams

are all widely found in the literature [4], [9], [13], [15],
[16], [27], [28], [29]. Each data stream consists of 100, 000
instances. A class noise of 10% was added to each stream in
order to evaluate the robustness of the drift detectors against
noisy data2. The synthetic data streams are described below.

• SINE1 · with abrupt drift: It has two attributes x and y
uniformly distributed on the interval [0, 1]. The classiﬁ-
cation function is y = sin(x). Instances are classiﬁed as
positive if they are under the curve; otherwise, they are
negative. At a drift point, the classiﬁcation is reversed
[9], [13], [14], [15].

• MIXED · with abrupt drift: The dataset has two numeric
attributes x and y distributed in [0, 1] with two boolean
attributes v and w. The instances are classiﬁed as positive
two of the three following conditions are
if at
satisﬁed: v, w, y < 0.5+0.3∗sin(3πx). The classiﬁcation
is reversed when drift points occur [9], [13], [16].

least

• CIRCLES · with gradual drift: It has two attributes x
and y distributed in [0, 1]. The classiﬁcation function is
the circle equation (x − xc)2 + (y − yc)2 = r2
c where
(xc, yc) and rc are the center and the radius of the circle,
respectively. Instances inside the circle are classiﬁed as
positive. Four different circles are employed in order to
simulate concept drift [9], [13], [14].

• LED · with gradual drift: The objective of this dataset
is to predict the digit on a seven-segment display, where
each digit has a 10% chance of being displayed. The
dataset has 7 class attributes, and 17 irrelevant ones. Con-
cept drift is simulated by interchanging relevant attributes
[4], [28], [29].

Concept Drift Simulation – Following Bifet et al. [28], we
used the sigmoid function to simulate abrupt and gradual
concept drifts. The function determines the probability of
belonging to a new context during a transition between two
concepts. The transition length ζ allows to simulate abrupt
or gradual concept drifts. The value was set to 50 for abrupt
concept drifts, and to 500 for gradual concept drifts in all our
experiments. To summarize, the drifts occur at every 20, 000
instances in SINE1 and MIXED with ζ = 50 for abrupt drift,
and at every 25, 000 instances in CIRCLES and LED with
ζ = 500 for gradual drift.

2) Real-world Data Streams: We extended our experiments
to real-world data streams3; which are frequently employed in
the online learning and adaptive learning literature [4], [9],
[13], [14], [15], [27], [28], [30]. Three data streams were
selected in our comparative study.

• ELECTRICITY · It contains 45, 312 instances, with 8
input attributes, recorded every half hour for two years by
the Australian New South Wales Electricity. The classiﬁer
must predict a rise (Up) or a fall (Down) in the electricity
price. The concept drift may result from changes in
consumption habits or unexpected events [31].

1) Synthetic Data Streams: We generated four synthetic
data streams from SINE1, MIXED, CIRCLES and LED, which

2Available at: https://www.github.com/alipsgh/data streams/.
3Available at: https://moa.cms.waikato.ac.nz/datasets/2013/.

• FOREST COVERTYPE · It consists of 54 attributes with
581, 012 instances describing 7 forest cover types for 30×
30 meter cells obtained from US Forest Service (USFS)
information system, for 4 wilderness areas located in the
Roosevelt National Forest of Northern Colorado [32].
• POKER HAND · It is composed of 1, 000, 000 instances,
where each instance is an example of ﬁve cards drawn
from a standard 52 cards deck. Each card is described by
two attributes (suit and rank), for a total of ten predictive
attributes. The classiﬁer predicts the poker hand [33].

B. Experiment Settings

We used the MOA framework [24] for our experiments.
We selected Hoeffding Tree (HT) [34] and Naive Bayes
(NB) as our incremental classiﬁers; and compared MDDMs
with CUSUM, PageHinkley, DDM, EDDM, RDDM, ADWIN,
SeqDrift2, HDDMs, and FHDDM. The default parameters
were employed for both the classiﬁers and the drift detection
methods. The algorithms were evaluated prequentially which
means that an instance is ﬁrst tested and then used for training
[35].

Pesaranghader et al. [9] introduced the acceptable delay
length notion for measuring detection delay and for determin-
ing true positive (TP), false positive (FP), and false negative
(FN) rates. The acceptable delay length ∆ is a threshold that
determines how far a given alarm should be from the true
location of a concept drift to be considered a true positive.
That is, we maintain three variables to count the numbers of
true positives, false negatives and false positives which are
initially set to zero. Therefore, the number of true positives
is incremented when the drift detector alarm occurs within
the acceptable delay range. Otherwise, the number of false
negatives is incremented as the alarm occurred too late. In
addition, the false positive value is incremented when a false
alarm occurs outside the acceptable delay range. Following
this approach, we set ∆ to 250 for the SINE1, MIXED, and
to 1000 for the CIRCLES and LED data streams. A longer ∆
should be considered for data streams with gradual drifts in
order to avoid a false negative increase.

Following [9], for both MDDMs and FHDDM, the window
size was set to 25 for the SINE1 and MIXED, and to 100 for the
CIRCLES and LED data streams. We used a wider window for
the CIRCLES and LED data streams in order to better detect
gradual concept drifts. These window sizes were chosen in
order to have shorter detection delay, as well as lower false
positive and false negative rates. Experiments were performed
on an Intel Core i5 @ 2.8 GHz with 16 GB of RAM running
Apple OS X Yosemite.

C. Experiments and Discussion

1) Synthetic Data Streams: Our experimental

results
against the synthetic data streams are presented in Tables I
and II. Recall that as we are aware of the locations of drifts
in synthetic data streams, we can evaluate the detection delay,
true positive (TP), false positive (FP) and false negative (FN).
We discuss the experimental results in the following:

Discussion I - SINE1 and MIXED (Abrupt Drift): As
represented in Table I, MDDMs and HDDMW-test detected
concept drifts with shorter delays against SINE1 and MIXED
data streams. MDDM, FHDDM, CUSUM and HDDMA-test
resulted in the lowest false positive rates. This observation may
indicate that MDDM, FHDDM, CUSUM, and HDDMA-test are
more accurate. Although RDDM had shorter detection delays
and false negative rates compared to DDM and EDDM, it
caused higher false positive rates. EDDM had the highest
false positive rates. Moreover, EDDM had the highest false
negative rates since it could not detect concept drifts within the
acceptable delay length. MDDMs showed comparable results
against
the other methods. As shown in Table I, for the
Hoeffding Tree classiﬁer, the highest classiﬁcation accuracies
was obtained with MDDMs and FHDDM, since they detected
drifts with the shortest delays and the lowest false positive
rates. Similar observations apply to the Naive Bayes classiﬁer.
It may be noticed that the false positive rate is lower for
Naive Bayes. This suggests that the Naive Bayes classiﬁer
represented the decision boundaries more accurately for noisy
SINE1 and MIXED data streams.
Discussion II - CIRCLES and LED (Gradual Drift): Table
II shows the results with the Hoeffding Tree and Naive Bayes
classiﬁers against the CIRCLES and LED data streams. The
MDDM algorithms resulted in the shortest concept drift detec-
tion delays, followed by FHDDM and HDDMW-test. Compared
to FHDDM, MDDMs detected concept drifts faster because of
its weighting schemes which favor the most recent elements.
On the other hand, EDDM produced the longest drift detection
delays. It also had the highest false negative rates. MDDMs,
FHDDM, CUSUM, RDDM, and HDDMs had the highest
true positive rates. EDDM showed the highest false positive
rates against the CIRCLES data streams. We achieved higher
accuracies with Hoeffding Tree than with Naive Bayes against
the CIRCLES data stream. In the case of the LED data streams,
ADWIN and SeqDrift2 triggered a relatively large number
of false alarms. Indeed, this could be potentially alleviated
by decreasing their conﬁdence levels, i.e. δ, to make their
tests more restrictive. SeqDrift2 caused fewer false positives
compared to ADWIN, since it applies a more conservative test
(Bernstein’s inequality). Although RDDM outperformed DDM
in all cases, in terms of detection delays and false negative
rates, it showed higher false positive rates. Finally, MDDMs,
FHDDM, and HDDMs led to the highest accuracies with both
classiﬁers.
Discussion III - MDDM Variants: Frequently, MDDM-
G and MDDM-E have shorter drift detection delays than
MDDM-A. The reason is to be found in the fact that they both
utilize an exponential weighting scheme (i.e. more weight is
put on the most recent entries which are the ones required
for faster detection) as opposed to MDDM-A which has a
linear one. The reader will notice that the false positive rates
of these two variants against the two streams with gradual
change, namely CIRCLES and LED, were higher than those
of MDDM-A. This is a consequence of the fact that MDDM-A
put more emphasis on the older entries in the window, which,

TABLE I: Hoeffding Tree and Naive Bayes with Drift Detectors against Synthetic Data Streams with Abrupt Change (ζ = 50)

Delay

Detector

FN
0.00
0.00
0.00
0.00

TP
4.00
4.00
4.00
4.00

MDDM-A 38.60 ± 3.38
MDDM-G 38.56 ± 3.36
MDDM-E 38.56 ± 3.36
CUSUM 86.89 ± 4.47

Hoeffding Tree (HT)
FP
0.21 ± 0.43
0.20 ± 0.42
0.20 ± 0.42
0.24 ± 0.47

Naive Bayes (NB)
Accuracy
FP
Delay
Accuracy
86.08 ± 0.25
0.13 ± 0.34
38.55 ± 3.35
87.07 ± 0.16
86.08 ± 0.25
0.14 ± 0.35
38.47 ± 3.35
87.07 ± 0.16
38.46 ± 3.35
86.08 ± 0.25
0.14 ± 0.35
87.07 ± 0.16
83.27 ± 6.96 3.99 ± 0.10 0.71 ± 0.86 0.01 ± 0.10 85.96 ± 0.25
86.94 ± 0.15
PageHinkley 229.24 ± 13.20 2.30 ± 1.07 1.71 ± 1.08 1.70 ± 1.07 86.06 ± 1.34 175.07 ± 24.72 3.71 ± 0.50 0.35 ± 0.54 0.29 ± 0.50 85.69 ± 0.27
DDM 163.11 ± 22.73 3.36 ± 0.77 3.30 ± 2.20 0.64 ± 0.77 86.06 ± 1.34 179.18 ± 26.83 2.87 ± 0.84 3.09 ± 1.88 1.13 ± 0.84 82.39 ± 4.32
EDDM 243.83 ± 14.25 0.22 ± 0.44 33.90 ± 11.61 3.78 ± 0.44 84.71 ± 0.55 234.28 ± 22.22 0.57 ± 0.64 33.53 ± 11.50 3.43 ± 0.64 83.44 ± 2.87
89.72 ± 16.45 3.99 ± 0.10 3.93 ± 2.91 0.01 ± 0.10 85.98 ± 0.27
RDDM 93.63 ± 7.57
4.72 ± 3.58
85.93 ± 0.23
63.92 ± 0.80 4.00 ± 0.00 3.86 ± 1.09
ADWIN 63.84 ± 1.12 4.00 ± 0.00 7.31 ± 3.18
4.83 ± 1.16
85.59 ± 0.25
4.26 ± 0.58
4.00
88.03 ± 25.73 3.97 ± 0.17 0.35 ± 0.55 0.03 ± 0.17 85.95 ± 0.25
0.71 ± 0.89
86.09 ± 0.25
0.41 ± 0.58
35.52 ± 3.10
0.46 ± 0.68
86.08 ± 0.25
0.04 ± 0.20
40.48 ± 3.37
0.10 ± 0.33

86.79 ± 0.18
86.67 ± 0.21
86.53 ± 0.15
87.01 ± 0.16
87.07 ± 0.15
87.07 ± 0.16

HDDMA-test 57.62 ± 11.81
HDDMW-test 35.70 ± 2.95
FHDDM 40.65 ± 3.15

0.00
0.00
0.00
0.00
0.00
0.00

FN
0.00
0.00
0.00

TP
4.00
4.00
4.00

4.00
4.00
4.00
4.00

SeqDrift2

4.00
4.00

0.00
0.00

0.00
0.00

200.00

200.00

4.00

0.00
0.00
0.00
0.00

4.00
4.00
4.00
4.00

1.11 ± 1.15
1.19 ± 1.21
1.19 ± 1.21
0.32 ± 0.58

MDDM-A 38.38 ± 3.66
MDDM-G 38.28 ± 3.64
MDDM-E 38.28 ± 3.64
CUSUM 90.90 ± 6.13

83.37 ± 0.09
0.69 ± 0.89
38.52 ± 3.81
83.36 ± 0.11
83.37 ± 0.09
0.70 ± 0.89
38.41 ± 3.81
83.36 ± 0.11
38.41 ± 3.81
83.37 ± 0.09
0.70 ± 0.89
83.36 ± 0.11
88.23 ± 8.97 3.99 ± 0.10 0.35 ± 0.54 0.01 ± 0.10 83.27 ± 0.08
83.27 ± 0.12
PageHinkley 229.91 ± 13.27 2.26 ± 0.98 1.74 ± 0.98 1.74 ± 0.98 82.88 ± 0.11 198.79 ± 18.72 3.56 ± 0.65 0.44 ± 0.65 0.44 ± 0.65 82.97 ± 0.10
DDM 195.73 ± 22.12 2.76 ± 1.01 2.91 ± 1.96 1.24 ± 1.01 81.78 ± 2.06 192.99 ± 23.82 2.78 ± 1.00 2.41 ± 1.44 1.22 ± 1.00 80.28 ± 4.11
EDDM 248.46 ± 7.69 0.05 ± 0.22 21.51 ± 7.70 3.95 ± 0.22 80.65 ± 0.82
247.47 ± 8.60 0.11 ± 0.31 20.22 ± 7.66 3.89 ± 0.31 80.30 ± 2.32
RDDM 106.68 ± 11.26 3.99 ± 0.10 3.49 ± 2.47 0.01 ± 0.10 83.16 ± 0.12 104.97 ± 12.06 3.99 ± 0.10 1.86 ± 1.65 0.01 ± 0.10 83.24 ± 0.09
83.28 ± 0.08
ADWIN 64.72 ± 2.79 4.00 ± 0.00 4.84 ± 2.44
64.48 ± 1.90 4.00 ± 0.00 3.47 ± 1.42
4.98 ± 1.20
82.91 ± 0.08
4.39 ± 0.79
4.00
83.71 ± 19.46 3.96 ± 0.20 0.48 ± 0.64 0.04 ± 0.20 83.28 ± 0.09
1.28 ± 1.09
83.36 ± 0.09
1.77 ± 1.39
35.75 ± 3.94
3.23 ± 1.95
83.38 ± 0.08
0.25 ± 0.48
40.56 ± 3.72
0.65 ± 0.94

HDDMA-test 69.42 ± 15.51
HDDMW-test 35.56 ± 3.50
FHDDM 40.55 ± 3.70

83.25 ± 0.12
82.91 ± 0.11
83.31 ± 0.11
83.27 ± 0.12
83.39 ± 0.10

0.00
0.00
0.00
0.00
0.00

4.00
4.00
4.00
4.00

0.00
0.00
0.00

4.00
4.00
4.00

SeqDrift2

0.00
0.00

4.00
4.00

0.00
0.00

200.00

200.00

t
p
u
r
b
A

-

1
E
N
I
S

t
p
u
r
b
A

-

D
E
X
I
M

TABLE II: Hoeffding Tree and Naive Bayes with Drift Detectors against Synthetic Data Streams with Gradual Change (ζ = 500)

Hoeffding Tree (HT)

Naive Bayes (NB)

Delay

Delay

Detector

FN
0.00
0.00
0.00

TP
3.00
3.00
3.00

MDDM-A 71.98 ± 22.19
MDDM-G 69.42 ± 22.09
MDDM-E 69.52 ± 22.12

CUSUM 220.07 ± 31.79 2.99 ± 0.10
PageHinkley 855.37 ± 56.27 1.79 ± 0.45
DDM 487.97 ± 82.24 2.78 ± 0.52

FP
0.27 ± 0.51
0.36 ± 0.61
0.37 ± 0.61
0.04 ± 0.20
1.24 ± 0.47
1.41 ± 1.24

Accuracy
161.25 ± 87.26 2.95 ± 0.22
86.58 ± 0.16
161.73 ± 89.49 2.94 ± 0.24
86.58 ± 0.17
161.74 ± 89.49 2.94 ± 0.24
86.57 ± 0.17
299.78 ± 52.29
0.01 ± 0.10 86.51 ± 0.13
1.21 ± 0.45 85.96 ± 0.15
677.32 ± 76.30 2.11 ± 0.55
0.22 ± 0.52 86.21 ± 0.47 703.59 ± 122.67 1.92 ± 0.72

0.05 ± 0.22 84.14 ± 0.12
0.06 ± 0.24 84.14 ± 0.12
0.06 ± 0.24 84.14 ± 0.12
84.08 ± 0.12
0.89 ± 0.55 83.94 ± 0.13
1.08 ± 0.72 83.18 ± 1.61
EDDM 987.61 ± 54.35 0.07 ± 0.26 24.61 ± 14.48 2.93 ± 0.26 84.89 ± 0.29 938.27 ± 106.60 0.35 ± 0.50 31.09 ± 18.14 2.65 ± 0.50 83.12 ± 0.40
0.01 ± 0.10 84.05 ± 0.11
RDDM 293.80 ± 38.52 2.98 ± 0.14
0.01 ± 0.10 84.12 ± 0.11
ADWIN 236.48 ± 130.94 2.67 ± 0.47
0.08 ± 0.27 84.13 ± 0.14
0.09 ± 0.29 84.09 ± 0.12
0.27 ± 0.44 84.11 ± 0.13
0.04 ± 0.20 84.14 ± 0.13

406.50 ± 69.40 2.99 ± 0.10
222.61 ± 57.00 2.99 ± 0.10
276.67 ± 91.10 2.92 ± 0.27
0.04 ± 0.20 86.52 ± 0.20 306.91 ± 107.78 2.91 ± 0.29
0.02 ± 0.14 86.53 ± 0.18 242.43 ± 134.19 2.73 ± 0.44
166.13 ± 83.84 2.96 ± 0.20

FP
0.63 ± 0.70
0.80 ± 0.73
0.81 ± 0.73
0.40 ± 0.62
0.93 ± 0.53
2.33 ± 1.49

0.02 ± 0.14 86.46 ± 0.16
0.33 ± 0.47 85.62 ± 0.19
86.47 ± 0.14

0.79 ± 1.25
9.74 ± 3.05
3.08 ± 0.90
0.65 ± 0.92
0.73 ± 0.87
0.17 ± 0.40

2.15 ± 1.94
5.56 ± 2.57
2.49 ± 0.97
0.49 ± 0.69
1.59 ± 1.00
0.43 ± 0.60

HDDMA-test 111.96 ± 68.22 2.96 ± 0.20
HDDMW-test 94.03 ± 57.61 2.98 ± 0.14

SeqDrift2 202.67 ± 16.11

FHDDM 79.28 ± 20.64

86.58 ± 0.13

Accuracy

3.00

3.00

3.00

0.00

0.00

0.00

FN

TP

3.00

CUSUM 300.68 ± 50.30

MDDM-A 210.31 ± 73.05 2.98 ± 0.14
MDDM-G 208.65 ± 73.05 2.98 ± 0.14
MDDM-E 208.61 ± 73.05 2.98 ± 0.14

0.02 ± 0.14 89.57 ± 0.04
0.02 ± 0.14 89.57 ± 0.04
0.02 ± 0.14 89.57 ± 0.04
89.57 ± 0.03
0.05 ± 0.26 89.36 ± 0.04
PageHinkley 560.30 ± 79.43 2.95 ± 0.26
0.04 ± 0.20 89.29 ± 1.15
DDM 444.13 ± 79.82 2.97 ± 0.17
2.30 ± 0.73 88.32 ± 0.53
EDDM 954.97 ± 62.98 0.66 ± 0.71
RDDM 321.88 ± 50.94 2.98 ± 0.14
0.02 ± 0.14 89.63 ± 0.04
ADWIN 521.47 ± 239.71 2.40 ± 0.77 474.95 ± 14.12 0.60 ± 0.77 72.25 ± 0.49 521.36 ± 238.56 2.36 ± 0.76 465.41 ± 12.53 0.64 ± 0.76 72.73 ± 0.44
SeqDrift2 426.00 ± 173.31 2.78 ± 0.44 277.0 ± 47.5 0.22 ± 0.44 76.51 ± 2.28 445.33 ± 192.27 2.75 ± 0.46 278.8 ± 47.5 0.25 ± 0.46 76.54 ± 2.25
0.02 ± 0.20 89.58 ± 0.05
0.05 ± 0.26 89.56 ± 0.03
0.03 ± 0.22 89.57 ± 0.04

210.31 ± 73.05 2.98 ± 0.14
208.65 ± 73.05 2.98 ± 0.14
208.61 ± 73.05 2.98 ± 0.14
300.61 ± 50.30
559.27 ± 78.99 2.95 ± 0.26
446.23 ± 82.12 2.96 ± 0.20
949.61 ± 68.94 0.70 ± 0.73
321.80 ± 50.94 2.98 ± 0.14

0.02 ± 0.14 89.56 ± 0.04
0.02 ± 0.14 89.56 ± 0.04
0.02 ± 0.14 89.56 ± 0.04
89.56 ± 0.03
0.05 ± 0.26 89.35 ± 0.04
0.03 ± 0.17 89.47 ± 0.56
2.34 ± 0.71 88.33 ± 0.50
0.02 ± 0.14 89.63 ± 0.04

HDDMA-test 295.03 ± 85.29 2.98 ± 0.20
HDDMW-test 259.18 ± 87.25 2.95 ± 0.26
FHDDM 220.40 ± 76.00 2.97 ± 0.22

0.03 ± 0.17
0.03 ± 0.17
0.03 ± 0.17
0.00
0.04 ± 0.24
0.32 ± 0.58
5.97 ± 1.69
0.61 ± 0.96

0.03 ± 0.17
0.03 ± 0.17
0.03 ± 0.17
0.00
0.04 ± 0.24
0.33 ± 0.58
6.33 ± 1.96
0.61 ± 0.96

295.85 ± 83.23 2.98 ± 0.20
259.17 ± 87.21 2.95 ± 0.26
220.40 ± 76.00 2.97 ± 0.22

0.02 ± 0.20 89.58 ± 0.05
0.05 ± 0.26 89.56 ± 0.04
0.03 ± 0.22 89.56 ± 0.04

0.16 ± 0.44
0.08 ± 0.31
0.03 ± 0.22

0.17 ± 0.47
0.05 ± 0.22
0.03 ± 0.22

3.00

0.00

0.00

l
a
u
d
a
r
G

-

S
E
L
C
R
I

C

l
a
u
d
a
r
G

-

3

.

1

.

3

.

0

D
E
L

in these cases are beneﬁcial to the learning process. All three
variants had comparable levels of accuracy. In general, one
may observe that an exponential-like scheme is beneﬁcial in
scenarios when faster detection is required. It follows that the
optimal shape for the weighting function is data, context and
application dependent.

2) Real-world Data Streams: There is a consensus among
researchers that the locations and/or the presence of concept
drift in the ELECTRICITY, FOREST COVERTYPE, and POKER
HAND data streams are not known [4], [9], [20], [28], [36].

This implies, in turn, that the drift detection delay as well as
the false positive and false negative rates cannot be determined
since the knowledge of the drift locations is necessary in order
to evaluate these quantities. Consequently, our evaluation is
based on the overall accuracy and the number of alarms for
concept drifts issued by each drift detector. We have also
considered blind adaptation and no detection approaches as
benchmarks for our experiments. In the blind adaptation, the
classiﬁer is retrained ab initio at every 100 instances. The
classiﬁers are trained without drift detectors in the case of no

detection. Similar to [9], a window of size 25 was selected
for FHDDM and MDDMs against real-world datasets. Our
experiments have shown that this choice is optimal in terms
of accuracy.

Table III presents the experimental results for ELECTRIC-
ITY, FOREST COVERTYPE, and POKER HAND data streams
with the Hoeffding Tree (HT) and Naive Bayes (NB) classi-
ﬁers. Firstly, the Hoeffding Tree classiﬁer showed higher clas-
siﬁcation accuracies compared to Naive Bayes when executed
without drift detector. This suggests that the Hoeffding Tree
classiﬁer could branch out and adequately reﬂect the new pat-
terns. Secondly, both classiﬁers achieved higher classiﬁcation
accuracies by using drift detection. Although this observation
indicates that using drift detection methods is beneﬁcial com-
pared to the no detection case, it does not necessarily mean
that a drift detector outperforms the others. Indeed, in a recent
study by Bifet et al. [10], it was found that blind detection has
the highest classiﬁcation accuracies, against the ELECTRICITY
and FOREST COVERTYPE data streams. Based on multiple
experiments, Bifet et al. [10] concluded that this behavior
may be explained by the temporal dependencies in between
the instances of the streams. As shown in Table III, a drift
detection method with a higher number of alarms usually led
to a higher classiﬁcation accuracy. In such a case, a classiﬁer
learns from a small portion of the data stream where almost
all instances are labeled with a common label (this refers to
temporal dependencies among examples as stated by Bifet et
al. [10]). To support this observation, as mentioned earlier, we
considered a blind adaptation as a benchmark. As shown in
the same table, the blind adaptation led to the highest or the
second highest classiﬁcation accuracies. We further extended
our experiments by running MDDMs with higher values of
δw. Recall that a higher δ implies that the drift detection
technique is less conservative. As indicated in the table, as

MDDMs became less conservative,
the number of alarms
as well as the classiﬁcation accuracies increased. Therefore,
because of temporal dependencies, both classiﬁers repeatedly
learned from instances presenting the same labels between two
consecutive alarms.

In summary, we concluded that using drift detection meth-
ods against real-world data streams is beneﬁcial. Nevertheless,
we are not in a position to make a strong statement based
solely on the accuracy because (1) the location of the drift
is unknown, and (2) because of the temporal dependencies
in between instances [10]. MDDM consistently led to high
classiﬁcation accuracies. Particularly, MDDM achieved the
highest classiﬁcation accuracies in all cases when the value
of δw increased from 10−6 to 0.001 and 0.01.

VIII. CONCLUSION

Sensor networks, smart houses, intelligent transportation,
autopilots are examples of technologies operating in evolving
environments where experiencing concept drifts over time
is commonplace. In order for the learning process to be
more accurate and efﬁcient in evolving environments, concept
drifts should be detected rapidly with false negative rate as
small as possible. In this research paper, we introduced the
McDiarmid Drift Detection Methods (MDDMs) for detecting
concept drifts with shorter delays and lower false negative
rates. We conducted various experiments to compare MDDMs
against the state-of-the-art. Our experimental results indicated
that MDDMs outperformed existing methods in terms of drift
detection delay, false negative, false positive, and classiﬁcation
accuracy rates.

In this paper, we considered incremental learning against
a single stream while evaluating the drift detection methods
accordingly. We aim to investigate streams with heterogeneous
concept drifts, i.e. streams in which different drift types and

TABLE III: Hoeffding Tree (HT) and Naive Bayes (NB) against Real-world Data Stream

Detector

MDDM-A
MDDM-G
MDDM-E
CUSUM
PageHinkley
DDM
EDDM
RDDM
ADWIN
SeqDrift2
HDDMA-test
HDDMW-test
FHDDM
Blind|W| = 100
No Detection

)
w
δ
(

1
0
0
.
0

)

w
δ
(

1
0
.
0

MDDM-A
MDDM-G
MDDM-E

MDDM-A
MDDM-G
MDDM-E

ELECTRICITY

HT

NB

FOREST COVERTYPE

HT

NB

POKER HAND

HT

NB

Alarms
105
105
105
22
6
169
191
143
65
59
210
117
90

453
—

180
182
182

256
252
252

Acc.
84.60
84.60
84.60
81.71
81.95
85.41
84.91
85.18
83.23
82.83
85.71
85.06
84.59

84.26
79.20

85.79
85.78
85.78

85.86
85.98
85.97

Alarms
126
126
126
28
10
143
203
164
88
60
211
132
109

453
—

208
209
209

265
265
266

Acc.
83.47
83.47
83.47
79.21
78.04
81.18
84.83
84.19
81.03
79.68
84.92
84.09
83.13

84.82
73.36

85.00
85.01
85.01

85.60
85.78
85.77

Alarms
1963
1966
1966
226
90
4301
2466
2671
1062
710
3695
2342
1794

5810
—

3253
3270
3270

3884
3969
3980

Acc.
85.33
85.35
85.35
83.01
81.65
87.35
86.00
86.42
83.36
82.85
87.24
85.97
85.08

87.24
80.31

87.03
87.05
87.06

87.63
87.73
87.73

Alarms
2022
2025
2025
286
117
4634
2416
2733
1151
757
3284
2383
185

5810
—

3221
3231
3234

3791
3856
3864

Acc.
85.38
85.39
85.39
81.55
80.06
88.03
86.08
86.86
83.24
82.44
87.42
86.22
85.09

87.70
60.52

87.27
87.29
87.29

87.95
88.05
88.05

Alarms
2036
2034
2034
617
403
1046
4806
2512
1358
1322
2565
2211
1876

8292
—

4320
4370
4369

6075
6095
6091

Acc.
76.89
76.89
76.89
72.85
71.30
72.74
77.30
76.70
73.84
72.51
76.40
77.11
76.72

77.96
76.07

77.82
77.83
77.83

78.18
78.21
78.21

Alarms
2145
2149
2149
659
489
433
4863
2579
1388
1395
2615
2312
1928

8292
—

4378
4425
4427

6099
6118
6116

Acc.
76.83
76.83
76.83
72.54
70.67
61.97
77.48
76.67
73.69
72.25
76.48
77.11
76.68

78.18
59.55

78.03
78.05
78.06

78.51
78.54
78.54

[18] S. Sakthithasan, R. Pears, and Y. S. Koh, “One pass concept change
detection for data streams,” in Paciﬁc-Asia Conference on Knowledge
Discovery and Data Mining. Springer, 2013, pp. 461–472.

[19] A. Pesaranghader, H. Viktor, and E. Paquet, “Reservoir of diverse
adaptive learners and stacking fast hoeffding drift detection methods
for evolving data streams,” arXiv preprint arXiv:1709.02457, 2017.
[20] D. T. J. Huang, Y. S. Koh, G. Dobbie, and A. Bifet, “Drift detection using
stream volatility,” in Joint European Conference on Machine Learning
and Knowledge Discovery in Databases. Springer, 2015, pp. 417–432.
[21] W. Hoeffding, “Probability inequalities for sums of bounded random
variables,” Journal of the American statistical association, vol. 58, no.
301, pp. 13–30, 1963.

[22] S. Bernstein, “The theory of probabilities,” 1946.
[23] R. Klinkenberg, “Learning drifting concepts: Example selection vs.
example weighting,” Intelligent Data Analysis, vol. 8, no. 3, pp. 281–
300, 2004.

[24] A. Bifet, G. Holmes, R. Kirkby, and B. Pfahringer, “Moa: Massive online
analysis,” Journal of Machine Learning Research, vol. 11, no. May, pp.
1601–1604, 2010.

[25] T. M. Mitchell, “Machine learning,” 1997.
[26] R. Sebasti˜ao, J. Gama, and T. Mendonc¸a, “Fading histograms in de-
tecting distribution and concept changes,” International Journal of Data
Science and Analytics, pp. 1–30, 2017.

[27] A. Pesaranghader, H. L. Viktor, and E. Paquet, “A framework for clas-
siﬁcation in data streams using multi-strategy learning,” in International
Conference on Discovery Science. Springer, 2016, pp. 341–355.
[28] A. Bifet, G. Holmes, B. Pfahringer, R. Kirkby, and R. Gavald`a, “New
ensemble methods for evolving data streams,” in Proceedings of the
15th ACM SIGKDD international conference on Knowledge discovery
and data mining. ACM, 2009, pp. 139–148.

[29] R. S. M. de Barros, J. I. G. Hidalgo, and D. R. de Lima Cabral,
“Wilcoxon rank sum test drift detector,” Neurocomputing, 2017.
[30] T. Escovedo, A. Koshiyama, A. A. da Cruz, and M. Vellasco, “Detecta:
abrupt concept drift detection in non-stationary environments,” Applied
Soft Computing, vol. 62, pp. 119–133, 2018.

ˇZliobait˙e, “How good is the electricity benchmark for evaluating

[31] I.

concept drift adaptation,” arXiv preprint arXiv:1301.3524, 2013.
[32] J. A. Blackard and D. J. Dean, “Comparative accuracies of artiﬁcial neu-
ral networks and discriminant analysis in predicting forest cover types
from cartographic variables,” Computers and electronics in agriculture,
vol. 24, no. 3, pp. 131–151, 1999.

[33] M. K. Olorunnimbe, H. L. Viktor, and E. Paquet, “Dynamic adaptation
of online ensembles for drifting data streams,” Journal of Intelligent
Information Systems, pp. 1–23, 2017.

[34] P. Domingos and G. Hulten, “Mining high-speed data streams,” in
Proceedings of the sixth ACM SIGKDD international conference on
Knowledge discovery and data mining. ACM, 2000, pp. 71–80.
[35] B. Krawczyk, L. L. Minku, J. Gama, J. Stefanowski, and M. Wo´zniak,
“Ensemble learning for data stream analysis: a survey,” Information
Fusion, vol. 37, pp. 132–156, 2017.

[36] V. Losing, B. Hammer, and H. Wersing, “Incremental on-line learning: A
review and comparison of state of the art algorithms,” Neurocomputing,
vol. 275, pp. 1261–1274, 2018.

[37] ——, “Knn classiﬁer with self adjusting memory for heterogeneous
concept drift,” in Data Mining (ICDM), 2016 IEEE 16th International
Conference on.

IEEE, 2016, pp. 291–300.

rates overlap. We are in addition interested to compare the per-
formance of MDDMs with proactive drift detection methods,
such as the DetectA algorithm [30], particularly regarding the
detection delay. Further, we aim to apply the notion of multiple
sliding windows stacking, as introduced by Pesaranghader et
al. [19], to the MDDM approaches. We also plan to investigate
adaptive ensemble approaches and self-adjusting algorithms
[37]. Finally, we will assess the performance of drift detection
methods against time-series data streams.

ACKNOWLEDGMENT

The authors wish to acknowledge ﬁnancial support by the
Canadian Natural Sciences and Engineering Research Council
(NSERC) as well as the Ontario Trillium Scholarship (OTS).

REFERENCES

[1] C. McDiarmid, “On the method of bounded differences,” Surveys in

combinatorics, vol. 141, no. 1, pp. 148–188, 1989.

[2] J. Gama, I. ˇZliobait˙e, A. Bifet, M. Pechenizkiy, and A. Bouchachia, “A
survey on concept drift adaptation,” ACM Computing Surveys (CSUR),
vol. 46, no. 4, p. 44, 2014.

[3] A. Bifet, G. Holmes, R. Kirkby, and B. Pfahringer, “Data stream mining

a practical approach,” 2011.

[4] I. Fr´ıas-Blanco, J. del Campo- ´Avila, G. Ramos-Jim´enez, R. Morales-
Bueno, A. Ortiz-D´ıaz, and Y. Caballero-Mota, “Online and non-
parametric drift detection methods based on hoeffdings bounds,” IEEE
Transactions on Knowledge and Data Engineering, vol. 27, no. 3, pp.
810–823, 2015.

[5] I. ˇZliobait˙e, “Learning under concept drift: an overview,” arXiv preprint

arXiv:1010.4784, 2010.

[6] G. Krempl, I.

ˇZliobaite, D. Brzezi´nski, E. H¨ullermeier, M. Last,
V. Lemaire, T. Noack, A. Shaker, S. Sievi, M. Spiliopoulou et al., “Open
challenges for data stream mining research,” ACM SIGKDD explorations
newsletter, vol. 16, no. 1, pp. 1–10, 2014.

[7] P. Duda, M. Jaworski, and L. Rutkowski, “Convergent time-varying
regression models for data streams: Tracking concept drift by the recur-
sive parzen-based generalized regression neural networks,” International
journal of neural systems, p. 1750048, 2017.

[8] R. Pears, S. Sakthithasan, and Y. S. Koh, “Detecting concept change in
dynamic data streams,” Machine Learning, vol. 97, no. 3, pp. 259–293,
2014.

[9] A. Pesaranghader and H. L. Viktor, “Fast hoeffding drift detection
method for evolving data streams,” in Joint European Conference on
Machine Learning and Knowledge Discovery in Databases. Springer,
2016, pp. 96–111.

[10] A. Bifet, “Classiﬁer concept drift detection and the illusion of progress,”
in International Conference on Artiﬁcial Intelligence and Soft Comput-
ing. Springer, 2017, pp. 715–725.

[11] I. ˇZliobait˙e, M. Budka, and F. Stahl, “Towards cost-sensitive adaptation:
when is it worth updating your predictive model?” Neurocomputing, vol.
150, pp. 240–249, 2015.

[12] E. Page, “Continuous inspection schemes,” Biometrika, vol. 41, no. 1/2,

pp. 100–115, 1954.

[13] J. Gama, P. Medas, G. Castillo, and P. Rodrigues, “Learning with drift
detection,” in Brazilian Symposium on Artiﬁcial Intelligence. Springer,
2004, pp. 286–295.

[14] M. Baena-Garcıa, J. del Campo- ´Avila, R. Fidalgo, A. Bifet, R. Gavalda,
and R. Morales-Bueno, “Early drift detection method,” in Fourth inter-
national workshop on knowledge discovery from data streams, vol. 6,
2006, pp. 77–86.

[15] G. J. Ross, N. M. Adams, D. K. Tasoulis, and D. J. Hand, “Exponentially
weighted moving average charts for detecting concept drift,” Pattern
Recognition Letters, vol. 33, no. 2, pp. 191–198, 2012.

[16] R. S. Barros, D. R. Cabral, S. G. Santos et al., “Rddm: Reactive drift

detection method,” Expert Systems with Applications, 2017.

[17] A. Bifet and R. Gavalda, “Learning from time-changing data with

adaptive windowing,” in SDM, vol. 7. SIAM, 2007, p. 2007.

McDiarmid Drift Detection Methods
for Evolving Data Streams

Ali Pesaranghader 1 ((cid:66)), Herna L. Viktor 1, Eric Paquet 1,2
1 School of Electrical Engineering and Computer Science,
University of Ottawa, Ottawa, ON K1N 6N5, Canada
{apesaran, hviktor}@uottawa.ca

2 National Research Council,
1200 Montreal Roard, Ottawa, ON K1A 0R6, Canada
eric.paquet@nrc-cnrc.gc.ca

8
1
0
2
 
n
a
J
 
7
1
 
 
]
L
M

.
t
a
t
s
[
 
 
2
v
0
3
0
2
0
.
0
1
7
1
:
v
i
X
r
a

Abstract—Increasingly, Internet of Things (IoT) domains, such
as sensor networks, smart cities, and social networks, generate
vast amounts of data. Such data are not only unbounded and
rapidly evolving. Rather, the content thereof dynamically evolves
over time, often in unforeseen ways. These variations are due
to so-called concept drifts, caused by changes in the underlying
data generation mechanisms. In a classiﬁcation setting, concept
drift causes the previously learned models to become inaccurate,
unsafe and even unusable. Accordingly, concept drifts need to
be detected, and handled, as soon as possible. In medical appli-
cations and emergency response settings, for example, change
in behaviours should be detected in near real-time, to avoid
potential loss of life. To this end, we introduce the McDiarmid
Drift Detection Method (MDDM), which utilizes McDiarmid’s
inequality [1] in order to detect concept drift. The MDDM
approach proceeds by sliding a window over prediction results,
and associate window entries with weights. Higher weights are
assigned to the most recent entries, in order to emphasize their
importance. As instances are processed, the detection algorithm
compares a weighted mean of elements inside the sliding window
with the maximum weighted mean observed so far. A signiﬁcant
difference between the two weighted means, upper-bounded by
the McDiarmid inequality, implies a concept drift. Our extensive
experimentation against synthetic and real-world data streams
show that our novel method outperforms the state-of-the-art.
Speciﬁcally, MDDM yields shorter detection delays as well as
lower false negative rates, while maintaining high classiﬁcation
accuracies.

I. INTRODUCTION

Traditionally, machine learning algorithms assume that data
are generated by a stationary distribution and collected prior
to learning. These assumptions are not valid in evolving
environments, where the underlying distributions may change
over time: a phenomenon known as concept drift [2], [3]. As
a consequence, classiﬁcation accuracy decreases as concept
drifts take place. Therefore, adaptation to new distributions
is essential to ensure the efﬁciency of the decision-making
process. An adaptive learning algorithm may utilize a drift
detection method for detecting concept drifts in a data stream
[2]. Once the drift detector signals the presence of a concept
drift,
the learning algorithm updates its current model by
considering the new distribution. For the learning process to be
efﬁcient, the drift detector must detect concept drifts rapidly,

while maintaining low false negative and false positive rates.
In this paper, we introduce the McDiarmid Drift Detection
Method (MDDM) which applies the McDiarmid inequality
[1] and various weighting schemes in order to rapidly and
efﬁciently detect concept drifts. Through numerous experi-
ments, we show that MDDM ﬁnds abrupt and gradual concept
drifts with shorter delays and with lower false negative rates,
compared to the state-of-the-art.

This paper is organized as follows. Data stream classiﬁca-
tion and concept drift are formally deﬁned in Sections II and
III, respectively. Section IV describes adaptive learning as a
form of incremental learning from evolving data streams. Sec-
tion V reviews the state-of-the-art for concept drift detection.
In Section VI, we introduce the McDiarmid Drift Detection
Methods (MDDMs). Next, in Section VII, our approaches are
compared with the start-of-the-art for both synthetic and real-
world data streams. We conclude the paper and discuss future
work in Section VIII.

II. DATA STREAM CLASSIFICATION

The primary objective of data stream classiﬁcation is to
incrementally, using the (current) available
build a model
data, the so-called training data, for predicting the label of
unseen examples. Data stream classiﬁcation may be deﬁned
as follows:

Let a stream S be a sequence of
instances:
(X1, y1), (X2, y2), ..., (Xt, yt) . The pair (Xt, yt) rep-
resents an instance arriving at time t, where Xt is a
vector containing k attributes: Xt = (x1, x2, ..., xk),
while yt is a class label which belongs to a set
of size m, yt ∈ {c1, c2, ..., cm}. Assume a target
function yt = f (Xt) which maps an input vector to
a particular class label. The learning task consists of
incrementally building a model ˜f that approximates
the function f at all time. Naturally, an approxima-
tion which maximizes the classiﬁcation accuracy is
preferred [4].

Bifet et al. [3] recommend that incremental learning algo-
rithms should fulﬁll four essential requirements for data stream
mining: (1) the examples should be processed one-by-one and

only once in the order of their arrival, (2) memory usage
should be constrained as the size of a data stream is typically
substantially larger than the size of the available memory, (3)
all the calculations should be performed in real-time or at least,
in near real-time, and (4) the outcome of the classiﬁcation
process should be available at any time.

III. CONCEPT DRIFT DEFINITION

The Bayesian Decision Theory is commonly employed
in describing classiﬁcation processes based on their prior
i.e. p(y), and the class
probability distribution of classes,
conditional probability distribution, i.e. p(X|y) [2], [5]. The
classiﬁcation decision is related to the posterior probabilities
of the classes. The posterior probability associated with class
ci, given instance X, is obtained by:

p(ci|X) =

p(ci) · p(X|ci)
p(X)

where p(X) = (cid:80)m
i=1 p(ci) · p(X|ci) is the marginal probability
distribution. Formally, if a concept drift occurs in between
time t0 and t1 we have:

∃X : pt0 (X, y) (cid:54)= pt1 (X, y)

(2)

where pt0 and pt1 represent the joint probability distributions
at time t0 and t1, respectively [2]. Eq. (2) implies that the
data distribution at times t0 and t1 are distinct, as their joint
probabilities differ. From Eq. (1), it may be observed that a
concept drift may occur [2]:

• As a result of a change in the class conditional probability

p(y),

distribution p(X|y),

• As a result of a change in the posterior probability dis-
tribution p(y|X), thus affecting the classiﬁcation decision
boundaries.

Gama et al. [2], ˇZliobait˙e [5], and Krempl et al. [6] classify
changes into two types, namely real concept drift and virtual
concept drift. A real concept drift refers to the changes in
p(y|X) which affects the decision boundaries or the target
concept (as shown in Fig. 1 (b)). On the other hand, virtual
drift is the result of a change in p(X), and subsequently in
p(X|y), but not in p(y|X). That is, a virtual drift is a change
in the distribution of the incoming data which implies that
the decision boundaries remain unaffected (as in Fig. 1 (c)).
From a predictive perspective, adaptation is required once a
real concept drift occurs, since the current decision boundary
turns out to be obsolete [2], [6].

A. Concept Drift Patterns

A concept drift may appear in different patterns [5]; as
illustrated in Fig. 2 (Note that colors represent different distri-
butions). An abrupt concept drift results from a sudden change
in the data distribution. On the other hand, a gradual concept
drift results from a slow transition from one data distribution
to the next. That is, the two patterns may coexist concurrently

(a) Original Data

(b) Real Drift

(c) Virtual Drift

Fig. 1: Real Concept Drift vs. Virtual Concept Drift
(Similar to Fig. 1 in [2])

(1)

(Fig. 2 (b)). In an incremental concept drift, a sequence of
data distributions appear during the transition. In re-occurring
concept drift, a previously active concept reappears after some
time, as shown in Fig. 2 (d). In practice, a mixture of different
concept drifts may be present in the stream.

(a) Abrupt

(b) Gradual

Fig. 2: Patterns of Concept Drifts
(Similar to Fig. 2 in [2])

IV. ADAPTIVE DATA STREAM LEARNING
As learning algorithms are often trained in non-stationary
environments, where concept drift is inevitable, they must have
the capacity to adapt to new situations [7]. Gama et al. [2]
deﬁned adaptive learning as a form of advance incremental
learning in which concept drifts are detected while the clas-
siﬁcation models are updated accordingly. Adaptive learning
algorithms must fulﬁll the following requirements in order
to maintain high predictive performances [8], [9], [10]: (1)
Minimum false positive and false negative rates – an adaptive
algorithm must detect concept drifts with a small number
of false positives and false negatives. A high false positive
rate involves more model retraining which in turn requires
more computational resources [11]. On the other hand, a high
false negative rate reduces the classiﬁcation accuracy, as the
current model does not reﬂect the new distribution. (2) Short
drift detection delay – An adaptive learning algorithm should
detect concept drifts rapidly, and update its predictive model in
quasi real-time in order to maintain the classiﬁcation accuracy.
(3) Robustness to noise – adaptive learners must be able to
distinguish concept drift from noise. Indeed, no adaptation is
required if noise is present in a stream.

• As a result of a change in the prior probability distribution

(c) Incremental

(d) Re-occurring

V. CONCEPT DRIFT DETECTION METHODS

Change detection methods refer to techniques and algo-
rithms that detect concept drifts and distributional changes
explicitly. Drift detection methods characterize and quantify
concept drifts by discovering the change points or small time
intervals during which concept drifts occur. Gama et al. [2]
classify concept drift detectors into three groups:

1) Sequential Analysis based Methods sequentially evaluate
prediction results as they become available. They alarm
for concept drifts when a pre-deﬁned threshold is met.
The Cumulative Sum (CUSUM) and its variant Page-
Hinkley (PH) [12] are representatives of this group.
2) Statistical based Approaches analyze statistical parame-
ters such as the mean and the standard deviation associ-
ated with the predicted results in order to detect concept
drifts. The Drift Detection Method (DDM) [13], Early
Drift Detection Method (EDDM) [14], Exponentially
Weighted Moving Average (EWMA) [15], and Reactive
Drift Detection Method (RDDM) [16] are members of
this group.

3) Windows based Methods usually utilize a ﬁxed reference
window for summarizing the past information and a
sliding window for summarizing the most recent infor-
mation. A signiﬁcant difference in between the distri-
butions of these two windows implies the occurrence
of a drift. Statistical tests or mathematical inequalities,
with the null-hypothesis indicating that the distributions
are equal, are employed. The Adaptive Windowing
(ADWIN) [17],
the
Drift Detection Methods based on Hoeffding’s Bound
(HDDMA-test and HDDMW-test) [4], Fast Hoeffding Drift
Detection Method (FHDDM) [9] and its stacking version
(FHDDMS) [19] are members of this family.

the SeqDrift detectors [8], [18],

CUSUM and its variant PageHinkley (PH) are some of
the pioneer methods in the community. DDM, EDDM, and
ADWIN have frequently been considered as benchmarks in the
literature [4], [9], [14], [17], [20]. RDDM, SeqDrift2, HDDMs,
and FHDDM present similar performances. For these reasons,
all these methods are evaluated in our experiments. Due to
page limitations, we do not provide descriptions of these
algorithms; therefore, we refer the interested reader to [2], [19]
for further details. The pros and cons of these approaches are
discussed below.

Discussion – CUSUM and PageHinkley (PH) detect concept
drifts from the deviation of the observed values from their
mean and alarm for a drift when this difference exceeds
a user-deﬁned threshold. These algorithms are sensitive to
the parameter values, resulting in a trade-off between false
alarms and detecting true drifts [2], [3]. DDM and EDDM
require less memory as only a small number of variables is
maintained [2]. On the other hand, the ADWIN and SeqDrift2
approaches necessitate multiple subsets of the stream which
lead to more memory consumption. They may computationally
be expensive, due to the sub-window compression or reservoir
sampling procedures. Barros et al. [16] observed that, RDDM

leads to a higher classiﬁcation accuracy compared to DDM,
especially against datasets with gradual concept drift, despite
an increase in false positives. EDDM may frequently alarm for
concept drift in the early stages of learning if the distances in
between wrong predictions are small. HDDM and FHDDM
employ the Hoeffding inequality [21]. FHDDM differs from
HDDM by sliding a window on prediction results for detecting
concept drifts. Recall that SeqDrift2 employs the Bernstein
inequality [22] in order to detect concept drift. SeqDrift2 uses
the sample variance, and assumes that the sampled data follow
a normal distribution. This assumption may be too restrictive,
in real-world domains. Further, the Bernstein inequality is
conservative and requires a variance parameter, in contrast
to, for instance, the Hoeffding inequality. These shortcomings
may lead to a longer detection delay and a potential loss of
accuracy. In the next section, we introduce McDiarmid Drift
Detection Method (MDDM) for detecting concept drifts faster.

VI. MCDIARMID DRIFT DETECTION METHODS

In a streaming environment, one may assume that old ex-
amples are either obsolete or outdated. Therefore, incremental
learners should rely on the most recent examples for training,
the current situation more adequately.
as the latter reﬂect
Fading or weighting approaches are typically used by online
learning algorithms to increase the weight attributed to the
most recent instances [2]. This is important from an adaptive
learning perspective, especially when a transition between two
contexts is occurring. For instance, Klinkenberg [23] relies on
an exponential weighting scheme wλ(Xi) = exp(−λi), where
λ is a parameter and i is the entry index, to assign lower
weights to old examples. Based on this observation, assigning
higher weights to recent predictions could potentially result
in a faster detection of concept drifts. In this section, we
introduce the McDiarmid Drift Detection Methods (MDDMs)
which utilizes a weighting scheme to ponderate the elements
of its sliding window for faster detection of concept drifts. We
also discuss variants of MDDM as well as the sensitivity of
their parameters.

A. McDiarmid Drift Detection Methods (MDDMs)

The McDiarmid Drift Detection Method (MDDM) applies
McDiarmid’s inequality [1] to detect concept drifts in evolving
data streams. The MDDM algorithm slides a window of size n
over the prediction results. It inserts a 1 into the window if the
prediction result is correct; and 0 otherwise. Each element in
the window is associated with a weight, as illustrated in Fig.
3, where wi < wi+1. While inputs are processed, the weighted
average of the elements of the sliding window is calculated,
i.e. µt
w, as well as the maximum weighted mean observed so
far, i.e. µm

w , as indicated in Eq. (3).

if µm

w < µt

w ⇒ µm

w = µt
w

(3)

Recall that MDDM relies on the assumption that by weight-
ing the prediction results associated with a sliding window,
and by putting more emphasis on the most recent elements,
concept drift could be detected faster and more efﬁciently.

Given the rule wi < wi+1, the elements located at the head
of the window have higher weights than those located at
the tail. Different weighting schemes have been considered
including the arithmetic and the geometric schemes. The
arithmetic scheme is given by wi = 1 + (i − 1) ∗ d, where
d ≥ 0 is the difference between two consecutive weights.
The geometric scheme is given by wi = r(i−1), where
r ≥ 1 is the ratio of two consecutive weights. In addition,
we employ the Euler scheme which is deﬁned by r = eλ
where λ ≥ 0. We have implemented three weighted drift
detection methods based on these three schemes: MDDM-A
(A for arithmetic), MDDM-G (G for geometric), and MDDM-
E (E for Euler)1. All these methods are described below. As
the prediction results are processed one-by-one, the algorithm
calculates the weighted average of the elements inside the
sliding window, and simultaneously updates two variables µt
w
(i.e. the current weighted average) and µm
w (i.e. the maximum
weighted average observed so far). A signiﬁcant difference
between µm
w implies a concept drift.

w and µt

Fig. 3: McDiarmid Drift Detection Method (General Scheme)

On the basis of the PAC learning model [25], the accuracy
should increase or stay constant as the number of instances
increases; otherwise, the possibility of facing drifts increases
[13], [26]. Thus, the value of µm
w should increase or remain
constant as more instances are processed. In other words, the
possibility of facing a concept drift increases if µm
w does not
change and µt
w decreases over time. Finally, as shown by Eq.
(4), a signiﬁcant difference in between µm
w indicates
the occurrence of a drift:

w and µt

∆µ = µm

w − µt

w ≥ εd ⇒ Drift := True

(4)

The McDiarmid inequality [1] is employed to determine if

the difference is deemed signiﬁcant.

Theorem I: McDiarmid’s Inequality – Let X1, X2, ..., Xn
be n independent random variables all taking values in the set
χ. Further, let f : χn (cid:55)→ R be a function of X1, ..., Xn that
satisﬁes ∀i, ∀x1, ..., xn, x(cid:48)

i ∈ χ,

|f (x1, ..., xi, ..., xn) − f (x1, ..., x(cid:48)

i, ..., xn) | ≤ ci.

This implies that replacing the ith coordinate xi by some
arbitrary value changes the function f by at most ci. Then,

1The source codes are available at https://www.github.com/alipsgh/ (One

may use them with the MOA framework [24]).

(5)

(6)

(8)

for all εM > 0, we have:

Pr{E[f ] − f ≥ εM } ≤ exp

−

(cid:18)

(cid:19)

2ε2
M
i=1 c2
i

(cid:80)n

Consequently, for a given conﬁdence level δM , the value of

εM is obtained by:

εM =

(cid:115) (cid:80)n
i=1 c2
i
2

ln

1
δM

Corollary I: MDDM test – In a streaming context, assume
µt
w is the weighted mean of a sequence of n random entries,
at time t, and µm
w is the maximum weighted mean observed
so far. Recall that each entry pi is in {0, 1} and has a weight
of wi. Let ∆µw = µm
w ≥ 0 be the difference between
these two weighted means. Given the conﬁdence level δw, the
McDiarmid inequality detects a drift if ∆µw ≥ εw, where
(cid:115) (cid:80)n
i=1 v2
i
2

w − µt

εw =

(7)

ln

1
δw

and where vi is given by

vi =

wi
i=1 wi

(cid:80)n

All three of our MDDM approaches apply Corollary I in
order to detect concept drift. In addition,
the McDiarmid
inequality allows for comparing the expectation of a function
of the random variables, such as the maximum, with the
function “per se”. This stands in contrast with, for instance
the Hoeffding inequality [21], in which the comparison is
restricted to the expectation of the random variables with their
empirical mean.

The pseudocode for the MDDM algorithm appears in Al-
gorithm 1. Firstly,
the INITIALIZE function initializes the
parameters, including the window size n, conﬁdence level δw,
εw, the sliding window win, and µm
w . As the data stream
examples are processed, the prediction results are pushed into
the window (lines 8-14). The algorithm updates the variables
w and µm
µt
w over time (lines 15-17). Finally, a drift is detected
if (µm
w) ≥ εw (lines 18-21). Recall
that we have
wi = 1+(i−1)∗d for MDDM-A, wi = r(i−1) for MDDM-G,
and wi = eλ(i−1) for MDDM-E.

w − µt

B. Discussion On Variants of MDDM

Recall that the MDDM-A approach employs an arithmetic
scheme wi = 1+(i−1)∗d, where wi+1 −wi = d meaning that
the weights increase linearly. On the the other hand, MDDM-
G applies the geometric scheme wi = r(i−1), indicating that
the weights increase exponentially with wi+1/wi = r (Note
that r = eλ for MDDM-E). The linear or exponential nature
of the weighting scheme affects the detection delay and the
false positive rate. That is, the exponential weighting scheme
often results in a faster concept drift detection, but at the
expense of a higher false positive rate if compared to the
linear weighting scheme. These statements are supported by
experimental results in Section VII.

Algorithm 1 McDiarmid Drift Detection Method

1: function INITIALIZE(windowSize, delta)
(n, δw) ← (windowSize, delta)
2:
εw = CALCULATEEPSILON()
3:
RESET()
4:
5: function RESET()
win = []
6:
µm
w = 0
7:
8: function DETECT(pr)

(cid:46) Creating an empty sliding window.

(cid:46) The pr is 1 for correct predictions, 0

(cid:46) Dropping an element from the tail.
(cid:46) Pushing an element into the head.

w = GETWEIGHTEDMEAN()

otherwise.

9:
10:

if win.size() = n then
win.tail.drop()

else

return False

win.push(pr)
if win.size() < n then

µt
w < µt
if µm
w then
w = µt
µm
w
∆µw = µm
w − µt
w
if ∆µw ≥ εw then

11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24: function CALCULATEEPSILON()
i=1 v2
25:
(cid:113) S

RESET()
return True

return False

S = (cid:80)n
return

else

26:

i

2 ln 1
δw

27: function GETWEIGHTEDMEAN()
i=1(pi × wi)/ (cid:80)n
28:

return (cid:80)n

i=1 wi

(cid:46) Resetting parameters.
(cid:46) Signaling for an alarm.

(cid:46) vi = wi/ (cid:80)n

i=1 wi

C. Parameters Sensitivity Analysis

The parameters n and δw are inversely proportional with
respect to εw. That is, as the value of n increases, the value of
εw decreases. This implies that, as more observations become
available, a more optimistic error bound should be applied.
On the other hand, as the value of δw decreases, the values of
εw increases (i.e. the bound becomes more conservative). The
parameter d in MDDM-A controls the scale of the weights
assigned to the sliding window elements. The value of εw
increases, as the value of d increases. Larger values of d lead
to faster drift detection, since higher weights are assigned to
the element located at the head of the window; however, the
false positive rate may increase. MDDM-G and MDDM-E
behave similarly; the scale of their weight is determined by
their parameters r and λ, respectively. That is, a higher r or
λ leads to a shorter detection delay, but at the expense of a
higher false positive rate. In order to set the default values
of these parameters, we conducted a number of experiments
against various synthetic data streams. We gradually increased
the values of these parameters to ﬁnd the optimal values:
δw = 10−6, d = 0.01, r = 1.01, and λ = 0.01.

VII. EXPERIMENTAL EVALUATION

A. Benchmarking Data Streams

are all widely found in the literature [4], [9], [13], [15],
[16], [27], [28], [29]. Each data stream consists of 100, 000
instances. A class noise of 10% was added to each stream in
order to evaluate the robustness of the drift detectors against
noisy data2. The synthetic data streams are described below.

• SINE1 · with abrupt drift: It has two attributes x and y
uniformly distributed on the interval [0, 1]. The classiﬁ-
cation function is y = sin(x). Instances are classiﬁed as
positive if they are under the curve; otherwise, they are
negative. At a drift point, the classiﬁcation is reversed
[9], [13], [14], [15].

• MIXED · with abrupt drift: The dataset has two numeric
attributes x and y distributed in [0, 1] with two boolean
attributes v and w. The instances are classiﬁed as positive
two of the three following conditions are
if at
satisﬁed: v, w, y < 0.5+0.3∗sin(3πx). The classiﬁcation
is reversed when drift points occur [9], [13], [16].

least

• CIRCLES · with gradual drift: It has two attributes x
and y distributed in [0, 1]. The classiﬁcation function is
the circle equation (x − xc)2 + (y − yc)2 = r2
c where
(xc, yc) and rc are the center and the radius of the circle,
respectively. Instances inside the circle are classiﬁed as
positive. Four different circles are employed in order to
simulate concept drift [9], [13], [14].

• LED · with gradual drift: The objective of this dataset
is to predict the digit on a seven-segment display, where
each digit has a 10% chance of being displayed. The
dataset has 7 class attributes, and 17 irrelevant ones. Con-
cept drift is simulated by interchanging relevant attributes
[4], [28], [29].

Concept Drift Simulation – Following Bifet et al. [28], we
used the sigmoid function to simulate abrupt and gradual
concept drifts. The function determines the probability of
belonging to a new context during a transition between two
concepts. The transition length ζ allows to simulate abrupt
or gradual concept drifts. The value was set to 50 for abrupt
concept drifts, and to 500 for gradual concept drifts in all our
experiments. To summarize, the drifts occur at every 20, 000
instances in SINE1 and MIXED with ζ = 50 for abrupt drift,
and at every 25, 000 instances in CIRCLES and LED with
ζ = 500 for gradual drift.

2) Real-world Data Streams: We extended our experiments
to real-world data streams3; which are frequently employed in
the online learning and adaptive learning literature [4], [9],
[13], [14], [15], [27], [28], [30]. Three data streams were
selected in our comparative study.

• ELECTRICITY · It contains 45, 312 instances, with 8
input attributes, recorded every half hour for two years by
the Australian New South Wales Electricity. The classiﬁer
must predict a rise (Up) or a fall (Down) in the electricity
price. The concept drift may result from changes in
consumption habits or unexpected events [31].

1) Synthetic Data Streams: We generated four synthetic
data streams from SINE1, MIXED, CIRCLES and LED, which

2Available at: https://www.github.com/alipsgh/data streams/.
3Available at: https://moa.cms.waikato.ac.nz/datasets/2013/.

• FOREST COVERTYPE · It consists of 54 attributes with
581, 012 instances describing 7 forest cover types for 30×
30 meter cells obtained from US Forest Service (USFS)
information system, for 4 wilderness areas located in the
Roosevelt National Forest of Northern Colorado [32].
• POKER HAND · It is composed of 1, 000, 000 instances,
where each instance is an example of ﬁve cards drawn
from a standard 52 cards deck. Each card is described by
two attributes (suit and rank), for a total of ten predictive
attributes. The classiﬁer predicts the poker hand [33].

B. Experiment Settings

We used the MOA framework [24] for our experiments.
We selected Hoeffding Tree (HT) [34] and Naive Bayes
(NB) as our incremental classiﬁers; and compared MDDMs
with CUSUM, PageHinkley, DDM, EDDM, RDDM, ADWIN,
SeqDrift2, HDDMs, and FHDDM. The default parameters
were employed for both the classiﬁers and the drift detection
methods. The algorithms were evaluated prequentially which
means that an instance is ﬁrst tested and then used for training
[35].

Pesaranghader et al. [9] introduced the acceptable delay
length notion for measuring detection delay and for determin-
ing true positive (TP), false positive (FP), and false negative
(FN) rates. The acceptable delay length ∆ is a threshold that
determines how far a given alarm should be from the true
location of a concept drift to be considered a true positive.
That is, we maintain three variables to count the numbers of
true positives, false negatives and false positives which are
initially set to zero. Therefore, the number of true positives
is incremented when the drift detector alarm occurs within
the acceptable delay range. Otherwise, the number of false
negatives is incremented as the alarm occurred too late. In
addition, the false positive value is incremented when a false
alarm occurs outside the acceptable delay range. Following
this approach, we set ∆ to 250 for the SINE1, MIXED, and
to 1000 for the CIRCLES and LED data streams. A longer ∆
should be considered for data streams with gradual drifts in
order to avoid a false negative increase.

Following [9], for both MDDMs and FHDDM, the window
size was set to 25 for the SINE1 and MIXED, and to 100 for the
CIRCLES and LED data streams. We used a wider window for
the CIRCLES and LED data streams in order to better detect
gradual concept drifts. These window sizes were chosen in
order to have shorter detection delay, as well as lower false
positive and false negative rates. Experiments were performed
on an Intel Core i5 @ 2.8 GHz with 16 GB of RAM running
Apple OS X Yosemite.

C. Experiments and Discussion

1) Synthetic Data Streams: Our experimental

results
against the synthetic data streams are presented in Tables I
and II. Recall that as we are aware of the locations of drifts
in synthetic data streams, we can evaluate the detection delay,
true positive (TP), false positive (FP) and false negative (FN).
We discuss the experimental results in the following:

Discussion I - SINE1 and MIXED (Abrupt Drift): As
represented in Table I, MDDMs and HDDMW-test detected
concept drifts with shorter delays against SINE1 and MIXED
data streams. MDDM, FHDDM, CUSUM and HDDMA-test
resulted in the lowest false positive rates. This observation may
indicate that MDDM, FHDDM, CUSUM, and HDDMA-test are
more accurate. Although RDDM had shorter detection delays
and false negative rates compared to DDM and EDDM, it
caused higher false positive rates. EDDM had the highest
false positive rates. Moreover, EDDM had the highest false
negative rates since it could not detect concept drifts within the
acceptable delay length. MDDMs showed comparable results
against
the other methods. As shown in Table I, for the
Hoeffding Tree classiﬁer, the highest classiﬁcation accuracies
was obtained with MDDMs and FHDDM, since they detected
drifts with the shortest delays and the lowest false positive
rates. Similar observations apply to the Naive Bayes classiﬁer.
It may be noticed that the false positive rate is lower for
Naive Bayes. This suggests that the Naive Bayes classiﬁer
represented the decision boundaries more accurately for noisy
SINE1 and MIXED data streams.
Discussion II - CIRCLES and LED (Gradual Drift): Table
II shows the results with the Hoeffding Tree and Naive Bayes
classiﬁers against the CIRCLES and LED data streams. The
MDDM algorithms resulted in the shortest concept drift detec-
tion delays, followed by FHDDM and HDDMW-test. Compared
to FHDDM, MDDMs detected concept drifts faster because of
its weighting schemes which favor the most recent elements.
On the other hand, EDDM produced the longest drift detection
delays. It also had the highest false negative rates. MDDMs,
FHDDM, CUSUM, RDDM, and HDDMs had the highest
true positive rates. EDDM showed the highest false positive
rates against the CIRCLES data streams. We achieved higher
accuracies with Hoeffding Tree than with Naive Bayes against
the CIRCLES data stream. In the case of the LED data streams,
ADWIN and SeqDrift2 triggered a relatively large number
of false alarms. Indeed, this could be potentially alleviated
by decreasing their conﬁdence levels, i.e. δ, to make their
tests more restrictive. SeqDrift2 caused fewer false positives
compared to ADWIN, since it applies a more conservative test
(Bernstein’s inequality). Although RDDM outperformed DDM
in all cases, in terms of detection delays and false negative
rates, it showed higher false positive rates. Finally, MDDMs,
FHDDM, and HDDMs led to the highest accuracies with both
classiﬁers.
Discussion III - MDDM Variants: Frequently, MDDM-
G and MDDM-E have shorter drift detection delays than
MDDM-A. The reason is to be found in the fact that they both
utilize an exponential weighting scheme (i.e. more weight is
put on the most recent entries which are the ones required
for faster detection) as opposed to MDDM-A which has a
linear one. The reader will notice that the false positive rates
of these two variants against the two streams with gradual
change, namely CIRCLES and LED, were higher than those
of MDDM-A. This is a consequence of the fact that MDDM-A
put more emphasis on the older entries in the window, which,

TABLE I: Hoeffding Tree and Naive Bayes with Drift Detectors against Synthetic Data Streams with Abrupt Change (ζ = 50)

Delay

Detector

FN
0.00
0.00
0.00
0.00

TP
4.00
4.00
4.00
4.00

MDDM-A 38.60 ± 3.38
MDDM-G 38.56 ± 3.36
MDDM-E 38.56 ± 3.36
CUSUM 86.89 ± 4.47

Hoeffding Tree (HT)
FP
0.21 ± 0.43
0.20 ± 0.42
0.20 ± 0.42
0.24 ± 0.47

Naive Bayes (NB)
Accuracy
FP
Delay
Accuracy
86.08 ± 0.25
0.13 ± 0.34
38.55 ± 3.35
87.07 ± 0.16
86.08 ± 0.25
0.14 ± 0.35
38.47 ± 3.35
87.07 ± 0.16
38.46 ± 3.35
86.08 ± 0.25
0.14 ± 0.35
87.07 ± 0.16
83.27 ± 6.96 3.99 ± 0.10 0.71 ± 0.86 0.01 ± 0.10 85.96 ± 0.25
86.94 ± 0.15
PageHinkley 229.24 ± 13.20 2.30 ± 1.07 1.71 ± 1.08 1.70 ± 1.07 86.06 ± 1.34 175.07 ± 24.72 3.71 ± 0.50 0.35 ± 0.54 0.29 ± 0.50 85.69 ± 0.27
DDM 163.11 ± 22.73 3.36 ± 0.77 3.30 ± 2.20 0.64 ± 0.77 86.06 ± 1.34 179.18 ± 26.83 2.87 ± 0.84 3.09 ± 1.88 1.13 ± 0.84 82.39 ± 4.32
EDDM 243.83 ± 14.25 0.22 ± 0.44 33.90 ± 11.61 3.78 ± 0.44 84.71 ± 0.55 234.28 ± 22.22 0.57 ± 0.64 33.53 ± 11.50 3.43 ± 0.64 83.44 ± 2.87
89.72 ± 16.45 3.99 ± 0.10 3.93 ± 2.91 0.01 ± 0.10 85.98 ± 0.27
RDDM 93.63 ± 7.57
4.72 ± 3.58
85.93 ± 0.23
63.92 ± 0.80 4.00 ± 0.00 3.86 ± 1.09
ADWIN 63.84 ± 1.12 4.00 ± 0.00 7.31 ± 3.18
4.83 ± 1.16
85.59 ± 0.25
4.26 ± 0.58
4.00
88.03 ± 25.73 3.97 ± 0.17 0.35 ± 0.55 0.03 ± 0.17 85.95 ± 0.25
0.71 ± 0.89
86.09 ± 0.25
0.41 ± 0.58
35.52 ± 3.10
0.46 ± 0.68
86.08 ± 0.25
0.04 ± 0.20
40.48 ± 3.37
0.10 ± 0.33

86.79 ± 0.18
86.67 ± 0.21
86.53 ± 0.15
87.01 ± 0.16
87.07 ± 0.15
87.07 ± 0.16

HDDMA-test 57.62 ± 11.81
HDDMW-test 35.70 ± 2.95
FHDDM 40.65 ± 3.15

0.00
0.00
0.00
0.00
0.00
0.00

FN
0.00
0.00
0.00

TP
4.00
4.00
4.00

4.00
4.00
4.00
4.00

SeqDrift2

0.00
0.00

0.00
0.00

4.00
4.00

200.00

200.00

4.00

0.00
0.00
0.00
0.00

4.00
4.00
4.00
4.00

1.11 ± 1.15
1.19 ± 1.21
1.19 ± 1.21
0.32 ± 0.58

MDDM-A 38.38 ± 3.66
MDDM-G 38.28 ± 3.64
MDDM-E 38.28 ± 3.64
CUSUM 90.90 ± 6.13

83.37 ± 0.09
0.69 ± 0.89
38.52 ± 3.81
83.36 ± 0.11
83.37 ± 0.09
0.70 ± 0.89
38.41 ± 3.81
83.36 ± 0.11
38.41 ± 3.81
83.37 ± 0.09
0.70 ± 0.89
83.36 ± 0.11
88.23 ± 8.97 3.99 ± 0.10 0.35 ± 0.54 0.01 ± 0.10 83.27 ± 0.08
83.27 ± 0.12
PageHinkley 229.91 ± 13.27 2.26 ± 0.98 1.74 ± 0.98 1.74 ± 0.98 82.88 ± 0.11 198.79 ± 18.72 3.56 ± 0.65 0.44 ± 0.65 0.44 ± 0.65 82.97 ± 0.10
DDM 195.73 ± 22.12 2.76 ± 1.01 2.91 ± 1.96 1.24 ± 1.01 81.78 ± 2.06 192.99 ± 23.82 2.78 ± 1.00 2.41 ± 1.44 1.22 ± 1.00 80.28 ± 4.11
EDDM 248.46 ± 7.69 0.05 ± 0.22 21.51 ± 7.70 3.95 ± 0.22 80.65 ± 0.82
247.47 ± 8.60 0.11 ± 0.31 20.22 ± 7.66 3.89 ± 0.31 80.30 ± 2.32
RDDM 106.68 ± 11.26 3.99 ± 0.10 3.49 ± 2.47 0.01 ± 0.10 83.16 ± 0.12 104.97 ± 12.06 3.99 ± 0.10 1.86 ± 1.65 0.01 ± 0.10 83.24 ± 0.09
83.28 ± 0.08
ADWIN 64.72 ± 2.79 4.00 ± 0.00 4.84 ± 2.44
64.48 ± 1.90 4.00 ± 0.00 3.47 ± 1.42
4.98 ± 1.20
82.91 ± 0.08
4.39 ± 0.79
4.00
83.71 ± 19.46 3.96 ± 0.20 0.48 ± 0.64 0.04 ± 0.20 83.28 ± 0.09
1.28 ± 1.09
83.36 ± 0.09
1.77 ± 1.39
35.75 ± 3.94
3.23 ± 1.95
83.38 ± 0.08
0.25 ± 0.48
40.56 ± 3.72
0.65 ± 0.94

HDDMA-test 69.42 ± 15.51
HDDMW-test 35.56 ± 3.50
FHDDM 40.55 ± 3.70

83.25 ± 0.12
82.91 ± 0.11
83.31 ± 0.11
83.27 ± 0.12
83.39 ± 0.10

0.00
0.00
0.00
0.00
0.00

4.00
4.00
4.00
4.00

0.00
0.00
0.00

4.00
4.00
4.00

SeqDrift2

0.00
0.00

4.00
4.00

0.00
0.00

200.00

200.00

t
p
u
r
b
A

-

1
E
N
I
S

t
p
u
r
b
A

-

D
E
X
I
M

TABLE II: Hoeffding Tree and Naive Bayes with Drift Detectors against Synthetic Data Streams with Gradual Change (ζ = 500)

Hoeffding Tree (HT)

Naive Bayes (NB)

Delay

Delay

Detector

FN
0.00
0.00
0.00

TP
3.00
3.00
3.00

MDDM-A 71.98 ± 22.19
MDDM-G 69.42 ± 22.09
MDDM-E 69.52 ± 22.12

CUSUM 220.07 ± 31.79 2.99 ± 0.10
PageHinkley 855.37 ± 56.27 1.79 ± 0.45
DDM 487.97 ± 82.24 2.78 ± 0.52

FP
0.27 ± 0.51
0.36 ± 0.61
0.37 ± 0.61
0.04 ± 0.20
1.24 ± 0.47
1.41 ± 1.24

Accuracy
161.25 ± 87.26 2.95 ± 0.22
86.58 ± 0.16
161.73 ± 89.49 2.94 ± 0.24
86.58 ± 0.17
161.74 ± 89.49 2.94 ± 0.24
86.57 ± 0.17
299.78 ± 52.29
0.01 ± 0.10 86.51 ± 0.13
1.21 ± 0.45 85.96 ± 0.15
677.32 ± 76.30 2.11 ± 0.55
0.22 ± 0.52 86.21 ± 0.47 703.59 ± 122.67 1.92 ± 0.72

0.05 ± 0.22 84.14 ± 0.12
0.06 ± 0.24 84.14 ± 0.12
0.06 ± 0.24 84.14 ± 0.12
84.08 ± 0.12
0.89 ± 0.55 83.94 ± 0.13
1.08 ± 0.72 83.18 ± 1.61
EDDM 987.61 ± 54.35 0.07 ± 0.26 24.61 ± 14.48 2.93 ± 0.26 84.89 ± 0.29 938.27 ± 106.60 0.35 ± 0.50 31.09 ± 18.14 2.65 ± 0.50 83.12 ± 0.40
0.01 ± 0.10 84.05 ± 0.11
RDDM 293.80 ± 38.52 2.98 ± 0.14
0.01 ± 0.10 84.12 ± 0.11
ADWIN 236.48 ± 130.94 2.67 ± 0.47
0.08 ± 0.27 84.13 ± 0.14
0.09 ± 0.29 84.09 ± 0.12
0.27 ± 0.44 84.11 ± 0.13
0.04 ± 0.20 84.14 ± 0.13

406.50 ± 69.40 2.99 ± 0.10
222.61 ± 57.00 2.99 ± 0.10
276.67 ± 91.10 2.92 ± 0.27
0.04 ± 0.20 86.52 ± 0.20 306.91 ± 107.78 2.91 ± 0.29
0.02 ± 0.14 86.53 ± 0.18 242.43 ± 134.19 2.73 ± 0.44
166.13 ± 83.84 2.96 ± 0.20

FP
0.63 ± 0.70
0.80 ± 0.73
0.81 ± 0.73
0.40 ± 0.62
0.93 ± 0.53
2.33 ± 1.49

0.02 ± 0.14 86.46 ± 0.16
0.33 ± 0.47 85.62 ± 0.19
86.47 ± 0.14

0.79 ± 1.25
9.74 ± 3.05
3.08 ± 0.90
0.65 ± 0.92
0.73 ± 0.87
0.17 ± 0.40

2.15 ± 1.94
5.56 ± 2.57
2.49 ± 0.97
0.49 ± 0.69
1.59 ± 1.00
0.43 ± 0.60

HDDMA-test 111.96 ± 68.22 2.96 ± 0.20
HDDMW-test 94.03 ± 57.61 2.98 ± 0.14

SeqDrift2 202.67 ± 16.11

FHDDM 79.28 ± 20.64

86.58 ± 0.13

Accuracy

3.00

3.00

3.00

0.00

0.00

0.00

FN

TP

3.00

CUSUM 300.68 ± 50.30

MDDM-A 210.31 ± 73.05 2.98 ± 0.14
MDDM-G 208.65 ± 73.05 2.98 ± 0.14
MDDM-E 208.61 ± 73.05 2.98 ± 0.14

0.02 ± 0.14 89.57 ± 0.04
0.02 ± 0.14 89.57 ± 0.04
0.02 ± 0.14 89.57 ± 0.04
89.57 ± 0.03
0.05 ± 0.26 89.36 ± 0.04
PageHinkley 560.30 ± 79.43 2.95 ± 0.26
0.04 ± 0.20 89.29 ± 1.15
DDM 444.13 ± 79.82 2.97 ± 0.17
2.30 ± 0.73 88.32 ± 0.53
EDDM 954.97 ± 62.98 0.66 ± 0.71
RDDM 321.88 ± 50.94 2.98 ± 0.14
0.02 ± 0.14 89.63 ± 0.04
ADWIN 521.47 ± 239.71 2.40 ± 0.77 474.95 ± 14.12 0.60 ± 0.77 72.25 ± 0.49 521.36 ± 238.56 2.36 ± 0.76 465.41 ± 12.53 0.64 ± 0.76 72.73 ± 0.44
SeqDrift2 426.00 ± 173.31 2.78 ± 0.44 277.0 ± 47.5 0.22 ± 0.44 76.51 ± 2.28 445.33 ± 192.27 2.75 ± 0.46 278.8 ± 47.5 0.25 ± 0.46 76.54 ± 2.25
0.02 ± 0.20 89.58 ± 0.05
0.05 ± 0.26 89.56 ± 0.03
0.03 ± 0.22 89.57 ± 0.04

210.31 ± 73.05 2.98 ± 0.14
208.65 ± 73.05 2.98 ± 0.14
208.61 ± 73.05 2.98 ± 0.14
300.61 ± 50.30
559.27 ± 78.99 2.95 ± 0.26
446.23 ± 82.12 2.96 ± 0.20
949.61 ± 68.94 0.70 ± 0.73
321.80 ± 50.94 2.98 ± 0.14

0.02 ± 0.14 89.56 ± 0.04
0.02 ± 0.14 89.56 ± 0.04
0.02 ± 0.14 89.56 ± 0.04
89.56 ± 0.03
0.05 ± 0.26 89.35 ± 0.04
0.03 ± 0.17 89.47 ± 0.56
2.34 ± 0.71 88.33 ± 0.50
0.02 ± 0.14 89.63 ± 0.04

HDDMA-test 295.03 ± 85.29 2.98 ± 0.20
HDDMW-test 259.18 ± 87.25 2.95 ± 0.26
FHDDM 220.40 ± 76.00 2.97 ± 0.22

0.03 ± 0.17
0.03 ± 0.17
0.03 ± 0.17
0.00
0.04 ± 0.24
0.32 ± 0.58
5.97 ± 1.69
0.61 ± 0.96

0.03 ± 0.17
0.03 ± 0.17
0.03 ± 0.17
0.00
0.04 ± 0.24
0.33 ± 0.58
6.33 ± 1.96
0.61 ± 0.96

295.85 ± 83.23 2.98 ± 0.20
259.17 ± 87.21 2.95 ± 0.26
220.40 ± 76.00 2.97 ± 0.22

0.02 ± 0.20 89.58 ± 0.05
0.05 ± 0.26 89.56 ± 0.04
0.03 ± 0.22 89.56 ± 0.04

0.16 ± 0.44
0.08 ± 0.31
0.03 ± 0.22

0.17 ± 0.47
0.05 ± 0.22
0.03 ± 0.22

0.00

3.00

0.00

l
a
u
d
a
r
G

-

S
E
L
C
R
I

C

l
a
u
d
a
r
G

-

3

.

1

.

3

.

0

D
E
L

in these cases are beneﬁcial to the learning process. All three
variants had comparable levels of accuracy. In general, one
may observe that an exponential-like scheme is beneﬁcial in
scenarios when faster detection is required. It follows that the
optimal shape for the weighting function is data, context and
application dependent.

2) Real-world Data Streams: There is a consensus among
researchers that the locations and/or the presence of concept
drift in the ELECTRICITY, FOREST COVERTYPE, and POKER
HAND data streams are not known [4], [9], [20], [28], [36].

This implies, in turn, that the drift detection delay as well as
the false positive and false negative rates cannot be determined
since the knowledge of the drift locations is necessary in order
to evaluate these quantities. Consequently, our evaluation is
based on the overall accuracy and the number of alarms for
concept drifts issued by each drift detector. We have also
considered blind adaptation and no detection approaches as
benchmarks for our experiments. In the blind adaptation, the
classiﬁer is retrained ab initio at every 100 instances. The
classiﬁers are trained without drift detectors in the case of no

detection. Similar to [9], a window of size 25 was selected
for FHDDM and MDDMs against real-world datasets. Our
experiments have shown that this choice is optimal in terms
of accuracy.

Table III presents the experimental results for ELECTRIC-
ITY, FOREST COVERTYPE, and POKER HAND data streams
with the Hoeffding Tree (HT) and Naive Bayes (NB) classi-
ﬁers. Firstly, the Hoeffding Tree classiﬁer showed higher clas-
siﬁcation accuracies compared to Naive Bayes when executed
without drift detector. This suggests that the Hoeffding Tree
classiﬁer could branch out and adequately reﬂect the new pat-
terns. Secondly, both classiﬁers achieved higher classiﬁcation
accuracies by using drift detection. Although this observation
indicates that using drift detection methods is beneﬁcial com-
pared to the no detection case, it does not necessarily mean
that a drift detector outperforms the others. Indeed, in a recent
study by Bifet et al. [10], it was found that blind detection has
the highest classiﬁcation accuracies, against the ELECTRICITY
and FOREST COVERTYPE data streams. Based on multiple
experiments, Bifet et al. [10] concluded that this behavior
may be explained by the temporal dependencies in between
the instances of the streams. As shown in Table III, a drift
detection method with a higher number of alarms usually led
to a higher classiﬁcation accuracy. In such a case, a classiﬁer
learns from a small portion of the data stream where almost
all instances are labeled with a common label (this refers to
temporal dependencies among examples as stated by Bifet et
al. [10]). To support this observation, as mentioned earlier, we
considered a blind adaptation as a benchmark. As shown in
the same table, the blind adaptation led to the highest or the
second highest classiﬁcation accuracies. We further extended
our experiments by running MDDMs with higher values of
δw. Recall that a higher δ implies that the drift detection
technique is less conservative. As indicated in the table, as

MDDMs became less conservative,
the number of alarms
as well as the classiﬁcation accuracies increased. Therefore,
because of temporal dependencies, both classiﬁers repeatedly
learned from instances presenting the same labels between two
consecutive alarms.

In summary, we concluded that using drift detection meth-
ods against real-world data streams is beneﬁcial. Nevertheless,
we are not in a position to make a strong statement based
solely on the accuracy because (1) the location of the drift
is unknown, and (2) because of the temporal dependencies
in between instances [10]. MDDM consistently led to high
classiﬁcation accuracies. Particularly, MDDM achieved the
highest classiﬁcation accuracies in all cases when the value
of δw increased from 10−6 to 0.001 and 0.01.

VIII. CONCLUSION

Sensor networks, smart houses, intelligent transportation,
autopilots are examples of technologies operating in evolving
environments where experiencing concept drifts over time
is commonplace. In order for the learning process to be
more accurate and efﬁcient in evolving environments, concept
drifts should be detected rapidly with false negative rate as
small as possible. In this research paper, we introduced the
McDiarmid Drift Detection Methods (MDDMs) for detecting
concept drifts with shorter delays and lower false negative
rates. We conducted various experiments to compare MDDMs
against the state-of-the-art. Our experimental results indicated
that MDDMs outperformed existing methods in terms of drift
detection delay, false negative, false positive, and classiﬁcation
accuracy rates.

In this paper, we considered incremental learning against
a single stream while evaluating the drift detection methods
accordingly. We aim to investigate streams with heterogeneous
concept drifts, i.e. streams in which different drift types and

TABLE III: Hoeffding Tree (HT) and Naive Bayes (NB) against Real-world Data Stream

Detector

MDDM-A
MDDM-G
MDDM-E
CUSUM
PageHinkley
DDM
EDDM
RDDM
ADWIN
SeqDrift2
HDDMA-test
HDDMW-test
FHDDM
Blind|W| = 100
No Detection

)
w
δ
(

1
0
0
.
0

)

w
δ
(

1
0
.
0

MDDM-A
MDDM-G
MDDM-E

MDDM-A
MDDM-G
MDDM-E

ELECTRICITY

HT

NB

FOREST COVERTYPE

HT

NB

POKER HAND

HT

NB

Alarms
105
105
105
22
6
169
191
143
65
59
210
117
90

453
—

180
182
182

256
252
252

Acc.
84.60
84.60
84.60
81.71
81.95
85.41
84.91
85.18
83.23
82.83
85.71
85.06
84.59

84.26
79.20

85.79
85.78
85.78

85.86
85.98
85.97

Alarms
126
126
126
28
10
143
203
164
88
60
211
132
109

453
—

208
209
209

265
265
266

Acc.
83.47
83.47
83.47
79.21
78.04
81.18
84.83
84.19
81.03
79.68
84.92
84.09
83.13

84.82
73.36

85.00
85.01
85.01

85.60
85.78
85.77

Alarms
1963
1966
1966
226
90
4301
2466
2671
1062
710
3695
2342
1794

5810
—

3253
3270
3270

3884
3969
3980

Acc.
85.33
85.35
85.35
83.01
81.65
87.35
86.00
86.42
83.36
82.85
87.24
85.97
85.08

87.24
80.31

87.03
87.05
87.06

87.63
87.73
87.73

Alarms
2022
2025
2025
286
117
4634
2416
2733
1151
757
3284
2383
185

5810
—

3221
3231
3234

3791
3856
3864

Acc.
85.38
85.39
85.39
81.55
80.06
88.03
86.08
86.86
83.24
82.44
87.42
86.22
85.09

87.70
60.52

87.27
87.29
87.29

87.95
88.05
88.05

Alarms
2036
2034
2034
617
403
1046
4806
2512
1358
1322
2565
2211
1876

8292
—

4320
4370
4369

6075
6095
6091

Acc.
76.89
76.89
76.89
72.85
71.30
72.74
77.30
76.70
73.84
72.51
76.40
77.11
76.72

77.96
76.07

77.82
77.83
77.83

78.18
78.21
78.21

Alarms
2145
2149
2149
659
489
433
4863
2579
1388
1395
2615
2312
1928

8292
—

4378
4425
4427

6099
6118
6116

Acc.
76.83
76.83
76.83
72.54
70.67
61.97
77.48
76.67
73.69
72.25
76.48
77.11
76.68

78.18
59.55

78.03
78.05
78.06

78.51
78.54
78.54

[18] S. Sakthithasan, R. Pears, and Y. S. Koh, “One pass concept change
detection for data streams,” in Paciﬁc-Asia Conference on Knowledge
Discovery and Data Mining. Springer, 2013, pp. 461–472.

[19] A. Pesaranghader, H. Viktor, and E. Paquet, “Reservoir of diverse
adaptive learners and stacking fast hoeffding drift detection methods
for evolving data streams,” arXiv preprint arXiv:1709.02457, 2017.
[20] D. T. J. Huang, Y. S. Koh, G. Dobbie, and A. Bifet, “Drift detection using
stream volatility,” in Joint European Conference on Machine Learning
and Knowledge Discovery in Databases. Springer, 2015, pp. 417–432.
[21] W. Hoeffding, “Probability inequalities for sums of bounded random
variables,” Journal of the American statistical association, vol. 58, no.
301, pp. 13–30, 1963.

[22] S. Bernstein, “The theory of probabilities,” 1946.
[23] R. Klinkenberg, “Learning drifting concepts: Example selection vs.
example weighting,” Intelligent Data Analysis, vol. 8, no. 3, pp. 281–
300, 2004.

[24] A. Bifet, G. Holmes, R. Kirkby, and B. Pfahringer, “Moa: Massive online
analysis,” Journal of Machine Learning Research, vol. 11, no. May, pp.
1601–1604, 2010.

[25] T. M. Mitchell, “Machine learning,” 1997.
[26] R. Sebasti˜ao, J. Gama, and T. Mendonc¸a, “Fading histograms in de-
tecting distribution and concept changes,” International Journal of Data
Science and Analytics, pp. 1–30, 2017.

[27] A. Pesaranghader, H. L. Viktor, and E. Paquet, “A framework for clas-
siﬁcation in data streams using multi-strategy learning,” in International
Conference on Discovery Science. Springer, 2016, pp. 341–355.
[28] A. Bifet, G. Holmes, B. Pfahringer, R. Kirkby, and R. Gavald`a, “New
ensemble methods for evolving data streams,” in Proceedings of the
15th ACM SIGKDD international conference on Knowledge discovery
and data mining. ACM, 2009, pp. 139–148.

[29] R. S. M. de Barros, J. I. G. Hidalgo, and D. R. de Lima Cabral,
“Wilcoxon rank sum test drift detector,” Neurocomputing, 2017.
[30] T. Escovedo, A. Koshiyama, A. A. da Cruz, and M. Vellasco, “Detecta:
abrupt concept drift detection in non-stationary environments,” Applied
Soft Computing, vol. 62, pp. 119–133, 2018.

ˇZliobait˙e, “How good is the electricity benchmark for evaluating

[31] I.

concept drift adaptation,” arXiv preprint arXiv:1301.3524, 2013.
[32] J. A. Blackard and D. J. Dean, “Comparative accuracies of artiﬁcial neu-
ral networks and discriminant analysis in predicting forest cover types
from cartographic variables,” Computers and electronics in agriculture,
vol. 24, no. 3, pp. 131–151, 1999.

[33] M. K. Olorunnimbe, H. L. Viktor, and E. Paquet, “Dynamic adaptation
of online ensembles for drifting data streams,” Journal of Intelligent
Information Systems, pp. 1–23, 2017.

[34] P. Domingos and G. Hulten, “Mining high-speed data streams,” in
Proceedings of the sixth ACM SIGKDD international conference on
Knowledge discovery and data mining. ACM, 2000, pp. 71–80.
[35] B. Krawczyk, L. L. Minku, J. Gama, J. Stefanowski, and M. Wo´zniak,
“Ensemble learning for data stream analysis: a survey,” Information
Fusion, vol. 37, pp. 132–156, 2017.

[36] V. Losing, B. Hammer, and H. Wersing, “Incremental on-line learning: A
review and comparison of state of the art algorithms,” Neurocomputing,
vol. 275, pp. 1261–1274, 2018.

[37] ——, “Knn classiﬁer with self adjusting memory for heterogeneous
concept drift,” in Data Mining (ICDM), 2016 IEEE 16th International
Conference on.

IEEE, 2016, pp. 291–300.

rates overlap. We are in addition interested to compare the per-
formance of MDDMs with proactive drift detection methods,
such as the DetectA algorithm [30], particularly regarding the
detection delay. Further, we aim to apply the notion of multiple
sliding windows stacking, as introduced by Pesaranghader et
al. [19], to the MDDM approaches. We also plan to investigate
adaptive ensemble approaches and self-adjusting algorithms
[37]. Finally, we will assess the performance of drift detection
methods against time-series data streams.

ACKNOWLEDGMENT

The authors wish to acknowledge ﬁnancial support by the
Canadian Natural Sciences and Engineering Research Council
(NSERC) as well as the Ontario Trillium Scholarship (OTS).

REFERENCES

[1] C. McDiarmid, “On the method of bounded differences,” Surveys in

combinatorics, vol. 141, no. 1, pp. 148–188, 1989.

[2] J. Gama, I. ˇZliobait˙e, A. Bifet, M. Pechenizkiy, and A. Bouchachia, “A
survey on concept drift adaptation,” ACM Computing Surveys (CSUR),
vol. 46, no. 4, p. 44, 2014.

[3] A. Bifet, G. Holmes, R. Kirkby, and B. Pfahringer, “Data stream mining

a practical approach,” 2011.

[4] I. Fr´ıas-Blanco, J. del Campo- ´Avila, G. Ramos-Jim´enez, R. Morales-
Bueno, A. Ortiz-D´ıaz, and Y. Caballero-Mota, “Online and non-
parametric drift detection methods based on hoeffdings bounds,” IEEE
Transactions on Knowledge and Data Engineering, vol. 27, no. 3, pp.
810–823, 2015.

[5] I. ˇZliobait˙e, “Learning under concept drift: an overview,” arXiv preprint

arXiv:1010.4784, 2010.

[6] G. Krempl, I.

ˇZliobaite, D. Brzezi´nski, E. H¨ullermeier, M. Last,
V. Lemaire, T. Noack, A. Shaker, S. Sievi, M. Spiliopoulou et al., “Open
challenges for data stream mining research,” ACM SIGKDD explorations
newsletter, vol. 16, no. 1, pp. 1–10, 2014.

[7] P. Duda, M. Jaworski, and L. Rutkowski, “Convergent time-varying
regression models for data streams: Tracking concept drift by the recur-
sive parzen-based generalized regression neural networks,” International
journal of neural systems, p. 1750048, 2017.

[8] R. Pears, S. Sakthithasan, and Y. S. Koh, “Detecting concept change in
dynamic data streams,” Machine Learning, vol. 97, no. 3, pp. 259–293,
2014.

[9] A. Pesaranghader and H. L. Viktor, “Fast hoeffding drift detection
method for evolving data streams,” in Joint European Conference on
Machine Learning and Knowledge Discovery in Databases. Springer,
2016, pp. 96–111.

[10] A. Bifet, “Classiﬁer concept drift detection and the illusion of progress,”
in International Conference on Artiﬁcial Intelligence and Soft Comput-
ing. Springer, 2017, pp. 715–725.

[11] I. ˇZliobait˙e, M. Budka, and F. Stahl, “Towards cost-sensitive adaptation:
when is it worth updating your predictive model?” Neurocomputing, vol.
150, pp. 240–249, 2015.

[12] E. Page, “Continuous inspection schemes,” Biometrika, vol. 41, no. 1/2,

pp. 100–115, 1954.

[13] J. Gama, P. Medas, G. Castillo, and P. Rodrigues, “Learning with drift
detection,” in Brazilian Symposium on Artiﬁcial Intelligence. Springer,
2004, pp. 286–295.

[14] M. Baena-Garcıa, J. del Campo- ´Avila, R. Fidalgo, A. Bifet, R. Gavalda,
and R. Morales-Bueno, “Early drift detection method,” in Fourth inter-
national workshop on knowledge discovery from data streams, vol. 6,
2006, pp. 77–86.

[15] G. J. Ross, N. M. Adams, D. K. Tasoulis, and D. J. Hand, “Exponentially
weighted moving average charts for detecting concept drift,” Pattern
Recognition Letters, vol. 33, no. 2, pp. 191–198, 2012.

[16] R. S. Barros, D. R. Cabral, S. G. Santos et al., “Rddm: Reactive drift

detection method,” Expert Systems with Applications, 2017.

[17] A. Bifet and R. Gavalda, “Learning from time-changing data with

adaptive windowing,” in SDM, vol. 7. SIAM, 2007, p. 2007.

