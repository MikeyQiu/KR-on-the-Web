9
1
0
2
 
p
e
S
 
6
 
 
]

G
L
.
s
c
[
 
 
1
v
4
2
8
3
0
.
9
0
9
1
:
v
i
X
r
a

Testing Deep Learning Models for Image Analysis
Using Object-Relevant Metamorphic Relations

Yongqiang Tian∗, Shiqing Ma†, Ming Wen∗, Yepang Liu‡, Shing-Chi Cheung∗ and Xiangyu Zhang§
∗ Department of Computer Science and Technology
Hong Kong University of Science and Technology, Hong Kong, China
Email: {ytianas, mwenaa, scc}@cse.ust.hk
† Department of Computer Science
Rutgers University, New Jersey, USA
Email: shiqing.ma@rutgers.edu
‡ Shenzhen Key Laboratory of Computational Intelligence
Southern University of Science and Technology, Shenzhen, China
Email: liuyp1@sustech.edu.cn
§ Department of Computer Science
Purdue University, Indiana, USA
Email: xyzhang@cs.purdue.edu

Abstract—Deep learning models are widely used for image
analysis. While they offer high performance in terms of accuracy,
people are concerned about if these models inappropriately make
inferences using irrelevant features that are not encoded from the
target object in a given image. To address the concern, we propose
a metamorphic testing approach that assesses if a given inference
is made based on irrelevant features. Speciﬁcally, we propose
two novel metamorphic relations to detect such inappropriate
inferences. We applied our approach to 10 image classiﬁca-
tion models and 10 object detection models, with three large
datasets, i.e., ImageNet, COCO, and Pascal VOC. Over 5.3% of
the top-5 correct predictions made by the image classiﬁcation
models are subject to inappropriate inferences using irrelevant
features. The corresponding rate for the object detection models
is over 8.5%. Based on the ﬁndings, we further designed a new
image generation strategy that can effectively attack existing
models. Comparing with a baseline approach, our strategy can
double the success rate of attacks.

I. INTRODUCTION

Deep learning models have been widely deployed for image
analysis applications, such as image classiﬁcation [1]–[3],
object detection [4]–[6] and human keypoint detection [7]–
[10]. While these image analysis models outperform classical
machine learning algorithms, recent studies [11]–[13] have
raised concerns on such models’ reliability.

Various testing techniques [14]–[20] have been proposed to
help assess the reliability of deep learning models for image
analysis. For instance, Pei et al. [14] proposed an optimization
strategy to generate test inputs for image classiﬁcation and
digit recognition applications. However, a major limitation
of these techniques is that
they do not consider whether
the inferences made by a model are based on the features
encoded from the target objects instead of those encoded from
these objects’ background. We refer to the former as object-
relevant features and the latter as object-irrelevant features.
For example,
those features encoded from the rectangular
region occupied by the keyboard object in the image as shown

in Fig.1a is considered as object-relevant for a keyboard detec-
tion model. Other features encoded from the rest of this image
are object-irrelevant. Such relevant and irrelevant features vary
with target objects. For example, a mouse detection model
would consider those features encoded from the “mouse” in
Fig.1a as object-relevant.

Deep learning models do not necessarily make inferences
based on object-relevant features. For instance, a recent study
showed that a model would classify an image with bright back-
ground as “wolf” regardless of the objects in the image [11].
Even though the model could output accurate results with
respect to the test inputs (i.e., test images), such inferences
are unreliable. More seriously, unreliable inferences based on
object-irrelevant features are vulnerable to malicious attacks.
For example, Gu et al. [21] showed that attackers could inject
a backdoor trigger, such as a yellow square in an image’s
background, to a deep neural network (DNN) model. A model
that makes inferences based on object-irrelevant features (e.g.,
yellow square at the background), will then classify an image
containing this trigger to a speciﬁc label, regardless of the
target object in the image. Deploying such a model in mission-
critical applications could cause catastrophic consequences.
Therefore, it is important to develop effective techniques to
assess deep learning inference results from the perspective of
object relevancy.

(a)

(b)

(c)

Fig. 1: (a): An Image from ImageNet. (b): Object (Mouse) Preserving
Mutation. (c): Object (Mouse) Removing Mutation

However, there are two major challenges that prevent us
from easily validating inference results generated by deep
learning models with respect to object relevancy. First, ob-
taining oracles for testing deep learning models is hard [17].
We resort to metamorphic testing [22] to tackle this challenge.
Metamorphic testing has been popularly leveraged to test
deep learning models for image analysis [16]–[19]. Second,
it is difﬁcult to measure whether a model makes inference
based on object-relevant features. Efforts have been made to
explain whether an inference made by a model is trustable
[11]. However, model explanation is still an outstanding chal-
lenge. Recent research focuses mostly on image classiﬁcation
models. Further, existing studies cannot quantitatively measure
to what extent an inference is made with respect to object
relevancy. Besides,
they are designed for the purpose of
interpretation instead of testing, and thus cannot be easily
adapted to validate inferences made by deep learning models
(e.g., cannot generate test inputs). To address this challenge,
we propose two novel metamorphic relations (MRs) to quan-
titatively assess a model’s inferences from the perspective of
object relevancy as follows:

• MR-1: An image after altering the regions unoccupied by
the target object should lead to a similar inference result.
• MR-2: An image after removing the target object should

lead to a dissimilar inference result.

Formulation of these two metamorphic relations is given
in Section III. Based on these two relations, we propose
a metamorphic testing technique to assess whether an in-
ference made by a deep learning model for image analysis
is based on object-relevant features. Essentially, we design
image mutation operations concerning the two relations to
generate test inputs. To test the object relevancy of an image
inference, we apply these operations on the given image to
construct mutated images and check whether the subsequent
inferences on such mutated images satisfy the metamorphic
relations. Based on the metamorphic testing results, we devise
an “object-relevancy score” as a metric to measure the extent
to which an inference made by a deep learning model is based
on object-relevant features.

We evaluated our technique using 10 common image clas-
siﬁcation and 10 object detection models on 3 popular large
datasets: ImageNet [23], VOC [24] and COCO [25]. We found
that over 5.3% of the correct classiﬁcation results made by the
image classiﬁcation models are not based on object-relevant
features. The corresponding rate for the object detection mod-
els is over 8.5%. For speciﬁc models, the rate can be as high as
29.1%. We additionally deﬁned and demonstrated a simple yet
effective strategy to attack deep learning models by leveraging
the object relevancy scores.

To summarize, this paper makes three major contributions:

1) We proposed a metamorphic testing technique to assess
the reliability of inferences generated by deep learning
models for image analysis using object-relevant meta-
morphic relations.

2) We proposed a metric “object-relevancy score” to mea-

sure the object relevancy of an inference result. We
further show that our metric could be used to effectively
facilitate an existing attacking method.

3) We conducted experiments on 20 common deep learning
models for image analysis. We found that the inference
results with low object-relevancy scores commonly exist
in these models.

II. PRELIMINARIES

A. Metamorphic Testing

Metamorphic testing [22], [26] was proposed to address the
test oracle problem. It works in two steps. First, it constructs
a new set of test inputs (called follow-up inputs) from a given
set of test inputs (called source inputs). Second, it checks
whether the program outputs based on the source inputs and
follow-up inputs satisfy some desirable properties, known as
metamorphic relations (MR).

For example, suppose p is a program implementing the sin
function. We know that the equation sin(π + x) = − sin(x)
holds for any numeric value x. Leveraging this knowledge,
we can apply metamorphic testing to p as follows. Given
a set of source inputs Is = {i1, i2, . . . , in}, we ﬁrst con-
struct a set of follow-up inputs If = {i(cid:48)
n}, where
i(cid:48)
j = π +ij. Then, we check whether the metamorphic relation
∀j ∈ [1, n] , p(ij) = −p(i(cid:48)
j) holds. A violation of it indicates
the presence of faults in p. These two steps can be applied
repetitively by treating the follow-up inputs in one cycle as
the source inputs in the next cycle.

2, . . . , i(cid:48)

1, i(cid:48)

B. Image Analysis Based on Deep Learning

Image analysis is a key application of deep learning algo-
rithms to image classiﬁcation [1]–[3], object detection [4]–[6],
human keypoint detection [7]–[10] and so on.

1) Image Classiﬁcation: An image classiﬁer is built
to
classify a given image into a category. AlexNet [27], VGG [2],
DenseNet [28], and sMobileNets [3] are popular models
for image classiﬁcation. MNIST [29], CIFAR-10 [30], and
ImageNet [23] are datasets that have been widely used to
evaluate these models. The performance of the models is
mostly evaluated based on the top-1/5 error rate, which refers
to the percentage of test images whose correct labels are not
in the top-1/5 inference(s) made by models [1]–[3], [27], [28].
2) Object Detection: An object detector is built to identify
the location of target objects in a given image and label
their categories. The object detection result usually contains
multiple regions of interest, each of which is marked by a
bounding box or a mask, and associated with a conﬁdence
value. Both bounding box and object mask show the region of
the object, in the form of rectangle or loop, respectively. Each
region of interest is annotated by a conﬁdence value, indicating
the conﬁdence in the inference. Single Shot MultiBox Detector
(SSD) [4], YOLO [6] and Faster R-CNN [5] are popular
detectors. PASCAL VOC [24] and COCO [25] are datasets
widely used by studies on object detection. The performance
of object detection models is evaluated using several metrics.
The VOC challenge uses the metrics Precision x Recall curve

and Average Precision. The COCO challenge uses mAP (mean
Average Precision) [31]. The metrics used in both challenges
require the computation of IOU (Intersection Over Union):
IOU = area(bboxgt∩bboxdt)
area(bboxgt∪bboxdt) , where the bboxgt is the object’s
bounding box in the ground truth and bboxdt is the bounding
box of the object detected by a model. Here, bbox can be
substituted by object mask mask.

III. OBJECT-RELEVANT METAMORPHIC RELATIONS
With the aim to quantitatively measure to what extend
that an inference made by deep learning models is based on
object-relevant features, we are motivated to propose two novel
metamorphic relations as mentioned in Section I. This section
presents the details of these two relations. Speciﬁcally, we
follow a common metamorphic testing framework to deﬁne
the metamorphic relations [26]. In subsequent formulation, let
M(i) denote the inference made by a deep learning model
M on an image i, and D(M(i), M(i(cid:48))) denote the distance
between two inferences M(i) and M(i(cid:48)).

MR-1: An image after altering the regions unoccupied by

the target object should lead to a similar inference result.

Relation Formulation: Let i(cid:48)

p be a follow-up image con-
structed from a source image ip for a model M by preserving
the target object but mutating the other parts. We consider
such a mutation object-preserving. An example of object-
preserving mutation for a keyboard detection model is given
by Fig.1a (source image) and Fig.1c (follow-up image). MR-
1 mandates that M(i) and M(i(cid:48)
p) should satisfy the relation:
D(M(i), M(i(cid:48)
p)) ≤ ∆p. Here, ∆p denotes a threshold for
the distance between two inference results made by a model
under metamorphic testing using object-preserving mutations.
Explanation: If an inference made by a speciﬁc model
is based on object-relevant features, after object-preserving
mutations, the new inference results should be similar since
the object-relevant features are preserved and should still be
leveraged by the model.

MR-2: An image after removing the target object should

lead to a dissimilar inference result.
Relation Formulation: Let i(cid:48)

r be a follow-up image con-
structed from a source image ir for a model M by removing
the target object but preserving its background. We consider
such a mutation object-removing. An example of object-
removing mutation for a keyboard detection model is given
by Fig.1a (source image) and Fig.1b (follow-up image). MR-
2 mandates that M(i) and M(i(cid:48)
r) should satisfy the relation:
D(M(i), M(i(cid:48)
r)) ≥ ∆r. Here, ∆r denotes a threshold for
the distance between two inference results made by a model
under metamorphic testing using object-removing mutations.
Explanation: If an inference made by a speciﬁc model
is based on object-relevant features, after object-removing
mutations, the new inference results should be affected since
the object-relevant features disappear and cannot be leveraged
by the model.

IV. OVERVIEW
In this section, we present the overview of our approach,

which consists of the following three steps:

Fig. 2: Overview of Our Approach

Object-Relevant Feature Identiﬁcation: We treat the im-
ages in a given model’s validation/test set as source images.
We apply image analysis techniques to each source image and
identify its object-relevant features. Speciﬁcally, we leverage
the ground truth in the validation/test set to divide an image
semantically into two parts, an object region and a background
region. We consider those segments (i.e., an area of pixels)
belonging to the object region as relevant features and the
others irrelevant.

Follow-up Tests Construction: Mutation functions are
designed to generate follow-up inputs from the source inputs.
Speciﬁcally, we design a set of object-preserving mutation
functions for MR-1 and and a set of object-removing mu-
tation functions for MR-2. The details of these functions are
explained in Section V.

Test Result Validation: We deﬁne distance functions D for
image analysis tasks and object detection tasks, respectively.
We validate if the distance between the result of a source
input and that of its follow-up input fulﬁlls the metamorphic
relations as described in Section III. Finally, we deﬁne the
object-relevancy score as a metric to measure to what extent
an inference is based on object-relevant features.

V. APPROACH

We present the details of our approach for two common
image analysis tasks in deep learning: image classiﬁcation and
object detection.

A. Image Classiﬁcation

1) Object-Relevant Feature Identiﬁcation: Since the images
used for image classiﬁcation usually contain one object, we
mark the pixels where the object resides as the object region
and the remaining pixels as the background region. For an
image whose ground truth indicates multiple objects, we
examine whether any one labels in the ground truth are ranked
top-5 by the model. If so, we regard the object whose label has
the highest rank as the object region. All other objects together
with the rest of the image are regarded as the background
region. If not, we regard the union of all objects as the object
region and the rest as the background region. We examine
‘top-5’ since existing evaluations mostly consider the top-5
results as discussed in Section II-B.

2) Follow-up Tests Construction: We generate follow-up
test input images by semantically mutating a source test input
image using the two aforementioned image mutations: object
preserving mutation and object removing mutation. For each
image mutation type, we design multiple mutation functions
(e.g., MoveObjToImg), as shown in Table I. Each of them
could use different ingredients (e.g., background image 1).
A mutation function together with an ingredient deﬁnes a
mutation operation (e.g., MoveObjToImg using background
image 1). In total, 38 mutation operations (25 for object
preserving and 13 for object removing) are designed.

3) Metamorphic Relation Validation: Before formulating
the object-relevancy score for an inference, let us introduce
our distance function.

Distance Function: Given a source input image i, an image
classiﬁcation model will generate a probability vector, m(i)
= (p1, p2, p3, . . .), where pk denotes the probability that this
image belongs to label lk. Suppose the image belongs to the
label l (i.e., ground truth). Its probability p is the j-th largest
element in the vector m(i), i.e. rank j. After feeding the
follow-up image i(cid:48) into the model, suppose the new result
generated by the model is m(i(cid:48)) = (p(cid:48)
1, p(cid:48)
3, . . .). Similarly,
each element p(cid:48)
k is associated with a speciﬁc label lk. We
assume that in m(i(cid:48)), the ground truth label l has probability
p(cid:48) and its rank is j(cid:48). We then compute the distance between
m(i) and m(i(cid:48)), according to the type of construction function
as follows:

2, p(cid:48)

(cid:104)

∗

(cid:20)

Object Preserving: If i(cid:48) is constructed by an object pre-
serving function, we follow the convention in Section III and
denote it as i(cid:48)
p. We measure the differences using changes of
the prediction probability and the rank of the label l as follows:
(cid:17)(cid:105)
max(0, p−p(cid:48))
D(m(i), m(i(cid:48)
p
The ﬁrst factor captures on the change in the probability
value while the second captures the change in the rank. If
this inference is made by a model based on object-relevancy
features, there should be no changes in the probability and the
rank of l, and hence D(m(i), m(i(cid:48)

p)) should be 0.

1 − max

j − 1
j(cid:48)

p)) =

0, 1

1 −

(cid:16)

(cid:21)

Object Removing: We measure how much the prediction
probability and the rank of label l are lowered. In the ideal
case, since the object has been removed, the new probability
should be reduced to 0 and l’s rank should be lowered.
D(m(i), m(i(cid:48)

(cid:20) max(0, p−p(cid:48))

(cid:104)
max

0, 1

(cid:17)(cid:105)

(cid:16)

(cid:21)

∗

r)) =

j − 1
j∗

p

Object-relevancy Score: We devise a new metric, called
Object-relevancy Score to measure to what extent an inference
m(i) by model m on input i is based on object-relevant
features, by integrating the distances between m(i) and m(i(cid:48))
for each follow-up input i(cid:48).

We deﬁne the Preserving Object-relevancy Score using the
weighted-average of all distances between the source input and
each of its follow-up input generated by an object preserving
mutation operation.

Sp(m(i)) =

w(i(cid:48)

p)D(m(i), m(i(cid:48)

p))

(cid:88)

Assume i(cid:48)

p is an image constructed by the h-th mutation
operation of n-th preserving mutation function, its weight

p) is deﬁned as w(i(cid:48)

w(i(cid:48)
Hn∗N . Hn is the total number
of mutation operations in n-th mutation function and N is the
total number of mutation functions.

p) = 1

Similarly, we deﬁne Removing Object-relevancy Score as

follows:

Sr(m(i)) =

w(i(cid:48)

r)D(m(i), m(i(cid:48)

r))

(cid:88)

Again, if i(cid:48)
r is an image constructed by the h-th mutation
operation of n-th removing mutation function, its weight w(i(cid:48)
r)
is deﬁned as w(i(cid:48)
Hn∗N . Hn is the total number of
mutation operations in n-th mutation function and N is the
total number of mutation functions.

p) =

1

Finally, we deﬁne the Object-relevancy Score as follows:

S(m(i)) =

Sp(m(i)) + Sr(m(i))
2

B. Object Detection

Object detection task has following differences with image
classiﬁcation problem and thus our the approach need to be
changed accordingly.

Model Output: In image classiﬁcation, model predicts a
label for whole image. In object detection, given a image,
model generates a result that contains multiple records. Each
record is a tuple representing a object detected, which contains
the detected object’s bounding box (or/and mask), label and
the corresponding conﬁdence probability.

Therefore, in our approach, when comparing the output
between source input and follow-up input, the smallest element
for comparison is each record, instead of each result. We will
measure to what extend a record is based on object-relevant
features, instead of a result.

Further, we need to effectively map the records from the new
results to original results, in order to select the corresponding
record to compare with the record to be measured. Later, we
would introduce how we solve this mapping problem by a new
concept Associated Object.

Dataset: Compared with image classiﬁcation, the dataset for
object detection has more objects per images. For example, in
the COCO test set, each image contains 7.3 objects on average,
shown in Table II. In particular, it is common that there exists
multiple objects with the same label in a single image.

Such difference brings a new challenge in feature identiﬁ-
cation. If we treat all objects as the object region and mutate
them together, noises might be introduced when comparing
the output of source input and follow-up input. For example,
assume we want to measure a record ‘dog’ in image to what
extend it is based on object-relevant features and there are
multiple dogs in this image. If we simply mutate all ‘dog’s
together in this images, this record could be affected. It is
hard for us to understand which dogs’ features cause such
affection. For example, it could be the dog having overlap
with this record, or it could be another dog which is in the
corner of image and far from the region labeled by this record.
We leverage Associated Object to solve this challenge, and its
detail is followed.

TABLE I: Image Mutation Functions & Operations

Mutation Function
Type

Mutation Function
Name

Description

The Number of
Mutation Operations

Object
Preserving

Object
Removing

MvObjToImg

First, directly move the object to a new background image.
Second, blur the object boundary by median ﬁlter.

BldObjToImg

Use OpenCV::seamlessClone to blend the object with a new background image.

PsvObj

RmvObjByRGB

RmvObjByTool

RmvObjByMM

First, change the value of pixels in the background region to gray.
Second, blur the object boundary by median ﬁlter(cid:63).

Remove the object by inpainting pixels of the object using a speciﬁc color.
Then, blur the object boundary by median ﬁlter.

Remove the object by inpainting the pixels of the object by the existing tools.
We use two tools from OpenCV: INPAINT NS and INPAINT TELEA.

Remove the object by inpainting the object with the mean/median value of
all pixels in the margin between mask and the bounding box.
This operation is only applicable if both mask and the bounding box exist.

12‡

12‡

1

9(cid:92)

2¶

2§

(cid:63):https://en.wikipedia.org/wiki/Median ﬁlter; § : mean and median; ¶ : 2 tools from OpenCV; (cid:92) : 9 common RGB colors.
‡ : top 12 different images by search ”background” and online;

Associated Object Given a detection record rcd, we ﬁrst
locate the object in the ground truth that is most matched to
this record, and denote it as the Associated Object.

We describe the method to ﬁnd the Associated Object for a
given detection record rcd as follows. Suppose that the input
image contains n objects in the ground truth. For k-th object
object, we mark it as objk, with label lk, bounding box bboxk.
Suppose the detected object in rcd is objrcd, the label is lrcd,
the bounding box is bboxrcd.

Then we compute the IOU score between the object objdt
with each object objk if they have same label, i.e.,lk = lrcd:

Object Preserving: If the mutation function is preserving,
We denote the record after mutation as rcd(cid:48)
p. The IOU with
objaso is denoted as IOU (cid:48)
aso. We measure the degree of
records, including the detection IOUs and labels, that remain
the same after mutation.

D(rcd, rcd(cid:48)

p) =

(cid:40)

1 − max(0,IOU aso−IOU ∗
0,

IOUaso

aso)

,

if lrcd = l∗
otherwise

rcd(cid:48)

Object Removing: We measure the degree of results, includ-

ing the detection IOUs and labels, that alter after mutation.

IOU k =

area(bboxk ∩ bboxrcd)
area(bboxk ∪ bboxrcd)

D(rcd, rcd(cid:48)

r) =

max(0, IOU aso − IOU

(cid:48)

aso)

IOU aso

We then select the object that has the highest IOU with objrcd
as the Associated Object, which is denoted as objaso, and the
corresponding IOU is denoted as IOU aso.

In feature identiﬁcation, we use the region belonging to
Associated Object as the object region. After feeding the
mutation into model, we denote the record which has the
highest IOU with Associated Object as rcd(cid:48) and we select
rcd(cid:48) to compare with the original record rcd.

1) Object-Relevant Feature Identiﬁcation: After locating
the Associated Object, we treat the pixels where it locates as
the object region and the other area as the background region.
2) Follow-up Tests Construction: We apply the same mu-

tation function as stated in Table I.

3) Metamorphic Relation Validation: First, we deﬁne the
distance function to compare the record rcd in output of a
source input with record rcd(cid:48) in output of follow-up input.
Second, we deﬁne the object-relevancy score of a single
detection record. Based on multiple record, we compute the
model object-relevance score.

Distance Function: For record rcd(cid:48), we denote its object
rcd. Similarly,

rcd, bounding box bbox(cid:48)

rcd with label l(cid:48)

in as obj(cid:48)
we compute the IOU (cid:48)

aso as follows:

IOU (cid:48)

aso =

area(bboxaso ∩ bbox(cid:48)
area(bboxaso ∪ bbox(cid:48)

)

)

rcdp

rcdp

Object-relevancy Score: Similar to image classiﬁcation
task, We devise a new metric, called Object-relevancy Score
to measure to what extend an inference is based on object-
relevant features. Noted that here the inference refers to one
detection record.

Firstly, we deﬁne the Preserving Object-relevancy Score via
weighted averaging all distance of rcd and rcd(cid:48)s constructed
by object preserving mutation operation.

Sp(rcd) =

w(rcd(cid:48)

p)D(rcd, rcd(cid:48)
p)

(cid:88)

w(rcd(cid:48)

p) is the same weight function as in Section V-A.
Similarly, we deﬁne Removing Object-relevancy Score as

follows:

Sr(rcd) =

(cid:88)

w(rcd(cid:48)

r)D(rcd, rcd(cid:48)
r)

Finally, we deﬁne the Object-relevancy Score as follows:

S(rcd) =

Sp(rcd) + Sr(rcd)
2

VI. EXPERIMENT DESIGN

We then compute the distance between rcd and rcd(cid:48) based on
different mutation function types as follows:

We conducted experiments with the aim to evaluate the
effectiveness and usefulness of our proposed approach. Specif-
ically, we propose the following two research questions:

1). Are correct inferences made by existing models prob-

TABLE III: Image Classiﬁcation Models and Their Accuracy

First, we investigate the performance of the state-of-the-art
deep learning models with respect to their object-relevancy
scores via answering the following research question:

Research Question 1: Do the state-of-the-art models make

inferences based on object-relevancy features?

We answer this question via investigating the following two

sub-questions:

lematic if they have low object-relevancy scores?

To answer this question, we ﬁrst selected those correct in-
ferences with high probabilities but with low object-relevancy
scores. We then examined whether such inferences are prob-
lematic via manual checking with the help of LIME [11], a
visualization tool that can explain an inference result made by
deep learning models. If the answer to this research question
is “yes”, which means that even though the inferences made
by existing models are correct with respect to their “labels”,
they might still be problematic. We are then curious towards
the distributions of such inferences with high probabilities
but low object-relevant scores. If they are frequently observed
in a certain number of image instances, we should then pay
more attention to such images when evaluating new models.
Therefore, we are motivated to propose the second sub-
question:

2) How are the distributions of those inferences with high
probabilities but low object-relevant scores among different
models and different image instances?

To answer this question, we evaluated 20 models for tasks
of image classiﬁcation and object detection under three large-
scale datasets. For each model, we calculated the proportion of
correct inferences that have high probabilities but low object-
relevancy scores.

Second, we investigate the usefulness of our proposed
approach. Speciﬁcally, we investigate whether the object-
relevancy score can be leveraged to attack existing state-of-the-
art models. This is motivated by a previous study [32], which
reveals that existing object detection models can be easily
attacked via image transplanting. In their study, moving the
object in an image to another with different background could
prevent the detector from successfully recognizing it, and thus
to attack existing models. Our proposed object-relevancy score
could guide us to perform the operation of image transplanting
when generating attacking images since it reveals whether an
inference is made majorly based on objects or backgrounds.
Therefore, we propose the following research question:

Research Question 2: Can the object-relevancy score be
used to guide the attack of existing the state-of-the-art models?
To answer this question, we designed a new strategy that
can effectively generate new images guided by the object-
relevancy score. We then fed these images to the state-of-the-
art techniques with the aim to attack them.

VII. EVALUATION I: EFFECTIVENESS

To evaluate the effectiveness of our approach, we systemati-
cally evaluated the performance of existing the state-of-the-art
deep learning models in terms of their object-relevant scores.

TABLE II: Datasets Information

Image Classiﬁcation

Object Detection

Name
Version

# images
# categories
# objects

ImageNet
2012 val

50000
1000
-

COCO
2017 val

VOC
2007 test

5000
80
36781

4952
20
14976

Model

Hashtag

Top-1
Accuracy

Top-5
Accuracy

DenseNet-121
DenseNet-161
MobileNets
ResNet-50
ResNet-101
ResNet-152
ResNeXt
SqueezeNet
VGG-16
VGG-19

f27dbf2d
b6c8a957
efbb2ca3
117a384e
1b2b825f
cddbc86f
8654ca5d
264ba497
e660d456
ad2f660d

0.750
0.777
0.733
0.792
0.805
0.806
0.807
0.561
0.732
0.741

0.923
0.938
0.913
0.946
0.951
0.953
0.952
0.791
0.913
0.914

A. Experimental Setup

[1]

In this experiment, we evaluated 20 models for

im-
age classiﬁcation and object detection on three differ-
ent datasets quantitatively with respect
to their object-
relevancy. Speciﬁcally, we selected 10 models for image
classiﬁcation, which are ResNet
(including ResNet-
50/101/152), MobileNets [3], VGG [2] (including VGG-16
and VGG-19), DenseNet [28] (including DenseNet-121/161),
Squeezenet [33] and ResNeXt [34]. We chose ImageNet to
evaluate the performance of these image classiﬁcation mod-
els. For object detection, the selected models are SSD [4],
YOLOv3 [6] and Faster R-CNN [5]. For SSD and YOLOv3,
variants using different feature extraction networks (e.g., Mo-
bileNets, VGG-16) were also considered in our evaluation.
We evaluated these object detection models under the COCO
and VOC datasets. The information of the selected datasets
is listed in Table II. All pre-trained models are obtainable
from GluonCV [35], [36], which is an open-source model zoo
providing implementations of common deep learning models.
All of their implementations have reproduced the results as
presented in the original publications.

B. Results and Findings

1) Are correct inferences made by existing models prob-
lematic if they have low object-relevancy scores?: To investi-
gate whether correct inferences made by existing models are

TABLE IV: Object Detection Models and Their mAP

Dataset

COCO

VOC

Model
Faster RCNN
SSD(ResNet-50)
YOLOv3(Darknet-53)

YOLOv3(MobileNets)
Faster RCNN
SSD(MobileNets)
SSD(ResNet-50)
SSD(VGG-16)
YOLOv3(Darknet-53)
YOLOv3(MobileNets)

Hashtag
5b4690fb
c4835162
09767802

66dbbae6
447328d8
37c18076
9c8b225a
daf8181b
f5ece5ce
3b47835a

mAP
0.370
0.306
0.370

0.280
0.783
0.754
0.801
0.792
0.815
0.758

problematic when they have low object-relevancy scores, we
selected images which are correctly classiﬁed by the image
classiﬁcation model ResNet-152 with high probabilities (≥
0.5) but low object-relevancy scores (≤ 0.5) for investigation.
Speciﬁcally, for each range [0.1 ∗ i, 0.1 ∗ i + 0.1) for integer
i from 0 to 4, we selected 20 images whose object-relevancy
scores are in this range. In total, 100 images were selected.

We then manually investigated to what extent these infer-
ence results are problematic. Speciﬁcally, we presented the
original images and the corresponding explanations generated
by LIME to 5 senior undergraduate students. They were then
asked to what extent do they think this inference results are
problematic in the range of [0%,100%]. The value of 0% refers
to ‘Not Problematic’ and 100% refers to ‘Very Problematic’.
The experiment was conducted for each student individually
and they were not aware of the corresponding object-relevancy
scores. For each question, they were also asked towards of
their conﬁdence on the estimation. We ﬁltered out the answers
with low conﬁdence (< 50%) to control the data quality.

inferences that predict

Finally we collected 80 results and 49 out of them were
labeled as problematic (≥ 50%) by at
least one student,
as shown in Fig.3. Besides, the lower the object-relevancy
score, the more number of students labeled the inferences as
problematic. For instance, for 53.8% of the inferences whose
object-relevancy scores are in the range of [0, 0.1), over 3
students labelled them as problematic. Such a ratio is 26.3%
for those inferences whose object-relevancy scores are in the
range of [0.2, 0.3), and is only 5.6% for the range of [0.4, 0.5).
We also selected three examples to demonstrate that correct
inferences with low object-relevancy scores are likely to be
problematic as shown in Fig.4. The left column in Fig.4
shows the original test images, and the other images show
correct
the images as “wolf” with
high probabilities (≥ 0.5) made by different models. The
object-relevancy scores are high (≥ 0.5) for the inferences
displayed in the middle column while they are low (≤ 0.5)
for the inferences displayed in the right column. As we can
see from the interpretation made by LIME (i.e., the green
areas are generated by LIME), those correct inferences in
the right column are more likely to be problematic since
they are majorly made based on object-irrelevant features
(i.e., background areas). Such problematic inferences can also
be successfully reﬂected by their low object-relevant scores.
2) How are the distributions of those inferences with high
probabilities but low object-relevant scores among different
models and different image instances?: To investigate the
distributions of those inferences that have high probabilities
but low object-relevant scores among different models and
different image instances, we investigated all the correct (Top-
5) inference results with high probabilities (≥ 0.5) but low
(≤ 0.5) object-relevancy scores for each image classiﬁcation
model. The statistical information of the selected images is
displayed in Table V. For each image classiﬁcation model,
around 6% of their correctly inference results have low object-
relevancy scores. We further collected the union of all images
with high classiﬁcation probability but low inference object-

Fig. 3: Percentage of Problematic Images

(a)

(b) 0.553

(c) 0.399

(d)

(e) 0.671

(f) 0.451

(g)

(h) 0.703

(i) 0.472

Fig. 4: Left Column: Test Images. Middle Column: Explanation
of Inferences based on Object-Relevant Features. Right Column:
Explaination of Inferences based on Object-Irrelevant Features. The
Object-Relevancy Scores are Below the Images. The Caption Denotes
the Object-Relevancy Score for the Inference.

TABLE V: The Number and Percentage of Correctly Classiﬁed Im-
ages with High Classiﬁcation Probability and Low Inference Object-
Relevancy Score in All Correctly Classiﬁed Images

DenseNet-121
DenseNet-161
MobileNets
ResNet-50
ResNet-101
ResNet-152
ResNeXt
SqueezeNet
VGG-16
VGG-19

Number
3066
2995
2726
2986
3171
3046
3064
2130
2872
2895

Percentage

Total(cid:63)
6.6% 46106
6.4% 46911
6.0% 45647
6.3% 47302
6.7% 47551
6.4% 47664
6.4% 47534
5.3% 40017
6.3% 45659
6.3% 45877

(cid:63): The Number of Correctly Classiﬁed Images by This Model

TABLE VI: The Number and Percentage of Detected Objects with
High IOU and Low Object-Relevancy Score in All Detected Objects
with High IOU

Dataset

COCO

VOC

Model
Faster RCNN
SSD(ResNet-50)
YOLOv3(Darknet-53)
YOLOv3(MobileNets)

Faster RCNN
SSD(MobileNets)
SSD(VGG-16)
SSD(ResNet-50)
YOLOv3(MobileNets)
YOLOv3(Darknet-53)

Number Percentage Total(cid:63)
27.0% 9819
21.2% 15557
15.1% 14919
29.1% 15281

2648
3296
2248
4450

260
2156
1162
1645
1865
906

28.3%
918
21.5% 10046
14.4% 8063
16.7% 9821
17.4% 10708
8.5% 10610

(cid:63): The Number of Detected (IOU >= 0.5) Objects by This Model

We extended such attacking method for image classiﬁcation
models. Speciﬁcally, given a model that is trained to classify
images of object l, there are two attacking scenarios with
respect to the two deﬁned metamorphic relations.

Scenario 1: Synthesize an image having object with label

l that force the model incorrectly classify it as other labels.

Scenario 2: Synthesize an image that does not contain any

objects of l but force the model incorrectly classify it as l.

In both scenarios, images are synthesized through trans-
planting as deﬁned in [32]. More speciﬁcally, to realize the
ﬁrst attacking scenario, we ﬁrst select an image ia from all
images with label la that is correctly classiﬁed by the target
model, and another image ib with another label lb (la (cid:54)= lb).
We then replace the object in ib with the object extracted from
ia with appropriate adjustment in scale. We ﬁnally feed the
synthesized image to the target image classiﬁer. If the top-1
prediction result is not equal to label la, we regard it as a
successful attack.

Fig.7 shows an example of such an attacking scenario. In
this example, we extracted the object in Fig.7a with label
‘eggnog’ and transplanted it to the Fig.7b. The ‘cup’ in Fig.7b
was replaced by ‘eggnog’. The synthesized image is shown
in Fig.7c and it is classiﬁed as ‘can opener’ by the model.
This is a successful attack, since Fig.7c has object ‘eggnog’
but it is classiﬁed as ‘can opener’ incorrectly instead.

The selection of image ia and ib could be either performed
randomly or guided by the object-relevancy score. Intuitively,
we should select ia with a lower preserving object-relevancy
score since lower preserving object-relevancy score indicates
changing the background of ia would signiﬁcantly affect the
classiﬁcation results. In other word, the object in ia is ignored
by the target model so even a new image has this object,

(a)

(b)

(c)

Fig. 7: (a): Image ia with Label ‘eggnog’. (b): Image ib with
Label ‘cup’. (c): Successful Attack, which is Predicted as Label ‘can
opener’ with a High Probability of 0.9987.

Fig. 5: Distribution of Correctly Classiﬁed Images with High Prob-
ability but Low Object-Relevant Score

Fig. 6: Distribution of Correctly Classiﬁed Image with High Prob-
ability but Low Object-Relevant Score by all the 10 Models w.r.t
Labels (only the frequency larger than 10 are shown).

relevancy score from 10 models. In total, we obtained 6317
images and the histogram of these images according to the
number of occurrences in the 10 models are shown in Fig. 5.
It shows that 771 images can be correctly classiﬁed with
high probabilities (≥ 0.5) but
the object-relevancy scores
evaluated by all the 10 models are low (≤ 0.5). From the
perspective of object-relevancy score, these images should be
paid more attentions to since all models evaluated by us do
not make inference based on object-relevant features. We then
investigated the distributions of these images, which belongs
to 231 distinct labels. Fig.6 shows the top 17 labels with the
highest frequencies in terms of the number of images. From
the perspective of object-relevancy score, these labels should
be paid more attention to in future model evaluations.

Similar investigation was conducted for the task of object
detection. We selected all the detection records with high IOU
(≥ 0.5) but low (≤ 0.5) object-relevancy scores. The statistical
information of the selected images is displayed in Table VI.
For most object detection models, around 10% to 20% of the
correct results have high IOUs but low object-relevancy scores.

VIII. EVALUATION II: USEFULNESS

To demonstrate the usefulness of our proposed approach, we
designed an approach via leveraging the object-relevancy score
to facilitate an existing model attacking approach [32]. Previ-
ous study [32] showed that the state-of-the-art object detection
models failed to detect the objects in object-transplanted im-
ages, which are generated by replacing an image’s sub-regions
with another sub-region that contains a object from another
image. The transplanted objects come from the original dataset
and they can be correctly detected in their original image.

the target model is less likely to recognize it and would not
classify it as la. Similarly, the ib should be selected with a
lower removing object-relevancy score since it indicates that
removing the object from this image would not signiﬁcantly
affect the classiﬁcation results. In other word, the background
in ib affects signiﬁcantly on the target model’s inference.
Therefore, such background could lead the model to label the
image as lb, regardless of the real object in the input image.
To guide the synthesis of an attacking image, we sort the
images with label la according to their preserving object-
relevancy scores, and then select ia starting from the image
with the lowest score. Similarly, we sort the images with label
lb according to their removing object-relevancy scores, and
then select ib starting from the image with the lowest score.
We compared the results using random selection and the
guided selection. We used the dataset ImageNet and the model
ResNet-152 (Model Hashtag: cddbc86f) from GluonCV model
zoo [35], [36], which achieves the top-5 accuracy on the
ImageNet dataset among the whole model zoo (ver0.3.0) in
this experimentas. We randomly generated 50 pairs of labels
la and lb. For each pair, we selected two images ia and
ib (i.e., randomly or guided by the object-relevancy score)
100 times and synthesized 100 images for attacking. We
recorded the number of successful attacks. The results are
displayed in Fig. 8. In total, our guided selection generated
3310 successful attacks (success attack rate = 66.2%) while
using random selection generated only 1800 successful attacks
(success attack rate = 36.0%). For 45 out of the 50 pairs,
our strategy is more effective in terms of the number of
successful attacks, the improvement of which ranges from
1.02x to 16.17x. In 40 out of the 45 pairs, our strategy is more
efﬁcient since it could synthesize the ﬁrst successful attacking
image more quickly.

We also designed a similar approach for the second attack.
First, we selected an image ia from all images with label
la, and then selected another image ib with label lb (la(cid:54)=lb).
After that, we substituted the object in ia with the object from
ib after appropriate adjustments. We then fed the synthesized
image to an image classiﬁer, and obtained the inference results.
If the top-1 prediction is equal to label la, we regard it as a
successful attack. Similar to the design of the ﬁrst attack, in
the guided selection, for ia, we prefer those images with lower

removing object-relevancy score with respect to the object
removing mutation. As for ib, we prefer those images with
lower preserving object-relevancy scores.

We conducted experiments following the methodology of
the ﬁrst attack. The results are displayed in Fig. 9. It shows that
our guided selection generated 1288 successful attacks while
the random selection only generated 629 successful attacks. In
particular, our guided selection outperformed the random one
for 33 out of the 50 pairs. The two selection strategies achieved
the same performance for 3 pairs. As for the rest 14 pairs,
random selection generated 113 successful attacks while our
guided selection generated 40 successful attacks. Although our
strategies do not outperform the random selection for certain
cases, our guided selection is much more effective in general.

IX. RELATED WORK

A. Metamorphic Testing in Deep Learning System

Several studies have applied metamorphic testing to validate
machine learning systems [17]–[19], including deep learning
ones [16], [18]. Dwarakanath et al. [18] leveraged two sets of
metamorphic relations to identify faults in machine learning
implementations. For example, one metamorphic relation for
deep learning system is the “permutation of input channels
(i.e. RGB channels) for the training and test data” would
not affect inference results. To validate whether a speciﬁc
implementation of DNN satisﬁes this relation, they re-order
the RGB channel of images in both training set and test set.
They examine the impact on the accuracy or precision of the
DNN model after it is trained using the permuted dataset. Their
relations treat the pixels in an image as independent units and
they do not consider objects and background in the image.

Xie et al. [17] performed metamorphic testing on two
machine learning algorithms: k-Nearest Neighbors and Na¨ıve
Bayes Classiﬁer. Their work targets at testing attribute-based
machine learning models instead of deep learning systems.
Ding et al. [19] proposed metamorphic relations for deep
learning at three different level of validation: system level,
data set level and data item level. For example, a metamorphic
relation on system level asserts that DNN should perform bet-
ter than SVM classiﬁer for image classiﬁcation. Both studies
require retraining of the machine learning systems under test,
they are inapplicable to pre-trained models.

Fig. 8: Number of Successful Attacks using Guided Selection and
Random Selection for the Attack Scenario 1

Fig. 9: Number of Successful Attacks using Guided Selection and
Random Selection for the Attack Scenario 2

Other studies [15], [16], [37] leveraged metamorphic test-
ing in validating autonomous driving systems. DeepTest [15]
designed a systematic testing approach to detecting the in-
consistent behaviors of autonomous driving systems using
metamorphic relation. Their relations focus on general image
transformation, including scale, shear, rotation and so on. Fur-
ther, DeepRoad [16] leverage GAN (Generative Adversarial
Networks) to improve the quality of transformed image. Given
a autonomous driving system, DeepRoad mutates the original
images to simulate weather conditions such as adding fog to an
image. An inconsistency is identiﬁed if a deep learning system
makes inconsistent decision on an image and its mutated one
(e.g., the difference of the steering degrees exceeds a certain
threshold). To the best of our knowledge, we are the ﬁrst to
design metamorphic relations to assess whether an inference
is based on object-relevant object or not.

B. Testing Deep Learning Systems

Besides metamorphic testing, studies have also been made
testing techniques for deep learn-
to adapt other classical
ing systems. DeepXplore [14] proposed neuron coverage to
quantify the adequacy of a testing dataset. DeepGauge [38]
proposed a collection of testing criteria. DeepFuzz [39] and
DeepHunt [40] leveraged fuzz testing to facilateing the debug-
ging processing in DNN. DeepMutation [41] applied mutation
testing to measure the quality of test data in deep learning.

Our study falls into the research direction of testing deep
learning systems. The major contribution of our study is to
test deep learning systems from a new perspective, i.e., the
object relevancy of inferences. This new perspective has not
attracted enough attention from communities.

X. THREATS TO VALIDITY

The validity of our study is subject to the following two
threats. First, we collected and tested 20 models for image
classiﬁcation and object detection. These models may not
include all models used by deep learning applications. To
mitigate the threat, all models collected are representative,
designed over popular model architectures in image analysis.
We ensured that all models in our implementation achieved
an accuracy not worse than the one reported in their original
research publications. All the models collected by us are the
representative and popular model architectures in their areas.
Second, our manual check is subject to human mistakes. To
address the threat, all results are cross validated by 5 senior
students independently. They were not aware of the object-
relevancy scores of dataset.

XI. CONCLUSION

In this work, we proposed to leverage metamorphic testing
to test whether the inference made by pre-trained deep learning
models are based on object-relevant features. We proposed two
novel metamorphic relations, from the perspective of object
relevancy. We devised a metric, i.e., object-relevancy score
to measure to what extend an inference is based on object-
relevant features. We applied our approach to 20 popular deep

learning models, with 3 large-scale datasets. We found that the
inferences based on object-irrelevant features commonly exist
in the output of these models. We further leveraged the object-
relevancy score to facilitate an existing attacking method.

REFERENCES

[1] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in 2016 IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), June 2016, pp. 770–778.

[2] K. Simonyan and A. Zisserman, “Very deep convolutional networks
for large-scale image recognition,” CoRR, vol. abs/1409.1556, 2014.
[Online]. Available: http://arxiv.org/abs/1409.1556

[3] A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang, T. Weyand,
M. Andreetto, and H. Adam, “Mobilenets: Efﬁcient convolutional neural
networks for mobile vision applications,” CoRR, vol. abs/1704.04861,
2017. [Online]. Available: http://arxiv.org/abs/1704.04861

[4] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.-Y. Fu, and
A. C. Berg, “Ssd: Single shot multibox detector,” in Computer Vision –
ECCV 2016, B. Leibe, J. Matas, N. Sebe, and M. Welling, Eds. Cham:
Springer International Publishing, 2016, pp. 21–37.

[5] S. Ren, K. He, R. Girshick, and J. Sun, “Faster r-cnn: Towards real-time
object detection with region proposal networks,” IEEE Transactions on
Pattern Analysis and Machine Intelligence, vol. 39, no. 6, pp. 1137–
1149, June 2017.

[6] J. Redmon and A. Farhadi, “Yolov3: An incremental improvement,”
CoRR, vol. abs/1804.02767, 2018. [Online]. Available: http://arxiv.org/
abs/1804.02767

[7] B. Xiao, H. Wu, and Y. Wei, “Simple baselines for human pose
estimation and tracking,” in Computer Vision - ECCV 2018 - 15th
European Conference, Munich, Germany, September 8-14, 2018,
Proceedings, Part VI,
in Computer Science,
ser. Lecture Notes
V. Ferrari, M. Hebert, C. Sminchisescu, and Y. Weiss, Eds.,
vol. 11210.
[Online]. Available:
https://doi.org/10.1007/978-3-030-01231-1 29

Springer, 2018, pp. 472–487.

[8] Y. Chen, Z. Wang, Y. Peng, Z. Zhang, G. Yu, and J. Sun,
“Cascaded pyramid network for multi-person pose
estimation,”
in 2018 IEEE Conference on Computer Vision and Pattern
Recognition, CVPR 2018, Salt Lake City, UT, USA, June 18-22,
2018.
[Online].
IEEE Computer Society, 2018, pp. 7103–7112.
Available: http://openaccess.thecvf.com/content cvpr 2018/html/Chen
Cascaded Pyramid Network CVPR 2018 paper.html

[9] H. Law, Y. Teng, O. Russakovsky, and J. Deng, “Cornernet-lite:
Efﬁcient keypoint based object detection,” CoRR, vol. abs/1904.08900,
2019. [Online]. Available: http://arxiv.org/abs/1904.08900

[10] C. Peng, T. Xiao, Z. Li, Y. Jiang, X. Zhang, K. Jia, G. Yu, and J. Sun,
“Megdet: A large mini-batch object detector,” in Proceedings of the
IEEE Conference on Computer Vision and Pattern Recognition, 2018,
pp. 6181–6189.

[11] M. T. Ribeiro, S. Singh, and C. Guestrin, “”why should I trust you?”:
Explaining the predictions of any classiﬁer,” in Proceedings of the 22nd
ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining, San Francisco, CA, USA, August 13-17, 2016, 2016, pp.
1135–1144.

[12] P. Stock and M. Ciss´e, “Convnets and imagenet beyond accuracy:
Explanations, bias detection, adversarial examples and model criticism,”
CoRR, vol. abs/1711.11443, 2017. [Online]. Available: http://arxiv.org/
abs/1711.11443

[13] S. Moosavi-Dezfooli, A. Fawzi, and P. Frossard, “Deepfool: a simple
and accurate method to fool deep neural networks,” CoRR, vol.
abs/1511.04599, 2015. [Online]. Available: http://arxiv.org/abs/1511.
04599

[14] K. Pei, Y. Cao, J. Yang, and S. Jana, “Deepxplore: Automated
whitebox testing of deep learning systems,” in Proceedings of
the
26th Symposium on Operating Systems Principles, ser. SOSP ’17.
New York, NY, USA: ACM, 2017, pp. 1–18. [Online]. Available:
http://doi.acm.org/10.1145/3132747.3132785

[15] Y. Tian, K. Pei, S. Jana, and B. Ray, “Deeptest: Automated testing
of deep-neural-network-driven autonomous cars,” in Proceedings of the
40th International Conference on Software Engineering, ser. ICSE ’18.
New York, NY, USA: ACM, 2018, pp. 303–314. [Online]. Available:
http://doi.acm.org/10.1145/3180155.3180220

[16] M. Zhang, Y. Zhang, L. Zhang, C. Liu, and S. Khurshid, “Deeproad:
Gan-based metamorphic testing and input validation framework for
autonomous driving systems,” in Proceedings of the 33rd ACM/IEEE
International Conference on Automated Software Engineering, ser. ASE
2018. New York, NY, USA: ACM, 2018, pp. 132–142. [Online].
Available: http://doi.acm.org/10.1145/3238147.3238187

[17] X. Xie, J. W. Ho, C. Murphy, G. Kaiser, B. Xu, and T. Y. Chen, “Testing
and validating machine learning classiﬁers by metamorphic testing,”
Journal of Systems and Software, vol. 84, no. 4, pp. 544 – 558, 2011, the
Ninth International Conference on Quality Software. [Online]. Available:
http://www.sciencedirect.com/science/article/pii/S0164121210003213

[18] A. Dwarakanath, M. Ahuja, S. Sikand, R. M. Rao, R. P. J. C.
Bose, N. Dubash, and S. Podder, “Identifying implementation bugs
in machine learning based image classiﬁers using metamorphic
the 27th ACM SIGSOFT International
testing,” in Proceedings of
Symposium on Software Testing and Analysis, ser. ISSTA 2018. New
York, NY, USA: ACM, 2018, pp. 118–128.
[Online]. Available:
http://doi.acm.org/10.1145/3213846.3213858

[19] J. Ding, X. Kang, and X. Hu, “Validating a deep learning framework by
metamorphic testing,” in 2017 IEEE/ACM 2nd International Workshop
on Metamorphic Testing (MET), May 2017, pp. 28–34.

[20] L. Ma, F. Zhang, J. Sun, M. Xue, B. Li, F. Juefei-Xu, C. Xie, L. Li,
Y. Liu, J. Zhao, and Y. Wang, “Deepmutation: Mutation testing of
deep learning systems,” in 29th IEEE International Symposium on
Software Reliability Engineering, ISSRE 2018, Memphis, TN, USA,
October 15-18, 2018, S. Ghosh, R. Natella, B. Cukic, R. Poston,
and N. Laranjeiro, Eds.
IEEE Computer Society, 2018, pp. 100–111.
[Online]. Available: https://doi.org/10.1109/ISSRE.2018.00021

[21] T. Gu, K. Liu, B. Dolan-Gavitt, and S. Garg, “Badnets: Evaluating
backdooring attacks on deep neural networks,” IEEE Access, vol. 7,
pp. 47 230–47 244, 2019.

[22] T. Y. Chen and S. M. Yiu, “Metamorphic testing: a new approach for
generating next test cases,” Department of Computer Science, Hong
Kong University of Science and Technology, Hong Kong, Tech. Rep.,
Jan 1998.

[23] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, “ImageNet:
A Large-Scale Hierarchical Image Database,” in CVPR09, 2009.
[24] M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisser-
man, “The pascal visual object classes (voc) challenge,” International
Journal of Computer Vision, vol. 88, no. 2, pp. 303–338, Jun. 2010.

[25] T. Lin, M. Maire, S. J. Belongie, L. D. Bourdev, R. B. Girshick,
J. Hays, P. Perona, D. Ramanan, P. Doll´ar, and C. L. Zitnick, “Microsoft
COCO: common objects in context,” CoRR, vol. abs/1405.0312, 2014.
[Online]. Available: http://arxiv.org/abs/1405.0312

[26] T. Y. Chen, F.-C. Kuo, H. Liu, P.-L. Poon, D. Towey, T. H. Tse,
and Z. Q. Zhou, “Metamorphic testing: A review of challenges and
opportunities,” ACM Comput. Surv., vol. 51, no. 1, pp. 4:1–4:27, Jan.
2018. [Online]. Available: http://doi.acm.org/10.1145/3143561

[27] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classiﬁcation
with deep convolutional neural networks,” in Advances in Neural
Information Processing Systems 25, F. Pereira, C. J. C. Burges,
L. Bottou, and K. Q. Weinberger, Eds. Curran Associates, Inc.,
2012, pp. 1097–1105. [Online]. Available: http://papers.nips.cc/paper/
4824-imagenet-classiﬁcation-with-deep-convolutional-neural-networks.
pdf

[28] G. Huang, Z. Liu, L. van der Maaten, and K. Q. Weinberger, “Densely
connected convolutional networks,” in 2017 IEEE Conference on

Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI,
USA, July 21-26, 2017.
IEEE Computer Society, 2017, pp. 2261–2269.
[Online]. Available: https://doi.org/10.1109/CVPR.2017.243

[29] Y. LeCun and C. Cortes, “MNIST handwritten digit database,” 2010.

[Online]. Available: http://yann.lecun.com/exdb/mnist/

[30] A. Krizhevsky, V. Nair, and G. Hinton, “The cifar-10 dataset.” [Online].

Available: http://www.cs.toronto.edu/∼kriz/cifar.html

[31] J. H. Hosang, R. Benenson, P. Doll´ar, and B. Schiele, “What makes
for effective detection proposals?” CoRR, vol. abs/1502.05082, 2015.
[Online]. Available: http://arxiv.org/abs/1502.05082

[32] A. Rosenfeld, R. S. Zemel, and J. K. Tsotsos, “The elephant

in
the room,” CoRR, vol. abs/1808.03305, 2018. [Online]. Available:
http://arxiv.org/abs/1808.03305

[33] F. N. Iandola, M. W. Moskewicz, K. Ashraf, S. Han, W. J. Dally,
and K. Keutzer, “Squeezenet: Alexnet-level accuracy with 50x fewer
parameters and <1mb model size,” CoRR, vol. abs/1602.07360, 2016.
[Online]. Available: http://arxiv.org/abs/1602.07360

[34] S. Xie, R. Girshick, P. Doll´ar, Z. Tu, and K. He, “Aggregated residual
transformations for deep neural networks,” in 2017 IEEE Conference
on Computer Vision and Pattern Recognition (CVPR), July 2017, pp.
5987–5995.

tricks for

[35] T. He, Z. Zhang, H. Zhang, Z. Zhang,

J. Xie, and M. Li,
“Bag of
image classiﬁcation with convolutional neural
networks,” arXiv preprint arXiv:1812.01187, 2018. [Online]. Available:
https://gluon-cv.mxnet.io/model zoo/index.html
[36] Z. Zhang, T. He, H. Zhang, Z. Zhang,

J. Xie, and M. Li,
training object detection neural networks,”
[Online]. Available: https:

freebies for

“Bag of
arXiv preprint arXiv:1902.04103, 2019.
//gluon-cv.mxnet.io/model zoo/index.html

[37] Z. Q. Zhou and L. Sun, “Metamorphic testing of driverless cars,”
Commun. ACM, vol. 62, no. 3, pp. 61–67, Feb. 2019. [Online].
Available: http://doi.acm.org/10.1145/3241979

[38] L. Ma, F. Juefei-Xu, F. Zhang, J. Sun, M. Xue, B. Li, C. Chen,
T. Su, L. Li, Y. Liu,
J. Zhao, and Y. Wang, “Deepgauge:
Multi-granularity testing criteria for deep learning systems,” in
the 33rd ACM/IEEE International Conference on
Proceedings of
Automated Software Engineering,
ser. ASE 2018. New York,
[Online]. Available: http:
NY, USA: ACM, 2018, pp. 120–131.
//doi.acm.org/10.1145/3238147.3238202

[39] A. Odena and I. Goodfellow, “Tensorfuzz: Debugging neural networks
with coverage-guided fuzzing,” arXiv preprint arXiv:1807.10875, 2018.
[40] X. Xie, L. Ma, F. Juefei-Xu, H. Chen, M. Xue, B. Li, Y. Liu,
J. Zhao, J. Yin, and S. See, “Coverage-guided fuzzing for deep neural
networks,” CoRR, vol. abs/1809.01266, 2018.
[Online]. Available:
http://arxiv.org/abs/1809.01266

[41] L. Ma, F. Zhang, J. Sun, M. Xue, B. Li, F. Juefei-Xu, C. Xie, L. Li,
Y. Liu, J. Zhao, and Y. Wang, “Deepmutation: Mutation testing of
deep learning systems,” in 29th IEEE International Symposium on
Software Reliability Engineering, ISSRE 2018, Memphis, TN, USA,
October 15-18, 2018, S. Ghosh, R. Natella, B. Cukic, R. Poston,
and N. Laranjeiro, Eds.
IEEE Computer Society, 2018, pp. 100–111.
[Online]. Available: https://doi.org/10.1109/ISSRE.2018.00021

[42] S. Ghosh, R. Natella, B. Cukic, R. Poston, and N. Laranjeiro,
Eds., 29th IEEE International Symposium on Software Reliability
ISSRE 2018, Memphis, TN, USA, October 15-18,
Engineering,
2018.
[Online]. Available: http:
//ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=8536838

IEEE Computer Society, 2018.

