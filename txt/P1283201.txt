Collaborative Filtering with User-Item Co-Autoregressive Models

Chao Du† Chongxuan Li† Yin Zheng‡

Jun Zhu∗† Bo Zhang†

†Dept. of Comp. Sci. & Tech., State Key Lab of Intell. Tech. & Sys., TNList Lab,
†Center for Bio-Inspired Computing Research, Tsinghua University, Beijing, 100084, China
‡Tencent AI Lab, Shenzhen, Guangdong, China

8
1
0
2
 
l
u
J
 
5
 
 
]

G
L
.
s
c
[
 
 
3
v
6
4
1
7
0
.
2
1
6
1
:
v
i
X
r
a

Abstract

Deep neural networks have shown promise in collaborative
ﬁltering (CF). However, existing neural approaches are either
user-based or item-based, which cannot leverage all the un-
derlying information explicitly. We propose CF-UIcA, a neu-
ral co-autoregressive model for CF tasks, which exploits the
structural correlation in the domains of both users and items.
The co-autoregression allows extra desired properties to be
incorporated for different tasks. Furthermore, we develop an
efﬁcient stochastic learning algorithm to handle large scale
datasets. We evaluate CF-UIcA on two popular benchmarks:
MovieLens 1M and Netﬂix, and achieve state-of-the-art per-
formance in both rating prediction and top-N recommenda-
tion tasks, which demonstrates the effectiveness of CF-UIcA.

1

Introduction

With the fast development of electronic commerce, so-
cial networks and music/movie content providers, recom-
mendation systems have attracted extensive research atten-
tion (Burke 2002; Schafer et al. 2007). As one of the most
popular methods, collaborative ﬁltering (CF) (Schafer et
al. 2007; Billsus and Pazzani 1998; Resnick et al. 1994;
Salakhutdinov, Mnih, and Hinton 2007) predicts users’ pref-
erences for items based on their previous behaviors (rat-
ing/clicking/purchasing etc.) in a recommendation system.
CF enjoys the beneﬁt of content-independence of the items
being recommended. Thus, it does not need expert knowl-
edge about the items when compared with content-based
methods (Van den Oord, Dieleman, and Schrauwen 2013;
Gopalan, Charlin, and Blei 2014) and could possibly pro-
vide cross-domain recommendations.

The basic assumption behind CF is that there exist corre-
lations between the observed user behaviors, and these cor-
relations can be generalized to their future behaviors. Ba-
sically, the correlations can be categorized as User-User
Correlations (UUCs)—the correlations between different
users’ behaviors on a same item, and Item-Item Correla-
tions (IICs)—the correlations between a user’s behaviors on
different items. These two types of underlying correlations
usually exist crisscrossing in the partially observed user be-
haviors, making CF a difﬁcult task.

∗corresponding author.

Copyright c(cid:13) 2018, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

Extensive work has studied how to effectively exploit the
underlying correlations to make accurate predictions. Early
approaches (Resnick et al. 1994; Sarwar et al. 2001) con-
sider UUCs or IICs by computing the similarities between
users or items. As one of the most popular classes of CF
methods, matrix factorization (MF) (Billsus and Pazzani
1998; Koren, Bell, and Volinsky 2009; Salakhutdinov and
Mnih 2007) assumes that the partially observed matrix (of
ratings) is low-rank and embeds both users and items into a
shared latent space. MF methods consider both UUCs and
IICs implicitly as a prediction is simply the inner product
of the latent vectors of the corresponding user and item.
Recently, deep learning methods have achieved promising
results in various tasks (Bahdanau, Cho, and Bengio 2014;
Mnih et al. 2015; Silver et al. 2016) due to their ability to
learn a rich set of abstract representations. Inspired by these
advances, neural networks based CF methods (Salakhutdi-
nov, Mnih, and Hinton 2007; Sedhain et al. 2015; Wu et
al. 2016; Zheng et al. 2016b), which employ highly ﬂexi-
ble transformations to model a user’s behavior proﬁle (all
behaviors) with a compact representation, are widely stud-
ied as alternatives to MF. These methods essentially consider
all UUCs explicitly as they take inputs of users’ all observed
behaviors. (See more details in Sec. 2.)

Though previous neural networks based methods are
promising, one common drawback of these methods lies in
that they cannot exploit both UUCs and IICs together, mak-
ing them further improvable. To this end, we propose a novel
neural autoregressive model for CF, named User-Item co-
Autoregressive model (CF-UIcA), which considers the au-
toregression in the domains of both users and items, so as
to model both UUCs and IICs together. The introduced co-
autoregression naturally provides a principled way to select
the UUCs and IICs to be generalized that are helpful for
prediction. This allows us to incorporate extra desired prop-
erties into the model for different tasks, which is not stud-
ied in previous work. We further develop a stochastic learn-
ing algorithm for CF-UIcA to make it applicable for large
datasets. We demonstrate our method on two real bench-
marks: MovieLens 1M and Netﬂix, achieving state-of-the-
art results in both rating prediction and top-N recommenda-
tion tasks, which is rarely accomplished in previous work.
In addition, the visualization demonstrates that CF-UIcA
learns semantic patterns without extra supervision.

(a)

(b)

(c)

(d)

Figure 1: Illustration of predictions in a toy recommendation system with 5 users and 6 items (best viewed in color). Each square
in green/yellow/gray corresponds to a positive/negative/unobserved behavior, respectively. The behavior (whose associating
user and item are colored in deep blue) being predicted is marked with a question mark. (a) Predict with a single User-User
Correlation: the behavior is predicted according to the behavior of another user (labeled as light blue); (b) Predict with a single
Item-Item Correlation; (c) Predict with multiple User-User Correlations, and (d) Predict with multiple Item-Item Correlations.

2 Related Work

Collaborative ﬁltering methods make predictions based on
user behaviors, which could reveal certain patterns for gen-
eralization. These phenomena involve two types of informa-
tion: User-User Correlations (UUCs) and Item-Item Cor-
relations (IICs). As shown in Fig. 1a, UUC depicts that a
user’s behavior is usually related to the one of some other
users on the same item, especially when they have similar
habits/tastes. Similarly, IIC depicts that a user’s behavior on
an item is related to his/her behaviors on other items, es-
pecially when these items are similar in nature, as shown in
Fig. 1b. Predictions are then possible to be made by integrat-
ing these correlations. Fig. 1c and Fig. 1d show all the UUCs
and IICs of the unknown preference marked by the question
mark. Intuitively, integrating multiple UUCs and IICs can
potentially lead to a more precise prediction.

Existing CF methods either implicitly or explicitly exploit
these correlations. Early methods model the correlations via
some similarity functions on the raw preferences, such as k-
NN collaborative ﬁltering (kNN-CF) (Resnick et al. 1994;
Sarwar et al. 2001). These methods make predictions with
the top k UUCs or IICs explicitly. Matrix factorization (MF)
methods characterize both users and items by vectors in
a low-dimensional latent space. The predictions are mod-
eled with the inner products of the latent vectors of the cor-
responding users and items. Representative works include
SVD-based methods (Billsus and Pazzani 1998; Sarwar et
al. 2000) and the probabilistic MF (PMF) (Salakhutdinov
and Mnih 2007; 2008). Recent approaches improve MF by
loosing the constrains of linearity and low-rank assumption.
Bias MF (Koren, Bell, and Volinsky 2009) introduces bias
terms associated with users and items. Lee et al. (2013) pro-
pose Local Low-Rank Matrix Approximation (LLORMA)
by assuming the observed rating matrix is a weighted sum
of low-rank matrices. NNMF (Dziugaite and Roy 2015) and
NeuMF (He et al. 2017) replace the inner product operations
in MF with neural networks. Since MF methods make pre-
dictions with the learned latent vectors of the users and the
items, the UUCs and IICs are not modeled explicitly.

With the success in many tasks (Krizhevsky, Sutskever,
and Hinton 2012; Graves, Mohamed, and Hinton 2013;

Bahdanau, Cho, and Bengio 2014; Mnih et al. 2015; Silver et
al. 2016), deep learning has been integrated into CF methods
with great success. Salakhutdinov, Mnih, and Hinton (2007)
propose RBM-CF, a CF methods based on Restricted Boltz-
mann Machines, which has shown its power in Netﬂix prize
challenge (Bennett and Lanning 2007). Sedhain et al. (2015)
propose AutoRec, a discriminative model based on auto-
encoders. A similar model known as CDAE is concurrently
proposed by Wu et al. (2016). Recently, Zheng et al. (2016b)
propose CF-NADE, a tractable model based on Neural Au-
toregressive Distribution Estimators (NADE) (Larochelle
and Murray 2011), and achieve the state-of-the-art results on
several CF benchmarks. These methods share two aspects:
1) different models are built for different users by sharing
parameters; and 2) predictions are made for a user according
to his/her behavior proﬁle. Note that as the role of users and
items are exchangeable, these methods usually have a user-
based and an item-based variants. As a result, these methods
make predictions with either the UUCs or the IICs explicitly.
Our CF-UIcA differs from existing CF methods in that
it can capture both UUCs and IICs explicitly and simulta-
neously. Similar as in CF-NADE, we adopt neural autore-
gressive architectures to model the probabilities of the be-
haviors. The crucial difference is that CF-NADE models
the rating vectors of each user, making the users indepen-
dent from each other, while CF-UIcA models the behaviors
across all users and items in order to consider UUCs and
IICs jointly. Moreover, we analyze the signiﬁcance of the
co-autoregression in a novel perspective and demonstrate its
effectiveness, which is another step beyond CF-NADE.

Hybrid recommendation (Burke 2002) is a class of meth-
ods focusing on combining different techniques at a high
level, e.g., combining CF-based methods and content-based
methods together. Different with the existing hybrid recom-
mendation methods, our model focuses on utilizing both
user-based and item-based information. Wang, De Vries,
and Reinders (2006) share similar motivation with ours.
However, their method is memory-based and uniﬁes user-
based and item-based models by similarity. While our
method is model-based and combines user-based and item-
based information by autoregressive neural networks.

Figure 2: An illustration of the conditional model. The yellow, green and gray entries are interpreted same as in Fig. 1. Suppose
Rot is the current behavior being modeled. The black striped lines mark the entries of Ro>t. The blue dashed boxes line
out the UUCs and IICs for Rot. The cuboids represent the columns of WU , WI , VU , VI , with the color corresponding to
the behaviors. The hidden representations hU and hI are computed by summing over the corresponding columns (with the
uncorresponding columns marked in lighter colors) of UUCs and IICs. The activations sU and sI are computed by multiplying
the hidden representations and the corresponding columns of VU and VI . We omit the bias terms for clarity.

3 Method
We now present CF-UIcA which models both UUCs and
IICs with co-autoregressvie architectures.

Let N and M denote the number of users and items,
respectively. We deﬁne the behavior matrix R ∈ RN ×M
from user behaviors by assigning entries of R with differ-
ent labels for different behaviors: For explicit feedback, e.g.
K-star scale ratings, we deﬁne Ri,j = k for the behavior
“user i rates item j with k stars”; For implicit feedback, e.g.
clicks, we deﬁne Ri,j = 1 for the behavior “user i clicks
item j”. And we deﬁne Ri,j = 0 for unobserved entries. Let
D = {Rid,jd}D
d=1 be all the observed behaviors, which form
the training set. The goal of CF is then to predict an unknown
behavior Ri∗,j∗ (cid:54)∈ D based on the observed behaviors D.

3.1 The Model
Autoregressive models (Frey 1998; Larochelle and Murray
2011; Lauly et al. 2017) offer a natural way to introduce in-
terdependencies, which is desired for CF tasks, as analyzed
in Sec. 2. We start with a very generic autoregressive as-
sumption to model the probability of the behavior matrix:

p(R) =

p(Rot |Ro<t ),

(1)

N ×M
(cid:89)

t=1

where o is a permutation of all (cid:104)user, item(cid:105) pairs that serves
as an ordering of all the entries in the behavior matrix R,
and Ro<t denotes the ﬁrst t − 1 entries of R indexed by o.
For example, ot = (i(cid:48), j(cid:48)) indicates that the behavior Ri(cid:48),j(cid:48)
is at the t-th position in o, i.e., Rot = Ri(cid:48),j(cid:48). Let oi
t = i(cid:48) and
oj
t = j(cid:48) denote the ﬁrst and second dimension of ot, which
index the user and the item, respectively.

Basically, there are (N ×M )! possible orderings of all the
entries of R. For now we assume that o is ﬁxed. (We will
discuss the orderings latter.) If we consider o as the order-
ing of the timestamps of the behaviors observed by the sys-
tem, then the conditional in Eqn. (1) means that the model
predicts behavior Rot at time t depends on all the observed
behaviors before t.

The Conditional Model According to Sec. 2, both UUCs
and IICs are informative for prediction. We therefore deﬁne
a conditional model that exploits both UUCs and IICs:

p(Rot |Ro<t ) = p(Rot |RU U C

ot

),

, RIIC
ot
: t(cid:48) < t, oj

(2)

where we have deﬁned RU U C
oj
t } as the behaviors on item oj
UUCs of Rot (by time t). RIIC
ot

ot

= {Rot(cid:48)

t(cid:48) =
t in Ro<t , which form all the
is deﬁned symmetrically.

Inspired by NADE (Larochelle and Murray 2011) and CF-
NADE (Zheng et al. 2016b), we model the conditional in
Eqn. (2) with neural networks due to the rich expressive abil-
ity. Speciﬁcally, CF-UIcA models the UUCs and IICs of Rot
with hidden representations respectively:

hU (RU U C

ot

) = f

hI (RIIC

ot

) = f

(cid:16) (cid:88)

(cid:16) (cid:88)

t(cid:48)<t:oj

t(cid:48) =oj

t

t(cid:48)<t:oi

t(cid:48) =oi

t

WU

:,oi

t(cid:48) ,Ro

t(cid:48)

WI

:,oj

t(cid:48) ,Ro

t(cid:48)

,

+ cU (cid:17)
+ cI (cid:17)
,

(3)

(4)

where f (·) is a nonlinear function, such as tanh(x) =
exp(x)−exp(−x)
exp(x)+exp(−x) , WU ∈ RHU ×N ×K and WI ∈ RHI ×M ×K
are 3-order tensors, cU ∈ RHU and cI ∈ RHI are the
bias terms. HU and HI are the dimensions of the hidden
representations for UUCs and IICs, respectively. The col-
umn WI
:,j,k denotes how much “behaving k on item j” con-
tributes to the hidden representations of the IICs while the
column WU
:,i,k denotes the contribution of “user i behaves
k” to the hidden representation of the UUCs.

CF-UIcA explains the hidden representations of the

UUCs and the IICs by computing the activations:

t,k(hU (RU U C
sU
oi
sI
t ,k(hI (RIIC
oj

ot

ot

)) = VU

)) = VI

:,oi

t,k

:,oj

t ,k

(cid:62)hU (RU U C

ot
(cid:62)hI (RIIC

ot

) + bU
t,k,
oi
) + bI
t ,k,
oj

(5)

(6)

where VU ∈ RHU ×N ×K and VI ∈ RHI ×M ×K are 3-order
tensors, bU ∈ RN ×K and bI ∈ RM ×K are the bias terms.
The column VI
:,j,k is the coefﬁcients that determine how the
hidden representation of the IICs affects the activation sI

j,k

for “behaving k on item j”. Higher activation sI
j,k indicates
that the considered IICs suggest higher probability that the
user will carry out a behavior k on item j. The activation sU
i,k
is interpreted similarly.

Finally, to combine the activations of UUCs and IICs of
Rot and produce a probability distribution, we deﬁne the ﬁ-
nal conditional model as a softmax function of the summa-
tion of the two activations:

p(Rot = k|Ro<t ) =

(cid:16)

exp

(cid:17)

sU
t,k + sI
oj
oi
t ,k
(cid:18)
t,k(cid:48) + sI
oj
t ,k(cid:48)

sU
oi

(cid:80)K

k(cid:48)=1 exp

(cid:19) .

(7)

Fig. 2 illustrates the conditional model.

i(cid:48),j(cid:48) and RIIC

Orderings in Different Tasks We now discuss the effect
of different orderings on the model and show what kinds of
orderings are considered for two major CF tasks detailedly.
In fact, the ordering o decides the conditional model for
each observed behavior Ri(cid:48),j(cid:48). Speciﬁcally, according to our
model (See Eqns. (2) to (4)), the contributions of UUCs and
IICs to a given behavior Ri(cid:48),j(cid:48), i.e. RU U C
i(cid:48),j(cid:48) , depend
on where the ordering o places Ri(cid:48),j(cid:48) and what o places be-
fore Ri(cid:48),j(cid:48). In general, different orderings result in different
conditional models or dependency relations (see Fig. 3 for
an illustration) and any possible conditional models can be
induced by some speciﬁc orderings. Such a property leaves
us freedom to control what kind of dependencies we would
like the model to exploit in different tasks, as shown below.
CF methods are usually evaluated on rating prediction
tasks (Zheng et al. 2016b; Sedhain et al. 2015), or more
generally, matrix completion tasks, by predicting randomly
missing ratings/values. For matrix completion tasks, taking
all UUCs and IICs into consideration leads the model to
exploit the underlying correlations to a maximum extent.
Therefore, we should consider all possible conditional mod-
els for each behavior, i.e., all orderings, in such tasks. The
objective could then be deﬁned as the expected (over all or-
derings) negative log-likelihood (NLL) of the training set:

L(θ) = E

− log p(D|θ, o)

o∈SD

= − E

o∈SD

(cid:88) D

d=1 log p(Rod |Ro<d , θ, o),

(8)

where θ denotes all the model parameters and SD is the set
of all the permutations of D1. Note that taking the expecta-
tion over all orderings is equivalent to integrating them out.
Thus the training procedure does not depend on any partic-
ular ordering and no manually chosen ordering is needed.

Recent works (Rendle et al. 2009; He et al. 2017) also
evaluate CF on top-N recommendation tasks, aiming to sug-
gest a short list of future preferences for each user, which is
closer to the goal of real-world recommendation systems. In
these tasks, not all IICs are useful. For example, people who
have just watched Harry Potter 1 (HP1) are very likely to be
interested in Harry Potter 2 (HP2), however those who have
just watched HP2 are less likely to have interest in HP1, as
he/she may have known some spoiler about HP1. To this

1Given the training set D, the ﬁrst D elements of o will be au-
tomatically restricted to D. As we only evaluate the likelihood of
the training set D, the number of equivalence orderings are D!.

(a)

(b)

(c)

Figure 3: An illustration of how the orderings decide the
conditional models. Colors are interpreted same as in Fig. 2.
(a) - (c) show 3 conditional models for the central (gray)
behavior in an example behavior matrix under 3 different
orderings. The numbers 1 - 9 indicate the indices of the cor-
responding behaviors in the orderings. The arrows indicate
the dependencies involved in the conditional models.

end, we should expect the model to capture the chronolog-
ical IICs, which only include the dependencies from later
behaviors to previous behaviors of each user, and all UUCs
in the meanwhile. Then, an appropriate objective should be
the expected NLL of the training set over all orderings that
do not break the chronological order of each user’s behav-
iors. Note that this can be implemented equivalently by re-
deﬁning RIIC
i(cid:48),j(cid:48) = {Ri(cid:48),j(cid:48)(cid:48) : T (Ri(cid:48),j(cid:48)(cid:48) ) < T (Ri(cid:48),j(cid:48))}, where
T (·) is the timestamp when the system observes the behav-
ior, and using Eqn. (8) as the objective2. Hence we still need
not to choose any ordering manually.

The above examples show that extra desired properties
can be incorporated into CF-UIcA for different tasks by con-
sidering different orderings in the objective, which indeed
beneﬁts from the co-autoregressive assumption.

3.2 Learning
The remaining challenge is to optimize the objective in
Eqn. (8). A common strategy to deal with complicate in-
tegrations or large-scale datasets is to adopt stochastic
optimization approaches, e.g. stochastic gradient descent
(SGD) (Bottou 2010; Kingma and Ba 2014), which require
an unbiased estimator of the objective or its gradient. SGD
and its variants have been widely adopted in various areas
due to its efﬁciency, including many CF methods (Sedhain
et al. 2015; Zheng et al. 2016b). However, unlike in the most
existing neural networks based methods (Wu et al. 2016;
Zheng et al. 2016b), the users are not modeled indepen-
dently in CF-UIcA, resulting the objective cannot be esti-
mated stochastically by simply sub-sampling the users. To
tackle this challenge, we derive an unbiased estimator of
Eqn. (8) below, which completes the proposed method.

By exchanging the order of the expectation and the sum-

mation in Eqn. (8) and doing some simple math, we get:

L(θ) = −

(cid:88)

(i(cid:48),j(cid:48))∈D

E
d

E
o∈SD |od=(i(cid:48),j(cid:48))

log p(Ri(cid:48),j(cid:48) |Ro<d ,θ,o).

(9)

According to the deﬁnition of the conditional model from
Eqns. (3) to (7), the log-probability of Ri(cid:48),j(cid:48) in Eqn. (9) de-
pends on at most Ri(cid:48),¬j(cid:48) = Ri(cid:48),:\{Ri(cid:48),j(cid:48)} (behaviors of user

2In this case RIIC

i(cid:48),j(cid:48) is deterministic and only RU U C

i(cid:48),j(cid:48) depends on

the ordering o.

i(cid:48),j(cid:48) = Ri(cid:48),¬j(cid:48) ∩Ro<d and the set RU U C

i(cid:48) except Ri(cid:48),j(cid:48)) and R¬i(cid:48),j(cid:48) = R:,j(cid:48)\{Ri(cid:48),j(cid:48)} (behaviors
on item j(cid:48) except Ri(cid:48),j(cid:48)). Speciﬁcally, given od = (i(cid:48), j(cid:48)),
the log-probability of Ri(cid:48),j(cid:48) depends on exactly the set
RIIC
i(cid:48),j(cid:48) = R¬i(cid:48),j(cid:48) ∩Ro<d.
As we treat the ordering o as a random variable uniformly
distributed over SD, RIIC
are also random.
i(cid:48),j(cid:48) = ∅, they are indepen-
Moreover, since RIIC
dent given their sizes m = |RIIC
i(cid:48),j(cid:48) | and n = |RU U C
i(cid:48),j(cid:48) |, i.e.,
RIIC
i(cid:48),j(cid:48) |n. By expanding the second expectation
in Eqn. (9) based on the above analysis, we have:

i(cid:48),j(cid:48) |m ⊥ RU U C

i(cid:48),j(cid:48) and RU U C
i(cid:48),j(cid:48)

i(cid:48),j(cid:48) ∩ RU U C

N
(cid:88)

M
(cid:88)

L(θ) = −

E
d

E
m,n|d

i(cid:48)=1

j(cid:48)=1
log p(Ri(cid:48),j(cid:48) |RU U C

i(cid:48),j(cid:48) , RIIC

E
RU U C
i(cid:48) ,j(cid:48) |n

E
RIIC
i(cid:48) ,j(cid:48) |m
i(cid:48),j(cid:48) , θ)I[(i(cid:48),j(cid:48))∈D],

(10)

i(cid:48),j(cid:48) |m and RU U C

where m, n, RIIC
i(cid:48),j(cid:48) |n are all random and are
decided by the random ordering o. Note the summation over
D is replaced by an equivalent representation using an indi-
cator function I[(i(cid:48),j(cid:48))∈D]. Given RU U C
i(cid:48),j(cid:48) , the log-
probability term and the indicator term can be computed eas-
ily. From now we omit these two terms for simplicity.

i(cid:48),j(cid:48) and RIIC

According to symmetry, it is easy to know that RIIC

i(cid:48),j(cid:48) |m
and RU U C
i(cid:48),j(cid:48) |n are uniformly distributed over all subsets of
size m of R¬i(cid:48),j(cid:48) ∩D and subsets of size n of Ri(cid:48),¬j(cid:48) ∩D, re-
spectively. However, these distributions have different sup-
ports since the numbers of the observed behaviors for users
(items) are different, which makes the sampling unparal-
lelizable. Note that the process of drawing o from SD can
be equivalently simulated by ﬁrst randomly drawing σ from
SN ×M , which can be viewed as an ordering of all the en-
tries of R, and then dropping the unobserved entries R\D.
The resulted ordering on D is still uniformly distributed over
SD. Then Eqn. (10) can be written equivalently as:

L(θ) = −

N
(cid:88)

M
(cid:88)

i(cid:48)=1

j(cid:48)=1

E
r

E
y,z|r

E
M⊆[M ]\{j(cid:48)}|y

E
N⊆[N ]\{i(cid:48)}|z

,

(11)

where r is the index of Ri(cid:48),j(cid:48) in σ, y and z are the number of
entries in Ri(cid:48),¬j(cid:48) ∩ Rσ<r and R¬i(cid:48),j(cid:48) ∩ Rσ<r , respectively.
M is a subset of size y of [M ]\{j(cid:48)} and N is a subset of
size z of [N ]\{i(cid:48)}, where [N ] denotes {1, · · · , N }. RU U C
i(cid:48),j(cid:48)
and RIIC

i(cid:48),j(cid:48) are therefore RN ,j(cid:48) ∩ D, Ri(cid:48),M ∩ D.

Finally, with some simple math we obtain:

L(θ) = −N M E
r

E
y,z|r

E
M⊆[M ]|y

E
N⊆[N ]|z

E
i(cid:48)∈[N ]\N

E
j(cid:48)∈[M ]\M

. (12)

In Eqn. (12), y and z can be computed after sampling r and
σ. M and N are sampled by uniformly choosing y and z
elements in [M ] and [N ] without replacement, respectively.
The last two expectations can be estimated unbiasedly by
sampling BU elements from [N ]\N and BI elements from
[M ]\M, respectively, where BU and BI can be viewed as
the minibatch sizes of users and items. Finally, we get an
unbiased estimation of the objective L(θ), which can be then
adopted in SGD algorithms.

Note that though the training objective involves expecta-
tions over multiple orderings (which help exploit the desired
UUCs and IICs during training), the prediction procedure is

Figure 4: The performance
on MovieLens 1M of CF-
UIcA and CF-NADE w.r.t.
the number of hidden units.

Figure 5: The performance
on Netﬂix of CF-UIcA
w.r.t. the number clusters of
users.

simple and deterministic. For an unknown behavior Ri∗,j∗ ,
the prediction is evaluated with ˆRi∗,j∗ = Ep(Ri∗ ,j∗ =k|D)[k]
with RU U C
i∗,j∗ = Ri∗,¬j∗ ∩ D,
where we have assumed Ri∗,j∗ = RoD+1 and Ro<D+1 = D.

i∗,j∗ = R¬i∗,j∗ ∩ D and RIIC

4 Experiments
We now present a series of experimental results of the pro-
posed CF-UIcA to demonstrate its effectiveness. We com-
pare CF-UIcA with other popular CF methods on two major
kinds of CF tasks: rating prediction and top-N recommenda-
tion. The experiments are conducted on two representative
datasets: MovieLens 1M (Harper and Konstan 2016) and
Netﬂix (Bennett and Lanning 2007). MovieLens 1M con-
sists of 1, 000, 209 ratings of 3, 952 movies (items) rated
by 6, 040 users. Netﬂix consists of 100, 480, 507 ratings
of 17, 770 movies rated by 480, 189 users. The ratings in
both datasets are 1-5 stars scale, i.e., K = 5. For all ex-
periments, we use Adam (Kingma and Ba 2014) to opti-
mize the objectives with an initial learning rate 0.001. Dur-
ing training, we anneal the learning rate by factor 0.25 un-
til no signiﬁcant improvement can be observed on valida-
tion set. Note that in Eqn. (12) the sizes of [N ]\N and
[M ]\M, i.e. N − z and M − y, vary from 1 to N − 1
and to M − 1, respectively. As a consequence, the mini-
batch sizes of users/items should be set dynamically. Nev-
ertheless, we choose ﬁxed minibatch sizes of users/items
BU /BI , which only take effect when M − y > BI or
N − z > BU . We adopt weight decay on model parameters
to prevent the model from overﬁtting. Other hyper parame-
ters and detailed experimental settings will be speciﬁed lat-
ter for each task. The codes and more detailed settings can be
found at https://github.com/thu-ml/CF-UIcA.

4.1 Rating Prediction
We use the same experimental settings with LLORMA (Lee
et al. 2013), AutoRec (Sedhain et al. 2015) and CF-
NADE (Zheng et al. 2016b). We randomly select 90%
of the ratings in each of the datasets as the training set,
leaving the remaining 10% of the ratings as the test set.
Among the ratings in the training set, 5% are hold out
for validation. We compare the predictive performance with
other state-of-the-art methods in terms of the common used
Root Mean Squared Error (RMSE) = ((cid:80)
(i,j)∈Dtest( ˆRi,j −
Ri,j)2/Dtest)1/2, where Dtest is the test set of Dtest unknown
ratings, Ri,j is the true rating and ˆRi,j is the prediction. The

Table 1: Test RMSE on MovieLens 1M and Netﬂix. All the
baseline results are taken from Zheng et al. (2016b).

Table 2: Test HR@10 and NDCG@10 of various methods
on MovieLens 1M. The results of baseline methods (except
CDAE) are kindly provided by He et al. (2017).

Method
PMF
U-RBM
U-AutoRec
LLORMA-Global
I-RBM
BiasMF
U-CF-NADE-S (2 layers)
NNMF
LLORMA-Local
I-AutoRec
I-CF-NADE-S (2 layers)
CF-UIcA (H U=H I=500)

MovieLens 1M Netﬂix

0.883
0.881
0.874
0.865
0.854
0.845
0.845
0.843
0.833
0.831
0.829

-
0.845
-
0.874
-
0.844
0.803
-
0.834
0.823
-

0.823

0.799

reported results are averaged over 10 random splits, with
standard deviations less than 0.0002.

MovieLens 1M For experiments on MovieLens 1M, we
set BU /BI to 1, 000/1, 000 and the weight decay to 0.0001.
Since CF-UIcA has a connection with CF-NADE (Zheng
et al. 2016b) as mentioned in Sec. 2, we ﬁrst present a com-
parison between CF-UIcA and CF-NADE in Fig. 4. CF-
NADE models each user with a latent representation, sim-
ilar with our hidden representation of UUCs or IICs. For
fairness, we compare the two methods with the same num-
ber of hidden units, where in our CF-UIcA the number of
hidden units is H U+H I . Note that in CF-UIcA H U is not
necessarily equal to H I , we nevertheless choose H U =H I
for simplicity. We report the item-based CF-NADE results
under best setting as described in (Zheng et al. 2016b).

From Fig. 4 we observe that for small number of hidden
units, e.g. 250, our method gives a worse result than CF-
NADE. This is attributed to that the hidden dimensions allo-
cated to the hidden representation of UUCs and IICs are too
small (H U =H I =125) to capture the underlying informa-
tion. As the number of hidden units increases, we observe
CF-UIcA outperforms CF-NADE since CF-UIcA can cap-
ture both UUCs and IICs while the item-based CF-NADE
can only capture UUCs. One thing worth mentioning is that
the total number of parameters in CF-UIcA is only around
83% of the number of parameters in CF-NADE for Movie-
Lens 1M when the number of hidden units are same, which
implies that CF-UIcA can capture more information than
CF-NADE with fewer parameters.

Table 1 (middle column) compares the performance of
CF-UIcA with state-of-the-art methods on MovieLens 1M.
The hidden dimensions of CF-UIcA are H U = H I = 500.
Our method achieves an RMSE of 0.823, outperforming all
the existing strong baselines. Note that as RMSE scores have
been highly optimized in previous work, our 0.006 RMSE
improvement w.r.t. CF-NADE is quite signiﬁcant, compared
to the 0.002 by which CF-NADE improves over AutoRec
and 0.002 by which AutoRec improves over LLORMA.

Netﬂix The Netﬂix dataset is much bigger than Movie-
Lens 1M, especially the number of users. We opt to clus-

HR@10 NDCG@10

Method
ItemPop
ItemKNN
BPR (Rendle et al. 2009)
eALS (He et al. 2016)
NeuMF
CDAE

CF-UIcA (Uniform)
CF-UIcA (Inverse)
CF-UIcA

0.454
0.623
0.690
0.704
0.730
0.726

0.692
0.616
0.736

0.254
0.359
0.419
0.433
0.447
0.448

0.406
0.353
0.492

ter all the 480, 189 users into 10K, 15K and 20K groups,
respectively, and make the users in same clusters sharing
their corresponding columns in WU and VU . To cluster
the users, we ﬁrst run matrix factorization (Juan et al. 2016)
with rank 100 on the training set. (Predicting the test set with
the learned vectors by MF gives an RMSE of 0.865.) Then
the clustering process is simply done by running a K-means
clustering algorithm on the latent vectors of users learned by
MF. For CF-UIcA, the weight decay is set to 5 × 10−6 as the
dataset is sufﬁciently large. The minibacth sizes of users and
items are set to BU = 4, 000 and BI = 1, 000. The hidden
dimensions are H U = H I = 500.

Fig. 5 shows the performance of CF-UIcA with different
number of clusters. We observe that the performance im-
proves as the number of clusters increases, which can be
attributed to that using more clusters empowers the model
to capture more variety among users. Another observation is
that the performance can be potentially improved by further
increasing the number of clusters. We do not increase the
number of clusters due to the limitation of GPU memory.

Table 1 (right column) summarizes our best result and
other state-of-the-art results. Symbol “-” indicates that the
authors didn’t report the result, probably due to the lack
of scalability3. Our method with 20, 000 clusters of users
achieves a state-of-the-art RMSE of 0.799, which, together
with the results on MovieLens 1M, proves that our CF-UIcA
has the ability to predict users’ ratings precisely.

4.2 Top-N Recommendation
In most real scenarios, the goal of recommendation sys-
tems is to suggest a top-N ranked list of items that are
supposed to be appealing for each user. Moreover, implicit
feedback (Zheng et al. 2016a) has attracted increasing in-
terests because it is usually collected automatically and is
thus much more easier to obtain. We follow the exper-
imental settings of NeuMF (He et al. 2017) to test the
recommendation quality of CF-UIcA with implicit feed-
back. We transform MovieLens 1M into implicit data by
marking all ratings as 1 indicating that the user has rated
the item. We adopt the leave-one-out (Rendle et al. 2009;

3We conﬁrmed with the authors of (Zheng et al. 2016b) that
I-CF-NADE is not scalable to Netﬂix. For AutoRec, the authors
reported that I-AutoRec is their best model.

Table 3: Average running time for each minibatch of CF-
UIcA on different datasets.

BU /BI

Dataset
ML 1M 1, 000/1, 000
4, 000/1, 000
Netﬂix

H U /H I
500/500
500/500

Time
0.77s
3.4s

Table 4: Average test time of different methods and tasks on
MovieLens 1M.

Method
CF-NADE
CF-UIcA
CF-UIcA

Task
Rating Prediction
Rating Prediction
Top-N Recommendation

Test Time
0.68s
0.80s
0.73s

Case) all orderings that reverse the chronological order of
each user’s behaviors. The results are shown in Table 2. We
can observe that the orderings signiﬁcantly affect the perfor-
mance. Compared to the result (NDCG@10 0.406) of Ignore
case where all UUCs and IICs are captured, our best result
brings a 0.09 improvment, demonstrating the effectiveness
of the orderings and the power of the co-autoregression.

4.3 Visualization
In MovieLens 1M, each movie is marked with one or
more genres. There are totally 18 different genres includ-
ing Action, Children’s, Drama, etc. We visualize the learned
weight matrices VI in Sec. 4.1. Speciﬁcally, once the model
:,j,: can be viewed as H I × K dimensional vec-
is learned, VI
tors associated with item j. We apply t-SNE (Maaten and
Hinton 2008) to embed these vectors into a 2-dimensional
plane. Fig. 6 shows the t-SNE embedding of two most exclu-
sive genres: Children’s and Documentary. We can observe
the learned vectors are distributed semantically in the gross.

4.4 Running Time and Memory
We analyze the running time and memory cost of the pro-
posed method. All the experiments are conducted on a single
Nvidia TITAN X GPU with Theano (Theano Development
Team 2016) codes. As explained in Sec. 4, the minibatch
sizes of users and items are not deterministic during training
and thus there is no standard way to train CF-UIcA epoch
by epoch. We report the average training time for each mini-
batch in Table 3. As for testing time, we compare CF-UIcA
with other state-of-the-art methods in Table 4.

The running memory cost of CF-UIcA is mainly for sav-
ing the 3-dimensional weight tensors. Speciﬁcally, the mem-
ory complexity of CF-UIcA is O((N H U + M H I )K). In
our experiments we always let H U = H I = H, resulting
the memory cost is proportional to (N + M )HK.

5 Conclusion
We propose CF-UIcA, a neural co-autoregressive model for
collaborative ﬁltering, with a scalable stochastic learning
algorithm. CF-UIcA performs autoregression in both users
and items domains, making it able to capture both correla-
tions between users and items explicitly and simultaneously.

Figure 6:
MovieLens 1M.

t-SNE embedding of the learned vectors for

He et al. 2017) evaluation: The latest rated item of each user
is held out as the test set; The second latest rated item of
each user is choosen as the validation set and the remain-
ing data are used as the training set. At test time, we adopt
the common strategy (Koren 2008; Elkahky, Song, and He
2015) that randomly samples 100 items that are not rated by
the user, and ask the algorithm to rank the test item among
the 100 sampled items. We evaluate the quality of the ranked
list for the user by computing the Hit Ratio (HR) and the
Normalized Discounted Cumulative Gain (NDCG) (He et
al. 2015). Speciﬁcally,

HR =

, NDCG =

#hits
#users

1
#users

#hits
(cid:88)

i=1

1
log2(pi +1)

,

(13)

where #hits is the number of users whose test item appears
in the recommended list and pi is the position of the test item
in the list for the i-th hit. For both metrics, the ranked list is
truncated at 10.

Since the model is always asked to make predictions of
latest behaviors based on former behaviors, we train the
model under the expectation over orderings that maintain
the chronological order of each user’s behaviors, as anyl-
ized in Sec. 3.1. An important difﬁculty of CF with implicit
feedback is that only positive signals are observed. To han-
dle the absence of negative signals, we follow the common
strategy (Pan et al. 2008; He et al. 2017) that randomly sam-
ples negative instances from unobserved entries dynamically
during the training procedure.

The minibatch sizes of users and items are set to 200. The
hidden dimensions are H U = H I = 256 and the weight
decay is 1 × 10−5. the results are averaged over 5 runs
with different random seeds, with standard deviations less
than 0.0005. Table 2 compares the results in HR@10 and
NDCG@10 with state-of-the-art methods for top-N recom-
mendation with implicit feedback on MovieLens 1M. The
baseline results are provided by He et al. (2017), except the
result of CDAE (Wu et al. 2016), which is evaluated with our
implementation. We can see that CF-UIcA achieves the best
performance under both measures. Importantly, our method
gives an NDCG@10 0.492, which outperforms the state-of-
the-art method NeuMF by a large margin 0.045 (relative
improvement 10.1%). To demonstrate the signiﬁcance of
the co-autoregression, we train another two CF-UIcA mod-
els under the expectation over: (Uniform Case) all possi-
ble orderings, which cover all UUCs and IICs; and (Inverse

Experiments show that our method achieves state-of-the-art
results, and is able to learn semantic information by visual-
ization, verifying that the autoregression provides a princi-
pled way to incorporate the correlations.

Acknowledgments
This work is supported by the National NSF of China (Nos.
61620106010, 61621136008, 61332007), the MIIT Grant
of Int. Man. Comp. Stan (No. 2016ZXFB00001) and the
NVIDIA NVAIL Program.

References
Bahdanau, D.; Cho, K.; and Bengio, Y. 2014. Neural machine
translation by jointly learning to align and translate. arXiv preprint
arXiv:1409.0473.
Bennett, J., and Lanning, S. 2007. The netﬂix prize. In Proceedings
of KDD cup and workshop, volume 2007, 35.
Billsus, D., and Pazzani, M. J. 1998. Learning collaborative infor-
mation ﬁlters. In ICML, volume 98, 46–54.
Bottou, L. 2010. Large-scale machine learning with stochastic
gradient descent. In Proceedings of COMPSTAT’2010. Springer.
177–186.
Burke, R. 2002. Hybrid recommender systems: Survey and exper-
iments. User modeling and user-adapted interaction 12(4):331–
370.
Dziugaite, G. K., and Roy, D. M. 2015. Neural network matrix
factorization. arXiv preprint arXiv:1511.06443.
Elkahky, A. M.; Song, Y.; and He, X. 2015. A multi-view deep
learning approach for cross domain user modeling in recommen-
dation systems. In WWW, 278–288.
Frey, B. J. 1998. Graphical models for machine learning and
digital communication.
Gopalan, P. K.; Charlin, L.; and Blei, D. 2014. Content-based
recommendations with poisson factorization. In NIPS.
Graves, A.; Mohamed, A.-r.; and Hinton, G. 2013. Speech recog-
nition with deep recurrent neural networks. In ICASSP.
Harper, F. M., and Konstan, J. A. 2016. The movielens datasets:
History and context. ACM Transactions on Interactive Intelligent
Systems (TiiS) 5(4):19.
He, X.; Chen, T.; Kan, M.-Y.; and Chen, X. 2015. Trirank: Review-
aware explainable recommendation by modeling aspects. In CIKM.
He, X.; Zhang, H.; Kan, M.-Y.; and Chua, T.-S. 2016. Fast matrix
factorization for online recommendation with implicit feedback. In
SIGIR, 549–558.
He, X.; Liao, L.; Zhang, H.; Nie, L.; Hu, X.; and Chua, T.-S. 2017.
Neural collaborative ﬁltering. In WWW.
Juan, Y.-C.; Chin, W.-S.; Zhuang, Y.; Yuan, B.-W.; Yang, M.-Y.;
and Lin, C.-J. 2016. Libmf: A matrix-factorization library for
recommender systems. https://www.csie.ntu.edu.tw/
˜cjlin/libmf/.
Kingma, D., and Ba, J. 2014. Adam: A method for stochastic
optimization. arXiv preprint arXiv:1412.6980.
Koren, Y.; Bell, R.; and Volinsky, C. 2009. Matrix factorization
techniques for recommender systems. Computer (8):30–37.
Koren, Y. 2008. Factorization meets the neighborhood: a multi-
faceted collaborative ﬁltering model. In SIGKDD.
Krizhevsky, A.; Sutskever, I.; and Hinton, G. E. 2012. Imagenet
classiﬁcation with deep convolutional neural networks. In NIPS.

2017.
JMLR

Larochelle, H., and Murray, I. 2011. The neural autoregressive
distribution estimator. In AISTATS.
Lauly, S.; Zheng, Y.; Allauzen, A.; and Larochelle, H.
Document neural autoregressive distribution estimation.
18(113):1–24.
Lee, J.; Kim, S.; Lebanon, G.; and Singer, Y. 2013. Local low-rank
matrix approximation. In ICML, 82–90.
Maaten, L. v. d., and Hinton, G. 2008. Visualizing data using t-sne.
JMLR 9:2579–2605.
Mnih, V.; Kavukcuoglu, K.; Silver, D.; Rusu, A. A.; Veness, J.;
Bellemare, M. G.; Graves, A.; Riedmiller, M.; Fidjeland, A. K.;
Ostrovski, G.; et al. 2015. Human-level control through deep rein-
forcement learning. Nature 518(7540):529–533.
Pan, R.; Zhou, Y.; Cao, B.; Liu, N. N.; Lukose, R.; Scholz, M.; and
Yang, Q. 2008. One-class collaborative ﬁltering. In ICDM.
Rendle, S.; Freudenthaler, C.; Gantner, Z.; and Schmidt-Thieme, L.
2009. Bpr: Bayesian personalized ranking from implicit feedback.
In UAI, 452–461.
Resnick, P.; Iacovou, N.; Suchak, M.; Bergstrom, P.; and Riedl, J.
1994. Grouplens: an open architecture for collaborative ﬁltering of
netnews. In Proceedings of the 1994 ACM conference on Computer
supported cooperative work, 175–186. ACM.
Salakhutdinov, R., and Mnih, A. 2007. Probabilistic matrix factor-
ization. In NIPS.
Salakhutdinov, R., and Mnih, A. 2008. Bayesian probabilistic ma-
trix factorization using markov chain monte carlo. In ICML.
Salakhutdinov, R.; Mnih, A.; and Hinton, G. 2007. Restricted
boltzmann machines for collaborative ﬁltering. In ICML.
Sarwar, B.; Karypis, G.; Konstan, J.; and Riedl, J. 2000. Applica-
tion of dimensionality reduction in recommender system – a case
study. In ACM WEBKDD WORKSHOP.
Sarwar, B.; Karypis, G.; Konstan, J.; and Riedl, J. 2001. Item-based
collaborative ﬁltering recommendation algorithms. In WWW.
Schafer, J. B.; Frankowski, D.; Herlocker, J.; and Sen, S. 2007.
Collaborative ﬁltering recommender systems. In The adaptive web.
Springer. 291–324.
Sedhain, S.; Menon, A. K.; Sanner, S.; and Xie, L. 2015. Autorec:
Autoencoders meet collaborative ﬁltering. In WWW.
Silver, D.; Huang, A.; Maddison, C. J.; Guez, A.; Sifre, L.; Van
Den Driessche, G.; Schrittwieser, J.; Antonoglou, I.; Panneershel-
vam, V.; Lanctot, M.; et al. 2016. Mastering the game of go with
deep neural networks and tree search. Nature 529(7587):484–489.
Theano Development Team. 2016. Theano: A Python framework
for fast computation of mathematical expressions. arXiv preprint
arXiv:1605.02688.
Van den Oord, A.; Dieleman, S.; and Schrauwen, B. 2013. Deep
content-based music recommendation. In NIPS.
Wang, J.; De Vries, A. P.; and Reinders, M. J. 2006. Unifying user-
based and item-based collaborative ﬁltering approaches by similar-
ity fusion. In SIGIR, 501–508.
Wu, Y.; DuBois, C.; Zheng, A. X.; and Ester, M. 2016. Collabo-
rative denoising auto-encoders for top-n recommender systems. In
WSDM, 153–162.
Zheng, Y.; Liu, C.; Tang, B.; and Zhou, H. 2016a. Neural au-
toregressive collaborative ﬁltering for implicit feedback. In Pro-
ceedings of the 1st Workshop on Deep Learning for Recommender
Systems, 2–6. ACM.
Zheng, Y.; Tang, B.; Ding, W.; and Zhou, H. 2016b. A neural
autoregressive approach to collaborative ﬁltering. In ICML.

Collaborative Filtering with User-Item Co-Autoregressive Models

Chao Du† Chongxuan Li† Yin Zheng‡

Jun Zhu∗† Bo Zhang†

†Dept. of Comp. Sci. & Tech., State Key Lab of Intell. Tech. & Sys., TNList Lab,
†Center for Bio-Inspired Computing Research, Tsinghua University, Beijing, 100084, China
‡Tencent AI Lab, Shenzhen, Guangdong, China

8
1
0
2
 
l
u
J
 
5
 
 
]

G
L
.
s
c
[
 
 
3
v
6
4
1
7
0
.
2
1
6
1
:
v
i
X
r
a

Abstract

Deep neural networks have shown promise in collaborative
ﬁltering (CF). However, existing neural approaches are either
user-based or item-based, which cannot leverage all the un-
derlying information explicitly. We propose CF-UIcA, a neu-
ral co-autoregressive model for CF tasks, which exploits the
structural correlation in the domains of both users and items.
The co-autoregression allows extra desired properties to be
incorporated for different tasks. Furthermore, we develop an
efﬁcient stochastic learning algorithm to handle large scale
datasets. We evaluate CF-UIcA on two popular benchmarks:
MovieLens 1M and Netﬂix, and achieve state-of-the-art per-
formance in both rating prediction and top-N recommenda-
tion tasks, which demonstrates the effectiveness of CF-UIcA.

1

Introduction

With the fast development of electronic commerce, so-
cial networks and music/movie content providers, recom-
mendation systems have attracted extensive research atten-
tion (Burke 2002; Schafer et al. 2007). As one of the most
popular methods, collaborative ﬁltering (CF) (Schafer et
al. 2007; Billsus and Pazzani 1998; Resnick et al. 1994;
Salakhutdinov, Mnih, and Hinton 2007) predicts users’ pref-
erences for items based on their previous behaviors (rat-
ing/clicking/purchasing etc.) in a recommendation system.
CF enjoys the beneﬁt of content-independence of the items
being recommended. Thus, it does not need expert knowl-
edge about the items when compared with content-based
methods (Van den Oord, Dieleman, and Schrauwen 2013;
Gopalan, Charlin, and Blei 2014) and could possibly pro-
vide cross-domain recommendations.

The basic assumption behind CF is that there exist corre-
lations between the observed user behaviors, and these cor-
relations can be generalized to their future behaviors. Ba-
sically, the correlations can be categorized as User-User
Correlations (UUCs)—the correlations between different
users’ behaviors on a same item, and Item-Item Correla-
tions (IICs)—the correlations between a user’s behaviors on
different items. These two types of underlying correlations
usually exist crisscrossing in the partially observed user be-
haviors, making CF a difﬁcult task.

∗corresponding author.

Copyright c(cid:13) 2018, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

Extensive work has studied how to effectively exploit the
underlying correlations to make accurate predictions. Early
approaches (Resnick et al. 1994; Sarwar et al. 2001) con-
sider UUCs or IICs by computing the similarities between
users or items. As one of the most popular classes of CF
methods, matrix factorization (MF) (Billsus and Pazzani
1998; Koren, Bell, and Volinsky 2009; Salakhutdinov and
Mnih 2007) assumes that the partially observed matrix (of
ratings) is low-rank and embeds both users and items into a
shared latent space. MF methods consider both UUCs and
IICs implicitly as a prediction is simply the inner product
of the latent vectors of the corresponding user and item.
Recently, deep learning methods have achieved promising
results in various tasks (Bahdanau, Cho, and Bengio 2014;
Mnih et al. 2015; Silver et al. 2016) due to their ability to
learn a rich set of abstract representations. Inspired by these
advances, neural networks based CF methods (Salakhutdi-
nov, Mnih, and Hinton 2007; Sedhain et al. 2015; Wu et
al. 2016; Zheng et al. 2016b), which employ highly ﬂexi-
ble transformations to model a user’s behavior proﬁle (all
behaviors) with a compact representation, are widely stud-
ied as alternatives to MF. These methods essentially consider
all UUCs explicitly as they take inputs of users’ all observed
behaviors. (See more details in Sec. 2.)

Though previous neural networks based methods are
promising, one common drawback of these methods lies in
that they cannot exploit both UUCs and IICs together, mak-
ing them further improvable. To this end, we propose a novel
neural autoregressive model for CF, named User-Item co-
Autoregressive model (CF-UIcA), which considers the au-
toregression in the domains of both users and items, so as
to model both UUCs and IICs together. The introduced co-
autoregression naturally provides a principled way to select
the UUCs and IICs to be generalized that are helpful for
prediction. This allows us to incorporate extra desired prop-
erties into the model for different tasks, which is not stud-
ied in previous work. We further develop a stochastic learn-
ing algorithm for CF-UIcA to make it applicable for large
datasets. We demonstrate our method on two real bench-
marks: MovieLens 1M and Netﬂix, achieving state-of-the-
art results in both rating prediction and top-N recommenda-
tion tasks, which is rarely accomplished in previous work.
In addition, the visualization demonstrates that CF-UIcA
learns semantic patterns without extra supervision.

(a)

(b)

(c)

(d)

Figure 1: Illustration of predictions in a toy recommendation system with 5 users and 6 items (best viewed in color). Each square
in green/yellow/gray corresponds to a positive/negative/unobserved behavior, respectively. The behavior (whose associating
user and item are colored in deep blue) being predicted is marked with a question mark. (a) Predict with a single User-User
Correlation: the behavior is predicted according to the behavior of another user (labeled as light blue); (b) Predict with a single
Item-Item Correlation; (c) Predict with multiple User-User Correlations, and (d) Predict with multiple Item-Item Correlations.

2 Related Work

Collaborative ﬁltering methods make predictions based on
user behaviors, which could reveal certain patterns for gen-
eralization. These phenomena involve two types of informa-
tion: User-User Correlations (UUCs) and Item-Item Cor-
relations (IICs). As shown in Fig. 1a, UUC depicts that a
user’s behavior is usually related to the one of some other
users on the same item, especially when they have similar
habits/tastes. Similarly, IIC depicts that a user’s behavior on
an item is related to his/her behaviors on other items, es-
pecially when these items are similar in nature, as shown in
Fig. 1b. Predictions are then possible to be made by integrat-
ing these correlations. Fig. 1c and Fig. 1d show all the UUCs
and IICs of the unknown preference marked by the question
mark. Intuitively, integrating multiple UUCs and IICs can
potentially lead to a more precise prediction.

Existing CF methods either implicitly or explicitly exploit
these correlations. Early methods model the correlations via
some similarity functions on the raw preferences, such as k-
NN collaborative ﬁltering (kNN-CF) (Resnick et al. 1994;
Sarwar et al. 2001). These methods make predictions with
the top k UUCs or IICs explicitly. Matrix factorization (MF)
methods characterize both users and items by vectors in
a low-dimensional latent space. The predictions are mod-
eled with the inner products of the latent vectors of the cor-
responding users and items. Representative works include
SVD-based methods (Billsus and Pazzani 1998; Sarwar et
al. 2000) and the probabilistic MF (PMF) (Salakhutdinov
and Mnih 2007; 2008). Recent approaches improve MF by
loosing the constrains of linearity and low-rank assumption.
Bias MF (Koren, Bell, and Volinsky 2009) introduces bias
terms associated with users and items. Lee et al. (2013) pro-
pose Local Low-Rank Matrix Approximation (LLORMA)
by assuming the observed rating matrix is a weighted sum
of low-rank matrices. NNMF (Dziugaite and Roy 2015) and
NeuMF (He et al. 2017) replace the inner product operations
in MF with neural networks. Since MF methods make pre-
dictions with the learned latent vectors of the users and the
items, the UUCs and IICs are not modeled explicitly.

With the success in many tasks (Krizhevsky, Sutskever,
and Hinton 2012; Graves, Mohamed, and Hinton 2013;

Bahdanau, Cho, and Bengio 2014; Mnih et al. 2015; Silver et
al. 2016), deep learning has been integrated into CF methods
with great success. Salakhutdinov, Mnih, and Hinton (2007)
propose RBM-CF, a CF methods based on Restricted Boltz-
mann Machines, which has shown its power in Netﬂix prize
challenge (Bennett and Lanning 2007). Sedhain et al. (2015)
propose AutoRec, a discriminative model based on auto-
encoders. A similar model known as CDAE is concurrently
proposed by Wu et al. (2016). Recently, Zheng et al. (2016b)
propose CF-NADE, a tractable model based on Neural Au-
toregressive Distribution Estimators (NADE) (Larochelle
and Murray 2011), and achieve the state-of-the-art results on
several CF benchmarks. These methods share two aspects:
1) different models are built for different users by sharing
parameters; and 2) predictions are made for a user according
to his/her behavior proﬁle. Note that as the role of users and
items are exchangeable, these methods usually have a user-
based and an item-based variants. As a result, these methods
make predictions with either the UUCs or the IICs explicitly.
Our CF-UIcA differs from existing CF methods in that
it can capture both UUCs and IICs explicitly and simulta-
neously. Similar as in CF-NADE, we adopt neural autore-
gressive architectures to model the probabilities of the be-
haviors. The crucial difference is that CF-NADE models
the rating vectors of each user, making the users indepen-
dent from each other, while CF-UIcA models the behaviors
across all users and items in order to consider UUCs and
IICs jointly. Moreover, we analyze the signiﬁcance of the
co-autoregression in a novel perspective and demonstrate its
effectiveness, which is another step beyond CF-NADE.

Hybrid recommendation (Burke 2002) is a class of meth-
ods focusing on combining different techniques at a high
level, e.g., combining CF-based methods and content-based
methods together. Different with the existing hybrid recom-
mendation methods, our model focuses on utilizing both
user-based and item-based information. Wang, De Vries,
and Reinders (2006) share similar motivation with ours.
However, their method is memory-based and uniﬁes user-
based and item-based models by similarity. While our
method is model-based and combines user-based and item-
based information by autoregressive neural networks.

Figure 2: An illustration of the conditional model. The yellow, green and gray entries are interpreted same as in Fig. 1. Suppose
Rot is the current behavior being modeled. The black striped lines mark the entries of Ro>t. The blue dashed boxes line
out the UUCs and IICs for Rot. The cuboids represent the columns of WU , WI , VU , VI , with the color corresponding to
the behaviors. The hidden representations hU and hI are computed by summing over the corresponding columns (with the
uncorresponding columns marked in lighter colors) of UUCs and IICs. The activations sU and sI are computed by multiplying
the hidden representations and the corresponding columns of VU and VI . We omit the bias terms for clarity.

3 Method
We now present CF-UIcA which models both UUCs and
IICs with co-autoregressvie architectures.

Let N and M denote the number of users and items,
respectively. We deﬁne the behavior matrix R ∈ RN ×M
from user behaviors by assigning entries of R with differ-
ent labels for different behaviors: For explicit feedback, e.g.
K-star scale ratings, we deﬁne Ri,j = k for the behavior
“user i rates item j with k stars”; For implicit feedback, e.g.
clicks, we deﬁne Ri,j = 1 for the behavior “user i clicks
item j”. And we deﬁne Ri,j = 0 for unobserved entries. Let
D = {Rid,jd}D
d=1 be all the observed behaviors, which form
the training set. The goal of CF is then to predict an unknown
behavior Ri∗,j∗ (cid:54)∈ D based on the observed behaviors D.

3.1 The Model
Autoregressive models (Frey 1998; Larochelle and Murray
2011; Lauly et al. 2017) offer a natural way to introduce in-
terdependencies, which is desired for CF tasks, as analyzed
in Sec. 2. We start with a very generic autoregressive as-
sumption to model the probability of the behavior matrix:

p(R) =

p(Rot |Ro<t ),

(1)

N ×M
(cid:89)

t=1

where o is a permutation of all (cid:104)user, item(cid:105) pairs that serves
as an ordering of all the entries in the behavior matrix R,
and Ro<t denotes the ﬁrst t − 1 entries of R indexed by o.
For example, ot = (i(cid:48), j(cid:48)) indicates that the behavior Ri(cid:48),j(cid:48)
is at the t-th position in o, i.e., Rot = Ri(cid:48),j(cid:48). Let oi
t = i(cid:48) and
oj
t = j(cid:48) denote the ﬁrst and second dimension of ot, which
index the user and the item, respectively.

Basically, there are (N ×M )! possible orderings of all the
entries of R. For now we assume that o is ﬁxed. (We will
discuss the orderings latter.) If we consider o as the order-
ing of the timestamps of the behaviors observed by the sys-
tem, then the conditional in Eqn. (1) means that the model
predicts behavior Rot at time t depends on all the observed
behaviors before t.

The Conditional Model According to Sec. 2, both UUCs
and IICs are informative for prediction. We therefore deﬁne
a conditional model that exploits both UUCs and IICs:

p(Rot |Ro<t ) = p(Rot |RU U C

ot

),

, RIIC
ot
: t(cid:48) < t, oj

(2)

where we have deﬁned RU U C
oj
t } as the behaviors on item oj
UUCs of Rot (by time t). RIIC
ot

ot

= {Rot(cid:48)

t(cid:48) =
t in Ro<t , which form all the
is deﬁned symmetrically.

Inspired by NADE (Larochelle and Murray 2011) and CF-
NADE (Zheng et al. 2016b), we model the conditional in
Eqn. (2) with neural networks due to the rich expressive abil-
ity. Speciﬁcally, CF-UIcA models the UUCs and IICs of Rot
with hidden representations respectively:

hU (RU U C

ot

) = f

hI (RIIC

ot

) = f

(cid:16) (cid:88)

(cid:16) (cid:88)

t(cid:48)<t:oj

t(cid:48) =oj

t

t(cid:48)<t:oi

t(cid:48) =oi

t

WU

:,oi

t(cid:48) ,Ro

t(cid:48)

WI

:,oj

t(cid:48) ,Ro

t(cid:48)

,

+ cU (cid:17)
+ cI (cid:17)
,

(3)

(4)

where f (·) is a nonlinear function, such as tanh(x) =
exp(x)−exp(−x)
exp(x)+exp(−x) , WU ∈ RHU ×N ×K and WI ∈ RHI ×M ×K
are 3-order tensors, cU ∈ RHU and cI ∈ RHI are the
bias terms. HU and HI are the dimensions of the hidden
representations for UUCs and IICs, respectively. The col-
umn WI
:,j,k denotes how much “behaving k on item j” con-
tributes to the hidden representations of the IICs while the
column WU
:,i,k denotes the contribution of “user i behaves
k” to the hidden representation of the UUCs.

CF-UIcA explains the hidden representations of the

UUCs and the IICs by computing the activations:

t,k(hU (RU U C
sU
oi
sI
t ,k(hI (RIIC
oj

ot

ot

)) = VU

)) = VI

:,oi

t,k

:,oj

t ,k

(cid:62)hU (RU U C

ot
(cid:62)hI (RIIC

ot

) + bU
t,k,
oi
) + bI
t ,k,
oj

(5)

(6)

where VU ∈ RHU ×N ×K and VI ∈ RHI ×M ×K are 3-order
tensors, bU ∈ RN ×K and bI ∈ RM ×K are the bias terms.
The column VI
:,j,k is the coefﬁcients that determine how the
hidden representation of the IICs affects the activation sI

j,k

for “behaving k on item j”. Higher activation sI
j,k indicates
that the considered IICs suggest higher probability that the
user will carry out a behavior k on item j. The activation sU
i,k
is interpreted similarly.

Finally, to combine the activations of UUCs and IICs of
Rot and produce a probability distribution, we deﬁne the ﬁ-
nal conditional model as a softmax function of the summa-
tion of the two activations:

p(Rot = k|Ro<t ) =

(cid:16)

exp

(cid:17)

sU
t,k + sI
oj
oi
t ,k
(cid:18)
t,k(cid:48) + sI
oj
t ,k(cid:48)

sU
oi

(cid:80)K

k(cid:48)=1 exp

(cid:19) .

(7)

Fig. 2 illustrates the conditional model.

i(cid:48),j(cid:48) and RIIC

Orderings in Different Tasks We now discuss the effect
of different orderings on the model and show what kinds of
orderings are considered for two major CF tasks detailedly.
In fact, the ordering o decides the conditional model for
each observed behavior Ri(cid:48),j(cid:48). Speciﬁcally, according to our
model (See Eqns. (2) to (4)), the contributions of UUCs and
IICs to a given behavior Ri(cid:48),j(cid:48), i.e. RU U C
i(cid:48),j(cid:48) , depend
on where the ordering o places Ri(cid:48),j(cid:48) and what o places be-
fore Ri(cid:48),j(cid:48). In general, different orderings result in different
conditional models or dependency relations (see Fig. 3 for
an illustration) and any possible conditional models can be
induced by some speciﬁc orderings. Such a property leaves
us freedom to control what kind of dependencies we would
like the model to exploit in different tasks, as shown below.
CF methods are usually evaluated on rating prediction
tasks (Zheng et al. 2016b; Sedhain et al. 2015), or more
generally, matrix completion tasks, by predicting randomly
missing ratings/values. For matrix completion tasks, taking
all UUCs and IICs into consideration leads the model to
exploit the underlying correlations to a maximum extent.
Therefore, we should consider all possible conditional mod-
els for each behavior, i.e., all orderings, in such tasks. The
objective could then be deﬁned as the expected (over all or-
derings) negative log-likelihood (NLL) of the training set:

L(θ) = E

− log p(D|θ, o)

o∈SD

= − E

o∈SD

(cid:88) D

d=1 log p(Rod |Ro<d , θ, o),

(8)

where θ denotes all the model parameters and SD is the set
of all the permutations of D1. Note that taking the expecta-
tion over all orderings is equivalent to integrating them out.
Thus the training procedure does not depend on any partic-
ular ordering and no manually chosen ordering is needed.

Recent works (Rendle et al. 2009; He et al. 2017) also
evaluate CF on top-N recommendation tasks, aiming to sug-
gest a short list of future preferences for each user, which is
closer to the goal of real-world recommendation systems. In
these tasks, not all IICs are useful. For example, people who
have just watched Harry Potter 1 (HP1) are very likely to be
interested in Harry Potter 2 (HP2), however those who have
just watched HP2 are less likely to have interest in HP1, as
he/she may have known some spoiler about HP1. To this

1Given the training set D, the ﬁrst D elements of o will be au-
tomatically restricted to D. As we only evaluate the likelihood of
the training set D, the number of equivalence orderings are D!.

(a)

(b)

(c)

Figure 3: An illustration of how the orderings decide the
conditional models. Colors are interpreted same as in Fig. 2.
(a) - (c) show 3 conditional models for the central (gray)
behavior in an example behavior matrix under 3 different
orderings. The numbers 1 - 9 indicate the indices of the cor-
responding behaviors in the orderings. The arrows indicate
the dependencies involved in the conditional models.

end, we should expect the model to capture the chronolog-
ical IICs, which only include the dependencies from later
behaviors to previous behaviors of each user, and all UUCs
in the meanwhile. Then, an appropriate objective should be
the expected NLL of the training set over all orderings that
do not break the chronological order of each user’s behav-
iors. Note that this can be implemented equivalently by re-
deﬁning RIIC
i(cid:48),j(cid:48) = {Ri(cid:48),j(cid:48)(cid:48) : T (Ri(cid:48),j(cid:48)(cid:48) ) < T (Ri(cid:48),j(cid:48))}, where
T (·) is the timestamp when the system observes the behav-
ior, and using Eqn. (8) as the objective2. Hence we still need
not to choose any ordering manually.

The above examples show that extra desired properties
can be incorporated into CF-UIcA for different tasks by con-
sidering different orderings in the objective, which indeed
beneﬁts from the co-autoregressive assumption.

3.2 Learning
The remaining challenge is to optimize the objective in
Eqn. (8). A common strategy to deal with complicate in-
tegrations or large-scale datasets is to adopt stochastic
optimization approaches, e.g. stochastic gradient descent
(SGD) (Bottou 2010; Kingma and Ba 2014), which require
an unbiased estimator of the objective or its gradient. SGD
and its variants have been widely adopted in various areas
due to its efﬁciency, including many CF methods (Sedhain
et al. 2015; Zheng et al. 2016b). However, unlike in the most
existing neural networks based methods (Wu et al. 2016;
Zheng et al. 2016b), the users are not modeled indepen-
dently in CF-UIcA, resulting the objective cannot be esti-
mated stochastically by simply sub-sampling the users. To
tackle this challenge, we derive an unbiased estimator of
Eqn. (8) below, which completes the proposed method.

By exchanging the order of the expectation and the sum-

mation in Eqn. (8) and doing some simple math, we get:

L(θ) = −

(cid:88)

(i(cid:48),j(cid:48))∈D

E
d

E
o∈SD |od=(i(cid:48),j(cid:48))

log p(Ri(cid:48),j(cid:48) |Ro<d ,θ,o).

(9)

According to the deﬁnition of the conditional model from
Eqns. (3) to (7), the log-probability of Ri(cid:48),j(cid:48) in Eqn. (9) de-
pends on at most Ri(cid:48),¬j(cid:48) = Ri(cid:48),:\{Ri(cid:48),j(cid:48)} (behaviors of user

2In this case RIIC

i(cid:48),j(cid:48) is deterministic and only RU U C

i(cid:48),j(cid:48) depends on

the ordering o.

i(cid:48),j(cid:48) = Ri(cid:48),¬j(cid:48) ∩Ro<d and the set RU U C

i(cid:48) except Ri(cid:48),j(cid:48)) and R¬i(cid:48),j(cid:48) = R:,j(cid:48)\{Ri(cid:48),j(cid:48)} (behaviors
on item j(cid:48) except Ri(cid:48),j(cid:48)). Speciﬁcally, given od = (i(cid:48), j(cid:48)),
the log-probability of Ri(cid:48),j(cid:48) depends on exactly the set
RIIC
i(cid:48),j(cid:48) = R¬i(cid:48),j(cid:48) ∩Ro<d.
As we treat the ordering o as a random variable uniformly
distributed over SD, RIIC
are also random.
i(cid:48),j(cid:48) = ∅, they are indepen-
Moreover, since RIIC
dent given their sizes m = |RIIC
i(cid:48),j(cid:48) | and n = |RU U C
i(cid:48),j(cid:48) |, i.e.,
RIIC
i(cid:48),j(cid:48) |n. By expanding the second expectation
in Eqn. (9) based on the above analysis, we have:

i(cid:48),j(cid:48) |m ⊥ RU U C

i(cid:48),j(cid:48) and RU U C
i(cid:48),j(cid:48)

i(cid:48),j(cid:48) ∩ RU U C

N
(cid:88)

M
(cid:88)

L(θ) = −

E
d

E
m,n|d

i(cid:48)=1

j(cid:48)=1
log p(Ri(cid:48),j(cid:48) |RU U C

i(cid:48),j(cid:48) , RIIC

E
RU U C
i(cid:48) ,j(cid:48) |n

E
RIIC
i(cid:48) ,j(cid:48) |m
i(cid:48),j(cid:48) , θ)I[(i(cid:48),j(cid:48))∈D],

(10)

i(cid:48),j(cid:48) |m and RU U C

where m, n, RIIC
i(cid:48),j(cid:48) |n are all random and are
decided by the random ordering o. Note the summation over
D is replaced by an equivalent representation using an indi-
cator function I[(i(cid:48),j(cid:48))∈D]. Given RU U C
i(cid:48),j(cid:48) , the log-
probability term and the indicator term can be computed eas-
ily. From now we omit these two terms for simplicity.

i(cid:48),j(cid:48) and RIIC

According to symmetry, it is easy to know that RIIC

i(cid:48),j(cid:48) |m
and RU U C
i(cid:48),j(cid:48) |n are uniformly distributed over all subsets of
size m of R¬i(cid:48),j(cid:48) ∩D and subsets of size n of Ri(cid:48),¬j(cid:48) ∩D, re-
spectively. However, these distributions have different sup-
ports since the numbers of the observed behaviors for users
(items) are different, which makes the sampling unparal-
lelizable. Note that the process of drawing o from SD can
be equivalently simulated by ﬁrst randomly drawing σ from
SN ×M , which can be viewed as an ordering of all the en-
tries of R, and then dropping the unobserved entries R\D.
The resulted ordering on D is still uniformly distributed over
SD. Then Eqn. (10) can be written equivalently as:

L(θ) = −

N
(cid:88)

M
(cid:88)

i(cid:48)=1

j(cid:48)=1

E
r

E
y,z|r

E
M⊆[M ]\{j(cid:48)}|y

E
N⊆[N ]\{i(cid:48)}|z

,

(11)

where r is the index of Ri(cid:48),j(cid:48) in σ, y and z are the number of
entries in Ri(cid:48),¬j(cid:48) ∩ Rσ<r and R¬i(cid:48),j(cid:48) ∩ Rσ<r , respectively.
M is a subset of size y of [M ]\{j(cid:48)} and N is a subset of
size z of [N ]\{i(cid:48)}, where [N ] denotes {1, · · · , N }. RU U C
i(cid:48),j(cid:48)
and RIIC

i(cid:48),j(cid:48) are therefore RN ,j(cid:48) ∩ D, Ri(cid:48),M ∩ D.

Finally, with some simple math we obtain:

L(θ) = −N M E
r

E
y,z|r

E
M⊆[M ]|y

E
N⊆[N ]|z

E
i(cid:48)∈[N ]\N

E
j(cid:48)∈[M ]\M

. (12)

In Eqn. (12), y and z can be computed after sampling r and
σ. M and N are sampled by uniformly choosing y and z
elements in [M ] and [N ] without replacement, respectively.
The last two expectations can be estimated unbiasedly by
sampling BU elements from [N ]\N and BI elements from
[M ]\M, respectively, where BU and BI can be viewed as
the minibatch sizes of users and items. Finally, we get an
unbiased estimation of the objective L(θ), which can be then
adopted in SGD algorithms.

Note that though the training objective involves expecta-
tions over multiple orderings (which help exploit the desired
UUCs and IICs during training), the prediction procedure is

Figure 4: The performance
on MovieLens 1M of CF-
UIcA and CF-NADE w.r.t.
the number of hidden units.

Figure 5: The performance
on Netﬂix of CF-UIcA
w.r.t. the number clusters of
users.

simple and deterministic. For an unknown behavior Ri∗,j∗ ,
the prediction is evaluated with ˆRi∗,j∗ = Ep(Ri∗ ,j∗ =k|D)[k]
with RU U C
i∗,j∗ = Ri∗,¬j∗ ∩ D,
where we have assumed Ri∗,j∗ = RoD+1 and Ro<D+1 = D.

i∗,j∗ = R¬i∗,j∗ ∩ D and RIIC

4 Experiments
We now present a series of experimental results of the pro-
posed CF-UIcA to demonstrate its effectiveness. We com-
pare CF-UIcA with other popular CF methods on two major
kinds of CF tasks: rating prediction and top-N recommenda-
tion. The experiments are conducted on two representative
datasets: MovieLens 1M (Harper and Konstan 2016) and
Netﬂix (Bennett and Lanning 2007). MovieLens 1M con-
sists of 1, 000, 209 ratings of 3, 952 movies (items) rated
by 6, 040 users. Netﬂix consists of 100, 480, 507 ratings
of 17, 770 movies rated by 480, 189 users. The ratings in
both datasets are 1-5 stars scale, i.e., K = 5. For all ex-
periments, we use Adam (Kingma and Ba 2014) to opti-
mize the objectives with an initial learning rate 0.001. Dur-
ing training, we anneal the learning rate by factor 0.25 un-
til no signiﬁcant improvement can be observed on valida-
tion set. Note that in Eqn. (12) the sizes of [N ]\N and
[M ]\M, i.e. N − z and M − y, vary from 1 to N − 1
and to M − 1, respectively. As a consequence, the mini-
batch sizes of users/items should be set dynamically. Nev-
ertheless, we choose ﬁxed minibatch sizes of users/items
BU /BI , which only take effect when M − y > BI or
N − z > BU . We adopt weight decay on model parameters
to prevent the model from overﬁtting. Other hyper parame-
ters and detailed experimental settings will be speciﬁed lat-
ter for each task. The codes and more detailed settings can be
found at https://github.com/thu-ml/CF-UIcA.

4.1 Rating Prediction
We use the same experimental settings with LLORMA (Lee
et al. 2013), AutoRec (Sedhain et al. 2015) and CF-
NADE (Zheng et al. 2016b). We randomly select 90%
of the ratings in each of the datasets as the training set,
leaving the remaining 10% of the ratings as the test set.
Among the ratings in the training set, 5% are hold out
for validation. We compare the predictive performance with
other state-of-the-art methods in terms of the common used
Root Mean Squared Error (RMSE) = ((cid:80)
(i,j)∈Dtest( ˆRi,j −
Ri,j)2/Dtest)1/2, where Dtest is the test set of Dtest unknown
ratings, Ri,j is the true rating and ˆRi,j is the prediction. The

Table 1: Test RMSE on MovieLens 1M and Netﬂix. All the
baseline results are taken from Zheng et al. (2016b).

Table 2: Test HR@10 and NDCG@10 of various methods
on MovieLens 1M. The results of baseline methods (except
CDAE) are kindly provided by He et al. (2017).

Method
PMF
U-RBM
U-AutoRec
LLORMA-Global
I-RBM
BiasMF
U-CF-NADE-S (2 layers)
NNMF
LLORMA-Local
I-AutoRec
I-CF-NADE-S (2 layers)
CF-UIcA (H U=H I=500)

MovieLens 1M Netﬂix

0.883
0.881
0.874
0.865
0.854
0.845
0.845
0.843
0.833
0.831
0.829

-
0.845
-
0.874
-
0.844
0.803
-
0.834
0.823
-

0.823

0.799

reported results are averaged over 10 random splits, with
standard deviations less than 0.0002.

MovieLens 1M For experiments on MovieLens 1M, we
set BU /BI to 1, 000/1, 000 and the weight decay to 0.0001.
Since CF-UIcA has a connection with CF-NADE (Zheng
et al. 2016b) as mentioned in Sec. 2, we ﬁrst present a com-
parison between CF-UIcA and CF-NADE in Fig. 4. CF-
NADE models each user with a latent representation, sim-
ilar with our hidden representation of UUCs or IICs. For
fairness, we compare the two methods with the same num-
ber of hidden units, where in our CF-UIcA the number of
hidden units is H U+H I . Note that in CF-UIcA H U is not
necessarily equal to H I , we nevertheless choose H U =H I
for simplicity. We report the item-based CF-NADE results
under best setting as described in (Zheng et al. 2016b).

From Fig. 4 we observe that for small number of hidden
units, e.g. 250, our method gives a worse result than CF-
NADE. This is attributed to that the hidden dimensions allo-
cated to the hidden representation of UUCs and IICs are too
small (H U =H I =125) to capture the underlying informa-
tion. As the number of hidden units increases, we observe
CF-UIcA outperforms CF-NADE since CF-UIcA can cap-
ture both UUCs and IICs while the item-based CF-NADE
can only capture UUCs. One thing worth mentioning is that
the total number of parameters in CF-UIcA is only around
83% of the number of parameters in CF-NADE for Movie-
Lens 1M when the number of hidden units are same, which
implies that CF-UIcA can capture more information than
CF-NADE with fewer parameters.

Table 1 (middle column) compares the performance of
CF-UIcA with state-of-the-art methods on MovieLens 1M.
The hidden dimensions of CF-UIcA are H U = H I = 500.
Our method achieves an RMSE of 0.823, outperforming all
the existing strong baselines. Note that as RMSE scores have
been highly optimized in previous work, our 0.006 RMSE
improvement w.r.t. CF-NADE is quite signiﬁcant, compared
to the 0.002 by which CF-NADE improves over AutoRec
and 0.002 by which AutoRec improves over LLORMA.

Netﬂix The Netﬂix dataset is much bigger than Movie-
Lens 1M, especially the number of users. We opt to clus-

HR@10 NDCG@10

Method
ItemPop
ItemKNN
BPR (Rendle et al. 2009)
eALS (He et al. 2016)
NeuMF
CDAE

CF-UIcA (Uniform)
CF-UIcA (Inverse)
CF-UIcA

0.454
0.623
0.690
0.704
0.730
0.726

0.692
0.616
0.736

0.254
0.359
0.419
0.433
0.447
0.448

0.406
0.353
0.492

ter all the 480, 189 users into 10K, 15K and 20K groups,
respectively, and make the users in same clusters sharing
their corresponding columns in WU and VU . To cluster
the users, we ﬁrst run matrix factorization (Juan et al. 2016)
with rank 100 on the training set. (Predicting the test set with
the learned vectors by MF gives an RMSE of 0.865.) Then
the clustering process is simply done by running a K-means
clustering algorithm on the latent vectors of users learned by
MF. For CF-UIcA, the weight decay is set to 5 × 10−6 as the
dataset is sufﬁciently large. The minibacth sizes of users and
items are set to BU = 4, 000 and BI = 1, 000. The hidden
dimensions are H U = H I = 500.

Fig. 5 shows the performance of CF-UIcA with different
number of clusters. We observe that the performance im-
proves as the number of clusters increases, which can be
attributed to that using more clusters empowers the model
to capture more variety among users. Another observation is
that the performance can be potentially improved by further
increasing the number of clusters. We do not increase the
number of clusters due to the limitation of GPU memory.

Table 1 (right column) summarizes our best result and
other state-of-the-art results. Symbol “-” indicates that the
authors didn’t report the result, probably due to the lack
of scalability3. Our method with 20, 000 clusters of users
achieves a state-of-the-art RMSE of 0.799, which, together
with the results on MovieLens 1M, proves that our CF-UIcA
has the ability to predict users’ ratings precisely.

4.2 Top-N Recommendation
In most real scenarios, the goal of recommendation sys-
tems is to suggest a top-N ranked list of items that are
supposed to be appealing for each user. Moreover, implicit
feedback (Zheng et al. 2016a) has attracted increasing in-
terests because it is usually collected automatically and is
thus much more easier to obtain. We follow the exper-
imental settings of NeuMF (He et al. 2017) to test the
recommendation quality of CF-UIcA with implicit feed-
back. We transform MovieLens 1M into implicit data by
marking all ratings as 1 indicating that the user has rated
the item. We adopt the leave-one-out (Rendle et al. 2009;

3We conﬁrmed with the authors of (Zheng et al. 2016b) that
I-CF-NADE is not scalable to Netﬂix. For AutoRec, the authors
reported that I-AutoRec is their best model.

Table 3: Average running time for each minibatch of CF-
UIcA on different datasets.

BU /BI

Dataset
ML 1M 1, 000/1, 000
4, 000/1, 000
Netﬂix

H U /H I
500/500
500/500

Time
0.77s
3.4s

Table 4: Average test time of different methods and tasks on
MovieLens 1M.

Method
CF-NADE
CF-UIcA
CF-UIcA

Task
Rating Prediction
Rating Prediction
Top-N Recommendation

Test Time
0.68s
0.80s
0.73s

Case) all orderings that reverse the chronological order of
each user’s behaviors. The results are shown in Table 2. We
can observe that the orderings signiﬁcantly affect the perfor-
mance. Compared to the result (NDCG@10 0.406) of Ignore
case where all UUCs and IICs are captured, our best result
brings a 0.09 improvment, demonstrating the effectiveness
of the orderings and the power of the co-autoregression.

4.3 Visualization
In MovieLens 1M, each movie is marked with one or
more genres. There are totally 18 different genres includ-
ing Action, Children’s, Drama, etc. We visualize the learned
weight matrices VI in Sec. 4.1. Speciﬁcally, once the model
:,j,: can be viewed as H I × K dimensional vec-
is learned, VI
tors associated with item j. We apply t-SNE (Maaten and
Hinton 2008) to embed these vectors into a 2-dimensional
plane. Fig. 6 shows the t-SNE embedding of two most exclu-
sive genres: Children’s and Documentary. We can observe
the learned vectors are distributed semantically in the gross.

4.4 Running Time and Memory
We analyze the running time and memory cost of the pro-
posed method. All the experiments are conducted on a single
Nvidia TITAN X GPU with Theano (Theano Development
Team 2016) codes. As explained in Sec. 4, the minibatch
sizes of users and items are not deterministic during training
and thus there is no standard way to train CF-UIcA epoch
by epoch. We report the average training time for each mini-
batch in Table 3. As for testing time, we compare CF-UIcA
with other state-of-the-art methods in Table 4.

The running memory cost of CF-UIcA is mainly for sav-
ing the 3-dimensional weight tensors. Speciﬁcally, the mem-
ory complexity of CF-UIcA is O((N H U + M H I )K). In
our experiments we always let H U = H I = H, resulting
the memory cost is proportional to (N + M )HK.

5 Conclusion
We propose CF-UIcA, a neural co-autoregressive model for
collaborative ﬁltering, with a scalable stochastic learning
algorithm. CF-UIcA performs autoregression in both users
and items domains, making it able to capture both correla-
tions between users and items explicitly and simultaneously.

Figure 6:
MovieLens 1M.

t-SNE embedding of the learned vectors for

He et al. 2017) evaluation: The latest rated item of each user
is held out as the test set; The second latest rated item of
each user is choosen as the validation set and the remain-
ing data are used as the training set. At test time, we adopt
the common strategy (Koren 2008; Elkahky, Song, and He
2015) that randomly samples 100 items that are not rated by
the user, and ask the algorithm to rank the test item among
the 100 sampled items. We evaluate the quality of the ranked
list for the user by computing the Hit Ratio (HR) and the
Normalized Discounted Cumulative Gain (NDCG) (He et
al. 2015). Speciﬁcally,

HR =

, NDCG =

#hits
#users

1
#users

#hits
(cid:88)

i=1

1
log2(pi +1)

,

(13)

where #hits is the number of users whose test item appears
in the recommended list and pi is the position of the test item
in the list for the i-th hit. For both metrics, the ranked list is
truncated at 10.

Since the model is always asked to make predictions of
latest behaviors based on former behaviors, we train the
model under the expectation over orderings that maintain
the chronological order of each user’s behaviors, as anyl-
ized in Sec. 3.1. An important difﬁculty of CF with implicit
feedback is that only positive signals are observed. To han-
dle the absence of negative signals, we follow the common
strategy (Pan et al. 2008; He et al. 2017) that randomly sam-
ples negative instances from unobserved entries dynamically
during the training procedure.

The minibatch sizes of users and items are set to 200. The
hidden dimensions are H U = H I = 256 and the weight
decay is 1 × 10−5. the results are averaged over 5 runs
with different random seeds, with standard deviations less
than 0.0005. Table 2 compares the results in HR@10 and
NDCG@10 with state-of-the-art methods for top-N recom-
mendation with implicit feedback on MovieLens 1M. The
baseline results are provided by He et al. (2017), except the
result of CDAE (Wu et al. 2016), which is evaluated with our
implementation. We can see that CF-UIcA achieves the best
performance under both measures. Importantly, our method
gives an NDCG@10 0.492, which outperforms the state-of-
the-art method NeuMF by a large margin 0.045 (relative
improvement 10.1%). To demonstrate the signiﬁcance of
the co-autoregression, we train another two CF-UIcA mod-
els under the expectation over: (Uniform Case) all possi-
ble orderings, which cover all UUCs and IICs; and (Inverse

Experiments show that our method achieves state-of-the-art
results, and is able to learn semantic information by visual-
ization, verifying that the autoregression provides a princi-
pled way to incorporate the correlations.

Acknowledgments
This work is supported by the National NSF of China (Nos.
61620106010, 61621136008, 61332007), the MIIT Grant
of Int. Man. Comp. Stan (No. 2016ZXFB00001) and the
NVIDIA NVAIL Program.

References
Bahdanau, D.; Cho, K.; and Bengio, Y. 2014. Neural machine
translation by jointly learning to align and translate. arXiv preprint
arXiv:1409.0473.
Bennett, J., and Lanning, S. 2007. The netﬂix prize. In Proceedings
of KDD cup and workshop, volume 2007, 35.
Billsus, D., and Pazzani, M. J. 1998. Learning collaborative infor-
mation ﬁlters. In ICML, volume 98, 46–54.
Bottou, L. 2010. Large-scale machine learning with stochastic
gradient descent. In Proceedings of COMPSTAT’2010. Springer.
177–186.
Burke, R. 2002. Hybrid recommender systems: Survey and exper-
iments. User modeling and user-adapted interaction 12(4):331–
370.
Dziugaite, G. K., and Roy, D. M. 2015. Neural network matrix
factorization. arXiv preprint arXiv:1511.06443.
Elkahky, A. M.; Song, Y.; and He, X. 2015. A multi-view deep
learning approach for cross domain user modeling in recommen-
dation systems. In WWW, 278–288.
Frey, B. J. 1998. Graphical models for machine learning and
digital communication.
Gopalan, P. K.; Charlin, L.; and Blei, D. 2014. Content-based
recommendations with poisson factorization. In NIPS.
Graves, A.; Mohamed, A.-r.; and Hinton, G. 2013. Speech recog-
nition with deep recurrent neural networks. In ICASSP.
Harper, F. M., and Konstan, J. A. 2016. The movielens datasets:
History and context. ACM Transactions on Interactive Intelligent
Systems (TiiS) 5(4):19.
He, X.; Chen, T.; Kan, M.-Y.; and Chen, X. 2015. Trirank: Review-
aware explainable recommendation by modeling aspects. In CIKM.
He, X.; Zhang, H.; Kan, M.-Y.; and Chua, T.-S. 2016. Fast matrix
factorization for online recommendation with implicit feedback. In
SIGIR, 549–558.
He, X.; Liao, L.; Zhang, H.; Nie, L.; Hu, X.; and Chua, T.-S. 2017.
Neural collaborative ﬁltering. In WWW.
Juan, Y.-C.; Chin, W.-S.; Zhuang, Y.; Yuan, B.-W.; Yang, M.-Y.;
and Lin, C.-J. 2016. Libmf: A matrix-factorization library for
recommender systems. https://www.csie.ntu.edu.tw/
˜cjlin/libmf/.
Kingma, D., and Ba, J. 2014. Adam: A method for stochastic
optimization. arXiv preprint arXiv:1412.6980.
Koren, Y.; Bell, R.; and Volinsky, C. 2009. Matrix factorization
techniques for recommender systems. Computer (8):30–37.
Koren, Y. 2008. Factorization meets the neighborhood: a multi-
faceted collaborative ﬁltering model. In SIGKDD.
Krizhevsky, A.; Sutskever, I.; and Hinton, G. E. 2012. Imagenet
classiﬁcation with deep convolutional neural networks. In NIPS.

2017.
JMLR

Larochelle, H., and Murray, I. 2011. The neural autoregressive
distribution estimator. In AISTATS.
Lauly, S.; Zheng, Y.; Allauzen, A.; and Larochelle, H.
Document neural autoregressive distribution estimation.
18(113):1–24.
Lee, J.; Kim, S.; Lebanon, G.; and Singer, Y. 2013. Local low-rank
matrix approximation. In ICML, 82–90.
Maaten, L. v. d., and Hinton, G. 2008. Visualizing data using t-sne.
JMLR 9:2579–2605.
Mnih, V.; Kavukcuoglu, K.; Silver, D.; Rusu, A. A.; Veness, J.;
Bellemare, M. G.; Graves, A.; Riedmiller, M.; Fidjeland, A. K.;
Ostrovski, G.; et al. 2015. Human-level control through deep rein-
forcement learning. Nature 518(7540):529–533.
Pan, R.; Zhou, Y.; Cao, B.; Liu, N. N.; Lukose, R.; Scholz, M.; and
Yang, Q. 2008. One-class collaborative ﬁltering. In ICDM.
Rendle, S.; Freudenthaler, C.; Gantner, Z.; and Schmidt-Thieme, L.
2009. Bpr: Bayesian personalized ranking from implicit feedback.
In UAI, 452–461.
Resnick, P.; Iacovou, N.; Suchak, M.; Bergstrom, P.; and Riedl, J.
1994. Grouplens: an open architecture for collaborative ﬁltering of
netnews. In Proceedings of the 1994 ACM conference on Computer
supported cooperative work, 175–186. ACM.
Salakhutdinov, R., and Mnih, A. 2007. Probabilistic matrix factor-
ization. In NIPS.
Salakhutdinov, R., and Mnih, A. 2008. Bayesian probabilistic ma-
trix factorization using markov chain monte carlo. In ICML.
Salakhutdinov, R.; Mnih, A.; and Hinton, G. 2007. Restricted
boltzmann machines for collaborative ﬁltering. In ICML.
Sarwar, B.; Karypis, G.; Konstan, J.; and Riedl, J. 2000. Applica-
tion of dimensionality reduction in recommender system – a case
study. In ACM WEBKDD WORKSHOP.
Sarwar, B.; Karypis, G.; Konstan, J.; and Riedl, J. 2001. Item-based
collaborative ﬁltering recommendation algorithms. In WWW.
Schafer, J. B.; Frankowski, D.; Herlocker, J.; and Sen, S. 2007.
Collaborative ﬁltering recommender systems. In The adaptive web.
Springer. 291–324.
Sedhain, S.; Menon, A. K.; Sanner, S.; and Xie, L. 2015. Autorec:
Autoencoders meet collaborative ﬁltering. In WWW.
Silver, D.; Huang, A.; Maddison, C. J.; Guez, A.; Sifre, L.; Van
Den Driessche, G.; Schrittwieser, J.; Antonoglou, I.; Panneershel-
vam, V.; Lanctot, M.; et al. 2016. Mastering the game of go with
deep neural networks and tree search. Nature 529(7587):484–489.
Theano Development Team. 2016. Theano: A Python framework
for fast computation of mathematical expressions. arXiv preprint
arXiv:1605.02688.
Van den Oord, A.; Dieleman, S.; and Schrauwen, B. 2013. Deep
content-based music recommendation. In NIPS.
Wang, J.; De Vries, A. P.; and Reinders, M. J. 2006. Unifying user-
based and item-based collaborative ﬁltering approaches by similar-
ity fusion. In SIGIR, 501–508.
Wu, Y.; DuBois, C.; Zheng, A. X.; and Ester, M. 2016. Collabo-
rative denoising auto-encoders for top-n recommender systems. In
WSDM, 153–162.
Zheng, Y.; Liu, C.; Tang, B.; and Zhou, H. 2016a. Neural au-
toregressive collaborative ﬁltering for implicit feedback. In Pro-
ceedings of the 1st Workshop on Deep Learning for Recommender
Systems, 2–6. ACM.
Zheng, Y.; Tang, B.; Ding, W.; and Zhou, H. 2016b. A neural
autoregressive approach to collaborative ﬁltering. In ICML.

Collaborative Filtering with User-Item Co-Autoregressive Models

Chao Du† Chongxuan Li† Yin Zheng‡

Jun Zhu∗† Bo Zhang†

†Dept. of Comp. Sci. & Tech., State Key Lab of Intell. Tech. & Sys., TNList Lab,
†Center for Bio-Inspired Computing Research, Tsinghua University, Beijing, 100084, China
‡Tencent AI Lab, Shenzhen, Guangdong, China

8
1
0
2
 
l
u
J
 
5
 
 
]

G
L
.
s
c
[
 
 
3
v
6
4
1
7
0
.
2
1
6
1
:
v
i
X
r
a

Abstract

Deep neural networks have shown promise in collaborative
ﬁltering (CF). However, existing neural approaches are either
user-based or item-based, which cannot leverage all the un-
derlying information explicitly. We propose CF-UIcA, a neu-
ral co-autoregressive model for CF tasks, which exploits the
structural correlation in the domains of both users and items.
The co-autoregression allows extra desired properties to be
incorporated for different tasks. Furthermore, we develop an
efﬁcient stochastic learning algorithm to handle large scale
datasets. We evaluate CF-UIcA on two popular benchmarks:
MovieLens 1M and Netﬂix, and achieve state-of-the-art per-
formance in both rating prediction and top-N recommenda-
tion tasks, which demonstrates the effectiveness of CF-UIcA.

1

Introduction

With the fast development of electronic commerce, so-
cial networks and music/movie content providers, recom-
mendation systems have attracted extensive research atten-
tion (Burke 2002; Schafer et al. 2007). As one of the most
popular methods, collaborative ﬁltering (CF) (Schafer et
al. 2007; Billsus and Pazzani 1998; Resnick et al. 1994;
Salakhutdinov, Mnih, and Hinton 2007) predicts users’ pref-
erences for items based on their previous behaviors (rat-
ing/clicking/purchasing etc.) in a recommendation system.
CF enjoys the beneﬁt of content-independence of the items
being recommended. Thus, it does not need expert knowl-
edge about the items when compared with content-based
methods (Van den Oord, Dieleman, and Schrauwen 2013;
Gopalan, Charlin, and Blei 2014) and could possibly pro-
vide cross-domain recommendations.

The basic assumption behind CF is that there exist corre-
lations between the observed user behaviors, and these cor-
relations can be generalized to their future behaviors. Ba-
sically, the correlations can be categorized as User-User
Correlations (UUCs)—the correlations between different
users’ behaviors on a same item, and Item-Item Correla-
tions (IICs)—the correlations between a user’s behaviors on
different items. These two types of underlying correlations
usually exist crisscrossing in the partially observed user be-
haviors, making CF a difﬁcult task.

∗corresponding author.

Copyright c(cid:13) 2018, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

Extensive work has studied how to effectively exploit the
underlying correlations to make accurate predictions. Early
approaches (Resnick et al. 1994; Sarwar et al. 2001) con-
sider UUCs or IICs by computing the similarities between
users or items. As one of the most popular classes of CF
methods, matrix factorization (MF) (Billsus and Pazzani
1998; Koren, Bell, and Volinsky 2009; Salakhutdinov and
Mnih 2007) assumes that the partially observed matrix (of
ratings) is low-rank and embeds both users and items into a
shared latent space. MF methods consider both UUCs and
IICs implicitly as a prediction is simply the inner product
of the latent vectors of the corresponding user and item.
Recently, deep learning methods have achieved promising
results in various tasks (Bahdanau, Cho, and Bengio 2014;
Mnih et al. 2015; Silver et al. 2016) due to their ability to
learn a rich set of abstract representations. Inspired by these
advances, neural networks based CF methods (Salakhutdi-
nov, Mnih, and Hinton 2007; Sedhain et al. 2015; Wu et
al. 2016; Zheng et al. 2016b), which employ highly ﬂexi-
ble transformations to model a user’s behavior proﬁle (all
behaviors) with a compact representation, are widely stud-
ied as alternatives to MF. These methods essentially consider
all UUCs explicitly as they take inputs of users’ all observed
behaviors. (See more details in Sec. 2.)

Though previous neural networks based methods are
promising, one common drawback of these methods lies in
that they cannot exploit both UUCs and IICs together, mak-
ing them further improvable. To this end, we propose a novel
neural autoregressive model for CF, named User-Item co-
Autoregressive model (CF-UIcA), which considers the au-
toregression in the domains of both users and items, so as
to model both UUCs and IICs together. The introduced co-
autoregression naturally provides a principled way to select
the UUCs and IICs to be generalized that are helpful for
prediction. This allows us to incorporate extra desired prop-
erties into the model for different tasks, which is not stud-
ied in previous work. We further develop a stochastic learn-
ing algorithm for CF-UIcA to make it applicable for large
datasets. We demonstrate our method on two real bench-
marks: MovieLens 1M and Netﬂix, achieving state-of-the-
art results in both rating prediction and top-N recommenda-
tion tasks, which is rarely accomplished in previous work.
In addition, the visualization demonstrates that CF-UIcA
learns semantic patterns without extra supervision.

(a)

(b)

(c)

(d)

Figure 1: Illustration of predictions in a toy recommendation system with 5 users and 6 items (best viewed in color). Each square
in green/yellow/gray corresponds to a positive/negative/unobserved behavior, respectively. The behavior (whose associating
user and item are colored in deep blue) being predicted is marked with a question mark. (a) Predict with a single User-User
Correlation: the behavior is predicted according to the behavior of another user (labeled as light blue); (b) Predict with a single
Item-Item Correlation; (c) Predict with multiple User-User Correlations, and (d) Predict with multiple Item-Item Correlations.

2 Related Work

Collaborative ﬁltering methods make predictions based on
user behaviors, which could reveal certain patterns for gen-
eralization. These phenomena involve two types of informa-
tion: User-User Correlations (UUCs) and Item-Item Cor-
relations (IICs). As shown in Fig. 1a, UUC depicts that a
user’s behavior is usually related to the one of some other
users on the same item, especially when they have similar
habits/tastes. Similarly, IIC depicts that a user’s behavior on
an item is related to his/her behaviors on other items, es-
pecially when these items are similar in nature, as shown in
Fig. 1b. Predictions are then possible to be made by integrat-
ing these correlations. Fig. 1c and Fig. 1d show all the UUCs
and IICs of the unknown preference marked by the question
mark. Intuitively, integrating multiple UUCs and IICs can
potentially lead to a more precise prediction.

Existing CF methods either implicitly or explicitly exploit
these correlations. Early methods model the correlations via
some similarity functions on the raw preferences, such as k-
NN collaborative ﬁltering (kNN-CF) (Resnick et al. 1994;
Sarwar et al. 2001). These methods make predictions with
the top k UUCs or IICs explicitly. Matrix factorization (MF)
methods characterize both users and items by vectors in
a low-dimensional latent space. The predictions are mod-
eled with the inner products of the latent vectors of the cor-
responding users and items. Representative works include
SVD-based methods (Billsus and Pazzani 1998; Sarwar et
al. 2000) and the probabilistic MF (PMF) (Salakhutdinov
and Mnih 2007; 2008). Recent approaches improve MF by
loosing the constrains of linearity and low-rank assumption.
Bias MF (Koren, Bell, and Volinsky 2009) introduces bias
terms associated with users and items. Lee et al. (2013) pro-
pose Local Low-Rank Matrix Approximation (LLORMA)
by assuming the observed rating matrix is a weighted sum
of low-rank matrices. NNMF (Dziugaite and Roy 2015) and
NeuMF (He et al. 2017) replace the inner product operations
in MF with neural networks. Since MF methods make pre-
dictions with the learned latent vectors of the users and the
items, the UUCs and IICs are not modeled explicitly.

With the success in many tasks (Krizhevsky, Sutskever,
and Hinton 2012; Graves, Mohamed, and Hinton 2013;

Bahdanau, Cho, and Bengio 2014; Mnih et al. 2015; Silver et
al. 2016), deep learning has been integrated into CF methods
with great success. Salakhutdinov, Mnih, and Hinton (2007)
propose RBM-CF, a CF methods based on Restricted Boltz-
mann Machines, which has shown its power in Netﬂix prize
challenge (Bennett and Lanning 2007). Sedhain et al. (2015)
propose AutoRec, a discriminative model based on auto-
encoders. A similar model known as CDAE is concurrently
proposed by Wu et al. (2016). Recently, Zheng et al. (2016b)
propose CF-NADE, a tractable model based on Neural Au-
toregressive Distribution Estimators (NADE) (Larochelle
and Murray 2011), and achieve the state-of-the-art results on
several CF benchmarks. These methods share two aspects:
1) different models are built for different users by sharing
parameters; and 2) predictions are made for a user according
to his/her behavior proﬁle. Note that as the role of users and
items are exchangeable, these methods usually have a user-
based and an item-based variants. As a result, these methods
make predictions with either the UUCs or the IICs explicitly.
Our CF-UIcA differs from existing CF methods in that
it can capture both UUCs and IICs explicitly and simulta-
neously. Similar as in CF-NADE, we adopt neural autore-
gressive architectures to model the probabilities of the be-
haviors. The crucial difference is that CF-NADE models
the rating vectors of each user, making the users indepen-
dent from each other, while CF-UIcA models the behaviors
across all users and items in order to consider UUCs and
IICs jointly. Moreover, we analyze the signiﬁcance of the
co-autoregression in a novel perspective and demonstrate its
effectiveness, which is another step beyond CF-NADE.

Hybrid recommendation (Burke 2002) is a class of meth-
ods focusing on combining different techniques at a high
level, e.g., combining CF-based methods and content-based
methods together. Different with the existing hybrid recom-
mendation methods, our model focuses on utilizing both
user-based and item-based information. Wang, De Vries,
and Reinders (2006) share similar motivation with ours.
However, their method is memory-based and uniﬁes user-
based and item-based models by similarity. While our
method is model-based and combines user-based and item-
based information by autoregressive neural networks.

Figure 2: An illustration of the conditional model. The yellow, green and gray entries are interpreted same as in Fig. 1. Suppose
Rot is the current behavior being modeled. The black striped lines mark the entries of Ro>t. The blue dashed boxes line
out the UUCs and IICs for Rot. The cuboids represent the columns of WU , WI , VU , VI , with the color corresponding to
the behaviors. The hidden representations hU and hI are computed by summing over the corresponding columns (with the
uncorresponding columns marked in lighter colors) of UUCs and IICs. The activations sU and sI are computed by multiplying
the hidden representations and the corresponding columns of VU and VI . We omit the bias terms for clarity.

3 Method
We now present CF-UIcA which models both UUCs and
IICs with co-autoregressvie architectures.

Let N and M denote the number of users and items,
respectively. We deﬁne the behavior matrix R ∈ RN ×M
from user behaviors by assigning entries of R with differ-
ent labels for different behaviors: For explicit feedback, e.g.
K-star scale ratings, we deﬁne Ri,j = k for the behavior
“user i rates item j with k stars”; For implicit feedback, e.g.
clicks, we deﬁne Ri,j = 1 for the behavior “user i clicks
item j”. And we deﬁne Ri,j = 0 for unobserved entries. Let
D = {Rid,jd}D
d=1 be all the observed behaviors, which form
the training set. The goal of CF is then to predict an unknown
behavior Ri∗,j∗ (cid:54)∈ D based on the observed behaviors D.

3.1 The Model
Autoregressive models (Frey 1998; Larochelle and Murray
2011; Lauly et al. 2017) offer a natural way to introduce in-
terdependencies, which is desired for CF tasks, as analyzed
in Sec. 2. We start with a very generic autoregressive as-
sumption to model the probability of the behavior matrix:

p(R) =

p(Rot |Ro<t ),

(1)

N ×M
(cid:89)

t=1

where o is a permutation of all (cid:104)user, item(cid:105) pairs that serves
as an ordering of all the entries in the behavior matrix R,
and Ro<t denotes the ﬁrst t − 1 entries of R indexed by o.
For example, ot = (i(cid:48), j(cid:48)) indicates that the behavior Ri(cid:48),j(cid:48)
is at the t-th position in o, i.e., Rot = Ri(cid:48),j(cid:48). Let oi
t = i(cid:48) and
oj
t = j(cid:48) denote the ﬁrst and second dimension of ot, which
index the user and the item, respectively.

Basically, there are (N ×M )! possible orderings of all the
entries of R. For now we assume that o is ﬁxed. (We will
discuss the orderings latter.) If we consider o as the order-
ing of the timestamps of the behaviors observed by the sys-
tem, then the conditional in Eqn. (1) means that the model
predicts behavior Rot at time t depends on all the observed
behaviors before t.

The Conditional Model According to Sec. 2, both UUCs
and IICs are informative for prediction. We therefore deﬁne
a conditional model that exploits both UUCs and IICs:

p(Rot |Ro<t ) = p(Rot |RU U C

ot

),

, RIIC
ot
: t(cid:48) < t, oj

(2)

where we have deﬁned RU U C
oj
t } as the behaviors on item oj
UUCs of Rot (by time t). RIIC
ot

ot

= {Rot(cid:48)

t(cid:48) =
t in Ro<t , which form all the
is deﬁned symmetrically.

Inspired by NADE (Larochelle and Murray 2011) and CF-
NADE (Zheng et al. 2016b), we model the conditional in
Eqn. (2) with neural networks due to the rich expressive abil-
ity. Speciﬁcally, CF-UIcA models the UUCs and IICs of Rot
with hidden representations respectively:

hU (RU U C

ot

) = f

hI (RIIC

ot

) = f

(cid:16) (cid:88)

(cid:16) (cid:88)

t(cid:48)<t:oj

t(cid:48) =oj

t

t(cid:48)<t:oi

t(cid:48) =oi

t

WU

:,oi

t(cid:48) ,Ro

t(cid:48)

WI

:,oj

t(cid:48) ,Ro

t(cid:48)

,

+ cU (cid:17)
+ cI (cid:17)
,

(3)

(4)

where f (·) is a nonlinear function, such as tanh(x) =
exp(x)−exp(−x)
exp(x)+exp(−x) , WU ∈ RHU ×N ×K and WI ∈ RHI ×M ×K
are 3-order tensors, cU ∈ RHU and cI ∈ RHI are the
bias terms. HU and HI are the dimensions of the hidden
representations for UUCs and IICs, respectively. The col-
umn WI
:,j,k denotes how much “behaving k on item j” con-
tributes to the hidden representations of the IICs while the
column WU
:,i,k denotes the contribution of “user i behaves
k” to the hidden representation of the UUCs.

CF-UIcA explains the hidden representations of the

UUCs and the IICs by computing the activations:

t,k(hU (RU U C
sU
oi
sI
t ,k(hI (RIIC
oj

ot

ot

)) = VU

)) = VI

:,oi

t,k

:,oj

t ,k

(cid:62)hU (RU U C

ot
(cid:62)hI (RIIC

ot

) + bU
t,k,
oi
) + bI
t ,k,
oj

(5)

(6)

where VU ∈ RHU ×N ×K and VI ∈ RHI ×M ×K are 3-order
tensors, bU ∈ RN ×K and bI ∈ RM ×K are the bias terms.
The column VI
:,j,k is the coefﬁcients that determine how the
hidden representation of the IICs affects the activation sI

j,k

for “behaving k on item j”. Higher activation sI
j,k indicates
that the considered IICs suggest higher probability that the
user will carry out a behavior k on item j. The activation sU
i,k
is interpreted similarly.

Finally, to combine the activations of UUCs and IICs of
Rot and produce a probability distribution, we deﬁne the ﬁ-
nal conditional model as a softmax function of the summa-
tion of the two activations:

p(Rot = k|Ro<t ) =

(cid:16)

exp

(cid:17)

sU
t,k + sI
oj
oi
t ,k
(cid:18)
t,k(cid:48) + sI
oj
t ,k(cid:48)

sU
oi

(cid:80)K

k(cid:48)=1 exp

(cid:19) .

(7)

Fig. 2 illustrates the conditional model.

i(cid:48),j(cid:48) and RIIC

Orderings in Different Tasks We now discuss the effect
of different orderings on the model and show what kinds of
orderings are considered for two major CF tasks detailedly.
In fact, the ordering o decides the conditional model for
each observed behavior Ri(cid:48),j(cid:48). Speciﬁcally, according to our
model (See Eqns. (2) to (4)), the contributions of UUCs and
IICs to a given behavior Ri(cid:48),j(cid:48), i.e. RU U C
i(cid:48),j(cid:48) , depend
on where the ordering o places Ri(cid:48),j(cid:48) and what o places be-
fore Ri(cid:48),j(cid:48). In general, different orderings result in different
conditional models or dependency relations (see Fig. 3 for
an illustration) and any possible conditional models can be
induced by some speciﬁc orderings. Such a property leaves
us freedom to control what kind of dependencies we would
like the model to exploit in different tasks, as shown below.
CF methods are usually evaluated on rating prediction
tasks (Zheng et al. 2016b; Sedhain et al. 2015), or more
generally, matrix completion tasks, by predicting randomly
missing ratings/values. For matrix completion tasks, taking
all UUCs and IICs into consideration leads the model to
exploit the underlying correlations to a maximum extent.
Therefore, we should consider all possible conditional mod-
els for each behavior, i.e., all orderings, in such tasks. The
objective could then be deﬁned as the expected (over all or-
derings) negative log-likelihood (NLL) of the training set:

L(θ) = E

− log p(D|θ, o)

o∈SD

= − E

o∈SD

(cid:88) D

d=1 log p(Rod |Ro<d , θ, o),

(8)

where θ denotes all the model parameters and SD is the set
of all the permutations of D1. Note that taking the expecta-
tion over all orderings is equivalent to integrating them out.
Thus the training procedure does not depend on any partic-
ular ordering and no manually chosen ordering is needed.

Recent works (Rendle et al. 2009; He et al. 2017) also
evaluate CF on top-N recommendation tasks, aiming to sug-
gest a short list of future preferences for each user, which is
closer to the goal of real-world recommendation systems. In
these tasks, not all IICs are useful. For example, people who
have just watched Harry Potter 1 (HP1) are very likely to be
interested in Harry Potter 2 (HP2), however those who have
just watched HP2 are less likely to have interest in HP1, as
he/she may have known some spoiler about HP1. To this

1Given the training set D, the ﬁrst D elements of o will be au-
tomatically restricted to D. As we only evaluate the likelihood of
the training set D, the number of equivalence orderings are D!.

(a)

(b)

(c)

Figure 3: An illustration of how the orderings decide the
conditional models. Colors are interpreted same as in Fig. 2.
(a) - (c) show 3 conditional models for the central (gray)
behavior in an example behavior matrix under 3 different
orderings. The numbers 1 - 9 indicate the indices of the cor-
responding behaviors in the orderings. The arrows indicate
the dependencies involved in the conditional models.

end, we should expect the model to capture the chronolog-
ical IICs, which only include the dependencies from later
behaviors to previous behaviors of each user, and all UUCs
in the meanwhile. Then, an appropriate objective should be
the expected NLL of the training set over all orderings that
do not break the chronological order of each user’s behav-
iors. Note that this can be implemented equivalently by re-
deﬁning RIIC
i(cid:48),j(cid:48) = {Ri(cid:48),j(cid:48)(cid:48) : T (Ri(cid:48),j(cid:48)(cid:48) ) < T (Ri(cid:48),j(cid:48))}, where
T (·) is the timestamp when the system observes the behav-
ior, and using Eqn. (8) as the objective2. Hence we still need
not to choose any ordering manually.

The above examples show that extra desired properties
can be incorporated into CF-UIcA for different tasks by con-
sidering different orderings in the objective, which indeed
beneﬁts from the co-autoregressive assumption.

3.2 Learning
The remaining challenge is to optimize the objective in
Eqn. (8). A common strategy to deal with complicate in-
tegrations or large-scale datasets is to adopt stochastic
optimization approaches, e.g. stochastic gradient descent
(SGD) (Bottou 2010; Kingma and Ba 2014), which require
an unbiased estimator of the objective or its gradient. SGD
and its variants have been widely adopted in various areas
due to its efﬁciency, including many CF methods (Sedhain
et al. 2015; Zheng et al. 2016b). However, unlike in the most
existing neural networks based methods (Wu et al. 2016;
Zheng et al. 2016b), the users are not modeled indepen-
dently in CF-UIcA, resulting the objective cannot be esti-
mated stochastically by simply sub-sampling the users. To
tackle this challenge, we derive an unbiased estimator of
Eqn. (8) below, which completes the proposed method.

By exchanging the order of the expectation and the sum-

mation in Eqn. (8) and doing some simple math, we get:

L(θ) = −

(cid:88)

(i(cid:48),j(cid:48))∈D

E
d

E
o∈SD |od=(i(cid:48),j(cid:48))

log p(Ri(cid:48),j(cid:48) |Ro<d ,θ,o).

(9)

According to the deﬁnition of the conditional model from
Eqns. (3) to (7), the log-probability of Ri(cid:48),j(cid:48) in Eqn. (9) de-
pends on at most Ri(cid:48),¬j(cid:48) = Ri(cid:48),:\{Ri(cid:48),j(cid:48)} (behaviors of user

2In this case RIIC

i(cid:48),j(cid:48) is deterministic and only RU U C

i(cid:48),j(cid:48) depends on

the ordering o.

i(cid:48),j(cid:48) = Ri(cid:48),¬j(cid:48) ∩Ro<d and the set RU U C

i(cid:48) except Ri(cid:48),j(cid:48)) and R¬i(cid:48),j(cid:48) = R:,j(cid:48)\{Ri(cid:48),j(cid:48)} (behaviors
on item j(cid:48) except Ri(cid:48),j(cid:48)). Speciﬁcally, given od = (i(cid:48), j(cid:48)),
the log-probability of Ri(cid:48),j(cid:48) depends on exactly the set
RIIC
i(cid:48),j(cid:48) = R¬i(cid:48),j(cid:48) ∩Ro<d.
As we treat the ordering o as a random variable uniformly
distributed over SD, RIIC
are also random.
i(cid:48),j(cid:48) = ∅, they are indepen-
Moreover, since RIIC
dent given their sizes m = |RIIC
i(cid:48),j(cid:48) | and n = |RU U C
i(cid:48),j(cid:48) |, i.e.,
RIIC
i(cid:48),j(cid:48) |n. By expanding the second expectation
in Eqn. (9) based on the above analysis, we have:

i(cid:48),j(cid:48) |m ⊥ RU U C

i(cid:48),j(cid:48) and RU U C
i(cid:48),j(cid:48)

i(cid:48),j(cid:48) ∩ RU U C

N
(cid:88)

M
(cid:88)

L(θ) = −

E
d

E
m,n|d

i(cid:48)=1

j(cid:48)=1
log p(Ri(cid:48),j(cid:48) |RU U C

i(cid:48),j(cid:48) , RIIC

E
RU U C
i(cid:48) ,j(cid:48) |n

E
RIIC
i(cid:48) ,j(cid:48) |m
i(cid:48),j(cid:48) , θ)I[(i(cid:48),j(cid:48))∈D],

(10)

i(cid:48),j(cid:48) |m and RU U C

where m, n, RIIC
i(cid:48),j(cid:48) |n are all random and are
decided by the random ordering o. Note the summation over
D is replaced by an equivalent representation using an indi-
cator function I[(i(cid:48),j(cid:48))∈D]. Given RU U C
i(cid:48),j(cid:48) , the log-
probability term and the indicator term can be computed eas-
ily. From now we omit these two terms for simplicity.

i(cid:48),j(cid:48) and RIIC

According to symmetry, it is easy to know that RIIC

i(cid:48),j(cid:48) |m
and RU U C
i(cid:48),j(cid:48) |n are uniformly distributed over all subsets of
size m of R¬i(cid:48),j(cid:48) ∩D and subsets of size n of Ri(cid:48),¬j(cid:48) ∩D, re-
spectively. However, these distributions have different sup-
ports since the numbers of the observed behaviors for users
(items) are different, which makes the sampling unparal-
lelizable. Note that the process of drawing o from SD can
be equivalently simulated by ﬁrst randomly drawing σ from
SN ×M , which can be viewed as an ordering of all the en-
tries of R, and then dropping the unobserved entries R\D.
The resulted ordering on D is still uniformly distributed over
SD. Then Eqn. (10) can be written equivalently as:

L(θ) = −

N
(cid:88)

M
(cid:88)

i(cid:48)=1

j(cid:48)=1

E
r

E
y,z|r

E
M⊆[M ]\{j(cid:48)}|y

E
N⊆[N ]\{i(cid:48)}|z

,

(11)

where r is the index of Ri(cid:48),j(cid:48) in σ, y and z are the number of
entries in Ri(cid:48),¬j(cid:48) ∩ Rσ<r and R¬i(cid:48),j(cid:48) ∩ Rσ<r , respectively.
M is a subset of size y of [M ]\{j(cid:48)} and N is a subset of
size z of [N ]\{i(cid:48)}, where [N ] denotes {1, · · · , N }. RU U C
i(cid:48),j(cid:48)
and RIIC

i(cid:48),j(cid:48) are therefore RN ,j(cid:48) ∩ D, Ri(cid:48),M ∩ D.

Finally, with some simple math we obtain:

L(θ) = −N M E
r

E
y,z|r

E
M⊆[M ]|y

E
N⊆[N ]|z

E
i(cid:48)∈[N ]\N

E
j(cid:48)∈[M ]\M

. (12)

In Eqn. (12), y and z can be computed after sampling r and
σ. M and N are sampled by uniformly choosing y and z
elements in [M ] and [N ] without replacement, respectively.
The last two expectations can be estimated unbiasedly by
sampling BU elements from [N ]\N and BI elements from
[M ]\M, respectively, where BU and BI can be viewed as
the minibatch sizes of users and items. Finally, we get an
unbiased estimation of the objective L(θ), which can be then
adopted in SGD algorithms.

Note that though the training objective involves expecta-
tions over multiple orderings (which help exploit the desired
UUCs and IICs during training), the prediction procedure is

Figure 4: The performance
on MovieLens 1M of CF-
UIcA and CF-NADE w.r.t.
the number of hidden units.

Figure 5: The performance
on Netﬂix of CF-UIcA
w.r.t. the number clusters of
users.

simple and deterministic. For an unknown behavior Ri∗,j∗ ,
the prediction is evaluated with ˆRi∗,j∗ = Ep(Ri∗ ,j∗ =k|D)[k]
with RU U C
i∗,j∗ = Ri∗,¬j∗ ∩ D,
where we have assumed Ri∗,j∗ = RoD+1 and Ro<D+1 = D.

i∗,j∗ = R¬i∗,j∗ ∩ D and RIIC

4 Experiments
We now present a series of experimental results of the pro-
posed CF-UIcA to demonstrate its effectiveness. We com-
pare CF-UIcA with other popular CF methods on two major
kinds of CF tasks: rating prediction and top-N recommenda-
tion. The experiments are conducted on two representative
datasets: MovieLens 1M (Harper and Konstan 2016) and
Netﬂix (Bennett and Lanning 2007). MovieLens 1M con-
sists of 1, 000, 209 ratings of 3, 952 movies (items) rated
by 6, 040 users. Netﬂix consists of 100, 480, 507 ratings
of 17, 770 movies rated by 480, 189 users. The ratings in
both datasets are 1-5 stars scale, i.e., K = 5. For all ex-
periments, we use Adam (Kingma and Ba 2014) to opti-
mize the objectives with an initial learning rate 0.001. Dur-
ing training, we anneal the learning rate by factor 0.25 un-
til no signiﬁcant improvement can be observed on valida-
tion set. Note that in Eqn. (12) the sizes of [N ]\N and
[M ]\M, i.e. N − z and M − y, vary from 1 to N − 1
and to M − 1, respectively. As a consequence, the mini-
batch sizes of users/items should be set dynamically. Nev-
ertheless, we choose ﬁxed minibatch sizes of users/items
BU /BI , which only take effect when M − y > BI or
N − z > BU . We adopt weight decay on model parameters
to prevent the model from overﬁtting. Other hyper parame-
ters and detailed experimental settings will be speciﬁed lat-
ter for each task. The codes and more detailed settings can be
found at https://github.com/thu-ml/CF-UIcA.

4.1 Rating Prediction
We use the same experimental settings with LLORMA (Lee
et al. 2013), AutoRec (Sedhain et al. 2015) and CF-
NADE (Zheng et al. 2016b). We randomly select 90%
of the ratings in each of the datasets as the training set,
leaving the remaining 10% of the ratings as the test set.
Among the ratings in the training set, 5% are hold out
for validation. We compare the predictive performance with
other state-of-the-art methods in terms of the common used
Root Mean Squared Error (RMSE) = ((cid:80)
(i,j)∈Dtest( ˆRi,j −
Ri,j)2/Dtest)1/2, where Dtest is the test set of Dtest unknown
ratings, Ri,j is the true rating and ˆRi,j is the prediction. The

Table 1: Test RMSE on MovieLens 1M and Netﬂix. All the
baseline results are taken from Zheng et al. (2016b).

Table 2: Test HR@10 and NDCG@10 of various methods
on MovieLens 1M. The results of baseline methods (except
CDAE) are kindly provided by He et al. (2017).

Method
PMF
U-RBM
U-AutoRec
LLORMA-Global
I-RBM
BiasMF
U-CF-NADE-S (2 layers)
NNMF
LLORMA-Local
I-AutoRec
I-CF-NADE-S (2 layers)
CF-UIcA (H U=H I=500)

MovieLens 1M Netﬂix

0.883
0.881
0.874
0.865
0.854
0.845
0.845
0.843
0.833
0.831
0.829

-
0.845
-
0.874
-
0.844
0.803
-
0.834
0.823
-

0.823

0.799

reported results are averaged over 10 random splits, with
standard deviations less than 0.0002.

MovieLens 1M For experiments on MovieLens 1M, we
set BU /BI to 1, 000/1, 000 and the weight decay to 0.0001.
Since CF-UIcA has a connection with CF-NADE (Zheng
et al. 2016b) as mentioned in Sec. 2, we ﬁrst present a com-
parison between CF-UIcA and CF-NADE in Fig. 4. CF-
NADE models each user with a latent representation, sim-
ilar with our hidden representation of UUCs or IICs. For
fairness, we compare the two methods with the same num-
ber of hidden units, where in our CF-UIcA the number of
hidden units is H U+H I . Note that in CF-UIcA H U is not
necessarily equal to H I , we nevertheless choose H U =H I
for simplicity. We report the item-based CF-NADE results
under best setting as described in (Zheng et al. 2016b).

From Fig. 4 we observe that for small number of hidden
units, e.g. 250, our method gives a worse result than CF-
NADE. This is attributed to that the hidden dimensions allo-
cated to the hidden representation of UUCs and IICs are too
small (H U =H I =125) to capture the underlying informa-
tion. As the number of hidden units increases, we observe
CF-UIcA outperforms CF-NADE since CF-UIcA can cap-
ture both UUCs and IICs while the item-based CF-NADE
can only capture UUCs. One thing worth mentioning is that
the total number of parameters in CF-UIcA is only around
83% of the number of parameters in CF-NADE for Movie-
Lens 1M when the number of hidden units are same, which
implies that CF-UIcA can capture more information than
CF-NADE with fewer parameters.

Table 1 (middle column) compares the performance of
CF-UIcA with state-of-the-art methods on MovieLens 1M.
The hidden dimensions of CF-UIcA are H U = H I = 500.
Our method achieves an RMSE of 0.823, outperforming all
the existing strong baselines. Note that as RMSE scores have
been highly optimized in previous work, our 0.006 RMSE
improvement w.r.t. CF-NADE is quite signiﬁcant, compared
to the 0.002 by which CF-NADE improves over AutoRec
and 0.002 by which AutoRec improves over LLORMA.

Netﬂix The Netﬂix dataset is much bigger than Movie-
Lens 1M, especially the number of users. We opt to clus-

HR@10 NDCG@10

Method
ItemPop
ItemKNN
BPR (Rendle et al. 2009)
eALS (He et al. 2016)
NeuMF
CDAE

CF-UIcA (Uniform)
CF-UIcA (Inverse)
CF-UIcA

0.454
0.623
0.690
0.704
0.730
0.726

0.692
0.616
0.736

0.254
0.359
0.419
0.433
0.447
0.448

0.406
0.353
0.492

ter all the 480, 189 users into 10K, 15K and 20K groups,
respectively, and make the users in same clusters sharing
their corresponding columns in WU and VU . To cluster
the users, we ﬁrst run matrix factorization (Juan et al. 2016)
with rank 100 on the training set. (Predicting the test set with
the learned vectors by MF gives an RMSE of 0.865.) Then
the clustering process is simply done by running a K-means
clustering algorithm on the latent vectors of users learned by
MF. For CF-UIcA, the weight decay is set to 5 × 10−6 as the
dataset is sufﬁciently large. The minibacth sizes of users and
items are set to BU = 4, 000 and BI = 1, 000. The hidden
dimensions are H U = H I = 500.

Fig. 5 shows the performance of CF-UIcA with different
number of clusters. We observe that the performance im-
proves as the number of clusters increases, which can be
attributed to that using more clusters empowers the model
to capture more variety among users. Another observation is
that the performance can be potentially improved by further
increasing the number of clusters. We do not increase the
number of clusters due to the limitation of GPU memory.

Table 1 (right column) summarizes our best result and
other state-of-the-art results. Symbol “-” indicates that the
authors didn’t report the result, probably due to the lack
of scalability3. Our method with 20, 000 clusters of users
achieves a state-of-the-art RMSE of 0.799, which, together
with the results on MovieLens 1M, proves that our CF-UIcA
has the ability to predict users’ ratings precisely.

4.2 Top-N Recommendation
In most real scenarios, the goal of recommendation sys-
tems is to suggest a top-N ranked list of items that are
supposed to be appealing for each user. Moreover, implicit
feedback (Zheng et al. 2016a) has attracted increasing in-
terests because it is usually collected automatically and is
thus much more easier to obtain. We follow the exper-
imental settings of NeuMF (He et al. 2017) to test the
recommendation quality of CF-UIcA with implicit feed-
back. We transform MovieLens 1M into implicit data by
marking all ratings as 1 indicating that the user has rated
the item. We adopt the leave-one-out (Rendle et al. 2009;

3We conﬁrmed with the authors of (Zheng et al. 2016b) that
I-CF-NADE is not scalable to Netﬂix. For AutoRec, the authors
reported that I-AutoRec is their best model.

Table 3: Average running time for each minibatch of CF-
UIcA on different datasets.

BU /BI

Dataset
ML 1M 1, 000/1, 000
4, 000/1, 000
Netﬂix

H U /H I
500/500
500/500

Time
0.77s
3.4s

Table 4: Average test time of different methods and tasks on
MovieLens 1M.

Method
CF-NADE
CF-UIcA
CF-UIcA

Task
Rating Prediction
Rating Prediction
Top-N Recommendation

Test Time
0.68s
0.80s
0.73s

Case) all orderings that reverse the chronological order of
each user’s behaviors. The results are shown in Table 2. We
can observe that the orderings signiﬁcantly affect the perfor-
mance. Compared to the result (NDCG@10 0.406) of Ignore
case where all UUCs and IICs are captured, our best result
brings a 0.09 improvment, demonstrating the effectiveness
of the orderings and the power of the co-autoregression.

4.3 Visualization
In MovieLens 1M, each movie is marked with one or
more genres. There are totally 18 different genres includ-
ing Action, Children’s, Drama, etc. We visualize the learned
weight matrices VI in Sec. 4.1. Speciﬁcally, once the model
:,j,: can be viewed as H I × K dimensional vec-
is learned, VI
tors associated with item j. We apply t-SNE (Maaten and
Hinton 2008) to embed these vectors into a 2-dimensional
plane. Fig. 6 shows the t-SNE embedding of two most exclu-
sive genres: Children’s and Documentary. We can observe
the learned vectors are distributed semantically in the gross.

4.4 Running Time and Memory
We analyze the running time and memory cost of the pro-
posed method. All the experiments are conducted on a single
Nvidia TITAN X GPU with Theano (Theano Development
Team 2016) codes. As explained in Sec. 4, the minibatch
sizes of users and items are not deterministic during training
and thus there is no standard way to train CF-UIcA epoch
by epoch. We report the average training time for each mini-
batch in Table 3. As for testing time, we compare CF-UIcA
with other state-of-the-art methods in Table 4.

The running memory cost of CF-UIcA is mainly for sav-
ing the 3-dimensional weight tensors. Speciﬁcally, the mem-
ory complexity of CF-UIcA is O((N H U + M H I )K). In
our experiments we always let H U = H I = H, resulting
the memory cost is proportional to (N + M )HK.

5 Conclusion
We propose CF-UIcA, a neural co-autoregressive model for
collaborative ﬁltering, with a scalable stochastic learning
algorithm. CF-UIcA performs autoregression in both users
and items domains, making it able to capture both correla-
tions between users and items explicitly and simultaneously.

Figure 6:
MovieLens 1M.

t-SNE embedding of the learned vectors for

He et al. 2017) evaluation: The latest rated item of each user
is held out as the test set; The second latest rated item of
each user is choosen as the validation set and the remain-
ing data are used as the training set. At test time, we adopt
the common strategy (Koren 2008; Elkahky, Song, and He
2015) that randomly samples 100 items that are not rated by
the user, and ask the algorithm to rank the test item among
the 100 sampled items. We evaluate the quality of the ranked
list for the user by computing the Hit Ratio (HR) and the
Normalized Discounted Cumulative Gain (NDCG) (He et
al. 2015). Speciﬁcally,

HR =

, NDCG =

#hits
#users

1
#users

#hits
(cid:88)

i=1

1
log2(pi +1)

,

(13)

where #hits is the number of users whose test item appears
in the recommended list and pi is the position of the test item
in the list for the i-th hit. For both metrics, the ranked list is
truncated at 10.

Since the model is always asked to make predictions of
latest behaviors based on former behaviors, we train the
model under the expectation over orderings that maintain
the chronological order of each user’s behaviors, as anyl-
ized in Sec. 3.1. An important difﬁculty of CF with implicit
feedback is that only positive signals are observed. To han-
dle the absence of negative signals, we follow the common
strategy (Pan et al. 2008; He et al. 2017) that randomly sam-
ples negative instances from unobserved entries dynamically
during the training procedure.

The minibatch sizes of users and items are set to 200. The
hidden dimensions are H U = H I = 256 and the weight
decay is 1 × 10−5. the results are averaged over 5 runs
with different random seeds, with standard deviations less
than 0.0005. Table 2 compares the results in HR@10 and
NDCG@10 with state-of-the-art methods for top-N recom-
mendation with implicit feedback on MovieLens 1M. The
baseline results are provided by He et al. (2017), except the
result of CDAE (Wu et al. 2016), which is evaluated with our
implementation. We can see that CF-UIcA achieves the best
performance under both measures. Importantly, our method
gives an NDCG@10 0.492, which outperforms the state-of-
the-art method NeuMF by a large margin 0.045 (relative
improvement 10.1%). To demonstrate the signiﬁcance of
the co-autoregression, we train another two CF-UIcA mod-
els under the expectation over: (Uniform Case) all possi-
ble orderings, which cover all UUCs and IICs; and (Inverse

Experiments show that our method achieves state-of-the-art
results, and is able to learn semantic information by visual-
ization, verifying that the autoregression provides a princi-
pled way to incorporate the correlations.

Acknowledgments
This work is supported by the National NSF of China (Nos.
61620106010, 61621136008, 61332007), the MIIT Grant
of Int. Man. Comp. Stan (No. 2016ZXFB00001) and the
NVIDIA NVAIL Program.

References
Bahdanau, D.; Cho, K.; and Bengio, Y. 2014. Neural machine
translation by jointly learning to align and translate. arXiv preprint
arXiv:1409.0473.
Bennett, J., and Lanning, S. 2007. The netﬂix prize. In Proceedings
of KDD cup and workshop, volume 2007, 35.
Billsus, D., and Pazzani, M. J. 1998. Learning collaborative infor-
mation ﬁlters. In ICML, volume 98, 46–54.
Bottou, L. 2010. Large-scale machine learning with stochastic
gradient descent. In Proceedings of COMPSTAT’2010. Springer.
177–186.
Burke, R. 2002. Hybrid recommender systems: Survey and exper-
iments. User modeling and user-adapted interaction 12(4):331–
370.
Dziugaite, G. K., and Roy, D. M. 2015. Neural network matrix
factorization. arXiv preprint arXiv:1511.06443.
Elkahky, A. M.; Song, Y.; and He, X. 2015. A multi-view deep
learning approach for cross domain user modeling in recommen-
dation systems. In WWW, 278–288.
Frey, B. J. 1998. Graphical models for machine learning and
digital communication.
Gopalan, P. K.; Charlin, L.; and Blei, D. 2014. Content-based
recommendations with poisson factorization. In NIPS.
Graves, A.; Mohamed, A.-r.; and Hinton, G. 2013. Speech recog-
nition with deep recurrent neural networks. In ICASSP.
Harper, F. M., and Konstan, J. A. 2016. The movielens datasets:
History and context. ACM Transactions on Interactive Intelligent
Systems (TiiS) 5(4):19.
He, X.; Chen, T.; Kan, M.-Y.; and Chen, X. 2015. Trirank: Review-
aware explainable recommendation by modeling aspects. In CIKM.
He, X.; Zhang, H.; Kan, M.-Y.; and Chua, T.-S. 2016. Fast matrix
factorization for online recommendation with implicit feedback. In
SIGIR, 549–558.
He, X.; Liao, L.; Zhang, H.; Nie, L.; Hu, X.; and Chua, T.-S. 2017.
Neural collaborative ﬁltering. In WWW.
Juan, Y.-C.; Chin, W.-S.; Zhuang, Y.; Yuan, B.-W.; Yang, M.-Y.;
and Lin, C.-J. 2016. Libmf: A matrix-factorization library for
recommender systems. https://www.csie.ntu.edu.tw/
˜cjlin/libmf/.
Kingma, D., and Ba, J. 2014. Adam: A method for stochastic
optimization. arXiv preprint arXiv:1412.6980.
Koren, Y.; Bell, R.; and Volinsky, C. 2009. Matrix factorization
techniques for recommender systems. Computer (8):30–37.
Koren, Y. 2008. Factorization meets the neighborhood: a multi-
faceted collaborative ﬁltering model. In SIGKDD.
Krizhevsky, A.; Sutskever, I.; and Hinton, G. E. 2012. Imagenet
classiﬁcation with deep convolutional neural networks. In NIPS.

2017.
JMLR

Larochelle, H., and Murray, I. 2011. The neural autoregressive
distribution estimator. In AISTATS.
Lauly, S.; Zheng, Y.; Allauzen, A.; and Larochelle, H.
Document neural autoregressive distribution estimation.
18(113):1–24.
Lee, J.; Kim, S.; Lebanon, G.; and Singer, Y. 2013. Local low-rank
matrix approximation. In ICML, 82–90.
Maaten, L. v. d., and Hinton, G. 2008. Visualizing data using t-sne.
JMLR 9:2579–2605.
Mnih, V.; Kavukcuoglu, K.; Silver, D.; Rusu, A. A.; Veness, J.;
Bellemare, M. G.; Graves, A.; Riedmiller, M.; Fidjeland, A. K.;
Ostrovski, G.; et al. 2015. Human-level control through deep rein-
forcement learning. Nature 518(7540):529–533.
Pan, R.; Zhou, Y.; Cao, B.; Liu, N. N.; Lukose, R.; Scholz, M.; and
Yang, Q. 2008. One-class collaborative ﬁltering. In ICDM.
Rendle, S.; Freudenthaler, C.; Gantner, Z.; and Schmidt-Thieme, L.
2009. Bpr: Bayesian personalized ranking from implicit feedback.
In UAI, 452–461.
Resnick, P.; Iacovou, N.; Suchak, M.; Bergstrom, P.; and Riedl, J.
1994. Grouplens: an open architecture for collaborative ﬁltering of
netnews. In Proceedings of the 1994 ACM conference on Computer
supported cooperative work, 175–186. ACM.
Salakhutdinov, R., and Mnih, A. 2007. Probabilistic matrix factor-
ization. In NIPS.
Salakhutdinov, R., and Mnih, A. 2008. Bayesian probabilistic ma-
trix factorization using markov chain monte carlo. In ICML.
Salakhutdinov, R.; Mnih, A.; and Hinton, G. 2007. Restricted
boltzmann machines for collaborative ﬁltering. In ICML.
Sarwar, B.; Karypis, G.; Konstan, J.; and Riedl, J. 2000. Applica-
tion of dimensionality reduction in recommender system – a case
study. In ACM WEBKDD WORKSHOP.
Sarwar, B.; Karypis, G.; Konstan, J.; and Riedl, J. 2001. Item-based
collaborative ﬁltering recommendation algorithms. In WWW.
Schafer, J. B.; Frankowski, D.; Herlocker, J.; and Sen, S. 2007.
Collaborative ﬁltering recommender systems. In The adaptive web.
Springer. 291–324.
Sedhain, S.; Menon, A. K.; Sanner, S.; and Xie, L. 2015. Autorec:
Autoencoders meet collaborative ﬁltering. In WWW.
Silver, D.; Huang, A.; Maddison, C. J.; Guez, A.; Sifre, L.; Van
Den Driessche, G.; Schrittwieser, J.; Antonoglou, I.; Panneershel-
vam, V.; Lanctot, M.; et al. 2016. Mastering the game of go with
deep neural networks and tree search. Nature 529(7587):484–489.
Theano Development Team. 2016. Theano: A Python framework
for fast computation of mathematical expressions. arXiv preprint
arXiv:1605.02688.
Van den Oord, A.; Dieleman, S.; and Schrauwen, B. 2013. Deep
content-based music recommendation. In NIPS.
Wang, J.; De Vries, A. P.; and Reinders, M. J. 2006. Unifying user-
based and item-based collaborative ﬁltering approaches by similar-
ity fusion. In SIGIR, 501–508.
Wu, Y.; DuBois, C.; Zheng, A. X.; and Ester, M. 2016. Collabo-
rative denoising auto-encoders for top-n recommender systems. In
WSDM, 153–162.
Zheng, Y.; Liu, C.; Tang, B.; and Zhou, H. 2016a. Neural au-
toregressive collaborative ﬁltering for implicit feedback. In Pro-
ceedings of the 1st Workshop on Deep Learning for Recommender
Systems, 2–6. ACM.
Zheng, Y.; Tang, B.; Ding, W.; and Zhou, H. 2016b. A neural
autoregressive approach to collaborative ﬁltering. In ICML.

Collaborative Filtering with User-Item Co-Autoregressive Models

Chao Du† Chongxuan Li† Yin Zheng‡

Jun Zhu∗† Bo Zhang†

†Dept. of Comp. Sci. & Tech., State Key Lab of Intell. Tech. & Sys., TNList Lab,
†Center for Bio-Inspired Computing Research, Tsinghua University, Beijing, 100084, China
‡Tencent AI Lab, Shenzhen, Guangdong, China

8
1
0
2
 
l
u
J
 
5
 
 
]

G
L
.
s
c
[
 
 
3
v
6
4
1
7
0
.
2
1
6
1
:
v
i
X
r
a

Abstract

Deep neural networks have shown promise in collaborative
ﬁltering (CF). However, existing neural approaches are either
user-based or item-based, which cannot leverage all the un-
derlying information explicitly. We propose CF-UIcA, a neu-
ral co-autoregressive model for CF tasks, which exploits the
structural correlation in the domains of both users and items.
The co-autoregression allows extra desired properties to be
incorporated for different tasks. Furthermore, we develop an
efﬁcient stochastic learning algorithm to handle large scale
datasets. We evaluate CF-UIcA on two popular benchmarks:
MovieLens 1M and Netﬂix, and achieve state-of-the-art per-
formance in both rating prediction and top-N recommenda-
tion tasks, which demonstrates the effectiveness of CF-UIcA.

1

Introduction

With the fast development of electronic commerce, so-
cial networks and music/movie content providers, recom-
mendation systems have attracted extensive research atten-
tion (Burke 2002; Schafer et al. 2007). As one of the most
popular methods, collaborative ﬁltering (CF) (Schafer et
al. 2007; Billsus and Pazzani 1998; Resnick et al. 1994;
Salakhutdinov, Mnih, and Hinton 2007) predicts users’ pref-
erences for items based on their previous behaviors (rat-
ing/clicking/purchasing etc.) in a recommendation system.
CF enjoys the beneﬁt of content-independence of the items
being recommended. Thus, it does not need expert knowl-
edge about the items when compared with content-based
methods (Van den Oord, Dieleman, and Schrauwen 2013;
Gopalan, Charlin, and Blei 2014) and could possibly pro-
vide cross-domain recommendations.

The basic assumption behind CF is that there exist corre-
lations between the observed user behaviors, and these cor-
relations can be generalized to their future behaviors. Ba-
sically, the correlations can be categorized as User-User
Correlations (UUCs)—the correlations between different
users’ behaviors on a same item, and Item-Item Correla-
tions (IICs)—the correlations between a user’s behaviors on
different items. These two types of underlying correlations
usually exist crisscrossing in the partially observed user be-
haviors, making CF a difﬁcult task.

∗corresponding author.

Copyright c(cid:13) 2018, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

Extensive work has studied how to effectively exploit the
underlying correlations to make accurate predictions. Early
approaches (Resnick et al. 1994; Sarwar et al. 2001) con-
sider UUCs or IICs by computing the similarities between
users or items. As one of the most popular classes of CF
methods, matrix factorization (MF) (Billsus and Pazzani
1998; Koren, Bell, and Volinsky 2009; Salakhutdinov and
Mnih 2007) assumes that the partially observed matrix (of
ratings) is low-rank and embeds both users and items into a
shared latent space. MF methods consider both UUCs and
IICs implicitly as a prediction is simply the inner product
of the latent vectors of the corresponding user and item.
Recently, deep learning methods have achieved promising
results in various tasks (Bahdanau, Cho, and Bengio 2014;
Mnih et al. 2015; Silver et al. 2016) due to their ability to
learn a rich set of abstract representations. Inspired by these
advances, neural networks based CF methods (Salakhutdi-
nov, Mnih, and Hinton 2007; Sedhain et al. 2015; Wu et
al. 2016; Zheng et al. 2016b), which employ highly ﬂexi-
ble transformations to model a user’s behavior proﬁle (all
behaviors) with a compact representation, are widely stud-
ied as alternatives to MF. These methods essentially consider
all UUCs explicitly as they take inputs of users’ all observed
behaviors. (See more details in Sec. 2.)

Though previous neural networks based methods are
promising, one common drawback of these methods lies in
that they cannot exploit both UUCs and IICs together, mak-
ing them further improvable. To this end, we propose a novel
neural autoregressive model for CF, named User-Item co-
Autoregressive model (CF-UIcA), which considers the au-
toregression in the domains of both users and items, so as
to model both UUCs and IICs together. The introduced co-
autoregression naturally provides a principled way to select
the UUCs and IICs to be generalized that are helpful for
prediction. This allows us to incorporate extra desired prop-
erties into the model for different tasks, which is not stud-
ied in previous work. We further develop a stochastic learn-
ing algorithm for CF-UIcA to make it applicable for large
datasets. We demonstrate our method on two real bench-
marks: MovieLens 1M and Netﬂix, achieving state-of-the-
art results in both rating prediction and top-N recommenda-
tion tasks, which is rarely accomplished in previous work.
In addition, the visualization demonstrates that CF-UIcA
learns semantic patterns without extra supervision.

(a)

(b)

(c)

(d)

Figure 1: Illustration of predictions in a toy recommendation system with 5 users and 6 items (best viewed in color). Each square
in green/yellow/gray corresponds to a positive/negative/unobserved behavior, respectively. The behavior (whose associating
user and item are colored in deep blue) being predicted is marked with a question mark. (a) Predict with a single User-User
Correlation: the behavior is predicted according to the behavior of another user (labeled as light blue); (b) Predict with a single
Item-Item Correlation; (c) Predict with multiple User-User Correlations, and (d) Predict with multiple Item-Item Correlations.

2 Related Work

Collaborative ﬁltering methods make predictions based on
user behaviors, which could reveal certain patterns for gen-
eralization. These phenomena involve two types of informa-
tion: User-User Correlations (UUCs) and Item-Item Cor-
relations (IICs). As shown in Fig. 1a, UUC depicts that a
user’s behavior is usually related to the one of some other
users on the same item, especially when they have similar
habits/tastes. Similarly, IIC depicts that a user’s behavior on
an item is related to his/her behaviors on other items, es-
pecially when these items are similar in nature, as shown in
Fig. 1b. Predictions are then possible to be made by integrat-
ing these correlations. Fig. 1c and Fig. 1d show all the UUCs
and IICs of the unknown preference marked by the question
mark. Intuitively, integrating multiple UUCs and IICs can
potentially lead to a more precise prediction.

Existing CF methods either implicitly or explicitly exploit
these correlations. Early methods model the correlations via
some similarity functions on the raw preferences, such as k-
NN collaborative ﬁltering (kNN-CF) (Resnick et al. 1994;
Sarwar et al. 2001). These methods make predictions with
the top k UUCs or IICs explicitly. Matrix factorization (MF)
methods characterize both users and items by vectors in
a low-dimensional latent space. The predictions are mod-
eled with the inner products of the latent vectors of the cor-
responding users and items. Representative works include
SVD-based methods (Billsus and Pazzani 1998; Sarwar et
al. 2000) and the probabilistic MF (PMF) (Salakhutdinov
and Mnih 2007; 2008). Recent approaches improve MF by
loosing the constrains of linearity and low-rank assumption.
Bias MF (Koren, Bell, and Volinsky 2009) introduces bias
terms associated with users and items. Lee et al. (2013) pro-
pose Local Low-Rank Matrix Approximation (LLORMA)
by assuming the observed rating matrix is a weighted sum
of low-rank matrices. NNMF (Dziugaite and Roy 2015) and
NeuMF (He et al. 2017) replace the inner product operations
in MF with neural networks. Since MF methods make pre-
dictions with the learned latent vectors of the users and the
items, the UUCs and IICs are not modeled explicitly.

With the success in many tasks (Krizhevsky, Sutskever,
and Hinton 2012; Graves, Mohamed, and Hinton 2013;

Bahdanau, Cho, and Bengio 2014; Mnih et al. 2015; Silver et
al. 2016), deep learning has been integrated into CF methods
with great success. Salakhutdinov, Mnih, and Hinton (2007)
propose RBM-CF, a CF methods based on Restricted Boltz-
mann Machines, which has shown its power in Netﬂix prize
challenge (Bennett and Lanning 2007). Sedhain et al. (2015)
propose AutoRec, a discriminative model based on auto-
encoders. A similar model known as CDAE is concurrently
proposed by Wu et al. (2016). Recently, Zheng et al. (2016b)
propose CF-NADE, a tractable model based on Neural Au-
toregressive Distribution Estimators (NADE) (Larochelle
and Murray 2011), and achieve the state-of-the-art results on
several CF benchmarks. These methods share two aspects:
1) different models are built for different users by sharing
parameters; and 2) predictions are made for a user according
to his/her behavior proﬁle. Note that as the role of users and
items are exchangeable, these methods usually have a user-
based and an item-based variants. As a result, these methods
make predictions with either the UUCs or the IICs explicitly.
Our CF-UIcA differs from existing CF methods in that
it can capture both UUCs and IICs explicitly and simulta-
neously. Similar as in CF-NADE, we adopt neural autore-
gressive architectures to model the probabilities of the be-
haviors. The crucial difference is that CF-NADE models
the rating vectors of each user, making the users indepen-
dent from each other, while CF-UIcA models the behaviors
across all users and items in order to consider UUCs and
IICs jointly. Moreover, we analyze the signiﬁcance of the
co-autoregression in a novel perspective and demonstrate its
effectiveness, which is another step beyond CF-NADE.

Hybrid recommendation (Burke 2002) is a class of meth-
ods focusing on combining different techniques at a high
level, e.g., combining CF-based methods and content-based
methods together. Different with the existing hybrid recom-
mendation methods, our model focuses on utilizing both
user-based and item-based information. Wang, De Vries,
and Reinders (2006) share similar motivation with ours.
However, their method is memory-based and uniﬁes user-
based and item-based models by similarity. While our
method is model-based and combines user-based and item-
based information by autoregressive neural networks.

Figure 2: An illustration of the conditional model. The yellow, green and gray entries are interpreted same as in Fig. 1. Suppose
Rot is the current behavior being modeled. The black striped lines mark the entries of Ro>t. The blue dashed boxes line
out the UUCs and IICs for Rot. The cuboids represent the columns of WU , WI , VU , VI , with the color corresponding to
the behaviors. The hidden representations hU and hI are computed by summing over the corresponding columns (with the
uncorresponding columns marked in lighter colors) of UUCs and IICs. The activations sU and sI are computed by multiplying
the hidden representations and the corresponding columns of VU and VI . We omit the bias terms for clarity.

3 Method
We now present CF-UIcA which models both UUCs and
IICs with co-autoregressvie architectures.

Let N and M denote the number of users and items,
respectively. We deﬁne the behavior matrix R ∈ RN ×M
from user behaviors by assigning entries of R with differ-
ent labels for different behaviors: For explicit feedback, e.g.
K-star scale ratings, we deﬁne Ri,j = k for the behavior
“user i rates item j with k stars”; For implicit feedback, e.g.
clicks, we deﬁne Ri,j = 1 for the behavior “user i clicks
item j”. And we deﬁne Ri,j = 0 for unobserved entries. Let
D = {Rid,jd}D
d=1 be all the observed behaviors, which form
the training set. The goal of CF is then to predict an unknown
behavior Ri∗,j∗ (cid:54)∈ D based on the observed behaviors D.

3.1 The Model
Autoregressive models (Frey 1998; Larochelle and Murray
2011; Lauly et al. 2017) offer a natural way to introduce in-
terdependencies, which is desired for CF tasks, as analyzed
in Sec. 2. We start with a very generic autoregressive as-
sumption to model the probability of the behavior matrix:

p(R) =

p(Rot |Ro<t ),

(1)

N ×M
(cid:89)

t=1

where o is a permutation of all (cid:104)user, item(cid:105) pairs that serves
as an ordering of all the entries in the behavior matrix R,
and Ro<t denotes the ﬁrst t − 1 entries of R indexed by o.
For example, ot = (i(cid:48), j(cid:48)) indicates that the behavior Ri(cid:48),j(cid:48)
is at the t-th position in o, i.e., Rot = Ri(cid:48),j(cid:48). Let oi
t = i(cid:48) and
oj
t = j(cid:48) denote the ﬁrst and second dimension of ot, which
index the user and the item, respectively.

Basically, there are (N ×M )! possible orderings of all the
entries of R. For now we assume that o is ﬁxed. (We will
discuss the orderings latter.) If we consider o as the order-
ing of the timestamps of the behaviors observed by the sys-
tem, then the conditional in Eqn. (1) means that the model
predicts behavior Rot at time t depends on all the observed
behaviors before t.

The Conditional Model According to Sec. 2, both UUCs
and IICs are informative for prediction. We therefore deﬁne
a conditional model that exploits both UUCs and IICs:

p(Rot |Ro<t ) = p(Rot |RU U C

ot

),

, RIIC
ot
: t(cid:48) < t, oj

(2)

where we have deﬁned RU U C
oj
t } as the behaviors on item oj
UUCs of Rot (by time t). RIIC
ot

ot

= {Rot(cid:48)

t(cid:48) =
t in Ro<t , which form all the
is deﬁned symmetrically.

Inspired by NADE (Larochelle and Murray 2011) and CF-
NADE (Zheng et al. 2016b), we model the conditional in
Eqn. (2) with neural networks due to the rich expressive abil-
ity. Speciﬁcally, CF-UIcA models the UUCs and IICs of Rot
with hidden representations respectively:

hU (RU U C

ot

) = f

hI (RIIC

ot

) = f

(cid:16) (cid:88)

(cid:16) (cid:88)

t(cid:48)<t:oj

t(cid:48) =oj

t

t(cid:48)<t:oi

t(cid:48) =oi

t

WU

:,oi

t(cid:48) ,Ro

t(cid:48)

WI

:,oj

t(cid:48) ,Ro

t(cid:48)

,

+ cU (cid:17)
+ cI (cid:17)
,

(3)

(4)

where f (·) is a nonlinear function, such as tanh(x) =
exp(x)−exp(−x)
exp(x)+exp(−x) , WU ∈ RHU ×N ×K and WI ∈ RHI ×M ×K
are 3-order tensors, cU ∈ RHU and cI ∈ RHI are the
bias terms. HU and HI are the dimensions of the hidden
representations for UUCs and IICs, respectively. The col-
umn WI
:,j,k denotes how much “behaving k on item j” con-
tributes to the hidden representations of the IICs while the
column WU
:,i,k denotes the contribution of “user i behaves
k” to the hidden representation of the UUCs.

CF-UIcA explains the hidden representations of the

UUCs and the IICs by computing the activations:

t,k(hU (RU U C
sU
oi
sI
t ,k(hI (RIIC
oj

ot

ot

)) = VU

)) = VI

:,oi

t,k

:,oj

t ,k

(cid:62)hU (RU U C

ot
(cid:62)hI (RIIC

ot

) + bU
t,k,
oi
) + bI
t ,k,
oj

(5)

(6)

where VU ∈ RHU ×N ×K and VI ∈ RHI ×M ×K are 3-order
tensors, bU ∈ RN ×K and bI ∈ RM ×K are the bias terms.
The column VI
:,j,k is the coefﬁcients that determine how the
hidden representation of the IICs affects the activation sI

j,k

for “behaving k on item j”. Higher activation sI
j,k indicates
that the considered IICs suggest higher probability that the
user will carry out a behavior k on item j. The activation sU
i,k
is interpreted similarly.

Finally, to combine the activations of UUCs and IICs of
Rot and produce a probability distribution, we deﬁne the ﬁ-
nal conditional model as a softmax function of the summa-
tion of the two activations:

p(Rot = k|Ro<t ) =

(cid:16)

exp

(cid:17)

sU
t,k + sI
oj
oi
t ,k
(cid:18)
t,k(cid:48) + sI
oj
t ,k(cid:48)

sU
oi

(cid:80)K

k(cid:48)=1 exp

(cid:19) .

(7)

Fig. 2 illustrates the conditional model.

i(cid:48),j(cid:48) and RIIC

Orderings in Different Tasks We now discuss the effect
of different orderings on the model and show what kinds of
orderings are considered for two major CF tasks detailedly.
In fact, the ordering o decides the conditional model for
each observed behavior Ri(cid:48),j(cid:48). Speciﬁcally, according to our
model (See Eqns. (2) to (4)), the contributions of UUCs and
IICs to a given behavior Ri(cid:48),j(cid:48), i.e. RU U C
i(cid:48),j(cid:48) , depend
on where the ordering o places Ri(cid:48),j(cid:48) and what o places be-
fore Ri(cid:48),j(cid:48). In general, different orderings result in different
conditional models or dependency relations (see Fig. 3 for
an illustration) and any possible conditional models can be
induced by some speciﬁc orderings. Such a property leaves
us freedom to control what kind of dependencies we would
like the model to exploit in different tasks, as shown below.
CF methods are usually evaluated on rating prediction
tasks (Zheng et al. 2016b; Sedhain et al. 2015), or more
generally, matrix completion tasks, by predicting randomly
missing ratings/values. For matrix completion tasks, taking
all UUCs and IICs into consideration leads the model to
exploit the underlying correlations to a maximum extent.
Therefore, we should consider all possible conditional mod-
els for each behavior, i.e., all orderings, in such tasks. The
objective could then be deﬁned as the expected (over all or-
derings) negative log-likelihood (NLL) of the training set:

L(θ) = E

− log p(D|θ, o)

o∈SD

= − E

o∈SD

(cid:88) D

d=1 log p(Rod |Ro<d , θ, o),

(8)

where θ denotes all the model parameters and SD is the set
of all the permutations of D1. Note that taking the expecta-
tion over all orderings is equivalent to integrating them out.
Thus the training procedure does not depend on any partic-
ular ordering and no manually chosen ordering is needed.

Recent works (Rendle et al. 2009; He et al. 2017) also
evaluate CF on top-N recommendation tasks, aiming to sug-
gest a short list of future preferences for each user, which is
closer to the goal of real-world recommendation systems. In
these tasks, not all IICs are useful. For example, people who
have just watched Harry Potter 1 (HP1) are very likely to be
interested in Harry Potter 2 (HP2), however those who have
just watched HP2 are less likely to have interest in HP1, as
he/she may have known some spoiler about HP1. To this

1Given the training set D, the ﬁrst D elements of o will be au-
tomatically restricted to D. As we only evaluate the likelihood of
the training set D, the number of equivalence orderings are D!.

(a)

(b)

(c)

Figure 3: An illustration of how the orderings decide the
conditional models. Colors are interpreted same as in Fig. 2.
(a) - (c) show 3 conditional models for the central (gray)
behavior in an example behavior matrix under 3 different
orderings. The numbers 1 - 9 indicate the indices of the cor-
responding behaviors in the orderings. The arrows indicate
the dependencies involved in the conditional models.

end, we should expect the model to capture the chronolog-
ical IICs, which only include the dependencies from later
behaviors to previous behaviors of each user, and all UUCs
in the meanwhile. Then, an appropriate objective should be
the expected NLL of the training set over all orderings that
do not break the chronological order of each user’s behav-
iors. Note that this can be implemented equivalently by re-
deﬁning RIIC
i(cid:48),j(cid:48) = {Ri(cid:48),j(cid:48)(cid:48) : T (Ri(cid:48),j(cid:48)(cid:48) ) < T (Ri(cid:48),j(cid:48))}, where
T (·) is the timestamp when the system observes the behav-
ior, and using Eqn. (8) as the objective2. Hence we still need
not to choose any ordering manually.

The above examples show that extra desired properties
can be incorporated into CF-UIcA for different tasks by con-
sidering different orderings in the objective, which indeed
beneﬁts from the co-autoregressive assumption.

3.2 Learning
The remaining challenge is to optimize the objective in
Eqn. (8). A common strategy to deal with complicate in-
tegrations or large-scale datasets is to adopt stochastic
optimization approaches, e.g. stochastic gradient descent
(SGD) (Bottou 2010; Kingma and Ba 2014), which require
an unbiased estimator of the objective or its gradient. SGD
and its variants have been widely adopted in various areas
due to its efﬁciency, including many CF methods (Sedhain
et al. 2015; Zheng et al. 2016b). However, unlike in the most
existing neural networks based methods (Wu et al. 2016;
Zheng et al. 2016b), the users are not modeled indepen-
dently in CF-UIcA, resulting the objective cannot be esti-
mated stochastically by simply sub-sampling the users. To
tackle this challenge, we derive an unbiased estimator of
Eqn. (8) below, which completes the proposed method.

By exchanging the order of the expectation and the sum-

mation in Eqn. (8) and doing some simple math, we get:

L(θ) = −

(cid:88)

(i(cid:48),j(cid:48))∈D

E
d

E
o∈SD |od=(i(cid:48),j(cid:48))

log p(Ri(cid:48),j(cid:48) |Ro<d ,θ,o).

(9)

According to the deﬁnition of the conditional model from
Eqns. (3) to (7), the log-probability of Ri(cid:48),j(cid:48) in Eqn. (9) de-
pends on at most Ri(cid:48),¬j(cid:48) = Ri(cid:48),:\{Ri(cid:48),j(cid:48)} (behaviors of user

2In this case RIIC

i(cid:48),j(cid:48) is deterministic and only RU U C

i(cid:48),j(cid:48) depends on

the ordering o.

i(cid:48),j(cid:48) = Ri(cid:48),¬j(cid:48) ∩Ro<d and the set RU U C

i(cid:48) except Ri(cid:48),j(cid:48)) and R¬i(cid:48),j(cid:48) = R:,j(cid:48)\{Ri(cid:48),j(cid:48)} (behaviors
on item j(cid:48) except Ri(cid:48),j(cid:48)). Speciﬁcally, given od = (i(cid:48), j(cid:48)),
the log-probability of Ri(cid:48),j(cid:48) depends on exactly the set
RIIC
i(cid:48),j(cid:48) = R¬i(cid:48),j(cid:48) ∩Ro<d.
As we treat the ordering o as a random variable uniformly
distributed over SD, RIIC
are also random.
i(cid:48),j(cid:48) = ∅, they are indepen-
Moreover, since RIIC
dent given their sizes m = |RIIC
i(cid:48),j(cid:48) | and n = |RU U C
i(cid:48),j(cid:48) |, i.e.,
RIIC
i(cid:48),j(cid:48) |n. By expanding the second expectation
in Eqn. (9) based on the above analysis, we have:

i(cid:48),j(cid:48) |m ⊥ RU U C

i(cid:48),j(cid:48) and RU U C
i(cid:48),j(cid:48)

i(cid:48),j(cid:48) ∩ RU U C

N
(cid:88)

M
(cid:88)

L(θ) = −

E
d

E
m,n|d

i(cid:48)=1

j(cid:48)=1
log p(Ri(cid:48),j(cid:48) |RU U C

i(cid:48),j(cid:48) , RIIC

E
RU U C
i(cid:48) ,j(cid:48) |n

E
RIIC
i(cid:48) ,j(cid:48) |m
i(cid:48),j(cid:48) , θ)I[(i(cid:48),j(cid:48))∈D],

(10)

i(cid:48),j(cid:48) |m and RU U C

where m, n, RIIC
i(cid:48),j(cid:48) |n are all random and are
decided by the random ordering o. Note the summation over
D is replaced by an equivalent representation using an indi-
cator function I[(i(cid:48),j(cid:48))∈D]. Given RU U C
i(cid:48),j(cid:48) , the log-
probability term and the indicator term can be computed eas-
ily. From now we omit these two terms for simplicity.

i(cid:48),j(cid:48) and RIIC

According to symmetry, it is easy to know that RIIC

i(cid:48),j(cid:48) |m
and RU U C
i(cid:48),j(cid:48) |n are uniformly distributed over all subsets of
size m of R¬i(cid:48),j(cid:48) ∩D and subsets of size n of Ri(cid:48),¬j(cid:48) ∩D, re-
spectively. However, these distributions have different sup-
ports since the numbers of the observed behaviors for users
(items) are different, which makes the sampling unparal-
lelizable. Note that the process of drawing o from SD can
be equivalently simulated by ﬁrst randomly drawing σ from
SN ×M , which can be viewed as an ordering of all the en-
tries of R, and then dropping the unobserved entries R\D.
The resulted ordering on D is still uniformly distributed over
SD. Then Eqn. (10) can be written equivalently as:

L(θ) = −

N
(cid:88)

M
(cid:88)

i(cid:48)=1

j(cid:48)=1

E
r

E
y,z|r

E
M⊆[M ]\{j(cid:48)}|y

E
N⊆[N ]\{i(cid:48)}|z

,

(11)

where r is the index of Ri(cid:48),j(cid:48) in σ, y and z are the number of
entries in Ri(cid:48),¬j(cid:48) ∩ Rσ<r and R¬i(cid:48),j(cid:48) ∩ Rσ<r , respectively.
M is a subset of size y of [M ]\{j(cid:48)} and N is a subset of
size z of [N ]\{i(cid:48)}, where [N ] denotes {1, · · · , N }. RU U C
i(cid:48),j(cid:48)
and RIIC

i(cid:48),j(cid:48) are therefore RN ,j(cid:48) ∩ D, Ri(cid:48),M ∩ D.

Finally, with some simple math we obtain:

L(θ) = −N M E
r

E
y,z|r

E
M⊆[M ]|y

E
N⊆[N ]|z

E
i(cid:48)∈[N ]\N

E
j(cid:48)∈[M ]\M

. (12)

In Eqn. (12), y and z can be computed after sampling r and
σ. M and N are sampled by uniformly choosing y and z
elements in [M ] and [N ] without replacement, respectively.
The last two expectations can be estimated unbiasedly by
sampling BU elements from [N ]\N and BI elements from
[M ]\M, respectively, where BU and BI can be viewed as
the minibatch sizes of users and items. Finally, we get an
unbiased estimation of the objective L(θ), which can be then
adopted in SGD algorithms.

Note that though the training objective involves expecta-
tions over multiple orderings (which help exploit the desired
UUCs and IICs during training), the prediction procedure is

Figure 4: The performance
on MovieLens 1M of CF-
UIcA and CF-NADE w.r.t.
the number of hidden units.

Figure 5: The performance
on Netﬂix of CF-UIcA
w.r.t. the number clusters of
users.

simple and deterministic. For an unknown behavior Ri∗,j∗ ,
the prediction is evaluated with ˆRi∗,j∗ = Ep(Ri∗ ,j∗ =k|D)[k]
with RU U C
i∗,j∗ = Ri∗,¬j∗ ∩ D,
where we have assumed Ri∗,j∗ = RoD+1 and Ro<D+1 = D.

i∗,j∗ = R¬i∗,j∗ ∩ D and RIIC

4 Experiments
We now present a series of experimental results of the pro-
posed CF-UIcA to demonstrate its effectiveness. We com-
pare CF-UIcA with other popular CF methods on two major
kinds of CF tasks: rating prediction and top-N recommenda-
tion. The experiments are conducted on two representative
datasets: MovieLens 1M (Harper and Konstan 2016) and
Netﬂix (Bennett and Lanning 2007). MovieLens 1M con-
sists of 1, 000, 209 ratings of 3, 952 movies (items) rated
by 6, 040 users. Netﬂix consists of 100, 480, 507 ratings
of 17, 770 movies rated by 480, 189 users. The ratings in
both datasets are 1-5 stars scale, i.e., K = 5. For all ex-
periments, we use Adam (Kingma and Ba 2014) to opti-
mize the objectives with an initial learning rate 0.001. Dur-
ing training, we anneal the learning rate by factor 0.25 un-
til no signiﬁcant improvement can be observed on valida-
tion set. Note that in Eqn. (12) the sizes of [N ]\N and
[M ]\M, i.e. N − z and M − y, vary from 1 to N − 1
and to M − 1, respectively. As a consequence, the mini-
batch sizes of users/items should be set dynamically. Nev-
ertheless, we choose ﬁxed minibatch sizes of users/items
BU /BI , which only take effect when M − y > BI or
N − z > BU . We adopt weight decay on model parameters
to prevent the model from overﬁtting. Other hyper parame-
ters and detailed experimental settings will be speciﬁed lat-
ter for each task. The codes and more detailed settings can be
found at https://github.com/thu-ml/CF-UIcA.

4.1 Rating Prediction
We use the same experimental settings with LLORMA (Lee
et al. 2013), AutoRec (Sedhain et al. 2015) and CF-
NADE (Zheng et al. 2016b). We randomly select 90%
of the ratings in each of the datasets as the training set,
leaving the remaining 10% of the ratings as the test set.
Among the ratings in the training set, 5% are hold out
for validation. We compare the predictive performance with
other state-of-the-art methods in terms of the common used
Root Mean Squared Error (RMSE) = ((cid:80)
(i,j)∈Dtest( ˆRi,j −
Ri,j)2/Dtest)1/2, where Dtest is the test set of Dtest unknown
ratings, Ri,j is the true rating and ˆRi,j is the prediction. The

Table 1: Test RMSE on MovieLens 1M and Netﬂix. All the
baseline results are taken from Zheng et al. (2016b).

Table 2: Test HR@10 and NDCG@10 of various methods
on MovieLens 1M. The results of baseline methods (except
CDAE) are kindly provided by He et al. (2017).

Method
PMF
U-RBM
U-AutoRec
LLORMA-Global
I-RBM
BiasMF
U-CF-NADE-S (2 layers)
NNMF
LLORMA-Local
I-AutoRec
I-CF-NADE-S (2 layers)
CF-UIcA (H U=H I=500)

MovieLens 1M Netﬂix

0.883
0.881
0.874
0.865
0.854
0.845
0.845
0.843
0.833
0.831
0.829

-
0.845
-
0.874
-
0.844
0.803
-
0.834
0.823
-

0.823

0.799

reported results are averaged over 10 random splits, with
standard deviations less than 0.0002.

MovieLens 1M For experiments on MovieLens 1M, we
set BU /BI to 1, 000/1, 000 and the weight decay to 0.0001.
Since CF-UIcA has a connection with CF-NADE (Zheng
et al. 2016b) as mentioned in Sec. 2, we ﬁrst present a com-
parison between CF-UIcA and CF-NADE in Fig. 4. CF-
NADE models each user with a latent representation, sim-
ilar with our hidden representation of UUCs or IICs. For
fairness, we compare the two methods with the same num-
ber of hidden units, where in our CF-UIcA the number of
hidden units is H U+H I . Note that in CF-UIcA H U is not
necessarily equal to H I , we nevertheless choose H U =H I
for simplicity. We report the item-based CF-NADE results
under best setting as described in (Zheng et al. 2016b).

From Fig. 4 we observe that for small number of hidden
units, e.g. 250, our method gives a worse result than CF-
NADE. This is attributed to that the hidden dimensions allo-
cated to the hidden representation of UUCs and IICs are too
small (H U =H I =125) to capture the underlying informa-
tion. As the number of hidden units increases, we observe
CF-UIcA outperforms CF-NADE since CF-UIcA can cap-
ture both UUCs and IICs while the item-based CF-NADE
can only capture UUCs. One thing worth mentioning is that
the total number of parameters in CF-UIcA is only around
83% of the number of parameters in CF-NADE for Movie-
Lens 1M when the number of hidden units are same, which
implies that CF-UIcA can capture more information than
CF-NADE with fewer parameters.

Table 1 (middle column) compares the performance of
CF-UIcA with state-of-the-art methods on MovieLens 1M.
The hidden dimensions of CF-UIcA are H U = H I = 500.
Our method achieves an RMSE of 0.823, outperforming all
the existing strong baselines. Note that as RMSE scores have
been highly optimized in previous work, our 0.006 RMSE
improvement w.r.t. CF-NADE is quite signiﬁcant, compared
to the 0.002 by which CF-NADE improves over AutoRec
and 0.002 by which AutoRec improves over LLORMA.

Netﬂix The Netﬂix dataset is much bigger than Movie-
Lens 1M, especially the number of users. We opt to clus-

HR@10 NDCG@10

Method
ItemPop
ItemKNN
BPR (Rendle et al. 2009)
eALS (He et al. 2016)
NeuMF
CDAE

CF-UIcA (Uniform)
CF-UIcA (Inverse)
CF-UIcA

0.454
0.623
0.690
0.704
0.730
0.726

0.692
0.616
0.736

0.254
0.359
0.419
0.433
0.447
0.448

0.406
0.353
0.492

ter all the 480, 189 users into 10K, 15K and 20K groups,
respectively, and make the users in same clusters sharing
their corresponding columns in WU and VU . To cluster
the users, we ﬁrst run matrix factorization (Juan et al. 2016)
with rank 100 on the training set. (Predicting the test set with
the learned vectors by MF gives an RMSE of 0.865.) Then
the clustering process is simply done by running a K-means
clustering algorithm on the latent vectors of users learned by
MF. For CF-UIcA, the weight decay is set to 5 × 10−6 as the
dataset is sufﬁciently large. The minibacth sizes of users and
items are set to BU = 4, 000 and BI = 1, 000. The hidden
dimensions are H U = H I = 500.

Fig. 5 shows the performance of CF-UIcA with different
number of clusters. We observe that the performance im-
proves as the number of clusters increases, which can be
attributed to that using more clusters empowers the model
to capture more variety among users. Another observation is
that the performance can be potentially improved by further
increasing the number of clusters. We do not increase the
number of clusters due to the limitation of GPU memory.

Table 1 (right column) summarizes our best result and
other state-of-the-art results. Symbol “-” indicates that the
authors didn’t report the result, probably due to the lack
of scalability3. Our method with 20, 000 clusters of users
achieves a state-of-the-art RMSE of 0.799, which, together
with the results on MovieLens 1M, proves that our CF-UIcA
has the ability to predict users’ ratings precisely.

4.2 Top-N Recommendation
In most real scenarios, the goal of recommendation sys-
tems is to suggest a top-N ranked list of items that are
supposed to be appealing for each user. Moreover, implicit
feedback (Zheng et al. 2016a) has attracted increasing in-
terests because it is usually collected automatically and is
thus much more easier to obtain. We follow the exper-
imental settings of NeuMF (He et al. 2017) to test the
recommendation quality of CF-UIcA with implicit feed-
back. We transform MovieLens 1M into implicit data by
marking all ratings as 1 indicating that the user has rated
the item. We adopt the leave-one-out (Rendle et al. 2009;

3We conﬁrmed with the authors of (Zheng et al. 2016b) that
I-CF-NADE is not scalable to Netﬂix. For AutoRec, the authors
reported that I-AutoRec is their best model.

Table 3: Average running time for each minibatch of CF-
UIcA on different datasets.

BU /BI

Dataset
ML 1M 1, 000/1, 000
4, 000/1, 000
Netﬂix

H U /H I
500/500
500/500

Time
0.77s
3.4s

Table 4: Average test time of different methods and tasks on
MovieLens 1M.

Method
CF-NADE
CF-UIcA
CF-UIcA

Task
Rating Prediction
Rating Prediction
Top-N Recommendation

Test Time
0.68s
0.80s
0.73s

Case) all orderings that reverse the chronological order of
each user’s behaviors. The results are shown in Table 2. We
can observe that the orderings signiﬁcantly affect the perfor-
mance. Compared to the result (NDCG@10 0.406) of Ignore
case where all UUCs and IICs are captured, our best result
brings a 0.09 improvment, demonstrating the effectiveness
of the orderings and the power of the co-autoregression.

4.3 Visualization
In MovieLens 1M, each movie is marked with one or
more genres. There are totally 18 different genres includ-
ing Action, Children’s, Drama, etc. We visualize the learned
weight matrices VI in Sec. 4.1. Speciﬁcally, once the model
:,j,: can be viewed as H I × K dimensional vec-
is learned, VI
tors associated with item j. We apply t-SNE (Maaten and
Hinton 2008) to embed these vectors into a 2-dimensional
plane. Fig. 6 shows the t-SNE embedding of two most exclu-
sive genres: Children’s and Documentary. We can observe
the learned vectors are distributed semantically in the gross.

4.4 Running Time and Memory
We analyze the running time and memory cost of the pro-
posed method. All the experiments are conducted on a single
Nvidia TITAN X GPU with Theano (Theano Development
Team 2016) codes. As explained in Sec. 4, the minibatch
sizes of users and items are not deterministic during training
and thus there is no standard way to train CF-UIcA epoch
by epoch. We report the average training time for each mini-
batch in Table 3. As for testing time, we compare CF-UIcA
with other state-of-the-art methods in Table 4.

The running memory cost of CF-UIcA is mainly for sav-
ing the 3-dimensional weight tensors. Speciﬁcally, the mem-
ory complexity of CF-UIcA is O((N H U + M H I )K). In
our experiments we always let H U = H I = H, resulting
the memory cost is proportional to (N + M )HK.

5 Conclusion
We propose CF-UIcA, a neural co-autoregressive model for
collaborative ﬁltering, with a scalable stochastic learning
algorithm. CF-UIcA performs autoregression in both users
and items domains, making it able to capture both correla-
tions between users and items explicitly and simultaneously.

Figure 6:
MovieLens 1M.

t-SNE embedding of the learned vectors for

He et al. 2017) evaluation: The latest rated item of each user
is held out as the test set; The second latest rated item of
each user is choosen as the validation set and the remain-
ing data are used as the training set. At test time, we adopt
the common strategy (Koren 2008; Elkahky, Song, and He
2015) that randomly samples 100 items that are not rated by
the user, and ask the algorithm to rank the test item among
the 100 sampled items. We evaluate the quality of the ranked
list for the user by computing the Hit Ratio (HR) and the
Normalized Discounted Cumulative Gain (NDCG) (He et
al. 2015). Speciﬁcally,

HR =

, NDCG =

#hits
#users

1
#users

#hits
(cid:88)

i=1

1
log2(pi +1)

,

(13)

where #hits is the number of users whose test item appears
in the recommended list and pi is the position of the test item
in the list for the i-th hit. For both metrics, the ranked list is
truncated at 10.

Since the model is always asked to make predictions of
latest behaviors based on former behaviors, we train the
model under the expectation over orderings that maintain
the chronological order of each user’s behaviors, as anyl-
ized in Sec. 3.1. An important difﬁculty of CF with implicit
feedback is that only positive signals are observed. To han-
dle the absence of negative signals, we follow the common
strategy (Pan et al. 2008; He et al. 2017) that randomly sam-
ples negative instances from unobserved entries dynamically
during the training procedure.

The minibatch sizes of users and items are set to 200. The
hidden dimensions are H U = H I = 256 and the weight
decay is 1 × 10−5. the results are averaged over 5 runs
with different random seeds, with standard deviations less
than 0.0005. Table 2 compares the results in HR@10 and
NDCG@10 with state-of-the-art methods for top-N recom-
mendation with implicit feedback on MovieLens 1M. The
baseline results are provided by He et al. (2017), except the
result of CDAE (Wu et al. 2016), which is evaluated with our
implementation. We can see that CF-UIcA achieves the best
performance under both measures. Importantly, our method
gives an NDCG@10 0.492, which outperforms the state-of-
the-art method NeuMF by a large margin 0.045 (relative
improvement 10.1%). To demonstrate the signiﬁcance of
the co-autoregression, we train another two CF-UIcA mod-
els under the expectation over: (Uniform Case) all possi-
ble orderings, which cover all UUCs and IICs; and (Inverse

Experiments show that our method achieves state-of-the-art
results, and is able to learn semantic information by visual-
ization, verifying that the autoregression provides a princi-
pled way to incorporate the correlations.

Acknowledgments
This work is supported by the National NSF of China (Nos.
61620106010, 61621136008, 61332007), the MIIT Grant
of Int. Man. Comp. Stan (No. 2016ZXFB00001) and the
NVIDIA NVAIL Program.

References
Bahdanau, D.; Cho, K.; and Bengio, Y. 2014. Neural machine
translation by jointly learning to align and translate. arXiv preprint
arXiv:1409.0473.
Bennett, J., and Lanning, S. 2007. The netﬂix prize. In Proceedings
of KDD cup and workshop, volume 2007, 35.
Billsus, D., and Pazzani, M. J. 1998. Learning collaborative infor-
mation ﬁlters. In ICML, volume 98, 46–54.
Bottou, L. 2010. Large-scale machine learning with stochastic
gradient descent. In Proceedings of COMPSTAT’2010. Springer.
177–186.
Burke, R. 2002. Hybrid recommender systems: Survey and exper-
iments. User modeling and user-adapted interaction 12(4):331–
370.
Dziugaite, G. K., and Roy, D. M. 2015. Neural network matrix
factorization. arXiv preprint arXiv:1511.06443.
Elkahky, A. M.; Song, Y.; and He, X. 2015. A multi-view deep
learning approach for cross domain user modeling in recommen-
dation systems. In WWW, 278–288.
Frey, B. J. 1998. Graphical models for machine learning and
digital communication.
Gopalan, P. K.; Charlin, L.; and Blei, D. 2014. Content-based
recommendations with poisson factorization. In NIPS.
Graves, A.; Mohamed, A.-r.; and Hinton, G. 2013. Speech recog-
nition with deep recurrent neural networks. In ICASSP.
Harper, F. M., and Konstan, J. A. 2016. The movielens datasets:
History and context. ACM Transactions on Interactive Intelligent
Systems (TiiS) 5(4):19.
He, X.; Chen, T.; Kan, M.-Y.; and Chen, X. 2015. Trirank: Review-
aware explainable recommendation by modeling aspects. In CIKM.
He, X.; Zhang, H.; Kan, M.-Y.; and Chua, T.-S. 2016. Fast matrix
factorization for online recommendation with implicit feedback. In
SIGIR, 549–558.
He, X.; Liao, L.; Zhang, H.; Nie, L.; Hu, X.; and Chua, T.-S. 2017.
Neural collaborative ﬁltering. In WWW.
Juan, Y.-C.; Chin, W.-S.; Zhuang, Y.; Yuan, B.-W.; Yang, M.-Y.;
and Lin, C.-J. 2016. Libmf: A matrix-factorization library for
recommender systems. https://www.csie.ntu.edu.tw/
˜cjlin/libmf/.
Kingma, D., and Ba, J. 2014. Adam: A method for stochastic
optimization. arXiv preprint arXiv:1412.6980.
Koren, Y.; Bell, R.; and Volinsky, C. 2009. Matrix factorization
techniques for recommender systems. Computer (8):30–37.
Koren, Y. 2008. Factorization meets the neighborhood: a multi-
faceted collaborative ﬁltering model. In SIGKDD.
Krizhevsky, A.; Sutskever, I.; and Hinton, G. E. 2012. Imagenet
classiﬁcation with deep convolutional neural networks. In NIPS.

2017.
JMLR

Larochelle, H., and Murray, I. 2011. The neural autoregressive
distribution estimator. In AISTATS.
Lauly, S.; Zheng, Y.; Allauzen, A.; and Larochelle, H.
Document neural autoregressive distribution estimation.
18(113):1–24.
Lee, J.; Kim, S.; Lebanon, G.; and Singer, Y. 2013. Local low-rank
matrix approximation. In ICML, 82–90.
Maaten, L. v. d., and Hinton, G. 2008. Visualizing data using t-sne.
JMLR 9:2579–2605.
Mnih, V.; Kavukcuoglu, K.; Silver, D.; Rusu, A. A.; Veness, J.;
Bellemare, M. G.; Graves, A.; Riedmiller, M.; Fidjeland, A. K.;
Ostrovski, G.; et al. 2015. Human-level control through deep rein-
forcement learning. Nature 518(7540):529–533.
Pan, R.; Zhou, Y.; Cao, B.; Liu, N. N.; Lukose, R.; Scholz, M.; and
Yang, Q. 2008. One-class collaborative ﬁltering. In ICDM.
Rendle, S.; Freudenthaler, C.; Gantner, Z.; and Schmidt-Thieme, L.
2009. Bpr: Bayesian personalized ranking from implicit feedback.
In UAI, 452–461.
Resnick, P.; Iacovou, N.; Suchak, M.; Bergstrom, P.; and Riedl, J.
1994. Grouplens: an open architecture for collaborative ﬁltering of
netnews. In Proceedings of the 1994 ACM conference on Computer
supported cooperative work, 175–186. ACM.
Salakhutdinov, R., and Mnih, A. 2007. Probabilistic matrix factor-
ization. In NIPS.
Salakhutdinov, R., and Mnih, A. 2008. Bayesian probabilistic ma-
trix factorization using markov chain monte carlo. In ICML.
Salakhutdinov, R.; Mnih, A.; and Hinton, G. 2007. Restricted
boltzmann machines for collaborative ﬁltering. In ICML.
Sarwar, B.; Karypis, G.; Konstan, J.; and Riedl, J. 2000. Applica-
tion of dimensionality reduction in recommender system – a case
study. In ACM WEBKDD WORKSHOP.
Sarwar, B.; Karypis, G.; Konstan, J.; and Riedl, J. 2001. Item-based
collaborative ﬁltering recommendation algorithms. In WWW.
Schafer, J. B.; Frankowski, D.; Herlocker, J.; and Sen, S. 2007.
Collaborative ﬁltering recommender systems. In The adaptive web.
Springer. 291–324.
Sedhain, S.; Menon, A. K.; Sanner, S.; and Xie, L. 2015. Autorec:
Autoencoders meet collaborative ﬁltering. In WWW.
Silver, D.; Huang, A.; Maddison, C. J.; Guez, A.; Sifre, L.; Van
Den Driessche, G.; Schrittwieser, J.; Antonoglou, I.; Panneershel-
vam, V.; Lanctot, M.; et al. 2016. Mastering the game of go with
deep neural networks and tree search. Nature 529(7587):484–489.
Theano Development Team. 2016. Theano: A Python framework
for fast computation of mathematical expressions. arXiv preprint
arXiv:1605.02688.
Van den Oord, A.; Dieleman, S.; and Schrauwen, B. 2013. Deep
content-based music recommendation. In NIPS.
Wang, J.; De Vries, A. P.; and Reinders, M. J. 2006. Unifying user-
based and item-based collaborative ﬁltering approaches by similar-
ity fusion. In SIGIR, 501–508.
Wu, Y.; DuBois, C.; Zheng, A. X.; and Ester, M. 2016. Collabo-
rative denoising auto-encoders for top-n recommender systems. In
WSDM, 153–162.
Zheng, Y.; Liu, C.; Tang, B.; and Zhou, H. 2016a. Neural au-
toregressive collaborative ﬁltering for implicit feedback. In Pro-
ceedings of the 1st Workshop on Deep Learning for Recommender
Systems, 2–6. ACM.
Zheng, Y.; Tang, B.; Ding, W.; and Zhou, H. 2016b. A neural
autoregressive approach to collaborative ﬁltering. In ICML.

