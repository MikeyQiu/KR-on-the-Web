From Word Segmentation to POS Tagging for Vietnamese

Dat Quoc Nguyen1, Thanh Vu2, Dai Quoc Nguyen3, Mark Dras1 and Mark Johnson1
1Department of Computing, Macquarie University, Australia
{dat.nguyen, mark.dras, mark.johnson}@mq.edu.au
2NIHR Innovation Observatory, Newcastle University, United Kingdom
thanh.vu@newcastle.ac.uk
3PRaDA Centre, Deakin University, Australia
dai.nguyen@deakin.edu.au

Abstract

This paper presents an empirical com-
parison of two strategies for Vietnamese
Part-of-Speech (POS) tagging from unseg-
mented text: (i) a pipeline strategy where
we consider the output of a word seg-
menter as the input of a POS tagger, and
(ii) a joint strategy where we predict a
combined segmentation and POS tag for
each syllable. We also make a comparison
between state-of-the-art (SOTA) feature-
based and neural network-based models.
On the benchmark Vietnamese treebank
(Nguyen et al., 2009), experimental results
show that the pipeline strategy produces
better scores of POS tagging from unseg-
mented text than the joint strategy, and the
highest accuracy is obtained by using a
feature-based model.

1

Introduction

POS tagging is one of the most fundamental nat-
ural language processing (NLP) tasks. In English
where white space is a strong indicator of word
boundaries, POS tagging is an important first step
towards many other NLP tasks. However, white
space when written in Vietnamese is also used
to separate syllables that constitute words. So for
Vietnamese NLP, word segmentation is referred to
as the key first step (Dien et al., 2001).

When applying POS tagging to real-world Viet-
namese text where gold word-segmentation is not
available, the pipeline strategy is to first segment
the text by using a word segmenter, and then
feed the word-segmented text—which is the out-
put of the word segmenter—as the input to a POS
tagger. For example, given a written text “thuế
thu nhập cá nhân” (individualcá_nhân incomethu_nhập
taxthuế) consisting of 5 syllables, the word seg-

menter returns a two-word phrase “thuế_thu_nhập
cá_nhân.”1 Then given the input segmented text
“thuế_thu_nhập cá_nhân”, the POS tagger returns
“thuế_thu_nhập/N cá_nhân/N.”

A class of approaches to POS tagging from un-
segmented text that has been actively explored in
other languages, such as in Chinese and Japanese,
is joint word segmentation and POS tagging
(Zhang and Clark, 2008). A possible joint strat-
egy is to assign a combined segmentation and POS
tag to each syllable (Kruengkrai et al., 2009). For
example, given the input text “thuế thu nhập cá
nhân”, the joint strategy would produce “thuế/B-
N thu/I-N nhập/I-N cá/B-N nhân/I-N”, where B
refers to the beginning of a word and I refers to
the inside of a word. Shao et al. (2017) showed
that this joint strategy gives SOTA results for Chi-
nese POS tagging by utilizing a BiLSTM-CNN-
CRF model (Ma and Hovy, 2016).

In this paper, we present the first empirical
study comparing the joint and pipeline strate-
gies for Vietnamese POS tagging from unseg-
mented text. In addition, we make a comparison
between SOTA feature-based and neural network-
based models, which, to the best of our knowledge,
has not done in any prior work on Vietnamese.
On the benchmark Vietnamese treebank (Nguyen
et al., 2009), we show that the pipeline strategy
produces better scores than the joint strategy. We
also show that the highest tagging accuracy is ob-
tained by using a traditional feature-based model
rather than neural network-based models.

2 Related work

2.1 Word segmentation

Nguyen et al. (2006), Dinh and Vu (2006) and

1In the traditional underscore-based representation in
Vietnamese word segmentation (Nguyen et al., 2009), white
space is only used to separate words while underscore is used
to separate syllables inside a word.

7
1
0
2
 
v
o
N
 
4
1
 
 
]
L
C
.
s
c
[
 
 
1
v
1
5
9
4
0
.
1
1
7
1
:
v
i
X
r
a

Tran et al. (2010) considered the Vietnamese word
segmentation task as a sequence labeling task, us-
ing either a CRF, SVM or MaxEnt model to as-
sign each syllable a segmentation tag such as B
or I. In addition, Le et al. (2008), Pham et al.
(2009) and Tran et al. (2012) used the maximum
matching method (NanYuan and YanBin, 1991) to
generate all possible segmentations for each in-
put sentence; then to select the best segmentation,
Le et al. (2008) and Tran et al. (2012) applied n-
gram language model while Pham et al. (2009)
employed POS information from an external POS
tagger. Later, Liu and Lin (2014) and Nguyen and
Le (2016) proposed approaches based on point-
wise prediction, where a binary classifier is trained
to identify whether or not there is a word bound-
ary at each point between two syllables. Further-
more, Nguyen et al. (2017b) proposed a rule-based
approach which gets the highest results to date in
terms of both segmentation accuracy and speed.

2.2 POS tagging

Regarding Vietnamese POS tagging, Dien and
Kiem (2003) projected POS annotations from En-
glish to Vietnamese via a bilingual corpus of word
alignments. As a standard sequence labeling task,
previous research has applied the CRF, SVM or
MaxEnt model to assign each word a POS tag
(Nghiem et al., 2008; Tran et al., 2009; Le-Hong
et al., 2010; Nguyen et al., 2010; Tran et al.,
2010; Bach et al., 2013). In addition, Nguyen et al.
(2011) proposed a rule-based approach to auto-
matically construct transformation rules for POS
tagging in the form of a Ripple Down Rules tree
(Compton and Jansen, 1990), leading to a devel-
opment of the RDRPOSTagger (Nguyen et al.,
2014a) which was the best system for the POS tag-
ging shared task at the 2013 Vietnamese Language
and Speech Processing (VLSP) workshop.

Nguyen et al. (2016a) and Nguyen et al. (2016b)
later showed that SOTA accuracies at 94+% in
the Vietnamese POS tagging task are obtained by
simply retraining existing English POS taggers on
Vietnamese data, showing that the MarMoT tagger
(Mueller et al., 2013) and the Stanford POS tagger
(Toutanova et al., 2003) obtain higher accuracies
than RDRPOSTagger. Nguyen et al. (2016a) also
showed that a simple lexicon-based approach as-
signing each word by its most probable POS tag
gains a promising accuracy at 91%. Note that both
Nguyen et al. (2016a) and Nguyen et al. (2016b)

did not experiment with neural network models.
Pham et al. (2017) recently applied the BiLSTM-
CNN-CRF (Ma and Hovy, 2016) for Vietnamese
POS tagging, however, they did not experiment
with SOTA feature-based models.

Previously, only Takahashi and Yamamoto
(2016) carried out joint word segmentation and
POS tagging for Vietnamese, to predicting a com-
bined segmentation and POS tag to each sylla-
ble. In particular, Takahashi and Yamamoto (2016)
experimented with traditional SVM- and CRF-
based toolkits on a dataset of about 7k sentences
and reported results of joint prediction only, i.e.,
they did not compare to the pipeline strategy. The
CoNLL 2017 shared task on Universal Dependen-
cies (UD) parsing from raw text (Zeman et al.,
2017) provided some results to the pipeline strat-
egy from word segmentation to POS tagging, how-
ever, the Vietnamese dataset in the UD project
is very small, consisting of 1,400 training sen-
tences. Furthermore, Nguyen et al. (2017a) pro-
vided a pre-trained jPTDP model for joint POS
tagging and dependency parsing for Vietnamese,2
which obtains a tagging accuracy at 93.0%, a UAS
score at 77.7% and a LAS score at 69.5% when
evaluated on the Vietnamese dependency treebank
VnDT of 10k sentences (Nguyen et al., 2014b).

3 Experimental methodology

We compare the joint word segmentation and POS
tagging strategy to the pipeline strategy on the
benchmark Vietnamese treebank (Nguyen et al.,
2009) using well-known POS tagging models.

3.1

Joint segmentation and POS tagging

Following Kruengkrai et al. (2009), Takahashi and
Yamamoto (2016) and Shao et al. (2017), we for-
malize the joint word segmentation and POS tag-
ging problem for Vietnamese as a sequence la-
beling task to assigning a combined segmenta-
tion and POS tag to each syllable. For exam-
ple, given a manually POS-annotated training cor-
pus “Cuộc/Nc điều_tra/V dường_như/X không/R
tiến_triển/V ./CH” ‘The investigation seems to
be making no progress’, we transform this cor-
pus into a syllable-based representation as follows:
“Cuộc/B-Nc điều/B-V tra/I-V dường/B-X như/I-X
không/B-R tiến/B-V triển/I-V ./B-CH”, where seg-
mentation tags B and I denote beginning and in-

2https://drive.google.com/drive/
folders/0B5eBgc8jrKtpUmhhSmtFLWdrTzQ

side of a word, respectively, while Nc, V, X, R and
CH are POS tags. Then we train sequence labeling
models on the syllable-based transformed corpus.

3.2 Dataset

The Vietnamese treebank (Nguyen et al., 2009) is
the largest annotated corpus for Vietnamese, pro-
viding a set of 27,870 manually POS-annotated
sentences for training and development (about 23
words per sentence on average) and a test set of
2120 manually POS-annotated sentences (about
31 words per sentence).3 From the set of 27,870
sentences, we use the first 27k sentences for train-
ing and the last 870 sentences for development.

3.3 Models

For both joint and pipeline strategies, we use the
following models:

• RDRPOSTagger (Nguyen et al., 2014a) is
a transformation rule-based learning model
which obtained the highest accuracy at the
VLSP 2013 POS tagging shared task.4

• MarMoT (Mueller et al., 2013) is a generic
CRF framework and a SOTA POS and mor-
phological tagger.5

• BiLSTM-CRF (Huang et al., 2015) is a se-
quence labeling model which extends the
BiLSTM model with a CRF layer.

• BiLSTM-CRF + CNN-char, i.e. BiLSTM-
CNN-CRF, is an extension of the BiLSTM-
CRF, using CNN to derive character-based
representations (Ma and Hovy, 2016).

• BiLSTM-CRF + LSTM-char is another ex-
tension of the BiLSTM-CRF, using BiLSTM
to derive the character-based representations
(Lample et al., 2016).

Here, for the pipeline strategy, we train these
models to predict POS tags with respect to (w.r.t.)
gold word segmentation. In addition, we also re-
train the fast and accurate Vietnamese word seg-
menter RDRsegmenter (Nguyen et al., 2017b) us-
ing the training set of 27k sentences.6

3The data was officially used for the Vietnamese POS tag-

ging shared task at the second VLSP 2013 workshop.

4http://rdrpostagger.sourceforge.net
5http://cistern.cis.lmu.de/marmot
6RDRsegmenter obtains a segmentation speed at 60k
words per second, computed on a personal computer of In-
tel Core i7 2.2 GHz. RDRsegmenter is available at: https:
//github.com/datquocnguyen/RDRsegmenter

Model
BiLSTM-CRF
+ CNN-char
+ LSTM-char

Pipeline
100
100
150

Joint
200
250
250

Table 1: Optimal number of LSTM units.

3.4

Implementation details

We use the original pure Java implementations of
RDRPOSTagger and MarMoT with default hyper-
parameter settings in our experiments. Instead of
using implementations independently provided by
authors of BiLSTM-CRF, BiLSTM-CRF + CNN-
char7 and BiLSTM-CRF + LSTM-char, we use
a reimplementation which is optimized for per-
formance of all these models from Reimers and
Gurevych (2017).8

For three BiLSTM-CRF-based models, we use
default hyper-parameters provided by Reimers and
Gurevych (2017) with the following exceptions:
we use a dropout rate at 0.5 (Ma and Hovy, 2016)
with the frequency threshold of 5 for unknown
word and syllable types. We initialize word and
syllable embeddings with 100-dimensional pre-
trained embeddings,9 then learn them together
with other model parameters during training by us-
ing Nadam (Dozat, 2016). For training, we run for
100 epochs. We perform a grid search of hyper-
parameters to select the number of BiLSTM lay-
ers from {1, 2, 3} and the number of LSTM units
in each layer from {50, 100, 150, 200, 250, 300}.
Early stopping is applied when no performance
improvement on the development set is obtained
after 5 contiguous epochs. For both pipeline and
joint strategies, we find the highest performance
on the development set is when using two stacked
BiLSTM layers. Table 1 presents the optimal num-
ber of LSTM units.

Here the performance is evaluated by F1 score,
based on the number of correctly segmented and
tagged words (Zhang and Clark, 2008). In the case
of gold word segmentation, F1 score for POS tag-
ging is in fact the tagging accuracy.

7https://github.com/XuezheMax/

LasagneNLP

8https://github.com/UKPLab/

emnlp2017-bilstm-cnn-crf

9Pre-trained word and syllable embeddings are learned
(Mikolov
by training the Word2Vec Skip-gram model
et al., 2013) on a Vietnamese news corpus which is avail-
able at: http://mim.hus.vnu.edu.vn/phuonglh/
corpus/baomoi.zip

Model
RDRPOSTagger
MarMoT
BiLSTM-CRF
+ CNN-char
+ LSTM-char

Accuracy
95.11
95.88
95.06
95.40
95.31

Speed
180k
25k
3k
2.5k
1.5k

Table 2: POS tagging accuracies (in %) on the test
set w.r.t. gold word segmentation. “Speed” denotes
the tagging speed, i.e. the number of words per
second, computed on a personal computer of Intel
Core i7 2.2 GHz (model loading time is not taken
into account).

4 Main results

Table 2 presents POS tagging accuracy and tag-
ging speed of each model on the test set w.r.t.
gold word segmentation, in which MarMoT is
the most accurate model while RDRPOSTagger
is the fastest one. In particular, MarMoT obtains
0.5%+ higher accuracy than the three BiLSTM-
based models. This is not surprising as the training
set of 27k sentences is relatively small compared
to the training data available in other languages
such as English or Chinese.

Table 3 presents F1 scores for word segmenta-
tion and POS tagging in a real-world application
scenario where the gold word-segmentation is not
available. Comparing the results in Table 2 to re-
sults for the pipeline strategy, we observe a drop
of about 2% for all models when using predicted
segmentation instead of gold segmentation. Also,
Table 3 clearly shows that the pipeline strategy
helps produce better results than the joint strategy.
In addition, pre-designed features in both RDR-
POSTagger and MarMoT are designed to capture
word-level information rather than syllable-level
information, so it is also not surprising that for
the joint strategy RDRPOSTagger is significantly
lower while MarMoT is lower than the BiLSTM-
CRF model with additional character-based repre-
sentations.

Tables 2 and 3 suggest that for a practical ap-
plication to Vietnamese where performance accu-
racy is preferred, we should consider using the
pipeline strategy with a traditional SOTA feature-
based tagger such as MarMoT. If speed is preferred
such as in big data, RDRPOSTagger would be a
superior alternative. With the current state of train-
ing data available in Vietnamese, future research
should focus on incorporating Vietnamese linguis-

e
n
i
l
e
p
i
P

t
n
i
o
J

Model

RDRPOSTagger
MarMoT
BiLSTM-CRF
+ CNN-char
+ LSTM-char
RDRPOSTagger
MarMoT
BiLSTM-CRF
+ CNN-char
+ LSTM-char

WSeg PTag
93.39
97.75
93.96
97.75
93.25
97.75
93.55
97.75
93.46
97.75
87.53
93.73
92.78
96.50
92.43
96.15
92.79
96.66
92.95
96.76

Table 3: F1 scores (in %) for word segmenta-
tion (WSeg) and POS tagging (PTag) from unseg-
mented text. The pipeline strategy uses RDRseg-
menter for word segmentation. In preliminary ex-
periments, where we also train the five models
above to predict a segmentation tag B or I for
each syllable, we then find that RDRsegmenter ob-
tains better word segmentation score than those
five models.

tic features into the traditional feature-based se-
quence taggers.

5 Conclusion

We have presented empirical comparisons be-
tween two strategies for Vietnamese POS tag-
ging from unsegmented text and between SOTA
feature- and neural network-based models. Ex-
perimental results on the benchmark Vietnamese
treebank (Nguyen et al., 2009) show that
the
pipeline strategy produces higher scores of POS
tagging from unsegmented text than the joint strat-
egy. In addition, we also show that a traditional
feature-based model (i.e. MarMoT) obtains bet-
ter POS tagging accuracy than neural network-
based models. We provide a pre-trained MarMoT
model for Vietnamese POS tagging at https://
github.com/datquocnguyen/VnMarMoT.

Acknowledgments

This research was partially supported by the
Australian Government
through the Australian
Research Council’s Discovery Projects funding
scheme (project DP160102156). This research
was also partially supported by NICTA, funded
by the Australian Government through the Depart-
ment of Communications and the Australian Re-
search Council through the ICT Centre of Excel-
lence Program.

References

Ngo Xuan Bach, Kunihiko Hiraishi, Nguyen Le Minh,
and Akira Shimazu. 2013. Dual decomposition for
Vietnamese part-of-speech tagging. In Proceedings
of the 17th International Conference on Knowledge
Based and Intelligent Information and Engineering
Systems. pages 123–131.

P. Compton and R. Jansen. 1990. A Philosophical Ba-
sis for Knowledge Acquisition. Knowledge Aquisi-
tion 2(3):241–257.

Wuying Liu and Li Lin. 2014. Probabilistic Ensemble
In
Learning for Vietnamese Word Segmentation.
Proceedings of the 37th International ACM SIGIR
Conference on Research & Development in Informa-
tion Retrieval. pages 931–934.

Xuezhe Ma and Eduard Hovy. 2016. End-to-end Se-
quence Labeling via Bi-directional LSTM-CNNs-
CRF. In Proceedings of the 54th Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers). pages 1064–1074.

Dinh Dien and Hoang Kiem. 2003. POS-Tagger for
English-Vietnamese Bilingual Corpus. In Proceed-
ings of the HLT-NAACL 2003 Workshop on Build-
ing and Using Parallel Texts: Data Driven Machine
Translation and Beyond. pages 88–95.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed Representa-
tions of Words and Phrases and their Composition-
ality. In Advances in Neural Information Processing
Systems 26. pages 3111–3119.

Dinh Dien, Hoang Kiem, and Nguyen Van Toan. 2001.
Vietnamese Word Segmentation. In Proceedings of
the Sixth Natural Language Processing Pacific Rim
Symposium. pages 749–756.

Dien Dinh and Thuy Vu. 2006. A Maximum Entropy
In
Approach for Vietnamese Word Segmentation.
Proceedings of the 2006 International Conference
on Research, Innovation and Vision for the Future.
pages 248–253.

Timothy Dozat. 2016. Incorporating Nesterov Momen-
tum into Adam. In Proceedings of the ICLR 2016
Workshop Track.

Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidi-
rectional LSTM-CRF models for sequence tagging.
arXiv preprint arXiv:1508.01991.

Canasai Kruengkrai, Kiyotaka Uchimoto, Jun’ichi
Kazama, Yiou Wang, Kentaro Torisawa, and Hitoshi
Isahara. 2009. An Error-Driven Word-Character
Hybrid Model for Joint Chinese Word Segmentation
and POS Tagging. In Proceedings of the 47th An-
nual Meeting of the ACL and the 4th IJCNLP of the
AFNLP. pages 513–521.

Guillaume Lample, Miguel Ballesteros, Sandeep Sub-
ramanian, Kazuya Kawakami, and Chris Dyer. 2016.
Neural Architectures for Named Entity Recognition.
In Proceedings of the 2016 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies.
pages 260–270.

Hong Phuong Le, Thi Minh Huyen Nguyen, Azim
Roussanaly, and Tuong Vinh Ho. 2008. A hybrid
approach to word segmentation of Vietnamese texts.
In Proceedings of the 2nd International Conference
on Language and Automata Theory and Applica-
tions. pages 240–249.

Phuong Le-Hong, Azim Roussanaly, Thi Minh Huyen
Nguyen, and Mathias Rossignol. 2010. An empir-
ical study of maximum entropy approach for part-
of-speech tagging of Vietnamese texts. In Proceed-
ings of the Traitement Automatique des Langues Na-
turelles.

Thomas Mueller, Helmut Schmid,

and Hinrich
Sch¨utze. 2013. Efficient Higher-Order CRFs for
In Proceedings of the
Morphological Tagging.
2013 Conference on Empirical Methods on Natural
Language Processing. pages 322–332.

Liang NanYuan and Zheng YanBin. 1991. A Chinese
word segmentation model and a Chinese word seg-
mentation system PC-CWSS. Journal of Chinese
Language and Computing 1(1).

Minh Nghiem, Dien Dinh, and Mai Nguyen. 2008. Im-
proving Vietnamese POS tagging by integrating a
rich feature set and Support Vector Machines.
In
Proceedings of the 2008 IEEE International Con-
ference on Research, Innovation and Vision for the
Future in Computing and Communication Technolo-
gies. pages 128–133.

Cam-Tu Nguyen, Trung-Kien Nguyen, Xuan-Hieu
Phan, Le-Minh Nguyen, and Quang-Thuy Ha. 2006.
Vietnamese Word Segmentation with CRFs and
SVMs: An Investigation. In Proceedings of the 20th
Pacific Asia Conference on Language, Information
and Computation. pages 215–222.

Dat Quoc Nguyen, Mark Dras, and Mark Johnson.
2017a. A Novel Neural Network Model for Joint
POS Tagging and Graph-based Dependency Pars-
In Proceedings of the CoNLL 2017 Shared
ing.
Task: Multilingual Parsing from Raw Text to Uni-
versal Dependencies. pages 134–142.

Dat Quoc Nguyen, Dai Quoc Nguyen, Dang Duc Pham,
and Son Bao Pham. 2014a. RDRPOSTagger: A Rip-
ple Down Rules-based Part-Of-Speech Tagger.
In
Proceedings of the Demonstrations at the 14th Con-
ference of the European Chapter of the Association
for Computational Linguistics. pages 17–20.

Dat Quoc Nguyen, Dai Quoc Nguyen, Dang Duc
Pham, and Son Bao Pham. 2016a. A Robust
Transformation-Based Learning Approach Using
Ripple Down Rules for Part-of-Speech Tagging. AI
Communications 29(3):409–422.

Yan Shao, Christian Hardmeier, J¨org Tiedemann, and
Joakim Nivre. 2017. Character-based Joint Segmen-
tation and POS Tagging for Chinese using Bidirec-
tional RNN-CRF. In Proceedings of the 8th Interna-
tional Joint Conference on Natural Language Pro-
cessing. page to appear.

Kanji Takahashi and Kazuhide Yamamoto. 2016. Fun-
damental tools and resource are available for Viet-
namese analysis. In Proceedings of the 2016 Inter-
national Conference on Asian Language Processing.
pages 246–249.

Kristina Toutanova, Dan Klein, Christopher D. Man-
ning, and Yoram Singer. 2003. Feature-rich Part-of-
speech Tagging with a Cyclic Dependency Network.
In Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology -
Volume 1. pages 173–180.

Ngoc Anh Tran, Thanh Tinh Dao, and Phuong Thai
Nguyen. 2012. An effective context-based method
for Vietnamese-word segmentation. In Proceedings
of First International Workshop on Vietnamese Lan-
guage and Speech Processing. pages 34–40.

Oanh Thi Tran, Cuong Anh Le, Thuy Quang Ha, and
Quynh Hoang Le. 2009. An Experimental Study
on Vietnamese POS Tagging. In Proceedings of the
2009 International Conference on Asian Language
Processing. pages 23–27.

Thi Oanh Tran, Anh Cuong Le, and Quang Thuy Ha.
Improving Vietnamese Word Segmentation
2010.
and POS Tagging using MEM with Various Kinds of
Resources. Journal of Natural Language Processing
17(3):41–60.

Daniel Zeman, Martin Popel, Milan Straka, Jan Ha-
jic, Joakim Nivre, et al. 2017. CoNLL 2017 Shared
Task: Multilingual Parsing from Raw Text to Uni-
versal Dependencies. In Proceedings of the CoNLL
2017 Shared Task: Multilingual Parsing from Raw
Text to Universal Dependencies. pages 1–19.

Yue Zhang and Stephen Clark. 2008. Joint Word Seg-
mentation and POS Tagging Using a Single Percep-
tron. In Proceedings of the 46th Annual Meeting of
the Association for Computational Linguistics: Hu-
man Language Technologies. pages 888–896.

Dat Quoc Nguyen, Dai Quoc Nguyen, Son Bao Pham,
Phuong-Thai Nguyen, and Minh Le Nguyen. 2014b.
From Treebank Conversion to Automatic Depen-
In Proceedings
dency Parsing for Vietnamese.
of 19th International Conference on Application of
Natural Language to Information Systems. pages
196–207.

Dat Quoc Nguyen, Dai Quoc Nguyen, Son Bao Pham,
and Dang Duc Pham. 2011. Ripple Down Rules
In Proceedings of the
for Part-of-Speech Tagging.
12th International Conference on Intelligent Text
Processing and Computational Linguistics - Volume
Part I. pages 190–201.

Dat Quoc Nguyen, Dai Quoc Nguyen, Thanh Vu, Mark
Dras, and Mark Johnson. 2017b. A Fast and Ac-
curate Vietnamese Word Segmenter. arXiv preprint
arXiv:1709.06307.

Le Minh Nguyen, Xuan Bach Ngo, Viet Cuong
Nguyen, Quang Nhat Minh Pham, and Akira Shi-
mazu. 2010. A Semi-supervised Learning Method
In Pro-
for Vietnamese Part-of-Speech Tagging.
ceedings of the International Conference on Knowl-
edge and Systems Engineering. pages 141–146.

Phuong Thai Nguyen, Xuan Luong Vu, Thi
Minh Huyen Nguyen, Van Hiep Nguyen, and
Building a Large
Hong Phuong Le. 2009.
Syntactically-Annotated Corpus of Vietnamese.
In Proceedings of the Third Linguistic Annotation
Workshop. pages 182–185.

Tuan-Phong Nguyen and Anh-Cuong Le. 2016. A Hy-
brid Approach to Vietnamese Word Segmentation.
In Proceedings of the 2016 IEEE RIVF Interna-
tional Conference on Computing and Communica-
tion Technologies: Research, Innovation, and Vision
for the Future. pages 114–119.

Tuan Phong Nguyen, Quoc Tuan Truong, Xuan Nam
Nguyen, and Anh Cuong Le. 2016b. An Experimen-
tal Investigation of Part-Of-Speech Taggers for Viet-
namese. VNU Journal of Science: Computer Sci-
ence and Communication Engineering 32(3):11–25.

Dang Duc Pham, Giang Binh Tran, and Son Bao Pham.
2009. A Hybrid Approach to Vietnamese Word Seg-
mentation using Part of Speech tags. In Proceedings
of the 2009 International Conference on Knowledge
and Systems Engineering. pages 154–161.

Thai-Hoang Pham, Xuan-Khoai Pham, Tuan-Anh
Nguyen, and Phuong Le-Hong. 2017. NNVLP: A
Neural Network-Based Vietnamese Language Pro-
cessing Toolkit. In Proceedings of the IJCNLP 2017
System Demonstrations. page to appear.

Nils Reimers and Iryna Gurevych. 2017. Report-
ing Score Distributions Makes a Difference: Perfor-
mance Study of LSTM-networks for Sequence Tag-
In Proceedings of the 2017 Conference on
ging.
Empirical Methods in Natural Language Process-
ing. pages 338–348.

From Word Segmentation to POS Tagging for Vietnamese

Dat Quoc Nguyen1, Thanh Vu2, Dai Quoc Nguyen3, Mark Dras1 and Mark Johnson1
1Department of Computing, Macquarie University, Australia
{dat.nguyen, mark.dras, mark.johnson}@mq.edu.au
2NIHR Innovation Observatory, Newcastle University, United Kingdom
thanh.vu@newcastle.ac.uk
3PRaDA Centre, Deakin University, Australia
dai.nguyen@deakin.edu.au

Abstract

This paper presents an empirical com-
parison of two strategies for Vietnamese
Part-of-Speech (POS) tagging from unseg-
mented text: (i) a pipeline strategy where
we consider the output of a word seg-
menter as the input of a POS tagger, and
(ii) a joint strategy where we predict a
combined segmentation and POS tag for
each syllable. We also make a comparison
between state-of-the-art (SOTA) feature-
based and neural network-based models.
On the benchmark Vietnamese treebank
(Nguyen et al., 2009), experimental results
show that the pipeline strategy produces
better scores of POS tagging from unseg-
mented text than the joint strategy, and the
highest accuracy is obtained by using a
feature-based model.

1

Introduction

POS tagging is one of the most fundamental nat-
ural language processing (NLP) tasks. In English
where white space is a strong indicator of word
boundaries, POS tagging is an important first step
towards many other NLP tasks. However, white
space when written in Vietnamese is also used
to separate syllables that constitute words. So for
Vietnamese NLP, word segmentation is referred to
as the key first step (Dien et al., 2001).

When applying POS tagging to real-world Viet-
namese text where gold word-segmentation is not
available, the pipeline strategy is to first segment
the text by using a word segmenter, and then
feed the word-segmented text—which is the out-
put of the word segmenter—as the input to a POS
tagger. For example, given a written text “thuế
thu nhập cá nhân” (individualcá_nhân incomethu_nhập
taxthuế) consisting of 5 syllables, the word seg-

menter returns a two-word phrase “thuế_thu_nhập
cá_nhân.”1 Then given the input segmented text
“thuế_thu_nhập cá_nhân”, the POS tagger returns
“thuế_thu_nhập/N cá_nhân/N.”

A class of approaches to POS tagging from un-
segmented text that has been actively explored in
other languages, such as in Chinese and Japanese,
is joint word segmentation and POS tagging
(Zhang and Clark, 2008). A possible joint strat-
egy is to assign a combined segmentation and POS
tag to each syllable (Kruengkrai et al., 2009). For
example, given the input text “thuế thu nhập cá
nhân”, the joint strategy would produce “thuế/B-
N thu/I-N nhập/I-N cá/B-N nhân/I-N”, where B
refers to the beginning of a word and I refers to
the inside of a word. Shao et al. (2017) showed
that this joint strategy gives SOTA results for Chi-
nese POS tagging by utilizing a BiLSTM-CNN-
CRF model (Ma and Hovy, 2016).

In this paper, we present the first empirical
study comparing the joint and pipeline strate-
gies for Vietnamese POS tagging from unseg-
mented text. In addition, we make a comparison
between SOTA feature-based and neural network-
based models, which, to the best of our knowledge,
has not done in any prior work on Vietnamese.
On the benchmark Vietnamese treebank (Nguyen
et al., 2009), we show that the pipeline strategy
produces better scores than the joint strategy. We
also show that the highest tagging accuracy is ob-
tained by using a traditional feature-based model
rather than neural network-based models.

2 Related work

2.1 Word segmentation

Nguyen et al. (2006), Dinh and Vu (2006) and

1In the traditional underscore-based representation in
Vietnamese word segmentation (Nguyen et al., 2009), white
space is only used to separate words while underscore is used
to separate syllables inside a word.

7
1
0
2
 
v
o
N
 
4
1
 
 
]
L
C
.
s
c
[
 
 
1
v
1
5
9
4
0
.
1
1
7
1
:
v
i
X
r
a

Tran et al. (2010) considered the Vietnamese word
segmentation task as a sequence labeling task, us-
ing either a CRF, SVM or MaxEnt model to as-
sign each syllable a segmentation tag such as B
or I. In addition, Le et al. (2008), Pham et al.
(2009) and Tran et al. (2012) used the maximum
matching method (NanYuan and YanBin, 1991) to
generate all possible segmentations for each in-
put sentence; then to select the best segmentation,
Le et al. (2008) and Tran et al. (2012) applied n-
gram language model while Pham et al. (2009)
employed POS information from an external POS
tagger. Later, Liu and Lin (2014) and Nguyen and
Le (2016) proposed approaches based on point-
wise prediction, where a binary classifier is trained
to identify whether or not there is a word bound-
ary at each point between two syllables. Further-
more, Nguyen et al. (2017b) proposed a rule-based
approach which gets the highest results to date in
terms of both segmentation accuracy and speed.

2.2 POS tagging

Regarding Vietnamese POS tagging, Dien and
Kiem (2003) projected POS annotations from En-
glish to Vietnamese via a bilingual corpus of word
alignments. As a standard sequence labeling task,
previous research has applied the CRF, SVM or
MaxEnt model to assign each word a POS tag
(Nghiem et al., 2008; Tran et al., 2009; Le-Hong
et al., 2010; Nguyen et al., 2010; Tran et al.,
2010; Bach et al., 2013). In addition, Nguyen et al.
(2011) proposed a rule-based approach to auto-
matically construct transformation rules for POS
tagging in the form of a Ripple Down Rules tree
(Compton and Jansen, 1990), leading to a devel-
opment of the RDRPOSTagger (Nguyen et al.,
2014a) which was the best system for the POS tag-
ging shared task at the 2013 Vietnamese Language
and Speech Processing (VLSP) workshop.

Nguyen et al. (2016a) and Nguyen et al. (2016b)
later showed that SOTA accuracies at 94+% in
the Vietnamese POS tagging task are obtained by
simply retraining existing English POS taggers on
Vietnamese data, showing that the MarMoT tagger
(Mueller et al., 2013) and the Stanford POS tagger
(Toutanova et al., 2003) obtain higher accuracies
than RDRPOSTagger. Nguyen et al. (2016a) also
showed that a simple lexicon-based approach as-
signing each word by its most probable POS tag
gains a promising accuracy at 91%. Note that both
Nguyen et al. (2016a) and Nguyen et al. (2016b)

did not experiment with neural network models.
Pham et al. (2017) recently applied the BiLSTM-
CNN-CRF (Ma and Hovy, 2016) for Vietnamese
POS tagging, however, they did not experiment
with SOTA feature-based models.

Previously, only Takahashi and Yamamoto
(2016) carried out joint word segmentation and
POS tagging for Vietnamese, to predicting a com-
bined segmentation and POS tag to each sylla-
ble. In particular, Takahashi and Yamamoto (2016)
experimented with traditional SVM- and CRF-
based toolkits on a dataset of about 7k sentences
and reported results of joint prediction only, i.e.,
they did not compare to the pipeline strategy. The
CoNLL 2017 shared task on Universal Dependen-
cies (UD) parsing from raw text (Zeman et al.,
2017) provided some results to the pipeline strat-
egy from word segmentation to POS tagging, how-
ever, the Vietnamese dataset in the UD project
is very small, consisting of 1,400 training sen-
tences. Furthermore, Nguyen et al. (2017a) pro-
vided a pre-trained jPTDP model for joint POS
tagging and dependency parsing for Vietnamese,2
which obtains a tagging accuracy at 93.0%, a UAS
score at 77.7% and a LAS score at 69.5% when
evaluated on the Vietnamese dependency treebank
VnDT of 10k sentences (Nguyen et al., 2014b).

3 Experimental methodology

We compare the joint word segmentation and POS
tagging strategy to the pipeline strategy on the
benchmark Vietnamese treebank (Nguyen et al.,
2009) using well-known POS tagging models.

3.1

Joint segmentation and POS tagging

Following Kruengkrai et al. (2009), Takahashi and
Yamamoto (2016) and Shao et al. (2017), we for-
malize the joint word segmentation and POS tag-
ging problem for Vietnamese as a sequence la-
beling task to assigning a combined segmenta-
tion and POS tag to each syllable. For exam-
ple, given a manually POS-annotated training cor-
pus “Cuộc/Nc điều_tra/V dường_như/X không/R
tiến_triển/V ./CH” ‘The investigation seems to
be making no progress’, we transform this cor-
pus into a syllable-based representation as follows:
“Cuộc/B-Nc điều/B-V tra/I-V dường/B-X như/I-X
không/B-R tiến/B-V triển/I-V ./B-CH”, where seg-
mentation tags B and I denote beginning and in-

2https://drive.google.com/drive/
folders/0B5eBgc8jrKtpUmhhSmtFLWdrTzQ

side of a word, respectively, while Nc, V, X, R and
CH are POS tags. Then we train sequence labeling
models on the syllable-based transformed corpus.

3.2 Dataset

The Vietnamese treebank (Nguyen et al., 2009) is
the largest annotated corpus for Vietnamese, pro-
viding a set of 27,870 manually POS-annotated
sentences for training and development (about 23
words per sentence on average) and a test set of
2120 manually POS-annotated sentences (about
31 words per sentence).3 From the set of 27,870
sentences, we use the first 27k sentences for train-
ing and the last 870 sentences for development.

3.3 Models

For both joint and pipeline strategies, we use the
following models:

• RDRPOSTagger (Nguyen et al., 2014a) is
a transformation rule-based learning model
which obtained the highest accuracy at the
VLSP 2013 POS tagging shared task.4

• MarMoT (Mueller et al., 2013) is a generic
CRF framework and a SOTA POS and mor-
phological tagger.5

• BiLSTM-CRF (Huang et al., 2015) is a se-
quence labeling model which extends the
BiLSTM model with a CRF layer.

• BiLSTM-CRF + CNN-char, i.e. BiLSTM-
CNN-CRF, is an extension of the BiLSTM-
CRF, using CNN to derive character-based
representations (Ma and Hovy, 2016).

• BiLSTM-CRF + LSTM-char is another ex-
tension of the BiLSTM-CRF, using BiLSTM
to derive the character-based representations
(Lample et al., 2016).

Here, for the pipeline strategy, we train these
models to predict POS tags with respect to (w.r.t.)
gold word segmentation. In addition, we also re-
train the fast and accurate Vietnamese word seg-
menter RDRsegmenter (Nguyen et al., 2017b) us-
ing the training set of 27k sentences.6

3The data was officially used for the Vietnamese POS tag-

ging shared task at the second VLSP 2013 workshop.

4http://rdrpostagger.sourceforge.net
5http://cistern.cis.lmu.de/marmot
6RDRsegmenter obtains a segmentation speed at 60k
words per second, computed on a personal computer of In-
tel Core i7 2.2 GHz. RDRsegmenter is available at: https:
//github.com/datquocnguyen/RDRsegmenter

Model
BiLSTM-CRF
+ CNN-char
+ LSTM-char

Pipeline
100
100
150

Joint
200
250
250

Table 1: Optimal number of LSTM units.

3.4

Implementation details

We use the original pure Java implementations of
RDRPOSTagger and MarMoT with default hyper-
parameter settings in our experiments. Instead of
using implementations independently provided by
authors of BiLSTM-CRF, BiLSTM-CRF + CNN-
char7 and BiLSTM-CRF + LSTM-char, we use
a reimplementation which is optimized for per-
formance of all these models from Reimers and
Gurevych (2017).8

For three BiLSTM-CRF-based models, we use
default hyper-parameters provided by Reimers and
Gurevych (2017) with the following exceptions:
we use a dropout rate at 0.5 (Ma and Hovy, 2016)
with the frequency threshold of 5 for unknown
word and syllable types. We initialize word and
syllable embeddings with 100-dimensional pre-
trained embeddings,9 then learn them together
with other model parameters during training by us-
ing Nadam (Dozat, 2016). For training, we run for
100 epochs. We perform a grid search of hyper-
parameters to select the number of BiLSTM lay-
ers from {1, 2, 3} and the number of LSTM units
in each layer from {50, 100, 150, 200, 250, 300}.
Early stopping is applied when no performance
improvement on the development set is obtained
after 5 contiguous epochs. For both pipeline and
joint strategies, we find the highest performance
on the development set is when using two stacked
BiLSTM layers. Table 1 presents the optimal num-
ber of LSTM units.

Here the performance is evaluated by F1 score,
based on the number of correctly segmented and
tagged words (Zhang and Clark, 2008). In the case
of gold word segmentation, F1 score for POS tag-
ging is in fact the tagging accuracy.

7https://github.com/XuezheMax/

LasagneNLP

8https://github.com/UKPLab/

emnlp2017-bilstm-cnn-crf

9Pre-trained word and syllable embeddings are learned
(Mikolov
by training the Word2Vec Skip-gram model
et al., 2013) on a Vietnamese news corpus which is avail-
able at: http://mim.hus.vnu.edu.vn/phuonglh/
corpus/baomoi.zip

Model
RDRPOSTagger
MarMoT
BiLSTM-CRF
+ CNN-char
+ LSTM-char

Accuracy
95.11
95.88
95.06
95.40
95.31

Speed
180k
25k
3k
2.5k
1.5k

Table 2: POS tagging accuracies (in %) on the test
set w.r.t. gold word segmentation. “Speed” denotes
the tagging speed, i.e. the number of words per
second, computed on a personal computer of Intel
Core i7 2.2 GHz (model loading time is not taken
into account).

4 Main results

Table 2 presents POS tagging accuracy and tag-
ging speed of each model on the test set w.r.t.
gold word segmentation, in which MarMoT is
the most accurate model while RDRPOSTagger
is the fastest one. In particular, MarMoT obtains
0.5%+ higher accuracy than the three BiLSTM-
based models. This is not surprising as the training
set of 27k sentences is relatively small compared
to the training data available in other languages
such as English or Chinese.

Table 3 presents F1 scores for word segmenta-
tion and POS tagging in a real-world application
scenario where the gold word-segmentation is not
available. Comparing the results in Table 2 to re-
sults for the pipeline strategy, we observe a drop
of about 2% for all models when using predicted
segmentation instead of gold segmentation. Also,
Table 3 clearly shows that the pipeline strategy
helps produce better results than the joint strategy.
In addition, pre-designed features in both RDR-
POSTagger and MarMoT are designed to capture
word-level information rather than syllable-level
information, so it is also not surprising that for
the joint strategy RDRPOSTagger is significantly
lower while MarMoT is lower than the BiLSTM-
CRF model with additional character-based repre-
sentations.

Tables 2 and 3 suggest that for a practical ap-
plication to Vietnamese where performance accu-
racy is preferred, we should consider using the
pipeline strategy with a traditional SOTA feature-
based tagger such as MarMoT. If speed is preferred
such as in big data, RDRPOSTagger would be a
superior alternative. With the current state of train-
ing data available in Vietnamese, future research
should focus on incorporating Vietnamese linguis-

e
n
i
l
e
p
i
P

t
n
i
o
J

Model

RDRPOSTagger
MarMoT
BiLSTM-CRF
+ CNN-char
+ LSTM-char
RDRPOSTagger
MarMoT
BiLSTM-CRF
+ CNN-char
+ LSTM-char

WSeg PTag
93.39
97.75
93.96
97.75
93.25
97.75
93.55
97.75
93.46
97.75
87.53
93.73
92.78
96.50
92.43
96.15
92.79
96.66
92.95
96.76

Table 3: F1 scores (in %) for word segmenta-
tion (WSeg) and POS tagging (PTag) from unseg-
mented text. The pipeline strategy uses RDRseg-
menter for word segmentation. In preliminary ex-
periments, where we also train the five models
above to predict a segmentation tag B or I for
each syllable, we then find that RDRsegmenter ob-
tains better word segmentation score than those
five models.

tic features into the traditional feature-based se-
quence taggers.

5 Conclusion

We have presented empirical comparisons be-
tween two strategies for Vietnamese POS tag-
ging from unsegmented text and between SOTA
feature- and neural network-based models. Ex-
perimental results on the benchmark Vietnamese
treebank (Nguyen et al., 2009) show that
the
pipeline strategy produces higher scores of POS
tagging from unsegmented text than the joint strat-
egy. In addition, we also show that a traditional
feature-based model (i.e. MarMoT) obtains bet-
ter POS tagging accuracy than neural network-
based models. We provide a pre-trained MarMoT
model for Vietnamese POS tagging at https://
github.com/datquocnguyen/VnMarMoT.

Acknowledgments

This research was partially supported by the
Australian Government
through the Australian
Research Council’s Discovery Projects funding
scheme (project DP160102156). This research
was also partially supported by NICTA, funded
by the Australian Government through the Depart-
ment of Communications and the Australian Re-
search Council through the ICT Centre of Excel-
lence Program.

References

Ngo Xuan Bach, Kunihiko Hiraishi, Nguyen Le Minh,
and Akira Shimazu. 2013. Dual decomposition for
Vietnamese part-of-speech tagging. In Proceedings
of the 17th International Conference on Knowledge
Based and Intelligent Information and Engineering
Systems. pages 123–131.

P. Compton and R. Jansen. 1990. A Philosophical Ba-
sis for Knowledge Acquisition. Knowledge Aquisi-
tion 2(3):241–257.

Wuying Liu and Li Lin. 2014. Probabilistic Ensemble
In
Learning for Vietnamese Word Segmentation.
Proceedings of the 37th International ACM SIGIR
Conference on Research & Development in Informa-
tion Retrieval. pages 931–934.

Xuezhe Ma and Eduard Hovy. 2016. End-to-end Se-
quence Labeling via Bi-directional LSTM-CNNs-
CRF. In Proceedings of the 54th Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers). pages 1064–1074.

Dinh Dien and Hoang Kiem. 2003. POS-Tagger for
English-Vietnamese Bilingual Corpus. In Proceed-
ings of the HLT-NAACL 2003 Workshop on Build-
ing and Using Parallel Texts: Data Driven Machine
Translation and Beyond. pages 88–95.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed Representa-
tions of Words and Phrases and their Composition-
ality. In Advances in Neural Information Processing
Systems 26. pages 3111–3119.

Dinh Dien, Hoang Kiem, and Nguyen Van Toan. 2001.
Vietnamese Word Segmentation. In Proceedings of
the Sixth Natural Language Processing Pacific Rim
Symposium. pages 749–756.

Dien Dinh and Thuy Vu. 2006. A Maximum Entropy
In
Approach for Vietnamese Word Segmentation.
Proceedings of the 2006 International Conference
on Research, Innovation and Vision for the Future.
pages 248–253.

Timothy Dozat. 2016. Incorporating Nesterov Momen-
tum into Adam. In Proceedings of the ICLR 2016
Workshop Track.

Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidi-
rectional LSTM-CRF models for sequence tagging.
arXiv preprint arXiv:1508.01991.

Canasai Kruengkrai, Kiyotaka Uchimoto, Jun’ichi
Kazama, Yiou Wang, Kentaro Torisawa, and Hitoshi
Isahara. 2009. An Error-Driven Word-Character
Hybrid Model for Joint Chinese Word Segmentation
and POS Tagging. In Proceedings of the 47th An-
nual Meeting of the ACL and the 4th IJCNLP of the
AFNLP. pages 513–521.

Guillaume Lample, Miguel Ballesteros, Sandeep Sub-
ramanian, Kazuya Kawakami, and Chris Dyer. 2016.
Neural Architectures for Named Entity Recognition.
In Proceedings of the 2016 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies.
pages 260–270.

Hong Phuong Le, Thi Minh Huyen Nguyen, Azim
Roussanaly, and Tuong Vinh Ho. 2008. A hybrid
approach to word segmentation of Vietnamese texts.
In Proceedings of the 2nd International Conference
on Language and Automata Theory and Applica-
tions. pages 240–249.

Phuong Le-Hong, Azim Roussanaly, Thi Minh Huyen
Nguyen, and Mathias Rossignol. 2010. An empir-
ical study of maximum entropy approach for part-
of-speech tagging of Vietnamese texts. In Proceed-
ings of the Traitement Automatique des Langues Na-
turelles.

Thomas Mueller, Helmut Schmid,

and Hinrich
Sch¨utze. 2013. Efficient Higher-Order CRFs for
In Proceedings of the
Morphological Tagging.
2013 Conference on Empirical Methods on Natural
Language Processing. pages 322–332.

Liang NanYuan and Zheng YanBin. 1991. A Chinese
word segmentation model and a Chinese word seg-
mentation system PC-CWSS. Journal of Chinese
Language and Computing 1(1).

Minh Nghiem, Dien Dinh, and Mai Nguyen. 2008. Im-
proving Vietnamese POS tagging by integrating a
rich feature set and Support Vector Machines.
In
Proceedings of the 2008 IEEE International Con-
ference on Research, Innovation and Vision for the
Future in Computing and Communication Technolo-
gies. pages 128–133.

Cam-Tu Nguyen, Trung-Kien Nguyen, Xuan-Hieu
Phan, Le-Minh Nguyen, and Quang-Thuy Ha. 2006.
Vietnamese Word Segmentation with CRFs and
SVMs: An Investigation. In Proceedings of the 20th
Pacific Asia Conference on Language, Information
and Computation. pages 215–222.

Dat Quoc Nguyen, Mark Dras, and Mark Johnson.
2017a. A Novel Neural Network Model for Joint
POS Tagging and Graph-based Dependency Pars-
In Proceedings of the CoNLL 2017 Shared
ing.
Task: Multilingual Parsing from Raw Text to Uni-
versal Dependencies. pages 134–142.

Dat Quoc Nguyen, Dai Quoc Nguyen, Dang Duc Pham,
and Son Bao Pham. 2014a. RDRPOSTagger: A Rip-
ple Down Rules-based Part-Of-Speech Tagger.
In
Proceedings of the Demonstrations at the 14th Con-
ference of the European Chapter of the Association
for Computational Linguistics. pages 17–20.

Dat Quoc Nguyen, Dai Quoc Nguyen, Dang Duc
Pham, and Son Bao Pham. 2016a. A Robust
Transformation-Based Learning Approach Using
Ripple Down Rules for Part-of-Speech Tagging. AI
Communications 29(3):409–422.

Yan Shao, Christian Hardmeier, J¨org Tiedemann, and
Joakim Nivre. 2017. Character-based Joint Segmen-
tation and POS Tagging for Chinese using Bidirec-
tional RNN-CRF. In Proceedings of the 8th Interna-
tional Joint Conference on Natural Language Pro-
cessing. page to appear.

Kanji Takahashi and Kazuhide Yamamoto. 2016. Fun-
damental tools and resource are available for Viet-
namese analysis. In Proceedings of the 2016 Inter-
national Conference on Asian Language Processing.
pages 246–249.

Kristina Toutanova, Dan Klein, Christopher D. Man-
ning, and Yoram Singer. 2003. Feature-rich Part-of-
speech Tagging with a Cyclic Dependency Network.
In Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology -
Volume 1. pages 173–180.

Ngoc Anh Tran, Thanh Tinh Dao, and Phuong Thai
Nguyen. 2012. An effective context-based method
for Vietnamese-word segmentation. In Proceedings
of First International Workshop on Vietnamese Lan-
guage and Speech Processing. pages 34–40.

Oanh Thi Tran, Cuong Anh Le, Thuy Quang Ha, and
Quynh Hoang Le. 2009. An Experimental Study
on Vietnamese POS Tagging. In Proceedings of the
2009 International Conference on Asian Language
Processing. pages 23–27.

Thi Oanh Tran, Anh Cuong Le, and Quang Thuy Ha.
Improving Vietnamese Word Segmentation
2010.
and POS Tagging using MEM with Various Kinds of
Resources. Journal of Natural Language Processing
17(3):41–60.

Daniel Zeman, Martin Popel, Milan Straka, Jan Ha-
jic, Joakim Nivre, et al. 2017. CoNLL 2017 Shared
Task: Multilingual Parsing from Raw Text to Uni-
versal Dependencies. In Proceedings of the CoNLL
2017 Shared Task: Multilingual Parsing from Raw
Text to Universal Dependencies. pages 1–19.

Yue Zhang and Stephen Clark. 2008. Joint Word Seg-
mentation and POS Tagging Using a Single Percep-
tron. In Proceedings of the 46th Annual Meeting of
the Association for Computational Linguistics: Hu-
man Language Technologies. pages 888–896.

Dat Quoc Nguyen, Dai Quoc Nguyen, Son Bao Pham,
Phuong-Thai Nguyen, and Minh Le Nguyen. 2014b.
From Treebank Conversion to Automatic Depen-
In Proceedings
dency Parsing for Vietnamese.
of 19th International Conference on Application of
Natural Language to Information Systems. pages
196–207.

Dat Quoc Nguyen, Dai Quoc Nguyen, Son Bao Pham,
and Dang Duc Pham. 2011. Ripple Down Rules
In Proceedings of the
for Part-of-Speech Tagging.
12th International Conference on Intelligent Text
Processing and Computational Linguistics - Volume
Part I. pages 190–201.

Dat Quoc Nguyen, Dai Quoc Nguyen, Thanh Vu, Mark
Dras, and Mark Johnson. 2017b. A Fast and Ac-
curate Vietnamese Word Segmenter. arXiv preprint
arXiv:1709.06307.

Le Minh Nguyen, Xuan Bach Ngo, Viet Cuong
Nguyen, Quang Nhat Minh Pham, and Akira Shi-
mazu. 2010. A Semi-supervised Learning Method
In Pro-
for Vietnamese Part-of-Speech Tagging.
ceedings of the International Conference on Knowl-
edge and Systems Engineering. pages 141–146.

Phuong Thai Nguyen, Xuan Luong Vu, Thi
Minh Huyen Nguyen, Van Hiep Nguyen, and
Building a Large
Hong Phuong Le. 2009.
Syntactically-Annotated Corpus of Vietnamese.
In Proceedings of the Third Linguistic Annotation
Workshop. pages 182–185.

Tuan-Phong Nguyen and Anh-Cuong Le. 2016. A Hy-
brid Approach to Vietnamese Word Segmentation.
In Proceedings of the 2016 IEEE RIVF Interna-
tional Conference on Computing and Communica-
tion Technologies: Research, Innovation, and Vision
for the Future. pages 114–119.

Tuan Phong Nguyen, Quoc Tuan Truong, Xuan Nam
Nguyen, and Anh Cuong Le. 2016b. An Experimen-
tal Investigation of Part-Of-Speech Taggers for Viet-
namese. VNU Journal of Science: Computer Sci-
ence and Communication Engineering 32(3):11–25.

Dang Duc Pham, Giang Binh Tran, and Son Bao Pham.
2009. A Hybrid Approach to Vietnamese Word Seg-
mentation using Part of Speech tags. In Proceedings
of the 2009 International Conference on Knowledge
and Systems Engineering. pages 154–161.

Thai-Hoang Pham, Xuan-Khoai Pham, Tuan-Anh
Nguyen, and Phuong Le-Hong. 2017. NNVLP: A
Neural Network-Based Vietnamese Language Pro-
cessing Toolkit. In Proceedings of the IJCNLP 2017
System Demonstrations. page to appear.

Nils Reimers and Iryna Gurevych. 2017. Report-
ing Score Distributions Makes a Difference: Perfor-
mance Study of LSTM-networks for Sequence Tag-
In Proceedings of the 2017 Conference on
ging.
Empirical Methods in Natural Language Process-
ing. pages 338–348.

From Word Segmentation to POS Tagging for Vietnamese

Dat Quoc Nguyen1, Thanh Vu2, Dai Quoc Nguyen3, Mark Dras1 and Mark Johnson1
1Department of Computing, Macquarie University, Australia
{dat.nguyen, mark.dras, mark.johnson}@mq.edu.au
2NIHR Innovation Observatory, Newcastle University, United Kingdom
thanh.vu@newcastle.ac.uk
3PRaDA Centre, Deakin University, Australia
dai.nguyen@deakin.edu.au

Abstract

This paper presents an empirical com-
parison of two strategies for Vietnamese
Part-of-Speech (POS) tagging from unseg-
mented text: (i) a pipeline strategy where
we consider the output of a word seg-
menter as the input of a POS tagger, and
(ii) a joint strategy where we predict a
combined segmentation and POS tag for
each syllable. We also make a comparison
between state-of-the-art (SOTA) feature-
based and neural network-based models.
On the benchmark Vietnamese treebank
(Nguyen et al., 2009), experimental results
show that the pipeline strategy produces
better scores of POS tagging from unseg-
mented text than the joint strategy, and the
highest accuracy is obtained by using a
feature-based model.

1

Introduction

POS tagging is one of the most fundamental nat-
ural language processing (NLP) tasks. In English
where white space is a strong indicator of word
boundaries, POS tagging is an important first step
towards many other NLP tasks. However, white
space when written in Vietnamese is also used
to separate syllables that constitute words. So for
Vietnamese NLP, word segmentation is referred to
as the key first step (Dien et al., 2001).

When applying POS tagging to real-world Viet-
namese text where gold word-segmentation is not
available, the pipeline strategy is to first segment
the text by using a word segmenter, and then
feed the word-segmented text—which is the out-
put of the word segmenter—as the input to a POS
tagger. For example, given a written text “thuế
thu nhập cá nhân” (individualcá_nhân incomethu_nhập
taxthuế) consisting of 5 syllables, the word seg-

menter returns a two-word phrase “thuế_thu_nhập
cá_nhân.”1 Then given the input segmented text
“thuế_thu_nhập cá_nhân”, the POS tagger returns
“thuế_thu_nhập/N cá_nhân/N.”

A class of approaches to POS tagging from un-
segmented text that has been actively explored in
other languages, such as in Chinese and Japanese,
is joint word segmentation and POS tagging
(Zhang and Clark, 2008). A possible joint strat-
egy is to assign a combined segmentation and POS
tag to each syllable (Kruengkrai et al., 2009). For
example, given the input text “thuế thu nhập cá
nhân”, the joint strategy would produce “thuế/B-
N thu/I-N nhập/I-N cá/B-N nhân/I-N”, where B
refers to the beginning of a word and I refers to
the inside of a word. Shao et al. (2017) showed
that this joint strategy gives SOTA results for Chi-
nese POS tagging by utilizing a BiLSTM-CNN-
CRF model (Ma and Hovy, 2016).

In this paper, we present the first empirical
study comparing the joint and pipeline strate-
gies for Vietnamese POS tagging from unseg-
mented text. In addition, we make a comparison
between SOTA feature-based and neural network-
based models, which, to the best of our knowledge,
has not done in any prior work on Vietnamese.
On the benchmark Vietnamese treebank (Nguyen
et al., 2009), we show that the pipeline strategy
produces better scores than the joint strategy. We
also show that the highest tagging accuracy is ob-
tained by using a traditional feature-based model
rather than neural network-based models.

2 Related work

2.1 Word segmentation

Nguyen et al. (2006), Dinh and Vu (2006) and

1In the traditional underscore-based representation in
Vietnamese word segmentation (Nguyen et al., 2009), white
space is only used to separate words while underscore is used
to separate syllables inside a word.

7
1
0
2
 
v
o
N
 
4
1
 
 
]
L
C
.
s
c
[
 
 
1
v
1
5
9
4
0
.
1
1
7
1
:
v
i
X
r
a

Tran et al. (2010) considered the Vietnamese word
segmentation task as a sequence labeling task, us-
ing either a CRF, SVM or MaxEnt model to as-
sign each syllable a segmentation tag such as B
or I. In addition, Le et al. (2008), Pham et al.
(2009) and Tran et al. (2012) used the maximum
matching method (NanYuan and YanBin, 1991) to
generate all possible segmentations for each in-
put sentence; then to select the best segmentation,
Le et al. (2008) and Tran et al. (2012) applied n-
gram language model while Pham et al. (2009)
employed POS information from an external POS
tagger. Later, Liu and Lin (2014) and Nguyen and
Le (2016) proposed approaches based on point-
wise prediction, where a binary classifier is trained
to identify whether or not there is a word bound-
ary at each point between two syllables. Further-
more, Nguyen et al. (2017b) proposed a rule-based
approach which gets the highest results to date in
terms of both segmentation accuracy and speed.

2.2 POS tagging

Regarding Vietnamese POS tagging, Dien and
Kiem (2003) projected POS annotations from En-
glish to Vietnamese via a bilingual corpus of word
alignments. As a standard sequence labeling task,
previous research has applied the CRF, SVM or
MaxEnt model to assign each word a POS tag
(Nghiem et al., 2008; Tran et al., 2009; Le-Hong
et al., 2010; Nguyen et al., 2010; Tran et al.,
2010; Bach et al., 2013). In addition, Nguyen et al.
(2011) proposed a rule-based approach to auto-
matically construct transformation rules for POS
tagging in the form of a Ripple Down Rules tree
(Compton and Jansen, 1990), leading to a devel-
opment of the RDRPOSTagger (Nguyen et al.,
2014a) which was the best system for the POS tag-
ging shared task at the 2013 Vietnamese Language
and Speech Processing (VLSP) workshop.

Nguyen et al. (2016a) and Nguyen et al. (2016b)
later showed that SOTA accuracies at 94+% in
the Vietnamese POS tagging task are obtained by
simply retraining existing English POS taggers on
Vietnamese data, showing that the MarMoT tagger
(Mueller et al., 2013) and the Stanford POS tagger
(Toutanova et al., 2003) obtain higher accuracies
than RDRPOSTagger. Nguyen et al. (2016a) also
showed that a simple lexicon-based approach as-
signing each word by its most probable POS tag
gains a promising accuracy at 91%. Note that both
Nguyen et al. (2016a) and Nguyen et al. (2016b)

did not experiment with neural network models.
Pham et al. (2017) recently applied the BiLSTM-
CNN-CRF (Ma and Hovy, 2016) for Vietnamese
POS tagging, however, they did not experiment
with SOTA feature-based models.

Previously, only Takahashi and Yamamoto
(2016) carried out joint word segmentation and
POS tagging for Vietnamese, to predicting a com-
bined segmentation and POS tag to each sylla-
ble. In particular, Takahashi and Yamamoto (2016)
experimented with traditional SVM- and CRF-
based toolkits on a dataset of about 7k sentences
and reported results of joint prediction only, i.e.,
they did not compare to the pipeline strategy. The
CoNLL 2017 shared task on Universal Dependen-
cies (UD) parsing from raw text (Zeman et al.,
2017) provided some results to the pipeline strat-
egy from word segmentation to POS tagging, how-
ever, the Vietnamese dataset in the UD project
is very small, consisting of 1,400 training sen-
tences. Furthermore, Nguyen et al. (2017a) pro-
vided a pre-trained jPTDP model for joint POS
tagging and dependency parsing for Vietnamese,2
which obtains a tagging accuracy at 93.0%, a UAS
score at 77.7% and a LAS score at 69.5% when
evaluated on the Vietnamese dependency treebank
VnDT of 10k sentences (Nguyen et al., 2014b).

3 Experimental methodology

We compare the joint word segmentation and POS
tagging strategy to the pipeline strategy on the
benchmark Vietnamese treebank (Nguyen et al.,
2009) using well-known POS tagging models.

3.1

Joint segmentation and POS tagging

Following Kruengkrai et al. (2009), Takahashi and
Yamamoto (2016) and Shao et al. (2017), we for-
malize the joint word segmentation and POS tag-
ging problem for Vietnamese as a sequence la-
beling task to assigning a combined segmenta-
tion and POS tag to each syllable. For exam-
ple, given a manually POS-annotated training cor-
pus “Cuộc/Nc điều_tra/V dường_như/X không/R
tiến_triển/V ./CH” ‘The investigation seems to
be making no progress’, we transform this cor-
pus into a syllable-based representation as follows:
“Cuộc/B-Nc điều/B-V tra/I-V dường/B-X như/I-X
không/B-R tiến/B-V triển/I-V ./B-CH”, where seg-
mentation tags B and I denote beginning and in-

2https://drive.google.com/drive/
folders/0B5eBgc8jrKtpUmhhSmtFLWdrTzQ

side of a word, respectively, while Nc, V, X, R and
CH are POS tags. Then we train sequence labeling
models on the syllable-based transformed corpus.

3.2 Dataset

The Vietnamese treebank (Nguyen et al., 2009) is
the largest annotated corpus for Vietnamese, pro-
viding a set of 27,870 manually POS-annotated
sentences for training and development (about 23
words per sentence on average) and a test set of
2120 manually POS-annotated sentences (about
31 words per sentence).3 From the set of 27,870
sentences, we use the first 27k sentences for train-
ing and the last 870 sentences for development.

3.3 Models

For both joint and pipeline strategies, we use the
following models:

• RDRPOSTagger (Nguyen et al., 2014a) is
a transformation rule-based learning model
which obtained the highest accuracy at the
VLSP 2013 POS tagging shared task.4

• MarMoT (Mueller et al., 2013) is a generic
CRF framework and a SOTA POS and mor-
phological tagger.5

• BiLSTM-CRF (Huang et al., 2015) is a se-
quence labeling model which extends the
BiLSTM model with a CRF layer.

• BiLSTM-CRF + CNN-char, i.e. BiLSTM-
CNN-CRF, is an extension of the BiLSTM-
CRF, using CNN to derive character-based
representations (Ma and Hovy, 2016).

• BiLSTM-CRF + LSTM-char is another ex-
tension of the BiLSTM-CRF, using BiLSTM
to derive the character-based representations
(Lample et al., 2016).

Here, for the pipeline strategy, we train these
models to predict POS tags with respect to (w.r.t.)
gold word segmentation. In addition, we also re-
train the fast and accurate Vietnamese word seg-
menter RDRsegmenter (Nguyen et al., 2017b) us-
ing the training set of 27k sentences.6

3The data was officially used for the Vietnamese POS tag-

ging shared task at the second VLSP 2013 workshop.

4http://rdrpostagger.sourceforge.net
5http://cistern.cis.lmu.de/marmot
6RDRsegmenter obtains a segmentation speed at 60k
words per second, computed on a personal computer of In-
tel Core i7 2.2 GHz. RDRsegmenter is available at: https:
//github.com/datquocnguyen/RDRsegmenter

Model
BiLSTM-CRF
+ CNN-char
+ LSTM-char

Pipeline
100
100
150

Joint
200
250
250

Table 1: Optimal number of LSTM units.

3.4

Implementation details

We use the original pure Java implementations of
RDRPOSTagger and MarMoT with default hyper-
parameter settings in our experiments. Instead of
using implementations independently provided by
authors of BiLSTM-CRF, BiLSTM-CRF + CNN-
char7 and BiLSTM-CRF + LSTM-char, we use
a reimplementation which is optimized for per-
formance of all these models from Reimers and
Gurevych (2017).8

For three BiLSTM-CRF-based models, we use
default hyper-parameters provided by Reimers and
Gurevych (2017) with the following exceptions:
we use a dropout rate at 0.5 (Ma and Hovy, 2016)
with the frequency threshold of 5 for unknown
word and syllable types. We initialize word and
syllable embeddings with 100-dimensional pre-
trained embeddings,9 then learn them together
with other model parameters during training by us-
ing Nadam (Dozat, 2016). For training, we run for
100 epochs. We perform a grid search of hyper-
parameters to select the number of BiLSTM lay-
ers from {1, 2, 3} and the number of LSTM units
in each layer from {50, 100, 150, 200, 250, 300}.
Early stopping is applied when no performance
improvement on the development set is obtained
after 5 contiguous epochs. For both pipeline and
joint strategies, we find the highest performance
on the development set is when using two stacked
BiLSTM layers. Table 1 presents the optimal num-
ber of LSTM units.

Here the performance is evaluated by F1 score,
based on the number of correctly segmented and
tagged words (Zhang and Clark, 2008). In the case
of gold word segmentation, F1 score for POS tag-
ging is in fact the tagging accuracy.

7https://github.com/XuezheMax/

LasagneNLP

8https://github.com/UKPLab/

emnlp2017-bilstm-cnn-crf

9Pre-trained word and syllable embeddings are learned
(Mikolov
by training the Word2Vec Skip-gram model
et al., 2013) on a Vietnamese news corpus which is avail-
able at: http://mim.hus.vnu.edu.vn/phuonglh/
corpus/baomoi.zip

Model
RDRPOSTagger
MarMoT
BiLSTM-CRF
+ CNN-char
+ LSTM-char

Accuracy
95.11
95.88
95.06
95.40
95.31

Speed
180k
25k
3k
2.5k
1.5k

Table 2: POS tagging accuracies (in %) on the test
set w.r.t. gold word segmentation. “Speed” denotes
the tagging speed, i.e. the number of words per
second, computed on a personal computer of Intel
Core i7 2.2 GHz (model loading time is not taken
into account).

4 Main results

Table 2 presents POS tagging accuracy and tag-
ging speed of each model on the test set w.r.t.
gold word segmentation, in which MarMoT is
the most accurate model while RDRPOSTagger
is the fastest one. In particular, MarMoT obtains
0.5%+ higher accuracy than the three BiLSTM-
based models. This is not surprising as the training
set of 27k sentences is relatively small compared
to the training data available in other languages
such as English or Chinese.

Table 3 presents F1 scores for word segmenta-
tion and POS tagging in a real-world application
scenario where the gold word-segmentation is not
available. Comparing the results in Table 2 to re-
sults for the pipeline strategy, we observe a drop
of about 2% for all models when using predicted
segmentation instead of gold segmentation. Also,
Table 3 clearly shows that the pipeline strategy
helps produce better results than the joint strategy.
In addition, pre-designed features in both RDR-
POSTagger and MarMoT are designed to capture
word-level information rather than syllable-level
information, so it is also not surprising that for
the joint strategy RDRPOSTagger is significantly
lower while MarMoT is lower than the BiLSTM-
CRF model with additional character-based repre-
sentations.

Tables 2 and 3 suggest that for a practical ap-
plication to Vietnamese where performance accu-
racy is preferred, we should consider using the
pipeline strategy with a traditional SOTA feature-
based tagger such as MarMoT. If speed is preferred
such as in big data, RDRPOSTagger would be a
superior alternative. With the current state of train-
ing data available in Vietnamese, future research
should focus on incorporating Vietnamese linguis-

e
n
i
l
e
p
i
P

t
n
i
o
J

Model

RDRPOSTagger
MarMoT
BiLSTM-CRF
+ CNN-char
+ LSTM-char
RDRPOSTagger
MarMoT
BiLSTM-CRF
+ CNN-char
+ LSTM-char

WSeg PTag
93.39
97.75
93.96
97.75
93.25
97.75
93.55
97.75
93.46
97.75
87.53
93.73
92.78
96.50
92.43
96.15
92.79
96.66
92.95
96.76

Table 3: F1 scores (in %) for word segmenta-
tion (WSeg) and POS tagging (PTag) from unseg-
mented text. The pipeline strategy uses RDRseg-
menter for word segmentation. In preliminary ex-
periments, where we also train the five models
above to predict a segmentation tag B or I for
each syllable, we then find that RDRsegmenter ob-
tains better word segmentation score than those
five models.

tic features into the traditional feature-based se-
quence taggers.

5 Conclusion

We have presented empirical comparisons be-
tween two strategies for Vietnamese POS tag-
ging from unsegmented text and between SOTA
feature- and neural network-based models. Ex-
perimental results on the benchmark Vietnamese
treebank (Nguyen et al., 2009) show that
the
pipeline strategy produces higher scores of POS
tagging from unsegmented text than the joint strat-
egy. In addition, we also show that a traditional
feature-based model (i.e. MarMoT) obtains bet-
ter POS tagging accuracy than neural network-
based models. We provide a pre-trained MarMoT
model for Vietnamese POS tagging at https://
github.com/datquocnguyen/VnMarMoT.

Acknowledgments

This research was partially supported by the
Australian Government
through the Australian
Research Council’s Discovery Projects funding
scheme (project DP160102156). This research
was also partially supported by NICTA, funded
by the Australian Government through the Depart-
ment of Communications and the Australian Re-
search Council through the ICT Centre of Excel-
lence Program.

References

Ngo Xuan Bach, Kunihiko Hiraishi, Nguyen Le Minh,
and Akira Shimazu. 2013. Dual decomposition for
Vietnamese part-of-speech tagging. In Proceedings
of the 17th International Conference on Knowledge
Based and Intelligent Information and Engineering
Systems. pages 123–131.

P. Compton and R. Jansen. 1990. A Philosophical Ba-
sis for Knowledge Acquisition. Knowledge Aquisi-
tion 2(3):241–257.

Wuying Liu and Li Lin. 2014. Probabilistic Ensemble
In
Learning for Vietnamese Word Segmentation.
Proceedings of the 37th International ACM SIGIR
Conference on Research & Development in Informa-
tion Retrieval. pages 931–934.

Xuezhe Ma and Eduard Hovy. 2016. End-to-end Se-
quence Labeling via Bi-directional LSTM-CNNs-
CRF. In Proceedings of the 54th Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers). pages 1064–1074.

Dinh Dien and Hoang Kiem. 2003. POS-Tagger for
English-Vietnamese Bilingual Corpus. In Proceed-
ings of the HLT-NAACL 2003 Workshop on Build-
ing and Using Parallel Texts: Data Driven Machine
Translation and Beyond. pages 88–95.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed Representa-
tions of Words and Phrases and their Composition-
ality. In Advances in Neural Information Processing
Systems 26. pages 3111–3119.

Dinh Dien, Hoang Kiem, and Nguyen Van Toan. 2001.
Vietnamese Word Segmentation. In Proceedings of
the Sixth Natural Language Processing Pacific Rim
Symposium. pages 749–756.

Dien Dinh and Thuy Vu. 2006. A Maximum Entropy
In
Approach for Vietnamese Word Segmentation.
Proceedings of the 2006 International Conference
on Research, Innovation and Vision for the Future.
pages 248–253.

Timothy Dozat. 2016. Incorporating Nesterov Momen-
tum into Adam. In Proceedings of the ICLR 2016
Workshop Track.

Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidi-
rectional LSTM-CRF models for sequence tagging.
arXiv preprint arXiv:1508.01991.

Canasai Kruengkrai, Kiyotaka Uchimoto, Jun’ichi
Kazama, Yiou Wang, Kentaro Torisawa, and Hitoshi
Isahara. 2009. An Error-Driven Word-Character
Hybrid Model for Joint Chinese Word Segmentation
and POS Tagging. In Proceedings of the 47th An-
nual Meeting of the ACL and the 4th IJCNLP of the
AFNLP. pages 513–521.

Guillaume Lample, Miguel Ballesteros, Sandeep Sub-
ramanian, Kazuya Kawakami, and Chris Dyer. 2016.
Neural Architectures for Named Entity Recognition.
In Proceedings of the 2016 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies.
pages 260–270.

Hong Phuong Le, Thi Minh Huyen Nguyen, Azim
Roussanaly, and Tuong Vinh Ho. 2008. A hybrid
approach to word segmentation of Vietnamese texts.
In Proceedings of the 2nd International Conference
on Language and Automata Theory and Applica-
tions. pages 240–249.

Phuong Le-Hong, Azim Roussanaly, Thi Minh Huyen
Nguyen, and Mathias Rossignol. 2010. An empir-
ical study of maximum entropy approach for part-
of-speech tagging of Vietnamese texts. In Proceed-
ings of the Traitement Automatique des Langues Na-
turelles.

Thomas Mueller, Helmut Schmid,

and Hinrich
Sch¨utze. 2013. Efficient Higher-Order CRFs for
In Proceedings of the
Morphological Tagging.
2013 Conference on Empirical Methods on Natural
Language Processing. pages 322–332.

Liang NanYuan and Zheng YanBin. 1991. A Chinese
word segmentation model and a Chinese word seg-
mentation system PC-CWSS. Journal of Chinese
Language and Computing 1(1).

Minh Nghiem, Dien Dinh, and Mai Nguyen. 2008. Im-
proving Vietnamese POS tagging by integrating a
rich feature set and Support Vector Machines.
In
Proceedings of the 2008 IEEE International Con-
ference on Research, Innovation and Vision for the
Future in Computing and Communication Technolo-
gies. pages 128–133.

Cam-Tu Nguyen, Trung-Kien Nguyen, Xuan-Hieu
Phan, Le-Minh Nguyen, and Quang-Thuy Ha. 2006.
Vietnamese Word Segmentation with CRFs and
SVMs: An Investigation. In Proceedings of the 20th
Pacific Asia Conference on Language, Information
and Computation. pages 215–222.

Dat Quoc Nguyen, Mark Dras, and Mark Johnson.
2017a. A Novel Neural Network Model for Joint
POS Tagging and Graph-based Dependency Pars-
In Proceedings of the CoNLL 2017 Shared
ing.
Task: Multilingual Parsing from Raw Text to Uni-
versal Dependencies. pages 134–142.

Dat Quoc Nguyen, Dai Quoc Nguyen, Dang Duc Pham,
and Son Bao Pham. 2014a. RDRPOSTagger: A Rip-
ple Down Rules-based Part-Of-Speech Tagger.
In
Proceedings of the Demonstrations at the 14th Con-
ference of the European Chapter of the Association
for Computational Linguistics. pages 17–20.

Dat Quoc Nguyen, Dai Quoc Nguyen, Dang Duc
Pham, and Son Bao Pham. 2016a. A Robust
Transformation-Based Learning Approach Using
Ripple Down Rules for Part-of-Speech Tagging. AI
Communications 29(3):409–422.

Yan Shao, Christian Hardmeier, J¨org Tiedemann, and
Joakim Nivre. 2017. Character-based Joint Segmen-
tation and POS Tagging for Chinese using Bidirec-
tional RNN-CRF. In Proceedings of the 8th Interna-
tional Joint Conference on Natural Language Pro-
cessing. page to appear.

Kanji Takahashi and Kazuhide Yamamoto. 2016. Fun-
damental tools and resource are available for Viet-
namese analysis. In Proceedings of the 2016 Inter-
national Conference on Asian Language Processing.
pages 246–249.

Kristina Toutanova, Dan Klein, Christopher D. Man-
ning, and Yoram Singer. 2003. Feature-rich Part-of-
speech Tagging with a Cyclic Dependency Network.
In Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology -
Volume 1. pages 173–180.

Ngoc Anh Tran, Thanh Tinh Dao, and Phuong Thai
Nguyen. 2012. An effective context-based method
for Vietnamese-word segmentation. In Proceedings
of First International Workshop on Vietnamese Lan-
guage and Speech Processing. pages 34–40.

Oanh Thi Tran, Cuong Anh Le, Thuy Quang Ha, and
Quynh Hoang Le. 2009. An Experimental Study
on Vietnamese POS Tagging. In Proceedings of the
2009 International Conference on Asian Language
Processing. pages 23–27.

Thi Oanh Tran, Anh Cuong Le, and Quang Thuy Ha.
Improving Vietnamese Word Segmentation
2010.
and POS Tagging using MEM with Various Kinds of
Resources. Journal of Natural Language Processing
17(3):41–60.

Daniel Zeman, Martin Popel, Milan Straka, Jan Ha-
jic, Joakim Nivre, et al. 2017. CoNLL 2017 Shared
Task: Multilingual Parsing from Raw Text to Uni-
versal Dependencies. In Proceedings of the CoNLL
2017 Shared Task: Multilingual Parsing from Raw
Text to Universal Dependencies. pages 1–19.

Yue Zhang and Stephen Clark. 2008. Joint Word Seg-
mentation and POS Tagging Using a Single Percep-
tron. In Proceedings of the 46th Annual Meeting of
the Association for Computational Linguistics: Hu-
man Language Technologies. pages 888–896.

Dat Quoc Nguyen, Dai Quoc Nguyen, Son Bao Pham,
Phuong-Thai Nguyen, and Minh Le Nguyen. 2014b.
From Treebank Conversion to Automatic Depen-
In Proceedings
dency Parsing for Vietnamese.
of 19th International Conference on Application of
Natural Language to Information Systems. pages
196–207.

Dat Quoc Nguyen, Dai Quoc Nguyen, Son Bao Pham,
and Dang Duc Pham. 2011. Ripple Down Rules
In Proceedings of the
for Part-of-Speech Tagging.
12th International Conference on Intelligent Text
Processing and Computational Linguistics - Volume
Part I. pages 190–201.

Dat Quoc Nguyen, Dai Quoc Nguyen, Thanh Vu, Mark
Dras, and Mark Johnson. 2017b. A Fast and Ac-
curate Vietnamese Word Segmenter. arXiv preprint
arXiv:1709.06307.

Le Minh Nguyen, Xuan Bach Ngo, Viet Cuong
Nguyen, Quang Nhat Minh Pham, and Akira Shi-
mazu. 2010. A Semi-supervised Learning Method
In Pro-
for Vietnamese Part-of-Speech Tagging.
ceedings of the International Conference on Knowl-
edge and Systems Engineering. pages 141–146.

Phuong Thai Nguyen, Xuan Luong Vu, Thi
Minh Huyen Nguyen, Van Hiep Nguyen, and
Building a Large
Hong Phuong Le. 2009.
Syntactically-Annotated Corpus of Vietnamese.
In Proceedings of the Third Linguistic Annotation
Workshop. pages 182–185.

Tuan-Phong Nguyen and Anh-Cuong Le. 2016. A Hy-
brid Approach to Vietnamese Word Segmentation.
In Proceedings of the 2016 IEEE RIVF Interna-
tional Conference on Computing and Communica-
tion Technologies: Research, Innovation, and Vision
for the Future. pages 114–119.

Tuan Phong Nguyen, Quoc Tuan Truong, Xuan Nam
Nguyen, and Anh Cuong Le. 2016b. An Experimen-
tal Investigation of Part-Of-Speech Taggers for Viet-
namese. VNU Journal of Science: Computer Sci-
ence and Communication Engineering 32(3):11–25.

Dang Duc Pham, Giang Binh Tran, and Son Bao Pham.
2009. A Hybrid Approach to Vietnamese Word Seg-
mentation using Part of Speech tags. In Proceedings
of the 2009 International Conference on Knowledge
and Systems Engineering. pages 154–161.

Thai-Hoang Pham, Xuan-Khoai Pham, Tuan-Anh
Nguyen, and Phuong Le-Hong. 2017. NNVLP: A
Neural Network-Based Vietnamese Language Pro-
cessing Toolkit. In Proceedings of the IJCNLP 2017
System Demonstrations. page to appear.

Nils Reimers and Iryna Gurevych. 2017. Report-
ing Score Distributions Makes a Difference: Perfor-
mance Study of LSTM-networks for Sequence Tag-
In Proceedings of the 2017 Conference on
ging.
Empirical Methods in Natural Language Process-
ing. pages 338–348.

