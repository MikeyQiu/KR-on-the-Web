3
1
0
2
 
v
o
N
8

 

 
 
]
E
M

.
t
a
t
s
[
 
 
2
v
1
3
7
1
.
1
1
3
1
:
v
i
X
r
a

Stochastic blockmodel approximation of a graphon:
Theory and consistent estimation∗

Edoardo M. Airoldi
Dept. Statistics
Harvard University

Thiago B. Costa
SEAS, and Dept. Statistics
Harvard University

Stanley H. Chan
SEAS, and Dept. Statistics
Harvard University

Abstract

Non-parametric approaches for analyzing network data based on exchangeable
graph models (ExGM) have recently gained interest. The key object that deﬁnes
an ExGM is often referred to as a graphon. This non-parametric perspective on
network modeling poses challenging questions on how to make inference on the
graphon underlying observed network data. In this paper, we propose a computa-
tionally efﬁcient procedure to estimate a graphon from a set of observed networks
generated from it. This procedure is based on a stochastic blockmodel approxi-
mation (SBA) of the graphon. We show that, by approximating the graphon with
a stochastic block model, the graphon can be consistently estimated, that is, the
estimation error vanishes as the size of the graph approaches inﬁnity.

1 Introduction

Revealing hidden structures of a graph is the heart of many data analysis problems. From the well-
known small-world network to the recent large-scale data collected from online service providers
such as Wikipedia, Twitter and Facebook, there is always a momentum in seeking better and
more informative representations of the graphs (Fienberg et al. 1985; Nowicki and Snijders 2001a;
Hoff et al. 2002; Handcock et al. 2007; Airoldi et al. 2008; Xu et al. 2012; Azari and Airoldi 2012;
Tang et al. 2013; Goldenberg et al. 2009; Kolaczyk 2009). In this paper, we develop a new com-
putational tool to study one type of non-parametric representations which recently draws signiﬁ-
cant attentions from the community (Bickel and Chen 2009; Lloyd et al. 2012; Bickel et al. 2011;
Zhao et al. 2011; Orbanz and Roy 2013).

The root of the non-parametric model discussed in this paper is in the theory of exchange-
able random arrays (Aldous 1981; Hoover 1979; Kallenberg 1989), and it
is presented in
(Diaconis and Janson 2008) as a link connecting de Finetti’s work on partial exchangeability and
graph limits (Lov´asz and Szegedy 2006; Borgs et al. 2006). In a nutshell, the theory predicts that
every convergent sequence of graphs (Gn) has a limit object that preserves many local and global
properties of the graphs in the sequence. This limit object, which is called a graphon, can be rep-
resented by measurable functions w : [0, 1]2
[0, 1], in a way that any w′ obtained from measure
preserving transformations of w describes the same graphon.

→

Graphons are usually seen as kernel functions for random network models (Lawrence 2005). To
construct an n-vertex random graph
(n, w) for a given w, we ﬁrst assign a random label ui ∼
Uniform[0, 1] to each vertex i
, and connect any two vertices i and j with probability
w(ui, uj), i.e.,

G
1, . . . , n

}

(1)
where G[i, j] denotes the (i, j)th entry of the adjacency matrix representing a particular realization
of
(n, w) (See Figure 1). As an example, we note that the stochastic block-model is the case where
w(x, y) is a piecewise constant function.

ui, uj) = w(ui, uj),

i, j = 1, . . . , n,

G

|

∈ {
Pr (G[i, j] = 1

∗This paper appears in the proceedings of NIPS 2013. In this version we include an appendix with proofs.

1

w

w(ui, uj)

×

uj

G2T

ui

(ui, uj)

G1

[Left] Given a graphon w :

[0, 1]2
samples ui, uj from
Figure 1:
Uniform[0,1] and assign Gt[i, j] = 1 with probability w(ui, uj), for t = 1, . . . , 2T .
[Middle]
Heat map of a graphon w. [Right] A random graph generated by the graphon shown in the middle.
Rows and columns of the graph are ordered by increasing ui, instead of i for better visualization.

[0, 1], we draw i.i.d.

→

The problem of interest is deﬁned as follows: Given a sequence of 2T observed directed graphs
G1, . . . , G2T , can we make an estimate
w with high probability as n goes to
w of w, such that
inﬁnity? This question has been loosely attempted in the literature, but none of which has a complete
solution. For example, Lloyd et al. (Lloyd et al. 2012) proposed a Bayesian estimator without a
consistency proof; Choi and Wolfe (Choi and Wolfe) studied the consistency properties, but did not
provide algorithms to estimate the graphon. To the best of our knowledge, the only method that
estimates graphons consistently, besides ours, is USVT (Chatterjee). However, our algorithm has
better complexity and outperforms USVT in our simulations. More recently, other groups have
begun exploring approaches related to ours (Wolfe and Olhede 2013; P.Latouche and Robin 2013).

→

w

b

b

The proposed approximation procedure requires w to be piecewise Lipschitz. The basic idea is to
approximate w by a two-dimensional step function
w with diminishing intervals as n increases.The
proposed method is called the Stochastic blockmodel approximation (SBA) algorithm, as the idea
of using a two-dimensional step function for approximation is equivalent to using the stochastic
block models (Choi et al. 2012; Nowicki and Snijders 2001a; Hoff 2008; Channarond et al. 2012;
Rohe et al. 2011). The SBA algorithm is deﬁned up to permutations of the nodes, so the estimated
graphon is not canonical. However, this does not affect the consistency properties of the SBA
algorithm, as the consistency is measured w.r.t. the graphon that generates the graphs.

b

2 Stochastic blockmodel approximation: Procedure

In this section we present the proposed SBA algorithm and discuss its basic properties.

2.1 Assumptions on graphons

We assume that w is piecewise Lipschitz, i.e., there exists a sequence of non-overlaping intervals
1, αk] deﬁned by 0 = α0 < . . . < αK = 1, and a constant L > 0 such that, for any
Ik = [αk
−
(x1, y1) and (x2, y2)

Ij ,

x1 −
For generality we assume w to be asymmetric i.e., w(u, v)
can be considered as a special case. Consequently, a random graph
directed, i.e., G[i, j]

x2|
= w(v, u), so that symmetric graphons
(n, w) generated by w is

w(x2, y2)

= G[j, i].

y1 −

L (
|

y2|

| ≤

) .

+

G

|

|

∈

Iij = Ii ×
w(x1, y1)
−

2.2 Similarity of graphon slices

The intuition of the proposed SBA algorithm is that if the graphon is smooth, neighboring cross-
sections of the graphon should be similar. In other words, if two labels ui and uj are close i.e.,

2

ui −
|
w(
·
|
graphon slices, we deﬁne the following distance

0, then the difference between the row slices
w(
·

and the column slices
w(ui,
should also be small. To measure the similarity between two labels using the

uj| ≈
, ui)
−

, uj)
|

w(uj,

)
|

−

)

|

·

·

dij =

1
2

1

0
(cid:18)Z

[w(x, ui)

w(x, uj )]2 dx +

[w(ui, y)

w(uj , y)]2 dy

.

(2)

−

(cid:19)

1

0
Z

Thus, dij is small only if both row and column slices of the graphon are similar.

The usage of dij for graphon estimation will be discussed in the next subsection. But before
we proceed, it should be noted that in practice dij has to be estimated from the observed graphs
G1, . . . , G2T . To derive an estimator
dij of dij, it is helpful to express dij in a way that the estima-
tors can be easily obtained. To this end, we let

−

b

cij =

w(x, ui)w(x, uj )dx

and

rij =

w(ui, y)w(uj , y)dy,

1

0
Z

and express dij as dij = 1
(cii −
2
we consider the following estimators for cij and rij :
h

cji +cjj )+(rii −

cij −

rij −

. Inspecting this expression,

1

0
Z
rji +rjj )
i

(3)

(4)

(5)

ck
ij =

b
rk
ij =

1
T 2 



1
T 2 

b

Gt1 [k, i]

Gt2 [k, j]

X1
t1≤
≤

T

XT <t2≤

2T

Gt1 [i, k]

Gt2 [j, k]

X1
t1≤
≤

T



XT <t2≤

2T

















,

.









Here, the superscript k can be interpreted as the dummy variables x and y in deﬁning cij and rij ,
respectively. Summing all possible k’s yields an estimator

dij that looks similar to dij :

dij =

1
2 "

1
S

rk
ii −

rk
ij −

rk
ji +

rk
jj

+

b
ck
ii −

ck
ij −

ck
ji +

ck
jj

Xk
∈S (cid:8)(cid:0)

(cid:0)
b
b
is the set of summation indices.

b

b

b

(cid:1)

b

b

b

,

#

(cid:1)(cid:9)

where

=

1, . . . , n

b

S

{

i, j

}\{

}

]

1

≤

t1≤

is w(ui,

T Gt1 [i,

The motivation of deﬁning the estimators in (3) and (4) is that a row of the adjacency matrix G[i,
]
·
). Thus the expected value of
is fully characterized by the corresponding row of the graphon w(ui,
1
rk
ij is an estimator for rij. To theoretically
k
T
∈S
justify this intuition, we will show in Section 3 that
dij is indeed a good estimator: it is not only
P
unbiased, but is also concentrated round dij for large n. Furthermore, we will show that it is possible
to achieve the same asymptotic behavior.
to use a random subset of
}\{
As a result, the estimation of dij can be performed locally in a neighborhood of i and j, instead of
all n vertices.

), and hence 1
S

instead of

1, . . . , n

(cid:16)P

i, j
b

S

(cid:17)

b

{

}

·

·

·

2.3 Blocking the vertices

The similarity metric
wise constant function
(unknown) labels
u1, . . . , un}
b
BK are deﬁned, we can then determine
the blocks
b
b
Bj:
frequency of edges that are present across blocks

dij discussed above suggests one simple method to approximate w by a piece-
w (i.e., a stochastic block-model). Given G1, . . . , G2T , we can cluster the
BK using a procedure described below. Once
w(ui, uj) by computing the empirical

into K blocks

{
B1, . . . ,

b
Bi and

B1, . . . ,

b
w(ui, uj) =

b

1
Bi| |
b

b

Bj| Xix∈
b
where
estimate of the expected number of edges linking block

b
Bi is the block containing ui so that summing Gt[x, y] over x

b
b
Bj
Bi Xjy∈

|

Bi and

Bj.

1
2T

b

(G1[ix, jy] + G2[ix, jy] + . . . + G2T [ix, jy]) ,

b

b

(6)

Bi and y

Bj yields an

∈

b

∈

b

b

b

3

To cluster the unknown labels
1. Starting with Ω =
other vertices iv ∈
Ω
precision parameter ∆ > 0. If
after scanning through Ω once, a block
Ω

{
u1, . . . , un}
{
ip}
\{

B1, the process repeats until Ω =
b

←

Ω

b

\

B1 =
.

∅

u1, . . . , un}
, we compute the distance

we propose a greedy approach as shown in Algorithm
, we randomly pick a node ip and call it the pivot. Then for all
dip,iv < ∆2 for some
dip,iv and check whether
dip,iv < ∆2, then we assign iv to the same block as ip. Therefore,
will be deﬁned. By updating Ω as

b

b

b

The proposed greedy algorithm is only a local solution in a sense that it does not return the globally
optimal clusters. However, as will be shown in Section 3, although the clustering algorithm is not
globally optimal, the estimated graphon
w is still guaranteed to be a consistent estimate of the true
graphon w as n
. Since the greedy algorithm is numerically efﬁcient, it serves as a practical
computational tool to estimate w.

→ ∞

ip, iv1, iv2 , . . .
}

{

b

2.4 Main algorithm

Algorithm 1 Stochastic blockmodel approximation

Input: A set of observed graphs G1, . . . , G2T and the precision parameter ∆.
Output: Estimated stochastic blocks
Initialize: Ω =
{
do
while Ω

, and k = 1.
b

B1, . . . ,

1, . . . , n

BK.

=

b

}

Randomly choose a vertex ip from Ω and assign it as the pivot for
for Every other vertices iv ∈

Ω

∅

do
ip}
dip,iv .

ip.

Bk:

b

Bk ←
b

∆2, then assign iv as a member of

Bk:

\{
Compute the distance estimate
If
dip,iv ≤
end for
Update Ω: Ω
Ω
b
Update counter: k

k + 1.

Bk.

←

b

\
←
b

end while

iv.

Bk ←
b

b

Algorithm 1 illustrates the pseudo-code for the proposed stochastic block-model approximation.
The complexity of this algorithm is
(T SKn), where T is half the number of observations, S is
the size of the neighborhood, K is the number of blocks and n is number of vertices of the graph.

O

3 Stochastic blockmodel approximation: Theory of estimation

In this section we present the theoretical aspects of the proposed SBA algorithm. We will ﬁrst
discuss the properties of the estimator
dij, and then show the consistency of the estimated graphon
w. Details of the proofs can be found in the supplementary material.

b
3.1 Concentration analysis of

dij

b

Our ﬁrst theorem below shows that the proposed estimator
around its expected value dij.

b

dij is both unbiased, and is concentrated

Theorem 1. The estimator

dij for dij is unbiased, i.e., E[

dij ] = dij . Further, for any ǫ > 0,

b

dij −
h(cid:12)
(cid:12)
where S is the size of the neighborhood
(cid:12) b

Pr

b

(cid:12)
(cid:12)
(cid:12)

S

≤

i

dij

> ǫ

Sǫ2
b
8e−
32/T +8ǫ/3 ,

, and 2T is the number of observations.

(7)

Proof. Here we only highlight the important steps to present the intuition. The basic idea of the
rk
ij and show that it is unbiased. To this end, we use the
proof is to zoom-in a microscopic term of

b

4

fact that Gt1 [i, k] and Gt2 [j, k] are conditionally independent on uk to show

E[Gt1 [i, k]Gt2[j, k]

uk] = Pr[Gt1 [i, k] = 1, Gt2[j, k] = 1

uk]

|

|

(a)
= Pr[Gt1 [i, k] = 1
= w(ui, uk)w(uj , uk),

|

uk] Pr[Gt2 [j, k] = 1

uk]

|

rk
ij ] =
uk]] = rij . The concentration inequality follows from a similar idea to bound the variance

uk] = w(ui, uk)w(uj , uk), and by iterated expectation we have E[

rk
ij |

which then implies E[
E[E[
rk
ij |
rk
ij and apply Bernstein’s inequality.
of
b
b

b

b

That Gt1[i, k] and Gt2[j, k] are conditionally independent on uk is a critical fact for the success of
the proposed algorithm. It also explains why at least 2 independently observed graphs are necessary,
for otherwise we cannot separate the probability in the second equality above marked with (a).

3.2 Choosing the number of blocks

The performance of the Algorithm 1 is sensitive to the number of blocks it deﬁnes. On the one hand,
it is desirable to have more blocks so that the graphon can be ﬁnely approximated. But on the other
hand, if the number of blocks is too large then each block will contain only few vertices. This is bad
because in order to estimate the value on each block, a sufﬁcient number of vertices in each block is
required. The trade-off between these two cases is controlled by the precision parameter ∆: a large
∆ generates few large clusters, while small ∆ generates many small clusters. A precise relationship
between the ∆ and K, the number of blocks generated the algorithm, is given in Theorem 2.
Theorem 2. Let ∆ be the accuracy parameter and K be the number of blocks estimated by Algo-
rithm 1, then

Pr

K >

"

QL√2

∆ # ≤

8n2e−

S∆4
128/T +16∆2/3 ,

where L is the Lipschitz constant and Q is the number of Lipschitz blocks in w.

In practice, we estimate ∆ using a cross-validation scheme to ﬁnd the optimal 2D histogram bin
width (Wasserman 2005). The idea is to test a sequence of potential values of ∆ and seek the one
that minimizes the cross validation risk, deﬁned as

J(∆) =

b

2

−

h(n

1) −

h(n

1)

n + 1

K

−

j=1
X

p2
j ,

b

/n and h = 1/K. Algorithm 2 details the proposed cross-validation scheme.

(8)

(9)

|

b

where

pj =

Bj|
b
Algorithm 2 Cross Validation
Input: Graphs G1, . . . , G2T .
Output: Blocks
B1, . . . ,
for a sequence of ∆’s do

Estimate blocks
B1, . . . ,
b
b
Compute
Bj|
pj =
|
b
J(∆) = 2
Compute
h(n
−
b
end for
b
Pick the ∆ with minimum
b

3.3 Consistency of

w

BK, and optimal ∆.

BK from G1, . . . , G2T . [Algorithm 1]

/n, for j = 1, . . . , K.
K
j=1

n+1

h(n

1)

b
1) −

−

p2
j , with h = 1/K.

P
J(∆), and the corresponding

b

B1, . . . ,

BK.

b

b

b

The goal of our next theorem is to show that
b
To begin with, let us ﬁrst recall two commonly used metric:

w is a consistent estimate of w, i.e.,

w

w as n

.
→ ∞

b

5

→

b

Deﬁnition 1. The mean squared error (MSE) and mean absolute error (MAE) are deﬁned as

(w(uiv , ujv )

w(uiv , ujv ))2

−

w(uiv , ujv )

b
w(uiv , ujv )
|

.

−

b
o(1), then

MSE(

w) =

MAE(

b
w) =

1
n2

1
n2

b

n

n

iv =1
X
n

jv =1
X
n

|

1
4

iv =1
X

jv =1
X

log(n)
n

∈

(cid:18)(cid:16)
w)] = 0

∩

(cid:19)
(cid:17)
and

E[MAE(

lim
n
→∞

b

E[MSE(

w)] = 0.

lim
n
→∞

b

Theorem 3. If S

Θ(n) and ∆

ω

∈

Proof. The details of the proof can be found in the supplementary material . Here we only outline
the key steps to present the intuition of the theorem. The goal of Theorem 3 is to show convergence
of

. The idea is to consider the following two quantities:

w(ui, uj)

w(uix , ujx),

|

w(ui, uj)
|

−

|

b

w(ui, uj) =

w(ui, uj) =

1
Bi| |
1
b
Bi| |
b
so that if we can bound
w(ui, uj)
w(ui, uj)
|

b

|

b
b
Bj
Bi Xjx∈

Bj| Xix∈
b
Bj| Xix∈
b
w(ui, uj)
|
can also be bounded.

b
b
Bj
Bi Xjy∈

1
2T

−

w(ui, uj)
|

and

w(ui, uj)

|

w(ui, uj)
|

−

, then consequently

|

−

w(ui, uj)

w(ui, uj)
|

|
The bound for the ﬁrst term
b
vertex iv ∈
average over

Bj, by Theorem 1 a probability bound involving ∆ can be obtained.

−
Bi is guaranteed to be within a distance ∆ from the pivot of
Bi and
b
is shown in Lemma 2. Different from Lemma
The bound for the second term
b
1, here we need to consider two possible situations: either the intermediate estimate w(ui, uj) is
close to the ground truth w(ui, uj), or w(ui, uj) is far from the ground truth w(ui, uj). This ac-
counts for the sum in Lemma 2. Individual bounds are derived based on Lemma 1 and Theorem 1.

is shown in Lemma 1: By Algorithm 1, any
Bi. Since w(ui, uj) is an

w(ui, uj)
|

w(ui, uj)

−

b

b

b

b

|

Combining Lemma 1 and Lemma 2, we can then bound the error and show convergence.

(G1[ix, jy] + G2[ix, jy] + . . . + G2T [ix, jy]) ,

Lemma 1. For any iv ∈

Bj,

Bi and jv ∈
b
w(ui, uj)

w(uiv , ujv )
|

b

−

Pr

|
h

Lemma 2. For any iv ∈

Bj,

Bi and jv ∈
> 8∆1/2L1/4
b

Pr

wij −

wij|

> 8∆1/2L1/4

32

S∆4
32/T +8∆2/3 .

e−

(10)

≤

i

|

Bi| |
b

Bj|
b

b
2e−

256(T

b
Bi| |

b
Bj |

|

√L∆) + 32

2e−

S∆4
32/T +8∆2/3) .

(11)

|
h
Θ(n) is necessary to make Theorem 3 valid, because if S is independent of n, it
The condition S
. The other condition on ∆ is also important
is not possible to drive (10) and (11) to 0 even if n
as it forces the numerators and denominators in the exponentials of (10) and (11) to be well behaved.

→ ∞

≤

∈

b

i

|

|

2

Bi|
b

Bj|
b

4 Experiments

In this section we evaluate the proposed SBA algorithm by showing some empirical results. For
the purpose of comparison, we consider (i) the universal singular value thresholding (USVT)
(Chatterjee); (ii) the largest-gap algorithm (LG) (Channarond et al. 2012); (iii) matrix completion
from few entries (OptSpace) (Keshavan et al. 2010).

6

4.1 Estimating stochastic blockmodels

Accuracy as a function of growing graph size. Our ﬁrst experiment is to evaluate the proposed
SBA algorithm for estimating stochastic blockmodels. For this purpose, we generate (arbitrarily) a
graphon

which represents a piecewise constant function with 4

4 equi-space blocks.

0.8 0.9 0.4 0.5
0.1 0.6 0.3 0.2
0.3 0.2 0.8 0.3
0.4 0.1 0.2 0.9

,






w = 




×

 

(12)

 

Proposed

)
E
A
M

(
0
1
g
o
l

−0.5

−1

−1.5

−2

−2.5

 
−3
0

Proposed
Largest Gap
OptSpace
USVT

)
E
A
M

(
0
1
g
o
l

−2

−2.1

−2.2

−2.3

−2.4

−2.5

−2.6

−2.7

−2.8

−2.9

 
−3
0

200

400

600

n

800

1000

5

10

15

25

30

35

40

20
2T

(a) Growing graph size, n

(b) Growing no. observations, 2T

Figure 2: (a) MAE reduces as graph size grows. For the fairness of the amount of data that can be
used, we use n
1 observation for USVT (Chatterjee)
and LG (Channarond et al. 2012). (b) MAE of the proposed SBA algorithm reduces when more
observations T is available. Both plots are averaged over 100 independent trials.

2 observations for SBA, and n

n
2 ×

2 ×

×

×

n

Since USVT and LG use only one observed graph whereas the proposed SBA require at least 2
observations, in order to make the comparison fair, we use half of the nodes for SBA by generating
two independent n
n
2 observed graphs. For USVT and LG, we use one n
Figure 2(a) shows the asymptotic behavior of the algorithms when n grows. Figure 2(b) shows the
estimation error of SBA algorithm as T grows for graphs of size 200 vertices.

n observed graph.

2 ×

×

Accuracy as a function of growing number of blocks. Our second experiment is to evaluate the
performance of the algorithms as K, the number of blocks, increases. To this end, we consider a
sequence of K, and for each K we generate a graphon w of K
K blocks. Each entry of the
block is a random number generated from Uniform[0, 1]. Same as the previous experiment, we ﬁx
n = 200 and T = 1. The experiment is repeated over 100 trials so that in every trial a different
graphon is generated. The result shown in Figure 3(a) indicates that while estimation error increases
as K grows, the proposed SBA algorithm still attains the lowest MAE for all K.

×

4.2 Estimation with missing edges

Our next experiment is to evaluate the performance of proposed SBA algorithm when there are
missing edges in the observed graph. To model missing edges, we construct an n
n binary matrix
×
M with probability Pr[M [i, j] = 0] = ξ, where 0
1 deﬁnes the percentage of missing
edges. Given ξ, 2T matrices are generated with missing edges, and the observed graphs are deﬁned
denotes the element-wise multiplication. The goal is to
as M1 ⊙
study how well SBA can reconstruct the graphon

w in the presence of missing links.

G1, . . . , M2T ⊙

G2T , where

≤

≤

⊙

ξ

The modiﬁcation of the proposed SBA algorithm for the case missing links is minimal: when com-
b
Bi and jy ∈
puting (6), instead of averaging over all ix ∈
Bj
that are not masked out by all M ′s. Figure 3(b) shows the result of average over 100 independent
b
b

Bj, we only average ix ∈
b

Bi and jy ∈
b

7

 

 

Proposed
Largest Gap
USVT

 
−1.4
0

5

10
K

15

20

(a) Growing no. blocks, K

Proposed
Largest Gap
OptSpace
USVT

5

10
% missing links

15

20

(b) Missing links

Figure 3: (a) As K increases, MAE of all three algorithm increases but SBA still attains the lowest
MAE. Here, we use n
1 observation for USVT (Chatterjee)
and LG (Channarond et al. 2012). (b) Estimation of graphon in the presence of missing links: As
the amount of missing links increases, estimation error also increases.

2 observations for SBA, and n

n
2 ×

2 ×

×

×

n

trials. Here, we consider the graphon given in (12), with n = 200 and T = 1. It is evident that SBA
outperforms its counterparts at a lower rate of missing links.

4.3 Estimating continuous graphons

Our ﬁnal experiment is to evaluate the proposed SBA algorithm in estimating continuous graphons.
Here, we consider two of the graphons reported in (Chatterjee):

w1(u, v) =

1 + exp

1
50(u2 + v2)
}

,

{−

and w2(u, v) = uv,

where u, v
latent feature relational model (Miller et al. 2009).

∈

[0, 1]. Here, w2 can be considered as a special case of the Eigenmodel (Hoff 2008) or

The results in Figure 4 shows that while both algorithms have improved estimates when n grows, the
performance depends on which of w1 and w2 that we are studying. This suggests that in practice the
choice of the algorithm should depend on the expected structure of the graphon to be estimated: If the
graph generated by the graphon demonstrates some low-rank properties, then USVT is likely to be
a better option. For more structured or complex graphons the proposed procedure is recommended.

 

Proposed
USVT

 

Proposed
USVT

−0.7

−0.8

−0.9

−1

−1.1

−1.2

−1.3

)
E
A
M

(
0
1
g
o
l

)
E
A
M

(
0
1
g
o
l

−2.9

−2.95

−3

−3.05

−3.1

−3.15

 
−3.2
0

)
E
A
M

(
0
1
g
o
l

−0.6

−0.7

−0.8

−0.9

−1

−1.1

−1.2

−1.3

−1.4

−1.5

 
−1.6
0

)
E
A
M

(
0
1
g
o
l

−0.6

−0.8

−1

−1.2

−1.4

−1.6

−1.8

 
−2
0

200

400

600

n

800

1000

200

400

600

n

800

1000

(a) graphon w1

(b) graphon w2

Figure 4: Comparison between SBA and USVT in estimating two continuous graphons w1 and w2.
Evidently, SBA performs better for w1 (high-rank) and worse for w2 (low-rank).

8

5 Concluding remarks

We presented a new computational tool for estimating graphons. The proposed algorithm approx-
imates the continuous graphon by a stochastic block-model, in which the ﬁrst step is to cluster
the unknown vertex labels into blocks by using an empirical estimate of the distance between two
graphon slices, and the second step is to build an empirical histogram to estimate the graphon. Com-
plete consistency analysis of the algorithm is derived. The algorithm was evaluated experimentally,
and we found that the algorithm is effective in estimating block structured graphons.

Code. An implementation of the stochastic blockmodel approximation (SBA) algorithm proposed
in this paper is available online at: https://github.com/airoldilab/SBA

Acknowledgments. EMA is partially supported by NSF CAREER award IIS-1149662, ARO MURI
award W911NF-11-1-0036, and an Alfred P. Sloan Research Fellowship. SHC is partially supported
by a Croucher Foundation Post-Doctoral Research Fellowship.

References

E.M. Airoldi, D.M. Blei, S.E. Fienberg, and E.P. Xing. Mixed-membership stochastic blockmodels. Journal of

Machine Learning Research, 9:1981–2014, 2008.

D.J. Aldous. Representations for partially exchangeable arrays of random variables. Journal of Multivariate

Analysis, 11:581–598, 1981.

Research, W&CP, 22:54–63, 2012.

H. Azari and E. M. Airoldi. Graphlet decomposition of a weighted network. Journal of Machine Learning

P.J. Bickel and A. Chen. A nonparametric view of network models and Newman-Girvan and other modularities.

Proc. Natl. Acad. Sci. USA, 106:21068–21073, 2009.

P.J. Bickel, A. Chen, and E. Levina. The method of moments and degree distributions for network models.

Annals of Statistics, 39(5):2280–2301, 2011.

C. Borgs, J. Chayes, L. Lov´asz, V. T. S´os, B. Szegedy, and K. Vesztergombi. Graph limits and parameter

testing. In Proc. ACM Symposium on Theory of Computing, pages 261–270, 2006.

A. Channarond, J. Daudin, and S. Robin. Classiﬁcation and estimation in the Stochastic Blockmodel based on

the empirical degrees. Electronic Journal of Statistics, 6:2574–2601, 2012.

S. Chatterjee. Matrix estimation by universal singular value thresholding. ArXiv:1212.1247. 2012.

D.S. Choi and P.J. Wolfe. Co-clustering separately exchangeable network data. ArXiv:1212.4093. 2012.

D.S. Choi, P.J. Wolfe, and E.M. Airoldi. Stochastic blockmodels with a growing number of classes. Biometrika,

99:273–284, 2012.

P. Diaconis and S. Janson. Graph limits and exchangeable random graphs. Rendiconti di Matematica e delle

sue Applicazioni, Series VII, pages 33–61, 2008.

S. E. Fienberg, M. M. Meyer, and S. Wasserman. Statistical analysis of multiple sociometric relations. Journal

of the American Statistical Association, 80:51–67, 1985.

A. Goldenberg, A.X. Zheng, S.E. Fienberg, and E.M. Airoldi. A survey of statistical network models. Founda-

tions and Trends in Machine Learning, 2:129–233, 2009.

M. Handcock, A. E. Raftery, and J. Tantrum. Model-based clustering for social networks (with discussion).

Journal of the Royal Statistical Society, Series A, 170:301–354, 2007.

P.D. Hoff. Modeling homophily and stochastic equivalence in symmetric relational data. In Neural Information

Processing Systems (NIPS), volume 20, pages 657–664, 2008.

P.D. Hoff, A.E. Raftery, and M.S. Handcock. Latent space approaches to social network analysis. Journal of

the American Statistical Association, 97(460):1090–1098, 2002.

D.N. Hoover. Relations on probability spaces and arrays of random variables. Preprint, Institute for Advanced

Study, Princeton, NJ, 1979.

(1):137–154, 1989.

Theory, 56:2980–2998, Jun. 2010.

O. Kallenberg. On the representation theorem for exchangeable arrays. Journal of Multivariate Analysis, 30

R.H. Keshavan, A. Montanari, and S. Oh. Matrix completion from a few entries. IEEE Trans. Information

E. D. Kolaczyk. Statistical Analysis of Network Data: Methods and Models. Springer, 2009.

9

N.D. Lawrence. Probabilistic non-linear principal component analysis with Gaussian process latent variable

models. Journal of Machine Learning Research, 6:1783–1816, 2005.

J.R. Lloyd, P. Orbanz, Z. Ghahramani, and D.M. Roy. Random function priors for exchangeable arrays with

applications to graphs and relational data. In Neural Information Processing Systems (NIPS), 2012.

L. Lov´asz and B. Szegedy. Limits of dense graph sequences. Journal of Combinatorial Theory, Series B, 96:

933–957, 2006.

K.T. Miller, T.L. Grifﬁths, and M.I. Jordan. Nonparametric latent fature models for link prediction. In Neural

Information Processing Systems (NIPS), 2009.

K. Nowicki and T. A. B. Snijders. Estimation and prediction for stochastic blockstructures. Journal of the

American Statistical Association, 96:1077–1087, 2001.

P. Orbanz and D.M. Roy. Bayesian models of graphs, arrays and other exchangeable random structures, 2013.

Unpublished manuscript.

P.Latouche and S. Robin. Bayesian model averaging of stochastic block models to estimate the graphon function
and motif frequencies in a w-graph model. ArXiv:1310.6150, October 2013. Unpublished manuscript.

K. Rohe, S. Chatterjee, and B. Yu. Spectral clustering and the high-dimensional stochastic blockmodel. Annals

of Statistics, 39(4):1878–1915, 2011.

Annals of Statistics, 2013. In press.

M. Tang, D.L. Sussman, and C.E. Priebe. Universally consistent vertex classiﬁcation for latent positions graphs.

L. Wasserman. All of Nonparametric Statistics. Springer, 2005.

P.J. Wolfe and S.C. Olhede. Nonparametric graphon estimation. ArXiv:1309.5936, September 2013. Unpub-

lished manuscript.

Z. Xu, F. Yan, and Y. Qi. Inﬁnite Tucker decomposition: nonparametric Bayesian models for multiway data

analysis. In Proc. Intl. Conf. Machine Learning (ICML), 2012.

Y. Zhao, E. Levina, and J. Zhu. Community extraction for social networks. In Proc. Natl. Acad. Sci. USA,

volume 108, pages 7321–7326, 2011.

Theorem 1. The estimator

dij for dij is unbiased. Further, for any ǫ > 0, if the graph is directed, then

A Proofs for Section 3.1

and if the graph is un-directed, then

(13)

(14)

where S is the size of the sampling neighborhood

, and 2T is the number of observations.

Proof. First, for given ui and uj, let us deﬁne the following two quantities

b

Pr

dij

dij

> ǫ

Sǫ2
32/T +8ǫ/3 ,

8e−

−

−

h(cid:12)
(cid:12)
(cid:12) b

h(cid:12)
(cid:12)
(cid:12) b

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
S

≤

i

≤

i

Pr

dij

dij

> ǫ

Sǫ2
64/T +8ǫ/3 ,

8e−

cij

def
=

rij

def
=

1

0
Z

1

0
Z

w(x, ui)w(x, uj)dx,

w(ui, y)w(uj, y)dy.

Consequently, we express dij as

dij

def
=

1

1
2
1
2

0

(cid:18)Z
[(rii

=

(w(ui, y)

w(uj , y))2dy +

(w(x, ui)

w(x, uj ))2dx

−

−

(cid:19)

rij

rji + rjj ) + (cii

cji + cjj )] .

−

−

1

0
Z
cij

−

−

In order to study

dij (the estimator of dij ), it is desired to express

dij in the same form of dij:

b
dij =

1
S

b

1
2

∈S (cid:26)
Xk

h(cid:16)

rk
ii −

rk
ij −

rk
ji +

rk
jj

+

ck
b
ii −

ck
ij −

ck
ji +

ck
jj

(cid:17)

(cid:16)

,

(cid:17)i(cid:27)

b

b

b

b

b

b

b

b

(15)

10

where
=
deﬁned as

S

{

}\{

}

1, . . . , n

i, j

is the sampling neighborhood, and S =

. In (15), individual components are

|S|

,

.







ck
ij =

b
rk
ij =

1
T 2 



1
T 2 

Gt1 [k, i]

Gt2 [k, j]

t1≤
X1
≤

T

XT <t2≤

2T













Gt1 [i, k]

Gt2 [j, k]

t1≤
X1
≤

T

XT <t2≤

2T






ij are unbiased estimators of rij and cij , i.e., E[
ck
dij will be an unbiased estimator of dij.
b
b
Pr

+ 0

Pr

·

Gt1 [i, k]Gt2 [j, k] = 1
h

i
Gt1 [i, k] = 1 and Gt2 [j, k] = 1
h

uk

(cid:12)
(cid:12)
(cid:12)

= Pr

= Pr[Gt1 [i, k] = 1
= w(ui, uk)w(uj, uk).

|

uk]

·

·

uk

(cid:12)
(cid:12)
(cid:12)

i
|

ij ] = rij and E[
rk

ck
ij ] = cij ,

Gt1 [i, k]Gt2 [j, k] = 1
h

uk

i

b

(cid:12)
(cid:12)
(cid:12)

Pr[Gt2 [j, k] = 1

uk],

because Gt1 [i, k]

⊥

Gt2 [j, k]
(16)

b
rk
ij and
Thus, if we can show that
then by linearity of expectation,

E[Gt1 [i, k]Gt2 [j, k]

uk] = 1

|

Therefore,

b
To this end, we consider the conditional expectation of Gt1 [i, k]Gt2 [j, k] given uk:

b

E

rk
ij |
h

b

uk

=

i

=

1
T 2

1
T 2

 

 

2T

T

t2=T +1
X
2T

t1=1
X
T

Xt2=T +1
= w(ui, uk)w(uj , uk).

t1=1
X

E

Gt1 [i, k]Gt2 [j, k]
h

|

uk

!
i

w(ui, uk)w(uj, uk)

,

by substituting (16)

!

Then, by the law of iterated expectations, we have

E

rk
ij
h

b

= E

E

uk

rk
ij |
h

b

i

= E

h
w(ui, uk)w(uj , uk)

ii

,

by substituting (17)

h
1

i
w(ui, v)w(uj, v)dv,

=

0
Z
= rij .

because uk

Uniform(0, 1)

∼

rk
Therefore,
ij is an unbiased estimator of rij . The proof of
ck
Gt[i, k] to Gt[k, i]. Since
ij are both unbiased,
b

rk
ij and

b

dij must be unbiased.

b

b

b

cij can be similarly proved by switching roles of

(17)

(18)

Now we proceed to prove the second part of the theorem. We ﬁrst claim that

To prove this, we note that

Var

2/T and Var

2/T.

(19)

≤

rk
ij
h

i

b

2T

T

ck
ij

h
b

≤

i

Var

rk
ij

= Var

h

i

b

=

"

2T

Xt2=T +1
T

t1=1
X

Gt1 [ik]Gt2 [jk]

#

Var

Gt1 [ik]Gt2 [jk]
i

h

t2=T +1
X

t1=1
X

2T

2T

T

T

+

Xτ2=T +1
=t2
τ26

Xt2=T +1

τ1=1
X
=t1
τ16

t1=1
X

Cov

Gt1 [ik]Gt2 [jk], Gτ1 [ik]Gτ2 [jk]
i
h

11

We consider three cases:

Case 1. First assume τ1

= t1 and τ2

= t2. (Occurs (T

1)2T 2 times.)

−

E[Gt1 [ik]Gt2 [jk]]) (Gτ1 [ik]Gτ2 [jk]

E[Gτ1 [ik]Gτ2 [jk]])

(Gt1 [ik]Gt2 [jk]

wikwjk) (Gτ1 [ik]Gτ2 [jk]

wikwjk)

i

Gt1 [ik]Gt2 [jk], Gτ1 [ik]Gτ2 [jk]
i

(Gt1 [ik]Gt2 [jk]

Cov

h
= E

h

= E

−

−

= E

= E

h
Gt1 [ik]Gt2 [jk]Gτ1 [ik]Gτ2 [jk]
i
h
Gt1 [ik]Gt2 [jk]Gτ1 [ik]Gτ2 [jk]
i
h

−

−

−

i
wikwjk

E

−
Gτ1 [ik]Gτ2 [jk]
i
h
ikw2
w2
jk

E

−

Gt1 [ik]Gt2 [jk]
i
h

wikwjk + w2

ikw2

jk

(20)

The ﬁrst term in (20) is E
Gτ2 [jk] are all independent. Therefore, the overall sum in (20) is 0.

Gt1 [ik]Gt2 [jk]Gτ1 [ik]Gτ2 [jk]
i
h

= w2

ikw2

jk because Gt1 [ik], Gt2 [jk], Gτ1 [ik] and

Case 2. Next assume that τ1

= t1 but τ2 = t2. (Occurs (T

1)T 2 times.) In this case,

E

Gt1 [ik]Gt2 [jk]Gτ1 [ik]Gτ2 [jk]
i
h

E

Gt2 [jk]Gτ2 [jk]
i
h

E

= E

−
Gτ1 [ik]
Gt1 [ik]
i
i
h
h
= wikwikE
Gt2 [jk]2
h

i

= w2

ikwjk.

= w2

ikwjk

w2

ikw2

jk = w2

ikwjk(1

−

wjk)

1.

≤

−

Substituting this result into (20) yields the covariance

Cov

h
Case 3. Assume τ1 = t1 but τ2

Gt1 [ik]Gt2 [jk], Gτ1 [ik]Gτ2 [jk]
i
= t2. (Occurs (T

1)T 2 times.) In this case,

−

E

Gt1 [ik]Gt2 [jk]Gτ1 [ik]Gτ2 [jk]
i
h

= wikw2

jk,

and so the covariance becomes

Gt1 [ik]Gt2 [jk], Gτ1 [ik]Gτ2 [jk]
i
h
Combining all 3 cases, we have the following bound:

Cov

= wikw2

jk(1

wik)

1.

≤

−

Var[

rk
ij] =

1
T 4 Var

b

Gt1 [ik]Gt2 [jk]

#

"

t2
t1 X
X

"

Var

Gt1 [ik]Gt2 [jk]
t2
t1 X
i
h
X
T 2wikwjk(1

wikwjk) + (T

1
T 4

1
T 4
1
T 4
2T

=

=

≤

=

−
1)T 2

−

(cid:3)

(cid:2)

T 2 + 2(T

2
T

.

(cid:2)
−

1
T 2 ≤
ck
ij

The bound for Var

can be proved similarly.

+ (T

1)T 2w2

ikwjk(1

wjk) + (T

1)T 2wikw2

jk(1

wik)

−

−

−

−

#

1)T 2w2

ikwjk(1

wjk) + (T

1)T 2wikw2

jk(1

wik)

−

−

−

−

(cid:3)

(cid:3)

Next, we observe that Gt (for any t) is a directed graph. So the random variables Gt1 [i, k] and Gt1 [k, i]
the product variables
are independent. Similarly, Gt2 [j, k] and Gt2 [k, j] are independent. Therefore,
= j and
Gt1 [i, k]Gt2 [j, k] and Gt1 [k, i]Gt2 [k, j] must be independent for any ﬁxed ui, uj and uk, where i
k =

ck
ij are independent, and hence

. Consequently,

rk
ij and

1, . . . , n

(cid:2)
b

i, j

{

}\{

}

which implies that

rk
ij and

ij are uncorrelated: E
ck

rij)(

cij )

= 0. Consequently,

E[
b

rk
ij

ij ] = E
ck
b

rk
ij
h
i
= rijcij ,

·

b

b

b
rk
ij −

(

E

i

ck
ij
h
b
ck
ij −

b

Var
b

1
2

(cid:20)

ck
ij

rk
ij +
(cid:16)

b

b

(cid:17)(cid:21)

=

1
(cid:2)
4

Var

b
(cid:16)

rk
ij
h

+ Var
b
i

1
T

.

≤

(cid:3)
ck
ij
h
b

i(cid:17)

b

12

Since

rij = 1
S

rk
ij and

cij = 1
S

ck
ij , by Bernstein’s inequality we have

k
∈S
P

cij )

b

−

1
2

b
(rij + cij )

k
∈S
P

b
rij +

(

b

b

b
Pr

1
2

(cid:20)(cid:12)
(cid:12)
(cid:12)
(cid:12)

Finally, we note that

> ǫ

= Pr

(cid:21)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

2e−

≤

1
S

1
2

rk
ij +

ck
ij

"(cid:12)
Xk
(cid:12)
∈S
(cid:12)
(cid:12)
2(Var[ 1
(cid:12)

(cid:17)

(cid:16)
Sǫ2
b
ij)]+ǫ/3)
+bck

b

2 ( brk
ij

1
2

−

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

Sǫ2
2(1/T +ǫ/3) .

2e−

≤

(rij + cij )

> ǫ

#

dij
|

−

dij

| ≤

b

1
2 |
1
2 |

−

−

−

−

|

|

rji +
b

cji
b

rji

cji

+

1
2 |
1
2 |

rii +

cii

rii

cii

+

rij +

cij

rij

cij

+

−

−

|

rjj +
b

cjj
b

rjj

cjj

.

|

−

−

Therefore by union bound we have

b

b

b

b

dij
Pr[
|
Pr
b

≤

−
1
2 |

+

h

> ǫ]

dij

|
rii +

−

1
b
2 |

rji +
b

cji

Pr

≤

1
2

−

1
2

−

1
2 |

|

−

rji

cji

+

−

|

1
b
2 |

cii

rii

cii

+

rij +

cij

rij

cij

+

−

−

|

rjj +
b

cjj

rjj

cjj

> ǫ

−

|

−

(

rii +
b

cii)
b

(rii + cii)

> ǫ/4
b

+ Pr
b

(

rij +

(rij + cij )

> ǫ/4

+

b
rji +

h (cid:12)
(cid:12)
1
(cid:12)
b
+ Pr
(
(cid:12)
2
h (cid:12)
(cid:12)
Sǫ2 /16
(cid:12)
b
2(1/T +ǫ/12) = 8e−
(cid:12)

8e−

cji)

b

−

1
2

(cid:12)
(cid:12)
(cid:12)
(cid:12)

i
> ǫ/4

h (cid:12)
(cid:12)
(cid:12)
+ Pr
(cid:12)

(rji + cji)

Sǫ2
32/T +8ǫ/3 .

(cid:12)
(cid:12)
(cid:12)
(cid:12)

i

(

b
rjj +

cjj )

(rjj + cjj )

1
2

−

b

b

(cid:12)
(cid:12)
(cid:12)
(cid:12)

i
> ǫ/4

i

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
2

1
b
2

h (cid:12)
(cid:12)
(cid:12)
(cid:12)

i
cij )

1
2

−

≤

(cid:2)

(cid:0)

If the graph is un-directed, then ck
Var

ij + ck
rk
ij

1
T . In this case,

1
2

≤

(cid:1)(cid:3)

B Proofs for Section 3.2

ij = rk

ij and we can only have Var

1
2

rk
ij + ck
ij

2
T instead of

(cid:2)

(cid:0)

≤

(cid:1)(cid:3)

dij
Pr[
|

−

dij

> ǫ]

|

≤

Sǫ2
64/T +8ǫ/3 .

8e−

b

Theorem 2. Let ∆ be the accuracy parameter and K be the number of blocks estimated by Algorithm 1, then

where L is the Lipschitz constant and Q is the number of Lipschitz blocks in the ground truth w.

Pr

K >

(cid:20)

QL√2
∆

≤

(cid:21)

8n2e−

S∆4
128/T +16∆2/3 ,

(21)

Proof. Recall that in deﬁning the Lipschitz condition of w (Section 2.1), we deﬁned a sequence of non-
overlapping intervals Ik = [αk, αk+1], where 0 = α0 < . . . < αQ = 1, and Q is the number of Lipschitz
blocks of w. For each of the interval Ik, we divide it into R
∆ subintervals of equal size 1/R. Thus,
the distance between any two elements in the same subinterval is at most 1/R. Also, the total number of
subintervals over [0, 1] is QR.

def
= L√2

Now, suppose that there are K > QR = QL√2
∆ blocks deﬁned by the algorithm, and denote the K pivots be
p1, . . . , pK. By the pigeonhole principle, there must be at least two pivots pi and pj in the same sub-interval.
In this case, the distance dpi,pj must satisfy the following condition:

dpi,pj =

(w(x, upi )

w(x, upj ))2dx +

(w(upi , y)

w(upj , y))2dy

1

0

Z

−

(cid:19)

−

1

1
2
0
(cid:18)Z
L2(upi −
L2 1
R2 =

≤

≤

upj )2
∆2
2

.

However, from the algorithm it holds that

∆2. So, if K > QR, then

dpi,pj ≥
b

13

dpi,pj > ∆2
2 .

dpi,pj −
b

Let

be the following event:

E

∆2
2

dpi,pj >

for at least one pair of pi, pj

.

(cid:27)

=

E

(cid:26)

dpi,pj −
b

E

Then, since the event

is a consequence of the event

K > QR

, we have

{

}

Pr

K >

= Pr[K > QR]

Pr[

].

≤

E

QL√2
∆

(cid:21)

(cid:20)

To bound Pr[

], we observe that

E

Pr

dpi,pj −
b
Therefore, by union bound,

(cid:20)

∆2
2

(cid:12)
(cid:12)
(cid:12)

≤

(cid:21)

dpi,pj >

pi, pj

8e−

32/T +8(∆2 /2)/3 = 8e−

S(∆2/2)2

S∆4
128/T +16∆2/3 .

and hence,

Pr

p1, . . . , pK

E
h

(cid:12)
(cid:12)
(cid:12)

Pr

(cid:20)

dpi,pj −
b

S∆4
128/T +16∆2/3 ,

pi,pj
X
8n2e−

≤

i

≤

dpi,pj >

pi, pj

(cid:21)

∆2
2

(cid:12)
(cid:12)
(cid:12)

Pr [

] =

E

Pr [

p1, . . . , pK] Pr [p1, . . . , pK]

E |

S∆4
128/T +16∆2/3

p1,...,pK
X
8n2e−

≤

(cid:18)

= 8n2e−

S∆4
128/T +16∆2/3 .

Pr [p1, . . . , pK]

·

(cid:19)

p1,...,pK
X

This completes the proof.

C Proofs for Section 3.3

Lemma 1. Let
Bi =
gorithm. Suppose that

vertices in

b
Bi and

Bj, respectively. Let

i1, i2, . . . , i
b
Bi|}
{
|
ui1 , ui2 , . . . , ui
{

and

| bBi | }

Bj =
and
b

j1, j2, . . . , j
b
Bj |}
{
|
uj1 , uj2 , . . . , uj
| bBj | }
{

be two clusters returned by the Al-
are the ground truth labels of the

b

b

wij =

w(uix , ujx ).

b
b
| Xix ∈
Bi Xjx ∈
Bj
Assume that the precision parameter satisﬁes ∆2 < δ2L
the smallest Lipschitz interval. Then, for any iv

Bi and jv

b

b

||

∈

Bj ,

∈

1

Bj

Bi
|

4 , where L is the Lipschitz constant and δ is the size of

Pr

wij
|
h

−

w(uiv ,jv )

> 8∆1/2L1/4
b

|

b
Bi
32
|

||

Bj

e−
|

≤

S∆4
32/T +8∆2/3 .

i

(22)

(23)

Proof. Let ip
holds that

∈
dip ,iv | ≤
|
b
b

Bi and jp

Bi and

Bj be pivots of the clusters
∈
∆2 and
djp,jv | ≤
|
b
0
b
dip,iv ≤

∆2 for any vertices iv
b
dip,iv + ∆2
b
dip,iv −

+ ∆2
≤ −
dip,iv + ∆2

dip,iv |
dip,iv −
b

≤ |
b

≤ −|

⇒

∈

b

which implies that

b

b

b
Bj, respectively. By deﬁnition of pivots, it

Bi and jv

Bj . Therefore,

∈

+ ∆2,

b
dip,iv |
b
+ ∆2 > 2∆2

i

> ∆2

i

Pr

dip,iv > 2∆2

(cid:2)

≤

(cid:3)

= Pr

Pr

dip,iv −
dip,iv |
|
h
dip,iv −
dip,iv |
b
|
h
S∆4
b
32/T +8∆2/3 .
8e−

≤

14

Similarly, we have Pr

djp,jv > 2∆2

8e−

32/T +8∆2/3 . Thus,

≤

∪

Pr

dip,iv > 2∆2

(cid:2)

(cid:3)
djp,jv > 2∆2

Pr

+ Pr

djp,jv > 2∆2

(cid:2)

(cid:2)

(cid:3)

dip,iv > 2∆2
S∆4
32/T +8∆2/3 .

(cid:3)

(cid:2)
16e−

S∆4

(cid:3)

≤

≤

ij =

1
Let dc
0 (w(x, ui)
for any 0 < (ǫ/2)2 < 2δL, if dc
R

−

w(x, uj))2dx and dr

ij =
(ǫ/2)4
8L = ǫ4
128L and dr
R

1
0 (w(ui, y)

i,j ≤

w(uj, y))2dy. By Lemma 5, it holds that

i,j ≤
w(x, uj )

w(x, ui)

w(ui, y)

w(uj, y)

−

−

−
ǫ4
128L , then
ǫ
2
ǫ
2

| ≤

| ≤

,

.

x

sup

[0,1] |

∈
sup
[0,1] |

y

∈

Therefore, if dc
jp

ip,iv ≤
Bj , and vertex iv

∈

w(uiv , ujv )
b
|

−

ǫ4
128L , dr
Bi, jv

ip,iv ≤
Bj :
∈
w(uip , ujp )
b

∈

ǫ4
128L , dc

jp,jv ≤

ǫ4
128L and dr

jp ,jv ≤

ǫ4
128L , then for pivots ip

−

w(uiv , ujp )

+
w(x, ujp )

|

w(x, ujv )

−

w(uiv , ujp )
|
+ sup
y

[0,1] |

|

−
w(uiv , y)

−

w(uip , ujp )

|
w(ujp , y)

|

∈

b
| ≤ |
≤

=

w(uiv , ujv )
sup
[0,1] |
ǫ
2

= ǫ.

x
∈
ǫ
2

+

Also, if dc

ip,ix ≤

ǫ4
128L , dr

ip,ix ≤

ǫ4
128L , dc

jp ,jx ≤

ǫ4
128L and dr

jp,jx ≤

ǫ4
128L for vertex every ix

Bi, jx

Bj

∈

∈

w(uix , ujx )

w(uip , ujp )

−

b
b
| Xix∈
Bi Xjx∈
Bj

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1

−

Bi
|

b
| Xix∈
Bi

1

Bj

b
1

||

b

Bi
|

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
≤ (cid:12)
Bi
(cid:12)
|
(cid:12)
(cid:12)
1
(cid:12)
b
(cid:12)
Bi
|

≤

|

1
b
Bi
|

|

≤

Bj

||

1
b
Bj
|

1
b
Bj
|

b
b
| Xix∈
Bi Xjx ∈
Bj

b
b
| Xix ∈
Bi Xjx ∈
Bj (cid:12)
(cid:12)
ǫ
2

b
b
| Xix ∈
Bi Xjx ∈
Bj

1

+

Bi
|

b
| Xix ∈
Bi

ǫ
2

= ǫ.

Combining (24) and (25) with triangle inequality yields

b

b

b

w(uix , ujx )

w(uix , ujp )

+

w(uix , ujp )

w(uip , ujp )

−

w(uix , ujx )

b
w(uix , ujp )

+

−

b
w(uix , ujp )

w(uip , ujp )

−

1

Bi
|

b
| Xix∈
Bi

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
b
| Xix∈
Bi (cid:12)
(cid:12)

1

Bi
|

b

(cid:12)
(cid:12)

Bi,

∈

b

(24)

b

b

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)

(25)

1

b
b
| Xix∈
Bi Xjx ∈
Bj
Consequently, by contrapositive this implies that

||

b

b

Bj

Bi
|

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

w(uix , ujx )

w(uiv , ujv )

−

2ǫ.

≤

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

dr
ip,ix >

128L ∪

dc
jp,jx >

ǫ4

128L ∪

dr
jp,jx >

ǫ4
128L

(cid:19)

wij

|

−

w(uiv , ujv )

> 2ǫ

|
dc
ip,ix >

b
Bi,jx ∈
[ix∈

b
Bj (cid:18)

⇒

⇒

b
Bi,jx ∈
[ix∈

b
Bj (cid:18)

Therefore,

dip,ix >

djp,jx >

128L ∪

ǫ4

128L ∪

ǫ4
128L

.

(cid:19)

Pr [
wij
|

−

w(uiv , ujv )

> 2ǫ]

Pr

|

ǫ4

ǫ4

≤

≤

dip,ix >

djp,jx >

ǫ4

128L ∪

ǫ4
128L

Pr

dip,ix >

+ Pr

djp,jx >

ǫ4
128L

(cid:21)

(cid:20)



(cid:19)

ǫ4
128L

.

(cid:21)(cid:19)





b
Bi,jx∈
[ix∈

b
Bj (cid:18)

b
Bi,jx∈
Xix∈

b
Bj (cid:18)

(cid:20)

15

Assuming ∆ < δ√L/2 and setting ǫ = 4∆1/2L1/4, we have 0 < (ǫ/2)2 < 2δL and thus

Pr

wij
|

−

h

w(uiv , ujv )

> 8∆1/2L1/4

|

Pr

dip,ix > 2∆2

+ Pr

djp,jx > 2∆2

(cid:3)

(cid:2)

(cid:3)(cid:1)

≤

i

b
Bi,jx∈
Xix∈

b
Bj (cid:0)

Bi
32
|

||

Bj

e−
|

≤

(cid:2)
S∆4
32/T +8∆2/3 .

b
Bj =
and
b

b
j1, j2, . . . , j
b
Bj |}
{
|
uj1 , uj2 , . . . , uj
| bBj | }
{

Lemma 2. Let
Bi =
gorithm. Suppose that

vertices in

b
Bi and

i1, i2, . . . , i
b
Bi|}
{
|
ui1 , ui2 , . . . , ui
{

and

| bBi | }

Bj, respectively. Let

be two clusters returned by the Al-
are the ground truth labels of the

b

b

wij =

b
wij =

1

||
1

||

Bj

b
Bj

Bi
|

b
Bi
|

b

b

b
b
Bj (cid:18)
| Xix∈
Bi Xjx ∈

b
b
| Xix∈
Bi Xjx ∈
Bj

w(uix , ujx ).

G1[ix, jx] + . . . + G2T [ix, jx]
2T

,

(cid:19)

Then,

Pr

wij
|
h

b

wij

> 8∆1/2L1/4

−

|

256(T

2e−

b
Bi | |

b
Bj |

|

√L∆) + 32
Bi
|

2
|

Bj
|

2e−
|

S∆4
32/T +8∆2/3 .

≤

i

Proof. There are two possible situations that we need to consider.

b

b

Case 1: For any vertex iv
is close to the ground truth wij
iv

Bi and jv

∈
Case 2: Complement of case 1.

Bi and jv
∈
def
= w(uiv , ujv ).
wij
|

b
b
Bj , so that the difference

∈

∈

b

b

To encapsulate these two cases, we ﬁrst deﬁne the event

Bj , the estimate of the previous lemma wij (independent of (iv, jv))
In other words, we want w(uiv , ujv ) to stay close for all
wij

remains small for all iv

Bi and jv

Bj.

−

|

∈

b

∈

b

=

wij
|
n
be the complement of

E

. Then,

E
> 8∆1/2L1/4

and deﬁne

E

Pr

wij

|

−

wij
|
h

b

So it remains to bound the two probabilities.

Conditioning on

, it holds that

E

wij

−

| ≤

8∆1/2L1/4,

iv

∀

∈

Bi, jv

Bj

∈

b

o

b

wij

> 8∆1/2L1/4

wij

−

wij

(cid:12)
> 8∆1/2L1/4
(cid:12)
(cid:12)

|
> 8∆1/2L1/4

|

|

Pr [

]

E

Pr

i
(cid:2)
+ Pr

E

(cid:12)
(cid:12)
(cid:12)
E

i
E

i

E

(cid:3)
E

.

(cid:2)

(cid:3)

(cid:12)
(cid:12)
(cid:12)

= Pr

wij
|
h
+ Pr

i

−

Pr

≤

wij
b
|
h
wij
b
|
h

−

b

wij
Fix a vertex pair (iv, jv), we note that G1[iv, jv], . . . , G2T [iv, jv] are independent Bernoulli random variable
with common mean w(uiv , ujv ). Denote

w + ǫ.

wij

−

≤

≤

ǫ

2T

1

2T

Bj

Bi
|

||

|

t=1
X

b
b
Bi Xjx∈
Xix∈
Bj

Gt[ix, jx],

then by Hoeffding inequality we have

b

b

Pr

wij

wij > 2ǫ

= Pr

wij > wij + 2ǫ

wij =

b

h

b

−

E

i

(cid:12)
(cid:12)
(cid:12)

h

Pr

≤

wij > wij + ǫ
b

e−

h
2(2T
b

b
Bi ||

b
Bj |

|

ǫ2),

b
Bj |

ǫ2). Therefore,

≤
b
Bi | |

|

(cid:12)
(cid:12)
(cid:12)

E

i

(cid:12)
(cid:12)
(cid:12)
E

i

2(2T

2e−

b
Bi | |

b
Bj |

|

ǫ2).

and similarly Pr

wij

wij <

2ǫ

2(2T

e−

−

−

E

≤

h

b

Pr

i

−

(cid:12)
(cid:12)
wij
(cid:12)
|
h

b

wij

> 2ǫ

|

E

≤

i

(cid:12)
(cid:12)
(cid:12)

16

Substituting ǫ = 4∆1/2L1/4, we have

Pr

wij
|

−

|

wij

> 8∆1/2L1/4

E

≤

128(

b
Bi | |

b
Bj |

|

2e−

(2T )√L∆).

h
The second probability is bounded as follows. Since
where at least one (iv, jv) violates the condition. Therefore,

b

E

i

(cid:12)
(cid:12)
(cid:12)
is the complement of

E

, it is bounded by the probability

Pr

= Pr

at least one iv, jv s.t.

E

(cid:2)

(cid:3)

h

w(uiv , ujv )
|

wij

> 8∆1/2L1/4

−

|
> 8∆1/2L1/4

i

≤

b
b
Bi Xjv ∈
Xiv ∈
Bj

Pr

w(uiv , ujv )
|
h

wij

|

−

Bi
32
|

2
|

Bj
|

2e−
|

≤

S∆4
32/T +8∆2/3 .

i

Finally, by combining the above results we have

b

b

wij

> 8∆1/2L1/4

−

|

256(T

2e−

b
Bi | |

b
Bj |

|

√L∆) + 32
Bi
|

2
|

Bj
|

2e−
|

S∆4
32/T +8∆2/3 .

Pr

wij
|
h

≤

i

b
Lemma 3. Let
Bi =
gorithm. Suppose that

vertices in

b
Bi and

i1, i2, . . . , i
b
Bi|}
{
|
ui1 , ui2 , . . . , ui
{

and

| bBi | }

Bj =
and
b

j1, j2, . . . , j
b
Bj |}
{
|
uj1 , uj2 , . . . , uj
| bBj | }
{

Bj, respectively. Let

b

b
be two clusters returned by the Al-
are the ground truth labels of the

b

b

wij =

Then,

b

1

Bj

Bi
|

||

b

b

G1[ix, jx] + . . . + G2T [ix, jx]
2T

.

(cid:19)

b
b
Bj (cid:18)
| Xix∈
Bi Xjx ∈

256(T

2e−

b
Bi | |

b
Bj |

|

√L∆) + 64n4e−

S∆4
32/T +8∆2/3 .

wij

|

−

> 16∆1/2L1/4

≤

i

Proof. By Lemma 1 and Lemma 2, we have

wij

> 8∆1/2L1/4

−

|

256(T

2e−

b
Bi | |

b
Bj |

|

√L∆) + 32
Bi
|

2
|

Bj
|

2e−
|

S∆4
32/T +8∆2/3

wij > 8∆1/2L1/4

Bi
32
|

||

Bj

e−
|

≤

S∆4
32/T +8∆2/3 .

b

b

≤

i

i

Therefore, it follows that

wij

|

−

> 16∆1/2L1/4

Pr

wij
|
h

b

b
wij

b
> 8∆1/2L1/4

Pr

wij
|

h
256(T
2e−
b

−
b
Bi | |

|

|

b
Bj |

256(T

2e−

b
Bi | |

b
Bj |

|

i

≤

≤

≤

+ Pr

wij

wij > 8∆1/2L1/4

−

S∆4

32/T +8∆2/3 + 32
Bi
|

||

e−
|

i
Bj

S∆4
32/T +8∆2/3

i
√L∆) + 32
Bi
|

h
2e−
2
Bj
|
|
|
S∆4
√L∆) + 64n4e−
32/T +8∆2/3 .
b

b

b

b

Lemma 4. Let E be a subset of the edge set E0 =
{
above setup, there exists constants c0 and c1 such that

(i, j)

i

1, . . . , n

, j

1, . . . , n

. Then under the

|

∈ {

}

∈ {

}}

Pr

1
E
|

"

| X
iv ,jv ∈

E

w(uiv , ujv )
|

−

|

wij

> c0√∆

# ≤

iv ,jv ∈
X

E

c1(T

2e−

b
Bi| |

b
Bj |

|

∆) + 64
E
|

n4e−
|

S∆4
32/T +8∆2/3 .

(26)

Pr

wij
|
h

b

Pr

wij
|
h
Pr

wij
b
h

−

Proof. From Lemma 3, average over all pairs (iv, jv)

E,

Pr

1
E
|

"

| Xiv ,jv ∈

E

w(uiv , ujv )
|

−

wij

|

> 16∆1/2L1/4

b

b

Xiv ,jv ∈
Choosing c0 = 16L1/4 and c1 = 256√L yields the desired result.

E

∈

# ≤

1
E
|

≤

17

E

| Xiv ,jv ∈
2e−

Pr

w(uiv , ujv )
|
h

−

wij > 16∆1/2L1/4

|
i

256(T

b
Bi | |

b
Bj |

|

b

√L∆) + 64
E
|

n4e−
|

S∆4
32/T +8∆2/3 .

Lemma 5. Let Ik = [αk

1, αk] for k = 1, . . . , K be a sequence of intervals such that Ii

Ij =

Ii = [0, 1]. Suppose that w is piecewise Lipschitz continuous and differentiable in Ik. For any ui, uj

∩

−

and
∅
[0, 1],

∈

∪
deﬁne

and

fij (x) = (w(x, ui)

gij(y) = (w(ui, y)

w(x, uj ))2
w(uj , y))2 ,

−

−

hij (x, y) =

[fij (x) + gij(y)] .

1
2

Let δ = min

k=1,...,K |

αk

αk

−

−

dc
ij =

fij (x)dx

and

dr
ij =

gij (y)dy

1

0

Z

ǫ2
8L

,

≤

for some constant 0 < ǫ < 2δL, then

sup

fij (x)

ǫ,

and

sup

gij (y)

ǫ.

y

[0,1]

∈

≤

1

. If
|
1

0

Z

x

[0,1]

∈
ǫ.

≤

ǫ2
8L

,

≤

≤

Hence,

sup

∈

(x,y)

[0,1]2

hij (x, y)

be the width of the interval. Consider a neighborhood surrounding the center of Ik with

1, αk] be the interval such that f sup

ij

is attained, and

−

Proof. Since hij (x, y) is separable, it is sufﬁcient to prove for fij (x).
Fix i and j, and let f sup

fij (x). Let Ik = [αk

ij = sup
[0,1]

x

∈

let δk =
αk
|
radius δk/2

1

αk
θ, where 0 < θ < δk/2. Then deﬁne

−

|

−
−

f sup
ij

(θ) =

sup
[αk−1+θ,αk−

θ]

x

∈

fij (x).

It is clear that f sup

ij = lim
0
→

θ

f sup
ij

(θ).

1 + θ, αk

The set [αk
fij (xmax
interval). For any 0 < ǫ0 < ǫ

). Assume, without lost of generality, that xmax
ij
θ,

θ] is compact, so there exists xmax

−

−

ij

ij

∈
(θ) + δk/2

(θ)

−

[αk
1 + θ, αk
θ (i.e., xmax

−

ij

θ] such that f sup
ij =
is in the lower half of the

−

4L −

δ
θ
θ
2 −
≤
hij (xmax
ij

≤
(θ))

δk
2 −
−

(θ) + ǫ0)

=

(w(i, xmax

ij

)

w(j, xmax

ij

))2

(θ) + ǫ0)

w(j, xmax

ij

(θ) + ǫ0))2

(w(i, xmax

ij

)

w(j, xmax

ij

))2

) + Lǫ0

w(j, xmax

ij

) + Lǫ0)2

−

−

−

ij

hij (xmax
ǫ0
(w(i, xmax
ij
ǫ0
(w(i, xmax
ǫ0
w(i, xmax

ij

)

ij

−

−

−

−

4L(w(j, xmax

ij

))

4L

≤

⇒

fij (xmax

ij

(θ))

−

fij (xmax
ǫ0

ij

(θ) + ǫ0)

4L,

≤

≤

≤

which implies that

Integrating both sides with respect to ǫ0 with limits 0 and ǫ

fij (xmax
ij

(θ))

4Lǫ0

−

≤

fij (xmax
ij

(θ))

ǫ
4L −

θ

4L
2

ǫ
4L −

θ

−

(cid:17)

(cid:16)

(cid:16)

(θ) + ǫ0).

fij (xmax
ij
θ yields
ǫ
4L −

4L −
2

θ

≤

0

Z

1

(cid:17)

≤

0

Z

fij (x)dx = dc

ij .

fij (xmax
ij

(θ) + ǫ0)dǫ0

Therefore,

and hence

fij (xmax
ij

(θ))

dc
ij

≤

ǫ
4L −

θ

+ 2L

ǫ
4L −

(cid:16)

f sup
ij = lim
0
→

θ

f sup
ij

(θ) = lim
0
→

θ

fij (xmax
ij

(θ))

≤

θ

,

(cid:17)
4Ldc
ij
ǫ

+

ǫ
2

.

It then follows that if dc

ǫ2
8L , then f sup

ij ≤

ǫ.

ij ≤

18

Deﬁnition 2. The mean squared error (MSE) and mean absolute error (MAE) are deﬁned as

n

n

iv =1
X
n

jv =1
X
n

MSE(

w) =

MAE(

b
w) =

1
n2

1
n2

iv =1
X

jv =1
X
1
4

log(n)
n

b

ω

∈
E[MAE(

(cid:18)(cid:16)
w)] = 0

(cid:17)

∩

(cid:19)
and

(w(uiv , ujv )

wiv ,jv )2

−

w(uiv , ujv )
|

−

b
wiv ,jv |

.

o(1), then

b

E[MSE(

w)] = 0.

lim
n
→∞

lim
n
→∞

b

b

Theorem 3. If S

Θ(n) and ∆n

∈

(27)

(28)

(29)

Proof. Suppose that the algorithm is executed for a set of observed graphs with n vertices using parameters ∆n
and S. Let K ′n be the number of blocks generated. Assume that, as n
Θ(n)

, the parameters satisfy S

→ ∞

∈

and ∆n

ω

∈

1
4

log(n)
n

∩

(cid:19)

(cid:17)

(cid:18)(cid:16)

o(1).

The proof is based on (4). The intuition is to that that the two terms

S∆4

E
32
|

n4e−
|

16/T +8∆2/3 vanish as n

. The latter is clear if S

Θ(n) and ∆n

P

ω

∈
For the ﬁrst term, it is necessary to consider the size
, which is the size of the cluster generated. We show
E
|
|
that the number of small clusters is asymptotically irrelevant. Most of the error come from vertices whose

→ ∞

(cid:18)(cid:16)

(cid:19)

∈

∩

(cid:17)

o(1).

log(n)
n

E 2e−

iv ,jv ∈

c1(T

b
Bi| |

b
Bj |

|

∆) and

1
4

cluster is large enough to make e−

32/T +8∆2/3 vanish.

S∆4

From Theorem 2, we have

Pr

K ′ >

QL√2
∆n (cid:21)

8n2e−

S∆4
n
128/T +16∆2

n/3 .

n be the event that K ′n ≤

≤
QL√2/∆n. Then limn
n happens and deﬁne rn as the number of blocks with less than n∆2
n
QL√2

n] = 1.

Pr[

→∞

(cid:20)

E

Let

E
Suppose

E

of these blocks, and deﬁne V n be the complement of Vn. Then,

Vn
|

| ≤

rn

n∆2
n
QL√2 ≤

K ′n

n∆2
n
QL√2 ≤

n∆n.

elements. Let Vn be the union

So,

Vn
|

/n
|

≤
Now, let’s consider MAE.

∆n.

MAE =

1
n2

1
n2

=

w(uiv , ujv )
|

−

wiv ,jv |

Xiv ∈

V
V Xjv ∈

Vn X
Vn
jv ∈

iv ∈
X
1
n2

+

Xiv ∈
2
Vn
n2 + |
|
|

V n Xjv ∈
Vn
Vn
V n
|
n
n

|

w(uiv , ujv )
|

b
wiv ,jv |
−

+

1
n2

w(uiv , ujv )

|

b
−

wiv ,jv |

+

w(uiv , ujv )

|

wiv ,jv |

+

−

w(uiv , ujv )

|

b
−

wiv ,jv |

V n Xjv ∈
V n

Xiv ∈
1
n2

Xiv ∈

Vn Xjv ∈
V n

|

+ |

V n
n

|

Vn
|
n

|

b
1
+
n2

w(uiv , ujv )
|

wiv ,jv |

−

b

≤

≤

≤

1
n2

1
n2

Xiv ∈

V n Xjv ∈
V n

Xiv ∈

V n Xjv ∈
V n

V n Xjv ∈
V n

Xiv ∈
+ ∆2

n + 2∆n

w(uiv , ujv )
|

−

wiv ,jv |

w(uiv , ujv )
|

−

b
wiv ,jv |

+ 3∆n.

Similar result holds for MSE:
1
n2

MSE =

V
iv ∈
X

V
jv ∈
X

−

b

Xiv ∈

V n Xjv ∈
V n

b

1
n2

≤

19

b

−

b

(w(uiv , ujv )

wiv ,jv )2

(w(uiv , ujv )

wiv ,jv )2 + 3∆n.

Therefore, using Lemma 4 with E = V n:

Pr

MAE(

w) > c0√∆n + 3∆n

h

b

w(uiv , ujv )

|

wiv ,jv |

−

+ 3∆n > c0√∆n + 3∆n

b
w(uiv , ujv )
|

wiv ,jv |

−

> c0√∆n

Xiv ∈

V n Xjv ∈
V n

256(T

2e−

b
Bi | |

b
Bj |

|

b
√L∆) + 64
V n
|

n4e−
|

E 

(cid:12)
(cid:12)

(cid:12)
S∆4
32/T +8∆2/3

E

≤

i

(cid:12)
(cid:12)
(cid:12)

Pr

1
n2




1
Pr[

]

E

≤

1
Pr[

≤

Xiv ∈

V n Xjv ∈
V n

1
V n
|

2
|

Pr





] 

E



Xiv ∈

V n Xjv ∈
V n

1
Pr[

] 

E



E

≤

i

(cid:12)
(cid:12)
(cid:12)

Xiv ∈

V n Xjv ∈
V n

E 



(cid:12)
(cid:12)
(cid:12)

.





.





Pr

MSE(

w) > c0√∆n + 3∆n

256(T

2e−

b
Bi | |

b
Bj |

|

√L∆) + 64
V n
|

n4e−
|

S∆2
32/T +8∆/3

and

h

So,

b

→∞

Since limn

∆n = 0 and limn

Pr[

n] = 1, it holds that for any ǫ > 0,

Pr

MAE(

w) > c0√∆n + 3∆n

lim
n
→∞

h

→∞

b

E
lim
n
→∞

Pr[MAE(

w) > ǫ] = 0.

Pr [

] = 0.

E

E

i

(cid:12)
(cid:12)
(cid:12)

Finally, since

w is bounded in [0, 1],

Sending ǫ

b

,

→ ∞

b

≤

E[MAE(

w)]

≤

ǫ Pr[MAE(

w)

ǫ] + Pr[MAE(

w) > ǫ].

b
E[MAE(

w)]

b
lim
n
→∞

≤

lim
n
→∞

Pr[MAE(

w) > ǫ] = 0.

b

Same arguments hold for MSE.

b

b

20

3
1
0
2
 
v
o
N
8

 

 
 
]
E
M

.
t
a
t
s
[
 
 
2
v
1
3
7
1
.
1
1
3
1
:
v
i
X
r
a

Stochastic blockmodel approximation of a graphon:
Theory and consistent estimation∗

Edoardo M. Airoldi
Dept. Statistics
Harvard University

Thiago B. Costa
SEAS, and Dept. Statistics
Harvard University

Stanley H. Chan
SEAS, and Dept. Statistics
Harvard University

Abstract

Non-parametric approaches for analyzing network data based on exchangeable
graph models (ExGM) have recently gained interest. The key object that deﬁnes
an ExGM is often referred to as a graphon. This non-parametric perspective on
network modeling poses challenging questions on how to make inference on the
graphon underlying observed network data. In this paper, we propose a computa-
tionally efﬁcient procedure to estimate a graphon from a set of observed networks
generated from it. This procedure is based on a stochastic blockmodel approxi-
mation (SBA) of the graphon. We show that, by approximating the graphon with
a stochastic block model, the graphon can be consistently estimated, that is, the
estimation error vanishes as the size of the graph approaches inﬁnity.

1 Introduction

Revealing hidden structures of a graph is the heart of many data analysis problems. From the well-
known small-world network to the recent large-scale data collected from online service providers
such as Wikipedia, Twitter and Facebook, there is always a momentum in seeking better and
more informative representations of the graphs (Fienberg et al. 1985; Nowicki and Snijders 2001a;
Hoff et al. 2002; Handcock et al. 2007; Airoldi et al. 2008; Xu et al. 2012; Azari and Airoldi 2012;
Tang et al. 2013; Goldenberg et al. 2009; Kolaczyk 2009). In this paper, we develop a new com-
putational tool to study one type of non-parametric representations which recently draws signiﬁ-
cant attentions from the community (Bickel and Chen 2009; Lloyd et al. 2012; Bickel et al. 2011;
Zhao et al. 2011; Orbanz and Roy 2013).

The root of the non-parametric model discussed in this paper is in the theory of exchange-
able random arrays (Aldous 1981; Hoover 1979; Kallenberg 1989), and it
is presented in
(Diaconis and Janson 2008) as a link connecting de Finetti’s work on partial exchangeability and
graph limits (Lov´asz and Szegedy 2006; Borgs et al. 2006). In a nutshell, the theory predicts that
every convergent sequence of graphs (Gn) has a limit object that preserves many local and global
properties of the graphs in the sequence. This limit object, which is called a graphon, can be rep-
resented by measurable functions w : [0, 1]2
[0, 1], in a way that any w′ obtained from measure
preserving transformations of w describes the same graphon.

→

Graphons are usually seen as kernel functions for random network models (Lawrence 2005). To
construct an n-vertex random graph
(n, w) for a given w, we ﬁrst assign a random label ui ∼
Uniform[0, 1] to each vertex i
, and connect any two vertices i and j with probability
w(ui, uj), i.e.,

G
1, . . . , n

}

(1)
where G[i, j] denotes the (i, j)th entry of the adjacency matrix representing a particular realization
of
(n, w) (See Figure 1). As an example, we note that the stochastic block-model is the case where
w(x, y) is a piecewise constant function.

ui, uj) = w(ui, uj),

i, j = 1, . . . , n,

G

|

∈ {
Pr (G[i, j] = 1

∗This paper appears in the proceedings of NIPS 2013. In this version we include an appendix with proofs.

1

w

w(ui, uj)

×

uj

G2T

ui

(ui, uj)

G1

[Left] Given a graphon w :

[0, 1]2
samples ui, uj from
Figure 1:
Uniform[0,1] and assign Gt[i, j] = 1 with probability w(ui, uj), for t = 1, . . . , 2T .
[Middle]
Heat map of a graphon w. [Right] A random graph generated by the graphon shown in the middle.
Rows and columns of the graph are ordered by increasing ui, instead of i for better visualization.

[0, 1], we draw i.i.d.

→

The problem of interest is deﬁned as follows: Given a sequence of 2T observed directed graphs
G1, . . . , G2T , can we make an estimate
w with high probability as n goes to
w of w, such that
inﬁnity? This question has been loosely attempted in the literature, but none of which has a complete
solution. For example, Lloyd et al. (Lloyd et al. 2012) proposed a Bayesian estimator without a
consistency proof; Choi and Wolfe (Choi and Wolfe) studied the consistency properties, but did not
provide algorithms to estimate the graphon. To the best of our knowledge, the only method that
estimates graphons consistently, besides ours, is USVT (Chatterjee). However, our algorithm has
better complexity and outperforms USVT in our simulations. More recently, other groups have
begun exploring approaches related to ours (Wolfe and Olhede 2013; P.Latouche and Robin 2013).

→

w

b

b

The proposed approximation procedure requires w to be piecewise Lipschitz. The basic idea is to
approximate w by a two-dimensional step function
w with diminishing intervals as n increases.The
proposed method is called the Stochastic blockmodel approximation (SBA) algorithm, as the idea
of using a two-dimensional step function for approximation is equivalent to using the stochastic
block models (Choi et al. 2012; Nowicki and Snijders 2001a; Hoff 2008; Channarond et al. 2012;
Rohe et al. 2011). The SBA algorithm is deﬁned up to permutations of the nodes, so the estimated
graphon is not canonical. However, this does not affect the consistency properties of the SBA
algorithm, as the consistency is measured w.r.t. the graphon that generates the graphs.

b

2 Stochastic blockmodel approximation: Procedure

In this section we present the proposed SBA algorithm and discuss its basic properties.

2.1 Assumptions on graphons

We assume that w is piecewise Lipschitz, i.e., there exists a sequence of non-overlaping intervals
1, αk] deﬁned by 0 = α0 < . . . < αK = 1, and a constant L > 0 such that, for any
Ik = [αk
−
(x1, y1) and (x2, y2)

Ij ,

x1 −
For generality we assume w to be asymmetric i.e., w(u, v)
can be considered as a special case. Consequently, a random graph
directed, i.e., G[i, j]

x2|
= w(v, u), so that symmetric graphons
(n, w) generated by w is

w(x2, y2)

= G[j, i].

y1 −

L (
|

y2|

| ≤

) .

+

G

|

|

∈

Iij = Ii ×
w(x1, y1)
−

2.2 Similarity of graphon slices

The intuition of the proposed SBA algorithm is that if the graphon is smooth, neighboring cross-
sections of the graphon should be similar. In other words, if two labels ui and uj are close i.e.,

2

ui −
|
w(
·
|
graphon slices, we deﬁne the following distance

0, then the difference between the row slices
w(
·

and the column slices
w(ui,
should also be small. To measure the similarity between two labels using the

uj| ≈
, ui)
−

, uj)
|

w(uj,

)
|

−

)

|

·

·

dij =

1
2

1

0
(cid:18)Z

[w(x, ui)

w(x, uj )]2 dx +

[w(ui, y)

w(uj , y)]2 dy

.

(2)

−

(cid:19)

1

0
Z

Thus, dij is small only if both row and column slices of the graphon are similar.

The usage of dij for graphon estimation will be discussed in the next subsection. But before
we proceed, it should be noted that in practice dij has to be estimated from the observed graphs
G1, . . . , G2T . To derive an estimator
dij of dij, it is helpful to express dij in a way that the estima-
tors can be easily obtained. To this end, we let

−

b

cij =

w(x, ui)w(x, uj )dx

and

rij =

w(ui, y)w(uj , y)dy,

1

0
Z

and express dij as dij = 1
(cii −
2
we consider the following estimators for cij and rij :
h

cji +cjj )+(rii −

cij −

rij −

. Inspecting this expression,

1

0
Z
rji +rjj )
i

(3)

(4)

(5)

ck
ij =

b
rk
ij =

1
T 2 



1
T 2 

b

Gt1 [k, i]

Gt2 [k, j]

X1
t1≤
≤

T

XT <t2≤

2T

Gt1 [i, k]

Gt2 [j, k]

X1
t1≤
≤

T



XT <t2≤

2T

















,

.









Here, the superscript k can be interpreted as the dummy variables x and y in deﬁning cij and rij ,
respectively. Summing all possible k’s yields an estimator

dij that looks similar to dij :

dij =

1
2 "

1
S

rk
ii −

rk
ij −

rk
ji +

rk
jj

+

b
ck
ii −

ck
ij −

ck
ji +

ck
jj

Xk
∈S (cid:8)(cid:0)

(cid:0)
b
b
is the set of summation indices.

b

b

b

(cid:1)

b

b

b

,

#

(cid:1)(cid:9)

where

=

1, . . . , n

b

S

{

i, j

}\{

}

]

1

≤

t1≤

is w(ui,

T Gt1 [i,

The motivation of deﬁning the estimators in (3) and (4) is that a row of the adjacency matrix G[i,
]
·
). Thus the expected value of
is fully characterized by the corresponding row of the graphon w(ui,
1
rk
ij is an estimator for rij. To theoretically
k
T
∈S
justify this intuition, we will show in Section 3 that
dij is indeed a good estimator: it is not only
P
unbiased, but is also concentrated round dij for large n. Furthermore, we will show that it is possible
to achieve the same asymptotic behavior.
to use a random subset of
}\{
As a result, the estimation of dij can be performed locally in a neighborhood of i and j, instead of
all n vertices.

), and hence 1
S

instead of

1, . . . , n

(cid:16)P

i, j
b

S

(cid:17)

b

}

{

·

·

·

2.3 Blocking the vertices

The similarity metric
wise constant function
(unknown) labels
u1, . . . , un}
b
BK are deﬁned, we can then determine
the blocks
b
b
Bj:
frequency of edges that are present across blocks

dij discussed above suggests one simple method to approximate w by a piece-
w (i.e., a stochastic block-model). Given G1, . . . , G2T , we can cluster the
BK using a procedure described below. Once
w(ui, uj) by computing the empirical

into K blocks

{
B1, . . . ,

b
Bi and

B1, . . . ,

b
w(ui, uj) =

b

1
Bi| |
b

b

Bj| Xix∈
b
where
estimate of the expected number of edges linking block

b
Bi is the block containing ui so that summing Gt[x, y] over x

b
b
Bj
Bi Xjy∈

|

Bi and

Bj.

1
2T

b

(G1[ix, jy] + G2[ix, jy] + . . . + G2T [ix, jy]) ,

b

b

(6)

Bi and y

Bj yields an

∈

b

∈

b

b

b

3

To cluster the unknown labels
1. Starting with Ω =
other vertices iv ∈
Ω
precision parameter ∆ > 0. If
after scanning through Ω once, a block
Ω

{
u1, . . . , un}
{
ip}
\{

B1, the process repeats until Ω =
b

←

Ω

b

\

B1 =
.

∅

u1, . . . , un}
, we compute the distance

we propose a greedy approach as shown in Algorithm
, we randomly pick a node ip and call it the pivot. Then for all
dip,iv < ∆2 for some
dip,iv and check whether
dip,iv < ∆2, then we assign iv to the same block as ip. Therefore,
will be deﬁned. By updating Ω as

b

b

b

The proposed greedy algorithm is only a local solution in a sense that it does not return the globally
optimal clusters. However, as will be shown in Section 3, although the clustering algorithm is not
globally optimal, the estimated graphon
w is still guaranteed to be a consistent estimate of the true
graphon w as n
. Since the greedy algorithm is numerically efﬁcient, it serves as a practical
computational tool to estimate w.

→ ∞

ip, iv1, iv2 , . . .
}

{

b

2.4 Main algorithm

Algorithm 1 Stochastic blockmodel approximation

Input: A set of observed graphs G1, . . . , G2T and the precision parameter ∆.
Output: Estimated stochastic blocks
Initialize: Ω =
{
do
while Ω

, and k = 1.
b

B1, . . . ,

1, . . . , n

BK.

=

b

}

Randomly choose a vertex ip from Ω and assign it as the pivot for
for Every other vertices iv ∈

Ω

∅

do
ip}
dip,iv .

ip.

Bk:

b

Bk ←
b

∆2, then assign iv as a member of

Bk:

\{
Compute the distance estimate
If
dip,iv ≤
end for
Update Ω: Ω
Ω
b
Update counter: k

k + 1.

Bk.

←

b

\
←
b

end while

iv.

Bk ←
b

b

Algorithm 1 illustrates the pseudo-code for the proposed stochastic block-model approximation.
The complexity of this algorithm is
(T SKn), where T is half the number of observations, S is
the size of the neighborhood, K is the number of blocks and n is number of vertices of the graph.

O

3 Stochastic blockmodel approximation: Theory of estimation

In this section we present the theoretical aspects of the proposed SBA algorithm. We will ﬁrst
discuss the properties of the estimator
dij, and then show the consistency of the estimated graphon
w. Details of the proofs can be found in the supplementary material.

b
3.1 Concentration analysis of

dij

b

Our ﬁrst theorem below shows that the proposed estimator
around its expected value dij.

b

dij is both unbiased, and is concentrated

Theorem 1. The estimator

dij for dij is unbiased, i.e., E[

dij ] = dij . Further, for any ǫ > 0,

b

dij −
h(cid:12)
(cid:12)
where S is the size of the neighborhood
(cid:12) b

Pr

b

(cid:12)
(cid:12)
(cid:12)

S

≤

i

dij

> ǫ

Sǫ2
b
8e−
32/T +8ǫ/3 ,

, and 2T is the number of observations.

(7)

Proof. Here we only highlight the important steps to present the intuition. The basic idea of the
rk
ij and show that it is unbiased. To this end, we use the
proof is to zoom-in a microscopic term of

b

4

fact that Gt1 [i, k] and Gt2 [j, k] are conditionally independent on uk to show

E[Gt1 [i, k]Gt2[j, k]

uk] = Pr[Gt1 [i, k] = 1, Gt2[j, k] = 1

uk]

|

|

(a)
= Pr[Gt1 [i, k] = 1
= w(ui, uk)w(uj , uk),

|

uk] Pr[Gt2 [j, k] = 1

uk]

|

rk
ij ] =
uk]] = rij . The concentration inequality follows from a similar idea to bound the variance

uk] = w(ui, uk)w(uj , uk), and by iterated expectation we have E[

rk
ij |

which then implies E[
E[E[
rk
ij |
rk
ij and apply Bernstein’s inequality.
of
b
b

b

b

That Gt1[i, k] and Gt2[j, k] are conditionally independent on uk is a critical fact for the success of
the proposed algorithm. It also explains why at least 2 independently observed graphs are necessary,
for otherwise we cannot separate the probability in the second equality above marked with (a).

3.2 Choosing the number of blocks

The performance of the Algorithm 1 is sensitive to the number of blocks it deﬁnes. On the one hand,
it is desirable to have more blocks so that the graphon can be ﬁnely approximated. But on the other
hand, if the number of blocks is too large then each block will contain only few vertices. This is bad
because in order to estimate the value on each block, a sufﬁcient number of vertices in each block is
required. The trade-off between these two cases is controlled by the precision parameter ∆: a large
∆ generates few large clusters, while small ∆ generates many small clusters. A precise relationship
between the ∆ and K, the number of blocks generated the algorithm, is given in Theorem 2.
Theorem 2. Let ∆ be the accuracy parameter and K be the number of blocks estimated by Algo-
rithm 1, then

Pr

K >

"

QL√2

∆ # ≤

8n2e−

S∆4
128/T +16∆2/3 ,

where L is the Lipschitz constant and Q is the number of Lipschitz blocks in w.

In practice, we estimate ∆ using a cross-validation scheme to ﬁnd the optimal 2D histogram bin
width (Wasserman 2005). The idea is to test a sequence of potential values of ∆ and seek the one
that minimizes the cross validation risk, deﬁned as

J(∆) =

b

2

−

h(n

1) −

h(n

1)

n + 1

K

−

j=1
X

p2
j ,

b

/n and h = 1/K. Algorithm 2 details the proposed cross-validation scheme.

(8)

(9)

|

b

where

pj =

Bj|
b
Algorithm 2 Cross Validation
Input: Graphs G1, . . . , G2T .
Output: Blocks
B1, . . . ,
for a sequence of ∆’s do

Estimate blocks
B1, . . . ,
b
b
Compute
Bj|
pj =
|
b
J(∆) = 2
Compute
h(n
−
b
end for
b
Pick the ∆ with minimum
b

3.3 Consistency of

w

BK, and optimal ∆.

BK from G1, . . . , G2T . [Algorithm 1]

/n, for j = 1, . . . , K.
K
j=1

n+1

h(n

1)

b
1) −

−

p2
j , with h = 1/K.

P
J(∆), and the corresponding

b

B1, . . . ,

BK.

b

b

b

The goal of our next theorem is to show that
b
To begin with, let us ﬁrst recall two commonly used metric:

w is a consistent estimate of w, i.e.,

w

w as n

.
→ ∞

b

5

→

b

Deﬁnition 1. The mean squared error (MSE) and mean absolute error (MAE) are deﬁned as

(w(uiv , ujv )

w(uiv , ujv ))2

−

w(uiv , ujv )

b
w(uiv , ujv )
|

.

−

b
o(1), then

MSE(

w) =

MAE(

b
w) =

1
n2

1
n2

b

n

n

iv =1
X
n

jv =1
X
n

|

1
4

iv =1
X

jv =1
X

log(n)
n

∈

(cid:18)(cid:16)
w)] = 0

∩

(cid:19)
(cid:17)
and

E[MAE(

lim
n
→∞

b

E[MSE(

w)] = 0.

lim
n
→∞

b

Theorem 3. If S

Θ(n) and ∆

ω

∈

Proof. The details of the proof can be found in the supplementary material . Here we only outline
the key steps to present the intuition of the theorem. The goal of Theorem 3 is to show convergence
of

. The idea is to consider the following two quantities:

w(ui, uj)

w(uix , ujx),

|

w(ui, uj)
|

−

|

b

w(ui, uj) =

w(ui, uj) =

1
Bi| |
1
b
Bi| |
b
so that if we can bound
w(ui, uj)
w(ui, uj)
|

−

b

|

b
b
Bj
Bi Xjx∈

Bj| Xix∈
b
Bj| Xix∈
b
w(ui, uj)
|
can also be bounded.

b
b
Bj
Bi Xjy∈

1
2T

−

w(ui, uj)
|

and

w(ui, uj)

|

w(ui, uj)
|

−

, then consequently

|

w(ui, uj)

w(ui, uj)
|

|
The bound for the ﬁrst term
b
vertex iv ∈
average over

Bj, by Theorem 1 a probability bound involving ∆ can be obtained.

−
Bi is guaranteed to be within a distance ∆ from the pivot of
Bi and
b
is shown in Lemma 2. Different from Lemma
The bound for the second term
b
1, here we need to consider two possible situations: either the intermediate estimate w(ui, uj) is
close to the ground truth w(ui, uj), or w(ui, uj) is far from the ground truth w(ui, uj). This ac-
counts for the sum in Lemma 2. Individual bounds are derived based on Lemma 1 and Theorem 1.

is shown in Lemma 1: By Algorithm 1, any
Bi. Since w(ui, uj) is an

w(ui, uj)
|

w(ui, uj)

−

b

b

b

b

|

Combining Lemma 1 and Lemma 2, we can then bound the error and show convergence.

(G1[ix, jy] + G2[ix, jy] + . . . + G2T [ix, jy]) ,

Lemma 1. For any iv ∈

Bj,

Bi and jv ∈
b
w(ui, uj)

w(uiv , ujv )
|

b

−

Pr

|
h

Lemma 2. For any iv ∈

Bj,

Bi and jv ∈
> 8∆1/2L1/4
b

Pr

wij −

wij|

> 8∆1/2L1/4

32

S∆4
32/T +8∆2/3 .

e−

(10)

≤

i

|

Bi| |
b

Bj|
b

b
2e−

256(T

b
Bi| |

b
Bj |

|

√L∆) + 32

2e−

S∆4
32/T +8∆2/3) .

(11)

|
h
Θ(n) is necessary to make Theorem 3 valid, because if S is independent of n, it
The condition S
. The other condition on ∆ is also important
is not possible to drive (10) and (11) to 0 even if n
as it forces the numerators and denominators in the exponentials of (10) and (11) to be well behaved.

→ ∞

≤

∈

b

i

|

|

2

Bi|
b

Bj|
b

4 Experiments

In this section we evaluate the proposed SBA algorithm by showing some empirical results. For
the purpose of comparison, we consider (i) the universal singular value thresholding (USVT)
(Chatterjee); (ii) the largest-gap algorithm (LG) (Channarond et al. 2012); (iii) matrix completion
from few entries (OptSpace) (Keshavan et al. 2010).

6

4.1 Estimating stochastic blockmodels

Accuracy as a function of growing graph size. Our ﬁrst experiment is to evaluate the proposed
SBA algorithm for estimating stochastic blockmodels. For this purpose, we generate (arbitrarily) a
graphon

which represents a piecewise constant function with 4

4 equi-space blocks.

0.8 0.9 0.4 0.5
0.1 0.6 0.3 0.2
0.3 0.2 0.8 0.3
0.4 0.1 0.2 0.9

,






w = 




×

 

(12)

 

Proposed

)
E
A
M

(
0
1
g
o
l

−0.5

−1

−1.5

−2

−2.5

 
−3
0

Proposed
Largest Gap
OptSpace
USVT

)
E
A
M

(
0
1
g
o
l

−2

−2.1

−2.2

−2.3

−2.4

−2.5

−2.6

−2.7

−2.8

−2.9

 
−3
0

200

400

600

n

800

1000

5

10

15

25

30

35

40

20
2T

(a) Growing graph size, n

(b) Growing no. observations, 2T

Figure 2: (a) MAE reduces as graph size grows. For the fairness of the amount of data that can be
used, we use n
1 observation for USVT (Chatterjee)
and LG (Channarond et al. 2012). (b) MAE of the proposed SBA algorithm reduces when more
observations T is available. Both plots are averaged over 100 independent trials.

2 observations for SBA, and n

n
2 ×

2 ×

×

×

n

Since USVT and LG use only one observed graph whereas the proposed SBA require at least 2
observations, in order to make the comparison fair, we use half of the nodes for SBA by generating
two independent n
n
2 observed graphs. For USVT and LG, we use one n
Figure 2(a) shows the asymptotic behavior of the algorithms when n grows. Figure 2(b) shows the
estimation error of SBA algorithm as T grows for graphs of size 200 vertices.

n observed graph.

2 ×

×

Accuracy as a function of growing number of blocks. Our second experiment is to evaluate the
performance of the algorithms as K, the number of blocks, increases. To this end, we consider a
sequence of K, and for each K we generate a graphon w of K
K blocks. Each entry of the
block is a random number generated from Uniform[0, 1]. Same as the previous experiment, we ﬁx
n = 200 and T = 1. The experiment is repeated over 100 trials so that in every trial a different
graphon is generated. The result shown in Figure 3(a) indicates that while estimation error increases
as K grows, the proposed SBA algorithm still attains the lowest MAE for all K.

×

4.2 Estimation with missing edges

Our next experiment is to evaluate the performance of proposed SBA algorithm when there are
missing edges in the observed graph. To model missing edges, we construct an n
n binary matrix
×
M with probability Pr[M [i, j] = 0] = ξ, where 0
1 deﬁnes the percentage of missing
edges. Given ξ, 2T matrices are generated with missing edges, and the observed graphs are deﬁned
denotes the element-wise multiplication. The goal is to
as M1 ⊙
study how well SBA can reconstruct the graphon

w in the presence of missing links.

G1, . . . , M2T ⊙

G2T , where

≤

≤

⊙

ξ

The modiﬁcation of the proposed SBA algorithm for the case missing links is minimal: when com-
b
Bi and jy ∈
puting (6), instead of averaging over all ix ∈
Bj
that are not masked out by all M ′s. Figure 3(b) shows the result of average over 100 independent
b
b

Bj, we only average ix ∈
b

Bi and jy ∈
b

7

 

 

Proposed
Largest Gap
USVT

 
−1.4
0

5

10
K

15

20

(a) Growing no. blocks, K

Proposed
Largest Gap
OptSpace
USVT

5

10
% missing links

15

20

(b) Missing links

Figure 3: (a) As K increases, MAE of all three algorithm increases but SBA still attains the lowest
MAE. Here, we use n
1 observation for USVT (Chatterjee)
and LG (Channarond et al. 2012). (b) Estimation of graphon in the presence of missing links: As
the amount of missing links increases, estimation error also increases.

2 observations for SBA, and n

n
2 ×

2 ×

×

×

n

trials. Here, we consider the graphon given in (12), with n = 200 and T = 1. It is evident that SBA
outperforms its counterparts at a lower rate of missing links.

4.3 Estimating continuous graphons

Our ﬁnal experiment is to evaluate the proposed SBA algorithm in estimating continuous graphons.
Here, we consider two of the graphons reported in (Chatterjee):

w1(u, v) =

1 + exp

1
50(u2 + v2)
}

,

{−

and w2(u, v) = uv,

where u, v
latent feature relational model (Miller et al. 2009).

∈

[0, 1]. Here, w2 can be considered as a special case of the Eigenmodel (Hoff 2008) or

The results in Figure 4 shows that while both algorithms have improved estimates when n grows, the
performance depends on which of w1 and w2 that we are studying. This suggests that in practice the
choice of the algorithm should depend on the expected structure of the graphon to be estimated: If the
graph generated by the graphon demonstrates some low-rank properties, then USVT is likely to be
a better option. For more structured or complex graphons the proposed procedure is recommended.

 

Proposed
USVT

 

Proposed
USVT

−0.7

−0.8

−0.9

−1

−1.1

−1.2

−1.3

)
E
A
M

(
0
1
g
o
l

)
E
A
M

(
0
1
g
o
l

−2.9

−2.95

−3

−3.05

−3.1

−3.15

 
−3.2
0

)
E
A
M

(
0
1
g
o
l

−0.6

−0.7

−0.8

−0.9

−1

−1.1

−1.2

−1.3

−1.4

−1.5

 
−1.6
0

)
E
A
M

(
0
1
g
o
l

−0.6

−0.8

−1

−1.2

−1.4

−1.6

−1.8

 
−2
0

200

400

600

n

800

1000

200

400

600

n

800

1000

(a) graphon w1

(b) graphon w2

Figure 4: Comparison between SBA and USVT in estimating two continuous graphons w1 and w2.
Evidently, SBA performs better for w1 (high-rank) and worse for w2 (low-rank).

8

5 Concluding remarks

We presented a new computational tool for estimating graphons. The proposed algorithm approx-
imates the continuous graphon by a stochastic block-model, in which the ﬁrst step is to cluster
the unknown vertex labels into blocks by using an empirical estimate of the distance between two
graphon slices, and the second step is to build an empirical histogram to estimate the graphon. Com-
plete consistency analysis of the algorithm is derived. The algorithm was evaluated experimentally,
and we found that the algorithm is effective in estimating block structured graphons.

Code. An implementation of the stochastic blockmodel approximation (SBA) algorithm proposed
in this paper is available online at: https://github.com/airoldilab/SBA

Acknowledgments. EMA is partially supported by NSF CAREER award IIS-1149662, ARO MURI
award W911NF-11-1-0036, and an Alfred P. Sloan Research Fellowship. SHC is partially supported
by a Croucher Foundation Post-Doctoral Research Fellowship.

References

E.M. Airoldi, D.M. Blei, S.E. Fienberg, and E.P. Xing. Mixed-membership stochastic blockmodels. Journal of

Machine Learning Research, 9:1981–2014, 2008.

D.J. Aldous. Representations for partially exchangeable arrays of random variables. Journal of Multivariate

Analysis, 11:581–598, 1981.

Research, W&CP, 22:54–63, 2012.

H. Azari and E. M. Airoldi. Graphlet decomposition of a weighted network. Journal of Machine Learning

P.J. Bickel and A. Chen. A nonparametric view of network models and Newman-Girvan and other modularities.

Proc. Natl. Acad. Sci. USA, 106:21068–21073, 2009.

P.J. Bickel, A. Chen, and E. Levina. The method of moments and degree distributions for network models.

Annals of Statistics, 39(5):2280–2301, 2011.

C. Borgs, J. Chayes, L. Lov´asz, V. T. S´os, B. Szegedy, and K. Vesztergombi. Graph limits and parameter

testing. In Proc. ACM Symposium on Theory of Computing, pages 261–270, 2006.

A. Channarond, J. Daudin, and S. Robin. Classiﬁcation and estimation in the Stochastic Blockmodel based on

the empirical degrees. Electronic Journal of Statistics, 6:2574–2601, 2012.

S. Chatterjee. Matrix estimation by universal singular value thresholding. ArXiv:1212.1247. 2012.

D.S. Choi and P.J. Wolfe. Co-clustering separately exchangeable network data. ArXiv:1212.4093. 2012.

D.S. Choi, P.J. Wolfe, and E.M. Airoldi. Stochastic blockmodels with a growing number of classes. Biometrika,

99:273–284, 2012.

P. Diaconis and S. Janson. Graph limits and exchangeable random graphs. Rendiconti di Matematica e delle

sue Applicazioni, Series VII, pages 33–61, 2008.

S. E. Fienberg, M. M. Meyer, and S. Wasserman. Statistical analysis of multiple sociometric relations. Journal

of the American Statistical Association, 80:51–67, 1985.

A. Goldenberg, A.X. Zheng, S.E. Fienberg, and E.M. Airoldi. A survey of statistical network models. Founda-

tions and Trends in Machine Learning, 2:129–233, 2009.

M. Handcock, A. E. Raftery, and J. Tantrum. Model-based clustering for social networks (with discussion).

Journal of the Royal Statistical Society, Series A, 170:301–354, 2007.

P.D. Hoff. Modeling homophily and stochastic equivalence in symmetric relational data. In Neural Information

Processing Systems (NIPS), volume 20, pages 657–664, 2008.

P.D. Hoff, A.E. Raftery, and M.S. Handcock. Latent space approaches to social network analysis. Journal of

the American Statistical Association, 97(460):1090–1098, 2002.

D.N. Hoover. Relations on probability spaces and arrays of random variables. Preprint, Institute for Advanced

Study, Princeton, NJ, 1979.

(1):137–154, 1989.

Theory, 56:2980–2998, Jun. 2010.

O. Kallenberg. On the representation theorem for exchangeable arrays. Journal of Multivariate Analysis, 30

R.H. Keshavan, A. Montanari, and S. Oh. Matrix completion from a few entries. IEEE Trans. Information

E. D. Kolaczyk. Statistical Analysis of Network Data: Methods and Models. Springer, 2009.

9

N.D. Lawrence. Probabilistic non-linear principal component analysis with Gaussian process latent variable

models. Journal of Machine Learning Research, 6:1783–1816, 2005.

J.R. Lloyd, P. Orbanz, Z. Ghahramani, and D.M. Roy. Random function priors for exchangeable arrays with

applications to graphs and relational data. In Neural Information Processing Systems (NIPS), 2012.

L. Lov´asz and B. Szegedy. Limits of dense graph sequences. Journal of Combinatorial Theory, Series B, 96:

933–957, 2006.

K.T. Miller, T.L. Grifﬁths, and M.I. Jordan. Nonparametric latent fature models for link prediction. In Neural

Information Processing Systems (NIPS), 2009.

K. Nowicki and T. A. B. Snijders. Estimation and prediction for stochastic blockstructures. Journal of the

American Statistical Association, 96:1077–1087, 2001.

P. Orbanz and D.M. Roy. Bayesian models of graphs, arrays and other exchangeable random structures, 2013.

Unpublished manuscript.

P.Latouche and S. Robin. Bayesian model averaging of stochastic block models to estimate the graphon function
and motif frequencies in a w-graph model. ArXiv:1310.6150, October 2013. Unpublished manuscript.

K. Rohe, S. Chatterjee, and B. Yu. Spectral clustering and the high-dimensional stochastic blockmodel. Annals

of Statistics, 39(4):1878–1915, 2011.

Annals of Statistics, 2013. In press.

M. Tang, D.L. Sussman, and C.E. Priebe. Universally consistent vertex classiﬁcation for latent positions graphs.

L. Wasserman. All of Nonparametric Statistics. Springer, 2005.

P.J. Wolfe and S.C. Olhede. Nonparametric graphon estimation. ArXiv:1309.5936, September 2013. Unpub-

lished manuscript.

Z. Xu, F. Yan, and Y. Qi. Inﬁnite Tucker decomposition: nonparametric Bayesian models for multiway data

analysis. In Proc. Intl. Conf. Machine Learning (ICML), 2012.

Y. Zhao, E. Levina, and J. Zhu. Community extraction for social networks. In Proc. Natl. Acad. Sci. USA,

volume 108, pages 7321–7326, 2011.

Theorem 1. The estimator

dij for dij is unbiased. Further, for any ǫ > 0, if the graph is directed, then

A Proofs for Section 3.1

and if the graph is un-directed, then

(13)

(14)

where S is the size of the sampling neighborhood

, and 2T is the number of observations.

Proof. First, for given ui and uj, let us deﬁne the following two quantities

b

Pr

dij

dij

> ǫ

Sǫ2
32/T +8ǫ/3 ,

8e−

−

−

h(cid:12)
(cid:12)
(cid:12) b

h(cid:12)
(cid:12)
(cid:12) b

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
S

≤

i

≤

i

Pr

dij

dij

> ǫ

Sǫ2
64/T +8ǫ/3 ,

8e−

cij

def
=

rij

def
=

1

0
Z

1

0
Z

w(x, ui)w(x, uj)dx,

w(ui, y)w(uj, y)dy.

Consequently, we express dij as

dij

def
=

1

1
2
1
2

0

(cid:18)Z
[(rii

=

(w(ui, y)

w(uj , y))2dy +

(w(x, ui)

w(x, uj ))2dx

−

−

(cid:19)

rij

rji + rjj ) + (cii

cji + cjj )] .

−

−

1

0
Z
cij

−

−

In order to study

dij (the estimator of dij ), it is desired to express

dij in the same form of dij:

b
dij =

1
S

b

1
2

∈S (cid:26)
Xk

h(cid:16)

rk
ii −

rk
ij −

rk
ji +

rk
jj

+

ck
b
ii −

ck
ij −

ck
ji +

ck
jj

(cid:17)

(cid:16)

,

(cid:17)i(cid:27)

b

b

b

b

b

b

b

b

(15)

10

where
=
deﬁned as

S

{

}\{

}

1, . . . , n

i, j

is the sampling neighborhood, and S =

. In (15), individual components are

|S|

,

.







ck
ij =

b
rk
ij =

1
T 2 



1
T 2 

Gt1 [k, i]

Gt2 [k, j]

t1≤
X1
≤

T

XT <t2≤

2T













Gt1 [i, k]

Gt2 [j, k]

t1≤
X1
≤

T

XT <t2≤

2T






ij are unbiased estimators of rij and cij , i.e., E[
ck
dij will be an unbiased estimator of dij.
b
b
Pr

+ 0

Pr

·

Gt1 [i, k]Gt2 [j, k] = 1
h

i
Gt1 [i, k] = 1 and Gt2 [j, k] = 1
h

uk

(cid:12)
(cid:12)
(cid:12)

= Pr

= Pr[Gt1 [i, k] = 1
= w(ui, uk)w(uj, uk).

|

uk]

·

·

uk

(cid:12)
(cid:12)
(cid:12)

i
|

ij ] = rij and E[
rk

ck
ij ] = cij ,

Gt1 [i, k]Gt2 [j, k] = 1
h

uk

i

b

(cid:12)
(cid:12)
(cid:12)

Pr[Gt2 [j, k] = 1

uk],

because Gt1 [i, k]

⊥

Gt2 [j, k]
(16)

b
rk
ij and
Thus, if we can show that
then by linearity of expectation,

E[Gt1 [i, k]Gt2 [j, k]

uk] = 1

|

Therefore,

b
To this end, we consider the conditional expectation of Gt1 [i, k]Gt2 [j, k] given uk:

b

E

rk
ij |
h

b

uk

=

i

=

1
T 2

1
T 2

 

 

2T

T

t2=T +1
X
2T

t1=1
X
T

Xt2=T +1
= w(ui, uk)w(uj , uk).

t1=1
X

E

Gt1 [i, k]Gt2 [j, k]
h

|

uk

!
i

w(ui, uk)w(uj, uk)

,

by substituting (16)

!

Then, by the law of iterated expectations, we have

E

rk
ij
h

b

= E

E

uk

rk
ij |
h

b

i

= E

h
w(ui, uk)w(uj , uk)

ii

,

by substituting (17)

h
1

i
w(ui, v)w(uj, v)dv,

=

0
Z
= rij .

because uk

Uniform(0, 1)

∼

rk
Therefore,
ij is an unbiased estimator of rij . The proof of
ck
Gt[i, k] to Gt[k, i]. Since
ij are both unbiased,
b

rk
ij and

b

dij must be unbiased.

b

b

b

cij can be similarly proved by switching roles of

(17)

(18)

Now we proceed to prove the second part of the theorem. We ﬁrst claim that

To prove this, we note that

Var

2/T and Var

2/T.

(19)

≤

rk
ij
h

i

b

2T

T

ck
ij

h
b

≤

i

Var

rk
ij

= Var

h

i

b

=

"

2T

Xt2=T +1
T

t1=1
X

Gt1 [ik]Gt2 [jk]

#

Var

Gt1 [ik]Gt2 [jk]
i

h

t2=T +1
X

t1=1
X

2T

2T

T

T

+

Xτ2=T +1
=t2
τ26

Xt2=T +1

τ1=1
X
=t1
τ16

t1=1
X

Cov

Gt1 [ik]Gt2 [jk], Gτ1 [ik]Gτ2 [jk]
i
h

11

We consider three cases:

Case 1. First assume τ1

= t1 and τ2

= t2. (Occurs (T

1)2T 2 times.)

−

E[Gt1 [ik]Gt2 [jk]]) (Gτ1 [ik]Gτ2 [jk]

E[Gτ1 [ik]Gτ2 [jk]])

(Gt1 [ik]Gt2 [jk]

wikwjk) (Gτ1 [ik]Gτ2 [jk]

wikwjk)

i

Gt1 [ik]Gt2 [jk], Gτ1 [ik]Gτ2 [jk]
i

(Gt1 [ik]Gt2 [jk]

Cov

h
= E

h

= E

−

−

= E

= E

h
Gt1 [ik]Gt2 [jk]Gτ1 [ik]Gτ2 [jk]
i
h
Gt1 [ik]Gt2 [jk]Gτ1 [ik]Gτ2 [jk]
i
h

−

−

−

i
wikwjk

E

−
Gτ1 [ik]Gτ2 [jk]
i
h
ikw2
w2
jk

E

−

Gt1 [ik]Gt2 [jk]
i
h

wikwjk + w2

ikw2

jk

(20)

The ﬁrst term in (20) is E
Gτ2 [jk] are all independent. Therefore, the overall sum in (20) is 0.

Gt1 [ik]Gt2 [jk]Gτ1 [ik]Gτ2 [jk]
i
h

= w2

ikw2

jk because Gt1 [ik], Gt2 [jk], Gτ1 [ik] and

Case 2. Next assume that τ1

= t1 but τ2 = t2. (Occurs (T

1)T 2 times.) In this case,

E

Gt1 [ik]Gt2 [jk]Gτ1 [ik]Gτ2 [jk]
i
h

E

Gt2 [jk]Gτ2 [jk]
i
h

E

= E

−
Gτ1 [ik]
Gt1 [ik]
i
i
h
h
= wikwikE
Gt2 [jk]2
h

i

= w2

ikwjk.

= w2

ikwjk

w2

ikw2

jk = w2

ikwjk(1

−

wjk)

1.

≤

−

Substituting this result into (20) yields the covariance

Cov

h
Case 3. Assume τ1 = t1 but τ2

Gt1 [ik]Gt2 [jk], Gτ1 [ik]Gτ2 [jk]
i
= t2. (Occurs (T

1)T 2 times.) In this case,

−

E

Gt1 [ik]Gt2 [jk]Gτ1 [ik]Gτ2 [jk]
i
h

= wikw2

jk,

and so the covariance becomes

Gt1 [ik]Gt2 [jk], Gτ1 [ik]Gτ2 [jk]
i
h
Combining all 3 cases, we have the following bound:

Cov

= wikw2

jk(1

wik)

1.

≤

−

Var[

rk
ij] =

1
T 4 Var

b

Gt1 [ik]Gt2 [jk]

#

"

t2
t1 X
X

"

Var

Gt1 [ik]Gt2 [jk]
t2
t1 X
i
h
X
T 2wikwjk(1

wikwjk) + (T

1
T 4

1
T 4
1
T 4
2T

=

=

≤

=

−
1)T 2

−

(cid:3)

(cid:2)

T 2 + 2(T

2
T

.

(cid:2)
−

1
T 2 ≤
ck
ij

The bound for Var

can be proved similarly.

+ (T

1)T 2w2

ikwjk(1

wjk) + (T

1)T 2wikw2

jk(1

wik)

−

−

−

−

#

1)T 2w2

ikwjk(1

wjk) + (T

1)T 2wikw2

jk(1

wik)

−

−

−

−

(cid:3)

(cid:3)

Next, we observe that Gt (for any t) is a directed graph. So the random variables Gt1 [i, k] and Gt1 [k, i]
the product variables
are independent. Similarly, Gt2 [j, k] and Gt2 [k, j] are independent. Therefore,
= j and
Gt1 [i, k]Gt2 [j, k] and Gt1 [k, i]Gt2 [k, j] must be independent for any ﬁxed ui, uj and uk, where i
k =

ck
ij are independent, and hence

. Consequently,

rk
ij and

1, . . . , n

(cid:2)
b

i, j

{

}\{

}

which implies that

rk
ij and

ij are uncorrelated: E
ck

rij)(

cij )

= 0. Consequently,

E[
b

rk
ij

ij ] = E
ck
b

rk
ij
h
i
= rijcij ,

·

b

b

b
rk
ij −

(

E

i

ck
ij
h
b
ck
ij −

b

Var
b

1
2

(cid:20)

ck
ij

rk
ij +
(cid:16)

b

b

(cid:17)(cid:21)

=

1
(cid:2)
4

Var

b
(cid:16)

rk
ij
h

+ Var
b
i

1
T

.

≤

(cid:3)
ck
ij
h
b

i(cid:17)

b

12

Since

rij = 1
S

rk
ij and

cij = 1
S

ck
ij , by Bernstein’s inequality we have

k
∈S
P

cij )

b

−

1
2

b
(rij + cij )

k
∈S
P

b
rij +

(

b

b

b
Pr

1
2

(cid:20)(cid:12)
(cid:12)
(cid:12)
(cid:12)

Finally, we note that

> ǫ

= Pr

(cid:21)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

2e−

≤

1
S

1
2

rk
ij +

ck
ij

"(cid:12)
Xk
(cid:12)
∈S
(cid:12)
(cid:12)
2(Var[ 1
(cid:12)

(cid:17)

(cid:16)
Sǫ2
b
ij)]+ǫ/3)
+bck

b

2 ( brk
ij

1
2

−

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

Sǫ2
2(1/T +ǫ/3) .

2e−

≤

(rij + cij )

> ǫ

#

dij
|

−

dij

| ≤

b

1
2 |
1
2 |

−

−

−

−

|

|

rji +
b

cji
b

rji

cji

+

1
2 |
1
2 |

rii +

cii

rii

cii

+

rij +

cij

rij

cij

+

−

−

|

rjj +
b

cjj
b

rjj

cjj

.

|

−

−

Therefore by union bound we have

b

b

b

b

dij
Pr[
|
Pr
b

≤

−
1
2 |

+

h

> ǫ]

dij

|
rii +

−

1
b
2 |

rji +
b

cji

Pr

≤

1
2

−

1
2

−

1
2 |

|

−

rji

cji

+

−

|

1
b
2 |

cii

rii

cii

+

rij +

cij

rij

cij

+

−

−

|

rjj +
b

cjj

rjj

cjj

> ǫ

−

|

−

(

rii +
b

cii)
b

(rii + cii)

> ǫ/4
b

+ Pr
b

(

rij +

(rij + cij )

> ǫ/4

+

b
rji +

h (cid:12)
(cid:12)
1
(cid:12)
b
+ Pr
(
(cid:12)
2
h (cid:12)
(cid:12)
Sǫ2 /16
(cid:12)
b
2(1/T +ǫ/12) = 8e−
(cid:12)

8e−

cji)

b

−

1
2

(cid:12)
(cid:12)
(cid:12)
(cid:12)

i
> ǫ/4

h (cid:12)
(cid:12)
(cid:12)
+ Pr
(cid:12)

(rji + cji)

Sǫ2
32/T +8ǫ/3 .

(cid:12)
(cid:12)
(cid:12)
(cid:12)

i

(

b
rjj +

cjj )

(rjj + cjj )

1
2

−

b

b

(cid:12)
(cid:12)
(cid:12)
(cid:12)

i
> ǫ/4

i

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
2

1
b
2

h (cid:12)
(cid:12)
(cid:12)
(cid:12)

i
cij )

1
2

−

≤

(cid:2)

(cid:0)

If the graph is un-directed, then ck
Var

ij + ck
rk
ij

1
T . In this case,

1
2

≤

(cid:1)(cid:3)

B Proofs for Section 3.2

ij = rk

ij and we can only have Var

1
2

rk
ij + ck
ij

2
T instead of

(cid:2)

(cid:0)

≤

(cid:1)(cid:3)

dij
Pr[
|

−

dij

> ǫ]

|

≤

Sǫ2
64/T +8ǫ/3 .

8e−

b

Theorem 2. Let ∆ be the accuracy parameter and K be the number of blocks estimated by Algorithm 1, then

where L is the Lipschitz constant and Q is the number of Lipschitz blocks in the ground truth w.

Pr

K >

(cid:20)

QL√2
∆

≤

(cid:21)

8n2e−

S∆4
128/T +16∆2/3 ,

(21)

Proof. Recall that in deﬁning the Lipschitz condition of w (Section 2.1), we deﬁned a sequence of non-
overlapping intervals Ik = [αk, αk+1], where 0 = α0 < . . . < αQ = 1, and Q is the number of Lipschitz
blocks of w. For each of the interval Ik, we divide it into R
∆ subintervals of equal size 1/R. Thus,
the distance between any two elements in the same subinterval is at most 1/R. Also, the total number of
subintervals over [0, 1] is QR.

def
= L√2

Now, suppose that there are K > QR = QL√2
∆ blocks deﬁned by the algorithm, and denote the K pivots be
p1, . . . , pK. By the pigeonhole principle, there must be at least two pivots pi and pj in the same sub-interval.
In this case, the distance dpi,pj must satisfy the following condition:

dpi,pj =

(w(x, upi )

w(x, upj ))2dx +

(w(upi , y)

w(upj , y))2dy

1

0

Z

−

(cid:19)

−

1

1
2
0
(cid:18)Z
L2(upi −
L2 1
R2 =

≤

≤

upj )2
∆2
2

.

However, from the algorithm it holds that

∆2. So, if K > QR, then

dpi,pj ≥
b

13

dpi,pj > ∆2
2 .

dpi,pj −
b

Let

be the following event:

E

∆2
2

dpi,pj >

for at least one pair of pi, pj

.

(cid:27)

=

E

(cid:26)

dpi,pj −
b

E

Then, since the event

is a consequence of the event

K > QR

, we have

{

}

Pr

K >

= Pr[K > QR]

Pr[

].

≤

E

QL√2
∆

(cid:21)

(cid:20)

To bound Pr[

], we observe that

E

Pr

dpi,pj −
b
Therefore, by union bound,

(cid:20)

∆2
2

(cid:12)
(cid:12)
(cid:12)

≤

(cid:21)

dpi,pj >

pi, pj

8e−

32/T +8(∆2 /2)/3 = 8e−

S(∆2/2)2

S∆4
128/T +16∆2/3 .

and hence,

Pr

p1, . . . , pK

E
h

(cid:12)
(cid:12)
(cid:12)

Pr

(cid:20)

dpi,pj −
b

S∆4
128/T +16∆2/3 ,

pi,pj
X
8n2e−

≤

i

≤

dpi,pj >

pi, pj

(cid:21)

∆2
2

(cid:12)
(cid:12)
(cid:12)

Pr [

] =

E

Pr [

p1, . . . , pK] Pr [p1, . . . , pK]

E |

S∆4
128/T +16∆2/3

p1,...,pK
X
8n2e−

≤

(cid:18)

= 8n2e−

S∆4
128/T +16∆2/3 .

Pr [p1, . . . , pK]

·

(cid:19)

p1,...,pK
X

This completes the proof.

C Proofs for Section 3.3

Lemma 1. Let
Bi =
gorithm. Suppose that

vertices in

b
Bi and

Bj, respectively. Let

i1, i2, . . . , i
b
Bi|}
{
|
ui1 , ui2 , . . . , ui
{

and

| bBi | }

Bj =
and
b

j1, j2, . . . , j
b
Bj |}
{
|
uj1 , uj2 , . . . , uj
| bBj | }
{

be two clusters returned by the Al-
are the ground truth labels of the

b

b

wij =

w(uix , ujx ).

b
b
| Xix ∈
Bi Xjx ∈
Bj
Assume that the precision parameter satisﬁes ∆2 < δ2L
the smallest Lipschitz interval. Then, for any iv

Bi and jv

b

b

||

∈

Bj ,

∈

1

Bj

Bi
|

4 , where L is the Lipschitz constant and δ is the size of

Pr

wij
|
h

−

w(uiv ,jv )

> 8∆1/2L1/4
b

|

b
Bi
32
|

||

Bj

e−
|

≤

S∆4
32/T +8∆2/3 .

i

(22)

(23)

Proof. Let ip
holds that

∈
dip ,iv | ≤
|
b
b

Bi and jp

Bi and

Bj be pivots of the clusters
∈
∆2 and
djp,jv | ≤
|
b
0
b
dip,iv ≤

∆2 for any vertices iv
b
dip,iv + ∆2
b
dip,iv −

+ ∆2
≤ −
dip,iv + ∆2

dip,iv |
dip,iv −
b

≤ |
b

≤ −|

⇒

∈

b

which implies that

b

b

b
Bj, respectively. By deﬁnition of pivots, it

Bi and jv

Bj . Therefore,

∈

+ ∆2,

b
dip,iv |
b
+ ∆2 > 2∆2

i

> ∆2

i

Pr

dip,iv > 2∆2

(cid:2)

≤

(cid:3)

= Pr

Pr

dip,iv −
dip,iv |
|
h
dip,iv −
dip,iv |
b
|
h
S∆4
b
32/T +8∆2/3 .
8e−

≤

14

Similarly, we have Pr

djp,jv > 2∆2

8e−

32/T +8∆2/3 . Thus,

≤

∪

Pr

dip,iv > 2∆2

(cid:2)

(cid:3)
djp,jv > 2∆2

Pr

+ Pr

djp,jv > 2∆2

(cid:2)

(cid:2)

(cid:3)

dip,iv > 2∆2
S∆4
32/T +8∆2/3 .

(cid:3)

(cid:2)
16e−

S∆4

(cid:3)

≤

≤

ij =

1
Let dc
0 (w(x, ui)
for any 0 < (ǫ/2)2 < 2δL, if dc
R

−

w(x, uj))2dx and dr

ij =
(ǫ/2)4
8L = ǫ4
128L and dr
R

1
0 (w(ui, y)

i,j ≤

w(uj, y))2dy. By Lemma 5, it holds that

i,j ≤
w(x, uj )

w(x, ui)

w(ui, y)

w(uj, y)

−

−

−
ǫ4
128L , then
ǫ
2
ǫ
2

| ≤

| ≤

,

.

x

sup

[0,1] |

∈
sup
[0,1] |

y

∈

Therefore, if dc
jp

ip,iv ≤
Bj , and vertex iv

∈

w(uiv , ujv )
b
|

−

ǫ4
128L , dr
Bi, jv

ip,iv ≤
Bj :
∈
w(uip , ujp )
b

∈

ǫ4
128L , dc

jp,jv ≤

ǫ4
128L and dr

jp ,jv ≤

ǫ4
128L , then for pivots ip

−

w(uiv , ujp )

+
w(x, ujp )

|

w(x, ujv )

−

w(uiv , ujp )
|
+ sup
y

[0,1] |

|

−
w(uiv , y)

−

w(uip , ujp )

|
w(ujp , y)

|

∈

b
| ≤ |
≤

=

w(uiv , ujv )
sup
[0,1] |
ǫ
2

= ǫ.

x
∈
ǫ
2

+

Also, if dc

ip,ix ≤

ǫ4
128L , dr

ip,ix ≤

ǫ4
128L , dc

jp ,jx ≤

ǫ4
128L and dr

jp,jx ≤

ǫ4
128L for vertex every ix

Bi, jx

Bj

∈

∈

w(uix , ujx )

w(uip , ujp )

−

b
b
| Xix∈
Bi Xjx∈
Bj

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1

−

Bi
|

b
| Xix∈
Bi

1

Bj

b
1

||

b

Bi
|

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
≤ (cid:12)
Bi
(cid:12)
|
(cid:12)
(cid:12)
1
(cid:12)
b
(cid:12)
Bi
|

≤

|

1
b
Bi
|

|

≤

Bj

||

1
b
Bj
|

1
b
Bj
|

b
b
| Xix∈
Bi Xjx ∈
Bj

b
b
| Xix ∈
Bi Xjx ∈
Bj (cid:12)
(cid:12)
ǫ
2

b
b
| Xix ∈
Bi Xjx ∈
Bj

1

+

Bi
|

b
| Xix ∈
Bi

ǫ
2

= ǫ.

Combining (24) and (25) with triangle inequality yields

b

b

b

w(uix , ujx )

w(uix , ujp )

+

w(uix , ujp )

w(uip , ujp )

−

w(uix , ujx )

b
w(uix , ujp )

+

−

b
w(uix , ujp )

w(uip , ujp )

−

1

Bi
|

b
| Xix∈
Bi

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
b
| Xix∈
Bi (cid:12)
(cid:12)

1

Bi
|

b

(cid:12)
(cid:12)

Bi,

∈

b

(24)

b

b

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)

(25)

1

b
b
| Xix∈
Bi Xjx ∈
Bj
Consequently, by contrapositive this implies that

||

b

b

Bj

Bi
|

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

w(uix , ujx )

w(uiv , ujv )

−

2ǫ.

≤

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

dr
ip,ix >

128L ∪

dc
jp,jx >

ǫ4

128L ∪

dr
jp,jx >

ǫ4
128L

(cid:19)

wij

|

−

w(uiv , ujv )

> 2ǫ

|
dc
ip,ix >

b
Bi,jx ∈
[ix∈

b
Bj (cid:18)

⇒

⇒

b
Bi,jx ∈
[ix∈

b
Bj (cid:18)

Therefore,

dip,ix >

djp,jx >

128L ∪

ǫ4

128L ∪

ǫ4
128L

.

(cid:19)

Pr [
wij
|

−

w(uiv , ujv )

> 2ǫ]

Pr

|

ǫ4

ǫ4

≤

≤

dip,ix >

djp,jx >

ǫ4

128L ∪

ǫ4
128L

Pr

dip,ix >

+ Pr

djp,jx >

ǫ4
128L

(cid:21)

(cid:20)



(cid:19)

ǫ4
128L

.

(cid:21)(cid:19)





b
Bi,jx∈
[ix∈

b
Bj (cid:18)

b
Bi,jx∈
Xix∈

b
Bj (cid:18)

(cid:20)

15

Assuming ∆ < δ√L/2 and setting ǫ = 4∆1/2L1/4, we have 0 < (ǫ/2)2 < 2δL and thus

Pr

wij
|

−

h

w(uiv , ujv )

> 8∆1/2L1/4

|

Pr

dip,ix > 2∆2

+ Pr

djp,jx > 2∆2

(cid:3)

(cid:2)

(cid:3)(cid:1)

≤

i

b
Bi,jx∈
Xix∈

b
Bj (cid:0)

Bi
32
|

||

Bj

e−
|

≤

(cid:2)
S∆4
32/T +8∆2/3 .

b
Bj =
and
b

b
j1, j2, . . . , j
b
Bj |}
{
|
uj1 , uj2 , . . . , uj
| bBj | }
{

Lemma 2. Let
Bi =
gorithm. Suppose that

vertices in

b
Bi and

i1, i2, . . . , i
b
Bi|}
{
|
ui1 , ui2 , . . . , ui
{

and

| bBi | }

Bj, respectively. Let

be two clusters returned by the Al-
are the ground truth labels of the

b

b

wij =

b
wij =

1

||
1

||

Bj

b
Bj

Bi
|

b
Bi
|

b

b

b
b
Bj (cid:18)
| Xix∈
Bi Xjx ∈

b
b
| Xix∈
Bi Xjx ∈
Bj

w(uix , ujx ).

G1[ix, jx] + . . . + G2T [ix, jx]
2T

,

(cid:19)

Then,

Pr

wij
|
h

b

wij

> 8∆1/2L1/4

−

|

256(T

2e−

b
Bi | |

b
Bj |

|

√L∆) + 32
Bi
|

2
|

Bj
|

2e−
|

S∆4
32/T +8∆2/3 .

≤

i

Proof. There are two possible situations that we need to consider.

b

b

Case 1: For any vertex iv
is close to the ground truth wij
iv

Bi and jv

∈
Case 2: Complement of case 1.

Bi and jv
∈
def
= w(uiv , ujv ).
wij
|

b
b
Bj , so that the difference

∈

∈

b

b

To encapsulate these two cases, we ﬁrst deﬁne the event

Bj , the estimate of the previous lemma wij (independent of (iv, jv))
In other words, we want w(uiv , ujv ) to stay close for all
wij

remains small for all iv

Bi and jv

Bj.

−

|

∈

b

∈

b

=

wij
|
n
be the complement of

E

. Then,

E
> 8∆1/2L1/4

and deﬁne

E

Pr

wij

|

−

wij
|
h

b

So it remains to bound the two probabilities.

Conditioning on

, it holds that

E

wij

−

| ≤

8∆1/2L1/4,

iv

∀

∈

Bi, jv

Bj

∈

b

o

b

wij

> 8∆1/2L1/4

wij

−

wij

(cid:12)
> 8∆1/2L1/4
(cid:12)
(cid:12)

|
> 8∆1/2L1/4

|

|

Pr [

]

E

Pr

i
(cid:2)
+ Pr

E

(cid:12)
(cid:12)
(cid:12)
E

i
E

i

E

(cid:3)
E

.

(cid:2)

(cid:3)

(cid:12)
(cid:12)
(cid:12)

= Pr

wij
|
h
+ Pr

i

−

Pr

≤

wij
b
|
h
wij
b
|
h

−

b

wij
Fix a vertex pair (iv, jv), we note that G1[iv, jv], . . . , G2T [iv, jv] are independent Bernoulli random variable
with common mean w(uiv , ujv ). Denote

w + ǫ.

wij

−

≤

≤

ǫ

2T

1

2T

Bj

Bi
|

||

|

t=1
X

b
b
Bi Xjx∈
Xix∈
Bj

Gt[ix, jx],

then by Hoeffding inequality we have

b

b

Pr

wij

wij > 2ǫ

= Pr

wij > wij + 2ǫ

wij =

b

h

b

−

E

i

(cid:12)
(cid:12)
(cid:12)

h

Pr

≤

wij > wij + ǫ
b

e−

h
2(2T
b

b
Bi ||

b
Bj |

|

ǫ2),

b
Bj |

ǫ2). Therefore,

≤
b
Bi | |

|

(cid:12)
(cid:12)
(cid:12)

E

i

(cid:12)
(cid:12)
(cid:12)
E

i

2(2T

2e−

b
Bi | |

b
Bj |

|

ǫ2).

and similarly Pr

wij

wij <

2ǫ

2(2T

e−

−

−

E

≤

h

b

Pr

i

−

(cid:12)
(cid:12)
wij
(cid:12)
|
h

b

wij

> 2ǫ

|

E

≤

i

(cid:12)
(cid:12)
(cid:12)

16

Substituting ǫ = 4∆1/2L1/4, we have

Pr

wij
|

−

|

wij

> 8∆1/2L1/4

E

≤

128(

b
Bi | |

b
Bj |

|

2e−

(2T )√L∆).

h
The second probability is bounded as follows. Since
where at least one (iv, jv) violates the condition. Therefore,

b

E

i

(cid:12)
(cid:12)
(cid:12)
is the complement of

E

, it is bounded by the probability

Pr

= Pr

at least one iv, jv s.t.

E

(cid:2)

(cid:3)

h

w(uiv , ujv )
|

wij

> 8∆1/2L1/4

−

|
> 8∆1/2L1/4

i

≤

b
b
Bi Xjv ∈
Xiv ∈
Bj

Pr

w(uiv , ujv )
|
h

wij

|

−

Bi
32
|

2
|

Bj
|

2e−
|

≤

S∆4
32/T +8∆2/3 .

i

Finally, by combining the above results we have

b

b

wij

> 8∆1/2L1/4

−

|

256(T

2e−

b
Bi | |

b
Bj |

|

√L∆) + 32
Bi
|

2
|

Bj
|

2e−
|

S∆4
32/T +8∆2/3 .

Pr

wij
|
h

≤

i

b
Lemma 3. Let
Bi =
gorithm. Suppose that

vertices in

b
Bi and

i1, i2, . . . , i
b
Bi|}
{
|
ui1 , ui2 , . . . , ui
{

and

| bBi | }

Bj =
and
b

j1, j2, . . . , j
b
Bj |}
{
|
uj1 , uj2 , . . . , uj
| bBj | }
{

Bj, respectively. Let

b

b
be two clusters returned by the Al-
are the ground truth labels of the

b

b

wij =

Then,

b

1

Bj

Bi
|

||

b

b

G1[ix, jx] + . . . + G2T [ix, jx]
2T

.

(cid:19)

b
b
Bj (cid:18)
| Xix∈
Bi Xjx ∈

256(T

2e−

b
Bi | |

b
Bj |

|

√L∆) + 64n4e−

S∆4
32/T +8∆2/3 .

wij

|

−

> 16∆1/2L1/4

≤

i

Proof. By Lemma 1 and Lemma 2, we have

wij

> 8∆1/2L1/4

−

|

256(T

2e−

b
Bi | |

b
Bj |

|

√L∆) + 32
Bi
|

2
|

Bj
|

2e−
|

S∆4
32/T +8∆2/3

wij > 8∆1/2L1/4

Bi
32
|

||

Bj

e−
|

≤

S∆4
32/T +8∆2/3 .

b

b

≤

i

i

Therefore, it follows that

wij

|

−

> 16∆1/2L1/4

Pr

wij
|
h

b

b
wij

b
> 8∆1/2L1/4

Pr

wij
|

h
256(T
2e−
b

−
b
Bi | |

|

|

b
Bj |

256(T

2e−

b
Bi | |

b
Bj |

|

i

≤

≤

≤

+ Pr

wij

wij > 8∆1/2L1/4

−

S∆4

32/T +8∆2/3 + 32
Bi
|

||

e−
|

i
Bj

S∆4
32/T +8∆2/3

i
√L∆) + 32
Bi
|

h
2e−
2
Bj
|
|
|
S∆4
√L∆) + 64n4e−
32/T +8∆2/3 .
b

b

b

b

Lemma 4. Let E be a subset of the edge set E0 =
{
above setup, there exists constants c0 and c1 such that

(i, j)

i

1, . . . , n

, j

1, . . . , n

. Then under the

|

∈ {

}

∈ {

}}

Pr

1
E
|

"

| X
iv ,jv ∈

E

w(uiv , ujv )
|

−

|

wij

> c0√∆

# ≤

iv ,jv ∈
X

E

c1(T

2e−

b
Bi| |

b
Bj |

|

∆) + 64
E
|

n4e−
|

S∆4
32/T +8∆2/3 .

(26)

Pr

wij
|
h

b

Pr

wij
|
h
Pr

wij
b
h

−

Proof. From Lemma 3, average over all pairs (iv, jv)

E,

Pr

1
E
|

"

| Xiv ,jv ∈

E

w(uiv , ujv )
|

−

wij

|

> 16∆1/2L1/4

b

b

Xiv ,jv ∈
Choosing c0 = 16L1/4 and c1 = 256√L yields the desired result.

E

∈

# ≤

1
E
|

≤

17

E

| Xiv ,jv ∈
2e−

Pr

w(uiv , ujv )
|
h

−

wij > 16∆1/2L1/4

|
i

256(T

b
Bi | |

b
Bj |

|

b

√L∆) + 64
E
|

n4e−
|

S∆4
32/T +8∆2/3 .

Lemma 5. Let Ik = [αk

1, αk] for k = 1, . . . , K be a sequence of intervals such that Ii

Ij =

Ii = [0, 1]. Suppose that w is piecewise Lipschitz continuous and differentiable in Ik. For any ui, uj

∩

−

and
∅
[0, 1],

∈

∪
deﬁne

and

fij (x) = (w(x, ui)

gij(y) = (w(ui, y)

w(x, uj ))2
w(uj , y))2 ,

−

−

hij (x, y) =

[fij (x) + gij(y)] .

1
2

Let δ = min

k=1,...,K |

αk

αk

−

−

dc
ij =

fij (x)dx

and

dr
ij =

gij (y)dy

1

0

Z

ǫ2
8L

,

≤

for some constant 0 < ǫ < 2δL, then

sup

fij (x)

ǫ,

and

sup

gij (y)

ǫ.

y

[0,1]

∈

≤

1

. If
|
1

0

Z

x

[0,1]

∈
ǫ.

≤

ǫ2
8L

,

≤

≤

Hence,

sup

∈

(x,y)

[0,1]2

hij (x, y)

be the width of the interval. Consider a neighborhood surrounding the center of Ik with

1, αk] be the interval such that f sup

ij

is attained, and

−

Proof. Since hij (x, y) is separable, it is sufﬁcient to prove for fij (x).
Fix i and j, and let f sup

fij (x). Let Ik = [αk

ij = sup
[0,1]

x

∈

let δk =
αk
|
radius δk/2

1

αk
θ, where 0 < θ < δk/2. Then deﬁne

−

|

−
−

f sup
ij

(θ) =

sup
[αk−1+θ,αk−

θ]

x

∈

fij (x).

It is clear that f sup

ij = lim
0
→

θ

f sup
ij

(θ).

1 + θ, αk

The set [αk
fij (xmax
interval). For any 0 < ǫ0 < ǫ

). Assume, without lost of generality, that xmax
ij
θ,

θ] is compact, so there exists xmax

−

−

ij

ij

∈
(θ) + δk/2

(θ)

−

[αk
1 + θ, αk
θ (i.e., xmax

−

ij

θ] such that f sup
ij =
is in the lower half of the

−

4L −

δ
θ
θ
2 −
≤
hij (xmax
ij

≤
(θ))

δk
2 −
−

(θ) + ǫ0)

=

(w(i, xmax

ij

)

w(j, xmax

ij

))2

(θ) + ǫ0)

w(j, xmax

ij

(θ) + ǫ0))2

(w(i, xmax

ij

)

w(j, xmax

ij

))2

) + Lǫ0

w(j, xmax

ij

) + Lǫ0)2

−

−

−

ij

hij (xmax
ǫ0
(w(i, xmax
ij
ǫ0
(w(i, xmax
ǫ0
w(i, xmax

ij

)

ij

−

−

−

−

4L(w(j, xmax

ij

))

4L

≤

⇒

fij (xmax

ij

(θ))

−

fij (xmax
ǫ0

ij

(θ) + ǫ0)

4L,

≤

≤

≤

which implies that

Integrating both sides with respect to ǫ0 with limits 0 and ǫ

fij (xmax
ij

(θ))

4Lǫ0

−

≤

fij (xmax
ij

(θ))

ǫ
4L −

θ

4L
2

ǫ
4L −

θ

−

(cid:17)

(cid:16)

(cid:16)

(θ) + ǫ0).

fij (xmax
ij
θ yields
ǫ
4L −

4L −
2

θ

≤

0

Z

1

(cid:17)

≤

0

Z

fij (x)dx = dc

ij .

fij (xmax
ij

(θ) + ǫ0)dǫ0

Therefore,

and hence

fij (xmax
ij

(θ))

dc
ij

≤

ǫ
4L −

θ

+ 2L

ǫ
4L −

(cid:16)

f sup
ij = lim
0
→

θ

f sup
ij

(θ) = lim
0
→

θ

fij (xmax
ij

(θ))

≤

θ

,

(cid:17)
4Ldc
ij
ǫ

+

ǫ
2

.

It then follows that if dc

ǫ2
8L , then f sup

ij ≤

ǫ.

ij ≤

18

Deﬁnition 2. The mean squared error (MSE) and mean absolute error (MAE) are deﬁned as

n

n

iv =1
X
n

jv =1
X
n

MSE(

w) =

MAE(

b
w) =

1
n2

1
n2

iv =1
X

jv =1
X
1
4

log(n)
n

b

ω

∈
E[MAE(

(cid:18)(cid:16)
w)] = 0

(cid:17)

∩

(cid:19)
and

(w(uiv , ujv )

wiv ,jv )2

−

w(uiv , ujv )
|

−

b
wiv ,jv |

.

o(1), then

b

E[MSE(

w)] = 0.

lim
n
→∞

lim
n
→∞

b

b

Theorem 3. If S

Θ(n) and ∆n

∈

(27)

(28)

(29)

Proof. Suppose that the algorithm is executed for a set of observed graphs with n vertices using parameters ∆n
and S. Let K ′n be the number of blocks generated. Assume that, as n
Θ(n)

, the parameters satisfy S

→ ∞

∈

and ∆n

ω

∈

1
4

log(n)
n

∩

(cid:19)

(cid:17)

(cid:18)(cid:16)

o(1).

The proof is based on (4). The intuition is to that that the two terms

S∆4

E
32
|

n4e−
|

16/T +8∆2/3 vanish as n

. The latter is clear if S

Θ(n) and ∆n

P

ω

∈
For the ﬁrst term, it is necessary to consider the size
, which is the size of the cluster generated. We show
E
|
|
that the number of small clusters is asymptotically irrelevant. Most of the error come from vertices whose

→ ∞

(cid:18)(cid:16)

(cid:19)

∈

∩

(cid:17)

o(1).

log(n)
n

E 2e−

iv ,jv ∈

c1(T

b
Bi| |

b
Bj |

|

∆) and

1
4

cluster is large enough to make e−

32/T +8∆2/3 vanish.

S∆4

From Theorem 2, we have

Pr

K ′ >

QL√2
∆n (cid:21)

8n2e−

S∆4
n
128/T +16∆2

n/3 .

n be the event that K ′n ≤

≤
QL√2/∆n. Then limn
n happens and deﬁne rn as the number of blocks with less than n∆2
n
QL√2

n] = 1.

Pr[

→∞

(cid:20)

E

Let

E
Suppose

E

of these blocks, and deﬁne V n be the complement of Vn. Then,

Vn
|

| ≤

rn

n∆2
n
QL√2 ≤

K ′n

n∆2
n
QL√2 ≤

n∆n.

elements. Let Vn be the union

So,

Vn
|

/n
|

≤
Now, let’s consider MAE.

∆n.

MAE =

1
n2

1
n2

=

w(uiv , ujv )
|

−

wiv ,jv |

Xiv ∈

V
V Xjv ∈

Vn X
Vn
jv ∈

iv ∈
X
1
n2

+

Xiv ∈
2
Vn
n2 + |
|
|

V n Xjv ∈
Vn
Vn
V n
|
n
n

|

w(uiv , ujv )
|

b
wiv ,jv |
−

+

1
n2

w(uiv , ujv )

|

b
−

wiv ,jv |

+

w(uiv , ujv )

|

wiv ,jv |

+

−

w(uiv , ujv )

|

b
−

wiv ,jv |

V n Xjv ∈
V n

Xiv ∈
1
n2

Xiv ∈

Vn Xjv ∈
V n

|

+ |

V n
n

|

Vn
|
n

|

b
1
+
n2

w(uiv , ujv )
|

wiv ,jv |

−

b

≤

≤

≤

1
n2

1
n2

Xiv ∈

V n Xjv ∈
V n

Xiv ∈

V n Xjv ∈
V n

V n Xjv ∈
V n

Xiv ∈
+ ∆2

n + 2∆n

w(uiv , ujv )
|

−

wiv ,jv |

w(uiv , ujv )
|

−

b
wiv ,jv |

+ 3∆n.

Similar result holds for MSE:
1
n2

MSE =

V
iv ∈
X

V
jv ∈
X

−

b

Xiv ∈

V n Xjv ∈
V n

b

1
n2

≤

19

b

−

b

(w(uiv , ujv )

wiv ,jv )2

(w(uiv , ujv )

wiv ,jv )2 + 3∆n.

Therefore, using Lemma 4 with E = V n:

Pr

MAE(

w) > c0√∆n + 3∆n

h

b

w(uiv , ujv )

|

wiv ,jv |

−

+ 3∆n > c0√∆n + 3∆n

b
w(uiv , ujv )
|

wiv ,jv |

−

> c0√∆n

Xiv ∈

V n Xjv ∈
V n

256(T

2e−

b
Bi | |

b
Bj |

|

b
√L∆) + 64
V n
|

n4e−
|

E 

(cid:12)
(cid:12)

(cid:12)
S∆4
32/T +8∆2/3

E

≤

i

(cid:12)
(cid:12)
(cid:12)

Pr

1
n2




1
Pr[

]

E

≤

1
Pr[

≤

Xiv ∈

V n Xjv ∈
V n

1
V n
|

2
|

Pr





] 

E



Xiv ∈

V n Xjv ∈
V n

1
Pr[

] 

E



E

≤

i

(cid:12)
(cid:12)
(cid:12)

Xiv ∈

V n Xjv ∈
V n

E 



(cid:12)
(cid:12)
(cid:12)

.





.





Pr

MSE(

w) > c0√∆n + 3∆n

256(T

2e−

b
Bi | |

b
Bj |

|

√L∆) + 64
V n
|

n4e−
|

S∆2
32/T +8∆/3

and

h

So,

b

→∞

Since limn

∆n = 0 and limn

Pr[

n] = 1, it holds that for any ǫ > 0,

Pr

MAE(

w) > c0√∆n + 3∆n

lim
n
→∞

h

→∞

b

E
lim
n
→∞

Pr[MAE(

w) > ǫ] = 0.

Pr [

] = 0.

E

E

i

(cid:12)
(cid:12)
(cid:12)

Finally, since

w is bounded in [0, 1],

Sending ǫ

b

,

→ ∞

b

≤

E[MAE(

w)]

≤

ǫ Pr[MAE(

w)

ǫ] + Pr[MAE(

w) > ǫ].

b
E[MAE(

w)]

b
lim
n
→∞

≤

lim
n
→∞

Pr[MAE(

w) > ǫ] = 0.

b

Same arguments hold for MSE.

b

b

20

