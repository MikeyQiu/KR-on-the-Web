gSLICr: SLIC superpixels at over 250Hz

Carl Yuheng Ren
carl@robots.ox.ac.uk
University of Oxford

Victor Adrian Prisacariu
victor@robots.ox.ac.uk
University of Oxford

Ian D Reid
ian.reid@adelaide.edu.au
University of Adelaide

September 15, 2015

Abstract

We introduce a parallel GPU implementation of the Simple Linear Iterative Clustering (SLIC) superpixel
segmentation. Using a single graphic card, our implementation achieves speedups of up to 83× from the
standard sequential implementation. Our implementation is fully compatible with the standard sequential
implementation and the software is now available online and is open source.

5
1
0
2
 
p
e
S
 
4
1
 
 
]

V
C
.
s
c
[
 
 
1
v
2
3
2
4
0
.
9
0
5
1
:
v
i
X
r
a

2 Simple Linear Iterative Clustering (SLIC)

3

gSLICr GPU Implementation

Contents

1

Introduction

4 Library Usage

5 Results

1

Introduction

Superpixels are regions of pixels grouped in some perceptually meaningful way, usually following colour or
boundary cues. They are designed to produce a simpler and more compact representation for an image, while
keeping its semantic meaning intact. Superpixel segmentation is used most often as an image preprocessing
step, with a view towards reducing computational complexity for subsequent processing steps.

The term superpixel, along with the ﬁrst notable superpixel algorithm, was introduced by [1]. Many algo-
rithms followed, using various types of image features, various optimisation strategies and various implemen-
tations techniques. These algorithms have varying speciﬁcations and performance requirements. For example,
some algorithms aim to ﬁnd a ﬁxed number of superpixels, others try to ﬁnd the minimum possible number
of superpixels by imposing a colour cohesion requirement, while others place emphasis on matching image
boundaries. Sometimes fast processing is required, when for example, the superpixel algorithm is used as a
precursor to a tracker. Sometimes superpixels are designed not to under-segment the image, when used for
example as a means of condensing the image information, to serve as the basis of a labelling problem. Re-
gardless of its design, superpixel segmentation is usually among the ﬁrst steps in a much longer processing
pipeline. Therefore, we believe that, for any superpixel method to be useful, it must satisfy the two following
requirements:

• it should not decrease the performance of the full processing pipeline;

• it should be fast.

1

1

2

3

3

4

Figure 1: Example SLIC superpixel segmentation

The performance requirement is satisﬁed in many vision applications by superpixels that are compact,
uniform and follow image edges. These requirements motivated the simple iterative clustering algorithm
(SLIC) algorithm of [2]. This is simple, efﬁcient and suitable for real-time operation. Still however, the CPU-
sequential implementation of SLIC need 300∼400ms to segment a single 640x480 image. Reducing the number
of iterations for each clustering pass can make the algorithm faster, at the cost of a decrease in performance.

In this work, we propose a GPU implementation of the SLIC algorithm, using the NVIDIA CUDA frame-
work. Our implementation is up to 83× faster than the original CPU implementation of [2], making it, to our
knowledge, the fastest superpixel method to date.

Our full source code with a simple example can be downloaded from https://github.com/carlren/

gSLICr. The following sections describe in detail our algorithm and implementation.

2 Simple Linear Iterative Clustering (SLIC)

The Simple Linear Iterative Clustering (SLIC) algorithm for superpixel segmentation was proposed in [2]. An
example segmentation result is shown in 1.

SLIC uses a k-means-based approach to build local clusters of pixels in the 5D [labxy] space deﬁned by
the L, a, b values of the CIELAB color space and the x, y pixel coordinates. The CIELAB color space is chosen
because it is perceptually uniform for a small distance in colour.

SLIC uses as input the desired number of approximately equally-sized superpixels K. Given an image
with N pixels, the approximate size of each superpixel therefore is N/K. Assuming roughly equally sized
superpixels, there would be a superpixel center at every grid interval S = (cid:112)N/K. Let [li, ai, bi, xi, yi]T be the 5D
point corresponding to a pixel. Writing the cluster center Ck as Ck = [lk, ak, bk, xk, yk]T , SLIC deﬁnes a distance
measure Dk as:

(cid:113)

dlab =

(lk − li)2 + (ak − ai)2 + (nk − bi)2

(cid:113)

dxy =

(xk − xi)2 + (yk − yi)2

Ds = dlab +

dxy

m
S

(1)

where Ds is the sum of the lab distance and the xy plane distance normalized by the grid interval S. The
variable m controls the compactness of superpixels i.e. the greater the value of m, the more spatial proximity is
emphasized and thus the more compact the cluster becomes.

This distance metric is next used in a standard local k-means algorithm. First, the cluster centers are
perturbed to the lowers gradient position from a local neighborhood. Next, iteratively, the algorithm assigns the
best matching pixels in a local neighborhood to each cluster and computes new center locations. The process
is stopped when the cluster centers stabilise i.e. when the L1 distance between centers at consecutive iterations
is smaller than a set threshold. Finally, connectively is enforced to cleanup the ﬁnal superpixel lattice.

In the next section we detail our GPU implementation of SLIC.

2

Figure 2: Workﬂow of gSLICr

3 gSLICr GPU Implementation

We split our implementation into two parts, as shown in Figure 2: the GPU is responsible for most of the
processing, with only data acquisition and visualization being left for the CPU.

The GPU implementation then proceeds as follows:

• Image space conversion: The RGB input image is converted to Cielab, using one thread for each pixel.

• Cluster center initialisation: We use one thread per cluster center (i.e. superpixel) to initialise our
superpixel map. This is an nsr × nsc image which contains, for each entry, center coordinates, number of
associated pixels and colour information. nsr and nsc represent the number of superpixels per image row
and column, respectively.

• Finding the cluster associations: Each pixel in the image determines what is its closest cluster using
the 5D distance detailed in the previous section. This requires a maximum of nine cluster centers to be
examined and is done using one thread per pixel.

• Updating the cluster center: Here we update each cluster center using the pixels assigned to it. This
process is done in two separate kernels. First, each cluster center must access all pixels associated to it,
within a local neighborhood that is a function of the superpixel size. Here we use nsr × nsc × nbl, where
nsr and nsc are deﬁned as before. nbl = spixel size × 3/BLOCK DIM captures the number of pixels
each thread can process, as a function of superpixel size and thread block dimension (16 in our case).
The result is written to an image of size nsr × nsc × nbl, upon which we run a reduction step on the third
dimension to obtain the ﬁnal updated cluster center positions.

• Enforce connectivity: We eliminate stray pixels with two one thread per pixel calls of the same kernel.
This prompts a pixel to change its label of that of the surrounding pixels (in a 2 × 2 neighborhood) if all
have a different label.

4 Library Usage

Our full code can be downloaded from https://github.com/carlren/gSLICr. It consists of (i) a
demo project (which requires OpenCV) and (ii) a separate library (which has no dependencies).

The demo project acquires images from the camera, processes them through the library and displays the
result back in an OpenCV window. It creates an instances of the core engine class, which is the main access
point to our code. This controls the segmentation code in the seg engine class and times the result.

The seg engine class is responsible for all the superpixel processing, and the algorithm is controlled from

the Perform Segmentation method. This code is listed below:

3

Figure 3: Cross Device Engine Design Pattern

v o i d s e g e n g i n e : : P e r f o r m S e g m e n t a t i o n ( UChar4Image ∗ i n i m g )
{

s o u r c e i m g −>SetFrom ( i n i m g , O R U t i l s : : MemoryBlock<V e c t o r 4 u > : :CPU TO CUDA ) ;
C v t I m g S p a c e ( s o u r c e i m g ,

i m g , g S L I C r s e t t i n g s . c o l o r s p a c e ) ;

c v t

I n i t C l u s t e r C e n t e r s ( ) ;
F i n d C e n t e r A s s o c i a t i o n ( ) ;

( i n t

i = 0 ;

i < g S L I C r s e t t i n g s . n o i t e r s ;

i ++)

U p d a t e C l u s t e r C e n t e r ( ) ;
F i n d C e n t e r A s s o c i a t i o n ( ) ;

f o r
{

}

}

i f ( g S L I C r s e t t i n g s . d o e n f o r c e c o n n e c t i v i t y ) E n f o r c e C o n n e c t i v i t y ( ) ;
c u d a T h r e a d S y n c h r o n i z e ( ) ;

Similar to the other projects from the Oxford Vision Library, such as LibISR [3] or InﬁniTAM [4], this
class follows our cross device engine design pattern outlined in Figure 3. The engine is split into 3 layers.
The topmost, so called Abstract Layer, contains the main algorithm function calls (listed above). The abstract
interface is implemented in the next, Device Speciﬁc Layer, which may be very different between e.g. a CPU
and a GPU implementation. Further implementations using e.g. OpenMP or other hardware acceleration archi-
tectures are possible. We only provide a GPU implementation in this case, in the gSLICr seg engine GPU.h
and gSLICr seg engine GPU.cu ﬁles. At the third, Device Agnostic Layer, there is some inline C-code that
may be called from the higher layers. This contains the bulk of the per-pixel and per-cluster processing code
and can be found in the gSLICr seg engine shared.h ﬁle.

5 Results

Our implementation is designed to produce the same result as the sequential SLIC implementation of [2], so
qualitatively and quantitatively the results are virtually identical. Our method is however considerably faster
than this, and, to our knowledge, all other superpixel segmentation techniques. We included a comparison with
many such techniques in Table 1. Here we used four images sizes, and our method was consistently much faster
than any other approach. Compared to the original SLIC algorithm, our approach is up to 83× faster.

Acknowldgements

We thank Magellium ltd. and CNAS for their support for our experimental section.

4

References

[1] J. Shi and J. Malik, “Normalized Cuts and Image Segmentation,” T-PAMI, vol. 22, pp. 888–905, 2000.

[2] R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, and S. S¨usstrunk, “SLIC Superpixels Compared to

State-of-the-Art Superpixel Methods,” T-PAMI, vol. 34, no. 11, pp. 2274–2282, 2012.

[3] C. Ren, V. Prisacariu, D. Murray, and I. Reid, “Star3d: Simultaneous tracking and reconstruction of 3d
objects using rgb-d data,” in Computer Vision (ICCV), 2013 IEEE International Conference on, pp. 1561–
1568, Dec 2013.

[4] V. A. Prisacariu, O. K¨ahler, M. Cheng, C. Y. Ren, J. P. C. Valentin, P. H. S. Torr, I. D. Reid, and D. W.
Murray, “A framework for the volumetric integration of depth images,” CoRR, vol. abs/1410.0925, 2014.

[5] O. Veksler, Y. Boykov, and P. Mehrani in ECCV, pp. 211–224, 2010.

[6] Y. Zhang, R. I. Hartley, J. Mashford, and S. Burn, “Superpixels via pseudo-Boolean optimization,” in

ICCV, pp. 1387–1394, 2011.

vol. 24, no. 5, pp. 603–619, 2002.

no. 2, pp. 167–181, 2004.

pp. 2097–2104, 2011.

[7] D. Comaniciu and P. Meer, “Mean Shift: A Robust Approach Toward Feature Space Analysis,” T-PAMI,

[8] P. F. Felzenszwalb and D. P. Huttenlocher, “Efﬁcient Graph-Based Image Segmentation,” IJCV, vol. 59,

[9] M.-Y. Liu, O. Tuzel, S. Ramalingam, and R. Chellappa, “Entropy rate superpixel segmentation,” in CVPR,

[10] M. V. den Bergh, X. Boix, G. Roig, B. de Capitani, and L. J. V. Gool, “SEEDS: Superpixels Extracted via

Energy-Driven Sampling,” in ECCV, pp. 13–26, 2012.

[11] A. Levinshtein, A. Stere, K. N. Kutulakos, D. J. Fleet, S. J. Dickinson, and K. Siddiqi, “TurboPixels: Fast

Superpixels Using Geometric Flows,” T-PAMI, vol. 31, no. 12, pp. 2290–2297, 2009.

[12] A. P. Moore, S. J. D. Prince, J. Warrell, U. Mohammed, and G. Jones, “Superpixel lattices,” in CVPR,

2008.

[13] M. Leordeanu, R. Sukthankar, and C. Sminchisescu, “Efﬁcient closed-form solution to generalized bound-

ary detection,” in ECCV, pp. 516–529, 2012.

[14] P. Dollar, Z. Tu, and S. Belongie, “Supervised Learning of Edges and Object Boundaries,” in CVPR,

vol. 2, pp. 1964–1971, 2006.

5

1024 × 1024

3631 × 3859

963 × 1024

1002 × 1002

933 × 800

method
Current Work
1000 spx
Current Work
2000 spx
Achanta [2]
1000 spx
Achanta [2]
2000 spx
Veksler [5]
patch size 25
Veksler [5]
patch size 50
Zhang [6]
patch size 40
Zhang [6]
patch size 60
Comaniciu [7]
sp. bandw. 11
Comaniciu [7]
sp. bandw. 23
Shi [1]
1000 spx
Shi [1]
2000 spx
Felzenszwalb
[8] σ = 0.4
Felzenszwalb
[8] σ = 0.5
Liu [9]
500 spx
Liu [9]
1000 spx
Liu [9]
2000 spx
den Bergh [10]
200 spx
den Bergh [10]
400 spx
Levinshtein
[11] 1000 spx
Levinshtein
[11] 2000 spx
Moore [12]
bounds [13]
Moore [12]
bounds [14]

0.01

0.01

0.73

0.74

22.6

25.2

0.63

0.60

12.1

43.3

329

515

0.62

0.70

6.76

6.94

7.26

1.53

2.36

38.7

38.4

2.07

2.44

0.01

0.01

0.70

0.71

19.3

19.7

0.50

0.50

9.73

32.5

334

411

0.85

0.92

7.00

7.10

7.60

1.39

2.00

52.1

55.6

1.79

2.17

0.008

0.008

0.55

0.55

16.7

17.7

0.36

0.36

9.47

34.2

218

338

0.41

0.47

5.34

5.35

5.62

1.01

1.42

26.9

26.8

1.37

1.25

0.01

0.01

0.75

0.72

20.6

21.6

0.49

0.48

12.3

53.8

316

384

0.96

0.97

7.34

6.90

7.23

1.67

2.35

46.6

44.0

2.20

2.12

0.12

0.12

9.69

9.88

321

368

7.49

7.53

17.4

18.3

116

116

120

22.1

31.2

x

x

x

x

x

x

x

x

6

Table 1: Timing results for the tested methods.

gSLICr: SLIC superpixels at over 250Hz

Carl Yuheng Ren
carl@robots.ox.ac.uk
University of Oxford

Victor Adrian Prisacariu
victor@robots.ox.ac.uk
University of Oxford

Ian D Reid
ian.reid@adelaide.edu.au
University of Adelaide

September 15, 2015

Abstract

We introduce a parallel GPU implementation of the Simple Linear Iterative Clustering (SLIC) superpixel
segmentation. Using a single graphic card, our implementation achieves speedups of up to 83× from the
standard sequential implementation. Our implementation is fully compatible with the standard sequential
implementation and the software is now available online and is open source.

5
1
0
2
 
p
e
S
 
4
1
 
 
]

V
C
.
s
c
[
 
 
1
v
2
3
2
4
0
.
9
0
5
1
:
v
i
X
r
a

2 Simple Linear Iterative Clustering (SLIC)

3

gSLICr GPU Implementation

Contents

1

Introduction

4 Library Usage

5 Results

1

Introduction

Superpixels are regions of pixels grouped in some perceptually meaningful way, usually following colour or
boundary cues. They are designed to produce a simpler and more compact representation for an image, while
keeping its semantic meaning intact. Superpixel segmentation is used most often as an image preprocessing
step, with a view towards reducing computational complexity for subsequent processing steps.

The term superpixel, along with the ﬁrst notable superpixel algorithm, was introduced by [1]. Many algo-
rithms followed, using various types of image features, various optimisation strategies and various implemen-
tations techniques. These algorithms have varying speciﬁcations and performance requirements. For example,
some algorithms aim to ﬁnd a ﬁxed number of superpixels, others try to ﬁnd the minimum possible number
of superpixels by imposing a colour cohesion requirement, while others place emphasis on matching image
boundaries. Sometimes fast processing is required, when for example, the superpixel algorithm is used as a
precursor to a tracker. Sometimes superpixels are designed not to under-segment the image, when used for
example as a means of condensing the image information, to serve as the basis of a labelling problem. Re-
gardless of its design, superpixel segmentation is usually among the ﬁrst steps in a much longer processing
pipeline. Therefore, we believe that, for any superpixel method to be useful, it must satisfy the two following
requirements:

• it should not decrease the performance of the full processing pipeline;

• it should be fast.

1

1

2

3

3

4

Figure 1: Example SLIC superpixel segmentation

The performance requirement is satisﬁed in many vision applications by superpixels that are compact,
uniform and follow image edges. These requirements motivated the simple iterative clustering algorithm
(SLIC) algorithm of [2]. This is simple, efﬁcient and suitable for real-time operation. Still however, the CPU-
sequential implementation of SLIC need 300∼400ms to segment a single 640x480 image. Reducing the number
of iterations for each clustering pass can make the algorithm faster, at the cost of a decrease in performance.

In this work, we propose a GPU implementation of the SLIC algorithm, using the NVIDIA CUDA frame-
work. Our implementation is up to 83× faster than the original CPU implementation of [2], making it, to our
knowledge, the fastest superpixel method to date.

Our full source code with a simple example can be downloaded from https://github.com/carlren/

gSLICr. The following sections describe in detail our algorithm and implementation.

2 Simple Linear Iterative Clustering (SLIC)

The Simple Linear Iterative Clustering (SLIC) algorithm for superpixel segmentation was proposed in [2]. An
example segmentation result is shown in 1.

SLIC uses a k-means-based approach to build local clusters of pixels in the 5D [labxy] space deﬁned by
the L, a, b values of the CIELAB color space and the x, y pixel coordinates. The CIELAB color space is chosen
because it is perceptually uniform for a small distance in colour.

SLIC uses as input the desired number of approximately equally-sized superpixels K. Given an image
with N pixels, the approximate size of each superpixel therefore is N/K. Assuming roughly equally sized
superpixels, there would be a superpixel center at every grid interval S = (cid:112)N/K. Let [li, ai, bi, xi, yi]T be the 5D
point corresponding to a pixel. Writing the cluster center Ck as Ck = [lk, ak, bk, xk, yk]T , SLIC deﬁnes a distance
measure Dk as:

(cid:113)

dlab =

(lk − li)2 + (ak − ai)2 + (nk − bi)2

(cid:113)

dxy =

(xk − xi)2 + (yk − yi)2

Ds = dlab +

dxy

m
S

(1)

where Ds is the sum of the lab distance and the xy plane distance normalized by the grid interval S. The
variable m controls the compactness of superpixels i.e. the greater the value of m, the more spatial proximity is
emphasized and thus the more compact the cluster becomes.

This distance metric is next used in a standard local k-means algorithm. First, the cluster centers are
perturbed to the lowers gradient position from a local neighborhood. Next, iteratively, the algorithm assigns the
best matching pixels in a local neighborhood to each cluster and computes new center locations. The process
is stopped when the cluster centers stabilise i.e. when the L1 distance between centers at consecutive iterations
is smaller than a set threshold. Finally, connectively is enforced to cleanup the ﬁnal superpixel lattice.

In the next section we detail our GPU implementation of SLIC.

2

Figure 2: Workﬂow of gSLICr

3 gSLICr GPU Implementation

We split our implementation into two parts, as shown in Figure 2: the GPU is responsible for most of the
processing, with only data acquisition and visualization being left for the CPU.

The GPU implementation then proceeds as follows:

• Image space conversion: The RGB input image is converted to Cielab, using one thread for each pixel.

• Cluster center initialisation: We use one thread per cluster center (i.e. superpixel) to initialise our
superpixel map. This is an nsr × nsc image which contains, for each entry, center coordinates, number of
associated pixels and colour information. nsr and nsc represent the number of superpixels per image row
and column, respectively.

• Finding the cluster associations: Each pixel in the image determines what is its closest cluster using
the 5D distance detailed in the previous section. This requires a maximum of nine cluster centers to be
examined and is done using one thread per pixel.

• Updating the cluster center: Here we update each cluster center using the pixels assigned to it. This
process is done in two separate kernels. First, each cluster center must access all pixels associated to it,
within a local neighborhood that is a function of the superpixel size. Here we use nsr × nsc × nbl, where
nsr and nsc are deﬁned as before. nbl = spixel size × 3/BLOCK DIM captures the number of pixels
each thread can process, as a function of superpixel size and thread block dimension (16 in our case).
The result is written to an image of size nsr × nsc × nbl, upon which we run a reduction step on the third
dimension to obtain the ﬁnal updated cluster center positions.

• Enforce connectivity: We eliminate stray pixels with two one thread per pixel calls of the same kernel.
This prompts a pixel to change its label of that of the surrounding pixels (in a 2 × 2 neighborhood) if all
have a different label.

4 Library Usage

Our full code can be downloaded from https://github.com/carlren/gSLICr. It consists of (i) a
demo project (which requires OpenCV) and (ii) a separate library (which has no dependencies).

The demo project acquires images from the camera, processes them through the library and displays the
result back in an OpenCV window. It creates an instances of the core engine class, which is the main access
point to our code. This controls the segmentation code in the seg engine class and times the result.

The seg engine class is responsible for all the superpixel processing, and the algorithm is controlled from

the Perform Segmentation method. This code is listed below:

3

Figure 3: Cross Device Engine Design Pattern

v o i d s e g e n g i n e : : P e r f o r m S e g m e n t a t i o n ( UChar4Image ∗ i n i m g )
{

s o u r c e i m g −>SetFrom ( i n i m g , O R U t i l s : : MemoryBlock<V e c t o r 4 u > : :CPU TO CUDA ) ;
C v t I m g S p a c e ( s o u r c e i m g ,

i m g , g S L I C r s e t t i n g s . c o l o r s p a c e ) ;

c v t

I n i t C l u s t e r C e n t e r s ( ) ;
F i n d C e n t e r A s s o c i a t i o n ( ) ;

( i n t

i = 0 ;

i < g S L I C r s e t t i n g s . n o i t e r s ;

i ++)

U p d a t e C l u s t e r C e n t e r ( ) ;
F i n d C e n t e r A s s o c i a t i o n ( ) ;

f o r
{

}

}

i f ( g S L I C r s e t t i n g s . d o e n f o r c e c o n n e c t i v i t y ) E n f o r c e C o n n e c t i v i t y ( ) ;
c u d a T h r e a d S y n c h r o n i z e ( ) ;

Similar to the other projects from the Oxford Vision Library, such as LibISR [3] or InﬁniTAM [4], this
class follows our cross device engine design pattern outlined in Figure 3. The engine is split into 3 layers.
The topmost, so called Abstract Layer, contains the main algorithm function calls (listed above). The abstract
interface is implemented in the next, Device Speciﬁc Layer, which may be very different between e.g. a CPU
and a GPU implementation. Further implementations using e.g. OpenMP or other hardware acceleration archi-
tectures are possible. We only provide a GPU implementation in this case, in the gSLICr seg engine GPU.h
and gSLICr seg engine GPU.cu ﬁles. At the third, Device Agnostic Layer, there is some inline C-code that
may be called from the higher layers. This contains the bulk of the per-pixel and per-cluster processing code
and can be found in the gSLICr seg engine shared.h ﬁle.

5 Results

Our implementation is designed to produce the same result as the sequential SLIC implementation of [2], so
qualitatively and quantitatively the results are virtually identical. Our method is however considerably faster
than this, and, to our knowledge, all other superpixel segmentation techniques. We included a comparison with
many such techniques in Table 1. Here we used four images sizes, and our method was consistently much faster
than any other approach. Compared to the original SLIC algorithm, our approach is up to 83× faster.

Acknowldgements

We thank Magellium ltd. and CNAS for their support for our experimental section.

4

References

[1] J. Shi and J. Malik, “Normalized Cuts and Image Segmentation,” T-PAMI, vol. 22, pp. 888–905, 2000.

[2] R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, and S. S¨usstrunk, “SLIC Superpixels Compared to

State-of-the-Art Superpixel Methods,” T-PAMI, vol. 34, no. 11, pp. 2274–2282, 2012.

[3] C. Ren, V. Prisacariu, D. Murray, and I. Reid, “Star3d: Simultaneous tracking and reconstruction of 3d
objects using rgb-d data,” in Computer Vision (ICCV), 2013 IEEE International Conference on, pp. 1561–
1568, Dec 2013.

[4] V. A. Prisacariu, O. K¨ahler, M. Cheng, C. Y. Ren, J. P. C. Valentin, P. H. S. Torr, I. D. Reid, and D. W.
Murray, “A framework for the volumetric integration of depth images,” CoRR, vol. abs/1410.0925, 2014.

[5] O. Veksler, Y. Boykov, and P. Mehrani in ECCV, pp. 211–224, 2010.

[6] Y. Zhang, R. I. Hartley, J. Mashford, and S. Burn, “Superpixels via pseudo-Boolean optimization,” in

ICCV, pp. 1387–1394, 2011.

vol. 24, no. 5, pp. 603–619, 2002.

no. 2, pp. 167–181, 2004.

pp. 2097–2104, 2011.

[7] D. Comaniciu and P. Meer, “Mean Shift: A Robust Approach Toward Feature Space Analysis,” T-PAMI,

[8] P. F. Felzenszwalb and D. P. Huttenlocher, “Efﬁcient Graph-Based Image Segmentation,” IJCV, vol. 59,

[9] M.-Y. Liu, O. Tuzel, S. Ramalingam, and R. Chellappa, “Entropy rate superpixel segmentation,” in CVPR,

[10] M. V. den Bergh, X. Boix, G. Roig, B. de Capitani, and L. J. V. Gool, “SEEDS: Superpixels Extracted via

Energy-Driven Sampling,” in ECCV, pp. 13–26, 2012.

[11] A. Levinshtein, A. Stere, K. N. Kutulakos, D. J. Fleet, S. J. Dickinson, and K. Siddiqi, “TurboPixels: Fast

Superpixels Using Geometric Flows,” T-PAMI, vol. 31, no. 12, pp. 2290–2297, 2009.

[12] A. P. Moore, S. J. D. Prince, J. Warrell, U. Mohammed, and G. Jones, “Superpixel lattices,” in CVPR,

2008.

[13] M. Leordeanu, R. Sukthankar, and C. Sminchisescu, “Efﬁcient closed-form solution to generalized bound-

ary detection,” in ECCV, pp. 516–529, 2012.

[14] P. Dollar, Z. Tu, and S. Belongie, “Supervised Learning of Edges and Object Boundaries,” in CVPR,

vol. 2, pp. 1964–1971, 2006.

5

1024 × 1024

3631 × 3859

963 × 1024

1002 × 1002

933 × 800

method
Current Work
1000 spx
Current Work
2000 spx
Achanta [2]
1000 spx
Achanta [2]
2000 spx
Veksler [5]
patch size 25
Veksler [5]
patch size 50
Zhang [6]
patch size 40
Zhang [6]
patch size 60
Comaniciu [7]
sp. bandw. 11
Comaniciu [7]
sp. bandw. 23
Shi [1]
1000 spx
Shi [1]
2000 spx
Felzenszwalb
[8] σ = 0.4
Felzenszwalb
[8] σ = 0.5
Liu [9]
500 spx
Liu [9]
1000 spx
Liu [9]
2000 spx
den Bergh [10]
200 spx
den Bergh [10]
400 spx
Levinshtein
[11] 1000 spx
Levinshtein
[11] 2000 spx
Moore [12]
bounds [13]
Moore [12]
bounds [14]

0.01

0.01

0.73

0.74

22.6

25.2

0.63

0.60

12.1

43.3

329

515

0.62

0.70

6.76

6.94

7.26

1.53

2.36

38.7

38.4

2.07

2.44

0.01

0.01

0.70

0.71

19.3

19.7

0.50

0.50

9.73

32.5

334

411

0.85

0.92

7.00

7.10

7.60

1.39

2.00

52.1

55.6

1.79

2.17

0.008

0.008

0.55

0.55

16.7

17.7

0.36

0.36

9.47

34.2

218

338

0.41

0.47

5.34

5.35

5.62

1.01

1.42

26.9

26.8

1.37

1.25

0.01

0.01

0.75

0.72

20.6

21.6

0.49

0.48

12.3

53.8

316

384

0.96

0.97

7.34

6.90

7.23

1.67

2.35

46.6

44.0

2.20

2.12

0.12

0.12

9.69

9.88

321

368

7.49

7.53

17.4

18.3

116

116

120

22.1

31.2

x

x

x

x

x

x

x

x

6

Table 1: Timing results for the tested methods.

gSLICr: SLIC superpixels at over 250Hz

Carl Yuheng Ren
carl@robots.ox.ac.uk
University of Oxford

Victor Adrian Prisacariu
victor@robots.ox.ac.uk
University of Oxford

Ian D Reid
ian.reid@adelaide.edu.au
University of Adelaide

September 15, 2015

Abstract

We introduce a parallel GPU implementation of the Simple Linear Iterative Clustering (SLIC) superpixel
segmentation. Using a single graphic card, our implementation achieves speedups of up to 83× from the
standard sequential implementation. Our implementation is fully compatible with the standard sequential
implementation and the software is now available online and is open source.

5
1
0
2
 
p
e
S
 
4
1
 
 
]

V
C
.
s
c
[
 
 
1
v
2
3
2
4
0
.
9
0
5
1
:
v
i
X
r
a

2 Simple Linear Iterative Clustering (SLIC)

3

gSLICr GPU Implementation

Contents

1

Introduction

4 Library Usage

5 Results

1

Introduction

Superpixels are regions of pixels grouped in some perceptually meaningful way, usually following colour or
boundary cues. They are designed to produce a simpler and more compact representation for an image, while
keeping its semantic meaning intact. Superpixel segmentation is used most often as an image preprocessing
step, with a view towards reducing computational complexity for subsequent processing steps.

The term superpixel, along with the ﬁrst notable superpixel algorithm, was introduced by [1]. Many algo-
rithms followed, using various types of image features, various optimisation strategies and various implemen-
tations techniques. These algorithms have varying speciﬁcations and performance requirements. For example,
some algorithms aim to ﬁnd a ﬁxed number of superpixels, others try to ﬁnd the minimum possible number
of superpixels by imposing a colour cohesion requirement, while others place emphasis on matching image
boundaries. Sometimes fast processing is required, when for example, the superpixel algorithm is used as a
precursor to a tracker. Sometimes superpixels are designed not to under-segment the image, when used for
example as a means of condensing the image information, to serve as the basis of a labelling problem. Re-
gardless of its design, superpixel segmentation is usually among the ﬁrst steps in a much longer processing
pipeline. Therefore, we believe that, for any superpixel method to be useful, it must satisfy the two following
requirements:

• it should not decrease the performance of the full processing pipeline;

• it should be fast.

1

1

2

3

3

4

Figure 1: Example SLIC superpixel segmentation

The performance requirement is satisﬁed in many vision applications by superpixels that are compact,
uniform and follow image edges. These requirements motivated the simple iterative clustering algorithm
(SLIC) algorithm of [2]. This is simple, efﬁcient and suitable for real-time operation. Still however, the CPU-
sequential implementation of SLIC need 300∼400ms to segment a single 640x480 image. Reducing the number
of iterations for each clustering pass can make the algorithm faster, at the cost of a decrease in performance.

In this work, we propose a GPU implementation of the SLIC algorithm, using the NVIDIA CUDA frame-
work. Our implementation is up to 83× faster than the original CPU implementation of [2], making it, to our
knowledge, the fastest superpixel method to date.

Our full source code with a simple example can be downloaded from https://github.com/carlren/

gSLICr. The following sections describe in detail our algorithm and implementation.

2 Simple Linear Iterative Clustering (SLIC)

The Simple Linear Iterative Clustering (SLIC) algorithm for superpixel segmentation was proposed in [2]. An
example segmentation result is shown in 1.

SLIC uses a k-means-based approach to build local clusters of pixels in the 5D [labxy] space deﬁned by
the L, a, b values of the CIELAB color space and the x, y pixel coordinates. The CIELAB color space is chosen
because it is perceptually uniform for a small distance in colour.

SLIC uses as input the desired number of approximately equally-sized superpixels K. Given an image
with N pixels, the approximate size of each superpixel therefore is N/K. Assuming roughly equally sized
superpixels, there would be a superpixel center at every grid interval S = (cid:112)N/K. Let [li, ai, bi, xi, yi]T be the 5D
point corresponding to a pixel. Writing the cluster center Ck as Ck = [lk, ak, bk, xk, yk]T , SLIC deﬁnes a distance
measure Dk as:

(cid:113)

dlab =

(lk − li)2 + (ak − ai)2 + (nk − bi)2

(cid:113)

dxy =

(xk − xi)2 + (yk − yi)2

Ds = dlab +

dxy

m
S

(1)

where Ds is the sum of the lab distance and the xy plane distance normalized by the grid interval S. The
variable m controls the compactness of superpixels i.e. the greater the value of m, the more spatial proximity is
emphasized and thus the more compact the cluster becomes.

This distance metric is next used in a standard local k-means algorithm. First, the cluster centers are
perturbed to the lowers gradient position from a local neighborhood. Next, iteratively, the algorithm assigns the
best matching pixels in a local neighborhood to each cluster and computes new center locations. The process
is stopped when the cluster centers stabilise i.e. when the L1 distance between centers at consecutive iterations
is smaller than a set threshold. Finally, connectively is enforced to cleanup the ﬁnal superpixel lattice.

In the next section we detail our GPU implementation of SLIC.

2

Figure 2: Workﬂow of gSLICr

3 gSLICr GPU Implementation

We split our implementation into two parts, as shown in Figure 2: the GPU is responsible for most of the
processing, with only data acquisition and visualization being left for the CPU.

The GPU implementation then proceeds as follows:

• Image space conversion: The RGB input image is converted to Cielab, using one thread for each pixel.

• Cluster center initialisation: We use one thread per cluster center (i.e. superpixel) to initialise our
superpixel map. This is an nsr × nsc image which contains, for each entry, center coordinates, number of
associated pixels and colour information. nsr and nsc represent the number of superpixels per image row
and column, respectively.

• Finding the cluster associations: Each pixel in the image determines what is its closest cluster using
the 5D distance detailed in the previous section. This requires a maximum of nine cluster centers to be
examined and is done using one thread per pixel.

• Updating the cluster center: Here we update each cluster center using the pixels assigned to it. This
process is done in two separate kernels. First, each cluster center must access all pixels associated to it,
within a local neighborhood that is a function of the superpixel size. Here we use nsr × nsc × nbl, where
nsr and nsc are deﬁned as before. nbl = spixel size × 3/BLOCK DIM captures the number of pixels
each thread can process, as a function of superpixel size and thread block dimension (16 in our case).
The result is written to an image of size nsr × nsc × nbl, upon which we run a reduction step on the third
dimension to obtain the ﬁnal updated cluster center positions.

• Enforce connectivity: We eliminate stray pixels with two one thread per pixel calls of the same kernel.
This prompts a pixel to change its label of that of the surrounding pixels (in a 2 × 2 neighborhood) if all
have a different label.

4 Library Usage

Our full code can be downloaded from https://github.com/carlren/gSLICr. It consists of (i) a
demo project (which requires OpenCV) and (ii) a separate library (which has no dependencies).

The demo project acquires images from the camera, processes them through the library and displays the
result back in an OpenCV window. It creates an instances of the core engine class, which is the main access
point to our code. This controls the segmentation code in the seg engine class and times the result.

The seg engine class is responsible for all the superpixel processing, and the algorithm is controlled from

the Perform Segmentation method. This code is listed below:

3

Figure 3: Cross Device Engine Design Pattern

v o i d s e g e n g i n e : : P e r f o r m S e g m e n t a t i o n ( UChar4Image ∗ i n i m g )
{

s o u r c e i m g −>SetFrom ( i n i m g , O R U t i l s : : MemoryBlock<V e c t o r 4 u > : :CPU TO CUDA ) ;
C v t I m g S p a c e ( s o u r c e i m g ,

i m g , g S L I C r s e t t i n g s . c o l o r s p a c e ) ;

c v t

I n i t C l u s t e r C e n t e r s ( ) ;
F i n d C e n t e r A s s o c i a t i o n ( ) ;

( i n t

i = 0 ;

i < g S L I C r s e t t i n g s . n o i t e r s ;

i ++)

U p d a t e C l u s t e r C e n t e r ( ) ;
F i n d C e n t e r A s s o c i a t i o n ( ) ;

f o r
{

}

}

i f ( g S L I C r s e t t i n g s . d o e n f o r c e c o n n e c t i v i t y ) E n f o r c e C o n n e c t i v i t y ( ) ;
c u d a T h r e a d S y n c h r o n i z e ( ) ;

Similar to the other projects from the Oxford Vision Library, such as LibISR [3] or InﬁniTAM [4], this
class follows our cross device engine design pattern outlined in Figure 3. The engine is split into 3 layers.
The topmost, so called Abstract Layer, contains the main algorithm function calls (listed above). The abstract
interface is implemented in the next, Device Speciﬁc Layer, which may be very different between e.g. a CPU
and a GPU implementation. Further implementations using e.g. OpenMP or other hardware acceleration archi-
tectures are possible. We only provide a GPU implementation in this case, in the gSLICr seg engine GPU.h
and gSLICr seg engine GPU.cu ﬁles. At the third, Device Agnostic Layer, there is some inline C-code that
may be called from the higher layers. This contains the bulk of the per-pixel and per-cluster processing code
and can be found in the gSLICr seg engine shared.h ﬁle.

5 Results

Our implementation is designed to produce the same result as the sequential SLIC implementation of [2], so
qualitatively and quantitatively the results are virtually identical. Our method is however considerably faster
than this, and, to our knowledge, all other superpixel segmentation techniques. We included a comparison with
many such techniques in Table 1. Here we used four images sizes, and our method was consistently much faster
than any other approach. Compared to the original SLIC algorithm, our approach is up to 83× faster.

Acknowldgements

We thank Magellium ltd. and CNAS for their support for our experimental section.

4

References

[1] J. Shi and J. Malik, “Normalized Cuts and Image Segmentation,” T-PAMI, vol. 22, pp. 888–905, 2000.

[2] R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, and S. S¨usstrunk, “SLIC Superpixels Compared to

State-of-the-Art Superpixel Methods,” T-PAMI, vol. 34, no. 11, pp. 2274–2282, 2012.

[3] C. Ren, V. Prisacariu, D. Murray, and I. Reid, “Star3d: Simultaneous tracking and reconstruction of 3d
objects using rgb-d data,” in Computer Vision (ICCV), 2013 IEEE International Conference on, pp. 1561–
1568, Dec 2013.

[4] V. A. Prisacariu, O. K¨ahler, M. Cheng, C. Y. Ren, J. P. C. Valentin, P. H. S. Torr, I. D. Reid, and D. W.
Murray, “A framework for the volumetric integration of depth images,” CoRR, vol. abs/1410.0925, 2014.

[5] O. Veksler, Y. Boykov, and P. Mehrani in ECCV, pp. 211–224, 2010.

[6] Y. Zhang, R. I. Hartley, J. Mashford, and S. Burn, “Superpixels via pseudo-Boolean optimization,” in

ICCV, pp. 1387–1394, 2011.

vol. 24, no. 5, pp. 603–619, 2002.

no. 2, pp. 167–181, 2004.

pp. 2097–2104, 2011.

[7] D. Comaniciu and P. Meer, “Mean Shift: A Robust Approach Toward Feature Space Analysis,” T-PAMI,

[8] P. F. Felzenszwalb and D. P. Huttenlocher, “Efﬁcient Graph-Based Image Segmentation,” IJCV, vol. 59,

[9] M.-Y. Liu, O. Tuzel, S. Ramalingam, and R. Chellappa, “Entropy rate superpixel segmentation,” in CVPR,

[10] M. V. den Bergh, X. Boix, G. Roig, B. de Capitani, and L. J. V. Gool, “SEEDS: Superpixels Extracted via

Energy-Driven Sampling,” in ECCV, pp. 13–26, 2012.

[11] A. Levinshtein, A. Stere, K. N. Kutulakos, D. J. Fleet, S. J. Dickinson, and K. Siddiqi, “TurboPixels: Fast

Superpixels Using Geometric Flows,” T-PAMI, vol. 31, no. 12, pp. 2290–2297, 2009.

[12] A. P. Moore, S. J. D. Prince, J. Warrell, U. Mohammed, and G. Jones, “Superpixel lattices,” in CVPR,

2008.

[13] M. Leordeanu, R. Sukthankar, and C. Sminchisescu, “Efﬁcient closed-form solution to generalized bound-

ary detection,” in ECCV, pp. 516–529, 2012.

[14] P. Dollar, Z. Tu, and S. Belongie, “Supervised Learning of Edges and Object Boundaries,” in CVPR,

vol. 2, pp. 1964–1971, 2006.

5

1024 × 1024

3631 × 3859

963 × 1024

1002 × 1002

933 × 800

method
Current Work
1000 spx
Current Work
2000 spx
Achanta [2]
1000 spx
Achanta [2]
2000 spx
Veksler [5]
patch size 25
Veksler [5]
patch size 50
Zhang [6]
patch size 40
Zhang [6]
patch size 60
Comaniciu [7]
sp. bandw. 11
Comaniciu [7]
sp. bandw. 23
Shi [1]
1000 spx
Shi [1]
2000 spx
Felzenszwalb
[8] σ = 0.4
Felzenszwalb
[8] σ = 0.5
Liu [9]
500 spx
Liu [9]
1000 spx
Liu [9]
2000 spx
den Bergh [10]
200 spx
den Bergh [10]
400 spx
Levinshtein
[11] 1000 spx
Levinshtein
[11] 2000 spx
Moore [12]
bounds [13]
Moore [12]
bounds [14]

0.01

0.01

0.73

0.74

22.6

25.2

0.63

0.60

12.1

43.3

329

515

0.62

0.70

6.76

6.94

7.26

1.53

2.36

38.7

38.4

2.07

2.44

0.01

0.01

0.70

0.71

19.3

19.7

0.50

0.50

9.73

32.5

334

411

0.85

0.92

7.00

7.10

7.60

1.39

2.00

52.1

55.6

1.79

2.17

0.008

0.008

0.55

0.55

16.7

17.7

0.36

0.36

9.47

34.2

218

338

0.41

0.47

5.34

5.35

5.62

1.01

1.42

26.9

26.8

1.37

1.25

0.01

0.01

0.75

0.72

20.6

21.6

0.49

0.48

12.3

53.8

316

384

0.96

0.97

7.34

6.90

7.23

1.67

2.35

46.6

44.0

2.20

2.12

0.12

0.12

9.69

9.88

321

368

7.49

7.53

17.4

18.3

116

116

120

22.1

31.2

x

x

x

x

x

x

x

x

6

Table 1: Timing results for the tested methods.

gSLICr: SLIC superpixels at over 250Hz

Carl Yuheng Ren
carl@robots.ox.ac.uk
University of Oxford

Victor Adrian Prisacariu
victor@robots.ox.ac.uk
University of Oxford

Ian D Reid
ian.reid@adelaide.edu.au
University of Adelaide

September 15, 2015

Abstract

We introduce a parallel GPU implementation of the Simple Linear Iterative Clustering (SLIC) superpixel
segmentation. Using a single graphic card, our implementation achieves speedups of up to 83× from the
standard sequential implementation. Our implementation is fully compatible with the standard sequential
implementation and the software is now available online and is open source.

5
1
0
2
 
p
e
S
 
4
1
 
 
]

V
C
.
s
c
[
 
 
1
v
2
3
2
4
0
.
9
0
5
1
:
v
i
X
r
a

2 Simple Linear Iterative Clustering (SLIC)

3

gSLICr GPU Implementation

Contents

1

Introduction

4 Library Usage

5 Results

1

Introduction

Superpixels are regions of pixels grouped in some perceptually meaningful way, usually following colour or
boundary cues. They are designed to produce a simpler and more compact representation for an image, while
keeping its semantic meaning intact. Superpixel segmentation is used most often as an image preprocessing
step, with a view towards reducing computational complexity for subsequent processing steps.

The term superpixel, along with the ﬁrst notable superpixel algorithm, was introduced by [1]. Many algo-
rithms followed, using various types of image features, various optimisation strategies and various implemen-
tations techniques. These algorithms have varying speciﬁcations and performance requirements. For example,
some algorithms aim to ﬁnd a ﬁxed number of superpixels, others try to ﬁnd the minimum possible number
of superpixels by imposing a colour cohesion requirement, while others place emphasis on matching image
boundaries. Sometimes fast processing is required, when for example, the superpixel algorithm is used as a
precursor to a tracker. Sometimes superpixels are designed not to under-segment the image, when used for
example as a means of condensing the image information, to serve as the basis of a labelling problem. Re-
gardless of its design, superpixel segmentation is usually among the ﬁrst steps in a much longer processing
pipeline. Therefore, we believe that, for any superpixel method to be useful, it must satisfy the two following
requirements:

• it should not decrease the performance of the full processing pipeline;

• it should be fast.

1

1

2

3

3

4

Figure 1: Example SLIC superpixel segmentation

The performance requirement is satisﬁed in many vision applications by superpixels that are compact,
uniform and follow image edges. These requirements motivated the simple iterative clustering algorithm
(SLIC) algorithm of [2]. This is simple, efﬁcient and suitable for real-time operation. Still however, the CPU-
sequential implementation of SLIC need 300∼400ms to segment a single 640x480 image. Reducing the number
of iterations for each clustering pass can make the algorithm faster, at the cost of a decrease in performance.

In this work, we propose a GPU implementation of the SLIC algorithm, using the NVIDIA CUDA frame-
work. Our implementation is up to 83× faster than the original CPU implementation of [2], making it, to our
knowledge, the fastest superpixel method to date.

Our full source code with a simple example can be downloaded from https://github.com/carlren/

gSLICr. The following sections describe in detail our algorithm and implementation.

2 Simple Linear Iterative Clustering (SLIC)

The Simple Linear Iterative Clustering (SLIC) algorithm for superpixel segmentation was proposed in [2]. An
example segmentation result is shown in 1.

SLIC uses a k-means-based approach to build local clusters of pixels in the 5D [labxy] space deﬁned by
the L, a, b values of the CIELAB color space and the x, y pixel coordinates. The CIELAB color space is chosen
because it is perceptually uniform for a small distance in colour.

SLIC uses as input the desired number of approximately equally-sized superpixels K. Given an image
with N pixels, the approximate size of each superpixel therefore is N/K. Assuming roughly equally sized
superpixels, there would be a superpixel center at every grid interval S = (cid:112)N/K. Let [li, ai, bi, xi, yi]T be the 5D
point corresponding to a pixel. Writing the cluster center Ck as Ck = [lk, ak, bk, xk, yk]T , SLIC deﬁnes a distance
measure Dk as:

(cid:113)

dlab =

(lk − li)2 + (ak − ai)2 + (nk − bi)2

(cid:113)

dxy =

(xk − xi)2 + (yk − yi)2

Ds = dlab +

dxy

m
S

(1)

where Ds is the sum of the lab distance and the xy plane distance normalized by the grid interval S. The
variable m controls the compactness of superpixels i.e. the greater the value of m, the more spatial proximity is
emphasized and thus the more compact the cluster becomes.

This distance metric is next used in a standard local k-means algorithm. First, the cluster centers are
perturbed to the lowers gradient position from a local neighborhood. Next, iteratively, the algorithm assigns the
best matching pixels in a local neighborhood to each cluster and computes new center locations. The process
is stopped when the cluster centers stabilise i.e. when the L1 distance between centers at consecutive iterations
is smaller than a set threshold. Finally, connectively is enforced to cleanup the ﬁnal superpixel lattice.

In the next section we detail our GPU implementation of SLIC.

2

Figure 2: Workﬂow of gSLICr

3 gSLICr GPU Implementation

We split our implementation into two parts, as shown in Figure 2: the GPU is responsible for most of the
processing, with only data acquisition and visualization being left for the CPU.

The GPU implementation then proceeds as follows:

• Image space conversion: The RGB input image is converted to Cielab, using one thread for each pixel.

• Cluster center initialisation: We use one thread per cluster center (i.e. superpixel) to initialise our
superpixel map. This is an nsr × nsc image which contains, for each entry, center coordinates, number of
associated pixels and colour information. nsr and nsc represent the number of superpixels per image row
and column, respectively.

• Finding the cluster associations: Each pixel in the image determines what is its closest cluster using
the 5D distance detailed in the previous section. This requires a maximum of nine cluster centers to be
examined and is done using one thread per pixel.

• Updating the cluster center: Here we update each cluster center using the pixels assigned to it. This
process is done in two separate kernels. First, each cluster center must access all pixels associated to it,
within a local neighborhood that is a function of the superpixel size. Here we use nsr × nsc × nbl, where
nsr and nsc are deﬁned as before. nbl = spixel size × 3/BLOCK DIM captures the number of pixels
each thread can process, as a function of superpixel size and thread block dimension (16 in our case).
The result is written to an image of size nsr × nsc × nbl, upon which we run a reduction step on the third
dimension to obtain the ﬁnal updated cluster center positions.

• Enforce connectivity: We eliminate stray pixels with two one thread per pixel calls of the same kernel.
This prompts a pixel to change its label of that of the surrounding pixels (in a 2 × 2 neighborhood) if all
have a different label.

4 Library Usage

Our full code can be downloaded from https://github.com/carlren/gSLICr. It consists of (i) a
demo project (which requires OpenCV) and (ii) a separate library (which has no dependencies).

The demo project acquires images from the camera, processes them through the library and displays the
result back in an OpenCV window. It creates an instances of the core engine class, which is the main access
point to our code. This controls the segmentation code in the seg engine class and times the result.

The seg engine class is responsible for all the superpixel processing, and the algorithm is controlled from

the Perform Segmentation method. This code is listed below:

3

Figure 3: Cross Device Engine Design Pattern

v o i d s e g e n g i n e : : P e r f o r m S e g m e n t a t i o n ( UChar4Image ∗ i n i m g )
{

s o u r c e i m g −>SetFrom ( i n i m g , O R U t i l s : : MemoryBlock<V e c t o r 4 u > : :CPU TO CUDA ) ;
C v t I m g S p a c e ( s o u r c e i m g ,

i m g , g S L I C r s e t t i n g s . c o l o r s p a c e ) ;

c v t

I n i t C l u s t e r C e n t e r s ( ) ;
F i n d C e n t e r A s s o c i a t i o n ( ) ;

( i n t

i = 0 ;

i < g S L I C r s e t t i n g s . n o i t e r s ;

i ++)

U p d a t e C l u s t e r C e n t e r ( ) ;
F i n d C e n t e r A s s o c i a t i o n ( ) ;

f o r
{

}

}

i f ( g S L I C r s e t t i n g s . d o e n f o r c e c o n n e c t i v i t y ) E n f o r c e C o n n e c t i v i t y ( ) ;
c u d a T h r e a d S y n c h r o n i z e ( ) ;

Similar to the other projects from the Oxford Vision Library, such as LibISR [3] or InﬁniTAM [4], this
class follows our cross device engine design pattern outlined in Figure 3. The engine is split into 3 layers.
The topmost, so called Abstract Layer, contains the main algorithm function calls (listed above). The abstract
interface is implemented in the next, Device Speciﬁc Layer, which may be very different between e.g. a CPU
and a GPU implementation. Further implementations using e.g. OpenMP or other hardware acceleration archi-
tectures are possible. We only provide a GPU implementation in this case, in the gSLICr seg engine GPU.h
and gSLICr seg engine GPU.cu ﬁles. At the third, Device Agnostic Layer, there is some inline C-code that
may be called from the higher layers. This contains the bulk of the per-pixel and per-cluster processing code
and can be found in the gSLICr seg engine shared.h ﬁle.

5 Results

Our implementation is designed to produce the same result as the sequential SLIC implementation of [2], so
qualitatively and quantitatively the results are virtually identical. Our method is however considerably faster
than this, and, to our knowledge, all other superpixel segmentation techniques. We included a comparison with
many such techniques in Table 1. Here we used four images sizes, and our method was consistently much faster
than any other approach. Compared to the original SLIC algorithm, our approach is up to 83× faster.

Acknowldgements

We thank Magellium ltd. and CNAS for their support for our experimental section.

4

References

[1] J. Shi and J. Malik, “Normalized Cuts and Image Segmentation,” T-PAMI, vol. 22, pp. 888–905, 2000.

[2] R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, and S. S¨usstrunk, “SLIC Superpixels Compared to

State-of-the-Art Superpixel Methods,” T-PAMI, vol. 34, no. 11, pp. 2274–2282, 2012.

[3] C. Ren, V. Prisacariu, D. Murray, and I. Reid, “Star3d: Simultaneous tracking and reconstruction of 3d
objects using rgb-d data,” in Computer Vision (ICCV), 2013 IEEE International Conference on, pp. 1561–
1568, Dec 2013.

[4] V. A. Prisacariu, O. K¨ahler, M. Cheng, C. Y. Ren, J. P. C. Valentin, P. H. S. Torr, I. D. Reid, and D. W.
Murray, “A framework for the volumetric integration of depth images,” CoRR, vol. abs/1410.0925, 2014.

[5] O. Veksler, Y. Boykov, and P. Mehrani in ECCV, pp. 211–224, 2010.

[6] Y. Zhang, R. I. Hartley, J. Mashford, and S. Burn, “Superpixels via pseudo-Boolean optimization,” in

ICCV, pp. 1387–1394, 2011.

vol. 24, no. 5, pp. 603–619, 2002.

no. 2, pp. 167–181, 2004.

pp. 2097–2104, 2011.

[7] D. Comaniciu and P. Meer, “Mean Shift: A Robust Approach Toward Feature Space Analysis,” T-PAMI,

[8] P. F. Felzenszwalb and D. P. Huttenlocher, “Efﬁcient Graph-Based Image Segmentation,” IJCV, vol. 59,

[9] M.-Y. Liu, O. Tuzel, S. Ramalingam, and R. Chellappa, “Entropy rate superpixel segmentation,” in CVPR,

[10] M. V. den Bergh, X. Boix, G. Roig, B. de Capitani, and L. J. V. Gool, “SEEDS: Superpixels Extracted via

Energy-Driven Sampling,” in ECCV, pp. 13–26, 2012.

[11] A. Levinshtein, A. Stere, K. N. Kutulakos, D. J. Fleet, S. J. Dickinson, and K. Siddiqi, “TurboPixels: Fast

Superpixels Using Geometric Flows,” T-PAMI, vol. 31, no. 12, pp. 2290–2297, 2009.

[12] A. P. Moore, S. J. D. Prince, J. Warrell, U. Mohammed, and G. Jones, “Superpixel lattices,” in CVPR,

2008.

[13] M. Leordeanu, R. Sukthankar, and C. Sminchisescu, “Efﬁcient closed-form solution to generalized bound-

ary detection,” in ECCV, pp. 516–529, 2012.

[14] P. Dollar, Z. Tu, and S. Belongie, “Supervised Learning of Edges and Object Boundaries,” in CVPR,

vol. 2, pp. 1964–1971, 2006.

5

1024 × 1024

3631 × 3859

963 × 1024

1002 × 1002

933 × 800

method
Current Work
1000 spx
Current Work
2000 spx
Achanta [2]
1000 spx
Achanta [2]
2000 spx
Veksler [5]
patch size 25
Veksler [5]
patch size 50
Zhang [6]
patch size 40
Zhang [6]
patch size 60
Comaniciu [7]
sp. bandw. 11
Comaniciu [7]
sp. bandw. 23
Shi [1]
1000 spx
Shi [1]
2000 spx
Felzenszwalb
[8] σ = 0.4
Felzenszwalb
[8] σ = 0.5
Liu [9]
500 spx
Liu [9]
1000 spx
Liu [9]
2000 spx
den Bergh [10]
200 spx
den Bergh [10]
400 spx
Levinshtein
[11] 1000 spx
Levinshtein
[11] 2000 spx
Moore [12]
bounds [13]
Moore [12]
bounds [14]

0.01

0.01

0.73

0.74

22.6

25.2

0.63

0.60

12.1

43.3

329

515

0.62

0.70

6.76

6.94

7.26

1.53

2.36

38.7

38.4

2.07

2.44

0.01

0.01

0.70

0.71

19.3

19.7

0.50

0.50

9.73

32.5

334

411

0.85

0.92

7.00

7.10

7.60

1.39

2.00

52.1

55.6

1.79

2.17

0.008

0.008

0.55

0.55

16.7

17.7

0.36

0.36

9.47

34.2

218

338

0.41

0.47

5.34

5.35

5.62

1.01

1.42

26.9

26.8

1.37

1.25

0.01

0.01

0.75

0.72

20.6

21.6

0.49

0.48

12.3

53.8

316

384

0.96

0.97

7.34

6.90

7.23

1.67

2.35

46.6

44.0

2.20

2.12

0.12

0.12

9.69

9.88

321

368

7.49

7.53

17.4

18.3

116

116

120

22.1

31.2

x

x

x

x

x

x

x

x

6

Table 1: Timing results for the tested methods.

