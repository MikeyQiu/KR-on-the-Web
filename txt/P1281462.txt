Consistent Dialogue Generation with Self-supervised Feature Learning

Yizhe Zhang

Xiang Gao

Sungjin Lee

Chris Brockett

Michel Galley

Jianfeng Gao

Bill Dolan

Microsoft Research, Redmond, WA, USA
{yizzhang,xiag,sule,chrisbkt,mgalley,jfgao,billdol}@microsoft.com

9
1
0
2
 
r
a

M
 
7
2
 
 
]
L
C
.
s
c
[
 
 
2
v
9
5
7
5
0
.
3
0
9
1
:
v
i
X
r
a

Abstract

Generating responses that are consistent with
the dialogue context is one of the central chal-
lenges in building engaging conversational
agents. In this paper, we propose a neural con-
versation model that generates consistent re-
sponses by maintaining certain features related
to topics and personas throughout the conver-
sation. Unlike past work that requires exter-
nal supervision such as user identities, which
are often unavailable or classiﬁed as sensi-
tive information, our approach trains topic and
persona feature extractors in a self-supervised
way by utilizing the natural structure of di-
alogue data. Moreover, we adopt a binary
feature representation and introduce a feature
disentangling loss which, paired with control-
lable response generation techniques, allows
us to promote or demote certain learned top-
ics and personas features. The evaluation re-
sult demonstrates the model’s capability of
capturing meaningful topics and personas fea-
tures, and the incorporation of the learned fea-
tures brings signiﬁcant improvement in terms
of the quality of generated responses on two
datasets, even comparing with model which
explicit persona information.

1

Introduction

The notion of speaker consistency is attracting
growing interest in neural response generation re-
search (Li et al., 2016b; Luan et al., 2016; Zhang
et al., 2018a; Gao et al., 2018). When interacting
with an open-domain neural conversation agent,
users may expect the agent to develop the dialogue
with consistent information, mitigating the user
confusion and improving engagement. Speaker
topic consis-
consistency presents two aspects:
tency and persona consistency. Topic consistency
reﬂects the model’s ability to maintain dialogue
topics such as sport, movie or music without get-
ting sidetracked. Persona consistency envisions
the agent as human-like, endowed with a relatively
invariant individual personality, style of engage-
ment (e.g., enthusiasm and casualness) or personal
proﬁle (e.g., place of residence).

Figure 1: Task illustration: generating responses that
are consistent with dialogue history in persona, tone
and topic (from our system, 2 context turns).

Generating appropriate responses with these
characteristics is a major challenge (Figure 1). Li
et al. (2016b); Luan et al. (2017) and Al-Rfou
et al. (2016) use persona embeddings as the ad-
ditional input to train end-to-end conversational
agents. Obtaining accurate persona embeddings as
in Li et al. (2016b) however requires many thou-
sands of utterances per persona, and targeted test
personas may not always be found in the train-
ing data. End-to-end systems are often trained
from social media data in which only a small
spectrum of personas (casual speakers) is repre-
sented and professional roles (e.g. customer ser-
vice) may be underrepresented, thus limiting de-
ployment. Typically, moreover, the objective is
to maintain consistency of both persona and topic
throughout the dialogue, rather than inject speciﬁc
personas/topics in responses. Under these scenar-
ios, learning and leveraging persona or dialogue
topic in a data-efﬁcient and unsupervised way be-
comes crucial.

We present a self-supervised approach that uses
the natural structure of conversational data to learn
and leverage topic and persona features. Our pro-
posals include:

1) A discriminative feature extraction mecha-
nism that captures conversational topics and per-
sonas in a self-supervised manner, without requir-
ing speciﬁcation of speaker identity, thus allow-

ing massive unlabeled datasets to be utilized while
protecting sensitive user information.

2) Use of binary features and a disentangling
loss to improve interpretability of learned features.
This affords ﬂexibility to activate or deactivate
speciﬁc features when generating responses.

3) Leveraging a controllable text generation
mechanism to force generated responses to adhere
to high-level features such as topic and persona en-
coded in the controlling signal.

been employed in text style transfer and many
other tasks (Ficler and Goldberg, 2017; Asghar
et al., 2018; Ghosh et al., 2017; Dong et al., 2017).
This helps disentangling high-level style infor-
mation from contextual information such that the
style information can be independently manipu-
lated to produce text with different styles. Related
to our work, Zhao et al. (2018) considered dis-
crete latent actions to learn a human-interpretable
representation for task-oriented dialogue systems.

2 Related Work

3 Proposed Approach

Self-supervised learning Self-supervised as a
subdomain of unsupervised learning, has been ap-
plied to representation learning for image, video
and audio (Denton and Vighnesh, 2017; Doersch
et al., 2015; Owens and Efros, 2018). However,
to the best of the authors’ knowledge, the applica-
tion of self-supervision in conversational agents is
rare. Borrowing deﬁnitions from other domains,
self-supervised approaches in NLP make use of
non-textual signals that intrinsically correlate with
the text to supervise the text feature learning (Den-
ton and Vighnesh, 2017).

Persona-aware response generation Welleck
et al. (2018) suggested a natural language infer-
ence (NLI) approach to improve the persona con-
sistency, however additional labels are required.
Zhang et al. (2018a); Qian et al. (2018) use ex-
plicit personal proﬁles as side information to guide
response generation. Such information, however,
may not always be available. Other work pro-
poses injecting either emotion (Zhou et al., 2018)
or functional control (Ke et al., 2018) into dia-
logue generation. As in Li et al. (2016b), learning
to leverage the controlling signal in order to bias
generation may require signiﬁcant amounts of la-
belled data.

Topic-aware response generation Leveraging
topic modeling in response generation has been
explored by several prior works (Xing et al., 2017;
Wang et al., 2017; Wu et al., 2018). Our approach
differs from these methods in that we focus on
learning discriminative features that help distin-
guish a topic or person from another. Also, our
method employs a neural sentence encoder to cap-
ture richer features than the bag-of-words features
that the conventional topic models opt for.

Interpretable
generation
Controllable text generation (Hu et al., 2017) has

and controllable

The proposed approach use additional unsupervis-
edly learned features to generate response utter-
ances that reﬂect these features. We elaborate two
major components of the proposed approach: a
feature extractor trained to extract topic/persona
features from each utterance; and a response gen-
erator that takes the extracted features as input to
generate responses accordingly.

D

1 , upiq

2 , ¨ ¨ ¨ , upiq

3.1 Problem statement
Let dpiq ﬁ rupiq
T s denote the i-th di-
, where upiq
alogue session in dataset
is the j-th
j
utterance and T is the number of turns in this di-
alogue session. We assume that each dialogue di
only consists of the utterances between two speak-
ers, interleaving with each other. Suppose the ﬁrst
K (K ă T ) turns of each dialogue are revealed,
our aim is to generate the remaining T ´K turns of
the dialogue that are consistent with the observed
context.

3.2 Discriminative feature extraction

Figure 2: Feature extractor design. s and t are two ran-
domly shufﬂed sentences. An extractor network F p¨q
(F can be either
) encodes both of them to yield
features F psq and F ptq, which are then used to predict
label y.

represents matching function/network

or

P

T

M

Inspired by Denton and Vighnesh (2017), we
adopt a self-supervised discriminative training
scheme where we design a neural model which
includes an explicit feature extraction layer as il-
lustrated in Figure 2 and formulate a discrimina-

tive task to train the model. When training is
done, the feature extraction layer yields relevant
features for the associated task. In this section, we
introduce two discriminative tasks to capture two
types of sentence features, respectively: 1) topic-
speciﬁc features (
) that characterize conversation
T
topics. 2) persona-speciﬁc features (
) that reﬂect
speaker characteristics.

P

Topic feature extractor
In order to build a topic
feature extractor with self-supervision, we rely on
the assumption that utterances from the same con-
versation session are likely to share similar topics.
Thus, we formulate a surrogate task to identify if
two random sentences s and t from
belong to
the same dialogue session. Speciﬁcally, when they
come from the same dialogue session, i.e.s, t P di,
we assign 1 to target y and 0 otherwise. We opti-
mize the cross-entropy objective:

D

xent “

L

ryi log

p
T

M

psiq,

ptiqq

T

1
N

Nÿ

i“1

p
T

` p1 ´ yiq logr1 ´

psiq,

ptiqqss,

T

T

T

T

M

psiq and

M
p¨q denotes the topic-speciﬁc feature ex-
where
tractor (shared among all sentences), and
p¨, ¨q
represents a matching network detecting whether
ptiq belong
the two feature vectors
T
to the same dialogue session. We use a 3-layer
convolutional neural network (CNN) followed by
a non-linear mapping for
p¨q to produce an L-
dimensional vector. For the non-linear mapping,
we explore two options: 1) We employ a sig-
moid function to produce a soft-binary represen-
pxq P p0, 1qL. 2) We compute a hard-
tation, i.e.
binary representation by taking 1 if it is positive
pxq P t0, 1uL. This non-
and 0 otherwise, i.e.
negative bounded representation lends itself well
to interpretation and control of each component
of
pxq. For instance, we can activate or deac-
tivate a certain topic or persona by simply turn-
ing on and off the corresponding component. For
the matching function, we apply a sigmoid func-
tion to the inner-product of two feature vectors,
i.e.f p
ptq{τ q, where τ
psq ¨
ptq.
is a hyperparameter to scale the
psq ¨

ptqq “ σp

psq,

T

T

T

T

T

T

T
T

T

Persona feature extractor Here we consider
extracting persona features in a broader sense of
current speaker’s status related to emotion (Zhou
et al., 2018), personality, tone and function con-
trol (Ke et al., 2018). Note that we are only inter-
ested in maintaining consistency of any emerging

T

P

) and persona (

persona, rather than characterizing a full spectrum
of persona features. The only difference between
the topic (
) feature extractors
is how the positive and negative sample pairs for
training are created. In the persona feature extrac-
tor, the positive pairs (y “ 1) or negative pairs
(y “ 0) are the utterances from the same or dif-
ferent speaker within a dialogue, aiming to elim-
inate the topic information from the persona fea-
tures. Ideally, the two speakers in a dialogue are
discussing the same topic. Under this assumption,
since the utterances in a negative pair are also from
the same dialogue, they are like to share the same
topics. Thus, the model is forced to learn the fea-
tures that can capture different personas of the two
speakers.

Unlike Li et al. (2016b), where each speaker is
assigned a single speaker embedding vector, in our
proposed method the utterances by one speaker
can have different feature vectors as the manifes-
tations of the underlying persona embedding in a
different context. Nevertheless, the discriminator
objective encourages these vectors to be similar
since they refer to the same person. We believe
that our approach is more data-efﬁcient than (Li
et al., 2016b) because the former allows borrow-
ing information from a wider range of speakers.
In (Li et al., 2016b), information borrowing only
happens to the speakers who are similar to the cur-
rent speaker in persona embedding space. As a
result, persona embeddings can be poor for those
not based on many dialogues. Our method, on
the other hand, can leverage those speakers who
share any speciﬁc features with the current speaker
and is able to learn more robust representations
of speakers because we aggregate personal traits
across all users. However, Li et al. (2016b) com-
plement our methods nicely in that it does not re-
quire dialogue history as the seed to initiate the
ﬁrst several turns.

features We

Interpretable
considered two
methods of making the learned features more
interpretable:
feature vector disentangle-
ment (Cogswell et al., 2015); 2) feature vector
binarization (Zhao et al., 2018).

1)

First, we employ a decorrelation (DeCorr)
loss inspired by Cogswell et al. (2015), who in-
troduced a DeCov loss to regularize deep neural
networks. Speciﬁcally, we add an additional term
in the objective function when training the topic

and persona feature extractors:

DeCorr “

L

Mjk “

1
p||M ||2
2
ř
ař

F ´ ||diagpM q||2
F q
ipF psjq ´ µjqpF pskq ´ µkq
ř
ipF psjq ´ µjq2

ipF pskq ´ µkq2

,

or

where ||¨||F represents the matrix Frobenius norm,
and the diagp¨q operator represents diagonaliza-
tion of a matrix. F denotes the feature extractor,
and can be either
. M is the correlation
P
matrix of F , computed from the current batch of
data. Note that achieving a reasonable estimation
of the correlation matrix requires a relatively large
mini-batch size. The resulting ﬁnal objective for
DeCorr, where λ is
the discriminator is
xent ` λ
a balancing hyperparameter.

L

L

T

Second, alternatively, we also consider binary
feature vectors, where a straight-through (ST) es-
timator is used for the gradient calculation (Bengio
et al., 2013; Shen et al., 2018). Suppose the binary
feature F is rounded from a probability vector
p, ST estimator back-propagate through the hard
threshold by approximating the gradient BF {Bp as
1. We empirically found that setting
to use the
inner product of F psq and F ptq fails. We presume
the reason may be that the value of the inner prod-
uct between two binary vectors can only take in-
tegers from r´L, Ls which limits the representa-
tion power of the model. We therefore concatenate
F psq and F ptq and passing it through a multi-layer
perceptron (MLP) to predict the matching label
y. Interchangeability is still loosely maintained as
the pair pS, T q is randomly swapped when feeding
into the discriminator.

M

Utterance pair construction One issue in con-
structing the positive/negative pair for the feature
extractor is that the number of positive/negative
pairs need to be balanced to achieve a robust em-
pirical result. Moreover, when constructing the
positive sample pairs with y “ 1, if the s and t
are adjacent or close to each other in a dialogue,
we might end up capturing adjacency pairs (Sacks
and Schegloff, 1973) rather than conversation top-
ics. For example, s “ ’How are you?’ and
t “ ’Fine.
How are you?’. The captured
similarity in feature space of this s, t pair is con-
textual appropriateness rather than topic/persona
consistency. To alleviate this, we collect only
those pairs that are more than 4 turns away from
each other for the positive sample pairs.

We note also that the persona features may af-
fect the topic feature extractor because the per-
sona features can be weak signals for predicting
whether two sentences are from the same dia-
logue. One remedy is to select utterances from
different speakers within a dialogue session when
constructing the positive pairs for the topic extrac-
tor to eliminate as much as possible the effect of
the persona features. However, this remedy can re-
sult in fewer positive pairs. Empirically the topic
extractor works well even without this remedy,
presumably because the strong signal from topic
overwhelms the weak signal from persona.

3.3 Generator design

that produces neural

Training a response generator The conditional
multi-turn generator
re-
sponses given the K-turn source sentences is
shown in Figure 3, which is conceptually related
to (Serban et al., 2016). During training time (Fig-
ure 3 left panel), each source sentence is ﬁrst en-
coded by a 3-layer CNN encoder, which shares
the same architecture as the feature extractor, fol-
lowed by a context aggregator (AGGC) layer
that summarizes all sentence embedding vectors
rc1, c2, ¨ ¨ ¨ , cKs into one single context vector C
In this paper,
with the same dimension as ci.
the AGGC layer is designed as ﬁrst concatenating
rc1, c2, ¨ ¨ ¨ , cKs and applying a fully-connected
layer to map the resulting vector to C.

On the other hand, the target sentence is pro-
cessed by the feature extractors to produce feature
vector(s) F as described in Section 3.2. The fea-
ture extractors are ﬁxed in the response generator
since we observed ﬁne-tuning the feature extrac-
tor leads to suboptimal empirical results. The con-
text vector C and feature vector(s) F are fed into
an MLP to generate a ﬁxed-length initial hidden
variable H0. This is followed by a series of long
short-term memory (LSTM) units as the decoder,
where H0 is employed as input in each time-step.

Controllable objective during training Our
generator loss incorporates two components. The
ﬁrst one is the vanilla teacher-forcing (Williams
MLE. The second
and Zipser, 1989) MLE loss
part is a cycle consistency loss
cycl, introduced
by (Hu et al., 2017) to admit additional controlling
ability of feature vector in the generation.
Intu-
itively, it encourages the self-generated response
under free-running generative mode to have the
same features as the input signal F . Speciﬁ-

L
L

Figure 3: Controllable generation scheme (better in color). The feature extractor F p¨q are represented as solid
blue arrows. During training time, contextual sources ru1, ¨ ¨ ¨ , uKs are encoded (by encoder), and aggregated (by
aggregator) to a context vector C, meanwhile the target uK`1 is abstracted by feature extractor as feature vector
F . The decoder then (controllably) generates a response ˜u based on both C and F . For testing, the feature F is
obtained by aggregating the feature vectors for each source sentence.

L

cycl “ ||F ´ F p˜uq||2.

cally, consider a response ˜u “ rw1, w2, ¨ ¨ ¨ , w|˜u|s
greedily generated by conditioning on previously
cycl is simply the Eu-
generated tokens. The
L
clidean distance between input feature vectors F
and F p˜uq, i.e.
In the
cycl “ ||F ´ P p˜uq||2
case of binary features,
L
where P p¨q is the network output before round-
ing to binary values. Note that the generated to-
kens rw1, w2, ¨ ¨ ¨ , w|˜u|s involves an argmax op-
eration and are not directly differentiable, prevent-
ing the gradient signals from back-propagating to
the encoder and decoder. Common remedies for
this includes Gumbel-softmax (GS)(Gumbel and
Lieblein, 1954), policy gradient (PG)(Yu et al.,
2017) and soft-argmax (SA)(Zhang et al., 2017).
Unfortunately, GS and PG suffer from high vari-
ances of gradient estimation while SA suffers from
a dilemma between gradient vanishing and inac-
curate gradient. To alleviate such a problem in
SA, we consider an approach in what we call the
Straight-Through LSTM unit (ST-LSTM), which
use ST estimation (Bengio et al., 2013; Jang et al.,
2016) to achieve a biased but smooth gradient sig-
nal while maintaining the forward computation ex-
act via a temperature parameter τ . The details are
provided in the Appendix.

In the experiment, we applied the slope-
annealing trick (Chung et al., 2016), and set τ “
0.01 which works well in practice. The ﬁnal train-
cycl.
ing objective for the generation is

MLE ` η

L

L

Testing time At test time, as shown in Fig-
ure 3 (right panel), the feature vectors from the
source sentences ru1, ¨ ¨ ¨ , uKs are ﬁrst collected
by applying feature extractors F p¨q. We de-
note the feature vectors for the source sentences
as rf1, ¨, fKs. We apply a feature aggregator
AGGF layer to estimate the output feature vec-

ř

ř

ř

K
k“1 wkfk, s.t.

tor F , which is further fed into the LSTM-RNN
for the generation. Different from the context
AGGC layer, we consider a weighted-sum ag-
gregation function for the feature AGGF layer 1,
K
i.e., F “
k“1 wk “ 1, where
wk, k “ r1, 2, ¨ ¨ ¨ , Ks are linear interpolation
weights learned during training time, where a Eu-
clidean distance between predicted target feature
and target feature is optimized, i.e.argminwL
p “
For the persona fea-
||fk`1 ´
ture, we only use the source sentences of the
current speaker, thus all wk where modpk, 2q “
modpK, 2q is set as zero.
Intuitively it can be
perceived as the attention of each utterance. We
note that more complicated attention mechanisms
can further improve the model; however, we leave
these for future work, since this paper focuses on
the utilization of dialogue features rather than im-
proving the multi-turn S2S structure in general.

K
k“1 wkfk||2.

4 Experimental setups

We evaluate the proposed methods on two
datasets. All experiments are conducted using sin-
gle Nvidia Tesla V100 GPU. The source code will
be released.

4.1 Data collection

We consider two datasets. For both we use a (80%,
10%, 10%) split for training, validation and test
respectively.

Twitter data Training data was extracted from
the Twitter FireHose covering a ﬁve-year period
from 2012 through 2016.2 From this set, we col-

1Other possibilities of such an AGGF layer exist, such
as mean, max or concatenation (as in AGGC ). We choose
weighted-sum for the AGGF layer due to its superior empir-
ical performance comparing to alternatives.

2Deleted tweets and closed accounts were removed.

lected total 6,658,385 8-turn dialogues where two
participants chatted with each other.

loss (λ “ 0.01), the correlation between features
drops from 0.25 to 0.16.

Maluuba data The Maluuba dataset consists of
40,389 dialogues with 11 turns. Each dialogue
is a task-oriented conversational interaction be-
tween two real speakers regarding 51 domains and
242 tasks, collected by crowd-sourcing where one
crowd worker simulates a user and another simu-
lates a chatbot.

4.2 System speciﬁcations

The dimension of the LSTM hidden layer is set at
500. We use ADAM as the optimizer with learn-
ing rate 0.0001. The hyperparameters λ and η are
set at 0.01 and 0.1, respectively. For the dimen-
sion of feature vectors we use 100. For Maluuba
dataset we use a 50% dropout rate in each of the
CNN layers and the λ is set to 0.1. The hyperpa-
rameters are selected to maintain the discrimina-
DeCorr as
tion accuracy while reducing as much
possible.

L

For evaluation, we consider three variants of
our COnsistent CONversation (CoCon) models:
CoCon-T: CoCon model with topic-consistency;
CoCon-TP: CoCon model with topic-consistency
and persona-consistency; CoCon-TP-bin: Co-
Con model using binary features with topic-
consistency and persona-consistency. We com-
pared our models with two baselines: a vanilla
sequence-to-sequence model (S2S) and persona
model (Persona) (Li et al., 2016b). We implement
the persona model by reusing the encoder and de-
coder architecture in our approach. For Twitter
dataset, we map all users with fewer than 88 utter-
ances as unknown (86% of the total training sam-
ples) and in the test set (for all compared methods)
we eliminate conversation sessions with unknown
users. This yields 50k total users. We use the same
number of feature dimensions for all systems com-
pared. All modules are trained until convergence.

5 Results

Self-supervised feature
learning We used
equal numbers of positive/negative examples to
train each feature extractor. For Twitter dataset,
the resulting accuracies for topic and persona
feature extractor are around 0.75 and 0.60 (for
both continuous and binary features), respectively.
For Maluuba dataset, the discriminator accuracy
for persona and topic feature extractors are 0.85
and 0.67, respectively. With the disentangling

Representative n-grams for some learned fea-
ture units for Twitter dataset are shown in Table 1.
To calculate the feature vector for a speciﬁc n-
gram, we average over the feature vector of test
sentences that contain that n-gram. We then select
the top-ranked n-grams with occurrences greater
than 200 for each feature bit. We observe that
when λ “ 0, i.e.without disentangling loss, the
learned features exhibit heavy colinearity, which
weakens the interpretability of each separate fea-
ture units.

Topics
T-2
(elec-
tronic)

T-59
(sport)

T-18
(Movie
, show)

Persona
P-71
(in-
quiry)
P-49
(agree-
ment)

P-28
(ab-
brevia-
tion)
P-83
(african
amer.)

1gram
android;
ios;
apps

striker;
arse-
nal;
madrid
episodes;
ﬁlm;
netﬂix

1gram
what;
thx;
wheres
yea;
great;
sure

hav;
urself;
wats

aint;
homie;
yo;

2gram
the iphone;
the app; my
ipad

champions
league
;
best player;
the spurs;
of thrones;
that movie;
the ending

2gram
can u; do
u; where
is
lol
yea;
yea i; hell
yea

u will; u
got; for u

3gram
a
new
phone; my
phone is; are
you using
the
in
league;
in
the playoffs;
a good game
i watched it;
to watch it;
the ﬁrst one

3gram
how do i; is
there a; what
is the
that s so;
i
will do; yea i
m

i thought u;
did u get; do
you have

4gram
is on my phone;
you can use the;
send it to the

one of the best;
best of the season;
the team in the;

one of my fa-
vorite; have you
seen the; i want to
see
4gram
thank
you
so
i need to
much;
get ; i want to see
i would love to;
looking
forward
to it; sounds like
a plan
s what s up; i m
bout to; do u have
any

n****
i;hell
yea;i ain

u ain ’t; cuz
i am;
i ’m
tryna

i ’m bout to; i ’m
gonna have; ain ’t
nothing gonna

Table 1: Representative n-grams in topic (T) and per-
sona (P) features

Figure 4:
t-SNE embedding of topic (left) and per-
sona (right) features for different tasks (left) and roles
(right).

We further visualized the topic features on
both datasets using t-SNE embedding (Maaten and
Hinton, 2008). For Maluuba dataset, Figure 4 il-
lustrates the learned topic and persona feature em-
beddings on the test set. Without any label infor-
mation, the learned topic and persona features sep-

Context:

Human:

S2S:
Persona:
(Ours)
CoCon-T:
(Ours)
CoCon-TP:
Context:

Human:

S2S:
Persona:
(Ours)
CoCon-T:
(Ours)
CoCon-TP:

A:tommorows game just became that much bigger . must
win .
B: unbeliebable . mourinho has never lost at home in the
league as chelsea coach and against the worst team in
the league he loses
A:yup , would be insane if they could somehow avoid
relegation now .
B:would be amazing.we played against them at home 3
weeks ago but barely beat them . they are always up for
it against the big teams
A:yeah , said they played aggainst top half of table much
better then bottom half .
A:i think they ’ll be ﬁne . . .
A:i think they ’ll be in the same position .
A:i think they play well . i ’m a big fan of the manager
. they ’ve played well in the same league as well .
A:yeah , they played well with the top three teams , but
i ’d say it was . not sure what to expect .
A:lucky you mate . have a super ﬁne weekend buddy
B: i m gonna be knackered next week should be a good
weekend though gonna get loads a pics
A:can n’t fault you mate nice mid night start tuesday lol
B:gonna be at the show saturday then home sunday back
to work monday . where you off to tomorrow ?
A:one out of cedar farm to march then not sure mate ei-
ther ipswich or a hiams to march .
A:not sure . i ’m off for a few days
A:i ’m off friday night . you going to the game ?
A:i know . i am going to manchester on the weekend .
what about you ?
A:i ’m going to the beach mate . i ’m going for a couple
days off . good weekend pal

Table 2: Sampled generation on Twitter.

Context: A:done with the game

B:what are you talking about
A:you heard me
B:if you ’re not there today i ’m going to be mad

Human: A:lol ok i aint going

Plain:

Sport:
on

B:are you trying to be a bod mon or something ?
A:oh you that ’s exactly how i ’m tryna be aha
B:so tell me why you are n’t going ? you just say you ’re not ,
talk about it
A:i’m on the vacation. i’m not going to play that game
B:you don’t really mean this, right? you’re n’t going to do that
A:i aint , i told you .
B:well you can n’t be a person like that , you can n’t be a loser
A:i’m watching the school football. that’s enough for now
B:that’s why you’re a loser
A:lol no i’m going to be the best player in the league.
B:oh well you’re not going to win man you are terrible at all this
time.

Table 3: Examples of bit manipulations. Plain denotes
without manipulation. X on denotes bit X is activated
(set to 1) when generating the response

arate well. For twitter dataset, we observed that
the persona features of the utterances from differ-
ent time zones form some clusters, indicating the
features learned from our approach can partially
reﬂect the difference in societal groups (See Ap-
pendix B).

Sampled response generation We evaluate our
approaches by generating the next response given
4 contextual seed source sentences. Some sam-
pled results are shown in Table 2. We observed
that the CoCon-T and CoCon-TP in general are
able to produce informative responses which seem
to be more consistent with the theme of the given
context comparing with baselines. For CoCon-TP,

beyond being context-aware, the responses seem
to be persona-aware, i.e., mimicking the tone and
personal wording preferences like mate, oh my
gosh, haha, ain ’t and other words associ-
ated with them.

L

Feature manipulation We further manipulate
feature bits that seem to be associated with cer-
tain topics. The results are shown in Table 3 (ad-
ditional results are provided in the Appendix). We
generate next 4 turns consecutively. The later gen-
erations consider the previous 4 sentences, includ-
ing previously generated utterances as source con-
text. This bit manipulation is based on binary fea-
ture codes, achieved by toggling the speciﬁc bit to
be 1 to activate it. With the additional controllable
cycl, we are able to better
generation objective
control the ﬂipping of each bit. As shown in Fig-
ure 6 in Appendix B, increasing η leads to a fast
cycl (indicating a better controlling
decrease of
power), however may at a cost of harming the gen-
eration quality. We select the η “ 0.01 by trading
off between both aspects. We observe the success
rate of bit toggling is about 17% percent (based
on 2000 tested cases), meaning that around 17%
cases where we ﬂip a 0 of the input feature F to
1, the response feature ˜F will remain 1. Presum-
ably, the model has learned to detect that, based
on the context, it is unnatural to toggle a certain
bit and refused to make the change. This hypoth-
esis needs further experimental veriﬁcation. Con-
trollable generation is still an emergent technology
and the noisy nature of dialogue data makes this
even more challenging.

L

For Maluuba dataset, we provide sampled re-
sponses of S2S and CoCon-TP in Table 8 in Ap-
pendix 5. The context is given as 4 turns of di-
alogues and the task to generate all remaining 7
turns. It can be seen that during free generation,
the S2S model tend to generate looping responses
like thanks - you ’re welcome and is gen-
erally less informative. However, our proposed
CoCon-TP approach can generate reasonably well
by unsupervisedly capturing the topics of the con-
text and role of each turn.

evaluations

Automatic
In our quantitative
evaluations we test both relevance and diversity
metrics. For relevance, we adopt BLEU (Pa-
pineni et al., 2002), METEOR (Denkowski
and
(Doddington,
embedding-based metrics
2002)

Lavie,
and

2014),

NIST

three

Ours

Models

CoCon-T
CoCon-TP
CoCon-TP-bin

S2S
Persona model
Human

Relevance

BLEU METEOR NIST Greedy Average
1.022
3.01
1.135
3.31
1.061
3.04
0.945
2.83
1.014
2.96
-
-

1.968
2.048
2.025
1.855
1.931
-

0.061
0.064
0.063
0.056
0.059
-

0.675
0.683
0.677
0.640
0.658
-

Diversity
Extreme Dist-1 Dist-2
0.065
0.008
0.081
0.008
0.100
0.009
0.023
0.004
0.028
0.005
0.473
0.078

0.321
0.342
0.331
0.307
0.319
-

Ent-4
9.71
10.46
10.59
7.51
7.96
11.75

Table 4: Quantitative evaluation for twitter dataset

Ours

Models

CoCon-T
CoCon-TP
CoCon-TP-bin

S2S
Persona model
Human

Relevance

Diversity

BLEU METEOR NIST Greedy Average
1.421
1.459
1.280
1.045
1.134
-

0.076
0.077
0.074
0.066
0.073
-

2.105
2.175
2.094
2.021
2.042
-

0.565
0.575
0.559
0.529
0.543
-

5.6
5.8
4.6
3.9
4.4
-

Extreme Dist-1 Dist-2
0.142
0.025
0.028
0.16
0.19
0.027
0.16
0.017
0.177
0.021
0.462
0.092

0.358
0.365
0.341
0.328
0.319
-

Ent-4
8.899
8.983
9.767
8.293
8.603
10.281

Table 5: Quantitative evaluation for Maluuba dataset

Topic Consistency (human judges preferred)

Persona Consistency (human judges preferred)

Our Method

Neutral

Comparison

Our Method

Neutral

Comparison

CoCon-TP
CoCon-TP

45.20% 22.30% 32.50% seq2seq
40.05% 23.10% 36.85% persona

CoCon-TP
CoCon-TP

40.95% 29.85% 29.20% seq2seq
35.65% 34.10% 30.25% persona

CoCon-TP

21.50% 26.85% 51.65% human

CoCon-TP

21.35% 33.35% 45.30% human

Table 6: Results of Human Evaluation for topical and persona consistency, showing preferences (%) for our
model (CoCon-TP) vis-a-vis baseline or other comparison systems. Distributions are skewed towards CoCon-TP,
except when compared with human outputs. Numbers in bold indicate the most preferred systems. For simplicity,
the 5-point Likert scale is collapsed to a 3-point scale. See the Appendix for further details.

following

Greedy,Average,Extreme
(Serban
et al., 2017; Rus and Lintean, 2012; Mitchell
To
and Lapata, 2008; Forgues et al., 2014).
evaluate diversity, we follow (Li et al., 2016a)
to use Dist-1 and Dist-2, which is characterized
by the proportion between the number of unique
n-grams and total number of n-grams of tested
sentence. We also include the Entropy (Ent-n)
metric (Zhang et al., 2018b; Gao et al., 2019),
which does not depend on the size of test data.
The results of automatic evaluations are shown
in Table 4 (Twitter) and Table 5 (Maluuba).
For both dataset, the CoCon-TP model achieves
best relevance score, while the CoCon-TP-bin
outperforms other methods in diversity.

Human evaluations We evaluated 500 ran-
domly sampled test sources from Twitter dataset
using crowd-sourcing provided by a contracting
service. Systems were paired and each pair of sys-
tem outputs was randomly presented to 4 judges,
who ranked them for topic consistency, persona
consistency, informativeness and relevance using
a 5-point Likert scale. Overall judges’ prefer-

ences for the topic consistency, persona consis-
tency, given as a percentage of total judgments are
shown in Table 6. A strong overall preference can
be observed for CoCon-TP over the other systems
evaluated. We also evaluated for relevance and
informativeness, with CoCon-TP showing similar
preference gains. Further details, including the hu-
man evaluation template used, are provided in the
Appendix.

6 Conclusion

We present a self-supervised feature learning
framework to abstract high-level latent represen-
tations of topic and persona information underly-
ing the dialogue context and leverage these rep-
resentations to generate more consistent dialogue
in a controllable manner. For future work, inves-
tigating the variance reduction strategies for con-
trollable text generation would presumably im-
prove the controllablity of the feature units. Be-
sides, combining and aligning supervised and un-
supervised features would potentially enable bet-
ter feature learning and interpretability. Our ap-

proach can be adapted to facilitate style transfer
and long-form text generation (Guo et al., 2018;
Zhang et al., 2017) to improve the generation con-
sistency.

References

Rami Al-Rfou, Marc Pickett, Javier Snaider, Yun-
hsuan Sung, Brian Strope, and Ray Kurzweil. 2016.
Conversational contextual cues: The case of person-
alization and history for response ranking. arXiv.

Nabiha Asghar, Pascal Poupart, Jesse Hoey, Xin Jiang,
and Lili Mou. 2018. Affective neural response gen-
eration. In ECIR, pages 154–166. Springer.

Yoshua Bengio, Nicholas L´eonard,

and Aaron
Courville. 2013. Estimating or propagating gradi-
ents through stochastic neurons for conditional com-
putation. arXiv.

Junyoung Chung, Sungjin Ahn, and Yoshua Bengio.
2016. Hierarchical multiscale recurrent neural net-
works. arXiv preprint arXiv:1609.01704.

Michael Cogswell, Faruk Ahmed, Ross Girshick, Larry
Zitnick, and Dhruv Batra. 2015. Reducing overﬁt-
ting in deep networks by decorrelating representa-
tions. arXiv preprint arXiv:1511.06068.

Michael Denkowski and Alon Lavie. 2014. Meteor
universal: Language speciﬁc translation evaluation
for any target language. In workshop on statistical
machine translation, pages 376–380.

Emily L Denton and Birodkar Vighnesh. 2017. Un-
supervised learning of disentangled representations
from video. In NIPS, pages 4414–4423.

George Doddington. 2002.

Automatic evaluation
of machine translation quality using n-gram co-
occurrence statistics. In Proceedings of the second
international conference on Human Language Tech-
nology Research, pages 138–145. Morgan Kauf-
mann Publishers Inc.

Carl Doersch, Abhinav Gupta, and Alexei A Efros.
2015. Unsupervised visual representation learning
by context prediction. In ICCV, pages 1422–1430.

Li Dong, Shaohan Huang, Furu Wei, Mirella Lapata,
Ming Zhou, and Ke Xu. 2017. Learning to generate
product reviews from attributes. In EACL, volume 1,
pages 623–632.

Jessica Ficler and Yoav Goldberg. 2017. Controlling
linguistic style aspects in neural language genera-
tion. EMNLP, page 94.

Gabriel

Joelle

Pineau,

Forgues,

Jean-Marie
Larchevˆeque, and R´eal Tremblay. 2014. Boot-
strapping dialog systems with word embeddings.
In NIPS, modern machine learning and natural
language processing workshop.

Jianfeng Gao, Michel Galley, and Lihong Li. 2018.
arXiv

Neural approaches to conversational AI.
preprint arXiv:1809.08267.

Xiang Gao, Sungjin Lee, Yizhe Zhang, Chris Brock-
ett, Michel Galley, Jianfeng Gao, and Bill Dolan.
Jointly optimizing diversity and relevance
2019.
arXiv preprint
in neural response generation.
arXiv:1902.11205.

Sayan Ghosh, Mathieu Chollet, Eugene Laksana,
Louis-Philippe Morency, and Stefan Scherer. 2017.
Affect-LM: A neural language model for customiz-
In ACL, volume 1,
able affective text generation.
pages 634–642.

Emil Julius Gumbel and Julius Lieblein. 1954. Sta-
tistical theory of extreme values and some practical
applications: a series of lectures. US Government
Printing Ofﬁce Washington.

Jiaxian Guo, Sidi Lu, Han Cai, Weinan Zhang, Yong
Yu, and Jun Wang. 2018. Long text generation
via adversarial training with leaked information. In
AAAI.

Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan
Salakhutdinov, and Eric P Xing. 2017. Toward con-
trolled generation of text. In International Confer-
ence on Machine Learning, pages 1587–1596.

Eric Jang, Shixiang Gu, and Ben Poole. 2016. Cat-
egorical reparameterization with gumbel-softmax.
arXiv.

Pei Ke, Jian Guan, Minlie Huang, and Xiaoyan Zhu.
2018. Generating informative responses with con-
trolled sentence function. In ACL, volume 1, pages
1499–1508.

Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao,
and Bill Dolan. 2016a. A diversity-promoting ob-
jective function for neural conversation models. In
NAACL.

Jiwei Li, Michel Galley, Chris Brockett, Georgios P
Spithourakis, Jianfeng Gao, and Bill Dolan. 2016b.
A persona-based neural conversation model. ACL.

Yi Luan, Chris Brockett, Bill Dolan, Jianfeng Gao,
and Michel Galley. 2017. Multi-task learning for
speaker-role adaptation in neural conversation mod-
els. In Proceedings of the Eighth International Joint
Conference on Natural Language Processing (Vol-
ume 1: Long Papers), volume 1, pages 605–614.

Yi Luan, Yangfeng Ji, Hannaneh Hajishirzi, and
Boyang Li. 2016. Multiplicative representations for
unsupervised semantic role induction. In ACL.

Laurens van der Maaten and Geoffrey Hinton. 2008.
Visualizing data using t-sne. Journal of Machine
Learning Research, 9(Nov):2579–2605.

Jeff Mitchell and Mirella Lapata. 2008. Vector-based

models of semantic composition. In ACL.

Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur
Szlam, Douwe Kiela, and Jason Weston. 2018a.
Personalizing dialogue agents: I have a dog, do you
have pets too? arXiv preprint arXiv:1801.07243.

Yizhe Zhang, Michel Galley, Jianfeng Gao, Zhe Gan,
Xiujun Li, Chris Brockett, and Bill Dolan. 2018b.
Generating informative and diverse conversational
responses via adversarial information maximization.
In NeurIPS.

Yizhe Zhang, Zhe Gan, Kai Fan, Zhi Chen, Ricardo
Henao, Dinghan Shen, and Lawrence Carin. 2017.
Adversarial feature matching for text generation. In
ICML.

Tiancheng Zhao, Kyusong Lee, and Maxine Eskenazi.
2018. Unsupervised discrete sentence representa-
tion learning for interpretable neural dialog gener-
ation. arXiv preprint arXiv:1804.08069.

Hao Zhou, Minlie Huang, Tianyang Zhang, Xiaoyan
Zhu, and Bing Liu. 2018. Emotional chatting ma-
chine: Emotional conversation generation with in-
ternal and external memory. In AAAI.

Andrew Owens and Alexei A Efros. 2018. Audio-
visual scene analysis with self-supervised multisen-
sory features. In ECCV.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic eval-
uation of machine translation. In ACL.

Qiao Qian, Minlie Huang, Haizhou Zhao, Jingfang
Xu, and Xiaoyan Zhu. 2018. Assigning personal-
ity/identity to a chatting machine for coherent con-
versation generation. In IJCAI.

Vasile Rus and Mihai Lintean. 2012. A comparison of
greedy and optimal assessment of natural language
student input using word-to-word similarity metrics.
In Proceedings of the Seventh Workshop on Building
Educational Applications Using NLP.

Harvey Sacks and Emanuel A. Schegloff. 1973. Open-

ing up closings. Semiotica, 8(4):289327.

Iulian V Serban, Alessandro Sordoni, Yoshua Bengio,
Aaron C Courville, and Joelle Pineau. 2016. Hierar-
chical neural network generative models for movie
dialogues. In AAAI.

Iulian Vlad Serban, Alessandro Sordoni, Ryan Lowe,
Laurent Charlin, Joelle Pineau, Aaron Courville, and
Yoshua Bengio. 2017. A hierarchical latent variable
encoder-decoder model for generating dialogues. In
AAAI.

Dinghan Shen, Qinliang Su, Paidamoyo Chapfuwa,
Wenlin Wang, Guoyin Wang, Lawrence Carin, and
Ricardo Henao. 2018. Nash: Toward end-to-end
neural architecture for generative semantic hashing.
In ACL.

Di Wang, Nebojsa Jojic, Chris Brockett, and Eric Ny-
berg. 2017. Steering output style and topic in neural
response generation. In EMNLP, pages 2140–2150.

Sean Welleck, Jason Weston, Arthur Szlam, and
Kyunghyun Cho. 2018. Dialogue natural language
inference. arXiv preprint arXiv:1811.00671.

Ronald J Williams and David Zipser. 1989. A learn-
ing algorithm for continually running fully recurrent
neural networks. Neural computation, 1(2):270–
280.

Yu Wu, Zhoujun Li, Wei Wu, and Ming Zhou. 2018.
Response selection with topic clues for retrieval-
based chatbots. Neurocomputing, 316:251–261.

Chen Xing, Wei Wu, Yu Wu, Jie Liu, Yalou Huang,
Ming Zhou, and Wei-Ying Ma. 2017. Topic aware
In AAAI, volume 17,
neural response generation.
pages 3351–3357.

Lantao Yu, Weinan Zhang, Jun Wang, and Yong Yu.
2017. Seqgan: sequence generative adversarial nets
with policy gradient. In AAAI.

Appendix for Consistent Dialogue Generation with Self-supervised
Feature Learning

A Straight-through LSTM (ST-LSTM)

In the forward calculation, the t-th ST-LSTM unit
takes the previously generated word wt´1, hidden
state Ht´1 and H0 as input, and generates the next
word wt that maximizes the probability pt over the
vocabulary set. That is, the argmax operation is
used. However, in the backward calculation, the
gradient of Bwt{Bpt is calculated as a constant 1{τ
where τ is a temperature parameter. Presumably,
this approach delivers a biased but smooth gradi-
ent signal while maintaining the forward compu-
tation exact.

B Twitter additional results

Figure 5 shows the t-SNE embedding of topic fea-
tures for speakers in different time zones, demon-
strating our self-supervised approach learned rea-
sonable representation to separate different users.
Here we use 2000 testing utterances with speakers
from 4 different time zones (500 for each).

Figure 5: t-SNE embedding of topic features for speak-
ers in different time zones.

Figure 6 shows that

cycl decreases faster
when η is larger, indicating the additional control-
ling loss
cycl can be effectively reduced using
Straight-through training.

L

L

Table 7 shows some additional results on con-

trolling the bit, in addition to Table 3.

C Maluuba results

We provide some generated samples for maluuba
dataset in Table 8. All compared models use ﬁrst
4 turns as seed and generate the remaining 7 turns

Figure 6:

cycl decreases faster when η is larger.

L

Context: A:planning on making a trip to hawaii

B:lol if only people knew what we are really going there for lolol
A:hahaha . you we might get judge a little
B:a little ? probably a lot haha
A:it’s okay. we should totally go together. we can become friends
B:lol i’m not sure. i’m going to vegas instead!
A:haha. i feel you. i just want to get out of all of these.
B:let’s get on our way!!
A:it’s okay. we should totally go together. i will friend you on fb

plain:

electronic
on:

B:lol sounds good. i will use my phone
A:sure. let me add you to my contact
B:i’m going to do that. i will add you too.

Table 7: Examples of bits manipulations. Plain denotes
without manipulation. X on denotes bit X is activated
(set to 1) when generating the response

by taking 4 previous 3 turns as context.

D Human evaluation

Human evaluation was conducted using the form
shown in Figure 7. The two response candidates
were presented in random order to the judges, who
used a Likert scale to indicate their preferences.
To make the questionnaire less abstract to judges,
persona was evaluated in terms of which response
better reﬂected the tone and style of Person A as
observable in the prior turns. The distributions of
judgments for each of the questions are shown in
Tables 9 through 12.

3previous turn use ground truth for ﬁrst 4 and generated

utterances for the rest

Figure 7: Questionnaire used to elicit pairwise judgments from crowdsourced annotators. Candidate responses
were presented in random order.

Source:

Human:

CoCon-TP:

S2S:

Source:

Human:

CoCon-TP:

S2S:

A:hello how may i help you ?
U:hi i want to look up a play
A:what play
U:what time does the secret miracle opening on ?
A:the secret miracle is scheduled for 8 pm on saturday
U:ok book me for tickets
A:ok sure
U:how much is that ?
A:50
U:ok book it now
A:done
A:9:00 PM friday
U:are there any tickets available for saturday there ?
A:yes tickets do have a deal at 8 pm
U:ok book me for tickets
A:ok ticket
U:reserve for 3 seats please
A:okay done
A:it ’s on saturday
U:and what time ?
A:2:00 PM
U:thank you
A:you ’re welcome
U:thanks for the help
A:you ’re welcome
A:hello how may i help you ?
U:i need to learn more about the rules for tag
A:i can certainly help with game rules . what do you want
to learn about the game tag ?
U:how do i pick the ﬁrst person to be ’ it ’
A: the ﬁrst person to ask who is it is considered ’ it ’.
U:hm , that makes sense . how do you know who is the
winner ?
A:you could keep track of times a person has been ’ it ’
U:oh , okay thanks so much
A:can i help you with something else today ?
U:no , that will be all today
A:thanks for taking the time to ask me a question !
A:the game of tag is a person who gets tagged the least .
U:is there a different rule for tag ?
A:yes , i can help you with that . there is a lot of tag
U:okay , what is the best time to play the most ?
A:the winner is the person that gets tagged the least
U:oh , okay , i ’ll play that game . thanks for the tips .
A:you are welcome . i am always here when you need to
learn .
A:the person who asks who is it is declared ’ it ’.
U:okay , thank you
A:you ’re welcome .
U:okay , thanks
A:you ’re welcome !
U:have a good day
A:you too .

Table 8: Generated Responses for maluuba dataset (in
consecutive generation manner)

Distribution of Pairwise Topic Consistency Preferences

Our Method

5

4

3

2

1

Baseline

CoCon-TP
CoCon-TP

12.60% 32.60% 22.30% 24.45%
10.20% 29.85% 23.10% 28.75%

8.05% seq2seq
8.10% persona

CoCon-TP

5.10% 16.40% 26.85% 33.70% 17.95% human

Table 9: Distribution of topical consistency preferences (%) for our model (CoCon-TP) compared with seq2seq
and persona baselines, according to a ﬁve-point Likert scale. A 5 indicates a strong preference for CoCon-TP; a 1
indicates strong preference for the alternative system.

Distribution of Pairwise Persona Preferences

Our Method

5

4

3

2

1

Baseline

CoCon-TP
CoCon-TP

11.30% 29.65% 29.85% 22.50%
8.30% 27.35% 34.10% 23.70%

6.70% seq2seq
6.55% persona

CoCon-TP

4.45% 16.90% 33.35% 30.95% 14.35% human

Table 10: Distribution of persona consistency preferences (%) for our model (CoCon-TP) compared with seq2seq
and persona baselines, according to a ﬁve-point Likert scale. A 5 indicates a strong preference for CoCon-TP; a 1
indicates strong preference for the alternative system.

Distribution of Pairwise Relevance Preferences

Our Method

5

4

3

2

1

Baseline

CoCon-TP
CoCon-TP

13.70% 31.05% 24.15% 22.80%
10.15% 28.60% 25.55% 25.85%

8.30% seq2seq
9.85% persona

CoCon-TP

4.75% 15.70% 28.10% 31.95% 19.50% human

Table 11: Distribution of relevance preferences (%) for our model (CoCon-TP) compared with seq2seq and persona
baselines, according to a ﬁve-point Likert scale. A 5 indicates a strong preference for CoCon-TP; 1 indicates strong
preference for the alternative system.

Distribution of Pairwise Informativeness Preferences

Our Method

5

4

3

2

1

Baseline

CoCon-TP
CoCon-TP

12.85% 29.95% 27.90% 22.60%
10.45% 28.20% 30.20% 23.55%

6.70% seq2seq
7.60% persona

CoCon-TP

4.40% 15.05% 29.80% 32.70% 18.05% human

Table 12: Distribution of informativeness preferences (%) for our model (CoCon-TP) compared with seq2seq
and persona baselines, according to a ﬁve-point Likert scale. A 5 indicates a strong preference for CoCon-TP; 1
indicates strong preference for the alternative system.

