9
1
0
2
 
v
o
N
 
3
 
 
]

G
L
.
s
c
[
 
 
1
v
6
8
8
0
0
.
1
1
9
1
:
v
i
X
r
a

Regularized Adversarial Sampling and Deep Time-aware
Attention for Click-Through Rate Prediction

Yikai Wang1∗

Liang Zhang2∗ Quanyu Dai3
Yang He2 Weipeng Yan2

Yongjun Bao2

Fuchun Sun1∥

Bo Zhang2

1 Department of Computer Science and Technology, Tsinghua University
Beijing National Research Center for Information Science and Technology (BNRist)
2 JD.COM 3 The Hong Kong Polytechnic University
{wangyk17@mails.,fcsun@}tsinghua.edu.cn,csqydai@comp.polyu.edu.hk
{zhangliang16,zhangbo35,landy,Paul.yan,baoyongjun}@jd.com

ABSTRACT
Improving the performance of click-through rate (CTR) prediction
remains one of the core tasks in online advertising systems. With
the rise of deep learning, CTR prediction models with deep net-
works remarkably enhance model capacities. In deep CTR models,
exploiting users’ historical data is essential for learning users’ be-
haviors and interests. As existing CTR prediction works neglect the
importance of the temporal signals when embed users’ historical
clicking records, we propose a time-aware attention model which
explicitly uses absolute temporal signals for expressing the users’
periodic behaviors and relative temporal signals for expressing the
temporal relation between items. Besides, we propose a regularized
adversarial sampling strategy for negative sampling which eases
the classification imbalance of CTR data and can make use of the
strong guidance provided by the observed negative CTR samples.
The adversarial sampling strategy significantly improves the train-
ing efficiency, and can be co-trained with the time-aware attention
model seamlessly. Experiments are conducted on real-world CTR
datasets from both in-station and out-station advertising places.

CCS CONCEPTS
•Information systems → Learning to rank; Recommender
systems; Retrieval effectiveness;

KEYWORDS
CTR Prediction; Time-aware Attention; Adversarial Sampling

ACM Reference Format:
Yikai Wang, Liang Zhang, Quanyu Dai, Fuchun Sun, Bo Zhang, Yang He,
Weipeng Yan, and Yongjun Bao. 2019. Regularized Adversarial Sampling and
Deep Time-aware Attention for Click-Through Rate Prediction. In The 28th
ACM International Conference on Information and Knowledge Management
(CIKM ’19), November 3–7, 2019, Beijing, China. ACM, New York, NY, USA,
10 pages. https://doi.org/10.1145/3357384.3357936

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
CIKM ’19, Beijing, China
© 2019 ACM. 978-1-4503-6976-3/19/11. . . $15.00
DOI: 10.1145/3357384.3357936

1 INTRODUCTION
Online advertising is widely used for delivering promotional prod-
ucts to users, due to its low ads displaying cost, easy customization,
easy deployment, large coverage and fast delivery speed. In online
advertising, cost per click (CPC) is one of the dominant methods, in
which the advertisers pay for each click on their ads. Click-though
rate (CTR) prediction, with the objective to estimate the probability
of users’ clicking behaviors, can directly influence the performance
of both bidding and ranking in CPC advertising systems.

Improving users’ CTR prediction performance in online adver-
tising remains a hot research topic. In the early stage, FM[24] uses
cross terms of user features and item features aiming to capture their
combination relations. Recent years, inspired by the powerful ca-
pability of deep learning, deep CTR models like Deep Crossing[29],
Wide&Deep[7], DeepFM[12] extend early works by replacing the
transformation functions with complex networks, which enhance
the model capacities. In these works, users’ historical behaviors
are integrally converted to low-dimensional embeddings without
exploration of each individual historical item. Thus these models
are limited to represent users’ rich historical behaviors.

To further improve the performance of CTR prediction, a crucial
part is to learn users’ preferences on the basis of their past interac-
tions with items, which are detailedly recorded over time. To do
this, current works mainly use attention-based[3, 19, 25] models
to exploit users’ historical clicking records. DIN[36] and DIEN[35]
capture users’ relative interests by exploiting users’ historical click-
ing items using the attention mechanism.

However, these attention-based models do not explicitly use the
clicking temporal signals of users’ historical data. The temporal
signals, on the one hand, can reflect the users’ periodic behavior
trends. For example, a user is likely to be more active after the
payday of each month, and tends to buy various seasonal clothes in
various months of each year. On the other hand, temporal signals
can express the extent of the influence of each historical item on the
target recommended item. Users’ behaviors present rich changes
with time, as past interests may fade away and new interests may
emerge. In order to take advantage of such temporal information in
users’ historical clicking records, we propose a time-aware attention
model for CTR prediction. The time-aware attention model contains
absolute temporal signals for periodicity representation and relative
temporal signals for temporal relation representation. Comparison

∗Both authors contribute equally to this research.
∥Fuchun Sun (fcsun@tsinghua.edu.cn) is the corresponding author.

results show that in CTR prediction tasks, the proposed time-aware
attention model outperforms the current works by a large margin.
CTR prediction essentially aims to classify between the minority
positive samples and the majority negative samples, and suffers
from a serious data imbalance problem (such as 1:100). Adopting
random sampling or down sampling on the negative samples can
alleviate the classification imbalance to some extent[13]. However,
these sampling strategies may miss informative negative samples,
which are overwhelmed by the huge amounts of the total negatives.
GAN-based[11] sampling, which is a state-of-the-art method in
recommender systems, improves data efficiency by seeking com-
petitive nonpositive samples for each positive sample to promote
adversarial training, where the nonpositive samples stand for ar-
bitrary combinations of users and items that are not positive and
are often non-interactive. IRGAN[27] and AdvIR[22] both apply
adversarial sampling models in the information retrieval area, and
the authors demonstrate several applications containing item rec-
ommendation. [28] describes recommendation-specific adversarial
sampling method in detail and acquires effective performance. A
same weakness of the current adversarial sampling methods in
recommender systems is that, they can only select the nonposi-
tive samples to train against the positive samples, thus these GAN
sampling works are not applicable to CTR prediction tasks where
observed negative samples should be considered.

In CTR prediction tasks, each item is carefully selected and ex-
posed to a user by the advertisement. Whether the exposed item
acquires a click or not, it has already practically interacted with the
user, and thus can provide us with strong user-item information.
Recommended items that fail to be clicked, are treated as items
that the user dislike, and these user-item pairs are labeled as nega-
tive samples. These observed negative samples are more negative
compared with previously mentioned nonpositive samples, and
thus can provide more guidance for pairwise learning. In order to
utilize such guidance, we propose a regularized adversarial sam-
pling model, which contains a distance-based discriminator and a
probability-based generator. We reframe the adversarial sampling
process in view of imbalanced classification and indicate that the
selected negative sample needs to be competitive among all the neg-
atives as well as correlative to the given positive sample. Therefore
in the discriminator, we design a feedback that contains not only
the sample score but also a regularization term. The regularization
is a weighted Euclidean distance between the embeddings of the
positive and negative samples calculated in the discriminator. The
designed feedback will help the generator select proper negative
samples that can promote the adversarial training. The difference
between the adversarial sample structures of the current works
for common recommender systems and ours specifically for CTR
prediction tasks is illustrated in Figure 1.

Our regularized adversarial sampling strategy is specifically de-
signed for CTR prediction, and can be seamlessly integrated with
the proposed time-aware attention model. Besides, we provide a
CTR calibration method to further deal with an over-estimation
issue of the absolute CTR values in the negative sampling process.
The contributions of our works are summarized as follows:

• We propose a time-aware attention model for CTR prediction
tasks, which can represent the usersfi periodic behaviors and

Figure 1: GAN-based sampling structures comparison

the temporal relations between items, by taking absolute and
relative temporal signals into consideration.

• We design a regularized adversarial sampling strategy for
CTR prediction, which can use the strong information of the
observed negative samples. The adversarial sampling model
can be co-trained with the time-aware attention model.
• We conduct experiments on real-world CTR data from both
in-station and out-station advertising places, and acquire com-
parison relative CTR results with recent state-of-the-art works.
We obtain accurate absolute CTR results with the help of CTR
calibration. We also provide an in-depth model exploration
and sensitivity analysis of hyperparameters.

The rest of the paper is organized as follows. We propose the
time-aware attention model in Section 2 and the regularized ad-
versarial sampling strategy in Section 3. We provide experimental
details, comparison results and in-depth analysis in Section 4. We
summarize the related works in Section 5. Finally we conclude our
works in Section 6.

2 TIME-AWARE ATTENTION
2.1 Data Description
Historical user-item interactions are largely recorded and play a
pivotal role in many real-world CTR prediction tasks. In our model,
a single sample is composed of a pair of a user and a target item
(recommended item), where the user’s information is represented
by a series of user’s recent L clicking items, and the target item is
selected and exposed to the user by the advertisement. Each item
has three parts of features, described as follows:

• Raw features embedding, denoted as er , has 50 dimensions
and is obtained by a pre-training process on the displayed
image of the item using Telepath[30]. Telepath acts as a good
feature extractor to our model as it extracts the key features
with deep CNNs[15] by considering relations between the
usersfi historical records and the target item.

• Interaction time, denoted as t, refers to the clicking time for
historical items or the exposing time for the target item, con-
taining an absolute time t a in seconds, a month index tm , a
week index tw , a day index td and an hour index th .

• Category index (cid3), denoted as c, is a single scalar value

representing the category that the item belongs to.

In summary, each sample in our CTR data contains L + 1 items in
, tl , cl ), l =

total, including L historical clicking items with features (er
l
1 · · · L, and a target item with features (er

0 , t0, c0).

Besides, each sample has several auxiliary features that represent

the attributes of the user such as the gender, age, etc.

2.2 Time-aware Embedding Structure
The structure of the sample embedding model is illustrated in Figure
2. The sample embedding (blue block in Figure 2) is a concatenation
of a history embedding, a (target) item embedding and an auxiliary
embedding.

0 , td

0 and th

The structure of the item embedding is a nonlinear mapping to
0 , t0, c0) of the target item. The absolute time t0 is spilt
features (er
into tm
0 as defined in Section 2.1. The four time signals,
0 , tw
as well as the cid3 c0, are five scalars followed by the same network
structure (dark green block in Figure 2) with independent weights.
These scalars are converted to one-hot embeddings and then sent
to a fully-connected layer for dimensional reduction. The five low
dimensional embeddings together with the raw features embedding
0 are concatenated and converted using fully-connected layers to
er
a d-dimensional item embedding, denoted as ei
0. The structure of
the item embedding is formulated as follows:

0 ),Ww O(tw

0 = R (cid:0)Wc O(c0)(cid:1) ,
ec
0 = R (cid:0)concat (cid:0)Wm O(tm
et
0 = F (cid:0)concat (cid:0)er
0 , et
ei
0
where O(·) is a projection of the one-hot embedding; R(·) is a
ReLU function; F (·) is a series of fully-connected layers; W∗ are
0 represent
trainable matrixes for dimensional reduction; ec
the embeddings of the cid3 and the absolute time respectively.

0 ),Wd O(td

0 ),Wh O(th

0 and et

0 )(cid:1)(cid:1) ,

0 , ec

(cid:1)(cid:1) ,

(1)

For L historical items in a sample, we get their corresponding
item embeddings using the same network structure (light green
block in Figure 2) as the embedding structure of the target item.
Denote these item embeddings as ei
∈ Rd , l = 1 · · · L. To capture
l
the sequential information, we apply GRU mechanism[8] to the
historical item embeddings, which is formulated as:

rl
zl

(cid:101)hl

hl

+ Whr hl −1 + br ) ,
+ Whzhl −1 + bz ) ,

= σ (Wer ei
l
= σ (Wezei
l
= tanh (cid:0)Wecei
l
= (1 − zl ) (cid:12) hl −1 + zl (cid:12) (cid:101)hl ,

+ Whc (rl (cid:12) hl −1) + bc

(cid:1) ,

time and the exposing time of the target item. The relative time
, is calculated as:
embedding of the lth historical item, denoted as et
l

[2j] = sin (cid:0)(t0 − tl )/100002j/d (cid:1) ,
[2j + 1] = cos (cid:0)(t0 − tl )/100002j/d (cid:1) ,

et
l
et
l

where 2j and 2j + 1 are the indexes; t0 and tl
are the absolute time in
seconds of the target item and the lth historical item respectively;
the coefficient 10000 is referring to the positional encodings in [26].
of the lth hidden

In the attention module, the weighted factor al

state hl

is formulated as:

ul
al

= (cid:118)(cid:62)tanh(Whhl
= so f tmax(ul ) ,

+ Wiei

0 + Wt et
l

) ,

is an intermediate variable; ei

where ul
of the target item; et
l
Rv×h , Wi , We ∈ Rv×d , (cid:118) ∈ Rv are trainable variables.

0 ∈ Rd is the item embedding
∈ Rd is the relative time embedding; Wh ∈

The history embedding eh of the sample, which is the output of

the attention module, is a linear weighted sum formulated as:

eh =

al hl .

L
(cid:213)

l =1

The auxiliary embedding ea is a nonlinear mapping of the auxil-
iary features described in Section 2.1 using fully-connected layers.
Finally the sample embedding es (blue block in Figure 2) is
a concatenation of the history embedding eh , the (target) item
embedding ei

0 and the auxiliary embedding ea , as follows:

es = concat (cid:0)eh, ei

0, ea (cid:1) .

After a user browsing through a recommended item, the user-
item sample is labeled as positive or negative based on whether
the user clicks the item or not. Given the labels, our model can be
learned by minimizing either a pointwise or a pairwise loss. The
pointwise loss function is a cross-entropy loss calculated as:
Lpoint = (cid:213)
s ∈ T

log σ (cid:0) f (cid:0)es (s)(cid:1)(cid:1) + (cid:213)
s ∈ T(cid:48)

log (cid:0)1 − σ (cid:0) f (cid:0)es (s)(cid:1)(cid:1)(cid:1) ,

(7)

(3)

(4)

(5)

(6)

(2)

where T and T (cid:48) are the sets of the whole positive and the negative
samples respectively; f (·) is a score function that converts the
sample embedding to a scalar score; σ (·) is a sigmoid function.

The pairwise loss function is a marginal hinge loss calculated as:

where σ (·) is a sigmoid function; hl ∈ Rh is the hidden state; rl
is
the reset gate controlling the input of the former hidden state hl −1;
is the update gate controlling the update ratio; W∗∗ and b∗ are
zl
trainable variables.

For exploration of each individual historical item, we apply the
attention mechanism to the hidden states of GRU, by assigning
proper weights to various hidden states. Instead of using the stan-
dard attention, given the speciality of CTR prediction, we provide
the attention model with d-dimensional relative time embeddings.
The relative time, specified in seconds, is an attribute of each his-
torical clicking item representing the interval between its clicking

Lpair = (cid:213)

(cid:2) − f (cid:0)es (s)(cid:1) + f (cid:0)es (s (cid:48))(cid:1) + γ (cid:3)

+ ,

(8)

s ∈ T,s (cid:48) ∈ T(cid:48)

where [·]+ = max(0, ·) is the hinge function, and γ is the margin.
In CTR prediction tasks, the size of the positives |T | is far smaller
than the size of the negatives |T (cid:48)|, and thus both loss functions
suffer from the imbalanced problem. Because of this, usual works
conduct a negative sampling process instead of directly using the
whole negative samples. In the next section, to improve the per-
formance of CTR prediction, we propose a GAN-based negative
sampling strategy which is adaptable for the both loss functions. We
take the pairwise loss for example and provide detailed derivations.

Figure 2: Structure of the time-aware attention model

3 REGULARIZED ADVERSARIAL SAMPLING
In this section we introduce our adversarial negative sampling
model which is specifically designed for CTR prediction. The model
contains a distance-based discriminator and a probability-based
generator. The proposed adversarial sampling model can make use
of the guidance brought by the observed negative samples.

3.1 Sampling Strategy
The sampling model trains a pairwise loss which is similar to Eq.
(8). Specifically, at each step, a positive sample s and a negative
sample s (cid:48) are embedded using a time-aware attention module, and
are both sent to the discriminator D. Networks in the discriminator
convert the sample embeddings into scores, denoted as fD (es
(s))
D
(s (cid:48))) respectively. Then the optimizer in the discrimina-
and fD (es
D
tor updates to increase the gap between the scores. The score fD
measures the attraction of the item to the user. Therefore positive
samples tend to have higher scores than the negatives.

When given a positive sample in each training step, a negative
sample needs to be selected for training the pairwise loss function
in the discriminator. One straightforward way is to uniformly
choose a negative sample from all the negatives, and we call this
method uniform sampling. Instead of using uniform sampling, we
are seeking a better sampling strategy to enhance training efficiency
and thus acquire better CTR prediction performance.

Supposing for a given positive sample s, a negative sample s (cid:48) is
sampled following a distribution conditioned on s. In our adver-
sarial sampling model, We use a generator G to fit this conditional
distribution, denoted as pG (s (cid:48)|s). In the generator, we adopt another
time-aware attention model for each sample to get the sample em-
bedding, denoted as es
. The attention model in the generator shares
G
the same structure with the attention model in the discriminator,
but has independent network weights. The conditional distribution
pG (s (cid:48)|s) is expressed by an explicit union function of es
(s) and
G
(s (cid:48)), which will be analyzed in later part of this section.
es
G

Referring to Eq. (8), the objective of the discriminator can be

formulated as minimizing the following hinge loss function:
LD = (cid:213)

D (s (cid:48))(cid:1) + γ (cid:3)
(cid:0)es

(cid:0)es
D (s)(cid:1) + fD

(cid:2) − fD

+, s (cid:48) ∼ pG (s (cid:48)|s) , (9)

s ∈ T

(s)) and decrease fD (es
D

where T is the set of the positive samples. Minimizing LD tends
(s (cid:48))) to ensure a gap γ .
to increase fD (es
D
In order to design a better sampling strategy pG (s (cid:48)|s), we take
two aspects into consideration. Firstly, at a training step, if the se-
lected negative sample s (cid:48) has a low score, the gap between fD (es
(s))
D
(s (cid:48))) may close to or already larger than γ before any
and fD (es
D
update, which leads to a useless training step. This will cause a low
data efficiency and therefore affect the performance. Secondly, CTR
prediction is a largely imbalanced classification problem. One-sided
selection[4], a typical neighbor-based imbalanced classification ap-
proach, focuses on the boundary negatives and removes redundant
or interferential majorities, achieving a better classification per-
formance. Inspired by this, we consider a negative sample in CTR
data to be redundant regarding to a given positive sample, if the
negative sample locates too far away from the positive sample in
some certain embedding spaces. The optimizer will acquire an
unsatisfactory performance if it pays too much attention on the
redundant negative samples, even though they have high scores.
To sum up, when given a positive sample s, a negative sample s (cid:48)
provided by the generator should have two desirable properties:

• Competitive: s (cid:48) should have a high score, so as to be a strong

impetus when training the discriminator.

• Correlative: Enough similarity needs to be ensured between
the embeddings of s and s (cid:48). We experimentally find that
using Euclidean distances on the embeddings calculated in
the discriminator embedding space works better.

Detailed experimental results in subsection 4.4 compare the indi-
vidual performance of either one of the properties and the overall
performance with a good cooperation of the two properties.

We visualize the influence to be correlative in Figure 3, where the
color shade reflects the score of the sample. A sample with darker
shade in either positive region or negative region is more tend to
be positive in the view of the discriminator. In each sub-figure, a
negative sample with a high score is selected regarding to a given
positive sample. The difference is, the first sampling seeks a tighter
and more effective decision boundary compared with the second,
giving the credit to the correlative negative sampling.

Figure 3: Effect visualization of the correlative sampling

and eh
D

Denote the item and history embedding functions in the dis-
respectively. In order to select a negative
criminator as ei
D
sample s (cid:48) which keeps correlative to the positive sample s. We
use Euclidean distances in the discriminator embedding space as a
penalty p(s, s (cid:48)), formulated as:
(cid:13)
(cid:13)ei

(10)
where λi , λh > 0 are penalty coefficients for the item embedding
penalty and the history embedding penalty respectively.

p(s, s (cid:48)) = λi

D (s (cid:48))(cid:13)
(cid:13)2 ,

D (s) − eh

D (s) − ei

D (s (cid:48))(cid:13)

(cid:13)2 + λh

(cid:13)
(cid:13)eh

The objective of the generator is designed to maximize the ex-
pectation of scores of the selected negative samples with penalties
for correlative restriction. The loss function can be written as:

LG = (cid:213)

s ∈T

E

(cid:124)

(cid:2)fD
s (cid:48)∼pG (s (cid:48) |s)
(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)

D (s (cid:48))(cid:1) − p(s, s (cid:48))(cid:3)
(cid:0)es
(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)
(cid:123)(cid:122)
(cid:125)
denote as JG (s)

.

(11)

A typical technique to calculate the gradient of the function with
expectations is to adopt the idea of policy gradient based reinforce-
ment learning (REINFORCE)[31, 34]. Denote the parameters in the
generator as θG . The gradient of JG (s) is derived as:

∇θG

JG (s) = ∇θG
N
(cid:213)

=

E

s (cid:48)∼pG (s (cid:48) |s)

(cid:2)fD

D (s (cid:48))(cid:1) − p(s, s (cid:48))(cid:3)
(cid:0)es

∇θG pG (s (cid:48)

n |s)(cid:2)fD

(cid:0)es
D (s (cid:48)

n )(cid:1) − p(s, s (cid:48)

n )(cid:3)

n=1
N
(cid:213)

n=1

(cid:39)

1

K

K
(cid:213)

k =1

=

pG (s (cid:48)

n |s)∇θG

log pG (s (cid:48)

n |s)(cid:2) fD

= E

s (cid:48)∼pG (s (cid:48) |s)

(cid:8)∇θG

log pG (s (cid:48)|s)(cid:2) fD

n )(cid:3)

n )(cid:1) − p(s, s (cid:48)

(cid:0)es
D (s (cid:48)
D (s (cid:48))(cid:1) − p(s, s (cid:48))(cid:3) (cid:9)
(cid:0)es

∇θG

log pG (s (cid:48)
k

|s)(cid:2)fD

(cid:0)es
D (s (cid:48)

k

)(cid:1) − p(s, s (cid:48)
k

)(cid:3) . (12)

The approximation in Eq. (12) is based on Monte Carlo method.
To update the generator, at each step, we sample a mini-batch of
positives and K corresponding negative samples for each positive
sample. With the REINFORCE terminology, the term [fD (es
)) −
D

(s (cid:48)
k

p(s, s (cid:48)
)], denoted as r (s (cid:48)
k
k
which takes an action s (cid:48)
k

), acts as the reward for the policy pG (s (cid:48)
k
given the environment state s.

|s)

Based on the above description, we can utilize the strong guid-
ance brought by the observed negatives, by adversarially selecting
the competitive negatives with embedding distance regularizations.
Our GAN-based sampling strategy is specifically designed for
CTR prediction tasks or some of the recommender tasks where
observed negative samples are available. We further unify our
sampling strategy with the previous strategy illustrated in Figure
1, where no observed negatives are available and the nonpositive
samples (randomly user-item combinations which are not positive)
are used to train against the positive samples. In this case, we fix
the user part of each positive sample, and combine the user to an
item that are not interacted with the user to form a negative sample.
With the same user part, the history embedding penalty in Eq. (10)
is zero, thus r (s (cid:48)
) can degenerate to an easier form. Summarizing
k
the both conditions, the reward r (s (cid:48)
k
(s (cid:48)
k
(s (cid:48)
k

)(cid:1) − p(s, s (cid:48)
k
(cid:13)
)(cid:1) − λi
(cid:13)ei
D

) is formulated as:

(cid:40) fD
fD

)(cid:13)
(cid:13)2 without negatives
(13)

with negatives

(s) − ei
D

(cid:0)es
D
(cid:0)es
D

r (s (cid:48)
k

(s (cid:48)
k

) =

)

.

As a common optimization in policy gradient to reduce variance,
we can subtract a baseline b from the reward, where b equals to the
average reward of the mini-batch Tbatch
. The baseline b updates
after each training step by the following equation:

b =

1
|Tbatch |

(cid:213)

s ∈ Tbat ch

1

K

K
(cid:213)

k =1

r (s (cid:48)
k

) .

(14)

Tbatch

With the technique of stochastic optimization, in a mini-batch
, the gradient of loss function LG in the generator is:
K
(cid:213)

(cid:213)

1

log pG (s (cid:48)
k

|s)(cid:2)r (s (cid:48)
k

) − b(cid:3) ,

(15)

∇θG

LG (cid:39)

k=1
where the baseline b is obtained from the previous mini-batch.

s ∈ Tbat ch

The sampling policy pG (s (cid:48)|s) for the negative sample s (cid:48) regard-
ing to a positive sample s, is modeled as a union function of the
generator sample embeddings es
G

K

pG (s (cid:48)|s) = so f tmaxs (cid:48) ∈N eд(s)

(16)

(s (cid:48)):
(s) and es
G
(s (cid:48))(cid:62)es
es
G
G
T (cid:13)
(s (cid:48))(cid:13)
(cid:13)es
(cid:13)2
G

(s)

,

where N eд(s) is the set of candidate negative samples for sample s;
(s (cid:48))(cid:107)2 is to
T is a temperature for sensitivity control; dividing (cid:107)es
G
(s (cid:48)).
eliminate the unfairness brought by the scale of es
G

As the negative samples in practical CTR tasks are noisy, nega-
tive samples with the highest scores are likely to be false negatives,
i.e. neglected positive samples, which will impact the training
performance. To tackle this issue, we generate the set N eд(s) by
uniformly sampling C negative samples as candidates, instead of
the whole negatives, where C is a hyperparameter. Denote the size
of the positives is |T |. For each positive sample s, calculating its
corresponding policy needs O(C) time complexity, and the total pol-
icy calculation expense in an epoch is O(|T | ·C). Such a complexity
can be reduced to O(|T | · log C) with hierarchical softmax[21].

GAN can suffer from the mode collapse issue where the genera-
tor collapses to some certain modes[2]. In our sampling process,

Algorithm 1 Training the adversarial sampling network
Require: positive samples T and negative samples T (cid:48)
Ensure: adversarially trained discriminator

1: Pre-train the discriminator D and the generator G
2: repeat
3:

Sample a mini-batch positive samples Tbatch ∈ T ;
for each positive sample s ∈ Tbatch do

4:

5:

6:

7:

8:

9:

Uniformly select C candidate negative samples from T (cid:48)
In G, sample a negative sample s (cid:48) from the C candidates
according to the policy pG (s (cid:48)|s) in Eq. (16)
In D, optimize LD by a stochastic gradient descent
In D, calculate the score fD (s (cid:48)) and the reward r (s (cid:48)) ac-
cording to Eq. (13)
In G, optimize LG by a stochastic gradient ascent accord-
ing to Eq. (15)

10:
end for
11: until convergence

the generator relies on pG (s (cid:48)|s) to sample the negatives, and the
collapse of pG (s (cid:48)|s) to some certain negatives will overfit on these
negatives. Thus we should balance the exploration process referring
to traveling through the negatives, and the exploitation process re-
ferring to sampling the negatives unfairly regarding to the rewards.
In Eq. (16), the sensitivity of softmax can be adjusted by adjust-
ing the temperature T . A larger T will lead to a lower sampling
sensitivity, which encourages the generator to explore, and a lower
T encourages the generator to exploit. The generator should ex-
plore at the early training to meet more negative samples, while
exploit later to take advantage of the adversarial sampling. Thus
we give a large initial temperature and decay it epoch by epoch
with a decay rate. Sensitivity analysis of T can be seen in Section
4.4.

We experimentally set the parameter K in Eq. (12) to one and
find it sufficient to deliver promising results. The main framework
of our adversarial training algorithm is described in Algorithm 1.

3.2 Output Calibration
The proposed adversarial sampling strategy brings better relative
CTR values which benefit the ranking process in CPC advertising.
But during the negative sampling, the proportion of the positives
and the negatives in the constructed training data will not match the
real data proportion. Such mismatching will lead to an inaccurate
absolute CTR estimates which is bad for the bidding process. In-
spired by the calibration method in [16], we adopt a similar output
calibration by taking into account the real data proportion.

The real CTR of a sample s for training can be expressed as:

CTR(s) = p (cid:0)Y (s) = 1| fD

D (s)(cid:1)(cid:1) ,
(cid:0)es

(17)

where Y (s) = 1 indicates that the sample s is a positive sample.

We apply a sigmoid function on the score fD (es
D

(s)) for [0, 1]
normalization, and denote the normalized score as σ (s). We divide
the region [0, 1] into n equal-sized buckets, where 0 ≤ v1 < v2 <
, · · · , < vn+1 ≤ 1 and n is large enough. Assuming that σ (s) locates
in [vj , vj+1), j = 1, · · · , n, an approximation of CTR(s) is:

CTR(s) (cid:39) p (cid:0)Y (s) = 1|vj ≤ σ (s) < vj+1(cid:1) ,

(18)

Denote the right part of Eq. (18) as p(vj ),

j = 1, · · · , n. An
approximation of p(vj ) is the proportion of the positive training
samples in all training samples, written as:

p(vj ) (cid:39)

# Positive training samples with σ (s) ∈ [vj , vj+1)
# All training samples with σ (s) ∈ [vj , vj+1)
An isotonic regression algorithm should be applied to keep p(vj )
monotonically increasing with j = 1, · · · , n. We experimentally
choose Pool Adjacent Violators Algorithm[17] for regression.

(19)

.

After obtaining the estimates of p(vj ), j = 1, · · · , n. For a single

sample ˆs in the testing data, its CTR is calibrated by:
CTR(ˆs) (cid:39) p (cid:0)Y (ˆs) = 1|vj ≤ σ (ˆs) < vj+1(cid:1)
= αp(vj ) + (1 − α)p(vj+1) ,

(20)

where we suppose σ (ˆs) ∈ [vj , vj+1), and α = vj+1−σ ( ˆs)
vj+1−vj

.

The final calibrated CTR value of the testing data is the average
calibrated CTR of all testing samples. Experimental results of the
output calibration are shown in Section 4.3.

4 EXPERIMENTS
We conduct experiments on three real-world industrial datasets
provided by JD.COM, one of which is from in-station advertising
places (ads are displayed in the JD mobile app) and the other two are
from out-station advertising places (ads are displayed in the third-
party platforms). The datasets we choose have various magnitudes
and CTR values for distinction considerations. A summary of the
datasets is provided in Table 1.

We use AUC (area under the receiver operating characteristic
curve) for performance evaluation. AUC is a commonly-used eval-
uation metric for CTR prediction, which measures the quality of
the order by ranking all the samples with predicted CTR[10].

Referring to [32, 36] , we adopt RelaImpr metric to measure the
relative enhancement of AUC scores over base models. As the AUC
score of a random guess is 0.5, RelaImpr is defined as:

RelaImpr =

(cid:18) AUC of measured model − 0.5
AUC of base model − 0.5

(cid:19)

− 1

× 100% .

(21)

4.1 Baselines
For verifying the time-aware attention model, we select the fol-
lowing base models for comparison, and we uniformly adopt the
regularized adversarial sampling for the sampling process.

• Two-layer GRU[9]: We implement a two-layer GRU network

to represent users’ historical records.

• DIN[36]: DIN adopts an attention-based model (without GRU)
for activating related user behaviors and obtains the relative
interests to a target item.

• GRU Attention: We discard the temporal components of our
time-aware attention model, using a two-layer GRU to model
usersfi sequential behaviors and a regular attention module
for activating inner relations between items.

For verifying the regularized adversarial sampling (rGAN), we
select the following models for comparison, and we uniformly adopt
the time-aware attention model for the embedding process.

• Logistic Regression[20]: Logistic regression is an ordinary
pointwise training method which uses all available samples.

Table 1: Summary of the data structure (Year: 2018)

Dataset

Items

Categories

Date

Training Data
Positives Negatives

CTR

Date

Testing Data
Positives Negatives

In-station-Sep.
Out-station-Jul.
Out-station-May.

1,680,735
3,411,957
3,734,557

3,137
4,574
4,389

Sep.14th
Jul.5th∼Jul.6th
May.6th

126,016
35,262
18,309

8,233,656
2,868,936
1,502,377

1.507% Sep.15th
1.214%
Jul.7th
1.204% May.7th

138,676
17,630
18,780

9,173,364
1,352,200
1,514,364

CTR

1.489%
1.287%
1.220%

• 1:5 Under Sampling[13, 18]: Under sampling is a common
sampling method to balance distributions for CTR prediction.
The ratio 1:5 is a tuned choice that realizes better results
among various under sampling ratio for our datasets.

• User-fixed Sampling[33]: User-fixed sampling is a regular
sampling method for CTR prediction which selects negative
samples that share the same users with the positives. Uniform
sampling is used as a complementary choice if there are not
enough negative samples that meet requirements.

• Uniform Sampling[13]: Uniform sampling, where the neg-
atives are selected uniformly given any positive sample, is a
commonly-used CTR sampling method, and can be seen as a
degradation of our rGAN strategy when T is large or C = 1.
• IRGAN[27]: IRGAN is a state-of-the-art model which ap-
plies adversarial sampling to select non-interactive user-item
samples to train against the positive samples. However, IR-
GAN cannot use the information of the practically observed
negative samples in CTR prediction tasks.

• IRGAN++: We modify IRGAN to sample from the practically
observed negatives. As directly sampling from the negatives
with IRGAN fails to consider the correlation (illustrated in
Figure 3) between samples, we explore some modifications of
the original IRGAN by narrowing down the sampling scope.
We denote the modification with the best result as IRGAN++:
given a positive sample, IRGAN is applied to sample from the
negatives that share the same target item with the positive
sample; and if there are not sufficient negative samples, we
sample from the negatives of which the target items belong
to the same category as the target item of the positive sample.

4.2 Implementation Details
The structural details of the embedding networks illustrated in
Figure 2 are described as follows:

• Item embedding: For an item, we convert its cid3 and four ab-
solute time signals to five one-hot embeddings, each of which
is further sent to a fully-connected layer with tanh activation
function. Every obtained output has eight dimensions, and
is concatenated with the item’s 50-dimensional raw features
embedding obtained by pre-training using Telepath[30]. The
fully-connected network between the concatenation and the
item embedding has three 90-dimensional layers, with ReLU
for the hidden layers and tanh for the output layer.

• History embedding: Each historical record in a sample con-
tains the user’s 10 latest clicking items, and their correspond-
ing item embeddings are obtained using the same structure
described in (4.2). The number 10 is selected by experimental
results. These item embeddings are sent to a two-layer GRU

network with 90 RNN size as inputs. The dimension of the rel-
ative time embedding is 90. We further apply the time-aware
attention module on GRU. The history embedding, which is
the output of the attention, has 90 dimensions.

• Auxiliary embedding: We apply a one-layer fully-connected
network with an eight-dimensional output layer on the auxil-
iary features. The layer uses tanh as the activation function.
In the discriminator, the score net is a linear single-layer fully-

connected network with one-dimensional outputs.

We use Adam[14] for both trainings in discriminator and gener-
ator. Parameters follow α = 0.001, β1 = 0.9, β2 = 0.999, ϵ = 10−8.
The model is trained for 50 epochs, where the first 25 are shown
in results. For each sample batch, we set one step for training either
the discriminator or the generator. We adjust the batch size to keep
30 steps per epoch. The initial learning rate for the discriminator
and the generator are respectively set to 0.02 and 0.01, which both
decay 50% every 10 epochs. K in Eq. (15) is set to one. The margin
of the loss function is 1.0. The penalty coefficients for the item
embedding and the history embedding are 3.0 and 5.0 respectively.
The candidate size C is set to 35 for the In-station-Sep. dataset and
set to 20 for the other two datasets. The initial temperature T is
constantly set to 20.0, with a decay rate 0.98.

4.3 Comparison Results
We tune key hyperparameters individually for each baseline method,
and collect the results in two aspects: comparison of the time-aware
attention with other embedding models, and comparison of the reg-
ularized adversarial sampling with other sampling strategies.

(a) In-station-Sep. dataset

(b) Out-station-Jul. dataset

Figure 4: Performance of various embedding models

Figure 4 illustrates the AUC scores of the time-aware attention
and several embedding baselines for two datasets. For each model,
we plot the corresponding average curves of five results. We adopt
the same regularized adversarial sampling for all the models so as to
observe the effect brought by the time-aware attention individually.

Table 2 shows the average optimal AUC scores of various em-
bedding models for the three datasets. Observe that the proposed
embedding model itself brings 8%∼9% relative AUC improvements.
The comparison between the time-aware attention and GRU atten-
tion proves the effect of the temporal components.

Table 2: Results of various embedding models

Model

in-station-Sep.
AUC

RelaImpr

out-station-Jul.
AUC

RelaImpr

out-station-May.
RelaImpr
AUC

Two-layer GRU
DIN*
GRU Attention

0.7350
0.7509
0.7523
Time-aware Attention 0.7745

-6.33%
0.6271
0.00%
0.6329
0.56%
0.6322
9.41%
0.6439
In each table, * indicates the baseline model for calculating RelaImpr.
rGAN sampling is applied for all models in Table 2.

0.6726
0.6850
0.6892
0.7021

-6.70%
0.00%
2.27%
9.24%

-4.36%
0.00%
-0.53%
8.28%

We conduct experiments to verify the effect of regularized ad-
versarial (rGAN) sampling. For each model, we adopt the same
time-aware attention model for the embedding process, aiming to
observe the individual effect of rGAN sampling. Figure 5 shows six
pairwise training methods, where rGAN sampling model promotes
the training performance with better AUC scores.

(a) In-station-Sep. dataset

(b) Out-station-Jul. dataset

Figure 5: Performance of various sampling models

Table 3 shows the average optimal AUC scores of one pointwise
model and six pairwise sampling models on three datasets. During
the training process, we find that with proper parameter settings,
rGAN stably outperforms the other models. It is worth mention
that the rGAN sampling is not only suitable for our time-aware
attention model, but also can help to improve the AUC scores for
other embedding models, such as the GRU model and DIN.

Table 3: Results of various sampling models

Model

in-station-Sep.
AUC

RelaImpr

out-station-Jul.
AUC

RelaImpr

out-station-May.
RelaImpr
AUC

Logistic Regression

0.7643

0.15%

0.6790

-5.34%

0.6251

-7.81%

1:5 Under Sampling
User-fixed Sampling
Uniform Sampling*

IRGAN Sampling
IRGAN++ Sampling
rGAN Sampling

0.7587
0.7589
0.7639

0.7366
0.7655
0.7745

-1.97%
-1.89%
0.00%

-10.34%
0.61%
4.02%

0.6818
0.6866
0.6891

0.6597
0.6924
0.7021

-3.86%
-1.32%
0.00%

-15.55%
1.75%
6.87%

0.6270
0.6379
0.6357

0.6165
0.6380
0.6439

-6.41%
1.62%
0.00%

-14.15%
1.69%
6.04%

Time-aware attention is applied for all models in Table 3.

As either of the previous results shows the individual effect of
the time-aware attention or the regularized adversarial sampling,
we now provide their overall improvements in Table 4. We make
comparison between our overall model and DIN with uniform
sampling. As shown in the table, our model acquires 11%∼15%
relative improvements of the AUC scores, which is more remarkable
than many state-of-the-art CTR prediction works like [12, 36] in
real-world datasets.

Table 4: Overall results of the proposed work

Model

in-station-Sep.
AUC

RelaImpr

out-station-Jul.
AUC

RelaImpr

out-station-May.
RelaImpr
AUC

DIN+Uniform*
Ours

0.7405
0.7745

0.00%
14.14%

0.6754
0.7021

0.00%
15.22%

0.6296
0.6439

0.00%
11.03%

Experiments above indicate that the proposed models bring
markedly better relative CTR values which will benefit the ranking
process in CPC advertising. Considering the bidding process, we
now follow subsection 3.2 to calibrate the absolute CTR values. For
the In-station-Sep. dataset, Figure 6(a) illustrates the curves of p(vj )
in Eq. (19) with 300 buckets (denote as n) and the corresponding
isotonic regression fitting using PAVA[17]. We add a small slope
ϵ = 0.1 on the isotonic fitting curve to make it strictly increasing.
Figure 6(b) illustrates absolute CTR calibrated results on the testing
data of the In-station-Sep. dataset w.r.t. various bucket numbers.
With 105 buckets, the calibration error drops to as low as 0.19%. We
also verify the performance on the out-station-Jul. and out-station-
May. datasets where the error are 0.20% and 0.22% respectively.
When calibrated CTR values of some certain categories (cid3) are
required, we can directly apply the same calibration procedure
specifically on these certain categories.

(a) p(vj ) and its isotonic fitting

(b) Calibrated results w.r.t. bucket numbers

Figure 6: Performance of the absolute CTR calibration

4.4 In-depth Model Analysis
In this part, we dive into an in-depth model analysis and quan-
tify the benefits of the components that build-up the proposed
regularized adversarial (rGAN) sampling strategy.

In Eq. (13), the reward function of rGAN sampling contains a
score term and a distance penalty term. To show the importance
of the two components, we omit either one of them and conduct
comparison experiments. Figure 7 illustrates that a good coopera-
tion of the score and the penalty will improve the CTR prediction
performance, and the two terms are both indispensable.

Impact of candidate size. The candidate size C in rGAN sam-
pling is an essential hyperparameter. rGAN with a small candidate
size will degenerate into the uniform sampling, and with a large
candidate size will be vulnerable to the false negatives (as analyzed
in Section 3.1). We test the sensitivity of the candidate size using
In-station-Sep. and Out-station-Jul. datasets, and show the average
results in Figure 9. Candidate size has obvious impact on the per-
formance and needs adjusting according to both the data amount
and the noise level.

Impact of initial temperature. As analyzed in Section 3.1,
the temperature T is used to adjust the sensitivity of Eq. (16). We
conduct experiments to observe the results with various initial
temperatures shown in Figure 10.

Results illustrate that the AUC score increases firstly and then
decreases as temperature increases. The two datasets both reach the
best performance when T = 20, which shows that the temperature
has good generalization to datasets.

(a) In-station-Sep. dataset

(b) Out-station-Jul. dataset

Figure 10: Sensitivity analysis of the initial temperature

5 RELATED WORK
We summarize the related works according to the deep CTR pre-
diction models and the adversarial negative sampling methods.

With the rise of deep learning, CTR prediction models have
evolved from shallow to deep, aiming to improve the model capaci-
ties. Typical models like Wide&Deep[7] which combines low-order
logistic regression components and high-order features with neural
networks for better representation of feature interactions. PNN[23]
imposes networks based on inner and outer products for stronger
expression of cross features. DCN[29] introduces a novel cross net-
work which is more efficient in learning feature interactions explic-
itly by apply feature crossing at each layer. These deep CTR works
greatly enhance model capacities, while lack the deeper exploration
of the users’ historical behaviors. With the evolution of the rec-
ommender systems, user-item interactions are detailedly recorded.
DIN[36] activates historical behaviors regarding to the target item
locally with attention mechanism to capture users’ relative interests.
DIEN[35] designs an attention-based interest extractor layer to cap-
ture diverse interests from users’ historical records. However, these
state-of-the-art deep CTR prediction models neglect the importance
of the temporal signals in users’ historical records. Our proposed
time-aware attention model aims to improve the performance of
CTR prediction giving credit to the temporal signals, which reflect
the users’ periodic trends and measure the temporal influence of
each historical item to the target recommended item.

(a) In-station-Sep. dataset

(b) Out-station-Jul. dataset

Figure 7: Performance of various reward structures

according to their scores fD (es
D

We further explore the relation between scores and penalties
during training. For each positive sample s, we rank the selected
C candidate negatives s (cid:48)
(s (cid:48)
j )) and
j
their negative penalties −p(s, s (cid:48)
j ) respectively, where j = 1, · · · , C.
Thus we get two permutations for s both with length C. We apply
Kendall Tau correlation coefficient[1] to measure the similarity
between the permutations, where a higher Tau coefficient indicates
more similarity between the permutations. We average over the
Tau coefficients of the mini-batch positive samples for each training
step. Figure 8 illustrates the Tau coefficient curve in out-station-Jul.
dataset. We also provide Tau curve between the permutation of
score and a random permutation for comparison. The correspond-
ing AUC score curve is together plotted in the figure, which reaches
its maximum where the permutations have high Tau coefficient.

Figure 8: Tau coefficient of scores and negative penalties

We provide the sensitivity analysis of two key hyperparameters
in the regularized adversarial (rGAN) sampling, the candidate size
and the initial temperature. Other parameters follow the default
settings described in Section 4.2.

(a) In-station-Sep. dataset

(b) Out-station-Jul. dataset

Figure 9: Sensitivity analysis of the candidate size

Generative adversarial nets (GANs), which are originally pro-
posed to fit continuous data distributions[11], have been recently
used for negative sampling in discrete data to promote the training
efficiency. IRGAN[27] unifies generative and discriminative models
of information retrieval into a discrete GAN framework. AdvIR[22]
expands IRGAN by adding additional generated adversarial ex-
amples for joint training. [5] learns by contrasting observed and
fictitious samples with an adversarially learned sampler. KBGAN[6]
designs an adversarial framework with dual KGE components for
improving knowledge graph embedding models. [28] further ex-
tends the idea to recommender systems, and proposes an adaptive
adversarial negative sampling scheme to generate negative samples
for each user, where the item in each negative sample is selected
from all items not interacted with the user. A common point of these
works is that, each negative sample is a combination of two compo-
nents with few interactions. In many application domains such as
CTR prediction tasks, however, observed negative interactions are
available as well, which provide stronger negative guidance than
nonpositive user-item combinations. Our regularized adversarial
sampling is designed for CTR prediction tasks and unlike these
common adversarial sampling strategies, it can make use of the
strong information of the observed negative samples.

6 CONCLUSION
In this paper, we focus on designing a temporal embedding model
and an adversarial sampling strategy that can promote the per-
formance of CTR prediction tasks. The proposed attention-based
model is capable to represent the users’ periodic behaviors and the
temporal relations between historical items and target items, by
considering absolute and relative temporal signals. In addition, the
proposed regularized adversarial negative sampling is able to make
use of the stronger guidance provided by the negative CTR samples,
which is different from existing adversarial sampling methods in
recommender systems. And the idea of regularization in adversarial
sampling can be potentially extend to other fields. We test our mod-
els in three real-world CTR datasets. Comparison results show that
the collaboration of the time-aware attention and the regularized
adversarial sampling strategy outperforms the state-of-the-art CTR
prediction models.

ACKNOWLEDGMENTS
This work is supported by the National Natural Science Foundation
of China under Grants 61621136008 and 91848206.

REFERENCES
[1] H. Abdi. 2007. Kendall Rank Correlation. In Encyclopedia of Measurement and

[2] Mart´ın Arjovsky, Soumith Chintala, and L´eon Bottou. 2017. Wasserstein GAN.

Statistics.

In ICML. 214–223.

[3] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural Machine

Translation by Jointly Learning to Align and Translate. In ICLR.

[4] Gustavo E. A. P. A. Batista, Andr´e Carlos Ponce Leon Ferreira de Carvalho, and
Maria Carolina Monard. 2000. Applying One-Sided Selection to Unbalanced
Datasets. In MICAI. 315–325.

[5] Avishek Joey Bose, Huan Ling, and Yanshuai Cao. 2018. Adversarial Contrastive

Estimation. In ACL. 1021–1032.

[6] Liwei Cai and William Yang Wang. 2018. KBGAN: Adversarial Learning for

Knowledge Graph Embeddings. In NAACL-HLT. 1470–1480.

[7] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra,
Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, Rohan

Anil, Zakaria Haque, Lichan Hong, Vihan Jain, Xiaobing Liu, and Hemal Shah.
2016. Wide & Deep Learning for Recommender Systems. In DLRS. 7–10.
[8] Kyunghyun Cho, Bart van Merrienboer, C¸aglar G¨ulc¸ehre, Dzmitry Bahdanau,
Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning Phrase
Representations using RNN Encoder-Decoder for Statistical Machine Translation.
In EMNLP. 1724–1734.

[9] Tim Donkers, Benedikt Loepp, and J¨urgen Ziegler. 2017. Sequential User-based

[11]

Recurrent Neural Network Recommendations. In RecSys. 152–160.

[10] Tom Fawcett. 2006. An introduction to ROC analysis. Pattern Recognition Letters

27, 8 (2006), 861–874.
Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-
Farley, Sherjil Ozair, Aaron C. Courville, and Yoshua Bengio. 2014. Generative
Adversarial Nets. In NIPS. 2672–2680.

[12] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017.
DeepFM: A Factorization-Machine based Neural Network for CTR Prediction. In
IJCAI. 1725–1731.

[13] Xinran He, Junfeng Pan, Ou Jin, Tianbing Xu, Bo Liu, Tao Xu, Yanxin Shi, Antoine
Atallah, Ralf Herbrich, Stuart Bowers, and Joaquin Qui ˜nonero Candela. 2014.
Practical Lessons from Predicting Clicks on Ads at Facebook. In ADKDD. 5:1–5:9.
[14] Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic

Optimization. In ICLR.

[15] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. 2012. ImageNet Classi-
fication with Deep Convolutional Neural Networks. In NIPS. 1106–1114.
[16] Kuang-chih Lee, Burkay Orten, Ali Dasdan, and Wentong Li. 2012. Estimating
Conversion Rate in Display Advertising from Past Performance Data. In SIGKDD.
768–776.
Jan De Leeuw, Hornik Kurt, and Mair Patrick. 2009. Isotone Optimization in R:
Pool-Adjacent-Violators Algorithm (PAVA) and Active Set Methods. Journal of
Statistical Software 32, 5 (2009), 1–24.

[18] Xu-Ying Liu, Jianxin Wu, and Zhi-Hua Zhou. 2006. Exploratory Under-Sampling

[17]

for Class-Imbalance Learning. In ICDM. 965–969.

[19] Thang Luong, Hieu Pham, and Christopher D. Manning. 2015. Effective Ap-
proaches to Attention-based Neural Machine Translation. In EMNLP. 1412–1421.
[20] H. Brendan McMahan, Gary Holt, David Sculley, Michael Young, Dietmar Ebner,
Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, Sharat
Chikkerur, Dan Liu, Martin Wattenberg, Arnar Mar Hrafnkelsson, Tom Boulos,
and Jeremy Kubica. 2013. Ad click prediction: a view from the trenches. In
SIGKDD. 1222–1230.

[21] Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S. Corrado, and Jeffrey Dean.
2013. Distributed Representations of Words and Phrases and their Composition-
ality. In NIPS. 3111–3119.

[22] Dae Hoon Park and Yi Chang. 2019. Adversarial Sampling and Training for

Semi-Supervised Information Retrieval. In WWW. 1443–1453.

[23] Yanru Qu, Han Cai, Kan Ren, Weinan Zhang, Yong Yu, Ying Wen, and Jun Wang.
2016. Product-Based Neural Networks for User Response Prediction. In ICDM.
1149–1154.

[27]

[24] Steffen Rendle. 2010. Factorization Machines. In ICDM. 995–1000.
[25]

Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014. Sequence to Sequence
Learning with Neural Networks. In NIPS. 3104–3112.

[26] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is All
you Need. In NIPS. 6000–6010.
Jun Wang, Lantao Yu, Weinan Zhang, Yu Gong, Yinghui Xu, Benyou Wang, Peng
Zhang, and Dell Zhang. 2017. IRGAN: A Minimax Game for Unifying Generative
and Discriminative Information Retrieval Models. In SIGIR. 515–524.

[28] Qinyong Wang, Hongzhi Yin, Zhiting Hu, Defu Lian, Hao Wang, and Zi Huang.
2018. Neural Memory Streaming Recommender Networks with Adversarial
Training. In SIGKDD. 2467–2475.

[29] Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. 2017. Deep & Cross Network

for Ad Click Predictions. In ADKDD. 12:1–12:7.

[30] Yu Wang, Jixing Xu, Aohan Wu, Mantian Li, Yang He, Jinghe Hu, and Weipeng P.
Yan. 2018. Telepath: Understanding Users from a Human Vision Perspective in
Large-Scale Recommender Systems. In AAAI. 467–474.

[31] Ronald J. Williams. 1992. Simple Statistical Gradient-Following Algorithms for
Connectionist Reinforcement Learning. Machine Learning (1992), 229–256.
[32] Ling Yan, Wu-Jun Li, Gui-Rong Xue, and Dingyi Han. 2014. Coupled Group
Lasso for Web-Scale CTR Prediction in Display Advertising. In ICML. 802–810.
[33] Yan Yan, Wentao Guo, Meng Zhao, Jinghe Hu, and Weipeng P. Yan. 2017. Opti-
mizing Gross Merchandise Volume via DNN-MAB Dynamic Ranking Paradigm.
CoRR abs/1708.03993 (2017). arXiv:1708.03993 http://arxiv.org/abs/1708.03993
[34] Lantao Yu, Weinan Zhang, Jun Wang, and Yong Yu. 2017. SeqGAN: Sequence
Generative Adversarial Nets with Policy Gradient. In AAAI. 2852–2858.
[35] Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Xiaoqiang
Zhu, and Kun Gai. 2019. Deep Interest Evolution Network for Click-Through
Rate Prediction. In AAAI. 5941–5948.

[36] Guorui Zhou, Xiaoqiang Zhu, Chengru Song, Ying Fan, Han Zhu, Xiao Ma,
Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep Interest Network for
Click-Through Rate Prediction. In SIGKDD. 1059–1068.

