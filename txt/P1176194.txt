DR Loss: Improving Object Detection by Distributional Ranking

Qi Qian1 Lei Chen2 Hao Li2 Rong Jin1
Alibaba Group
1Bellevue, WA, 98004, USA
2Hangzhou, China
{qi.qian, fanjiang.cl, lihao.lh, jinrong.jr}@alibaba-inc.com

0
2
0
2
 
r
p
A
 
3
1
 
 
]

V
C
.
s
c
[
 
 
3
v
6
5
1
0
1
.
7
0
9
1
:
v
i
X
r
a

Abstract

Most of object detection algorithms can be categorized
into two classes: two-stage detectors and one-stage detec-
tors. Recently, many efforts have been devoted to one-stage
detectors for the simple yet effective architecture. Differ-
ent from two-stage detectors, one-stage detectors aim to
identify foreground objects from all candidates in a single
stage. This architecture is efﬁcient but can suffer from the
imbalance issue with respect to two aspects: the inter-class
imbalance between the number of candidates from fore-
ground and background classes and the intra-class imbal-
ance in the hardness of background candidates, where only
a few candidates are hard to be identiﬁed. In this work, we
propose a novel distributional ranking (DR) loss to han-
dle the challenge. For each image, we convert the clas-
siﬁcation problem to a ranking problem, which considers
pairs of candidates within the image, to address the inter-
class imbalance problem. Then, we push the distributions of
conﬁdence scores for foreground and background towards
the decision boundary. After that, we optimize the rank of
the expectations of derived distributions in lieu of original
pairs. Our method not only mitigates the intra-class imbal-
ance issue in background candidates but also improves the
efﬁciency for the ranking algorithm. By merely replacing
the focal loss in RetinaNet with the developed DR loss and
applying ResNet-101 as the backbone, mAP of the single-
scale test on COCO can be improved from 39.1% to 41.7%
without bells and whistles, which demonstrates the effec-
tiveness of the proposed loss function. Code is available at
https://github.com/idstcv/DR_loss.

1. Introduction

The performance of object detection has been improved
dramatically with the development of deep neural networks
in the past few years. Most of detection algorithms fall into
two categories: two-stage detectors [4, 12, 13, 16] and one-
stage detectors [3, 15, 17, 19, 22, 26, 30]. For the two-stage

Figure 1. Illustration of the proposed distributional ranking loss.
First, we push the distributions of conﬁdence scores towards the
decision boundary by re-weighting examples. Then, we try to rank
the expectation of the derived distribution of foreground above that
of background by a large margin.

schema, the procedure of the algorithms can be divided
into two parts. In the ﬁrst stage, a region proposal method
ﬁlters most of background candidate bounding boxes and
keeps only a small set of candidates. In the following stage,
these candidates are classiﬁed as speciﬁc foreground classes
or background and the bounding boxes will be further re-
ﬁned by minimizing a regression loss. Two-stage detectors
demonstrate the superior performance on real-world data
sets while the efﬁciency can be an issue in practice, es-
pecially for the devices with limited computing resources,
e.g., smartphones, cameras, etc.

Therefore, one-stage detectors are developed for the ef-
ﬁcient detection. Different from two-stage detectors, one-
stage methods consist of a single phase and have to identify
foreground objects from all candidates directly. The proce-
dure of one-stage detectors is straightforward and efﬁcient.
However, one-stage detectors can suffer from the imbalance
problem that can reside in the following two aspects. First,
the numbers of candidates between classes are imbalanced.
Without a region proposal phase, the number of background
candidates can easily overwhelm that of foreground ones.
Second, the hardness of identiﬁcation for background can-
didates is imbalanced. Most of them can be easily identiﬁed
from foreground objects while only a few of them are hard
to be classiﬁed.

To mitigate the imbalance problem, SSD [19] adopts
hard negative mining in training, which is a popular strat-

egy [25, 28] to keep a small set of background candidates
with the highest loss. By eliminating simple background
candidates, the strategy balances the number of candidates
between classes and the hardness of background simultane-
ously. However, certain information from background can
be lost, and thus the detection performance can degrade as
illustrated in [17]. RetinaNet [17] proposes to keep all back-
ground candidates but assign different weights for the loss
functions of candidates. The weighted cross entropy loss
is referred as focal loss. It makes the algorithm focus on
the hard candidates while reserving the information from
all candidates. This strategy improves the performance of
one-stage detectors signiﬁcantly. Despite the success of fo-
cal loss, it re-weights classiﬁcation losses in a heuristic way
and can be insufﬁcient to address the imbalance problem.
Moreover, focal loss is designed for a single candidate and
is image-independent while object detection aims to iden-
tify objects in a single image. Focal loss lacks the explo-
ration for each image as a whole and the inconsistency can
make the performance suboptimal.

In this work, we propose an image-dependent ranking
loss to handle the imbalance challenge. First, to mitigate
the effect of the inter-class imbalance problem, we convert
the classiﬁcation problem to a ranking problem, which con-
siders ranks of pairs. Since each pair consists of a fore-
ground candidate and a background candidate, it is well bal-
anced. Moreover, considering the intra-class imbalance in
hardness of background candidates, we design the distribu-
tional ranking (DR) loss to rank the distribution of conﬁ-
dence scores for foreground above that for background can-
didates. As illustrated in Fig. 1, we ﬁrst push the original
distributions towards the decision boundary with appropri-
ate constraints. After obtaining the drifted distributions, we
can rank the expectations of distributions in lieu of original
examples to identify foreground from background, which
improves the efﬁciency by reducing the number of pairs
from O(n2) to O(1) in ranking, where n is the number of
candidates in an image. Compared with focal loss, DR loss
is image-dependent and can explore the information within
each image sufﬁciently.

We conduct experiments on COCO [18] to demonstrate
the proposed DR loss. Since the focal loss is designed as the
classiﬁcation loss in RetinaNet, we adopt RetinaNet as the
base detector for a fair comparison. Speciﬁcally, we merely
replace the focal loss with the DR loss while keeping other
components unchanged. With ResNet-101 [13] as the back-
bone, minimizing our loss function can boost the mAP of
RetinaNet from 39.1% to 41.7%, which conﬁrms the effec-
tiveness of the proposed loss.

The rest of this paper is organized as follows. Section
2 reviews the related work in object detection. Section 3
describes the details of the proposed DR loss. Section 4
compares our method to others on COCO detection task.

Finally, Section 5 concludes this work.

2. Related Work

Detection is a fundamental task in computer vision. In
conventional methods, hand crafted features, e.g., HOG [5]
and SIFT [20], are used for detection either with a sliding-
window strategy which holds a dense set of candidates, e.g.,
DPM [7] or with a region proposal method which keeps a
sparse set of candidates, e.g., Selective Search [27]. Re-
cently, deep neural networks have shown the dominating
performance in classiﬁcation tasks [14], and the features
obtained from neural networks are leveraged for detection
tasks.

R-CNN [10] equips the region proposal stage and works
as a two-stage algorithm. It ﬁrst obtains a sparse set of re-
gions by selective search. In the next stage, a deep convolu-
tional neural network is applied to extract features for each
region. Finally, regions are classiﬁed with a conventional
classiﬁer, e.g., SVM. R-CNN improves the performance of
detection by a large margin but the procedure is too slow
for real-world applications. Hence, many variants are de-
veloped to accelerate it [9, 23]. To further improve the ac-
curacy, Mask-RCNN [12] adds a branch for object mask
prediction to boost the performance with the additional in-
formation from multi-task learning. Besides the two-stage
structure, Cascade R-CNN [2] develops a multi-stage strat-
egy to promote the quality of detectors after the region pro-
posal stage in a cascade fashion.

One-stage detectors are developed for efﬁciency [3, 19,
21, 24, 30]. Since there is no region proposal phase to sam-
ple background candidates, one-stage detectors can suffer
from the imbalance issue from both the inter-class imbal-
ance between foreground and background candidates and
intra-class imbalance in the background candidates. To ad-
dress the challenge, SSD [19] adopts hard negative min-
ing, which only keeps a small set of hard background can-
didates for training. Recently, focal loss [17] is proposed
to handle the problem in RetinaNet. Unlike SSD, it keeps
all background candidates but re-weights them such that
the hard examples are assigned with a large weight. Fo-
cal loss improves the performance of one-stage detection
explicitly, but the imbalance problem in detection is still
not sufﬁciently explored. Besides those anchor-based algo-
rithms, anchor-free one-stage detectors [26, 30] have been
developed, where focal loss is also applied for classiﬁca-
tion. The work closest to ours is the AP-loss in [3], where a
ranking loss is designed to optimize the average precision.
However, the loss focuses on the original pairs and is non-
differentiable. A speciﬁc algorithm has to be developed to
minimize the AP-loss. In this work, we develop the DR loss
that ranks the expectations of distributions in lieu of original
pairs. DR loss is differentiable and can be optimized with
stochastic gradient descent (SGD) in the standard training

pipeline. Therefore, our loss can work in a plug and play
manner, which is important for real-world applications.

ten as

The objective of ranking for a single image can be writ-

3. DR Loss

Given a set of candidate bounding boxes from an im-
age, a detector has to identify the foreground objects from
background ones with a classiﬁcation model. Let θ denote
a classiﬁer and it can be learned by optimizing the problem

min
θ

N
(cid:88)

(cid:88)

i

j,k

(cid:96)(pi,j,k)

(1)

where N is the number of total images. In this work, we
employ sigmoid function to predict the probability for each
candidate. pi,j,k is the prediction from θ and indicates the
estimated probability that the j-th candidate in the i-th im-
age is from the k-th class. (cid:96)(·) is the loss function. In most
of detectors, the classiﬁer is learned by minimizing the cross
entropy loss or its variants.

The objective in Eqn. 1 is prevalent but can suffer from
the inter-class imbalance problem. The problem can be
demonstrated by rewriting the original problem as

min
θ

n+
(cid:88)

N
(cid:88)
(

i

j+

n−
(cid:88)

j−

(cid:96)(pi,j+) +

(cid:96)(pi,j− ))

(2)

where j+ and j− denote the positive (i.e., foreground) and
negative (i.e., background) examples (e.g., anchors), re-
spectively. n+ and n− are the corresponding number of
examples. When n− (cid:29) n+, the accumulated loss from
the latter term will dominate. This issue is from the fact
that the losses for positive and negative examples are sepa-
rated and the contribution from positive examples will be
overwhelmed by negative ones. One heuristic to handle
the problem is emphasizing positive examples, which can
change the weights for the corresponding losses.
In this
work, we aim to address the problem in a fundamental way.
For brevity, we will omit the index of image (i.e., i) from
the next subsection.

3.1. Ranking

To mitigate the challenge from the imbalance between
classes, we consider to optimize the rank between positive
and negative examples. Given a pair of positive and nega-
tive examples, an ideal ranking model can rank the positive
example above the negative one with a large margin

∀j+, j− pj+ − pj− ≥ γ

where γ is a non-negative constant. Compared with the
objective in Eqn. 1, the ranking model optimizes the rela-
tionship between individual positive and negative examples,
which is well balanced.

min
θ

n+
(cid:88)

n−
(cid:88)

j+

j−

(cid:96)(pj− − pj+ + γ)

(3)

where the hinge loss is applied as the loss function

(cid:96)hinge(z) = [z]+ =

(cid:26) z
0

z > 0
o.w.

The objective can be interpreted by the equivalent form

1
n+n−

n+
(cid:88)

n−
(cid:88)

j+

j−

(cid:96)(pj− − pj+ + γ)

= Ej+,j− [(cid:96)(pj− − pj+ + γ)]

(4)

It demonstrates that the objective measures the expectation
of the ranking loss on a randomly sampled pair.

The ranking loss addresses the inter-class imbalance is-
sue by comparing the rank of each positive example to neg-
ative examples. However, it ignores a phenomenon in ob-
ject detection, where the hardness of negative examples is
also imbalanced. Besides, the ranking loss introduces a new
challenge, that is, the vast number of pairs. We tackle them
in the following subsection.

3.2. Distributional Ranking

As indicated in Eqn. 4, the ranking loss in Eqn. 3 pun-
ishes a mis-ranking for a uniformly sampled pair. In detec-
tion, most of negative examples can be easily ranked well,
that is, a randomly sampled pair will not incur the ranking
loss with high probability. Therefore, we consider to opti-
mize the ranking boundary to avoid the trivial solution

min
θ

(cid:96)(max
j−

{pj− } − min
j+

{pj+} + γ)

(5)

If we can rank the positive example with the lowest score
above the negative one with the highest conﬁdence, the
whole set of examples in an image are perfectly ranked. The
pair in Eqn. 5 is referred as the worst-case scenario, which
will incur the largest loss among all pairs. Compared with
the conventional ranking loss, optimizing the loss from the
worst-case scenario is much more efﬁcient, which reduces
the number of pairs from n+n− to 1. Moreover, it clearly
eliminates the inter-class imbalance issue since only a sin-
gle pair of positive and negative examples is required for
each image. However, this formulation is very sensitive to
the selected pair, which can result in the degraded detection
model.

To improve the robustness, we ﬁrst introduce the distri-
bution of conﬁdence scores for the positive and negative ex-
amples and obtain the expectation as

P+ =

qj+pj+; P− =

qj− pj−

n+
(cid:88)

j+

n−
(cid:88)

j−

where q+ ∈ ∆ and q− ∈ ∆ denote the distributions
over positive and negative examples, respectively. P+ and
P− represent the expected scores under the corresponding
distribution. ∆ is the simplex as ∆ = {q : (cid:80)
j qj =
1, ∀j, qj ≥ 0}. When q+ and q− are the uniform distri-
bution, P+ and P− demonstrate the expectation from the
original distribution.

With these deﬁnitions, the distribution corresponding to

the worst-case scenario can be derived as

We observe that the former term is linear in q−. Hence,
if Ω(·) is convex in q−, the problem can be solved efﬁ-
ciently by ﬁrst order algorithms [1]. In this work, we adopt
KL-divergence as the regularizer and have the closed-form
solution as follows

Proposition 1. For the problem

max
q−∈∆

(cid:88)

j−

qj− pj− − λ−KL(q− ||o−)

P+ = min
q+∈∆

qj+pj+; P− = max
q−∈∆

qj−pj−

we have the closed-form solution as

n+
(cid:88)

j+

n−
(cid:88)

j−

We can rewrite the problem in Eqn. 5 in the equivalent form

min
θ

(cid:96)(P− − P+ + γ)

which can be considered as ranking the distributions be-
tween positive and negative examples in the worst-case sce-
nario.

By investigating the new formulation, it is obvious that
optimizing the worst-case scenario is not robust due to the
fact that the domain of the generated distribution is uncon-
strained. Consequently, it will concentrate on a single ex-
ample while ignoring the inﬂuence of the original distribu-
tion that contains massive information. Hence, we improve
the robustness of the loss by regularizing the freedom of the
derived distribution

P− =

max
q−∈∆,Ω(q−||o−)≤(cid:15)−

qj− pj−

−P+ =

max
q+∈∆,Ω(q+||o+)≤(cid:15)+

qj+(−pj+)

where o+, o− denote the original distributions for positive
and negative examples, respectively. Ω(·) is a regularizer
for the diversity of the distribution to prevent the distribu-
tion from the trivial one-hot solution. It measures the sim-
ilarity between the generated distribution and the original
distribution, and some popular similarity function can be
applied, e.g., Lp distance, R´enyi entropy, Shannon entropy,
etc. (cid:15)− and (cid:15)+ are constants to control the freedom of de-
rived distributions.

To obtain the constrained distribution, we consider the

subproblem

n−
(cid:88)

j−
n+
(cid:88)

j+

(cid:88)

qj− pj−

max
q−∈∆

j−
Ω(q−||o−) ≤ (cid:15)−

s.t.

According to the dual theory [1], given (cid:15)−, we can ﬁnd the
parameter λ− to obtain the optimal q− by solving the prob-
lem

max
q−∈∆

(cid:88)

j−

qj− pj− − λ−Ω(q−||o−)

qj− =

oj− exp(

); Z− =

oj− exp(

1
Z−

pj−
λ−

pj−
λ−

)

(cid:88)

j−

Proof. It can be proved directly from K.K.T. condition [1].

For the distribution over positive examples, we have the

similar result as

Proposition 2. For the problem

max
q+∈∆

(cid:88)

j+

qj+(−pj+) − λ+KL(q+||o+)

we have the closed-form solution as

qj+ =

oj+ exp(

); Z+ =

oj+ exp(

1
Z+

−pj+
λ+

−pj+
λ+

)

(cid:88)

j+

Remark 1 These Propositions show that the harder the
example, the larger the weight of the example. Besides,
the weight is image-dependent and will be affected by other
examples in the same image.

The original distributions (i.e., o− and o+) can also in-
ﬂuence the derived distributions by weighting each candi-
date. Therefore, the prior knowledge about the problem can
be encoded into the original distributions, which makes gen-
erating new distributions more ﬂexible. Here we take o− as
an example to illustrate different distributions.

• Uniform distribution: It means that ∀j, oj− = 1/n−.
the closed-form solution
pj−
); Z− =
λ−

With the constant value,
can be simpliﬁed as qj− = 1
Z−
(cid:80)
)

exp(

exp(

j−

pj−
λ−

• Hard negative mining:

In this scenario, we assume
∀j, oj− ∈ {0, 1/ˆn−}, where ˆn− denotes the number
of non-zero elements in o−. According to Proposi-
tion 1, only candidates selected by o− will be accu-
mulated to derive the new distribution. Therefore, our
formulation can incorporate with hard negative mining
by setting the weights in o− appropriately.

To keep the loss function simple, we adopt the uniform
distribution in this work. Fig. 2 illustrates the changing of
the distribution with the proposed strategy. The derived dis-
tribution approaches the distribution corresponding to the
worst-case scenario when decreasing λ. Note that the orig-
inal distributions in Fig. 2 (a) and Fig. 2 (b) have the same
mean but different variance. For the distribution with the
small variance as in Fig. 2 (a), we can observe that the reg-
ularizer λ should be small to change the distribution effec-
tively. When the distribution has the large variance, Fig. 2
(b) shows that a large λ is sufﬁcient to change the shape
of the distribution dramatically. Considering that the dis-
tributions of positive and negative examples have different
variances, Fig. 2 implies that different weights for the regu-
larizers should be assigned.

(a) Small Variance

(b) Large Variance

Figure 2. Illustration of the drifting in the distribution. We ran-
domly sample 1e7 points from a Gaussian distribution with differ-
ent variances to mimic scores of anchors. We change the weights
of examples according to the proposed strategy as in Proposition 1
and then plot the curves of different probability density functions
(PDF) when varying λ.

With the closed-form solutions of distributions, the ex-

pectation of distributions can be computed as

ˆP− =

qj− pj− =

exp(

)pj−

(6)

pj−
λ−

ˆP+ =

qj+pj+ =

exp(

−pj+
λ+

)pj+

n−
(cid:88)

j−
n+
(cid:88)

j+

1
Z−

1
Z+

n−
(cid:88)

j−
n−
(cid:88)

j−

Finally, smoothness is crucial for the convergence of
non-convex optimization [8]. So we apply the smooth ap-
proximation instead of the original hinge loss as the loss
function for pairs. The popular substitutes to the hinge loss
include quadratic loss and logistic loss

(cid:96)quad(z) =






z
(z+ρ)2
4ρ
0

z ≥ ρ
−ρ < z < ρ
z ≤ −ρ

(cid:96)logistic(z) =

log(1 + exp(Lz))

1
L

(7)

(8)

where ρ and L control the approximation error of the func-
tion. The larger the L is , the closer to the hinge loss the

approximation is. ρ works in an opposite direction. Fig. 3
compares the hinge loss to its smooth variants. Explicitly,
these functions share the similar shape and we adopt the lo-
gistic loss in this work.

(a) Quadratic Loss

(b) Logistic Loss

Figure 3. Illustration of the hinge loss and its smooth variants.

Incorporating all of these components, our distributional

ranking loss can be deﬁned as

min
θ

LDR(θ) =

N
(cid:88)

i

(cid:96)logistic( ˆPi,− − ˆPi,+ + γ)

(9)

where ˆPi,− and ˆPi,+ are given in Eqn. 6 and (cid:96)logistic(·) is in
Eqn. 8. If there is no positive examples in an image, we will
let ˆPi,+ = 1. Compared with the conventional ranking loss,
we rank the expectations of two distributions. It shrinks the
number of pairs to 1 that leads to the efﬁcient optimization.
The gradient of the objective in Eqn. 9 is easy to com-
pute. The detailed calculation of the gradient can be found
in the appendix.

If optimizing the DR loss by the standard SGD with
mini-batch as θt+1 = θt − η 1
t , we can show
m
that it can converge as in the following theorem. The norm
of the gradient is applied to measure the convergence, which
is a standard criterion for non-convex optimization [8]. The
detailed proof is cast to the appendix.

s=1 ∇(cid:96)s

(cid:80)m

Theorem 1. Let θt denote the model obtained from the
t-th iteration with SGD optimizer and the size of mini-
batch is m. If we assume the objective L in Eqn. 9 is µ-
smoothness and the variance of the gradient is bounded as
∀s, (cid:107)∇(cid:96)s
t − ∇Lt(cid:107)F ≤ δ, when setting the learning rate as
2mL(θ0)
µT
δ

µ , we have

and η ≤ 1

η =

√

√

1
T

(cid:88)

t

(cid:107)∇L(θt)(cid:107)2

F ≤

√

2δ

2µ

(cid:112)mT L(θ0)

Remark 2 Theorem 1 implies that the learning rate de-
pends on the mini-batch size and the number of iterations as
η = O((cid:112)m/T ) and the convergence rate is O(1/
mT ),
where mT /N is the number of training epochs.

√

We can obtain a scaling strategy for the learning rate. Let
η0, m0 and T0 denote a default conﬁguration for training.
If we change the mini-batch size as m(cid:48) = m0/α, where

α is a non-negative constant, and keep the same number
of epochs for training (i.e., T (cid:48) = αT0), the convergence
rate remains the same. However, the learning rate becomes
η(cid:48) = O((cid:112)m(cid:48)/T (cid:48)) = η0/α.
It shows that to obtain the
same performance with a different mini-batch size, we have
to rescale the learning rate with a corresponding factor,
which is consistent with the observation in [11]. Besides,
the learning rate should be no larger than 1/µ, which means
that the scaling strategy is inapplicable when the mini-batch
size is too large.

3.3. Recover Classiﬁcation from Ranking

Detection is to identify foreground objects from back-
ground. Therefore, the results from ranking have to be con-
verted to classiﬁcation. A straightforward way is to set a
threshold for all ranking scores. However, the range of rank-
ing scores from different images can vary due to the image-
dependent mechanism, and should be calibrated for classi-
ﬁcation. We investigate the bound for the ranking scores of
positive and negative examples as follows.

Theorem 2. When optimizing the ranking problem as

∀j+, j−,

pj+ − pj− ≥ γ

it implies

∀j+,

pj+ > γ;

∀j−,

pj− ≤ 1 − γ

Therefore, we can recover the standard classiﬁcation cri-

terion by setting a large margin.

Corollary 1. If setting the margin of ranking as γ = 0.5, we
can recover the classiﬁcation criterion for ranking scores

∀j+,

pj+ > 0.5;

∀j−,

pj− ≤ 0.5

With these appropriate settings, our ﬁnal objective for

detection can be summarized as

min

τ (cid:96)i

DR + (cid:96)i

Reg

N
(cid:88)

i

where (cid:96)Reg is the original regression loss in RetinaNet and
we keep it unchanged. τ is the parameter for balancing the
weights between classiﬁcation and regression. We ﬁx it as
τ = 4 in the experiments.

4. Experiments

4.1. Implementation Details

RetinaNet [17] as the backbone and only substitute the cor-
responding focal loss. For a fair comparison, we implement
our algorithm in a public codebase 1. Besides, we train the
model with the same conﬁguration as RetinaNet. Speciﬁ-
cally, the model is learned with SGD on 8 GPUs and the
mini-batch size is set as 16 where each GPU can hold 2 im-
ages at each iteration. Most of experiments are trained with
90k iterations that is denoted as “1×”. The initial learn-
ing rate is 0.01 and is decayed by a factor of 10 after 60k
iterations and then 80k iterations. For anchor density, we
apply the same setting as in [17], where each location has 3
scales and 3 aspect ratios. The standard COCO evaluation
criterion is used to compare the performance of different
methods.

4.2. Parameters in DR Loss

From the deﬁnition in Eqn. 9, DR loss has three param-
eters λ+, λ− and L to be tuned. λ+ and λ− regularize the
distribution of scores for positive and negative examples,
respectively. L controls the smoothness of the loss func-
tion. The margin γ is ﬁxed as 0.5 according to Corollary 1.
Compared with the focal loss [17], DR loss has one more
parameter. However, RetinaNet lacks optimizing the rela-
tionship between positive and negative distributions, and it
has an additional parameter to initialize the output proba-
bility of the classiﬁer (i.e., 0.01) to ﬁt the distribution of
background. In contrast, we initialize the probability of the
sigmoid function at 0.5, which is the default threshold for
binary classiﬁcation scenario without any prior knowledge.
It veriﬁes that the proposed DR loss can handle the imbal-
ance problem better. Consequently, DR loss roughly has the
same number of parameters as that in focal loss.

We will have the ablation study on these parameters to
illustrate the inﬂuence in the next subsections. Note that
RetinaNet applies Feature Pyramid Network (FPN) [16] to
obtain multiple scale features. To compute DR loss in one
image, we collect anchors from multiple pyramid levels and
obtain a single distribution for positive and negative an-
chors, respectively.

4.3. Effect of Parameters

We conduct ablation experiments to evaluate the effect of
multiple parameters on the minival set. All experiments in
this subsection are implemented with a single image scale
of 800 for training and test. ResNet-50 [13] is applied as
the backbone for comparison. Only horizontal ﬂipping is
adopted as the data augmentation in this subsection.

We evaluate the proposed DR loss on COCO data
set [18], which contains about 118k images for training, 5k
images for validation, and 40k images for test. To focus on
the comparison of loss functions, we employ the structure of

Effect of λ+ and λ−: First, we evaluate the effect of λ+
and λ− in Eqn. 6. These parameters constrain the free-
dom of the derived distributions. As illustrated in Fig. 2,

1https://github.com/facebookresearch/maskrcnn-benchmark

variances of distributions will have the impact on select-
ing appropriate weights for regularizers. We investigate the
variance of positive and negative anchors, and observe that
the standard deviation of positive anchors is about 10 times
larger than that of negative ones. So we roughly set λ+ = 1
and λ− = 0.1 and ﬁne-tune them as λ+ = 1/ log(h+)
and λ− = 0.1/ log(h−). It is easy to show that this strat-
egy is equivalent to ﬁxing λ+ and λ− as 1 and 0.1, and
changing the base in the deﬁnition of the KL-divergence as
KL(q||o) = (cid:80)

.

j qj logh

qj
oj

We vary h+ and h− and summarize the results in Table 1.
First, we observe that the default setting with λ+ = 1 and
λ− = 0.1 can outperform focal loss by 1% ,which demon-
strates the effectiveness of the proposed DR loss. Second,
the performance of our loss is quite stable in a reasonable
range. Finally, the distribution of positive anchors is more
sensitive to a small λ+, which is consistent with the illus-
tration in Fig. 2. We keep the best settings in the following
experiments.

h+
e
e
e
e
5.5
20

39.4
40.0
40.0
39.4
39.4
38.1

h− AP
37.1
e
37.4
3.5
5.5
37.2
36.6
20
36.7
3.5
3.5
35.6

AP50 AP75 APS APM APL
50.1
19.7
56.1
50.5
20.8
56.0
50.4
19.6
55.7
50.3
19.6
54.7
50.0
19.9
55.2
48.3
19.2
54.2
Table 1. Comparison of λ+ and λ− as in Eqn. 6. Note that
we tune the parameters in the form of λ+ = 1/ log(h+) and
λ− = 0.1/ log(h−). We adopt 1× iterations and ResNet-50 as
the backbone in training. Performance on the minival is reported
for the ablation study.

40.9
41.2
41.2
40.5
40.4
39.7

Effect of Smoothness: L controls the smoothness of the
loss function in Eqn. 8. We compare the model with dif-
ferent L’s in Table 2. We also include the results for the
quadratic loss function in Eqn. 7 with different ρ’s for com-
parison. The original hinge loss is denoted as “Hinge”.
First, all smooth loss functions outperform hinge loss. It
conﬁrms that smoothness is important for non-convex opti-
mization. Second, the smooth variants of hinge loss surpass
focal loss with a signiﬁcant margin. It is because that DR
loss leverages the information from an image rather than
an anchor, which can handle the imbalance issue better.
Since quadratic loss and logistic loss have the similar per-
formance, we adopt the logistic loss with L = 6 in the rest
experiments.

Effect of Pairing Strategy:
In DR loss, we propose to
rank a single pair consisting of expectations from positive
and negative distributions. To evaluate the pairing strategy,
we compare it to different strategies for ranking. Specif-
ically, we denote optimizing all pairs in Eqn. 3 as “All”,

AP
36.1
35.8
36.9
37.2
37.2
37.4
37.1
36.8

Loss
Focal
Hinge
ρ = 0.2
ρ = 0.5
L = 4
L = 6
L = 8
L = 10

AP50 AP75 APS APM APL
49.0
19.5
55.0
47.6
19.3
54.0
49.6
21.1
55.5
50.4
21.1
56.0
50.3
20.3
55.9
50.5
20.8
56.0
50.5
19.5
55.7
50.0
20.0
55.4

38.7
38.3
39.5
39.8
39.9
40.0
39.7
39.4
Table 2. Comparison of different loss functions. ρ and L are from
Eqn. 7 and Eqn. 8, respectively.

39.5
39.5
40.7
41.1
41.0
41.2
41.2
40.7

Pair
All
NegOnly
DR

AP
12.9
37.0
37.4

AP50 AP75 APS APM APL
15.0
8.8
23.0
50.5
19.8
55.5
50.5
20.8
56.0

12.6
39.5
40.0

16.7
40.7
41.2

Table 3. Comparison of different pairing strategies.

which is corresponding to the standard ranking problem.
We also include a variant of DR loss as “NegOnly” that
pushes distributions for negative anchors only. The objec-
tive of NegOnly on a single image can be written as

min
θ

1
n+

(cid:88)

j+

(cid:96)logistic( ˆP− − pj+ + γ)

The result of optimizing the worst-case scenario in Eqn. 5
is not included since training with that fails to obtain the
meaningful result.

The comparison is summarized in Table 3. As illustrated
in Section 3.1, the conventional ranking algorithm suffers
from the intra-class imbalance in the hardness of negative
anchors, which results in the poor performance for detec-
tion. By mitigating this issue with the proposed strategy,
NegOnly can outperform focal loss. It conﬁrms that han-
dling the imbalance in the negative anchors is important and
the proposed strategy can serve the purpose well. Finally,
we observe that a tailored distribution for positive anchors
can further improve the performance as in DR loss.

Effect of DR Loss: To illustrate the effectiveness of DR
loss, we collect the conﬁdence scores of anchors from all
images in minival and compare the empirical probability
density in Fig. 4. We include the results from cross entropy
loss and focal loss in the comparison.

First, we observe that most of examples have an ex-
tremely low conﬁdence after minimizing cross entropy loss.
It is because the number of negative examples overwhelms
that of positive ones and it will classify most of examples to
be negative to obtain a small loss as demonstrated in Eqn. 2.
Second, focal loss is better than cross entropy loss by im-
proving the distribution of positive anchors. However, the
expectation of the foreground distribution is still close to

AP50 AP75 APS APM APL

AP

Backbone

34.9
36.2
37.5
38.2

ResNet-101-C4
ResNet-101-FPN
Aligned-Inception-ResNet
ResNet-101-FPN

Methods
two-stage detectors
Faster R-CNN+++ [13]
Faster R-CNN w FPN [16]
Deformable R-FCN [4]
Mask R-CNN [12]
one-stage detectors
21.6
DarkNet-19
YOLOv2 [22]
31.2
ResNet-101-SSD
SSD513 [19]
37.4
ResNet-101-FPN
AP-Loss [3]
ResNet-101-FPN
39.1
RetinaNet [17]
ResNeXt-32x8d-101-FPN 40.8
RetinaNet [17]
40.5
Hourglass-104
CornerNet [15]
40.9
ResNet-101-FPN
FSAF [30]
ResNet-101-FPN
41.5
FCOS [26]
ResNeXt-32x8d-101-FPN 42.7
FCOS [26]
ResNet-101-FPN
41.7
Dr. Retina
ResNeXt-32x8d-101-FPN 43.1
Dr. Retina
Dr. Retina (multi-scale test) ResNet-101-FPN
43.4
Dr. Retina (multi-scale test) ResNeXt-32x8d-101-FPN 44.7

55.7
59.1
58.0
60.3

44.0
50.4
58.6
59.1
61.1
56.5
61.5
60.7
62.2
60.9
62.8
62.1
63.8

37.4
39.0
40.8
41.7

19.2
33.3
40.5
42.3
44.1
43.1
44.0
45.0
46.1
44.8
46.4
47.0
48.7

15.6
18.2
19.4
20.1

5.0
10.2
17.3
21.8
24.1
19.4
24.0
24.4
26.0
23.5
25.6
26.7
28.2

38.7
39.0
40.1
41.1

22.4
34.5
40.8
42.7
44.2
42.7
44.2
44.8
45.6
44.9
46.2
46.1
47.4

50.9
48.2
52.5
50.2

35.5
49.8
51.9
50.2
51.2
53.9
51.3
51.6
52.6
53.1
54.0
55.0
56.2

Table 4. Comparison with the state-of-the-art methods on COCO test-dev set.

of training iterations to 2×, which contains 180k iterations,
and applies scale jitter in [640, 800] as the additional data
augmentation for training. Note that we still use a single
image scale and a single crop for test as above. Table 4 sum-
marizes the comparison for Dr. Retina. With ResNet-101
as the backbone, we can observe that Dr. Retina improves
mAP from 39.1% to 41.7%. It illustrates that DR loss can
explore the imbalance issue in detection more sufﬁciently
than focal loss. Equipped with ResNeXt-32x8d-101 [29]
and 1.5× iterations (i.e., 135k iterations), the performance
of Dr. Retina can achieve 43.1% as a one-stage detector on
COCO detection task without bells and whistles. Note that
we only replace focal loss with DR loss to obtain the signif-
icant gain, which implies that DR loss can be a good substi-
tute of focal loss. Finally, the multi-scale test with scales
from {400, 500, 600, 700, 800, 900, 1000, 1100, 1200} can
further improve the performance as expected.

5. Conclusion

In this work, we introduce the distributional ranking loss
to address the imbalance challenge in one-stage object de-
tection. We ﬁrst convert the original classiﬁcation problem
to a ranking problem, which balances the positive and neg-
ative classes. After that, we propose to push the original
distributions to the decision boundary and rank the expec-
tations of derived distributions in lieu of original examples
to focus on the hard examples, which balances the hardness
of background examples. Experiments on COCO verify the
effectiveness of the proposed loss function.

(a) Negative Anchors Distribution
Figure 4. Illustration of empirical PDF of distributions that are
computed from images in the minival.

(b) Positive Anchors Distribution

that of background, and it interprets the fact that focal loss
has to initialize the probability of the classiﬁer to be small
(i.e., 0.01). Compared to cross entropy and focal loss, DR
loss improves the foreground distribution signiﬁcantly. By
optimizing our ranking loss with a large margin, the expec-
tation of the positive anchors is larger than 0.5 while that of
background is smaller than 0.1. It conﬁrms that DR loss can
address the imbalance between classes well. Besides, the
hardness of negative anchors with DR loss is more balanced
than that with cross entropy or focal loss. It veriﬁes that
with the image-dependent mechanism, DR loss can handle
the intra-class imbalance in background examples and focus
on the hard negative examples appropriately. More analysis
can be found in the appendix.

4.4. Comparison with State-of-the-Art

We denote RetinaNet with DR loss as “Dr. Retina” and
compare it to the state-of-the-art detectors on COCO test-
dev set. We follow the setting in [17] to increase the number

References

[1] Stephen Boyd and Lieven Vandenberghe. Convex op-

timization. Cambridge university press, 2004.

[2] Zhaowei Cai and Nuno Vasconcelos. Cascade R-
In
CNN: delving into high quality object detection.
CVPR, pages 6154–6162, 2018.

[3] Kean Chen, Jianguo Li, Weiyao Lin, John See, Ji
Wang, Lingyu Duan, Zhibo Chen, Changwei He, and
Junni Zou. Towards accurate one-stage object detec-
tion with ap-loss. In CVPR, pages 5119–5127, 2019.
[4] Jifeng Dai, Haozhi Qi, Yuwen Xiong, Yi Li, Guodong
Zhang, Han Hu, and Yichen Wei. Deformable convo-
lutional networks. In ICCV, pages 764–773, 2017.
[5] Navneet Dalal and Bill Triggs. Histograms of oriented
gradients for human detection. In CVPR, pages 886–
893, 2005.

[6] M. Everingham,

J. Winn,

L. Van Gool, C. K.

and A. Zisserman.

Williams,
PASCAL Visual Object
2007 (VOC2007) Results.
network.org/challenges/VOC/voc2007/workshop/index.html.

I.
The
Challenge
http://www.pascal-

Classes

[7] Pedro F. Felzenszwalb, David A. McAllester, and
Deva Ramanan. A discriminatively trained, multi-
scale, deformable part model. In CVPR, 2008.

[8] Saeed Ghadimi and Guanghui Lan. Stochastic ﬁrst-
and zeroth-order methods for nonconvex stochas-
SIAM Journal on Optimization,
tic programming.
23(4):2341–2368, 2013.

[9] Ross B. Girshick. Fast R-CNN. In ICCV, pages 1440–

1448, 2015.

[10] Ross B. Girshick, Jeff Donahue, Trevor Darrell, and
Jitendra Malik. Rich feature hierarchies for accurate
object detection and semantic segmentation. In CVPR,
pages 580–587, 2014.

[11] Priya Goyal, Piotr Doll´ar, Ross B. Girshick, Pieter No-
ordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew
Tulloch, Yangqing Jia, and Kaiming He. Accurate,
large minibatch SGD: training imagenet in 1 hour.
CoRR, abs/1706.02677, 2017.

[12] Kaiming He, Georgia Gkioxari, Piotr Doll´ar, and
In ICCV, pages

Ross B. Girshick. Mask R-CNN.
2980–2988, 2017.

[13] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian
Sun. Deep residual learning for image recognition. In
CVPR, pages 770–778, 2016.

[14] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hin-
ton. Imagenet classiﬁcation with deep convolutional
neural networks. In NIPS, pages 1106–1114, 2012.

[15] Hei Law and Jia Deng. Cornernet: Detecting objects
as paired keypoints. In ECCV, pages 765–781, 2018.

[16] Tsung-Yi Lin, Piotr Doll´ar, Ross B. Girshick, Kaim-
ing He, Bharath Hariharan, and Serge J. Belongie.
Feature pyramid networks for object detection.
In
CVPR, pages 936–944, 2017.

[17] Tsung-Yi Lin, Priya Goyal, Ross B. Girshick, Kaim-
ing He, and Piotr Doll´ar. Focal loss for dense object
detection. In ICCV, pages 2999–3007, 2017.

[18] Tsung-Yi Lin, Michael Maire, Serge J. Belongie,
James Hays, Pietro Perona, Deva Ramanan, Piotr
Doll´ar, and C. Lawrence Zitnick. Microsoft COCO:
common objects in context. In ECCV, pages 740–755,
2014.

[19] Wei Liu, Dragomir Anguelov, Dumitru Erhan, Chris-
tian Szegedy, Scott E. Reed, Cheng-Yang Fu, and
Alexander C. Berg. SSD: single shot multibox detec-
tor. In ECCV, pages 21–37, 2016.

[20] David G. Lowe. Distinctive image features from scale-
International Journal of Com-

invariant keypoints.
puter Vision, 60(2):91–110, 2004.

[21] Joseph Redmon, Santosh Kumar Divvala, Ross B. Gir-
shick, and Ali Farhadi. You only look once: Uniﬁed,
real-time object detection. In CVPR, pages 779–788,
2016.

[22] Joseph Redmon and Ali Farhadi. YOLO9000: better,
faster, stronger. In CVPR, pages 6517–6525, 2017.
[23] Shaoqing Ren, Kaiming He, Ross B. Girshick, and
Jian Sun. Faster R-CNN: towards real-time object de-
tection with region proposal networks. In NIPS, pages
91–99, 2015.

[24] Pierre Sermanet, David Eigen, Xiang Zhang, Micha¨el
Mathieu, Rob Fergus, and Yann LeCun. Overfeat: In-
tegrated recognition, localization and detection using
convolutional networks. In ICLR, 2014.

[25] Abhinav Shrivastava, Abhinav Gupta, and Ross B.
Girshick. Training region-based object detectors with
In CVPR, pages 761–
online hard example mining.
769, 2016.

[26] Zhi Tian, Chunhua Shen, Hao Chen, and Tong He.
FCOS: Fully convolutional one-stage object detection.
In ICCV, 2019.

[27] Jasper R. R. Uijlings, Koen E. A. van de Sande,
Theo Gevers, and Arnold W. M. Smeulders. Selective
search for object recognition. International Journal of
Computer Vision, 104(2):154–171, 2013.

[28] Paul A. Viola and Michael J. Jones. Rapid object de-
tection using a boosted cascade of simple features. In
CVPR, pages 511–518, 2001.

[29] Saining Xie, Ross B. Girshick, Piotr Doll´ar, Zhuowen
Tu, and Kaiming He. Aggregated residual transfor-
In CVPR, pages
mations for deep neural networks.
5987–5995, 2017.

[30] Chenchen Zhu, Yihui He, and Marios Savvides. Fea-
ture selective anchor-free module for single-shot ob-
ject detection. In CVPR, pages 840–849, 2019.

we have

A. Gradient of DR Loss

We have the DR loss as

min
θ

LDR(θ) =

N
(cid:88)

i

(cid:96)logistic( ˆPi,− − ˆPi,+ + γ)

where

and

(cid:96)logistic(z) =

log(1 + exp(Lz))

1
L

exp(

)pi,j− =

qi,j− pi,j−

then we have

ˆPi,− =

ˆPi,+ =

n−
(cid:88)

j−
n+
(cid:88)

j+

1
Z−

1
Z+

pi,j−
λ−

exp(

−pi,j+
λ+

n−
(cid:88)

j−

n+
(cid:88)

j+

)pi,j+ =

qi,j+pi,j+

It looks complicated but its gradient is easy to compute.

Here we give the detailed gradient. For pi,j− , we have

∂L
∂pi,j−

=

1
1 + exp(−Lz)

∂z
∂pi,j−

=

qi,j−
1 + exp(−Lz)

(1 +

pi,j−
λ−

−

1
λ−

(cid:88)
(

j−

qi,j− pi,j−))

where z = ˆP− − ˆP+ + γ.
For pi,j+, we have

∂L
∂pi,j+

=

1
1 + exp(−Lz)

=

qi,j+
1 + exp(−Lz)

(−1 +

∂z
∂pi,j+
pi,j+
λ+

−

1
λ+

(cid:88)
(

j+

qi,j+pi,j+))

E[L(θt+1)] ≤ E[L(θt) + (cid:104)∇L(θt), θt+1 − θt(cid:105)

= E[L(θt) + (cid:104)∇L(θt), −

+

µ
2

(cid:107)θt+1 − θt(cid:107)2
F ]
m
(cid:88)

η
m

m
(cid:88)

s=1

∇(cid:96)s
t (cid:105)

s=1

∇(cid:96)s

t (cid:107)2
F ]

+

µη2
2

(cid:107)

1
m

According to the deﬁnition, we have

∀s, E[∇(cid:96)s

t ] = ∇L(θt)

If we assume that the variance is bounded as

∀s, (cid:107)∇(cid:96)s

t − ∇Lt(cid:107)F ≤ δ

E[L(θt+1)] ≤ E[L(θt) − η(cid:107)∇Lt(cid:107)2
F
µη2
2

m
(cid:88)

1
m

∇(cid:96)s

+

(cid:107)

t − ∇Lt + ∇Lt(cid:107)2
F ]

≤ E[L(θt) − η(cid:107)∇Lt(cid:107)2

F +

+ (cid:107)∇Lt(cid:107)2

F )

s=1

µη2
2

(

δ2
m

Therefore, we have

(η −

)(cid:107)∇L(θt)(cid:107)2

F ≤ E[L(θt)] − E[L(θt+1)] +

µη2
2

µη2δ2
2m

By assuming η ≤ 1

µ and adding t from 1 to T , we have

(cid:107)∇L(θt)(cid:107)2

F ≤

2L(θ0)
η

+

µηT δ2
m

(cid:88)

t

We ﬁnish the proof by letting

η =

(cid:112)2mL(θ0)
√
µT

δ

B. Proof of Theorem 1

Proof. First, we give the deﬁnition of smoothness

C. Additional Experiments

Deﬁnition 1. A function F is called µ-smoothness w.r.t. a
norm (cid:107) · (cid:107) if there is a constant µ such that for any θ and θ(cid:48),
it holds that

F (θ(cid:48)) ≤ F (θ) + (cid:104)∇F (θ), θ(cid:48) − θ(cid:105) +

(cid:107)θ(cid:48) − θ(cid:107)2

µ
2

We assume that the loss in Eqn. 9 is µ-smoothness, then

Effect of DR Loss: We illustrate the empirical PDF of
foreground and background from DR loss in Fig. 5. Fig. 5
(a) shows the original density of foreground and back-
ground. To make the results more explicit, we decay the
density of background by a factor of 10 and demonstrate
the result in Fig. 5 (b). It is obvious that DR loss can sepa-
rate the foreground and background with a large margin in
the imbalanced scenario.

Focal Loss

DR Loss

Threshold AP
36.1
0.05
36.1
0.1
35.4
0.2
33.9
0.3
31.6
0.4
28.4
0.5

AP50 AP75 APS APM APL AP
37.4
55.0
37.4
54.9
37.4
53.4
37.4
50.2
37.3
45.8
37.2
39.7

AP50 AP75 APS APM APL
50.5
20.8
56.0
50.5
20.8
56.0
50.5
20.8
56.0
50.5
20.8
56.0
50.4
20.7
55.9
50.3
20.1
55.6
Table 5. Comparison of different threshold.

38.7
38.7
38.2
37.0
35.0
31.7

19.5
19.4
18.3
16.2
14.1
10.5

40.0
40.0
40.0
40.0
40.0
39.8

49.0
49.0
48.6
47.6
45.2
42.1

39.5
39.4
38.7
37.1
34.4
30.5

41.2
41.2
41.2
41.2
41.2
41.0

Focal Loss [17]

DR Loss

scale AP
30.5
400
500
32.5
34.3
600
35.1
700
35.7
800

46.1
46.7
47.4
46.4
46.3
Table 6. Comparison of different input scales. We adopt 1× iterations and ResNet-50 as the backbone in training. Results on the test-dev
are reported.

AP50 AP75 APS APM APL AP
32.4
47.8
34.5
50.9
36.1
53.2
37.1
54.2
37.6
55.0

AP50 AP75 APS APM APL
48.0
11.7
49.9
48.9
14.7
52.6
49.2
17.4
54.6
49.2
18.9
55.8
48.9
20.1
56.4

11.2
13.9
16.2
18.0
18.9

34.5
36.6
38.7
39.7
40.3

32.7
34.8
36.9
37.7
38.5

34.8
36.9
38.5
39.8
40.5

33.8
35.8
37.4
39.3
38.9

that the proposed loss function is not sensitive to the scale
of input images.

Comparison on PASCAL: Finally, we evaluate the
proposed DR loss on a different data set: PASCAL
VOC2007 [6], which contains 9, 963 images and 20 classes.
We adopt the same conﬁgurations for RetinaNet as in the
ablation study and the same parameters as those on COCO
for DR loss and focal loss. We change the initial learning
rate to 0.008 and it is decayed at 6, 250 iterations, where the
total number of iterations is 8, 750 as suggested by the code-
base. Other training settings are the same as the pipeline for
COCO. The detector is trained with the training and vali-
dation sets, and Table 7 shows the comparison on the test
data. We can observe that with the same parameters on a
different task, our method can outperform focal loss with a
signiﬁcant margin. It demonstrates that the proposed loss
function can be applicable for different tasks.

Loss
Focal
DR

AP
39.5
41.2

AP50 AP75
40.8
67.2
42.6
68.6

Table 7. Comparison on VOC2007. Results on the test are re-
ported.

(a) Original Density

(b) Decayed Density

Figure 5. Illustration of empirical PDF of distributions from DR
loss.

Effect of Large Margin: Before non-maximum suppres-
sion (NMS), the candidates with low conﬁdence will be ﬁl-
tered to accelerate detection. Since the distribution of fore-
ground from focal loss is close to that of background as
illustrated in Fig. 4, a small threshold as 0.05 is adopted
to eliminate negative examples. The proposed loss func-
tion optimizes the distributions with a large margin and can
be robust to the selection of the threshold. Table 5 demon-
strates the performance with different thresholds. It is obvi-
ous that the performance of DR loss keeps almost the same
while that of focal loss degrades signiﬁcantly when increas-
ing the threshold.

Effect of Image Scale: We tune the parameters of DR
loss with a single input scale of 800 but the parameters are
robust to different input scales. We follow the settings in
the ablation study and Table 6 compares the performance
on test-dev with scales varied in {400, 500, 600, 700, 800}.
Note that the maximal size of images is also changed with
a corresponding factor. We report the results of focal loss
from [17]. Evidently, DR loss can consistently improve the
performance over focal loss by about 2%. It demonstrates

