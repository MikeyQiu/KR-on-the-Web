AdversarialNAS: Adversarial Neural Architecture Search for GANs

Chen Gao1,2,4, Yunpeng Chen4, Si Liu3∗, Zhenxiong Tan5, Shuicheng Yan4
1Institute of Information Engineering, Chinese Academy of Sciences
2University of Chinese Academy of Sciences
3School of Computer Science and Engineering, Beihang University

4Yitu Technology

5Beijing Forestry University

gaochen@iie.ac.cn, liusi@buaa.edu.cn, yunpeng.chen@yitu-inc.com

0
2
0
2
 
r
p
A
 
8
 
 
]

V
C
.
s
c
[
 
 
2
v
7
3
0
2
0
.
2
1
9
1
:
v
i
X
r
a

Abstract

Neural Architecture Search (NAS) that aims to automate
the procedure of architecture design has achieved promis-
ing results in many computer vision ﬁelds. In this paper,
we propose an AdversarialNAS method specially tailored
for Generative Adversarial Networks (GANs) to search for
a superior generative model on the task of unconditional
image generation. The AdversarialNAS is the ﬁrst method
that can search the architectures of generator and discrim-
inator simultaneously in a differentiable manner. Dur-
ing searching, the designed adversarial search algorithm
does not need to comput any extra metric to evaluate the
performance of the searched architecture, and the search
paradigm considers the relevance between the two network
architectures and improves their mutual balance. There-
fore, AdversarialNAS is very efﬁcient and only takes 1 GPU
day to search for a superior generative model in the pro-
posed large search space (1038). Experiments demonstrate
the effectiveness and superiority of our method. The discov-
ered generative model sets a new state-of-the-art FID score
of 10.87 and highly competitive Inception Score of 8.74 on
CIFAR-10. Its transferability is also proven by setting new
state-of-the-art FID score of 26.98 and Inception score of
9.63 on STL-10. Code is at: https://github.com/
chengaopro/AdversarialNAS.

1. Introduction

Image generation is a fundamental task in the ﬁeld of
computer vision. Recently, GANs [13] have attracted much
attention due to their remarkable performance for generat-
ing realistic images. Previous architectures of GANs are
designed by human experts with laborious trial-and-error
testings (Fig. 1 a)) and the instability issue in GAN train-
ing extremely increases the difﬁculty of architecture design.
Therefore, the architecture of the generative model in GAN

∗Corresponding author

Figure 1. Comparisons of different ways of designing GAN archi-
tectures. a) The previous hand-crafted GAN architectures depend
on the experience of human experts. b) AutoGAN [12] adopts
IS or FID as reward to update the architecture controller via rein-
forcement learning. c) The proposed AdversarialNAS searches ar-
chitecture in a differentiable way with an adversarial search mech-
anism, which achieves better performance with higher efﬁciency.

literature has very few types and can be simply divided into
two styles: DCGANs-based [35] and ResNet-based [17].
On the other hand, the beneﬁts of specially designing the
network architecture have been proven through lost of dis-
criminative networks, such as ResNet [17], DenseNet [20],
MobileNet [37], ShufﬂeNet [49], EfﬁcientNet [39], HR-
Net [38] and [6, 10]. Therefore, the research about the back-
bone architecture of GANs needs more attention to further
improve the performance of the generative model.

Recently, Neural Architecture Search (NAS) has been
studied heatedly owing to its ability to automatically dis-
cover the optimal network architecture, which signiﬁcantly
reduces human labor. However, on generation tasks, specif-
ically GANs-based generation, only AutoGAN [12] and

AGAN [41] have explored the application of NAS.

To design a NAS algorithm specially tailored for GANs
on the unconditional image generation task, there are two
main challenges. First, it is expected to utilize an efﬁcient
supervision signal to guide the search process in this unsu-
pervised task. However, the existing works [12, 41] both
adopt the Inception Score (IS) [36] or FID to evaluate the
architecture performance and take IS or FID as a reward to
update the architecture controller via reinforcement learn-
ing strategy. Obtaining IS or FID needs to generate hun-
dreds of images and use the statistics produced by an In-
ception network to calculate the ﬁnal score. Thus it is ex-
tremely time-consuming, e.g. 200 GPUs over 6 days [41].
Second, the relevance and balance between generator and
discriminator need to be considered during searching since
the training process of GANs is a unique competition. How-
ever, AutoGAN search for a generator with a pre-deﬁned
growing discriminator (Fig. 1 b)), where the architecture of
the discriminator can be regarded as ﬁxed and may limit the
algorithm to search for an optimal architecture of generator.
In this work, we propose an Adversarial Neural
Architecture Search (AdversarialNAS) method to address
the above challenges (Fig. 1 c)). First, we design a large
search space (1038) for fragile GAN and relax the search
space to be continuous. Thus the architecture can be
represented by a set of continuous variables obeying cer-
tain probability distribution and searched in a differentiable
manner. Second, we propose to directly utilize the exist-
ing discriminator to evaluate the architecture of generator
in each search iteration. Speciﬁcally, when searching for
the generator architecture, the discriminator provides the
supervision signal to guide the search direction, which is
technically utilized to update the architecture distribution of
generator through gradient descent. Therefore, our method
is much more efﬁcient since the extra computation cost for
calculating evaluation metric is eliminated. Third, in order
to consider the relevance and balance between the generator
and discriminator, we propose to dynamically change the
architecture of discriminator simultaneously during search-
ing. Accordingly, we adopt the generator to evaluate the ar-
chitecture of discriminator and comput the loss to update the
discriminator architecture through ascending the stochas-
tic gradient. The two architectures play against each other
in a competition to continually improve their performance,
which is essentially an adversarial searching mechanism.
Therefore, the AdversarialNAS gets rid of calculating extra
evaluation metric and solves the unsupervised task through
an adversarial mechanism. It adequately considers the mu-
tual balance between the two architectures, which beneﬁts
for searching a superior generative model.

To sum up, our main contributions are three-fold.

• We propose a novel AdversarialNAS method, which is
the ﬁrst gradient-based NAS method in GAN ﬁeld and

achieves state-of-art performance with much higher ef-
ﬁciency. We design a large architecture search space
(1038) for GAN and make it feasible to search in. Our
AdversarialNAS can only tasks 1 GPU day for search-
ing an optimal architecture in the large search space.

• Considering GAN is an unique competition between
two networks,
the proposed AdversarialNAS alter-
nately searches the architecture of both of them under
an adversarial searching strategy to improve their mu-
tual balance, which is speciﬁcally tailored for GAN.

• The searched architecture has more advanced transfer-
ability and scalability while achieving state-of-the-art
performance on both CIFAR-10 and STL-10 datasets.

2. Related Work

2.1. Generative Adversarial Networks

Although Restricted Boltzmann Machines [18] and ﬂow-
based generative models [8] are all capable of generating
natural images, GANs [13] are still the most widely used
methods in recent years due to their impressive generation
ability. GANs based approaches have achieved advanced
results in various generation tasks, such as image-to-image
translation [21, 7, 22, 51], text-to-image translation [46, 48]
and image inpainting [32]. However, the potential of GANs
has not been fully explored since there is rare work [35]
studying the impact of architecture design on the perfor-
mance of GANs. In this work, we aim to search for a power-
ful and effective network structure speciﬁcally for the gen-
erative model via an automatic manner.

2.2. Neural Architecture Search

Automatic Machine Learning (AutoML) has attracted
lots of attention recently, and Neural Architecture Search
(NAS) is one of the most important direction. The goal
of NAS is to automatically search for an effective archi-
tecture that satisﬁes certain demands. The NAS technique
has applied to many computer vision tasks such as image
classiﬁcation [2, 28, 29, 34, 52, 4], dense image predic-
tion [27, 50, 3] and object detection [11, 33].

Early works of NAS adopt heuristic methods such as re-
inforcement learning [52] and evolutionary algorithm [44].
Obtaining an architecture with remarkable performance us-
ing such methods requires huge computational resources,
e.g., 2000 GPUs days [44]. Therefore, lots of works de-
sign various strategies to reduce the expensive costs includ-
ing weight sharing [34], performance prediction [1], pro-
gressive manner [28] and one-shot mechanism [29, 45].
The DARTS [29] in one-shot literature is the ﬁrst approach
that relaxes the search space to be continuous and conducts
searching in a differentiable way. The architecture param-
eters and network weights can be trained simultaneously

in an end-to-end fashion by gradient descent. Thus it ex-
tremely compresses the search time.

However, all of these methods are designed for recog-
nition and supervision tasks. To the best of our knowledge,
there have been limited works [12] exploring applying NAS
to unsupervised or weakly supervised tasks. In this work,
we present the ﬁrst gradient-based NAS method in GAN
ﬁeld and achieve state-of-the-art performance with much
higher efﬁciency in the unsupervised image generation task.

2.3. NAS in GANs

Recently, a few works have attempted to incorporate
neural architecture search with GANs. AutoGAN [12]
adopts the reinforcement learning strategy to discover the
architecture of generative models automatically. However,
it only searches for the generator with a ﬁxed architecture
of discriminator. This mechanism limits the performance
of the searched generator since the stability of GANs train-
ing is highly dependent on the balance between these two
players. Besides, the search space is relatively small (105),
thus its randomly searched architecture can achieve accept-
able results, e.g., FID (lower is better): 21.39 (random) and
12.42 (search) in CIFAR-10 dataset. The AGAN [41] en-
larges the search space speciﬁcally for the generative model,
but the computational cost is expensive (1200 GPUs days)
under the reinforcement learning framework. The perfor-
mance of the discovered model is slightly worse, e.g., FID:
30.5 in CIFAR-10. Moreover, the reward used to update the
weights of the network controller during evaluation stage is
Inception Score, which is not a suitable supervisory single
to guide the architecture search since it is time-consuming.
Instead, we search the architecture in a differentiable
way and discard the evaluation stage. The reward of pre-
vious methods is obtained after a prolonged training and
evaluation process, while our signal (loss) for guiding the
search direction is given instantly in each iteration. Thus
our method is more efﬁcient. The designed adversarial
search algorithm improves the mutual balance of the two
networks for stabling and optimizing the search process.

3. Method

In this section, we ﬁrst introduce the proposed search
space of GANs and the way for relaxing it to be continuous.
Then we describe the AdversarialNAS method.

3.1. Search Space for GANs

The goal of the proposed AdversarialNAS is to automati-
cally search for an superior architecture of generative model
through an adversarial searching mannr. Speciﬁcally, we
aim to search for a series of cells, including Up-Cell and
Down-Cell, as the building blocks to construct the ﬁnal ar-
chitecture of GAN. Three Up-Cells and four Down-Cells

are stacked to form a generator and discriminator respec-
tively. Since the convolution neural network has a natural
hierarchical structure and each layer has unique function,
we search for the cells each with a different architecture.

We represent a cell as a Directed Acyclic Graph (DAG)
consisting of an ordered sequence of N nodes (Fig. 2). The
cell takes image features as input and outputs processed fea-
tures, where each node xi in DAG indicates an intermediate
feature and each edge fi,j between two nodes xi, xj is a
speciﬁc operation. Since we aim to search for an optimal
architecture of generator that is actually an upsampling net-
work, we design a search space for speciﬁc Up-Cell that
is almost fully connected topology, as given in the left of
Fig. 2. The Up-Cell consists of 4 nodes, and each node can
be obtained by its previous nodes through selecting an oper-
ation from a candidate set according to the search algorithm.
The search space of generator FG includes a candidate set
of normal operations, which is designed as below.

• None
• Convolution 1x1, Dilation=1
• Convolution 3x3, Dilation=1
• Convolution 5x5, Dilation=1

• Identity

• Convolution 3x3, Dilation=2
• Convolution 5x5, Dilation=2

The ‘None’ means there is no operation between two cor-
responding nodes, which is used to change the topology of
the cell. The ‘Identity’ denotes the skip connection opera-
tion that provides multi-scale features. The stride of these
operations is 1 so that they will keep the spatial resolution.
The search space of generator also contains a subset of up-
sampling operations, which is devised as below.

• Transposed Convolution 3x3
• Nearest Neighbor Interpolation

• Bilinear Interpolation

Note that, these operations can only be searched by edge
0 → 1 and 0 → 2 in a speciﬁc Up-Cell. To search for the
generator in an adversarial way, we simply invert the Up-
Cell to form a Down-Cell (shown in the right of Fig. 2) en-
suring their balance. The search space of discriminator FD
also contains a candidate set of normal operations, which is
the same as the one of Up-Cell. However, the candidate set
of downsampling operations is achieved by

• Average Pooling
• Convolution 3x3, Dilation=1
• Convolution 5x5, Dilation=1

• Max Pooling
• Convolution 3x3, Dilation=2
• Convolution 5x5, Dilation=2

With stride equaling 2, the downsampling operations can
only be searched in edge 2 → 4 and 3 → 4. Therefore,
during searching, there are totally 1038 different network
architectures for GANs.

3.2. Continuous Relaxation of Architectures

The goal of the search algorithm is to select a speciﬁc
operation from the pre-deﬁned candidate set for each edge.
Therefore, the intermediate node xn,j in the n-th cell can
be calculated through the selected functions and its previ-
ous connected nodes as xn,j = (cid:80)
i<j fn,i,j(xn,i). For RL-

based NAS algorithms, the function fn,i,j is directly sam-
pled from the candidate set according to the learnable ar-
chitecture controller. Inspired by Gradient-based NAS al-
gorithm [29], we relax the function fn,i,j to a soft version
through Gumbel-Max trick [30]:

f sof t
n,i,j (x) =

(cid:88)

exp((pf

n,i,j + of )/τ )

(cid:80)

f ∈FG

f (cid:48)∈FG

exp((pf (cid:48)

n,i,j + of (cid:48))/τ )

f (x),

(1)
where of is the noise sampled from the Gumbel (0,1) dis-
tribution, and the τ is the softmax temperature. The pf
n,i,j
is the probability of selecting a speciﬁc function f in edge
i → j of n-th cell. The Gumbel version softmax is ap-
plied to follow the learned probability distribution more
strictly. Therefore, each edge will contain a probability vec-
tor [pf1, ..., pfm ], m = |FG|. This discrete probability dis-
tribution is calculated through a simple softmax function as
pf =
, where the α is the learnable param-

exp(αf )

(cid:80)

f ∈F

G

exp(αf (cid:48) )

eter. Therefore, the goal of searching for an architecture is
converted to learning an optimal set of probability vectors
for every edge, and the architecture can be derived from
the learned probability distribution. Besides, in order to dy-
namically change the architecture of discriminator simulta-
neously, we also conduct a set of continuous parameters β
for calculating the probability of each function in discrim-
inator as qf =
. Therefore, the soft version

exp(βf (cid:48) )
of the function can be achieved like the generator as

exp(βf )

f ∈F

(cid:80)

D

f sof t
n,i,j (x) =

(cid:88)

exp((qf

n,i,j + of )/τ )

(cid:80)

f ∈FD

f (cid:48)∈FD

exp((qf (cid:48)

n,i,j + of (cid:48))/τ )

f (x).

(2)
Then, the proposed AdversarialNAS aims to learn a set of
continuous parameters α and β in a differentiable manner
and obtain the ﬁnal architecture of generator by simply pre-
serving the most likely operations in the search space. Note
that, we term the networks with all operations softly com-
bined by the architecture parameters as Super-G and Super-
D. The topology of the network would be changed by the
learned high probability ‘None’ operation, and the ‘Iden-
tity’ operation would provide multi-scale fusion.

3.3. Adversarial Architecture Search

Before introducing the optimization strategy of the pro-
posed AdversarialNAS, we ﬁrst brieﬂy revisit the optimiza-
tion function in the classiﬁcation literature. The searching
process is formulated as a bilevel optimization problem:

min
α

Lval(w∗(α), α)

s.t. w∗(α) = arg min

Ltrain(w, α),

w

(3)

where Lval and Ltrain denote the loss function on the vali-
dation and training set respectively. The goal of the search

Figure 2. The search space of Up-cell and Down-Cell. The ar-
chitectures of both Up-Cell and Down-Cell will continuously pro-
mote each other in an adversarial manner.

algorithm is to discover an optimal architecture α∗ by cal-
culating and minimizing the validation loss Lval(w∗, α),
where w∗ is the optimal weights of the current architecture
α and is obtained by calculating and minimizing the train-
ing loss Ltrain(w, α). Both the weight and architecture are
optimized by ascending its gradient descent.

However, in the task of unconditional image generation,
there are no labels to supervise the searching procedure.
AutoGAN [12] and AGAN [41] apply IS to evaluate the
architecture performance and optimize the architecture by
RL strategy. Computing IS requires generating hundreds of
images and adopts Inception model to infer the result of-
ﬂine after a prolonged training trajectory of each discrete
architecture, which is extremely time consuming. There-
fore, we propose to make the architectures of generator and
discriminator compete with each other to improve both of
their performance, i.e., utilizing discriminator to guide the
generator search and vice versa. AdversarialNAS leverages
an adversarial optimization strategy that is inspired by the
formulation of original GANs [13] for optimizing the archi-
tecture in a differentiable way. Thus the optimization pro-
cess is deﬁned as a two-player min-max game with value
function V (α, β) where the weight of each network must
be current optimal. The formulation of the introduced algo-
rithm is given in Eqn.( 4):

V (α, β) = Ex∼pdata(x)[log D(x | β, W ∗

max
β

min
α
+ Ez∼pz(z)[log(1 − D(G(z | α, W ∗

G(α)) | β, W ∗

D(β))]

D(β)))]

s.t.
W ∗

D(β) = arg max
WD(β)
+ Ez∼pz(z)[log(1 − D(G∗
Dβ
W ∗

G(α) = arg min
WG(α)

Ex∼pdata(x)[log D(x | β, WD(β))]

(z) | β, WD(β)))]

Ez∼pz(z)[log(1 − D∗
Gα

(G(α | WG(α)))],

(4)
where pdata means true data distribution and pz is a prior
distribution. In the up-level stage the W ∗
D(β) denotes the

optimal weights of discriminator under the speciﬁc archi-
tecture β and W ∗
G(α) represents the optimal weights of gen-
erator under the architecture α. In the low-level stage, the
two optimal weights {W ∗
G(α), W ∗
D(β)} for any particular
pair of architectures {α, β} can be obtained through another
min-max game between WG and WD:

However,

max
WD(β)

V (WG(α), WD(β)) =

this inner optimization (Eq. 5)

min
WG(α)
Ex∼pdata(x)[log D(x | β, WD(β))]
+ Ez∼pz(z)[log(1 − D(G(z | α, WG(α)) | β, WD(β)))].
(5)
is time-
consuming. For NAS in the classiﬁcation task [29, 9, 5],
the inner optimization (Eq. 3) is normally approximated by
one step training as ∇αLval(w∗(α), α) ≈ ∇αLval(w −
ξ∇wLtrain(w, α), α).
Inspired by this technique, for a
given pair of architectures {α, β}, the corresponding op-
timal weights {W ∗
D(β)} can be obtained by single
step of adversarial training (Eq. 5) as vanilla GANs.

G(α), W ∗

for k step do

Algorithm 1 Minibatch stochastic gradient descent training
of Adversarial Neural Architecture Search.
1: for number of training iterations do
2:
3:

Sample minibatch
(cid:8)z(1), ..., z(2m)(cid:9) from noise prior.
Sample
examples
minibatch
(cid:8)x(1), ..., x(2m)(cid:9) from real data distribution.

2m noise

samples

2m

of

of

4:

5:

6:

i=1

1
m

1
m

7:
8:

(cid:80)m

i=m+1

(cid:2)log(xi) + log(1 − D(G(zi)))(cid:3)

(cid:2)log(xi) + log(1 − D(G(zi)))(cid:3)

Update the architecture of discriminator by as-
cending its stochastic gradient:
∇β
Update the weights of discriminator by ascending
its stochastic gradient:
(cid:80)2m
∇WD
end for
Sample minibatch
(cid:8)z(1), ..., z(2m)(cid:9) from noise prior.
Update the architecture of generator by descending
its stochastic gradient:
∇α
Update the weights of generator by descending its
stochastic gradient:
∇WG
11: end for

(cid:2)log(1 − D(G(zi)))(cid:3)

(cid:2)log(1 − D(G(zi)))(cid:3)

2m noise

samples

(cid:80)2m

i=m+1

(cid:80)m

1
m

1
m

i=1

of

10:

9:

Moreover, the min-max game between two architectures
can also be searched in an alternative way. Speciﬁcally,
the currently optimal architecture of generator for the given
discriminator can be achieved through single step of ad-
versarial training, which has been proven by Goodfellow
in [13]. The proposed AdversarialNAS algorithm is shown
in Alg. 1, and optimal architectures or weights in each itera-

tion can be achieved by ascending or descending the corre-
sponding stochastic gradient. Note that, the order of the up-
dating strategy is architecture ﬁrst in each training iteration,
which guarantees the weights for updating the correspond-
ing architecture to be currently optimal. For example, the
discriminator used in ninth line of Alg. 1 is D∗ with optimal
architecture and weights for the current generator.

The proposed AdversarialNAS method can be plug-and-
play to the original training procedure of GANs to search
the architecture more naturally, which is speciﬁcally tai-
lored for GANs.

4. Experiments

4.1. Experimental Setup

Datasets. Following [12, 41], we adopt CIFAR-10 [25] and
STL-10 to evaluate the effectiveness of our approach. The
CIFAR-10 contains 60,000 natural images including 10 dif-
ferent classes in 32 × 32 spatial resolution. Concretely, we
use its training set that consists of 50,000 images without
any data augmentation technique to search for the optimal
architecture of the generator. We also apply this training
set to train the discovered architecture. To further evalu-
ate the transferability of the architecture, we also adopt to-
tally 105,000 images in STL-10 dataset to directly train the
searched architecture without any data augmentation for a
fair comparison with previous works.
Implementation. We use Adam optimizer [24] and hinge
loss to train the shared weights of Super-GAN and pro-
vide the supervision signal for updating the architectures.
Speciﬁcally, the hyper-parameters of optimizers for train-
ing the weights of both generator and discriminator are set
to β1 = 0.0, β2 = 0.9 and learning rate is set to 0.0002.
The hyper-parameters of optimizers for optimizing both ar-
chitectures are set to β1 = 0.5, β2 = 0.9 and the learn-
ing rate is 0.0003 with the weight decay of 0.0001. When
searching, the batch size is set to 100 for both generator
and discriminator, and we search for about 2,500 iterations.
When training the derived generator, we directly adopt the
discriminator used in AutoGAN [12] for a fair comparison,
which is similar to the one in SNGAN [31]. The batch size
is set to 40 for generator and 20 for discriminator, respec-
tively. We train the network for about 500 epochs, and the
hyper-parameters of the optimizer are the same as the ones
in searching. Besides, the same as all other methods, we
randomly generate 50,000 images for calculating the Incep-
tion Score and FID to evaluate the network performance.
Computational Costs. The proposed AdversarialNAS
takes about 12 hours to converge for searching for an op-
timal architecture on two NVIDIA RTX 2080Ti GPUs. It
requires only 1 GPU day to achieve the ﬁnal architecture in
a large search space (about 1038), while AutoGAN [12] re-
quires 2 GPU days in a quite small search space (about 105)

and AGAN [41] needs even 1200 GPU days for searching in
a comparable space. Note that we directly use the released
code of AutoGAN to search on the same hardware 2080Ti
GPU and the searching time of AGAN is from their original
paper (running on NVIDIA Titan X GPU).

4.2. Compared with State-of-the-Art Approaches

In this section, we discuss the searched architecture and
compare its performance with state-of-the-art approaches
including hand-crafted and auto-discovered ones. To ex-
plore the transferability of the discovered architecture, we
directly apply it to another dataset and retrain its weights for
comparing with other methods. Besides, we further study
the scalability of the searched architecture and prove its su-
periority to other methods.

4.2.1 Results on CIFAR-10

At the end of the searching program, we directly sample
the architecture from the search space by picking the oper-
ations with maximum weights α. The optimal architecture
searched on CIFAR-10 is shown in Tab. 1 and some valu-
able observations can be received from this table.

• The searched generator prefer ‘Bilinear’ operation
for upsampling features although it has no learn-
able parameters. Besides, the ‘Bilinear Interpolation’
provides more accurate expanded features than sim-
ple ‘Nearest ’ operation, which is discovered by the
searching algorithm.

• Surprisingly, there is no dilated convolution in this ar-
chitecture.
It seems that, for low-resolution images
(32 × 32), simply stacking normal convolutions may
already satisfy and achieve the optimal Effective Re-
ceptive Field (ERF) of the generator.

• We can also observe that the deeper cell tends to be
more shallow since more ‘None’ operations are pre-
ferred. The shallow cell has more multi-scale feature
fusion operation, which is represented by the discov-
ered parallel ‘Identity’ connection of convolution.

The quantitative comparisons with previous state-of-the-art
methods are given in Tab. 2. From the table, we can see
that the proposed AdversarialNAS is the ﬁrst gradient-based
approach that can search in a large search space with af-
fordable cost. The designed search space has 1038 different
architectures of GANs, which is several orders of magni-
tude larger than the search space (105) of AutoGAN [12].
Moreover, the proposed method only takes about 1 GPU
day for searching for an optimal architecture while the
AGAN [41] spends 1200 GPU days under a comparable
In the CIFAR-10 dataset, our discovered
search space.
‘AdversarialNAS-GAN’ achieves new state-of-the-art FID
score (10.87), which is quite encouraging. It also obtains

Up-Cell

Cell-1

Cell-2

Cell-3

Operation
Edge
0 → 1
Bilinear
0 → 2
Bilinear
1 → 3
Identity
Conv 3 × 3
1 → 4
2 → 3
None
Conv 3 × 3
2 → 4
3 → 4
Identity
3 → c2 Bilinear
3 → c3 Nearest
0 → 1
Bilinear
0 → 2
Bilinear
1 → 3
None
Conv 3 × 3
1 → 4
2 → 3
Identity
Conv 3 × 3
2 → 4
3 → 4
Conv 3 × 3
3 → c3 Nearest
0 → 1
Nearest
0 → 2
Bilinear
1 → 3
None
Conv 3 × 3
1 → 4
Conv 3 × 3
2 → 3
2 → 4
None
Conv 3 × 3
3 → 4

Num Resolution
1
1
1
256
−
256
1
1
1
1
1
−
256
1
256
256
1
1
1
−
256
256
−
256

4 → 8
4 → 8
8 → 8
8 → 8
−
8 → 8
8 → 8
8 → 16
8 → 32
8 → 16
8 → 16
−
16 → 16
16 → 16
16 → 16
16 → 16
16 → 32
16 → 32
16 → 32
−
32 → 32
32 → 32
−
32 → 32

Table 1. The searched optimal architecture of generator by the pro-
posed AdversarialNAS on CIFAR-10 with no category labels used.
The ‘Num’ indicates the number of operations.

an Inception Score (8.74 ± 0.07) that is highly competitive
with state-of-the-art Progressive GAN [23] (8.80 ± 0.05)
and superior to AutoGAN [12] (8.55 ± 0.10). It is worth
noting that the Progressive GAN applies a well-designed
progressive training strategy that is time-consuming, while
we directly train the discovered generator as vanilla GANs.
Besides, we randomly generate 50 images without
cherry-picking, which are given in the Fig. 3. These qual-
itative results demonstrate that our searched generator can
create diverse images that contain realistic appearance and
natural texture without any clue of model collapse.

Figure 3. The CIFAR-10 images generated by discovered genera-
tor in random without cherry-picking.

Method

DCGANs [35]
Improved GAN [36]
LRGAN [47]
DFM [43]
ProbGAN [16]
WGAN-GP, ResNet [15]
Splitting GAN [14]
MGAN [19]
Dist-GAN [40]
Progressive GAN [23]
Improving MMD-GAN [42]
SN-GAN [31]
AGAN [41]
Random Search [26]†
AutoGAN [12]
Random Search [26]††
AdversarialNAS-GAN

Search
Method

Search
Space

Search
Cost

Size
(MB)

FID↓ on
C-10

IS↑ on
S-10

FID↓ on
S-10

IS↑ on
C-10
6.64 ± 0.14
6.86 ± 0.06
7.17 ± 0.17
7.72 ± 0.13
7.75
7.86 ± 0.07
7.90 ± 0.09
8.33 ± 0.10

−
−
−
−
24.6
−
−
26.7
17.61

8.80 ± 0.05 −
8.29
8.22 ± 0.05
8.29 ± 0.09
8.09
8.55 ± 0.10
6.74 ± 0.07
8.74 ± 0.07

16.21
21.7
30.5
17.34
12.42
38.32
10.87

4.3
20.1
−
4.4
12.5
8.8

−
−
−
8.51 ± 0.13
8.87 ± 0.09
−
−
−
−
−
9.23 ± 0.08
9.16 ± 0.12
9.23 ± 0.08
−
9.16 ± 0.12
7.66 ± 0.08
9.63 ± 0.19

−
−
−
−
46.74
−
−
−
36.19
−
37.64
40.1
52.7
−
31.01
53.45
26.98

Manual

−

−

−

RL
Random
RL
Random
Gradient

−
105
105
1038
1038

1200
2
2
1
1

Table 2. The quantitative comparisons with state-of-the-art approaches. † indicates the results are achieved in the search space of AutoGAN
and †† denotes the results in our search space.

4.2.2 Transferability of the Architectures

Following the setting of AutoGAN [12] and AGAN [41],
we directly apply the generator searched on CIFAR-10 to
STL-10 dataset for evaluating the transferability of the ar-
chitecture. Speciﬁcally, we adopt totally 105,000 images
with no labels used to train this network. The number of
training epochs is the same as the one on CIFAR-10 and
we also randomly generate 50,000 images for calculating
the Inception Score and FID. We alter the resolution of in-
put noise to 6 × 6 for generating the image with the size of
48 × 48, as the AutoGAN and AGAN do.

The quantitative results are shown in Tab. 2. We can ob-
serve that our network suffers no overﬁtting on the CIFAR-
10 dataset and has a superior ability of generalization.
Speciﬁcally, it achieves the state-of-the-art Inception Score
(9.63) and FID (26.98) on STL-10, which are far better than
all hand-crafted and auto-discovered methods. The qualita-
tive results are also given in Fig. 4 to prove its ability to
generate diverse and realistic images.

4.2.3 Scalability of the Architectures

In this section, we further explore the scalability of the dis-
covered architecture on the CIFAR-10 dataset.

We compare our searched generator with two repre-
sentative works, manual-designed SNGAN [31] and auto-
discovered AutoGAN [12]. We scale the parameter size of
these generators from 1 MB to 25 MB through channel di-
mension, which is a large scope. Note that, for a fair com-
parison, we use the same discriminator with a ﬁxed size in

Figure 4. The STL-10 images randomly generated without cherry-
picking by the generator discovered on CIFAR-10.

all experiments to observe the impact of generator capac-
ity changes. The qualitative comparisons are illustrated in
Fig. 5 and Fig. 6. The x-axis in both ﬁgures denotes the
parameter size (MB) of the speciﬁc generator. The y-axis is
IS in Fig. 5 and is FID in Fig. 6. These experiments demon-
strate that our searched architecture is more stable and al-
most unaffected when scaling the model size. When the size
is extremely compressed to only 1 MB, the SNGAN and
AutoGAN all suffer from the disaster of performance degra-
dation, while the performance of ‘AdversarialNAS-GAN’ is
almost unchanged. Notably, the performance will continu-
ally drop when expanding the generator size because the
enlarged generator will not be balanced with the ﬁxed-size
discriminator any more. However, both Fig. 5 and Fig. 6
demonstrate that our discovered architecture will not suffer
from performance drop, which means it is more robust and
has superior inclusiveness for discriminators.

Discriminator

CIFAR-10

STL-10

Architecture

Type

IS↑

FID↓

IS↑

FID↓

Random Search

AutoGAN-D 6.74 ± 0.13

38.32

7.66 ± 0.11

53.45

Methods

SingalNAS
SingalNAS
SingalNAS

Fixed

Fixed
Fixed
Fixed

7.72 ± 0.03
SNGAN-D
AutoGAN-D 7.86 ± 0.08
7.77 ± 0.05

Super-D

27.79
24.04
23.01

6.56 ± 0.12
8.52 ± 0.05
8.62 ± 0.03

84.19
38.85
41.57

AdversarialNAS

Dynamic

Searched-D

8.74 ± 0.07

10.87

9.63 ± 0.19

26.98

Table 3. We search the generative model on CIFAR-10 with different methods and retain the weight of these searched architectures to
evaluate their performance on both CIFAR-10 and STL-10.

4.3. Ablation Studies

To further evaluate the effectiveness of the proposed Ad-

versarialNAS, we conduct a series of ablation studies.

First, we conduct a random search strategy [26] to search
for the generator where we adopt the ﬁxed-architecture dis-
criminator of AutoGAN for a fair comparison. The perfor-
mance of the searched generative model is shown in Tab. 3.
Second, we propose ‘SingalNAS’ to search the optimal gen-
erator with different types of ﬁxed architecture of discrimi-
nator, while the weights of discriminator can still be trained.
Accordingly, the supervision signal for updating the gener-
ator architecture comes from the ﬁxed architecture of dis-
criminator, and the discriminator architecture does not dy-
namically change according to generator during searching.
We adopt the discriminator architecture of SNGAN and Au-
toGAN, respectively. In addition, to verify the inﬂuences of
our search space, we also conduct ‘SingalNAS’ with the
ﬁxed Super-D. Third, we use the proposed ‘Adversarial-
NAS’ to search the generator and discriminator simultane-
ously. Note that, the time consuming of both searching and
training in all experiments is constrained to be consistent.

Figure 5. Inception Score curves of different methods.

Figure 6. FID curves of different methods.

The effectiveness of our adversarial searching strategy

can be observed from the comparisons in Tab. 3.

5. Conclusion

In this work, we propose a large search space for GANs
and a novel AdversarialNAS method to search for a superior
generative model automatically. The proposed searching al-
gorithm can directly be inserted to the original procedure
of GAN training and search the architecture of generator
in a differentiable manner through an adversarial mecha-
nism, which extremely reduces the search cost. The discov-
ered network achieves state-of-the-art performance on both
CIFAR-10 and STL-10 datasets, and it also has advanced
transferability and scalability.

Furthermore, we believe the idea behind our Adversar-
ialNAS is not only speciﬁc to NAS-GAN and may beneﬁt
other potential ﬁeld where there are multiple network archi-
tectures requiring mutual inﬂuence, such as network archi-
tecture distillation, pruning and mutual learning.

References

[1] Andrew Brock, Theodore Lim, James Millar Ritchie, and
Nicholas J Weston. Smash: One-shot model architecture
search through hypernetworks. In ICLR, 2018.

[2] Han Cai, Ligeng Zhu, and Song Han. Proxylessnas: Direct
neural architecture search on target task and hardware. arXiv
preprint arXiv:1812.00332, 2018.

[3] Liang-Chieh Chen, Maxwell Collins, Yukun Zhu, George
Papandreou, Barret Zoph, Florian Schroff, Hartwig Adam,
and Jon Shlens. Searching for efﬁcient multi-scale architec-
tures for dense image prediction. In NIPS, 2018.

[4] Shoufa Chen, Yunpeng Chen, Shuicheng Yan, and Jiashi
Feng. Efﬁcient differentiable neural architecture search with
meta kernels. arXiv preprint arXiv:1912.04749, 2019.

[5] Xin Chen, Lingxi Xie, Jun Wu, and Qi Tian.

Pro-
gressive differentiable architecture search: Bridging the
depth gap between search and evaluation. arXiv preprint
arXiv:1904.12760, 2019.

[6] Yunpeng Chen, Haoqi Fan, Bing Xu, Zhicheng Yan, Yan-
nis Kalantidis, Marcus Rohrbach, Shuicheng Yan, and Ji-
ashi Feng. Drop an octave: Reducing spatial redundancy in
convolutional neural networks with octave convolution. In
ICCV, 2019.

[7] Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha,
Sunghun Kim, and Jaegul Choo. Stargan: Uniﬁed genera-
tive adversarial networks for multi-domain image-to-image
translation. In CVPR, 2018.

[8] Laurent Dinh, David Krueger, and Yoshua Bengio. Nice:
arXiv

Non-linear independent components estimation.
preprint arXiv:1410.8516, 2014.

[9] Xuanyi Dong and Yi Yang. One-shot neural architecture
search via self-evaluated template network. In ICCV, 2019.
[10] Shang-Hua Gao, Yong-Qiang Tan, Ming-Ming Cheng,
Chengze Lu, Yunpeng Chen, and Shuicheng Yan. Highly ef-
ﬁcient salient object detection with 100k parameters. arXiv
preprint arXiv:2003.05643, 2020.

[11] Golnaz Ghiasi, Tsung-Yi Lin, and Quoc V Le. Nas-fpn:
Learning scalable feature pyramid architecture for object de-
tection. In CVPR, 2019.

[12] Xinyu Gong, Shiyu Chang, Yifan Jiang, and Zhangyang
Wang. Autogan: Neural architecture search for generative
adversarial networks. In ICCV, 2019.

[13] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing
Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and
Yoshua Bengio. Generative adversarial nets. In NIPS, 2014.
[14] Guillermo L. Grinblat, Lucas C. Uzal, and Pablo M.
Granitto. Class-splitting generative adversarial networks.
ArXiv, abs/1709.07359, 2017.

[15] Ishaan Gulrajani, Faruk Ahmed, Mart´ın Arjovsky, Vincent
Improved training of

Dumoulin, and Aaron C. Courville.
wasserstein gans. In NIPS, 2017.

[16] Hao He, Hao Wang, Guang-He Lee, and Yonglong Tian.
Probgan: Towards probabilistic gan with theoretical guaran-
tees. In ICLR, 2019.

[17] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
In CVPR,

Deep residual learning for image recognition.
2016.

[18] Geoffrey E Hinton and Ruslan R Salakhutdinov. Reducing
science,

the dimensionality of data with neural networks.
313(5786):504–507, 2006.

[19] Quan Hoang, Tu Dinh Nguyen, Trung Le, and Dinh Q.
Phung. Mgan: Training generative adversarial nets with mul-
tiple generators. In ICLR, 2018.

[20] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kil-
ian Q Weinberger. Densely connected convolutional net-
works. In CVPR, 2017.

[21] Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A
Image-to-image translation with conditional adver-

Efros.
sarial networks. In CVPR, 2017.

[22] Wentao Jiang, Si Liu, Chen Gao, Jie Cao, Ran He, Jiashi
Feng, and Shuicheng Yan. Psgan: Pose and expression
robust spatial-aware gan for customizable makeup transfer.
arXiv preprint arXiv:1909.06956, 2019.

[23] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen.
Progressive growing of gans for improved quality, stability,
and variation. arXiv preprint arXiv:1710.10196, 2017.
[24] Diederik P Kingma and Jimmy Ba. Adam: A method for
arXiv preprint arXiv:1412.6980,

stochastic optimization.
2014.

[25] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple
layers of features from tiny images. Technical report, Cite-
seer, 2009.

[26] Liam Li and Ameet Talwalkar. Random search and re-
producibility for neural architecture search. arXiv preprint
arXiv:1902.07638, 2019.

[27] Chenxi Liu, Liang-Chieh Chen, Florian Schroff, Hartwig
Adam, Wei Hua, Alan L Yuille, and Li Fei-Fei. Auto-
deeplab: Hierarchical neural architecture search for semantic
image segmentation. In CVPR, pages 82–92, 2019.

[28] Chenxi Liu, Barret Zoph, Maxim Neumann, Jonathon
Shlens, Wei Hua, Li-Jia Li, Li Fei-Fei, Alan Yuille, Jonathan
Huang, and Kevin Murphy. Progressive neural architecture
search. In ECCV, 2018.

[29] Hanxiao Liu, Karen Simonyan,

Darts: Differentiable architecture search.
arXiv:1806.09055, 2018.

and Yiming Yang.
arXiv preprint

[30] Chris J Maddison, Daniel Tarlow, and Tom Minka. A* sam-

pling. In NIPS, 2014.

[31] Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and
Yuichi Yoshida. Spectral normalization for generative ad-
versarial networks. arXiv preprint arXiv:1802.05957, 2018.
[32] Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor
Darrell, and Alexei A Efros. Context encoders: Feature
learning by inpainting. In CVPR, 2016.

[33] Junran Peng, Ming Sun, Zhaoxiang Zhang, Tieniu Tan,
and Junjie Yan. Efﬁcient neural architecture transformation
searchin channel-level for object detection. arXiv preprint
arXiv:1909.02293, 2019.

[34] Hieu Pham, Melody Guan, Barret Zoph, Quoc Le, and Jeff
Dean. Efﬁcient neural architecture search via parameter shar-
ing. In ICML, 2018.

[35] Alec Radford, Luke Metz, and Soumith Chintala. Un-
supervised representation learning with deep convolu-
arXiv preprint
tional generative adversarial networks.
arXiv:1511.06434, 2015.

[36] Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki
Cheung, Alec Radford, and Xi Chen. Improved techniques
for training gans. In NIPS, 2016.

[37] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zh-
moginov, and Liang-Chieh Chen. Mobilenetv2: Inverted
residuals and linear bottlenecks. In CVPR, 2018.

[38] Ke Sun, Bin Xiao, Dong Liu, and Jingdong Wang. Deep
high-resolution representation learning for human pose esti-
mation. In CVPR, 2019.

[39] Mingxing Tan and Quoc V Le. Efﬁcientnet: Rethinking
arXiv

model scaling for convolutional neural networks.
preprint arXiv:1905.11946, 2019.

[40] Ngoc-Trung Tran, Tuan-Anh Bui, and Ngai-Man Cheung.
Dist-gan: An improved gan using distance constraints.
In
ECCV, 2018.

[41] Hanchao Wang and Jun Huan. Agan: Towards automated
design of generative adversarial networks. arXiv preprint
arXiv:1906.11080, 2019.

[42] Wei Wang, Yuan Sun, and Saman K. Halgamuge. Improv-
ing mmd-gan training with repulsive loss function. ArXiv,
abs/1812.09916, 2018.

[43] David Warde-Farley and Yoshua Bengio. Improving gener-
ative adversarial networks with denoising feature matching.
In ICLR, 2017.

[44] Lingxi Xie and Alan Yuille. Genetic cnn. In ICCV, 2017.
[45] Sirui Xie, Hehui Zheng, Chunxiao Liu, and Liang Lin.
Snas: stochastic neural architecture search. arXiv preprint
arXiv:1812.09926, 2018.

[46] Tao Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang,
Zhe Gan, Xiaolei Huang, and Xiaodong He. Attngan: Fine-
grained text to image generation with attentional generative
adversarial networks. In CVPR, 2018.

[47] Jianwei Yang, Anitha Kannan, Dhruv Batra, and Devi
Lr-gan: Layered recursive generative adver-
arXiv preprint

Parikh.
sarial networks for image generation.
arXiv:1703.01560, 2017.

[48] Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiao-
gang Wang, Xiaolei Huang, and Dimitris N Metaxas. Stack-
gan: Text to photo-realistic image synthesis with stacked
generative adversarial networks. In ICCV, 2017.

[49] Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, and Jian Sun.
Shufﬂenet: An extremely efﬁcient convolutional neural net-
work for mobile devices. In CVPR, 2018.

[50] Yiheng Zhang, Zhaofan Qiu, Jingen Liu, Ting Yao, Dong
Liu, and Tao Mei. Customizable architecture search for se-
mantic segmentation. In CVPR, 2019.

[51] Defa Zhu, Si Liu, Wentao Jiang, Chen Gao, Tianyi Wu, and
Guodong Guo. Ugan: Untraceable gan for multi-domain
face translation. arXiv preprint arXiv:1907.11418, 2019.
[52] Barret Zoph and Quoc V Le. Neural architecture search with
reinforcement learning. arXiv preprint arXiv:1611.01578,
2016.

