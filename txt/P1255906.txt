7
1
0
2
 
l
u
J
 
9
2
 
 
]

A
N
.
h
t
a
m

[
 
 
2
v
9
1
8
3
0
.
0
1
6
1
:
v
i
X
r
a

Recursive Diﬀeomorphism-Based Regression for Shape
Functions

Jieren Xu†, Haizhao Yang∗ and Ingrid Daubechies†

† Department of Mathematics, Duke University
∗Department of Mathematics, National University of Singapore

October, 2016; revised July 2017

Abstract

This paper proposes a recursive diﬀeomorphism-based regression method for the
one-dimensional generalized mode decomposition problem that aims at extracting gen-
eralized modes αk(t)sk(2πNkφk(t)) from their superposition (cid:80)K
k=1 αk(t)sk(2πNkφk(t)).
We assume that the instantaneous information, e.g., αk(t) and Nkφk(t), is determined
by, e.g., a one-dimensional synchrosqueezed transform or some other methods. Our
main contribution is to propose a novel approach based on diﬀeomorphisms and non-
parametric regression to estimate wave shape functions sk(t). This leads to a framework
for the generalized mode decomposition problem under a weak well-separation condi-
tion. Numerical examples of synthetic and real data are provided to demonstrate the
successful application of our approach.

Keywords. Generalized mode decomposition, generalized shape function, instanta-
neous, synchrosqueezed wave packet transform, diﬀeomorphism, recursive nonparametric
regression.

AMS subject classiﬁcations: 42A99 and 65T99.

1 Introduction

The analysis of oscillatory data is a ubiquitous challenge, arising in a wide range of appli-
cations including but not limited to medicine (like ECG and EEG readings [1]), physical
science (e.g., gravitational waves [2], atomic crystal images [3]), mechanical engineering
(such as vibration measurements [4]), ﬁnance, geology (e.g., seismic data analysis [5, 6]),
art investigation [7], and audio signals (including speech and music recordings [8]). Al-
though diﬀerent problems depend on diﬀerent interpretation of the data measurement, it
is common that one wants to extract certain time-varying features or conduct adaptive
component analysis. For this purpose, a typical model is to assume that the oscillatory
data f (t) consists of a superposition of several (but typically reasonably few) oscillatory
modes like

f (t) =

αk(t)e2πiNkφk(t),

(1)

where αk(t) is the instantaneous amplitude, 2πNkφk(t) is the instantaneous phase and
Nkφ(cid:48)
k(t) is the instantaneous frequency. Analyzing instantaneous properties (e.g., instanta-
neous frequencies, instantaneous amplitudes and instantaneous phases) and decomposing

K
(cid:88)

k=1

1

Figure 1: Left: A generalized shape function s(t) of a real ECG signal (in blue) and its band-
limited approximation (cid:80)
|n|≤10 (cid:98)s(n)e2πint (in red). Right: The Fourier power spectrum
|(cid:98)s(ξ)| of s(t). As seen in the real ECG shape function in blue, there are three major peaks
(called P, R, and T peaks from left to right, respectively) that are valuable in medical
study. This ﬁgure illustrates that a high sampling rate is needed to identify these peaks
accurately, and that a band-limited approximation to the shape function loses important
information.

the signal f (t) into several modes αk(t)e2πiNkφk(t) have been an important topic for over two
decades. Many methods, have been proposed to address this mode decomposition prob-
lem, e.g. empirical mode decomposition methods [9], time-frequency reassignment methods
[10, 11], synchrosqueezed transforms [12], adaptive optimization [13, 14], recursive ﬁltering
[15, 16], and data-driven time-frequency decomposition [17, 18].

In spite of considerable success in modeling oscillatory data of the form (1), modes
with sinusoidal oscillatory patterns like αk(t)e2πiNkφk(t) are not longer suﬃciently adaptive
to characterize complicated features in the data. This motivates the generalized mode
decomposition problem of the form

f (t) =

fk(t) =

αk(t)sk(2πNkφk(t)),

(2)

K
(cid:88)

k=1

K
(cid:88)

k=1

where {sk(t)}1≤k≤K are 2π-periodic generalized shape functions. For example, the oscilla-
tory pattern in the electrocardiography (ECG) signal contains information of the electrical
pathway inside the heart, the respiration, and the heart anatomy, which is embedded in a
generalized shape function as shown in Figure 1 (left). For another example, diﬀerent kinds
of timbre of diﬀerent music instruments result from diﬀerent wave shapes in music signals
(see Figure 2). The Fourier expansion of generalized shape functions results in

f (t) =

αk(t)sk(2πNkφk(t)) =

(cid:98)sk(n)αk(t)e2πinNkφk(t).

(3)

K
(cid:88)

k=1

Hence, in another point of view, the generalized mode decomposition problem comes from
the motivation that combining modes with similar oscillatory patterns of the form (1) leads

K
(cid:88)

∞
(cid:88)

k=1

n=−∞

2

Figure 2: A few consecutive copies of generalized shape functions for the sound produced
by playing a note on a musical instrument. Left: Violin. Right: Piano.

to a more adaptive and physically more meaningful decomposition of the form (2). When
generalized shape functions are not band-limited, the generalized mode decomposition prob-
lem is challenging.

Although various methods have been proposed for the mode decomposition problem,
the generalized mode decomposition problem is relatively recent and there are few solutions.
Existing solutions assume that the instantaneous amplitudes αk(t) and the fundamental in-
stantaneous frequencies Nkφ(cid:48)
k(t) can be estimated by the synchrosqueezed transform [19, 20]
or the data-driven time-frequency analysis [14]. With these instantaneous properties ready,
the generalized shape function can be estimated by the diﬀeomorphism based spectral anal-
ysis (DSA) [19], the singular value decomposition (SVD) method [21], and the functional
regression method [20] under diﬀerent conditions as speciﬁed in these references. This pa-
per proposes a recursive diﬀeomorphism-based regression method (RDBR) as an alterna-
tive solution to the generalized mode decomposition problem. Before applying the RDBR
method, the synchrosqueezed transform is applied to estimate instantaneous amplitudes
{αk(t)}k and instantaneous frequencies {Nkφ(cid:48)
k(t)}k. With these instantaneous properties
ready, the RDBR method is able to estimate generalized shape functions {sk(t)}k using a
time-frequency unwarping technique (a diﬀeomorphism to be clariﬁed later) and a nonpara-
metric regression algorithm with theoretical guarantee. Numerical examples show that this
novel method works in many diﬀerent situations:
it can identify and extract generalized
modes with similar phase functions and a wide range of generalized shape functions; it can
estimate generalized shape functions of a short signal with few periods, which potentially
enables online computation for dynamic shapes changing in time.

The rest of this paper is organized as follows. In Section 2, the one-dimensional syn-
In Section 3, the
chrosqueezed transform is brieﬂy introduced with a simple example.
recursive diﬀeomorphism-based shape regression method is introduced and asymptotically
analyzed.1 In Section 4, some synthetic and real examples are provided to demonstrate the
eﬃciency of the RDBR method. Finally, we conclude this paper in Section 5.

2 Synchrosqueezed transform (SST)

A powerful tool for the mode decomposition problem is the synchrosqueezed transform
(SST). It consists of a linear time-frequency analysis tool and a nonlinear synchrosqueezing
technique to obtain a sharpened time-frequency representation [6, 22, 12, 19, 23, 24]. The
SST is a reasonably robust algorithm [25, 26] with fast forward and inverse transforms

1Notations in the asymptotical analysis: we shall use the O((cid:15)) notation, as well as the related notations
(cid:46) and (cid:38); in particular, we write F = O((cid:15))G if there exists a constant C (which we will not specify further)
such that |F | ≤ C(cid:15)|G|; here C may depend on some general parameters as detailed just before Theorem 2.9.

3

(a)

(b)

(c)

(d)

Figure 3: (a) and (c): two generalized shape functions s1(2πt) and s2(2πt) of real ECG
signals; (b) and (d): the Fourier spectrum of the generalized shape functions in (a) and (c),
respectively.

based on the FFT. It has been applied to analyze oscillatory data in a wide range of real
problems. Following [19], the one-dimensional synchrosqueezed wave packet transforms
(SSWPT) is applied to estimate fundamental instantaneous properties before estimating
generalized shapes. Hence, we will follow the notations in [19] and brieﬂy introduce the
SSWPT with a concrete example

f (t) = f1(t) + f2(t),

(4)

where

f1(t) = α1(t)s1(2πN1φ1(t)) = (1 + 0.05 sin(4πx))s1 (120π(x + 0.01 sin(2πx)))

f2(t) = α2(t)s2(2πN2φ2(t)) = (1 + 0.1 sin(2πx))s2 (180π(x + 0.01 cos(2πx))) ,

s1(t) and s2(t) are generalized shape functions deﬁned in [0, 1] as shown in Figure 3. The
SSWPT is applied to recover αi(t), i = 1, 2, and Niφi(t), i = 1, 2 from f (t). For detailed
implementation, the reader is referred to [19].

Let w(t) be a mother wave packet in the Schwartz class. The Fourier transform (cid:98)w(ξ) is
assumed to be a real-valued, non-negative, smooth function with a support equal to (−d, d)
with d ≤ 1. Using w(t), a family of wave packets can be constructed through scaling,
modulation, and translation controlled by a geometric parameter s.

Deﬁnition 2.1. Given the mother wave packet w(t) and the parameter s ∈ (1/2, 1), the
family of wave packets {wab(t) : |a| ≥ 1, b ∈ R} is deﬁned as

or equivalently, in the Fourier domain as

wab(t) = |a|s/2w(|a|s(t − b))e2πi(t−b)a,

(cid:100)wab(ξ) = |a|−s/2e−2πibξ

(cid:98)w(|a|−s(ξ − a)).

If s were equal to 1 or 1/2, these functions would be qualitatively similar to the standard
wavelets or the wave atoms [27], respectively. Allowing one more degree of freedom s makes
wave packets more adaptive to the given data.

4

Deﬁnition 2.2. The one-dimensional wave packet transform of a function f (t) is a function

Wf (a, b) = (cid:104)wab, f (cid:105) =

wab(t)f (t)dt

(cid:90)

for |a| ≥ 1, b ∈ R.

Deﬁnition 2.3. Instantaneous frequency information function:

Let f ∈ L∞(R). The instantaneous frequency information function of f is deﬁned by

vf (a, b) =

(cid:40) ∂bWf (a,b)
2πiWf (a,b) ,
∞,

for |Wf (a, b)| > 0;
otherwise,

(5)

(6)

where ∂bWf (a, b) is the partial derivative of Wf (a, b) with respect to b.

As we shall see in Theorem 2.9, for a class of oscillatory functions f (t) = α(t)e2πiN φ(t),
vf (a, b) ≈ N φ(cid:48)(b) independently of a as long as Wf (a, b) (cid:54)= 0. If we reassign the coeﬃcients
Wf (a, b) from the original position (a, b) to a new position (vf (a, b), b), then we would
obtain a sharpened time-frequency representation of f (t). This motivates the deﬁnition of
the synchrosqueezed energy distribution as follows.

Deﬁnition 2.4. Given f (t), Wf (a, b), and vf (a, b), the synchrosqueezed energy distribution
Tf (v, b) is deﬁned by

Tf (v, b) =

|Wf (a, b)|2δ((cid:60)vf (a, b) − v)da

(7)

(cid:90)

R

for v, b ∈ R, where (cid:60) means the real part of a complex number.

k(b), i.e.

For a multi-component signal f (t) = (cid:80)K

k=1 αk(t)e2πiNkφk(t), the synchrosqueezed en-
ergy of each component will concentrate around its corresponding instantaneous frequency
Nkφ(cid:48)
the supports of Tf (v, b) are essentially narrow bands around the curves
(b, Nkφ(cid:48)
k(b)) in the two-dimensional time-frequency domain, (see Figure 4 (left) for an ex-
ample of Tf (v, b)). Hence, the SSWPT can provide information about their instantaneous
frequencies.
In the presence of generalized shape functions deﬁned below, the spectral
information becomes more complicated (see Figure 4 (right) for an example).

Deﬁnition 2.5. Generalized shape functions: The generalized shape function class SM
consists of 2π-periodic functions s(t) in the Wiener Algebra with a unit L2([−π, π])-norm
and a L∞-norm bounded by M satisfying the following spectral conditions:

1. The Fourier series of s(t) is uniformly convergent;

2. (cid:80)∞

n=−∞ |(cid:98)s(n)| ≤ M and (cid:98)s(0) = 0;

3. Let Λ be the set of integers {|n| : (cid:98)s(n) (cid:54)= 0}. The greatest common divisor gcd(s) of

all the elements in Λ is 1.

Deﬁnition 2.6. A function f (t) = α(t)s(2πN φ(t)) is a generalized intrinsic mode type
function (GIMT) of type (M, N ), if s(t) ∈ SM and α(t) and φ(t) satisfy the conditions
below.

α(t) ∈ C∞,

φ(t) ∈ C∞,

|α(cid:48)| ≤ M,
1/M ≤ |φ(cid:48)| ≤ M,

1/M ≤ α ≤ M
|φ(cid:48)(cid:48)| ≤ M.

5

Deﬁnition 2.7. A function f (t) is a well-separated generalized superposition of type (M, N, K, s),
if

f (t) =

fk(t),

K
(cid:88)

k=1

where each fk(t) = αk(t)sk(2πNkφk(t)) is a GIMT of type (M, Nk) such that Nk ≥ N and
the phase functions satisfy the separation condition: for any pair (a, b), there exists at most
one pair (n, k) such that (cid:98)sk(n) (cid:54)= 0 and that

We denote by GF (M, N, K, s) the set of all such functions.

|a|−s|a − nNkφ(cid:48)

k(b)| < d.

If f (t) is a well-separated generalized superposition of type (M, N, K, s), the syn-
chrosqueezed energy distribution Tf (v, b) has well-separated supports, each of which con-
centrates around one instantaneous frequency nNkφ(cid:48)
k(b). Fortunately, although f (t) is not a
well-separated generalized superposition, its Fourier expansion components (cid:98)sk(n)αk(t)e2πinNkφk(t)
might still be well-separated in the low-frequency domain (see Figure 4 (left) for an exam-
ple). Hence, some instantaneous frequency nNkφ(cid:48)
k(b) can be estimated from the ridge (or av-
erage) of its corresponding support, and its corresponding component (cid:98)sk(n)αk(t)e2πinNkφk(t)
can be recovered by an inverse SST restricted to the corresponding support. Since in prac-
tice, and as illustrated by Figure 4, even if low-frequency components are well-separated,
high-frequency components might still be mixed up, well-separated generalized superposi-
tion is thus very rare; this motivates the deﬁnition of a more reasonable situation below.

Deﬁnition 2.8. A function f (t) is a weak well-separated generalized superposition of type
(M, N, K, s) if

f (t) =

fk(t)

K
(cid:88)

k=1

where each fk(t) = αk(t)sk(2πNkφk(t)) is a GIMT of type (M, Nk) such that Nk ≥ N and
the phase functions satisfy the following weak well-separation conditions.

1. Suppose

Znk = (cid:8)(a, b) : |a − nNkφ(cid:48)

k(b)| ≤ d|a|s(cid:9) .

For each k, there exists nk such that (cid:98)sk(nk) (cid:54)= 0 and Znkk ∩ Znj = ∅ for all pairs
(n, j) (cid:54)= (nk, k) and (cid:98)sj(n) (cid:54)= 0.

2. ∃K0 < ∞ such that ∀a ∈ R and ∀b ∈ R there exists at most K0 pairs of (n, k) such

that (a, b) ∈ Znk.

We denote by wGF (M, N, K0, K, s) the set of all such functions.

The weak well-separation condition essentially requires that each generalized mode has
at least one Fourier expansion component (cid:98)sk(n)αk(t)e2πinNkφk(t) well-separated in the time-
frequency domain. This enables the SSWPT to estimate the fundamental instantaneous
amplitude and frequency of each generalized mode. The following theorem proved in [19]
supports this intuition in more detail. Recall that, when we write O(·), (cid:46), or (cid:38), the implicit
constants may depend on M , K, K0, and no other parameters.

6

Figure 4: Both ﬁgures show the synchrosqueezed energy distribution of the same signal in
Equation 4 . Left: in the low-frequency domain, the synchrosqueezed energy distribution
shows a few well-separated oscillatory components. The instantaneous frequencies of these
components can be directly read oﬀ from this distribution. Right: the synchrosqueezed
energy distribution in the whole time-frequency domain. Instantaneous frequencies of the
Fourier expansion terms in { (cid:98)sk(n)αk(t)e2πinNkφk(t)}k,n cross over together.

Theorem 2.9. For a function f (t) and ε > 0, we deﬁne

Rε = {(a, b) : |Wf (a, b)| ≥ |a|−s/2√

ε}

and

Zn,k = {(a, b) : |a − nNkφ(cid:48)

k(b)| ≤ d|a|s}

for 1 ≤ k ≤ K and |n| ≥ 1. For ﬁxed M , K0, K and ∀ε > 0, there exists a constant
N0(M, K0, K, s, ε) > 0 such that ∀N > N0 and f (t) ∈ wGF (M, N, K0, K, s) the following
statements hold.

(i) For each j, there exists nj such that (cid:98)sj(nj) (cid:54)= 0 and Znj j ∩ Znk = ∅ for all pairs

(n, k) (cid:54)= (nj, j) and (cid:98)sk(n) (cid:54)= 0;

(ii) For any (a, b) ∈ Rε ∩ Znj ,j,

|vf (a, b) − njNjφ(cid:48)
|njNjφ(cid:48)
j(b)|

j(b)|

√

ε.

(cid:46)

(iii) For each j, let

lnj (b) = min (cid:8)a : (a, b) ∈ R(cid:15) ∩ Znj j

(cid:9) ,

unj (b) = max (cid:8)a : (a, b) ∈ R(cid:15) ∪ Znj j

(cid:9) .

Suppose vf (a, b) (cid:54)= ∞. If a ≤ lnj (b), then vf (a, b) ≤ lnj (b)(1 + O(
then vf (a, b) ≥ unj (b)(1 − O(
(cid:15))).

√

√

(cid:15))). If a ≥ unj (b),

Theorem 2.9 shows that the supports of the synchrosqueezed energy distribution Tf (v, b)
are essentially narrow bands around the curves (b, nkNkφ(cid:48)
k(b)) in the two-dimensional time-
frequency domain, (see Figure 4 (left) for an example of Tf (v, b)). Hence, we can estimate

7

the instantaneous frequencies by tracking these curves. These curves naturally belong to K
groups, each of which corresponds to the multiple of a fundamental instantaneous frequency
Nkφ(cid:48)
k(t). Following the curve classiﬁcation idea in Algorithm 3.7 and Theorem 3.9 in [19],
we are able to classify these curves and extract the fundamental instantaneous frequencies
{Nkφ(cid:48)
k(t)}1≤k≤K, which give the fundamental instantaneous phases {Nkφk(t)}1≤k≤K. By
applying the inverse synchrosqueezed transform to the support of Tf (v, b) corresponding
to the instantaneous frequency nkNkφ(cid:48)
k(t), we can reconstruct (cid:98)sk(nk)αk(t)e2πinkNkφk(t), the
magnitude of which gives the estimation of the fundamental instantaneous amplitudes αk(t)
up to a constant prefactor. We refer the reader to [19] for more detail and assume that
these estimates are available afterward. There are some other alternative methods available
to estimate fundamental instantaneous properties, e.g. a recent paper [28] based on the
short-time ceptrum transform.

3 Recursive diﬀeomorphism-based shape regression (RDBR)

3.1 Algorithm description

In this section, we introduce the recursive diﬀeomorphism-based regression (RDBR), which
we shall use to estimate generalized shape functions sk(t) in a superposition of the form

f (t) =

αk(t)sk(2πNkφk(t)),

K
(cid:88)

k=1

assuming that the fundamental instantaneous phases {Nkφk(t)}K
k=1 and the instantaneous
amplitudes {αk(t)}K
k=1 are known a priori. Suppose the signal f (t) is sampled randomly
in the domain [0, 1]. In particular, we have L points of measurement {f (t(cid:96))}(cid:96)=1,...,L with
L independent and identically distributed (i.i.d.) grid points {t(cid:96)}(cid:96)=1,...,L with a uniform
distribution in [0, 1]. Usually, the grid is uniform in [0, 1), which is a special case in our
assumption. Numerical examples are provided in Section 4.1 to support this assumption.
Notice that the smooth function pk(t) = Nkφk(t) has the interpretation of a warping
in each generalized mode via a diﬀeomorphism pk : R → R. Hence, we can deﬁne the
inverse-warping data by

hk(v) =

f ◦ p−1
αk ◦ p−1

k (v)
k (v)

= sk(2πv) +

(cid:88)

j(cid:54)=k

αj ◦ p−1
αk ◦ p−1

k (v)
k (v)

sj(2πpj ◦ p−1

k (v))

:= sk(2πv) + κk(v),

where v = pk(t). Correspondingly, we have a set of measurements of hk(v) sampled on
{hk(v(cid:96))}(cid:96)=1,...,L with v(cid:96) = pk(t(cid:96)).

The observation that sk(2πv) is a periodic function with a period 1 motivates the fol-
lowing folding map τ that folds the two-dimensional point set {(v(cid:96), hk(v(cid:96)))}(cid:96)=1,...,L together

τ :

(v(cid:96), hk(v(cid:96))) (cid:55)→ (mod(v(cid:96), 1), hk(v(cid:96))) .

If there was only one generalized mode, then the point set {τ (v(cid:96), sk(2πv(cid:96)))}(cid:96)=1,...,L ⊂ R2 is
a two-dimensional point set located at the curve (v, sk(2πv)) ⊂ R2 given by the generalized

8

Figure 5: Left: the point set {τ (v(cid:96), sk(2πv(cid:96)))}(cid:96)=1,...,L ⊂ R2 in the case of one mode f (t) =
f1(t), where f1(t) is given in (4). Middle: the point set {τ (v(cid:96), sk(2πv(cid:96)))}(cid:96)=1,...,L ⊂ R2 in
the case of two modes f (t) = f1(t) + f2(t) deﬁned in (4). Right: the true shape function
s1(2πt) and the estimated one ¯s1(2πt) by regression once from the point set in the middle
ﬁgure.

shape function sk(2πv) with v ∈ [0, 1). Figure 5 (left) visualizes one example of this point
set in the case of one mode. This could also be understood in the following way. Let Xk
be an independent random variable in [0, 1) and Yk be the response random variable in R.
Consider (x(cid:96), y(cid:96)) = τ (v(cid:96), sk(2πv(cid:96))) for (cid:96) = 1, . . . , L as L i.i.d. samples of the random vector
(Xk, Yk). Then we know sk is the regression function satisfying Yk = sk(2πXk). Hence, the
solution of the following regression problem gives the generalized shape function

sk = sR

k := arg min
s:R→R

E{|s(2πXk) − Yk|2},

(8)

where the superscript R means the ground truth regression function. Let ¯sk denote the
numerical solution of the above regression problem, then the approximation ¯sk ≈ sk is
precise once L is suﬃciently large, since the variance σ2 := Var{Yk|Xk = x} = 0 for
all x ∈ [0, 1). Once the generalized shape function sk has been estimated, the estimated
generalized mode αk(t)¯sk(2πNkφk(t)) is an immediate result.

The assumption that (x(cid:96), y(cid:96)) = τ (v(cid:96), sk(2πv(cid:96))) for (cid:96) = 1, . . . , L are L i.i.d. samples of
the random vector (Xk, Yk) comes from the fact that grid points {t(cid:96)}(cid:96)=1,...,L are i.i.d.. In
practice, these grid points are determinate and usually uniform. Notice that the warping
and folding maps behave essentially like pseudorandom number generators with a nonlin-
ear congruential function mod(pk(t), 1) for k = 1, . . . , K. Hence, even if in the case of
determinate grid points, the point set (x(cid:96), y(cid:96)) = τ (v(cid:96), sk(2πv(cid:96))) for (cid:96) = 1, . . . , L has similar
statistical properties like a set of i.i.d. samples.
It might be interesting to analyze this
assumption further but we would only assume it in this paper and focus on the regression
problem. This assumption will be validated by numerical examples in Section 4.1.

However, in the presence of multiple modes, the trace τ (v(cid:96), κk(v(cid:96))) of κk(v) in the (cid:96)th
component stets like a noise perturbation in the regression problem (see Figure 5 middle
for an illustration). In this case, (x(cid:96), y(cid:96)) = τ (v(cid:96), sk(2πv(cid:96)) + κk(v(cid:96))) for (cid:96) = 1, . . . , L can be
considered as L i.i.d. samples of a random vector (Xk, Yk) with a noise perturbation in
Yk. Hence, the regression in (8) only results in a rough estimate ¯sk as shown in Figure 5
right. To be more precise, let sE
k (2πx) := E{Yk − sk(2πXk)|Xk = x} be the residual shape

9

function, then ¯sk ≈ sR

k := sk + sE

k . Hence, the residual error of the mode decomposition

r(t) = f (t) −

αk(t)¯sk(2πNkφk(t)) ≈ −

αk(t)sE

k (2πNkφk(t))

K
(cid:88)

k=1

K
(cid:88)

k=1

might be large, if the residual shape functions {sE
k }k are not zero. This motivates the
design of a recursive scheme that repeats the same decomposition procedure to decompose
the residual r(t) until the residual is small as follows.

1 Input: L points of i.i.d. measurement {f (t(cid:96))}(cid:96)=1,...,L with t(cid:96) ∈ [0, 1], instantaneous

phases {pk}k=1,...,K, instantaneous amplitudes {αk}k=1,...,K, an accuracy parameter
(cid:15) < 1, and the maximum iteration number J.

2 Output: generalized shape function estimates {˜sk}k=1,...,K.
3 Initialize: let r(0) = f , (cid:15)1 = (cid:15)2 = 1, (cid:15)0 = 2, the iteration number j = 0, ¯s(0)

k = 0, and

˜sk = 0 for all k = 1, . . . , K.

4 while j < J, (cid:15)1 > (cid:15), (cid:15)2 > (cid:15), and |(cid:15)1 − (cid:15)0| > (cid:15) do
5

For all k, 1 ≤ k ≤ K, deﬁne

h(j)
k =

r(j) ◦ p−1
k
αk ◦ p−1
k

,

and we know it is sampled on grid points v(cid:96) = pk(t(cid:96));
(cid:110)
τ (v(cid:96), h(j)
Observe that
a certain random vector (Xk, Y (j)
k
For all k, 1 ≤ k ≤ K, solve the distribution-free regression problem

) with Xk ∈ [0, 1);

k (v(cid:96)))

(cid:96)=1,...,L

(cid:111)

behaves like a sequence of i.i.d. samples of

¯s(j+1)
k

≈ sR,(j+1)
k

= arg min
s:R→R

E{

(cid:12)
(cid:12)s(2πXk) − Y (j)
(cid:12)

k

(cid:12)
(cid:12)
(cid:12)

2

},

(9)

denotes the numerical solution approximating the ground truth

k

k

where ¯s(j+1)
k
solution sR,(j+1)
;
Update ¯s(j+1)
= ¯s(j+1)
k
Update ˜sk = ˜sk + ¯s(j+1)
Update r(j+1) = r(j) − (cid:80)K
(2πpk(t));
Update (cid:15)0 = (cid:15)1, (cid:15)1 = (cid:107)r(j+1)(cid:107)L2, (cid:15)2 = maxk{(cid:107)¯s(j+1)
Set j = j + 1.

− 1
k
2π
for all k;
k=1 αk(t)¯s(j+1)

(cid:82) 2π
0 ¯s(j+1)

(t)dt for all k;

k

k

k

(cid:107)L2},

6

7

8

9

10

11

12

Algorithm 1: Recursive diﬀeomorphism-based regression (RDBR).

Remark that Line 8 in Algorithm 1 is essential because it is a crucial condition for
the convergence of the recursive scheme as we shall see in Lemma 3.3. It ensures that all
generalized shape functions in each iteration has a zero mean. In practice, it is suﬃcient
to estimate instantaneous amplitude functions {αk(t)} up to an unknown prefactor, (e.g.,
{(cid:98)sk(1)αk(t)} can be estimated by the synchrosqueezed transform but {(cid:98)sk(1)} are not avail-
able), because the unknown prefactor has been absorbed in the shape function estimation
˜sk(t), which will approximate sk(t)/(cid:98)sk(1). Hence, when we reconstruct the kth mode, the
unknown prefactor is cancelled out as follows

(cid:98)sk(1)αk(t)

1
(cid:98)sk(1)

sk(2πpk(t)) = αk(t)sk(2πpk(t)).

10

Similarly, it is suﬃcient that a phase function pk(t) is available up to a constant, e.g., pk(t)−
pk(0) can be estimated by the synchrosqueezed transform but pk(0) is unknown. A shift
in the estimation of a phase function leads to a shift in the estimation of its corresponding
shape function. In the end, the shift is cancelled out when a mode is reconstructed.

Although Algorithm 1 relies on the exact instantaneous amplitudes and phases, numer-
ical examples in Section 4 shows that the algorithm is not sensitive to the input amplitudes
and phases as long as the folding procedure in Line 6 is able to fold the periodic part in
h(j)
k

together.

3.2 Convergence analysis

In this section, an asymptotic analysis on the convergence of the recursive diﬀeomorphism-
based regression (RDBR) method is provided. The partition-based regression method (or
partitioning estimate) in Chapter 4 of [29] will be used. The ﬁrst theorem concerns about
the convergence rate of the estimated regression function to the ground truth regression
function as the number of samples tends to inﬁnity. The second theorem clariﬁes the
conditions that guarantee the convergence of the RDBR. The last theorem shows that the
RDBR method is robust against noise. Before presenting these theorems, some notations
and deﬁnitions are introduced below.

h (assumed to be an integer) parts {[th

Given a small step side h (cid:28) 1, the time domain [0, 1] is uniformly partitioned into
N h = 1
n = nh. The
partition-based regression method with this uniform partition is applied to analyze the
samples of a random vector (X, Y ) with a
RDBR. Suppose (x(cid:96), y(cid:96))(cid:96)=1,...,L are L i.i.d.
ground truth regression function denoted as sR. Let sP
L denote the estimated regression
function by the partition-based regression method with L samples. Following the deﬁnition
in Chapter 4 of [29], we have

n+1)}n=0,...,N h−1, where th

n, th

sR(x) ≈ sP

L (x) :=

(cid:80)L

(cid:96)=1 X[th
n,th
(cid:96)=1 X[th

n+1)(x(cid:96))y(cid:96)
n+1)(x(cid:96))

n,th

(cid:80)L

,

n, th

n+1), where X[th

when x ∈ [th
theorem given in Chapter 4 in [29] estimates the L2 risk of the approximation sP
follows.

n+1)(x) is an indicator function of [th

n+1). The following
L ≈ sR as

n, th

n,th

Theorem 3.1. For the uniform partition with a step side h in [0, 1) as deﬁned just above,
assume that

Var(Y |X = x) ≤ σ2,

x ∈ R,

|sR(x) − sR(z)| ≤ C|x − z|,

x, z ∈ R,

X has a compact support [0, 1), and there are L i.i.d. samples of (X, Y ). Then the partition-
based regression method provides an estimated regression function sP
L to approximate the
ground truth regression function sR, where

with an L2 risk bounded by

sR = arg min
s:R→R

E{|s(2πX) − Y |2},

E(cid:107)sP

L − sR(cid:107)2 ≤ c0

σ2 + (cid:107)sR(cid:107)2
Lh

L∞

+ C2h2,

11

where c0 is a constant independent of the number of samples L, the regression function s,
the step side h, and the Lipschitz continuity constant C.

Other regression methods would also be suitable for the analysis of the RDBR and might
lead to better convergence rate than the one in Theorem 3.1. For the sake of simplicity, we
only focus on the analysis based on Theorem 3.1. To simplify notations, sP will be used
instead of sP
L and s ∈ LC means that s is a Lipschitz continuous function with a constant
C later on.

Denote the set of sampling grid points {t(cid:96)}(cid:96)=1,...,L in Algorithm 1 as T . To estimate the
regression function using the partition-based regression method, T is divided into several
subsets as follows. For i, j = 1, . . . , K, i (cid:54)= j, m, n = 0, . . . , N h − 1, let

T ij
h (m, n) =

(cid:110)

t ∈ T : mod (pi(t), 1) ∈ [th

m, th

m + h), mod (pj(t), 1) ∈ [th

n, th

n + h)

(cid:111)

,

and

(cid:110)

T i
h (m) =

t ∈ T : mod (pi(t), 1) ∈ [th

m, th

m + h)

(cid:111)

,

then T = ∪N h−1

m=0 T i

h (m) = ∪N h−1

m=0 ∪N h−1

n=0 T ij

h (m, n). Let

Dij

h (m, n)

and Di

h(m)

(10)

denote the number of points in T ij

h (m, n) and T i

h (m), respectively.

Deﬁnition 3.2. Suppose fk(t) = αk(t)sk(2πNkφk(t)) is a GIMT of type (M, Nk) for k =
1, . . . , K. Then the collection of phase functions {pk(t)}1≤k≤K is said to be (M, N, K, h, β, γ)-
well-diﬀerentiated and denoted as {pk(t)}1≤k≤K ∈ WD(M, N, K, h, β, γ), if the following
conditions are satisﬁed:

Dij

h (m, n) satisﬁes γ > 0 , where Dij

h (m, n) (and Di

h(m) below) is deﬁned

1. Nk ≥ N for k = 1, . . . , K;

2. γ := min

m,n,i(cid:54)=j

in (10);

3. Let

βi,j :=





N h−1
(cid:88)

m=0

1
h(m)

Di





N h−1
(cid:88)

n=0





1/2

(Dij

h (m, n) − γ)2





for all i (cid:54)= j, then β := max{βi,j : i (cid:54)= j} satisﬁes M 2(K − 1)β < 1.

In the above deﬁnition, γ quantiﬁes the dissimilarity between phase functions. The
If two phases are very similar,
larger γ is, the more dissimilarity phase functions have.
there might be some nearly empty sets T ij
h (m, n) and hence γ is small. If γ is larger, the
numbers {Dij
h (m, n)}m,n are closer and β would be smaller. To guarantee a large γ, N and
L should be suﬃciently large. With these notations deﬁned, it is ready to present the main
analysis of the RDBR.

Let’s recall that in each iteration of Algorithm 1, if we denote the target shape function

as s(j)
k

then the given data is

r(j) =

αk(t)s(j)

k (2πpk(t)).

K
(cid:88)

k=1

12

(11)

In the regression problem

sR,(j+1)
k

= arg min
s:R→R

= arg min
s:R→R

(cid:12)
(cid:12)s(2πXk) − Y (j)
(cid:12)
E{
(cid:12)
(cid:12)s(2πXk) − (Y (j)
(cid:12)
E{

k

(cid:12)
2
(cid:12)
(cid:12)

}

k − s(j)

(cid:12)
(cid:12)
k (2πXk))
(cid:12)

2

} − s(j)
k ,

(12)

(13)

we have

where

sR,(j+1)
k

= s(j)

k + sE,(j)

k

,

sE,(j)
k

(2πx) := E{Y (j)

k − s(j)
due to the perturbation caused by other modes. In the next iteration, the target shape
function s(j+1)
decays
k
as j → ∞.

. Hence, the key convergence analysis is to show that sE,(j)

k (2πXk)|Xk = x} (cid:54)= 0

= −sE,(j)
k

(14)

k

k

Remark that the partition-based regression method is only used to provide a decay rate.
=

In the analysis, we assume that all regression problems are solved exactly, i.e., ¯s(j+1)
sR,(j+1)
k

in Equation (9).

0 s(j)

k (2πt)dt = 0 at each iteration for all k and j. Note that Var(Y (j)

In what follows, we assume that an accuracy parameter (cid:15) is ﬁxed. Furthermore, sup-
pose the given K GIMT’s fk(t) = αk(t)sk(2πNkφk(t)), k = 1, . . . , K, have phases in
WD(M, N, K, h, β, γ), all generalized shape functions and amplitude functions are in the
space LC. Under these conditions, all regression functions s(j)
k ∈ LC and have bounded L∞
norm depending only on M and K. By Line 8 in Algorithm 1, we have the nice and key con-
dition that (cid:82) 1
|Xk = x)
is bounded by a constant depending only on M and K as well. For the ﬁxed (cid:15) and C,
there exists h0((cid:15), M, K, C) such that C2h2 < (cid:15)2 if 0 < h < h0. By the abuse of notation,
O((cid:15)) is used instead of Ch later. By Theorem 3.1, for the ﬁxed (cid:15), M , K, C, and h, there
exists L0((cid:15), M, K, C, h) such that the L2 error of the partition-based regression is bounded
by (cid:15)2. In what follows, h is smaller than h0, L is larger than L0, and hence all estimated
regression functions approximate the ground truth regression function with an L2 error of
order (cid:15). Under these conditions and assumptions, sE,(j)
is shown to decay to O((cid:15)) as j → ∞
and the decay rate will be estimated.

k

k

Lemma 3.3. Under the conditions listed in the paragraph immediately preceding this lemma,
for the given (cid:15),the estimated regression function sP,(j)
of the regression problem in (13) by
the partition-based regression method satisﬁes

k

(cid:107)sP,(j)
k

(cid:107)L2 ≤ O((cid:15)) + M 2(K − 1)β max
1≤k≤K

(cid:107)s(j)

k (cid:107)L2

for all k = 1, . . . , K and j.

in Algorithm 1.

We would like to emphasize that sP,(j)

k

is only used in the analysis and it is not computed

Proof. First, we start with the case when K = 2 and αk(t) = 1 for all t and k.

13

Recall that pk(t) can be considered as a diﬀeomorphism from R to R transforming data

in the t domain to the pk(t) domain. We have introduced the inverse-warping data

h(j)
k (v) = r(j) ◦ p−1
= s(j)

k (v)
k (2πv) +

s(j)
j (2πpj ◦ p−1

k (v))

(cid:88)

j(cid:54)=k

:= s(j)

k (2πv) + κ(j)

k (v),

where v = pk(t). After the folding map

τ :

(v, hk(v)) (cid:55)→

(cid:16)

mod(v, 1), h(j)

k (v)

(cid:17)

,

k (2πv(cid:96))+κ(j)

we have (x(cid:96), y(cid:96)) = τ (v(cid:96), s(j)
k (v(cid:96))) for (cid:96) = 1, . . . , L as L i.i.d. samples of a random
vector (Xk, Y (j)
for all
k at the jth step are known in the analysis, although they are not known in practice. The
partition-based regression method is applied (not necessary to know the distribution of the
random vector (Xk, Y (j)

), where Xk ∈ [0, 1]. We can assume the target shape functions s(j)
k

)) to solve the following regression problem approximately

k

k

arg min
s:R→R

(cid:12)
(cid:12)s(2πXk) − (Y (j)
(cid:12)
E{

k − s(j)

(cid:12)
(cid:12)
k (2πXk))
(cid:12)

2

},

and the solution is denoted as sP,(j)
based regression method, when x ∈ [th

k

. Recall notations in Deﬁnition 3.2. By the partition-
m, th
(cid:16)

m + h),

(cid:17)

sP,(j)
k

(x) =

(cid:80)N h−1
n=0

s(j)
i (2πth
n) + O((cid:15))
Dk
h(m)

Dki

h (m, n)

,

where i = 1 if k = 2 or i = 2 if k = 1, O((cid:15)) comes from the approximation of the LC
function si using the values on grid points th

n. Hence,

|sP,(j)
k

(x)| ≤ O((cid:15)) +

(cid:80)N h−1

n=0 s(j)

n)Dki

h (m, n)

i (2πth
Dk
h(m)
i (2πth
Dk

n) (cid:0)Dki
h(m)

= O((cid:15)) +

(cid:80)N h−1

n=0 s(j)

h (m, n) − γ(cid:1)

+

γ (cid:80)N h−1
n=0 s(j)
Dk
h(m)

i (2πth
n)

.

i ∈ LC and (cid:82) 1

Since s(j)
N hγ = γ/h. Hence,

0 s(j)

i (2πt)dt = 0, | (cid:80)N h−1

n=0 s(j)

i (2πth

n)| ≤ C. Note that Dk

h(m) ≥

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

γ (cid:80)N h−1
n=0 s(j)
Dk
h(m)

i (2πth
n)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤ O((cid:15)),

and

|sP,(j)
k

(x)| ≤ O((cid:15)) +

(cid:80)N h−1

n=0 s(j)

i (2πth
Dk

n) (cid:0)Dki
h(m)

h (m, n) − γ(cid:1)

.

14

By the triangle inequality,

(cid:107)sP,(j)
k

(cid:107)L2 ≤ O((cid:15)) +



N h−1
(cid:88)

(cid:32) (cid:80)N h−1

n=0 s(j)

i (2πth
Dk

h (m, n) − γ(cid:1)

(cid:33)2



1/2

h



≤ O((cid:15)) +

s(j)
i (2πth
n)

m=0

N h−1
(cid:88)

N h−1
(cid:88)

(cid:16)





m=0

n=0

N h−1
(cid:88)

(cid:18) Dki

h (m, n) − γ
h(m)

Dk



1/2

(cid:19)2
 h



= O((cid:15)) +

s(j)
i (2πth
n)

(cid:17)2



1/2 

h





N h−1
(cid:88)

(cid:16)

n=0

N h−1
(cid:88)

N h−1
(cid:88)

(cid:18) Dki

m=0

n=0

h (m, n) − γ
h(m)

Dk



1/2

(cid:19)2




,

n) (cid:0)Dki
h(m)




(cid:17)2





n=0














where the second inequality comes from H¨older’s inequality. Since s(j)

i ∈ LC,





N h−1
(cid:88)

(cid:16)

n=0



1/2

s(j)
i (2πth
n)

(cid:17)2

h



(cid:16)

=

(cid:107)s(j)

i (cid:107)2

L2 + O((cid:15))

(cid:17)1/2

= (cid:107)s(j)

i (cid:107)L2 + O((cid:15)).

Since phase functions are in WD(M, N, h, β, γ),









N h−1
(cid:88)

N h−1
(cid:88)

(cid:18) Dki

m=0

n=0

h (m, n) − γ
h(m)

Dk



1/2

(cid:19)2




≤ β < 1.

Hence,

(cid:107)sP,(j)
k

(cid:107)L2 ≤ O((cid:15)) + β(cid:107)s(j)

i (cid:107)2

L2 ≤ O((cid:15)) + β max
1≤k≤K

(cid:107)s(j)

k (cid:107)L2.

To care the general case, we need to extend the argument to K > 2 and non-constant
αk. We shall do this in two steps: ﬁrst K > 2 but αk ≡ 1 for all k, and then, ﬁnally, K > 2
and varying αk. Rather than repeating the earlier argument in full detail, adapted to these
more general situations, we indicate simply, for both steps, what extra estimates need to
be taken into account. This may not give the sharpest estimate, but this is not a concern
for now.

Next, we prove the case when K > 2 and αk(t) = 1 for all t and k. Similarly, by the

deﬁnition of the partition-based regression and the triangle inequality, we have

|sP,(j)
k

(x)| ≤ O(K(cid:15)) +

(cid:88)

i(cid:54)=k

λi

(cid:80)N h−1

n=0 s(j)

i (2πth
Dk

n) (cid:0)Dki
h(m)

h (m, n) − γ(cid:1)

.

15

Hence, by the triangle inequality and the H¨older inequality again, it holds that

(cid:107)sP,(j)
k

(cid:107)L2 ≤ O(K(cid:15)) +

(cid:88)

N h−1
(cid:88)

(cid:32) (cid:80)N h−1

n=0 s(j)

h (m, n) − γ(cid:1)

(cid:33)2



1/2

h











i(cid:54)=k

m=0

(cid:88)

N h−1
(cid:88)

(cid:16)

i(cid:54)=k
(cid:88)

n=0
β(cid:107)s(j)

i (cid:107)L2

i(cid:54)=k

≤ O(K(cid:15)) +

≤ O(K(cid:15)) +

i (2πth
Dk

n) (cid:0)Dki
h(m)
1/2 

(cid:17)2



h





s(j)
i (2πth
n)

≤ O(K(cid:15)) + (K − 1)β max
1≤k≤K

(cid:107)s(j)

k (cid:107)L2

= O((cid:15)) + (K − 1)β max
1≤k≤K

(cid:107)s(j)

k (cid:107)L2.

N h−1
(cid:88)

N h−1
(cid:88)

(cid:18) Dki





m=0

n=0

h (m, n) − γ
h(m)

Dk



1/2

(cid:19)2




Finally, we prove the case when amplitude functions are smooth functions but not a
constant 1. If the instantaneous frequencies are suﬃciently large, depending on (cid:15), M , K,
and C, amplitude functions are nearly constant up to an approximation error of order
(cid:15). The time domain [0, 1] is divided into suﬃciently small intervals such that amplitude
functions are nearly constant inside each interval. Accordingly, the samples (x(cid:96), y(cid:96)) =
τ (v(cid:96), sk(2πv(cid:96)) + κk(v(cid:96))) for (cid:96) = 1, . . . , L of the random vector (Xk, Y (j)
) is divided into
groups and the partition-based regression method is applied to estimate the regression
function for each group. This is similar to data splitting in nonparametric regression. The
bound of |sP,(j)
(x)| is a weighted average of the bound given by each group, and the weight
comes the number of points in each group over the total number of samples. Note that
(cid:107)αk(cid:107)L∞ ≤ M . By repeating the analysis above, it is simple to show

k

k

(cid:107)sP,(j)
k

(cid:107)L2 ≤ O((cid:15)) + M 2(K − 1)β max
1≤k≤K

(cid:107)s(j)

k (cid:107)L2,

where M 2 comes from

in κk(v) after warping.

αi ◦ p−1
αk ◦ p−1

k (v)
k (v)

Lemma 3.4. Under the conditions in Lemma 3.3, sE,(j)

in (14) satisﬁes

k

(cid:107)sE,(j)
k

(cid:107)L2 ≤ O((cid:15)) + M 2(K − 1)β max
1≤k≤K

(cid:107)s(j)

k (cid:107)L2

for all k = 1, . . . , K and j.

Proof. Let sP,(j)

k

be the estimated regression function constructed in Lemma 3.3, then

(cid:107)sE,(j)
k

(cid:107)L2 ≤ (cid:107)sE,(j)

(cid:107)L2 + (cid:107)sP,(j)
− sP,(j)
k
≤ O((cid:15)) + M 2(K − 1)β max
1≤k≤K

k

k

(cid:107)L2
(cid:107)s(j)

k (cid:107)L2,

by Theorem 3.1 and Lemma 3.3.

16

Theorem 3.5. (Convergence of the RDBR) Under the conditions in Lemma 3.3, we have

max
1≤k≤K

(cid:107)sE,(j)
k

(cid:107)L2 ≤ O(c(cid:15) + (cid:0)M 2(K − 1)β(cid:1)j+1

),

(cid:107)r(j)(cid:107)L2 ≤ O(c(cid:15) + (cid:0)M 2(K − 1)β(cid:1)j

),

where c =
deﬁned in Equation (11).

1−M 2(K−1)β is a ﬁnite number, sE,(j)

k

1

is deﬁned in Equation (14) and r(j) is

Proof. This theorem is an immediate result of Lemma 3.4 by induction. Let

and

and

c1 = M 2(K − 1)β,

c2(j) =

j
(cid:88)

n=0

cn
1 ,

then c2(j) < limj→∞ c2(j) = c for all j and c is a ﬁnite number because 0 < M 2(K −1)β < 1
by the assumption. In the initial step when j = 0, s(j)
k = sk, (cid:107)sk(cid:107)L∞ ≤ M , and (cid:107)αk(cid:107)L∞ ≤
M . Hence, by Lemma 3.4,

max
1≤k≤K

(cid:107)sE,(0)
k

(cid:107)L2 ≤ O((cid:15)) + M 2(K − 1)β max
1≤k≤K
√

≤ O((cid:15)) + M 2(K − 1)β
2πM
= O((cid:15)c2(0) + M 2(K − 1)β),

(cid:107)s(0)

k (cid:107)L2

(cid:107)r(0)(cid:107)L2 ≤

(cid:107)αk(t)sk(2πNkφk(t))(cid:107)L2 ≤ KM 2 = O(1)

K
(cid:88)

k=1

and the conclusion holds. When j (cid:54)= 0, we have

k = −sE,(j−1)
s(j)

k

,

where

max
1≤k≤K

(cid:107)sE,(j−1)

k

(cid:107)L2 ≤ O((cid:15)c2(j − 1) + (cid:0)M 2(K − 1)β(cid:1)j

).

By Lemma 3.4, Equation (15) and (16),

(15)

(16)

for all k. Hence,

By (15) and (16),

(cid:107)sE,(j)
k

(cid:107)L2 ≤ O((cid:15)) + M 2(K − 1)β max
1≤k≤K

(cid:107)s(j)

k (cid:107)L2

≤ O((cid:15)c2(j) + (cid:0)M 2(K − 1)β(cid:1)(j+1)

)

max
1≤k≤K

(cid:107)sE,(j)
k

(cid:107)L2 ≤ O((cid:15)c2(j) + (cid:0)M 2(K − 1)β(cid:1)j+1

).

(cid:107)r(j)(cid:107)L2 = (cid:107)

αk(t)s(j)

k (2πpk(t))(cid:107)L2

K
(cid:88)

k=1
K
(cid:88)

k=1

17

≤

M (cid:107)s(j)

k (2πpk(t))(cid:107)L2

≤ O((cid:15)c2(j − 1) + (cid:0)M 2(K − 1)β(cid:1)j

).

Note that for all j we have 0 < c2(j) < limj→∞ c2(j) = c. Hence, this theorem holds for
j (cid:54)= 0.

Theorem 3.5 shows that the regression function in each step of Algorithm 1 decays, if
M 2(K − 1)β < 1, in the L2 sense up to a ﬁxed accuracy parameter as the iteration number
becomes large. Hence, the recovered shape function ˜sk converges and the residual decays
up to a ﬁxed accuracy parameter, if M 2(K − 1)β < 1. When the iteration number is
suﬃciently large, the accuracy of the RDBR in Theorem 3.5 is as good as a single step of
regression in Theorem 3.1.

Theorem 3.6. (Robustness of the RDBR) Let fk(t) = αk(t)sk(2πNkφk(t)), k = 1, . . . , K,
be K GIMT’s and f (t) = (cid:80)K
k=1 fk(t) + n(t), where n(t) is a random noise with a bounded
variance σ2. Under the other conditions introduced in Theorem 3.5, for the given (cid:15),
∃L0((cid:15), M, K, C, h, σ), if L > L0, then

max
1≤k≤K

(cid:107)sE,(j)
k

(cid:107)L2 ≤ O(c(cid:15) + (cid:0)M 2(K − 1)β(cid:1)j+1

),

and

(cid:107)r(j)(cid:107)L2 ≤ O(c(cid:15) + (cid:0)M 2(K − 1)β(cid:1)j

),

where c =
deﬁned in Equation (11).

1−M 2(K−1)β is a ﬁnite number, sE,(j)

k

1

is deﬁned in Equation (14) and r(j) is

Proof. The proof basically follows the one in Theorem 3.5. The diﬀerence is that the number
of samples in (Xk, Y (j)
) should be large enough, depending on σ2, such that Lemma 3.3 is
still true.

k

Theorem 3.6 shows that as soon as the number of sampling points L is large enough,
the noise eﬀect will be negligible and the RDBR method can still identify generalized shape
functions accurately.

4 Numerical examples

In this section, some numerical examples of synthetic and real data are provided to demon-
strate the proposed properties of the RDBR. We apply the least squares spline regression
method with free knots in [30] to solve all the regression problems in this paper. The im-
plementation of this method is available online2. In all synthetic examples, we assume the
fundamental instantaneous phases and amplitudes are known and only focus on verifying
In real examples, we apply the one-dimensional
the theory of the RDBR in Section 3.
synchrosqueezed wave packet transform (SSWPT) to estimate instantaneous phases and
amplitudes as inputs of the RDBR. The implementation of the SSWPT is also publicly
available in SynLab3. The code for the RDBR will be available online shortly4.

Before presenting results, we would like to summarize the main parameters in the above
packages and in Algorithm 1. In the spline regression with free knots, main parameters are

• nk: the number of free knots;

2Available
approximation.

3Available at https://github.com/HaizhaoYang/SynLab.
4Will be available at https://github.com/HaizhaoYang/DeCom.

at

https://www.mathworks.com/matlabcentral/ﬁleexchange/25872-free-knot-spline-

18

• krf : the knot removal factor, a number quantifying how likely a free knot would be

removed;

• ord: the highest degree of spline polynomials.

In SynLab, main parameters are

• s: a geometric scaling parameter;

• rad: the support size of the mother wave packet in the Fourier domain;

• red: a redundancy parameter, the number of frames in the wave packet transform;

• (cid:15)sst: a threshold for the wave packet coeﬃcients.

In Algorithm 1, main parameters are

• mIter: the maximum number of iterations allowed;

• (cid:15): the accuracy parameter.

For the purpose of convenience, the synthetic data is deﬁned in [0, 1] and sampled on a
uniform grid. All these parameters in diﬀerent examples are summarized in Table 1.

ﬁgure nk

krf

ord

s

rad

red

6
7 (left)
7 (middle)
7 (right)
8 (clean)
8 (noisy)
9 (clean)
9 (noisy)
11 (clean)
11 (noisy)
12-14 (clean)
12-14 (noisy)
15 (noisy)

20
20
20
20
20
20
20
20
20
20
20
20
20

1.01
1.01
1.01
1.01
1.01
1.0001
1.01
1.01
1.01
1.001
1.001
1.001
1.01

3
3
3
3
3
3
2
2
3
3
3
3
3

–
–
–
–
–
–
–
–
–
–
0.66
0.66
0.66

–
–
–
–
–
–
–
–
–
–
1
1
1

(cid:15)sst mIter
4000
–
9
–
200
–
–
–
200
–
200
–
200
–
200
–
200
–
200
–
200
1e-3
200
1e-3
200
1e-3

(cid:15)

1e-6
1e-13
1e-13
–
1e-6
1e-10
1e-6
1e-6
1e-6
1e-6
1e-10
1e-10
1e-10

L
216
212
–
–
212
216
212
216
212
216
214
216
1600

–
–
–
–
–
–
–
–
–
–
8
8
20

Table 1: Parameters in the spline regression, SynLab, and Algorithm 1. The notation “–”
means the corresponding parameter is not used or its value can be found in the description
of its corresponding example.

In the noisy synthetic examples, Gaussian random noise with a distribution N (σ2, 0) is

used. We follow the deﬁnition of the signal-to-noise ration (SNR) in [19]:

SNR[dB] = min

10 log10

(cid:26)

(cid:19)

(cid:18) (cid:107)fi(cid:107)L2
σ2

(cid:27)

, 1 ≤ i ≤ K

,

(17)

where {fi}K

i=1 are the generalized modes contained in the signal f (t) to be analyzed.

19

Figure 6: Histograms of the point sets S0 (left column), S1 (middle column), and S2 (right
column) with a uniform bin size 0.02. Here S1 and S2 are deﬁned in Equation 18 and
Equation 19, respectively, and S0 is deﬁned right below Equation 19. From top to bottom,
the number of samples in Sk (for all k = 0, 1, and 2) is L = 212, 214, and 216, respectively.
These histograms show that points in S1 and S2 are approximately uniformly distributed
in [0, 1).

20

4.1 Numerical distribution of sampling points

In this section, we provide numerical examples to support the assumption that, the col-
lection of samples after warping and folding behaves essentially like a collection of i.i.d.
samples, in the analysis of the RDBR in Section 3.

Let us revisit the example in (4) and choose its instantaneous phase functions

and

and

and

to deﬁne warping and folding maps

p1(t) = 60(t + 0.01 sin(2πt))

p2(t) = 90(t + 0.01 cos(2πt))

τ1 :

t (cid:55)→ mod(p1(t), 1),

τ2 :

t (cid:55)→ mod(p2(t), 1).

Let T denote the collection of L uniform grid points {tn}n=0,...,L−1 in [0, 1] with a step
side 1/L and tn = n/L. The warping and folding map τ1 (or τ2) acts like a pseudorandom
number generator mapping T to a collection of i.i.d. samples of a random variable X with
a uniform distribution in [0, 1], i.e., sample points in

S1 = τ1(T )

S2 = τ2(T )

(18)

(19)

are approximately uniformly distributed in [0, 1]. To support this claim numerically, we
randomly sample L points from a random variable with a uniform distribution in [0, 1] and
denote this set of samples as S0. The distribution of Sk for k = 0, 1, and 2, when L = 212,
214, and 216, are summarized in Figure 6. Figure 6 shows that points in S1 and S2 have a
more uniform distribution than those in S0. Hence, S1 and S2 would lead to better results
in the regression than S0.

4.2 Convergence of the RDBR

In this section, numerical examples are provided to verify the convergence analysis in Section
3. In the analysis, for a ﬁxed accuracy parameter (cid:15), we have shown that as long as the
fundamental instantaneous frequencies are suﬃciently high and the number of samples is
large enough, the RDBR is able to estimate shape functions from a class of superpositions
of generalized modes. The residual error in the iterative scheme linearly converges to a
quantity of order (cid:15). Since it is diﬃcult to specify the relation of the rate of convergence
and other parameters explicitly in the analysis, we provide numerical examples to study
this rate quantitatively.

In all examples in this section, we consider a simple case when the signal has two
components with piecewise linear and continuous generalized shapes. This makes it easier
to verify the convergence analysis. For example, we consider signals of the form

f (t) = f1(t) + f2(t),

(20)

21

Figure 7: Numerical results of the signal in (20) when N = 2. Left: the ground truth shape
function s1 and its estimation by the RDBR. Middle: the ground truth shape function s2
and its estimation by the RDBR. Right: the L2-norm of residual r(j) in the jth iteration,
i.e., (cid:15)1 in Algorithm 1.

where

and

f1(t) = α1(t)s1(2πN φ1(t)) = (1 + 0.05 sin(4πx))s1 (2πN (x + 0.006 sin(2πx)))

f2(t) = α2(t)s2(2πN φ2(t)) = (1 + 0.05 cos(2πx))s1 (2πN (x + 0.006 cos(2πx))) ,

s1(t) and s2(t) are generalized shape functions deﬁned in [0, 1] as shown in Figure 7.

In the ﬁrst example of this section, we show that the RDBR still converges even if the
fundamental instantaneous frequencies are very low, i.e., the signal only contains a few
periods of oscillation. Figure 7 shows the numerical results of a signal when N = 2 in
(20) and L = 216 samples on a uniform grid in [0, 1]. This is a challenging case when
there are approximately two periods in each mode. Although we cannot prove a linear
convergence in this case, Figure 7 (right) shows that the RDBR converges with a sublinear
convergence rate. With a suﬃciently large iteration number, the RDBR is able to identify
shape functions with a reasonably good accuracy as shown in Figure 7 (left and middle).
The capability of handling low-frequency modes is attractive to people working on real-time
data, in which the shape function might change in time and such changes are interesting to
track; in this case, only the information within a few consecutive periods can be used for
shape function extraction (see [28] for more references).

In the second example in this section, we ﬁx the number of samples L = 212, vary
the parameter N in (20), and estimate the convergence rate numerically. By Theorem 3.5
(adapted to the example in this section), the residual norm (cid:15)1 in Algorithm 1 converges to
O((cid:15)) as follows

Hence, if we deﬁne a sequence {µj} by

and a sequence {ηj} by

(cid:15)(j)
1 = O((cid:15)) + βjO(1).

µj = log(|(cid:15)(j−1)

1

− (cid:15)(j)

1 |).

ηj = µj − µj+1,

22

Figure 8: Left: Estimated convergence rates β in diﬀerent iteration steps when diﬀerent
values are assigned to N in (20). Middle: the relation of the ﬁnal residual norm (cid:15)(j)
(after
1
the RDBR has been terminated) and the number of samples L. Right: the relation of the
regression error in the L2-norm and the number of samples L.

then ηj approximately quantiﬁes the convergence in the jth iteration, and should be nearly
a constant close to − log(β). Figure 8 (left) visualizes the sequences {ηj} generated from
It shows that when the fundamental frequency N is
diﬀerent signals with various N ’s.
suﬃciently large, {ηj} are approximately a constant for all j and hence the convergence is
linear; when N is small, the RDBR converges sublinearly since ηj > 0 for all j and {ηj}
decays as j becomes large. Remark that the convergence analysis is valid up to an O((cid:15))
accuracy, i.e., once the residual is reduced to O((cid:15)), it might not be reduced any further
and, in the worst case, it might even increase again due to the numerical error in the spline
regression with free knots. Hence, we only show results in the ﬁrst few iterations in Figure
8 (left) to verify the convergence rate. Actually in the next example will illustrate the eﬀect
of the error in the spline regression on the accuracy of the RDBR.

In the last example of this section, we ﬁxed N = 100, only vary the number of samples
L = 2m with m = 7, 8, . . . , 12, and compare the accuracy of the RDBR and the spline
regression with free knots. To obtain results with an accuracy as high as possible, we let
maxIter = 200 and (cid:15) = 1e − 13. Figure 8 (middle) shows that the ﬁnal residual norm (cid:15)1
after the RDBR essentially decays in L with the exception of the two largest values of L.
To understand the two exceptions observed in Figure 8 (middle), let us check the eﬀect
of the error in the spline regression on the accuracy of the RDBR. Recall that the ﬁnal
residual norm after the RDBR depends on the accuracy of the regression in Lemma 3.3
by the analysis in Theorem 3.5. Although Theorem 3.1 considers only the partition-based
regression, a similar conclusion holds for the spline regression (see Chapter 14 in [29]).
Hence, if the number of samples L increases to inﬁnity, the regression error is reduced to
a small constant depends on other parameters, i.e., the solution of the regression problem
cannot be improved any more by increasing L. Therefore, the accuracy of the RDBR
might not be improved by increasing L if L has been large enough. This explains the two
exceptions in Figure 8 (middle).

To further verify the explanation in the last paragraph, we check the accuracy of the
spline regression when L is increased. Recall that, in each iteration of the RDBR, the
estimation of each shape function is perturbed by other modes. For the example considered
here, in the ﬁrst iteration, when we try to estimate s1 by regression, another mode f2 acts
like a noise perturbation with a nonzero mean and a bounded variance determined by the
amplitude function and the shape function in f2. By the formula of f2, the largest amount

23

perturbed is approximately 0.5. Hence, we use a toy example

Y = s1(2πX) + ns,

where X is a random variable with a uniform distribution in [0, 1], and ns is a random
variable with a zero mean and a uniform distribution in [−0.5, 0.5]. L samples of the
random vector (X, Y ) are generated independently. The spline regression with free knots
is applied to estimate s1(2πx) from these samples and its L2 regression error deﬁned in
Theorem 3.1 is recorded. Figure 8 (right) shows the regression errors with diﬀerent L’s.
As we can see, the regression error cannot be further reduced by increasing L once L has
reached almost the same (large) critical value as in Figure 8 (middle). This agrees with the
explanation in the last paragraph. Remark that the accuracy in Figure 8 (middle) is much
higher than the one in Figure 8 (right), and the decay rate is larger as well, indicating the
possibility that the accuracy of the recursive scheme in the RDBR exceeds that of a single
regression.

4.3 Synthetic examples

In this section, we apply the RDBR to examples with known instantaneous properties
in various generalized mode decomposition problems. To make it easier to compare the
RDBR with other methods, we follow the examples in the paper of the diﬀeomorphism-
based spectral analysis (DSA) method in [19], since [19] provides various examples with
diﬀerent shape functions. We will apply the RDBR to the examples in Figure 16, 17, and
18 in [19], without replicating the results of the DSA here. For more details about setting
up these examples, the reader is referred to [19]. As for the parameters in the RDBR, please
see Table 1.

The ﬁrst example in this section, corresponding to the example in Figure 17 and 18
in [19], contains two generalized modes generated with two ECG shape functions shown
in Figure 9. Figure 9 (left two graphs) shows the recovered shape functions, as compared
with the ground truth shape functions, when the synthetic data is clean. Figure 9 (right
two graphs) shows the recovered shape functions when the signal-to-noise ratio (SNR as
deﬁned in Equation (17)) is −3 dB. Note that the SNR in the example in Figure 17 and
18 in [19] is 0 dB, which is larger than the one in our example. Comparing Figure 17 in
[19] and Figure 9, we see that the RDBR is more accurate than the DSA.

Figure 9: Recovered shapes in clean (left) and noisy (right) examples, as compared with
ground truth shapes.

The second example in this section, corresponding to the example in Figure 16 in [19],
contains two generalized modes generated with two piecewise constant shape functions,

24

which is shown in Figure 10. Figure 10 (left two graphs) shows the recovered shape func-
tions, as compared with the ground truth shape functions, when the synthetic data is clean.
Figure 10 (right two graphs) shows the recovered shape functions when SNR = −3 dB.
Again, the SNR in the example in Figure 16 in [19] is 0 dB, meaning that our example
here is noisier than that in [19], and we obtained better results, even though the results
in [19] are improved by additional TV-norm minimization to remove noise and the Gibbs
phenomenon around discontinuous points in shape functions. Comparing Figure 16 in [19]
and Figure 10, we see that the RDBR, even without post-processing, is competitive with
the DSA.

Figure 10: Recovered shapes in clean (left) and noisy (right) examples, as compared with
ground truth shapes.

In the last example of this section, we apply the RDBR to a very challenging case, in
which the signal f (t) contains four modes with close instantaneous frequencies (see Figure
11) given below.

f (t) = f1(t) + f2(t) + f3(t) + f4(t),

(21)

where

fk(t) = sk(2πN φk(t)),

φk(t) = t + 0.05(k − 1) + 0.01 sin(2π(t + 0.05(k − 1))),

for k = 1, . . . , 4, N = 200, and {sk(t)}k=1,...,4 are visualized in Figure 12. As shown in
Figure 12, the RDBR is able to estimate shape functions precisely from clean data. In the
case of very noisy data when SNR = −3 dB, even if the instantaneous frequencies are very
close, the RDBR is still able to recover shape functions with a reasonably good accuracy.

4.4 Practical applications

In this section, we provide two examples to demonstrate the capability of the RDBR in
practical applications when instantaneous properties are not known. The synchrosqueezed
transform as implemented in [19] is applied to estimate these properties as inputs of the
RDBR. These inputs may contain systematic error due the synchrosqueezed transform, but
the RDBR is still able to estimate the shape functions precisely. The ﬁrst example is a
generalized mode decomposition similar to the example of Figure 9 that used ECG shape
functions. To make the problem more challenging, instantaneous frequencies are much
smaller and more similar in this example. Let us deﬁne

f (t) = α1(t)s1(2πN1φ1(t)) + α2(t)s2(2πN2φ2(t)),

where α1(t) = 1 + 0.05 sin(2πt), α2(t) = 1 + 0.05 cos(2πt), N1 = 32, N2 = 48, φ1(t) =
t + 0.001 sin(2πt), and φ2(t) = t + 0.001 cos(2πt).

25

Figure 11: Instantaneous frequencies of the example in (21).

Figure 12: From left to right, the ground truth shape functions sk(2πt) for k = 1, . . . , 4
(in red) and their estimations by the RDBR (in blue). From top to buttom, the results
recovered from a clean signal and a noisy signal with SNR = −3 dB.

A clean signal and a noisy signal with SNR = −3 dB were analyzed. The SSWPT in
[19] was applied to estimate fundamental instantaneous properties and results are shown
in Figure 13 and 14. Inputing these properties in the RDBR, we obtained estimated shape
functions contained in f (t) as shown in Figure 15. Note that even though the estimated
instantaneous properties have large errors, especially in the noisy case, the RDBR is still
able to give reasonably good shape estimation.

In the last example, we apply the RDBR to analyze daily atmospheric CO2 concen-
tration data in [31]. The data were observed by National Oceanic and Atmospheric Ad-
ministration at Mauna Loa (MLO) in recent 31 years (1981-2011). As shown in Figure 16
(top), there is a smooth growing trend in the original data. To focus on the oscillatory pat-
tern, this trend is approximated by a linear function and removed from the original data.
The SSWPT is applied to estimate fundamental instantaneous properties of the residual
data. As shown in Figure 17 (left), the synchrosqueezed energy distribution indicates only

26

Figure 13: Recovered fundamental instantaneous frequencies in clean (left) and noisy (right)
examples by the synchrosqueezed transform in [19], as compared with ground truth shapes.

Figure 14: Recovered fundamental instantaneous amplitudes (up to an unknown factor)
in clean (left) and noisy (right) examples by the synchrosqueezed transform in [19], as
compared with ground truth shapes.

Figure 15: Recovered shapes in clean (left) and noisy (right) examples, as compared with
ground truth shapes.

one fundamental component. The semiannual component has a instantaneous frequency
that is nearly twice of the one of the annual component. The RDBR is applied to the
residual data with the estimated fundamental properties by the SSWPT. Figure 17 (right)
shows the estimated shape function contained in the residual data. This shape function
reﬂects a nonlinear evolution pattern in a year: the CO2 concentration usually increases in
a longer period and decreases in a shorter period. As explained in [31], this special pattern
comes from seasonal photosynthetic drawdown and respiratory release of CO2 by terrestrial
ecosystems.

27

Figure 16: Top: original CO2 concentration data. Bottom: the residual CO2 concentration
data after removing a smooth trend.

Figure 17: Left: the synchrosqueezed energy distribution of the CO2 concentration data in
the low frequency part. Right: estimated shape function by the RDBR.

5 Conclusion

This paper introduced a recursive diﬀeomorphism-based regression method (RDBR) for es-
timating shape functions from a superposition of generalized intrinsic mode type functions
(GIMT). Combining the RDBR with other methods for estimating instantaneous proper-
ties of GIMT’s, namely, synchrosqueezed transforms [12], adaptive optimization [13, 14],
recursive ﬁltering [15, 16], we provide an alternative solution to the generalized mode de-
composition problem. As we have shown theoretically and numerically, once the instanta-
neous properties are accurate, the RDBR is a precise and robust method to estimate shape
function, as long as instantaneous phases of these oscillatory modes are well-diﬀerentiated.
The convergence of the RDBR is linear if instantaneous frequencies are suﬃciently large.
Numerical observation suggests that the RDBR converges sublinearly if instantaneous fre-
quencies are small.

Acknowledgments. H.Y. thanks the support of the AMS-Simons Travel Award and
the National Science Foundation under grants ACI-1450280, and the startup grant from
the Department of Mathematrics at the National University of Singapore.

References

[1] Hau-Tieng Wu, Yi-Hsin Chan, Yu-Ting Lin, and Yung-Hsin Yeh. Using synchrosqueez-
ing transform to discover breathing dynamics from ECG signals. Applied and Compu-

28

tational Harmonic Analysis, 36(2):354 – 359, 2014.

[2] Emmanuel J. Cand`es, Philip R. Charlton, and Hannes Helgason. Detecting highly
oscillatory signals by chirplet path pursuit. Applied and Computational Harmonic
Analysis, 24(1):14 – 40, 2008.

[3] Haizhao Yang, Jianfeng Lu, and Lexing Ying. Crystal image analysis using 2D syn-
chrosqueezed transforms. Multiscale Modeling & Simulation, 13(4):1542–1572, 2015.

[4] Wei Huang, Zheng Shen, Norden E. Huang, and Yuan Cheng Fung. Engineering
analysis of biological variables: An example of blood pressure over 1 day. Proc. Natl.
Acad. Sci., 95, 1998.

[5] Jean B. Tary, Roberto H. Herrera, Jiajun Han, and Mirko van der Baan. Spectral
estimation-What is new? What is next? Rev. Geophys., 52(4):723–749, December
2014.

[6] Haizhao Yang and Lexing Ying.
dimensional mode decomposition.
46(3):2052–2083, 2014.

Synchrosqueezed curvelet transform for two-
SIAM Journal on Mathematical Analysis,

[7] Haizhao Yang, Jianfeng Lu, W.P. Brown, I. Daubechies, and Lexing Ying. Quantitative
canvas weave analysis using 2-D synchrosqueezed transforms: Application of time-
frequency analysis to art investigation. Signal Processing Magazine, IEEE, 32(4):55–
63, July 2015.

[8] Zhiyao Duan, Yungang Zhang, Changshui Zhang, and Zhenwei Shi. Unsupervised
single-channel music source separation by average harmonic structure modeling. IEEE
Transactions on Audio, Speech, and Language Processing, 16(4):766–778, May 2008.

[9] Norden E. Huang, Zheng Shen, Steven R. Long, Manli C. Wu, Hsing H. Shih, Quanan
Zheng, Nai-Chyuan Yen, Chi Chao Tung, and Henry H. Liu. The empirical mode
decomposition and the Hilbert spectrum for nonlinear and non-stationary time series
analysis. R. Soc. Lond. Proc. Ser. A Math. Phys. Eng. Sci., 454(1971):903–995, 1998.

[10] Franq¸cois Auger and Patrick Flandrin. Improving the readability of time-frequency
and time-scale representations by the reassignment method. Signal Processing, IEEE
Transactions on, 43(5):1068 –1089, 1995.

[11] Eric Chassande-Mottin, Francois Auger, and Patrick Flandrin. Time-frequency/time-
scale reassignment. In Wavelets and signal processing, Appl. Numer. Harmon. Anal.,
pages 233–267. Birkh¨auser Boston, Boston, MA, 2003.

[12] Ingrid Daubechies, Jianfeng Lu, and Hau-Tieng Wu. Synchrosqueezed wavelet trans-
forms: an empirical mode decomposition-like tool. Appl. Comput. Harmon. Anal.,
30(2):243–261, 2011.

[13] Konstantin Dragomiretskiy and Dominique Zosso. Variational mode decomposition.

Signal Processing, IEEE Transactions on, 62(3):531–544, Feb 2014.

[14] Thomas Y. Hou and Zuoqiang Shi. Data-driven timefrequency analysis. Applied and

Computational Harmonic Analysis, 35(2):284 – 308, 2013.

29

[15] Antonio Cicone, Jingfang Liu, and Haomin Zhou. Adaptive local iterative ﬁltering for
signal decomposition and instantaneous frequency analysis. Applied and Computational
Harmonic Analysis, pages –, 2016.

[16] Luan Lin, Yang Wang, and Haomin Zhou. Iterative ﬁltering as an alternative algorithm
for empirical mode decomposition. Advances in Adaptive Data Analysis, 01(04):543–
560, 2009.

[17] Charles K. Chui and H.N. Mhaskar. Signal decomposition and analysis via extraction
of frequencies. Applied and Computational Harmonic Analysis, 40(1):97 – 136, 2016.

[18] J´erˆome Gilles. Empirical wavelet transform. Signal Processing, IEEE Transactions on,

61(16):3999–4010, 2013.

[19] Haizhao Yang. Synchrosqueezed wave packet transforms and diﬀeomorphism based
spectral analysis for 1d general mode decompositions. Applied and Computational
Harmonic Analysis, 39(1):33 – 66, 2015.

[20] Charles K. Chui, Yu-Ting Lin, and Hau-Tieng Wu. Real-time dynamics acquisition
from irregular samples with application to anesthesia evaluation. Analysis and Appli-
cations, 14(04):537–590, 2016.

[21] Thomas Y. Hou and Zuoqiang Shi. Extracting a shape function for a signal with
intra-wave frequency modulation. Philosophical Transactions of the Royal Society of
London A: Mathematical, Physical and Engineering Sciences, 374(2065), 2016.

[22] Gaurav Thakur and Hau-Tieng Wu. Synchrosqueezing-based recovery of instantaneous
frequency from nonuniform samples. SIAM J. Math. Analysis, 43(5):2078–2095, 2011.

[23] Haizhao Yang and Lexing Ying. Synchrosqueezed wave packet transform for 2D mode

decomposition. SIAM Journal of Imaging Science, 2013.

[24] Ratikanta Behera, Sylvain Meignen, and Thomas Oberlin. Theoretical Analysis of the
Second-order Synchrosqueezing Transform. working paper or preprint, December 2015.

[25] Haizhao Yang. Statistical analysis of synchrosqueezed transforms, 2014. preprint,

arXiv:1410.5939 [math.ST].

[26] Ingrid Daubechies, Yi (Grace) Wang, and Hau-tieng Wu. Conceft: concentration
of frequency and time via a multitapered synchrosqueezed transform. Philosophical
Transactions of the Royal Society of London A: Mathematical, Physical and Engineer-
ing Sciences, 374(2065), 2016.

[27] Laurent Demanet and Lexing Ying. Wave atoms and sparsity of oscillatory patterns.

Appl. Comput. Harmon. Anal., 23(3):368–387, 2007.

[28] Chen-Yun Lin, Su Li, and Hau-Tieng Wu. Wave-shape function analysis – when
ceptrum meets time-frequency analysis. arXiv:1605.01805[physics.data-an], 2016.

[29] L´aszl´o Gy¨orﬁ, Micael Kohler, Adam Krzy˙zak, and Harro Walk. A distribution-free
theory of nonparametric regression. Springer series in statistics. Springer, New York,
Berlin, Paris, 2002. Autre(s) tirage(s) : 2010.

30

[30] David L. B. Jupp. Approximation to data by splines with free knots. SIAM Journal

on Numerical Analysis, 15(2):328–343, 1978.

[31] Zhaohua Wu, Norden E. Huang, and Xianyao Chen. Some considerations on physical

analysis of data. Advances in Adaptive Data Analysis, 3(1-2):95–113, 2011.

31

