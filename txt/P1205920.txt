Improving Review Representations with User Attention
and Product Attention for Sentiment Classiﬁcation

Zhen Wu, Xin-Yu Dai∗, Cunyan Yin, Shujian Huang, Jiajun Chen
National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, 210023, China
Collaborative Innovation Center of Novel Software Technology and Industrialization, Nanjing, 210023, China
wuz@nlp.nju.edu.cn, {daixinyu,yincy,huangsj,chenjj}@nju.edu.cn

8
1
0
2
 
n
a
J
 
4
2
 
 
]
L
C
.
s
c
[
 
 
1
v
1
6
8
7
0
.
1
0
8
1
:
v
i
X
r
a

Abstract

Neural network methods have achieved great success in
reviews sentiment classiﬁcation. Recently, some works
achieved improvement by incorporating user and product in-
formation to generate a review representation. However, in re-
views, we observe that some words or sentences show strong
user’s preference, and some others tend to indicate product’s
characteristic. The two kinds of information play different
roles in determining the sentiment label of a review. There-
fore, it is not reasonable to encode user and product informa-
tion together into one representation. In this paper, we pro-
pose a novel framework to encode user and product infor-
mation. Firstly, we apply two individual hierarchical neural
networks to generate two representations, with user attention
or with product attention. Then, we design a combined strat-
egy to make full use of the two representations for training
and ﬁnal prediction. The experimental results show that our
model obviously outperforms other state-of-the-art methods
on IMDB and Yelp datasets. Through the visualization of at-
tention over words related to user or product, we validate our
observation mentioned above.

Introduction
Sentiment analysis aims to determine people’s attitudes to-
wards some topic or the overall polarity to a document, in-
teraction, or event. In recent years, sentiment analysis draws
increasing attention of researchers and industries because of
the rapid growth of online review sites such as Amazon, Yelp
and IMDB. In this work, we focus on the task of document-
level review sentiment classiﬁcation, which is a fundamen-
tal task in the ﬁeld of sentiment analysis and opinion min-
ing (Pang and Lee 2008). The task aims to infer the overall
sentiment intensity (e.g. 1-5 stars on the review site Yelp) of
review documents written by users for products.

Dominating studies follow (Pang and Lee 2005; Pang,
Lee, and Vaithyanathan 2002) and take sentiment classiﬁ-
cation as a special case of text classiﬁcation problem. They
usually regard user-marked sentiment polarities or ratings as
labels and use machine learning algorithms to build senti-
ment classiﬁers with text features. Following the idea, many
works devote to designing effective features from text (Pang,

∗Corresponding author.

Copyright c(cid:13) 2018, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

Lee, and Vaithyanathan 2002; Qu, Ifrim, and Weikum 2010)
or additional sentiment lexicons (Ding, Liu, and Yu 2008;
Taboada et al. 2011; Kiritchenko, Zhu, and Mohammad
2014). Motivated by the great success of deep learning in
computer vision (Krizhevsky, Sutskever, and Hinton 2012),
speech recognition (Dahl et al. 2012) and natural language
processing (Bengio et al. 2003), more recent methods use
neural networks to learn low-dimensional and continuous
text representations without any feature engineering (Glorot,
Bordes, and Bengio 2011; Socher et al. 2011; Socher et al.
2012; Socher et al. 2013; Kim 2014). These models achieve
very competitive performances in sentiment classiﬁcation.

Despite neural network based approaches have been quite
effective for sentiment classiﬁcation (Johnson and Zhang
2015; Tang, Qin, and Liu 2015a), they typically only fo-
cus on the text content while ignoring the crucial inﬂuences
of users and products. It is a common sense that the user’s
preference and product’s characteristic make a signiﬁcant
effect on the ratings. For different users, same word might
express different emotional intensity. For example, a lenient
user may use “good” to evaluate an ordinary product while
a critical user might use “good” to express an excellent atti-
tude. Similarly, product’s characteristic also have an effect
on review ratings. Reviews of high-quality products tend
to receive higher ratings compared to those of low-quality
products.

In order to incorporate user and product information into
sentiment classiﬁcation, Tang, Qin, and Liu (2015b) intro-
duce a word-level preference matrix and a representation
vector for each user and product into CNN sentiment clas-
siﬁer. The model achieves some improvements, but suf-
fers from high model complexity and only considers word-
level user and product information rather than semantic-
level. Chen et al. (2016a) consider user and product infor-
mation together and incorporate them into one review rep-
resentation via attention mechanism (Bahdanau, Cho, and
Bengio 2015). However, in reviews, we observe that some
words or sentences show strong user’s preference, and some
others tend to indicate product’s characteristic. For example,
for the review “the bar area is deﬁnitely good ‘people watch-
ing’ and i love the modern contemporary d´ecor.”, the word
“good”, “modern” and “contemporary” describe the charac-
teristic of product, and the “love” shows strong user’s sen-
timent. Opinions are more related to products and emotions

are more centered on the user. They are called rational eval-
uation and emotional evaluation respectively by Liu (2012).
Obviously, the two kinds of information have different ef-
fects on inferring sentiment label of the review. Intuitively,
a review has different latent semantic representations with
different views from users or products. Therefore, it is un-
reasonable to encode user and product information together
into one representation.

In this paper, we address the above issues by encoding
user and product information, respectively, into two hierar-
chical networks to generate two individual text representa-
tions with user attention or product attention. Then, we de-
sign a combined strategy to make most use of the two repre-
sentations for training and ﬁnal prediction, which proves ef-
fective. The experimental results show that our model obvi-
ously outperforms other state-of-the-art methods on IMDB
and Yelp datasets. We open the source code in GitHub.1
The main contributions of our work are as follows:

• We propose a novel framework to encode review from
two views for sentiment classiﬁcation. With user atten-
tion and product attention, respectively, two representa-
tions are generated, which are concatenated for further
classiﬁcation.

• For better learning the neural network, we introduce
a combined strategy to improve review representations.
With a weighted loss function, better representations from
two views can be achieved and further help sentiment
classiﬁcation.

• The experimental results demonstrate that our model
achieves obvious and consistent improvements compared
to all state-of-the-art methods. Some visualization cases
also validate the effectiveness and interpretability of our
method.

Background

Long Short-Term Memory
Long Short-Term Memory(LSTM) (Hochreiter and Schmid-
huber 1997) is widely used for text modeling because of
its excellent performance on sequence modeling, especially
for long documents. In order to address the problem of
long-term dependencies, the LSTM architecture introduces
a memory cell that is able to preserve cell state over long
periods of time.

There are three gates to protect and control the state ﬂow
in LSTM unit. At each time step t, given an input vector xt,
the current cell state ct and hidden state ht can be updated
with previous cell state ct−1 and hidden state ht−1 as fol-
lows:

(cid:35)

(cid:34) it
ft
ot

(cid:35)

(cid:34)σ
σ
σ

=

(W [ht−1; xt] + b) ,

ˆct = tanh (Wc [ht−1; xt] + bc) ,
ct = ft (cid:12) ˆct−1 + it (cid:12) ˆct,
ht = ot (cid:12) tanh(ct),

(1)

(2)
(3)
(4)

1https://github.com/wuzhen247/HUAPA

where it, ft and ot are gate activations and in [0, 1], σ is
the logistic sigmoid function and (cid:12) stands for element-wise
multiplication. Intuitively, the forget gate ft controls the ex-
tent to which the previous memory cell is forgotten, the in-
put gate it controls how much each unit is updated, and the
output gate ot controls the exposure of the internal mem-
ory state. The hidden state ht denotes output information of
LSTM unit’s internal memory cell.

In order to increase the amount of input information avail-
able to the network, a more common approach is to adopt
bidirectional LSTM to model text semantics both from for-
ward and backward. For sequence vectors [x1, x2, · · · , xT ],
the forward LSTM reads sequence from x1 to xT and the
backward LSTM reads sequence from xT to x1. Then we
−→
ht and backward hid-
concatenate the forward hidden state
←−
, where the [·; ·] denotes con-
ht
den state
catenation operation. The ht summarizes the information of
the whole sequence centered around xt.

←−
ht, i.e., ht =

(cid:104)−→
ht;

(cid:105)

Attention Mechanism
Inspired by human visual attention, the attention mecha-
nism is proposed by Bahdanau, Cho, and Bengio (2015) in
machine translation, which is introduced into the Encoder-
Decoder framework to select the reference words in source
language for words in target language. It is also used in im-
age caption generation (Xu et al. 2015), parsing (Vinyals et
al. 2015), natural language question answering (Sukhbaatar
et al. 2015). Yang et al. (2016) and Chen et al. (2016a) ex-
plore hierarchical attention mechanism to select informative
words or sentences for the semantics of document.

Document-level Sentiment Classiﬁcation
Document-level sentiment classiﬁcation usually aims to pre-
dict the corresponding sentiment label of review text. In gen-
eral, a review is written by a user u ∈ U for a product p ∈ P .
We denote the review as a document d with n sentences
{s1, s2, · · · , sn} and li is the length of i-th sentence. The
i-th sentence si consists of li words {wi1, wi2, · · · , wili}.
For modelling document-level text semantics, we can em-
ploy bidirectional LSTM with hierarchical structure to ob-
tain document representation. In word level, each word wij
is mapped to its embedding wij ∈ Rd. BiLSTM network
receives [wi1, wi2, · · · , wili] and generates hidden states
[hi1, hi2, · · · , hili]. Then we can fetch the last hidden state
hili or feed [hi1, hi2, · · · , hili] to an average pooling layer
or use attention mechanism to obtain the sentence represen-
tation si. In sentence level, we feed the generated sentence
representations [s1, s2, · · · , sn] into BiLSTM and then ob-
tain the document representation d in a similar way. Finally,
d is taken as feature of softmax classiﬁer to predict senti-
ment label of the review.

Methods
It is obvious that not all words/sentences contribute equally
to the review text semantics for different users and differ-
ent products. In addition, in reviews, we observe that some
words or sentences show strong user’s preference, and some

Figure 1: The architecture of Hierarchical User Attention and Product Attention neural network.

others tend to indicate product’s characteristic. The two
kinds of information play different roles in inferring the sen-
timent label of reviews, which implies a review has differ-
ent latent semantic representations in user’s view and prod-
uct’s view. In order to address the issue, we propose a novel
framework to incorporate user and product information into
sentiment classiﬁcation.

Framework

We refer to our model as HUAPA for convenience. An illus-
tration of HUAPA is shown in Figure 1. It consists of two
components mainly: a hierarchical user attention network
and a hierarchical product attention network. With atten-
tion mechanism, the former incorporates user information
into review document modeling while the latter incorporates
product information. Then, we concatenate the two review
representations as the ﬁnal representation to predict user’s
overall sentiment on a review about a product. In addition,
we design a combined strategy to enhance review represen-
tations for sentiment classiﬁcation. Speciﬁcally, we add a
softmax classiﬁer respectively to three review representation
du, dp and d, and introduce a weighted loss function as op-
timization objective, which proves effective. We will present
the details of HUAPA in the following sections.

Hierarchical User Attention

From the user’s point of view, not all words reﬂect equally
user’s preference or sentiment. In order to address the is-
sue, we use user attention mechanism to extract user-speciﬁc

words that are signiﬁcant to the meaning of sentence. Fi-
nally, the sentence representation is aggregated by the rep-
resentations of those informative words. Formally, the en-
hanced sentence representation su
is a weighted sum of
i
word-level hidden states in user’s view as:

su
i =

ijhu
αu
ij,

li(cid:88)

j=1

(5)

(7)

ij is the attention weight of hu

where hu
ij is the hidden state of the j-th word in the i-th
sentence, αu
ij and measures
the importance of the j-th word for current user. We map
each user u into a continuous and real valued vector u ∈
Rdu, where du denotes the dimension of user embeddings.
Speciﬁcally, the attention weight αu
ij for each hidden state
can be deﬁned as:

e(hu

ij, u) = (vu

whhu

ij + Wu

wuu + bu
w

(cid:1) , (6)

w)(cid:62) tanh (cid:0)Wu
ij, u(cid:1)(cid:1)
exp (cid:0)e (cid:0)hu
k=1 exp (e (hu

ik, u))

αu

ij =

(cid:80)li

w is weight vector and (vu
wh and Wu

w)(cid:62) represents its trans-
where vu
pose, Wu
wu are weight matrices, e(·) is a score
function which scores the importance of words for compos-
ing sentence representation about current user.

Similarly, different sentences contribute unequally to doc-
ument semantics for users. Therefore, in sentence level, we
also use a attention mechanism with user vector u in word
level to generate the document representation. The docu-

Datasets
IMDB
Yelp 2013
Yelp 2014

#classes
10
5
5

#docs
84,919
78,966
231,163

#users
1,310
1,631
4,818

#products
1,635
1,633
4,194

#docs/user
64.82
48.42
47.97

#docs/product
51.94
48.36
55.11

#sens/doc
16.08
10.89
11.41

#words/sen
24.54
17.38
17.26

Table 1: Statistics of IMDB, Yelp2013 and Yelp2014 datasets

e (hu

i , u) = (vu

ment representation du in user’s view is obtained via:
s )(cid:62) tanh (Wu
suu + bu
exp (e (hu
i , u))
k=1 exp (e (hu

i + Wu

βu
i =

k, u))

shhu

(cid:80)n

,

s ) ,

du =

i hu
βu
i ,

n
(cid:88)

i=1

where hu
document, βu
i
level and can be calculated similar to the word level.

i is the hidden state of the i-th sentence in a review
i in sentence

is the weight of hidden state hu

Hierarchical Product Attention
It is also true for different products that every word or sen-
tence contributes different information to the text semantics.
Based on the common sense, hierarchical product attention
incorporates product information into review representation
similar to hierarchical user attention. In product’s view, the
sentence representation sp
i and document representation dp
of a review are obtained formally as:

(8)

(9)

(10)

(11)

(12)

sp
i =

ijhp
αp
ij,

dp =

βp
i hp
i ,

li(cid:88)

j=1
n
(cid:88)

i=1

where αp
level and hp

ij and βp

i are the weight of hidden state hp

ij in word

i in sentence level respectively.

Combined Strategy
In order to make full use of document representation du and
dp, we design a combined strategy for training and the ﬁnal
prediction.

Since document representation du and dp are high level
representations of review in user’s view and product’s view
respectively. Hence, we concatenate them as the ﬁnal review
representation for sentiment classiﬁcation without feature
engineering:

d = [du; dp] .
(13)
Speciﬁcally, we use a linear layer and a softmax layer to
project review representation d into review sentiment distri-
bution of C classes:

p = softmax (Wd + b) .

(14)

In our model, the cross-entropy error between ground truth
distribution of review sentiment and p is deﬁned as loss1:
C
(cid:88)

(cid:88)

pg
c (d) · log (pc(d)) ,

(15)

loss1 = −

d∈T

c=1

where pg
c is the probability of sentiment label c with ground
truth being 1 and others being 0, T represents the training
set.

To make the review representations du and dp both
have certain predictive capability and futher improve perfor-
mance for sentiment classiﬁcation, we add a softmax classi-
ﬁer respectively to du and dp. The corresponding losses are
deﬁned as follows:

pu = softmax (Wudu + bu) ,
C
(cid:88)

(cid:88)

loss2 = −

c (d) · log (pu
pg

c (d)) ,

d∈T

c=1
pp = softmax (Wpdp + bp) ,
C
(cid:88)

(cid:88)

loss3 = −

c (d) · log (pp
pg

c (d)) ,

d∈T

c=1

(16)

(17)

(18)

(19)

where pu is the predicted sentiment distribution of with
user’s view and pp is the predicted sentiment distribution
of with product’s view. The ﬁnal loss of our model is a
weighted sum of loss1, loss2 and loss3 as:

L = λ1loss1 + λ2loss2 + λ3loss3.

(20)

The loss2 and loss3 are introduced as supervised informa-
tion to improve review representations and further help sen-
timent classiﬁcation. Note that, we predict review sentiment
label according to the distribution p because it contains both
user information and product information.

Experiments

We conduct experiments on several real-world datasets to
validate the effectiveness of our model and report empirical
results in this section.

Experiments Settings

We conduct experiments on three sentiment classiﬁcation
datasets2 with user and product information, which are from
IMDB and Yelp Dataset Challenge in 2013 and 2014 (Tang,
Qin, and Liu 2015b). The statistics of the datasets are sum-
marized in Table 1. The datasets are split into three parts,
80% for training, 10% for validation, and the remaining 10%
for test. We use standard Accuracy to measure the overall
sentiment classiﬁcation performance, and RM SE to mea-
sure the divergences between predicted sentiment label and

2http://ir.hit.edu.cn/ dytang/paper/acl2015/dataset.7z

Models

Majority
Trigram
TextFeature
AvgWordvec+SVM
SSWE+SVM
Paragraph Vector
RNTN+Recurrent
UPNN(CNN and no UP)
NSC
NSC+LA
NSC+LA(BiLSTM)

Trigram+UPF
TextFeature+UPF
JMARS
UPNN(CNN)
UPNN(NSC)
LUPDR
NSC+UPA
NSC+UPA(BiLSTM)
HUAPA

IMDB

Yelp 2013

Acc.

Acc.

0.196
0.399
0.402
0.304
0.312
0.341
0.400
0.405
0.443
0.487
0.490

0.411
0.569
0.556
0.526
0.549
0.554
0.574
0.577
0.627
0.631
0.638

RMSE
RMSE
Models without user and product information
1.060
2.495
0.814
1.783
0.845
1.793
0.898
1.985
0.849
1.973
0.832
1.814
0.804
1.764
0.812
1.629
0.701
1.465
0.706
1.381
0.691
1.325
Models with user and product information
0.803
1.764
1.822
1.774
0.985
1.773
0.784
1.602
0.702
1.443
0.694
1.451
0.692
1.281
0.672
1.247
0.628
1.185

0.404
0.402
N/A
0.435
0.471
0.488
0.533
0.529
0.550

0.570
0.561
N/A
0.596
0.631
0.639
0.650
0.655
0.683

Yelp 2014

Acc.

RMSE

0.392
0.577
0.572
0.530
0.557
0.564
0.582
0.585
0.637
0.630
0.646

0.576
0.579
N/A
0.608
N/A
0.639
0.667
0.669
0.686

1.097
0.804
0.800
0.893
0.851
0.802
0.821
0.808
0.686
0.715
0.678

0.789
0.791
0.999
0.764
N/A
0.688
0.654
0.654
0.626

Table 2: Reviews sentiment classiﬁcation results. Acc.(Accuracy, higher is better) and RMSE(lower is better) are the evaluation
metrics. The best performances are in bold. HUAPA outperforms previous best state-of-the-art method signiﬁcantly(p < 0.01).

ground truth label. They are deﬁned as follows:

,

T
N
(cid:80)N

(cid:115)

Accuracy =

RM SE =

k=1 (gdk − prk)2
N

,

(21)

(22)

where T is the numbers of predicted sentiment labels that
are same with ground truth sentiment labels of reviews, N is
the numbers of review documents, gdk represents the ground
sentiment label, and prk denotes predicted sentiment label.
We pre-train the 200-dimensional word embeddings on
each dataset with SkipGram (Mikolov et al. 2013). The word
embeddings are not ﬁne-tuned when training, so hierarchical
user attention and hierarchical product attention use same
word embeddings. We set the user embeddings dimension
and product embeddings dimension to be 200, and randomly
initialize them from a uniform distribution U (−0.01, 0.01).
The dimensions of hidden states in LSTM cell are set to 100.
In this setting, a bidirectional LSTM gives us 200 dimen-
sional output for word/sentence representation. To speed up
training, we limit that a review document has 40 sentences
at most and every sentence has no more than 50 words.
We use Adam (Kingma and Ba 2015) to update parameters
when training and empirically set initial learning rate to be
0.005. Finally, We select the best parameters based on per-
formance on the validation set, and evaluate the parameters
on the test set. Note that, we do not use any regularization or
dropout (Srivastava et al. 2014) to improve performance of
the model.

Baselines
We compare our model HUAPA with several baseline meth-
ods for document-level review sentiment classiﬁcation:

Majority assigns the majority sentiment label in training

set to each review document in test set.

Trigram uses unigrams, bigrams and trigrams as features

to train a SVM classiﬁer with LibLinear (Fan et al. 2008).

TextFeature extracts sophisticated text features to train
SVM classiﬁer, such word/character n-grams, sentiment lex-
icon features, cluster features, etc. (Kiritchenko, Zhu, and
Mohammad 2014).

UPF extracts user leniency and corresponding product
popularity features (Gao et al. 2013) from training data, and
further concatenates them with the features in Trigram and
TextFeature.

AvgWordvec averages word embeddings of a document
to generate document representation, then feeds it into a
SVM classiﬁer as features.

SSWE learns

sentiment-speciﬁc word embeddings
(SSWE) (Tang et al. 2014), and uses max/min/average
pooling to obtain document representation which is used as
features for a SVM classiﬁer.

RNTN + RNN uses the Recursive Neural Tensor Network
(RNTN) (Socher et al. 2013) to obtain sentence represen-
tations, then feeds them into the Recurrent Neural Network
(RNN). Afterwards, the hidden vectors of RNN are averaged
to generate document representation for sentiment classiﬁ-
cation.

Paragraph Vector implements the Distributed Memory
Model of Paragraph Vectors (Le and Mikolov 2014) for doc-

Table 3: Effect of user attention and product attention. HUA only uses user information and local text, and HPA only uses
product information and local text.

Models

NSC+LA(BiLSTM)
HUA
HPA
HUAPA

IMDB

Yelp 2013

Yelp 2014

Acc.
0.490
0.521
0.493
0.550

RMSE
1.325
1.300
1.326
1.185

Acc.
0.638
0.649
0.641
0.683

RMSE
0.691
0.691
0.681
0.628

Acc.
0.646
0.663
0.646
0.686

RMSE
0.678
0.661
0.678
0.626

λ1

1.0
0.7
0.7
0.4

λ2

0.0
0.3
0.0
0.3

λ3

0.0
0.0
0.3
0.3

IMDB

Yelp 2013

Yelp 2014

Acc.
0.538
0.541
0.540
0.550

RMSE
1.229
1.239
1.287
1.185

Acc.
0.669
0.672
0.675
0.683

RMSE
0.658
0.644
0.646
0.628

Acc.
0.675
0.680
0.679
0.686

RMSE
0.647
0.641
0.633
0.626

Table 4: Effect of the different weighted loss.

ument sentiment classiﬁcation. The window size is tuned on
validation set.

JMARS is a recommendation algorithm (Diao et al.
2014), which uses the information of users and aspects with
collaborative ﬁltering and topic modeling to predict docu-
ment sentiment rating.

UPNN introduces a word-level preference matrix and a
representation vector for each user and each product into
CNN sentiment classiﬁer (Kim 2014). The meaning of
words can modiﬁed in the input layer with the preference
matrix. Finally, it concatenates the user/product representa-
tion vectors with generated review representation as features
fed into softmax layer (Tang, Qin, and Liu 2015b).

LUPDR uses recurrent neural network to embed tempo-
ral relations of reviews into the categories of distributed user
and product representations learning for the sentiment clas-
siﬁcation of reviews (Chen et al. 2016b).

NSC uses hierarchical LSTM model to encode review text

for sentiment classiﬁcation.

NSC+LA implements the idea of local semantic atten-

tion (Yang et al. 2016) based on NSC.

NSC+UPA puts user and product information account to-
gether and uses hierarchical LSTM model with attention
mechanism to generate a review representation for sentiment
classiﬁcation.

implement

Chen et al. (2016a) do not

the model
NSC+UPA and NSC+LA with bidirectional LSTM. To
make the experimental results more convincing, we imple-
ment and train them in our experimental settings. In addition
to LUPDR and the models related to NSC, we report the re-
sults in (Tang, Qin, and Liu 2015b) since we use the same
datasets for other baseline methods above.

Model Comparisons

The experimental results are given in Table 2, which are di-
vided into two parts: the models only using the local text
information, and the models incorporating both local text in-
formation and the global user and product information.

From the ﬁrst part, we can see that the majority performs
very poor because it does not use any text, user, and prod-
uct information. Compared to the methods taking SVM as
classiﬁer, hierarchical neural networks achieve better per-
formances generally. In addition, the results show NSC+LA
obtains a considerable improvements based on NSC, which
proves that importance of selecting more meaningful words
and sentences in sentiment classiﬁcation. It is also a main
reason that attention mechanism is introduced into sentiment
classiﬁcation.

From the second part, we observe that the methods con-
sidering user and product information achieve more or less
improvements compared to the corresponding methods in
the ﬁrst part. For example, TextFeature+UPF achieves 0.5%
improvement and NSC+UPA obtains 2.3% improvement on
Yelp2013 in accuracy. The comparisons indicate that the
user and product information is helpful for sentiment clas-
siﬁcation.

The experimental results show that our proposed model
with user attention and product attention achieves best per-
formance on all datasets. We can see improvements regard-
less of data scale. For smaller dataset such as Yelp2013
and IMDB, our model outperforms the previous best state-
of-the-art method by 2.8% and 1.7% respectively in accu-
racy. This ﬁnding is consistent on larger dataset. Our model
achieves improvement by 1.7% on dataset Yelp2014 in accu-
racy. The observations demonstrate that our model incorpo-
rates user and product information in a more effective way,
which ﬁnally improves review representations for sentiment
classiﬁcation.

Model Analysis: Effect of User Attention and
Product Attention
To investigate the effects of single user attention or product
attention, we also implement independent hierarchical user
attention network (HUA) and hierarchical product attention
network (HPA). Table 3 shows the performance of single
attention mechanism with user or product information. From
the table, we can observe that:

• Compared to the model NSC+LA(BiLSTM) only using
local semantic attention, HUA and HPA both achieve
some improvements, which validates the rationality of in-
corporating user and product into sentiment classiﬁcation
via attention mechanism. The results also indicate that
user attention or product attention can capture more in-
formation related to sentiment.

• The user information is more effective than the product
information to enhance review representations. Although
some words or sentences in reviews show product’s char-
acteristic, the ratings are ﬁnally decided by users. Hence,
it is reasonable that the discrimination of user’s preference
is more obvious than product’s characteristic.

• Compared to single user attention or product attention,
our model achieves better performance, which indicates
that user and product information both contribute to our
model. The results demonstrate our user attention and
product attention mechanism can catch the speciﬁc user’s
preference and product’s characteristic.

Model Analysis: Effect of the Different Weighted
Loss
The λ1, λ2, and λ3 respectively represent the weight of
loss1, loss2 and loss3. We investigate the effect of differ-
ent weighted loss by empirically adjusting their proportion.
When λ2 is set to 0, we do not use loss2 to enhance the re-
view representations. Similarly, we set λ3 to 0 to avoid the
effect of loss3. The experimental results are in Table 4. From
the Table 4 and Table 2, we can observe that:

• Compared to other state-of-the-art methods, our model
without loss2 and loss3 also achieve consistent improve-
ments on the three datasets. It indicates that our attention
mechanism is more effective in incorporating user infor-
mation and product information.

• When considering loss2 or loss3, HUAPA both obtains
some improvements. It is obvious that full HUAPA model
achieves best performance. The results demonstrate that
with the designed combined strategy, better review rep-
resentations from two views can be achieved and further
help sentiment classiﬁcation.

Case Study for Visualization of Attention
To validate our observation and demonstrate the effective-
ness of user attention and product attention, we take some
review instances in Yelp2013 dataset as example. We visu-
alize the attention weights of these reviews at word level in
HUAPA. The results are shown in Figure 2. Note that, the
darker color means higher weight.

For the review 1, we can see that the word “love” has high-
est attention weight in user attention and the word “cool” has
highest attention weight in product attention. In fact, it is in-
tuitive that “love” usually expresses user’s affection or pref-
erence, and “cool” is used to describe the characteristic of
product. There are also some reviews that user’s preference
is inconsistent with product’s characteristic, such as review
3 in Figure 2. The content of the review 3 is “much of it was
quite good but I was disappointed with the spider roll.”. It is

Figure 2: Visualization of user attention and product atten-
tion over words

obvious that the word “good” indicates the product’s char-
acteristic and the word “disappointed” shows user’s negative
sentiment. Our model not only catches such information but
also gives right prediction. The visualizations of attention
demonstrate that our model can capture global user’s prefer-
ence and product’s characteristic.

Conclusion

In this paper, we propose a novel framework incorporat-
ing user and product information for sentiment classiﬁca-
tion. Speciﬁcally, we ﬁrstly apply two individual hierarchi-
cal neural networks to generate two representations, with
user attention or with product attention. Then, we design a
combined strategy to make full use of the two representa-
tions for training and ﬁnal prediction. We evaluate our model
on several sentiment classiﬁcation datasets. The experimen-
tal results show that our model achieves obvious and consis-
tent improvements compared to other state-of-the-art meth-
ods. Finally, the visualizations of attention also show our
model can capture user information and product informa-
tion.

Acknowledgments

We would like to thank the anonymous reviewers for
their insightful comments. This work was supported by
the 863 program(No. 2015AA015406) and the NSFC(No.
61472183, 61672277).

References

[Bahdanau, Cho, and Bengio 2015] Bahdanau, D.; Cho, K.;
and Bengio, Y. 2015. Neural machine translation by jointly
learning to align and translate. In ICLR.
[Bengio et al. 2003] Bengio, Y.; Ducharme, R.; Vincent, P.;
and Jauvin, C. 2003. A neural probabilistic language model.
JMLR 3(Feb):1137–1155.
[Chen et al. 2016a] Chen, H.; Sun, M.; Tu, C.; Lin, Y.; and
Liu, Z. 2016a. Neural sentiment classiﬁcation with user and
product attention. In EMNLP, 1650–1659.
[Chen et al. 2016b] Chen, T.; Xu, R.; He, Y.; Xia, Y.; and
Wang, X. 2016b. Learning user and product distributed rep-
resentations using a sequence model for sentiment analysis.
IEEE Computational Intelligence Magazine 11(3):34–44.
[Dahl et al. 2012] Dahl, G. E.; Yu, D.; Deng, L.; and Acero,
A. 2012. Context-dependent pre-trained deep neural net-
TASLP
works for large-vocabulary speech recognition.
20(1):30–42.

[Diao et al. 2014] Diao, Q.; Qiu, M.; Wu, C.-Y.; Smola, A. J.;
Jiang, J.; and Wang, C. 2014.
Jointly modeling aspects,
ratings and sentiments for movie recommendation (jmars).
In KDD, 193–202.
[Ding, Liu, and Yu 2008] Ding, X.; Liu, B.; and Yu, P. S.
2008. A holistic lexicon-based approach to opinion mining.
In WSDM, 231–240.
[Fan et al. 2008] Fan, R.-E.; Chang, K.-W.; Hsieh, C.-J.;
Wang, X.-R.; and Lin, C.-J. 2008. Liblinear: A library for
large linear classiﬁcation. JMLR 9(Aug):1871–1874.
[Gao et al. 2013] Gao, W.; Yoshinaga, N.; Kaji, N.; and Kit-
suregawa, M. 2013. Modeling user leniency and product
In IJCNLP, 1107–
popularity for sentiment classiﬁcation.
1111.

[Glorot, Bordes, and Bengio 2011] Glorot, X.; Bordes, A.;
and Bengio, Y. 2011. Domain adaptation for large-scale sen-
timent classiﬁcation: A deep learning approach. In ICML,
513–520.

S.,

[Hochreiter and Schmidhuber 1997] Hochreiter,
and
Schmidhuber, J. 1997. Long short-term memory. Neural
Computation 9(8):1735–1780.
[Johnson and Zhang 2015] Johnson, R., and Zhang, T. 2015.
Effective use of word order for text categorization with con-
volutional neural networks. In HLT-NAACL, 103–112.
[Kim 2014] Kim, Y. 2014. Convolutional neural networks
for sentence classiﬁcation. In EMNLP, 1746–1751.
[Kingma and Ba 2015] Kingma, D., and Ba, J. 2015. Adam:
A method for stochastic optimization. In ICLR.
[Kiritchenko, Zhu, and Mohammad 2014] Kiritchenko, S.;
Zhu, X.; and Mohammad, S. M. 2014. Sentiment analysis
of short informal texts. JAIR 50:723–762.
[Krizhevsky, Sutskever, and Hinton 2012] Krizhevsky, A.;
Imagenet classiﬁ-
Sutskever, I.; and Hinton, G. E. 2012.
In NIPS,
cation with deep convolutional neural networks.
1097–1105.

2011.

Ifrim, G.;

[Le and Mikolov 2014] Le, Q., and Mikolov, T. 2014. Dis-
tributed representations of sentences and documents.
In
ICML, 1188–1196.
[Liu 2012] Liu, B. 2012. Sentiment analysis and opinion
mining. Synthesis Lectures on Human Language Technolo-
gies 5(1):1–167.
[Mikolov et al. 2013] Mikolov, T.; Sutskever, I.; Chen, K.;
Corrado, G. S.; and Dean, J. 2013. Distributed represen-
tations of words and phrases and their compositionality. In
NIPS, 3111–3119.
[Pang and Lee 2005] Pang, B., and Lee, L. 2005. Seeing
stars: Exploiting class relationships for sentiment catego-
rization with respect to rating scales. In ACL, 115–124.
[Pang and Lee 2008] Pang, B., and Lee, L. 2008. Opinion
mining and sentiment analysis. Foundations and Trends in
Information Retrieval 2(12):1–135.
[Pang, Lee, and Vaithyanathan 2002] Pang, B.; Lee, L.; and
Vaithyanathan, S. 2002. Thumbs up?: sentiment classiﬁca-
tion using machine learning techniques. In EMNLP, 79–86.
[Qu, Ifrim, and Weikum 2010] Qu, L.;
and
Weikum, G. 2010. The bag-of-opinions method for review
In COLING,
rating prediction from sparse text patterns.
913–921.
J.; Huang,
[Socher et al. 2011] Socher, R.; Pennington,
E. H.; Ng, A. Y.; and Manning, C. D.
Semi-
supervised recursive autoencoders for predicting sentiment
distributions. In EMNLP, 151–161.
[Socher et al. 2012] Socher, R.; Huval, B.; Manning, C. D.;
and Ng, A. Y. 2012. Semantic compositionality through
recursive matrix-vector spaces. In EMNLP-CoNLL, 1201–
1211.
[Socher et al. 2013] Socher, R.; Perelygin, A.; Wu, J. Y.;
Chuang, J.; Manning, C. D.; Ng, A. Y.; Potts, C.; et al. 2013.
Recursive deep models for semantic compositionality over a
sentiment treebank. In EMNLP, 1631–1642.
[Srivastava et al. 2014] Srivastava, N.; Hinton, G. E.;
Krizhevsky, A.; Sutskever, I.; and Salakhutdinov, R. 2014.
Dropout: a simple way to prevent neural networks from
overﬁtting. JMLR 15(1):1929–1958.
[Sukhbaatar et al. 2015] Sukhbaatar, S.; Weston, J.; Fergus,
In NIPS,
R.; et al. 2015. End-to-end memory networks.
2440–2448.
[Taboada et al. 2011] Taboada, M.; Brooke, J.; Toﬁloski, M.;
Voll, K.; and Stede, M. 2011. Lexicon-based methods for
sentiment analysis. Computational Linguistics 37(2):267–
307.
[Tang et al. 2014] Tang, D.; Wei, F.; Yang, N.; Zhou, M.; Liu,
T.; and Qin, B. 2014. Learning sentiment-speciﬁc word em-
bedding for twitter sentiment classiﬁcation. In ACL, 1555–
1565.
[Tang, Qin, and Liu 2015a] Tang, D.; Qin, B.; and Liu, T.
2015a. Document modeling with gated recurrent neural net-
work for sentiment classiﬁcation. In EMNLP, 1422–1432.
[Tang, Qin, and Liu 2015b] Tang, D.; Qin, B.; and Liu, T.
2015b. Learning semantic representations of users and prod-

In ACL,

ucts for document level sentiment classiﬁcation.
1014–1023.
[Vinyals et al. 2015] Vinyals, O.; Kaiser, Ł.; Koo, T.; Petrov,
S.; Sutskever, I.; and Hinton, G. 2015. Grammar as a foreign
language. In NIPS, 2773–2781.
[Xu et al. 2015] Xu, K.; Ba, J.; Kiros, R.; Cho, K.; Courville,
2015.
A.; Salakhudinov, R.; Zemel, R.; and Bengio, Y.
Show, attend and tell: Neural image caption generation with
visual attention. In ICML, 2048–2057.
[Yang et al. 2016] Yang, Z.; Yang, D.; Dyer, C.; He, X.;
Smola, A. J.; and Hovy, E. H. 2016. Hierarchical atten-
tion networks for document classiﬁcation. In HLT-NAACL,
1480–1489.

Improving Review Representations with User Attention
and Product Attention for Sentiment Classiﬁcation

Zhen Wu, Xin-Yu Dai∗, Cunyan Yin, Shujian Huang, Jiajun Chen
National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, 210023, China
Collaborative Innovation Center of Novel Software Technology and Industrialization, Nanjing, 210023, China
wuz@nlp.nju.edu.cn, {daixinyu,yincy,huangsj,chenjj}@nju.edu.cn

8
1
0
2
 
n
a
J
 
4
2
 
 
]
L
C
.
s
c
[
 
 
1
v
1
6
8
7
0
.
1
0
8
1
:
v
i
X
r
a

Abstract

Neural network methods have achieved great success in
reviews sentiment classiﬁcation. Recently, some works
achieved improvement by incorporating user and product in-
formation to generate a review representation. However, in re-
views, we observe that some words or sentences show strong
user’s preference, and some others tend to indicate product’s
characteristic. The two kinds of information play different
roles in determining the sentiment label of a review. There-
fore, it is not reasonable to encode user and product informa-
tion together into one representation. In this paper, we pro-
pose a novel framework to encode user and product infor-
mation. Firstly, we apply two individual hierarchical neural
networks to generate two representations, with user attention
or with product attention. Then, we design a combined strat-
egy to make full use of the two representations for training
and ﬁnal prediction. The experimental results show that our
model obviously outperforms other state-of-the-art methods
on IMDB and Yelp datasets. Through the visualization of at-
tention over words related to user or product, we validate our
observation mentioned above.

Introduction
Sentiment analysis aims to determine people’s attitudes to-
wards some topic or the overall polarity to a document, in-
teraction, or event. In recent years, sentiment analysis draws
increasing attention of researchers and industries because of
the rapid growth of online review sites such as Amazon, Yelp
and IMDB. In this work, we focus on the task of document-
level review sentiment classiﬁcation, which is a fundamen-
tal task in the ﬁeld of sentiment analysis and opinion min-
ing (Pang and Lee 2008). The task aims to infer the overall
sentiment intensity (e.g. 1-5 stars on the review site Yelp) of
review documents written by users for products.

Dominating studies follow (Pang and Lee 2005; Pang,
Lee, and Vaithyanathan 2002) and take sentiment classiﬁ-
cation as a special case of text classiﬁcation problem. They
usually regard user-marked sentiment polarities or ratings as
labels and use machine learning algorithms to build senti-
ment classiﬁers with text features. Following the idea, many
works devote to designing effective features from text (Pang,

∗Corresponding author.

Copyright c(cid:13) 2018, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

Lee, and Vaithyanathan 2002; Qu, Ifrim, and Weikum 2010)
or additional sentiment lexicons (Ding, Liu, and Yu 2008;
Taboada et al. 2011; Kiritchenko, Zhu, and Mohammad
2014). Motivated by the great success of deep learning in
computer vision (Krizhevsky, Sutskever, and Hinton 2012),
speech recognition (Dahl et al. 2012) and natural language
processing (Bengio et al. 2003), more recent methods use
neural networks to learn low-dimensional and continuous
text representations without any feature engineering (Glorot,
Bordes, and Bengio 2011; Socher et al. 2011; Socher et al.
2012; Socher et al. 2013; Kim 2014). These models achieve
very competitive performances in sentiment classiﬁcation.

Despite neural network based approaches have been quite
effective for sentiment classiﬁcation (Johnson and Zhang
2015; Tang, Qin, and Liu 2015a), they typically only fo-
cus on the text content while ignoring the crucial inﬂuences
of users and products. It is a common sense that the user’s
preference and product’s characteristic make a signiﬁcant
effect on the ratings. For different users, same word might
express different emotional intensity. For example, a lenient
user may use “good” to evaluate an ordinary product while
a critical user might use “good” to express an excellent atti-
tude. Similarly, product’s characteristic also have an effect
on review ratings. Reviews of high-quality products tend
to receive higher ratings compared to those of low-quality
products.

In order to incorporate user and product information into
sentiment classiﬁcation, Tang, Qin, and Liu (2015b) intro-
duce a word-level preference matrix and a representation
vector for each user and product into CNN sentiment clas-
siﬁer. The model achieves some improvements, but suf-
fers from high model complexity and only considers word-
level user and product information rather than semantic-
level. Chen et al. (2016a) consider user and product infor-
mation together and incorporate them into one review rep-
resentation via attention mechanism (Bahdanau, Cho, and
Bengio 2015). However, in reviews, we observe that some
words or sentences show strong user’s preference, and some
others tend to indicate product’s characteristic. For example,
for the review “the bar area is deﬁnitely good ‘people watch-
ing’ and i love the modern contemporary d´ecor.”, the word
“good”, “modern” and “contemporary” describe the charac-
teristic of product, and the “love” shows strong user’s sen-
timent. Opinions are more related to products and emotions

are more centered on the user. They are called rational eval-
uation and emotional evaluation respectively by Liu (2012).
Obviously, the two kinds of information have different ef-
fects on inferring sentiment label of the review. Intuitively,
a review has different latent semantic representations with
different views from users or products. Therefore, it is un-
reasonable to encode user and product information together
into one representation.

In this paper, we address the above issues by encoding
user and product information, respectively, into two hierar-
chical networks to generate two individual text representa-
tions with user attention or product attention. Then, we de-
sign a combined strategy to make most use of the two repre-
sentations for training and ﬁnal prediction, which proves ef-
fective. The experimental results show that our model obvi-
ously outperforms other state-of-the-art methods on IMDB
and Yelp datasets. We open the source code in GitHub.1
The main contributions of our work are as follows:

• We propose a novel framework to encode review from
two views for sentiment classiﬁcation. With user atten-
tion and product attention, respectively, two representa-
tions are generated, which are concatenated for further
classiﬁcation.

• For better learning the neural network, we introduce
a combined strategy to improve review representations.
With a weighted loss function, better representations from
two views can be achieved and further help sentiment
classiﬁcation.

• The experimental results demonstrate that our model
achieves obvious and consistent improvements compared
to all state-of-the-art methods. Some visualization cases
also validate the effectiveness and interpretability of our
method.

Background

Long Short-Term Memory
Long Short-Term Memory(LSTM) (Hochreiter and Schmid-
huber 1997) is widely used for text modeling because of
its excellent performance on sequence modeling, especially
for long documents. In order to address the problem of
long-term dependencies, the LSTM architecture introduces
a memory cell that is able to preserve cell state over long
periods of time.

There are three gates to protect and control the state ﬂow
in LSTM unit. At each time step t, given an input vector xt,
the current cell state ct and hidden state ht can be updated
with previous cell state ct−1 and hidden state ht−1 as fol-
lows:

(cid:35)

(cid:34) it
ft
ot

(cid:35)

(cid:34)σ
σ
σ

=

(W [ht−1; xt] + b) ,

ˆct = tanh (Wc [ht−1; xt] + bc) ,
ct = ft (cid:12) ˆct−1 + it (cid:12) ˆct,
ht = ot (cid:12) tanh(ct),

(1)

(2)
(3)
(4)

1https://github.com/wuzhen247/HUAPA

where it, ft and ot are gate activations and in [0, 1], σ is
the logistic sigmoid function and (cid:12) stands for element-wise
multiplication. Intuitively, the forget gate ft controls the ex-
tent to which the previous memory cell is forgotten, the in-
put gate it controls how much each unit is updated, and the
output gate ot controls the exposure of the internal mem-
ory state. The hidden state ht denotes output information of
LSTM unit’s internal memory cell.

In order to increase the amount of input information avail-
able to the network, a more common approach is to adopt
bidirectional LSTM to model text semantics both from for-
ward and backward. For sequence vectors [x1, x2, · · · , xT ],
the forward LSTM reads sequence from x1 to xT and the
backward LSTM reads sequence from xT to x1. Then we
−→
ht and backward hid-
concatenate the forward hidden state
←−
, where the [·; ·] denotes con-
ht
den state
catenation operation. The ht summarizes the information of
the whole sequence centered around xt.

←−
ht, i.e., ht =

(cid:104)−→
ht;

(cid:105)

Attention Mechanism
Inspired by human visual attention, the attention mecha-
nism is proposed by Bahdanau, Cho, and Bengio (2015) in
machine translation, which is introduced into the Encoder-
Decoder framework to select the reference words in source
language for words in target language. It is also used in im-
age caption generation (Xu et al. 2015), parsing (Vinyals et
al. 2015), natural language question answering (Sukhbaatar
et al. 2015). Yang et al. (2016) and Chen et al. (2016a) ex-
plore hierarchical attention mechanism to select informative
words or sentences for the semantics of document.

Document-level Sentiment Classiﬁcation
Document-level sentiment classiﬁcation usually aims to pre-
dict the corresponding sentiment label of review text. In gen-
eral, a review is written by a user u ∈ U for a product p ∈ P .
We denote the review as a document d with n sentences
{s1, s2, · · · , sn} and li is the length of i-th sentence. The
i-th sentence si consists of li words {wi1, wi2, · · · , wili}.
For modelling document-level text semantics, we can em-
ploy bidirectional LSTM with hierarchical structure to ob-
tain document representation. In word level, each word wij
is mapped to its embedding wij ∈ Rd. BiLSTM network
receives [wi1, wi2, · · · , wili] and generates hidden states
[hi1, hi2, · · · , hili]. Then we can fetch the last hidden state
hili or feed [hi1, hi2, · · · , hili] to an average pooling layer
or use attention mechanism to obtain the sentence represen-
tation si. In sentence level, we feed the generated sentence
representations [s1, s2, · · · , sn] into BiLSTM and then ob-
tain the document representation d in a similar way. Finally,
d is taken as feature of softmax classiﬁer to predict senti-
ment label of the review.

Methods
It is obvious that not all words/sentences contribute equally
to the review text semantics for different users and differ-
ent products. In addition, in reviews, we observe that some
words or sentences show strong user’s preference, and some

Figure 1: The architecture of Hierarchical User Attention and Product Attention neural network.

others tend to indicate product’s characteristic. The two
kinds of information play different roles in inferring the sen-
timent label of reviews, which implies a review has differ-
ent latent semantic representations in user’s view and prod-
uct’s view. In order to address the issue, we propose a novel
framework to incorporate user and product information into
sentiment classiﬁcation.

Framework

We refer to our model as HUAPA for convenience. An illus-
tration of HUAPA is shown in Figure 1. It consists of two
components mainly: a hierarchical user attention network
and a hierarchical product attention network. With atten-
tion mechanism, the former incorporates user information
into review document modeling while the latter incorporates
product information. Then, we concatenate the two review
representations as the ﬁnal representation to predict user’s
overall sentiment on a review about a product. In addition,
we design a combined strategy to enhance review represen-
tations for sentiment classiﬁcation. Speciﬁcally, we add a
softmax classiﬁer respectively to three review representation
du, dp and d, and introduce a weighted loss function as op-
timization objective, which proves effective. We will present
the details of HUAPA in the following sections.

Hierarchical User Attention

From the user’s point of view, not all words reﬂect equally
user’s preference or sentiment. In order to address the is-
sue, we use user attention mechanism to extract user-speciﬁc

words that are signiﬁcant to the meaning of sentence. Fi-
nally, the sentence representation is aggregated by the rep-
resentations of those informative words. Formally, the en-
hanced sentence representation su
is a weighted sum of
i
word-level hidden states in user’s view as:

su
i =

ijhu
αu
ij,

li(cid:88)

j=1

(5)

(7)

ij is the attention weight of hu

where hu
ij is the hidden state of the j-th word in the i-th
sentence, αu
ij and measures
the importance of the j-th word for current user. We map
each user u into a continuous and real valued vector u ∈
Rdu, where du denotes the dimension of user embeddings.
Speciﬁcally, the attention weight αu
ij for each hidden state
can be deﬁned as:

e(hu

ij, u) = (vu

whhu

ij + Wu

wuu + bu
w

(cid:1) , (6)

w)(cid:62) tanh (cid:0)Wu
ij, u(cid:1)(cid:1)
exp (cid:0)e (cid:0)hu
k=1 exp (e (hu

ik, u))

αu

ij =

(cid:80)li

w is weight vector and (vu
wh and Wu

w)(cid:62) represents its trans-
where vu
pose, Wu
wu are weight matrices, e(·) is a score
function which scores the importance of words for compos-
ing sentence representation about current user.

Similarly, different sentences contribute unequally to doc-
ument semantics for users. Therefore, in sentence level, we
also use a attention mechanism with user vector u in word
level to generate the document representation. The docu-

Datasets
IMDB
Yelp 2013
Yelp 2014

#classes
10
5
5

#docs
84,919
78,966
231,163

#users
1,310
1,631
4,818

#products
1,635
1,633
4,194

#docs/user
64.82
48.42
47.97

#docs/product
51.94
48.36
55.11

#sens/doc
16.08
10.89
11.41

#words/sen
24.54
17.38
17.26

Table 1: Statistics of IMDB, Yelp2013 and Yelp2014 datasets

e (hu

i , u) = (vu

ment representation du in user’s view is obtained via:
s )(cid:62) tanh (Wu
suu + bu
exp (e (hu
i , u))
k=1 exp (e (hu

i + Wu

βu
i =

k, u))

shhu

(cid:80)n

,

s ) ,

du =

i hu
βu
i ,

n
(cid:88)

i=1

where hu
document, βu
i
level and can be calculated similar to the word level.

i is the hidden state of the i-th sentence in a review
i in sentence

is the weight of hidden state hu

Hierarchical Product Attention
It is also true for different products that every word or sen-
tence contributes different information to the text semantics.
Based on the common sense, hierarchical product attention
incorporates product information into review representation
similar to hierarchical user attention. In product’s view, the
sentence representation sp
i and document representation dp
of a review are obtained formally as:

(8)

(9)

(10)

(11)

(12)

sp
i =

ijhp
αp
ij,

dp =

βp
i hp
i ,

li(cid:88)

j=1
n
(cid:88)

i=1

where αp
level and hp

ij and βp

i are the weight of hidden state hp

ij in word

i in sentence level respectively.

Combined Strategy
In order to make full use of document representation du and
dp, we design a combined strategy for training and the ﬁnal
prediction.

Since document representation du and dp are high level
representations of review in user’s view and product’s view
respectively. Hence, we concatenate them as the ﬁnal review
representation for sentiment classiﬁcation without feature
engineering:

d = [du; dp] .
(13)
Speciﬁcally, we use a linear layer and a softmax layer to
project review representation d into review sentiment distri-
bution of C classes:

p = softmax (Wd + b) .

(14)

In our model, the cross-entropy error between ground truth
distribution of review sentiment and p is deﬁned as loss1:
C
(cid:88)

(cid:88)

pg
c (d) · log (pc(d)) ,

(15)

loss1 = −

d∈T

c=1

where pg
c is the probability of sentiment label c with ground
truth being 1 and others being 0, T represents the training
set.

To make the review representations du and dp both
have certain predictive capability and futher improve perfor-
mance for sentiment classiﬁcation, we add a softmax classi-
ﬁer respectively to du and dp. The corresponding losses are
deﬁned as follows:

pu = softmax (Wudu + bu) ,
C
(cid:88)

(cid:88)

loss2 = −

c (d) · log (pu
pg

c (d)) ,

d∈T

c=1
pp = softmax (Wpdp + bp) ,
C
(cid:88)

(cid:88)

loss3 = −

c (d) · log (pp
pg

c (d)) ,

d∈T

c=1

(16)

(17)

(18)

(19)

where pu is the predicted sentiment distribution of with
user’s view and pp is the predicted sentiment distribution
of with product’s view. The ﬁnal loss of our model is a
weighted sum of loss1, loss2 and loss3 as:

L = λ1loss1 + λ2loss2 + λ3loss3.

(20)

The loss2 and loss3 are introduced as supervised informa-
tion to improve review representations and further help sen-
timent classiﬁcation. Note that, we predict review sentiment
label according to the distribution p because it contains both
user information and product information.

Experiments

We conduct experiments on several real-world datasets to
validate the effectiveness of our model and report empirical
results in this section.

Experiments Settings

We conduct experiments on three sentiment classiﬁcation
datasets2 with user and product information, which are from
IMDB and Yelp Dataset Challenge in 2013 and 2014 (Tang,
Qin, and Liu 2015b). The statistics of the datasets are sum-
marized in Table 1. The datasets are split into three parts,
80% for training, 10% for validation, and the remaining 10%
for test. We use standard Accuracy to measure the overall
sentiment classiﬁcation performance, and RM SE to mea-
sure the divergences between predicted sentiment label and

2http://ir.hit.edu.cn/ dytang/paper/acl2015/dataset.7z

Models

Majority
Trigram
TextFeature
AvgWordvec+SVM
SSWE+SVM
Paragraph Vector
RNTN+Recurrent
UPNN(CNN and no UP)
NSC
NSC+LA
NSC+LA(BiLSTM)

Trigram+UPF
TextFeature+UPF
JMARS
UPNN(CNN)
UPNN(NSC)
LUPDR
NSC+UPA
NSC+UPA(BiLSTM)
HUAPA

IMDB

Yelp 2013

Acc.

Acc.

0.196
0.399
0.402
0.304
0.312
0.341
0.400
0.405
0.443
0.487
0.490

0.411
0.569
0.556
0.526
0.549
0.554
0.574
0.577
0.627
0.631
0.638

RMSE
RMSE
Models without user and product information
1.060
2.495
0.814
1.783
0.845
1.793
0.898
1.985
0.849
1.973
0.832
1.814
0.804
1.764
0.812
1.629
0.701
1.465
0.706
1.381
0.691
1.325
Models with user and product information
0.803
1.764
1.822
1.774
0.985
1.773
0.784
1.602
0.702
1.443
0.694
1.451
0.692
1.281
0.672
1.247
0.628
1.185

0.570
0.561
N/A
0.596
0.631
0.639
0.650
0.655
0.683

0.404
0.402
N/A
0.435
0.471
0.488
0.533
0.529
0.550

Yelp 2014

Acc.

RMSE

0.392
0.577
0.572
0.530
0.557
0.564
0.582
0.585
0.637
0.630
0.646

0.576
0.579
N/A
0.608
N/A
0.639
0.667
0.669
0.686

1.097
0.804
0.800
0.893
0.851
0.802
0.821
0.808
0.686
0.715
0.678

0.789
0.791
0.999
0.764
N/A
0.688
0.654
0.654
0.626

Table 2: Reviews sentiment classiﬁcation results. Acc.(Accuracy, higher is better) and RMSE(lower is better) are the evaluation
metrics. The best performances are in bold. HUAPA outperforms previous best state-of-the-art method signiﬁcantly(p < 0.01).

ground truth label. They are deﬁned as follows:

,

T
N
(cid:80)N

(cid:115)

Accuracy =

RM SE =

k=1 (gdk − prk)2
N

,

(21)

(22)

where T is the numbers of predicted sentiment labels that
are same with ground truth sentiment labels of reviews, N is
the numbers of review documents, gdk represents the ground
sentiment label, and prk denotes predicted sentiment label.
We pre-train the 200-dimensional word embeddings on
each dataset with SkipGram (Mikolov et al. 2013). The word
embeddings are not ﬁne-tuned when training, so hierarchical
user attention and hierarchical product attention use same
word embeddings. We set the user embeddings dimension
and product embeddings dimension to be 200, and randomly
initialize them from a uniform distribution U (−0.01, 0.01).
The dimensions of hidden states in LSTM cell are set to 100.
In this setting, a bidirectional LSTM gives us 200 dimen-
sional output for word/sentence representation. To speed up
training, we limit that a review document has 40 sentences
at most and every sentence has no more than 50 words.
We use Adam (Kingma and Ba 2015) to update parameters
when training and empirically set initial learning rate to be
0.005. Finally, We select the best parameters based on per-
formance on the validation set, and evaluate the parameters
on the test set. Note that, we do not use any regularization or
dropout (Srivastava et al. 2014) to improve performance of
the model.

Baselines
We compare our model HUAPA with several baseline meth-
ods for document-level review sentiment classiﬁcation:

Majority assigns the majority sentiment label in training

set to each review document in test set.

Trigram uses unigrams, bigrams and trigrams as features

to train a SVM classiﬁer with LibLinear (Fan et al. 2008).

TextFeature extracts sophisticated text features to train
SVM classiﬁer, such word/character n-grams, sentiment lex-
icon features, cluster features, etc. (Kiritchenko, Zhu, and
Mohammad 2014).

UPF extracts user leniency and corresponding product
popularity features (Gao et al. 2013) from training data, and
further concatenates them with the features in Trigram and
TextFeature.

AvgWordvec averages word embeddings of a document
to generate document representation, then feeds it into a
SVM classiﬁer as features.

SSWE learns

sentiment-speciﬁc word embeddings
(SSWE) (Tang et al. 2014), and uses max/min/average
pooling to obtain document representation which is used as
features for a SVM classiﬁer.

RNTN + RNN uses the Recursive Neural Tensor Network
(RNTN) (Socher et al. 2013) to obtain sentence represen-
tations, then feeds them into the Recurrent Neural Network
(RNN). Afterwards, the hidden vectors of RNN are averaged
to generate document representation for sentiment classiﬁ-
cation.

Paragraph Vector implements the Distributed Memory
Model of Paragraph Vectors (Le and Mikolov 2014) for doc-

Table 3: Effect of user attention and product attention. HUA only uses user information and local text, and HPA only uses
product information and local text.

Models

NSC+LA(BiLSTM)
HUA
HPA
HUAPA

IMDB

Yelp 2013

Yelp 2014

Acc.
0.490
0.521
0.493
0.550

RMSE
1.325
1.300
1.326
1.185

Acc.
0.638
0.649
0.641
0.683

RMSE
0.691
0.691
0.681
0.628

Acc.
0.646
0.663
0.646
0.686

RMSE
0.678
0.661
0.678
0.626

λ1

1.0
0.7
0.7
0.4

λ2

0.0
0.3
0.0
0.3

λ3

0.0
0.0
0.3
0.3

IMDB

Yelp 2013

Yelp 2014

Acc.
0.538
0.541
0.540
0.550

RMSE
1.229
1.239
1.287
1.185

Acc.
0.669
0.672
0.675
0.683

RMSE
0.658
0.644
0.646
0.628

Acc.
0.675
0.680
0.679
0.686

RMSE
0.647
0.641
0.633
0.626

Table 4: Effect of the different weighted loss.

ument sentiment classiﬁcation. The window size is tuned on
validation set.

JMARS is a recommendation algorithm (Diao et al.
2014), which uses the information of users and aspects with
collaborative ﬁltering and topic modeling to predict docu-
ment sentiment rating.

UPNN introduces a word-level preference matrix and a
representation vector for each user and each product into
CNN sentiment classiﬁer (Kim 2014). The meaning of
words can modiﬁed in the input layer with the preference
matrix. Finally, it concatenates the user/product representa-
tion vectors with generated review representation as features
fed into softmax layer (Tang, Qin, and Liu 2015b).

LUPDR uses recurrent neural network to embed tempo-
ral relations of reviews into the categories of distributed user
and product representations learning for the sentiment clas-
siﬁcation of reviews (Chen et al. 2016b).

NSC uses hierarchical LSTM model to encode review text

for sentiment classiﬁcation.

NSC+LA implements the idea of local semantic atten-

tion (Yang et al. 2016) based on NSC.

NSC+UPA puts user and product information account to-
gether and uses hierarchical LSTM model with attention
mechanism to generate a review representation for sentiment
classiﬁcation.

implement

Chen et al. (2016a) do not

the model
NSC+UPA and NSC+LA with bidirectional LSTM. To
make the experimental results more convincing, we imple-
ment and train them in our experimental settings. In addition
to LUPDR and the models related to NSC, we report the re-
sults in (Tang, Qin, and Liu 2015b) since we use the same
datasets for other baseline methods above.

Model Comparisons

The experimental results are given in Table 2, which are di-
vided into two parts: the models only using the local text
information, and the models incorporating both local text in-
formation and the global user and product information.

From the ﬁrst part, we can see that the majority performs
very poor because it does not use any text, user, and prod-
uct information. Compared to the methods taking SVM as
classiﬁer, hierarchical neural networks achieve better per-
formances generally. In addition, the results show NSC+LA
obtains a considerable improvements based on NSC, which
proves that importance of selecting more meaningful words
and sentences in sentiment classiﬁcation. It is also a main
reason that attention mechanism is introduced into sentiment
classiﬁcation.

From the second part, we observe that the methods con-
sidering user and product information achieve more or less
improvements compared to the corresponding methods in
the ﬁrst part. For example, TextFeature+UPF achieves 0.5%
improvement and NSC+UPA obtains 2.3% improvement on
Yelp2013 in accuracy. The comparisons indicate that the
user and product information is helpful for sentiment clas-
siﬁcation.

The experimental results show that our proposed model
with user attention and product attention achieves best per-
formance on all datasets. We can see improvements regard-
less of data scale. For smaller dataset such as Yelp2013
and IMDB, our model outperforms the previous best state-
of-the-art method by 2.8% and 1.7% respectively in accu-
racy. This ﬁnding is consistent on larger dataset. Our model
achieves improvement by 1.7% on dataset Yelp2014 in accu-
racy. The observations demonstrate that our model incorpo-
rates user and product information in a more effective way,
which ﬁnally improves review representations for sentiment
classiﬁcation.

Model Analysis: Effect of User Attention and
Product Attention
To investigate the effects of single user attention or product
attention, we also implement independent hierarchical user
attention network (HUA) and hierarchical product attention
network (HPA). Table 3 shows the performance of single
attention mechanism with user or product information. From
the table, we can observe that:

• Compared to the model NSC+LA(BiLSTM) only using
local semantic attention, HUA and HPA both achieve
some improvements, which validates the rationality of in-
corporating user and product into sentiment classiﬁcation
via attention mechanism. The results also indicate that
user attention or product attention can capture more in-
formation related to sentiment.

• The user information is more effective than the product
information to enhance review representations. Although
some words or sentences in reviews show product’s char-
acteristic, the ratings are ﬁnally decided by users. Hence,
it is reasonable that the discrimination of user’s preference
is more obvious than product’s characteristic.

• Compared to single user attention or product attention,
our model achieves better performance, which indicates
that user and product information both contribute to our
model. The results demonstrate our user attention and
product attention mechanism can catch the speciﬁc user’s
preference and product’s characteristic.

Model Analysis: Effect of the Different Weighted
Loss
The λ1, λ2, and λ3 respectively represent the weight of
loss1, loss2 and loss3. We investigate the effect of differ-
ent weighted loss by empirically adjusting their proportion.
When λ2 is set to 0, we do not use loss2 to enhance the re-
view representations. Similarly, we set λ3 to 0 to avoid the
effect of loss3. The experimental results are in Table 4. From
the Table 4 and Table 2, we can observe that:

• Compared to other state-of-the-art methods, our model
without loss2 and loss3 also achieve consistent improve-
ments on the three datasets. It indicates that our attention
mechanism is more effective in incorporating user infor-
mation and product information.

• When considering loss2 or loss3, HUAPA both obtains
some improvements. It is obvious that full HUAPA model
achieves best performance. The results demonstrate that
with the designed combined strategy, better review rep-
resentations from two views can be achieved and further
help sentiment classiﬁcation.

Case Study for Visualization of Attention
To validate our observation and demonstrate the effective-
ness of user attention and product attention, we take some
review instances in Yelp2013 dataset as example. We visu-
alize the attention weights of these reviews at word level in
HUAPA. The results are shown in Figure 2. Note that, the
darker color means higher weight.

For the review 1, we can see that the word “love” has high-
est attention weight in user attention and the word “cool” has
highest attention weight in product attention. In fact, it is in-
tuitive that “love” usually expresses user’s affection or pref-
erence, and “cool” is used to describe the characteristic of
product. There are also some reviews that user’s preference
is inconsistent with product’s characteristic, such as review
3 in Figure 2. The content of the review 3 is “much of it was
quite good but I was disappointed with the spider roll.”. It is

Figure 2: Visualization of user attention and product atten-
tion over words

obvious that the word “good” indicates the product’s char-
acteristic and the word “disappointed” shows user’s negative
sentiment. Our model not only catches such information but
also gives right prediction. The visualizations of attention
demonstrate that our model can capture global user’s prefer-
ence and product’s characteristic.

Conclusion

In this paper, we propose a novel framework incorporat-
ing user and product information for sentiment classiﬁca-
tion. Speciﬁcally, we ﬁrstly apply two individual hierarchi-
cal neural networks to generate two representations, with
user attention or with product attention. Then, we design a
combined strategy to make full use of the two representa-
tions for training and ﬁnal prediction. We evaluate our model
on several sentiment classiﬁcation datasets. The experimen-
tal results show that our model achieves obvious and consis-
tent improvements compared to other state-of-the-art meth-
ods. Finally, the visualizations of attention also show our
model can capture user information and product informa-
tion.

Acknowledgments

We would like to thank the anonymous reviewers for
their insightful comments. This work was supported by
the 863 program(No. 2015AA015406) and the NSFC(No.
61472183, 61672277).

References

[Bahdanau, Cho, and Bengio 2015] Bahdanau, D.; Cho, K.;
and Bengio, Y. 2015. Neural machine translation by jointly
learning to align and translate. In ICLR.
[Bengio et al. 2003] Bengio, Y.; Ducharme, R.; Vincent, P.;
and Jauvin, C. 2003. A neural probabilistic language model.
JMLR 3(Feb):1137–1155.
[Chen et al. 2016a] Chen, H.; Sun, M.; Tu, C.; Lin, Y.; and
Liu, Z. 2016a. Neural sentiment classiﬁcation with user and
product attention. In EMNLP, 1650–1659.
[Chen et al. 2016b] Chen, T.; Xu, R.; He, Y.; Xia, Y.; and
Wang, X. 2016b. Learning user and product distributed rep-
resentations using a sequence model for sentiment analysis.
IEEE Computational Intelligence Magazine 11(3):34–44.
[Dahl et al. 2012] Dahl, G. E.; Yu, D.; Deng, L.; and Acero,
A. 2012. Context-dependent pre-trained deep neural net-
TASLP
works for large-vocabulary speech recognition.
20(1):30–42.

[Diao et al. 2014] Diao, Q.; Qiu, M.; Wu, C.-Y.; Smola, A. J.;
Jiang, J.; and Wang, C. 2014.
Jointly modeling aspects,
ratings and sentiments for movie recommendation (jmars).
In KDD, 193–202.
[Ding, Liu, and Yu 2008] Ding, X.; Liu, B.; and Yu, P. S.
2008. A holistic lexicon-based approach to opinion mining.
In WSDM, 231–240.
[Fan et al. 2008] Fan, R.-E.; Chang, K.-W.; Hsieh, C.-J.;
Wang, X.-R.; and Lin, C.-J. 2008. Liblinear: A library for
large linear classiﬁcation. JMLR 9(Aug):1871–1874.
[Gao et al. 2013] Gao, W.; Yoshinaga, N.; Kaji, N.; and Kit-
suregawa, M. 2013. Modeling user leniency and product
In IJCNLP, 1107–
popularity for sentiment classiﬁcation.
1111.

[Glorot, Bordes, and Bengio 2011] Glorot, X.; Bordes, A.;
and Bengio, Y. 2011. Domain adaptation for large-scale sen-
timent classiﬁcation: A deep learning approach. In ICML,
513–520.

S.,

[Hochreiter and Schmidhuber 1997] Hochreiter,
and
Schmidhuber, J. 1997. Long short-term memory. Neural
Computation 9(8):1735–1780.
[Johnson and Zhang 2015] Johnson, R., and Zhang, T. 2015.
Effective use of word order for text categorization with con-
volutional neural networks. In HLT-NAACL, 103–112.
[Kim 2014] Kim, Y. 2014. Convolutional neural networks
for sentence classiﬁcation. In EMNLP, 1746–1751.
[Kingma and Ba 2015] Kingma, D., and Ba, J. 2015. Adam:
A method for stochastic optimization. In ICLR.
[Kiritchenko, Zhu, and Mohammad 2014] Kiritchenko, S.;
Zhu, X.; and Mohammad, S. M. 2014. Sentiment analysis
of short informal texts. JAIR 50:723–762.
[Krizhevsky, Sutskever, and Hinton 2012] Krizhevsky, A.;
Imagenet classiﬁ-
Sutskever, I.; and Hinton, G. E. 2012.
In NIPS,
cation with deep convolutional neural networks.
1097–1105.

2011.

Ifrim, G.;

[Le and Mikolov 2014] Le, Q., and Mikolov, T. 2014. Dis-
tributed representations of sentences and documents.
In
ICML, 1188–1196.
[Liu 2012] Liu, B. 2012. Sentiment analysis and opinion
mining. Synthesis Lectures on Human Language Technolo-
gies 5(1):1–167.
[Mikolov et al. 2013] Mikolov, T.; Sutskever, I.; Chen, K.;
Corrado, G. S.; and Dean, J. 2013. Distributed represen-
tations of words and phrases and their compositionality. In
NIPS, 3111–3119.
[Pang and Lee 2005] Pang, B., and Lee, L. 2005. Seeing
stars: Exploiting class relationships for sentiment catego-
rization with respect to rating scales. In ACL, 115–124.
[Pang and Lee 2008] Pang, B., and Lee, L. 2008. Opinion
mining and sentiment analysis. Foundations and Trends in
Information Retrieval 2(12):1–135.
[Pang, Lee, and Vaithyanathan 2002] Pang, B.; Lee, L.; and
Vaithyanathan, S. 2002. Thumbs up?: sentiment classiﬁca-
tion using machine learning techniques. In EMNLP, 79–86.
[Qu, Ifrim, and Weikum 2010] Qu, L.;
and
Weikum, G. 2010. The bag-of-opinions method for review
In COLING,
rating prediction from sparse text patterns.
913–921.
J.; Huang,
[Socher et al. 2011] Socher, R.; Pennington,
E. H.; Ng, A. Y.; and Manning, C. D.
Semi-
supervised recursive autoencoders for predicting sentiment
distributions. In EMNLP, 151–161.
[Socher et al. 2012] Socher, R.; Huval, B.; Manning, C. D.;
and Ng, A. Y. 2012. Semantic compositionality through
recursive matrix-vector spaces. In EMNLP-CoNLL, 1201–
1211.
[Socher et al. 2013] Socher, R.; Perelygin, A.; Wu, J. Y.;
Chuang, J.; Manning, C. D.; Ng, A. Y.; Potts, C.; et al. 2013.
Recursive deep models for semantic compositionality over a
sentiment treebank. In EMNLP, 1631–1642.
[Srivastava et al. 2014] Srivastava, N.; Hinton, G. E.;
Krizhevsky, A.; Sutskever, I.; and Salakhutdinov, R. 2014.
Dropout: a simple way to prevent neural networks from
overﬁtting. JMLR 15(1):1929–1958.
[Sukhbaatar et al. 2015] Sukhbaatar, S.; Weston, J.; Fergus,
In NIPS,
R.; et al. 2015. End-to-end memory networks.
2440–2448.
[Taboada et al. 2011] Taboada, M.; Brooke, J.; Toﬁloski, M.;
Voll, K.; and Stede, M. 2011. Lexicon-based methods for
sentiment analysis. Computational Linguistics 37(2):267–
307.
[Tang et al. 2014] Tang, D.; Wei, F.; Yang, N.; Zhou, M.; Liu,
T.; and Qin, B. 2014. Learning sentiment-speciﬁc word em-
bedding for twitter sentiment classiﬁcation. In ACL, 1555–
1565.
[Tang, Qin, and Liu 2015a] Tang, D.; Qin, B.; and Liu, T.
2015a. Document modeling with gated recurrent neural net-
work for sentiment classiﬁcation. In EMNLP, 1422–1432.
[Tang, Qin, and Liu 2015b] Tang, D.; Qin, B.; and Liu, T.
2015b. Learning semantic representations of users and prod-

In ACL,

ucts for document level sentiment classiﬁcation.
1014–1023.
[Vinyals et al. 2015] Vinyals, O.; Kaiser, Ł.; Koo, T.; Petrov,
S.; Sutskever, I.; and Hinton, G. 2015. Grammar as a foreign
language. In NIPS, 2773–2781.
[Xu et al. 2015] Xu, K.; Ba, J.; Kiros, R.; Cho, K.; Courville,
2015.
A.; Salakhudinov, R.; Zemel, R.; and Bengio, Y.
Show, attend and tell: Neural image caption generation with
visual attention. In ICML, 2048–2057.
[Yang et al. 2016] Yang, Z.; Yang, D.; Dyer, C.; He, X.;
Smola, A. J.; and Hovy, E. H. 2016. Hierarchical atten-
tion networks for document classiﬁcation. In HLT-NAACL,
1480–1489.

