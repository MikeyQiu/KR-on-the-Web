Causal Inference Under Interference And Network Uncertainty

9
1
0
2
 
n
u
J
 
9
2
 
 
]

G
L
.
s
c
[
 
 
1
v
1
2
2
0
0
.
7
0
9
1
:
v
i
X
r
a

Rohit Bhattacharya

Ilya Shpitser

Daniel Malinsky
Department of Computer Science
Johns Hopkins University
{rbhattacharya@, malinsky@, ilyas@cs.}jhu.edu

Abstract

Classical causal and statistical inference meth-
ods typically assume the observed data con-
sists of independent realizations. However, in
many applications this assumption is inappro-
priate due to a network of dependences be-
tween units in the data. Methods for esti-
mating causal effects have been developed in
the setting where the structure of dependence
between units is known exactly [12, 40, 24],
but in practice there is often substantial un-
certainty about the precise network structure.
This is true, for example, in trial data drawn
from vulnerable communities where social ties
are difﬁcult to query directly. In this paper we
combine techniques from the structure learn-
ing and interference literatures in causal in-
ference, proposing a general method for esti-
mating causal effects under data dependence
when the structure of this dependence is not
known a priori. We demonstrate the utility of
our method on synthetic datasets which exhibit
network dependence.

1

INTRODUCTION

In many scientiﬁc and policy settings, research subjects
do not exist in isolation but in interacting networks. For
instance, data drawn from an online social network will
exhibit homophily (friends are similar, because they are
friends), and contagion (friends may causally inﬂuence
each other) [19, 33, 15, 34]. Similarly, vaccinating some
subset of a population may confer immunity to the entire
population – a well-documented phenomenon known as
herd immunity in infectious disease epidemiology. This
implies that a treatment given to one unit affects out-
comes for another. Finally, resource constraints in al-
location problems may also induce data dependence.

In the context of causal inference, methods for dealing
with data dependence are developed under the heading
of interference [36, 10, 31, 12, 40, 33, 24, 39]. Most such
work assumes the structure of the dependence (which
units depend on which others, and how) is known pre-
cisely. For example, [40] assumes units in the data may
be organized into equal sized blocks, where units within
a block are pairwise dependent and units across blocks
are not. Some work makes alternative assumptions, e.g.,
[39] assumes that blocks are drawn from a known ran-
dom ﬁeld.

In many applications, the network inducing dependence
between units may not be known exactly. For instance,
in vulnerable, stigmatized, or isolated communities (such
as groups of drug users, or remote villages), we may
have no way of reconstructing the precise social ties be-
tween individuals. Some online databases of social me-
dia users may be anonymized, with friendship ties delib-
erately omitted. There has been some work in such set-
tings that involves adapting the data collection method
itself in order to discover the underlying networks: e.g.,
snowball sampling in [5] and [3]. Unfortunately, such
study designs are not always possible to arrange in ad-
vance, and most data available on networks of interacting
units is not collected under such designs.

While there is a rich literature on model selection from
observational data in the context of causal inference (e.g.,
[37, 4, 35, 27]), to our knowledge all previous work has
assumed the absence of interference. We explore learn-
ing the dependence structure using graphical model se-
lection methods. Techniques for structure learning from
probabilistic relational models are also related to this
work [21, 18].

The contributions of our paper may be viewed in one of
two ways. From the point of view of causal inference
under interference, our paper contributes to methods for
estimating causal effects when there is substantial uncer-
tainty about network structure. From the point of view

of structure learning, we introduce novel algorithms for
model selection when units are dependent due to a net-
work, the structure of which is unknown.

2 MOTIVATING EXAMPLE AND

BACKGROUND ASSUMPTIONS

To motivate our work, we discuss an example applica-
tion. Consider a public health program aimed at lowering
the incidence of blood-borne diseases such as HIV in at-
risk individuals who are addicted to heroin and share nee-
dles when injecting intravenously. An example of such a
program is described in [38]. The program creates pop-
up clinics around the city where disposable needles are
distributed for free to individuals in need, but due to lim-
ited resources only a limited number of individuals will
actually receive these needles. We would like to know,
in this restricted resource setting, if the use of disposable
needles spreads amongst the rest of the population. Ad-
ditionally, we would like to detect the phenomenon of
herd immunity, i.e., whether some members of the pop-
ulation being protected due to taking advantage of the
clean needles confer this protection to others who do not.

Data on heroin users was collected via such program,
with users arranged by neighborhood or municipality.
Users in different neighborhoods are assumed indepen-
dent, but users within the same neighborhood are likely
dependent. This setting is known as partial interfer-
ence [12]. For each individual i, data is collected on
their use of disposable needles Ai,
their subsequent
health outcome Yi (risk of obtaining blood-born dis-
ease), along with a vector of pre-treatment covariates
Li = (L1,i, ..., Lp,i). We may be interested in quanti-
fying the causal effects of Ai on Yj, for arbitrary i and j
within a neighborhood, or network-averaged versions of
such effects [24].

We may assume that background knowledge or study de-
sign implies a “known” individual-level causal structure
for each i, namely that Ai → Yi and Ai ← Li → Yi, but
that we are uncertain about network ties among users.
One approach is to assume the least restrictive model,
where all users in a neighborhood are arbitrarily depen-
dent. This would correspond to a complete network,
where every pair of vertices is directly connected. How-
ever, assuming a complete network when the true net-
work is sparse ignores useful structure in the problem
and leads to inefﬁcient estimates of target quantities. In
addition, complete networks often lead to likelihoods
that are intractable to evaluate. An alternative is to a se-
lect a sparse network supported by the data. In addition
to enabling tractable and statistically efﬁcient inference,
such an approach may also rule out the presence of cer-

L1

L2

L3

L4

A1

A2

A3

A4

Y1

Y2

Y3

Y4

Figure 1: A chain graph over three variables (L, A, and
Y ) on 4 individuals, representing possible relationships
between disposable needle use and risk of blood-borne
disease among heroin-users.

tain causal effects without explicitly estimating them, if
corresponding pathways are absent in the selected net-
work.

As an example, if neighborhoods have 4 units, we may
aim to learn a graphical model such as shown in Figure
1. This model, containing both directed edges (represent-
ing direct causal inﬂuences) and undirected edges (rep-
resenting symmetric network ties), is known as a chain
graph model [16]. We describe chain graphs in more de-
tail below. This model tells us that we should expect
some spread of disposable needle use from one unit to
another. However, it also tells us that users in neighbor-
hoods are split into two non-interacting groups: {1, 2}
and {3, 4}. This implies the absence of contagion from
one group to another. In addition, the conditional inde-
pendences among units implied by this split suggests that
contagion effects within groups may be estimated more
efﬁciently as compared to a statistically saturated model,
with a complete network across units.

The algorithms we propose are consistent (in the sense
that they asymptotically converge on the true model)
under a set of assumptions which we now informally
summarize. We assume the true data-generating pro-
cess corresponds perfectly (satisfying Markov and faith-
fulness conditions) to some unknown chain graph, with
two restrictions: (1) the unit-level graph is known, re-
ﬂecting the aforementioned causal ordering between pre-
treatment covariates, treatment variables, and outcomes;
and (2) the graph respects what we later call tier symme-
try, which restricts connections between variables at the
same “tier” in the causal ordering to be symmetric. We
assume the data is distributed with some (known) likeli-
hood in the exponential family, as well as some weak sta-
tistical regularity conditions. We also present algorithms
that make an additional simplifying assumption on the
graphical structure – namely that inﬂuence between units
is the same for all unit pairs – but such an assumption is
not strictly necessary for consistency.

We begin by describing some technical preliminaries, in-
cluding chain graph models, causal inference, and graph-
ical model selection. Then we present algorithms to learn
graphical models of the sort shown in Figure 1, before
estimating causal effects.

3 PRELIMINARIES

3.1 Graphical Terminology

Chain graphs (CGs) are a class of mixed graphs contain-
ing directed (→) and undirected (−) edges, such that it
is impossible to create a directed cycle by orienting any
combination of the undirected edges [16]. A CG with no
undirected edges is a directed acyclic graph (DAG). A
CG with no directed edges is an undirected graph (UG)
Vertices of a graph are denoted by capital letters (e.g.
A), and they correspond to random variables. We use
boldface (e.g. A) to denote sets of vertices or sets of ran-
dom variables. Lowercase letters denote speciﬁc values
of random variables (e.g. a) or sets of values (e.g. a). We
use V and E to denote the set of all vertices and edges in
a graph G, respectively.

For a subset of vertices A ⊆ V we deﬁne the induced
subgraph GA to be the graph with vertices A and edges
of G that have both endpoints in A. A block B is deﬁned
as a maximal set of vertices such that every vertex pair in
GB is connected by an undirected path. The set of blocks
in a CG G, denoted by B(G), partitions the vertices in G.
A clique C is deﬁned as a maximal set of vertices that
are pairwise connected by undirected edges. A clique in
a CG is always a subset of some block B. We denote the
set of all cliques in an UG G by C(G).

For a graph G and vertex V ∈ V we deﬁne some stan-
dard vertex sets as follows: the set of parents paG(V ) ≡
{V (cid:48) : V (cid:48) → V in G}; the set of neighbors nbG(V ) ≡
{V (cid:48) : V (cid:48) − V in G}; the boundary bdG(V ) ≡ paG(V ) ∪
nbG(V ); and the closure clG(V ) ≡ bdG(V ) ∪ V .
These deﬁnitions generalize disjunctively to sets, e.g.
paG(A) ≡ (cid:83)
A∈A paG(A). Note that for a block B,
bdG(B) = B ∪ paG(B). Given a CG G, deﬁne the aug-
mented graph Ga to be an UG constructed from G by
replacing all directed edges with undirected edges and
connecting all vertices in paG(B) for every block B in G
by undirected edges.

We will utilize chain graphs to represent both causal rela-
tionships and network dependence among units that form
a (“social”) network N . The undirected network N is a
graph (distinct from our CG of interest) where the ver-
tices correspond to units (e.g. individuals i, j, ...), not
random variables. Units may be adjacent or non-adjacent
in N based on whether they are “friends” or otherwise

directly dependent.

For each unit i, we denote the unit-level variables for i
in the CG G (e.g., Li, Ai, and Yi in Figure 1) by Vi, and
edges among those variables by Ei. Similarly, for a pair
of units i, j which are adjacent in N , we represent the
set of edges from Vi to Vj (and vice versa) by Eij. It is
the presence of these edges that induces data dependence
between i and j in our analysis. The set of Eij for all pairs
i, j adjacent in N (i.e., the set of all cross-unit edges) will
be denoted by EN .

3.2 Chain Graph Models

A statistical chain graph model associated with a LWF
(Lauritzen-Wermuth-Frydenberg) chain graph G is a set
of distributions that factorize as:

p(V) =

(cid:89)

p(B | paG(B))

B∈B(G)

and

p(B | paG(B)) =

(cid:81)

(1)
{C∈C((GbdG (B))a):C(cid:54)⊆paG (B)} φC(C)
Z(paG(B))

for each block B in G, where φC(C) is a clique potential
function for a clique C in the UG (GbdG (B))a deﬁned as
above and Z(paG(B)) is a normalizing function [16].

A CG without undirected edges is a DAG, which has a
simpler factorization: p(V) = (cid:81)
V ∈V p(V | paG(V )).
If it is the case that for every block B in CG G, GbdG (B)
has missing edges only among elements of paG(B), then
(GbdG (B))a has a single clique containing all elements
in bdG(B). In other words, the model corresponding to
such a CG may be viewed as a DAG model with entire
blocks B acting as vertices in a DAG.

3.3 Causal Models

A causal model is a set of distributions over counter-
factual random variables, a.k.a. potential outcomes. For
Y ∈ V and A ⊆ V \ Y , the counterfactual Y (a) denotes
the value of Y when the “treatment” variables A are ﬁxed
to values a by an intervention. Sometimes interventions
are formalized by the ‘do’-operator: do(a) denotes the
assigment a to A [25]. The counterfactual distribution
corresponding to the intervention where A is set to a is
written p(Y (a)) or p(Y | do(a)).

A causal model of a DAG G is a set of distributions de-
ﬁned on counterfactual random variables V (a) for each
V ∈ V and where a is a set of values for paG(V ). Equiv-
alently, a causal model can be understood as the set of
distributions induced by a system of structural equations
(one equation for each vertex) equipped with the do(·)

In a causal model of a DAG G, all
operator [25, 29].
counterfactual distributions are identiﬁed, i.e., they can
be expressed as functions of the observed data, by the
g-formula [30]:

identiﬁed causal effect of interest in network settings (for
example, spillover effects). Consider a block is of size m
and two ﬁxed π1, π2 assignment probabilities. Then the
PAOE is deﬁned as:

p(V \ A | do(a)) =

p(V | paG(V ))

E[Yi(A)]{π1(A) − π2(A)}.

(3)

(cid:89)

V ∈V\A

(cid:12)
(cid:12)
(cid:12)
(cid:12)A=a

.

1
m

m
(cid:88)

(cid:88)

i=1

A

Counterfactual responses to interventions are often con-
trasted on a mean difference scale under two possible
interventions a and a(cid:48), representing cases and controls.
For example, the average causal effect (ACE) is given by
E[Y (a)] − E[Y (a(cid:48))].

Causal models have been generalized from DAGs to CGs
(details in the Supplement) and yield the following gen-
eralization of the g-formula [17]:

p(V \ A| do(a)) =

p(B \ A | pa(B), B ∩ A)

(cid:89)

B∈B(G)

3.4 The Conditionally Ignorable Network Model

and Network Causal Effects

For the purposes of this paper, we consider CGs decom-
posed into three disjoint sets of variables: L, represent-
ing vectors of baseline (pre-treatment) factors; A, repre-
senting treatments; and Y, representing outcomes. For
each unit i, we assume Li ⊆ paG(Ai), and Li ∪ {Ai} ⊆
paG(Yi). This represents a common assumption (which
we call causal ordering) in causal inference that for each
unit both baseline factors and treatment potentially af-
fect the outcome, and that the baseline factors also affect
treatment assignment. Here each unit has one treatment
variable Ai, one outcome variable Yi, and possibly many
baseline variables Li. In interference settings, it is stan-
dard to allow that variables for another unit j may inﬂu-
ence variables for unit i. In our case, there is a further
complication: the precise nature of this inﬂuence is un-
known.

This model implies, for positive p(V), the following
standard assumptions from the interference literature:
Y(a) ⊥⊥ A | L (network ignorability); p(a | L) > 0
∀a (positivity); and Y(a) = Y if A = a (consis-
tency). Under these assumptions, the joint counterfac-
tual outcome is identiﬁed, regardless of the underlyling
network structure, as the following special case of (2):
p(Y(a)) = (cid:80)

L p(Y | A = a, L)p(L).

Given a particular treatment assignment probability
π(A), a number of causal effects of interest may be de-
ﬁned, see [40] for an extensive discussion. In this paper,
we focus on a single effect, the population average over-
all effect (PAOE), though our results generalize to any

Under the aforementioned assumptions,
identiﬁed by the following functional [40]:

this effect is

1
m

m
(cid:88)

(cid:88)

i=1

L,A

E[Yi | A, L]p(L){π1(A) − π2(A)}.

(4)

.

(cid:12)
(cid:12)
(cid:12)
(cid:12)A=a
(2)

A number of estimation strategies for (4) are possible un-
der various assumptions on network structure. For ex-
ample, [40] considered an inverse probability weighted
estimator. In this paper, we use the auto-g-computation
algorithm in [39] to estimate the PAOE, which allows for
arbitrary network structure; we describe this estimator in
detail in the Supplement.

4 MODEL SELECTION FOR
UNKNOWN NETWORKS

We are interested in estimating causal effects like the
PAOE under the aforementioned assumptions, where
there is uncertainty about the network structure. We give
a taxonomy of problems of this type, having different
levels of difﬁculty depending on the degree of uncer-
tainty present.

The most general version of the problem occurs when
neither the causal structure of each unit, nor the network
structure inducing dependence between units, is known.
In this case the problem reduces to a structure learning
problem for arbitrary chain graphs, as considered in [20]
and [26]. We do not pursue this version of the problem
here for two reasons. First, the causal structure for each
unit is often known due to background knowledge on
temporal ordering and study design, as is the case for our
needle-dispensary motivating example. Second, model
selection of arbitrary CGs is known to be a very chal-
lenging problem which (in the worst case) may require
large sample sizes [6].

In many settings, the causal structure for each individual
unit is known and is typically assumed to be the same
for every unit, i.e., Ei = Ej for all i, j. The problem
of model selection then amounts to learning the struc-
ture of the connections between units i.e., Eij for all i, j.
The search space for such a problem, while much smaller
than the general problem, is still exponential. For a block
(cid:1) possible pairings of
that contains m units, there are (cid:0)m

2

units, leading to 2(m
2 ) possible networks. The number of
possible valid chain graphs is even larger, since units i, j
adjacent in a network could be connected in a variety of
ways via (undirected or directed) edges in Eij. Learning
these connections requires a search through all possible
combinations of edges that form Eij such that the overall
graph is a CG.

We may restrict the problem further by requiring that the
connections between any two units, if present, are ho-
mogenous, meaning that dependence between any two
units, if it exists, arises in the same way. Formally, we
deﬁne homogeneity such that, for all pairs (i, j), (k, l) ∈
N , Eij = Ekl. Notice that the space of homogenous
networks is still fairly large. The problem may be made
more tractable by one of the following two assumptions.
We may assume the existence of network connections is
known, but that their types are unknown, i.e., we know
N and would like to learn Eij. Alternatively, we may as-
sume we know how two adjacent units are connected, but
not which pairs are adjacent, i.e., we know Eij and would
like to learn N . We may also have no such background
knowledge. In the following, we present algorithms for
both homogenous and heterogenous settings.

Throughout, we make an assumption which we call tier
symmetry, which is commonly made implicitly or explic-
itly in the interference literature [40, 39]. That is, we re-
quire connections between variables in the same “tier” of
causal ordering to represent symmetric relations between
the variables. This restricts edges Li − Lj, Ai − Aj, and
Yi − Yj to always be undirected. Also it is natural to
extend the known causal ordering of variables to connec-
tions between units: while we allow for e.g., Ai → Yj,
the reverse, Yj → Ai is ruled out. Finally, we rule out
the existence of undirected edges connecting variables
across tiers, e.g, edges of the form Ai − Yj, since the ex-
istence of such edges, coupled with our causal ordering
assumption, leads to graphs which are not CGs.

Before presenting algorithms to address the above taxon-
omy of problems, we introduce some necessary concepts
from the graphical model selection literature.

4.1 Markov Properties and Faithfulness

If p(V) is a positive distribution, the factorization (1) is
equivalent to a global Markov property which relates cer-
tain graphical separation facts in the CG G (given by the
c-separation criterion) to conditional independence rela-
tions in p(V); see [16] for precise deﬁnitions. In what
follows, we make the faithfulness assumption, which is
if (A ⊥⊥
the converse of the global Markov property:
B | C) in p(V), then A is c-separated from B given C
in G. This is directly analogous to the faithfulness as-

sumption made when selecting DAG models from data
by constraint-based or score-based methods [37, 4].

4.2 Model Scores and the Pseudolikelihood

In this paper, we will learn the structure of the network
using a score-based approach to model selection. Score-
based methods proceed by choosing the graph (from
among some space of candidates) that optimizes a model
score. Exhaustive model search is typically infeasible,
so it is popular to employ greedy methods that optimize
only “locally,” that is, they traverse the space of candi-
date graphs considering only single-edge additions and
deletions. Under some conditions, such greedy proce-
dures can be shown to asymptotically converge to the
globally optimal model [4]. Scores used for greedy
search typically satisfy three properties that are sufﬁcient
for ﬁnding the globally optimal model: decomposability,
score-equivalence, and consistency.

A score is said to be decomposable if it can be written
as a sum of local contributions, each a function of one
vertex and its boundary. A score is said to be score-
equivalent if two Markov equivalent graphs (i.e., graphs
that imply the same set of conditional independences by
the global Markov property) yield the same score. A
score is said to be consistent if, as the sample size goes to
inﬁnity, the following two conditions hold. First, when
two models both contain the true generating model, the
model of lower dimension will have a better score. Sec-
ond, when one model contains the true model and an-
other does not, the former will have a better score.

A popular score satisfying these properties for model
selection among DAG models
the Bayesian
Given a d-
Information Criterion (BIC)
dimensional data set D of size n and model likelihood
L(D; G) ≡ (cid:81)n
i=1 p(x1,i, . . . , xd,i; G), the BIC is given
by 2 ln L(D; G) − k ln(n) where k is model dimension.

[32].

is

For CG models,
the BIC is only decomposable for
blocks, not for variables within the block. In addition,
the score is not easy to evaluate. Both of these issues
arise due to the presence of normalizing functions in the
likelihood. Here, we present an alternative score which
avoids some of these problems, based on the pseudolike-
lihood function [2]:

PL(D; G) ≡

p(xj,i | x−j,i; G),

n
(cid:89)

d
(cid:89)

i=1

j=1

where x−j is the vector (x1, . . . , xj−1, xj+1, . . . , xd).
We deﬁne a score based on the pseudolikelihood called
Pseudo-BIC (PBIC): 2 ln PL(D; G) − k ln(n).

We propose a greedy score-based model selection proce-

dure based on the PBIC score, which is consistent and
obeys a weaker notion of decomposability for exponen-
tial families, as we show below. All proofs are deferred
to the Supplement.

Lemma 1. With dimension ﬁxed and sample size in-
creasing to inﬁnity, the PBIC is a consistent score for
curved exponential families whose natural parameter
space Θ forms a compact set.

Decomposability of a scoring criterion makes greedy
search a practical procedure, by limiting the number of
terms in the overall score that need to be recomputed for
each considered edge modiﬁcation. While the BIC score
for DAG models is decomposable, the PBIC score for
CG models is not. Nevertheless, a weaker notion of de-
composability holds, which implies that two CG models
that differ by a single edge differ by a subset of compo-
nents of the score, which we now describe. Consider a
candidate edge between Vi and Vj in a CG G. Let Bloc
denote the block to which Vj belongs when the edge is
directed Vi → Vj, or to which Vi and Vj belong when
the edge is undirected Vi − Vj. We use loc(Vi, Vj; G) to
denote a set of vertices called the local set, deﬁned as:

{C ∈ C((GbdG (Bloc))a) : Vi, Vj ∈ C (cid:54)⊆ paG(Bloc)}.

(cid:91)

C

As we show, the score difference for graphs G and G(cid:48)
which differ by a single edge can be written as the dif-
ference between terms that involve only variables in the
local set of G. The next result, and much subsequent
discussion in the paper, is stated for conditional Markov
random ﬁelds (MRFs). This is because statistical CG
models can be equivalently described as sets of condi-
tional MRF models. We elaborate on this relationship in
the Supplement.
Lemma 2. Let G and G(cid:48) be graphs which differ by a
single edge between Vi and Vj. For conditional MRFs in
the exponential family, the local score difference between
(cid:0)D; G(cid:1) −
G and G(cid:48) is given by: (cid:80)
(cid:0)D; G(cid:48)(cid:1)}, where sV (.) denotes the component of the
sV
score for V .

V ∈loc(Vi,Vj ;G)∩Bloc

{sV

Note that the above deﬁnition of the local set may sim-
plify further in certain special cases of MRF models in
the exponential family. In particular, if we consider an
MRF that is multivariate normal, or a log linear discrete
model with only main effects and pairwise interactions,
then the sum in Lemma 2 reduces to either a sum over el-
ements Vi and Vj (for an undirected edge Vi −Vj) or only
Vj (for a directed edge Vi → Vj). We omit the straight-
forward proofs in the interest of space. We will not con-
sider these special instances of the exponential family in
the remainder of this paper, but in the supplement we

Algorithm 1 GREEDY NETWORK SEARCH(Ginit, D)

1: G∗ ← Ginit
2: score change ← True
3: while score change do
4:
5:
6:
7:
8:
9:
10: return E ∗
N

G∗ ← G∗ \ Emax
score change ← True

score change ← False
E ∗
N ← network ties in G∗
Emax ← argmaxE∈E ∗
if PBIC(D; G∗ \ Emax) > PBIC(D; G∗) then

PBIC(D; G∗ \ E)

N

(cid:46) deleting edge Emax

discuss the incurred computational costs for exponential
families in general.

4.3 Greedy Network Search

While there exist numerous methods that
take a
pseudolikelihood-type approach to model selection in
UGs [28, 13, 7, 1], these have been typically restricted
to Ising or Gaussian models. Such methods involve a
per-vertex neighbourhood selection procedure using L1-
regularized regression or the standard BIC, which may
yield self-inconsistent results (e.g., ﬁnd that Vi in nb(Vj)
but not vice versa). Any resulting inconsistencies would
need to be resolved post hoc through union or intersec-
tion consolidation procedures. Methods that try to en-
force self-consistency by explicitly maximizing the pseu-
dolikelihood with a regularization penalty are presented
in [9] and [14], but are again restricted to Ising and Gaus-
sian graphical models. The properties of the PBIC de-
scribed in the previous section allow us to design algo-
rithms for greedy network search that are parallelizable,
while also generalizing to all exponential families and
circumventing the need for post hoc procedures. While
our method covers a more general class of models, it
can be computationally expensive to calculate the local
scores at each step. A more efﬁcient procedure is possi-
ble in some subclasses (including Ising and Gaussian),
where we can modify our procedure into a “forward-
backward” algorithm reminiscent of the GES algorithm
[4]. Since our focus is on a general procedure for all ex-
ponential families, we defer further discussion of these
special cases to the Supplement.

We begin by describing a greedy search procedure that
learns network ties EN , without imposing homogeneity.
Model selection proceeds by solving 3 independent sub
problems: learning a Markov random ﬁeld (MRF) over
the baseline covariates L, learning a conditional MRF
on the treatments A, and learning a conditional MRF
on the outcomes Y. The resulting network ties learned
from each of these, are combined to produce the ﬁnal re-

Algorithm 2 HETEROGENOUS(Gcomplete, D)

1: GL, GA, GY ← conditional MRFs on L, A, and Y

formed from Gcomplete

← GREEDY NETWORK SEARCH(GL, D)
← GREEDY NETWORK SEARCH(GA, D)
← GREEDY NETWORK SEARCH(GY, D)

2: E ∗
NL
3: E ∗
NA
4: E ∗
NY
5: return E ∗
NL

∪ E ∗
NA

∪ E ∗
NY

Algorithm 3 HOMOGENOUS(Gcomplete, D, Eproto N )
1: G∗ ← graph obtained by removing all edges between

units i, j in Gcomplete when Eij (cid:54)∈ h(Eproto N )

score change ← False
N ∗ ← network in G∗
(i, j)max ← argmax(i,j)∈N ∗ PBIC(D; G∗ \ Eij)
if PBIC(D; G∗ \ Eijmax ) > PBIC(D; G∗) then

2: score change ← True
3: while score change do
4:
5:
6:
7:
8:
9:
10: return N ∗

G∗ ← G∗ \ Eijmax
score change ← True

sult (Alg. 2). Each of the above subproblems is solved
by a greedy search procedure (Alg. 1) that starts with
the complete conditional MRF (or MRF), and deletes the
edge that yields the greatest improvement to the PBIC
score on each iteration.

We now describe procedures for learning network ties
in the homogenous setting, after deﬁning some prelimi-
naries. The homologs of an edge Eij ∈ EN with end-
points Ui, Wj ∈ V, are deﬁned as: h(Eij) ≡ {Ekl ∈
EN : endpoints(Ekl) = Uk, Wl}. The network tie
prototypes in a homogenous graph G are deﬁned as:
Eproto N ≡ {Eij ∈ Eij for any (i, j) ∈ N }. h(Eproto N )
can then be deﬁned as: {h(E) : E ∈ Eproto N }.

When the types of connections Eproto N between any two
connected units is known, we start with a CG that is
fully connected as Eproto N for every pairwise combina-
tion of units. Search proceeds by deleting Eij between
two units i and j that yields the best improvement in the
PBIC on each iteration (Alg. 3). When the social net-
work N is known, we start with a CG where pairs of
units in N are fully connected in network ties. Search
proceeds by deleting all homologs of the type of edge in
Eproto N that yields the best improvement in the PBIC on
each iteration (Alg. 4). Finally, when there is no back-
ground knowledge, homogenous search (Alg. 5) can be
performed by chaining the operations of Alg. 3 and Alg.
4 (or vice versa) on the CG complete in network ties for
every pairwise combination of units.

Algorithm 4 HOMOGENOUS(Gcomplete, D, N )
1: G∗ ← graph obtained by removing all edges between

units i, j in Gcomplete when (i, j) (cid:54)∈ N

2: score change ← True
3: while score change do
4:
5:
6:

score change ← False
E ∗
proto N ← prototypes of network ties in G∗
PBIC(D; G∗ \ h(E))
Emax ← argmaxE∈E ∗
if PBIC(D; G∗ \ h(Emax) > PBIC(D; G∗) then

proto N

7:
8:
9:
10: return E ∗

proto N

G∗ ← G∗ \ h(Emax)
score change ← True

Algorithm 5 HOMOGENOUS(Gcomplete, D)
1: Eproto N ← prototypes of network ties in Gcomplete
2: N ∗ ← HOMOGENOUS(Gcomplete, D, Eproto N )
proto N ← HOMOGENOUS(Gcomplete, D, N ∗)
3: E ∗
4: return N ∗, E ∗

proto N

the true underlying network ties are homogenous, since
it is most general. However, intuitively we expect the
homogenous procedures to fare better in a ﬁnite data set-
ting, because the homogeneity assumption allows pool-
ing data from samples across units for each edge deletion
test. This intuition is conﬁrmed in our simulations.

4.4 Size of the Search Space

2

In the heterogenous case, the search space grows as
O(|Eproto N |(cid:0)m
(cid:1)) i.e., as a function of the number of
possible edges between two units i and j multiplied
by the number of possible pairings on m units. Un-
der homogeneity when Eproto N is known, this reduces to
O((cid:0)m
(cid:1)); when N is known, it reduces to O(|Eproto N |);
and under homogeneity where neither is available, it is
O((cid:0)m

(cid:1)) + O(|Eproto N |).

2

2

4.5 Consistency of Network Search

Lemma 3. If the generating distribution is Markov to
a CG satisfying tier symmetry and the causal ordering
assumption, then the search space of GREEDY NET-
WORK SEARCH consists of graphs belonging to their
own equivalence classes of size 1.

Theorem 1. If the generating distribution is in the expo-
nential family (with compact natural parameter space Θ)
and is Markov and faithful to a CG satisfying tier sym-
metry and causal ordering, then GREEDY NETWORK
SEARCH is consistent.

Clearly we could use the heterogenous procedure even if

Under the same assumptions in the theorem above, we

have the following corollary results.
Corollary 1.1. The HETEROGENOUS procedure is con-
sistent.

Corollary 1.2. When the true network ties are homoge-
nous, the HOMOGENOUS procedure is consistent.

5 EXPERIMENTS

We evaluate the performance of our proposed algorithms
on networks of varying size, for various block sizes, and
for different regularity settings. (Regularity refers to the
number of neighbors for each unit i in the dependency
network N . This setting thus controls the density of the
graph.) We consider blocks of size 4, 8, 16, and 32, with
regularity 2 or 3. The ground truth models are homoge-
nous and of the form shown in Figures 2 and 3, where we
display the case of block size 4. Data is generated from
each network via a Gibbs sampler with a burn-in period
of 1000 iterations and thinning every 100 iterations using
the following equations:

p(Li = 1) = expit(τ1),

p(Ai = 1|Li, {Aj : j ∈ nbN (i)}) =

expit(β1Li + β2

p(Yi = 1|Li, Ai, {Aj : j ∈ nbN (i)}) =

expit(ν1Li + ν2Ai + ν3

(cid:88)

Aj),

j∈nbN (i)

(cid:88)

Aj),

j∈nbN (i)

where expit(x) = (1 + exp(−x))−1. We emphasize that
some of these networks are quite large; for example, the
network with block size 32 and 2000 iid blocks has an
effective size of 64,000 individuals. For each network
setting we run 100 bootstraps of structure learning in or-
der to get an average estimate of precision and recall as
shown in Figure 4. However, to spare computation time,
we use only Algorithm 3 on the latter two block settings.
An interesting feature of the results in Figure 4, which
matches our earlier intuition, is the faster convergence of
the homogenous procedures to the true model – which
we attribute to the parameter sharing (effectively using
of more data when testing each edge deletion).

In order to demonstrate the utility of learning the struc-
ture in dealing with network uncertainty, we consider the
population average overall effect (3). We ﬁrst execute
structure learning, and then estimate the PAOE, contrast-
ing a treatment assignment determined with probabil-
ity 0.7 with the naturally observed probability. We do
this for 2-regular networks with 2000 realizations of iid
blocks of varying size. We use the heterogenous proce-
dure and one of the homogenous procedures (Alg. 3) to
learn the structure of the networks. Estimation of the

causal effect is done by the auto-g-computation algo-
rithm described in [39] and the Supplement. We per-
form a 1000 bootstraps of both structure learning and
effect estimation to compare the bias and variance of
the estimates from the learned graphs to the estimates
provided by utilizing the maximally uninformative com-
plete graph. Unfortunately the auto-g-computation pro-
cedure is also computationally intensive because it re-
quires Gibbs sampling. Again, to spare computation time
we do not run the heterogenous procedure on the larger
graphs with block sizes 16 and 32 (networks with 32,000
and 64,000 individuals). We also only perform 8 boot-
straps for these larger networks. In order to emphasize
the need to deal with interference and network uncer-
tainty appropriately, we additionally estimated the bias
for 200 bootstraps of the network with blocks of size 8
using the empty graph (a complete iid assumption), and
an incorrect graph where N is shufﬂed randomly to have
incorrect adjacencies. In both cases the bias turned out to
be approximately .06, an order of magnitude higher than
the bias from utilizing the complete or learned graphs.

Figure 2: The 2-regular CG for a block of size 4

L1

L3

L1

L3

A1

A3

A1

A3

Y1

Y3

Y1

Y3

Y2Y2

Y4

Y2Y2

Y4

A2

A4

A2

A4

L2

L4

L2

L4

Figure 3: The 3-regular CG for a block of size 4

From Table 1 we see that causal effect estimates based
on learned structure have the same or lower bias as com-

Block Size

Complete

Homogenous Heterogenous

4
8
16
32

.009, 9.2e-5
.007, 6.6e-5
.006, 3.8e-5
.007, 6.1e-5

.008, 8.1e-5
.006, 4.1e-5
.005, 1.9e-5
.002, 7.6e-6

.009, 9.7e-5
.006, 4.5e-5
x
x

Table 1: Bias and variance for estimating the PAOE.

Figure 4: Performance of structure learning algorithms as measured by precision and recall

pared with using the complete graph. Furthermore, the
sparsity of the learned graph reduces variance of the es-
timates in most cases. This reduction in bias and vari-
ance is more easily achieved when we are able to exploit
homogeneity in the network structure.
In experiments
with lower sample sizes, we see that the bias of effect
estimates may increase (because the learning procedure
may fail to recover the true graph) but that the variance
of the estimates remains comparable to or lower than the
estimates based on the complete graph.

6 CONCLUSION

We have developed a method for estimating causal ef-
fects under unit dependence induced by a network rep-
resented by a chain graph (CG) model [16], when there
is uncertainty about network structure. Instead of esti-
mating causal effects given a completely uninformative
network where each pair of units is connected, as is typ-
ically done in the interference literature [40, 41], we es-
timated causal effects given a sparser network learned
via a score-based model selection method based on the
pseudolikelihood function [2]. We showed that this strat-
egy can yield lower variance in estimates without sac-
riﬁcing bias, if the underlying true network structure is
recovered accurately. Our model selection method re-

lied on weak parametric assumptions, speciﬁcally that
all Markov factors in the CG model corresponded to
conditional Markov random ﬁelds in the exponential
family. The approach here is a generalization of local
score-based search algorithms for directed acyclic graph
(DAG) models [4] to CG models. As a price of this gen-
eralization, our local search algorithms recompute a po-
tentially larger part of the model score with every move
through the model space. In addition, our approach only
works for settings with partial interference, where units
within a block exhibit dependence, but data on blocks is
iid. The restriction to blocks of identical size may be re-
laxed by combining our heterogeneous procedure with a
scheme of parameter sharing and hierarchical modeling
across blocks that are of different sizes. In future work,
we aim to extend our methods to full interference set-
tings.

Acknowledgements

This project is sponsored in part by the NIH grant R01
AI127271-01 A1, the ONR grant N00014-18-1-2760,
and DARPA under contract HR0011-18-C-0049. The
content of the information does not necessarily reﬂect the
position or the policy of the Government, and no ofﬁcial
endorsement should be inferred.

References

[1] Rina Foygel Barber and Mathias Drton.

High-
dimensional Ising model selection with Bayesian infor-
mation criteria. Electronic Journal of Statistics, 9(1):567–
607, 2015.

[2] Julian Besag. Spatial interaction and the statistical anal-
ysis of lattice systems. Journal of the Royal Statistical
Society: Series B (Methodological Statistics), 36(2):192–
236, 1974.

[3] Yann Bramoull´e, Andrea Galeotti, and Brian Rogers. The
Oxford Handbook of the Economics of Networks. Oxford
University Press, 2016.

[4] David Maxwell Chickering. Optimal structure identiﬁca-
tion with greedy search. Journal of Machine Learning
Research, 3(Nov):507–554, 2002.

[5] Forrest W. Crawford, Peter M. Aronow, Li Zeng, and
Jianghong Li. Identiﬁcation of homophily and preferen-
tial recruitment in respondent-driven sampling. American
Journal of Epidemiology, 187(1):153–160, 2017.

[6] Robin J. Evans. Model selection and local geometry.

arXiv preprint arXiv:1801.08364, 2018.

[7] Rina Foygel and Mathias Drton. Extended Bayesian in-
formation criteria for Gaussian graphical models. In Ad-
vances in Neural Information Processing Systems, pages
604–612, 2010.

[8] Dominique M. A. Haughton. On the choice of a model to
ﬁt data from an exponential family. Annals of Statistics,
16(1):342–355, 1988.

[9] Holger H¨oﬂing and Robert Tibshirani. Estimation of
sparse binary pairwise markov networks using pseudo-
Journal of Machine Learning Research,
likelihoods.
10(Apr):883–906, 2009.

[10] Guanglei Hong and Stephen W. Raudenbush. Evaluat-
ing kindergarten retention policy: A case study of causal
inference for multilevel observational data. Journal of
the American Statistical Association, 101(475):901–910,
2006.

[11] Peter J. Huber. The behavior of maximum likelihood es-
In Proceedings
timates under nonstandard conditions.
of the Fifth Berkeley Symposium on Mathematical Statis-
tics and Probability, Volume 1: Statistics, pages 221–233.
University of California Press, 1967.

[12] Michael G. Hudgens and M. Elizabeth Halloran. Toward
causal inference with interference. Journal of the Ameri-
can Statistical Association, 103(482):832–842, 2008.

[13] Ali Jalali, Christopher C. Johnson, and Pradeep K.
Ravikumar. On learning discrete graphical models us-
ing greedy methods. In Advances in Neural Information
Processing Systems, pages 1935–1943, 2011.

[14] Kshitij Khare, Sang-Yun Oh, and Bala Rajaratnam. A
convex pseudolikelihood framework for high dimensional
partial correlation estimation with convergence guaran-
tees. Journal of the Royal Statistical Society: Series B
(Statistical Methodology), 77(4):803–825, 2015.

[15] Adam D. I. Kramer, Jamie E Guillory, and Jeffrey T. Han-
cock. Experimental evidence of massive-scale emotional
contagion through social networks. Proceedings of the
National Academy of Sciences, pages 8788–8790, 2014.

[16] Steffen L. Lauritzen. Graphical Models. Oxford Univer-

sity Press, 1996.

[17] Steffen L. Lauritzen and Thomas S. Richardson. Chain
Jour-
graph models and their causal interpretations.
nal of the Royal Statistical Society: Series B (Statistical
Methodology), 64(3):321–348, 2002.

[18] Sanghack Lee and Vasant Honavar. On learning causal
In Thirtieth AAAI Confer-

models from relational data.
ence on Artiﬁcial Intelligence, pages 3263–3270, 2016.

[19] Kevin Lewis, Marco Gonzalez, and Jason Kaufman. So-
cial selection and peer inﬂuence in an online social net-
work. Proceedings of the National Academy of Sciences,
109(1):68–72, 2012.

[20] Zongming Ma, Xianchao Xie, and Zhi Geng. Structural
learning of chain graphs via decomposition. Journal of
Machine Learning Research, 9(Dec):2847–2880, 2008.

[21] Marc Maier, Katerina Marazopoulou, David Arbour, and
David Jensen. A sound and complete algorithm for learn-
ing causal models from relational data. In Proceedings of
the Twenty-Ninth Conference on Uncertainty in Artiﬁcial
Intelligence, pages 371–380. AUAI Press, 2013.

[22] Alexander Mozeika, Onur Dikmen, and Joonas Piili.
Consistent inference of a general model using the pseu-
dolikelihood method. Phys. Rev. E, 90:010101, 2014.

[23] Elizabeth L. Ogburn, Ilya Shpitser, and Youjin Lee.
Causal inference, social networks, and chain graphs.
arXiv preprint arXiv:1812.04990, 2018.

[24] Elizabeth L. Ogburn and Tyler J. VanderWeele. Causal
diagrams for interference. Statistical Science, 29(4):559–
578, 2014.

[25] Judea Pearl. Causality. Cambridge University Press,

2009.

[26] Jose Pe˜na, Dag Sonntag, and Jens Nielsen. An inclusion
optimal algorithm for chain graph structure learning. In
Proceedings of the 17th International Conference on Ar-
tiﬁcial Intelligence and Statistics, pages 778–786, 2014.

[27] Jonas Peters, Joris M. Mooij, Dominik Janzing, and Bern-
hard Sch¨olkopf. Causal discovery with continuous addi-
tive noise models. The Journal of Machine Learning Re-
search, 15(1):2009–2053, 2014.

[28] Pradeep K. Ravikumar, Martin J. Wainwright, and
John D. Lafferty. High-dimensional Ising model selec-
tion using L1-regularized logistic regression. Annals of
Statistics, 38(3):1287–1319, 2010.

[29] Thomas S. Richardson and James M. Robins. Single
world intervention graphs (SWIGs): A uniﬁcation of
the counterfactual and graphical approaches to causality.
Center for the Statistics and the Social Sciences, Univer-
sity of Washington Series. Working Paper 128, pages 1–
146, 2013.

[30] James M. Robins. A new approach to causal infer-
ence in mortality studies with a sustained exposure pe-
riod—application to control of the healthy worker sur-
vivor effect. Mathematical Modelling, 7(9-12):1393–
1512, 1986.

[31] Paul R. Rosenbaum. Interference between units in ran-
domized experiments. Journal of the American Statistical
Association, 102(477):191–200, 2007.

[32] Gideon Schwarz. Estimating the dimension of a model.

Annals of Statistics, 6(2):461–464, 1978.

[33] Cosma Rohilla Shalizi and Andrew C. Thomas. Ho-
mophily and contagion are generically confounded in ob-
servational social network studies. Sociological Methods
& Research, 40(2):211–239, 2011.

[34] Eli Sherman and Ilya Shpitser. Identiﬁcation and estima-
tion of causal effects from dependent data. In Advances in
Neural Information Processing Systems 31, pages 9424–
9435. 2018.

[35] Shohei Shimizu. LiNGAM: non-Gaussian methods for
estimating causal structures. Behaviormetrika, 41(1):65–
98, 2014.

[36] Michael E. Sobel. What do randomized studies of hous-
ing mobility demonstrate? Causal inference in the face of
interference. Journal of the American Statistical Associ-
ation, 101(476):1398–1407, 2006.

[37] Peter Spirtes, Clark Glymour, and Richard Scheines.
Causation, Prediction, and Search. MIT press, 2nd edi-
tion, 2000.

[38] Sharon Stancliff, Bruce Agins, Josiah D. Rich, and Scott
Burris. Syringe access for the prevention of blood borne
BMC Public
infections among injection drug users.
Health, 3(1):37, 2003.

[39] Eric J. Tchetgen Tchetgen, Isabel Fulcher, and Ilya Sh-
pitser. Auto-G-Computation of causal effects on a net-
work. arXiv:1709.01577, 2017.

[40] Eric J. Tchetgen Tchetgen and Tyler J. VanderWeele. On
causal inference in the presence of interference. Statisti-
cal Methods in Medical Research, 21(1):55–75, 2012.

[41] Tyler J. VanderWeele, Eric J. Tchetgen Tchetgen, and
M. Elizabeth Halloran. Components of the indirect ef-
fect in vaccine trials: identiﬁcation of contagion and in-
fectiousness effects. Epidemiology, 23(5):751, 2012.

[42] Daniel Westreich, Stephen R. Cole, Jessica G. Young,
Frank Palella, Phyllis C. Tien, Lawrence Kingsley,
Stephen J. Gange, and Miguel A. Hern´an. The paramet-
ric g-formula to estimate the effect of highly active an-
tiretroviral therapy on incident aids or death. Statistics in
Medicine, 31(18):2000–2009, 2012.

Supplementary Material

CAUSAL CHAIN GRAPHS AND THEIR
INTERPRETATION

Causal models associated with DAGs may be general-
ized to causal models associated with CGs. CGs may in-
clude directed edges, representing direct causation, and
undirected edges, representing symmetric relationships
between units in a network. A causal interpretation
of CGs, understood as equilibria of dynamic models
with feedback, was given in [17]. Under this interpre-
tation, the distribution p(B | paG(B)) for each block
B ∈ B(G) can be determined by a Gibbs sampler on
the variables B ∈ B. Here, each conditional distribution
p(B | B\B, paG(B)) is produced by structural equations
of the form fB(B \ B, paG(B), (cid:15)B). Interventions on el-
ements of B are deﬁned by replacing the appropriate line
in the Gibbs sampler program. For all disjoint sets Y and
A, [17] showed that p(Y | do(a)) is identiﬁed by a CG
version of the g-formula (2).

If only interventions on entire blocks are of interest, i.e.,
we consider only treatment assignments A such that if
B ∩ A (cid:54)= ∅ then B ⊆ A, then an alternative causal in-
terpretation of a CG G that does not rely on the Gibbs
sampler machinery of [17] exists. Speciﬁcally, in such a
case we consider a causal DAG model where each block
B corresponds to a supervariable VB deﬁned as a Carte-
sian product of variables in B, and a DAG causal model
is deﬁned on VB(A), where A are values assigned to par-
ents of VB.
If, for each block B in a CG G, the graph (GbdG (B))a has
a single clique, then this yields a classical causal model
of a DAG, deﬁned on {VB|B ∈ B(G)}. If not, we can still
view the model as a classical causal model of a DAG, but
with an extra restriction that the observed data distribu-
tion factorizes as (1). See also [23] for a perspective on
interpreting chain graphs in an interference setting.

The model selection methodology introduced here does
not depend on which causal interpretation for chain
graphs one may choose, and all causal models described
above lead to interventional distributions being identiﬁed
by (2).

CONDITIONAL MRFs

A CG model can be viewed as a set of conditional MRFs.
A conditional MRF corresponds to a graph whose ver-
tices can be partitioned into two disjoint sets: W, cor-
responding to non-random variables whose values are
ﬁxed; and V, corresponding to random variables. The
only edges allowed in a conditional MRF are directed

edges W → V and undirected edges V − V (cid:48)
for W ∈ W and V, V (cid:48) ∈ V. A statistical model associ-
ated with a conditional MRF G is a set of densities that
factorize as:

p(V | W) =

(cid:81)

{C∈C((GbdG (V))a):C(cid:54)⊆W} φC(C)
Z(W)

It is easy to see that the above factorization is analogous
to the second level of CG factorization found in (1) where
V is a block, and W are its parents.

THE AUTO-G-COMPUTATION
ALGORITHM

The auto-g-computation algorithm, introduced in [39],
may be viewed as a generalization of the Monte Carlo
sampling version of the g-computation algorithm for
classical causal models (represented by DAGs) [42] to
causal models of the sort we consider here, represented
by CGs. We describe a version of this algorithm based
on the pseudolikelihood estimator. An alternative based
on the coding estimator [2] is less efﬁcient, but leads to
asymptotically normal estimators of the population aver-
age overall effect (PAOE).

Auto-g-computation generates samples from either the
observed data distribution that factorizes as (1) according
to a CG, or of functions of these distributions, such as
counterfactual expectations identiﬁed using (4).

This is done by imposing a topological ordering on
blocks in a CG, and generating samples for each block
sequentially using Gibbs sampling. The parameters
for Gibbs factors used in the sampler (which by the
global Markov property for CGs take the form of
p(Xi|XbdG (Xi))) are learned via maximizing the pseu-
dolikelihood function. For any block X, the Gibbs sam-
pler draws samples from p(X | bdG(X)), given a ﬁxed
set of samples drawn from all blocks with elements in
paG(X) as follows:

Gibbs Sampler for X:

for t = 0, let x(0) denote initial values ;
for t = 1, ..., T

draw value of X (t)
1
draw value of X (t)
2
...
draw value of X (t)

from p(X1|x(t−1)
from p(X2|x(t−1)

bdG (X1)));
bdG (X2)));

m from p(Xm|x(t−1)

bdG (Xm)));

This method may be used to estimate the counterfac-
tual expectation in (4) as follows. We ﬁrst generate a

set of samples L(t), t = 1, . . . , T . Then we generate
a sample A directly using some πi(A), i = 1, 2. Fi-
nally, we use the above samples to generate a set of
samples Y(t), t = 1, . . . , T using Gibbs factors p(Yi |
AA∩bdG (Yi), bdG(Yi) \ A). Finally, we estimate

ing additional assumptions, such as Gaussianity, or non-
existence of higher order interaction terms in log-linear
models. We contrast this with DAG models, where the
local set is of constant size regardless of parametric as-
sumptions made.

1
m

m
(cid:88)

i=1

E[Yi(A)] =

1
m · T

m
(cid:88)

T
(cid:88)

i=1

t=1

Y (t)
i

.

It is not difﬁcult to show, (see [39] for details), that rerun-
ning this procedure with different draws A from either
π1(A) or π2(A), and taking the difference of the result-
ing averages yields a valid estimate of the PAOE.

Fitting parameters of Gibbs factors using the pseudo-
likelihood function avoids the usual difﬁculties CGs in-
herit from Markov random ﬁelds, speciﬁcally, the in-
tractability of the likelihood function due to the pres-
ence of normalizing functions. In addition, if the learned
block structure is sparse, while the number of indepen-
dent samples considered is small, this approach allows
one to impose parameter sharing among Gibbs factors,
which leads to reasonable estimates even in small sam-
ples. Taken to the extreme, this approach allows infer-
ences to be made even from a single sample of a network,
as discussed in detail in [39]. In this manuscript we only
consider the setting where multiple independent samples
from blocks are available.

COMPUTATIONAL COMPLEXITY OF
COMPUTING SCORES OF A CHAIN
GRAPH MODEL

In blocks of a CG, the number of local terms that need
to be computed corresponds to the number of vertices
present in cliques containing the edge of interest in the
augmented subgraph of the block and its parents. A term
for Vj requires an O(| bdG(Vj)|) computation to update,
which in the worst case may be exponential in the num-
ber of vertices if the graph is not sparse. In search prob-
lems, restrictions can be made on the maximum size of
the boundary set, sacriﬁcing accuracy for tractability. For
a block in a CG corresponding to a conditional MRF in
the exponential family, and an edge that is present in a
set of cliques spanning all vertices, we will have a local
set of size O(d) in the worst case, with each local term
requiring an O(clique size) computation. Thus, limiting
the maximum clique size may speed up the computation
of each local term, but in many cases we may be unable
to avoid an O(d) number of such terms. In other words,
our scoring method for CG models where blocks cor-
respond to conditional MRFs in the exponential family
may not scale to very large graphs, even if such graphs
are sparse. Achieving such a scaling will entail mak-

FORWARD-BACKWARD SEARCH

Consistency of the score was sufﬁcient to show consis-
tency of a backwards greedy search involving only edge
deletions starting from a complete conditional MRF.
[4] showed that a property called local consistency,
which follows from decomposability and consistency of
the score, is sufﬁcient to design a consistent forward-
backward greedy search in the space of (Markov equiv-
alent) DAGs. The forward stepwise search considers ad-
ditions, rather than deletions, of single edges to improve
the score, which typically produces a more sparse start-
ing model for the subsequent backwards search.

Consider a graph G and another G(cid:48) that differs only by
the addition of an edge Vi − Vj or Vi → Vj. A score
S(D; G) is called locally consistent if:

1. Vi (cid:54)⊥⊥G0 Vj | bdG(Vi) or Vj (cid:54)⊥⊥G0 Vi | bdG(Vj)

then limn→∞ P (S(D; G(cid:48)) > S(D; G)) → 1

2. Vi ⊥⊥G0 Vj | bdG(cid:48)(Vi) and Vj ⊥⊥G0 Vi | bdG(Vj)

then limn→∞ P (S(D; G(cid:48)) < S(D; G)) → 1

Such a property requires a stronger notion of decompos-
ability than is available in our general setting. In Section
4.2 we mention that if our model is an MRF that is mul-
tivariate normal, or corresponds to a log linear discrete
model with only main effects and pairwise interactions,
then it sufﬁces to consider the following terms derived
from the local set: {s(Vi, bdG(Vi)), s(Vj, bdG(Vj))} for
an edge Vi − Vj, and {s(Vj, bdG(Vj))} for an edge
Vi → Vj (dropping implicit D and G for brevity). This
is the strong notion of decomposability we need for local
consistency. Thus, in such settings one can follow the
work in [4] to show that PBIC will be locally consistent
and design a search procedure involving a forward phase
followed by a backward phase. The advantage of such a
procedure is that it is more scalable, even more so when
the underlying true model is sparse.

PROOFS

Let M0 denote the true model and M1, M2 two candi-
date models. A scoring criterion S(D; M) is said to be

k
2

k
2

consistent if:

lim
n→∞

Pn(S(D; M1) < S(D; M2)) → 1 when

M1 (cid:54)⊇ M0 and M2 ⊇ M0 or

M1, M2 ⊇ M0 and k1 > k2.

(*)

(**)

Lemma 1 With dimension ﬁxed and sample size increas-
ing to inﬁnity, the PBIC is a consistent score for curved
exponential families whose natural parameter space Θ
forms a compact set.

sup
θ∈M∩Θ

n
(cid:88)

i=1

from a curved exponential family density p(X; θ) =
h(X)exp(θT (X) − Z(θ)), where θ ∈ Rk is a set of
canonical parameters in the natural parameter space Θ,
T (X) is a set of sufﬁcient statistics, and Z(θ) is a nor-
malizing function. For a particular choice of a model M
in this setting, the BIC can be written as lnLn(D; ˆθ) −
k
2 ln(n) or equivalently,

θT (Xi) − Z(θ) −

ln(n),

(11)

Proof. To prove consistency we need to show that,

lim
n→∞

Pn(P BIC(D; M1) < P BIC(D; M2)) → 1

(5)

when (*) or (**).

Note in all following steps, we assume D to be implicit in
the calculation of the likelihoods and pseudolikelihoods.

To prove (5) holds under the scenario (*), it is sufﬁcient
to show that the following is true for some (cid:15) > 0

Note that for simplicity of notation and without loss of
generality, we set h(X) = 1. Now consider Tn =
1
the sample average of the sufﬁcient
n
statistics. We can then express (11) as

i=1 T (Xi),

(cid:80)n

n sup

θTn − Z(θ) −

ln(n).

(12)

θ∈M∩Θ

Deﬁne the quantities Sn,i and Un as,

Sn,i ≡ sup

θiTn − Z(θi) = ˆθn,iTn − Z(ˆθn,i),

(ln PLn(ˆθ2) − ln PLn(ˆθ1)) > (cid:15)

(6)

θi∈Mi∩Θ
Un ≡ θ0Tn − Z(θ0),

It was shown in [8] that for any M1 outside of a neigh-
bourhood N of θ0, and M2 containing this neighbour-
hood, we can pick a δ > 0 such that:

(ln Ln(ˆθ2) − ln Ln(ˆθ1)) > δ

(7)

where ˆθn,i is the MLE. We now show that Sn,i − Un and
by extension each term in (10) is Op(1/n). Since θ0 lies
in both model spaces under scenario (**),

Sn,i−Un = (ˆθn,i−θ0)Tn−Z(ˆθn,i)+Z(θ0) ≥ 0. (13)

In order to extend this result to (6), we invoke a result
from [22] stating that

PLn(θ) ≥ dLn(θ) +

Hi( (cid:101)Pn)

(8)

d
(cid:88)

i=1

where d is the dimensionality of the data, and Hi( (cid:101)Pn) is
the Shannon entropy of the empirical distribution. It then
follows that (6) holds when (7) is true.

Showing that (5) holds under the scenario (**) is equiva-
lent to showing that the following difference is Op(1/n):

| ln PLn(ˆθ1) − ln PLn(ˆθ2)|

(9)

Considering the Taylor expansion of Z about θ0, we have
that Z(ˆθn,i) − Z(θ0) = (ˆθn,i − θ0)∇Z(θ0) + Op(1/n),
where the Op(1/n) term comes from the efﬁciency of
MLE [11]. Plugging this into (13) we get,

Sn,i−Un = (Tn−∇Z(θ0))(ˆθn,i−θ0)+Op(1/n). (14)

√

By the Central Limit Theorem, Tn − ∇Z(θ0) is
n) and by the efﬁciency of MLE, ˆθn,i − θ0 is
Op(1/
n). Thus, Sn,i − Un is Op(1/n), and we
also Op(1/
have our result.

√

In order to extend this result to (9), we once again invoke
the result from [22] that

Consider the difference between the full log-likelihoods:

PLn(θ) ≥ dLn(θ) +

Hi( (cid:101)Pn)

(15)

| ln Ln(ˆθ1) − ln Ln(ˆθ2)|.

(10)

We ﬁrst closely follow the proof in [8] to show that
the quantity in (10) is Op(1/n). Consider data drawn

where Hi( (cid:101)Pn) is the Shannon entropy of the empirical
distribution. We see that as long d (cid:28) n (which in our
setting we assume to be true), (10) being Op(1/n) im-
plies that (9) is as well.

d
(cid:88)

i=1

1
n

1
n

1
n

1
n

Lemma 2 Let G and G(cid:48) be graphs which differ by a
single edge between Vi and Vj. For conditional MRFs in
the exponential family, the local score difference between
(cid:0)D; G(cid:1) −
G and G(cid:48) is given by: (cid:80)
(cid:0)D; G(cid:48)(cid:1)}, where sV (.) denotes the component of the
sV
score for V .

V ∈loc(Vi,Vj ;G)∩Bloc

{sV

Proof. A conditional MRF corresponding to p(B |
paG(B)) for a block B in a CG G in the (conditional)
exponential family has a probability distribution of the
general form:

will be parameterized by the same set of ψS in the model
for G− as it was in the model for G.

Our conclusion then follows because, by properties of
the exponential family,
the sufﬁcient statistics for a
clique parameter ψS are functions of only S. Since draws
from p(S) are ﬁxed, the estimates for ψS will coincide
if the data is evaluated under the model for G, and the
model for G−. Furthermore, the number of parameters
in p(V | bdG(V )) and p(V | bdG− (V )) is the same.
This implies the score contribution for p(V | bdG(V )) in
G will equal the score contribution of p(V | bdG−(V ))
in G−. The only terms remaining in the score differ-
ence between G and G(cid:48) are then local scores for V ∈
loc(Vi, Vj; G).

(16)



(cid:88)

ψCT (C) − Z(ψ, paG(B))



{C∈C((GbdG (B))a):C(cid:54)⊆paG (B)}

This implies the conclusion.

p(B | paG(B); ψ) =



exp



where

(cid:8)ψC : C ∈ C((GbdG (B))a), C (cid:54)⊆ paG(B)(cid:9)

is a set of canonical parameters associated with potential
functions φC in the CG factorization,

(cid:8)T (C) : C ∈ C((GbdG (B))a), C (cid:54)⊆ paG(B)(cid:9)

is a set of sufﬁcient statistics for ψC, and Z(θ, paG(B))
is a normalizing function.

Assume V is in a clique C that contains the edge Vi − Vj
in G, and let G− be the edge subgraph of G with that edge
removed. Then p(V | bdG(V )) will only be a function of
clique parameters ψS, where S ⊆ C((GbdG (B))a) : C (cid:54)⊆
paG(B) and V ∈ S. All others terms in the factorization
cancel by deﬁnition of conditioning. As a consequence,
p(V | bdG(V )) will be a function of ψC.

However, after Vi − Vj is removed, C will no longer be
a clique in G−, by deﬁnition, but will instead decom-
pose into two cliques, say C1 and C2. By following the
above reasoning, p(V | bdG− (V )) will be a function of
all clique parameters {ψS : S ⊆ C((GbdG (B))a), C (cid:54)⊆
paG(B), V ∈ S}, which will include ψC1 and ψC2. Since
the parameterization for p(V | bdG− (V )) is thus differ-
ent in models for G and G−, the contribution to the score
associated with this term will also be different.

Assume V is not in a clique that contains the edge Vi−Vj
in G, and let G− be the edge subgraph of G with that edge
removed, as before. Then p(V | bdG(V )) will only be
a function of clique parameters ψS, where S contains V ,
all others will cancel by deﬁnition of conditioning.

Note that since no such S contains the edge Vi − Vj in G,
the set of cliques S in G is the same as the set of cliques S
in G−. Moreover, since G− is an edge subgraph of G, no
new cliques are introduced. As a result, p(V | bdG−(V ))

Lemma 3 If the generating distribution is Markov to
a CG satisfying tier symmetry and the causal ordering
assumption, then the search space of GREEDY NET-
WORK SEARCH consists of graphs belonging to their
own equivalence classes of size 1.

Proof. Under the restrictions listed above,
the only
changes allowed are edge deletions or additions of the
form Li − Lj, Ai − Aj, Yi − Yj, Li → Aj, Li → Yj,
Ai → Yj.

Consider an edge deletion Vi − Vj in G, giving rise to
a graph G(cid:48). Notice that boundaries of Vi and Vj have
changed. Thus by the local Markov property on chain
graphs, G and G(cid:48) must imply different conditional inde-
pendences. Concretely, G implies:

Vi ⊥⊥ V \ clG(Vi) | bdG(Vi)
Vj ⊥⊥ V \ clG(Vj) | bdG(Vj)

while G(cid:48) implies:

Vi ⊥⊥ V \ (clG(Vi) \ Vj) | bdG(Vi) \ Vj
Vj ⊥⊥ V \ (clG(Vj) \ Vi) | bdG(Vj) \ Vi

We can similarly show that an edge deletion Vi → Vj
also implies different conditional independences in G and
G(cid:48). Thus, in general, an edge deletion or addition in our
search space gives rise to graphs that are not Markov
equivalent and hence, reside in their own equivalence
classes of size 1.

Theorem 1 If the generating distribution is in the expo-
nential family (with compact natural parameter space Θ)

and is Markov and faithful to a CG satisfying tier sym-
metry and causal ordering, then GREEDY NETWORK
SEARCH is consistent.

Proof. The algorithm begins with a complete conditional
MRF that contains the true underlying distribution. We
are guaranteed that the truth is contained in every state
through the entirety of the algorithm by the following
argument. Consider the ﬁrst edge deletion performed by
GNS to a conditional MRF that does not contain the true
model. It follows from consistency of the PBIC that any
such deletion would decrease the score. Choosing such
an edge deletion would contradict the greediness of the
algorithm.

Now assume the algorithm stops at a sub optimal con-
ditional MRF G that contains the truth but has more pa-
rameters than the true model G∗. We know there exists a
series of single edge deletions in EN that takes us from
G to G∗. By Lemma 3, each of these edge deletions yield
graphs in separate equivalence classes. It follows then
from the consistency of the PBIC that each of these edge
deletions strictly increases the score (each edge deletion
yields a smaller model containing the truth) and thus, a
local optimum found by greedily maximizing the PBIC
corresponds to ﬁnding the global optimum G∗.

Corollary 1.1 The HETEROGENOUS procedure is con-
sistent.

Proof. By consistency of GNS, each conditional MRF
returned for L, A, and Y corresponds to the true model.
The union of these will then produce the true CG on V.

Corollary 1.2 When the true network ties are homoge-
nous, HOMOGENOUS network search is consistent.

Proof. Each of the homogenous procedures described
above can be decomposed into a series of single edge
deletions that we have shown to be consistent.

