Self-regulation: Employing a Generative Adversarial Network to Improve
Event Detection

Yu Hong Wenxuan Zhou Jingli Zhang Qiaoming Zhu Guodong Zhou∗
Institute of Artiﬁcial Intelligence, Soochow University
School of Computer Science and Technology, Soochow University
No.1, Shizi ST, Suzhou, China, 215006
{tianxianer, wxchow024, jlzhang05}@gmail.com
{qmzhu, gdzhou}@suda.edu.cn

Abstract

Due to the ability of encoding and map-
ping semantic information into a high-
dimensional latent feature space, neural
networks have been successfully used for
detecting events to a certain extent. How-
ever, such a feature space can be easily
contaminated by spurious features inher-
ent in event detection.
In this paper, we
propose a self-regulated learning approach
by utilizing a generative adversarial net-
work to generate spurious features. On the
basis, we employ a recurrent network to
eliminate the fakes. Detailed experiments
on the ACE 2005 and TAC-KBP 2015 cor-
pora show that our proposed method is
highly effective and adaptable.

1

Introduction

Event detection aims to locate the event triggers
of speciﬁed types in text. Normally, triggers are
words or nuggets that evoke the events of interest.
Detecting events in an automatic way is chal-
lenging, not only because an event can be ex-
pressed in different words, but also because a word
may express a variety of events in different con-
texts. In particular, the frequent utilization of com-
mon words, ambiguous words and pronouns in
event mentions makes them harder to detect:

1) Generality – taken home <Transport>

Ambiguity 1 – campaign in Iraq <Attack>
Ambiguity 2 – political campaign <Elect>
Coreference – Either its bad or good <Marry>

A promising solution to this challenge is
through semantic understanding. Recently, neu-
ral networks have been widely used in this direc-
tion (Nguyen and Grishman, 2016; Ghaeini et al.,

∗ Corresponding author

2016; Feng et al., 2016; Liu et al., 2017b; Chen
et al., 2017), which allows semantics of event
mentions (trigger plus context) to be encoded in
a high-dimensional latent feature space. This fa-
cilitates the learning of deep-level semantics. Be-
sides, the use of neural networks not only strength-
ens current supervised classiﬁcation of events but
alleviates the complexity of feature engineering.

However, compared to the earlier study (Liao
and Grishman, 2010; Hong et al., 2011; Li et al.,
2013), in which the features are carefully designed
by experts, the neural network based methods suf-
fer more from spurious features. Here, spurious
feature is speciﬁed as the latent information which
looks like the semantically related information to
an event, but actually not (Liu et al., 2017a). For
example, in the following sample, the semantic
information of the word “prison” most probably
enables spurious features to come into being, be-
cause the word often co-occurs with the trigger
”taken” to evoke an Arrest-jail event instead
of the ground-truth event Transport:

2) Prison authorities have given the nod for An-
war to be taken home later in the afternoon.
Trigger: taken. Event Type: Transport

It is certain that spurious features often result
from the semantically pseudo-related context, and
during training, a neural network may mistakenly
and unconsciously preserve the memory to pro-
duce the fakes. However, it is difﬁcult to deter-
mine which words are pseudo-related in a speciﬁc
case, and when they will “jump out” to mislead the
generation of latent features during testing.

To address the challenge, we suggest to regu-
late the learning process with a two-channel self-
regulated learning strategy. In the self-regulation
process, on one hand, a generative adversarial net-
work is trained to produce the most spurious fea-
tures, while on the other hand, a neural network

(cid:28595)

(cid:28661)(cid:28660)(cid:28662)(cid:28670)(cid:28595)(cid:28675)(cid:28677)(cid:28674)(cid:28675)(cid:28660)(cid:28666)(cid:28660)(cid:28679)(cid:28668)(cid:28674)(cid:28673)(cid:28595)

(cid:22) 

(cid:7) 

(cid:28643)(cid:28677)(cid:28664)(cid:28663)(cid:28668)(cid:28662)(cid:28679)(cid:28668)(cid:28674)(cid:28673)(cid:28595)

(cid:1876) 

(cid:10) 

(cid:10)(cid:3545) 

(cid:7)(cid:3545) 

(cid:28661)(cid:28660)(cid:28662)(cid:28670)(cid:28595)(cid:28675)(cid:28677)(cid:28674)(cid:28675)(cid:28660)(cid:28666)(cid:28660)(cid:28679)(cid:28668)(cid:28674)(cid:28673)(cid:28595)

Figure 1: Self-regulated learning scheme

is equipped with a memory suppressor to elimi-
nate the fakes. Detailed experiments on event de-
tection show that our proposed method achieves
a substantial performance gain, and is capable of
robust domain adaptation.

2 Task Deﬁnition

The task of event detection is to determine whether
there is one or more event triggers in a sentence.
Trigger is deﬁned as a token or nugget that best
signals the occurrence of an event. If successfully
identiﬁed, a trigger is required to be assigned a tag
to indicate the event type:

Input: Either its bad or good
Output: its <trigger>; Marry <type>
We formalize the event detection problem as a
multi-class classiﬁcation problem. Given a sen-
tence, we classify every token of the sentence into
one of the predeﬁned event classes (Doddington
et al., 2004) or non-trigger class.

3 Self-Regulated Learning (SELF)

SELF is a double-channel model (Figure 1), con-
sisted of a cooperative network (Islam et al., 2003)
and a generative adversarial net (GAN) (Goodfel-
low et al., 2014). A memory suppressor S is used
to regulate communication between the channels.

3.1 Cooperative Network

In channel 1, the generator G is speciﬁed as a mul-
tilayer perceptron. It plays a role of a “diligent stu-
dent”. By a differentiable function G(x, θg) with
parameters θg, the generator learns to produce a
vector of latent features og that may best charac-
terize the token x, i.e., og = G(x, θg).

The discriminator D (called “a lucky profes-
sor”) is a single-layer perceptron, implemented as
a differentiable function D(og, θd) with parame-
ters θd. Relying on the feature vector og, it at-
tempts to accurately predict the probability of the
token x triggering an event for all event classes,
i.e., ˆy = D(og, θd), and assigns x to the most
probable class c (iff ˆyc > ∀ˆy¯c, ¯c (cid:3)= c).

Therefore, G and D cooperate with each other
during training, developing the parameters θg and
θd with the same goal – to minimize the perfor-
mance loss L(ˆy, y) in the detection task:

(cid:2)

(cid:3)

θg
θd

= argmin L(ˆy, y)

(1)

where, y denotes the ground-truth probability dis-
tribution over event classes, and L indicates the
deviation of the prediction from the ground truth.

3.2 Generative Adversarial Network
In channel 2, the generator ˇG and discriminator
ˇD have the same perceptual structures as G and
D. They also perform learning by differentiable
functions, respectively ˇG(x, θˇg) and ˇD(oˇg, θ ˇd
). A
major difference, however, is that they are caught
into a cycle of highly adversarial competition.

The generator ˇG is a “trouble maker”. It learns
to produce spurious features, and utilizes them to
contaminate the feature vector oˇg of the token x.
Thus ˇG changes a real sample x into a fake z –
sometimes successfully, sometimes less so. Using
the fakes, ˇG repeatedly instigates the discrimina-
tor ˇD to make mistakes. On the other side, ˇD (“a
hapless professor”) has to avoid being deceived,
and struggles to correctly detect events no matter
whether it encounters x or z.

In order to outsmart the adversary, ˇG develops
the parameters θˇg during training to maximize the
performance loss, but on the contrary, ˇD develops
the parameters θ ˇd to minimize the loss:

θˇg = argmax L(ˆy, y)
= argmin L(ˆy, y)
θ ˇd

(2)

(3)

Numerous studies have conﬁrmed that the two-
player minmax game enables both ˇG and ˇD to im-
prove their methods (Goodfellow et al., 2014; Liu
and Tuzel, 2016; Huang et al., 2017).

3.3 Regulation with Memory Suppressor

Using a memory suppressor, we try to optimize the
diligent student G. The goal is to enable G to be
as dissimilar as possible to the troublemaker ˇG.

The suppressor uses the output oˇg of ˇG as a ref-
erence resource which should be full of spurious
features. On the basis, it looks over the output og
of G, so as to verify whether the features in og
are different to those in oˇg. If very different, the
suppressor allows G to preserve the memory (viz.,
θg in G(x, θg)), otherwise update. In other word,

for G, the suppressor forcibly erases the memory
which may result in the generation of spurious fea-
tures. We call this the self-regulation.

Self-regulation is performed for the whole sen-
tence which is fed into G and ˇG. Assume that Og
is a matrix, constituted with a series of feature vec-
tors, i.e., the vectors generated by G for all the to-
kens in an input sentence (og ∈ Og), while Oˇg
is another feature matrix, generated by ˇG for the
tokens (oˇg ∈ Oˇg). Thus, we utilize the matrix ap-
proximation between Og and Oˇg for measuring the
loss of self-regulation learning Ldif f . The higher
the similarity, the greater the loss. During training,
the generator G is required to develop the param-
eters θg to minimize the loss:

θg = argmin Ldif f (og, oˇg)

(4)

We present in detail the matrix approximate cal-
culation in section 4.4, where the squared Frobe-
nius norm (Bousmalis et al., 2016) is used.

3.4 Learning to Predict

We incorporate the cooperative network with the
GAN, and enhance their learning by joint training.
In the 4-member incorporation, i.e., {G, ˇG, D
and ˇD}, the primary beneﬁciary is the lucky pro-
fessor D. It can beneﬁt from both the cooperation
in channel 1 and the competition in channel 2. The
latent features it uses are well-produced by G, and
decontaminated by eliminating possible fakes like
those made by ˇG. Therefore, in experiments, we
choose to output the prediction results of D.

In this paper, we use two recurrent neural net-
works (RNN) (Sutskever et al., 2014; Chung et al.,
2014) of the same structure as the generators. And
both the discriminators are implemented as a fully-
connected layer followed by a softmax layer.

4 Recurrent Models for SELF

RNN with long short-term memory (abbr., LSTM)
is adopted due to the superior performance in a va-
riety of NLP tasks (Liu et al., 2016a; Lin et al.,
2017; Liu et al., 2017a). Furthermore, the bidi-
rectional LSTM (Bi-LSTM) architecture (Schus-
ter and Paliwal, 1997; Ghaeini et al., 2016; Feng
et al., 2016) is strictly followed. This architecture
enables modeling of the semantics of a token with
both the preceding and following contexts.

4.1 LSTM based Generator

Given a sentence, we follow Chen et al (2015) to
take all the tokens of the whole sentence as the in-

put. Before feeding the tokens into the network,
we transform each of them into a real-valued vec-
tor x ∈ Re. The vector is formed by concatenating
a word embedding with an entity type embedding.

• Word Embedding: It is a ﬁxed-dimensional
real-valued vector which represents the hid-
den semantic properties of a token (Collobert
and Weston, 2008; Turian et al., 2010).

• Entity Type Embedding: It is specially used
to characterize the entity type associated with
a token. The BIO2 tagging scheme (Wang
and Manning, 2013; Huang et al., 2015) is
employed for assigning a type label to each
token in the sentence.

For the input token xt at the current time step t,
the LSTM generates the latent feature vector ot ∈
Rd by the previous memory. Meanwhile, the token
is used to update the current memory.

The LSTM possesses a long-term memory unit
ct ∈ Rd and short-term (cid:4)ct ∈ Rd. In addition, it
is equipped with the input gate it, forgetting gate
ft and a hidden state ht, which are assembled to-
gether to promote the use of memory, as well as
dynamic memory updating. Similarly, they are de-
ﬁned as a d-dimensional vector in Rd. Thus LSTM
works in the following way:

⎡

⎢
⎢
⎣

ot
(cid:4)ct
it
ft

⎤

⎥
⎥
⎦ =

⎡

⎢
⎢
⎣

⎤

⎥
⎥
⎦

σ
tanh
σ
σ

(cid:11)

(cid:2)

(cid:3)

(cid:12)

W

xt
ht−1

+ b

ht = ot (cid:5) tanh(ct)
ct = (cid:4)ct (cid:5) it + ct−1 (cid:5) ft

(5)

(6)

(7)

where W ∈ R4d×(d+e) and b ∈ R4d are parame-
ters of afﬁne transformation; σ refers to the logis-
tic sigmoid function and (cid:5) denotes element-wise
multiplication.

The output functions of both the generators in
SELF, i.e., G and ˇG, can be boiled down to the
output gate ot ∈ Rd of the LSTM cell:

ot = LST M (xt; θ)

(8)

where, the function LSTM (·;·) is a shorthand for
Eq. (5-7) and θ represents all the parameters of
LSTM. For both G and ˇG, θ are initialized with the
same values in experiments. But due to the distinct
training goals of G and ˇG (diligence or making-
trouble), the values of the parameters in the two

cases will change to be very different after train-
ing. Therefore, we have og,t = LST M (xt, θg,t)
and oˇg,t = LST M (xt, θˇg,t).

4.2 Fully-connected Layer for Discrimination

Depending on the feature vectors og,t and oˇg,t, the
two discriminators D and ˇD predict the probabil-
ity of the token xt triggering an event for all event
classes. As usual, they compute the probability
distribution over classes using a fully connected
layer followed by a softmax layer:

ˆy = sof tmax( ˆW · ot + ˆb)

(9)

where ˇy is a C-dimensional vector, in which each
dimension indicates the prediction for a class; C
is the class number; ˆW ∈ Rd is the weight which
needs to be learned; ˆb is a bias term.

It is noteworthy that the discriminator D and ˇD
don’t share the weight and the bias. It means that,
for the same token xt, they may make markedly
different predictions: ˆyg,t = sof tmax( ˆWg · og,t +
ˆbg) and ˆyˇg,t = sof tmax( ˆWˇg · oˇg,t + ˆbˇg).

4.3 Classiﬁcation Loss

We specify the loss as the cross-entropy between
the predicted and ground-truth probability distri-
butions over classes. Given a batch of training data
that includes N samples (xi, yi), we calculate the
losses the discriminators cause as below:

where, (cid:6) · (cid:6)2
F denotes the squared Frobenius norm
(Bousmalis et al., 2016), which is used to calculate
the similarity between matrices.

It is noteworthy that the feature vectors a gen-
erator outputs are required to serve as the rows in
the matrix, deployed in a top-down manner and
arranged in the order in which they are generated.
For example, the feature vector og,t the generator
G outputs at the time t needs to be placed in the
t-th row of the matrix Og.

At the very beginning of the measurement, the
similarity between every feature vector in Og and
that in O ˇG is ﬁrst calculated by the matrix-matrix
multiplication OgO(cid:3)
ˇg :

⎛

⎜
⎜
⎜
⎜
⎝

og,1o(cid:3)
ˇg,1
...
og,1o(cid:3)
ˇg,t
...
og,1o(cid:3)
ˇg,l

... og,1o(cid:3)
ˇg,t
...
...
... og,to(cid:3)
ˇg,t
...
...
og,lo(cid:3)
...
ˇg,t

...

... og,1o(cid:3)
ˇg,l
...
... og,to(cid:3)
ˇg,l
...
...

...
og,lo(cid:3)
ˇg,l

⎞

⎟
⎟
⎟
⎟
⎠

where, the symbol (cid:7) denotes the transpose opera-
tion; l is the sentence length which is deﬁned to be
uniform for all sentences (l=80), and if it is larger
than the real ones, padding is used; og,ioˇg,j de-
notes the scalar product between the feature vec-
tors og,i and oˇg,j.

Let Am×n be a matrix, the squared Frobenius

norm of Am×n (i.e., (cid:6)Am×n(cid:6)2

F ) is deﬁned as:

⎛

m(cid:13)

n(cid:13)

⎞

1
2

i=1

j=1

N(cid:13)

C(cid:13)

i=1
N(cid:13)

j=1
C(cid:13)

i=1

j=1

L(ˆyg, y) = −

i log(ˆyj
yj

g,i

)

(10)

(cid:6)Am×n(cid:6)2

F

⎝

=

|aij|2

⎠

(13)

L(ˆyˇg, y) = −

i log(ˆyj
yj
ˇg,i

)

(11)

where yi is a C-dimensional one-hot vector. The
value of its j-th dimension is set to be 1 only if the
token xi triggers an event of the j-th class, other-
wise 0. Both ˆyg,i and ˆyˇg,i are the predicted proba-
bility distributions over the C classes for xi.

4.4 Loss of Self-regulated Learning

Assume that Og is a matrix, consisted of the fea-
ture vectors output by G for all the tokens in a sen-
tence, i.e., og,t ∈ Og, and Oˇg is that provided by
ˇG, i.e., oˇg,t ∈ Oˇg, thus we compute the similarity
between Og and Oˇg and use it as the measure of
self-regulation loss Ldif f (Og, Oˇg):

where, aij denotes the j-th element in the i-th
row of Am×n. Thus, if we let Am×n be the ma-
trix produced by the matrix-matrix multiplication
OgO(cid:3)
ˇg , the self-regulation loss Ldif f (Og, Oˇg) can
be eventually obtained by:

Ldif f (Og, Oˇg) =

|og,ioˇg,j|2

(14)

⎛

⎝

l(cid:13)

l(cid:13)

i=1

j=1

1
2

⎞

⎠

For a batch of training data that includes N (cid:4)
sentences, the global self-regulation loss is spec-
iﬁed as the sum of the losses for all the sentences:
LSELF =

N (cid:3)
i=1 Ldif f (Og, Oˇg).

(cid:20)

4.5 Training

Ldif f (Og, Oˇg) = (cid:6)OgO(cid:3)
ˇg

(cid:6)2

F

(12)

We train the cooperative network in SELF to min-
imize the classiﬁcation loss L(ˆyg, y) and the loss

of self-regulated learning LSELF :

θg = argmin (Lˆyg, y)
θd = argmin (L(ˆyg, y) + λ · LSELF )

(15)

(16)

where λ is a hyper-parameter, which is used to har-
monize the two losses.

The min-max game is utilized for training the
adversarial net in SELF: θˇg = argmax L(ˆyˇg, y);
θ ˇd

= argmin L(ˆyˇg, y).
All the networks in SELF are trained jointly us-
ing the same batches of samples. They are trained
via stochastic gradient descent (Nguyen and Gr-
ishman, 2015) with shufﬂed mini-batches and the
AdaDelta update rule (Zeiler, 2012). The gradi-
ents are computed using back propagation. And
regularization is implemented by a dropout (Hin-
ton et al., 2012).

5 Experimentation

5.1 Resource and Experimental Datasets

We test the presented model on the ACE 2005 cor-
pus. The corpus is annotated with single-token
event triggers and has 33 predeﬁned event types
(Doddington et al., 2004; Ahn, 2006), along with
one class “None” for the non-trigger tokens, con-
stitutes a 34-class classiﬁcation problem.

For comparison purpose, we use the corpus in
the traditional way, randomly selecting 30 articles
in English from different genres as the develop-
ment set, and utilizing a separate set of 40 English
newswire articles as the test set. The remaining
529 English articles are used as the training set.

5.2 Hyperparameter Settings

The word embeddings are initialized with the 300-
dimensional real-valued vectors. We follow Chen
et al (2015) and Feng et al (2016) to pre-train the
embeddings over NYT corpus using Mikolov et al
(2013)’s skip-gram tool. The entity type embed-
dings, as usual (Nguyen et al., 2016; Feng et al.,
2016; Liu et al., 2017b), are speciﬁed as the 50-
dimensional real-valued vectors. They are initial-
ized with the 32-bit ﬂoating-point values, which
are all randomly sampled from the uniformly dis-
tributed values in [-1, 1]1. We initialize other ad-
justable parameters of the back-propagation algo-
rithm by randomly sampling in [-0.1, 0.1].

We follow Feng et al (2016) to set the dropout
rate as 0.2 and the mini-batch size as 10. We
1https://www.tensorﬂow.org/api docs/python/tf/random

uniform

tune the initialized parameters mentioned above,
harmonic coefﬁcient λ, learning rate and the L2
norm on the development set. Grid search (Liu
et al., 2017a) is used to seek for the optimal pa-
rameters. Eventually, we take the coefﬁcient λ of
0.1+3, learning rate of 0.3 and L2 norm of 0.

The source code of SELF2 to reproduce the ex-

periments has been made publicly available.

5.3 Compared Systems

The state-of-the-art models proposed in the past
decade are compared with ours. By taking learn-
ing framework as the criterion, we divide the mod-
els into three classes:

Minimally supervised approach: is Peng et al

(2016)’s MSEP-EMD.

Feature based approaches: primarily includ-
ing Liao and Grishman (2010)’s Cross-Event in-
ference model, which is based on the max-entropy
classiﬁcation and embeds the document-level con-
ﬁdent information in the feature space; Hong et al
(2011)’s Cross-Entity inference model, in which
existential backgrounds of name entities are em-
ployed as the additional discriminant features; and
Li et al (2013)’s Joint model, a sophisticated pre-
dictor frequently ranked among the top 3 in re-
cent TAC-KBP evaluations for nugget and corefer-
ence detection (Hong et al., 2014, 2015; Yu et al.,
2016).
It is based on structured perceptron and
combines the local and global features.

Neural network based approaches: including
the convolutional neural network (CNN) (Nguyen
and Grishman, 2015),
the non-consecutive N-
grams based CNN (NC-CNN) (Nguyen and Gr-
ishman, 2016) and the CNN that is assembled with
a dynamic multi-pooling layer (DM-CNN) (Chen
et al., 2015). Others include Ghaeini et al (2016)’s
forward-backward recurrent neural network (FB-
RNN) which is developed using gated recurrent
units (GRU), Nguyen et al (2016)’s bidirectional
RNN (Bi-RNN) and Feng et al (2016)’s Hybrid
networks that consist of a Bi-LSTM and a CNN.

Besides, we compare our model with Liu et al
(2016b)’s artiﬁcial neural networks (ANNs), Liu
et al (2017b)’s attention-based ANN (ANN-S2)
and Chen et al (2017)’s DM-CNN∗. The models
recently have become popular because, although
simple in structure, they are very analytic by learn-
ing from richer event examples, such as those in

2https://github.com/JoeZhouWenxuan/Self-regulation-
Employing-a-Generative-Adversarial-Network-to-Improve-
Event-Detection/tree/master

P (%) R (%)
Method
76.9
Joint (Local+Global)
75.6
MSEP-EMD
80.4
DM-CNN
DM-CNN∗
79.7
Bi-RNN
68.5
Hybrid: Bi-LSTM+CNN 80.8
SELF: Bi-LSTM+GAN 75.3

65.0
69.8
67.7
69.6
75.7
71.5
78.8

F (%)
70.4
72.6
73.5
74.3
71.9
75.9
77.0

Table 1: Trigger identiﬁcation performance

FrameNet (FN) and Wikipeida (Wiki).

5.4 Experimental Results

We evaluate our model using Precision (P), Re-
call (R) and F-score (F). To facilitate the compar-
ison, we review the best performance of the com-
petitors, which has been evaluated using the same
metrics, and publicly reported earlier.

Trigger identiﬁcation

Table 1 shows the trigger identiﬁcation perfor-
mance. It can be observed that SELF outperforms
other models, with a performance gain of no less
than 1.1% F-score.

Frankly, the performance mainly beneﬁts from
the higher recall (78.8%). But in fact the relatively
comparable precision (75.3%) to the recall rein-
forces the advantages. By contrast, although most
of the compared models achieve much higher pre-
cision over SELF, they suffer greatly from the sub-
stantial gaps between precision and recall. The ad-
vantage is offset by the greater loss of recall.

GAN plays an important role in optimizing Bi-
RNN. This is proven by the fact that SELF (Bi-
LSTM+GAN) outperforms Nguyen et al (2016)’s
Bi-RNN. To be honest, the models use two differ-
ent kinds of recurrent units. Bi-RNN uses GRUs,
but SELF uses the units that possess LSTM. Nev-
ertheless, GRU has been experimentally proven to
be comparable in performance to LSTM (Chung
et al., 2014; Jozefowicz et al., 2015). This allows
a fair comparison between Bi-RNN and SELF.

Event classiﬁcation

Table 2 shows the performance of multi-class clas-
siﬁcation. SELF achieves nearly the same F-score
as Feng et al (2016)’s Hybrid, and outperforms the
others. More importantly, SELF is the only one
which obtains a performance higher than 70% for
both precision and recall.

Besides, by analyzing the experimental results,

we have identiﬁed the following regularities:

P (%) R (%)
Methods
70.4
MSEP-EMD
68.8
Cross-Event
72.9
Cross-Entity
73.7
Joint (Local+Global)
71.8
CNN
75.6
DM-CNN
-
NC-CNN
66.8
FB-RNN (GRU)
66.0
Bi-RNN (GRU)
77.6
ANNs (ACE+FN)
DM-CNN∗(ACE+Wiki)
75.7
ANN-S2 (ACE+FN)
76.8
Hybrid: Bi-LSTM+CNN 84.6
71.3
SELF: Bi-LSTM+GAN

65.0
68.9
64.3
62.3
66.4
63.6
-
68.0
73.0
65.2
66.0
67.5
64.9
74.7

F (%)
67.6
68.8
68.3
67.5
69.0
69.1
71.3
67.4
69.3
70.7
70.5
71.9
73.4
73.0

Table 2: Detection performance (trigger identiﬁ-
cation plus multi-class classiﬁcation)

• Similar to the pattern classiﬁers that are based
on hand-designed features, the CNN models
enable higher precision to be obtained. How-
ever the recall is lower.

• The RNN models contribute to achieving a
higher recall. However the precision is lower.

• Expansion of the training data set helps to in-

crease the precision.

Let us turn to the structurally more complicated

models, SELF and Hybrid.

SELF inherits the merits of the RNN models,
classifying the events with higher recall. Besides,
by the utilization of GAN, SELF has evolved from
the traditional learning strategies, being capable of
learning from GAN and getting rid of the mistak-
enly generated spurious features. So that it outper-
forms other RNNs, with improvements of no less
than 4.5% precision and 1.7% recall.

Hybrid is elaborately established by assembling
a RNN with a CNN. It models an event from two
perspectives: language generation and pragmatics.
The former is deeply learned by using the contin-
uous states hidden in the recurrent units, while the
later the convolutional features. Multi-angled cog-
nition enables Hybrid to be more precise. How-
ever it is built using a single-channel architecture,
concatenating the RNN and the CNN. This results
in twofold accumulation of feature information,
causing a serious overﬁtting problem. Therefore,
Hybrid is localized to much higher precision but
substantially lower recall.

Overﬁtting results in enlargement of the gap be-
tween precision and recall when the task changes
to be more difﬁcult. For Hybrid, as illustrated in

MSEP-EMD                      Joint                              DM-CNN                      DM-CNN*                                   Hybrid                          Bi-RNN                            SELF 

P

R

P

R

P

R

P

R

gap=12.7% 

gap=10.1% 

85

80

75

70

65

60

gap=5.8%

%
4
.
5
=
p
a
g

 

%
9
.
1
1
=
p
a
g

 

%
4
.
1
1
=
p
a
g

85

80

75

70

65

60

85

80

75

70

65

60

 

%
2
1
=
p
a
g

(Bi-LSTM+CNN) 
R

P

(GRU) 
R

P

(Bi-LSTM+GAN) 
R

P

 

85

80

75

70

65

60

 

%
7
.
9
=
p
a
g

 

%
3
.
9
=
p
a
g

 

%
7
.
9
1
=
p
a
g

 

%
7
=
p
a
g

 

%
7
=
p
a
g

85

80

75

70

65

60

 

%
5
.
3
=
p
a
g

%
4
.
3
=
p
a
g

85

80

75

70

65

60

Trigger 

Trigger+
Type 

Trigger 

Trigger+
Type 

Trigger 

Trigger+
Type 

Trigger 

Trigger+
Type 

Trigger 

Trigger+
Type 

Trigger 

Trigger+
Type 

Trigger 

 

Trigger+
Type 

Min-supervision 

Feature engineering 

CNN-based 

Hybrid networks 

RNN-based 

85

80

75

70

65

60

 
 

Figure 2: Gaps between precision and recall in the tasks of trigger identiﬁcation and event classiﬁcation

Training Data
ACE+FN
ACE+FN
ACE+Wiki

Embedding Types
word
word, NE-type

Methods
ANNs
ANN-S2
DM-CNN∗ word, PSN
CNN
NC-CNN
Bi-RNN
Hybrid
DM-CNN
FB-RNN
SELF

word, NE-type, PSN ACE
word, NE-type, PSN ACE
word, NE-type, DEP ACE
word, NE-type, PSN ACE
ACE
word, PSN
ACE
word, branch
ACE
word, NE-type

Table 3: Embedding types and training data (DEP:
Dependency grammar; PSN: Position)

Figure 2, the gap becomes much wider (from 9%
to 19.7%) when the binary classiﬁcation task (trig-
ger identiﬁcation) is shifted to multi-class classiﬁ-
cation (event detection). By contrast, other work
shows a nearly constant gap. In particular, SELF
yields a minimum gap in each task, which changes
negligibly from 3.5% to 3.4%.

It may be added that, similar to DM-CNN and
FB-RNN, SELF is cost-effective. Compared to
other models (Table 3), it either uses less training
data, or is only required to learn two kinds of em-
beddings, such as that of words and entity types.

5.5 Discussion: Adaptation, Robustness and

Effectiveness

Domain adaptation is a key criteria for evaluating
the utility of a model in practical application. A
model can be thought of being adaptable only if it
works well for the unlabeled data in the target do-
main when trained on the source domain (Blitzer
et al., 2006; Plank and Moschitti, 2013).

We perform two groups of domain adaptation
experiments, respectively, using the ACE 2005
corpus and the corpus for TAC-KBP 2015 event
nugget track (Ellis et al., 2015).

The ACE corpus consists of 6 domains: broad-

cast conversation (bc), broadcast news (bn), tele-
phone conversation (cts), newswire (nw), usenet
(un) and web blogs (wl). Following the com-
mon practice of adaptation research on this data
(Nguyen and Grishman, 2014, 2015; Plank and
Moschitti, 2013), we take the union of bn and nw
as the source domain and bc, cts and wl as three
different target domains. We randomly select half
of the instances from bc to constitute the develop-
ment set. The TAC-KBP corpus consists of 2 do-
mains: newswire (NW) and discussion forum (DF).
We follow Peng et al (2016) to use one of NW and
DF in alternation as the source domain, while the
other the target domain. We randomly select a pro-
portion (20%) of the instances from the target do-
main to constitute the development set.

We compare with Joint, CNN, MSEP-EMD,
SSED (Sammons et al., 2015) and Hybrid. All
the models except Hybrid have been reported for
the performance assessment of domain adaptation.
In this section, we only cite the best performance
they obtained. We reproduce Hybrid by using the
source code given by authors. To ensure a fair
comparison, we perform 3 runs, in each of which,
both Hybrid and SELF were redeveloped on a new
development set. What we report herein is the av-
erage performance they obtained over the 3 runs.

Adaptation Performance

We show the adaptation performance on the ACE
corpus in Tables 4 and that on TAC-KBP in Table
5. It can be observed that SELF outperforms other
models in the out-of-domain scenarios.

Besides, when testing is performed on the out-
of-domain ACE corpus, the performance degrada-
tion of SELF is not much larger than that of CNN
and Hybrid. When the out-of-domain TAC-KBP
corpus is used, the performance of SELF is im-
paired much less severely than SSED and Hybrid.

Methods

Joint
CNN
Hybrid
SELF

In-domain (bn+nw)
P(%) R(%) F(%)

72.9
69.2
68.8
73.8

63.2
67.0
54.8
65.7

67.7
68.0
61.0
69.5

Out-of-domain (bc)
P(%) R(%) F(%) Loss
↓5.1
↓0.4
↑0.6
↓0.6

57.5
65.2
58.8
67.2

68.8
70.2
64.7
70.0

62.6
67.6
61.6
68.9

Out-of-domain (cts)
P(%) R(%) F(%) Loss
↓10.0
↓5.2
↓6.1
↓6.2

64.5
68.3
59.9
68.3

52.3
58.2
50.6
60.2

57.7
62.8
54.9
63.3

Out-of-domain (wl)
P(%) R(%) F(%) Loss
↓22.0
↓20.5
↓16.5
↓19.5

56.4
54.8
54.0
58.0

38.5
42.0
37.9
44.0

45.7
47.5
44.5
50.0

Table 4: Experimental results of domain adaptation on the ACE 2005 corpus

Methods

In-domain (NW)
P(%) R(%) F(%)

MSEP-EMD NA
NA
72.6
67.6

SSED
Hybrid
SELF

NA
NA
55.4
60.6

Out-of-domain (DF)
P(%) R(%) F(%) Loss
↓5.7
NA
↓11.4 NA
↓14.8 66.0
↓7.2
70.5

52.8
52.3
48.1
56.7

NA
NA
39.2
58.7

58.5 NA
63.7 NA
62.3
62.9
69.0
63.9

In-domain (DF)
P(%) R(%) F(%)

NA
NA
42.6
48.3

57.9
62.6
51.8
57.3

Out-of-domain (NW)
P(%) R(%) F(%) Loss
↓2.8
↓7.8
↑1.5
↑1.9

NA
NA
59.1
69.3

NA
NA
48.4
51.7

55.1
54.8
53.3
59.2

Table 5: Experimental results of domain adaptation on the TAC-KBP 2015 corpus (NA: not released)

More importantly, the adaptability of SELF is
relatively close to that of MSEP-EMD. Consider-
ing that MSEP-EMD is stable due to using mini-
mal supervision (Peng et al., 2016), we suggest the
fully trained networks in SELF may not appear to
be extremely inﬂexible, but on the contrary, they
should be transferable for use (Ge et al., 2016).

Robustness in Resource-Poor Settings

There are two resource-poor conditions discussed
in this section, including lack of in-domain train-
ing data and that of out-domain. Hybrid and SELF
are brought into the discussion.

For the former (in-domain) case, we went over
the numbers of samples used for training in the
adaptation experiments, which are shown in Ta-
ble 6. It can be observed that there is a minimum
number of training samples (triggers plus tokens)
contained in the domain of NW. By contrast, the
domain of bn+nw contains the smallest number of
positive samples (triggers) though an overwhelm-
ing number of negative samples (general tokens).
Under such conditions, Hybrid performs better
in the domain of NW compared to bn+nw and DF
in the three in-domain adaptation experiments (see
the column labelled as “In-domain bn+nw” in Ta-
ble 4 as well as “In-domain NW” and “In-domain
DF” in Table 5). It illustrates that Hybrid unnec-
essarily relies on a tremendous number of training
samples to ensure the robustness. But SELF does.
It needs far more negative samples than Hybrid be-
cause of the following reasons:

• It relies on the use of spurious features to im-

plement self-regulation during training.

Domain

bn+nw
NW
DF

Training

Testing

trigger
1,721
2,098
4,106

token
74,179
31,014
10,9275

trigger
343
2,813
1,773

token
16,336
55,459
43,877

Table 6: Data distribution in the source domains

• For a positive sample, the concerned spurious
features (if have) most probably hide in some
negative samples.

• It’s impossible to be aware of such negative
samples. Therefore, taking into consideration
as many negative samples as possible may
help to increase the probability that the spu-
rious features will be discovered.

This is demonstrated by the fact that SELF ob-
tains better performance in the domain of bn+nw
but not NW (see the column labeled as “Training”
in Table 6 and “In-domain” in Table 4 and 5). It
may be added that SELF performs worse in DF al-
though there are more negative samples used for
training (see Table 6). Taking a glance at the num-
ber of positive samples, one may ﬁnd that it is ap-
proximately 2.4 times more than that in bn+nw.
But the number of negative samples in DF is only
1.5 times more than that in bn+nw. It implies that,
if there are more positive samples used for train-
ing, SELF needs to consume proportionally more
negative samples for self-regulation. Otherwise,
the performance will degrade.

For the out-domain case, ideally, both Hybrid
and SELF encounter the problem that there is lack
of target domain data available for training. In this
case, SELF displays less performance degradation

Event mentions
And it still does
We had no part in it
Nobody questions if this is right or ...
And that is what ha- what is happening
Oh, yeah, it wasn’t perfect

Type
Die
Arrest-Jail
Attack
End-Position
Marry

Table 7: Examples of pronouns that act as a trigger

(7.2%) than Hybrid (14.8%) when NW is used for
training. Considering that NW contains the mini-
mum number of samples, we would like to believe
that SELF is more robust than Hybrid for cross-
domain event detection in a resource-poor setting.

Recall and Missing

SELF is able to accurately recall the events whose
occurrence is triggered by ambiguous words, such
as “ﬁne”, “charge”, “campaign”, etc. These am-
biguous words easily causes confusion. For exam-
ple, “campaign” may trigger an Elect event or
Attack in the ACE corpus.

More importantly, SELF ﬁshes out the common
words which serve as a trigger, although they are
not closely related to any kind of events, such as
“take”, “try”, “acquire”, “become”, “create”, etc.
In general, it is very difﬁcult to accurately recall
such triggers because their meanings are not con-
crete enough, and the contexts may be full of kinds
of noises (see example 2 in pg. 1). We observe that
Bi-RNN and Hybrid seldom pick them up.

However, SELF fails to recall the pronouns that
act as a trigger. This is because they occur in spo-
ken language much more frequently than they oc-
cur in written language. The lack of narrative con-
tent makes it difﬁcult to learn the relationship be-
tween the pronouns and the events. Some real ex-
amples collected from ACE are shown in Table 7.

6 Related Work

Event detection is an important subtask of event
extraction (Doddington et al., 2004; Ahn, 2006).

The research can be traced back to the pattern
based approach (Grishman et al., 2005). Encour-
aged by the high accuracy and the beneﬁt of easy-
to-use, researchers have made great efforts to ex-
tract discriminative patterns. Cao et al (2015a;
2015b) use dependency regularization and active
leaning to generalize and expand the patterns.

In the earlier study, another trend is to explore
the features that best characterize each event class,
so as to facilitate supervised classiﬁcation. A vari-

ety of strategies have emerged for converting clas-
siﬁcation clues into feature vectors (Ahn, 2006;
Patwardhan and Riloff, 2009; Liao and Grishman,
2010; Hong et al., 2011; Li et al., 2013, 2014; Wei
et al., 2017). Beneﬁting from the general model-
ing framework, the methods enable the fusion of
multiple features, and more importantly, they are
ﬂexible to use by feature selection. But consider-
able expertise is required for feature engineering.
Recently, the use of neural networks for event
detection has become a promising line of research.
The closely related work has been presented in
section 5.3. The primary advantages of neural net-
works have been demonstrated in the work, such
as performance enhancement, self-learning capa-
bility and robustness.

The generative adversarial network (Goodfel-
low et al., 2014) has emerged as an increasingly
popular approach for text processing (Zhang et al.,
2016; Lamb et al., 2016; Yu et al., 2017). Liu et
al (2017a) use the adversarial multi-task learning
for text classiﬁcation. We follow the work to cre-
ate spurious features, but use them to regulate the
self-learning process in a single-task situation.

7 Conclusion

We use a self-regulated learning approach to im-
prove event detection. In the learning process, the
adversarial and cooperative models are utilized in
decontaminating the latent feature space.

In this study, the performance of the discrimi-
nator in the adversarial network is left to be evalu-
ated. Most probably, the discriminator also per-
forms well because it is gradually enhanced by
ﬁerce competition. Considering this possibility,
we suggest to drive the two discriminators in our
self-regulation framework to cooperate with each
other. Besides, the global features extracted in Li
et al (2013)’s work are potentially useful for de-
tecting the event instances referred by pronouns,
although involve noises. Therefore, in the future,
we will encode the global information by neural
networks and use the self-regulation strategy to re-
duce the negative inﬂuence of noises.

Acknowledgments

We thank Xiaocheng Feng and his colleagues who
shared the source code of Hybrid with us.

This work was supported by the national Natu-
ral Science Foundation of China (NSFC) via Grant
Nos. 61525205, 61751206, 61672368.

References

David Ahn. 2006. The stages of event extraction.
In Proceedings of
the Workshop on Annotating
and Reasoning about Time and Events, Associa-
tion for Computational Linguistics (ACL’06). As-
sociation for Computational Linguistics, pages 1–8.
http://www.aclweb.org/anthology/W06-0901.

John Blitzer, Ryan McDonald, and Fernando Pereira.
Domain adaptation with structural cor-
2006.
respondence learning.
the
2006 conference on Empirical Methods in Natu-
ral Language Processing (EMNLP’06). Associa-
tion for Computational Linguistics, pages 120–128.
http://www.aclweb.org/anthology/W06-1615.

In Proceedings of

Konstantinos Bousmalis, George Trigeorgis, Nathan
Silberman, Dilip Krishnan, and Dumitru Erhan.
2016. Domain separation networks. In Advances in
Neural Information Processing Systems. pages 343–
351.

Kai Cao, Xiang Li, Miao Fan, and Ralph Grish-
Improving event detection with
man. 2015a.
active learning.
the Inter-
national Conference Recent Advances in Natural
Language Processing (RANLP’15). pages 72–77.
http://www.aclweb.org/anthology/R15-1010.

In Proceedings of

Kai Cao, Xiang Li, and Ralph Grishman. 2015b.
Improving event detection with dependency reg-
ularization.
the Interna-
In Proceedings of
tional Conference Recent Advances in Natural
Language Processing (RANLP’15). pages 78–83.
http://www.aclweb.org/anthology/R15-1011.

Yubo Chen, Shulin Liu, Xiang Zhang, Kang Liu, and
Jun Zhao. 2017. Automatically labeled data gener-
ation for large scale event extraction.
In Proceed-
ings of the 55th Annual Meeting of the Association
for Computational Linguistics (ACL’17). volume 1,
https://doi.org/10.18653/v1/P17-
pages 409–419.
1038.

Yubo Chen, Liheng Xu, Kang Liu, Daojian Zeng, Jun
Zhao, et al. 2015. Event extraction via dynamic
In
multi-pooling convolutional neural networks.
Proceedings of the 53th Annual Meeting of the As-
sociation for Computational Linguistics (ACL’15).
pages 167–176.
https://doi.org/10.3115/v1/P15-
1017.

Junyoung Chung, Caglar Gulcehre, KyungHyun Cho,
and Yoshua Bengio. 2014. Empirical evaluation of
gated recurrent neural networks on sequence model-
ing. arXiv preprint arXiv:1412.3555 .

George R Doddington, Alexis Mitchell, Mark A Przy-
bocki, Lance A Ramshaw, Stephanie Strassel, and
Ralph M Weischedel. 2004. The automatic con-
tent extraction (ACE) program-tasks, data, and
evaluation.
In LREC. volume 2, pages 1–4.
http://www.aclweb.org/anthology/L04-1011.

Joe Ellis, Jeremy Getman, Dana Fore, Neil Kuster,
Zhiyi Song, Ann Bies, and Stephanie Strassel. 2015.
Overview of linguistic resources for the tac kbp 2015
evaluations: Methodologies and results. In Proceed-
ings of TAC KBP 2015 Workshop, National Institute
of Standards and Technology (TAC’15). pages 16–
17.

Xiaocheng Feng, Lifu Huang, Duyu Tang, Heng Ji,
Bing Qin, and Ting Liu. 2016.
A language-
independent neural network for event detec-
tion.
the 54th Annual
the Association for Computational
Meeting of
Linguistics (ACL’16). volume 2, pages 66–71.
https://doi.org/10.18653/v1/P16-2011.

In Proceedings of

Tao Ge, Lei Cui, Baobao Chang, Zhifang Sui, and
Ming Zhou. 2016. Event detection with burst infor-
mation networks. In Proceedings of COLING 2016,
the 26th International Conference on Computational
Linguistics: Technical Papers. pages 3276–3286.

Reza Ghaeini, Xiaoli Fern, Liang Huang,

and
Prasad Tadepalli. 2016.
Event nugget detec-
tion with forward-backward recurrent neural net-
In Proceedings of the 54th Annual Meet-
works.
the Association for Computational Lin-
ing of
guistics (ACL’16). volume 2, pages 369–373.
https://doi.org/10.18653/v1/P16-2060.

Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,
Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. 2014. Generative ad-
versarial nets.
In Advances in neural information
processing systems. pages 2672–2680.

Ralph Grishman, David Westbrook, and Adam Meyers.
2005. Nyu’s English ACE 2005 system description.
ACE’05 .

Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky,
Ilya Sutskever, and Ruslan R Salakhutdinov. 2012.
Improving neural networks by preventing co-
adaptation of feature detectors.
arXiv preprint
arXiv:1207.0580 .

Yu Hong, Di Lu, Dian Yu, Xiaoman Pan, Xiaobin
Wang, Yadong Chen, Lifu Huang, and Heng Ji.
2015. RPI BLENDER TAC-KBP2015 system de-
scription.
In Proceedings of Text Analysis Confer-
ence (TAC’15).

Ronan Collobert and Jason Weston. 2008. A uniﬁed
architecture for natural language processing: Deep
In Pro-
neural networks with multitask learning.
ceedings of the 25th international conference on
Machine learning (ICML’08). ACM, pages 160–
167.

Yu Hong, Xiaobin Wang, Yadong Chen, Jian Wang,
Tongtao Zhang, Jin Zheng, Dian Yu, Qi Li, Boliang
Zhang, Han Wang, et al. 2014. RPI BLENDER
TAC-KBP2014 knowledge base population sys-
tem.
In Proceedings of Text Analysis Conference
(TAC’14).

Yu Hong, Jianfeng Zhang, Bin Ma, Jianmin Yao,
Guodong Zhou, and Qiaoming Zhu. 2011. Using
cross-entity inference to improve event extraction.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies (ACL-HLT’11). Association
for Computational Linguistics, pages 1127–1136.
http://www.aclweb.org/anthology/P11-1113.

Xun Huang, Yixuan Li, Omid Poursaeed,

John
Hopcroft, and Serge Belongie. 2017. Stacked gener-
ative adversarial networks. In IEEE Conference on
Computer Vision and Pattern Recognition (CVPR).
volume 2, page 4.

Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidi-
rectional LSTM-CRF models for sequence tagging.
arXiv preprint arXiv:1508.01991 .

Md M Islam, Xin Yao, and Kazuyuki Murase. 2003. A
constructive algorithm for training cooperative neu-
ral network ensembles. IEEE Transactions on neu-
ral networks 14(4):820–834.

Rafal

Jozefowicz, Wojciech Zaremba,

and Ilya
Sutskever. 2015. An empirical exploration of recur-
rent network architectures.
In Proceedings of the
32nd International Conference on Machine Learn-
ing (ICML’15). pages 2342–2350.

Alex M Lamb, Anirudh Goyal ALIAS PARTH
GOYAL, Ying Zhang, Saizheng Zhang, Aaron C
Courville, and Yoshua Bengio. 2016.
Professor
forcing: A new algorithm for training recurrent net-
works. In Advances In Neural Information Process-
ing Systems. pages 4601–4609.

Qi Li, Heng Ji, and Liang Huang. 2013.

Joint
event extraction via structured prediction with
the 51th
global
the Association for Com-
Annual Meeting of
putational Linguistics
(ACL’13). pages 73–82.
http://www.aclweb.org/anthology/P13-1008.

In Proceedings of

features.

Qi Li, Heng Ji, HONG Yu, and Sujian Li. 2014.
Constructing information networks using one sin-
gle model.
the 2014 Con-
In Proceedings of
ference on Empirical Methods in Natural Lan-
guage Processing (EMNLP’14). pages 1846–1851.
https://doi.org/10.3115/v1/D14-1198.

Shasha Liao and Ralph Grishman. 2010.

Us-
ing document level cross-event inference to im-
prove event extraction.
the
the Association for
48th Annual Meeting of
Computational Linguistics (ACL’10). Association
for Computational Linguistics, pages 789–797.
http://www.aclweb.org/anthology/P10-1081.

In Proceedings of

Zhouhan Lin, Minwei Feng, Cicero Nogueira dos San-
tos, Mo Yu, Bing Xiang, Bowen Zhou, and Yoshua
Bengio. 2017. A structured self-attentive sentence
embedding. arXiv preprint arXiv:1703.03130 .

Ming-Yu Liu and Oncel Tuzel. 2016. Coupled gener-
In Advances in neural

ative adversarial networks.
information processing systems. pages 469–477.

Pengfei Liu, Xipeng Qiu, Jifan Chen, and Xuanjing
Huang. 2016a. Deep fusion LSTMs for text se-
mantic matching.
In Proceedings of the 54th An-
nual Meeting of the Association for Computational
Linguistics (ACL’16). volume 1, pages 1034–1043.
https://doi.org/10.18653/v1/P16-1098.

Pengfei Liu, Xipeng Qiu, and Xuanjing Huang.
2017a. Adversarial multi-task learning for text
classiﬁcation.
arXiv preprint arXiv:1704.05742
https://doi.org/10.18653/v1/P17-1001.

Shulin Liu, Yubo Chen, Shizhu He, Kang Liu, and
Jun Zhao. 2016b.
to im-
prove automatic event detection.
In Proceed-
the Asso-
the 54th Annual Meeting of
ings of
ciation for Computational Linguistics (ACL’16).
https://doi.org/10.18653/v1/P16-1201.

Leveraging framenet

Shulin Liu, Yubo Chen, Kang Liu, and Jun Zhao.
2017b. Exploiting argument information to improve
event detection via supervised attention mechanisms
1:1789–1797.
https://doi.org/10.18653/v1/P17-
1164.

Linguistic regularities

Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013.
in continuous
space word representations.
In Proceedings
of
the 2013 Conference of
the North Ameri-
the Association for Computa-
can Chapter of
tional Linguistics: Human Language Technolo-
gies (NAACL’13). volume 13, pages 746–751.
http://www.aclweb.org/anthology/N13-1090.

Thien Huu Nguyen, Kyunghyun Cho, and Ralph Gr-
ishman. 2016. Joint event extraction via recurrent
neural networks. In Proceedings of the 2016 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies (NAACL’16). pages 300–309.
https://doi.org/10.18653/v1/N16-1034.

Thien Huu Nguyen and Ralph Grishman. 2014. Em-
ploying word representations and regularization for
domain adaptation of relation extraction.
In Pro-
ceedings of the 52th Annual Meeting of the Associa-
tion for Computational Linguistics (ACL’14). pages
68–74. https://doi.org/10.3115/v1/P14-2012.

Thien Huu Nguyen and Ralph Grishman. 2015. Event
detection and domain adaptation with convolu-
tional neural networks.
the
53th Annual Meeting of the Association for Com-
putational Linguistics (ACL’15). pages 365–371.
https://doi.org/10.3115/v1/P15-2060.

In Proceedings of

Thien Huu Nguyen and Ralph Grishman. 2016. Mod-
eling skip-grams for event detection with convo-
lutional neural networks.
In Proceedings of the
2016 Conference on Empirical Methods in Natural
Language Processing (EMNLP’16). pages 886–891.
https://doi.org/10.18653/v1/D16-1085.

Siddharth Patwardhan and Ellen Riloff. 2009. A
uniﬁed model of phrasal and sentential evidence

for information extraction.
In Proceedings of the
2009 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP’09). Associa-
tion for Computational Linguistics, pages 151–160.
http://www.aclweb.org/anthology/D09-1016.

Lantao Yu, Weinan Zhang, Jun Wang, and Yong Yu.
Seqgan: Sequence generative adversarial
2017.
nets with policy gradient.
In Proceedings of the
32nd AAAI Conference on Artiﬁcial Intelligence
(AAAI’17). pages 2852–2858.

Haoruo Peng, Yangqiu Song, and Dan Roth. 2016.
Event detection and co-reference with minimal
supervision.
the 2016 Con-
In Proceedings of
ference on Empirical Methods in Natural Lan-
guage Processing (EMNLP’16). pages 392–402.
https://doi.org/10.18653/v1/D16-1038.

Matthew D Zeiler. 2012. Adadelta: an adaptive learn-
ing rate method. arXiv preprint arXiv:1212.5701 .

Yizhe Zhang, Zhe Gan, and Lawrence Carin. 2016.
In NIPS

Generating text via adversarial training.
workshop on Adversarial Training. volume 21.

Barbara Plank and Alessandro Moschitti. 2013. Em-
bedding semantic similarity in tree kernels for do-
main adaptation of relation extraction. In Proceed-
ings of the 51th Annual Meeting of the Associa-
tion for Computational Linguistics (ACL’13). pages
1498–1507. http://www.aclweb.org/anthology/P13-
1147.

Mark Sammons, Haoruo Peng, Yangqiu Song, Shyam
Upadhyay, Chen-Tse Tsai, Pavankumar Reddy,
Subhro Roy, and Dan Roth. 2015. Illinois CCG TAC
2015 event nugget, entity discovery and linking, and
slot ﬁller validation systems. In Proceedings of Text
Analytics Conference (TAC’15).

Mike Schuster and Kuldip K Paliwal. 1997. Bidirec-
tional recurrent neural networks. IEEE Transactions
on Signal Processing 45(11):2673–2681.

Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.
Sequence to sequence learning with neural net-
works. In Advances in neural information process-
ing systems. pages 3104–3112.

Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.
Word representations: a simple and general method
for semi-supervised learning.
In Proceedings of
the 48th Annual Meeting of the Association for
Computational Linguistics
(ACL’10). Associa-
tion for Computational Linguistics, pages 384–394.
https://doi.org/http://www.aclweb.org/anthology/P10-
1040.

Mengqiu Wang and Christopher D Manning. 2013.
Effect of non-linear deep architecture in se-
quence labeling.
the Sixth
International Joint Conference on Natural Lan-
guage Processing (IJCNLP’13). pages 1285–1291.
https://doi.org/http://www.aclweb.org/anthology/I13-
1183.

In Proceedings of

Sam Wei,

Igor Korostil, Joel Nothman, and Ben
Hachey. 2017. English event detection with trans-
lated language features. In Proceedings of the 55th
Annual Meeting of the Association for Computa-
tional Linguistics (ACL’17). volume 2, pages 293–
298. https://doi.org/10.18653/v1/P17-2046.

Dian Yu, Xiaoman Pan, Boliang Zhang, Lifu Huang,
Di Lu, Spencer Whitehead, and Heng Ji. 2016. RPI
BLENDER TAC-KBP2016 system description.
In
Proceedings of Text Analysis Conference (TAC’16).

Self-regulation: Employing a Generative Adversarial Network to Improve
Event Detection

Yu Hong Wenxuan Zhou Jingli Zhang Qiaoming Zhu Guodong Zhou∗
Institute of Artiﬁcial Intelligence, Soochow University
School of Computer Science and Technology, Soochow University
No.1, Shizi ST, Suzhou, China, 215006
{tianxianer, wxchow024, jlzhang05}@gmail.com
{qmzhu, gdzhou}@suda.edu.cn

Abstract

Due to the ability of encoding and map-
ping semantic information into a high-
dimensional latent feature space, neural
networks have been successfully used for
detecting events to a certain extent. How-
ever, such a feature space can be easily
contaminated by spurious features inher-
ent in event detection.
In this paper, we
propose a self-regulated learning approach
by utilizing a generative adversarial net-
work to generate spurious features. On the
basis, we employ a recurrent network to
eliminate the fakes. Detailed experiments
on the ACE 2005 and TAC-KBP 2015 cor-
pora show that our proposed method is
highly effective and adaptable.

1

Introduction

Event detection aims to locate the event triggers
of speciﬁed types in text. Normally, triggers are
words or nuggets that evoke the events of interest.
Detecting events in an automatic way is chal-
lenging, not only because an event can be ex-
pressed in different words, but also because a word
may express a variety of events in different con-
texts. In particular, the frequent utilization of com-
mon words, ambiguous words and pronouns in
event mentions makes them harder to detect:

1) Generality – taken home <Transport>

Ambiguity 1 – campaign in Iraq <Attack>
Ambiguity 2 – political campaign <Elect>
Coreference – Either its bad or good <Marry>

A promising solution to this challenge is
through semantic understanding. Recently, neu-
ral networks have been widely used in this direc-
tion (Nguyen and Grishman, 2016; Ghaeini et al.,

∗ Corresponding author

2016; Feng et al., 2016; Liu et al., 2017b; Chen
et al., 2017), which allows semantics of event
mentions (trigger plus context) to be encoded in
a high-dimensional latent feature space. This fa-
cilitates the learning of deep-level semantics. Be-
sides, the use of neural networks not only strength-
ens current supervised classiﬁcation of events but
alleviates the complexity of feature engineering.

However, compared to the earlier study (Liao
and Grishman, 2010; Hong et al., 2011; Li et al.,
2013), in which the features are carefully designed
by experts, the neural network based methods suf-
fer more from spurious features. Here, spurious
feature is speciﬁed as the latent information which
looks like the semantically related information to
an event, but actually not (Liu et al., 2017a). For
example, in the following sample, the semantic
information of the word “prison” most probably
enables spurious features to come into being, be-
cause the word often co-occurs with the trigger
”taken” to evoke an Arrest-jail event instead
of the ground-truth event Transport:

2) Prison authorities have given the nod for An-
war to be taken home later in the afternoon.
Trigger: taken. Event Type: Transport

It is certain that spurious features often result
from the semantically pseudo-related context, and
during training, a neural network may mistakenly
and unconsciously preserve the memory to pro-
duce the fakes. However, it is difﬁcult to deter-
mine which words are pseudo-related in a speciﬁc
case, and when they will “jump out” to mislead the
generation of latent features during testing.

To address the challenge, we suggest to regu-
late the learning process with a two-channel self-
regulated learning strategy. In the self-regulation
process, on one hand, a generative adversarial net-
work is trained to produce the most spurious fea-
tures, while on the other hand, a neural network

(cid:28595)

(cid:28661)(cid:28660)(cid:28662)(cid:28670)(cid:28595)(cid:28675)(cid:28677)(cid:28674)(cid:28675)(cid:28660)(cid:28666)(cid:28660)(cid:28679)(cid:28668)(cid:28674)(cid:28673)(cid:28595)

(cid:22) 

(cid:7) 

(cid:28643)(cid:28677)(cid:28664)(cid:28663)(cid:28668)(cid:28662)(cid:28679)(cid:28668)(cid:28674)(cid:28673)(cid:28595)

(cid:1876) 

(cid:10) 

(cid:10)(cid:3545) 

(cid:7)(cid:3545) 

(cid:28661)(cid:28660)(cid:28662)(cid:28670)(cid:28595)(cid:28675)(cid:28677)(cid:28674)(cid:28675)(cid:28660)(cid:28666)(cid:28660)(cid:28679)(cid:28668)(cid:28674)(cid:28673)(cid:28595)

Figure 1: Self-regulated learning scheme

is equipped with a memory suppressor to elimi-
nate the fakes. Detailed experiments on event de-
tection show that our proposed method achieves
a substantial performance gain, and is capable of
robust domain adaptation.

2 Task Deﬁnition

The task of event detection is to determine whether
there is one or more event triggers in a sentence.
Trigger is deﬁned as a token or nugget that best
signals the occurrence of an event. If successfully
identiﬁed, a trigger is required to be assigned a tag
to indicate the event type:

Input: Either its bad or good
Output: its <trigger>; Marry <type>
We formalize the event detection problem as a
multi-class classiﬁcation problem. Given a sen-
tence, we classify every token of the sentence into
one of the predeﬁned event classes (Doddington
et al., 2004) or non-trigger class.

3 Self-Regulated Learning (SELF)

SELF is a double-channel model (Figure 1), con-
sisted of a cooperative network (Islam et al., 2003)
and a generative adversarial net (GAN) (Goodfel-
low et al., 2014). A memory suppressor S is used
to regulate communication between the channels.

3.1 Cooperative Network

In channel 1, the generator G is speciﬁed as a mul-
tilayer perceptron. It plays a role of a “diligent stu-
dent”. By a differentiable function G(x, θg) with
parameters θg, the generator learns to produce a
vector of latent features og that may best charac-
terize the token x, i.e., og = G(x, θg).

The discriminator D (called “a lucky profes-
sor”) is a single-layer perceptron, implemented as
a differentiable function D(og, θd) with parame-
ters θd. Relying on the feature vector og, it at-
tempts to accurately predict the probability of the
token x triggering an event for all event classes,
i.e., ˆy = D(og, θd), and assigns x to the most
probable class c (iff ˆyc > ∀ˆy¯c, ¯c (cid:3)= c).

Therefore, G and D cooperate with each other
during training, developing the parameters θg and
θd with the same goal – to minimize the perfor-
mance loss L(ˆy, y) in the detection task:

(cid:2)

(cid:3)

θg
θd

= argmin L(ˆy, y)

(1)

where, y denotes the ground-truth probability dis-
tribution over event classes, and L indicates the
deviation of the prediction from the ground truth.

3.2 Generative Adversarial Network
In channel 2, the generator ˇG and discriminator
ˇD have the same perceptual structures as G and
D. They also perform learning by differentiable
functions, respectively ˇG(x, θˇg) and ˇD(oˇg, θ ˇd
). A
major difference, however, is that they are caught
into a cycle of highly adversarial competition.

The generator ˇG is a “trouble maker”. It learns
to produce spurious features, and utilizes them to
contaminate the feature vector oˇg of the token x.
Thus ˇG changes a real sample x into a fake z –
sometimes successfully, sometimes less so. Using
the fakes, ˇG repeatedly instigates the discrimina-
tor ˇD to make mistakes. On the other side, ˇD (“a
hapless professor”) has to avoid being deceived,
and struggles to correctly detect events no matter
whether it encounters x or z.

In order to outsmart the adversary, ˇG develops
the parameters θˇg during training to maximize the
performance loss, but on the contrary, ˇD develops
the parameters θ ˇd to minimize the loss:

θˇg = argmax L(ˆy, y)
= argmin L(ˆy, y)
θ ˇd

(2)

(3)

Numerous studies have conﬁrmed that the two-
player minmax game enables both ˇG and ˇD to im-
prove their methods (Goodfellow et al., 2014; Liu
and Tuzel, 2016; Huang et al., 2017).

3.3 Regulation with Memory Suppressor

Using a memory suppressor, we try to optimize the
diligent student G. The goal is to enable G to be
as dissimilar as possible to the troublemaker ˇG.

The suppressor uses the output oˇg of ˇG as a ref-
erence resource which should be full of spurious
features. On the basis, it looks over the output og
of G, so as to verify whether the features in og
are different to those in oˇg. If very different, the
suppressor allows G to preserve the memory (viz.,
θg in G(x, θg)), otherwise update. In other word,

for G, the suppressor forcibly erases the memory
which may result in the generation of spurious fea-
tures. We call this the self-regulation.

Self-regulation is performed for the whole sen-
tence which is fed into G and ˇG. Assume that Og
is a matrix, constituted with a series of feature vec-
tors, i.e., the vectors generated by G for all the to-
kens in an input sentence (og ∈ Og), while Oˇg
is another feature matrix, generated by ˇG for the
tokens (oˇg ∈ Oˇg). Thus, we utilize the matrix ap-
proximation between Og and Oˇg for measuring the
loss of self-regulation learning Ldif f . The higher
the similarity, the greater the loss. During training,
the generator G is required to develop the param-
eters θg to minimize the loss:

θg = argmin Ldif f (og, oˇg)

(4)

We present in detail the matrix approximate cal-
culation in section 4.4, where the squared Frobe-
nius norm (Bousmalis et al., 2016) is used.

3.4 Learning to Predict

We incorporate the cooperative network with the
GAN, and enhance their learning by joint training.
In the 4-member incorporation, i.e., {G, ˇG, D
and ˇD}, the primary beneﬁciary is the lucky pro-
fessor D. It can beneﬁt from both the cooperation
in channel 1 and the competition in channel 2. The
latent features it uses are well-produced by G, and
decontaminated by eliminating possible fakes like
those made by ˇG. Therefore, in experiments, we
choose to output the prediction results of D.

In this paper, we use two recurrent neural net-
works (RNN) (Sutskever et al., 2014; Chung et al.,
2014) of the same structure as the generators. And
both the discriminators are implemented as a fully-
connected layer followed by a softmax layer.

4 Recurrent Models for SELF

RNN with long short-term memory (abbr., LSTM)
is adopted due to the superior performance in a va-
riety of NLP tasks (Liu et al., 2016a; Lin et al.,
2017; Liu et al., 2017a). Furthermore, the bidi-
rectional LSTM (Bi-LSTM) architecture (Schus-
ter and Paliwal, 1997; Ghaeini et al., 2016; Feng
et al., 2016) is strictly followed. This architecture
enables modeling of the semantics of a token with
both the preceding and following contexts.

4.1 LSTM based Generator

Given a sentence, we follow Chen et al (2015) to
take all the tokens of the whole sentence as the in-

put. Before feeding the tokens into the network,
we transform each of them into a real-valued vec-
tor x ∈ Re. The vector is formed by concatenating
a word embedding with an entity type embedding.

• Word Embedding: It is a ﬁxed-dimensional
real-valued vector which represents the hid-
den semantic properties of a token (Collobert
and Weston, 2008; Turian et al., 2010).

• Entity Type Embedding: It is specially used
to characterize the entity type associated with
a token. The BIO2 tagging scheme (Wang
and Manning, 2013; Huang et al., 2015) is
employed for assigning a type label to each
token in the sentence.

For the input token xt at the current time step t,
the LSTM generates the latent feature vector ot ∈
Rd by the previous memory. Meanwhile, the token
is used to update the current memory.

The LSTM possesses a long-term memory unit
ct ∈ Rd and short-term (cid:4)ct ∈ Rd. In addition, it
is equipped with the input gate it, forgetting gate
ft and a hidden state ht, which are assembled to-
gether to promote the use of memory, as well as
dynamic memory updating. Similarly, they are de-
ﬁned as a d-dimensional vector in Rd. Thus LSTM
works in the following way:

⎡

⎢
⎢
⎣

ot
(cid:4)ct
it
ft

⎤

⎥
⎥
⎦ =

⎡

⎢
⎢
⎣

⎤

⎥
⎥
⎦

σ
tanh
σ
σ

(cid:11)

(cid:2)

(cid:3)

(cid:12)

W

xt
ht−1

+ b

ht = ot (cid:5) tanh(ct)
ct = (cid:4)ct (cid:5) it + ct−1 (cid:5) ft

(5)

(6)

(7)

where W ∈ R4d×(d+e) and b ∈ R4d are parame-
ters of afﬁne transformation; σ refers to the logis-
tic sigmoid function and (cid:5) denotes element-wise
multiplication.

The output functions of both the generators in
SELF, i.e., G and ˇG, can be boiled down to the
output gate ot ∈ Rd of the LSTM cell:

ot = LST M (xt; θ)

(8)

where, the function LSTM (·;·) is a shorthand for
Eq. (5-7) and θ represents all the parameters of
LSTM. For both G and ˇG, θ are initialized with the
same values in experiments. But due to the distinct
training goals of G and ˇG (diligence or making-
trouble), the values of the parameters in the two

cases will change to be very different after train-
ing. Therefore, we have og,t = LST M (xt, θg,t)
and oˇg,t = LST M (xt, θˇg,t).

4.2 Fully-connected Layer for Discrimination

Depending on the feature vectors og,t and oˇg,t, the
two discriminators D and ˇD predict the probabil-
ity of the token xt triggering an event for all event
classes. As usual, they compute the probability
distribution over classes using a fully connected
layer followed by a softmax layer:

ˆy = sof tmax( ˆW · ot + ˆb)

(9)

where ˇy is a C-dimensional vector, in which each
dimension indicates the prediction for a class; C
is the class number; ˆW ∈ Rd is the weight which
needs to be learned; ˆb is a bias term.

It is noteworthy that the discriminator D and ˇD
don’t share the weight and the bias. It means that,
for the same token xt, they may make markedly
different predictions: ˆyg,t = sof tmax( ˆWg · og,t +
ˆbg) and ˆyˇg,t = sof tmax( ˆWˇg · oˇg,t + ˆbˇg).

4.3 Classiﬁcation Loss

We specify the loss as the cross-entropy between
the predicted and ground-truth probability distri-
butions over classes. Given a batch of training data
that includes N samples (xi, yi), we calculate the
losses the discriminators cause as below:

where, (cid:6) · (cid:6)2
F denotes the squared Frobenius norm
(Bousmalis et al., 2016), which is used to calculate
the similarity between matrices.

It is noteworthy that the feature vectors a gen-
erator outputs are required to serve as the rows in
the matrix, deployed in a top-down manner and
arranged in the order in which they are generated.
For example, the feature vector og,t the generator
G outputs at the time t needs to be placed in the
t-th row of the matrix Og.

At the very beginning of the measurement, the
similarity between every feature vector in Og and
that in O ˇG is ﬁrst calculated by the matrix-matrix
multiplication OgO(cid:3)
ˇg :

⎛

⎜
⎜
⎜
⎜
⎝

og,1o(cid:3)
ˇg,1
...
og,1o(cid:3)
ˇg,t
...
og,1o(cid:3)
ˇg,l

... og,1o(cid:3)
ˇg,t
...
...
... og,to(cid:3)
ˇg,t
...
...
og,lo(cid:3)
...
ˇg,t

...

... og,1o(cid:3)
ˇg,l
...
... og,to(cid:3)
ˇg,l
...
...

...
og,lo(cid:3)
ˇg,l

⎞

⎟
⎟
⎟
⎟
⎠

where, the symbol (cid:7) denotes the transpose opera-
tion; l is the sentence length which is deﬁned to be
uniform for all sentences (l=80), and if it is larger
than the real ones, padding is used; og,ioˇg,j de-
notes the scalar product between the feature vec-
tors og,i and oˇg,j.

Let Am×n be a matrix, the squared Frobenius

norm of Am×n (i.e., (cid:6)Am×n(cid:6)2

F ) is deﬁned as:

⎛

m(cid:13)

n(cid:13)

⎞

1
2

i=1

j=1

N(cid:13)

C(cid:13)

i=1
N(cid:13)

j=1
C(cid:13)

i=1

j=1

L(ˆyg, y) = −

i log(ˆyj
yj

g,i

)

(10)

(cid:6)Am×n(cid:6)2

F

⎝

=

|aij|2

⎠

(13)

L(ˆyˇg, y) = −

i log(ˆyj
yj
ˇg,i

)

(11)

where yi is a C-dimensional one-hot vector. The
value of its j-th dimension is set to be 1 only if the
token xi triggers an event of the j-th class, other-
wise 0. Both ˆyg,i and ˆyˇg,i are the predicted proba-
bility distributions over the C classes for xi.

4.4 Loss of Self-regulated Learning

Assume that Og is a matrix, consisted of the fea-
ture vectors output by G for all the tokens in a sen-
tence, i.e., og,t ∈ Og, and Oˇg is that provided by
ˇG, i.e., oˇg,t ∈ Oˇg, thus we compute the similarity
between Og and Oˇg and use it as the measure of
self-regulation loss Ldif f (Og, Oˇg):

where, aij denotes the j-th element in the i-th
row of Am×n. Thus, if we let Am×n be the ma-
trix produced by the matrix-matrix multiplication
OgO(cid:3)
ˇg , the self-regulation loss Ldif f (Og, Oˇg) can
be eventually obtained by:

Ldif f (Og, Oˇg) =

|og,ioˇg,j|2

(14)

⎛

⎝

l(cid:13)

l(cid:13)

i=1

j=1

1
2

⎞

⎠

For a batch of training data that includes N (cid:4)
sentences, the global self-regulation loss is spec-
iﬁed as the sum of the losses for all the sentences:
LSELF =

N (cid:3)
i=1 Ldif f (Og, Oˇg).

(cid:20)

4.5 Training

Ldif f (Og, Oˇg) = (cid:6)OgO(cid:3)
ˇg

(cid:6)2

F

(12)

We train the cooperative network in SELF to min-
imize the classiﬁcation loss L(ˆyg, y) and the loss

of self-regulated learning LSELF :

θg = argmin (Lˆyg, y)
θd = argmin (L(ˆyg, y) + λ · LSELF )

(15)

(16)

where λ is a hyper-parameter, which is used to har-
monize the two losses.

The min-max game is utilized for training the
adversarial net in SELF: θˇg = argmax L(ˆyˇg, y);
θ ˇd

= argmin L(ˆyˇg, y).
All the networks in SELF are trained jointly us-
ing the same batches of samples. They are trained
via stochastic gradient descent (Nguyen and Gr-
ishman, 2015) with shufﬂed mini-batches and the
AdaDelta update rule (Zeiler, 2012). The gradi-
ents are computed using back propagation. And
regularization is implemented by a dropout (Hin-
ton et al., 2012).

5 Experimentation

5.1 Resource and Experimental Datasets

We test the presented model on the ACE 2005 cor-
pus. The corpus is annotated with single-token
event triggers and has 33 predeﬁned event types
(Doddington et al., 2004; Ahn, 2006), along with
one class “None” for the non-trigger tokens, con-
stitutes a 34-class classiﬁcation problem.

For comparison purpose, we use the corpus in
the traditional way, randomly selecting 30 articles
in English from different genres as the develop-
ment set, and utilizing a separate set of 40 English
newswire articles as the test set. The remaining
529 English articles are used as the training set.

5.2 Hyperparameter Settings

The word embeddings are initialized with the 300-
dimensional real-valued vectors. We follow Chen
et al (2015) and Feng et al (2016) to pre-train the
embeddings over NYT corpus using Mikolov et al
(2013)’s skip-gram tool. The entity type embed-
dings, as usual (Nguyen et al., 2016; Feng et al.,
2016; Liu et al., 2017b), are speciﬁed as the 50-
dimensional real-valued vectors. They are initial-
ized with the 32-bit ﬂoating-point values, which
are all randomly sampled from the uniformly dis-
tributed values in [-1, 1]1. We initialize other ad-
justable parameters of the back-propagation algo-
rithm by randomly sampling in [-0.1, 0.1].

We follow Feng et al (2016) to set the dropout
rate as 0.2 and the mini-batch size as 10. We
1https://www.tensorﬂow.org/api docs/python/tf/random

uniform

tune the initialized parameters mentioned above,
harmonic coefﬁcient λ, learning rate and the L2
norm on the development set. Grid search (Liu
et al., 2017a) is used to seek for the optimal pa-
rameters. Eventually, we take the coefﬁcient λ of
0.1+3, learning rate of 0.3 and L2 norm of 0.

The source code of SELF2 to reproduce the ex-

periments has been made publicly available.

5.3 Compared Systems

The state-of-the-art models proposed in the past
decade are compared with ours. By taking learn-
ing framework as the criterion, we divide the mod-
els into three classes:

Minimally supervised approach: is Peng et al

(2016)’s MSEP-EMD.

Feature based approaches: primarily includ-
ing Liao and Grishman (2010)’s Cross-Event in-
ference model, which is based on the max-entropy
classiﬁcation and embeds the document-level con-
ﬁdent information in the feature space; Hong et al
(2011)’s Cross-Entity inference model, in which
existential backgrounds of name entities are em-
ployed as the additional discriminant features; and
Li et al (2013)’s Joint model, a sophisticated pre-
dictor frequently ranked among the top 3 in re-
cent TAC-KBP evaluations for nugget and corefer-
ence detection (Hong et al., 2014, 2015; Yu et al.,
2016).
It is based on structured perceptron and
combines the local and global features.

Neural network based approaches: including
the convolutional neural network (CNN) (Nguyen
and Grishman, 2015),
the non-consecutive N-
grams based CNN (NC-CNN) (Nguyen and Gr-
ishman, 2016) and the CNN that is assembled with
a dynamic multi-pooling layer (DM-CNN) (Chen
et al., 2015). Others include Ghaeini et al (2016)’s
forward-backward recurrent neural network (FB-
RNN) which is developed using gated recurrent
units (GRU), Nguyen et al (2016)’s bidirectional
RNN (Bi-RNN) and Feng et al (2016)’s Hybrid
networks that consist of a Bi-LSTM and a CNN.

Besides, we compare our model with Liu et al
(2016b)’s artiﬁcial neural networks (ANNs), Liu
et al (2017b)’s attention-based ANN (ANN-S2)
and Chen et al (2017)’s DM-CNN∗. The models
recently have become popular because, although
simple in structure, they are very analytic by learn-
ing from richer event examples, such as those in

2https://github.com/JoeZhouWenxuan/Self-regulation-
Employing-a-Generative-Adversarial-Network-to-Improve-
Event-Detection/tree/master

P (%) R (%)
Method
76.9
Joint (Local+Global)
75.6
MSEP-EMD
80.4
DM-CNN
DM-CNN∗
79.7
Bi-RNN
68.5
Hybrid: Bi-LSTM+CNN 80.8
SELF: Bi-LSTM+GAN 75.3

65.0
69.8
67.7
69.6
75.7
71.5
78.8

F (%)
70.4
72.6
73.5
74.3
71.9
75.9
77.0

Table 1: Trigger identiﬁcation performance

FrameNet (FN) and Wikipeida (Wiki).

5.4 Experimental Results

We evaluate our model using Precision (P), Re-
call (R) and F-score (F). To facilitate the compar-
ison, we review the best performance of the com-
petitors, which has been evaluated using the same
metrics, and publicly reported earlier.

Trigger identiﬁcation

Table 1 shows the trigger identiﬁcation perfor-
mance. It can be observed that SELF outperforms
other models, with a performance gain of no less
than 1.1% F-score.

Frankly, the performance mainly beneﬁts from
the higher recall (78.8%). But in fact the relatively
comparable precision (75.3%) to the recall rein-
forces the advantages. By contrast, although most
of the compared models achieve much higher pre-
cision over SELF, they suffer greatly from the sub-
stantial gaps between precision and recall. The ad-
vantage is offset by the greater loss of recall.

GAN plays an important role in optimizing Bi-
RNN. This is proven by the fact that SELF (Bi-
LSTM+GAN) outperforms Nguyen et al (2016)’s
Bi-RNN. To be honest, the models use two differ-
ent kinds of recurrent units. Bi-RNN uses GRUs,
but SELF uses the units that possess LSTM. Nev-
ertheless, GRU has been experimentally proven to
be comparable in performance to LSTM (Chung
et al., 2014; Jozefowicz et al., 2015). This allows
a fair comparison between Bi-RNN and SELF.

Event classiﬁcation

Table 2 shows the performance of multi-class clas-
siﬁcation. SELF achieves nearly the same F-score
as Feng et al (2016)’s Hybrid, and outperforms the
others. More importantly, SELF is the only one
which obtains a performance higher than 70% for
both precision and recall.

Besides, by analyzing the experimental results,

we have identiﬁed the following regularities:

P (%) R (%)
Methods
70.4
MSEP-EMD
68.8
Cross-Event
72.9
Cross-Entity
73.7
Joint (Local+Global)
71.8
CNN
75.6
DM-CNN
-
NC-CNN
66.8
FB-RNN (GRU)
66.0
Bi-RNN (GRU)
77.6
ANNs (ACE+FN)
DM-CNN∗(ACE+Wiki)
75.7
ANN-S2 (ACE+FN)
76.8
Hybrid: Bi-LSTM+CNN 84.6
71.3
SELF: Bi-LSTM+GAN

65.0
68.9
64.3
62.3
66.4
63.6
-
68.0
73.0
65.2
66.0
67.5
64.9
74.7

F (%)
67.6
68.8
68.3
67.5
69.0
69.1
71.3
67.4
69.3
70.7
70.5
71.9
73.4
73.0

Table 2: Detection performance (trigger identiﬁ-
cation plus multi-class classiﬁcation)

• Similar to the pattern classiﬁers that are based
on hand-designed features, the CNN models
enable higher precision to be obtained. How-
ever the recall is lower.

• The RNN models contribute to achieving a
higher recall. However the precision is lower.

• Expansion of the training data set helps to in-

crease the precision.

Let us turn to the structurally more complicated

models, SELF and Hybrid.

SELF inherits the merits of the RNN models,
classifying the events with higher recall. Besides,
by the utilization of GAN, SELF has evolved from
the traditional learning strategies, being capable of
learning from GAN and getting rid of the mistak-
enly generated spurious features. So that it outper-
forms other RNNs, with improvements of no less
than 4.5% precision and 1.7% recall.

Hybrid is elaborately established by assembling
a RNN with a CNN. It models an event from two
perspectives: language generation and pragmatics.
The former is deeply learned by using the contin-
uous states hidden in the recurrent units, while the
later the convolutional features. Multi-angled cog-
nition enables Hybrid to be more precise. How-
ever it is built using a single-channel architecture,
concatenating the RNN and the CNN. This results
in twofold accumulation of feature information,
causing a serious overﬁtting problem. Therefore,
Hybrid is localized to much higher precision but
substantially lower recall.

Overﬁtting results in enlargement of the gap be-
tween precision and recall when the task changes
to be more difﬁcult. For Hybrid, as illustrated in

MSEP-EMD                      Joint                              DM-CNN                      DM-CNN*                                   Hybrid                          Bi-RNN                            SELF 

P

R

P

R

P

R

P

R

gap=12.7% 

gap=10.1% 

85

80

75

70

65

60

gap=5.8%

%
4
.
5
=
p
a
g

 

%
9
.
1
1
=
p
a
g

 

%
4
.
1
1
=
p
a
g

85

80

75

70

65

60

85

80

75

70

65

60

 

%
2
1
=
p
a
g

(Bi-LSTM+CNN) 
R

P

(GRU) 
R

P

(Bi-LSTM+GAN) 
R

P

 

85

80

75

70

65

60

 

%
7
.
9
=
p
a
g

 

%
3
.
9
=
p
a
g

 

%
7
.
9
1
=
p
a
g

 

%
7
=
p
a
g

 

%
7
=
p
a
g

85

80

75

70

65

60

 

%
5
.
3
=
p
a
g

%
4
.
3
=
p
a
g

85

80

75

70

65

60

Trigger 

Trigger+
Type 

Trigger 

Trigger+
Type 

Trigger 

Trigger+
Type 

Trigger 

Trigger+
Type 

Trigger 

Trigger+
Type 

Trigger 

Trigger+
Type 

Trigger 

 

Trigger+
Type 

Min-supervision 

Feature engineering 

CNN-based 

Hybrid networks 

RNN-based 

85

80

75

70

65

60

 
 

Figure 2: Gaps between precision and recall in the tasks of trigger identiﬁcation and event classiﬁcation

Training Data
ACE+FN
ACE+FN
ACE+Wiki

Embedding Types
word
word, NE-type

Methods
ANNs
ANN-S2
DM-CNN∗ word, PSN
CNN
NC-CNN
Bi-RNN
Hybrid
DM-CNN
FB-RNN
SELF

word, NE-type, PSN ACE
word, NE-type, PSN ACE
word, NE-type, DEP ACE
word, NE-type, PSN ACE
ACE
word, PSN
ACE
word, branch
ACE
word, NE-type

Table 3: Embedding types and training data (DEP:
Dependency grammar; PSN: Position)

Figure 2, the gap becomes much wider (from 9%
to 19.7%) when the binary classiﬁcation task (trig-
ger identiﬁcation) is shifted to multi-class classiﬁ-
cation (event detection). By contrast, other work
shows a nearly constant gap. In particular, SELF
yields a minimum gap in each task, which changes
negligibly from 3.5% to 3.4%.

It may be added that, similar to DM-CNN and
FB-RNN, SELF is cost-effective. Compared to
other models (Table 3), it either uses less training
data, or is only required to learn two kinds of em-
beddings, such as that of words and entity types.

5.5 Discussion: Adaptation, Robustness and

Effectiveness

Domain adaptation is a key criteria for evaluating
the utility of a model in practical application. A
model can be thought of being adaptable only if it
works well for the unlabeled data in the target do-
main when trained on the source domain (Blitzer
et al., 2006; Plank and Moschitti, 2013).

We perform two groups of domain adaptation
experiments, respectively, using the ACE 2005
corpus and the corpus for TAC-KBP 2015 event
nugget track (Ellis et al., 2015).

The ACE corpus consists of 6 domains: broad-

cast conversation (bc), broadcast news (bn), tele-
phone conversation (cts), newswire (nw), usenet
(un) and web blogs (wl). Following the com-
mon practice of adaptation research on this data
(Nguyen and Grishman, 2014, 2015; Plank and
Moschitti, 2013), we take the union of bn and nw
as the source domain and bc, cts and wl as three
different target domains. We randomly select half
of the instances from bc to constitute the develop-
ment set. The TAC-KBP corpus consists of 2 do-
mains: newswire (NW) and discussion forum (DF).
We follow Peng et al (2016) to use one of NW and
DF in alternation as the source domain, while the
other the target domain. We randomly select a pro-
portion (20%) of the instances from the target do-
main to constitute the development set.

We compare with Joint, CNN, MSEP-EMD,
SSED (Sammons et al., 2015) and Hybrid. All
the models except Hybrid have been reported for
the performance assessment of domain adaptation.
In this section, we only cite the best performance
they obtained. We reproduce Hybrid by using the
source code given by authors. To ensure a fair
comparison, we perform 3 runs, in each of which,
both Hybrid and SELF were redeveloped on a new
development set. What we report herein is the av-
erage performance they obtained over the 3 runs.

Adaptation Performance

We show the adaptation performance on the ACE
corpus in Tables 4 and that on TAC-KBP in Table
5. It can be observed that SELF outperforms other
models in the out-of-domain scenarios.

Besides, when testing is performed on the out-
of-domain ACE corpus, the performance degrada-
tion of SELF is not much larger than that of CNN
and Hybrid. When the out-of-domain TAC-KBP
corpus is used, the performance of SELF is im-
paired much less severely than SSED and Hybrid.

Methods

Joint
CNN
Hybrid
SELF

In-domain (bn+nw)
P(%) R(%) F(%)

72.9
69.2
68.8
73.8

63.2
67.0
54.8
65.7

67.7
68.0
61.0
69.5

Out-of-domain (bc)
P(%) R(%) F(%) Loss
↓5.1
↓0.4
↑0.6
↓0.6

57.5
65.2
58.8
67.2

68.8
70.2
64.7
70.0

62.6
67.6
61.6
68.9

Out-of-domain (cts)
P(%) R(%) F(%) Loss
↓10.0
↓5.2
↓6.1
↓6.2

64.5
68.3
59.9
68.3

52.3
58.2
50.6
60.2

57.7
62.8
54.9
63.3

Out-of-domain (wl)
P(%) R(%) F(%) Loss
↓22.0
↓20.5
↓16.5
↓19.5

56.4
54.8
54.0
58.0

38.5
42.0
37.9
44.0

45.7
47.5
44.5
50.0

Table 4: Experimental results of domain adaptation on the ACE 2005 corpus

Methods

In-domain (NW)
P(%) R(%) F(%)

MSEP-EMD NA
NA
72.6
67.6

SSED
Hybrid
SELF

NA
NA
55.4
60.6

Out-of-domain (DF)
P(%) R(%) F(%) Loss
↓5.7
NA
↓11.4 NA
↓14.8 66.0
↓7.2
70.5

52.8
52.3
48.1
56.7

NA
NA
39.2
58.7

58.5 NA
63.7 NA
62.3
62.9
69.0
63.9

In-domain (DF)
P(%) R(%) F(%)

NA
NA
42.6
48.3

57.9
62.6
51.8
57.3

Out-of-domain (NW)
P(%) R(%) F(%) Loss
↓2.8
↓7.8
↑1.5
↑1.9

NA
NA
59.1
69.3

NA
NA
48.4
51.7

55.1
54.8
53.3
59.2

Table 5: Experimental results of domain adaptation on the TAC-KBP 2015 corpus (NA: not released)

More importantly, the adaptability of SELF is
relatively close to that of MSEP-EMD. Consider-
ing that MSEP-EMD is stable due to using mini-
mal supervision (Peng et al., 2016), we suggest the
fully trained networks in SELF may not appear to
be extremely inﬂexible, but on the contrary, they
should be transferable for use (Ge et al., 2016).

Robustness in Resource-Poor Settings

There are two resource-poor conditions discussed
in this section, including lack of in-domain train-
ing data and that of out-domain. Hybrid and SELF
are brought into the discussion.

For the former (in-domain) case, we went over
the numbers of samples used for training in the
adaptation experiments, which are shown in Ta-
ble 6. It can be observed that there is a minimum
number of training samples (triggers plus tokens)
contained in the domain of NW. By contrast, the
domain of bn+nw contains the smallest number of
positive samples (triggers) though an overwhelm-
ing number of negative samples (general tokens).
Under such conditions, Hybrid performs better
in the domain of NW compared to bn+nw and DF
in the three in-domain adaptation experiments (see
the column labelled as “In-domain bn+nw” in Ta-
ble 4 as well as “In-domain NW” and “In-domain
DF” in Table 5). It illustrates that Hybrid unnec-
essarily relies on a tremendous number of training
samples to ensure the robustness. But SELF does.
It needs far more negative samples than Hybrid be-
cause of the following reasons:

• It relies on the use of spurious features to im-

plement self-regulation during training.

Domain

bn+nw
NW
DF

Training

Testing

trigger
1,721
2,098
4,106

token
74,179
31,014
10,9275

trigger
343
2,813
1,773

token
16,336
55,459
43,877

Table 6: Data distribution in the source domains

• For a positive sample, the concerned spurious
features (if have) most probably hide in some
negative samples.

• It’s impossible to be aware of such negative
samples. Therefore, taking into consideration
as many negative samples as possible may
help to increase the probability that the spu-
rious features will be discovered.

This is demonstrated by the fact that SELF ob-
tains better performance in the domain of bn+nw
but not NW (see the column labeled as “Training”
in Table 6 and “In-domain” in Table 4 and 5). It
may be added that SELF performs worse in DF al-
though there are more negative samples used for
training (see Table 6). Taking a glance at the num-
ber of positive samples, one may ﬁnd that it is ap-
proximately 2.4 times more than that in bn+nw.
But the number of negative samples in DF is only
1.5 times more than that in bn+nw. It implies that,
if there are more positive samples used for train-
ing, SELF needs to consume proportionally more
negative samples for self-regulation. Otherwise,
the performance will degrade.

For the out-domain case, ideally, both Hybrid
and SELF encounter the problem that there is lack
of target domain data available for training. In this
case, SELF displays less performance degradation

Event mentions
And it still does
We had no part in it
Nobody questions if this is right or ...
And that is what ha- what is happening
Oh, yeah, it wasn’t perfect

Type
Die
Arrest-Jail
Attack
End-Position
Marry

Table 7: Examples of pronouns that act as a trigger

(7.2%) than Hybrid (14.8%) when NW is used for
training. Considering that NW contains the mini-
mum number of samples, we would like to believe
that SELF is more robust than Hybrid for cross-
domain event detection in a resource-poor setting.

Recall and Missing

SELF is able to accurately recall the events whose
occurrence is triggered by ambiguous words, such
as “ﬁne”, “charge”, “campaign”, etc. These am-
biguous words easily causes confusion. For exam-
ple, “campaign” may trigger an Elect event or
Attack in the ACE corpus.

More importantly, SELF ﬁshes out the common
words which serve as a trigger, although they are
not closely related to any kind of events, such as
“take”, “try”, “acquire”, “become”, “create”, etc.
In general, it is very difﬁcult to accurately recall
such triggers because their meanings are not con-
crete enough, and the contexts may be full of kinds
of noises (see example 2 in pg. 1). We observe that
Bi-RNN and Hybrid seldom pick them up.

However, SELF fails to recall the pronouns that
act as a trigger. This is because they occur in spo-
ken language much more frequently than they oc-
cur in written language. The lack of narrative con-
tent makes it difﬁcult to learn the relationship be-
tween the pronouns and the events. Some real ex-
amples collected from ACE are shown in Table 7.

6 Related Work

Event detection is an important subtask of event
extraction (Doddington et al., 2004; Ahn, 2006).

The research can be traced back to the pattern
based approach (Grishman et al., 2005). Encour-
aged by the high accuracy and the beneﬁt of easy-
to-use, researchers have made great efforts to ex-
tract discriminative patterns. Cao et al (2015a;
2015b) use dependency regularization and active
leaning to generalize and expand the patterns.

In the earlier study, another trend is to explore
the features that best characterize each event class,
so as to facilitate supervised classiﬁcation. A vari-

ety of strategies have emerged for converting clas-
siﬁcation clues into feature vectors (Ahn, 2006;
Patwardhan and Riloff, 2009; Liao and Grishman,
2010; Hong et al., 2011; Li et al., 2013, 2014; Wei
et al., 2017). Beneﬁting from the general model-
ing framework, the methods enable the fusion of
multiple features, and more importantly, they are
ﬂexible to use by feature selection. But consider-
able expertise is required for feature engineering.
Recently, the use of neural networks for event
detection has become a promising line of research.
The closely related work has been presented in
section 5.3. The primary advantages of neural net-
works have been demonstrated in the work, such
as performance enhancement, self-learning capa-
bility and robustness.

The generative adversarial network (Goodfel-
low et al., 2014) has emerged as an increasingly
popular approach for text processing (Zhang et al.,
2016; Lamb et al., 2016; Yu et al., 2017). Liu et
al (2017a) use the adversarial multi-task learning
for text classiﬁcation. We follow the work to cre-
ate spurious features, but use them to regulate the
self-learning process in a single-task situation.

7 Conclusion

We use a self-regulated learning approach to im-
prove event detection. In the learning process, the
adversarial and cooperative models are utilized in
decontaminating the latent feature space.

In this study, the performance of the discrimi-
nator in the adversarial network is left to be evalu-
ated. Most probably, the discriminator also per-
forms well because it is gradually enhanced by
ﬁerce competition. Considering this possibility,
we suggest to drive the two discriminators in our
self-regulation framework to cooperate with each
other. Besides, the global features extracted in Li
et al (2013)’s work are potentially useful for de-
tecting the event instances referred by pronouns,
although involve noises. Therefore, in the future,
we will encode the global information by neural
networks and use the self-regulation strategy to re-
duce the negative inﬂuence of noises.

Acknowledgments

We thank Xiaocheng Feng and his colleagues who
shared the source code of Hybrid with us.

This work was supported by the national Natu-
ral Science Foundation of China (NSFC) via Grant
Nos. 61525205, 61751206, 61672368.

References

David Ahn. 2006. The stages of event extraction.
In Proceedings of
the Workshop on Annotating
and Reasoning about Time and Events, Associa-
tion for Computational Linguistics (ACL’06). As-
sociation for Computational Linguistics, pages 1–8.
http://www.aclweb.org/anthology/W06-0901.

John Blitzer, Ryan McDonald, and Fernando Pereira.
Domain adaptation with structural cor-
2006.
respondence learning.
the
2006 conference on Empirical Methods in Natu-
ral Language Processing (EMNLP’06). Associa-
tion for Computational Linguistics, pages 120–128.
http://www.aclweb.org/anthology/W06-1615.

In Proceedings of

Konstantinos Bousmalis, George Trigeorgis, Nathan
Silberman, Dilip Krishnan, and Dumitru Erhan.
2016. Domain separation networks. In Advances in
Neural Information Processing Systems. pages 343–
351.

Kai Cao, Xiang Li, Miao Fan, and Ralph Grish-
Improving event detection with
man. 2015a.
active learning.
the Inter-
national Conference Recent Advances in Natural
Language Processing (RANLP’15). pages 72–77.
http://www.aclweb.org/anthology/R15-1010.

In Proceedings of

Kai Cao, Xiang Li, and Ralph Grishman. 2015b.
Improving event detection with dependency reg-
ularization.
the Interna-
In Proceedings of
tional Conference Recent Advances in Natural
Language Processing (RANLP’15). pages 78–83.
http://www.aclweb.org/anthology/R15-1011.

Yubo Chen, Shulin Liu, Xiang Zhang, Kang Liu, and
Jun Zhao. 2017. Automatically labeled data gener-
ation for large scale event extraction.
In Proceed-
ings of the 55th Annual Meeting of the Association
for Computational Linguistics (ACL’17). volume 1,
https://doi.org/10.18653/v1/P17-
pages 409–419.
1038.

Yubo Chen, Liheng Xu, Kang Liu, Daojian Zeng, Jun
Zhao, et al. 2015. Event extraction via dynamic
In
multi-pooling convolutional neural networks.
Proceedings of the 53th Annual Meeting of the As-
sociation for Computational Linguistics (ACL’15).
pages 167–176.
https://doi.org/10.3115/v1/P15-
1017.

Junyoung Chung, Caglar Gulcehre, KyungHyun Cho,
and Yoshua Bengio. 2014. Empirical evaluation of
gated recurrent neural networks on sequence model-
ing. arXiv preprint arXiv:1412.3555 .

George R Doddington, Alexis Mitchell, Mark A Przy-
bocki, Lance A Ramshaw, Stephanie Strassel, and
Ralph M Weischedel. 2004. The automatic con-
tent extraction (ACE) program-tasks, data, and
evaluation.
In LREC. volume 2, pages 1–4.
http://www.aclweb.org/anthology/L04-1011.

Joe Ellis, Jeremy Getman, Dana Fore, Neil Kuster,
Zhiyi Song, Ann Bies, and Stephanie Strassel. 2015.
Overview of linguistic resources for the tac kbp 2015
evaluations: Methodologies and results. In Proceed-
ings of TAC KBP 2015 Workshop, National Institute
of Standards and Technology (TAC’15). pages 16–
17.

Xiaocheng Feng, Lifu Huang, Duyu Tang, Heng Ji,
Bing Qin, and Ting Liu. 2016.
A language-
independent neural network for event detec-
tion.
the 54th Annual
the Association for Computational
Meeting of
Linguistics (ACL’16). volume 2, pages 66–71.
https://doi.org/10.18653/v1/P16-2011.

In Proceedings of

Tao Ge, Lei Cui, Baobao Chang, Zhifang Sui, and
Ming Zhou. 2016. Event detection with burst infor-
mation networks. In Proceedings of COLING 2016,
the 26th International Conference on Computational
Linguistics: Technical Papers. pages 3276–3286.

Reza Ghaeini, Xiaoli Fern, Liang Huang,

and
Prasad Tadepalli. 2016.
Event nugget detec-
tion with forward-backward recurrent neural net-
In Proceedings of the 54th Annual Meet-
works.
the Association for Computational Lin-
ing of
guistics (ACL’16). volume 2, pages 369–373.
https://doi.org/10.18653/v1/P16-2060.

Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,
Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. 2014. Generative ad-
versarial nets.
In Advances in neural information
processing systems. pages 2672–2680.

Ralph Grishman, David Westbrook, and Adam Meyers.
2005. Nyu’s English ACE 2005 system description.
ACE’05 .

Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky,
Ilya Sutskever, and Ruslan R Salakhutdinov. 2012.
Improving neural networks by preventing co-
adaptation of feature detectors.
arXiv preprint
arXiv:1207.0580 .

Yu Hong, Di Lu, Dian Yu, Xiaoman Pan, Xiaobin
Wang, Yadong Chen, Lifu Huang, and Heng Ji.
2015. RPI BLENDER TAC-KBP2015 system de-
scription.
In Proceedings of Text Analysis Confer-
ence (TAC’15).

Ronan Collobert and Jason Weston. 2008. A uniﬁed
architecture for natural language processing: Deep
In Pro-
neural networks with multitask learning.
ceedings of the 25th international conference on
Machine learning (ICML’08). ACM, pages 160–
167.

Yu Hong, Xiaobin Wang, Yadong Chen, Jian Wang,
Tongtao Zhang, Jin Zheng, Dian Yu, Qi Li, Boliang
Zhang, Han Wang, et al. 2014. RPI BLENDER
TAC-KBP2014 knowledge base population sys-
tem.
In Proceedings of Text Analysis Conference
(TAC’14).

Yu Hong, Jianfeng Zhang, Bin Ma, Jianmin Yao,
Guodong Zhou, and Qiaoming Zhu. 2011. Using
cross-entity inference to improve event extraction.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies (ACL-HLT’11). Association
for Computational Linguistics, pages 1127–1136.
http://www.aclweb.org/anthology/P11-1113.

Xun Huang, Yixuan Li, Omid Poursaeed,

John
Hopcroft, and Serge Belongie. 2017. Stacked gener-
ative adversarial networks. In IEEE Conference on
Computer Vision and Pattern Recognition (CVPR).
volume 2, page 4.

Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidi-
rectional LSTM-CRF models for sequence tagging.
arXiv preprint arXiv:1508.01991 .

Md M Islam, Xin Yao, and Kazuyuki Murase. 2003. A
constructive algorithm for training cooperative neu-
ral network ensembles. IEEE Transactions on neu-
ral networks 14(4):820–834.

Rafal

Jozefowicz, Wojciech Zaremba,

and Ilya
Sutskever. 2015. An empirical exploration of recur-
rent network architectures.
In Proceedings of the
32nd International Conference on Machine Learn-
ing (ICML’15). pages 2342–2350.

Alex M Lamb, Anirudh Goyal ALIAS PARTH
GOYAL, Ying Zhang, Saizheng Zhang, Aaron C
Courville, and Yoshua Bengio. 2016.
Professor
forcing: A new algorithm for training recurrent net-
works. In Advances In Neural Information Process-
ing Systems. pages 4601–4609.

Qi Li, Heng Ji, and Liang Huang. 2013.

Joint
event extraction via structured prediction with
the 51th
global
the Association for Com-
Annual Meeting of
putational Linguistics
(ACL’13). pages 73–82.
http://www.aclweb.org/anthology/P13-1008.

In Proceedings of

features.

Qi Li, Heng Ji, HONG Yu, and Sujian Li. 2014.
Constructing information networks using one sin-
gle model.
the 2014 Con-
In Proceedings of
ference on Empirical Methods in Natural Lan-
guage Processing (EMNLP’14). pages 1846–1851.
https://doi.org/10.3115/v1/D14-1198.

Shasha Liao and Ralph Grishman. 2010.

Us-
ing document level cross-event inference to im-
prove event extraction.
the
the Association for
48th Annual Meeting of
Computational Linguistics (ACL’10). Association
for Computational Linguistics, pages 789–797.
http://www.aclweb.org/anthology/P10-1081.

In Proceedings of

Zhouhan Lin, Minwei Feng, Cicero Nogueira dos San-
tos, Mo Yu, Bing Xiang, Bowen Zhou, and Yoshua
Bengio. 2017. A structured self-attentive sentence
embedding. arXiv preprint arXiv:1703.03130 .

Ming-Yu Liu and Oncel Tuzel. 2016. Coupled gener-
In Advances in neural

ative adversarial networks.
information processing systems. pages 469–477.

Pengfei Liu, Xipeng Qiu, Jifan Chen, and Xuanjing
Huang. 2016a. Deep fusion LSTMs for text se-
mantic matching.
In Proceedings of the 54th An-
nual Meeting of the Association for Computational
Linguistics (ACL’16). volume 1, pages 1034–1043.
https://doi.org/10.18653/v1/P16-1098.

Pengfei Liu, Xipeng Qiu, and Xuanjing Huang.
2017a. Adversarial multi-task learning for text
classiﬁcation.
arXiv preprint arXiv:1704.05742
https://doi.org/10.18653/v1/P17-1001.

Shulin Liu, Yubo Chen, Shizhu He, Kang Liu, and
Jun Zhao. 2016b.
to im-
prove automatic event detection.
In Proceed-
the Asso-
the 54th Annual Meeting of
ings of
ciation for Computational Linguistics (ACL’16).
https://doi.org/10.18653/v1/P16-1201.

Leveraging framenet

Shulin Liu, Yubo Chen, Kang Liu, and Jun Zhao.
2017b. Exploiting argument information to improve
event detection via supervised attention mechanisms
1:1789–1797.
https://doi.org/10.18653/v1/P17-
1164.

Linguistic regularities

Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013.
in continuous
space word representations.
In Proceedings
of
the 2013 Conference of
the North Ameri-
the Association for Computa-
can Chapter of
tional Linguistics: Human Language Technolo-
gies (NAACL’13). volume 13, pages 746–751.
http://www.aclweb.org/anthology/N13-1090.

Thien Huu Nguyen, Kyunghyun Cho, and Ralph Gr-
ishman. 2016. Joint event extraction via recurrent
neural networks. In Proceedings of the 2016 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies (NAACL’16). pages 300–309.
https://doi.org/10.18653/v1/N16-1034.

Thien Huu Nguyen and Ralph Grishman. 2014. Em-
ploying word representations and regularization for
domain adaptation of relation extraction.
In Pro-
ceedings of the 52th Annual Meeting of the Associa-
tion for Computational Linguistics (ACL’14). pages
68–74. https://doi.org/10.3115/v1/P14-2012.

Thien Huu Nguyen and Ralph Grishman. 2015. Event
detection and domain adaptation with convolu-
tional neural networks.
the
53th Annual Meeting of the Association for Com-
putational Linguistics (ACL’15). pages 365–371.
https://doi.org/10.3115/v1/P15-2060.

In Proceedings of

Thien Huu Nguyen and Ralph Grishman. 2016. Mod-
eling skip-grams for event detection with convo-
lutional neural networks.
In Proceedings of the
2016 Conference on Empirical Methods in Natural
Language Processing (EMNLP’16). pages 886–891.
https://doi.org/10.18653/v1/D16-1085.

Siddharth Patwardhan and Ellen Riloff. 2009. A
uniﬁed model of phrasal and sentential evidence

for information extraction.
In Proceedings of the
2009 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP’09). Associa-
tion for Computational Linguistics, pages 151–160.
http://www.aclweb.org/anthology/D09-1016.

Lantao Yu, Weinan Zhang, Jun Wang, and Yong Yu.
Seqgan: Sequence generative adversarial
2017.
nets with policy gradient.
In Proceedings of the
32nd AAAI Conference on Artiﬁcial Intelligence
(AAAI’17). pages 2852–2858.

Haoruo Peng, Yangqiu Song, and Dan Roth. 2016.
Event detection and co-reference with minimal
supervision.
the 2016 Con-
In Proceedings of
ference on Empirical Methods in Natural Lan-
guage Processing (EMNLP’16). pages 392–402.
https://doi.org/10.18653/v1/D16-1038.

Matthew D Zeiler. 2012. Adadelta: an adaptive learn-
ing rate method. arXiv preprint arXiv:1212.5701 .

Yizhe Zhang, Zhe Gan, and Lawrence Carin. 2016.
In NIPS

Generating text via adversarial training.
workshop on Adversarial Training. volume 21.

Barbara Plank and Alessandro Moschitti. 2013. Em-
bedding semantic similarity in tree kernels for do-
main adaptation of relation extraction. In Proceed-
ings of the 51th Annual Meeting of the Associa-
tion for Computational Linguistics (ACL’13). pages
1498–1507. http://www.aclweb.org/anthology/P13-
1147.

Mark Sammons, Haoruo Peng, Yangqiu Song, Shyam
Upadhyay, Chen-Tse Tsai, Pavankumar Reddy,
Subhro Roy, and Dan Roth. 2015. Illinois CCG TAC
2015 event nugget, entity discovery and linking, and
slot ﬁller validation systems. In Proceedings of Text
Analytics Conference (TAC’15).

Mike Schuster and Kuldip K Paliwal. 1997. Bidirec-
tional recurrent neural networks. IEEE Transactions
on Signal Processing 45(11):2673–2681.

Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.
Sequence to sequence learning with neural net-
works. In Advances in neural information process-
ing systems. pages 3104–3112.

Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.
Word representations: a simple and general method
for semi-supervised learning.
In Proceedings of
the 48th Annual Meeting of the Association for
Computational Linguistics
(ACL’10). Associa-
tion for Computational Linguistics, pages 384–394.
https://doi.org/http://www.aclweb.org/anthology/P10-
1040.

Mengqiu Wang and Christopher D Manning. 2013.
Effect of non-linear deep architecture in se-
quence labeling.
the Sixth
International Joint Conference on Natural Lan-
guage Processing (IJCNLP’13). pages 1285–1291.
https://doi.org/http://www.aclweb.org/anthology/I13-
1183.

In Proceedings of

Sam Wei,

Igor Korostil, Joel Nothman, and Ben
Hachey. 2017. English event detection with trans-
lated language features. In Proceedings of the 55th
Annual Meeting of the Association for Computa-
tional Linguistics (ACL’17). volume 2, pages 293–
298. https://doi.org/10.18653/v1/P17-2046.

Dian Yu, Xiaoman Pan, Boliang Zhang, Lifu Huang,
Di Lu, Spencer Whitehead, and Heng Ji. 2016. RPI
BLENDER TAC-KBP2016 system description.
In
Proceedings of Text Analysis Conference (TAC’16).

Self-regulation: Employing a Generative Adversarial Network to Improve
Event Detection

Yu Hong Wenxuan Zhou Jingli Zhang Qiaoming Zhu Guodong Zhou∗
Institute of Artiﬁcial Intelligence, Soochow University
School of Computer Science and Technology, Soochow University
No.1, Shizi ST, Suzhou, China, 215006
{tianxianer, wxchow024, jlzhang05}@gmail.com
{qmzhu, gdzhou}@suda.edu.cn

Abstract

Due to the ability of encoding and map-
ping semantic information into a high-
dimensional latent feature space, neural
networks have been successfully used for
detecting events to a certain extent. How-
ever, such a feature space can be easily
contaminated by spurious features inher-
ent in event detection.
In this paper, we
propose a self-regulated learning approach
by utilizing a generative adversarial net-
work to generate spurious features. On the
basis, we employ a recurrent network to
eliminate the fakes. Detailed experiments
on the ACE 2005 and TAC-KBP 2015 cor-
pora show that our proposed method is
highly effective and adaptable.

1

Introduction

Event detection aims to locate the event triggers
of speciﬁed types in text. Normally, triggers are
words or nuggets that evoke the events of interest.
Detecting events in an automatic way is chal-
lenging, not only because an event can be ex-
pressed in different words, but also because a word
may express a variety of events in different con-
texts. In particular, the frequent utilization of com-
mon words, ambiguous words and pronouns in
event mentions makes them harder to detect:

1) Generality – taken home <Transport>

Ambiguity 1 – campaign in Iraq <Attack>
Ambiguity 2 – political campaign <Elect>
Coreference – Either its bad or good <Marry>

A promising solution to this challenge is
through semantic understanding. Recently, neu-
ral networks have been widely used in this direc-
tion (Nguyen and Grishman, 2016; Ghaeini et al.,

∗ Corresponding author

2016; Feng et al., 2016; Liu et al., 2017b; Chen
et al., 2017), which allows semantics of event
mentions (trigger plus context) to be encoded in
a high-dimensional latent feature space. This fa-
cilitates the learning of deep-level semantics. Be-
sides, the use of neural networks not only strength-
ens current supervised classiﬁcation of events but
alleviates the complexity of feature engineering.

However, compared to the earlier study (Liao
and Grishman, 2010; Hong et al., 2011; Li et al.,
2013), in which the features are carefully designed
by experts, the neural network based methods suf-
fer more from spurious features. Here, spurious
feature is speciﬁed as the latent information which
looks like the semantically related information to
an event, but actually not (Liu et al., 2017a). For
example, in the following sample, the semantic
information of the word “prison” most probably
enables spurious features to come into being, be-
cause the word often co-occurs with the trigger
”taken” to evoke an Arrest-jail event instead
of the ground-truth event Transport:

2) Prison authorities have given the nod for An-
war to be taken home later in the afternoon.
Trigger: taken. Event Type: Transport

It is certain that spurious features often result
from the semantically pseudo-related context, and
during training, a neural network may mistakenly
and unconsciously preserve the memory to pro-
duce the fakes. However, it is difﬁcult to deter-
mine which words are pseudo-related in a speciﬁc
case, and when they will “jump out” to mislead the
generation of latent features during testing.

To address the challenge, we suggest to regu-
late the learning process with a two-channel self-
regulated learning strategy. In the self-regulation
process, on one hand, a generative adversarial net-
work is trained to produce the most spurious fea-
tures, while on the other hand, a neural network

(cid:28595)

(cid:28661)(cid:28660)(cid:28662)(cid:28670)(cid:28595)(cid:28675)(cid:28677)(cid:28674)(cid:28675)(cid:28660)(cid:28666)(cid:28660)(cid:28679)(cid:28668)(cid:28674)(cid:28673)(cid:28595)

(cid:22) 

(cid:7) 

(cid:28643)(cid:28677)(cid:28664)(cid:28663)(cid:28668)(cid:28662)(cid:28679)(cid:28668)(cid:28674)(cid:28673)(cid:28595)

(cid:1876) 

(cid:10) 

(cid:10)(cid:3545) 

(cid:7)(cid:3545) 

(cid:28661)(cid:28660)(cid:28662)(cid:28670)(cid:28595)(cid:28675)(cid:28677)(cid:28674)(cid:28675)(cid:28660)(cid:28666)(cid:28660)(cid:28679)(cid:28668)(cid:28674)(cid:28673)(cid:28595)

Figure 1: Self-regulated learning scheme

is equipped with a memory suppressor to elimi-
nate the fakes. Detailed experiments on event de-
tection show that our proposed method achieves
a substantial performance gain, and is capable of
robust domain adaptation.

2 Task Deﬁnition

The task of event detection is to determine whether
there is one or more event triggers in a sentence.
Trigger is deﬁned as a token or nugget that best
signals the occurrence of an event. If successfully
identiﬁed, a trigger is required to be assigned a tag
to indicate the event type:

Input: Either its bad or good
Output: its <trigger>; Marry <type>
We formalize the event detection problem as a
multi-class classiﬁcation problem. Given a sen-
tence, we classify every token of the sentence into
one of the predeﬁned event classes (Doddington
et al., 2004) or non-trigger class.

3 Self-Regulated Learning (SELF)

SELF is a double-channel model (Figure 1), con-
sisted of a cooperative network (Islam et al., 2003)
and a generative adversarial net (GAN) (Goodfel-
low et al., 2014). A memory suppressor S is used
to regulate communication between the channels.

3.1 Cooperative Network

In channel 1, the generator G is speciﬁed as a mul-
tilayer perceptron. It plays a role of a “diligent stu-
dent”. By a differentiable function G(x, θg) with
parameters θg, the generator learns to produce a
vector of latent features og that may best charac-
terize the token x, i.e., og = G(x, θg).

The discriminator D (called “a lucky profes-
sor”) is a single-layer perceptron, implemented as
a differentiable function D(og, θd) with parame-
ters θd. Relying on the feature vector og, it at-
tempts to accurately predict the probability of the
token x triggering an event for all event classes,
i.e., ˆy = D(og, θd), and assigns x to the most
probable class c (iff ˆyc > ∀ˆy¯c, ¯c (cid:3)= c).

Therefore, G and D cooperate with each other
during training, developing the parameters θg and
θd with the same goal – to minimize the perfor-
mance loss L(ˆy, y) in the detection task:

(cid:2)

(cid:3)

θg
θd

= argmin L(ˆy, y)

(1)

where, y denotes the ground-truth probability dis-
tribution over event classes, and L indicates the
deviation of the prediction from the ground truth.

3.2 Generative Adversarial Network
In channel 2, the generator ˇG and discriminator
ˇD have the same perceptual structures as G and
D. They also perform learning by differentiable
functions, respectively ˇG(x, θˇg) and ˇD(oˇg, θ ˇd
). A
major difference, however, is that they are caught
into a cycle of highly adversarial competition.

The generator ˇG is a “trouble maker”. It learns
to produce spurious features, and utilizes them to
contaminate the feature vector oˇg of the token x.
Thus ˇG changes a real sample x into a fake z –
sometimes successfully, sometimes less so. Using
the fakes, ˇG repeatedly instigates the discrimina-
tor ˇD to make mistakes. On the other side, ˇD (“a
hapless professor”) has to avoid being deceived,
and struggles to correctly detect events no matter
whether it encounters x or z.

In order to outsmart the adversary, ˇG develops
the parameters θˇg during training to maximize the
performance loss, but on the contrary, ˇD develops
the parameters θ ˇd to minimize the loss:

θˇg = argmax L(ˆy, y)
= argmin L(ˆy, y)
θ ˇd

(2)

(3)

Numerous studies have conﬁrmed that the two-
player minmax game enables both ˇG and ˇD to im-
prove their methods (Goodfellow et al., 2014; Liu
and Tuzel, 2016; Huang et al., 2017).

3.3 Regulation with Memory Suppressor

Using a memory suppressor, we try to optimize the
diligent student G. The goal is to enable G to be
as dissimilar as possible to the troublemaker ˇG.

The suppressor uses the output oˇg of ˇG as a ref-
erence resource which should be full of spurious
features. On the basis, it looks over the output og
of G, so as to verify whether the features in og
are different to those in oˇg. If very different, the
suppressor allows G to preserve the memory (viz.,
θg in G(x, θg)), otherwise update. In other word,

for G, the suppressor forcibly erases the memory
which may result in the generation of spurious fea-
tures. We call this the self-regulation.

Self-regulation is performed for the whole sen-
tence which is fed into G and ˇG. Assume that Og
is a matrix, constituted with a series of feature vec-
tors, i.e., the vectors generated by G for all the to-
kens in an input sentence (og ∈ Og), while Oˇg
is another feature matrix, generated by ˇG for the
tokens (oˇg ∈ Oˇg). Thus, we utilize the matrix ap-
proximation between Og and Oˇg for measuring the
loss of self-regulation learning Ldif f . The higher
the similarity, the greater the loss. During training,
the generator G is required to develop the param-
eters θg to minimize the loss:

θg = argmin Ldif f (og, oˇg)

(4)

We present in detail the matrix approximate cal-
culation in section 4.4, where the squared Frobe-
nius norm (Bousmalis et al., 2016) is used.

3.4 Learning to Predict

We incorporate the cooperative network with the
GAN, and enhance their learning by joint training.
In the 4-member incorporation, i.e., {G, ˇG, D
and ˇD}, the primary beneﬁciary is the lucky pro-
fessor D. It can beneﬁt from both the cooperation
in channel 1 and the competition in channel 2. The
latent features it uses are well-produced by G, and
decontaminated by eliminating possible fakes like
those made by ˇG. Therefore, in experiments, we
choose to output the prediction results of D.

In this paper, we use two recurrent neural net-
works (RNN) (Sutskever et al., 2014; Chung et al.,
2014) of the same structure as the generators. And
both the discriminators are implemented as a fully-
connected layer followed by a softmax layer.

4 Recurrent Models for SELF

RNN with long short-term memory (abbr., LSTM)
is adopted due to the superior performance in a va-
riety of NLP tasks (Liu et al., 2016a; Lin et al.,
2017; Liu et al., 2017a). Furthermore, the bidi-
rectional LSTM (Bi-LSTM) architecture (Schus-
ter and Paliwal, 1997; Ghaeini et al., 2016; Feng
et al., 2016) is strictly followed. This architecture
enables modeling of the semantics of a token with
both the preceding and following contexts.

4.1 LSTM based Generator

Given a sentence, we follow Chen et al (2015) to
take all the tokens of the whole sentence as the in-

put. Before feeding the tokens into the network,
we transform each of them into a real-valued vec-
tor x ∈ Re. The vector is formed by concatenating
a word embedding with an entity type embedding.

• Word Embedding: It is a ﬁxed-dimensional
real-valued vector which represents the hid-
den semantic properties of a token (Collobert
and Weston, 2008; Turian et al., 2010).

• Entity Type Embedding: It is specially used
to characterize the entity type associated with
a token. The BIO2 tagging scheme (Wang
and Manning, 2013; Huang et al., 2015) is
employed for assigning a type label to each
token in the sentence.

For the input token xt at the current time step t,
the LSTM generates the latent feature vector ot ∈
Rd by the previous memory. Meanwhile, the token
is used to update the current memory.

The LSTM possesses a long-term memory unit
ct ∈ Rd and short-term (cid:4)ct ∈ Rd. In addition, it
is equipped with the input gate it, forgetting gate
ft and a hidden state ht, which are assembled to-
gether to promote the use of memory, as well as
dynamic memory updating. Similarly, they are de-
ﬁned as a d-dimensional vector in Rd. Thus LSTM
works in the following way:

⎡

⎢
⎢
⎣

ot
(cid:4)ct
it
ft

⎤

⎥
⎥
⎦ =

⎡

⎢
⎢
⎣

⎤

⎥
⎥
⎦

σ
tanh
σ
σ

(cid:11)

(cid:2)

(cid:3)

(cid:12)

W

xt
ht−1

+ b

ht = ot (cid:5) tanh(ct)
ct = (cid:4)ct (cid:5) it + ct−1 (cid:5) ft

(5)

(6)

(7)

where W ∈ R4d×(d+e) and b ∈ R4d are parame-
ters of afﬁne transformation; σ refers to the logis-
tic sigmoid function and (cid:5) denotes element-wise
multiplication.

The output functions of both the generators in
SELF, i.e., G and ˇG, can be boiled down to the
output gate ot ∈ Rd of the LSTM cell:

ot = LST M (xt; θ)

(8)

where, the function LSTM (·;·) is a shorthand for
Eq. (5-7) and θ represents all the parameters of
LSTM. For both G and ˇG, θ are initialized with the
same values in experiments. But due to the distinct
training goals of G and ˇG (diligence or making-
trouble), the values of the parameters in the two

cases will change to be very different after train-
ing. Therefore, we have og,t = LST M (xt, θg,t)
and oˇg,t = LST M (xt, θˇg,t).

4.2 Fully-connected Layer for Discrimination

Depending on the feature vectors og,t and oˇg,t, the
two discriminators D and ˇD predict the probabil-
ity of the token xt triggering an event for all event
classes. As usual, they compute the probability
distribution over classes using a fully connected
layer followed by a softmax layer:

ˆy = sof tmax( ˆW · ot + ˆb)

(9)

where ˇy is a C-dimensional vector, in which each
dimension indicates the prediction for a class; C
is the class number; ˆW ∈ Rd is the weight which
needs to be learned; ˆb is a bias term.

It is noteworthy that the discriminator D and ˇD
don’t share the weight and the bias. It means that,
for the same token xt, they may make markedly
different predictions: ˆyg,t = sof tmax( ˆWg · og,t +
ˆbg) and ˆyˇg,t = sof tmax( ˆWˇg · oˇg,t + ˆbˇg).

4.3 Classiﬁcation Loss

We specify the loss as the cross-entropy between
the predicted and ground-truth probability distri-
butions over classes. Given a batch of training data
that includes N samples (xi, yi), we calculate the
losses the discriminators cause as below:

where, (cid:6) · (cid:6)2
F denotes the squared Frobenius norm
(Bousmalis et al., 2016), which is used to calculate
the similarity between matrices.

It is noteworthy that the feature vectors a gen-
erator outputs are required to serve as the rows in
the matrix, deployed in a top-down manner and
arranged in the order in which they are generated.
For example, the feature vector og,t the generator
G outputs at the time t needs to be placed in the
t-th row of the matrix Og.

At the very beginning of the measurement, the
similarity between every feature vector in Og and
that in O ˇG is ﬁrst calculated by the matrix-matrix
multiplication OgO(cid:3)
ˇg :

⎛

⎜
⎜
⎜
⎜
⎝

og,1o(cid:3)
ˇg,1
...
og,1o(cid:3)
ˇg,t
...
og,1o(cid:3)
ˇg,l

... og,1o(cid:3)
ˇg,t
...
...
... og,to(cid:3)
ˇg,t
...
...
og,lo(cid:3)
...
ˇg,t

...

... og,1o(cid:3)
ˇg,l
...
... og,to(cid:3)
ˇg,l
...
...

...
og,lo(cid:3)
ˇg,l

⎞

⎟
⎟
⎟
⎟
⎠

where, the symbol (cid:7) denotes the transpose opera-
tion; l is the sentence length which is deﬁned to be
uniform for all sentences (l=80), and if it is larger
than the real ones, padding is used; og,ioˇg,j de-
notes the scalar product between the feature vec-
tors og,i and oˇg,j.

Let Am×n be a matrix, the squared Frobenius

norm of Am×n (i.e., (cid:6)Am×n(cid:6)2

F ) is deﬁned as:

⎛

m(cid:13)

n(cid:13)

⎞

1
2

i=1

j=1

N(cid:13)

C(cid:13)

i=1
N(cid:13)

j=1
C(cid:13)

i=1

j=1

L(ˆyg, y) = −

i log(ˆyj
yj

g,i

)

(10)

(cid:6)Am×n(cid:6)2

F

⎝

=

|aij|2

⎠

(13)

L(ˆyˇg, y) = −

i log(ˆyj
yj
ˇg,i

)

(11)

where yi is a C-dimensional one-hot vector. The
value of its j-th dimension is set to be 1 only if the
token xi triggers an event of the j-th class, other-
wise 0. Both ˆyg,i and ˆyˇg,i are the predicted proba-
bility distributions over the C classes for xi.

4.4 Loss of Self-regulated Learning

Assume that Og is a matrix, consisted of the fea-
ture vectors output by G for all the tokens in a sen-
tence, i.e., og,t ∈ Og, and Oˇg is that provided by
ˇG, i.e., oˇg,t ∈ Oˇg, thus we compute the similarity
between Og and Oˇg and use it as the measure of
self-regulation loss Ldif f (Og, Oˇg):

where, aij denotes the j-th element in the i-th
row of Am×n. Thus, if we let Am×n be the ma-
trix produced by the matrix-matrix multiplication
OgO(cid:3)
ˇg , the self-regulation loss Ldif f (Og, Oˇg) can
be eventually obtained by:

Ldif f (Og, Oˇg) =

|og,ioˇg,j|2

(14)

⎛

⎝

l(cid:13)

l(cid:13)

i=1

j=1

1
2

⎞

⎠

For a batch of training data that includes N (cid:4)
sentences, the global self-regulation loss is spec-
iﬁed as the sum of the losses for all the sentences:
LSELF =

N (cid:3)
i=1 Ldif f (Og, Oˇg).

(cid:20)

4.5 Training

Ldif f (Og, Oˇg) = (cid:6)OgO(cid:3)
ˇg

(cid:6)2

F

(12)

We train the cooperative network in SELF to min-
imize the classiﬁcation loss L(ˆyg, y) and the loss

of self-regulated learning LSELF :

θg = argmin (Lˆyg, y)
θd = argmin (L(ˆyg, y) + λ · LSELF )

(15)

(16)

where λ is a hyper-parameter, which is used to har-
monize the two losses.

The min-max game is utilized for training the
adversarial net in SELF: θˇg = argmax L(ˆyˇg, y);
θ ˇd

= argmin L(ˆyˇg, y).
All the networks in SELF are trained jointly us-
ing the same batches of samples. They are trained
via stochastic gradient descent (Nguyen and Gr-
ishman, 2015) with shufﬂed mini-batches and the
AdaDelta update rule (Zeiler, 2012). The gradi-
ents are computed using back propagation. And
regularization is implemented by a dropout (Hin-
ton et al., 2012).

5 Experimentation

5.1 Resource and Experimental Datasets

We test the presented model on the ACE 2005 cor-
pus. The corpus is annotated with single-token
event triggers and has 33 predeﬁned event types
(Doddington et al., 2004; Ahn, 2006), along with
one class “None” for the non-trigger tokens, con-
stitutes a 34-class classiﬁcation problem.

For comparison purpose, we use the corpus in
the traditional way, randomly selecting 30 articles
in English from different genres as the develop-
ment set, and utilizing a separate set of 40 English
newswire articles as the test set. The remaining
529 English articles are used as the training set.

5.2 Hyperparameter Settings

The word embeddings are initialized with the 300-
dimensional real-valued vectors. We follow Chen
et al (2015) and Feng et al (2016) to pre-train the
embeddings over NYT corpus using Mikolov et al
(2013)’s skip-gram tool. The entity type embed-
dings, as usual (Nguyen et al., 2016; Feng et al.,
2016; Liu et al., 2017b), are speciﬁed as the 50-
dimensional real-valued vectors. They are initial-
ized with the 32-bit ﬂoating-point values, which
are all randomly sampled from the uniformly dis-
tributed values in [-1, 1]1. We initialize other ad-
justable parameters of the back-propagation algo-
rithm by randomly sampling in [-0.1, 0.1].

We follow Feng et al (2016) to set the dropout
rate as 0.2 and the mini-batch size as 10. We
1https://www.tensorﬂow.org/api docs/python/tf/random

uniform

tune the initialized parameters mentioned above,
harmonic coefﬁcient λ, learning rate and the L2
norm on the development set. Grid search (Liu
et al., 2017a) is used to seek for the optimal pa-
rameters. Eventually, we take the coefﬁcient λ of
0.1+3, learning rate of 0.3 and L2 norm of 0.

The source code of SELF2 to reproduce the ex-

periments has been made publicly available.

5.3 Compared Systems

The state-of-the-art models proposed in the past
decade are compared with ours. By taking learn-
ing framework as the criterion, we divide the mod-
els into three classes:

Minimally supervised approach: is Peng et al

(2016)’s MSEP-EMD.

Feature based approaches: primarily includ-
ing Liao and Grishman (2010)’s Cross-Event in-
ference model, which is based on the max-entropy
classiﬁcation and embeds the document-level con-
ﬁdent information in the feature space; Hong et al
(2011)’s Cross-Entity inference model, in which
existential backgrounds of name entities are em-
ployed as the additional discriminant features; and
Li et al (2013)’s Joint model, a sophisticated pre-
dictor frequently ranked among the top 3 in re-
cent TAC-KBP evaluations for nugget and corefer-
ence detection (Hong et al., 2014, 2015; Yu et al.,
2016).
It is based on structured perceptron and
combines the local and global features.

Neural network based approaches: including
the convolutional neural network (CNN) (Nguyen
and Grishman, 2015),
the non-consecutive N-
grams based CNN (NC-CNN) (Nguyen and Gr-
ishman, 2016) and the CNN that is assembled with
a dynamic multi-pooling layer (DM-CNN) (Chen
et al., 2015). Others include Ghaeini et al (2016)’s
forward-backward recurrent neural network (FB-
RNN) which is developed using gated recurrent
units (GRU), Nguyen et al (2016)’s bidirectional
RNN (Bi-RNN) and Feng et al (2016)’s Hybrid
networks that consist of a Bi-LSTM and a CNN.

Besides, we compare our model with Liu et al
(2016b)’s artiﬁcial neural networks (ANNs), Liu
et al (2017b)’s attention-based ANN (ANN-S2)
and Chen et al (2017)’s DM-CNN∗. The models
recently have become popular because, although
simple in structure, they are very analytic by learn-
ing from richer event examples, such as those in

2https://github.com/JoeZhouWenxuan/Self-regulation-
Employing-a-Generative-Adversarial-Network-to-Improve-
Event-Detection/tree/master

P (%) R (%)
Method
76.9
Joint (Local+Global)
75.6
MSEP-EMD
80.4
DM-CNN
DM-CNN∗
79.7
Bi-RNN
68.5
Hybrid: Bi-LSTM+CNN 80.8
SELF: Bi-LSTM+GAN 75.3

65.0
69.8
67.7
69.6
75.7
71.5
78.8

F (%)
70.4
72.6
73.5
74.3
71.9
75.9
77.0

Table 1: Trigger identiﬁcation performance

FrameNet (FN) and Wikipeida (Wiki).

5.4 Experimental Results

We evaluate our model using Precision (P), Re-
call (R) and F-score (F). To facilitate the compar-
ison, we review the best performance of the com-
petitors, which has been evaluated using the same
metrics, and publicly reported earlier.

Trigger identiﬁcation

Table 1 shows the trigger identiﬁcation perfor-
mance. It can be observed that SELF outperforms
other models, with a performance gain of no less
than 1.1% F-score.

Frankly, the performance mainly beneﬁts from
the higher recall (78.8%). But in fact the relatively
comparable precision (75.3%) to the recall rein-
forces the advantages. By contrast, although most
of the compared models achieve much higher pre-
cision over SELF, they suffer greatly from the sub-
stantial gaps between precision and recall. The ad-
vantage is offset by the greater loss of recall.

GAN plays an important role in optimizing Bi-
RNN. This is proven by the fact that SELF (Bi-
LSTM+GAN) outperforms Nguyen et al (2016)’s
Bi-RNN. To be honest, the models use two differ-
ent kinds of recurrent units. Bi-RNN uses GRUs,
but SELF uses the units that possess LSTM. Nev-
ertheless, GRU has been experimentally proven to
be comparable in performance to LSTM (Chung
et al., 2014; Jozefowicz et al., 2015). This allows
a fair comparison between Bi-RNN and SELF.

Event classiﬁcation

Table 2 shows the performance of multi-class clas-
siﬁcation. SELF achieves nearly the same F-score
as Feng et al (2016)’s Hybrid, and outperforms the
others. More importantly, SELF is the only one
which obtains a performance higher than 70% for
both precision and recall.

Besides, by analyzing the experimental results,

we have identiﬁed the following regularities:

P (%) R (%)
Methods
70.4
MSEP-EMD
68.8
Cross-Event
72.9
Cross-Entity
73.7
Joint (Local+Global)
71.8
CNN
75.6
DM-CNN
-
NC-CNN
66.8
FB-RNN (GRU)
66.0
Bi-RNN (GRU)
77.6
ANNs (ACE+FN)
DM-CNN∗(ACE+Wiki)
75.7
ANN-S2 (ACE+FN)
76.8
Hybrid: Bi-LSTM+CNN 84.6
71.3
SELF: Bi-LSTM+GAN

65.0
68.9
64.3
62.3
66.4
63.6
-
68.0
73.0
65.2
66.0
67.5
64.9
74.7

F (%)
67.6
68.8
68.3
67.5
69.0
69.1
71.3
67.4
69.3
70.7
70.5
71.9
73.4
73.0

Table 2: Detection performance (trigger identiﬁ-
cation plus multi-class classiﬁcation)

• Similar to the pattern classiﬁers that are based
on hand-designed features, the CNN models
enable higher precision to be obtained. How-
ever the recall is lower.

• The RNN models contribute to achieving a
higher recall. However the precision is lower.

• Expansion of the training data set helps to in-

crease the precision.

Let us turn to the structurally more complicated

models, SELF and Hybrid.

SELF inherits the merits of the RNN models,
classifying the events with higher recall. Besides,
by the utilization of GAN, SELF has evolved from
the traditional learning strategies, being capable of
learning from GAN and getting rid of the mistak-
enly generated spurious features. So that it outper-
forms other RNNs, with improvements of no less
than 4.5% precision and 1.7% recall.

Hybrid is elaborately established by assembling
a RNN with a CNN. It models an event from two
perspectives: language generation and pragmatics.
The former is deeply learned by using the contin-
uous states hidden in the recurrent units, while the
later the convolutional features. Multi-angled cog-
nition enables Hybrid to be more precise. How-
ever it is built using a single-channel architecture,
concatenating the RNN and the CNN. This results
in twofold accumulation of feature information,
causing a serious overﬁtting problem. Therefore,
Hybrid is localized to much higher precision but
substantially lower recall.

Overﬁtting results in enlargement of the gap be-
tween precision and recall when the task changes
to be more difﬁcult. For Hybrid, as illustrated in

MSEP-EMD                      Joint                              DM-CNN                      DM-CNN*                                   Hybrid                          Bi-RNN                            SELF 

P

R

P

R

P

R

P

R

gap=12.7% 

gap=10.1% 

85

80

75

70

65

60

gap=5.8%

%
4
.
5
=
p
a
g

 

%
9
.
1
1
=
p
a
g

 

%
4
.
1
1
=
p
a
g

85

80

75

70

65

60

85

80

75

70

65

60

 

%
2
1
=
p
a
g

(Bi-LSTM+CNN) 
R

P

(GRU) 
R

P

(Bi-LSTM+GAN) 
R

P

 

85

80

75

70

65

60

 

%
7
.
9
=
p
a
g

 

%
3
.
9
=
p
a
g

 

%
7
.
9
1
=
p
a
g

 

%
7
=
p
a
g

 

%
7
=
p
a
g

85

80

75

70

65

60

 

%
5
.
3
=
p
a
g

%
4
.
3
=
p
a
g

85

80

75

70

65

60

Trigger 

Trigger+
Type 

Trigger 

Trigger+
Type 

Trigger 

Trigger+
Type 

Trigger 

Trigger+
Type 

Trigger 

Trigger+
Type 

Trigger 

Trigger+
Type 

Trigger 

 

Trigger+
Type 

Min-supervision 

Feature engineering 

CNN-based 

Hybrid networks 

RNN-based 

85

80

75

70

65

60

 
 

Figure 2: Gaps between precision and recall in the tasks of trigger identiﬁcation and event classiﬁcation

Training Data
ACE+FN
ACE+FN
ACE+Wiki

Embedding Types
word
word, NE-type

Methods
ANNs
ANN-S2
DM-CNN∗ word, PSN
CNN
NC-CNN
Bi-RNN
Hybrid
DM-CNN
FB-RNN
SELF

word, NE-type, PSN ACE
word, NE-type, PSN ACE
word, NE-type, DEP ACE
word, NE-type, PSN ACE
ACE
word, PSN
ACE
word, branch
ACE
word, NE-type

Table 3: Embedding types and training data (DEP:
Dependency grammar; PSN: Position)

Figure 2, the gap becomes much wider (from 9%
to 19.7%) when the binary classiﬁcation task (trig-
ger identiﬁcation) is shifted to multi-class classiﬁ-
cation (event detection). By contrast, other work
shows a nearly constant gap. In particular, SELF
yields a minimum gap in each task, which changes
negligibly from 3.5% to 3.4%.

It may be added that, similar to DM-CNN and
FB-RNN, SELF is cost-effective. Compared to
other models (Table 3), it either uses less training
data, or is only required to learn two kinds of em-
beddings, such as that of words and entity types.

5.5 Discussion: Adaptation, Robustness and

Effectiveness

Domain adaptation is a key criteria for evaluating
the utility of a model in practical application. A
model can be thought of being adaptable only if it
works well for the unlabeled data in the target do-
main when trained on the source domain (Blitzer
et al., 2006; Plank and Moschitti, 2013).

We perform two groups of domain adaptation
experiments, respectively, using the ACE 2005
corpus and the corpus for TAC-KBP 2015 event
nugget track (Ellis et al., 2015).

The ACE corpus consists of 6 domains: broad-

cast conversation (bc), broadcast news (bn), tele-
phone conversation (cts), newswire (nw), usenet
(un) and web blogs (wl). Following the com-
mon practice of adaptation research on this data
(Nguyen and Grishman, 2014, 2015; Plank and
Moschitti, 2013), we take the union of bn and nw
as the source domain and bc, cts and wl as three
different target domains. We randomly select half
of the instances from bc to constitute the develop-
ment set. The TAC-KBP corpus consists of 2 do-
mains: newswire (NW) and discussion forum (DF).
We follow Peng et al (2016) to use one of NW and
DF in alternation as the source domain, while the
other the target domain. We randomly select a pro-
portion (20%) of the instances from the target do-
main to constitute the development set.

We compare with Joint, CNN, MSEP-EMD,
SSED (Sammons et al., 2015) and Hybrid. All
the models except Hybrid have been reported for
the performance assessment of domain adaptation.
In this section, we only cite the best performance
they obtained. We reproduce Hybrid by using the
source code given by authors. To ensure a fair
comparison, we perform 3 runs, in each of which,
both Hybrid and SELF were redeveloped on a new
development set. What we report herein is the av-
erage performance they obtained over the 3 runs.

Adaptation Performance

We show the adaptation performance on the ACE
corpus in Tables 4 and that on TAC-KBP in Table
5. It can be observed that SELF outperforms other
models in the out-of-domain scenarios.

Besides, when testing is performed on the out-
of-domain ACE corpus, the performance degrada-
tion of SELF is not much larger than that of CNN
and Hybrid. When the out-of-domain TAC-KBP
corpus is used, the performance of SELF is im-
paired much less severely than SSED and Hybrid.

Methods

Joint
CNN
Hybrid
SELF

In-domain (bn+nw)
P(%) R(%) F(%)

72.9
69.2
68.8
73.8

63.2
67.0
54.8
65.7

67.7
68.0
61.0
69.5

Out-of-domain (bc)
P(%) R(%) F(%) Loss
↓5.1
↓0.4
↑0.6
↓0.6

57.5
65.2
58.8
67.2

68.8
70.2
64.7
70.0

62.6
67.6
61.6
68.9

Out-of-domain (cts)
P(%) R(%) F(%) Loss
↓10.0
↓5.2
↓6.1
↓6.2

64.5
68.3
59.9
68.3

52.3
58.2
50.6
60.2

57.7
62.8
54.9
63.3

Out-of-domain (wl)
P(%) R(%) F(%) Loss
↓22.0
↓20.5
↓16.5
↓19.5

56.4
54.8
54.0
58.0

38.5
42.0
37.9
44.0

45.7
47.5
44.5
50.0

Table 4: Experimental results of domain adaptation on the ACE 2005 corpus

Methods

In-domain (NW)
P(%) R(%) F(%)

MSEP-EMD NA
NA
72.6
67.6

SSED
Hybrid
SELF

NA
NA
55.4
60.6

Out-of-domain (DF)
P(%) R(%) F(%) Loss
↓5.7
NA
↓11.4 NA
↓14.8 66.0
↓7.2
70.5

52.8
52.3
48.1
56.7

NA
NA
39.2
58.7

58.5 NA
63.7 NA
62.3
62.9
69.0
63.9

In-domain (DF)
P(%) R(%) F(%)

NA
NA
42.6
48.3

57.9
62.6
51.8
57.3

Out-of-domain (NW)
P(%) R(%) F(%) Loss
↓2.8
↓7.8
↑1.5
↑1.9

NA
NA
59.1
69.3

NA
NA
48.4
51.7

55.1
54.8
53.3
59.2

Table 5: Experimental results of domain adaptation on the TAC-KBP 2015 corpus (NA: not released)

More importantly, the adaptability of SELF is
relatively close to that of MSEP-EMD. Consider-
ing that MSEP-EMD is stable due to using mini-
mal supervision (Peng et al., 2016), we suggest the
fully trained networks in SELF may not appear to
be extremely inﬂexible, but on the contrary, they
should be transferable for use (Ge et al., 2016).

Robustness in Resource-Poor Settings

There are two resource-poor conditions discussed
in this section, including lack of in-domain train-
ing data and that of out-domain. Hybrid and SELF
are brought into the discussion.

For the former (in-domain) case, we went over
the numbers of samples used for training in the
adaptation experiments, which are shown in Ta-
ble 6. It can be observed that there is a minimum
number of training samples (triggers plus tokens)
contained in the domain of NW. By contrast, the
domain of bn+nw contains the smallest number of
positive samples (triggers) though an overwhelm-
ing number of negative samples (general tokens).
Under such conditions, Hybrid performs better
in the domain of NW compared to bn+nw and DF
in the three in-domain adaptation experiments (see
the column labelled as “In-domain bn+nw” in Ta-
ble 4 as well as “In-domain NW” and “In-domain
DF” in Table 5). It illustrates that Hybrid unnec-
essarily relies on a tremendous number of training
samples to ensure the robustness. But SELF does.
It needs far more negative samples than Hybrid be-
cause of the following reasons:

• It relies on the use of spurious features to im-

plement self-regulation during training.

Domain

bn+nw
NW
DF

Training

Testing

trigger
1,721
2,098
4,106

token
74,179
31,014
10,9275

trigger
343
2,813
1,773

token
16,336
55,459
43,877

Table 6: Data distribution in the source domains

• For a positive sample, the concerned spurious
features (if have) most probably hide in some
negative samples.

• It’s impossible to be aware of such negative
samples. Therefore, taking into consideration
as many negative samples as possible may
help to increase the probability that the spu-
rious features will be discovered.

This is demonstrated by the fact that SELF ob-
tains better performance in the domain of bn+nw
but not NW (see the column labeled as “Training”
in Table 6 and “In-domain” in Table 4 and 5). It
may be added that SELF performs worse in DF al-
though there are more negative samples used for
training (see Table 6). Taking a glance at the num-
ber of positive samples, one may ﬁnd that it is ap-
proximately 2.4 times more than that in bn+nw.
But the number of negative samples in DF is only
1.5 times more than that in bn+nw. It implies that,
if there are more positive samples used for train-
ing, SELF needs to consume proportionally more
negative samples for self-regulation. Otherwise,
the performance will degrade.

For the out-domain case, ideally, both Hybrid
and SELF encounter the problem that there is lack
of target domain data available for training. In this
case, SELF displays less performance degradation

Event mentions
And it still does
We had no part in it
Nobody questions if this is right or ...
And that is what ha- what is happening
Oh, yeah, it wasn’t perfect

Type
Die
Arrest-Jail
Attack
End-Position
Marry

Table 7: Examples of pronouns that act as a trigger

(7.2%) than Hybrid (14.8%) when NW is used for
training. Considering that NW contains the mini-
mum number of samples, we would like to believe
that SELF is more robust than Hybrid for cross-
domain event detection in a resource-poor setting.

Recall and Missing

SELF is able to accurately recall the events whose
occurrence is triggered by ambiguous words, such
as “ﬁne”, “charge”, “campaign”, etc. These am-
biguous words easily causes confusion. For exam-
ple, “campaign” may trigger an Elect event or
Attack in the ACE corpus.

More importantly, SELF ﬁshes out the common
words which serve as a trigger, although they are
not closely related to any kind of events, such as
“take”, “try”, “acquire”, “become”, “create”, etc.
In general, it is very difﬁcult to accurately recall
such triggers because their meanings are not con-
crete enough, and the contexts may be full of kinds
of noises (see example 2 in pg. 1). We observe that
Bi-RNN and Hybrid seldom pick them up.

However, SELF fails to recall the pronouns that
act as a trigger. This is because they occur in spo-
ken language much more frequently than they oc-
cur in written language. The lack of narrative con-
tent makes it difﬁcult to learn the relationship be-
tween the pronouns and the events. Some real ex-
amples collected from ACE are shown in Table 7.

6 Related Work

Event detection is an important subtask of event
extraction (Doddington et al., 2004; Ahn, 2006).

The research can be traced back to the pattern
based approach (Grishman et al., 2005). Encour-
aged by the high accuracy and the beneﬁt of easy-
to-use, researchers have made great efforts to ex-
tract discriminative patterns. Cao et al (2015a;
2015b) use dependency regularization and active
leaning to generalize and expand the patterns.

In the earlier study, another trend is to explore
the features that best characterize each event class,
so as to facilitate supervised classiﬁcation. A vari-

ety of strategies have emerged for converting clas-
siﬁcation clues into feature vectors (Ahn, 2006;
Patwardhan and Riloff, 2009; Liao and Grishman,
2010; Hong et al., 2011; Li et al., 2013, 2014; Wei
et al., 2017). Beneﬁting from the general model-
ing framework, the methods enable the fusion of
multiple features, and more importantly, they are
ﬂexible to use by feature selection. But consider-
able expertise is required for feature engineering.
Recently, the use of neural networks for event
detection has become a promising line of research.
The closely related work has been presented in
section 5.3. The primary advantages of neural net-
works have been demonstrated in the work, such
as performance enhancement, self-learning capa-
bility and robustness.

The generative adversarial network (Goodfel-
low et al., 2014) has emerged as an increasingly
popular approach for text processing (Zhang et al.,
2016; Lamb et al., 2016; Yu et al., 2017). Liu et
al (2017a) use the adversarial multi-task learning
for text classiﬁcation. We follow the work to cre-
ate spurious features, but use them to regulate the
self-learning process in a single-task situation.

7 Conclusion

We use a self-regulated learning approach to im-
prove event detection. In the learning process, the
adversarial and cooperative models are utilized in
decontaminating the latent feature space.

In this study, the performance of the discrimi-
nator in the adversarial network is left to be evalu-
ated. Most probably, the discriminator also per-
forms well because it is gradually enhanced by
ﬁerce competition. Considering this possibility,
we suggest to drive the two discriminators in our
self-regulation framework to cooperate with each
other. Besides, the global features extracted in Li
et al (2013)’s work are potentially useful for de-
tecting the event instances referred by pronouns,
although involve noises. Therefore, in the future,
we will encode the global information by neural
networks and use the self-regulation strategy to re-
duce the negative inﬂuence of noises.

Acknowledgments

We thank Xiaocheng Feng and his colleagues who
shared the source code of Hybrid with us.

This work was supported by the national Natu-
ral Science Foundation of China (NSFC) via Grant
Nos. 61525205, 61751206, 61672368.

References

David Ahn. 2006. The stages of event extraction.
In Proceedings of
the Workshop on Annotating
and Reasoning about Time and Events, Associa-
tion for Computational Linguistics (ACL’06). As-
sociation for Computational Linguistics, pages 1–8.
http://www.aclweb.org/anthology/W06-0901.

John Blitzer, Ryan McDonald, and Fernando Pereira.
Domain adaptation with structural cor-
2006.
respondence learning.
the
2006 conference on Empirical Methods in Natu-
ral Language Processing (EMNLP’06). Associa-
tion for Computational Linguistics, pages 120–128.
http://www.aclweb.org/anthology/W06-1615.

In Proceedings of

Konstantinos Bousmalis, George Trigeorgis, Nathan
Silberman, Dilip Krishnan, and Dumitru Erhan.
2016. Domain separation networks. In Advances in
Neural Information Processing Systems. pages 343–
351.

Kai Cao, Xiang Li, Miao Fan, and Ralph Grish-
Improving event detection with
man. 2015a.
active learning.
the Inter-
national Conference Recent Advances in Natural
Language Processing (RANLP’15). pages 72–77.
http://www.aclweb.org/anthology/R15-1010.

In Proceedings of

Kai Cao, Xiang Li, and Ralph Grishman. 2015b.
Improving event detection with dependency reg-
ularization.
the Interna-
In Proceedings of
tional Conference Recent Advances in Natural
Language Processing (RANLP’15). pages 78–83.
http://www.aclweb.org/anthology/R15-1011.

Yubo Chen, Shulin Liu, Xiang Zhang, Kang Liu, and
Jun Zhao. 2017. Automatically labeled data gener-
ation for large scale event extraction.
In Proceed-
ings of the 55th Annual Meeting of the Association
for Computational Linguistics (ACL’17). volume 1,
https://doi.org/10.18653/v1/P17-
pages 409–419.
1038.

Yubo Chen, Liheng Xu, Kang Liu, Daojian Zeng, Jun
Zhao, et al. 2015. Event extraction via dynamic
In
multi-pooling convolutional neural networks.
Proceedings of the 53th Annual Meeting of the As-
sociation for Computational Linguistics (ACL’15).
pages 167–176.
https://doi.org/10.3115/v1/P15-
1017.

Junyoung Chung, Caglar Gulcehre, KyungHyun Cho,
and Yoshua Bengio. 2014. Empirical evaluation of
gated recurrent neural networks on sequence model-
ing. arXiv preprint arXiv:1412.3555 .

George R Doddington, Alexis Mitchell, Mark A Przy-
bocki, Lance A Ramshaw, Stephanie Strassel, and
Ralph M Weischedel. 2004. The automatic con-
tent extraction (ACE) program-tasks, data, and
evaluation.
In LREC. volume 2, pages 1–4.
http://www.aclweb.org/anthology/L04-1011.

Joe Ellis, Jeremy Getman, Dana Fore, Neil Kuster,
Zhiyi Song, Ann Bies, and Stephanie Strassel. 2015.
Overview of linguistic resources for the tac kbp 2015
evaluations: Methodologies and results. In Proceed-
ings of TAC KBP 2015 Workshop, National Institute
of Standards and Technology (TAC’15). pages 16–
17.

Xiaocheng Feng, Lifu Huang, Duyu Tang, Heng Ji,
Bing Qin, and Ting Liu. 2016.
A language-
independent neural network for event detec-
tion.
the 54th Annual
the Association for Computational
Meeting of
Linguistics (ACL’16). volume 2, pages 66–71.
https://doi.org/10.18653/v1/P16-2011.

In Proceedings of

Tao Ge, Lei Cui, Baobao Chang, Zhifang Sui, and
Ming Zhou. 2016. Event detection with burst infor-
mation networks. In Proceedings of COLING 2016,
the 26th International Conference on Computational
Linguistics: Technical Papers. pages 3276–3286.

Reza Ghaeini, Xiaoli Fern, Liang Huang,

and
Prasad Tadepalli. 2016.
Event nugget detec-
tion with forward-backward recurrent neural net-
In Proceedings of the 54th Annual Meet-
works.
the Association for Computational Lin-
ing of
guistics (ACL’16). volume 2, pages 369–373.
https://doi.org/10.18653/v1/P16-2060.

Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,
Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. 2014. Generative ad-
versarial nets.
In Advances in neural information
processing systems. pages 2672–2680.

Ralph Grishman, David Westbrook, and Adam Meyers.
2005. Nyu’s English ACE 2005 system description.
ACE’05 .

Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky,
Ilya Sutskever, and Ruslan R Salakhutdinov. 2012.
Improving neural networks by preventing co-
adaptation of feature detectors.
arXiv preprint
arXiv:1207.0580 .

Yu Hong, Di Lu, Dian Yu, Xiaoman Pan, Xiaobin
Wang, Yadong Chen, Lifu Huang, and Heng Ji.
2015. RPI BLENDER TAC-KBP2015 system de-
scription.
In Proceedings of Text Analysis Confer-
ence (TAC’15).

Ronan Collobert and Jason Weston. 2008. A uniﬁed
architecture for natural language processing: Deep
In Pro-
neural networks with multitask learning.
ceedings of the 25th international conference on
Machine learning (ICML’08). ACM, pages 160–
167.

Yu Hong, Xiaobin Wang, Yadong Chen, Jian Wang,
Tongtao Zhang, Jin Zheng, Dian Yu, Qi Li, Boliang
Zhang, Han Wang, et al. 2014. RPI BLENDER
TAC-KBP2014 knowledge base population sys-
tem.
In Proceedings of Text Analysis Conference
(TAC’14).

Yu Hong, Jianfeng Zhang, Bin Ma, Jianmin Yao,
Guodong Zhou, and Qiaoming Zhu. 2011. Using
cross-entity inference to improve event extraction.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies (ACL-HLT’11). Association
for Computational Linguistics, pages 1127–1136.
http://www.aclweb.org/anthology/P11-1113.

Xun Huang, Yixuan Li, Omid Poursaeed,

John
Hopcroft, and Serge Belongie. 2017. Stacked gener-
ative adversarial networks. In IEEE Conference on
Computer Vision and Pattern Recognition (CVPR).
volume 2, page 4.

Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidi-
rectional LSTM-CRF models for sequence tagging.
arXiv preprint arXiv:1508.01991 .

Md M Islam, Xin Yao, and Kazuyuki Murase. 2003. A
constructive algorithm for training cooperative neu-
ral network ensembles. IEEE Transactions on neu-
ral networks 14(4):820–834.

Rafal

Jozefowicz, Wojciech Zaremba,

and Ilya
Sutskever. 2015. An empirical exploration of recur-
rent network architectures.
In Proceedings of the
32nd International Conference on Machine Learn-
ing (ICML’15). pages 2342–2350.

Alex M Lamb, Anirudh Goyal ALIAS PARTH
GOYAL, Ying Zhang, Saizheng Zhang, Aaron C
Courville, and Yoshua Bengio. 2016.
Professor
forcing: A new algorithm for training recurrent net-
works. In Advances In Neural Information Process-
ing Systems. pages 4601–4609.

Qi Li, Heng Ji, and Liang Huang. 2013.

Joint
event extraction via structured prediction with
the 51th
global
the Association for Com-
Annual Meeting of
putational Linguistics
(ACL’13). pages 73–82.
http://www.aclweb.org/anthology/P13-1008.

In Proceedings of

features.

Qi Li, Heng Ji, HONG Yu, and Sujian Li. 2014.
Constructing information networks using one sin-
gle model.
the 2014 Con-
In Proceedings of
ference on Empirical Methods in Natural Lan-
guage Processing (EMNLP’14). pages 1846–1851.
https://doi.org/10.3115/v1/D14-1198.

Shasha Liao and Ralph Grishman. 2010.

Us-
ing document level cross-event inference to im-
prove event extraction.
the
the Association for
48th Annual Meeting of
Computational Linguistics (ACL’10). Association
for Computational Linguistics, pages 789–797.
http://www.aclweb.org/anthology/P10-1081.

In Proceedings of

Zhouhan Lin, Minwei Feng, Cicero Nogueira dos San-
tos, Mo Yu, Bing Xiang, Bowen Zhou, and Yoshua
Bengio. 2017. A structured self-attentive sentence
embedding. arXiv preprint arXiv:1703.03130 .

Ming-Yu Liu and Oncel Tuzel. 2016. Coupled gener-
In Advances in neural

ative adversarial networks.
information processing systems. pages 469–477.

Pengfei Liu, Xipeng Qiu, Jifan Chen, and Xuanjing
Huang. 2016a. Deep fusion LSTMs for text se-
mantic matching.
In Proceedings of the 54th An-
nual Meeting of the Association for Computational
Linguistics (ACL’16). volume 1, pages 1034–1043.
https://doi.org/10.18653/v1/P16-1098.

Pengfei Liu, Xipeng Qiu, and Xuanjing Huang.
2017a. Adversarial multi-task learning for text
classiﬁcation.
arXiv preprint arXiv:1704.05742
https://doi.org/10.18653/v1/P17-1001.

Shulin Liu, Yubo Chen, Shizhu He, Kang Liu, and
Jun Zhao. 2016b.
to im-
prove automatic event detection.
In Proceed-
the Asso-
the 54th Annual Meeting of
ings of
ciation for Computational Linguistics (ACL’16).
https://doi.org/10.18653/v1/P16-1201.

Leveraging framenet

Shulin Liu, Yubo Chen, Kang Liu, and Jun Zhao.
2017b. Exploiting argument information to improve
event detection via supervised attention mechanisms
1:1789–1797.
https://doi.org/10.18653/v1/P17-
1164.

Linguistic regularities

Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013.
in continuous
space word representations.
In Proceedings
of
the 2013 Conference of
the North Ameri-
the Association for Computa-
can Chapter of
tional Linguistics: Human Language Technolo-
gies (NAACL’13). volume 13, pages 746–751.
http://www.aclweb.org/anthology/N13-1090.

Thien Huu Nguyen, Kyunghyun Cho, and Ralph Gr-
ishman. 2016. Joint event extraction via recurrent
neural networks. In Proceedings of the 2016 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies (NAACL’16). pages 300–309.
https://doi.org/10.18653/v1/N16-1034.

Thien Huu Nguyen and Ralph Grishman. 2014. Em-
ploying word representations and regularization for
domain adaptation of relation extraction.
In Pro-
ceedings of the 52th Annual Meeting of the Associa-
tion for Computational Linguistics (ACL’14). pages
68–74. https://doi.org/10.3115/v1/P14-2012.

Thien Huu Nguyen and Ralph Grishman. 2015. Event
detection and domain adaptation with convolu-
tional neural networks.
the
53th Annual Meeting of the Association for Com-
putational Linguistics (ACL’15). pages 365–371.
https://doi.org/10.3115/v1/P15-2060.

In Proceedings of

Thien Huu Nguyen and Ralph Grishman. 2016. Mod-
eling skip-grams for event detection with convo-
lutional neural networks.
In Proceedings of the
2016 Conference on Empirical Methods in Natural
Language Processing (EMNLP’16). pages 886–891.
https://doi.org/10.18653/v1/D16-1085.

Siddharth Patwardhan and Ellen Riloff. 2009. A
uniﬁed model of phrasal and sentential evidence

for information extraction.
In Proceedings of the
2009 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP’09). Associa-
tion for Computational Linguistics, pages 151–160.
http://www.aclweb.org/anthology/D09-1016.

Lantao Yu, Weinan Zhang, Jun Wang, and Yong Yu.
Seqgan: Sequence generative adversarial
2017.
nets with policy gradient.
In Proceedings of the
32nd AAAI Conference on Artiﬁcial Intelligence
(AAAI’17). pages 2852–2858.

Haoruo Peng, Yangqiu Song, and Dan Roth. 2016.
Event detection and co-reference with minimal
supervision.
the 2016 Con-
In Proceedings of
ference on Empirical Methods in Natural Lan-
guage Processing (EMNLP’16). pages 392–402.
https://doi.org/10.18653/v1/D16-1038.

Matthew D Zeiler. 2012. Adadelta: an adaptive learn-
ing rate method. arXiv preprint arXiv:1212.5701 .

Yizhe Zhang, Zhe Gan, and Lawrence Carin. 2016.
In NIPS

Generating text via adversarial training.
workshop on Adversarial Training. volume 21.

Barbara Plank and Alessandro Moschitti. 2013. Em-
bedding semantic similarity in tree kernels for do-
main adaptation of relation extraction. In Proceed-
ings of the 51th Annual Meeting of the Associa-
tion for Computational Linguistics (ACL’13). pages
1498–1507. http://www.aclweb.org/anthology/P13-
1147.

Mark Sammons, Haoruo Peng, Yangqiu Song, Shyam
Upadhyay, Chen-Tse Tsai, Pavankumar Reddy,
Subhro Roy, and Dan Roth. 2015. Illinois CCG TAC
2015 event nugget, entity discovery and linking, and
slot ﬁller validation systems. In Proceedings of Text
Analytics Conference (TAC’15).

Mike Schuster and Kuldip K Paliwal. 1997. Bidirec-
tional recurrent neural networks. IEEE Transactions
on Signal Processing 45(11):2673–2681.

Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.
Sequence to sequence learning with neural net-
works. In Advances in neural information process-
ing systems. pages 3104–3112.

Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.
Word representations: a simple and general method
for semi-supervised learning.
In Proceedings of
the 48th Annual Meeting of the Association for
Computational Linguistics
(ACL’10). Associa-
tion for Computational Linguistics, pages 384–394.
https://doi.org/http://www.aclweb.org/anthology/P10-
1040.

Mengqiu Wang and Christopher D Manning. 2013.
Effect of non-linear deep architecture in se-
quence labeling.
the Sixth
International Joint Conference on Natural Lan-
guage Processing (IJCNLP’13). pages 1285–1291.
https://doi.org/http://www.aclweb.org/anthology/I13-
1183.

In Proceedings of

Sam Wei,

Igor Korostil, Joel Nothman, and Ben
Hachey. 2017. English event detection with trans-
lated language features. In Proceedings of the 55th
Annual Meeting of the Association for Computa-
tional Linguistics (ACL’17). volume 2, pages 293–
298. https://doi.org/10.18653/v1/P17-2046.

Dian Yu, Xiaoman Pan, Boliang Zhang, Lifu Huang,
Di Lu, Spencer Whitehead, and Heng Ji. 2016. RPI
BLENDER TAC-KBP2016 system description.
In
Proceedings of Text Analysis Conference (TAC’16).

Self-regulation: Employing a Generative Adversarial Network to Improve
Event Detection

Yu Hong Wenxuan Zhou Jingli Zhang Qiaoming Zhu Guodong Zhou∗
Institute of Artiﬁcial Intelligence, Soochow University
School of Computer Science and Technology, Soochow University
No.1, Shizi ST, Suzhou, China, 215006
{tianxianer, wxchow024, jlzhang05}@gmail.com
{qmzhu, gdzhou}@suda.edu.cn

Abstract

Due to the ability of encoding and map-
ping semantic information into a high-
dimensional latent feature space, neural
networks have been successfully used for
detecting events to a certain extent. How-
ever, such a feature space can be easily
contaminated by spurious features inher-
ent in event detection.
In this paper, we
propose a self-regulated learning approach
by utilizing a generative adversarial net-
work to generate spurious features. On the
basis, we employ a recurrent network to
eliminate the fakes. Detailed experiments
on the ACE 2005 and TAC-KBP 2015 cor-
pora show that our proposed method is
highly effective and adaptable.

1

Introduction

Event detection aims to locate the event triggers
of speciﬁed types in text. Normally, triggers are
words or nuggets that evoke the events of interest.
Detecting events in an automatic way is chal-
lenging, not only because an event can be ex-
pressed in different words, but also because a word
may express a variety of events in different con-
texts. In particular, the frequent utilization of com-
mon words, ambiguous words and pronouns in
event mentions makes them harder to detect:

1) Generality – taken home <Transport>

Ambiguity 1 – campaign in Iraq <Attack>
Ambiguity 2 – political campaign <Elect>
Coreference – Either its bad or good <Marry>

A promising solution to this challenge is
through semantic understanding. Recently, neu-
ral networks have been widely used in this direc-
tion (Nguyen and Grishman, 2016; Ghaeini et al.,

∗ Corresponding author

2016; Feng et al., 2016; Liu et al., 2017b; Chen
et al., 2017), which allows semantics of event
mentions (trigger plus context) to be encoded in
a high-dimensional latent feature space. This fa-
cilitates the learning of deep-level semantics. Be-
sides, the use of neural networks not only strength-
ens current supervised classiﬁcation of events but
alleviates the complexity of feature engineering.

However, compared to the earlier study (Liao
and Grishman, 2010; Hong et al., 2011; Li et al.,
2013), in which the features are carefully designed
by experts, the neural network based methods suf-
fer more from spurious features. Here, spurious
feature is speciﬁed as the latent information which
looks like the semantically related information to
an event, but actually not (Liu et al., 2017a). For
example, in the following sample, the semantic
information of the word “prison” most probably
enables spurious features to come into being, be-
cause the word often co-occurs with the trigger
”taken” to evoke an Arrest-jail event instead
of the ground-truth event Transport:

2) Prison authorities have given the nod for An-
war to be taken home later in the afternoon.
Trigger: taken. Event Type: Transport

It is certain that spurious features often result
from the semantically pseudo-related context, and
during training, a neural network may mistakenly
and unconsciously preserve the memory to pro-
duce the fakes. However, it is difﬁcult to deter-
mine which words are pseudo-related in a speciﬁc
case, and when they will “jump out” to mislead the
generation of latent features during testing.

To address the challenge, we suggest to regu-
late the learning process with a two-channel self-
regulated learning strategy. In the self-regulation
process, on one hand, a generative adversarial net-
work is trained to produce the most spurious fea-
tures, while on the other hand, a neural network

(cid:28595)

(cid:28661)(cid:28660)(cid:28662)(cid:28670)(cid:28595)(cid:28675)(cid:28677)(cid:28674)(cid:28675)(cid:28660)(cid:28666)(cid:28660)(cid:28679)(cid:28668)(cid:28674)(cid:28673)(cid:28595)

(cid:22) 

(cid:7) 

(cid:28643)(cid:28677)(cid:28664)(cid:28663)(cid:28668)(cid:28662)(cid:28679)(cid:28668)(cid:28674)(cid:28673)(cid:28595)

(cid:1876) 

(cid:10) 

(cid:10)(cid:3545) 

(cid:7)(cid:3545) 

(cid:28661)(cid:28660)(cid:28662)(cid:28670)(cid:28595)(cid:28675)(cid:28677)(cid:28674)(cid:28675)(cid:28660)(cid:28666)(cid:28660)(cid:28679)(cid:28668)(cid:28674)(cid:28673)(cid:28595)

Figure 1: Self-regulated learning scheme

is equipped with a memory suppressor to elimi-
nate the fakes. Detailed experiments on event de-
tection show that our proposed method achieves
a substantial performance gain, and is capable of
robust domain adaptation.

2 Task Deﬁnition

The task of event detection is to determine whether
there is one or more event triggers in a sentence.
Trigger is deﬁned as a token or nugget that best
signals the occurrence of an event. If successfully
identiﬁed, a trigger is required to be assigned a tag
to indicate the event type:

Input: Either its bad or good
Output: its <trigger>; Marry <type>
We formalize the event detection problem as a
multi-class classiﬁcation problem. Given a sen-
tence, we classify every token of the sentence into
one of the predeﬁned event classes (Doddington
et al., 2004) or non-trigger class.

3 Self-Regulated Learning (SELF)

SELF is a double-channel model (Figure 1), con-
sisted of a cooperative network (Islam et al., 2003)
and a generative adversarial net (GAN) (Goodfel-
low et al., 2014). A memory suppressor S is used
to regulate communication between the channels.

3.1 Cooperative Network

In channel 1, the generator G is speciﬁed as a mul-
tilayer perceptron. It plays a role of a “diligent stu-
dent”. By a differentiable function G(x, θg) with
parameters θg, the generator learns to produce a
vector of latent features og that may best charac-
terize the token x, i.e., og = G(x, θg).

The discriminator D (called “a lucky profes-
sor”) is a single-layer perceptron, implemented as
a differentiable function D(og, θd) with parame-
ters θd. Relying on the feature vector og, it at-
tempts to accurately predict the probability of the
token x triggering an event for all event classes,
i.e., ˆy = D(og, θd), and assigns x to the most
probable class c (iff ˆyc > ∀ˆy¯c, ¯c (cid:3)= c).

Therefore, G and D cooperate with each other
during training, developing the parameters θg and
θd with the same goal – to minimize the perfor-
mance loss L(ˆy, y) in the detection task:

(cid:2)

(cid:3)

θg
θd

= argmin L(ˆy, y)

(1)

where, y denotes the ground-truth probability dis-
tribution over event classes, and L indicates the
deviation of the prediction from the ground truth.

3.2 Generative Adversarial Network
In channel 2, the generator ˇG and discriminator
ˇD have the same perceptual structures as G and
D. They also perform learning by differentiable
functions, respectively ˇG(x, θˇg) and ˇD(oˇg, θ ˇd
). A
major difference, however, is that they are caught
into a cycle of highly adversarial competition.

The generator ˇG is a “trouble maker”. It learns
to produce spurious features, and utilizes them to
contaminate the feature vector oˇg of the token x.
Thus ˇG changes a real sample x into a fake z –
sometimes successfully, sometimes less so. Using
the fakes, ˇG repeatedly instigates the discrimina-
tor ˇD to make mistakes. On the other side, ˇD (“a
hapless professor”) has to avoid being deceived,
and struggles to correctly detect events no matter
whether it encounters x or z.

In order to outsmart the adversary, ˇG develops
the parameters θˇg during training to maximize the
performance loss, but on the contrary, ˇD develops
the parameters θ ˇd to minimize the loss:

θˇg = argmax L(ˆy, y)
= argmin L(ˆy, y)
θ ˇd

(2)

(3)

Numerous studies have conﬁrmed that the two-
player minmax game enables both ˇG and ˇD to im-
prove their methods (Goodfellow et al., 2014; Liu
and Tuzel, 2016; Huang et al., 2017).

3.3 Regulation with Memory Suppressor

Using a memory suppressor, we try to optimize the
diligent student G. The goal is to enable G to be
as dissimilar as possible to the troublemaker ˇG.

The suppressor uses the output oˇg of ˇG as a ref-
erence resource which should be full of spurious
features. On the basis, it looks over the output og
of G, so as to verify whether the features in og
are different to those in oˇg. If very different, the
suppressor allows G to preserve the memory (viz.,
θg in G(x, θg)), otherwise update. In other word,

for G, the suppressor forcibly erases the memory
which may result in the generation of spurious fea-
tures. We call this the self-regulation.

Self-regulation is performed for the whole sen-
tence which is fed into G and ˇG. Assume that Og
is a matrix, constituted with a series of feature vec-
tors, i.e., the vectors generated by G for all the to-
kens in an input sentence (og ∈ Og), while Oˇg
is another feature matrix, generated by ˇG for the
tokens (oˇg ∈ Oˇg). Thus, we utilize the matrix ap-
proximation between Og and Oˇg for measuring the
loss of self-regulation learning Ldif f . The higher
the similarity, the greater the loss. During training,
the generator G is required to develop the param-
eters θg to minimize the loss:

θg = argmin Ldif f (og, oˇg)

(4)

We present in detail the matrix approximate cal-
culation in section 4.4, where the squared Frobe-
nius norm (Bousmalis et al., 2016) is used.

3.4 Learning to Predict

We incorporate the cooperative network with the
GAN, and enhance their learning by joint training.
In the 4-member incorporation, i.e., {G, ˇG, D
and ˇD}, the primary beneﬁciary is the lucky pro-
fessor D. It can beneﬁt from both the cooperation
in channel 1 and the competition in channel 2. The
latent features it uses are well-produced by G, and
decontaminated by eliminating possible fakes like
those made by ˇG. Therefore, in experiments, we
choose to output the prediction results of D.

In this paper, we use two recurrent neural net-
works (RNN) (Sutskever et al., 2014; Chung et al.,
2014) of the same structure as the generators. And
both the discriminators are implemented as a fully-
connected layer followed by a softmax layer.

4 Recurrent Models for SELF

RNN with long short-term memory (abbr., LSTM)
is adopted due to the superior performance in a va-
riety of NLP tasks (Liu et al., 2016a; Lin et al.,
2017; Liu et al., 2017a). Furthermore, the bidi-
rectional LSTM (Bi-LSTM) architecture (Schus-
ter and Paliwal, 1997; Ghaeini et al., 2016; Feng
et al., 2016) is strictly followed. This architecture
enables modeling of the semantics of a token with
both the preceding and following contexts.

4.1 LSTM based Generator

Given a sentence, we follow Chen et al (2015) to
take all the tokens of the whole sentence as the in-

put. Before feeding the tokens into the network,
we transform each of them into a real-valued vec-
tor x ∈ Re. The vector is formed by concatenating
a word embedding with an entity type embedding.

• Word Embedding: It is a ﬁxed-dimensional
real-valued vector which represents the hid-
den semantic properties of a token (Collobert
and Weston, 2008; Turian et al., 2010).

• Entity Type Embedding: It is specially used
to characterize the entity type associated with
a token. The BIO2 tagging scheme (Wang
and Manning, 2013; Huang et al., 2015) is
employed for assigning a type label to each
token in the sentence.

For the input token xt at the current time step t,
the LSTM generates the latent feature vector ot ∈
Rd by the previous memory. Meanwhile, the token
is used to update the current memory.

The LSTM possesses a long-term memory unit
ct ∈ Rd and short-term (cid:4)ct ∈ Rd. In addition, it
is equipped with the input gate it, forgetting gate
ft and a hidden state ht, which are assembled to-
gether to promote the use of memory, as well as
dynamic memory updating. Similarly, they are de-
ﬁned as a d-dimensional vector in Rd. Thus LSTM
works in the following way:

⎡

⎢
⎢
⎣

ot
(cid:4)ct
it
ft

⎤

⎥
⎥
⎦ =

⎡

⎢
⎢
⎣

⎤

⎥
⎥
⎦

σ
tanh
σ
σ

(cid:11)

(cid:2)

(cid:3)

(cid:12)

W

xt
ht−1

+ b

ht = ot (cid:5) tanh(ct)
ct = (cid:4)ct (cid:5) it + ct−1 (cid:5) ft

(5)

(6)

(7)

where W ∈ R4d×(d+e) and b ∈ R4d are parame-
ters of afﬁne transformation; σ refers to the logis-
tic sigmoid function and (cid:5) denotes element-wise
multiplication.

The output functions of both the generators in
SELF, i.e., G and ˇG, can be boiled down to the
output gate ot ∈ Rd of the LSTM cell:

ot = LST M (xt; θ)

(8)

where, the function LSTM (·;·) is a shorthand for
Eq. (5-7) and θ represents all the parameters of
LSTM. For both G and ˇG, θ are initialized with the
same values in experiments. But due to the distinct
training goals of G and ˇG (diligence or making-
trouble), the values of the parameters in the two

cases will change to be very different after train-
ing. Therefore, we have og,t = LST M (xt, θg,t)
and oˇg,t = LST M (xt, θˇg,t).

4.2 Fully-connected Layer for Discrimination

Depending on the feature vectors og,t and oˇg,t, the
two discriminators D and ˇD predict the probabil-
ity of the token xt triggering an event for all event
classes. As usual, they compute the probability
distribution over classes using a fully connected
layer followed by a softmax layer:

ˆy = sof tmax( ˆW · ot + ˆb)

(9)

where ˇy is a C-dimensional vector, in which each
dimension indicates the prediction for a class; C
is the class number; ˆW ∈ Rd is the weight which
needs to be learned; ˆb is a bias term.

It is noteworthy that the discriminator D and ˇD
don’t share the weight and the bias. It means that,
for the same token xt, they may make markedly
different predictions: ˆyg,t = sof tmax( ˆWg · og,t +
ˆbg) and ˆyˇg,t = sof tmax( ˆWˇg · oˇg,t + ˆbˇg).

4.3 Classiﬁcation Loss

We specify the loss as the cross-entropy between
the predicted and ground-truth probability distri-
butions over classes. Given a batch of training data
that includes N samples (xi, yi), we calculate the
losses the discriminators cause as below:

where, (cid:6) · (cid:6)2
F denotes the squared Frobenius norm
(Bousmalis et al., 2016), which is used to calculate
the similarity between matrices.

It is noteworthy that the feature vectors a gen-
erator outputs are required to serve as the rows in
the matrix, deployed in a top-down manner and
arranged in the order in which they are generated.
For example, the feature vector og,t the generator
G outputs at the time t needs to be placed in the
t-th row of the matrix Og.

At the very beginning of the measurement, the
similarity between every feature vector in Og and
that in O ˇG is ﬁrst calculated by the matrix-matrix
multiplication OgO(cid:3)
ˇg :

⎛

⎜
⎜
⎜
⎜
⎝

og,1o(cid:3)
ˇg,1
...
og,1o(cid:3)
ˇg,t
...
og,1o(cid:3)
ˇg,l

... og,1o(cid:3)
ˇg,t
...
...
... og,to(cid:3)
ˇg,t
...
...
og,lo(cid:3)
...
ˇg,t

...

... og,1o(cid:3)
ˇg,l
...
... og,to(cid:3)
ˇg,l
...
...

...
og,lo(cid:3)
ˇg,l

⎞

⎟
⎟
⎟
⎟
⎠

where, the symbol (cid:7) denotes the transpose opera-
tion; l is the sentence length which is deﬁned to be
uniform for all sentences (l=80), and if it is larger
than the real ones, padding is used; og,ioˇg,j de-
notes the scalar product between the feature vec-
tors og,i and oˇg,j.

Let Am×n be a matrix, the squared Frobenius

norm of Am×n (i.e., (cid:6)Am×n(cid:6)2

F ) is deﬁned as:

⎛

m(cid:13)

n(cid:13)

⎞

1
2

i=1

j=1

N(cid:13)

C(cid:13)

i=1
N(cid:13)

j=1
C(cid:13)

i=1

j=1

L(ˆyg, y) = −

i log(ˆyj
yj

g,i

)

(10)

(cid:6)Am×n(cid:6)2

F

⎝

=

|aij|2

⎠

(13)

L(ˆyˇg, y) = −

i log(ˆyj
yj
ˇg,i

)

(11)

where yi is a C-dimensional one-hot vector. The
value of its j-th dimension is set to be 1 only if the
token xi triggers an event of the j-th class, other-
wise 0. Both ˆyg,i and ˆyˇg,i are the predicted proba-
bility distributions over the C classes for xi.

4.4 Loss of Self-regulated Learning

Assume that Og is a matrix, consisted of the fea-
ture vectors output by G for all the tokens in a sen-
tence, i.e., og,t ∈ Og, and Oˇg is that provided by
ˇG, i.e., oˇg,t ∈ Oˇg, thus we compute the similarity
between Og and Oˇg and use it as the measure of
self-regulation loss Ldif f (Og, Oˇg):

where, aij denotes the j-th element in the i-th
row of Am×n. Thus, if we let Am×n be the ma-
trix produced by the matrix-matrix multiplication
OgO(cid:3)
ˇg , the self-regulation loss Ldif f (Og, Oˇg) can
be eventually obtained by:

Ldif f (Og, Oˇg) =

|og,ioˇg,j|2

(14)

⎛

⎝

l(cid:13)

l(cid:13)

i=1

j=1

1
2

⎞

⎠

For a batch of training data that includes N (cid:4)
sentences, the global self-regulation loss is spec-
iﬁed as the sum of the losses for all the sentences:
LSELF =

N (cid:3)
i=1 Ldif f (Og, Oˇg).

(cid:20)

4.5 Training

Ldif f (Og, Oˇg) = (cid:6)OgO(cid:3)
ˇg

(cid:6)2

F

(12)

We train the cooperative network in SELF to min-
imize the classiﬁcation loss L(ˆyg, y) and the loss

of self-regulated learning LSELF :

θg = argmin (Lˆyg, y)
θd = argmin (L(ˆyg, y) + λ · LSELF )

(15)

(16)

where λ is a hyper-parameter, which is used to har-
monize the two losses.

The min-max game is utilized for training the
adversarial net in SELF: θˇg = argmax L(ˆyˇg, y);
θ ˇd

= argmin L(ˆyˇg, y).
All the networks in SELF are trained jointly us-
ing the same batches of samples. They are trained
via stochastic gradient descent (Nguyen and Gr-
ishman, 2015) with shufﬂed mini-batches and the
AdaDelta update rule (Zeiler, 2012). The gradi-
ents are computed using back propagation. And
regularization is implemented by a dropout (Hin-
ton et al., 2012).

5 Experimentation

5.1 Resource and Experimental Datasets

We test the presented model on the ACE 2005 cor-
pus. The corpus is annotated with single-token
event triggers and has 33 predeﬁned event types
(Doddington et al., 2004; Ahn, 2006), along with
one class “None” for the non-trigger tokens, con-
stitutes a 34-class classiﬁcation problem.

For comparison purpose, we use the corpus in
the traditional way, randomly selecting 30 articles
in English from different genres as the develop-
ment set, and utilizing a separate set of 40 English
newswire articles as the test set. The remaining
529 English articles are used as the training set.

5.2 Hyperparameter Settings

The word embeddings are initialized with the 300-
dimensional real-valued vectors. We follow Chen
et al (2015) and Feng et al (2016) to pre-train the
embeddings over NYT corpus using Mikolov et al
(2013)’s skip-gram tool. The entity type embed-
dings, as usual (Nguyen et al., 2016; Feng et al.,
2016; Liu et al., 2017b), are speciﬁed as the 50-
dimensional real-valued vectors. They are initial-
ized with the 32-bit ﬂoating-point values, which
are all randomly sampled from the uniformly dis-
tributed values in [-1, 1]1. We initialize other ad-
justable parameters of the back-propagation algo-
rithm by randomly sampling in [-0.1, 0.1].

We follow Feng et al (2016) to set the dropout
rate as 0.2 and the mini-batch size as 10. We
1https://www.tensorﬂow.org/api docs/python/tf/random

uniform

tune the initialized parameters mentioned above,
harmonic coefﬁcient λ, learning rate and the L2
norm on the development set. Grid search (Liu
et al., 2017a) is used to seek for the optimal pa-
rameters. Eventually, we take the coefﬁcient λ of
0.1+3, learning rate of 0.3 and L2 norm of 0.

The source code of SELF2 to reproduce the ex-

periments has been made publicly available.

5.3 Compared Systems

The state-of-the-art models proposed in the past
decade are compared with ours. By taking learn-
ing framework as the criterion, we divide the mod-
els into three classes:

Minimally supervised approach: is Peng et al

(2016)’s MSEP-EMD.

Feature based approaches: primarily includ-
ing Liao and Grishman (2010)’s Cross-Event in-
ference model, which is based on the max-entropy
classiﬁcation and embeds the document-level con-
ﬁdent information in the feature space; Hong et al
(2011)’s Cross-Entity inference model, in which
existential backgrounds of name entities are em-
ployed as the additional discriminant features; and
Li et al (2013)’s Joint model, a sophisticated pre-
dictor frequently ranked among the top 3 in re-
cent TAC-KBP evaluations for nugget and corefer-
ence detection (Hong et al., 2014, 2015; Yu et al.,
2016).
It is based on structured perceptron and
combines the local and global features.

Neural network based approaches: including
the convolutional neural network (CNN) (Nguyen
and Grishman, 2015),
the non-consecutive N-
grams based CNN (NC-CNN) (Nguyen and Gr-
ishman, 2016) and the CNN that is assembled with
a dynamic multi-pooling layer (DM-CNN) (Chen
et al., 2015). Others include Ghaeini et al (2016)’s
forward-backward recurrent neural network (FB-
RNN) which is developed using gated recurrent
units (GRU), Nguyen et al (2016)’s bidirectional
RNN (Bi-RNN) and Feng et al (2016)’s Hybrid
networks that consist of a Bi-LSTM and a CNN.

Besides, we compare our model with Liu et al
(2016b)’s artiﬁcial neural networks (ANNs), Liu
et al (2017b)’s attention-based ANN (ANN-S2)
and Chen et al (2017)’s DM-CNN∗. The models
recently have become popular because, although
simple in structure, they are very analytic by learn-
ing from richer event examples, such as those in

2https://github.com/JoeZhouWenxuan/Self-regulation-
Employing-a-Generative-Adversarial-Network-to-Improve-
Event-Detection/tree/master

P (%) R (%)
Method
76.9
Joint (Local+Global)
75.6
MSEP-EMD
80.4
DM-CNN
DM-CNN∗
79.7
Bi-RNN
68.5
Hybrid: Bi-LSTM+CNN 80.8
SELF: Bi-LSTM+GAN 75.3

65.0
69.8
67.7
69.6
75.7
71.5
78.8

F (%)
70.4
72.6
73.5
74.3
71.9
75.9
77.0

Table 1: Trigger identiﬁcation performance

FrameNet (FN) and Wikipeida (Wiki).

5.4 Experimental Results

We evaluate our model using Precision (P), Re-
call (R) and F-score (F). To facilitate the compar-
ison, we review the best performance of the com-
petitors, which has been evaluated using the same
metrics, and publicly reported earlier.

Trigger identiﬁcation

Table 1 shows the trigger identiﬁcation perfor-
mance. It can be observed that SELF outperforms
other models, with a performance gain of no less
than 1.1% F-score.

Frankly, the performance mainly beneﬁts from
the higher recall (78.8%). But in fact the relatively
comparable precision (75.3%) to the recall rein-
forces the advantages. By contrast, although most
of the compared models achieve much higher pre-
cision over SELF, they suffer greatly from the sub-
stantial gaps between precision and recall. The ad-
vantage is offset by the greater loss of recall.

GAN plays an important role in optimizing Bi-
RNN. This is proven by the fact that SELF (Bi-
LSTM+GAN) outperforms Nguyen et al (2016)’s
Bi-RNN. To be honest, the models use two differ-
ent kinds of recurrent units. Bi-RNN uses GRUs,
but SELF uses the units that possess LSTM. Nev-
ertheless, GRU has been experimentally proven to
be comparable in performance to LSTM (Chung
et al., 2014; Jozefowicz et al., 2015). This allows
a fair comparison between Bi-RNN and SELF.

Event classiﬁcation

Table 2 shows the performance of multi-class clas-
siﬁcation. SELF achieves nearly the same F-score
as Feng et al (2016)’s Hybrid, and outperforms the
others. More importantly, SELF is the only one
which obtains a performance higher than 70% for
both precision and recall.

Besides, by analyzing the experimental results,

we have identiﬁed the following regularities:

P (%) R (%)
Methods
70.4
MSEP-EMD
68.8
Cross-Event
72.9
Cross-Entity
73.7
Joint (Local+Global)
71.8
CNN
75.6
DM-CNN
-
NC-CNN
66.8
FB-RNN (GRU)
66.0
Bi-RNN (GRU)
77.6
ANNs (ACE+FN)
DM-CNN∗(ACE+Wiki)
75.7
ANN-S2 (ACE+FN)
76.8
Hybrid: Bi-LSTM+CNN 84.6
71.3
SELF: Bi-LSTM+GAN

65.0
68.9
64.3
62.3
66.4
63.6
-
68.0
73.0
65.2
66.0
67.5
64.9
74.7

F (%)
67.6
68.8
68.3
67.5
69.0
69.1
71.3
67.4
69.3
70.7
70.5
71.9
73.4
73.0

Table 2: Detection performance (trigger identiﬁ-
cation plus multi-class classiﬁcation)

• Similar to the pattern classiﬁers that are based
on hand-designed features, the CNN models
enable higher precision to be obtained. How-
ever the recall is lower.

• The RNN models contribute to achieving a
higher recall. However the precision is lower.

• Expansion of the training data set helps to in-

crease the precision.

Let us turn to the structurally more complicated

models, SELF and Hybrid.

SELF inherits the merits of the RNN models,
classifying the events with higher recall. Besides,
by the utilization of GAN, SELF has evolved from
the traditional learning strategies, being capable of
learning from GAN and getting rid of the mistak-
enly generated spurious features. So that it outper-
forms other RNNs, with improvements of no less
than 4.5% precision and 1.7% recall.

Hybrid is elaborately established by assembling
a RNN with a CNN. It models an event from two
perspectives: language generation and pragmatics.
The former is deeply learned by using the contin-
uous states hidden in the recurrent units, while the
later the convolutional features. Multi-angled cog-
nition enables Hybrid to be more precise. How-
ever it is built using a single-channel architecture,
concatenating the RNN and the CNN. This results
in twofold accumulation of feature information,
causing a serious overﬁtting problem. Therefore,
Hybrid is localized to much higher precision but
substantially lower recall.

Overﬁtting results in enlargement of the gap be-
tween precision and recall when the task changes
to be more difﬁcult. For Hybrid, as illustrated in

MSEP-EMD                      Joint                              DM-CNN                      DM-CNN*                                   Hybrid                          Bi-RNN                            SELF 

P

R

P

R

P

R

P

R

gap=12.7% 

gap=10.1% 

85

80

75

70

65

60

gap=5.8%

%
4
.
5
=
p
a
g

 

%
9
.
1
1
=
p
a
g

 

%
4
.
1
1
=
p
a
g

85

80

75

70

65

60

85

80

75

70

65

60

 

%
2
1
=
p
a
g

(Bi-LSTM+CNN) 
R

P

(GRU) 
R

P

(Bi-LSTM+GAN) 
R

P

 

85

80

75

70

65

60

 

%
7
.
9
=
p
a
g

 

%
3
.
9
=
p
a
g

 

%
7
.
9
1
=
p
a
g

 

%
7
=
p
a
g

 

%
7
=
p
a
g

85

80

75

70

65

60

 

%
5
.
3
=
p
a
g

%
4
.
3
=
p
a
g

85

80

75

70

65

60

Trigger 

Trigger+
Type 

Trigger 

Trigger+
Type 

Trigger 

Trigger+
Type 

Trigger 

Trigger+
Type 

Trigger 

Trigger+
Type 

Trigger 

Trigger+
Type 

Trigger 

 

Trigger+
Type 

Min-supervision 

Feature engineering 

CNN-based 

Hybrid networks 

RNN-based 

85

80

75

70

65

60

 
 

Figure 2: Gaps between precision and recall in the tasks of trigger identiﬁcation and event classiﬁcation

Training Data
ACE+FN
ACE+FN
ACE+Wiki

Embedding Types
word
word, NE-type

Methods
ANNs
ANN-S2
DM-CNN∗ word, PSN
CNN
NC-CNN
Bi-RNN
Hybrid
DM-CNN
FB-RNN
SELF

word, NE-type, PSN ACE
word, NE-type, PSN ACE
word, NE-type, DEP ACE
word, NE-type, PSN ACE
ACE
word, PSN
ACE
word, branch
ACE
word, NE-type

Table 3: Embedding types and training data (DEP:
Dependency grammar; PSN: Position)

Figure 2, the gap becomes much wider (from 9%
to 19.7%) when the binary classiﬁcation task (trig-
ger identiﬁcation) is shifted to multi-class classiﬁ-
cation (event detection). By contrast, other work
shows a nearly constant gap. In particular, SELF
yields a minimum gap in each task, which changes
negligibly from 3.5% to 3.4%.

It may be added that, similar to DM-CNN and
FB-RNN, SELF is cost-effective. Compared to
other models (Table 3), it either uses less training
data, or is only required to learn two kinds of em-
beddings, such as that of words and entity types.

5.5 Discussion: Adaptation, Robustness and

Effectiveness

Domain adaptation is a key criteria for evaluating
the utility of a model in practical application. A
model can be thought of being adaptable only if it
works well for the unlabeled data in the target do-
main when trained on the source domain (Blitzer
et al., 2006; Plank and Moschitti, 2013).

We perform two groups of domain adaptation
experiments, respectively, using the ACE 2005
corpus and the corpus for TAC-KBP 2015 event
nugget track (Ellis et al., 2015).

The ACE corpus consists of 6 domains: broad-

cast conversation (bc), broadcast news (bn), tele-
phone conversation (cts), newswire (nw), usenet
(un) and web blogs (wl). Following the com-
mon practice of adaptation research on this data
(Nguyen and Grishman, 2014, 2015; Plank and
Moschitti, 2013), we take the union of bn and nw
as the source domain and bc, cts and wl as three
different target domains. We randomly select half
of the instances from bc to constitute the develop-
ment set. The TAC-KBP corpus consists of 2 do-
mains: newswire (NW) and discussion forum (DF).
We follow Peng et al (2016) to use one of NW and
DF in alternation as the source domain, while the
other the target domain. We randomly select a pro-
portion (20%) of the instances from the target do-
main to constitute the development set.

We compare with Joint, CNN, MSEP-EMD,
SSED (Sammons et al., 2015) and Hybrid. All
the models except Hybrid have been reported for
the performance assessment of domain adaptation.
In this section, we only cite the best performance
they obtained. We reproduce Hybrid by using the
source code given by authors. To ensure a fair
comparison, we perform 3 runs, in each of which,
both Hybrid and SELF were redeveloped on a new
development set. What we report herein is the av-
erage performance they obtained over the 3 runs.

Adaptation Performance

We show the adaptation performance on the ACE
corpus in Tables 4 and that on TAC-KBP in Table
5. It can be observed that SELF outperforms other
models in the out-of-domain scenarios.

Besides, when testing is performed on the out-
of-domain ACE corpus, the performance degrada-
tion of SELF is not much larger than that of CNN
and Hybrid. When the out-of-domain TAC-KBP
corpus is used, the performance of SELF is im-
paired much less severely than SSED and Hybrid.

Methods

Joint
CNN
Hybrid
SELF

In-domain (bn+nw)
P(%) R(%) F(%)

72.9
69.2
68.8
73.8

63.2
67.0
54.8
65.7

67.7
68.0
61.0
69.5

Out-of-domain (bc)
P(%) R(%) F(%) Loss
↓5.1
↓0.4
↑0.6
↓0.6

57.5
65.2
58.8
67.2

68.8
70.2
64.7
70.0

62.6
67.6
61.6
68.9

Out-of-domain (cts)
P(%) R(%) F(%) Loss
↓10.0
↓5.2
↓6.1
↓6.2

64.5
68.3
59.9
68.3

52.3
58.2
50.6
60.2

57.7
62.8
54.9
63.3

Out-of-domain (wl)
P(%) R(%) F(%) Loss
↓22.0
↓20.5
↓16.5
↓19.5

56.4
54.8
54.0
58.0

38.5
42.0
37.9
44.0

45.7
47.5
44.5
50.0

Table 4: Experimental results of domain adaptation on the ACE 2005 corpus

Methods

In-domain (NW)
P(%) R(%) F(%)

MSEP-EMD NA
NA
72.6
67.6

SSED
Hybrid
SELF

NA
NA
55.4
60.6

Out-of-domain (DF)
P(%) R(%) F(%) Loss
↓5.7
NA
↓11.4 NA
↓14.8 66.0
↓7.2
70.5

52.8
52.3
48.1
56.7

NA
NA
39.2
58.7

58.5 NA
63.7 NA
62.3
62.9
69.0
63.9

In-domain (DF)
P(%) R(%) F(%)

NA
NA
42.6
48.3

57.9
62.6
51.8
57.3

Out-of-domain (NW)
P(%) R(%) F(%) Loss
↓2.8
↓7.8
↑1.5
↑1.9

NA
NA
48.4
51.7

NA
NA
59.1
69.3

55.1
54.8
53.3
59.2

Table 5: Experimental results of domain adaptation on the TAC-KBP 2015 corpus (NA: not released)

More importantly, the adaptability of SELF is
relatively close to that of MSEP-EMD. Consider-
ing that MSEP-EMD is stable due to using mini-
mal supervision (Peng et al., 2016), we suggest the
fully trained networks in SELF may not appear to
be extremely inﬂexible, but on the contrary, they
should be transferable for use (Ge et al., 2016).

Robustness in Resource-Poor Settings

There are two resource-poor conditions discussed
in this section, including lack of in-domain train-
ing data and that of out-domain. Hybrid and SELF
are brought into the discussion.

For the former (in-domain) case, we went over
the numbers of samples used for training in the
adaptation experiments, which are shown in Ta-
ble 6. It can be observed that there is a minimum
number of training samples (triggers plus tokens)
contained in the domain of NW. By contrast, the
domain of bn+nw contains the smallest number of
positive samples (triggers) though an overwhelm-
ing number of negative samples (general tokens).
Under such conditions, Hybrid performs better
in the domain of NW compared to bn+nw and DF
in the three in-domain adaptation experiments (see
the column labelled as “In-domain bn+nw” in Ta-
ble 4 as well as “In-domain NW” and “In-domain
DF” in Table 5). It illustrates that Hybrid unnec-
essarily relies on a tremendous number of training
samples to ensure the robustness. But SELF does.
It needs far more negative samples than Hybrid be-
cause of the following reasons:

• It relies on the use of spurious features to im-

plement self-regulation during training.

Domain

bn+nw
NW
DF

Training

Testing

trigger
1,721
2,098
4,106

token
74,179
31,014
10,9275

trigger
343
2,813
1,773

token
16,336
55,459
43,877

Table 6: Data distribution in the source domains

• For a positive sample, the concerned spurious
features (if have) most probably hide in some
negative samples.

• It’s impossible to be aware of such negative
samples. Therefore, taking into consideration
as many negative samples as possible may
help to increase the probability that the spu-
rious features will be discovered.

This is demonstrated by the fact that SELF ob-
tains better performance in the domain of bn+nw
but not NW (see the column labeled as “Training”
in Table 6 and “In-domain” in Table 4 and 5). It
may be added that SELF performs worse in DF al-
though there are more negative samples used for
training (see Table 6). Taking a glance at the num-
ber of positive samples, one may ﬁnd that it is ap-
proximately 2.4 times more than that in bn+nw.
But the number of negative samples in DF is only
1.5 times more than that in bn+nw. It implies that,
if there are more positive samples used for train-
ing, SELF needs to consume proportionally more
negative samples for self-regulation. Otherwise,
the performance will degrade.

For the out-domain case, ideally, both Hybrid
and SELF encounter the problem that there is lack
of target domain data available for training. In this
case, SELF displays less performance degradation

Event mentions
And it still does
We had no part in it
Nobody questions if this is right or ...
And that is what ha- what is happening
Oh, yeah, it wasn’t perfect

Type
Die
Arrest-Jail
Attack
End-Position
Marry

Table 7: Examples of pronouns that act as a trigger

(7.2%) than Hybrid (14.8%) when NW is used for
training. Considering that NW contains the mini-
mum number of samples, we would like to believe
that SELF is more robust than Hybrid for cross-
domain event detection in a resource-poor setting.

Recall and Missing

SELF is able to accurately recall the events whose
occurrence is triggered by ambiguous words, such
as “ﬁne”, “charge”, “campaign”, etc. These am-
biguous words easily causes confusion. For exam-
ple, “campaign” may trigger an Elect event or
Attack in the ACE corpus.

More importantly, SELF ﬁshes out the common
words which serve as a trigger, although they are
not closely related to any kind of events, such as
“take”, “try”, “acquire”, “become”, “create”, etc.
In general, it is very difﬁcult to accurately recall
such triggers because their meanings are not con-
crete enough, and the contexts may be full of kinds
of noises (see example 2 in pg. 1). We observe that
Bi-RNN and Hybrid seldom pick them up.

However, SELF fails to recall the pronouns that
act as a trigger. This is because they occur in spo-
ken language much more frequently than they oc-
cur in written language. The lack of narrative con-
tent makes it difﬁcult to learn the relationship be-
tween the pronouns and the events. Some real ex-
amples collected from ACE are shown in Table 7.

6 Related Work

Event detection is an important subtask of event
extraction (Doddington et al., 2004; Ahn, 2006).

The research can be traced back to the pattern
based approach (Grishman et al., 2005). Encour-
aged by the high accuracy and the beneﬁt of easy-
to-use, researchers have made great efforts to ex-
tract discriminative patterns. Cao et al (2015a;
2015b) use dependency regularization and active
leaning to generalize and expand the patterns.

In the earlier study, another trend is to explore
the features that best characterize each event class,
so as to facilitate supervised classiﬁcation. A vari-

ety of strategies have emerged for converting clas-
siﬁcation clues into feature vectors (Ahn, 2006;
Patwardhan and Riloff, 2009; Liao and Grishman,
2010; Hong et al., 2011; Li et al., 2013, 2014; Wei
et al., 2017). Beneﬁting from the general model-
ing framework, the methods enable the fusion of
multiple features, and more importantly, they are
ﬂexible to use by feature selection. But consider-
able expertise is required for feature engineering.
Recently, the use of neural networks for event
detection has become a promising line of research.
The closely related work has been presented in
section 5.3. The primary advantages of neural net-
works have been demonstrated in the work, such
as performance enhancement, self-learning capa-
bility and robustness.

The generative adversarial network (Goodfel-
low et al., 2014) has emerged as an increasingly
popular approach for text processing (Zhang et al.,
2016; Lamb et al., 2016; Yu et al., 2017). Liu et
al (2017a) use the adversarial multi-task learning
for text classiﬁcation. We follow the work to cre-
ate spurious features, but use them to regulate the
self-learning process in a single-task situation.

7 Conclusion

We use a self-regulated learning approach to im-
prove event detection. In the learning process, the
adversarial and cooperative models are utilized in
decontaminating the latent feature space.

In this study, the performance of the discrimi-
nator in the adversarial network is left to be evalu-
ated. Most probably, the discriminator also per-
forms well because it is gradually enhanced by
ﬁerce competition. Considering this possibility,
we suggest to drive the two discriminators in our
self-regulation framework to cooperate with each
other. Besides, the global features extracted in Li
et al (2013)’s work are potentially useful for de-
tecting the event instances referred by pronouns,
although involve noises. Therefore, in the future,
we will encode the global information by neural
networks and use the self-regulation strategy to re-
duce the negative inﬂuence of noises.

Acknowledgments

We thank Xiaocheng Feng and his colleagues who
shared the source code of Hybrid with us.

This work was supported by the national Natu-
ral Science Foundation of China (NSFC) via Grant
Nos. 61525205, 61751206, 61672368.

References

David Ahn. 2006. The stages of event extraction.
In Proceedings of
the Workshop on Annotating
and Reasoning about Time and Events, Associa-
tion for Computational Linguistics (ACL’06). As-
sociation for Computational Linguistics, pages 1–8.
http://www.aclweb.org/anthology/W06-0901.

John Blitzer, Ryan McDonald, and Fernando Pereira.
Domain adaptation with structural cor-
2006.
respondence learning.
the
2006 conference on Empirical Methods in Natu-
ral Language Processing (EMNLP’06). Associa-
tion for Computational Linguistics, pages 120–128.
http://www.aclweb.org/anthology/W06-1615.

In Proceedings of

Konstantinos Bousmalis, George Trigeorgis, Nathan
Silberman, Dilip Krishnan, and Dumitru Erhan.
2016. Domain separation networks. In Advances in
Neural Information Processing Systems. pages 343–
351.

Kai Cao, Xiang Li, Miao Fan, and Ralph Grish-
Improving event detection with
man. 2015a.
active learning.
the Inter-
national Conference Recent Advances in Natural
Language Processing (RANLP’15). pages 72–77.
http://www.aclweb.org/anthology/R15-1010.

In Proceedings of

Kai Cao, Xiang Li, and Ralph Grishman. 2015b.
Improving event detection with dependency reg-
ularization.
the Interna-
In Proceedings of
tional Conference Recent Advances in Natural
Language Processing (RANLP’15). pages 78–83.
http://www.aclweb.org/anthology/R15-1011.

Yubo Chen, Shulin Liu, Xiang Zhang, Kang Liu, and
Jun Zhao. 2017. Automatically labeled data gener-
ation for large scale event extraction.
In Proceed-
ings of the 55th Annual Meeting of the Association
for Computational Linguistics (ACL’17). volume 1,
https://doi.org/10.18653/v1/P17-
pages 409–419.
1038.

Yubo Chen, Liheng Xu, Kang Liu, Daojian Zeng, Jun
Zhao, et al. 2015. Event extraction via dynamic
In
multi-pooling convolutional neural networks.
Proceedings of the 53th Annual Meeting of the As-
sociation for Computational Linguistics (ACL’15).
pages 167–176.
https://doi.org/10.3115/v1/P15-
1017.

Junyoung Chung, Caglar Gulcehre, KyungHyun Cho,
and Yoshua Bengio. 2014. Empirical evaluation of
gated recurrent neural networks on sequence model-
ing. arXiv preprint arXiv:1412.3555 .

George R Doddington, Alexis Mitchell, Mark A Przy-
bocki, Lance A Ramshaw, Stephanie Strassel, and
Ralph M Weischedel. 2004. The automatic con-
tent extraction (ACE) program-tasks, data, and
evaluation.
In LREC. volume 2, pages 1–4.
http://www.aclweb.org/anthology/L04-1011.

Joe Ellis, Jeremy Getman, Dana Fore, Neil Kuster,
Zhiyi Song, Ann Bies, and Stephanie Strassel. 2015.
Overview of linguistic resources for the tac kbp 2015
evaluations: Methodologies and results. In Proceed-
ings of TAC KBP 2015 Workshop, National Institute
of Standards and Technology (TAC’15). pages 16–
17.

Xiaocheng Feng, Lifu Huang, Duyu Tang, Heng Ji,
Bing Qin, and Ting Liu. 2016.
A language-
independent neural network for event detec-
tion.
the 54th Annual
the Association for Computational
Meeting of
Linguistics (ACL’16). volume 2, pages 66–71.
https://doi.org/10.18653/v1/P16-2011.

In Proceedings of

Tao Ge, Lei Cui, Baobao Chang, Zhifang Sui, and
Ming Zhou. 2016. Event detection with burst infor-
mation networks. In Proceedings of COLING 2016,
the 26th International Conference on Computational
Linguistics: Technical Papers. pages 3276–3286.

Reza Ghaeini, Xiaoli Fern, Liang Huang,

and
Prasad Tadepalli. 2016.
Event nugget detec-
tion with forward-backward recurrent neural net-
In Proceedings of the 54th Annual Meet-
works.
the Association for Computational Lin-
ing of
guistics (ACL’16). volume 2, pages 369–373.
https://doi.org/10.18653/v1/P16-2060.

Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,
Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. 2014. Generative ad-
versarial nets.
In Advances in neural information
processing systems. pages 2672–2680.

Ralph Grishman, David Westbrook, and Adam Meyers.
2005. Nyu’s English ACE 2005 system description.
ACE’05 .

Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky,
Ilya Sutskever, and Ruslan R Salakhutdinov. 2012.
Improving neural networks by preventing co-
adaptation of feature detectors.
arXiv preprint
arXiv:1207.0580 .

Yu Hong, Di Lu, Dian Yu, Xiaoman Pan, Xiaobin
Wang, Yadong Chen, Lifu Huang, and Heng Ji.
2015. RPI BLENDER TAC-KBP2015 system de-
scription.
In Proceedings of Text Analysis Confer-
ence (TAC’15).

Ronan Collobert and Jason Weston. 2008. A uniﬁed
architecture for natural language processing: Deep
In Pro-
neural networks with multitask learning.
ceedings of the 25th international conference on
Machine learning (ICML’08). ACM, pages 160–
167.

Yu Hong, Xiaobin Wang, Yadong Chen, Jian Wang,
Tongtao Zhang, Jin Zheng, Dian Yu, Qi Li, Boliang
Zhang, Han Wang, et al. 2014. RPI BLENDER
TAC-KBP2014 knowledge base population sys-
tem.
In Proceedings of Text Analysis Conference
(TAC’14).

Yu Hong, Jianfeng Zhang, Bin Ma, Jianmin Yao,
Guodong Zhou, and Qiaoming Zhu. 2011. Using
cross-entity inference to improve event extraction.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies (ACL-HLT’11). Association
for Computational Linguistics, pages 1127–1136.
http://www.aclweb.org/anthology/P11-1113.

Xun Huang, Yixuan Li, Omid Poursaeed,

John
Hopcroft, and Serge Belongie. 2017. Stacked gener-
ative adversarial networks. In IEEE Conference on
Computer Vision and Pattern Recognition (CVPR).
volume 2, page 4.

Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidi-
rectional LSTM-CRF models for sequence tagging.
arXiv preprint arXiv:1508.01991 .

Md M Islam, Xin Yao, and Kazuyuki Murase. 2003. A
constructive algorithm for training cooperative neu-
ral network ensembles. IEEE Transactions on neu-
ral networks 14(4):820–834.

Rafal

Jozefowicz, Wojciech Zaremba,

and Ilya
Sutskever. 2015. An empirical exploration of recur-
rent network architectures.
In Proceedings of the
32nd International Conference on Machine Learn-
ing (ICML’15). pages 2342–2350.

Alex M Lamb, Anirudh Goyal ALIAS PARTH
GOYAL, Ying Zhang, Saizheng Zhang, Aaron C
Courville, and Yoshua Bengio. 2016.
Professor
forcing: A new algorithm for training recurrent net-
works. In Advances In Neural Information Process-
ing Systems. pages 4601–4609.

Qi Li, Heng Ji, and Liang Huang. 2013.

Joint
event extraction via structured prediction with
the 51th
global
the Association for Com-
Annual Meeting of
putational Linguistics
(ACL’13). pages 73–82.
http://www.aclweb.org/anthology/P13-1008.

In Proceedings of

features.

Qi Li, Heng Ji, HONG Yu, and Sujian Li. 2014.
Constructing information networks using one sin-
gle model.
the 2014 Con-
In Proceedings of
ference on Empirical Methods in Natural Lan-
guage Processing (EMNLP’14). pages 1846–1851.
https://doi.org/10.3115/v1/D14-1198.

Shasha Liao and Ralph Grishman. 2010.

Us-
ing document level cross-event inference to im-
prove event extraction.
the
the Association for
48th Annual Meeting of
Computational Linguistics (ACL’10). Association
for Computational Linguistics, pages 789–797.
http://www.aclweb.org/anthology/P10-1081.

In Proceedings of

Zhouhan Lin, Minwei Feng, Cicero Nogueira dos San-
tos, Mo Yu, Bing Xiang, Bowen Zhou, and Yoshua
Bengio. 2017. A structured self-attentive sentence
embedding. arXiv preprint arXiv:1703.03130 .

Ming-Yu Liu and Oncel Tuzel. 2016. Coupled gener-
In Advances in neural

ative adversarial networks.
information processing systems. pages 469–477.

Pengfei Liu, Xipeng Qiu, Jifan Chen, and Xuanjing
Huang. 2016a. Deep fusion LSTMs for text se-
mantic matching.
In Proceedings of the 54th An-
nual Meeting of the Association for Computational
Linguistics (ACL’16). volume 1, pages 1034–1043.
https://doi.org/10.18653/v1/P16-1098.

Pengfei Liu, Xipeng Qiu, and Xuanjing Huang.
2017a. Adversarial multi-task learning for text
classiﬁcation.
arXiv preprint arXiv:1704.05742
https://doi.org/10.18653/v1/P17-1001.

Shulin Liu, Yubo Chen, Shizhu He, Kang Liu, and
Jun Zhao. 2016b.
to im-
prove automatic event detection.
In Proceed-
the Asso-
the 54th Annual Meeting of
ings of
ciation for Computational Linguistics (ACL’16).
https://doi.org/10.18653/v1/P16-1201.

Leveraging framenet

Shulin Liu, Yubo Chen, Kang Liu, and Jun Zhao.
2017b. Exploiting argument information to improve
event detection via supervised attention mechanisms
1:1789–1797.
https://doi.org/10.18653/v1/P17-
1164.

Linguistic regularities

Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013.
in continuous
space word representations.
In Proceedings
of
the 2013 Conference of
the North Ameri-
the Association for Computa-
can Chapter of
tional Linguistics: Human Language Technolo-
gies (NAACL’13). volume 13, pages 746–751.
http://www.aclweb.org/anthology/N13-1090.

Thien Huu Nguyen, Kyunghyun Cho, and Ralph Gr-
ishman. 2016. Joint event extraction via recurrent
neural networks. In Proceedings of the 2016 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies (NAACL’16). pages 300–309.
https://doi.org/10.18653/v1/N16-1034.

Thien Huu Nguyen and Ralph Grishman. 2014. Em-
ploying word representations and regularization for
domain adaptation of relation extraction.
In Pro-
ceedings of the 52th Annual Meeting of the Associa-
tion for Computational Linguistics (ACL’14). pages
68–74. https://doi.org/10.3115/v1/P14-2012.

Thien Huu Nguyen and Ralph Grishman. 2015. Event
detection and domain adaptation with convolu-
tional neural networks.
the
53th Annual Meeting of the Association for Com-
putational Linguistics (ACL’15). pages 365–371.
https://doi.org/10.3115/v1/P15-2060.

In Proceedings of

Thien Huu Nguyen and Ralph Grishman. 2016. Mod-
eling skip-grams for event detection with convo-
lutional neural networks.
In Proceedings of the
2016 Conference on Empirical Methods in Natural
Language Processing (EMNLP’16). pages 886–891.
https://doi.org/10.18653/v1/D16-1085.

Siddharth Patwardhan and Ellen Riloff. 2009. A
uniﬁed model of phrasal and sentential evidence

for information extraction.
In Proceedings of the
2009 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP’09). Associa-
tion for Computational Linguistics, pages 151–160.
http://www.aclweb.org/anthology/D09-1016.

Lantao Yu, Weinan Zhang, Jun Wang, and Yong Yu.
Seqgan: Sequence generative adversarial
2017.
nets with policy gradient.
In Proceedings of the
32nd AAAI Conference on Artiﬁcial Intelligence
(AAAI’17). pages 2852–2858.

Haoruo Peng, Yangqiu Song, and Dan Roth. 2016.
Event detection and co-reference with minimal
supervision.
the 2016 Con-
In Proceedings of
ference on Empirical Methods in Natural Lan-
guage Processing (EMNLP’16). pages 392–402.
https://doi.org/10.18653/v1/D16-1038.

Matthew D Zeiler. 2012. Adadelta: an adaptive learn-
ing rate method. arXiv preprint arXiv:1212.5701 .

Yizhe Zhang, Zhe Gan, and Lawrence Carin. 2016.
In NIPS

Generating text via adversarial training.
workshop on Adversarial Training. volume 21.

Barbara Plank and Alessandro Moschitti. 2013. Em-
bedding semantic similarity in tree kernels for do-
main adaptation of relation extraction. In Proceed-
ings of the 51th Annual Meeting of the Associa-
tion for Computational Linguistics (ACL’13). pages
1498–1507. http://www.aclweb.org/anthology/P13-
1147.

Mark Sammons, Haoruo Peng, Yangqiu Song, Shyam
Upadhyay, Chen-Tse Tsai, Pavankumar Reddy,
Subhro Roy, and Dan Roth. 2015. Illinois CCG TAC
2015 event nugget, entity discovery and linking, and
slot ﬁller validation systems. In Proceedings of Text
Analytics Conference (TAC’15).

Mike Schuster and Kuldip K Paliwal. 1997. Bidirec-
tional recurrent neural networks. IEEE Transactions
on Signal Processing 45(11):2673–2681.

Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.
Sequence to sequence learning with neural net-
works. In Advances in neural information process-
ing systems. pages 3104–3112.

Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.
Word representations: a simple and general method
for semi-supervised learning.
In Proceedings of
the 48th Annual Meeting of the Association for
Computational Linguistics
(ACL’10). Associa-
tion for Computational Linguistics, pages 384–394.
https://doi.org/http://www.aclweb.org/anthology/P10-
1040.

Mengqiu Wang and Christopher D Manning. 2013.
Effect of non-linear deep architecture in se-
quence labeling.
the Sixth
International Joint Conference on Natural Lan-
guage Processing (IJCNLP’13). pages 1285–1291.
https://doi.org/http://www.aclweb.org/anthology/I13-
1183.

In Proceedings of

Sam Wei,

Igor Korostil, Joel Nothman, and Ben
Hachey. 2017. English event detection with trans-
lated language features. In Proceedings of the 55th
Annual Meeting of the Association for Computa-
tional Linguistics (ACL’17). volume 2, pages 293–
298. https://doi.org/10.18653/v1/P17-2046.

Dian Yu, Xiaoman Pan, Boliang Zhang, Lifu Huang,
Di Lu, Spencer Whitehead, and Heng Ji. 2016. RPI
BLENDER TAC-KBP2016 system description.
In
Proceedings of Text Analysis Conference (TAC’16).

