Radially-Distorted Conjugate Translations

James Pritts1
Visual Recognition Group, CTU in Prague1

Zuzana Kukelova1

Viktor Larsson2

Ondˇrej Chum1
Centre for Mathematical Sciences, Lund University2

8
1
0
2
 
n
u
J
 
1
2
 
 
]

V
C
.
s
c
[
 
 
3
v
9
3
3
1
1
.
1
1
7
1
:
v
i
X
r
a

Abstract

This paper introduces the ﬁrst minimal solvers that
jointly solve for afﬁne-rectiﬁcation and radial lens distor-
tion from coplanar repeated patterns. Even with imagery
from moderately distorted lenses, plane rectiﬁcation using
the pinhole camera model is inaccurate or invalid. The pro-
posed solvers incorporate lens distortion into the camera
model and extend accurate rectiﬁcation to wide-angle im-
agery, which is now common from consumer cameras. The
solvers are derived from constraints induced by the conju-
gate translations of an imaged scene plane, which are in-
tegrated with the division model for radial lens distortion.
The hidden-variable trick with ideal saturation is used to
reformulate the constraints so that the solvers generated by
the Gröbner-basis method are stable, small and fast.

Rectiﬁcation and lens distortion are recovered from ei-
ther one conjugately translated afﬁne-covariant feature or
two independently translated similarity-covariant features.
The proposed solvers are used in a RANSAC-based estima-
tor, which gives accurate rectiﬁcations after few iterations.
The proposed solvers are evaluated against the state-of-
the-art and demonstrate signiﬁcantly better rectiﬁcations on
noisy measurements. Qualitative results on diverse imagery
demonstrate high-accuracy undistortions and rectiﬁcations.
The source code is publicly available1.

1. Introduction

Scene-plane rectiﬁcation is used in many classic
computer-vision tasks,
including single-view 3D recon-
struction, camera calibration, grouping coplanar symme-
tries, and image editing [26, 21, 15]. In particular, the afﬁne
rectiﬁcation of a scene plane transforms the camera’s prin-
cipal plane so that it is parallel to the scene plane. This re-
stores the afﬁne invariants of the imaged scene plane, which
include parallelism of lines and translational symmetries
[9, 21]. There is only an afﬁne transformation between the
afﬁne-rectiﬁed imaged scene plane and its real-world coun-
terpart. The removal of the effects of perspective imaging is
helpful to understanding the geometry of the scene plane.

1https://github.com/prittjam/repeats

Figure 1: Input (top left) is a distorted view of a scene plane,
and the outputs (top right, bottom) are the the undistorted
and rectiﬁed scene plane. The method is fully automatic.

Wide-angle imagery that has signiﬁcant lens distortion
is common since consumer photography is now dominated
by mobile-phone and GoPro-type cameras. High-accuracy
rectiﬁcation from wide-angle imagery is not possible with
only pinhole camera models [11, 25]. Lens distortion can be
estimated by performing a camera calibration apriori, but a
fully automated method is desirable.

Several state-of-the-art planar-rectiﬁcation methods as-
sume a pinhole camera model, which ignores the effect of
lens distortion [1, 4, 15, 27]. Pritts et al. [21] attempt to up-
grade the pinhole camera model with radial lens distortion
by giving an initial guess of the scene plane’s rectiﬁcation
that is consistent with a pinhole camera to a non-linear op-
timization that incorporates a lens-distortion model. How-
ever, even with relaxed thresholds, a robust estimator (i.e.
RANSAC) will discard measurements that capture the most
extreme effects of lens distortion, especially around the
boundary of the image, since these measurements are not
consistent with the pinhole-camera assumption. Thus, fail-
ing to account for lens distortion while labeling the mea-

1

narrow

medium

wide

Figure 2: GoPro Hero 4 imagery. (top row) Input images
taken at different ﬁeld-of-view settings. (bottom row) Rec-
tiﬁed results.

surements as outliers, as done during a RANSAC iteration,
can give biased ﬁts that underestimate the camera’s lens-
distortion [11], which, in turn, reduces rectiﬁcation accu-
racy.

This paper introduces the ﬁrst minimal solvers that
jointly solve for the afﬁne rectiﬁcation of an imaged scene
plane and a camera’s radial lens distortion. The solvers are
derived from constraints induced by the conjugate trans-
lations of an imaged scene plane (see Sec. 2 for details),
which are integrated with the division model of radial dis-
tortion [7]. Despite the simple formulation of the division
model, it is accurate for even wide-angle lenses [7]. In addi-
tion, the solvers estimate the vanishing translation direction
of the corresponded points used for input.

Two types of solvers are introduced: one-direction
solvers, which require 3 coplanar point correspondences
translate in the same direction, and two-direction
that
solvers, which require 4 coplanar point correspondences, 2
of which translate in one-direction and the remaining 2 in
a different direction. Covariant feature detectors are used
to extract the needed point correspondences [14, 16, 18,
19, 24]. The solvers are used in a RANSAC-based frame-
work for robust rectiﬁcation estimation. With one or two-
correspondence sampling, an accurate undistortion and rec-
tiﬁcation is quickly recovered, even for difﬁcult scenes.

Fitzgibbon used a one-parameter division model to de-
velop a minimal solver for jointly estimating lens distortion
with a fundamental matrix or homography [7]. Kukelova et
al. [11] proposed an extension to [7] for homographies to
model two-views from cameras with different radial lens
distortions. These two-view solvers can jointly estimate
lens distortion and conjugate translations, but are overpa-
rameterized for this task, which can result in inaccurate es-
timates as is shown by the synthetic experiments in Sec. 5.
Wildenauer et al. [25] and Antunes et al. [2] are two meth-

ods that use constraints induced by imaged parallel lines to
jointly solve for their vanishing point and the division model
parameter, but but both require a multi-model estimation to
recover scene-plane rectiﬁcation (i.e. 2 consistent vanishing
points).

The systems of polynomial equations induced from the
constraints arising from joint estimation of conjugate trans-
lation with the division-model parameter are solved using
an algebraic method based on Gröbner bases. Automated
solver-generators using the Gröbner basis method [10, 12]
were recently used to generate solvers for several problems
in multi-view geometry [10, 13, 12, 11]. However, straight-
forward application of an automated solver-generator to the
proposed problem resulted in unstable solvers (see Sec. 5).
Therefore, we transformed the constraints to simplify the
structure of the systems of polynomial equations, while
explicitly accounting for the parasitic solutions that arose
from the new formulation. The new formulation resulted in
solvers with increased stability and speed.

The problem of rectiﬁcation is closely coupled with the
detection of coplanar repeats in a classic chicken-and-egg
scenario: rectiﬁcation is easy if the repeats are grouped,
and repeats are more easily grouped if the afﬁne invari-
ants of the rectiﬁed plane are available [21]. Most methods
tentatively group repeats from their local texture, which is
veriﬁed later by a hypothesized rectiﬁcation. Methods us-
ing this approach include Schaffalitzky et al. [23], which,
similar to the solvers proposed in this paper, uses con-
straints induced by conjugate translations to recover the
scene-plane’s vanishing line, and Chum et al. [4], which
uses the constraint that coplanar repeats are equiareal in the
scene-plane’s afﬁne-rectiﬁed image. None of these meth-
ods account for lens distortion, and do not perform well on
imagery with signiﬁcant lens distortion (see Sec. 6).

2. Problem Formulation

Assume that the scene plane π and a camera’s image
plane π(cid:48) are related point-wise by the homography P, so
that αix(cid:48)
i ∈ π(cid:48).
i = PXi, where αi is a scalar, Xi ∈ π and x(cid:48)
Let Xi and X(cid:48)
i be two points on the scene plane π such that
X(cid:48)
i − Xi = t. By encoding t in the homogeneous transla-
tion matrix T, the points Xi and X(cid:48)
i as imaged by camera P
can be expressed as

αix(cid:48)

i = PX(cid:48)

i = PTXi = PTP−1xi = Huxi,

(1)

where the homography Hu = PTP−1 is called a conjugate
translation because of the form of its matrix decomposition
and points xi and x(cid:48)
i are in correspondence with respect to
the conjugate translation Hu, which we denote xi ↔ x(cid:48)
i
[9, 23]. Decomposing Hu into its projective components

gives

αix(cid:48)

i = Huxi =


PI3P−1 + P











P−(cid:62)





tx
ty
1

(cid:62)






 xi


0
0

1

= [I3 + su

i ul(cid:62)] · xi

(2)

where I3 is the 3 × 3 identity matrix, and

• line l is the imaged scene plane’s vanishing line,

• point u is the vanishing direction of translation, which

must meet the vanishing line l, i.e., l(cid:62)u = 0,

• and scalar su

rection u for the point correspondence ˜xi ↔ ˜x(cid:48)

i is the magnitude of translation in the di-
i [23].

Note that (2) holds only for points projected by a pinhole
camera viewing a scene plane, which is parameterized by
the homography P as deﬁned above. For every real camera,
some amount of radial distortion is always present, so for
(2) to hold, the measured image points ˜xi and ˜x(cid:48)
i must ﬁrst
be undistorted. We use the one-parameter division model
to parameterize the radial lens distortion [7], which has the
form

f (˜xi, λ) = (cid:0)˜xi, ˜yi, 1 + λ(˜x2
where the distortion center is given;
center-subtracted measurements from a feature detector.

i + ˜y2

i )(cid:1)(cid:62)

i.e., ˜xi, ˜yi are the

(3)

,

In this work we incorporate constraints induced by a con-
jugate translation as derived in (2) with the division model
deﬁned in (3) to accurately rectify imaged scene planes
from lens-distorted cameras. Since the unknown division
model parameter is exclusively encoded in the homoge-
neous coordinate, the relation for conjugate translations can
be directly augmented to model lens distortion, namely,

αif (˜x(cid:48)

i, λ) = Huf (˜xi, λ) = [I3 + su

i ul(cid:62)] · f (˜xi, λ),

(4)

where αi is some non-zero scalar, and ˜xi ↔ ˜x(cid:48)
correspondence.

i is a point

3. Solvers

The model for radially-distorted conjugate translations
(i) di-
in (4) deﬁnes the unknown geometric quantities:
vision-model parameter λ, (ii) scene-plane vanishing line
l = (cid:0)l1, l2, l3
,
(iii) vanishing translation direction
u = (cid:0)u1, u2, u3
(cid:1)(cid:62)
tensions), (iv) scale of translation su
i
˜xi ↔ ˜x(cid:48)

(see Sec. 3.2 for the two-direction ex-
for correspondence

i, (v) and the scalar parameter αi.

(cid:1)(cid:62)

The solution for the vanishing line l is constrained to the
afﬁne subspace l3 = 1 of the real-projective plane, which
makes it unique. This inhomogeneous choice of l is unable
to represent the pencil of lines that pass through the ori-
gin. If this degeneracy is encountered, then the scale of l

is ﬁxed by setting l2 = 1 instead. Solver variants for both
constraints are generated for all of the proposed solvers. In
practice, this degeneracy is rarely encountered. If the l3 = 1
solver variant suffers from bad numerical conditioning, then
the l2 = 1 variant can be activated and its solutions tested
for consensus with the measurements (see Sec. 4). Without
loss of generality the derivations below assume that l3 = 1.
The vanishing direction u must meet the vanishing line l,
which deﬁnes a subspace of solutions for u. The magnitude
of u is set to the translation scale su
1 of the ﬁrst correspon-
dence, which deﬁnes a unique solution

l(cid:62)u = l1u1 + l2u2 + u3 = 0 ∧ (cid:107)u(cid:107) = su
1 .

(5)

The relative scale of translation ¯su
˜xi ↔ ˜x(cid:48)
that ¯su

i for each correspondence
i with respect to the magnitude of (cid:107)u(cid:107) is deﬁned so
1 = 1.

i /(cid:107)u(cid:107). Note that ¯su

i = su

In this paper we propose four different minimal solvers
for different variants of the problem of radially-distorted
conjugate translations based on different translation direc-
tions and relative scales ¯su
i . These variants are motivated
by the types of covariant feature detectors used to extract
point correspondences [14, 16, 18, 19, 24]. Each afﬁne-
covariant feature deﬁnes an afﬁne frame, i.e. an ordered
triplet of points. Thus, 1 afﬁne-frame correspondence pro-
vides the 3 point correspondences that translate in the same
direction with the same scale. This is sufﬁcient input for
the one-directional solvers. A visualization of the features
is provided in Fig. C.4 of the supplemental material. In the
case of similarity-covariant features, such as DoG [14], only
a similarity frame can be constructed. A correspondence of
similarity frames gives 2 point correspondences that trans-
late jointly. Two correspondences of similarity-covariant
features of different direction of the translation provide suf-
ﬁcient constraints for the two directional solvers.

1 = ¯su

1 = ¯su

Two one-direction solvers are proposed, which require
3 (2.5) coplanar point correspondences that translate in the
same direction. The “3-point” solver H3lusuλ assumes that
two of the point correspondences have the same scale of
translation (i.e. ¯su
2 = 1), and the third point corre-
spondence has an unknown relative scale of the translation
¯su
3 . The “2.5-point” solver H2.5luλ assumes that all 3 point
correspondences have the same relative scales of transla-
tion, i.e. ¯su

2 = ¯su
two two-direction solvers are proposed,
which require 4 (3.5) coplanar point correspondences, 2 of
which translate in one-direction u and the remaining 2 in a
different direction v. Here the “4-point” solver H4luvsvλ
assumes that the ﬁrst two point correspondences translate
in the direction u with the same relative scale of translation,
i.e., ¯su
2 = 1. The remaining two point correspon-
dence translate in the direction v with arbitrary translation
magnitudes, i.e., the relative scales of translations of these
two correspondences with respect to (cid:107)v(cid:107) = sv
3 = 1

In addition,

1 = ¯su

3 are ¯sv

3 = 1.

and an unknown relative scale ¯su
4 .

The “3.5-point” H3.5luvλ solver assumes that the rela-
1 and

2 = 1 with respect to (cid:107)u(cid:107) = su
4 = 1 with respect to (cid:107)v(cid:107) = sv
3 .

tive scales ¯su
3 = ¯sv
¯sv

1 = ¯su

In all proposed solvers the scalar values αi are elimi-
nated from (4). This is done by multiplying (4) by the skew-
symmetric matrix [f (˜x(cid:48)
i, λ)]×. The fact that the join of a
point xi with itself [xi]×xi is 0 gives,





˜y(cid:48)
i
−˜x(cid:48)
i
0





×

0 − ˜w(cid:48)
i
˜w(cid:48)
0
i
˜x(cid:48)
−˜y(cid:48)
i
i

1 + ¯su
i u1l1
¯su
i u2l1
¯su
i u3l1



¯su
i u1l2
1 + ¯su
¯su
i u3l2

i u2l2

¯su
i u1
¯su
i u2
1 + ¯su

i u3











 = 0,

˜xi
˜yi
˜wi

(6)

i + ˜y2

where ˜wi = 1 + λ(˜x2
i ).
The matrix equation in (6) contains three polynomial equa-
tions from which only two are linearly independent, since
the skew-symmetric matrix [f (˜x(cid:48)

i = 1 + λ(˜x(cid:48)2

i ) and ˜w(cid:48)

i, λ)]× is rank two.

i + ˜y(cid:48)2

To solve the systems of polynomial equations result-
ing from the presented problems, we use the Gröbner ba-
sis method [6]. To generate efﬁcient solvers we used the
automatic generator of Gröbner basis solvers proposed in
[10, 12]. However, for our problems the coefﬁcients of
the input equations are not fully independent. This means
that using the default settings for the automatic generator
[10, 12] that initialize the coefﬁcients of equations by ran-
dom values from Zp does not lead to correct solvers. To ob-
tain working Gröbner basis solvers, one has to create correct
problems instances with values from Zp for the automatic
generator initialization.

The straightforward application of the automatic gen-
erator [10, 12] to the needed constraints with correct co-
efﬁcients from Zp resulted in large templates and unsta-
ble solvers, especially for the two-direction problems. The
Gröbner basis solvers generated for the original constraints
have template matrices with sizes 80 × 84, 74 × 76, 348 ×
354, and 730 × 734 for the H2.5luλ, H3lusuλ, H3.5luvλ
and H4luvsvλ problems, respectively. Therefore, we use
the hidden-variable trick [6] to eliminate the vanishing
translation directions together with ideal saturation [13] to
eliminate parasitic solutions. The reformulated constraints
are simpler systems in only 3 or 4 unknowns, and the solvers
generated by the Gröbner basis method are smaller and
more stable. The reduced eliminiation template sizes are
also summarized in Sec. B of the supplemental material.
Next, we describe the solvers based on the hidden-variable
trick in more detail.

3.1. One-Direction Solvers

For the “3-point” one-direction H3lusuλ solver we have
2 = 1. Therefore the constraints (6) result in two

1 = ¯su
¯su

u
l
2
H

[23]

Reference
Distortion

H∞ (cid:88)
2
1

# points
# solutions

λ
u

l
5
.
2
H

λ
u
s
u
l
3
H

λ
v
u
l
5
.
3
H

λ
v
s
v
u

l
4
H

(cid:88) (cid:88) (cid:88) (cid:88)
(cid:88) (cid:88) (cid:88) (cid:88) (cid:88)
4
3.5
2.5
1
6
4

4
4

3
2

γ
l
4
H

[4]

2
λ
1
λ
5
H

[10]
(cid:88)

5
5

λ
5
H

[7]
(cid:88)

5
18

Table 1: Proposed solvers (grey) vs. state-of-the-art.

pairs of linearly independent equations without the scale pa-
rameter ¯su
i for i = 1, 2, and two linearly independent equa-
tions with an unknown relative scale ¯su
3 for the third point
correspondence, i.e., i = 3. Additionally, we have the or-
thogonality constraint in (5). All together we have seven
equations in seven unknowns (l1, l2, u1, u2, u3, ¯su

3 , λ).

Note, that these equations are linear with respect to the
vanishing translation direction u. Therefore, we can rewrite
the seven equations as

M(l1, l2, ¯su

3 , λ)

= 0

(7)













u1
u2
u3
1

3 , λ) is a 7 × 4 matrix which elements are

where M(l1, l2, ¯su
polynomials in (l1, l2, ¯su
Since M(l1, l2, ¯su

3 , λ).

3 , λ) has a null vector, it must be rank
deﬁcient. Therefore, all the 4 × 4 sub-determinants of
(cid:1) = 35
3 , λ) must equal zero. This results in (cid:0)7
M(l1, l2, ¯su
polynomial equations which only involve four unknowns.

4

Unfortunately,

the formulation (7) introduces a one-
dimensional family of false solutions. These are not present
in the original system and corresponds to solutions where
the ﬁrst three columns of M become rank deﬁcient. In this
case there exist null vectors to M where the last element of
the vector is zero, i.e. not on the same form as in (7).

These false solutions can be removed by saturating any
of the 3 × 3 sub-determinants from the ﬁrst three columns
of M. The matrix M has the following form,

M(l1, l2, ¯su

3 , λ) =

(8)













m11 m12
m21 m22
m31
m41
m51 m52
m61
l1

0 m14
0 m24
0 m33 m34
0 m43 m44
0 m54
0 m63 m64
1
l2

0













where mij are polynomials in l1, l2, ¯su
3 and λ. We choose to
saturate the 3×3 sub-determinant corresponding to the ﬁrst,
second and last row since it reduces to only the top-left 2×2

sub-determinant, i.e. m11m22 − m12m21, which is only a
quadratic polynomial in the unknowns. The other 3 × 3 de-
terminants are more complicated and leads to larger polyno-
mial solvers. Using the saturation technique from Larsson
et al. [13] we were able to create a polynomial solver for
this saturated ideal. The size of the elimination template is
24 × 26. Note that without using the hidden-variable trick
the elimination template was 74 × 76.

2 = ¯su

For the H2.5luλ solver we can use the same hidden-
1 = ¯su
variable trick. In this case ¯su
3 = 1 and therefore
the matrix M in (7) contains only three unknowns l1, l2 and
λ. The minimal number of point correspondences necessary
to solve this problem is 2.5. Therefore, for this problem we
can drop one of the equations from (6), e.g., for i = 3, and
the matrix M in (7) has size 6 × 4. In this case all 4 × 4
sub-determinants of M result in 15 equations in 3 unknowns.
this introduces a one-
dimensional family of false solutions. The matrix M has a
similar structure as in (8) and again it is sufﬁcient to sat-
urate top-left 2 × 2 sub-determinant. For this formulation
we were able to create a solver with template size 14 × 18
(compared with 80×84 without using hidden-variable trick)

Similar to the 3 point case,

3.2. Two-Direction Solvers

(cid:1)(cid:62)

(cid:1)(cid:62)

and v = (cid:0)v1, v2, v3

In the case of the two-direction H4luvsvλ solvers, the
input equations for two vanishing translation directions u =
(cid:0)u1, u2, u3
can be separated into
two sets of equations, i.e., the equations containing u and
the equations containing v. Note that in this case we have
two equations of the form (5), i.e., the equation for the di-
rection u and the equation for the direction v and we have
an unknown relative scale ¯sv
4 . Therefore, the ﬁnal system
of 10 equations in 10 unknowns can be rewritten using two
matrix equations as

M1(l1, l2, λ)

= 0, M2(l1, l2, ¯sv

4 , λ)

= 0 (9)













u1
u2
u3
1













v1
v2
v3
1

where M1 and M2 are 5 × 4 matrices where the elements are
polynomials in (l1, l2, λ) and (l1, l2, ¯sv

4 , λ) respectively.

Again all 4 × 4 sub-determinants of M1 and M2 must con-
currently equal zero. This results in 5 + 5 = 10 polynomial
equations in four unknowns (l1, l2, ¯sv
4 , λ). In this case, only
39 additional false solutions arise from the hidden-variable
trick. The matrices M1 and M2 have a similar structure as in
(8) and again it is sufﬁcient to saturate the top-left 2 × 2
sub-determinants to remove the extra solutions. By saturat-
ing these determinants we were able to create a solver with
template size 76 × 80 (previously 730 × 734).

for the “3.5-point” two-direction H3.5luvλ
Finally,
solver ¯su
4 = 1 so we can drop
one of the equations from the constraint (6), e.g., for i = 4.

2 = 1 and ¯sv

1 = ¯su

3 = ¯sv

Therefore, the matrix M2 from (9) has size 4 × 4 and it con-
tains only 3 unknowns (l1, l2, λ). In this case all 4 × 4 sub-
determinants of M1 and M2 result in 5 + 1 = 6 polynomial
equations in three unknowns (l1, l2, λ).

In-
For this case we get 18 additional false solutions.
vestigations in Macaulay2 [8] revealed that for this particu-
lar formulation it was sufﬁcient to only saturate the top-left
2 × 2 sub-determinant of M1 and the top-left element of M2.
Saturating these we were able to create a polynomial solver
with a template size of 54 × 60 (previously 348 × 354).

4. Robust Estimation

The solvers are used in a LO-RANSAC-based robust-
estimation framework [5]. Afﬁne-covariant features are
extracted from the image for input to the solvers. Afﬁne-
covariant features are highly repeatable on the same imaged
scene texture with respect to signiﬁcant changes of view-
point and illumination [17]. Their proven robustness in
the multi-view correspondence problem makes them good
candidates for representing the local geometry of repeated
In particular, for the real-image experiments in
textures.
Sec. 6, we use the Maximally-Stable Extremal Region and
Hesssian-Afﬁne detectors [16, 18]. The detections are pa-
rameterized as 3 distinct points, which deﬁne an afﬁne co-
ordinate frame in the image space [20]. These detections
are visualized in Fig. C.4 of the supplemental material.

Afﬁne frames are labeled as repeated texture based on
the similarity of their appearance, which is given by the
RootSIFT embedding of the image patch local to the afﬁne
frame [3, 14]. The RootSIFT descriptors are agglomera-
tively clustered, which establishes pair-wise tentative corre-
spondences among the connected components linked by the
clustering. Each appearance cluster has some proportion
of its members that correspond to afﬁne frames that give
the geometry of imaged repeated scene content, which are
the inliers of that appearance cluster. The remaining afﬁne
frames are the outliers.

LO-RANSAC samples pairs of afﬁne frames from the ap-
pearance cluster, which are inputted to the proposed mini-
mal solvers. Each pair of afﬁne frames across all appear-
ance clusters has an equi-probable chance of being drawn.
The consensus with the minimal sample is measured by the
number of pairs of afﬁne frames within appearance groups
that are consistent with the hypothesized model, normalized
by the size of each respective group. A non-linear optimizer
following [21] is used as the local optimization step of the
LO-RANSAC estimator.

5. Synthetic Experiments

The proposed solvers are evaluated across several bench-
marks on synthetic data against state-of-the-art solvers. In-
cluded in the benchmarks are two single-view solvers: H2lu

H2.5luλ
H3lusuλ
H3.5luvλ
H4luvsvλ

100

50

y
c
n
e
u
q
e
r
F

0
−15

−5

−10
log10 ∆xfer

RMS (see Sec. 5.1)

0

5

Figure 3: Stability study. Hidden-variable trick solvers are
solid; standard solvers are dashed. The log10 transfer error
is reported. The hidden-variable trick increases stability.

[23], which also incorporates constraints from conjugate
translations, and H4lγ [4], which solves for rectiﬁcation and
change-of-scale, and also two full-homography and radial
distortion solvers, H5λ [7] and H5λ1λ2 [11], which we use
for conjugate translation and lens-istortion estimation. The
bench of state-of-the-art solvers is summarized in Table 1).
The benchmarks are evaluated for 1000 synthetic images
of 3D scenes with known ground-truth parameters. A cam-
era with a random but realistic focal length is randomly ori-
ented and positioned with respect to a 10x10 square meter
scene plane such that the plane is mostly in the camera’s
ﬁeld-of-view. Image resolution is set to 1000x1000 pixels.
Conjugately translated afﬁne frames are generated on the
scene plane such that their scale with respect to the scene
plane is realistic. This modeling choice reﬂects the use of
afﬁne-covariant feature detectors for real images. The con-
jugately translated features are distorted according to the di-
vision model, and, for the sensitivity experiments, isotropic
white noise is added to the distorted afﬁne frames at increas-
ing levels. Performance is characterized by the relative error
of the estimated distortion parameter and by the transfer and
warp errors, which measure the accuracies of the estimated
conjugate translation and rectiﬁcation (see Sec. 5.1 - 5.4).
The proposed solvers have an average solve time from 0.3
to 2 milliseconds over the 1000 synthetic scenes (see also
Sec. B of the supplemental material).

5.1. Transfer Error

The geometric transfer error jointly measures the accu-
racy of an the estimated conjugate translation and lens dis-
tortion. The scene plane is tesselated by a 10x10 square
grid of points { Xi}. Let the translation on the scene plane
induced by the noiseless pre-images of the point correspon-
dences used to estimate ˆHu and ˆλ be t. Then the grid points
are translated by t/(cid:107)t(cid:107) to { X(cid:48)
i}. The grid and its trans-
lation are imaged by the ground-truth lens-distorted cam-

era parameterized by matrix P and division-model parame-
ter λ. The imaged grid is given by ˜xi = f d(PXi, λ) and
the translated grid by ˜x(cid:48)
i, λ), where f d is the
i = f d(PX(cid:48)
the function that transforms from pinhole points to radially-
distorted points. Then the geometric transfer error is deﬁned
as

1
(cid:107)t(cid:107)

∆xfer

i = d(f d([I3 +

(ˆHu − I3)]f (˜xi, ˆλ1), ˆλ2), ˜x(cid:48)

i),
(10)
where d(·, ·) is the Euclidean distance. All solvers except
H5λ1λ2 have the constraint that ˆλ1 = ˆλ2 [11]. The root-
mean-square of transfer errors ∆xfer
RMS for correspondences
{ (˜xi, ˜x(cid:48)
i) } is reported. For two-direction solvers, the trans-
fer error in the second direction is included in ∆xfer
RMS. The
transfer error is used in the stability study, where the solvers
are tested over varying division model parameters and in the
sensitivity study, where the solvers are tested over varying
noise levels with ﬁxed division model parameter. The solver
H4lγ of [4] does not estimate conjugate translations, so it is
not reported. For a derivation of (10) see Sec. A in the sup-
plementary material.

5.2. Numerical Stability

The stability study measures the RMS transfer error
of solvers (see Sec. 5.1) for noiseless afﬁne-frame corre-
spondences across realistic scene and camera conﬁgura-
tions generated as described in the introduction to this sec-
tion. The ground-truth parameter of the division model λ is
drawn uniformly at random from the interval [−6, 0]. For
a reference, the division parameter of λ = −4 is typi-
cal for wide ﬁeld-of-view cameras like the GoPro where
width+height . Fig. 3 reports
the image is normalized by
the histogram of log10 RMS transfer errors. For all new
solvers we evaluate a solver generated from constraints de-
rived with (solid histogram) and without (dashed histogram)
the hidden-variable trick. The hidden-variable trick sig-
niﬁcantly improves the stability of the proposed solvers.
The increased stabilities of the hidden-variable solvers most
likely result from the reduced size of the G-J elimination
problems needed by these solvers. The hidden-variable
solvers are used for the remainder of the experiments.

1

5.3. Noise Sensitivity

The proposed and state-of-the-art solvers solvers are
tested with increasing levels of white noise added to the
afﬁne correspondences induced by the ground-truth conju-
gate translation and lens distortion parameter. The white
noise is parameterized by the standard-deviation of a zero-
mean isotropic Gaussian distribution, and the solvers are
tested at noise levels of σ ∈ {0.1, 0.5, 1, 2}. The ground
truth division model parameter is set to λ = −4, which is
typical for GoPro-type imagery. The solvers are wrapped in

λ
/
)
ˆλ
−
λ
(

0.6

0.4

0.2

0

−0.2

−0.4

−0.6

]
s
l
e
x
i
p
[

S
r
M
e
f
R
x
∆

]
s
l
e
x
i
p
[

S
p
M
r
a
R
w
∆

40

30

20

10

0

40

30

20

10

0

0.1

0.5

1

2

Noise (σ) [pixels]

0.1

0.5

1

2

Noise (σ) [pixels]

H2lu

H2.5luλ

H3lusuλ

H3.5luvλ

H4luvsvλ

H4lγ

H5λ

H5λ1λ2

Figure 4: Comparison of the transfer error (left, see Sec. 5.1) and the relative radial distortion error (right) after 25 iterations
of a simple RANSAC for different solvers over increasingly noisy measurements for 1000 scenes.

5.4. Warp Error

Since the accuracy of scene-plane rectiﬁcation is a pri-
mary concern, we also report the warp error for rectifying
homographies proposed by Pritts et al. [22], which we aug-
ment with the division model for radial lens distortion. A
rectifying homography H∞ of an imaged scene plane is con-
structed from its vanishing line l (see [9]). A round trip be-
tween the image space and rectiﬁed space is made by undis-
torting and rectifying imaged coplanar points by the esti-
mated lens distortion ˆλ and rectifying homography ^H∞ and
then re-warping and distorting the rectiﬁed points into the
image by a synthetic camera constructed from the ground-
truth lens distortion λ and rectifying homography H∞. Ide-
ally, the synthetic camera constructed from the truth would
project the undistorted and rectiﬁed points onto the original
points.

Note that there is an afﬁne ambiguity, denoted A, be-
tween ^H∞ and H∞, which is folded into the expression for
the synthetic camera, namely P(A) = (AH∞)−1, and esti-
mated during computation of the warp error,

∆warp = min

d2(˜xi, f d(P(ˆA)^H∞f (˜xi, ˆλ)), ˆλ),

(11)

(cid:88)

ˆA

i

where d(·, ·) is the Euclidean distance, and {˜xi} are the im-
aged grid points of the scene-plane tesselation as deﬁned
in Sec. 5.1. The root mean square warp error for { ˜xi } is
reported and denoted as ∆warp
RMS. The vanishing line is not di-
rectly estimated by solvers H5λ of [7] and H5λ1λ2 of [11],
so they are not reported.

The proposed solvers—H2.5luλ, H3lusuλ, H3.5luvλ,
H4luvsvλ—estimate rectiﬁcations with less than 5 pixel
RMS warp error ∆warp
RMS, even at the 2 pixel noise level, see
Fig. 5. The need to model radial lens distortion is shown by
the biased ﬁts for the solvers H2lu, H4γ.

0.1

0.5

1

2

Noise (σ) [pixels]

Figure 5: Warp-error comparison (see Sec. 5.4) after 25 it-
erations of a simple RANSAC for different solvers over in-
creasingly noisy measurements for 1000 scenes.

a simple RANSAC-loop, which minimizes the RMS trans-
fer error ∆xfer
RMS over 25 sampled afﬁne-frame correspon-
dences. Results are calculated from the estimate given by
RANSAC and summarized for the 1000 generated scenes as
boxplots. The interquartile range is contained within the ex-
tents of a box, and the median is the horizontal line dividing
the box.

As shown in Fig. 4 the proposed solvers give the
most accurate joint estimation of conjugate translation
and division model parameter as measured by the RMS
transfer error ∆xfer
RMS and relative error of estimated divsion
model parameter. As expected,
the minimal parame-
terization of the radially-distorted conjugate translation
solvers—H2.5luλ, H3lusuλ, H3.5luvλ, H4luvsvλ—show
signiﬁcantly less sensitivity to noise than the overparme-
terized radially-distorted homography solvers H5λ and
H5λ1λ2 for both measures. The solver H2lu shows signiﬁ-
cant bias (see the transfer error boxplots in Fig. 4) since it
does not model lens distortion.

Original image

H2lu + LO; 11.2% inliers

H2.5luλ+LO; 20.4% inliers H3.5luvλ+LO; 20.2% inliers

Figure 6: GoPro Hero 4 at the wide setting for different solvers. Results from LO-RANSAC (see Sec. 4) for H2lu, which
omits distortion, and the proposed solvers H2.5luλ and H3.5luvλ. The top row has rectiﬁcations after local optimization
(LO); The bottom row has undistortions estimated from the best minimal sample. LO-RANSAC cannot recover from the poor
initializations by H2lu (column 2). The proposed solvers in columns 3 and 4 give a correct rectiﬁcation. The bottom left has
a chessboard undistorted using the division parameter estimated from the building facade by H2.5luλ+LO.

6. Real Images

In the qualitative experiments on real images shown in
Figs. 1 and 2, we tested the proposed solvers on Go-
Pro4 Hero 4 images with increasing ﬁeld-of-view settings,
namely narrow, medium and wide, where a wider ﬁeld-of-
view setting generates more extreme radial distortion since
the boundary of the lens is used. The proposed method gen-
erates high-quality rectiﬁcations at all the ﬁeld-of-view set-
tings. More real-image experiments, including results for
cameras with radial distortions that are typical for mobile
phone cameras and ﬁsheye lenses (e.g., 8mm lens) can be
found in Sec. C in the supplementary material.

The experiment shown in Fig. 6 compares the per-
formance of two of the proposed solvers, H2.5luλ and
H3.5luvλ, to H2lu in a state-of-the-art local-optimization
(LO) framework (see Sec. 4) on an GoPro Hero 4 image at
the wide ﬁeld-of-view setting. The two proposed solvers
accurately estimate the division-model parameter (see the
undistorted reference chessboard in Fig. 6) and the rectiﬁ-
cation, while the LO-variant using the H2lu solver is unable
to recover the lens distortion parameter. See Fig. C.2 in the
supplemental material for results on an image at the medium
ﬁeld-of-view setting.

7. Conclusions

This paper proposes the ﬁrst minimal solvers that jointly
solve for the afﬁne rectiﬁcation of an imaged scene plane
and a camera’s radial lens distortion from coplanar repeated
patterns. Rectiﬁcation and radial lens distortion are recov-

ered from only one conjugately translated afﬁne-covariant
feature or two independently translated similarity-covariant
features. Synthetic experiments demonstrate the good sta-
bility and superior robustness to noise with respect to mea-
sures of rectiﬁcation accuracy and lens-distortion estima-
tion of the proposed solvers as compared to the state-of-
the-art. However, the polynomial constraint equations that
arise from conjugate translations distorted by the division
model need to be transformed with the hidden-variable
trick to generate stable solvers, though. Qualitative real-
image experiments demonstrate high-quality rectiﬁcations
for highly-distorted wide-angle lenses, which was not pos-
sible using the state-of-the-art. Future work could include
conditionally sampling the measurements during robust es-
timation to take into account their size, relative distance
from each other, or distance from the distortion center. We
expect these factors have a big impact on rectiﬁcation qual-
ity, but this study was beyond scope for this paper.

8. Acknowledgements

James Pritts was supported by the grants MSMT
LL1303 ERC-CZ and SGS17/185/OHK3/3T/13, Zuzana
Kukelova by the Czech Science Foundation Project GACR
P103/12/G084, Viktor Larsson by the strategic research
projects ELLIIT and eSSENCE, Swedish Foundation for
Strategic Research project ”Semantic Mapping and Visual
Navigation for Smart Robots” (grant no. RIT15-0038) and
Wallenberg Autonomous Systems and Software Program
(WASP), and Ondrej Chum by the grant MSMT LL1303
ERC-CZ.

[22] J. Pritts, D. Rozumnyi, M. P. Kumar, and O. Chum. Coplanar

repeats by energy minimization. In BMVC, 2016. 7

[23] F. Schaffalitzky and A. Zisserman. Geometric grouping of
repeated elements within images. In BMVC, 1998. 2, 3, 4, 6
[24] A. Vedaldi and B. Fulkerson. VLFeat: An open and portable
http://www.

library of computer vision algorithms.
vlfeat.org/, 2008. 2, 3

[25] H. Wildenauer and B. Micusík. Closed form solution for
radial distortion estimation from a single vanishing point. In
BMVC, 2013. 1, 2

[26] C. Wu, J. M. Frahm, and M. Pollefeys. Repetition-based
dense single-view reconstruction. In CVPR, 2011. 1
[27] Z. Zhang, A. Ganesh, X. Liang, and Y. Ma. TILT: transform
invariant low-rank textures. IJCV, 99(1):1–24, 2012. 1

References

[1] D. Aiger, D. Cohen-Or, and N. Mitra. Repetition maximiza-
tion based texture rectiﬁcation. Computer Graphics Forum,
31(2):439–448, 2012. 1

[2] M. Antunes, J. P. Barreto, D. Aouada, and B. Ottersten. Un-
supervised vanishing point detection and camera calibration
from a single manhattan image with radial distortion.
In
CVPR, July 2017. 2

[3] R. Arandjelovi´c and A. Zisserman. Three things everyone
should know to improve object retrieval. In CVPR, 2012. 5
[4] O. Chum and J. Matas. Planar afﬁne rectiﬁcation from

change of scale. In ACCV, 2010. 1, 2, 4, 6

[5] O. Chum, J. Matas, and v. Obdržálek. Enhancing RANSAC
by generalized model optimization. In ACCV, 2004. 5
[6] D. Cox, J. Little, and O. D. Using algebraic geometry.

Springer, 2004. 4

[7] A. W. Fitzgibbon. Simultaneous linear estimation of multiple
view geometry and lens distortion. In CVPR, 2001. 2, 3, 4,
6, 7, 12

[8] D. R. Grayson and M. E. Stillman. Macaulay 2, a software

system for research in algebraic geometry, 2002. 5

[9] R. I. Hartley and A. W. Zisserman. Multiple View Geome-
try in Computer Vision. Cambridge University Press, ISBN:
0521540518, second edition, 2004. 1, 2, 7

[10] Z. Kukelova, M. Bujnak, and T. Pajdla. Automatic generator

of minimal problem solvers. In ECCV, 2008. 2, 4

[11] Z. Kukelova, J. Heller, B. M., and T. Pajdla. Radial distortion

homography. In CVPR, 2015. 1, 2, 6, 7

[12] V. Larsson, K. Åström, and M. Oskarsson. Efﬁcient solvers
for minimal problems by syzygy-based reduction. In CVPR,
2017. 2, 4

[13] V. Larsson, K. Åström, and M. Oskarsson. Polynomial

solvers for saturated ideals. In ICCV, 2017. 2, 4, 5

[14] D. Lowe. Distinctive image features from scale-invariant

keypoints. IJCV, 60(2):91–110, 2004. 2, 3, 5

[15] M. Lukáˇc, D. Sýkora, K. Sunkavalli, E. Shechtman, O. Jam-
riška, N. Carr, and T. Pajdla. Nautilus: Recovering regional
symmetry transformations for image editing. ACM Trans.
Graph., 36(4):108:1–108:11, July 2017. 1

[16] J. Matas, O. Chum, M. Urban, and T. Pajdla. Robust wide
baseline stereo from maximally stable extremal regions. In
BMVC, 2002. 2, 3, 5

[17] K. Mikolajczyk and C. Schmid. A performance evaluation

of local descriptors. PAMI, 2004. 5

[18] K. Mikolajczyk and C. Schmid. Scale and afﬁne invariant

interest point detectors. volume 60, 2004. 2, 3, 5

[19] D. Mishkin, F. Radenovic, and J. Matas. Learning dis-
CoRR,

criminative afﬁne regions via discriminability.
abs/1711.06704, 2017. 2, 3

[20] Š. Obdržálek and J. Matas. Object recognition using local

afﬁne frames on distinguished regions. In BMVC, 2002. 5

[21] J. Pritts, O. Chum, and J. Matas. Detection, rectiﬁcation and
segmentation of coplanar repeated patterns. In 2014 IEEE
Conference on Computer Vision and Pattern Recognition,
2014. 1, 2, 5

A. Transfer Error

torted point correspondence y ↔ y(cid:48) as

I3 +

l(cid:62) = I3 +

[I3 + ul(cid:62) − I3]

u
(cid:107)t(cid:107)

= I3 +

[Hu − I3].

(14)

1
(cid:107)t(cid:107)
1
(cid:107)t(cid:107)

The derivation of (14) gives the form of transformation used
in the transfer error ∆xfer
RMS deﬁned in Sec. 5.1, which maps
from the undistorted points of the grid {xi} to their trans-
lated correspondences {x(cid:48)

i}.

B. Computational Complexity

Table B.1 lists the elimiation template sizes for the pro-
posed solvers. The average time to compute the solutions
for a given input for a solver is directly proportional to the
elimination template size. The solvers are implemented in
MATLAB and C++. Signiﬁcantly faster implementations
are possible with a pure C++ port. Still the solvers are sufﬁ-
ciently fast for use in RANSAC. The proposed solvers have
an average solve time from 0.3 to 2 milliseconds.

H2.5luλ

H3lusuλ

H3.5luvλ

H4luvsvλ

14x18

24x26

54x60

76x80

Table B.1: Template sizes for the proposed solvers.

C. Extended Experiments

The extended real-data experiments in the following
pages include (i) images with lesser radial distortion from
consumer cameras and mobile phones;
the images also
demonstrate the proposed method’s effectiveness on diverse
scene content, (ii) images for very wide ﬁeld-of-view lenses
(8mm and 12mm), (iii) and an additional local-optimiza-
tion experiment similar to the one in Fig. 6 on a GoPro
Hero 4 image taken with its medium ﬁeld-of-view setting,
which further demonstrates the need for a minimal solver
that jointly estimates lens distortion with afﬁne-rectiﬁcation
to achieve an accurate undistortions and rectiﬁcations.

The scene plane is tessellated by a 10x10 square grid
of points, denoted { Xi }, with a 1 meter spacing between
adjacent points. Suppose that y ↔ y(cid:48) is an undistorted
point correspondence induced by the conjugate translation
Hu = [I3 + ul(cid:62)] in the imaged scene plane (here we as-
sume that su
i = 1 since we speak about an individual point
correspondence).

Points { Xi } are translated by 1 meter on the scene plane
in the direction of translation induced by the preimage of
the point correspondence y ↔ y(cid:48) giving the translated grid
{ X(cid:48)
i }. The purpose of constructing the grid and it’s trans-
lation is to uniformly cover the scene plane that the camera
images in its ﬁeld of view. In this way, the accuracy of the
conjugate translation and lens-distortion parameter estima-
tion can be measured across most of the image. The conju-
gate translation Hu is not used directly because the magni-
tude of translation may span the extent of the scene plane,
so applying it to the tessellation would transform the grid
out of the ﬁeld of view.

Let the camera be parameterized by the camera ma-
trix P = (AH)−1 (see Sec. 5.4 for the deﬁnition of the
camera matrix) that pointwise maps the scene plane Π to
the imaged scene plane π and division model parameter
λ. The preimages of the undistorted point correspondence
y ↔ y(cid:48) in the scene-plane coordinate system is, respec-
tively, βY = P−1y and β(cid:48)Y(cid:48) = P−1y(cid:48). The translation
t of the preimages in the scene plane coordinate system is
t = Y − Y(cid:48) = (cid:0)tx, ty, 0(cid:1)(cid:62)

.

Then (cid:107)t(cid:107) is the magnitude of translation between the re-
peated scene elements in the scene-plane coordinate system.
Denote the homogeneous translation matrix T(t) to be the
matrix constructed from t as

T(t) =


1
0
0 1

0
0



 .

tx
ty
1

The translation of the grid points by unit distance is given
by X(cid:48)
i = T(t/(cid:107)t(cid:107))Xi. Recall from (1) that a conjugate
translation has the form PT(·)P−1. Using (2), the conjugate
translation of unit distance in the direction of point corre-
spondences y ↔ y(cid:48) is





tx/(cid:107)t(cid:107)
ty/(cid:107)t(cid:107)
1






P−(cid:62)






(cid:62)




0
0

1

Hu/(cid:107)t(cid:107) = PI3P−1 + P

= [I3 +

u
(cid:107)t(cid:107)

l(cid:62)].

The unit conjugate translation Hu/(cid:107)t(cid:107) can be written in
terms of the conjugate translation Hu induced by the undis-

(12)

(13)

10

Figure C.1: Narrow ﬁeld-of-view and diverse scene-content experiments for H2.5luλ+LO. The proposed method works well
if the input image has little or no radial lens distortion. This imagery is typical of consumer cameras and mobile phone
cameras. The images are diverse and contain unconventional scene content. Input images are on the top row; undistorted
images are on the middles row, and the rectiﬁed images are on the bottom row.

Original image

H2lu+LO; 20.3% inliers

H2.5luλ+LO; 31.2% inliers H3.5luvλ+LO; 30.7% inliers

Figure C.2: GoPro Hero 4 at the medium setting for different solvers. Results from LO-RANSAC (see Sec. 4) for H2lu, which
omits distortion, and the proposed solvers H2.5luλ and H3.5luvλ. The top row has rectiﬁcations after local optimization
(LO); The bottom row has undistortions estimated from the best minimal sample. LO-RANSAC fails from the poor initial-
izations by H2lu (column 2). The proposed solvers in columns 3 and 4 give a correct rectiﬁcation. The bottom left has a
chessboard undistorted using the division parameter estimated from the building facade by H2.5luλ+LO.

11

Figure C.3: Very wide-angle images undistorted and rectiﬁed with H2.5luλ+LO. The left column is an image from an 8mm
lens, and the right column is from a 12mm lens. The top row contains the input images; the middle row contains the
undistorted images, and the bottom row contains the rectiﬁed images. The division model [7] used for radial lens distortion
has only 1 parameter, which may impose limits for modeling extreme lens distortion.

12

Afﬁne-covariant feature detections

Inlying afﬁne-covariant features

Undistorted

Undistorted and rectiﬁed

Figure C.4: Problem difﬁculty and method robustness The input to the method is ungrouped afﬁne-covriant features (top left).
Common problems include missed detections of repeated texture, duplicate detections, and detections due to compression
artifacts, all of which are visible in this example. The inliers with respect to the total number of detected features can be a
very small proportion (top right). Still the method can estimate accurate undistortion (bottom left) and afﬁne rectiﬁcation
(bottom right) even from a very sparse sampling of the inlying afﬁne-covariant features on the scene plane (top right).

13

Radially-Distorted Conjugate Translations

James Pritts1
Visual Recognition Group, CTU in Prague1

Zuzana Kukelova1

Viktor Larsson2

Ondˇrej Chum1
Centre for Mathematical Sciences, Lund University2

8
1
0
2
 
n
u
J
 
1
2
 
 
]

V
C
.
s
c
[
 
 
3
v
9
3
3
1
1
.
1
1
7
1
:
v
i
X
r
a

Abstract

This paper introduces the ﬁrst minimal solvers that
jointly solve for afﬁne-rectiﬁcation and radial lens distor-
tion from coplanar repeated patterns. Even with imagery
from moderately distorted lenses, plane rectiﬁcation using
the pinhole camera model is inaccurate or invalid. The pro-
posed solvers incorporate lens distortion into the camera
model and extend accurate rectiﬁcation to wide-angle im-
agery, which is now common from consumer cameras. The
solvers are derived from constraints induced by the conju-
gate translations of an imaged scene plane, which are in-
tegrated with the division model for radial lens distortion.
The hidden-variable trick with ideal saturation is used to
reformulate the constraints so that the solvers generated by
the Gröbner-basis method are stable, small and fast.

Rectiﬁcation and lens distortion are recovered from ei-
ther one conjugately translated afﬁne-covariant feature or
two independently translated similarity-covariant features.
The proposed solvers are used in a RANSAC-based estima-
tor, which gives accurate rectiﬁcations after few iterations.
The proposed solvers are evaluated against the state-of-
the-art and demonstrate signiﬁcantly better rectiﬁcations on
noisy measurements. Qualitative results on diverse imagery
demonstrate high-accuracy undistortions and rectiﬁcations.
The source code is publicly available1.

1. Introduction

Scene-plane rectiﬁcation is used in many classic
computer-vision tasks,
including single-view 3D recon-
struction, camera calibration, grouping coplanar symme-
tries, and image editing [26, 21, 15]. In particular, the afﬁne
rectiﬁcation of a scene plane transforms the camera’s prin-
cipal plane so that it is parallel to the scene plane. This re-
stores the afﬁne invariants of the imaged scene plane, which
include parallelism of lines and translational symmetries
[9, 21]. There is only an afﬁne transformation between the
afﬁne-rectiﬁed imaged scene plane and its real-world coun-
terpart. The removal of the effects of perspective imaging is
helpful to understanding the geometry of the scene plane.

1https://github.com/prittjam/repeats

Figure 1: Input (top left) is a distorted view of a scene plane,
and the outputs (top right, bottom) are the the undistorted
and rectiﬁed scene plane. The method is fully automatic.

Wide-angle imagery that has signiﬁcant lens distortion
is common since consumer photography is now dominated
by mobile-phone and GoPro-type cameras. High-accuracy
rectiﬁcation from wide-angle imagery is not possible with
only pinhole camera models [11, 25]. Lens distortion can be
estimated by performing a camera calibration apriori, but a
fully automated method is desirable.

Several state-of-the-art planar-rectiﬁcation methods as-
sume a pinhole camera model, which ignores the effect of
lens distortion [1, 4, 15, 27]. Pritts et al. [21] attempt to up-
grade the pinhole camera model with radial lens distortion
by giving an initial guess of the scene plane’s rectiﬁcation
that is consistent with a pinhole camera to a non-linear op-
timization that incorporates a lens-distortion model. How-
ever, even with relaxed thresholds, a robust estimator (i.e.
RANSAC) will discard measurements that capture the most
extreme effects of lens distortion, especially around the
boundary of the image, since these measurements are not
consistent with the pinhole-camera assumption. Thus, fail-
ing to account for lens distortion while labeling the mea-

1

narrow

medium

wide

Figure 2: GoPro Hero 4 imagery. (top row) Input images
taken at different ﬁeld-of-view settings. (bottom row) Rec-
tiﬁed results.

surements as outliers, as done during a RANSAC iteration,
can give biased ﬁts that underestimate the camera’s lens-
distortion [11], which, in turn, reduces rectiﬁcation accu-
racy.

This paper introduces the ﬁrst minimal solvers that
jointly solve for the afﬁne rectiﬁcation of an imaged scene
plane and a camera’s radial lens distortion. The solvers are
derived from constraints induced by the conjugate trans-
lations of an imaged scene plane (see Sec. 2 for details),
which are integrated with the division model of radial dis-
tortion [7]. Despite the simple formulation of the division
model, it is accurate for even wide-angle lenses [7]. In addi-
tion, the solvers estimate the vanishing translation direction
of the corresponded points used for input.

Two types of solvers are introduced: one-direction
solvers, which require 3 coplanar point correspondences
translate in the same direction, and two-direction
that
solvers, which require 4 coplanar point correspondences, 2
of which translate in one-direction and the remaining 2 in
a different direction. Covariant feature detectors are used
to extract the needed point correspondences [14, 16, 18,
19, 24]. The solvers are used in a RANSAC-based frame-
work for robust rectiﬁcation estimation. With one or two-
correspondence sampling, an accurate undistortion and rec-
tiﬁcation is quickly recovered, even for difﬁcult scenes.

Fitzgibbon used a one-parameter division model to de-
velop a minimal solver for jointly estimating lens distortion
with a fundamental matrix or homography [7]. Kukelova et
al. [11] proposed an extension to [7] for homographies to
model two-views from cameras with different radial lens
distortions. These two-view solvers can jointly estimate
lens distortion and conjugate translations, but are overpa-
rameterized for this task, which can result in inaccurate es-
timates as is shown by the synthetic experiments in Sec. 5.
Wildenauer et al. [25] and Antunes et al. [2] are two meth-

ods that use constraints induced by imaged parallel lines to
jointly solve for their vanishing point and the division model
parameter, but but both require a multi-model estimation to
recover scene-plane rectiﬁcation (i.e. 2 consistent vanishing
points).

The systems of polynomial equations induced from the
constraints arising from joint estimation of conjugate trans-
lation with the division-model parameter are solved using
an algebraic method based on Gröbner bases. Automated
solver-generators using the Gröbner basis method [10, 12]
were recently used to generate solvers for several problems
in multi-view geometry [10, 13, 12, 11]. However, straight-
forward application of an automated solver-generator to the
proposed problem resulted in unstable solvers (see Sec. 5).
Therefore, we transformed the constraints to simplify the
structure of the systems of polynomial equations, while
explicitly accounting for the parasitic solutions that arose
from the new formulation. The new formulation resulted in
solvers with increased stability and speed.

The problem of rectiﬁcation is closely coupled with the
detection of coplanar repeats in a classic chicken-and-egg
scenario: rectiﬁcation is easy if the repeats are grouped,
and repeats are more easily grouped if the afﬁne invari-
ants of the rectiﬁed plane are available [21]. Most methods
tentatively group repeats from their local texture, which is
veriﬁed later by a hypothesized rectiﬁcation. Methods us-
ing this approach include Schaffalitzky et al. [23], which,
similar to the solvers proposed in this paper, uses con-
straints induced by conjugate translations to recover the
scene-plane’s vanishing line, and Chum et al. [4], which
uses the constraint that coplanar repeats are equiareal in the
scene-plane’s afﬁne-rectiﬁed image. None of these meth-
ods account for lens distortion, and do not perform well on
imagery with signiﬁcant lens distortion (see Sec. 6).

2. Problem Formulation

Assume that the scene plane π and a camera’s image
plane π(cid:48) are related point-wise by the homography P, so
that αix(cid:48)
i ∈ π(cid:48).
i = PXi, where αi is a scalar, Xi ∈ π and x(cid:48)
Let Xi and X(cid:48)
i be two points on the scene plane π such that
X(cid:48)
i − Xi = t. By encoding t in the homogeneous transla-
tion matrix T, the points Xi and X(cid:48)
i as imaged by camera P
can be expressed as

αix(cid:48)

i = PX(cid:48)

i = PTXi = PTP−1xi = Huxi,

(1)

where the homography Hu = PTP−1 is called a conjugate
translation because of the form of its matrix decomposition
and points xi and x(cid:48)
i are in correspondence with respect to
the conjugate translation Hu, which we denote xi ↔ x(cid:48)
i
[9, 23]. Decomposing Hu into its projective components

gives

αix(cid:48)

i = Huxi =


PI3P−1 + P











P−(cid:62)





tx
ty
1

(cid:62)






 xi


0
0

1

= [I3 + su

i ul(cid:62)] · xi

(2)

where I3 is the 3 × 3 identity matrix, and

• line l is the imaged scene plane’s vanishing line,

• point u is the vanishing direction of translation, which

must meet the vanishing line l, i.e., l(cid:62)u = 0,

• and scalar su

rection u for the point correspondence ˜xi ↔ ˜x(cid:48)

i is the magnitude of translation in the di-
i [23].

Note that (2) holds only for points projected by a pinhole
camera viewing a scene plane, which is parameterized by
the homography P as deﬁned above. For every real camera,
some amount of radial distortion is always present, so for
(2) to hold, the measured image points ˜xi and ˜x(cid:48)
i must ﬁrst
be undistorted. We use the one-parameter division model
to parameterize the radial lens distortion [7], which has the
form

f (˜xi, λ) = (cid:0)˜xi, ˜yi, 1 + λ(˜x2
where the distortion center is given;
center-subtracted measurements from a feature detector.

i + ˜y2

i )(cid:1)(cid:62)

i.e., ˜xi, ˜yi are the

(3)

,

In this work we incorporate constraints induced by a con-
jugate translation as derived in (2) with the division model
deﬁned in (3) to accurately rectify imaged scene planes
from lens-distorted cameras. Since the unknown division
model parameter is exclusively encoded in the homoge-
neous coordinate, the relation for conjugate translations can
be directly augmented to model lens distortion, namely,

αif (˜x(cid:48)

i, λ) = Huf (˜xi, λ) = [I3 + su

i ul(cid:62)] · f (˜xi, λ),

(4)

where αi is some non-zero scalar, and ˜xi ↔ ˜x(cid:48)
correspondence.

i is a point

3. Solvers

The model for radially-distorted conjugate translations
(i) di-
in (4) deﬁnes the unknown geometric quantities:
vision-model parameter λ, (ii) scene-plane vanishing line
l = (cid:0)l1, l2, l3
,
(iii) vanishing translation direction
u = (cid:0)u1, u2, u3
(cid:1)(cid:62)
tensions), (iv) scale of translation su
i
˜xi ↔ ˜x(cid:48)

(see Sec. 3.2 for the two-direction ex-
for correspondence

i, (v) and the scalar parameter αi.

(cid:1)(cid:62)

The solution for the vanishing line l is constrained to the
afﬁne subspace l3 = 1 of the real-projective plane, which
makes it unique. This inhomogeneous choice of l is unable
to represent the pencil of lines that pass through the ori-
gin. If this degeneracy is encountered, then the scale of l

is ﬁxed by setting l2 = 1 instead. Solver variants for both
constraints are generated for all of the proposed solvers. In
practice, this degeneracy is rarely encountered. If the l3 = 1
solver variant suffers from bad numerical conditioning, then
the l2 = 1 variant can be activated and its solutions tested
for consensus with the measurements (see Sec. 4). Without
loss of generality the derivations below assume that l3 = 1.
The vanishing direction u must meet the vanishing line l,
which deﬁnes a subspace of solutions for u. The magnitude
of u is set to the translation scale su
1 of the ﬁrst correspon-
dence, which deﬁnes a unique solution

l(cid:62)u = l1u1 + l2u2 + u3 = 0 ∧ (cid:107)u(cid:107) = su
1 .

(5)

The relative scale of translation ¯su
˜xi ↔ ˜x(cid:48)
that ¯su

i for each correspondence
i with respect to the magnitude of (cid:107)u(cid:107) is deﬁned so
1 = 1.

i /(cid:107)u(cid:107). Note that ¯su

i = su

In this paper we propose four different minimal solvers
for different variants of the problem of radially-distorted
conjugate translations based on different translation direc-
tions and relative scales ¯su
i . These variants are motivated
by the types of covariant feature detectors used to extract
point correspondences [14, 16, 18, 19, 24]. Each afﬁne-
covariant feature deﬁnes an afﬁne frame, i.e. an ordered
triplet of points. Thus, 1 afﬁne-frame correspondence pro-
vides the 3 point correspondences that translate in the same
direction with the same scale. This is sufﬁcient input for
the one-directional solvers. A visualization of the features
is provided in Fig. C.4 of the supplemental material. In the
case of similarity-covariant features, such as DoG [14], only
a similarity frame can be constructed. A correspondence of
similarity frames gives 2 point correspondences that trans-
late jointly. Two correspondences of similarity-covariant
features of different direction of the translation provide suf-
ﬁcient constraints for the two directional solvers.

1 = ¯su

1 = ¯su

Two one-direction solvers are proposed, which require
3 (2.5) coplanar point correspondences that translate in the
same direction. The “3-point” solver H3lusuλ assumes that
two of the point correspondences have the same scale of
translation (i.e. ¯su
2 = 1), and the third point corre-
spondence has an unknown relative scale of the translation
¯su
3 . The “2.5-point” solver H2.5luλ assumes that all 3 point
correspondences have the same relative scales of transla-
tion, i.e. ¯su

2 = ¯su
two two-direction solvers are proposed,
which require 4 (3.5) coplanar point correspondences, 2 of
which translate in one-direction u and the remaining 2 in a
different direction v. Here the “4-point” solver H4luvsvλ
assumes that the ﬁrst two point correspondences translate
in the direction u with the same relative scale of translation,
i.e., ¯su
2 = 1. The remaining two point correspon-
dence translate in the direction v with arbitrary translation
magnitudes, i.e., the relative scales of translations of these
two correspondences with respect to (cid:107)v(cid:107) = sv
3 = 1

In addition,

1 = ¯su

3 are ¯sv

3 = 1.

and an unknown relative scale ¯su
4 .

The “3.5-point” H3.5luvλ solver assumes that the rela-
1 and

2 = 1 with respect to (cid:107)u(cid:107) = su
4 = 1 with respect to (cid:107)v(cid:107) = sv
3 .

tive scales ¯su
3 = ¯sv
¯sv

1 = ¯su

In all proposed solvers the scalar values αi are elimi-
nated from (4). This is done by multiplying (4) by the skew-
symmetric matrix [f (˜x(cid:48)
i, λ)]×. The fact that the join of a
point xi with itself [xi]×xi is 0 gives,





˜y(cid:48)
i
−˜x(cid:48)
i
0





×

0 − ˜w(cid:48)
i
˜w(cid:48)
0
i
˜x(cid:48)
−˜y(cid:48)
i
i

1 + ¯su
i u1l1
¯su
i u2l1
¯su
i u3l1



¯su
i u1l2
1 + ¯su
¯su
i u3l2

i u2l2

¯su
i u1
¯su
i u2
1 + ¯su

i u3











 = 0,

˜xi
˜yi
˜wi

(6)

i + ˜y2

where ˜wi = 1 + λ(˜x2
i ).
The matrix equation in (6) contains three polynomial equa-
tions from which only two are linearly independent, since
the skew-symmetric matrix [f (˜x(cid:48)

i = 1 + λ(˜x(cid:48)2

i ) and ˜w(cid:48)

i, λ)]× is rank two.

i + ˜y(cid:48)2

To solve the systems of polynomial equations result-
ing from the presented problems, we use the Gröbner ba-
sis method [6]. To generate efﬁcient solvers we used the
automatic generator of Gröbner basis solvers proposed in
[10, 12]. However, for our problems the coefﬁcients of
the input equations are not fully independent. This means
that using the default settings for the automatic generator
[10, 12] that initialize the coefﬁcients of equations by ran-
dom values from Zp does not lead to correct solvers. To ob-
tain working Gröbner basis solvers, one has to create correct
problems instances with values from Zp for the automatic
generator initialization.

The straightforward application of the automatic gen-
erator [10, 12] to the needed constraints with correct co-
efﬁcients from Zp resulted in large templates and unsta-
ble solvers, especially for the two-direction problems. The
Gröbner basis solvers generated for the original constraints
have template matrices with sizes 80 × 84, 74 × 76, 348 ×
354, and 730 × 734 for the H2.5luλ, H3lusuλ, H3.5luvλ
and H4luvsvλ problems, respectively. Therefore, we use
the hidden-variable trick [6] to eliminate the vanishing
translation directions together with ideal saturation [13] to
eliminate parasitic solutions. The reformulated constraints
are simpler systems in only 3 or 4 unknowns, and the solvers
generated by the Gröbner basis method are smaller and
more stable. The reduced eliminiation template sizes are
also summarized in Sec. B of the supplemental material.
Next, we describe the solvers based on the hidden-variable
trick in more detail.

3.1. One-Direction Solvers

For the “3-point” one-direction H3lusuλ solver we have
2 = 1. Therefore the constraints (6) result in two

1 = ¯su
¯su

u
l
2
H

[23]

Reference
Distortion

H∞ (cid:88)
2
1

# points
# solutions

λ
u

l
5
.
2
H

λ
u
s
u
l
3
H

λ
v
u
l
5
.
3
H

λ
v
s
v
u

l
4
H

(cid:88) (cid:88) (cid:88) (cid:88)
(cid:88) (cid:88) (cid:88) (cid:88) (cid:88)
4
3.5
2.5
1
6
4

4
4

3
2

γ
l
4
H

[4]

2
λ
1
λ
5
H

[10]
(cid:88)

5
5

λ
5
H

[7]
(cid:88)

5
18

Table 1: Proposed solvers (grey) vs. state-of-the-art.

pairs of linearly independent equations without the scale pa-
rameter ¯su
i for i = 1, 2, and two linearly independent equa-
tions with an unknown relative scale ¯su
3 for the third point
correspondence, i.e., i = 3. Additionally, we have the or-
thogonality constraint in (5). All together we have seven
equations in seven unknowns (l1, l2, u1, u2, u3, ¯su

3 , λ).

Note, that these equations are linear with respect to the
vanishing translation direction u. Therefore, we can rewrite
the seven equations as

M(l1, l2, ¯su

3 , λ)

= 0

(7)













u1
u2
u3
1

3 , λ) is a 7 × 4 matrix which elements are

where M(l1, l2, ¯su
polynomials in (l1, l2, ¯su
Since M(l1, l2, ¯su

3 , λ).

3 , λ) has a null vector, it must be rank
deﬁcient. Therefore, all the 4 × 4 sub-determinants of
(cid:1) = 35
3 , λ) must equal zero. This results in (cid:0)7
M(l1, l2, ¯su
polynomial equations which only involve four unknowns.

4

Unfortunately,

the formulation (7) introduces a one-
dimensional family of false solutions. These are not present
in the original system and corresponds to solutions where
the ﬁrst three columns of M become rank deﬁcient. In this
case there exist null vectors to M where the last element of
the vector is zero, i.e. not on the same form as in (7).

These false solutions can be removed by saturating any
of the 3 × 3 sub-determinants from the ﬁrst three columns
of M. The matrix M has the following form,

M(l1, l2, ¯su

3 , λ) =

(8)













m11 m12
m21 m22
m31
m41
m51 m52
m61
l1

0 m14
0 m24
0 m33 m34
0 m43 m44
0 m54
0 m63 m64
1
l2

0













where mij are polynomials in l1, l2, ¯su
3 and λ. We choose to
saturate the 3×3 sub-determinant corresponding to the ﬁrst,
second and last row since it reduces to only the top-left 2×2

sub-determinant, i.e. m11m22 − m12m21, which is only a
quadratic polynomial in the unknowns. The other 3 × 3 de-
terminants are more complicated and leads to larger polyno-
mial solvers. Using the saturation technique from Larsson
et al. [13] we were able to create a polynomial solver for
this saturated ideal. The size of the elimination template is
24 × 26. Note that without using the hidden-variable trick
the elimination template was 74 × 76.

2 = ¯su

For the H2.5luλ solver we can use the same hidden-
1 = ¯su
variable trick. In this case ¯su
3 = 1 and therefore
the matrix M in (7) contains only three unknowns l1, l2 and
λ. The minimal number of point correspondences necessary
to solve this problem is 2.5. Therefore, for this problem we
can drop one of the equations from (6), e.g., for i = 3, and
the matrix M in (7) has size 6 × 4. In this case all 4 × 4
sub-determinants of M result in 15 equations in 3 unknowns.
this introduces a one-
dimensional family of false solutions. The matrix M has a
similar structure as in (8) and again it is sufﬁcient to sat-
urate top-left 2 × 2 sub-determinant. For this formulation
we were able to create a solver with template size 14 × 18
(compared with 80×84 without using hidden-variable trick)

Similar to the 3 point case,

3.2. Two-Direction Solvers

(cid:1)(cid:62)

(cid:1)(cid:62)

and v = (cid:0)v1, v2, v3

In the case of the two-direction H4luvsvλ solvers, the
input equations for two vanishing translation directions u =
(cid:0)u1, u2, u3
can be separated into
two sets of equations, i.e., the equations containing u and
the equations containing v. Note that in this case we have
two equations of the form (5), i.e., the equation for the di-
rection u and the equation for the direction v and we have
an unknown relative scale ¯sv
4 . Therefore, the ﬁnal system
of 10 equations in 10 unknowns can be rewritten using two
matrix equations as

M1(l1, l2, λ)

= 0, M2(l1, l2, ¯sv

4 , λ)

= 0 (9)













u1
u2
u3
1













v1
v2
v3
1

where M1 and M2 are 5 × 4 matrices where the elements are
polynomials in (l1, l2, λ) and (l1, l2, ¯sv

4 , λ) respectively.

Again all 4 × 4 sub-determinants of M1 and M2 must con-
currently equal zero. This results in 5 + 5 = 10 polynomial
equations in four unknowns (l1, l2, ¯sv
4 , λ). In this case, only
39 additional false solutions arise from the hidden-variable
trick. The matrices M1 and M2 have a similar structure as in
(8) and again it is sufﬁcient to saturate the top-left 2 × 2
sub-determinants to remove the extra solutions. By saturat-
ing these determinants we were able to create a solver with
template size 76 × 80 (previously 730 × 734).

for the “3.5-point” two-direction H3.5luvλ
Finally,
solver ¯su
4 = 1 so we can drop
one of the equations from the constraint (6), e.g., for i = 4.

2 = 1 and ¯sv

1 = ¯su

3 = ¯sv

Therefore, the matrix M2 from (9) has size 4 × 4 and it con-
tains only 3 unknowns (l1, l2, λ). In this case all 4 × 4 sub-
determinants of M1 and M2 result in 5 + 1 = 6 polynomial
equations in three unknowns (l1, l2, λ).

In-
For this case we get 18 additional false solutions.
vestigations in Macaulay2 [8] revealed that for this particu-
lar formulation it was sufﬁcient to only saturate the top-left
2 × 2 sub-determinant of M1 and the top-left element of M2.
Saturating these we were able to create a polynomial solver
with a template size of 54 × 60 (previously 348 × 354).

4. Robust Estimation

The solvers are used in a LO-RANSAC-based robust-
estimation framework [5]. Afﬁne-covariant features are
extracted from the image for input to the solvers. Afﬁne-
covariant features are highly repeatable on the same imaged
scene texture with respect to signiﬁcant changes of view-
point and illumination [17]. Their proven robustness in
the multi-view correspondence problem makes them good
candidates for representing the local geometry of repeated
In particular, for the real-image experiments in
textures.
Sec. 6, we use the Maximally-Stable Extremal Region and
Hesssian-Afﬁne detectors [16, 18]. The detections are pa-
rameterized as 3 distinct points, which deﬁne an afﬁne co-
ordinate frame in the image space [20]. These detections
are visualized in Fig. C.4 of the supplemental material.

Afﬁne frames are labeled as repeated texture based on
the similarity of their appearance, which is given by the
RootSIFT embedding of the image patch local to the afﬁne
frame [3, 14]. The RootSIFT descriptors are agglomera-
tively clustered, which establishes pair-wise tentative corre-
spondences among the connected components linked by the
clustering. Each appearance cluster has some proportion
of its members that correspond to afﬁne frames that give
the geometry of imaged repeated scene content, which are
the inliers of that appearance cluster. The remaining afﬁne
frames are the outliers.

LO-RANSAC samples pairs of afﬁne frames from the ap-
pearance cluster, which are inputted to the proposed mini-
mal solvers. Each pair of afﬁne frames across all appear-
ance clusters has an equi-probable chance of being drawn.
The consensus with the minimal sample is measured by the
number of pairs of afﬁne frames within appearance groups
that are consistent with the hypothesized model, normalized
by the size of each respective group. A non-linear optimizer
following [21] is used as the local optimization step of the
LO-RANSAC estimator.

5. Synthetic Experiments

The proposed solvers are evaluated across several bench-
marks on synthetic data against state-of-the-art solvers. In-
cluded in the benchmarks are two single-view solvers: H2lu

H2.5luλ
H3lusuλ
H3.5luvλ
H4luvsvλ

100

50

y
c
n
e
u
q
e
r
F

0
−15

−5

−10
log10 ∆xfer

RMS (see Sec. 5.1)

0

5

Figure 3: Stability study. Hidden-variable trick solvers are
solid; standard solvers are dashed. The log10 transfer error
is reported. The hidden-variable trick increases stability.

[23], which also incorporates constraints from conjugate
translations, and H4lγ [4], which solves for rectiﬁcation and
change-of-scale, and also two full-homography and radial
distortion solvers, H5λ [7] and H5λ1λ2 [11], which we use
for conjugate translation and lens-istortion estimation. The
bench of state-of-the-art solvers is summarized in Table 1).
The benchmarks are evaluated for 1000 synthetic images
of 3D scenes with known ground-truth parameters. A cam-
era with a random but realistic focal length is randomly ori-
ented and positioned with respect to a 10x10 square meter
scene plane such that the plane is mostly in the camera’s
ﬁeld-of-view. Image resolution is set to 1000x1000 pixels.
Conjugately translated afﬁne frames are generated on the
scene plane such that their scale with respect to the scene
plane is realistic. This modeling choice reﬂects the use of
afﬁne-covariant feature detectors for real images. The con-
jugately translated features are distorted according to the di-
vision model, and, for the sensitivity experiments, isotropic
white noise is added to the distorted afﬁne frames at increas-
ing levels. Performance is characterized by the relative error
of the estimated distortion parameter and by the transfer and
warp errors, which measure the accuracies of the estimated
conjugate translation and rectiﬁcation (see Sec. 5.1 - 5.4).
The proposed solvers have an average solve time from 0.3
to 2 milliseconds over the 1000 synthetic scenes (see also
Sec. B of the supplemental material).

5.1. Transfer Error

The geometric transfer error jointly measures the accu-
racy of an the estimated conjugate translation and lens dis-
tortion. The scene plane is tesselated by a 10x10 square
grid of points { Xi}. Let the translation on the scene plane
induced by the noiseless pre-images of the point correspon-
dences used to estimate ˆHu and ˆλ be t. Then the grid points
are translated by t/(cid:107)t(cid:107) to { X(cid:48)
i}. The grid and its trans-
lation are imaged by the ground-truth lens-distorted cam-

era parameterized by matrix P and division-model parame-
ter λ. The imaged grid is given by ˜xi = f d(PXi, λ) and
the translated grid by ˜x(cid:48)
i, λ), where f d is the
i = f d(PX(cid:48)
the function that transforms from pinhole points to radially-
distorted points. Then the geometric transfer error is deﬁned
as

1
(cid:107)t(cid:107)

∆xfer

i = d(f d([I3 +

(ˆHu − I3)]f (˜xi, ˆλ1), ˆλ2), ˜x(cid:48)

i),
(10)
where d(·, ·) is the Euclidean distance. All solvers except
H5λ1λ2 have the constraint that ˆλ1 = ˆλ2 [11]. The root-
mean-square of transfer errors ∆xfer
RMS for correspondences
{ (˜xi, ˜x(cid:48)
i) } is reported. For two-direction solvers, the trans-
fer error in the second direction is included in ∆xfer
RMS. The
transfer error is used in the stability study, where the solvers
are tested over varying division model parameters and in the
sensitivity study, where the solvers are tested over varying
noise levels with ﬁxed division model parameter. The solver
H4lγ of [4] does not estimate conjugate translations, so it is
not reported. For a derivation of (10) see Sec. A in the sup-
plementary material.

5.2. Numerical Stability

The stability study measures the RMS transfer error
of solvers (see Sec. 5.1) for noiseless afﬁne-frame corre-
spondences across realistic scene and camera conﬁgura-
tions generated as described in the introduction to this sec-
tion. The ground-truth parameter of the division model λ is
drawn uniformly at random from the interval [−6, 0]. For
a reference, the division parameter of λ = −4 is typi-
cal for wide ﬁeld-of-view cameras like the GoPro where
width+height . Fig. 3 reports
the image is normalized by
the histogram of log10 RMS transfer errors. For all new
solvers we evaluate a solver generated from constraints de-
rived with (solid histogram) and without (dashed histogram)
the hidden-variable trick. The hidden-variable trick sig-
niﬁcantly improves the stability of the proposed solvers.
The increased stabilities of the hidden-variable solvers most
likely result from the reduced size of the G-J elimination
problems needed by these solvers. The hidden-variable
solvers are used for the remainder of the experiments.

1

5.3. Noise Sensitivity

The proposed and state-of-the-art solvers solvers are
tested with increasing levels of white noise added to the
afﬁne correspondences induced by the ground-truth conju-
gate translation and lens distortion parameter. The white
noise is parameterized by the standard-deviation of a zero-
mean isotropic Gaussian distribution, and the solvers are
tested at noise levels of σ ∈ {0.1, 0.5, 1, 2}. The ground
truth division model parameter is set to λ = −4, which is
typical for GoPro-type imagery. The solvers are wrapped in

λ
/
)
ˆλ
−
λ
(

0.6

0.4

0.2

0

−0.2

−0.4

−0.6

]
s
l
e
x
i
p
[

S
r
M
e
f
R
x
∆

]
s
l
e
x
i
p
[

S
p
M
r
a
R
w
∆

40

30

20

10

0

40

30

20

10

0

0.1

0.5

1

2

Noise (σ) [pixels]

0.1

0.5

1

2

Noise (σ) [pixels]

H2lu

H2.5luλ

H3lusuλ

H3.5luvλ

H4luvsvλ

H4lγ

H5λ

H5λ1λ2

Figure 4: Comparison of the transfer error (left, see Sec. 5.1) and the relative radial distortion error (right) after 25 iterations
of a simple RANSAC for different solvers over increasingly noisy measurements for 1000 scenes.

5.4. Warp Error

Since the accuracy of scene-plane rectiﬁcation is a pri-
mary concern, we also report the warp error for rectifying
homographies proposed by Pritts et al. [22], which we aug-
ment with the division model for radial lens distortion. A
rectifying homography H∞ of an imaged scene plane is con-
structed from its vanishing line l (see [9]). A round trip be-
tween the image space and rectiﬁed space is made by undis-
torting and rectifying imaged coplanar points by the esti-
mated lens distortion ˆλ and rectifying homography ^H∞ and
then re-warping and distorting the rectiﬁed points into the
image by a synthetic camera constructed from the ground-
truth lens distortion λ and rectifying homography H∞. Ide-
ally, the synthetic camera constructed from the truth would
project the undistorted and rectiﬁed points onto the original
points.

Note that there is an afﬁne ambiguity, denoted A, be-
tween ^H∞ and H∞, which is folded into the expression for
the synthetic camera, namely P(A) = (AH∞)−1, and esti-
mated during computation of the warp error,

∆warp = min

d2(˜xi, f d(P(ˆA)^H∞f (˜xi, ˆλ)), ˆλ),

(11)

(cid:88)

ˆA

i

where d(·, ·) is the Euclidean distance, and {˜xi} are the im-
aged grid points of the scene-plane tesselation as deﬁned
in Sec. 5.1. The root mean square warp error for { ˜xi } is
reported and denoted as ∆warp
RMS. The vanishing line is not di-
rectly estimated by solvers H5λ of [7] and H5λ1λ2 of [11],
so they are not reported.

The proposed solvers—H2.5luλ, H3lusuλ, H3.5luvλ,
H4luvsvλ—estimate rectiﬁcations with less than 5 pixel
RMS warp error ∆warp
RMS, even at the 2 pixel noise level, see
Fig. 5. The need to model radial lens distortion is shown by
the biased ﬁts for the solvers H2lu, H4γ.

0.1

0.5

1

2

Noise (σ) [pixels]

Figure 5: Warp-error comparison (see Sec. 5.4) after 25 it-
erations of a simple RANSAC for different solvers over in-
creasingly noisy measurements for 1000 scenes.

a simple RANSAC-loop, which minimizes the RMS trans-
fer error ∆xfer
RMS over 25 sampled afﬁne-frame correspon-
dences. Results are calculated from the estimate given by
RANSAC and summarized for the 1000 generated scenes as
boxplots. The interquartile range is contained within the ex-
tents of a box, and the median is the horizontal line dividing
the box.

As shown in Fig. 4 the proposed solvers give the
most accurate joint estimation of conjugate translation
and division model parameter as measured by the RMS
transfer error ∆xfer
RMS and relative error of estimated divsion
model parameter. As expected,
the minimal parame-
terization of the radially-distorted conjugate translation
solvers—H2.5luλ, H3lusuλ, H3.5luvλ, H4luvsvλ—show
signiﬁcantly less sensitivity to noise than the overparme-
terized radially-distorted homography solvers H5λ and
H5λ1λ2 for both measures. The solver H2lu shows signiﬁ-
cant bias (see the transfer error boxplots in Fig. 4) since it
does not model lens distortion.

Original image

H2lu + LO; 11.2% inliers

H2.5luλ+LO; 20.4% inliers H3.5luvλ+LO; 20.2% inliers

Figure 6: GoPro Hero 4 at the wide setting for different solvers. Results from LO-RANSAC (see Sec. 4) for H2lu, which
omits distortion, and the proposed solvers H2.5luλ and H3.5luvλ. The top row has rectiﬁcations after local optimization
(LO); The bottom row has undistortions estimated from the best minimal sample. LO-RANSAC cannot recover from the poor
initializations by H2lu (column 2). The proposed solvers in columns 3 and 4 give a correct rectiﬁcation. The bottom left has
a chessboard undistorted using the division parameter estimated from the building facade by H2.5luλ+LO.

6. Real Images

In the qualitative experiments on real images shown in
Figs. 1 and 2, we tested the proposed solvers on Go-
Pro4 Hero 4 images with increasing ﬁeld-of-view settings,
namely narrow, medium and wide, where a wider ﬁeld-of-
view setting generates more extreme radial distortion since
the boundary of the lens is used. The proposed method gen-
erates high-quality rectiﬁcations at all the ﬁeld-of-view set-
tings. More real-image experiments, including results for
cameras with radial distortions that are typical for mobile
phone cameras and ﬁsheye lenses (e.g., 8mm lens) can be
found in Sec. C in the supplementary material.

The experiment shown in Fig. 6 compares the per-
formance of two of the proposed solvers, H2.5luλ and
H3.5luvλ, to H2lu in a state-of-the-art local-optimization
(LO) framework (see Sec. 4) on an GoPro Hero 4 image at
the wide ﬁeld-of-view setting. The two proposed solvers
accurately estimate the division-model parameter (see the
undistorted reference chessboard in Fig. 6) and the rectiﬁ-
cation, while the LO-variant using the H2lu solver is unable
to recover the lens distortion parameter. See Fig. C.2 in the
supplemental material for results on an image at the medium
ﬁeld-of-view setting.

7. Conclusions

This paper proposes the ﬁrst minimal solvers that jointly
solve for the afﬁne rectiﬁcation of an imaged scene plane
and a camera’s radial lens distortion from coplanar repeated
patterns. Rectiﬁcation and radial lens distortion are recov-

ered from only one conjugately translated afﬁne-covariant
feature or two independently translated similarity-covariant
features. Synthetic experiments demonstrate the good sta-
bility and superior robustness to noise with respect to mea-
sures of rectiﬁcation accuracy and lens-distortion estima-
tion of the proposed solvers as compared to the state-of-
the-art. However, the polynomial constraint equations that
arise from conjugate translations distorted by the division
model need to be transformed with the hidden-variable
trick to generate stable solvers, though. Qualitative real-
image experiments demonstrate high-quality rectiﬁcations
for highly-distorted wide-angle lenses, which was not pos-
sible using the state-of-the-art. Future work could include
conditionally sampling the measurements during robust es-
timation to take into account their size, relative distance
from each other, or distance from the distortion center. We
expect these factors have a big impact on rectiﬁcation qual-
ity, but this study was beyond scope for this paper.

8. Acknowledgements

James Pritts was supported by the grants MSMT
LL1303 ERC-CZ and SGS17/185/OHK3/3T/13, Zuzana
Kukelova by the Czech Science Foundation Project GACR
P103/12/G084, Viktor Larsson by the strategic research
projects ELLIIT and eSSENCE, Swedish Foundation for
Strategic Research project ”Semantic Mapping and Visual
Navigation for Smart Robots” (grant no. RIT15-0038) and
Wallenberg Autonomous Systems and Software Program
(WASP), and Ondrej Chum by the grant MSMT LL1303
ERC-CZ.

[22] J. Pritts, D. Rozumnyi, M. P. Kumar, and O. Chum. Coplanar

repeats by energy minimization. In BMVC, 2016. 7

[23] F. Schaffalitzky and A. Zisserman. Geometric grouping of
repeated elements within images. In BMVC, 1998. 2, 3, 4, 6
[24] A. Vedaldi and B. Fulkerson. VLFeat: An open and portable
http://www.

library of computer vision algorithms.
vlfeat.org/, 2008. 2, 3

[25] H. Wildenauer and B. Micusík. Closed form solution for
radial distortion estimation from a single vanishing point. In
BMVC, 2013. 1, 2

[26] C. Wu, J. M. Frahm, and M. Pollefeys. Repetition-based
dense single-view reconstruction. In CVPR, 2011. 1
[27] Z. Zhang, A. Ganesh, X. Liang, and Y. Ma. TILT: transform
invariant low-rank textures. IJCV, 99(1):1–24, 2012. 1

References

[1] D. Aiger, D. Cohen-Or, and N. Mitra. Repetition maximiza-
tion based texture rectiﬁcation. Computer Graphics Forum,
31(2):439–448, 2012. 1

[2] M. Antunes, J. P. Barreto, D. Aouada, and B. Ottersten. Un-
supervised vanishing point detection and camera calibration
from a single manhattan image with radial distortion.
In
CVPR, July 2017. 2

[3] R. Arandjelovi´c and A. Zisserman. Three things everyone
should know to improve object retrieval. In CVPR, 2012. 5
[4] O. Chum and J. Matas. Planar afﬁne rectiﬁcation from

change of scale. In ACCV, 2010. 1, 2, 4, 6

[5] O. Chum, J. Matas, and v. Obdržálek. Enhancing RANSAC
by generalized model optimization. In ACCV, 2004. 5
[6] D. Cox, J. Little, and O. D. Using algebraic geometry.

Springer, 2004. 4

[7] A. W. Fitzgibbon. Simultaneous linear estimation of multiple
view geometry and lens distortion. In CVPR, 2001. 2, 3, 4,
6, 7, 12

[8] D. R. Grayson and M. E. Stillman. Macaulay 2, a software

system for research in algebraic geometry, 2002. 5

[9] R. I. Hartley and A. W. Zisserman. Multiple View Geome-
try in Computer Vision. Cambridge University Press, ISBN:
0521540518, second edition, 2004. 1, 2, 7

[10] Z. Kukelova, M. Bujnak, and T. Pajdla. Automatic generator

of minimal problem solvers. In ECCV, 2008. 2, 4

[11] Z. Kukelova, J. Heller, B. M., and T. Pajdla. Radial distortion

homography. In CVPR, 2015. 1, 2, 6, 7

[12] V. Larsson, K. Åström, and M. Oskarsson. Efﬁcient solvers
for minimal problems by syzygy-based reduction. In CVPR,
2017. 2, 4

[13] V. Larsson, K. Åström, and M. Oskarsson. Polynomial

solvers for saturated ideals. In ICCV, 2017. 2, 4, 5

[14] D. Lowe. Distinctive image features from scale-invariant

keypoints. IJCV, 60(2):91–110, 2004. 2, 3, 5

[15] M. Lukáˇc, D. Sýkora, K. Sunkavalli, E. Shechtman, O. Jam-
riška, N. Carr, and T. Pajdla. Nautilus: Recovering regional
symmetry transformations for image editing. ACM Trans.
Graph., 36(4):108:1–108:11, July 2017. 1

[16] J. Matas, O. Chum, M. Urban, and T. Pajdla. Robust wide
baseline stereo from maximally stable extremal regions. In
BMVC, 2002. 2, 3, 5

[17] K. Mikolajczyk and C. Schmid. A performance evaluation

of local descriptors. PAMI, 2004. 5

[18] K. Mikolajczyk and C. Schmid. Scale and afﬁne invariant

interest point detectors. volume 60, 2004. 2, 3, 5

[19] D. Mishkin, F. Radenovic, and J. Matas. Learning dis-
CoRR,

criminative afﬁne regions via discriminability.
abs/1711.06704, 2017. 2, 3

[20] Š. Obdržálek and J. Matas. Object recognition using local

afﬁne frames on distinguished regions. In BMVC, 2002. 5

[21] J. Pritts, O. Chum, and J. Matas. Detection, rectiﬁcation and
segmentation of coplanar repeated patterns. In 2014 IEEE
Conference on Computer Vision and Pattern Recognition,
2014. 1, 2, 5

A. Transfer Error

torted point correspondence y ↔ y(cid:48) as

I3 +

l(cid:62) = I3 +

[I3 + ul(cid:62) − I3]

u
(cid:107)t(cid:107)

= I3 +

[Hu − I3].

(14)

1
(cid:107)t(cid:107)
1
(cid:107)t(cid:107)

The derivation of (14) gives the form of transformation used
in the transfer error ∆xfer
RMS deﬁned in Sec. 5.1, which maps
from the undistorted points of the grid {xi} to their trans-
lated correspondences {x(cid:48)

i}.

B. Computational Complexity

Table B.1 lists the elimiation template sizes for the pro-
posed solvers. The average time to compute the solutions
for a given input for a solver is directly proportional to the
elimination template size. The solvers are implemented in
MATLAB and C++. Signiﬁcantly faster implementations
are possible with a pure C++ port. Still the solvers are sufﬁ-
ciently fast for use in RANSAC. The proposed solvers have
an average solve time from 0.3 to 2 milliseconds.

H2.5luλ

H3lusuλ

H3.5luvλ

H4luvsvλ

14x18

24x26

54x60

76x80

Table B.1: Template sizes for the proposed solvers.

C. Extended Experiments

The extended real-data experiments in the following
pages include (i) images with lesser radial distortion from
consumer cameras and mobile phones;
the images also
demonstrate the proposed method’s effectiveness on diverse
scene content, (ii) images for very wide ﬁeld-of-view lenses
(8mm and 12mm), (iii) and an additional local-optimiza-
tion experiment similar to the one in Fig. 6 on a GoPro
Hero 4 image taken with its medium ﬁeld-of-view setting,
which further demonstrates the need for a minimal solver
that jointly estimates lens distortion with afﬁne-rectiﬁcation
to achieve an accurate undistortions and rectiﬁcations.

The scene plane is tessellated by a 10x10 square grid
of points, denoted { Xi }, with a 1 meter spacing between
adjacent points. Suppose that y ↔ y(cid:48) is an undistorted
point correspondence induced by the conjugate translation
Hu = [I3 + ul(cid:62)] in the imaged scene plane (here we as-
sume that su
i = 1 since we speak about an individual point
correspondence).

Points { Xi } are translated by 1 meter on the scene plane
in the direction of translation induced by the preimage of
the point correspondence y ↔ y(cid:48) giving the translated grid
{ X(cid:48)
i }. The purpose of constructing the grid and it’s trans-
lation is to uniformly cover the scene plane that the camera
images in its ﬁeld of view. In this way, the accuracy of the
conjugate translation and lens-distortion parameter estima-
tion can be measured across most of the image. The conju-
gate translation Hu is not used directly because the magni-
tude of translation may span the extent of the scene plane,
so applying it to the tessellation would transform the grid
out of the ﬁeld of view.

Let the camera be parameterized by the camera ma-
trix P = (AH)−1 (see Sec. 5.4 for the deﬁnition of the
camera matrix) that pointwise maps the scene plane Π to
the imaged scene plane π and division model parameter
λ. The preimages of the undistorted point correspondence
y ↔ y(cid:48) in the scene-plane coordinate system is, respec-
tively, βY = P−1y and β(cid:48)Y(cid:48) = P−1y(cid:48). The translation
t of the preimages in the scene plane coordinate system is
t = Y − Y(cid:48) = (cid:0)tx, ty, 0(cid:1)(cid:62)

.

Then (cid:107)t(cid:107) is the magnitude of translation between the re-
peated scene elements in the scene-plane coordinate system.
Denote the homogeneous translation matrix T(t) to be the
matrix constructed from t as

T(t) =


1
0
0 1

0
0



 .

tx
ty
1

The translation of the grid points by unit distance is given
by X(cid:48)
i = T(t/(cid:107)t(cid:107))Xi. Recall from (1) that a conjugate
translation has the form PT(·)P−1. Using (2), the conjugate
translation of unit distance in the direction of point corre-
spondences y ↔ y(cid:48) is





tx/(cid:107)t(cid:107)
ty/(cid:107)t(cid:107)
1






P−(cid:62)






(cid:62)




0
0

1

Hu/(cid:107)t(cid:107) = PI3P−1 + P

= [I3 +

u
(cid:107)t(cid:107)

l(cid:62)].

The unit conjugate translation Hu/(cid:107)t(cid:107) can be written in
terms of the conjugate translation Hu induced by the undis-

(12)

(13)

10

Figure C.1: Narrow ﬁeld-of-view and diverse scene-content experiments for H2.5luλ+LO. The proposed method works well
if the input image has little or no radial lens distortion. This imagery is typical of consumer cameras and mobile phone
cameras. The images are diverse and contain unconventional scene content. Input images are on the top row; undistorted
images are on the middles row, and the rectiﬁed images are on the bottom row.

Original image

H2lu+LO; 20.3% inliers

H2.5luλ+LO; 31.2% inliers H3.5luvλ+LO; 30.7% inliers

Figure C.2: GoPro Hero 4 at the medium setting for different solvers. Results from LO-RANSAC (see Sec. 4) for H2lu, which
omits distortion, and the proposed solvers H2.5luλ and H3.5luvλ. The top row has rectiﬁcations after local optimization
(LO); The bottom row has undistortions estimated from the best minimal sample. LO-RANSAC fails from the poor initial-
izations by H2lu (column 2). The proposed solvers in columns 3 and 4 give a correct rectiﬁcation. The bottom left has a
chessboard undistorted using the division parameter estimated from the building facade by H2.5luλ+LO.

11

Figure C.3: Very wide-angle images undistorted and rectiﬁed with H2.5luλ+LO. The left column is an image from an 8mm
lens, and the right column is from a 12mm lens. The top row contains the input images; the middle row contains the
undistorted images, and the bottom row contains the rectiﬁed images. The division model [7] used for radial lens distortion
has only 1 parameter, which may impose limits for modeling extreme lens distortion.

12

Afﬁne-covariant feature detections

Inlying afﬁne-covariant features

Undistorted

Undistorted and rectiﬁed

Figure C.4: Problem difﬁculty and method robustness The input to the method is ungrouped afﬁne-covriant features (top left).
Common problems include missed detections of repeated texture, duplicate detections, and detections due to compression
artifacts, all of which are visible in this example. The inliers with respect to the total number of detected features can be a
very small proportion (top right). Still the method can estimate accurate undistortion (bottom left) and afﬁne rectiﬁcation
(bottom right) even from a very sparse sampling of the inlying afﬁne-covariant features on the scene plane (top right).

13

