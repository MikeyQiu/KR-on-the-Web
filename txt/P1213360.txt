8
1
0
2
 
n
u
J
 
4
1
 
 
]
E
M

.
t
a
t
s
[
 
 
2
v
4
1
4
9
0
.
1
1
6
1
:
v
i
X
r
a

arXiv: arXiv:1611.09414

SPLIT-DOOR CRITERION: IDENTIFICATION OF CAUSAL
EFFECTS THROUGH AUXILIARY OUTCOMES

By Amit Sharma, Jake M. Hofman and Duncan J. Watts

Microsoft Research

We present a method for estimating causal eﬀects in time series data
when ﬁne-grained information about the outcome of interest is available.
Speciﬁcally, we examine what we call the split-door setting, where the out-
come variable can be split into two parts: one that is potentially aﬀected
by the cause being studied and another that is independent of it, with
both parts sharing the same (unobserved) confounders. We show that un-
der these conditions, the problem of identiﬁcation reduces to that of testing
for independence among observed variables, and present a method that uses
this approach to automatically ﬁnd subsets of the data that are causally
identiﬁed. We demonstrate the method by estimating the causal impact of
Amazon’s recommender system on traﬃc to product pages, ﬁnding thou-
sands of examples within the dataset that satisfy the split-door criterion.
Unlike past studies based on natural experiments that were limited to a
single product category, our method applies to a large and representative
sample of products viewed on the site. In line with previous work, we ﬁnd
that the widely-used click-through rate (CTR) metric overestimates the
causal impact of recommender systems; depending on the product category,
we estimate that 50-80% of the traﬃc attributed to recommender systems
would have happened even without any recommendations. We conclude
with guidelines for using the split-door criterion as well as a discussion of
other contexts where the method can be applied.

1. Introduction. The recent growth of digital platforms has generated an avalanche
of highly granular and often longitudinal data regarding individual and collective behav-
ior in a variety of domains of interest to researchers, including in e-commerce, health-
care, and social media consumption. Because the vast majority of this data is generated
in non-experimental settings, researchers typically must deal with the possibility that
any causal eﬀects of interest are complicated by a number of potential confounds. For
example, even eﬀects as conceptually simple as the causal impact of recommendations
on customer purchases are likely confounded by selection eﬀects [Lewis, Rao and Reiley,
2011], correlated demand [Sharma, Hofman and Watts, 2015], or other shared causes
of both exposure and purchase. Figure 1a shows this canonical class of causal inference
problems in the form of a causal graphical model [Pearl, 2009], where X is the cause and
Y is its eﬀect. Together U and W refer to all of the common causes of X and Y that
may confound estimation of the causal eﬀect, where critically some of these confounders
(labeled W ) may be observed, while others (U ) are unobserved or even unknown. Ideally
one would answer such questions by running randomized experiments on these platforms,
but in practice such tests are possible only for the owners of the platform in question,
and even then are often beset with implementation diﬃculties or ethical concerns [Fiske
and Hauser, 2014]. As a result researchers are left with two main strategies for making
causal estimates from large-scale observational data, each with its own assumptions and
limitations: either conditioning on observables or exploiting natural experiments.

1.1. Background: Back-door criterion and natural experiments. The ﬁrst and by far
the more common approach is to assume that the eﬀect of unobserved confounders (U )
is negligible after conditioning on the observed variables (W ). Under such a selection on
observables assumption [Imbens and Rubin, 2015], one conditions on W to estimate the

∗We would like to thank Dean Eckles, Praneeth Netrapalli, Joshua Angrist, T. Tony Ke, and anony-

mous reviewers for their valuable feedback on this work.

Keywords and phrases: causal inference, data mining, causal graphical model, natural experiment,

recommendation systems

1

2

SHARMA ET AL.

(a) Canonical causal in-
ference problem

Estimation with

(b)
back-door criterion

(c) Estimation with Z as an
instrumental variable

Fig 1: Left: Graphical model for the canonical problem in causal inference. We wish to
estimate the eﬀect of X on Y . W represents observed common causes of X and Y ; U
represents other unobserved (and unknown) common causes that confound observational
estimates. Middle: The causal model under the selection on observables assumption,
where there are no known unobserved confounds U . Right: The canonical causal model
for an instrumental variable Z that systematically shifts the distribution of the cause X
independently of confounds U .

eﬀect of X on Y when these confounders are held constant. In the language of graph-
ical models, this strategy is referred to as the back-door criterion [Pearl, 2009] on the
grounds that the “back-door pathway” from X to Y (via W) is blocked by condition-
ing on W (see Figure 1b) and can be implemented by a variety of methods, including
regression, stratiﬁcation, and matching [Rubin, 2006; Stuart, 2010]. Unfortunately for
most practical problems it is diﬃcult to establish that all of the important confounders
have been observed. For example, consider the problem of estimating the causal impact
of a recommender system on traﬃc to e-commerce websites such as Amazon.com, where
X corresponds to the number of visits to a product’s webpage, and Y the visits to a
recommended product shown on that webpage. One could compute the observed click-
through rate after conditioning on all available user and product attributes (e.g., user
demographics, product categories and popularities, etc.), assuming that these features
constitute a proxy for latent demand. Unfortunately, there are also many potentially
unobserved confounders (e.g., advertising, media coverage, seasonality, etc.) that impact
both a product and its recommendations, which if excluded would render the back-door
criterion invalid.

Motivated by the limitations of the back-door strategy, a second main approach is to
identify an external event that aﬀects the treatment X in a way that is arguably ran-
dom with respect to potential confounds. The hope is that such variation, known as a
natural experiment [Dunning, 2012], can serve as a substitute for an actual randomized
experiment. Continuing with the problem of estimating the causal impact of recommen-
dations, one might look for a natural experiment in which some products experience
large and sudden changes in traﬃc, for instance when a book is featured on Oprah’s
book club [Carmi, Oestreicher-Singer and Sundararajan, 2012]. Assuming that the in-
crease in traﬃc for the book is independent of demand for its recommendations, one can
estimate the causal eﬀect of the recommender by measuring the change in sales to the
recommended products before and after the book was featured, arguing that these sales
would not have happened in the absence of the recommender. Such events provide in-
strumental variables that identify the eﬀect of interest by shifting the distribution of the
cause X independently of unobserved confounds U [Angrist, Imbens and Rubin, 1996].
Figure 1c depicts this in a graphical model, where the additional observed variable Z
denotes the instrumental variable.

These two main approaches trade oﬀ critical goals of identiﬁcation and generalization
in causal inference. The estimate for back-door conditioning is typically derived using all
available data, but provides no identiﬁcation guarantees in the presence of unobserved

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

3

(a) General split-door model: Outcome Y
is split into YR and YD

(b) Valid split-door model: Data subsets
where X is independent of UY

Fig 2: Panel (a) illustrates the canonical causal inference problem when outcome Y can
be split up into two components. For clarity, unobserved confounders U are broken into
UY that aﬀects both X and Y , and UX that aﬀects only X. The split-door criterion ﬁnds
subsets of the data where the cause X is independent of UY by testing independence of
X and YD, leading to the unconfounded causal model shown in Panel (b).

confounders. Instrumental variables, in contrast, provide identiﬁcation guarantees even
in the presence of unobserved confounders, but these guarantees apply only for local
subsets of the available data—the relatively rare instances for which a valid instrument
that exogenously varies the cause X is known (e.g., lotteries [Angrist, Imbens and Rubin,
1996], variation in weather [Phan and Airoldi, 2015], or sudden, large events [Rosenzweig
and Wolpin, 2000; Dunning, 2012]).

1.2. The “split-door” criterion.

In this paper we introduce a causal identiﬁcation
strategy that incorporates elements of both the back-door and natural experiment ap-
proaches, but that applies in a diﬀerent setting. Rather than conditioning on observable
confounds W or exploiting sources of independent variation in the cause X, we instead
look to auxiliary outcomes [Mealli and Pacini, 2013] to identify subsets of the data that
are causally identiﬁed. Speciﬁcally, our strategy applies when the outcome variable Y can
be eﬀectively “split” into two constituents: one that is caused by X and another that is
independent of it. Figure 2a shows the corresponding causal graphical model, where YR
denotes the “referred” outcome of interest aﬀected by X and YD indicates the “direct”
constituent of Y that does not directly depend on X. Returning to the recommender sys-
tem example, YR corresponds to recommendation click-throughs on a product whereas
YD would be all other traﬃc to that product that comes through channels such as direct
search or browsing. Whenever such ﬁne-grained data on Y is available, we show that it is
possible to reduce causal identiﬁcation to an independence test between the cause X and
the auxiliary outcome YD. Because this strategy depends on the availability of a split set
of variables for Y , we call it the split-door criterion for causal identiﬁcation, by analogy
with the more familiar back-door criterion.

Although we make no assumptions about the functional form of relationships between
variables, a crucial assumption underlying the split-door criterion is connectedness; i.e.,
that the auxiliary outcome YD must be aﬀected (possibly diﬀerently) by all causes that
also aﬀect YR. As we discuss in more detail in Section 5, this assumption is plausible in
scenarios such as online recommender systems, where recommended products are reach-
able through multiple channels (e.g., search or direct navigation) and it is unlikely that
demand for a product manifests itself exclusively through only one of these channels.
More generally, the connectedness assumption is expected to hold in scenarios where
direct and referred outcomes incur similar cost, which makes it unlikely that something
that causes the outcome does so only when referred through X, but never directly.

Under the above assumption, the split-door criterion seeks to identify subsets of the
data where causal identiﬁcation is possible. In this sense, the method resembles a natural

4

SHARMA ET AL.

experiment, except that instead of looking for an instrument that creates variation in X,
we look for variations in X directly. As in a natural experiment, however, it is important
that any such variation in X is independent of potential confounds. For instance in the
example above, it is important that a sudden burst of interest in a particular book is
not correlated with changes in latent demand for its recommendations. To verify this
requirement, the split-door criterion relies on a statistical test to select for cases where
there are no confounds (observed or otherwise) between X and YR. Speciﬁcally, we show
that given a suitable auxiliary outcome YD, and a test to establish if X and YD are
independent, the causal eﬀect between X and YR can be identiﬁed. Furthermore, since
this test involves two observed quantities (X and YD), we can systematically search for
subsets of the data that satisfy the required condition, potentially discovering a large
number of cases in which we can identify the causal eﬀect of X on YR.

We illustrate this method with a detailed example in which we estimate the causal
impact of Amazon.com’s recommendation system using historical web browsing data.
Under the above assumptions on the dependence between referred and direct visits to
a product’s webpage, we show how the criterion provides a principled mechanism for
determining which subsets of the data to include in the analysis. The split-door criterion
identiﬁes thousands of such instances in a nine-month period, comparable in magnitude
to a manually tuned approach using the same data [Sharma, Hofman and Watts, 2015],
and an order of magnitude more than traditional approaches [Carmi, Oestreicher-Singer
and Sundararajan, 2012]. Further, the products included in our analysis are representa-
tive of the overall product distribution over product categories on Amazon.com, thereby
improving both the precision and generalizability of estimates. Consistent with previous
work [Sharma, Hofman and Watts, 2015], we ﬁnd that observational estimates of rec-
ommendation click-through rates (CTRs) overstate the actual eﬀect by anywhere from
50% to 80%, calling into question the validity of popular CTR metrics for assessing the
impact of recommendation systems. For applications to other online and oﬄine scenarios,
we provide an R package1 that implements the split-door criterion.

1.3. Outline of paper. The remainder of this paper proceeds as follows. In Section 2
we start with a formal deﬁnition of the split-door criterion and give precise conditions un-
der which the criterion holds. For clarity we provide proofs for causal identiﬁcation both
in terms of the causal graphical model from Figure 2a and also in terms of structural
equations. In Section 3 we propose a simple, scalable algorithm for identifying causal
eﬀects using the split-door criterion. Then in Section 4, we explain more formally how
the split-door criterion diﬀers from the instrumental variables and back-door methods
mentioned above. Section 5 presents details about the Amazon.com data and an appli-
cation of the split-door criterion to estimate the causal impact of its recommendation
system. In Section 6 we then discuss limitations of the split-door criterion as well as
other settings in which the criterion applies, arguing that many existing datasets across
a variety of domains have the structure that outcomes of interest can be decomposed into
their “direct” and “referred” constituents. We conclude with a prediction that as the size
and granularity of available datasets, along with the number of variables in them, in-
crease at an ever faster rate, data-driven approaches to causal identiﬁcation will become
commonplace.

2. The Split-door Identiﬁcation Criterion. The split-door criterion can be used
whenever observed data is generated from the model shown in Figure 2a. Here X repre-
sents the cause of interest, YR denotes the “referred” portion of the outcome aﬀected by
it, and YD indicates the “direct” part of the outcome which does not directly depend on
X. We denote the overall outcome by Y = YR + YD. We let UY represent all unobserved
causes of Y , some of which may also be common causes of X, hence the arrow from UY
to X. Additional latent factors that aﬀect only X are captured by UX . Both UX and UY

1URL: http://www.github.com/amit-sharma/splitdoor-causal-criterion

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

5

can be a combination of many variables, some observed and some unobserved. (For full
generality, the analysis presented here assumes that all confounds are unobserved.) As
noted earlier, the unobserved variables UY create “back-door pathways” that confound
the causal eﬀect of X on Y , resulting in biased estimates. The central idea behind the
split-door criterion is that we can use an independence test between the auxiliary out-
come YD and X to systematically search for subsets of the data that are free of these
confounds and do not contain back-door pathways between X and YR. In other words,
we can conclude that such subsets of the data were generated from the unconfounded
causal model shown in Figure 2b, and therefore the causal eﬀect of X on Y can be esti-
mated directly from these data. Importantly, identiﬁcation of the causal eﬀect rests on
the assumption that no part of UY causes one part of Y and not the other.

2.1. The split-door criterion through a graphical model. Here we formalize the intu-
ition above in the causal graphical model framework. To identify the causal eﬀect, we
make the following two assumptions. The ﬁrst pertains to connectedness of the causal
model.

Assumption 1 (Connectedness). Any unobserved confounder UY that causes both

X and YR also causes YD and the causal eﬀect of such UY on YD is non-zero.

Note that Assumption 1 requires only that the causal eﬀect of UY on YD be non-
zero, without any requirements on the size of the eﬀect(s) involved. That said, it is a
strong requirement in general, as it applies to all sub-components of UY and thus involves
assumptions about potentially high-dimensional, unobserved variables. Whenever YD and
YR are components of the same variable it is plausible that they share causes, but one still
must establish that this condition holds to ensure causal identiﬁcation. It is instructive
to compare this assumption to the strict independence assumptions involving unobserved
confounders required by methods such as instrumental variables [Angrist, Imbens and
Rubin, 1996].

The second assumption, which relates statistical and causal independence between
observed variables, is standard for many methods of causal discovery from observational
data.

Assumption 2 (Independence).

If X and YD are statistically independent, then they

are also causally independent in the graphical model of Figure 2a.

Here causal independence between two variables means that they share no common
causes and no directed path in the causal graphical model leads from one to another.
More formally, the two variables are “d-separated” [Pearl, 2009] from each other. Thus,
Assumption 2 is a variant of the Faithfulness or Stability assumptions in causal graphs
with latent unobserved variables [Spirtes, Glymour and Scheines, 2000; Pearl, 2009].
In the causal model shown in Figure 2a, for instance, this assumption rules out the
possibility of an event where the observed variables X and YD are found to be statistically
independent, but UY still aﬀects both of them and the observed independence in the data
results from UY ’s eﬀect canceling out exactly over the path X-UY -YD. In other words, this
assumption serves to rule out an (unlikely) event where incidental equality of parameters
or certain data distributions render two variables statistically independent even though
they are causally related.

Under Assumptions 1 and 2, we can show that statistical independence of X and YD
ensures that X is not confounded by UY . First, we provide a result about the resulting
causal graph structure when X ⊥⊥ YD.

Lemma 1. Let X, YR and YD be three observed variables corresponding to the causal
model in Figure 2a, where UY refers to unobserved causes of YR. If the connectedness (1)
and independence (2) assumptions hold, then X ⊥⊥ YD implies that the edge UY → X
does not exist or that UY is constant.

6

SHARMA ET AL.

Proof (Argument). The proof can be completed directly from Figure 2a and properties
of a causal graphical model.

X ⊥⊥ YD implies that the causal eﬀect of UY on YD and X somehow cancels out on
the path X ← UY → YD. By Assumption 2, this cancellation is not due to incidental
equality of parameters or a particular data distribution, but rather a property of the
causal graphical model. Therefore, this can only happen if
(i) UY is constant (and thus blocks the path), or
(ii) One of the edges exists trivially (does not have a causal eﬀect). Using Assumption
1, UY has a non-zero eﬀect on YD. Then, the only alternative is that the X ← UY edge
does not exist, leading to the unconfounded causal model in Figure 2b.

Proof. We provide a proof by contradiction using the principle of d-separation [Pearl,

2009] in a causal graphical model.

Let us suppose X ⊥⊥ YD, and that the UY → X edge exists and UY is not constant.
Using the rules of d-separation on the causal model in Figure 2a, the path X-UY -YD

corresponds to:

(2.1)

(2.2)

(2.3)

(X ⊥⊥ YD|UY )G
(X (cid:54)⊥⊥ YD)G

(X ⊥⊥ YD)G

where the notation (.)G refers to d-separation under a causal model G. In our case, G
corresponds to the causal model in Figure 2a.

However, using Assumption 2, statistical independence of X and YD implies causal

independence, and thus, d-separation of X and YD.

Equations 2.2 and 2.3 result in a contradiction. To resolve,
(i) Either UY is constant and thus 2.1 implies (X ⊥⊥ YD)G holds, or
(ii) The path X-UY -YD does not exist. Using Assumption 1 of dependence of YD on

UY , the only possibility is that the X ← UY edge does not exist.

We now show that Lemma 1 removes confounding due to UY and that the observational

estimate P (YR|X = x) is also the causal estimate.

Theorem 2.1 (Split-door Criterion). Under the assumptions of Lemma 1, the causal

eﬀect of X on YR is not confounded by UY and is given by:

P (YR|do(X = x)) = P (YR|X = x)

where do(X = x) refers to experimental manipulation of X and YR|X = x refers to the
observed conditional distribution.

Proof (Argument). Lemma 1 leads to two cases:
(i) By the back-door criterion [Pearl, 2009], if UY is constant, then X and YR are uncon-
founded, because the only back-door path between X and YR contains UY on it.
(ii) Similarly, if the UY → X edge does not exist, then X and YR are unconfounded
because absence of the UY → X edge removes the back-door path between X and YR.

In both cases, unconfoundedness implies that the eﬀect of X on YR can be estimated

using the observational distribution.

Proof. The proof follows from an application of the second rule of do-calculus [Pearl,

2009].

P (Y|do(Z = z), W) = P (Y|Z = z, W)

if

(Y ⊥⊥ Z|W)GZ

(2.4)

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

7

where GZ refers to the underlying causal graphical model with all outgoing edges from
Z removed.

Substituting Y = YR, Z = X, GX corresponds to the causal model from Figure 2a

without the X → YR edge. Using Lemma 1, two cases exist:

(i) UY is constant

Let W = UY . Under the modiﬁed causal model GX without the X → YR edge, the path
X-UY -YR is the only path connecting X and YR, which leads to the following d-separation
result:

(YR ⊥⊥ X|UY )GX

(2.5)

Combining Rule 2.4 and the above d-separation result, we obtain

P (YR|do(X = x), UY ) = P (YR|X = x, UY ) = P (YR|X = x)

where the last equality holds because UY is constant throughout.

(ii) The edge UY → X does not exist.

Let W = ∅. Under the modiﬁed causal model GX without the X → YR edge, X and YR
are trivially d-separated because no path connects them without the edge UY → X.

(YR ⊥⊥ X)GX

(2.6)

From Rule 2.4 and the above d-separation result, we obtain

P (YR|do(X = x)) = P (YR|X = x)

2.2. The split-door criterion through structural equations. Although we have already
analyzed the split-door criterion in terms of the causal graphical model in Figure 2a,
for expositional clarity we note that it is also possible to do the same using structural
equations. Speciﬁcally, we can write three structural equations:

x = g(ux, uy, εx)

yr = f (x, uy, εyr)

yd = h(uy, εyd),

(2.7)

where εx, εyr, and εyd are mutually independent, zero-mean random variables that cap-
ture modeling error and statistical variability. As in Assumption 1, we assume that UY
aﬀects both YD and YR. In general, the causal eﬀects among variables may not be linear;
however, for the purpose of building intuition we rewrite the above equations in linear
parametric form:

x = ηux + γ1uy + (cid:15)x

yr = ρx + γ2uy + (cid:15)yr

yd = γ3uy + (cid:15)yd,

(2.8)

where ρ is the causal parameter of interest, and (cid:15)x, (cid:15)yr (cid:15)yd are independent errors in the
regression equations. The split-door criterion requires independence of X and YD, which
in turn implies that Cov(X, YD) = 0:

0 = Cov(X, YD) = E[XYD] − E[X] E[YD]

= E[(ηux + γ1uy + (cid:15)x)(γ3uy + (cid:15)yd)] − E[ηux + γ1uy + (cid:15)x] E[γ3uy + (cid:15)yd]
= γ1γ3 E[UY .UY ] − γ1γ3 E[UY ] E[UY ]
= γ1γ3 Var(UY )

Assuming that YD is aﬀected by UY (and therefore γ3 is not 0), the above can be zero
only if γ1 = 0, or if UY is constant (Var[UY ] = 0). In both cases, X becomes independent
of UY and the following regression can be used as an unbiased estimator for the eﬀect of
X on YR:

yr = ρx + (cid:15)(cid:48)
yr

(2.9)

where (cid:15)(cid:48)

yr denotes an independent error.

8

SHARMA ET AL.

3. Applying the Split-door Criterion. The results of the previous section moti-
vate an algorithm for applying the split-door criterion to observational data. Speciﬁcally,
given an empirical test for independence between the cause X and the auxiliary outcome
YD, we can select instances in our data that pass this test and satisfy the split-door
criterion. In this section we develop such a test for time series data, resulting in a simple,
scalable identiﬁcation algorithm.

At a high level, the algorithm works as follows. First, divide the data into equally-
spaced time periods τ such that each period has enough data points to reliably estimate
the joint probability distribution P (X, YD). Then, for each time period τ ,

1. Determine whether X and YD are independent using an empirical independence

2. If X and YD are determined to be independent, then the current time period τ
corresponds to a valid split-door instance. Use the observed conditional probability
P (YR|X = x) to estimate the causal eﬀect in the time period τ . Otherwise, exclude
the current time period from the analysis.

3. Average over all time periods where X ⊥⊥ YD to obtain the mean causal eﬀect of

test.

X on YR.

Implementing the algorithm requires making suitable choices for an independence test
and also its signiﬁcance level, taking into account multiple comparisons. In the follow-
ing sections, we discuss these choices in detail, as well as sensitivity of the method to
violations in our assumptions.

3.1. Choosing an independence test. Each X-YD pair in Step 1 provides two vectors
of length τ with observed values for X and YD. The key decision is whether these vec-
tors are independent of each other. In theory any empirical test that reliably establishes
independence between X and YD is suﬃcient to identify instances where the split-door
criterion applies. For instance, assuming we have enough data, we could test for inde-
pendence by comparing the empirical mutual information to zero [Steuer et al., 2002;
Pethel and Hahs, 2014]. In practice, however, because we consider subsets of the data
over relatively small time periods τ , there may be substantial limits to the statistical
power we have in testing for independence. For example, it is well known that in small
sample sizes, testing for independence via mutual information estimation can be heavily
biased [Paninski, 2003].

Thus, when working with small time periods τ we recommend the use of exact inde-
pendence tests and randomization inference [Agresti, 1992, 2001; Lydersen et al., 2007].2
In general, this approach involves repeatedly sampling randomized versions of the em-
pirical data to simulate the null hypothesis and then comparing a test statistic on the
observed data to the same on the null distribution. Speciﬁcally, for each X-YD pair,
we simulate the null hypothesis of independence between X and YD by replacing the
observed X vector with a randomly sampled vector from the overall empirical distribu-
tion of X values. From this simulated X-YD instance, we compute a test statistic that
captures statistical dependence, such as the distance correlation, which can detect both
non-linear and linear dependence [Sz´ekely et al., 2007; de Siqueira Santos et al., 2014]. We
then repeat this procedure many times to obtain a null distribution for the test statistic
of this X-YD pair. Finally, we compute the probability p of obtaining a test statistic
as extreme as the observed statistic under the null distribution, and select instances in
which the probability p is above a pre-chosen signiﬁcance level α.

3.2. Choosing a signiﬁcance level.

In contrast to standard hypothesis testing where
one is looking to reject the null hypothesis that two variables are independent and there-
fore thresholds on a small p-value, here we are looking for independent X-YD pairs that

2 When X and YD are discrete variables, methods such as Fisher’s exact test are appropriate. If,
however, X and YD are continuous—as is this case for the example we study in Section 5—we recommend
the use of resampling-based randomization inference for establishing independence.

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

9

(a) General model: Unobserved variables
split into UY and VY

(b) Invalid split-door model: X is indepen-
dent of UY but not VY

Fig 3: Violation of the connectedness assumption. Causes for X and YR consist of two
components, UY and VY , where VY does not aﬀect YD and hence is undetectable by
the split-door criterion. In the general causal model shown in Panel (a), X → YR is
confounded by both UY and VY . In the causal model corresponding to a split-door
instance in Panel (b), X → YR is still confounded by the common cause VY .

are highly probable under the null and thus want a large p-value. In other words, we are
interested in a low Type II error (or false negatives), in contrast to standard null hypoth-
esis testing, where the focus is on Type I errors (false positives) and hence signiﬁcance
levels are set low. Therefore, one way to choose a signiﬁcance level would be to choose α
as close as possible to 1 to minimize Type II errors when X and YD are dependent. At the
same time, we need to ensure that the test yields adequate power for ﬁnding independent
X-YD pairs. Unlike a conventional hypothesis test for dependent pairs, power for our test
is 1 − α, the probability that the test declares an X-YD pair to be independent when it is
actually independent. As we increase α, type II errors decrease, but power also decreases.
Complicating matters, the combination of low power and a large number of hypothesis
tests raises concerns about falsely accepting pairs that are actually dependent. As an ex-
treme example, even when all X-YD pairs in a given dataset are dependent, some of them
will pass the independence test simply due to random chance. Therefore, a more princi-
pled approach to selecting α comes through estimating the expected fraction of erroneous
split-door instances returned by the procedure, which we refer to as φ. As described in
Appendix A, we apply techniques from the multiple comparisons literature [Storey, 2002;
Liang and Nettleton, 2012; Farcomeni, 2008] to estimate this fraction φ for any given
signiﬁcance level.

3.3. Sensitivity to identifying assumptions. The above algorithm yields a causal es-
timate only if the identifying assumptions of connectedness and independence are satis-
ﬁed. Independence is based on the standard faithfulness assumption in causal discovery
[Spirtes, Glymour and Scheines, 2000]. Connectedness, on the other hand, requires jus-
tiﬁcation based on domain knowledge. Even when the connectedness assumption seems
plausible, we recommend a sensitivity analysis to assess the eﬀects of potential violations
to this assumption.

From Assumption 1, violation of connectedness implies that there exist some unob-
served variables that aﬀect X and YR but not YD. Figure 3a shows this scenario, which is
identical to the model in Figure 2a with the addition of an unobserved variable VY that
aﬀects X and YR, but not YD. Applying the split-door criterion in this setting ensures
that there is no eﬀect of UY on X, but does not alleviate possible confounds from VY , as
shown in Figure 3b. Note that this is analogous to the situation in back-door-based meth-
ods when one fails to condition on unobserved variables that aﬀect both the treatment
and outcome. Correspondingly, sensitivity analyses designed for back-door-based meth-
ods [Harding, 2009; Rosenbaum, 2010; VanderWeele and Arah, 2011; Carnegie, Harada
and Hill, 2016] can be readily adapted to analyzing split-door instances. In addition, not-
ing that split-door estimates represent averages over all discovered split-door instances,

10

SHARMA ET AL.

Graphical model

Description

Untestable as-
sumptions

Limitations

Recommendations
example

Condition on ob-
served confounders
W to isolate the
treatment effect.

X ⊥⊥ U or
Y ⊥⊥ U

Unlikely
there
are
unobserved
founders U .

that
no
con-

click-
Regress
throughs on product
attributes and direct
visits
recom-
to
mended product.

Analyze subset of
data that has inde-
pendent variation
in the treatment.

Z ⊥⊥ U and
Z ⊥⊥ Y |X, U

Difficult to find a
source of exoge-
nous variation in
the treatment.

marginal
Measure
click-throughs
on
products that expe-
rience large, sudden
shocks in traffic.

Analyze subset of
data where
the
auxiliary outcome
YD is independent
of the treatment.

YD (cid:54)⊥⊥ UY

depen-
Requires
dency
between
an auxiliary out-
come
all
and
confounders.

marginal
Measure
click-throughs
on
all pairs of products
that have uncorre-
lated direct traffic.

(a) Back-door
criterion

(b) Instrumental
variable

(c) Split-door
criterion

Fig 4
Comparison of methods for estimating the eﬀect of a treatment X on an outcome Y . W and U
represent all observed and unobserved confounders, respectively, that commonly cause both X and Y .

we introduce an additional sensitivity parameter κ that denotes the fraction of instances
for which connectedness is violated. In Appendix B we provide a derivation showing that
sensitivity for the split-door estimate reduces to sensitivity for back-door methods and
conduct this analysis for the application presented in Section 5.

4. Connections to other methods. The split-door criterion is an example of
methods that use empirical independence tests to identify causal eﬀects under certain
assumptions [Jensen et al., 2008; Cattaneo, Frandsen and Titiunik, 2015; Sharma, Hof-
man and Watts, 2015; Grosse-Wentrup et al., 2016]. By searching for subsets of the data
where desired independence holds, it also shares some properties with natural experiment
methods such as instrumental variables and conditioning methods such as regression. We
discuss these connections below; table 4 provides a summary for easy comparison.

4.1. Instrumental Variables. Both the split-door criterion and instrumental variable
(IV) methods can be used to exploit naturally occurring variation in subsets of ob-
servational data to identify causal eﬀects. Importantly, however, they make diﬀerent
assumptions. In IV methods, one uses an auxiliary variable Z, called an instrument,
that is assumed to be exogenous and that systematically shifts the distribution of the
cause X. The validity of an instrument relies on two additional assumptions: ﬁrst that
it is eﬀectively random with regard to potential confounders (Z ⊥⊥ U ), and second that
the instrument aﬀects the outcome Y only through the cause X (Z ⊥⊥ Y |X, U ). Both of
these conditions involve independence claims between observed and unobserved variables,
making them impossible to test in practice [Dunning, 2012].

The split-door criterion also relies on an auxiliary variable, but one that relates to the
outcome instead of the treatment. Speciﬁcally, it exploits an auxiliary outcome YD that
serves as a proxy for unobserved common causes UY under three important assumptions.
The ﬁrst is that the cause X does not aﬀect YD directly. The second assumption requires
that all unobserved confounders (between the cause and outcome) that aﬀect YR also
aﬀect YD. As with IV methods above, these two assumptions involve knowledge of an
unobserved variable and, as a result, cannot be tested. The third assumption requires
independence between the cause X and the auxiliary outcome YD. Since both of these
variables are observed, this assumption can be tested empirically so long as we are in the
standard setting where statistical independence implies causal independence (Assumption
2 ), equivalent to the assumption of faithfulness [Spirtes, Glymour and Scheines, 2000].
It is diﬃcult to compare these two sets of assumptions in general, but in diﬀerent
scenarios, one of these methods may be more suitable than the other. If a valid instrument
is known to exist, for instance through changes in weather or as a result of a lottery, the

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

11

variation it produces can and should be exploited to identify causal eﬀects of interest.
The split-door criterion, in contrast, is most useful when one suspects there is random
variation in the data, but cannot identify its source a priori. In particular, it is well-suited
for large-scale data where the ﬁrst two assumptions mentioned above are plausible, such
as in digital or online systems.

4.2. Back-door criterion. Alternatively, the split-door criterion can be interpreted as
using YD as a proxy for all confounders UY , and estimating the causal eﬀect whenever
YD (and hence UY ) is independent of X. Viewed this way, the split-door approach may
appear to be nothing more than a variant of the back-door criterion where one conditions
on YD instead of UY , however there are two key diﬀerences between the two methods.

First, substituting YD for UY in the back-door criterion assumes that YD is a perfect
proxy for UY . This is a much stronger assumption than requiring that YD be simply
aﬀected by UY , because any diﬀerence (e.g., measurement error) between YD and UY
can invalidate the back-door criterion [Spirtes, Glymour and Scheines, 2000]. Second, the
two methods diﬀer in their approach to identiﬁcation. The split-door criterion controls for
the eﬀect of unobserved confounders by ﬁnding subsets of data where X is not aﬀected
by UY , whereas the back-door criterion conditions on a proxy for UY to nullify the
eﬀect of unobserved confounders. Therefore, by directly controlling at the time of data
selection, the split-door criterion focuses on admitting a subset of the data for analysis
and simpliﬁes eﬀect estimation, whereas methods based on back-door criterion such as
regression, matching, and stratiﬁcation process the whole dataset and extract estimates
via statistical models [Morgan and Winship, 2014].

To illustrate these diﬀerences, we compare mathematical forms of the split-door and
back-door criteria in terms of regression equations. Conditioning on YD using regression
will lead to the following equation

applied to the entire dataset. In contrast the split-door criterion leads to the simpler
equation (as shown earlier in Section 2.2)

yr = ρ(cid:48)(cid:48)x + βyd + (cid:15)(cid:48)(cid:48)

yr,

yr = ρx + (cid:15)(cid:48)

yr,

applied only to subsets of data where X and YD are independent.

4.3. Methods based on empirical independence tests. Finally, the split-door criterion
is similar to recent work that proposes a data-driven method for determining the ap-
propriate window size in regression discontinuity designs [Cattaneo, Frandsen and Titiu-
nik, 2015; Cattaneo, Titiunik and Vazquez-Bare]. In regression discontinuities, treatment
(e.g., acceptance into a program) is assigned based on whether an observed variable (e.g.,
a test score) is above or below a pre-determined cutoﬀ. The assumption is that one can
compare outcomes for those just above and just below the cutoﬀ to estimate causal ef-
fects, but the central problem is how far from the cutoﬀ this assumption holds. The
authors present a data-driven method for selecting a window by testing for independence
between the treatment and pre-determined covariates that are uncoupled to the outcome
of interest. This approach resembles the split-door criterion in that both use indepen-
dence tests to determine which subsets of the data to include when making a causal
estimate. As a result, both methods are subject to concerns around multiple hypothesis
testing, although the regression discontinuity setting typically involves many fewer com-
parisons than the split-door criterion (dozens instead of the thousands we analyze here)
and occurs over nested windows. For these reasons we treat multiple comparisons diﬀer-
ently, estimating the error rate in identifying independent instances instead of adjusting
nominal thresholds to try to eliminate errors.

12

SHARMA ET AL.

Fig 5: Screenshot of a focal product, the book “Purity”, and its recommendations on
Amazon.com.

5. Application: Impact of a Recommender System. We now apply the split-
door criterion to the problem of estimating the causal impact of Amazon.com’s recom-
mender system. Recommender systems have become ubiquitous in online settings, pro-
viding suggestions for what to buy, watch, read or do next [Ricci, Rokach and Shapira,
2011]. Figure 5 shows an example of one of the millions of product pages on Ama-
zon.com, where the main item listed on the page, or focal product, is the book “Purity”
by Jonathan Franzen. Listed alongside this item are a few recommended products—two
written by Franzen and one by another author—suggested by Amazon as potentially of
interest to a user looking for “Purity”. Generating and maintaining these recommenda-
tions takes considerable resources, and so a natural question one might ask is how exactly
exposure to these recommended products changes consumer activity.

While simple to state, this question is diﬃcult to answer because it requires an estimate
of the counterfactual of what would have happened had someone visited a focal product
but had not been exposed to any recommendations. Speciﬁcally, we would like to know
how much traﬃc recommender systems cause, over and above what would have happened
in their absence. Naively one could assume that users would not have viewed these other
products without the recommender system, and as a result simply compute the observed
click-through rate on recommendations [Mulpuru, 2006; Grau, 2009]. As discussed earlier,
however, this assumption ignores correlated demand: users might have found their way
to some of these recommended products anyway via direct search or browsing, which we
collectively refer to as “direct traﬃc”. For instance, some users who are interested in the
book “Purity” might be fans of Franzen in general, and so might have directly searched
on Amazon.com for his other works such as “Freedom” or “The Corrections”, even if they
had not been shown recommendations linking to them. The key to properly estimating
the causal impact of the recommender, then, lies in accounting for this correlated demand
between a focal product and its recommendations.

In this section we show how the split-door criterion can be used to eliminate the
issue of correlated demand by automatically identifying and analyzing instances where
demand for a product and one (or more) of its recommendations are independent over
some time period τ . We do so by ﬁrst formalizing this problem through a causal graphical
model of recommender system traﬃc, revealing a structure amenable to the split-door
criterion. Then we apply the criterion to a large-scale dataset of web browsing activity on
Amazon.com to discover thousands of instances satisfying the criterion. Our results show
that a naive observational estimate of the impact of this recommender system overstates
the causal impact on the products analyzed by a factor of at least two. We conclude with
a number of robustness checks and comments on the validity and generalizability of our
results.

5.1. Building the causal model. The above discussion highlights that unobserved
common demand for both a focal product and its recommendations can introduce bias in
naive estimates of the causal click-through rate (CTR) on recommendations. Referring

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

13

back to Figure 2a, we formalize the problem as follows, with variables aggregated for
each day:

• X denotes the number of visits to the focal product i’s webpage.
• YR denotes recommendation visits, the number of visits to the recommended prod-
uct j through clicks on the recommendation for product j on product i’s webpage.
• YD denotes direct visits, the number of visits to product j that did not occur
through clicking on a recommendation. These could be visits to j from Amazon’s
search page or through direct visits to j’s webpage.

• UY denotes unobserved demand for product j, including both recommendation

click-throughs and direct visits.

• UX represents the part of unobserved demand for product i that is independent of

UY .

To apply the split-door criterion, we must investigate the plausibility of the con-
nectedness and independence assumptions from Section 2.1. First, the connectedness
assumption states that both YR and YD are aﬀected (possibly diﬀerently) by the same
components of demand UY for the product j. As mentioned above, connectedness is espe-
cially plausible in the context of online recommender systems where products are easily
reachable through multiple channels (e.g., search, direct navigation or recommendation
click-through) and it is unlikely that demand for a product manifests itself exclusively
through only one of these channels. Speciﬁcally, it is unlikely that there exists a compo-
nent of demand for a product that manifests itself only through indirect recommendation
click-throughs, but not through direct visits. Put another way, for connectedness not to
hold, it would have to be the case that users would have demand for a product only if
they arrived via a recommendation link, but not through other means. To the best of
our knowledge no path-speciﬁc feature of this sort exists on Amazon; thus, we expect the
connectedness assumption to hold.

Second, with respect to the independence assumption, although we cannot rule out
coincidental cancellation of eﬀects that result in X ⊥⊥ YD and violate the assumption,
we expect such events to be unlikely over a large number of product pairs. Furthermore,
for complementary product recommendations (which are the focus of this paper), we
can logically rule out violation of the independence assumption because the demand for
two complementary products are expected to be positively correlated with each other.
Therefore, it is reasonable to assume that the unobserved demand UY (and all its sub-
components) aﬀect both X and YD in the same direction. For instance, let the eﬀect
of UY be increasing for both X and YD. Then the independence assumption is satisﬁed
because the eﬀect of UY cannot be canceled out on the path X ← UY → YD if the eﬀects
of UY (and any of its sub-components) on X and YD are all positive. Given the above
assumptions, the same reasoning from Section 2.1 allows us to establish that X ⊥⊥ YD is
a suﬃcient condition for causal identiﬁcation.

5.2. Browsing data. Estimating the causal impact of Amazon.com’s recommender
system requires ﬁne-grained data detailing activity on the site. To obtain such informa-
tion, we turn to anonymized browsing logs from users who installed the Bing Toolbar
and consented to provide their anonymized browsing data through it. These logs cover a
period of nine months from September 2013 to May 2014 and contain a session identiﬁer,
an anonymous user identiﬁer, and a time-stamped sequence of all non-secure URLs that
the user visited in that session. We restrict our attention to browsing sessions on Ama-
zon.com, which leaves us with 23.4 million page visits by 2.1 million users spanning 1.3
million unique products. Of these products, we examine those that receive a minimum
of 10 page visits on at least one day in this time period, resulting in roughly 22,000 focal
products of interest.

Amazon shows many kinds of recommendations on its site. We limit our analysis to
the “Customers who bought this also bought” recommendations depicted in Figure 5, as
these recommendations are the most common and are shown on product pages from all

14

SHARMA ET AL.

product categories. To apply the split-door criterion, we need to identify focal product and
recommended product pairs from the log data and separate out traﬃc for recommended
products into direct (YD) and recommended (YR) visits. Fortunately it happens to be
the case that Amazon makes this identiﬁcation possible by explicitly embedding this
information in their URLs. Speciﬁcally, given a URL for an Amazon.com page visit, we
can use the ref, or referrer, parameter in the URL to determine if a user arrived at a
page by clicking on a recommendation or by other means. We then use the sequence
of page visits in a session to identify focal and recommended product pairs by looking
for focal product visits that precede recommendation visits. Further details about the
toolbar dataset and construction of focal and recommended product pairs can be found
in past work [Sharma, Hofman and Watts, 2015].

5.3. Applying the split-door criterion. Having argued for the assumptions underlying
the split-door criterion and extracted the relevant data from browsing logs, the ﬁnal step
in estimating the causal eﬀect of Amazon.com’s recommendation system is to use the cri-
terion to search for instances where a product and its recommendation have uncorrelated
demand.

Recalling Section 3, we employ a randomization test to search for 15-day time periods
that fail to reject the null hypothesis that direct visits to a product and one (or more) of
its recommended products are independent. The choice of 15 days represents a trade-oﬀ
between two requirements: ﬁrst, a time period large enough to yield reliable estimates;
and second, a time period short enough that Amazon’s recommendations for any given
product are unlikely to have changed within that window.

The full application of the split-door criterion is as follows. For each focal product i

and each τ = 15 day time period:

1. Compute X (i), the number of visits to the focal product on each day, and Y (ij)
R ,
the number of click-throughs to each recommended product j. Also record the total
direct visits Y (j)

D to each recommended product j.

2. For each recommended product j, use the randomization test from Section 3.1 to

determine if X (i) is independent of Y (j)

D at a pre-speciﬁed signiﬁcance level.3

• If X (i) is found to be independent of Y (j)

rate (CTR), ˆρijτ = ((cid:80)τ
CTR. Otherwise ignore this product pair.

R )/((cid:80)τ

t=1 Y (ij)

D , compute the observed click-through
t=1 X (i)), as the causal estimate of the

3. Aggregate the causal CTR estimate over all recommended products to compute

the total causal CTR per focal product, ˆρiτ .

Finally, average the causal CTR estimate over all time periods and focal products to arrive
at the mean causal eﬀect, ˆρ, and compute the rate of erroneous split-door instances φ to
estimate error in this estimate, as detailed in Appendices A and C.

5.4. Results. Applying the above algorithm results in over 114,000 potential split-
door instances, where each instance consists of a pair of focal and recommended product
over a 15-day time period. At a signiﬁcance level of α = 0.95, we obtain more than 7,000
instances that satisfy the split-door criterion. Consistent with previous work [Sharma,
Hofman and Watts, 2015], the corresponding causal CTR estimate ˆρ is 2.6% (with the
error bars spanning 2.0% to 2.7%), roughly one quarter of the naive observational es-
timate of 9.6% arrived at by computing the click-through rate across all focal and rec-
ommended product pairs. Put another way, these results imply that nearly 75% of page
visits generated via recommendation click-throughs would likely occur in the absence of
recommendations.

3Here we ﬁlter out any time periods where YD is exactly constant (because that will satisfy empirical

independence conditions trivially).

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

15

(a) Accepted at α=0.95

(b) Rejected at α=0.95

Fig 6: Examples of time series for focal and recommended products that are (a) accepted
or (b) rejected by the split-door criterion at a signiﬁcance level of α = 0.95 for the
independence test.

(a)

(b)
Fig 7: Subplot (a) shows the number of valid split-door instances obtained as the p-value
threshold (α) is increased. Subplot (b) shows the expected fraction of erroneous instances
(φ) returned by the method for those values of α. The corresponding estimate for causal
CTR is shown in Subplot (c); error bars account for both bias due to φ and natural
variance in the mean estimate.

(c)

Figure 6a shows examples of product pairs that are accepted by the test at α = 0.95.
The example on the left shows a focal product that receives a large and sudden shock in
page visits, while direct visits to its recommended product remains relatively ﬂat. This
is reminiscent of the examples analyzed in Carmi, Oestreicher-Singer and Sundararajan
[2012] and Sharma, Hofman and Watts [2015]. The example on the right, however, shows
more general patterns that are accepted under the split-door criterion but not considered
by these previous approaches: although direct visits to both the focal and recommended
products vary substantially, they do so independently, and so are still useful in our
estimate of the recommender’s eﬀect. Conversely, two example product pairs that are
rejected by the test are shown in Figure 6b. As is visually apparent, visit patterns for
each of the focal and recommended product pairs are highly correlated, and therefore
not useful in our analysis.

Changing the nominal p-value threshold used in the independence test allows us to
explore a tradeoﬀ between coverage across products in our dataset and the precision
of our causal estimate. As detailed in Appendix A, a lower threshold results in more
discovered instances, but with a higher likelihood of these instances being invalid. For
instance, Figures 7a and 7b show that decreasing the threshold to α = 0.80 results in
over 20,000 split-door instances covering nearly 11,000 unique focal products, but does so
at the expense of increasing the expected fraction of invalid instances to 0.21, indicating
that approximately one in ﬁve of the returned split-door instances may be invalid. The
result, summarized in Figure 7c, is that the error bars on our estimate of ρ increase as we
decrease α. These error bars, calculated using Equation C.4 from Appendix C, account

16

SHARMA ET AL.

Fig 8: Comparison of the causal CTR with the naive observational CTR for products
that satisfy the split-door criterion. Categories are ordered by the number of products
found by the split-door criterion in each category, with eBooks containing the most and
Health and Beauty the least.

for both bias due to erroneous split-door instances and the natural variance in the mean
estimate due to sampling.4 As α decreases, erroneous instances due to φ contribute to
most of the magnitude of the error bars shown in Figure 7c. We observe that α = 0.95
oﬀers a good compromise: error bounds are within 1 percentage point and we obtain
more than 7,000 split-door instances.

Furthermore, we can break these estimates down by the diﬀerent product categories
present on Amazon.com. Figure 8 shows the variation of ˆρ across the most popular
categories, at a nominal signiﬁcance level of α = 0.95. For the set of focal products
that satisfy the split-door criterion, we also compute the naive observational CTR. We
see substantial variation in the naive estimate, ranging from 14% on e-Books to 5% on
Personal Computer. However, when we use the split-door criterion to compute estimates,
we ﬁnd that the causal CTR for all product categories lies below 5%. These results
indicate that naive observational estimates overstate the causal impact by anywhere
from two- to ﬁve-fold across diﬀerent product categories.

There are two clear advantages to the split-door criterion compared to past approaches
for estimating the causal impact of recommender systems. First, we are able to study a
larger fraction of products compared to instrumental variable approaches that depend on
single-source variations [Carmi, Oestreicher-Singer and Sundararajan, 2012] or restricting
our attention to mining only shocks in observational data [Sharma, Hofman and Watts,
2015]. On the same dataset, the shock-based method in Sharma, Hofman and Watts [2015]
identiﬁed valid instances on 4,000 unique focal products, while the split-door criterion
ﬁnds instances for over 5,000 unique focal products at α = 0.95, and over 11,000 at
α = 0.80. Second, the split-door criterion provides a principled method to select valid
instances for analysis by tuning α, the desired signiﬁcance level, while also allowing for
an estimate of the fraction of falsely accepted instances, φ.

5.5. Threats to validity. As with any observational analysis, our results rely on cer-
tain assumptions that may be violated in practice. Furthermore, results obtained on a
subset of data may not be representative of the broader dataset of interest. Here we con-

4Note that the error bars are asymmetric; we expect erroneous split-door instances to drive the causal
estimate up from its true value, under the assumption that demand for the two products are positively
correlated with each other, as argued in Section 5.1.

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

17

(a)

(b)

Fig 9: Sensitivity analysis of the obtained click-through estimate. Panel (a) shows the
scenario where all split-door instances may be invalid. Panel (b) assumes that at most
half of the instances are invalid. The deviation of the true estimate from the obtained
estimate increases as the magnitude of the confounding from VY to X( c1) or Y (c2)
increases; however this deviation is lower in Panel (b). In both ﬁgures, dotted line shows
the obtained CTR estimate.

duct additional analyses to assess both the internal and external validity of our estimate
of the causal eﬀect of Amazon’s recommendations.

5.5.1. Internal validity: Sensitivity to the connectedness assumption. As described in
Section 3.3, connectedness is the key identifying assumption for the split-door criterion.
Here we describe a test for sensitivity of the obtained estimate (ˆρ) to violations of the
connectedness assumption.

Referring to the causal model in Figure 3a, violation of the connectedness assumption
implies that there exist components of unobserved demand VY that aﬀect both focal
product visits X and recommendation click-throughs YR, but not direct visits to the
recommended product YD. For simplicity, let us assume that VY is univariate normal
and aﬀects both X and YR linearly. We can write the corresponding structural equations
for the causal model in Figure 3b for each split-door instance as

x = c1vy + (cid:15)1
yr = f (x) + c2vy + (cid:15)2,

(5.1)

(5.2)

where f is an unknown function, and (cid:15)1 and (cid:15)2 are independent from all variables men-
tioned above and are also mutually independent. Note that (cid:15)1 includes the eﬀect of UX
and (cid:15)2 includes the eﬀect of UY . For any split-door instance, the estimator from Sec-
tion 5.3 estimates the causal eﬀect assuming that either c1 or c2 is zero.

To test the sensitivity of our estimate to the connectedness assumption, we take our
actual data and introduce an artiﬁcial confound VY by simulation, adding c1VY to X
and c2VY to YR, respectively, for a range of diﬀerent c1 and c2 values. We simulate VY
as a standard normal and vary c1 and c2 between [−1, 1], and compare these artiﬁcially
confounded estimates to our actual estimate of ˆρ = 2.6% for α = 0.95. Figure 9a shows
the deviation between estimates using the actual and simulated data as c1 and c2 vary.
The diﬀerence is maximized when both c1 and c2 are high in magnitude and is negligible
when either of c1 or c2 are zero. These simulation results suggest a bilinear sensitivity

18

SHARMA ET AL.

(a)

(b)

Fig 10: The distribution of products and total visits over product categories. Among
products with at least 10 page visits on at least one day, the subset of focal products
that satisfy the split-door criterion are nearly identical to the set of all products. Fraction
of page visits to those focal products show more variation, but the overall distributions
are similar.

to c1 and c2, a result we conﬁrm theoretically in the case of a linear causal model in
Appendix B.

This analysis assumes that all split-door instances violate the connectedness assump-
tion. Recognizing that this need not be the case, and that only some instances may be
invalid, we introduce a third sensitivity parameter κ, which corresponds to the fraction
of split-door instances that violate connectedness. For instance, we can test sensitivity of
the estimate when at least half of the split-door instances satisfy connectedness, as done
by Kang et al. [2016] for inference under multiple possibly invalid instrumental variables.
As shown in Figure 9b, when κ = 0.5 deviations from the obtained split-door estimate
are nearly halved, resulting in more robust estimates.

5.5.2. External validity: Generalizability. Although the split-door criterion yields valid
estimates of the causal impact of recommendations for the time periods where prod-
uct pairs are found to be statistically independent, it is important to emphasize that
products in the split-door sample may not be selected at random, thus violating the as-
if-random [Angrist, Imbens and Rubin, 1996] assumption powering generalizability for
natural experiments. As a result, care must be taken to extrapolate these estimates to
all products on Amazon.com.

Fortunately, as shown in Figure 10, the distribution of products and page visits in our
sample closely matches the inventory and activity on Amazon.com. Products with at least
one valid split-door time period span many product categories and cover nearly a quarter
of all focal products in the dataset at α = 0.95. Figure 10a shows that the distribution of
products analyzed by the split-door criterion across diﬀerent product categories is almost
identical to the overall set of products. Figure 10b shows a similar result for the number
of page visits of these products across diﬀerent product categories, except for eBooks
which are over-represented in valid split-door instances. For comparison, we apply the
same popularity ﬁlter that we used for the split-door criterion—at least 10 page visits
on at least one day—to the dataset with all products.

Although these results do not necessarily imply that the as-if-random assumption
is satisﬁed (indeed it is very likely not satisﬁed) they do indicate that the split-door
criterion at least allows us to estimate causal eﬀects over a diverse sample of popular
product categories, which is a clear improvement over past work [Carmi, Oestreicher-
Singer and Sundararajan, 2012; Sharma, Hofman and Watts, 2015].

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

19

6. Discussion.

In this paper we have presented a method for computing the causal
eﬀect of a variable X on another variable YR whenever we have an additional variable
YD which follows some testable conditions, and have shown its application in estimating
the causal impact of a recommender system. We now suggest guidelines to ensure proper
use of the criterion and discuss other applications for which it might be used.

6.1. Guidelines for using the criterion. As with any non-experimental method for
causal inference, the split-door criterion rests on various untestable assumptions and
requires making certain modeling choices. We encourage researchers to reason carefully
about these assumptions, explore sensitivity to modeling choices, and examine threats
to the validity of their results.

6.1.1. Reason about assumptions. The split-door criterion relies on two untestable
assumptions: independence (of X and YD), and connectedness (i.e. non-zero causal eﬀect
of UY on YD). The independence assumption is a standard assumption for observational
causal inference. Barring coincidental equality of parameters such that the eﬀect of unob-
served confounders on X and YD cancel out, the independence assumption is likely to be
satisﬁed. Nonetheless we encourage researchers to think carefully about this assumption
in applying the criterion in other domains. Depending on the application it may be pos-
sible to rule out such cancellations. For example, in our recommendation system study
we expect demand for the focal and recommended product to be correlated. Therefore,
the causal eﬀect of demand on both products is expected to be directionally identical,
and hence cancellation becomes impossible.

The connectedness assumption is potentially more restrictive. In general, it is plau-
sible whenever measurements YR and YD are additive components of the same tangible
outcome Y that can be reached by similar means. That said, connectedness remains an
untestable assumption where, once again, domain knowledge should be used to assess
its plausibility. For instance, even when YR and YD are additive components, in some
isolated cases, UY may not be connected to YD at all. In a recommender system this
can happen when customers with pre-existing interest in a product somehow visit it
only through recommendation click-throughs from other products. In such a scenario,
the split-door criterion would be invalid. We note, however, that this situation can arise
only in the (unlikely) event that no such user found the product directly. When there is
even a small number of users that visit the product directly, the split-door criterion will
again be valid and, depending on the precision of the statistical independence condition,
can be applied.

6.1.2. Explore sensitivity to test parameters. A key advantage of the split-door cri-
terion is that once these two assumptions are met, it reduces the problem of causal
identiﬁcation to that of implementing a test for statistical independence. At the same
time, this requires choosing a suitable statistical test and deciding on any free parameters
the test may have. For instance, in the case of the randomization test used here, there is
a signiﬁcance level α used to determine when to accept or reject focal and recommended
product pairs as statistically independent. Any such parameters should be varied to check
the sensitivity of estimates to these choices, as in Figures 7b and 7c.

6.1.3. Examine threats to validity. After identifying and estimating the eﬀect of inter-
est, one should examine both the internal and external validity of the resulting estimate.
In terms of internal validity, we recommend conducting a sensitivity analysis to assess
how results change when the assumptions required for identiﬁcation are violated. In the
case of the recommender system example, we simulated violations of the connectedness
assumption by artiﬁcially adding correlated noise to X and YR (but not YD) and re-ran
the split-door method to look at variation in results, as shown in Figure 9.

Finally, after establishing internal validity, one needs to consider how useful the re-
sulting estimate is for practical applications. As remarked earlier and demonstrated in

20

SHARMA ET AL.

our recommender system application, the split-door criterion is capable of capturing the
local average causal eﬀect for a large sample of the dataset that satisﬁes the required
independence assumption (X ⊥⊥ YD). The argument has been made that such local es-
timates are indeed useful in themselves [Imbens, 2010]. That said, the sample may not
be representative of the entire population, and so one must always be careful to qualify
an extension of the split-door estimate to the general population. Naturally, the more
instances discovered by the method, the more likely the estimate is to be of general use.
Additionally, we recommend that researchers perform checks similar to those in Figure 10
to compare the distribution of any available covariates to check for diﬀerences between
the general population and instances that pass the split-door criterion.

6.2. Potential applications of the split-door criterion. The key requirement of the
split-door criterion is that the outcome variable must comprise two distinct components:
one that is potentially aﬀected by the cause, and another that is not directly aﬀected by it.
In addition, we should have suﬃcient reason to believe that the two outcome components
share common causes (i.e. the connectedness assumption must be satisﬁed), and that
one of outcome variables can be shown to be independent of the cause variable (i.e. the
independence assumption must be satisﬁed). These might seem like overly restrictive
assumptions that limit applicability of the criterion, but in this section we argue that
there are in fact many interesting cases where the split-door criterion can be employed.
As we have already noted, recommendation systems such as Amazon’s are especially
well-suited to these conditions, in large part because YD has a natural interpretation
of “direct traﬃc”, or any traﬃc that is not caused by a particular recommendation.
Likewise the criterion can be easily applied to other online systems that automatically
log user visits, such as in estimating the causal eﬀect of advertisements on search engines
or websites. Somewhat more broadly, time series data in general may be amenable to
the split-door criterion, in part because diﬀerent components of the outcome occurring
at the same time are more likely to be correlated than components that share other
characteristics, and in part because time series naturally generate many observations on
the input and output variables, which permits convenient testing for independence.

For example, consider the problem of estimating the eﬀect of social media on news
consumption. There has been recent interest [Flaxman, Goel and Rao, 2016] in how social
media websites such as Facebook impact the news that people read, especially through
algorithmic recommendations such as those for “Trending news”. Given time series data
for user activity on a social media website and article visits from news website logs, we
can use the split-door criterion to estimate the eﬀect of social media on news reading.
Here YR would correspond to the visits that are referred from social media, and YD would
be all other direct visits to the news article. Most websites record the source of each page
visit, so obtaining these two components for the outcome—visits to an article through
social media and through other means—should be straightforward. Whenever people’s
social media usage is not correlated with direct visits to a news article, we can identify
the causal eﬀect of social media on news consumption. Similar analysis can be applied
to problems such as estimating the eﬀect of online popularity of politicians on campaign
ﬁnancing or the eﬀect of television advertisements on purchases.

Finally, although we have focused on online settings for which highly granular time
series data is often collected by default, we note that there is nothing intrinsic to the
split-door criterion that prevents it from being applied oﬄine. For example, many retail-
ers routinely send direct mail advertisements to existing customers whom they identify
through loyalty programs. The split-door criterion could easily be used to estimate the
causal eﬀect of these advertisements on product purchases: X would be the number of
customers that are sent an advertisement; YR would be the customers among them who
purchased the product; and YD would be the number of customers who bought the prod-
uct without receiving the mailer. More generally, the split-door criterion could be used
in any context where the outcome of interest can be diﬀerentiated into more than one
channel.

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

21

7. Conclusion.

In closing we note that the split-door criterion is just one example
of a more general class of methods that adopt a data-driven approach to causal dis-
covery [Jensen et al., 2008; Sharma, Hofman and Watts, 2015; Cattaneo, Frandsen and
Titiunik, 2015; Grosse-Wentrup et al., 2016]. As we have discussed, data-driven methods
have important advantages over traditional methods for exploiting natural variation—
allowing inference to be performed on much larger and more representative samples—
while also being less susceptible to unobserved confounders than back-door identiﬁcation
strategies. As the volume and variety of ﬁne-grained data continues to grow, we expect
these methods to increase in popularity and to raise numerous questions regarding their
theoretical foundations and practical applicability.

APPENDIX A: ESTIMATING THE FRACTION OF ERRONEOUS SPLIT-DOOR

INSTANCES

Let the expected fraction of erroneous X-YD pairs—split-door instances—returned
by the method be φ. In the terminology of multiple testing, φ refers to the False Non-
Discovery Rate (FNDR) [Delongchamp et al., 2004]. This is diﬀerent from the more
commonly used False Discovery Rate (FDR) [Farcomeni, 2008], since we deviate from
standard hypothesis testing by looking for split-door instances that have a p-value higher
than a pre-determined threshold. Given m hypothesis tests and a signiﬁcance level of α,
we show that the false non-discovery rate φ for the split-door criterion can be character-
ized as

φα ≤

(1 − α)πdepm
Wα

,

(A.1)

where πdep is the fraction of actually dependent X-YD instances in the dataset and Wα
is the observed number of X-YD instances returned by the method at level α.

The above estimate can be derived using the framework proposed by Storey [2002]
under two assumptions. The ﬁrst is that the that the distribution of p-values under the
null hypothesis is uniform, and the second is that the distribution of p-values under the
alternative hypothesis is stochastic smaller than the uniform distribution. Let the number
of invalid instances found using the split-door criterion be T . Then, by deﬁnition, the
false non-discovery rate can be written as:

φα = E

W > 0

.

(cid:21)

(cid:20) T
W

(cid:12)
(cid:12)
(cid:12)
(cid:12)

φα ≤

(1 − α) ∗ πdepm
Wα

.

Since the alternative distribution is stochastically smaller than uniform, we can arrive
at an upper bound by replacing T by the expected number of split-door instances if the
alternative distribution were uniform, (1 − α) ∗ mdependent = (1 − α) ∗ πdep ∗ m, giving

Here πdep is unknown, so it needs to be estimated. A common approach is to estimate
the fraction of actually independent instances or null hypotheses πindep and then use
πdep = 1 − πindep [Delongchamp et al., 2004]. For robustness, we suggest using multiple
procedures to estimate πindep and verify sensitivity of results to the choice of πindep. In
this paper, we use two diﬀerent estimates, derived from Storey and Tibshirani [2003],
Storey [2002] (Storey’s estimate); and Nettleton et al. [2006], Liang and Nettleton [2012]
(Nettleton’s estimate).

Storey’s estimate is deﬁned as

ˆπindep =

Wλ
m(1 − λ)

,

where λ ∈ [0, 1) is a tunable parameter—similar in interpretation to α—and Wλ is the
number of hypothesis tests having a p-value higher than λ. The choice of λ involves a

(A.2)

(A.3)

22

SHARMA ET AL.

bias-variance tradeoﬀ, with λ = 0.5 being a common choice, as in the SAM software
developed by Storey and Tibshirani [2003].

Nettleton’s estimate, on the other hand, chooses the eﬀective value of λ adaptively,
based on the observed p-value distribution. First, the p-value distribution is summarized
in a histogram containing B bins. Then, a threshold λ is chosen as the index (I) corre-
sponding to the left-most bin whose count fails to exceed the average count of the bins
to its right. This results in the following estimate, where λ = (I − 1)/B:

ˆπindep =

Wλ
m(1 − λ)

=

Wλ
m(1 − I−1
B )

.

(A.4)

Applying each of these to the m = 114, 469 focal and recommended product pairs
analyzed in Section 5 allows us to estimate the true number of dependent X-YD pairs
in the dataset, πdep. At α = 0.95, both methods give very similar results (πdep,Storey =
0.184, πdep,N ettleton = 0.187); we use πdep = 0.187 in our analysis.

APPENDIX B: SENSITIVITY ANALYSIS FOR THE CONNECTEDNESS

ASSUMPTION

In this section we analyze the sensitivity of an estimate obtained using the split-door
criterion to violations of the connectedness assumption. As Figure 3a shows, violation
implies that there exist variables VY that aﬀect only X and YR but not YD. We use the
structural equation model from Section 2.2 to illustrate sensitivity analysis.

Given that the unobserved confounders can be broken down into two components UY

and VY , we can rewrite the linear structural equations from Equation 2.8 as:

with two additional parameters c1 and c2 denoting the eﬀect of the unobserved variable
VY on X and YR, respectively. Applying the split-door criterion X ⊥⊥ YD, we write the
following equations for each obtained split-door instance:

x = ηux + γ1uy + c1vy + (cid:15)x
yr = ρx + γ2uy + c2vy + (cid:15)yr
yd = γ3uy + (cid:15)yd,

x = ηux + c1vy + (cid:15)(cid:48)
x
yr = ρx + c2vy + (cid:15)(cid:48)
yr

(B.1)

(B.2)

(B.3)

(B.4)

(B.5)

Here VY is unobserved and hence the causal eﬀect is not identiﬁed. Using (B.5) as an esti-
mating equation will lead to a biased estimate of the causal eﬀect due to the confounding
eﬀect of the unobserved common cause VY . Note that this structure is identical to the
omitted variable bias problem in back-door and conditioning-based methods [Harding,
2009]. Consequently, we obtain a similar bilinear dependence of the split-door estimate
to sensitivity parameters c1 and c2.

Speciﬁcally, the split-door method regresses YR on X to obtain an estimate ˆρ for
each obtained instance. When connectedness is violated, the bias of this estimate can be
characterized as,

ˆρ = (X T X)−1X T YR =

(cid:80)

(cid:80)

i xiyri
(cid:80)
j x2
j
i xi(ρxi + c2vyi + (cid:15)(cid:48)
(cid:80)
j x2
j
i vyixi
(cid:80)
j x2
j

(cid:80)

(cid:80)

+

= ρ + c2

=

)

yri

xi

i (cid:15)(cid:48)
(cid:80)

yri
j x2
j

,

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

23

where we use (B.5) to expand yri . As in Section 3, let τ denote the sample size for each
split-door instance. When X and VY are both standardized to have zero mean and unit
variance, and taking expectation on both sides, we obtain,

E[ˆρ] = ρ + c2 E[

vyixi] + E[

1
τ

(cid:88)

i

(cid:15)(cid:48)
yri

xi]

= ρ + c2 E[

vyi(ηuxi + c1vyi + (cid:15)(cid:48)
xi

)]

(cid:88)

i
(cid:88)

1
τ

1
τ

i

1
τ

(cid:88)

i

= ρ + c1c2 E[

vyi vyi] + η E[

vyiuxi] + E[

1
τ

(cid:88)

i

1
τ

(cid:88)

i

vyi(cid:15)(cid:48)
xi

]

E[ˆρ] = ρ + c1c2

(B.6)

where we use the independence of error terms and that UX ⊥⊥ VY .

In addition, note that the split-door method averages the estimate ˆρ obtained from
each instance. Not all instances may violate the connectedness assumption, therefore
we introduce an additional sensitivity parameter κ that denotes the fraction of invalid
split-door instances. Bias in the ﬁnal split-door estimate is then given by the following
equation in the three sensitivity parameters:

E[ˆρ] = ρ + κc1c2 .

(B.7)

For expositional clarity, the above analysis assumed a linear structural model and
demonstrated similarities with sensitivity of conditioning-based methods to unobserved
common causes. However, in practice, the structural model may not be linear. In the
recommendation example discussed in Section 5, we do not assume a linear model and
instead use an aggregate ratio estimator. As shown in Figure 9, simulations show that
sensitivity of this estimator follows a similar bilinear dependence on c1 and c2.

APPENDIX C: CHARACTERIZING ERROR IN THE SPLIT-DOOR ESTIMATE

FOR A RECOMMENDATION SYSTEM

In Section 5.3, the split-door causal estimate is deﬁned as the mean of CTR esti-
mates over all time periods and focal products with valid split-door instances. Here we
characterize the error in this estimate. The key idea is that the error comes from two
components: the ﬁrst due to some erroneously identiﬁed split-door instances, and the
second due to natural variance in estimating the mean. For a signiﬁcance level α of the
independence test, let W be the number of obtained split-door instances and N be the
number of aggregated CTR estimates ˆρiτ computed from these instances. Then the mean
estimate can be written as:

ˆρ =

(cid:80)

iτ ˆρiτ
N

,

(C.1)

where i refers to a focal product and τ refers to a split-door time period. As in Ap-
pendix A, let φ denote the expected fraction of erroneous split-door instances obtained.
That is, for an expected number of φW instances, the method may have erroneously
concluded that the focal and recommended products are independent. Correspondingly,
an expected φW = φ(cid:48)N number of ˆρiτ estimates will be invalid.5 These invalid estimates
can be expanded as:

ˆρiτ = ρcausal

iτ

+ ηiτ ,

(C.2)

5In general, the expected number of invalid ˆρiτ estimates may be less than or equal to φW , since a
focal product may have more than one recommended product that corresponds to an invalid split-door
instance.

24

SHARMA ET AL.

where η refers to the click-through rate due to correlated demand between the focal and
recommended products. Thus, the overall mean estimate can be written as:

(cid:80)

iτ ∈A ρcausal
iτ

ˆρ =

(cid:80)

=

iτ ρcausal
iτ
N

+

+ (cid:80)
iτ ∈B(ρcausal
iτ
N
iτ ∈B ηiτ
N

(cid:80)

,

+ ηiτ )

where A and B refer to (i, τ ) pairs with valid and erroneous split-door estimates respec-
tively (|A| = (1 − φ(cid:48))N, |B| = φ(cid:48)N ).

Comparing this to the true ρcausal, we obtain

ρcausal − ˆρ = (ρcausal − ¯ρcausal) −

(C.3)

(cid:80)

iτ ∈B ηiτ
N

.

The ﬁrst term of the RHS corresponds to error due to sampling variance, and the second
term corresponds to error due to correlated demand (φ). We estimate these terms below.

Error due to φ. Based on the argument for justifying the independence assumption
in Section 5.1, let us assume that the total eﬀect of UY on YR is positive (without
stipulating it for each individual instance). This means that the term due to correlated
demand is positive, (cid:80)
iτ ∈B ηiτ ≥ 0. Further, the maximum value of ηiτ is attained when
all the observed click-throughs are due to correlated demand (ηiτ = ˆρiτ ). Under this
assumption,

(cid:80)

0 ≤

iτ ∈B ηiτ
N

≤

ρmaxsum
N

,

where ρmaxsum corresponds to the maximum sum of any subset of φ(cid:48)N ˆρiτ values. An
approximate estimate can be derived using ˆρ—the empirical mean over all N values of
ρiτ —leading to ρmaxsum ≈ φ(cid:48)N ˆρ.

Error due to natural variance. We characterize this error by the 99% conﬁdence interval
for the mean estimate, given by 2.58 ∗ ˆσ√
, where ˆσ is the empirical standard deviation.
N

Combining these two, the resultant interval for the split-door estimate is

(ˆρ −

ρmaxsum
N

− 2.58

, ˆρ + 2.58

ˆσ
√
N

ˆσ
√
N

) .

(C.4)

The above interval demonstrates the bias-variance tradeoﬀ in choosing a nominal
signiﬁcance level for the independence test and the corresponding φ. At high nominal
signiﬁcance level α, bias due to φ is expected to be low but variance of the estimate may
be high due to low N . Conversely, at low values of α, variance will be lower but φ is
expected to be higher because we accept many more split-door instances.

SUPPLEMENTARY MATERIAL

Supplement A: Code for split-door criterion

(http://www.github.com/amit-sharma/splitdoor-causal-criterion). We provide an R pack-
age that implements the split-door criterion, along with code samples for applying the
criterion to new applications.

REFERENCES

Agresti, A. (1992). A survey of exact inference for contingency tables. Statistical Science 7 131–153.
Agresti, A. (2001). Exact inference for categorical data: recent advances and continuing controversies.

Statistics in Medicine 20 2709–2722.

Angrist, J. D., Imbens, G. W. and Rubin, D. B. (1996). Identiﬁcation of causal eﬀects using instru-

mental variables. Journal of the American Statistical Association 91 444–455.

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

25

Carmi, E., Oestreicher-Singer, G. and Sundararajan, A. (2012). Is Oprah contagious? Identifying

demand spillovers in online networks. NET Institute Working Paper 10-18.

Carnegie, N. B., Harada, M. and Hill, J. L. (2016). Assessing Sensitivity to Unmeasured Confounding
Using a Simulated Potential Confounder. Journal of Research on Educational Eﬀectiveness 9 395-420.
Cattaneo, M. D., Frandsen, B. R. and Titiunik, R. (2015). Randomization inference in the regression
discontinuity design: An application to party advantages in the US Senate. Journal of Causal Inference
3 1–24.

Cattaneo, M. D., Titiunik, R. and Vazquez-Bare, G. Comparing inference approaches for RD de-
signs: A reexamination of the eﬀect of head start on child mortality. Journal of Policy Analysis and
Management 36 643-681.

de Siqueira Santos, S., Takahashi, D. Y., Nakata, A. and Fujita, A. (2014). A comparative study
of statistical methods used to identify dependencies between gene expression signals. Brieﬁngs in
Bioinformatics 15 906-918.

Delongchamp, R. R., Bowyer, J. F., Chen, J. J. and Kodell, R. L. (2004). Multiple-testing strategy

for analyzing cDNA array data on gene expression. Biometrics 60 774–782.

Dunning, T. (2012). Natural experiments in the social sciences: A design-based approach. Cambridge

University Press.

Farcomeni, A. (2008). A review of modern multiple hypothesis testing, with particular attention to the

false discovery proportion. Statistical Methods in Medical Research 17 347–388.

Fiske, S. T. and Hauser, R. M. (2014). Protecting human research participants in the age of big data.

Proceedings of the National Academy of Sciences 111 13675-13676.

Flaxman, S., Goel, S. and Rao, J. M. (2016). Filter bubbles, echo chambers, and online news con-

sumption. Public Opinion Quarterly 80 298–320.

Grau, J. (2009). Personalized product recommendations: Predicting shoppers’ needs. eMarketer.
Grosse-Wentrup, M., Janzing, D., Siegel, M. and Sch¨olkopf, B. (2016). Identiﬁcation of causal rela-
tions in neuroimaging data with latent confounders: An instrumental variable approach. NeuroImage
125 825–833.

Harding, D. J. (2009). Collateral consequences of violence in disadvantaged neighborhoods. Social

Forces 88 757–784.

Imbens, G. W. (2010). Better LATE than nothing. Journal of Economic Literature 48.
Imbens, G. W. and Rubin, D. B. (2015). Causal inference in statistics, social, and biomedical sciences.

Cambridge University Press.

Jensen, D. D., Fast, A. S., Taylor, B. J. and Maier, M. E. (2008). Automatic identiﬁcation of quasi-
experimental designs for discovering causal knowledge. In Proceedings of the 14th ACM International
Conference on Knowledge Discovery and Data Mining 372–380.

Kang, H., Zhang, A., Cai, T. T. and Small, D. S. (2016). Instrumental variables estimation with
some invalid instruments and its application to Mendelian randomization. Journal of the American
Statistical Association 111 132–144.

Lewis, R. A., Rao, J. M. and Reiley, D. H. (2011). Here, there, and everywhere: Correlated online be-
haviors can lead to overestimates of the eﬀects of advertising. In Proceedings of the 20th International
Conference on World Wide Web 157–166. ACM.

Liang, K. and Nettleton, D. (2012). Adaptive and dynamic adaptive procedures for false discovery rate
control and estimation. Journal of the Royal Statistical Society. Series B (Statistical Methodology)
74 163-182.

Lydersen, S., Pradhan, V., Senchaudhuri, P. and Laake, P. (2007). Choice of test for association in

small sample unordered r× c tables. Statistics in Medicine 26 4328–4343.

Mealli, F. and Pacini, B. (2013). Using secondary outcomes to sharpen inference in randomized ex-
periments with noncompliance. Journal of the American Statistical Association 108 1120–1131.
Morgan, S. L. and Winship, C. (2014). Counterfactuals and causal inference. Cambridge University

Press.

Research.

16 2839–2849.

Springer.

Mulpuru, S. (2006). What you need to know about third-party recommendation engines. Forrester

Nettleton, D., Hwang, J. T. G., Caldo, R. A. and Wise, R. P. (2006). Estimating the number of true
null hypotheses from a histogram of p values. Journal of Agricultural, Biological, and Environmental
Statistics 11 337.

Paninski, L. (2003). Estimation of entropy and mutual information. Neural Computation 15 1191–1253.
Pearl, J. (2009). Causality. Cambridge University Press.
Pethel, S. D. and Hahs, D. W. (2014). Exact test of independence using mutual information. Entropy

Phan, T. Q. and Airoldi, E. M. (2015). A natural experiment of social network formation and dynamics.

Proceedings of the National Academy of Sciences 112 6595–6600.

Ricci, F., Rokach, L. and Shapira, B. (2011). Introduction to recommender systems handbook.

Rosenbaum, P. R. (2010). Design of observational studies. Springer.
Rosenzweig, M. R. and Wolpin, K. I. (2000). Natural “natural experiments” in economics. Journal of

Economic Literature 38 827–874.

Rubin, D. B. (2006). Matched sampling for causal eﬀects. Cambridge University Press.
Sharma, A., Hofman, J. M. and Watts, D. J. (2015). Estimating the causal impact of recommendation
systems from observational data. In Proceedings of the 16th ACM Conference on Economics and

26

SHARMA ET AL.

Computation 453–470.

Spirtes, P., Glymour, C. N. and Scheines, R. (2000). Causation, prediction, and search. MIT Press.
Steuer, R., Kurths, J., Daub, C. O., Weise, J. and Selbig, J. (2002). The mutual information:

Detecting and evaluating dependencies between variables. Bioinformatics 18 S231–S240.

Storey, J. D. (2002). A direct approach to false discovery rates. Journal of the Royal Statistical Society:

Series B (Statistical Methodology) 64 479–498.

Storey, J. D. and Tibshirani, R. (2003). SAM thresholding and false discovery rates for detecting
diﬀerential gene expression in DNA microarrays In The Analysis of Gene Expression Data: Methods
and Software 272–290. Springer New York, New York, NY.

Stuart, E. A. (2010). Matching methods for causal inference: A review and a look forward. Statistical

Science: a review journal of the Institute of Mathematical Statistics 25 1.

Sz´ekely, G. J., Rizzo, M. L., Bakirov, N. K. et al. (2007). Measuring and testing dependence by

correlation of distances. The Annals of Statistics 35 2769–2794.

VanderWeele, T. J. and Arah, O. A. (2011). Bias formulas for sensitivity analysis of unmeasured
confounding for general outcomes, treatments, and confounders. Epidemiology (Cambridge, Mass.)
22 42–52.

9 Lavelle Road
Bangalore, India 560008
E-mail: amshar@microsoft.com

641 Ave. of the Americas
New York, NY USA 10011
E-mail: jmh@microsoft.com

duncan@microsoft.com

8
1
0
2
 
n
u
J
 
4
1
 
 
]
E
M

.
t
a
t
s
[
 
 
2
v
4
1
4
9
0
.
1
1
6
1
:
v
i
X
r
a

arXiv: arXiv:1611.09414

SPLIT-DOOR CRITERION: IDENTIFICATION OF CAUSAL
EFFECTS THROUGH AUXILIARY OUTCOMES

By Amit Sharma, Jake M. Hofman and Duncan J. Watts

Microsoft Research

We present a method for estimating causal eﬀects in time series data
when ﬁne-grained information about the outcome of interest is available.
Speciﬁcally, we examine what we call the split-door setting, where the out-
come variable can be split into two parts: one that is potentially aﬀected
by the cause being studied and another that is independent of it, with
both parts sharing the same (unobserved) confounders. We show that un-
der these conditions, the problem of identiﬁcation reduces to that of testing
for independence among observed variables, and present a method that uses
this approach to automatically ﬁnd subsets of the data that are causally
identiﬁed. We demonstrate the method by estimating the causal impact of
Amazon’s recommender system on traﬃc to product pages, ﬁnding thou-
sands of examples within the dataset that satisfy the split-door criterion.
Unlike past studies based on natural experiments that were limited to a
single product category, our method applies to a large and representative
sample of products viewed on the site. In line with previous work, we ﬁnd
that the widely-used click-through rate (CTR) metric overestimates the
causal impact of recommender systems; depending on the product category,
we estimate that 50-80% of the traﬃc attributed to recommender systems
would have happened even without any recommendations. We conclude
with guidelines for using the split-door criterion as well as a discussion of
other contexts where the method can be applied.

1. Introduction. The recent growth of digital platforms has generated an avalanche
of highly granular and often longitudinal data regarding individual and collective behav-
ior in a variety of domains of interest to researchers, including in e-commerce, health-
care, and social media consumption. Because the vast majority of this data is generated
in non-experimental settings, researchers typically must deal with the possibility that
any causal eﬀects of interest are complicated by a number of potential confounds. For
example, even eﬀects as conceptually simple as the causal impact of recommendations
on customer purchases are likely confounded by selection eﬀects [Lewis, Rao and Reiley,
2011], correlated demand [Sharma, Hofman and Watts, 2015], or other shared causes
of both exposure and purchase. Figure 1a shows this canonical class of causal inference
problems in the form of a causal graphical model [Pearl, 2009], where X is the cause and
Y is its eﬀect. Together U and W refer to all of the common causes of X and Y that
may confound estimation of the causal eﬀect, where critically some of these confounders
(labeled W ) may be observed, while others (U ) are unobserved or even unknown. Ideally
one would answer such questions by running randomized experiments on these platforms,
but in practice such tests are possible only for the owners of the platform in question,
and even then are often beset with implementation diﬃculties or ethical concerns [Fiske
and Hauser, 2014]. As a result researchers are left with two main strategies for making
causal estimates from large-scale observational data, each with its own assumptions and
limitations: either conditioning on observables or exploiting natural experiments.

1.1. Background: Back-door criterion and natural experiments. The ﬁrst and by far
the more common approach is to assume that the eﬀect of unobserved confounders (U )
is negligible after conditioning on the observed variables (W ). Under such a selection on
observables assumption [Imbens and Rubin, 2015], one conditions on W to estimate the

∗We would like to thank Dean Eckles, Praneeth Netrapalli, Joshua Angrist, T. Tony Ke, and anony-

mous reviewers for their valuable feedback on this work.

Keywords and phrases: causal inference, data mining, causal graphical model, natural experiment,

recommendation systems

1

2

SHARMA ET AL.

(a) Canonical causal in-
ference problem

Estimation with

(b)
back-door criterion

(c) Estimation with Z as an
instrumental variable

Fig 1: Left: Graphical model for the canonical problem in causal inference. We wish to
estimate the eﬀect of X on Y . W represents observed common causes of X and Y ; U
represents other unobserved (and unknown) common causes that confound observational
estimates. Middle: The causal model under the selection on observables assumption,
where there are no known unobserved confounds U . Right: The canonical causal model
for an instrumental variable Z that systematically shifts the distribution of the cause X
independently of confounds U .

eﬀect of X on Y when these confounders are held constant. In the language of graph-
ical models, this strategy is referred to as the back-door criterion [Pearl, 2009] on the
grounds that the “back-door pathway” from X to Y (via W) is blocked by condition-
ing on W (see Figure 1b) and can be implemented by a variety of methods, including
regression, stratiﬁcation, and matching [Rubin, 2006; Stuart, 2010]. Unfortunately for
most practical problems it is diﬃcult to establish that all of the important confounders
have been observed. For example, consider the problem of estimating the causal impact
of a recommender system on traﬃc to e-commerce websites such as Amazon.com, where
X corresponds to the number of visits to a product’s webpage, and Y the visits to a
recommended product shown on that webpage. One could compute the observed click-
through rate after conditioning on all available user and product attributes (e.g., user
demographics, product categories and popularities, etc.), assuming that these features
constitute a proxy for latent demand. Unfortunately, there are also many potentially
unobserved confounders (e.g., advertising, media coverage, seasonality, etc.) that impact
both a product and its recommendations, which if excluded would render the back-door
criterion invalid.

Motivated by the limitations of the back-door strategy, a second main approach is to
identify an external event that aﬀects the treatment X in a way that is arguably ran-
dom with respect to potential confounds. The hope is that such variation, known as a
natural experiment [Dunning, 2012], can serve as a substitute for an actual randomized
experiment. Continuing with the problem of estimating the causal impact of recommen-
dations, one might look for a natural experiment in which some products experience
large and sudden changes in traﬃc, for instance when a book is featured on Oprah’s
book club [Carmi, Oestreicher-Singer and Sundararajan, 2012]. Assuming that the in-
crease in traﬃc for the book is independent of demand for its recommendations, one can
estimate the causal eﬀect of the recommender by measuring the change in sales to the
recommended products before and after the book was featured, arguing that these sales
would not have happened in the absence of the recommender. Such events provide in-
strumental variables that identify the eﬀect of interest by shifting the distribution of the
cause X independently of unobserved confounds U [Angrist, Imbens and Rubin, 1996].
Figure 1c depicts this in a graphical model, where the additional observed variable Z
denotes the instrumental variable.

These two main approaches trade oﬀ critical goals of identiﬁcation and generalization
in causal inference. The estimate for back-door conditioning is typically derived using all
available data, but provides no identiﬁcation guarantees in the presence of unobserved

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

3

(a) General split-door model: Outcome Y
is split into YR and YD

(b) Valid split-door model: Data subsets
where X is independent of UY

Fig 2: Panel (a) illustrates the canonical causal inference problem when outcome Y can
be split up into two components. For clarity, unobserved confounders U are broken into
UY that aﬀects both X and Y , and UX that aﬀects only X. The split-door criterion ﬁnds
subsets of the data where the cause X is independent of UY by testing independence of
X and YD, leading to the unconfounded causal model shown in Panel (b).

confounders. Instrumental variables, in contrast, provide identiﬁcation guarantees even
in the presence of unobserved confounders, but these guarantees apply only for local
subsets of the available data—the relatively rare instances for which a valid instrument
that exogenously varies the cause X is known (e.g., lotteries [Angrist, Imbens and Rubin,
1996], variation in weather [Phan and Airoldi, 2015], or sudden, large events [Rosenzweig
and Wolpin, 2000; Dunning, 2012]).

1.2. The “split-door” criterion.

In this paper we introduce a causal identiﬁcation
strategy that incorporates elements of both the back-door and natural experiment ap-
proaches, but that applies in a diﬀerent setting. Rather than conditioning on observable
confounds W or exploiting sources of independent variation in the cause X, we instead
look to auxiliary outcomes [Mealli and Pacini, 2013] to identify subsets of the data that
are causally identiﬁed. Speciﬁcally, our strategy applies when the outcome variable Y can
be eﬀectively “split” into two constituents: one that is caused by X and another that is
independent of it. Figure 2a shows the corresponding causal graphical model, where YR
denotes the “referred” outcome of interest aﬀected by X and YD indicates the “direct”
constituent of Y that does not directly depend on X. Returning to the recommender sys-
tem example, YR corresponds to recommendation click-throughs on a product whereas
YD would be all other traﬃc to that product that comes through channels such as direct
search or browsing. Whenever such ﬁne-grained data on Y is available, we show that it is
possible to reduce causal identiﬁcation to an independence test between the cause X and
the auxiliary outcome YD. Because this strategy depends on the availability of a split set
of variables for Y , we call it the split-door criterion for causal identiﬁcation, by analogy
with the more familiar back-door criterion.

Although we make no assumptions about the functional form of relationships between
variables, a crucial assumption underlying the split-door criterion is connectedness; i.e.,
that the auxiliary outcome YD must be aﬀected (possibly diﬀerently) by all causes that
also aﬀect YR. As we discuss in more detail in Section 5, this assumption is plausible in
scenarios such as online recommender systems, where recommended products are reach-
able through multiple channels (e.g., search or direct navigation) and it is unlikely that
demand for a product manifests itself exclusively through only one of these channels.
More generally, the connectedness assumption is expected to hold in scenarios where
direct and referred outcomes incur similar cost, which makes it unlikely that something
that causes the outcome does so only when referred through X, but never directly.

Under the above assumption, the split-door criterion seeks to identify subsets of the
data where causal identiﬁcation is possible. In this sense, the method resembles a natural

4

SHARMA ET AL.

experiment, except that instead of looking for an instrument that creates variation in X,
we look for variations in X directly. As in a natural experiment, however, it is important
that any such variation in X is independent of potential confounds. For instance in the
example above, it is important that a sudden burst of interest in a particular book is
not correlated with changes in latent demand for its recommendations. To verify this
requirement, the split-door criterion relies on a statistical test to select for cases where
there are no confounds (observed or otherwise) between X and YR. Speciﬁcally, we show
that given a suitable auxiliary outcome YD, and a test to establish if X and YD are
independent, the causal eﬀect between X and YR can be identiﬁed. Furthermore, since
this test involves two observed quantities (X and YD), we can systematically search for
subsets of the data that satisfy the required condition, potentially discovering a large
number of cases in which we can identify the causal eﬀect of X on YR.

We illustrate this method with a detailed example in which we estimate the causal
impact of Amazon.com’s recommendation system using historical web browsing data.
Under the above assumptions on the dependence between referred and direct visits to
a product’s webpage, we show how the criterion provides a principled mechanism for
determining which subsets of the data to include in the analysis. The split-door criterion
identiﬁes thousands of such instances in a nine-month period, comparable in magnitude
to a manually tuned approach using the same data [Sharma, Hofman and Watts, 2015],
and an order of magnitude more than traditional approaches [Carmi, Oestreicher-Singer
and Sundararajan, 2012]. Further, the products included in our analysis are representa-
tive of the overall product distribution over product categories on Amazon.com, thereby
improving both the precision and generalizability of estimates. Consistent with previous
work [Sharma, Hofman and Watts, 2015], we ﬁnd that observational estimates of rec-
ommendation click-through rates (CTRs) overstate the actual eﬀect by anywhere from
50% to 80%, calling into question the validity of popular CTR metrics for assessing the
impact of recommendation systems. For applications to other online and oﬄine scenarios,
we provide an R package1 that implements the split-door criterion.

1.3. Outline of paper. The remainder of this paper proceeds as follows. In Section 2
we start with a formal deﬁnition of the split-door criterion and give precise conditions un-
der which the criterion holds. For clarity we provide proofs for causal identiﬁcation both
in terms of the causal graphical model from Figure 2a and also in terms of structural
equations. In Section 3 we propose a simple, scalable algorithm for identifying causal
eﬀects using the split-door criterion. Then in Section 4, we explain more formally how
the split-door criterion diﬀers from the instrumental variables and back-door methods
mentioned above. Section 5 presents details about the Amazon.com data and an appli-
cation of the split-door criterion to estimate the causal impact of its recommendation
system. In Section 6 we then discuss limitations of the split-door criterion as well as
other settings in which the criterion applies, arguing that many existing datasets across
a variety of domains have the structure that outcomes of interest can be decomposed into
their “direct” and “referred” constituents. We conclude with a prediction that as the size
and granularity of available datasets, along with the number of variables in them, in-
crease at an ever faster rate, data-driven approaches to causal identiﬁcation will become
commonplace.

2. The Split-door Identiﬁcation Criterion. The split-door criterion can be used
whenever observed data is generated from the model shown in Figure 2a. Here X repre-
sents the cause of interest, YR denotes the “referred” portion of the outcome aﬀected by
it, and YD indicates the “direct” part of the outcome which does not directly depend on
X. We denote the overall outcome by Y = YR + YD. We let UY represent all unobserved
causes of Y , some of which may also be common causes of X, hence the arrow from UY
to X. Additional latent factors that aﬀect only X are captured by UX . Both UX and UY

1URL: http://www.github.com/amit-sharma/splitdoor-causal-criterion

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

5

can be a combination of many variables, some observed and some unobserved. (For full
generality, the analysis presented here assumes that all confounds are unobserved.) As
noted earlier, the unobserved variables UY create “back-door pathways” that confound
the causal eﬀect of X on Y , resulting in biased estimates. The central idea behind the
split-door criterion is that we can use an independence test between the auxiliary out-
come YD and X to systematically search for subsets of the data that are free of these
confounds and do not contain back-door pathways between X and YR. In other words,
we can conclude that such subsets of the data were generated from the unconfounded
causal model shown in Figure 2b, and therefore the causal eﬀect of X on Y can be esti-
mated directly from these data. Importantly, identiﬁcation of the causal eﬀect rests on
the assumption that no part of UY causes one part of Y and not the other.

2.1. The split-door criterion through a graphical model. Here we formalize the intu-
ition above in the causal graphical model framework. To identify the causal eﬀect, we
make the following two assumptions. The ﬁrst pertains to connectedness of the causal
model.

Assumption 1 (Connectedness). Any unobserved confounder UY that causes both

X and YR also causes YD and the causal eﬀect of such UY on YD is non-zero.

Note that Assumption 1 requires only that the causal eﬀect of UY on YD be non-
zero, without any requirements on the size of the eﬀect(s) involved. That said, it is a
strong requirement in general, as it applies to all sub-components of UY and thus involves
assumptions about potentially high-dimensional, unobserved variables. Whenever YD and
YR are components of the same variable it is plausible that they share causes, but one still
must establish that this condition holds to ensure causal identiﬁcation. It is instructive
to compare this assumption to the strict independence assumptions involving unobserved
confounders required by methods such as instrumental variables [Angrist, Imbens and
Rubin, 1996].

The second assumption, which relates statistical and causal independence between
observed variables, is standard for many methods of causal discovery from observational
data.

Assumption 2 (Independence).

If X and YD are statistically independent, then they

are also causally independent in the graphical model of Figure 2a.

Here causal independence between two variables means that they share no common
causes and no directed path in the causal graphical model leads from one to another.
More formally, the two variables are “d-separated” [Pearl, 2009] from each other. Thus,
Assumption 2 is a variant of the Faithfulness or Stability assumptions in causal graphs
with latent unobserved variables [Spirtes, Glymour and Scheines, 2000; Pearl, 2009].
In the causal model shown in Figure 2a, for instance, this assumption rules out the
possibility of an event where the observed variables X and YD are found to be statistically
independent, but UY still aﬀects both of them and the observed independence in the data
results from UY ’s eﬀect canceling out exactly over the path X-UY -YD. In other words, this
assumption serves to rule out an (unlikely) event where incidental equality of parameters
or certain data distributions render two variables statistically independent even though
they are causally related.

Under Assumptions 1 and 2, we can show that statistical independence of X and YD
ensures that X is not confounded by UY . First, we provide a result about the resulting
causal graph structure when X ⊥⊥ YD.

Lemma 1. Let X, YR and YD be three observed variables corresponding to the causal
model in Figure 2a, where UY refers to unobserved causes of YR. If the connectedness (1)
and independence (2) assumptions hold, then X ⊥⊥ YD implies that the edge UY → X
does not exist or that UY is constant.

6

SHARMA ET AL.

Proof (Argument). The proof can be completed directly from Figure 2a and properties
of a causal graphical model.

X ⊥⊥ YD implies that the causal eﬀect of UY on YD and X somehow cancels out on
the path X ← UY → YD. By Assumption 2, this cancellation is not due to incidental
equality of parameters or a particular data distribution, but rather a property of the
causal graphical model. Therefore, this can only happen if
(i) UY is constant (and thus blocks the path), or
(ii) One of the edges exists trivially (does not have a causal eﬀect). Using Assumption
1, UY has a non-zero eﬀect on YD. Then, the only alternative is that the X ← UY edge
does not exist, leading to the unconfounded causal model in Figure 2b.

Proof. We provide a proof by contradiction using the principle of d-separation [Pearl,

2009] in a causal graphical model.

Let us suppose X ⊥⊥ YD, and that the UY → X edge exists and UY is not constant.
Using the rules of d-separation on the causal model in Figure 2a, the path X-UY -YD

corresponds to:

(2.1)

(2.2)

(2.3)

(X ⊥⊥ YD|UY )G
(X (cid:54)⊥⊥ YD)G

(X ⊥⊥ YD)G

where the notation (.)G refers to d-separation under a causal model G. In our case, G
corresponds to the causal model in Figure 2a.

However, using Assumption 2, statistical independence of X and YD implies causal

independence, and thus, d-separation of X and YD.

Equations 2.2 and 2.3 result in a contradiction. To resolve,
(i) Either UY is constant and thus 2.1 implies (X ⊥⊥ YD)G holds, or
(ii) The path X-UY -YD does not exist. Using Assumption 1 of dependence of YD on

UY , the only possibility is that the X ← UY edge does not exist.

We now show that Lemma 1 removes confounding due to UY and that the observational

estimate P (YR|X = x) is also the causal estimate.

Theorem 2.1 (Split-door Criterion). Under the assumptions of Lemma 1, the causal

eﬀect of X on YR is not confounded by UY and is given by:

P (YR|do(X = x)) = P (YR|X = x)

where do(X = x) refers to experimental manipulation of X and YR|X = x refers to the
observed conditional distribution.

Proof (Argument). Lemma 1 leads to two cases:
(i) By the back-door criterion [Pearl, 2009], if UY is constant, then X and YR are uncon-
founded, because the only back-door path between X and YR contains UY on it.
(ii) Similarly, if the UY → X edge does not exist, then X and YR are unconfounded
because absence of the UY → X edge removes the back-door path between X and YR.

In both cases, unconfoundedness implies that the eﬀect of X on YR can be estimated

using the observational distribution.

Proof. The proof follows from an application of the second rule of do-calculus [Pearl,

2009].

P (Y|do(Z = z), W) = P (Y|Z = z, W)

if

(Y ⊥⊥ Z|W)GZ

(2.4)

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

7

where GZ refers to the underlying causal graphical model with all outgoing edges from
Z removed.

Substituting Y = YR, Z = X, GX corresponds to the causal model from Figure 2a

without the X → YR edge. Using Lemma 1, two cases exist:

(i) UY is constant

Let W = UY . Under the modiﬁed causal model GX without the X → YR edge, the path
X-UY -YR is the only path connecting X and YR, which leads to the following d-separation
result:

(YR ⊥⊥ X|UY )GX

(2.5)

Combining Rule 2.4 and the above d-separation result, we obtain

P (YR|do(X = x), UY ) = P (YR|X = x, UY ) = P (YR|X = x)

where the last equality holds because UY is constant throughout.

(ii) The edge UY → X does not exist.

Let W = ∅. Under the modiﬁed causal model GX without the X → YR edge, X and YR
are trivially d-separated because no path connects them without the edge UY → X.

(YR ⊥⊥ X)GX

(2.6)

From Rule 2.4 and the above d-separation result, we obtain

P (YR|do(X = x)) = P (YR|X = x)

2.2. The split-door criterion through structural equations. Although we have already
analyzed the split-door criterion in terms of the causal graphical model in Figure 2a,
for expositional clarity we note that it is also possible to do the same using structural
equations. Speciﬁcally, we can write three structural equations:

x = g(ux, uy, εx)

yr = f (x, uy, εyr)

yd = h(uy, εyd),

(2.7)

where εx, εyr, and εyd are mutually independent, zero-mean random variables that cap-
ture modeling error and statistical variability. As in Assumption 1, we assume that UY
aﬀects both YD and YR. In general, the causal eﬀects among variables may not be linear;
however, for the purpose of building intuition we rewrite the above equations in linear
parametric form:

x = ηux + γ1uy + (cid:15)x

yr = ρx + γ2uy + (cid:15)yr

yd = γ3uy + (cid:15)yd,

(2.8)

where ρ is the causal parameter of interest, and (cid:15)x, (cid:15)yr (cid:15)yd are independent errors in the
regression equations. The split-door criterion requires independence of X and YD, which
in turn implies that Cov(X, YD) = 0:

0 = Cov(X, YD) = E[XYD] − E[X] E[YD]

= E[(ηux + γ1uy + (cid:15)x)(γ3uy + (cid:15)yd)] − E[ηux + γ1uy + (cid:15)x] E[γ3uy + (cid:15)yd]
= γ1γ3 E[UY .UY ] − γ1γ3 E[UY ] E[UY ]
= γ1γ3 Var(UY )

Assuming that YD is aﬀected by UY (and therefore γ3 is not 0), the above can be zero
only if γ1 = 0, or if UY is constant (Var[UY ] = 0). In both cases, X becomes independent
of UY and the following regression can be used as an unbiased estimator for the eﬀect of
X on YR:

yr = ρx + (cid:15)(cid:48)
yr

(2.9)

where (cid:15)(cid:48)

yr denotes an independent error.

8

SHARMA ET AL.

3. Applying the Split-door Criterion. The results of the previous section moti-
vate an algorithm for applying the split-door criterion to observational data. Speciﬁcally,
given an empirical test for independence between the cause X and the auxiliary outcome
YD, we can select instances in our data that pass this test and satisfy the split-door
criterion. In this section we develop such a test for time series data, resulting in a simple,
scalable identiﬁcation algorithm.

At a high level, the algorithm works as follows. First, divide the data into equally-
spaced time periods τ such that each period has enough data points to reliably estimate
the joint probability distribution P (X, YD). Then, for each time period τ ,

1. Determine whether X and YD are independent using an empirical independence

2. If X and YD are determined to be independent, then the current time period τ
corresponds to a valid split-door instance. Use the observed conditional probability
P (YR|X = x) to estimate the causal eﬀect in the time period τ . Otherwise, exclude
the current time period from the analysis.

3. Average over all time periods where X ⊥⊥ YD to obtain the mean causal eﬀect of

test.

X on YR.

Implementing the algorithm requires making suitable choices for an independence test
and also its signiﬁcance level, taking into account multiple comparisons. In the follow-
ing sections, we discuss these choices in detail, as well as sensitivity of the method to
violations in our assumptions.

3.1. Choosing an independence test. Each X-YD pair in Step 1 provides two vectors
of length τ with observed values for X and YD. The key decision is whether these vec-
tors are independent of each other. In theory any empirical test that reliably establishes
independence between X and YD is suﬃcient to identify instances where the split-door
criterion applies. For instance, assuming we have enough data, we could test for inde-
pendence by comparing the empirical mutual information to zero [Steuer et al., 2002;
Pethel and Hahs, 2014]. In practice, however, because we consider subsets of the data
over relatively small time periods τ , there may be substantial limits to the statistical
power we have in testing for independence. For example, it is well known that in small
sample sizes, testing for independence via mutual information estimation can be heavily
biased [Paninski, 2003].

Thus, when working with small time periods τ we recommend the use of exact inde-
pendence tests and randomization inference [Agresti, 1992, 2001; Lydersen et al., 2007].2
In general, this approach involves repeatedly sampling randomized versions of the em-
pirical data to simulate the null hypothesis and then comparing a test statistic on the
observed data to the same on the null distribution. Speciﬁcally, for each X-YD pair,
we simulate the null hypothesis of independence between X and YD by replacing the
observed X vector with a randomly sampled vector from the overall empirical distribu-
tion of X values. From this simulated X-YD instance, we compute a test statistic that
captures statistical dependence, such as the distance correlation, which can detect both
non-linear and linear dependence [Sz´ekely et al., 2007; de Siqueira Santos et al., 2014]. We
then repeat this procedure many times to obtain a null distribution for the test statistic
of this X-YD pair. Finally, we compute the probability p of obtaining a test statistic
as extreme as the observed statistic under the null distribution, and select instances in
which the probability p is above a pre-chosen signiﬁcance level α.

3.2. Choosing a signiﬁcance level.

In contrast to standard hypothesis testing where
one is looking to reject the null hypothesis that two variables are independent and there-
fore thresholds on a small p-value, here we are looking for independent X-YD pairs that

2 When X and YD are discrete variables, methods such as Fisher’s exact test are appropriate. If,
however, X and YD are continuous—as is this case for the example we study in Section 5—we recommend
the use of resampling-based randomization inference for establishing independence.

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

9

(a) General model: Unobserved variables
split into UY and VY

(b) Invalid split-door model: X is indepen-
dent of UY but not VY

Fig 3: Violation of the connectedness assumption. Causes for X and YR consist of two
components, UY and VY , where VY does not aﬀect YD and hence is undetectable by
the split-door criterion. In the general causal model shown in Panel (a), X → YR is
confounded by both UY and VY . In the causal model corresponding to a split-door
instance in Panel (b), X → YR is still confounded by the common cause VY .

are highly probable under the null and thus want a large p-value. In other words, we are
interested in a low Type II error (or false negatives), in contrast to standard null hypoth-
esis testing, where the focus is on Type I errors (false positives) and hence signiﬁcance
levels are set low. Therefore, one way to choose a signiﬁcance level would be to choose α
as close as possible to 1 to minimize Type II errors when X and YD are dependent. At the
same time, we need to ensure that the test yields adequate power for ﬁnding independent
X-YD pairs. Unlike a conventional hypothesis test for dependent pairs, power for our test
is 1 − α, the probability that the test declares an X-YD pair to be independent when it is
actually independent. As we increase α, type II errors decrease, but power also decreases.
Complicating matters, the combination of low power and a large number of hypothesis
tests raises concerns about falsely accepting pairs that are actually dependent. As an ex-
treme example, even when all X-YD pairs in a given dataset are dependent, some of them
will pass the independence test simply due to random chance. Therefore, a more princi-
pled approach to selecting α comes through estimating the expected fraction of erroneous
split-door instances returned by the procedure, which we refer to as φ. As described in
Appendix A, we apply techniques from the multiple comparisons literature [Storey, 2002;
Liang and Nettleton, 2012; Farcomeni, 2008] to estimate this fraction φ for any given
signiﬁcance level.

3.3. Sensitivity to identifying assumptions. The above algorithm yields a causal es-
timate only if the identifying assumptions of connectedness and independence are satis-
ﬁed. Independence is based on the standard faithfulness assumption in causal discovery
[Spirtes, Glymour and Scheines, 2000]. Connectedness, on the other hand, requires jus-
tiﬁcation based on domain knowledge. Even when the connectedness assumption seems
plausible, we recommend a sensitivity analysis to assess the eﬀects of potential violations
to this assumption.

From Assumption 1, violation of connectedness implies that there exist some unob-
served variables that aﬀect X and YR but not YD. Figure 3a shows this scenario, which is
identical to the model in Figure 2a with the addition of an unobserved variable VY that
aﬀects X and YR, but not YD. Applying the split-door criterion in this setting ensures
that there is no eﬀect of UY on X, but does not alleviate possible confounds from VY , as
shown in Figure 3b. Note that this is analogous to the situation in back-door-based meth-
ods when one fails to condition on unobserved variables that aﬀect both the treatment
and outcome. Correspondingly, sensitivity analyses designed for back-door-based meth-
ods [Harding, 2009; Rosenbaum, 2010; VanderWeele and Arah, 2011; Carnegie, Harada
and Hill, 2016] can be readily adapted to analyzing split-door instances. In addition, not-
ing that split-door estimates represent averages over all discovered split-door instances,

10

SHARMA ET AL.

Graphical model

Description

Untestable as-
sumptions

Limitations

Recommendations
example

Condition on ob-
served confounders
W to isolate the
treatment effect.

X ⊥⊥ U or
Y ⊥⊥ U

Unlikely
there
are
unobserved
founders U .

that
no
con-

click-
Regress
throughs on product
attributes and direct
visits
recom-
to
mended product.

Analyze subset of
data that has inde-
pendent variation
in the treatment.

Z ⊥⊥ U and
Z ⊥⊥ Y |X, U

Difficult to find a
source of exoge-
nous variation in
the treatment.

marginal
Measure
click-throughs
on
products that expe-
rience large, sudden
shocks in traffic.

Analyze subset of
data where
the
auxiliary outcome
YD is independent
of the treatment.

YD (cid:54)⊥⊥ UY

depen-
Requires
dency
between
an auxiliary out-
come
all
and
confounders.

marginal
Measure
click-throughs
on
all pairs of products
that have uncorre-
lated direct traffic.

(a) Back-door
criterion

(b) Instrumental
variable

(c) Split-door
criterion

Fig 4
Comparison of methods for estimating the eﬀect of a treatment X on an outcome Y . W and U
represent all observed and unobserved confounders, respectively, that commonly cause both X and Y .

we introduce an additional sensitivity parameter κ that denotes the fraction of instances
for which connectedness is violated. In Appendix B we provide a derivation showing that
sensitivity for the split-door estimate reduces to sensitivity for back-door methods and
conduct this analysis for the application presented in Section 5.

4. Connections to other methods. The split-door criterion is an example of
methods that use empirical independence tests to identify causal eﬀects under certain
assumptions [Jensen et al., 2008; Cattaneo, Frandsen and Titiunik, 2015; Sharma, Hof-
man and Watts, 2015; Grosse-Wentrup et al., 2016]. By searching for subsets of the data
where desired independence holds, it also shares some properties with natural experiment
methods such as instrumental variables and conditioning methods such as regression. We
discuss these connections below; table 4 provides a summary for easy comparison.

4.1. Instrumental Variables. Both the split-door criterion and instrumental variable
(IV) methods can be used to exploit naturally occurring variation in subsets of ob-
servational data to identify causal eﬀects. Importantly, however, they make diﬀerent
assumptions. In IV methods, one uses an auxiliary variable Z, called an instrument,
that is assumed to be exogenous and that systematically shifts the distribution of the
cause X. The validity of an instrument relies on two additional assumptions: ﬁrst that
it is eﬀectively random with regard to potential confounders (Z ⊥⊥ U ), and second that
the instrument aﬀects the outcome Y only through the cause X (Z ⊥⊥ Y |X, U ). Both of
these conditions involve independence claims between observed and unobserved variables,
making them impossible to test in practice [Dunning, 2012].

The split-door criterion also relies on an auxiliary variable, but one that relates to the
outcome instead of the treatment. Speciﬁcally, it exploits an auxiliary outcome YD that
serves as a proxy for unobserved common causes UY under three important assumptions.
The ﬁrst is that the cause X does not aﬀect YD directly. The second assumption requires
that all unobserved confounders (between the cause and outcome) that aﬀect YR also
aﬀect YD. As with IV methods above, these two assumptions involve knowledge of an
unobserved variable and, as a result, cannot be tested. The third assumption requires
independence between the cause X and the auxiliary outcome YD. Since both of these
variables are observed, this assumption can be tested empirically so long as we are in the
standard setting where statistical independence implies causal independence (Assumption
2 ), equivalent to the assumption of faithfulness [Spirtes, Glymour and Scheines, 2000].
It is diﬃcult to compare these two sets of assumptions in general, but in diﬀerent
scenarios, one of these methods may be more suitable than the other. If a valid instrument
is known to exist, for instance through changes in weather or as a result of a lottery, the

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

11

variation it produces can and should be exploited to identify causal eﬀects of interest.
The split-door criterion, in contrast, is most useful when one suspects there is random
variation in the data, but cannot identify its source a priori. In particular, it is well-suited
for large-scale data where the ﬁrst two assumptions mentioned above are plausible, such
as in digital or online systems.

4.2. Back-door criterion. Alternatively, the split-door criterion can be interpreted as
using YD as a proxy for all confounders UY , and estimating the causal eﬀect whenever
YD (and hence UY ) is independent of X. Viewed this way, the split-door approach may
appear to be nothing more than a variant of the back-door criterion where one conditions
on YD instead of UY , however there are two key diﬀerences between the two methods.

First, substituting YD for UY in the back-door criterion assumes that YD is a perfect
proxy for UY . This is a much stronger assumption than requiring that YD be simply
aﬀected by UY , because any diﬀerence (e.g., measurement error) between YD and UY
can invalidate the back-door criterion [Spirtes, Glymour and Scheines, 2000]. Second, the
two methods diﬀer in their approach to identiﬁcation. The split-door criterion controls for
the eﬀect of unobserved confounders by ﬁnding subsets of data where X is not aﬀected
by UY , whereas the back-door criterion conditions on a proxy for UY to nullify the
eﬀect of unobserved confounders. Therefore, by directly controlling at the time of data
selection, the split-door criterion focuses on admitting a subset of the data for analysis
and simpliﬁes eﬀect estimation, whereas methods based on back-door criterion such as
regression, matching, and stratiﬁcation process the whole dataset and extract estimates
via statistical models [Morgan and Winship, 2014].

To illustrate these diﬀerences, we compare mathematical forms of the split-door and
back-door criteria in terms of regression equations. Conditioning on YD using regression
will lead to the following equation

applied to the entire dataset. In contrast the split-door criterion leads to the simpler
equation (as shown earlier in Section 2.2)

yr = ρ(cid:48)(cid:48)x + βyd + (cid:15)(cid:48)(cid:48)

yr,

yr = ρx + (cid:15)(cid:48)

yr,

applied only to subsets of data where X and YD are independent.

4.3. Methods based on empirical independence tests. Finally, the split-door criterion
is similar to recent work that proposes a data-driven method for determining the ap-
propriate window size in regression discontinuity designs [Cattaneo, Frandsen and Titiu-
nik, 2015; Cattaneo, Titiunik and Vazquez-Bare]. In regression discontinuities, treatment
(e.g., acceptance into a program) is assigned based on whether an observed variable (e.g.,
a test score) is above or below a pre-determined cutoﬀ. The assumption is that one can
compare outcomes for those just above and just below the cutoﬀ to estimate causal ef-
fects, but the central problem is how far from the cutoﬀ this assumption holds. The
authors present a data-driven method for selecting a window by testing for independence
between the treatment and pre-determined covariates that are uncoupled to the outcome
of interest. This approach resembles the split-door criterion in that both use indepen-
dence tests to determine which subsets of the data to include when making a causal
estimate. As a result, both methods are subject to concerns around multiple hypothesis
testing, although the regression discontinuity setting typically involves many fewer com-
parisons than the split-door criterion (dozens instead of the thousands we analyze here)
and occurs over nested windows. For these reasons we treat multiple comparisons diﬀer-
ently, estimating the error rate in identifying independent instances instead of adjusting
nominal thresholds to try to eliminate errors.

12

SHARMA ET AL.

Fig 5: Screenshot of a focal product, the book “Purity”, and its recommendations on
Amazon.com.

5. Application: Impact of a Recommender System. We now apply the split-
door criterion to the problem of estimating the causal impact of Amazon.com’s recom-
mender system. Recommender systems have become ubiquitous in online settings, pro-
viding suggestions for what to buy, watch, read or do next [Ricci, Rokach and Shapira,
2011]. Figure 5 shows an example of one of the millions of product pages on Ama-
zon.com, where the main item listed on the page, or focal product, is the book “Purity”
by Jonathan Franzen. Listed alongside this item are a few recommended products—two
written by Franzen and one by another author—suggested by Amazon as potentially of
interest to a user looking for “Purity”. Generating and maintaining these recommenda-
tions takes considerable resources, and so a natural question one might ask is how exactly
exposure to these recommended products changes consumer activity.

While simple to state, this question is diﬃcult to answer because it requires an estimate
of the counterfactual of what would have happened had someone visited a focal product
but had not been exposed to any recommendations. Speciﬁcally, we would like to know
how much traﬃc recommender systems cause, over and above what would have happened
in their absence. Naively one could assume that users would not have viewed these other
products without the recommender system, and as a result simply compute the observed
click-through rate on recommendations [Mulpuru, 2006; Grau, 2009]. As discussed earlier,
however, this assumption ignores correlated demand: users might have found their way
to some of these recommended products anyway via direct search or browsing, which we
collectively refer to as “direct traﬃc”. For instance, some users who are interested in the
book “Purity” might be fans of Franzen in general, and so might have directly searched
on Amazon.com for his other works such as “Freedom” or “The Corrections”, even if they
had not been shown recommendations linking to them. The key to properly estimating
the causal impact of the recommender, then, lies in accounting for this correlated demand
between a focal product and its recommendations.

In this section we show how the split-door criterion can be used to eliminate the
issue of correlated demand by automatically identifying and analyzing instances where
demand for a product and one (or more) of its recommendations are independent over
some time period τ . We do so by ﬁrst formalizing this problem through a causal graphical
model of recommender system traﬃc, revealing a structure amenable to the split-door
criterion. Then we apply the criterion to a large-scale dataset of web browsing activity on
Amazon.com to discover thousands of instances satisfying the criterion. Our results show
that a naive observational estimate of the impact of this recommender system overstates
the causal impact on the products analyzed by a factor of at least two. We conclude with
a number of robustness checks and comments on the validity and generalizability of our
results.

5.1. Building the causal model. The above discussion highlights that unobserved
common demand for both a focal product and its recommendations can introduce bias in
naive estimates of the causal click-through rate (CTR) on recommendations. Referring

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

13

back to Figure 2a, we formalize the problem as follows, with variables aggregated for
each day:

• X denotes the number of visits to the focal product i’s webpage.
• YR denotes recommendation visits, the number of visits to the recommended prod-
uct j through clicks on the recommendation for product j on product i’s webpage.
• YD denotes direct visits, the number of visits to product j that did not occur
through clicking on a recommendation. These could be visits to j from Amazon’s
search page or through direct visits to j’s webpage.

• UY denotes unobserved demand for product j, including both recommendation

click-throughs and direct visits.

• UX represents the part of unobserved demand for product i that is independent of

UY .

To apply the split-door criterion, we must investigate the plausibility of the con-
nectedness and independence assumptions from Section 2.1. First, the connectedness
assumption states that both YR and YD are aﬀected (possibly diﬀerently) by the same
components of demand UY for the product j. As mentioned above, connectedness is espe-
cially plausible in the context of online recommender systems where products are easily
reachable through multiple channels (e.g., search, direct navigation or recommendation
click-through) and it is unlikely that demand for a product manifests itself exclusively
through only one of these channels. Speciﬁcally, it is unlikely that there exists a compo-
nent of demand for a product that manifests itself only through indirect recommendation
click-throughs, but not through direct visits. Put another way, for connectedness not to
hold, it would have to be the case that users would have demand for a product only if
they arrived via a recommendation link, but not through other means. To the best of
our knowledge no path-speciﬁc feature of this sort exists on Amazon; thus, we expect the
connectedness assumption to hold.

Second, with respect to the independence assumption, although we cannot rule out
coincidental cancellation of eﬀects that result in X ⊥⊥ YD and violate the assumption,
we expect such events to be unlikely over a large number of product pairs. Furthermore,
for complementary product recommendations (which are the focus of this paper), we
can logically rule out violation of the independence assumption because the demand for
two complementary products are expected to be positively correlated with each other.
Therefore, it is reasonable to assume that the unobserved demand UY (and all its sub-
components) aﬀect both X and YD in the same direction. For instance, let the eﬀect
of UY be increasing for both X and YD. Then the independence assumption is satisﬁed
because the eﬀect of UY cannot be canceled out on the path X ← UY → YD if the eﬀects
of UY (and any of its sub-components) on X and YD are all positive. Given the above
assumptions, the same reasoning from Section 2.1 allows us to establish that X ⊥⊥ YD is
a suﬃcient condition for causal identiﬁcation.

5.2. Browsing data. Estimating the causal impact of Amazon.com’s recommender
system requires ﬁne-grained data detailing activity on the site. To obtain such informa-
tion, we turn to anonymized browsing logs from users who installed the Bing Toolbar
and consented to provide their anonymized browsing data through it. These logs cover a
period of nine months from September 2013 to May 2014 and contain a session identiﬁer,
an anonymous user identiﬁer, and a time-stamped sequence of all non-secure URLs that
the user visited in that session. We restrict our attention to browsing sessions on Ama-
zon.com, which leaves us with 23.4 million page visits by 2.1 million users spanning 1.3
million unique products. Of these products, we examine those that receive a minimum
of 10 page visits on at least one day in this time period, resulting in roughly 22,000 focal
products of interest.

Amazon shows many kinds of recommendations on its site. We limit our analysis to
the “Customers who bought this also bought” recommendations depicted in Figure 5, as
these recommendations are the most common and are shown on product pages from all

14

SHARMA ET AL.

product categories. To apply the split-door criterion, we need to identify focal product and
recommended product pairs from the log data and separate out traﬃc for recommended
products into direct (YD) and recommended (YR) visits. Fortunately it happens to be
the case that Amazon makes this identiﬁcation possible by explicitly embedding this
information in their URLs. Speciﬁcally, given a URL for an Amazon.com page visit, we
can use the ref, or referrer, parameter in the URL to determine if a user arrived at a
page by clicking on a recommendation or by other means. We then use the sequence
of page visits in a session to identify focal and recommended product pairs by looking
for focal product visits that precede recommendation visits. Further details about the
toolbar dataset and construction of focal and recommended product pairs can be found
in past work [Sharma, Hofman and Watts, 2015].

5.3. Applying the split-door criterion. Having argued for the assumptions underlying
the split-door criterion and extracted the relevant data from browsing logs, the ﬁnal step
in estimating the causal eﬀect of Amazon.com’s recommendation system is to use the cri-
terion to search for instances where a product and its recommendation have uncorrelated
demand.

Recalling Section 3, we employ a randomization test to search for 15-day time periods
that fail to reject the null hypothesis that direct visits to a product and one (or more) of
its recommended products are independent. The choice of 15 days represents a trade-oﬀ
between two requirements: ﬁrst, a time period large enough to yield reliable estimates;
and second, a time period short enough that Amazon’s recommendations for any given
product are unlikely to have changed within that window.

The full application of the split-door criterion is as follows. For each focal product i

and each τ = 15 day time period:

1. Compute X (i), the number of visits to the focal product on each day, and Y (ij)
R ,
the number of click-throughs to each recommended product j. Also record the total
direct visits Y (j)

D to each recommended product j.

2. For each recommended product j, use the randomization test from Section 3.1 to

determine if X (i) is independent of Y (j)

D at a pre-speciﬁed signiﬁcance level.3

• If X (i) is found to be independent of Y (j)

rate (CTR), ˆρijτ = ((cid:80)τ
CTR. Otherwise ignore this product pair.

R )/((cid:80)τ

t=1 Y (ij)

D , compute the observed click-through
t=1 X (i)), as the causal estimate of the

3. Aggregate the causal CTR estimate over all recommended products to compute

the total causal CTR per focal product, ˆρiτ .

Finally, average the causal CTR estimate over all time periods and focal products to arrive
at the mean causal eﬀect, ˆρ, and compute the rate of erroneous split-door instances φ to
estimate error in this estimate, as detailed in Appendices A and C.

5.4. Results. Applying the above algorithm results in over 114,000 potential split-
door instances, where each instance consists of a pair of focal and recommended product
over a 15-day time period. At a signiﬁcance level of α = 0.95, we obtain more than 7,000
instances that satisfy the split-door criterion. Consistent with previous work [Sharma,
Hofman and Watts, 2015], the corresponding causal CTR estimate ˆρ is 2.6% (with the
error bars spanning 2.0% to 2.7%), roughly one quarter of the naive observational es-
timate of 9.6% arrived at by computing the click-through rate across all focal and rec-
ommended product pairs. Put another way, these results imply that nearly 75% of page
visits generated via recommendation click-throughs would likely occur in the absence of
recommendations.

3Here we ﬁlter out any time periods where YD is exactly constant (because that will satisfy empirical

independence conditions trivially).

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

15

(a) Accepted at α=0.95

(b) Rejected at α=0.95

Fig 6: Examples of time series for focal and recommended products that are (a) accepted
or (b) rejected by the split-door criterion at a signiﬁcance level of α = 0.95 for the
independence test.

(a)

(b)
Fig 7: Subplot (a) shows the number of valid split-door instances obtained as the p-value
threshold (α) is increased. Subplot (b) shows the expected fraction of erroneous instances
(φ) returned by the method for those values of α. The corresponding estimate for causal
CTR is shown in Subplot (c); error bars account for both bias due to φ and natural
variance in the mean estimate.

(c)

Figure 6a shows examples of product pairs that are accepted by the test at α = 0.95.
The example on the left shows a focal product that receives a large and sudden shock in
page visits, while direct visits to its recommended product remains relatively ﬂat. This
is reminiscent of the examples analyzed in Carmi, Oestreicher-Singer and Sundararajan
[2012] and Sharma, Hofman and Watts [2015]. The example on the right, however, shows
more general patterns that are accepted under the split-door criterion but not considered
by these previous approaches: although direct visits to both the focal and recommended
products vary substantially, they do so independently, and so are still useful in our
estimate of the recommender’s eﬀect. Conversely, two example product pairs that are
rejected by the test are shown in Figure 6b. As is visually apparent, visit patterns for
each of the focal and recommended product pairs are highly correlated, and therefore
not useful in our analysis.

Changing the nominal p-value threshold used in the independence test allows us to
explore a tradeoﬀ between coverage across products in our dataset and the precision
of our causal estimate. As detailed in Appendix A, a lower threshold results in more
discovered instances, but with a higher likelihood of these instances being invalid. For
instance, Figures 7a and 7b show that decreasing the threshold to α = 0.80 results in
over 20,000 split-door instances covering nearly 11,000 unique focal products, but does so
at the expense of increasing the expected fraction of invalid instances to 0.21, indicating
that approximately one in ﬁve of the returned split-door instances may be invalid. The
result, summarized in Figure 7c, is that the error bars on our estimate of ρ increase as we
decrease α. These error bars, calculated using Equation C.4 from Appendix C, account

16

SHARMA ET AL.

Fig 8: Comparison of the causal CTR with the naive observational CTR for products
that satisfy the split-door criterion. Categories are ordered by the number of products
found by the split-door criterion in each category, with eBooks containing the most and
Health and Beauty the least.

for both bias due to erroneous split-door instances and the natural variance in the mean
estimate due to sampling.4 As α decreases, erroneous instances due to φ contribute to
most of the magnitude of the error bars shown in Figure 7c. We observe that α = 0.95
oﬀers a good compromise: error bounds are within 1 percentage point and we obtain
more than 7,000 split-door instances.

Furthermore, we can break these estimates down by the diﬀerent product categories
present on Amazon.com. Figure 8 shows the variation of ˆρ across the most popular
categories, at a nominal signiﬁcance level of α = 0.95. For the set of focal products
that satisfy the split-door criterion, we also compute the naive observational CTR. We
see substantial variation in the naive estimate, ranging from 14% on e-Books to 5% on
Personal Computer. However, when we use the split-door criterion to compute estimates,
we ﬁnd that the causal CTR for all product categories lies below 5%. These results
indicate that naive observational estimates overstate the causal impact by anywhere
from two- to ﬁve-fold across diﬀerent product categories.

There are two clear advantages to the split-door criterion compared to past approaches
for estimating the causal impact of recommender systems. First, we are able to study a
larger fraction of products compared to instrumental variable approaches that depend on
single-source variations [Carmi, Oestreicher-Singer and Sundararajan, 2012] or restricting
our attention to mining only shocks in observational data [Sharma, Hofman and Watts,
2015]. On the same dataset, the shock-based method in Sharma, Hofman and Watts [2015]
identiﬁed valid instances on 4,000 unique focal products, while the split-door criterion
ﬁnds instances for over 5,000 unique focal products at α = 0.95, and over 11,000 at
α = 0.80. Second, the split-door criterion provides a principled method to select valid
instances for analysis by tuning α, the desired signiﬁcance level, while also allowing for
an estimate of the fraction of falsely accepted instances, φ.

5.5. Threats to validity. As with any observational analysis, our results rely on cer-
tain assumptions that may be violated in practice. Furthermore, results obtained on a
subset of data may not be representative of the broader dataset of interest. Here we con-

4Note that the error bars are asymmetric; we expect erroneous split-door instances to drive the causal
estimate up from its true value, under the assumption that demand for the two products are positively
correlated with each other, as argued in Section 5.1.

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

17

(a)

(b)

Fig 9: Sensitivity analysis of the obtained click-through estimate. Panel (a) shows the
scenario where all split-door instances may be invalid. Panel (b) assumes that at most
half of the instances are invalid. The deviation of the true estimate from the obtained
estimate increases as the magnitude of the confounding from VY to X( c1) or Y (c2)
increases; however this deviation is lower in Panel (b). In both ﬁgures, dotted line shows
the obtained CTR estimate.

duct additional analyses to assess both the internal and external validity of our estimate
of the causal eﬀect of Amazon’s recommendations.

5.5.1. Internal validity: Sensitivity to the connectedness assumption. As described in
Section 3.3, connectedness is the key identifying assumption for the split-door criterion.
Here we describe a test for sensitivity of the obtained estimate (ˆρ) to violations of the
connectedness assumption.

Referring to the causal model in Figure 3a, violation of the connectedness assumption
implies that there exist components of unobserved demand VY that aﬀect both focal
product visits X and recommendation click-throughs YR, but not direct visits to the
recommended product YD. For simplicity, let us assume that VY is univariate normal
and aﬀects both X and YR linearly. We can write the corresponding structural equations
for the causal model in Figure 3b for each split-door instance as

x = c1vy + (cid:15)1
yr = f (x) + c2vy + (cid:15)2,

(5.1)

(5.2)

where f is an unknown function, and (cid:15)1 and (cid:15)2 are independent from all variables men-
tioned above and are also mutually independent. Note that (cid:15)1 includes the eﬀect of UX
and (cid:15)2 includes the eﬀect of UY . For any split-door instance, the estimator from Sec-
tion 5.3 estimates the causal eﬀect assuming that either c1 or c2 is zero.

To test the sensitivity of our estimate to the connectedness assumption, we take our
actual data and introduce an artiﬁcial confound VY by simulation, adding c1VY to X
and c2VY to YR, respectively, for a range of diﬀerent c1 and c2 values. We simulate VY
as a standard normal and vary c1 and c2 between [−1, 1], and compare these artiﬁcially
confounded estimates to our actual estimate of ˆρ = 2.6% for α = 0.95. Figure 9a shows
the deviation between estimates using the actual and simulated data as c1 and c2 vary.
The diﬀerence is maximized when both c1 and c2 are high in magnitude and is negligible
when either of c1 or c2 are zero. These simulation results suggest a bilinear sensitivity

18

SHARMA ET AL.

(a)

(b)

Fig 10: The distribution of products and total visits over product categories. Among
products with at least 10 page visits on at least one day, the subset of focal products
that satisfy the split-door criterion are nearly identical to the set of all products. Fraction
of page visits to those focal products show more variation, but the overall distributions
are similar.

to c1 and c2, a result we conﬁrm theoretically in the case of a linear causal model in
Appendix B.

This analysis assumes that all split-door instances violate the connectedness assump-
tion. Recognizing that this need not be the case, and that only some instances may be
invalid, we introduce a third sensitivity parameter κ, which corresponds to the fraction
of split-door instances that violate connectedness. For instance, we can test sensitivity of
the estimate when at least half of the split-door instances satisfy connectedness, as done
by Kang et al. [2016] for inference under multiple possibly invalid instrumental variables.
As shown in Figure 9b, when κ = 0.5 deviations from the obtained split-door estimate
are nearly halved, resulting in more robust estimates.

5.5.2. External validity: Generalizability. Although the split-door criterion yields valid
estimates of the causal impact of recommendations for the time periods where prod-
uct pairs are found to be statistically independent, it is important to emphasize that
products in the split-door sample may not be selected at random, thus violating the as-
if-random [Angrist, Imbens and Rubin, 1996] assumption powering generalizability for
natural experiments. As a result, care must be taken to extrapolate these estimates to
all products on Amazon.com.

Fortunately, as shown in Figure 10, the distribution of products and page visits in our
sample closely matches the inventory and activity on Amazon.com. Products with at least
one valid split-door time period span many product categories and cover nearly a quarter
of all focal products in the dataset at α = 0.95. Figure 10a shows that the distribution of
products analyzed by the split-door criterion across diﬀerent product categories is almost
identical to the overall set of products. Figure 10b shows a similar result for the number
of page visits of these products across diﬀerent product categories, except for eBooks
which are over-represented in valid split-door instances. For comparison, we apply the
same popularity ﬁlter that we used for the split-door criterion—at least 10 page visits
on at least one day—to the dataset with all products.

Although these results do not necessarily imply that the as-if-random assumption
is satisﬁed (indeed it is very likely not satisﬁed) they do indicate that the split-door
criterion at least allows us to estimate causal eﬀects over a diverse sample of popular
product categories, which is a clear improvement over past work [Carmi, Oestreicher-
Singer and Sundararajan, 2012; Sharma, Hofman and Watts, 2015].

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

19

6. Discussion.

In this paper we have presented a method for computing the causal
eﬀect of a variable X on another variable YR whenever we have an additional variable
YD which follows some testable conditions, and have shown its application in estimating
the causal impact of a recommender system. We now suggest guidelines to ensure proper
use of the criterion and discuss other applications for which it might be used.

6.1. Guidelines for using the criterion. As with any non-experimental method for
causal inference, the split-door criterion rests on various untestable assumptions and
requires making certain modeling choices. We encourage researchers to reason carefully
about these assumptions, explore sensitivity to modeling choices, and examine threats
to the validity of their results.

6.1.1. Reason about assumptions. The split-door criterion relies on two untestable
assumptions: independence (of X and YD), and connectedness (i.e. non-zero causal eﬀect
of UY on YD). The independence assumption is a standard assumption for observational
causal inference. Barring coincidental equality of parameters such that the eﬀect of unob-
served confounders on X and YD cancel out, the independence assumption is likely to be
satisﬁed. Nonetheless we encourage researchers to think carefully about this assumption
in applying the criterion in other domains. Depending on the application it may be pos-
sible to rule out such cancellations. For example, in our recommendation system study
we expect demand for the focal and recommended product to be correlated. Therefore,
the causal eﬀect of demand on both products is expected to be directionally identical,
and hence cancellation becomes impossible.

The connectedness assumption is potentially more restrictive. In general, it is plau-
sible whenever measurements YR and YD are additive components of the same tangible
outcome Y that can be reached by similar means. That said, connectedness remains an
untestable assumption where, once again, domain knowledge should be used to assess
its plausibility. For instance, even when YR and YD are additive components, in some
isolated cases, UY may not be connected to YD at all. In a recommender system this
can happen when customers with pre-existing interest in a product somehow visit it
only through recommendation click-throughs from other products. In such a scenario,
the split-door criterion would be invalid. We note, however, that this situation can arise
only in the (unlikely) event that no such user found the product directly. When there is
even a small number of users that visit the product directly, the split-door criterion will
again be valid and, depending on the precision of the statistical independence condition,
can be applied.

6.1.2. Explore sensitivity to test parameters. A key advantage of the split-door cri-
terion is that once these two assumptions are met, it reduces the problem of causal
identiﬁcation to that of implementing a test for statistical independence. At the same
time, this requires choosing a suitable statistical test and deciding on any free parameters
the test may have. For instance, in the case of the randomization test used here, there is
a signiﬁcance level α used to determine when to accept or reject focal and recommended
product pairs as statistically independent. Any such parameters should be varied to check
the sensitivity of estimates to these choices, as in Figures 7b and 7c.

6.1.3. Examine threats to validity. After identifying and estimating the eﬀect of inter-
est, one should examine both the internal and external validity of the resulting estimate.
In terms of internal validity, we recommend conducting a sensitivity analysis to assess
how results change when the assumptions required for identiﬁcation are violated. In the
case of the recommender system example, we simulated violations of the connectedness
assumption by artiﬁcially adding correlated noise to X and YR (but not YD) and re-ran
the split-door method to look at variation in results, as shown in Figure 9.

Finally, after establishing internal validity, one needs to consider how useful the re-
sulting estimate is for practical applications. As remarked earlier and demonstrated in

20

SHARMA ET AL.

our recommender system application, the split-door criterion is capable of capturing the
local average causal eﬀect for a large sample of the dataset that satisﬁes the required
independence assumption (X ⊥⊥ YD). The argument has been made that such local es-
timates are indeed useful in themselves [Imbens, 2010]. That said, the sample may not
be representative of the entire population, and so one must always be careful to qualify
an extension of the split-door estimate to the general population. Naturally, the more
instances discovered by the method, the more likely the estimate is to be of general use.
Additionally, we recommend that researchers perform checks similar to those in Figure 10
to compare the distribution of any available covariates to check for diﬀerences between
the general population and instances that pass the split-door criterion.

6.2. Potential applications of the split-door criterion. The key requirement of the
split-door criterion is that the outcome variable must comprise two distinct components:
one that is potentially aﬀected by the cause, and another that is not directly aﬀected by it.
In addition, we should have suﬃcient reason to believe that the two outcome components
share common causes (i.e. the connectedness assumption must be satisﬁed), and that
one of outcome variables can be shown to be independent of the cause variable (i.e. the
independence assumption must be satisﬁed). These might seem like overly restrictive
assumptions that limit applicability of the criterion, but in this section we argue that
there are in fact many interesting cases where the split-door criterion can be employed.
As we have already noted, recommendation systems such as Amazon’s are especially
well-suited to these conditions, in large part because YD has a natural interpretation
of “direct traﬃc”, or any traﬃc that is not caused by a particular recommendation.
Likewise the criterion can be easily applied to other online systems that automatically
log user visits, such as in estimating the causal eﬀect of advertisements on search engines
or websites. Somewhat more broadly, time series data in general may be amenable to
the split-door criterion, in part because diﬀerent components of the outcome occurring
at the same time are more likely to be correlated than components that share other
characteristics, and in part because time series naturally generate many observations on
the input and output variables, which permits convenient testing for independence.

For example, consider the problem of estimating the eﬀect of social media on news
consumption. There has been recent interest [Flaxman, Goel and Rao, 2016] in how social
media websites such as Facebook impact the news that people read, especially through
algorithmic recommendations such as those for “Trending news”. Given time series data
for user activity on a social media website and article visits from news website logs, we
can use the split-door criterion to estimate the eﬀect of social media on news reading.
Here YR would correspond to the visits that are referred from social media, and YD would
be all other direct visits to the news article. Most websites record the source of each page
visit, so obtaining these two components for the outcome—visits to an article through
social media and through other means—should be straightforward. Whenever people’s
social media usage is not correlated with direct visits to a news article, we can identify
the causal eﬀect of social media on news consumption. Similar analysis can be applied
to problems such as estimating the eﬀect of online popularity of politicians on campaign
ﬁnancing or the eﬀect of television advertisements on purchases.

Finally, although we have focused on online settings for which highly granular time
series data is often collected by default, we note that there is nothing intrinsic to the
split-door criterion that prevents it from being applied oﬄine. For example, many retail-
ers routinely send direct mail advertisements to existing customers whom they identify
through loyalty programs. The split-door criterion could easily be used to estimate the
causal eﬀect of these advertisements on product purchases: X would be the number of
customers that are sent an advertisement; YR would be the customers among them who
purchased the product; and YD would be the number of customers who bought the prod-
uct without receiving the mailer. More generally, the split-door criterion could be used
in any context where the outcome of interest can be diﬀerentiated into more than one
channel.

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

21

7. Conclusion.

In closing we note that the split-door criterion is just one example
of a more general class of methods that adopt a data-driven approach to causal dis-
covery [Jensen et al., 2008; Sharma, Hofman and Watts, 2015; Cattaneo, Frandsen and
Titiunik, 2015; Grosse-Wentrup et al., 2016]. As we have discussed, data-driven methods
have important advantages over traditional methods for exploiting natural variation—
allowing inference to be performed on much larger and more representative samples—
while also being less susceptible to unobserved confounders than back-door identiﬁcation
strategies. As the volume and variety of ﬁne-grained data continues to grow, we expect
these methods to increase in popularity and to raise numerous questions regarding their
theoretical foundations and practical applicability.

APPENDIX A: ESTIMATING THE FRACTION OF ERRONEOUS SPLIT-DOOR

INSTANCES

Let the expected fraction of erroneous X-YD pairs—split-door instances—returned
by the method be φ. In the terminology of multiple testing, φ refers to the False Non-
Discovery Rate (FNDR) [Delongchamp et al., 2004]. This is diﬀerent from the more
commonly used False Discovery Rate (FDR) [Farcomeni, 2008], since we deviate from
standard hypothesis testing by looking for split-door instances that have a p-value higher
than a pre-determined threshold. Given m hypothesis tests and a signiﬁcance level of α,
we show that the false non-discovery rate φ for the split-door criterion can be character-
ized as

φα ≤

(1 − α)πdepm
Wα

,

(A.1)

where πdep is the fraction of actually dependent X-YD instances in the dataset and Wα
is the observed number of X-YD instances returned by the method at level α.

The above estimate can be derived using the framework proposed by Storey [2002]
under two assumptions. The ﬁrst is that the that the distribution of p-values under the
null hypothesis is uniform, and the second is that the distribution of p-values under the
alternative hypothesis is stochastic smaller than the uniform distribution. Let the number
of invalid instances found using the split-door criterion be T . Then, by deﬁnition, the
false non-discovery rate can be written as:

φα = E

W > 0

.

(cid:21)

(cid:20) T
W

(cid:12)
(cid:12)
(cid:12)
(cid:12)

φα ≤

(1 − α) ∗ πdepm
Wα

.

Since the alternative distribution is stochastically smaller than uniform, we can arrive
at an upper bound by replacing T by the expected number of split-door instances if the
alternative distribution were uniform, (1 − α) ∗ mdependent = (1 − α) ∗ πdep ∗ m, giving

Here πdep is unknown, so it needs to be estimated. A common approach is to estimate
the fraction of actually independent instances or null hypotheses πindep and then use
πdep = 1 − πindep [Delongchamp et al., 2004]. For robustness, we suggest using multiple
procedures to estimate πindep and verify sensitivity of results to the choice of πindep. In
this paper, we use two diﬀerent estimates, derived from Storey and Tibshirani [2003],
Storey [2002] (Storey’s estimate); and Nettleton et al. [2006], Liang and Nettleton [2012]
(Nettleton’s estimate).

Storey’s estimate is deﬁned as

ˆπindep =

Wλ
m(1 − λ)

,

where λ ∈ [0, 1) is a tunable parameter—similar in interpretation to α—and Wλ is the
number of hypothesis tests having a p-value higher than λ. The choice of λ involves a

(A.2)

(A.3)

22

SHARMA ET AL.

bias-variance tradeoﬀ, with λ = 0.5 being a common choice, as in the SAM software
developed by Storey and Tibshirani [2003].

Nettleton’s estimate, on the other hand, chooses the eﬀective value of λ adaptively,
based on the observed p-value distribution. First, the p-value distribution is summarized
in a histogram containing B bins. Then, a threshold λ is chosen as the index (I) corre-
sponding to the left-most bin whose count fails to exceed the average count of the bins
to its right. This results in the following estimate, where λ = (I − 1)/B:

ˆπindep =

Wλ
m(1 − λ)

=

Wλ
m(1 − I−1
B )

.

(A.4)

Applying each of these to the m = 114, 469 focal and recommended product pairs
analyzed in Section 5 allows us to estimate the true number of dependent X-YD pairs
in the dataset, πdep. At α = 0.95, both methods give very similar results (πdep,Storey =
0.184, πdep,N ettleton = 0.187); we use πdep = 0.187 in our analysis.

APPENDIX B: SENSITIVITY ANALYSIS FOR THE CONNECTEDNESS

ASSUMPTION

In this section we analyze the sensitivity of an estimate obtained using the split-door
criterion to violations of the connectedness assumption. As Figure 3a shows, violation
implies that there exist variables VY that aﬀect only X and YR but not YD. We use the
structural equation model from Section 2.2 to illustrate sensitivity analysis.

Given that the unobserved confounders can be broken down into two components UY

and VY , we can rewrite the linear structural equations from Equation 2.8 as:

with two additional parameters c1 and c2 denoting the eﬀect of the unobserved variable
VY on X and YR, respectively. Applying the split-door criterion X ⊥⊥ YD, we write the
following equations for each obtained split-door instance:

x = ηux + γ1uy + c1vy + (cid:15)x
yr = ρx + γ2uy + c2vy + (cid:15)yr
yd = γ3uy + (cid:15)yd,

x = ηux + c1vy + (cid:15)(cid:48)
x
yr = ρx + c2vy + (cid:15)(cid:48)
yr

(B.1)

(B.2)

(B.3)

(B.4)

(B.5)

Here VY is unobserved and hence the causal eﬀect is not identiﬁed. Using (B.5) as an esti-
mating equation will lead to a biased estimate of the causal eﬀect due to the confounding
eﬀect of the unobserved common cause VY . Note that this structure is identical to the
omitted variable bias problem in back-door and conditioning-based methods [Harding,
2009]. Consequently, we obtain a similar bilinear dependence of the split-door estimate
to sensitivity parameters c1 and c2.

Speciﬁcally, the split-door method regresses YR on X to obtain an estimate ˆρ for
each obtained instance. When connectedness is violated, the bias of this estimate can be
characterized as,

ˆρ = (X T X)−1X T YR =

(cid:80)

(cid:80)

i xiyri
(cid:80)
j x2
j
i xi(ρxi + c2vyi + (cid:15)(cid:48)
(cid:80)
j x2
j
i vyixi
(cid:80)
j x2
j

(cid:80)

(cid:80)

+

= ρ + c2

=

)

yri

xi

i (cid:15)(cid:48)
(cid:80)

yri
j x2
j

,

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

23

where we use (B.5) to expand yri . As in Section 3, let τ denote the sample size for each
split-door instance. When X and VY are both standardized to have zero mean and unit
variance, and taking expectation on both sides, we obtain,

E[ˆρ] = ρ + c2 E[

vyixi] + E[

1
τ

(cid:88)

i

(cid:15)(cid:48)
yri

xi]

= ρ + c2 E[

vyi(ηuxi + c1vyi + (cid:15)(cid:48)
xi

)]

(cid:88)

i
(cid:88)

1
τ

1
τ

i

1
τ

(cid:88)

i

= ρ + c1c2 E[

vyi vyi] + η E[

vyiuxi] + E[

1
τ

(cid:88)

i

1
τ

(cid:88)

i

vyi(cid:15)(cid:48)
xi

]

E[ˆρ] = ρ + c1c2

(B.6)

where we use the independence of error terms and that UX ⊥⊥ VY .

In addition, note that the split-door method averages the estimate ˆρ obtained from
each instance. Not all instances may violate the connectedness assumption, therefore
we introduce an additional sensitivity parameter κ that denotes the fraction of invalid
split-door instances. Bias in the ﬁnal split-door estimate is then given by the following
equation in the three sensitivity parameters:

E[ˆρ] = ρ + κc1c2 .

(B.7)

For expositional clarity, the above analysis assumed a linear structural model and
demonstrated similarities with sensitivity of conditioning-based methods to unobserved
common causes. However, in practice, the structural model may not be linear. In the
recommendation example discussed in Section 5, we do not assume a linear model and
instead use an aggregate ratio estimator. As shown in Figure 9, simulations show that
sensitivity of this estimator follows a similar bilinear dependence on c1 and c2.

APPENDIX C: CHARACTERIZING ERROR IN THE SPLIT-DOOR ESTIMATE

FOR A RECOMMENDATION SYSTEM

In Section 5.3, the split-door causal estimate is deﬁned as the mean of CTR esti-
mates over all time periods and focal products with valid split-door instances. Here we
characterize the error in this estimate. The key idea is that the error comes from two
components: the ﬁrst due to some erroneously identiﬁed split-door instances, and the
second due to natural variance in estimating the mean. For a signiﬁcance level α of the
independence test, let W be the number of obtained split-door instances and N be the
number of aggregated CTR estimates ˆρiτ computed from these instances. Then the mean
estimate can be written as:

ˆρ =

(cid:80)

iτ ˆρiτ
N

,

(C.1)

where i refers to a focal product and τ refers to a split-door time period. As in Ap-
pendix A, let φ denote the expected fraction of erroneous split-door instances obtained.
That is, for an expected number of φW instances, the method may have erroneously
concluded that the focal and recommended products are independent. Correspondingly,
an expected φW = φ(cid:48)N number of ˆρiτ estimates will be invalid.5 These invalid estimates
can be expanded as:

ˆρiτ = ρcausal

iτ

+ ηiτ ,

(C.2)

5In general, the expected number of invalid ˆρiτ estimates may be less than or equal to φW , since a
focal product may have more than one recommended product that corresponds to an invalid split-door
instance.

24

SHARMA ET AL.

where η refers to the click-through rate due to correlated demand between the focal and
recommended products. Thus, the overall mean estimate can be written as:

(cid:80)

iτ ∈A ρcausal
iτ

ˆρ =

(cid:80)

=

iτ ρcausal
iτ
N

+

+ (cid:80)
iτ ∈B(ρcausal
iτ
N
iτ ∈B ηiτ
N

(cid:80)

,

+ ηiτ )

where A and B refer to (i, τ ) pairs with valid and erroneous split-door estimates respec-
tively (|A| = (1 − φ(cid:48))N, |B| = φ(cid:48)N ).

Comparing this to the true ρcausal, we obtain

ρcausal − ˆρ = (ρcausal − ¯ρcausal) −

(C.3)

(cid:80)

iτ ∈B ηiτ
N

.

The ﬁrst term of the RHS corresponds to error due to sampling variance, and the second
term corresponds to error due to correlated demand (φ). We estimate these terms below.

Error due to φ. Based on the argument for justifying the independence assumption
in Section 5.1, let us assume that the total eﬀect of UY on YR is positive (without
stipulating it for each individual instance). This means that the term due to correlated
demand is positive, (cid:80)
iτ ∈B ηiτ ≥ 0. Further, the maximum value of ηiτ is attained when
all the observed click-throughs are due to correlated demand (ηiτ = ˆρiτ ). Under this
assumption,

(cid:80)

0 ≤

iτ ∈B ηiτ
N

≤

ρmaxsum
N

,

where ρmaxsum corresponds to the maximum sum of any subset of φ(cid:48)N ˆρiτ values. An
approximate estimate can be derived using ˆρ—the empirical mean over all N values of
ρiτ —leading to ρmaxsum ≈ φ(cid:48)N ˆρ.

Error due to natural variance. We characterize this error by the 99% conﬁdence interval
for the mean estimate, given by 2.58 ∗ ˆσ√
, where ˆσ is the empirical standard deviation.
N

Combining these two, the resultant interval for the split-door estimate is

(ˆρ −

ρmaxsum
N

− 2.58

, ˆρ + 2.58

ˆσ
√
N

ˆσ
√
N

) .

(C.4)

The above interval demonstrates the bias-variance tradeoﬀ in choosing a nominal
signiﬁcance level for the independence test and the corresponding φ. At high nominal
signiﬁcance level α, bias due to φ is expected to be low but variance of the estimate may
be high due to low N . Conversely, at low values of α, variance will be lower but φ is
expected to be higher because we accept many more split-door instances.

SUPPLEMENTARY MATERIAL

Supplement A: Code for split-door criterion

(http://www.github.com/amit-sharma/splitdoor-causal-criterion). We provide an R pack-
age that implements the split-door criterion, along with code samples for applying the
criterion to new applications.

REFERENCES

Agresti, A. (1992). A survey of exact inference for contingency tables. Statistical Science 7 131–153.
Agresti, A. (2001). Exact inference for categorical data: recent advances and continuing controversies.

Statistics in Medicine 20 2709–2722.

Angrist, J. D., Imbens, G. W. and Rubin, D. B. (1996). Identiﬁcation of causal eﬀects using instru-

mental variables. Journal of the American Statistical Association 91 444–455.

SPLIT-DOOR CRITERION FOR CAUSAL IDENTIFICATION

25

Carmi, E., Oestreicher-Singer, G. and Sundararajan, A. (2012). Is Oprah contagious? Identifying

demand spillovers in online networks. NET Institute Working Paper 10-18.

Carnegie, N. B., Harada, M. and Hill, J. L. (2016). Assessing Sensitivity to Unmeasured Confounding
Using a Simulated Potential Confounder. Journal of Research on Educational Eﬀectiveness 9 395-420.
Cattaneo, M. D., Frandsen, B. R. and Titiunik, R. (2015). Randomization inference in the regression
discontinuity design: An application to party advantages in the US Senate. Journal of Causal Inference
3 1–24.

Cattaneo, M. D., Titiunik, R. and Vazquez-Bare, G. Comparing inference approaches for RD de-
signs: A reexamination of the eﬀect of head start on child mortality. Journal of Policy Analysis and
Management 36 643-681.

de Siqueira Santos, S., Takahashi, D. Y., Nakata, A. and Fujita, A. (2014). A comparative study
of statistical methods used to identify dependencies between gene expression signals. Brieﬁngs in
Bioinformatics 15 906-918.

Delongchamp, R. R., Bowyer, J. F., Chen, J. J. and Kodell, R. L. (2004). Multiple-testing strategy

for analyzing cDNA array data on gene expression. Biometrics 60 774–782.

Dunning, T. (2012). Natural experiments in the social sciences: A design-based approach. Cambridge

University Press.

Farcomeni, A. (2008). A review of modern multiple hypothesis testing, with particular attention to the

false discovery proportion. Statistical Methods in Medical Research 17 347–388.

Fiske, S. T. and Hauser, R. M. (2014). Protecting human research participants in the age of big data.

Proceedings of the National Academy of Sciences 111 13675-13676.

Flaxman, S., Goel, S. and Rao, J. M. (2016). Filter bubbles, echo chambers, and online news con-

sumption. Public Opinion Quarterly 80 298–320.

Grau, J. (2009). Personalized product recommendations: Predicting shoppers’ needs. eMarketer.
Grosse-Wentrup, M., Janzing, D., Siegel, M. and Sch¨olkopf, B. (2016). Identiﬁcation of causal rela-
tions in neuroimaging data with latent confounders: An instrumental variable approach. NeuroImage
125 825–833.

Harding, D. J. (2009). Collateral consequences of violence in disadvantaged neighborhoods. Social

Forces 88 757–784.

Imbens, G. W. (2010). Better LATE than nothing. Journal of Economic Literature 48.
Imbens, G. W. and Rubin, D. B. (2015). Causal inference in statistics, social, and biomedical sciences.

Cambridge University Press.

Jensen, D. D., Fast, A. S., Taylor, B. J. and Maier, M. E. (2008). Automatic identiﬁcation of quasi-
experimental designs for discovering causal knowledge. In Proceedings of the 14th ACM International
Conference on Knowledge Discovery and Data Mining 372–380.

Kang, H., Zhang, A., Cai, T. T. and Small, D. S. (2016). Instrumental variables estimation with
some invalid instruments and its application to Mendelian randomization. Journal of the American
Statistical Association 111 132–144.

Lewis, R. A., Rao, J. M. and Reiley, D. H. (2011). Here, there, and everywhere: Correlated online be-
haviors can lead to overestimates of the eﬀects of advertising. In Proceedings of the 20th International
Conference on World Wide Web 157–166. ACM.

Liang, K. and Nettleton, D. (2012). Adaptive and dynamic adaptive procedures for false discovery rate
control and estimation. Journal of the Royal Statistical Society. Series B (Statistical Methodology)
74 163-182.

Lydersen, S., Pradhan, V., Senchaudhuri, P. and Laake, P. (2007). Choice of test for association in

small sample unordered r× c tables. Statistics in Medicine 26 4328–4343.

Mealli, F. and Pacini, B. (2013). Using secondary outcomes to sharpen inference in randomized ex-
periments with noncompliance. Journal of the American Statistical Association 108 1120–1131.
Morgan, S. L. and Winship, C. (2014). Counterfactuals and causal inference. Cambridge University

Press.

Research.

16 2839–2849.

Springer.

Mulpuru, S. (2006). What you need to know about third-party recommendation engines. Forrester

Nettleton, D., Hwang, J. T. G., Caldo, R. A. and Wise, R. P. (2006). Estimating the number of true
null hypotheses from a histogram of p values. Journal of Agricultural, Biological, and Environmental
Statistics 11 337.

Paninski, L. (2003). Estimation of entropy and mutual information. Neural Computation 15 1191–1253.
Pearl, J. (2009). Causality. Cambridge University Press.
Pethel, S. D. and Hahs, D. W. (2014). Exact test of independence using mutual information. Entropy

Phan, T. Q. and Airoldi, E. M. (2015). A natural experiment of social network formation and dynamics.

Proceedings of the National Academy of Sciences 112 6595–6600.

Ricci, F., Rokach, L. and Shapira, B. (2011). Introduction to recommender systems handbook.

Rosenbaum, P. R. (2010). Design of observational studies. Springer.
Rosenzweig, M. R. and Wolpin, K. I. (2000). Natural “natural experiments” in economics. Journal of

Economic Literature 38 827–874.

Rubin, D. B. (2006). Matched sampling for causal eﬀects. Cambridge University Press.
Sharma, A., Hofman, J. M. and Watts, D. J. (2015). Estimating the causal impact of recommendation
systems from observational data. In Proceedings of the 16th ACM Conference on Economics and

26

SHARMA ET AL.

Computation 453–470.

Spirtes, P., Glymour, C. N. and Scheines, R. (2000). Causation, prediction, and search. MIT Press.
Steuer, R., Kurths, J., Daub, C. O., Weise, J. and Selbig, J. (2002). The mutual information:

Detecting and evaluating dependencies between variables. Bioinformatics 18 S231–S240.

Storey, J. D. (2002). A direct approach to false discovery rates. Journal of the Royal Statistical Society:

Series B (Statistical Methodology) 64 479–498.

Storey, J. D. and Tibshirani, R. (2003). SAM thresholding and false discovery rates for detecting
diﬀerential gene expression in DNA microarrays In The Analysis of Gene Expression Data: Methods
and Software 272–290. Springer New York, New York, NY.

Stuart, E. A. (2010). Matching methods for causal inference: A review and a look forward. Statistical

Science: a review journal of the Institute of Mathematical Statistics 25 1.

Sz´ekely, G. J., Rizzo, M. L., Bakirov, N. K. et al. (2007). Measuring and testing dependence by

correlation of distances. The Annals of Statistics 35 2769–2794.

VanderWeele, T. J. and Arah, O. A. (2011). Bias formulas for sensitivity analysis of unmeasured
confounding for general outcomes, treatments, and confounders. Epidemiology (Cambridge, Mass.)
22 42–52.

9 Lavelle Road
Bangalore, India 560008
E-mail: amshar@microsoft.com

641 Ave. of the Americas
New York, NY USA 10011
E-mail: jmh@microsoft.com

duncan@microsoft.com

