9
1
0
2
 
g
u
A
 
0
3
 
 
]

G
L
.
s
c
[
 
 
1
v
4
1
5
1
1
.
8
0
9
1
:
v
i
X
r
a

Adversarial Training Methods for Network Embedding

Quanyu Dai
The Hong Kong Polytechnic University
Kowloon, Hong Kong
dqyzm100@hotmail.com

Xiao Shen
The Hong Kong Polytechnic University
Kowloon, Hong Kong
shenxiaocam@163.com

Liang Zhang
JD.com
Beijing, China
zhangliang16@jd.com

Qiang Li
Y-tech, Kwai
Beijing, China
leetsiang.cloud@gmail.com

Dan Wang
The Hong Kong Polytechnic University
Kowloon, Hong Kong
csdwang@comp.polyu.edu.hk

ABSTRACT
Network Embedding is the task of learning continuous node repre-
sentations for networks, which has been shown effective in a variety
of tasks such as link prediction and node classification. Most of
existing works aim to preserve different network structures and
properties in low-dimensional embedding vectors, while neglecting
the existence of noisy information in many real-world networks
and the overfitting issue in the embedding learning process. Most
recently, generative adversarial networks (GANs) based regular-
ization methods are exploited to regularize embedding learning
process, which can encourage a global smoothness of embedding
vectors. These methods have very complicated architecture and
suffer from the well-recognized non-convergence problem of GANs.
In this paper, we aim to introduce a more succinct and effective lo-
cal regularization method, namely adversarial training, to network
embedding so as to achieve model robustness and better generaliza-
tion performance. Firstly, the adversarial training method is applied
by defining adversarial perturbations in the embedding space with
an adaptive L2 norm constraint that depends on the connectivity
pattern of node pairs. Though effective as a regularizer, it suffers
from the interpretability issue which may hinder its application in
certain real-world scenarios. To improve this strategy, we further
propose an interpretable adversarial training method by enforc-
ing the reconstruction of the adversarial examples in the discrete
graph domain. These two regularization methods can be applied
to many existing embedding models, and we take DeepWalk as
the base model for illustration in the paper. Empirical evaluations
in both link prediction and node classification demonstrate the
effectiveness of the proposed methods. The source code is available
online1.

KEYWORDS
Network Embedding, Adversarial Training, Robustness

ACM Reference Format:
Quanyu Dai, Xiao Shen, Liang Zhang, Qiang Li, and Dan Wang. 2019. Adver-
sarial Training Methods for Network Embedding. In Proceedings of the 2019

1https://github.com/wonniu/AdvT4NE_WWW2019

This paper is published under the Creative Commons Attribution 4.0 International
(CC-BY 4.0) license. Authors reserve their rights to disseminate the work on their
personal and corporate Web sites with the appropriate attribution.
WWW ’19, May 13–17, 2019, San Francisco, CA, USA
© 2019 IW3C2 (International World Wide Web Conference Committee), published
under Creative Commons CC-BY 4.0 License.
ACM ISBN 978-1-4503-6674-8/19/05.
https://doi.org/10.1145/3308558.3313445

World Wide Web Conference (WWW ’19), May 13–17, 2019, San Francisco, CA,
USA. ACM, New York, NY, USA, 11 pages. https://doi.org/10.1145/3308558.
3313445

1 INTRODUCTION
Network embedding strategies, as an effective way for extracting
features from graph structured data automatically, have gained
increasing attention in both academia and industry in recent years.
The learned node representations from embedding methods can
be utilized to facilitate a wide range of downstream learning tasks,
including some traditional network analysis tasks such as link pre-
diction and node classification, and many important applications
in industry such as product recommendation in e-commerce web-
site and advertisement distribution in social networks. Therefore,
under such great application interest, substantial efforts have been
devoted to designing effective and scalable network embedding
models.

Most of the existing works focus on preserving network struc-
tures and properties in low-dimensional embedding vectors [4, 35,
37]. Firstly, DeepWalk [35] defines random walk based neighbor-
hood for capturing node dependencies, and node2vec [13] extends
it with more flexibility in balancing local and global structural
properties. LINE [35] preserves both first-order and second-order
proximities through considering existing connection information.
Further, GraRep [4] manages to learn different high-order proximi-
ties based on different k-step transition probability matrix. Aside
from the above mentioned structure-preserving methods, several
research works investigate the learning of property-aware network
embeddings. For example, network transitivity, as the driving force
of link formation, is considered in [26], and node popularity, as
another important factor affecting link generation, is incorporated
into RaRE [14] to learn social-rank aware and proximity-preserving
embedding vectors. However, the existence of nosiy information
in real-world networks and the overfitting issue in the embedding
learning process are neglected in most of these methods, which
leaves the necessity and potential improvement space for further
exploration.

Most recently, adversarial learning regularization method is ex-
ploited for improving model robustness and generalization perfor-
mance in network embedding [8, 41]. ANE [8] is the first try in this
direction, which imposes a prior distribution on embedding vectors
through adversarial learning. Then, the adversarially regularized au-
toencoder is adopted in NetRA [41] to overcome the mode-collapse
problem in ANE method. These two methods both encourage the

global smoothness of the embedding distribution based on gen-
erative adversarial networks (GANs) [11]. Thus, they have very
complicated frameworks and suffer from the well-recognized hard
training problems of GANs [3, 29].

In this paper, we aim to leverage the adversarial training (AdvT)
method [12, 34] for network embedding to achieve model robust-
ness and better generalization ability. AdvT is a local smoothness
regularization method with more succinct architecture. Specifically,
it forces the learned classifier to be robust to adversarial examples
generated from clean ones with small crafted perturbation [34].
Such designed noise with respect to each input example is dynam-
ically obtained through finding the direction to maximize model
loss based on current model parameters, and can be approximately
computed with fast gradient method [12]. It has been demonstrated
to be extremely useful for some classification problems [12, 23].

However, how to adapt AdvT for graph representation learning
remains an open problem. It is not clear how to generate adversarial
examples in the discrete graph domain since the original method
is designed for continuous inputs. In this paper, we propose an ad-
versarial training DeepWalk model, which defines the adversarial
examples in the embedding space instead of the original discrete
relations and obtains adversarial perturbation with fast gradient
method. We also leverage the dependencies among nodes based
on connectivity patterns in the graph to design perturbations with
different L2 norm constraints, which enables more reasonable ad-
versarial regularization. The training process can be formulated as
a two-player game, where the adversarial perturbations are gener-
ated to maximize the model loss while the embedding vectors are
optimized against such designed noises with stochastic gradient
descent method. Although effective as a regularization technique,
directly generating adversarial perturbation in embedding space
with fast gradient method suffers from interpretability issue, which
may restrict its application areas. Further, we manage to restore
the interpretability of adversarial examples by constraining the
perturbation directions to embedding vectors of other nodes, such
that the adversarial examples can be considered as the substitution
of nodes in the original discrete graph domain.

Empirical evaluations show the effectiveness of both adversarial
and interpretable adversarial training regularization methods by
building network embedding method upon DeepWalk. It is worth
mentioning that the proposed regularization methods, as a principle,
can also be applied to other embedding models with embedding
vectors as model parameters such as node2vec and LINE. The main
contributions of this paper can be summarized as follows:

• We introduce a novel, succinct and effective regularization tech-
nique, namely adversarial training method, for network embed-
ding models which can improve both model robustness and gen-
eralization ability.

• We leverage the dependencies among node pairs based on net-
work topology to design perturbations with different L2 norm
constraints for different positive target-context pairs, which en-
ables more flexible and effective adversarial training regulariza-
tion.

• We also equip the adversarial training method with interpretabil-
ity for discrete graph data by restricting the perturbation direc-
tions to embedding vectors of other nodes, while maintaining

its usefulness in link prediction and only slightly sacrificing its
regularization ability in node classification.

• We conduct extensive experiments to evaluate the effectiveness

of the proposed methods.

2 BACKGROUND
2.1 Framework of Network Embedding
The purpose of network embedding is to transform discrete net-
work structure information into compact embedding vectors, which
can be further used to facilitate downstream learning tasks, such as
node classification and link prediction. The research problem can be
formally formulated as follows: Given a weighted (unweighted) di-
i=1 as
rected (undirected) graph G(V , E, A) (N = |V |), with V = {vi }N
the node set, E = {ei j }N
i, j=1 as the edge set, and A as the weighted
adjacency matrix with Ai j quantifying the strength of the rela-
tionship between node vi and vj , network embedding is aimed
: V (cid:55)→ U , where U ∈ RN ×d
at learning a mapping function f
(d ≪ N ) is the embedding matrix with the ith row ui
T as the em-
bedding vector of node vi . Note that for many network embedding
models, a context embedding matrix U ′ will also be learned. For
these methods, embedding matrix U is also called target embedding
matrix.

The learning framework of many famous network embedding
methods, such as DeepWalk [27], LINE [35] and node2vec [13], can
be summarized into two phases: a sampling phase that determines
node pairs with strong relationships, and an optimization phase that
tries to preserve pairwise relationships in the embedding vectors
through the negative sampling approach [22]. In particular, in the
first phase, these three methods capture structural information
by defining different neighborhood structures, such as random
walk explored neighborhood in [13, 27], first-order and second-
order proximities in [35]. We denote the generalized neighbors
(not restricted to directly connected nodes) of node vi as N (vi ), i.e.,
nodes in this set are closely related with vi and should be close with
vi in the embedding space. The loss function of this framework can
be abstracted as follows:

L(G |Θ) = − (cid:205)
vi ∈V
K
(cid:205)
k =1

+

{log σ (s(vi, vj |Θ))

(cid:205)
vj ∈N(vi )
Evk ∼Pk (v )[log σ (−s(vi, vk |Θ))]},

(1)

where Θ represents model parameters such as target and context
embedding matrices, s(vi , vj |Θ) represents the similarity score of
node vi and vj based on model parameters Θ, and σ (·) is the sig-
moid function. Pk (v) denotes the distribution for sampling negative
nodes, and a simple variant of unigram distribution is usually uti-
lized, i.e., Pk (v) ∝ d
, where dv is the out-degree of node v.
Eq. (1) is actually a cross entropy loss with closely related node
pair (vi , vj ) as positive samples and (vi , vk ) as negative samples,
and thus network embedding can be considered as a classification
problem.

3/4
v

2.2 Adversarial Training
Adversarial training [12, 34] is a newly proposed effective regu-
larization method for classifiers which can not only improve the
robustness of the model against adversarial attacks, but also achieve

(a) Cora, training ratio=50%, 80%.

(b) Citeseer, training ratio=50%, 80%.

(c) Wiki, training ratio=50%, 80%.

Figure 1: Impact of applying adversarial and random perturbations to the embedding vectors learned by DeepWalk on Cora,
Citeseer and Wiki on multi-class classification with training ratio as 50% and 80%. Note that "random" represents random
perturbations (noises generated from a normal distribution), while "adversarial" represents adversarial perturbations.

better generalization performance on learning tasks. It augments
the original clean data with the dynamically generated adversarial
examples, and then trains the model with the newly mixed exam-
ples. Denote the input as x and model parameters as θ . The loss on
adversarial examples can be considered as a regularization term in
the trained classifier p(y|·), which is as follows:

− log p(y |x + nadv ; θ ),

(2)

(3)

log p(y |x + n; ˆ
θ ),

wher e nadv = arg min
n, ∥n ∥≤ϵ
where n is the perturbation on the input, ϵ represents the norm
constraint of n, and ˆ
θ are current model parameters but fixed as
constants. We employ L2 norm in this paper, while L1 norm has
also been used in the literature [12]. Eq. (2) means that the model
should be robust on the adversarial perturbed examples. Before
each batch training, the adversarial noise n with respect to the
input x is firstly generated by solving optimization problem (3) to
make it resistant to current model. Since it is difficult to calculate
Eq.( 3) exactly in general, fast gradient descent method [12] is widely
used to obtain the adversarial noise approximately by linearizing
log p(y|x; θ ) around x. Specifically, the adversarial perturbation
with L2 norm constraint can be obtained as follows:
д
wher e д = ∇x log p(y |x ; ˆ
θ ).
∥д ∥2

nadv = −ϵ ·

(4)

It can be easily calculated with backpropagation method.

2.3 Motivation
To improve the generalization ability of network embedding mod-
els, two ways have been used: firstly, some denoising autoencoder
based methods [5, 8] improve model robustness by adding random
perturbation to input data or hidden layers of deep models; sec-
ondly, some existing methods [8, 41] regularize embedding vectors
from a global perspective through GAN-based method, i.e., encour-
aging the global smoothness of the distribution of embeddings.
In this paper, we aim to introduce a novel, more succinct and ef-
fective regularization method for network embedding models, i.e.,
adversarial training (AdvT) [12]. AdvT generates crafted adversarial
perturbations to model inputs and encourages local smoothness
for improving model robustness and generalization performance,
which can be expected to be more effective than the random per-
turbation methods [5] and global regularization methods [8, 41]. In
the following, we would like to compare the impact of adversarial

and random perturbation on embedding vectors to better motivate
this new regularization method.

However, it is not clear how to integrate adversarial training
into existing network embedding methods. Graph data is discrete,
and the continuous adversarial noise can not be directly imposed
on the discrete connected information. To bypass this difficulty, we
seek to define the adversarial perturbation on embedding vectors
instead of the discrete graph domain as inspired by [23]. We define
the adversarial perturbation on node embeddings as follows:

nadv = arg max
n, ∥n ∥≤ϵ

L(G | ˆΘ + n),

(5)

which can be further approximated with fast gradient method as
presented in Eq. (4).

Take DeepWalk [27] with negative sampling loss as an illustra-
tive example. We explore the effect of adversarial perturbations
on embedding vectors by adding them to the learned embedding
vectors from DeepWalk, and then perform multi-class classifica-
tion with the perturbed embeddings on several datasets. Besides,
we choose random perturbations as the compared baseline, i.e.,
noises generated from a normal distribution. Figure 1 displays node
classification results with varying L2 norm constraints on the per-
turbations. We can find that embedding vectors are much more
vulnerable to adversarial perturbations than random ones. For ex-
ample, when ε is set to 2.0, the performance of node classification
with training ratio as 80% on Cora drops 3.35% under random pertur-
bation, while that decreases 16.25% under adversarial perturbation
which is around 4 times more serious. If the embedding vectors can
be trained to be more robust on adversarial noises, we can expect
more significant improvements in generalization performance.

3 PROPOSED METHODS
In this section, we first describe the adapted adversarial training
method for network embedding models, and present the algorithm
based on DeepWalk. Then, we will tackle its interpretability issue
by designing a new adversarial perturbation generation method.

3.1 Adversarial Training DeepWalk
Figure 2 shows the framework of DeepWalk with adversarial train-
ing regularization. It consists of two phases: a sampling phase
that determines node pairs with strong relationships, and an opti-
mization phase that tries to preserve pairwise relationships in the

Figure 2: DeepWalk with Adversarial Training Regularization

embedding vectors based on negative sampling approach. Note that
in this paper we take DeepWalk as the illustrative example, and
the proposed framework can be applied to the network embedding
methods, such as LINE and node2vec, with the main difference in
the sampling phase only.

between vk

In the first phase, DeepWalk transforms the network into node
sequences by truncated random walk. For each node vi ∈ V , η
sequences each with l nodes will be randomly sampled based on
network structure with vi as the starting point. In every walking
step, the next node vj will be sampled from the neighbors of current
node vk
with the probability proportional to the edge strength
and vj . In practice, the alias table method [19] is
Ak j
usually leveraged for node sampling given the weight distribution
of neighbors of current node, which only takes O(1) time in a
single sampling step. Then in the context construction process,
closely related node pairs will be determined based on the sampled
node sequences. Denote a node sequence as S with the ith node
as si . The positive target-context pairs from S is defined as P =
{(si , sj ) : |i − j | ≤ c}, where c represents the window size. With the
constructed node pairs, the negative sampling loss will be optimized,
which is defined as follows:

L(G |Θ) = − (cid:205)
vi ∈V
K
(cid:205)
k =1

+

{log σ (u ′
j

(cid:205)
vj ∈N(vi )
Evk ∼Pk (v )[log σ (−u ′

k

T · u i )

T · u i )]},

(6)

where (vi , vj ) is from the constructed positive target-context pairs,
and ui and u ′
are the target embedding of node vi and context
j
embedding of node vj respectively.

For the adversarial version of DeepWalk, an adversarial train-
ing regularization term is added to the original loss to help learn
robust node representations against adversarial perturbations. The
regularization term shares the same set of model parameters with
the original model, but with the perturbed target and context em-
beddings as input. Existing methods consider the input examples
independently, and impose the unique L2 norm constraint on all
adversarial perturbations [12, 23]. For graph structured data, enti-
ties often correlate with each other in a very complicated way, so it
is inappropriate to treat all positive target-context relations equally
without discrimination. Adversarial regularization helps alleviate
overfitting issue, but it may also bring in some noises that can hin-
der the preservation of structural proximities, i.e., adding noises to

those inherently closely-related node pairs will prevent them from
having similar embeddings. Thus, we take advantages of the den-
pendencies among nodes to assign different L2 norm constraints to
different positive target-context relations adaptively. Specifically,
the more closely two nodes are connected, the smaller the con-
straint should be. The intuition is that less noises should be added
to those node pairs which are inherently strongly-connected in the
original network, thus they can be pushed closer in the embedding
space with high flexibility, while for those weakly-connected pairs
larger constraint can help alleviate the overfitting issue.

We obtain the similarity score of two nodes through computing

the shifted positive pointwise mutual information matrix [18]:

Mi j = max{log(

) − log(β ), 0},

(7)

ˆMi j
ˆMk j

(cid:205)
k

2 + · · · + ˆAt captures different high-order proxim-
where ˆM = ˆA + ˆA
ities, ˆA is the 1-step probability transition matrix obtained from A
after the row-wise normalization, and β is a shift factor. We set t to
2 and β to 1
in the experiments. Then, the adaptive scale factor
N
for the L2 norm constraint of the target-context pair vi and vj is
calculated as below:

Φi j = 1 − Mi j /max{M },
where max{M } represents the maximum entry of matrix M. Since
Mi j > 0 (∀i, j), Φi j ∈ [0, 1]. For those strongly-connected target-
context pairs, the adaptive scale factor can help scale down the L2
norm constraint of the adversarial perturbation, and thus alleviate
the negative effect from the noises.

(8)

Then, the adversarial training regularizer with scale factor for

L2 norm constraint is defined as follows:

Ladv (G |Θ + nadv )
= − (cid:205)
vi ∈V
K
(cid:205)
k =1

(cid:205)
vj ∈N(vi )
Evk ∼Pk (v )[log σ (−(u ′

{log σ ((u ′
j

+

k

+ Φi j · (n′

j )adv )T · (u i + Φi j · (ni )adv ))

+ (n′
k

)adv )T · (u i + (ni )adv ))]},

j )adv

(9)
where (ni )adv
represent the original adversarial per-
turbation for target embedding of node vi and context embedding
of node vj respectively.

and (n′

Finally, one key problem is how to compute the adversarial
perturbation for the given embedding vector of a node v. Here,
we follow the famous adversarial training method directly [12, 34],

and generate the perturbation noises to maximize model loss under
current model parameters. The adversarial perturbation for node v
is defined as follows:

It can be further approximated with fast gradient method as follows:

nadv = arg max
n, ∥n ∥≤ϵ

L(G | ˆΘ + n).

nadv

= ϵ

д
∥д∥2

where д = ∇u L(G | ˆΘ).

Algorithm 1: The adversarial training DeepWalk

Input

: graph G(V , E, A), window size c, embedding size d , walks
per node η, negative size K , walk length l , adversarial noise
level ϵ , adversarial regularization strength λ, batch size b

Output : Embedding matrix U

1 Initialize target and context embeddings with DeepWalk;
2 while not converge do
3

Generate a set of positive target-context pairs P with random
walk based method;

(10)

(11)

Therefore, the overall loss for the proposed adversarial training

repeat

DeepWalk is defined as follows:

L(G |Θ) + λ · Ladv (G |Θ + nadv ),
where λ is a hyperparameter to control the importance of the regu-
larization term.

(12)

In this paper, we utilize DeepWalk with negative sampling loss
as the base model for building the adversarial version of network
embedding methods. Since the original implementation is based
on the well encapsulated library, which lacks flexibility for fur-
ther adaption, we re-implement the model with tensorflow [1] and
utilize a slightly different training strategy. Specifically, in each
training epoch, we independently construct positive target-context
pairs with random walk based method, and then optimize model
parameters with mini-batch stochastic gradient descent technique.
Algorithm 1 summarizes the training procedure for the adversarial
training DeepWalk. The model parameters are firstly initialized by
training DeepWalk with the method introduced above. For each
batch training, adversarial perturbations are generated with fast
gradient method for each node in the batch as presented in Line
7. Then, the target and context embeddings will be updated by
optimizing the negative sampling loss with adversarial training reg-
ularization as shown in Line 9. Asynchronous version of stochastic
gradient descent [25] can be utilized to accelerate the training as
DeepWalk. Note that we ignore the derivative of nadv
with re-
spect to model parameters. The adversarial perturbations can be
computed with simple back-propagation method, which enjoys low
computational cost. Thus, the adversarial training DeepWalk is
scalable as the base model.

3.2 Interpretable Adversarial Training

DeepWalk

Adversarial examples refer to examples that are generated by adding
viciously designed perturbations with norm constraint to the clean
input, which can significantly increase model loss and probably
induce prediction error [34]. Take an example from [12] for il-
lustration, a “panda" image with imperceptibly small adversarial
perturbation is assigned to be “gibbon" by the well-trained clas-
sification model with high confidence, while the original image
can be correctly classified. Such adversarial examples can be well
interpreted since the perturbations are imposed on the input space.
For the adversarial training DeepWalk, adversarial perturbations
are added to node embeddings instead of the discrete nodes and
connected relations, and thus can not be easily reconstructed in
the discrete graph domain. Though effective as a regularizer for
improving model generalization performance, it suffers from lack
of interpretability, which may create a barrier for its adoption in
some real-world applications.

4

5

6

7

8

9

Sample a batch B of target-context pairs from P;
// Generate adversarial perturbations
nadv = ϵ д
∥д ∥2
batch;
// Optimize model parameters
Update target and context embeddings by applying gradient

where д = ∇u L(G | ˆΘ) for each node v in the

descent technique to Eq. (12) ;

until [| P |/b]+ times;

10
11 end

In this section, we propose an interpretable adversarial Deep-
Walk model by restoring the interpretability of adversarial pertur-
bations. Instead of pursuing the worst perturbation direction only,
we restrict the direction of perturbations toward a subset of nodes
in the graph in the embedding space, such as the neighbors of the
considered node. In this way, the adversarial perturbations in the
node embedding space might be interpreted as the substitution of
nodes in the original input space, i.e., the discrete target-context
relations. However, there might be a certain level of sacrifice on
the regularization performance because of the restriction on per-
turbation directions.

The direction vector from node vt to vk

in the embedding space

is defined as follows:

v (t )
k

=

, wher e ˜v (t )
k

= u k − u t .

(13)

˜v (t )
k
∥ ˜v (t )
k

∥2

Denote V (t ) ⊆ V (|V (t )| = T , |V (t )| ≪ |V |) as a set of nodes for
generating adversarial perturbation for node vt . We define V (t ) as
the topT nearest neighbors of node vt in the embedding space based
on current model parameters. To improve model efficiency, we can
also obtain V (t ) based on the pretrained model parameters, and fix it
for all training epochs. We use the latter strategy for experiments in
this paper. Denote w(t ) ∈ RT as the weight vector for node vt with
representing the weight associated with direction vector v(t )
,
w
k
is the kth node in V (t ). The interpretable perturbation for
where vk
vt is defined as the weighted sum of the direction vectors starting
from vt and ending with nodes in V (t ):

(t )
k

n(w (t )) =

w

(t )
k

v (t )
k

, vk ∈ V (t ), ∀k = 1, · · · , T .

(14)

T
(cid:213)

k =1

The adversarial perturbation is obtained by finding the weights
that can maximize the model loss:

w

(t )
i Adv

=

arg max
w (t ), ∥w (t ) ∥≤ϵ

Li Adv (G |Θ + n(w (t ))),

(15)

Table 1: Statistics of benchmark datasets

Name
|V |
|E|
Avg. degree
#Labels

Cora Citeseer Wiki
2,363
3,264
2,708
11,596
4,551
5,278
4.91
1.39
1.95
17
6
7

CA-GrQc CA-HepTh

5,242
14,484
2.76
-

9,877
25,973
2.63
-

is obtained by replacing nadv

in Eq. (9) with n(w(t )).
where LiAdv
In consideration of model efficiency, the above regularization term is
approximated with first-order Taylor series for easy computation as
in [12]. Thus, the weights for constructing interpretable adversarial
perturbation for node vt can be computed as follows:

w

(t )
i Adv

= ϵ

д
∥д ∥2

wher e д = ∇

w (t ) Li Adv (G |Θ + n(w (t ))).

(16)

(t )
iAdv
(t )
iAdv

with n(w

into Eq. (14), we can get the adversarial per-
). Further, by replacing nadv

Substituting w
turbations n(w
)
in Eq. (9), we can have the interpretable adversarial training regu-
larizer for DeepWalk. The algorithm for interpretable adversarial
training DeepWalk is different from Algorithm 1 in the way of
generating adversarial perturbations, and thus we do not present it
in this paper due to space limitation. Since |V (t )| ≪ |V |, the com-
putation of adversarial perturbation for one node takes constant
time. Therefore, the time complexity of this model is also linear to
the number of nodes in the graph as DeepWalk.

(t )
iAdv

4 EXPERIMENTS
In this section, we empirically evaluate the proposed methods
through performing link prediction and node classification on sev-
eral benchmark datasets.

4.1 Experiment Setup
4.1.1 Datasets. We conduct experiments on several benchmark
datasets from various real-world applications. Table 1 shows some
statistics of them. Note that we do some preprocessing on the
original datasets by deleting self-loops and nodes with zero degree.
Some descriptions of these datasets are summarized as follows:
• Cora, Citeseer [21]: Paper citation networks. Cora consists of
2708 papers with 7 categories, and Citeseer consists 3264 papers
including 6 categories.

• Wiki [31]: Wiki is a network with nodes as web pages and edges

as the hyperlinks between web pages.

• CA-GrQc, CA-HepTh [17]: Author collaboration networks. They
describe scientific collaborations between authors with papers
submitted to General Relativity and Quantum Cosmology cate-
gory, and High Energy Physics, respectively.

4.1.2 Baseline Models. The descriptions of the baseline models are
as follows:
• Graph Factorization (GF) [2]: GF directly factorizes the adja-
cency matrix with stochastic gradient descent technique to obtain
the embeddings, which enables it scale to large networks.

• DeepWalk [27]: DeepWalk regards node sequence obtained
from truncated random walk as word sequence, and then uses
skip-gram model to learn node representations. We directly use

the publicly available source code with hierarchical softmax ap-
proximation for experiments.

• LINE [35]: LINE preserves network structural proximities through
modeling node co-occurrence probability and node conditional
probability, and leverages the negative sampling approach to
alleviate the expensive computation.

• node2vec [13]: node2vec differs from DeepWalk by proposing
more flexible method for sampling node sequences to strike a
balance between local and global structural properties.

• GraRep [4]: GraRep applies SVD technique to different k-step
probability transition matrix to learn node embeddings, and fi-
nally obtains global representations through concatenating all
k-step representations.

• AIDW [8]: AIDW is an inductive version of DeepWalk with
GAN-based regularization method. A prior distribution is im-
posed on node representations through adversarial learning to
achieve a global smoothness in the distribution.

Our implemented version of DeepWalk is based on negative
sampling approach, thus we denote it as Dwns to avoid confu-
sion. We also include a baseline, namely Dwns_rand, with noises
from a normal distribution as perturbations in the regularization
term. Following existing work [30], we denote the adversarial train-
ing DeepWalk as Dwns_AdvT, and the interpretable adversarial
training DeepWalk as Dwns_iAdvT in the rest of the paper.

4.1.3 Parameter Settings. For Dwns and its variants including
Dwns_rand, Dwns_AdvT and Dwns_iAdvT, the walk length, walks
per node, window size, negative size, regularization strength, batch
size and learning rate are set to 40, 1, 5, 5, 1, 1024 and 0.001, re-
spectively. The adversarial noise level ϵ has different settings in
Dwns_AdvT and Dwns_iAdvT, while Dwns_rand follows the set-
tings of Dwns_AdvT. For Dwns_AdvT, ϵ is set to different value
for different datasets. Specifically, ϵ is set to 0.9 for Cora, 1.1 for
Citeseer in both link prediction and node classification, and 0.6 and
0.5 for Wiki in node classification and link prediction respectively,
while it is set to 0.5 for all other datasets in these two learning
tasks. For Dwns_iAdvT, ϵ is set to 5 for all datasets in both node
classification and link prediction tasks, and the size of the nearest
neighbor set T is set to 5. Besides, the dimension of embedding
vectors are set to 128 for all methods.

4.2 Impact of Adversarial Training

Regularization

In this section, we conduct link prediction and multi-class classi-
fication on adversarial training DeepWalk, i.e., Dwns_AdvT, to
study the impact of adversarial training regularization on network
representation learning from two aspects: model performance on
different training epochs and model performance under different
model size.

Node classification is conducted with support vector classifier in
Liblinear package2 [10] in default settings with the learned embed-
ding vectors as node features. In link prediction, network embed-
ding is first performed on a sub-network, which contains 80% of
edges in the original network, to learn node representations. Note
that the degree of each node is ensured to be greater than or equal

2https://www.csie.ntu.edu.tw/∼cjlin/liblinear/

(a) Cora.

(b) Citeseer.

(c) Wiki.

Figure 3: Training curves of node classification (left, training ratio 10%) and link prediction (right).

(a) Cora, training ratio=10%, 50%.

(b) Citeseer, training ratio=10%, 50%.

(c) Wiki, training ratio=10%, 50%.

Figure 4: Performance comparison between Dwns and Dwns_AdvT on multi-class classification with training ratio as 10% (left)
and 50% (right) respectively under varying embedding size.

to 1 during subsampling process to avoid meaningless embedding
vectors. We use AUC score as the performance measure, and treat
link prediction as a classification problem. Specifically, a L2-SVM
classifier is trained with edge feature inputs obtained from the
Hadamard product of embedding vectors of two endpoints as many
other works [13, 40], positive training samples as the observed 80%
edges, and the same number of negative training samples randomly
sampled from the network, i.e., node pairs without direct edge con-
nection. The testing set consists of the hidden 20% edges and two
times of randomly sampled negative edges. All experimental results
are obtained by making an average of 10 different runs.

4.2.1 Training Process. We train Dwns model for 100 epochs, and
evaluate the generalization performance of the learned embedding
vectors in each epoch with node classification and link prediction
on Cora, Citeseer and Wiki. We also conduct similar experiments
on Dwns_AdvT for 90 epochs with the model parameters initialized
from those of Dwns after 10th training epochs. Figures 3 shows
the experimental results.

In general, adversarial training regularization can bring a sig-
nificant improvement in generalization ability to Dwns through
the observation of training curves in both node classification and
link prediction. Specifically, after 10 training epochs, the evalua-
tion performance has little improvements for all datasets in two
learning tasks with further training for Dwns, while adversarial
training regularization leads to an obvious performance increase.
In Figure 3, the blue line is drew by setting its vertical coordinates
as the maximum value of the metrics of Dwns in the corresponding
experiments. We can find that the training curve of Dwns_AdvT is
continuously above the blue line in different training epochs. Par-
ticularly, there is an impressive 7.2% and 9.2% relative performance

improvement in link prediction for Cora and Citeseer respectively.
We notice that the performance of Dwns_AdvT drops slightly after
about 40 training epochs for Cora in link prediction, and about 20
training epochs for Wiki in node classification. The reason might be
that some networks are more vulnerable to overfitting, and deeper
understanding of this phenomenon needs further exploration.

4.2.2 Performance vs. Embedding Size. We explore the effect of ad-
versarial regularization under different model size with multi-class
classification. Figure 4 demonstrates the classification results on
Cora, Citeseer and Wiki with training ratio as 10% and 50%. In gen-
eral, adversarial training regularization is essential for improving
model generalization ability. Across all tested embedding size, our
proposed adversarial training DeepWalk can consistently outper-
form the base model. For two models, when varying embedding
size from 2 to 512, the classification accuracy firstly increases in a
relatively fast speed, then grows slowly, and finally becomes sta-
ble or even drops slightly. The reason is that model generalization
ability is improved with the increase of model capacity firstly until
some threshold, since more network structural information can be
captured with larger model capacity. However, when the model ca-
pacity becomes too large, it can easily result in overfitting, and thus
cause performance degradation. We notice that the performance
improvement of Dwns_AdvT over Dwns is quite small when the
embedding size is 2. It is probably because model capacity is the
main reason limiting model performance and model robustness is
not a serious issue when embedding size is too small.

4.3 Link Prediction
Link prediction is essential for many applications such as extracting
missing information and identifying spurious interaction [20]. In

this section, we conduct link prediction on five real-world networks,
and compare our proposed methods with the state-of-the-art meth-
ods. The experimental settings have been illustrated in Section 4.2.
Table 2 summarizes the experimental results.

It can be easily observed that both our proposed methods, includ-
ing Dwns_AdvT and Dwns_iAdvT, performs better than Dwns in
all five datasets, which demonstrates that two types of adversar-
ial regularization methods can help improve model generalization
ability. Specifically, there is a 4.62% performance improvement for
Dwns_AdvT over Dwns on average across all datasets, and that
for Dwns_iAdvT is 4.60%, which are very impressive.

We noticed that AIDW has a poor performance in link predic-
tion. The reasons can be two-folds: firstly, AIDW encourages the
smoothness of embedding distribution from a global perspective
by imposing a prior distribution on them, which can result in over-
regularization and thus cause performance degradation; secondly,
AIDW suffers from mode-collapse problem because of its gener-
ative adversarial network component, which can also result in
model corruption. Besides, Dwns_rand has similar performance
with Dwns, which means that the regularization term with random
perturbation contributes little to model generalization ability. By
comparison, our proposed novel adversarial training regularization
method is more stable and effective.

It can be observed that the performance of Dwns_AdvT and
Dwns_iAdvT are comparable. Either Dwns_AdvT or Dwns_iAdvT
achieves the best results across the five datasets, which shows the
remarkable usefulness of the proposed regularization methods. For
Cora and CA-GrQc, Dwns_iAdvT has better performance, although
we restrict the perturbation directions toward the nearest neighbors
of the considered node. It suggests that such restriction of perturba-
tion directions might provide useful information for representation
learning.

4.4 Node Classification
Node classification can be conducted to dig out missing information
in a network. In this section, we conduct multi-class classification
on three benchmark datasets, including Cora, Citeseer and Wiki,
with the training ratio ranging from 1% to 90%. Tables 3, 4 and 5
summarize the experimental results.

Firstly, Dwns_rand and Dwns have similar performance in all
three datasets. For example, the average improvement of Dwns_rand
over Dwns is 0.16% across all training ratios in Wiki, which can be
negligible. It validates that random perturbation for the regulariza-
tion term contributes little to the model generalization performance
again. It is understandable, since the expected dot product between
any reference vector and the random perturbation from a zero mean
gaussian distribution is zero, and thus the regularization term will
barely affect the embedding learning.

Secondly, Dwns_AdvT and Dwns_iAdvT consistently outper-
form Dwns across all different training ratios in the three datasets,
with the only exception of Dwns_iAdvT in Citeseer when the train-
ing ratio is 3%. Specifically, Dwns_AdvT achieves 5.06%, 6.45% and
5.21% performance gain over Dwns on average across all training ra-
tios in Cora, Citeseer and Wiki respectively, while the improvement
over Dwns for Dwns_iAdvT are 2.35%, 4.50% and 2.62% respec-
tively. It validates that adversarial perturbation can provide useful

direction for generating adversarial examples, and thus brings sig-
nificant improvements to model generalization ability after the
adversarial training process. For Dwns_iAdvT, it brings less perfor-
mance gain compared with Dwns_AdvT, which might because the
restriction on perturbation direction limit its regularization ability
for classification tasks. In this case, there is a tradeoff between
interpretability and regularization effect.

Thirdly, AIDW achieves better results than DeepWalk, LINE
and GraRep, which shows that global regularization on embed-
ding vectors through adversarial learning can help improve model
generalization performance. Our proposed methods, especially
Dwns_AdvT, demonstrate superiority over all the state-of-the-art
baselines, including AIDW and node2vec, based on experimental
results comparison. We can summarize that the adversarial training
regularization method has advantages over the GAN-based global
regularization methods in three aspects, including more succinct
architecture, better computational efficiency and more effective
performance contribution.

4.5 Parameter Sensitivity
We conduct parameter sensitivity analysis with link prediction and
multi-class classification on Cora, Citeseer and Wiki in this section.
Here we only present the results for Dwns_AdvT due to space
limitation. Adversarial training regularization method is very suc-
cinct. Dwns_AdvT only has two more hyperparameters compared
with Dwns, which are noise level ϵ and adversarial regularization
strength λ. Note that when studying one hyper-parameter, we fol-
low default settings for other hyper-parameters. The experimental
settings of link prediction and node classification have been ex-
plained in Section 4.2.

Fig. 5(a) presents the experimental results when varying ϵ from
0.1 to 5.0. For both learning tasks, we can find that the performance
in these three datasets first improves with the increase of ϵ, and
then drops dramatically after ϵ passing some threshold. It suggests
that appropriate setting of ϵ improves the model robustness and
generalization ability, while adversarial perturbation with too large
norm constraint can destroy the learning process of embedding
vectors. Besides, it can be easily noticed that the best settings of ϵ
are different for different datasets in general. Specifically, Citeseer
has the best results in both link prediction and node classification
when ϵ = 1.1, Cora achieves the best results when ϵ = 0.9, while the
best setting of ϵ for Wiki is around 0.5. Based on the experimental
results on these three datasets only, it seems that the denser the
network is, the smaller the best noise level parameter ϵ should be.
We conduct link prediction and node classification on three
datasets with the adversarial regularization strength λ from the set
{0.001, 0.01, 0.1, 1, 10, 100, 1000}. Fig. 5(b) displays the experimental
results. For node classification, the best result is obtained when λ is
set to around 1, larger values can result in performance degradation.
For example, the classification accuracy on Wiki drops dramatically
when λ reaches 10, and larger setting produces worse results. For
link prediction, the performance is quite consistent among the three
datasets. Specifically, when λ increases from 0.001 to 10, the AUC
score shows apparent increase for all datasets, and then tends to
saturate or decrease slightly. Empirically, 1 is an appropriate value
for the adversarial regularization strength λ.

Table 2: AUC score for link prediction

Cora
Dataset
0.550 ± 0.005
GF
0.620 ± 0.003
DeepWalk
0.626 ± 0.011
LINE
0.626 ± 0.023
node2vec
GraRep
0.609 ± 0.035
0.552 ± 0.034
AIDW
0.609 ± 0.018
Dwns
Dwns_rand
0.606 ± 0.012
Dwns_AdvT
0.644 ± 0.009
Dwns_iAdvT 0.655 ± 0.015

Citeseer
0.550 ± 0.002
0.621 ± 0.002
0.625 ± 0.004
0.627 ± 0.022
0.589 ± 0.025
0.606 ± 0.035
0.609 ± 0.011
0.608 ± 0.005
0.656 ± 0.007
0.653 ± 0.006

Wiki
0.584 ± 0.007
0.658 ± 0.002
0.647 ± 0.010
0.639 ± 0.010
0.642 ± 0.045
0.511 ± 0.019
0.648 ± 0.007
0.645 ± 0.010
0.665 ± 0.005
0.660 ± 0.002

CA-GrQc
0.593 ± 0.003
0.694 ± 0.001
0.641 ± 0.002
0.695 ± 0.006
0.500 ± 0.000
0.615 ± 0.023
0.690 ± 0.004
0.696 ± 0.006
0.707 ± 0.004
0.707 ± 0.004

CA-HepTh
0.554 ± 0.001
0.683 ± 0.000
0.629 ± 0.005
0.667 ± 0.009
0.500 ± 0.000
0.592 ± 0.019
0.662 ± 0.006
0.662 ± 0.003
0.692 ± 0.003
0.688 ± 0.004

Table 3: Accuracy (%) of multi-class classification on Cora

Table 4: Accuracy (%) of multi-class classification on Citeseer

%Ratio
GF
DeepWalk
LINE
node2vec
GraRep
AIDW
Dwns
Dwns_rand
Dwns_AdvT
Dwns_iAdvT

%Ratio
GF
DeepWalk
LINE
node2vec
GraRep
AIDW
Dwns
Dwns_rand
Dwns_AdvT
Dwns_iAdvT

%Ratio
GF
DeepWalk
LINE
node2vec
GraRep
AIDW
Dwns
Dwns_rand
Dwns_AdvT
Dwns_iAdvT

1%
24.55
44.63
38.78
58.02
54.24
54.55
57.72
56.46
62.66
58.67

1%
22.63
27.82
29.98
36.56
37.98
38.77
38.13
39.29
41.33
40.88

1%
19.76
28.65
32.46
32.41
33.38
35.17
35.76
36.12
38.42
37.46

2%
28.87
49.30
49.62
63.98
63.58
63.30
64.82
64.87
68.46
66.65

2%
24.49
32.44
34.91
40.21
40.72
42.84
42.88
43.42
45.00
45.53

2%
22.70
32.84
40.84
41.96
45.61
43.05
42.71
44.57
45.80
45.11

3%
32.07
52.25
54.51
66.33
65.36
65.86
67.93
67.44
69.91
70.17

3%
25.76
35.47
37.02
44.14
43.33
44.04
46.60
42.73
46.73
46.01

3%
27.00
36.66
44.56
47.32
49.10
46.63
48.08
46.71
50.21
49.14

4%
33.11
53.05
56.49
68.07
68.78
66.20
68.50
68.24
73.62
70.52

4%
28.21
36.85
40.51
45.71
45.56
44.27
46.14
46.00
48.57
47.10

4%
28.41
37.98
49.59
48.15
50.92
51.29
50.01
49.15
51.12
51.57

5%
34.45
55.21
58.99
69.91
70.67
67.62
68.27
70.38
74.71
71.42

5%
28.07
39.10
41.63
46.32
47.48
46.29
46.38
46.13
50.37
50.02

5%
30.28
40.73
51.11
50.65
53.01
52.40
50.21
51.74
54.29
51.88

6%
35.83
59.10
61.30
69.87
72.69
68.61
70.81
71.16
75.55
72.47

6%
29.02
41.01
42.48
47.47
47.93
47.89
48.18
48.69
51.06
50.79

6%
31.49
42.94
52.37
51.08
54.43
52.72
52.26
53.37
56.43
54.43

7%
38.25
59.26
63.05
71.41
72.37
69.52
70.72
71.34
76.18
74.26

7%
30.20
41.56
43.65
49.56
49.54
47.73
48.58
48.15
52.07
49.59

7%
31.87
45.57
54.32
52.71
54.84
55.92
53.26
53.22
57.12
55.42

8%
39.05
62.20
64.19
72.60
72.70
71.07
72.30
72.67
76.77
75.32

8%
30.70
42.81
44.25
49.78
49.87
49.61
48.35
49.92
53.09
52.78

8%
32.18
45.47
55.72
54.66
57.50
56.78
53.80
53.27
57.82
56.05

9%
39.84
63.07
66.59
73.63
73.53
71.44
72.00
73.51
77.72
74.52

9%
31.20
45.35
45.65
50.73
50.65
49.55
50.16
50.08
53.73
51.95

9%
34.16
46.06
56.51
54.81
57.01
55.92
55.27
54.21
58.60
55.93

10%
39.42
64.60
66.06
73.96
74.98
73.83
73.20
73.45
77.73
76.12

10%
31.48
45.53
47.03
50.78
50.60
50.77
50.00
50.84
54.79
52.26

10%
34.25
46.60
57.88
55.94
58.57
57.32
55.77
56.33
59.97
57.81

20%
46.14
69.85
70.86
78.04
77.48
77.93
76.98
78.04
80.50
78.88

20%
34.05
50.98
50.09
55.89
53.56
54.82
53.74
55.26
59.21
56.65

20%
36.13
54.48
61.08
59.67
61.91
61.84
59.63
59.41
63.33
61.40

30%
48.57
74.21
72.25
80.07
78.57
79.43
79.83
79.76
82.33
80.31

30%
35.69
53.79
52.71
57.93
54.63
56.96
57.37
58.51
61.06
59.07

30%
37.66
59.05
63.50
61.11
63.58
63.54
61.98
61.94
65.32
63.37

40%
50.09
76.68
73.94
81.62
79.38
81.16
80.56
81.66
83.54
81.61

40%
36.26
55.25
53.52
58.60
55.44
58.04
58.59
59.59
61.26
60.27

40%
37.43
62.70
64.68
64.21
63.77
64.90
64.01
64.07
66.53
65.71

50%
50.85
77.59
74.03
82.16
79.53
81.79
82.27
81.72
83.63
82.80

50%
37.18
56.05
54.20
59.44
55.20
59.65
59.00
59.12
62.56
61.96

50%
39.48
64.66
66.29
65.08
64.68
65.58
64.59
65.17
67.06
65.56

60%
51.88
77.68
74.65
82.25
79.68
82.27
82.52
82.53
84.41
83.03

60%
37.87
56.84
55.42
59.97
55.07
60.03
59.53
60.22
62.63
62.04

60%
40.17
65.95
66.91
65.58
65.39
66.54
66.99
66.18
67.69
67.09

70%
52.89
78.63
75.12
82.85
79.75
82.93
82.92
83.57
84.99
83.63

70%
38.85
57.36
55.87
60.32
56.04
60.99
59.62
60.62
62.40
62.20

70%
39.83
66.98
67.43
66.76
65.92
65.59
66.45
65.64
68.94
66.81

80%
52.34
79.35
75.30
84.02
80.89
84.11
82.97
83.51
85.66
83.75

80%
39.16
58.15
55.93
60.75
55.48
61.18
59.51
61.59
63.05
62.21

80%
40.25
68.37
67.46
67.19
65.18
66.58
67.55
68.20
68.35
67.70

90%
51.51
79.23
75.76
84.91
80.74
83.69
84.54
83.69
85.65
85.02

90%
39.54
59.11
57.22
61.04
56.39
62.84
60.18
60.55
63.73
63.15

90%
41.01
68.78
68.61
68.73
67.05
68.02
67.51
67.34
69.32
68.02

Table 5: Accuracy (%) of multi-class classification on Wiki

5 RELATED WORK
Network Embedding. Some early methods, such as IsoMap [36]
and LLE [28], assume the existence of a manifold structure on input
vectors to compute low-dimensional embeddings, but suffer from
the expensive computation and their inability in capturing highly
non-linear structural information of networks. More recently, some
negative sampling approach based models have been proposed,
including DeepWalk [27], LINE [35] and node2vec [13], which

enjoys two attractive strengths: firstly, they can effectively cap-
ture high-order proximities of networks; secondly, they can scale
to the widely existed large networks. DeepWalk obtains node se-
quences with truncated random walk, and learns node embeddings
with Skip-gram model [22] by regarding node sequences as sen-
tences. node2vec differs from DeepWalk by proposing more flexible
random walk method for sampling node sequences. LINE defines

(a) Noise level ϵ .

(b) Adversarial regularization strength λ.

Figure 5: Impact of hyperparameters on node classification
(left, training ratio 50%) and link prediction (right).

first-order and second-order proximities in network, and resorts to
negative sampling for capturing them.

Further, some works [4, 26, 39] tried to preserve various net-
work structural properties in embedding vectors based on matrix
factorization technique. GraRep [4] can preserve different k-step
proximities between nodes independently, HOPE [26] aims to cap-
ture asymmetric transitivity property in node embeddings, while
N-NMF [39] learns community structure preserving embedding
vectors by building upon the modularity based community de-
tection model [24]. Meanwhile, deep learning embedding mod-
els [5, 32, 33, 37] have also been proposed to capture highly non-
linear structure. DNGR [5] takes advantages of deep denoising au-
toencoder for learning compact node embeddings, which can also
improve model robustness. SDNE [37] modifies the framework of
stacked autoencoder to learn both first-order and second-order prox-
imities simultaneously. DNE-SBP [33] utilizes a semi-supervised
SAE to preserve the structural balance property of the signed net-
works. Both GraphGAN [38] and A-RNE [9] leverage generative
adversarial networks to facilitate network embedding, with the
former unifies the generative models and discriminative models
of network embedding to boost the performance while the latter
focuses on sampling high-quality negative nodes to achieve better
similariy ranking among node pairs.

However, the above mentioned models mainly focus on learning
different network structures and properties, while neglecting the
existence of noisy information in real-world networks and the over-
fitting issue in embedding learning process. Most recently, some
methods, including ANE [8] and NetRA [41], try to regularize the
embedding learning process for improving model robustness and
generalization ability based on generative adversarial networks
(GANs). They have very complicated frameworks and suffer from
the well-recognized hard training problems of GANs. Furthermore,
these two methods both encourage the global smoothness of the em-
bedding distribution, while in this paper we utilize a more succinct
and effective local regularization method.

Adversarial Machine Learning. It was found that several ma-
chine learning models, including both deep neural network and
shallow classifiers such as logistic regression, are vulnerable to
examples with imperceptibly small designed perturbations, called
adversarial examples [12, 34]. This phenomenon was firstly ob-
served in areas like computer vision with continuous input vectors.
To improve model robustness and generalization ability, adversarial
training method [12] is shown to be effective. It generates adversar-
ial perturbations for original clean input with the aim of maximizing
current model loss, and further approximates the difficult optimiza-
tion objective with first-order Taylor Series. Such method has also
been applied to text classification problem in [23, 30] by defining
the perturbation on continuous word embeddings, and recommen-
dation in [15] by generating adversarial perturbations on model
parameters. However, to the best of our knowledge, there is no prac-
tice of adversarial training regularization for graph representation
learning.

For graph structured data, they are fundamentally different from
images because of their discrete and indifferentiable characteristics.
Some existing works [6, 7, 42] aimed to explore how to generate
the adversarial examples in the discrete, binary graph domain, and
whether similar vulnerability exists in graph analysis applications.
In [7], adversarial attacks are generated by modifying combinato-
rial structure of graph with a reinforcement learning based method,
which is shown to be effective in Graph Neural Network models.
Both [42] and [6] designed attack methods to Graph Convolutional
Network [16]. Particularly, NETTACK [42] focuses on attributed
graph classification problem and FGA [6] tackles network repre-
sentation learning. However, all of them studied adversarial attack
methods without providing any defense algorithms for improving
the robustness of existing methods against these attacks. Differ-
ently, in this paper, we aim to propose adversarial regularization
method for network embedding algorithms to improve both model
robustness and generalization ability.

6 CONCLUSION
In this paper, we proposed two adversarial training regularization
methods for network embedding models to improve the robustness
and generalization ability. Specifically, the first method is adapted
from the classic adversarial training method by defining the pertur-
bation in the embedding space with adaptive L2 norm constraint.
Though it is effective as a regularizer, the lack of interpretability
may hinder its adoption in some real-world applications. To tackle
this problem, we further proposed an interpretable adversarial train-
ing method by restricting the perturbation directions to embedding
vectors of other nodes, such that the crafted adversarial examples
can be reconstructed in the discrete graph domain. Both methods
can be applied to the existing embedding models with node em-
beddings as model parameters, and DeepWalk is used as the base
model in the paper for illustration. Extensive experiments prove the
effectiveness of the proposed adversarial regularization methods
for improving model robustness and generalization ability. Future
works would include applying adversarial training method to the
parameterized network embedding methods such as deep learning
embedding models.

7 ACKNOWLEDGMENTS
Parts of the work were supported by HK ITF UIM/363.

REFERENCES
[1] Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey
Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, Manju-
nath Kudlur, Josh Levenberg, Rajat Monga, Sherry Moore, Derek Gordon Murray,
Benoit Steiner, Paul A. Tucker, Vijay Vasudevan, Pete Warden, Martin Wicke,
Yuan Yu, and Xiaoqiang Zheng. 2016. TensorFlow: A System for Large-Scale
Machine Learning. In OSDI. USENIX Association, 265–283.

[2] Amr Ahmed, Nino Shervashidze, Shravan M. Narayanamurthy, Vanja Josifovski,
and Alexander J. Smola. 2013. Distributed large-scale natural graph factorization.
In WWW. 37–48.

[3] Martín Arjovsky, Soumith Chintala, and Léon Bottou. 2017. Wasserstein Genera-

tive Adversarial Networks. In ICML. 214–223.

[4] Shaosheng Cao, Wei Lu, and Qiongkai Xu. 2015. GraRep: Learning Graph Repre-

sentations with Global Structural Information. In CIKM. 891–900.

[5] Shaosheng Cao, Wei Lu, and Qiongkai Xu. 2016. Deep Neural Networks for

Learning Graph Representations. In AAAI. 1145–1152.

[6] Jinyin Chen, Yangyang Wu, Xuanheng Xu, Yixian Chen, Haibin Zheng, and Qi
Xuan. 2018. Fast Gradient Attack on Network Embedding. CoRR abs/1809.02797
(2018).

[7] Hanjun Dai, Hui Li, Tian Tian, Xin Huang, Lin Wang, Jun Zhu, and Le Song.
2018. Adversarial Attack on Graph Structured Data. In ICML (JMLR Workshop
and Conference Proceedings), Vol. 80. 1123–1132.

[8] Quanyu Dai, Qiang Li, Jian Tang, and Dan Wang. 2018. Adversarial Network

Embedding. In AAAI.

[9] Quanyu Dai, Qiang Li, Liang Zhang, and Dan Wang. 2019. Ranking Network

Embedding via Adversarial Learning. In PAKDD.

[10] Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen
Lin. 2008. LIBLINEAR: A Library for Large Linear Classification. JMLR 9 (2008),
1871–1874.

[11] Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-
Farley, Sherjil Ozair, Aaron C. Courville, and Yoshua Bengio. 2014. Generative
Adversarial Nets. In NIPS. 2672–2680.

[12] Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. 2014. Explaining and

Harnessing Adversarial Examples. CoRR abs/1412.6572 (2014).

[13] Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable Feature Learning for

Networks. In KDD. 855–864.

[14] Yupeng Gu, Yizhou Sun, Yanen Li, and Yang Yang. 2018. RaRE: Social Rank

Regulated Large-scale Network Embedding. In WWW. ACM, 359–368.

[15] Xiangnan He, Zhankui He, Xiaoyu Du, and Tat-Seng Chua. 2018. Adversarial

Personalized Ranking for Recommendation. In SIGIR. ACM, 355–364.

[16] Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with

Graph Convolutional Networks. In ICLR.

[17] Jure Leskovec, Jon M. Kleinberg, and Christos Faloutsos. 2007. Graph evolution:

Densification and shrinking diameters. TKDD 1, 1 (2007), 2.

[18] Omer Levy and Yoav Goldberg. 2014. Neural Word Embedding as Implicit Matrix

Factorization. In NIPS. 2177–2185.

[19] Aaron Q. Li, Amr Ahmed, Sujith Ravi, and Alexander J. Smola. 2014. Reducing

the sampling complexity of topic models. In KDD. 891–900.

[20] Linyuan Lv and Tao Zhou. 2011. Link prediction in complex networks: A survey.

Physica A: Statistical Mechanics and its Applications 390, 6 (2011), 1150 – 1170.

[21] Andrew McCallum, Kamal Nigam, Jason Rennie, and Kristie Seymore. 2000.
Automating the Construction of Internet Portals with Machine Learning. Inf.
Retr. 3, 2 (2000), 127–163.

[22] Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S. Corrado, and Jeffrey Dean.
2013. Distributed Representations of Words and Phrases and their Composition-
ality. In NIPS. 3111–3119.

[23] Takeru Miyato, Andrew M. Dai, and Ian Goodfellow. 2017. Adversarial Training

Methods for Semi-Supervised Text Classification. In ICLR.

[24] M. E. J. Newman. 2006. Finding community structure in networks using the

eigenvectors of matrices. Phys. Rev. E 74 (Sep 2006), 036104. Issue 3.

[25] Feng Niu, Benjamin Recht, Christopher Ré, and Stephen J. Wright. 2011. HOG-
WILD!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent.
Advances in Neural Information Processing Systems (2011), 693–701.

[26] Mingdong Ou, Peng Cui, Jian Pei, Ziwei Zhang, and Wenwu Zhu. 2016. Asym-

metric Transitivity Preserving Graph Embedding. In KDD. 1105–1114.

[27] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. DeepWalk: online learning

of social representations. In KDD. 701–710.

[28] Sam T. Roweis and Lawrence K. Saul. 2000. Nonlinear Dimensionality Reduction
by Locally Linear Embedding. Science 290 (2000), 2323–2326. Issue 5500.
[29] Tim Salimans, Ian J. Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford,
and Xi Chen. 2016. Improved Techniques for Training GANs. In NIPS. 2226–2234.
[30] Motoki Sato, Jun Suzuki, Hiroyuki Shindo, and Yuji Matsumoto. 2018. Inter-
pretable Adversarial Perturbation in Input Embedding Space for Text. In IJCAL.
4323–4330.

[31] Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, and
Tina Eliassi-Rad. 2008. Collective Classification in Network Data. AI Magazing
29, 3 (2008), 93–106.

[32] Xiao Shen and Fu-Lai Chung. 2017. Deep Network Embedding with Aggregated
Proximity Preserving. In Proceedings of the IEEE/ACM International Conference
on Advances in Social Networks Analysis and Mining. 40–43.

[33] Xiao Shen and Fu-Lai Chung. 2018. Deep Network Embedding for Graph Rep-
IEEE Transactions on Cybernetics

resentation Learning in Signed Networks.
(2018).

[34] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
Ian Goodfellow, and Rob Fergus. 2014. Intriguing properties of neural networks.
In ICLR.

[35] Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei.
2015. LINE: Large-scale Information Network Embedding. In WWW. 1067–1077.
[36] Joshua B. Tenenbaum, Vin de Silva, and John C. Langford. 2000. A Global
Geometric Framework for Nonlinear Dimensionality Reduction. Science 290
(2000), 2319–2323. Issue 5500.

[37] Daixin Wang, Peng Cui, and Wenwu Zhu. 2016. Structural Deep Network Em-

bedding. In KDD. 1225–1234.

[38] Hongwei Wang, Jia Wang, Jialin Wang, Miao Zhao, Weinan Zhang, Fuzheng
Zhang, Xing Xie, and Minyi Guo. 2018. GraphGAN: Graph Representation
Learning with Generative Adversarial Nets. In AAAI.

[39] Xiao Wang, Peng Cui, Jing Wang, Jian Pei, Wenwu Zhu, and Shiqiang Yang. 2017.

Community Preserving Network Embedding. In AAAI. 203–209.

[40] Zhitao Wang, Chengyao Chen, and Wenjie Li. 2017. Predictive Network Repre-

sentation Learning for Link Prediction. In SIGIR. 969–972.

[41] Wenchao Yu, Cheng Zheng, Wei Cheng, Charu C. Aggarwal, Dongjin Song, Bo
Zong, Haifeng Chen, and Wei Wang. 2018. Learning Deep Network Representa-
tions with Adversarially Regularized Autoencoders. In KDD. 2663–2671.
[42] Daniel Zügner, Amir Akbarnejad, and Stephan Günnemann. 2018. Adversarial

Attacks on Neural Networks for Graph Data. In KDD. 2847–2856.

