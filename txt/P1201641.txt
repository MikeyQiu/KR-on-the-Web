Determining Semantic Textual Similarity
using Natural Deduction Proofs

Hitomi Yanaka1
hitomiyanaka@g.ecc.u-tokyo.ac.jp

Koji Mineshima2
mineshima.koji@ocha.ac.jp

Pascual Mart´ınez-G´omez3
pascual.mg@aist.go.jp

Daisuke Bekki2
bekki@is.ocha.ac.jp

1The University of Tokyo
2Ochanomizu University
3Artiﬁcial Intelligence Research Center, AIST
Tokyo, Japan

Abstract

Determining semantic textual similarity is
a core research subject in natural language
processing. Since vector-based models for
sentence representation often use shallow
information, capturing accurate semantics
is difﬁcult. By contrast, logical seman-
tic representations capture deeper levels of
sentence semantics, but their symbolic na-
ture does not offer graded notions of tex-
tual similarity. We propose a method for
determining semantic textual similarity by
combining shallow features with features
extracted from natural deduction proofs of
bidirectional entailment relations between
sentence pairs. For the natural deduc-
tion proofs, we use ccg2lambda, a higher-
order automatic inference system, which
converts Combinatory Categorial Gram-
mar (CCG) derivation trees into semantic
representations and conducts natural de-
duction proofs. Experiments show that our
system was able to outperform other logic-
based systems and that features derived
from the proofs are effective for learning
textual similarity.

1

Introduction

Determining semantic textual similarity (STS) is
one of the most critical tasks in information re-
trieval and natural language processing. Vector-
based sentence representation models have been
widely used to compare and rank words, phrases
or sentences using various similarity and related-
ness scores (Wong and Raghavan, 1984; Mitchell
and Lapata, 2010; Le and Mikolov, 2014). Re-

cently, neural network-based sentence representa-
tion models (Mueller and Thyagarajan, 2016; Hill
et al., 2016) have been proposed for learning tex-
tual similarity. However, these vector-based mod-
els often use shallow information, such as words
and characters, and whether they can account for
phenomena such as negation and quantiﬁcation is
not clear. Consider the sentences: Tom did not
meet some of the players and Tom did not meet any
of the players. If functional words such as some or
any are ignored or represented as the same vec-
tor, then these sentences are to be represented by
identical vectors. However, the ﬁrst sentence im-
plies that there is a player who Tom did not meet,
whereas the second sentence means that Tom did
not meet anyone, so the sentences have different
meanings.

Conversely, logic-based approaches have been
successful in representing the meanings of com-
plex sentences, having had a positive impact for
applications such as recognizing textual entail-
ment (Mineshima et al., 2015, 2016; Abzian-
idze, 2015, 2016). However, purely logic-based
approaches only assess entailment or contradic-
tion relations between sentences and do not offer
graded notions of semantic similarity.

In this paper, we propose to leverage logic cues
to learn textual similarity. Our hypothesis is that
observing proof processes when testing the seman-
tic relations is predictive of textual similarity. We
show that our approach can be more effective than
systems that ignore these logic cues.

2 Related Work

Vector-based models of semantic composition
have been widely studied with regards to calcu-
lating STS. Mitchell and Lapata (2008, 2010)

7
1
0
2
 
l
u
J
 
7
2
 
 
]
L
C
.
s
c
[
 
 
1
v
3
1
7
8
0
.
7
0
7
1
:
v
i
X
r
a

proposed a sentence vector model involving word
vector addition or component-wise multiplication.
Addition and multiplication are commutative and
associative and thus ignore word order.
Polaj-
nar et al. (2015) proposed a discourse-based sen-
tence vector model considering extra-intra senten-
tial context. Also, a categorical compositional dis-
tributional semantic model has been developed for
recognizing textual entailment and for calculating
STS (Grefenstette and Sadrzadeh, 2011; Kartsak-
lis et al., 2014; Kartsaklis and Sadrzadeh, 2016).
However, these previous studies are mostly con-
cerned with the structures of basic phrases or sen-
tences and do not address logical and functional
words such as negations and connectives. Neu-
ral network-based models of semantic composi-
tion (Mueller and Thyagarajan, 2016; Hill et al.,
2016) have also been proposed. Although these
models achieve higher accuracy, their end-to-end
nature introduces challenges in the diagnosis of
the reasons that make two sentences to be similar
or dissimilar to each other. These diagnosis capa-
bilities may play an important role in making the
system explainable and also to guide future system
improvements in a more precise manner. Our ap-
proach presented in this paper is partially inspired
by the latter two objectives.

Meanwhile, some previous studies have pro-
posed logic systems for capturing the seman-
tic relatedness of sentences. The Meaning Fac-
tory (Bjerva et al., 2014) uses both shallow and
logic-based features for learning textual similarity.
In this system, the overlap of predicates and entail-
ment judgments are extracted as logic-based fea-
tures. UTexas (Beltagy et al., 2014b) uses Prob-
abilistic Soft Logic for learning textual similarity.
In this system, each ground atom in the logical for-
mulas has a probability based on distributional se-
mantics of a word. The weights of the logical for-
mulas are calculated from the probabilities of their
ground atoms and are extracted as features. These
previous studies improved the accuracy by using
logic-based features derived from the entailment
results of ﬁrst-order theorem proving in addition
to using shallow features such as sentence lengths.

In our study, we determine the semantic similar-
ity of sentences based on the conception of proof-
theoretic semantics (Bekki and Mineshima, 2017).
The key idea is that not only the entailment results
but also the theorem proving process can be con-
sidered as features for learning textual similarity.

That is, by taking into account not only whether a
theorem is proved but also how it is proved, we can
capture the semantic relationships between sen-
tence pairs in more depth.

Another difference between our study and pre-
vious logic systems is that we use higher-order
predicate logic. Higher-order predicate logic is
able to represent complex sentence semantics such
as generalized quantiﬁers more precisely than
ﬁrst-order predicate logic.
In addition, higher-
order predicate logic makes the logical structure
of a sentence more explicit than ﬁrst-order predi-
cate logic does, so it can simplify the process of
proof search (Miller and Nadathur, 1986).

3 System Overview

Figure 1 shows an overview of the system which
extracts features for learning textual similarity
from logical proofs. To produce semantic repre-
sentations of sentences and prove them automati-
cally, we use ccg2lambda (Mart´ınez-G´omez et al.,
2016), which is a semantic parser combined with
an inference system based on natural deduction.

First,

sentences are parsed into syntactic
trees based on Combinatory Categorial Grammar
(CCG) (Steedman, 2000). CCG is a syntactic the-
ory suitable for semantic composition from syn-
tactic structures. Meaning representations are ob-
tained based on semantic templates and combina-
tory rules for the CCG trees. Semantic templates
are deﬁned manually based on formal semantics.
Combinatory rules specify the syntactic behaviors
of words and compositional rules for the CCG
In ccg2lambda, two wide-coverage CCG
trees.
parsers, C&C (Clark and Curran, 2007) and Easy-
CCG (Lewis and Steedman, 2014), are used for
converting tokenized sentences into CCG trees ro-
bustly. According to a previous study (Mart´ınez-
G´omez et al., 2017), EasyCCG achieves higher ac-
curacy. Thus, when the output of both C&C and
EasyCCG can be proved, we use EasyCCG’s out-
put for creating features.

Second, the meanings of words are described
using lambda terms. Semantic representations are
obtained by combining lambda terms in accor-
dance with the meaning composition rules spec-
iﬁed in the CCG tree. The semantic representa-
tions are based on Neo-Davidsonian event seman-
tics (Parsons, 1990; Mineshima et al., 2015), in
which every verb is decomposed into a predicate
over events and a set of functional expressions re-

prove the bidirectional entailment relations, A(cid:48) ⇒
B(cid:48) and B(cid:48) ⇒ A(cid:48).
If the initial natural deduc-
tion proofs fail, we re-run the proof, adding rel-
evant external axioms or skipping unproved sub-
goals until the proof is completed. After that, fea-
tures for learning textual similarity are extracted
by quantifying the provability of the bidirectional
entailment relations.

The details of the procedure are as follows.
First, we attempt a natural deduction proof without
using external axioms, aiming to prove entailment
relations, A(cid:48) ⇒ B(cid:48) and B(cid:48) ⇒ A(cid:48). If both fail,
then we check whether A(cid:48) contradicts B(cid:48), which
amounts to proving the negation of the original
conclusion, namely A(cid:48) ⇒ ¬B(cid:48) and B(cid:48) ⇒ ¬A(cid:48).

The similarity of a sentence pair tends to be
higher when the negation of the conclusion can
be proved, compared with the case where nei-
ther the conclusion nor its negation can be proved.
In the SICK (Sentences Involving Compositional
Knowledge) dataset (Marelli et al., 2014) (see Sec-
tion 6.1 for details), 70% of the sentence pairs an-
notated as contradictory are assigned a relatedness
score in [3, 5).

Next, if we fail to prove entailment or contradic-
tion, that is, we cannot prove the conclusion or its
negation, we identify an unproved sub-goal which
is not matched by any predicate in the premise.
We then attempt to prove A(cid:48) ⇒ B(cid:48) and B(cid:48) ⇒ A(cid:48)
using axiom injection, following the method in-
troduced in Mart´ınez-G´omez et al. (2017). In ax-
iom injection, unproved sub-goals are candidates
to form axioms. We focus only on predicates that
share at least one argument with both the premise
and the conclusion. This means that an axiom can
be generated only if there is a predicate p in the
pool of premises and a predicate q in a sub-goal
and p and q share a variable in an argument posi-
tion, possibly with the same case (e.g., Subject or
Object).

In generating axioms,

the semantic relation-
ships between the predicates in the premise and
those in the conclusion are checked using lexical
knowledge. In this study, we use WordNet (Miller,
1995) as the source of lexical knowledge. Linguis-
tic relations between predicates are checked in the
following order: inﬂections, derivationally related
forms, synonyms, antonyms, hypernyms, similar-
ities, and hyponyms. If any one of these relations
is found in the lexical knowledge, an axiom can
be generated. Again, if the proof fails, we attempt

Figure 1: System overview.

lating the events. Adverbs and prepositions are
also represented as predicates over events.

Third, we attempt to prove entailment relations
between sentence pairs. For this purpose, we use
Coq (Bertot and Castran, 2010), which can be
used for efﬁcient theorem-proving for natural lan-
guage inference using both ﬁrst-order and higher-
order logic (Mineshima et al., 2015). Coq’s proof
calculus is based on natural deduction (Prawitz,
1965), a proof system based on inference rules
called introduction and elimination rules for log-
ical connectives. The inference system imple-
mented in ccg2lambda using Coq achieves efﬁ-
cient automatic inference by feeding a set of pre-
deﬁned tactics and user-deﬁned proof-search tac-
tics to its interactive mode. The natural deduc-
tion system is particularly suitable for injecting
external axioms during the theorem-proving pro-
cess (Mart´ınez-G´omez et al., 2017).

Finally, features for learning textual similar-
ity are extracted from the proofs produced by
ccg2lambda during the theorem-proving process.
In this study, we experimented with logistic re-
gression, support vector regression and random
forest regression, ﬁnding that random forest re-
gression was the most effective. We therefore
chose random forest regression for learning tex-
tual similarity, with its hyperparameters being op-
timized by grid search. The mean squared error
(MSE) was used to measure the prediction perfor-
mance of our system.

4 Proof Strategy for Learning Textual

Similarity

4.1 Overview of the proof strategy

Sentence similarity depends on complex elements,
such as word overlaps and semantic relations. We
capture the similarity between the sentence pair
(A, B) as a function of the provability of bidirec-
tional entailment relations for (A, B) and combine
it with shallow features. After obtaining logical
formulas A(cid:48) and B(cid:48) from A and B, we attempt to

G : A ∧ B

∧-INTRO

G1 : A
G2 : B

P : A1 ∧ A2 ∧ · · · ∧ An

P0 : ∃e1x1x2(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1)

∧ bar(x2) ∧ in(e1, x2))

∧-ELIM

G0 : ∃e1x1(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1))

P1 : A1, P2 : A2, . . . , Pn : An

∃-ELIM (P0), ∃-INTRO (G0)

G : A → B

→-INTRO

P : A
G : B

P1 : A → B
P2 : A

→-ELIM

P : B

G : ∃xA(x)

P : ∃xA(x)

∃-INTRO

∃-ELIM

P1 : A(t)
P2 : t = u

=-ELIM

G1 : A(x)

P1 : A(x)

P : A(u)

Figure 2: Example of the inference rules used in
natural deduction. P, P1, . . . Pn are formulas in
the premise, while G, G1, G2 are formulas in the
goal. The initial formulas are at the top, with the
formulas obtained by applying the inference rules
shown below.

to prove the negation of the conclusion using the
axiom injection mechanism.

If the proof by axiom injection fails because of
a lack of lexical knowledge, we obtain sentence
similarity information from partial proofs by sim-
ply accepting the unproved sub-goals and forcibly
completing the proof. After the proof is com-
pleted, information about the generated axioms
and skipped sub-goals is used to create features.

4.2 Proving entailment relations

As an illustration of how our natural deduction
proof works, consider the case of proving entail-
ment for the following sentence pair:
A: A man is singing in a bar.
B: A man is singing.

The sentences A and B are mapped onto logical
formulas A(cid:48) and B(cid:48) based on event semantics via
CCG-based semantic composition, as follows.

A(cid:48) : ∃e1x1x2(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1)

∧ bar(x2) ∧ in(e1, x2))

B(cid:48) : ∃e1x1(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1))

First, we attempt a natural deduction proof of
A(cid:48) ⇒ B(cid:48), setting A(cid:48) as the premise and B(cid:48) as the
goal of the proof. Then A(cid:48) and B(cid:48) are decomposed
according to the inference rules.

Figure 2 shows the major inference rules we use
in the proofs. Inference rules in natural deduction
are divided into two types: introduction rules and

P1 : man(x1) ∧ sing(e1) ∧ (subj(e1) = x1)

∧ bar(x2) ∧ in(e1, x2)

G1 : man(x1) ∧ sing(e1) ∧ (subj(e1) = x1)

∧-ELIM (P1), ∧-INTRO (G1)

P2 : man(x1), P3 : sing(e1), P4 : subj(e1) = x1,

P5 : bar(x2), P6 : in(e1, x2)

G2 : man(x1), G3 : sing(e1), G4 : subj(e1) = x1

Figure 3: The proof process for the example en-
tailment relation.

elimination rules. Introduction rules specify how
to prove a formula in the goal, decomposing a goal
formula into smaller sub-goals. Elimination rules
specify how to use a premise, decomposing a for-
mula in the pool of premises into smaller ones.

The proof process for A(cid:48) ⇒ B(cid:48) is shown in Fig-
ure 3. Here A(cid:48) is initially set to the premise P0 and
B(cid:48) to the goal G0. P0 and G0 are then decomposed
using elimination rules (∧-ELIM, ∃-ELIM) and intro-
duction rules (∧-INTRO, ∃-INTRO). Then we obtain a
set of premise formulas P = {P2, P3, P4, P5, P6},
and a set of sub-goals G = {G2, G3, G4}. The
proof is performed by searching for a premise Pi
whose predicate and arguments match those of a
given sub-goal Gj.
If such a logical premise is
found, the sub-goal is removed. In this example,
the sub-goals G2, G3, and G4 match the premises
P2, P3, and P4, respectively. Thus, A(cid:48) ⇒ B(cid:48) can
be proved without introducing axioms.

Second, we attempt the proof in the opposite
direction, B(cid:48) ⇒ A(cid:48), by switching P0 and G0 in
Figure 3. Again, by applying inference rules, we
obtain the following sets of premises P and sub-
goals G:

P = {P2 : man(x1), P3 : sing(e1),

P4 : subj(e1) = x1}

G = {G2 : man(x1), G3 : sing(e1),

G4 : subj(e1) = x1,
G5 : bar(x2), G6 : in(e1, x2))}

Here, the two sub-goals G5 and G6 do not match
any of the premises, so the attempted proof of
B(cid:48) ⇒ A(cid:48) fails. We therefore attempt to inject
additional axioms, but in this case no predicate
in P shares the argument x2 of the predicates
bar(x2) and in(e1, x2) in G. Thus, no axiom can
be generated. To obtain information from a partial
proof, we forcibly complete the proof of B(cid:48) ⇒ A(cid:48)
by skipping the unproved sub-goals bar(x) and

in(e1, x2).

4.3 Proving the contradiction

The proof strategy illustrated here can be straight-
forwardly applied to proving the contradiction. In
natural deduction, a negative formula of the form
¬A can be deﬁned as A → False (“the formula
A implies the contradiction”), by using a proposi-
tional constant False to encode the contradiction.
Thus, the inference rules for negation can be taken
as special cases of implication rules, as shown in
Figure 4.

As an illustration, let us consider the following

sentence pair:

A: No man is singing.
B: There is a man singing loudly.

Figure 5 shows the proof process. The sentences
A and B are mapped to P0 and P1, respectively,
via compositional semantics and the goal G0 is set
to False. By decomposing P1 using elimination
rules and then by combining P2, P3, and P4, we
can obtain P6. From P0 and P6 we can then derive
the contradiction.

These proofs are performed by an automated
prover implemented on Coq, using tactics for ﬁrst-
order theorem proving. When a proof is success-
ful, Coq outputs the resulting proof (a proof term),
from which we can extract detailed information
such as the number of proof steps and the types
of inference rules used. In addition to the entail-
ment/contradiction result, information about the
proof process is used to create features.

5 Description of the Features

To maximize accuracy when learning textual sim-
ilarity, we adopt a hybrid approach that uses both
logic-based features extracted from the natural de-
duction proof and other, non-logic-based features.
All features are scaled to the [0, 1] range.

5.1 Logic-based Features

We propose 15 features consisting of nine different
types of logic-based features. Six of these feature
types are derived from the bidirectional natural de-
duction proofs: six features are extracted from the
direct proof (A(cid:48) ⇒ B(cid:48)) and another six from the
reverse proof (B(cid:48) ⇒ A(cid:48)). The remaining three
feature types are derived from semantic represen-
tations of the sentence pairs. The feature types are
as follows.

G : ¬A

¬-INTRO

P : A
G : False

P1 : ¬A
P2 : A

¬-ELIM

P : False

Figure 4: Inference rules of negation.

P0 : ¬∃e1∃x1(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1))
P1 : ∃e1∃x1(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1)

∧ loudly(e1))

G0 : False

∃-ELIM, ∧-ELIM (P2)

P2 : man(x1), P3 : sing(e1), P4 : subj(e1) = x1,
P5 : loudly(e1)

∃-INTRO, ∧-INTRO (P2)

P6 : ∃e1∃x1(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1))

Figure 5: Proof process for the contradiction ex-
ample.

Logical inference result. As stated in Section 4,
we include features to distinguish the case where
either the conclusion or its negation can be proved
from the one where neither can be proved. If the
conclusion can be proved, the feature is set to 1.0.
If the negation of the conclusion can be proved,
the feature is set to 0.5. If neither can be proved,
the feature is set to 0.0.
Axiom probabilities. The probability of an ax-
iom and the number of axioms appearing in the
proof are used to create features. The probability
of an axiom is deﬁned as the inverse of the length
of the shortest path that connects the senses in the
is-a (hypernym/hyponym) taxonomy in WordNet.
When multiple axioms are used in the proof, the
average of the probabilities of the axioms is ex-
tracted as a feature. If the proof can be completed
without using axioms, the feature is set to 1.0.
Proved sub-goals. Given that proofs can be ob-
tained either by proving all the sub-goals or skip-
ping unproved sub-goals, we use the proportion of
proved sub-goals as a feature. Our assumption is
that if there are more unproved sub-goals then the
sentence pair is less similar. When there are m
logical formulas in the premise pool and n proved
sub-goals, we set the feature to n/m. If the theo-
rem can be proved without skipping any sub-goals,
the feature is set to 1.0. It may be the case that
the number of sub-goals is so large that some sub-
goals remain unproved even after axiom injection.

Since the proportion of unproved sub-goals is de-
creased by axiom injection, we use the proportion
of unproved sub-goals both with and without ax-
iom injection as features.
Cases in unproved sub-goals. Subject or object
words can affect the similarity of sentence pairs.
Therefore, the number of each case in unproved
sub-goals, like subj(e1) in Figures 3 and 5, is
used as a feature. Here, we count subjective, ob-
jective, and dative cases.
Proof steps. In general, complex theorems are dif-
ﬁcult to prove and in such cases the sentence pairs
are considered to be less similar. We therefore use
the number of Coq’s proof steps, namely the num-
ber of inference rule applications in a given proof,
as a feature.
Inference rules. The complexity of a natural de-
duction proof can be measured in terms of the in-
ference rules used for each proof step. We there-
fore extract the relative frequency with which each
inference rule is used in the proof as a feature. We
check seven inference rules for natural deduction
using Coq (cf. Figure 2): introduction and elimi-
nation rules for conjunction (∧-INTRO, ∧-ELIM), im-
plication (→-INTRO, →-ELIM), and existential quan-
tiﬁcation (∃-INTRO, ∃-ELIM), and the elimination
rule for equality (=-ELIM).
Predicate overlap.
Intuitively, the more predi-
cates overlap between the premise and the conclu-
sion, the more likely it is that the inference can be
proved. We therefore use the proportion of pred-
icates that overlap between the premise and the
conclusion as a feature.
Semantic type overlap. Each semantic represen-
tation in higher-order logic has a semantic type,
such as Entity for entities and Prop for proposi-
tions. As with predicates, we use the degree of se-
mantic type overlap between the premise and the
conclusion as a feature.
Existence of negative clauses. Whether or not the
premise or conclusion contain negative clauses is
an effective measure of similarity. In semantic rep-
resentations, negative clauses are represented by
the negation operator ¬, so we check for negation
operators in the premise and the conclusion and
set this feature to 1.0 if either contains one.

5.2 Non-logic-based Features

nouns and verbs from the sentence pairs and use
the degrees of overlap of the noun and verb lem-
mas as features.
Part-of-speech overlap. We obtain part-of-
speech (POS) tags for all words in the sentence
pairs by ﬁrst tokenizing them with the Penn Tree-
bank Project tokenizer1 and then POS tagging
them with C&C POS tagger (Curran and Clark,
2003). The degree of overlap between the sen-
tences’ POS tags is used as a feature.
Synset overlap. For each sentence in the pair, we
obtain the set containing all the synonym lemmas
(the synset) for the words in the sentence. The
degree of overlap between the sentences’ synsets
is used as a feature.
Synset distance. For each word in the ﬁrst sen-
tence, we compute the maximum path similarity
between its synset and the synset of any other
word in the second sentence. Then, we use the
average of maximum path similarities as a feature.
Sentence length.
If the conclusion sentence is
long, there will possibly be many sub-goals in the
proof. We therefore use the average of the sen-
tence lengths and the difference in length between
the premise and the conclusion sentences as fea-
tures.
String similarity. We use the similarity of the se-
quence of characters within the sentence pairs as a
feature. The Python Difﬂib2 function returns the
similarity between two sequences as a ﬂoating-
point value in [0, 1]. This measure is given by
2.0 ∗ M/T , where T is the total number of ele-
ments in both sequences and M is the number of
matches. This feature is 1.0 if the sequences are
identical and 0.0 if they have nothing in common.
Sentence similarity from vector space models.
We calculate sentence similarity by using three
major vector space models, TF-IDF, latent se-
mantic analysis (LSA) (Deerwester et al., 1990),
and latent Dirichlet allocation (LDA) (Blei et al.,
2003). We use these cosine similarities as features.
Existence of passive clauses. Passive clauses
have an inﬂuence on similarity.
In CCG trees,
passive clauses are represented using the syntactic
category Spss\N P . We check for the occurrence
of passive clauses in the premise and conclusion,
and if either of them contains a passive clause then
the feature is set to 1.0.

We also use the following eight non-logic-based
features.
Noun/verb overlap. We extract and lemmatize all

1ftp://ftp.cis.upenn.edu/pub/treebank/public html/

tokenization.html

2https://docs.python.org/3.5/library/difﬂib.html

ID
23
1412
9963

Sentence1

Sentence2

Entailment Score

There is no biker jumping in the air. A lone biker is jumping in the air

Men are sawing logs.
The animal is grazing on the grass.

Men are cutting wood.
The cop is sitting on a police bike.

no
yes
unknown

4.2
4.5
1

Table 1: Examples in the SICK dataset with different entailment labels and similarity scores.

Mueller et al. (2016)
Our system
SemEval2014 Best Score
The Meaning Factory
UTexas
Baseline

γ
0.882
0.838
0.828
0.827
0.714
0.653

ρ
0.835
0.796
0.769
0.772
0.674
0.745

MSE
0.229
0.561
0.325
0.322
0.499
0.808

Table 2: Results on the test split of SICK dataset.

6 Experiments and Evaluation

SemEval-2014

6.1 Experimental Conditions
We evaluated our system3 using two datasets:
SICK
the
dataset (Marelli et al., 2014) and the SemEval-
2012 version of the MSR-paraphrase video corpus
dataset (MSR-vid) (Agirre et al., 2012). The
experimental conditions were as follows.

version

the

of

6.1.1 The SICK dataset

The SICK dataset is a dataset for studying STS as
well as for recognizing textual entailment (RTE).
It was originally developed for evaluating com-
positional distributional semantics, so it contains
logically challenging expressions such as quan-
tiﬁers, negations, conjunctions and disjunctions.
The dataset contains 9927 sentence pairs with a
5000/4927 training/test split. These sentence pairs
are manually annotated with three types of labels
yes (entailment), no (contradiction), or unknown
(neutral) as well as a semantic relatedness scores
in [1, 5] (see Table 1 for a sample).

In this dataset, sentence pairs whose gold entail-
ment labels are no tend to be scored a little more
highly than the average, whereas those whose la-
bels are unknown have a wide range of scores.
Thus, we set the baseline of the relatedness score
to 5 when the gold entailment label was yes and to
3 when the label was no or unknown.

We compared our system with the following
systems: the state-of-the-art neural network-based
system (Mueller and Thyagarajan, 2016); the best
system (Zhao et al., 2014) from SemEval-2014;
and two of the logic-based systems stated in Sec-

tion 2: namely The Meaning Factory (Bjerva et al.,
2014) and UTexas (Beltagy et al., 2014b). The
Pearson correlation coefﬁcient γ, Spearman’s rank
correlation coefﬁcient ρ, and the MSE were used
as the evaluation metrics.

6.1.2 The MSR-vid dataset

The MSR-vid dataset is our second dataset for the
STS task and contains 1500 sentence pairs with
a 750/750 training/test split. All sentence pairs
are annotated with semantic relatedness scores in
the range [0, 5]. We used this dataset to compare
our system with the best system from SemEval-
2012 (B¨ar et al., 2012) and the logic-based UTexas
system (Beltagy et al., 2014a). We used the Pear-
son correlation coefﬁcient γ as the evaluation met-
ric.

6.2 Results

Table 2 shows the results of our experiments with
the SICK dataset. Although the state-of-the-art
neural network-based system yielded the best re-
sults overall, our system achieved higher scores
including the
than SemEval-2014 submissions,
two logic-based systems (The Meaning Factory
and UTexas), in terms of Pearson correlation and
Spearman’s correlation.

The main reason for our system’s lower per-
formance in terms of MSE is that some theorems
could not be proved because of a lack of lexical
knowledge. In the current work, we only consider
word-level knowledge (word-for-word paraphras-
ing); we may expand the knowledge base in the
future by using more external resources.

As we mentioned above, the sentence pairs an-
notated as unknown produced a wide range of
scores. The Pearson correlation of the unknown
portion of the SICK dataset was 0.766, which sug-
gests that our logic-based system can also be ap-
plied to neutral sentence pairs.

Table 3 shows the results of our experiments
with the MSR-vid dataset. These results also in-
dicate that our logic-based system achieved higher
accuracy than the other logic-based systems.

3Available at https://github.com/mynlp/ccg2lambda.

Table 4 shows evaluation results for each feature

SemEval2012 Best Score
Our system
Beltagy et al. (2014)

γ
0.873
0.853
0.830

Table 3: Results on the test split of MSR-vid.

Predicate overlap
Inference rules
Probability of axioms
Proof steps
Proved sub-goals
Logical inference result
Unproved sub-goals’ case
Semantic type overlap
Negative clauses
Noun/verb overlap
Vector space model
String similarity
Synset overlap
Synset distance
Part-of-speech overlap
Sentence length
Passive clauses
Only logic-based
Only non logic-based
All

ρ
γ
MSE
0.734
0.609
0.691
0.794
0.619
0.632
0.865
0.540
0.543
0.915
0.494
0.458
0.926
0.443
0.432
0.939
0.399
0.386
0.973
0.307
0.301
0.987
0.219
0.245
1.004
0.323
0.163
0.763
0.554
0.661
0.857
0.510
0.594
0.977
0.418
0.414
0.978
0.341
0.382
0.999
0.330
0.352
0.954
0.346
0.349
0.993
0.240
0.231
1.017
0.046
0.023
0.613
0.760
0.798
0.793
0.621
0.732
0.838 0.796 0.561

Table 4: Results when training our regressor with
each feature group in isolation.

group in isolation, showing that inference rules
and predicate overlaps are the most effective fea-
tures. Compared with the non-logic-based fea-
tures, the logic-based features achieved a slightly
higher accuracy, a point that will be analyzed in
more detail in the next section. Overall, our re-
sults show that combining logic-based features
with non logic-based ones is an effective method
for determining textual similarity.

6.3 Positive examples and error analysis

Table 5 shows some examples for which the pre-
diction score was better when using logic-based
features than when using non-logic-based ones.

For IDs 642 and 1360, one sentence contains a
passive clause while the other sentence does not.
In such cases, the sentence pairs are not superﬁ-
cially similar. By using logical formulas based on
event semantics we were able to interpret the sen-
tence containing the passive clause correctly and
judge that the passive and non-passive sentences

are similar to each other.

In ID 891, one sentence contains a negative
clause while the other does not. Using shallow
features, the word overlap is small and the predic-
tion score was much lower than the correct score.
Our logic-based method, however, interpreted the
ﬁrst sentence as a negative existential formula of
the form ¬∃xP(x) and the second sentence as an
existential formula ∃xP (cid:48)(x). Thus, it could easily
handle the semantic difference between the posi-
tive and negative sentences.

In ID 1158, by contrast, the proportion of word
overlap is so high that the prediction score with
non-logic-based features was much higher than
the correct score. Our method, however, was able
to prove the contradiction using an antonym axiom
of the form ∀x(remove(x) → ¬add(x)) from
WordNet and thus predict the score correctly.

In ID 59, the proportion of word overlap is
low, so the prediction score with non-logic-based
features was lower than the correct score. Our
method, however, was able to prove the partial en-
tailment relations for the sentence pair and thus
predict the score correctly. Here the logic-based
method captured the common meaning of the sen-
tence pair: both sentences talk about the kids play-
ing in the leaves.

Finally, in ID 71, the prediction score with non-
logic-based features was much higher than the cor-
rect score. There are two reasons for this phe-
nomenon: negations tend to be omitted in non-
logic-based features such as TF-IDF and the pro-
portion of word overlap is high. However, as
logical formulas and proofs can handle negative
clauses correctly, our method was able to predict
the score correctly.

Table 6 shows examples where using only logic-
based features produced erroneous results. In ID
3974, the probability of axiom ∀x(awaken(x) →
up(x)) was low (0.25) and thus the prediction
score was lower than the correct score. Likewise,
in ID 4833, the probability of axiom ∀x(ﬁle(x) →
do(x)) was very low (0.09) and thus the pre-
diction score was negatively affected.
In these
cases, we need to consider phrase-level axioms
such as ∀x(awaken(x) → wake up(x)) and
∀x(ﬁle nail(x) → do manicure(x)) using a
paraphrase database. This, however, is an issue
for future study. In ID 1941, the system wrongly
proved the bidirectional entailment relations by
adding external axioms, so the prediction score

Gold

Pred
+logic

Pred
-logic

Entailment

ID Sentence Pair

642

1360

891

1158

59

71

A person is climbing a rock with a rope, which is pink.
A rock is being climbed by a person with a rope, which is pink.
The machine is shaving the end of a pencil.
A pencil is being shaved by the machine.
There is no one on the shore.
A bunch of people is on the shore.
A woman is removing ingredients from a bowl.
A woman is adding ingredients to a bowl.
Kids in red shirts are playing in the leaves.
Three kids are jumping in the leaves.
There is no child lying in the snow and making snow angels.
Two people in snowsuits are lying in the snow and making snow angels.

5.0

4.7

3.6

3.3

3.9

3.3

4.9

4.6

3.7

3.5

3.8

3.3

4.1

3.8

2.6

4.1

3.1

4.1

Yes

Yes

No

No

Unknown

Unknown

Table 5: Examples for which our regressor trained only with logic-based features performs better than
when using non-logic features. “Gold”: correct score, “Pred+logic”: prediction score only with logic-
based features, “Pred-logic”: prediction score only with non-logic-based features.

ID Sentence Pair

Gold

System Axiom

A girl is awakening.
A girl is waking up.
A girl is ﬁling her nails.
A girl is doing a manicure.

3974

4833

1941

A woman is putting the baby into a trash can.
A person is putting meat into a skillet.

4.9

4.2

1.0

3.6

1.8

3.3

∀x(awaken(x) → wake(x))
∀x(awaken(x) → up(x))
∀x(nail(x) → manicure(x))
∀x(ﬁle(x) → do(x))
∀x(woman(x) → person(x))
∀x(trash(x) → skillet(x))
∀x(baby(x) → meat(x))

Table 6: Error examples when training the regressor only with logic-based features.

was much higher than the correct score. Set-
ting the threshold for the probability of an axiom
may be an effective way of improving our axiom-
injection method.

7 Conclusion

We have developed a hybrid method for learn-
ing textual similarity by combining features based
on logical proofs of bidirectional entailment rela-
tions with non-logic-based features. The results
of our experiments on two datasets show that our
system was able to outperform other logic-based
systems. In addition, the results show that infor-
mation about the natural deduction proof process
can be used to create effective features for learning
textual similarity. Since these logic-based features
provide accuracy improvements that are largely
additive with those provided by non-logic-based
features, neural network-based systems may also
beneﬁt from using them.

In future work, we will reﬁne our system so
that it can be applied to other tasks such as ques-
tion answering. Compared with neural network-
based systems, our natural deduction-based sys-
tem can not only assess how similar sentence pairs
are, but also explain what the sources of simi-

larity/dissimilarity are by referring to information
about sub-goals in the proof. Given this interpreta-
tive ability, we believe that our logic-based system
may also be of beneﬁt to other natural language
processing tasks, such as question answering and
text summarization.

Acknowledgments

We thank the three anonymous reviewers for their
detailed comments. This work was supported by
JST CREST Grant Number JPMJCR1301, Japan.

References

Lasha Abzianidze. 2015. A tableau prover for natural
logic and language. In Proceedings of the 2015 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP-15), pages 2492–2502, Lisbon,
Portugal. Association for Computational Linguis-
tics.

Lasha Abzianidze. 2016. Natural solution to FraCaS
entailment problems. In Proceedings of the 5th Joint
Conference on Lexical and Computational Seman-
tics, pages 64–74, Berlin, Germany. Association for
Computational Linguistics.

Eneko Agirre, Daniel Cer, Mona Diab, and Aitor
Gonzalez-Agirre. 2012. SemEval-2012 Task 6: A

pilot on semantic textual similarity. In Proceedings
of the 6th International Workshop on Semantic Eval-
uation (SemEval-2012), pages 385–393, Montr´eal,
Canada. Association for Computational Linguistics.

Daniel B¨ar, Chris Biemann,

Iryna Gurevych, and
Torsten Zesch. 2012. UKP: Computing seman-
tic textual similarity by combining multiple con-
In Proceedings of the
tent similarity measures.
Sixth International Workshop on Semantic Evalu-
ation (SemEval-2012), pages 435–440, Montr´eal,
Canada. Association for Computational Linguistics.

Daisuke Bekki and Koji Mineshima. 2017. Context-
passing and underspeciﬁcation in dependent type se-
mantics. In Stergios Chatzikyriakidis and Zhaohui
Luo, editors, Modern Perspectives in Type Theoret-
ical Semantics, Studies of Linguistics and Philoso-
phy, pages 11–41. Springer.

Islam Beltagy, Katrin Erk, and Raymond Mooney.
2014a. Probabilistic soft logic for semantic tex-
tual similarity. In Proceedings of the 52nd Annual
Meeting of the Association for Computational Lin-
guistics (ACL-2014), pages 1210–1219, Baltimore,
Maryland. Association for Computational Linguis-
tics.

Islam Beltagy, Stephen Roller, Gemma Boleda, Ka-
trin Erk, and Raymond Mooney. 2014b. UTexas:
Natural language semantics using distributional se-
In Proceedings of
mantics and probabilistic logic.
the 8th International Workshop on Semantic Evalu-
ation (SemEval-2014), pages 796–801, Dublin, Ire-
land. Association for Computational Linguistics and
Dublin City University.

Yves Bertot and Pierre Castran. 2010.

Interac-
tive Theorem Proving and Program Development:
Coq’Art The Calculus of Inductive Constructions.
Springer Publishing Company, Incorporated, New
York, USA.

Johannes Bjerva, Johan Bos, Rob van der Goot, and
Malvina Nissim. 2014. The Meaning Factory: For-
mal semantics for recognizing textual entailment
and determining semantic similarity. In Proceedings
of the 8th International Workshop on Semantic Eval-
uation (SemEval-2014), pages 642–646, Dublin, Ire-
land. Association for Computational Linguistics and
Dublin City University.

David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet allocation. Journal of Ma-
chine Learning, 3:993–1022.

Stephen Clark and James R. Curran. 2007. Wide-
coverage efﬁcient statistical parsing with CCG
and log-linear models. Computational Linguistics,
33(4):493–552.

James R Curran and Stephen Clark. 2003. Investigat-
ing GIS and smoothing for maximum entropy tag-
gers. In Proceedings of the tenth conference on Eu-
ropean chapter of the Association for Computational

Linguistics-Volume 1, pages 91–98. Association for
Computational Linguistics.

Scott Deerwester, Susan T. Dumais, Thomas K. Lan-
dauer, and Richard Harshman. 1990.
Indexing by
latent semantic analysis. Journal of the American
Society for Information Science, 41(6):391–407.

Edward Grefenstette and Mehrnoosh Sadrzadeh. 2011.
Experimental support for a categorical composi-
tional distributional model of meaning. In Proceed-
ings of the 2011 Conference on Empirical Methods
in Natural Language Processing (EMNLP-2011),
pages 1394–1404, Edinburgh, Scotland, UK. Asso-
ciation for Computational Linguistics.

Felix Hill, Kyunghyun Cho, and Anna Korhonen.
2016. Learning distributed representations of sen-
tences from unlabelled data. In Proceedings of the
2016 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 1367–1377, San
Diego, California. Association for Computational
Linguistics.

Dimitri Kartsaklis, Nal Kalchbrenner, and Mehrnoosh
Sadrzadeh. 2014. Resolving lexical ambiguity in
In Proceed-
tensor regression models of meaning.
ings of the 52nd Annual Meeting of the Associ-
ation for Computational Linguistics (ACL-2014),
pages 212–217, Baltimore, Maryland. Association
for Computational Linguistics.

Dimitri Kartsaklis and Mehrnoosh Sadrzadeh. 2016.
Distributional inclusion hypothesis for tensor-based
In Proceedings of the 26th Inter-
composition.
national Conference on Computational Linguistics:
Technical Papers (COLING-2016), pages 2849–
2860, Osaka, Japan. The COLING 2016 Organizing
Committee.

Quoc V. Le and Tomas Mikolov. 2014. Distributed
representations of sentences and documents.
In
Proceedings of the 31th International Conference
on Machine Learning, (ICML-2014), pages 1188–
1196, Beijing, China.

Mike Lewis and Mark Steedman. 2014. A* CCG pars-
In Proceed-
ing with a supertag-factored model.
ings of the 2014 Conference on Empirical Methods
in Natural Language Processing (EMNLP-2014),
pages 990–1000, Doha, Qatar. Association for Com-
putational Linguistics.

Marco Marelli, Stefano Menini, Marco Baroni, Luisa
Bentivogli, Raffaella Bernardi, and Roberto Zam-
parelli. 2014. A SICK cure for the evaluation of
In
compositional distributional semantic models.
Proceedings of the 9th International Conference on
Language Resources and Evaluation (LREC-2014),
pages 216–223, Reykjavik, Iceland. European Lan-
guage Resources Association.

Pascual Mart´ınez-G´omez, Koji Mineshima, Yusuke
Miyao, and Daisuke Bekki. 2016. ccg2lambda: A

Tamara Polajnar, Laura Rimell, and Stephen Clark.
2015. An exploration of discourse-based sentence
spaces for compositional distributional semantics.
In Proceedings of the 1st Workshop on Linking
Computational Models of Lexical, Sentential and
Discourse-level Semantics, pages 1–11, Lisbon, Por-
tugal. Association for Computational Linguistics.

Dag Prawitz. 1965. Natural Deduction – A Proof-
Theoretical Study. Almqvist & Wiksell, Stockholm,
Sweden.

Mark Steedman. 2000. The Syntactic Process. MIT

Press, Cambridge, USA.

S. K. M. Wong and Vijay V. Raghavan. 1984. Vector
space model of information retrieval: A reevalua-
tion. In Proceedings of the 7th Annual International
ACM SIGIR Conference on Research and Develop-
ment in Information Retrieval, pages 167–185.

Jiang Zhao, Tiantian Zhu, and Man Lan. 2014. ECNU:
One stone two birds: Ensemble of heterogenous
measures for semantic relatedness and textual en-
In Proceedings of the 8th International
tailment.
Workshop on Semantic Evaluation (SemEval-2014),
pages 271–277, Dublin, Ireland. Association for
Computational Linguistics and Dublin City Univer-
sity.

In Proceedings
compositional semantics system.
of ACL-2016 System Demonstrations, pages 85–
90, Berlin, Germany. Association for Computational
Linguistics.

Pascual Mart´ınez-G´omez, Koji Mineshima, Yusuke
Miyao, and Daisuke Bekki. 2017. On-demand injec-
tion of lexical knowledge for recognising textual en-
tailment. In Proceedings of the 15th Conference of
the European Chapter of the Association for Compu-
tational Linguistics (EACL-2017), pages 710–720,
Valencia, Spain. Association for Computational Lin-
guistics.

Dale A. Miller and Gopalan Nadathur. 1986. Some
uses of higher-order logic in computational linguis-
In Proceedings of the 24th Annual Meeting
tics.
of the Association for Computational Linguistics,
pages 247–256, New York, New York, USA. Asso-
ciation for Computational Linguistics.

George A. Miller. 1995. WordNet: A lexical
database for English. Communications of the ACM,
38(11):39–41.

Koji Mineshima, Pascual Mart´ınez-G´omez, Yusuke
Miyao, and Daisuke Bekki. 2015. Higher-order
logical inference with compositional semantics. In
Proceedings of the 2015 Conference on Empirical
Methods in Natural Language Processing (EMNLP-
2015), pages 2055–2061, Lisbon, Portugal. Associ-
ation for Computational Linguistics.

Koji Mineshima, Ribeka Tanaka, Pascual Mart´ınez-
G´omez, Yusuke Miyao, and Daisuke Bekki. 2016.
Building compositional semantics and higher-order
inference system for a wide-coverage Japanese CCG
In Proceedings of the 2016 Conference on
parser.
Empirical Methods in Natural Language Process-
ing, pages 2236–2242, Austin, Texas. Association
for Computational Linguistics.

Jeff Mitchell and Mirella Lapata. 2008. Vector-based
In Proceedings
models of semantic composition.
of the 46th Annual Meeting of the Association for
Computational Linguistics (ACL-08), pages 236–
244, Columbus, Ohio. Association for Computa-
tional Linguistics.

Jeff Mitchell and Mirella Lapata. 2010. Composition
in distributional models of semantics. Cognitive Sci-
ence, 34(8):1388–1429.

Jonas Mueller and Aditya Thyagarajan. 2016. Siamese
recurrent architectures for learning sentence similar-
In Proceedings of the 30th AAAI Conference
ity.
on Artiﬁcial Intelligence (AAAI-2016), pages 2786–
2792, Arizona, USA. Association for the Advance-
ment of Artiﬁcial Intelligence.

Terence Parsons. 1990. Events in The Semantics of En-
glish: a Study in Subatomic Semantics. MIT Press,
Cambridge, USA.

Determining Semantic Textual Similarity
using Natural Deduction Proofs

Hitomi Yanaka1
hitomiyanaka@g.ecc.u-tokyo.ac.jp

Koji Mineshima2
mineshima.koji@ocha.ac.jp

Pascual Mart´ınez-G´omez3
pascual.mg@aist.go.jp

Daisuke Bekki2
bekki@is.ocha.ac.jp

1The University of Tokyo
2Ochanomizu University
3Artiﬁcial Intelligence Research Center, AIST
Tokyo, Japan

Abstract

Determining semantic textual similarity is
a core research subject in natural language
processing. Since vector-based models for
sentence representation often use shallow
information, capturing accurate semantics
is difﬁcult. By contrast, logical seman-
tic representations capture deeper levels of
sentence semantics, but their symbolic na-
ture does not offer graded notions of tex-
tual similarity. We propose a method for
determining semantic textual similarity by
combining shallow features with features
extracted from natural deduction proofs of
bidirectional entailment relations between
sentence pairs. For the natural deduc-
tion proofs, we use ccg2lambda, a higher-
order automatic inference system, which
converts Combinatory Categorial Gram-
mar (CCG) derivation trees into semantic
representations and conducts natural de-
duction proofs. Experiments show that our
system was able to outperform other logic-
based systems and that features derived
from the proofs are effective for learning
textual similarity.

1

Introduction

Determining semantic textual similarity (STS) is
one of the most critical tasks in information re-
trieval and natural language processing. Vector-
based sentence representation models have been
widely used to compare and rank words, phrases
or sentences using various similarity and related-
ness scores (Wong and Raghavan, 1984; Mitchell
and Lapata, 2010; Le and Mikolov, 2014). Re-

cently, neural network-based sentence representa-
tion models (Mueller and Thyagarajan, 2016; Hill
et al., 2016) have been proposed for learning tex-
tual similarity. However, these vector-based mod-
els often use shallow information, such as words
and characters, and whether they can account for
phenomena such as negation and quantiﬁcation is
not clear. Consider the sentences: Tom did not
meet some of the players and Tom did not meet any
of the players. If functional words such as some or
any are ignored or represented as the same vec-
tor, then these sentences are to be represented by
identical vectors. However, the ﬁrst sentence im-
plies that there is a player who Tom did not meet,
whereas the second sentence means that Tom did
not meet anyone, so the sentences have different
meanings.

Conversely, logic-based approaches have been
successful in representing the meanings of com-
plex sentences, having had a positive impact for
applications such as recognizing textual entail-
ment (Mineshima et al., 2015, 2016; Abzian-
idze, 2015, 2016). However, purely logic-based
approaches only assess entailment or contradic-
tion relations between sentences and do not offer
graded notions of semantic similarity.

In this paper, we propose to leverage logic cues
to learn textual similarity. Our hypothesis is that
observing proof processes when testing the seman-
tic relations is predictive of textual similarity. We
show that our approach can be more effective than
systems that ignore these logic cues.

2 Related Work

Vector-based models of semantic composition
have been widely studied with regards to calcu-
lating STS. Mitchell and Lapata (2008, 2010)

7
1
0
2
 
l
u
J
 
7
2
 
 
]
L
C
.
s
c
[
 
 
1
v
3
1
7
8
0
.
7
0
7
1
:
v
i
X
r
a

proposed a sentence vector model involving word
vector addition or component-wise multiplication.
Addition and multiplication are commutative and
associative and thus ignore word order.
Polaj-
nar et al. (2015) proposed a discourse-based sen-
tence vector model considering extra-intra senten-
tial context. Also, a categorical compositional dis-
tributional semantic model has been developed for
recognizing textual entailment and for calculating
STS (Grefenstette and Sadrzadeh, 2011; Kartsak-
lis et al., 2014; Kartsaklis and Sadrzadeh, 2016).
However, these previous studies are mostly con-
cerned with the structures of basic phrases or sen-
tences and do not address logical and functional
words such as negations and connectives. Neu-
ral network-based models of semantic composi-
tion (Mueller and Thyagarajan, 2016; Hill et al.,
2016) have also been proposed. Although these
models achieve higher accuracy, their end-to-end
nature introduces challenges in the diagnosis of
the reasons that make two sentences to be similar
or dissimilar to each other. These diagnosis capa-
bilities may play an important role in making the
system explainable and also to guide future system
improvements in a more precise manner. Our ap-
proach presented in this paper is partially inspired
by the latter two objectives.

Meanwhile, some previous studies have pro-
posed logic systems for capturing the seman-
tic relatedness of sentences. The Meaning Fac-
tory (Bjerva et al., 2014) uses both shallow and
logic-based features for learning textual similarity.
In this system, the overlap of predicates and entail-
ment judgments are extracted as logic-based fea-
tures. UTexas (Beltagy et al., 2014b) uses Prob-
abilistic Soft Logic for learning textual similarity.
In this system, each ground atom in the logical for-
mulas has a probability based on distributional se-
mantics of a word. The weights of the logical for-
mulas are calculated from the probabilities of their
ground atoms and are extracted as features. These
previous studies improved the accuracy by using
logic-based features derived from the entailment
results of ﬁrst-order theorem proving in addition
to using shallow features such as sentence lengths.

In our study, we determine the semantic similar-
ity of sentences based on the conception of proof-
theoretic semantics (Bekki and Mineshima, 2017).
The key idea is that not only the entailment results
but also the theorem proving process can be con-
sidered as features for learning textual similarity.

That is, by taking into account not only whether a
theorem is proved but also how it is proved, we can
capture the semantic relationships between sen-
tence pairs in more depth.

Another difference between our study and pre-
vious logic systems is that we use higher-order
predicate logic. Higher-order predicate logic is
able to represent complex sentence semantics such
as generalized quantiﬁers more precisely than
ﬁrst-order predicate logic.
In addition, higher-
order predicate logic makes the logical structure
of a sentence more explicit than ﬁrst-order predi-
cate logic does, so it can simplify the process of
proof search (Miller and Nadathur, 1986).

3 System Overview

Figure 1 shows an overview of the system which
extracts features for learning textual similarity
from logical proofs. To produce semantic repre-
sentations of sentences and prove them automati-
cally, we use ccg2lambda (Mart´ınez-G´omez et al.,
2016), which is a semantic parser combined with
an inference system based on natural deduction.

First,

sentences are parsed into syntactic
trees based on Combinatory Categorial Grammar
(CCG) (Steedman, 2000). CCG is a syntactic the-
ory suitable for semantic composition from syn-
tactic structures. Meaning representations are ob-
tained based on semantic templates and combina-
tory rules for the CCG trees. Semantic templates
are deﬁned manually based on formal semantics.
Combinatory rules specify the syntactic behaviors
of words and compositional rules for the CCG
In ccg2lambda, two wide-coverage CCG
trees.
parsers, C&C (Clark and Curran, 2007) and Easy-
CCG (Lewis and Steedman, 2014), are used for
converting tokenized sentences into CCG trees ro-
bustly. According to a previous study (Mart´ınez-
G´omez et al., 2017), EasyCCG achieves higher ac-
curacy. Thus, when the output of both C&C and
EasyCCG can be proved, we use EasyCCG’s out-
put for creating features.

Second, the meanings of words are described
using lambda terms. Semantic representations are
obtained by combining lambda terms in accor-
dance with the meaning composition rules spec-
iﬁed in the CCG tree. The semantic representa-
tions are based on Neo-Davidsonian event seman-
tics (Parsons, 1990; Mineshima et al., 2015), in
which every verb is decomposed into a predicate
over events and a set of functional expressions re-

prove the bidirectional entailment relations, A(cid:48) ⇒
B(cid:48) and B(cid:48) ⇒ A(cid:48).
If the initial natural deduc-
tion proofs fail, we re-run the proof, adding rel-
evant external axioms or skipping unproved sub-
goals until the proof is completed. After that, fea-
tures for learning textual similarity are extracted
by quantifying the provability of the bidirectional
entailment relations.

The details of the procedure are as follows.
First, we attempt a natural deduction proof without
using external axioms, aiming to prove entailment
relations, A(cid:48) ⇒ B(cid:48) and B(cid:48) ⇒ A(cid:48). If both fail,
then we check whether A(cid:48) contradicts B(cid:48), which
amounts to proving the negation of the original
conclusion, namely A(cid:48) ⇒ ¬B(cid:48) and B(cid:48) ⇒ ¬A(cid:48).

The similarity of a sentence pair tends to be
higher when the negation of the conclusion can
be proved, compared with the case where nei-
ther the conclusion nor its negation can be proved.
In the SICK (Sentences Involving Compositional
Knowledge) dataset (Marelli et al., 2014) (see Sec-
tion 6.1 for details), 70% of the sentence pairs an-
notated as contradictory are assigned a relatedness
score in [3, 5).

Next, if we fail to prove entailment or contradic-
tion, that is, we cannot prove the conclusion or its
negation, we identify an unproved sub-goal which
is not matched by any predicate in the premise.
We then attempt to prove A(cid:48) ⇒ B(cid:48) and B(cid:48) ⇒ A(cid:48)
using axiom injection, following the method in-
troduced in Mart´ınez-G´omez et al. (2017). In ax-
iom injection, unproved sub-goals are candidates
to form axioms. We focus only on predicates that
share at least one argument with both the premise
and the conclusion. This means that an axiom can
be generated only if there is a predicate p in the
pool of premises and a predicate q in a sub-goal
and p and q share a variable in an argument posi-
tion, possibly with the same case (e.g., Subject or
Object).

In generating axioms,

the semantic relation-
ships between the predicates in the premise and
those in the conclusion are checked using lexical
knowledge. In this study, we use WordNet (Miller,
1995) as the source of lexical knowledge. Linguis-
tic relations between predicates are checked in the
following order: inﬂections, derivationally related
forms, synonyms, antonyms, hypernyms, similar-
ities, and hyponyms. If any one of these relations
is found in the lexical knowledge, an axiom can
be generated. Again, if the proof fails, we attempt

Figure 1: System overview.

lating the events. Adverbs and prepositions are
also represented as predicates over events.

Third, we attempt to prove entailment relations
between sentence pairs. For this purpose, we use
Coq (Bertot and Castran, 2010), which can be
used for efﬁcient theorem-proving for natural lan-
guage inference using both ﬁrst-order and higher-
order logic (Mineshima et al., 2015). Coq’s proof
calculus is based on natural deduction (Prawitz,
1965), a proof system based on inference rules
called introduction and elimination rules for log-
ical connectives. The inference system imple-
mented in ccg2lambda using Coq achieves efﬁ-
cient automatic inference by feeding a set of pre-
deﬁned tactics and user-deﬁned proof-search tac-
tics to its interactive mode. The natural deduc-
tion system is particularly suitable for injecting
external axioms during the theorem-proving pro-
cess (Mart´ınez-G´omez et al., 2017).

Finally, features for learning textual similar-
ity are extracted from the proofs produced by
ccg2lambda during the theorem-proving process.
In this study, we experimented with logistic re-
gression, support vector regression and random
forest regression, ﬁnding that random forest re-
gression was the most effective. We therefore
chose random forest regression for learning tex-
tual similarity, with its hyperparameters being op-
timized by grid search. The mean squared error
(MSE) was used to measure the prediction perfor-
mance of our system.

4 Proof Strategy for Learning Textual

Similarity

4.1 Overview of the proof strategy

Sentence similarity depends on complex elements,
such as word overlaps and semantic relations. We
capture the similarity between the sentence pair
(A, B) as a function of the provability of bidirec-
tional entailment relations for (A, B) and combine
it with shallow features. After obtaining logical
formulas A(cid:48) and B(cid:48) from A and B, we attempt to

G : A ∧ B

∧-INTRO

G1 : A
G2 : B

P : A1 ∧ A2 ∧ · · · ∧ An

P0 : ∃e1x1x2(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1)

∧ bar(x2) ∧ in(e1, x2))

∧-ELIM

G0 : ∃e1x1(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1))

P1 : A1, P2 : A2, . . . , Pn : An

∃-ELIM (P0), ∃-INTRO (G0)

G : A → B

→-INTRO

P : A
G : B

P1 : A → B
P2 : A

→-ELIM

P : B

G : ∃xA(x)

P : ∃xA(x)

∃-INTRO

∃-ELIM

P1 : A(t)
P2 : t = u

=-ELIM

G1 : A(x)

P1 : A(x)

P : A(u)

Figure 2: Example of the inference rules used in
natural deduction. P, P1, . . . Pn are formulas in
the premise, while G, G1, G2 are formulas in the
goal. The initial formulas are at the top, with the
formulas obtained by applying the inference rules
shown below.

to prove the negation of the conclusion using the
axiom injection mechanism.

If the proof by axiom injection fails because of
a lack of lexical knowledge, we obtain sentence
similarity information from partial proofs by sim-
ply accepting the unproved sub-goals and forcibly
completing the proof. After the proof is com-
pleted, information about the generated axioms
and skipped sub-goals is used to create features.

4.2 Proving entailment relations

As an illustration of how our natural deduction
proof works, consider the case of proving entail-
ment for the following sentence pair:
A: A man is singing in a bar.
B: A man is singing.

The sentences A and B are mapped onto logical
formulas A(cid:48) and B(cid:48) based on event semantics via
CCG-based semantic composition, as follows.

A(cid:48) : ∃e1x1x2(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1)

∧ bar(x2) ∧ in(e1, x2))

B(cid:48) : ∃e1x1(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1))

First, we attempt a natural deduction proof of
A(cid:48) ⇒ B(cid:48), setting A(cid:48) as the premise and B(cid:48) as the
goal of the proof. Then A(cid:48) and B(cid:48) are decomposed
according to the inference rules.

Figure 2 shows the major inference rules we use
in the proofs. Inference rules in natural deduction
are divided into two types: introduction rules and

P1 : man(x1) ∧ sing(e1) ∧ (subj(e1) = x1)

∧ bar(x2) ∧ in(e1, x2)

G1 : man(x1) ∧ sing(e1) ∧ (subj(e1) = x1)

∧-ELIM (P1), ∧-INTRO (G1)

P2 : man(x1), P3 : sing(e1), P4 : subj(e1) = x1,

P5 : bar(x2), P6 : in(e1, x2)

G2 : man(x1), G3 : sing(e1), G4 : subj(e1) = x1

Figure 3: The proof process for the example en-
tailment relation.

elimination rules. Introduction rules specify how
to prove a formula in the goal, decomposing a goal
formula into smaller sub-goals. Elimination rules
specify how to use a premise, decomposing a for-
mula in the pool of premises into smaller ones.

The proof process for A(cid:48) ⇒ B(cid:48) is shown in Fig-
ure 3. Here A(cid:48) is initially set to the premise P0 and
B(cid:48) to the goal G0. P0 and G0 are then decomposed
using elimination rules (∧-ELIM, ∃-ELIM) and intro-
duction rules (∧-INTRO, ∃-INTRO). Then we obtain a
set of premise formulas P = {P2, P3, P4, P5, P6},
and a set of sub-goals G = {G2, G3, G4}. The
proof is performed by searching for a premise Pi
whose predicate and arguments match those of a
given sub-goal Gj.
If such a logical premise is
found, the sub-goal is removed. In this example,
the sub-goals G2, G3, and G4 match the premises
P2, P3, and P4, respectively. Thus, A(cid:48) ⇒ B(cid:48) can
be proved without introducing axioms.

Second, we attempt the proof in the opposite
direction, B(cid:48) ⇒ A(cid:48), by switching P0 and G0 in
Figure 3. Again, by applying inference rules, we
obtain the following sets of premises P and sub-
goals G:

P = {P2 : man(x1), P3 : sing(e1),

P4 : subj(e1) = x1}

G = {G2 : man(x1), G3 : sing(e1),

G4 : subj(e1) = x1,
G5 : bar(x2), G6 : in(e1, x2))}

Here, the two sub-goals G5 and G6 do not match
any of the premises, so the attempted proof of
B(cid:48) ⇒ A(cid:48) fails. We therefore attempt to inject
additional axioms, but in this case no predicate
in P shares the argument x2 of the predicates
bar(x2) and in(e1, x2) in G. Thus, no axiom can
be generated. To obtain information from a partial
proof, we forcibly complete the proof of B(cid:48) ⇒ A(cid:48)
by skipping the unproved sub-goals bar(x) and

in(e1, x2).

4.3 Proving the contradiction

The proof strategy illustrated here can be straight-
forwardly applied to proving the contradiction. In
natural deduction, a negative formula of the form
¬A can be deﬁned as A → False (“the formula
A implies the contradiction”), by using a proposi-
tional constant False to encode the contradiction.
Thus, the inference rules for negation can be taken
as special cases of implication rules, as shown in
Figure 4.

As an illustration, let us consider the following

sentence pair:

A: No man is singing.
B: There is a man singing loudly.

Figure 5 shows the proof process. The sentences
A and B are mapped to P0 and P1, respectively,
via compositional semantics and the goal G0 is set
to False. By decomposing P1 using elimination
rules and then by combining P2, P3, and P4, we
can obtain P6. From P0 and P6 we can then derive
the contradiction.

These proofs are performed by an automated
prover implemented on Coq, using tactics for ﬁrst-
order theorem proving. When a proof is success-
ful, Coq outputs the resulting proof (a proof term),
from which we can extract detailed information
such as the number of proof steps and the types
of inference rules used. In addition to the entail-
ment/contradiction result, information about the
proof process is used to create features.

5 Description of the Features

To maximize accuracy when learning textual sim-
ilarity, we adopt a hybrid approach that uses both
logic-based features extracted from the natural de-
duction proof and other, non-logic-based features.
All features are scaled to the [0, 1] range.

5.1 Logic-based Features

We propose 15 features consisting of nine different
types of logic-based features. Six of these feature
types are derived from the bidirectional natural de-
duction proofs: six features are extracted from the
direct proof (A(cid:48) ⇒ B(cid:48)) and another six from the
reverse proof (B(cid:48) ⇒ A(cid:48)). The remaining three
feature types are derived from semantic represen-
tations of the sentence pairs. The feature types are
as follows.

G : ¬A

¬-INTRO

P : A
G : False

P1 : ¬A
P2 : A

¬-ELIM

P : False

Figure 4: Inference rules of negation.

P0 : ¬∃e1∃x1(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1))
P1 : ∃e1∃x1(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1)

∧ loudly(e1))

G0 : False

∃-ELIM, ∧-ELIM (P2)

P2 : man(x1), P3 : sing(e1), P4 : subj(e1) = x1,
P5 : loudly(e1)

∃-INTRO, ∧-INTRO (P2)

P6 : ∃e1∃x1(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1))

Figure 5: Proof process for the contradiction ex-
ample.

Logical inference result. As stated in Section 4,
we include features to distinguish the case where
either the conclusion or its negation can be proved
from the one where neither can be proved. If the
conclusion can be proved, the feature is set to 1.0.
If the negation of the conclusion can be proved,
the feature is set to 0.5. If neither can be proved,
the feature is set to 0.0.
Axiom probabilities. The probability of an ax-
iom and the number of axioms appearing in the
proof are used to create features. The probability
of an axiom is deﬁned as the inverse of the length
of the shortest path that connects the senses in the
is-a (hypernym/hyponym) taxonomy in WordNet.
When multiple axioms are used in the proof, the
average of the probabilities of the axioms is ex-
tracted as a feature. If the proof can be completed
without using axioms, the feature is set to 1.0.
Proved sub-goals. Given that proofs can be ob-
tained either by proving all the sub-goals or skip-
ping unproved sub-goals, we use the proportion of
proved sub-goals as a feature. Our assumption is
that if there are more unproved sub-goals then the
sentence pair is less similar. When there are m
logical formulas in the premise pool and n proved
sub-goals, we set the feature to n/m. If the theo-
rem can be proved without skipping any sub-goals,
the feature is set to 1.0. It may be the case that
the number of sub-goals is so large that some sub-
goals remain unproved even after axiom injection.

Since the proportion of unproved sub-goals is de-
creased by axiom injection, we use the proportion
of unproved sub-goals both with and without ax-
iom injection as features.
Cases in unproved sub-goals. Subject or object
words can affect the similarity of sentence pairs.
Therefore, the number of each case in unproved
sub-goals, like subj(e1) in Figures 3 and 5, is
used as a feature. Here, we count subjective, ob-
jective, and dative cases.
Proof steps. In general, complex theorems are dif-
ﬁcult to prove and in such cases the sentence pairs
are considered to be less similar. We therefore use
the number of Coq’s proof steps, namely the num-
ber of inference rule applications in a given proof,
as a feature.
Inference rules. The complexity of a natural de-
duction proof can be measured in terms of the in-
ference rules used for each proof step. We there-
fore extract the relative frequency with which each
inference rule is used in the proof as a feature. We
check seven inference rules for natural deduction
using Coq (cf. Figure 2): introduction and elimi-
nation rules for conjunction (∧-INTRO, ∧-ELIM), im-
plication (→-INTRO, →-ELIM), and existential quan-
tiﬁcation (∃-INTRO, ∃-ELIM), and the elimination
rule for equality (=-ELIM).
Predicate overlap.
Intuitively, the more predi-
cates overlap between the premise and the conclu-
sion, the more likely it is that the inference can be
proved. We therefore use the proportion of pred-
icates that overlap between the premise and the
conclusion as a feature.
Semantic type overlap. Each semantic represen-
tation in higher-order logic has a semantic type,
such as Entity for entities and Prop for proposi-
tions. As with predicates, we use the degree of se-
mantic type overlap between the premise and the
conclusion as a feature.
Existence of negative clauses. Whether or not the
premise or conclusion contain negative clauses is
an effective measure of similarity. In semantic rep-
resentations, negative clauses are represented by
the negation operator ¬, so we check for negation
operators in the premise and the conclusion and
set this feature to 1.0 if either contains one.

5.2 Non-logic-based Features

nouns and verbs from the sentence pairs and use
the degrees of overlap of the noun and verb lem-
mas as features.
Part-of-speech overlap. We obtain part-of-
speech (POS) tags for all words in the sentence
pairs by ﬁrst tokenizing them with the Penn Tree-
bank Project tokenizer1 and then POS tagging
them with C&C POS tagger (Curran and Clark,
2003). The degree of overlap between the sen-
tences’ POS tags is used as a feature.
Synset overlap. For each sentence in the pair, we
obtain the set containing all the synonym lemmas
(the synset) for the words in the sentence. The
degree of overlap between the sentences’ synsets
is used as a feature.
Synset distance. For each word in the ﬁrst sen-
tence, we compute the maximum path similarity
between its synset and the synset of any other
word in the second sentence. Then, we use the
average of maximum path similarities as a feature.
Sentence length.
If the conclusion sentence is
long, there will possibly be many sub-goals in the
proof. We therefore use the average of the sen-
tence lengths and the difference in length between
the premise and the conclusion sentences as fea-
tures.
String similarity. We use the similarity of the se-
quence of characters within the sentence pairs as a
feature. The Python Difﬂib2 function returns the
similarity between two sequences as a ﬂoating-
point value in [0, 1]. This measure is given by
2.0 ∗ M/T , where T is the total number of ele-
ments in both sequences and M is the number of
matches. This feature is 1.0 if the sequences are
identical and 0.0 if they have nothing in common.
Sentence similarity from vector space models.
We calculate sentence similarity by using three
major vector space models, TF-IDF, latent se-
mantic analysis (LSA) (Deerwester et al., 1990),
and latent Dirichlet allocation (LDA) (Blei et al.,
2003). We use these cosine similarities as features.
Existence of passive clauses. Passive clauses
have an inﬂuence on similarity.
In CCG trees,
passive clauses are represented using the syntactic
category Spss\N P . We check for the occurrence
of passive clauses in the premise and conclusion,
and if either of them contains a passive clause then
the feature is set to 1.0.

We also use the following eight non-logic-based
features.
Noun/verb overlap. We extract and lemmatize all

1ftp://ftp.cis.upenn.edu/pub/treebank/public html/

tokenization.html

2https://docs.python.org/3.5/library/difﬂib.html

ID
23
1412
9963

Sentence1

Sentence2

Entailment Score

There is no biker jumping in the air. A lone biker is jumping in the air

Men are sawing logs.
The animal is grazing on the grass.

Men are cutting wood.
The cop is sitting on a police bike.

no
yes
unknown

4.2
4.5
1

Table 1: Examples in the SICK dataset with different entailment labels and similarity scores.

Mueller et al. (2016)
Our system
SemEval2014 Best Score
The Meaning Factory
UTexas
Baseline

γ
0.882
0.838
0.828
0.827
0.714
0.653

ρ
0.835
0.796
0.769
0.772
0.674
0.745

MSE
0.229
0.561
0.325
0.322
0.499
0.808

Table 2: Results on the test split of SICK dataset.

6 Experiments and Evaluation

SemEval-2014

6.1 Experimental Conditions
We evaluated our system3 using two datasets:
SICK
the
dataset (Marelli et al., 2014) and the SemEval-
2012 version of the MSR-paraphrase video corpus
dataset (MSR-vid) (Agirre et al., 2012). The
experimental conditions were as follows.

version

the

of

6.1.1 The SICK dataset

The SICK dataset is a dataset for studying STS as
well as for recognizing textual entailment (RTE).
It was originally developed for evaluating com-
positional distributional semantics, so it contains
logically challenging expressions such as quan-
tiﬁers, negations, conjunctions and disjunctions.
The dataset contains 9927 sentence pairs with a
5000/4927 training/test split. These sentence pairs
are manually annotated with three types of labels
yes (entailment), no (contradiction), or unknown
(neutral) as well as a semantic relatedness scores
in [1, 5] (see Table 1 for a sample).

In this dataset, sentence pairs whose gold entail-
ment labels are no tend to be scored a little more
highly than the average, whereas those whose la-
bels are unknown have a wide range of scores.
Thus, we set the baseline of the relatedness score
to 5 when the gold entailment label was yes and to
3 when the label was no or unknown.

We compared our system with the following
systems: the state-of-the-art neural network-based
system (Mueller and Thyagarajan, 2016); the best
system (Zhao et al., 2014) from SemEval-2014;
and two of the logic-based systems stated in Sec-

tion 2: namely The Meaning Factory (Bjerva et al.,
2014) and UTexas (Beltagy et al., 2014b). The
Pearson correlation coefﬁcient γ, Spearman’s rank
correlation coefﬁcient ρ, and the MSE were used
as the evaluation metrics.

6.1.2 The MSR-vid dataset

The MSR-vid dataset is our second dataset for the
STS task and contains 1500 sentence pairs with
a 750/750 training/test split. All sentence pairs
are annotated with semantic relatedness scores in
the range [0, 5]. We used this dataset to compare
our system with the best system from SemEval-
2012 (B¨ar et al., 2012) and the logic-based UTexas
system (Beltagy et al., 2014a). We used the Pear-
son correlation coefﬁcient γ as the evaluation met-
ric.

6.2 Results

Table 2 shows the results of our experiments with
the SICK dataset. Although the state-of-the-art
neural network-based system yielded the best re-
sults overall, our system achieved higher scores
including the
than SemEval-2014 submissions,
two logic-based systems (The Meaning Factory
and UTexas), in terms of Pearson correlation and
Spearman’s correlation.

The main reason for our system’s lower per-
formance in terms of MSE is that some theorems
could not be proved because of a lack of lexical
knowledge. In the current work, we only consider
word-level knowledge (word-for-word paraphras-
ing); we may expand the knowledge base in the
future by using more external resources.

As we mentioned above, the sentence pairs an-
notated as unknown produced a wide range of
scores. The Pearson correlation of the unknown
portion of the SICK dataset was 0.766, which sug-
gests that our logic-based system can also be ap-
plied to neutral sentence pairs.

Table 3 shows the results of our experiments
with the MSR-vid dataset. These results also in-
dicate that our logic-based system achieved higher
accuracy than the other logic-based systems.

3Available at https://github.com/mynlp/ccg2lambda.

Table 4 shows evaluation results for each feature

SemEval2012 Best Score
Our system
Beltagy et al. (2014)

γ
0.873
0.853
0.830

Table 3: Results on the test split of MSR-vid.

Predicate overlap
Inference rules
Probability of axioms
Proof steps
Proved sub-goals
Logical inference result
Unproved sub-goals’ case
Semantic type overlap
Negative clauses
Noun/verb overlap
Vector space model
String similarity
Synset overlap
Synset distance
Part-of-speech overlap
Sentence length
Passive clauses
Only logic-based
Only non logic-based
All

ρ
γ
MSE
0.734
0.609
0.691
0.794
0.619
0.632
0.865
0.540
0.543
0.915
0.494
0.458
0.926
0.443
0.432
0.939
0.399
0.386
0.973
0.307
0.301
0.987
0.219
0.245
1.004
0.323
0.163
0.763
0.554
0.661
0.857
0.510
0.594
0.977
0.418
0.414
0.978
0.341
0.382
0.999
0.330
0.352
0.954
0.346
0.349
0.993
0.240
0.231
1.017
0.046
0.023
0.613
0.760
0.798
0.793
0.621
0.732
0.838 0.796 0.561

Table 4: Results when training our regressor with
each feature group in isolation.

group in isolation, showing that inference rules
and predicate overlaps are the most effective fea-
tures. Compared with the non-logic-based fea-
tures, the logic-based features achieved a slightly
higher accuracy, a point that will be analyzed in
more detail in the next section. Overall, our re-
sults show that combining logic-based features
with non logic-based ones is an effective method
for determining textual similarity.

6.3 Positive examples and error analysis

Table 5 shows some examples for which the pre-
diction score was better when using logic-based
features than when using non-logic-based ones.

For IDs 642 and 1360, one sentence contains a
passive clause while the other sentence does not.
In such cases, the sentence pairs are not superﬁ-
cially similar. By using logical formulas based on
event semantics we were able to interpret the sen-
tence containing the passive clause correctly and
judge that the passive and non-passive sentences

are similar to each other.

In ID 891, one sentence contains a negative
clause while the other does not. Using shallow
features, the word overlap is small and the predic-
tion score was much lower than the correct score.
Our logic-based method, however, interpreted the
ﬁrst sentence as a negative existential formula of
the form ¬∃xP(x) and the second sentence as an
existential formula ∃xP (cid:48)(x). Thus, it could easily
handle the semantic difference between the posi-
tive and negative sentences.

In ID 1158, by contrast, the proportion of word
overlap is so high that the prediction score with
non-logic-based features was much higher than
the correct score. Our method, however, was able
to prove the contradiction using an antonym axiom
of the form ∀x(remove(x) → ¬add(x)) from
WordNet and thus predict the score correctly.

In ID 59, the proportion of word overlap is
low, so the prediction score with non-logic-based
features was lower than the correct score. Our
method, however, was able to prove the partial en-
tailment relations for the sentence pair and thus
predict the score correctly. Here the logic-based
method captured the common meaning of the sen-
tence pair: both sentences talk about the kids play-
ing in the leaves.

Finally, in ID 71, the prediction score with non-
logic-based features was much higher than the cor-
rect score. There are two reasons for this phe-
nomenon: negations tend to be omitted in non-
logic-based features such as TF-IDF and the pro-
portion of word overlap is high. However, as
logical formulas and proofs can handle negative
clauses correctly, our method was able to predict
the score correctly.

Table 6 shows examples where using only logic-
based features produced erroneous results. In ID
3974, the probability of axiom ∀x(awaken(x) →
up(x)) was low (0.25) and thus the prediction
score was lower than the correct score. Likewise,
in ID 4833, the probability of axiom ∀x(ﬁle(x) →
do(x)) was very low (0.09) and thus the pre-
diction score was negatively affected.
In these
cases, we need to consider phrase-level axioms
such as ∀x(awaken(x) → wake up(x)) and
∀x(ﬁle nail(x) → do manicure(x)) using a
paraphrase database. This, however, is an issue
for future study. In ID 1941, the system wrongly
proved the bidirectional entailment relations by
adding external axioms, so the prediction score

Gold

Pred
+logic

Pred
-logic

Entailment

ID Sentence Pair

642

1360

891

1158

59

71

A person is climbing a rock with a rope, which is pink.
A rock is being climbed by a person with a rope, which is pink.
The machine is shaving the end of a pencil.
A pencil is being shaved by the machine.
There is no one on the shore.
A bunch of people is on the shore.
A woman is removing ingredients from a bowl.
A woman is adding ingredients to a bowl.
Kids in red shirts are playing in the leaves.
Three kids are jumping in the leaves.
There is no child lying in the snow and making snow angels.
Two people in snowsuits are lying in the snow and making snow angels.

5.0

4.7

3.6

3.3

3.9

3.3

4.9

4.6

3.7

3.5

3.8

3.3

4.1

3.8

2.6

4.1

3.1

4.1

Yes

Yes

No

No

Unknown

Unknown

Table 5: Examples for which our regressor trained only with logic-based features performs better than
when using non-logic features. “Gold”: correct score, “Pred+logic”: prediction score only with logic-
based features, “Pred-logic”: prediction score only with non-logic-based features.

ID Sentence Pair

Gold

System Axiom

A girl is awakening.
A girl is waking up.
A girl is ﬁling her nails.
A girl is doing a manicure.

3974

4833

1941

A woman is putting the baby into a trash can.
A person is putting meat into a skillet.

4.9

4.2

1.0

3.6

1.8

3.3

∀x(awaken(x) → wake(x))
∀x(awaken(x) → up(x))
∀x(nail(x) → manicure(x))
∀x(ﬁle(x) → do(x))
∀x(woman(x) → person(x))
∀x(trash(x) → skillet(x))
∀x(baby(x) → meat(x))

Table 6: Error examples when training the regressor only with logic-based features.

was much higher than the correct score. Set-
ting the threshold for the probability of an axiom
may be an effective way of improving our axiom-
injection method.

7 Conclusion

We have developed a hybrid method for learn-
ing textual similarity by combining features based
on logical proofs of bidirectional entailment rela-
tions with non-logic-based features. The results
of our experiments on two datasets show that our
system was able to outperform other logic-based
systems. In addition, the results show that infor-
mation about the natural deduction proof process
can be used to create effective features for learning
textual similarity. Since these logic-based features
provide accuracy improvements that are largely
additive with those provided by non-logic-based
features, neural network-based systems may also
beneﬁt from using them.

In future work, we will reﬁne our system so
that it can be applied to other tasks such as ques-
tion answering. Compared with neural network-
based systems, our natural deduction-based sys-
tem can not only assess how similar sentence pairs
are, but also explain what the sources of simi-

larity/dissimilarity are by referring to information
about sub-goals in the proof. Given this interpreta-
tive ability, we believe that our logic-based system
may also be of beneﬁt to other natural language
processing tasks, such as question answering and
text summarization.

Acknowledgments

We thank the three anonymous reviewers for their
detailed comments. This work was supported by
JST CREST Grant Number JPMJCR1301, Japan.

References

Lasha Abzianidze. 2015. A tableau prover for natural
logic and language. In Proceedings of the 2015 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP-15), pages 2492–2502, Lisbon,
Portugal. Association for Computational Linguis-
tics.

Lasha Abzianidze. 2016. Natural solution to FraCaS
entailment problems. In Proceedings of the 5th Joint
Conference on Lexical and Computational Seman-
tics, pages 64–74, Berlin, Germany. Association for
Computational Linguistics.

Eneko Agirre, Daniel Cer, Mona Diab, and Aitor
Gonzalez-Agirre. 2012. SemEval-2012 Task 6: A

pilot on semantic textual similarity. In Proceedings
of the 6th International Workshop on Semantic Eval-
uation (SemEval-2012), pages 385–393, Montr´eal,
Canada. Association for Computational Linguistics.

Daniel B¨ar, Chris Biemann,

Iryna Gurevych, and
Torsten Zesch. 2012. UKP: Computing seman-
tic textual similarity by combining multiple con-
In Proceedings of the
tent similarity measures.
Sixth International Workshop on Semantic Evalu-
ation (SemEval-2012), pages 435–440, Montr´eal,
Canada. Association for Computational Linguistics.

Daisuke Bekki and Koji Mineshima. 2017. Context-
passing and underspeciﬁcation in dependent type se-
mantics. In Stergios Chatzikyriakidis and Zhaohui
Luo, editors, Modern Perspectives in Type Theoret-
ical Semantics, Studies of Linguistics and Philoso-
phy, pages 11–41. Springer.

Islam Beltagy, Katrin Erk, and Raymond Mooney.
2014a. Probabilistic soft logic for semantic tex-
tual similarity. In Proceedings of the 52nd Annual
Meeting of the Association for Computational Lin-
guistics (ACL-2014), pages 1210–1219, Baltimore,
Maryland. Association for Computational Linguis-
tics.

Islam Beltagy, Stephen Roller, Gemma Boleda, Ka-
trin Erk, and Raymond Mooney. 2014b. UTexas:
Natural language semantics using distributional se-
In Proceedings of
mantics and probabilistic logic.
the 8th International Workshop on Semantic Evalu-
ation (SemEval-2014), pages 796–801, Dublin, Ire-
land. Association for Computational Linguistics and
Dublin City University.

Yves Bertot and Pierre Castran. 2010.

Interac-
tive Theorem Proving and Program Development:
Coq’Art The Calculus of Inductive Constructions.
Springer Publishing Company, Incorporated, New
York, USA.

Johannes Bjerva, Johan Bos, Rob van der Goot, and
Malvina Nissim. 2014. The Meaning Factory: For-
mal semantics for recognizing textual entailment
and determining semantic similarity. In Proceedings
of the 8th International Workshop on Semantic Eval-
uation (SemEval-2014), pages 642–646, Dublin, Ire-
land. Association for Computational Linguistics and
Dublin City University.

David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet allocation. Journal of Ma-
chine Learning, 3:993–1022.

Stephen Clark and James R. Curran. 2007. Wide-
coverage efﬁcient statistical parsing with CCG
and log-linear models. Computational Linguistics,
33(4):493–552.

James R Curran and Stephen Clark. 2003. Investigat-
ing GIS and smoothing for maximum entropy tag-
gers. In Proceedings of the tenth conference on Eu-
ropean chapter of the Association for Computational

Linguistics-Volume 1, pages 91–98. Association for
Computational Linguistics.

Scott Deerwester, Susan T. Dumais, Thomas K. Lan-
dauer, and Richard Harshman. 1990.
Indexing by
latent semantic analysis. Journal of the American
Society for Information Science, 41(6):391–407.

Edward Grefenstette and Mehrnoosh Sadrzadeh. 2011.
Experimental support for a categorical composi-
tional distributional model of meaning. In Proceed-
ings of the 2011 Conference on Empirical Methods
in Natural Language Processing (EMNLP-2011),
pages 1394–1404, Edinburgh, Scotland, UK. Asso-
ciation for Computational Linguistics.

Felix Hill, Kyunghyun Cho, and Anna Korhonen.
2016. Learning distributed representations of sen-
tences from unlabelled data. In Proceedings of the
2016 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 1367–1377, San
Diego, California. Association for Computational
Linguistics.

Dimitri Kartsaklis, Nal Kalchbrenner, and Mehrnoosh
Sadrzadeh. 2014. Resolving lexical ambiguity in
In Proceed-
tensor regression models of meaning.
ings of the 52nd Annual Meeting of the Associ-
ation for Computational Linguistics (ACL-2014),
pages 212–217, Baltimore, Maryland. Association
for Computational Linguistics.

Dimitri Kartsaklis and Mehrnoosh Sadrzadeh. 2016.
Distributional inclusion hypothesis for tensor-based
In Proceedings of the 26th Inter-
composition.
national Conference on Computational Linguistics:
Technical Papers (COLING-2016), pages 2849–
2860, Osaka, Japan. The COLING 2016 Organizing
Committee.

Quoc V. Le and Tomas Mikolov. 2014. Distributed
representations of sentences and documents.
In
Proceedings of the 31th International Conference
on Machine Learning, (ICML-2014), pages 1188–
1196, Beijing, China.

Mike Lewis and Mark Steedman. 2014. A* CCG pars-
In Proceed-
ing with a supertag-factored model.
ings of the 2014 Conference on Empirical Methods
in Natural Language Processing (EMNLP-2014),
pages 990–1000, Doha, Qatar. Association for Com-
putational Linguistics.

Marco Marelli, Stefano Menini, Marco Baroni, Luisa
Bentivogli, Raffaella Bernardi, and Roberto Zam-
parelli. 2014. A SICK cure for the evaluation of
In
compositional distributional semantic models.
Proceedings of the 9th International Conference on
Language Resources and Evaluation (LREC-2014),
pages 216–223, Reykjavik, Iceland. European Lan-
guage Resources Association.

Pascual Mart´ınez-G´omez, Koji Mineshima, Yusuke
Miyao, and Daisuke Bekki. 2016. ccg2lambda: A

Tamara Polajnar, Laura Rimell, and Stephen Clark.
2015. An exploration of discourse-based sentence
spaces for compositional distributional semantics.
In Proceedings of the 1st Workshop on Linking
Computational Models of Lexical, Sentential and
Discourse-level Semantics, pages 1–11, Lisbon, Por-
tugal. Association for Computational Linguistics.

Dag Prawitz. 1965. Natural Deduction – A Proof-
Theoretical Study. Almqvist & Wiksell, Stockholm,
Sweden.

Mark Steedman. 2000. The Syntactic Process. MIT

Press, Cambridge, USA.

S. K. M. Wong and Vijay V. Raghavan. 1984. Vector
space model of information retrieval: A reevalua-
tion. In Proceedings of the 7th Annual International
ACM SIGIR Conference on Research and Develop-
ment in Information Retrieval, pages 167–185.

Jiang Zhao, Tiantian Zhu, and Man Lan. 2014. ECNU:
One stone two birds: Ensemble of heterogenous
measures for semantic relatedness and textual en-
In Proceedings of the 8th International
tailment.
Workshop on Semantic Evaluation (SemEval-2014),
pages 271–277, Dublin, Ireland. Association for
Computational Linguistics and Dublin City Univer-
sity.

In Proceedings
compositional semantics system.
of ACL-2016 System Demonstrations, pages 85–
90, Berlin, Germany. Association for Computational
Linguistics.

Pascual Mart´ınez-G´omez, Koji Mineshima, Yusuke
Miyao, and Daisuke Bekki. 2017. On-demand injec-
tion of lexical knowledge for recognising textual en-
tailment. In Proceedings of the 15th Conference of
the European Chapter of the Association for Compu-
tational Linguistics (EACL-2017), pages 710–720,
Valencia, Spain. Association for Computational Lin-
guistics.

Dale A. Miller and Gopalan Nadathur. 1986. Some
uses of higher-order logic in computational linguis-
In Proceedings of the 24th Annual Meeting
tics.
of the Association for Computational Linguistics,
pages 247–256, New York, New York, USA. Asso-
ciation for Computational Linguistics.

George A. Miller. 1995. WordNet: A lexical
database for English. Communications of the ACM,
38(11):39–41.

Koji Mineshima, Pascual Mart´ınez-G´omez, Yusuke
Miyao, and Daisuke Bekki. 2015. Higher-order
logical inference with compositional semantics. In
Proceedings of the 2015 Conference on Empirical
Methods in Natural Language Processing (EMNLP-
2015), pages 2055–2061, Lisbon, Portugal. Associ-
ation for Computational Linguistics.

Koji Mineshima, Ribeka Tanaka, Pascual Mart´ınez-
G´omez, Yusuke Miyao, and Daisuke Bekki. 2016.
Building compositional semantics and higher-order
inference system for a wide-coverage Japanese CCG
In Proceedings of the 2016 Conference on
parser.
Empirical Methods in Natural Language Process-
ing, pages 2236–2242, Austin, Texas. Association
for Computational Linguistics.

Jeff Mitchell and Mirella Lapata. 2008. Vector-based
In Proceedings
models of semantic composition.
of the 46th Annual Meeting of the Association for
Computational Linguistics (ACL-08), pages 236–
244, Columbus, Ohio. Association for Computa-
tional Linguistics.

Jeff Mitchell and Mirella Lapata. 2010. Composition
in distributional models of semantics. Cognitive Sci-
ence, 34(8):1388–1429.

Jonas Mueller and Aditya Thyagarajan. 2016. Siamese
recurrent architectures for learning sentence similar-
In Proceedings of the 30th AAAI Conference
ity.
on Artiﬁcial Intelligence (AAAI-2016), pages 2786–
2792, Arizona, USA. Association for the Advance-
ment of Artiﬁcial Intelligence.

Terence Parsons. 1990. Events in The Semantics of En-
glish: a Study in Subatomic Semantics. MIT Press,
Cambridge, USA.

Determining Semantic Textual Similarity
using Natural Deduction Proofs

Hitomi Yanaka1
hitomiyanaka@g.ecc.u-tokyo.ac.jp

Koji Mineshima2
mineshima.koji@ocha.ac.jp

Pascual Mart´ınez-G´omez3
pascual.mg@aist.go.jp

Daisuke Bekki2
bekki@is.ocha.ac.jp

1The University of Tokyo
2Ochanomizu University
3Artiﬁcial Intelligence Research Center, AIST
Tokyo, Japan

Abstract

Determining semantic textual similarity is
a core research subject in natural language
processing. Since vector-based models for
sentence representation often use shallow
information, capturing accurate semantics
is difﬁcult. By contrast, logical seman-
tic representations capture deeper levels of
sentence semantics, but their symbolic na-
ture does not offer graded notions of tex-
tual similarity. We propose a method for
determining semantic textual similarity by
combining shallow features with features
extracted from natural deduction proofs of
bidirectional entailment relations between
sentence pairs. For the natural deduc-
tion proofs, we use ccg2lambda, a higher-
order automatic inference system, which
converts Combinatory Categorial Gram-
mar (CCG) derivation trees into semantic
representations and conducts natural de-
duction proofs. Experiments show that our
system was able to outperform other logic-
based systems and that features derived
from the proofs are effective for learning
textual similarity.

1

Introduction

Determining semantic textual similarity (STS) is
one of the most critical tasks in information re-
trieval and natural language processing. Vector-
based sentence representation models have been
widely used to compare and rank words, phrases
or sentences using various similarity and related-
ness scores (Wong and Raghavan, 1984; Mitchell
and Lapata, 2010; Le and Mikolov, 2014). Re-

cently, neural network-based sentence representa-
tion models (Mueller and Thyagarajan, 2016; Hill
et al., 2016) have been proposed for learning tex-
tual similarity. However, these vector-based mod-
els often use shallow information, such as words
and characters, and whether they can account for
phenomena such as negation and quantiﬁcation is
not clear. Consider the sentences: Tom did not
meet some of the players and Tom did not meet any
of the players. If functional words such as some or
any are ignored or represented as the same vec-
tor, then these sentences are to be represented by
identical vectors. However, the ﬁrst sentence im-
plies that there is a player who Tom did not meet,
whereas the second sentence means that Tom did
not meet anyone, so the sentences have different
meanings.

Conversely, logic-based approaches have been
successful in representing the meanings of com-
plex sentences, having had a positive impact for
applications such as recognizing textual entail-
ment (Mineshima et al., 2015, 2016; Abzian-
idze, 2015, 2016). However, purely logic-based
approaches only assess entailment or contradic-
tion relations between sentences and do not offer
graded notions of semantic similarity.

In this paper, we propose to leverage logic cues
to learn textual similarity. Our hypothesis is that
observing proof processes when testing the seman-
tic relations is predictive of textual similarity. We
show that our approach can be more effective than
systems that ignore these logic cues.

2 Related Work

Vector-based models of semantic composition
have been widely studied with regards to calcu-
lating STS. Mitchell and Lapata (2008, 2010)

7
1
0
2
 
l
u
J
 
7
2
 
 
]
L
C
.
s
c
[
 
 
1
v
3
1
7
8
0
.
7
0
7
1
:
v
i
X
r
a

proposed a sentence vector model involving word
vector addition or component-wise multiplication.
Addition and multiplication are commutative and
associative and thus ignore word order.
Polaj-
nar et al. (2015) proposed a discourse-based sen-
tence vector model considering extra-intra senten-
tial context. Also, a categorical compositional dis-
tributional semantic model has been developed for
recognizing textual entailment and for calculating
STS (Grefenstette and Sadrzadeh, 2011; Kartsak-
lis et al., 2014; Kartsaklis and Sadrzadeh, 2016).
However, these previous studies are mostly con-
cerned with the structures of basic phrases or sen-
tences and do not address logical and functional
words such as negations and connectives. Neu-
ral network-based models of semantic composi-
tion (Mueller and Thyagarajan, 2016; Hill et al.,
2016) have also been proposed. Although these
models achieve higher accuracy, their end-to-end
nature introduces challenges in the diagnosis of
the reasons that make two sentences to be similar
or dissimilar to each other. These diagnosis capa-
bilities may play an important role in making the
system explainable and also to guide future system
improvements in a more precise manner. Our ap-
proach presented in this paper is partially inspired
by the latter two objectives.

Meanwhile, some previous studies have pro-
posed logic systems for capturing the seman-
tic relatedness of sentences. The Meaning Fac-
tory (Bjerva et al., 2014) uses both shallow and
logic-based features for learning textual similarity.
In this system, the overlap of predicates and entail-
ment judgments are extracted as logic-based fea-
tures. UTexas (Beltagy et al., 2014b) uses Prob-
abilistic Soft Logic for learning textual similarity.
In this system, each ground atom in the logical for-
mulas has a probability based on distributional se-
mantics of a word. The weights of the logical for-
mulas are calculated from the probabilities of their
ground atoms and are extracted as features. These
previous studies improved the accuracy by using
logic-based features derived from the entailment
results of ﬁrst-order theorem proving in addition
to using shallow features such as sentence lengths.

In our study, we determine the semantic similar-
ity of sentences based on the conception of proof-
theoretic semantics (Bekki and Mineshima, 2017).
The key idea is that not only the entailment results
but also the theorem proving process can be con-
sidered as features for learning textual similarity.

That is, by taking into account not only whether a
theorem is proved but also how it is proved, we can
capture the semantic relationships between sen-
tence pairs in more depth.

Another difference between our study and pre-
vious logic systems is that we use higher-order
predicate logic. Higher-order predicate logic is
able to represent complex sentence semantics such
as generalized quantiﬁers more precisely than
ﬁrst-order predicate logic.
In addition, higher-
order predicate logic makes the logical structure
of a sentence more explicit than ﬁrst-order predi-
cate logic does, so it can simplify the process of
proof search (Miller and Nadathur, 1986).

3 System Overview

Figure 1 shows an overview of the system which
extracts features for learning textual similarity
from logical proofs. To produce semantic repre-
sentations of sentences and prove them automati-
cally, we use ccg2lambda (Mart´ınez-G´omez et al.,
2016), which is a semantic parser combined with
an inference system based on natural deduction.

First,

sentences are parsed into syntactic
trees based on Combinatory Categorial Grammar
(CCG) (Steedman, 2000). CCG is a syntactic the-
ory suitable for semantic composition from syn-
tactic structures. Meaning representations are ob-
tained based on semantic templates and combina-
tory rules for the CCG trees. Semantic templates
are deﬁned manually based on formal semantics.
Combinatory rules specify the syntactic behaviors
of words and compositional rules for the CCG
In ccg2lambda, two wide-coverage CCG
trees.
parsers, C&C (Clark and Curran, 2007) and Easy-
CCG (Lewis and Steedman, 2014), are used for
converting tokenized sentences into CCG trees ro-
bustly. According to a previous study (Mart´ınez-
G´omez et al., 2017), EasyCCG achieves higher ac-
curacy. Thus, when the output of both C&C and
EasyCCG can be proved, we use EasyCCG’s out-
put for creating features.

Second, the meanings of words are described
using lambda terms. Semantic representations are
obtained by combining lambda terms in accor-
dance with the meaning composition rules spec-
iﬁed in the CCG tree. The semantic representa-
tions are based on Neo-Davidsonian event seman-
tics (Parsons, 1990; Mineshima et al., 2015), in
which every verb is decomposed into a predicate
over events and a set of functional expressions re-

prove the bidirectional entailment relations, A(cid:48) ⇒
B(cid:48) and B(cid:48) ⇒ A(cid:48).
If the initial natural deduc-
tion proofs fail, we re-run the proof, adding rel-
evant external axioms or skipping unproved sub-
goals until the proof is completed. After that, fea-
tures for learning textual similarity are extracted
by quantifying the provability of the bidirectional
entailment relations.

The details of the procedure are as follows.
First, we attempt a natural deduction proof without
using external axioms, aiming to prove entailment
relations, A(cid:48) ⇒ B(cid:48) and B(cid:48) ⇒ A(cid:48). If both fail,
then we check whether A(cid:48) contradicts B(cid:48), which
amounts to proving the negation of the original
conclusion, namely A(cid:48) ⇒ ¬B(cid:48) and B(cid:48) ⇒ ¬A(cid:48).

The similarity of a sentence pair tends to be
higher when the negation of the conclusion can
be proved, compared with the case where nei-
ther the conclusion nor its negation can be proved.
In the SICK (Sentences Involving Compositional
Knowledge) dataset (Marelli et al., 2014) (see Sec-
tion 6.1 for details), 70% of the sentence pairs an-
notated as contradictory are assigned a relatedness
score in [3, 5).

Next, if we fail to prove entailment or contradic-
tion, that is, we cannot prove the conclusion or its
negation, we identify an unproved sub-goal which
is not matched by any predicate in the premise.
We then attempt to prove A(cid:48) ⇒ B(cid:48) and B(cid:48) ⇒ A(cid:48)
using axiom injection, following the method in-
troduced in Mart´ınez-G´omez et al. (2017). In ax-
iom injection, unproved sub-goals are candidates
to form axioms. We focus only on predicates that
share at least one argument with both the premise
and the conclusion. This means that an axiom can
be generated only if there is a predicate p in the
pool of premises and a predicate q in a sub-goal
and p and q share a variable in an argument posi-
tion, possibly with the same case (e.g., Subject or
Object).

In generating axioms,

the semantic relation-
ships between the predicates in the premise and
those in the conclusion are checked using lexical
knowledge. In this study, we use WordNet (Miller,
1995) as the source of lexical knowledge. Linguis-
tic relations between predicates are checked in the
following order: inﬂections, derivationally related
forms, synonyms, antonyms, hypernyms, similar-
ities, and hyponyms. If any one of these relations
is found in the lexical knowledge, an axiom can
be generated. Again, if the proof fails, we attempt

Figure 1: System overview.

lating the events. Adverbs and prepositions are
also represented as predicates over events.

Third, we attempt to prove entailment relations
between sentence pairs. For this purpose, we use
Coq (Bertot and Castran, 2010), which can be
used for efﬁcient theorem-proving for natural lan-
guage inference using both ﬁrst-order and higher-
order logic (Mineshima et al., 2015). Coq’s proof
calculus is based on natural deduction (Prawitz,
1965), a proof system based on inference rules
called introduction and elimination rules for log-
ical connectives. The inference system imple-
mented in ccg2lambda using Coq achieves efﬁ-
cient automatic inference by feeding a set of pre-
deﬁned tactics and user-deﬁned proof-search tac-
tics to its interactive mode. The natural deduc-
tion system is particularly suitable for injecting
external axioms during the theorem-proving pro-
cess (Mart´ınez-G´omez et al., 2017).

Finally, features for learning textual similar-
ity are extracted from the proofs produced by
ccg2lambda during the theorem-proving process.
In this study, we experimented with logistic re-
gression, support vector regression and random
forest regression, ﬁnding that random forest re-
gression was the most effective. We therefore
chose random forest regression for learning tex-
tual similarity, with its hyperparameters being op-
timized by grid search. The mean squared error
(MSE) was used to measure the prediction perfor-
mance of our system.

4 Proof Strategy for Learning Textual

Similarity

4.1 Overview of the proof strategy

Sentence similarity depends on complex elements,
such as word overlaps and semantic relations. We
capture the similarity between the sentence pair
(A, B) as a function of the provability of bidirec-
tional entailment relations for (A, B) and combine
it with shallow features. After obtaining logical
formulas A(cid:48) and B(cid:48) from A and B, we attempt to

G : A ∧ B

∧-INTRO

G1 : A
G2 : B

P : A1 ∧ A2 ∧ · · · ∧ An

P0 : ∃e1x1x2(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1)

∧ bar(x2) ∧ in(e1, x2))

∧-ELIM

G0 : ∃e1x1(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1))

P1 : A1, P2 : A2, . . . , Pn : An

∃-ELIM (P0), ∃-INTRO (G0)

G : A → B

→-INTRO

P : A
G : B

P1 : A → B
P2 : A

→-ELIM

P : B

G : ∃xA(x)

P : ∃xA(x)

∃-INTRO

∃-ELIM

P1 : A(t)
P2 : t = u

=-ELIM

G1 : A(x)

P1 : A(x)

P : A(u)

Figure 2: Example of the inference rules used in
natural deduction. P, P1, . . . Pn are formulas in
the premise, while G, G1, G2 are formulas in the
goal. The initial formulas are at the top, with the
formulas obtained by applying the inference rules
shown below.

to prove the negation of the conclusion using the
axiom injection mechanism.

If the proof by axiom injection fails because of
a lack of lexical knowledge, we obtain sentence
similarity information from partial proofs by sim-
ply accepting the unproved sub-goals and forcibly
completing the proof. After the proof is com-
pleted, information about the generated axioms
and skipped sub-goals is used to create features.

4.2 Proving entailment relations

As an illustration of how our natural deduction
proof works, consider the case of proving entail-
ment for the following sentence pair:
A: A man is singing in a bar.
B: A man is singing.

The sentences A and B are mapped onto logical
formulas A(cid:48) and B(cid:48) based on event semantics via
CCG-based semantic composition, as follows.

A(cid:48) : ∃e1x1x2(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1)

∧ bar(x2) ∧ in(e1, x2))

B(cid:48) : ∃e1x1(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1))

First, we attempt a natural deduction proof of
A(cid:48) ⇒ B(cid:48), setting A(cid:48) as the premise and B(cid:48) as the
goal of the proof. Then A(cid:48) and B(cid:48) are decomposed
according to the inference rules.

Figure 2 shows the major inference rules we use
in the proofs. Inference rules in natural deduction
are divided into two types: introduction rules and

P1 : man(x1) ∧ sing(e1) ∧ (subj(e1) = x1)

∧ bar(x2) ∧ in(e1, x2)

G1 : man(x1) ∧ sing(e1) ∧ (subj(e1) = x1)

∧-ELIM (P1), ∧-INTRO (G1)

P2 : man(x1), P3 : sing(e1), P4 : subj(e1) = x1,

P5 : bar(x2), P6 : in(e1, x2)

G2 : man(x1), G3 : sing(e1), G4 : subj(e1) = x1

Figure 3: The proof process for the example en-
tailment relation.

elimination rules. Introduction rules specify how
to prove a formula in the goal, decomposing a goal
formula into smaller sub-goals. Elimination rules
specify how to use a premise, decomposing a for-
mula in the pool of premises into smaller ones.

The proof process for A(cid:48) ⇒ B(cid:48) is shown in Fig-
ure 3. Here A(cid:48) is initially set to the premise P0 and
B(cid:48) to the goal G0. P0 and G0 are then decomposed
using elimination rules (∧-ELIM, ∃-ELIM) and intro-
duction rules (∧-INTRO, ∃-INTRO). Then we obtain a
set of premise formulas P = {P2, P3, P4, P5, P6},
and a set of sub-goals G = {G2, G3, G4}. The
proof is performed by searching for a premise Pi
whose predicate and arguments match those of a
given sub-goal Gj.
If such a logical premise is
found, the sub-goal is removed. In this example,
the sub-goals G2, G3, and G4 match the premises
P2, P3, and P4, respectively. Thus, A(cid:48) ⇒ B(cid:48) can
be proved without introducing axioms.

Second, we attempt the proof in the opposite
direction, B(cid:48) ⇒ A(cid:48), by switching P0 and G0 in
Figure 3. Again, by applying inference rules, we
obtain the following sets of premises P and sub-
goals G:

P = {P2 : man(x1), P3 : sing(e1),

P4 : subj(e1) = x1}

G = {G2 : man(x1), G3 : sing(e1),

G4 : subj(e1) = x1,
G5 : bar(x2), G6 : in(e1, x2))}

Here, the two sub-goals G5 and G6 do not match
any of the premises, so the attempted proof of
B(cid:48) ⇒ A(cid:48) fails. We therefore attempt to inject
additional axioms, but in this case no predicate
in P shares the argument x2 of the predicates
bar(x2) and in(e1, x2) in G. Thus, no axiom can
be generated. To obtain information from a partial
proof, we forcibly complete the proof of B(cid:48) ⇒ A(cid:48)
by skipping the unproved sub-goals bar(x) and

in(e1, x2).

4.3 Proving the contradiction

The proof strategy illustrated here can be straight-
forwardly applied to proving the contradiction. In
natural deduction, a negative formula of the form
¬A can be deﬁned as A → False (“the formula
A implies the contradiction”), by using a proposi-
tional constant False to encode the contradiction.
Thus, the inference rules for negation can be taken
as special cases of implication rules, as shown in
Figure 4.

As an illustration, let us consider the following

sentence pair:

A: No man is singing.
B: There is a man singing loudly.

Figure 5 shows the proof process. The sentences
A and B are mapped to P0 and P1, respectively,
via compositional semantics and the goal G0 is set
to False. By decomposing P1 using elimination
rules and then by combining P2, P3, and P4, we
can obtain P6. From P0 and P6 we can then derive
the contradiction.

These proofs are performed by an automated
prover implemented on Coq, using tactics for ﬁrst-
order theorem proving. When a proof is success-
ful, Coq outputs the resulting proof (a proof term),
from which we can extract detailed information
such as the number of proof steps and the types
of inference rules used. In addition to the entail-
ment/contradiction result, information about the
proof process is used to create features.

5 Description of the Features

To maximize accuracy when learning textual sim-
ilarity, we adopt a hybrid approach that uses both
logic-based features extracted from the natural de-
duction proof and other, non-logic-based features.
All features are scaled to the [0, 1] range.

5.1 Logic-based Features

We propose 15 features consisting of nine different
types of logic-based features. Six of these feature
types are derived from the bidirectional natural de-
duction proofs: six features are extracted from the
direct proof (A(cid:48) ⇒ B(cid:48)) and another six from the
reverse proof (B(cid:48) ⇒ A(cid:48)). The remaining three
feature types are derived from semantic represen-
tations of the sentence pairs. The feature types are
as follows.

G : ¬A

¬-INTRO

P : A
G : False

P1 : ¬A
P2 : A

¬-ELIM

P : False

Figure 4: Inference rules of negation.

P0 : ¬∃e1∃x1(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1))
P1 : ∃e1∃x1(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1)

∧ loudly(e1))

G0 : False

∃-ELIM, ∧-ELIM (P2)

P2 : man(x1), P3 : sing(e1), P4 : subj(e1) = x1,
P5 : loudly(e1)

∃-INTRO, ∧-INTRO (P2)

P6 : ∃e1∃x1(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1))

Figure 5: Proof process for the contradiction ex-
ample.

Logical inference result. As stated in Section 4,
we include features to distinguish the case where
either the conclusion or its negation can be proved
from the one where neither can be proved. If the
conclusion can be proved, the feature is set to 1.0.
If the negation of the conclusion can be proved,
the feature is set to 0.5. If neither can be proved,
the feature is set to 0.0.
Axiom probabilities. The probability of an ax-
iom and the number of axioms appearing in the
proof are used to create features. The probability
of an axiom is deﬁned as the inverse of the length
of the shortest path that connects the senses in the
is-a (hypernym/hyponym) taxonomy in WordNet.
When multiple axioms are used in the proof, the
average of the probabilities of the axioms is ex-
tracted as a feature. If the proof can be completed
without using axioms, the feature is set to 1.0.
Proved sub-goals. Given that proofs can be ob-
tained either by proving all the sub-goals or skip-
ping unproved sub-goals, we use the proportion of
proved sub-goals as a feature. Our assumption is
that if there are more unproved sub-goals then the
sentence pair is less similar. When there are m
logical formulas in the premise pool and n proved
sub-goals, we set the feature to n/m. If the theo-
rem can be proved without skipping any sub-goals,
the feature is set to 1.0. It may be the case that
the number of sub-goals is so large that some sub-
goals remain unproved even after axiom injection.

Since the proportion of unproved sub-goals is de-
creased by axiom injection, we use the proportion
of unproved sub-goals both with and without ax-
iom injection as features.
Cases in unproved sub-goals. Subject or object
words can affect the similarity of sentence pairs.
Therefore, the number of each case in unproved
sub-goals, like subj(e1) in Figures 3 and 5, is
used as a feature. Here, we count subjective, ob-
jective, and dative cases.
Proof steps. In general, complex theorems are dif-
ﬁcult to prove and in such cases the sentence pairs
are considered to be less similar. We therefore use
the number of Coq’s proof steps, namely the num-
ber of inference rule applications in a given proof,
as a feature.
Inference rules. The complexity of a natural de-
duction proof can be measured in terms of the in-
ference rules used for each proof step. We there-
fore extract the relative frequency with which each
inference rule is used in the proof as a feature. We
check seven inference rules for natural deduction
using Coq (cf. Figure 2): introduction and elimi-
nation rules for conjunction (∧-INTRO, ∧-ELIM), im-
plication (→-INTRO, →-ELIM), and existential quan-
tiﬁcation (∃-INTRO, ∃-ELIM), and the elimination
rule for equality (=-ELIM).
Predicate overlap.
Intuitively, the more predi-
cates overlap between the premise and the conclu-
sion, the more likely it is that the inference can be
proved. We therefore use the proportion of pred-
icates that overlap between the premise and the
conclusion as a feature.
Semantic type overlap. Each semantic represen-
tation in higher-order logic has a semantic type,
such as Entity for entities and Prop for proposi-
tions. As with predicates, we use the degree of se-
mantic type overlap between the premise and the
conclusion as a feature.
Existence of negative clauses. Whether or not the
premise or conclusion contain negative clauses is
an effective measure of similarity. In semantic rep-
resentations, negative clauses are represented by
the negation operator ¬, so we check for negation
operators in the premise and the conclusion and
set this feature to 1.0 if either contains one.

5.2 Non-logic-based Features

nouns and verbs from the sentence pairs and use
the degrees of overlap of the noun and verb lem-
mas as features.
Part-of-speech overlap. We obtain part-of-
speech (POS) tags for all words in the sentence
pairs by ﬁrst tokenizing them with the Penn Tree-
bank Project tokenizer1 and then POS tagging
them with C&C POS tagger (Curran and Clark,
2003). The degree of overlap between the sen-
tences’ POS tags is used as a feature.
Synset overlap. For each sentence in the pair, we
obtain the set containing all the synonym lemmas
(the synset) for the words in the sentence. The
degree of overlap between the sentences’ synsets
is used as a feature.
Synset distance. For each word in the ﬁrst sen-
tence, we compute the maximum path similarity
between its synset and the synset of any other
word in the second sentence. Then, we use the
average of maximum path similarities as a feature.
Sentence length.
If the conclusion sentence is
long, there will possibly be many sub-goals in the
proof. We therefore use the average of the sen-
tence lengths and the difference in length between
the premise and the conclusion sentences as fea-
tures.
String similarity. We use the similarity of the se-
quence of characters within the sentence pairs as a
feature. The Python Difﬂib2 function returns the
similarity between two sequences as a ﬂoating-
point value in [0, 1]. This measure is given by
2.0 ∗ M/T , where T is the total number of ele-
ments in both sequences and M is the number of
matches. This feature is 1.0 if the sequences are
identical and 0.0 if they have nothing in common.
Sentence similarity from vector space models.
We calculate sentence similarity by using three
major vector space models, TF-IDF, latent se-
mantic analysis (LSA) (Deerwester et al., 1990),
and latent Dirichlet allocation (LDA) (Blei et al.,
2003). We use these cosine similarities as features.
Existence of passive clauses. Passive clauses
have an inﬂuence on similarity.
In CCG trees,
passive clauses are represented using the syntactic
category Spss\N P . We check for the occurrence
of passive clauses in the premise and conclusion,
and if either of them contains a passive clause then
the feature is set to 1.0.

We also use the following eight non-logic-based
features.
Noun/verb overlap. We extract and lemmatize all

1ftp://ftp.cis.upenn.edu/pub/treebank/public html/

tokenization.html

2https://docs.python.org/3.5/library/difﬂib.html

ID
23
1412
9963

Sentence1

Sentence2

Entailment Score

There is no biker jumping in the air. A lone biker is jumping in the air

Men are sawing logs.
The animal is grazing on the grass.

Men are cutting wood.
The cop is sitting on a police bike.

no
yes
unknown

4.2
4.5
1

Table 1: Examples in the SICK dataset with different entailment labels and similarity scores.

Mueller et al. (2016)
Our system
SemEval2014 Best Score
The Meaning Factory
UTexas
Baseline

γ
0.882
0.838
0.828
0.827
0.714
0.653

ρ
0.835
0.796
0.769
0.772
0.674
0.745

MSE
0.229
0.561
0.325
0.322
0.499
0.808

Table 2: Results on the test split of SICK dataset.

6 Experiments and Evaluation

SemEval-2014

6.1 Experimental Conditions
We evaluated our system3 using two datasets:
SICK
the
dataset (Marelli et al., 2014) and the SemEval-
2012 version of the MSR-paraphrase video corpus
dataset (MSR-vid) (Agirre et al., 2012). The
experimental conditions were as follows.

version

the

of

6.1.1 The SICK dataset

The SICK dataset is a dataset for studying STS as
well as for recognizing textual entailment (RTE).
It was originally developed for evaluating com-
positional distributional semantics, so it contains
logically challenging expressions such as quan-
tiﬁers, negations, conjunctions and disjunctions.
The dataset contains 9927 sentence pairs with a
5000/4927 training/test split. These sentence pairs
are manually annotated with three types of labels
yes (entailment), no (contradiction), or unknown
(neutral) as well as a semantic relatedness scores
in [1, 5] (see Table 1 for a sample).

In this dataset, sentence pairs whose gold entail-
ment labels are no tend to be scored a little more
highly than the average, whereas those whose la-
bels are unknown have a wide range of scores.
Thus, we set the baseline of the relatedness score
to 5 when the gold entailment label was yes and to
3 when the label was no or unknown.

We compared our system with the following
systems: the state-of-the-art neural network-based
system (Mueller and Thyagarajan, 2016); the best
system (Zhao et al., 2014) from SemEval-2014;
and two of the logic-based systems stated in Sec-

tion 2: namely The Meaning Factory (Bjerva et al.,
2014) and UTexas (Beltagy et al., 2014b). The
Pearson correlation coefﬁcient γ, Spearman’s rank
correlation coefﬁcient ρ, and the MSE were used
as the evaluation metrics.

6.1.2 The MSR-vid dataset

The MSR-vid dataset is our second dataset for the
STS task and contains 1500 sentence pairs with
a 750/750 training/test split. All sentence pairs
are annotated with semantic relatedness scores in
the range [0, 5]. We used this dataset to compare
our system with the best system from SemEval-
2012 (B¨ar et al., 2012) and the logic-based UTexas
system (Beltagy et al., 2014a). We used the Pear-
son correlation coefﬁcient γ as the evaluation met-
ric.

6.2 Results

Table 2 shows the results of our experiments with
the SICK dataset. Although the state-of-the-art
neural network-based system yielded the best re-
sults overall, our system achieved higher scores
including the
than SemEval-2014 submissions,
two logic-based systems (The Meaning Factory
and UTexas), in terms of Pearson correlation and
Spearman’s correlation.

The main reason for our system’s lower per-
formance in terms of MSE is that some theorems
could not be proved because of a lack of lexical
knowledge. In the current work, we only consider
word-level knowledge (word-for-word paraphras-
ing); we may expand the knowledge base in the
future by using more external resources.

As we mentioned above, the sentence pairs an-
notated as unknown produced a wide range of
scores. The Pearson correlation of the unknown
portion of the SICK dataset was 0.766, which sug-
gests that our logic-based system can also be ap-
plied to neutral sentence pairs.

Table 3 shows the results of our experiments
with the MSR-vid dataset. These results also in-
dicate that our logic-based system achieved higher
accuracy than the other logic-based systems.

3Available at https://github.com/mynlp/ccg2lambda.

Table 4 shows evaluation results for each feature

SemEval2012 Best Score
Our system
Beltagy et al. (2014)

γ
0.873
0.853
0.830

Table 3: Results on the test split of MSR-vid.

Predicate overlap
Inference rules
Probability of axioms
Proof steps
Proved sub-goals
Logical inference result
Unproved sub-goals’ case
Semantic type overlap
Negative clauses
Noun/verb overlap
Vector space model
String similarity
Synset overlap
Synset distance
Part-of-speech overlap
Sentence length
Passive clauses
Only logic-based
Only non logic-based
All

ρ
γ
MSE
0.734
0.609
0.691
0.794
0.619
0.632
0.865
0.540
0.543
0.915
0.494
0.458
0.926
0.443
0.432
0.939
0.399
0.386
0.973
0.307
0.301
0.987
0.219
0.245
1.004
0.323
0.163
0.763
0.554
0.661
0.857
0.510
0.594
0.977
0.418
0.414
0.978
0.341
0.382
0.999
0.330
0.352
0.954
0.346
0.349
0.993
0.240
0.231
1.017
0.046
0.023
0.613
0.760
0.798
0.793
0.621
0.732
0.838 0.796 0.561

Table 4: Results when training our regressor with
each feature group in isolation.

group in isolation, showing that inference rules
and predicate overlaps are the most effective fea-
tures. Compared with the non-logic-based fea-
tures, the logic-based features achieved a slightly
higher accuracy, a point that will be analyzed in
more detail in the next section. Overall, our re-
sults show that combining logic-based features
with non logic-based ones is an effective method
for determining textual similarity.

6.3 Positive examples and error analysis

Table 5 shows some examples for which the pre-
diction score was better when using logic-based
features than when using non-logic-based ones.

For IDs 642 and 1360, one sentence contains a
passive clause while the other sentence does not.
In such cases, the sentence pairs are not superﬁ-
cially similar. By using logical formulas based on
event semantics we were able to interpret the sen-
tence containing the passive clause correctly and
judge that the passive and non-passive sentences

are similar to each other.

In ID 891, one sentence contains a negative
clause while the other does not. Using shallow
features, the word overlap is small and the predic-
tion score was much lower than the correct score.
Our logic-based method, however, interpreted the
ﬁrst sentence as a negative existential formula of
the form ¬∃xP(x) and the second sentence as an
existential formula ∃xP (cid:48)(x). Thus, it could easily
handle the semantic difference between the posi-
tive and negative sentences.

In ID 1158, by contrast, the proportion of word
overlap is so high that the prediction score with
non-logic-based features was much higher than
the correct score. Our method, however, was able
to prove the contradiction using an antonym axiom
of the form ∀x(remove(x) → ¬add(x)) from
WordNet and thus predict the score correctly.

In ID 59, the proportion of word overlap is
low, so the prediction score with non-logic-based
features was lower than the correct score. Our
method, however, was able to prove the partial en-
tailment relations for the sentence pair and thus
predict the score correctly. Here the logic-based
method captured the common meaning of the sen-
tence pair: both sentences talk about the kids play-
ing in the leaves.

Finally, in ID 71, the prediction score with non-
logic-based features was much higher than the cor-
rect score. There are two reasons for this phe-
nomenon: negations tend to be omitted in non-
logic-based features such as TF-IDF and the pro-
portion of word overlap is high. However, as
logical formulas and proofs can handle negative
clauses correctly, our method was able to predict
the score correctly.

Table 6 shows examples where using only logic-
based features produced erroneous results. In ID
3974, the probability of axiom ∀x(awaken(x) →
up(x)) was low (0.25) and thus the prediction
score was lower than the correct score. Likewise,
in ID 4833, the probability of axiom ∀x(ﬁle(x) →
do(x)) was very low (0.09) and thus the pre-
diction score was negatively affected.
In these
cases, we need to consider phrase-level axioms
such as ∀x(awaken(x) → wake up(x)) and
∀x(ﬁle nail(x) → do manicure(x)) using a
paraphrase database. This, however, is an issue
for future study. In ID 1941, the system wrongly
proved the bidirectional entailment relations by
adding external axioms, so the prediction score

Gold

Pred
+logic

Pred
-logic

Entailment

ID Sentence Pair

642

1360

891

1158

59

71

A person is climbing a rock with a rope, which is pink.
A rock is being climbed by a person with a rope, which is pink.
The machine is shaving the end of a pencil.
A pencil is being shaved by the machine.
There is no one on the shore.
A bunch of people is on the shore.
A woman is removing ingredients from a bowl.
A woman is adding ingredients to a bowl.
Kids in red shirts are playing in the leaves.
Three kids are jumping in the leaves.
There is no child lying in the snow and making snow angels.
Two people in snowsuits are lying in the snow and making snow angels.

5.0

4.7

3.6

3.3

3.9

3.3

4.9

4.6

3.7

3.5

3.8

3.3

4.1

3.8

2.6

4.1

3.1

4.1

Yes

Yes

No

No

Unknown

Unknown

Table 5: Examples for which our regressor trained only with logic-based features performs better than
when using non-logic features. “Gold”: correct score, “Pred+logic”: prediction score only with logic-
based features, “Pred-logic”: prediction score only with non-logic-based features.

ID Sentence Pair

Gold

System Axiom

A girl is awakening.
A girl is waking up.
A girl is ﬁling her nails.
A girl is doing a manicure.

3974

4833

1941

A woman is putting the baby into a trash can.
A person is putting meat into a skillet.

4.9

4.2

1.0

3.6

1.8

3.3

∀x(awaken(x) → wake(x))
∀x(awaken(x) → up(x))
∀x(nail(x) → manicure(x))
∀x(ﬁle(x) → do(x))
∀x(woman(x) → person(x))
∀x(trash(x) → skillet(x))
∀x(baby(x) → meat(x))

Table 6: Error examples when training the regressor only with logic-based features.

was much higher than the correct score. Set-
ting the threshold for the probability of an axiom
may be an effective way of improving our axiom-
injection method.

7 Conclusion

We have developed a hybrid method for learn-
ing textual similarity by combining features based
on logical proofs of bidirectional entailment rela-
tions with non-logic-based features. The results
of our experiments on two datasets show that our
system was able to outperform other logic-based
systems. In addition, the results show that infor-
mation about the natural deduction proof process
can be used to create effective features for learning
textual similarity. Since these logic-based features
provide accuracy improvements that are largely
additive with those provided by non-logic-based
features, neural network-based systems may also
beneﬁt from using them.

In future work, we will reﬁne our system so
that it can be applied to other tasks such as ques-
tion answering. Compared with neural network-
based systems, our natural deduction-based sys-
tem can not only assess how similar sentence pairs
are, but also explain what the sources of simi-

larity/dissimilarity are by referring to information
about sub-goals in the proof. Given this interpreta-
tive ability, we believe that our logic-based system
may also be of beneﬁt to other natural language
processing tasks, such as question answering and
text summarization.

Acknowledgments

We thank the three anonymous reviewers for their
detailed comments. This work was supported by
JST CREST Grant Number JPMJCR1301, Japan.

References

Lasha Abzianidze. 2015. A tableau prover for natural
logic and language. In Proceedings of the 2015 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP-15), pages 2492–2502, Lisbon,
Portugal. Association for Computational Linguis-
tics.

Lasha Abzianidze. 2016. Natural solution to FraCaS
entailment problems. In Proceedings of the 5th Joint
Conference on Lexical and Computational Seman-
tics, pages 64–74, Berlin, Germany. Association for
Computational Linguistics.

Eneko Agirre, Daniel Cer, Mona Diab, and Aitor
Gonzalez-Agirre. 2012. SemEval-2012 Task 6: A

pilot on semantic textual similarity. In Proceedings
of the 6th International Workshop on Semantic Eval-
uation (SemEval-2012), pages 385–393, Montr´eal,
Canada. Association for Computational Linguistics.

Daniel B¨ar, Chris Biemann,

Iryna Gurevych, and
Torsten Zesch. 2012. UKP: Computing seman-
tic textual similarity by combining multiple con-
In Proceedings of the
tent similarity measures.
Sixth International Workshop on Semantic Evalu-
ation (SemEval-2012), pages 435–440, Montr´eal,
Canada. Association for Computational Linguistics.

Daisuke Bekki and Koji Mineshima. 2017. Context-
passing and underspeciﬁcation in dependent type se-
mantics. In Stergios Chatzikyriakidis and Zhaohui
Luo, editors, Modern Perspectives in Type Theoret-
ical Semantics, Studies of Linguistics and Philoso-
phy, pages 11–41. Springer.

Islam Beltagy, Katrin Erk, and Raymond Mooney.
2014a. Probabilistic soft logic for semantic tex-
tual similarity. In Proceedings of the 52nd Annual
Meeting of the Association for Computational Lin-
guistics (ACL-2014), pages 1210–1219, Baltimore,
Maryland. Association for Computational Linguis-
tics.

Islam Beltagy, Stephen Roller, Gemma Boleda, Ka-
trin Erk, and Raymond Mooney. 2014b. UTexas:
Natural language semantics using distributional se-
In Proceedings of
mantics and probabilistic logic.
the 8th International Workshop on Semantic Evalu-
ation (SemEval-2014), pages 796–801, Dublin, Ire-
land. Association for Computational Linguistics and
Dublin City University.

Yves Bertot and Pierre Castran. 2010.

Interac-
tive Theorem Proving and Program Development:
Coq’Art The Calculus of Inductive Constructions.
Springer Publishing Company, Incorporated, New
York, USA.

Johannes Bjerva, Johan Bos, Rob van der Goot, and
Malvina Nissim. 2014. The Meaning Factory: For-
mal semantics for recognizing textual entailment
and determining semantic similarity. In Proceedings
of the 8th International Workshop on Semantic Eval-
uation (SemEval-2014), pages 642–646, Dublin, Ire-
land. Association for Computational Linguistics and
Dublin City University.

David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet allocation. Journal of Ma-
chine Learning, 3:993–1022.

Stephen Clark and James R. Curran. 2007. Wide-
coverage efﬁcient statistical parsing with CCG
and log-linear models. Computational Linguistics,
33(4):493–552.

James R Curran and Stephen Clark. 2003. Investigat-
ing GIS and smoothing for maximum entropy tag-
gers. In Proceedings of the tenth conference on Eu-
ropean chapter of the Association for Computational

Linguistics-Volume 1, pages 91–98. Association for
Computational Linguistics.

Scott Deerwester, Susan T. Dumais, Thomas K. Lan-
dauer, and Richard Harshman. 1990.
Indexing by
latent semantic analysis. Journal of the American
Society for Information Science, 41(6):391–407.

Edward Grefenstette and Mehrnoosh Sadrzadeh. 2011.
Experimental support for a categorical composi-
tional distributional model of meaning. In Proceed-
ings of the 2011 Conference on Empirical Methods
in Natural Language Processing (EMNLP-2011),
pages 1394–1404, Edinburgh, Scotland, UK. Asso-
ciation for Computational Linguistics.

Felix Hill, Kyunghyun Cho, and Anna Korhonen.
2016. Learning distributed representations of sen-
tences from unlabelled data. In Proceedings of the
2016 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 1367–1377, San
Diego, California. Association for Computational
Linguistics.

Dimitri Kartsaklis, Nal Kalchbrenner, and Mehrnoosh
Sadrzadeh. 2014. Resolving lexical ambiguity in
In Proceed-
tensor regression models of meaning.
ings of the 52nd Annual Meeting of the Associ-
ation for Computational Linguistics (ACL-2014),
pages 212–217, Baltimore, Maryland. Association
for Computational Linguistics.

Dimitri Kartsaklis and Mehrnoosh Sadrzadeh. 2016.
Distributional inclusion hypothesis for tensor-based
In Proceedings of the 26th Inter-
composition.
national Conference on Computational Linguistics:
Technical Papers (COLING-2016), pages 2849–
2860, Osaka, Japan. The COLING 2016 Organizing
Committee.

Quoc V. Le and Tomas Mikolov. 2014. Distributed
representations of sentences and documents.
In
Proceedings of the 31th International Conference
on Machine Learning, (ICML-2014), pages 1188–
1196, Beijing, China.

Mike Lewis and Mark Steedman. 2014. A* CCG pars-
In Proceed-
ing with a supertag-factored model.
ings of the 2014 Conference on Empirical Methods
in Natural Language Processing (EMNLP-2014),
pages 990–1000, Doha, Qatar. Association for Com-
putational Linguistics.

Marco Marelli, Stefano Menini, Marco Baroni, Luisa
Bentivogli, Raffaella Bernardi, and Roberto Zam-
parelli. 2014. A SICK cure for the evaluation of
In
compositional distributional semantic models.
Proceedings of the 9th International Conference on
Language Resources and Evaluation (LREC-2014),
pages 216–223, Reykjavik, Iceland. European Lan-
guage Resources Association.

Pascual Mart´ınez-G´omez, Koji Mineshima, Yusuke
Miyao, and Daisuke Bekki. 2016. ccg2lambda: A

Tamara Polajnar, Laura Rimell, and Stephen Clark.
2015. An exploration of discourse-based sentence
spaces for compositional distributional semantics.
In Proceedings of the 1st Workshop on Linking
Computational Models of Lexical, Sentential and
Discourse-level Semantics, pages 1–11, Lisbon, Por-
tugal. Association for Computational Linguistics.

Dag Prawitz. 1965. Natural Deduction – A Proof-
Theoretical Study. Almqvist & Wiksell, Stockholm,
Sweden.

Mark Steedman. 2000. The Syntactic Process. MIT

Press, Cambridge, USA.

S. K. M. Wong and Vijay V. Raghavan. 1984. Vector
space model of information retrieval: A reevalua-
tion. In Proceedings of the 7th Annual International
ACM SIGIR Conference on Research and Develop-
ment in Information Retrieval, pages 167–185.

Jiang Zhao, Tiantian Zhu, and Man Lan. 2014. ECNU:
One stone two birds: Ensemble of heterogenous
measures for semantic relatedness and textual en-
In Proceedings of the 8th International
tailment.
Workshop on Semantic Evaluation (SemEval-2014),
pages 271–277, Dublin, Ireland. Association for
Computational Linguistics and Dublin City Univer-
sity.

In Proceedings
compositional semantics system.
of ACL-2016 System Demonstrations, pages 85–
90, Berlin, Germany. Association for Computational
Linguistics.

Pascual Mart´ınez-G´omez, Koji Mineshima, Yusuke
Miyao, and Daisuke Bekki. 2017. On-demand injec-
tion of lexical knowledge for recognising textual en-
tailment. In Proceedings of the 15th Conference of
the European Chapter of the Association for Compu-
tational Linguistics (EACL-2017), pages 710–720,
Valencia, Spain. Association for Computational Lin-
guistics.

Dale A. Miller and Gopalan Nadathur. 1986. Some
uses of higher-order logic in computational linguis-
In Proceedings of the 24th Annual Meeting
tics.
of the Association for Computational Linguistics,
pages 247–256, New York, New York, USA. Asso-
ciation for Computational Linguistics.

George A. Miller. 1995. WordNet: A lexical
database for English. Communications of the ACM,
38(11):39–41.

Koji Mineshima, Pascual Mart´ınez-G´omez, Yusuke
Miyao, and Daisuke Bekki. 2015. Higher-order
logical inference with compositional semantics. In
Proceedings of the 2015 Conference on Empirical
Methods in Natural Language Processing (EMNLP-
2015), pages 2055–2061, Lisbon, Portugal. Associ-
ation for Computational Linguistics.

Koji Mineshima, Ribeka Tanaka, Pascual Mart´ınez-
G´omez, Yusuke Miyao, and Daisuke Bekki. 2016.
Building compositional semantics and higher-order
inference system for a wide-coverage Japanese CCG
In Proceedings of the 2016 Conference on
parser.
Empirical Methods in Natural Language Process-
ing, pages 2236–2242, Austin, Texas. Association
for Computational Linguistics.

Jeff Mitchell and Mirella Lapata. 2008. Vector-based
In Proceedings
models of semantic composition.
of the 46th Annual Meeting of the Association for
Computational Linguistics (ACL-08), pages 236–
244, Columbus, Ohio. Association for Computa-
tional Linguistics.

Jeff Mitchell and Mirella Lapata. 2010. Composition
in distributional models of semantics. Cognitive Sci-
ence, 34(8):1388–1429.

Jonas Mueller and Aditya Thyagarajan. 2016. Siamese
recurrent architectures for learning sentence similar-
In Proceedings of the 30th AAAI Conference
ity.
on Artiﬁcial Intelligence (AAAI-2016), pages 2786–
2792, Arizona, USA. Association for the Advance-
ment of Artiﬁcial Intelligence.

Terence Parsons. 1990. Events in The Semantics of En-
glish: a Study in Subatomic Semantics. MIT Press,
Cambridge, USA.

Determining Semantic Textual Similarity
using Natural Deduction Proofs

Hitomi Yanaka1
hitomiyanaka@g.ecc.u-tokyo.ac.jp

Koji Mineshima2
mineshima.koji@ocha.ac.jp

Pascual Mart´ınez-G´omez3
pascual.mg@aist.go.jp

Daisuke Bekki2
bekki@is.ocha.ac.jp

1The University of Tokyo
2Ochanomizu University
3Artiﬁcial Intelligence Research Center, AIST
Tokyo, Japan

Abstract

Determining semantic textual similarity is
a core research subject in natural language
processing. Since vector-based models for
sentence representation often use shallow
information, capturing accurate semantics
is difﬁcult. By contrast, logical seman-
tic representations capture deeper levels of
sentence semantics, but their symbolic na-
ture does not offer graded notions of tex-
tual similarity. We propose a method for
determining semantic textual similarity by
combining shallow features with features
extracted from natural deduction proofs of
bidirectional entailment relations between
sentence pairs. For the natural deduc-
tion proofs, we use ccg2lambda, a higher-
order automatic inference system, which
converts Combinatory Categorial Gram-
mar (CCG) derivation trees into semantic
representations and conducts natural de-
duction proofs. Experiments show that our
system was able to outperform other logic-
based systems and that features derived
from the proofs are effective for learning
textual similarity.

1

Introduction

Determining semantic textual similarity (STS) is
one of the most critical tasks in information re-
trieval and natural language processing. Vector-
based sentence representation models have been
widely used to compare and rank words, phrases
or sentences using various similarity and related-
ness scores (Wong and Raghavan, 1984; Mitchell
and Lapata, 2010; Le and Mikolov, 2014). Re-

cently, neural network-based sentence representa-
tion models (Mueller and Thyagarajan, 2016; Hill
et al., 2016) have been proposed for learning tex-
tual similarity. However, these vector-based mod-
els often use shallow information, such as words
and characters, and whether they can account for
phenomena such as negation and quantiﬁcation is
not clear. Consider the sentences: Tom did not
meet some of the players and Tom did not meet any
of the players. If functional words such as some or
any are ignored or represented as the same vec-
tor, then these sentences are to be represented by
identical vectors. However, the ﬁrst sentence im-
plies that there is a player who Tom did not meet,
whereas the second sentence means that Tom did
not meet anyone, so the sentences have different
meanings.

Conversely, logic-based approaches have been
successful in representing the meanings of com-
plex sentences, having had a positive impact for
applications such as recognizing textual entail-
ment (Mineshima et al., 2015, 2016; Abzian-
idze, 2015, 2016). However, purely logic-based
approaches only assess entailment or contradic-
tion relations between sentences and do not offer
graded notions of semantic similarity.

In this paper, we propose to leverage logic cues
to learn textual similarity. Our hypothesis is that
observing proof processes when testing the seman-
tic relations is predictive of textual similarity. We
show that our approach can be more effective than
systems that ignore these logic cues.

2 Related Work

Vector-based models of semantic composition
have been widely studied with regards to calcu-
lating STS. Mitchell and Lapata (2008, 2010)

7
1
0
2
 
l
u
J
 
7
2
 
 
]
L
C
.
s
c
[
 
 
1
v
3
1
7
8
0
.
7
0
7
1
:
v
i
X
r
a

proposed a sentence vector model involving word
vector addition or component-wise multiplication.
Addition and multiplication are commutative and
associative and thus ignore word order.
Polaj-
nar et al. (2015) proposed a discourse-based sen-
tence vector model considering extra-intra senten-
tial context. Also, a categorical compositional dis-
tributional semantic model has been developed for
recognizing textual entailment and for calculating
STS (Grefenstette and Sadrzadeh, 2011; Kartsak-
lis et al., 2014; Kartsaklis and Sadrzadeh, 2016).
However, these previous studies are mostly con-
cerned with the structures of basic phrases or sen-
tences and do not address logical and functional
words such as negations and connectives. Neu-
ral network-based models of semantic composi-
tion (Mueller and Thyagarajan, 2016; Hill et al.,
2016) have also been proposed. Although these
models achieve higher accuracy, their end-to-end
nature introduces challenges in the diagnosis of
the reasons that make two sentences to be similar
or dissimilar to each other. These diagnosis capa-
bilities may play an important role in making the
system explainable and also to guide future system
improvements in a more precise manner. Our ap-
proach presented in this paper is partially inspired
by the latter two objectives.

Meanwhile, some previous studies have pro-
posed logic systems for capturing the seman-
tic relatedness of sentences. The Meaning Fac-
tory (Bjerva et al., 2014) uses both shallow and
logic-based features for learning textual similarity.
In this system, the overlap of predicates and entail-
ment judgments are extracted as logic-based fea-
tures. UTexas (Beltagy et al., 2014b) uses Prob-
abilistic Soft Logic for learning textual similarity.
In this system, each ground atom in the logical for-
mulas has a probability based on distributional se-
mantics of a word. The weights of the logical for-
mulas are calculated from the probabilities of their
ground atoms and are extracted as features. These
previous studies improved the accuracy by using
logic-based features derived from the entailment
results of ﬁrst-order theorem proving in addition
to using shallow features such as sentence lengths.

In our study, we determine the semantic similar-
ity of sentences based on the conception of proof-
theoretic semantics (Bekki and Mineshima, 2017).
The key idea is that not only the entailment results
but also the theorem proving process can be con-
sidered as features for learning textual similarity.

That is, by taking into account not only whether a
theorem is proved but also how it is proved, we can
capture the semantic relationships between sen-
tence pairs in more depth.

Another difference between our study and pre-
vious logic systems is that we use higher-order
predicate logic. Higher-order predicate logic is
able to represent complex sentence semantics such
as generalized quantiﬁers more precisely than
ﬁrst-order predicate logic.
In addition, higher-
order predicate logic makes the logical structure
of a sentence more explicit than ﬁrst-order predi-
cate logic does, so it can simplify the process of
proof search (Miller and Nadathur, 1986).

3 System Overview

Figure 1 shows an overview of the system which
extracts features for learning textual similarity
from logical proofs. To produce semantic repre-
sentations of sentences and prove them automati-
cally, we use ccg2lambda (Mart´ınez-G´omez et al.,
2016), which is a semantic parser combined with
an inference system based on natural deduction.

First,

sentences are parsed into syntactic
trees based on Combinatory Categorial Grammar
(CCG) (Steedman, 2000). CCG is a syntactic the-
ory suitable for semantic composition from syn-
tactic structures. Meaning representations are ob-
tained based on semantic templates and combina-
tory rules for the CCG trees. Semantic templates
are deﬁned manually based on formal semantics.
Combinatory rules specify the syntactic behaviors
of words and compositional rules for the CCG
In ccg2lambda, two wide-coverage CCG
trees.
parsers, C&C (Clark and Curran, 2007) and Easy-
CCG (Lewis and Steedman, 2014), are used for
converting tokenized sentences into CCG trees ro-
bustly. According to a previous study (Mart´ınez-
G´omez et al., 2017), EasyCCG achieves higher ac-
curacy. Thus, when the output of both C&C and
EasyCCG can be proved, we use EasyCCG’s out-
put for creating features.

Second, the meanings of words are described
using lambda terms. Semantic representations are
obtained by combining lambda terms in accor-
dance with the meaning composition rules spec-
iﬁed in the CCG tree. The semantic representa-
tions are based on Neo-Davidsonian event seman-
tics (Parsons, 1990; Mineshima et al., 2015), in
which every verb is decomposed into a predicate
over events and a set of functional expressions re-

prove the bidirectional entailment relations, A(cid:48) ⇒
B(cid:48) and B(cid:48) ⇒ A(cid:48).
If the initial natural deduc-
tion proofs fail, we re-run the proof, adding rel-
evant external axioms or skipping unproved sub-
goals until the proof is completed. After that, fea-
tures for learning textual similarity are extracted
by quantifying the provability of the bidirectional
entailment relations.

The details of the procedure are as follows.
First, we attempt a natural deduction proof without
using external axioms, aiming to prove entailment
relations, A(cid:48) ⇒ B(cid:48) and B(cid:48) ⇒ A(cid:48). If both fail,
then we check whether A(cid:48) contradicts B(cid:48), which
amounts to proving the negation of the original
conclusion, namely A(cid:48) ⇒ ¬B(cid:48) and B(cid:48) ⇒ ¬A(cid:48).

The similarity of a sentence pair tends to be
higher when the negation of the conclusion can
be proved, compared with the case where nei-
ther the conclusion nor its negation can be proved.
In the SICK (Sentences Involving Compositional
Knowledge) dataset (Marelli et al., 2014) (see Sec-
tion 6.1 for details), 70% of the sentence pairs an-
notated as contradictory are assigned a relatedness
score in [3, 5).

Next, if we fail to prove entailment or contradic-
tion, that is, we cannot prove the conclusion or its
negation, we identify an unproved sub-goal which
is not matched by any predicate in the premise.
We then attempt to prove A(cid:48) ⇒ B(cid:48) and B(cid:48) ⇒ A(cid:48)
using axiom injection, following the method in-
troduced in Mart´ınez-G´omez et al. (2017). In ax-
iom injection, unproved sub-goals are candidates
to form axioms. We focus only on predicates that
share at least one argument with both the premise
and the conclusion. This means that an axiom can
be generated only if there is a predicate p in the
pool of premises and a predicate q in a sub-goal
and p and q share a variable in an argument posi-
tion, possibly with the same case (e.g., Subject or
Object).

In generating axioms,

the semantic relation-
ships between the predicates in the premise and
those in the conclusion are checked using lexical
knowledge. In this study, we use WordNet (Miller,
1995) as the source of lexical knowledge. Linguis-
tic relations between predicates are checked in the
following order: inﬂections, derivationally related
forms, synonyms, antonyms, hypernyms, similar-
ities, and hyponyms. If any one of these relations
is found in the lexical knowledge, an axiom can
be generated. Again, if the proof fails, we attempt

Figure 1: System overview.

lating the events. Adverbs and prepositions are
also represented as predicates over events.

Third, we attempt to prove entailment relations
between sentence pairs. For this purpose, we use
Coq (Bertot and Castran, 2010), which can be
used for efﬁcient theorem-proving for natural lan-
guage inference using both ﬁrst-order and higher-
order logic (Mineshima et al., 2015). Coq’s proof
calculus is based on natural deduction (Prawitz,
1965), a proof system based on inference rules
called introduction and elimination rules for log-
ical connectives. The inference system imple-
mented in ccg2lambda using Coq achieves efﬁ-
cient automatic inference by feeding a set of pre-
deﬁned tactics and user-deﬁned proof-search tac-
tics to its interactive mode. The natural deduc-
tion system is particularly suitable for injecting
external axioms during the theorem-proving pro-
cess (Mart´ınez-G´omez et al., 2017).

Finally, features for learning textual similar-
ity are extracted from the proofs produced by
ccg2lambda during the theorem-proving process.
In this study, we experimented with logistic re-
gression, support vector regression and random
forest regression, ﬁnding that random forest re-
gression was the most effective. We therefore
chose random forest regression for learning tex-
tual similarity, with its hyperparameters being op-
timized by grid search. The mean squared error
(MSE) was used to measure the prediction perfor-
mance of our system.

4 Proof Strategy for Learning Textual

Similarity

4.1 Overview of the proof strategy

Sentence similarity depends on complex elements,
such as word overlaps and semantic relations. We
capture the similarity between the sentence pair
(A, B) as a function of the provability of bidirec-
tional entailment relations for (A, B) and combine
it with shallow features. After obtaining logical
formulas A(cid:48) and B(cid:48) from A and B, we attempt to

G : A ∧ B

∧-INTRO

G1 : A
G2 : B

P : A1 ∧ A2 ∧ · · · ∧ An

P0 : ∃e1x1x2(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1)

∧ bar(x2) ∧ in(e1, x2))

∧-ELIM

G0 : ∃e1x1(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1))

P1 : A1, P2 : A2, . . . , Pn : An

∃-ELIM (P0), ∃-INTRO (G0)

G : A → B

→-INTRO

P : A
G : B

P1 : A → B
P2 : A

→-ELIM

P : B

G : ∃xA(x)

P : ∃xA(x)

∃-INTRO

∃-ELIM

P1 : A(t)
P2 : t = u

=-ELIM

G1 : A(x)

P1 : A(x)

P : A(u)

Figure 2: Example of the inference rules used in
natural deduction. P, P1, . . . Pn are formulas in
the premise, while G, G1, G2 are formulas in the
goal. The initial formulas are at the top, with the
formulas obtained by applying the inference rules
shown below.

to prove the negation of the conclusion using the
axiom injection mechanism.

If the proof by axiom injection fails because of
a lack of lexical knowledge, we obtain sentence
similarity information from partial proofs by sim-
ply accepting the unproved sub-goals and forcibly
completing the proof. After the proof is com-
pleted, information about the generated axioms
and skipped sub-goals is used to create features.

4.2 Proving entailment relations

As an illustration of how our natural deduction
proof works, consider the case of proving entail-
ment for the following sentence pair:
A: A man is singing in a bar.
B: A man is singing.

The sentences A and B are mapped onto logical
formulas A(cid:48) and B(cid:48) based on event semantics via
CCG-based semantic composition, as follows.

A(cid:48) : ∃e1x1x2(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1)

∧ bar(x2) ∧ in(e1, x2))

B(cid:48) : ∃e1x1(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1))

First, we attempt a natural deduction proof of
A(cid:48) ⇒ B(cid:48), setting A(cid:48) as the premise and B(cid:48) as the
goal of the proof. Then A(cid:48) and B(cid:48) are decomposed
according to the inference rules.

Figure 2 shows the major inference rules we use
in the proofs. Inference rules in natural deduction
are divided into two types: introduction rules and

P1 : man(x1) ∧ sing(e1) ∧ (subj(e1) = x1)

∧ bar(x2) ∧ in(e1, x2)

G1 : man(x1) ∧ sing(e1) ∧ (subj(e1) = x1)

∧-ELIM (P1), ∧-INTRO (G1)

P2 : man(x1), P3 : sing(e1), P4 : subj(e1) = x1,

P5 : bar(x2), P6 : in(e1, x2)

G2 : man(x1), G3 : sing(e1), G4 : subj(e1) = x1

Figure 3: The proof process for the example en-
tailment relation.

elimination rules. Introduction rules specify how
to prove a formula in the goal, decomposing a goal
formula into smaller sub-goals. Elimination rules
specify how to use a premise, decomposing a for-
mula in the pool of premises into smaller ones.

The proof process for A(cid:48) ⇒ B(cid:48) is shown in Fig-
ure 3. Here A(cid:48) is initially set to the premise P0 and
B(cid:48) to the goal G0. P0 and G0 are then decomposed
using elimination rules (∧-ELIM, ∃-ELIM) and intro-
duction rules (∧-INTRO, ∃-INTRO). Then we obtain a
set of premise formulas P = {P2, P3, P4, P5, P6},
and a set of sub-goals G = {G2, G3, G4}. The
proof is performed by searching for a premise Pi
whose predicate and arguments match those of a
given sub-goal Gj.
If such a logical premise is
found, the sub-goal is removed. In this example,
the sub-goals G2, G3, and G4 match the premises
P2, P3, and P4, respectively. Thus, A(cid:48) ⇒ B(cid:48) can
be proved without introducing axioms.

Second, we attempt the proof in the opposite
direction, B(cid:48) ⇒ A(cid:48), by switching P0 and G0 in
Figure 3. Again, by applying inference rules, we
obtain the following sets of premises P and sub-
goals G:

P = {P2 : man(x1), P3 : sing(e1),

P4 : subj(e1) = x1}

G = {G2 : man(x1), G3 : sing(e1),

G4 : subj(e1) = x1,
G5 : bar(x2), G6 : in(e1, x2))}

Here, the two sub-goals G5 and G6 do not match
any of the premises, so the attempted proof of
B(cid:48) ⇒ A(cid:48) fails. We therefore attempt to inject
additional axioms, but in this case no predicate
in P shares the argument x2 of the predicates
bar(x2) and in(e1, x2) in G. Thus, no axiom can
be generated. To obtain information from a partial
proof, we forcibly complete the proof of B(cid:48) ⇒ A(cid:48)
by skipping the unproved sub-goals bar(x) and

in(e1, x2).

4.3 Proving the contradiction

The proof strategy illustrated here can be straight-
forwardly applied to proving the contradiction. In
natural deduction, a negative formula of the form
¬A can be deﬁned as A → False (“the formula
A implies the contradiction”), by using a proposi-
tional constant False to encode the contradiction.
Thus, the inference rules for negation can be taken
as special cases of implication rules, as shown in
Figure 4.

As an illustration, let us consider the following

sentence pair:

A: No man is singing.
B: There is a man singing loudly.

Figure 5 shows the proof process. The sentences
A and B are mapped to P0 and P1, respectively,
via compositional semantics and the goal G0 is set
to False. By decomposing P1 using elimination
rules and then by combining P2, P3, and P4, we
can obtain P6. From P0 and P6 we can then derive
the contradiction.

These proofs are performed by an automated
prover implemented on Coq, using tactics for ﬁrst-
order theorem proving. When a proof is success-
ful, Coq outputs the resulting proof (a proof term),
from which we can extract detailed information
such as the number of proof steps and the types
of inference rules used. In addition to the entail-
ment/contradiction result, information about the
proof process is used to create features.

5 Description of the Features

To maximize accuracy when learning textual sim-
ilarity, we adopt a hybrid approach that uses both
logic-based features extracted from the natural de-
duction proof and other, non-logic-based features.
All features are scaled to the [0, 1] range.

5.1 Logic-based Features

We propose 15 features consisting of nine different
types of logic-based features. Six of these feature
types are derived from the bidirectional natural de-
duction proofs: six features are extracted from the
direct proof (A(cid:48) ⇒ B(cid:48)) and another six from the
reverse proof (B(cid:48) ⇒ A(cid:48)). The remaining three
feature types are derived from semantic represen-
tations of the sentence pairs. The feature types are
as follows.

G : ¬A

¬-INTRO

P : A
G : False

P1 : ¬A
P2 : A

¬-ELIM

P : False

Figure 4: Inference rules of negation.

P0 : ¬∃e1∃x1(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1))
P1 : ∃e1∃x1(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1)

∧ loudly(e1))

G0 : False

∃-ELIM, ∧-ELIM (P2)

P2 : man(x1), P3 : sing(e1), P4 : subj(e1) = x1,
P5 : loudly(e1)

∃-INTRO, ∧-INTRO (P2)

P6 : ∃e1∃x1(man(x1) ∧ sing(e1) ∧ (subj(e1) = x1))

Figure 5: Proof process for the contradiction ex-
ample.

Logical inference result. As stated in Section 4,
we include features to distinguish the case where
either the conclusion or its negation can be proved
from the one where neither can be proved. If the
conclusion can be proved, the feature is set to 1.0.
If the negation of the conclusion can be proved,
the feature is set to 0.5. If neither can be proved,
the feature is set to 0.0.
Axiom probabilities. The probability of an ax-
iom and the number of axioms appearing in the
proof are used to create features. The probability
of an axiom is deﬁned as the inverse of the length
of the shortest path that connects the senses in the
is-a (hypernym/hyponym) taxonomy in WordNet.
When multiple axioms are used in the proof, the
average of the probabilities of the axioms is ex-
tracted as a feature. If the proof can be completed
without using axioms, the feature is set to 1.0.
Proved sub-goals. Given that proofs can be ob-
tained either by proving all the sub-goals or skip-
ping unproved sub-goals, we use the proportion of
proved sub-goals as a feature. Our assumption is
that if there are more unproved sub-goals then the
sentence pair is less similar. When there are m
logical formulas in the premise pool and n proved
sub-goals, we set the feature to n/m. If the theo-
rem can be proved without skipping any sub-goals,
the feature is set to 1.0. It may be the case that
the number of sub-goals is so large that some sub-
goals remain unproved even after axiom injection.

Since the proportion of unproved sub-goals is de-
creased by axiom injection, we use the proportion
of unproved sub-goals both with and without ax-
iom injection as features.
Cases in unproved sub-goals. Subject or object
words can affect the similarity of sentence pairs.
Therefore, the number of each case in unproved
sub-goals, like subj(e1) in Figures 3 and 5, is
used as a feature. Here, we count subjective, ob-
jective, and dative cases.
Proof steps. In general, complex theorems are dif-
ﬁcult to prove and in such cases the sentence pairs
are considered to be less similar. We therefore use
the number of Coq’s proof steps, namely the num-
ber of inference rule applications in a given proof,
as a feature.
Inference rules. The complexity of a natural de-
duction proof can be measured in terms of the in-
ference rules used for each proof step. We there-
fore extract the relative frequency with which each
inference rule is used in the proof as a feature. We
check seven inference rules for natural deduction
using Coq (cf. Figure 2): introduction and elimi-
nation rules for conjunction (∧-INTRO, ∧-ELIM), im-
plication (→-INTRO, →-ELIM), and existential quan-
tiﬁcation (∃-INTRO, ∃-ELIM), and the elimination
rule for equality (=-ELIM).
Predicate overlap.
Intuitively, the more predi-
cates overlap between the premise and the conclu-
sion, the more likely it is that the inference can be
proved. We therefore use the proportion of pred-
icates that overlap between the premise and the
conclusion as a feature.
Semantic type overlap. Each semantic represen-
tation in higher-order logic has a semantic type,
such as Entity for entities and Prop for proposi-
tions. As with predicates, we use the degree of se-
mantic type overlap between the premise and the
conclusion as a feature.
Existence of negative clauses. Whether or not the
premise or conclusion contain negative clauses is
an effective measure of similarity. In semantic rep-
resentations, negative clauses are represented by
the negation operator ¬, so we check for negation
operators in the premise and the conclusion and
set this feature to 1.0 if either contains one.

5.2 Non-logic-based Features

nouns and verbs from the sentence pairs and use
the degrees of overlap of the noun and verb lem-
mas as features.
Part-of-speech overlap. We obtain part-of-
speech (POS) tags for all words in the sentence
pairs by ﬁrst tokenizing them with the Penn Tree-
bank Project tokenizer1 and then POS tagging
them with C&C POS tagger (Curran and Clark,
2003). The degree of overlap between the sen-
tences’ POS tags is used as a feature.
Synset overlap. For each sentence in the pair, we
obtain the set containing all the synonym lemmas
(the synset) for the words in the sentence. The
degree of overlap between the sentences’ synsets
is used as a feature.
Synset distance. For each word in the ﬁrst sen-
tence, we compute the maximum path similarity
between its synset and the synset of any other
word in the second sentence. Then, we use the
average of maximum path similarities as a feature.
Sentence length.
If the conclusion sentence is
long, there will possibly be many sub-goals in the
proof. We therefore use the average of the sen-
tence lengths and the difference in length between
the premise and the conclusion sentences as fea-
tures.
String similarity. We use the similarity of the se-
quence of characters within the sentence pairs as a
feature. The Python Difﬂib2 function returns the
similarity between two sequences as a ﬂoating-
point value in [0, 1]. This measure is given by
2.0 ∗ M/T , where T is the total number of ele-
ments in both sequences and M is the number of
matches. This feature is 1.0 if the sequences are
identical and 0.0 if they have nothing in common.
Sentence similarity from vector space models.
We calculate sentence similarity by using three
major vector space models, TF-IDF, latent se-
mantic analysis (LSA) (Deerwester et al., 1990),
and latent Dirichlet allocation (LDA) (Blei et al.,
2003). We use these cosine similarities as features.
Existence of passive clauses. Passive clauses
have an inﬂuence on similarity.
In CCG trees,
passive clauses are represented using the syntactic
category Spss\N P . We check for the occurrence
of passive clauses in the premise and conclusion,
and if either of them contains a passive clause then
the feature is set to 1.0.

We also use the following eight non-logic-based
features.
Noun/verb overlap. We extract and lemmatize all

1ftp://ftp.cis.upenn.edu/pub/treebank/public html/

tokenization.html

2https://docs.python.org/3.5/library/difﬂib.html

ID
23
1412
9963

Sentence1

Sentence2

Entailment Score

There is no biker jumping in the air. A lone biker is jumping in the air

Men are sawing logs.
The animal is grazing on the grass.

Men are cutting wood.
The cop is sitting on a police bike.

no
yes
unknown

4.2
4.5
1

Table 1: Examples in the SICK dataset with different entailment labels and similarity scores.

Mueller et al. (2016)
Our system
SemEval2014 Best Score
The Meaning Factory
UTexas
Baseline

γ
0.882
0.838
0.828
0.827
0.714
0.653

ρ
0.835
0.796
0.769
0.772
0.674
0.745

MSE
0.229
0.561
0.325
0.322
0.499
0.808

Table 2: Results on the test split of SICK dataset.

6 Experiments and Evaluation

SemEval-2014

6.1 Experimental Conditions
We evaluated our system3 using two datasets:
SICK
the
dataset (Marelli et al., 2014) and the SemEval-
2012 version of the MSR-paraphrase video corpus
dataset (MSR-vid) (Agirre et al., 2012). The
experimental conditions were as follows.

version

the

of

6.1.1 The SICK dataset

The SICK dataset is a dataset for studying STS as
well as for recognizing textual entailment (RTE).
It was originally developed for evaluating com-
positional distributional semantics, so it contains
logically challenging expressions such as quan-
tiﬁers, negations, conjunctions and disjunctions.
The dataset contains 9927 sentence pairs with a
5000/4927 training/test split. These sentence pairs
are manually annotated with three types of labels
yes (entailment), no (contradiction), or unknown
(neutral) as well as a semantic relatedness scores
in [1, 5] (see Table 1 for a sample).

In this dataset, sentence pairs whose gold entail-
ment labels are no tend to be scored a little more
highly than the average, whereas those whose la-
bels are unknown have a wide range of scores.
Thus, we set the baseline of the relatedness score
to 5 when the gold entailment label was yes and to
3 when the label was no or unknown.

We compared our system with the following
systems: the state-of-the-art neural network-based
system (Mueller and Thyagarajan, 2016); the best
system (Zhao et al., 2014) from SemEval-2014;
and two of the logic-based systems stated in Sec-

tion 2: namely The Meaning Factory (Bjerva et al.,
2014) and UTexas (Beltagy et al., 2014b). The
Pearson correlation coefﬁcient γ, Spearman’s rank
correlation coefﬁcient ρ, and the MSE were used
as the evaluation metrics.

6.1.2 The MSR-vid dataset

The MSR-vid dataset is our second dataset for the
STS task and contains 1500 sentence pairs with
a 750/750 training/test split. All sentence pairs
are annotated with semantic relatedness scores in
the range [0, 5]. We used this dataset to compare
our system with the best system from SemEval-
2012 (B¨ar et al., 2012) and the logic-based UTexas
system (Beltagy et al., 2014a). We used the Pear-
son correlation coefﬁcient γ as the evaluation met-
ric.

6.2 Results

Table 2 shows the results of our experiments with
the SICK dataset. Although the state-of-the-art
neural network-based system yielded the best re-
sults overall, our system achieved higher scores
including the
than SemEval-2014 submissions,
two logic-based systems (The Meaning Factory
and UTexas), in terms of Pearson correlation and
Spearman’s correlation.

The main reason for our system’s lower per-
formance in terms of MSE is that some theorems
could not be proved because of a lack of lexical
knowledge. In the current work, we only consider
word-level knowledge (word-for-word paraphras-
ing); we may expand the knowledge base in the
future by using more external resources.

As we mentioned above, the sentence pairs an-
notated as unknown produced a wide range of
scores. The Pearson correlation of the unknown
portion of the SICK dataset was 0.766, which sug-
gests that our logic-based system can also be ap-
plied to neutral sentence pairs.

Table 3 shows the results of our experiments
with the MSR-vid dataset. These results also in-
dicate that our logic-based system achieved higher
accuracy than the other logic-based systems.

3Available at https://github.com/mynlp/ccg2lambda.

Table 4 shows evaluation results for each feature

SemEval2012 Best Score
Our system
Beltagy et al. (2014)

γ
0.873
0.853
0.830

Table 3: Results on the test split of MSR-vid.

Predicate overlap
Inference rules
Probability of axioms
Proof steps
Proved sub-goals
Logical inference result
Unproved sub-goals’ case
Semantic type overlap
Negative clauses
Noun/verb overlap
Vector space model
String similarity
Synset overlap
Synset distance
Part-of-speech overlap
Sentence length
Passive clauses
Only logic-based
Only non logic-based
All

ρ
γ
MSE
0.734
0.609
0.691
0.794
0.619
0.632
0.865
0.540
0.543
0.915
0.494
0.458
0.926
0.443
0.432
0.939
0.399
0.386
0.973
0.307
0.301
0.987
0.219
0.245
1.004
0.323
0.163
0.763
0.554
0.661
0.857
0.510
0.594
0.977
0.418
0.414
0.978
0.341
0.382
0.999
0.330
0.352
0.954
0.346
0.349
0.993
0.240
0.231
1.017
0.046
0.023
0.613
0.760
0.798
0.793
0.621
0.732
0.838 0.796 0.561

Table 4: Results when training our regressor with
each feature group in isolation.

group in isolation, showing that inference rules
and predicate overlaps are the most effective fea-
tures. Compared with the non-logic-based fea-
tures, the logic-based features achieved a slightly
higher accuracy, a point that will be analyzed in
more detail in the next section. Overall, our re-
sults show that combining logic-based features
with non logic-based ones is an effective method
for determining textual similarity.

6.3 Positive examples and error analysis

Table 5 shows some examples for which the pre-
diction score was better when using logic-based
features than when using non-logic-based ones.

For IDs 642 and 1360, one sentence contains a
passive clause while the other sentence does not.
In such cases, the sentence pairs are not superﬁ-
cially similar. By using logical formulas based on
event semantics we were able to interpret the sen-
tence containing the passive clause correctly and
judge that the passive and non-passive sentences

are similar to each other.

In ID 891, one sentence contains a negative
clause while the other does not. Using shallow
features, the word overlap is small and the predic-
tion score was much lower than the correct score.
Our logic-based method, however, interpreted the
ﬁrst sentence as a negative existential formula of
the form ¬∃xP(x) and the second sentence as an
existential formula ∃xP (cid:48)(x). Thus, it could easily
handle the semantic difference between the posi-
tive and negative sentences.

In ID 1158, by contrast, the proportion of word
overlap is so high that the prediction score with
non-logic-based features was much higher than
the correct score. Our method, however, was able
to prove the contradiction using an antonym axiom
of the form ∀x(remove(x) → ¬add(x)) from
WordNet and thus predict the score correctly.

In ID 59, the proportion of word overlap is
low, so the prediction score with non-logic-based
features was lower than the correct score. Our
method, however, was able to prove the partial en-
tailment relations for the sentence pair and thus
predict the score correctly. Here the logic-based
method captured the common meaning of the sen-
tence pair: both sentences talk about the kids play-
ing in the leaves.

Finally, in ID 71, the prediction score with non-
logic-based features was much higher than the cor-
rect score. There are two reasons for this phe-
nomenon: negations tend to be omitted in non-
logic-based features such as TF-IDF and the pro-
portion of word overlap is high. However, as
logical formulas and proofs can handle negative
clauses correctly, our method was able to predict
the score correctly.

Table 6 shows examples where using only logic-
based features produced erroneous results. In ID
3974, the probability of axiom ∀x(awaken(x) →
up(x)) was low (0.25) and thus the prediction
score was lower than the correct score. Likewise,
in ID 4833, the probability of axiom ∀x(ﬁle(x) →
do(x)) was very low (0.09) and thus the pre-
diction score was negatively affected.
In these
cases, we need to consider phrase-level axioms
such as ∀x(awaken(x) → wake up(x)) and
∀x(ﬁle nail(x) → do manicure(x)) using a
paraphrase database. This, however, is an issue
for future study. In ID 1941, the system wrongly
proved the bidirectional entailment relations by
adding external axioms, so the prediction score

Gold

Pred
+logic

Pred
-logic

Entailment

ID Sentence Pair

642

1360

891

1158

59

71

A person is climbing a rock with a rope, which is pink.
A rock is being climbed by a person with a rope, which is pink.
The machine is shaving the end of a pencil.
A pencil is being shaved by the machine.
There is no one on the shore.
A bunch of people is on the shore.
A woman is removing ingredients from a bowl.
A woman is adding ingredients to a bowl.
Kids in red shirts are playing in the leaves.
Three kids are jumping in the leaves.
There is no child lying in the snow and making snow angels.
Two people in snowsuits are lying in the snow and making snow angels.

5.0

4.7

3.6

3.3

3.9

3.3

4.9

4.6

3.7

3.5

3.8

3.3

4.1

3.8

2.6

4.1

3.1

4.1

Yes

Yes

No

No

Unknown

Unknown

Table 5: Examples for which our regressor trained only with logic-based features performs better than
when using non-logic features. “Gold”: correct score, “Pred+logic”: prediction score only with logic-
based features, “Pred-logic”: prediction score only with non-logic-based features.

ID Sentence Pair

Gold

System Axiom

A girl is awakening.
A girl is waking up.
A girl is ﬁling her nails.
A girl is doing a manicure.

3974

4833

1941

A woman is putting the baby into a trash can.
A person is putting meat into a skillet.

4.9

4.2

1.0

3.6

1.8

3.3

∀x(awaken(x) → wake(x))
∀x(awaken(x) → up(x))
∀x(nail(x) → manicure(x))
∀x(ﬁle(x) → do(x))
∀x(woman(x) → person(x))
∀x(trash(x) → skillet(x))
∀x(baby(x) → meat(x))

Table 6: Error examples when training the regressor only with logic-based features.

was much higher than the correct score. Set-
ting the threshold for the probability of an axiom
may be an effective way of improving our axiom-
injection method.

7 Conclusion

We have developed a hybrid method for learn-
ing textual similarity by combining features based
on logical proofs of bidirectional entailment rela-
tions with non-logic-based features. The results
of our experiments on two datasets show that our
system was able to outperform other logic-based
systems. In addition, the results show that infor-
mation about the natural deduction proof process
can be used to create effective features for learning
textual similarity. Since these logic-based features
provide accuracy improvements that are largely
additive with those provided by non-logic-based
features, neural network-based systems may also
beneﬁt from using them.

In future work, we will reﬁne our system so
that it can be applied to other tasks such as ques-
tion answering. Compared with neural network-
based systems, our natural deduction-based sys-
tem can not only assess how similar sentence pairs
are, but also explain what the sources of simi-

larity/dissimilarity are by referring to information
about sub-goals in the proof. Given this interpreta-
tive ability, we believe that our logic-based system
may also be of beneﬁt to other natural language
processing tasks, such as question answering and
text summarization.

Acknowledgments

We thank the three anonymous reviewers for their
detailed comments. This work was supported by
JST CREST Grant Number JPMJCR1301, Japan.

References

Lasha Abzianidze. 2015. A tableau prover for natural
logic and language. In Proceedings of the 2015 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP-15), pages 2492–2502, Lisbon,
Portugal. Association for Computational Linguis-
tics.

Lasha Abzianidze. 2016. Natural solution to FraCaS
entailment problems. In Proceedings of the 5th Joint
Conference on Lexical and Computational Seman-
tics, pages 64–74, Berlin, Germany. Association for
Computational Linguistics.

Eneko Agirre, Daniel Cer, Mona Diab, and Aitor
Gonzalez-Agirre. 2012. SemEval-2012 Task 6: A

pilot on semantic textual similarity. In Proceedings
of the 6th International Workshop on Semantic Eval-
uation (SemEval-2012), pages 385–393, Montr´eal,
Canada. Association for Computational Linguistics.

Daniel B¨ar, Chris Biemann,

Iryna Gurevych, and
Torsten Zesch. 2012. UKP: Computing seman-
tic textual similarity by combining multiple con-
In Proceedings of the
tent similarity measures.
Sixth International Workshop on Semantic Evalu-
ation (SemEval-2012), pages 435–440, Montr´eal,
Canada. Association for Computational Linguistics.

Daisuke Bekki and Koji Mineshima. 2017. Context-
passing and underspeciﬁcation in dependent type se-
mantics. In Stergios Chatzikyriakidis and Zhaohui
Luo, editors, Modern Perspectives in Type Theoret-
ical Semantics, Studies of Linguistics and Philoso-
phy, pages 11–41. Springer.

Islam Beltagy, Katrin Erk, and Raymond Mooney.
2014a. Probabilistic soft logic for semantic tex-
tual similarity. In Proceedings of the 52nd Annual
Meeting of the Association for Computational Lin-
guistics (ACL-2014), pages 1210–1219, Baltimore,
Maryland. Association for Computational Linguis-
tics.

Islam Beltagy, Stephen Roller, Gemma Boleda, Ka-
trin Erk, and Raymond Mooney. 2014b. UTexas:
Natural language semantics using distributional se-
In Proceedings of
mantics and probabilistic logic.
the 8th International Workshop on Semantic Evalu-
ation (SemEval-2014), pages 796–801, Dublin, Ire-
land. Association for Computational Linguistics and
Dublin City University.

Yves Bertot and Pierre Castran. 2010.

Interac-
tive Theorem Proving and Program Development:
Coq’Art The Calculus of Inductive Constructions.
Springer Publishing Company, Incorporated, New
York, USA.

Johannes Bjerva, Johan Bos, Rob van der Goot, and
Malvina Nissim. 2014. The Meaning Factory: For-
mal semantics for recognizing textual entailment
and determining semantic similarity. In Proceedings
of the 8th International Workshop on Semantic Eval-
uation (SemEval-2014), pages 642–646, Dublin, Ire-
land. Association for Computational Linguistics and
Dublin City University.

David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet allocation. Journal of Ma-
chine Learning, 3:993–1022.

Stephen Clark and James R. Curran. 2007. Wide-
coverage efﬁcient statistical parsing with CCG
and log-linear models. Computational Linguistics,
33(4):493–552.

James R Curran and Stephen Clark. 2003. Investigat-
ing GIS and smoothing for maximum entropy tag-
gers. In Proceedings of the tenth conference on Eu-
ropean chapter of the Association for Computational

Linguistics-Volume 1, pages 91–98. Association for
Computational Linguistics.

Scott Deerwester, Susan T. Dumais, Thomas K. Lan-
dauer, and Richard Harshman. 1990.
Indexing by
latent semantic analysis. Journal of the American
Society for Information Science, 41(6):391–407.

Edward Grefenstette and Mehrnoosh Sadrzadeh. 2011.
Experimental support for a categorical composi-
tional distributional model of meaning. In Proceed-
ings of the 2011 Conference on Empirical Methods
in Natural Language Processing (EMNLP-2011),
pages 1394–1404, Edinburgh, Scotland, UK. Asso-
ciation for Computational Linguistics.

Felix Hill, Kyunghyun Cho, and Anna Korhonen.
2016. Learning distributed representations of sen-
tences from unlabelled data. In Proceedings of the
2016 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 1367–1377, San
Diego, California. Association for Computational
Linguistics.

Dimitri Kartsaklis, Nal Kalchbrenner, and Mehrnoosh
Sadrzadeh. 2014. Resolving lexical ambiguity in
In Proceed-
tensor regression models of meaning.
ings of the 52nd Annual Meeting of the Associ-
ation for Computational Linguistics (ACL-2014),
pages 212–217, Baltimore, Maryland. Association
for Computational Linguistics.

Dimitri Kartsaklis and Mehrnoosh Sadrzadeh. 2016.
Distributional inclusion hypothesis for tensor-based
In Proceedings of the 26th Inter-
composition.
national Conference on Computational Linguistics:
Technical Papers (COLING-2016), pages 2849–
2860, Osaka, Japan. The COLING 2016 Organizing
Committee.

Quoc V. Le and Tomas Mikolov. 2014. Distributed
representations of sentences and documents.
In
Proceedings of the 31th International Conference
on Machine Learning, (ICML-2014), pages 1188–
1196, Beijing, China.

Mike Lewis and Mark Steedman. 2014. A* CCG pars-
In Proceed-
ing with a supertag-factored model.
ings of the 2014 Conference on Empirical Methods
in Natural Language Processing (EMNLP-2014),
pages 990–1000, Doha, Qatar. Association for Com-
putational Linguistics.

Marco Marelli, Stefano Menini, Marco Baroni, Luisa
Bentivogli, Raffaella Bernardi, and Roberto Zam-
parelli. 2014. A SICK cure for the evaluation of
In
compositional distributional semantic models.
Proceedings of the 9th International Conference on
Language Resources and Evaluation (LREC-2014),
pages 216–223, Reykjavik, Iceland. European Lan-
guage Resources Association.

Pascual Mart´ınez-G´omez, Koji Mineshima, Yusuke
Miyao, and Daisuke Bekki. 2016. ccg2lambda: A

Tamara Polajnar, Laura Rimell, and Stephen Clark.
2015. An exploration of discourse-based sentence
spaces for compositional distributional semantics.
In Proceedings of the 1st Workshop on Linking
Computational Models of Lexical, Sentential and
Discourse-level Semantics, pages 1–11, Lisbon, Por-
tugal. Association for Computational Linguistics.

Dag Prawitz. 1965. Natural Deduction – A Proof-
Theoretical Study. Almqvist & Wiksell, Stockholm,
Sweden.

Mark Steedman. 2000. The Syntactic Process. MIT

Press, Cambridge, USA.

S. K. M. Wong and Vijay V. Raghavan. 1984. Vector
space model of information retrieval: A reevalua-
tion. In Proceedings of the 7th Annual International
ACM SIGIR Conference on Research and Develop-
ment in Information Retrieval, pages 167–185.

Jiang Zhao, Tiantian Zhu, and Man Lan. 2014. ECNU:
One stone two birds: Ensemble of heterogenous
measures for semantic relatedness and textual en-
In Proceedings of the 8th International
tailment.
Workshop on Semantic Evaluation (SemEval-2014),
pages 271–277, Dublin, Ireland. Association for
Computational Linguistics and Dublin City Univer-
sity.

In Proceedings
compositional semantics system.
of ACL-2016 System Demonstrations, pages 85–
90, Berlin, Germany. Association for Computational
Linguistics.

Pascual Mart´ınez-G´omez, Koji Mineshima, Yusuke
Miyao, and Daisuke Bekki. 2017. On-demand injec-
tion of lexical knowledge for recognising textual en-
tailment. In Proceedings of the 15th Conference of
the European Chapter of the Association for Compu-
tational Linguistics (EACL-2017), pages 710–720,
Valencia, Spain. Association for Computational Lin-
guistics.

Dale A. Miller and Gopalan Nadathur. 1986. Some
uses of higher-order logic in computational linguis-
In Proceedings of the 24th Annual Meeting
tics.
of the Association for Computational Linguistics,
pages 247–256, New York, New York, USA. Asso-
ciation for Computational Linguistics.

George A. Miller. 1995. WordNet: A lexical
database for English. Communications of the ACM,
38(11):39–41.

Koji Mineshima, Pascual Mart´ınez-G´omez, Yusuke
Miyao, and Daisuke Bekki. 2015. Higher-order
logical inference with compositional semantics. In
Proceedings of the 2015 Conference on Empirical
Methods in Natural Language Processing (EMNLP-
2015), pages 2055–2061, Lisbon, Portugal. Associ-
ation for Computational Linguistics.

Koji Mineshima, Ribeka Tanaka, Pascual Mart´ınez-
G´omez, Yusuke Miyao, and Daisuke Bekki. 2016.
Building compositional semantics and higher-order
inference system for a wide-coverage Japanese CCG
In Proceedings of the 2016 Conference on
parser.
Empirical Methods in Natural Language Process-
ing, pages 2236–2242, Austin, Texas. Association
for Computational Linguistics.

Jeff Mitchell and Mirella Lapata. 2008. Vector-based
In Proceedings
models of semantic composition.
of the 46th Annual Meeting of the Association for
Computational Linguistics (ACL-08), pages 236–
244, Columbus, Ohio. Association for Computa-
tional Linguistics.

Jeff Mitchell and Mirella Lapata. 2010. Composition
in distributional models of semantics. Cognitive Sci-
ence, 34(8):1388–1429.

Jonas Mueller and Aditya Thyagarajan. 2016. Siamese
recurrent architectures for learning sentence similar-
In Proceedings of the 30th AAAI Conference
ity.
on Artiﬁcial Intelligence (AAAI-2016), pages 2786–
2792, Arizona, USA. Association for the Advance-
ment of Artiﬁcial Intelligence.

Terence Parsons. 1990. Events in The Semantics of En-
glish: a Study in Subatomic Semantics. MIT Press,
Cambridge, USA.

