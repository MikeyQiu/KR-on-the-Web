5
1
0
2
 
b
e
F
1
1
 
 
]
L
M

 

.
t
a
t
s
[
 
 
2
v
2
0
9
5
.
2
0
4
1
:
v
i
X
r
a

On Learning from Label Proportions

Felix X. Yu∗1, Krzysztof Choromanski3, Sanjiv Kumar3,
Tony Jebara2, and Shih-Fu Chang1

1Department of Electrical Engineering, Columbia University
2Department of Computer Science, Columbia University
3Google Inc.

Abstract

Learning from Label Proportions (LLP) is a learning setting, where the training data is pro-
vided in groups, or “bags”, and only the proportion of each class in each bag is known. The
task is to learn a model to predict the class labels of the individual instances. LLP has broad
applications in political science, marketing, healthcare, and computer vision. This work answers
the fundamental question, when and why LLP is possible, by introducing a general framework,
Empirical Proportion Risk Minimization (EPRM). EPRM learns an instance label classiﬁer to
match the given label proportions on the training data. Our result is based on a two-step analysis.
First, we provide a VC bound on the generalization error of the bag proportions. We show that the
bag sample complexity is only mildly sensitive to the bag size. Second, we show that under some
mild assumptions, good bag proportion prediction guarantees good instance label prediction. The
results together provide a formal guarantee that the individual labels can indeed be learned in the
LLP setting. We discuss applications of the analysis, including justiﬁcation of LLP algorithms,
learning with population proportions, and a paradigm for learning algorithms with privacy guar-
antees. We also demonstrate the feasibility of LLP based on a case study in real-world setting:
predicting income based on census data.

1 Introduction

A lot of information of individuals is released in the form of group label proportions. For exam-
ple, after election, the proportions of votes of each demographic area are released by the government.
In healthcare, the proportions of diagnosed diseases of each ZIP code area are available to public.
Is it possible to learn a model to predict the individual labels based on only the group-level label
proportions? Recent works in a machine learning setting called Learning from Label Proportions
(LLP) tried to study this problem. In LLP, the training instances are provided as groups, or “bags”.
In this work, we consider a binary learning setting: for each bag, only the proportion of the posi-
tive instances is available. The task is to learn a model to predict the labels of individual instances.
It is shown that by combining the label proportions with instance-level attributes, models capable
of correctly predicting instance labels can be learned [18,19,25]. As non-conﬁdential attributes of
individuals can be easily acquired from census survey, digital footprint, shopping history etc., LLP
leads to not only promising new applications, but also serious privacy concerns as releasing label
proportions may result in the discovery of sensitive personal information. Recently, LLP has also
been applied in visual attribute modeling [6,24] and event detection [16] in computer vision.

This work studies when and why individual labels can be learned from label proportions, by
analyzing a general framework, namely Empirical Proportion Risk Minimization (EPRM). EPRM

∗yuxinnan@ee.columbia.edu

OnLearningfromLabelProportions

2

optimizes the instance-level classiﬁer to minimize the empirical proportion loss. In other words, it
tries to ﬁnd an instance hypothesis to match the given label proportions. The main contribution of
this paper is a formal guarantee that under some mild assumptions, the individual instance labels can
be recovered (learned), with the EPRM framework. Speciﬁcally, we provide a two-step analysis.

Our ﬁrst result bounds the generalization error of bag proportions by the empirical bag propor-
tion error (Section 5). We show that the sample complexity is only mildly sensitive to the bag size.
In other words, our analysis shows that given enough training bags, it is possible to learn a bag pro-
portion predictor, which generalizes well to unseen bags. This conclusion in itself is interesting as
in some applications we are simply interested in getting good proportion estimates for bags: doctors
may want to predict the rate of disease on certain geographical area, and companies may want to
predict attrition rate of certain department.

Second, we show that under some mild conditions, the instance label error can be controlled
by the bag proportion error (Section 6). In other words, “good” bag proportion predictions imply
“good” instance label predictions. This ﬁnding is more crucial. For example, from privacy point of
view, the ability to learn a good instance label predictor given label proportions can be of concern.
In addition, we discuss using LLP to increase the privacy level of algorithms that aim to con-
struct private preserving machine learning structures. We also discuss applying the analysis into
justifying LLP algorithms, and LLP in some real-world cases (Section 8). Finally, we demonstrate
the feasibility of LLP in a case study: predicting income based on census data (Section 9).

2 Related Works

Algorithms for LLP. In their seminal work, [18] proposed to estimate the mean of each class
using the mean of each bag and the label proportions. These estimates are then used in a conditional
exponential model to maximize the log likelihood. The algorithm is under a restrictive assumption
that the instances are conditionally independent given the label. [19] proposed to use a large-margin
regression method by assuming the mean instance of each bag having a soft label corresponding
to the label proportion. As an extension to multiple-instance learning, [15] designed a hierarchical
probabilistic model to generate consistent label proportions. Similar ideas have also been shown
in [5] and [17]. A recently proposed
SVM algorithm [25] explicitly models the latent unknown
instance labels together with the known group label proportions in a large-margin framework. Dif-
ferent from the above works, this paper provides theoretical results addressing when and why bag
proportion and instance labels can be learned. Our result is independent of the algorithms.

∝

Multiple Instance Learning. A related, yet more extensively studied learning setting is Multiple
Instance Learning (MIL) [9]. In MIL, the learner has access to bags, with their labels generated by
the Boolean OR operator on the unobserved instance labels, i.e., a bag is positive iff it has at least
one positive instance. The task is to learn a binary predictor for the bags. It has been shown that if all
the instances are drawn iid from a single distribution, MIL is as easy as learning from iid instances
with one-sided label noise [4]. In real-world applications, the instances inside each bag can have
arbitrary dependencies, or even a manifold structure. The learnability and sample complexity results
in the above scenarios are given by [20,21], and [2], respectively. In this paper, we use the tools in
[20] to analyze the generalization error of bag proportions. More importantly, we show that under
some conditions, a good bag proportion predictor implies a good instance label predictor.

3 The Learning Setting: Learning from Label Proportions

Denote by

the domain of instance attributes, and denote by

the instance labels. Each bag, consisting of the instance attributes ˜x = (x1,
corresponding labels ˜y = (y1,

the domain of
, xr) and their
, yr), is generated iid by a probability distribution D over bags

}
· · ·

1, 1

{−

=

X

Y

· · ·

OnLearningfromLabelProportions

3

)r.1 Here, r is the bag size. For simplicity, we assume that the bags are of the same size.

(
X × Y
Our result can be easily generalized to bags with variable sizes as described in Section 7.

The learner does not have access to the instance labels. Instead it receives (˜x, f (˜y)), where,

R, is the proportion generation function. In learning with label proportions,

f :

r

Y

→

f (˜y) =

r

1
r

i=1
X

yi + 1
2

.

(1)

m
k=1,

H ⊆ Y

X to denote a hypothesis class on the instances. The learning task is to ﬁnd an h

Let the training set received by the learner be a set of m bags with their proportions S =
(˜xk, f (˜yk))
}
in which ˜xk and ˜yk are the instances and the (unobserved) labels for the k-th bag, respectively. We
use
∈ H
which gives low prediction error for unseen instances generated by the above process. In the con-
ventional supervised learning, where all the labels of the training instances are known, a popular
framework is the Empirical Risk Minimization (ERM), i.e. ﬁnding the instance hypothesis h
∈ H
to minimize the empirical instance label error. In LLP, however, the instance labels are not available
at the training time. Therefore, we can only try to ﬁnd h
to minimize the empirical proportion
error.

∈ H

{

4 The Framework: Empirical Proportion Risk Minimization

X

→

∈ H

r (h) :

r (h)(˜x) := f

Deﬁnition 1. For h
R, φf
r
φf
the hypothesis class on the bags φf
r (
(cid:0)(cid:0)

, deﬁne an operator to predict bag proportion based on the instances
, xr). And therefore

, h(xr)
h
r (h)
|
The Empirical Proportion Risk Minimization (EPRM) selects the instance label hypothesis h
∈
to minimize the empirical bag proportion loss on the training set S. It can be expressed as follows.

X r, ˜x = (x1,

h(x1),
) :=

· · ·
φf
{

(cid:1)(cid:1)
∈ H}

· · ·

, ˜x

∈
.

H

H

arg min
h
∈H

L

φf
r (h)(˜x), f (˜y)

X(˜x,f (˜y))

∈

S

(cid:0)

(cid:1)

(2)

Here, L is a loss function to compute the error of the predicted proportion φf
r (h)(˜x), and the given
proportion f (˜y). In this paper, we assume that L is 1-Lipschitz in ξ := φf
f (˜y). EPRM
is a very general framework for LLP. One immediate question is whether the instance labels can
be learned by EPRM. In the following sections, we provide afﬁrmative results. We ﬁrst bound the
generalization error of bag proportions based on the empirical bag proportions. We show that the
sample complexity of learning bag proportions is only mildly sensitive to the bag size (Section 5).
We then show that, under some mild conditions, instance hypothesis h which can achieve low error
of bag proportions with high probability, is guaranteed to achieve low error on instance labels with
high probability (Section 6).

r (h)(˜x)

−

5 Generalization Error of Predicting the Bag Proportions

Given a training set S and a hypothesis h
error with a loss function L, and denote by erL
a loss function L over distribution D:

, denote by erL

S (h) the empirical bag proportion
∈ H
D(h) the generalization error of bag proportions with

erL

S (h) =

1
S

|

| X(˜x,f (˜y))

∈

S

L(φf

r (h)(˜x), f (˜y)),

erL

D(h) = E(˜x,˜y)

DL(φf

r (h)(˜x), f (˜y)).

∼

In this section, we show that good proportion prediction is possible for unseen bags. Note that learn-
ing the bag proportion is basically a regression problem on the bags. Therefore, without considering

1This is a very mild assumption. Note that iid bags do not imply iid instances across all bags. The instances inside each

bag can have arbitrary dependencies.

OnLearningfromLabelProportions

4

the instance label hypothesis, for a smooth loss function L, the generalization error of bag propor-
tions can be bounded in terms of the empirical proportion error and some complexity measure, e.g.,
fat shattering dimension [1], of the hypothesis class on the bags. Unfortunately, the above does not
provide us insights into LLP, as it does not utilize the structure of the problem. As we show later,
such structure is important in relating the error of bag proportion to the error of instance labels.

Based on the deﬁnitions in Section 3, our main intuition is that the complexity (or “capacity”)
) should be dependent on the complexity of the instance
. Formally, we adapt the MIL analysis in [20,21], to bound the covering
is a binary hypothesis class,
based on its VC-dimension [23]. This leads to the

of bag proportion hypothesis class φf
r (
label hypothesis class
number [1] of φf
r (
we further bound the covering number of
following theorem on the generalization error of learning bag proportions.

), by the covering number of

. As in our case

H

H

H

H

H

H

Theorem 1. For any 0 < δ < 1, 0 < ǫ < 1, h
erL

S (h) + ǫ, if

∈ H

, with probability at least 1

64
ǫ2 (2V C(
H
) is the VC dimension of the instance label hypothesis class

) ln(12r/ǫ) + ln(4/δ)),

m

≥

in which V C(
of training bags, and r is the bag size.

H

δ, erL

D(h)

−

≤

(3)

, and m is the number

H

The details of the proof are given in the appendix. From the above, the generalization error of
bag proportions can be bounded by the empirical proportion error if there are sufﬁcient number of
bags in training. Note that the sample complexity (smallest sufﬁcient size of m above) grows in
terms of the bag size. This is intuitive as larger bags create more “confusions”. Fortunately, the
sample complexity grows at most logarithmically with r. It means that the generalization error is
only mildly sensitive to r. We also note that the above theorem generalizes to the well-known result
of binary supervised learning, as shown below.

Corollary 1. When bag size r = 1, for any 0 < δ < 1, 0 < ǫ < 1, h
1

δ, erL

erL

S (h) + ǫ, if

D(h)

∈ H

−

≤

, with probability at least

m

≥

64
ǫ2 (2V C(
H

) ln(12/ǫ) + ln(4/δ)).

(4)

6 Bounding the Instance Label Error by Bag Proportion Error

From the analysis above, we know that the generalization error of bag proportions can be
bounded. The result is without any additional assumptions other than that the bags are iid.
In
this section, based on assumptions about the proportions (Section 6.1), or the instances (Section 6.2,
Section 6.3), we present results bounding the generalization error of predicting instance labels by the
generalization error of predicting bag proportions. We also discuss the limitations of LLP under our
framework, providing insights into protecting the instance labels when releasing label proportions.
The analysis in this section is based on the assumption that we already have an instance hypoth-
esis h, which predicts the proportions well: P
φf
δ with some small
|
0 < ǫ, δ < 1. From Section 5, the above is true when we have sufﬁcient number of training bags,
(cid:0)
and a good algorithm to achieve small empirical bag proportion error. Formally, from Theorem 1,
suppose we have a hypothesis h, such that erL
ǫ′′)
D(h)
for some other small ǫ′′ can also be bounded. With Markov’s inequality: for any 0 < δ < 1, deﬁne
ǫ′′ = ǫ′/δ, then P(˜x,˜y)
ǫ′′)

ǫ′. Then P(˜x,˜y)

r (h)(˜x)

r (h)(˜x)

D(
|

f (˜y)

f (˜y)

f (˜y)

| ≤

| ≤

φf

φf

r (h)(˜x)

≤

−

≥

−

−

δ.

1

1

(cid:1)

∼

ǫ

−

| ≤

≥

−

D(
|

∼

6.1 Learning with Pure Bags

Intuitively, if the bags are very “pure”, i.e., their proportions are either very low or very high, the
instance label error can be well controlled by the bag proportion error. The case that all the bags are
with proportions 0 or 1 should be the easiest, as it is identical to the conventional supervised learning

OnLearningfromLabelProportions

5

setting. We justify the intuition in this section. For 0 < η < 1, we say that a bag is (1
at least a fraction (1
our analysis.

η)-pure if
η) of all instances have the same label. The following theorem summarizes

−

−

Theorem 2. Let h be a hypothesis satisfying P(˜x,˜y)
δ for some
0 < ǫ, δ < 1. Assume that the probability that each bag is (1
ρ for some
0 < η, ρ < 1. Then, for any 0 < τ < 1, the probability that h classiﬁes correctly at least a fraction
ǫ).
ǫ) of all nr instances given in n bags is at least 1
(1

1
| ≤
η)-pure is at least 1

r (h)(˜x)

τ 2
2 nr(1

D(
|

f (˜y)

−
−

τ )(1

ρ)(1

φf

ρ)(1

2η

ǫ)

≥

−

−

2η

δ

∼

δ

−

−

e−

−

−

−

−

−

−

−

−

Theorem 2 follows from Lemma 1 with standard concentration inequalities (the proof is given

in the appendix). In addition, Theorem 2 is shown to be tight based on Lemma 2.

Lemma 1. Let h be a hypothesis satisfying P(˜x,˜y)
δ for some
0 < ǫ, δ < 1. Assume that the probability that a bag is (1
ρ for some
0 < η, ρ < 1. Then for that bag, the probability that h classiﬁes correctly at least a fraction
ρ).
(1

1
| ≤
η)-pure is at least 1

ǫ) of its instances is at least (1

r (h)(˜x)

D(
|

−
−

f (˜y)

φf

2η

ǫ)

−

≥

−

δ

∼

−

−

−

−

Lemma 2. There exists a distribution
f (˜y), each bag is (1

D

−

over all bags of size r and a learner h such that φf

r (h)(˜x) =

η)-pure but h misclassiﬁes a fraction 2η instances of each bag.

Lemma 2 also shows limitations of LLP. It is interesting to consider an extreme case, where all
the bags are with label proportion 50% (they are the least “pure”). Then there exists a hypothesis h
which can achieve zero bag proportion prediction error, yet with 100% instance label error. In other
words, it is hopeless to learn or recover the instance labels. This provides an interesting failure case
of LLP. In the appendix, we further show a case under generative assumptions, where EPRM fails
when all the bag proportions are the same and close to 50%. Such negative results worth further
study as they provide insights into “protecting” the instance labels when releasing label proportions.

6.2 Instances Are Conditionally Independent Given Bag

The purity result presented in the former section is without any assumptions on the way the bags
are formed. In this section, we consider the case where the instances are conditionally independent
given the bag. A lot of real-world applications follow this assumption. For example, to model the
voting behavior, each bag is generated by randomly sampling a number of individuals from certain
location. It is reasonable to assume that the individuals are iid given the location.

D

, a distribution over bags.

Formally, we assume that the bags are generated from

is a “mix-
ture” of multiple components D1, ..., DM , where each Di is also a distribution over bags. We
as ﬁrstly picking a distribution Di with some ﬁxed
consider the process of drawing a bag from
, M , there exists
probability ζi, and then generating a bag from Di. We assume for Di, i = 1,
an instance distribution D′i, such that generating a bag from Di is by drawing r iid instances from
D′i. Also assume that the priors P(x,y)
(yi = 1) = αi. We note ﬁrst that under the above as-
sumptions, the purity results in the former section can be utilized. For c > 0, the probability that
2rc2
,
a bag generated from the mixture of multiple components is (1
−
where η = maxi(min(αi, 1
αi)) + c. The proof is straightforward with Chernoff bound. One
disadvantage of the purity result is that it is only useful when αi,

η)-pure, is at least 1

i is not close to 1/2.

· · ·

e−

D′
i

−

−

D

D

∼

φf

f (˜y)

r (h)(˜x)

We can instead use the generative assumption to provide stronger results: under some mild as-
sumptions, the probability of making wrong label prediction β := P(h(x)
= y) can be expressed as
a function of P
. Let’s ﬁrst consider a special case, when all the instances
are drawn iid over a distribution of the instances. This is a special case of the generative model men-
(cid:1)
tioned above with only one component in
. In addition, we assume that the prior of the instances
can be matched by the hypothesis, i.e., P(h(x) = 1) = P(y = 1). This assumption is not too restric-
tive, as the small empirical bag proportion error already implies that the priors are approximately
matched, and for most learning models, we can adjust the hypothesis by a bias term to match the em-
pirical prior estimated on the training data. In such case, we can express P
ǫ

f (˜y)

(cid:0)(cid:12)
(cid:12)

φf

≤

−

D

(cid:12)
(cid:12)

ǫ

∀

r (h)(˜x)

−

(cid:0)(cid:12)
(cid:12)

≤

(cid:12)
(cid:12)

(cid:1)

OnLearningfromLabelProportions

6

 

r = 10
r = 15
r = 20
r = 25
r = 30
r = 35
r = 40
r = 45
r = 50
r = 100

1

0.8

0.6

0.4

0.2

0
 
0

|
(cid:0)

β

β

β

 

r = 1
r = 2
r = 3
r = 4
r = 5
r = 10
r = 15
r = 20
r = 25
r = 30
r = 35
r = 40
r = 45
r = 50

1

0.8

0.6

0.4

0.2

0
0

1

0.8

0.6

0.4

0.2

0
 
0

 

ε = 0.00
ε = 0.02
ε = 0.04
ε = 0.06
ε = 0.08
ε = 0.10

)
r
,
ǫ
(
u

1

0.8

0.6

0.4

0.2

0
 
0

0.2
P (|φf

0.8

0.4

0.6
r (h)(˜x) − f (˜y)| ≤ ǫ)
(a) ǫ = 0

1

0.2
P (|φf

0.4

0.6
r (h)(˜x) − f (˜y)| ≤ ǫ)

0.8

1

(b) ǫ = 0.1

0.2
P (|φf

0.4

0.8

0.6
r (h)(˜x) − f (˜y)| ≤ ǫ)
(c) r = 50

1

0.2 0.4 0.6 0.8
ǫ

1

(d) u(r, ǫ)

Figure 1: (a)-(c): Relationship of the probability of making wrong label prediction, β := P(h(x)
=
y), and the probability of bag proportion prediction error is small than ǫ, P
,
ǫ
under the assumption that the instances are drawn iid, and the prior can be matched by the
(cid:1)
hypothesis, i.e., P(h(x) = 1) = P(y = 1). β is a monotonically decreasing function of
P
(u(r, ǫ), 1]. u(r, ǫ) is shown in (d).
f (˜y)
−
Larger r and larger ǫ will result in larger u(r, ǫ).

r (h)(˜x)

r (h)(˜x)

r (h)(˜x)

, if P

f (˜y)

f (˜y)

|
(cid:0)

| ≤

| ≤

| ≤

φf

φf

φf

−

−

∈

ǫ

ǫ

|
(cid:0)

(cid:1)

(cid:1)

analytically as a function of β:

r

θi
2

r
i!

(cid:16)

i=0  
X

(cid:16)(cid:12)
(cid:12)
(cid:12)
where
the CDF of binomial distribution.

is the ﬂoor operator, θ1 = (2

⌊·⌋

(cid:12)
(cid:12)
(cid:12)

(cid:17)

−

P

φf

r (h)(˜x) − f (˜y)

≤ ǫ

= θr
1

F(i + ⌊ǫr⌋; r − i, θ2) − F(i − ⌊ǫr⌋ − 1; r − i, θ2)

,

β)/2, θ2 = β/(2

β), 0 < β < 1, 0 < ǫ < 1 and

is

(cid:17)

F

−
φf

ǫ

ǫ

(cid:1)

(cid:12)
(cid:12)

−

−

≤

≤

φf

φf

|
(cid:0)

f (˜y)

f (˜y)

f (˜y)

(cid:0)(cid:12)
(cid:12)
| ≤

r (h)(˜x)

r (h)(˜x)

r (h)(˜x)

, when P

As what we actually want is to bound β based on P

, we show the
“inverse” function in Figure 1. From the curves, we see that β is a monotonically decreasing function
(cid:1)
of P
(u(r, ǫ), 1]. u(r, ǫ) is shown in
Figure 1 (d). In other words, the instance label error can be controlled by the bag proportion error,
when the later is small. The results are of course the “tightest” under the above assumptions.

(cid:0)(cid:12)
(cid:12)
One important observation is that the curves are independent of P(y = 1). Therefore, the
analytical results can be directly applied to the case when the instances are conditionally independent
given the bag, under the assumption that P(x,y)
D′
i

∀
∼
= y) is approximately linear to the bag size r, when r is sufﬁciently large, and P

Our additional observations of Figure 1 are summarized below. From (b), the growth of β :=
P(h(x)
r (h)(˜x)
−
is close to 1. From Figure 1 (c), with large bag size (r = 50), the growth of β is approximately
quadratic to the proportion prediction error ǫ, when P

(h(x) = 1) = P(x,y)

is close to 1.

(y = 1),

f (˜y)

|
(cid:0)

φf

φf

D′
i

−

∈

i.

(cid:12)
(cid:12)

(cid:1)

∼

ǫ

ǫ

r (h)(˜x)

(cid:1)
6.3 Instances Are Drawn by Independent Bernoulli Variables

|
(cid:0)

−

| ≤

In this section, we focus on an alternative model, which essentially picks instances independently
from a ﬁnite set of instances to build the bags. This setting is relevant to most real-world applications.
For example, there are always a ﬁnite set of persons in a political survey. Our intuition is that if
the bags “cover” the space of the instances well, the instance labels (of all possible instances) are
relatively easy to be recovered.

Formally, we consider the following model for bag generation. Let X =

be the set
of all instances. For each instance xi, deﬁne an Bernoulli variable κi that determines whether the
instance will be picked, i.e.:

x1, ..., xn}

{

κi =

1
0

(cid:26)

if xi was selected to the bag,
otherwise.

Let pi = P(κi = 1). Note that κi are independent but not necessarily identically distributed. Denote
κ = (κ1, .., κn). We call the above model the κ-model. Note that in the κ-model, the bag size is
variable instead of being ﬁxed. The proof of the results is shown in the appendix.

f (˜y)

ǫ

| ≤

(cid:1)

OnLearningfromLabelProportions

7

{

ǫ)

· · ·

x1,

, xn}

be the set all the instances. Let maxi pi =

( 1
n ). Assume that
R/n for some R > 0. Let D be a distribution over bags such that drawing a bag from

Theorem 3. Let X =
mini pi ≥
D is by drawing a bag from the κ-model. Let h be a hypothesis such that P(˜x,˜y)
f (˜y)
δ > 0 and large enough R, h misclassiﬁes at most

δ, where r(˜x) is the size of ˜x. Let q = ǫ2(Pn

D(
|
−
pi) . Then, for small enough

O
The following corollary shows the result when the probabilities of the instances being drawn are
( 1
n ). In such case, the instances are iid, and the bags very well “cover” X.

uniform, and equal to
This is similar to one case studied in Section 6.2 when all instances are drawn iid.

(qn) instances of X.

φf
r(˜x)(h)(˜x)

i=1 pi)2
−

n mini pi(1

| ≤

O

O

≥

−

1

∼

{

x1, ..., xn}

( 1
Corollary 2. Let X =
n ).
Denote by ˆr the expected size of the bag, ˆr = np. Let D be a distribution over bags such that
drawing a bag from D is by drawing a bag from the above κ-model. Let h be a hypothesis such
that P(˜x,˜y)
δ. Then for small enough δ and large enough ˆr, h
∼
misclassiﬁes at most

1
(ǫ2ˆrn) instances of X.

be the set all the instances. Let p1 =

φf
r(˜x)(h)(˜x)

= pn = p =

D(
|

f (˜y)

| ≤

· · ·

ǫ)

O

−

≥

−

O

Similar to Section 6.2, the model has an analogous “conditionally-independent” version, where
we have a probability distribution on the set of sequences κ. In this setting we ﬁrst choose a sequence
κ and then use it to generate a particular bag. All the results we give above easily translate to this
more general setting. In addition, based on our proof in the appendix, it is also possible to generalize
the result to cases where dependencies between small subsets of instances exist.

7 Extending the Results to Variable Bag Size

For simplicity in our analysis, except Section 6.3, we assumed that all the bags were of size
r. In fact, all our results can be easily generalized to variable bag size. For the result on the bag
proportion error, Theorem 1 holds immediately by replacing r with the average bag size in training
¯r. This is based on the fact that the covering number bound holds (shown in the proof of Theorem 1
in the appendix) with average bag size [20]. For results on the instance label error, we can assume
that the bag size r is generated from some ﬁxed probability distribution independent of the instances.
Lemma 1 holds for any bag size. Theorem 2 holds immediately by replacing r with the expected bag
size ˆr, following the proof described in the appendixappendix. We can further bound the expected
bag size ˆr by the average bag size in training ¯r based on Chernoff bound: for any t > 0, with
probability at least 1
t, where m is the number of training bags. In addition, our
−
analysis with the generative assumptions (Section 6.2) holds for any bag size.

, ˆr > ¯r

2mt2

e−

−

8 Applications

LLP for privacy preserving learning algorithms. Data used by machine learning algorithms
is often very sensitive and therefore versions of the machine learning algorithms that achieve some
level of privacy are of much interest [8,11]. LLP can be very useful to provide data privacy. In a
nutshell, the LLP learner, only having access to the label proportions, sufﬁces to construct good-
quality machine learning structures. We provide preliminary discussions in the appendix.

Justifying LLP algorithms. Among the existing algorithms, our analysis is well aligned with
SVM
algorithms that implicitly utilize the EPRM framework. One algorithm in this category is
[25], which has been shown to give good performance. The objective of
SVM is to ﬁnd a large-
margin classiﬁer consistent with the label proportions, with the help of latent labels. The analysis of
Section 5 can be generalized to justify

SVM using margin-based analysis [26].

∝

∝

Learning with population proportions. Consider the scenario of modeling voting behavior
based on government released statistics: the government releases the population proportion (e.g.

∝

OnLearningfromLabelProportions

8

 

r = 1
r = 5
r = 30
r = 100

0.26

0.24

0.22

0.2

0.18

0.16

r
o
r
r
e
 
e
c
n
a
t
s
n
i
 
t
s
e
T

 

0.22

 

0.2

 

0.18

r = 1
r = 5
r = 30
r = 100

r
o
r
r
e
 
e
c
n
a
t
s
n
i
 
t
s
e
T

0.2

0.18

0.16

0.14

r = 1
r = 5
r = 30
r = 100

r
o
r
r
e
 
e
c
n
a
t
s
n
i
 
t
s
e
T

0.18

0.16

0.14

r = 1
r = 5
r = 30
r = 100

r
o
r
r
e
 
e
c
n
a
t
s
n
i
 
t
s
e
T

0.16

0.14

0.12

 
1
3
# Training instances (normalized)

4

2

5

0.12

 
1
3
# Training instances (normalized)

4

2

5

0.12

 
1
3
# Training instances (normalized)

5

2

4

0.1

 
1
3
# Training instances (normalized)

4

2

5

(a) IID

(b) Occupation

(c) Education

(d) Race

Figure 2: Predicting income based on census data. (a) All the instances are iid. (b)-(d) The instances
are conditionally independent given the bag, with title of each ﬁgure as its grouping attributes. The
number of training instances is equal-spaced in log-scale, with the smallest number 500, and the
largest number 50,000.

62.6% in New York voted for Obama in 2012 election) of each location, and we only have a subset
of randomly sampled instances for each location. Can LLP be applied to correctly predict labels of
the individuals? In such a scenario, EPRM can only minimize the proportion error in terms of the
population proportions, because the actual proportions of the sampled subsets are not available. We
r
can assume that a bag is formed by randomly sampling r instances
i=1 from a location
with a true (population) proportion p∗, which is released. The Chernoff bound ensures that the
ln(2/δ)/(2ǫ2),
sampled proportion is concentrated to the released population proportion: when r
with probability at least 1
ǫ. Therefore, with enough training bags, and enough
δ,
p∗
samples per bag, the generalization error can be bounded.

(xi, yi)
}

f (˜y)

| ≤

−

≥

−

{

|

9 A Case Study: Predicting Income based on Census Data

So far we have provided formal guarantees that under some conditions, labels of individual
instances can be learned or recovered. In this section, we conduct a case study to demonstrate the
feasibility of LLP on real-world data. The task is to predict individual income based on census
data, and label proportions. We use a dataset which covers a subset of the 1994 census data2. It
contains 32,561 instances (individual persons), each with 123 binary attributes about education,
marital status, sex, occupation, working hours per week etc. Each individual has a binary label
indicating whether his/her income > 50k. We consider this label as sensitive information, for which
we only know its proportions on some bags of people. Next we will show the feasibility of LLP
based on different ways of forming the bags. We ﬁrst divide the dataset to use 80% of the instances
for training, and 20% for testing. For all the experiments below, the bags are formed on the 80%
training data. The proportion of each training bag is computed based on the ground-truth labels.
SVM [25] with linear kernel, and ℓ1 loss. We use the algorithms
The experiments are based on
proposed in [19] and [18] as the initialization methods for the alter-
SVM solver. The parameters,
[0.01, 0.1, 1], are tuned on the bag proportion prediction error by performing
C
cross validation. We report mean and standard deviation of error on the test data based on 5 runs.

[0.1, 1, 10], Cp ∈
All instances are drawn iid. We ﬁrst simulate a simple case where all the instances are drawn
iid from a distribution of instances. We achieve this by assuming that all the instances of the dataset
form a “distribution” of individuals. For all the bags (with r instances), each instance is drawn by
randomly sampling the whole training set with replacement. Figure 2 (a) shows the experimental
results. Based on the results, more instances (bags) lead to lower test error. The relatively low
test error demonstrates the feasibility of LLP under such settings. Fewer training bags (and larger
training bag size) generally result in larger test error variance, as the algorithm is more likely to
converge to worse local solutions.

∝

∝

∈

Instances are conditionally independent given bag. We simulate the case by a “hierarchical

2http://archive.ics.uci.edu/ml/datasets/Adult

OnLearningfromLabelProportions

9

Grouping Attribute Native Country
Number of Bags
∝SVM Error %
Baseline Error %

41
18.75 ± 0.25
24.02 ± 0.56

Education
16
19.61 ± 0.10
22.29 ± 0.55

Occupation
15
18.19 ± 0.16
24.28 ± 0.28

Relationship
5
18.59 ± 0.82
24.19 ± 0.72

Race
5
24.02 ± 0.15
24.28 ± 0.40

Table 1: Error on predicted income based on census in a real-world setting.

bag generation” process. The individuals are ﬁrst grouped by a grouping attribute. For example, if
the grouping attribute is “occupation”, the individuals are groups into 15 groups, corresponding to
the 15 occupations. Each group is assigned a prior, which is simply uniform in this experiment. To
generate a bag of r instances, we ﬁrst pick a group based on the priors, and then perform random
sampling with replacement r times in the selected group. Figure 2 (b)-(d) show the experiment
results. The trend of the learning curves is the same as in Figure 2 (a), showing that LLP is indeed
possible in such a setting.

A challenging real-world scenario. For real-world applications, the bags are predeﬁned rather
than “randomly” generated. In this experiment, we simply group the individuals deﬁned by different
grouping attributes. Different from the setting in the former section, the whole group is treated as a
single bag, without further sampling process. Table 1 shows the performance of LLP. The “Baseline”
result is formed by the following: a new instance is predicted positive if the training bag with
the same grouping attribute has proportion larger than 50%; otherwise it is predicted as negative.
For example, it predicts a person with elementary education as negative, as the label proportion
of elementary education group is less than 50%. For most experiments, this result is similar to
assigning +1 to all test instances, because most training bags are with proportion larger than 50%.
This scheme provides performance gain for “education”, as the label proportion for individuals with
very low education is also very low. We ﬁnd that for most grouping attributes, the performance of
LLP signiﬁcantly improves over the baseline. This is also true for some cases where the number
of bags is very small. We do observe that for certain way of forming the bags, e.g., by Race, the
improvement is not that big. This is due to the fact that the instance distributions of the bags are
very similar, and therefore most of the bags are redundant for the task.

10 Conclusion

This paper proposed a novel two-step analysis to answer the question whether the individual
labels can be learned when only the label proportions are observed. We showed how parameters such
as bag size and bag proportion affect the bag proportion error and instance label error. Our ﬁrst result
shows that the generalization error of bag proportions is only mildly sensitive to the size of the bags.
Our second result shows that under different mild assumptions, a good bag proportion predictor
guarantees a good instance label predictor. We have also demonstrated the feasibility of LLP based
on a case study. As the future work, data dependent measure, e.g., Rademacher complexity [3], may
lead to tighter bound for practical use. Some alternative tools, e.g., sample complexity results of
learning
-valued functions [13], can be used for analyzing the generalization error of bag
proportions. The failure cases of LLP worth further study as they can be utilized to protect sensitive
personal information when releasing label proportions.

0, ..., n

}

{

11 Appendix

11.1 Proof Sketch of Theorem 1

One important tool used in the proof is the lemma below bounding the covering number of bag

proportion hypothesis class φf
r (

) by the covering number of the instance hypothesis class

.

H

H

OnLearningfromLabelProportions

10

Lemma 1. [20,21] Let r
∈
some αf > 0. Let γ > 0, p

N and suppose f : Rr
[1,

], and

→
RX . For any m

R is α-Lipschitz w.r.t. the inﬁnity norm, for

∈
∞
Np(γ, φf
r (

H

H ∈
), m)

≤ Np(

γ
αf r1/p ,

H

, rm).

0,

≥

Covering number [1] can be seen as a complexity measure on real-valued hypothesis class.
The larger the covering number, the larger the complexity. Another lemma we use is the uniform
convergence for real function class.
Lemma 2. [1]. Let ˆ
ˆ
Y
Y
ﬁrst argument with Lipschitz constant αL > 0. Let D be any distribution on
0 < ǫ < 1 and g

[0, 1], such that L is Lipschitz in its
. Then for any

X , and L : ˆ

Y × Y →

X × Y

Y ⊆

G ⊆

R,

:

,

∈ G

PS

Dm

∼

(cid:18)
S (g) = 1
S
|

|

sup
g
∈G (cid:12)
(cid:12)
x
∈

in which erL

1:

erL

D(g)

erL

S (g)

−

ǫ

≥

4

N1(ǫ/(8αL),

G

≤

, 2m)e−

mǫ2/32,

(cid:19)
(cid:12)
(cid:12)
D(g) = Ex
S L(g(x), y), erL

DL(g(x), y).

∼

N1(ǫ, W, m)

≤ N∞

Based on the deﬁnition of covering number:

P

(ǫ, W, m). Applying Lemma

4

N1(ǫ/(8αL),

H

, 2m)e−

mǫ2/32

, 2m)e−

mǫ2/32

4

4

≤

N∞

≤

N∞

(ǫ/(8αL),

H
(ǫ/(8αLαf ),

H

, 2rm)e−

mǫ2/32.

(5)

Also, the proportion generation function f in our case is 1-Lipschitz with the inﬁnity norm. And the
loss functions L we are considering is 1-Lipschitz.
Based on the deﬁnition of covering number, for

X , for any ǫ < 2,

1, 1

(ǫ,

, d

) =

N

xm
1

H|

∞

. Thus,

|H|

xm
1 |

H ⊆ {−

}

(ǫ,

, m) = Π

(m).

H
Refer to [1] for the deﬁnition of restriction

N∞

(m). In addition, we
H|
have the following lemma to to bound the growth function by VC dimension of the hypothesis class.

and growth function Π

xm
1

H

H

Lemma 3. [22] Let

1, 1

X with VC(

) = d

. For all m

G ⊆ {−

}

G

≤ ∞

d, Π
G

(m)

≥

≤

em
d

d.

d
i=0

m
i

≤

P

(cid:0)

(cid:1)

(cid:0)

Let d = V C(
(cid:1)

). By combining the above facts, and 0 < ǫ < 1, (5) leads to

H

Therefore, with probability at least 1

δ,

4Π

(2rm)e−

H

mǫ2/32

2erm
d

d

(cid:19)

4

≤

(cid:18)

e−

mǫ2/32.

erL

D(f )

erL

S (f ) +

≤

−

32
m

(cid:18)

(d ln(2emr/d) + ln(4/δ))

1/2

(cid:19)

m

≤

32
ǫ2 (d ln m + d ln(2er/d) + ln(4/δ)).

Since ln x

ax

≤

−

⇐
ln a

1 for all a, x > 0, we have

m + ln

ǫ2
64d

−
32d
ǫ2 ln m
m
2
64
ǫ2 (2d ln(12r/ǫ) + ln(4/δ)).

32d
ǫ2
≤
(cid:19)(cid:19)
32
ǫ2 (d ln(128r/ǫ2) + ln(4/δ)).

64d
ǫ2

+

≥

(cid:18)

(cid:18)

≥

m

m

⇐

⇐

⇐

m
2

+

32d
ǫ2 ln

≤

64d
eǫ2

.

(cid:19)

(cid:18)

OnLearningfromLabelProportions

11

11.2 Appendix of Section 6.1

Proof of Lemma 1
Let ˜x = (x1, ..., xr) be a bag. Assume that

r (h)(˜x)

φf
|
1, ..., r
}
1, ..., r
}
)/r.

−

f (˜y)
: h(xi) =
: h(xi) =

| ≤
1
−

ǫ. Denote
yi = +1
yi =

i
i

A1 =
∈
,
A3 =
∈
}
. We have:
1
}
−

{
{

,
,

|

−

+

∧
1

{
{
+

1, ..., r
{
}
1, ..., r
{
}
φf
r (h)(˜x) = (

: h(xi) = +1
: h(xi) = +1
|A1|
−
η)-pure. Without loss of generality we can assume that

yi =
1
}
∧
yi = +1
}
∧
)/r, f (˜y) = (
|A3|
φf

A2 =
A4 =
|A2|
r (h)(˜x)

i
∈ {
i
∈ {
|A3|
f (˜y)

ǫ, we have:

ηr. Thus we also have that

Thus, from the assumption:

ǫr. Assume
||A1| − |A2|| ≤
that ˜x is (1
ηr. This
−
implies that
(η + ǫ)r. Hypothesis h correctly classiﬁes
|A1| ≤
instances of the bag ˜x. From what we have just derived, we conclude that h correctly
+
|A3|
|A4|
ǫ)r instances of the bag ˜x. So far in the analysis above we assumed that:
classiﬁes at least (1
φf
η)-pure. From the statement of the theorem we know that the
|
former happens with probability at least 1
ρ. Thus,
by the union bound, we know that with probability at least 1
ρ, h classiﬁes correctly at least
ǫ) instances of the bag drawn from the distribution
(1

δ and the latter with probability at least 1

2η
ǫ and ˜x is (1

|A4| ≤

|A2| ≤

r (h)(˜x)

−
| ≤

|A1|

f (˜y)

| ≤

2η

δ
.

−

+

−

−

−

−

−

−

∧

−

−
Proof of Theorem 2
Denote θ = 2η + ǫ, p = δ + ρ. Let Z be a random variable deﬁned as follows:

−
D

θ)r

(1
0

−

with probability 1
with probability p

−

p,

Z =

(cid:26)

p)(1

Denote by Zi for i = 1, 2, ..., m the ith independent copy of Z. Lets Zsum = Z1 + ... + Zn. Note
that, according to Lemma 1, Z is the lower bound on the number of instances from m bags that
are correctly classiﬁed We have µ = EZsum = nr(1
θ). From Chernoff’s inequality
τ 2
we immediately get: for 0 < τ < 1, P(Zsum < (1
2 µ. Thus we conclude that
e−
θ) the hypothesis h classiﬁes correctly at least a fraction
with probability at least 1
(1

θ) of all nr instances coming in n bags.

−
Proof of Lemma 2
Assume that the bags are selected in such a way that ﬁrst ηr instances have label +1, next ηr
2η)r instances have label +1. Assume furthermore that the hypothesis
yi for every instance xi from the list of ﬁrst 2ηr instances of the bag and
2η)r instances from the list. Then of course the classiﬁer always

have label
h satisﬁes: h(xi) =
satiﬁes: h(xi) = yi for last (1
misslassiﬁes ﬁrst 2η instances of each bag but predicts bag proportions with 0 error.

1 and last (1

τ 2
2 nr(1

τ )µ)

τ )(1

p)(1

e−

p)(1

≤

−

−

−

−

−

−

−

−

−

−

−

−

11.3 Appendix of Section 6.3

Proof of Theorem 3
The theorem follows from the following more general technical theorem that we will prove ﬁrst.

Note that we treat the labels as 0/1 for simplicity in this section.

, hn) be two sequences of 0s and 1s. Denote η =
Theorem 4. Let (y1,
Pn
hi
. Let 0 < ǫ < 1. Let p = maxi pi. Let v = mini=1,...,n V ar(κi). Let ρ(x) =
|
et(log(np)+1)
. As-
e(t+ 1

yi
i=1 |
n
n
t=√xηnv

. Assume that: xρ(x)

, yn) and (h1,

0 as x

0 as x

and

· · ·

· · ·

−

)t

2

→

x ρ(x)
∞
for some constant ∆ > 0. Then the following is true for
R
hi)

big enough:

→ ∞

→ ∞

→

sume furthermore that η
P
∆, n big enough, and

∆ǫ2(Pn

≥
n
i=1 V ar

i=1 Eκi)2
nv
κi(yi −

P

(cid:0)

Pκ=(κ1,...,κn)

n

(cid:1)
κi(yi −

i=1
X

 (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

>

κiǫ

> ξ

!

n

i=1
X

hi)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

for some constant ξ(∆) that does not depend on η and ǫ.

OnLearningfromLabelProportions

12

Proof
Denote Xi = κi(yi −

hi), X =

Notice that we have: EY = V ar(X) =
n
the probability p1 = Pκ=(κ1,...,κn)[
(we will show later how to choose C).
P

P
|

n

EXi, Z =

EX)2.
n
i=1 V ar(Xi). First we want to ﬁnd a lower bound on
V ar(Z)] for some constant C > 0

n
i=1 Zi and Y = (X

i=1 Xi, Zi = Xi −
hi)
i=1 κi(yi −
P
|

> C

P

−

p
C
| ≤
> 2C

|

|

−

EX

|
EX

Let us consider two cases. In the ﬁrst case we have:

V ar(Z). So it only sufﬁces
to ﬁnd a lower bound on the probability p2 = P[
V ar(Z)], because trivially:
X
p2. Let α, β > 0 (α < β) be two positive constants (we will see later how to choose the values
p1 ≥
of α and β). To ﬁnd a lower bound on p2 we partition the probability space Ω into three subspaces:
Ω1, Ω2, Ω3. Let us deﬁne: Ω1 =
,
βV ar(Z)
}
C).
Ω3 =
Y > βV ar(Z)
}
Let us ﬁrst consider the expression: P[C]E(Y
C) and lets ﬁx some α > 0. We want to show that for
β large enough we have: P[C]E(Y
C) < αV ar(Z). So we want to prove that for β large enough
] < αV ar(Z). The latter inequality is equivalent to
the following is true: E[Y I
Y > βV ar(Z)
}
] < α. Let us denote Dn =
the following one: E[
. We want to
V ar(Z) > β
}
Dn|

] < α. Let us ﬁrst bound the expression P[

Y < αV ar(Z)
}
P[A]E(Y

≤
A) + P[B]βV ar(Z) + P[C]E(Y

{
Y
V ar(Z) I
n > β

. We trivially have: EY

Z
√V ar(Z)

αV ar(Z)

, Ω2 =

p
p

≤

≤

Y

{

{

{

}

{

n

Y

|

|

|

|

|

1 and that different Xi are independent. Thus we have: P[Dn > x]

i=1(Xi −

EXi)

≥

> x] for an arbitrary
x√ηnv]. Now notice that each Xi is
pt, where

show that E[D2
D2
nI
{
x > 0. Notice that P[Dn > x] = P[
either 0, 1 or
−
t = x√ηnv. Thus we get that:

P

≤

n
t

(cid:0)

(cid:1)

P[Dn > x]

(np)t
t!

≤

= O(

et log(np)+t
e(t+ 1
2 ) log(t)

)

where the last relation follows immediately from Stirling’s formula. Thus we have:

E[

Y
V ar(Z)

I

{

Y
V ar(Z)

}

> β

] = βP[D2

n > β] +

∞

P[D2

n > x]dx = o(1)

β
Z

|

|

α

≤

→ ∞

A) + P[B]βV ar(Z) + P[C]E(Y

), where the last relation follows from our assumptions on
(i.e. the expression goes to 0 as x
ρ(x) and the upper bound on the value of P[Dn > x] that we have just derived. We can conclude
that for β large enough we have: P[C]E(Y
C) < αV ar(Z). Now, if we go back to the formula:
P[A]E(Y
C) and notice that EY = V ar(Z), then from
EY
the fact that P[C]E(Y
β . Taking arbitrary 0 < α < 1
2
|
4 we see that: P[B]
and C =
V ar(Z)]. Thus we have proved that
δ for some constant δ > 0 that does not depend on η and ǫ. That
δ and therefore also p1 ≥
p2 ≥
was however under an assumption that
|
> C
EX

V ar(Z). Without loss of generality we can assume that
EX > 0. In this case we will prove that P[
V ar(Z)] < δ for some 0 < δ < 1
−
that does not depend on η and ǫ. We can proceed as before, using our upper bound on P[Dn > x],
to conclude that P[Dn < C

C) < αV ar(Z), we obtain: P[B]
> 2C
X

2 ] < δ for some 0 < δ < 1. Thus we have proven that

Now let us assume that

p
V ar(Z).

p
EX

< C
2

EX

EX

| ≤

P[

p

p

p

X

≤

−

≥

C

2α

−

1

|

|

|

|

|

|

|

Pκ=(κ1,...,κn)[

κi(yi −

hi)
|

>

V ar(Z)] > δ

n

|

i=1
X

C
2

p

for some 0 < δ < 1 which does not depend on η and ǫ.

Denote T = C

2 . Now we will upper-bound the probability that ǫ

V ar(Z).
V ar(Z) (see: asumptions of
One can easily check that we can assume that: ǫ
the theorem, V ar(Z) is large enough). Now, using standard concentration inequalities such that
Chernoff’s inequality and again the assumptions of the theorem, it is easy to verify that the latter
probability can be bounded by the negligible function of R. That obviously completes the proof.

i=1 Eκi ≤

i=1 κi ≥

P

P

p

p

T
2

T

n

n

Proof of Theorem 3

OnLearningfromLabelProportions

13

n

We can proof Theorem 3 by contradiction. Note ﬁrst that the conditions put on the function
ρ(x) from Theorem 4 are trivially satisﬁed under our assumptions on the κ-model. Let
x1, ..., xn}
be a test set. Without loss of generality we can assume that ξ is as in δ of Theorem 3 in the main
of the
text. Denote h(xi) = hi. Take the groundtruth labels
y1, ..., yn}
n
i=1 κiǫ is equivalent to saying that the proportion prediction on the
form
>
bag coming according to the κ-model was not within error ǫ from the groundtruth. If we now take
the constant ∆ > 0 for which Theorem 4 holds and assume by contradiction that the instance label
classiﬁer misclassiﬁed at least ηn points from the test set for η = ∆ǫ2(Pn
i=1 Eκi)2
n mini=1,...,n V ar(κi) then we
conclude that the probability of
pi).
Taking ξ to be smaller than ξ(∆) from Theorem 4 completes the proof.

is more than ξ. Note that Eκi = pi, and V ar(pi) = pi(1

. Note that an event

i=1 κi(yi −

hi)
|

P

P

−

E

E

{

{

|

11.4 Private Learning with Label Proportions

(6)

(7)

We provide preliminary discussions on the usefulness of LLP in several settings where privacy
guarantees are required. We will ﬁrst deﬁne an important notion of differential privacy. Below we
give all necessary deﬁnitions involving differential privacy and some of its properties. One can think
about differential privacy as a mechanism that, if applied to a given database-access mechanism,
guarantees small changes in the output as long as the database does not substantially change.

satisﬁes ǫ-differential-privacy if for all databases

Deﬁnition 2 ([10]). A randomized algorithm
D1 and

D2 differing on at most one element, and all S
exp(ǫ)
D1) = S]
(

≤
The probability is taken over the coin tosses of

P r[

M

M

.

·

M

Range(

),

∈
P r[

M
D2) = S].
(

M

Smaller values of ǫ mean stronger privacy guarantees. If f is a function and

aims to compute
a differentially-private version of f , it can achieve it by adding noise with the magnitude adjusted to
the sensitivity of f .

M

Deﬁnition 3 ([10]). The global sensitivity S(f ) of a function f is the smallest number s such that
for all

D1 and

D2 which differ on at most one element,
D2)

D1)

f (

f (

|

s.

−
Let Lap(0, λ) denote the Laplace distribution with mean 0 and standard deviation λ.

| ≤

Theorem 5 ([10]). Let f be a function on databases with range Rm, where m is the number of rows
of databases. Then, the mechanism that outputs f (
) + (Y1, . . . , Ym), where Yi are drawn i.i.d from
Lap(0, S(f )/ǫ), satisﬁes ǫ-differential-privacy.

D

Differential privacy is preserved under composition, but with an extra loss of privacy for each

conducted query.

Theorem 6 ([10]). (Composition Theorem) The sequential application of mechanisms
giving ǫi-differential privacy, satisﬁes

i ǫi-differential-privacy.

Mi, each

P

Differential privacy is one of the strongest notions of privacy that is being applied in many
In this section we show how learning from label
different scenarios, also in machine learning.
proportions can make some existing differentially-private machine learning algorithms even more
secure. The mechanism proposed by us below may serve as a new paradigm for constructing them.
The overall scheme of constructing differentially-private algorithm usually reduces to two steps.
In the ﬁrst step data is used to construct some machine learning structure. Then this structure with
a partial information obtained from the data is being published. Publishing just partial information
enables to get differentially-private guarantees and very often means outputting some proportions

OnLearningfromLabelProportions

14

regarding data. For example, in the random decision tree approach (see: [12], [14]) for every leaf
of the tree the perturbated counts of items with particular labels are being released. Then the pro-
portions of those items determine the classiﬁcation of the test data point. It should be mentioned
however that in the ﬁrst phase the algorithm producing those proportions has an access to all the data
and stores it explicitly in the structure under construction. This phase can take signiﬁcant amount
of time and during this period the structure is usually very vulnerable to different attacks aiming to
compromise privacy.

Note however that since very often the only information involving labels that needs to be released
is the proportions of items with different labels, we can use the classiﬁer that learns the proportions
to construct the structure in the ﬁrst phase. We feed the learner with bags of data without releasing
the actual mapping from instances to their labels. The information, quantized in those bags, is then
used by the learner to compute good approximations of the proportions and will be later published
in a differentially-private way (usually by adding Laplacian noise).

This scheme is more secure than a standard approach since even the algorithm that constructs
differentially-private structure does not know labels of data points it is receiving – It only knows
proportions. So even though the ﬁrst phase of the algorithm is deﬁnitely not differentially-private
(since the algorithm still receives unperturbated data points), it can be easily proven that it achieves
k-anonymity. We should note that in the standard approach the ﬁrst phase did not give any privacy
guarantees.

At the very end we would like to show quantitatively that differential privacy mechanism is
a natural candidate for making private the algorithms that heavily rely on proportions of counts
to classify points. Among those algorithm are those involving random decision trees or random
projection trees [7,14].

−

−

S

−

2 e−|

+, np

with label

k ). Let ﬁx a set

+ = n+ + g1 and np

−
and np = np

k ), where k is the number of all sets

Without loss of generality we will assume that we have 2-labels setting. Let

be a set of ob-
. The
1. Denote n = n+ + n
jects consisting of n+ instances with label +1 and n
by adding Laplacian noise indepen-
differentially-private mechanism perturbates counts: n+, n
−
dently to each of them to obtain: np
+ + np
. Denote by g(λ) the Laplacian variable
−
with pdf: λ
λ. The key observation now is that the sensitivity of each count is only 1. Therefore
x
|
it sufﬁces to add a Laplacian g( η
under consideration (we as-
are pairwise disjoint) and η is a desired differential privacy parameter of the entire
sume that sets
S
algorithm. Thus we have: np
+ g2, where each gi has the distribution as
−
g( η
. Random variable X measures the difference
between the actual proportion and the one output by the differentially-private mechanism. We have:
. Now one can easily check that for ﬁxed η, k, δ, θ > 0 and number of instances
X
) |
n large enough we have: P(X > θ)
δ. Thus, by Azuma’s inequality, with probability at least
all but at most a fraction δ + ǫ of all output proportions are within distance θ from their
1
nonperturbated versions. This means that in practice most of the proportions will be very close to
their nonperturbated versions and explains why differential privacy is a good scalable tool in this
setting. The learner that accurately learns label proportions can make this setting even more se-
cure. It can output proportions close to original without having a straightforward information about
the mapping between the instances used to construct differentially-private structure and their labels.
Those proportions can be then perturbated and published.

−
n++g1
n+g1+g2 −

n+g2
g1n−
−
n2(1+ g1+g2

. Denote: X =

= n
n+
n |

≤ |

2kǫ2

e−

≤

−

S

S

|

n

References

[1] Martin Anthony and Peter L Bartlett. Neural network learning: Theoretical foundations. Cam-

bridge University Press, 2009.

[2] Boris Babenko, Nakul Verma, Piotr Doll´ar, and Serge J Belongie. Multiple instance learning
with manifold bags. In Proceedings of the 28th International Conference on Machine Learn-
ing, pages 81–88, 2011.

OnLearningfromLabelProportions

15

[3] Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds

and structural results. The Journal of Machine Learning Research, 3:463–482, 2003.

[4] Avrim Blum and Adam Kalai. A note on learning from multiple-instance examples. Machine

Learning, 30(1):23–29, 1998.

[5] B.C. Chen, L. Chen, R. Ramakrishnan, and D.R. Musicant. Learning from aggregate views.
In Proceedings of the 22nd International Conference on Data Engineering, pages 3–3. IEEE,
2006.

[6] T. Chen, F. X. Yu, J. Chen, Y. Cui, Y.-Y. Chen, and S.-F. Chang. Object-based visual sentiment

concept analysis and application. In ACM Multimedia, 2014.

[7] A. Choromanska, K. Choromanski, G. Jagannathan, and C. Monteleoni. Differentially-private
learning of low dimensional manifolds. In International Conference on Algorithmic Learning
Theory, pages 249–263, 2013.

[8] Krzysztof Choromanski, Tony Jebara, and Kui Tang. Adaptive anonymity via b-matching. In

Advances in Neural Information Processing Systems, pages 3192–3200, 2013.

[9] Thomas G Dietterich, Richard H Lathrop, and Tom´as Lozano-P´erez. Solving the multiple
instance problem with axis-parallel rectangles. Artiﬁcial Intelligence, 89(1):31–71, 1997.

[10] C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating noise to sensitivity in private

data analysis. TCC, pages 265–284, 2006.

[11] Cynthia Dwork. Differential privacy. In Automata, languages and programming, pages 1–12.

Springer, 2006.

[12] W. Fan, H. Wang, P.S Yu, and S. Ma. Is random model better? on its accuracy and efﬁciency.

ICDM 2003, pages 51–58, 2003.

[13] David Haussler and Philip M Long. A generalization of Sauer’s Lemma. Journal of Combina-

torial Theory, Series A, 71(2):219–240, 1995.

[14] G. Jagannathan, K. Pillaipakkamnatt, and R. N. Wright. A practical differentially private

random decision tree classiﬁer. Transactions on data privacy, pages 273–295, 2012.

[15] Hendrik Kuck and Nando de Freitas. Learning about individuals from group statistics.

In
Proceedings of the 21st Conference on Uncertainty in Artiﬁcial Intelligence, pages 332–339.
AUAI Press, 2005.

[16] K.-T. Lai, F. X. Yu, M.-S. Chen, and S.-F. Chang. Video event detection by inferring temporal

instance labels. In Computer Vision and Pattern Recognition, 2014.

[17] D.R. Musicant, J.M. Christensen, and J.F. Olson. Supervised learning by training on aggregate
outputs. In Proceedings of the 7th International Conference on Data Mining, pages 252–261.
IEEE, 2007.

[18] N. Quadrianto, A.J. Smola, T.S. Caetano, and Q.V. Le. Estimating labels from label propor-

tions. The Journal of Machine Learning Research, 10:2349–2374, 2009.

[19] S. R¨ueping. SVM classiﬁer estimation from group probabilities. In Proceedings of the 27th

International Conference on Machine Learning, 2010.

[20] Sivan Sabato. Partial Information and Distribution-Dependence in Supervised Learning
Models. PhD thesis, School of Computer Science and Engineering, Hebrew University of
Jerusalem, 2012.

OnLearningfromLabelProportions

16

[21] Sivan Sabato and Naftali Tishby. Multi-instance learning with any hypothesis class. Journal

of Machine Learning Research, 13:2999–3039, 2012.

[22] Norbert Sauer. On the density of families of sets. Journal of Combinatorial Theory, Series A,

13(1):145–147, 1972.

[23] Vladimir N Vapnik and A Ya Chervonenkis. On the uniform convergence of relative frequen-
cies of events to their probabilities. Theory of Probability & Its Applications, 16(2):264–280,
1971.

[24] F. X. Yu, L. Cao, M. Merler, T. Chen, J.R. Smith, and S.-F. Chang. Modeling attributes from

category-attribute proportions. In ACM Multimedia, 2014.

[25] F. X. Yu, D. Liu, Sanjiv K., T. Jebara, and S.-F. Chang.

SVM for learning with label propor-

tions. In Proceedings of the 30th International Conference on Machine Learning, 2013.

∝

[26] Tong Zhang. Covering number bounds of certain regularized linear function classes. The

Journal of Machine Learning Research, 2:527–550, 2002.

5
1
0
2
 
b
e
F
1
1
 
 
]
L
M

 

.
t
a
t
s
[
 
 
2
v
2
0
9
5
.
2
0
4
1
:
v
i
X
r
a

On Learning from Label Proportions

Felix X. Yu∗1, Krzysztof Choromanski3, Sanjiv Kumar3,
Tony Jebara2, and Shih-Fu Chang1

1Department of Electrical Engineering, Columbia University
2Department of Computer Science, Columbia University
3Google Inc.

Abstract

Learning from Label Proportions (LLP) is a learning setting, where the training data is pro-
vided in groups, or “bags”, and only the proportion of each class in each bag is known. The
task is to learn a model to predict the class labels of the individual instances. LLP has broad
applications in political science, marketing, healthcare, and computer vision. This work answers
the fundamental question, when and why LLP is possible, by introducing a general framework,
Empirical Proportion Risk Minimization (EPRM). EPRM learns an instance label classiﬁer to
match the given label proportions on the training data. Our result is based on a two-step analysis.
First, we provide a VC bound on the generalization error of the bag proportions. We show that the
bag sample complexity is only mildly sensitive to the bag size. Second, we show that under some
mild assumptions, good bag proportion prediction guarantees good instance label prediction. The
results together provide a formal guarantee that the individual labels can indeed be learned in the
LLP setting. We discuss applications of the analysis, including justiﬁcation of LLP algorithms,
learning with population proportions, and a paradigm for learning algorithms with privacy guar-
antees. We also demonstrate the feasibility of LLP based on a case study in real-world setting:
predicting income based on census data.

1 Introduction

A lot of information of individuals is released in the form of group label proportions. For exam-
ple, after election, the proportions of votes of each demographic area are released by the government.
In healthcare, the proportions of diagnosed diseases of each ZIP code area are available to public.
Is it possible to learn a model to predict the individual labels based on only the group-level label
proportions? Recent works in a machine learning setting called Learning from Label Proportions
(LLP) tried to study this problem. In LLP, the training instances are provided as groups, or “bags”.
In this work, we consider a binary learning setting: for each bag, only the proportion of the posi-
tive instances is available. The task is to learn a model to predict the labels of individual instances.
It is shown that by combining the label proportions with instance-level attributes, models capable
of correctly predicting instance labels can be learned [18,19,25]. As non-conﬁdential attributes of
individuals can be easily acquired from census survey, digital footprint, shopping history etc., LLP
leads to not only promising new applications, but also serious privacy concerns as releasing label
proportions may result in the discovery of sensitive personal information. Recently, LLP has also
been applied in visual attribute modeling [6,24] and event detection [16] in computer vision.

This work studies when and why individual labels can be learned from label proportions, by
analyzing a general framework, namely Empirical Proportion Risk Minimization (EPRM). EPRM

∗yuxinnan@ee.columbia.edu

OnLearningfromLabelProportions

2

optimizes the instance-level classiﬁer to minimize the empirical proportion loss. In other words, it
tries to ﬁnd an instance hypothesis to match the given label proportions. The main contribution of
this paper is a formal guarantee that under some mild assumptions, the individual instance labels can
be recovered (learned), with the EPRM framework. Speciﬁcally, we provide a two-step analysis.

Our ﬁrst result bounds the generalization error of bag proportions by the empirical bag propor-
tion error (Section 5). We show that the sample complexity is only mildly sensitive to the bag size.
In other words, our analysis shows that given enough training bags, it is possible to learn a bag pro-
portion predictor, which generalizes well to unseen bags. This conclusion in itself is interesting as
in some applications we are simply interested in getting good proportion estimates for bags: doctors
may want to predict the rate of disease on certain geographical area, and companies may want to
predict attrition rate of certain department.

Second, we show that under some mild conditions, the instance label error can be controlled
by the bag proportion error (Section 6). In other words, “good” bag proportion predictions imply
“good” instance label predictions. This ﬁnding is more crucial. For example, from privacy point of
view, the ability to learn a good instance label predictor given label proportions can be of concern.
In addition, we discuss using LLP to increase the privacy level of algorithms that aim to con-
struct private preserving machine learning structures. We also discuss applying the analysis into
justifying LLP algorithms, and LLP in some real-world cases (Section 8). Finally, we demonstrate
the feasibility of LLP in a case study: predicting income based on census data (Section 9).

2 Related Works

Algorithms for LLP. In their seminal work, [18] proposed to estimate the mean of each class
using the mean of each bag and the label proportions. These estimates are then used in a conditional
exponential model to maximize the log likelihood. The algorithm is under a restrictive assumption
that the instances are conditionally independent given the label. [19] proposed to use a large-margin
regression method by assuming the mean instance of each bag having a soft label corresponding
to the label proportion. As an extension to multiple-instance learning, [15] designed a hierarchical
probabilistic model to generate consistent label proportions. Similar ideas have also been shown
in [5] and [17]. A recently proposed
SVM algorithm [25] explicitly models the latent unknown
instance labels together with the known group label proportions in a large-margin framework. Dif-
ferent from the above works, this paper provides theoretical results addressing when and why bag
proportion and instance labels can be learned. Our result is independent of the algorithms.

∝

Multiple Instance Learning. A related, yet more extensively studied learning setting is Multiple
Instance Learning (MIL) [9]. In MIL, the learner has access to bags, with their labels generated by
the Boolean OR operator on the unobserved instance labels, i.e., a bag is positive iff it has at least
one positive instance. The task is to learn a binary predictor for the bags. It has been shown that if all
the instances are drawn iid from a single distribution, MIL is as easy as learning from iid instances
with one-sided label noise [4]. In real-world applications, the instances inside each bag can have
arbitrary dependencies, or even a manifold structure. The learnability and sample complexity results
in the above scenarios are given by [20,21], and [2], respectively. In this paper, we use the tools in
[20] to analyze the generalization error of bag proportions. More importantly, we show that under
some conditions, a good bag proportion predictor implies a good instance label predictor.

3 The Learning Setting: Learning from Label Proportions

Denote by

the domain of instance attributes, and denote by

the instance labels. Each bag, consisting of the instance attributes ˜x = (x1,
corresponding labels ˜y = (y1,

the domain of
, xr) and their
, yr), is generated iid by a probability distribution D over bags

}
· · ·

1, 1

{−

=

X

Y

· · ·

OnLearningfromLabelProportions

3

)r.1 Here, r is the bag size. For simplicity, we assume that the bags are of the same size.

(
X × Y
Our result can be easily generalized to bags with variable sizes as described in Section 7.

The learner does not have access to the instance labels. Instead it receives (˜x, f (˜y)), where,

R, is the proportion generation function. In learning with label proportions,

f :

r

Y

→

f (˜y) =

r

1
r

i=1
X

yi + 1
2

.

(1)

m
k=1,

H ⊆ Y

X to denote a hypothesis class on the instances. The learning task is to ﬁnd an h

Let the training set received by the learner be a set of m bags with their proportions S =
(˜xk, f (˜yk))
}
in which ˜xk and ˜yk are the instances and the (unobserved) labels for the k-th bag, respectively. We
use
∈ H
which gives low prediction error for unseen instances generated by the above process. In the con-
ventional supervised learning, where all the labels of the training instances are known, a popular
framework is the Empirical Risk Minimization (ERM), i.e. ﬁnding the instance hypothesis h
∈ H
to minimize the empirical instance label error. In LLP, however, the instance labels are not available
at the training time. Therefore, we can only try to ﬁnd h
to minimize the empirical proportion
error.

∈ H

{

4 The Framework: Empirical Proportion Risk Minimization

X

→

∈ H

r (h) :

r (h)(˜x) := f

Deﬁnition 1. For h
R, φf
r
φf
the hypothesis class on the bags φf
r (
(cid:0)(cid:0)

, deﬁne an operator to predict bag proportion based on the instances
, xr). And therefore

, h(xr)
h
r (h)
|
The Empirical Proportion Risk Minimization (EPRM) selects the instance label hypothesis h
∈
to minimize the empirical bag proportion loss on the training set S. It can be expressed as follows.

X r, ˜x = (x1,

h(x1),
) :=

· · ·
φf
{

(cid:1)(cid:1)
∈ H}

· · ·

, ˜x

∈
.

H

H

arg min
h
∈H

L

φf
r (h)(˜x), f (˜y)

X(˜x,f (˜y))

∈

S

(cid:0)

(cid:1)

(2)

Here, L is a loss function to compute the error of the predicted proportion φf
r (h)(˜x), and the given
proportion f (˜y). In this paper, we assume that L is 1-Lipschitz in ξ := φf
f (˜y). EPRM
is a very general framework for LLP. One immediate question is whether the instance labels can
be learned by EPRM. In the following sections, we provide afﬁrmative results. We ﬁrst bound the
generalization error of bag proportions based on the empirical bag proportions. We show that the
sample complexity of learning bag proportions is only mildly sensitive to the bag size (Section 5).
We then show that, under some mild conditions, instance hypothesis h which can achieve low error
of bag proportions with high probability, is guaranteed to achieve low error on instance labels with
high probability (Section 6).

r (h)(˜x)

−

5 Generalization Error of Predicting the Bag Proportions

Given a training set S and a hypothesis h
error with a loss function L, and denote by erL
a loss function L over distribution D:

, denote by erL

S (h) the empirical bag proportion
∈ H
D(h) the generalization error of bag proportions with

erL

S (h) =

1
S

|

| X(˜x,f (˜y))

∈

S

L(φf

r (h)(˜x), f (˜y)),

erL

D(h) = E(˜x,˜y)

DL(φf

r (h)(˜x), f (˜y)).

∼

In this section, we show that good proportion prediction is possible for unseen bags. Note that learn-
ing the bag proportion is basically a regression problem on the bags. Therefore, without considering

1This is a very mild assumption. Note that iid bags do not imply iid instances across all bags. The instances inside each

bag can have arbitrary dependencies.

OnLearningfromLabelProportions

4

the instance label hypothesis, for a smooth loss function L, the generalization error of bag propor-
tions can be bounded in terms of the empirical proportion error and some complexity measure, e.g.,
fat shattering dimension [1], of the hypothesis class on the bags. Unfortunately, the above does not
provide us insights into LLP, as it does not utilize the structure of the problem. As we show later,
such structure is important in relating the error of bag proportion to the error of instance labels.

Based on the deﬁnitions in Section 3, our main intuition is that the complexity (or “capacity”)
) should be dependent on the complexity of the instance
. Formally, we adapt the MIL analysis in [20,21], to bound the covering
is a binary hypothesis class,
based on its VC-dimension [23]. This leads to the

of bag proportion hypothesis class φf
r (
label hypothesis class
number [1] of φf
r (
we further bound the covering number of
following theorem on the generalization error of learning bag proportions.

), by the covering number of

. As in our case

H

H

H

H

H

H

Theorem 1. For any 0 < δ < 1, 0 < ǫ < 1, h
erL

S (h) + ǫ, if

∈ H

, with probability at least 1

64
ǫ2 (2V C(
H
) is the VC dimension of the instance label hypothesis class

) ln(12r/ǫ) + ln(4/δ)),

m

≥

in which V C(
of training bags, and r is the bag size.

H

δ, erL

D(h)

−

≤

(3)

, and m is the number

H

The details of the proof are given in the appendix. From the above, the generalization error of
bag proportions can be bounded by the empirical proportion error if there are sufﬁcient number of
bags in training. Note that the sample complexity (smallest sufﬁcient size of m above) grows in
terms of the bag size. This is intuitive as larger bags create more “confusions”. Fortunately, the
sample complexity grows at most logarithmically with r. It means that the generalization error is
only mildly sensitive to r. We also note that the above theorem generalizes to the well-known result
of binary supervised learning, as shown below.

Corollary 1. When bag size r = 1, for any 0 < δ < 1, 0 < ǫ < 1, h
1

δ, erL

erL

S (h) + ǫ, if

D(h)

∈ H

−

≤

, with probability at least

m

≥

64
ǫ2 (2V C(
H

) ln(12/ǫ) + ln(4/δ)).

(4)

6 Bounding the Instance Label Error by Bag Proportion Error

From the analysis above, we know that the generalization error of bag proportions can be
bounded. The result is without any additional assumptions other than that the bags are iid.
In
this section, based on assumptions about the proportions (Section 6.1), or the instances (Section 6.2,
Section 6.3), we present results bounding the generalization error of predicting instance labels by the
generalization error of predicting bag proportions. We also discuss the limitations of LLP under our
framework, providing insights into protecting the instance labels when releasing label proportions.
The analysis in this section is based on the assumption that we already have an instance hypoth-
esis h, which predicts the proportions well: P
φf
δ with some small
|
0 < ǫ, δ < 1. From Section 5, the above is true when we have sufﬁcient number of training bags,
(cid:0)
and a good algorithm to achieve small empirical bag proportion error. Formally, from Theorem 1,
suppose we have a hypothesis h, such that erL
ǫ′′)
D(h)
for some other small ǫ′′ can also be bounded. With Markov’s inequality: for any 0 < δ < 1, deﬁne
ǫ′′ = ǫ′/δ, then P(˜x,˜y)
ǫ′′)

ǫ′. Then P(˜x,˜y)

r (h)(˜x)

r (h)(˜x)

D(
|

f (˜y)

f (˜y)

f (˜y)

| ≤

| ≤

φf

φf

r (h)(˜x)

≤

−

≥

−

−

δ.

1

1

(cid:1)

∼

ǫ

−

| ≤

≥

−

D(
|

∼

6.1 Learning with Pure Bags

Intuitively, if the bags are very “pure”, i.e., their proportions are either very low or very high, the
instance label error can be well controlled by the bag proportion error. The case that all the bags are
with proportions 0 or 1 should be the easiest, as it is identical to the conventional supervised learning

OnLearningfromLabelProportions

5

setting. We justify the intuition in this section. For 0 < η < 1, we say that a bag is (1
at least a fraction (1
our analysis.

η)-pure if
η) of all instances have the same label. The following theorem summarizes

−

−

Theorem 2. Let h be a hypothesis satisfying P(˜x,˜y)
δ for some
0 < ǫ, δ < 1. Assume that the probability that each bag is (1
ρ for some
0 < η, ρ < 1. Then, for any 0 < τ < 1, the probability that h classiﬁes correctly at least a fraction
ǫ).
ǫ) of all nr instances given in n bags is at least 1
(1

1
| ≤
η)-pure is at least 1

r (h)(˜x)

τ 2
2 nr(1

D(
|

f (˜y)

−
−

τ )(1

ρ)(1

φf

ρ)(1

2η

ǫ)

−

−

≥

2η

δ

∼

δ

−

−

e−

−

−

−

−

−

−

−

−

Theorem 2 follows from Lemma 1 with standard concentration inequalities (the proof is given

in the appendix). In addition, Theorem 2 is shown to be tight based on Lemma 2.

Lemma 1. Let h be a hypothesis satisfying P(˜x,˜y)
δ for some
0 < ǫ, δ < 1. Assume that the probability that a bag is (1
ρ for some
0 < η, ρ < 1. Then for that bag, the probability that h classiﬁes correctly at least a fraction
ρ).
(1

1
| ≤
η)-pure is at least 1

ǫ) of its instances is at least (1

r (h)(˜x)

D(
|

−
−

f (˜y)

φf

2η

ǫ)

−

≥

−

δ

∼

−

−

−

−

Lemma 2. There exists a distribution
f (˜y), each bag is (1

D

−

over all bags of size r and a learner h such that φf

r (h)(˜x) =

η)-pure but h misclassiﬁes a fraction 2η instances of each bag.

Lemma 2 also shows limitations of LLP. It is interesting to consider an extreme case, where all
the bags are with label proportion 50% (they are the least “pure”). Then there exists a hypothesis h
which can achieve zero bag proportion prediction error, yet with 100% instance label error. In other
words, it is hopeless to learn or recover the instance labels. This provides an interesting failure case
of LLP. In the appendix, we further show a case under generative assumptions, where EPRM fails
when all the bag proportions are the same and close to 50%. Such negative results worth further
study as they provide insights into “protecting” the instance labels when releasing label proportions.

6.2 Instances Are Conditionally Independent Given Bag

The purity result presented in the former section is without any assumptions on the way the bags
are formed. In this section, we consider the case where the instances are conditionally independent
given the bag. A lot of real-world applications follow this assumption. For example, to model the
voting behavior, each bag is generated by randomly sampling a number of individuals from certain
location. It is reasonable to assume that the individuals are iid given the location.

D

, a distribution over bags.

Formally, we assume that the bags are generated from

is a “mix-
ture” of multiple components D1, ..., DM , where each Di is also a distribution over bags. We
as ﬁrstly picking a distribution Di with some ﬁxed
consider the process of drawing a bag from
, M , there exists
probability ζi, and then generating a bag from Di. We assume for Di, i = 1,
an instance distribution D′i, such that generating a bag from Di is by drawing r iid instances from
D′i. Also assume that the priors P(x,y)
(yi = 1) = αi. We note ﬁrst that under the above as-
sumptions, the purity results in the former section can be utilized. For c > 0, the probability that
2rc2
,
a bag generated from the mixture of multiple components is (1
−
where η = maxi(min(αi, 1
αi)) + c. The proof is straightforward with Chernoff bound. One
disadvantage of the purity result is that it is only useful when αi,

η)-pure, is at least 1

i is not close to 1/2.

· · ·

e−

D′
i

−

−

D

D

∼

φf

f (˜y)

r (h)(˜x)

We can instead use the generative assumption to provide stronger results: under some mild as-
sumptions, the probability of making wrong label prediction β := P(h(x)
= y) can be expressed as
a function of P
. Let’s ﬁrst consider a special case, when all the instances
are drawn iid over a distribution of the instances. This is a special case of the generative model men-
(cid:1)
tioned above with only one component in
. In addition, we assume that the prior of the instances
can be matched by the hypothesis, i.e., P(h(x) = 1) = P(y = 1). This assumption is not too restric-
tive, as the small empirical bag proportion error already implies that the priors are approximately
matched, and for most learning models, we can adjust the hypothesis by a bias term to match the em-
pirical prior estimated on the training data. In such case, we can express P
ǫ

f (˜y)

(cid:0)(cid:12)
(cid:12)

φf

≤

−

D

(cid:12)
(cid:12)

ǫ

∀

r (h)(˜x)

−

(cid:0)(cid:12)
(cid:12)

≤

(cid:12)
(cid:12)

(cid:1)

OnLearningfromLabelProportions

6

 

r = 10
r = 15
r = 20
r = 25
r = 30
r = 35
r = 40
r = 45
r = 50
r = 100

1

0.8

0.6

0.4

0.2

0
 
0

|
(cid:0)

β

β

β

 

r = 1
r = 2
r = 3
r = 4
r = 5
r = 10
r = 15
r = 20
r = 25
r = 30
r = 35
r = 40
r = 45
r = 50

1

0.8

0.6

0.4

0.2

0
0

1

0.8

0.6

0.4

0.2

0
 
0

 

ε = 0.00
ε = 0.02
ε = 0.04
ε = 0.06
ε = 0.08
ε = 0.10

)
r
,
ǫ
(
u

1

0.8

0.6

0.4

0.2

0
 
0

0.2
P (|φf

0.8

0.4

0.6
r (h)(˜x) − f (˜y)| ≤ ǫ)
(a) ǫ = 0

1

0.2
P (|φf

0.4

0.6
r (h)(˜x) − f (˜y)| ≤ ǫ)

0.8

1

(b) ǫ = 0.1

0.2
P (|φf

0.4

0.8

0.6
r (h)(˜x) − f (˜y)| ≤ ǫ)
(c) r = 50

1

0.2 0.4 0.6 0.8
ǫ

1

(d) u(r, ǫ)

Figure 1: (a)-(c): Relationship of the probability of making wrong label prediction, β := P(h(x)
=
y), and the probability of bag proportion prediction error is small than ǫ, P
,
ǫ
under the assumption that the instances are drawn iid, and the prior can be matched by the
(cid:1)
hypothesis, i.e., P(h(x) = 1) = P(y = 1). β is a monotonically decreasing function of
P
(u(r, ǫ), 1]. u(r, ǫ) is shown in (d).
f (˜y)
−
Larger r and larger ǫ will result in larger u(r, ǫ).

r (h)(˜x)

r (h)(˜x)

r (h)(˜x)

, if P

f (˜y)

f (˜y)

|
(cid:0)

| ≤

| ≤

| ≤

φf

φf

φf

−

−

∈

ǫ

ǫ

|
(cid:0)

(cid:1)

(cid:1)

analytically as a function of β:

r

θi
2

r
i!

(cid:16)

i=0  
X

(cid:16)(cid:12)
(cid:12)
(cid:12)
where
the CDF of binomial distribution.

is the ﬂoor operator, θ1 = (2

⌊·⌋

(cid:12)
(cid:12)
(cid:12)

(cid:17)

−

P

φf

r (h)(˜x) − f (˜y)

≤ ǫ

= θr
1

F(i + ⌊ǫr⌋; r − i, θ2) − F(i − ⌊ǫr⌋ − 1; r − i, θ2)

,

β)/2, θ2 = β/(2

β), 0 < β < 1, 0 < ǫ < 1 and

is

(cid:17)

F

−
φf

ǫ

ǫ

(cid:1)

(cid:12)
(cid:12)

−

−

≤

≤

φf

φf

|
(cid:0)

f (˜y)

f (˜y)

f (˜y)

(cid:0)(cid:12)
(cid:12)
| ≤

r (h)(˜x)

r (h)(˜x)

r (h)(˜x)

, when P

As what we actually want is to bound β based on P

, we show the
“inverse” function in Figure 1. From the curves, we see that β is a monotonically decreasing function
(cid:1)
of P
(u(r, ǫ), 1]. u(r, ǫ) is shown in
Figure 1 (d). In other words, the instance label error can be controlled by the bag proportion error,
when the later is small. The results are of course the “tightest” under the above assumptions.

(cid:0)(cid:12)
(cid:12)
One important observation is that the curves are independent of P(y = 1). Therefore, the
analytical results can be directly applied to the case when the instances are conditionally independent
given the bag, under the assumption that P(x,y)
D′
i

∀
∼
= y) is approximately linear to the bag size r, when r is sufﬁciently large, and P

Our additional observations of Figure 1 are summarized below. From (b), the growth of β :=
P(h(x)
r (h)(˜x)
−
is close to 1. From Figure 1 (c), with large bag size (r = 50), the growth of β is approximately
quadratic to the proportion prediction error ǫ, when P

(h(x) = 1) = P(x,y)

is close to 1.

(y = 1),

f (˜y)

|
(cid:0)

φf

φf

D′
i

−

∈

i.

(cid:12)
(cid:12)

(cid:1)

∼

ǫ

ǫ

r (h)(˜x)

(cid:1)
6.3 Instances Are Drawn by Independent Bernoulli Variables

|
(cid:0)

−

| ≤

In this section, we focus on an alternative model, which essentially picks instances independently
from a ﬁnite set of instances to build the bags. This setting is relevant to most real-world applications.
For example, there are always a ﬁnite set of persons in a political survey. Our intuition is that if
the bags “cover” the space of the instances well, the instance labels (of all possible instances) are
relatively easy to be recovered.

Formally, we consider the following model for bag generation. Let X =

be the set
of all instances. For each instance xi, deﬁne an Bernoulli variable κi that determines whether the
instance will be picked, i.e.:

x1, ..., xn}

{

κi =

1
0

(cid:26)

if xi was selected to the bag,
otherwise.

Let pi = P(κi = 1). Note that κi are independent but not necessarily identically distributed. Denote
κ = (κ1, .., κn). We call the above model the κ-model. Note that in the κ-model, the bag size is
variable instead of being ﬁxed. The proof of the results is shown in the appendix.

f (˜y)

ǫ

| ≤

(cid:1)

OnLearningfromLabelProportions

7

{

ǫ)

· · ·

x1,

, xn}

be the set all the instances. Let maxi pi =

( 1
n ). Assume that
R/n for some R > 0. Let D be a distribution over bags such that drawing a bag from

Theorem 3. Let X =
mini pi ≥
D is by drawing a bag from the κ-model. Let h be a hypothesis such that P(˜x,˜y)
f (˜y)
δ > 0 and large enough R, h misclassiﬁes at most

δ, where r(˜x) is the size of ˜x. Let q = ǫ2(Pn

D(
|
−
pi) . Then, for small enough

O
The following corollary shows the result when the probabilities of the instances being drawn are
( 1
n ). In such case, the instances are iid, and the bags very well “cover” X.

uniform, and equal to
This is similar to one case studied in Section 6.2 when all instances are drawn iid.

(qn) instances of X.

φf
r(˜x)(h)(˜x)

i=1 pi)2
−

n mini pi(1

| ≤

O

O

≥

−

1

∼

{

x1, ..., xn}

( 1
Corollary 2. Let X =
n ).
Denote by ˆr the expected size of the bag, ˆr = np. Let D be a distribution over bags such that
drawing a bag from D is by drawing a bag from the above κ-model. Let h be a hypothesis such
that P(˜x,˜y)
δ. Then for small enough δ and large enough ˆr, h
∼
misclassiﬁes at most

1
(ǫ2ˆrn) instances of X.

be the set all the instances. Let p1 =

φf
r(˜x)(h)(˜x)

= pn = p =

D(
|

f (˜y)

| ≤

· · ·

ǫ)

O

−

≥

−

O

Similar to Section 6.2, the model has an analogous “conditionally-independent” version, where
we have a probability distribution on the set of sequences κ. In this setting we ﬁrst choose a sequence
κ and then use it to generate a particular bag. All the results we give above easily translate to this
more general setting. In addition, based on our proof in the appendix, it is also possible to generalize
the result to cases where dependencies between small subsets of instances exist.

7 Extending the Results to Variable Bag Size

For simplicity in our analysis, except Section 6.3, we assumed that all the bags were of size
r. In fact, all our results can be easily generalized to variable bag size. For the result on the bag
proportion error, Theorem 1 holds immediately by replacing r with the average bag size in training
¯r. This is based on the fact that the covering number bound holds (shown in the proof of Theorem 1
in the appendix) with average bag size [20]. For results on the instance label error, we can assume
that the bag size r is generated from some ﬁxed probability distribution independent of the instances.
Lemma 1 holds for any bag size. Theorem 2 holds immediately by replacing r with the expected bag
size ˆr, following the proof described in the appendixappendix. We can further bound the expected
bag size ˆr by the average bag size in training ¯r based on Chernoff bound: for any t > 0, with
probability at least 1
t, where m is the number of training bags. In addition, our
−
analysis with the generative assumptions (Section 6.2) holds for any bag size.

, ˆr > ¯r

2mt2

e−

−

8 Applications

LLP for privacy preserving learning algorithms. Data used by machine learning algorithms
is often very sensitive and therefore versions of the machine learning algorithms that achieve some
level of privacy are of much interest [8,11]. LLP can be very useful to provide data privacy. In a
nutshell, the LLP learner, only having access to the label proportions, sufﬁces to construct good-
quality machine learning structures. We provide preliminary discussions in the appendix.

Justifying LLP algorithms. Among the existing algorithms, our analysis is well aligned with
SVM
algorithms that implicitly utilize the EPRM framework. One algorithm in this category is
[25], which has been shown to give good performance. The objective of
SVM is to ﬁnd a large-
margin classiﬁer consistent with the label proportions, with the help of latent labels. The analysis of
Section 5 can be generalized to justify

SVM using margin-based analysis [26].

∝

∝

Learning with population proportions. Consider the scenario of modeling voting behavior
based on government released statistics: the government releases the population proportion (e.g.

∝

OnLearningfromLabelProportions

8

 

r = 1
r = 5
r = 30
r = 100

0.26

0.24

0.22

0.2

0.18

0.16

r
o
r
r
e
 
e
c
n
a
t
s
n
i
 
t
s
e
T

 

0.22

 

0.2

 

0.18

r = 1
r = 5
r = 30
r = 100

r
o
r
r
e
 
e
c
n
a
t
s
n
i
 
t
s
e
T

0.2

0.18

0.16

0.14

r = 1
r = 5
r = 30
r = 100

r
o
r
r
e
 
e
c
n
a
t
s
n
i
 
t
s
e
T

0.18

0.16

0.14

r = 1
r = 5
r = 30
r = 100

r
o
r
r
e
 
e
c
n
a
t
s
n
i
 
t
s
e
T

0.16

0.14

0.12

 
1
3
# Training instances (normalized)

5

4

2

0.12

 
1
3
# Training instances (normalized)

2

5

4

0.12

 
1
3
# Training instances (normalized)

4

2

5

0.1

 
1
3
# Training instances (normalized)

4

2

5

(a) IID

(b) Occupation

(c) Education

(d) Race

Figure 2: Predicting income based on census data. (a) All the instances are iid. (b)-(d) The instances
are conditionally independent given the bag, with title of each ﬁgure as its grouping attributes. The
number of training instances is equal-spaced in log-scale, with the smallest number 500, and the
largest number 50,000.

62.6% in New York voted for Obama in 2012 election) of each location, and we only have a subset
of randomly sampled instances for each location. Can LLP be applied to correctly predict labels of
the individuals? In such a scenario, EPRM can only minimize the proportion error in terms of the
population proportions, because the actual proportions of the sampled subsets are not available. We
r
can assume that a bag is formed by randomly sampling r instances
i=1 from a location
with a true (population) proportion p∗, which is released. The Chernoff bound ensures that the
ln(2/δ)/(2ǫ2),
sampled proportion is concentrated to the released population proportion: when r
with probability at least 1
ǫ. Therefore, with enough training bags, and enough
δ,
p∗
samples per bag, the generalization error can be bounded.

(xi, yi)
}

f (˜y)

| ≤

−

≥

−

{

|

9 A Case Study: Predicting Income based on Census Data

So far we have provided formal guarantees that under some conditions, labels of individual
instances can be learned or recovered. In this section, we conduct a case study to demonstrate the
feasibility of LLP on real-world data. The task is to predict individual income based on census
data, and label proportions. We use a dataset which covers a subset of the 1994 census data2. It
contains 32,561 instances (individual persons), each with 123 binary attributes about education,
marital status, sex, occupation, working hours per week etc. Each individual has a binary label
indicating whether his/her income > 50k. We consider this label as sensitive information, for which
we only know its proportions on some bags of people. Next we will show the feasibility of LLP
based on different ways of forming the bags. We ﬁrst divide the dataset to use 80% of the instances
for training, and 20% for testing. For all the experiments below, the bags are formed on the 80%
training data. The proportion of each training bag is computed based on the ground-truth labels.
SVM [25] with linear kernel, and ℓ1 loss. We use the algorithms
The experiments are based on
proposed in [19] and [18] as the initialization methods for the alter-
SVM solver. The parameters,
[0.01, 0.1, 1], are tuned on the bag proportion prediction error by performing
C
cross validation. We report mean and standard deviation of error on the test data based on 5 runs.

[0.1, 1, 10], Cp ∈
All instances are drawn iid. We ﬁrst simulate a simple case where all the instances are drawn
iid from a distribution of instances. We achieve this by assuming that all the instances of the dataset
form a “distribution” of individuals. For all the bags (with r instances), each instance is drawn by
randomly sampling the whole training set with replacement. Figure 2 (a) shows the experimental
results. Based on the results, more instances (bags) lead to lower test error. The relatively low
test error demonstrates the feasibility of LLP under such settings. Fewer training bags (and larger
training bag size) generally result in larger test error variance, as the algorithm is more likely to
converge to worse local solutions.

∝

∝

∈

Instances are conditionally independent given bag. We simulate the case by a “hierarchical

2http://archive.ics.uci.edu/ml/datasets/Adult

OnLearningfromLabelProportions

9

Grouping Attribute Native Country
Number of Bags
∝SVM Error %
Baseline Error %

41
18.75 ± 0.25
24.02 ± 0.56

Education
16
19.61 ± 0.10
22.29 ± 0.55

Occupation
15
18.19 ± 0.16
24.28 ± 0.28

Relationship
5
18.59 ± 0.82
24.19 ± 0.72

Race
5
24.02 ± 0.15
24.28 ± 0.40

Table 1: Error on predicted income based on census in a real-world setting.

bag generation” process. The individuals are ﬁrst grouped by a grouping attribute. For example, if
the grouping attribute is “occupation”, the individuals are groups into 15 groups, corresponding to
the 15 occupations. Each group is assigned a prior, which is simply uniform in this experiment. To
generate a bag of r instances, we ﬁrst pick a group based on the priors, and then perform random
sampling with replacement r times in the selected group. Figure 2 (b)-(d) show the experiment
results. The trend of the learning curves is the same as in Figure 2 (a), showing that LLP is indeed
possible in such a setting.

A challenging real-world scenario. For real-world applications, the bags are predeﬁned rather
than “randomly” generated. In this experiment, we simply group the individuals deﬁned by different
grouping attributes. Different from the setting in the former section, the whole group is treated as a
single bag, without further sampling process. Table 1 shows the performance of LLP. The “Baseline”
result is formed by the following: a new instance is predicted positive if the training bag with
the same grouping attribute has proportion larger than 50%; otherwise it is predicted as negative.
For example, it predicts a person with elementary education as negative, as the label proportion
of elementary education group is less than 50%. For most experiments, this result is similar to
assigning +1 to all test instances, because most training bags are with proportion larger than 50%.
This scheme provides performance gain for “education”, as the label proportion for individuals with
very low education is also very low. We ﬁnd that for most grouping attributes, the performance of
LLP signiﬁcantly improves over the baseline. This is also true for some cases where the number
of bags is very small. We do observe that for certain way of forming the bags, e.g., by Race, the
improvement is not that big. This is due to the fact that the instance distributions of the bags are
very similar, and therefore most of the bags are redundant for the task.

10 Conclusion

This paper proposed a novel two-step analysis to answer the question whether the individual
labels can be learned when only the label proportions are observed. We showed how parameters such
as bag size and bag proportion affect the bag proportion error and instance label error. Our ﬁrst result
shows that the generalization error of bag proportions is only mildly sensitive to the size of the bags.
Our second result shows that under different mild assumptions, a good bag proportion predictor
guarantees a good instance label predictor. We have also demonstrated the feasibility of LLP based
on a case study. As the future work, data dependent measure, e.g., Rademacher complexity [3], may
lead to tighter bound for practical use. Some alternative tools, e.g., sample complexity results of
learning
-valued functions [13], can be used for analyzing the generalization error of bag
proportions. The failure cases of LLP worth further study as they can be utilized to protect sensitive
personal information when releasing label proportions.

0, ..., n

{

}

11 Appendix

11.1 Proof Sketch of Theorem 1

One important tool used in the proof is the lemma below bounding the covering number of bag

proportion hypothesis class φf
r (

) by the covering number of the instance hypothesis class

.

H

H

OnLearningfromLabelProportions

10

Lemma 1. [20,21] Let r
∈
some αf > 0. Let γ > 0, p

N and suppose f : Rr
[1,

], and

→
RX . For any m

R is α-Lipschitz w.r.t. the inﬁnity norm, for

∈
∞
Np(γ, φf
r (

H

H ∈
), m)

≤ Np(

γ
αf r1/p ,

H

, rm).

0,

≥

Covering number [1] can be seen as a complexity measure on real-valued hypothesis class.
The larger the covering number, the larger the complexity. Another lemma we use is the uniform
convergence for real function class.
Lemma 2. [1]. Let ˆ
ˆ
Y
Y
ﬁrst argument with Lipschitz constant αL > 0. Let D be any distribution on
0 < ǫ < 1 and g

[0, 1], such that L is Lipschitz in its
. Then for any

X , and L : ˆ

Y × Y →

X × Y

Y ⊆

G ⊆

R,

:

,

∈ G

PS

Dm

∼

(cid:18)
S (g) = 1
S
|

|

sup
g
∈G (cid:12)
(cid:12)
x
∈

in which erL

1:

erL

D(g)

erL

S (g)

−

ǫ

≥

4

N1(ǫ/(8αL),

G

≤

, 2m)e−

mǫ2/32,

(cid:19)
(cid:12)
(cid:12)
D(g) = Ex
S L(g(x), y), erL

DL(g(x), y).

∼

N1(ǫ, W, m)

≤ N∞

Based on the deﬁnition of covering number:

P

(ǫ, W, m). Applying Lemma

4

N1(ǫ/(8αL),

H

, 2m)e−

mǫ2/32

, 2m)e−

mǫ2/32

4

4

≤

N∞

≤

N∞

(ǫ/(8αL),

H
(ǫ/(8αLαf ),

H

, 2rm)e−

mǫ2/32.

(5)

Also, the proportion generation function f in our case is 1-Lipschitz with the inﬁnity norm. And the
loss functions L we are considering is 1-Lipschitz.
Based on the deﬁnition of covering number, for

X , for any ǫ < 2,

1, 1

(ǫ,

, d

) =

N

xm
1

H|

∞

. Thus,

|H|

xm
1 |

H ⊆ {−

}

(ǫ,

, m) = Π

(m).

H
Refer to [1] for the deﬁnition of restriction

N∞

(m). In addition, we
H|
have the following lemma to to bound the growth function by VC dimension of the hypothesis class.

and growth function Π

xm
1

H

H

Lemma 3. [22] Let

1, 1

X with VC(

) = d

. For all m

G ⊆ {−

}

G

≤ ∞

d, Π
G

(m)

≥

≤

em
d

d.

d
i=0

m
i

≤

P

(cid:0)

(cid:1)

(cid:0)

Let d = V C(
(cid:1)

). By combining the above facts, and 0 < ǫ < 1, (5) leads to

H

Therefore, with probability at least 1

δ,

4Π

(2rm)e−

H

mǫ2/32

2erm
d

d

(cid:19)

4

≤

(cid:18)

e−

mǫ2/32.

erL

D(f )

erL

S (f ) +

≤

−

32
m

(cid:18)

(d ln(2emr/d) + ln(4/δ))

1/2

(cid:19)

m

≤

32
ǫ2 (d ln m + d ln(2er/d) + ln(4/δ)).

Since ln x

ax

≤

−

⇐
ln a

1 for all a, x > 0, we have

m + ln

ǫ2
64d

−
32d
ǫ2 ln m
m
2
64
ǫ2 (2d ln(12r/ǫ) + ln(4/δ)).

32d
ǫ2
≤
(cid:19)(cid:19)
32
ǫ2 (d ln(128r/ǫ2) + ln(4/δ)).

64d
ǫ2

+

≥

(cid:18)

(cid:18)

≥

m

m

⇐

⇐

⇐

m
2

+

32d
ǫ2 ln

≤

64d
eǫ2

.

(cid:19)

(cid:18)

OnLearningfromLabelProportions

11

11.2 Appendix of Section 6.1

Proof of Lemma 1
Let ˜x = (x1, ..., xr) be a bag. Assume that

r (h)(˜x)

φf
|
1, ..., r
}
1, ..., r
}
)/r.

−

f (˜y)
: h(xi) =
: h(xi) =

| ≤
1
−

ǫ. Denote
yi = +1
yi =

i
i

A1 =
∈
,
A3 =
∈
}
. We have:
1
}
−

{
{

,
,

|

−

+

∧
1

{
{
+

1, ..., r
{
}
1, ..., r
{
}
φf
r (h)(˜x) = (

: h(xi) = +1
: h(xi) = +1
|A1|
−
η)-pure. Without loss of generality we can assume that

yi =
1
}
∧
yi = +1
}
∧
)/r, f (˜y) = (
|A3|
φf

A2 =
A4 =
|A2|
r (h)(˜x)

i
∈ {
i
∈ {
|A3|
f (˜y)

ǫ, we have:

ηr. Thus we also have that

Thus, from the assumption:

ǫr. Assume
||A1| − |A2|| ≤
that ˜x is (1
ηr. This
−
implies that
(η + ǫ)r. Hypothesis h correctly classiﬁes
|A1| ≤
instances of the bag ˜x. From what we have just derived, we conclude that h correctly
+
|A3|
|A4|
ǫ)r instances of the bag ˜x. So far in the analysis above we assumed that:
classiﬁes at least (1
φf
η)-pure. From the statement of the theorem we know that the
|
former happens with probability at least 1
ρ. Thus,
by the union bound, we know that with probability at least 1
ρ, h classiﬁes correctly at least
ǫ) instances of the bag drawn from the distribution
(1

δ and the latter with probability at least 1

2η
ǫ and ˜x is (1

|A4| ≤

|A2| ≤

r (h)(˜x)

−
| ≤

|A1|

f (˜y)

| ≤

2η

δ
.

−

−

+

−

−

−

−

−

∧

−

−
Proof of Theorem 2
Denote θ = 2η + ǫ, p = δ + ρ. Let Z be a random variable deﬁned as follows:

−
D

θ)r

(1
0

−

with probability 1
with probability p

−

p,

Z =

(cid:26)

p)(1

Denote by Zi for i = 1, 2, ..., m the ith independent copy of Z. Lets Zsum = Z1 + ... + Zn. Note
that, according to Lemma 1, Z is the lower bound on the number of instances from m bags that
are correctly classiﬁed We have µ = EZsum = nr(1
θ). From Chernoff’s inequality
τ 2
we immediately get: for 0 < τ < 1, P(Zsum < (1
2 µ. Thus we conclude that
e−
θ) the hypothesis h classiﬁes correctly at least a fraction
with probability at least 1
(1

θ) of all nr instances coming in n bags.

−
Proof of Lemma 2
Assume that the bags are selected in such a way that ﬁrst ηr instances have label +1, next ηr
2η)r instances have label +1. Assume furthermore that the hypothesis
yi for every instance xi from the list of ﬁrst 2ηr instances of the bag and
2η)r instances from the list. Then of course the classiﬁer always

have label
h satisﬁes: h(xi) =
satiﬁes: h(xi) = yi for last (1
misslassiﬁes ﬁrst 2η instances of each bag but predicts bag proportions with 0 error.

1 and last (1

τ 2
2 nr(1

τ )µ)

τ )(1

p)(1

e−

p)(1

−

−

−

−

−

−

−

−

−

≤

−

−

−

11.3 Appendix of Section 6.3

Proof of Theorem 3
The theorem follows from the following more general technical theorem that we will prove ﬁrst.

Note that we treat the labels as 0/1 for simplicity in this section.

, hn) be two sequences of 0s and 1s. Denote η =
Theorem 4. Let (y1,
Pn
hi
. Let 0 < ǫ < 1. Let p = maxi pi. Let v = mini=1,...,n V ar(κi). Let ρ(x) =
|
et(log(np)+1)
. As-
e(t+ 1

yi
i=1 |
n
n
t=√xηnv

. Assume that: xρ(x)

, yn) and (h1,

0 as x

0 as x

and

· · ·

· · ·

−

)t

2

→

x ρ(x)
∞
for some constant ∆ > 0. Then the following is true for
R
hi)

big enough:

→ ∞

→ ∞

→

sume furthermore that η
P
∆, n big enough, and

∆ǫ2(Pn

≥
n
i=1 V ar

i=1 Eκi)2
nv
κi(yi −

P

(cid:0)

Pκ=(κ1,...,κn)

n

(cid:1)
κi(yi −

i=1
X

 (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

>

κiǫ

> ξ

!

n

i=1
X

hi)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

for some constant ξ(∆) that does not depend on η and ǫ.

OnLearningfromLabelProportions

12

Proof
Denote Xi = κi(yi −

hi), X =

Notice that we have: EY = V ar(X) =
n
the probability p1 = Pκ=(κ1,...,κn)[
(we will show later how to choose C).
P

P
|

n

EXi, Z =

EX)2.
n
i=1 V ar(Xi). First we want to ﬁnd a lower bound on
V ar(Z)] for some constant C > 0

n
i=1 Zi and Y = (X

i=1 Xi, Zi = Xi −
hi)
i=1 κi(yi −
P
|

> C

P

−

p
C
| ≤
> 2C

|

|

−

EX

|
EX

Let us consider two cases. In the ﬁrst case we have:

V ar(Z). So it only sufﬁces
to ﬁnd a lower bound on the probability p2 = P[
V ar(Z)], because trivially:
X
p2. Let α, β > 0 (α < β) be two positive constants (we will see later how to choose the values
p1 ≥
of α and β). To ﬁnd a lower bound on p2 we partition the probability space Ω into three subspaces:
Ω1, Ω2, Ω3. Let us deﬁne: Ω1 =
,
βV ar(Z)
}
C).
Ω3 =
Y > βV ar(Z)
}
Let us ﬁrst consider the expression: P[C]E(Y
C) and lets ﬁx some α > 0. We want to show that for
β large enough we have: P[C]E(Y
C) < αV ar(Z). So we want to prove that for β large enough
] < αV ar(Z). The latter inequality is equivalent to
the following is true: E[Y I
Y > βV ar(Z)
}
] < α. Let us denote Dn =
the following one: E[
. We want to
V ar(Z) > β
}
Dn|

] < α. Let us ﬁrst bound the expression P[

Y < αV ar(Z)
}
P[A]E(Y

≤
A) + P[B]βV ar(Z) + P[C]E(Y

{
Y
V ar(Z) I
n > β

. We trivially have: EY

Z
√V ar(Z)

αV ar(Z)

, Ω2 =

p
p

≤

≤

Y

{

{

{

{

n

Y

|

|

|

|

|

1 and that different Xi are independent. Thus we have: P[Dn > x]

i=1(Xi −

EXi)

≥

> x] for an arbitrary
x√ηnv]. Now notice that each Xi is
pt, where

show that E[D2
D2
nI
{
x > 0. Notice that P[Dn > x] = P[
either 0, 1 or
−
t = x√ηnv. Thus we get that:

}

P

≤

n
t

(cid:0)

(cid:1)

P[Dn > x]

(np)t
t!

≤

= O(

et log(np)+t
e(t+ 1
2 ) log(t)

)

where the last relation follows immediately from Stirling’s formula. Thus we have:

E[

Y
V ar(Z)

I

{

Y
V ar(Z)

}

> β

] = βP[D2

n > β] +

∞

P[D2

n > x]dx = o(1)

β
Z

|

|

α

≤

→ ∞

A) + P[B]βV ar(Z) + P[C]E(Y

), where the last relation follows from our assumptions on
(i.e. the expression goes to 0 as x
ρ(x) and the upper bound on the value of P[Dn > x] that we have just derived. We can conclude
that for β large enough we have: P[C]E(Y
C) < αV ar(Z). Now, if we go back to the formula:
P[A]E(Y
C) and notice that EY = V ar(Z), then from
EY
the fact that P[C]E(Y
β . Taking arbitrary 0 < α < 1
2
|
4 we see that: P[B]
and C =
V ar(Z)]. Thus we have proved that
δ for some constant δ > 0 that does not depend on η and ǫ. That
δ and therefore also p1 ≥
p2 ≥
was however under an assumption that
|
> C
EX

V ar(Z). Without loss of generality we can assume that
EX > 0. In this case we will prove that P[
V ar(Z)] < δ for some 0 < δ < 1
−
that does not depend on η and ǫ. We can proceed as before, using our upper bound on P[Dn > x],
to conclude that P[Dn < C

C) < αV ar(Z), we obtain: P[B]
> 2C
X

2 ] < δ for some 0 < δ < 1. Thus we have proven that

Now let us assume that

p
V ar(Z).

p
EX

< C
2

EX

EX

| ≤

P[

p

p

p

X

≤

−

≥

C

2α

−

1

|

|

|

|

|

|

|

Pκ=(κ1,...,κn)[

κi(yi −

hi)
|

>

V ar(Z)] > δ

n

|

i=1
X

C
2

p

for some 0 < δ < 1 which does not depend on η and ǫ.

Denote T = C

2 . Now we will upper-bound the probability that ǫ

V ar(Z).
V ar(Z) (see: asumptions of
One can easily check that we can assume that: ǫ
the theorem, V ar(Z) is large enough). Now, using standard concentration inequalities such that
Chernoff’s inequality and again the assumptions of the theorem, it is easy to verify that the latter
probability can be bounded by the negligible function of R. That obviously completes the proof.

i=1 Eκi ≤

i=1 κi ≥

P

P

p

p

T
2

T

n

n

Proof of Theorem 3

OnLearningfromLabelProportions

13

n

We can proof Theorem 3 by contradiction. Note ﬁrst that the conditions put on the function
ρ(x) from Theorem 4 are trivially satisﬁed under our assumptions on the κ-model. Let
x1, ..., xn}
be a test set. Without loss of generality we can assume that ξ is as in δ of Theorem 3 in the main
of the
text. Denote h(xi) = hi. Take the groundtruth labels
y1, ..., yn}
n
i=1 κiǫ is equivalent to saying that the proportion prediction on the
form
>
bag coming according to the κ-model was not within error ǫ from the groundtruth. If we now take
the constant ∆ > 0 for which Theorem 4 holds and assume by contradiction that the instance label
classiﬁer misclassiﬁed at least ηn points from the test set for η = ∆ǫ2(Pn
i=1 Eκi)2
n mini=1,...,n V ar(κi) then we
conclude that the probability of
pi).
Taking ξ to be smaller than ξ(∆) from Theorem 4 completes the proof.

is more than ξ. Note that Eκi = pi, and V ar(pi) = pi(1

. Note that an event

i=1 κi(yi −

hi)
|

P

P

−

E

E

{

{

|

11.4 Private Learning with Label Proportions

(6)

(7)

We provide preliminary discussions on the usefulness of LLP in several settings where privacy
guarantees are required. We will ﬁrst deﬁne an important notion of differential privacy. Below we
give all necessary deﬁnitions involving differential privacy and some of its properties. One can think
about differential privacy as a mechanism that, if applied to a given database-access mechanism,
guarantees small changes in the output as long as the database does not substantially change.

satisﬁes ǫ-differential-privacy if for all databases

Deﬁnition 2 ([10]). A randomized algorithm
D1 and

D2 differing on at most one element, and all S
exp(ǫ)
D1) = S]
(

≤
The probability is taken over the coin tosses of

P r[

M

M

.

·

M

Range(

),

∈
P r[

M
D2) = S].
(

M

Smaller values of ǫ mean stronger privacy guarantees. If f is a function and

aims to compute
a differentially-private version of f , it can achieve it by adding noise with the magnitude adjusted to
the sensitivity of f .

M

Deﬁnition 3 ([10]). The global sensitivity S(f ) of a function f is the smallest number s such that
for all

D1 and

D2 which differ on at most one element,
D2)

D1)

f (

f (

|

s.

−
Let Lap(0, λ) denote the Laplace distribution with mean 0 and standard deviation λ.

| ≤

Theorem 5 ([10]). Let f be a function on databases with range Rm, where m is the number of rows
of databases. Then, the mechanism that outputs f (
) + (Y1, . . . , Ym), where Yi are drawn i.i.d from
Lap(0, S(f )/ǫ), satisﬁes ǫ-differential-privacy.

D

Differential privacy is preserved under composition, but with an extra loss of privacy for each

conducted query.

Theorem 6 ([10]). (Composition Theorem) The sequential application of mechanisms
giving ǫi-differential privacy, satisﬁes

i ǫi-differential-privacy.

Mi, each

P

Differential privacy is one of the strongest notions of privacy that is being applied in many
In this section we show how learning from label
different scenarios, also in machine learning.
proportions can make some existing differentially-private machine learning algorithms even more
secure. The mechanism proposed by us below may serve as a new paradigm for constructing them.
The overall scheme of constructing differentially-private algorithm usually reduces to two steps.
In the ﬁrst step data is used to construct some machine learning structure. Then this structure with
a partial information obtained from the data is being published. Publishing just partial information
enables to get differentially-private guarantees and very often means outputting some proportions

OnLearningfromLabelProportions

14

regarding data. For example, in the random decision tree approach (see: [12], [14]) for every leaf
of the tree the perturbated counts of items with particular labels are being released. Then the pro-
portions of those items determine the classiﬁcation of the test data point. It should be mentioned
however that in the ﬁrst phase the algorithm producing those proportions has an access to all the data
and stores it explicitly in the structure under construction. This phase can take signiﬁcant amount
of time and during this period the structure is usually very vulnerable to different attacks aiming to
compromise privacy.

Note however that since very often the only information involving labels that needs to be released
is the proportions of items with different labels, we can use the classiﬁer that learns the proportions
to construct the structure in the ﬁrst phase. We feed the learner with bags of data without releasing
the actual mapping from instances to their labels. The information, quantized in those bags, is then
used by the learner to compute good approximations of the proportions and will be later published
in a differentially-private way (usually by adding Laplacian noise).

This scheme is more secure than a standard approach since even the algorithm that constructs
differentially-private structure does not know labels of data points it is receiving – It only knows
proportions. So even though the ﬁrst phase of the algorithm is deﬁnitely not differentially-private
(since the algorithm still receives unperturbated data points), it can be easily proven that it achieves
k-anonymity. We should note that in the standard approach the ﬁrst phase did not give any privacy
guarantees.

At the very end we would like to show quantitatively that differential privacy mechanism is
a natural candidate for making private the algorithms that heavily rely on proportions of counts
to classify points. Among those algorithm are those involving random decision trees or random
projection trees [7,14].

−

−

S

−

2 e−|

+, np

with label

k ). Let ﬁx a set

+ = n+ + g1 and np

−
and np = np

k ), where k is the number of all sets

Without loss of generality we will assume that we have 2-labels setting. Let

be a set of ob-
. The
1. Denote n = n+ + n
jects consisting of n+ instances with label +1 and n
by adding Laplacian noise indepen-
differentially-private mechanism perturbates counts: n+, n
−
dently to each of them to obtain: np
+ + np
. Denote by g(λ) the Laplacian variable
−
with pdf: λ
λ. The key observation now is that the sensitivity of each count is only 1. Therefore
x
|
it sufﬁces to add a Laplacian g( η
under consideration (we as-
are pairwise disjoint) and η is a desired differential privacy parameter of the entire
sume that sets
S
algorithm. Thus we have: np
+ g2, where each gi has the distribution as
−
g( η
. Random variable X measures the difference
between the actual proportion and the one output by the differentially-private mechanism. We have:
. Now one can easily check that for ﬁxed η, k, δ, θ > 0 and number of instances
X
) |
n large enough we have: P(X > θ)
δ. Thus, by Azuma’s inequality, with probability at least
all but at most a fraction δ + ǫ of all output proportions are within distance θ from their
1
nonperturbated versions. This means that in practice most of the proportions will be very close to
their nonperturbated versions and explains why differential privacy is a good scalable tool in this
setting. The learner that accurately learns label proportions can make this setting even more se-
cure. It can output proportions close to original without having a straightforward information about
the mapping between the instances used to construct differentially-private structure and their labels.
Those proportions can be then perturbated and published.

−
n++g1
n+g1+g2 −

n+g2
g1n−
−
n2(1+ g1+g2

. Denote: X =

= n
n+
n |

≤ |

2kǫ2

e−

≤

−

S

S

|

n

References

[1] Martin Anthony and Peter L Bartlett. Neural network learning: Theoretical foundations. Cam-

bridge University Press, 2009.

[2] Boris Babenko, Nakul Verma, Piotr Doll´ar, and Serge J Belongie. Multiple instance learning
with manifold bags. In Proceedings of the 28th International Conference on Machine Learn-
ing, pages 81–88, 2011.

OnLearningfromLabelProportions

15

[3] Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds

and structural results. The Journal of Machine Learning Research, 3:463–482, 2003.

[4] Avrim Blum and Adam Kalai. A note on learning from multiple-instance examples. Machine

Learning, 30(1):23–29, 1998.

[5] B.C. Chen, L. Chen, R. Ramakrishnan, and D.R. Musicant. Learning from aggregate views.
In Proceedings of the 22nd International Conference on Data Engineering, pages 3–3. IEEE,
2006.

[6] T. Chen, F. X. Yu, J. Chen, Y. Cui, Y.-Y. Chen, and S.-F. Chang. Object-based visual sentiment

concept analysis and application. In ACM Multimedia, 2014.

[7] A. Choromanska, K. Choromanski, G. Jagannathan, and C. Monteleoni. Differentially-private
learning of low dimensional manifolds. In International Conference on Algorithmic Learning
Theory, pages 249–263, 2013.

[8] Krzysztof Choromanski, Tony Jebara, and Kui Tang. Adaptive anonymity via b-matching. In

Advances in Neural Information Processing Systems, pages 3192–3200, 2013.

[9] Thomas G Dietterich, Richard H Lathrop, and Tom´as Lozano-P´erez. Solving the multiple
instance problem with axis-parallel rectangles. Artiﬁcial Intelligence, 89(1):31–71, 1997.

[10] C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating noise to sensitivity in private

data analysis. TCC, pages 265–284, 2006.

[11] Cynthia Dwork. Differential privacy. In Automata, languages and programming, pages 1–12.

Springer, 2006.

[12] W. Fan, H. Wang, P.S Yu, and S. Ma. Is random model better? on its accuracy and efﬁciency.

ICDM 2003, pages 51–58, 2003.

[13] David Haussler and Philip M Long. A generalization of Sauer’s Lemma. Journal of Combina-

torial Theory, Series A, 71(2):219–240, 1995.

[14] G. Jagannathan, K. Pillaipakkamnatt, and R. N. Wright. A practical differentially private

random decision tree classiﬁer. Transactions on data privacy, pages 273–295, 2012.

[15] Hendrik Kuck and Nando de Freitas. Learning about individuals from group statistics.

In
Proceedings of the 21st Conference on Uncertainty in Artiﬁcial Intelligence, pages 332–339.
AUAI Press, 2005.

[16] K.-T. Lai, F. X. Yu, M.-S. Chen, and S.-F. Chang. Video event detection by inferring temporal

instance labels. In Computer Vision and Pattern Recognition, 2014.

[17] D.R. Musicant, J.M. Christensen, and J.F. Olson. Supervised learning by training on aggregate
outputs. In Proceedings of the 7th International Conference on Data Mining, pages 252–261.
IEEE, 2007.

[18] N. Quadrianto, A.J. Smola, T.S. Caetano, and Q.V. Le. Estimating labels from label propor-

tions. The Journal of Machine Learning Research, 10:2349–2374, 2009.

[19] S. R¨ueping. SVM classiﬁer estimation from group probabilities. In Proceedings of the 27th

International Conference on Machine Learning, 2010.

[20] Sivan Sabato. Partial Information and Distribution-Dependence in Supervised Learning
Models. PhD thesis, School of Computer Science and Engineering, Hebrew University of
Jerusalem, 2012.

OnLearningfromLabelProportions

16

[21] Sivan Sabato and Naftali Tishby. Multi-instance learning with any hypothesis class. Journal

of Machine Learning Research, 13:2999–3039, 2012.

[22] Norbert Sauer. On the density of families of sets. Journal of Combinatorial Theory, Series A,

13(1):145–147, 1972.

[23] Vladimir N Vapnik and A Ya Chervonenkis. On the uniform convergence of relative frequen-
cies of events to their probabilities. Theory of Probability & Its Applications, 16(2):264–280,
1971.

[24] F. X. Yu, L. Cao, M. Merler, T. Chen, J.R. Smith, and S.-F. Chang. Modeling attributes from

category-attribute proportions. In ACM Multimedia, 2014.

[25] F. X. Yu, D. Liu, Sanjiv K., T. Jebara, and S.-F. Chang.

SVM for learning with label propor-

tions. In Proceedings of the 30th International Conference on Machine Learning, 2013.

∝

[26] Tong Zhang. Covering number bounds of certain regularized linear function classes. The

Journal of Machine Learning Research, 2:527–550, 2002.

