9
1
0
2
 
g
u
A
 
5
 
 
]
L
M

.
t
a
t
s
[
 
 
4
v
4
4
2
2
1
.
5
0
8
1
:
v
i
X
r
a

Mining gold from implicit models to improve
likelihood-free inference

Johann Brehmer,1 Gilles Louppe,2 Juan Pavez,3 and Kyle Cranmer1
1 New York University, 2 University of Liège, 3 Federico Santa María Technical University
johann.brehmer@nyu.edu, g.louppe@uliege.be,
juan.pavezs@alumnos.usm.cl, kyle.cranmer@nyu.edu

Abstract

Simulators often provide the best description of real-world phenomena. However,
the density they implicitly deﬁne is often intractable, leading to challenging inverse
problems for inference. Recently, a number of techniques have been introduced in
which a surrogate for the intractable density is learned, including normalizing ﬂows
and density ratio estimators. We show that additional information that characterizes
the latent process can often be extracted from simulators and used to augment the
training data for these surrogate models. We introduce several new loss functions
that leverage this augmented data, and demonstrate that these new techniques can
improve sample efﬁciency and quality of inference.

1

Introduction

In many areas of science, complicated real-world phenomena are best described through computer
simulations. Typically, the simulators implement a stochastic generative process in the “forward”
mode based on a well-motivated mechanistic model with parameters θ. While the simulators can
generate samples of observations x ∼ p(x|θ), they typically do not admit a tractable likelihood (or
density) p(x|θ). Probabilistic models deﬁned only via the samples they produce are often called
implicit models. Implicit models lead to intractable inverse problems, which is a barrier for statistical
inference of the parameters θ given observed data. These problems arise in ﬁelds as diverse as
particle physics, epidemiology, and population genetics, which has motivated the development of
likelihood-free inference algorithms such as Approximate Bayesian Computation (ABC) [1–4] and
neural density estimation (NDE) techniques [5–34]. While many of these techniques can be exact
in the limit of inﬁnite training samples, real-world simulators are computationally expensive, and
sample efﬁciency is immensely important.

We present a suite of new techniques that can dramatically improve the sample efﬁciency for training
neural network surrogates that estimate the likelihood p(x|θ) or likelihood ratio r(x|θ0, θ1) =
p(x|θ0)/p(x|θ1). This provides the key quantity needed for both frequentist and Bayesian inference
procedures. Our approach involves extracting additional information that characterizes the latent
process from the simulator, as we explain in Sec. 3. In Sec. 4 we introduce the loss functions that
utilize this augmented data. In Sec. 5 we demonstrate through a range of experiments that these new
techniques provide a signiﬁcant increase in sample efﬁciency compared to techniques that do not
leverage the augmented data, which ultimately increase the quality of inference.

Techniques for likelihood-free inference can be divided into two broad categories. In the ﬁrst category,
the inference is performed by directly comparing the observed data to the output of the simulator.
This includes Approximate Bayesian Computation (ABC) [1–4] and probabilistic programming

2 Related work

Preprint. Under review.

systems [35, 36]. Here we focus on a second category, in which the simulator is used to generate
training data for a tractable surrogate model that is used during inference. There are rich connections
between simulator-based inference and learning in implicit generative models such as GANs, with a
considerable amount of cross-pollination between these areas [9].

The likelihood ratio trick (LRT). A surrogate model for the likelihood ratio ˆr(x|θ0, θ1) can
be deﬁned by training a probabilistic classiﬁer to discriminate between two equal-sized samples
{xi} ∼ p(x|θ0) and {xi} ∼ p(x|θ1). The binary cross-entropy loss

LXE = −E[1(θ = θ1) log ˆs(x|θ0, θ1) + 1(θ = θ0) log(1 − ˆs(x|θ0, θ1))]

(1)

is minimized by the optimal decision function s(x|θ0, θ1) = p(x|θ1)/(p(x|θ0) + p(x|θ1)). Inverting
this relation, the likelihood ratio can be estimated from the classiﬁer decision function ˆs(x) as
ˆr(x|θ0, θ1) = (1 − ˆs(x|θ0, θ1))/ˆs(x|θ0, θ1). This “likelihood ratio trick” is widely appreciated [5–
13]. In practice, not all probabilistic classiﬁers trained to separate samples from θ0 and θ1 learn the
optimal decision function. As long as the classiﬁer decision function is a monotonic function of the
likelihood ratio, this relation can be restored through a calibration procedure, substantially increasing
the applicability of the likelihood ratio trick [6–8]. We use the term CARL (Calibrated approximate
ratios of likelihoods) to describe likelihood ratio estimators based on calibrated classiﬁers.

Neural density estimation (NDE). More recently, several methods for conditional density estima-
tion have been proposed, often based on neural networks [13–34]. They can be used to train a surrog-
ate for the likelihood p(x|θ) [17, 19, 34] or, in a Bayesian setting, the posterior p(θ|x) [29, 33, 37].
One particularly interesting class of models are normalizing ﬂows [14–22], which model the density
as a sequence of invertible transformations applied to a simple base density. The target density
is then given by the Jacobian determinant of the transformation. Closely related, autoregressive
models [23–27] factorize a target density as a sequence of simpler conditional densities.

Novel contributions. The most important novel contribution that differentiates our work from the
existing methods is the observation that additional information can be extracted from the simulator,
and the development of loss functions that allow us to use this “augmented” data to more efﬁciently
learn surrogates for the likelihood function. In addition, we show how the augmented data can
be used to deﬁne locally optimal summary statistics, which can then be used for inference with
density estimation techniques or ABC. We playfully introduce the analogy of mining gold as this
augmented data requires work to extract and is very valuable. In experiments we demonstrate that
these approaches can dramatically improve sample efﬁciency and quality of likelihood-free inference.

Concurrently, the application of these methods to a speciﬁc class of problems in particle physics
has been discussed in Refs. [38, 39]. The present manuscript is meant to serve as the primary
reference for these new techniques and is addressed to the broader physical science and machine
learning communities. Most importantly, it generalizes the speciﬁc particle physics case to almost
any scientiﬁc simulator, requiring signiﬁcantly weaker assumption than those made in the physics
context. We also introduce an entirely new algorithm called SCANDAL, for which we provide the
ﬁrst experimental results.

3 Extracting more information from the simulator

We consider a scientiﬁc simulator that implements a stochastic generative process that proceeds
through a series of latent states zi ∈ Zi and ﬁnally to an output x ∈ Rdx . The latent space structure
Z can involve discrete and continuous components and is derived from the control ﬂow of the
(differentiable or non-differentiable) simulation code. Based on the mechanistic model implemented
by the simulator, each latent state is sampled from a conditional probability density zi ∼ pi(zi|θ, z<i)
and the ﬁnal output is sampled from x ∼ px(x|θ, z). The likelihood is then given by

(cid:90)

(cid:90)

p(x|θ) =

dz p(x, z|θ) =

dz px(x|θ, z)

pi(zi|θ, z<i) .

(2)

(cid:89)

i

Often the likelihood is intractable exactly because the latent space z is enormous and it is unfeasible
to explicitly calculate this integral. In real-world scientiﬁc simulators, the trajectory for a single
observation can involve many millions of latent variables.

2

In this paper we consider the problem of estimating the likelihood p(x|θ) or the likelihood ratio
r(x|θ0, θ1), which for the practical purpose of inferring parameter values θ can be used almost
interchangably, based on the data available from N runs of the simulator.

Typically, the setting of likelihood-free inference assumes that the only available output from the
simulator are samples of observations x ∼ p(x|θ). But in real-life simulators, more information can
usually be extracted. We typically have access to the latent variables z, and the distributions of each
latent variable pi(zi|θ, z<i) and px(x|θ, z) are tractable.

The key observation that is the starting point of our new inference methods is the following: While
p(x|θ) is intractable, for each simulated sample we can calculate the joint score

t(x, z|θ0) ≡ ∇θ log p(x, z|θ)

=

+ ∇θ log px(x|θ, z)

(3)

(cid:12)
(cid:12)
(cid:12)
(cid:12)θ0

(cid:12)
(cid:12)
∇θ log pi(zi|θ, z<i)
(cid:12)
(cid:12)θ0

(cid:88)

i

(cid:12)
(cid:12)
(cid:12)
(cid:12)θ0

by accumulating the factors ∇θ log p(zi|θ, z:i) as the simulation runs forward through its control
ﬂow conditioned on the random trajectory z. It can be insightful to think of the mechanistic model
in the simulator as deﬁning a policy πθ and t(x, z|θ0) as analogous to the policy gradient used in
REINFORCE [40]. However, instead of trying to optimize θ via a stochastic gradient estimate of some
reward function, we will simply augment the data generated by the simulator with the joint score.

Similarly, we can extract the joint likelihood ratio

r(x, z|θ0, θ1) ≡

p(x, z|θ0)
p(x, z|θ1)

=

px(x|θ0, z)
px(x|θ1, z)

(cid:89)

i

pi(zi|θ0, z<i)
pi(zi|θ1, z<i)

.

(4)

The joint score and joint likelihood ratio quantify how much more or less likely a particular simulated
trajectory through the simulator would be if one changed θ.

As a motivating example, consider the simulation for a
generalization of the Galton board, in which a set of balls
is dropped through a lattice of nails ending in one of sev-
eral bins denoted by x. The Galton board is commonly
used to demonstrate the central limit theorem, and if the
nails are uniformly placed such that the probability of
bouncing to the left is p, the sum over the latent space is
tractable analytically and the resulting distribution of x
is a binomial distribution. However, if the nails are not
uniformly placed, and the probability of bouncing to the
left is an arbitrary function of the nail position and some
parameter θ, the resulting distribution requires an explicit
sum over the latent paths z that might lead to a particular
x. Such a distribution would become intractable as the
size of the lattice increases. Figure 1 shows an example
of two latent trajectories that lead to the same x. In this
toy example, the probability p(zh, zv, θ) of going left is
given by (1 − f (zv))/2 + f (zv)σ(5θ(zh − 1/2)), where
f (zv) = sin(πzv), σ is the sigmoid function, and zh and
zv are the horizontal and vertical nail positions normal-
ized to [0, 1]. This leads to a non-trivial p(x|θ), which can
even be bimodal. Code for simulation and inference in
this problem is available at Ref. [41].

Figure 1: A toy simulation generalizing the
Galton board where the transitions are biased
left (blue) or right (red) depending on the nail
position and the value of θ. Two example lat-
ent trajectories z are shown (blue and green),
leading to the same observed value of x. Be-
low, the distribution for θ0 = −0.8 and
θ1 = −0.6. An example empirical distri-
bution from 100 runs for θ0 shows that the
sample variance is much larger than the dif-
ferences from θ0 vs θ1.

Figure 1 shows that a large number of samples from the
simulator are needed to reveal the differences in the distri-
bution of x for small changes in θ – the number of samples needed grows like (p/∆p)2. Moreover,
this toy simulation is representative of many real-world simulators in that it is composed of non-
differentiable control-ﬂow elements. This poses a difﬁculty, making methods based on ∇zx [42]
and ∇θx inapplicable, which previously motivated techniques such as Adversarial Variational
Optimization [32]. But the joint score in Eq. (3) can easily be computed by accumulating the
factors ∇θ log p(zh, zv|θ0), and we can calculate the joint likelihood ratio by accumulating factors
p(zh, zv|θ0)/p(zh, zv|θ1). In analogy to the Galton board toy example, even complicated real-world
simulators often allow us to accumulate these factors as they run, and to calculate the joint score and

3

joint likelihood ratio conditional on a particular stochastic execution trace z. We will demonstrate
this with two more examples in Sec. 5.

For simulators written in an automatic differentiation framework, the calculation of the joint score
and joint likelihood ratio can be entirely automatic and does not require any changes to the simulator
code and output. As a proof of principle, at Ref. [43] we provide a framework that automates
these calculations for any simulator in which all stochastic steps are implemented with the PYRO
library [44].

4 Learning from augmented data

4.1 Key idea

How can the “augmented data” consisting of simulated observations xi, the joint likelihood ratio
r(xi, zi|θ0, θ1), and the joint score t(xi, zi|θ0) be used to estimate the likelihood p(x|θ) or likelihood
ratio r(x|θ0, θ1)? The relation between r(x, z|θ0, θ1) and r(x|θ0, θ1) is not trivial — the integral of
the ratio is not the ratio of the integrals! Similarly, how can the joint score be used to estimate the
intractable score function

t(x|θ0) ≡ ∇θ log p(x|θ)

?

(cid:12)
(cid:12)
(cid:12)
(cid:12)θ0

The integral of the log is not the log of the integral!

Consider the squared error of a function ˆg(x) that only depends on the observable x, but is trying to
approximate a function g(x, z) that also depends on the latent variable z,

LMSE = Ep(x,z|θ)

(cid:104)

(g(x, z) − ˆg(x))2 (cid:105)

.

The minimum-mean-squared-error prediction of ˆg(x) is given by the conditional expectation g∗(x) =
arg minˆg LMSE = Ep(z|x,θ)[g(x, z)].
Identifying g(x, z) with the joint likelihood ratio r(x, z|θ0, θ1) and θ = θ1, we deﬁne
(cid:104)

Lr = Ep(x,z|θ1)

(r(x, z|θ0, θ1) − ˆr(x))2 (cid:105)

,

and ﬁnd that this functional is minimized by r∗(x) = arg minˆr Lr = Ep(z|x,θ1) [ r(x, z|θ0, θ1) ] =
r(x|θ0, θ1). Similarly, by identifying g(x, z) with the joint score t(x, z|θ0) and setting θ = θ0, we
deﬁne

Lt = Ep(x,z|θ0)

(cid:104) (cid:0)t(x, z|θ0) − ˆt(x|θ0)(cid:1)2 (cid:105)

,

which is minimized by t∗(x) = Ep(z|x,θ0) [ t(x, z|θ0) ] = t(x|θ0).
These loss functionals are immensely useful because they allow us to transform t(x, z|θ0) into t(x|θ0)
and r(x, z|θ0, θ1) into r(x|θ0, θ1): we are able to regress on these two intractable quantities! This is
what makes the joint score and joint likelihood ratio the gold worth mining.

(5)

(6)

(7)

(8)

4.2 Learning the likelihood ratio

Based on this observation we introduce a family of new likelihood-free inference techniques. They
fall into two categories. We ﬁrst discuss a class of algorithms that uses the augmented data to learn
a surrogate model for any likelihood p(x|θ) or likelihood ratio r(x|θ0, θ1). In Section 4.3 we will
deﬁne a second class of methods that is based on a local expansion of the model around some
reference parameter point.

The simulators we consider in this work do not only implicitly deﬁne a single density p(x), but a
family of densities p(x|θ). The parameters θ may potentially belong to a high-dimensional parameter
space. For inference models based on surrogate models, there are two broad strategies to model
this dependence. The ﬁrst is to estimate p(x|θ) or the likelihood ratio r(x|θ0, θ1) for speciﬁc values
of θ or pairs (θ0, θ1). This may be done via a pre-deﬁned set of θ values or on-demand using an
active-learning iteration. We follow a second approach, in which we train parameterized estimators
for the full model ˆp(x|θ) or ˆr(x|θ0, θ1) as a function of both the observables x and the parameters
θ [6, 45]. The training data then consists of a number of samples, each generated with different

4

values of θ0 and θ1, and the parameter values are used as additional inputs to the surrogate model.
When modeling the likelihood ratio, the reference hypothesis θ1 in the denominator of the likelihood
ratio can be kept at a ﬁxed reference value (or a marginal model with some prior π(θ1)), and only
the θ0 dependence is modeled by the network. This approach encourages the estimator to learn the
typically smooth dependence of the likelihood ratio on the parameters of interest from the training
data and borrow power from neighboring points.

ROLR (Regression On Likelihood Ratio): First, a number of parameter points (θ0, θ1) is drawn
from θi ∼ πi(θi). For each pair (θ0, θ1), we run the simulator both for θ0 and for θ1, labelling the
samples with y = 0 and y = 1, respectively. In addition to samples x ∼ p(x|θy) we also extract the
joint likelihood ratio r(x, z|θ0, θ1).

An expressive regressor ˆr(x|θ0, θ1) (e. g. a neural network) is trained by minimizing the squared
error loss

LROLR[ˆr] =

yi |r(xi, zi) − ˆr(xi)|2 + (1 − yi)

1
N

(cid:32)

(cid:88)

i

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
r(xi, zi)

−

2(cid:33)
.

1
ˆr(xi)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(9)

Here and in the following the θ dependence is implicit to reduce the notational clutter.

Both terms in this loss function are estimators of Eq. (7) (in the second term we switch θ0 ↔ θ1
to reduce the variance by mapping out other regions of x space). As we showed in the previous
section, this loss function is, at least in the limit of inﬁnite data, minimized by the true likelihood
ratio r(x|θ0, θ1). A regressor trained in this way thus provides an estimator for the likelihood ratio
and can be used for frequentist or Bayesian inference methods.

RASCAL (Ratio And SCore Approximate Likelihood ratio):
If such a likelihood ratio regressor
is differentiable (as is the case for neural networks) with respect to θ, we can calculate the predicted
score ˆt(x|θ0) = ∇θ0 log ˆr(x|θ0, θ1). For a perfect likelihood ratio estimator, ˆt(x|θ0) minimizes the
squared error with respect to the joint score, see Eq. (8). Turning this argument around, we can
improve the training of a likelihood ratio estimator by minimizing the combined ratio and score loss
with a hyper-parameter α

LRASCAL[ˆr] = LROLR[ˆr] + α

(1 − yi) |t(xi, zi) − ∇θ0 log ˆr(xi)|2 .

(10)

1
N

(cid:88)

i

CASCAL (CARL And SCore Approximate Likelihood ratio): The same trick can be used to
improve the likelihood ratio trick and the CARL inference method [6, 8]. Following the discussion
around Eq. (1), a calibrated classiﬁer trained to discriminate samples {xi} ∼ p(x|θ0) and {xi} ∼
p(x|θ1) provides a likelihood ratio estimator. For a differentiable parameterized classiﬁer, we can
calculate the surrogate score ˆt(x|θ0) = ∇θ0 log[(1 − ˆs(x|θ0, θ1))/ˆs(x|θ0, θ1)]. This allows us to
train an improved classiﬁer (and thus a likelihood ratio estimator) by minimizing the combined loss

LCASCAL[ˆs] = LXE[ˆs] + α

(1 − yi)

t(xi, zi) − ∇θ0 log

1
N

(cid:88)

i

(cid:12)
(cid:12)
(cid:12)
(cid:12)

2

(cid:20) 1 − ˆs(x)
ˆs(x)

(cid:21)(cid:12)
(cid:12)
(cid:12)
(cid:12)

.

(11)

SCANDAL (SCore-Augmented Neural Density Approximates Likelihood): Finally, we can use
the same strategy to improve conditional neural density estimators such as density networks or
normalizing ﬂows. If a parameterized neural density estimator ˆp(x|θ) is differentiable with respect to
θ, we can calculate the surrogate score ˆt(x) = ∇θ log ˆp(x|θ) and train an improved density estimator
by minimizing

LSCANDAL[ˆp] = LMLE + α

|t(xi, zi) − ∇θ log ˆp(x)|2 .

(12)

Unlike the methods discussed before, this provides an estimator of the likelihood itself rather than its
ratio. Depending on the architecture, the surrogate also provides a generative model.

1
N

(cid:88)

i

5

4.3 Locally sufﬁcient statistics for implicit models

A second class of new likelihood-free inference methods is based on an expansion of the implicit
model around a reference parameter point θref. Up to linear order in θ − θref, we ﬁnd

plocal(x|θ) =

p(t(x|θref) | θref) exp[t(x|θref) · (θ − θref)]

(13)

1
Z(θ)

with some normalization factor Z(θ). This local approximation is in the exponential family and the
score vector t(x|θref), deﬁned in Eq. (5), are its sufﬁcient statistics.
For inference in a sufﬁciently small neighborhood around a reference point θref, a precise estimator
of the score ˆt(x|θref) therefore deﬁnes a vector of ideal summary statistics that contain all the
information in an observation x on the parameters θ [see also 3, 46, 47]. The joint score together
with a minimization of the loss in Eq. (8) allows us to extract sufﬁcient statistics from an intractable,
non-differentiable simulator, at least in the neighborhood of θref. Moreover, this local model can be
estimated by running the simulator at a single value θref — it does not require scanning the θ space,
and thus avoids the curse of dimensionality. Based on this observation, we introduce two further
inference strategies:

SALLY (Score Approximates Likelihood LocallY): By minimizing the squared error with respect
to the joint score, see Eq. (8), we train a score estimator ˆt(x|θref). In a next step, we estimate the
density ˆp(ˆt(x|θref)|θ) through standard multivariate density estimation techniques. This calibration
procedure implicitly includes the effect of the normalizing constant Z(θ).

SALLINO (Score Approximates Likelihood Locally IN One dimension): The SALLY inference
method requires density estimation in the estimated score space, with typically dim ˆt ≡ dim θ (cid:28)
dim x. But in cases with large number of parameters, it is beneﬁcial to reduce the dimensionality even
further. In the local model of Eq. (13), the likelihood ratio r(x|θ0, θ1) only depends on h(x|θ0, θ1) ≡
t(x|θref) · (θ0 − θ1) up to an x-independent constant related to Z(θ). Any neural score estimator lets
us also estimate this scalar function, which is a sufﬁcient statistic for the 1-dimensional parameter
space connecting θ0 and θ1. We can thus estimate the likelihood ratio through univariate, rather than
multivariate, density estimation on ˆh.

The SALLY and SALLINO techniques are designed to work very well close to the reference point.
The local model approximation may deteriorate further away, leading to a reduced sensitivity and
weaker bounds. These approaches are simple and robust, and in particular the SALLINO algorithm
scales exceptionally well to high-dimensional parameter spaces.

For all these inference strategies, the augmented data is particularly powerful for enhancing the
power of simulation-based inference for small changes in the parameter θ. When restricted to
samples x ∼ p(x|θ), the variance from the simulator is a challenge. The ﬂuctuations in the empirical
density scale with the square root of the number of samples, thus large numbers of samples are
required before small changes in the implicit density can faithfully be distinguished. In contrast, each
sample of the joint ratio and joint score provides an exact piece of information even for arbitrarily
small changes in θ. On the other hand, the augmented data is less powerful for deciding between
model parameter points that are far apart. In this situation the joint probability distributions p(x, z|θ)
often do not overlap signiﬁcantly, and the joint likelihood ratio can have a large variance around the
intractable likelihood ratio r(x|θ0, θ1). In addition, over large distances in parameter space the local
model is not valid and the score does not characterize the likelihood ratios anymore, limiting the
usefulness of the joint score.

5 Experiments

Generalized Galton board. We return to the motivating example in Sec. 3 and Fig. 1 and try to
estimate likelihood ratios for the generalized Galton board. We use the likelihood ratio trick and
a neural density estimator as baselines and compare them to the new ROLR, RASCAL, CASCAL,
and SCANDAL methods. As the simulator deﬁnes a distribution over a discrete x, for the NDE and
SCANDAL methods we use a neural network with a softmax output layer over the bins to model
ˆp(x|θ). All networks are explicitly parameterized in terms of θ, the parameter of the simulator that

6

Figure 2: Left: Galton board example. MSE on log r vs. training sample size. We show the mean and its error
based on 15 runs. Middle: Lotka-Volterra example. MSE on log p (top) and log r (bottom) vs. training sample
size. We show the median and the standard deviation of 10 runs. Right: Particle physics example. MSE on log r
vs. training sample size.

deﬁnes the position of the nails (i. e. they take θ as an input). We use a simple network architecture
with a single hidden layer, 10 hidden units, and tanh activations. The left panel of Fig. 2 shows the
mean squared error between log ˆr(x|θ0, θ1) and the true log r(x|θ0, θ1) (estimated from histograms
of 2 · 104 simulations from θ0 = −0.8 and θ1 = −0.6), summing over x ∈ [5, 15], versus the
training sample size (which refers to the total number of x samples, distributed over 10 values of
θ ∈ [−1, −0.4]). We ﬁnd that both SCANDAL and RASCAL are dramatically more sample efﬁcient
than pure neural density estimation and the likelihood ratio trick, which do not leverage the joint
score. ROLR improves upon pure neural density estimation and achieves the same asymptotic error
as SCANDAL, though more slowly.

Lotka-Volterra model. As a second example, we consider the Lotka-Volterra system [48, 49], a
common example in the likelihood-free inference literature. This stochastic Markov jump process
models the dynamics of a species of predators interacting with a species of prey. Four parameters θ
set the rate of predators and prey being born, predators dying, and predators eating prey.

We simulate the Lotka-Volterra model with Gillespie’s algorithm [50]. From the time evolution of
the predator and prey populations we calculate summary statistics x ∈ R9. Our model deﬁnitions,
summary statistics, and initial conditions exactly follow Appendix F of Ref. [29]. In addition to the
observations, we extract the joint score as well as the joint likelihood ratio with respect to a reference
hypothesis log θ1 = (−4.61, −0.69, 0.00, −4.61)T from the simulator. On this augmented data we
train different likelihood and likelihood ratio estimators. As baselines we use CARL [6, 8] and a
conditional masked autoregressive ﬂow (MAF) [17, 51]. We compare them to the new techniques
introduced in section 4.2, including a SCANDAL likelihood estimator based on a MAF. For MAF and
SCANDAL we stack four masked autoregressive distribution estimators (MADEs) [23] on a mixture
of MADEs with 10 components [17]. For all other methods, we use three hidden layers. In all cases,
the hidden layers have 100 units and tanh activations. Code for simulation and inference is available
at Ref. [52].

For inference on a wide prior in the parameter space, the different probability densities often do not
overlap. As discussed above, the augmented data is then of limited use. Instead, we focus on the
regime where we try to discriminate between close parameter points with similar predictions for
the observables. We generate training data and evaluate the models in the range log(θ1)i − 0.01 ≤
θi ≤ log(θ1)i + 0.01 with a uniform prior in log space. In the middle panel of Fig. 2 we evaluate
the different methods by calculating the mean squared error of estimators trained on small training
samples. Since the true likelihood is intractable, we calculate the error with respect to the median
predictions of 10 estimators1 trained on the full data set of 200 000 samples.

1We pick the algorithms we use for these “ground truth” predictions based on the variance between independ-
ent runs and the consistency of improvements with increasing training sample size. For likelihood estimation,
we use the MAF as baseline, with qualitatively similar results when using SCANDAL. For likelihood ratio
estimation, we use the SCANDAL estimator as baseline, and ﬁnd qualitatively similar results for CASCAL.

7

Our results indicate a trade-off between the performance in likelihood (density) estimation and
likelihood ratio estimation. For density estimation, the MAF performs well. The variance of the
score term in the SCANDAL loss degrades the performance, especially for larger values of the
hyperparameter α. However, for statistical inference the more relevant quantity is the likelihood
ratio. Here the new techniques that use the joint score, in particular SCANDAL, are signiﬁcantly more
sample efﬁcient.

Particle physics. Finally we consider a real-world problem from particle physics. A simulator
describes the production of a Higgs boson at the Large Hadron Collider experiments, followed
by the decay into four electrons or muons, subsequent radiation patterns, the interaction with the
detector elements, and the reconstruction procedure. Each recorded collision produces a single
high-dimensional observable x ∈ R42, and the dataset consists of multiple iid observations of x.
The goal is to infer the likelihood of two parameters θ ∈ [−1, 1]2 that characterize the effect of
high-energy physics models on these interactions. We consider a synthetic observed dataset with 36
iid simulated observations of x drawn from θ = (0, 0).

The new inference techniques can accommodate state-of-the-art simulators, but in that setting we
cannot compare them to the true likelihood function. We therefore present a simpliﬁed setup and
approximate the detector response such that the true likelihood function is tractable, providing us
with a ground truth to compare the inference techniques to. As simulator we use a combination
of MADGRAPH 5 [53] and MADMAX [54–56]. The setup and the results of this experiment are
described at length in Ref. [39], which is attached as supplementary material.

In the right panel of Fig. 2 we show the expected mean squared error of the approximate
log ˆr(x|θ0, θ1) for the different techniques as a function of the training sample size. We take the
expectation over random values of θ0, drawn from a Gaussian prior with mean (0, 0) and covariance
matrix diag(0.22, 0.22). We compare the new techniques to the standard practice in particle physics,
in which the likelihood is estimated through histograms of two hand-picked summary statistics.

All new inference techniques outperform the traditional histogram method, provided that the training
samples are sufﬁciently large. Using augmented data substantially decreases the amount of training
data required for a good performance: the RASCAL method, which uses both the joint ratio and joint
score information from the simulator, reduces the amount of training data by two orders of magnitude
compared to the CARL technique, which uses only the samples x ∼ p(x|θ). The particularly simple
local techniques SALLY and SALLINO need even less data for a good performance. However, their
performance eventually plateaus and does not asymptote to zero error. This is because the local
model approximation breaks down further away from the reference point θref = (0, 0)T , and the
score is no longer the sufﬁcient statistics. In the supplementary material we show further results and
demonstrate how the improved likelihood ratio estimation leads to better inference results.

6 Conclusions

In this work we have presented a family of new inference techniques for the setting in which the
likelihood is only implicitly deﬁned through a stochastic generative simulator. The new methods
estimate likelihoods or ratios of likelihoods with data available from the simulator. Most established
inference methods, such as ABC and techniques based on neural density estimation, only use samples
of observables from the simulator. We pointed out that in many cases the joint likelihood ratio and
the joint score — quantities conditioned on the latent variables that characterize the trajectory through
the data generation process — can be extracted from the simulator.

While these additional quantities often require work to be extracted, they also prove to be very
valuable as they can dramatically improve sample efﬁciency and quality of inference. Indeed, we
have shown that this additional information lets us deﬁne loss functionals that are minimized by the
likelihood or likelihood ratio, which can in turn be used to efﬁciently guide the training of neural
networks to precisely estimate the likelihood function. A second class of new techniques is motivated
by a local approximation of the likelihood function around a reference parameter value, where the
score vector is the sufﬁcient statistic. In the case where the simulator provides the joint score, we can
use it to train a precise estimator of the score and use it as locally optimal summary statistics.

8

We have demonstrated in three experiments that the new inference techniques let us precisely estimate
likelihood ratios. In turn, this enables parameter measurements with a higher precision and less
training data than with established methods.

This approach is complementary to many recent advances in likelihood-free inference: the augmented
data can be used to improve training for any neural density estimator or likelihood ratio estimator,
as we have demonstrated for Masked Autoregressive Flows and CARL. It can also be used to deﬁne
locally optimal summary statistics that can be used for instance in ABC techniques.

Finally, these results motivate the development of tools that provide a nonstandard interpretation
of the simulator code and automatically generate the joint score and joint ratio, building on recent
developments in probabilistic programming and automatic differentiation [35, 36, 57–60]. We have
provided a ﬁrst proof-of-principle implementation of such a tool based on PYRO [43].

Acknowledgments

We would like to thank Cyril Becot and Lukas Heinrich, who contributed to this project at an
early stage. We are grateful to Jan-Matthis Lückmann for helping us automate the calculation of
the joint likelihood ratio and joint score in PYRO and to all participants of the Likelihood-free
inference workshop at the Flatiron Institute for great discussions. We would like to thank Felix
Kling, Tilman Plehn, and Peter Schichtel for providing the MADMAX code and helping us use it, and
to George Papamakarios for discussing the Masked Autoregressive Flow code with us. KC wants
to thank CP3 at UC Louvain for their hospitality. Finally, we would like to thank Atılım Güne¸s
Baydin, Lydia Brenner, Joan Bruna, Kyunghyun Cho, Michael Gill, Siavash Golkar, Ian Goodfellow,
Daniela Huppenkothen, Michael Kagan, Hugo Larochelle, Yann LeCun, Fabio Maltoni, Jean-Michel
Marin, Iain Murray, George Papamakarios, Duccio Pappadopulo, Dennis Prangle, Rajesh Ranganath,
Dustin Tran, Rost Verkerke, Wouter Verkerke, Max Welling, and Richard Wilkinson for interesting
discussions.

JB, KC, and GL are grateful for the support of the Moore-Sloan data science environment at NYU.
KC and GL were supported through the NSF grants ACI-1450310 and PHY-1505463. JP was partially
supported by the Scientiﬁc and Technological Center of Valparaíso (CCTVal) under Fondecyt grant
BASAL FB0821. This work was supported in part through the NYU IT High Performance Computing
resources, services, and staff expertise.

References

[1] D. B. Rubin:

‘Bayesianly justiﬁable and relevant frequency calculations for the applied
statistician’. Ann. Statist. 12 (4), p. 1151, 1984. URL https://doi.org/10.1214/aos/
1176346785.

[2] M. A. Beaumont, W. Zhang, and D. J. Balding: ‘Approximate bayesian computation in popula-

tion genetics’. Genetics 162 (4), p. 2025, 2002.

[3] J. Alsing, B. Wandelt, and S. Feeney: ‘Massive optimal data compression and density estimation

for scalable, likelihood-free inference in cosmology’ , 2018. arXiv:1801.01497.

[4] T. Charnock, G. Lavaux, and B. D. Wandelt: ‘Automatic physical inference with information

maximizing neural networks’. Phys. Rev. D97 (8), p. 083004, 2018. arXiv:1802.03537.

[5] I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, et al.: ‘Generative Adversarial Networks’. ArXiv

e-prints , 2014. arXiv:1406.2661.

[6] K. Cranmer, J. Pavez, and G. Louppe: ‘Approximating Likelihood Ratios with Calibrated

Discriminative Classiﬁers’ , 2015. arXiv:1506.02169.

[7] K. Cranmer and G. Louppe: ‘Unifying generative models and exact likelihood-free inference

with conditional bijections’. J. Brief Ideas , 2016.

[8] G. Louppe, K. Cranmer, and J. Pavez: ‘carl: a likelihood-free inference toolbox’. J. Open

Source Softw. , 2016.

[9] S. Mohamed and B. Lakshminarayanan: ‘Learning in Implicit Generative Models’. ArXiv

e-prints , 2016. arXiv:1610.03483.

9

[10] M. U. Gutmann, R. Dutta, S. Kaski, and J. Corander: ‘Likelihood-free inference via classiﬁca-

tion’. Statistics and Computing p. 1–15, 2017.

[11] T. Dinev and M. U. Gutmann: ‘Dynamic Likelihood-free Inference via Ratio Estimation

(DIRE)’. arXiv e-prints arXiv:1810.09899, 2018. arXiv:1810.09899.

[12] J. Hermans, V. Begy, and G. Louppe: ‘Likelihood-free MCMC with Approximate Likelihood

Ratios’ , 2019. arXiv:1903.04057.

[13] D. Tran, R. Ranganath, and D. Blei: ‘Hierarchical implicit models and likelihood-free vari-
ational inference’. In I. Guyon, U. V. Luxburg, S. Bengio, et al. (eds.), ‘Advances in Neural
Information Processing Systems 30’, p. 5523–5533, 2017.

[14] L. Dinh, D. Krueger, and Y. Bengio: ‘NICE: Non-linear Independent Components Estimation’.

ArXiv e-prints , 2014. arXiv:1410.8516.

[15] D. Jimenez Rezende and S. Mohamed: ‘Variational Inference with Normalizing Flows’. ArXiv

e-prints , 2015. arXiv:1505.05770.

[16] L. Dinh, J. Sohl-Dickstein, and S. Bengio: ‘Density estimation using Real NVP’. ArXiv e-prints

, 2016. arXiv:1605.08803.

[17] G. Papamakarios, T. Pavlakou, and I. Murray: ‘Masked Autoregressive Flow for Density

Estimation’. ArXiv e-prints , 2017. arXiv:1705.07057.

[18] C.-W. Huang, D. Krueger, A. Lacoste, and A. Courville: ‘Neural Autoregressive Flows’. ArXiv

e-prints , 2018. arXiv:1804.00779.

[19] G. Papamakarios, D. C. Sterratt, and I. Murray: ‘Sequential Neural Likelihood: Fast Likelihood-

free Inference with Autoregressive Flows’. ArXiv e-prints , 2018. arXiv:1805.07226.

[20] T. Q. Chen, Y. Rubanova, J. Bettencourt, and D. K. Duvenaud: ‘Neural ordinary differential
equations’. CoRR abs/1806.07366, 2018. arXiv:1806.07366, URL http://arxiv.org/abs/
1806.07366.

[21] D. P. Kingma and P. Dhariwal: ‘Glow: Generative Flow with Invertible 1x1 Convolutions’.

arXiv e-prints arXiv:1807.03039, 2018. arXiv:1807.03039.

[22] W. Grathwohl, R. T. Q. Chen, J. Bettencourt, I. Sutskever, and D. Duvenaud: ‘FFJORD: Free-
form Continuous Dynamics for Scalable Reversible Generative Models’. ArXiv e-prints , 2018.
arXiv:1810.01367.

[23] M. Germain, K. Gregor, I. Murray, and H. Larochelle: ‘MADE: Masked Autoencoder for

Distribution Estimation’. ArXiv e-prints , 2015. arXiv:1502.03509.

[24] B. Uria, M.-A. Côté, K. Gregor, I. Murray, and H. Larochelle: ‘Neural Autoregressive Distribu-

tion Estimation’. ArXiv e-prints , 2016. arXiv:1605.02226.

[25] A. van den Oord, S. Dieleman, H. Zen, et al.: ‘WaveNet: A Generative Model for Raw Audio’.

ArXiv e-prints , 2016. arXiv:1609.03499.

[26] A. van den Oord, N. Kalchbrenner, O. Vinyals, L. Espeholt, A. Graves, and K. Kavuk-
cuoglu: ‘Conditional Image Generation with PixelCNN Decoders’. ArXiv e-prints , 2016.
arXiv:1606.05328.

[27] A. van den Oord, N. Kalchbrenner, and K. Kavukcuoglu: ‘Pixel Recurrent Neural Networks’.

ArXiv e-prints , 2016. arXiv:1601.06759.

[28] Y. Fan, D. J. Nott, and S. A. Sisson: ‘Approximate Bayesian Computation via Regression

Density Estimation’. ArXiv e-prints , 2012. arXiv:1212.1479.

[29] G. Papamakarios and I. Murray: ‘Fast ε-free inference of simulation models with bayesian
conditional density estimation’. In ‘Advances in Neural Information Processing Systems’, p.
1028–1036, 2016.

10

[30] B. Paige and F. Wood: ‘Inference Networks for Sequential Monte Carlo in Graphical Models’.

ArXiv e-prints , 2016. arXiv:1602.06701.

[31] R. Dutta, J. Corander, S. Kaski, and M. U. Gutmann: ‘Likelihood-free inference by ratio

estimation’. ArXiv e-prints , 2016. arXiv:1611.10242.

[32] G. Louppe and K. Cranmer: ‘Adversarial Variational Optimization of Non-Differentiable

Simulators’. ArXiv e-prints , 2017. arXiv:1707.07113.

[33] J.-M. Lueckmann, P. J. Goncalves, G. Bassetto, K. Öcal, M. Nonnenmacher, and J. H. Macke:
‘Flexible statistical inference for mechanistic models of neural dynamics’. arXiv e-prints
arXiv:1711.01861, 2017. arXiv:1711.01861.

[34] J.-M. Lueckmann, G. Bassetto, T. Karaletsos, and J. H. Macke: ‘Likelihood-free inference with

emulator networks’. arXiv e-prints arXiv:1805.09294, 2018. arXiv:1805.09294.

[35] F. Wood, J. W. van de Meent, and V. Mansinghka: ‘A new approach to probabilistic program-
ming inference’. In ‘Proceedings of the 17th International conference on Artiﬁcial Intelligence
and Statistics’, p. 1024-1032, 2014.

[36] T. A. Le, Baydin, A. G. Baydin, and F. Wood: ‘Inference compilation and universal probabilistic
programming’. In ‘Proceedings of the 20th International Conference on Artiﬁcial Intelligence
and Statistics (AISTATS)’, volume 54 of Proceedings of Machine Learning Research, p. 1338–
1348. PMLR, Fort Lauderdale, FL, USA, 2017.

[37] D. S. Greenberg, M. Nonnenmacher, and J. H. Macke: ‘Automatic Posterior Transformation
for Likelihood-Free Inference’. arXiv e-prints arXiv:1905.07488, 2019. arXiv:1905.07488.

[38] J. Brehmer, K. Cranmer, G. Louppe, and J. Pavez: ‘Constraining Effective Field Theories with

Machine Learning’. Phys. Rev. Lett. 121 (11), p. 111801, 2018. arXiv:1805.00013.

[39] J. Brehmer, K. Cranmer, G. Louppe, and J. Pavez: ‘A Guide to Constraining Effective Field

Theories with Machine Learning’. Phys. Rev. D98 (5), p. 052004, 2018. arXiv:1805.00020.

[40] R. J. Williams: ‘Simple statistical gradient-following algorithms for connectionist reinforcement

learning’. In ‘Reinforcement Learning’, Springer, p. 5–32, 1992.

[41] J. Brehmer, K. Cranmer, G. Louppe, and J. Pavez: ‘Code repository for the generalized Galton
board example in the paper “Mining gold from implicit models to improve likelihood-free
inference”’. http://github.com/johannbrehmer/simulator-mining-example, 2018.

[42] M. M. Graham, A. J. Storkey, et al.: ‘Asymptotically exact inference in differentiable generative

models’. Electronic Journal of Statistics 11 (2), p. 5105, 2017.

[43] Participants of the Likelihood-Free Inference Meeting at the Flatiron Institute 2019: ‘Code
repository for the automatic calculation of joint score and joint likelihood ratio with Pyro.’
https://github.com/LFITaskForce/benchmark, 2019.

[44] E. Bingham, J. P. Chen, M. Jankowiak, et al.: ‘Pyro: Deep Universal Probabilistic Program-

ming’. Journal of Machine Learning Research , 2018.

[45] P. Baldi, K. Cranmer, T. Faucett, P. Sadowski, and D. Whiteson: ‘Parameterized neural networks

for high-energy physics’. Eur. Phys. J. C76 (5), p. 235, 2016. arXiv:1601.07913.

[46] J. Alsing and B. Wandelt: ‘Generalized massive optimal data compression’. Mon. Not. Roy.

Astron. Soc. 476 (1), p. L60, 2018. arXiv:1712.00012.

[47] J. Alsing and B. Wandelt: ‘Nuisance hardened data compression for fast likelihood-free infer-

ence’ , 2019. arXiv:1903.01473.

[48] A. J. Lotka: ‘Analytical note on certain rhythmic relations in organic systems’. Proceedings of

the National Academy of Sciences 6 (7), p. 410, 1920.

[49] A. J. Lotka: ‘Undamped oscillations derived from the law of mass action.’ Journal of the

american chemical society 42 (8), p. 1595, 1920.

11

[50] D. T. Gillespie: ‘A general method for numerically simulating the stochastic time evolution of

coupled chemical reactions’. Journal of Computational Physics 22 (4), p. 403 , 1976.

[51] G. Papamakarios, T. Pavlakou, and I. Murray: ‘Code repository for paper “Masked Autoregress-

ive Flow for Density Estimation”’. http://github.com/gpapamak/maf, 2017.

[52] J. Brehmer, K. Cranmer, G. Louppe, and J. Pavez: ‘Code repository for the Lotka-Volterra
example in the paper “Mining gold from implicit models to improve likelihood-free inference”’.
http://github.com/johannbrehmer/goldmine, 2018.

[53] J. Alwall, R. Frederix, S. Frixione, et al.: ‘The automated computation of tree-level and next-
to-leading order differential cross sections, and their matching to parton shower simulations’.
JHEP 07, p. 079, 2014. arXiv:1405.0301.

[54] K. Cranmer and T. Plehn: ‘Maximum signiﬁcance at the LHC and Higgs decays to muons’. Eur.

Phys. J. C51, p. 415, 2007. arXiv:hep-ph/0605268.

[55] T. Plehn, P. Schichtel, and D. Wiegand: ‘Where boosted signiﬁcances come from’. Phys. Rev.

D89 (5), p. 054002, 2014. arXiv:1311.2591.

[56] F. Kling, T. Plehn, and P. Schichtel: ‘Maximizing the signiﬁcance in Higgs boson pair analyses’.

Phys. Rev. D95 (3), p. 035026, 2017. arXiv:1607.07441.

[57] B. Eli, J. P. Chen, M. Jankowiak, et al.: ‘Pyro: Deep probabilistic programming’. https:

//github.com/uber/pyro, 2017.

[58] D. Tran, M. D. Hoffman, R. A. Saurous, E. Brevdo, K. Murphy, and D. M. Blei: ‘Deep

probabilistic programming’. arXiv preprint arXiv:1701.03757 , 2017.

[59] N. Siddharth, B. Paige, J.-W. van de Meent, et al.: ‘Learning disentangled representations with
semi-supervised deep generative models’. In I. Guyon, U. V. Luxburg, S. Bengio, et al. (eds.),
‘Advances in Neural Information Processing Systems 30’, p. 5927–5937. Curran Associates,
Inc., 2017.

[60] A. Gelman, D. Lee, and J. Guo: ‘Stan: A Probabilistic Programming Language for Bayesian
Inference and Optimization’. Journal of Educational and Behavioral Statistics 40 (5), p. 530,
2015.

12

9
1
0
2
 
g
u
A
 
5
 
 
]
L
M

.
t
a
t
s
[
 
 
4
v
4
4
2
2
1
.
5
0
8
1
:
v
i
X
r
a

Mining gold from implicit models to improve
likelihood-free inference

Johann Brehmer,1 Gilles Louppe,2 Juan Pavez,3 and Kyle Cranmer1
1 New York University, 2 University of Liège, 3 Federico Santa María Technical University
johann.brehmer@nyu.edu, g.louppe@uliege.be,
juan.pavezs@alumnos.usm.cl, kyle.cranmer@nyu.edu

Abstract

Simulators often provide the best description of real-world phenomena. However,
the density they implicitly deﬁne is often intractable, leading to challenging inverse
problems for inference. Recently, a number of techniques have been introduced in
which a surrogate for the intractable density is learned, including normalizing ﬂows
and density ratio estimators. We show that additional information that characterizes
the latent process can often be extracted from simulators and used to augment the
training data for these surrogate models. We introduce several new loss functions
that leverage this augmented data, and demonstrate that these new techniques can
improve sample efﬁciency and quality of inference.

1

Introduction

In many areas of science, complicated real-world phenomena are best described through computer
simulations. Typically, the simulators implement a stochastic generative process in the “forward”
mode based on a well-motivated mechanistic model with parameters θ. While the simulators can
generate samples of observations x ∼ p(x|θ), they typically do not admit a tractable likelihood (or
density) p(x|θ). Probabilistic models deﬁned only via the samples they produce are often called
implicit models. Implicit models lead to intractable inverse problems, which is a barrier for statistical
inference of the parameters θ given observed data. These problems arise in ﬁelds as diverse as
particle physics, epidemiology, and population genetics, which has motivated the development of
likelihood-free inference algorithms such as Approximate Bayesian Computation (ABC) [1–4] and
neural density estimation (NDE) techniques [5–34]. While many of these techniques can be exact
in the limit of inﬁnite training samples, real-world simulators are computationally expensive, and
sample efﬁciency is immensely important.

We present a suite of new techniques that can dramatically improve the sample efﬁciency for training
neural network surrogates that estimate the likelihood p(x|θ) or likelihood ratio r(x|θ0, θ1) =
p(x|θ0)/p(x|θ1). This provides the key quantity needed for both frequentist and Bayesian inference
procedures. Our approach involves extracting additional information that characterizes the latent
process from the simulator, as we explain in Sec. 3. In Sec. 4 we introduce the loss functions that
utilize this augmented data. In Sec. 5 we demonstrate through a range of experiments that these new
techniques provide a signiﬁcant increase in sample efﬁciency compared to techniques that do not
leverage the augmented data, which ultimately increase the quality of inference.

Techniques for likelihood-free inference can be divided into two broad categories. In the ﬁrst category,
the inference is performed by directly comparing the observed data to the output of the simulator.
This includes Approximate Bayesian Computation (ABC) [1–4] and probabilistic programming

2 Related work

Preprint. Under review.

systems [35, 36]. Here we focus on a second category, in which the simulator is used to generate
training data for a tractable surrogate model that is used during inference. There are rich connections
between simulator-based inference and learning in implicit generative models such as GANs, with a
considerable amount of cross-pollination between these areas [9].

The likelihood ratio trick (LRT). A surrogate model for the likelihood ratio ˆr(x|θ0, θ1) can
be deﬁned by training a probabilistic classiﬁer to discriminate between two equal-sized samples
{xi} ∼ p(x|θ0) and {xi} ∼ p(x|θ1). The binary cross-entropy loss

LXE = −E[1(θ = θ1) log ˆs(x|θ0, θ1) + 1(θ = θ0) log(1 − ˆs(x|θ0, θ1))]

(1)

is minimized by the optimal decision function s(x|θ0, θ1) = p(x|θ1)/(p(x|θ0) + p(x|θ1)). Inverting
this relation, the likelihood ratio can be estimated from the classiﬁer decision function ˆs(x) as
ˆr(x|θ0, θ1) = (1 − ˆs(x|θ0, θ1))/ˆs(x|θ0, θ1). This “likelihood ratio trick” is widely appreciated [5–
13]. In practice, not all probabilistic classiﬁers trained to separate samples from θ0 and θ1 learn the
optimal decision function. As long as the classiﬁer decision function is a monotonic function of the
likelihood ratio, this relation can be restored through a calibration procedure, substantially increasing
the applicability of the likelihood ratio trick [6–8]. We use the term CARL (Calibrated approximate
ratios of likelihoods) to describe likelihood ratio estimators based on calibrated classiﬁers.

Neural density estimation (NDE). More recently, several methods for conditional density estima-
tion have been proposed, often based on neural networks [13–34]. They can be used to train a surrog-
ate for the likelihood p(x|θ) [17, 19, 34] or, in a Bayesian setting, the posterior p(θ|x) [29, 33, 37].
One particularly interesting class of models are normalizing ﬂows [14–22], which model the density
as a sequence of invertible transformations applied to a simple base density. The target density
is then given by the Jacobian determinant of the transformation. Closely related, autoregressive
models [23–27] factorize a target density as a sequence of simpler conditional densities.

Novel contributions. The most important novel contribution that differentiates our work from the
existing methods is the observation that additional information can be extracted from the simulator,
and the development of loss functions that allow us to use this “augmented” data to more efﬁciently
learn surrogates for the likelihood function. In addition, we show how the augmented data can
be used to deﬁne locally optimal summary statistics, which can then be used for inference with
density estimation techniques or ABC. We playfully introduce the analogy of mining gold as this
augmented data requires work to extract and is very valuable. In experiments we demonstrate that
these approaches can dramatically improve sample efﬁciency and quality of likelihood-free inference.

Concurrently, the application of these methods to a speciﬁc class of problems in particle physics
has been discussed in Refs. [38, 39]. The present manuscript is meant to serve as the primary
reference for these new techniques and is addressed to the broader physical science and machine
learning communities. Most importantly, it generalizes the speciﬁc particle physics case to almost
any scientiﬁc simulator, requiring signiﬁcantly weaker assumption than those made in the physics
context. We also introduce an entirely new algorithm called SCANDAL, for which we provide the
ﬁrst experimental results.

3 Extracting more information from the simulator

We consider a scientiﬁc simulator that implements a stochastic generative process that proceeds
through a series of latent states zi ∈ Zi and ﬁnally to an output x ∈ Rdx . The latent space structure
Z can involve discrete and continuous components and is derived from the control ﬂow of the
(differentiable or non-differentiable) simulation code. Based on the mechanistic model implemented
by the simulator, each latent state is sampled from a conditional probability density zi ∼ pi(zi|θ, z<i)
and the ﬁnal output is sampled from x ∼ px(x|θ, z). The likelihood is then given by

(cid:90)

(cid:90)

p(x|θ) =

dz p(x, z|θ) =

dz px(x|θ, z)

pi(zi|θ, z<i) .

(2)

(cid:89)

i

Often the likelihood is intractable exactly because the latent space z is enormous and it is unfeasible
to explicitly calculate this integral. In real-world scientiﬁc simulators, the trajectory for a single
observation can involve many millions of latent variables.

2

In this paper we consider the problem of estimating the likelihood p(x|θ) or the likelihood ratio
r(x|θ0, θ1), which for the practical purpose of inferring parameter values θ can be used almost
interchangably, based on the data available from N runs of the simulator.

Typically, the setting of likelihood-free inference assumes that the only available output from the
simulator are samples of observations x ∼ p(x|θ). But in real-life simulators, more information can
usually be extracted. We typically have access to the latent variables z, and the distributions of each
latent variable pi(zi|θ, z<i) and px(x|θ, z) are tractable.

The key observation that is the starting point of our new inference methods is the following: While
p(x|θ) is intractable, for each simulated sample we can calculate the joint score

t(x, z|θ0) ≡ ∇θ log p(x, z|θ)

=

+ ∇θ log px(x|θ, z)

(3)

(cid:12)
(cid:12)
(cid:12)
(cid:12)θ0

(cid:12)
(cid:12)
∇θ log pi(zi|θ, z<i)
(cid:12)
(cid:12)θ0

(cid:88)

i

(cid:12)
(cid:12)
(cid:12)
(cid:12)θ0

by accumulating the factors ∇θ log p(zi|θ, z:i) as the simulation runs forward through its control
ﬂow conditioned on the random trajectory z. It can be insightful to think of the mechanistic model
in the simulator as deﬁning a policy πθ and t(x, z|θ0) as analogous to the policy gradient used in
REINFORCE [40]. However, instead of trying to optimize θ via a stochastic gradient estimate of some
reward function, we will simply augment the data generated by the simulator with the joint score.

Similarly, we can extract the joint likelihood ratio

r(x, z|θ0, θ1) ≡

p(x, z|θ0)
p(x, z|θ1)

=

px(x|θ0, z)
px(x|θ1, z)

(cid:89)

i

pi(zi|θ0, z<i)
pi(zi|θ1, z<i)

.

(4)

The joint score and joint likelihood ratio quantify how much more or less likely a particular simulated
trajectory through the simulator would be if one changed θ.

As a motivating example, consider the simulation for a
generalization of the Galton board, in which a set of balls
is dropped through a lattice of nails ending in one of sev-
eral bins denoted by x. The Galton board is commonly
used to demonstrate the central limit theorem, and if the
nails are uniformly placed such that the probability of
bouncing to the left is p, the sum over the latent space is
tractable analytically and the resulting distribution of x
is a binomial distribution. However, if the nails are not
uniformly placed, and the probability of bouncing to the
left is an arbitrary function of the nail position and some
parameter θ, the resulting distribution requires an explicit
sum over the latent paths z that might lead to a particular
x. Such a distribution would become intractable as the
size of the lattice increases. Figure 1 shows an example
of two latent trajectories that lead to the same x. In this
toy example, the probability p(zh, zv, θ) of going left is
given by (1 − f (zv))/2 + f (zv)σ(5θ(zh − 1/2)), where
f (zv) = sin(πzv), σ is the sigmoid function, and zh and
zv are the horizontal and vertical nail positions normal-
ized to [0, 1]. This leads to a non-trivial p(x|θ), which can
even be bimodal. Code for simulation and inference in
this problem is available at Ref. [41].

Figure 1: A toy simulation generalizing the
Galton board where the transitions are biased
left (blue) or right (red) depending on the nail
position and the value of θ. Two example lat-
ent trajectories z are shown (blue and green),
leading to the same observed value of x. Be-
low, the distribution for θ0 = −0.8 and
θ1 = −0.6. An example empirical distri-
bution from 100 runs for θ0 shows that the
sample variance is much larger than the dif-
ferences from θ0 vs θ1.

Figure 1 shows that a large number of samples from the
simulator are needed to reveal the differences in the distri-
bution of x for small changes in θ – the number of samples needed grows like (p/∆p)2. Moreover,
this toy simulation is representative of many real-world simulators in that it is composed of non-
differentiable control-ﬂow elements. This poses a difﬁculty, making methods based on ∇zx [42]
and ∇θx inapplicable, which previously motivated techniques such as Adversarial Variational
Optimization [32]. But the joint score in Eq. (3) can easily be computed by accumulating the
factors ∇θ log p(zh, zv|θ0), and we can calculate the joint likelihood ratio by accumulating factors
p(zh, zv|θ0)/p(zh, zv|θ1). In analogy to the Galton board toy example, even complicated real-world
simulators often allow us to accumulate these factors as they run, and to calculate the joint score and

3

joint likelihood ratio conditional on a particular stochastic execution trace z. We will demonstrate
this with two more examples in Sec. 5.

For simulators written in an automatic differentiation framework, the calculation of the joint score
and joint likelihood ratio can be entirely automatic and does not require any changes to the simulator
code and output. As a proof of principle, at Ref. [43] we provide a framework that automates
these calculations for any simulator in which all stochastic steps are implemented with the PYRO
library [44].

4 Learning from augmented data

4.1 Key idea

How can the “augmented data” consisting of simulated observations xi, the joint likelihood ratio
r(xi, zi|θ0, θ1), and the joint score t(xi, zi|θ0) be used to estimate the likelihood p(x|θ) or likelihood
ratio r(x|θ0, θ1)? The relation between r(x, z|θ0, θ1) and r(x|θ0, θ1) is not trivial — the integral of
the ratio is not the ratio of the integrals! Similarly, how can the joint score be used to estimate the
intractable score function

t(x|θ0) ≡ ∇θ log p(x|θ)

?

(cid:12)
(cid:12)
(cid:12)
(cid:12)θ0

The integral of the log is not the log of the integral!

Consider the squared error of a function ˆg(x) that only depends on the observable x, but is trying to
approximate a function g(x, z) that also depends on the latent variable z,

LMSE = Ep(x,z|θ)

(cid:104)

(g(x, z) − ˆg(x))2 (cid:105)

.

The minimum-mean-squared-error prediction of ˆg(x) is given by the conditional expectation g∗(x) =
arg minˆg LMSE = Ep(z|x,θ)[g(x, z)].
Identifying g(x, z) with the joint likelihood ratio r(x, z|θ0, θ1) and θ = θ1, we deﬁne
(cid:104)

Lr = Ep(x,z|θ1)

(r(x, z|θ0, θ1) − ˆr(x))2 (cid:105)

,

and ﬁnd that this functional is minimized by r∗(x) = arg minˆr Lr = Ep(z|x,θ1) [ r(x, z|θ0, θ1) ] =
r(x|θ0, θ1). Similarly, by identifying g(x, z) with the joint score t(x, z|θ0) and setting θ = θ0, we
deﬁne

Lt = Ep(x,z|θ0)

(cid:104) (cid:0)t(x, z|θ0) − ˆt(x|θ0)(cid:1)2 (cid:105)

,

which is minimized by t∗(x) = Ep(z|x,θ0) [ t(x, z|θ0) ] = t(x|θ0).
These loss functionals are immensely useful because they allow us to transform t(x, z|θ0) into t(x|θ0)
and r(x, z|θ0, θ1) into r(x|θ0, θ1): we are able to regress on these two intractable quantities! This is
what makes the joint score and joint likelihood ratio the gold worth mining.

(5)

(6)

(7)

(8)

4.2 Learning the likelihood ratio

Based on this observation we introduce a family of new likelihood-free inference techniques. They
fall into two categories. We ﬁrst discuss a class of algorithms that uses the augmented data to learn
a surrogate model for any likelihood p(x|θ) or likelihood ratio r(x|θ0, θ1). In Section 4.3 we will
deﬁne a second class of methods that is based on a local expansion of the model around some
reference parameter point.

The simulators we consider in this work do not only implicitly deﬁne a single density p(x), but a
family of densities p(x|θ). The parameters θ may potentially belong to a high-dimensional parameter
space. For inference models based on surrogate models, there are two broad strategies to model
this dependence. The ﬁrst is to estimate p(x|θ) or the likelihood ratio r(x|θ0, θ1) for speciﬁc values
of θ or pairs (θ0, θ1). This may be done via a pre-deﬁned set of θ values or on-demand using an
active-learning iteration. We follow a second approach, in which we train parameterized estimators
for the full model ˆp(x|θ) or ˆr(x|θ0, θ1) as a function of both the observables x and the parameters
θ [6, 45]. The training data then consists of a number of samples, each generated with different

4

values of θ0 and θ1, and the parameter values are used as additional inputs to the surrogate model.
When modeling the likelihood ratio, the reference hypothesis θ1 in the denominator of the likelihood
ratio can be kept at a ﬁxed reference value (or a marginal model with some prior π(θ1)), and only
the θ0 dependence is modeled by the network. This approach encourages the estimator to learn the
typically smooth dependence of the likelihood ratio on the parameters of interest from the training
data and borrow power from neighboring points.

ROLR (Regression On Likelihood Ratio): First, a number of parameter points (θ0, θ1) is drawn
from θi ∼ πi(θi). For each pair (θ0, θ1), we run the simulator both for θ0 and for θ1, labelling the
samples with y = 0 and y = 1, respectively. In addition to samples x ∼ p(x|θy) we also extract the
joint likelihood ratio r(x, z|θ0, θ1).

An expressive regressor ˆr(x|θ0, θ1) (e. g. a neural network) is trained by minimizing the squared
error loss

LROLR[ˆr] =

yi |r(xi, zi) − ˆr(xi)|2 + (1 − yi)

1
N

(cid:32)

(cid:88)

i

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
r(xi, zi)

−

2(cid:33)
.

1
ˆr(xi)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(9)

Here and in the following the θ dependence is implicit to reduce the notational clutter.

Both terms in this loss function are estimators of Eq. (7) (in the second term we switch θ0 ↔ θ1
to reduce the variance by mapping out other regions of x space). As we showed in the previous
section, this loss function is, at least in the limit of inﬁnite data, minimized by the true likelihood
ratio r(x|θ0, θ1). A regressor trained in this way thus provides an estimator for the likelihood ratio
and can be used for frequentist or Bayesian inference methods.

RASCAL (Ratio And SCore Approximate Likelihood ratio):
If such a likelihood ratio regressor
is differentiable (as is the case for neural networks) with respect to θ, we can calculate the predicted
score ˆt(x|θ0) = ∇θ0 log ˆr(x|θ0, θ1). For a perfect likelihood ratio estimator, ˆt(x|θ0) minimizes the
squared error with respect to the joint score, see Eq. (8). Turning this argument around, we can
improve the training of a likelihood ratio estimator by minimizing the combined ratio and score loss
with a hyper-parameter α

LRASCAL[ˆr] = LROLR[ˆr] + α

(1 − yi) |t(xi, zi) − ∇θ0 log ˆr(xi)|2 .

(10)

1
N

(cid:88)

i

CASCAL (CARL And SCore Approximate Likelihood ratio): The same trick can be used to
improve the likelihood ratio trick and the CARL inference method [6, 8]. Following the discussion
around Eq. (1), a calibrated classiﬁer trained to discriminate samples {xi} ∼ p(x|θ0) and {xi} ∼
p(x|θ1) provides a likelihood ratio estimator. For a differentiable parameterized classiﬁer, we can
calculate the surrogate score ˆt(x|θ0) = ∇θ0 log[(1 − ˆs(x|θ0, θ1))/ˆs(x|θ0, θ1)]. This allows us to
train an improved classiﬁer (and thus a likelihood ratio estimator) by minimizing the combined loss

LCASCAL[ˆs] = LXE[ˆs] + α

(1 − yi)

t(xi, zi) − ∇θ0 log

1
N

(cid:88)

i

(cid:12)
(cid:12)
(cid:12)
(cid:12)

2

(cid:20) 1 − ˆs(x)
ˆs(x)

(cid:21)(cid:12)
(cid:12)
(cid:12)
(cid:12)

.

(11)

SCANDAL (SCore-Augmented Neural Density Approximates Likelihood): Finally, we can use
the same strategy to improve conditional neural density estimators such as density networks or
normalizing ﬂows. If a parameterized neural density estimator ˆp(x|θ) is differentiable with respect to
θ, we can calculate the surrogate score ˆt(x) = ∇θ log ˆp(x|θ) and train an improved density estimator
by minimizing

LSCANDAL[ˆp] = LMLE + α

|t(xi, zi) − ∇θ log ˆp(x)|2 .

(12)

Unlike the methods discussed before, this provides an estimator of the likelihood itself rather than its
ratio. Depending on the architecture, the surrogate also provides a generative model.

1
N

(cid:88)

i

5

4.3 Locally sufﬁcient statistics for implicit models

A second class of new likelihood-free inference methods is based on an expansion of the implicit
model around a reference parameter point θref. Up to linear order in θ − θref, we ﬁnd

plocal(x|θ) =

p(t(x|θref) | θref) exp[t(x|θref) · (θ − θref)]

(13)

1
Z(θ)

with some normalization factor Z(θ). This local approximation is in the exponential family and the
score vector t(x|θref), deﬁned in Eq. (5), are its sufﬁcient statistics.
For inference in a sufﬁciently small neighborhood around a reference point θref, a precise estimator
of the score ˆt(x|θref) therefore deﬁnes a vector of ideal summary statistics that contain all the
information in an observation x on the parameters θ [see also 3, 46, 47]. The joint score together
with a minimization of the loss in Eq. (8) allows us to extract sufﬁcient statistics from an intractable,
non-differentiable simulator, at least in the neighborhood of θref. Moreover, this local model can be
estimated by running the simulator at a single value θref — it does not require scanning the θ space,
and thus avoids the curse of dimensionality. Based on this observation, we introduce two further
inference strategies:

SALLY (Score Approximates Likelihood LocallY): By minimizing the squared error with respect
to the joint score, see Eq. (8), we train a score estimator ˆt(x|θref). In a next step, we estimate the
density ˆp(ˆt(x|θref)|θ) through standard multivariate density estimation techniques. This calibration
procedure implicitly includes the effect of the normalizing constant Z(θ).

SALLINO (Score Approximates Likelihood Locally IN One dimension): The SALLY inference
method requires density estimation in the estimated score space, with typically dim ˆt ≡ dim θ (cid:28)
dim x. But in cases with large number of parameters, it is beneﬁcial to reduce the dimensionality even
further. In the local model of Eq. (13), the likelihood ratio r(x|θ0, θ1) only depends on h(x|θ0, θ1) ≡
t(x|θref) · (θ0 − θ1) up to an x-independent constant related to Z(θ). Any neural score estimator lets
us also estimate this scalar function, which is a sufﬁcient statistic for the 1-dimensional parameter
space connecting θ0 and θ1. We can thus estimate the likelihood ratio through univariate, rather than
multivariate, density estimation on ˆh.

The SALLY and SALLINO techniques are designed to work very well close to the reference point.
The local model approximation may deteriorate further away, leading to a reduced sensitivity and
weaker bounds. These approaches are simple and robust, and in particular the SALLINO algorithm
scales exceptionally well to high-dimensional parameter spaces.

For all these inference strategies, the augmented data is particularly powerful for enhancing the
power of simulation-based inference for small changes in the parameter θ. When restricted to
samples x ∼ p(x|θ), the variance from the simulator is a challenge. The ﬂuctuations in the empirical
density scale with the square root of the number of samples, thus large numbers of samples are
required before small changes in the implicit density can faithfully be distinguished. In contrast, each
sample of the joint ratio and joint score provides an exact piece of information even for arbitrarily
small changes in θ. On the other hand, the augmented data is less powerful for deciding between
model parameter points that are far apart. In this situation the joint probability distributions p(x, z|θ)
often do not overlap signiﬁcantly, and the joint likelihood ratio can have a large variance around the
intractable likelihood ratio r(x|θ0, θ1). In addition, over large distances in parameter space the local
model is not valid and the score does not characterize the likelihood ratios anymore, limiting the
usefulness of the joint score.

5 Experiments

Generalized Galton board. We return to the motivating example in Sec. 3 and Fig. 1 and try to
estimate likelihood ratios for the generalized Galton board. We use the likelihood ratio trick and
a neural density estimator as baselines and compare them to the new ROLR, RASCAL, CASCAL,
and SCANDAL methods. As the simulator deﬁnes a distribution over a discrete x, for the NDE and
SCANDAL methods we use a neural network with a softmax output layer over the bins to model
ˆp(x|θ). All networks are explicitly parameterized in terms of θ, the parameter of the simulator that

6

Figure 2: Left: Galton board example. MSE on log r vs. training sample size. We show the mean and its error
based on 15 runs. Middle: Lotka-Volterra example. MSE on log p (top) and log r (bottom) vs. training sample
size. We show the median and the standard deviation of 10 runs. Right: Particle physics example. MSE on log r
vs. training sample size.

deﬁnes the position of the nails (i. e. they take θ as an input). We use a simple network architecture
with a single hidden layer, 10 hidden units, and tanh activations. The left panel of Fig. 2 shows the
mean squared error between log ˆr(x|θ0, θ1) and the true log r(x|θ0, θ1) (estimated from histograms
of 2 · 104 simulations from θ0 = −0.8 and θ1 = −0.6), summing over x ∈ [5, 15], versus the
training sample size (which refers to the total number of x samples, distributed over 10 values of
θ ∈ [−1, −0.4]). We ﬁnd that both SCANDAL and RASCAL are dramatically more sample efﬁcient
than pure neural density estimation and the likelihood ratio trick, which do not leverage the joint
score. ROLR improves upon pure neural density estimation and achieves the same asymptotic error
as SCANDAL, though more slowly.

Lotka-Volterra model. As a second example, we consider the Lotka-Volterra system [48, 49], a
common example in the likelihood-free inference literature. This stochastic Markov jump process
models the dynamics of a species of predators interacting with a species of prey. Four parameters θ
set the rate of predators and prey being born, predators dying, and predators eating prey.

We simulate the Lotka-Volterra model with Gillespie’s algorithm [50]. From the time evolution of
the predator and prey populations we calculate summary statistics x ∈ R9. Our model deﬁnitions,
summary statistics, and initial conditions exactly follow Appendix F of Ref. [29]. In addition to the
observations, we extract the joint score as well as the joint likelihood ratio with respect to a reference
hypothesis log θ1 = (−4.61, −0.69, 0.00, −4.61)T from the simulator. On this augmented data we
train different likelihood and likelihood ratio estimators. As baselines we use CARL [6, 8] and a
conditional masked autoregressive ﬂow (MAF) [17, 51]. We compare them to the new techniques
introduced in section 4.2, including a SCANDAL likelihood estimator based on a MAF. For MAF and
SCANDAL we stack four masked autoregressive distribution estimators (MADEs) [23] on a mixture
of MADEs with 10 components [17]. For all other methods, we use three hidden layers. In all cases,
the hidden layers have 100 units and tanh activations. Code for simulation and inference is available
at Ref. [52].

For inference on a wide prior in the parameter space, the different probability densities often do not
overlap. As discussed above, the augmented data is then of limited use. Instead, we focus on the
regime where we try to discriminate between close parameter points with similar predictions for
the observables. We generate training data and evaluate the models in the range log(θ1)i − 0.01 ≤
θi ≤ log(θ1)i + 0.01 with a uniform prior in log space. In the middle panel of Fig. 2 we evaluate
the different methods by calculating the mean squared error of estimators trained on small training
samples. Since the true likelihood is intractable, we calculate the error with respect to the median
predictions of 10 estimators1 trained on the full data set of 200 000 samples.

1We pick the algorithms we use for these “ground truth” predictions based on the variance between independ-
ent runs and the consistency of improvements with increasing training sample size. For likelihood estimation,
we use the MAF as baseline, with qualitatively similar results when using SCANDAL. For likelihood ratio
estimation, we use the SCANDAL estimator as baseline, and ﬁnd qualitatively similar results for CASCAL.

7

Our results indicate a trade-off between the performance in likelihood (density) estimation and
likelihood ratio estimation. For density estimation, the MAF performs well. The variance of the
score term in the SCANDAL loss degrades the performance, especially for larger values of the
hyperparameter α. However, for statistical inference the more relevant quantity is the likelihood
ratio. Here the new techniques that use the joint score, in particular SCANDAL, are signiﬁcantly more
sample efﬁcient.

Particle physics. Finally we consider a real-world problem from particle physics. A simulator
describes the production of a Higgs boson at the Large Hadron Collider experiments, followed
by the decay into four electrons or muons, subsequent radiation patterns, the interaction with the
detector elements, and the reconstruction procedure. Each recorded collision produces a single
high-dimensional observable x ∈ R42, and the dataset consists of multiple iid observations of x.
The goal is to infer the likelihood of two parameters θ ∈ [−1, 1]2 that characterize the effect of
high-energy physics models on these interactions. We consider a synthetic observed dataset with 36
iid simulated observations of x drawn from θ = (0, 0).

The new inference techniques can accommodate state-of-the-art simulators, but in that setting we
cannot compare them to the true likelihood function. We therefore present a simpliﬁed setup and
approximate the detector response such that the true likelihood function is tractable, providing us
with a ground truth to compare the inference techniques to. As simulator we use a combination
of MADGRAPH 5 [53] and MADMAX [54–56]. The setup and the results of this experiment are
described at length in Ref. [39], which is attached as supplementary material.

In the right panel of Fig. 2 we show the expected mean squared error of the approximate
log ˆr(x|θ0, θ1) for the different techniques as a function of the training sample size. We take the
expectation over random values of θ0, drawn from a Gaussian prior with mean (0, 0) and covariance
matrix diag(0.22, 0.22). We compare the new techniques to the standard practice in particle physics,
in which the likelihood is estimated through histograms of two hand-picked summary statistics.

All new inference techniques outperform the traditional histogram method, provided that the training
samples are sufﬁciently large. Using augmented data substantially decreases the amount of training
data required for a good performance: the RASCAL method, which uses both the joint ratio and joint
score information from the simulator, reduces the amount of training data by two orders of magnitude
compared to the CARL technique, which uses only the samples x ∼ p(x|θ). The particularly simple
local techniques SALLY and SALLINO need even less data for a good performance. However, their
performance eventually plateaus and does not asymptote to zero error. This is because the local
model approximation breaks down further away from the reference point θref = (0, 0)T , and the
score is no longer the sufﬁcient statistics. In the supplementary material we show further results and
demonstrate how the improved likelihood ratio estimation leads to better inference results.

6 Conclusions

In this work we have presented a family of new inference techniques for the setting in which the
likelihood is only implicitly deﬁned through a stochastic generative simulator. The new methods
estimate likelihoods or ratios of likelihoods with data available from the simulator. Most established
inference methods, such as ABC and techniques based on neural density estimation, only use samples
of observables from the simulator. We pointed out that in many cases the joint likelihood ratio and
the joint score — quantities conditioned on the latent variables that characterize the trajectory through
the data generation process — can be extracted from the simulator.

While these additional quantities often require work to be extracted, they also prove to be very
valuable as they can dramatically improve sample efﬁciency and quality of inference. Indeed, we
have shown that this additional information lets us deﬁne loss functionals that are minimized by the
likelihood or likelihood ratio, which can in turn be used to efﬁciently guide the training of neural
networks to precisely estimate the likelihood function. A second class of new techniques is motivated
by a local approximation of the likelihood function around a reference parameter value, where the
score vector is the sufﬁcient statistic. In the case where the simulator provides the joint score, we can
use it to train a precise estimator of the score and use it as locally optimal summary statistics.

8

We have demonstrated in three experiments that the new inference techniques let us precisely estimate
likelihood ratios. In turn, this enables parameter measurements with a higher precision and less
training data than with established methods.

This approach is complementary to many recent advances in likelihood-free inference: the augmented
data can be used to improve training for any neural density estimator or likelihood ratio estimator,
as we have demonstrated for Masked Autoregressive Flows and CARL. It can also be used to deﬁne
locally optimal summary statistics that can be used for instance in ABC techniques.

Finally, these results motivate the development of tools that provide a nonstandard interpretation
of the simulator code and automatically generate the joint score and joint ratio, building on recent
developments in probabilistic programming and automatic differentiation [35, 36, 57–60]. We have
provided a ﬁrst proof-of-principle implementation of such a tool based on PYRO [43].

Acknowledgments

We would like to thank Cyril Becot and Lukas Heinrich, who contributed to this project at an
early stage. We are grateful to Jan-Matthis Lückmann for helping us automate the calculation of
the joint likelihood ratio and joint score in PYRO and to all participants of the Likelihood-free
inference workshop at the Flatiron Institute for great discussions. We would like to thank Felix
Kling, Tilman Plehn, and Peter Schichtel for providing the MADMAX code and helping us use it, and
to George Papamakarios for discussing the Masked Autoregressive Flow code with us. KC wants
to thank CP3 at UC Louvain for their hospitality. Finally, we would like to thank Atılım Güne¸s
Baydin, Lydia Brenner, Joan Bruna, Kyunghyun Cho, Michael Gill, Siavash Golkar, Ian Goodfellow,
Daniela Huppenkothen, Michael Kagan, Hugo Larochelle, Yann LeCun, Fabio Maltoni, Jean-Michel
Marin, Iain Murray, George Papamakarios, Duccio Pappadopulo, Dennis Prangle, Rajesh Ranganath,
Dustin Tran, Rost Verkerke, Wouter Verkerke, Max Welling, and Richard Wilkinson for interesting
discussions.

JB, KC, and GL are grateful for the support of the Moore-Sloan data science environment at NYU.
KC and GL were supported through the NSF grants ACI-1450310 and PHY-1505463. JP was partially
supported by the Scientiﬁc and Technological Center of Valparaíso (CCTVal) under Fondecyt grant
BASAL FB0821. This work was supported in part through the NYU IT High Performance Computing
resources, services, and staff expertise.

References

[1] D. B. Rubin:

‘Bayesianly justiﬁable and relevant frequency calculations for the applied
statistician’. Ann. Statist. 12 (4), p. 1151, 1984. URL https://doi.org/10.1214/aos/
1176346785.

[2] M. A. Beaumont, W. Zhang, and D. J. Balding: ‘Approximate bayesian computation in popula-

tion genetics’. Genetics 162 (4), p. 2025, 2002.

[3] J. Alsing, B. Wandelt, and S. Feeney: ‘Massive optimal data compression and density estimation

for scalable, likelihood-free inference in cosmology’ , 2018. arXiv:1801.01497.

[4] T. Charnock, G. Lavaux, and B. D. Wandelt: ‘Automatic physical inference with information

maximizing neural networks’. Phys. Rev. D97 (8), p. 083004, 2018. arXiv:1802.03537.

[5] I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, et al.: ‘Generative Adversarial Networks’. ArXiv

e-prints , 2014. arXiv:1406.2661.

[6] K. Cranmer, J. Pavez, and G. Louppe: ‘Approximating Likelihood Ratios with Calibrated

Discriminative Classiﬁers’ , 2015. arXiv:1506.02169.

[7] K. Cranmer and G. Louppe: ‘Unifying generative models and exact likelihood-free inference

with conditional bijections’. J. Brief Ideas , 2016.

[8] G. Louppe, K. Cranmer, and J. Pavez: ‘carl: a likelihood-free inference toolbox’. J. Open

Source Softw. , 2016.

[9] S. Mohamed and B. Lakshminarayanan: ‘Learning in Implicit Generative Models’. ArXiv

e-prints , 2016. arXiv:1610.03483.

9

[10] M. U. Gutmann, R. Dutta, S. Kaski, and J. Corander: ‘Likelihood-free inference via classiﬁca-

tion’. Statistics and Computing p. 1–15, 2017.

[11] T. Dinev and M. U. Gutmann: ‘Dynamic Likelihood-free Inference via Ratio Estimation

(DIRE)’. arXiv e-prints arXiv:1810.09899, 2018. arXiv:1810.09899.

[12] J. Hermans, V. Begy, and G. Louppe: ‘Likelihood-free MCMC with Approximate Likelihood

Ratios’ , 2019. arXiv:1903.04057.

[13] D. Tran, R. Ranganath, and D. Blei: ‘Hierarchical implicit models and likelihood-free vari-
ational inference’. In I. Guyon, U. V. Luxburg, S. Bengio, et al. (eds.), ‘Advances in Neural
Information Processing Systems 30’, p. 5523–5533, 2017.

[14] L. Dinh, D. Krueger, and Y. Bengio: ‘NICE: Non-linear Independent Components Estimation’.

ArXiv e-prints , 2014. arXiv:1410.8516.

[15] D. Jimenez Rezende and S. Mohamed: ‘Variational Inference with Normalizing Flows’. ArXiv

e-prints , 2015. arXiv:1505.05770.

[16] L. Dinh, J. Sohl-Dickstein, and S. Bengio: ‘Density estimation using Real NVP’. ArXiv e-prints

, 2016. arXiv:1605.08803.

[17] G. Papamakarios, T. Pavlakou, and I. Murray: ‘Masked Autoregressive Flow for Density

Estimation’. ArXiv e-prints , 2017. arXiv:1705.07057.

[18] C.-W. Huang, D. Krueger, A. Lacoste, and A. Courville: ‘Neural Autoregressive Flows’. ArXiv

e-prints , 2018. arXiv:1804.00779.

[19] G. Papamakarios, D. C. Sterratt, and I. Murray: ‘Sequential Neural Likelihood: Fast Likelihood-

free Inference with Autoregressive Flows’. ArXiv e-prints , 2018. arXiv:1805.07226.

[20] T. Q. Chen, Y. Rubanova, J. Bettencourt, and D. K. Duvenaud: ‘Neural ordinary differential
equations’. CoRR abs/1806.07366, 2018. arXiv:1806.07366, URL http://arxiv.org/abs/
1806.07366.

[21] D. P. Kingma and P. Dhariwal: ‘Glow: Generative Flow with Invertible 1x1 Convolutions’.

arXiv e-prints arXiv:1807.03039, 2018. arXiv:1807.03039.

[22] W. Grathwohl, R. T. Q. Chen, J. Bettencourt, I. Sutskever, and D. Duvenaud: ‘FFJORD: Free-
form Continuous Dynamics for Scalable Reversible Generative Models’. ArXiv e-prints , 2018.
arXiv:1810.01367.

[23] M. Germain, K. Gregor, I. Murray, and H. Larochelle: ‘MADE: Masked Autoencoder for

Distribution Estimation’. ArXiv e-prints , 2015. arXiv:1502.03509.

[24] B. Uria, M.-A. Côté, K. Gregor, I. Murray, and H. Larochelle: ‘Neural Autoregressive Distribu-

tion Estimation’. ArXiv e-prints , 2016. arXiv:1605.02226.

[25] A. van den Oord, S. Dieleman, H. Zen, et al.: ‘WaveNet: A Generative Model for Raw Audio’.

ArXiv e-prints , 2016. arXiv:1609.03499.

[26] A. van den Oord, N. Kalchbrenner, O. Vinyals, L. Espeholt, A. Graves, and K. Kavuk-
cuoglu: ‘Conditional Image Generation with PixelCNN Decoders’. ArXiv e-prints , 2016.
arXiv:1606.05328.

[27] A. van den Oord, N. Kalchbrenner, and K. Kavukcuoglu: ‘Pixel Recurrent Neural Networks’.

ArXiv e-prints , 2016. arXiv:1601.06759.

[28] Y. Fan, D. J. Nott, and S. A. Sisson: ‘Approximate Bayesian Computation via Regression

Density Estimation’. ArXiv e-prints , 2012. arXiv:1212.1479.

[29] G. Papamakarios and I. Murray: ‘Fast ε-free inference of simulation models with bayesian
conditional density estimation’. In ‘Advances in Neural Information Processing Systems’, p.
1028–1036, 2016.

10

[30] B. Paige and F. Wood: ‘Inference Networks for Sequential Monte Carlo in Graphical Models’.

ArXiv e-prints , 2016. arXiv:1602.06701.

[31] R. Dutta, J. Corander, S. Kaski, and M. U. Gutmann: ‘Likelihood-free inference by ratio

estimation’. ArXiv e-prints , 2016. arXiv:1611.10242.

[32] G. Louppe and K. Cranmer: ‘Adversarial Variational Optimization of Non-Differentiable

Simulators’. ArXiv e-prints , 2017. arXiv:1707.07113.

[33] J.-M. Lueckmann, P. J. Goncalves, G. Bassetto, K. Öcal, M. Nonnenmacher, and J. H. Macke:
‘Flexible statistical inference for mechanistic models of neural dynamics’. arXiv e-prints
arXiv:1711.01861, 2017. arXiv:1711.01861.

[34] J.-M. Lueckmann, G. Bassetto, T. Karaletsos, and J. H. Macke: ‘Likelihood-free inference with

emulator networks’. arXiv e-prints arXiv:1805.09294, 2018. arXiv:1805.09294.

[35] F. Wood, J. W. van de Meent, and V. Mansinghka: ‘A new approach to probabilistic program-
ming inference’. In ‘Proceedings of the 17th International conference on Artiﬁcial Intelligence
and Statistics’, p. 1024-1032, 2014.

[36] T. A. Le, Baydin, A. G. Baydin, and F. Wood: ‘Inference compilation and universal probabilistic
programming’. In ‘Proceedings of the 20th International Conference on Artiﬁcial Intelligence
and Statistics (AISTATS)’, volume 54 of Proceedings of Machine Learning Research, p. 1338–
1348. PMLR, Fort Lauderdale, FL, USA, 2017.

[37] D. S. Greenberg, M. Nonnenmacher, and J. H. Macke: ‘Automatic Posterior Transformation
for Likelihood-Free Inference’. arXiv e-prints arXiv:1905.07488, 2019. arXiv:1905.07488.

[38] J. Brehmer, K. Cranmer, G. Louppe, and J. Pavez: ‘Constraining Effective Field Theories with

Machine Learning’. Phys. Rev. Lett. 121 (11), p. 111801, 2018. arXiv:1805.00013.

[39] J. Brehmer, K. Cranmer, G. Louppe, and J. Pavez: ‘A Guide to Constraining Effective Field

Theories with Machine Learning’. Phys. Rev. D98 (5), p. 052004, 2018. arXiv:1805.00020.

[40] R. J. Williams: ‘Simple statistical gradient-following algorithms for connectionist reinforcement

learning’. In ‘Reinforcement Learning’, Springer, p. 5–32, 1992.

[41] J. Brehmer, K. Cranmer, G. Louppe, and J. Pavez: ‘Code repository for the generalized Galton
board example in the paper “Mining gold from implicit models to improve likelihood-free
inference”’. http://github.com/johannbrehmer/simulator-mining-example, 2018.

[42] M. M. Graham, A. J. Storkey, et al.: ‘Asymptotically exact inference in differentiable generative

models’. Electronic Journal of Statistics 11 (2), p. 5105, 2017.

[43] Participants of the Likelihood-Free Inference Meeting at the Flatiron Institute 2019: ‘Code
repository for the automatic calculation of joint score and joint likelihood ratio with Pyro.’
https://github.com/LFITaskForce/benchmark, 2019.

[44] E. Bingham, J. P. Chen, M. Jankowiak, et al.: ‘Pyro: Deep Universal Probabilistic Program-

ming’. Journal of Machine Learning Research , 2018.

[45] P. Baldi, K. Cranmer, T. Faucett, P. Sadowski, and D. Whiteson: ‘Parameterized neural networks

for high-energy physics’. Eur. Phys. J. C76 (5), p. 235, 2016. arXiv:1601.07913.

[46] J. Alsing and B. Wandelt: ‘Generalized massive optimal data compression’. Mon. Not. Roy.

Astron. Soc. 476 (1), p. L60, 2018. arXiv:1712.00012.

[47] J. Alsing and B. Wandelt: ‘Nuisance hardened data compression for fast likelihood-free infer-

ence’ , 2019. arXiv:1903.01473.

[48] A. J. Lotka: ‘Analytical note on certain rhythmic relations in organic systems’. Proceedings of

the National Academy of Sciences 6 (7), p. 410, 1920.

[49] A. J. Lotka: ‘Undamped oscillations derived from the law of mass action.’ Journal of the

american chemical society 42 (8), p. 1595, 1920.

11

[50] D. T. Gillespie: ‘A general method for numerically simulating the stochastic time evolution of

coupled chemical reactions’. Journal of Computational Physics 22 (4), p. 403 , 1976.

[51] G. Papamakarios, T. Pavlakou, and I. Murray: ‘Code repository for paper “Masked Autoregress-

ive Flow for Density Estimation”’. http://github.com/gpapamak/maf, 2017.

[52] J. Brehmer, K. Cranmer, G. Louppe, and J. Pavez: ‘Code repository for the Lotka-Volterra
example in the paper “Mining gold from implicit models to improve likelihood-free inference”’.
http://github.com/johannbrehmer/goldmine, 2018.

[53] J. Alwall, R. Frederix, S. Frixione, et al.: ‘The automated computation of tree-level and next-
to-leading order differential cross sections, and their matching to parton shower simulations’.
JHEP 07, p. 079, 2014. arXiv:1405.0301.

[54] K. Cranmer and T. Plehn: ‘Maximum signiﬁcance at the LHC and Higgs decays to muons’. Eur.

Phys. J. C51, p. 415, 2007. arXiv:hep-ph/0605268.

[55] T. Plehn, P. Schichtel, and D. Wiegand: ‘Where boosted signiﬁcances come from’. Phys. Rev.

D89 (5), p. 054002, 2014. arXiv:1311.2591.

[56] F. Kling, T. Plehn, and P. Schichtel: ‘Maximizing the signiﬁcance in Higgs boson pair analyses’.

Phys. Rev. D95 (3), p. 035026, 2017. arXiv:1607.07441.

[57] B. Eli, J. P. Chen, M. Jankowiak, et al.: ‘Pyro: Deep probabilistic programming’. https:

//github.com/uber/pyro, 2017.

[58] D. Tran, M. D. Hoffman, R. A. Saurous, E. Brevdo, K. Murphy, and D. M. Blei: ‘Deep

probabilistic programming’. arXiv preprint arXiv:1701.03757 , 2017.

[59] N. Siddharth, B. Paige, J.-W. van de Meent, et al.: ‘Learning disentangled representations with
semi-supervised deep generative models’. In I. Guyon, U. V. Luxburg, S. Bengio, et al. (eds.),
‘Advances in Neural Information Processing Systems 30’, p. 5927–5937. Curran Associates,
Inc., 2017.

[60] A. Gelman, D. Lee, and J. Guo: ‘Stan: A Probabilistic Programming Language for Bayesian
Inference and Optimization’. Journal of Educational and Behavioral Statistics 40 (5), p. 530,
2015.

12

9
1
0
2
 
g
u
A
 
5
 
 
]
L
M

.
t
a
t
s
[
 
 
4
v
4
4
2
2
1
.
5
0
8
1
:
v
i
X
r
a

Mining gold from implicit models to improve
likelihood-free inference

Johann Brehmer,1 Gilles Louppe,2 Juan Pavez,3 and Kyle Cranmer1
1 New York University, 2 University of Liège, 3 Federico Santa María Technical University
johann.brehmer@nyu.edu, g.louppe@uliege.be,
juan.pavezs@alumnos.usm.cl, kyle.cranmer@nyu.edu

Abstract

Simulators often provide the best description of real-world phenomena. However,
the density they implicitly deﬁne is often intractable, leading to challenging inverse
problems for inference. Recently, a number of techniques have been introduced in
which a surrogate for the intractable density is learned, including normalizing ﬂows
and density ratio estimators. We show that additional information that characterizes
the latent process can often be extracted from simulators and used to augment the
training data for these surrogate models. We introduce several new loss functions
that leverage this augmented data, and demonstrate that these new techniques can
improve sample efﬁciency and quality of inference.

1

Introduction

In many areas of science, complicated real-world phenomena are best described through computer
simulations. Typically, the simulators implement a stochastic generative process in the “forward”
mode based on a well-motivated mechanistic model with parameters θ. While the simulators can
generate samples of observations x ∼ p(x|θ), they typically do not admit a tractable likelihood (or
density) p(x|θ). Probabilistic models deﬁned only via the samples they produce are often called
implicit models. Implicit models lead to intractable inverse problems, which is a barrier for statistical
inference of the parameters θ given observed data. These problems arise in ﬁelds as diverse as
particle physics, epidemiology, and population genetics, which has motivated the development of
likelihood-free inference algorithms such as Approximate Bayesian Computation (ABC) [1–4] and
neural density estimation (NDE) techniques [5–34]. While many of these techniques can be exact
in the limit of inﬁnite training samples, real-world simulators are computationally expensive, and
sample efﬁciency is immensely important.

We present a suite of new techniques that can dramatically improve the sample efﬁciency for training
neural network surrogates that estimate the likelihood p(x|θ) or likelihood ratio r(x|θ0, θ1) =
p(x|θ0)/p(x|θ1). This provides the key quantity needed for both frequentist and Bayesian inference
procedures. Our approach involves extracting additional information that characterizes the latent
process from the simulator, as we explain in Sec. 3. In Sec. 4 we introduce the loss functions that
utilize this augmented data. In Sec. 5 we demonstrate through a range of experiments that these new
techniques provide a signiﬁcant increase in sample efﬁciency compared to techniques that do not
leverage the augmented data, which ultimately increase the quality of inference.

Techniques for likelihood-free inference can be divided into two broad categories. In the ﬁrst category,
the inference is performed by directly comparing the observed data to the output of the simulator.
This includes Approximate Bayesian Computation (ABC) [1–4] and probabilistic programming

2 Related work

Preprint. Under review.

systems [35, 36]. Here we focus on a second category, in which the simulator is used to generate
training data for a tractable surrogate model that is used during inference. There are rich connections
between simulator-based inference and learning in implicit generative models such as GANs, with a
considerable amount of cross-pollination between these areas [9].

The likelihood ratio trick (LRT). A surrogate model for the likelihood ratio ˆr(x|θ0, θ1) can
be deﬁned by training a probabilistic classiﬁer to discriminate between two equal-sized samples
{xi} ∼ p(x|θ0) and {xi} ∼ p(x|θ1). The binary cross-entropy loss

LXE = −E[1(θ = θ1) log ˆs(x|θ0, θ1) + 1(θ = θ0) log(1 − ˆs(x|θ0, θ1))]

(1)

is minimized by the optimal decision function s(x|θ0, θ1) = p(x|θ1)/(p(x|θ0) + p(x|θ1)). Inverting
this relation, the likelihood ratio can be estimated from the classiﬁer decision function ˆs(x) as
ˆr(x|θ0, θ1) = (1 − ˆs(x|θ0, θ1))/ˆs(x|θ0, θ1). This “likelihood ratio trick” is widely appreciated [5–
13]. In practice, not all probabilistic classiﬁers trained to separate samples from θ0 and θ1 learn the
optimal decision function. As long as the classiﬁer decision function is a monotonic function of the
likelihood ratio, this relation can be restored through a calibration procedure, substantially increasing
the applicability of the likelihood ratio trick [6–8]. We use the term CARL (Calibrated approximate
ratios of likelihoods) to describe likelihood ratio estimators based on calibrated classiﬁers.

Neural density estimation (NDE). More recently, several methods for conditional density estima-
tion have been proposed, often based on neural networks [13–34]. They can be used to train a surrog-
ate for the likelihood p(x|θ) [17, 19, 34] or, in a Bayesian setting, the posterior p(θ|x) [29, 33, 37].
One particularly interesting class of models are normalizing ﬂows [14–22], which model the density
as a sequence of invertible transformations applied to a simple base density. The target density
is then given by the Jacobian determinant of the transformation. Closely related, autoregressive
models [23–27] factorize a target density as a sequence of simpler conditional densities.

Novel contributions. The most important novel contribution that differentiates our work from the
existing methods is the observation that additional information can be extracted from the simulator,
and the development of loss functions that allow us to use this “augmented” data to more efﬁciently
learn surrogates for the likelihood function. In addition, we show how the augmented data can
be used to deﬁne locally optimal summary statistics, which can then be used for inference with
density estimation techniques or ABC. We playfully introduce the analogy of mining gold as this
augmented data requires work to extract and is very valuable. In experiments we demonstrate that
these approaches can dramatically improve sample efﬁciency and quality of likelihood-free inference.

Concurrently, the application of these methods to a speciﬁc class of problems in particle physics
has been discussed in Refs. [38, 39]. The present manuscript is meant to serve as the primary
reference for these new techniques and is addressed to the broader physical science and machine
learning communities. Most importantly, it generalizes the speciﬁc particle physics case to almost
any scientiﬁc simulator, requiring signiﬁcantly weaker assumption than those made in the physics
context. We also introduce an entirely new algorithm called SCANDAL, for which we provide the
ﬁrst experimental results.

3 Extracting more information from the simulator

We consider a scientiﬁc simulator that implements a stochastic generative process that proceeds
through a series of latent states zi ∈ Zi and ﬁnally to an output x ∈ Rdx . The latent space structure
Z can involve discrete and continuous components and is derived from the control ﬂow of the
(differentiable or non-differentiable) simulation code. Based on the mechanistic model implemented
by the simulator, each latent state is sampled from a conditional probability density zi ∼ pi(zi|θ, z<i)
and the ﬁnal output is sampled from x ∼ px(x|θ, z). The likelihood is then given by

(cid:90)

(cid:90)

p(x|θ) =

dz p(x, z|θ) =

dz px(x|θ, z)

pi(zi|θ, z<i) .

(2)

(cid:89)

i

Often the likelihood is intractable exactly because the latent space z is enormous and it is unfeasible
to explicitly calculate this integral. In real-world scientiﬁc simulators, the trajectory for a single
observation can involve many millions of latent variables.

2

In this paper we consider the problem of estimating the likelihood p(x|θ) or the likelihood ratio
r(x|θ0, θ1), which for the practical purpose of inferring parameter values θ can be used almost
interchangably, based on the data available from N runs of the simulator.

Typically, the setting of likelihood-free inference assumes that the only available output from the
simulator are samples of observations x ∼ p(x|θ). But in real-life simulators, more information can
usually be extracted. We typically have access to the latent variables z, and the distributions of each
latent variable pi(zi|θ, z<i) and px(x|θ, z) are tractable.

The key observation that is the starting point of our new inference methods is the following: While
p(x|θ) is intractable, for each simulated sample we can calculate the joint score

t(x, z|θ0) ≡ ∇θ log p(x, z|θ)

=

+ ∇θ log px(x|θ, z)

(3)

(cid:12)
(cid:12)
(cid:12)
(cid:12)θ0

(cid:12)
(cid:12)
∇θ log pi(zi|θ, z<i)
(cid:12)
(cid:12)θ0

(cid:88)

i

(cid:12)
(cid:12)
(cid:12)
(cid:12)θ0

by accumulating the factors ∇θ log p(zi|θ, z:i) as the simulation runs forward through its control
ﬂow conditioned on the random trajectory z. It can be insightful to think of the mechanistic model
in the simulator as deﬁning a policy πθ and t(x, z|θ0) as analogous to the policy gradient used in
REINFORCE [40]. However, instead of trying to optimize θ via a stochastic gradient estimate of some
reward function, we will simply augment the data generated by the simulator with the joint score.

Similarly, we can extract the joint likelihood ratio

r(x, z|θ0, θ1) ≡

p(x, z|θ0)
p(x, z|θ1)

=

px(x|θ0, z)
px(x|θ1, z)

(cid:89)

i

pi(zi|θ0, z<i)
pi(zi|θ1, z<i)

.

(4)

The joint score and joint likelihood ratio quantify how much more or less likely a particular simulated
trajectory through the simulator would be if one changed θ.

As a motivating example, consider the simulation for a
generalization of the Galton board, in which a set of balls
is dropped through a lattice of nails ending in one of sev-
eral bins denoted by x. The Galton board is commonly
used to demonstrate the central limit theorem, and if the
nails are uniformly placed such that the probability of
bouncing to the left is p, the sum over the latent space is
tractable analytically and the resulting distribution of x
is a binomial distribution. However, if the nails are not
uniformly placed, and the probability of bouncing to the
left is an arbitrary function of the nail position and some
parameter θ, the resulting distribution requires an explicit
sum over the latent paths z that might lead to a particular
x. Such a distribution would become intractable as the
size of the lattice increases. Figure 1 shows an example
of two latent trajectories that lead to the same x. In this
toy example, the probability p(zh, zv, θ) of going left is
given by (1 − f (zv))/2 + f (zv)σ(5θ(zh − 1/2)), where
f (zv) = sin(πzv), σ is the sigmoid function, and zh and
zv are the horizontal and vertical nail positions normal-
ized to [0, 1]. This leads to a non-trivial p(x|θ), which can
even be bimodal. Code for simulation and inference in
this problem is available at Ref. [41].

Figure 1: A toy simulation generalizing the
Galton board where the transitions are biased
left (blue) or right (red) depending on the nail
position and the value of θ. Two example lat-
ent trajectories z are shown (blue and green),
leading to the same observed value of x. Be-
low, the distribution for θ0 = −0.8 and
θ1 = −0.6. An example empirical distri-
bution from 100 runs for θ0 shows that the
sample variance is much larger than the dif-
ferences from θ0 vs θ1.

Figure 1 shows that a large number of samples from the
simulator are needed to reveal the differences in the distri-
bution of x for small changes in θ – the number of samples needed grows like (p/∆p)2. Moreover,
this toy simulation is representative of many real-world simulators in that it is composed of non-
differentiable control-ﬂow elements. This poses a difﬁculty, making methods based on ∇zx [42]
and ∇θx inapplicable, which previously motivated techniques such as Adversarial Variational
Optimization [32]. But the joint score in Eq. (3) can easily be computed by accumulating the
factors ∇θ log p(zh, zv|θ0), and we can calculate the joint likelihood ratio by accumulating factors
p(zh, zv|θ0)/p(zh, zv|θ1). In analogy to the Galton board toy example, even complicated real-world
simulators often allow us to accumulate these factors as they run, and to calculate the joint score and

3

joint likelihood ratio conditional on a particular stochastic execution trace z. We will demonstrate
this with two more examples in Sec. 5.

For simulators written in an automatic differentiation framework, the calculation of the joint score
and joint likelihood ratio can be entirely automatic and does not require any changes to the simulator
code and output. As a proof of principle, at Ref. [43] we provide a framework that automates
these calculations for any simulator in which all stochastic steps are implemented with the PYRO
library [44].

4 Learning from augmented data

4.1 Key idea

How can the “augmented data” consisting of simulated observations xi, the joint likelihood ratio
r(xi, zi|θ0, θ1), and the joint score t(xi, zi|θ0) be used to estimate the likelihood p(x|θ) or likelihood
ratio r(x|θ0, θ1)? The relation between r(x, z|θ0, θ1) and r(x|θ0, θ1) is not trivial — the integral of
the ratio is not the ratio of the integrals! Similarly, how can the joint score be used to estimate the
intractable score function

t(x|θ0) ≡ ∇θ log p(x|θ)

?

(cid:12)
(cid:12)
(cid:12)
(cid:12)θ0

The integral of the log is not the log of the integral!

Consider the squared error of a function ˆg(x) that only depends on the observable x, but is trying to
approximate a function g(x, z) that also depends on the latent variable z,

LMSE = Ep(x,z|θ)

(cid:104)

(g(x, z) − ˆg(x))2 (cid:105)

.

The minimum-mean-squared-error prediction of ˆg(x) is given by the conditional expectation g∗(x) =
arg minˆg LMSE = Ep(z|x,θ)[g(x, z)].
Identifying g(x, z) with the joint likelihood ratio r(x, z|θ0, θ1) and θ = θ1, we deﬁne
(cid:104)

Lr = Ep(x,z|θ1)

(r(x, z|θ0, θ1) − ˆr(x))2 (cid:105)

,

and ﬁnd that this functional is minimized by r∗(x) = arg minˆr Lr = Ep(z|x,θ1) [ r(x, z|θ0, θ1) ] =
r(x|θ0, θ1). Similarly, by identifying g(x, z) with the joint score t(x, z|θ0) and setting θ = θ0, we
deﬁne

Lt = Ep(x,z|θ0)

(cid:104) (cid:0)t(x, z|θ0) − ˆt(x|θ0)(cid:1)2 (cid:105)

,

which is minimized by t∗(x) = Ep(z|x,θ0) [ t(x, z|θ0) ] = t(x|θ0).
These loss functionals are immensely useful because they allow us to transform t(x, z|θ0) into t(x|θ0)
and r(x, z|θ0, θ1) into r(x|θ0, θ1): we are able to regress on these two intractable quantities! This is
what makes the joint score and joint likelihood ratio the gold worth mining.

(5)

(6)

(7)

(8)

4.2 Learning the likelihood ratio

Based on this observation we introduce a family of new likelihood-free inference techniques. They
fall into two categories. We ﬁrst discuss a class of algorithms that uses the augmented data to learn
a surrogate model for any likelihood p(x|θ) or likelihood ratio r(x|θ0, θ1). In Section 4.3 we will
deﬁne a second class of methods that is based on a local expansion of the model around some
reference parameter point.

The simulators we consider in this work do not only implicitly deﬁne a single density p(x), but a
family of densities p(x|θ). The parameters θ may potentially belong to a high-dimensional parameter
space. For inference models based on surrogate models, there are two broad strategies to model
this dependence. The ﬁrst is to estimate p(x|θ) or the likelihood ratio r(x|θ0, θ1) for speciﬁc values
of θ or pairs (θ0, θ1). This may be done via a pre-deﬁned set of θ values or on-demand using an
active-learning iteration. We follow a second approach, in which we train parameterized estimators
for the full model ˆp(x|θ) or ˆr(x|θ0, θ1) as a function of both the observables x and the parameters
θ [6, 45]. The training data then consists of a number of samples, each generated with different

4

values of θ0 and θ1, and the parameter values are used as additional inputs to the surrogate model.
When modeling the likelihood ratio, the reference hypothesis θ1 in the denominator of the likelihood
ratio can be kept at a ﬁxed reference value (or a marginal model with some prior π(θ1)), and only
the θ0 dependence is modeled by the network. This approach encourages the estimator to learn the
typically smooth dependence of the likelihood ratio on the parameters of interest from the training
data and borrow power from neighboring points.

ROLR (Regression On Likelihood Ratio): First, a number of parameter points (θ0, θ1) is drawn
from θi ∼ πi(θi). For each pair (θ0, θ1), we run the simulator both for θ0 and for θ1, labelling the
samples with y = 0 and y = 1, respectively. In addition to samples x ∼ p(x|θy) we also extract the
joint likelihood ratio r(x, z|θ0, θ1).

An expressive regressor ˆr(x|θ0, θ1) (e. g. a neural network) is trained by minimizing the squared
error loss

LROLR[ˆr] =

yi |r(xi, zi) − ˆr(xi)|2 + (1 − yi)

1
N

(cid:32)

(cid:88)

i

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
r(xi, zi)

−

2(cid:33)
.

1
ˆr(xi)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(9)

Here and in the following the θ dependence is implicit to reduce the notational clutter.

Both terms in this loss function are estimators of Eq. (7) (in the second term we switch θ0 ↔ θ1
to reduce the variance by mapping out other regions of x space). As we showed in the previous
section, this loss function is, at least in the limit of inﬁnite data, minimized by the true likelihood
ratio r(x|θ0, θ1). A regressor trained in this way thus provides an estimator for the likelihood ratio
and can be used for frequentist or Bayesian inference methods.

RASCAL (Ratio And SCore Approximate Likelihood ratio):
If such a likelihood ratio regressor
is differentiable (as is the case for neural networks) with respect to θ, we can calculate the predicted
score ˆt(x|θ0) = ∇θ0 log ˆr(x|θ0, θ1). For a perfect likelihood ratio estimator, ˆt(x|θ0) minimizes the
squared error with respect to the joint score, see Eq. (8). Turning this argument around, we can
improve the training of a likelihood ratio estimator by minimizing the combined ratio and score loss
with a hyper-parameter α

LRASCAL[ˆr] = LROLR[ˆr] + α

(1 − yi) |t(xi, zi) − ∇θ0 log ˆr(xi)|2 .

(10)

1
N

(cid:88)

i

CASCAL (CARL And SCore Approximate Likelihood ratio): The same trick can be used to
improve the likelihood ratio trick and the CARL inference method [6, 8]. Following the discussion
around Eq. (1), a calibrated classiﬁer trained to discriminate samples {xi} ∼ p(x|θ0) and {xi} ∼
p(x|θ1) provides a likelihood ratio estimator. For a differentiable parameterized classiﬁer, we can
calculate the surrogate score ˆt(x|θ0) = ∇θ0 log[(1 − ˆs(x|θ0, θ1))/ˆs(x|θ0, θ1)]. This allows us to
train an improved classiﬁer (and thus a likelihood ratio estimator) by minimizing the combined loss

LCASCAL[ˆs] = LXE[ˆs] + α

(1 − yi)

t(xi, zi) − ∇θ0 log

1
N

(cid:88)

i

(cid:12)
(cid:12)
(cid:12)
(cid:12)

2

(cid:20) 1 − ˆs(x)
ˆs(x)

(cid:21)(cid:12)
(cid:12)
(cid:12)
(cid:12)

.

(11)

SCANDAL (SCore-Augmented Neural Density Approximates Likelihood): Finally, we can use
the same strategy to improve conditional neural density estimators such as density networks or
normalizing ﬂows. If a parameterized neural density estimator ˆp(x|θ) is differentiable with respect to
θ, we can calculate the surrogate score ˆt(x) = ∇θ log ˆp(x|θ) and train an improved density estimator
by minimizing

LSCANDAL[ˆp] = LMLE + α

|t(xi, zi) − ∇θ log ˆp(x)|2 .

(12)

Unlike the methods discussed before, this provides an estimator of the likelihood itself rather than its
ratio. Depending on the architecture, the surrogate also provides a generative model.

1
N

(cid:88)

i

5

4.3 Locally sufﬁcient statistics for implicit models

A second class of new likelihood-free inference methods is based on an expansion of the implicit
model around a reference parameter point θref. Up to linear order in θ − θref, we ﬁnd

plocal(x|θ) =

p(t(x|θref) | θref) exp[t(x|θref) · (θ − θref)]

(13)

1
Z(θ)

with some normalization factor Z(θ). This local approximation is in the exponential family and the
score vector t(x|θref), deﬁned in Eq. (5), are its sufﬁcient statistics.
For inference in a sufﬁciently small neighborhood around a reference point θref, a precise estimator
of the score ˆt(x|θref) therefore deﬁnes a vector of ideal summary statistics that contain all the
information in an observation x on the parameters θ [see also 3, 46, 47]. The joint score together
with a minimization of the loss in Eq. (8) allows us to extract sufﬁcient statistics from an intractable,
non-differentiable simulator, at least in the neighborhood of θref. Moreover, this local model can be
estimated by running the simulator at a single value θref — it does not require scanning the θ space,
and thus avoids the curse of dimensionality. Based on this observation, we introduce two further
inference strategies:

SALLY (Score Approximates Likelihood LocallY): By minimizing the squared error with respect
to the joint score, see Eq. (8), we train a score estimator ˆt(x|θref). In a next step, we estimate the
density ˆp(ˆt(x|θref)|θ) through standard multivariate density estimation techniques. This calibration
procedure implicitly includes the effect of the normalizing constant Z(θ).

SALLINO (Score Approximates Likelihood Locally IN One dimension): The SALLY inference
method requires density estimation in the estimated score space, with typically dim ˆt ≡ dim θ (cid:28)
dim x. But in cases with large number of parameters, it is beneﬁcial to reduce the dimensionality even
further. In the local model of Eq. (13), the likelihood ratio r(x|θ0, θ1) only depends on h(x|θ0, θ1) ≡
t(x|θref) · (θ0 − θ1) up to an x-independent constant related to Z(θ). Any neural score estimator lets
us also estimate this scalar function, which is a sufﬁcient statistic for the 1-dimensional parameter
space connecting θ0 and θ1. We can thus estimate the likelihood ratio through univariate, rather than
multivariate, density estimation on ˆh.

The SALLY and SALLINO techniques are designed to work very well close to the reference point.
The local model approximation may deteriorate further away, leading to a reduced sensitivity and
weaker bounds. These approaches are simple and robust, and in particular the SALLINO algorithm
scales exceptionally well to high-dimensional parameter spaces.

For all these inference strategies, the augmented data is particularly powerful for enhancing the
power of simulation-based inference for small changes in the parameter θ. When restricted to
samples x ∼ p(x|θ), the variance from the simulator is a challenge. The ﬂuctuations in the empirical
density scale with the square root of the number of samples, thus large numbers of samples are
required before small changes in the implicit density can faithfully be distinguished. In contrast, each
sample of the joint ratio and joint score provides an exact piece of information even for arbitrarily
small changes in θ. On the other hand, the augmented data is less powerful for deciding between
model parameter points that are far apart. In this situation the joint probability distributions p(x, z|θ)
often do not overlap signiﬁcantly, and the joint likelihood ratio can have a large variance around the
intractable likelihood ratio r(x|θ0, θ1). In addition, over large distances in parameter space the local
model is not valid and the score does not characterize the likelihood ratios anymore, limiting the
usefulness of the joint score.

5 Experiments

Generalized Galton board. We return to the motivating example in Sec. 3 and Fig. 1 and try to
estimate likelihood ratios for the generalized Galton board. We use the likelihood ratio trick and
a neural density estimator as baselines and compare them to the new ROLR, RASCAL, CASCAL,
and SCANDAL methods. As the simulator deﬁnes a distribution over a discrete x, for the NDE and
SCANDAL methods we use a neural network with a softmax output layer over the bins to model
ˆp(x|θ). All networks are explicitly parameterized in terms of θ, the parameter of the simulator that

6

Figure 2: Left: Galton board example. MSE on log r vs. training sample size. We show the mean and its error
based on 15 runs. Middle: Lotka-Volterra example. MSE on log p (top) and log r (bottom) vs. training sample
size. We show the median and the standard deviation of 10 runs. Right: Particle physics example. MSE on log r
vs. training sample size.

deﬁnes the position of the nails (i. e. they take θ as an input). We use a simple network architecture
with a single hidden layer, 10 hidden units, and tanh activations. The left panel of Fig. 2 shows the
mean squared error between log ˆr(x|θ0, θ1) and the true log r(x|θ0, θ1) (estimated from histograms
of 2 · 104 simulations from θ0 = −0.8 and θ1 = −0.6), summing over x ∈ [5, 15], versus the
training sample size (which refers to the total number of x samples, distributed over 10 values of
θ ∈ [−1, −0.4]). We ﬁnd that both SCANDAL and RASCAL are dramatically more sample efﬁcient
than pure neural density estimation and the likelihood ratio trick, which do not leverage the joint
score. ROLR improves upon pure neural density estimation and achieves the same asymptotic error
as SCANDAL, though more slowly.

Lotka-Volterra model. As a second example, we consider the Lotka-Volterra system [48, 49], a
common example in the likelihood-free inference literature. This stochastic Markov jump process
models the dynamics of a species of predators interacting with a species of prey. Four parameters θ
set the rate of predators and prey being born, predators dying, and predators eating prey.

We simulate the Lotka-Volterra model with Gillespie’s algorithm [50]. From the time evolution of
the predator and prey populations we calculate summary statistics x ∈ R9. Our model deﬁnitions,
summary statistics, and initial conditions exactly follow Appendix F of Ref. [29]. In addition to the
observations, we extract the joint score as well as the joint likelihood ratio with respect to a reference
hypothesis log θ1 = (−4.61, −0.69, 0.00, −4.61)T from the simulator. On this augmented data we
train different likelihood and likelihood ratio estimators. As baselines we use CARL [6, 8] and a
conditional masked autoregressive ﬂow (MAF) [17, 51]. We compare them to the new techniques
introduced in section 4.2, including a SCANDAL likelihood estimator based on a MAF. For MAF and
SCANDAL we stack four masked autoregressive distribution estimators (MADEs) [23] on a mixture
of MADEs with 10 components [17]. For all other methods, we use three hidden layers. In all cases,
the hidden layers have 100 units and tanh activations. Code for simulation and inference is available
at Ref. [52].

For inference on a wide prior in the parameter space, the different probability densities often do not
overlap. As discussed above, the augmented data is then of limited use. Instead, we focus on the
regime where we try to discriminate between close parameter points with similar predictions for
the observables. We generate training data and evaluate the models in the range log(θ1)i − 0.01 ≤
θi ≤ log(θ1)i + 0.01 with a uniform prior in log space. In the middle panel of Fig. 2 we evaluate
the different methods by calculating the mean squared error of estimators trained on small training
samples. Since the true likelihood is intractable, we calculate the error with respect to the median
predictions of 10 estimators1 trained on the full data set of 200 000 samples.

1We pick the algorithms we use for these “ground truth” predictions based on the variance between independ-
ent runs and the consistency of improvements with increasing training sample size. For likelihood estimation,
we use the MAF as baseline, with qualitatively similar results when using SCANDAL. For likelihood ratio
estimation, we use the SCANDAL estimator as baseline, and ﬁnd qualitatively similar results for CASCAL.

7

Our results indicate a trade-off between the performance in likelihood (density) estimation and
likelihood ratio estimation. For density estimation, the MAF performs well. The variance of the
score term in the SCANDAL loss degrades the performance, especially for larger values of the
hyperparameter α. However, for statistical inference the more relevant quantity is the likelihood
ratio. Here the new techniques that use the joint score, in particular SCANDAL, are signiﬁcantly more
sample efﬁcient.

Particle physics. Finally we consider a real-world problem from particle physics. A simulator
describes the production of a Higgs boson at the Large Hadron Collider experiments, followed
by the decay into four electrons or muons, subsequent radiation patterns, the interaction with the
detector elements, and the reconstruction procedure. Each recorded collision produces a single
high-dimensional observable x ∈ R42, and the dataset consists of multiple iid observations of x.
The goal is to infer the likelihood of two parameters θ ∈ [−1, 1]2 that characterize the effect of
high-energy physics models on these interactions. We consider a synthetic observed dataset with 36
iid simulated observations of x drawn from θ = (0, 0).

The new inference techniques can accommodate state-of-the-art simulators, but in that setting we
cannot compare them to the true likelihood function. We therefore present a simpliﬁed setup and
approximate the detector response such that the true likelihood function is tractable, providing us
with a ground truth to compare the inference techniques to. As simulator we use a combination
of MADGRAPH 5 [53] and MADMAX [54–56]. The setup and the results of this experiment are
described at length in Ref. [39], which is attached as supplementary material.

In the right panel of Fig. 2 we show the expected mean squared error of the approximate
log ˆr(x|θ0, θ1) for the different techniques as a function of the training sample size. We take the
expectation over random values of θ0, drawn from a Gaussian prior with mean (0, 0) and covariance
matrix diag(0.22, 0.22). We compare the new techniques to the standard practice in particle physics,
in which the likelihood is estimated through histograms of two hand-picked summary statistics.

All new inference techniques outperform the traditional histogram method, provided that the training
samples are sufﬁciently large. Using augmented data substantially decreases the amount of training
data required for a good performance: the RASCAL method, which uses both the joint ratio and joint
score information from the simulator, reduces the amount of training data by two orders of magnitude
compared to the CARL technique, which uses only the samples x ∼ p(x|θ). The particularly simple
local techniques SALLY and SALLINO need even less data for a good performance. However, their
performance eventually plateaus and does not asymptote to zero error. This is because the local
model approximation breaks down further away from the reference point θref = (0, 0)T , and the
score is no longer the sufﬁcient statistics. In the supplementary material we show further results and
demonstrate how the improved likelihood ratio estimation leads to better inference results.

6 Conclusions

In this work we have presented a family of new inference techniques for the setting in which the
likelihood is only implicitly deﬁned through a stochastic generative simulator. The new methods
estimate likelihoods or ratios of likelihoods with data available from the simulator. Most established
inference methods, such as ABC and techniques based on neural density estimation, only use samples
of observables from the simulator. We pointed out that in many cases the joint likelihood ratio and
the joint score — quantities conditioned on the latent variables that characterize the trajectory through
the data generation process — can be extracted from the simulator.

While these additional quantities often require work to be extracted, they also prove to be very
valuable as they can dramatically improve sample efﬁciency and quality of inference. Indeed, we
have shown that this additional information lets us deﬁne loss functionals that are minimized by the
likelihood or likelihood ratio, which can in turn be used to efﬁciently guide the training of neural
networks to precisely estimate the likelihood function. A second class of new techniques is motivated
by a local approximation of the likelihood function around a reference parameter value, where the
score vector is the sufﬁcient statistic. In the case where the simulator provides the joint score, we can
use it to train a precise estimator of the score and use it as locally optimal summary statistics.

8

We have demonstrated in three experiments that the new inference techniques let us precisely estimate
likelihood ratios. In turn, this enables parameter measurements with a higher precision and less
training data than with established methods.

This approach is complementary to many recent advances in likelihood-free inference: the augmented
data can be used to improve training for any neural density estimator or likelihood ratio estimator,
as we have demonstrated for Masked Autoregressive Flows and CARL. It can also be used to deﬁne
locally optimal summary statistics that can be used for instance in ABC techniques.

Finally, these results motivate the development of tools that provide a nonstandard interpretation
of the simulator code and automatically generate the joint score and joint ratio, building on recent
developments in probabilistic programming and automatic differentiation [35, 36, 57–60]. We have
provided a ﬁrst proof-of-principle implementation of such a tool based on PYRO [43].

Acknowledgments

We would like to thank Cyril Becot and Lukas Heinrich, who contributed to this project at an
early stage. We are grateful to Jan-Matthis Lückmann for helping us automate the calculation of
the joint likelihood ratio and joint score in PYRO and to all participants of the Likelihood-free
inference workshop at the Flatiron Institute for great discussions. We would like to thank Felix
Kling, Tilman Plehn, and Peter Schichtel for providing the MADMAX code and helping us use it, and
to George Papamakarios for discussing the Masked Autoregressive Flow code with us. KC wants
to thank CP3 at UC Louvain for their hospitality. Finally, we would like to thank Atılım Güne¸s
Baydin, Lydia Brenner, Joan Bruna, Kyunghyun Cho, Michael Gill, Siavash Golkar, Ian Goodfellow,
Daniela Huppenkothen, Michael Kagan, Hugo Larochelle, Yann LeCun, Fabio Maltoni, Jean-Michel
Marin, Iain Murray, George Papamakarios, Duccio Pappadopulo, Dennis Prangle, Rajesh Ranganath,
Dustin Tran, Rost Verkerke, Wouter Verkerke, Max Welling, and Richard Wilkinson for interesting
discussions.

JB, KC, and GL are grateful for the support of the Moore-Sloan data science environment at NYU.
KC and GL were supported through the NSF grants ACI-1450310 and PHY-1505463. JP was partially
supported by the Scientiﬁc and Technological Center of Valparaíso (CCTVal) under Fondecyt grant
BASAL FB0821. This work was supported in part through the NYU IT High Performance Computing
resources, services, and staff expertise.

References

[1] D. B. Rubin:

‘Bayesianly justiﬁable and relevant frequency calculations for the applied
statistician’. Ann. Statist. 12 (4), p. 1151, 1984. URL https://doi.org/10.1214/aos/
1176346785.

[2] M. A. Beaumont, W. Zhang, and D. J. Balding: ‘Approximate bayesian computation in popula-

tion genetics’. Genetics 162 (4), p. 2025, 2002.

[3] J. Alsing, B. Wandelt, and S. Feeney: ‘Massive optimal data compression and density estimation

for scalable, likelihood-free inference in cosmology’ , 2018. arXiv:1801.01497.

[4] T. Charnock, G. Lavaux, and B. D. Wandelt: ‘Automatic physical inference with information

maximizing neural networks’. Phys. Rev. D97 (8), p. 083004, 2018. arXiv:1802.03537.

[5] I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, et al.: ‘Generative Adversarial Networks’. ArXiv

e-prints , 2014. arXiv:1406.2661.

[6] K. Cranmer, J. Pavez, and G. Louppe: ‘Approximating Likelihood Ratios with Calibrated

Discriminative Classiﬁers’ , 2015. arXiv:1506.02169.

[7] K. Cranmer and G. Louppe: ‘Unifying generative models and exact likelihood-free inference

with conditional bijections’. J. Brief Ideas , 2016.

[8] G. Louppe, K. Cranmer, and J. Pavez: ‘carl: a likelihood-free inference toolbox’. J. Open

Source Softw. , 2016.

[9] S. Mohamed and B. Lakshminarayanan: ‘Learning in Implicit Generative Models’. ArXiv

e-prints , 2016. arXiv:1610.03483.

9

[10] M. U. Gutmann, R. Dutta, S. Kaski, and J. Corander: ‘Likelihood-free inference via classiﬁca-

tion’. Statistics and Computing p. 1–15, 2017.

[11] T. Dinev and M. U. Gutmann: ‘Dynamic Likelihood-free Inference via Ratio Estimation

(DIRE)’. arXiv e-prints arXiv:1810.09899, 2018. arXiv:1810.09899.

[12] J. Hermans, V. Begy, and G. Louppe: ‘Likelihood-free MCMC with Approximate Likelihood

Ratios’ , 2019. arXiv:1903.04057.

[13] D. Tran, R. Ranganath, and D. Blei: ‘Hierarchical implicit models and likelihood-free vari-
ational inference’. In I. Guyon, U. V. Luxburg, S. Bengio, et al. (eds.), ‘Advances in Neural
Information Processing Systems 30’, p. 5523–5533, 2017.

[14] L. Dinh, D. Krueger, and Y. Bengio: ‘NICE: Non-linear Independent Components Estimation’.

ArXiv e-prints , 2014. arXiv:1410.8516.

[15] D. Jimenez Rezende and S. Mohamed: ‘Variational Inference with Normalizing Flows’. ArXiv

e-prints , 2015. arXiv:1505.05770.

[16] L. Dinh, J. Sohl-Dickstein, and S. Bengio: ‘Density estimation using Real NVP’. ArXiv e-prints

, 2016. arXiv:1605.08803.

[17] G. Papamakarios, T. Pavlakou, and I. Murray: ‘Masked Autoregressive Flow for Density

Estimation’. ArXiv e-prints , 2017. arXiv:1705.07057.

[18] C.-W. Huang, D. Krueger, A. Lacoste, and A. Courville: ‘Neural Autoregressive Flows’. ArXiv

e-prints , 2018. arXiv:1804.00779.

[19] G. Papamakarios, D. C. Sterratt, and I. Murray: ‘Sequential Neural Likelihood: Fast Likelihood-

free Inference with Autoregressive Flows’. ArXiv e-prints , 2018. arXiv:1805.07226.

[20] T. Q. Chen, Y. Rubanova, J. Bettencourt, and D. K. Duvenaud: ‘Neural ordinary differential
equations’. CoRR abs/1806.07366, 2018. arXiv:1806.07366, URL http://arxiv.org/abs/
1806.07366.

[21] D. P. Kingma and P. Dhariwal: ‘Glow: Generative Flow with Invertible 1x1 Convolutions’.

arXiv e-prints arXiv:1807.03039, 2018. arXiv:1807.03039.

[22] W. Grathwohl, R. T. Q. Chen, J. Bettencourt, I. Sutskever, and D. Duvenaud: ‘FFJORD: Free-
form Continuous Dynamics for Scalable Reversible Generative Models’. ArXiv e-prints , 2018.
arXiv:1810.01367.

[23] M. Germain, K. Gregor, I. Murray, and H. Larochelle: ‘MADE: Masked Autoencoder for

Distribution Estimation’. ArXiv e-prints , 2015. arXiv:1502.03509.

[24] B. Uria, M.-A. Côté, K. Gregor, I. Murray, and H. Larochelle: ‘Neural Autoregressive Distribu-

tion Estimation’. ArXiv e-prints , 2016. arXiv:1605.02226.

[25] A. van den Oord, S. Dieleman, H. Zen, et al.: ‘WaveNet: A Generative Model for Raw Audio’.

ArXiv e-prints , 2016. arXiv:1609.03499.

[26] A. van den Oord, N. Kalchbrenner, O. Vinyals, L. Espeholt, A. Graves, and K. Kavuk-
cuoglu: ‘Conditional Image Generation with PixelCNN Decoders’. ArXiv e-prints , 2016.
arXiv:1606.05328.

[27] A. van den Oord, N. Kalchbrenner, and K. Kavukcuoglu: ‘Pixel Recurrent Neural Networks’.

ArXiv e-prints , 2016. arXiv:1601.06759.

[28] Y. Fan, D. J. Nott, and S. A. Sisson: ‘Approximate Bayesian Computation via Regression

Density Estimation’. ArXiv e-prints , 2012. arXiv:1212.1479.

[29] G. Papamakarios and I. Murray: ‘Fast ε-free inference of simulation models with bayesian
conditional density estimation’. In ‘Advances in Neural Information Processing Systems’, p.
1028–1036, 2016.

10

[30] B. Paige and F. Wood: ‘Inference Networks for Sequential Monte Carlo in Graphical Models’.

ArXiv e-prints , 2016. arXiv:1602.06701.

[31] R. Dutta, J. Corander, S. Kaski, and M. U. Gutmann: ‘Likelihood-free inference by ratio

estimation’. ArXiv e-prints , 2016. arXiv:1611.10242.

[32] G. Louppe and K. Cranmer: ‘Adversarial Variational Optimization of Non-Differentiable

Simulators’. ArXiv e-prints , 2017. arXiv:1707.07113.

[33] J.-M. Lueckmann, P. J. Goncalves, G. Bassetto, K. Öcal, M. Nonnenmacher, and J. H. Macke:
‘Flexible statistical inference for mechanistic models of neural dynamics’. arXiv e-prints
arXiv:1711.01861, 2017. arXiv:1711.01861.

[34] J.-M. Lueckmann, G. Bassetto, T. Karaletsos, and J. H. Macke: ‘Likelihood-free inference with

emulator networks’. arXiv e-prints arXiv:1805.09294, 2018. arXiv:1805.09294.

[35] F. Wood, J. W. van de Meent, and V. Mansinghka: ‘A new approach to probabilistic program-
ming inference’. In ‘Proceedings of the 17th International conference on Artiﬁcial Intelligence
and Statistics’, p. 1024-1032, 2014.

[36] T. A. Le, Baydin, A. G. Baydin, and F. Wood: ‘Inference compilation and universal probabilistic
programming’. In ‘Proceedings of the 20th International Conference on Artiﬁcial Intelligence
and Statistics (AISTATS)’, volume 54 of Proceedings of Machine Learning Research, p. 1338–
1348. PMLR, Fort Lauderdale, FL, USA, 2017.

[37] D. S. Greenberg, M. Nonnenmacher, and J. H. Macke: ‘Automatic Posterior Transformation
for Likelihood-Free Inference’. arXiv e-prints arXiv:1905.07488, 2019. arXiv:1905.07488.

[38] J. Brehmer, K. Cranmer, G. Louppe, and J. Pavez: ‘Constraining Effective Field Theories with

Machine Learning’. Phys. Rev. Lett. 121 (11), p. 111801, 2018. arXiv:1805.00013.

[39] J. Brehmer, K. Cranmer, G. Louppe, and J. Pavez: ‘A Guide to Constraining Effective Field

Theories with Machine Learning’. Phys. Rev. D98 (5), p. 052004, 2018. arXiv:1805.00020.

[40] R. J. Williams: ‘Simple statistical gradient-following algorithms for connectionist reinforcement

learning’. In ‘Reinforcement Learning’, Springer, p. 5–32, 1992.

[41] J. Brehmer, K. Cranmer, G. Louppe, and J. Pavez: ‘Code repository for the generalized Galton
board example in the paper “Mining gold from implicit models to improve likelihood-free
inference”’. http://github.com/johannbrehmer/simulator-mining-example, 2018.

[42] M. M. Graham, A. J. Storkey, et al.: ‘Asymptotically exact inference in differentiable generative

models’. Electronic Journal of Statistics 11 (2), p. 5105, 2017.

[43] Participants of the Likelihood-Free Inference Meeting at the Flatiron Institute 2019: ‘Code
repository for the automatic calculation of joint score and joint likelihood ratio with Pyro.’
https://github.com/LFITaskForce/benchmark, 2019.

[44] E. Bingham, J. P. Chen, M. Jankowiak, et al.: ‘Pyro: Deep Universal Probabilistic Program-

ming’. Journal of Machine Learning Research , 2018.

[45] P. Baldi, K. Cranmer, T. Faucett, P. Sadowski, and D. Whiteson: ‘Parameterized neural networks

for high-energy physics’. Eur. Phys. J. C76 (5), p. 235, 2016. arXiv:1601.07913.

[46] J. Alsing and B. Wandelt: ‘Generalized massive optimal data compression’. Mon. Not. Roy.

Astron. Soc. 476 (1), p. L60, 2018. arXiv:1712.00012.

[47] J. Alsing and B. Wandelt: ‘Nuisance hardened data compression for fast likelihood-free infer-

ence’ , 2019. arXiv:1903.01473.

[48] A. J. Lotka: ‘Analytical note on certain rhythmic relations in organic systems’. Proceedings of

the National Academy of Sciences 6 (7), p. 410, 1920.

[49] A. J. Lotka: ‘Undamped oscillations derived from the law of mass action.’ Journal of the

american chemical society 42 (8), p. 1595, 1920.

11

[50] D. T. Gillespie: ‘A general method for numerically simulating the stochastic time evolution of

coupled chemical reactions’. Journal of Computational Physics 22 (4), p. 403 , 1976.

[51] G. Papamakarios, T. Pavlakou, and I. Murray: ‘Code repository for paper “Masked Autoregress-

ive Flow for Density Estimation”’. http://github.com/gpapamak/maf, 2017.

[52] J. Brehmer, K. Cranmer, G. Louppe, and J. Pavez: ‘Code repository for the Lotka-Volterra
example in the paper “Mining gold from implicit models to improve likelihood-free inference”’.
http://github.com/johannbrehmer/goldmine, 2018.

[53] J. Alwall, R. Frederix, S. Frixione, et al.: ‘The automated computation of tree-level and next-
to-leading order differential cross sections, and their matching to parton shower simulations’.
JHEP 07, p. 079, 2014. arXiv:1405.0301.

[54] K. Cranmer and T. Plehn: ‘Maximum signiﬁcance at the LHC and Higgs decays to muons’. Eur.

Phys. J. C51, p. 415, 2007. arXiv:hep-ph/0605268.

[55] T. Plehn, P. Schichtel, and D. Wiegand: ‘Where boosted signiﬁcances come from’. Phys. Rev.

D89 (5), p. 054002, 2014. arXiv:1311.2591.

[56] F. Kling, T. Plehn, and P. Schichtel: ‘Maximizing the signiﬁcance in Higgs boson pair analyses’.

Phys. Rev. D95 (3), p. 035026, 2017. arXiv:1607.07441.

[57] B. Eli, J. P. Chen, M. Jankowiak, et al.: ‘Pyro: Deep probabilistic programming’. https:

//github.com/uber/pyro, 2017.

[58] D. Tran, M. D. Hoffman, R. A. Saurous, E. Brevdo, K. Murphy, and D. M. Blei: ‘Deep

probabilistic programming’. arXiv preprint arXiv:1701.03757 , 2017.

[59] N. Siddharth, B. Paige, J.-W. van de Meent, et al.: ‘Learning disentangled representations with
semi-supervised deep generative models’. In I. Guyon, U. V. Luxburg, S. Bengio, et al. (eds.),
‘Advances in Neural Information Processing Systems 30’, p. 5927–5937. Curran Associates,
Inc., 2017.

[60] A. Gelman, D. Lee, and J. Guo: ‘Stan: A Probabilistic Programming Language for Bayesian
Inference and Optimization’. Journal of Educational and Behavioral Statistics 40 (5), p. 530,
2015.

12

9
1
0
2
 
g
u
A
 
5
 
 
]
L
M

.
t
a
t
s
[
 
 
4
v
4
4
2
2
1
.
5
0
8
1
:
v
i
X
r
a

Mining gold from implicit models to improve
likelihood-free inference

Johann Brehmer,1 Gilles Louppe,2 Juan Pavez,3 and Kyle Cranmer1
1 New York University, 2 University of Liège, 3 Federico Santa María Technical University
johann.brehmer@nyu.edu, g.louppe@uliege.be,
juan.pavezs@alumnos.usm.cl, kyle.cranmer@nyu.edu

Abstract

Simulators often provide the best description of real-world phenomena. However,
the density they implicitly deﬁne is often intractable, leading to challenging inverse
problems for inference. Recently, a number of techniques have been introduced in
which a surrogate for the intractable density is learned, including normalizing ﬂows
and density ratio estimators. We show that additional information that characterizes
the latent process can often be extracted from simulators and used to augment the
training data for these surrogate models. We introduce several new loss functions
that leverage this augmented data, and demonstrate that these new techniques can
improve sample efﬁciency and quality of inference.

1

Introduction

In many areas of science, complicated real-world phenomena are best described through computer
simulations. Typically, the simulators implement a stochastic generative process in the “forward”
mode based on a well-motivated mechanistic model with parameters θ. While the simulators can
generate samples of observations x ∼ p(x|θ), they typically do not admit a tractable likelihood (or
density) p(x|θ). Probabilistic models deﬁned only via the samples they produce are often called
implicit models. Implicit models lead to intractable inverse problems, which is a barrier for statistical
inference of the parameters θ given observed data. These problems arise in ﬁelds as diverse as
particle physics, epidemiology, and population genetics, which has motivated the development of
likelihood-free inference algorithms such as Approximate Bayesian Computation (ABC) [1–4] and
neural density estimation (NDE) techniques [5–34]. While many of these techniques can be exact
in the limit of inﬁnite training samples, real-world simulators are computationally expensive, and
sample efﬁciency is immensely important.

We present a suite of new techniques that can dramatically improve the sample efﬁciency for training
neural network surrogates that estimate the likelihood p(x|θ) or likelihood ratio r(x|θ0, θ1) =
p(x|θ0)/p(x|θ1). This provides the key quantity needed for both frequentist and Bayesian inference
procedures. Our approach involves extracting additional information that characterizes the latent
process from the simulator, as we explain in Sec. 3. In Sec. 4 we introduce the loss functions that
utilize this augmented data. In Sec. 5 we demonstrate through a range of experiments that these new
techniques provide a signiﬁcant increase in sample efﬁciency compared to techniques that do not
leverage the augmented data, which ultimately increase the quality of inference.

Techniques for likelihood-free inference can be divided into two broad categories. In the ﬁrst category,
the inference is performed by directly comparing the observed data to the output of the simulator.
This includes Approximate Bayesian Computation (ABC) [1–4] and probabilistic programming

2 Related work

Preprint. Under review.

systems [35, 36]. Here we focus on a second category, in which the simulator is used to generate
training data for a tractable surrogate model that is used during inference. There are rich connections
between simulator-based inference and learning in implicit generative models such as GANs, with a
considerable amount of cross-pollination between these areas [9].

The likelihood ratio trick (LRT). A surrogate model for the likelihood ratio ˆr(x|θ0, θ1) can
be deﬁned by training a probabilistic classiﬁer to discriminate between two equal-sized samples
{xi} ∼ p(x|θ0) and {xi} ∼ p(x|θ1). The binary cross-entropy loss

LXE = −E[1(θ = θ1) log ˆs(x|θ0, θ1) + 1(θ = θ0) log(1 − ˆs(x|θ0, θ1))]

(1)

is minimized by the optimal decision function s(x|θ0, θ1) = p(x|θ1)/(p(x|θ0) + p(x|θ1)). Inverting
this relation, the likelihood ratio can be estimated from the classiﬁer decision function ˆs(x) as
ˆr(x|θ0, θ1) = (1 − ˆs(x|θ0, θ1))/ˆs(x|θ0, θ1). This “likelihood ratio trick” is widely appreciated [5–
13]. In practice, not all probabilistic classiﬁers trained to separate samples from θ0 and θ1 learn the
optimal decision function. As long as the classiﬁer decision function is a monotonic function of the
likelihood ratio, this relation can be restored through a calibration procedure, substantially increasing
the applicability of the likelihood ratio trick [6–8]. We use the term CARL (Calibrated approximate
ratios of likelihoods) to describe likelihood ratio estimators based on calibrated classiﬁers.

Neural density estimation (NDE). More recently, several methods for conditional density estima-
tion have been proposed, often based on neural networks [13–34]. They can be used to train a surrog-
ate for the likelihood p(x|θ) [17, 19, 34] or, in a Bayesian setting, the posterior p(θ|x) [29, 33, 37].
One particularly interesting class of models are normalizing ﬂows [14–22], which model the density
as a sequence of invertible transformations applied to a simple base density. The target density
is then given by the Jacobian determinant of the transformation. Closely related, autoregressive
models [23–27] factorize a target density as a sequence of simpler conditional densities.

Novel contributions. The most important novel contribution that differentiates our work from the
existing methods is the observation that additional information can be extracted from the simulator,
and the development of loss functions that allow us to use this “augmented” data to more efﬁciently
learn surrogates for the likelihood function. In addition, we show how the augmented data can
be used to deﬁne locally optimal summary statistics, which can then be used for inference with
density estimation techniques or ABC. We playfully introduce the analogy of mining gold as this
augmented data requires work to extract and is very valuable. In experiments we demonstrate that
these approaches can dramatically improve sample efﬁciency and quality of likelihood-free inference.

Concurrently, the application of these methods to a speciﬁc class of problems in particle physics
has been discussed in Refs. [38, 39]. The present manuscript is meant to serve as the primary
reference for these new techniques and is addressed to the broader physical science and machine
learning communities. Most importantly, it generalizes the speciﬁc particle physics case to almost
any scientiﬁc simulator, requiring signiﬁcantly weaker assumption than those made in the physics
context. We also introduce an entirely new algorithm called SCANDAL, for which we provide the
ﬁrst experimental results.

3 Extracting more information from the simulator

We consider a scientiﬁc simulator that implements a stochastic generative process that proceeds
through a series of latent states zi ∈ Zi and ﬁnally to an output x ∈ Rdx . The latent space structure
Z can involve discrete and continuous components and is derived from the control ﬂow of the
(differentiable or non-differentiable) simulation code. Based on the mechanistic model implemented
by the simulator, each latent state is sampled from a conditional probability density zi ∼ pi(zi|θ, z<i)
and the ﬁnal output is sampled from x ∼ px(x|θ, z). The likelihood is then given by

(cid:90)

(cid:90)

p(x|θ) =

dz p(x, z|θ) =

dz px(x|θ, z)

pi(zi|θ, z<i) .

(2)

(cid:89)

i

Often the likelihood is intractable exactly because the latent space z is enormous and it is unfeasible
to explicitly calculate this integral. In real-world scientiﬁc simulators, the trajectory for a single
observation can involve many millions of latent variables.

2

In this paper we consider the problem of estimating the likelihood p(x|θ) or the likelihood ratio
r(x|θ0, θ1), which for the practical purpose of inferring parameter values θ can be used almost
interchangably, based on the data available from N runs of the simulator.

Typically, the setting of likelihood-free inference assumes that the only available output from the
simulator are samples of observations x ∼ p(x|θ). But in real-life simulators, more information can
usually be extracted. We typically have access to the latent variables z, and the distributions of each
latent variable pi(zi|θ, z<i) and px(x|θ, z) are tractable.

The key observation that is the starting point of our new inference methods is the following: While
p(x|θ) is intractable, for each simulated sample we can calculate the joint score

t(x, z|θ0) ≡ ∇θ log p(x, z|θ)

=

+ ∇θ log px(x|θ, z)

(3)

(cid:12)
(cid:12)
(cid:12)
(cid:12)θ0

(cid:12)
(cid:12)
∇θ log pi(zi|θ, z<i)
(cid:12)
(cid:12)θ0

(cid:88)

i

(cid:12)
(cid:12)
(cid:12)
(cid:12)θ0

by accumulating the factors ∇θ log p(zi|θ, z:i) as the simulation runs forward through its control
ﬂow conditioned on the random trajectory z. It can be insightful to think of the mechanistic model
in the simulator as deﬁning a policy πθ and t(x, z|θ0) as analogous to the policy gradient used in
REINFORCE [40]. However, instead of trying to optimize θ via a stochastic gradient estimate of some
reward function, we will simply augment the data generated by the simulator with the joint score.

Similarly, we can extract the joint likelihood ratio

r(x, z|θ0, θ1) ≡

p(x, z|θ0)
p(x, z|θ1)

=

px(x|θ0, z)
px(x|θ1, z)

(cid:89)

i

pi(zi|θ0, z<i)
pi(zi|θ1, z<i)

.

(4)

The joint score and joint likelihood ratio quantify how much more or less likely a particular simulated
trajectory through the simulator would be if one changed θ.

As a motivating example, consider the simulation for a
generalization of the Galton board, in which a set of balls
is dropped through a lattice of nails ending in one of sev-
eral bins denoted by x. The Galton board is commonly
used to demonstrate the central limit theorem, and if the
nails are uniformly placed such that the probability of
bouncing to the left is p, the sum over the latent space is
tractable analytically and the resulting distribution of x
is a binomial distribution. However, if the nails are not
uniformly placed, and the probability of bouncing to the
left is an arbitrary function of the nail position and some
parameter θ, the resulting distribution requires an explicit
sum over the latent paths z that might lead to a particular
x. Such a distribution would become intractable as the
size of the lattice increases. Figure 1 shows an example
of two latent trajectories that lead to the same x. In this
toy example, the probability p(zh, zv, θ) of going left is
given by (1 − f (zv))/2 + f (zv)σ(5θ(zh − 1/2)), where
f (zv) = sin(πzv), σ is the sigmoid function, and zh and
zv are the horizontal and vertical nail positions normal-
ized to [0, 1]. This leads to a non-trivial p(x|θ), which can
even be bimodal. Code for simulation and inference in
this problem is available at Ref. [41].

Figure 1: A toy simulation generalizing the
Galton board where the transitions are biased
left (blue) or right (red) depending on the nail
position and the value of θ. Two example lat-
ent trajectories z are shown (blue and green),
leading to the same observed value of x. Be-
low, the distribution for θ0 = −0.8 and
θ1 = −0.6. An example empirical distri-
bution from 100 runs for θ0 shows that the
sample variance is much larger than the dif-
ferences from θ0 vs θ1.

Figure 1 shows that a large number of samples from the
simulator are needed to reveal the differences in the distri-
bution of x for small changes in θ – the number of samples needed grows like (p/∆p)2. Moreover,
this toy simulation is representative of many real-world simulators in that it is composed of non-
differentiable control-ﬂow elements. This poses a difﬁculty, making methods based on ∇zx [42]
and ∇θx inapplicable, which previously motivated techniques such as Adversarial Variational
Optimization [32]. But the joint score in Eq. (3) can easily be computed by accumulating the
factors ∇θ log p(zh, zv|θ0), and we can calculate the joint likelihood ratio by accumulating factors
p(zh, zv|θ0)/p(zh, zv|θ1). In analogy to the Galton board toy example, even complicated real-world
simulators often allow us to accumulate these factors as they run, and to calculate the joint score and

3

joint likelihood ratio conditional on a particular stochastic execution trace z. We will demonstrate
this with two more examples in Sec. 5.

For simulators written in an automatic differentiation framework, the calculation of the joint score
and joint likelihood ratio can be entirely automatic and does not require any changes to the simulator
code and output. As a proof of principle, at Ref. [43] we provide a framework that automates
these calculations for any simulator in which all stochastic steps are implemented with the PYRO
library [44].

4 Learning from augmented data

4.1 Key idea

How can the “augmented data” consisting of simulated observations xi, the joint likelihood ratio
r(xi, zi|θ0, θ1), and the joint score t(xi, zi|θ0) be used to estimate the likelihood p(x|θ) or likelihood
ratio r(x|θ0, θ1)? The relation between r(x, z|θ0, θ1) and r(x|θ0, θ1) is not trivial — the integral of
the ratio is not the ratio of the integrals! Similarly, how can the joint score be used to estimate the
intractable score function

t(x|θ0) ≡ ∇θ log p(x|θ)

?

(cid:12)
(cid:12)
(cid:12)
(cid:12)θ0

The integral of the log is not the log of the integral!

Consider the squared error of a function ˆg(x) that only depends on the observable x, but is trying to
approximate a function g(x, z) that also depends on the latent variable z,

LMSE = Ep(x,z|θ)

(cid:104)

(g(x, z) − ˆg(x))2 (cid:105)

.

The minimum-mean-squared-error prediction of ˆg(x) is given by the conditional expectation g∗(x) =
arg minˆg LMSE = Ep(z|x,θ)[g(x, z)].
Identifying g(x, z) with the joint likelihood ratio r(x, z|θ0, θ1) and θ = θ1, we deﬁne
(cid:104)

Lr = Ep(x,z|θ1)

(r(x, z|θ0, θ1) − ˆr(x))2 (cid:105)

,

and ﬁnd that this functional is minimized by r∗(x) = arg minˆr Lr = Ep(z|x,θ1) [ r(x, z|θ0, θ1) ] =
r(x|θ0, θ1). Similarly, by identifying g(x, z) with the joint score t(x, z|θ0) and setting θ = θ0, we
deﬁne

Lt = Ep(x,z|θ0)

(cid:104) (cid:0)t(x, z|θ0) − ˆt(x|θ0)(cid:1)2 (cid:105)

,

which is minimized by t∗(x) = Ep(z|x,θ0) [ t(x, z|θ0) ] = t(x|θ0).
These loss functionals are immensely useful because they allow us to transform t(x, z|θ0) into t(x|θ0)
and r(x, z|θ0, θ1) into r(x|θ0, θ1): we are able to regress on these two intractable quantities! This is
what makes the joint score and joint likelihood ratio the gold worth mining.

(5)

(6)

(7)

(8)

4.2 Learning the likelihood ratio

Based on this observation we introduce a family of new likelihood-free inference techniques. They
fall into two categories. We ﬁrst discuss a class of algorithms that uses the augmented data to learn
a surrogate model for any likelihood p(x|θ) or likelihood ratio r(x|θ0, θ1). In Section 4.3 we will
deﬁne a second class of methods that is based on a local expansion of the model around some
reference parameter point.

The simulators we consider in this work do not only implicitly deﬁne a single density p(x), but a
family of densities p(x|θ). The parameters θ may potentially belong to a high-dimensional parameter
space. For inference models based on surrogate models, there are two broad strategies to model
this dependence. The ﬁrst is to estimate p(x|θ) or the likelihood ratio r(x|θ0, θ1) for speciﬁc values
of θ or pairs (θ0, θ1). This may be done via a pre-deﬁned set of θ values or on-demand using an
active-learning iteration. We follow a second approach, in which we train parameterized estimators
for the full model ˆp(x|θ) or ˆr(x|θ0, θ1) as a function of both the observables x and the parameters
θ [6, 45]. The training data then consists of a number of samples, each generated with different

4

values of θ0 and θ1, and the parameter values are used as additional inputs to the surrogate model.
When modeling the likelihood ratio, the reference hypothesis θ1 in the denominator of the likelihood
ratio can be kept at a ﬁxed reference value (or a marginal model with some prior π(θ1)), and only
the θ0 dependence is modeled by the network. This approach encourages the estimator to learn the
typically smooth dependence of the likelihood ratio on the parameters of interest from the training
data and borrow power from neighboring points.

ROLR (Regression On Likelihood Ratio): First, a number of parameter points (θ0, θ1) is drawn
from θi ∼ πi(θi). For each pair (θ0, θ1), we run the simulator both for θ0 and for θ1, labelling the
samples with y = 0 and y = 1, respectively. In addition to samples x ∼ p(x|θy) we also extract the
joint likelihood ratio r(x, z|θ0, θ1).

An expressive regressor ˆr(x|θ0, θ1) (e. g. a neural network) is trained by minimizing the squared
error loss

LROLR[ˆr] =

yi |r(xi, zi) − ˆr(xi)|2 + (1 − yi)

1
N

(cid:32)

(cid:88)

i

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
r(xi, zi)

−

2(cid:33)
.

1
ˆr(xi)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(9)

Here and in the following the θ dependence is implicit to reduce the notational clutter.

Both terms in this loss function are estimators of Eq. (7) (in the second term we switch θ0 ↔ θ1
to reduce the variance by mapping out other regions of x space). As we showed in the previous
section, this loss function is, at least in the limit of inﬁnite data, minimized by the true likelihood
ratio r(x|θ0, θ1). A regressor trained in this way thus provides an estimator for the likelihood ratio
and can be used for frequentist or Bayesian inference methods.

RASCAL (Ratio And SCore Approximate Likelihood ratio):
If such a likelihood ratio regressor
is differentiable (as is the case for neural networks) with respect to θ, we can calculate the predicted
score ˆt(x|θ0) = ∇θ0 log ˆr(x|θ0, θ1). For a perfect likelihood ratio estimator, ˆt(x|θ0) minimizes the
squared error with respect to the joint score, see Eq. (8). Turning this argument around, we can
improve the training of a likelihood ratio estimator by minimizing the combined ratio and score loss
with a hyper-parameter α

LRASCAL[ˆr] = LROLR[ˆr] + α

(1 − yi) |t(xi, zi) − ∇θ0 log ˆr(xi)|2 .

(10)

1
N

(cid:88)

i

CASCAL (CARL And SCore Approximate Likelihood ratio): The same trick can be used to
improve the likelihood ratio trick and the CARL inference method [6, 8]. Following the discussion
around Eq. (1), a calibrated classiﬁer trained to discriminate samples {xi} ∼ p(x|θ0) and {xi} ∼
p(x|θ1) provides a likelihood ratio estimator. For a differentiable parameterized classiﬁer, we can
calculate the surrogate score ˆt(x|θ0) = ∇θ0 log[(1 − ˆs(x|θ0, θ1))/ˆs(x|θ0, θ1)]. This allows us to
train an improved classiﬁer (and thus a likelihood ratio estimator) by minimizing the combined loss

LCASCAL[ˆs] = LXE[ˆs] + α

(1 − yi)

t(xi, zi) − ∇θ0 log

1
N

(cid:88)

i

(cid:12)
(cid:12)
(cid:12)
(cid:12)

2

(cid:20) 1 − ˆs(x)
ˆs(x)

(cid:21)(cid:12)
(cid:12)
(cid:12)
(cid:12)

.

(11)

SCANDAL (SCore-Augmented Neural Density Approximates Likelihood): Finally, we can use
the same strategy to improve conditional neural density estimators such as density networks or
normalizing ﬂows. If a parameterized neural density estimator ˆp(x|θ) is differentiable with respect to
θ, we can calculate the surrogate score ˆt(x) = ∇θ log ˆp(x|θ) and train an improved density estimator
by minimizing

LSCANDAL[ˆp] = LMLE + α

|t(xi, zi) − ∇θ log ˆp(x)|2 .

(12)

Unlike the methods discussed before, this provides an estimator of the likelihood itself rather than its
ratio. Depending on the architecture, the surrogate also provides a generative model.

1
N

(cid:88)

i

5

4.3 Locally sufﬁcient statistics for implicit models

A second class of new likelihood-free inference methods is based on an expansion of the implicit
model around a reference parameter point θref. Up to linear order in θ − θref, we ﬁnd

plocal(x|θ) =

p(t(x|θref) | θref) exp[t(x|θref) · (θ − θref)]

(13)

1
Z(θ)

with some normalization factor Z(θ). This local approximation is in the exponential family and the
score vector t(x|θref), deﬁned in Eq. (5), are its sufﬁcient statistics.
For inference in a sufﬁciently small neighborhood around a reference point θref, a precise estimator
of the score ˆt(x|θref) therefore deﬁnes a vector of ideal summary statistics that contain all the
information in an observation x on the parameters θ [see also 3, 46, 47]. The joint score together
with a minimization of the loss in Eq. (8) allows us to extract sufﬁcient statistics from an intractable,
non-differentiable simulator, at least in the neighborhood of θref. Moreover, this local model can be
estimated by running the simulator at a single value θref — it does not require scanning the θ space,
and thus avoids the curse of dimensionality. Based on this observation, we introduce two further
inference strategies:

SALLY (Score Approximates Likelihood LocallY): By minimizing the squared error with respect
to the joint score, see Eq. (8), we train a score estimator ˆt(x|θref). In a next step, we estimate the
density ˆp(ˆt(x|θref)|θ) through standard multivariate density estimation techniques. This calibration
procedure implicitly includes the effect of the normalizing constant Z(θ).

SALLINO (Score Approximates Likelihood Locally IN One dimension): The SALLY inference
method requires density estimation in the estimated score space, with typically dim ˆt ≡ dim θ (cid:28)
dim x. But in cases with large number of parameters, it is beneﬁcial to reduce the dimensionality even
further. In the local model of Eq. (13), the likelihood ratio r(x|θ0, θ1) only depends on h(x|θ0, θ1) ≡
t(x|θref) · (θ0 − θ1) up to an x-independent constant related to Z(θ). Any neural score estimator lets
us also estimate this scalar function, which is a sufﬁcient statistic for the 1-dimensional parameter
space connecting θ0 and θ1. We can thus estimate the likelihood ratio through univariate, rather than
multivariate, density estimation on ˆh.

The SALLY and SALLINO techniques are designed to work very well close to the reference point.
The local model approximation may deteriorate further away, leading to a reduced sensitivity and
weaker bounds. These approaches are simple and robust, and in particular the SALLINO algorithm
scales exceptionally well to high-dimensional parameter spaces.

For all these inference strategies, the augmented data is particularly powerful for enhancing the
power of simulation-based inference for small changes in the parameter θ. When restricted to
samples x ∼ p(x|θ), the variance from the simulator is a challenge. The ﬂuctuations in the empirical
density scale with the square root of the number of samples, thus large numbers of samples are
required before small changes in the implicit density can faithfully be distinguished. In contrast, each
sample of the joint ratio and joint score provides an exact piece of information even for arbitrarily
small changes in θ. On the other hand, the augmented data is less powerful for deciding between
model parameter points that are far apart. In this situation the joint probability distributions p(x, z|θ)
often do not overlap signiﬁcantly, and the joint likelihood ratio can have a large variance around the
intractable likelihood ratio r(x|θ0, θ1). In addition, over large distances in parameter space the local
model is not valid and the score does not characterize the likelihood ratios anymore, limiting the
usefulness of the joint score.

5 Experiments

Generalized Galton board. We return to the motivating example in Sec. 3 and Fig. 1 and try to
estimate likelihood ratios for the generalized Galton board. We use the likelihood ratio trick and
a neural density estimator as baselines and compare them to the new ROLR, RASCAL, CASCAL,
and SCANDAL methods. As the simulator deﬁnes a distribution over a discrete x, for the NDE and
SCANDAL methods we use a neural network with a softmax output layer over the bins to model
ˆp(x|θ). All networks are explicitly parameterized in terms of θ, the parameter of the simulator that

6

Figure 2: Left: Galton board example. MSE on log r vs. training sample size. We show the mean and its error
based on 15 runs. Middle: Lotka-Volterra example. MSE on log p (top) and log r (bottom) vs. training sample
size. We show the median and the standard deviation of 10 runs. Right: Particle physics example. MSE on log r
vs. training sample size.

deﬁnes the position of the nails (i. e. they take θ as an input). We use a simple network architecture
with a single hidden layer, 10 hidden units, and tanh activations. The left panel of Fig. 2 shows the
mean squared error between log ˆr(x|θ0, θ1) and the true log r(x|θ0, θ1) (estimated from histograms
of 2 · 104 simulations from θ0 = −0.8 and θ1 = −0.6), summing over x ∈ [5, 15], versus the
training sample size (which refers to the total number of x samples, distributed over 10 values of
θ ∈ [−1, −0.4]). We ﬁnd that both SCANDAL and RASCAL are dramatically more sample efﬁcient
than pure neural density estimation and the likelihood ratio trick, which do not leverage the joint
score. ROLR improves upon pure neural density estimation and achieves the same asymptotic error
as SCANDAL, though more slowly.

Lotka-Volterra model. As a second example, we consider the Lotka-Volterra system [48, 49], a
common example in the likelihood-free inference literature. This stochastic Markov jump process
models the dynamics of a species of predators interacting with a species of prey. Four parameters θ
set the rate of predators and prey being born, predators dying, and predators eating prey.

We simulate the Lotka-Volterra model with Gillespie’s algorithm [50]. From the time evolution of
the predator and prey populations we calculate summary statistics x ∈ R9. Our model deﬁnitions,
summary statistics, and initial conditions exactly follow Appendix F of Ref. [29]. In addition to the
observations, we extract the joint score as well as the joint likelihood ratio with respect to a reference
hypothesis log θ1 = (−4.61, −0.69, 0.00, −4.61)T from the simulator. On this augmented data we
train different likelihood and likelihood ratio estimators. As baselines we use CARL [6, 8] and a
conditional masked autoregressive ﬂow (MAF) [17, 51]. We compare them to the new techniques
introduced in section 4.2, including a SCANDAL likelihood estimator based on a MAF. For MAF and
SCANDAL we stack four masked autoregressive distribution estimators (MADEs) [23] on a mixture
of MADEs with 10 components [17]. For all other methods, we use three hidden layers. In all cases,
the hidden layers have 100 units and tanh activations. Code for simulation and inference is available
at Ref. [52].

For inference on a wide prior in the parameter space, the different probability densities often do not
overlap. As discussed above, the augmented data is then of limited use. Instead, we focus on the
regime where we try to discriminate between close parameter points with similar predictions for
the observables. We generate training data and evaluate the models in the range log(θ1)i − 0.01 ≤
θi ≤ log(θ1)i + 0.01 with a uniform prior in log space. In the middle panel of Fig. 2 we evaluate
the different methods by calculating the mean squared error of estimators trained on small training
samples. Since the true likelihood is intractable, we calculate the error with respect to the median
predictions of 10 estimators1 trained on the full data set of 200 000 samples.

1We pick the algorithms we use for these “ground truth” predictions based on the variance between independ-
ent runs and the consistency of improvements with increasing training sample size. For likelihood estimation,
we use the MAF as baseline, with qualitatively similar results when using SCANDAL. For likelihood ratio
estimation, we use the SCANDAL estimator as baseline, and ﬁnd qualitatively similar results for CASCAL.

7

Our results indicate a trade-off between the performance in likelihood (density) estimation and
likelihood ratio estimation. For density estimation, the MAF performs well. The variance of the
score term in the SCANDAL loss degrades the performance, especially for larger values of the
hyperparameter α. However, for statistical inference the more relevant quantity is the likelihood
ratio. Here the new techniques that use the joint score, in particular SCANDAL, are signiﬁcantly more
sample efﬁcient.

Particle physics. Finally we consider a real-world problem from particle physics. A simulator
describes the production of a Higgs boson at the Large Hadron Collider experiments, followed
by the decay into four electrons or muons, subsequent radiation patterns, the interaction with the
detector elements, and the reconstruction procedure. Each recorded collision produces a single
high-dimensional observable x ∈ R42, and the dataset consists of multiple iid observations of x.
The goal is to infer the likelihood of two parameters θ ∈ [−1, 1]2 that characterize the effect of
high-energy physics models on these interactions. We consider a synthetic observed dataset with 36
iid simulated observations of x drawn from θ = (0, 0).

The new inference techniques can accommodate state-of-the-art simulators, but in that setting we
cannot compare them to the true likelihood function. We therefore present a simpliﬁed setup and
approximate the detector response such that the true likelihood function is tractable, providing us
with a ground truth to compare the inference techniques to. As simulator we use a combination
of MADGRAPH 5 [53] and MADMAX [54–56]. The setup and the results of this experiment are
described at length in Ref. [39], which is attached as supplementary material.

In the right panel of Fig. 2 we show the expected mean squared error of the approximate
log ˆr(x|θ0, θ1) for the different techniques as a function of the training sample size. We take the
expectation over random values of θ0, drawn from a Gaussian prior with mean (0, 0) and covariance
matrix diag(0.22, 0.22). We compare the new techniques to the standard practice in particle physics,
in which the likelihood is estimated through histograms of two hand-picked summary statistics.

All new inference techniques outperform the traditional histogram method, provided that the training
samples are sufﬁciently large. Using augmented data substantially decreases the amount of training
data required for a good performance: the RASCAL method, which uses both the joint ratio and joint
score information from the simulator, reduces the amount of training data by two orders of magnitude
compared to the CARL technique, which uses only the samples x ∼ p(x|θ). The particularly simple
local techniques SALLY and SALLINO need even less data for a good performance. However, their
performance eventually plateaus and does not asymptote to zero error. This is because the local
model approximation breaks down further away from the reference point θref = (0, 0)T , and the
score is no longer the sufﬁcient statistics. In the supplementary material we show further results and
demonstrate how the improved likelihood ratio estimation leads to better inference results.

6 Conclusions

In this work we have presented a family of new inference techniques for the setting in which the
likelihood is only implicitly deﬁned through a stochastic generative simulator. The new methods
estimate likelihoods or ratios of likelihoods with data available from the simulator. Most established
inference methods, such as ABC and techniques based on neural density estimation, only use samples
of observables from the simulator. We pointed out that in many cases the joint likelihood ratio and
the joint score — quantities conditioned on the latent variables that characterize the trajectory through
the data generation process — can be extracted from the simulator.

While these additional quantities often require work to be extracted, they also prove to be very
valuable as they can dramatically improve sample efﬁciency and quality of inference. Indeed, we
have shown that this additional information lets us deﬁne loss functionals that are minimized by the
likelihood or likelihood ratio, which can in turn be used to efﬁciently guide the training of neural
networks to precisely estimate the likelihood function. A second class of new techniques is motivated
by a local approximation of the likelihood function around a reference parameter value, where the
score vector is the sufﬁcient statistic. In the case where the simulator provides the joint score, we can
use it to train a precise estimator of the score and use it as locally optimal summary statistics.

8

We have demonstrated in three experiments that the new inference techniques let us precisely estimate
likelihood ratios. In turn, this enables parameter measurements with a higher precision and less
training data than with established methods.

This approach is complementary to many recent advances in likelihood-free inference: the augmented
data can be used to improve training for any neural density estimator or likelihood ratio estimator,
as we have demonstrated for Masked Autoregressive Flows and CARL. It can also be used to deﬁne
locally optimal summary statistics that can be used for instance in ABC techniques.

Finally, these results motivate the development of tools that provide a nonstandard interpretation
of the simulator code and automatically generate the joint score and joint ratio, building on recent
developments in probabilistic programming and automatic differentiation [35, 36, 57–60]. We have
provided a ﬁrst proof-of-principle implementation of such a tool based on PYRO [43].

Acknowledgments

We would like to thank Cyril Becot and Lukas Heinrich, who contributed to this project at an
early stage. We are grateful to Jan-Matthis Lückmann for helping us automate the calculation of
the joint likelihood ratio and joint score in PYRO and to all participants of the Likelihood-free
inference workshop at the Flatiron Institute for great discussions. We would like to thank Felix
Kling, Tilman Plehn, and Peter Schichtel for providing the MADMAX code and helping us use it, and
to George Papamakarios for discussing the Masked Autoregressive Flow code with us. KC wants
to thank CP3 at UC Louvain for their hospitality. Finally, we would like to thank Atılım Güne¸s
Baydin, Lydia Brenner, Joan Bruna, Kyunghyun Cho, Michael Gill, Siavash Golkar, Ian Goodfellow,
Daniela Huppenkothen, Michael Kagan, Hugo Larochelle, Yann LeCun, Fabio Maltoni, Jean-Michel
Marin, Iain Murray, George Papamakarios, Duccio Pappadopulo, Dennis Prangle, Rajesh Ranganath,
Dustin Tran, Rost Verkerke, Wouter Verkerke, Max Welling, and Richard Wilkinson for interesting
discussions.

JB, KC, and GL are grateful for the support of the Moore-Sloan data science environment at NYU.
KC and GL were supported through the NSF grants ACI-1450310 and PHY-1505463. JP was partially
supported by the Scientiﬁc and Technological Center of Valparaíso (CCTVal) under Fondecyt grant
BASAL FB0821. This work was supported in part through the NYU IT High Performance Computing
resources, services, and staff expertise.

References

[1] D. B. Rubin:

‘Bayesianly justiﬁable and relevant frequency calculations for the applied
statistician’. Ann. Statist. 12 (4), p. 1151, 1984. URL https://doi.org/10.1214/aos/
1176346785.

[2] M. A. Beaumont, W. Zhang, and D. J. Balding: ‘Approximate bayesian computation in popula-

tion genetics’. Genetics 162 (4), p. 2025, 2002.

[3] J. Alsing, B. Wandelt, and S. Feeney: ‘Massive optimal data compression and density estimation

for scalable, likelihood-free inference in cosmology’ , 2018. arXiv:1801.01497.

[4] T. Charnock, G. Lavaux, and B. D. Wandelt: ‘Automatic physical inference with information

maximizing neural networks’. Phys. Rev. D97 (8), p. 083004, 2018. arXiv:1802.03537.

[5] I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, et al.: ‘Generative Adversarial Networks’. ArXiv

e-prints , 2014. arXiv:1406.2661.

[6] K. Cranmer, J. Pavez, and G. Louppe: ‘Approximating Likelihood Ratios with Calibrated

Discriminative Classiﬁers’ , 2015. arXiv:1506.02169.

[7] K. Cranmer and G. Louppe: ‘Unifying generative models and exact likelihood-free inference

with conditional bijections’. J. Brief Ideas , 2016.

[8] G. Louppe, K. Cranmer, and J. Pavez: ‘carl: a likelihood-free inference toolbox’. J. Open

Source Softw. , 2016.

[9] S. Mohamed and B. Lakshminarayanan: ‘Learning in Implicit Generative Models’. ArXiv

e-prints , 2016. arXiv:1610.03483.

9

[10] M. U. Gutmann, R. Dutta, S. Kaski, and J. Corander: ‘Likelihood-free inference via classiﬁca-

tion’. Statistics and Computing p. 1–15, 2017.

[11] T. Dinev and M. U. Gutmann: ‘Dynamic Likelihood-free Inference via Ratio Estimation

(DIRE)’. arXiv e-prints arXiv:1810.09899, 2018. arXiv:1810.09899.

[12] J. Hermans, V. Begy, and G. Louppe: ‘Likelihood-free MCMC with Approximate Likelihood

Ratios’ , 2019. arXiv:1903.04057.

[13] D. Tran, R. Ranganath, and D. Blei: ‘Hierarchical implicit models and likelihood-free vari-
ational inference’. In I. Guyon, U. V. Luxburg, S. Bengio, et al. (eds.), ‘Advances in Neural
Information Processing Systems 30’, p. 5523–5533, 2017.

[14] L. Dinh, D. Krueger, and Y. Bengio: ‘NICE: Non-linear Independent Components Estimation’.

ArXiv e-prints , 2014. arXiv:1410.8516.

[15] D. Jimenez Rezende and S. Mohamed: ‘Variational Inference with Normalizing Flows’. ArXiv

e-prints , 2015. arXiv:1505.05770.

[16] L. Dinh, J. Sohl-Dickstein, and S. Bengio: ‘Density estimation using Real NVP’. ArXiv e-prints

, 2016. arXiv:1605.08803.

[17] G. Papamakarios, T. Pavlakou, and I. Murray: ‘Masked Autoregressive Flow for Density

Estimation’. ArXiv e-prints , 2017. arXiv:1705.07057.

[18] C.-W. Huang, D. Krueger, A. Lacoste, and A. Courville: ‘Neural Autoregressive Flows’. ArXiv

e-prints , 2018. arXiv:1804.00779.

[19] G. Papamakarios, D. C. Sterratt, and I. Murray: ‘Sequential Neural Likelihood: Fast Likelihood-

free Inference with Autoregressive Flows’. ArXiv e-prints , 2018. arXiv:1805.07226.

[20] T. Q. Chen, Y. Rubanova, J. Bettencourt, and D. K. Duvenaud: ‘Neural ordinary differential
equations’. CoRR abs/1806.07366, 2018. arXiv:1806.07366, URL http://arxiv.org/abs/
1806.07366.

[21] D. P. Kingma and P. Dhariwal: ‘Glow: Generative Flow with Invertible 1x1 Convolutions’.

arXiv e-prints arXiv:1807.03039, 2018. arXiv:1807.03039.

[22] W. Grathwohl, R. T. Q. Chen, J. Bettencourt, I. Sutskever, and D. Duvenaud: ‘FFJORD: Free-
form Continuous Dynamics for Scalable Reversible Generative Models’. ArXiv e-prints , 2018.
arXiv:1810.01367.

[23] M. Germain, K. Gregor, I. Murray, and H. Larochelle: ‘MADE: Masked Autoencoder for

Distribution Estimation’. ArXiv e-prints , 2015. arXiv:1502.03509.

[24] B. Uria, M.-A. Côté, K. Gregor, I. Murray, and H. Larochelle: ‘Neural Autoregressive Distribu-

tion Estimation’. ArXiv e-prints , 2016. arXiv:1605.02226.

[25] A. van den Oord, S. Dieleman, H. Zen, et al.: ‘WaveNet: A Generative Model for Raw Audio’.

ArXiv e-prints , 2016. arXiv:1609.03499.

[26] A. van den Oord, N. Kalchbrenner, O. Vinyals, L. Espeholt, A. Graves, and K. Kavuk-
cuoglu: ‘Conditional Image Generation with PixelCNN Decoders’. ArXiv e-prints , 2016.
arXiv:1606.05328.

[27] A. van den Oord, N. Kalchbrenner, and K. Kavukcuoglu: ‘Pixel Recurrent Neural Networks’.

ArXiv e-prints , 2016. arXiv:1601.06759.

[28] Y. Fan, D. J. Nott, and S. A. Sisson: ‘Approximate Bayesian Computation via Regression

Density Estimation’. ArXiv e-prints , 2012. arXiv:1212.1479.

[29] G. Papamakarios and I. Murray: ‘Fast ε-free inference of simulation models with bayesian
conditional density estimation’. In ‘Advances in Neural Information Processing Systems’, p.
1028–1036, 2016.

10

[30] B. Paige and F. Wood: ‘Inference Networks for Sequential Monte Carlo in Graphical Models’.

ArXiv e-prints , 2016. arXiv:1602.06701.

[31] R. Dutta, J. Corander, S. Kaski, and M. U. Gutmann: ‘Likelihood-free inference by ratio

estimation’. ArXiv e-prints , 2016. arXiv:1611.10242.

[32] G. Louppe and K. Cranmer: ‘Adversarial Variational Optimization of Non-Differentiable

Simulators’. ArXiv e-prints , 2017. arXiv:1707.07113.

[33] J.-M. Lueckmann, P. J. Goncalves, G. Bassetto, K. Öcal, M. Nonnenmacher, and J. H. Macke:
‘Flexible statistical inference for mechanistic models of neural dynamics’. arXiv e-prints
arXiv:1711.01861, 2017. arXiv:1711.01861.

[34] J.-M. Lueckmann, G. Bassetto, T. Karaletsos, and J. H. Macke: ‘Likelihood-free inference with

emulator networks’. arXiv e-prints arXiv:1805.09294, 2018. arXiv:1805.09294.

[35] F. Wood, J. W. van de Meent, and V. Mansinghka: ‘A new approach to probabilistic program-
ming inference’. In ‘Proceedings of the 17th International conference on Artiﬁcial Intelligence
and Statistics’, p. 1024-1032, 2014.

[36] T. A. Le, Baydin, A. G. Baydin, and F. Wood: ‘Inference compilation and universal probabilistic
programming’. In ‘Proceedings of the 20th International Conference on Artiﬁcial Intelligence
and Statistics (AISTATS)’, volume 54 of Proceedings of Machine Learning Research, p. 1338–
1348. PMLR, Fort Lauderdale, FL, USA, 2017.

[37] D. S. Greenberg, M. Nonnenmacher, and J. H. Macke: ‘Automatic Posterior Transformation
for Likelihood-Free Inference’. arXiv e-prints arXiv:1905.07488, 2019. arXiv:1905.07488.

[38] J. Brehmer, K. Cranmer, G. Louppe, and J. Pavez: ‘Constraining Effective Field Theories with

Machine Learning’. Phys. Rev. Lett. 121 (11), p. 111801, 2018. arXiv:1805.00013.

[39] J. Brehmer, K. Cranmer, G. Louppe, and J. Pavez: ‘A Guide to Constraining Effective Field

Theories with Machine Learning’. Phys. Rev. D98 (5), p. 052004, 2018. arXiv:1805.00020.

[40] R. J. Williams: ‘Simple statistical gradient-following algorithms for connectionist reinforcement

learning’. In ‘Reinforcement Learning’, Springer, p. 5–32, 1992.

[41] J. Brehmer, K. Cranmer, G. Louppe, and J. Pavez: ‘Code repository for the generalized Galton
board example in the paper “Mining gold from implicit models to improve likelihood-free
inference”’. http://github.com/johannbrehmer/simulator-mining-example, 2018.

[42] M. M. Graham, A. J. Storkey, et al.: ‘Asymptotically exact inference in differentiable generative

models’. Electronic Journal of Statistics 11 (2), p. 5105, 2017.

[43] Participants of the Likelihood-Free Inference Meeting at the Flatiron Institute 2019: ‘Code
repository for the automatic calculation of joint score and joint likelihood ratio with Pyro.’
https://github.com/LFITaskForce/benchmark, 2019.

[44] E. Bingham, J. P. Chen, M. Jankowiak, et al.: ‘Pyro: Deep Universal Probabilistic Program-

ming’. Journal of Machine Learning Research , 2018.

[45] P. Baldi, K. Cranmer, T. Faucett, P. Sadowski, and D. Whiteson: ‘Parameterized neural networks

for high-energy physics’. Eur. Phys. J. C76 (5), p. 235, 2016. arXiv:1601.07913.

[46] J. Alsing and B. Wandelt: ‘Generalized massive optimal data compression’. Mon. Not. Roy.

Astron. Soc. 476 (1), p. L60, 2018. arXiv:1712.00012.

[47] J. Alsing and B. Wandelt: ‘Nuisance hardened data compression for fast likelihood-free infer-

ence’ , 2019. arXiv:1903.01473.

[48] A. J. Lotka: ‘Analytical note on certain rhythmic relations in organic systems’. Proceedings of

the National Academy of Sciences 6 (7), p. 410, 1920.

[49] A. J. Lotka: ‘Undamped oscillations derived from the law of mass action.’ Journal of the

american chemical society 42 (8), p. 1595, 1920.

11

[50] D. T. Gillespie: ‘A general method for numerically simulating the stochastic time evolution of

coupled chemical reactions’. Journal of Computational Physics 22 (4), p. 403 , 1976.

[51] G. Papamakarios, T. Pavlakou, and I. Murray: ‘Code repository for paper “Masked Autoregress-

ive Flow for Density Estimation”’. http://github.com/gpapamak/maf, 2017.

[52] J. Brehmer, K. Cranmer, G. Louppe, and J. Pavez: ‘Code repository for the Lotka-Volterra
example in the paper “Mining gold from implicit models to improve likelihood-free inference”’.
http://github.com/johannbrehmer/goldmine, 2018.

[53] J. Alwall, R. Frederix, S. Frixione, et al.: ‘The automated computation of tree-level and next-
to-leading order differential cross sections, and their matching to parton shower simulations’.
JHEP 07, p. 079, 2014. arXiv:1405.0301.

[54] K. Cranmer and T. Plehn: ‘Maximum signiﬁcance at the LHC and Higgs decays to muons’. Eur.

Phys. J. C51, p. 415, 2007. arXiv:hep-ph/0605268.

[55] T. Plehn, P. Schichtel, and D. Wiegand: ‘Where boosted signiﬁcances come from’. Phys. Rev.

D89 (5), p. 054002, 2014. arXiv:1311.2591.

[56] F. Kling, T. Plehn, and P. Schichtel: ‘Maximizing the signiﬁcance in Higgs boson pair analyses’.

Phys. Rev. D95 (3), p. 035026, 2017. arXiv:1607.07441.

[57] B. Eli, J. P. Chen, M. Jankowiak, et al.: ‘Pyro: Deep probabilistic programming’. https:

//github.com/uber/pyro, 2017.

[58] D. Tran, M. D. Hoffman, R. A. Saurous, E. Brevdo, K. Murphy, and D. M. Blei: ‘Deep

probabilistic programming’. arXiv preprint arXiv:1701.03757 , 2017.

[59] N. Siddharth, B. Paige, J.-W. van de Meent, et al.: ‘Learning disentangled representations with
semi-supervised deep generative models’. In I. Guyon, U. V. Luxburg, S. Bengio, et al. (eds.),
‘Advances in Neural Information Processing Systems 30’, p. 5927–5937. Curran Associates,
Inc., 2017.

[60] A. Gelman, D. Lee, and J. Guo: ‘Stan: A Probabilistic Programming Language for Bayesian
Inference and Optimization’. Journal of Educational and Behavioral Statistics 40 (5), p. 530,
2015.

12

