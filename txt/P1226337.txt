8
1
0
2
 
p
e
S
 
1
2
 
 
]

V
C
.
s
c
[
 
 
2
v
1
9
3
6
0
.
2
1
7
1
:
v
i
X
r
a

1

On the Effectiveness of Least Squares
Generative Adversarial Networks

Xudong Mao, Qing Li, Senior Member, IEEE, Haoran Xie, Member, IEEE,
Raymond Y.K. Lau, Senior Member, IEEE, Zhen Wang, and Stephen Paul Smolley

Abstract—Unsupervised learning with generative adversarial networks (GANs) has proven to be hugely successful. Regular GANs
hypothesize the discriminator as a classiﬁer with the sigmoid cross entropy loss function. However, we found that this loss function may
lead to the vanishing gradients problem during the learning process. To overcome such a problem, we propose in this paper the Least
Squares Generative Adversarial Networks (LSGANs) which adopt the least squares loss for both the discriminator and the generator.
We show that minimizing the objective function of LSGAN yields minimizing the Pearson χ2 divergence. We also show that the derived
objective function that yields minimizing the Pearson χ2 divergence performs better than the classical one of using least squares for
classiﬁcation. There are two beneﬁts of LSGANs over regular GANs. First, LSGANs are able to generate higher quality images than
regular GANs. Second, LSGANs perform more stably during the learning process. For evaluating the image quality, we conduct both
qualitative and quantitative experiments, and the experimental results show that LSGANs can generate higher quality images than
regular GANs. Furthermore, we evaluate the stability of LSGANs in two groups. One is to compare between LSGANs and regular
GANs without gradient penalty. We conduct three experiments, including Gaussian mixture distribution, difﬁcult architectures, and a
newly proposed method — datasets with small variability, to illustrate the stability of LSGANs. The other one is to compare between
LSGANs with gradient penalty (LSGANs-GP) and WGANs with gradient penalty (WGANs-GP). The experimental results show that
LSGANs-GP succeed in training for all the difﬁcult architectures used in WGANs-GP, including 101-layer ResNet.

Index Terms—Least squares GANs, χ2 divergence, generative model, image generation.

(cid:70)

1 INTRODUCTION

D EEP learning has launched a profound reformation and

even been applied to many real-world tasks, such as image
classiﬁcation [1], object detection [2], and segmentation [3].
These tasks fall into the scope of supervised learning, which means
that a lot of labeled data is provided for the learning processes.
Compared with supervised learning, however, unsupervised learn-
ing (such as generative models) obtains limited impact from deep
learning. Although some deep generative models, e.g., RBM [4],
DBM [5], and VAE [6], have been proposed, these models
all face the difﬁculties of intractable functions (e.g., intractable
partition function) or intractable inference, which in turn restricts
the effectiveness of these models.

Unlike the above deep generative models which usually adopt
approximation methods for intractable functions or inference,
Generative Adversarial Networks (GANs) [7] requires no ap-
proximate inference and can be trained end-to-end through a
differentiable network [8]. The basic idea of GANs is to train
a discriminator and a generator simultaneously: the discriminator
aims to distinguish between real samples and generated samples;

• X. Mao and Q. Li are with Department of Computer Science, City

University of Hong Kong, Hong Kong.
E-mail: xudong.xdmao@gmail.com, itqli@cityu.edu.hk

• H. Xie is with Department of Mathematics and Information Technology,

The Education University of Hong Kong, Hong Kong.
E-mail: hrxie2@gmail.com

• R. Lau is with Department of Information Systems, City University of Hong

•

•

Kong, Hong Kong. E-mail: raylau@cityu.edu.hk
Z. Wang is with Center for Optical Imagery Analysis and Learning and
School of Mechanical Engineering, Northwestern Polytechnical Univer-
sity, Xian 710072, China. E-mail: zhenwang0@gmail.com
S. Smolley is with CodeHatch Corp., Edmonton, Alberta Canada.
E-mail: steve@codehatch.com

while the generator tries to generate fake samples as real as pos-
sible, making the discriminator believe that the fake samples are
from real data. GANs have demonstrated impressive performance
for various computer vision tasks such as image generation [9],
[10], image super-resolution [11], and semi-supervised learning
[12].

The original GAN paper

[7] adopted the sigmoid cross
entropy loss for the discriminator and presented two different
losses for the generator: the “minimax” loss (M-GANs) and the
“non-saturating” loss (NS-GANs). They have pointed out that M-
GANs will saturate at the early stage of the learning process. Thus
NS-GANs are recommended for use in practice.

We argue that both the non-saturating loss and the minimax
loss, however, will lead to the problem of vanishing gradients
when updating the generator. As Fig. 2(a) shows,
the non-
saturating loss, i.e., − log D(·), will saturate when the input is
relatively large, while the minimax loss, i.e., log(1 − D(·)), will
saturate when the input is relatively small. Consequently, as Fig.
1(b) shows, when updating the generator, the non-saturating loss
will cause almost no gradient for the fake samples in magenta,
because these samples are on the side of real data, corresponding
to the input with relatively large values in Fig. 2(a). Similarly,
the minimax loss will cause almost no gradient for the fake
samples in green. However, these fake samples are still far from
real data, and we want to pull them closer to real data. Based
on this observation, we propose the Least Squares Generative
Adversarial Networks (LSGANs) which adopt the least squares
loss for both the discriminator and the generator. The idea is
simple yet powerful: the least squares loss is able to move the fake
samples toward the decision boundary, because the least squares
loss penalizes samples that lie in a long way to the decision

2

(a)

(b)

(c)

Fig. 1. Illustration of different behaviors of two loss functions. (a): Decision boundaries of two loss functions. Note that the decision boundary should
go across real data distribution for a successful GANs learning. Otherwise, the learning process is saturated. (b): Decision boundary of the sigmoid
cross entropy loss function. The orange area is the side of real samples, and the blue area is the side of fake samples. The non-saturating loss and
the minimax loss will cause almost no gradient for the fake samples in magenta and green, respectively, when we use them to update the generator.
(c): Decision boundary of the least squares loss function. It penalizes the fake samples (both in magenta and green), and as a result, it forces the
generator to generate samples toward the decision boundary.

rendering 28 × 28 digits using some standard fonts. Datasets
with small variability are difﬁcult for GANs to learn, since the
discriminator can distinguish the real samples very easily for such
datasets.

Recently, gradient penalty has shown the effectiveness of
improving the stability of GANs training [18], [19]. We ﬁnd
that gradient penalty is also helpful for improving the stability
of LSGANs. By adding the gradient penalty in [18], LSGANs
are able to train successfully for all the difﬁcult architectures used
in WGANs-GP [19]. However, gradient penalty also has some
inevitable disadvantages such as additional computational cost and
memory cost. Based on this observation, we evaluate the stability
of LSGANs in two settings: LSGANs without gradient penalty
and LSGANs with gradient penalty.

Our contributions in this paper can be summarized as follows:

• We propose LSGANs which adopt

least squares loss
for both the discriminator and the generator. We show
that minimizing the objective function of LSGANs yields
minimizing the Pearson χ2 divergence.

• We show that the derived objective function that yields
minimizing the Pearson χ2 divergence performs better
than the classical one of using least squares for classiﬁ-
cation.

• We evaluate the image quality of LSGANs on several
datasets including the LSUN-scenes and a cat dataset, and
the experimental results demonstrate that LSGANs can
generate higher quality images than NS-GANs.

• We also evaluate LSGANs on four datasets using the quan-
titative evaluation metric of Fr´echet inception distance
(FID), and the results show that LSGANs with the derived
objective function outperform NS-GANs on four datasets
and outperform WGANs-GP on three datasets. Further-
more, LSGANs spend a quarter of the time comparing
with WGANs-GP to reach a similar relatively optimal FID
on LSUN-bedroom.

• A new evaluation method for the training stability is
proposed. We propose to use datasets with small variabil-
ity to evaluate the stability of GANs. Furthermore, two
synthetic digit datasets with small variability are created
and published.

• We evaluate the training stability of LSGANs with-
out gradient penalty through three experiments including

(a)

(b)

Fig. 2. (a): The non-saturating loss and the minimax loss. (b): The least
squares loss.

boundary even though they are on the correct side. As Fig. 1(c)
shows, the least squares loss will penalize the above two types of
fake samples and pull them toward the decision boundary. Based
on this property, LSGANs are able to generate samples that are
closer to real data.

Another beneﬁt of LSGANs is the improved training stability.
Generally speaking, training GANs is a difﬁcult issue in practice
because of the instability of GANs learning [13], [14]. Recently,
several papers have pointed out that the instability of GANs
learning is partially caused by the objective function [14], [15],
[16]. Speciﬁcally, minimizing the objective function of regular
GANs may cause the problem of vanishing gradients, which
makes it hard to update the generator. LSGANs can alleviate this
problem because penalizing samples based on the distances to
the decision boundary can generate more gradients when updating
the generator. Moreover, we theoretically show that the training
instability of regular GANs is due to the mode-seeking behavior
[17] of the objective function, while LSGANs exhibit less mode-
seeking behavior.

In this paper, we also propose a new method for evaluating
the stability of GANs. One popular evaluation method is to use
difﬁcult architectures, e.g., by excluding the batch normalization
[15]. However,
the stable
architectures for their tasks. Sometimes the difﬁculty is from the
datasets. Motivated by this, we propose to use difﬁcult datasets but
stable architectures to evaluate the stability of GANs. Speciﬁcally,
we create two synthetic digit datasets with small variability by

in practice, one will always select

Gaussian mixture distribution, difﬁcult architectures, and
datasets with small variability. The experimental results
demonstrate that LSGANs perform more stably than NS-
GANs.

• We also evaluate the training stability of LSGANs-GP
through training on six difﬁcult architectures used in
WGANs-GP. LSGANs-GP succeed in training for all the
six architectures including 101-layer ResNet.

This paper extends our earlier conference work [20] in a
number of ways. First, we present more theoretical analysis about
the properties of LSGANs and χ2 divergence. Second, we conduct
a new quantitative experiment based on the FID evaluation metric,
and the results demonstrate that LSGANs perform better than NS-
GANs and WGANs-GP. The results also show that the derived
objective function (Eq. (13)) that yields minimizing the Pearson
χ2 divergence performs better than the classical one (Eq. (14))
of using least squares for classiﬁcation. Eq. (14) is used in our
earlier conference work, but we change to use Eq. (13) in this
paper. Third, we provide new qualitative results on a cat dataset,
which also shows that LSGANs generate higher quality images
than NS-GANs. Fourth, we propose a new method for evaluating
the training stability. In addition to using difﬁcult architectures
[15], we propose to use difﬁcult datasets but stable architectures to
evaluate the training stability. Fifth, we present a new comparison
experiment between LSGANs-GP and WGANs-GP. The results
show that LSGANs-GP succeed in training for all the difﬁcult
architectures used in [19], including 101-layer ResNet. Finally, we
present a new comparison experiment between the two parameter
schemes (Eq. (13) and (14)) of LSGANs.

2 RELATED WORK
Deep generative models attempt to capture the probability dis-
tributions over the given data. Restricted Boltzmann Machines
(RBMs), one type of deep generative models, are the basis of
many other hierarchical models, and they have been used to
model the distributions of images [21] and documents [22]. Deep
Belief Networks (DBNs) [23] and Deep Boltzmann Machines
(DBMs) [5] are extended from the RBMs. The most successful
application of DBNs is for image classiﬁcation [23], where DBNs
are used to extract feature representations. However, RBMs,
DBNs, and DBMs all have the difﬁculties of intractable partition
functions or intractable posterior distributions, which thus use the
approximation methods to learn the models. Another important
deep generative model is Variational Autoencoders (VAE) [6],
a directed model, which can be trained with gradient-based op-
timization methods. But VAEs are trained by maximizing the
variational lower bound, which may lead to the blurry problem
of generated images [8].

Recently, Generative Adversarial Networks (GANs) have been
proposed by Goodfellow et al.
[7], who explained the theory
of GANs learning based on a game theoretic scenario. A similar
idea is also introduced by Ganin et al.
[24], where a method of
adversarial training is proposed for domain adaptation. Showing
the powerful capability for unsupervised tasks, GANs have been
applied to many speciﬁc tasks, like image super-resolution [11],
text to image synthesis [25], and image to image translation [26].
By combining the traditional content loss and the adversarial loss,
super-resolution generative adversarial networks [11] achieved
state-of-the-art performance for the task of image super-resolution.
Reed et al. [25] proposed a model to synthesize images given text

3

descriptions based on the conditional GANs [27]. Isola et al. [26]
also used the conditional GANs to transfer images from one rep-
resentation to another. In addition to unsupervised learning tasks,
GANs also show the good potential for semi-supervised learning
tasks. Salimans et al.
[12] proposed a GAN-based framework
for semi-supervised learning, in which the discriminator not only
outputs the probability that an input image is from real data, but
also outputs the probabilities of belonging to each class. Another
important problem of GANs is to inference the latent vectors from
given examples [28], [29], [30]. Both [28] and [29] proposed a
bidirectional adversarial learning framework by incorporating an
encoder into the GANs framework. Li et al. [30] proposed to use
the conditional entropy to regularize the objectives in [28], [29],
making the learning process more stable.

Despite the great successes GANs have achieved, improving
the quality of generated images is still a challenge. A lot of works
have been proposed to improve the quality of images for GANs.
Radford et al. [13] ﬁrst introduced convolutional layers to GANs
architecture, and proposed a network architecture called deep
convolutional generative adversarial networks (DCGANs). Denton
et al.
[31] proposed a framework called Laplacian pyramid of
generative adversarial networks to improve the image quality of
high-resolution images, where a Laplacian pyramid is constructed
to generate high-resolution images starting from low-resolution
images. A similar approach is proposed by Huang et al.
[32]
who used a series of stacked GANs to generate images from
abstract to speciﬁc. Salimans et al.
[12] proposed a technique
called feature matching to get better convergence. The idea is to
make the generated samples match the statistics of real data by
minimizing the mean square error on an intermediate layer of the
discriminator.

Another critical issue for GANs is the stability of the learning
process. Many works have been proposed to address this problem
[14], [15], [16],
by analyzing the objective functions of GANs
[33], [34]. Viewing the discriminator as an energy function, Zhao
et al.
[35] used an auto-encoder architecture to improve the
stability of GANs learning. Dai et al.
[36] extended the energy-
based GANs by adding some regularizations to make the discrimi-
nator non-degenerate. To make the generator and the discriminator
more balanced, Metz et al.
[14] created an unrolled objective
function to enhance the generator. Che et al. [33] incorporated a
reconstruction module and used the distance between real samples
and reconstructed samples as a regularizer to get more stable
gradients. Nowozin et al.
[34] pointed out that the objective of
regular GAN [7] which is related to Jensen-Shannon divergence
is a special case of divergence estimation, and generalized it
to arbitrary f-divergences [37]. Arjovsky et al.
[15] extended
this by analyzing the properties of four different divergences
and concluded that Wasserstein distance is more stable than
Jensen-Shannon divergence. Qi
[16] proposed the loss-sensitive
GAN whose loss function is based on the assumption that real
samples should have smaller losses than fake samples. They also
introduced to use Lipschitz regularity to stabilize the learning
process. Base on the above assumptions, they proved that loss-
sensitive GAN has non-vanishing gradient almost everywhere.
Some other techniques to stabilize GANs learning include the
second order method [38] and gradient penalty [18], [19], [39].
Mescheder et al.
[38] analyzed the convergence property of
GANs from the perspective of the eigenvalues of the equilibrium
and proposed a method to regularize the eigenvalues, which in
turn leads to better training stability. Gulrajani et al.
[19] used

gradient penalty to enforce the Lipschitz constraint in Wasserstein
distance. They showed that this approach performs more stably
than the method used in [15]. Unlike [19] that applies gradient
penalty around the region between the real data and the fake data,
Kodali et al.
[18] proposed to apply gradient penalty around
the real data manifold only, which has the advantage that it is
applicable to various GANs. Roth et al.
[39] derived a new
gradient-based regularization from analyzing that adding noise to
the discriminator yields training with gradient penalty.

3 METHOD

3.1 Generative Adversarial Networks

The learning process of GANs is to train a discriminator D and
a generator G simultaneously. The target of G is to learn the
distribution pg over data x. G starts with sampling input variables
z from a uniform or Gaussian distribution pz(z), then maps the
input variables z to data space G(z; θg) through a differentiable
network. On the other hand, D is a classiﬁer D(x; θd) that aims
to recognize whether an image is from training data or from G.
The minimax objective for GANs can be formulated as follows:

min
G

max
D

VGAN(D, G) = Ex∼pdata(x)[log D(x)]
+Ez∼pz(z)[log(1 − D(G(z)))].

(1)

In practice, Goodfellow et al.
[7] recommend implementing the
following non-saturating loss for the generator, which provides
much stronger gradients.

min
G

VGAN(G) = −Ez∼pz(z)[log(D(G(z)))].

(2)

Following [40], we refer to Eq. (1) as minimax GANs (M-GANs)
and Eq. (2) as non-saturating GANs (NS-GANs). In the following
experiments, we compare our proposed LSGANs with NS-GANs
since NS-GANs perform much better than M-GANs [7], [40].

3.2 Least Squares Generative Adversarial Networks

As stated in Section 1, the original GAN paper
[7] adopted the
sigmoid cross entropy loss function for the discriminator, and
introduced the minimax loss and the non-saturating loss for the
generator. However, both the minimax loss and the non-saturating
loss will cause the problem of vanishing gradients for some fake
samples that are far from real data, as shown in Fig. 1(b). To
remedy this problem, we propose the Least Squares Generative
Adversarial Networks (LSGANs). Suppose we use the a-b coding
scheme for the discriminator, where a and b are the labels for
the fake data and the real data, respectively. Then the objective
functions for LSGANs can be deﬁned as follows:

min
D

VLSGAN(D) =

Ex∼pdata(x)

(cid:2)(D(x) − b)2(cid:3)

+

Ez∼pz(z)

(cid:2)(D(G(z)) − a)2(cid:3)

(3)

min
G

VLSGAN(G) =

Ez∼pz(z)

(cid:2)(D(G(z)) − c)2(cid:3),

1
2
1
2
1
2

4

3.2.1 Beneﬁts of LSGANs
The beneﬁts of LSGANs can be derived from two aspects. First,
unlike M-GANs and NS-GANs which cause almost no gradient
for some kinds of fake samples, LSGANs will penalize those
samples even though they are correctly classiﬁed, as shown in
Fig. 1(c). When we update the generator, the parameters of the
discriminator are ﬁxed, i.e., the decision boundary is ﬁxed. As
a result, the penalization will cause the generator to generate
samples toward the decision boundary. On the other hand, the
decision boundary should go across the manifold of real data for a
successful GANs learning; otherwise, the learning process will be
saturated. Thus moving the generated samples toward the decision
boundary leads to making them closer to the manifold of real data.
Second, penalizing the samples lying in a long way to the
decision boundary can generate more gradients when updating
the generator, which in turn relieves the problem of vanishing
gradients. This allows LSGANs to perform more stably during the
learning process. This beneﬁt can also be derived from another
perspective: as shown in Fig. 2, the least squares loss function is
ﬂat only at one point, while NS-GANs will saturate when x is
relatively large, and M-GANs will saturate when x is relatively
small. In Section 3.3.2, we provide further theoretical analysis
about the stability of LSGANs.

3.3 Theoretical Analysis
3.3.1 Relation to χ2 Divergence
In the original GAN paper [7], the authors have shown that mini-
mizing Eq. (1) yields minimizing the Jensen-Shannon divergence:

C(G) = KL

pdata

(cid:18)

(cid:13)
(cid:13)
(cid:13)
(cid:13)

pdata + pg
2

(cid:19)

(cid:18)

+ KL

pg

(cid:13)
(cid:13)
(cid:13)
(cid:13)

pdata + pg
2

(cid:19)

− log(4). (4)

Here we also explore the relation between LSGANs and f-

min
D

VLSGAN(D) =

Ex∼pdata(x)

(cid:2)(D(x) − b)2(cid:3)

divergence. Consider the following extension of Eq. (3):
1
2
1
2
1
2
1
2

(cid:2)(D(x) − c)2(cid:3)

(cid:2)(D(G(z)) − a)2(cid:3)

(cid:2)(D(G(z)) − c)2(cid:3).

Ex∼pdata(x)

VLSGAN(G) =

Ez∼pz(z)

Ez∼pz(z)

min
G

+

+

Note that adding the term Ex∼pdata(x)[(D(x) − c)2]
to
VLSGAN(G) causes no change of the optimal values since this term
does not contain parameters of G.

We ﬁrst derive the optimal discriminator D for a ﬁxed G.

Proposition 1. For a ﬁxed G, the optimal discriminator D is

D∗(x) =

bpdata(x) + apg(x)
pdata(x) + pg(x)

.

Proof. Given any generator G, we try to minimize V (D) with
respect to the discriminator D:

V (D) =

Ex∼pdata

Ez∼pz

(cid:2)(D(G(z)) − a)2(cid:3)

(cid:2)(D(x) − b)2(cid:3) +

1
2
1
2
(cid:0)pdata(x)(D(x) − b)2 + pg(x)(D(x) − a)2(cid:1)dx.

(cid:2)(D(x) − b)2(cid:3) +

(cid:2)(D(x) − a)2(cid:3)

Ex∼pg

Ex∼pdata
1
2

X

(5)

(6)

(7)

(8)

1
2
1
2
(cid:90)

=

=

1
2

where c denotes the value that G wants D to believe for the fake
data.

(cid:0)pdata(x)(D(x) − b)2 + pg(x)(D(x) − a)2(cid:1).

Consider the internal function:

5

(a) Generated images (64 × 64) by NS-GANs (reported in [13]).

(b) Generated images (112 × 112) by NS-GANs.

(c) Generated images (112 × 112) by LSGANs.

Fig. 3. Generated images on LSUN-bedroom.

It achieves the mimimum at bpdata(x)+apg(x)
concluding the proof.

pdata(x)+pg(x) with respect to D(x),

In the following equations we use pd to denote pdata for

simplicity.

Theorem 1. Optimizing LSGANs yields minimizing the Pearson
χ2 divergence between pd + pg and 2pg, if a, b, and c satisfy the
conditions of b − c = 1 and b − a = 2 in Eq. (5).

Proof. We can reformulate VLSGAN(G) in Eq. (5) by using Propo-
sition 1:

2C(G) = Ex∼pd
= Ex∼pd

(cid:2)(D∗(G(z)) − c)2(cid:3)
(cid:2)(D∗(x) − c)2(cid:3)
(cid:21)

(cid:2)(D∗(x) − c)2(cid:3) + Ez∼pz
(cid:2)(D∗(x) − c)2(cid:3) + Ex∼pg
(cid:20)
(cid:0) bpd(x) + apg(x)
− c(cid:1)2
pd(x) + pg(x)
(cid:0) bpd(x) + apg(x)
pd(x) + pg(x)

− c(cid:1)2

(cid:20)

(cid:21)

(9)

pd(x)(cid:0) (b − c)pd(x) + (a − c)pg(x)

(cid:1)2dx

pd(x) + pg(x)

pg(x)(cid:0) (b − c)pd(x) + (a − c)pg(x)
(cid:0)(b − c)pd(x) + (a − c)pg(x)(cid:1)2
pd(x) + pg(x)

pd(x) + pg(x)

dx

(cid:1)2dx

(cid:0)(b − c)(pd(x) + pg(x)) − (b − a)pg(x)(cid:1)2
pd(x) + pg(x)

dx.

= Ex∼pd

+ Ex∼pg
(cid:90)

=

+

=

=

X

(cid:90)

X
(cid:90)

X

(cid:90)

X

If we set b − c = 1 and b − a = 2, then

2C(G) =

(cid:90)

(cid:0)2pg(x) − (pd(x) + pg(x))(cid:1)2
pd(x) + pg(x)

dx

X
= χ2
Pearson(pd + pg(cid:107)2pg),

(10)

Pearson is the Pearson χ2 divergence. Thus minimizing Eq.
where χ2
(5) yields minimizing the Pearson χ2 divergence between pd + pg
and 2pg if a, b, and c satisfy the conditions of b − c = 1 and
b − a = 2.

3.3.2 Properties of χ2 Divergence
As Eq. (4) shows, the original GAN has been proven to optimize
the JS divergence. Furthermore, Husz´ar [41] pointed out that Eq.
(4) can be viewed as an interpolation between KL(pg(cid:107)pd) and
KL(pd(cid:107)pg):

JSπ(pd(cid:107)pg) = (1 − π)KL(pd(cid:107)πpd + (1 − π)pg)

+ πKL(pg(cid:107)πpd + (1 − π)pg),

(11)

where Eq. (4) corresponds to π = 0.5. They also found that
optimizing Eq. (4) tends to perform similarly to KL(pg(cid:107)pd).
KL(pg(cid:107)pd) is widely used in variational inference due to the
convenient evidence lower bound
[17]. However, optimizing
KL(pg(cid:107)pd) has the problem of mode-seeking behavior or under-
dispersed approximations
[17], [41], [42]. This problem also
appears in GANs learning, which is known as the mode collapse
problem. The deﬁnition of KL(pg(cid:107)pd) is given below:

6

(a) Church outdoor.

(b) Dining room.

Fig. 4. Generated images on different scene datasets.

(c) Kitchen.

(d) Conference room.

KL(pg(cid:107)pd) = −

pg(x) ln

dx.

(12)

(cid:90)

X

(cid:19)

(cid:18) pd(x)
pg(x)

The mode-seeking behavior of KL(pg(cid:107)pd) can be understood by
noting that pg will be close to zero where pd is near zero, because
KL(pg(cid:107)pd) will be inﬁnite if pd = 0 and pg > 0. This is called
the zero-forcing property [17].

Recently, χ2 divergence has drawn researchers’ attention in
variational inference since χ2 divergence is able to produce over-
dispersed approximations [42]. For the objective function in Eq.
(10), it will become inﬁnite if pd +pg = 0 and pg −pd > 0, which
will not happen since pg ≥ 0 and pd ≥ 0. Thus χ2
Pearson(pd +
pg(cid:107)2pg) has no zero-forcing property. This makes LSGANs less
mode-seeking and alleviates the mode collapse problem.

3.4 Parameters Selection

One method to determine the values of a, b, and c in Eq. (3) is
to satisfy the conditions of b − c = 1 and b − a = 2, such that
minimizing Eq. (3) yields minimizing the Pearson χ2 divergence
between pd +pg and 2pg. For example, by setting a = −1, b = 1,
and c = 0, we get the following objective functions:

min
D

VLSGAN(D) =

Ex∼pdata(x)

(cid:2)(D(x) − 1)2(cid:3)

+

Ez∼pz(z)

(cid:2)(D(G(z)) + 1)2(cid:3)

(13)

min
G

VLSGAN(G) =

Ez∼pz(z)

(cid:2)(D(G(z)))2(cid:3).

1
2
1
2
1
2

using least squares for classiﬁcation. For example, by using the 0-
1 binary coding scheme, we get the following objective functions:

1
2
1
2
1
2

min
D

VLSGAN(D) =

Ex∼pdata(x)

(cid:2)(D(x) − 1)2(cid:3)

+

Ez∼pz(z)

(cid:2)(D(G(z)))2(cid:3)

(14)

min
G

VLSGAN(G) =

Ez∼pz(z)

(cid:2)(D(G(z)) − 1)2(cid:3).

In practice, we ﬁnd that Eq. (13) shows better FID results
and faster convergence speed than Eq. (14), as demonstrated
by experiments. For the experiments presented in our earlier
conference work [20], we adopted Eq. (14), but for the newly
introduced experiments in this paper, Eq. (13) is adopted.

4 EXPERIMENTS

In this section, we ﬁrst present some details of our implementation.
Next, we present the results of the qualitative evaluation and
quantitative evaluation of LSGANs. Then we evaluate the stability
of LSGANs in two groups. One is to compare LSGANs with
DCGANs without gradient penalty by three experiments. The
other one is to compare LSGANs-GP with WGANs-GP. Note
that we implement DCGANs using the non-saturating loss (NS-
GANs). In the following experiments, we denote NS-GANs as the
baseline method.

4.1 Implementation Details

The implementation of our proposed models is based on a public
implementation of DCGANs1 using TensorFlow [43]. The learn-
ing rate is set to 0.0002 except for LSUN-scenes whose learning
rate is set to 0.001. The mini-batch size is set to 64, and the
variables are initialized from a Gaussian distribution with a mean

Another method is to make G generate samples as real as
possible by setting c = b, corresponding to the traditional way of

1 https://github.com/carpedm20/DCGAN-tensorﬂow

7

(a) Generated cats (128 × 128) by NS-GANs.

(b) Generated cats (128 × 128) by LSGANs.

(c) NS-GANs

(d) LSGANs

(e) Real Sample

Fig. 5. Generated images on cat datasets. (c)(d)(e): Comparison by zooming in on the details of the images. LSGANs generate cats with sharper
and more exquisite hair and faces than the ones generated by NS-GANs.

of zero and a standard deviation of 0.02. Following DCGANs,
β1 for Adam optimizer is set to 0.5. The pixel values of all
the images are scaled to [-1,1], since we use the Tanh in the
generator to produce images. Our implementation is available at
https://github.com/xudonmao/improved LSGAN.

TABLE 1
The network architecture for scene generation, where CONV denotes
the convolutional layer, TCONV denotes the transposed convolutional
layer, FC denotes the fully-connected layer, BN denotes the batch
normalization, LReLU denotes the Leaky-ReLU, and (K3,S2,O256)
denotes a layer with 3 × 3 kernel, stride 2, and 256 output ﬁlters.

4.2 Image Quality

4.2.1 Qualitative Evaluation

Scenes Generation We train LSGANs and NS-GANs using the
same network architecture on the LSUN-bedroom dataset. The
network architecture is presented in Table 1. All the images are
resized to the resolution of 112 × 112. The generated images by
the two models are presented in Fig. 3. Compared with the images
generated by NS-GANs, the texture details (e.g., the textures of
beds) of the images generated by LSGANs are more exquisite,
and the images generated by LSGANs look sharper. We also train
LSGANs on four other scene datasets including church, dining
room, kitchen, and conference room. The generated results are
shown in Fig. 4.
Cats Generation We further evaluate LSGANs on a cat dataset
[44]. We ﬁrst use the preprocess methods in a public project2 to

2 https://github.com/AlexiaJM/Deep-learning-with-cats

Generator
Input z
FC(O12544), BN, ReLU
TCONV(K3,S2,O256), BN, ReLU
TCONV(K3,S1,O256), BN, ReLU
TCONV(K3,S2,O256), BN, ReLU
TCONV(K3,S1,O256), BN, ReLU
TCONV(K3,S2,O128), BN, ReLU
TCONV(K3,S2,O64), BN, ReLU
TCONV(K3,S1,O3), Tanh

Discriminator
Input 112 × 112 × 3
CONV(K5,S2,O64), LReLU
CONV(K5,S2,O128), BN, LReLU
CONV(K5,S2,O256), BN, LReLU
CONV(K5,S2,O512), BN, LReLU
FC(O1)
Loss

get cat head images whose resolution is larger than 128 × 128,
and then resize all the images to the resolution of 128 × 128.
The network architecture used in this task is presented in Table 2.
We use the following evaluation protocol for comparing the
performance between LSGANs and NS-GANs. First, we train
LSGANs and NS-GANs using the same architecture on the cat
dataset. During training, we save a checkpoint of the model
and a batch of generated images every 1000 iterations. Sec-

8

(a) Interpolation on the LSUN-bedroom dataset.

Fig. 6.
representations in the latent space.

Interpolation result by LSGANs. The generated images show smooth transitions, which indicates that LSGANs have learned semantic

(b) Interpolation on the cats dataset.

TABLE 2
The network architecture for cats generation. The meanings of the
symbols can be found in Table 1.

TABLE 3
FID results of NS-GANs, WGANs-GP, and LSGANs on four datasets.
LSGANs(−110) and LSGANs(011) refer to Eq. (13) and Eq. (14),
respectively.

Generator
Input z
FC(O32768), BN, ReLU
TCONV(K3,S2,O256), BN, ReLU
TCONV(K3,S2,O128), BN, ReLU
TCONV(K3,S2,O64), BN, ReLU
TCONV(K3,S2,O3), Tanh

Discriminator
Input 128 × 128 × 3
CONV(K5,S2,O64), LReLU
CONV(K5,S2,O128), BN, LReLU
CONV(K5,S2,O256), BN, LReLU
CONV(K5,S2,O512), BN, LReLU
FC(O1)
Loss

Method
NS-GANs
WGANs-GP
LSGANs(011)
LSGANs(−110)

LSUN
28.04
22.77
27.21
21.55

Cat
15.81
29.03
15.46
14.28

ImageNet CIFAR10
74.15
62.05
72.54
68.95

35.25
40.83
36.46
35.19

ond, we select the best models of LSGANs and NS-GANs by
checking the quality of saved images in every 1000 iterations.
Finally, we use the selected best models to randomly gener-
ate cat images and compare the quality of generated images.
The selected models of LSGANs and NS-GANs are available
at https://github.com/xudonmao/improved LSGAN. Fig. 5 shows
the generated cat images of LSGANs and NS-GANs. We observe
that LSGANs generate cats with sharper and more exquisite hair
than the ones generated by NS-GANs. Fig. 5(c)(d) shows the
details of the cat hair by zooming in the generated images. We
observe that the cat hair generated by NS-GANs contains more
artiﬁcial noise. By checking more generated samples using the
above saved models, we also observe that the overall quality of
generated images by LSGANs is better than NS-GANs.
Walking in the Latent Space We also present the interpolation
results in Fig. 6. The result of walking in the latent space is a
sign of whether a model is just memorizing the training dataset.
We ﬁrst randomly sample two points of the noise vector z, and
then interpolate the vector values between the two sampled points.
The images in Fig. 6 show smooth transitions, which indicates
that LSGANs have learned semantic representations in the latent
space.

4.2.2 Quantitative Evaluation
For the quantitative evaluation of LSGANs, we adopt Fr´echet
Inception Distance (FID)
[45] as the evaluation metric. FID
measures the distance between the generated images and the
real images by approximating the feature space of the inception

(a)

(b)

Fig. 7.
(a): Comparison of FID on LSUN between NS-GANs and
LSGANs during the learning process, which is aligned with iterations.
(b): Comparison of FID on LSUN between WGANs-GP and LSGANs
during the learning process, which is aligned with wall-clock time.

model as a multidimensional Gaussian distribution, which has
been proved to be more consistent with human judgment than
inception score [12]. Smaller FID values mean closer distances
between the generated and real images. We also conduct a human
subjective study on the LSUN-bedroom dataset.
Fr´echet Inception Distance For FID, we evaluate the perfor-
mances of LSGANs, NS-GANs, and WGANs-GP on several
datasets including LSUN-bedroom, the cat dataset, ImageNet, and
CIFAR-10. We also compare the performances of Eq. (13) (de-
noted as LSGANs(−110)) and Eq. (14) (denoted as LSGANs(011)).
For a fair comparison, all the models are trained with the same
architecture proposed in DCGAN [13] (i.e., four convolutional
layers for both the discriminator and the generator), and the
dimension of the noise input is set to 100. For WGANs-GP, we

9

Fig. 8. Dynamic results of Gaussian kernel estimation for NS-GANs and LSGANs. The ﬁnal column shows the distribution of real data.

adopt the ofﬁcial implementation for evaluation. The resolutions
for LSUN, Cat, ImageNet, and CIFAR-10 are 64 × 64, 128 × 128,
64 × 64, and 32 × 32, respectively. We randomly generate 50, 000
images every 4k iterations for each model and then compute
FID. The results are shown in Table 3, and we have the fol-
lowing four observations. First, LSGANs(−110) outperform NS-
GANs for all the four datasets. Second, comparing with WGANs-
GP, LSGANs(−110) perform better for three datasets, especially
for the cat dataset. Third, LSGANs(−110) perform better than
LSGANs(011) for all the four datasets. Fourth, the performance
of LSGANs(011) is comparable to NS-GANs.

We also show the FID plot of the learning process in Fig.
7, where LSGANs refer to LSGANs(−110). Following [45], the
plots of NS-GANs and LSGANs are aligned by iterations, and
the plots of WGANs-GP and LSGANs are aligned by wall-clock
time. As Fig. 7(a) shows, NS-GANs and LSGANs show similar
FID at the ﬁrst 25k iterations, but LSGANs can decrease FID after
25k iterations, achieving better performance eventually. Fig. 7(b)
shows that WGANs-GP and LSGANs achieve similar optimal FID
eventually, but LSGANs spend much less time (1, 100 minutes)
than WGANs-GP (4, 600 minutes) to reach a relatively optimal
FID around 22. This is due to that WGANs-GP need multiple
updates for the discriminator and need additional computational
time for the gradient penalty.

Human Subjective Study To further evaluate the performance of
LSGANs, we conduct a human subjective study using the gener-
ated bedroom images (112 × 112) from NS-GANs and LSGANs
with the same network architecture. We randomly construct image
pairs, where one image is from NS-GANs and the other one is
from LSGANs. We ask Amazon Mechanical Turk annotators to
judge which image looks more realistic. With 4,000 votes totally,
NS-GANs get 43.6% votes and LSGANs get 56.4% votes, i.e., an
overall 12.8% increase of votes over NS-GANs.

4.3 Training Stability

In this section, we evaluate the stability of our proposed LS-
GANs and compare with two baselines including NS-GANs and
WGANs-GP. Gradient penalty has been proven to be effective for
improving the stability of GANs training [18], [19], but it also has
some inevitable disadvantages such as additional computational
cost and memory cost. Thus we evaluate the stability of LSGANs
in two groups. One is to compare with the model without gradient
penalty (i.e., NS-GANs), and the other one is to compare with the
model with gradient penalty (i.e., WGANs-GP).

TABLE 4
Experiments on Gaussian mixture distribution. We run 100 times for
each model and record how many times that a model ever generates
samples around one or two modes during the training process.

Method

NS-GANs

LSGANs (ours)

The number of generating samples

around one or two modes

99 / 100
5 / 100

4.3.1 Evaluation without Gradient Penalty
We ﬁrst compare LSGANs with NS-GANs, both of which are
without gradient penalty. Three comparison experiments are con-
ducted: 1) learning on a Gaussian mixture distribution; 2) learning
with difﬁcult architectures; and 3) learning on datasets with small
variability.
Gaussian Mixture Distribution Learning on a Gaussian mix-
ture distribution to evaluate the stability is proposed by Metz
et al. [14]. If the model suffers from the mode collapse problem,
it will generate samples only around one or two modes. We train
NS-GANs and LSGANs with the same network architecture on
a 2D mixture of eight Gaussian mixture distribution, where both
the generator and the discriminator contain three fully-connected
layers. Fig. 8 shows the dynamic results of Gaussian kernel density
estimation. We can see that NS-GANs suffer from mode collapse
starting at 15k iterations. They only generate samples around
a single valid mode of the data distribution. But LSGANs can
learn the Gaussian mixture distribution successfully. We also try
different architectures (four or ﬁve fully-connected layers) and
different values of the hyper-parameters (the learning rate and the
dimension of the noise vector). The results also show that NS-
GANs tend to generate samples around one or two modes, while
LSGANs are less prone to this problem.

To further verify the robustness of the above observation,
we run 100 times for each model and record how many times
that a model suffers from the mode collapse problem. For each
experiment, we save the density estimation every 5k iterations and
observe whether a model generates samples only around one or
two modes in each saved estimation. The results show that NS-
GANs appear to generate one or two modes 99 times out of 100,
while LSGANs only have 5 times, as shown in Table 4.
Difﬁcult Architectures Another experiment is to train GANs
[15]. The
with difﬁcult architectures, which is proposed in
model will generate very similar images if it suffers from mode

NS-GANs

LSGANs

NS-GANs

LSGANs

10

(a) No BN in G using Adam.

(b) No BN in either G or D using RMSProp.

(c) No BN in G using RMSProp.

(d) No BN in either G or D using Adam.

Fig. 9. Comparison experiments between NS-GANs and LSGANs by excluding batch normalization (BN).

Real Samples

NS-GANs

LSGANs

(a) Training on MNIST.

(b) Training on a synthetic digit dataset with random horizontal shift.

(c) Training on a synthetic digit dataset with random horizontal shift and rotation.

Fig. 10. Evaluation on datasets with small variability. All the tasks are conducted using the same network architecture as shown in Table 5. DCGANs
succeed in learning on MNIST but fail on the two synthetic digit datasets with small variability, while LSGANs succeed in learning on all the three
datasets.

collapse problem. The network architecture used in this task is
similar to the one in Table 2 except for the image resolution.
Based on this network architecture, two architectures are designed
to compare the stability. The ﬁrst one is to exclude the batch
normalization in the generator (BNG for short), and the second
one is to exclude the batch normalization in both the generator
and discriminator (BNGD for short). As pointed out in [15], the
selection of optimizer is critical to the model performance. Thus
we evaluate the two architectures with two optimizers, Adam [46]
and RMSProp [47]. In summary, we have the following four
training settings: (1) BNG with Adam, (2) BNG with RMSProp,
(3) BNGD with Adam, and (4) BNGD with RMSProp. We train
the above models on the LSUN-bedroom dataset using NS-GANs
and LSGANs separately. The results are shown in Fig. 9, and
we make the following three major observations. First, for BNG
with Adam, there is a chance for LSGANs to generate relatively
good quality images. We test 10 times, and 5 of those succeed to
generate relatively good quality images. For NS-GANs, however,
we never observe successful learning, suffering from a severe
degree of mode collapse. Second, for BNGD with RMSProp,
as Fig. 9 shows, LSGANs generate higher quality images than
NS-GANs which have a slight degree of mode collapse. Third,
LSGANs and NS-GANs have similar performance for BNG with
RMSProp and BNGD with Adam. Speciﬁcally, for BNG with
RMSProp, both LSGANs and NS-GANs can generate relatively

TABLE 5
The network architecture for stability evaluation on datasets with small
variability. The meanings of the symbols can be found in Table 1.

Generator
Input z
FC(O8192), BN, ReLU
TCONV(K3,S2,O256), BN, ReLU
TCONV(K3,S2,O128), BN, ReLU
TCONV(K3,S2,O1), Tanh

Discriminator
Input 28 × 28 × 1
CONV(K5,S2,O20), LReLU
CONV(K5,S2,O50), BN, LReLU
FC(O500), BN, LReLU
FC(O1)
Loss

good images. For BNGD with Adam, both have a slight degree of
mode collapse.
Datasets with small variability Using difﬁcult architectures is an
effective way to evaluate the stability of GANs [15]. However,
in practice, it is natural to select a stable architecture for a given
task. The difﬁculty of a practical task is the task itself. Inspired
by this motivation, we propose to use difﬁcult datasets but stable
architectures to evaluate the stability of GANs. We ﬁnd that the
datasets with small variability are difﬁcult for GANs to learn,
since the discriminator can distinguish the real samples very easily
for the datasets with small variability. Speciﬁcally, we construct
the datasets by rendering 28 × 28 digits using the Times-New-
Roman font. Two datasets are created3: 1) one is applied with

3 Available at https://github.com/xudonmao/improved LSGAN

WGANs-GP

LSGANs-GP

WGANs-GP

LSGANs-GP

11

(a) G: No BN and a constant number of ﬁlters, D: DCGAN.

(b) G: 4-layer 512-dim ReLU MLP, D: DCGAN.

(c) No normalization in either G or D.

(d) Gated multiplicative nonlinearities everywhere in G and D.

(e) Tanh nonlinearities everywhere in G and D.

(f) 101-layer ResNet G and D.

Fig. 11. Comparison experiments between WGANs-GP and LSGANs-GP using difﬁcult architectures, where the images generated by WGANs-GP
are duplicated from [19]. LSGANs-GP succeed for all the architectures.

Fig. 12. Dynamic results of the two parameter schemes on the SVHN dataset. The ﬁrst row corresponds to Eq. (13), and the second row corresponds
to Eq. (14).

random horizontal shift; and 2) the other one is applied with
random horizontal shift and random rotation from 0 to 10 degrees.
Each category contains one thousand samples for both datasets.
Note that the second dataset is with larger variability than the
ﬁrst one. Examples of the two synthetic datasets are shown in
the ﬁrst column of Fig. 10. We adopt a stable architecture for
digits generation, following the suggestions in [13], where the
discriminator is similar to LeNet, and the generator contains
three transposed convolutional layers. The detail of the network
architecture is presented in Table 5. We train NS-GANs and
LSGANs on the above two datasets, and the generated images
are shown in Fig. 10, along with the results on MNIST. We have
two major observations. First, NS-GANs succeed in learning on
MNIST but fail on the two synthetic digit datasets, while LSGANs
succeed in learning on all the three datasets. Second, LSGANs
generate higher quality images on the second dataset than the ﬁrst
one. This implies that increasing the variability of the dataset can
improve the generated image quality and relieve the mode collapse
problem. Based on this observation, applying data augmentation
such as shifting, cropping, and rotation is an effective way of
improving GANs learning.

4.3.2 Evaluation with Gradient Penalty

Gradient penalty has been proven to be effective in improving the
stability of GAN training [18], [19]. To compare with WGANs-
GP, which is the state-of-the-art GAN model in stability, we adopt
the gradient penalty in [18] for LSGANs and set the hyper-
parameters c and λ to 30 and 150, respectively. For this exper-
iment, our implementation is based on the ofﬁcial implementation
of WGANs-GP. We follow the evaluation method in WGANs-GP:
to train with six difﬁcult architectures including 1) no normal-
ization and a constant number of ﬁlters in the generator; 2) 4-
layer 512-dimension ReLU MLP generator; 3) no normalization
in either the generator or discriminator; 4) gated multiplicative
nonlinearities in both the generator and discriminator; 5) tanh
nonlinearities in both the generator and discriminator; and 6)
101-layer ResNet for both the generator and discriminator. The
results are presented in Fig. 11, where the generated images by
WGANs-GP are duplicated from [19]. We have the following
two major observations. First, like WGANs-GP, LSGANs-GP
also succeed in training for each architecture, including 101-layer
ResNet. Second, LSGANs-GP with 101-layer ResNet generate
higher quality images than the other ﬁve architectures.

4.4 Comparison of Two Parameter Schemes

As stated in Section 4.2.2, LSGANs(−110) perform better than
for the FID-based experiment. In this experi-
LSGANs(011)
ment, we show another comparison between the two param-
eter schemes. We train LSGANs(−110) and LSGANs(011) on
SVHN [48] dataset using the same network architecture. Fig.
12 shows the dynamic results of the two schemes. We can
observe that LSGANs(−110) shows faster convergence speed than
LSGANs(011). We also evaluate the two schemes on the LSUN-
bedroom and cat dataset, and similar results are observed.

4.5 Suggestions in Practice

Based on the above experiments, we have the following sugges-
tions in practice. First, we suggest using LSGANs(−110) without
gradient penalty if it works, because using gradient penalty will
introduce additional computational cost and memory cost. Second,
we observe that the quality of generated images by LSGANs may
shift between good and bad during the training process, which is
also indicated in Fig. 7. Thus we suggest to keep a record of gener-
ated images at every thousand or hundred iterations and select the
model manually by checking the image quality. Third, if LSGANs
without gradient penalty fail, we suggest using LSGANs-GP and
set the hyper-parameters according to the suggestions in literature
[18]. In our experiments, we ﬁnd that the hyper-parameter setting,
c = 30 and λ = 150, works for all the tasks.

5 CONCLUSIONS AND FUTURE WORK

In this paper, we have proposed the Least Squares Generative
Adversarial Networks (LSGANs) to overcome the vanishing gra-
dients problem during the learning process. The experimental
results show that LSGANs generate higher quality images than
regular GANs. Based on the quantitative experiments, we ﬁnd
that the derived objective function that yields minimizing the
Pearson χ2 divergence performs better than the classical one of
using least squares for classiﬁcation. We also conducted three
comparison experiments for evaluating the stability, and the re-
sults demonstrate that LSGANs perform more stably than regular
GANs. We further compare the stability between LSGANs-GP
and WGANs-GP, and LSGANs-GP show comparable stability to
WGANs-GP. For the future work, instead of pulling the generated
samples toward the decision boundary, designing a method to pull
the generated samples toward real data directly is worth further
investigation.

REFERENCES

[1] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in Computer Vision and Pattern Recognition (CVPR), 2016.
[2] S. Ren, K. He, R. Girshick, and J. Sun, “Faster r-cnn: Towards real-time
object detection with region proposal networks,” in Advances in Neural
Information Processing Systems 28, 2015, pp. 91–99.
J. Long, E. Shelhamer, and T. Darrell, “Fully convolutional networks
for semantic segmentation,” in Computer Vision and Pattern Recognition
(CVPR), 2015.

[3]

[4] G. Hinton and R. Salakhutdinov, “Reducing the dimensionality of data
with neural networks,” Science, vol. 313, no. 5786, pp. 504 – 507, 2006.
[5] R. Salakhutdinov and G. Hinton, “Deep Boltzmann machines,” in Pro-
ceedings of the International Conference on Artiﬁcial Intelligence and
Statistics, vol. 5, 2009, pp. 448–455.

[6] D. P. Kingma and M. Welling, “Auto-encoding variational bayes,” in
International Conference on Learning Representations (ICLR), 2014.

12

[7]

[8]

I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,
S. Ozair, A. Courville, and Y. Bengio, “Generative adversarial nets,” in
Advances in Neural Information Processing Systems (NIPS), 2014, pp.
2672–2680.
I. Goodfellow, Y. Bengio, and A. Courville, Deep Learning. MIT Press,
2016.

[9] A. Nguyen, J. Yosinski, Y. Bengio, A. Dosovitskiy, and J. Clune, “Plug
& play generative networks: Conditional iterative generation of images
in latent space,” arXiv:1612.00005, 2016.

[10] X. Chen, Y. Duan, R. Houthooft, J. Schulman, I. Sutskever, and
P. Abbeel, “Infogan: Interpretable representation learning by information
maximizing generative adversarial nets,” in Advances in Neural Informa-
tion Processing Systems (NIPS), 2016, pp. 2172–2180.

[11] C. Ledig, L. Theis, F. Huszar, J. Caballero, A. Cunningham, A. Acosta,
A. Aitken, A. Tejani, J. Totz, Z. Wang, and W. Shi, “Photo-Realistic Sin-
gle Image Super-Resolution Using a Generative Adversarial Network,”
arXiv:1609.04802, 2016.

[12] T. Salimans, I. Goodfellow, W. Zaremba, V. Cheung, A. Radford,
X. Chen, and X. Chen, “Improved techniques for training gans,” in
Advances in Neural Information Processing Systems (NIPS), 2016, pp.
2226–2234.

[13] A. Radford, L. Metz, and S. Chintala, “Unsupervised representation
learning with deep convolutional generative adversarial networks,” in
International Conference on Learning Representations (ICLR), 2015.
[14] L. Metz, B. Poole, D. Pfau, and J. Sohl-Dickstein, “Unrolled generative

adversarial networks,” arXiv:1611.02163, 2016.

[15] M. Arjovsky, S. Chintala,
arXiv:1701.07875, 2017.

and L. Bottou,

“Wasserstein gan,”

[16] G.-J. Qi, “Loss-sensitive generative adversarial networks on lipschitz

densities,” arXiv:1701.06264, 2017.

[17] C. M. Bishop, Pattern Recognition and Machine Learning, 2006.
[18] N. Kodali, J. Abernethy, J. Hays, and Z. Kira, “On convergence and

stability of gans,” arXiv:1705.07215, 2017.

[19] I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. Courville,
“Improved training of wasserstein gans,” in Advances in Neural Informa-
tion Processing Systems (NIPS), 2017.

[20] X. Mao, Q. Li, H. Xie, R. Y. Lau, Z. Wang, and S. P. Smolley, “Least
squares generative adversarial networks,” in International Conference on
Computer Vision (ICCV), 2017.

[21] G. W. Taylor, R. Fergus, Y. LeCun, and C. Bregler, “Convolutional learn-
ing of spatio-temporal features,” in European Conference on Computer
Vision (ECCV), 2010, pp. 140–153.

[22] G. E. Hinton and R. R. Salakhutdinov, “Replicated softmax: an undi-
rected topic model,” in Advances in Neural Information Processing
Systems (NIPS), 2009, pp. 1607–1614.

[23] G. E. Hinton, S. Osindero, and Y.-W. Teh, “A fast learning algorithm for
deep belief nets,” Neural Computation, vol. 18, no. 7, pp. 1527–1554,
Jul. 2006.

[24] Y. Ganin, E. Ustinova, H. Ajakan, P. Germain, H. Larochelle, F. Lavio-
lette, M. Marchand, and V. Lempitsky, “Domain-adversarial training of
neural networks,” The Journal of Machine Learning Research, vol. 17,
no. 1, pp. 2096–2030, 2016.

[25] S. Reed, Z. Akata, X. Yan, L. Logeswaran, B. Schiele, and H. Lee,
“Generative adversarial text-to-image synthesis,” in Proceedings of The
33rd International Conference on Machine Learning (ICML), 2016.
[26] P. Isola, J.-Y. Zhu, T. Zhou, and A. A. Efros, “Image-to-image translation
with conditional adversarial networks,” arXiv:1611.07004, 2016.
[27] M. Mirza and S. Osindero, “Conditional Generative Adversarial Nets,”

arXiv:1411.1784, 2014.

[28] J. Donahue, P. Kr¨ahenb¨uhl, and T. Darrell, “Adversarial feature learning,”
in International Conference on Learning Representations (ICLR), 2017.
[29] V. Dumoulin, I. Belghazi, B. Poole, O. Mastropietro, A. Lamb, M. Ar-
jovsky, and A. Courville, “Adversarially learned inference,” in Interna-
tional Conference on Learning Representations (ICLR), 2017.

[30] C. Li, H. Liu, C. Chen, Y. Pu, L. Chen, R. Henao, and L. Carin, “Alice:
Towards understanding adversarial learning for joint distribution match-
ing,” in Advances in Neural Information Processing Systems (NIPS),
2017.

[31] E. Denton, S. Chintala, A. Szlam, and R. Fergus, “Deep generative image
models using a laplacian pyramid of adversarial networks,” in Advances
in Neural Information Processing Systems (NIPS), 2015, pp. 1486–1494.
[32] X. Huang, Y. Li, O. Poursaeed, J. Hopcroft, and S. Belongie, “Stacked

generative adversarial networks,” arXiv:1612.04357, 2016.

[33] T. Che, Y. Li, A. P. Jacob, Y. Bengio, and W. Li, “Mode regularized

generative adversarial networks,” arXiv:1612.02136, 2016.

13

[34] S. Nowozin, B. Cseke, and R. Tomioka, “f-gan: Training gen-
erative neural samplers using variational divergence minimization,”
arXiv:1606.00709, 2016.

[35] J. Zhao, M. Mathieu, and Y. LeCun, “Energy-based Generative Adver-

sarial Network,” arXiv:1609.03126, 2016.

[36] Z. Dai, A. Almahairi, P. Bachman, E. Hovy, and A. Courville, “Cali-
brating energy-based generative adversarial networks,” in International
Conference on Learning Representations (ICLR), 2017.

[37] X. Nguyen, M. J. Wainwright, and M. I. Jordan, “Estimating divergence
functionals and the likelihood ratio by convex risk minimization,” IEEE
Transactions on Information Theory, vol. 56, no. 11, pp. 5847–5861,
2010.

[38] L. Mescheder, S. Nowozin, and A. Geiger, “The numerics of gans,” in
Advances in Neural Information Processing Systems (NIPS), 2017.
[39] K. Roth, A. Lucchi, S. Nowozin, and T. Hofmann, “Stabilizing training
of generative adversarial networks through regularization,” in Advances
in Neural Information Processing Systems (NIPS), 2017.

[40] W. Fedus, M. Rosca, B. Lakshminarayanan, A. M. Dai, S. Mohamed, and
I. Goodfellow, “Many paths to equilibrium: Gans do not need to decrease
a divergence at every step,” in International Conference on Learning
Representations (ICLR), 2018.

[41] F. Husz´ar, “How (not) to train your generative model: Scheduled sam-

pling, likelihood, adversary?” arXiv:1511.05101, 2015.

[42] A. B. Dieng, D. Tran, R. Ranganath, J. Paisley, and D. M. Blei,
“Variational inference via χ upper bound minimization,” in Advances
in Neural Information Processing Systems (NIPS), 2017.

[43] M. Abadi, A. Agarwal, P. Barham, and et al, “TensorFlow: Large-scale

machine learning on heterogeneous systems,” 2015.

[44] W. Zhang, J. Sun, and X. Tang, “Cat head detection - how to effectively
exploit shape and texture features,” in European Conference on Computer
Vision (ECCV), 2008, pp. 802–816.

[45] M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, and S. Hochreiter,
“Gans trained by a two time-scale update rule converge to a local nash
equilibrium,” in Advances in Neural Information Processing Systems
(NIPS), 2017.

[46] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”

arXiv:1412.6980, 2014.

[47] T. Tieleman and G. Hinton, “Lecture 6.5—RMSProp: Divide the gradient
by a running average of its recent magnitude,” COURSERA: Neural
Networks for Machine Learning, 2012.

[48] Y. Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu, and A. Y. Ng,
“Reading digits in natural images with unsupervised feature learning,” in
NIPS Workshop on Deep Learning and Unsupervised Feature Learning,
2011.

8
1
0
2
 
p
e
S
 
1
2
 
 
]

V
C
.
s
c
[
 
 
2
v
1
9
3
6
0
.
2
1
7
1
:
v
i
X
r
a

1

On the Effectiveness of Least Squares
Generative Adversarial Networks

Xudong Mao, Qing Li, Senior Member, IEEE, Haoran Xie, Member, IEEE,
Raymond Y.K. Lau, Senior Member, IEEE, Zhen Wang, and Stephen Paul Smolley

Abstract—Unsupervised learning with generative adversarial networks (GANs) has proven to be hugely successful. Regular GANs
hypothesize the discriminator as a classiﬁer with the sigmoid cross entropy loss function. However, we found that this loss function may
lead to the vanishing gradients problem during the learning process. To overcome such a problem, we propose in this paper the Least
Squares Generative Adversarial Networks (LSGANs) which adopt the least squares loss for both the discriminator and the generator.
We show that minimizing the objective function of LSGAN yields minimizing the Pearson χ2 divergence. We also show that the derived
objective function that yields minimizing the Pearson χ2 divergence performs better than the classical one of using least squares for
classiﬁcation. There are two beneﬁts of LSGANs over regular GANs. First, LSGANs are able to generate higher quality images than
regular GANs. Second, LSGANs perform more stably during the learning process. For evaluating the image quality, we conduct both
qualitative and quantitative experiments, and the experimental results show that LSGANs can generate higher quality images than
regular GANs. Furthermore, we evaluate the stability of LSGANs in two groups. One is to compare between LSGANs and regular
GANs without gradient penalty. We conduct three experiments, including Gaussian mixture distribution, difﬁcult architectures, and a
newly proposed method — datasets with small variability, to illustrate the stability of LSGANs. The other one is to compare between
LSGANs with gradient penalty (LSGANs-GP) and WGANs with gradient penalty (WGANs-GP). The experimental results show that
LSGANs-GP succeed in training for all the difﬁcult architectures used in WGANs-GP, including 101-layer ResNet.

Index Terms—Least squares GANs, χ2 divergence, generative model, image generation.

(cid:70)

1 INTRODUCTION

D EEP learning has launched a profound reformation and

even been applied to many real-world tasks, such as image
classiﬁcation [1], object detection [2], and segmentation [3].
These tasks fall into the scope of supervised learning, which means
that a lot of labeled data is provided for the learning processes.
Compared with supervised learning, however, unsupervised learn-
ing (such as generative models) obtains limited impact from deep
learning. Although some deep generative models, e.g., RBM [4],
DBM [5], and VAE [6], have been proposed, these models
all face the difﬁculties of intractable functions (e.g., intractable
partition function) or intractable inference, which in turn restricts
the effectiveness of these models.

Unlike the above deep generative models which usually adopt
approximation methods for intractable functions or inference,
Generative Adversarial Networks (GANs) [7] requires no ap-
proximate inference and can be trained end-to-end through a
differentiable network [8]. The basic idea of GANs is to train
a discriminator and a generator simultaneously: the discriminator
aims to distinguish between real samples and generated samples;

• X. Mao and Q. Li are with Department of Computer Science, City

University of Hong Kong, Hong Kong.
E-mail: xudong.xdmao@gmail.com, itqli@cityu.edu.hk

• H. Xie is with Department of Mathematics and Information Technology,

The Education University of Hong Kong, Hong Kong.
E-mail: hrxie2@gmail.com

• R. Lau is with Department of Information Systems, City University of Hong

•

•

Kong, Hong Kong. E-mail: raylau@cityu.edu.hk
Z. Wang is with Center for Optical Imagery Analysis and Learning and
School of Mechanical Engineering, Northwestern Polytechnical Univer-
sity, Xian 710072, China. E-mail: zhenwang0@gmail.com
S. Smolley is with CodeHatch Corp., Edmonton, Alberta Canada.
E-mail: steve@codehatch.com

while the generator tries to generate fake samples as real as pos-
sible, making the discriminator believe that the fake samples are
from real data. GANs have demonstrated impressive performance
for various computer vision tasks such as image generation [9],
[10], image super-resolution [11], and semi-supervised learning
[12].

The original GAN paper

[7] adopted the sigmoid cross
entropy loss for the discriminator and presented two different
losses for the generator: the “minimax” loss (M-GANs) and the
“non-saturating” loss (NS-GANs). They have pointed out that M-
GANs will saturate at the early stage of the learning process. Thus
NS-GANs are recommended for use in practice.

We argue that both the non-saturating loss and the minimax
loss, however, will lead to the problem of vanishing gradients
when updating the generator. As Fig. 2(a) shows,
the non-
saturating loss, i.e., − log D(·), will saturate when the input is
relatively large, while the minimax loss, i.e., log(1 − D(·)), will
saturate when the input is relatively small. Consequently, as Fig.
1(b) shows, when updating the generator, the non-saturating loss
will cause almost no gradient for the fake samples in magenta,
because these samples are on the side of real data, corresponding
to the input with relatively large values in Fig. 2(a). Similarly,
the minimax loss will cause almost no gradient for the fake
samples in green. However, these fake samples are still far from
real data, and we want to pull them closer to real data. Based
on this observation, we propose the Least Squares Generative
Adversarial Networks (LSGANs) which adopt the least squares
loss for both the discriminator and the generator. The idea is
simple yet powerful: the least squares loss is able to move the fake
samples toward the decision boundary, because the least squares
loss penalizes samples that lie in a long way to the decision

2

(a)

(b)

(c)

Fig. 1. Illustration of different behaviors of two loss functions. (a): Decision boundaries of two loss functions. Note that the decision boundary should
go across real data distribution for a successful GANs learning. Otherwise, the learning process is saturated. (b): Decision boundary of the sigmoid
cross entropy loss function. The orange area is the side of real samples, and the blue area is the side of fake samples. The non-saturating loss and
the minimax loss will cause almost no gradient for the fake samples in magenta and green, respectively, when we use them to update the generator.
(c): Decision boundary of the least squares loss function. It penalizes the fake samples (both in magenta and green), and as a result, it forces the
generator to generate samples toward the decision boundary.

rendering 28 × 28 digits using some standard fonts. Datasets
with small variability are difﬁcult for GANs to learn, since the
discriminator can distinguish the real samples very easily for such
datasets.

Recently, gradient penalty has shown the effectiveness of
improving the stability of GANs training [18], [19]. We ﬁnd
that gradient penalty is also helpful for improving the stability
of LSGANs. By adding the gradient penalty in [18], LSGANs
are able to train successfully for all the difﬁcult architectures used
in WGANs-GP [19]. However, gradient penalty also has some
inevitable disadvantages such as additional computational cost and
memory cost. Based on this observation, we evaluate the stability
of LSGANs in two settings: LSGANs without gradient penalty
and LSGANs with gradient penalty.

Our contributions in this paper can be summarized as follows:

• We propose LSGANs which adopt

least squares loss
for both the discriminator and the generator. We show
that minimizing the objective function of LSGANs yields
minimizing the Pearson χ2 divergence.

• We show that the derived objective function that yields
minimizing the Pearson χ2 divergence performs better
than the classical one of using least squares for classiﬁ-
cation.

• We evaluate the image quality of LSGANs on several
datasets including the LSUN-scenes and a cat dataset, and
the experimental results demonstrate that LSGANs can
generate higher quality images than NS-GANs.

• We also evaluate LSGANs on four datasets using the quan-
titative evaluation metric of Fr´echet inception distance
(FID), and the results show that LSGANs with the derived
objective function outperform NS-GANs on four datasets
and outperform WGANs-GP on three datasets. Further-
more, LSGANs spend a quarter of the time comparing
with WGANs-GP to reach a similar relatively optimal FID
on LSUN-bedroom.

• A new evaluation method for the training stability is
proposed. We propose to use datasets with small variabil-
ity to evaluate the stability of GANs. Furthermore, two
synthetic digit datasets with small variability are created
and published.

• We evaluate the training stability of LSGANs with-
out gradient penalty through three experiments including

(a)

(b)

Fig. 2. (a): The non-saturating loss and the minimax loss. (b): The least
squares loss.

boundary even though they are on the correct side. As Fig. 1(c)
shows, the least squares loss will penalize the above two types of
fake samples and pull them toward the decision boundary. Based
on this property, LSGANs are able to generate samples that are
closer to real data.

Another beneﬁt of LSGANs is the improved training stability.
Generally speaking, training GANs is a difﬁcult issue in practice
because of the instability of GANs learning [13], [14]. Recently,
several papers have pointed out that the instability of GANs
learning is partially caused by the objective function [14], [15],
[16]. Speciﬁcally, minimizing the objective function of regular
GANs may cause the problem of vanishing gradients, which
makes it hard to update the generator. LSGANs can alleviate this
problem because penalizing samples based on the distances to
the decision boundary can generate more gradients when updating
the generator. Moreover, we theoretically show that the training
instability of regular GANs is due to the mode-seeking behavior
[17] of the objective function, while LSGANs exhibit less mode-
seeking behavior.

In this paper, we also propose a new method for evaluating
the stability of GANs. One popular evaluation method is to use
difﬁcult architectures, e.g., by excluding the batch normalization
[15]. However,
the stable
architectures for their tasks. Sometimes the difﬁculty is from the
datasets. Motivated by this, we propose to use difﬁcult datasets but
stable architectures to evaluate the stability of GANs. Speciﬁcally,
we create two synthetic digit datasets with small variability by

in practice, one will always select

Gaussian mixture distribution, difﬁcult architectures, and
datasets with small variability. The experimental results
demonstrate that LSGANs perform more stably than NS-
GANs.

• We also evaluate the training stability of LSGANs-GP
through training on six difﬁcult architectures used in
WGANs-GP. LSGANs-GP succeed in training for all the
six architectures including 101-layer ResNet.

This paper extends our earlier conference work [20] in a
number of ways. First, we present more theoretical analysis about
the properties of LSGANs and χ2 divergence. Second, we conduct
a new quantitative experiment based on the FID evaluation metric,
and the results demonstrate that LSGANs perform better than NS-
GANs and WGANs-GP. The results also show that the derived
objective function (Eq. (13)) that yields minimizing the Pearson
χ2 divergence performs better than the classical one (Eq. (14))
of using least squares for classiﬁcation. Eq. (14) is used in our
earlier conference work, but we change to use Eq. (13) in this
paper. Third, we provide new qualitative results on a cat dataset,
which also shows that LSGANs generate higher quality images
than NS-GANs. Fourth, we propose a new method for evaluating
the training stability. In addition to using difﬁcult architectures
[15], we propose to use difﬁcult datasets but stable architectures to
evaluate the training stability. Fifth, we present a new comparison
experiment between LSGANs-GP and WGANs-GP. The results
show that LSGANs-GP succeed in training for all the difﬁcult
architectures used in [19], including 101-layer ResNet. Finally, we
present a new comparison experiment between the two parameter
schemes (Eq. (13) and (14)) of LSGANs.

2 RELATED WORK
Deep generative models attempt to capture the probability dis-
tributions over the given data. Restricted Boltzmann Machines
(RBMs), one type of deep generative models, are the basis of
many other hierarchical models, and they have been used to
model the distributions of images [21] and documents [22]. Deep
Belief Networks (DBNs) [23] and Deep Boltzmann Machines
(DBMs) [5] are extended from the RBMs. The most successful
application of DBNs is for image classiﬁcation [23], where DBNs
are used to extract feature representations. However, RBMs,
DBNs, and DBMs all have the difﬁculties of intractable partition
functions or intractable posterior distributions, which thus use the
approximation methods to learn the models. Another important
deep generative model is Variational Autoencoders (VAE) [6],
a directed model, which can be trained with gradient-based op-
timization methods. But VAEs are trained by maximizing the
variational lower bound, which may lead to the blurry problem
of generated images [8].

Recently, Generative Adversarial Networks (GANs) have been
proposed by Goodfellow et al.
[7], who explained the theory
of GANs learning based on a game theoretic scenario. A similar
idea is also introduced by Ganin et al.
[24], where a method of
adversarial training is proposed for domain adaptation. Showing
the powerful capability for unsupervised tasks, GANs have been
applied to many speciﬁc tasks, like image super-resolution [11],
text to image synthesis [25], and image to image translation [26].
By combining the traditional content loss and the adversarial loss,
super-resolution generative adversarial networks [11] achieved
state-of-the-art performance for the task of image super-resolution.
Reed et al. [25] proposed a model to synthesize images given text

3

descriptions based on the conditional GANs [27]. Isola et al. [26]
also used the conditional GANs to transfer images from one rep-
resentation to another. In addition to unsupervised learning tasks,
GANs also show the good potential for semi-supervised learning
tasks. Salimans et al.
[12] proposed a GAN-based framework
for semi-supervised learning, in which the discriminator not only
outputs the probability that an input image is from real data, but
also outputs the probabilities of belonging to each class. Another
important problem of GANs is to inference the latent vectors from
given examples [28], [29], [30]. Both [28] and [29] proposed a
bidirectional adversarial learning framework by incorporating an
encoder into the GANs framework. Li et al. [30] proposed to use
the conditional entropy to regularize the objectives in [28], [29],
making the learning process more stable.

Despite the great successes GANs have achieved, improving
the quality of generated images is still a challenge. A lot of works
have been proposed to improve the quality of images for GANs.
Radford et al. [13] ﬁrst introduced convolutional layers to GANs
architecture, and proposed a network architecture called deep
convolutional generative adversarial networks (DCGANs). Denton
et al.
[31] proposed a framework called Laplacian pyramid of
generative adversarial networks to improve the image quality of
high-resolution images, where a Laplacian pyramid is constructed
to generate high-resolution images starting from low-resolution
images. A similar approach is proposed by Huang et al.
[32]
who used a series of stacked GANs to generate images from
abstract to speciﬁc. Salimans et al.
[12] proposed a technique
called feature matching to get better convergence. The idea is to
make the generated samples match the statistics of real data by
minimizing the mean square error on an intermediate layer of the
discriminator.

Another critical issue for GANs is the stability of the learning
process. Many works have been proposed to address this problem
[14], [15], [16],
by analyzing the objective functions of GANs
[33], [34]. Viewing the discriminator as an energy function, Zhao
et al.
[35] used an auto-encoder architecture to improve the
stability of GANs learning. Dai et al.
[36] extended the energy-
based GANs by adding some regularizations to make the discrimi-
nator non-degenerate. To make the generator and the discriminator
more balanced, Metz et al.
[14] created an unrolled objective
function to enhance the generator. Che et al. [33] incorporated a
reconstruction module and used the distance between real samples
and reconstructed samples as a regularizer to get more stable
gradients. Nowozin et al.
[34] pointed out that the objective of
regular GAN [7] which is related to Jensen-Shannon divergence
is a special case of divergence estimation, and generalized it
to arbitrary f-divergences [37]. Arjovsky et al.
[15] extended
this by analyzing the properties of four different divergences
and concluded that Wasserstein distance is more stable than
Jensen-Shannon divergence. Qi
[16] proposed the loss-sensitive
GAN whose loss function is based on the assumption that real
samples should have smaller losses than fake samples. They also
introduced to use Lipschitz regularity to stabilize the learning
process. Base on the above assumptions, they proved that loss-
sensitive GAN has non-vanishing gradient almost everywhere.
Some other techniques to stabilize GANs learning include the
second order method [38] and gradient penalty [18], [19], [39].
Mescheder et al.
[38] analyzed the convergence property of
GANs from the perspective of the eigenvalues of the equilibrium
and proposed a method to regularize the eigenvalues, which in
turn leads to better training stability. Gulrajani et al.
[19] used

gradient penalty to enforce the Lipschitz constraint in Wasserstein
distance. They showed that this approach performs more stably
than the method used in [15]. Unlike [19] that applies gradient
penalty around the region between the real data and the fake data,
Kodali et al.
[18] proposed to apply gradient penalty around
the real data manifold only, which has the advantage that it is
applicable to various GANs. Roth et al.
[39] derived a new
gradient-based regularization from analyzing that adding noise to
the discriminator yields training with gradient penalty.

3 METHOD

3.1 Generative Adversarial Networks

The learning process of GANs is to train a discriminator D and
a generator G simultaneously. The target of G is to learn the
distribution pg over data x. G starts with sampling input variables
z from a uniform or Gaussian distribution pz(z), then maps the
input variables z to data space G(z; θg) through a differentiable
network. On the other hand, D is a classiﬁer D(x; θd) that aims
to recognize whether an image is from training data or from G.
The minimax objective for GANs can be formulated as follows:

min
G

max
D

VGAN(D, G) = Ex∼pdata(x)[log D(x)]
+Ez∼pz(z)[log(1 − D(G(z)))].

(1)

In practice, Goodfellow et al.
[7] recommend implementing the
following non-saturating loss for the generator, which provides
much stronger gradients.

min
G

VGAN(G) = −Ez∼pz(z)[log(D(G(z)))].

(2)

Following [40], we refer to Eq. (1) as minimax GANs (M-GANs)
and Eq. (2) as non-saturating GANs (NS-GANs). In the following
experiments, we compare our proposed LSGANs with NS-GANs
since NS-GANs perform much better than M-GANs [7], [40].

3.2 Least Squares Generative Adversarial Networks

As stated in Section 1, the original GAN paper
[7] adopted the
sigmoid cross entropy loss function for the discriminator, and
introduced the minimax loss and the non-saturating loss for the
generator. However, both the minimax loss and the non-saturating
loss will cause the problem of vanishing gradients for some fake
samples that are far from real data, as shown in Fig. 1(b). To
remedy this problem, we propose the Least Squares Generative
Adversarial Networks (LSGANs). Suppose we use the a-b coding
scheme for the discriminator, where a and b are the labels for
the fake data and the real data, respectively. Then the objective
functions for LSGANs can be deﬁned as follows:

min
D

VLSGAN(D) =

Ex∼pdata(x)

(cid:2)(D(x) − b)2(cid:3)

+

Ez∼pz(z)

(cid:2)(D(G(z)) − a)2(cid:3)

(3)

min
G

VLSGAN(G) =

Ez∼pz(z)

(cid:2)(D(G(z)) − c)2(cid:3),

1
2
1
2
1
2

4

3.2.1 Beneﬁts of LSGANs
The beneﬁts of LSGANs can be derived from two aspects. First,
unlike M-GANs and NS-GANs which cause almost no gradient
for some kinds of fake samples, LSGANs will penalize those
samples even though they are correctly classiﬁed, as shown in
Fig. 1(c). When we update the generator, the parameters of the
discriminator are ﬁxed, i.e., the decision boundary is ﬁxed. As
a result, the penalization will cause the generator to generate
samples toward the decision boundary. On the other hand, the
decision boundary should go across the manifold of real data for a
successful GANs learning; otherwise, the learning process will be
saturated. Thus moving the generated samples toward the decision
boundary leads to making them closer to the manifold of real data.
Second, penalizing the samples lying in a long way to the
decision boundary can generate more gradients when updating
the generator, which in turn relieves the problem of vanishing
gradients. This allows LSGANs to perform more stably during the
learning process. This beneﬁt can also be derived from another
perspective: as shown in Fig. 2, the least squares loss function is
ﬂat only at one point, while NS-GANs will saturate when x is
relatively large, and M-GANs will saturate when x is relatively
small. In Section 3.3.2, we provide further theoretical analysis
about the stability of LSGANs.

3.3 Theoretical Analysis
3.3.1 Relation to χ2 Divergence
In the original GAN paper [7], the authors have shown that mini-
mizing Eq. (1) yields minimizing the Jensen-Shannon divergence:

C(G) = KL

pdata

(cid:18)

(cid:13)
(cid:13)
(cid:13)
(cid:13)

pdata + pg
2

(cid:19)

(cid:18)

+ KL

pg

(cid:13)
(cid:13)
(cid:13)
(cid:13)

pdata + pg
2

(cid:19)

− log(4). (4)

Here we also explore the relation between LSGANs and f-

min
D

VLSGAN(D) =

Ex∼pdata(x)

(cid:2)(D(x) − b)2(cid:3)

divergence. Consider the following extension of Eq. (3):
1
2
1
2
1
2
1
2

(cid:2)(D(x) − c)2(cid:3)

(cid:2)(D(G(z)) − a)2(cid:3)

(cid:2)(D(G(z)) − c)2(cid:3).

Ex∼pdata(x)

VLSGAN(G) =

Ez∼pz(z)

Ez∼pz(z)

min
G

+

+

Note that adding the term Ex∼pdata(x)[(D(x) − c)2]
to
VLSGAN(G) causes no change of the optimal values since this term
does not contain parameters of G.

We ﬁrst derive the optimal discriminator D for a ﬁxed G.

Proposition 1. For a ﬁxed G, the optimal discriminator D is

D∗(x) =

bpdata(x) + apg(x)
pdata(x) + pg(x)

.

Proof. Given any generator G, we try to minimize V (D) with
respect to the discriminator D:

V (D) =

Ex∼pdata

Ez∼pz

(cid:2)(D(G(z)) − a)2(cid:3)

(cid:2)(D(x) − b)2(cid:3) +

1
2
1
2
(cid:0)pdata(x)(D(x) − b)2 + pg(x)(D(x) − a)2(cid:1)dx.

(cid:2)(D(x) − b)2(cid:3) +

(cid:2)(D(x) − a)2(cid:3)

Ex∼pg

Ex∼pdata
1
2

X

(5)

(6)

(7)

(8)

1
2
1
2
(cid:90)

=

=

1
2

where c denotes the value that G wants D to believe for the fake
data.

(cid:0)pdata(x)(D(x) − b)2 + pg(x)(D(x) − a)2(cid:1).

Consider the internal function:

5

(a) Generated images (64 × 64) by NS-GANs (reported in [13]).

(b) Generated images (112 × 112) by NS-GANs.

(c) Generated images (112 × 112) by LSGANs.

Fig. 3. Generated images on LSUN-bedroom.

It achieves the mimimum at bpdata(x)+apg(x)
concluding the proof.

pdata(x)+pg(x) with respect to D(x),

In the following equations we use pd to denote pdata for

simplicity.

Theorem 1. Optimizing LSGANs yields minimizing the Pearson
χ2 divergence between pd + pg and 2pg, if a, b, and c satisfy the
conditions of b − c = 1 and b − a = 2 in Eq. (5).

Proof. We can reformulate VLSGAN(G) in Eq. (5) by using Propo-
sition 1:

2C(G) = Ex∼pd
= Ex∼pd

(cid:2)(D∗(G(z)) − c)2(cid:3)
(cid:2)(D∗(x) − c)2(cid:3)
(cid:21)

(cid:2)(D∗(x) − c)2(cid:3) + Ez∼pz
(cid:2)(D∗(x) − c)2(cid:3) + Ex∼pg
(cid:20)
(cid:0) bpd(x) + apg(x)
− c(cid:1)2
pd(x) + pg(x)
(cid:0) bpd(x) + apg(x)
pd(x) + pg(x)

− c(cid:1)2

(cid:20)

(cid:21)

(9)

pd(x)(cid:0) (b − c)pd(x) + (a − c)pg(x)

(cid:1)2dx

pd(x) + pg(x)

pg(x)(cid:0) (b − c)pd(x) + (a − c)pg(x)
(cid:0)(b − c)pd(x) + (a − c)pg(x)(cid:1)2
pd(x) + pg(x)

pd(x) + pg(x)

dx

(cid:1)2dx

(cid:0)(b − c)(pd(x) + pg(x)) − (b − a)pg(x)(cid:1)2
pd(x) + pg(x)

dx.

= Ex∼pd

+ Ex∼pg
(cid:90)

=

+

=

=

X

(cid:90)

X
(cid:90)

X

(cid:90)

X

If we set b − c = 1 and b − a = 2, then

2C(G) =

(cid:90)

(cid:0)2pg(x) − (pd(x) + pg(x))(cid:1)2
pd(x) + pg(x)

dx

X
= χ2
Pearson(pd + pg(cid:107)2pg),

(10)

Pearson is the Pearson χ2 divergence. Thus minimizing Eq.
where χ2
(5) yields minimizing the Pearson χ2 divergence between pd + pg
and 2pg if a, b, and c satisfy the conditions of b − c = 1 and
b − a = 2.

3.3.2 Properties of χ2 Divergence
As Eq. (4) shows, the original GAN has been proven to optimize
the JS divergence. Furthermore, Husz´ar [41] pointed out that Eq.
(4) can be viewed as an interpolation between KL(pg(cid:107)pd) and
KL(pd(cid:107)pg):

JSπ(pd(cid:107)pg) = (1 − π)KL(pd(cid:107)πpd + (1 − π)pg)

+ πKL(pg(cid:107)πpd + (1 − π)pg),

(11)

where Eq. (4) corresponds to π = 0.5. They also found that
optimizing Eq. (4) tends to perform similarly to KL(pg(cid:107)pd).
KL(pg(cid:107)pd) is widely used in variational inference due to the
convenient evidence lower bound
[17]. However, optimizing
KL(pg(cid:107)pd) has the problem of mode-seeking behavior or under-
dispersed approximations
[17], [41], [42]. This problem also
appears in GANs learning, which is known as the mode collapse
problem. The deﬁnition of KL(pg(cid:107)pd) is given below:

6

(a) Church outdoor.

(b) Dining room.

Fig. 4. Generated images on different scene datasets.

(c) Kitchen.

(d) Conference room.

KL(pg(cid:107)pd) = −

pg(x) ln

dx.

(12)

(cid:90)

X

(cid:19)

(cid:18) pd(x)
pg(x)

The mode-seeking behavior of KL(pg(cid:107)pd) can be understood by
noting that pg will be close to zero where pd is near zero, because
KL(pg(cid:107)pd) will be inﬁnite if pd = 0 and pg > 0. This is called
the zero-forcing property [17].

Recently, χ2 divergence has drawn researchers’ attention in
variational inference since χ2 divergence is able to produce over-
dispersed approximations [42]. For the objective function in Eq.
(10), it will become inﬁnite if pd +pg = 0 and pg −pd > 0, which
will not happen since pg ≥ 0 and pd ≥ 0. Thus χ2
Pearson(pd +
pg(cid:107)2pg) has no zero-forcing property. This makes LSGANs less
mode-seeking and alleviates the mode collapse problem.

3.4 Parameters Selection

One method to determine the values of a, b, and c in Eq. (3) is
to satisfy the conditions of b − c = 1 and b − a = 2, such that
minimizing Eq. (3) yields minimizing the Pearson χ2 divergence
between pd +pg and 2pg. For example, by setting a = −1, b = 1,
and c = 0, we get the following objective functions:

min
D

VLSGAN(D) =

Ex∼pdata(x)

(cid:2)(D(x) − 1)2(cid:3)

+

Ez∼pz(z)

(cid:2)(D(G(z)) + 1)2(cid:3)

(13)

min
G

VLSGAN(G) =

Ez∼pz(z)

(cid:2)(D(G(z)))2(cid:3).

1
2
1
2
1
2

using least squares for classiﬁcation. For example, by using the 0-
1 binary coding scheme, we get the following objective functions:

1
2
1
2
1
2

min
D

VLSGAN(D) =

Ex∼pdata(x)

(cid:2)(D(x) − 1)2(cid:3)

+

Ez∼pz(z)

(cid:2)(D(G(z)))2(cid:3)

(14)

min
G

VLSGAN(G) =

Ez∼pz(z)

(cid:2)(D(G(z)) − 1)2(cid:3).

In practice, we ﬁnd that Eq. (13) shows better FID results
and faster convergence speed than Eq. (14), as demonstrated
by experiments. For the experiments presented in our earlier
conference work [20], we adopted Eq. (14), but for the newly
introduced experiments in this paper, Eq. (13) is adopted.

4 EXPERIMENTS

In this section, we ﬁrst present some details of our implementation.
Next, we present the results of the qualitative evaluation and
quantitative evaluation of LSGANs. Then we evaluate the stability
of LSGANs in two groups. One is to compare LSGANs with
DCGANs without gradient penalty by three experiments. The
other one is to compare LSGANs-GP with WGANs-GP. Note
that we implement DCGANs using the non-saturating loss (NS-
GANs). In the following experiments, we denote NS-GANs as the
baseline method.

4.1 Implementation Details

The implementation of our proposed models is based on a public
implementation of DCGANs1 using TensorFlow [43]. The learn-
ing rate is set to 0.0002 except for LSUN-scenes whose learning
rate is set to 0.001. The mini-batch size is set to 64, and the
variables are initialized from a Gaussian distribution with a mean

Another method is to make G generate samples as real as
possible by setting c = b, corresponding to the traditional way of

1 https://github.com/carpedm20/DCGAN-tensorﬂow

7

(a) Generated cats (128 × 128) by NS-GANs.

(b) Generated cats (128 × 128) by LSGANs.

(c) NS-GANs

(d) LSGANs

(e) Real Sample

Fig. 5. Generated images on cat datasets. (c)(d)(e): Comparison by zooming in on the details of the images. LSGANs generate cats with sharper
and more exquisite hair and faces than the ones generated by NS-GANs.

of zero and a standard deviation of 0.02. Following DCGANs,
β1 for Adam optimizer is set to 0.5. The pixel values of all
the images are scaled to [-1,1], since we use the Tanh in the
generator to produce images. Our implementation is available at
https://github.com/xudonmao/improved LSGAN.

TABLE 1
The network architecture for scene generation, where CONV denotes
the convolutional layer, TCONV denotes the transposed convolutional
layer, FC denotes the fully-connected layer, BN denotes the batch
normalization, LReLU denotes the Leaky-ReLU, and (K3,S2,O256)
denotes a layer with 3 × 3 kernel, stride 2, and 256 output ﬁlters.

4.2 Image Quality

4.2.1 Qualitative Evaluation

Scenes Generation We train LSGANs and NS-GANs using the
same network architecture on the LSUN-bedroom dataset. The
network architecture is presented in Table 1. All the images are
resized to the resolution of 112 × 112. The generated images by
the two models are presented in Fig. 3. Compared with the images
generated by NS-GANs, the texture details (e.g., the textures of
beds) of the images generated by LSGANs are more exquisite,
and the images generated by LSGANs look sharper. We also train
LSGANs on four other scene datasets including church, dining
room, kitchen, and conference room. The generated results are
shown in Fig. 4.
Cats Generation We further evaluate LSGANs on a cat dataset
[44]. We ﬁrst use the preprocess methods in a public project2 to

2 https://github.com/AlexiaJM/Deep-learning-with-cats

Generator
Input z
FC(O12544), BN, ReLU
TCONV(K3,S2,O256), BN, ReLU
TCONV(K3,S1,O256), BN, ReLU
TCONV(K3,S2,O256), BN, ReLU
TCONV(K3,S1,O256), BN, ReLU
TCONV(K3,S2,O128), BN, ReLU
TCONV(K3,S2,O64), BN, ReLU
TCONV(K3,S1,O3), Tanh

Discriminator
Input 112 × 112 × 3
CONV(K5,S2,O64), LReLU
CONV(K5,S2,O128), BN, LReLU
CONV(K5,S2,O256), BN, LReLU
CONV(K5,S2,O512), BN, LReLU
FC(O1)
Loss

get cat head images whose resolution is larger than 128 × 128,
and then resize all the images to the resolution of 128 × 128.
The network architecture used in this task is presented in Table 2.
We use the following evaluation protocol for comparing the
performance between LSGANs and NS-GANs. First, we train
LSGANs and NS-GANs using the same architecture on the cat
dataset. During training, we save a checkpoint of the model
and a batch of generated images every 1000 iterations. Sec-

8

(a) Interpolation on the LSUN-bedroom dataset.

Fig. 6.
representations in the latent space.

Interpolation result by LSGANs. The generated images show smooth transitions, which indicates that LSGANs have learned semantic

(b) Interpolation on the cats dataset.

TABLE 2
The network architecture for cats generation. The meanings of the
symbols can be found in Table 1.

TABLE 3
FID results of NS-GANs, WGANs-GP, and LSGANs on four datasets.
LSGANs(−110) and LSGANs(011) refer to Eq. (13) and Eq. (14),
respectively.

Generator
Input z
FC(O32768), BN, ReLU
TCONV(K3,S2,O256), BN, ReLU
TCONV(K3,S2,O128), BN, ReLU
TCONV(K3,S2,O64), BN, ReLU
TCONV(K3,S2,O3), Tanh

Discriminator
Input 128 × 128 × 3
CONV(K5,S2,O64), LReLU
CONV(K5,S2,O128), BN, LReLU
CONV(K5,S2,O256), BN, LReLU
CONV(K5,S2,O512), BN, LReLU
FC(O1)
Loss

Method
NS-GANs
WGANs-GP
LSGANs(011)
LSGANs(−110)

LSUN
28.04
22.77
27.21
21.55

Cat
15.81
29.03
15.46
14.28

ImageNet CIFAR10
74.15
62.05
72.54
68.95

35.25
40.83
36.46
35.19

ond, we select the best models of LSGANs and NS-GANs by
checking the quality of saved images in every 1000 iterations.
Finally, we use the selected best models to randomly gener-
ate cat images and compare the quality of generated images.
The selected models of LSGANs and NS-GANs are available
at https://github.com/xudonmao/improved LSGAN. Fig. 5 shows
the generated cat images of LSGANs and NS-GANs. We observe
that LSGANs generate cats with sharper and more exquisite hair
than the ones generated by NS-GANs. Fig. 5(c)(d) shows the
details of the cat hair by zooming in the generated images. We
observe that the cat hair generated by NS-GANs contains more
artiﬁcial noise. By checking more generated samples using the
above saved models, we also observe that the overall quality of
generated images by LSGANs is better than NS-GANs.
Walking in the Latent Space We also present the interpolation
results in Fig. 6. The result of walking in the latent space is a
sign of whether a model is just memorizing the training dataset.
We ﬁrst randomly sample two points of the noise vector z, and
then interpolate the vector values between the two sampled points.
The images in Fig. 6 show smooth transitions, which indicates
that LSGANs have learned semantic representations in the latent
space.

4.2.2 Quantitative Evaluation
For the quantitative evaluation of LSGANs, we adopt Fr´echet
Inception Distance (FID)
[45] as the evaluation metric. FID
measures the distance between the generated images and the
real images by approximating the feature space of the inception

(a)

(b)

Fig. 7.
(a): Comparison of FID on LSUN between NS-GANs and
LSGANs during the learning process, which is aligned with iterations.
(b): Comparison of FID on LSUN between WGANs-GP and LSGANs
during the learning process, which is aligned with wall-clock time.

model as a multidimensional Gaussian distribution, which has
been proved to be more consistent with human judgment than
inception score [12]. Smaller FID values mean closer distances
between the generated and real images. We also conduct a human
subjective study on the LSUN-bedroom dataset.
Fr´echet Inception Distance For FID, we evaluate the perfor-
mances of LSGANs, NS-GANs, and WGANs-GP on several
datasets including LSUN-bedroom, the cat dataset, ImageNet, and
CIFAR-10. We also compare the performances of Eq. (13) (de-
noted as LSGANs(−110)) and Eq. (14) (denoted as LSGANs(011)).
For a fair comparison, all the models are trained with the same
architecture proposed in DCGAN [13] (i.e., four convolutional
layers for both the discriminator and the generator), and the
dimension of the noise input is set to 100. For WGANs-GP, we

9

Fig. 8. Dynamic results of Gaussian kernel estimation for NS-GANs and LSGANs. The ﬁnal column shows the distribution of real data.

adopt the ofﬁcial implementation for evaluation. The resolutions
for LSUN, Cat, ImageNet, and CIFAR-10 are 64 × 64, 128 × 128,
64 × 64, and 32 × 32, respectively. We randomly generate 50, 000
images every 4k iterations for each model and then compute
FID. The results are shown in Table 3, and we have the fol-
lowing four observations. First, LSGANs(−110) outperform NS-
GANs for all the four datasets. Second, comparing with WGANs-
GP, LSGANs(−110) perform better for three datasets, especially
for the cat dataset. Third, LSGANs(−110) perform better than
LSGANs(011) for all the four datasets. Fourth, the performance
of LSGANs(011) is comparable to NS-GANs.

We also show the FID plot of the learning process in Fig.
7, where LSGANs refer to LSGANs(−110). Following [45], the
plots of NS-GANs and LSGANs are aligned by iterations, and
the plots of WGANs-GP and LSGANs are aligned by wall-clock
time. As Fig. 7(a) shows, NS-GANs and LSGANs show similar
FID at the ﬁrst 25k iterations, but LSGANs can decrease FID after
25k iterations, achieving better performance eventually. Fig. 7(b)
shows that WGANs-GP and LSGANs achieve similar optimal FID
eventually, but LSGANs spend much less time (1, 100 minutes)
than WGANs-GP (4, 600 minutes) to reach a relatively optimal
FID around 22. This is due to that WGANs-GP need multiple
updates for the discriminator and need additional computational
time for the gradient penalty.

Human Subjective Study To further evaluate the performance of
LSGANs, we conduct a human subjective study using the gener-
ated bedroom images (112 × 112) from NS-GANs and LSGANs
with the same network architecture. We randomly construct image
pairs, where one image is from NS-GANs and the other one is
from LSGANs. We ask Amazon Mechanical Turk annotators to
judge which image looks more realistic. With 4,000 votes totally,
NS-GANs get 43.6% votes and LSGANs get 56.4% votes, i.e., an
overall 12.8% increase of votes over NS-GANs.

4.3 Training Stability

In this section, we evaluate the stability of our proposed LS-
GANs and compare with two baselines including NS-GANs and
WGANs-GP. Gradient penalty has been proven to be effective for
improving the stability of GANs training [18], [19], but it also has
some inevitable disadvantages such as additional computational
cost and memory cost. Thus we evaluate the stability of LSGANs
in two groups. One is to compare with the model without gradient
penalty (i.e., NS-GANs), and the other one is to compare with the
model with gradient penalty (i.e., WGANs-GP).

TABLE 4
Experiments on Gaussian mixture distribution. We run 100 times for
each model and record how many times that a model ever generates
samples around one or two modes during the training process.

Method

NS-GANs

LSGANs (ours)

The number of generating samples

around one or two modes

99 / 100
5 / 100

4.3.1 Evaluation without Gradient Penalty
We ﬁrst compare LSGANs with NS-GANs, both of which are
without gradient penalty. Three comparison experiments are con-
ducted: 1) learning on a Gaussian mixture distribution; 2) learning
with difﬁcult architectures; and 3) learning on datasets with small
variability.
Gaussian Mixture Distribution Learning on a Gaussian mix-
ture distribution to evaluate the stability is proposed by Metz
et al. [14]. If the model suffers from the mode collapse problem,
it will generate samples only around one or two modes. We train
NS-GANs and LSGANs with the same network architecture on
a 2D mixture of eight Gaussian mixture distribution, where both
the generator and the discriminator contain three fully-connected
layers. Fig. 8 shows the dynamic results of Gaussian kernel density
estimation. We can see that NS-GANs suffer from mode collapse
starting at 15k iterations. They only generate samples around
a single valid mode of the data distribution. But LSGANs can
learn the Gaussian mixture distribution successfully. We also try
different architectures (four or ﬁve fully-connected layers) and
different values of the hyper-parameters (the learning rate and the
dimension of the noise vector). The results also show that NS-
GANs tend to generate samples around one or two modes, while
LSGANs are less prone to this problem.

To further verify the robustness of the above observation,
we run 100 times for each model and record how many times
that a model suffers from the mode collapse problem. For each
experiment, we save the density estimation every 5k iterations and
observe whether a model generates samples only around one or
two modes in each saved estimation. The results show that NS-
GANs appear to generate one or two modes 99 times out of 100,
while LSGANs only have 5 times, as shown in Table 4.
Difﬁcult Architectures Another experiment is to train GANs
[15]. The
with difﬁcult architectures, which is proposed in
model will generate very similar images if it suffers from mode

NS-GANs

LSGANs

NS-GANs

LSGANs

10

(a) No BN in G using Adam.

(b) No BN in either G or D using RMSProp.

(c) No BN in G using RMSProp.

(d) No BN in either G or D using Adam.

Fig. 9. Comparison experiments between NS-GANs and LSGANs by excluding batch normalization (BN).

Real Samples

NS-GANs

LSGANs

(a) Training on MNIST.

(b) Training on a synthetic digit dataset with random horizontal shift.

(c) Training on a synthetic digit dataset with random horizontal shift and rotation.

Fig. 10. Evaluation on datasets with small variability. All the tasks are conducted using the same network architecture as shown in Table 5. DCGANs
succeed in learning on MNIST but fail on the two synthetic digit datasets with small variability, while LSGANs succeed in learning on all the three
datasets.

collapse problem. The network architecture used in this task is
similar to the one in Table 2 except for the image resolution.
Based on this network architecture, two architectures are designed
to compare the stability. The ﬁrst one is to exclude the batch
normalization in the generator (BNG for short), and the second
one is to exclude the batch normalization in both the generator
and discriminator (BNGD for short). As pointed out in [15], the
selection of optimizer is critical to the model performance. Thus
we evaluate the two architectures with two optimizers, Adam [46]
and RMSProp [47]. In summary, we have the following four
training settings: (1) BNG with Adam, (2) BNG with RMSProp,
(3) BNGD with Adam, and (4) BNGD with RMSProp. We train
the above models on the LSUN-bedroom dataset using NS-GANs
and LSGANs separately. The results are shown in Fig. 9, and
we make the following three major observations. First, for BNG
with Adam, there is a chance for LSGANs to generate relatively
good quality images. We test 10 times, and 5 of those succeed to
generate relatively good quality images. For NS-GANs, however,
we never observe successful learning, suffering from a severe
degree of mode collapse. Second, for BNGD with RMSProp,
as Fig. 9 shows, LSGANs generate higher quality images than
NS-GANs which have a slight degree of mode collapse. Third,
LSGANs and NS-GANs have similar performance for BNG with
RMSProp and BNGD with Adam. Speciﬁcally, for BNG with
RMSProp, both LSGANs and NS-GANs can generate relatively

TABLE 5
The network architecture for stability evaluation on datasets with small
variability. The meanings of the symbols can be found in Table 1.

Generator
Input z
FC(O8192), BN, ReLU
TCONV(K3,S2,O256), BN, ReLU
TCONV(K3,S2,O128), BN, ReLU
TCONV(K3,S2,O1), Tanh

Discriminator
Input 28 × 28 × 1
CONV(K5,S2,O20), LReLU
CONV(K5,S2,O50), BN, LReLU
FC(O500), BN, LReLU
FC(O1)
Loss

good images. For BNGD with Adam, both have a slight degree of
mode collapse.
Datasets with small variability Using difﬁcult architectures is an
effective way to evaluate the stability of GANs [15]. However,
in practice, it is natural to select a stable architecture for a given
task. The difﬁculty of a practical task is the task itself. Inspired
by this motivation, we propose to use difﬁcult datasets but stable
architectures to evaluate the stability of GANs. We ﬁnd that the
datasets with small variability are difﬁcult for GANs to learn,
since the discriminator can distinguish the real samples very easily
for the datasets with small variability. Speciﬁcally, we construct
the datasets by rendering 28 × 28 digits using the Times-New-
Roman font. Two datasets are created3: 1) one is applied with

3 Available at https://github.com/xudonmao/improved LSGAN

WGANs-GP

LSGANs-GP

WGANs-GP

LSGANs-GP

11

(a) G: No BN and a constant number of ﬁlters, D: DCGAN.

(b) G: 4-layer 512-dim ReLU MLP, D: DCGAN.

(c) No normalization in either G or D.

(d) Gated multiplicative nonlinearities everywhere in G and D.

(e) Tanh nonlinearities everywhere in G and D.

(f) 101-layer ResNet G and D.

Fig. 11. Comparison experiments between WGANs-GP and LSGANs-GP using difﬁcult architectures, where the images generated by WGANs-GP
are duplicated from [19]. LSGANs-GP succeed for all the architectures.

Fig. 12. Dynamic results of the two parameter schemes on the SVHN dataset. The ﬁrst row corresponds to Eq. (13), and the second row corresponds
to Eq. (14).

random horizontal shift; and 2) the other one is applied with
random horizontal shift and random rotation from 0 to 10 degrees.
Each category contains one thousand samples for both datasets.
Note that the second dataset is with larger variability than the
ﬁrst one. Examples of the two synthetic datasets are shown in
the ﬁrst column of Fig. 10. We adopt a stable architecture for
digits generation, following the suggestions in [13], where the
discriminator is similar to LeNet, and the generator contains
three transposed convolutional layers. The detail of the network
architecture is presented in Table 5. We train NS-GANs and
LSGANs on the above two datasets, and the generated images
are shown in Fig. 10, along with the results on MNIST. We have
two major observations. First, NS-GANs succeed in learning on
MNIST but fail on the two synthetic digit datasets, while LSGANs
succeed in learning on all the three datasets. Second, LSGANs
generate higher quality images on the second dataset than the ﬁrst
one. This implies that increasing the variability of the dataset can
improve the generated image quality and relieve the mode collapse
problem. Based on this observation, applying data augmentation
such as shifting, cropping, and rotation is an effective way of
improving GANs learning.

4.3.2 Evaluation with Gradient Penalty

Gradient penalty has been proven to be effective in improving the
stability of GAN training [18], [19]. To compare with WGANs-
GP, which is the state-of-the-art GAN model in stability, we adopt
the gradient penalty in [18] for LSGANs and set the hyper-
parameters c and λ to 30 and 150, respectively. For this exper-
iment, our implementation is based on the ofﬁcial implementation
of WGANs-GP. We follow the evaluation method in WGANs-GP:
to train with six difﬁcult architectures including 1) no normal-
ization and a constant number of ﬁlters in the generator; 2) 4-
layer 512-dimension ReLU MLP generator; 3) no normalization
in either the generator or discriminator; 4) gated multiplicative
nonlinearities in both the generator and discriminator; 5) tanh
nonlinearities in both the generator and discriminator; and 6)
101-layer ResNet for both the generator and discriminator. The
results are presented in Fig. 11, where the generated images by
WGANs-GP are duplicated from [19]. We have the following
two major observations. First, like WGANs-GP, LSGANs-GP
also succeed in training for each architecture, including 101-layer
ResNet. Second, LSGANs-GP with 101-layer ResNet generate
higher quality images than the other ﬁve architectures.

4.4 Comparison of Two Parameter Schemes

As stated in Section 4.2.2, LSGANs(−110) perform better than
for the FID-based experiment. In this experi-
LSGANs(011)
ment, we show another comparison between the two param-
eter schemes. We train LSGANs(−110) and LSGANs(011) on
SVHN [48] dataset using the same network architecture. Fig.
12 shows the dynamic results of the two schemes. We can
observe that LSGANs(−110) shows faster convergence speed than
LSGANs(011). We also evaluate the two schemes on the LSUN-
bedroom and cat dataset, and similar results are observed.

4.5 Suggestions in Practice

Based on the above experiments, we have the following sugges-
tions in practice. First, we suggest using LSGANs(−110) without
gradient penalty if it works, because using gradient penalty will
introduce additional computational cost and memory cost. Second,
we observe that the quality of generated images by LSGANs may
shift between good and bad during the training process, which is
also indicated in Fig. 7. Thus we suggest to keep a record of gener-
ated images at every thousand or hundred iterations and select the
model manually by checking the image quality. Third, if LSGANs
without gradient penalty fail, we suggest using LSGANs-GP and
set the hyper-parameters according to the suggestions in literature
[18]. In our experiments, we ﬁnd that the hyper-parameter setting,
c = 30 and λ = 150, works for all the tasks.

5 CONCLUSIONS AND FUTURE WORK

In this paper, we have proposed the Least Squares Generative
Adversarial Networks (LSGANs) to overcome the vanishing gra-
dients problem during the learning process. The experimental
results show that LSGANs generate higher quality images than
regular GANs. Based on the quantitative experiments, we ﬁnd
that the derived objective function that yields minimizing the
Pearson χ2 divergence performs better than the classical one of
using least squares for classiﬁcation. We also conducted three
comparison experiments for evaluating the stability, and the re-
sults demonstrate that LSGANs perform more stably than regular
GANs. We further compare the stability between LSGANs-GP
and WGANs-GP, and LSGANs-GP show comparable stability to
WGANs-GP. For the future work, instead of pulling the generated
samples toward the decision boundary, designing a method to pull
the generated samples toward real data directly is worth further
investigation.

REFERENCES

[1] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in Computer Vision and Pattern Recognition (CVPR), 2016.
[2] S. Ren, K. He, R. Girshick, and J. Sun, “Faster r-cnn: Towards real-time
object detection with region proposal networks,” in Advances in Neural
Information Processing Systems 28, 2015, pp. 91–99.
J. Long, E. Shelhamer, and T. Darrell, “Fully convolutional networks
for semantic segmentation,” in Computer Vision and Pattern Recognition
(CVPR), 2015.

[3]

[4] G. Hinton and R. Salakhutdinov, “Reducing the dimensionality of data
with neural networks,” Science, vol. 313, no. 5786, pp. 504 – 507, 2006.
[5] R. Salakhutdinov and G. Hinton, “Deep Boltzmann machines,” in Pro-
ceedings of the International Conference on Artiﬁcial Intelligence and
Statistics, vol. 5, 2009, pp. 448–455.

[6] D. P. Kingma and M. Welling, “Auto-encoding variational bayes,” in
International Conference on Learning Representations (ICLR), 2014.

12

[7]

[8]

I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,
S. Ozair, A. Courville, and Y. Bengio, “Generative adversarial nets,” in
Advances in Neural Information Processing Systems (NIPS), 2014, pp.
2672–2680.
I. Goodfellow, Y. Bengio, and A. Courville, Deep Learning. MIT Press,
2016.

[9] A. Nguyen, J. Yosinski, Y. Bengio, A. Dosovitskiy, and J. Clune, “Plug
& play generative networks: Conditional iterative generation of images
in latent space,” arXiv:1612.00005, 2016.

[10] X. Chen, Y. Duan, R. Houthooft, J. Schulman, I. Sutskever, and
P. Abbeel, “Infogan: Interpretable representation learning by information
maximizing generative adversarial nets,” in Advances in Neural Informa-
tion Processing Systems (NIPS), 2016, pp. 2172–2180.

[11] C. Ledig, L. Theis, F. Huszar, J. Caballero, A. Cunningham, A. Acosta,
A. Aitken, A. Tejani, J. Totz, Z. Wang, and W. Shi, “Photo-Realistic Sin-
gle Image Super-Resolution Using a Generative Adversarial Network,”
arXiv:1609.04802, 2016.

[12] T. Salimans, I. Goodfellow, W. Zaremba, V. Cheung, A. Radford,
X. Chen, and X. Chen, “Improved techniques for training gans,” in
Advances in Neural Information Processing Systems (NIPS), 2016, pp.
2226–2234.

[13] A. Radford, L. Metz, and S. Chintala, “Unsupervised representation
learning with deep convolutional generative adversarial networks,” in
International Conference on Learning Representations (ICLR), 2015.
[14] L. Metz, B. Poole, D. Pfau, and J. Sohl-Dickstein, “Unrolled generative

adversarial networks,” arXiv:1611.02163, 2016.

[15] M. Arjovsky, S. Chintala,
arXiv:1701.07875, 2017.

and L. Bottou,

“Wasserstein gan,”

[16] G.-J. Qi, “Loss-sensitive generative adversarial networks on lipschitz

densities,” arXiv:1701.06264, 2017.

[17] C. M. Bishop, Pattern Recognition and Machine Learning, 2006.
[18] N. Kodali, J. Abernethy, J. Hays, and Z. Kira, “On convergence and

stability of gans,” arXiv:1705.07215, 2017.

[19] I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. Courville,
“Improved training of wasserstein gans,” in Advances in Neural Informa-
tion Processing Systems (NIPS), 2017.

[20] X. Mao, Q. Li, H. Xie, R. Y. Lau, Z. Wang, and S. P. Smolley, “Least
squares generative adversarial networks,” in International Conference on
Computer Vision (ICCV), 2017.

[21] G. W. Taylor, R. Fergus, Y. LeCun, and C. Bregler, “Convolutional learn-
ing of spatio-temporal features,” in European Conference on Computer
Vision (ECCV), 2010, pp. 140–153.

[22] G. E. Hinton and R. R. Salakhutdinov, “Replicated softmax: an undi-
rected topic model,” in Advances in Neural Information Processing
Systems (NIPS), 2009, pp. 1607–1614.

[23] G. E. Hinton, S. Osindero, and Y.-W. Teh, “A fast learning algorithm for
deep belief nets,” Neural Computation, vol. 18, no. 7, pp. 1527–1554,
Jul. 2006.

[24] Y. Ganin, E. Ustinova, H. Ajakan, P. Germain, H. Larochelle, F. Lavio-
lette, M. Marchand, and V. Lempitsky, “Domain-adversarial training of
neural networks,” The Journal of Machine Learning Research, vol. 17,
no. 1, pp. 2096–2030, 2016.

[25] S. Reed, Z. Akata, X. Yan, L. Logeswaran, B. Schiele, and H. Lee,
“Generative adversarial text-to-image synthesis,” in Proceedings of The
33rd International Conference on Machine Learning (ICML), 2016.
[26] P. Isola, J.-Y. Zhu, T. Zhou, and A. A. Efros, “Image-to-image translation
with conditional adversarial networks,” arXiv:1611.07004, 2016.
[27] M. Mirza and S. Osindero, “Conditional Generative Adversarial Nets,”

arXiv:1411.1784, 2014.

[28] J. Donahue, P. Kr¨ahenb¨uhl, and T. Darrell, “Adversarial feature learning,”
in International Conference on Learning Representations (ICLR), 2017.
[29] V. Dumoulin, I. Belghazi, B. Poole, O. Mastropietro, A. Lamb, M. Ar-
jovsky, and A. Courville, “Adversarially learned inference,” in Interna-
tional Conference on Learning Representations (ICLR), 2017.

[30] C. Li, H. Liu, C. Chen, Y. Pu, L. Chen, R. Henao, and L. Carin, “Alice:
Towards understanding adversarial learning for joint distribution match-
ing,” in Advances in Neural Information Processing Systems (NIPS),
2017.

[31] E. Denton, S. Chintala, A. Szlam, and R. Fergus, “Deep generative image
models using a laplacian pyramid of adversarial networks,” in Advances
in Neural Information Processing Systems (NIPS), 2015, pp. 1486–1494.
[32] X. Huang, Y. Li, O. Poursaeed, J. Hopcroft, and S. Belongie, “Stacked

generative adversarial networks,” arXiv:1612.04357, 2016.

[33] T. Che, Y. Li, A. P. Jacob, Y. Bengio, and W. Li, “Mode regularized

generative adversarial networks,” arXiv:1612.02136, 2016.

13

[34] S. Nowozin, B. Cseke, and R. Tomioka, “f-gan: Training gen-
erative neural samplers using variational divergence minimization,”
arXiv:1606.00709, 2016.

[35] J. Zhao, M. Mathieu, and Y. LeCun, “Energy-based Generative Adver-

sarial Network,” arXiv:1609.03126, 2016.

[36] Z. Dai, A. Almahairi, P. Bachman, E. Hovy, and A. Courville, “Cali-
brating energy-based generative adversarial networks,” in International
Conference on Learning Representations (ICLR), 2017.

[37] X. Nguyen, M. J. Wainwright, and M. I. Jordan, “Estimating divergence
functionals and the likelihood ratio by convex risk minimization,” IEEE
Transactions on Information Theory, vol. 56, no. 11, pp. 5847–5861,
2010.

[38] L. Mescheder, S. Nowozin, and A. Geiger, “The numerics of gans,” in
Advances in Neural Information Processing Systems (NIPS), 2017.
[39] K. Roth, A. Lucchi, S. Nowozin, and T. Hofmann, “Stabilizing training
of generative adversarial networks through regularization,” in Advances
in Neural Information Processing Systems (NIPS), 2017.

[40] W. Fedus, M. Rosca, B. Lakshminarayanan, A. M. Dai, S. Mohamed, and
I. Goodfellow, “Many paths to equilibrium: Gans do not need to decrease
a divergence at every step,” in International Conference on Learning
Representations (ICLR), 2018.

[41] F. Husz´ar, “How (not) to train your generative model: Scheduled sam-

pling, likelihood, adversary?” arXiv:1511.05101, 2015.

[42] A. B. Dieng, D. Tran, R. Ranganath, J. Paisley, and D. M. Blei,
“Variational inference via χ upper bound minimization,” in Advances
in Neural Information Processing Systems (NIPS), 2017.

[43] M. Abadi, A. Agarwal, P. Barham, and et al, “TensorFlow: Large-scale

machine learning on heterogeneous systems,” 2015.

[44] W. Zhang, J. Sun, and X. Tang, “Cat head detection - how to effectively
exploit shape and texture features,” in European Conference on Computer
Vision (ECCV), 2008, pp. 802–816.

[45] M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, and S. Hochreiter,
“Gans trained by a two time-scale update rule converge to a local nash
equilibrium,” in Advances in Neural Information Processing Systems
(NIPS), 2017.

[46] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”

arXiv:1412.6980, 2014.

[47] T. Tieleman and G. Hinton, “Lecture 6.5—RMSProp: Divide the gradient
by a running average of its recent magnitude,” COURSERA: Neural
Networks for Machine Learning, 2012.

[48] Y. Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu, and A. Y. Ng,
“Reading digits in natural images with unsupervised feature learning,” in
NIPS Workshop on Deep Learning and Unsupervised Feature Learning,
2011.

