Using Optimal Ratio Mask as Training Target for 
Supervised Speech Separation 

Shasha Xia, Hao Li and Xueliang Zhang 
Inner Mongolia University, Hohhot, China 
E-mail: cszxl@imu.edu.cn    Tel: +86-0471-4993132 
 
 
 

Abstractâ€”Supervised  speech  separation  uses  supervised 
learning algorithms to learn a mapping from an input noisy signal 
to an output target. With the fast development of deep learning, 
supervised separation has become the most important direction in 
speech  separation  area  in  recent  years.  For  the  supervised 
algorithm,  training  target  has  a  significant  impact  on  the 
performance. Ideal ratio mask is a commonly used training target, 
which  can  improve  the  speech  intelligibility  and  quality  of  the 
separated  speech.  However,  it  does  not  take  into  account  the 
correlation between noise and clean speech. In this paper, we use 
the optimal ratio mask as the training target of the deep neural 
network  (DNN)  for  speech  separation.  The  experiments  are 
carried out under various noise environments and signal to noise 
ratio  (SNR)  conditions.  The  results  show  that  the  optimal  ratio 
mask outperforms other training targets in general. 

I. 

INTRODUCTION 

Speech separation aims to extract the target speech signal from 
a noisy mixture and it is meaningful for many applications such 
as robust automatic speech recognition (ASR) and hearing aids 
design. Monaural speech separation is the most common case 
and  also  very  challenging,  because  only  one  channel  signal 
could  be  used.  In  this  study,  we  focus  on  monaural  speech 
separation. This problem has been studied for many years. The 
early  methods,  e.g.  spectral  subtraction  [1],  have  stationary 
assumptions on background noise, which limit their application. 
Computational auditory scene analysis (CASA) [2] stimulates 
human auditory mechanism and employs an Ideal binary mask 
(IBM)  [3]  as  the  computational  goal.  The  IBM  indicates  the 
target speech on a time-frequency (T-F) representation, where 
â€œ1â€ and â€œ0â€ indicates a T-F unit dominated by target speech and 
noise respectively. With this concept, it is natural to formulate 
the speech separation as a binary classification problem which 
can be solved by supervised learning algorithms. 

For the supervised speech separation, three key factors are 
mainly concerned, i.e. learning machines, features and training 
targets.  Several  learning  machines  have  been  investigated  in 
the literature, e.g. Gaussian mixture model (GMM) [4], support 
vector machine (SVM) [5] and Deep Neural Networks (DNN) 
[6].  Typically,  DNN-based  speech  separation  has  achieved  a 
great  success,  because  its  strong  learning  capacity  enables 
effective  modeling  of  nonlinear  interactions  between  speech 
and the acoustic environments as well as dynamic structure of 
speech.  Discriminative  features  are  also  important.  In  [7-8], 
extensive  features  are  studied  in  noisy  and  reverberant 
conditions.   

For the training target, we should keep in mind that the ideal 
target  can  obtain  good  separation  results,  and  its  estimation 
shouldnâ€™t be hard by current learning machines. The IBM and 
Ideal  Ratio  Mask  (IRM)  [9]  are  commonly  used  targets. 
Separating  with  the  IBM  usually  introduces  residual  musical 
noise  and  speech  quality  cannot  be  improved.  IRM  can  be 
thought  of  as  smooth  form  of  IBM,  which  improves  both 
speech  quality  and  intelligibility.  Recent  works  show  that 
phase  information  is  also  important  for  speech  separation. 
Based on these researches, complex Ideal Ratio Mask (cIRM) 
[10] and Phase Sensitive Mask (PSM) [11] were proposed. The 
cIRM  is  computed  on  complex  domain.  Although  the  cIRM 
can  perfectly  recover  the  target  speech,  it  increases  the 
difficulty  of  estimation.  The  PSM  introduces  the  phase 
information and operates on real domain.   

Recently, Optimal Ratio Mask (ORM) is proposed in [12], 
which can be viewed as an improved version of the IRM. The 
ORM considers the correlation between the target speech and 
noise in real environment. Theoretical analysis shows that the 
ORM  can  improve  the  SNR  over  the  IRM.  However,  is  the 
ORM a good training target for supervised speech separation 
algorithm? This key question, as we mentioned earlier, is not 
answered. 

This  paper  aims  to  investigate  the  performance  of  ORM 
when applied in DNN-based monaural speech separation. The 
rest of this paper is organized as follows: next Section describes 
the framework and procedure of DNN-based monaural speech 
separation system. In Section III, we describe the calculations 
of five training targets adopted for comparison. The results are 
shown in Section IV. We conclude the paper in the last Section. 

II.  DNN-BASED MONAURAL SPEECH SEPARATION 

The  framework  of  the  DNN-based  monaural  speech 
separation used in this study is same as in [9]. We use a set of 
complementary  features  consisting  of  amplitude  modulation 
spectrogram (AMS), relative spectral transform and perceptual 
linear  prediction  (RASTA-PLP)  and  Mel-frequency  cepstral 
coefficients (MFCC). The feature set used here is similar to the 
one  in  [9].  Since  useful  information  is  carried  across  time 
frames, a symmetric 5-frame context window is used to splice 
adjacent frames into a single feature vector.   

The DNN is composed of three hidden layers, each layer has 
1024  rectified  linear  hidden  units  (ReLU)  [13].  The  back 
propagation with dropout regularization (dropout rate 0.2) [14] 
is  used  for  network  training.  Adaptive  gradient  descent  [15] 

APSIPA ASC 2017 

coupled with a momentum term as the optimization technique. 
Momentum rate is 0.5 during first 5 epochs and 0.9 during the 
rest epochs. The goal of network training is to output an ideal 
estimation  of  training  target.  We  use  the  mean  squared  error 
(MSE)  as  cost  function.  The  number  of  output  units  is 
correspond  to  the  dimensionality  of  the  training  target.  The 
sigmoid  activation  function  is  applied  when  target  is  in  the 
range of [0, 1], otherwise linear activation function is applied. 
The general architecture is shown in Fig. 1. 
 

Fig. 1. The architecture of DNN-based speech separation. 

 

III.  THE OPTIMAL RATIO MASK 

The  definition  for  the  ORM  is  derived  by  minimizing  the 
mean square error (MSE) of clean speech and estimated target 
speech [12]. 

ğ›¾(ğ‘¡, ğ‘“) =

|ğ‘†(ğ‘¡, ğ‘“)|2 + â„›(ğ‘†(ğ‘¡, ğ‘“)ğ‘âˆ—(ğ‘¡, ğ‘“))
|ğ‘†(ğ‘¡, ğ‘“)|2 + |ğ‘(ğ‘¡, ğ‘“)|2 + 2â„›(ğ‘†(ğ‘¡, ğ‘“)ğ‘âˆ—(ğ‘¡, ğ‘“))

 

        (1) 
where,  ğ‘†(ğ‘¡, ğ‘“)  and  ğ‘(ğ‘¡, ğ‘“)  are  the  spectrum  of  speech  and 
noise  at  frame  ğ‘¡   and  frequency  ğ‘“ .  â„›(Â°)   denotes  the  real 
component of spectrum and â€˜*â€™ denotes the conjugate operation. 
It can be seen that ORM is very similar to IRM, except for 
the coherent part  â„›(ğ‘†(ğ‘¡, ğ‘“)ğ‘âˆ—(ğ‘¡, ğ‘“)), which is assumed to be 
0 in IRM. In fact, this assumption is too strong. Figure 2 shows 
the spectral coherence between  the  speech and the noise in a 
noisy  speech.  We  can  see  that  the  speech  and  the  noise  are 
highly  correlated.  The  ORM 
to  get  better 
performance for speech separation in [12]. 

is  proven 

 
Fig. 2. Coherence estimation of the speech and noise signals in a noisy 
speech. 

The ORM varies in the range of  (âˆ’âˆ, +âˆ)  that is not easy 
to  estimate.  So,  we  restrict  the  value  of  the  ORM  with  a 
hyperbolic tangent as in [9] 

ORM(ğ‘¡, ğ‘“) = ğ¾

1 âˆ’ ğ‘’âˆ’ğ‘ğ›¾(ğ‘¡,ğ‘“)
1 + ğ‘’âˆ’ğ‘ğ›¾(ğ‘¡,ğ‘“) 

(2) 
where,  c = 0.1  is  steepness  and  ğ¾=10  restricts  the  range  of 
the  ORM  to  (âˆ’10, +10) .  ğ›¾(ğ‘¡, ğ‘“)   is  the  original  ORM 
defined in eq. (1). 

IV.  VARIOUS TRAINING TARGETS 

In this section, we will introduce several mask targets. The 
separation system employing mask target is called mask-based 
speech separation.   

A. 

Ideal binary mask (IBM) 

The IBM the simplest mask which is defined as following. 

IBM(ğ‘¡, ğ‘“) = {

1,
0,

  

 ğ‘–ğ‘“ |ğ‘†(ğ‘¡, ğ‘“)|2 âˆ’ |ğ‘(ğ‘¡, ğ‘“)|2 > ğœƒ
ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’

 

(3) 
where  ğœƒ  is the local threshold in T-F units, and it is set to zero. 

B. 

Ideal ratio mask (IRM) 

From eq. (3), we can see that the IBM makes a hard decision 
according to the energy of speech and noise in T-F unit. IRM 
can be viewed as a soft decision, which is defined as, 

IRM(ğ‘¡, ğ‘“) = (

|ğ‘†(ğ‘¡, ğ‘“)|2
|ğ‘†(ğ‘¡, ğ‘“)|2 + |ğ‘(ğ‘¡, ğ‘“)|2)

ğ›½

 

(4) 

where  ğ›½  is a tunable parameter, which is usually set to 0.5. 

C.  Complex Ideal ratio mask (cIRM) 

The IBM and the IRM are constructed on the magnitude of 
the speech and the noise. Recent research showed that the phase 
information is also important for speech separation [16]. The 
cIRM  includes  the  phase  in  its  construction,  which  can  be 
viewed as the IRM in the complex domain. 

Given the spectrum Y of mixture, the spectrum S of speech 

signal can be generated as follows, 

S(ğ‘¡, ğ‘“) = ğ‘€(ğ‘¡, ğ‘“) âˆ— ğ‘Œ(ğ‘¡, ğ‘“)                      (5) 
where â€˜*â€™ is complex multiplication.  ğ‘€(ğ‘¡, ğ‘“)  is the complex 
mask which can be expressed as follows, 

M =

ğ‘Œğ‘Ÿğ‘†ğ‘Ÿ + ğ‘Œğ‘–ğ‘†ğ‘–
2 + ğ‘Œğ‘–
ğ‘Œğ‘Ÿ

2 + ğ‘–

ğ‘Œğ‘Ÿğ‘†ğ‘– âˆ’ ğ‘Œğ‘Ÿ
2 
2 + ğ‘Œğ‘–
ğ‘Œğ‘Ÿ

(6) 
where  ğ‘Œğ‘Ÿ ,  ğ‘Œğ‘– ,  ğ‘†ğ‘Ÿ   and  ğ‘†ğ‘–   stand  for  the  real  and  imaginary 
components of  ğ‘Œ  and  ğ‘†, respectively.   

D.  Phase sensitive mask (PSM) 

The  PSM  directly  uses  a  phase  sensitive  target  function, 

which involves both amplitude and phase information. 

PSM(ğ‘¡, ğ‘“) =

|ğ‘†(ğ‘¡, ğ‘“)|
|ğ‘Œ(ğ‘¡, ğ‘“)|

cos ğœƒ 

(7) 
where  ğœƒ = ğœƒ ğ‘† + ğœƒğ‘Œ   is  the  phase.  PSM  is  restricted  in  real 
domain. 

APSIPA ASC 2017 

(a)                                                            (b)                       

(c)                                                            (d)                       

(e)                                                            (f)                       

Fig. 3. Illustration of various mask targets. (a) is IBM; (b) is IRM; (c) and (d) 
are the real and imaginary parts of the cIRM; (e) is the PSM; (f) is the ORM. 

V.  EXPERIMENTAL RESULTS 

A.  Dateset 

We  use  600  randomly  chosen  utterances  from  the  IEEE 
female  corpus  as  our  training  utterances.  The  rest  of  120 
utterances  are  used  as  the  test  set.  Four  noises  from  the 
NOISEX dataset [17] are used as our training and test noises, 
including a speech-shaped noise (SSN), a babble noise (babble), 
a  factory  noise  (factory)  and  a  destroyer  engine  room  noise 
(engine). Except SNN, all other 3 noises are non-stationary. All 
noises are around 4 minutes long. To create the training set, we 
use random 10 slices from the first 2 minutes of each noise to 
mix  with  each  utterance  from  the  training  utterances  at  -3, 0 
and 3dB. Thus,  we  have 72000 (600 utterancesÃ—10 slicesÃ—4 
noisesÃ—3 SNR). The test mixtures are constructed by mixing 
random cuts from the last 2 minutes of each noise with the test 
utterances at -3, 0 and 3 dB. Cutting from different parts of the 
noises ensures that noise segments used in training and testing 
phase are different. 

B.  Evaluation Criteria 

We  use  the  Short-Time  Objective  Intelligibility  (STOI) 
score  [18]  to  measure  the  objective  intelligibility.  STOI 
denotes a correlation of short-time temporal envelopes between 
clean and separated speech, and has been proved to be highly 
correlated to human speech intelligibility score.  The value of 
STOI  is  in  the  range  of  [0,  1].  We  also  evaluate  objective 
speech  quality  using  the  Perceptual  Evaluation  of  Speech 

 

 

 

Quality  (PESQ)  score  [19].  Same  as  the  STOI,  the  PESQ  is 
calculated  by  comparing  the  separated  speech  with  the 
corresponding clean speech. The STOI score ranges from 0 to 
1, and PESQ score ranges from -0.5 to 4.5. 

C.  Results 

The separating results of the five training targets is given in 
table  1,  2,  3,  which  are  respectively  under  the  condition  of  -
3dB, 0dB, 3dB SNR mixture. Bold face indicates the target that 
performed best within a noise type. IBM and IRM are two most 
widely  used  training  targets.  Table  1~3  show  that  IBM 
improves speech intelligibility but not speech quality. This may 
due  to  the  binary  property  of  IBM,  and  musical  noise  is 
produced  during  the  separation.  Compared  to  IBM,  IRM 
improves  both  speech  intelligibility  and  speech  quality 
significantly, especially the speech quality. 
 

TABLE      I 
PERFORMANCE COMPARISONS BETWEEN VARIOUS TARGETS ON -3 DB 
MIXTURES 

PESQ 

STOI 

Targets 

SNN  Babble  Factory  Engine  SNN  Babble  Factory  Engine 

1.56 
1.65 
2.30 
2.45 
2.56 
2.63 

1.53 
0.84 
1.80 
1.76 
1.95 
1.93 

IBM 
IRM 
cIRM 
PSM 
ORM 

Mixture  1.37 
1.19 
2.05 
2.14 
2.23 
2.29 

1.39 
1.09 
1.94 
2.04 
2.15 
2.20 
 
TABLE      II 
PERFORMANCE COMPARISONS BETWEEN VARIOUS TARGETS ON 0 DB 
MIXTURES 

0.61 
0.69 
0.77 
0.76 
0.78 
0.77 

0.60 
0.63 
0.70 
0.70 
0.72 
0.71 

0.65 
0.81 
0.86 
0.85 
0.87 
0.86 

0.60 
0.68 
0.75 
0.74 
0.76 
0.75 

PESQ 

STOI 

Targets 

Mixture  1.53   
1.52   
2.32   
2.42   
2.53   
2.58   

IBM 
IRM 
cIRM 
PSM 
ORM 

SNN  Babble  Factory  Engine  SNN  Babble  Factory  Engine 
0.67   
0.77   
0.82   
0.82   
0.83   
0.83   

1.73   
1.23   
2.11   
2.13   
2.28   
2.30   

0.67   
0.74   
0.79   
0.79   
0.80   
0.80   

1.67   
1.87   
2.61   
2.64   
2.73   
2.80   

1.57   
1.43   
2.09   
2.32   
2.43   
2.49   

0.68   
0.78   
0.83   
0.83   
0.85   
0.84   

0.71   
0.86   
0.90   
0.89   
0.90   
0.90   

 

TABLE      III 
PERFORMANCE COMPARISONS BETWEEN VARIOUS TARGETS ON 3 DB 
MIXTURES 

PESQ 

STOI 

Targets 

Mixture  1.72   
1.76   
2.56   
2.67   
2.74   
2.81   

IBM 
IRM 
cIRM 
PSM 
ORM 

SNN  Babble  Factory  Engine  SNN  Babble  Factory  Engine 
0.74   
0.84   
0.87   
0.87   
0.88   
0.88   

1.91   
1.64   
2.40   
2.45   
2.55   
2.60   

0.74   
0.83   
0.86   
0.86   
0.87   
0.87   

1.80   
2.08   
2.77   
2.86   
2.90   
2.95   

1.73   
1.73   
2.39   
2.58   
2.67   
2.73   

0.74   
0.84   
0.88   
0.88   
0.89   
0.89   

0.78   
0.90   
0.92   
0.92   
0.93   
0.92   

 
cIRM, PSM and ORM are training targets proposed recent 
years whose value various in a large range. cIRM performs best 
theoretically,  the  result  shows  it  outperforms  IRM  on 
improvement  of  speech  quality,  whereas  its  improvement  of 
speech  intelligibility  is  close  to  IRM.  cIRM  and  PSM  both 
concerned about phase information, cIRM operates on complex 
domain while PSM on real domain. Table 1~3 show that PSM 
improves  speech  intelligibility  by  1%~2%  and  12%~22% 
compared  to  cIRM  and  unprocessed  mixture,  outperforms 
other  training  targets.  PSM  improves  speech  quality  by 
0.07~0.19  compared  to  cIRM.  This  maybe  because  that 

APSIPA ASC 2017 

REFERENCES 

[1]  S.  Boll  â€œSuppression  of  acoustic  noise  in  speech  using  spectral 
subtraction,â€ IEEE Trans. on acoust., speech, and signal process., vol. 27, 
pp. 113-120, 1979. 

[2]  D.L.  Wang  and  G.J.  Brown,  Eds.,  Computational  Auditory  Scene 
Analysis:  Principles,  Algorithms,  and  Applications,  Hobboken,  NJ: 
Wiley-IEEE Press, 2006. 

[3]  D.L  Wang,  â€œOn  Ideal  Binary  Mask  as  the  Computational  Goal  of 
Auditory  Scene  Analysis,â€  in  P.  Divenyi  (Ed.),  Speech  Separation  by 
Humans and Machines, Kluwer Academic, Norwell MA, 2005:181-197, 
2005. 

[4]  G.  Kim,  Y.  Lu,  Y.  Hu  and  P.C.  Loizou,  â€œAn  algorithm  that  improves 
speech intelligibility in noise for normal-hearing listeners,â€ J. Acoust. Soc. 
Amer., vol. 126, pp. 1486â€“1494, 2009. 

[5]  K.  Han  and  D.L.  Wang,  â€œA  classification  based  approach  to  speech 
segregation,â€ Journal of the Acoust. Society of Amer., vol. 132, pp. 3475-
3483, 2012. 

[6]  Y.  Wang  and  D.L.  Wang,  â€œCocktail  party  processing  via  structured 

prediction,â€ Proceedings of NIPS-12, pp. 224-232, 2012. 

[7]  J.  Chen,  Y.  Wang  and  D.L.  Wang,  â€œA  feature  study  for  classification-
based speech separation at low signal-to-noise ratios,â€ IEEE/ACM Trans. 
on Audio, Speech, and Lang. Process., vol. 22, pp. 1993-2002, 2014. 
[8]  M.  Delfarah  and  D.L.  Wang,  â€œFeatures  for  masking-based  monaural 
speech separation in reverberant conditions,â€ IEEE/ACM Trans. on Audio, 
Speech, and Lang. Process., vol. 25, pp. 1085-1094, 2017. 

[9]  Y.  Wang,  A.  Narayanan  and  D.L.  Wang,  â€œOn  training  targets  for 
supervised speech separation,â€ IEEE/ACM Trans. on Audio, Speech, and 
Lang. Process., vol. 22, pp. 1849-1858, 2014. 

[10]  D.S. Williamson, Y. Wang and D.L. Wang, â€œComplex ratio masking for 
monaural speech separation,â€ IEEE/ACM Trans. on Audio, Speech, and 
Lang. Process, vol. 24, pp. 483-492, 2016. 

[11]  H.  Erdogan,  J.R.  Hershey,  S.  Watanabe,  et  al.  â€œPhase-sensitive  and 
recognition-boosted  speech  separation  using  deep  recurrent  neural 
networks,â€ ICASSP, pp. 708-712, 2015. 

[12]  S. Liang S, W. Liu, W. Jiang,  et al. â€œThe optimal ratio time-frequency 
mask for speech separation in terms of the signal-to-noise ratio,â€ Journal 
of the Acoust. Society of Amer., vol. 134, pp.452-458, 2013. 

[13]  V.  Nair  and  G.  Hinton,  â€œRectified  linear  units  improve  restricted 

boltzmann machines,â€ In Proc. ICML 2010 pp. 807-814. 

[14]  N. Srivastava, G. Hinton, A. Krizhevsky, et al. â€œDropout: A simple way 
to  prevent  neural  networks  from  overfitting,â€  The  Journal  of  Machine 
Learn. Resear., vol. 15, pp. 1929-1958, 2014. 

[15]  J.  Duchi,  E.  Hazan  and  Y.  Singer,  â€œAdaptive  subgradient  methods  for 
online  learning  and  stochastic  optimization,â€  The  Journal  of  Machine 
Learning Research, vol. 12, pp. 2121-2159, 2011. 

[16]  K. Paliwal,  K. WÃ³jcicki and B. Shannon, â€œThe importance of phase in 
speech enhancement,â€ Speech Commun., vol. 53, pp. 465-494, 2011. 
[17]  A.  Varga  and  H.  Steeneken,  â€œAssessment  for  automatic  speech 
recognition: II. NOISEX-92: A database and an experiment to study the 
effect of additive noise on speech recognition systems,â€ Speech Commun., 
vol. 12, pp. 247â€“251, 1993. 

[18]  C.  Taal,  R.  Hendriks,  R.  Heusdens,  and  J.  Jensen,  â€œAn  algorithm  for 
intelligibility prediction of time-frequency weighted noisy speech,â€ IEEE 
Trans. Audio, Speech, Lang. Process., vol. 19, pp. 2125â€“2136, 2011. 
[19]  A. Rix, J. Beerends, M. Hollier, and A. Hekstra, â€œPerceptual evaluation 
of speech quality (PESQ)-a new method for speech quality assessment of 
telephone networks and codecs,â€ in Proc. ICASSP, pp. 749â€“752, 2001. 

structure of the imagine component of cIRM is not obvious and 
difficult to estimate, which lead to its poor actual performance. 
Table  I,  II  and  III  show  that  the  improvement  on  speech 
intelligibility  of  ORM  and  PSM  are  close,  while  ORM 
outperforms PSM on speech quality. We can see from Table I 
that improvement of ORM is 1% lower than PSM while better 
than  other  training  targets.  For  the  speech  quality,  on  SSN, 
Engine  and  Factory  noise,  ORM  performs  best,  which 
improves  0.81~1.07  compared  to  unprocessed  mixture  and 
0.05~0.07 compared to PSM. In Table II, performance of ORM 
is  close  to  PSM  on  speech  intelligibility.  ORM  outperforms 
other training targets on speech quality. In Table III, on engine 
noise PSM is little bit better than ORM, while on other noise 
their  performance  are  close  as  to  speech  intelligibility  ORM 
outperforms  other 
In  general,  ORM 
outperforms  other  training  targets.  ORM  concerns  about  the 
correlation  between  clean  speech  and  noise  while  PSM 
concerns  about  the  phase  information.  ORM  performs  better 
than PSM may due to that the correlation between clean speech 
and noise have greater impact on speech separation than phase 
information,  the  estimated  target  signal  is  closer  to  clean 
speech. Fig 5 shows STFT spectrogram of mixture on Babble 
noise at 3dB and target speech separated with IBM, IRM, cIRM, 
ORM, PSM as the training targets. 

training 

targets. 

VI.  CONCLUSIONS 

Monaural speech separation is always a challenging task in 
the  area  of  speech  recognition.  Supervised  speech  separation 
integrates deep neural network technology which emerged as a 
new  trend  in  recent  years,  impressive  improvements  are 
achieved  under  low  SNR  mixture  and  non-stationary  noise 
condition.  The  IBM  and  IRM  are  the  most  popular  training 
targets. However, IBM improves speech intelligibility but not 
speech  quality.  IRM  improves  both  speech  intelligibility  and 
speech  quality  under  the  assumption  that  clean  speech  is 
independent  with  noise.  Recent  research  prove  that  phase 
information is important for speech separation, cIRM and PSM 
were  proposed.  cIRM  performs  well  theoretically,  while  the 
structure of its imagine component is not obvious, difficult to 
estimate.  PSM  improves  speech  intelligibility  and  speech 
quality significantly, outperform other training targets.   

In  this  paper,  we  adapt  ORM  as  training  target,  which 
concerns about the correlation between clean speech and noise, 
the result shows that ORM performs better than other training 
targets  in  general.  This  maybe  because  that  there  is  relation 
between clean speech and noise in real environment and have 
greater  impact  on  speech  separation  than  phase  information. 
Based  on  this,  we  think  the  analyses  of  the  relation  between 
clean speech and noise and how to describe and estimate it is 
going  to  be  a  new  direction  in  the  area  of  training  target 
research. 

ACKNOWLEDGMENT 

This  research  was  supported  in  part  by  a  China  National 

Nature Science Foundation grant (No. 61365006), 

APSIPA ASC 2017 

