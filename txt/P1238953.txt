Style Transfer Through Back-Translation

Shrimai Prabhumoye, Yulia Tsvetkov, Ruslan Salakhutdinov, Alan W Black
Carnegie Mellon University, Pittsburgh, PA, USA
{sprabhum,ytsvetko,rsalakhu,awb}@cs.cmu.edu

8
1
0
2
 
y
a
M
 
4
2
 
 
]
L
C
.
s
c
[
 
 
3
v
0
0
0
9
0
.
4
0
8
1
:
v
i
X
r
a

Abstract

Style transfer is the task of rephrasing the
text to contain speciﬁc stylistic proper-
ties without changing the intent or affect
within the context. This paper introduces
a new method for automatic style trans-
fer. We ﬁrst learn a latent representation of
the input sentence which is grounded in a
language translation model in order to bet-
ter preserve the meaning of the sentence
while reducing stylistic properties. Then
adversarial generation techniques are used
to make the output match the desired style.
We evaluate this technique on three dif-
sentiment,
ferent style transformations:
gender and political slant.
Compared
to two state-of-the-art style transfer mod-
eling techniques we show improvements
both in automatic evaluation of style trans-
fer and in manual evaluation of meaning
preservation and ﬂuency.

1

Introduction

Intelligent, situation-aware applications must pro-
duce naturalistic outputs,
lexicalizing the same
meaning differently, depending upon the envi-
ronment. This is particularly relevant for lan-
guage generation tasks such as machine trans-
lation (Sutskever et al., 2014; Bahdanau et al.,
2015), caption generation (Karpathy and Fei-Fei,
2015; Xu et al., 2015), and natural language gen-
eration (Wen et al., 2017; Kiddon et al., 2016). In
conversational agents (Ritter et al., 2011; Sordoni
et al., 2015; Vinyals and Le, 2015; Li et al., 2016),
for example, modulating the politeness style, to
sound natural depending upon a situation: at a
the video is start-
party with friends “Shut up!
ing!”, or in a professional setting “Please be quiet,
the video will begin shortly.”.

These goals have motivated a considerable
amount of recent research efforts focused at “con-
trolled” language generation—aiming at separat-
ing the semantic content of what is said from
the stylistic dimensions of how it is said. These
include approaches relying on heuristic substitu-
tions, deletions, and insertions to modulate de-
mographic properties of a writer (Reddy and
Knight, 2016),
integrating stylistic and demo-
graphic speaker traits in statistical machine trans-
lation (Rabinovich et al., 2016; Niu et al., 2017),
and deep generative models controlling for a par-
ticular stylistic aspect, e.g., politeness (Sennrich
et al., 2016), sentiment, or tense (Hu et al., 2017;
Shen et al., 2017). The latter approaches to style
transfer, while more powerful and ﬂexible than
heuristic methods, have yet to show that in addi-
tion to transferring style they effectively preserve
meaning of input sentences.

This paper introduces a novel approach to trans-
ferring style of a sentence while better preserv-
ing its meaning. We hypothesize—relying on the
study of Rabinovich et al. (2016) who showed
that author characteristics are signiﬁcantly ob-
fuscated by both manual and automatic machine
translation—that grounding in back-translation is
a plausible approach to rephrase a sentence while
reducing its stylistic properties. We thus ﬁrst use
back-translation to rephrase the sentence and re-
duce the effect of the original style; then, we gen-
erate from the latent representation, using separate
style-speciﬁc generators controlling for style (§2).
We focus on transferring author attributes:
(1) gender and (2) political slant, and (3) on sen-
timent modiﬁcation. The second task is novel:
given a sentence by an author with a particular po-
litical leaning, rephrase the sentence to preserve
its meaning but to confound classiﬁers of politi-
cal slant (§3). The task of sentiment modiﬁcation
enables us to compare our approach with state-of-

Figure 1: Style transfer pipeline: to rephrase a sentence and reduce its stylistic characteristics, the sen-
tence is back-translated. Then, separate style-speciﬁc generators are used for style transfer.

the-art models (Hu et al., 2017; Shen et al., 2017).
Style transfer is evaluated using style classi-
ﬁers trained on held-out data. Our back-translation
style transfer model outperforms the state-of-the-
art baselines (Shen et al., 2017; Hu et al., 2017)
on the tasks of political slant and sentiment mod-
iﬁcation; 12% absolute improvement was attained
for political slant transfer, and up to 7% absolute
improvement in modiﬁcation of sentiment (§5).
Meaning preservation was evaluated manually, us-
ing A/B testing (§4). Our approach performs bet-
ter than the baseline on the task of transferring
gender and political slant. Finally, we evaluate the
ﬂuency of the generated sentences using human
evaluation and our model outperforms the baseline
in all experiments for ﬂuency.

The main contribution of this work is a new
approach to style transfer that outperforms state-
of-the-art baselines in both the quality of input–
output correspondence (meaning preservation and
ﬂuency), and the accuracy of style transfer. The
secondary contribution is a new task that we pro-
pose to evaluate style transfer: transferring politi-
cal slant.

2 Methodology

1 , . . . , x(n)

Given two datasets X 1 = {x(1)
1 } and
X 2 = {x(1)
2 , . . . , x(n)
2 } which represent two dif-
ferent styles s1 and s2, respectively, our task is to
generate sentences of the desired style while pre-
serving the meaning of the input sentence. Speciﬁ-
cally, we generate samples of dataset X 1 such that
they belong to style s2 and samples of X 2 such
that they belong to style s1. We denote the out-
put of dataset X 1 transfered to style s2 as ˆX 1 =
{ˆx(1)
2 } and the output of dataset X 2
transferred to style s1 as ˆX 2 = {ˆx(1)
1 }.
Hu et al. (2017) and Shen et al. (2017) in-
troduced state-of-the-art style transfer models
that use variational auto-encoders (Kingma and

2 , . . . , ˆx(n)

1 , . . . , ˆx(n)

Welling, 2014, VAEs) and cross-aligned auto-
encoders, respectively, to model a latent content
variable z. The latent content variable z is a code
which is not observed. The generative model con-
ditions on this code during the generation pro-
cess. Our aim is to design a latent code z which
(1) represents the meaning of the input sentence
grounded in back-translation and (2) weakens the
style attributes of author’s traits. To model the
former, we use neural machine translation. Prior
work has shown that the process of translating a
sentence from a source language to a target lan-
guage retains the meaning of the sentence but does
not preserve the stylistic features related to the au-
thor’s traits (Rabinovich et al., 2016). We hypoth-
esize that a latent code z obtained through back-
translation will normalize the sentence and devoid
it from style attributes speciﬁc to author’s traits.

Figure 1 shows the overview of the proposed
In our framework, we ﬁrst train a ma-
method.
chine translation model from source language e
to a target language f . We also train a back-
translation model from f to e. Let us assume our
styles s1 and s2 correspond to DEMOCRATIC and
REPUBLICAN style, respectively. In Figure 1, the
input sentence i thank you, rep. visclosky.
is la-
beled as DEMOCRATIC. We translate the sentence
using the e → f machine translation model and
generate the parallel sentence in the target lan-
guage f : je vous remercie, rep. visclosky. Using
the ﬁxed encoder of the f → e machine transla-
tion model, we encode this sentence in language
f . The hidden representation created by this en-
coder of the back-translation model is used as z.
We condition our generative models on this z. We
then train two separate decoders for each style
s1 and s2 to generate samples in these respective
styles in source language e. Hence the sentence
could be translated to the REPUBLICAN style us-
ing the decoder for s2. For example, the sentence
i’m praying for you sir. is the REPUBLICAN ver-

Figure 2: The latent representation from back-translation and the style classiﬁer feedback are used to
guide the style-speciﬁc generators.

sion of the input sentence and i thank you, senator
visclosky. is the more DEMOCRATIC version of it.
Note that in this setting, the machine translation
and the encoder of the back-translation model re-
main ﬁxed. They are not dependent on the data
we use across different tasks. This facilitates re-
usability and spares the need of learning separate
models to generate z for a new style data.

2.1 Meaning-Grounded Representation

In this section we describe how we learn the la-
tent content variable z using back-translation. The
e → f machine translation and f → e back-
translation models are trained using a sequence-to-
sequence framework (Sutskever et al., 2014; Bah-
danau et al., 2015) with style-agnostic corpus. The
style-speciﬁc sentence i thank you, rep. visclosky.
in source language e is translated to the target lan-
guage f to get je vous remercie, rep. visclosky.
The individual tokens of this sentence are then
encoded using the encoder of the f → e back-
translation model. The learned hidden representa-
tion is z.

Formally, let θE represent the parameters of the
encoder of f → e translation system. Then z is
given by:

for each style. The sentence generated by a de-
coder is passed through the classiﬁer. The loss
of the classiﬁer for the generated sentence is used
as feedback to guide the decoder for the gener-
ation process. The target attribute of the clas-
siﬁer is determined by the decoder from which
the output is generated. For example, in the case
of DEMOCRATIC decoder, the target attribute is
DEMOCRATIC and for the REPUBLICAN decoder
the target is REPUBLICAN.

2.2.1 Style Classiﬁers

We train a convolutional neural network (CNN)
classiﬁer to accurately predict the given style. We
also use it to evaluate the error in the generated
samples for the desired style. We train the classi-
ﬁer in a supervised manner. The classiﬁer accepts
either discrete or continuous tokens as inputs. This
is done such that the generator output can be used
as input to the classiﬁer. We need labeled exam-
ples to train the classiﬁer such that each instance
in the dataset X should have a label in the set
s = {s1, s2}. Let θC denote the parameters of
the classiﬁer. The objective to train the classiﬁer
is given by:

z = Encoder(xf ; θE)

(1)

Lclass(θC) = EX [log qC(s|x)].

(2)

where, xf is the sentence x in language f . Specif-
ically, xf is the output of e → f translation sys-
tem when xe is given as input. Since z is derived
from a non-style speciﬁc process, this Encoder is
not style speciﬁc.

2.2 Style-Speciﬁc Generation

Figure 2 shows the architecture of the generative
model for generating different styles. Using the
encoder embedding z, we train multiple decoders

To improve the accuracy of the classiﬁer, we aug-
ment classiﬁer’s inputs with style-speciﬁc lexi-
cons. We concatenate binary style indicators to
each input word embedding in the classiﬁer. The
indicators are set to 1 if the input word is present
in a style-speciﬁc lexicon; otherwise they are set to
0. Style lexicons are extracted using the log-odds
ratio informative Dirichlet prior (Monroe et al.,
2008), a method that identiﬁes words that are sta-
tistically overrepresented in each of the categories.

2.2.2 Generator Learning
We use a bidirectional LSTM to build our de-
coders which generate the sequence of tokens ˆx =
{x1, · · · xT }. The sequence ˆx is conditioned on
the latent code z (in our case, on the machine
translation model).
In this work we use a cor-
pus translated to French by the machine transla-
tion system as the input to the encoder of the back-
translation model. The same encoder is used to en-
code sentences of both styles. The representation
created by this encoder is given by Eq 1. Samples
are generated as follows:

ˆx ∼ z = p(ˆx|z)

=

p(ˆxt|ˆx<t, z)

(cid:89)

t

(3)

(4)

where, ˆx<t are the tokens generated before ˆxt.

Tokens are discrete and non-differentiable. This
makes it difﬁcult to use a classiﬁer, as the gen-
eration process samples discrete tokens from the
multinomial distribution parametrized using soft-
max function at each time step t. This non-
in turn, breaks down gradient
differentiability,
propagation from the discriminators to the gen-
erator.
Instead, following Hu et al. (2017) we
use a continuous approximation based on softmax,
along with the temperature parameter which an-
neals the softmax to the discrete case as training
proceeds. To create a continuous representation of
the output of the generative model which will be
given as an input to the classiﬁer, we use:

ˆxt ∼ softmax(ot/τ ),

where, ot is the output of the generator and τ is the
temperature which decreases as the training pro-
ceeds. Let θG denote the parameters of the gen-
erators. Then the reconstruction loss is calculated
using the cross entropy function, given by:

Lrecon(θG; x) = EqE (z|x)[log pgen(x|z)]

(5)

Here, the back-translation encoder E creates the
latent code z by:

z = E(x) = qE(z|x)

(6)

The generative loss Lgen is then given by:

minθgenLgen = Lrecon + λcLclass

(7)

where Lrecon is given by Eq. (5), Lclass is given
by Eq (2) and λc is a balancing parameter.

We also use global attention of (Luong et al.,
2015) to aid our generators. At each time step t of
the generation process, we infer a variable length
alignment vector at:

at =

(cid:80)

exp(score(ht, ¯hs))
s(cid:48) exp(score(ht, ¯hs(cid:48) )

(8)

t , ¯hs),

score(ht, ¯hs) = dot(hT

(9)
where ht is the current target state and ¯hs are all
source states. While generating sentences, we use
the attention vector to replace unknown characters
(UNK) using the copy mechanism in (See et al.,
2017).

3 Style Transfer Tasks

Much work in computational social science has
shown that people’s personal and demographic
characteristics—either publicly observable (e.g.,
age, gender) or private (e.g.,
religion, politi-
cal afﬁliation)—are revealed in their linguistic
choices (Nguyen et al., 2016). There are practi-
cal scenarios, however, when these attributes need
to be modulated or obfuscated. For example,
some users may wish to preserve their anonymity
online, for personal security concerns (Jardine,
2016), or to reduce stereotype threat (Spencer
et al., 1999). Modulating authors’ attributes while
preserving meaning of sentences can also help
generate demographically-balanced training data
for a variety of downstream applications.

Moreover, prior work has shown that the qual-
ity of language identiﬁcation and POS tagging
degrades signiﬁcantly on African American Ver-
nacular English (Blodgett et al., 2016; Jørgensen
et al., 2015); YouTube’s automatic captions have
higher error rates for women and speakers from
Synthesiz-
Scotland (Rudinger et al., 2017).
ing balanced training data—using style transfer
techniques—is a plausible way to alleviate bias
present in existing NLP technologies.

We thus focus on two tasks that have practi-
cal and social-good applications, and also accu-
rate style classiﬁers. To position our method with
respect to prior work, we employ a third task of
sentiment transfer, which was used in two state-
of-the-art approaches to style transfer (Hu et al.,
2017; Shen et al., 2017). We describe the three
tasks and associated dataset statistics below. The
methodology that we advocate is general and can
be applied to other styles, for transferring various

social categories, types of bias, and in multi-class
settings.

Gender.
In sociolinguistics, gender is known to
be one of the most important social categories
driving language choice (Eckert and McConnell-
Ginet, 2003; Lakoff and Bucholtz, 2004; Coates,
2015). Reddy and Knight (2016) proposed a
heuristic-based method to obfuscate gender of a
writer. This method uses statistical association
measures to identify gender-salient words and sub-
stitute them with synonyms typically of the oppo-
site gender. This simple approach produces highly
ﬂuent, meaning-preserving sentences, but does not
allow for more general rephrasing of sentence be-
yond single-word substitutions. In our work, we
adopt this task of transferring the author’s gender
and adapt it to our experimental settings.

We used Reddy and Knight’s (2016) dataset of
reviews from Yelp annotated for two genders cor-
responding to markers of sex.1 We split the re-
views to sentences, preserving the original gender
labels. To keep only sentences that are strongly
indicative of a gender, we then ﬁltered out gender-
neutral sentences (e.g., thank you) and sentences
whose likelihood to be written by authors of one
gender is lower than 0.7.2

Political slant. Our second dataset is comprised
of top-level comments on Facebook posts from all
412 current members of the United States Sen-
ate and House who have public Facebook pages
(Voigt et al., 2018).3 Only top-level comments
that directly respond to the post are included. Ev-
ery comment to a Congressperson is labeled with
the Congressperson’s party afﬁliation: democratic
or republican. Topic and sentiment in these com-
ments reveal commenter’s political slant. For ex-
ample, defund them all, especially when it comes
to the illegal immigrants . and thank u james,
praying for all the work u do . are republican,
whereas on behalf of the hard-working nh public
school teachers- thank you ! and we need more
strong voices like yours ﬁghting for gun control .

1We note that gender may be considered along a spec-
trum (Eckert and McConnell-Ginet, 2003), but use gender
as a binary variable due to the absence of corpora with
continuous-valued gender annotations.

2We did not experiment with other threshold values.
3The posts and comments are all public; however, to pro-
tect the identity of Facebook users in this dataset Voigt et al.
(2018) have removed all identifying user information as well
as Facebook-internal information such as User IDs and Post
IDs, replacing these with randomized ID numbers.

Style
gender
political
sentiment

dev

train

class
test
2.57M 2.67M 4.5K 535K
540K
80K
56K
4K
444K 63.5K 127K
2M

Table 1: Sentence count in style-speciﬁc corpora.

represent examples of democratic sentences. Our
task is to preserve intent of the commenter (e.g.,
to thank their representative), but to modify their
observable political afﬁliation, as in the example
in Figure 1. We preprocessed and ﬁltered the
comments similarly to the gender-annotated cor-
pus above.

Sentiment. To compare our work with the state-
of-the-art approaches of style transfer for non-
parallel corpus we perform sentiment
transfer,
replicating the models and experimental setups of
Hu et al. (2017) and Shen et al. (2017). Given a
positive Yelp review, a style transfer model will
generate a similar review but with an opposite sen-
timent. We used Shen et al.’s (2017) corpus of
reviews from Yelp. They have followed the stan-
dard practice of labeling the reviews with rating of
higher than three as positive and less than three as
negative. They have also split the reviews to sen-
tences and assumed that the sentence has the same
sentiment as the review.

Dataset statistics. We summarize below cor-
pora statistics for the three tasks: transferring gen-
der, political slant, and sentiment. The dataset for
sentiment modiﬁcation task was used as described
in (Shen et al., 2017). We split Yelp and Facebook
corpora into four disjoint parts each: (1) a training
corpus for training a style classiﬁer (class); (2) a
training corpus (train) used for training the style-
speciﬁc generative model described in §2.2; (3)
development and (4) test sets. We have removed
from training corpora class and train all sentences
that overlap with development and test corpora.
Corpora sizes are shown in Table 1.

Table 2 shows the approximate vocabulary sizes
used for each dataset. The vocabulary is the same
for both the styles in each experiment.

Style
Vocabulary

gender
20K

political
20K

sentiment
10K

Table 2: Vocabulary sizes of the datasets.

Table 3 summarizes sentence statistics. All the

sentences have maximum length of 50 tokens.

Style
male
female
republican
democratic
negative
positive

Avg. Length %data
50.00
50.00
50.00
50.00
39.81
60.19

18.08
18.21
16.18
16.01
9.66
8.45

Table 3: Average sentence length and class distri-
bution of style corpora.

5 Results

4 Experimental Setup

In what follows, we describe our experimental set-
tings, including baselines used, hyperparameter
settings, datasets, and evaluation setups.

Baseline. We compare our model against the
“cross-aligned” auto-encoder (Shen et al., 2017),
which uses style-speciﬁc decoders to align the
style of generated sentences to the actual distribu-
tion of the style. We used the off-the-shelf senti-
ment model released by Shen et al. (2017) for the
sentiment experiments. We also separately train
this model for the gender and political slant using
hyper-parameters detailed below.4

Translation data. We trained an English–
French neural machine translation system and a
French–English back-translation system. We used
data from Workshop in Statistical Machine Trans-
lation 2015 (WMT15) (Bojar et al., 2015) to train
our translation models. We used the French–
English data from the Europarl v7 corpus, the
news commentary v10 corpus and the common
crawl corpus from WMT15. Data were tokenized
using the Moses tokenizer (Koehn et al., 2007).
Approximately 5.4M English–French parallel sen-
tences were used for training. A vocabulary size of
100K was used to train the translation systems.

Hyperparameter settings.
the experi-
ments, the generator and the encoders are a two-
layer LSTM with an input size of 300 and the hid-
den dimension of 500. The encoders are bidirec-

In all

4In addition, we compared our model with the current
state-of-the-art approach introduced by Hu et al. (2017); Shen
et al. (2017) use this method as baseline, obtaining compara-
ble results. We reproduced the results reported in (Hu et al.,
2017) using their tasks and data. However, the same model
trained on our political slant datasets (described in §3), ob-
tained an almost random accuracy of 50.98% in style transfer.
We thus omit these results.

tional. The generator samples a sentence of max-
imum length 50. All the generators use global at-
tention vectors of size 500. The CNN classiﬁer
is trained with 100 ﬁlters of size 5, with max-
the
pooling. The input to CNN is of size 302:
300-dimensional word embedding plus two bits
for membership of the word in our style lexicons,
as described in §2.2.1. Balancing parameter λc is
set to 15. For sentiment task, we have used set-
tings provided in (Shen et al., 2017).

We evaluate our approach along three dimensions.
(1) Style transfer accuracy, measuring the propor-
tion of our models’ outputs that generate sentences
of the desired style. The style transfer accuracy
is performed using classiﬁers trained on held-out
train data that were not used in training the style
transfer models. (2) Preservation of meaning. (3)
Fluency, measuring the readability and the natu-
ralness of the generated sentences. We conducted
human evaluations for the latter two.

In what follows, we ﬁrst present the quality of
our neural machine translation systems, then we
present the evaluation setups, and then present the
results of our experiments.

quality. The

Translation
BLEU scores
achieved for English–French MT system is
32.52 and for French–English MT system is
31.11; these are strong translation systems. We
deliberately chose a European language close to
English for which massive amounts of parallel
data are available and translation quality is high,
to concentrate on the style generation, rather than
improving a translation system. 5

5.1 Style Transfer Accuracy

We measure the accuracy of style transfer for the
generated sentences using a pre-trained style clas-
siﬁer (§2.2.1). The classiﬁer is trained on data that
is not used for training our style transfer genera-
tive models (as described in §3). The classiﬁer has
an accuracy of 82% for the gender-annotated cor-
pus, 92% accuracy for the political slant dataset
and 93.23% accuracy for the sentiment dataset.

5Alternatively, we could use a pivot language that is ty-
pologically more distant from English, e.g., Chinese. In this
case we hypothesize that stylistic traits would be even less
preserved in translation, but the quality of back-translated
sentences would be worse. We have not yet investigated how
the accuracy of the translation model, nor the language of
translation affects our models.

We transfer the style of test sentences and then
test the classiﬁcation accuracy of the generated
sentences for the opposite label. For example, if
we want to transfer the style of male Yelp reviews
to female, then we use the ﬁxed common encoder
of the back-translation model to encode the test
male sentences and then we use the female gener-
ative model to generate the female-styled reviews.
We then test these generated sentences for the fe-
male label using the gender classiﬁer.

Experiment
Gender
Political slant
Sentiment

CAE
60.40
75.82
80.43

BST
57.04
88.01
87.22

Table 4: Accuracy of the style transfer in gener-
ated sentences.

In Table 4, we detail the accuracy of each
classiﬁer on generated style-transfered sentences.6
We denote the Shen et al.’s (2017) Cross-aligned
Auto-Encoder model as CAE and our model as
Back-translation for Style Transfer (BST).

On two out of three tasks our model substan-
tially outperforms the baseline, by up to 12% in
political slant transfer, and by up to 7% in senti-
ment modiﬁcation.

5.2 Preservation of Meaning

Although we attempted to use automatics mea-
sures to evaluate how well meaning is preserved
in our transformations; measures such as BLEU
(Papineni et al., 2002) and Meteor (Denkowski
and Lavie, 2011), or even cosine similarity be-
tween distributed representations of sentences do
not capture this distance well.

Meaning preservation in style transfer is not
trivial to deﬁne as literal meaning is likely to
change when style transfer occurs. For example
“My girlfriend loved the desserts” vs “My partner
liked the desserts”. Thus we must relax the con-
dition of literal meaning to intent or affect of the
utterance within the context of the discourse. Thus
if the intent is to criticize a restaurant’s service
in a review, changing “salad” to “chicken” could
still have the same effect but if the intent is to or-
der food that substitution would not be acceptable.
Ideally we wish to evaluate transfer within some

6In each experiment, we report aggregated results across
directions of style transfer; same results broke-down to style
categories are listed in the Supplementary Material.

Experiment
Gender
Political slant
Sentiment

CAE No Pref. BST
43.41
41.36
15.23
45.90
39.55
14.55
40.91
23.18
35.91

Table 5: Human preference for meaning preserva-
tion in percentages.

downstream task and ensure that the task has the
same outcome even after style transfer. This is a
hard evaluation and hence we resort to a simpler
evaluation of the “meaning” of the sentence.

We set up a manual pairwise comparison fol-
lowing Bennett (2005). The test presents the orig-
inal sentence and then, in random order, its corre-
sponding sentences produced by the baseline and
our models. For the gender style transfer we asked
“Which transferred sentence maintains the same
sentiment of the source sentence in the same se-
mantic context (i.e. you can ignore if food items
are changed)”. For the task of changing the po-
litical slant, we asked “Which transferred sen-
tence maintains the same semantic intent of the
source sentence while changing the political po-
sition”. For the task of sentiment transfer we
have followed the annotation instruction in (Shen
et al., 2017) and asked “Which transferred sen-
tence is semantically equivalent to the source sen-
tence with an opposite sentiment”

We then count the preferences of the eleven
participants, measuring the relative acceptance of
the generated sentences.7 A third option “=” was
given to participants to mark no preference for ei-
ther of the generated sentence. The “no prefer-
ence” option includes choices both are equally bad
and both are equally good. We conducted three
tests one for each type of experiment - gender, po-
litical slant and sentiment. We also divided our
annotation set into short (#tokens ≤ 15) and long
(15 < #tokens ≤ 30) sentences for the gender and
the political slant experiment. In each set we had
20 random samples for each type of style trans-
fer. In total we had 100 sentences to be annotated.
Note that we did not ask about appropriateness of
the style transfer in this test, or ﬂuency of outputs,
only about meaning preservation.

The results of human evaluation are presented
in Table 5.
Although a no-preference op-
tion was chosen often—showing that state-of-
the-art systems are still not on par with hu-

7None of the human judges are authors of this paper

man expectations—the BST models outperform
the baselines in the gender and the political slant
transfer tasks.

Crucially, the BST models signiﬁcantly outper-
form the CAE models when transferring style in
longer and harder sentences. Annotators preferred
the CAE model only for 12.5% of the long sen-
tences, compared to 47.27% preference for the
BST model.

tional content, and to modify sentiment while pre-
serving meaning or intent. On the other hand, the
style-transfer accuracy for gender is lower for BST
model but the preservation of meaning is much
better for the BST model, compared to CAE model
and to ”No preference” option. This means that
the BST model does better job at closely repre-
senting the input sentence while taking a mild hit
in the style transfer accuracy.

5.3 Fluency

6 Related Work

Finally, we evaluate the ﬂuency of the generated
sentences. Fluency was rated from 1 (unreadable)
to 4 (perfect) as is described in (Shen et al., 2017).
We randomly selected 60 sentences each gener-
ated by the baseline and the BST model.

The results shown in Table 6 are averaged

scores for each model.

Experiment
Gender
Political slant
Sentiment
Overall
Overall Short
Overall Long

CAE BST
2.81
2.42
2.87
2.79
3.18
3.09
2.91
2.70
3.11
3.05
2.62
2.18

Table 6: Fluency of the generated sentences.

BST outperforms the baseline overall. It is in-
teresting to note that BST generates signiﬁcantly
more ﬂuent longer sentences than the baseline
model. Since the average length of sentences was
higher for the gender experiment, BST notably
outperformed the baseline in this task, relatively to
the sentiment task where the sentences are shorter.
Examples of the original and style-transfered sen-
tences generated by the baseline and our model are
shown in the Supplementary Material.

5.4 Discussion

The loss function of the generators given in Eq.
5 includes two competing terms, one to improve
meaning preservation and the other to improve the
style transfer accuracy.
In the task of sentiment
modiﬁcation, the BST model preserved meaning
worse than the baseline, on the expense of be-
ing better at style transfer. We note, however,
that the sentiment modiﬁcation task is not partic-
ularly well-suited for evaluating style transfer: it
is particularly hard (if not impossible) to disentan-
gle the sentiment of a sentence from its proposi-

Style transfer with non-parallel text corpus has be-
come an active research area due to the recent ad-
vances in text generation tasks. Hu et al. (2017)
use variational auto-encoders with a discriminator
to generate sentences with controllable attributes.
The method learns a disentangled latent represen-
tation and generates a sentence from it using a
code. This paper mainly focuses on sentiment
and tense for style transfer attributes. It evaluates
the transfer strength of the generated sentences
but does not evaluate the extent of preservation
In our
of meaning in the generated sentences.
work, we show a qualitative evaluation of mean-
ing preservation.

Shen et al. (2017) ﬁrst present a theoretical anal-
ysis of style transfer in text using non-parallel
corpus. The paper then proposes a novel cross-
alignment auto-encoders with discriminators ar-
It mainly fo-
chitecture to generate sentences.
cuses on sentiment and word decipherment for
style transfer experiments.

Fu et al. (2018) explore two models for style
transfer. The ﬁrst approach uses multiple decoders
for each type of style.
In the second approach,
style embeddings are used to augment the encoded
representations, so that only one decoder needs to
be learned to generate outputs in different styles.
Style transfer is evaluated on scientiﬁc paper ti-
tles and newspaper tiles, and sentiment in reviews.
This method is different from ours in that we use
machine translation to create a strong latent state
from which multiple decoders can be trained for
each style. We also propose a different human
evaluation scheme.

Li et al. (2018) ﬁrst extract words or phrases
associated with the original style of the sentence,
delete them from the original sentence and then
replace them with new phrases associated with the
target style. They then use a neural model to ﬂu-
Junbo
ently combine these into a ﬁnal output.

et al. (2017) learn a representation which is style-
agnostic, using adversarial training of the auto-
encoder.

Our work is also closely-related to a problem of
paraphrase generation (Madnani and Dorr, 2010;
Dong et al., 2017),
including methods relying
on (phrase-based) back-translation (Ganitkevitch
et al., 2011; Ganitkevitch and Callison-Burch,
2014). More recently, Mallinson et al. (2017) and
Wieting et al. (2017) showed how neural back-
translation can be used to generate paraphrases.
An additional related line of research is machine
translation with non-parallel data. Lample et al.
(2018) and Artetxe et al. (2018) have proposed
sophisticated methods for unsupervised machine
translation. These methods could in principle be
used for style transfer as well.

7 Conclusion

We propose a novel approach to the task of style
transfer with non-parallel text.8 We learn a la-
tent content representation using machine transla-
tion techniques; this aids grounding the meaning
of the sentences, as well as weakening the style
attributes. We apply this technique to three dif-
ferent style transfer tasks. In transfer of political
slant and sentiment we outperform an off-the-shelf
state-of-the-art baseline using a cross-aligned au-
toencoder. The political slant task is a novel task
that we introduce. Our model also outperforms the
baseline in all the experiments of ﬂuency, and in
the experiments for meaning preservation in gen-
erated sentences of gender and political slant. Yet,
we acknowledge that the generated sentences do
not always adequately preserve meaning.

This technique is suitable not just for style
transfer, but for enforcing style, and removing
style too. In future work we intend to apply this
technique to debiasing sentences and anonymiza-
tion of author traits such as gender and age.

In the future work, we will also explore whether
an enhanced back-translation by pivoting through
several languages will learn better grounded latent
meaning representations. In particular, it would be
interesting to back-translate through multiple tar-
get languages with a single source language (John-
son et al., 2016).

8All

the

and

code

experi-
data
ments will be released to facilitate reproducibility at
https://github.com/shrimai/Style-Transfer-Through-Back-
Translation

used

the

in

Measuring the separation of style from content
is hard, even for humans. It depends on the task
and the context of the utterance within its dis-
course. Ultimately we must evaluate our style
transfer within some down-stream task where our
style transfer has its intended use but we achieve
the same task completion criteria.

Acknowledgments

This work was funded by a fellowship from Robert
Bosch, and in part by the National Science Foun-
dation through award IIS-1526745. We would like
to thank Sravana Reddy for sharing the Yelp cor-
pus used in gender transfer experiments, Zhiting
Hu for providing an implementation of a VAE-
based baseline, and the 11 CMU graduate students
who helped with annotation and manual evalu-
ations. We are also grateful to the anonymous
reviewers for their constructive feedback, and to
Dan Jurafsky, David Jurgens, Vinod Prabhakaran,
and Rob Voigt for valuable discussions at earlier
stages of this work.

References

Mikel Artetxe, Gorka Labaka, Eneko Agirre, and
Kyunghyun Cho. 2018. Unsupervised neural ma-
chine translation. In Proc ICLR.

Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-
gio. 2015. Neural machine translation by jointly
learning to align and translate. In Proc. ICLR.

Christina L Bennett. 2005. Large scale evaluation of
corpus-based synthesizers: Results and lessons from
In Ninth European
the blizzard challenge 2005.
Conference on Speech Communication and Technol-
ogy.

Su Lin Blodgett, Lisa Green, and Brendan O’Connor.
2016. Demographic dialectal variation in social me-
dia: A case study of African-American English. In
Proc. EMNLP.

Ondˇrej Bojar, Rajen Chatterjee, Christian Federmann,
Barry Haddow, Matthias Huck, Chris Hokamp,
Philipp Koehn, Varvara Logacheva, Christof Monz,
Matteo Negri, Matt Post, Carolina Scarton, Lucia
Specia, and Marco Turchi. 2015. Findings of the
2015 workshop on statistical machine translation. In
Proc. WMT, pages 1–46.

Jennifer Coates. 2015. Women, men and language: A
sociolinguistic account of gender differences in lan-
guage. Routledge.

Michael Denkowski and Alon Lavie. 2011. Meteor
1.3: Automatic metric for reliable optimization and

evaluation of machine translation systems. In Proc.
WMT, pages 85–91.

Li Dong, Jonathan Mallinson, Siva Reddy, and Mirella
Lapata. 2017. Learning to paraphrase for question
answering. In Proceedings of the 2017 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 875–886. Association for Computa-
tional Linguistics.

Penelope Eckert and Sally McConnell-Ginet. 2003.
Language and gender. Cambridge University Press.

Zhenxin Fu, Xiaoye Tan, Nanyun Peng, Dongyan
Zhao, and Rui Yan. 2018. Style Transfer in Text:
Exploration and Evaluation. In Proc. AAAI.

Juri Ganitkevitch and Chris Callison-Burch. 2014. The
In Proc. LREC,

multilingual paraphrase database.
pages 4276–4283.

Juri Ganitkevitch, Chris Callison-Burch, Courtney
Napoles, and Benjamin Van Durme. 2011. Learning
sentential paraphrases from bilingual parallel cor-
In Proc. EMNLP,
pora for text-to-text generation.
pages 1168–1179.

Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan
Salakhutdinov, and Eric P Xing. 2017. Toward con-
In Proc. ICML, pages
trolled generation of text.
1587–1596.

Eric Jardine. 2016. Tor, what is it good for? political
repression and the use of online anonymity-granting
technologies. New Media & Society.

Melvin Johnson, Mike Schuster, Quoc V Le, Maxim
Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat,
Fernanda Vi´egas, Martin Wattenberg, Greg Corrado,
et al. 2016. Google’s multilingual neural machine
translation system: enabling zero-shot translation.
arXiv preprint arXiv:1611.04558.

Anna Jørgensen, Dirk Hovy, and Anders Søgaard.
2015. Challenges of studying and processing di-
alects in social media. In Proc. of the Workshop on
Noisy User-generated Text, pages 9–18.

Junbo, Zhao, Y. Kim, K. Zhang, A. M. Rush, and
Y. LeCun. 2017. Adversarially Regularized Autoen-
coders for Generating Discrete Structures. ArXiv e-
prints.

Andrej Karpathy and Li Fei-Fei. 2015. Deep visual-
semantic alignments for generating image descrip-
tions. In Proc. CVPR, pages 3128–3137.

Chlo´e Kiddon, Luke Zettlemoyer, and Yejin Choi.
2016. Globally coherent text generation with neural
checklist models. In Proc. EMNLP, pages 329–339.

Diederik P Kingma and Max Welling. 2014. Auto-

encoding variational bayes. In Proc. ICLR.

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, et al. 2007. Moses: Open source
In Proc.
toolkit for statistical machine translation.
ACL (demonstration sessions), pages 177–180.

Robin Tolmach Lakoff and Mary Bucholtz. 2004. Lan-
guage and woman’s place: Text and commentaries,
volume 3. Oxford University Press, USA.

Guillaume Lample, Alexis Conneau, Ludovic Denoyer,
and Marc’Aurelio Ranzato. 2018. Unsupervised
machine translation using monolingual corpora only.
In Proc. ICLR.

J. Li, R. Jia, H. He, and P. Liang. 2018. Delete, Re-
trieve, Generate: A Simple Approach to Sentiment
and Style Transfer. ArXiv e-prints.

Jiwei Li, Michel Galley, Chris Brockett, Georgios P
Spithourakis, Jianfeng Gao, and Bill Dolan. 2016. A
persona-based neural conversation model. In Proc.
ACL.

Minh-Thang Luong, Hieu Pham, and Christopher D.
Manning. 2015. Effective approaches to attention-
based neural machine translation. In Proc. EMNLP.

Nitin Madnani and Bonnie J Dorr. 2010. Generat-
ing phrasal and sentential paraphrases: A survey
of data-driven methods. Computational Linguistics,
36(3):341–387.

Jonathan Mallinson, Rico Sennrich, and Mirella Lap-
ata. 2017. Paraphrasing revisited with neural ma-
chine translation. In Proce. EACL, volume 1, pages
881–893.

Burt L. Monroe, Michael P. Colaresi, and Kevin M.
Quinn. 2008. Fightin words: Lexical feature selec-
tion and evaluation for identifying the content of po-
litical conﬂict. Political Analysis.

Dong Nguyen, A. Seza Do˘gru¨oz, Carolyn P. Ros´e,
and Franciska de Jong. 2016. Computational soci-
olinguistics: A survey. Computational Linguistics,
42(3):537–593.

Xing Niu, Marianna Martindale, and Marine Carpuat.
2017. A study of style in machine translation: Con-
trolling the formality of machine translation output.
In Proc. EMNLP, pages 2804–2809.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
In Proc. ACL,
evaluation of machine translation.
pages 311–318.

Ella Rabinovich, Shachar Mirkin, Raj Nath Patel, Lu-
cia Specia, and Shuly Wintner. 2016. Personal-
ized machine translation: Preserving original author
traits. In Proc. EACL.

Sravana Reddy and Kevin Knight. 2016. Obfuscating
In Proc. of Work-
gender in social media writing.
shop on Natural Language Processing and Compu-
tational Social Science, pages 17–26.

Alan Ritter, Colin Cherry, and William B Dolan. 2011.
Data-driven response generation in social media. In
Proc. EMNLP, pages 583–593.

Rachel Rudinger, Chandler May,

and Benjamin
Van Durme. 2017. Social bias in elicited natural lan-
guage inferences. In Proc. of the First Workshop on
Ethics in Natural Language Processing, page 74.

Abigail See, Peter J Liu, and Christopher D Manning.
2017. Get to the point: Summarization with pointer-
generator networks. In Proc. ACL.

Rico Sennrich, Barry Haddow, and Alexandra Birch.
2016. Controlling politeness in neural machine
In Proc. NAACL,
translation via side constraints.
pages 35–40.

Tianxiao Shen, Tao Lei, Regina Barzilay, and Tommi
Jaakkola. 2017. Style transfer from non-parallel text
by cross-alignment. In Proc. NIPS.

Alessandro Sordoni, Michel Galley, Michael Auli,
Chris Brockett, Yangfeng Ji, Margaret Mitchell,
Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. 2015.
A neural network approach to context-sensitive
In Proc.
generation of conversational responses.
NAACL.

Steven J. Spencer, Claude M. Steele, and Diane M.
Quinn. 1999. Stereotype Threat and Women’s Math
Performance. Journal of Experimental Social Psy-
chology, 35:4–28.

Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.
Sequence to sequence learning with neural net-
works. In Proc. NIPS, pages 3104–3112.

Oriol Vinyals and Quoc Le. 2015. A neural conversa-
tional model. In Proc. ICML Deep Learning Work-
shop.

Rob Voigt, David Jurgens, Vinodkumar Prabhakaran,
Dan Jurafsky, and Yulia Tsvetkov. 2018. RtGender:
A corpus for studying differential responses to gen-
der. In Proc. LREC.

Tsung-Hsien Wen, David Vandyke, Nikola Mrksic,
Milica Gasic, Lina M Rojas-Barahona, Pei-Hao Su,
Stefan Ultes, and Steve Young. 2017. A network-
based end-to-end trainable task-oriented dialogue
system. In Proc. EACL.

John Wieting, Jonathan Mallinson, and Kevin Gimpel.
2017. Learning paraphrastic sentence embeddings
from back-translated bitext. In Proc. EMNLP, pages
274–285.

Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho,
Aaron Courville, Ruslan Salakhudinov, Rich Zemel,
and Yoshua Bengio. 2015. Show, attend and tell:
Neural image caption generation with visual atten-
tion. In Proc. ICML, pages 2048–2057.

A Supplementary Material

In Tables 7, 8, and 9 we present the style transfer
accuracy results broken-down to style categories.
We denote the Cross-aligned Auto-Encoder model
as CAE and our model as Back-translation for
Style Transfer (BST).

Model
Style transfer
CAE male → female
BST male → female
female → male
CAE
female → male
BST

Acc
64.75
54.59
56.05
59.49

Table 7: Gender transfer accuracy.

Model
CAE
BST
CAE
BST

Style transfer
republican → democratic
republican → democratic
democratic → republican
democratic → republican

Acc
65.44
80.55
86.20
95.47

Table 8: Political slant transfer accuracy.

Model
CAE
BST
CAE
BST

Style transfer
negative → positive
negative → positive
positive → negative
positive → negative

Acc
81.63
95.68
79.65
81.65

Table 9: Sentiment modiﬁcation accuracy.

In Table 10, we detail the accuracy of the gender
classiﬁer on generated style-transfered sentences
by an auto-encoder; Table 11 shows the accuracy
of transfer of political slant. The experiments are
setup as described in Section 5.1. We denote the
Auto-Encoder as (AE) and our model as Back-
translation for Style Transfer (BST).

Style transfer
Model
male → female
AE
BST male → female
female → male
AE
female → male
BST

Acc
41.48
54.59
41.88
59.49

Table 10: Gender transfer accuracy for Auto-
encoder.

To evaluate the preservation of meaning by the
Auto-Encoder, the experiments were setup as de-
scribed in Section 5.2. We conducted four tests,

Model
AE
BST
AE
BST

Style transfer
republican → democratic
republican → democratic
democratic → republican
democratic → republican

Acc
60.76
80.55
64.05
95.47

Table 11: Political slant transfer accuracy for
Auto-encoder.

each of 20 random samples for each type of style
transfer. Note that we did not ask about appropri-
ateness of the style transfer in this test, or ﬂuency
of outputs, only about meaning preservation. We
show the results of human evaluation in Table 12

Style transfer
male → female
female → male
republican → democratic
democratic → republican

=
43.3
45.0
43.3
55.00

AE BST
43.3
13.4
45.0
10.0
53.3
3.4
33.3
11.7

Table 12: Human preference for meaning preser-
vation in percentages.

Examples of the original and style-transfered
sentences generated by the baseline and our model
are shown in Table 13

Input Sentence

BST

CAE
male → female
i got ta get the chicken breast .

we could n’t go back and i would
be able to get me to get me.

the place is small but cosy and

the staff and the place is very

very clean.

nice.

save

yourself

the

huge

female → male
the sauces are excellent.

would i discourage someone else

i believe i would be back?

my husband ordered the chicken

salad and the fries.

great place to go back and try a

lot of which you ’ ve never had
to try or could not have been
able to get some of the best.
the place is great but very clean

and very friendly.

going

you

are
disappointed.
i wouldn’t go back!

to

be

tom,

i wish u would bring

i agree,

senator warren and

brian, i am proud to have you

the sauces - lrb - - rrb - - rrb -

and - rrb -.

my wife ordered the mac-n-
cheese and the salad - lrb - $
00 minutes - rrb - was cooked.

republican → democratic
i am proud of you and your vote

for us!

could be.

and then we will be praying for
them and i am proud of this
position and i am proud of
democratic → republican
a lot , i am proud of you <unk>.

and in bigotry–racism,
programming, cut,
granddaughters,
unprescedented and excludes.
thank you for standing up for us

i will continue to ﬁght for you

and the rest of our
democracy!

representing me.

keep up and dont know, you

have a lot of respect as
breitbart

as a hoosier, i’m praying for

you sir.

thanks for standing up for the
constitution and get rid of
obamacare, homophobie
, cut, and actuality.

and i am proud of us!

for us, senator scott!

thanks lawmaker for all you do

thank you for standing up for

do you for standing up for highly

my wife ordered country fried

steak and eggs.

great place to visit and maybe
ﬁnd that one rare item you
just have never seen or can
not ﬁnd anywhere else.

headaches.

from going?

my husband ordered the salad
and the dressing - lrb - blue
cheese - rrb - was watered
down.

i will continue praying for you
and the decisions made by
our government!

change.

all talk and no action-why dont
you have some guts like
breitbart

as a hoosier, i thank you, rep.

visclosky.

justice and against bigotry-
-racism, homophobia, sexism
, misogyny, religious and
xenophobia.

thank you for all you are do-
for us, attorney general
ing

harris!

crap fries, hard hamburger buns,
burger tasted like crap!
the people behind the counter
were not friendly whatsoever.

like like!

friendly.

negative → positive
good selection, fresh food, like

empathy,

best
but it was very nice!

the

food,

the people who the staff were

the people here are really good.

this place is bad news!

this place is great!

this place is amazing!

the food is excellent and the

positive → negative
the food is the food and the

service is exceptional!

service is terrible.

great as always,

i

love there

i really don’t eat

food.

i would recommend a visit here.

horrible as,
here.

i would not recommend a dinner
here.

the food is horrible and the

service is terrible.
really disappointed,
be
i will not recommend this place.

i couldn’t

back.

Table 13: Gender, Political slant and Sentiment style transfer examples. In addition to better preserving
meaning, sentences generated by the BST model are generally grammatically better structured.

Style Transfer Through Back-Translation

Shrimai Prabhumoye, Yulia Tsvetkov, Ruslan Salakhutdinov, Alan W Black
Carnegie Mellon University, Pittsburgh, PA, USA
{sprabhum,ytsvetko,rsalakhu,awb}@cs.cmu.edu

8
1
0
2
 
y
a
M
 
4
2
 
 
]
L
C
.
s
c
[
 
 
3
v
0
0
0
9
0
.
4
0
8
1
:
v
i
X
r
a

Abstract

Style transfer is the task of rephrasing the
text to contain speciﬁc stylistic proper-
ties without changing the intent or affect
within the context. This paper introduces
a new method for automatic style trans-
fer. We ﬁrst learn a latent representation of
the input sentence which is grounded in a
language translation model in order to bet-
ter preserve the meaning of the sentence
while reducing stylistic properties. Then
adversarial generation techniques are used
to make the output match the desired style.
We evaluate this technique on three dif-
sentiment,
ferent style transformations:
gender and political slant.
Compared
to two state-of-the-art style transfer mod-
eling techniques we show improvements
both in automatic evaluation of style trans-
fer and in manual evaluation of meaning
preservation and ﬂuency.

1

Introduction

Intelligent, situation-aware applications must pro-
duce naturalistic outputs,
lexicalizing the same
meaning differently, depending upon the envi-
ronment. This is particularly relevant for lan-
guage generation tasks such as machine trans-
lation (Sutskever et al., 2014; Bahdanau et al.,
2015), caption generation (Karpathy and Fei-Fei,
2015; Xu et al., 2015), and natural language gen-
eration (Wen et al., 2017; Kiddon et al., 2016). In
conversational agents (Ritter et al., 2011; Sordoni
et al., 2015; Vinyals and Le, 2015; Li et al., 2016),
for example, modulating the politeness style, to
sound natural depending upon a situation: at a
the video is start-
party with friends “Shut up!
ing!”, or in a professional setting “Please be quiet,
the video will begin shortly.”.

These goals have motivated a considerable
amount of recent research efforts focused at “con-
trolled” language generation—aiming at separat-
ing the semantic content of what is said from
the stylistic dimensions of how it is said. These
include approaches relying on heuristic substitu-
tions, deletions, and insertions to modulate de-
mographic properties of a writer (Reddy and
Knight, 2016),
integrating stylistic and demo-
graphic speaker traits in statistical machine trans-
lation (Rabinovich et al., 2016; Niu et al., 2017),
and deep generative models controlling for a par-
ticular stylistic aspect, e.g., politeness (Sennrich
et al., 2016), sentiment, or tense (Hu et al., 2017;
Shen et al., 2017). The latter approaches to style
transfer, while more powerful and ﬂexible than
heuristic methods, have yet to show that in addi-
tion to transferring style they effectively preserve
meaning of input sentences.

This paper introduces a novel approach to trans-
ferring style of a sentence while better preserv-
ing its meaning. We hypothesize—relying on the
study of Rabinovich et al. (2016) who showed
that author characteristics are signiﬁcantly ob-
fuscated by both manual and automatic machine
translation—that grounding in back-translation is
a plausible approach to rephrase a sentence while
reducing its stylistic properties. We thus ﬁrst use
back-translation to rephrase the sentence and re-
duce the effect of the original style; then, we gen-
erate from the latent representation, using separate
style-speciﬁc generators controlling for style (§2).
We focus on transferring author attributes:
(1) gender and (2) political slant, and (3) on sen-
timent modiﬁcation. The second task is novel:
given a sentence by an author with a particular po-
litical leaning, rephrase the sentence to preserve
its meaning but to confound classiﬁers of politi-
cal slant (§3). The task of sentiment modiﬁcation
enables us to compare our approach with state-of-

Figure 1: Style transfer pipeline: to rephrase a sentence and reduce its stylistic characteristics, the sen-
tence is back-translated. Then, separate style-speciﬁc generators are used for style transfer.

the-art models (Hu et al., 2017; Shen et al., 2017).
Style transfer is evaluated using style classi-
ﬁers trained on held-out data. Our back-translation
style transfer model outperforms the state-of-the-
art baselines (Shen et al., 2017; Hu et al., 2017)
on the tasks of political slant and sentiment mod-
iﬁcation; 12% absolute improvement was attained
for political slant transfer, and up to 7% absolute
improvement in modiﬁcation of sentiment (§5).
Meaning preservation was evaluated manually, us-
ing A/B testing (§4). Our approach performs bet-
ter than the baseline on the task of transferring
gender and political slant. Finally, we evaluate the
ﬂuency of the generated sentences using human
evaluation and our model outperforms the baseline
in all experiments for ﬂuency.

The main contribution of this work is a new
approach to style transfer that outperforms state-
of-the-art baselines in both the quality of input–
output correspondence (meaning preservation and
ﬂuency), and the accuracy of style transfer. The
secondary contribution is a new task that we pro-
pose to evaluate style transfer: transferring politi-
cal slant.

2 Methodology

1 , . . . , x(n)

Given two datasets X 1 = {x(1)
1 } and
X 2 = {x(1)
2 , . . . , x(n)
2 } which represent two dif-
ferent styles s1 and s2, respectively, our task is to
generate sentences of the desired style while pre-
serving the meaning of the input sentence. Speciﬁ-
cally, we generate samples of dataset X 1 such that
they belong to style s2 and samples of X 2 such
that they belong to style s1. We denote the out-
put of dataset X 1 transfered to style s2 as ˆX 1 =
{ˆx(1)
2 } and the output of dataset X 2
transferred to style s1 as ˆX 2 = {ˆx(1)
1 }.
Hu et al. (2017) and Shen et al. (2017) in-
troduced state-of-the-art style transfer models
that use variational auto-encoders (Kingma and

2 , . . . , ˆx(n)

1 , . . . , ˆx(n)

Welling, 2014, VAEs) and cross-aligned auto-
encoders, respectively, to model a latent content
variable z. The latent content variable z is a code
which is not observed. The generative model con-
ditions on this code during the generation pro-
cess. Our aim is to design a latent code z which
(1) represents the meaning of the input sentence
grounded in back-translation and (2) weakens the
style attributes of author’s traits. To model the
former, we use neural machine translation. Prior
work has shown that the process of translating a
sentence from a source language to a target lan-
guage retains the meaning of the sentence but does
not preserve the stylistic features related to the au-
thor’s traits (Rabinovich et al., 2016). We hypoth-
esize that a latent code z obtained through back-
translation will normalize the sentence and devoid
it from style attributes speciﬁc to author’s traits.

Figure 1 shows the overview of the proposed
In our framework, we ﬁrst train a ma-
method.
chine translation model from source language e
to a target language f . We also train a back-
translation model from f to e. Let us assume our
styles s1 and s2 correspond to DEMOCRATIC and
REPUBLICAN style, respectively. In Figure 1, the
input sentence i thank you, rep. visclosky.
is la-
beled as DEMOCRATIC. We translate the sentence
using the e → f machine translation model and
generate the parallel sentence in the target lan-
guage f : je vous remercie, rep. visclosky. Using
the ﬁxed encoder of the f → e machine transla-
tion model, we encode this sentence in language
f . The hidden representation created by this en-
coder of the back-translation model is used as z.
We condition our generative models on this z. We
then train two separate decoders for each style
s1 and s2 to generate samples in these respective
styles in source language e. Hence the sentence
could be translated to the REPUBLICAN style us-
ing the decoder for s2. For example, the sentence
i’m praying for you sir. is the REPUBLICAN ver-

Figure 2: The latent representation from back-translation and the style classiﬁer feedback are used to
guide the style-speciﬁc generators.

sion of the input sentence and i thank you, senator
visclosky. is the more DEMOCRATIC version of it.
Note that in this setting, the machine translation
and the encoder of the back-translation model re-
main ﬁxed. They are not dependent on the data
we use across different tasks. This facilitates re-
usability and spares the need of learning separate
models to generate z for a new style data.

2.1 Meaning-Grounded Representation

In this section we describe how we learn the la-
tent content variable z using back-translation. The
e → f machine translation and f → e back-
translation models are trained using a sequence-to-
sequence framework (Sutskever et al., 2014; Bah-
danau et al., 2015) with style-agnostic corpus. The
style-speciﬁc sentence i thank you, rep. visclosky.
in source language e is translated to the target lan-
guage f to get je vous remercie, rep. visclosky.
The individual tokens of this sentence are then
encoded using the encoder of the f → e back-
translation model. The learned hidden representa-
tion is z.

Formally, let θE represent the parameters of the
encoder of f → e translation system. Then z is
given by:

for each style. The sentence generated by a de-
coder is passed through the classiﬁer. The loss
of the classiﬁer for the generated sentence is used
as feedback to guide the decoder for the gener-
ation process. The target attribute of the clas-
siﬁer is determined by the decoder from which
the output is generated. For example, in the case
of DEMOCRATIC decoder, the target attribute is
DEMOCRATIC and for the REPUBLICAN decoder
the target is REPUBLICAN.

2.2.1 Style Classiﬁers

We train a convolutional neural network (CNN)
classiﬁer to accurately predict the given style. We
also use it to evaluate the error in the generated
samples for the desired style. We train the classi-
ﬁer in a supervised manner. The classiﬁer accepts
either discrete or continuous tokens as inputs. This
is done such that the generator output can be used
as input to the classiﬁer. We need labeled exam-
ples to train the classiﬁer such that each instance
in the dataset X should have a label in the set
s = {s1, s2}. Let θC denote the parameters of
the classiﬁer. The objective to train the classiﬁer
is given by:

z = Encoder(xf ; θE)

(1)

Lclass(θC) = EX [log qC(s|x)].

(2)

where, xf is the sentence x in language f . Specif-
ically, xf is the output of e → f translation sys-
tem when xe is given as input. Since z is derived
from a non-style speciﬁc process, this Encoder is
not style speciﬁc.

2.2 Style-Speciﬁc Generation

Figure 2 shows the architecture of the generative
model for generating different styles. Using the
encoder embedding z, we train multiple decoders

To improve the accuracy of the classiﬁer, we aug-
ment classiﬁer’s inputs with style-speciﬁc lexi-
cons. We concatenate binary style indicators to
each input word embedding in the classiﬁer. The
indicators are set to 1 if the input word is present
in a style-speciﬁc lexicon; otherwise they are set to
0. Style lexicons are extracted using the log-odds
ratio informative Dirichlet prior (Monroe et al.,
2008), a method that identiﬁes words that are sta-
tistically overrepresented in each of the categories.

2.2.2 Generator Learning
We use a bidirectional LSTM to build our de-
coders which generate the sequence of tokens ˆx =
{x1, · · · xT }. The sequence ˆx is conditioned on
the latent code z (in our case, on the machine
translation model).
In this work we use a cor-
pus translated to French by the machine transla-
tion system as the input to the encoder of the back-
translation model. The same encoder is used to en-
code sentences of both styles. The representation
created by this encoder is given by Eq 1. Samples
are generated as follows:

ˆx ∼ z = p(ˆx|z)

=

p(ˆxt|ˆx<t, z)

(cid:89)

t

(3)

(4)

where, ˆx<t are the tokens generated before ˆxt.

Tokens are discrete and non-differentiable. This
makes it difﬁcult to use a classiﬁer, as the gen-
eration process samples discrete tokens from the
multinomial distribution parametrized using soft-
max function at each time step t. This non-
in turn, breaks down gradient
differentiability,
propagation from the discriminators to the gen-
erator.
Instead, following Hu et al. (2017) we
use a continuous approximation based on softmax,
along with the temperature parameter which an-
neals the softmax to the discrete case as training
proceeds. To create a continuous representation of
the output of the generative model which will be
given as an input to the classiﬁer, we use:

ˆxt ∼ softmax(ot/τ ),

where, ot is the output of the generator and τ is the
temperature which decreases as the training pro-
ceeds. Let θG denote the parameters of the gen-
erators. Then the reconstruction loss is calculated
using the cross entropy function, given by:

Lrecon(θG; x) = EqE (z|x)[log pgen(x|z)]

(5)

Here, the back-translation encoder E creates the
latent code z by:

z = E(x) = qE(z|x)

(6)

The generative loss Lgen is then given by:

minθgenLgen = Lrecon + λcLclass

(7)

where Lrecon is given by Eq. (5), Lclass is given
by Eq (2) and λc is a balancing parameter.

We also use global attention of (Luong et al.,
2015) to aid our generators. At each time step t of
the generation process, we infer a variable length
alignment vector at:

at =

(cid:80)

exp(score(ht, ¯hs))
s(cid:48) exp(score(ht, ¯hs(cid:48) )

(8)

t , ¯hs),

score(ht, ¯hs) = dot(hT

(9)
where ht is the current target state and ¯hs are all
source states. While generating sentences, we use
the attention vector to replace unknown characters
(UNK) using the copy mechanism in (See et al.,
2017).

3 Style Transfer Tasks

Much work in computational social science has
shown that people’s personal and demographic
characteristics—either publicly observable (e.g.,
age, gender) or private (e.g.,
religion, politi-
cal afﬁliation)—are revealed in their linguistic
choices (Nguyen et al., 2016). There are practi-
cal scenarios, however, when these attributes need
to be modulated or obfuscated. For example,
some users may wish to preserve their anonymity
online, for personal security concerns (Jardine,
2016), or to reduce stereotype threat (Spencer
et al., 1999). Modulating authors’ attributes while
preserving meaning of sentences can also help
generate demographically-balanced training data
for a variety of downstream applications.

Moreover, prior work has shown that the qual-
ity of language identiﬁcation and POS tagging
degrades signiﬁcantly on African American Ver-
nacular English (Blodgett et al., 2016; Jørgensen
et al., 2015); YouTube’s automatic captions have
higher error rates for women and speakers from
Synthesiz-
Scotland (Rudinger et al., 2017).
ing balanced training data—using style transfer
techniques—is a plausible way to alleviate bias
present in existing NLP technologies.

We thus focus on two tasks that have practi-
cal and social-good applications, and also accu-
rate style classiﬁers. To position our method with
respect to prior work, we employ a third task of
sentiment transfer, which was used in two state-
of-the-art approaches to style transfer (Hu et al.,
2017; Shen et al., 2017). We describe the three
tasks and associated dataset statistics below. The
methodology that we advocate is general and can
be applied to other styles, for transferring various

social categories, types of bias, and in multi-class
settings.

Gender.
In sociolinguistics, gender is known to
be one of the most important social categories
driving language choice (Eckert and McConnell-
Ginet, 2003; Lakoff and Bucholtz, 2004; Coates,
2015). Reddy and Knight (2016) proposed a
heuristic-based method to obfuscate gender of a
writer. This method uses statistical association
measures to identify gender-salient words and sub-
stitute them with synonyms typically of the oppo-
site gender. This simple approach produces highly
ﬂuent, meaning-preserving sentences, but does not
allow for more general rephrasing of sentence be-
yond single-word substitutions. In our work, we
adopt this task of transferring the author’s gender
and adapt it to our experimental settings.

We used Reddy and Knight’s (2016) dataset of
reviews from Yelp annotated for two genders cor-
responding to markers of sex.1 We split the re-
views to sentences, preserving the original gender
labels. To keep only sentences that are strongly
indicative of a gender, we then ﬁltered out gender-
neutral sentences (e.g., thank you) and sentences
whose likelihood to be written by authors of one
gender is lower than 0.7.2

Political slant. Our second dataset is comprised
of top-level comments on Facebook posts from all
412 current members of the United States Sen-
ate and House who have public Facebook pages
(Voigt et al., 2018).3 Only top-level comments
that directly respond to the post are included. Ev-
ery comment to a Congressperson is labeled with
the Congressperson’s party afﬁliation: democratic
or republican. Topic and sentiment in these com-
ments reveal commenter’s political slant. For ex-
ample, defund them all, especially when it comes
to the illegal immigrants . and thank u james,
praying for all the work u do . are republican,
whereas on behalf of the hard-working nh public
school teachers- thank you ! and we need more
strong voices like yours ﬁghting for gun control .

1We note that gender may be considered along a spec-
trum (Eckert and McConnell-Ginet, 2003), but use gender
as a binary variable due to the absence of corpora with
continuous-valued gender annotations.

2We did not experiment with other threshold values.
3The posts and comments are all public; however, to pro-
tect the identity of Facebook users in this dataset Voigt et al.
(2018) have removed all identifying user information as well
as Facebook-internal information such as User IDs and Post
IDs, replacing these with randomized ID numbers.

Style
gender
political
sentiment

dev

train

class
test
2.57M 2.67M 4.5K 535K
540K
80K
56K
4K
444K 63.5K 127K
2M

Table 1: Sentence count in style-speciﬁc corpora.

represent examples of democratic sentences. Our
task is to preserve intent of the commenter (e.g.,
to thank their representative), but to modify their
observable political afﬁliation, as in the example
in Figure 1. We preprocessed and ﬁltered the
comments similarly to the gender-annotated cor-
pus above.

Sentiment. To compare our work with the state-
of-the-art approaches of style transfer for non-
parallel corpus we perform sentiment
transfer,
replicating the models and experimental setups of
Hu et al. (2017) and Shen et al. (2017). Given a
positive Yelp review, a style transfer model will
generate a similar review but with an opposite sen-
timent. We used Shen et al.’s (2017) corpus of
reviews from Yelp. They have followed the stan-
dard practice of labeling the reviews with rating of
higher than three as positive and less than three as
negative. They have also split the reviews to sen-
tences and assumed that the sentence has the same
sentiment as the review.

Dataset statistics. We summarize below cor-
pora statistics for the three tasks: transferring gen-
der, political slant, and sentiment. The dataset for
sentiment modiﬁcation task was used as described
in (Shen et al., 2017). We split Yelp and Facebook
corpora into four disjoint parts each: (1) a training
corpus for training a style classiﬁer (class); (2) a
training corpus (train) used for training the style-
speciﬁc generative model described in §2.2; (3)
development and (4) test sets. We have removed
from training corpora class and train all sentences
that overlap with development and test corpora.
Corpora sizes are shown in Table 1.

Table 2 shows the approximate vocabulary sizes
used for each dataset. The vocabulary is the same
for both the styles in each experiment.

Style
Vocabulary

gender
20K

political
20K

sentiment
10K

Table 2: Vocabulary sizes of the datasets.

Table 3 summarizes sentence statistics. All the

sentences have maximum length of 50 tokens.

Style
male
female
republican
democratic
negative
positive

Avg. Length %data
50.00
50.00
50.00
50.00
39.81
60.19

18.08
18.21
16.18
16.01
9.66
8.45

Table 3: Average sentence length and class distri-
bution of style corpora.

5 Results

4 Experimental Setup

In what follows, we describe our experimental set-
tings, including baselines used, hyperparameter
settings, datasets, and evaluation setups.

Baseline. We compare our model against the
“cross-aligned” auto-encoder (Shen et al., 2017),
which uses style-speciﬁc decoders to align the
style of generated sentences to the actual distribu-
tion of the style. We used the off-the-shelf senti-
ment model released by Shen et al. (2017) for the
sentiment experiments. We also separately train
this model for the gender and political slant using
hyper-parameters detailed below.4

Translation data. We trained an English–
French neural machine translation system and a
French–English back-translation system. We used
data from Workshop in Statistical Machine Trans-
lation 2015 (WMT15) (Bojar et al., 2015) to train
our translation models. We used the French–
English data from the Europarl v7 corpus, the
news commentary v10 corpus and the common
crawl corpus from WMT15. Data were tokenized
using the Moses tokenizer (Koehn et al., 2007).
Approximately 5.4M English–French parallel sen-
tences were used for training. A vocabulary size of
100K was used to train the translation systems.

Hyperparameter settings.
the experi-
ments, the generator and the encoders are a two-
layer LSTM with an input size of 300 and the hid-
den dimension of 500. The encoders are bidirec-

In all

4In addition, we compared our model with the current
state-of-the-art approach introduced by Hu et al. (2017); Shen
et al. (2017) use this method as baseline, obtaining compara-
ble results. We reproduced the results reported in (Hu et al.,
2017) using their tasks and data. However, the same model
trained on our political slant datasets (described in §3), ob-
tained an almost random accuracy of 50.98% in style transfer.
We thus omit these results.

tional. The generator samples a sentence of max-
imum length 50. All the generators use global at-
tention vectors of size 500. The CNN classiﬁer
is trained with 100 ﬁlters of size 5, with max-
the
pooling. The input to CNN is of size 302:
300-dimensional word embedding plus two bits
for membership of the word in our style lexicons,
as described in §2.2.1. Balancing parameter λc is
set to 15. For sentiment task, we have used set-
tings provided in (Shen et al., 2017).

We evaluate our approach along three dimensions.
(1) Style transfer accuracy, measuring the propor-
tion of our models’ outputs that generate sentences
of the desired style. The style transfer accuracy
is performed using classiﬁers trained on held-out
train data that were not used in training the style
transfer models. (2) Preservation of meaning. (3)
Fluency, measuring the readability and the natu-
ralness of the generated sentences. We conducted
human evaluations for the latter two.

In what follows, we ﬁrst present the quality of
our neural machine translation systems, then we
present the evaluation setups, and then present the
results of our experiments.

quality. The

Translation
BLEU scores
achieved for English–French MT system is
32.52 and for French–English MT system is
31.11; these are strong translation systems. We
deliberately chose a European language close to
English for which massive amounts of parallel
data are available and translation quality is high,
to concentrate on the style generation, rather than
improving a translation system. 5

5.1 Style Transfer Accuracy

We measure the accuracy of style transfer for the
generated sentences using a pre-trained style clas-
siﬁer (§2.2.1). The classiﬁer is trained on data that
is not used for training our style transfer genera-
tive models (as described in §3). The classiﬁer has
an accuracy of 82% for the gender-annotated cor-
pus, 92% accuracy for the political slant dataset
and 93.23% accuracy for the sentiment dataset.

5Alternatively, we could use a pivot language that is ty-
pologically more distant from English, e.g., Chinese. In this
case we hypothesize that stylistic traits would be even less
preserved in translation, but the quality of back-translated
sentences would be worse. We have not yet investigated how
the accuracy of the translation model, nor the language of
translation affects our models.

We transfer the style of test sentences and then
test the classiﬁcation accuracy of the generated
sentences for the opposite label. For example, if
we want to transfer the style of male Yelp reviews
to female, then we use the ﬁxed common encoder
of the back-translation model to encode the test
male sentences and then we use the female gener-
ative model to generate the female-styled reviews.
We then test these generated sentences for the fe-
male label using the gender classiﬁer.

Experiment
Gender
Political slant
Sentiment

CAE
60.40
75.82
80.43

BST
57.04
88.01
87.22

Table 4: Accuracy of the style transfer in gener-
ated sentences.

In Table 4, we detail the accuracy of each
classiﬁer on generated style-transfered sentences.6
We denote the Shen et al.’s (2017) Cross-aligned
Auto-Encoder model as CAE and our model as
Back-translation for Style Transfer (BST).

On two out of three tasks our model substan-
tially outperforms the baseline, by up to 12% in
political slant transfer, and by up to 7% in senti-
ment modiﬁcation.

5.2 Preservation of Meaning

Although we attempted to use automatics mea-
sures to evaluate how well meaning is preserved
in our transformations; measures such as BLEU
(Papineni et al., 2002) and Meteor (Denkowski
and Lavie, 2011), or even cosine similarity be-
tween distributed representations of sentences do
not capture this distance well.

Meaning preservation in style transfer is not
trivial to deﬁne as literal meaning is likely to
change when style transfer occurs. For example
“My girlfriend loved the desserts” vs “My partner
liked the desserts”. Thus we must relax the con-
dition of literal meaning to intent or affect of the
utterance within the context of the discourse. Thus
if the intent is to criticize a restaurant’s service
in a review, changing “salad” to “chicken” could
still have the same effect but if the intent is to or-
der food that substitution would not be acceptable.
Ideally we wish to evaluate transfer within some

6In each experiment, we report aggregated results across
directions of style transfer; same results broke-down to style
categories are listed in the Supplementary Material.

Experiment
Gender
Political slant
Sentiment

CAE No Pref. BST
43.41
41.36
15.23
45.90
39.55
14.55
40.91
23.18
35.91

Table 5: Human preference for meaning preserva-
tion in percentages.

downstream task and ensure that the task has the
same outcome even after style transfer. This is a
hard evaluation and hence we resort to a simpler
evaluation of the “meaning” of the sentence.

We set up a manual pairwise comparison fol-
lowing Bennett (2005). The test presents the orig-
inal sentence and then, in random order, its corre-
sponding sentences produced by the baseline and
our models. For the gender style transfer we asked
“Which transferred sentence maintains the same
sentiment of the source sentence in the same se-
mantic context (i.e. you can ignore if food items
are changed)”. For the task of changing the po-
litical slant, we asked “Which transferred sen-
tence maintains the same semantic intent of the
source sentence while changing the political po-
sition”. For the task of sentiment transfer we
have followed the annotation instruction in (Shen
et al., 2017) and asked “Which transferred sen-
tence is semantically equivalent to the source sen-
tence with an opposite sentiment”

We then count the preferences of the eleven
participants, measuring the relative acceptance of
the generated sentences.7 A third option “=” was
given to participants to mark no preference for ei-
ther of the generated sentence. The “no prefer-
ence” option includes choices both are equally bad
and both are equally good. We conducted three
tests one for each type of experiment - gender, po-
litical slant and sentiment. We also divided our
annotation set into short (#tokens ≤ 15) and long
(15 < #tokens ≤ 30) sentences for the gender and
the political slant experiment. In each set we had
20 random samples for each type of style trans-
fer. In total we had 100 sentences to be annotated.
Note that we did not ask about appropriateness of
the style transfer in this test, or ﬂuency of outputs,
only about meaning preservation.

The results of human evaluation are presented
in Table 5.
Although a no-preference op-
tion was chosen often—showing that state-of-
the-art systems are still not on par with hu-

7None of the human judges are authors of this paper

man expectations—the BST models outperform
the baselines in the gender and the political slant
transfer tasks.

Crucially, the BST models signiﬁcantly outper-
form the CAE models when transferring style in
longer and harder sentences. Annotators preferred
the CAE model only for 12.5% of the long sen-
tences, compared to 47.27% preference for the
BST model.

tional content, and to modify sentiment while pre-
serving meaning or intent. On the other hand, the
style-transfer accuracy for gender is lower for BST
model but the preservation of meaning is much
better for the BST model, compared to CAE model
and to ”No preference” option. This means that
the BST model does better job at closely repre-
senting the input sentence while taking a mild hit
in the style transfer accuracy.

5.3 Fluency

6 Related Work

Finally, we evaluate the ﬂuency of the generated
sentences. Fluency was rated from 1 (unreadable)
to 4 (perfect) as is described in (Shen et al., 2017).
We randomly selected 60 sentences each gener-
ated by the baseline and the BST model.

The results shown in Table 6 are averaged

scores for each model.

Experiment
Gender
Political slant
Sentiment
Overall
Overall Short
Overall Long

CAE BST
2.81
2.42
2.87
2.79
3.18
3.09
2.91
2.70
3.11
3.05
2.62
2.18

Table 6: Fluency of the generated sentences.

BST outperforms the baseline overall. It is in-
teresting to note that BST generates signiﬁcantly
more ﬂuent longer sentences than the baseline
model. Since the average length of sentences was
higher for the gender experiment, BST notably
outperformed the baseline in this task, relatively to
the sentiment task where the sentences are shorter.
Examples of the original and style-transfered sen-
tences generated by the baseline and our model are
shown in the Supplementary Material.

5.4 Discussion

The loss function of the generators given in Eq.
5 includes two competing terms, one to improve
meaning preservation and the other to improve the
style transfer accuracy.
In the task of sentiment
modiﬁcation, the BST model preserved meaning
worse than the baseline, on the expense of be-
ing better at style transfer. We note, however,
that the sentiment modiﬁcation task is not partic-
ularly well-suited for evaluating style transfer: it
is particularly hard (if not impossible) to disentan-
gle the sentiment of a sentence from its proposi-

Style transfer with non-parallel text corpus has be-
come an active research area due to the recent ad-
vances in text generation tasks. Hu et al. (2017)
use variational auto-encoders with a discriminator
to generate sentences with controllable attributes.
The method learns a disentangled latent represen-
tation and generates a sentence from it using a
code. This paper mainly focuses on sentiment
and tense for style transfer attributes. It evaluates
the transfer strength of the generated sentences
but does not evaluate the extent of preservation
In our
of meaning in the generated sentences.
work, we show a qualitative evaluation of mean-
ing preservation.

Shen et al. (2017) ﬁrst present a theoretical anal-
ysis of style transfer in text using non-parallel
corpus. The paper then proposes a novel cross-
alignment auto-encoders with discriminators ar-
It mainly fo-
chitecture to generate sentences.
cuses on sentiment and word decipherment for
style transfer experiments.

Fu et al. (2018) explore two models for style
transfer. The ﬁrst approach uses multiple decoders
for each type of style.
In the second approach,
style embeddings are used to augment the encoded
representations, so that only one decoder needs to
be learned to generate outputs in different styles.
Style transfer is evaluated on scientiﬁc paper ti-
tles and newspaper tiles, and sentiment in reviews.
This method is different from ours in that we use
machine translation to create a strong latent state
from which multiple decoders can be trained for
each style. We also propose a different human
evaluation scheme.

Li et al. (2018) ﬁrst extract words or phrases
associated with the original style of the sentence,
delete them from the original sentence and then
replace them with new phrases associated with the
target style. They then use a neural model to ﬂu-
Junbo
ently combine these into a ﬁnal output.

et al. (2017) learn a representation which is style-
agnostic, using adversarial training of the auto-
encoder.

Our work is also closely-related to a problem of
paraphrase generation (Madnani and Dorr, 2010;
Dong et al., 2017),
including methods relying
on (phrase-based) back-translation (Ganitkevitch
et al., 2011; Ganitkevitch and Callison-Burch,
2014). More recently, Mallinson et al. (2017) and
Wieting et al. (2017) showed how neural back-
translation can be used to generate paraphrases.
An additional related line of research is machine
translation with non-parallel data. Lample et al.
(2018) and Artetxe et al. (2018) have proposed
sophisticated methods for unsupervised machine
translation. These methods could in principle be
used for style transfer as well.

7 Conclusion

We propose a novel approach to the task of style
transfer with non-parallel text.8 We learn a la-
tent content representation using machine transla-
tion techniques; this aids grounding the meaning
of the sentences, as well as weakening the style
attributes. We apply this technique to three dif-
ferent style transfer tasks. In transfer of political
slant and sentiment we outperform an off-the-shelf
state-of-the-art baseline using a cross-aligned au-
toencoder. The political slant task is a novel task
that we introduce. Our model also outperforms the
baseline in all the experiments of ﬂuency, and in
the experiments for meaning preservation in gen-
erated sentences of gender and political slant. Yet,
we acknowledge that the generated sentences do
not always adequately preserve meaning.

This technique is suitable not just for style
transfer, but for enforcing style, and removing
style too. In future work we intend to apply this
technique to debiasing sentences and anonymiza-
tion of author traits such as gender and age.

In the future work, we will also explore whether
an enhanced back-translation by pivoting through
several languages will learn better grounded latent
meaning representations. In particular, it would be
interesting to back-translate through multiple tar-
get languages with a single source language (John-
son et al., 2016).

8All

the

and

code

experi-
data
ments will be released to facilitate reproducibility at
https://github.com/shrimai/Style-Transfer-Through-Back-
Translation

used

the

in

Measuring the separation of style from content
is hard, even for humans. It depends on the task
and the context of the utterance within its dis-
course. Ultimately we must evaluate our style
transfer within some down-stream task where our
style transfer has its intended use but we achieve
the same task completion criteria.

Acknowledgments

This work was funded by a fellowship from Robert
Bosch, and in part by the National Science Foun-
dation through award IIS-1526745. We would like
to thank Sravana Reddy for sharing the Yelp cor-
pus used in gender transfer experiments, Zhiting
Hu for providing an implementation of a VAE-
based baseline, and the 11 CMU graduate students
who helped with annotation and manual evalu-
ations. We are also grateful to the anonymous
reviewers for their constructive feedback, and to
Dan Jurafsky, David Jurgens, Vinod Prabhakaran,
and Rob Voigt for valuable discussions at earlier
stages of this work.

References

Mikel Artetxe, Gorka Labaka, Eneko Agirre, and
Kyunghyun Cho. 2018. Unsupervised neural ma-
chine translation. In Proc ICLR.

Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-
gio. 2015. Neural machine translation by jointly
learning to align and translate. In Proc. ICLR.

Christina L Bennett. 2005. Large scale evaluation of
corpus-based synthesizers: Results and lessons from
In Ninth European
the blizzard challenge 2005.
Conference on Speech Communication and Technol-
ogy.

Su Lin Blodgett, Lisa Green, and Brendan O’Connor.
2016. Demographic dialectal variation in social me-
dia: A case study of African-American English. In
Proc. EMNLP.

Ondˇrej Bojar, Rajen Chatterjee, Christian Federmann,
Barry Haddow, Matthias Huck, Chris Hokamp,
Philipp Koehn, Varvara Logacheva, Christof Monz,
Matteo Negri, Matt Post, Carolina Scarton, Lucia
Specia, and Marco Turchi. 2015. Findings of the
2015 workshop on statistical machine translation. In
Proc. WMT, pages 1–46.

Jennifer Coates. 2015. Women, men and language: A
sociolinguistic account of gender differences in lan-
guage. Routledge.

Michael Denkowski and Alon Lavie. 2011. Meteor
1.3: Automatic metric for reliable optimization and

evaluation of machine translation systems. In Proc.
WMT, pages 85–91.

Li Dong, Jonathan Mallinson, Siva Reddy, and Mirella
Lapata. 2017. Learning to paraphrase for question
answering. In Proceedings of the 2017 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 875–886. Association for Computa-
tional Linguistics.

Penelope Eckert and Sally McConnell-Ginet. 2003.
Language and gender. Cambridge University Press.

Zhenxin Fu, Xiaoye Tan, Nanyun Peng, Dongyan
Zhao, and Rui Yan. 2018. Style Transfer in Text:
Exploration and Evaluation. In Proc. AAAI.

Juri Ganitkevitch and Chris Callison-Burch. 2014. The
In Proc. LREC,

multilingual paraphrase database.
pages 4276–4283.

Juri Ganitkevitch, Chris Callison-Burch, Courtney
Napoles, and Benjamin Van Durme. 2011. Learning
sentential paraphrases from bilingual parallel cor-
In Proc. EMNLP,
pora for text-to-text generation.
pages 1168–1179.

Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan
Salakhutdinov, and Eric P Xing. 2017. Toward con-
In Proc. ICML, pages
trolled generation of text.
1587–1596.

Eric Jardine. 2016. Tor, what is it good for? political
repression and the use of online anonymity-granting
technologies. New Media & Society.

Melvin Johnson, Mike Schuster, Quoc V Le, Maxim
Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat,
Fernanda Vi´egas, Martin Wattenberg, Greg Corrado,
et al. 2016. Google’s multilingual neural machine
translation system: enabling zero-shot translation.
arXiv preprint arXiv:1611.04558.

Anna Jørgensen, Dirk Hovy, and Anders Søgaard.
2015. Challenges of studying and processing di-
alects in social media. In Proc. of the Workshop on
Noisy User-generated Text, pages 9–18.

Junbo, Zhao, Y. Kim, K. Zhang, A. M. Rush, and
Y. LeCun. 2017. Adversarially Regularized Autoen-
coders for Generating Discrete Structures. ArXiv e-
prints.

Andrej Karpathy and Li Fei-Fei. 2015. Deep visual-
semantic alignments for generating image descrip-
tions. In Proc. CVPR, pages 3128–3137.

Chlo´e Kiddon, Luke Zettlemoyer, and Yejin Choi.
2016. Globally coherent text generation with neural
checklist models. In Proc. EMNLP, pages 329–339.

Diederik P Kingma and Max Welling. 2014. Auto-

encoding variational bayes. In Proc. ICLR.

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, et al. 2007. Moses: Open source
In Proc.
toolkit for statistical machine translation.
ACL (demonstration sessions), pages 177–180.

Robin Tolmach Lakoff and Mary Bucholtz. 2004. Lan-
guage and woman’s place: Text and commentaries,
volume 3. Oxford University Press, USA.

Guillaume Lample, Alexis Conneau, Ludovic Denoyer,
and Marc’Aurelio Ranzato. 2018. Unsupervised
machine translation using monolingual corpora only.
In Proc. ICLR.

J. Li, R. Jia, H. He, and P. Liang. 2018. Delete, Re-
trieve, Generate: A Simple Approach to Sentiment
and Style Transfer. ArXiv e-prints.

Jiwei Li, Michel Galley, Chris Brockett, Georgios P
Spithourakis, Jianfeng Gao, and Bill Dolan. 2016. A
persona-based neural conversation model. In Proc.
ACL.

Minh-Thang Luong, Hieu Pham, and Christopher D.
Manning. 2015. Effective approaches to attention-
based neural machine translation. In Proc. EMNLP.

Nitin Madnani and Bonnie J Dorr. 2010. Generat-
ing phrasal and sentential paraphrases: A survey
of data-driven methods. Computational Linguistics,
36(3):341–387.

Jonathan Mallinson, Rico Sennrich, and Mirella Lap-
ata. 2017. Paraphrasing revisited with neural ma-
chine translation. In Proce. EACL, volume 1, pages
881–893.

Burt L. Monroe, Michael P. Colaresi, and Kevin M.
Quinn. 2008. Fightin words: Lexical feature selec-
tion and evaluation for identifying the content of po-
litical conﬂict. Political Analysis.

Dong Nguyen, A. Seza Do˘gru¨oz, Carolyn P. Ros´e,
and Franciska de Jong. 2016. Computational soci-
olinguistics: A survey. Computational Linguistics,
42(3):537–593.

Xing Niu, Marianna Martindale, and Marine Carpuat.
2017. A study of style in machine translation: Con-
trolling the formality of machine translation output.
In Proc. EMNLP, pages 2804–2809.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
In Proc. ACL,
evaluation of machine translation.
pages 311–318.

Ella Rabinovich, Shachar Mirkin, Raj Nath Patel, Lu-
cia Specia, and Shuly Wintner. 2016. Personal-
ized machine translation: Preserving original author
traits. In Proc. EACL.

Sravana Reddy and Kevin Knight. 2016. Obfuscating
In Proc. of Work-
gender in social media writing.
shop on Natural Language Processing and Compu-
tational Social Science, pages 17–26.

Alan Ritter, Colin Cherry, and William B Dolan. 2011.
Data-driven response generation in social media. In
Proc. EMNLP, pages 583–593.

Rachel Rudinger, Chandler May,

and Benjamin
Van Durme. 2017. Social bias in elicited natural lan-
guage inferences. In Proc. of the First Workshop on
Ethics in Natural Language Processing, page 74.

Abigail See, Peter J Liu, and Christopher D Manning.
2017. Get to the point: Summarization with pointer-
generator networks. In Proc. ACL.

Rico Sennrich, Barry Haddow, and Alexandra Birch.
2016. Controlling politeness in neural machine
In Proc. NAACL,
translation via side constraints.
pages 35–40.

Tianxiao Shen, Tao Lei, Regina Barzilay, and Tommi
Jaakkola. 2017. Style transfer from non-parallel text
by cross-alignment. In Proc. NIPS.

Alessandro Sordoni, Michel Galley, Michael Auli,
Chris Brockett, Yangfeng Ji, Margaret Mitchell,
Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. 2015.
A neural network approach to context-sensitive
In Proc.
generation of conversational responses.
NAACL.

Steven J. Spencer, Claude M. Steele, and Diane M.
Quinn. 1999. Stereotype Threat and Women’s Math
Performance. Journal of Experimental Social Psy-
chology, 35:4–28.

Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.
Sequence to sequence learning with neural net-
works. In Proc. NIPS, pages 3104–3112.

Oriol Vinyals and Quoc Le. 2015. A neural conversa-
tional model. In Proc. ICML Deep Learning Work-
shop.

Rob Voigt, David Jurgens, Vinodkumar Prabhakaran,
Dan Jurafsky, and Yulia Tsvetkov. 2018. RtGender:
A corpus for studying differential responses to gen-
der. In Proc. LREC.

Tsung-Hsien Wen, David Vandyke, Nikola Mrksic,
Milica Gasic, Lina M Rojas-Barahona, Pei-Hao Su,
Stefan Ultes, and Steve Young. 2017. A network-
based end-to-end trainable task-oriented dialogue
system. In Proc. EACL.

John Wieting, Jonathan Mallinson, and Kevin Gimpel.
2017. Learning paraphrastic sentence embeddings
from back-translated bitext. In Proc. EMNLP, pages
274–285.

Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho,
Aaron Courville, Ruslan Salakhudinov, Rich Zemel,
and Yoshua Bengio. 2015. Show, attend and tell:
Neural image caption generation with visual atten-
tion. In Proc. ICML, pages 2048–2057.

A Supplementary Material

In Tables 7, 8, and 9 we present the style transfer
accuracy results broken-down to style categories.
We denote the Cross-aligned Auto-Encoder model
as CAE and our model as Back-translation for
Style Transfer (BST).

Model
Style transfer
CAE male → female
BST male → female
female → male
CAE
female → male
BST

Acc
64.75
54.59
56.05
59.49

Table 7: Gender transfer accuracy.

Model
CAE
BST
CAE
BST

Style transfer
republican → democratic
republican → democratic
democratic → republican
democratic → republican

Acc
65.44
80.55
86.20
95.47

Table 8: Political slant transfer accuracy.

Model
CAE
BST
CAE
BST

Style transfer
negative → positive
negative → positive
positive → negative
positive → negative

Acc
81.63
95.68
79.65
81.65

Table 9: Sentiment modiﬁcation accuracy.

In Table 10, we detail the accuracy of the gender
classiﬁer on generated style-transfered sentences
by an auto-encoder; Table 11 shows the accuracy
of transfer of political slant. The experiments are
setup as described in Section 5.1. We denote the
Auto-Encoder as (AE) and our model as Back-
translation for Style Transfer (BST).

Style transfer
Model
male → female
AE
BST male → female
female → male
AE
female → male
BST

Acc
41.48
54.59
41.88
59.49

Table 10: Gender transfer accuracy for Auto-
encoder.

To evaluate the preservation of meaning by the
Auto-Encoder, the experiments were setup as de-
scribed in Section 5.2. We conducted four tests,

Model
AE
BST
AE
BST

Style transfer
republican → democratic
republican → democratic
democratic → republican
democratic → republican

Acc
60.76
80.55
64.05
95.47

Table 11: Political slant transfer accuracy for
Auto-encoder.

each of 20 random samples for each type of style
transfer. Note that we did not ask about appropri-
ateness of the style transfer in this test, or ﬂuency
of outputs, only about meaning preservation. We
show the results of human evaluation in Table 12

Style transfer
male → female
female → male
republican → democratic
democratic → republican

=
43.3
45.0
43.3
55.00

AE BST
43.3
13.4
45.0
10.0
53.3
3.4
33.3
11.7

Table 12: Human preference for meaning preser-
vation in percentages.

Examples of the original and style-transfered
sentences generated by the baseline and our model
are shown in Table 13

Input Sentence

BST

CAE
male → female
i got ta get the chicken breast .

we could n’t go back and i would
be able to get me to get me.

the place is small but cosy and

the staff and the place is very

very clean.

nice.

save

yourself

the

huge

female → male
the sauces are excellent.

would i discourage someone else

i believe i would be back?

my husband ordered the chicken

salad and the fries.

great place to go back and try a

lot of which you ’ ve never had
to try or could not have been
able to get some of the best.
the place is great but very clean

and very friendly.

going

you

are
disappointed.
i wouldn’t go back!

to

be

tom,

i wish u would bring

i agree,

senator warren and

brian, i am proud to have you

the sauces - lrb - - rrb - - rrb -

and - rrb -.

my wife ordered the mac-n-
cheese and the salad - lrb - $
00 minutes - rrb - was cooked.

republican → democratic
i am proud of you and your vote

for us!

could be.

and then we will be praying for
them and i am proud of this
position and i am proud of
democratic → republican
a lot , i am proud of you <unk>.

and in bigotry–racism,
programming, cut,
granddaughters,
unprescedented and excludes.
thank you for standing up for us

i will continue to ﬁght for you

and the rest of our
democracy!

representing me.

keep up and dont know, you

have a lot of respect as
breitbart

as a hoosier, i’m praying for

you sir.

thanks for standing up for the
constitution and get rid of
obamacare, homophobie
, cut, and actuality.

and i am proud of us!

for us, senator scott!

thanks lawmaker for all you do

thank you for standing up for

do you for standing up for highly

my wife ordered country fried

steak and eggs.

great place to visit and maybe
ﬁnd that one rare item you
just have never seen or can
not ﬁnd anywhere else.

headaches.

from going?

my husband ordered the salad
and the dressing - lrb - blue
cheese - rrb - was watered
down.

i will continue praying for you
and the decisions made by
our government!

change.

all talk and no action-why dont
you have some guts like
breitbart

as a hoosier, i thank you, rep.

visclosky.

justice and against bigotry-
-racism, homophobia, sexism
, misogyny, religious and
xenophobia.

thank you for all you are do-
for us, attorney general
ing

harris!

crap fries, hard hamburger buns,
burger tasted like crap!
the people behind the counter
were not friendly whatsoever.

like like!

friendly.

negative → positive
good selection, fresh food, like

empathy,

best
but it was very nice!

the

food,

the people who the staff were

the people here are really good.

this place is bad news!

this place is great!

this place is amazing!

the food is excellent and the

positive → negative
the food is the food and the

service is exceptional!

service is terrible.

great as always,

i

love there

i really don’t eat

food.

i would recommend a visit here.

horrible as,
here.

i would not recommend a dinner
here.

the food is horrible and the

service is terrible.
really disappointed,
be
i will not recommend this place.

i couldn’t

back.

Table 13: Gender, Political slant and Sentiment style transfer examples. In addition to better preserving
meaning, sentences generated by the BST model are generally grammatically better structured.

Style Transfer Through Back-Translation

Shrimai Prabhumoye, Yulia Tsvetkov, Ruslan Salakhutdinov, Alan W Black
Carnegie Mellon University, Pittsburgh, PA, USA
{sprabhum,ytsvetko,rsalakhu,awb}@cs.cmu.edu

8
1
0
2
 
y
a
M
 
4
2
 
 
]
L
C
.
s
c
[
 
 
3
v
0
0
0
9
0
.
4
0
8
1
:
v
i
X
r
a

Abstract

Style transfer is the task of rephrasing the
text to contain speciﬁc stylistic proper-
ties without changing the intent or affect
within the context. This paper introduces
a new method for automatic style trans-
fer. We ﬁrst learn a latent representation of
the input sentence which is grounded in a
language translation model in order to bet-
ter preserve the meaning of the sentence
while reducing stylistic properties. Then
adversarial generation techniques are used
to make the output match the desired style.
We evaluate this technique on three dif-
sentiment,
ferent style transformations:
gender and political slant.
Compared
to two state-of-the-art style transfer mod-
eling techniques we show improvements
both in automatic evaluation of style trans-
fer and in manual evaluation of meaning
preservation and ﬂuency.

1

Introduction

Intelligent, situation-aware applications must pro-
duce naturalistic outputs,
lexicalizing the same
meaning differently, depending upon the envi-
ronment. This is particularly relevant for lan-
guage generation tasks such as machine trans-
lation (Sutskever et al., 2014; Bahdanau et al.,
2015), caption generation (Karpathy and Fei-Fei,
2015; Xu et al., 2015), and natural language gen-
eration (Wen et al., 2017; Kiddon et al., 2016). In
conversational agents (Ritter et al., 2011; Sordoni
et al., 2015; Vinyals and Le, 2015; Li et al., 2016),
for example, modulating the politeness style, to
sound natural depending upon a situation: at a
the video is start-
party with friends “Shut up!
ing!”, or in a professional setting “Please be quiet,
the video will begin shortly.”.

These goals have motivated a considerable
amount of recent research efforts focused at “con-
trolled” language generation—aiming at separat-
ing the semantic content of what is said from
the stylistic dimensions of how it is said. These
include approaches relying on heuristic substitu-
tions, deletions, and insertions to modulate de-
mographic properties of a writer (Reddy and
Knight, 2016),
integrating stylistic and demo-
graphic speaker traits in statistical machine trans-
lation (Rabinovich et al., 2016; Niu et al., 2017),
and deep generative models controlling for a par-
ticular stylistic aspect, e.g., politeness (Sennrich
et al., 2016), sentiment, or tense (Hu et al., 2017;
Shen et al., 2017). The latter approaches to style
transfer, while more powerful and ﬂexible than
heuristic methods, have yet to show that in addi-
tion to transferring style they effectively preserve
meaning of input sentences.

This paper introduces a novel approach to trans-
ferring style of a sentence while better preserv-
ing its meaning. We hypothesize—relying on the
study of Rabinovich et al. (2016) who showed
that author characteristics are signiﬁcantly ob-
fuscated by both manual and automatic machine
translation—that grounding in back-translation is
a plausible approach to rephrase a sentence while
reducing its stylistic properties. We thus ﬁrst use
back-translation to rephrase the sentence and re-
duce the effect of the original style; then, we gen-
erate from the latent representation, using separate
style-speciﬁc generators controlling for style (§2).
We focus on transferring author attributes:
(1) gender and (2) political slant, and (3) on sen-
timent modiﬁcation. The second task is novel:
given a sentence by an author with a particular po-
litical leaning, rephrase the sentence to preserve
its meaning but to confound classiﬁers of politi-
cal slant (§3). The task of sentiment modiﬁcation
enables us to compare our approach with state-of-

Figure 1: Style transfer pipeline: to rephrase a sentence and reduce its stylistic characteristics, the sen-
tence is back-translated. Then, separate style-speciﬁc generators are used for style transfer.

the-art models (Hu et al., 2017; Shen et al., 2017).
Style transfer is evaluated using style classi-
ﬁers trained on held-out data. Our back-translation
style transfer model outperforms the state-of-the-
art baselines (Shen et al., 2017; Hu et al., 2017)
on the tasks of political slant and sentiment mod-
iﬁcation; 12% absolute improvement was attained
for political slant transfer, and up to 7% absolute
improvement in modiﬁcation of sentiment (§5).
Meaning preservation was evaluated manually, us-
ing A/B testing (§4). Our approach performs bet-
ter than the baseline on the task of transferring
gender and political slant. Finally, we evaluate the
ﬂuency of the generated sentences using human
evaluation and our model outperforms the baseline
in all experiments for ﬂuency.

The main contribution of this work is a new
approach to style transfer that outperforms state-
of-the-art baselines in both the quality of input–
output correspondence (meaning preservation and
ﬂuency), and the accuracy of style transfer. The
secondary contribution is a new task that we pro-
pose to evaluate style transfer: transferring politi-
cal slant.

2 Methodology

1 , . . . , x(n)

Given two datasets X 1 = {x(1)
1 } and
X 2 = {x(1)
2 , . . . , x(n)
2 } which represent two dif-
ferent styles s1 and s2, respectively, our task is to
generate sentences of the desired style while pre-
serving the meaning of the input sentence. Speciﬁ-
cally, we generate samples of dataset X 1 such that
they belong to style s2 and samples of X 2 such
that they belong to style s1. We denote the out-
put of dataset X 1 transfered to style s2 as ˆX 1 =
{ˆx(1)
2 } and the output of dataset X 2
transferred to style s1 as ˆX 2 = {ˆx(1)
1 }.
Hu et al. (2017) and Shen et al. (2017) in-
troduced state-of-the-art style transfer models
that use variational auto-encoders (Kingma and

2 , . . . , ˆx(n)

1 , . . . , ˆx(n)

Welling, 2014, VAEs) and cross-aligned auto-
encoders, respectively, to model a latent content
variable z. The latent content variable z is a code
which is not observed. The generative model con-
ditions on this code during the generation pro-
cess. Our aim is to design a latent code z which
(1) represents the meaning of the input sentence
grounded in back-translation and (2) weakens the
style attributes of author’s traits. To model the
former, we use neural machine translation. Prior
work has shown that the process of translating a
sentence from a source language to a target lan-
guage retains the meaning of the sentence but does
not preserve the stylistic features related to the au-
thor’s traits (Rabinovich et al., 2016). We hypoth-
esize that a latent code z obtained through back-
translation will normalize the sentence and devoid
it from style attributes speciﬁc to author’s traits.

Figure 1 shows the overview of the proposed
In our framework, we ﬁrst train a ma-
method.
chine translation model from source language e
to a target language f . We also train a back-
translation model from f to e. Let us assume our
styles s1 and s2 correspond to DEMOCRATIC and
REPUBLICAN style, respectively. In Figure 1, the
input sentence i thank you, rep. visclosky.
is la-
beled as DEMOCRATIC. We translate the sentence
using the e → f machine translation model and
generate the parallel sentence in the target lan-
guage f : je vous remercie, rep. visclosky. Using
the ﬁxed encoder of the f → e machine transla-
tion model, we encode this sentence in language
f . The hidden representation created by this en-
coder of the back-translation model is used as z.
We condition our generative models on this z. We
then train two separate decoders for each style
s1 and s2 to generate samples in these respective
styles in source language e. Hence the sentence
could be translated to the REPUBLICAN style us-
ing the decoder for s2. For example, the sentence
i’m praying for you sir. is the REPUBLICAN ver-

Figure 2: The latent representation from back-translation and the style classiﬁer feedback are used to
guide the style-speciﬁc generators.

sion of the input sentence and i thank you, senator
visclosky. is the more DEMOCRATIC version of it.
Note that in this setting, the machine translation
and the encoder of the back-translation model re-
main ﬁxed. They are not dependent on the data
we use across different tasks. This facilitates re-
usability and spares the need of learning separate
models to generate z for a new style data.

2.1 Meaning-Grounded Representation

In this section we describe how we learn the la-
tent content variable z using back-translation. The
e → f machine translation and f → e back-
translation models are trained using a sequence-to-
sequence framework (Sutskever et al., 2014; Bah-
danau et al., 2015) with style-agnostic corpus. The
style-speciﬁc sentence i thank you, rep. visclosky.
in source language e is translated to the target lan-
guage f to get je vous remercie, rep. visclosky.
The individual tokens of this sentence are then
encoded using the encoder of the f → e back-
translation model. The learned hidden representa-
tion is z.

Formally, let θE represent the parameters of the
encoder of f → e translation system. Then z is
given by:

for each style. The sentence generated by a de-
coder is passed through the classiﬁer. The loss
of the classiﬁer for the generated sentence is used
as feedback to guide the decoder for the gener-
ation process. The target attribute of the clas-
siﬁer is determined by the decoder from which
the output is generated. For example, in the case
of DEMOCRATIC decoder, the target attribute is
DEMOCRATIC and for the REPUBLICAN decoder
the target is REPUBLICAN.

2.2.1 Style Classiﬁers

We train a convolutional neural network (CNN)
classiﬁer to accurately predict the given style. We
also use it to evaluate the error in the generated
samples for the desired style. We train the classi-
ﬁer in a supervised manner. The classiﬁer accepts
either discrete or continuous tokens as inputs. This
is done such that the generator output can be used
as input to the classiﬁer. We need labeled exam-
ples to train the classiﬁer such that each instance
in the dataset X should have a label in the set
s = {s1, s2}. Let θC denote the parameters of
the classiﬁer. The objective to train the classiﬁer
is given by:

z = Encoder(xf ; θE)

(1)

Lclass(θC) = EX [log qC(s|x)].

(2)

where, xf is the sentence x in language f . Specif-
ically, xf is the output of e → f translation sys-
tem when xe is given as input. Since z is derived
from a non-style speciﬁc process, this Encoder is
not style speciﬁc.

2.2 Style-Speciﬁc Generation

Figure 2 shows the architecture of the generative
model for generating different styles. Using the
encoder embedding z, we train multiple decoders

To improve the accuracy of the classiﬁer, we aug-
ment classiﬁer’s inputs with style-speciﬁc lexi-
cons. We concatenate binary style indicators to
each input word embedding in the classiﬁer. The
indicators are set to 1 if the input word is present
in a style-speciﬁc lexicon; otherwise they are set to
0. Style lexicons are extracted using the log-odds
ratio informative Dirichlet prior (Monroe et al.,
2008), a method that identiﬁes words that are sta-
tistically overrepresented in each of the categories.

2.2.2 Generator Learning
We use a bidirectional LSTM to build our de-
coders which generate the sequence of tokens ˆx =
{x1, · · · xT }. The sequence ˆx is conditioned on
the latent code z (in our case, on the machine
translation model).
In this work we use a cor-
pus translated to French by the machine transla-
tion system as the input to the encoder of the back-
translation model. The same encoder is used to en-
code sentences of both styles. The representation
created by this encoder is given by Eq 1. Samples
are generated as follows:

ˆx ∼ z = p(ˆx|z)

=

p(ˆxt|ˆx<t, z)

(cid:89)

t

(3)

(4)

where, ˆx<t are the tokens generated before ˆxt.

Tokens are discrete and non-differentiable. This
makes it difﬁcult to use a classiﬁer, as the gen-
eration process samples discrete tokens from the
multinomial distribution parametrized using soft-
max function at each time step t. This non-
in turn, breaks down gradient
differentiability,
propagation from the discriminators to the gen-
erator.
Instead, following Hu et al. (2017) we
use a continuous approximation based on softmax,
along with the temperature parameter which an-
neals the softmax to the discrete case as training
proceeds. To create a continuous representation of
the output of the generative model which will be
given as an input to the classiﬁer, we use:

ˆxt ∼ softmax(ot/τ ),

where, ot is the output of the generator and τ is the
temperature which decreases as the training pro-
ceeds. Let θG denote the parameters of the gen-
erators. Then the reconstruction loss is calculated
using the cross entropy function, given by:

Lrecon(θG; x) = EqE (z|x)[log pgen(x|z)]

(5)

Here, the back-translation encoder E creates the
latent code z by:

z = E(x) = qE(z|x)

(6)

The generative loss Lgen is then given by:

minθgenLgen = Lrecon + λcLclass

(7)

where Lrecon is given by Eq. (5), Lclass is given
by Eq (2) and λc is a balancing parameter.

We also use global attention of (Luong et al.,
2015) to aid our generators. At each time step t of
the generation process, we infer a variable length
alignment vector at:

at =

(cid:80)

exp(score(ht, ¯hs))
s(cid:48) exp(score(ht, ¯hs(cid:48) )

(8)

t , ¯hs),

score(ht, ¯hs) = dot(hT

(9)
where ht is the current target state and ¯hs are all
source states. While generating sentences, we use
the attention vector to replace unknown characters
(UNK) using the copy mechanism in (See et al.,
2017).

3 Style Transfer Tasks

Much work in computational social science has
shown that people’s personal and demographic
characteristics—either publicly observable (e.g.,
age, gender) or private (e.g.,
religion, politi-
cal afﬁliation)—are revealed in their linguistic
choices (Nguyen et al., 2016). There are practi-
cal scenarios, however, when these attributes need
to be modulated or obfuscated. For example,
some users may wish to preserve their anonymity
online, for personal security concerns (Jardine,
2016), or to reduce stereotype threat (Spencer
et al., 1999). Modulating authors’ attributes while
preserving meaning of sentences can also help
generate demographically-balanced training data
for a variety of downstream applications.

Moreover, prior work has shown that the qual-
ity of language identiﬁcation and POS tagging
degrades signiﬁcantly on African American Ver-
nacular English (Blodgett et al., 2016; Jørgensen
et al., 2015); YouTube’s automatic captions have
higher error rates for women and speakers from
Synthesiz-
Scotland (Rudinger et al., 2017).
ing balanced training data—using style transfer
techniques—is a plausible way to alleviate bias
present in existing NLP technologies.

We thus focus on two tasks that have practi-
cal and social-good applications, and also accu-
rate style classiﬁers. To position our method with
respect to prior work, we employ a third task of
sentiment transfer, which was used in two state-
of-the-art approaches to style transfer (Hu et al.,
2017; Shen et al., 2017). We describe the three
tasks and associated dataset statistics below. The
methodology that we advocate is general and can
be applied to other styles, for transferring various

social categories, types of bias, and in multi-class
settings.

Gender.
In sociolinguistics, gender is known to
be one of the most important social categories
driving language choice (Eckert and McConnell-
Ginet, 2003; Lakoff and Bucholtz, 2004; Coates,
2015). Reddy and Knight (2016) proposed a
heuristic-based method to obfuscate gender of a
writer. This method uses statistical association
measures to identify gender-salient words and sub-
stitute them with synonyms typically of the oppo-
site gender. This simple approach produces highly
ﬂuent, meaning-preserving sentences, but does not
allow for more general rephrasing of sentence be-
yond single-word substitutions. In our work, we
adopt this task of transferring the author’s gender
and adapt it to our experimental settings.

We used Reddy and Knight’s (2016) dataset of
reviews from Yelp annotated for two genders cor-
responding to markers of sex.1 We split the re-
views to sentences, preserving the original gender
labels. To keep only sentences that are strongly
indicative of a gender, we then ﬁltered out gender-
neutral sentences (e.g., thank you) and sentences
whose likelihood to be written by authors of one
gender is lower than 0.7.2

Political slant. Our second dataset is comprised
of top-level comments on Facebook posts from all
412 current members of the United States Sen-
ate and House who have public Facebook pages
(Voigt et al., 2018).3 Only top-level comments
that directly respond to the post are included. Ev-
ery comment to a Congressperson is labeled with
the Congressperson’s party afﬁliation: democratic
or republican. Topic and sentiment in these com-
ments reveal commenter’s political slant. For ex-
ample, defund them all, especially when it comes
to the illegal immigrants . and thank u james,
praying for all the work u do . are republican,
whereas on behalf of the hard-working nh public
school teachers- thank you ! and we need more
strong voices like yours ﬁghting for gun control .

1We note that gender may be considered along a spec-
trum (Eckert and McConnell-Ginet, 2003), but use gender
as a binary variable due to the absence of corpora with
continuous-valued gender annotations.

2We did not experiment with other threshold values.
3The posts and comments are all public; however, to pro-
tect the identity of Facebook users in this dataset Voigt et al.
(2018) have removed all identifying user information as well
as Facebook-internal information such as User IDs and Post
IDs, replacing these with randomized ID numbers.

Style
gender
political
sentiment

dev

train

class
test
2.57M 2.67M 4.5K 535K
540K
80K
56K
4K
444K 63.5K 127K
2M

Table 1: Sentence count in style-speciﬁc corpora.

represent examples of democratic sentences. Our
task is to preserve intent of the commenter (e.g.,
to thank their representative), but to modify their
observable political afﬁliation, as in the example
in Figure 1. We preprocessed and ﬁltered the
comments similarly to the gender-annotated cor-
pus above.

Sentiment. To compare our work with the state-
of-the-art approaches of style transfer for non-
parallel corpus we perform sentiment
transfer,
replicating the models and experimental setups of
Hu et al. (2017) and Shen et al. (2017). Given a
positive Yelp review, a style transfer model will
generate a similar review but with an opposite sen-
timent. We used Shen et al.’s (2017) corpus of
reviews from Yelp. They have followed the stan-
dard practice of labeling the reviews with rating of
higher than three as positive and less than three as
negative. They have also split the reviews to sen-
tences and assumed that the sentence has the same
sentiment as the review.

Dataset statistics. We summarize below cor-
pora statistics for the three tasks: transferring gen-
der, political slant, and sentiment. The dataset for
sentiment modiﬁcation task was used as described
in (Shen et al., 2017). We split Yelp and Facebook
corpora into four disjoint parts each: (1) a training
corpus for training a style classiﬁer (class); (2) a
training corpus (train) used for training the style-
speciﬁc generative model described in §2.2; (3)
development and (4) test sets. We have removed
from training corpora class and train all sentences
that overlap with development and test corpora.
Corpora sizes are shown in Table 1.

Table 2 shows the approximate vocabulary sizes
used for each dataset. The vocabulary is the same
for both the styles in each experiment.

Style
Vocabulary

gender
20K

political
20K

sentiment
10K

Table 2: Vocabulary sizes of the datasets.

Table 3 summarizes sentence statistics. All the

sentences have maximum length of 50 tokens.

Style
male
female
republican
democratic
negative
positive

Avg. Length %data
50.00
50.00
50.00
50.00
39.81
60.19

18.08
18.21
16.18
16.01
9.66
8.45

Table 3: Average sentence length and class distri-
bution of style corpora.

5 Results

4 Experimental Setup

In what follows, we describe our experimental set-
tings, including baselines used, hyperparameter
settings, datasets, and evaluation setups.

Baseline. We compare our model against the
“cross-aligned” auto-encoder (Shen et al., 2017),
which uses style-speciﬁc decoders to align the
style of generated sentences to the actual distribu-
tion of the style. We used the off-the-shelf senti-
ment model released by Shen et al. (2017) for the
sentiment experiments. We also separately train
this model for the gender and political slant using
hyper-parameters detailed below.4

Translation data. We trained an English–
French neural machine translation system and a
French–English back-translation system. We used
data from Workshop in Statistical Machine Trans-
lation 2015 (WMT15) (Bojar et al., 2015) to train
our translation models. We used the French–
English data from the Europarl v7 corpus, the
news commentary v10 corpus and the common
crawl corpus from WMT15. Data were tokenized
using the Moses tokenizer (Koehn et al., 2007).
Approximately 5.4M English–French parallel sen-
tences were used for training. A vocabulary size of
100K was used to train the translation systems.

Hyperparameter settings.
the experi-
ments, the generator and the encoders are a two-
layer LSTM with an input size of 300 and the hid-
den dimension of 500. The encoders are bidirec-

In all

4In addition, we compared our model with the current
state-of-the-art approach introduced by Hu et al. (2017); Shen
et al. (2017) use this method as baseline, obtaining compara-
ble results. We reproduced the results reported in (Hu et al.,
2017) using their tasks and data. However, the same model
trained on our political slant datasets (described in §3), ob-
tained an almost random accuracy of 50.98% in style transfer.
We thus omit these results.

tional. The generator samples a sentence of max-
imum length 50. All the generators use global at-
tention vectors of size 500. The CNN classiﬁer
is trained with 100 ﬁlters of size 5, with max-
the
pooling. The input to CNN is of size 302:
300-dimensional word embedding plus two bits
for membership of the word in our style lexicons,
as described in §2.2.1. Balancing parameter λc is
set to 15. For sentiment task, we have used set-
tings provided in (Shen et al., 2017).

We evaluate our approach along three dimensions.
(1) Style transfer accuracy, measuring the propor-
tion of our models’ outputs that generate sentences
of the desired style. The style transfer accuracy
is performed using classiﬁers trained on held-out
train data that were not used in training the style
transfer models. (2) Preservation of meaning. (3)
Fluency, measuring the readability and the natu-
ralness of the generated sentences. We conducted
human evaluations for the latter two.

In what follows, we ﬁrst present the quality of
our neural machine translation systems, then we
present the evaluation setups, and then present the
results of our experiments.

quality. The

Translation
BLEU scores
achieved for English–French MT system is
32.52 and for French–English MT system is
31.11; these are strong translation systems. We
deliberately chose a European language close to
English for which massive amounts of parallel
data are available and translation quality is high,
to concentrate on the style generation, rather than
improving a translation system. 5

5.1 Style Transfer Accuracy

We measure the accuracy of style transfer for the
generated sentences using a pre-trained style clas-
siﬁer (§2.2.1). The classiﬁer is trained on data that
is not used for training our style transfer genera-
tive models (as described in §3). The classiﬁer has
an accuracy of 82% for the gender-annotated cor-
pus, 92% accuracy for the political slant dataset
and 93.23% accuracy for the sentiment dataset.

5Alternatively, we could use a pivot language that is ty-
pologically more distant from English, e.g., Chinese. In this
case we hypothesize that stylistic traits would be even less
preserved in translation, but the quality of back-translated
sentences would be worse. We have not yet investigated how
the accuracy of the translation model, nor the language of
translation affects our models.

We transfer the style of test sentences and then
test the classiﬁcation accuracy of the generated
sentences for the opposite label. For example, if
we want to transfer the style of male Yelp reviews
to female, then we use the ﬁxed common encoder
of the back-translation model to encode the test
male sentences and then we use the female gener-
ative model to generate the female-styled reviews.
We then test these generated sentences for the fe-
male label using the gender classiﬁer.

Experiment
Gender
Political slant
Sentiment

CAE
60.40
75.82
80.43

BST
57.04
88.01
87.22

Table 4: Accuracy of the style transfer in gener-
ated sentences.

In Table 4, we detail the accuracy of each
classiﬁer on generated style-transfered sentences.6
We denote the Shen et al.’s (2017) Cross-aligned
Auto-Encoder model as CAE and our model as
Back-translation for Style Transfer (BST).

On two out of three tasks our model substan-
tially outperforms the baseline, by up to 12% in
political slant transfer, and by up to 7% in senti-
ment modiﬁcation.

5.2 Preservation of Meaning

Although we attempted to use automatics mea-
sures to evaluate how well meaning is preserved
in our transformations; measures such as BLEU
(Papineni et al., 2002) and Meteor (Denkowski
and Lavie, 2011), or even cosine similarity be-
tween distributed representations of sentences do
not capture this distance well.

Meaning preservation in style transfer is not
trivial to deﬁne as literal meaning is likely to
change when style transfer occurs. For example
“My girlfriend loved the desserts” vs “My partner
liked the desserts”. Thus we must relax the con-
dition of literal meaning to intent or affect of the
utterance within the context of the discourse. Thus
if the intent is to criticize a restaurant’s service
in a review, changing “salad” to “chicken” could
still have the same effect but if the intent is to or-
der food that substitution would not be acceptable.
Ideally we wish to evaluate transfer within some

6In each experiment, we report aggregated results across
directions of style transfer; same results broke-down to style
categories are listed in the Supplementary Material.

Experiment
Gender
Political slant
Sentiment

CAE No Pref. BST
43.41
41.36
15.23
45.90
39.55
14.55
40.91
23.18
35.91

Table 5: Human preference for meaning preserva-
tion in percentages.

downstream task and ensure that the task has the
same outcome even after style transfer. This is a
hard evaluation and hence we resort to a simpler
evaluation of the “meaning” of the sentence.

We set up a manual pairwise comparison fol-
lowing Bennett (2005). The test presents the orig-
inal sentence and then, in random order, its corre-
sponding sentences produced by the baseline and
our models. For the gender style transfer we asked
“Which transferred sentence maintains the same
sentiment of the source sentence in the same se-
mantic context (i.e. you can ignore if food items
are changed)”. For the task of changing the po-
litical slant, we asked “Which transferred sen-
tence maintains the same semantic intent of the
source sentence while changing the political po-
sition”. For the task of sentiment transfer we
have followed the annotation instruction in (Shen
et al., 2017) and asked “Which transferred sen-
tence is semantically equivalent to the source sen-
tence with an opposite sentiment”

We then count the preferences of the eleven
participants, measuring the relative acceptance of
the generated sentences.7 A third option “=” was
given to participants to mark no preference for ei-
ther of the generated sentence. The “no prefer-
ence” option includes choices both are equally bad
and both are equally good. We conducted three
tests one for each type of experiment - gender, po-
litical slant and sentiment. We also divided our
annotation set into short (#tokens ≤ 15) and long
(15 < #tokens ≤ 30) sentences for the gender and
the political slant experiment. In each set we had
20 random samples for each type of style trans-
fer. In total we had 100 sentences to be annotated.
Note that we did not ask about appropriateness of
the style transfer in this test, or ﬂuency of outputs,
only about meaning preservation.

The results of human evaluation are presented
in Table 5.
Although a no-preference op-
tion was chosen often—showing that state-of-
the-art systems are still not on par with hu-

7None of the human judges are authors of this paper

man expectations—the BST models outperform
the baselines in the gender and the political slant
transfer tasks.

Crucially, the BST models signiﬁcantly outper-
form the CAE models when transferring style in
longer and harder sentences. Annotators preferred
the CAE model only for 12.5% of the long sen-
tences, compared to 47.27% preference for the
BST model.

tional content, and to modify sentiment while pre-
serving meaning or intent. On the other hand, the
style-transfer accuracy for gender is lower for BST
model but the preservation of meaning is much
better for the BST model, compared to CAE model
and to ”No preference” option. This means that
the BST model does better job at closely repre-
senting the input sentence while taking a mild hit
in the style transfer accuracy.

5.3 Fluency

6 Related Work

Finally, we evaluate the ﬂuency of the generated
sentences. Fluency was rated from 1 (unreadable)
to 4 (perfect) as is described in (Shen et al., 2017).
We randomly selected 60 sentences each gener-
ated by the baseline and the BST model.

The results shown in Table 6 are averaged

scores for each model.

Experiment
Gender
Political slant
Sentiment
Overall
Overall Short
Overall Long

CAE BST
2.81
2.42
2.87
2.79
3.18
3.09
2.91
2.70
3.11
3.05
2.62
2.18

Table 6: Fluency of the generated sentences.

BST outperforms the baseline overall. It is in-
teresting to note that BST generates signiﬁcantly
more ﬂuent longer sentences than the baseline
model. Since the average length of sentences was
higher for the gender experiment, BST notably
outperformed the baseline in this task, relatively to
the sentiment task where the sentences are shorter.
Examples of the original and style-transfered sen-
tences generated by the baseline and our model are
shown in the Supplementary Material.

5.4 Discussion

The loss function of the generators given in Eq.
5 includes two competing terms, one to improve
meaning preservation and the other to improve the
style transfer accuracy.
In the task of sentiment
modiﬁcation, the BST model preserved meaning
worse than the baseline, on the expense of be-
ing better at style transfer. We note, however,
that the sentiment modiﬁcation task is not partic-
ularly well-suited for evaluating style transfer: it
is particularly hard (if not impossible) to disentan-
gle the sentiment of a sentence from its proposi-

Style transfer with non-parallel text corpus has be-
come an active research area due to the recent ad-
vances in text generation tasks. Hu et al. (2017)
use variational auto-encoders with a discriminator
to generate sentences with controllable attributes.
The method learns a disentangled latent represen-
tation and generates a sentence from it using a
code. This paper mainly focuses on sentiment
and tense for style transfer attributes. It evaluates
the transfer strength of the generated sentences
but does not evaluate the extent of preservation
In our
of meaning in the generated sentences.
work, we show a qualitative evaluation of mean-
ing preservation.

Shen et al. (2017) ﬁrst present a theoretical anal-
ysis of style transfer in text using non-parallel
corpus. The paper then proposes a novel cross-
alignment auto-encoders with discriminators ar-
It mainly fo-
chitecture to generate sentences.
cuses on sentiment and word decipherment for
style transfer experiments.

Fu et al. (2018) explore two models for style
transfer. The ﬁrst approach uses multiple decoders
for each type of style.
In the second approach,
style embeddings are used to augment the encoded
representations, so that only one decoder needs to
be learned to generate outputs in different styles.
Style transfer is evaluated on scientiﬁc paper ti-
tles and newspaper tiles, and sentiment in reviews.
This method is different from ours in that we use
machine translation to create a strong latent state
from which multiple decoders can be trained for
each style. We also propose a different human
evaluation scheme.

Li et al. (2018) ﬁrst extract words or phrases
associated with the original style of the sentence,
delete them from the original sentence and then
replace them with new phrases associated with the
target style. They then use a neural model to ﬂu-
Junbo
ently combine these into a ﬁnal output.

et al. (2017) learn a representation which is style-
agnostic, using adversarial training of the auto-
encoder.

Our work is also closely-related to a problem of
paraphrase generation (Madnani and Dorr, 2010;
Dong et al., 2017),
including methods relying
on (phrase-based) back-translation (Ganitkevitch
et al., 2011; Ganitkevitch and Callison-Burch,
2014). More recently, Mallinson et al. (2017) and
Wieting et al. (2017) showed how neural back-
translation can be used to generate paraphrases.
An additional related line of research is machine
translation with non-parallel data. Lample et al.
(2018) and Artetxe et al. (2018) have proposed
sophisticated methods for unsupervised machine
translation. These methods could in principle be
used for style transfer as well.

7 Conclusion

We propose a novel approach to the task of style
transfer with non-parallel text.8 We learn a la-
tent content representation using machine transla-
tion techniques; this aids grounding the meaning
of the sentences, as well as weakening the style
attributes. We apply this technique to three dif-
ferent style transfer tasks. In transfer of political
slant and sentiment we outperform an off-the-shelf
state-of-the-art baseline using a cross-aligned au-
toencoder. The political slant task is a novel task
that we introduce. Our model also outperforms the
baseline in all the experiments of ﬂuency, and in
the experiments for meaning preservation in gen-
erated sentences of gender and political slant. Yet,
we acknowledge that the generated sentences do
not always adequately preserve meaning.

This technique is suitable not just for style
transfer, but for enforcing style, and removing
style too. In future work we intend to apply this
technique to debiasing sentences and anonymiza-
tion of author traits such as gender and age.

In the future work, we will also explore whether
an enhanced back-translation by pivoting through
several languages will learn better grounded latent
meaning representations. In particular, it would be
interesting to back-translate through multiple tar-
get languages with a single source language (John-
son et al., 2016).

8All

the

and

code

experi-
data
ments will be released to facilitate reproducibility at
https://github.com/shrimai/Style-Transfer-Through-Back-
Translation

used

the

in

Measuring the separation of style from content
is hard, even for humans. It depends on the task
and the context of the utterance within its dis-
course. Ultimately we must evaluate our style
transfer within some down-stream task where our
style transfer has its intended use but we achieve
the same task completion criteria.

Acknowledgments

This work was funded by a fellowship from Robert
Bosch, and in part by the National Science Foun-
dation through award IIS-1526745. We would like
to thank Sravana Reddy for sharing the Yelp cor-
pus used in gender transfer experiments, Zhiting
Hu for providing an implementation of a VAE-
based baseline, and the 11 CMU graduate students
who helped with annotation and manual evalu-
ations. We are also grateful to the anonymous
reviewers for their constructive feedback, and to
Dan Jurafsky, David Jurgens, Vinod Prabhakaran,
and Rob Voigt for valuable discussions at earlier
stages of this work.

References

Mikel Artetxe, Gorka Labaka, Eneko Agirre, and
Kyunghyun Cho. 2018. Unsupervised neural ma-
chine translation. In Proc ICLR.

Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-
gio. 2015. Neural machine translation by jointly
learning to align and translate. In Proc. ICLR.

Christina L Bennett. 2005. Large scale evaluation of
corpus-based synthesizers: Results and lessons from
In Ninth European
the blizzard challenge 2005.
Conference on Speech Communication and Technol-
ogy.

Su Lin Blodgett, Lisa Green, and Brendan O’Connor.
2016. Demographic dialectal variation in social me-
dia: A case study of African-American English. In
Proc. EMNLP.

Ondˇrej Bojar, Rajen Chatterjee, Christian Federmann,
Barry Haddow, Matthias Huck, Chris Hokamp,
Philipp Koehn, Varvara Logacheva, Christof Monz,
Matteo Negri, Matt Post, Carolina Scarton, Lucia
Specia, and Marco Turchi. 2015. Findings of the
2015 workshop on statistical machine translation. In
Proc. WMT, pages 1–46.

Jennifer Coates. 2015. Women, men and language: A
sociolinguistic account of gender differences in lan-
guage. Routledge.

Michael Denkowski and Alon Lavie. 2011. Meteor
1.3: Automatic metric for reliable optimization and

evaluation of machine translation systems. In Proc.
WMT, pages 85–91.

Li Dong, Jonathan Mallinson, Siva Reddy, and Mirella
Lapata. 2017. Learning to paraphrase for question
answering. In Proceedings of the 2017 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 875–886. Association for Computa-
tional Linguistics.

Penelope Eckert and Sally McConnell-Ginet. 2003.
Language and gender. Cambridge University Press.

Zhenxin Fu, Xiaoye Tan, Nanyun Peng, Dongyan
Zhao, and Rui Yan. 2018. Style Transfer in Text:
Exploration and Evaluation. In Proc. AAAI.

Juri Ganitkevitch and Chris Callison-Burch. 2014. The
In Proc. LREC,

multilingual paraphrase database.
pages 4276–4283.

Juri Ganitkevitch, Chris Callison-Burch, Courtney
Napoles, and Benjamin Van Durme. 2011. Learning
sentential paraphrases from bilingual parallel cor-
In Proc. EMNLP,
pora for text-to-text generation.
pages 1168–1179.

Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan
Salakhutdinov, and Eric P Xing. 2017. Toward con-
In Proc. ICML, pages
trolled generation of text.
1587–1596.

Eric Jardine. 2016. Tor, what is it good for? political
repression and the use of online anonymity-granting
technologies. New Media & Society.

Melvin Johnson, Mike Schuster, Quoc V Le, Maxim
Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat,
Fernanda Vi´egas, Martin Wattenberg, Greg Corrado,
et al. 2016. Google’s multilingual neural machine
translation system: enabling zero-shot translation.
arXiv preprint arXiv:1611.04558.

Anna Jørgensen, Dirk Hovy, and Anders Søgaard.
2015. Challenges of studying and processing di-
alects in social media. In Proc. of the Workshop on
Noisy User-generated Text, pages 9–18.

Junbo, Zhao, Y. Kim, K. Zhang, A. M. Rush, and
Y. LeCun. 2017. Adversarially Regularized Autoen-
coders for Generating Discrete Structures. ArXiv e-
prints.

Andrej Karpathy and Li Fei-Fei. 2015. Deep visual-
semantic alignments for generating image descrip-
tions. In Proc. CVPR, pages 3128–3137.

Chlo´e Kiddon, Luke Zettlemoyer, and Yejin Choi.
2016. Globally coherent text generation with neural
checklist models. In Proc. EMNLP, pages 329–339.

Diederik P Kingma and Max Welling. 2014. Auto-

encoding variational bayes. In Proc. ICLR.

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, et al. 2007. Moses: Open source
In Proc.
toolkit for statistical machine translation.
ACL (demonstration sessions), pages 177–180.

Robin Tolmach Lakoff and Mary Bucholtz. 2004. Lan-
guage and woman’s place: Text and commentaries,
volume 3. Oxford University Press, USA.

Guillaume Lample, Alexis Conneau, Ludovic Denoyer,
and Marc’Aurelio Ranzato. 2018. Unsupervised
machine translation using monolingual corpora only.
In Proc. ICLR.

J. Li, R. Jia, H. He, and P. Liang. 2018. Delete, Re-
trieve, Generate: A Simple Approach to Sentiment
and Style Transfer. ArXiv e-prints.

Jiwei Li, Michel Galley, Chris Brockett, Georgios P
Spithourakis, Jianfeng Gao, and Bill Dolan. 2016. A
persona-based neural conversation model. In Proc.
ACL.

Minh-Thang Luong, Hieu Pham, and Christopher D.
Manning. 2015. Effective approaches to attention-
based neural machine translation. In Proc. EMNLP.

Nitin Madnani and Bonnie J Dorr. 2010. Generat-
ing phrasal and sentential paraphrases: A survey
of data-driven methods. Computational Linguistics,
36(3):341–387.

Jonathan Mallinson, Rico Sennrich, and Mirella Lap-
ata. 2017. Paraphrasing revisited with neural ma-
chine translation. In Proce. EACL, volume 1, pages
881–893.

Burt L. Monroe, Michael P. Colaresi, and Kevin M.
Quinn. 2008. Fightin words: Lexical feature selec-
tion and evaluation for identifying the content of po-
litical conﬂict. Political Analysis.

Dong Nguyen, A. Seza Do˘gru¨oz, Carolyn P. Ros´e,
and Franciska de Jong. 2016. Computational soci-
olinguistics: A survey. Computational Linguistics,
42(3):537–593.

Xing Niu, Marianna Martindale, and Marine Carpuat.
2017. A study of style in machine translation: Con-
trolling the formality of machine translation output.
In Proc. EMNLP, pages 2804–2809.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
In Proc. ACL,
evaluation of machine translation.
pages 311–318.

Ella Rabinovich, Shachar Mirkin, Raj Nath Patel, Lu-
cia Specia, and Shuly Wintner. 2016. Personal-
ized machine translation: Preserving original author
traits. In Proc. EACL.

Sravana Reddy and Kevin Knight. 2016. Obfuscating
In Proc. of Work-
gender in social media writing.
shop on Natural Language Processing and Compu-
tational Social Science, pages 17–26.

Alan Ritter, Colin Cherry, and William B Dolan. 2011.
Data-driven response generation in social media. In
Proc. EMNLP, pages 583–593.

Rachel Rudinger, Chandler May,

and Benjamin
Van Durme. 2017. Social bias in elicited natural lan-
guage inferences. In Proc. of the First Workshop on
Ethics in Natural Language Processing, page 74.

Abigail See, Peter J Liu, and Christopher D Manning.
2017. Get to the point: Summarization with pointer-
generator networks. In Proc. ACL.

Rico Sennrich, Barry Haddow, and Alexandra Birch.
2016. Controlling politeness in neural machine
In Proc. NAACL,
translation via side constraints.
pages 35–40.

Tianxiao Shen, Tao Lei, Regina Barzilay, and Tommi
Jaakkola. 2017. Style transfer from non-parallel text
by cross-alignment. In Proc. NIPS.

Alessandro Sordoni, Michel Galley, Michael Auli,
Chris Brockett, Yangfeng Ji, Margaret Mitchell,
Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. 2015.
A neural network approach to context-sensitive
In Proc.
generation of conversational responses.
NAACL.

Steven J. Spencer, Claude M. Steele, and Diane M.
Quinn. 1999. Stereotype Threat and Women’s Math
Performance. Journal of Experimental Social Psy-
chology, 35:4–28.

Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.
Sequence to sequence learning with neural net-
works. In Proc. NIPS, pages 3104–3112.

Oriol Vinyals and Quoc Le. 2015. A neural conversa-
tional model. In Proc. ICML Deep Learning Work-
shop.

Rob Voigt, David Jurgens, Vinodkumar Prabhakaran,
Dan Jurafsky, and Yulia Tsvetkov. 2018. RtGender:
A corpus for studying differential responses to gen-
der. In Proc. LREC.

Tsung-Hsien Wen, David Vandyke, Nikola Mrksic,
Milica Gasic, Lina M Rojas-Barahona, Pei-Hao Su,
Stefan Ultes, and Steve Young. 2017. A network-
based end-to-end trainable task-oriented dialogue
system. In Proc. EACL.

John Wieting, Jonathan Mallinson, and Kevin Gimpel.
2017. Learning paraphrastic sentence embeddings
from back-translated bitext. In Proc. EMNLP, pages
274–285.

Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho,
Aaron Courville, Ruslan Salakhudinov, Rich Zemel,
and Yoshua Bengio. 2015. Show, attend and tell:
Neural image caption generation with visual atten-
tion. In Proc. ICML, pages 2048–2057.

A Supplementary Material

In Tables 7, 8, and 9 we present the style transfer
accuracy results broken-down to style categories.
We denote the Cross-aligned Auto-Encoder model
as CAE and our model as Back-translation for
Style Transfer (BST).

Model
Style transfer
CAE male → female
BST male → female
female → male
CAE
female → male
BST

Acc
64.75
54.59
56.05
59.49

Table 7: Gender transfer accuracy.

Model
CAE
BST
CAE
BST

Style transfer
republican → democratic
republican → democratic
democratic → republican
democratic → republican

Acc
65.44
80.55
86.20
95.47

Table 8: Political slant transfer accuracy.

Model
CAE
BST
CAE
BST

Style transfer
negative → positive
negative → positive
positive → negative
positive → negative

Acc
81.63
95.68
79.65
81.65

Table 9: Sentiment modiﬁcation accuracy.

In Table 10, we detail the accuracy of the gender
classiﬁer on generated style-transfered sentences
by an auto-encoder; Table 11 shows the accuracy
of transfer of political slant. The experiments are
setup as described in Section 5.1. We denote the
Auto-Encoder as (AE) and our model as Back-
translation for Style Transfer (BST).

Style transfer
Model
male → female
AE
BST male → female
female → male
AE
female → male
BST

Acc
41.48
54.59
41.88
59.49

Table 10: Gender transfer accuracy for Auto-
encoder.

To evaluate the preservation of meaning by the
Auto-Encoder, the experiments were setup as de-
scribed in Section 5.2. We conducted four tests,

Model
AE
BST
AE
BST

Style transfer
republican → democratic
republican → democratic
democratic → republican
democratic → republican

Acc
60.76
80.55
64.05
95.47

Table 11: Political slant transfer accuracy for
Auto-encoder.

each of 20 random samples for each type of style
transfer. Note that we did not ask about appropri-
ateness of the style transfer in this test, or ﬂuency
of outputs, only about meaning preservation. We
show the results of human evaluation in Table 12

Style transfer
male → female
female → male
republican → democratic
democratic → republican

=
43.3
45.0
43.3
55.00

AE BST
43.3
13.4
45.0
10.0
53.3
3.4
33.3
11.7

Table 12: Human preference for meaning preser-
vation in percentages.

Examples of the original and style-transfered
sentences generated by the baseline and our model
are shown in Table 13

Input Sentence

BST

CAE
male → female
i got ta get the chicken breast .

we could n’t go back and i would
be able to get me to get me.

the place is small but cosy and

the staff and the place is very

very clean.

nice.

save

yourself

the

huge

female → male
the sauces are excellent.

would i discourage someone else

i believe i would be back?

my husband ordered the chicken

salad and the fries.

great place to go back and try a

lot of which you ’ ve never had
to try or could not have been
able to get some of the best.
the place is great but very clean

and very friendly.

going

you

are
disappointed.
i wouldn’t go back!

to

be

tom,

i wish u would bring

i agree,

senator warren and

brian, i am proud to have you

the sauces - lrb - - rrb - - rrb -

and - rrb -.

my wife ordered the mac-n-
cheese and the salad - lrb - $
00 minutes - rrb - was cooked.

republican → democratic
i am proud of you and your vote

for us!

could be.

and then we will be praying for
them and i am proud of this
position and i am proud of
democratic → republican
a lot , i am proud of you <unk>.

and in bigotry–racism,
programming, cut,
granddaughters,
unprescedented and excludes.
thank you for standing up for us

i will continue to ﬁght for you

and the rest of our
democracy!

representing me.

keep up and dont know, you

have a lot of respect as
breitbart

as a hoosier, i’m praying for

you sir.

thanks for standing up for the
constitution and get rid of
obamacare, homophobie
, cut, and actuality.

and i am proud of us!

for us, senator scott!

thanks lawmaker for all you do

thank you for standing up for

do you for standing up for highly

my wife ordered country fried

steak and eggs.

great place to visit and maybe
ﬁnd that one rare item you
just have never seen or can
not ﬁnd anywhere else.

headaches.

from going?

my husband ordered the salad
and the dressing - lrb - blue
cheese - rrb - was watered
down.

i will continue praying for you
and the decisions made by
our government!

change.

all talk and no action-why dont
you have some guts like
breitbart

as a hoosier, i thank you, rep.

visclosky.

justice and against bigotry-
-racism, homophobia, sexism
, misogyny, religious and
xenophobia.

thank you for all you are do-
for us, attorney general
ing

harris!

crap fries, hard hamburger buns,
burger tasted like crap!
the people behind the counter
were not friendly whatsoever.

like like!

friendly.

negative → positive
good selection, fresh food, like

empathy,

best
but it was very nice!

the

food,

the people who the staff were

the people here are really good.

this place is bad news!

this place is great!

this place is amazing!

the food is excellent and the

positive → negative
the food is the food and the

service is exceptional!

service is terrible.

great as always,

i

love there

i really don’t eat

food.

i would recommend a visit here.

horrible as,
here.

i would not recommend a dinner
here.

the food is horrible and the

service is terrible.
really disappointed,
be
i will not recommend this place.

i couldn’t

back.

Table 13: Gender, Political slant and Sentiment style transfer examples. In addition to better preserving
meaning, sentences generated by the BST model are generally grammatically better structured.

Style Transfer Through Back-Translation

Shrimai Prabhumoye, Yulia Tsvetkov, Ruslan Salakhutdinov, Alan W Black
Carnegie Mellon University, Pittsburgh, PA, USA
{sprabhum,ytsvetko,rsalakhu,awb}@cs.cmu.edu

8
1
0
2
 
y
a
M
 
4
2
 
 
]
L
C
.
s
c
[
 
 
3
v
0
0
0
9
0
.
4
0
8
1
:
v
i
X
r
a

Abstract

Style transfer is the task of rephrasing the
text to contain speciﬁc stylistic proper-
ties without changing the intent or affect
within the context. This paper introduces
a new method for automatic style trans-
fer. We ﬁrst learn a latent representation of
the input sentence which is grounded in a
language translation model in order to bet-
ter preserve the meaning of the sentence
while reducing stylistic properties. Then
adversarial generation techniques are used
to make the output match the desired style.
We evaluate this technique on three dif-
sentiment,
ferent style transformations:
gender and political slant.
Compared
to two state-of-the-art style transfer mod-
eling techniques we show improvements
both in automatic evaluation of style trans-
fer and in manual evaluation of meaning
preservation and ﬂuency.

1

Introduction

Intelligent, situation-aware applications must pro-
duce naturalistic outputs,
lexicalizing the same
meaning differently, depending upon the envi-
ronment. This is particularly relevant for lan-
guage generation tasks such as machine trans-
lation (Sutskever et al., 2014; Bahdanau et al.,
2015), caption generation (Karpathy and Fei-Fei,
2015; Xu et al., 2015), and natural language gen-
eration (Wen et al., 2017; Kiddon et al., 2016). In
conversational agents (Ritter et al., 2011; Sordoni
et al., 2015; Vinyals and Le, 2015; Li et al., 2016),
for example, modulating the politeness style, to
sound natural depending upon a situation: at a
the video is start-
party with friends “Shut up!
ing!”, or in a professional setting “Please be quiet,
the video will begin shortly.”.

These goals have motivated a considerable
amount of recent research efforts focused at “con-
trolled” language generation—aiming at separat-
ing the semantic content of what is said from
the stylistic dimensions of how it is said. These
include approaches relying on heuristic substitu-
tions, deletions, and insertions to modulate de-
mographic properties of a writer (Reddy and
Knight, 2016),
integrating stylistic and demo-
graphic speaker traits in statistical machine trans-
lation (Rabinovich et al., 2016; Niu et al., 2017),
and deep generative models controlling for a par-
ticular stylistic aspect, e.g., politeness (Sennrich
et al., 2016), sentiment, or tense (Hu et al., 2017;
Shen et al., 2017). The latter approaches to style
transfer, while more powerful and ﬂexible than
heuristic methods, have yet to show that in addi-
tion to transferring style they effectively preserve
meaning of input sentences.

This paper introduces a novel approach to trans-
ferring style of a sentence while better preserv-
ing its meaning. We hypothesize—relying on the
study of Rabinovich et al. (2016) who showed
that author characteristics are signiﬁcantly ob-
fuscated by both manual and automatic machine
translation—that grounding in back-translation is
a plausible approach to rephrase a sentence while
reducing its stylistic properties. We thus ﬁrst use
back-translation to rephrase the sentence and re-
duce the effect of the original style; then, we gen-
erate from the latent representation, using separate
style-speciﬁc generators controlling for style (§2).
We focus on transferring author attributes:
(1) gender and (2) political slant, and (3) on sen-
timent modiﬁcation. The second task is novel:
given a sentence by an author with a particular po-
litical leaning, rephrase the sentence to preserve
its meaning but to confound classiﬁers of politi-
cal slant (§3). The task of sentiment modiﬁcation
enables us to compare our approach with state-of-

Figure 1: Style transfer pipeline: to rephrase a sentence and reduce its stylistic characteristics, the sen-
tence is back-translated. Then, separate style-speciﬁc generators are used for style transfer.

the-art models (Hu et al., 2017; Shen et al., 2017).
Style transfer is evaluated using style classi-
ﬁers trained on held-out data. Our back-translation
style transfer model outperforms the state-of-the-
art baselines (Shen et al., 2017; Hu et al., 2017)
on the tasks of political slant and sentiment mod-
iﬁcation; 12% absolute improvement was attained
for political slant transfer, and up to 7% absolute
improvement in modiﬁcation of sentiment (§5).
Meaning preservation was evaluated manually, us-
ing A/B testing (§4). Our approach performs bet-
ter than the baseline on the task of transferring
gender and political slant. Finally, we evaluate the
ﬂuency of the generated sentences using human
evaluation and our model outperforms the baseline
in all experiments for ﬂuency.

The main contribution of this work is a new
approach to style transfer that outperforms state-
of-the-art baselines in both the quality of input–
output correspondence (meaning preservation and
ﬂuency), and the accuracy of style transfer. The
secondary contribution is a new task that we pro-
pose to evaluate style transfer: transferring politi-
cal slant.

2 Methodology

1 , . . . , x(n)

Given two datasets X 1 = {x(1)
1 } and
X 2 = {x(1)
2 , . . . , x(n)
2 } which represent two dif-
ferent styles s1 and s2, respectively, our task is to
generate sentences of the desired style while pre-
serving the meaning of the input sentence. Speciﬁ-
cally, we generate samples of dataset X 1 such that
they belong to style s2 and samples of X 2 such
that they belong to style s1. We denote the out-
put of dataset X 1 transfered to style s2 as ˆX 1 =
{ˆx(1)
2 } and the output of dataset X 2
transferred to style s1 as ˆX 2 = {ˆx(1)
1 }.
Hu et al. (2017) and Shen et al. (2017) in-
troduced state-of-the-art style transfer models
that use variational auto-encoders (Kingma and

2 , . . . , ˆx(n)

1 , . . . , ˆx(n)

Welling, 2014, VAEs) and cross-aligned auto-
encoders, respectively, to model a latent content
variable z. The latent content variable z is a code
which is not observed. The generative model con-
ditions on this code during the generation pro-
cess. Our aim is to design a latent code z which
(1) represents the meaning of the input sentence
grounded in back-translation and (2) weakens the
style attributes of author’s traits. To model the
former, we use neural machine translation. Prior
work has shown that the process of translating a
sentence from a source language to a target lan-
guage retains the meaning of the sentence but does
not preserve the stylistic features related to the au-
thor’s traits (Rabinovich et al., 2016). We hypoth-
esize that a latent code z obtained through back-
translation will normalize the sentence and devoid
it from style attributes speciﬁc to author’s traits.

Figure 1 shows the overview of the proposed
In our framework, we ﬁrst train a ma-
method.
chine translation model from source language e
to a target language f . We also train a back-
translation model from f to e. Let us assume our
styles s1 and s2 correspond to DEMOCRATIC and
REPUBLICAN style, respectively. In Figure 1, the
input sentence i thank you, rep. visclosky.
is la-
beled as DEMOCRATIC. We translate the sentence
using the e → f machine translation model and
generate the parallel sentence in the target lan-
guage f : je vous remercie, rep. visclosky. Using
the ﬁxed encoder of the f → e machine transla-
tion model, we encode this sentence in language
f . The hidden representation created by this en-
coder of the back-translation model is used as z.
We condition our generative models on this z. We
then train two separate decoders for each style
s1 and s2 to generate samples in these respective
styles in source language e. Hence the sentence
could be translated to the REPUBLICAN style us-
ing the decoder for s2. For example, the sentence
i’m praying for you sir. is the REPUBLICAN ver-

Figure 2: The latent representation from back-translation and the style classiﬁer feedback are used to
guide the style-speciﬁc generators.

sion of the input sentence and i thank you, senator
visclosky. is the more DEMOCRATIC version of it.
Note that in this setting, the machine translation
and the encoder of the back-translation model re-
main ﬁxed. They are not dependent on the data
we use across different tasks. This facilitates re-
usability and spares the need of learning separate
models to generate z for a new style data.

2.1 Meaning-Grounded Representation

In this section we describe how we learn the la-
tent content variable z using back-translation. The
e → f machine translation and f → e back-
translation models are trained using a sequence-to-
sequence framework (Sutskever et al., 2014; Bah-
danau et al., 2015) with style-agnostic corpus. The
style-speciﬁc sentence i thank you, rep. visclosky.
in source language e is translated to the target lan-
guage f to get je vous remercie, rep. visclosky.
The individual tokens of this sentence are then
encoded using the encoder of the f → e back-
translation model. The learned hidden representa-
tion is z.

Formally, let θE represent the parameters of the
encoder of f → e translation system. Then z is
given by:

for each style. The sentence generated by a de-
coder is passed through the classiﬁer. The loss
of the classiﬁer for the generated sentence is used
as feedback to guide the decoder for the gener-
ation process. The target attribute of the clas-
siﬁer is determined by the decoder from which
the output is generated. For example, in the case
of DEMOCRATIC decoder, the target attribute is
DEMOCRATIC and for the REPUBLICAN decoder
the target is REPUBLICAN.

2.2.1 Style Classiﬁers

We train a convolutional neural network (CNN)
classiﬁer to accurately predict the given style. We
also use it to evaluate the error in the generated
samples for the desired style. We train the classi-
ﬁer in a supervised manner. The classiﬁer accepts
either discrete or continuous tokens as inputs. This
is done such that the generator output can be used
as input to the classiﬁer. We need labeled exam-
ples to train the classiﬁer such that each instance
in the dataset X should have a label in the set
s = {s1, s2}. Let θC denote the parameters of
the classiﬁer. The objective to train the classiﬁer
is given by:

z = Encoder(xf ; θE)

(1)

Lclass(θC) = EX [log qC(s|x)].

(2)

where, xf is the sentence x in language f . Specif-
ically, xf is the output of e → f translation sys-
tem when xe is given as input. Since z is derived
from a non-style speciﬁc process, this Encoder is
not style speciﬁc.

2.2 Style-Speciﬁc Generation

Figure 2 shows the architecture of the generative
model for generating different styles. Using the
encoder embedding z, we train multiple decoders

To improve the accuracy of the classiﬁer, we aug-
ment classiﬁer’s inputs with style-speciﬁc lexi-
cons. We concatenate binary style indicators to
each input word embedding in the classiﬁer. The
indicators are set to 1 if the input word is present
in a style-speciﬁc lexicon; otherwise they are set to
0. Style lexicons are extracted using the log-odds
ratio informative Dirichlet prior (Monroe et al.,
2008), a method that identiﬁes words that are sta-
tistically overrepresented in each of the categories.

2.2.2 Generator Learning
We use a bidirectional LSTM to build our de-
coders which generate the sequence of tokens ˆx =
{x1, · · · xT }. The sequence ˆx is conditioned on
the latent code z (in our case, on the machine
translation model).
In this work we use a cor-
pus translated to French by the machine transla-
tion system as the input to the encoder of the back-
translation model. The same encoder is used to en-
code sentences of both styles. The representation
created by this encoder is given by Eq 1. Samples
are generated as follows:

ˆx ∼ z = p(ˆx|z)

=

p(ˆxt|ˆx<t, z)

(cid:89)

t

(3)

(4)

where, ˆx<t are the tokens generated before ˆxt.

Tokens are discrete and non-differentiable. This
makes it difﬁcult to use a classiﬁer, as the gen-
eration process samples discrete tokens from the
multinomial distribution parametrized using soft-
max function at each time step t. This non-
in turn, breaks down gradient
differentiability,
propagation from the discriminators to the gen-
erator.
Instead, following Hu et al. (2017) we
use a continuous approximation based on softmax,
along with the temperature parameter which an-
neals the softmax to the discrete case as training
proceeds. To create a continuous representation of
the output of the generative model which will be
given as an input to the classiﬁer, we use:

ˆxt ∼ softmax(ot/τ ),

where, ot is the output of the generator and τ is the
temperature which decreases as the training pro-
ceeds. Let θG denote the parameters of the gen-
erators. Then the reconstruction loss is calculated
using the cross entropy function, given by:

Lrecon(θG; x) = EqE (z|x)[log pgen(x|z)]

(5)

Here, the back-translation encoder E creates the
latent code z by:

z = E(x) = qE(z|x)

(6)

The generative loss Lgen is then given by:

minθgenLgen = Lrecon + λcLclass

(7)

where Lrecon is given by Eq. (5), Lclass is given
by Eq (2) and λc is a balancing parameter.

We also use global attention of (Luong et al.,
2015) to aid our generators. At each time step t of
the generation process, we infer a variable length
alignment vector at:

at =

(cid:80)

exp(score(ht, ¯hs))
s(cid:48) exp(score(ht, ¯hs(cid:48) )

(8)

t , ¯hs),

score(ht, ¯hs) = dot(hT

(9)
where ht is the current target state and ¯hs are all
source states. While generating sentences, we use
the attention vector to replace unknown characters
(UNK) using the copy mechanism in (See et al.,
2017).

3 Style Transfer Tasks

Much work in computational social science has
shown that people’s personal and demographic
characteristics—either publicly observable (e.g.,
age, gender) or private (e.g.,
religion, politi-
cal afﬁliation)—are revealed in their linguistic
choices (Nguyen et al., 2016). There are practi-
cal scenarios, however, when these attributes need
to be modulated or obfuscated. For example,
some users may wish to preserve their anonymity
online, for personal security concerns (Jardine,
2016), or to reduce stereotype threat (Spencer
et al., 1999). Modulating authors’ attributes while
preserving meaning of sentences can also help
generate demographically-balanced training data
for a variety of downstream applications.

Moreover, prior work has shown that the qual-
ity of language identiﬁcation and POS tagging
degrades signiﬁcantly on African American Ver-
nacular English (Blodgett et al., 2016; Jørgensen
et al., 2015); YouTube’s automatic captions have
higher error rates for women and speakers from
Synthesiz-
Scotland (Rudinger et al., 2017).
ing balanced training data—using style transfer
techniques—is a plausible way to alleviate bias
present in existing NLP technologies.

We thus focus on two tasks that have practi-
cal and social-good applications, and also accu-
rate style classiﬁers. To position our method with
respect to prior work, we employ a third task of
sentiment transfer, which was used in two state-
of-the-art approaches to style transfer (Hu et al.,
2017; Shen et al., 2017). We describe the three
tasks and associated dataset statistics below. The
methodology that we advocate is general and can
be applied to other styles, for transferring various

social categories, types of bias, and in multi-class
settings.

Gender.
In sociolinguistics, gender is known to
be one of the most important social categories
driving language choice (Eckert and McConnell-
Ginet, 2003; Lakoff and Bucholtz, 2004; Coates,
2015). Reddy and Knight (2016) proposed a
heuristic-based method to obfuscate gender of a
writer. This method uses statistical association
measures to identify gender-salient words and sub-
stitute them with synonyms typically of the oppo-
site gender. This simple approach produces highly
ﬂuent, meaning-preserving sentences, but does not
allow for more general rephrasing of sentence be-
yond single-word substitutions. In our work, we
adopt this task of transferring the author’s gender
and adapt it to our experimental settings.

We used Reddy and Knight’s (2016) dataset of
reviews from Yelp annotated for two genders cor-
responding to markers of sex.1 We split the re-
views to sentences, preserving the original gender
labels. To keep only sentences that are strongly
indicative of a gender, we then ﬁltered out gender-
neutral sentences (e.g., thank you) and sentences
whose likelihood to be written by authors of one
gender is lower than 0.7.2

Political slant. Our second dataset is comprised
of top-level comments on Facebook posts from all
412 current members of the United States Sen-
ate and House who have public Facebook pages
(Voigt et al., 2018).3 Only top-level comments
that directly respond to the post are included. Ev-
ery comment to a Congressperson is labeled with
the Congressperson’s party afﬁliation: democratic
or republican. Topic and sentiment in these com-
ments reveal commenter’s political slant. For ex-
ample, defund them all, especially when it comes
to the illegal immigrants . and thank u james,
praying for all the work u do . are republican,
whereas on behalf of the hard-working nh public
school teachers- thank you ! and we need more
strong voices like yours ﬁghting for gun control .

1We note that gender may be considered along a spec-
trum (Eckert and McConnell-Ginet, 2003), but use gender
as a binary variable due to the absence of corpora with
continuous-valued gender annotations.

2We did not experiment with other threshold values.
3The posts and comments are all public; however, to pro-
tect the identity of Facebook users in this dataset Voigt et al.
(2018) have removed all identifying user information as well
as Facebook-internal information such as User IDs and Post
IDs, replacing these with randomized ID numbers.

Style
gender
political
sentiment

dev

train

class
test
2.57M 2.67M 4.5K 535K
540K
80K
56K
4K
444K 63.5K 127K
2M

Table 1: Sentence count in style-speciﬁc corpora.

represent examples of democratic sentences. Our
task is to preserve intent of the commenter (e.g.,
to thank their representative), but to modify their
observable political afﬁliation, as in the example
in Figure 1. We preprocessed and ﬁltered the
comments similarly to the gender-annotated cor-
pus above.

Sentiment. To compare our work with the state-
of-the-art approaches of style transfer for non-
parallel corpus we perform sentiment
transfer,
replicating the models and experimental setups of
Hu et al. (2017) and Shen et al. (2017). Given a
positive Yelp review, a style transfer model will
generate a similar review but with an opposite sen-
timent. We used Shen et al.’s (2017) corpus of
reviews from Yelp. They have followed the stan-
dard practice of labeling the reviews with rating of
higher than three as positive and less than three as
negative. They have also split the reviews to sen-
tences and assumed that the sentence has the same
sentiment as the review.

Dataset statistics. We summarize below cor-
pora statistics for the three tasks: transferring gen-
der, political slant, and sentiment. The dataset for
sentiment modiﬁcation task was used as described
in (Shen et al., 2017). We split Yelp and Facebook
corpora into four disjoint parts each: (1) a training
corpus for training a style classiﬁer (class); (2) a
training corpus (train) used for training the style-
speciﬁc generative model described in §2.2; (3)
development and (4) test sets. We have removed
from training corpora class and train all sentences
that overlap with development and test corpora.
Corpora sizes are shown in Table 1.

Table 2 shows the approximate vocabulary sizes
used for each dataset. The vocabulary is the same
for both the styles in each experiment.

Style
Vocabulary

gender
20K

political
20K

sentiment
10K

Table 2: Vocabulary sizes of the datasets.

Table 3 summarizes sentence statistics. All the

sentences have maximum length of 50 tokens.

Style
male
female
republican
democratic
negative
positive

Avg. Length %data
50.00
50.00
50.00
50.00
39.81
60.19

18.08
18.21
16.18
16.01
9.66
8.45

Table 3: Average sentence length and class distri-
bution of style corpora.

5 Results

4 Experimental Setup

In what follows, we describe our experimental set-
tings, including baselines used, hyperparameter
settings, datasets, and evaluation setups.

Baseline. We compare our model against the
“cross-aligned” auto-encoder (Shen et al., 2017),
which uses style-speciﬁc decoders to align the
style of generated sentences to the actual distribu-
tion of the style. We used the off-the-shelf senti-
ment model released by Shen et al. (2017) for the
sentiment experiments. We also separately train
this model for the gender and political slant using
hyper-parameters detailed below.4

Translation data. We trained an English–
French neural machine translation system and a
French–English back-translation system. We used
data from Workshop in Statistical Machine Trans-
lation 2015 (WMT15) (Bojar et al., 2015) to train
our translation models. We used the French–
English data from the Europarl v7 corpus, the
news commentary v10 corpus and the common
crawl corpus from WMT15. Data were tokenized
using the Moses tokenizer (Koehn et al., 2007).
Approximately 5.4M English–French parallel sen-
tences were used for training. A vocabulary size of
100K was used to train the translation systems.

Hyperparameter settings.
the experi-
ments, the generator and the encoders are a two-
layer LSTM with an input size of 300 and the hid-
den dimension of 500. The encoders are bidirec-

In all

4In addition, we compared our model with the current
state-of-the-art approach introduced by Hu et al. (2017); Shen
et al. (2017) use this method as baseline, obtaining compara-
ble results. We reproduced the results reported in (Hu et al.,
2017) using their tasks and data. However, the same model
trained on our political slant datasets (described in §3), ob-
tained an almost random accuracy of 50.98% in style transfer.
We thus omit these results.

tional. The generator samples a sentence of max-
imum length 50. All the generators use global at-
tention vectors of size 500. The CNN classiﬁer
is trained with 100 ﬁlters of size 5, with max-
the
pooling. The input to CNN is of size 302:
300-dimensional word embedding plus two bits
for membership of the word in our style lexicons,
as described in §2.2.1. Balancing parameter λc is
set to 15. For sentiment task, we have used set-
tings provided in (Shen et al., 2017).

We evaluate our approach along three dimensions.
(1) Style transfer accuracy, measuring the propor-
tion of our models’ outputs that generate sentences
of the desired style. The style transfer accuracy
is performed using classiﬁers trained on held-out
train data that were not used in training the style
transfer models. (2) Preservation of meaning. (3)
Fluency, measuring the readability and the natu-
ralness of the generated sentences. We conducted
human evaluations for the latter two.

In what follows, we ﬁrst present the quality of
our neural machine translation systems, then we
present the evaluation setups, and then present the
results of our experiments.

quality. The

Translation
BLEU scores
achieved for English–French MT system is
32.52 and for French–English MT system is
31.11; these are strong translation systems. We
deliberately chose a European language close to
English for which massive amounts of parallel
data are available and translation quality is high,
to concentrate on the style generation, rather than
improving a translation system. 5

5.1 Style Transfer Accuracy

We measure the accuracy of style transfer for the
generated sentences using a pre-trained style clas-
siﬁer (§2.2.1). The classiﬁer is trained on data that
is not used for training our style transfer genera-
tive models (as described in §3). The classiﬁer has
an accuracy of 82% for the gender-annotated cor-
pus, 92% accuracy for the political slant dataset
and 93.23% accuracy for the sentiment dataset.

5Alternatively, we could use a pivot language that is ty-
pologically more distant from English, e.g., Chinese. In this
case we hypothesize that stylistic traits would be even less
preserved in translation, but the quality of back-translated
sentences would be worse. We have not yet investigated how
the accuracy of the translation model, nor the language of
translation affects our models.

We transfer the style of test sentences and then
test the classiﬁcation accuracy of the generated
sentences for the opposite label. For example, if
we want to transfer the style of male Yelp reviews
to female, then we use the ﬁxed common encoder
of the back-translation model to encode the test
male sentences and then we use the female gener-
ative model to generate the female-styled reviews.
We then test these generated sentences for the fe-
male label using the gender classiﬁer.

Experiment
Gender
Political slant
Sentiment

CAE
60.40
75.82
80.43

BST
57.04
88.01
87.22

Table 4: Accuracy of the style transfer in gener-
ated sentences.

In Table 4, we detail the accuracy of each
classiﬁer on generated style-transfered sentences.6
We denote the Shen et al.’s (2017) Cross-aligned
Auto-Encoder model as CAE and our model as
Back-translation for Style Transfer (BST).

On two out of three tasks our model substan-
tially outperforms the baseline, by up to 12% in
political slant transfer, and by up to 7% in senti-
ment modiﬁcation.

5.2 Preservation of Meaning

Although we attempted to use automatics mea-
sures to evaluate how well meaning is preserved
in our transformations; measures such as BLEU
(Papineni et al., 2002) and Meteor (Denkowski
and Lavie, 2011), or even cosine similarity be-
tween distributed representations of sentences do
not capture this distance well.

Meaning preservation in style transfer is not
trivial to deﬁne as literal meaning is likely to
change when style transfer occurs. For example
“My girlfriend loved the desserts” vs “My partner
liked the desserts”. Thus we must relax the con-
dition of literal meaning to intent or affect of the
utterance within the context of the discourse. Thus
if the intent is to criticize a restaurant’s service
in a review, changing “salad” to “chicken” could
still have the same effect but if the intent is to or-
der food that substitution would not be acceptable.
Ideally we wish to evaluate transfer within some

6In each experiment, we report aggregated results across
directions of style transfer; same results broke-down to style
categories are listed in the Supplementary Material.

Experiment
Gender
Political slant
Sentiment

CAE No Pref. BST
43.41
41.36
15.23
45.90
39.55
14.55
40.91
23.18
35.91

Table 5: Human preference for meaning preserva-
tion in percentages.

downstream task and ensure that the task has the
same outcome even after style transfer. This is a
hard evaluation and hence we resort to a simpler
evaluation of the “meaning” of the sentence.

We set up a manual pairwise comparison fol-
lowing Bennett (2005). The test presents the orig-
inal sentence and then, in random order, its corre-
sponding sentences produced by the baseline and
our models. For the gender style transfer we asked
“Which transferred sentence maintains the same
sentiment of the source sentence in the same se-
mantic context (i.e. you can ignore if food items
are changed)”. For the task of changing the po-
litical slant, we asked “Which transferred sen-
tence maintains the same semantic intent of the
source sentence while changing the political po-
sition”. For the task of sentiment transfer we
have followed the annotation instruction in (Shen
et al., 2017) and asked “Which transferred sen-
tence is semantically equivalent to the source sen-
tence with an opposite sentiment”

We then count the preferences of the eleven
participants, measuring the relative acceptance of
the generated sentences.7 A third option “=” was
given to participants to mark no preference for ei-
ther of the generated sentence. The “no prefer-
ence” option includes choices both are equally bad
and both are equally good. We conducted three
tests one for each type of experiment - gender, po-
litical slant and sentiment. We also divided our
annotation set into short (#tokens ≤ 15) and long
(15 < #tokens ≤ 30) sentences for the gender and
the political slant experiment. In each set we had
20 random samples for each type of style trans-
fer. In total we had 100 sentences to be annotated.
Note that we did not ask about appropriateness of
the style transfer in this test, or ﬂuency of outputs,
only about meaning preservation.

The results of human evaluation are presented
in Table 5.
Although a no-preference op-
tion was chosen often—showing that state-of-
the-art systems are still not on par with hu-

7None of the human judges are authors of this paper

man expectations—the BST models outperform
the baselines in the gender and the political slant
transfer tasks.

Crucially, the BST models signiﬁcantly outper-
form the CAE models when transferring style in
longer and harder sentences. Annotators preferred
the CAE model only for 12.5% of the long sen-
tences, compared to 47.27% preference for the
BST model.

tional content, and to modify sentiment while pre-
serving meaning or intent. On the other hand, the
style-transfer accuracy for gender is lower for BST
model but the preservation of meaning is much
better for the BST model, compared to CAE model
and to ”No preference” option. This means that
the BST model does better job at closely repre-
senting the input sentence while taking a mild hit
in the style transfer accuracy.

5.3 Fluency

6 Related Work

Finally, we evaluate the ﬂuency of the generated
sentences. Fluency was rated from 1 (unreadable)
to 4 (perfect) as is described in (Shen et al., 2017).
We randomly selected 60 sentences each gener-
ated by the baseline and the BST model.

The results shown in Table 6 are averaged

scores for each model.

Experiment
Gender
Political slant
Sentiment
Overall
Overall Short
Overall Long

CAE BST
2.81
2.42
2.87
2.79
3.18
3.09
2.91
2.70
3.11
3.05
2.62
2.18

Table 6: Fluency of the generated sentences.

BST outperforms the baseline overall. It is in-
teresting to note that BST generates signiﬁcantly
more ﬂuent longer sentences than the baseline
model. Since the average length of sentences was
higher for the gender experiment, BST notably
outperformed the baseline in this task, relatively to
the sentiment task where the sentences are shorter.
Examples of the original and style-transfered sen-
tences generated by the baseline and our model are
shown in the Supplementary Material.

5.4 Discussion

The loss function of the generators given in Eq.
5 includes two competing terms, one to improve
meaning preservation and the other to improve the
style transfer accuracy.
In the task of sentiment
modiﬁcation, the BST model preserved meaning
worse than the baseline, on the expense of be-
ing better at style transfer. We note, however,
that the sentiment modiﬁcation task is not partic-
ularly well-suited for evaluating style transfer: it
is particularly hard (if not impossible) to disentan-
gle the sentiment of a sentence from its proposi-

Style transfer with non-parallel text corpus has be-
come an active research area due to the recent ad-
vances in text generation tasks. Hu et al. (2017)
use variational auto-encoders with a discriminator
to generate sentences with controllable attributes.
The method learns a disentangled latent represen-
tation and generates a sentence from it using a
code. This paper mainly focuses on sentiment
and tense for style transfer attributes. It evaluates
the transfer strength of the generated sentences
but does not evaluate the extent of preservation
In our
of meaning in the generated sentences.
work, we show a qualitative evaluation of mean-
ing preservation.

Shen et al. (2017) ﬁrst present a theoretical anal-
ysis of style transfer in text using non-parallel
corpus. The paper then proposes a novel cross-
alignment auto-encoders with discriminators ar-
It mainly fo-
chitecture to generate sentences.
cuses on sentiment and word decipherment for
style transfer experiments.

Fu et al. (2018) explore two models for style
transfer. The ﬁrst approach uses multiple decoders
for each type of style.
In the second approach,
style embeddings are used to augment the encoded
representations, so that only one decoder needs to
be learned to generate outputs in different styles.
Style transfer is evaluated on scientiﬁc paper ti-
tles and newspaper tiles, and sentiment in reviews.
This method is different from ours in that we use
machine translation to create a strong latent state
from which multiple decoders can be trained for
each style. We also propose a different human
evaluation scheme.

Li et al. (2018) ﬁrst extract words or phrases
associated with the original style of the sentence,
delete them from the original sentence and then
replace them with new phrases associated with the
target style. They then use a neural model to ﬂu-
Junbo
ently combine these into a ﬁnal output.

et al. (2017) learn a representation which is style-
agnostic, using adversarial training of the auto-
encoder.

Our work is also closely-related to a problem of
paraphrase generation (Madnani and Dorr, 2010;
Dong et al., 2017),
including methods relying
on (phrase-based) back-translation (Ganitkevitch
et al., 2011; Ganitkevitch and Callison-Burch,
2014). More recently, Mallinson et al. (2017) and
Wieting et al. (2017) showed how neural back-
translation can be used to generate paraphrases.
An additional related line of research is machine
translation with non-parallel data. Lample et al.
(2018) and Artetxe et al. (2018) have proposed
sophisticated methods for unsupervised machine
translation. These methods could in principle be
used for style transfer as well.

7 Conclusion

We propose a novel approach to the task of style
transfer with non-parallel text.8 We learn a la-
tent content representation using machine transla-
tion techniques; this aids grounding the meaning
of the sentences, as well as weakening the style
attributes. We apply this technique to three dif-
ferent style transfer tasks. In transfer of political
slant and sentiment we outperform an off-the-shelf
state-of-the-art baseline using a cross-aligned au-
toencoder. The political slant task is a novel task
that we introduce. Our model also outperforms the
baseline in all the experiments of ﬂuency, and in
the experiments for meaning preservation in gen-
erated sentences of gender and political slant. Yet,
we acknowledge that the generated sentences do
not always adequately preserve meaning.

This technique is suitable not just for style
transfer, but for enforcing style, and removing
style too. In future work we intend to apply this
technique to debiasing sentences and anonymiza-
tion of author traits such as gender and age.

In the future work, we will also explore whether
an enhanced back-translation by pivoting through
several languages will learn better grounded latent
meaning representations. In particular, it would be
interesting to back-translate through multiple tar-
get languages with a single source language (John-
son et al., 2016).

8All

the

and

code

experi-
data
ments will be released to facilitate reproducibility at
https://github.com/shrimai/Style-Transfer-Through-Back-
Translation

used

the

in

Measuring the separation of style from content
is hard, even for humans. It depends on the task
and the context of the utterance within its dis-
course. Ultimately we must evaluate our style
transfer within some down-stream task where our
style transfer has its intended use but we achieve
the same task completion criteria.

Acknowledgments

This work was funded by a fellowship from Robert
Bosch, and in part by the National Science Foun-
dation through award IIS-1526745. We would like
to thank Sravana Reddy for sharing the Yelp cor-
pus used in gender transfer experiments, Zhiting
Hu for providing an implementation of a VAE-
based baseline, and the 11 CMU graduate students
who helped with annotation and manual evalu-
ations. We are also grateful to the anonymous
reviewers for their constructive feedback, and to
Dan Jurafsky, David Jurgens, Vinod Prabhakaran,
and Rob Voigt for valuable discussions at earlier
stages of this work.

References

Mikel Artetxe, Gorka Labaka, Eneko Agirre, and
Kyunghyun Cho. 2018. Unsupervised neural ma-
chine translation. In Proc ICLR.

Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-
gio. 2015. Neural machine translation by jointly
learning to align and translate. In Proc. ICLR.

Christina L Bennett. 2005. Large scale evaluation of
corpus-based synthesizers: Results and lessons from
In Ninth European
the blizzard challenge 2005.
Conference on Speech Communication and Technol-
ogy.

Su Lin Blodgett, Lisa Green, and Brendan O’Connor.
2016. Demographic dialectal variation in social me-
dia: A case study of African-American English. In
Proc. EMNLP.

Ondˇrej Bojar, Rajen Chatterjee, Christian Federmann,
Barry Haddow, Matthias Huck, Chris Hokamp,
Philipp Koehn, Varvara Logacheva, Christof Monz,
Matteo Negri, Matt Post, Carolina Scarton, Lucia
Specia, and Marco Turchi. 2015. Findings of the
2015 workshop on statistical machine translation. In
Proc. WMT, pages 1–46.

Jennifer Coates. 2015. Women, men and language: A
sociolinguistic account of gender differences in lan-
guage. Routledge.

Michael Denkowski and Alon Lavie. 2011. Meteor
1.3: Automatic metric for reliable optimization and

evaluation of machine translation systems. In Proc.
WMT, pages 85–91.

Li Dong, Jonathan Mallinson, Siva Reddy, and Mirella
Lapata. 2017. Learning to paraphrase for question
answering. In Proceedings of the 2017 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 875–886. Association for Computa-
tional Linguistics.

Penelope Eckert and Sally McConnell-Ginet. 2003.
Language and gender. Cambridge University Press.

Zhenxin Fu, Xiaoye Tan, Nanyun Peng, Dongyan
Zhao, and Rui Yan. 2018. Style Transfer in Text:
Exploration and Evaluation. In Proc. AAAI.

Juri Ganitkevitch and Chris Callison-Burch. 2014. The
In Proc. LREC,

multilingual paraphrase database.
pages 4276–4283.

Juri Ganitkevitch, Chris Callison-Burch, Courtney
Napoles, and Benjamin Van Durme. 2011. Learning
sentential paraphrases from bilingual parallel cor-
In Proc. EMNLP,
pora for text-to-text generation.
pages 1168–1179.

Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan
Salakhutdinov, and Eric P Xing. 2017. Toward con-
In Proc. ICML, pages
trolled generation of text.
1587–1596.

Eric Jardine. 2016. Tor, what is it good for? political
repression and the use of online anonymity-granting
technologies. New Media & Society.

Melvin Johnson, Mike Schuster, Quoc V Le, Maxim
Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat,
Fernanda Vi´egas, Martin Wattenberg, Greg Corrado,
et al. 2016. Google’s multilingual neural machine
translation system: enabling zero-shot translation.
arXiv preprint arXiv:1611.04558.

Anna Jørgensen, Dirk Hovy, and Anders Søgaard.
2015. Challenges of studying and processing di-
alects in social media. In Proc. of the Workshop on
Noisy User-generated Text, pages 9–18.

Junbo, Zhao, Y. Kim, K. Zhang, A. M. Rush, and
Y. LeCun. 2017. Adversarially Regularized Autoen-
coders for Generating Discrete Structures. ArXiv e-
prints.

Andrej Karpathy and Li Fei-Fei. 2015. Deep visual-
semantic alignments for generating image descrip-
tions. In Proc. CVPR, pages 3128–3137.

Chlo´e Kiddon, Luke Zettlemoyer, and Yejin Choi.
2016. Globally coherent text generation with neural
checklist models. In Proc. EMNLP, pages 329–339.

Diederik P Kingma and Max Welling. 2014. Auto-

encoding variational bayes. In Proc. ICLR.

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, et al. 2007. Moses: Open source
In Proc.
toolkit for statistical machine translation.
ACL (demonstration sessions), pages 177–180.

Robin Tolmach Lakoff and Mary Bucholtz. 2004. Lan-
guage and woman’s place: Text and commentaries,
volume 3. Oxford University Press, USA.

Guillaume Lample, Alexis Conneau, Ludovic Denoyer,
and Marc’Aurelio Ranzato. 2018. Unsupervised
machine translation using monolingual corpora only.
In Proc. ICLR.

J. Li, R. Jia, H. He, and P. Liang. 2018. Delete, Re-
trieve, Generate: A Simple Approach to Sentiment
and Style Transfer. ArXiv e-prints.

Jiwei Li, Michel Galley, Chris Brockett, Georgios P
Spithourakis, Jianfeng Gao, and Bill Dolan. 2016. A
persona-based neural conversation model. In Proc.
ACL.

Minh-Thang Luong, Hieu Pham, and Christopher D.
Manning. 2015. Effective approaches to attention-
based neural machine translation. In Proc. EMNLP.

Nitin Madnani and Bonnie J Dorr. 2010. Generat-
ing phrasal and sentential paraphrases: A survey
of data-driven methods. Computational Linguistics,
36(3):341–387.

Jonathan Mallinson, Rico Sennrich, and Mirella Lap-
ata. 2017. Paraphrasing revisited with neural ma-
chine translation. In Proce. EACL, volume 1, pages
881–893.

Burt L. Monroe, Michael P. Colaresi, and Kevin M.
Quinn. 2008. Fightin words: Lexical feature selec-
tion and evaluation for identifying the content of po-
litical conﬂict. Political Analysis.

Dong Nguyen, A. Seza Do˘gru¨oz, Carolyn P. Ros´e,
and Franciska de Jong. 2016. Computational soci-
olinguistics: A survey. Computational Linguistics,
42(3):537–593.

Xing Niu, Marianna Martindale, and Marine Carpuat.
2017. A study of style in machine translation: Con-
trolling the formality of machine translation output.
In Proc. EMNLP, pages 2804–2809.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
In Proc. ACL,
evaluation of machine translation.
pages 311–318.

Ella Rabinovich, Shachar Mirkin, Raj Nath Patel, Lu-
cia Specia, and Shuly Wintner. 2016. Personal-
ized machine translation: Preserving original author
traits. In Proc. EACL.

Sravana Reddy and Kevin Knight. 2016. Obfuscating
In Proc. of Work-
gender in social media writing.
shop on Natural Language Processing and Compu-
tational Social Science, pages 17–26.

Alan Ritter, Colin Cherry, and William B Dolan. 2011.
Data-driven response generation in social media. In
Proc. EMNLP, pages 583–593.

Rachel Rudinger, Chandler May,

and Benjamin
Van Durme. 2017. Social bias in elicited natural lan-
guage inferences. In Proc. of the First Workshop on
Ethics in Natural Language Processing, page 74.

Abigail See, Peter J Liu, and Christopher D Manning.
2017. Get to the point: Summarization with pointer-
generator networks. In Proc. ACL.

Rico Sennrich, Barry Haddow, and Alexandra Birch.
2016. Controlling politeness in neural machine
In Proc. NAACL,
translation via side constraints.
pages 35–40.

Tianxiao Shen, Tao Lei, Regina Barzilay, and Tommi
Jaakkola. 2017. Style transfer from non-parallel text
by cross-alignment. In Proc. NIPS.

Alessandro Sordoni, Michel Galley, Michael Auli,
Chris Brockett, Yangfeng Ji, Margaret Mitchell,
Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. 2015.
A neural network approach to context-sensitive
In Proc.
generation of conversational responses.
NAACL.

Steven J. Spencer, Claude M. Steele, and Diane M.
Quinn. 1999. Stereotype Threat and Women’s Math
Performance. Journal of Experimental Social Psy-
chology, 35:4–28.

Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.
Sequence to sequence learning with neural net-
works. In Proc. NIPS, pages 3104–3112.

Oriol Vinyals and Quoc Le. 2015. A neural conversa-
tional model. In Proc. ICML Deep Learning Work-
shop.

Rob Voigt, David Jurgens, Vinodkumar Prabhakaran,
Dan Jurafsky, and Yulia Tsvetkov. 2018. RtGender:
A corpus for studying differential responses to gen-
der. In Proc. LREC.

Tsung-Hsien Wen, David Vandyke, Nikola Mrksic,
Milica Gasic, Lina M Rojas-Barahona, Pei-Hao Su,
Stefan Ultes, and Steve Young. 2017. A network-
based end-to-end trainable task-oriented dialogue
system. In Proc. EACL.

John Wieting, Jonathan Mallinson, and Kevin Gimpel.
2017. Learning paraphrastic sentence embeddings
from back-translated bitext. In Proc. EMNLP, pages
274–285.

Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho,
Aaron Courville, Ruslan Salakhudinov, Rich Zemel,
and Yoshua Bengio. 2015. Show, attend and tell:
Neural image caption generation with visual atten-
tion. In Proc. ICML, pages 2048–2057.

A Supplementary Material

In Tables 7, 8, and 9 we present the style transfer
accuracy results broken-down to style categories.
We denote the Cross-aligned Auto-Encoder model
as CAE and our model as Back-translation for
Style Transfer (BST).

Model
Style transfer
CAE male → female
BST male → female
female → male
CAE
female → male
BST

Acc
64.75
54.59
56.05
59.49

Table 7: Gender transfer accuracy.

Model
CAE
BST
CAE
BST

Style transfer
republican → democratic
republican → democratic
democratic → republican
democratic → republican

Acc
65.44
80.55
86.20
95.47

Table 8: Political slant transfer accuracy.

Model
CAE
BST
CAE
BST

Style transfer
negative → positive
negative → positive
positive → negative
positive → negative

Acc
81.63
95.68
79.65
81.65

Table 9: Sentiment modiﬁcation accuracy.

In Table 10, we detail the accuracy of the gender
classiﬁer on generated style-transfered sentences
by an auto-encoder; Table 11 shows the accuracy
of transfer of political slant. The experiments are
setup as described in Section 5.1. We denote the
Auto-Encoder as (AE) and our model as Back-
translation for Style Transfer (BST).

Style transfer
Model
male → female
AE
BST male → female
female → male
AE
female → male
BST

Acc
41.48
54.59
41.88
59.49

Table 10: Gender transfer accuracy for Auto-
encoder.

To evaluate the preservation of meaning by the
Auto-Encoder, the experiments were setup as de-
scribed in Section 5.2. We conducted four tests,

Model
AE
BST
AE
BST

Style transfer
republican → democratic
republican → democratic
democratic → republican
democratic → republican

Acc
60.76
80.55
64.05
95.47

Table 11: Political slant transfer accuracy for
Auto-encoder.

each of 20 random samples for each type of style
transfer. Note that we did not ask about appropri-
ateness of the style transfer in this test, or ﬂuency
of outputs, only about meaning preservation. We
show the results of human evaluation in Table 12

Style transfer
male → female
female → male
republican → democratic
democratic → republican

=
43.3
45.0
43.3
55.00

AE BST
43.3
13.4
45.0
10.0
53.3
3.4
33.3
11.7

Table 12: Human preference for meaning preser-
vation in percentages.

Examples of the original and style-transfered
sentences generated by the baseline and our model
are shown in Table 13

Input Sentence

BST

CAE
male → female
i got ta get the chicken breast .

we could n’t go back and i would
be able to get me to get me.

the place is small but cosy and

the staff and the place is very

very clean.

nice.

save

yourself

the

huge

female → male
the sauces are excellent.

would i discourage someone else

i believe i would be back?

my husband ordered the chicken

salad and the fries.

great place to go back and try a

lot of which you ’ ve never had
to try or could not have been
able to get some of the best.
the place is great but very clean

and very friendly.

going

you

are
disappointed.
i wouldn’t go back!

to

be

tom,

i wish u would bring

i agree,

senator warren and

brian, i am proud to have you

the sauces - lrb - - rrb - - rrb -

and - rrb -.

my wife ordered the mac-n-
cheese and the salad - lrb - $
00 minutes - rrb - was cooked.

republican → democratic
i am proud of you and your vote

for us!

could be.

and then we will be praying for
them and i am proud of this
position and i am proud of
democratic → republican
a lot , i am proud of you <unk>.

and in bigotry–racism,
programming, cut,
granddaughters,
unprescedented and excludes.
thank you for standing up for us

i will continue to ﬁght for you

and the rest of our
democracy!

representing me.

keep up and dont know, you

have a lot of respect as
breitbart

as a hoosier, i’m praying for

you sir.

thanks for standing up for the
constitution and get rid of
obamacare, homophobie
, cut, and actuality.

and i am proud of us!

for us, senator scott!

thanks lawmaker for all you do

thank you for standing up for

do you for standing up for highly

my wife ordered country fried

steak and eggs.

great place to visit and maybe
ﬁnd that one rare item you
just have never seen or can
not ﬁnd anywhere else.

headaches.

from going?

my husband ordered the salad
and the dressing - lrb - blue
cheese - rrb - was watered
down.

i will continue praying for you
and the decisions made by
our government!

change.

all talk and no action-why dont
you have some guts like
breitbart

as a hoosier, i thank you, rep.

visclosky.

justice and against bigotry-
-racism, homophobia, sexism
, misogyny, religious and
xenophobia.

thank you for all you are do-
for us, attorney general
ing

harris!

crap fries, hard hamburger buns,
burger tasted like crap!
the people behind the counter
were not friendly whatsoever.

like like!

friendly.

negative → positive
good selection, fresh food, like

empathy,

best
but it was very nice!

the

food,

the people who the staff were

the people here are really good.

this place is bad news!

this place is great!

this place is amazing!

the food is excellent and the

positive → negative
the food is the food and the

service is exceptional!

service is terrible.

great as always,

i

love there

i really don’t eat

food.

i would recommend a visit here.

horrible as,
here.

i would not recommend a dinner
here.

the food is horrible and the

service is terrible.
really disappointed,
be
i will not recommend this place.

i couldn’t

back.

Table 13: Gender, Political slant and Sentiment style transfer examples. In addition to better preserving
meaning, sentences generated by the BST model are generally grammatically better structured.

