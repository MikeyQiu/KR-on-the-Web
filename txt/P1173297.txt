8
1
0
2
 
t
c
O
 
3
 
 
]

V
C
.
s
c
[
 
 
3
v
7
9
4
0
0
.
4
0
8
1
:
v
i
X
r
a

MicronNet: A Highly Compact Deep Convolutional
Neural Network Architecture for Real-time
Embedded Trafﬁc Sign Classiﬁcation

Alexander Wong1, Mohammad Javad Shaﬁee1, and Michael St. Jules1,2
1Waterloo Artiﬁcial Intelligence Institute, University of Waterloo, Waterloo, ON, Canada
2DarwinAI Corp., Waterloo, ON, Canada
a28wong@uwaterloo.ca

Abstract

Trafﬁc sign recognition is a very important computer vision task for a number of
real-world applications such as intelligent transportation surveillance and analysis.
While deep neural networks have been demonstrated in recent years to provide
state-of-the-art performance trafﬁc sign recognition, a key challenge for enabling
the widespread deployment of deep neural networks for embedded trafﬁc sign
recognition is the high computational and memory requirements of such networks.
As a consequence, there are signiﬁcant beneﬁts in investigating compact deep
neural network architectures for trafﬁc sign recognition that are better suited for
embedded devices. In this paper, we introduce MicronNet, a highly compact
deep convolutional neural network for real-time embedded trafﬁc sign recognition
designed based on macroarchitecture design principles (e.g., spectral macroarchi-
tecture augmentation, parameter precision optimization, etc.) as well as numerical
microarchitecture optimization strategies. The resulting overall architecture of
MicronNet is thus designed with as few parameters and computations as possible
while maintaining recognition performance, leading to optimized information den-
sity of the proposed network. The resulting MicronNet possesses a model size of
just ∼1MB and ∼510,000 parameters (∼27x fewer parameters than state-of-the-
art) while still achieving a human performance level top-1 accuracy of 98.9% on
the German trafﬁc sign recognition benchmark. Furthermore, MicronNet requires
just ∼10 million multiply-accumulate operations to perform inference, and has
a time-to-compute of just 32.19 ms on a Cortex-A53 high efﬁciency processor.
These experimental results show that highly compact, optimized deep neural net-
work architectures can be designed for real-time trafﬁc sign recognition that are
well-suited for embedded scenarios.

1

Introduction

Trafﬁc sign recognition can be considered an important computer vision task for a number of real-
world applications such as intelligent transportation surveillance and analysis (see Figure 1). The
arrival of modern breakthroughs in deep learning [15, 13] has resulted in signiﬁcant state-of-the-art
results for trafﬁc sign recognition, with much of the research focused on designing deep convolutional
neural networks for improved accuracy [18, 5, 6, 25, 12, 1, 3, 2].

Despite the fact that such trafﬁc sign recognition networks have shown state-of-the-art object detection
accuracies beyond what can be achieved by previous state-of-the-art methods, a key challenge for
enabling the widespread deployment of deep neural networks for embedded trafﬁc sign recognition is
the high computational and memory requirements of such networks. For example, the committee

Preprint. Work in progress.

Figure 1: The goal of the trafﬁc signal recognition problem is to identify which type of trafﬁc sign
is in the scene. For context, some example images of trafﬁc signs from the German trafﬁc sign
recognition benchmark [20] are shown.

of deep convolutional neural networks proposed by Ciresan et al. [6] consists of ∼38.5 million
parameters while the ensemble of deep convolutional neural networks trained via hinge loss as
proposed by Jin et al. [12] consists of ∼23.2 million parameters. More recently, the state-of-
the-art deep convolutional network with spatial transformers proposed by Arcos-Garcia et al. [3],
while having fewer parameters than the aforementioned approaches, still consisted of over ∼14
million parameters. At a signiﬁcantly smaller sizes than the aforementioned conﬁgurations, the
macroarchitectures proposed by Ciresan et al. [6] still consist of ∼1.5 million parameters. As such,
the design of more compact and efﬁcient deep neural network architectures for trafﬁc sign recognition
is highly desired for embedded applications.

Recently, there has been an increasing focus in exploring small deep neural network architectures that
are more suitable for embedded devices [10, 11, 17, 8, 1, 23, 19, 24, 16]. For example, in the work by
Iandola et al. [11], three key design strategies were leveraged to create compact macroarchitectures:
1) ﬁlter quantity reduction, 2) input channel reduction, and 3) late downsampling in the network.
As a result of such design strategies, a compact SqueezeNet macroarchitecture was introduced
that comprised of Fire modules that was ∼50X smaller than AlexNet with comparable accuracy on
ImageNet [7] for 1000 classes. In the work by Howard et al. [10], they leveraged depth-wise separable
convolutions to reduce the number of parameters, as well as two global hyperparameters based on
network width and resolution for ﬁnding the tradeoff between latency and accuracy. Sandler et al. [17]
expanded upon this by introducing an inverted residual structure that enabled further reductions in the
number of parameters while maintaining high performance. Aghdam et al. [1] presented techniques
for optimizing the efﬁciency of deep neural network architectures for the speciﬁc purpose of trafﬁc
sign recognition. Based on the practical principles they discussed for building small deep neural
network architectures for trafﬁc sign recognition, the authors were able to create a high-performance
deep neural network consisting of just ∼1.74 million parameters, while still achieving great accuracy.

In this study, we introduce MicronNet, a highly compact deep convolutional neural network designed
speciﬁcally for real-time embedded trafﬁc sign recognition. In MicronNet’s highly optimized network
architecture, the underlying microarchitecture of each convolutional layer in the network (with mi-
croarchitecture here referring to the number and size of convolutional ﬁlters) is numerically optimized
to have as few parameters and computations as possible while maintaining recognition performance,
hence resulting in an optimized information density for the underlying network. Furthermore, the
macroarchitecture of the proposed MicronNet network is designed via macroarchitecture design
strategies (e.g., spectral macroarchitecture augmentation, parameter precision optimization, etc.)

2

Figure 2: Integrated microarchitecture-level and macroarchitecture-level design principles and opti-
mization strategies leveraged for designing MicronNet for high efﬁciency while maintaining strong
accuracy.

that encourage improved computational efﬁciency and efﬁcacy in embedded environments. As
such, the main contribution of this work is the investigation and exploration of integrating design
principles and optimization strategies at both the microarchitecture level and the macroarchitecture
level to design deep neural networks with optimized information densities that satisfy real-time
embedded requirements while achieving strong accuracy, thus enabling real-time embedded trafﬁc
sign recognition.

This paper is organized as follows. Section 2 describes the highly optimized network architecture and
design considerations underlying the proposed MicronNet network. Section 3 presents experimental
results that evaluate the efﬁcacy of the proposed MicronNet network for real-time embedded trafﬁc
sign recognition, along with a discussion on some key observations about the network. Finally,
conclusions are drawn in Section 4.

2 Network architecture of MicronNet

Leveraging macroarchitecture design principles such as those from [10, 11, 17, 1] and a numerical
microarchitecture optimization strategy inspired by [23], the overall network architecture of the
proposed MicronNet network for real-time embedded trafﬁc sign recognition is inspired by the
network macroarchitecture described in [1] and takes the following microarchitecture-level and
macroarchitecture-level design considerations and optimization strategies into account to greatly
improve the efﬁciency of the resulting deep convolutional neural network while maintaining strong
accuracy (see Figure 2):

• Optimizing microarchitectures of each convolutional layer via numerical optimization for

reduced number of parameters

3

Table 1: The optimized network architecture underlying MicronNet

Type / Stride / Pad
Conv / s1 / p0
Conv / s1 / p0
Pool / s2 / p0
Conv / s1 / p0
Pool / s2 / p0
Conv / s1 / p0
Pool / s2 / p0
FC / s1
FC / s1
Softmax / s1

Filter Shape
1 × 1 × 1
5 × 5 × 29
3 × 3
3 × 3 × 59
3 × 3
3 × 3 × 74
3 × 3
1 × 300
1 × 300
Classiﬁer

Input Size
48 × 48
48 × 48
maxpool
22 × 22
maxpool
10 × 10
maxpool
1 × 1184
1 × 300
1 × 43

• Incorporating spectral augmentations to produce a spectral-spatial macroarchitecture that
further reduces number of parameters and computational complexity while maintaining
strong accuracy

• Optimizing parameter precision for reduced model size while maintaining strong accuracy

Table 1 shows the overall architecture of the proposed MicronNet network architecture. The pro-
posed MicronNet network architecture is a 16-bit ﬂoating-point deep convolutional neural network
composed of four convolutional layers, followed by two fully-connected layers and a softmax layer.
A combination of 1×1 point-wise convolutional layer with 5×5 and 3×3 spatial convolutional
layers form a spectral-spatial macroarchitecture for reducing complexity while maintaining accuracy.
Furthermore, rectiﬁed linear unit (ReLU) activation functions are leveraged within the proposed
MicronNet network architecture for low computational complexity and better suitability for real-time
embedded applications. Each of the design considerations in the design of MicronNet is discussed in
detail below.

2.1 Numerical microarchitecture optimization

The ﬁrst design consideration in obtaining an ideal network architecture for real-time embedded
trafﬁc sign recognition in this study is to optimize the network microarchitecture of the proposed
MicronNet network. One of the key challenges to identifying the ideal microarchitecture for each of
the individual convolutional layers in the deep neural network is to achieve a ﬁne balance between
modeling performance and model size as well as computations involved. While a number of existing
techniques have focused on uniform microarchitecture design [10, 17], the strategy employed here
is instead focused on numerical microarchitecture optimizations that operates at a more ﬁne-grain
level than other techniques, as it was found by the authors to yield a better balance between modeling
performance and model size as well as reduced computations.

Taking that mentality into account here, the key design parameters of the microarchitectures of each
convolutional layer are the number of convolutional ﬁlters that form the microarchitecture, and their
associated sizes. Therefore, here we optimize the number of convolutional ﬁlters and their associated
sizes in each convolutional layer via numerical optimization. More speciﬁcally, the key objective
leveraged here is to minimize the number of parameters that compose each convolutional layer in the
network architecture while maintaining the overall accuracy of the network.

One quantiﬁable assessment of the relative amount of accuracy a given deep neural network captures
with respect to a fundamental building block (in this case, a parameter) that ties well with this key
objective is the information density [4] of a deep neural network. By taking into account both model
size and network performance by means of a single metric, information density provides a good
representation of the network’s ability to utilize its full modeling capacity. Therefore, a deep neural
network with a good balance of being smaller with fewer parameters yet still maintaining strong
performance would be characterized by a higher information density, and hence higher information
density indicates better network efﬁciency and is thus our desired outcome.

4

Figure 3: Spectral macroarchitecture augmentation: a 1×1 point-wise convolutional layer (a) sits
before a 5 × 5 convolutional layer (b) to form a spectral-spatial macroarchitecture where spectral
features are ﬁrst extracted through computing linear combinations of the input spectral channels in
the point-wise convolutional layer, before spatial features are extracted in subsequent convolutional
layers (c).

In this study, the numerical microarchitecture optimization strategy is framed as a constrained opti-
mization problem, where the set of optimization parameters F is set as the number of convolutional
ﬁlters and their associated sizes in each convolutional layer for a given network N , and the goal is to
numerically determine the optimal F that minimizes the total number of network parameters (denoted
here as p(N ; F )) for a given F , with the validation accuracy av(N ) constrained to being greater than
or equal to an accuracy lower-bound of l (set to 98.5% in this study based on the performance of [6]):

F = min

p(N ; F ) subject to av(N ) ≥ l.

F

(1)

An approximate solution to the above constrained optimization problem posed in Eq. 1 can be
obtained using an iterative optimization approach. The key advantage with leveraging such a
numerical microarchitecture optimization strategy is that each layer has its own unique information
density limits and thus the degree of microarchitecture optimization that can be achieved for each
layer can differ substantially. Therefore, a numerical microarchitecture optimization strategy allows
signiﬁcantly greater ﬂexibility in obtaining the ideal microarchitectures for each convolutional
layer with the optimal information densities without being constrained by the need for uniform
ﬁne-tuning. As a result, the proposed MicronNet network architecture possesses highly optimized
microarchitectures that is optimized for real-time embedded scenarios.

2.2 Spectral macroarchitecture augmentation

The second design consideration in obtaining an ideal network architecture for real-time embedded
trafﬁc sign recognition is to incorporate additional layers to the macroarchitecture of the MicronNet
network that enable further reductions in computational complexity to be made while maintaining
strong accuracy. Taking inspiration from [10, 11, 17] where 1×1 convolutional layers are leveraged to
reduce the number of parameters in the network while preserving modeling performance, we augment
the proposed MicronNet network an additional 1×1 convolutional layer placed at a strategic location
where it would have the most impact on reducing computational complexity while having a positive
impact on modeling performance. More speciﬁcally, we take inspiration from work on spectral-
spatial macroarchitectures such as that proposed in [26], which are designed to learn spectral features
prior to learning spatial features in an end-to-end macroarchitecture, and incorporated an additional
1×1 convolutional layer at the beginning of proposed MicronNet network architecture. This 1×1
convolutional layer sits before a 5 × 5 convolutional layer and acts as a pointwise feature transform
layer where new features are built through computing linear combinations of the input spectral
channels. Therefore, from a theoretical perspective, one can view this 1×1 convolutional layer as a
spectral feature learning layer that learns the optimal spectral mixing projection between the input
color channels in an image to produce a single-channel spectral feature map that feeds into subsequent
convolutional layers (see Figure 3), resulting in a spectral-spatial network macroarchitecture. The key
advantage of this additional 1×1 convolutional layer compared to the strategy used by deep neural
networks such as that proposed by [1], which converts color input images into grayscale images using
a pre-deﬁned conversion scheme, is that it provides a much greater level of ﬂexibility in learning a
more discriminative spectral projection into a single feature channel than that can be achieved with a
ﬁxed grayscale conversion scheme.

5

Based on empirical experiments, the augmentation of this additional pointwise convolutional layer to
form a spectral-spatial network architecture enables us to greatly reduce the number of ﬁlters needed
in the 5×5 convolutional layer to obtain strong modeling accuracy. In addition to reducing the number
of parameters in the proposed MicronNet network, the reduction in the number of convolutional ﬁlters
in the 5×5 convolutional layer is very important as the convolutional ﬁlters are used to convolve
inputs at the original image resolution, and as such reducing the number of convolutional ﬁlters result
in a signiﬁcant reduction in the number of computations that need to be performed. It is important to
note that this augmentation is performed on the proposed network architecture prior to the numerical
microarchitecture optimization process.

2.3 Parameter Precision Optimization and Activation Function Selection

The third design consideration in obtaining an ideal network architecture for real-time embedded
trafﬁc sign recognition is to optimize the precision of the parameters used in the proposed MicronNet
network. For embedded applications, the computational requirements and memory requirements
are typically quite strict and as such an effective strategy to address these requirements is to reduce
the data precision of parameters in a deep neural network. In particular, embedded processors often
support accelerated mixed precision operations, and as a result leveraging such parameter precision
considerations into the design of the deep neural network can result in noticeable improvements in
computational time as well as memory storage for embedded scenarios. For the MicronNet network
architecture, all parameters are characterized with half precision ﬂoating-point data representations
after training to enable further model size reductions while still achieving strong performance.
Alongside the use of ﬁxed-point parameter precision for embedded applications, the utilization of half-
precision ﬂoating-point parameter precision for deep neural networks has seen widespread adoption
for embedded applications and hardware-accelerated in a wide range of embedded processors,
including the Nvidia Tegra family of embedded processors as well as widely-used ARM embedded
processors such as the Cortex-A53 high efﬁciency processor tested in this study. In additional, we
also produced a variant of the proposed MicronNet network architecture with 16-bit ﬁxed-point data
representation for comparison purposes.

Finally, to reduce the computational complexity of the proposed MicronNet network architecture, the
rectiﬁed linear unit (ReLU) function is used as the activation function in the deep neural network
since it is more suitable for real-time embedded applications when compared to other activation
functions such as the scaled hyperbolic tangent function [14] and the parametric rectiﬁer linear unit
(PReLU) function [9].

2.4 Training

Here, we will discuss the training policy for learning the proposed MicronNet network. The proposed
MicronNet network was trained for 60,000 iterations in the Caffe framework with a training batch
size of 50. Stochastic gradient descent with momentum and exponential decay was utilized as the
training policy with the base learning rate set to 0.007, the momentum set to 0.9, the learning rate
decay step size set to 1000, and the learning rate decay rate set to 0.9996. A l2 weight decay with
rate 0.00001 was also used on the ﬁlters and matrices.

3 Experimental Results and Discussion

To study the efﬁcacy of the proposed MicronNet for real-time embedded trafﬁc sign recognition, we
evaluate the following:

• Top-1 accuracy on the German trafﬁc sign recognition benchmark (GTSRB) [20]
• Resource usage (model size, number of parameters, number of multiply-accumulate (MAC)

operations, time-to-compute on a 1.2GHz Cortex-A53 high efﬁciency processor)

• Information density [4] and NetScore [22]
• Robustness against image degradation

For evaluation purposes, the following state-of-the-art trafﬁc sign recognition networks were also
compared:

6

• STDNN [3], deep convolutional neural network with spatial transformers,

• HLSGD [12]: hinge loss trained deep convolutional neural network,

• MCDNN [6]: multi-column deep convolutional neural network,

• CDNN [6]: Ciresan deep convolutional neural network.

3.1 Dataset

The German trafﬁc sign recognition benchmark (GTSRB) [20] used for evaluation purposes in this
paper consists of color images of trafﬁc signs (one trafﬁc sign per image, with a total of 43 types of
trafﬁc signs) with image sizes varying from 15×15 to 250×250 pixels. There are a total of 39,209
color images in the training set and a total of 12,630 images in the test set. To balance the number
of samples in different classes as well as improve the generality of the resulting network, a number
of different data augmentation techniques were leveraged including: i) rotation, ii) shifting, iii)
sharpening, iv) Gaussian blur, v) motion blur, vi) HSV augmentation, and vii) mirroring. As standard
for evaluating performance using GTSRB, all images are cropped and all images are resized to 48×48
pixels [6]. To evaluate the accuracy of the network, the top-1 accuracy was computed on the GTSRB
test set.

Table 2: Top-1 accuracy results and number of parameters of MicronNet on German trafﬁc sign
recognition benchmark (GTSRB) [20]. The results of several state-of-the-art trafﬁc sign recognition
are provided, along with the average human performance, for comparison purposes.

Model
Name
Human [21]
STDNN [3]
HLSGD [12]
MCDNN [6]
CDNN† [6]
MicronNet (fp16)
MicronNet (ﬁxed16)

Number of
parameters
-
14M
23.2M
38.5M
1.54M
0.51M
0.51M

Top-1 accuracy
(GTSRB)
98.8%
99.7%
99.6%
99.5%
98.5%
98.9%
98.0%

†average reported top-1 accuracy

3.2

Information density and NetScore

The model efﬁciency of the proposed MicronNet network and the state-of-the-art trafﬁc sign recog-
nition networks also being compared were assessed by means of its information density [4] and
NetScore [22] as well to obtain a better understanding of the amount of relative performance a given
deep neural network captured with respect to a fundamental building block. More speciﬁcally, the
information density (D) of a deep neural network N is deﬁned as the performance of the deep neural
network (denoted by a(N )) divided by the number of parameters needed for representing it (denoted
by p(N )),

D(N ) =

a(N )
p(N )

(2)

By taking into account both model size and network performance by means of a single metric,
information density (expressed as percent of top-1 accuracy per parameter in this study) provides
a good representation of the network’s ability to utilize its full modeling capacity, with higher
information density indicating better network efﬁciency.

One aspect that information capacity does not account for is the computational cost for performing
inference with a given deep neural network, which is important for real-time embedded applications.
Therefore, the NetScore [22] metric was also leveraged in this study for assessing the performance

7

of a deep neural network N for practical usage. The NetScore metric (denoted here as Ω) can be
deﬁned as:
(cid:32)

(cid:33)

Ω(N ) = 20 log

a(N )α
p(N )βm(N )γ

(3)

where a(N ) is the accuracy of the network, p(N ) is the number of parameters in the network,
m(N ) is the number of multiply–accumulate (MAC) operations performed during network inference,
and α, β, γ are coefﬁcients that control the inﬂuence of accuracy, architectural complexity, and
computational complexity of the network on Ω. We set α = 2, β = 0.5, and γ = 0.5 as proposed
in [22].

Table 3: Information density of MicronNet on German trafﬁc sign recognition benchmark (GT-
SRB) [20]. The results of several state-of-the-art trafﬁc sign recognition networks are provided for
comparison purposes. Higher is better.

Model
Name
STDNN [3]
HLSGD [12]
MCDNN [6]
CDNN [6]
MicronNet (fp16)
MicronNet (ﬁxed16)

Information capacity
(% per MParams)
7.1
4.3
2.6
64
194
192

3.3 Discussion

Top-1 accuracy. Table 2 shows the number of parameters and the top-1 accuracy of the proposed
MicronNet network (both in half-precision ﬂoating-point data representation and 16-bit ﬁxed-point
data representation) on the GTSRB test dataset, along with the number of parameters and top-1
accuracies for state-of-the-art trafﬁc sign recognition networks. A number of interesting observations
can be made. First, the resulting MicronNet possesses just ∼510,000 parameters, which is ∼27.5x
fewer than the state-of-the-art STDNN network [3]. Even when compared to the smallest state-of-
the-art trafﬁc sign recognition network compared in this paper (i.e., the CDNN network [6], which
MicronNet outperforms), the proposed MicronNet network still has ∼3x fewer parameters. The
signiﬁcantly smaller number of parameters in the proposed MicronNet network compared to all
of the evaluated state-of-the-art trafﬁc sign recognition networks illustrates its efﬁcacy for greatly
reducing the computational and memory requirements, making the use of MicronNet very well
suited for real-time embedded trafﬁc sign recognition purposes. Second, it can be observed that the
resulting MicronNet was still able to achieve a top-1 accuracy of 98.9% on the GTSRB test dataset,
which is just ∼0.8% lower than that achieved using the state-of-the-art STDNN network, and ∼0.4%
higher than that achieved by the smallest tested network outside of the proposed MicronNet (i.e.,
CDNN [6]). Third, it can be observed that the top-1 accuracy of the proposed MicronNet network was
equivalent to the average human performance reported in [21]. The top-1 accuracy results exhibited
by MicronNet illustrates the efﬁcacy of this proposed network for providing strong embedded trafﬁc
sign recognition capabilities despite its signiﬁcantly smaller size compared to other state-of-the-art
networks. In addition, it can be observed that the variant of the proposed MicronNet with 16-bit
ﬁxed-point data representation, while achieving lower top-1 accuracy than the proposed MicronNet
with half-precision data representation, still managed to achieve a top-1 accuracy of 98.0% on the
GTSRB test dataset.

To study where the proposed MicronNet encounters difﬁculties, we examine some of the trafﬁc images
from the GTSRB test dataset that has been misclassiﬁed by the proposed MicronNet (see Fig. 4). It
can be observed that in the example misclassiﬁed trafﬁc images, the sign is either heavily motion
blurred (left), partially occluded (middle), or exhibit poor illumination (right). The identiﬁcation of
such misclassiﬁcations can provide good insight into the weaknesses of a network, as one potential
mechanism for improving the robustness to such scenarios may be to extend the data augmentation

8

Figure 4: Examples of trafﬁc images from the GTSRB test dataset that has been misclassiﬁed by the
proposed MicronNet. It can be seen that in the example misclassiﬁed trafﬁc images, the sign is either
heavily motion blurred (left), partially occluded (middle), or exhibit poor illumination (right).

policy to include more synthetic examples at different forms of occlusions as well as different
illumination levels.

Information density and NetScore. Table 3 shows the information density of the proposed
MicronNet network on the GTSRB test dataset, along with the information density for state-of-the-art
trafﬁc sign recognition networks. It can be observed that the information density of the resulting
MicronNet is signiﬁcantly higher than all of the other tested trafﬁc sign recognition networks, by as
much as ∼75x higher in the case of MCDNN [6]. The high information density of the proposed
MicronNet network, for both half-precision ﬂoating-point and 16-bit ﬁxed-point data representations,
when compared to the other evaluated state-of-the-art trafﬁc sign recognition networks further
illustrate the network efﬁciency of the proposed network. Finally, the NetScore of the proposed
MicronNet network was computed to be 102.52, which is quite high and further reinforces the strong
balance between accuracy, architectural complexity, and computational cost of the proposed network.

Resource usage. Table 4 shows the resource usage of the proposed MicronNet network,
which is very important for evaluating its efﬁcacy for real-time embedded applications given that
both memory and computational resources are very limited in such cases. A number of interesting
observations can be made. First, it can be observed that the proposed MicronNet network is just
∼1.05MB in size, which can be contributed to the fact that not only is the number of parameters
being very low compared to existing state-of-the-art networks but also a result of the fact that the
parameters are represented with half-precision ﬂoat-point values. Second, it can be observed that the
proposed MicronNet network requires just ∼10.5 million multiply-accumulate (MAC) operations to
perform inference, which indicates that the proposed MicronNet network has low computational
requirements for performance network inference. To better evaluate the computational requirements
of the proposed MicronNet network in a real-world embedded scenario, the network was evaluated
on a 1.2GHz Cortex-A53 high efﬁciency processor in a Broadcom BCM2837B0 SoC. It was found
that the time-to-compute was just 32.19 ms on the tested high efﬁciency processor in half-precision
ﬂoating-point (fp16) mode with power consumption of ∼3W, making it very well-suited for real-time
embedded trafﬁc sign recognition. These experimental results clearly demonstrate that very small yet
accurate deep neural network architectures can be designed for real-time trafﬁc sign recognition that
are well-suited for embedded scenarios.

Robustness against image degradation. To study the robustness of the proposed Micron-
Net network against different levels of image degradation, all 12,630 images in the GTSRB test
dataset were contaminated by Gaussian noise at three different degradation levels (i.e., σ= 2.5%,
5%, and 7.5% of the dynamic range). Table 5 shows the top-1 accuracy of the proposed MicronNet
network across the different degradation levels. It can be observed that the proposed MicronNet
network is reasonably robustness to image degradation, still achieving a top-1 accuracy of 92.3% at
the highest tested degradation level (σ=7.5%).

9

Table 4: Resource usage of MicronNet. The time-to-compute was computed on a 1.2GHz Cortex-A53
high efﬁciency processor.
Model
Size
1.05MB

Total number
of Parameters
0.51M

Total number
of MACs
10.5M

Compute (fp16) Consumption (W)

32.19 ms

Time To

Power

3W

Table 5: Robustness of MicronNet against different levels of image degradation.

Degradation level
Top-1 accuracy

σ=0% σ=2.5% σ=5% σ=7.5%
98.9% 98.5% 96.5% 92.3%

4 Conclusions

In this paper, a highly compact deep convolutional neural network called MicronNet is introduced for
real-time embedded trafﬁc sign recognition. By designing a highly optimized network architecture
where each layer’s microarchitecture is optimized to have as few parameters as possible, along
with macroarchitecture augmentation and parameter precision optimization, the resulting MicronNet
network achieves a good balance between accuracy and model size as well as inference speed. The
resulting MicronNet possess a model size of just ∼1MB and ∼510,000 parameters (∼27x fewer
parameters than state-of-the-art), requires just ∼10 million multiply-accumulate operations to perform
inference (with a time-to-compute of 32.19 ms on a Cortex-A53 high efﬁciency processor), while
still achieving a top-1 accuracy of 98.9% on the German trafﬁc sign recognition benchmark, thus
achieving human-level performance. These experimental results show that very small yet accurate
deep neural network architectures can be designed for real-time trafﬁc sign recognition that are
well-suited for embedded scenarios.

Future work involves exploring extensions upon MicronNet across a larger range of trafﬁc datasets
to improve generalizability in different scenarios. Furthermore, it is also worth exploring and inves-
tigating this integrated microarchitecture-level and macroarchitecture-level design principles and
optimization strategies on deep neural network architectures for different tasks outside of trafﬁc sign
recognition, and the fundamental tradeoffs between microarchitecture-level and macroarchitecture-
level design principles and optimization strategies on such deep neural network architectures and
mechanisms to optimize for such tradeoffs to improve generalizability of such an approach. Fur-
thermore, model stability studies that also involve assessing the performance of this approach in the
case of less training data given smaller model sizes would be quite interesting to explore as future
work. Finally, model performance studies with a wider variety of embedded processors at different
ﬂoating-point and ﬁxed-point precision levels would be interesting to explore as future work.

The authors thank the Natural Sciences and Engineering Research Council of Canada, Canada
Research Chairs Program, and DarwinAI, as well as Nvidia for hardware support.

Acknowledgment

References

[1] H. Aghdam, E. Heravi, and D. Puig. A practical approach for detection and classiﬁcation of trafﬁc signs

using convolutional neural networks. Robotics and Autonomous Systems, 2016.

[2] H. Aghdam, E. Heravi, and D. Puig. A practical and highly optimized convolutional neural network for

classifying trafﬁc signs in real-time. International Journal of Computer Vision, 2017.

[3] A. Arcos-Garcia, J. Alvarez-Garcia, and Luis M.Soria-Morillo. Deep neural network for trafﬁc sign
recognition systems: An analysis of spatial transformers and stochastic optimisation methods. In Neural
Networks, pages 158–165, 2018.

10

[4] A. Canziani, A. Paszke, and E. Culurciello. An analysis of deep neural network models for practical

applications. arXiv:1605.07678, 2017.

[5] Meier U. Masci-J. Schmidhuber J. Ciresan, D. A committee of neural networks for trafﬁc sign classiﬁcation.

In IEEE International joint conference on neural networks, 2011.

[6] Meier U. Masci-J. Schmidhuber J. Ciresan, D. Multi-column deep neural network for trafﬁc sign classiﬁca-

[7] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. ImageNet: A Large-Scale Hierarchical Image

tion. In Neural Networks, 2012.

Database. In CVPR09, 2009.

[8] Seyyed Hossein Hasanpour, Mohammad Rouhani, Mohsen Fayyaz, Mohammad Sabokrou, and Ehsan
Adeli. Towards principled design of deep convolutional networks: Introducing simpnet. arXiv preprint
arXiv:1802.06205, 2018.

[9] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectiﬁers: Surpassing
human-level performance on imagenet classiﬁcation. In Proceedings of the IEEE international conference
on computer vision, pages 1026–1034, 2015.

[10] Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand,
Marco Andreetto, and Hartwig Adam. Mobilenets: Efﬁcient convolutional neural networks for mobile
vision applications. arXiv preprint arXiv:1704.04861, 2017.

[11] Forrest N Iandola, Song Han, Matthew W Moskewicz, Khalid Ashraf, William J Dally, and Kurt Keutzer.
Squeezenet: Alexnet-level accuracy with 50x fewer parameters and< 0.5 mb model size. arXiv preprint
arXiv:1602.07360, 2016.

[12] Zhang C. Jin J., Fu K. Trafﬁc sign recognition with hinge loss trained convolutional neural networks. In

IEEE Transactions on Intelligent Transportation Systems, pages 1991–2000, 2014.

[13] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classiﬁcation with deep convolutional

[14] Bottou L. Bengio Y. LeCun, Y. and P. Haffner. Gradient-based learning applied to document recognition.

neural networks. In NIPS, 2012.

Proceedings of the IEEE, 1998.

[15] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature, 2015.

[16] J. Redmon. YOLO: Real-time object detection. https://pjreddie.com/darknet/yolo/, 2016.

[17] Mark Sandler, Andrew Howard, and Menglong Zhu Andrey Zhmoginov Liang-Chieh Chen. Inverted
residuals and linear bottlenecks: Mobile networks for classiﬁcation, detection and segmentation. arXiv
preprint arXiv:1801.04381, 2018.

[18] P. Sermanet and Y. LeCun. Trafﬁc sign recognition with multi-scale convolutional networks. In The

International Joint Conference on Neural Networks (IJCNN), 2011.

[19] Mohammad Javad Shaﬁee, Francis Li, Brendan Chwyl, and Alexander Wong. Squishednets: Squish-
ing squeezenet further for edge device scenarios via deep evolutionary synthesis. arXiv preprint
arXiv:1711.07459, 2017.

[20] J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel. The german trafﬁc sign recognition benchmark: a
multi-class classiﬁcation competition. IEEE International joint conference on neural networks, 2011.

[21] Johannes Stallkamp, Marc Schlipsing, Jan Salmen, and Christian Igel. Man vs. computer: Benchmarking

machine learning algorithms for trafﬁc sign recognition. Neural networks, 32:323–332, 2012.

[22] A. Wong. Netscore: Towards universal metrics for large-scale performance analysis of deep neural

networks for practical usage. arXiv:1806.05512, 2018.

[23] A. Wong, M. Shaﬁee, F. Li, and B. Chwyl. Tiny ssd: A tiny single-shot detection deep convolutional neural

network for real-time embedded object detection. arXiv preprint arXiv:1802.06488, 2018.

[24] Bichen Wu, Forrest Iandola, Peter H Jin, and Kurt Keutzer. Squeezedet: Uniﬁed, small, low power fully
convolutional neural networks for real-time object detection for autonomous driving. arXiv preprint
arXiv:1612.01051, 2016.

[25] Liu Y. Li-J. Liu H. Wu, Y. and X. Hu. Trafﬁc sign detection based on convolutional neural networks. In

The International Joint Conference on Neural Networks (IJCNN), 2013.

[26] Z. Zhong, J. Li, Z. Luo, and M. Chapman. Spectral-spatial residual network for hyperspectral image
classiﬁcation: A 3-d deep learning framework. IEEE Transaction on Geoscience and Remote Sensing,
2018.

11

