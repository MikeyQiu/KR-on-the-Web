Knowledge Diffusion for Neural Dialogue Generation

Shuman Liu†,§∗, Hongshen Chen‡, Zhaochun Ren‡, Yang Feng†, Qun Liu♦, Dawei Yin‡,
† Key Laboratory of Intelligent Information Processing
Institute of Computing Technology, Chinese Academy of Sciences
‡ Data Science Lab, JD.com
♦ ADAPT centre, School of Computing, Dublin City University
§ University of Chinese Academy of Sciences
liushuman@ict.ac.cn, chenhongshen,renzhaochun@jd.com,
fengyang,liuqun@ict.ac.cn, yindawei@acm.org

Abstract

End-to-end neural dialogue generation has
shown promising results recently, but it
does not employ knowledge to guide the
generation and hence tends to generate
short, general, and meaningless responses.
In this paper, we propose a neural knowl-
to intro-
edge diffusion (NKD) model
duce knowledge into dialogue generation.
This method can not only match the rele-
vant facts for the input utterance but dif-
fuse them to similar entities. With the
help of facts matching and entity diffu-
sion,
the neural dialogue generation is
augmented with the ability of convergent
and divergent thinking over the knowledge
base. Our empirical study on a real-world
dataset proves that our model is capable of
generating meaningful, diverse and natural
responses for both factoid-questions and
knowledge grounded chi-chats. The ex-
periment results also show that our model
outperforms competitive baseline models
signiﬁcantly.

1

Introduction

Dialogue systems are receiving more and more
attention in recent years. Given previous ut-
terances, a dialogue system aims to generate a
proper response in a natural way. Compared with
the traditional pipeline based dialogue system,
the new method based on sequence-to-sequence
model (Shang et al., 2015; Vinyals and Le, 2015;
Cho et al., 2014) impressed the research com-
munities with its elegant simplicity. Such meth-
ods are usually in an end-to-end manner: utter-
ances are encoded by a recurrent neural network

∗Work done when the ﬁrst author was an intern at Data

Science Lab, JD.com.

while responses are generated sequentially by an-
other (sometimes identical) recurrent neural net-
work. However, due to lack of universal back-
ground knowledge and common senses, the end-
to-end data-driven structure inherently tends to
generate meaningless and short responses, such as
“haha” or “I don’t know.”

To bridge the gap of the common knowledge
between human and computers, different kinds
of knowledge bases ( e.g., the freebase (Google,
2013) and DBpedia (Lehmann et al., 2017) ) are
leveraged. A related application of knowledge
bases is question answering, where the given ques-
tions are ﬁrst analyzed, followed by retrieving re-
lated facts from knowledge bases (KBs), and ﬁ-
nally the answers are generated.The facts are usu-
ally presented in the form of “subject-relation-
object” triplets, where the subject and object are
entities. With the aid of knowledge triplets, neural
generative question answering systems are capa-
ble of answering facts related inquiries (Yin et al.,
2016; Zhu et al., 2017; He et al., 2017a), WH ques-
tions in particular, like “who is Yao Ming’s wife ?”.
Although answering enquiries is essential for
dialogue systems, especially for task-oriented di-
alogue systems (Eric et al., 2017), it is still far
behind a natural knowledge grounded dialogue
system, which should be able to understand the
facts involved in current dialogue session (so-
called facts matching), as well as diffuse them
to other similar entities for knowledge-based chit-
chats (i.e. entity diffusion):
1) facts matching: in dialogue systems, matching
utterances to exact facts is much harder than ex-
plicit factoid inquiries answering. Though some
utterances are facts related inquiries, whose sub-
jects and relations can be easily recognized, for
some utterances, the subjects and relations are elu-
sive, which leads the trouble in exact facts match-
ing.

ID

Dialogue

1

2

3

4

A: Who is the director of the Titanic?
泰坦尼克号的导演是谁？
B: James Cameron.
詹姆斯卡梅隆。
A: Titanic is my favorite ﬁlm!
泰坦尼克号是我最爱的电影！
B: The love inside it is so touching.
里面的爱情太感人了。
A: Is there anything like the Titanic?
有什么像泰坦尼克号一样的电影吗？
B: I think the love story in ﬁlm Waterloo
Bridge is beautiful, too.
我觉得魂断蓝桥中的爱情故事也很美。
A: Is there anything like the Titanic?
有什么像泰坦尼克号一样的电影吗？
B: Poseidon is also a classic marine ﬁlm.
海神号也是一部经典的海难电影。

• We manage both facts matching and entity
diffusion by introducing a novel knowledge
diffusion mechanism and generate the re-
sponses with the retrieved knowledge items,
which enable the convergent and divergent
thinking over the knowledge base.

• The experimental results show that the pro-
posed model effectively generate more di-
verse and meaningful responses involving
more accurate relevant entities compared
with the state-of-the-art baselines.

The corpus will be released upon publication.

2 Model

Table 1: Examples of knowledge grounded con-
versations. Knowledge entities are underlined.

Table 1 shows an example: Item 1 and 2 are talk-
ing about the ﬁlm “Titanic”, Unlike item 1, which
is a typical question answering conversation,item
2 is a knowledge related chit-chat without any ex-
plicit relation. It is difﬁcult to deﬁne the exact fact
match for item 2.
2) entity diffusion:
another noticeable phe-
nomenon is that the conversation usually drifts
from one entity to another. In Table 1, utterances
in item 3 and 4 are about entity “Titanic”, how-
ever, the entity of responses are other similar ﬁlms.
Such entity diffusion relations are rarely captured
by the current knowledge triplets. The response
in item 3 shows that the two entities “Titanic” and
“Waterloo Bridge” are relevant through “love sto-
ries”. Item 4 suggests another similar shipwreck
ﬁlm of “Titanic”.

To deal with the aforementioned challenges,
in this paper, we propose a neural knowledge
diffusion (NKD) dialogue system to beneﬁt the
neural dialogue generation with the ability of both
convergent and divergent thinking over the knowl-
edge base, and handle factoid QA and knowledge
grounded chit-chats simultaneously. NKD learns
to match utterances to relevant facts; the matched
facts are then diffused to similar entities; and ﬁ-
nally, the model generates the responses with re-
spect to all the retrieved knowledge items.

In general, our contributions are as follows:

• We identify the problem of incorporating
knowledge bases and dialogue systems as
facts matching and entity diffusion.

Figure 1: Neural Knowledge Diffusion Dialogue
System.

the

input

Given

utterance X

=
(x1, x2, ..., xNX ), NKD produces a response
Y = (y1, y2, ..., yNY ) containing the entities from
the knowledge base K. NX and NY are the
number of tokens in the utterance and response re-
spectively. The knowledge base K is a collection
of knowledge facts in the form of triplets (subject,
relation, object). In particular, both subjects and
objects are entities in this work. As illustrated
in Figure 1, the model mainly consists of four
components:

1. An encoder encodes the input utterance X

into a vector representation.

2. A context RNN keeps the dialogue state
along a conversation session. It takes the ut-
terance representation as input, and outputs a
vector guiding the response generation each
turn.

3. A decoder generates the ﬁnal response Y .

4. A knowledge retriever performs the facts
matching and diffuses to similar entities at
each turn.

recurrent
Our work is built on hierarchical
encoder-decoder architecture (Sordoni et al.,
2015a), and a knowledge retriever network inte-
grates the structured knowledge base into the dia-
logue system.

2.1 Encoder

1 , hC

2 , ..., hC
NX

The encoder transforms discrete tokens into vec-
tor representations. To capture information at dif-
ferent aspects, we learn utterance representations
with two independent RNNs resulting with two
hidden state sequences H C = (hC
)
and H K = (hK
2 , ..., hK
1 , hK
) respectively. One
NX
ﬁnal hidden state hC
is used as the input of con-
NX
text RNN to track the dialogue state. The other
ﬁnal hidden state hK
is utilized in knowledge
NX
retriever and is designed to encode the knowl-
edge entities and relations within the input utter-
ances. For instance, in Figure 1, “director” and
“Titanic” in X1 are knowledge elements.

2.2 Knowledge Retriever

Knowledge retriever extracts a certain number of
facts from knowledge base and speciﬁes their im-
portance. It enables the knowledge grounded neu-
ral dialogue system with convergent and divergent
thinking ability through facts matching and entity
diffusion. Figure 2 illustrates the process.

2.2.1 Facts Matching
Given the input utterance X and hK
, relevant
NX
facts are extracted from both the knowledge base
and the dialogue history. A predeﬁned number
of relevant facts F = {f1, f2, ..., fNf } are ob-
tained through string matching, entity linking or
named entity recognition. As shown in Figure
2, in the ﬁrst sentence, “Titanic” is recognized
as an entity, all the relevant knowledge triplets
are extracted. Then, these entities and knowledge
triplets are transformed into fact representations

hf = {hf 1, hf 2, ...hf Nf
} by averaging the en-
tity embedding and relation embedding. The rele-
vance coefﬁcient rf between a fact and the input
utterances, ranging from 0 to 1, is calculated by a
nonlinear function or a sub neural network. Here,
we apply a multi-layer perceptron (MLP):

rf
k = M LP ([hK
NX

, hf k]).

For the multi-turn conversation, entities in pre-
vious utterances are also inherited and reserved
as depicted in Figure 2 the dotted lines. For in-
stance, in the second sentence of Figure 2 (right
one), no new fact is extracted from the input utter-
ance. Thus it is necessary to record the history en-
tities “Titanic” and “James Cameron”. We sum-
marize the facts as relevant fact representation Cf
through a weighted average of fact representations
hf :

Cf =

k hf k

(cid:80)Nf

k=1 rf
(cid:80)Nf

k=1 rf

k

.

2.2.2 Entity Diffusion
To retrieve other relevant entities, which are typ-
ically not mentioned in the dialogue utterance,
we diffuse the matched facts. We calculate the
similarity between the entities (except the enti-
ties that have occurred in previous utterances) in
the knowledge base and the relevant fact represen-
tation through a multi-layer perceptron, resulting
with a similarity coefﬁcient re, ranging from 0 to
1:

k = M LP ([hK
re
NX

, Cf , ek]),

where ek is the entity embedding. The top Ne
number of entities E = {e1, e2, ..., eNe} are se-
lected as similar entities. Then, the similar entity
representation Cs is formalized as:

Cs =

(cid:80)Ne

k=1 re
kek
(cid:80)Ne
k=1 re
k

.

Back to the example in Figure 2, in the ﬁrst
turn,
the matched fact of the input utterance
(T itanic, direct by, JamesCameron) is of a
high relevance coefﬁcient in “facts matching” as
expected. When a fact getting matched, intuitively
it is not necessary for entity diffusion.
In such
case, from the Figure 2, we observe that the en-
tities in “entity diffusing” are of low similarities.
In the second turn, there is no triplets matched to
the utterance, while the entity “Titanic” achieves
a much higher relevance score. Then in “entity

Figure 2: Knowledge Retriever. Facts related to input utterance are extracted by facts matching. Similar
entities are then ﬁgured out by entity diffusion. The dotted lines show the inheritance of previous facts.

diffusion”, the similar entities “Waterloo Bridge”
and “Poseidon” get relatively higher similarity
weights than in the ﬁrst turn.

2.3 Context RNN

Context RNN records the utterance level dialogue
state. It takes in the utterance representation and
the knowledge representations. The hidden state
of the context RNN is updated as:

t = RN N (hC
hT

t , [Cf , Cs], hT

t−1).

is then conveyed to the decoder to guide the

hT
t
response generation.

2.4 Decoder

The decoder generates the response sequentially
t , Cf
through a word generator conditioned on hT
and Cs. Let C denotes the concatenation of hT
t ,
Cf and Cs. Knowledge items coefﬁcient R is the
concatenation of relevance coefﬁcient rf and sim-
ilarity coefﬁcient re. We introduce two variants of
word generator:

Vanilla decoder simply generates the response
Y = (y1, y2, ..., yNy ) according to C, R. The

Figure 3: The decoder generates words from both
vocabulary and knowledge base. A score updater
keeps tracking of the knowledge item coefﬁcients
to ensure its coverage during response generation.

probability of Y is deﬁned as

p(y1, .., yNy |C, R; θ)
Ny
(cid:89)

= p(y1|C, R; θ)

t=2

p(yt|y1, .., yt−1, C, R; θ),

where θ denotes the model parameters. The con-
ditional probability of yt is speciﬁed by

p(yt|y1, ..., yt−1, C, R; θ)

= p(yt|yt−1, st, C, R; θ),

where yt is the embedding of the vocabulary or
object entities of retrieved knowledge items, st is
the decoder RNN hidden state .

Probabilistic gated decoder utilizes a gating
variable zt (Yin et al., 2016) to indicate whether
the tth word is generated from common vocabu-
lary or knowledge entities. The probability of gen-
erating the tth word is given by:

p(yt|yt−1, st, C, R; θ)

=p(zt = 0|st; θ)p(yt|yt−1, st, C, R, zt = 0; θ)
+p(zt = 1|st; θ)p(yt|R, zt = 1; θ),

where p(zt|st; θ) is computed by a logistic regres-
sion, p(yt|R, zt = 1; θ) is approximated with the
knowledge items coefﬁcient R, and θ is the model
parameter.

During response generation,

if an entity is
overused, the response diversity will be reduced.
Therefore, once a knowledge item occurred in
the response, the corresponding coefﬁcient should
be reduced in case that an item occurs multiple
times. To keep tracking the coverage of knowl-
edge items, we update the knowledge items coef-
ﬁcient R at each time step. We also explore two
coverage tracking mechanisms: 1) Mask coefﬁ-
cient tracker directly reduces the coefﬁcient of the
chosen knowledge item to 0 to ensure it can never
be selected as the response word again. 2) Coefﬁ-
cient attenuation tracker calculates an attenuation
score it based on st, R0, Rt−1 and yt−1:

it = DN N (st, yt−1, R0, Rt−1),

and then update the coefﬁcient as:

Rt = it · Rt−1,

where it ranges from 0 to 1 to gradually decrease
the coefﬁcient.

2.5 Training

The model parameters include the embedding of
vocabulary, entities, relations, and all the model
components. The model is differential and can
be optimized in an end-to-end manner using back-
propagation. Given the training data

where Nd is the max turns of a dialogue, F de-
notes the set of relevant knowledge and E denotes
the set of similar knowledge in response, the ob-
jective function is to minimize the negative log-
likelihood:

(cid:96)(D, θ) = −

log p(Yi|Xi, Fi, Ei)

(cid:88)

ND(cid:88)

i=1

3 Experiment

3.1 Dataset

Most existing knowledge related datasets are
mainly focused on single-turn factoid question
answering (Yin et al., 2016; He et al., 2017b).
We here collect a multi-turn conversation cor-
pus grounded on the knowledge base, which in-
cludes not only facts related inquiries but also
knowledge-based chit-chats. The data is publicly
available online1.

We ﬁrst obtain the element information of each
movie,
including the movie’s title, publication
time, directors, actors and other attributes from
https://movie.douban.com/, a popular Chinese
social network for movies. Then, entities and re-
lations are extracted as triplets to build the knowl-
edge base K.

To collect the question-answering dialogues,
we crawled the corpus from a question-answering
forum https://zhidao.baidu.com/.
To
gather the knowledge related chit-chat corpus,
we mined the dataset from the social forum
https://www.douban.com/group/. Users post
their comments, feedbacks, and impressions of
ﬁlms and televisions on it.

The conversations are grounded on the knowl-
edge using NER, string match, and artiﬁcial scor-
ing and ﬁltering rules. The statistical informa-
tion of the dataset is shown in Table 2. We ob-
served that the conversations follow the long tail
distribution, where famous ﬁlms and televisions
are discussed repeatedly and the low rating ones
are rarely mentioned.

3.2 Experiment Detail

The total 32977 conversations consisting of
104567 utterances are divided into training
(32177) and testing set (800). Bi-directional
LSTM (Schuster and Paliwal, 1997) is used for
encoder, and the dimension of the LSTM hidden

D = {(X Nd

1 , Y Nd

1

, F Nd
1

, ENd

1 )}

diffusion

1https://github.com/liushuman/neural-knowledge-

Knowledge base
#relations
4

#entities
152568

#triplets
766854

Community QA Multi-round dialogue
#sentences
88325

#dialogues
24856

#QA pairs
8121

Table 2: Statistics of knowledge base and conversations.

layer is set to 512. For the context RNN, the di-
mension of the LSTM unit is set to 1024. The
dimension of word embedding shared by the vo-
cabulary, entities and relations is also set to 512
empirically. We use Adam learning (Kingma and
Ba, 2014) to update the gradient and clip the gra-
dient in 5.0. It takes 140 to 150 epochs to train the
model with a batch size of 80.

3.3 Baselines

We compare our neural knowledge diffusion
model with three state-of-the-art baselines:

• Seq2Seq: a sequence to sequence model with
vanilla RNN encoder-decoder (Shang et al.,
2015; Vinyals and Le, 2015).

• HRED: a hierarchical recurrent encoder-

decoder model.

• GenDS: a neural generative dialogue system
that is capable of generating responses based
on input message and related knowledge base
(KB) (Zhu et al., 2017) .

Three variants of the neural diffusion dialogue
generation model are implemented to verify dif-
ferent conﬁgurations of decoders.

• NKD-ori is the original model with a vanilla

decoder and a mask coefﬁcient tracker.

• NKD-gated is augmented with a probabilis-
tic gated decoder and a mask coefﬁcient
tracker.

• NKD-atte utilizes a vanilla decoder and the

coefﬁcient attenuation tracker.

3.4 Evaluation Metric

Both automatic and human evaluation metrics are
used to analyze the model’s performance. To val-
idate the effectiveness of facts matching and dif-
fusion, we calculate entity accuracy and recall
on factoid QA data set as well as the whole data
set. Human evaluation rates the model in three
aspects: ﬂuency, knowledge relevance and cor-
rectness of the response. All these metrics range
from 0 to 3, where 0 represents complete error, 1

model
LSTM
HRED
GenDS
NKD-ori
NKD-gated
NKD-atte

accuracy(%)
7.8
3.7
70.3
67.0
77.6
55.1

recall(%)
7.5
3.9
63.1
56.2
77.3
46.6

Table 3: Evaluation results on factoid question
answering dialogues.

model
LSTM
HRED
GenDS
NKD-ori
NKD-gated
NKD-atte

accuracy(%)
2.6
1.4
20.9
22.9
24.8
18.4

recall(%)
2.5
1.5
17.4
19.7
25.6
16.0

entity number
1.65
1.79
1.34
2.55
1.59
3.41

Table 4: Evaluation results on entire dataset.

for partially correct, 2 for almost correct, 3 for ab-
solutely correct.

3.5 Experiment Result

Table 3 displays the accuracy and recall of entities
on factoid question answering dialogues. The per-
formance of NKD is slightly better than the spe-
ciﬁc QA solution GenDS, while LSTM and HRED
which are designed for chi-chat almost fail in this
task. All the variants of NKD models are capa-
ble of generating entities with an accuracy of 60%
to 70%, and NKD-gated achieves the best perfor-
mance with an accuracy of 77.6% and a recall of
77.3%.

Table 4 lists the accuracy and recall of entities
on the entire dataset including both the factoid QA
and knowledge grounded chit-chats. Not surpris-
ingly, both NKD-ori and NKD-gated outperform
GenDS on the entire dataset, and the relative im-
provement over GenDS is even higher than the im-
provement in QA dialogues. It conﬁrms that al-
though NKD and GenDS are comparable in an-
swering factoid questions, NKD is better at in-
troducing the knowledge entities for knowledge
grounded chit-chats.

All the NKD variants in Table 4 generate more
entities than GenDS. LSTM and HRED also pro-
duce a certain amount of entities, but are of low

Fluency Appropriateness

model

LSTM
HRED
GenDS
NKD-ori
NKD-gated
NKD-atte

2.52
2.48
2.76
2.42
2.08
2.7

of knowledge
0.88
0.36
1.36
1.92
1.72
1.54

Entire
Correctness
0.8
0.32
1.34
1.58
1.44
1.38

Table 5: Human evaluation result.

accuracies and recalls. We also noticed that NKD-
gated achieves the highest accuracy and recall,
but generates fewer entities compared with NKD-
ori and NKD-gated, whereas NKD-atte generates
more entities but also with relatively low accu-
racies and recalls.This demonstrates that NKD-
gated not only learns to generate more entities but
also maintains the quality ( with a relatively high
accuracy and recall ).

The results of human evaluation in Table 5 also
validate the superiority of the proposed model, es-
pecially on appropriateness. Responses generated
by LSTM and HRED are of high ﬂuency, but are
simply repetitions, or even dull responses as “I
don’t know.”, “Good.”. NKD-gated is more adept
at incorporating the knowledge base with respect
to appropriateness and correctness, while NKD-
atte generates more ﬂuent responses. NKD-ori
is a compromise, and obtains the best correctness
in completing an entire dialogue. Four evaluators
rated the scores independently. The pairwise Co-
hen’s Kappa agreement scores are 0.67 on ﬂuency,
0.54 on appropriateness, and 0.60 on entire cor-
rectness, which indicate a strong annotator agree-
ment.

To our surprise, one of the variant model of
NKD, which utilized both probabilistic gated de-
coder and coefﬁcient attenuation tracker does not
perform well on entire dataset. The accuracy of
the model is quite high, but the recall is very
low compared to others. We speculate that this
is due to the method of minimizing negative
log-likelihood during the training process, which
makes the model tend to generate completely cor-
rect answers, and therefore reduces the number of
generated entities.

3.6 Case Study

Table 6 shows typical examples of the generated
responses. Both Item 1 and 2 are based on facts
relevant utterances. NKD handles these questions
by facts matching. Item 3 asks for a recommen-

dation. NKD obtains similar entities by diffus-
ing the entities. For item 4, 5 and 6, no explicit
entity appears in the utterances. NKD is able to
output appropriate recommendations through en-
tity diffusion. The entities are recorded during
the whole dialogue session, so NKD keeps recom-
mending for several turns. Item 7 fails to gener-
ate an appropriate response because the entity in
the golden response does not appear in the train-
ing set, which suggests the future work for out-of-
vocabulary cases.

4 Related Work

The successes of sequence-to-sequence architec-
ture (Cho et al., 2014; Sutskever et al., 2014) mo-
tivated investigation in dialogue systems that can
effectively learn to generate a response sequence
given the previous utterance sequence (Shang
et al., 2015; Sordoni et al., 2015b; Vinyals and Le,
2015). The model is trained to minimize the nega-
tive log-likelihood of the training data. Despite the
current progress, the lack of response diversity is
a notorious problem, where the model inherently
tends to generate short, general responses in spite
of different inputs. Li et al. (2016a); Serban et al.
(2017); Cao and Clark (2017) suggested that the-
ses boring responses are common in training data
and shorter responses are more likely to be given
a higher likelihood. To tackle the problem, Li
et al. (2016a) introduced a maximum mutual in-
formation training objective. Serban et al. (2017),
Cao and Clark (2017) and Chen et al. (2018) used
latent variables to introduce stochasticity to en-
hance the response diversity. Vijayakumar et al.
(2016),Shao et al. (2017) and Li et al. (2016b)
recognized that the greedy search decoding pro-
cess, especially beam-search with a wide beam
size, leads the short responses possess higher like-
lihoods. They reserved more diverse candidates
during beam-search decoding.
In this paper, we
present that the absence of background knowledge
and common sense is another source of lacking di-
versity. We augment the knowledge base to end-
to-end dialogue generation.

Another research line comes from the utiliz-
ing of knowledge bases. A typical application is
question-answering (QA) systems. The end-to-
end QA also resort to the encoder-decoder frame-
work (Yin et al., 2016; He et al., 2017a). Yin et al.
(2016) enquired the knowledge-base to achieve
one fact and answer the simple factoid questions

1

2

3

4

5

6

7

ID Utterance

X1:Duckweed, casts

乘风破浪，演员表

X1: Just spend the whole night watching the movie
Silenced, a little depressed now

刚看完熔炉... 连夜看完的，略低落

X1:Which movie most representative of youth? I’d like
In the Heat of the Sun, Flipped, First Love(Sing Street)
你觉得最能代表青春的电影有哪些呢 我觉得有
阳光灿烂的日子，怦然心动，初恋这件小事（唱街）
X1:Can anyone recommend me some touching movie,
tears streaming after watching

谁能给我推荐两部感人的电影，直接点的，看了

可以流两缸眼泪那种
X1:burn brain or suspense movies please, recommend me
some burn brain or suspense or horror ﬁlms please! sus-
pense ﬁlms which are less popular are ok!!!

求推荐烧脑的推理悬疑电影 求各位大神推荐烧脑

的悬疑恐怖电影 冷门的推理剧也爱！！！

X2:I’ve seen it, it’s nice

看过哦不错呢

Response
Y1:Hongda Guan Jiufeng Shi Qi Wang Zhi Cheng

关宏达 史久峰 汪漪 程之

NKD:Hongda Guan Jiufeng Shi Qi Wang Zhi Cheng

关宏达 史久峰 汪漪 程之
Y1:I saw it last night and had a hard time

昨晚看了，心里好难过

NKD:The ﬁlm has an atmosphere make us rethink sth

气氛有，会反思一些事

Y1:Kids Return

坏孩子的天空

NKD:《Love Letter》《Once》
《情书》《曾经》

Y1:Gift From Room 7 Hearty Paws Memories of Matsuko

7号房的礼物 人狗奇缘 被嫌弃的松子的一生

NKD:Wedding Dress, these ones,,,

婚纱，这些，，，

Y1:《The Skeleton Key》《Identity》

《万能钥匙》《致命id》

NKD:Identity
致命id
Y1:《Orphan》？
《孤儿怨》？

NKD: Also Inception Whisper of the Heart
Whisper of the Heart

还有 盗梦空间 侧耳倾听 侧耳倾听

死亡录像，山村老尸，死寂，1408，

NKD:Recommend a few I’ve seen, 《A Wicked Ghost》,
《hide and seek》

推荐几部我看过《山村老尸》、《捉迷藏》

Y1:The Others, hardly call to mind

小岛惊魂，冷不丁还真想不起来

NKD: Identity, Fight Club, Interstellar, Snowpiercer
致命id、搏击俱乐部、星际穿越、雪国列车

X1:It’s a bit boring recently. Any good horror movies,
guys? I’ve watched a lot.

Y1:Rec,
1408 phontom horror,

A Wicked Ghost,

Dead Silence,

最近有点无聊，各位豆友有什么好看的恐怖片推

荐啊？看了好多了。

X2:I’ve seen it all, anything else?

卤煮都看过了。还有推荐？

X3:Have seen it before, really great

看过，真的很不错的说

X1:any awesome animation like Song of the Sea, please

Y1::The Girl Without Hands

求一些画风超赞的动画 类似于海洋之歌这种的，

谢谢

Y3:《The Revenant》, nice movie

《亡灵》，非常好看

NKD:So what type do you like?
那你喜欢什么类型的？

无手的少女

NKD:strongly recommended

强烈推荐

Table 6: Examples of the generated response. Entities are underlined and Yi denotes the gold response.

by referring to the fact. He et al. (2017a) ex-
tended this approach by augmenting the copying
mechanism and enabled the output words to copy
from the original input sequence. Eric et al. (2017)
noticed that neural task-oriented dialogue systems
often struggle to smoothly interface with a knowl-
edge base and they addressed the problem by aug-
menting the end-to-end structure with a key-value
retrieval mechanism where a separate attention is
performed over the key of each entry in the KB.
Ghazvininejad et al. (2017) represented the un-
structured text as bag of words representation and

also performed soft attention over the facts to re-
trieve a facts vector. Zhu et al. (2017) generated
responses with any number of answer entities in
the structured KB, even when these entities never
appear in the training set. Dhingra et al. (2017)
proposed a multi-turn dialogue agent which helps
users search knowledge base by soft KB lookup.
In our model, we perform not only facts matching
to answer factoid inquiries, but also entity diffu-
sion to infer similar entities. Given previous utter-
ances, we retrieve the relevant facts, diffuse them,
and generate responses based on diversiﬁed rele-

vant knowledge items.

5 Conclusion

In this paper, we identify the knowledge diffusion
in conversations and propose an end-to-end neu-
ral knowledge diffusion model to deal with the
problem. The model integrates the dialogue sys-
tem with the knowledge base through both facts
matching and entity diffusion, which enable the
convergent and divergent thinking over the knowl-
edge base. Under such mechanism, the factoid
question answering and knowledge grounded chit-
chats can be tackled together. Empirical results
show the proposed model is able to generate more
meaningful and diverse responses, compared with
In future work,
the state-of-the-art baselines.
we plan to introduce reinforcement learning and
knowledge base reasoning mechanisms to improve
the performance.

Acknowledgements

This work is supported by the National Natu-
ral Science Foundation of China (No.61662077,
No.61472428). We also would like to thank all the
reviewers for their insightful and valuable com-
ments and suggestions.

References

Kris Cao and Stephen Clark. 2017. Latent variable di-
alogue models and their diversity. In Proceedings of
the 15th Conference of the European Chapter of the
Association for Computational Linguistics: Volume
2, Short Papers, pages 182–187, Valencia, Spain.
Association for Computational Linguistics.

Hongshen Chen, Zhaochun Ren, Jiliang Tang, Yi-
hong Eric Zhao, and Dawei Yin. 2018. Hierarchi-
cal variational memory network for dialogue gener-
ation. In Proceedings of the 2018 World Wide Web
Conference on World Wide Web, pages 1653–1662.
International World Wide Web Conferences Steering
Committee.

Kyunghyun Cho, Bart van Merrienboer, Caglar Gul-
cehre, Dzmitry Bahdanau, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. 2014.
Learning
phrase representations using rnn encoder–decoder
for statistical machine translation. In Proceedings of
the 2014 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP), pages 1724–
1734, Doha, Qatar. Association for Computational
Linguistics.

Bhuwan Dhingra, Lihong Li, Xiujun Li, Jianfeng Gao,
Yun-Nung Chen, Faisal Ahmed, and Li Deng. 2017.

Towards end-to-end reinforcement learning of dia-
logue agents for information access. In Proceedings
of the 55th Annual Meeting of the Association for
Computational Linguistics.

Mihail Eric, Lakshmi Krishnan, Francois Charette, and
Christopher D. Manning. 2017. Key-value retrieval
networks for task-oriented dialogue. In Proceedings
of the 18th Annual SIGdial Meeting on Discourse
and Dialogue, pages 37–49. Association for Com-
putational Linguistics.

Marjan Ghazvininejad, Chris Brockett, Ming-Wei
Chang, Bill Dolan, Jianfeng Gao, Wen-tau Yih,
and Michel Galley. 2017. A knowledge-grounded
arXiv preprint
neural conversation model.
arXiv:1702.01932.

Google. 2013. Freebase data dumps.

Shizhu He, Cao Liu, Kang Liu, Jun Zhao, Shizhu He,
Cao Liu, Kang Liu, and Jun Zhao. 2017a. Generat-
ing natural answers by incorporating copying and re-
trieving mechanisms in sequence-to-sequence learn-
In Meeting of the Association for Computa-
ing.
tional Linguistics, pages 199–208.

Wei He, Kai Liu, Yajuan Lyu, Shiqi Zhao, Xinyan
Xiao, Yuan Liu, Yizhong Wang, Hua Wu, Qiaoqiao
She, Xuan Liu, Tian Wu, and Haifeng Wang. 2017b.
Dureader: a chinese machine reading comprehen-
arXiv
sion dataset from real-world applications.
eprint arXiv:1711.05073.

Diederik P. Kingma and Jimmy Ba. 2014. Adam:
CoRR,

A method for stochastic optimization.
abs/1412.6980.

Jens Lehmann, Robert

Isele, Max Jakob, Anja
Jentzsch, Dimitris Kontokostas, Pablo N. Mendes,
Sebastian Hellmann, Mohamed Morsey, Patrick van
Kleef, S¨oren Auer, and Christian Bizer. 2017. Db-
pedia – a large-scale, multilingual knowledge base
extracted from wikipedia.

Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao,
and Bill Dolan. 2016a. A diversity-promoting ob-
jective function for neural conversation models. In
Proceedings of the 2016 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 110–119, San Diego, California. Association
for Computational Linguistics.

Jiwei Li, Will Monroe, and Jurafsky Dan. 2016b. A
simple, fast diverse decoding algorithm for neural
generation. arXiv preprint arXiv:1611.08562.

M. Schuster and K. K. Paliwal. 1997. Bidirectional re-
current neural networks. IEEE Transactions on Sig-
nal Processing, 45(11):2673–2681.

Iulian Serban, Alessandro Sordoni, Ryan Lowe, Lau-
rent Charlin, Joelle Pineau, Aaron Courville, and
Yoshua Bengio. 2017. A hierarchical latent variable
encoder-decoder model for generating dialogues. In
AAAI Conference on Artiﬁcial Intelligence.

Lifeng Shang, Zhengdong Lu, and Hang Li. 2015.
Neural responding machine for short-text conver-
In Proceedings of the 53rd Annual Meet-
sation.
ing of the Association for Computational Linguistics
and the 7th International Joint Conference on Natu-
ral Language Processing (Volume 1: Long Papers),
pages 1577–1586, Beijing, China. Association for
Computational Linguistics.

Louis Shao, Stephan Gouws, Denny Britz, Anna
Goldie, and Brian Strope. 2017. Generating long
and diverse responses with neural conversation mod-
els. arXiv preprint arXiv:1701.03185.

Alessandro Sordoni, Yoshua Bengio, Hossein Vahabi,
Christina Lioma, Jakob Grue Simonsen, and Jian-
Yun Nie. 2015a. A hierarchical recurrent encoder-
decoder for generative context-aware query sugges-
tion. In Proceedings of the 24th ACM International
on Conference on Information and Knowledge Man-
agement, pages 553–562. ACM.

Alessandro Sordoni, Michel Galley, Michael Auli,
Chris Brockett, Yangfeng Ji, Margaret Mitchell,
Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. 2015b.
A neural network approach to context-sensitive gen-
In Proceed-
eration of conversational responses.
ings of the 2015 Conference of the North Ameri-
can Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
196–205, Denver, Colorado. Association for Com-
putational Linguistics.

Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.
Sequence to sequence learning with neural net-
works. In Advances in neural information process-
ing systems, pages 3104–3112.

Ashwin K Vijayakumar, Michael Cogswell, Ram-
prasath R Selvaraju, Qing Sun, Stefan Lee, David
Crandall, and Dhruv Batra. 2016. Diverse beam
search: Decoding diverse solutions from neural se-
quence models. arXiv preprint arXiv:1610.02424.

Oriol Vinyals and Quoc Le. 2015. A neural conversa-
tional model. arXiv preprint arXiv:1506.05869.

Jun Yin, Xin Jiang, Zhengdong Lu, Lifeng Shang,
Hang Li, and Xiaoming Li. 2016. Neural generative
question answering. In International Joint Confer-
ence on Artiﬁcial Intelligence, pages 2972–2978.

Wenya Zhu, Kaixiang Mo, Yu Zhang, Zhangbin Zhu,
Xuezheng Peng, and Qiang Yang. 2017. Flexible
end-to-end dialogue system for knowledge grounded
conversation. arXiv eprint arXiv:1709.04264.

Knowledge Diffusion for Neural Dialogue Generation

Shuman Liu†,§∗, Hongshen Chen‡, Zhaochun Ren‡, Yang Feng†, Qun Liu♦, Dawei Yin‡,
† Key Laboratory of Intelligent Information Processing
Institute of Computing Technology, Chinese Academy of Sciences
‡ Data Science Lab, JD.com
♦ ADAPT centre, School of Computing, Dublin City University
§ University of Chinese Academy of Sciences
liushuman@ict.ac.cn, chenhongshen,renzhaochun@jd.com,
fengyang,liuqun@ict.ac.cn, yindawei@acm.org

Abstract

End-to-end neural dialogue generation has
shown promising results recently, but it
does not employ knowledge to guide the
generation and hence tends to generate
short, general, and meaningless responses.
In this paper, we propose a neural knowl-
to intro-
edge diffusion (NKD) model
duce knowledge into dialogue generation.
This method can not only match the rele-
vant facts for the input utterance but dif-
fuse them to similar entities. With the
help of facts matching and entity diffu-
sion,
the neural dialogue generation is
augmented with the ability of convergent
and divergent thinking over the knowledge
base. Our empirical study on a real-world
dataset proves that our model is capable of
generating meaningful, diverse and natural
responses for both factoid-questions and
knowledge grounded chi-chats. The ex-
periment results also show that our model
outperforms competitive baseline models
signiﬁcantly.

1

Introduction

Dialogue systems are receiving more and more
attention in recent years. Given previous ut-
terances, a dialogue system aims to generate a
proper response in a natural way. Compared with
the traditional pipeline based dialogue system,
the new method based on sequence-to-sequence
model (Shang et al., 2015; Vinyals and Le, 2015;
Cho et al., 2014) impressed the research com-
munities with its elegant simplicity. Such meth-
ods are usually in an end-to-end manner: utter-
ances are encoded by a recurrent neural network

∗Work done when the ﬁrst author was an intern at Data

Science Lab, JD.com.

while responses are generated sequentially by an-
other (sometimes identical) recurrent neural net-
work. However, due to lack of universal back-
ground knowledge and common senses, the end-
to-end data-driven structure inherently tends to
generate meaningless and short responses, such as
“haha” or “I don’t know.”

To bridge the gap of the common knowledge
between human and computers, different kinds
of knowledge bases ( e.g., the freebase (Google,
2013) and DBpedia (Lehmann et al., 2017) ) are
leveraged. A related application of knowledge
bases is question answering, where the given ques-
tions are ﬁrst analyzed, followed by retrieving re-
lated facts from knowledge bases (KBs), and ﬁ-
nally the answers are generated.The facts are usu-
ally presented in the form of “subject-relation-
object” triplets, where the subject and object are
entities. With the aid of knowledge triplets, neural
generative question answering systems are capa-
ble of answering facts related inquiries (Yin et al.,
2016; Zhu et al., 2017; He et al., 2017a), WH ques-
tions in particular, like “who is Yao Ming’s wife ?”.
Although answering enquiries is essential for
dialogue systems, especially for task-oriented di-
alogue systems (Eric et al., 2017), it is still far
behind a natural knowledge grounded dialogue
system, which should be able to understand the
facts involved in current dialogue session (so-
called facts matching), as well as diffuse them
to other similar entities for knowledge-based chit-
chats (i.e. entity diffusion):
1) facts matching: in dialogue systems, matching
utterances to exact facts is much harder than ex-
plicit factoid inquiries answering. Though some
utterances are facts related inquiries, whose sub-
jects and relations can be easily recognized, for
some utterances, the subjects and relations are elu-
sive, which leads the trouble in exact facts match-
ing.

ID

Dialogue

1

2

3

4

A: Who is the director of the Titanic?
泰坦尼克号的导演是谁？
B: James Cameron.
詹姆斯卡梅隆。
A: Titanic is my favorite ﬁlm!
泰坦尼克号是我最爱的电影！
B: The love inside it is so touching.
里面的爱情太感人了。
A: Is there anything like the Titanic?
有什么像泰坦尼克号一样的电影吗？
B: I think the love story in ﬁlm Waterloo
Bridge is beautiful, too.
我觉得魂断蓝桥中的爱情故事也很美。
A: Is there anything like the Titanic?
有什么像泰坦尼克号一样的电影吗？
B: Poseidon is also a classic marine ﬁlm.
海神号也是一部经典的海难电影。

• We manage both facts matching and entity
diffusion by introducing a novel knowledge
diffusion mechanism and generate the re-
sponses with the retrieved knowledge items,
which enable the convergent and divergent
thinking over the knowledge base.

• The experimental results show that the pro-
posed model effectively generate more di-
verse and meaningful responses involving
more accurate relevant entities compared
with the state-of-the-art baselines.

The corpus will be released upon publication.

2 Model

Table 1: Examples of knowledge grounded con-
versations. Knowledge entities are underlined.

Table 1 shows an example: Item 1 and 2 are talk-
ing about the ﬁlm “Titanic”, Unlike item 1, which
is a typical question answering conversation,item
2 is a knowledge related chit-chat without any ex-
plicit relation. It is difﬁcult to deﬁne the exact fact
match for item 2.
2) entity diffusion:
another noticeable phe-
nomenon is that the conversation usually drifts
from one entity to another. In Table 1, utterances
in item 3 and 4 are about entity “Titanic”, how-
ever, the entity of responses are other similar ﬁlms.
Such entity diffusion relations are rarely captured
by the current knowledge triplets. The response
in item 3 shows that the two entities “Titanic” and
“Waterloo Bridge” are relevant through “love sto-
ries”. Item 4 suggests another similar shipwreck
ﬁlm of “Titanic”.

To deal with the aforementioned challenges,
in this paper, we propose a neural knowledge
diffusion (NKD) dialogue system to beneﬁt the
neural dialogue generation with the ability of both
convergent and divergent thinking over the knowl-
edge base, and handle factoid QA and knowledge
grounded chit-chats simultaneously. NKD learns
to match utterances to relevant facts; the matched
facts are then diffused to similar entities; and ﬁ-
nally, the model generates the responses with re-
spect to all the retrieved knowledge items.

In general, our contributions are as follows:

• We identify the problem of incorporating
knowledge bases and dialogue systems as
facts matching and entity diffusion.

Figure 1: Neural Knowledge Diffusion Dialogue
System.

the

input

Given

utterance X

=
(x1, x2, ..., xNX ), NKD produces a response
Y = (y1, y2, ..., yNY ) containing the entities from
the knowledge base K. NX and NY are the
number of tokens in the utterance and response re-
spectively. The knowledge base K is a collection
of knowledge facts in the form of triplets (subject,
relation, object). In particular, both subjects and
objects are entities in this work. As illustrated
in Figure 1, the model mainly consists of four
components:

1. An encoder encodes the input utterance X

into a vector representation.

2. A context RNN keeps the dialogue state
along a conversation session. It takes the ut-
terance representation as input, and outputs a
vector guiding the response generation each
turn.

3. A decoder generates the ﬁnal response Y .

4. A knowledge retriever performs the facts
matching and diffuses to similar entities at
each turn.

recurrent
Our work is built on hierarchical
encoder-decoder architecture (Sordoni et al.,
2015a), and a knowledge retriever network inte-
grates the structured knowledge base into the dia-
logue system.

2.1 Encoder

1 , hC

2 , ..., hC
NX

The encoder transforms discrete tokens into vec-
tor representations. To capture information at dif-
ferent aspects, we learn utterance representations
with two independent RNNs resulting with two
hidden state sequences H C = (hC
)
and H K = (hK
2 , ..., hK
1 , hK
) respectively. One
NX
ﬁnal hidden state hC
is used as the input of con-
NX
text RNN to track the dialogue state. The other
ﬁnal hidden state hK
is utilized in knowledge
NX
retriever and is designed to encode the knowl-
edge entities and relations within the input utter-
ances. For instance, in Figure 1, “director” and
“Titanic” in X1 are knowledge elements.

2.2 Knowledge Retriever

Knowledge retriever extracts a certain number of
facts from knowledge base and speciﬁes their im-
portance. It enables the knowledge grounded neu-
ral dialogue system with convergent and divergent
thinking ability through facts matching and entity
diffusion. Figure 2 illustrates the process.

2.2.1 Facts Matching
Given the input utterance X and hK
, relevant
NX
facts are extracted from both the knowledge base
and the dialogue history. A predeﬁned number
of relevant facts F = {f1, f2, ..., fNf } are ob-
tained through string matching, entity linking or
named entity recognition. As shown in Figure
2, in the ﬁrst sentence, “Titanic” is recognized
as an entity, all the relevant knowledge triplets
are extracted. Then, these entities and knowledge
triplets are transformed into fact representations

hf = {hf 1, hf 2, ...hf Nf
} by averaging the en-
tity embedding and relation embedding. The rele-
vance coefﬁcient rf between a fact and the input
utterances, ranging from 0 to 1, is calculated by a
nonlinear function or a sub neural network. Here,
we apply a multi-layer perceptron (MLP):

rf
k = M LP ([hK
NX

, hf k]).

For the multi-turn conversation, entities in pre-
vious utterances are also inherited and reserved
as depicted in Figure 2 the dotted lines. For in-
stance, in the second sentence of Figure 2 (right
one), no new fact is extracted from the input utter-
ance. Thus it is necessary to record the history en-
tities “Titanic” and “James Cameron”. We sum-
marize the facts as relevant fact representation Cf
through a weighted average of fact representations
hf :

Cf =

k hf k

(cid:80)Nf

k=1 rf
(cid:80)Nf

k=1 rf

k

.

2.2.2 Entity Diffusion
To retrieve other relevant entities, which are typ-
ically not mentioned in the dialogue utterance,
we diffuse the matched facts. We calculate the
similarity between the entities (except the enti-
ties that have occurred in previous utterances) in
the knowledge base and the relevant fact represen-
tation through a multi-layer perceptron, resulting
with a similarity coefﬁcient re, ranging from 0 to
1:

k = M LP ([hK
re
NX

, Cf , ek]),

where ek is the entity embedding. The top Ne
number of entities E = {e1, e2, ..., eNe} are se-
lected as similar entities. Then, the similar entity
representation Cs is formalized as:

Cs =

(cid:80)Ne

k=1 re
kek
(cid:80)Ne
k=1 re
k

.

Back to the example in Figure 2, in the ﬁrst
turn,
the matched fact of the input utterance
(T itanic, direct by, JamesCameron) is of a
high relevance coefﬁcient in “facts matching” as
expected. When a fact getting matched, intuitively
it is not necessary for entity diffusion.
In such
case, from the Figure 2, we observe that the en-
tities in “entity diffusing” are of low similarities.
In the second turn, there is no triplets matched to
the utterance, while the entity “Titanic” achieves
a much higher relevance score. Then in “entity

Figure 2: Knowledge Retriever. Facts related to input utterance are extracted by facts matching. Similar
entities are then ﬁgured out by entity diffusion. The dotted lines show the inheritance of previous facts.

diffusion”, the similar entities “Waterloo Bridge”
and “Poseidon” get relatively higher similarity
weights than in the ﬁrst turn.

2.3 Context RNN

Context RNN records the utterance level dialogue
state. It takes in the utterance representation and
the knowledge representations. The hidden state
of the context RNN is updated as:

t = RN N (hC
hT

t , [Cf , Cs], hT

t−1).

is then conveyed to the decoder to guide the

hT
t
response generation.

2.4 Decoder

The decoder generates the response sequentially
t , Cf
through a word generator conditioned on hT
and Cs. Let C denotes the concatenation of hT
t ,
Cf and Cs. Knowledge items coefﬁcient R is the
concatenation of relevance coefﬁcient rf and sim-
ilarity coefﬁcient re. We introduce two variants of
word generator:

Vanilla decoder simply generates the response
Y = (y1, y2, ..., yNy ) according to C, R. The

Figure 3: The decoder generates words from both
vocabulary and knowledge base. A score updater
keeps tracking of the knowledge item coefﬁcients
to ensure its coverage during response generation.

probability of Y is deﬁned as

p(y1, .., yNy |C, R; θ)
Ny
(cid:89)

= p(y1|C, R; θ)

t=2

p(yt|y1, .., yt−1, C, R; θ),

where θ denotes the model parameters. The con-
ditional probability of yt is speciﬁed by

p(yt|y1, ..., yt−1, C, R; θ)

= p(yt|yt−1, st, C, R; θ),

where yt is the embedding of the vocabulary or
object entities of retrieved knowledge items, st is
the decoder RNN hidden state .

Probabilistic gated decoder utilizes a gating
variable zt (Yin et al., 2016) to indicate whether
the tth word is generated from common vocabu-
lary or knowledge entities. The probability of gen-
erating the tth word is given by:

p(yt|yt−1, st, C, R; θ)

=p(zt = 0|st; θ)p(yt|yt−1, st, C, R, zt = 0; θ)
+p(zt = 1|st; θ)p(yt|R, zt = 1; θ),

where p(zt|st; θ) is computed by a logistic regres-
sion, p(yt|R, zt = 1; θ) is approximated with the
knowledge items coefﬁcient R, and θ is the model
parameter.

During response generation,

if an entity is
overused, the response diversity will be reduced.
Therefore, once a knowledge item occurred in
the response, the corresponding coefﬁcient should
be reduced in case that an item occurs multiple
times. To keep tracking the coverage of knowl-
edge items, we update the knowledge items coef-
ﬁcient R at each time step. We also explore two
coverage tracking mechanisms: 1) Mask coefﬁ-
cient tracker directly reduces the coefﬁcient of the
chosen knowledge item to 0 to ensure it can never
be selected as the response word again. 2) Coefﬁ-
cient attenuation tracker calculates an attenuation
score it based on st, R0, Rt−1 and yt−1:

it = DN N (st, yt−1, R0, Rt−1),

and then update the coefﬁcient as:

Rt = it · Rt−1,

where it ranges from 0 to 1 to gradually decrease
the coefﬁcient.

2.5 Training

The model parameters include the embedding of
vocabulary, entities, relations, and all the model
components. The model is differential and can
be optimized in an end-to-end manner using back-
propagation. Given the training data

where Nd is the max turns of a dialogue, F de-
notes the set of relevant knowledge and E denotes
the set of similar knowledge in response, the ob-
jective function is to minimize the negative log-
likelihood:

(cid:96)(D, θ) = −

log p(Yi|Xi, Fi, Ei)

(cid:88)

ND(cid:88)

i=1

3 Experiment

3.1 Dataset

Most existing knowledge related datasets are
mainly focused on single-turn factoid question
answering (Yin et al., 2016; He et al., 2017b).
We here collect a multi-turn conversation cor-
pus grounded on the knowledge base, which in-
cludes not only facts related inquiries but also
knowledge-based chit-chats. The data is publicly
available online1.

We ﬁrst obtain the element information of each
movie,
including the movie’s title, publication
time, directors, actors and other attributes from
https://movie.douban.com/, a popular Chinese
social network for movies. Then, entities and re-
lations are extracted as triplets to build the knowl-
edge base K.

To collect the question-answering dialogues,
we crawled the corpus from a question-answering
forum https://zhidao.baidu.com/.
To
gather the knowledge related chit-chat corpus,
we mined the dataset from the social forum
https://www.douban.com/group/. Users post
their comments, feedbacks, and impressions of
ﬁlms and televisions on it.

The conversations are grounded on the knowl-
edge using NER, string match, and artiﬁcial scor-
ing and ﬁltering rules. The statistical informa-
tion of the dataset is shown in Table 2. We ob-
served that the conversations follow the long tail
distribution, where famous ﬁlms and televisions
are discussed repeatedly and the low rating ones
are rarely mentioned.

3.2 Experiment Detail

The total 32977 conversations consisting of
104567 utterances are divided into training
(32177) and testing set (800). Bi-directional
LSTM (Schuster and Paliwal, 1997) is used for
encoder, and the dimension of the LSTM hidden

D = {(X Nd

1 , Y Nd

1

, F Nd
1

, ENd

1 )}

diffusion

1https://github.com/liushuman/neural-knowledge-

Knowledge base
#relations
4

#entities
152568

#triplets
766854

Community QA Multi-round dialogue
#sentences
88325

#dialogues
24856

#QA pairs
8121

Table 2: Statistics of knowledge base and conversations.

layer is set to 512. For the context RNN, the di-
mension of the LSTM unit is set to 1024. The
dimension of word embedding shared by the vo-
cabulary, entities and relations is also set to 512
empirically. We use Adam learning (Kingma and
Ba, 2014) to update the gradient and clip the gra-
dient in 5.0. It takes 140 to 150 epochs to train the
model with a batch size of 80.

3.3 Baselines

We compare our neural knowledge diffusion
model with three state-of-the-art baselines:

• Seq2Seq: a sequence to sequence model with
vanilla RNN encoder-decoder (Shang et al.,
2015; Vinyals and Le, 2015).

• HRED: a hierarchical recurrent encoder-

decoder model.

• GenDS: a neural generative dialogue system
that is capable of generating responses based
on input message and related knowledge base
(KB) (Zhu et al., 2017) .

Three variants of the neural diffusion dialogue
generation model are implemented to verify dif-
ferent conﬁgurations of decoders.

• NKD-ori is the original model with a vanilla

decoder and a mask coefﬁcient tracker.

• NKD-gated is augmented with a probabilis-
tic gated decoder and a mask coefﬁcient
tracker.

• NKD-atte utilizes a vanilla decoder and the

coefﬁcient attenuation tracker.

3.4 Evaluation Metric

Both automatic and human evaluation metrics are
used to analyze the model’s performance. To val-
idate the effectiveness of facts matching and dif-
fusion, we calculate entity accuracy and recall
on factoid QA data set as well as the whole data
set. Human evaluation rates the model in three
aspects: ﬂuency, knowledge relevance and cor-
rectness of the response. All these metrics range
from 0 to 3, where 0 represents complete error, 1

model
LSTM
HRED
GenDS
NKD-ori
NKD-gated
NKD-atte

accuracy(%)
7.8
3.7
70.3
67.0
77.6
55.1

recall(%)
7.5
3.9
63.1
56.2
77.3
46.6

Table 3: Evaluation results on factoid question
answering dialogues.

model
LSTM
HRED
GenDS
NKD-ori
NKD-gated
NKD-atte

accuracy(%)
2.6
1.4
20.9
22.9
24.8
18.4

recall(%)
2.5
1.5
17.4
19.7
25.6
16.0

entity number
1.65
1.79
1.34
2.55
1.59
3.41

Table 4: Evaluation results on entire dataset.

for partially correct, 2 for almost correct, 3 for ab-
solutely correct.

3.5 Experiment Result

Table 3 displays the accuracy and recall of entities
on factoid question answering dialogues. The per-
formance of NKD is slightly better than the spe-
ciﬁc QA solution GenDS, while LSTM and HRED
which are designed for chi-chat almost fail in this
task. All the variants of NKD models are capa-
ble of generating entities with an accuracy of 60%
to 70%, and NKD-gated achieves the best perfor-
mance with an accuracy of 77.6% and a recall of
77.3%.

Table 4 lists the accuracy and recall of entities
on the entire dataset including both the factoid QA
and knowledge grounded chit-chats. Not surpris-
ingly, both NKD-ori and NKD-gated outperform
GenDS on the entire dataset, and the relative im-
provement over GenDS is even higher than the im-
provement in QA dialogues. It conﬁrms that al-
though NKD and GenDS are comparable in an-
swering factoid questions, NKD is better at in-
troducing the knowledge entities for knowledge
grounded chit-chats.

All the NKD variants in Table 4 generate more
entities than GenDS. LSTM and HRED also pro-
duce a certain amount of entities, but are of low

Fluency Appropriateness

model

LSTM
HRED
GenDS
NKD-ori
NKD-gated
NKD-atte

2.52
2.48
2.76
2.42
2.08
2.7

of knowledge
0.88
0.36
1.36
1.92
1.72
1.54

Entire
Correctness
0.8
0.32
1.34
1.58
1.44
1.38

Table 5: Human evaluation result.

accuracies and recalls. We also noticed that NKD-
gated achieves the highest accuracy and recall,
but generates fewer entities compared with NKD-
ori and NKD-gated, whereas NKD-atte generates
more entities but also with relatively low accu-
racies and recalls.This demonstrates that NKD-
gated not only learns to generate more entities but
also maintains the quality ( with a relatively high
accuracy and recall ).

The results of human evaluation in Table 5 also
validate the superiority of the proposed model, es-
pecially on appropriateness. Responses generated
by LSTM and HRED are of high ﬂuency, but are
simply repetitions, or even dull responses as “I
don’t know.”, “Good.”. NKD-gated is more adept
at incorporating the knowledge base with respect
to appropriateness and correctness, while NKD-
atte generates more ﬂuent responses. NKD-ori
is a compromise, and obtains the best correctness
in completing an entire dialogue. Four evaluators
rated the scores independently. The pairwise Co-
hen’s Kappa agreement scores are 0.67 on ﬂuency,
0.54 on appropriateness, and 0.60 on entire cor-
rectness, which indicate a strong annotator agree-
ment.

To our surprise, one of the variant model of
NKD, which utilized both probabilistic gated de-
coder and coefﬁcient attenuation tracker does not
perform well on entire dataset. The accuracy of
the model is quite high, but the recall is very
low compared to others. We speculate that this
is due to the method of minimizing negative
log-likelihood during the training process, which
makes the model tend to generate completely cor-
rect answers, and therefore reduces the number of
generated entities.

3.6 Case Study

Table 6 shows typical examples of the generated
responses. Both Item 1 and 2 are based on facts
relevant utterances. NKD handles these questions
by facts matching. Item 3 asks for a recommen-

dation. NKD obtains similar entities by diffus-
ing the entities. For item 4, 5 and 6, no explicit
entity appears in the utterances. NKD is able to
output appropriate recommendations through en-
tity diffusion. The entities are recorded during
the whole dialogue session, so NKD keeps recom-
mending for several turns. Item 7 fails to gener-
ate an appropriate response because the entity in
the golden response does not appear in the train-
ing set, which suggests the future work for out-of-
vocabulary cases.

4 Related Work

The successes of sequence-to-sequence architec-
ture (Cho et al., 2014; Sutskever et al., 2014) mo-
tivated investigation in dialogue systems that can
effectively learn to generate a response sequence
given the previous utterance sequence (Shang
et al., 2015; Sordoni et al., 2015b; Vinyals and Le,
2015). The model is trained to minimize the nega-
tive log-likelihood of the training data. Despite the
current progress, the lack of response diversity is
a notorious problem, where the model inherently
tends to generate short, general responses in spite
of different inputs. Li et al. (2016a); Serban et al.
(2017); Cao and Clark (2017) suggested that the-
ses boring responses are common in training data
and shorter responses are more likely to be given
a higher likelihood. To tackle the problem, Li
et al. (2016a) introduced a maximum mutual in-
formation training objective. Serban et al. (2017),
Cao and Clark (2017) and Chen et al. (2018) used
latent variables to introduce stochasticity to en-
hance the response diversity. Vijayakumar et al.
(2016),Shao et al. (2017) and Li et al. (2016b)
recognized that the greedy search decoding pro-
cess, especially beam-search with a wide beam
size, leads the short responses possess higher like-
lihoods. They reserved more diverse candidates
during beam-search decoding.
In this paper, we
present that the absence of background knowledge
and common sense is another source of lacking di-
versity. We augment the knowledge base to end-
to-end dialogue generation.

Another research line comes from the utiliz-
ing of knowledge bases. A typical application is
question-answering (QA) systems. The end-to-
end QA also resort to the encoder-decoder frame-
work (Yin et al., 2016; He et al., 2017a). Yin et al.
(2016) enquired the knowledge-base to achieve
one fact and answer the simple factoid questions

1

2

3

4

5

6

7

ID Utterance

X1:Duckweed, casts

乘风破浪，演员表

X1: Just spend the whole night watching the movie
Silenced, a little depressed now

刚看完熔炉... 连夜看完的，略低落

X1:Which movie most representative of youth? I’d like
In the Heat of the Sun, Flipped, First Love(Sing Street)
你觉得最能代表青春的电影有哪些呢 我觉得有
阳光灿烂的日子，怦然心动，初恋这件小事（唱街）
X1:Can anyone recommend me some touching movie,
tears streaming after watching

谁能给我推荐两部感人的电影，直接点的，看了

可以流两缸眼泪那种
X1:burn brain or suspense movies please, recommend me
some burn brain or suspense or horror ﬁlms please! sus-
pense ﬁlms which are less popular are ok!!!

求推荐烧脑的推理悬疑电影 求各位大神推荐烧脑

的悬疑恐怖电影 冷门的推理剧也爱！！！

X2:I’ve seen it, it’s nice

看过哦不错呢

Response
Y1:Hongda Guan Jiufeng Shi Qi Wang Zhi Cheng

关宏达 史久峰 汪漪 程之

NKD:Hongda Guan Jiufeng Shi Qi Wang Zhi Cheng

关宏达 史久峰 汪漪 程之
Y1:I saw it last night and had a hard time

昨晚看了，心里好难过

NKD:The ﬁlm has an atmosphere make us rethink sth

气氛有，会反思一些事

Y1:Kids Return

坏孩子的天空

NKD:《Love Letter》《Once》
《情书》《曾经》

Y1:Gift From Room 7 Hearty Paws Memories of Matsuko

7号房的礼物 人狗奇缘 被嫌弃的松子的一生

NKD:Wedding Dress, these ones,,,

婚纱，这些，，，

Y1:《The Skeleton Key》《Identity》

《万能钥匙》《致命id》

NKD:Identity
致命id
Y1:《Orphan》？
《孤儿怨》？

NKD: Also Inception Whisper of the Heart
Whisper of the Heart

还有 盗梦空间 侧耳倾听 侧耳倾听

死亡录像，山村老尸，死寂，1408，

NKD:Recommend a few I’ve seen, 《A Wicked Ghost》,
《hide and seek》

推荐几部我看过《山村老尸》、《捉迷藏》

Y1:The Others, hardly call to mind

小岛惊魂，冷不丁还真想不起来

NKD: Identity, Fight Club, Interstellar, Snowpiercer
致命id、搏击俱乐部、星际穿越、雪国列车

X1:It’s a bit boring recently. Any good horror movies,
guys? I’ve watched a lot.

Y1:Rec,
1408 phontom horror,

A Wicked Ghost,

Dead Silence,

最近有点无聊，各位豆友有什么好看的恐怖片推

荐啊？看了好多了。

X2:I’ve seen it all, anything else?

卤煮都看过了。还有推荐？

X3:Have seen it before, really great

看过，真的很不错的说

X1:any awesome animation like Song of the Sea, please

Y1::The Girl Without Hands

求一些画风超赞的动画 类似于海洋之歌这种的，

谢谢

Y3:《The Revenant》, nice movie

《亡灵》，非常好看

NKD:So what type do you like?
那你喜欢什么类型的？

无手的少女

NKD:strongly recommended

强烈推荐

Table 6: Examples of the generated response. Entities are underlined and Yi denotes the gold response.

by referring to the fact. He et al. (2017a) ex-
tended this approach by augmenting the copying
mechanism and enabled the output words to copy
from the original input sequence. Eric et al. (2017)
noticed that neural task-oriented dialogue systems
often struggle to smoothly interface with a knowl-
edge base and they addressed the problem by aug-
menting the end-to-end structure with a key-value
retrieval mechanism where a separate attention is
performed over the key of each entry in the KB.
Ghazvininejad et al. (2017) represented the un-
structured text as bag of words representation and

also performed soft attention over the facts to re-
trieve a facts vector. Zhu et al. (2017) generated
responses with any number of answer entities in
the structured KB, even when these entities never
appear in the training set. Dhingra et al. (2017)
proposed a multi-turn dialogue agent which helps
users search knowledge base by soft KB lookup.
In our model, we perform not only facts matching
to answer factoid inquiries, but also entity diffu-
sion to infer similar entities. Given previous utter-
ances, we retrieve the relevant facts, diffuse them,
and generate responses based on diversiﬁed rele-

vant knowledge items.

5 Conclusion

In this paper, we identify the knowledge diffusion
in conversations and propose an end-to-end neu-
ral knowledge diffusion model to deal with the
problem. The model integrates the dialogue sys-
tem with the knowledge base through both facts
matching and entity diffusion, which enable the
convergent and divergent thinking over the knowl-
edge base. Under such mechanism, the factoid
question answering and knowledge grounded chit-
chats can be tackled together. Empirical results
show the proposed model is able to generate more
meaningful and diverse responses, compared with
In future work,
the state-of-the-art baselines.
we plan to introduce reinforcement learning and
knowledge base reasoning mechanisms to improve
the performance.

Acknowledgements

This work is supported by the National Natu-
ral Science Foundation of China (No.61662077,
No.61472428). We also would like to thank all the
reviewers for their insightful and valuable com-
ments and suggestions.

References

Kris Cao and Stephen Clark. 2017. Latent variable di-
alogue models and their diversity. In Proceedings of
the 15th Conference of the European Chapter of the
Association for Computational Linguistics: Volume
2, Short Papers, pages 182–187, Valencia, Spain.
Association for Computational Linguistics.

Hongshen Chen, Zhaochun Ren, Jiliang Tang, Yi-
hong Eric Zhao, and Dawei Yin. 2018. Hierarchi-
cal variational memory network for dialogue gener-
ation. In Proceedings of the 2018 World Wide Web
Conference on World Wide Web, pages 1653–1662.
International World Wide Web Conferences Steering
Committee.

Kyunghyun Cho, Bart van Merrienboer, Caglar Gul-
cehre, Dzmitry Bahdanau, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. 2014.
Learning
phrase representations using rnn encoder–decoder
for statistical machine translation. In Proceedings of
the 2014 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP), pages 1724–
1734, Doha, Qatar. Association for Computational
Linguistics.

Bhuwan Dhingra, Lihong Li, Xiujun Li, Jianfeng Gao,
Yun-Nung Chen, Faisal Ahmed, and Li Deng. 2017.

Towards end-to-end reinforcement learning of dia-
logue agents for information access. In Proceedings
of the 55th Annual Meeting of the Association for
Computational Linguistics.

Mihail Eric, Lakshmi Krishnan, Francois Charette, and
Christopher D. Manning. 2017. Key-value retrieval
networks for task-oriented dialogue. In Proceedings
of the 18th Annual SIGdial Meeting on Discourse
and Dialogue, pages 37–49. Association for Com-
putational Linguistics.

Marjan Ghazvininejad, Chris Brockett, Ming-Wei
Chang, Bill Dolan, Jianfeng Gao, Wen-tau Yih,
and Michel Galley. 2017. A knowledge-grounded
arXiv preprint
neural conversation model.
arXiv:1702.01932.

Google. 2013. Freebase data dumps.

Shizhu He, Cao Liu, Kang Liu, Jun Zhao, Shizhu He,
Cao Liu, Kang Liu, and Jun Zhao. 2017a. Generat-
ing natural answers by incorporating copying and re-
trieving mechanisms in sequence-to-sequence learn-
In Meeting of the Association for Computa-
ing.
tional Linguistics, pages 199–208.

Wei He, Kai Liu, Yajuan Lyu, Shiqi Zhao, Xinyan
Xiao, Yuan Liu, Yizhong Wang, Hua Wu, Qiaoqiao
She, Xuan Liu, Tian Wu, and Haifeng Wang. 2017b.
Dureader: a chinese machine reading comprehen-
arXiv
sion dataset from real-world applications.
eprint arXiv:1711.05073.

Diederik P. Kingma and Jimmy Ba. 2014. Adam:
CoRR,

A method for stochastic optimization.
abs/1412.6980.

Jens Lehmann, Robert

Isele, Max Jakob, Anja
Jentzsch, Dimitris Kontokostas, Pablo N. Mendes,
Sebastian Hellmann, Mohamed Morsey, Patrick van
Kleef, S¨oren Auer, and Christian Bizer. 2017. Db-
pedia – a large-scale, multilingual knowledge base
extracted from wikipedia.

Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao,
and Bill Dolan. 2016a. A diversity-promoting ob-
jective function for neural conversation models. In
Proceedings of the 2016 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 110–119, San Diego, California. Association
for Computational Linguistics.

Jiwei Li, Will Monroe, and Jurafsky Dan. 2016b. A
simple, fast diverse decoding algorithm for neural
generation. arXiv preprint arXiv:1611.08562.

M. Schuster and K. K. Paliwal. 1997. Bidirectional re-
current neural networks. IEEE Transactions on Sig-
nal Processing, 45(11):2673–2681.

Iulian Serban, Alessandro Sordoni, Ryan Lowe, Lau-
rent Charlin, Joelle Pineau, Aaron Courville, and
Yoshua Bengio. 2017. A hierarchical latent variable
encoder-decoder model for generating dialogues. In
AAAI Conference on Artiﬁcial Intelligence.

Lifeng Shang, Zhengdong Lu, and Hang Li. 2015.
Neural responding machine for short-text conver-
In Proceedings of the 53rd Annual Meet-
sation.
ing of the Association for Computational Linguistics
and the 7th International Joint Conference on Natu-
ral Language Processing (Volume 1: Long Papers),
pages 1577–1586, Beijing, China. Association for
Computational Linguistics.

Louis Shao, Stephan Gouws, Denny Britz, Anna
Goldie, and Brian Strope. 2017. Generating long
and diverse responses with neural conversation mod-
els. arXiv preprint arXiv:1701.03185.

Alessandro Sordoni, Yoshua Bengio, Hossein Vahabi,
Christina Lioma, Jakob Grue Simonsen, and Jian-
Yun Nie. 2015a. A hierarchical recurrent encoder-
decoder for generative context-aware query sugges-
tion. In Proceedings of the 24th ACM International
on Conference on Information and Knowledge Man-
agement, pages 553–562. ACM.

Alessandro Sordoni, Michel Galley, Michael Auli,
Chris Brockett, Yangfeng Ji, Margaret Mitchell,
Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. 2015b.
A neural network approach to context-sensitive gen-
In Proceed-
eration of conversational responses.
ings of the 2015 Conference of the North Ameri-
can Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
196–205, Denver, Colorado. Association for Com-
putational Linguistics.

Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.
Sequence to sequence learning with neural net-
works. In Advances in neural information process-
ing systems, pages 3104–3112.

Ashwin K Vijayakumar, Michael Cogswell, Ram-
prasath R Selvaraju, Qing Sun, Stefan Lee, David
Crandall, and Dhruv Batra. 2016. Diverse beam
search: Decoding diverse solutions from neural se-
quence models. arXiv preprint arXiv:1610.02424.

Oriol Vinyals and Quoc Le. 2015. A neural conversa-
tional model. arXiv preprint arXiv:1506.05869.

Jun Yin, Xin Jiang, Zhengdong Lu, Lifeng Shang,
Hang Li, and Xiaoming Li. 2016. Neural generative
question answering. In International Joint Confer-
ence on Artiﬁcial Intelligence, pages 2972–2978.

Wenya Zhu, Kaixiang Mo, Yu Zhang, Zhangbin Zhu,
Xuezheng Peng, and Qiang Yang. 2017. Flexible
end-to-end dialogue system for knowledge grounded
conversation. arXiv eprint arXiv:1709.04264.

