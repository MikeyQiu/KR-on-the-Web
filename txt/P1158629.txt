9
1
0
2
 
n
a
J
 
2
1
 
 
]

G
L
.
s
c
[
 
 
3
v
5
4
1
0
0
.
1
1
8
1
:
v
i
X
r
a

Scalable End-to-End Autonomous Vehicle Testing
via Rare-event Simulation

Matthew O’Kelly*1 Aman Sinha∗

2 Hongseok Namkoong∗

2

John Duchi2 Russ Tedrake3
1University of Pennsylvania
2Stanford University
3Massachusetts Institute of Technology

mokelly@seas.upenn.edu

amans,hnamk,jduchi
{

@stanford.edu russt@mit.edu
}

Abstract

While recent developments in autonomous vehicle (AV) technology highlight substantial
progress, we lack tools for rigorous and scalable testing. Real-world testing, the de facto eval-
uation environment, places the public in danger, and, due to the rare nature of accidents, will
require billions of miles in order to statistically validate performance claims. We implement a
simulation framework that can test an entire modern autonomous driving system, including, in
particular, systems that employ deep-learning perception and control algorithms. Using adap-
tive importance-sampling methods to accelerate rare-event probability evaluation, we estimate
the probability of an accident under a base distribution governing standard traﬃc behavior.
We demonstrate our framework on a highway scenario, accelerating system evaluation by 2-20
times over naive Monte Carlo sampling methods and 10-300P times (where P is the number of
processors) over real-world testing.

1

Introduction

Recent breakthroughs in deep learning have accelerated the development of autonomous vehi-
cles (AVs); many research prototypes now operate on real roads alongside human drivers. While
advances in computer-vision techniques have made human-level performance possible on narrow
perception tasks such as object recognition, several fatal accidents involving AVs underscore the
importance of testing whether the perception and control pipeline—when considered as a whole sys-
tem—can safely interact with humans. Unfortunately, testing AVs in real environments, the most
straightforward validation framework for system-level input-output behavior, requires prohibitive
amounts of time due to the rare nature of serious accidents [49]. Concretely, a recent study [29]
argues that AVs need to drive “hundreds of millions of miles and, under some scenarios, hundreds
of billions of miles to create enough data to clearly demonstrate their safety.” Alteratively, formally
verifying an AV algorithm’s “correctness” [34, 2, 47, 37] is diﬃcult since all driving policies are sub-
ject to crashes caused by other drivers [49]. It is unreasonable to ask that the policy be safe under
all scenarios. Unfortunately, ruling out scenarios where the AV should not be blamed is a task
subject to logical inconsistency, combinatorial growth in speciﬁcation complexity, and subjective
assignment of fault.

Motivated by the challenges underlying real-world testing and formal veriﬁcation, we consider
a probabilistic paradigm—which we call a risk-based framework —where the goal is to evaluate
the probability of an accident under a base distribution representing standard traﬃc behavior. By

*Equal contribution

1

assigning learned probability values to environmental states and agent behaviors, our risk-based
framework considers performance of the AV’s policy under a data-driven model of the world. To
eﬃciently evaluate the probability of an accident, we implement a photo-realistic and physics-based
simulator that provides the AV with perceptual inputs (e.g. video and range data) and traﬃc
conditions (e.g. other cars and pedestrians). The simulator allows parallelized, faster-than-real-
time evaluations in varying environments (e.g. weather, geographic locations, and aggressiveness of
other cars).

∼

Formally, we let P0 denote the base distribution that models standard traﬃc behavior and
P0 be a realization of the simulation (e.g. weather conditions and driving policies of other
R that measures “safety”—so that low values of f (x)

X
agents). For an objective function f :
correspond to dangerous scenarios—our goal is to evaluate the probability of a dangerous event
pγ := P0(f (X)

X →

(1)

γ)

≤

for some threshold γ. Our risk-based framework is agnostic to the complexity of the ego-policy
and views it as a black-box module. Such an approach allows, in particular, deep-learning based
perception systems that make formal veriﬁcation methods intractable.

An essential component of this approach is to estimate the base distribution P0 from data;
we use public traﬃc data collected by the US Department of Transportation [36]. While such
datasets do not oﬀer insights into how AVs interact with human agents—this is precisely why we
design our simulator—they illustrate the range of standard human driving behavior that the base
distribution P0 must model. We use imitation learning [45, 41, 42, 22, 6] to learn a generative
model for the behavior (policy) of environment vehicles; unlike traditional imitation learning, we
train an ensemble of models to characterize a distribution of human-like driving policies.

As serious accidents are rare (pγ is small), we view this as a rare-event simulation [4] problem;
naive Monte Carlo sampling methods require prohibitively many simulation rollouts to generate
dangerous scenarios and estimate pγ. To accelerate safety evaluation, we use adaptive importance-
sampling methods to learn alternative distributions Pθ that generate accidents more frequently.
Speciﬁcally, we use the cross-entropy algorithm [44] to iteratively approximate the optimal impor-
tance sampling distribution. In contrast to simple classical settings [44, 55] which allow analytic
updates to Pθ, our high-dimensional search space requires solving convex optimization problems
in each iteration (Section 2). To address numerical instabilities of importance sampling estima-
tors in high dimensions, we carefully design search spaces and perform computations in logarithmic
scale. Our implementation produces 2-20 times as many rare events as naive Monte Carlo methods,
independent of the complexity of the ego-policy.

In addition to accelerating evaluation of pγ, learning a distribution Pθ that frequently generates
realistic dangerous scenarios Xi
Pθ is useful for engineering purposes. The importance-sampling
distribution Pθ not only eﬃciently samples dangerous scenarios, but also ranks them according to
their likelihoods under the base distribution P0. This capability enables a deeper understanding of
failure modes and prioritizes their importance to improving the ego-policy.

∼

As a system, our simulator allows fully distributed rollouts, making our approach orders of
magnitude cheaper, faster, and safer than real-world testing. Using the asynchronous messaging
library ZeroMQ [21], our implementation is fully-distributed among available CPUs and GPUs; our
rollouts are up to 30P times faster than real time, where P is the number of processors. Combined
with the cross-entropy method’s speedup, we achieve 10-300P speedup over real-world testing.

In what follows, we describe components of our open-source toolchain, a photo-realistic simula-
tor equipped with our data-driven risk-based framework and cross-entropy search techniques. The

2

Figure 1. Multi-lane highway driving on I-80: (left) real image, (right) rendered image from simu-
lator

toolchain can test an AV as a whole system, simulating the driving policy of the ego-vehicle by
viewing it as a black-box model. The use of adaptive-importance sampling methods motivates a
unique simulator architecture (Section 3) which allows real-time updates of the policies of environ-
ment vehicles. In Section 4, we test our toolchain by considering an end-to-end deep-learning-based
ego-policy [9] in a multi-agent highway scenario. Figure 1 shows one conﬁguration of this scenario
in the real world along with rendered images from the simulator, which uses Unreal Engine 4 [17].
Our experiments show that we accelerate the assessment of rare-event probabilities with respect to
naive Monte Carlo methods as well as real-world testing. We believe our open-source framework is
a step towards a rigorous yet scalable platform for evaluating AV systems, with the broader goal
of understanding how to reliably deploy deep-learning systems in safety-critical applications.

2 Rare-event simulation

To motivate our risk-based framework, we ﬁrst argue that formally verifying correctness of a AV
system is infeasible due to the challenge of deﬁning “correctness.” Consider a scenario where an
AV commits a traﬃc violation to avoid collision with an out-of-control truck approaching from
behind. If the ego-vehicle decides to avoid collision by running through a red light with no further
ramiﬁcations, is it “correct” to do so? The “correctness” of the policy depends on the extent to
which the traﬃc violation endangers nearby humans and whether any element of the “correctness”
speciﬁcation explicitly forbids such actions. That is, “correctness” as a binary output is a concept
deﬁned by its exceptions, many elements of which are subject to individual valuations [10].
Instead of trying to verify correctness, we begin with a continuous measure of safety f :

R,
where
is space of traﬃc conditions and behaviors of other vehicles. The prototypical example
in this paper is the minimum time-to-collision (TTC) (see Appendix A for its deﬁnition) to other
environmental agents over a simulation rollout. Rather than requiring safety for all x
, we
relax the deterministic veriﬁcation problem into a probabilistic one where we are concerned with
the probability under standard traﬃc conditions that f (X) goes below a safety threshold. Given a
distribution P0 on
γ) based
on simulated rollouts f (X1), . . . , f (Xn). As accidents are rare and pγ is near 0, we treat this as a
rare-event simulation problem; see [11, 4, Chapter VI] for an overview of this topic.

, our goal is to estimate the rare event probability pγ := P0(f (X)

X →

∈ X

≤

X

X

First, we brieﬂy illustrate the well-known diﬃculty of naive Monte Carlo simulation when pγ is
.
small. From a sample Xi
}
As pγ is small, we use relative accuracy to measure our performance, and the central limit theorem

P0, the naive Monte Carlo estimate is

pN,γ := 1
N

f (Xi)
{

N
i=1 1

iid
∼

≤

γ

b

P

3

(0, 1), Stepsizes

αk
{

k∈N, Sample sizes
}

Nk
{

k∈N, Number of iterations K
}

Algorithm 1 Cross-Entropy Method

1: Input: Quantile ρ
Θ
2: Initialize: θ0 ∈
3: for k = 0, 1, 2, . . . , K

∈

4:

5:

6:

Sample Xk,1, . . . , Xk,Nk
Set γk as the minimum of γ and the ρ-quantile of f (Xk,1), . . . , f (Xk,Nk)
θk+1 = argmaxθ∈Θ

αkθ⊤Dk+1 + (1

αk)θ⊤

A(θk)

A(θ)

Pθk

−

∇

−

(cid:9)

1 do

−

iid
∼

(cid:8)

implies the relative accuracy is approximately

1
(cid:12)
(cid:12)
(cid:12)
For small pγ, we require a sample of size N & 1/(pγ ǫ2) to achieve ǫ-relative accuracy, and if f (X)
(cid:12)
is light-tailed, the sample size must grow exponentially in γ.

(0, 1).

∼ N

+ o(1/√N ) for Z

(cid:12)
(cid:12)
(cid:12)
(cid:12)

Z

|

dist
≈ s

pγ
1
−
N pγ |

pN,γ
pγ −
b

Cross-entropy method As an alternative to a naive Monte Carlo estimator, we consider (adap-
tive) importance sampling [4], and we use a model-based optimization procedure to ﬁnd a good
importance-sampling distribution. The optimal importance-sampling distribution for estimating pγ
has the conditional density p⋆(x) = 1
p0(x)/pγ, where p0 is the density function of P0: as
p0(x)/p⋆(x) = pγ for all x satisfying 1
, the estimate
}
is exact. This sampling scheme is, unfortunately, de facto impossible, because we do not know pγ.
Instead, we use a parameterized importance sampler Pθ and employ an iterative model-based search
method to modify θ so that Pθ approximates P ⋆.

N,γ := 1
p⋆
N

f (x)
f (x)

p0(Xi)
p⋆(Xi) 1

γ
}
γ
}

f (Xi)

≤
≤

N
i=1

{
{

P

≤

b

γ

{

}

{

∈

≤

∝

=

γk

f (x)

argminθ∈Θ Dkl (P ⋆

X
(0, 1)—usually we choose ρ

The cross-entropy method [44] iteratively tries to ﬁnd θ⋆

Pθ), the Kullback-
||
Leibler projection of P ⋆ onto the class of parameterized distributions
θ∈Θ. Over iterations
Pθ
}
P
{
1
k, we maintain a surrogate distribution qk(x)
γ is a (potentially
p0(x) where γk
≥
random) proxy for the rare-event threshold γ, and we use samples from Pθ to update θ as an
. The motivation underlying this approach is to update θ so
approximate projection of Q onto
with low objective value (i.e. unsafe) f (x). We ﬁx a quantile level
that Pθ upweights regions of
ρ
Pθk as γk,
our proxy for the rare event threshold γ (see [23] for alternatives). We have the additional chal-
Pθk .
lenge that the ρ-quantile of f (X) is unknown, so we approximate it using i.i.d. samples Xi
Compared to applications of the cross-entropy method [44, 55] that focus on low-dimensional prob-
lems permitting analytic updates to θ, our high-dimensional search space requires solving convex
optimization problems in each iteration. To address numerical challenges in computing likelihood
ratios in high-dimensions, our implementation carefully constrains the search space and we compute
likelihoods in logarithmic scale.

[0.01, 0.2]—and use the ρ-quantile of f (X) where X

∼

∼

P

∈

∈

We now rigorously describe the algorithmic details. First, we use natural exponential families

as our class of importance samplers

.

P

Deﬁnition 1. The family of density functions
pθ
{
a natural exponential family if there exists a suﬃcient statistic Γ such that pθ(x) = exp(θ⊤Γ(x)
A(θ)) where A(θ) = log

θ∈Θ, deﬁned with respect to base measure µ, is
}

X exp(θ⊤Γ(x))dµ(x) is the log partition function and Θ :=

A(θ) <

θ
{

|

−
.
∞}

R

4

Given this family, we consider idealized updates to the parameter vector θk at iteration k, where
we compute projections of a mixture of Qk and Pθk onto
P
Pθ)
αk)Pθk ||
αkEQk[log pθ(X)] + (1

θ∈Θ
= argmax

Dkl (αkQk + (1

θk+1 = argmin

−

θ∈Θ {

= argmax

θ∈Θ

αkθ⊤EQk [Γ(X)] + (1
n

−

αk)Eθk [log pθ(X)]
}

−
αk)θ⊤

A(θk)

A(θ)

.

∇

−

o

The term EQk [Γ(X)] is unknown in practice, so we use a sampled estimate. For Xk,1, . . . , Xk,Nk
Pθk , let γk be the ρ-quantile of f (Xk,1), . . . , f (Xk,Nk) and deﬁne

Dk+1 :=

1
Nk

Nk

i=1
X

qk(Xk,i)
pθk (Xk,i)

Γ(Xk,i) =

p0(Xk,i)
pθk (Xk,i)

{

1

f (Xk,i)

γk

Γ(Xk,i).

≤

}

1
Nk

Nk

i=1
X

Using the estimate Dk+1 in place of EQk [Γ(X)] in the idealized update (2), we obtain Algorithm 1.
To select the ﬁnal importance sampling distribution from Algorithm 1, we choose θk with the
lowest ρ-quantile of f (Xk,i). We observe that this choice consistently improves performance over
taking the last iterate or Polyak averaging. Letting θce denote the parameters for the importance
pN,γ :=
sampling distribution learned by the cross-entropy method, we sample Xi
1
N

as our ﬁnal importance-sampling estimator for pγ.

Pθce and use

f (Xi)

p0(Xi)
pθce (Xi) 1

N
i=1

iid
∼

γ

In the context of our rare-event simulator, we use a combination of Beta and Normal distri-
P
butions for Pθ. The suﬃcient statistics Γ include (i) the parameters of the generative model of
behaviors that our imitation-learning schemes produce and (ii) the initial poses and velocities of
other vehicles, pedestrians, and obstacles in the simulation. Given a current parameter θ and real-
ization from the model distribution Pθ, our simulator then (i) sets the parameters of the generative
model for vehicle policies and draws policies from this model, and (ii) chooses random poses and
velocities for the simulation. Our simulator is one of the largest-scale applications of cross-entropy
methods.

≤

b

{

}

(2)

iid
∼

(3)

3 Simulation framework

Two key considerations in our risk-based framework inﬂuence design choices for our simulation
toolchain: (1) learning the base distribution P0 of nominal traﬃc behavior via data-driven modeling,
and (2) testing the AV as a whole system. We now describe how our toolchain achieves these goals.

3.1 Data-driven generative modeling

While our risk-based framework (cf. Section 2) is a concise, unambiguous measure of system safety,
the rare-event probability pγ is only meaningful insofar as the base distribution P0 of road conditions
and the behaviors of other (human) drivers is estimable. Thus, to implement our risk-based frame-
work, we ﬁrst learn a base distribution P0 of nominal traﬃc behavior. Using the highway traﬃc
dataset NGSim [36], we train policies of human drivers via imitation learning [45, 41, 42, 22, 6]. Our
data consists of videos of highway traﬃc [36], and our goal is to create models that imitate human
driving behavior even in scenarios distinct from those in the data. We employ an ensemble of gen-
erative adversarial imitation learning (GAIL) [22] models to learn P0. Our approach is motivated

5

by the observation that reducing an imitation-learning problem to supervised learning—where we
simply use expert data to predict actions given vehicle states—suﬀers from poor performance in
regions of the state space not encountered in data [41, 42]. Reinforcement-learning techniques have
been observed to improve generalization performance, as the imitation agent is able to explore
regions of the state space in simulation during training that do not necessarily occur in the expert
data traces.

log(1

Generically, GAIL is a minimax game between two functions: a discriminator Dφ and a genera-
tor Gξ (with parameters φ and ξ respectively). The discriminator takes in a state-action pair (s, u)
and outputs the probability that the pair came from real data, P(real data). The generator takes
in a state s and outputs a conditional distribution Gξ(s) := P(u
s) of the action u to take given
state s. In our context, Gξ(
) is then the (learned) policy of a human driver given environmental
·
inputs s. Training the generator weights ξ occurs in a reinforcement-learning paradigm with re-
ward
Dφ(s, Gξ(s))). We use the model-based variant of GAIL (MGAIL) [6] which renders
this reward fully diﬀerentiable with respect to ξ over a simulation rollout, allowing eﬃcient model
training. GAIL has been validated by Kueﬂer et al. [33] to realistically mimic human-like driving
behavior from the NGSim dataset across multiple metrics. These include the similarity of low-
level actions (speeds, accelerations, turn-rates, jerks, and time-to-collision), as well as higher-level
behaviors (lane change rate, collision rate, hard-brake rate, etc). See Appendix C for a reference
to an example video of the learned model driving in a scenario alongside data traces from human
drivers.

−

−

|

Our importance sampling and cross-entropy methods use not just a single instance of model
parameters ξ, but rather a distribution over them to form a generative model of human driving
behavior. To model this distribution, we use a (multivariate normal) parametric bootstrap over a
Rd, d >
trained ensemble of generators ξi, i = 1, . . . , m. Our models ξi are high-dimensional (ξ
m) as they characterize the weights of large neural networks, so we employ the graphical lasso [15]
to ﬁt the inverse covariance matrix for our ensemble. This approach to modeling uncertainty in
neural-network weights is similar to the bootstrap approach of Osband et al. [38]. Other approaches
include using dropout for inference [16] and variational methods [18, 8, 31].

∈

While several open source driving simulators have been proposed [14, 48, 39], our problem
formulation requires unique features to allow sampling from a continuous distribution of driving
policies for environmental agents. Conditional on each sample of model parameters ξ, the simulator
constructs a (random) rollout of vehicle behaviors according to Gξ. Unlike other existing simulators,
ours is designed to eﬃciently execute and update these policies as new samples ξ are drawn for
each rollout.

3.2 System architecture

The second key characteristic of our framework is that it enables black-box testing the AV as a
whole system. Flaws in complex systems routinely occur at poorly speciﬁed interfaces between
components, as interactions between processes can induce unexpected behavior. Consequently,
solely testing subcomponents of an AV control pipeline separately is insuﬃcient [1]. Moreover, it
is increasingly common for manufacturers to utilize software and hardware artifacts for which they
do not have any whitebox model [19, 12]. We provide a concise but extensible language-agnostic
interface to our benchmark world model so that common AV sensors such as cameras and lidar can
provide the necessary inputs to induce vehicle actuation commands.

Our simulator is a distributed, modular framework, which is necessary to support the inclusion

6

of new AV systems and updates to the environment-vehicle policies. A beneﬁt of this design is
that simulation rollouts are simple to parallelize. In particular, we allow instantiation of multiple
simulations simultaneously, without requiring that each include the entire set of components. For
example, a desktop may support only one instance of Unreal Engine but could be capable of simu-
lating 10 physics simulations in parallel; it would be impossible to fully utilize the compute resource
with a monolithic executable wrapping all engines together. Our architecture enables instances of
the components to be distributed on heterogeneous GPU compute clusters while maintaining the
ability to perform meaningful analysis locally on commodity desktops. In Appendix A, we detail
our scenario speciﬁcation, which describes how Algorithm 1 maps onto our distributed architecture.

4 Experiments

In this section, we demonstrate our risk-based framework on a multi-agent highway scenario. As
the rare-event probability of interest pγ gets smaller, the cross-entropy method learns to sample
more rare events compared to naive Monte Carlo sampling; we empirically observe that the cross-
entropy method produces 2-20 times as many rare events as its naive counterpart. Our ﬁndings
hold across diﬀerent ego-vehicle policies, base distributions P0, and scenarios.

To highlight the modularity of our simulator, we evaluate the rare-event probability pγ on two
diﬀerent ego-vehicle policies. The ﬁrst is an instantiation of an imitation learning (non-vision) policy
which uses lidar as its primary perceptual input. Secondly, we investigate a vision-based controller
(vision policy), where the ego-vehicle drives with an end-to-end highway autopilot network [9], tak-
ing as input a rendered image from the simulator (and lidar observations) and outputting actuation
commands. See Appendix B for a summary of network architectures used.

We consider a scenario consisting of six agents, ﬁve of which are considered part of the environ-
ment. The environment vehicles’ policies follow the distribution learned in Section 3.1. All vehicles
are constrained to start within a set of possible initial conﬁgurations consisting of pose and velocity,
and each vehicle has a goal of reaching the end of the approximately 2 km stretch of road. Fig. 1
shows one such conﬁguration of the scenario, along with rendered images from the simulator. We
create scene geometry based on surveyors’ records and photogrammetric reconstructions of satellite
imagery of the portion of I-80 in Emeryville, California where the traﬃc data was collected [36].

∈

Rm×2
+

Simulation parameters We detail our postulated base distribution P0. Letting m denote the
number of vehicles, we consider the random tuple X = (S, T, W, V, ξ) as our simulation parameter
indicates the two-dimensional positioning of each vehicle in their
where the pair (S, T )
respective lanes (in meters), W the orientation of each vehicle (in degrees), and V the initial
R404 to denote the weights of the
velocity of each vehicle (in meters per second). We use ξ
last layer of the neural network trained to imitate human-like driving behavior. Speciﬁcally, we
set S
0.25
with respect to the lane’s center, W
∼
∼
10Beta(2, 2)+10. We assume ξ
(µ0, Σ0), with the mean and covariance matrices learned via the
ensemble approach outlined in Section 3.1. The neural network whose last layer is parameterized
by ξ describes the policy of environment vehicles; it takes as input the state of the vehicle and lidar
observations of the surrounding environment (see Appendix B for more details). Throughout this
R as the minimum time-to-collision (TTC) over
section, we deﬁne our measure of safety f :
the simulation rollout. We calculate TTC from the center of mass of the ego vehicle; if the ego-

40Beta(2, 2) + 80 with respect to the starting point of the road, T

3.6 with respect to facing forward, and V

0.5Beta(2, 2)

7.2Beta(2, 2)

X →

∼ N

∼

−

∼

−

∈

7

9

8

7

6

5

4

3

2
0.14

101

100

10-1

0.16

0.18

0.2

0.22

0.24

0.26

0.14

0.16

0.18

0.2

0.22

0.24

0.26

(a) Ratio of number of rare events vs. threshold

(b) Ratio of variance vs. threshold

Figure 2. The ratio of (a) number of rare events and (b) variance of estimator for pγ between cross-
entropy method and naive MC sampling for the non-vision ego policy. Rarity is inversely proportional
to γ, and, as expected, we see the best performance for our method over naive MC at small γ.

Search Algorithm

γtest = 0.14
(12.4±3.1)e-6
Cross-entropy 100K (19.8±8.88)e-6

Naive 1300K

Naive 100K

(20±14.1)e-6

γtest = 0.15
(80.6±7.91)e-6
(66.1 ± 15)e-6
(100± 31.6)e-6

γtest = 0.19
(133±3.2)e-5
(108± 9.51)e-5
(132±11.5)e-5

γtest = 0.20
(186±3.79)e-5
(164 ± 14)e-5
(185±13.6)e-5

Table 1. Estimate of rare-event probability pγ (non-vision ego policy) with standard errors. For
the cross-entropy method, we show results for the learned importance sampling distribution with
ρ = 0.01.

vehicle’s body crashes into obstacles, we end the simulation before the TTC can further decrease
(see Appendix A for details).

Cross-entropy method Throughout our experiments, we impose constraints on the space of
importance samplers (adversarial distributions) for feasibility. Numerical stability considerations
predominantly drive our hyperparameter choices. For model parameters ξ, we also constrain the
search space to ensure that generative models Gξ maintain reasonably realistic human-like policies
(recall Sec. 3.1). For S, T, W , and V , we let
be the model space over
which the cross-entropy method searches, scaled and centered appropriately to match the scale
R404
of the respective base distributions. We restrict the search space of distributions over ξ
by searching over
, where (µ0, Σ0) are the parameters of the base
.01
}
(bootstrap) distribution. For our importance sampling distribution Pθ, we use products of the above
marginal distributions. These restrictions on the search space mitigate numerical instabilities in
computing likelihood ratios within our optimization routines, which is important for our high-
dimensional problems.

Beta(α, β) : α, β
{

µ0k∞ ≤

[1.5, 7]
}

(µ, Σ0) :

µ
k

{N

−

∈

∈

We ﬁrst illustrate the dependence of the cross-entropy method on its hyperparameters. We
choose to use a non-vision ego-vehicle policy as a test bed for hyperparameter tuning, since this
allows us to take advantage of the fastest simulation speeds for our experiments. We focus on the
eﬀects (in Algorithm 1) of varying the most inﬂuential hyperparameter, ρ
(0, 1], which is the
quantile level determining the rarity of the observations used to compute the importance sampler

∈

8

X

≤

γ). In order to avoid overﬁtting θk as ρ

θk. Intuitively, as ρ approaches 0, the cross-entropy method learns importance samplers Pθ that
with lower f (x), increasing the frequency of sampling rare events
up-weight unsafe regions of
(events with f (X)
0, we need to increase Nk as ρ
decreases. Our choice of Nk is borne out of computational constraints as it is the biggest factor
that determines the run-time of the cross-entropy method. Consistent with prior works [44, 24], we
[0.01, 0.2] is a good range for the values of Nk deemed feasible for our
observe empirically that ρ
computational budget (Nk = 1000
5000). We ﬁx the number of iterations at K = 100, number
of samples taken per iteration at Nk = 5000, step size for updates at αk = 0.8, and γ = 0.14. As
we see below, we consistently observe that the cross-entropy method learns to sample signiﬁcantly
more rare events, despite the high-dimensional nature (d

500) of the problem.

→

∼

∈

To evaluate the learned parameters, we draw n = 105 samples from the importance sampling
distribution to form an estimate of pγ. In Figure 2, we vary ρ and report the relative performance of
the cross-entropy method compared to naive Monte Carlo sampling. Even though we set γ = 0.14
in Algorithm 1, we evaluate the performance of all models with respect to multiple threshold
levels γtest. We note that as ρ approaches 0, the cross-entropy method learns to frequently sample
increasingly rare events; the cross-entropy method yields 3-10 times as many dangerous scenarios,
and achieves 2-16 times variance reduction depending on the threshold level γtest.
In Table 1,
we contrast the estimates provided by naive Monte Carlo and the importance sampling estimator
provided by the cross-entropy method with ρ = 0.01; to form a baseline estimate, we run naive
106 samples. For a given number of samples, the cross-entropy method with
Monte Carlo with 1.3
10−5 over naive Monte
ρ = 0.01 provides more precise estimates for the rare-event probability pγ
Carlo.

≈

·

≈

We now leverage the tuned hyperparameter (ρ = 0.01) for our main experiment: evaluating the
probability of a dangerous event for the vision-based ego policy. We ﬁnd that the hyperparameters
for the cross-entropy method generalize, allowing us to produce good importance samplers for a
very diﬀerent policy without further tuning. Based on our computational budget (with our current
implementation, vision-based simulations run about 15 times slower than simulations with only
non-vision policies), we choose K = 20 and Nk = 1000 for the cross-entropy method to learn a
good importance sampling distribution for the vision-based policy (although we also observe similar
behavior for Nk as small as 100). In Figure 3, we illustrate again that the cross-entropy method
learns to sample dangerous scenarios more frequently (Figure 3a)—up to 18 times that of naive
Monte Carlo—and produces importance sampling estimators with lower variance (Figure 3b). As a
result, our estimator in Table 2 is better calibrated compared to that computed from naive Monte
Carlo.

Qualitative analysis We provide a qualitative interpretation for the learned parameters of the
importance sampler. For initial velocities, angles, and positioning of vehicles, the importance sam-
pler shifts environmental vehicles to box in the ego-vehicle and increases the speeds of trailing
vehicles by 20%, making accidents more frequent. We also observe that the learned distribution
for initial conditions have variance 50% smaller than that of the base distribution, implying con-
centration around adversarial conditions. Perturbing the policy weights ξ for GAIL increases the
frequency of risky high-level behaviors (lane-change rate, hard-brake rate, etc.). An interesting
consequence of using our deﬁnition of TTC from the center of the ego vehicle (cf. Appendix A)
as a measure of safety is that dangerous events f (X)
γtest (for small γtest) include frequent
sideswiping behavior, as such accidents result in smaller TTC values than front- or rear-end colli-

≤

9

20

18

16

14

12

10

8

6

4

2

100

10-2

10-4

0.22

0.24

0.26

0.28

0.3

0.22

0.24

0.26

0.28

0.3

(a) Ratio of number of rare events vs. threshold

(b) Ratio of variance vs. threshold

Figure 3. The ratio of (a) number of rare events and (b) variance of estimator for pγ between
cross-entropy method and naive MC sampling for the vision-based ego policy.

Search Algorithm
Cross-entropy 50K (5.87±1.82)e-5
(11.3±4.60)e-5

γtest = 0.22

Naive 50K

γtest = 0.23
(13.0± 2.94)e-5
(20.6±6.22)e-5

γtest = 0.24
(19.0 ± 3.14)e-5
(43.2±9.00)e-5

γtest = 0.25
(4.52 ± 1.35)e-4
(6.75±1.13)e-4

Table 2. Estimate of rare-event probability pγ (non-vision ego policy) with standard errors. For
the cross-entropy method, we show results for the learned importance sampling distribution with
ρ = 0.01.

sions. See Appendix C for a reference to supplementary videos that exhibit the range of behavior
across many levels γtest. The modularity of our simulation framework easily allows us to modify the
safety objective to an alternative deﬁnition of TTC or even include more sophisticated notions of
safety, e.g. temporal-logic speciﬁcations or implementations of responsibility-sensitive safety (RSS)
[49, 40].

5 Related work and conclusions

Given the complexity of AV software and hardware components, it is unlikely that any single
method will serve as an oracle for certiﬁcation. Many existing tools are complementary to our
risk-based framework. In this section, we compare and contrast representative results in testing,
veriﬁcation, and simulation.

AV testing generally consists of three paradigms. The ﬁrst, largely attributable to regulatory
eﬀorts, uses a ﬁnite set of basic competencies (e.g. the Euro NCAP Test Protocol [46]); while
this methodology is successful in designing safety features such as airbags and seat-belts, the non-
adaptive nature of static testing is less eﬀective in complex software systems found in AVs. Al-
ternatively, real-world testing—deployment of vehicles with human oversight—exposes the vehicle
to a wider variety of unpredictable test conditions. However, as we outlined above, these methods
pose a danger to the public and require prohibitive number of driving hours due to the rare na-
ture of accidents [29]. Simulation-based falsiﬁcation (in our context, simply ﬁnding any crash) has
also been successfully utilized [51]; this approach does not maintain a link to the likelihood of the

10

occurrence of a particular event, which we believe to be key in acting to prioritize and correct AV
behavior.

Formal veriﬁcation methods [34, 2, 47, 37] have emerged as a candidate to reduce the intractabil-
ity of empirical validation. A veriﬁcation procedure considers whether the system can ever violate
a speciﬁcation and returns either a proof that there is no such execution or a counterexample. Ver-
iﬁcation procedures require a white-box description of the system (although it may be abstract),
as well as a mathematically precise speciﬁcation. Due to the impossibility of certifying safety in
all scenarios, these approaches [49] require further speciﬁcations that assign blame in the case of a
crash. Such assignment of blame is impossible to completely characterize and relies on subjective
notions of fault. Our risk-based framework allows one to circumvent this diﬃculty by only using
a measure of safety that does not assign blame (e.g. TTC) and replacing the speciﬁcations that
assign blame with a probabilistic notion of how likely the accident is. While this approach requires
a learned model of the world P0—a highly nontrivial statistical task in itself—the adaptive impor-
tance sampling techniques we employ can still eﬃciently identify dangerous scenarios even when
P0 is not completely accurate. Conceptually, we view veriﬁcation and our framework as comple-
mentary; they form powerful tools that can evaluate safety before deploying a ﬂeet for real-world
testing.

Even given a consistent and complete notion of blame, veriﬁcation remains highly intractable
from a computational standpoint. Eﬃcient algorithms only exist for restricted classes of systems in
the domain of AVs, and they are fundamentally diﬃcult to scale. Speciﬁcally, AVs—unlike previous
successful applications of veriﬁcation methods to application domains such as microprocessors [5]—
include both continuous and discrete dynamics. This class of dynamics falls within the purview of
hybrid systems [35], for which exhaustive veriﬁcation is largely undecidable [20].

Verifying individual components of the perception pipeline, even as standalone systems, is a
nascent, active area of research (see [3, 13, 7] and many others). Current subsystem veriﬁcation
techniques for deep neural networks [28, 30, 50] do not scale to state-of-the-art models and largely
investigate the robustness of the network with respect to small perturbations of a single sample.
There are two key assumptions in these works; the label of the input is unchanged within the
radius of allowable perturbations, and the resulting expansion of the test set covers a meaningful
portion of possible inputs to the network. Unfortunately, for realistic cases in AVs it is likely that
perturbations to the state of the world which in turn generates an image should change the label.
Furthermore, the combinatorial nature of scenario conﬁgurations casts serious doubt on any claims
of coverage.

In our risk-based framework, we replace the complex system speciﬁcations required for formal
veriﬁcation methods with a model P0 that we learn via imitation-learning techniques. Generative
adversarial imitation learning (GAIL) was ﬁrst introduced by Ho and Ermon [22] as a way to
directly learn policies from data and has since been applied to model human driving behavior
by Kueﬂer et al. [33]. Model-based GAIL (MGAIL) is the speciﬁc variant of GAIL that we employ;
introduced by Baram et al. [6], MGAIL’s generative model is fully diﬀerentiable, allowing eﬃcient
model training with standard stochastic approximation methods.

The cross-entropy method was introduced by Rubinstein [43] and has attracted interest in
many rare-event simulation scenarios [44, 32]. More broadly, it can be thought of as a model-
based optimization method [24, 25, 26, 53, 27, 56]. With respect to assessing safety of AVs, the
cross-entropy method has recently been applied in simple lane-changing and car-following scenarios
in two dimensions [54, 55]. Our work signiﬁcantly extends these works by implementing a photo-

11

realistic simulator that can assess the deep-learning based perception pipeline along with the control
framework. We leave the development of rare-event simulation methods that scale better with
dimension as a future work.

To summarize, a fundamental tradeoﬀ emerges when comparing the requirements of our risk-
based framework to other testing paradigms, such as real-world testing or formal veriﬁcation.
Real-world testing endangers the public but is still in some sense a gold standard. Veriﬁed sub-
systems provide evidence that the AV should drive safely even if the estimated distribution shifts,
but veriﬁcation techniques are limited by computational intractability as well as the need for both
white-box models and the completeness of speciﬁcations that assign blame (e.g. [49]). In turn, our
risk-based framework is most useful when the base distribution P0 is accurate, but even when P0 is
misspeciﬁed, our adaptive importance sampling techniques can still eﬃciently identify dangerous
scenarios, especially those that may be missed by veriﬁcation methods assigning blame. Our frame-
work oﬀers signiﬁcant speedups over real-world testing and allows eﬃcient evaluation of black-box
AV input/output behavior, providing a powerful tool to aid in the design of safe AVs.

Acknowledgments

MOK was partially supported by a National Science Foundation Graduate Research Fellowship. AS
was partially supported by a Stanford Graduate Fellowship and a Fannie & John Hertz Foundation
Fellowship. HN was partially supported by a Samsung Fellowship and the SAIL-Toyota Center for
AI Research. JD was partially supported by the SAIL-Toyota Center for AI Research and National
Science Foundation award NSF-CAREER-1553086.

References

[1] H. Abbas, M. O’Kelly, A. Rodionova, and R. Mangharam. Safe at any speed: A simulation-

based test harness for autonomous vehicles. LNCS. Springer, 2018.

[2] M. Althoﬀ and J. Dolan. Online veriﬁcation of automated road vehicles using reachability
analysis. Robotics, IEEE Transactions on, 30(4):903–918, Aug 2014. ISSN 1552-3098. doi:
10.1109/TRO.2014.2312453.

[3] S. Arora, A. Bhaskara, R. Ge, and T. Ma. Provable bounds for learning some deep represen-

tations. In International Conference on Machine Learning, pages 584–592.

, 2014.

[4] S. Asmussen and P. W. Glynn. Stochastic Simulation: Algorithms and Analysis. Springer,

2007.

Cambridge, 2008.

[5] C. Baier, J.-P. Katoen, et al. Principles of model checking, volume 26202649. MIT press

[6] N. Baram, O. Anschel, I. Caspi, and S. Mannor. End-to-end diﬀerentiable adversarial imitation

learning. In International Conference on Machine Learning, pages 390–399, 2017.

[7] P. L. Bartlett, D. J. Foster, and M. J. Telgarsky. Spectrally-normalized margin bounds for
,
neural networks. In Advances in Neural Information Processing Systems, pages 6241–6250.
2017.

[8] C. Blundell, J. Cornebise, K. Kavukcuoglu, and D. Wierstra. Weight uncertainty in neural

networks. arXiv preprint arXiv:1505.05424, 2015.

12

[9] M. Bojarski, D. Del Testa, D. Dworakowski, B. Firner, B. Flepp, P. Goyal, L. D. Jackel,
M. Monfort, U. Muller, J. Zhang, et al. End to end learning for self-driving cars. arXiv
preprint arXiv:1604.07316, 2016.

[10] J.-F. Bonnefon, A. Shariﬀ, and I. Rahwan. The social dilemma of autonomous vehicles.
ISSN 0036-8075. doi: 10.1126/science.aaf2654. URL

Science, 352(6293):1573–1576, 2016.
http://science.sciencemag.org/content/352/6293/1573.

[11] J. Bucklew. Introduction to rare event simulation. Springer Science & Business Media, 2013.

[12] M. Cheah, S. A. Shaikh, J. Bryans, and H. N. Nguyen. Combining third party components
In IFIP International Conference on Information Security

securely in automotive systems.
Theory and Practice, pages 262–269. Springer, 2016.

[13] N. Cohen, O. Sharir, and A. Shashua. On the expressive power of deep learning: A tensor

analysis. In Conference on Learning Theory, pages 698–728.

, 2016.

[14] A. Dosovitskiy, G. Ros, F. Codevilla, A. Lopez, and V. Koltun. CARLA: An open urban
In Proceedings of the 1st Annual Conference on Robot Learning, pages

driving simulator.
1–16, 2017.

[15] J. Friedman, T. Hastie, and R. Tibshirani. Sparse inverse covariance estimation with the

graphical lasso. Biostatistics, 9(3):432–441, 2008.

[16] Y. Gal and Z. Ghahramani. Dropout as a bayesian approximation: Representing model un-
certainty in deep learning. In International Conference on Machine Learningearning, pages
1050–1059, 2016.

[17] E. Games.

Unreal

engine 4 documentation.

URL https://docs. unrealengine.

com/latest/INT/index. html, 2015.

[18] A. Graves. Practical variational inference for neural networks. In Advances in Neural Infor-

mation Processing Systems, pages 2348–2356, 2011.

[19] H. Heinecke, K.-P. Schnelle, H. Fennel, J. Bortolazzi, L. Lundh, J. Leﬂour, J.-L. Mat´e,
K. Nishikawa, and T. Scharnhorst. Automotive open system architecture-an industry-wide
initiative to manage the complexity of emerging automotive e/e-architectures. Technical re-
port, SAE Technical Paper, 2004.

[20] T. A. Henzinger, P. W. Kopke, A. Puri, and P. Varaiya. What’s decidable about hybrid

automata? J. Comput. Syst. Sci., 57(1):94–124, 1998.

[21] P. Hintjens. ZeroMQ: messaging for many applications. ” O’Reilly Media, Inc.”, 2013.

[22] J. Ho and S. Ermon. Generative adversarial imitation learning. In Advances in Neural Infor-

mation Processing Systems, pages 4565–4573, 2016.

[23] T. Homem-de Mello. A study on the cross-entropy method for rare-event probability estima-

tion. INFORMS Journal on Computing, 19(3):381–394, 2007.

[24] J. Hu and P. Hu. On the performance of the cross-entropy method. In Simulation Conference

(WSC), Proceedings of the 2009 Winter, pages 459–468. IEEE, 2009.

[25] J. Hu and P. Hu. Annealing adaptive search, cross-entropy, and stochastic approximation in

global optimization. Naval Research Logistics (NRL), 58(5):457–477, 2011.

[26] J. Hu, P. Hu, and H. S. Chang. A stochastic approximation framework for a class of randomized
optimization algorithms. IEEE Transactions on Automatic Control, 57(1):165–178, 2012.

13

[27] J. Hu, E. Zhou, and Q. Fan. Model-based annealing random search with stochastic averaging.
ACM Transactions on Modeling and Computer Simulation (TOMACS), 24(4):21, 2014.

[28] X. Huang, M. Kwiatkowska, S. Wang, and M. Wu. Safety veriﬁcation of deep neural networks.
In International Conference on Computer Aided Veriﬁcation, pages 3–29. Springer, 2017.

[29] N. Kalra and S. M. Paddock. Driving to safety: How many miles of driving would it take
to demonstrate autonomous vehicle reliability? Transportation Research Part A: Policy and
Practice, 94:182–193, 2016.

[30] G. Katz, C. Barrett, D. Dill, K. Julian, and M. Kochenderfer. Reluplex: An eﬃcient smt

solver for verifying deep neural networks. arXiv:1702.01135 [cs.AI], 1:1, 2017.

[31] D. P. Kingma, T. Salimans, and M. Welling. Variational dropout and the local reparam-
eterization trick. In Advances in Neural Information Processing Systems, pages 2575–2583,
2015.

[32] D. P. Kroese, R. Y. Rubinstein, and P. W. Glynn. The cross-entropy method for estimation.

Handbook of Statistics: Machine Learning: Theory and Applications, 31:19–34, 2013.

[33] A. Kueﬂer, J. Morton, T. Wheeler, and M. Kochenderfer.

Imitating driver behavior with
generative adversarial networks. In Intelligent Vehicles Symposium (IV), 2017 IEEE, pages
204–211. IEEE, 2017.

[34] M. Kwiatkowska, G. Norman, and D. Parker. Prism 4.0: Veriﬁcation of probabilistic real-time
systems. In International conference on computer aided veriﬁcation, pages 585–591. Springer,
2011.

[35] J. Lygeros. Lecture notes on hybrid systems. In Notes for an ENSIETA workshop, 2004.

[36] U. D. of Transportation FHWA. Ngsim – next generation simulation, 2008.

[37] M. O’Kelly, H. Abbas, S. Gao, S. Shiraishi, S. Kato, and R. Mangharam. Apex: Autonomous

vehicle plan veriﬁcation and execution. volume 1, Apr 2016.

[38] I. Osband, C. Blundell, A. Pritzel, and B. Van Roy. Deep exploration via bootstrapped dqn.

In Advances in neural information processing systems, pages 4026–4034, 2016.

[39] C. Quiter and M. Ernst. Deepdrive. https://github.com/deepdrive/deepdrive, 2018.

[40] N. Roohi, R. Kaur, J. Weimer, O. Sokolsky, and I. Lee. Self-driving vehicle veriﬁcation towards

a benchmark. arXiv preprint arXiv:1806.08810, 2018.

[41] S. Ross and D. Bagnell. Eﬃcient reductions for imitation learning.

In Proceedings of the
thirteenth international conference on artiﬁcial intelligence and statistics, pages 661–668, 2010.

[42] S. Ross, G. Gordon, and D. Bagnell. A reduction of imitation learning and structured prediction
In Proceedings of the fourteenth international conference on

to no-regret online learning.
artiﬁcial intelligence and statistics, pages 627–635, 2011.

[43] R. Y. Rubinstein. Combinatorial optimization, cross-entropy, ants and rare events. In Stochas-

tic optimization: algorithms and applications, pages 303–363. Springer, 2001.

[44] R. Y. Rubinstein and D. P. Kroese. The cross-entropy method: A uniﬁed approach to Monte
Information Science &

Carlo simulation, randomized optimization and machine learning.
Statistics, Springer Verlag, NY, 2004.

[45] S. Russell. Learning agents for uncertain environments. In Proceedings of the eleventh annual

conference on Computational learning theory, pages 101–103. ACM, 1998.

14

[46] R. Schram, A. Williams, and M. van Ratingen.

Implementation of autonomous emergency

braking (aeb), the next step in euro ncaps safety assessment. ESV, Seoul, 2013.

[47] S. A. Seshia, D. Sadigh, and S. S. Sastry. Formal methods for semi-autonomous driving. In
Proceedings of the 52nd Annual Design Automation Conference, page 148. ACM, 2015.

[48] S. Shah, D. Dey, C. Lovett, and A. Kapoor. Airsim: High-ﬁdelity visual and phys-
In Field and Service Robotics, 2017. URL

ical simulation for autonomous vehicles.
https://arxiv.org/abs/1705.05065.

[49] S. Shalev-Shwartz, S. Shammah, and A. Shashua. On a formal model of safe and scalable

self-driving cars. arXiv preprint arXiv:1708.06374, 2017.

[50] V. Tjeng and R. Tedrake. Verifying neural networks with mixed integer programming.

arXiv:1711.07356 [cs.LG], 2017.

[51] C. E. Tuncali, T. P. Pavlic, and G. Fainekos. Utilizing s-taliro as an automatic test generation
framework for autonomous vehicles. In Intelligent Transportation Systems (ITSC), 2016 IEEE
19th International Conference on, pages 1470–1475. IEEE, 2016.

[52] K. Vogel. A comparison of headway and time to collision as safety indicators. Accident analysis

[53] Z. B. Zabinsky. Stochastic adaptive search for global optimization, volume 72. Springer Science

& prevention, 35(3):427–433, 2003.

& Business Media, 2013.

[54] D. Zhao. Accelerated Evaluation of Automated Vehicles. Ph.D. thesis, Department of Mechan-

ical Engineering, University of Michigan, 2016.

[55] D. Zhao, X. Huang, H. Peng, H. Lam, and D. J. LeBlanc. Accelerated evaluation of automated
vehicles in car-following maneuvers. IEEE Transactions on Intelligent Transportation Systems,
19(3):733–744, 2018.

[56] E. Zhou and J. Hu. Gradient-based adaptive stochastic search for non-diﬀerentiable optimiza-

tion. IEEE Transactions on Automatic Control, 59(7):1818–1832, 2014.

15

A Scenario speciﬁcation

•

•

•

•

A scenario speciﬁcation consists of a scenario description and outputs both pγ (1), the accident rate,
and a dataset consisting of initial conditions and the minimum time to collision, our continuous
objective safety measure. Concretely, a scenario description includes

a set of possible initial conditions, e.g. a range of velocities and poses for each agent

a safety measure speciﬁcation for the ego agent,

a generative model of environment policies, an ego vehicle model,

a world geometry model, e.g.a textured mesh of the static scene in which the scenario is to
take place.

Given the scenario description, the search module creates physics and rendering engine worker
instances, and Algorithm 1 then adaptively searches through many perturbations of conditions in
the scenario, which we call scenario realizations. A set of scenario realizations may be mapped to
multiple physics, rendering, and agent instantiations, evaluated in parallel, and reduced by a sink
node which reports a measure of each scenarios performance relative to the speciﬁcation.

In our implementation the safety measure is minimum time-to-collision (TTC). TTC is deﬁned
as the time it would take for two vehicles to intercept one another given that they each maintain
their current heading and velocity [52]. The TTC between the ego-vehicle and vehicle i is given by

T T Ci(t) =

ri(t)
˙ri(t)

,

−

(4)

where ri is the distance between the ego vehicle and vehicle i, and ˙ri the time derivative of this
distance (which is simply computed by projecting the relative velocity of vehicle i onto the vector
between the vehicles’ poses).

In this paper, vehicles are described as oriented rectangles in the 2D plane. Since we are
interested in the time it would take for the ego-vehicle to intersect the polygonal boundary of
another vehicle on the road, we utilize a ﬁnite set of range and range measurements in order to
approximate the TTC metric. For a given conﬁguration of vehicles, we compute N uniformly
spaced angles θ1, . . . , θN in the range [0, 2π] with respect to the ego vehicle’s orientation and cast
rays outward from the center of the ego vehicle. For each direction we compute the distance which
a ray could travel before intersecting one of the M other vehicles in the environment. These form
N range measurements s1, . . . , sN . Further, for each ray si, we determine which vehicle (if any)
that ray hit; projecting the relative velocity of this vehicle with respect to ego vehicle gives the
range-rate measurement ˙si. Finally, we approximate the minimum TTC for a given simulation
rollout X of length T discrete time steps by:

f (X) := min

t=0,...,T

min
i=1,...,N

si(t)
−
˙si(t)

(cid:18)
Note that this measure can approximate the true TTC arbitrarily well via choice of N and the
discretization of time used by the simulator. Furthermore, note that our deﬁnition of TTC is with
respect to the center of the ego vehicle touching the boundary of another vehicle. Crashing, on the
other hand, is deﬁned in our simulation as the intersection of boundaries of two vehicles. Thus,
TTC values we evaluate in our simulation are nonzero even during crashes, since the center of the
ego vehicle has not yet collided with the boundary of another vehicle.

(cid:19)

16

Figure 4: Depiction of lidar sensor input used for GAIL models.

B Network architectures

The MGAIL generator model we use takes the same inputs as that of Kueﬂer et al. [33]—the
dynamical states of the vehicle as well as virtual lidar beam reﬂections. Speciﬁcally, we take as
inputs: geometric parameters (vehicle length/width), dynamical states (vehicle speed, lateral and
angular oﬀsets with respect to the center and heading of the lane, distance to left and right lane
boundaries, and local lane curvature), three indicators for collision, road departure, and traveling
in reverse, and lidar sensor observations (ranges and range-rates of 20 lidar beams) as depicted in
Figure 4. The generator has two hidden layers of 200 and 100 neurons. The output consists of the
mean and variance of normal distributions for throttle and steering commands; we then sample
from these distributions to draw a given vehicle’s action. The discriminator shares the same size
for hidden layers. The forward model used to allow fully-diﬀerentiable training ﬁrst encodes both
the state and action through a 150 neuron layer and also adds a GRU layer to the state encoding.
A Hadamard product of the results creates a joint embedding which is put through three hidden
layers each of 150 neurons. The output is a prediction of the next state.

The end-to-end highway autopilot model is a direct implementation of Bojarski et al. [9] via the
code found at the link https://github.com/sullychen/autopilot-tensorflow. In our imple-
mentation of the vision-based policy, this highway autopilot model uses rendered images to produce
steering commands. Lidar inputs are used to generate throttle commands using the same network
as the non-vision policy.

C Supplementary videos

We have provided some videos to augment the analysis in our paper (available in the NeurIPS
supplement and at http://amansinha.org/docs/OKellySiNaDuTe18_videos.zip):

•

•

gail.mp4 provides an example of a trained GAIL model driving alongside data traces from
real human drivers [36].

Example videos from rollouts. The ﬁlenames start with “mttc =” to indicate the minimum
TTC that resulted between the ego and any other vehicle during the rollout. Note that even
crashes have nonzero values of TTC due to the deﬁnition we used for TTC from the center
of the ego vehicle (cf. Appendix A). The videos are all played back at 2.5
real-time speed.
The videos included in the supplement are:

×

– Crashes:

17

crash.mp4

−

mttc = 0.23
mttc = 0.30.mp4
mttc = 0.42.mp4
mttc = 0.56.mp4

– Non-crashes:

nocrash.mp4

−

mttc = 0.23
mttc = 0.79.mp4
mttc = 1.43.mp4
mttc = 2.01.mp4
mttc = 3.05.mp4
mttc = 6.00.mp4
mttc = 6.01.mp4
mttc = 10.11.mp4

∗
∗
∗
∗

∗
∗
∗
∗
∗
∗
∗
∗

These videos contain overhead, RGB, segmented, and depth views. We also include higher-
resolution RGB videos with the same base names as above but the extension “ hires.mp4”.

18

