7
1
0
2
 
v
o
N
 
6
1
 
 
]
L
M

.
t
a
t
s
[
 
 
1
v
8
7
1
6
0
.
1
1
7
1
:
v
i
X
r
a

Beyond Sparsity: Tree Regularization of Deep Models for Interpretability

Mike Wu1, Michael C. Hughes2, Sonali Parbhoo3,
Maurizio Zazzi4, Volker Roth3, and Finale Doshi-Velez2
1Stanford University, wumike@cs.stanford.edu
2Harvard University SEAS, mike@michaelchughes.com, ﬁnale@seas.harvard.edu
3University of Basel, {sonali.parbhoo,volker.roth}@unibas.ch
4University of Siena, maurizio.zazzi@unisi.it

Abstract

The lack of interpretability remains a key barrier to the adop-
tion of deep models in many applications. In this work, we
explicitly regularize deep models so human users might step
through the process behind their predictions in little time.
Speciﬁcally, we train deep time-series models so their class-
probability predictions have high accuracy while being closely
modeled by decision trees with few nodes. Using intuitive toy
examples as well as medical tasks for treating sepsis and HIV,
we demonstrate that this new tree regularization yields models
that are easier for humans to simulate than simpler L1 or L2
penalties without sacriﬁcing predictive power.

1

Introduction

Deep models have become the de-facto approach for pre-
diction in a variety of applications such as image classiﬁ-
cation (e.g. (Krizhevsky, Sutskever, and Hinton 2012)) and
machine translation (e.g. (Bahdanau, Cho, and Bengio 2014;
Sutskever, Vinyals, and Le 2014)). However, many practi-
tioners are reluctant to adopt deep models because their pre-
dictions are difﬁcult to interpret. In this work, we seek a spe-
ciﬁc form of interpretability known as human-simulability.
A human-simulatable model is one in which a human user
can “take in input data together with the parameters of the
model and in reasonable time step through every calculation
required to produce a prediction” (Lipton 2016). For exam-
ple, small decision trees with only a few nodes are easy for
humans to simulate and thus understand and trust. In con-
trast, even simple deep models like multi-layer perceptrons
with a few dozen units can have far too many parameters and
connections for a human to easily step through. Deep models
for sequences are even more challenging. Of course, decision
trees with too many nodes are also hard to simulate. Our
key research question is: can we create deep models that are
well-approximated by compact, human-simulatable models?
The question of creating accurate yet human-simulatable
models is an important one, because in many domains sim-
ulatability is paramount. For example, despite advances in
deep learning for clinical decision support (e.g. (Miotto et al.

A version of this work will appear in AAAI 2018 (https://
aaai.org/Conferences/AAAI-18/). This paper includes
an extended appendix with supplementary material.

2016; Choi et al. 2016; Che et al. 2015)), the clinical com-
munity remains skeptical of machine learning systems (Chen
and Asch 2017). Simulatability allows clinicians to audit pre-
dictions easily. They can manually inspect changes to outputs
under slightly-perturbed inputs, check substeps against their
expert knowledge, and identify when predictions are made
due to systemic bias in the data rather than real causes. Sim-
ilar needs for simulatability exist in many decision-critical
domains such as disaster response or recidivism prediction.
To address this need for interpretability, a number of works
have been developed to assist in the interpretation of already-
trained models. Craven and Shavlik (1996) train decision
trees that mimic the predictions of a ﬁxed, pretrained neural
network, but do not train the network itself to be simpler.
Other post-hoc interpretations typically typically evaluate the
sensitivity of predictions to local perturbations of inputs or
the input gradient (Ribeiro, Singh, and Guestrin 2016; Sel-
varaju et al. 2016; Adler et al. 2016; Lundberg and Lee 2016;
Erhan et al. 2009). In parallel, research efforts have empha-
sized that simple lists of (perhaps locally) important features
are not sufﬁcient: Singh, Ribeiro, and Guestrin (2016) pro-
vide explanations in the form of programs; Lakkaraju, Bach,
and Leskovec (2016) learn decision sets and show beneﬁts
over other rule-based methods.

These techniques focus on understanding already learned
models, rather than ﬁnding models that are more interpretable.
However, it is well-known that deep models often have mul-
tiple optima of similar predictive accuracy (Goodfellow, Ben-
gio, and Courville 2016), and thus one might hope to ﬁnd
more interpretable models with equal predictive accuracy.
However, the ﬁeld of optimizing deep models for interpretabil-
ity remains nascent. Ross, Hughes, and Doshi-Velez (2017)
penalize input sensitivity to features marked as less relevant.
Lei, Barzilay, and Jaakkola (2016) train deep models that
make predictions from text and simultaneously highlight con-
tiguous subsets of words, called a “rationale,” to justify each
prediction. While both works optimize their deep models to
expose relevant features, lists of features are not sufﬁcient to
simulate the prediction.

In this work, we take steps toward optimiz-
Contributions.
ing deep models for human-simulatability via a new model
complexity penalty function we call tree regularization. Tree
regularization favors models whose decision boundaries can

be well-approximated by small decision-trees, thus penaliz-
ing models that would require many calculations to simulate
predictions. We ﬁrst demonstrate how this technique can be
used to train simple multi-layer perceptrons to have tree-like
decision boundaries. We then focus on time-series appli-
cations and show that gated recurrent unit (GRU) models
trained with strong tree-regularization reach a high-accuracy-
at-low-complexity sweet spot that is not possible with any
strength of L1 or L2 regularization. Prediction quality can
be further boosted by training new hybrid models – GRU-
HMMs – which explain the residuals of interpretable discrete
HMMs via tree-regularized GRUs. We further show that
the approximate decision trees for our tree-regularized deep
models are useful for human simulation and interpretability.
We demonstrate our approach on a speech recognition task
and two medical treatment prediction tasks for patients with
sepsis in the intensive care unit (ICU) and for patients with
human immunodeﬁciency virus (HIV). Throughout, we also
show that standalone decision trees as a baseline are notice-
ably less accurate than our tree-regularized deep models. We
have released an open-source Python toolbox to allow others
to experiment with tree regularization 1.

Related work. While there is little work (as mentioned
above) on optimizing models for interpretability, there are
some related threads. The ﬁrst is model compression, which
trains smaller models that perform similarly to large, black-
box models (e.g. (?; Hinton, Vinyals, and Dean 2015;
Balan et al. 2015; Han et al. 2015)). Other efforts speciﬁ-
cally train very sparse networks via L1 penalties (Zhang, Lee,
and Jordan 2016) or even binary neural networks (Tang, Hua,
and Wang 2017; Rastegari et al. 2016) with the goal of faster
computation. Edge and node regularization is commonly used
to improve prediction accuracy (Drucker and Le Cun 1992;
Ochiai et al. 2017), and recently Hu et al. (2016) improve
prediction accuracy by training neural networks so that pre-
dictions match a small list of known domain-speciﬁc ﬁrst-
order logic rules. Sometimes, these regularizations—which
all smooth or simplify decision boundaries—can have the
effect of also improving interpretability. However, there is
no guarantee that these regularizations will improve inter-
pretability; we emphasize that speciﬁcally training deep mod-
els to have easily-simulatable decision boundaries is (to our
knowledge) novel.

2 Background and Notation
We consider supervised learning tasks given datasets of N
labeled examples, where each example (indexed by n) has
an input feature vectors xn and a target output vector yn. We
shall assume the targets yn are binary, though it is simple to
extend to other types. When modeling time series, each ex-
ample sequence n contains Tn timesteps indexed by t which
each have a feature vector xnt and an output ynt. Formally,
we write: xn = [xn1 . . . xnTn ] and yn = [yn1 . . . ynTn ]. Each
value ynt could be prediction about the next timestep (e.g. the
character at time t + 1) or some other task-related annotation
(e.g. if the patient became septic at time t).

1https://github.com/dtak/tree-regularization-public

Simple neural networks. A multi-layer perceptron (MLP)
makes predictions ˆyn of the target yn via a function
ˆyn(xn, W ), where the vector W represents all parameters of
the network. Given a data set {(xn, yn)}, our goal is to learn
the parameters W to minimize the objective

min
W

λΨ(W ) +

loss(yn, ˆyn(xn, W ))

(1)

N
(cid:88)

n=1

For binary targets yn, the logistic loss (binary cross entropy)
is an effective choice. The regularization term Ψ(W ) can
represent L1 or L2 penalties (e.g. (Drucker and Le Cun 1992;
Goodfellow, Bengio, and Courville 2016; Ochiai et al. 2017))
or our new regularization.

Recurrent Neural Networks with Gated Recurrent Units.
A recurrent neural network (RNN) takes as input an arbitrary
length sequence xn = [xn1 . . . xnTn ] and produces a “hidden
state” sequence hn = [hn1 . . . hnTn ] of the same length as
the input. Each hidden state vector at timestep t represents a
location in a (possibly low-dimensional) “state space” with K
dimensions: hnt ∈ RK. RNNs perform sequential nonlinear
embedding of the form hnt = f (xnt, hnt−1) in hope that
the state space location hnt is a useful summary statistic for
making predictions of the target ynt at timestep t.

Many different variants of the transition function architec-
ture f have been proposed to solve the challenge of capturing
long-term dependencies. In this paper, we use gated recurrent
units (GRUs) (Cho et al. 2014), which are simpler than other
alternatives such as long short-term memory units (LSTMs)
(Hochreiter and Schmidhuber 1997). While GRUs are con-
venient, any differentiable RNN architecture is compatible
with our new tree-regularization approach.

Below we describe the evolution of a single GRU sequence,
dropping the sequence index n for readability. The GRU tran-
sition function f produces the state vector ht = [ht1 . . . htK]
from a previous state ht−1 and an input vector xt, via the
following feed-forward architecture:

output state : htk = (1 − ztk)ht−1,k + zt,k

candidate state : ˜htk = tanh(V h
update gate : ztk = σ(V z
reset gate : rtk = σ(V r

k xt + U z
k xt + U r

k ht−1)
k ht−1)

k xt + U h

˜htk
k (rt (cid:12) ht−1))

(2)

The internal network nodes include candidate state gates
˜h, update gates z and reset gates r which have the same
cardinalty as the state vector h. Reset gates allow the network
to forget past state vectors when set near zero via the logistic
sigmoid nonlinearity σ(·). Update gates allow the network to
either pass along the previous state vector unchanged or use
the new candidate state vector instead. This architecture is
diagrammed in Figure 1.

The predicted probability of the binary label yt for time t

is a sigmoid transformation of the state at time t:

ˆyt = σ(wT ht)
Here, weight vector w ∈ RK represents the parameters of
this output layer. We denote the parameters for the entire

(3)

2

Algorithm 1 Average-Path-Length Cost Function

Require:

n=1 : reference dataset with N examples

ˆy(·, W ) : binary prediction function, with parameters W
D = {xn}N
1: function Ω(W )
2:
3:

tree ← TRAINTREE({xn, ˆy(xn, W )})
return 1
n PATHLENGTH(tree, xn)
N

(cid:80)

supplement.) Next, PATHLENGTH counts how many nodes
are needed to make a speciﬁc input to an output node in the
provided decision tree. In our evaluations, we will apply our
average-decision-tree-path-length regularization, or simply
“tree regularization,” to several neural models.
Alg. 1 deﬁnes our average-path-length cost function Ω(W ),
which can be plugged into the abstract regularization term
Ψ(W ) in the objectives in equations 1 and 4.

Making the Decision-Tree Loss Differentiable Training
decision trees is not differentiable, and thus Ω(W ) as deﬁned
in Alg. 1 is not differentiable with respect to the network
parameters W (unlike standard regularizers such as the L1
or L2 norm). While one could resort to derivative-free opti-
mization techniques (Audet and Kokkolaras 2016), gradient
descent has been an extremely fast and robust way of training
networks (Goodfellow, Bengio, and Courville 2016).

A key technical contribution of our work is introducing
and training a surrogate regularization function ˆΩ(W ) :
supp(W ) → R+ to map each candidate neural model pa-
rameter vector W to an estimate of the average-path-length.
Our approximate function ˆΩ is implemented as a standalone
multi-layer perceptron network and is thus differentiable. Let
vector ξ of size k denote the parameters of this chosen MLP
approximator. We can train ˆΩ to be a good estimator by
minimizing a squared error loss function:

(cid:80)J

j=1(Ω(Wj) − ˆΩ(Wj, ξ))2 + (cid:15)||ξ||2

2

(5)

min
ξ

where Wj are the entire set of parameters for our model,
(cid:15) > 0 is a regularization strength, and we assume we have
a dataset of J known parameter vectors and their associ-
ated true path-lengths: {Wj, Ω(Wj)}J
j=1. This dataset can
be assembled using the candidate W vectors obtained while
training our target neural model ˆy(·, W ), as well as by evalu-
ating Ω(W ) for randomly generated W . Importantly, one can
train the surrogate function ˆΩ in parallel with our network.
In the supplement, we show evidence that our surrogate pre-
dictor ˆΩ(·) tracks the true average path length as we train the
target predictor ˆy(·, W ).

Training the Surrogate Loss Even moderately-sized
GRUs can have parameter vectors W with thousands of
dimensions. Our labeled dataset for surrogate training –
{Wj, Ω(Wj)}J
j=1—will only have one Wj example from
each target network training iteration. Thus, in early itera-
tions, we will have only few examples from which to learn
a good surrogate function ˆΩ(W ). We resolve this challenge

Figure 1: Diagram of gated recurrent unit (GRU) used for
each timestep our neural time-series model. The orange trian-
gle indicates the predicted output ˆyt at time t.

GRU-RNN model as W = (w, U, V ), concatenating all com-
ponent parameters. We can train GRU-RNN time-series mod-
els (hereafter often just called GRUs) via the following loss
minimization objective:

min
W

λΨ(W ) +

N
(cid:88)

Tn(cid:88)

n=1

n=1

loss(ynt, ˆynt(xn, W ))

(4)

where again Ψ(W ) deﬁnes a regularization cost.

3 Tree Regularization for Deep Models
We now propose a novel tree regularization function Ω(W )
for the parameters of a differentiable model which attempts
to penalize models whose predictions are not easily simu-
latable. Of course, it is difﬁcult to measure “simulatability”
directly for an arbitrary network, so we take inspiration from
decision trees. Our chosen method has two stages: ﬁrst, ﬁnd
a single binary decision tree which accurately reproduces
the network’s thresholded binary predictions ˆyn given input
xn. Second, measure the complexity of this decision tree as
the output of Ω(W ). We measure complexity as the aver-
age decision path length—the average number of decision
nodes that must be touched to make a prediction for an input
example xn. We compute the average with respect to some
designated reference dataset of example inputs D = {xn}
from the training set. While many ways to measure complex-
ity exist, we ﬁnd average path length is most relevant to our
notion of simulatability. Remember that for us, human simu-
lation requires stepping through every calculation required
to make a prediction. Average path length exactly counts the
number of true-or-false boolean calculations needed to make
an average prediction, assuming the model is a decision tree.
Total number of nodes could be used as a metric, but might
penalize more accurate trees that have short paths for most
examples but need more involved logic for few outliers.

Our true-average-path-length cost function Ω(W ) is de-
tailed in Alg. 1. It requires two subroutines, TRAINTREE and
PATHLENGTH. TRAINTREE trains a binary decision tree to
accurately reproduce the provided labeled examples {xn, ˆyn}.
We use the DecisionTree module distributed in Python’s
scikit-learn (Pedregosa et al. 2011) with post-pruning to sim-
plify the tree. These trees can give probabilistic predictions at
each leaf. (Complete decision-tree training details are in the

3

via augmenting our training set with additional examples: We
randomly sample weight vectors W and calculate the true
average path length Ω(W ), and we also perform several ran-
dom restarts on the unregularized GRU and use those weights
in our training set.

A second challenge occurs later in training: as the model
parameters W shift away from their initial values, those early
parameters may not be as relevant in characterizing the cur-
rent decision function of the GRU. To address this, for each
epoch, we use examples only from the past E epochs (in ad-
dition to augmentation), where in practice, E is empirically
chosen. Using examples from a ﬁxed window of epochs also
speeds up training. The supplement shows a comparison of
the importance of these heuristics for efﬁcient and accurate
training—empirically, data augmentation for stabilizing sur-
rogate training allows us to scale to GRUs with 100s of nodes.
GRUs of this size are sufﬁcient for many real problems, such
as those we encounter in healthcare domains.

Typically, we use J = 50 labeled pairs for surrogate train-
ing for toy datasets and J = 100 for real world datasets.
Optimization of our surrogate objective is done via gradient
descent. We use Autograd to compute gradients of the loss in
Eq. (5) with respect to ξ, then use Adam to compute descent
directions with step sizes set to 0.01 for toy datasets and
0.001 for real world datasets.

4 Tree-Regularized MLPs: A Demonstration
While time-series models are the main focus of this work,
we ﬁrst demonstrate tree regularization on a simple binary
classiﬁcation task to build intuition. We call this task the 2D
Parabola problem, because as Fig. 2(a) shows, the training
data consists of 2D input points whose two-class decision
boundary is roughly shaped like a parabola. The true decision
function is deﬁned by y = 5 ∗ (x − 0.5)2 + 0.4. We sam-
pled 500 input points xn uniformly within the unit square
[0, 1] × [0, 1] and labeled those above the decision function
as positive. To make it easy for models to overﬁt, we ﬂipped
10% of the points in a region near the boundary. A random
30% were held out for testing.

For the classiﬁer ˆy, we train a 3-layer MLP with 100 ﬁrst
layer nodes, 100 second layer nodes, and 10 third layer nodes.
This MLP is intentionally overly expressive to encourage
overﬁtting and expose the impact of different forms of regular-
ization: our proposed tree regularization Ψ(W ) = ˆΩ(W ) and
two baselines: an L2 penalty on the weights Ψ(W ) = ||W ||2,
and an L1 penalty on the weights Ψ(W ) = ||W ||1. For each
regularization function, we train models at many different
regularization strengths λ chosen to explore the full range
of decision boundary complexities possible under each tech-
nique.

For our tree regularization, we model our surrogate ˆΩ(W )
with a 1-hidden layer MLP with 25 units. We ﬁnd this simple
architecture works well, but certainly more complex MLPs
could could be used on more complex problems. The objec-
tive in equation 1 was optimized via Adam gradient descent
(Kingma and Ba 2014) using a batch size of 100 and a learn-
ing rate of 1e-3 for 250 epochs, and hyperparameters were
set via cross validation using grid search (see supplement for

full experimental details).

Fig. 2 (b) shows the each trained model as a single point
in a 2D ﬁtness space: the x-axis measures model complexity
via our average-path-length metric, and the y-axis measures
AUC prediction performance. These results show that sim-
ple L1 or L2 regularization does not produce models with
both small node count and good predictions at any value of
the regularization strength λ. As expected, large λ values
for L1 and L2 only produce far-too-simple linear decision
boundaries with poor accuracies. In contrast, our proposed
tree regularization directly optimizes the MLP to have simple
tree-like boundaries at high λ values which can still yield
good predictions.

The lower panes of Fig. 2 shows these boundaries. Our
tree regularization is uniquely able to create axis-aligned
functions, because decision trees prefer functions that are
axis-aligned splits. These axis-aligned functions require very
few nodes but are more effective than L1 and L2 counterparts.
The L1 boundary is more sharp, whereas the L2 is more
round.

5 Tree-Regularized Time-Series Models
We now evaluate our tree-regularization approach on time-
series models. We focus on GRU-RNN models, with some
later experiments on new hybrid GRU-HMM models. As
with the MLP, each regularization technique (tree, L2, L1)
can be applied to the output node of the GRU across a range
of strength parameters λ. Importantly, Algorithm 1 can com-
pute the average-decision-tree-path-length for any ﬁxed deep
model given its parameters, and can hence be used to mea-
sure decision boundary complexity under any regularization,
including L1 or L2. This means that when training any model,
we can track both the predictive performance (as measured
by area-under-the-ROC-curve (AUC); higher values mean
better predictions), as well as the complexity of the deci-
sion tree required to explain each model (as measured by
our average path length metric; lower values mean more
interpretable models). We also show results for a baseline
standalone decision tree classiﬁer without any associated
deep model, sweeping a range of parameters controlling leaf
size to explore how this baseline trades off path length and
prediction quality. Further details of our experimental proto-
col are in the supplement, as well as more extensive results
with additional baselines.

5.1 Tasks
Synthetic Task: Signal-and-noise HMM We generated
a toy dataset of N = 100 sequences, each with T = 50
timesteps. Each timestep has a data vector xnt of 14 binary
features and a single binary output label ynt. The data comes
from two separate HMM processes. First, a “signal” HMM
generates the ﬁrst 7 data dimensions from 5 well-separated
states. Second, an independent “noise” HMM generates the
remaining 7 data dimensions from a different set of 5 states.
Each timestep’s output label ynt is produced by a rule involv-
ing both the signal data and the signal hidden state: the target
is 1 at timestep t only if both the ﬁrst signal state is active and
the ﬁrst observation is turned on. We deliberately designed

4

septic ICU patients from the public MIMIC III dataset
(Johnson et al. 2016). We observe at each hour t a data
vector xnt of 35 vital signs and lab results as well as a label
vector ynt of 5 binary outcomes. Hourly data xnt measures
continuous features such as respiration rate (RR), blood
oxygen levels (paO2), ﬂuid levels, and more. Hourly binary
labels ynt include whether the patient died in hospital
and if mechanical ventilation was applied. Models are
trained to predict all 5 output dimensions concurrently
from one shared embedding. The average sequence length
is 15 hours. 7 070 patients are used in training, 1 769 for
validation, and 294 for test.

• HIV Therapy Outcome (HIV): We use the EuResist In-
tegrated Database (Zazzi et al. 2012) for 53 236 patients
diagnosed with HIV. We consider 4-6 month intervals (cor-
responding to hospital visits) as time steps. Each data
vector xnt has 40 features, including blood counts, viral
load measurements and lab results. Each output vector ynt
has 15 binary labels, including whether a therapy was suc-
cessful in reducing viral load to below detection limits, if
therapy caused CD4 blood cell counts to drop to dangerous
levels (indicating AIDS), or if the patient suffered adher-
ence issues to medication. The average sequence length
is 14 steps. 37 618 patients are used for training; 7 986 for
testing, and 7 632 for validation.

• Phonetic Speech (TIMIT): We have recordings of 630
speakers of eight major dialects of American English read-
ing ten phonetically rich sentences (Garofolo et al. 1993).
Each sentence contains time-aligned transcriptions of 60
phonemes. We focus on distinguishing stop phonemes
(those that stop the ﬂow of air, such as “b” or “g”) from
non-stops. Each timestep has one binary label ynt indicat-
ing if a stop phoneme occurs or not. Each input xnt has 26
continuous features: the acoustic signal’s Mel-frequency
cepstral coefﬁcients and derivatives. There are 6 303 se-
quences, split into 3 697 for training, 925 for validation,
and 1 681 for testing. The average length is 614.

5.2 Results
The major conclusions of our experiments comparing GRUs
with various regularizations are outlined below.

Tree-regularized models have fewer nodes than other
forms of regularization. Across tasks, we see that in the
target regime of small decision trees (low average-path
lengths), our proposed tree-regularization achieves higher pre-
diction quality (higher AUCs). In the signal-and-noise HMM
task, tree regularization (green line in Fig. 3(d)) achieves
AUC values near 0.9 when its trees have an average path
length of 10. Similar models with L1 or L2 regularization
reach this AUC only with trees that are nearly double in com-
plexity (path length over 25). On the Sepsis task (Fig. 4) we
see AUC gains of 0.05-0.1 at path lengths of 2-10. On the
TIMIT task (Fig. 5a), we see AUC gains of 0.05-0.1 at path
lengths of 20-30. Finally, on the HIV CD4 blood cell count
task in Fig. 5b, we see AUC differences of between 0.03 and
0.15 for path lengths of 10-15. The HIV adherence task in

(a) Training Data and Binary Class Labels for 2D Parabola

(b) Prediction quality and complexity as reg. strength λ varies

(c) Decision Boundaries with L1 regularization

(d) Decision Boundaries with L2 regularization

(e) Decision Boundaries Tree regularization

Figure 2: 2D Parabola task: (a) Each training data point
in 2D space, overlaid with true parabolic class boundary.
(b): Each method’s prediction quality (AUC) and complexity
(path length) metrics, across range of regularization strength
λ. In the small path length regime between 0 and 5, tree reg-
ularization produces models with higher AUC than L1 or L2.
(c-e): Decision boundaries (black lines) have qualitatively
different shapes for different regularization schemes, as regu-
larization strength λ increases. We color predictions as true
positive (red), true negative (yellow), false negative (green),
and false positive (blue).

the generation process so that neither logistic regression with
x as features nor an RNN model that makes predictions from
hidden states alone can perfectly separate this data.

Real-World Tasks: We tested our approach on several real
tasks: predicting medical outcomes of hospitalized septic pa-
tients, predicting HIV therapy outcomes, and identifying stop
phonemes in English speech recordings. To normalize scales,
we independently standardized features x via z-scoring.

• Sepsis Critical Care: We study time-series data for 11 786

5

(a) GRU λ = 1

(b) GRU λ = 800

(c) GRU λ = 1 000

(d) GRU

Figure 3: Toy Signal-and-Noise HMM Task: (a)-(c) Decision trees trained to mimic predictions of GRU models with 25 hidden
states at different regularization strengths λ; as expected, increasing λ decreases the size of the learned trees (see supplement for
more trees). Decision tree (c) suggests the model learns to predict positive output (blue) if and only if “x[0] == 1 and x[3] == 1
and x[4] == 0”, which is consistent with the true rule we used to generate labels: assign positive label only if ﬁrst dimension is
on (x[0] == 1) and ﬁrst state is active (emission probabilities for this state: [.5 .5 .5 .5 0 . . .]). (d) Tree-regularized GRU models
reach a sweet spot of small path lengths yet high AUC predictions that alternatives cannot reach at any tested value of λ.

(a) In-Hospital Mortality

(b) In-Hospital Mortality

(c) Mechanical Ventilation

(d) Mechanical Ventilation

Figure 4: Sepsis task: Study of different regularization techniques for GRU model with 100 states, trained to jointly predict 5
binary outcomes. Panels (a) and (c) show AUC vs. average path length for 2 of the 5 outcomes (remainder in the supplement); in
both cases, tree-regularization provides higher accuracy in the target regime of low-complexity decision trees. Panels (b) and (d)
show the associated decision trees for λ = 2 000; these were found by clinically interpretable by an ICU clinician (see main text).

(a) TIMIT Stop Phonemes

(b) HIV: CD4+ ≤ 200 cells/ml

(c) HIV Therapy Adherence

(d) HIV Therapy Adherence

Figure 5: TIMIT and HIV tasks: Study of different regularization techniques for GRU model with 75 states. Panels (a)-(c) are
tradeoff curves showing how AUC predictive power and decision-tree complexity evolve with increasing regularization strength
under L1, L2 or tree regularization on both TIMIT and HIV tasks. The GRU is trained to jointly predict 15 binary outcomes for
HIV, of which 2 are shown here in Panels (b) - (c). The GRU’s decision tree proxy for HIV Adherence is shown in (d).

6

Fig. 5d has AUC gains of between 0.03 and 0.05 in the path
length range of 19 to 25 while at smaller paths all methods
are quite poor, indicating the problem’s difﬁculty. Overall,
these AUC gains are particularly useful in determining how
to administer subsequent HIV therapies.

We emphasize that our tree-regularization usually achieves
a sweet spot of high AUCs at short path lengths not possible
with standalone decision trees (orange lines), L1-regularized
deep models (red lines) or L2-regularized deep models (blue
lines). In unshown experiments, we also tested elastic net
regularization (Zou and Hastie 2005), a linear combination
of L1 and L2 penalities. We found elastic nets to follow the
same trend lines as L1 and L2, with no visible differences. In
domains where human-simulatability is required, increases in
prediction accuracy in the small-complexity regime can mean
the difference between models that provide value on a task
and models that are unusable, either because performance is
too poor or predictions are uninterpretable.

Our learned decision tree proxies are interpretable.
Across all tasks, the decision trees which mimic the pre-
dictions of tree-regularized deep models are small enough
to simulate by hand (path length ≤ 25) and help users grasp
the model’s nonlinear prediction logic. Intuitively, the trees
for our synthetic task in Fig. 3(a)-(c) decrease in size as the
strength λ increases. The logic of these trees also matches
the true labeling process: even the simplest tree (c) checks a
relevant subset of input dimensions necessary to verify that
both the ﬁrst state and the ﬁrst output dimension are active.
In Fig. 4, we show decision tree proxies for our deep mod-
els on two sepsis prediction tasks: mortality and need for
ventilation. We consulted a clinical expert on sepsis treat-
ment, who noted that the trees helped him understand what
the models might be doing and thus determine if he would
trust the deep model. For example, he said that using FiO2,
RR, CO2 and paO2 to predict need for mechanical ventilation
(Fig. 4d) was sensible, as these all measure breathing quality.
In contrast, the in-hospital mortality tree (Fig. 4b) predicts
that some young patients with no organ failure have high
mortality rates while other young patients with organ failure
have low mortality. These counter-intuitive results led to hy-
potheses about how uncaptured variables impact the training
process. Such reasoning would not be possible from simple
sensitivity analyses of the deep model.

Finally, we have veriﬁed that the decision tree proxies of
our tree-regularized deep models of the HIV task in Fig. 5d
are interpretable for understanding why a patient has trouble
adhering to a prescription; that is, taking drugs regularly as
directed. Our clinical collaborators conﬁrm that the baseline
viral load and number of prior treatment lines, which are
prominent attributes for the decisions in Fig. 5d, are useful
predictors of a patient with adherence issues. Several med-
ical studies (Langford, Ananworanich, and Cooper 2007;
Socas et al. 2011) suggest that patients with higher base-
line viral loads tend to have faster disease progression, and
hence have to take several drug cocktails to combat resistance.
Juggling many drugs typically makes it difﬁcult for these pa-
tients to adhere as directed. We hope interpretable predictive

models for adherence could help assess a patient’s overall
prognosis (Paterson et al. 2000) and offer opportunities for
intervention (e.g. with alternative single-tablet regimens).

Decision trees trained to mimic deep models make faith-
ful predictions. Across datasets, we ﬁnd that each tree-
regularized deep time-series model has predictions that agree
with its corresponding decision tree proxy in about 85-90%
of test examples. Table 1 shows exact ﬁdelty scores for each
dataset. Thus, the simulatable paths of the decision tree will
be trustworthy in a majority of cases.

Practical runtimes for tree regularization are less than
twice that of simpler L2. While our tree-regularized GRU
with 10 states takes 3977 seconds per epoch on TIMIT, a
similar L2-regularized GRU takes 2116 seconds per epoch.
Thus, our new method has cost less than twice the baseline
even when the surrogate is serially computed. Because the
surrogate ˆΩ(W ) will in general be a much smaller model
than the predictor ˆy(x, W ), we expect one could get faster
per-epoch times by parallelizing the creation of (W, Ω(W ))
training pairs and the training of the surrogate ˆΩ(W ). Ad-
ditionally, 3977 seconds includes the time needed to train
the surrogate. In practice, we do this sparingly, only once
every 25 epochs, yielding an amortized per-epoch cost of
2191 seconds (more runtime results are in the supplement).

Decision trees are stable over multiple optimization runs.
When tree regularization is strong (high λ), the decision trees
trained to match the predictions of deep models are stable. For
both signal-and-noise and sepsis tasks, multiple runs from
different random restarts have nearly identical tree shape
and size, perhaps differing by a few nodes. This stability is
crucial to building trust in our method. On the signal-and-
noise task (λ = 7000), 7 of 10 independent runs with random
initializations resulted in trees of exactly the same structure,
and the others closely resembled those sharing the same
subtrees and features (more details in supplement).

The deep residual GRU-HMM achieves high AUC with
less complexity. So far, we have focused on regularizing
standard deep models, such as MLPs or GRUs. Another op-
tion is to use a deep model as a residual on another model
that is already interpretable: for example, discrete HMMs par-
tition timesteps into clusters, each of which can be inspected,
but its predictions might have limited accuracy. In Fig. 6, we
show the performance of jointly training a GRU-HMM, a
new model which combines an HMM with a tree-regularized
GRU to improve its predictions (details and further results
in the supplement). Here, the ideal path length is zero, indi-
cating only the HMM makes predictions. For small average-
path-lengths, the GRU-HMM improves the original HMM’s
predictions and has simulatability gains over earlier GRUs.
On the mechanical ventilation task, the GRU-HMM requires
an average path length of only 28 to reach AUC of 0.88, while
the GRU alone with the same number of states requires a
path length of 60 to reach the same AUC. This suggests that

7

Dataset
signal-and-noise HMM
SEPSIS (In-Hospital Mortality)
SEPSIS (90-Day Mortality)
SEPSIS (Mech. Vent.)
SEPSIS (Median Vaso.)
SEPSIS (Max Vaso.)
HIV (CD4+ below 200)
HIV (Therapy Success)
HIV (Mortality)
HIV (Poor Adherence)
HIV (AIDS Onset)
TIMIT

Fidelity
0.88
0.81
0.88
0.90
0.92
0.93
0.84
0.88
0.93
0.90
0.93
0.85

Table 1: Fidelity of predictions from our trained deep GRU-
RNN and its corresponding decision tree. Fidelity is deﬁned
as the percentage of test examples on which the prediction
made by a tree agrees with the deep model (Craven and
Shavlik 1996). We used 20 hidden GRU states for signal-and-
noise task, 50 states for all others.

jointly-trained deep residual models may provide even better
interpretability.

(a) Signal-and-noise 20+5

(b) In-Hosp. Mort. 50+50

(c) Mech. Vent. 50+50

(d) Stop Phonemes 50+25

Figure 6: Fitness curves for the GRU-HMM, showing predic-
tion quality (AUC) vs. complexity (path length) across range
of regularization strengths λ. Captions show the number of
HMM states plus the number of GRU states. See earlier ﬁg-
ures to compare these GRU-HMM numbers to simpler GRU
and decision tree baselines.

6 Discussion and Conclusion
We have introduced a novel tree-regularization technique that
encourages the complex decision boundaries of any differen-
tiable model to be well-approximated by human-simulatable
functions, allowing domain experts to quickly understand
and approximately compute what the more complex model
is doing. Overall, our training procedure is robust and efﬁ-
cient; future work could continue to explore and increase the

8

stability of the learned models as well as identify ways to
apply our approach to situations in which the inputs are not
inherently interpretable (e.g. pixels in an image).

Across three complex, real-world domains – HIV treat-
ment, sepsis treatment, and human speech processing – our
tree-regularized models provide gains in prediction accuracy
in the regime of simpler, approximately human-simulatable
models. Future work could apply tree regularization to lo-
cal, example-speciﬁc approximations of a loss (Ribeiro,
Singh, and Guestrin 2016) or to representation learning tasks
(encouraging embeddings with simple boundaries). More
broadly, our general training procedure could apply tree-
regularization or other procedure-regularization to a wide
class of popular models, helping us move beyond sparsity
toward models humans can easily simulate and thus trust.

Acknowledgements
MW is supported by the U.S. National Science Foundation.
MCH is supported by Oracle Labs. SP is supported by the
Swiss National Science Foundation project 51MRP0 158328.
The authors thank the EuResist Network for providing HIV
data for this study, and thank Matthieu Komorowski for the
preprocessed sepsis data (Raghu et al. 2017). Computations
were supported by the FAS Research Computing Group at
Harvard and sciCORE (http://scicore.unibas.ch/) scientiﬁc
computing core facility at University of Basel.

References
Adler, P.; Falk, C.; Friedler, S. A.; Rybeck, G.; Scheidegger,
C.; Smith, B.; and Venkatasubramanian, S. 2016. Auditing
black-box models for indirect inﬂuence. In ICDM.
2016. Blackbox and
Audet, C., and Kokkolaras, M.
derivative-free optimization: theory, algorithms and applica-
tions. Springer.
Bahdanau, D.; Cho, K.; and Bengio, Y. 2014. Neural machine
translation by jointly learning to align and translate. arXiv
preprint arXiv:1409.0473.
Balan, A. K.; Rathod, V.; Murphy, K. P.; and Welling, M.
2015. Bayesian dark knowledge. In NIPS.
Che, Z.; Kale, D.; Li, W.; Bahadori, M. T.; and Liu, Y. 2015.
Deep computational phenotyping. In KDD.
Chen, J. H., and Asch, S. M. 2017. Machine learning and pre-
diction in medicinebeyond the peak of inﬂated expectations.
N Engl J Med 376(26):2507–2509.
Cho, K.; Gulcehre, B. v. M. C.; Bahdanau, D.; Schwenk,
F. B. H.; and Bengio, Y. 2014. Learning phrase represen-
tations using RNN encoder–decoder for statistical machine
translation. In EMLNP.
Choi, E.; Bahadori, M. T.; Schuetz, A.; Stewart, W. F.; and
Sun, J. 2016. Doctor AI: Predicting clinical events via recur-
rent neural networks. In Machine Learning for Healthcare
Conference.
Craven, M., and Shavlik, J. W. 1996. Extracting tree-
structured representations of trained networks. In NIPS.
Drucker, H., and Le Cun, Y. 1992. Improving generalization
performance using double backpropagation. IEEE Transac-
tions on Neural Networks 3(6):991–997.

Pedregosa, F.; Varoquaux, G.; Gramfort, A.; Michel, V.; et al.
2011. Scikit-learn: Machine learning in Python. Journal of
Machine Learning Research 12:2825–2830.
Raghu, A.; Komorowski, M.; Celi, L. A.; Szolovits, P.; and
Ghassemi, M. 2017. Continuous state-space models for opti-
mal sepsis treatment-a deep reinforcement learning approach.
In Machine Learning for Healthcare Conference.
Rastegari, M.; Ordonez, V.; Redmon, J.; and Farhadi, A. 2016.
XNOR-Net: ImageNet classiﬁcation using binary convolu-
tional neural networks. In ECCV.
Ribeiro, M. T.; Singh, S.; and Guestrin, C. 2016. Why should
I trust you?: Explaining the predictions of any classiﬁer. In
KDD.
Ross, A.; Hughes, M. C.; and Doshi-Velez, F. 2017. Right
for the right reasons: Training differentiable models by con-
straining their explanations. In IJCAI.
Selvaraju, R. R.; Das, A.; Vedantam, R.; Cogswell, M.;
Parikh, D.; and Batra, D. 2016. Grad-cam: Why did you say
that? visual explanations from deep networks via gradient-
based localization. arXiv preprint arXiv:1610.02391.
Singh, S.; Ribeiro, M. T.; and Guestrin, C. 2016. Programs
as black-box explanations. arXiv preprint arXiv:1611.07579.
Socas, M. E.; Sued, O.; Laufer, N.; Lzaro, M. E.; Mingrone,
H.; Pryluka, D.; Remondegui, C.; Figueroa, M. I.; Cesar, C.;
Gun, A.; Turk, G.; Bouzas, M. B.; Kavasery, R.; Krolewiecki,
A.; Prez, H.; Salomn, H.; Cahn, P.; and de Seroconversin
Study Group, G. A. 2011. Acute retroviral syndrome and
high baseline viral load are predictors of rapid hiv progression
among untreated argentinean seroconverters. Journal of the
International AIDS Society 14(1):40–40.
Sutskever, I.; Vinyals, O.; and Le, Q. V. 2014. Sequence to
sequence learning with neural networks. In NIPS.
Tang, W.; Hua, G.; and Wang, L. 2017. How to train a
compact binary neural network with high accuracy? In AAAI.
Zazzi, M.; Incardona, F.; Rosen-Zvi, M.; Prosperi, M.;
Lengauer, T.; Altmann, A.; Sonnerborg, A.; Lavee, T.;
Sch¨ulter, E.; and Kaiser, R. 2012. Predicting response to
antiretroviral treatment by machine learning: the euresist
project. Intervirology 55(2):123–127.
Zhang, Y.; Lee, J. D.; and Jordan, M. I. 2016. l1-regularized
neural networks are improperly learnable in polynomial time.
In ICML.
Zou, H., and Hastie, T. 2005. Regularization and variable
selection via the elastic net. Journal of the Royal Statistical
Society: Series B (Statistical Methodology) 67(2):301–320.

MIT Press.

I.; Bengio, Y.;

and Courville, A.
http:

Erhan, D.; Bengio, Y.; Courville, A.; and Vincent, P. 2009.
Visualizing higher-layer features of a deep network. Tech-
nical Report 1341, Department of Computer Science and
Operations Research, University of Montreal.
Garofolo, J. S.; Lamel, L. F.; Fisher, W. M.; Fiscus, J. G.;
Pallett, D. S.; Dahlgren, N. L.; and Zue, V. 1993. Timit
acoustic-phonetic continuous speech corpus. Linguistic data
consortium 10(5).
Goodfellow,
Deep Learning.
2016.
//www.deeplearningbook.org.
Han, S.; Pool, J.; Tran, J.; and Dally, W. 2015. Learning
both weights and connections for efﬁcient neural network. In
NIPS.
Hinton, G.; Vinyals, O.; and Dean, J.
2015. Distill-
ing the knowledge in a neural network. arXiv preprint
arXiv:1503.02531.
Hochreiter, S., and Schmidhuber, J. 1997. Long short-term
memory. Neural computation 9(8):1735–1780.
Hu, Z.; Ma, X.; Liu, Z.; Hovy, E.; and Xing, E. 2016. Har-
nessing deep neural networks with logic rules. In ACL.
Johnson, A. E.; Pollard, T. J.; Shen, L.; Lehman, L. H.; Feng,
M.; Ghassemi, M.; Moody, B.; Szolovits, P.; Celi, L. A.; and
Mark, R. G. 2016. MIMIC-III, a freely accessible critical
care database. Scientiﬁc Data 3.
Kingma, D., and Ba, J. 2014. Adam: A method for stochastic
optimization. arXiv preprint arXiv:1412.6980.
Krizhevsky, A.; Sutskever, I.; and Hinton, G. E. 2012. Ima-
geNet classiﬁcation with deep convolutional neural networks.
In NIPS.
Lakkaraju, H.; Bach, S. H.; and Leskovec, J. 2016. Inter-
pretable decision sets: A joint framework for description and
prediction. In KDD.
Langford, S. E.; Ananworanich, J.; and Cooper, D. A. 2007.
Predictors of disease progression in hiv infection: a review.
AIDS Research and Therapy 4(1):11.
Lei, T.; Barzilay, R.; and Jaakkola, T. 2016. Rationalizing
neural predictions. arXiv preprint arXiv:1606.04155.
Lipton, Z. C. 2016. The mythos of model interpretability.
In ICML Workshop on Human Interpretability in Machine
Learning.
Lundberg, S., and Lee, S.-I. 2016. An unexpected unity
among methods for interpreting model predictions. arXiv
preprint arXiv:1611.07478.
Miotto, R.; Li, L.; Kidd, B. A.; and Dudley, J. T. 2016. Deep
patient: An unsupervised representation to predict the future
of patients from the electronic health records. Scientiﬁc
Reports 6:26094.
Ochiai, T.; Matsuda, S.; Watanabe, H.; and Katagiri, S. 2017.
Automatic node selection for deep neural networks using
group lasso regularization. In ICASSP.
Paterson, D. L.; Swindells, S.; Mohr, J.; Brester, M.; Vergis,
E. N.; Squier, C.; Wagener, M. M.; and Singh, N. 2000. Ad-
herence to protease inhibitor therapy and outcomes in patients
with hiv infection. Annals of internal medicine 133(1):21–30.

9

Supplementary Material

A Details for Decision-Tree Training
Training decision trees with post-pruning. Our average path length function Ω(W ) for determining the complexity of a deep
model with parameters W – deﬁned in the main paper in Alg. 1 – assumes that we have a robust, black-box way to train binary
decision-trees called TRAINTREE given a labeled dataset {xn, ˆyn}. For this we use the DecisionTree module distributed in
Python’s sci-kit learn, which optimizes information gain with Gini impurity. The speciﬁc syntax we use (for reproducibility) is:
tree = DecisionTree(min_sample_count=5)
tree.fit(x_train, y_train)
tree = prune_tree(tree, x_valid, y_valid)

The provided keyword options force the tree to have at least 5 examples from the training set in every leaf. We found that tuning
hyperparameters of the TRAINTREE subprocedure, such as the minimum size of a leaf node, to be important for making useful
trees.

Generally, the runtime cost of sklearn’s ﬁtting procedure scales superlinearly with the number of examples N and linearly
with the number of features F – a total complexity of O(F N log(N )). In practice, we found that with N = 1000 examples,
F = 10 features, tree construction takes 15.3 microseconds.

The pruning procedure is a heuristic to create simpler trees, summarized in algorithm 2. After TRAINTREE delivers a working
decision tree, we iterative propose removing each remaining leaf node, accepting the proposal if the squared prediction error on a
validation set improves. This pruning removes sub-trees that don’t generalize to unseen data.

Algorithm 2 Post-pruning for training decision trees.

Require:

T : initial decision tree
ERRONVAL(·) : squared error on validation data

n=1(T (xn) − yn)2

ERRONVAL(T ) (cid:44) (cid:80)N
1: procedure PRUNETREE( T , err )
e ← ERRONVAL(T ).
2:
for node n ∈ SORTLEAFTOROOT(T.nodes) do
3:
4:
5:
6:
7:

T (cid:48) ← REMOVENODE(T, n)
enew ← ERRONVAL(T (cid:48))
if enew < e then T ← T (cid:48)

Return T

Sanity check: Surrogate path length closely follow true path length. Fig. A.1 shows that our surrogate predictor ˆΩ(·) tracks
the true average path length as we train the target predictor ˆy(·, W ) on several different datasets.

Sensitivity to different choices for surrogate training.
In Fig. A.2, we show sample learning curves for variations of methods
for approximating the average path length (also called “node count”) in a decision tree. In blue is the true value. Each of the other
3 lines use the same surrogate model: an MLP with 25 hidden nodes. Increasing its capacity too much, i.e. 100 hidden nodes,
leads to overﬁtting where the surrogate is able to predict the average path length extremely well for a small number of iterations,
while the performance quickly decays. With an MLP of the right capacity, four additional tricks: (1) weight augmentation, (2)
random restarts with an unregularized model, (3) ﬁxed window of data, and (4) surrogate retraining greatly improve the accuracy
of the average path length predictions.

Normally, if our differentiable model is a GRU, we compile examples using the GRU weights at every batch and calculate the
true average path length. This dataset is used to train the surrogate model. If examples are very sparse, surrogate predictions
may be unstable. Augmentation addresses this by randomly sampling weight vectors and computing the average path length
to artiﬁcially create a larger dataset. Early epochs are especially problematic when it comes to lacking data. In addition to
augmentation, we use random restarts to separately train unregularized GRUs (each with different weight initializations) to grow
a dataset of weight vectors prior to training the regularized model.

As the GRU parameters take steps away from their initial values, our examples from those early epochs no longer describe the
current state of the model. Retraining and a ﬁxed window of data address this by re-learning the surrogate function at a ﬁxed
frequency using examples only from the last J epochs. In practice, both the augmentation size, the retraining frequency, and J
are functions of the learning rate and the dataset size. See table B.1 for exact numbers.

10

(a) Path length estimates ˆΩ for 2D Parabola task

(b) Path length estimates ˆΩ for Signal-and-noise HMM task

Figure A.1: True average path lengths (yellow) and surrogate estimates ˆΩ (green) across many iterations of network parameter
training iterations.

Figure A.2: This ﬁgure shows the effects of weight augmentation and retraining. The blue line is the true average path length of
the decision tree at each epoch. All other lines show predicted path lengths using the surrogate MLP. By randomly sampling
weights and intermittently retraining the surrogate, we signiﬁcantly improve the ability of the surrogate model to track the
changes in the ground truth.

11

B Experimental Protocol
See table B.1 for model hyperparameters for each dataset. For standard recurrent models such as HMM or GRU, the decision trees
were trained on the input data and the predictions of the model’s output node. For our deep residual GRU-HMM, the decision
trees were trained on the predictions on the GRU’s output node only. For both synthetic and real-world datasets, our surrogate
to the tree loss is a multilayer perceptron with 1 hidden layer of 25 nodes. For each dataset, when we investigated several
regularization strengths (λ), we initialize the model weights using the same random seed. We use the Adam algorithm (Kingma
and Ba 2014) for all optimization.

Dataset
parabola
signal-and-noise HMM
HIV
SEPSIS
TIMIT

n/a
100
53 236
11 786
6 303

Total Num. Sequences Avg. seq. length Learning Rate Batch size Minimum Leaf Sample

Post-pruned Epochs (Model) Epochs (Surrogate) Retraining Freq.

n/a
50
14
15
614

1e-2
1e-2
1e-3
1e-3
1e-3

32
10
256
256
256

0
25
1 000
1 000
5 000

N
Y
Y
Y
Y

250
300
300
300
200

500
1000
5000
5000
5000

100
50
25
25
25

J
n/a
50
100
100
100

Table B.1: Dataset summaries and training parameters used in our experiments.

B.1

2D Parabola

Dataset generation. The training data consists of 2D input points whose two-class decision boundary is roughly shaped like
a parabola. The true decision function is deﬁned by y = 5 ∗ (x − 0.5)2 + 0.4. We sampled all 200 input points xn uniformly
within the unit square [0, 1] × [0, 1] and labeled those above the decision function as positive. To add randomness, we ﬂipped
10% of the points in the region near the boundary between y = 5 ∗ (x − 0.5)2 + 0.2 and y = 5 ∗ (x − 0.5)2 + 0.6.

Regularization strengths. Tested values of regularization strength parameter λ: 0.1, 0.5, 1, 5, 10, 25, 50, 75, 100, 250, 500,
750, 1 000, 2 500, 5 000, 7 500, 10 000, 25 000, 50 000, 75 000, 100 000

B.2 Signal-and-noise HMM

Dataset generation The transition and emission matrices describing the generative process used to create the signal-and-noise
HMM are shown in Fig. B.1. The output yn at every timestep is created by concatenating a one-hot vector of an emitted state and
the 7-dimensional binary input vector. We emphasize that to output 1, the HMM must be in state 1 and the ﬁrst input feature
must be 1.

(cid:33)

(cid:32) .5 .5 .5 .5 0 0 0
.5 .5 .5 .5 .5 0 0
.5 .5 .5 0 .5 0 0
.5 .5 .5 0 0 .5 0
.5 .5 .5 0 0 0 .5

(cid:33)

(cid:32) .5 .5 .5 0 0 0 0
0 .5 .5 .5 0 0 0
0 0 .5 .5 .5 0 0
0 0 0 .5 .5 .5 0
0 0 0 0 .5 .5 .5

(a)

(c)

(cid:33)

(cid:32) .7 .3 0

0 0
.5 .25 .25 0 0
0 .25 .5 .25 0
0 0 .25 .25 .5
0 .5 .5
0 0

(b)

(cid:33)

(cid:32) .2 .2 .2 .2 .2
.2 .2 .2 .2 .2
.2 .2 .2 .2 .2
.2 .2 .2 .2 .2
.2 .2 .2 .2 .2

(d)

Figure B.1: Emission (5 states vs 7 features) and transition probabilities for the signal HMM (a, b) and noise HMM (c, d).

Training Details. With synthetic datasets, we explore (1, 5, 6, 10, 15, 20) GRU nodes, (5, 6, 20) HMM states, and GRU-HMMs
with 5 HMM states and (1, 5, 10, 15) GRU nodes.

B.3 Sepsis

B.4 HIV

Training Details. We explore (1, 5, 6, 10, 11, 15, 20, 25, 26, 30, 35, 50, 51, 55, 60, 75, 100) GRU nodes, (5, 6, 10, 11, 15, 20,
25, 26, 30, 35, 50, 51, 55, 60, 75, 100) HMM states, and GRU-HMMs with (5, 10, 25, 50) HMM states and (1, 5, 10, 25, 50)
GRU nodes. The input features are z-scored prior to training.

Training Details. We explore (1, 5, 6, 10, 11, 15, 20, 25, 26, 30, 35, 50, 51, 55, 60, 75) GRU nodes, (5, 6, 10, 11, 15, 20, 25,
26, 30, 35, 50, 51, 55, 60, 75) HMM states, and GRU-HMMs with (5, 10, 25) HMM states and (1, 5, 10, 25, 50) GRU nodes.

12

B.5 TIMIT
Training Details. We explore (1, 5, 6, 10, 11, 15, 20, 25, 26, 30, 35, 50, 51, 55, 60, 75) GRU nodes, (5, 6, 10, 11, 15, 20, 25,
26, 30, 35, 50, 51, 55, 60, 75) HMM states, and GRU-HMMs with (5, 10, 25) HMM states and (1, 5, 10, 25, 50) GRU nodes.
Like Sepsis, the input features are z-scored prior to training.

C Extended Results
For signal-to-noise HMM, Sepsis, and TIMIT, we ﬁrst show expanded versions of the ﬁtness trace plots and the tree visualizations.
For Sepsis and HIV, we show the additional output dimensions not in the paper.

We also include tables of the test AUC performance for our synthetic and real data sets over a vast array of parameter settings
(GRU node counts, HMM state counts, regularization strengths). Consistent with the common wisdom of training deep models,
we found that larger models, with regularization, tended to perform the best.

C.1 Signal-and-noise HMM: Plots

(a) GRU: Signal-and-noise HMM

(b) GRUHMM: Signal-and-noise HMM

Figure C.1: Performance and complexity trade-offs using L1, L2, and Tree regularization on (a) GRU and (b) GRU-HMM
performance on the Signal-and-noise HMM dataset. Note the differences in scale.

13

C.2 Signal-and-noise HMM: Tree Visualization

(a) GRU:0.1

(b) GRU:0.1

(c) GRU:1.0

(d) GRU:10

(e) GRU:20

(f) GRU:100

(g) GRU::400

(h) GRU:800

(i) GRU:1 000

(j) GRU:10 000

Figure C.2: Decision trees trained under varying tree regularization strengths for GRU models on the signal-and-noise HMM
dataset dataset. As the tree regularization increases, the number of nodes collapses to a single one. If we focus on (h), we see that
the tree resembles the ground truth data-generating function quite closely.

14

C.3 Signal-and-noise HMM: AUCs

Model AUC (Test) Average Path Length
logreg
decision tree
hmm (5)
hmm (20)
gru (1)
gru (5)
gru (6)
gru (10)
gru (15)
gru (20)
grutree (20/10.0)
grutree (20/200.0)
grutree (20/7 000.0)
grutree (20/9 000.0)
grutree (20/10 000.0)
gruhmm (5/1)
gruhmm (5/5)
gruhmm (5/10)
gruhmm (5/15)
gruhmmtree (5/15/1.0)
gruhmmtree (5/15/10.0)
gruhmmtree (5/15/50.0)
gruhmmtree (5/15/200.0)
gruhmmtree (5/15/500.0)
gruhmmtree (5/15/900.0)
gruhmmtree (5/15/2 000.0)
gruhmmtree (5/15/5 000.0)
gruhmmtree (5/15/7 000.0)

17.302
29.4424
25.5736
27.2784
1.8876
26.304
27.2118
28.563
30.7172
37.0844
28.1850
26.8140
22.4646
9.1127
3.4400
18.2202
27.258
30.9624
36.7188
24.115
16.883
12.573
8.926
5.231
3.942
2.694
1.896
0.000

0.91832
0.92050
0.93591
0.94177
0.65049
0.94812
0.94883
0.94962
0.93982
0.93368
0.94226
0.94806
0.94431
0.90555
0.82770
0.95146
0.95584
0.95773
0.94857
0.95382
0.95180
0.95258
0.95145
0.95769
0.95708
0.95648
0.95399
0.93591

Parameter Count
6
-
71
581
29
205
264
560
1 065
1 720
1 720
1 720
1 720
1 720
1 720
100
276
631
1 136
1 136
1 136
1 136
1 136
1 136
1 136
1 136
1 136
1 136

Table C.1: Performance metrics across models on the signal-and-noise HMM dataset. The parameter count is included as a
measure of the model capacity.

15

C.4 Sepsis: Plots

(a) In-Hospital Mortality

(b) 90-Day Mortality

(c) Mechanical Ventilation

(d) Median Vasopressor

(e) Max Vasopressor

Figure C.3: Performance and complexity trade-offs using L1, L2, and Tree regularization on GRU performance on the Sepsis
dataset.

C.5 Sepsis: Tree Visualization

(a) In-Hospital Mortality

(b) 90-Day Mortality

(c) Mechanical Ventilation (d) Median Vasopressor

(e) Max Vasopressor

Figure C.4: Decision trees trained using λ = 800.0 for a GRU model using Sepsis. The 5 output dimensions are jointly trained.

16

C.6 Sepsis: AUCs

Median
Vasopressor
0.7392
0.7439
0.7295
0.7409
0.7346
0.7371
0.7313
0.7316
0.7201
0.7335
0.7434
0.7408
0.7414
0.7866
0.7983
0.8020
0.8018
0.8113
0.8063
0.8095
0.8054
0.8006
0.7977
0.7873
0.7812
0.7845
0.7813
0.7988
0.7676
0.7616
0.6668
0.6230
0.5026
0.7478
0.7418
0.7353
0.7120
0.8009
0.7991
0.7955
0.7814
0.8098
0.8098
0.8055
0.7903
0.8236
0.8225
0.8186
0.8106
0.8228
0.8220
0.8205
0.8056
0.7854
0.7914
0.7922
0.7832
0.8092
0.7909
0.7882
0.8013
0.802
0.7881
0.7301

Max
Vasopressor
0.7392
0.7427
0.7290
0.7405
0.7341
0.7364
0.7310
0.7311
0.7195
0.7328
0.7430
0.7403
0.7411
0.7862
0.7979
0.8021
0.8017
0.8114
0.8061
0.8091
0.8051
0.8000
0.7975
0.7867
0.7810
0.7840
0.7813
0.7986
0.7678
0.7619
0.6530
0.6138
0.5057
0.7477
0.7419
0.7352
0.7121
0.8006
0.7988
0.7952
0.7811
0.8097
0.8096
0.8054
0.7903
0.8235
0.8225
0.8184
0.8103
0.8226
0.8219
0.8203
0.8055
0.7849
0.7906
0.7918
0.7824
0.8091
0.7905
0.7873
0.8011
0.8024
0.7882
0.7299

Total Average
Path Length
32.489
76.242
35.125
57.629
61.832
62.353
63.415
65.164
65.474
66.317
72.553
80.415
31.816
45.395
58.102
61.025
61.214
62.029
72.854
74.091
76.543
87.422
94.161
91.797
82.019
73.767
65.035
61.012
54.177
48.206
26.085
20.214
13.383
41.583
61.041
65.955
70.534
47.639
63.627
68.215
71.572
50.902
63.522
70.919
71.297
51.794
64.223
72.480
79.127
64.229
69.281
85.503
101.637
84.188
77.815
71.719
69.715
66.9
63.703
60.949
54.751
44.868
27.836
0.0

Parameter
Count

180
-
405
860
1 365
1 920
2 525
3 180
3 885
6 300
11 325
17 600
117
645
1 440
2 385
3 480
4 725
6 120
7 665
13 200
25 425
41 400
41 400
41 400
41 400
41 400
41 400
41 400
41 400
41 400
41 400
41 400
722
1 517
4 802
13 277
1 050
1 845
5 130
13 605
1 505
2 300
5 585
14 060
3 170
3 965
7 250
11 025
6 945
7 740
11 025
19 500
19 500
19 500
19 500
19 500
19 500
19 500
19 500
19 500
19 500
19 500
19 500

Model
logreg
decision tree
hmm (5)
hmm (10)
hmm (15)
hmm (20)
hmm (25)
hmm (30)
hmm (35)
hmm (50)
hmm (75)
hmm (100)
gru (1)
gru (5)
gru (10)
gru (15)
gru (20)
gru (25)
gru (30)
gru (35)
gru (50)
gru (75)
gru (100)
grutree (100/0.01)
grutree (100/1.0)
grutree (100/8.0)
grutree (100/20.0)
grutree (100/70.0)
grutree (100/300.0)
grutree (100/2 000.0)
grutree (100/5 000.0)
grutree (100/7 000.0)
grutree (100/8 000.0)
gruhmm (1/5)
gruhmm (1/10)
gruhmm (1/25)
gruhmm (1/50)
gruhmm (5/5)
gruhmm (5/10)
gruhmm (5/25)
gruhmm (5/50)
gruhmm (10/5)
gruhmm (10/10)
gruhmm (10/25)
gruhmm (10/50)
gruhmm (25/5)
gruhmm (25/10)
gruhmm (25/25)
gruhmm (25/50)
gruhmm (50/5)
gruhmm (50/10)
gruhmm (50/25)
gruhmm (50/50)
gruhmmtree (50/50/0.5)
gruhmmtree (50/50/20.0)
gruhmmtree (50/50/50.0)
gruhmmtree (50/50/200.0
gruhmmtree (50/50/300.0)
gruhmmtree (50/50/600.0
gruhmmtree (50/50/1 000.0)
gruhmmtree (50/50/3 000.0)
gruhmmtree (50/50/4 000.0)
gruhmmtree (50/50/7 000.0)
gruhmmtree (50/50/9 000.0)

In-Hospital
Mortality
0.6980
0.7017
0.7128
0.7227
0.7216
0.7233
0.7147
0.7164
0.7177
0.7267
0.7254
0.7294
0.3897
0.7357
0.7488
0.7529
0.7535
0.7578
0.7602
0.7522
0.7431
0.7408
0.7325
0.7276
0.7147
0.7232
0.7123
0.7360
0.7210
0.7230
0.6546
0.6063
0.5298
0.4222
0.4007
0.4019
0.3999
0.7430
0.7408
0.7365
0.7222
0.7468
0.7490
0.7422
0.7254
0.7580
0.7592
0.7525
0.7604
0.7655
0.7648
0.7600
0.7412
0.7432
0.7435
0.7384
0.747
0.7539
0.7435
0.7575
0.7396
0.7432
0.7308
0.7132

90-Day
Mortality
0.6986
0.7016
0.7095
0.7297
0.7282
0.7350
0.7321
0.7297
0.7237
0.7357
0.7361
0.7354
0.6400
0.7296
0.7445
0.7450
0.7497
0.7486
0.7508
0.7483
0.7390
0.7239
0.7273
0.7314
0.7040
0.7203
0.7085
0.7376
0.7197
0.7167
0.6552
0.6554
0.5242
0.6472
0.6295
0.6207
0.6162
0.7372
0.7320
0.7279
0.7107
0.7467
0.7478
0.7407
0.7221
0.7568
0.7563
0.7508
0.7583
0.7592
0.7568
0.7555
0.7373
0.7492
0.747
0.7548
0.7502
0.7623
0.7453
0.7502
0.7484
0.7511
0.7477
0.7319

Mechanical
Ventilation
0.8242
0.8509
0.6979
0.8237
0.8188
0.8218
0.8089
0.8099
0.8095
0.8373
0.8059
0.8129
0.4761
0.8795
0.8892
0.8912
0.8887
0.8902
0.8927
0.8900
0.8895
0.8837
0.8781
0.8776
0.8741
0.8763
0.8733
0.8813
0.8681
0.8335
0.6752
0.6565
0.5025
0.4678
0.4730
0.4773
0.4772
0.8798
0.8819
0.8776
0.8660
0.8949
0.8958
0.8916
0.8824
0.8941
0.8945
0.8912
0.8954
0.9006
0.9003
0.8981
0.8910
0.879
0.8826
0.8914
0.8767
0.8942
0.8821
0.8739
0.8926
0.8915
0.8813
0.8261

17

Table C.2: Performance metrics for multi-dimensional classiﬁcation on a held-out portion of the Sepsis dataset. Total Average
Path Length refers to the summed average path lengths across the 5 output dimensions. Refer to Fig. C.3 for average-path-lengths
split across dimensions.

C.7 HIV:Plots

(a) Therapy Success

(b) CD4+ ≤ 200 cells/ml

(c) Adherence

(d) Mortality

(e) Onset of AIDS

Figure C.5: Performance and complexity trade-offs using L1, L2, and Tree regularization on GRU for the HIV dataset. The 5
outputs shown here were trained jointly.

18

C.8 HIV: AUCs

Model
logreg
decision tree
hmm (5)
hmm (10)
hmm (25)
hmm (50)
hmm (75)
hmm (100)
gru (5)
gru (25)
gru (50)
gru (75)
gru (100)
grutree (100/0.01)
grutree (100/1.0)
grutree (100/20.0)
grutree (100/70.0)
grutree (100/300.0)
grutree (100/2 000.0)
grutree (100/5 000.0)
grutree (100/7 000.0)
grutree (100/8 000.0)
gruhmm (5/5)
gruhmm (5/10)
gruhmm (5/25)
gruhmm (5/50)
gruhmm (10/5)
gruhmm (10/10)
gruhmm (10/25)
gruhmm (10/50)
gruhmm (25/10)
gruhmm (25/25)
gruhmm (25/50)
gruhmm (50/10)
gruhmm (50/25)
gruhmm (50/50)
gruhmmtree (50/50/0.5)
gruhmmtree (50/50/50.0)
gruhmmtree (50/50/200.0
gruhmmtree (50/50/600.0
gruhmmtree (50/50/1 000.0)
gruhmmtree (50/50/4 000.0)
gruhmmtree (50/50/7 000.0)

Poor

Adherence Mortality
0.6884
0.7100
0.7106
0.7287
0.7243
0.7181
0.7244
0.7261
0.6457
0.7516
0.7011
0.7623
0.7340
0.7176
0.7134
0.7157
0.7485
0.7251
0.7030
0.6549
0.6167
0.5874
0.6430
0.6708
0.6951
0.6810
0.7018
0.7190
0.7264
0.7570
0.7462
0.7435
0.7484
0.7437
0.7380
0.7317
0.7432
0.7426
0.7461
0.7467
0.7375
0.7242
0.7280

0.7031
0.7601
0.7611
0.7627
0.7627
0.7639
0.7661
0.7657
0.6814
0.7986
0.8290
0.8514
0.8216
0.7948
0.7997
0.8066
0.8210
0.8178
0.8169
0.7582
0.7524
0.7412
0.6647
0.6720
0.6981
0.7002
0.7147
0.7378
0.7457
0.7522
0.7861
0.8102
0.7714
0.7668
0.7557
0.7684
0.7692
0.8152
0.8308
0.8820
0.8951
0.8461
0.8462

CD4+
Count ≤ 200
0.5741
0.5937
0.6012
0.6237
0.6327
0.6412
0.6294
0.6287
0.6695
0.7073
0.6995
0.7117
0.6981
0.7046
0.7138
0.7216
0.7413
0.7264
0.6342
0.6142
0.5740
0.5003
0.5418
0.5879
0.6476
0.6760
0.7049
0.7136
0.7217
0.7224
0.7152
0.7425
0.7501
0.7813
0.7824
0.7920
0.8790
0.8914
0.8767
0.8821
0.8739
0.8515
0.8313

Therapy
Success
0.6092
0.6286
0.6265
0.6409
0.6384
0.6370
0.6518
0.6524
0.6834
0.6991
0.7054
0.7490
0.7235
0.6803
0.6892
0.7114
0.7060
0.6746
0.6627
0.6352
0.5634
0.5027
0.6479
0.6517
0.6955
0.7114
0.7208
0.7578
0.7951
0.8234
0.8217
0.8186
0.8006
0.8260
0.8215
0.8007
0.7804
0.7979
0.8032
0.8293
0.7882
0.8030
0.7484

Total Average
Path Length
38.942
62.150
41.864
46.309
56.159
69.014
70.476
71.159
58.347
60.072
67.513
64.870
67.183
91.020
86.774
76.025
68.952
54.058
49.839
23.895
15.283
7.391
67.619
72.137
68.200
71.518
64.852
73.252
70.884
69.726
68.241
79.261
76.174
70.081
88.617
97.864
73.168
67.729
59.025
52.128
48.247
14.868
1.836

Parameter
Count

1155
-
865
1780
4825
10900
18225
26800
1310
8050
19850
35400
54700
54700
54700
54700
54700
54700
54700
54700
54700
54700
2175
3090
6135
12210
3635
4550
7595
13670
9830
12875
18950
21630
24675
30750
30750
30750
30750
30750
30750
30750
30750

Table C.3: Performance metrics for multi-dimensional classiﬁcation on a held-out portion of the HIV dataset. Total Average Path
Length refers to the summed average path lengths across the output dimensions.

19

C.9 TIMIT:Plots/Tree Visualization

(a) TIMIT Stop Phonemes

20

Figure C.6: (a) Performance and complexity trade-offs using L1, L2, and Tree regularization for GRU models on TIMIT. (b)
Decision tree trained using λ = 500.0 tree regularization on GRU.

(b) GRU:500

C.10 TIMIT:AUCs

Model
logreg
decision tree
hmm (5)
hmm (10)
hmm (25)
hmm (50)
hmm (75)
gru (1)
gru (5)
gru (10)
gru (25)
gru (50)
gru (75)
gruhmm (1/5)
gruhmm (1/10)
gruhmm (1/25)
gruhmm (5/5)
gruhmm (5/10)
gruhmm (5/25)
gruhmm (10/5)
gruhmm (10/10)
gruhmm (10/25)
gruhmm (25/5)
gruhmm (25/10)
gruhmm (25/25)
gruhmm (50/5)
gruhmm (50/10)
gruhmm (50/25)
grutree (75/0.01)
grutree (75/0.1)
grutree (75/0.5)
grutree (75/2.0)
grutree (75/5.0)
grutree (75/10.0)
grutree (75/100.0)
grutree (75/500.0)
grutree (75/700.0)
grutree (75/800.0)
grutree (75/1 000.0)
grutree (75/6 000.0)
grutree (75/7 000.0)
gruhmmtree (50/25/0.1)
gruhmmtree (50/25/1.0)
gruhmmtree (50/25/6.0)
gruhmmtree (50/25/20.0)
gruhmmtree (50/25/30.0)
gruhmmtree (50/25/70.0)
gruhmmtree (50/25/100.0)
gruhmmtree (50/25/500.0)
gruhmmtree (50/25/700.0)
gruhmmtree (50/25/1 000.0)
gruhmmtree (50/25/3 000.0)
gruhmmtree (50/25/4 000.0)
gruhmmtree (50/25/7 000.0)
gruhmmtree (50/25/9 000.0)
gruhmmtree (50/25/10 000.0)

AUC
0.7747
0.8668
0.8900
0.8981
0.9129
0.9189
0.9251
0.9169
0.9451
0.9509
0.9547
0.9578
0.9620
0.9419
0.9535
0.9636
0.9569
0.9575
0.9603
0.9626
0.9641
0.9651
0.9635
0.9657
0.9663
0.9676
0.9679
0.9685
0.9517
0.9466
0.9367
0.9311
0.9302
0.9288
0.8911
0.8998
0.8628
0.7471
0.7082
0.5441
0.5088
0.9507
0.9465
0.9515
0.9449
0.9482
0.9460
0.9470
0.9401
0.9352
0.9390
0.9280
0.9311
0.9290
0.9134
0.9125

Average Path Length
23.460
59.2061
51.911
56.273
57.602
63.752
71.473
42.602
49.275
60.079
62.051
64.957
68.998
54.9723
53.5642
57.3290
55.9531
57.6199
59.9925
57.0652
60.7877
61.0018
57.5288
60.5212
65.0161
62.2378
65.1191
67.4301
66.2801
62.4316
60.8764
58.3659
55.7588
46.6616
40.1123
28.4240
25.136
22.6671
17.1523
11.1108
8.9910
69.1110
67.5773
65.1494
64.0072
62.5406
58.0111
51.2417
42.1882
40.1281
38.0072
25.9120
21.7170
10.1122
1.0563
0.0000

Parameter Count
27
-
295
640
1 975
5 200
9 675
86
490
1 130
3 950
11 650
23 100
381
726
2601
785
1 130
2 465
1 425
1 770
3 105
4 245
4 590
5 925
11 945
12 290
13 625
23 100
23 100
23 100
23 100
23 100
23 100
23 100
23 100
23 100
23 100
23 100
23 100
23 100
13 625
13 625
13 625
13 625
13 625
13 625
13 625
13 625
13 625
13 625
13 625
13 625
13 625
13 625
13 625

21

Table C.4: Performance metrics across models on a held-out portion of the TIMIT dataset.

D GRU-HMM: Deep Residual Timeseries Model
Hidden Markov Model For our purposes, Hidden Markov Models (HMMs) can be viewed as stochastic RNNs which can
be interpreted as probabilistic generative models. In this work, we consider an HMM to generate a latent variable sequence
z = [z1, . . . zT ] via a Markov chain, where each latent indicates one of K possible discrete states: zt ∈ {1, ..., K}. This state
sequence is then used to jointly produce the “data” xt and “outcomes” yt observed at each timestep. The joint distribution over
z, x, y factorizes as:

p(z, y) = π0(z0)

p(zt|zt−1, A) · p(xt|zt, φ)Bern(yt|σ(

wkδk(zt))),

(6)

T
(cid:89)

t=1

(cid:88)

k

where A is a transition matrix such that Ai,j = Pr(zt = i|zt−1 = j), π0 = p(z0) is the initial state distribution, {φk}K
emission parameters that generate data. We can then apply the same objective as above for training.

k=1 are the

GRU-HMM: Modeling the residuals of an HMM. We now consider an additional model, the GRU-HMM, designed for
interpretability. The idea is to use a GRU to to model the residual errors when predicting the binary target via the HMM
belief states. We can further penalize the complexity of the GRU predictions via our tree regularization, so that higher-quality
predictions do not come at the price of a much less interpretable model.

Figure D.1: Deep residual model: GRU-HMM. The orange triangle indicates the output used in surrogate training for tree
regularization.

We train the deep residual model on the same suite of synthetic and real world datasets. See Tables C.1, C.2, C.4 for a
comparison of GRU-HMM with vanilla GRU and HMM models under different regularization and expressiveness parameters.
We can see that across the datasets, deep residual models perform around 1% better than their vanilla equivalents with roughly
the same number of model parameters.

By nature of being a residual model, decision trees were trained only on the GRU output node, leaving the HMM unconstrained.
See Figure D.1 for a pictoral representation. Similar to what we did for GRU models, ﬁgures C.1b, D.2 compare model
performance as the λ parameter for L1, L2, and Tree regularization increase. We can see a similar albeit less pronounced effect
where Tree regularization dominates other methods in low node count regions. It is important to notice the range of the AUC axis
in these ﬁgures, where the worst the residual model can performance is the HMM-only AUC. Figure D.3 show the regularized
trees produced by the GRU-HMM. Although they share some structure with Figure C.4, there are important distinctions that
encourage us to conclude that the GRU in a residual models performs a different role than when trained alone.

22

D.1 GRU-HMM: Sepsis Plots

(a) In-Hospital Mortality

(b) 90-Day Mortality

(c) Mechanical Ventilation

(d) Median Vasopressor

(e) Max Vasopressor

Figure D.2: Performance and complexity trade-offs using L1, L2, and Tree regularization on GRU-HMM performance on the
Sepsis dataset.

D.2 GRU-HMM: Sepsis Tree Visualization

(a) In-Hospital Mortality

(b) 90-Day Mortality

(c) Mechanical Ventilation (d) Median Vasopressor

(e) Max Vasopressor

Figure D.3: Decision trees trained using Tree regularization (λ = 2000.0) from GRU-HMM predictions on the Sepsis dataset.

23

D.3 GRU-HMM: HIV Plots/Tree Visualization

(a) GRU-HMM: CD4+ ≤ 200 cells/ml

(b) GRU-HMM: CD4+ ≤ 200 cells/ml

Figure D.4: HIV task: Study of different regularization techniques for GRU-HMM model with 75 GRU nodes and 25 HMM
states, trained to predict whether CD4+ ≤ 200 cells/ml. (a) Example decision tree for λ = 1000.0. (b) Example decision tree for
λ = 3000.0. The tree in (b) is slightly smaller than the tree in (a) as a result of the regularisation.

D.4 GRU-HMM: TIMIT Plots/Tree Visualization

(a) GRU-HMM: Stop vs Non-Stop

(b) GRU-HMM: Stop vs Non-Stop

(c) GRU-HMM: Stop vs Non-Stop

Figure D.5: TIMIT task: Study of different regularization techniques for GRU-HMM model with 75 GRU nodes and 25 HMM
states, trained to predict STOP phonemes. (a) Tradeoff curves showing how AUC predictive power and decision-tree complexity
evolve with increasing regularization strength under L1, L2, or Tree regularization. (b) Example decision tree for λ = 3000.0.
(c) Example decision tree for λ = 7000.0. When comparing with ﬁgure C.6b, this tree is signiﬁcantly smaller, suggesting that
the GRU performs a different role in the residual model.

24

E Runtime comparisons
Training Time for Tree-Regularized Models. Table E.1 shows the wall time for training one epoch of each of the models
presented in this paper using each of the datasets. Please note that the wall times for GRU-TREE and GRU-HMM-TREE include
the cost of surrogate training. If the retraining frequency is small, then the amortized cost should be small.

Epoch Time (Sec.)
Dataset
Model
16.66 ± 2.53
Signal-and-noise HMM HMM
30.48 ± 1.92
Signal-and-noise HMM GRU
50.40 ± 5.56
Signal-and-noise HMM GRU-HMM
43.83 ± 3.84
Signal-and-noise HMM GRU-TREE
Signal-and-noise HMM GRU-HMM-TREE 73.24 ± 7.86
589.80 ± 24.11
HMM
SEPSIS
822.27 ± 11.17
GRU
SEPSIS
1 666.98 ± 147.00
GRU-HMM
SEPSIS
2 015.15 ± 388.12
GRU-TREE
SEPSIS
GRU-HMM-TREE 2 443.66 ± 351.22
SEPSIS
1 668.96 ± 126.96
HMM
TIMIT
2 116.83 ± 438.83
GRU
TIMIT
3207.16 ± 651.85
GRU-HMM
TIMIT
3 977.01 ± 812.11
GRU-TREE
TIMIT
GRU-HMM-TREE 4 601.44 ± 805.88
TIMIT

Table E.1: Training time for recurrent models measured against all datasets used in this paper. Epoch time denotes the number of
seconds it took for a single pass through all the training data. The epoch times for GRU-TREE and GRU-HMM-TREE include
surrogate training expenses. If we retrain sparsely, then the cost of surrogate training is amortized and the epoch time for GRU
and GRU-TREE, GRU-HMM and GRU-HMM-TREE are approximately the same. To measure epoch time, we used 10 HMM
states, 10 GRU states, and 5 of each for GRU-HMM models. We trained the surrogate model for 5000 epochs. These tests were
run on a single Intel Core i5 CPU.

25

F Extended Stability Tests
In the paper, we noted that decision trees are stable over multiple run. Here, we show that using the signal-and-noise HMM dataset,
10 independent runs with random initializations and λ = 1000.0 produce either the same or comparable trees. Additionally, we
show that with weak regularization (λ = 0.01), the variability of the learned decision trees is high. Figures F.1, F.2 include
examples of such trees on the signal-and-noise dataset. Similar results are found for real-world datasets.

(a) 7/10 Runs

(b) 2/10 Runs

(c) 1/10 Runs

Figure F.1: Decision trees from 10 independent runs on the signal-and-noise HMM dataset with λ = 1000.0. Seven of the ten
runs resulted in a tree of the same structure. The other three trees are similar, often having additional subtrees but sharing the
same splits and features.

(a)

(b)

(c)

(d)

Figure F.2: Decision trees from 10 independent runs on the signal-and-noise HMM dataset with λ = 0.01. With low regularization,
the variance in tree size and shape is high.

26

