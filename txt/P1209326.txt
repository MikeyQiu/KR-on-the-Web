AUTOMATIC PULMONARY LOBE SEGMENTATION USING DEEP LEARNING

Hao Tang∗†‡, Chupeng Zhang∗†‡, Xiaohui Xie†

†Department of Computer Science, University of California, Irvine
‡Deep Voxel Inc., 3200 Park Center Dr, Costa Mesa

9
1
0
2
 
r
p
A
 
0
1
 
 
]

V
C
.
s
c
[
 
 
3
v
9
7
8
9
0
.
3
0
9
1
:
v
i
X
r
a

ABSTRACT

Pulmonary lobe segmentation is an important task for pul-
monary disease related Computer Aided Diagnosis systems
(CADs). Classical methods for lobe segmentation rely on
successful detection of ﬁssures and other anatomical infor-
mation such as the location of blood vessels and airways.
With the success of deep learning in recent years, Deep Con-
volutional Neural Network (DCNN) has been widely applied
to analyze medical images like Computed Tomography (CT)
and Magnetic Resonance Imaging (MRI), which, however,
requires a large number of ground truth annotations. In this
work, we release our manually labeled 50 CT scans which are
randomly chosen from the LUNA16 dataset and explore the
use of deep learning on this task. We propose pre-processing
CT image by cropping region that is covered by the con-
vex hull of the lungs in order to mitigate the inﬂuence of
noise from outside the lungs. Moreover, we use a hybrid
loss function with dice loss to tackle extreme class imbalance
issue and focal loss to force model to focus on voxels that
are hard to be discriminated. To validate the robustness and
performance of our proposed framework trained with a small
number of training examples, we further tested our model
on CT scans from an independent dataset. Experimental re-
sults show the robustness of the proposed approach, which
consistently improves performance across different datasets
by a maximum of 5.87% as compared to a baseline model.
The annotations are public available https://github.
com/deep-voxel/automatic_pulmonary_lobe_
segmentation_using_deep_learning/ and are for
non-commercial use only.

Index Terms— Pulmonary Lobe Segmentation, Deep

Learning, Computed Tomography

1. INTRODUCTION

Lung cancer has been the leading cause of all cancer-related
disease during the past years [1]. Segmentation of pulmonary
lobe based on Computed Tomography (CT) is an important
task for Computer Aided Diagnosis systems (CADs). Pul-
monary lobe segmentation is relevant in a wide range of

∗These authors have contributed equally to this work.

clinical applications. The location and distribution of pul-
monary disease can be a signiﬁcant factor in determining the
most suitable treatment. According to [2], locally distributed
emphysema can be treated more effectively by lobar vol-
ume resection than homogeneously distributed emphysema.
Another application is pulmonary nodule detection where
detecting pulmonary nodule in its early stage is critical for a
good prognosis of the disease. Recent success in deep learn-
ing especially the use of Deep Convolutional Neural Network
(DCNN) has accelerated the development of automatic pul-
monary nodule detection and classiﬁcation system, such as
[3, 4], which can be used to help radiologist and reduce their
labor work. Precise segmentation of lung lobes can be used to
generate automatic electronic diagnosis report since the rough
location of nodules are required and the precise coordinate
information is rarely used in most medical institutes.

Human lungs are composed of ﬁve lobes (two in the left
lung and three in the right lung). The upper lobe and lower
lobe of left lung are separated by the major ﬁssures (oblique
ﬁssure). In the right lung, there are three lobes, namely upper
lobe, middle lobe and lower lobe. The upper lobe and middle
lobe are divided by the minor ﬁssure (horizontal ﬁssure) while
the major ﬁssure (oblique ﬁssure) separates the lower lobe
from the rest of the lung.

Methods for pulmonary lobe segmentation have been fo-
cused on unsupervised models using classical computer vi-
sion techniques which usually include detecting ﬁssures, lo-
cating bronchi and vessels, such as [5, 6]. More recently, FJS
Bragman et al. applied probabilistic model in enhanced ﬁs-
sure detection using ﬁssure prior which yields accurate results
under various ﬁssure incompleteness. However, the attempt
of using deep learning in this task is still rare [7] because of
the need for a large number of annotated training examples.
Moreover, publicly available annotations for pulmonary lobe
segmentation can hardly be found for supervised training of
deep neural network.

In this work, we collaborate with our radiologist on man-
ually creating and releasing reference annotations from a ran-
domly chosen subset from the LUNA16 [8]. Next, we present
a framework using DCNN that can be trained effectively and
robustly with a small number of training examples.
In or-
der to further validate the generalization ability and robust-
ness of the trained deep neural net, we annotated 10 more

CT scans from Tianchi dataset as a holdout test set. Experi-
mental results show the proposed framework generalize well
to CT scans collected from different sources, which yields a
maximum of 5.87% improvement as compared to a baseline
model.

Our contributions of this work are summarized as below:
a). We propose pre-processing CT image by cropping re-
gion that is covered by the convex hull of the lungs in or-
der to mitigate the inﬂuence of noise outside the lungs. We
use a hybrid loss function with dice loss to tackle extreme
class imbalance issue and focal loss to force model to focus
on voxels that are hard to be discriminated, similar to [9]. This
achieves the state-of-art averaged dice coefﬁcient of 91.48%
on the LUNA16 test set and 94.17% on the Tianchi test set
respectively.

b). We release our reference annotations on 50 CT scans
randomly chosen from LUNA16 for supervised pulmonary
lobe segmentation study, which is the ﬁrst publicly available
dataset with reference annotations on this task.

2. DATA

2.1. Data and annotation

We randomly chose 50 CT scans from LUNA16 [8] and col-
laborated with our radiologist in creating annotations for each
CT scan. LUNA16 is a subset of LIDC-IDRI [10] for pul-
monary nodules, which is the largest publicly available lung
image dataset. LUNA16 was then created by removing CT
scan that has a slice thickness greater than 3mm, inconsis-
tent slice spacing or missing slices from LIDC-IDRI dataset
to provide an evaluation framework for pulmonary nodule de-
tection. LIDC-IDRI data uses the Creative Commons Attri-
bution 3.0 Unported License.

Reference annotation for each CT scan was then manually
delineated by radiologist using Chest Image Platform1. This
software platform is built on top of the 3D slicer and uses
an interactive algorithm to perform lobe segmentation where
user is required to mark points on three ﬁssures [5, 6].

We used 40 of the annotated CT scans for training our
model and 10 for testing on the LUNA16 dataset. In order to
validate the robustness of our algorithm, we further annotated
another 10 randomly chosen CT scans collected from a differ-
ent source: Tianchi2, which is also a large-scaled competition
dataset.

Fig. 1. Neural network architecture. Each cube represents
3D image volume and the side number denotes the number
of channels in that block. Different from original V-Net, we
only use one down-sampling to balance the trade-off between
feature representation capacity and GPU memory.

3. METHOD

We present in this section the framework using the deep con-
volutional neural network which includes pre-processing of
removing regions outside the lung region, model architecture
and hybrid loss function used to train the network.

3.1. Pre-processing

We propose pre-processing by cropping region covered by the
convex hull of the lungs, which removes noise from different
CT scans outside the lungs, as well as reducing the cost of
GPU memory as the input volume is substantially smaller.

We start with normalizing the whole CT scan by trun-
cating Hounsﬁeld Unit (HU) values outside the range of
[−1000, 600]. Next, we use OTSU to binarize the CT image.
A binary morphology close is then used to remove regions
outside the lungs and binary hole ﬁlling is applied to ﬁll small
isolated regions in the lung on a per slice base. The convex
hull of the two lungs is computed and a binary morphology
dilation using 5 ∗ 5 kernel is applied to preserve information
near the border slice by slice.

3.2. Model architecture

The network architecture is illustrated in Figure 1. We use 3D
residual block [11] as a basic building block which consists of
two consecutive 3∗3∗3 convolution layers followed by ReLU
and Batchnorm. We only use one down sampling in this archi-
tecture to balance the trade-off between feature representation
capacity and GPU memory, which is different from original
V-Net [12] who employs the standard four down-samplings.

2.2. Reference annotation availability

50 annotations created on the LUNA16 dataset are publicly
available for supervised lung lobe segmentation study. How-
ever, the 10 annotations made on the Tianchi dataset will not
be made publicly available at this time.

3.3. Loss

1https://chestimagingplatform.org/about
2https://tianchi.aliyun.com/competition/

rankingList.htm?raceId=231601&season=0

Dice loss is widely used for training a segmentation network
using deep learning in the medical image. Dice loss performs
relatively well when training samples are highly imbalanced

as compared to cross entropy loss. However, dice loss fails
to capture the difference of difﬁculty in classifying different
voxels. For instance, voxels on the border are more difﬁcult to
be classiﬁed correctly than voxels are in the center of the lobe.
As a result, we use a hybrid loss of both dice loss and focal
loss [13] to address voxel-wise imbalance and force model to
focus on those voxels that are hard to be correctly predicted,
similar to [9]:

L = Ldice + λLf ocal

(1)

Ldice =

C
(cid:88)

N
(cid:88)

c

i

pic ∗ gic
pic ∗ gic + (1 − pic) ∗ gic + pic ∗ (1 − gic)

Lf ocal = −

αc ∗ gic ∗ (1 − pic)γ ∗ log(pic)

1
N

C
(cid:88)

N
(cid:88)

c

i

λ is a hyper-parameter controlling the balance between dice
loss and focal loss, which is set to 1 in this work. N is the to-
tal number of voxels in each mini-batch and i is the index of
each individual voxel. C denotes the total number of classes
which is six in this task (one more class for background). pic
is the predicted probability that i-th voxel is class c and gic
is 1 if i-th voxel is class c and 0 otherwise. α and γ are pa-
rameters controlling weight for each class and adjusting the
down-weighting of well-classiﬁed voxels respectively. We set
α to be one and γ to be two as suggested in [13].

3.4. Data augmentation

Data augmentation is critical for training model that can gen-
eralize well across different datasets, especially when the
number of training samples is small. The input volume is ran-
domly shifted, z-axis ﬂipped and XY-plane rotated in order to
improve the generalization ability of the model.

4. EXPERIMENTS

Dice coefﬁcient was used to evaluate the performance of the
model:

DCc(P, G) = 2 ∗

, c ∈ C

Pc ∪ Gc
Pc ∩ Gc

DCavg(P, G) =

DCc(Pc, Gc)

1
C

C
(cid:88)

c

(2)

(3)

where P is the set of predictions for each voxel and G rep-
resents the set of ground truth label. We calculate dice co-
efﬁcient for each lobe independently and averaged dice co-
efﬁcient for all lobes as described in Equation (2) and Equa-
tion (3) respectively.

We split 50 annotated CT scans from LUNA16 into 40
for training and 10 for testing. We tested our model on a
holdout 10 CT scans annotated from Tianchi dataset as well
to illustrate the robustness of our proposed approach.

Fig. 2. Comparison between prediction of the model and
ground-truth in CT scan views: Axial, Sagittal and Coronal.

In order to assess the inﬂuence of hybrid loss and pre-
processing by using convex hull, we added each component
step by step and all models were trained using the same data
augmentation with the same hyper parameters. We trained
each model for 300 epochs using Adam as the optimizer and
used the last epoch for predicting each test set. Batch size was
set to one since the size of input volume might be different for
each CT scan after pre-processing.

The step-wise gains of using hybrid loss and pre-processing
by using convex hull are shown in Table 1. Also, we com-
pared our best model with [7] which we found most relative
to our work. As shown in the tables, model trained with
hybrid loss increased the averaged dice coefﬁcient of the
baseline model by 3.87% on LUNA16 test set and 3.95% on
Tianchi test set. By removing regions outside the lung using
convex hull further increased the averaged dice coefﬁcient
by 0.54% on LUNA16 test set and 1.92% on Tianchi test
set as compared to the model trained only with hybrid loss.
Moreover, the comparison between [7] and our approach fur-
ther validated the robustness and generalization ability of the
proposed framework by improving the previous state-of-art
result by a maximum of 2.39% on averaged dice coefﬁcient.
We visualized in Figure 2 qualitative comparison between
model prediction and reference annotation from three views,
which illustrates the signiﬁcance of focusing on hard negative
examples and only regions inside and between two lungs.

5. CONCLUSION

In this work, we release our manual annotation by radiolo-
gist for 50 CT scans collected from the LUNA16 challenge
and present a practical and robust framework for robust pul-
monary lobe segmentation. We believe the public availabil-

RU
92.76
[7]
78.28
DL
90.58
+ FL
+ CH 92.53

RU
93.11
[7]
80.80
DL
92.59
+ FL
+ CH 95.11

LUNA16 test set
RL
94.33
93.96
93.95
93.05
Tianchi test set
RL
94.54
94.46
93.08
95.15

LU
88.10
88.65
96.01
96.10

LU
89.30
89.03
95.94
97.21

RM
84.68
79.69
78.41
80.60

RM
86.43
82.71
84.75
87.92

LL
94.78
94.79
95.77
95.30

LL
95.40
94.51
94.88
95.46

AVG
90.93
87.07
90.94
91.48

AVG
91.76
88.30
92.25
94.17

Table 1. Step-wise performance gains of using hybrid loss
and pre-processing using convex hull as compared to a base-
line model trained only with dice loss and previous state-of-
art method [7]. RU, RM, RL, LU, LL and AVG represent the
dice coefﬁcient of right upper lobe, right middle lobe, right
lower lobe, left upper lobe, left lower lobe and their average
respectively. DL means model trained with dice loss and +FL
means model trained with hybrid loss of focal loss and dice
loss. +CH represents model trained with hybrid loss and train-
ing data cropped by the convex hull of the lungs.

ity of those reference annotations will help the study of pul-
monary lobe segmentation using supervised learning. Also,
our proposed framework trained with a small number of train-
ing examples is proved to perform well across CT scans from
different sources.

6. REFERENCES

[1] Rebecca L Siegel, Kimberly D Miller, and Ahmedin Je-
mal, “Cancer statistics, 2015,” CA: a cancer journal for
clinicians, vol. 65, no. 1, pp. 5–29, 2015.

[2] National Emphysema Treatment Trial Research Group,
“Patients at high risk of death after lung-volume–
reduction surgery,” New England Journal of Medicine,
vol. 345, no. 15, pp. 1075–1083, 2001.

[3] Hao Tang, Daniel R Kim, and Xiaohui Xie,

“Auto-
mated pulmonary nodule detection using 3d deep con-
in Biomedical Imaging
volutional neural networks,”
(ISBI 2018), 2018 IEEE 15th International Symposium
on. IEEE, 2018, pp. 523–526.

[4] Wentao Zhu, Chaochun Liu, Wei Fan, and Xiaohui Xie,
“Deeplung: 3d deep convolutional nets for automated
pulmonary nodule detection and classiﬁcation,” CoRR,
vol. abs/1709.05538, 2017.

[5] Jan-Martin Kuhnigk, Volker Dicken, Stephan Zidowitz,
Lars Bornemann, Bernd Kuemmerlen, Stefan Krass,

Heinz-Otto Peitgen, Silja Yuval, Hans-Holger Jend,
Wigbert S Rau, et al., “New tools for computer assis-
tance in thoracic ct. part 1. functional analysis of lungs,
lung lobes, and bronchopulmonary segments,” Radio-
graphics, vol. 25, no. 2, pp. 525–536, 2005.

[6] Bianca Lassen, Eva M van Rikxoort, Michael Schmidt,
Sjoerd Kerkstra, Bram van Ginneken, and Jan-Martin
Kuhnigk, “Automatic segmentation of the pulmonary
lobes from chest ct scans based on ﬁssures, vessels, and
bronchi,” IEEE transactions on medical imaging, vol.
32, no. 2, pp. 210–222, 2013.

[7] F. T. Ferreira, P. Sousa, A. Galdran, M. R. Sousa, and
A. Campilho, “End-to-end supervised lung lobe seg-
mentation,” in 2018 International Joint Conference on
Neural Networks (IJCNN), July 2018, pp. 1–8.

[8] Arnaud Arindra Adiyoso Setio, Alberto Traverso,
Thomas De Bel, Moira SN Berens, Cas van den
Bogaard, Piergiorgio Cerello, Hao Chen, Qi Dou,
Maria Evelina Fantacci, Bram Geurts, et al., “Valida-
tion, comparison, and combination of algorithms for au-
tomatic detection of pulmonary nodules in computed to-
mography images: the luna16 challenge,” Medical im-
age analysis, vol. 42, pp. 1–13, 2017.

[9] Wentao Zhu, Yufang Huang, Liang Zeng, Xuming
Chen, Yong Liu, Zhen Qian, Nan Du, Wei Fan, and Xi-
aohui Xie, “Anatomynet: Deep learning for fast and
fully automated whole-volume segmentation of head
and neck anatomy,” Medical physics, vol. 46, no. 2, pp.
576–589, 2019.

[10] Samuel G Armato III, Geoffrey McLennan, Luc Bidaut,
Michael F McNitt-Gray, Charles R Meyer, Anthony P
Reeves, Binsheng Zhao, Denise R Aberle, Claudia I
Henschke, Eric A Hoffman, et al., “The lung image
database consortium (lidc) and image database resource
initiative (idri): a completed reference database of lung
nodules on ct scans,” Medical physics, vol. 38, no. 2,
pp. 915–931, 2011.

[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian
Sun, “Deep residual learning for image recognition,”
CoRR, vol. abs/1512.03385, 2015.

[12] Fausto Milletari, Nassir Navab, and Seyed-Ahmad Ah-
madi, “V-net: Fully convolutional neural networks for
volumetric medical image segmentation,” CoRR, vol.
abs/1606.04797, 2016.

[13] T. Lin, P. Goyal, R. Girshick, K. He, and P. Dollr, “Fo-
cal loss for dense object detection,” in 2017 IEEE Inter-
national Conference on Computer Vision (ICCV), Oct
2017, pp. 2999–3007.

