Legal Judgment Prediction via Topological Learning

Haoxi Zhong∗, Zhipeng Guo∗, Cunchao Tu, Chaojun Xiao, Zhiyuan Liu†, Maosong Sun
Department of Computer Science and Technology
State Key Lab on Intelligent Technology and Systems
Institute for Artiﬁcial Intelligence, Tsinghua University, Beijing, China
{zhonghx18,gzp17,xiaocj16}@mails.tsinghua.edu.cn, tucunchao@gmail.com
{lzy,sms}@tsinghua.edu.cn

Abstract

Legal Judgment Prediction (LJP) aims to pre-
dict the judgment result based on the facts of
a case and becomes a promising application
of artiﬁcial intelligence techniques in the le-
gal ﬁeld. In real-world scenarios, legal judg-
ment usually consists of multiple subtasks,
such as the decisions of applicable law arti-
cles, charges, ﬁnes, and the term of penalty.
Moreover, there exist topological dependen-
cies among these subtasks. While most ex-
isting works only focus on a speciﬁc sub-
task of judgment prediction and ignore the de-
pendencies among subtasks, we formalize the
dependencies among subtasks as a Directed
Acyclic Graph (DAG) and propose a topo-
logical multi-task learning framework, TOP-
JUDGE, which incorporates multiple subtasks
and DAG dependencies into judgment predic-
tion. We conduct experiments on several real-
world large-scale datasets of criminal cases
in the civil law system. Experimental results
show that our model achieves consistent and
signiﬁcant improvements over baselines on all
judgment prediction tasks. The source code
can be obtained from https://github.
com/thunlp/TopJudge.

1

Introduction

Legal Judgment Prediction (LJP) aims to predict
the judgment results of legal cases according to the
fact descriptions. It is a critical technique for the
legal assistant system. On the one hand, LJP can
provide low-cost but high-quality legal consulting
services to the masses who are unfamiliar with le-
gal terminology and the complex judgment pro-
cedures. On the other hand, it can serve as the
handy reference for professionals (e.g., lawyers
and judges) and improve their work efﬁciency.

∗ Indicates equal contribution. The order is determined by

dice rolling.

† Corresponding author.

Figure 1: An illustration of the judicial logic of hu-
man judges in civil law system.

LJP has been studied for decades (Kort, 1957;
Ulmer, 1963; Nagel, 1963; Keown, 1980; Segal,
1984; Lauderdale and Clark, 2012; Ye et al., 2018;
Hu et al., 2018), and most existing works for-
malize LJP as a text classiﬁcation task. For ex-
ample, some works (Liu et al., 2004; Liu and
Hsieh, 2006) propose to extract shallow textual
features (e.g. characters, words, and phrases) for
charge prediction. Katz et al. (2017) predict the
US Supreme Court’s decisions based on efﬁcient
features from case proﬁles. Luo et al. (2017) pro-
pose an attention-based neural model for charge
prediction by incorporating the relevant law arti-
cles.

Despite these efforts in designing efﬁcient fea-
tures and employing advanced NLP techniques,
LJP is still confronted with two major challenges:
Multiple Subtasks in Legal Judgment: Prac-
tically, legal judgment usually consists of detailed
and complicated subclauses, such as charges, the
term of penalty, and ﬁnes. Speciﬁcally, for those
countries with the civil law system (e.g., China,
France, and Germany), the prediction of relevant
articles is also considered to be one of the funda-
mental subtasks, which will guide the prediction
for other subtasks. In other words, all these sub-
tasks compose the complete form of judgment pre-

diction. Nevertheless, existing works on LJP usu-
ally focus on one speciﬁc subtask of judgments,
which does not conform to the real scenarios. Al-
though some methods (Luo et al., 2017) are devel-
oped to predict law articles and charges at the same
time, their models are designed for a speciﬁc set of
subtasks which are hard to scale to other subtasks.
Topological Dependencies between Subtasks:
there exists a strict order
For human judges,
among the subtasks of legal judgment. As illus-
trated in Fig. 1, given the fact description of a spe-
ciﬁc case, a judge in the civil law system ﬁrst de-
cides which law articles are relevant to the sce-
nario, and then determines the charges according
to the instructions of relevant law articles. Based
on these results, the judge further conﬁrms the
term of penalty and ﬁnes. How to simulate the ju-
dicial logic of human judges and model the topo-
logical dependencies among legal subtasks will
deeply inﬂuence the creditability and interpretabil-
ity of judgment prediction.

As stated above, conventional works cannot
handle these two challenges due to both the lim-
itation of speciﬁc tasks and neglecting topological
dependencies. To address these issues, we propose
to model the multiple subtasks in judgment pre-
diction jointly under a novel multi-task learning
framework.

We model the topological dependencies among
these subtasks with a Directed Acyclic Graph
(DAG), which means all subtasks are arranged in
topological order. If the judgment of the j-th sub-
task tj depends on the output of the i-th subtask
ti, then ti appears earlier than tj in such order. It
is notable that such formulation provides an ex-
plicit explanation of dependency relations among
subtasks.

Accordingly, we introduce topological learning
for LJP and propose a uniﬁed framework, named
as TOPJUDGE. Speciﬁcally, given the encoded
representation of the fact description, TOPJUDGE
predicts the outputs of all the subtasks following
the topological order, and the output of a speciﬁc
subtask will be affected by all the subtasks it de-
pends on. In contrast with conventional multi-task
learning, our model takes the explicit topological
dependencies of LJP subtasks into consideration
and is ﬂexible to handle other LJP subtasks. More-
over, the topological order of legal dependencies
renders our model interpretable and reliable.

To verify the effectiveness and ﬂexibility of

TOPJUDGE, we conduct a series of experiments
on several real-world large-scale datasets. Exper-
imental results show that our model achieves sig-
niﬁcant and consistent improvements over state-
of-the-art models on all tasks and datasets. To
summarize, we make several noteworthy contribu-
tions as follows:

(1) We are the ﬁrst to explore and formalize the
multiple subtasks of legal judgment under a joint
learning framework. Moreover, we formulate the
dependencies among the subtasks of LJP as a form
of DAG and introduce this prior knowledge to en-
hance judgment prediction.

(2) We propose a novel judgment prediction
framework, TOPJUDGE, to unify multiple sub-
tasks and make judgment predictions through
topological learning. This model can handle any
form of DAG dependent subtasks, which has been
veriﬁed in the experiments.

(3) We carry out experiments on several large-
scale real-world datasets, and our model signiﬁ-
cantly and consistently outperforms all the base-
lines on all subtasks.

2 Related Work

2.1

Judgment Prediction

Employing automatic analysis techniques for legal
judgment has drawn attention from researchers in
the legal ﬁeld for decades. Early works usually
focus on analyzing existing legal cases in speciﬁc
scenarios with mathematical and statistical algo-
rithms (Kort, 1957; Ulmer, 1963; Nagel, 1963;
Keown, 1980; Segal, 1984; Lauderdale and Clark,
2012).

With the development of machine learning and
text mining techniques, more researchersformal-
ize this task under text classiﬁcation frameworks.
Most of these studies attempt to extract efﬁcient
features from text content (Liu and Hsieh, 2006;
Lin et al., 2012; Aletras et al., 2016; Sulea et al.,
2017) or case annotations (e.g., dates, terms, lo-
cations, and types) (Katz et al., 2017). However,
these conventional methods can only utilize shal-
low textual features and manually designed fac-
tors, both require massive human efforts and usu-
ally suffer from the generalization issue when ap-
plied to other scenarios.

Inspired by the success of neural networks on
NLP tasks (Kim, 2014; Baharudin et al., 2010;
Tang et al., 2015), researchers began to handle LJP
by incorporating neural models with legal knowl-

edge. For example, Luo et al. (2017) present an
attention-based neural network that jointly mod-
els charge prediction and relevant article extrac-
tion. Hu et al. (2018) incorporate 10 discrimina-
tive legal attributes to predict few-shot and con-
fusing charges. Nevertheless, these models are de-
signed for speciﬁc subtasks and thus non-trivial to
be extended to more subtasks of LJP with complex
dependencies. Besides, Ye et al. (2018) utilize a
Seq2Seq model to generate court views with fact
descriptions and predicted charges in Chinese civil
law.

2.2 Multi-task Learning

Multi-task learning (MTL) aims to exploit the
commonalities and differences across relevant
tasks by solving them at the same time.
It can
transfer useful information among various tasks
and has been applied to a wide range of ar-
eas, including NLP (Collobert and Weston, 2008),
speech recognition (Deng et al., 2013), and com-
puter vision (Girshick, 2015; Mao et al., 2017).

There have been numerous successful usages
of MTL in NLP tasks. Most works follow the
hard parameter sharing setting by sharing repre-
sentations or some encoding layers among rele-
vant tasks. For example, Collobert and Weston
(2008) use shared word embeddings in solving
part-of-speech tagging and semantic role labeling
tasks. Liu et al. (2015) share the encoding lay-
ers of input queries to address query classiﬁcation
and information retrieval. Dong et al. (2015) and
Luong et al. (2016) propose to share encoders or
decoders to improve one (many) to many neural
machine translation. Firat et al. (2016) propose to
share attention mechanism in multi-way, multilin-
gual machine translation. Besides hard parameter
sharing, soft parameter sharing is another com-
mon approach in MTL. It assumes that each task
owns its speciﬁc parameters and the distance be-
tween parameters in different tasks should be close
to each other. For example, Duong et al. (2015)
employ L2 distance for regularization, while Yang
and Hospedales (2017) use the trace norm. Liu
et al. (2016) introduce gates among task-speciﬁc
RNN layers to control the information ﬂow. Ruder
et al. (2017) introduce a model which can de-
cide the amount of sharing between different NLP
tasks. There are also some works focusing on in-
creasing tasks (Hashimoto et al., 2017) or handing
unlabeled data (Augenstein et al., 2018).

Figure 2: The framework of TOPJUDGE.

In this work, we introduce a topological learn-
ing framework TOPJUDGE to handle multiple sub-
tasks in LJP. Different to conventional MTL mod-
els which focus on how to share parameters among
relevant tasks, TOPJUDGE models the explicit de-
pendencies among these subtasks with scalable
DAG forms.

3 Method

In the following parts, we will ﬁrst give the essen-
tial deﬁnitions of LJP task. We then introduce the
DAG dependencies of the subtasks in LJP. And ﬁ-
nally, we describe the neural encoder for fact rep-
resentation and the judgment predictor for the sub-
tasks with DAG dependencies. The overall frame-
work of TOPJUDGE has been shown in Fig 2.

3.1 Problem Formulation

We will focus on the LJP tasks in civil law. Sup-
pose the fact description of a case is a word se-
quence x = {x1, x2, . . . , xn}, where n is the
length of x and each word xi comes from a ﬁxed
vocabulary W . Based on the fact description x,
the task of LJP T aims to predict judgment results
of applicable law articles, charges, term of penalty,
ﬁnes and so on. Formally, we assume T contains
|T | subtasks, i.e., T = {t1, t2, . . . , t|T |}, each of
which is a classiﬁcation task. For the i-th subtask
ti ∈ T , we aim to predict the corresponding result
yi ⊆ Yi, where Yi is a subtask-speciﬁc label set.
Take the subtask of charge prediction for example,
the corresponding label set should contain Theft,
Trafﬁc Violation, Intentional Homicide and so on.

3.2 DAG Dependencies of Subtasks

We assume that the dependencies among multiple
subtasks of LJP form a DAG. As a result, the task
list T should satisfy topological constraints. For-
mally, we use the notation ti (cid:1) tj to denote that

(a) Typical MTL form of DAG

(b) Sequential form of DAG

(c) General form of DAG

Figure 3: Three typical forms of DAG dependencies.

the j-th subtask depends on the i-th subtask, and
Dj = {ti | ti (cid:1) tj} to denote the dependency set.
The task list T can be ordered to satisfy the fol-
lowing constraint

i < j,

∀(i, j) ∈ {(i, j) | ti ∈ Dj}.

(1)

We demonstrate the ﬂexibility of our formula-
tion by describing two special cases: (1) As shown
in Fig. 3 (a), if no dependencies exist, i.e., Dj = ∅,
it corresponds to the typical MTL setting where
we simultaneously make predictions for all sub-
tasks. (2) As shown in Fig. 3 (b), if each task only
depends on its previous task, i.e., Dj = {tj−1}, it
forms a sequential learning process.

3.3 Neural Encoder for Fact Descriptions

We employ a fact encoder to generate the fact de-
scription’s vector representation as the input of
TOPJUDGE. In the following part, we brieﬂy in-
troduce an encoder based on Convolutional Neural
Networks (CNN) (Kim, 2014).

Taking a word sequence x as input, the CNN
encoder computes the text representation through
three layers, i.e., lookup layer, convolution layer
and pooling layer.

Lookup We ﬁrst convert each word xi in x into
its word embedding xi ∈ Rk, where k is the di-
mension of word embeddings. The word embed-
ding sequence is then represented as

ˆx = {x1, x2, . . . , xn}.

(2)

Convolution A convolution operation involves
a convolution matrix W ∈ Rm×(h×k), which is
applied to a sliding window of length h with num-
ber of ﬁlters m to produce a feature map by

ci = W · xi:i+h−1 + b,

(3)

where xi:i+h−1 is the concatenation of word em-
beddings within the i-th window and b ∈ Rm is
the bias vector. By applying convolution over each
window, we obtain c = {c1, . . . , cn−h+1}.

Pooling We apply per-dimension max-pooling
over c and obtain the ﬁnal fact representation d =
[d1, . . . , dm] by

dt = max(c1,t, . . . , cn−h+1,t), ∀t ∈ [1, m].

(4)

3.4

Judgment Predictor over DAG

Based on the DAG assumption, we obtain an or-
dered task list T ∗ = [t1, t2, . . . , t|T |]. For each
task tj ∈ T , we aim to predict its judgment result
yj based on the fact representation vector d and
the judgment results of its dependent tasks.

For prediction, we employ a speciﬁc LSTM cell
for each task and get the output of each task in
the topological order. More speciﬁcally, for each
task tj ∈ T , we obtain its ﬁnal judgment result
through three steps, i.e., cell initialization, task-
speciﬁc representation, and prediction.

Cell Initialization As stated above, the predic-
tion result of tj will be conditioned on the fact
representation d and the outputs of all dependent
tasks yk, ∀tk ∈ Dj. Hence, we have

(cid:105)

(cid:104)¯hj
¯cj

=

(cid:88)

(cid:16)

Wi,j

(cid:105)(cid:17)

(cid:104)hi
ci

+ bj

(5)

ti∈Dj

Here, hi and ci are the hidden state and memory
cell of ti. ¯hj and ¯cj are the initial hidden state and
memory cell of tj. Wi,j and bj are transformation
matrices and bias vectors speciﬁc to ti and tj.

Task-Speciﬁc Representation Taking the fact
representation d, the initial hidden state ¯hj, and
the initial memory cell ¯cj as inputs, we process

them with an LSTM cell (Hochreiter and Schmid-
huber, 1997).

We regard the ﬁnal hidden state hj as the task-
speciﬁc representation of task tj. The last cell
state cj is used to compose the initial hidden state
for the downstream tasks by Eq. 5

Prediction With the representation hj, we ap-
ply an afﬁne transformation followed by softmax
and obtain the ﬁnal prediction as

ˆyj = softmax (cid:0)Wp

j hj + bp

j

(cid:1) .

(6)

j are parameters speciﬁc to task

Here, Wp
tj.

j and bp

With the prediction result ˆyj, we minimize the

cross-entropy between ˆyj and yj as follows:

Lj(ˆyj, yj) = −

yj,k log(ˆyj,k).

(7)

|Yj |
(cid:88)

k=1

3.5 Training

We use cross-entropy loss for each subtask and
sum up losses to train TOPJUDGE:

L =

λjLj(ˆyj, yj),

(8)

|T |
(cid:88)

j=1

where λj is the weight factor for each subtask tj.
The DAG dependencies of subtasks ensure that
our model is differentiable and can be trained in an
end-to-end fashion. In practice, we set all weights
λj to 1, and employ Adam (Kingma and Ba, 2015)
for optimization. We also apply dropout (Srivas-
tava et al., 2014) on the fact representation to pre-
vent overﬁtting.

4 Experiments

To evaluate the proposed TOPJUDGE framework,
we conduct a series of experiments on LJP over
three large-scale datasets of criminal cases in
China. We select three representative judgment
prediction subtasks for comparison, including law
articles, charges, and the terms of penalty.

4.1 Dataset Construction

As there are no publicly available LJP datasets
in previous works, we collect and construct three
different LJP datasets, including CJO, PKU, and
CAIL. CJO consists of criminal cases published
by the Chinese government from China Judge-
ment Online1. PKU contains criminal cases pub-
lished by Peking University Law Online2. CAIL

1 http://wenshu.court.gov.cn/
2 http://www.pkulaw.com/

Datasets

CJO

PKU

CAIL

Cases
Law Articles
Charges
Term of Penalty

1, 007, 744
98
99
11

175, 744
68
64
11

113, 536
105
122
11

Table 1: The statistics of different datasets.

(Chinese AI and Law Challenge) is another crim-
inal case dataset for competition released by the
Supreme People’s Court of China3. The details of
CAIL can be found in Xiao et al. (2018).

For all datasets we mentioned above, as the doc-
uments are well-structured and human-annotated,
we can easily extract fact descriptions, applica-
ble law articles, charges and the terms of penalty
from each document using regular expressions.
We have manually checked a randomly sampled
set of cases, and extraction errors are negligible.

In real-world scenarios, there are some cases
with multiple defendants and multiple charges,
which will increase the complexity of judgment
prediction. As our model aims to explore the ef-
fectiveness of considering topological dependen-
cies between various subtasks, we ﬁlter out these
cases and leave them as our future work.

Meanwhile,

there are also some infrequent
charges and law articles, such as money launder-
ing, smuggling of nuclear materials and tax dodge.
We ﬁlter out these infrequent charges and law arti-
cles and only keep those with frequencies greater
than 100. For the term of penalty, we divide the
terms into non-overlapping intervals. We list de-
tailed statistics of these datasets in Table 1.

4.2 Baselines

For comparison, we employ the following text
classiﬁcation models and judgment prediction
methods as baselines:

TFIDF+SVM: We employ term-frequency in-
verse document frequency (TFIDF) (Salton and
Buckley, 1988) to extract word features and uti-
lize SVM (Suykens and Vandewalle, 1999) for text
classiﬁcation.

CNN: We employ CNN with multiple ﬁlter
widths (Kim, 2014) for fact encoding and classi-
ﬁcation.

Hierarchical LSTM (HLSTM): Tang et al.
(2015) employs hierarchical neural networks to
learn document representations in sentiment clas-

3 http://cail.cipsc.org.cn/index.html

Tasks

Law Articles

Charges

The Term of Penalty

Metrics

Acc. MP MR

F1

Acc. MP MR

F1

Acc. MP MR

F1

Single

Multi

TFIDF+SVM 82.4
92.5
91.4

CNN
HLSTM

Fact-Law Att.
PM
CNN-MTL
HLSTM-MTL

93.5
93.7
94.3
92.4

94.4

45.5
46.9
38.6

50.9
51.9
53.0
45.5

53.9

26.7
38.4
37.3

45.6
44.1
46.0
41.4

47.3

30.2
40.0
36.9

45.9
44.9
46.9
41.0

48.2

82.2
92.3
91.8

93.4
93.6
94.1
92.3

94.9

47.4
41.2
37.8

47.2
45.5
48.5
41.9

53.9

27.9
32.3
36.0

41.4
39.1
41.7
36.6

48.2

31.3
33.7
35.2

41.5
39.3
42.5
35.9

49.1

48.5
57.4
56.1

56.3
58.2
58.7
54.9

58.8

36.0
35.6
22.5

31.3
38.2
39.9
30.6

40.2

16.7
22.2
25.0

26.4
24.9
28.8
26.6

32.9

16.5
22.7
23.3

26.7
26.8
29.4
26.4

32.8

Ours

TOPJUDGE

Table 2: Judgment prediction results on CJO.

Tasks

Law Articles

Charges

The Term of Penalty

Metrics

Acc. MP MR

F1

Acc. MP MR

F1

Acc. MP MR

F1

Single

Multi

TFIDF+SVM 80.9
93.1
91.7

CNN
HLSTM

Fact-Law Att.
PM
CNN-MTL
HLSTM-MTL

93.9
94.4
95.0
93.9

95.4

51.3
64.3
54.4

68.1
69.6
73.8
71.2

76.4

32.6
52.6
53.4

63.4
61.0
64.9
64.6

67.6

36.4
54.3
50.9

63.5
62.2
66.0
65.1

68.4

81.0
93.3
91.9

94.2
94.3
95.0
93.8

95.6

53.4
61.9
52.5

65.8
65.1
70.7
67.8

75.9

35.4
49.3
48.9

58.5
56.2
60.6
60.0

69.6

38.7
51.1
47.3

58.7
57.2
61.7
60.7

70.9

45.3
57.6
54.3

55.7
58.2
58.4
55.4

57.8

30.4
24.1
20.6

27.7
36.2
36.0
31.3

38.9

17.4
23.1
21.7

27.4
26.4
28.7
26.2

32.1

17.2
23.3
19.0

26.5
27.1
28.9
25.7

31.8

Ours

TOPJUDGE

Table 3: Judgment prediction results on PKU.

siﬁcation. Based on this work, we employ an
LSTM for sentence representations and another
one to obtain the representation of complete fact
descriptions.

Fact-Law Attention Model: Luo et al. (2017)
proposes a neural charge prediction model by cap-
turing the interaction between fact descriptions
and applicable laws with attention mechanism.

Pipeline Model (PM): To demonstrate the
advantage of TOPJUDGE on modeling subtasks
jointly, we also implement a pipelined method for
comparison. Here, we train 3 separate CNN classi-
ﬁers for law articles, charges, and term of penalty.
For each subtask, the input is the concatenation
of the fact representation and the embeddings for
predicted labels of previous subtasks.

Besides, we compare our model with conven-
tional MTL methods that do not consider the de-
pendencies among subtasks as in Fig. 3 (a). These
methods are denoted as CNN-MTL and HLSTM-
MTL, where we implement the fact encoder as in
Fig. 2 using CNN or HLSTM respectively.

4.3 Experimental Settings

As the case documents are written in Chinese
with no space between words, we employ THU-
LAC (Sun et al., 2016) for word segmentation. Af-
terward, we adopt the Skip-Gram model (Mikolov
et al., 2013) to pre-train word embeddings on these

case documents, with embedding size set to 200
and frequency threshold set to 25.

For all models, we set

the fact representa-
tion and task-speciﬁc representation size to 256.
Meanwhile, we set the maximum sentence length
to 128 words and maximum document length to
32 sentences.

For training, the learning rate of Adam opti-
mizer is 10−3, and the dropout probability is 0.5.
We also set the batch size to 128 for all models.
We train every model for 16 epochs, and evaluate
the ﬁnal model on the testing set.

We employ accuracy (Acc.), macro-precision
(MP), macro-recall (MR) and macro-F1 (F1)
the macro-
as evaluation metrics.
precision/recall/F1 are calculated by averaging the
precision/recall/F1 of each category.

Here,

4.4 Results and Analysis

We evaluate the performance on three LJP sub-
including law articles (denoted as t1),
tasks,
charges (denoted as t2), and the terms of penalty
(denoted as t3). Experimental results are shown in
Tables 2, 3, and 4. Note that, we implement TOP-
JUDGE with the dependency relationship in Fig. 3
(c), i.e.,

D1 = φ, D2 = {t1}, D3 = {t1, t2}.

(9)

Tasks

Law Articles

Charges

The Term of Penalty

Metrics

Acc. MP MR

F1

Acc. MP MR

F1

Acc. MP MR

F1

Single

Multi

TFIDF+SVM 60.1
81.4
-

CNN
HLSTM

Fact-Law Att.
PM
CNN-MTL
HLSTM-MTL

70.9
84.7
84.5
-

86.3

54.9
74.4
-

64.8
80.7
80.0
-

81.9

45.3
64.1
-

63.6
68.6
68.1
-

71.1

46.3
65.7
-

59.1
70.8
70.3
-

73.4

59.2
80.7
-

68.7
83.6
83.4
-

85.7

53.9
77.3
-

66.1
81.6
81.6
-

83.4

45.0
65.5
-

65.3
70.0
69.1
-

76.0

45.7
67.2
-

60.1
72.1
71.6
-

78.3

28.4
28.8
-

36.5
40.0
39.5
-

38.3

22.9
34.7
-

29.9
37.4
37.2
-

36.1

20.0
27.8
-

27.6
32.0
32.3
-

33.1

18.1
28.6
-

27.1
31.6
31.3
-

32.1

Ours

TOPJUDGE

Table 4: Judgment prediction results on CAIL. Note that, “-” means the model does not converge within
128 epochs.

This means that the prediction of charges depends
on law articles, and the prediction of term of
penalty depends on both law articles and charges.
Such explicit dependencies conform to the judi-
cial logic of human judges, which will be veriﬁed
in later sections. These results show that:

(1) The proposed TOPJUDGE model outper-
forms other baselines signiﬁcantly on most sub-
tasks and datasets. It demonstrates the effective-
ness and robustness of our proposed framework.

(2) Compared with conventional single-task
models, e.g., CNN and HLSTM, MTL methods
take advantage of the correlation among relevant
subtasks and thus achieve promising improve-
It indicates the importance of modeling
ments.
LJP subtasks jointly.

(3) Moreover, TOPJUDGE signiﬁcantly outper-
forms typical MTL models, especially on the pre-
diction of charges and the terms of penalty. It veri-
ﬁes the rationality and importance of modeling de-
pendencies over LJP subtasks with DAG.

4.5 Ablation Analysis

Tasks

t1

t2

t3

Metrics

Acc.

F1

Acc.

F1

Acc.

F1

TOPJUDGE
- t3 (cid:1) t1
- t2 (cid:1) t1
φ

95.4
95.2
94.8
94.7

68.4
67.7
64.7
64.4

95.6
95.4
94.9
94.9

70.9
70.3
60.2
60.1

57.8
57.4
57.0
57.8

31.8
31.2
31.6
27.6

Table 5: Ablation analysis on PKU.

To further illustrate the signiﬁcance of legal de-
pendencies and explore how the DAG dependen-
cies inﬂuence the performance, we evaluate the
performance of TOPJUDGE under various DAG
architectures. Using Eq. 9 as the full dependen-
cies, we remove the dependency of t3 (cid:1) t1 (law
articles and term of penalty, corresponding to the
sequential form in Fig. 3), t2 (cid:1) t1 (law articles and

charges), and all dependencies respectively. Re-
sults are summarized in Table 5.

We observe that the performance of TOPJUDGE
decreases on all tasks after removing either depen-
dency. More speciﬁcally, when we dropped de-
pendencies t3 (cid:1) t1 and t2 (cid:1) t1 respectively, sig-
niﬁcant decreases are observed for t3 and t2 corre-
spondingly. This demonstrates that incorporating
dependencies is beneﬁcial for relevant subtasks,
verifying its guiding role in the civil law system.

Meanwhile, we note that there are two main
differences between TOPJUDGE and traditional
multi-task models, namely the Cell Initialization
and the Task-Speciﬁc Representation. We can
see that if we eliminate Cell Initialization from
TOPJUDGE,
the dependencies will not be rep-
resented in the model and it will become sim-
ilar to CNN-MTL. If we eliminate the Task-
Speciﬁc Representation from TOPJUDGE, TOP-
JUDGE will become the same as the Pipeline
Model. In a word, the main improvement of our
models comes from the combination.

4.6 Case Study

We give some intuitive examples to demonstrate
the signiﬁcance of TOPJUDGE on LJP subtasks.

As shown in Table 6, case 1 is about negligently
causing a ﬁre. The fact description of this case
states “The defendant pulled up weeds in the ﬁelds
and piled them up in haphazard stacks. Afterward,
he lighted them up and triggered the forest ﬁres...”
TOPJUDGE predicts all judgments correctly, while
CNN-MTL fails to predict the charge and term of
penalty. Moreover, CNN-MTL obtains conﬂicting
judgments, i.e., “crime of arson” and “1-2 years”,
due to its neglecting of dependencies of these sub-
tasks. According to the legal provisions of law ar-
ticle 115, the crime of arson should be sentenced
to more than 10 years.

Methods

Law Charge

Term
(months)

12-24(×)

CNN-MTL

115 Arson(×)

TOPJUDGE

115 Negligently Caus-
ing a Fire

0-6

CNN-MTL

293

Intentional Dam-
age to Property(×)

12-24(×)

TOPJUDGE

293 Affray

0-6

Table 6: Example cases and their prediction results.

Case 2 in Table 6 is another evidence of the in-
sufﬁciency of conventional MTL on LJP. This case
is about picking quarrels and provoking troubles.
Both CNN-MTL and TOPJUDGE succeed to pre-
law article 293
dict the relevant law articles (i.e.,
of the crime of affray). However, CNN-MTL is
confused between “crime of affray” and “crime of
intentional destruction or damage of properties”,
two charges similar to each other. Conversely,
TOPJUDGE can utilize the prediction result of law
articles and consequently prevent this confusion.

To summarize, modeling the explicit dependen-
cies among various subtasks can remarkably help
the LJP model address the issue of predicting con-
ﬂicting results.

4.7 Error Analysis

Prediction errors induced by our proposed model
can be traced down into the following causes.

Data Imbalance.

For the subtasks of law
articles and charges, our model achieves more
than 90% on accuracy, while only about 60% for
macro-F1. This issue is much more severe on the
subtask of the term of penalty, which our model
yields a poor performance of only 30% macro-F1.
The bad performance is mainly due to the imbal-
ance of category labels, e.g., there are only a few
training instances where the term is “life imprison-
ment or death penalty”. Most judgment prediction
approaches perform poorly (especially for Recall)
on these labels as listed in Fig. 4. Instance weight-
ing schemes can be introduced to address this is-
sue in future works.

Incomplete Information. Following existing
LJP works, we predict the ﬁnal judgment accord-
ing to the fact descriptions, which is incomplete as
compared to the whole materials relevant to this
In Chinese Law, there are certain circum-
case.
stances under which the sentence can be short-
ened. For example, minors usually receive a light-

Figure 4: The confusion matrix in the subtask
of predicting the term of penalty on the PKU
dataset. The rows denote the ground truth while
the columns denote the prediction results.

ened penalty, and those guilty of misdemeanors
are allowed for a secured pending trial while pay-
ing a security deposit. However, such informa-
tion is not included in the fact descriptions. The
lack of such information also raises difﬁculties for
judgment prediction, especially for the prediction
of the term of penalty. In Fig. 4, we can see that
the highest error rate comes from the cases with a
short term of penalty. Our model fails to distin-
guish the cases with no penalty and those with 0-6
months term of imprisonment.

5 Conclusion

In this paper, we focus on the task of legal judg-
ment prediction (LJP) and address multiple sub-
tasks of judgment predication with a topological
learning framework. To be speciﬁc, we formalize
the explicit dependencies over these subtasks in a
DAG form, and propose a novel MTL framework,
TOPJUDGE, by integrating the DAG dependen-
cies. Experimental results on three LJP subtasks
and three different datasets show that our TOP-
JUDGE outperforms all single-task baselines and
conventional MTL models consistently and signif-
icantly.

In the future, we will seek to explore the follow-
ing directions: (1) We will explore more LJP sub-
tasks and more scenarios of cases such as multiple

defendants and charges to investigate the effective-
ness of TOPJUDGE. (2) We will explore how to
incorporate into LJP the temporal factors, which
are not considered in this work.

6 Acknowledgements

This work is supported by the National Nat-
ural Science Foundation of China (NSFC No.
61572273, 61772302) and the research fund of
Powerlaw Inc.
for AI+Law Technology. This
work is also funded by China Association for Sci-
ence and Technology (2016QNRC001). Tu is also
supported by China Postdoctoral Innovative Talent
Support Programme.

References

Nikolaos Aletras, Dimitrios Tsarapatsanis, Daniel
Preotiuc-Pietro, and Vasileios Lampos. 2016. Pre-
dicting judicial decisions of the european court of
human rights: A natural language processing per-
spective. PeerJ Computer Science, 2.

Isabelle Augenstein, Sebastian Ruder, and Anders
Søgaard. 2018. Multi-task learning of pairwise
sequence classiﬁcation tasks over disparate label
spaces. In Proceedings of NAACL.

Baharum Baharudin, Lam Hong Lee, and Khairullah
Khan. 2010. A review of machine learning algo-
rithms for text-documents classiﬁcation. Journal of
Advances in Information Technology, 1(1):4–20.

Ronan Collobert and Jason Weston. 2008. A uniﬁed
architecture for natural language processing: Deep
In Pro-
neural networks with multitask learning.
ceedings of ICML, pages 160–167.

Li Deng, Geoffrey Hinton, and Brian Kingsbury. 2013.
New types of deep neural network learning for
speech recognition and related applications: An
overview. In Proceedings of ICASSP, pages 8599–
8603.

Daxiang Dong, Hua Wu, Wei He, Dianhai Yu, and
Haifeng Wang. 2015. Multi-task learning for mul-
tiple language translation. In Proceedings of ACL,
volume 1, pages 1723–1732.

Long Duong, Trevor Cohn, Steven Bird, and Paul
Cook. 2015. Low resource dependency parsing:
Cross-lingual parameter sharing in a neural network
In Proceedings of ACL, volume 2, pages
parser.
845–850.

Orhan Firat, Kyunghyun Cho, and Yoshua Bengio.
2016. Multi-way, multilingual neural machine
translation with a shared attention mechanism.
In
Proceedings of NAACL, pages 866–875.

Ross Girshick. 2015. Fast r-cnn.

In Proceedings of

ICCV, pages 1440–1448.

Kazuma Hashimoto, Yoshimasa Tsuruoka, Richard
Socher, et al. 2017. A joint many-task model: Grow-
ing a neural network for multiple nlp tasks. In Pro-
ceedings of EMNLP, pages 1923–1933.

Sepp Hochreiter and Jurgen Schmidhuber. 1997.
Neural computation,

Long short-term memory.
9(8):1735–1780.

Zikun Hu, Xiang Li, Cunchao Tu, Zhiyuan Liu, and
Maosong Sun. 2018. Few-shot charge prediction
with discriminative legal attributes. In Proceedings
of COLING.

Daniel Martin Katz, Michael J Bommarito II, and Josh
Blackman. 2017. A general approach for predict-
ing the behavior of the supreme court of the united
states. Plos one, 12(4).

R Keown. 1980. Mathematical models for legal pre-

diction. Computer/LJ, 2:829.

Yoon Kim. 2014. Convolutional neural networks for
sentence classiﬁcation. In Proceedings of EMNLP.

Diederik Kingma and Jimmy Ba. 2015. Adam: A
method for stochastic optimization. In Proceedings
of ICLR.

Fred Kort. 1957. Predicting supreme court decisions
mathematically: A quantitative analysis of the ”right
to counsel” cases. American Political Science Re-
view, 51(1):1–12.

Benjamin E Lauderdale and Tom S Clark. 2012. The
supreme court’s many median justices. American
Political Science Review, 106(4):847–866.

Wanchen Lin, Tsung Ting Kuo, and Tung Jia Chang.
2012. Exploiting machine learning models for chi-
nese legal documents labeling, case classiﬁcation,
and sentencing prediction. In Processdings of RO-
CLING, page 140.

Chaolin Liu, Cheng Tsung Chang, and Jim How Ho.
2004. Case instance generation and reﬁnement
for case-based criminal summary judgments in chi-
nese. Journal of Informationence & Engineering,
20(4):783–800.

Chaolin Liu and Chwen Dar Hsieh. 2006. Exploring
phrase-based classiﬁcation of judicial documents for
criminal charges in chinese. In Proceedings of IS-
MIS, pages 681–690.

Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2016.
Recurrent neural network for text classiﬁcation with
multi-task learning. In Proceedings of IJCAI.

Xiaodong Liu, Jianfeng Gao, Xiaodong He, Li Deng,
Kevin Duh, and Ye-Yi Wang. 2015. Representation
learning using multi-task deep neural networks for
semantic classiﬁcation and information retrieval. In
Proceedings of NAACL, pages 912–921.

Chaojun Xiao, Haoxi Zhong, Zhipeng Guo, Cunchao
Tu, Zhiyuan Liu, Maosong Sun, Yansong Feng,
Xianpei Han, Zhen Hu, Heng Wang, et al. 2018.
Cail2018: A large-scale legal dataset for judgment
prediction. arXiv preprint arXiv:1807.02478.

Yongxin Yang and Timothy Hospedales. 2017. Deep
multi-task representation learning: A tensor factori-
sation approach. In Proceedings of ICLR.

Hai Ye, Xin Jiang, Zhunchen Luo, and Wenhan Chao.
2018. Interpretable charge predictions for criminal
cases: Learning to generate court views from fact
descriptions. In Proceedings of NAACL.

Bingfeng Luo, Yansong Feng, Jianbo Xu, Xiang
Zhang, and Dongyan Zhao. 2017. Learning to pre-
dict charges for criminal cases with legal basis. In
Proceedings of EMNLP.

Minh-Thang Luong, Quoc V Le, Ilya Sutskever, Oriol
Vinyals, and Lukasz Kaiser. 2016. Multi-task se-
In Proceedings of
quence to sequence learning.
ICLR.

Jiayuan Mao, Tete Xiao, Yuning Jiang, and Zhimin
Cao. 2017. What can help pedestrian detection? In
Proceedings of CVPR, pages 3127–3136.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Proceedings of NIPS, pages 3111–3119.

Stuart S Nagel. 1963. Applying correlation analysis to

case prediction. Texas Law Review, 42:1006.

Sebastian Ruder, Joachim Bingel, Isabelle Augen-
stein, and Anders Søgaard. 2017. Learning what to
share between loosely related tasks. arXiv preprint
arXiv:1705.08142.

Gerard Salton and Christopher Buckley. 1988. Term-
weighting approaches in automatic text retrieval. In-
formation processing & management, 24(5):513–
523.

Jeffrey A Segal. 1984. Predicting supreme court cases
probabilistically: The search and seizure cases,
American Political Science Review,
1962-1981.
78(4):891–900.

Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: a simple way to prevent neural networks
from overﬁtting. JMLR, 15(1):1929–1958.

Octavia Maria Sulea, Marcos Zampieri, Mihaela Vela,
and Josef Van Genabith. 2017. Exploring the use of
text classi cation in the legal domain. In Proceedings
of ASAIL workshop.

Maosong Sun, Xinxiong Chen, Kaixu Zhang, Zhipeng
Guo, and Zhiyuan Liu. 2016. Thulac: An efﬁcient
lexical analyzer for chinese.

Johan AK Suykens and Joos Vandewalle. 1999. Least
squares support vector machine classiﬁers. Neural
processing letters, 9(3):293–300.

Duyu Tang, Bing Qin, and Ting Liu. 2015. Document
modeling with gated recurrent neural network for
sentiment classiﬁcation. In Proceedings of EMNLP,
pages 1422–1432.

S Sidney Ulmer. 1963. Quantitative analysis of judi-
cial processes: Some practical and theoretical appli-
cations. Law and Contemporary Problems, 28:164.

Legal Judgment Prediction via Topological Learning

Haoxi Zhong∗, Zhipeng Guo∗, Cunchao Tu, Chaojun Xiao, Zhiyuan Liu†, Maosong Sun
Department of Computer Science and Technology
State Key Lab on Intelligent Technology and Systems
Institute for Artiﬁcial Intelligence, Tsinghua University, Beijing, China
{zhonghx18,gzp17,xiaocj16}@mails.tsinghua.edu.cn, tucunchao@gmail.com
{lzy,sms}@tsinghua.edu.cn

Abstract

Legal Judgment Prediction (LJP) aims to pre-
dict the judgment result based on the facts of
a case and becomes a promising application
of artiﬁcial intelligence techniques in the le-
gal ﬁeld. In real-world scenarios, legal judg-
ment usually consists of multiple subtasks,
such as the decisions of applicable law arti-
cles, charges, ﬁnes, and the term of penalty.
Moreover, there exist topological dependen-
cies among these subtasks. While most ex-
isting works only focus on a speciﬁc sub-
task of judgment prediction and ignore the de-
pendencies among subtasks, we formalize the
dependencies among subtasks as a Directed
Acyclic Graph (DAG) and propose a topo-
logical multi-task learning framework, TOP-
JUDGE, which incorporates multiple subtasks
and DAG dependencies into judgment predic-
tion. We conduct experiments on several real-
world large-scale datasets of criminal cases
in the civil law system. Experimental results
show that our model achieves consistent and
signiﬁcant improvements over baselines on all
judgment prediction tasks. The source code
can be obtained from https://github.
com/thunlp/TopJudge.

1

Introduction

Legal Judgment Prediction (LJP) aims to predict
the judgment results of legal cases according to the
fact descriptions. It is a critical technique for the
legal assistant system. On the one hand, LJP can
provide low-cost but high-quality legal consulting
services to the masses who are unfamiliar with le-
gal terminology and the complex judgment pro-
cedures. On the other hand, it can serve as the
handy reference for professionals (e.g., lawyers
and judges) and improve their work efﬁciency.

∗ Indicates equal contribution. The order is determined by

dice rolling.

† Corresponding author.

Figure 1: An illustration of the judicial logic of hu-
man judges in civil law system.

LJP has been studied for decades (Kort, 1957;
Ulmer, 1963; Nagel, 1963; Keown, 1980; Segal,
1984; Lauderdale and Clark, 2012; Ye et al., 2018;
Hu et al., 2018), and most existing works for-
malize LJP as a text classiﬁcation task. For ex-
ample, some works (Liu et al., 2004; Liu and
Hsieh, 2006) propose to extract shallow textual
features (e.g. characters, words, and phrases) for
charge prediction. Katz et al. (2017) predict the
US Supreme Court’s decisions based on efﬁcient
features from case proﬁles. Luo et al. (2017) pro-
pose an attention-based neural model for charge
prediction by incorporating the relevant law arti-
cles.

Despite these efforts in designing efﬁcient fea-
tures and employing advanced NLP techniques,
LJP is still confronted with two major challenges:
Multiple Subtasks in Legal Judgment: Prac-
tically, legal judgment usually consists of detailed
and complicated subclauses, such as charges, the
term of penalty, and ﬁnes. Speciﬁcally, for those
countries with the civil law system (e.g., China,
France, and Germany), the prediction of relevant
articles is also considered to be one of the funda-
mental subtasks, which will guide the prediction
for other subtasks. In other words, all these sub-
tasks compose the complete form of judgment pre-

diction. Nevertheless, existing works on LJP usu-
ally focus on one speciﬁc subtask of judgments,
which does not conform to the real scenarios. Al-
though some methods (Luo et al., 2017) are devel-
oped to predict law articles and charges at the same
time, their models are designed for a speciﬁc set of
subtasks which are hard to scale to other subtasks.
Topological Dependencies between Subtasks:
there exists a strict order
For human judges,
among the subtasks of legal judgment. As illus-
trated in Fig. 1, given the fact description of a spe-
ciﬁc case, a judge in the civil law system ﬁrst de-
cides which law articles are relevant to the sce-
nario, and then determines the charges according
to the instructions of relevant law articles. Based
on these results, the judge further conﬁrms the
term of penalty and ﬁnes. How to simulate the ju-
dicial logic of human judges and model the topo-
logical dependencies among legal subtasks will
deeply inﬂuence the creditability and interpretabil-
ity of judgment prediction.

As stated above, conventional works cannot
handle these two challenges due to both the lim-
itation of speciﬁc tasks and neglecting topological
dependencies. To address these issues, we propose
to model the multiple subtasks in judgment pre-
diction jointly under a novel multi-task learning
framework.

We model the topological dependencies among
these subtasks with a Directed Acyclic Graph
(DAG), which means all subtasks are arranged in
topological order. If the judgment of the j-th sub-
task tj depends on the output of the i-th subtask
ti, then ti appears earlier than tj in such order. It
is notable that such formulation provides an ex-
plicit explanation of dependency relations among
subtasks.

Accordingly, we introduce topological learning
for LJP and propose a uniﬁed framework, named
as TOPJUDGE. Speciﬁcally, given the encoded
representation of the fact description, TOPJUDGE
predicts the outputs of all the subtasks following
the topological order, and the output of a speciﬁc
subtask will be affected by all the subtasks it de-
pends on. In contrast with conventional multi-task
learning, our model takes the explicit topological
dependencies of LJP subtasks into consideration
and is ﬂexible to handle other LJP subtasks. More-
over, the topological order of legal dependencies
renders our model interpretable and reliable.

To verify the effectiveness and ﬂexibility of

TOPJUDGE, we conduct a series of experiments
on several real-world large-scale datasets. Exper-
imental results show that our model achieves sig-
niﬁcant and consistent improvements over state-
of-the-art models on all tasks and datasets. To
summarize, we make several noteworthy contribu-
tions as follows:

(1) We are the ﬁrst to explore and formalize the
multiple subtasks of legal judgment under a joint
learning framework. Moreover, we formulate the
dependencies among the subtasks of LJP as a form
of DAG and introduce this prior knowledge to en-
hance judgment prediction.

(2) We propose a novel judgment prediction
framework, TOPJUDGE, to unify multiple sub-
tasks and make judgment predictions through
topological learning. This model can handle any
form of DAG dependent subtasks, which has been
veriﬁed in the experiments.

(3) We carry out experiments on several large-
scale real-world datasets, and our model signiﬁ-
cantly and consistently outperforms all the base-
lines on all subtasks.

2 Related Work

2.1

Judgment Prediction

Employing automatic analysis techniques for legal
judgment has drawn attention from researchers in
the legal ﬁeld for decades. Early works usually
focus on analyzing existing legal cases in speciﬁc
scenarios with mathematical and statistical algo-
rithms (Kort, 1957; Ulmer, 1963; Nagel, 1963;
Keown, 1980; Segal, 1984; Lauderdale and Clark,
2012).

With the development of machine learning and
text mining techniques, more researchersformal-
ize this task under text classiﬁcation frameworks.
Most of these studies attempt to extract efﬁcient
features from text content (Liu and Hsieh, 2006;
Lin et al., 2012; Aletras et al., 2016; Sulea et al.,
2017) or case annotations (e.g., dates, terms, lo-
cations, and types) (Katz et al., 2017). However,
these conventional methods can only utilize shal-
low textual features and manually designed fac-
tors, both require massive human efforts and usu-
ally suffer from the generalization issue when ap-
plied to other scenarios.

Inspired by the success of neural networks on
NLP tasks (Kim, 2014; Baharudin et al., 2010;
Tang et al., 2015), researchers began to handle LJP
by incorporating neural models with legal knowl-

edge. For example, Luo et al. (2017) present an
attention-based neural network that jointly mod-
els charge prediction and relevant article extrac-
tion. Hu et al. (2018) incorporate 10 discrimina-
tive legal attributes to predict few-shot and con-
fusing charges. Nevertheless, these models are de-
signed for speciﬁc subtasks and thus non-trivial to
be extended to more subtasks of LJP with complex
dependencies. Besides, Ye et al. (2018) utilize a
Seq2Seq model to generate court views with fact
descriptions and predicted charges in Chinese civil
law.

2.2 Multi-task Learning

Multi-task learning (MTL) aims to exploit the
commonalities and differences across relevant
tasks by solving them at the same time.
It can
transfer useful information among various tasks
and has been applied to a wide range of ar-
eas, including NLP (Collobert and Weston, 2008),
speech recognition (Deng et al., 2013), and com-
puter vision (Girshick, 2015; Mao et al., 2017).

There have been numerous successful usages
of MTL in NLP tasks. Most works follow the
hard parameter sharing setting by sharing repre-
sentations or some encoding layers among rele-
vant tasks. For example, Collobert and Weston
(2008) use shared word embeddings in solving
part-of-speech tagging and semantic role labeling
tasks. Liu et al. (2015) share the encoding lay-
ers of input queries to address query classiﬁcation
and information retrieval. Dong et al. (2015) and
Luong et al. (2016) propose to share encoders or
decoders to improve one (many) to many neural
machine translation. Firat et al. (2016) propose to
share attention mechanism in multi-way, multilin-
gual machine translation. Besides hard parameter
sharing, soft parameter sharing is another com-
mon approach in MTL. It assumes that each task
owns its speciﬁc parameters and the distance be-
tween parameters in different tasks should be close
to each other. For example, Duong et al. (2015)
employ L2 distance for regularization, while Yang
and Hospedales (2017) use the trace norm. Liu
et al. (2016) introduce gates among task-speciﬁc
RNN layers to control the information ﬂow. Ruder
et al. (2017) introduce a model which can de-
cide the amount of sharing between different NLP
tasks. There are also some works focusing on in-
creasing tasks (Hashimoto et al., 2017) or handing
unlabeled data (Augenstein et al., 2018).

Figure 2: The framework of TOPJUDGE.

In this work, we introduce a topological learn-
ing framework TOPJUDGE to handle multiple sub-
tasks in LJP. Different to conventional MTL mod-
els which focus on how to share parameters among
relevant tasks, TOPJUDGE models the explicit de-
pendencies among these subtasks with scalable
DAG forms.

3 Method

In the following parts, we will ﬁrst give the essen-
tial deﬁnitions of LJP task. We then introduce the
DAG dependencies of the subtasks in LJP. And ﬁ-
nally, we describe the neural encoder for fact rep-
resentation and the judgment predictor for the sub-
tasks with DAG dependencies. The overall frame-
work of TOPJUDGE has been shown in Fig 2.

3.1 Problem Formulation

We will focus on the LJP tasks in civil law. Sup-
pose the fact description of a case is a word se-
quence x = {x1, x2, . . . , xn}, where n is the
length of x and each word xi comes from a ﬁxed
vocabulary W . Based on the fact description x,
the task of LJP T aims to predict judgment results
of applicable law articles, charges, term of penalty,
ﬁnes and so on. Formally, we assume T contains
|T | subtasks, i.e., T = {t1, t2, . . . , t|T |}, each of
which is a classiﬁcation task. For the i-th subtask
ti ∈ T , we aim to predict the corresponding result
yi ⊆ Yi, where Yi is a subtask-speciﬁc label set.
Take the subtask of charge prediction for example,
the corresponding label set should contain Theft,
Trafﬁc Violation, Intentional Homicide and so on.

3.2 DAG Dependencies of Subtasks

We assume that the dependencies among multiple
subtasks of LJP form a DAG. As a result, the task
list T should satisfy topological constraints. For-
mally, we use the notation ti (cid:1) tj to denote that

(a) Typical MTL form of DAG

(b) Sequential form of DAG

(c) General form of DAG

Figure 3: Three typical forms of DAG dependencies.

the j-th subtask depends on the i-th subtask, and
Dj = {ti | ti (cid:1) tj} to denote the dependency set.
The task list T can be ordered to satisfy the fol-
lowing constraint

i < j,

∀(i, j) ∈ {(i, j) | ti ∈ Dj}.

(1)

We demonstrate the ﬂexibility of our formula-
tion by describing two special cases: (1) As shown
in Fig. 3 (a), if no dependencies exist, i.e., Dj = ∅,
it corresponds to the typical MTL setting where
we simultaneously make predictions for all sub-
tasks. (2) As shown in Fig. 3 (b), if each task only
depends on its previous task, i.e., Dj = {tj−1}, it
forms a sequential learning process.

3.3 Neural Encoder for Fact Descriptions

We employ a fact encoder to generate the fact de-
scription’s vector representation as the input of
TOPJUDGE. In the following part, we brieﬂy in-
troduce an encoder based on Convolutional Neural
Networks (CNN) (Kim, 2014).

Taking a word sequence x as input, the CNN
encoder computes the text representation through
three layers, i.e., lookup layer, convolution layer
and pooling layer.

Lookup We ﬁrst convert each word xi in x into
its word embedding xi ∈ Rk, where k is the di-
mension of word embeddings. The word embed-
ding sequence is then represented as

ˆx = {x1, x2, . . . , xn}.

(2)

Convolution A convolution operation involves
a convolution matrix W ∈ Rm×(h×k), which is
applied to a sliding window of length h with num-
ber of ﬁlters m to produce a feature map by

ci = W · xi:i+h−1 + b,

(3)

where xi:i+h−1 is the concatenation of word em-
beddings within the i-th window and b ∈ Rm is
the bias vector. By applying convolution over each
window, we obtain c = {c1, . . . , cn−h+1}.

Pooling We apply per-dimension max-pooling
over c and obtain the ﬁnal fact representation d =
[d1, . . . , dm] by

dt = max(c1,t, . . . , cn−h+1,t), ∀t ∈ [1, m].

(4)

3.4

Judgment Predictor over DAG

Based on the DAG assumption, we obtain an or-
dered task list T ∗ = [t1, t2, . . . , t|T |]. For each
task tj ∈ T , we aim to predict its judgment result
yj based on the fact representation vector d and
the judgment results of its dependent tasks.

For prediction, we employ a speciﬁc LSTM cell
for each task and get the output of each task in
the topological order. More speciﬁcally, for each
task tj ∈ T , we obtain its ﬁnal judgment result
through three steps, i.e., cell initialization, task-
speciﬁc representation, and prediction.

Cell Initialization As stated above, the predic-
tion result of tj will be conditioned on the fact
representation d and the outputs of all dependent
tasks yk, ∀tk ∈ Dj. Hence, we have

(cid:105)

(cid:104)¯hj
¯cj

=

(cid:88)

(cid:16)

Wi,j

(cid:105)(cid:17)

(cid:104)hi
ci

+ bj

(5)

ti∈Dj

Here, hi and ci are the hidden state and memory
cell of ti. ¯hj and ¯cj are the initial hidden state and
memory cell of tj. Wi,j and bj are transformation
matrices and bias vectors speciﬁc to ti and tj.

Task-Speciﬁc Representation Taking the fact
representation d, the initial hidden state ¯hj, and
the initial memory cell ¯cj as inputs, we process

them with an LSTM cell (Hochreiter and Schmid-
huber, 1997).

We regard the ﬁnal hidden state hj as the task-
speciﬁc representation of task tj. The last cell
state cj is used to compose the initial hidden state
for the downstream tasks by Eq. 5

Prediction With the representation hj, we ap-
ply an afﬁne transformation followed by softmax
and obtain the ﬁnal prediction as

ˆyj = softmax (cid:0)Wp

j hj + bp

j

(cid:1) .

(6)

j are parameters speciﬁc to task

Here, Wp
tj.

j and bp

With the prediction result ˆyj, we minimize the

cross-entropy between ˆyj and yj as follows:

Lj(ˆyj, yj) = −

yj,k log(ˆyj,k).

(7)

|Yj |
(cid:88)

k=1

3.5 Training

We use cross-entropy loss for each subtask and
sum up losses to train TOPJUDGE:

L =

λjLj(ˆyj, yj),

(8)

|T |
(cid:88)

j=1

where λj is the weight factor for each subtask tj.
The DAG dependencies of subtasks ensure that
our model is differentiable and can be trained in an
end-to-end fashion. In practice, we set all weights
λj to 1, and employ Adam (Kingma and Ba, 2015)
for optimization. We also apply dropout (Srivas-
tava et al., 2014) on the fact representation to pre-
vent overﬁtting.

4 Experiments

To evaluate the proposed TOPJUDGE framework,
we conduct a series of experiments on LJP over
three large-scale datasets of criminal cases in
China. We select three representative judgment
prediction subtasks for comparison, including law
articles, charges, and the terms of penalty.

4.1 Dataset Construction

As there are no publicly available LJP datasets
in previous works, we collect and construct three
different LJP datasets, including CJO, PKU, and
CAIL. CJO consists of criminal cases published
by the Chinese government from China Judge-
ment Online1. PKU contains criminal cases pub-
lished by Peking University Law Online2. CAIL

1 http://wenshu.court.gov.cn/
2 http://www.pkulaw.com/

Datasets

CJO

PKU

CAIL

Cases
Law Articles
Charges
Term of Penalty

1, 007, 744
98
99
11

175, 744
68
64
11

113, 536
105
122
11

Table 1: The statistics of different datasets.

(Chinese AI and Law Challenge) is another crim-
inal case dataset for competition released by the
Supreme People’s Court of China3. The details of
CAIL can be found in Xiao et al. (2018).

For all datasets we mentioned above, as the doc-
uments are well-structured and human-annotated,
we can easily extract fact descriptions, applica-
ble law articles, charges and the terms of penalty
from each document using regular expressions.
We have manually checked a randomly sampled
set of cases, and extraction errors are negligible.

In real-world scenarios, there are some cases
with multiple defendants and multiple charges,
which will increase the complexity of judgment
prediction. As our model aims to explore the ef-
fectiveness of considering topological dependen-
cies between various subtasks, we ﬁlter out these
cases and leave them as our future work.

Meanwhile,

there are also some infrequent
charges and law articles, such as money launder-
ing, smuggling of nuclear materials and tax dodge.
We ﬁlter out these infrequent charges and law arti-
cles and only keep those with frequencies greater
than 100. For the term of penalty, we divide the
terms into non-overlapping intervals. We list de-
tailed statistics of these datasets in Table 1.

4.2 Baselines

For comparison, we employ the following text
classiﬁcation models and judgment prediction
methods as baselines:

TFIDF+SVM: We employ term-frequency in-
verse document frequency (TFIDF) (Salton and
Buckley, 1988) to extract word features and uti-
lize SVM (Suykens and Vandewalle, 1999) for text
classiﬁcation.

CNN: We employ CNN with multiple ﬁlter
widths (Kim, 2014) for fact encoding and classi-
ﬁcation.

Hierarchical LSTM (HLSTM): Tang et al.
(2015) employs hierarchical neural networks to
learn document representations in sentiment clas-

3 http://cail.cipsc.org.cn/index.html

Tasks

Law Articles

Charges

The Term of Penalty

Metrics

Acc. MP MR

F1

Acc. MP MR

F1

Acc. MP MR

F1

Single

Multi

TFIDF+SVM 82.4
92.5
91.4

CNN
HLSTM

Fact-Law Att.
PM
CNN-MTL
HLSTM-MTL

93.5
93.7
94.3
92.4

94.4

45.5
46.9
38.6

50.9
51.9
53.0
45.5

53.9

26.7
38.4
37.3

45.6
44.1
46.0
41.4

47.3

30.2
40.0
36.9

45.9
44.9
46.9
41.0

48.2

82.2
92.3
91.8

93.4
93.6
94.1
92.3

94.9

47.4
41.2
37.8

47.2
45.5
48.5
41.9

53.9

27.9
32.3
36.0

41.4
39.1
41.7
36.6

48.2

31.3
33.7
35.2

41.5
39.3
42.5
35.9

49.1

48.5
57.4
56.1

56.3
58.2
58.7
54.9

58.8

36.0
35.6
22.5

31.3
38.2
39.9
30.6

40.2

16.7
22.2
25.0

26.4
24.9
28.8
26.6

32.9

16.5
22.7
23.3

26.7
26.8
29.4
26.4

32.8

Ours

TOPJUDGE

Table 2: Judgment prediction results on CJO.

Tasks

Law Articles

Charges

The Term of Penalty

Metrics

Acc. MP MR

F1

Acc. MP MR

F1

Acc. MP MR

F1

Single

Multi

TFIDF+SVM 80.9
93.1
91.7

CNN
HLSTM

Fact-Law Att.
PM
CNN-MTL
HLSTM-MTL

93.9
94.4
95.0
93.9

95.4

51.3
64.3
54.4

68.1
69.6
73.8
71.2

76.4

32.6
52.6
53.4

63.4
61.0
64.9
64.6

67.6

36.4
54.3
50.9

63.5
62.2
66.0
65.1

68.4

81.0
93.3
91.9

94.2
94.3
95.0
93.8

95.6

53.4
61.9
52.5

65.8
65.1
70.7
67.8

75.9

35.4
49.3
48.9

58.5
56.2
60.6
60.0

69.6

38.7
51.1
47.3

58.7
57.2
61.7
60.7

70.9

45.3
57.6
54.3

55.7
58.2
58.4
55.4

57.8

30.4
24.1
20.6

27.7
36.2
36.0
31.3

38.9

17.4
23.1
21.7

27.4
26.4
28.7
26.2

32.1

17.2
23.3
19.0

26.5
27.1
28.9
25.7

31.8

Ours

TOPJUDGE

Table 3: Judgment prediction results on PKU.

siﬁcation. Based on this work, we employ an
LSTM for sentence representations and another
one to obtain the representation of complete fact
descriptions.

Fact-Law Attention Model: Luo et al. (2017)
proposes a neural charge prediction model by cap-
turing the interaction between fact descriptions
and applicable laws with attention mechanism.

Pipeline Model (PM): To demonstrate the
advantage of TOPJUDGE on modeling subtasks
jointly, we also implement a pipelined method for
comparison. Here, we train 3 separate CNN classi-
ﬁers for law articles, charges, and term of penalty.
For each subtask, the input is the concatenation
of the fact representation and the embeddings for
predicted labels of previous subtasks.

Besides, we compare our model with conven-
tional MTL methods that do not consider the de-
pendencies among subtasks as in Fig. 3 (a). These
methods are denoted as CNN-MTL and HLSTM-
MTL, where we implement the fact encoder as in
Fig. 2 using CNN or HLSTM respectively.

4.3 Experimental Settings

As the case documents are written in Chinese
with no space between words, we employ THU-
LAC (Sun et al., 2016) for word segmentation. Af-
terward, we adopt the Skip-Gram model (Mikolov
et al., 2013) to pre-train word embeddings on these

case documents, with embedding size set to 200
and frequency threshold set to 25.

For all models, we set

the fact representa-
tion and task-speciﬁc representation size to 256.
Meanwhile, we set the maximum sentence length
to 128 words and maximum document length to
32 sentences.

For training, the learning rate of Adam opti-
mizer is 10−3, and the dropout probability is 0.5.
We also set the batch size to 128 for all models.
We train every model for 16 epochs, and evaluate
the ﬁnal model on the testing set.

We employ accuracy (Acc.), macro-precision
(MP), macro-recall (MR) and macro-F1 (F1)
the macro-
as evaluation metrics.
precision/recall/F1 are calculated by averaging the
precision/recall/F1 of each category.

Here,

4.4 Results and Analysis

We evaluate the performance on three LJP sub-
including law articles (denoted as t1),
tasks,
charges (denoted as t2), and the terms of penalty
(denoted as t3). Experimental results are shown in
Tables 2, 3, and 4. Note that, we implement TOP-
JUDGE with the dependency relationship in Fig. 3
(c), i.e.,

D1 = φ, D2 = {t1}, D3 = {t1, t2}.

(9)

Tasks

Law Articles

Charges

The Term of Penalty

Metrics

Acc. MP MR

F1

Acc. MP MR

F1

Acc. MP MR

F1

Single

Multi

TFIDF+SVM 60.1
81.4
-

CNN
HLSTM

Fact-Law Att.
PM
CNN-MTL
HLSTM-MTL

70.9
84.7
84.5
-

86.3

54.9
74.4
-

64.8
80.7
80.0
-

81.9

45.3
64.1
-

63.6
68.6
68.1
-

71.1

46.3
65.7
-

59.1
70.8
70.3
-

73.4

59.2
80.7
-

68.7
83.6
83.4
-

85.7

53.9
77.3
-

66.1
81.6
81.6
-

83.4

45.0
65.5
-

65.3
70.0
69.1
-

76.0

45.7
67.2
-

60.1
72.1
71.6
-

78.3

28.4
28.8
-

36.5
40.0
39.5
-

38.3

22.9
34.7
-

29.9
37.4
37.2
-

36.1

20.0
27.8
-

27.6
32.0
32.3
-

33.1

18.1
28.6
-

27.1
31.6
31.3
-

32.1

Ours

TOPJUDGE

Table 4: Judgment prediction results on CAIL. Note that, “-” means the model does not converge within
128 epochs.

This means that the prediction of charges depends
on law articles, and the prediction of term of
penalty depends on both law articles and charges.
Such explicit dependencies conform to the judi-
cial logic of human judges, which will be veriﬁed
in later sections. These results show that:

(1) The proposed TOPJUDGE model outper-
forms other baselines signiﬁcantly on most sub-
tasks and datasets. It demonstrates the effective-
ness and robustness of our proposed framework.

(2) Compared with conventional single-task
models, e.g., CNN and HLSTM, MTL methods
take advantage of the correlation among relevant
subtasks and thus achieve promising improve-
It indicates the importance of modeling
ments.
LJP subtasks jointly.

(3) Moreover, TOPJUDGE signiﬁcantly outper-
forms typical MTL models, especially on the pre-
diction of charges and the terms of penalty. It veri-
ﬁes the rationality and importance of modeling de-
pendencies over LJP subtasks with DAG.

4.5 Ablation Analysis

Tasks

t1

t2

t3

Metrics

Acc.

F1

Acc.

F1

Acc.

F1

TOPJUDGE
- t3 (cid:1) t1
- t2 (cid:1) t1
φ

95.4
95.2
94.8
94.7

68.4
67.7
64.7
64.4

95.6
95.4
94.9
94.9

70.9
70.3
60.2
60.1

57.8
57.4
57.0
57.8

31.8
31.2
31.6
27.6

Table 5: Ablation analysis on PKU.

To further illustrate the signiﬁcance of legal de-
pendencies and explore how the DAG dependen-
cies inﬂuence the performance, we evaluate the
performance of TOPJUDGE under various DAG
architectures. Using Eq. 9 as the full dependen-
cies, we remove the dependency of t3 (cid:1) t1 (law
articles and term of penalty, corresponding to the
sequential form in Fig. 3), t2 (cid:1) t1 (law articles and

charges), and all dependencies respectively. Re-
sults are summarized in Table 5.

We observe that the performance of TOPJUDGE
decreases on all tasks after removing either depen-
dency. More speciﬁcally, when we dropped de-
pendencies t3 (cid:1) t1 and t2 (cid:1) t1 respectively, sig-
niﬁcant decreases are observed for t3 and t2 corre-
spondingly. This demonstrates that incorporating
dependencies is beneﬁcial for relevant subtasks,
verifying its guiding role in the civil law system.

Meanwhile, we note that there are two main
differences between TOPJUDGE and traditional
multi-task models, namely the Cell Initialization
and the Task-Speciﬁc Representation. We can
see that if we eliminate Cell Initialization from
TOPJUDGE,
the dependencies will not be rep-
resented in the model and it will become sim-
ilar to CNN-MTL. If we eliminate the Task-
Speciﬁc Representation from TOPJUDGE, TOP-
JUDGE will become the same as the Pipeline
Model. In a word, the main improvement of our
models comes from the combination.

4.6 Case Study

We give some intuitive examples to demonstrate
the signiﬁcance of TOPJUDGE on LJP subtasks.

As shown in Table 6, case 1 is about negligently
causing a ﬁre. The fact description of this case
states “The defendant pulled up weeds in the ﬁelds
and piled them up in haphazard stacks. Afterward,
he lighted them up and triggered the forest ﬁres...”
TOPJUDGE predicts all judgments correctly, while
CNN-MTL fails to predict the charge and term of
penalty. Moreover, CNN-MTL obtains conﬂicting
judgments, i.e., “crime of arson” and “1-2 years”,
due to its neglecting of dependencies of these sub-
tasks. According to the legal provisions of law ar-
ticle 115, the crime of arson should be sentenced
to more than 10 years.

Methods

Law Charge

Term
(months)

12-24(×)

CNN-MTL

115 Arson(×)

TOPJUDGE

115 Negligently Caus-
ing a Fire

0-6

CNN-MTL

293

Intentional Dam-
age to Property(×)

12-24(×)

TOPJUDGE

293 Affray

0-6

Table 6: Example cases and their prediction results.

Case 2 in Table 6 is another evidence of the in-
sufﬁciency of conventional MTL on LJP. This case
is about picking quarrels and provoking troubles.
Both CNN-MTL and TOPJUDGE succeed to pre-
law article 293
dict the relevant law articles (i.e.,
of the crime of affray). However, CNN-MTL is
confused between “crime of affray” and “crime of
intentional destruction or damage of properties”,
two charges similar to each other. Conversely,
TOPJUDGE can utilize the prediction result of law
articles and consequently prevent this confusion.

To summarize, modeling the explicit dependen-
cies among various subtasks can remarkably help
the LJP model address the issue of predicting con-
ﬂicting results.

4.7 Error Analysis

Prediction errors induced by our proposed model
can be traced down into the following causes.

Data Imbalance.

For the subtasks of law
articles and charges, our model achieves more
than 90% on accuracy, while only about 60% for
macro-F1. This issue is much more severe on the
subtask of the term of penalty, which our model
yields a poor performance of only 30% macro-F1.
The bad performance is mainly due to the imbal-
ance of category labels, e.g., there are only a few
training instances where the term is “life imprison-
ment or death penalty”. Most judgment prediction
approaches perform poorly (especially for Recall)
on these labels as listed in Fig. 4. Instance weight-
ing schemes can be introduced to address this is-
sue in future works.

Incomplete Information. Following existing
LJP works, we predict the ﬁnal judgment accord-
ing to the fact descriptions, which is incomplete as
compared to the whole materials relevant to this
In Chinese Law, there are certain circum-
case.
stances under which the sentence can be short-
ened. For example, minors usually receive a light-

Figure 4: The confusion matrix in the subtask
of predicting the term of penalty on the PKU
dataset. The rows denote the ground truth while
the columns denote the prediction results.

ened penalty, and those guilty of misdemeanors
are allowed for a secured pending trial while pay-
ing a security deposit. However, such informa-
tion is not included in the fact descriptions. The
lack of such information also raises difﬁculties for
judgment prediction, especially for the prediction
of the term of penalty. In Fig. 4, we can see that
the highest error rate comes from the cases with a
short term of penalty. Our model fails to distin-
guish the cases with no penalty and those with 0-6
months term of imprisonment.

5 Conclusion

In this paper, we focus on the task of legal judg-
ment prediction (LJP) and address multiple sub-
tasks of judgment predication with a topological
learning framework. To be speciﬁc, we formalize
the explicit dependencies over these subtasks in a
DAG form, and propose a novel MTL framework,
TOPJUDGE, by integrating the DAG dependen-
cies. Experimental results on three LJP subtasks
and three different datasets show that our TOP-
JUDGE outperforms all single-task baselines and
conventional MTL models consistently and signif-
icantly.

In the future, we will seek to explore the follow-
ing directions: (1) We will explore more LJP sub-
tasks and more scenarios of cases such as multiple

defendants and charges to investigate the effective-
ness of TOPJUDGE. (2) We will explore how to
incorporate into LJP the temporal factors, which
are not considered in this work.

6 Acknowledgements

This work is supported by the National Nat-
ural Science Foundation of China (NSFC No.
61572273, 61772302) and the research fund of
Powerlaw Inc.
for AI+Law Technology. This
work is also funded by China Association for Sci-
ence and Technology (2016QNRC001). Tu is also
supported by China Postdoctoral Innovative Talent
Support Programme.

References

Nikolaos Aletras, Dimitrios Tsarapatsanis, Daniel
Preotiuc-Pietro, and Vasileios Lampos. 2016. Pre-
dicting judicial decisions of the european court of
human rights: A natural language processing per-
spective. PeerJ Computer Science, 2.

Isabelle Augenstein, Sebastian Ruder, and Anders
Søgaard. 2018. Multi-task learning of pairwise
sequence classiﬁcation tasks over disparate label
spaces. In Proceedings of NAACL.

Baharum Baharudin, Lam Hong Lee, and Khairullah
Khan. 2010. A review of machine learning algo-
rithms for text-documents classiﬁcation. Journal of
Advances in Information Technology, 1(1):4–20.

Ronan Collobert and Jason Weston. 2008. A uniﬁed
architecture for natural language processing: Deep
In Pro-
neural networks with multitask learning.
ceedings of ICML, pages 160–167.

Li Deng, Geoffrey Hinton, and Brian Kingsbury. 2013.
New types of deep neural network learning for
speech recognition and related applications: An
overview. In Proceedings of ICASSP, pages 8599–
8603.

Daxiang Dong, Hua Wu, Wei He, Dianhai Yu, and
Haifeng Wang. 2015. Multi-task learning for mul-
tiple language translation. In Proceedings of ACL,
volume 1, pages 1723–1732.

Long Duong, Trevor Cohn, Steven Bird, and Paul
Cook. 2015. Low resource dependency parsing:
Cross-lingual parameter sharing in a neural network
In Proceedings of ACL, volume 2, pages
parser.
845–850.

Orhan Firat, Kyunghyun Cho, and Yoshua Bengio.
2016. Multi-way, multilingual neural machine
translation with a shared attention mechanism.
In
Proceedings of NAACL, pages 866–875.

Ross Girshick. 2015. Fast r-cnn.

In Proceedings of

ICCV, pages 1440–1448.

Kazuma Hashimoto, Yoshimasa Tsuruoka, Richard
Socher, et al. 2017. A joint many-task model: Grow-
ing a neural network for multiple nlp tasks. In Pro-
ceedings of EMNLP, pages 1923–1933.

Sepp Hochreiter and Jurgen Schmidhuber. 1997.
Neural computation,

Long short-term memory.
9(8):1735–1780.

Zikun Hu, Xiang Li, Cunchao Tu, Zhiyuan Liu, and
Maosong Sun. 2018. Few-shot charge prediction
with discriminative legal attributes. In Proceedings
of COLING.

Daniel Martin Katz, Michael J Bommarito II, and Josh
Blackman. 2017. A general approach for predict-
ing the behavior of the supreme court of the united
states. Plos one, 12(4).

R Keown. 1980. Mathematical models for legal pre-

diction. Computer/LJ, 2:829.

Yoon Kim. 2014. Convolutional neural networks for
sentence classiﬁcation. In Proceedings of EMNLP.

Diederik Kingma and Jimmy Ba. 2015. Adam: A
method for stochastic optimization. In Proceedings
of ICLR.

Fred Kort. 1957. Predicting supreme court decisions
mathematically: A quantitative analysis of the ”right
to counsel” cases. American Political Science Re-
view, 51(1):1–12.

Benjamin E Lauderdale and Tom S Clark. 2012. The
supreme court’s many median justices. American
Political Science Review, 106(4):847–866.

Wanchen Lin, Tsung Ting Kuo, and Tung Jia Chang.
2012. Exploiting machine learning models for chi-
nese legal documents labeling, case classiﬁcation,
and sentencing prediction. In Processdings of RO-
CLING, page 140.

Chaolin Liu, Cheng Tsung Chang, and Jim How Ho.
2004. Case instance generation and reﬁnement
for case-based criminal summary judgments in chi-
nese. Journal of Informationence & Engineering,
20(4):783–800.

Chaolin Liu and Chwen Dar Hsieh. 2006. Exploring
phrase-based classiﬁcation of judicial documents for
criminal charges in chinese. In Proceedings of IS-
MIS, pages 681–690.

Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2016.
Recurrent neural network for text classiﬁcation with
multi-task learning. In Proceedings of IJCAI.

Xiaodong Liu, Jianfeng Gao, Xiaodong He, Li Deng,
Kevin Duh, and Ye-Yi Wang. 2015. Representation
learning using multi-task deep neural networks for
semantic classiﬁcation and information retrieval. In
Proceedings of NAACL, pages 912–921.

Chaojun Xiao, Haoxi Zhong, Zhipeng Guo, Cunchao
Tu, Zhiyuan Liu, Maosong Sun, Yansong Feng,
Xianpei Han, Zhen Hu, Heng Wang, et al. 2018.
Cail2018: A large-scale legal dataset for judgment
prediction. arXiv preprint arXiv:1807.02478.

Yongxin Yang and Timothy Hospedales. 2017. Deep
multi-task representation learning: A tensor factori-
sation approach. In Proceedings of ICLR.

Hai Ye, Xin Jiang, Zhunchen Luo, and Wenhan Chao.
2018. Interpretable charge predictions for criminal
cases: Learning to generate court views from fact
descriptions. In Proceedings of NAACL.

Bingfeng Luo, Yansong Feng, Jianbo Xu, Xiang
Zhang, and Dongyan Zhao. 2017. Learning to pre-
dict charges for criminal cases with legal basis. In
Proceedings of EMNLP.

Minh-Thang Luong, Quoc V Le, Ilya Sutskever, Oriol
Vinyals, and Lukasz Kaiser. 2016. Multi-task se-
In Proceedings of
quence to sequence learning.
ICLR.

Jiayuan Mao, Tete Xiao, Yuning Jiang, and Zhimin
Cao. 2017. What can help pedestrian detection? In
Proceedings of CVPR, pages 3127–3136.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Proceedings of NIPS, pages 3111–3119.

Stuart S Nagel. 1963. Applying correlation analysis to

case prediction. Texas Law Review, 42:1006.

Sebastian Ruder, Joachim Bingel, Isabelle Augen-
stein, and Anders Søgaard. 2017. Learning what to
share between loosely related tasks. arXiv preprint
arXiv:1705.08142.

Gerard Salton and Christopher Buckley. 1988. Term-
weighting approaches in automatic text retrieval. In-
formation processing & management, 24(5):513–
523.

Jeffrey A Segal. 1984. Predicting supreme court cases
probabilistically: The search and seizure cases,
American Political Science Review,
1962-1981.
78(4):891–900.

Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: a simple way to prevent neural networks
from overﬁtting. JMLR, 15(1):1929–1958.

Octavia Maria Sulea, Marcos Zampieri, Mihaela Vela,
and Josef Van Genabith. 2017. Exploring the use of
text classi cation in the legal domain. In Proceedings
of ASAIL workshop.

Maosong Sun, Xinxiong Chen, Kaixu Zhang, Zhipeng
Guo, and Zhiyuan Liu. 2016. Thulac: An efﬁcient
lexical analyzer for chinese.

Johan AK Suykens and Joos Vandewalle. 1999. Least
squares support vector machine classiﬁers. Neural
processing letters, 9(3):293–300.

Duyu Tang, Bing Qin, and Ting Liu. 2015. Document
modeling with gated recurrent neural network for
sentiment classiﬁcation. In Proceedings of EMNLP,
pages 1422–1432.

S Sidney Ulmer. 1963. Quantitative analysis of judi-
cial processes: Some practical and theoretical appli-
cations. Law and Contemporary Problems, 28:164.

Legal Judgment Prediction via Topological Learning

Haoxi Zhong∗, Zhipeng Guo∗, Cunchao Tu, Chaojun Xiao, Zhiyuan Liu†, Maosong Sun
Department of Computer Science and Technology
State Key Lab on Intelligent Technology and Systems
Institute for Artiﬁcial Intelligence, Tsinghua University, Beijing, China
{zhonghx18,gzp17,xiaocj16}@mails.tsinghua.edu.cn, tucunchao@gmail.com
{lzy,sms}@tsinghua.edu.cn

Abstract

Legal Judgment Prediction (LJP) aims to pre-
dict the judgment result based on the facts of
a case and becomes a promising application
of artiﬁcial intelligence techniques in the le-
gal ﬁeld. In real-world scenarios, legal judg-
ment usually consists of multiple subtasks,
such as the decisions of applicable law arti-
cles, charges, ﬁnes, and the term of penalty.
Moreover, there exist topological dependen-
cies among these subtasks. While most ex-
isting works only focus on a speciﬁc sub-
task of judgment prediction and ignore the de-
pendencies among subtasks, we formalize the
dependencies among subtasks as a Directed
Acyclic Graph (DAG) and propose a topo-
logical multi-task learning framework, TOP-
JUDGE, which incorporates multiple subtasks
and DAG dependencies into judgment predic-
tion. We conduct experiments on several real-
world large-scale datasets of criminal cases
in the civil law system. Experimental results
show that our model achieves consistent and
signiﬁcant improvements over baselines on all
judgment prediction tasks. The source code
can be obtained from https://github.
com/thunlp/TopJudge.

1

Introduction

Legal Judgment Prediction (LJP) aims to predict
the judgment results of legal cases according to the
fact descriptions. It is a critical technique for the
legal assistant system. On the one hand, LJP can
provide low-cost but high-quality legal consulting
services to the masses who are unfamiliar with le-
gal terminology and the complex judgment pro-
cedures. On the other hand, it can serve as the
handy reference for professionals (e.g., lawyers
and judges) and improve their work efﬁciency.

∗ Indicates equal contribution. The order is determined by

dice rolling.

† Corresponding author.

Figure 1: An illustration of the judicial logic of hu-
man judges in civil law system.

LJP has been studied for decades (Kort, 1957;
Ulmer, 1963; Nagel, 1963; Keown, 1980; Segal,
1984; Lauderdale and Clark, 2012; Ye et al., 2018;
Hu et al., 2018), and most existing works for-
malize LJP as a text classiﬁcation task. For ex-
ample, some works (Liu et al., 2004; Liu and
Hsieh, 2006) propose to extract shallow textual
features (e.g. characters, words, and phrases) for
charge prediction. Katz et al. (2017) predict the
US Supreme Court’s decisions based on efﬁcient
features from case proﬁles. Luo et al. (2017) pro-
pose an attention-based neural model for charge
prediction by incorporating the relevant law arti-
cles.

Despite these efforts in designing efﬁcient fea-
tures and employing advanced NLP techniques,
LJP is still confronted with two major challenges:
Multiple Subtasks in Legal Judgment: Prac-
tically, legal judgment usually consists of detailed
and complicated subclauses, such as charges, the
term of penalty, and ﬁnes. Speciﬁcally, for those
countries with the civil law system (e.g., China,
France, and Germany), the prediction of relevant
articles is also considered to be one of the funda-
mental subtasks, which will guide the prediction
for other subtasks. In other words, all these sub-
tasks compose the complete form of judgment pre-

diction. Nevertheless, existing works on LJP usu-
ally focus on one speciﬁc subtask of judgments,
which does not conform to the real scenarios. Al-
though some methods (Luo et al., 2017) are devel-
oped to predict law articles and charges at the same
time, their models are designed for a speciﬁc set of
subtasks which are hard to scale to other subtasks.
Topological Dependencies between Subtasks:
there exists a strict order
For human judges,
among the subtasks of legal judgment. As illus-
trated in Fig. 1, given the fact description of a spe-
ciﬁc case, a judge in the civil law system ﬁrst de-
cides which law articles are relevant to the sce-
nario, and then determines the charges according
to the instructions of relevant law articles. Based
on these results, the judge further conﬁrms the
term of penalty and ﬁnes. How to simulate the ju-
dicial logic of human judges and model the topo-
logical dependencies among legal subtasks will
deeply inﬂuence the creditability and interpretabil-
ity of judgment prediction.

As stated above, conventional works cannot
handle these two challenges due to both the lim-
itation of speciﬁc tasks and neglecting topological
dependencies. To address these issues, we propose
to model the multiple subtasks in judgment pre-
diction jointly under a novel multi-task learning
framework.

We model the topological dependencies among
these subtasks with a Directed Acyclic Graph
(DAG), which means all subtasks are arranged in
topological order. If the judgment of the j-th sub-
task tj depends on the output of the i-th subtask
ti, then ti appears earlier than tj in such order. It
is notable that such formulation provides an ex-
plicit explanation of dependency relations among
subtasks.

Accordingly, we introduce topological learning
for LJP and propose a uniﬁed framework, named
as TOPJUDGE. Speciﬁcally, given the encoded
representation of the fact description, TOPJUDGE
predicts the outputs of all the subtasks following
the topological order, and the output of a speciﬁc
subtask will be affected by all the subtasks it de-
pends on. In contrast with conventional multi-task
learning, our model takes the explicit topological
dependencies of LJP subtasks into consideration
and is ﬂexible to handle other LJP subtasks. More-
over, the topological order of legal dependencies
renders our model interpretable and reliable.

To verify the effectiveness and ﬂexibility of

TOPJUDGE, we conduct a series of experiments
on several real-world large-scale datasets. Exper-
imental results show that our model achieves sig-
niﬁcant and consistent improvements over state-
of-the-art models on all tasks and datasets. To
summarize, we make several noteworthy contribu-
tions as follows:

(1) We are the ﬁrst to explore and formalize the
multiple subtasks of legal judgment under a joint
learning framework. Moreover, we formulate the
dependencies among the subtasks of LJP as a form
of DAG and introduce this prior knowledge to en-
hance judgment prediction.

(2) We propose a novel judgment prediction
framework, TOPJUDGE, to unify multiple sub-
tasks and make judgment predictions through
topological learning. This model can handle any
form of DAG dependent subtasks, which has been
veriﬁed in the experiments.

(3) We carry out experiments on several large-
scale real-world datasets, and our model signiﬁ-
cantly and consistently outperforms all the base-
lines on all subtasks.

2 Related Work

2.1

Judgment Prediction

Employing automatic analysis techniques for legal
judgment has drawn attention from researchers in
the legal ﬁeld for decades. Early works usually
focus on analyzing existing legal cases in speciﬁc
scenarios with mathematical and statistical algo-
rithms (Kort, 1957; Ulmer, 1963; Nagel, 1963;
Keown, 1980; Segal, 1984; Lauderdale and Clark,
2012).

With the development of machine learning and
text mining techniques, more researchersformal-
ize this task under text classiﬁcation frameworks.
Most of these studies attempt to extract efﬁcient
features from text content (Liu and Hsieh, 2006;
Lin et al., 2012; Aletras et al., 2016; Sulea et al.,
2017) or case annotations (e.g., dates, terms, lo-
cations, and types) (Katz et al., 2017). However,
these conventional methods can only utilize shal-
low textual features and manually designed fac-
tors, both require massive human efforts and usu-
ally suffer from the generalization issue when ap-
plied to other scenarios.

Inspired by the success of neural networks on
NLP tasks (Kim, 2014; Baharudin et al., 2010;
Tang et al., 2015), researchers began to handle LJP
by incorporating neural models with legal knowl-

edge. For example, Luo et al. (2017) present an
attention-based neural network that jointly mod-
els charge prediction and relevant article extrac-
tion. Hu et al. (2018) incorporate 10 discrimina-
tive legal attributes to predict few-shot and con-
fusing charges. Nevertheless, these models are de-
signed for speciﬁc subtasks and thus non-trivial to
be extended to more subtasks of LJP with complex
dependencies. Besides, Ye et al. (2018) utilize a
Seq2Seq model to generate court views with fact
descriptions and predicted charges in Chinese civil
law.

2.2 Multi-task Learning

Multi-task learning (MTL) aims to exploit the
commonalities and differences across relevant
tasks by solving them at the same time.
It can
transfer useful information among various tasks
and has been applied to a wide range of ar-
eas, including NLP (Collobert and Weston, 2008),
speech recognition (Deng et al., 2013), and com-
puter vision (Girshick, 2015; Mao et al., 2017).

There have been numerous successful usages
of MTL in NLP tasks. Most works follow the
hard parameter sharing setting by sharing repre-
sentations or some encoding layers among rele-
vant tasks. For example, Collobert and Weston
(2008) use shared word embeddings in solving
part-of-speech tagging and semantic role labeling
tasks. Liu et al. (2015) share the encoding lay-
ers of input queries to address query classiﬁcation
and information retrieval. Dong et al. (2015) and
Luong et al. (2016) propose to share encoders or
decoders to improve one (many) to many neural
machine translation. Firat et al. (2016) propose to
share attention mechanism in multi-way, multilin-
gual machine translation. Besides hard parameter
sharing, soft parameter sharing is another com-
mon approach in MTL. It assumes that each task
owns its speciﬁc parameters and the distance be-
tween parameters in different tasks should be close
to each other. For example, Duong et al. (2015)
employ L2 distance for regularization, while Yang
and Hospedales (2017) use the trace norm. Liu
et al. (2016) introduce gates among task-speciﬁc
RNN layers to control the information ﬂow. Ruder
et al. (2017) introduce a model which can de-
cide the amount of sharing between different NLP
tasks. There are also some works focusing on in-
creasing tasks (Hashimoto et al., 2017) or handing
unlabeled data (Augenstein et al., 2018).

Figure 2: The framework of TOPJUDGE.

In this work, we introduce a topological learn-
ing framework TOPJUDGE to handle multiple sub-
tasks in LJP. Different to conventional MTL mod-
els which focus on how to share parameters among
relevant tasks, TOPJUDGE models the explicit de-
pendencies among these subtasks with scalable
DAG forms.

3 Method

In the following parts, we will ﬁrst give the essen-
tial deﬁnitions of LJP task. We then introduce the
DAG dependencies of the subtasks in LJP. And ﬁ-
nally, we describe the neural encoder for fact rep-
resentation and the judgment predictor for the sub-
tasks with DAG dependencies. The overall frame-
work of TOPJUDGE has been shown in Fig 2.

3.1 Problem Formulation

We will focus on the LJP tasks in civil law. Sup-
pose the fact description of a case is a word se-
quence x = {x1, x2, . . . , xn}, where n is the
length of x and each word xi comes from a ﬁxed
vocabulary W . Based on the fact description x,
the task of LJP T aims to predict judgment results
of applicable law articles, charges, term of penalty,
ﬁnes and so on. Formally, we assume T contains
|T | subtasks, i.e., T = {t1, t2, . . . , t|T |}, each of
which is a classiﬁcation task. For the i-th subtask
ti ∈ T , we aim to predict the corresponding result
yi ⊆ Yi, where Yi is a subtask-speciﬁc label set.
Take the subtask of charge prediction for example,
the corresponding label set should contain Theft,
Trafﬁc Violation, Intentional Homicide and so on.

3.2 DAG Dependencies of Subtasks

We assume that the dependencies among multiple
subtasks of LJP form a DAG. As a result, the task
list T should satisfy topological constraints. For-
mally, we use the notation ti (cid:1) tj to denote that

(a) Typical MTL form of DAG

(b) Sequential form of DAG

(c) General form of DAG

Figure 3: Three typical forms of DAG dependencies.

the j-th subtask depends on the i-th subtask, and
Dj = {ti | ti (cid:1) tj} to denote the dependency set.
The task list T can be ordered to satisfy the fol-
lowing constraint

i < j,

∀(i, j) ∈ {(i, j) | ti ∈ Dj}.

(1)

We demonstrate the ﬂexibility of our formula-
tion by describing two special cases: (1) As shown
in Fig. 3 (a), if no dependencies exist, i.e., Dj = ∅,
it corresponds to the typical MTL setting where
we simultaneously make predictions for all sub-
tasks. (2) As shown in Fig. 3 (b), if each task only
depends on its previous task, i.e., Dj = {tj−1}, it
forms a sequential learning process.

3.3 Neural Encoder for Fact Descriptions

We employ a fact encoder to generate the fact de-
scription’s vector representation as the input of
TOPJUDGE. In the following part, we brieﬂy in-
troduce an encoder based on Convolutional Neural
Networks (CNN) (Kim, 2014).

Taking a word sequence x as input, the CNN
encoder computes the text representation through
three layers, i.e., lookup layer, convolution layer
and pooling layer.

Lookup We ﬁrst convert each word xi in x into
its word embedding xi ∈ Rk, where k is the di-
mension of word embeddings. The word embed-
ding sequence is then represented as

ˆx = {x1, x2, . . . , xn}.

(2)

Convolution A convolution operation involves
a convolution matrix W ∈ Rm×(h×k), which is
applied to a sliding window of length h with num-
ber of ﬁlters m to produce a feature map by

ci = W · xi:i+h−1 + b,

(3)

where xi:i+h−1 is the concatenation of word em-
beddings within the i-th window and b ∈ Rm is
the bias vector. By applying convolution over each
window, we obtain c = {c1, . . . , cn−h+1}.

Pooling We apply per-dimension max-pooling
over c and obtain the ﬁnal fact representation d =
[d1, . . . , dm] by

dt = max(c1,t, . . . , cn−h+1,t), ∀t ∈ [1, m].

(4)

3.4

Judgment Predictor over DAG

Based on the DAG assumption, we obtain an or-
dered task list T ∗ = [t1, t2, . . . , t|T |]. For each
task tj ∈ T , we aim to predict its judgment result
yj based on the fact representation vector d and
the judgment results of its dependent tasks.

For prediction, we employ a speciﬁc LSTM cell
for each task and get the output of each task in
the topological order. More speciﬁcally, for each
task tj ∈ T , we obtain its ﬁnal judgment result
through three steps, i.e., cell initialization, task-
speciﬁc representation, and prediction.

Cell Initialization As stated above, the predic-
tion result of tj will be conditioned on the fact
representation d and the outputs of all dependent
tasks yk, ∀tk ∈ Dj. Hence, we have

(cid:105)

(cid:104)¯hj
¯cj

=

(cid:88)

(cid:16)

Wi,j

(cid:105)(cid:17)

(cid:104)hi
ci

+ bj

(5)

ti∈Dj

Here, hi and ci are the hidden state and memory
cell of ti. ¯hj and ¯cj are the initial hidden state and
memory cell of tj. Wi,j and bj are transformation
matrices and bias vectors speciﬁc to ti and tj.

Task-Speciﬁc Representation Taking the fact
representation d, the initial hidden state ¯hj, and
the initial memory cell ¯cj as inputs, we process

them with an LSTM cell (Hochreiter and Schmid-
huber, 1997).

We regard the ﬁnal hidden state hj as the task-
speciﬁc representation of task tj. The last cell
state cj is used to compose the initial hidden state
for the downstream tasks by Eq. 5

Prediction With the representation hj, we ap-
ply an afﬁne transformation followed by softmax
and obtain the ﬁnal prediction as

ˆyj = softmax (cid:0)Wp

j hj + bp

j

(cid:1) .

(6)

j are parameters speciﬁc to task

Here, Wp
tj.

j and bp

With the prediction result ˆyj, we minimize the

cross-entropy between ˆyj and yj as follows:

Lj(ˆyj, yj) = −

yj,k log(ˆyj,k).

(7)

|Yj |
(cid:88)

k=1

3.5 Training

We use cross-entropy loss for each subtask and
sum up losses to train TOPJUDGE:

L =

λjLj(ˆyj, yj),

(8)

|T |
(cid:88)

j=1

where λj is the weight factor for each subtask tj.
The DAG dependencies of subtasks ensure that
our model is differentiable and can be trained in an
end-to-end fashion. In practice, we set all weights
λj to 1, and employ Adam (Kingma and Ba, 2015)
for optimization. We also apply dropout (Srivas-
tava et al., 2014) on the fact representation to pre-
vent overﬁtting.

4 Experiments

To evaluate the proposed TOPJUDGE framework,
we conduct a series of experiments on LJP over
three large-scale datasets of criminal cases in
China. We select three representative judgment
prediction subtasks for comparison, including law
articles, charges, and the terms of penalty.

4.1 Dataset Construction

As there are no publicly available LJP datasets
in previous works, we collect and construct three
different LJP datasets, including CJO, PKU, and
CAIL. CJO consists of criminal cases published
by the Chinese government from China Judge-
ment Online1. PKU contains criminal cases pub-
lished by Peking University Law Online2. CAIL

1 http://wenshu.court.gov.cn/
2 http://www.pkulaw.com/

Datasets

CJO

PKU

CAIL

Cases
Law Articles
Charges
Term of Penalty

1, 007, 744
98
99
11

175, 744
68
64
11

113, 536
105
122
11

Table 1: The statistics of different datasets.

(Chinese AI and Law Challenge) is another crim-
inal case dataset for competition released by the
Supreme People’s Court of China3. The details of
CAIL can be found in Xiao et al. (2018).

For all datasets we mentioned above, as the doc-
uments are well-structured and human-annotated,
we can easily extract fact descriptions, applica-
ble law articles, charges and the terms of penalty
from each document using regular expressions.
We have manually checked a randomly sampled
set of cases, and extraction errors are negligible.

In real-world scenarios, there are some cases
with multiple defendants and multiple charges,
which will increase the complexity of judgment
prediction. As our model aims to explore the ef-
fectiveness of considering topological dependen-
cies between various subtasks, we ﬁlter out these
cases and leave them as our future work.

Meanwhile,

there are also some infrequent
charges and law articles, such as money launder-
ing, smuggling of nuclear materials and tax dodge.
We ﬁlter out these infrequent charges and law arti-
cles and only keep those with frequencies greater
than 100. For the term of penalty, we divide the
terms into non-overlapping intervals. We list de-
tailed statistics of these datasets in Table 1.

4.2 Baselines

For comparison, we employ the following text
classiﬁcation models and judgment prediction
methods as baselines:

TFIDF+SVM: We employ term-frequency in-
verse document frequency (TFIDF) (Salton and
Buckley, 1988) to extract word features and uti-
lize SVM (Suykens and Vandewalle, 1999) for text
classiﬁcation.

CNN: We employ CNN with multiple ﬁlter
widths (Kim, 2014) for fact encoding and classi-
ﬁcation.

Hierarchical LSTM (HLSTM): Tang et al.
(2015) employs hierarchical neural networks to
learn document representations in sentiment clas-

3 http://cail.cipsc.org.cn/index.html

Tasks

Law Articles

Charges

The Term of Penalty

Metrics

Acc. MP MR

F1

Acc. MP MR

F1

Acc. MP MR

F1

Single

Multi

TFIDF+SVM 82.4
92.5
91.4

CNN
HLSTM

Fact-Law Att.
PM
CNN-MTL
HLSTM-MTL

93.5
93.7
94.3
92.4

94.4

45.5
46.9
38.6

50.9
51.9
53.0
45.5

53.9

26.7
38.4
37.3

45.6
44.1
46.0
41.4

47.3

30.2
40.0
36.9

45.9
44.9
46.9
41.0

48.2

82.2
92.3
91.8

93.4
93.6
94.1
92.3

94.9

47.4
41.2
37.8

47.2
45.5
48.5
41.9

53.9

27.9
32.3
36.0

41.4
39.1
41.7
36.6

48.2

31.3
33.7
35.2

41.5
39.3
42.5
35.9

49.1

48.5
57.4
56.1

56.3
58.2
58.7
54.9

58.8

36.0
35.6
22.5

31.3
38.2
39.9
30.6

40.2

16.7
22.2
25.0

26.4
24.9
28.8
26.6

32.9

16.5
22.7
23.3

26.7
26.8
29.4
26.4

32.8

Ours

TOPJUDGE

Table 2: Judgment prediction results on CJO.

Tasks

Law Articles

Charges

The Term of Penalty

Metrics

Acc. MP MR

F1

Acc. MP MR

F1

Acc. MP MR

F1

Single

Multi

TFIDF+SVM 80.9
93.1
91.7

CNN
HLSTM

Fact-Law Att.
PM
CNN-MTL
HLSTM-MTL

93.9
94.4
95.0
93.9

95.4

51.3
64.3
54.4

68.1
69.6
73.8
71.2

76.4

32.6
52.6
53.4

63.4
61.0
64.9
64.6

67.6

36.4
54.3
50.9

63.5
62.2
66.0
65.1

68.4

81.0
93.3
91.9

94.2
94.3
95.0
93.8

95.6

53.4
61.9
52.5

65.8
65.1
70.7
67.8

75.9

35.4
49.3
48.9

58.5
56.2
60.6
60.0

69.6

38.7
51.1
47.3

58.7
57.2
61.7
60.7

70.9

45.3
57.6
54.3

55.7
58.2
58.4
55.4

57.8

30.4
24.1
20.6

27.7
36.2
36.0
31.3

38.9

17.4
23.1
21.7

27.4
26.4
28.7
26.2

32.1

17.2
23.3
19.0

26.5
27.1
28.9
25.7

31.8

Ours

TOPJUDGE

Table 3: Judgment prediction results on PKU.

siﬁcation. Based on this work, we employ an
LSTM for sentence representations and another
one to obtain the representation of complete fact
descriptions.

Fact-Law Attention Model: Luo et al. (2017)
proposes a neural charge prediction model by cap-
turing the interaction between fact descriptions
and applicable laws with attention mechanism.

Pipeline Model (PM): To demonstrate the
advantage of TOPJUDGE on modeling subtasks
jointly, we also implement a pipelined method for
comparison. Here, we train 3 separate CNN classi-
ﬁers for law articles, charges, and term of penalty.
For each subtask, the input is the concatenation
of the fact representation and the embeddings for
predicted labels of previous subtasks.

Besides, we compare our model with conven-
tional MTL methods that do not consider the de-
pendencies among subtasks as in Fig. 3 (a). These
methods are denoted as CNN-MTL and HLSTM-
MTL, where we implement the fact encoder as in
Fig. 2 using CNN or HLSTM respectively.

4.3 Experimental Settings

As the case documents are written in Chinese
with no space between words, we employ THU-
LAC (Sun et al., 2016) for word segmentation. Af-
terward, we adopt the Skip-Gram model (Mikolov
et al., 2013) to pre-train word embeddings on these

case documents, with embedding size set to 200
and frequency threshold set to 25.

For all models, we set

the fact representa-
tion and task-speciﬁc representation size to 256.
Meanwhile, we set the maximum sentence length
to 128 words and maximum document length to
32 sentences.

For training, the learning rate of Adam opti-
mizer is 10−3, and the dropout probability is 0.5.
We also set the batch size to 128 for all models.
We train every model for 16 epochs, and evaluate
the ﬁnal model on the testing set.

We employ accuracy (Acc.), macro-precision
(MP), macro-recall (MR) and macro-F1 (F1)
the macro-
as evaluation metrics.
precision/recall/F1 are calculated by averaging the
precision/recall/F1 of each category.

Here,

4.4 Results and Analysis

We evaluate the performance on three LJP sub-
including law articles (denoted as t1),
tasks,
charges (denoted as t2), and the terms of penalty
(denoted as t3). Experimental results are shown in
Tables 2, 3, and 4. Note that, we implement TOP-
JUDGE with the dependency relationship in Fig. 3
(c), i.e.,

D1 = φ, D2 = {t1}, D3 = {t1, t2}.

(9)

Tasks

Law Articles

Charges

The Term of Penalty

Metrics

Acc. MP MR

F1

Acc. MP MR

F1

Acc. MP MR

F1

Single

Multi

TFIDF+SVM 60.1
81.4
-

CNN
HLSTM

Fact-Law Att.
PM
CNN-MTL
HLSTM-MTL

70.9
84.7
84.5
-

86.3

54.9
74.4
-

64.8
80.7
80.0
-

81.9

45.3
64.1
-

63.6
68.6
68.1
-

71.1

46.3
65.7
-

59.1
70.8
70.3
-

73.4

59.2
80.7
-

68.7
83.6
83.4
-

85.7

53.9
77.3
-

66.1
81.6
81.6
-

83.4

45.0
65.5
-

65.3
70.0
69.1
-

76.0

45.7
67.2
-

60.1
72.1
71.6
-

78.3

28.4
28.8
-

36.5
40.0
39.5
-

38.3

22.9
34.7
-

29.9
37.4
37.2
-

36.1

20.0
27.8
-

27.6
32.0
32.3
-

33.1

18.1
28.6
-

27.1
31.6
31.3
-

32.1

Ours

TOPJUDGE

Table 4: Judgment prediction results on CAIL. Note that, “-” means the model does not converge within
128 epochs.

This means that the prediction of charges depends
on law articles, and the prediction of term of
penalty depends on both law articles and charges.
Such explicit dependencies conform to the judi-
cial logic of human judges, which will be veriﬁed
in later sections. These results show that:

(1) The proposed TOPJUDGE model outper-
forms other baselines signiﬁcantly on most sub-
tasks and datasets. It demonstrates the effective-
ness and robustness of our proposed framework.

(2) Compared with conventional single-task
models, e.g., CNN and HLSTM, MTL methods
take advantage of the correlation among relevant
subtasks and thus achieve promising improve-
It indicates the importance of modeling
ments.
LJP subtasks jointly.

(3) Moreover, TOPJUDGE signiﬁcantly outper-
forms typical MTL models, especially on the pre-
diction of charges and the terms of penalty. It veri-
ﬁes the rationality and importance of modeling de-
pendencies over LJP subtasks with DAG.

4.5 Ablation Analysis

Tasks

t1

t2

t3

Metrics

Acc.

F1

Acc.

F1

Acc.

F1

TOPJUDGE
- t3 (cid:1) t1
- t2 (cid:1) t1
φ

95.4
95.2
94.8
94.7

68.4
67.7
64.7
64.4

95.6
95.4
94.9
94.9

70.9
70.3
60.2
60.1

57.8
57.4
57.0
57.8

31.8
31.2
31.6
27.6

Table 5: Ablation analysis on PKU.

To further illustrate the signiﬁcance of legal de-
pendencies and explore how the DAG dependen-
cies inﬂuence the performance, we evaluate the
performance of TOPJUDGE under various DAG
architectures. Using Eq. 9 as the full dependen-
cies, we remove the dependency of t3 (cid:1) t1 (law
articles and term of penalty, corresponding to the
sequential form in Fig. 3), t2 (cid:1) t1 (law articles and

charges), and all dependencies respectively. Re-
sults are summarized in Table 5.

We observe that the performance of TOPJUDGE
decreases on all tasks after removing either depen-
dency. More speciﬁcally, when we dropped de-
pendencies t3 (cid:1) t1 and t2 (cid:1) t1 respectively, sig-
niﬁcant decreases are observed for t3 and t2 corre-
spondingly. This demonstrates that incorporating
dependencies is beneﬁcial for relevant subtasks,
verifying its guiding role in the civil law system.

Meanwhile, we note that there are two main
differences between TOPJUDGE and traditional
multi-task models, namely the Cell Initialization
and the Task-Speciﬁc Representation. We can
see that if we eliminate Cell Initialization from
TOPJUDGE,
the dependencies will not be rep-
resented in the model and it will become sim-
ilar to CNN-MTL. If we eliminate the Task-
Speciﬁc Representation from TOPJUDGE, TOP-
JUDGE will become the same as the Pipeline
Model. In a word, the main improvement of our
models comes from the combination.

4.6 Case Study

We give some intuitive examples to demonstrate
the signiﬁcance of TOPJUDGE on LJP subtasks.

As shown in Table 6, case 1 is about negligently
causing a ﬁre. The fact description of this case
states “The defendant pulled up weeds in the ﬁelds
and piled them up in haphazard stacks. Afterward,
he lighted them up and triggered the forest ﬁres...”
TOPJUDGE predicts all judgments correctly, while
CNN-MTL fails to predict the charge and term of
penalty. Moreover, CNN-MTL obtains conﬂicting
judgments, i.e., “crime of arson” and “1-2 years”,
due to its neglecting of dependencies of these sub-
tasks. According to the legal provisions of law ar-
ticle 115, the crime of arson should be sentenced
to more than 10 years.

Methods

Law Charge

Term
(months)

12-24(×)

CNN-MTL

115 Arson(×)

TOPJUDGE

115 Negligently Caus-
ing a Fire

0-6

CNN-MTL

293

Intentional Dam-
age to Property(×)

12-24(×)

TOPJUDGE

293 Affray

0-6

Table 6: Example cases and their prediction results.

Case 2 in Table 6 is another evidence of the in-
sufﬁciency of conventional MTL on LJP. This case
is about picking quarrels and provoking troubles.
Both CNN-MTL and TOPJUDGE succeed to pre-
law article 293
dict the relevant law articles (i.e.,
of the crime of affray). However, CNN-MTL is
confused between “crime of affray” and “crime of
intentional destruction or damage of properties”,
two charges similar to each other. Conversely,
TOPJUDGE can utilize the prediction result of law
articles and consequently prevent this confusion.

To summarize, modeling the explicit dependen-
cies among various subtasks can remarkably help
the LJP model address the issue of predicting con-
ﬂicting results.

4.7 Error Analysis

Prediction errors induced by our proposed model
can be traced down into the following causes.

Data Imbalance.

For the subtasks of law
articles and charges, our model achieves more
than 90% on accuracy, while only about 60% for
macro-F1. This issue is much more severe on the
subtask of the term of penalty, which our model
yields a poor performance of only 30% macro-F1.
The bad performance is mainly due to the imbal-
ance of category labels, e.g., there are only a few
training instances where the term is “life imprison-
ment or death penalty”. Most judgment prediction
approaches perform poorly (especially for Recall)
on these labels as listed in Fig. 4. Instance weight-
ing schemes can be introduced to address this is-
sue in future works.

Incomplete Information. Following existing
LJP works, we predict the ﬁnal judgment accord-
ing to the fact descriptions, which is incomplete as
compared to the whole materials relevant to this
In Chinese Law, there are certain circum-
case.
stances under which the sentence can be short-
ened. For example, minors usually receive a light-

Figure 4: The confusion matrix in the subtask
of predicting the term of penalty on the PKU
dataset. The rows denote the ground truth while
the columns denote the prediction results.

ened penalty, and those guilty of misdemeanors
are allowed for a secured pending trial while pay-
ing a security deposit. However, such informa-
tion is not included in the fact descriptions. The
lack of such information also raises difﬁculties for
judgment prediction, especially for the prediction
of the term of penalty. In Fig. 4, we can see that
the highest error rate comes from the cases with a
short term of penalty. Our model fails to distin-
guish the cases with no penalty and those with 0-6
months term of imprisonment.

5 Conclusion

In this paper, we focus on the task of legal judg-
ment prediction (LJP) and address multiple sub-
tasks of judgment predication with a topological
learning framework. To be speciﬁc, we formalize
the explicit dependencies over these subtasks in a
DAG form, and propose a novel MTL framework,
TOPJUDGE, by integrating the DAG dependen-
cies. Experimental results on three LJP subtasks
and three different datasets show that our TOP-
JUDGE outperforms all single-task baselines and
conventional MTL models consistently and signif-
icantly.

In the future, we will seek to explore the follow-
ing directions: (1) We will explore more LJP sub-
tasks and more scenarios of cases such as multiple

defendants and charges to investigate the effective-
ness of TOPJUDGE. (2) We will explore how to
incorporate into LJP the temporal factors, which
are not considered in this work.

6 Acknowledgements

This work is supported by the National Nat-
ural Science Foundation of China (NSFC No.
61572273, 61772302) and the research fund of
Powerlaw Inc.
for AI+Law Technology. This
work is also funded by China Association for Sci-
ence and Technology (2016QNRC001). Tu is also
supported by China Postdoctoral Innovative Talent
Support Programme.

References

Nikolaos Aletras, Dimitrios Tsarapatsanis, Daniel
Preotiuc-Pietro, and Vasileios Lampos. 2016. Pre-
dicting judicial decisions of the european court of
human rights: A natural language processing per-
spective. PeerJ Computer Science, 2.

Isabelle Augenstein, Sebastian Ruder, and Anders
Søgaard. 2018. Multi-task learning of pairwise
sequence classiﬁcation tasks over disparate label
spaces. In Proceedings of NAACL.

Baharum Baharudin, Lam Hong Lee, and Khairullah
Khan. 2010. A review of machine learning algo-
rithms for text-documents classiﬁcation. Journal of
Advances in Information Technology, 1(1):4–20.

Ronan Collobert and Jason Weston. 2008. A uniﬁed
architecture for natural language processing: Deep
In Pro-
neural networks with multitask learning.
ceedings of ICML, pages 160–167.

Li Deng, Geoffrey Hinton, and Brian Kingsbury. 2013.
New types of deep neural network learning for
speech recognition and related applications: An
overview. In Proceedings of ICASSP, pages 8599–
8603.

Daxiang Dong, Hua Wu, Wei He, Dianhai Yu, and
Haifeng Wang. 2015. Multi-task learning for mul-
tiple language translation. In Proceedings of ACL,
volume 1, pages 1723–1732.

Long Duong, Trevor Cohn, Steven Bird, and Paul
Cook. 2015. Low resource dependency parsing:
Cross-lingual parameter sharing in a neural network
In Proceedings of ACL, volume 2, pages
parser.
845–850.

Orhan Firat, Kyunghyun Cho, and Yoshua Bengio.
2016. Multi-way, multilingual neural machine
translation with a shared attention mechanism.
In
Proceedings of NAACL, pages 866–875.

Ross Girshick. 2015. Fast r-cnn.

In Proceedings of

ICCV, pages 1440–1448.

Kazuma Hashimoto, Yoshimasa Tsuruoka, Richard
Socher, et al. 2017. A joint many-task model: Grow-
ing a neural network for multiple nlp tasks. In Pro-
ceedings of EMNLP, pages 1923–1933.

Sepp Hochreiter and Jurgen Schmidhuber. 1997.
Neural computation,

Long short-term memory.
9(8):1735–1780.

Zikun Hu, Xiang Li, Cunchao Tu, Zhiyuan Liu, and
Maosong Sun. 2018. Few-shot charge prediction
with discriminative legal attributes. In Proceedings
of COLING.

Daniel Martin Katz, Michael J Bommarito II, and Josh
Blackman. 2017. A general approach for predict-
ing the behavior of the supreme court of the united
states. Plos one, 12(4).

R Keown. 1980. Mathematical models for legal pre-

diction. Computer/LJ, 2:829.

Yoon Kim. 2014. Convolutional neural networks for
sentence classiﬁcation. In Proceedings of EMNLP.

Diederik Kingma and Jimmy Ba. 2015. Adam: A
method for stochastic optimization. In Proceedings
of ICLR.

Fred Kort. 1957. Predicting supreme court decisions
mathematically: A quantitative analysis of the ”right
to counsel” cases. American Political Science Re-
view, 51(1):1–12.

Benjamin E Lauderdale and Tom S Clark. 2012. The
supreme court’s many median justices. American
Political Science Review, 106(4):847–866.

Wanchen Lin, Tsung Ting Kuo, and Tung Jia Chang.
2012. Exploiting machine learning models for chi-
nese legal documents labeling, case classiﬁcation,
and sentencing prediction. In Processdings of RO-
CLING, page 140.

Chaolin Liu, Cheng Tsung Chang, and Jim How Ho.
2004. Case instance generation and reﬁnement
for case-based criminal summary judgments in chi-
nese. Journal of Informationence & Engineering,
20(4):783–800.

Chaolin Liu and Chwen Dar Hsieh. 2006. Exploring
phrase-based classiﬁcation of judicial documents for
criminal charges in chinese. In Proceedings of IS-
MIS, pages 681–690.

Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2016.
Recurrent neural network for text classiﬁcation with
multi-task learning. In Proceedings of IJCAI.

Xiaodong Liu, Jianfeng Gao, Xiaodong He, Li Deng,
Kevin Duh, and Ye-Yi Wang. 2015. Representation
learning using multi-task deep neural networks for
semantic classiﬁcation and information retrieval. In
Proceedings of NAACL, pages 912–921.

Chaojun Xiao, Haoxi Zhong, Zhipeng Guo, Cunchao
Tu, Zhiyuan Liu, Maosong Sun, Yansong Feng,
Xianpei Han, Zhen Hu, Heng Wang, et al. 2018.
Cail2018: A large-scale legal dataset for judgment
prediction. arXiv preprint arXiv:1807.02478.

Yongxin Yang and Timothy Hospedales. 2017. Deep
multi-task representation learning: A tensor factori-
sation approach. In Proceedings of ICLR.

Hai Ye, Xin Jiang, Zhunchen Luo, and Wenhan Chao.
2018. Interpretable charge predictions for criminal
cases: Learning to generate court views from fact
descriptions. In Proceedings of NAACL.

Bingfeng Luo, Yansong Feng, Jianbo Xu, Xiang
Zhang, and Dongyan Zhao. 2017. Learning to pre-
dict charges for criminal cases with legal basis. In
Proceedings of EMNLP.

Minh-Thang Luong, Quoc V Le, Ilya Sutskever, Oriol
Vinyals, and Lukasz Kaiser. 2016. Multi-task se-
In Proceedings of
quence to sequence learning.
ICLR.

Jiayuan Mao, Tete Xiao, Yuning Jiang, and Zhimin
Cao. 2017. What can help pedestrian detection? In
Proceedings of CVPR, pages 3127–3136.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Proceedings of NIPS, pages 3111–3119.

Stuart S Nagel. 1963. Applying correlation analysis to

case prediction. Texas Law Review, 42:1006.

Sebastian Ruder, Joachim Bingel, Isabelle Augen-
stein, and Anders Søgaard. 2017. Learning what to
share between loosely related tasks. arXiv preprint
arXiv:1705.08142.

Gerard Salton and Christopher Buckley. 1988. Term-
weighting approaches in automatic text retrieval. In-
formation processing & management, 24(5):513–
523.

Jeffrey A Segal. 1984. Predicting supreme court cases
probabilistically: The search and seizure cases,
American Political Science Review,
1962-1981.
78(4):891–900.

Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: a simple way to prevent neural networks
from overﬁtting. JMLR, 15(1):1929–1958.

Octavia Maria Sulea, Marcos Zampieri, Mihaela Vela,
and Josef Van Genabith. 2017. Exploring the use of
text classi cation in the legal domain. In Proceedings
of ASAIL workshop.

Maosong Sun, Xinxiong Chen, Kaixu Zhang, Zhipeng
Guo, and Zhiyuan Liu. 2016. Thulac: An efﬁcient
lexical analyzer for chinese.

Johan AK Suykens and Joos Vandewalle. 1999. Least
squares support vector machine classiﬁers. Neural
processing letters, 9(3):293–300.

Duyu Tang, Bing Qin, and Ting Liu. 2015. Document
modeling with gated recurrent neural network for
sentiment classiﬁcation. In Proceedings of EMNLP,
pages 1422–1432.

S Sidney Ulmer. 1963. Quantitative analysis of judi-
cial processes: Some practical and theoretical appli-
cations. Law and Contemporary Problems, 28:164.

Legal Judgment Prediction via Topological Learning

Haoxi Zhong∗, Zhipeng Guo∗, Cunchao Tu, Chaojun Xiao, Zhiyuan Liu†, Maosong Sun
Department of Computer Science and Technology
State Key Lab on Intelligent Technology and Systems
Institute for Artiﬁcial Intelligence, Tsinghua University, Beijing, China
{zhonghx18,gzp17,xiaocj16}@mails.tsinghua.edu.cn, tucunchao@gmail.com
{lzy,sms}@tsinghua.edu.cn

Abstract

Legal Judgment Prediction (LJP) aims to pre-
dict the judgment result based on the facts of
a case and becomes a promising application
of artiﬁcial intelligence techniques in the le-
gal ﬁeld. In real-world scenarios, legal judg-
ment usually consists of multiple subtasks,
such as the decisions of applicable law arti-
cles, charges, ﬁnes, and the term of penalty.
Moreover, there exist topological dependen-
cies among these subtasks. While most ex-
isting works only focus on a speciﬁc sub-
task of judgment prediction and ignore the de-
pendencies among subtasks, we formalize the
dependencies among subtasks as a Directed
Acyclic Graph (DAG) and propose a topo-
logical multi-task learning framework, TOP-
JUDGE, which incorporates multiple subtasks
and DAG dependencies into judgment predic-
tion. We conduct experiments on several real-
world large-scale datasets of criminal cases
in the civil law system. Experimental results
show that our model achieves consistent and
signiﬁcant improvements over baselines on all
judgment prediction tasks. The source code
can be obtained from https://github.
com/thunlp/TopJudge.

1

Introduction

Legal Judgment Prediction (LJP) aims to predict
the judgment results of legal cases according to the
fact descriptions. It is a critical technique for the
legal assistant system. On the one hand, LJP can
provide low-cost but high-quality legal consulting
services to the masses who are unfamiliar with le-
gal terminology and the complex judgment pro-
cedures. On the other hand, it can serve as the
handy reference for professionals (e.g., lawyers
and judges) and improve their work efﬁciency.

∗ Indicates equal contribution. The order is determined by

dice rolling.

† Corresponding author.

Figure 1: An illustration of the judicial logic of hu-
man judges in civil law system.

LJP has been studied for decades (Kort, 1957;
Ulmer, 1963; Nagel, 1963; Keown, 1980; Segal,
1984; Lauderdale and Clark, 2012; Ye et al., 2018;
Hu et al., 2018), and most existing works for-
malize LJP as a text classiﬁcation task. For ex-
ample, some works (Liu et al., 2004; Liu and
Hsieh, 2006) propose to extract shallow textual
features (e.g. characters, words, and phrases) for
charge prediction. Katz et al. (2017) predict the
US Supreme Court’s decisions based on efﬁcient
features from case proﬁles. Luo et al. (2017) pro-
pose an attention-based neural model for charge
prediction by incorporating the relevant law arti-
cles.

Despite these efforts in designing efﬁcient fea-
tures and employing advanced NLP techniques,
LJP is still confronted with two major challenges:
Multiple Subtasks in Legal Judgment: Prac-
tically, legal judgment usually consists of detailed
and complicated subclauses, such as charges, the
term of penalty, and ﬁnes. Speciﬁcally, for those
countries with the civil law system (e.g., China,
France, and Germany), the prediction of relevant
articles is also considered to be one of the funda-
mental subtasks, which will guide the prediction
for other subtasks. In other words, all these sub-
tasks compose the complete form of judgment pre-

diction. Nevertheless, existing works on LJP usu-
ally focus on one speciﬁc subtask of judgments,
which does not conform to the real scenarios. Al-
though some methods (Luo et al., 2017) are devel-
oped to predict law articles and charges at the same
time, their models are designed for a speciﬁc set of
subtasks which are hard to scale to other subtasks.
Topological Dependencies between Subtasks:
there exists a strict order
For human judges,
among the subtasks of legal judgment. As illus-
trated in Fig. 1, given the fact description of a spe-
ciﬁc case, a judge in the civil law system ﬁrst de-
cides which law articles are relevant to the sce-
nario, and then determines the charges according
to the instructions of relevant law articles. Based
on these results, the judge further conﬁrms the
term of penalty and ﬁnes. How to simulate the ju-
dicial logic of human judges and model the topo-
logical dependencies among legal subtasks will
deeply inﬂuence the creditability and interpretabil-
ity of judgment prediction.

As stated above, conventional works cannot
handle these two challenges due to both the lim-
itation of speciﬁc tasks and neglecting topological
dependencies. To address these issues, we propose
to model the multiple subtasks in judgment pre-
diction jointly under a novel multi-task learning
framework.

We model the topological dependencies among
these subtasks with a Directed Acyclic Graph
(DAG), which means all subtasks are arranged in
topological order. If the judgment of the j-th sub-
task tj depends on the output of the i-th subtask
ti, then ti appears earlier than tj in such order. It
is notable that such formulation provides an ex-
plicit explanation of dependency relations among
subtasks.

Accordingly, we introduce topological learning
for LJP and propose a uniﬁed framework, named
as TOPJUDGE. Speciﬁcally, given the encoded
representation of the fact description, TOPJUDGE
predicts the outputs of all the subtasks following
the topological order, and the output of a speciﬁc
subtask will be affected by all the subtasks it de-
pends on. In contrast with conventional multi-task
learning, our model takes the explicit topological
dependencies of LJP subtasks into consideration
and is ﬂexible to handle other LJP subtasks. More-
over, the topological order of legal dependencies
renders our model interpretable and reliable.

To verify the effectiveness and ﬂexibility of

TOPJUDGE, we conduct a series of experiments
on several real-world large-scale datasets. Exper-
imental results show that our model achieves sig-
niﬁcant and consistent improvements over state-
of-the-art models on all tasks and datasets. To
summarize, we make several noteworthy contribu-
tions as follows:

(1) We are the ﬁrst to explore and formalize the
multiple subtasks of legal judgment under a joint
learning framework. Moreover, we formulate the
dependencies among the subtasks of LJP as a form
of DAG and introduce this prior knowledge to en-
hance judgment prediction.

(2) We propose a novel judgment prediction
framework, TOPJUDGE, to unify multiple sub-
tasks and make judgment predictions through
topological learning. This model can handle any
form of DAG dependent subtasks, which has been
veriﬁed in the experiments.

(3) We carry out experiments on several large-
scale real-world datasets, and our model signiﬁ-
cantly and consistently outperforms all the base-
lines on all subtasks.

2 Related Work

2.1

Judgment Prediction

Employing automatic analysis techniques for legal
judgment has drawn attention from researchers in
the legal ﬁeld for decades. Early works usually
focus on analyzing existing legal cases in speciﬁc
scenarios with mathematical and statistical algo-
rithms (Kort, 1957; Ulmer, 1963; Nagel, 1963;
Keown, 1980; Segal, 1984; Lauderdale and Clark,
2012).

With the development of machine learning and
text mining techniques, more researchersformal-
ize this task under text classiﬁcation frameworks.
Most of these studies attempt to extract efﬁcient
features from text content (Liu and Hsieh, 2006;
Lin et al., 2012; Aletras et al., 2016; Sulea et al.,
2017) or case annotations (e.g., dates, terms, lo-
cations, and types) (Katz et al., 2017). However,
these conventional methods can only utilize shal-
low textual features and manually designed fac-
tors, both require massive human efforts and usu-
ally suffer from the generalization issue when ap-
plied to other scenarios.

Inspired by the success of neural networks on
NLP tasks (Kim, 2014; Baharudin et al., 2010;
Tang et al., 2015), researchers began to handle LJP
by incorporating neural models with legal knowl-

edge. For example, Luo et al. (2017) present an
attention-based neural network that jointly mod-
els charge prediction and relevant article extrac-
tion. Hu et al. (2018) incorporate 10 discrimina-
tive legal attributes to predict few-shot and con-
fusing charges. Nevertheless, these models are de-
signed for speciﬁc subtasks and thus non-trivial to
be extended to more subtasks of LJP with complex
dependencies. Besides, Ye et al. (2018) utilize a
Seq2Seq model to generate court views with fact
descriptions and predicted charges in Chinese civil
law.

2.2 Multi-task Learning

Multi-task learning (MTL) aims to exploit the
commonalities and differences across relevant
tasks by solving them at the same time.
It can
transfer useful information among various tasks
and has been applied to a wide range of ar-
eas, including NLP (Collobert and Weston, 2008),
speech recognition (Deng et al., 2013), and com-
puter vision (Girshick, 2015; Mao et al., 2017).

There have been numerous successful usages
of MTL in NLP tasks. Most works follow the
hard parameter sharing setting by sharing repre-
sentations or some encoding layers among rele-
vant tasks. For example, Collobert and Weston
(2008) use shared word embeddings in solving
part-of-speech tagging and semantic role labeling
tasks. Liu et al. (2015) share the encoding lay-
ers of input queries to address query classiﬁcation
and information retrieval. Dong et al. (2015) and
Luong et al. (2016) propose to share encoders or
decoders to improve one (many) to many neural
machine translation. Firat et al. (2016) propose to
share attention mechanism in multi-way, multilin-
gual machine translation. Besides hard parameter
sharing, soft parameter sharing is another com-
mon approach in MTL. It assumes that each task
owns its speciﬁc parameters and the distance be-
tween parameters in different tasks should be close
to each other. For example, Duong et al. (2015)
employ L2 distance for regularization, while Yang
and Hospedales (2017) use the trace norm. Liu
et al. (2016) introduce gates among task-speciﬁc
RNN layers to control the information ﬂow. Ruder
et al. (2017) introduce a model which can de-
cide the amount of sharing between different NLP
tasks. There are also some works focusing on in-
creasing tasks (Hashimoto et al., 2017) or handing
unlabeled data (Augenstein et al., 2018).

Figure 2: The framework of TOPJUDGE.

In this work, we introduce a topological learn-
ing framework TOPJUDGE to handle multiple sub-
tasks in LJP. Different to conventional MTL mod-
els which focus on how to share parameters among
relevant tasks, TOPJUDGE models the explicit de-
pendencies among these subtasks with scalable
DAG forms.

3 Method

In the following parts, we will ﬁrst give the essen-
tial deﬁnitions of LJP task. We then introduce the
DAG dependencies of the subtasks in LJP. And ﬁ-
nally, we describe the neural encoder for fact rep-
resentation and the judgment predictor for the sub-
tasks with DAG dependencies. The overall frame-
work of TOPJUDGE has been shown in Fig 2.

3.1 Problem Formulation

We will focus on the LJP tasks in civil law. Sup-
pose the fact description of a case is a word se-
quence x = {x1, x2, . . . , xn}, where n is the
length of x and each word xi comes from a ﬁxed
vocabulary W . Based on the fact description x,
the task of LJP T aims to predict judgment results
of applicable law articles, charges, term of penalty,
ﬁnes and so on. Formally, we assume T contains
|T | subtasks, i.e., T = {t1, t2, . . . , t|T |}, each of
which is a classiﬁcation task. For the i-th subtask
ti ∈ T , we aim to predict the corresponding result
yi ⊆ Yi, where Yi is a subtask-speciﬁc label set.
Take the subtask of charge prediction for example,
the corresponding label set should contain Theft,
Trafﬁc Violation, Intentional Homicide and so on.

3.2 DAG Dependencies of Subtasks

We assume that the dependencies among multiple
subtasks of LJP form a DAG. As a result, the task
list T should satisfy topological constraints. For-
mally, we use the notation ti (cid:1) tj to denote that

(a) Typical MTL form of DAG

(b) Sequential form of DAG

(c) General form of DAG

Figure 3: Three typical forms of DAG dependencies.

the j-th subtask depends on the i-th subtask, and
Dj = {ti | ti (cid:1) tj} to denote the dependency set.
The task list T can be ordered to satisfy the fol-
lowing constraint

i < j,

∀(i, j) ∈ {(i, j) | ti ∈ Dj}.

(1)

We demonstrate the ﬂexibility of our formula-
tion by describing two special cases: (1) As shown
in Fig. 3 (a), if no dependencies exist, i.e., Dj = ∅,
it corresponds to the typical MTL setting where
we simultaneously make predictions for all sub-
tasks. (2) As shown in Fig. 3 (b), if each task only
depends on its previous task, i.e., Dj = {tj−1}, it
forms a sequential learning process.

3.3 Neural Encoder for Fact Descriptions

We employ a fact encoder to generate the fact de-
scription’s vector representation as the input of
TOPJUDGE. In the following part, we brieﬂy in-
troduce an encoder based on Convolutional Neural
Networks (CNN) (Kim, 2014).

Taking a word sequence x as input, the CNN
encoder computes the text representation through
three layers, i.e., lookup layer, convolution layer
and pooling layer.

Lookup We ﬁrst convert each word xi in x into
its word embedding xi ∈ Rk, where k is the di-
mension of word embeddings. The word embed-
ding sequence is then represented as

ˆx = {x1, x2, . . . , xn}.

(2)

Convolution A convolution operation involves
a convolution matrix W ∈ Rm×(h×k), which is
applied to a sliding window of length h with num-
ber of ﬁlters m to produce a feature map by

ci = W · xi:i+h−1 + b,

(3)

where xi:i+h−1 is the concatenation of word em-
beddings within the i-th window and b ∈ Rm is
the bias vector. By applying convolution over each
window, we obtain c = {c1, . . . , cn−h+1}.

Pooling We apply per-dimension max-pooling
over c and obtain the ﬁnal fact representation d =
[d1, . . . , dm] by

dt = max(c1,t, . . . , cn−h+1,t), ∀t ∈ [1, m].

(4)

3.4

Judgment Predictor over DAG

Based on the DAG assumption, we obtain an or-
dered task list T ∗ = [t1, t2, . . . , t|T |]. For each
task tj ∈ T , we aim to predict its judgment result
yj based on the fact representation vector d and
the judgment results of its dependent tasks.

For prediction, we employ a speciﬁc LSTM cell
for each task and get the output of each task in
the topological order. More speciﬁcally, for each
task tj ∈ T , we obtain its ﬁnal judgment result
through three steps, i.e., cell initialization, task-
speciﬁc representation, and prediction.

Cell Initialization As stated above, the predic-
tion result of tj will be conditioned on the fact
representation d and the outputs of all dependent
tasks yk, ∀tk ∈ Dj. Hence, we have

(cid:105)

(cid:104)¯hj
¯cj

=

(cid:88)

(cid:16)

Wi,j

(cid:105)(cid:17)

(cid:104)hi
ci

+ bj

(5)

ti∈Dj

Here, hi and ci are the hidden state and memory
cell of ti. ¯hj and ¯cj are the initial hidden state and
memory cell of tj. Wi,j and bj are transformation
matrices and bias vectors speciﬁc to ti and tj.

Task-Speciﬁc Representation Taking the fact
representation d, the initial hidden state ¯hj, and
the initial memory cell ¯cj as inputs, we process

them with an LSTM cell (Hochreiter and Schmid-
huber, 1997).

We regard the ﬁnal hidden state hj as the task-
speciﬁc representation of task tj. The last cell
state cj is used to compose the initial hidden state
for the downstream tasks by Eq. 5

Prediction With the representation hj, we ap-
ply an afﬁne transformation followed by softmax
and obtain the ﬁnal prediction as

ˆyj = softmax (cid:0)Wp

j hj + bp

j

(cid:1) .

(6)

j are parameters speciﬁc to task

Here, Wp
tj.

j and bp

With the prediction result ˆyj, we minimize the

cross-entropy between ˆyj and yj as follows:

Lj(ˆyj, yj) = −

yj,k log(ˆyj,k).

(7)

|Yj |
(cid:88)

k=1

3.5 Training

We use cross-entropy loss for each subtask and
sum up losses to train TOPJUDGE:

L =

λjLj(ˆyj, yj),

(8)

|T |
(cid:88)

j=1

where λj is the weight factor for each subtask tj.
The DAG dependencies of subtasks ensure that
our model is differentiable and can be trained in an
end-to-end fashion. In practice, we set all weights
λj to 1, and employ Adam (Kingma and Ba, 2015)
for optimization. We also apply dropout (Srivas-
tava et al., 2014) on the fact representation to pre-
vent overﬁtting.

4 Experiments

To evaluate the proposed TOPJUDGE framework,
we conduct a series of experiments on LJP over
three large-scale datasets of criminal cases in
China. We select three representative judgment
prediction subtasks for comparison, including law
articles, charges, and the terms of penalty.

4.1 Dataset Construction

As there are no publicly available LJP datasets
in previous works, we collect and construct three
different LJP datasets, including CJO, PKU, and
CAIL. CJO consists of criminal cases published
by the Chinese government from China Judge-
ment Online1. PKU contains criminal cases pub-
lished by Peking University Law Online2. CAIL

1 http://wenshu.court.gov.cn/
2 http://www.pkulaw.com/

Datasets

CJO

PKU

CAIL

Cases
Law Articles
Charges
Term of Penalty

1, 007, 744
98
99
11

175, 744
68
64
11

113, 536
105
122
11

Table 1: The statistics of different datasets.

(Chinese AI and Law Challenge) is another crim-
inal case dataset for competition released by the
Supreme People’s Court of China3. The details of
CAIL can be found in Xiao et al. (2018).

For all datasets we mentioned above, as the doc-
uments are well-structured and human-annotated,
we can easily extract fact descriptions, applica-
ble law articles, charges and the terms of penalty
from each document using regular expressions.
We have manually checked a randomly sampled
set of cases, and extraction errors are negligible.

In real-world scenarios, there are some cases
with multiple defendants and multiple charges,
which will increase the complexity of judgment
prediction. As our model aims to explore the ef-
fectiveness of considering topological dependen-
cies between various subtasks, we ﬁlter out these
cases and leave them as our future work.

Meanwhile,

there are also some infrequent
charges and law articles, such as money launder-
ing, smuggling of nuclear materials and tax dodge.
We ﬁlter out these infrequent charges and law arti-
cles and only keep those with frequencies greater
than 100. For the term of penalty, we divide the
terms into non-overlapping intervals. We list de-
tailed statistics of these datasets in Table 1.

4.2 Baselines

For comparison, we employ the following text
classiﬁcation models and judgment prediction
methods as baselines:

TFIDF+SVM: We employ term-frequency in-
verse document frequency (TFIDF) (Salton and
Buckley, 1988) to extract word features and uti-
lize SVM (Suykens and Vandewalle, 1999) for text
classiﬁcation.

CNN: We employ CNN with multiple ﬁlter
widths (Kim, 2014) for fact encoding and classi-
ﬁcation.

Hierarchical LSTM (HLSTM): Tang et al.
(2015) employs hierarchical neural networks to
learn document representations in sentiment clas-

3 http://cail.cipsc.org.cn/index.html

Tasks

Law Articles

Charges

The Term of Penalty

Metrics

Acc. MP MR

F1

Acc. MP MR

F1

Acc. MP MR

F1

Single

Multi

TFIDF+SVM 82.4
92.5
91.4

CNN
HLSTM

Fact-Law Att.
PM
CNN-MTL
HLSTM-MTL

93.5
93.7
94.3
92.4

94.4

45.5
46.9
38.6

50.9
51.9
53.0
45.5

53.9

26.7
38.4
37.3

45.6
44.1
46.0
41.4

47.3

30.2
40.0
36.9

45.9
44.9
46.9
41.0

48.2

82.2
92.3
91.8

93.4
93.6
94.1
92.3

94.9

47.4
41.2
37.8

47.2
45.5
48.5
41.9

53.9

27.9
32.3
36.0

41.4
39.1
41.7
36.6

48.2

31.3
33.7
35.2

41.5
39.3
42.5
35.9

49.1

48.5
57.4
56.1

56.3
58.2
58.7
54.9

58.8

36.0
35.6
22.5

31.3
38.2
39.9
30.6

40.2

16.7
22.2
25.0

26.4
24.9
28.8
26.6

32.9

16.5
22.7
23.3

26.7
26.8
29.4
26.4

32.8

Ours

TOPJUDGE

Table 2: Judgment prediction results on CJO.

Tasks

Law Articles

Charges

The Term of Penalty

Metrics

Acc. MP MR

F1

Acc. MP MR

F1

Acc. MP MR

F1

Single

Multi

TFIDF+SVM 80.9
93.1
91.7

CNN
HLSTM

Fact-Law Att.
PM
CNN-MTL
HLSTM-MTL

93.9
94.4
95.0
93.9

95.4

51.3
64.3
54.4

68.1
69.6
73.8
71.2

76.4

32.6
52.6
53.4

63.4
61.0
64.9
64.6

67.6

36.4
54.3
50.9

63.5
62.2
66.0
65.1

68.4

81.0
93.3
91.9

94.2
94.3
95.0
93.8

95.6

53.4
61.9
52.5

65.8
65.1
70.7
67.8

75.9

35.4
49.3
48.9

58.5
56.2
60.6
60.0

69.6

38.7
51.1
47.3

58.7
57.2
61.7
60.7

70.9

45.3
57.6
54.3

55.7
58.2
58.4
55.4

57.8

30.4
24.1
20.6

27.7
36.2
36.0
31.3

38.9

17.4
23.1
21.7

27.4
26.4
28.7
26.2

32.1

17.2
23.3
19.0

26.5
27.1
28.9
25.7

31.8

Ours

TOPJUDGE

Table 3: Judgment prediction results on PKU.

siﬁcation. Based on this work, we employ an
LSTM for sentence representations and another
one to obtain the representation of complete fact
descriptions.

Fact-Law Attention Model: Luo et al. (2017)
proposes a neural charge prediction model by cap-
turing the interaction between fact descriptions
and applicable laws with attention mechanism.

Pipeline Model (PM): To demonstrate the
advantage of TOPJUDGE on modeling subtasks
jointly, we also implement a pipelined method for
comparison. Here, we train 3 separate CNN classi-
ﬁers for law articles, charges, and term of penalty.
For each subtask, the input is the concatenation
of the fact representation and the embeddings for
predicted labels of previous subtasks.

Besides, we compare our model with conven-
tional MTL methods that do not consider the de-
pendencies among subtasks as in Fig. 3 (a). These
methods are denoted as CNN-MTL and HLSTM-
MTL, where we implement the fact encoder as in
Fig. 2 using CNN or HLSTM respectively.

4.3 Experimental Settings

As the case documents are written in Chinese
with no space between words, we employ THU-
LAC (Sun et al., 2016) for word segmentation. Af-
terward, we adopt the Skip-Gram model (Mikolov
et al., 2013) to pre-train word embeddings on these

case documents, with embedding size set to 200
and frequency threshold set to 25.

For all models, we set

the fact representa-
tion and task-speciﬁc representation size to 256.
Meanwhile, we set the maximum sentence length
to 128 words and maximum document length to
32 sentences.

For training, the learning rate of Adam opti-
mizer is 10−3, and the dropout probability is 0.5.
We also set the batch size to 128 for all models.
We train every model for 16 epochs, and evaluate
the ﬁnal model on the testing set.

We employ accuracy (Acc.), macro-precision
(MP), macro-recall (MR) and macro-F1 (F1)
the macro-
as evaluation metrics.
precision/recall/F1 are calculated by averaging the
precision/recall/F1 of each category.

Here,

4.4 Results and Analysis

We evaluate the performance on three LJP sub-
including law articles (denoted as t1),
tasks,
charges (denoted as t2), and the terms of penalty
(denoted as t3). Experimental results are shown in
Tables 2, 3, and 4. Note that, we implement TOP-
JUDGE with the dependency relationship in Fig. 3
(c), i.e.,

D1 = φ, D2 = {t1}, D3 = {t1, t2}.

(9)

Tasks

Law Articles

Charges

The Term of Penalty

Metrics

Acc. MP MR

F1

Acc. MP MR

F1

Acc. MP MR

F1

Single

Multi

TFIDF+SVM 60.1
81.4
-

CNN
HLSTM

Fact-Law Att.
PM
CNN-MTL
HLSTM-MTL

70.9
84.7
84.5
-

86.3

54.9
74.4
-

64.8
80.7
80.0
-

81.9

45.3
64.1
-

63.6
68.6
68.1
-

71.1

46.3
65.7
-

59.1
70.8
70.3
-

73.4

59.2
80.7
-

68.7
83.6
83.4
-

85.7

53.9
77.3
-

66.1
81.6
81.6
-

83.4

45.0
65.5
-

65.3
70.0
69.1
-

76.0

45.7
67.2
-

60.1
72.1
71.6
-

78.3

28.4
28.8
-

36.5
40.0
39.5
-

38.3

22.9
34.7
-

29.9
37.4
37.2
-

36.1

20.0
27.8
-

27.6
32.0
32.3
-

33.1

18.1
28.6
-

27.1
31.6
31.3
-

32.1

Ours

TOPJUDGE

Table 4: Judgment prediction results on CAIL. Note that, “-” means the model does not converge within
128 epochs.

This means that the prediction of charges depends
on law articles, and the prediction of term of
penalty depends on both law articles and charges.
Such explicit dependencies conform to the judi-
cial logic of human judges, which will be veriﬁed
in later sections. These results show that:

(1) The proposed TOPJUDGE model outper-
forms other baselines signiﬁcantly on most sub-
tasks and datasets. It demonstrates the effective-
ness and robustness of our proposed framework.

(2) Compared with conventional single-task
models, e.g., CNN and HLSTM, MTL methods
take advantage of the correlation among relevant
subtasks and thus achieve promising improve-
It indicates the importance of modeling
ments.
LJP subtasks jointly.

(3) Moreover, TOPJUDGE signiﬁcantly outper-
forms typical MTL models, especially on the pre-
diction of charges and the terms of penalty. It veri-
ﬁes the rationality and importance of modeling de-
pendencies over LJP subtasks with DAG.

4.5 Ablation Analysis

Tasks

t1

t2

t3

Metrics

Acc.

F1

Acc.

F1

Acc.

F1

TOPJUDGE
- t3 (cid:1) t1
- t2 (cid:1) t1
φ

95.4
95.2
94.8
94.7

68.4
67.7
64.7
64.4

95.6
95.4
94.9
94.9

70.9
70.3
60.2
60.1

57.8
57.4
57.0
57.8

31.8
31.2
31.6
27.6

Table 5: Ablation analysis on PKU.

To further illustrate the signiﬁcance of legal de-
pendencies and explore how the DAG dependen-
cies inﬂuence the performance, we evaluate the
performance of TOPJUDGE under various DAG
architectures. Using Eq. 9 as the full dependen-
cies, we remove the dependency of t3 (cid:1) t1 (law
articles and term of penalty, corresponding to the
sequential form in Fig. 3), t2 (cid:1) t1 (law articles and

charges), and all dependencies respectively. Re-
sults are summarized in Table 5.

We observe that the performance of TOPJUDGE
decreases on all tasks after removing either depen-
dency. More speciﬁcally, when we dropped de-
pendencies t3 (cid:1) t1 and t2 (cid:1) t1 respectively, sig-
niﬁcant decreases are observed for t3 and t2 corre-
spondingly. This demonstrates that incorporating
dependencies is beneﬁcial for relevant subtasks,
verifying its guiding role in the civil law system.

Meanwhile, we note that there are two main
differences between TOPJUDGE and traditional
multi-task models, namely the Cell Initialization
and the Task-Speciﬁc Representation. We can
see that if we eliminate Cell Initialization from
TOPJUDGE,
the dependencies will not be rep-
resented in the model and it will become sim-
ilar to CNN-MTL. If we eliminate the Task-
Speciﬁc Representation from TOPJUDGE, TOP-
JUDGE will become the same as the Pipeline
Model. In a word, the main improvement of our
models comes from the combination.

4.6 Case Study

We give some intuitive examples to demonstrate
the signiﬁcance of TOPJUDGE on LJP subtasks.

As shown in Table 6, case 1 is about negligently
causing a ﬁre. The fact description of this case
states “The defendant pulled up weeds in the ﬁelds
and piled them up in haphazard stacks. Afterward,
he lighted them up and triggered the forest ﬁres...”
TOPJUDGE predicts all judgments correctly, while
CNN-MTL fails to predict the charge and term of
penalty. Moreover, CNN-MTL obtains conﬂicting
judgments, i.e., “crime of arson” and “1-2 years”,
due to its neglecting of dependencies of these sub-
tasks. According to the legal provisions of law ar-
ticle 115, the crime of arson should be sentenced
to more than 10 years.

Methods

Law Charge

Term
(months)

12-24(×)

CNN-MTL

115 Arson(×)

TOPJUDGE

115 Negligently Caus-
ing a Fire

0-6

CNN-MTL

293

Intentional Dam-
age to Property(×)

12-24(×)

TOPJUDGE

293 Affray

0-6

Table 6: Example cases and their prediction results.

Case 2 in Table 6 is another evidence of the in-
sufﬁciency of conventional MTL on LJP. This case
is about picking quarrels and provoking troubles.
Both CNN-MTL and TOPJUDGE succeed to pre-
law article 293
dict the relevant law articles (i.e.,
of the crime of affray). However, CNN-MTL is
confused between “crime of affray” and “crime of
intentional destruction or damage of properties”,
two charges similar to each other. Conversely,
TOPJUDGE can utilize the prediction result of law
articles and consequently prevent this confusion.

To summarize, modeling the explicit dependen-
cies among various subtasks can remarkably help
the LJP model address the issue of predicting con-
ﬂicting results.

4.7 Error Analysis

Prediction errors induced by our proposed model
can be traced down into the following causes.

Data Imbalance.

For the subtasks of law
articles and charges, our model achieves more
than 90% on accuracy, while only about 60% for
macro-F1. This issue is much more severe on the
subtask of the term of penalty, which our model
yields a poor performance of only 30% macro-F1.
The bad performance is mainly due to the imbal-
ance of category labels, e.g., there are only a few
training instances where the term is “life imprison-
ment or death penalty”. Most judgment prediction
approaches perform poorly (especially for Recall)
on these labels as listed in Fig. 4. Instance weight-
ing schemes can be introduced to address this is-
sue in future works.

Incomplete Information. Following existing
LJP works, we predict the ﬁnal judgment accord-
ing to the fact descriptions, which is incomplete as
compared to the whole materials relevant to this
In Chinese Law, there are certain circum-
case.
stances under which the sentence can be short-
ened. For example, minors usually receive a light-

Figure 4: The confusion matrix in the subtask
of predicting the term of penalty on the PKU
dataset. The rows denote the ground truth while
the columns denote the prediction results.

ened penalty, and those guilty of misdemeanors
are allowed for a secured pending trial while pay-
ing a security deposit. However, such informa-
tion is not included in the fact descriptions. The
lack of such information also raises difﬁculties for
judgment prediction, especially for the prediction
of the term of penalty. In Fig. 4, we can see that
the highest error rate comes from the cases with a
short term of penalty. Our model fails to distin-
guish the cases with no penalty and those with 0-6
months term of imprisonment.

5 Conclusion

In this paper, we focus on the task of legal judg-
ment prediction (LJP) and address multiple sub-
tasks of judgment predication with a topological
learning framework. To be speciﬁc, we formalize
the explicit dependencies over these subtasks in a
DAG form, and propose a novel MTL framework,
TOPJUDGE, by integrating the DAG dependen-
cies. Experimental results on three LJP subtasks
and three different datasets show that our TOP-
JUDGE outperforms all single-task baselines and
conventional MTL models consistently and signif-
icantly.

In the future, we will seek to explore the follow-
ing directions: (1) We will explore more LJP sub-
tasks and more scenarios of cases such as multiple

defendants and charges to investigate the effective-
ness of TOPJUDGE. (2) We will explore how to
incorporate into LJP the temporal factors, which
are not considered in this work.

6 Acknowledgements

This work is supported by the National Nat-
ural Science Foundation of China (NSFC No.
61572273, 61772302) and the research fund of
Powerlaw Inc.
for AI+Law Technology. This
work is also funded by China Association for Sci-
ence and Technology (2016QNRC001). Tu is also
supported by China Postdoctoral Innovative Talent
Support Programme.

References

Nikolaos Aletras, Dimitrios Tsarapatsanis, Daniel
Preotiuc-Pietro, and Vasileios Lampos. 2016. Pre-
dicting judicial decisions of the european court of
human rights: A natural language processing per-
spective. PeerJ Computer Science, 2.

Isabelle Augenstein, Sebastian Ruder, and Anders
Søgaard. 2018. Multi-task learning of pairwise
sequence classiﬁcation tasks over disparate label
spaces. In Proceedings of NAACL.

Baharum Baharudin, Lam Hong Lee, and Khairullah
Khan. 2010. A review of machine learning algo-
rithms for text-documents classiﬁcation. Journal of
Advances in Information Technology, 1(1):4–20.

Ronan Collobert and Jason Weston. 2008. A uniﬁed
architecture for natural language processing: Deep
In Pro-
neural networks with multitask learning.
ceedings of ICML, pages 160–167.

Li Deng, Geoffrey Hinton, and Brian Kingsbury. 2013.
New types of deep neural network learning for
speech recognition and related applications: An
overview. In Proceedings of ICASSP, pages 8599–
8603.

Daxiang Dong, Hua Wu, Wei He, Dianhai Yu, and
Haifeng Wang. 2015. Multi-task learning for mul-
tiple language translation. In Proceedings of ACL,
volume 1, pages 1723–1732.

Long Duong, Trevor Cohn, Steven Bird, and Paul
Cook. 2015. Low resource dependency parsing:
Cross-lingual parameter sharing in a neural network
In Proceedings of ACL, volume 2, pages
parser.
845–850.

Orhan Firat, Kyunghyun Cho, and Yoshua Bengio.
2016. Multi-way, multilingual neural machine
translation with a shared attention mechanism.
In
Proceedings of NAACL, pages 866–875.

Ross Girshick. 2015. Fast r-cnn.

In Proceedings of

ICCV, pages 1440–1448.

Kazuma Hashimoto, Yoshimasa Tsuruoka, Richard
Socher, et al. 2017. A joint many-task model: Grow-
ing a neural network for multiple nlp tasks. In Pro-
ceedings of EMNLP, pages 1923–1933.

Sepp Hochreiter and Jurgen Schmidhuber. 1997.
Neural computation,

Long short-term memory.
9(8):1735–1780.

Zikun Hu, Xiang Li, Cunchao Tu, Zhiyuan Liu, and
Maosong Sun. 2018. Few-shot charge prediction
with discriminative legal attributes. In Proceedings
of COLING.

Daniel Martin Katz, Michael J Bommarito II, and Josh
Blackman. 2017. A general approach for predict-
ing the behavior of the supreme court of the united
states. Plos one, 12(4).

R Keown. 1980. Mathematical models for legal pre-

diction. Computer/LJ, 2:829.

Yoon Kim. 2014. Convolutional neural networks for
sentence classiﬁcation. In Proceedings of EMNLP.

Diederik Kingma and Jimmy Ba. 2015. Adam: A
method for stochastic optimization. In Proceedings
of ICLR.

Fred Kort. 1957. Predicting supreme court decisions
mathematically: A quantitative analysis of the ”right
to counsel” cases. American Political Science Re-
view, 51(1):1–12.

Benjamin E Lauderdale and Tom S Clark. 2012. The
supreme court’s many median justices. American
Political Science Review, 106(4):847–866.

Wanchen Lin, Tsung Ting Kuo, and Tung Jia Chang.
2012. Exploiting machine learning models for chi-
nese legal documents labeling, case classiﬁcation,
and sentencing prediction. In Processdings of RO-
CLING, page 140.

Chaolin Liu, Cheng Tsung Chang, and Jim How Ho.
2004. Case instance generation and reﬁnement
for case-based criminal summary judgments in chi-
nese. Journal of Informationence & Engineering,
20(4):783–800.

Chaolin Liu and Chwen Dar Hsieh. 2006. Exploring
phrase-based classiﬁcation of judicial documents for
criminal charges in chinese. In Proceedings of IS-
MIS, pages 681–690.

Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2016.
Recurrent neural network for text classiﬁcation with
multi-task learning. In Proceedings of IJCAI.

Xiaodong Liu, Jianfeng Gao, Xiaodong He, Li Deng,
Kevin Duh, and Ye-Yi Wang. 2015. Representation
learning using multi-task deep neural networks for
semantic classiﬁcation and information retrieval. In
Proceedings of NAACL, pages 912–921.

Chaojun Xiao, Haoxi Zhong, Zhipeng Guo, Cunchao
Tu, Zhiyuan Liu, Maosong Sun, Yansong Feng,
Xianpei Han, Zhen Hu, Heng Wang, et al. 2018.
Cail2018: A large-scale legal dataset for judgment
prediction. arXiv preprint arXiv:1807.02478.

Yongxin Yang and Timothy Hospedales. 2017. Deep
multi-task representation learning: A tensor factori-
sation approach. In Proceedings of ICLR.

Hai Ye, Xin Jiang, Zhunchen Luo, and Wenhan Chao.
2018. Interpretable charge predictions for criminal
cases: Learning to generate court views from fact
descriptions. In Proceedings of NAACL.

Bingfeng Luo, Yansong Feng, Jianbo Xu, Xiang
Zhang, and Dongyan Zhao. 2017. Learning to pre-
dict charges for criminal cases with legal basis. In
Proceedings of EMNLP.

Minh-Thang Luong, Quoc V Le, Ilya Sutskever, Oriol
Vinyals, and Lukasz Kaiser. 2016. Multi-task se-
In Proceedings of
quence to sequence learning.
ICLR.

Jiayuan Mao, Tete Xiao, Yuning Jiang, and Zhimin
Cao. 2017. What can help pedestrian detection? In
Proceedings of CVPR, pages 3127–3136.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Proceedings of NIPS, pages 3111–3119.

Stuart S Nagel. 1963. Applying correlation analysis to

case prediction. Texas Law Review, 42:1006.

Sebastian Ruder, Joachim Bingel, Isabelle Augen-
stein, and Anders Søgaard. 2017. Learning what to
share between loosely related tasks. arXiv preprint
arXiv:1705.08142.

Gerard Salton and Christopher Buckley. 1988. Term-
weighting approaches in automatic text retrieval. In-
formation processing & management, 24(5):513–
523.

Jeffrey A Segal. 1984. Predicting supreme court cases
probabilistically: The search and seizure cases,
American Political Science Review,
1962-1981.
78(4):891–900.

Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: a simple way to prevent neural networks
from overﬁtting. JMLR, 15(1):1929–1958.

Octavia Maria Sulea, Marcos Zampieri, Mihaela Vela,
and Josef Van Genabith. 2017. Exploring the use of
text classi cation in the legal domain. In Proceedings
of ASAIL workshop.

Maosong Sun, Xinxiong Chen, Kaixu Zhang, Zhipeng
Guo, and Zhiyuan Liu. 2016. Thulac: An efﬁcient
lexical analyzer for chinese.

Johan AK Suykens and Joos Vandewalle. 1999. Least
squares support vector machine classiﬁers. Neural
processing letters, 9(3):293–300.

Duyu Tang, Bing Qin, and Ting Liu. 2015. Document
modeling with gated recurrent neural network for
sentiment classiﬁcation. In Proceedings of EMNLP,
pages 1422–1432.

S Sidney Ulmer. 1963. Quantitative analysis of judi-
cial processes: Some practical and theoretical appli-
cations. Law and Contemporary Problems, 28:164.

Legal Judgment Prediction via Topological Learning

Haoxi Zhong∗, Zhipeng Guo∗, Cunchao Tu, Chaojun Xiao, Zhiyuan Liu†, Maosong Sun
Department of Computer Science and Technology
State Key Lab on Intelligent Technology and Systems
Institute for Artiﬁcial Intelligence, Tsinghua University, Beijing, China
{zhonghx18,gzp17,xiaocj16}@mails.tsinghua.edu.cn, tucunchao@gmail.com
{lzy,sms}@tsinghua.edu.cn

Abstract

Legal Judgment Prediction (LJP) aims to pre-
dict the judgment result based on the facts of
a case and becomes a promising application
of artiﬁcial intelligence techniques in the le-
gal ﬁeld. In real-world scenarios, legal judg-
ment usually consists of multiple subtasks,
such as the decisions of applicable law arti-
cles, charges, ﬁnes, and the term of penalty.
Moreover, there exist topological dependen-
cies among these subtasks. While most ex-
isting works only focus on a speciﬁc sub-
task of judgment prediction and ignore the de-
pendencies among subtasks, we formalize the
dependencies among subtasks as a Directed
Acyclic Graph (DAG) and propose a topo-
logical multi-task learning framework, TOP-
JUDGE, which incorporates multiple subtasks
and DAG dependencies into judgment predic-
tion. We conduct experiments on several real-
world large-scale datasets of criminal cases
in the civil law system. Experimental results
show that our model achieves consistent and
signiﬁcant improvements over baselines on all
judgment prediction tasks. The source code
can be obtained from https://github.
com/thunlp/TopJudge.

1

Introduction

Legal Judgment Prediction (LJP) aims to predict
the judgment results of legal cases according to the
fact descriptions. It is a critical technique for the
legal assistant system. On the one hand, LJP can
provide low-cost but high-quality legal consulting
services to the masses who are unfamiliar with le-
gal terminology and the complex judgment pro-
cedures. On the other hand, it can serve as the
handy reference for professionals (e.g., lawyers
and judges) and improve their work efﬁciency.

∗ Indicates equal contribution. The order is determined by

dice rolling.

† Corresponding author.

Figure 1: An illustration of the judicial logic of hu-
man judges in civil law system.

LJP has been studied for decades (Kort, 1957;
Ulmer, 1963; Nagel, 1963; Keown, 1980; Segal,
1984; Lauderdale and Clark, 2012; Ye et al., 2018;
Hu et al., 2018), and most existing works for-
malize LJP as a text classiﬁcation task. For ex-
ample, some works (Liu et al., 2004; Liu and
Hsieh, 2006) propose to extract shallow textual
features (e.g. characters, words, and phrases) for
charge prediction. Katz et al. (2017) predict the
US Supreme Court’s decisions based on efﬁcient
features from case proﬁles. Luo et al. (2017) pro-
pose an attention-based neural model for charge
prediction by incorporating the relevant law arti-
cles.

Despite these efforts in designing efﬁcient fea-
tures and employing advanced NLP techniques,
LJP is still confronted with two major challenges:
Multiple Subtasks in Legal Judgment: Prac-
tically, legal judgment usually consists of detailed
and complicated subclauses, such as charges, the
term of penalty, and ﬁnes. Speciﬁcally, for those
countries with the civil law system (e.g., China,
France, and Germany), the prediction of relevant
articles is also considered to be one of the funda-
mental subtasks, which will guide the prediction
for other subtasks. In other words, all these sub-
tasks compose the complete form of judgment pre-

diction. Nevertheless, existing works on LJP usu-
ally focus on one speciﬁc subtask of judgments,
which does not conform to the real scenarios. Al-
though some methods (Luo et al., 2017) are devel-
oped to predict law articles and charges at the same
time, their models are designed for a speciﬁc set of
subtasks which are hard to scale to other subtasks.
Topological Dependencies between Subtasks:
there exists a strict order
For human judges,
among the subtasks of legal judgment. As illus-
trated in Fig. 1, given the fact description of a spe-
ciﬁc case, a judge in the civil law system ﬁrst de-
cides which law articles are relevant to the sce-
nario, and then determines the charges according
to the instructions of relevant law articles. Based
on these results, the judge further conﬁrms the
term of penalty and ﬁnes. How to simulate the ju-
dicial logic of human judges and model the topo-
logical dependencies among legal subtasks will
deeply inﬂuence the creditability and interpretabil-
ity of judgment prediction.

As stated above, conventional works cannot
handle these two challenges due to both the lim-
itation of speciﬁc tasks and neglecting topological
dependencies. To address these issues, we propose
to model the multiple subtasks in judgment pre-
diction jointly under a novel multi-task learning
framework.

We model the topological dependencies among
these subtasks with a Directed Acyclic Graph
(DAG), which means all subtasks are arranged in
topological order. If the judgment of the j-th sub-
task tj depends on the output of the i-th subtask
ti, then ti appears earlier than tj in such order. It
is notable that such formulation provides an ex-
plicit explanation of dependency relations among
subtasks.

Accordingly, we introduce topological learning
for LJP and propose a uniﬁed framework, named
as TOPJUDGE. Speciﬁcally, given the encoded
representation of the fact description, TOPJUDGE
predicts the outputs of all the subtasks following
the topological order, and the output of a speciﬁc
subtask will be affected by all the subtasks it de-
pends on. In contrast with conventional multi-task
learning, our model takes the explicit topological
dependencies of LJP subtasks into consideration
and is ﬂexible to handle other LJP subtasks. More-
over, the topological order of legal dependencies
renders our model interpretable and reliable.

To verify the effectiveness and ﬂexibility of

TOPJUDGE, we conduct a series of experiments
on several real-world large-scale datasets. Exper-
imental results show that our model achieves sig-
niﬁcant and consistent improvements over state-
of-the-art models on all tasks and datasets. To
summarize, we make several noteworthy contribu-
tions as follows:

(1) We are the ﬁrst to explore and formalize the
multiple subtasks of legal judgment under a joint
learning framework. Moreover, we formulate the
dependencies among the subtasks of LJP as a form
of DAG and introduce this prior knowledge to en-
hance judgment prediction.

(2) We propose a novel judgment prediction
framework, TOPJUDGE, to unify multiple sub-
tasks and make judgment predictions through
topological learning. This model can handle any
form of DAG dependent subtasks, which has been
veriﬁed in the experiments.

(3) We carry out experiments on several large-
scale real-world datasets, and our model signiﬁ-
cantly and consistently outperforms all the base-
lines on all subtasks.

2 Related Work

2.1

Judgment Prediction

Employing automatic analysis techniques for legal
judgment has drawn attention from researchers in
the legal ﬁeld for decades. Early works usually
focus on analyzing existing legal cases in speciﬁc
scenarios with mathematical and statistical algo-
rithms (Kort, 1957; Ulmer, 1963; Nagel, 1963;
Keown, 1980; Segal, 1984; Lauderdale and Clark,
2012).

With the development of machine learning and
text mining techniques, more researchersformal-
ize this task under text classiﬁcation frameworks.
Most of these studies attempt to extract efﬁcient
features from text content (Liu and Hsieh, 2006;
Lin et al., 2012; Aletras et al., 2016; Sulea et al.,
2017) or case annotations (e.g., dates, terms, lo-
cations, and types) (Katz et al., 2017). However,
these conventional methods can only utilize shal-
low textual features and manually designed fac-
tors, both require massive human efforts and usu-
ally suffer from the generalization issue when ap-
plied to other scenarios.

Inspired by the success of neural networks on
NLP tasks (Kim, 2014; Baharudin et al., 2010;
Tang et al., 2015), researchers began to handle LJP
by incorporating neural models with legal knowl-

edge. For example, Luo et al. (2017) present an
attention-based neural network that jointly mod-
els charge prediction and relevant article extrac-
tion. Hu et al. (2018) incorporate 10 discrimina-
tive legal attributes to predict few-shot and con-
fusing charges. Nevertheless, these models are de-
signed for speciﬁc subtasks and thus non-trivial to
be extended to more subtasks of LJP with complex
dependencies. Besides, Ye et al. (2018) utilize a
Seq2Seq model to generate court views with fact
descriptions and predicted charges in Chinese civil
law.

2.2 Multi-task Learning

Multi-task learning (MTL) aims to exploit the
commonalities and differences across relevant
tasks by solving them at the same time.
It can
transfer useful information among various tasks
and has been applied to a wide range of ar-
eas, including NLP (Collobert and Weston, 2008),
speech recognition (Deng et al., 2013), and com-
puter vision (Girshick, 2015; Mao et al., 2017).

There have been numerous successful usages
of MTL in NLP tasks. Most works follow the
hard parameter sharing setting by sharing repre-
sentations or some encoding layers among rele-
vant tasks. For example, Collobert and Weston
(2008) use shared word embeddings in solving
part-of-speech tagging and semantic role labeling
tasks. Liu et al. (2015) share the encoding lay-
ers of input queries to address query classiﬁcation
and information retrieval. Dong et al. (2015) and
Luong et al. (2016) propose to share encoders or
decoders to improve one (many) to many neural
machine translation. Firat et al. (2016) propose to
share attention mechanism in multi-way, multilin-
gual machine translation. Besides hard parameter
sharing, soft parameter sharing is another com-
mon approach in MTL. It assumes that each task
owns its speciﬁc parameters and the distance be-
tween parameters in different tasks should be close
to each other. For example, Duong et al. (2015)
employ L2 distance for regularization, while Yang
and Hospedales (2017) use the trace norm. Liu
et al. (2016) introduce gates among task-speciﬁc
RNN layers to control the information ﬂow. Ruder
et al. (2017) introduce a model which can de-
cide the amount of sharing between different NLP
tasks. There are also some works focusing on in-
creasing tasks (Hashimoto et al., 2017) or handing
unlabeled data (Augenstein et al., 2018).

Figure 2: The framework of TOPJUDGE.

In this work, we introduce a topological learn-
ing framework TOPJUDGE to handle multiple sub-
tasks in LJP. Different to conventional MTL mod-
els which focus on how to share parameters among
relevant tasks, TOPJUDGE models the explicit de-
pendencies among these subtasks with scalable
DAG forms.

3 Method

In the following parts, we will ﬁrst give the essen-
tial deﬁnitions of LJP task. We then introduce the
DAG dependencies of the subtasks in LJP. And ﬁ-
nally, we describe the neural encoder for fact rep-
resentation and the judgment predictor for the sub-
tasks with DAG dependencies. The overall frame-
work of TOPJUDGE has been shown in Fig 2.

3.1 Problem Formulation

We will focus on the LJP tasks in civil law. Sup-
pose the fact description of a case is a word se-
quence x = {x1, x2, . . . , xn}, where n is the
length of x and each word xi comes from a ﬁxed
vocabulary W . Based on the fact description x,
the task of LJP T aims to predict judgment results
of applicable law articles, charges, term of penalty,
ﬁnes and so on. Formally, we assume T contains
|T | subtasks, i.e., T = {t1, t2, . . . , t|T |}, each of
which is a classiﬁcation task. For the i-th subtask
ti ∈ T , we aim to predict the corresponding result
yi ⊆ Yi, where Yi is a subtask-speciﬁc label set.
Take the subtask of charge prediction for example,
the corresponding label set should contain Theft,
Trafﬁc Violation, Intentional Homicide and so on.

3.2 DAG Dependencies of Subtasks

We assume that the dependencies among multiple
subtasks of LJP form a DAG. As a result, the task
list T should satisfy topological constraints. For-
mally, we use the notation ti (cid:1) tj to denote that

(a) Typical MTL form of DAG

(b) Sequential form of DAG

(c) General form of DAG

Figure 3: Three typical forms of DAG dependencies.

the j-th subtask depends on the i-th subtask, and
Dj = {ti | ti (cid:1) tj} to denote the dependency set.
The task list T can be ordered to satisfy the fol-
lowing constraint

i < j,

∀(i, j) ∈ {(i, j) | ti ∈ Dj}.

(1)

We demonstrate the ﬂexibility of our formula-
tion by describing two special cases: (1) As shown
in Fig. 3 (a), if no dependencies exist, i.e., Dj = ∅,
it corresponds to the typical MTL setting where
we simultaneously make predictions for all sub-
tasks. (2) As shown in Fig. 3 (b), if each task only
depends on its previous task, i.e., Dj = {tj−1}, it
forms a sequential learning process.

3.3 Neural Encoder for Fact Descriptions

We employ a fact encoder to generate the fact de-
scription’s vector representation as the input of
TOPJUDGE. In the following part, we brieﬂy in-
troduce an encoder based on Convolutional Neural
Networks (CNN) (Kim, 2014).

Taking a word sequence x as input, the CNN
encoder computes the text representation through
three layers, i.e., lookup layer, convolution layer
and pooling layer.

Lookup We ﬁrst convert each word xi in x into
its word embedding xi ∈ Rk, where k is the di-
mension of word embeddings. The word embed-
ding sequence is then represented as

ˆx = {x1, x2, . . . , xn}.

(2)

Convolution A convolution operation involves
a convolution matrix W ∈ Rm×(h×k), which is
applied to a sliding window of length h with num-
ber of ﬁlters m to produce a feature map by

ci = W · xi:i+h−1 + b,

(3)

where xi:i+h−1 is the concatenation of word em-
beddings within the i-th window and b ∈ Rm is
the bias vector. By applying convolution over each
window, we obtain c = {c1, . . . , cn−h+1}.

Pooling We apply per-dimension max-pooling
over c and obtain the ﬁnal fact representation d =
[d1, . . . , dm] by

dt = max(c1,t, . . . , cn−h+1,t), ∀t ∈ [1, m].

(4)

3.4

Judgment Predictor over DAG

Based on the DAG assumption, we obtain an or-
dered task list T ∗ = [t1, t2, . . . , t|T |]. For each
task tj ∈ T , we aim to predict its judgment result
yj based on the fact representation vector d and
the judgment results of its dependent tasks.

For prediction, we employ a speciﬁc LSTM cell
for each task and get the output of each task in
the topological order. More speciﬁcally, for each
task tj ∈ T , we obtain its ﬁnal judgment result
through three steps, i.e., cell initialization, task-
speciﬁc representation, and prediction.

Cell Initialization As stated above, the predic-
tion result of tj will be conditioned on the fact
representation d and the outputs of all dependent
tasks yk, ∀tk ∈ Dj. Hence, we have

(cid:105)

(cid:104)¯hj
¯cj

=

(cid:88)

(cid:16)

Wi,j

(cid:105)(cid:17)

(cid:104)hi
ci

+ bj

(5)

ti∈Dj

Here, hi and ci are the hidden state and memory
cell of ti. ¯hj and ¯cj are the initial hidden state and
memory cell of tj. Wi,j and bj are transformation
matrices and bias vectors speciﬁc to ti and tj.

Task-Speciﬁc Representation Taking the fact
representation d, the initial hidden state ¯hj, and
the initial memory cell ¯cj as inputs, we process

them with an LSTM cell (Hochreiter and Schmid-
huber, 1997).

We regard the ﬁnal hidden state hj as the task-
speciﬁc representation of task tj. The last cell
state cj is used to compose the initial hidden state
for the downstream tasks by Eq. 5

Prediction With the representation hj, we ap-
ply an afﬁne transformation followed by softmax
and obtain the ﬁnal prediction as

ˆyj = softmax (cid:0)Wp

j hj + bp

j

(cid:1) .

(6)

j are parameters speciﬁc to task

Here, Wp
tj.

j and bp

With the prediction result ˆyj, we minimize the

cross-entropy between ˆyj and yj as follows:

Lj(ˆyj, yj) = −

yj,k log(ˆyj,k).

(7)

|Yj |
(cid:88)

k=1

3.5 Training

We use cross-entropy loss for each subtask and
sum up losses to train TOPJUDGE:

L =

λjLj(ˆyj, yj),

(8)

|T |
(cid:88)

j=1

where λj is the weight factor for each subtask tj.
The DAG dependencies of subtasks ensure that
our model is differentiable and can be trained in an
end-to-end fashion. In practice, we set all weights
λj to 1, and employ Adam (Kingma and Ba, 2015)
for optimization. We also apply dropout (Srivas-
tava et al., 2014) on the fact representation to pre-
vent overﬁtting.

4 Experiments

To evaluate the proposed TOPJUDGE framework,
we conduct a series of experiments on LJP over
three large-scale datasets of criminal cases in
China. We select three representative judgment
prediction subtasks for comparison, including law
articles, charges, and the terms of penalty.

4.1 Dataset Construction

As there are no publicly available LJP datasets
in previous works, we collect and construct three
different LJP datasets, including CJO, PKU, and
CAIL. CJO consists of criminal cases published
by the Chinese government from China Judge-
ment Online1. PKU contains criminal cases pub-
lished by Peking University Law Online2. CAIL

1 http://wenshu.court.gov.cn/
2 http://www.pkulaw.com/

Datasets

CJO

PKU

CAIL

Cases
Law Articles
Charges
Term of Penalty

1, 007, 744
98
99
11

175, 744
68
64
11

113, 536
105
122
11

Table 1: The statistics of different datasets.

(Chinese AI and Law Challenge) is another crim-
inal case dataset for competition released by the
Supreme People’s Court of China3. The details of
CAIL can be found in Xiao et al. (2018).

For all datasets we mentioned above, as the doc-
uments are well-structured and human-annotated,
we can easily extract fact descriptions, applica-
ble law articles, charges and the terms of penalty
from each document using regular expressions.
We have manually checked a randomly sampled
set of cases, and extraction errors are negligible.

In real-world scenarios, there are some cases
with multiple defendants and multiple charges,
which will increase the complexity of judgment
prediction. As our model aims to explore the ef-
fectiveness of considering topological dependen-
cies between various subtasks, we ﬁlter out these
cases and leave them as our future work.

Meanwhile,

there are also some infrequent
charges and law articles, such as money launder-
ing, smuggling of nuclear materials and tax dodge.
We ﬁlter out these infrequent charges and law arti-
cles and only keep those with frequencies greater
than 100. For the term of penalty, we divide the
terms into non-overlapping intervals. We list de-
tailed statistics of these datasets in Table 1.

4.2 Baselines

For comparison, we employ the following text
classiﬁcation models and judgment prediction
methods as baselines:

TFIDF+SVM: We employ term-frequency in-
verse document frequency (TFIDF) (Salton and
Buckley, 1988) to extract word features and uti-
lize SVM (Suykens and Vandewalle, 1999) for text
classiﬁcation.

CNN: We employ CNN with multiple ﬁlter
widths (Kim, 2014) for fact encoding and classi-
ﬁcation.

Hierarchical LSTM (HLSTM): Tang et al.
(2015) employs hierarchical neural networks to
learn document representations in sentiment clas-

3 http://cail.cipsc.org.cn/index.html

Tasks

Law Articles

Charges

The Term of Penalty

Metrics

Acc. MP MR

F1

Acc. MP MR

F1

Acc. MP MR

F1

Single

Multi

TFIDF+SVM 82.4
92.5
91.4

CNN
HLSTM

Fact-Law Att.
PM
CNN-MTL
HLSTM-MTL

93.5
93.7
94.3
92.4

94.4

45.5
46.9
38.6

50.9
51.9
53.0
45.5

53.9

26.7
38.4
37.3

45.6
44.1
46.0
41.4

47.3

30.2
40.0
36.9

45.9
44.9
46.9
41.0

48.2

82.2
92.3
91.8

93.4
93.6
94.1
92.3

94.9

47.4
41.2
37.8

47.2
45.5
48.5
41.9

53.9

27.9
32.3
36.0

41.4
39.1
41.7
36.6

48.2

31.3
33.7
35.2

41.5
39.3
42.5
35.9

49.1

48.5
57.4
56.1

56.3
58.2
58.7
54.9

58.8

36.0
35.6
22.5

31.3
38.2
39.9
30.6

40.2

16.7
22.2
25.0

26.4
24.9
28.8
26.6

32.9

16.5
22.7
23.3

26.7
26.8
29.4
26.4

32.8

Ours

TOPJUDGE

Table 2: Judgment prediction results on CJO.

Tasks

Law Articles

Charges

The Term of Penalty

Metrics

Acc. MP MR

F1

Acc. MP MR

F1

Acc. MP MR

F1

Single

Multi

TFIDF+SVM 80.9
93.1
91.7

CNN
HLSTM

Fact-Law Att.
PM
CNN-MTL
HLSTM-MTL

93.9
94.4
95.0
93.9

95.4

51.3
64.3
54.4

68.1
69.6
73.8
71.2

76.4

32.6
52.6
53.4

63.4
61.0
64.9
64.6

67.6

36.4
54.3
50.9

63.5
62.2
66.0
65.1

68.4

81.0
93.3
91.9

94.2
94.3
95.0
93.8

95.6

53.4
61.9
52.5

65.8
65.1
70.7
67.8

75.9

35.4
49.3
48.9

58.5
56.2
60.6
60.0

69.6

38.7
51.1
47.3

58.7
57.2
61.7
60.7

70.9

45.3
57.6
54.3

55.7
58.2
58.4
55.4

57.8

30.4
24.1
20.6

27.7
36.2
36.0
31.3

38.9

17.4
23.1
21.7

27.4
26.4
28.7
26.2

32.1

17.2
23.3
19.0

26.5
27.1
28.9
25.7

31.8

Ours

TOPJUDGE

Table 3: Judgment prediction results on PKU.

siﬁcation. Based on this work, we employ an
LSTM for sentence representations and another
one to obtain the representation of complete fact
descriptions.

Fact-Law Attention Model: Luo et al. (2017)
proposes a neural charge prediction model by cap-
turing the interaction between fact descriptions
and applicable laws with attention mechanism.

Pipeline Model (PM): To demonstrate the
advantage of TOPJUDGE on modeling subtasks
jointly, we also implement a pipelined method for
comparison. Here, we train 3 separate CNN classi-
ﬁers for law articles, charges, and term of penalty.
For each subtask, the input is the concatenation
of the fact representation and the embeddings for
predicted labels of previous subtasks.

Besides, we compare our model with conven-
tional MTL methods that do not consider the de-
pendencies among subtasks as in Fig. 3 (a). These
methods are denoted as CNN-MTL and HLSTM-
MTL, where we implement the fact encoder as in
Fig. 2 using CNN or HLSTM respectively.

4.3 Experimental Settings

As the case documents are written in Chinese
with no space between words, we employ THU-
LAC (Sun et al., 2016) for word segmentation. Af-
terward, we adopt the Skip-Gram model (Mikolov
et al., 2013) to pre-train word embeddings on these

case documents, with embedding size set to 200
and frequency threshold set to 25.

For all models, we set

the fact representa-
tion and task-speciﬁc representation size to 256.
Meanwhile, we set the maximum sentence length
to 128 words and maximum document length to
32 sentences.

For training, the learning rate of Adam opti-
mizer is 10−3, and the dropout probability is 0.5.
We also set the batch size to 128 for all models.
We train every model for 16 epochs, and evaluate
the ﬁnal model on the testing set.

We employ accuracy (Acc.), macro-precision
(MP), macro-recall (MR) and macro-F1 (F1)
the macro-
as evaluation metrics.
precision/recall/F1 are calculated by averaging the
precision/recall/F1 of each category.

Here,

4.4 Results and Analysis

We evaluate the performance on three LJP sub-
including law articles (denoted as t1),
tasks,
charges (denoted as t2), and the terms of penalty
(denoted as t3). Experimental results are shown in
Tables 2, 3, and 4. Note that, we implement TOP-
JUDGE with the dependency relationship in Fig. 3
(c), i.e.,

D1 = φ, D2 = {t1}, D3 = {t1, t2}.

(9)

Tasks

Law Articles

Charges

The Term of Penalty

Metrics

Acc. MP MR

F1

Acc. MP MR

F1

Acc. MP MR

F1

Single

Multi

TFIDF+SVM 60.1
81.4
-

CNN
HLSTM

Fact-Law Att.
PM
CNN-MTL
HLSTM-MTL

70.9
84.7
84.5
-

86.3

54.9
74.4
-

64.8
80.7
80.0
-

81.9

45.3
64.1
-

63.6
68.6
68.1
-

71.1

46.3
65.7
-

59.1
70.8
70.3
-

73.4

59.2
80.7
-

68.7
83.6
83.4
-

85.7

53.9
77.3
-

66.1
81.6
81.6
-

83.4

45.0
65.5
-

65.3
70.0
69.1
-

76.0

45.7
67.2
-

60.1
72.1
71.6
-

78.3

28.4
28.8
-

36.5
40.0
39.5
-

38.3

22.9
34.7
-

29.9
37.4
37.2
-

36.1

20.0
27.8
-

27.6
32.0
32.3
-

33.1

18.1
28.6
-

27.1
31.6
31.3
-

32.1

Ours

TOPJUDGE

Table 4: Judgment prediction results on CAIL. Note that, “-” means the model does not converge within
128 epochs.

This means that the prediction of charges depends
on law articles, and the prediction of term of
penalty depends on both law articles and charges.
Such explicit dependencies conform to the judi-
cial logic of human judges, which will be veriﬁed
in later sections. These results show that:

(1) The proposed TOPJUDGE model outper-
forms other baselines signiﬁcantly on most sub-
tasks and datasets. It demonstrates the effective-
ness and robustness of our proposed framework.

(2) Compared with conventional single-task
models, e.g., CNN and HLSTM, MTL methods
take advantage of the correlation among relevant
subtasks and thus achieve promising improve-
It indicates the importance of modeling
ments.
LJP subtasks jointly.

(3) Moreover, TOPJUDGE signiﬁcantly outper-
forms typical MTL models, especially on the pre-
diction of charges and the terms of penalty. It veri-
ﬁes the rationality and importance of modeling de-
pendencies over LJP subtasks with DAG.

4.5 Ablation Analysis

Tasks

t1

t2

t3

Metrics

Acc.

F1

Acc.

F1

Acc.

F1

TOPJUDGE
- t3 (cid:1) t1
- t2 (cid:1) t1
φ

95.4
95.2
94.8
94.7

68.4
67.7
64.7
64.4

95.6
95.4
94.9
94.9

70.9
70.3
60.2
60.1

57.8
57.4
57.0
57.8

31.8
31.2
31.6
27.6

Table 5: Ablation analysis on PKU.

To further illustrate the signiﬁcance of legal de-
pendencies and explore how the DAG dependen-
cies inﬂuence the performance, we evaluate the
performance of TOPJUDGE under various DAG
architectures. Using Eq. 9 as the full dependen-
cies, we remove the dependency of t3 (cid:1) t1 (law
articles and term of penalty, corresponding to the
sequential form in Fig. 3), t2 (cid:1) t1 (law articles and

charges), and all dependencies respectively. Re-
sults are summarized in Table 5.

We observe that the performance of TOPJUDGE
decreases on all tasks after removing either depen-
dency. More speciﬁcally, when we dropped de-
pendencies t3 (cid:1) t1 and t2 (cid:1) t1 respectively, sig-
niﬁcant decreases are observed for t3 and t2 corre-
spondingly. This demonstrates that incorporating
dependencies is beneﬁcial for relevant subtasks,
verifying its guiding role in the civil law system.

Meanwhile, we note that there are two main
differences between TOPJUDGE and traditional
multi-task models, namely the Cell Initialization
and the Task-Speciﬁc Representation. We can
see that if we eliminate Cell Initialization from
TOPJUDGE,
the dependencies will not be rep-
resented in the model and it will become sim-
ilar to CNN-MTL. If we eliminate the Task-
Speciﬁc Representation from TOPJUDGE, TOP-
JUDGE will become the same as the Pipeline
Model. In a word, the main improvement of our
models comes from the combination.

4.6 Case Study

We give some intuitive examples to demonstrate
the signiﬁcance of TOPJUDGE on LJP subtasks.

As shown in Table 6, case 1 is about negligently
causing a ﬁre. The fact description of this case
states “The defendant pulled up weeds in the ﬁelds
and piled them up in haphazard stacks. Afterward,
he lighted them up and triggered the forest ﬁres...”
TOPJUDGE predicts all judgments correctly, while
CNN-MTL fails to predict the charge and term of
penalty. Moreover, CNN-MTL obtains conﬂicting
judgments, i.e., “crime of arson” and “1-2 years”,
due to its neglecting of dependencies of these sub-
tasks. According to the legal provisions of law ar-
ticle 115, the crime of arson should be sentenced
to more than 10 years.

Methods

Law Charge

Term
(months)

12-24(×)

CNN-MTL

115 Arson(×)

TOPJUDGE

115 Negligently Caus-
ing a Fire

0-6

CNN-MTL

293

Intentional Dam-
age to Property(×)

12-24(×)

TOPJUDGE

293 Affray

0-6

Table 6: Example cases and their prediction results.

Case 2 in Table 6 is another evidence of the in-
sufﬁciency of conventional MTL on LJP. This case
is about picking quarrels and provoking troubles.
Both CNN-MTL and TOPJUDGE succeed to pre-
law article 293
dict the relevant law articles (i.e.,
of the crime of affray). However, CNN-MTL is
confused between “crime of affray” and “crime of
intentional destruction or damage of properties”,
two charges similar to each other. Conversely,
TOPJUDGE can utilize the prediction result of law
articles and consequently prevent this confusion.

To summarize, modeling the explicit dependen-
cies among various subtasks can remarkably help
the LJP model address the issue of predicting con-
ﬂicting results.

4.7 Error Analysis

Prediction errors induced by our proposed model
can be traced down into the following causes.

Data Imbalance.

For the subtasks of law
articles and charges, our model achieves more
than 90% on accuracy, while only about 60% for
macro-F1. This issue is much more severe on the
subtask of the term of penalty, which our model
yields a poor performance of only 30% macro-F1.
The bad performance is mainly due to the imbal-
ance of category labels, e.g., there are only a few
training instances where the term is “life imprison-
ment or death penalty”. Most judgment prediction
approaches perform poorly (especially for Recall)
on these labels as listed in Fig. 4. Instance weight-
ing schemes can be introduced to address this is-
sue in future works.

Incomplete Information. Following existing
LJP works, we predict the ﬁnal judgment accord-
ing to the fact descriptions, which is incomplete as
compared to the whole materials relevant to this
In Chinese Law, there are certain circum-
case.
stances under which the sentence can be short-
ened. For example, minors usually receive a light-

Figure 4: The confusion matrix in the subtask
of predicting the term of penalty on the PKU
dataset. The rows denote the ground truth while
the columns denote the prediction results.

ened penalty, and those guilty of misdemeanors
are allowed for a secured pending trial while pay-
ing a security deposit. However, such informa-
tion is not included in the fact descriptions. The
lack of such information also raises difﬁculties for
judgment prediction, especially for the prediction
of the term of penalty. In Fig. 4, we can see that
the highest error rate comes from the cases with a
short term of penalty. Our model fails to distin-
guish the cases with no penalty and those with 0-6
months term of imprisonment.

5 Conclusion

In this paper, we focus on the task of legal judg-
ment prediction (LJP) and address multiple sub-
tasks of judgment predication with a topological
learning framework. To be speciﬁc, we formalize
the explicit dependencies over these subtasks in a
DAG form, and propose a novel MTL framework,
TOPJUDGE, by integrating the DAG dependen-
cies. Experimental results on three LJP subtasks
and three different datasets show that our TOP-
JUDGE outperforms all single-task baselines and
conventional MTL models consistently and signif-
icantly.

In the future, we will seek to explore the follow-
ing directions: (1) We will explore more LJP sub-
tasks and more scenarios of cases such as multiple

defendants and charges to investigate the effective-
ness of TOPJUDGE. (2) We will explore how to
incorporate into LJP the temporal factors, which
are not considered in this work.

6 Acknowledgements

This work is supported by the National Nat-
ural Science Foundation of China (NSFC No.
61572273, 61772302) and the research fund of
Powerlaw Inc.
for AI+Law Technology. This
work is also funded by China Association for Sci-
ence and Technology (2016QNRC001). Tu is also
supported by China Postdoctoral Innovative Talent
Support Programme.

References

Nikolaos Aletras, Dimitrios Tsarapatsanis, Daniel
Preotiuc-Pietro, and Vasileios Lampos. 2016. Pre-
dicting judicial decisions of the european court of
human rights: A natural language processing per-
spective. PeerJ Computer Science, 2.

Isabelle Augenstein, Sebastian Ruder, and Anders
Søgaard. 2018. Multi-task learning of pairwise
sequence classiﬁcation tasks over disparate label
spaces. In Proceedings of NAACL.

Baharum Baharudin, Lam Hong Lee, and Khairullah
Khan. 2010. A review of machine learning algo-
rithms for text-documents classiﬁcation. Journal of
Advances in Information Technology, 1(1):4–20.

Ronan Collobert and Jason Weston. 2008. A uniﬁed
architecture for natural language processing: Deep
In Pro-
neural networks with multitask learning.
ceedings of ICML, pages 160–167.

Li Deng, Geoffrey Hinton, and Brian Kingsbury. 2013.
New types of deep neural network learning for
speech recognition and related applications: An
overview. In Proceedings of ICASSP, pages 8599–
8603.

Daxiang Dong, Hua Wu, Wei He, Dianhai Yu, and
Haifeng Wang. 2015. Multi-task learning for mul-
tiple language translation. In Proceedings of ACL,
volume 1, pages 1723–1732.

Long Duong, Trevor Cohn, Steven Bird, and Paul
Cook. 2015. Low resource dependency parsing:
Cross-lingual parameter sharing in a neural network
In Proceedings of ACL, volume 2, pages
parser.
845–850.

Orhan Firat, Kyunghyun Cho, and Yoshua Bengio.
2016. Multi-way, multilingual neural machine
translation with a shared attention mechanism.
In
Proceedings of NAACL, pages 866–875.

Ross Girshick. 2015. Fast r-cnn.

In Proceedings of

ICCV, pages 1440–1448.

Kazuma Hashimoto, Yoshimasa Tsuruoka, Richard
Socher, et al. 2017. A joint many-task model: Grow-
ing a neural network for multiple nlp tasks. In Pro-
ceedings of EMNLP, pages 1923–1933.

Sepp Hochreiter and Jurgen Schmidhuber. 1997.
Neural computation,

Long short-term memory.
9(8):1735–1780.

Zikun Hu, Xiang Li, Cunchao Tu, Zhiyuan Liu, and
Maosong Sun. 2018. Few-shot charge prediction
with discriminative legal attributes. In Proceedings
of COLING.

Daniel Martin Katz, Michael J Bommarito II, and Josh
Blackman. 2017. A general approach for predict-
ing the behavior of the supreme court of the united
states. Plos one, 12(4).

R Keown. 1980. Mathematical models for legal pre-

diction. Computer/LJ, 2:829.

Yoon Kim. 2014. Convolutional neural networks for
sentence classiﬁcation. In Proceedings of EMNLP.

Diederik Kingma and Jimmy Ba. 2015. Adam: A
method for stochastic optimization. In Proceedings
of ICLR.

Fred Kort. 1957. Predicting supreme court decisions
mathematically: A quantitative analysis of the ”right
to counsel” cases. American Political Science Re-
view, 51(1):1–12.

Benjamin E Lauderdale and Tom S Clark. 2012. The
supreme court’s many median justices. American
Political Science Review, 106(4):847–866.

Wanchen Lin, Tsung Ting Kuo, and Tung Jia Chang.
2012. Exploiting machine learning models for chi-
nese legal documents labeling, case classiﬁcation,
and sentencing prediction. In Processdings of RO-
CLING, page 140.

Chaolin Liu, Cheng Tsung Chang, and Jim How Ho.
2004. Case instance generation and reﬁnement
for case-based criminal summary judgments in chi-
nese. Journal of Informationence & Engineering,
20(4):783–800.

Chaolin Liu and Chwen Dar Hsieh. 2006. Exploring
phrase-based classiﬁcation of judicial documents for
criminal charges in chinese. In Proceedings of IS-
MIS, pages 681–690.

Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2016.
Recurrent neural network for text classiﬁcation with
multi-task learning. In Proceedings of IJCAI.

Xiaodong Liu, Jianfeng Gao, Xiaodong He, Li Deng,
Kevin Duh, and Ye-Yi Wang. 2015. Representation
learning using multi-task deep neural networks for
semantic classiﬁcation and information retrieval. In
Proceedings of NAACL, pages 912–921.

Chaojun Xiao, Haoxi Zhong, Zhipeng Guo, Cunchao
Tu, Zhiyuan Liu, Maosong Sun, Yansong Feng,
Xianpei Han, Zhen Hu, Heng Wang, et al. 2018.
Cail2018: A large-scale legal dataset for judgment
prediction. arXiv preprint arXiv:1807.02478.

Yongxin Yang and Timothy Hospedales. 2017. Deep
multi-task representation learning: A tensor factori-
sation approach. In Proceedings of ICLR.

Hai Ye, Xin Jiang, Zhunchen Luo, and Wenhan Chao.
2018. Interpretable charge predictions for criminal
cases: Learning to generate court views from fact
descriptions. In Proceedings of NAACL.

Bingfeng Luo, Yansong Feng, Jianbo Xu, Xiang
Zhang, and Dongyan Zhao. 2017. Learning to pre-
dict charges for criminal cases with legal basis. In
Proceedings of EMNLP.

Minh-Thang Luong, Quoc V Le, Ilya Sutskever, Oriol
Vinyals, and Lukasz Kaiser. 2016. Multi-task se-
In Proceedings of
quence to sequence learning.
ICLR.

Jiayuan Mao, Tete Xiao, Yuning Jiang, and Zhimin
Cao. 2017. What can help pedestrian detection? In
Proceedings of CVPR, pages 3127–3136.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Proceedings of NIPS, pages 3111–3119.

Stuart S Nagel. 1963. Applying correlation analysis to

case prediction. Texas Law Review, 42:1006.

Sebastian Ruder, Joachim Bingel, Isabelle Augen-
stein, and Anders Søgaard. 2017. Learning what to
share between loosely related tasks. arXiv preprint
arXiv:1705.08142.

Gerard Salton and Christopher Buckley. 1988. Term-
weighting approaches in automatic text retrieval. In-
formation processing & management, 24(5):513–
523.

Jeffrey A Segal. 1984. Predicting supreme court cases
probabilistically: The search and seizure cases,
American Political Science Review,
1962-1981.
78(4):891–900.

Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: a simple way to prevent neural networks
from overﬁtting. JMLR, 15(1):1929–1958.

Octavia Maria Sulea, Marcos Zampieri, Mihaela Vela,
and Josef Van Genabith. 2017. Exploring the use of
text classi cation in the legal domain. In Proceedings
of ASAIL workshop.

Maosong Sun, Xinxiong Chen, Kaixu Zhang, Zhipeng
Guo, and Zhiyuan Liu. 2016. Thulac: An efﬁcient
lexical analyzer for chinese.

Johan AK Suykens and Joos Vandewalle. 1999. Least
squares support vector machine classiﬁers. Neural
processing letters, 9(3):293–300.

Duyu Tang, Bing Qin, and Ting Liu. 2015. Document
modeling with gated recurrent neural network for
sentiment classiﬁcation. In Proceedings of EMNLP,
pages 1422–1432.

S Sidney Ulmer. 1963. Quantitative analysis of judi-
cial processes: Some practical and theoretical appli-
cations. Law and Contemporary Problems, 28:164.

Legal Judgment Prediction via Topological Learning

Haoxi Zhong∗, Zhipeng Guo∗, Cunchao Tu, Chaojun Xiao, Zhiyuan Liu†, Maosong Sun
Department of Computer Science and Technology
State Key Lab on Intelligent Technology and Systems
Institute for Artiﬁcial Intelligence, Tsinghua University, Beijing, China
{zhonghx18,gzp17,xiaocj16}@mails.tsinghua.edu.cn, tucunchao@gmail.com
{lzy,sms}@tsinghua.edu.cn

Abstract

Legal Judgment Prediction (LJP) aims to pre-
dict the judgment result based on the facts of
a case and becomes a promising application
of artiﬁcial intelligence techniques in the le-
gal ﬁeld. In real-world scenarios, legal judg-
ment usually consists of multiple subtasks,
such as the decisions of applicable law arti-
cles, charges, ﬁnes, and the term of penalty.
Moreover, there exist topological dependen-
cies among these subtasks. While most ex-
isting works only focus on a speciﬁc sub-
task of judgment prediction and ignore the de-
pendencies among subtasks, we formalize the
dependencies among subtasks as a Directed
Acyclic Graph (DAG) and propose a topo-
logical multi-task learning framework, TOP-
JUDGE, which incorporates multiple subtasks
and DAG dependencies into judgment predic-
tion. We conduct experiments on several real-
world large-scale datasets of criminal cases
in the civil law system. Experimental results
show that our model achieves consistent and
signiﬁcant improvements over baselines on all
judgment prediction tasks. The source code
can be obtained from https://github.
com/thunlp/TopJudge.

1

Introduction

Legal Judgment Prediction (LJP) aims to predict
the judgment results of legal cases according to the
fact descriptions. It is a critical technique for the
legal assistant system. On the one hand, LJP can
provide low-cost but high-quality legal consulting
services to the masses who are unfamiliar with le-
gal terminology and the complex judgment pro-
cedures. On the other hand, it can serve as the
handy reference for professionals (e.g., lawyers
and judges) and improve their work efﬁciency.

∗ Indicates equal contribution. The order is determined by

dice rolling.

† Corresponding author.

Figure 1: An illustration of the judicial logic of hu-
man judges in civil law system.

LJP has been studied for decades (Kort, 1957;
Ulmer, 1963; Nagel, 1963; Keown, 1980; Segal,
1984; Lauderdale and Clark, 2012; Ye et al., 2018;
Hu et al., 2018), and most existing works for-
malize LJP as a text classiﬁcation task. For ex-
ample, some works (Liu et al., 2004; Liu and
Hsieh, 2006) propose to extract shallow textual
features (e.g. characters, words, and phrases) for
charge prediction. Katz et al. (2017) predict the
US Supreme Court’s decisions based on efﬁcient
features from case proﬁles. Luo et al. (2017) pro-
pose an attention-based neural model for charge
prediction by incorporating the relevant law arti-
cles.

Despite these efforts in designing efﬁcient fea-
tures and employing advanced NLP techniques,
LJP is still confronted with two major challenges:
Multiple Subtasks in Legal Judgment: Prac-
tically, legal judgment usually consists of detailed
and complicated subclauses, such as charges, the
term of penalty, and ﬁnes. Speciﬁcally, for those
countries with the civil law system (e.g., China,
France, and Germany), the prediction of relevant
articles is also considered to be one of the funda-
mental subtasks, which will guide the prediction
for other subtasks. In other words, all these sub-
tasks compose the complete form of judgment pre-

diction. Nevertheless, existing works on LJP usu-
ally focus on one speciﬁc subtask of judgments,
which does not conform to the real scenarios. Al-
though some methods (Luo et al., 2017) are devel-
oped to predict law articles and charges at the same
time, their models are designed for a speciﬁc set of
subtasks which are hard to scale to other subtasks.
Topological Dependencies between Subtasks:
there exists a strict order
For human judges,
among the subtasks of legal judgment. As illus-
trated in Fig. 1, given the fact description of a spe-
ciﬁc case, a judge in the civil law system ﬁrst de-
cides which law articles are relevant to the sce-
nario, and then determines the charges according
to the instructions of relevant law articles. Based
on these results, the judge further conﬁrms the
term of penalty and ﬁnes. How to simulate the ju-
dicial logic of human judges and model the topo-
logical dependencies among legal subtasks will
deeply inﬂuence the creditability and interpretabil-
ity of judgment prediction.

As stated above, conventional works cannot
handle these two challenges due to both the lim-
itation of speciﬁc tasks and neglecting topological
dependencies. To address these issues, we propose
to model the multiple subtasks in judgment pre-
diction jointly under a novel multi-task learning
framework.

We model the topological dependencies among
these subtasks with a Directed Acyclic Graph
(DAG), which means all subtasks are arranged in
topological order. If the judgment of the j-th sub-
task tj depends on the output of the i-th subtask
ti, then ti appears earlier than tj in such order. It
is notable that such formulation provides an ex-
plicit explanation of dependency relations among
subtasks.

Accordingly, we introduce topological learning
for LJP and propose a uniﬁed framework, named
as TOPJUDGE. Speciﬁcally, given the encoded
representation of the fact description, TOPJUDGE
predicts the outputs of all the subtasks following
the topological order, and the output of a speciﬁc
subtask will be affected by all the subtasks it de-
pends on. In contrast with conventional multi-task
learning, our model takes the explicit topological
dependencies of LJP subtasks into consideration
and is ﬂexible to handle other LJP subtasks. More-
over, the topological order of legal dependencies
renders our model interpretable and reliable.

To verify the effectiveness and ﬂexibility of

TOPJUDGE, we conduct a series of experiments
on several real-world large-scale datasets. Exper-
imental results show that our model achieves sig-
niﬁcant and consistent improvements over state-
of-the-art models on all tasks and datasets. To
summarize, we make several noteworthy contribu-
tions as follows:

(1) We are the ﬁrst to explore and formalize the
multiple subtasks of legal judgment under a joint
learning framework. Moreover, we formulate the
dependencies among the subtasks of LJP as a form
of DAG and introduce this prior knowledge to en-
hance judgment prediction.

(2) We propose a novel judgment prediction
framework, TOPJUDGE, to unify multiple sub-
tasks and make judgment predictions through
topological learning. This model can handle any
form of DAG dependent subtasks, which has been
veriﬁed in the experiments.

(3) We carry out experiments on several large-
scale real-world datasets, and our model signiﬁ-
cantly and consistently outperforms all the base-
lines on all subtasks.

2 Related Work

2.1

Judgment Prediction

Employing automatic analysis techniques for legal
judgment has drawn attention from researchers in
the legal ﬁeld for decades. Early works usually
focus on analyzing existing legal cases in speciﬁc
scenarios with mathematical and statistical algo-
rithms (Kort, 1957; Ulmer, 1963; Nagel, 1963;
Keown, 1980; Segal, 1984; Lauderdale and Clark,
2012).

With the development of machine learning and
text mining techniques, more researchersformal-
ize this task under text classiﬁcation frameworks.
Most of these studies attempt to extract efﬁcient
features from text content (Liu and Hsieh, 2006;
Lin et al., 2012; Aletras et al., 2016; Sulea et al.,
2017) or case annotations (e.g., dates, terms, lo-
cations, and types) (Katz et al., 2017). However,
these conventional methods can only utilize shal-
low textual features and manually designed fac-
tors, both require massive human efforts and usu-
ally suffer from the generalization issue when ap-
plied to other scenarios.

Inspired by the success of neural networks on
NLP tasks (Kim, 2014; Baharudin et al., 2010;
Tang et al., 2015), researchers began to handle LJP
by incorporating neural models with legal knowl-

edge. For example, Luo et al. (2017) present an
attention-based neural network that jointly mod-
els charge prediction and relevant article extrac-
tion. Hu et al. (2018) incorporate 10 discrimina-
tive legal attributes to predict few-shot and con-
fusing charges. Nevertheless, these models are de-
signed for speciﬁc subtasks and thus non-trivial to
be extended to more subtasks of LJP with complex
dependencies. Besides, Ye et al. (2018) utilize a
Seq2Seq model to generate court views with fact
descriptions and predicted charges in Chinese civil
law.

2.2 Multi-task Learning

Multi-task learning (MTL) aims to exploit the
commonalities and differences across relevant
tasks by solving them at the same time.
It can
transfer useful information among various tasks
and has been applied to a wide range of ar-
eas, including NLP (Collobert and Weston, 2008),
speech recognition (Deng et al., 2013), and com-
puter vision (Girshick, 2015; Mao et al., 2017).

There have been numerous successful usages
of MTL in NLP tasks. Most works follow the
hard parameter sharing setting by sharing repre-
sentations or some encoding layers among rele-
vant tasks. For example, Collobert and Weston
(2008) use shared word embeddings in solving
part-of-speech tagging and semantic role labeling
tasks. Liu et al. (2015) share the encoding lay-
ers of input queries to address query classiﬁcation
and information retrieval. Dong et al. (2015) and
Luong et al. (2016) propose to share encoders or
decoders to improve one (many) to many neural
machine translation. Firat et al. (2016) propose to
share attention mechanism in multi-way, multilin-
gual machine translation. Besides hard parameter
sharing, soft parameter sharing is another com-
mon approach in MTL. It assumes that each task
owns its speciﬁc parameters and the distance be-
tween parameters in different tasks should be close
to each other. For example, Duong et al. (2015)
employ L2 distance for regularization, while Yang
and Hospedales (2017) use the trace norm. Liu
et al. (2016) introduce gates among task-speciﬁc
RNN layers to control the information ﬂow. Ruder
et al. (2017) introduce a model which can de-
cide the amount of sharing between different NLP
tasks. There are also some works focusing on in-
creasing tasks (Hashimoto et al., 2017) or handing
unlabeled data (Augenstein et al., 2018).

Figure 2: The framework of TOPJUDGE.

In this work, we introduce a topological learn-
ing framework TOPJUDGE to handle multiple sub-
tasks in LJP. Different to conventional MTL mod-
els which focus on how to share parameters among
relevant tasks, TOPJUDGE models the explicit de-
pendencies among these subtasks with scalable
DAG forms.

3 Method

In the following parts, we will ﬁrst give the essen-
tial deﬁnitions of LJP task. We then introduce the
DAG dependencies of the subtasks in LJP. And ﬁ-
nally, we describe the neural encoder for fact rep-
resentation and the judgment predictor for the sub-
tasks with DAG dependencies. The overall frame-
work of TOPJUDGE has been shown in Fig 2.

3.1 Problem Formulation

We will focus on the LJP tasks in civil law. Sup-
pose the fact description of a case is a word se-
quence x = {x1, x2, . . . , xn}, where n is the
length of x and each word xi comes from a ﬁxed
vocabulary W . Based on the fact description x,
the task of LJP T aims to predict judgment results
of applicable law articles, charges, term of penalty,
ﬁnes and so on. Formally, we assume T contains
|T | subtasks, i.e., T = {t1, t2, . . . , t|T |}, each of
which is a classiﬁcation task. For the i-th subtask
ti ∈ T , we aim to predict the corresponding result
yi ⊆ Yi, where Yi is a subtask-speciﬁc label set.
Take the subtask of charge prediction for example,
the corresponding label set should contain Theft,
Trafﬁc Violation, Intentional Homicide and so on.

3.2 DAG Dependencies of Subtasks

We assume that the dependencies among multiple
subtasks of LJP form a DAG. As a result, the task
list T should satisfy topological constraints. For-
mally, we use the notation ti (cid:1) tj to denote that

(a) Typical MTL form of DAG

(b) Sequential form of DAG

(c) General form of DAG

Figure 3: Three typical forms of DAG dependencies.

the j-th subtask depends on the i-th subtask, and
Dj = {ti | ti (cid:1) tj} to denote the dependency set.
The task list T can be ordered to satisfy the fol-
lowing constraint

i < j,

∀(i, j) ∈ {(i, j) | ti ∈ Dj}.

(1)

We demonstrate the ﬂexibility of our formula-
tion by describing two special cases: (1) As shown
in Fig. 3 (a), if no dependencies exist, i.e., Dj = ∅,
it corresponds to the typical MTL setting where
we simultaneously make predictions for all sub-
tasks. (2) As shown in Fig. 3 (b), if each task only
depends on its previous task, i.e., Dj = {tj−1}, it
forms a sequential learning process.

3.3 Neural Encoder for Fact Descriptions

We employ a fact encoder to generate the fact de-
scription’s vector representation as the input of
TOPJUDGE. In the following part, we brieﬂy in-
troduce an encoder based on Convolutional Neural
Networks (CNN) (Kim, 2014).

Taking a word sequence x as input, the CNN
encoder computes the text representation through
three layers, i.e., lookup layer, convolution layer
and pooling layer.

Lookup We ﬁrst convert each word xi in x into
its word embedding xi ∈ Rk, where k is the di-
mension of word embeddings. The word embed-
ding sequence is then represented as

ˆx = {x1, x2, . . . , xn}.

(2)

Convolution A convolution operation involves
a convolution matrix W ∈ Rm×(h×k), which is
applied to a sliding window of length h with num-
ber of ﬁlters m to produce a feature map by

ci = W · xi:i+h−1 + b,

(3)

where xi:i+h−1 is the concatenation of word em-
beddings within the i-th window and b ∈ Rm is
the bias vector. By applying convolution over each
window, we obtain c = {c1, . . . , cn−h+1}.

Pooling We apply per-dimension max-pooling
over c and obtain the ﬁnal fact representation d =
[d1, . . . , dm] by

dt = max(c1,t, . . . , cn−h+1,t), ∀t ∈ [1, m].

(4)

3.4

Judgment Predictor over DAG

Based on the DAG assumption, we obtain an or-
dered task list T ∗ = [t1, t2, . . . , t|T |]. For each
task tj ∈ T , we aim to predict its judgment result
yj based on the fact representation vector d and
the judgment results of its dependent tasks.

For prediction, we employ a speciﬁc LSTM cell
for each task and get the output of each task in
the topological order. More speciﬁcally, for each
task tj ∈ T , we obtain its ﬁnal judgment result
through three steps, i.e., cell initialization, task-
speciﬁc representation, and prediction.

Cell Initialization As stated above, the predic-
tion result of tj will be conditioned on the fact
representation d and the outputs of all dependent
tasks yk, ∀tk ∈ Dj. Hence, we have

(cid:105)

(cid:104)¯hj
¯cj

=

(cid:88)

(cid:16)

Wi,j

(cid:105)(cid:17)

(cid:104)hi
ci

+ bj

(5)

ti∈Dj

Here, hi and ci are the hidden state and memory
cell of ti. ¯hj and ¯cj are the initial hidden state and
memory cell of tj. Wi,j and bj are transformation
matrices and bias vectors speciﬁc to ti and tj.

Task-Speciﬁc Representation Taking the fact
representation d, the initial hidden state ¯hj, and
the initial memory cell ¯cj as inputs, we process

them with an LSTM cell (Hochreiter and Schmid-
huber, 1997).

We regard the ﬁnal hidden state hj as the task-
speciﬁc representation of task tj. The last cell
state cj is used to compose the initial hidden state
for the downstream tasks by Eq. 5

Prediction With the representation hj, we ap-
ply an afﬁne transformation followed by softmax
and obtain the ﬁnal prediction as

ˆyj = softmax (cid:0)Wp

j hj + bp

j

(cid:1) .

(6)

j are parameters speciﬁc to task

Here, Wp
tj.

j and bp

With the prediction result ˆyj, we minimize the

cross-entropy between ˆyj and yj as follows:

Lj(ˆyj, yj) = −

yj,k log(ˆyj,k).

(7)

|Yj |
(cid:88)

k=1

3.5 Training

We use cross-entropy loss for each subtask and
sum up losses to train TOPJUDGE:

L =

λjLj(ˆyj, yj),

(8)

|T |
(cid:88)

j=1

where λj is the weight factor for each subtask tj.
The DAG dependencies of subtasks ensure that
our model is differentiable and can be trained in an
end-to-end fashion. In practice, we set all weights
λj to 1, and employ Adam (Kingma and Ba, 2015)
for optimization. We also apply dropout (Srivas-
tava et al., 2014) on the fact representation to pre-
vent overﬁtting.

4 Experiments

To evaluate the proposed TOPJUDGE framework,
we conduct a series of experiments on LJP over
three large-scale datasets of criminal cases in
China. We select three representative judgment
prediction subtasks for comparison, including law
articles, charges, and the terms of penalty.

4.1 Dataset Construction

As there are no publicly available LJP datasets
in previous works, we collect and construct three
different LJP datasets, including CJO, PKU, and
CAIL. CJO consists of criminal cases published
by the Chinese government from China Judge-
ment Online1. PKU contains criminal cases pub-
lished by Peking University Law Online2. CAIL

1 http://wenshu.court.gov.cn/
2 http://www.pkulaw.com/

Datasets

CJO

PKU

CAIL

Cases
Law Articles
Charges
Term of Penalty

1, 007, 744
98
99
11

175, 744
68
64
11

113, 536
105
122
11

Table 1: The statistics of different datasets.

(Chinese AI and Law Challenge) is another crim-
inal case dataset for competition released by the
Supreme People’s Court of China3. The details of
CAIL can be found in Xiao et al. (2018).

For all datasets we mentioned above, as the doc-
uments are well-structured and human-annotated,
we can easily extract fact descriptions, applica-
ble law articles, charges and the terms of penalty
from each document using regular expressions.
We have manually checked a randomly sampled
set of cases, and extraction errors are negligible.

In real-world scenarios, there are some cases
with multiple defendants and multiple charges,
which will increase the complexity of judgment
prediction. As our model aims to explore the ef-
fectiveness of considering topological dependen-
cies between various subtasks, we ﬁlter out these
cases and leave them as our future work.

Meanwhile,

there are also some infrequent
charges and law articles, such as money launder-
ing, smuggling of nuclear materials and tax dodge.
We ﬁlter out these infrequent charges and law arti-
cles and only keep those with frequencies greater
than 100. For the term of penalty, we divide the
terms into non-overlapping intervals. We list de-
tailed statistics of these datasets in Table 1.

4.2 Baselines

For comparison, we employ the following text
classiﬁcation models and judgment prediction
methods as baselines:

TFIDF+SVM: We employ term-frequency in-
verse document frequency (TFIDF) (Salton and
Buckley, 1988) to extract word features and uti-
lize SVM (Suykens and Vandewalle, 1999) for text
classiﬁcation.

CNN: We employ CNN with multiple ﬁlter
widths (Kim, 2014) for fact encoding and classi-
ﬁcation.

Hierarchical LSTM (HLSTM): Tang et al.
(2015) employs hierarchical neural networks to
learn document representations in sentiment clas-

3 http://cail.cipsc.org.cn/index.html

Tasks

Law Articles

Charges

The Term of Penalty

Metrics

Acc. MP MR

F1

Acc. MP MR

F1

Acc. MP MR

F1

Single

Multi

TFIDF+SVM 82.4
92.5
91.4

CNN
HLSTM

Fact-Law Att.
PM
CNN-MTL
HLSTM-MTL

93.5
93.7
94.3
92.4

94.4

45.5
46.9
38.6

50.9
51.9
53.0
45.5

53.9

26.7
38.4
37.3

45.6
44.1
46.0
41.4

47.3

30.2
40.0
36.9

45.9
44.9
46.9
41.0

48.2

82.2
92.3
91.8

93.4
93.6
94.1
92.3

94.9

47.4
41.2
37.8

47.2
45.5
48.5
41.9

53.9

27.9
32.3
36.0

41.4
39.1
41.7
36.6

48.2

31.3
33.7
35.2

41.5
39.3
42.5
35.9

49.1

48.5
57.4
56.1

56.3
58.2
58.7
54.9

58.8

36.0
35.6
22.5

31.3
38.2
39.9
30.6

40.2

16.7
22.2
25.0

26.4
24.9
28.8
26.6

32.9

16.5
22.7
23.3

26.7
26.8
29.4
26.4

32.8

Ours

TOPJUDGE

Table 2: Judgment prediction results on CJO.

Tasks

Law Articles

Charges

The Term of Penalty

Metrics

Acc. MP MR

F1

Acc. MP MR

F1

Acc. MP MR

F1

Single

Multi

TFIDF+SVM 80.9
93.1
91.7

CNN
HLSTM

Fact-Law Att.
PM
CNN-MTL
HLSTM-MTL

93.9
94.4
95.0
93.9

95.4

51.3
64.3
54.4

68.1
69.6
73.8
71.2

76.4

32.6
52.6
53.4

63.4
61.0
64.9
64.6

67.6

36.4
54.3
50.9

63.5
62.2
66.0
65.1

68.4

81.0
93.3
91.9

94.2
94.3
95.0
93.8

95.6

53.4
61.9
52.5

65.8
65.1
70.7
67.8

75.9

35.4
49.3
48.9

58.5
56.2
60.6
60.0

69.6

38.7
51.1
47.3

58.7
57.2
61.7
60.7

70.9

45.3
57.6
54.3

55.7
58.2
58.4
55.4

57.8

30.4
24.1
20.6

27.7
36.2
36.0
31.3

38.9

17.4
23.1
21.7

27.4
26.4
28.7
26.2

32.1

17.2
23.3
19.0

26.5
27.1
28.9
25.7

31.8

Ours

TOPJUDGE

Table 3: Judgment prediction results on PKU.

siﬁcation. Based on this work, we employ an
LSTM for sentence representations and another
one to obtain the representation of complete fact
descriptions.

Fact-Law Attention Model: Luo et al. (2017)
proposes a neural charge prediction model by cap-
turing the interaction between fact descriptions
and applicable laws with attention mechanism.

Pipeline Model (PM): To demonstrate the
advantage of TOPJUDGE on modeling subtasks
jointly, we also implement a pipelined method for
comparison. Here, we train 3 separate CNN classi-
ﬁers for law articles, charges, and term of penalty.
For each subtask, the input is the concatenation
of the fact representation and the embeddings for
predicted labels of previous subtasks.

Besides, we compare our model with conven-
tional MTL methods that do not consider the de-
pendencies among subtasks as in Fig. 3 (a). These
methods are denoted as CNN-MTL and HLSTM-
MTL, where we implement the fact encoder as in
Fig. 2 using CNN or HLSTM respectively.

4.3 Experimental Settings

As the case documents are written in Chinese
with no space between words, we employ THU-
LAC (Sun et al., 2016) for word segmentation. Af-
terward, we adopt the Skip-Gram model (Mikolov
et al., 2013) to pre-train word embeddings on these

case documents, with embedding size set to 200
and frequency threshold set to 25.

For all models, we set

the fact representa-
tion and task-speciﬁc representation size to 256.
Meanwhile, we set the maximum sentence length
to 128 words and maximum document length to
32 sentences.

For training, the learning rate of Adam opti-
mizer is 10−3, and the dropout probability is 0.5.
We also set the batch size to 128 for all models.
We train every model for 16 epochs, and evaluate
the ﬁnal model on the testing set.

We employ accuracy (Acc.), macro-precision
(MP), macro-recall (MR) and macro-F1 (F1)
the macro-
as evaluation metrics.
precision/recall/F1 are calculated by averaging the
precision/recall/F1 of each category.

Here,

4.4 Results and Analysis

We evaluate the performance on three LJP sub-
including law articles (denoted as t1),
tasks,
charges (denoted as t2), and the terms of penalty
(denoted as t3). Experimental results are shown in
Tables 2, 3, and 4. Note that, we implement TOP-
JUDGE with the dependency relationship in Fig. 3
(c), i.e.,

D1 = φ, D2 = {t1}, D3 = {t1, t2}.

(9)

Tasks

Law Articles

Charges

The Term of Penalty

Metrics

Acc. MP MR

F1

Acc. MP MR

F1

Acc. MP MR

F1

Single

Multi

TFIDF+SVM 60.1
81.4
-

CNN
HLSTM

Fact-Law Att.
PM
CNN-MTL
HLSTM-MTL

70.9
84.7
84.5
-

86.3

54.9
74.4
-

64.8
80.7
80.0
-

81.9

45.3
64.1
-

63.6
68.6
68.1
-

71.1

46.3
65.7
-

59.1
70.8
70.3
-

73.4

59.2
80.7
-

68.7
83.6
83.4
-

85.7

53.9
77.3
-

66.1
81.6
81.6
-

83.4

45.0
65.5
-

65.3
70.0
69.1
-

76.0

45.7
67.2
-

60.1
72.1
71.6
-

78.3

28.4
28.8
-

36.5
40.0
39.5
-

38.3

22.9
34.7
-

29.9
37.4
37.2
-

36.1

20.0
27.8
-

27.6
32.0
32.3
-

33.1

18.1
28.6
-

27.1
31.6
31.3
-

32.1

Ours

TOPJUDGE

Table 4: Judgment prediction results on CAIL. Note that, “-” means the model does not converge within
128 epochs.

This means that the prediction of charges depends
on law articles, and the prediction of term of
penalty depends on both law articles and charges.
Such explicit dependencies conform to the judi-
cial logic of human judges, which will be veriﬁed
in later sections. These results show that:

(1) The proposed TOPJUDGE model outper-
forms other baselines signiﬁcantly on most sub-
tasks and datasets. It demonstrates the effective-
ness and robustness of our proposed framework.

(2) Compared with conventional single-task
models, e.g., CNN and HLSTM, MTL methods
take advantage of the correlation among relevant
subtasks and thus achieve promising improve-
It indicates the importance of modeling
ments.
LJP subtasks jointly.

(3) Moreover, TOPJUDGE signiﬁcantly outper-
forms typical MTL models, especially on the pre-
diction of charges and the terms of penalty. It veri-
ﬁes the rationality and importance of modeling de-
pendencies over LJP subtasks with DAG.

4.5 Ablation Analysis

Tasks

t1

t2

t3

Metrics

Acc.

F1

Acc.

F1

Acc.

F1

TOPJUDGE
- t3 (cid:1) t1
- t2 (cid:1) t1
φ

95.4
95.2
94.8
94.7

68.4
67.7
64.7
64.4

95.6
95.4
94.9
94.9

70.9
70.3
60.2
60.1

57.8
57.4
57.0
57.8

31.8
31.2
31.6
27.6

Table 5: Ablation analysis on PKU.

To further illustrate the signiﬁcance of legal de-
pendencies and explore how the DAG dependen-
cies inﬂuence the performance, we evaluate the
performance of TOPJUDGE under various DAG
architectures. Using Eq. 9 as the full dependen-
cies, we remove the dependency of t3 (cid:1) t1 (law
articles and term of penalty, corresponding to the
sequential form in Fig. 3), t2 (cid:1) t1 (law articles and

charges), and all dependencies respectively. Re-
sults are summarized in Table 5.

We observe that the performance of TOPJUDGE
decreases on all tasks after removing either depen-
dency. More speciﬁcally, when we dropped de-
pendencies t3 (cid:1) t1 and t2 (cid:1) t1 respectively, sig-
niﬁcant decreases are observed for t3 and t2 corre-
spondingly. This demonstrates that incorporating
dependencies is beneﬁcial for relevant subtasks,
verifying its guiding role in the civil law system.

Meanwhile, we note that there are two main
differences between TOPJUDGE and traditional
multi-task models, namely the Cell Initialization
and the Task-Speciﬁc Representation. We can
see that if we eliminate Cell Initialization from
TOPJUDGE,
the dependencies will not be rep-
resented in the model and it will become sim-
ilar to CNN-MTL. If we eliminate the Task-
Speciﬁc Representation from TOPJUDGE, TOP-
JUDGE will become the same as the Pipeline
Model. In a word, the main improvement of our
models comes from the combination.

4.6 Case Study

We give some intuitive examples to demonstrate
the signiﬁcance of TOPJUDGE on LJP subtasks.

As shown in Table 6, case 1 is about negligently
causing a ﬁre. The fact description of this case
states “The defendant pulled up weeds in the ﬁelds
and piled them up in haphazard stacks. Afterward,
he lighted them up and triggered the forest ﬁres...”
TOPJUDGE predicts all judgments correctly, while
CNN-MTL fails to predict the charge and term of
penalty. Moreover, CNN-MTL obtains conﬂicting
judgments, i.e., “crime of arson” and “1-2 years”,
due to its neglecting of dependencies of these sub-
tasks. According to the legal provisions of law ar-
ticle 115, the crime of arson should be sentenced
to more than 10 years.

Methods

Law Charge

Term
(months)

12-24(×)

CNN-MTL

115 Arson(×)

TOPJUDGE

115 Negligently Caus-
ing a Fire

0-6

CNN-MTL

293

Intentional Dam-
age to Property(×)

12-24(×)

TOPJUDGE

293 Affray

0-6

Table 6: Example cases and their prediction results.

Case 2 in Table 6 is another evidence of the in-
sufﬁciency of conventional MTL on LJP. This case
is about picking quarrels and provoking troubles.
Both CNN-MTL and TOPJUDGE succeed to pre-
law article 293
dict the relevant law articles (i.e.,
of the crime of affray). However, CNN-MTL is
confused between “crime of affray” and “crime of
intentional destruction or damage of properties”,
two charges similar to each other. Conversely,
TOPJUDGE can utilize the prediction result of law
articles and consequently prevent this confusion.

To summarize, modeling the explicit dependen-
cies among various subtasks can remarkably help
the LJP model address the issue of predicting con-
ﬂicting results.

4.7 Error Analysis

Prediction errors induced by our proposed model
can be traced down into the following causes.

Data Imbalance.

For the subtasks of law
articles and charges, our model achieves more
than 90% on accuracy, while only about 60% for
macro-F1. This issue is much more severe on the
subtask of the term of penalty, which our model
yields a poor performance of only 30% macro-F1.
The bad performance is mainly due to the imbal-
ance of category labels, e.g., there are only a few
training instances where the term is “life imprison-
ment or death penalty”. Most judgment prediction
approaches perform poorly (especially for Recall)
on these labels as listed in Fig. 4. Instance weight-
ing schemes can be introduced to address this is-
sue in future works.

Incomplete Information. Following existing
LJP works, we predict the ﬁnal judgment accord-
ing to the fact descriptions, which is incomplete as
compared to the whole materials relevant to this
In Chinese Law, there are certain circum-
case.
stances under which the sentence can be short-
ened. For example, minors usually receive a light-

Figure 4: The confusion matrix in the subtask
of predicting the term of penalty on the PKU
dataset. The rows denote the ground truth while
the columns denote the prediction results.

ened penalty, and those guilty of misdemeanors
are allowed for a secured pending trial while pay-
ing a security deposit. However, such informa-
tion is not included in the fact descriptions. The
lack of such information also raises difﬁculties for
judgment prediction, especially for the prediction
of the term of penalty. In Fig. 4, we can see that
the highest error rate comes from the cases with a
short term of penalty. Our model fails to distin-
guish the cases with no penalty and those with 0-6
months term of imprisonment.

5 Conclusion

In this paper, we focus on the task of legal judg-
ment prediction (LJP) and address multiple sub-
tasks of judgment predication with a topological
learning framework. To be speciﬁc, we formalize
the explicit dependencies over these subtasks in a
DAG form, and propose a novel MTL framework,
TOPJUDGE, by integrating the DAG dependen-
cies. Experimental results on three LJP subtasks
and three different datasets show that our TOP-
JUDGE outperforms all single-task baselines and
conventional MTL models consistently and signif-
icantly.

In the future, we will seek to explore the follow-
ing directions: (1) We will explore more LJP sub-
tasks and more scenarios of cases such as multiple

defendants and charges to investigate the effective-
ness of TOPJUDGE. (2) We will explore how to
incorporate into LJP the temporal factors, which
are not considered in this work.

6 Acknowledgements

This work is supported by the National Nat-
ural Science Foundation of China (NSFC No.
61572273, 61772302) and the research fund of
Powerlaw Inc.
for AI+Law Technology. This
work is also funded by China Association for Sci-
ence and Technology (2016QNRC001). Tu is also
supported by China Postdoctoral Innovative Talent
Support Programme.

References

Nikolaos Aletras, Dimitrios Tsarapatsanis, Daniel
Preotiuc-Pietro, and Vasileios Lampos. 2016. Pre-
dicting judicial decisions of the european court of
human rights: A natural language processing per-
spective. PeerJ Computer Science, 2.

Isabelle Augenstein, Sebastian Ruder, and Anders
Søgaard. 2018. Multi-task learning of pairwise
sequence classiﬁcation tasks over disparate label
spaces. In Proceedings of NAACL.

Baharum Baharudin, Lam Hong Lee, and Khairullah
Khan. 2010. A review of machine learning algo-
rithms for text-documents classiﬁcation. Journal of
Advances in Information Technology, 1(1):4–20.

Ronan Collobert and Jason Weston. 2008. A uniﬁed
architecture for natural language processing: Deep
In Pro-
neural networks with multitask learning.
ceedings of ICML, pages 160–167.

Li Deng, Geoffrey Hinton, and Brian Kingsbury. 2013.
New types of deep neural network learning for
speech recognition and related applications: An
overview. In Proceedings of ICASSP, pages 8599–
8603.

Daxiang Dong, Hua Wu, Wei He, Dianhai Yu, and
Haifeng Wang. 2015. Multi-task learning for mul-
tiple language translation. In Proceedings of ACL,
volume 1, pages 1723–1732.

Long Duong, Trevor Cohn, Steven Bird, and Paul
Cook. 2015. Low resource dependency parsing:
Cross-lingual parameter sharing in a neural network
In Proceedings of ACL, volume 2, pages
parser.
845–850.

Orhan Firat, Kyunghyun Cho, and Yoshua Bengio.
2016. Multi-way, multilingual neural machine
translation with a shared attention mechanism.
In
Proceedings of NAACL, pages 866–875.

Ross Girshick. 2015. Fast r-cnn.

In Proceedings of

ICCV, pages 1440–1448.

Kazuma Hashimoto, Yoshimasa Tsuruoka, Richard
Socher, et al. 2017. A joint many-task model: Grow-
ing a neural network for multiple nlp tasks. In Pro-
ceedings of EMNLP, pages 1923–1933.

Sepp Hochreiter and Jurgen Schmidhuber. 1997.
Neural computation,

Long short-term memory.
9(8):1735–1780.

Zikun Hu, Xiang Li, Cunchao Tu, Zhiyuan Liu, and
Maosong Sun. 2018. Few-shot charge prediction
with discriminative legal attributes. In Proceedings
of COLING.

Daniel Martin Katz, Michael J Bommarito II, and Josh
Blackman. 2017. A general approach for predict-
ing the behavior of the supreme court of the united
states. Plos one, 12(4).

R Keown. 1980. Mathematical models for legal pre-

diction. Computer/LJ, 2:829.

Yoon Kim. 2014. Convolutional neural networks for
sentence classiﬁcation. In Proceedings of EMNLP.

Diederik Kingma and Jimmy Ba. 2015. Adam: A
method for stochastic optimization. In Proceedings
of ICLR.

Fred Kort. 1957. Predicting supreme court decisions
mathematically: A quantitative analysis of the ”right
to counsel” cases. American Political Science Re-
view, 51(1):1–12.

Benjamin E Lauderdale and Tom S Clark. 2012. The
supreme court’s many median justices. American
Political Science Review, 106(4):847–866.

Wanchen Lin, Tsung Ting Kuo, and Tung Jia Chang.
2012. Exploiting machine learning models for chi-
nese legal documents labeling, case classiﬁcation,
and sentencing prediction. In Processdings of RO-
CLING, page 140.

Chaolin Liu, Cheng Tsung Chang, and Jim How Ho.
2004. Case instance generation and reﬁnement
for case-based criminal summary judgments in chi-
nese. Journal of Informationence & Engineering,
20(4):783–800.

Chaolin Liu and Chwen Dar Hsieh. 2006. Exploring
phrase-based classiﬁcation of judicial documents for
criminal charges in chinese. In Proceedings of IS-
MIS, pages 681–690.

Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2016.
Recurrent neural network for text classiﬁcation with
multi-task learning. In Proceedings of IJCAI.

Xiaodong Liu, Jianfeng Gao, Xiaodong He, Li Deng,
Kevin Duh, and Ye-Yi Wang. 2015. Representation
learning using multi-task deep neural networks for
semantic classiﬁcation and information retrieval. In
Proceedings of NAACL, pages 912–921.

Chaojun Xiao, Haoxi Zhong, Zhipeng Guo, Cunchao
Tu, Zhiyuan Liu, Maosong Sun, Yansong Feng,
Xianpei Han, Zhen Hu, Heng Wang, et al. 2018.
Cail2018: A large-scale legal dataset for judgment
prediction. arXiv preprint arXiv:1807.02478.

Yongxin Yang and Timothy Hospedales. 2017. Deep
multi-task representation learning: A tensor factori-
sation approach. In Proceedings of ICLR.

Hai Ye, Xin Jiang, Zhunchen Luo, and Wenhan Chao.
2018. Interpretable charge predictions for criminal
cases: Learning to generate court views from fact
descriptions. In Proceedings of NAACL.

Bingfeng Luo, Yansong Feng, Jianbo Xu, Xiang
Zhang, and Dongyan Zhao. 2017. Learning to pre-
dict charges for criminal cases with legal basis. In
Proceedings of EMNLP.

Minh-Thang Luong, Quoc V Le, Ilya Sutskever, Oriol
Vinyals, and Lukasz Kaiser. 2016. Multi-task se-
In Proceedings of
quence to sequence learning.
ICLR.

Jiayuan Mao, Tete Xiao, Yuning Jiang, and Zhimin
Cao. 2017. What can help pedestrian detection? In
Proceedings of CVPR, pages 3127–3136.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Proceedings of NIPS, pages 3111–3119.

Stuart S Nagel. 1963. Applying correlation analysis to

case prediction. Texas Law Review, 42:1006.

Sebastian Ruder, Joachim Bingel, Isabelle Augen-
stein, and Anders Søgaard. 2017. Learning what to
share between loosely related tasks. arXiv preprint
arXiv:1705.08142.

Gerard Salton and Christopher Buckley. 1988. Term-
weighting approaches in automatic text retrieval. In-
formation processing & management, 24(5):513–
523.

Jeffrey A Segal. 1984. Predicting supreme court cases
probabilistically: The search and seizure cases,
American Political Science Review,
1962-1981.
78(4):891–900.

Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: a simple way to prevent neural networks
from overﬁtting. JMLR, 15(1):1929–1958.

Octavia Maria Sulea, Marcos Zampieri, Mihaela Vela,
and Josef Van Genabith. 2017. Exploring the use of
text classi cation in the legal domain. In Proceedings
of ASAIL workshop.

Maosong Sun, Xinxiong Chen, Kaixu Zhang, Zhipeng
Guo, and Zhiyuan Liu. 2016. Thulac: An efﬁcient
lexical analyzer for chinese.

Johan AK Suykens and Joos Vandewalle. 1999. Least
squares support vector machine classiﬁers. Neural
processing letters, 9(3):293–300.

Duyu Tang, Bing Qin, and Ting Liu. 2015. Document
modeling with gated recurrent neural network for
sentiment classiﬁcation. In Proceedings of EMNLP,
pages 1422–1432.

S Sidney Ulmer. 1963. Quantitative analysis of judi-
cial processes: Some practical and theoretical appli-
cations. Law and Contemporary Problems, 28:164.

Legal Judgment Prediction via Topological Learning

Haoxi Zhong∗, Zhipeng Guo∗, Cunchao Tu, Chaojun Xiao, Zhiyuan Liu†, Maosong Sun
Department of Computer Science and Technology
State Key Lab on Intelligent Technology and Systems
Institute for Artiﬁcial Intelligence, Tsinghua University, Beijing, China
{zhonghx18,gzp17,xiaocj16}@mails.tsinghua.edu.cn, tucunchao@gmail.com
{lzy,sms}@tsinghua.edu.cn

Abstract

Legal Judgment Prediction (LJP) aims to pre-
dict the judgment result based on the facts of
a case and becomes a promising application
of artiﬁcial intelligence techniques in the le-
gal ﬁeld. In real-world scenarios, legal judg-
ment usually consists of multiple subtasks,
such as the decisions of applicable law arti-
cles, charges, ﬁnes, and the term of penalty.
Moreover, there exist topological dependen-
cies among these subtasks. While most ex-
isting works only focus on a speciﬁc sub-
task of judgment prediction and ignore the de-
pendencies among subtasks, we formalize the
dependencies among subtasks as a Directed
Acyclic Graph (DAG) and propose a topo-
logical multi-task learning framework, TOP-
JUDGE, which incorporates multiple subtasks
and DAG dependencies into judgment predic-
tion. We conduct experiments on several real-
world large-scale datasets of criminal cases
in the civil law system. Experimental results
show that our model achieves consistent and
signiﬁcant improvements over baselines on all
judgment prediction tasks. The source code
can be obtained from https://github.
com/thunlp/TopJudge.

1

Introduction

Legal Judgment Prediction (LJP) aims to predict
the judgment results of legal cases according to the
fact descriptions. It is a critical technique for the
legal assistant system. On the one hand, LJP can
provide low-cost but high-quality legal consulting
services to the masses who are unfamiliar with le-
gal terminology and the complex judgment pro-
cedures. On the other hand, it can serve as the
handy reference for professionals (e.g., lawyers
and judges) and improve their work efﬁciency.

∗ Indicates equal contribution. The order is determined by

dice rolling.

† Corresponding author.

Figure 1: An illustration of the judicial logic of hu-
man judges in civil law system.

LJP has been studied for decades (Kort, 1957;
Ulmer, 1963; Nagel, 1963; Keown, 1980; Segal,
1984; Lauderdale and Clark, 2012; Ye et al., 2018;
Hu et al., 2018), and most existing works for-
malize LJP as a text classiﬁcation task. For ex-
ample, some works (Liu et al., 2004; Liu and
Hsieh, 2006) propose to extract shallow textual
features (e.g. characters, words, and phrases) for
charge prediction. Katz et al. (2017) predict the
US Supreme Court’s decisions based on efﬁcient
features from case proﬁles. Luo et al. (2017) pro-
pose an attention-based neural model for charge
prediction by incorporating the relevant law arti-
cles.

Despite these efforts in designing efﬁcient fea-
tures and employing advanced NLP techniques,
LJP is still confronted with two major challenges:
Multiple Subtasks in Legal Judgment: Prac-
tically, legal judgment usually consists of detailed
and complicated subclauses, such as charges, the
term of penalty, and ﬁnes. Speciﬁcally, for those
countries with the civil law system (e.g., China,
France, and Germany), the prediction of relevant
articles is also considered to be one of the funda-
mental subtasks, which will guide the prediction
for other subtasks. In other words, all these sub-
tasks compose the complete form of judgment pre-

diction. Nevertheless, existing works on LJP usu-
ally focus on one speciﬁc subtask of judgments,
which does not conform to the real scenarios. Al-
though some methods (Luo et al., 2017) are devel-
oped to predict law articles and charges at the same
time, their models are designed for a speciﬁc set of
subtasks which are hard to scale to other subtasks.
Topological Dependencies between Subtasks:
there exists a strict order
For human judges,
among the subtasks of legal judgment. As illus-
trated in Fig. 1, given the fact description of a spe-
ciﬁc case, a judge in the civil law system ﬁrst de-
cides which law articles are relevant to the sce-
nario, and then determines the charges according
to the instructions of relevant law articles. Based
on these results, the judge further conﬁrms the
term of penalty and ﬁnes. How to simulate the ju-
dicial logic of human judges and model the topo-
logical dependencies among legal subtasks will
deeply inﬂuence the creditability and interpretabil-
ity of judgment prediction.

As stated above, conventional works cannot
handle these two challenges due to both the lim-
itation of speciﬁc tasks and neglecting topological
dependencies. To address these issues, we propose
to model the multiple subtasks in judgment pre-
diction jointly under a novel multi-task learning
framework.

We model the topological dependencies among
these subtasks with a Directed Acyclic Graph
(DAG), which means all subtasks are arranged in
topological order. If the judgment of the j-th sub-
task tj depends on the output of the i-th subtask
ti, then ti appears earlier than tj in such order. It
is notable that such formulation provides an ex-
plicit explanation of dependency relations among
subtasks.

Accordingly, we introduce topological learning
for LJP and propose a uniﬁed framework, named
as TOPJUDGE. Speciﬁcally, given the encoded
representation of the fact description, TOPJUDGE
predicts the outputs of all the subtasks following
the topological order, and the output of a speciﬁc
subtask will be affected by all the subtasks it de-
pends on. In contrast with conventional multi-task
learning, our model takes the explicit topological
dependencies of LJP subtasks into consideration
and is ﬂexible to handle other LJP subtasks. More-
over, the topological order of legal dependencies
renders our model interpretable and reliable.

To verify the effectiveness and ﬂexibility of

TOPJUDGE, we conduct a series of experiments
on several real-world large-scale datasets. Exper-
imental results show that our model achieves sig-
niﬁcant and consistent improvements over state-
of-the-art models on all tasks and datasets. To
summarize, we make several noteworthy contribu-
tions as follows:

(1) We are the ﬁrst to explore and formalize the
multiple subtasks of legal judgment under a joint
learning framework. Moreover, we formulate the
dependencies among the subtasks of LJP as a form
of DAG and introduce this prior knowledge to en-
hance judgment prediction.

(2) We propose a novel judgment prediction
framework, TOPJUDGE, to unify multiple sub-
tasks and make judgment predictions through
topological learning. This model can handle any
form of DAG dependent subtasks, which has been
veriﬁed in the experiments.

(3) We carry out experiments on several large-
scale real-world datasets, and our model signiﬁ-
cantly and consistently outperforms all the base-
lines on all subtasks.

2 Related Work

2.1

Judgment Prediction

Employing automatic analysis techniques for legal
judgment has drawn attention from researchers in
the legal ﬁeld for decades. Early works usually
focus on analyzing existing legal cases in speciﬁc
scenarios with mathematical and statistical algo-
rithms (Kort, 1957; Ulmer, 1963; Nagel, 1963;
Keown, 1980; Segal, 1984; Lauderdale and Clark,
2012).

With the development of machine learning and
text mining techniques, more researchersformal-
ize this task under text classiﬁcation frameworks.
Most of these studies attempt to extract efﬁcient
features from text content (Liu and Hsieh, 2006;
Lin et al., 2012; Aletras et al., 2016; Sulea et al.,
2017) or case annotations (e.g., dates, terms, lo-
cations, and types) (Katz et al., 2017). However,
these conventional methods can only utilize shal-
low textual features and manually designed fac-
tors, both require massive human efforts and usu-
ally suffer from the generalization issue when ap-
plied to other scenarios.

Inspired by the success of neural networks on
NLP tasks (Kim, 2014; Baharudin et al., 2010;
Tang et al., 2015), researchers began to handle LJP
by incorporating neural models with legal knowl-

edge. For example, Luo et al. (2017) present an
attention-based neural network that jointly mod-
els charge prediction and relevant article extrac-
tion. Hu et al. (2018) incorporate 10 discrimina-
tive legal attributes to predict few-shot and con-
fusing charges. Nevertheless, these models are de-
signed for speciﬁc subtasks and thus non-trivial to
be extended to more subtasks of LJP with complex
dependencies. Besides, Ye et al. (2018) utilize a
Seq2Seq model to generate court views with fact
descriptions and predicted charges in Chinese civil
law.

2.2 Multi-task Learning

Multi-task learning (MTL) aims to exploit the
commonalities and differences across relevant
tasks by solving them at the same time.
It can
transfer useful information among various tasks
and has been applied to a wide range of ar-
eas, including NLP (Collobert and Weston, 2008),
speech recognition (Deng et al., 2013), and com-
puter vision (Girshick, 2015; Mao et al., 2017).

There have been numerous successful usages
of MTL in NLP tasks. Most works follow the
hard parameter sharing setting by sharing repre-
sentations or some encoding layers among rele-
vant tasks. For example, Collobert and Weston
(2008) use shared word embeddings in solving
part-of-speech tagging and semantic role labeling
tasks. Liu et al. (2015) share the encoding lay-
ers of input queries to address query classiﬁcation
and information retrieval. Dong et al. (2015) and
Luong et al. (2016) propose to share encoders or
decoders to improve one (many) to many neural
machine translation. Firat et al. (2016) propose to
share attention mechanism in multi-way, multilin-
gual machine translation. Besides hard parameter
sharing, soft parameter sharing is another com-
mon approach in MTL. It assumes that each task
owns its speciﬁc parameters and the distance be-
tween parameters in different tasks should be close
to each other. For example, Duong et al. (2015)
employ L2 distance for regularization, while Yang
and Hospedales (2017) use the trace norm. Liu
et al. (2016) introduce gates among task-speciﬁc
RNN layers to control the information ﬂow. Ruder
et al. (2017) introduce a model which can de-
cide the amount of sharing between different NLP
tasks. There are also some works focusing on in-
creasing tasks (Hashimoto et al., 2017) or handing
unlabeled data (Augenstein et al., 2018).

Figure 2: The framework of TOPJUDGE.

In this work, we introduce a topological learn-
ing framework TOPJUDGE to handle multiple sub-
tasks in LJP. Different to conventional MTL mod-
els which focus on how to share parameters among
relevant tasks, TOPJUDGE models the explicit de-
pendencies among these subtasks with scalable
DAG forms.

3 Method

In the following parts, we will ﬁrst give the essen-
tial deﬁnitions of LJP task. We then introduce the
DAG dependencies of the subtasks in LJP. And ﬁ-
nally, we describe the neural encoder for fact rep-
resentation and the judgment predictor for the sub-
tasks with DAG dependencies. The overall frame-
work of TOPJUDGE has been shown in Fig 2.

3.1 Problem Formulation

We will focus on the LJP tasks in civil law. Sup-
pose the fact description of a case is a word se-
quence x = {x1, x2, . . . , xn}, where n is the
length of x and each word xi comes from a ﬁxed
vocabulary W . Based on the fact description x,
the task of LJP T aims to predict judgment results
of applicable law articles, charges, term of penalty,
ﬁnes and so on. Formally, we assume T contains
|T | subtasks, i.e., T = {t1, t2, . . . , t|T |}, each of
which is a classiﬁcation task. For the i-th subtask
ti ∈ T , we aim to predict the corresponding result
yi ⊆ Yi, where Yi is a subtask-speciﬁc label set.
Take the subtask of charge prediction for example,
the corresponding label set should contain Theft,
Trafﬁc Violation, Intentional Homicide and so on.

3.2 DAG Dependencies of Subtasks

We assume that the dependencies among multiple
subtasks of LJP form a DAG. As a result, the task
list T should satisfy topological constraints. For-
mally, we use the notation ti (cid:1) tj to denote that

(a) Typical MTL form of DAG

(b) Sequential form of DAG

(c) General form of DAG

Figure 3: Three typical forms of DAG dependencies.

the j-th subtask depends on the i-th subtask, and
Dj = {ti | ti (cid:1) tj} to denote the dependency set.
The task list T can be ordered to satisfy the fol-
lowing constraint

i < j,

∀(i, j) ∈ {(i, j) | ti ∈ Dj}.

(1)

We demonstrate the ﬂexibility of our formula-
tion by describing two special cases: (1) As shown
in Fig. 3 (a), if no dependencies exist, i.e., Dj = ∅,
it corresponds to the typical MTL setting where
we simultaneously make predictions for all sub-
tasks. (2) As shown in Fig. 3 (b), if each task only
depends on its previous task, i.e., Dj = {tj−1}, it
forms a sequential learning process.

3.3 Neural Encoder for Fact Descriptions

We employ a fact encoder to generate the fact de-
scription’s vector representation as the input of
TOPJUDGE. In the following part, we brieﬂy in-
troduce an encoder based on Convolutional Neural
Networks (CNN) (Kim, 2014).

Taking a word sequence x as input, the CNN
encoder computes the text representation through
three layers, i.e., lookup layer, convolution layer
and pooling layer.

Lookup We ﬁrst convert each word xi in x into
its word embedding xi ∈ Rk, where k is the di-
mension of word embeddings. The word embed-
ding sequence is then represented as

ˆx = {x1, x2, . . . , xn}.

(2)

Convolution A convolution operation involves
a convolution matrix W ∈ Rm×(h×k), which is
applied to a sliding window of length h with num-
ber of ﬁlters m to produce a feature map by

ci = W · xi:i+h−1 + b,

(3)

where xi:i+h−1 is the concatenation of word em-
beddings within the i-th window and b ∈ Rm is
the bias vector. By applying convolution over each
window, we obtain c = {c1, . . . , cn−h+1}.

Pooling We apply per-dimension max-pooling
over c and obtain the ﬁnal fact representation d =
[d1, . . . , dm] by

dt = max(c1,t, . . . , cn−h+1,t), ∀t ∈ [1, m].

(4)

3.4

Judgment Predictor over DAG

Based on the DAG assumption, we obtain an or-
dered task list T ∗ = [t1, t2, . . . , t|T |]. For each
task tj ∈ T , we aim to predict its judgment result
yj based on the fact representation vector d and
the judgment results of its dependent tasks.

For prediction, we employ a speciﬁc LSTM cell
for each task and get the output of each task in
the topological order. More speciﬁcally, for each
task tj ∈ T , we obtain its ﬁnal judgment result
through three steps, i.e., cell initialization, task-
speciﬁc representation, and prediction.

Cell Initialization As stated above, the predic-
tion result of tj will be conditioned on the fact
representation d and the outputs of all dependent
tasks yk, ∀tk ∈ Dj. Hence, we have

(cid:105)

(cid:104)¯hj
¯cj

=

(cid:88)

(cid:16)

Wi,j

(cid:105)(cid:17)

(cid:104)hi
ci

+ bj

(5)

ti∈Dj

Here, hi and ci are the hidden state and memory
cell of ti. ¯hj and ¯cj are the initial hidden state and
memory cell of tj. Wi,j and bj are transformation
matrices and bias vectors speciﬁc to ti and tj.

Task-Speciﬁc Representation Taking the fact
representation d, the initial hidden state ¯hj, and
the initial memory cell ¯cj as inputs, we process

them with an LSTM cell (Hochreiter and Schmid-
huber, 1997).

We regard the ﬁnal hidden state hj as the task-
speciﬁc representation of task tj. The last cell
state cj is used to compose the initial hidden state
for the downstream tasks by Eq. 5

Prediction With the representation hj, we ap-
ply an afﬁne transformation followed by softmax
and obtain the ﬁnal prediction as

ˆyj = softmax (cid:0)Wp

j hj + bp

j

(cid:1) .

(6)

j are parameters speciﬁc to task

Here, Wp
tj.

j and bp

With the prediction result ˆyj, we minimize the

cross-entropy between ˆyj and yj as follows:

Lj(ˆyj, yj) = −

yj,k log(ˆyj,k).

(7)

|Yj |
(cid:88)

k=1

3.5 Training

We use cross-entropy loss for each subtask and
sum up losses to train TOPJUDGE:

L =

λjLj(ˆyj, yj),

(8)

|T |
(cid:88)

j=1

where λj is the weight factor for each subtask tj.
The DAG dependencies of subtasks ensure that
our model is differentiable and can be trained in an
end-to-end fashion. In practice, we set all weights
λj to 1, and employ Adam (Kingma and Ba, 2015)
for optimization. We also apply dropout (Srivas-
tava et al., 2014) on the fact representation to pre-
vent overﬁtting.

4 Experiments

To evaluate the proposed TOPJUDGE framework,
we conduct a series of experiments on LJP over
three large-scale datasets of criminal cases in
China. We select three representative judgment
prediction subtasks for comparison, including law
articles, charges, and the terms of penalty.

4.1 Dataset Construction

As there are no publicly available LJP datasets
in previous works, we collect and construct three
different LJP datasets, including CJO, PKU, and
CAIL. CJO consists of criminal cases published
by the Chinese government from China Judge-
ment Online1. PKU contains criminal cases pub-
lished by Peking University Law Online2. CAIL

1 http://wenshu.court.gov.cn/
2 http://www.pkulaw.com/

Datasets

CJO

PKU

CAIL

Cases
Law Articles
Charges
Term of Penalty

1, 007, 744
98
99
11

175, 744
68
64
11

113, 536
105
122
11

Table 1: The statistics of different datasets.

(Chinese AI and Law Challenge) is another crim-
inal case dataset for competition released by the
Supreme People’s Court of China3. The details of
CAIL can be found in Xiao et al. (2018).

For all datasets we mentioned above, as the doc-
uments are well-structured and human-annotated,
we can easily extract fact descriptions, applica-
ble law articles, charges and the terms of penalty
from each document using regular expressions.
We have manually checked a randomly sampled
set of cases, and extraction errors are negligible.

In real-world scenarios, there are some cases
with multiple defendants and multiple charges,
which will increase the complexity of judgment
prediction. As our model aims to explore the ef-
fectiveness of considering topological dependen-
cies between various subtasks, we ﬁlter out these
cases and leave them as our future work.

Meanwhile,

there are also some infrequent
charges and law articles, such as money launder-
ing, smuggling of nuclear materials and tax dodge.
We ﬁlter out these infrequent charges and law arti-
cles and only keep those with frequencies greater
than 100. For the term of penalty, we divide the
terms into non-overlapping intervals. We list de-
tailed statistics of these datasets in Table 1.

4.2 Baselines

For comparison, we employ the following text
classiﬁcation models and judgment prediction
methods as baselines:

TFIDF+SVM: We employ term-frequency in-
verse document frequency (TFIDF) (Salton and
Buckley, 1988) to extract word features and uti-
lize SVM (Suykens and Vandewalle, 1999) for text
classiﬁcation.

CNN: We employ CNN with multiple ﬁlter
widths (Kim, 2014) for fact encoding and classi-
ﬁcation.

Hierarchical LSTM (HLSTM): Tang et al.
(2015) employs hierarchical neural networks to
learn document representations in sentiment clas-

3 http://cail.cipsc.org.cn/index.html

Tasks

Law Articles

Charges

The Term of Penalty

Metrics

Acc. MP MR

F1

Acc. MP MR

F1

Acc. MP MR

F1

Single

Multi

TFIDF+SVM 82.4
92.5
91.4

CNN
HLSTM

Fact-Law Att.
PM
CNN-MTL
HLSTM-MTL

93.5
93.7
94.3
92.4

94.4

45.5
46.9
38.6

50.9
51.9
53.0
45.5

53.9

26.7
38.4
37.3

45.6
44.1
46.0
41.4

47.3

30.2
40.0
36.9

45.9
44.9
46.9
41.0

48.2

82.2
92.3
91.8

93.4
93.6
94.1
92.3

94.9

47.4
41.2
37.8

47.2
45.5
48.5
41.9

53.9

27.9
32.3
36.0

41.4
39.1
41.7
36.6

48.2

31.3
33.7
35.2

41.5
39.3
42.5
35.9

49.1

48.5
57.4
56.1

56.3
58.2
58.7
54.9

58.8

36.0
35.6
22.5

31.3
38.2
39.9
30.6

40.2

16.7
22.2
25.0

26.4
24.9
28.8
26.6

32.9

16.5
22.7
23.3

26.7
26.8
29.4
26.4

32.8

Ours

TOPJUDGE

Table 2: Judgment prediction results on CJO.

Tasks

Law Articles

Charges

The Term of Penalty

Metrics

Acc. MP MR

F1

Acc. MP MR

F1

Acc. MP MR

F1

Single

Multi

TFIDF+SVM 80.9
93.1
91.7

CNN
HLSTM

Fact-Law Att.
PM
CNN-MTL
HLSTM-MTL

93.9
94.4
95.0
93.9

95.4

51.3
64.3
54.4

68.1
69.6
73.8
71.2

76.4

32.6
52.6
53.4

63.4
61.0
64.9
64.6

67.6

36.4
54.3
50.9

63.5
62.2
66.0
65.1

68.4

81.0
93.3
91.9

94.2
94.3
95.0
93.8

95.6

53.4
61.9
52.5

65.8
65.1
70.7
67.8

75.9

35.4
49.3
48.9

58.5
56.2
60.6
60.0

69.6

38.7
51.1
47.3

58.7
57.2
61.7
60.7

70.9

45.3
57.6
54.3

55.7
58.2
58.4
55.4

57.8

30.4
24.1
20.6

27.7
36.2
36.0
31.3

38.9

17.4
23.1
21.7

27.4
26.4
28.7
26.2

32.1

17.2
23.3
19.0

26.5
27.1
28.9
25.7

31.8

Ours

TOPJUDGE

Table 3: Judgment prediction results on PKU.

siﬁcation. Based on this work, we employ an
LSTM for sentence representations and another
one to obtain the representation of complete fact
descriptions.

Fact-Law Attention Model: Luo et al. (2017)
proposes a neural charge prediction model by cap-
turing the interaction between fact descriptions
and applicable laws with attention mechanism.

Pipeline Model (PM): To demonstrate the
advantage of TOPJUDGE on modeling subtasks
jointly, we also implement a pipelined method for
comparison. Here, we train 3 separate CNN classi-
ﬁers for law articles, charges, and term of penalty.
For each subtask, the input is the concatenation
of the fact representation and the embeddings for
predicted labels of previous subtasks.

Besides, we compare our model with conven-
tional MTL methods that do not consider the de-
pendencies among subtasks as in Fig. 3 (a). These
methods are denoted as CNN-MTL and HLSTM-
MTL, where we implement the fact encoder as in
Fig. 2 using CNN or HLSTM respectively.

4.3 Experimental Settings

As the case documents are written in Chinese
with no space between words, we employ THU-
LAC (Sun et al., 2016) for word segmentation. Af-
terward, we adopt the Skip-Gram model (Mikolov
et al., 2013) to pre-train word embeddings on these

case documents, with embedding size set to 200
and frequency threshold set to 25.

For all models, we set

the fact representa-
tion and task-speciﬁc representation size to 256.
Meanwhile, we set the maximum sentence length
to 128 words and maximum document length to
32 sentences.

For training, the learning rate of Adam opti-
mizer is 10−3, and the dropout probability is 0.5.
We also set the batch size to 128 for all models.
We train every model for 16 epochs, and evaluate
the ﬁnal model on the testing set.

We employ accuracy (Acc.), macro-precision
(MP), macro-recall (MR) and macro-F1 (F1)
the macro-
as evaluation metrics.
precision/recall/F1 are calculated by averaging the
precision/recall/F1 of each category.

Here,

4.4 Results and Analysis

We evaluate the performance on three LJP sub-
including law articles (denoted as t1),
tasks,
charges (denoted as t2), and the terms of penalty
(denoted as t3). Experimental results are shown in
Tables 2, 3, and 4. Note that, we implement TOP-
JUDGE with the dependency relationship in Fig. 3
(c), i.e.,

D1 = φ, D2 = {t1}, D3 = {t1, t2}.

(9)

Tasks

Law Articles

Charges

The Term of Penalty

Metrics

Acc. MP MR

F1

Acc. MP MR

F1

Acc. MP MR

F1

Single

Multi

TFIDF+SVM 60.1
81.4
-

CNN
HLSTM

Fact-Law Att.
PM
CNN-MTL
HLSTM-MTL

70.9
84.7
84.5
-

86.3

54.9
74.4
-

64.8
80.7
80.0
-

81.9

45.3
64.1
-

63.6
68.6
68.1
-

71.1

46.3
65.7
-

59.1
70.8
70.3
-

73.4

59.2
80.7
-

68.7
83.6
83.4
-

85.7

53.9
77.3
-

66.1
81.6
81.6
-

83.4

45.0
65.5
-

65.3
70.0
69.1
-

76.0

45.7
67.2
-

60.1
72.1
71.6
-

78.3

28.4
28.8
-

36.5
40.0
39.5
-

38.3

22.9
34.7
-

29.9
37.4
37.2
-

36.1

20.0
27.8
-

27.6
32.0
32.3
-

33.1

18.1
28.6
-

27.1
31.6
31.3
-

32.1

Ours

TOPJUDGE

Table 4: Judgment prediction results on CAIL. Note that, “-” means the model does not converge within
128 epochs.

This means that the prediction of charges depends
on law articles, and the prediction of term of
penalty depends on both law articles and charges.
Such explicit dependencies conform to the judi-
cial logic of human judges, which will be veriﬁed
in later sections. These results show that:

(1) The proposed TOPJUDGE model outper-
forms other baselines signiﬁcantly on most sub-
tasks and datasets. It demonstrates the effective-
ness and robustness of our proposed framework.

(2) Compared with conventional single-task
models, e.g., CNN and HLSTM, MTL methods
take advantage of the correlation among relevant
subtasks and thus achieve promising improve-
It indicates the importance of modeling
ments.
LJP subtasks jointly.

(3) Moreover, TOPJUDGE signiﬁcantly outper-
forms typical MTL models, especially on the pre-
diction of charges and the terms of penalty. It veri-
ﬁes the rationality and importance of modeling de-
pendencies over LJP subtasks with DAG.

4.5 Ablation Analysis

Tasks

t1

t2

t3

Metrics

Acc.

F1

Acc.

F1

Acc.

F1

TOPJUDGE
- t3 (cid:1) t1
- t2 (cid:1) t1
φ

95.4
95.2
94.8
94.7

68.4
67.7
64.7
64.4

95.6
95.4
94.9
94.9

70.9
70.3
60.2
60.1

57.8
57.4
57.0
57.8

31.8
31.2
31.6
27.6

Table 5: Ablation analysis on PKU.

To further illustrate the signiﬁcance of legal de-
pendencies and explore how the DAG dependen-
cies inﬂuence the performance, we evaluate the
performance of TOPJUDGE under various DAG
architectures. Using Eq. 9 as the full dependen-
cies, we remove the dependency of t3 (cid:1) t1 (law
articles and term of penalty, corresponding to the
sequential form in Fig. 3), t2 (cid:1) t1 (law articles and

charges), and all dependencies respectively. Re-
sults are summarized in Table 5.

We observe that the performance of TOPJUDGE
decreases on all tasks after removing either depen-
dency. More speciﬁcally, when we dropped de-
pendencies t3 (cid:1) t1 and t2 (cid:1) t1 respectively, sig-
niﬁcant decreases are observed for t3 and t2 corre-
spondingly. This demonstrates that incorporating
dependencies is beneﬁcial for relevant subtasks,
verifying its guiding role in the civil law system.

Meanwhile, we note that there are two main
differences between TOPJUDGE and traditional
multi-task models, namely the Cell Initialization
and the Task-Speciﬁc Representation. We can
see that if we eliminate Cell Initialization from
TOPJUDGE,
the dependencies will not be rep-
resented in the model and it will become sim-
ilar to CNN-MTL. If we eliminate the Task-
Speciﬁc Representation from TOPJUDGE, TOP-
JUDGE will become the same as the Pipeline
Model. In a word, the main improvement of our
models comes from the combination.

4.6 Case Study

We give some intuitive examples to demonstrate
the signiﬁcance of TOPJUDGE on LJP subtasks.

As shown in Table 6, case 1 is about negligently
causing a ﬁre. The fact description of this case
states “The defendant pulled up weeds in the ﬁelds
and piled them up in haphazard stacks. Afterward,
he lighted them up and triggered the forest ﬁres...”
TOPJUDGE predicts all judgments correctly, while
CNN-MTL fails to predict the charge and term of
penalty. Moreover, CNN-MTL obtains conﬂicting
judgments, i.e., “crime of arson” and “1-2 years”,
due to its neglecting of dependencies of these sub-
tasks. According to the legal provisions of law ar-
ticle 115, the crime of arson should be sentenced
to more than 10 years.

Methods

Law Charge

Term
(months)

12-24(×)

CNN-MTL

115 Arson(×)

TOPJUDGE

115 Negligently Caus-
ing a Fire

0-6

CNN-MTL

293

Intentional Dam-
age to Property(×)

12-24(×)

TOPJUDGE

293 Affray

0-6

Table 6: Example cases and their prediction results.

Case 2 in Table 6 is another evidence of the in-
sufﬁciency of conventional MTL on LJP. This case
is about picking quarrels and provoking troubles.
Both CNN-MTL and TOPJUDGE succeed to pre-
law article 293
dict the relevant law articles (i.e.,
of the crime of affray). However, CNN-MTL is
confused between “crime of affray” and “crime of
intentional destruction or damage of properties”,
two charges similar to each other. Conversely,
TOPJUDGE can utilize the prediction result of law
articles and consequently prevent this confusion.

To summarize, modeling the explicit dependen-
cies among various subtasks can remarkably help
the LJP model address the issue of predicting con-
ﬂicting results.

4.7 Error Analysis

Prediction errors induced by our proposed model
can be traced down into the following causes.

Data Imbalance.

For the subtasks of law
articles and charges, our model achieves more
than 90% on accuracy, while only about 60% for
macro-F1. This issue is much more severe on the
subtask of the term of penalty, which our model
yields a poor performance of only 30% macro-F1.
The bad performance is mainly due to the imbal-
ance of category labels, e.g., there are only a few
training instances where the term is “life imprison-
ment or death penalty”. Most judgment prediction
approaches perform poorly (especially for Recall)
on these labels as listed in Fig. 4. Instance weight-
ing schemes can be introduced to address this is-
sue in future works.

Incomplete Information. Following existing
LJP works, we predict the ﬁnal judgment accord-
ing to the fact descriptions, which is incomplete as
compared to the whole materials relevant to this
In Chinese Law, there are certain circum-
case.
stances under which the sentence can be short-
ened. For example, minors usually receive a light-

Figure 4: The confusion matrix in the subtask
of predicting the term of penalty on the PKU
dataset. The rows denote the ground truth while
the columns denote the prediction results.

ened penalty, and those guilty of misdemeanors
are allowed for a secured pending trial while pay-
ing a security deposit. However, such informa-
tion is not included in the fact descriptions. The
lack of such information also raises difﬁculties for
judgment prediction, especially for the prediction
of the term of penalty. In Fig. 4, we can see that
the highest error rate comes from the cases with a
short term of penalty. Our model fails to distin-
guish the cases with no penalty and those with 0-6
months term of imprisonment.

5 Conclusion

In this paper, we focus on the task of legal judg-
ment prediction (LJP) and address multiple sub-
tasks of judgment predication with a topological
learning framework. To be speciﬁc, we formalize
the explicit dependencies over these subtasks in a
DAG form, and propose a novel MTL framework,
TOPJUDGE, by integrating the DAG dependen-
cies. Experimental results on three LJP subtasks
and three different datasets show that our TOP-
JUDGE outperforms all single-task baselines and
conventional MTL models consistently and signif-
icantly.

In the future, we will seek to explore the follow-
ing directions: (1) We will explore more LJP sub-
tasks and more scenarios of cases such as multiple

defendants and charges to investigate the effective-
ness of TOPJUDGE. (2) We will explore how to
incorporate into LJP the temporal factors, which
are not considered in this work.

6 Acknowledgements

This work is supported by the National Nat-
ural Science Foundation of China (NSFC No.
61572273, 61772302) and the research fund of
Powerlaw Inc.
for AI+Law Technology. This
work is also funded by China Association for Sci-
ence and Technology (2016QNRC001). Tu is also
supported by China Postdoctoral Innovative Talent
Support Programme.

References

Nikolaos Aletras, Dimitrios Tsarapatsanis, Daniel
Preotiuc-Pietro, and Vasileios Lampos. 2016. Pre-
dicting judicial decisions of the european court of
human rights: A natural language processing per-
spective. PeerJ Computer Science, 2.

Isabelle Augenstein, Sebastian Ruder, and Anders
Søgaard. 2018. Multi-task learning of pairwise
sequence classiﬁcation tasks over disparate label
spaces. In Proceedings of NAACL.

Baharum Baharudin, Lam Hong Lee, and Khairullah
Khan. 2010. A review of machine learning algo-
rithms for text-documents classiﬁcation. Journal of
Advances in Information Technology, 1(1):4–20.

Ronan Collobert and Jason Weston. 2008. A uniﬁed
architecture for natural language processing: Deep
In Pro-
neural networks with multitask learning.
ceedings of ICML, pages 160–167.

Li Deng, Geoffrey Hinton, and Brian Kingsbury. 2013.
New types of deep neural network learning for
speech recognition and related applications: An
overview. In Proceedings of ICASSP, pages 8599–
8603.

Daxiang Dong, Hua Wu, Wei He, Dianhai Yu, and
Haifeng Wang. 2015. Multi-task learning for mul-
tiple language translation. In Proceedings of ACL,
volume 1, pages 1723–1732.

Long Duong, Trevor Cohn, Steven Bird, and Paul
Cook. 2015. Low resource dependency parsing:
Cross-lingual parameter sharing in a neural network
In Proceedings of ACL, volume 2, pages
parser.
845–850.

Orhan Firat, Kyunghyun Cho, and Yoshua Bengio.
2016. Multi-way, multilingual neural machine
translation with a shared attention mechanism.
In
Proceedings of NAACL, pages 866–875.

Ross Girshick. 2015. Fast r-cnn.

In Proceedings of

ICCV, pages 1440–1448.

Kazuma Hashimoto, Yoshimasa Tsuruoka, Richard
Socher, et al. 2017. A joint many-task model: Grow-
ing a neural network for multiple nlp tasks. In Pro-
ceedings of EMNLP, pages 1923–1933.

Sepp Hochreiter and Jurgen Schmidhuber. 1997.
Neural computation,

Long short-term memory.
9(8):1735–1780.

Zikun Hu, Xiang Li, Cunchao Tu, Zhiyuan Liu, and
Maosong Sun. 2018. Few-shot charge prediction
with discriminative legal attributes. In Proceedings
of COLING.

Daniel Martin Katz, Michael J Bommarito II, and Josh
Blackman. 2017. A general approach for predict-
ing the behavior of the supreme court of the united
states. Plos one, 12(4).

R Keown. 1980. Mathematical models for legal pre-

diction. Computer/LJ, 2:829.

Yoon Kim. 2014. Convolutional neural networks for
sentence classiﬁcation. In Proceedings of EMNLP.

Diederik Kingma and Jimmy Ba. 2015. Adam: A
method for stochastic optimization. In Proceedings
of ICLR.

Fred Kort. 1957. Predicting supreme court decisions
mathematically: A quantitative analysis of the ”right
to counsel” cases. American Political Science Re-
view, 51(1):1–12.

Benjamin E Lauderdale and Tom S Clark. 2012. The
supreme court’s many median justices. American
Political Science Review, 106(4):847–866.

Wanchen Lin, Tsung Ting Kuo, and Tung Jia Chang.
2012. Exploiting machine learning models for chi-
nese legal documents labeling, case classiﬁcation,
and sentencing prediction. In Processdings of RO-
CLING, page 140.

Chaolin Liu, Cheng Tsung Chang, and Jim How Ho.
2004. Case instance generation and reﬁnement
for case-based criminal summary judgments in chi-
nese. Journal of Informationence & Engineering,
20(4):783–800.

Chaolin Liu and Chwen Dar Hsieh. 2006. Exploring
phrase-based classiﬁcation of judicial documents for
criminal charges in chinese. In Proceedings of IS-
MIS, pages 681–690.

Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2016.
Recurrent neural network for text classiﬁcation with
multi-task learning. In Proceedings of IJCAI.

Xiaodong Liu, Jianfeng Gao, Xiaodong He, Li Deng,
Kevin Duh, and Ye-Yi Wang. 2015. Representation
learning using multi-task deep neural networks for
semantic classiﬁcation and information retrieval. In
Proceedings of NAACL, pages 912–921.

Chaojun Xiao, Haoxi Zhong, Zhipeng Guo, Cunchao
Tu, Zhiyuan Liu, Maosong Sun, Yansong Feng,
Xianpei Han, Zhen Hu, Heng Wang, et al. 2018.
Cail2018: A large-scale legal dataset for judgment
prediction. arXiv preprint arXiv:1807.02478.

Yongxin Yang and Timothy Hospedales. 2017. Deep
multi-task representation learning: A tensor factori-
sation approach. In Proceedings of ICLR.

Hai Ye, Xin Jiang, Zhunchen Luo, and Wenhan Chao.
2018. Interpretable charge predictions for criminal
cases: Learning to generate court views from fact
descriptions. In Proceedings of NAACL.

Bingfeng Luo, Yansong Feng, Jianbo Xu, Xiang
Zhang, and Dongyan Zhao. 2017. Learning to pre-
dict charges for criminal cases with legal basis. In
Proceedings of EMNLP.

Minh-Thang Luong, Quoc V Le, Ilya Sutskever, Oriol
Vinyals, and Lukasz Kaiser. 2016. Multi-task se-
In Proceedings of
quence to sequence learning.
ICLR.

Jiayuan Mao, Tete Xiao, Yuning Jiang, and Zhimin
Cao. 2017. What can help pedestrian detection? In
Proceedings of CVPR, pages 3127–3136.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Proceedings of NIPS, pages 3111–3119.

Stuart S Nagel. 1963. Applying correlation analysis to

case prediction. Texas Law Review, 42:1006.

Sebastian Ruder, Joachim Bingel, Isabelle Augen-
stein, and Anders Søgaard. 2017. Learning what to
share between loosely related tasks. arXiv preprint
arXiv:1705.08142.

Gerard Salton and Christopher Buckley. 1988. Term-
weighting approaches in automatic text retrieval. In-
formation processing & management, 24(5):513–
523.

Jeffrey A Segal. 1984. Predicting supreme court cases
probabilistically: The search and seizure cases,
American Political Science Review,
1962-1981.
78(4):891–900.

Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: a simple way to prevent neural networks
from overﬁtting. JMLR, 15(1):1929–1958.

Octavia Maria Sulea, Marcos Zampieri, Mihaela Vela,
and Josef Van Genabith. 2017. Exploring the use of
text classi cation in the legal domain. In Proceedings
of ASAIL workshop.

Maosong Sun, Xinxiong Chen, Kaixu Zhang, Zhipeng
Guo, and Zhiyuan Liu. 2016. Thulac: An efﬁcient
lexical analyzer for chinese.

Johan AK Suykens and Joos Vandewalle. 1999. Least
squares support vector machine classiﬁers. Neural
processing letters, 9(3):293–300.

Duyu Tang, Bing Qin, and Ting Liu. 2015. Document
modeling with gated recurrent neural network for
sentiment classiﬁcation. In Proceedings of EMNLP,
pages 1422–1432.

S Sidney Ulmer. 1963. Quantitative analysis of judi-
cial processes: Some practical and theoretical appli-
cations. Law and Contemporary Problems, 28:164.

