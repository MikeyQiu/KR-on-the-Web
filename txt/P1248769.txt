Medical Image Imputation from Image Collections

Adrian V. Dalca, Katherine L. Bouman, William T. Freeman, Natalia S. Rost, Mert R. Sabuncu, Polina Golland

for the Alzheimers Disease Neuroimaging Initiative*

1

8
1
0
2
 
g
u
A
 
7
1
 
 
]

V
C
.
s
c
[
 
 
1
v
2
3
7
5
0
.
8
0
8
1
:
v
i
X
r
a

to capture much of

Abstract—We present an algorithm for creating high resolution
anatomically plausible images consistent with acquired clinical
brain MRI scans with large inter-slice spacing. Although large
images contain a wealth of information,
data sets of clinical
time constraints during acquisition result in sparse scans that
fail
the anatomy. These characteristics
often render computational analysis impractical as many image
analysis algorithms tend to fail when applied to such images.
Highly specialized algorithms that explicitly handle sparse slice
spacing do not generalize well across problem domains. In
contrast, we aim to enable application of existing algorithms
that were originally developed for high resolution research scans
to signiﬁcantly undersampled scans. We introduce a genera-
tive model that captures ﬁne-scale anatomical structure across
subjects in clinical image collections and derive an algorithm
for ﬁlling in the missing data in scans with large inter-slice
spacing. Our experimental results demonstrate that the resulting
method outperforms state-of-the-art upsampling super-resolution
techniques, and promises to facilitate subsequent analysis not
previously possible with scans of this quality. Our implementation
is freely available at https://github.com/adalca/papago.

Index Terms—Imputation,

super-resolution, clinical

scans,

thick slices, sparse slices, MRI, brain scans

I. INTRODUCTION

Increasingly open image acquisition efforts in clinical prac-
tice are driving dramatic increases in the number and size
of patient cohorts in clinical archives. Unfortunately, clinical
scans are typically of dramatically lower resolution than the
research scans that motivate most methodological develop-
ment. Speciﬁcally, while slice thickness can vary depending
inter-slice spacing is often
on the clinical study or scan,
signiﬁcantly larger than the in-plane resolution of individual
slices. This results in missing voxels that are typically ﬁlled
via interpolation.

Our work is motivated by a study that

includes brain
MRI scans of thousands of stroke patients acquired within
48 hours of stroke onset. The study aims to quantify

Adrian V. Dalca is with the Computer Science and Artiﬁcial Intelligence
Lab, MIT (main contact: adalca@csail.mit.edu) and also Martinos Center for
Biomedical Imaging, Massachusetts General Hospital, HMS.

Katherine L. Bouman and Polina Golland are with the Computer Science

and Artiﬁcial Intelligence Lab, MIT.

William T. Freeman is with the Computer Science and Artiﬁcial Intelligence

Lab, MIT and Google.

Fig. 1: An example scan from our clinical dataset. The three panels display
axial, sagittal and coronal slices, respectively. While axial in-plane resolution
can be similar to that of a research scan, slice spacing is signiﬁcantly
larger. We visualize the saggital and coronal views using nearest neighbor
interpolation.

white matter disease burden [23], necessitating skull strip-
ping and deformable registration into a common coordinate
frame [27], [31], [32]. The volumes are severely under-
sampled (0.85mm ˆ 0.85mm ˆ 6mm) due to constraints of
acute stroke care (Fig. 1). Such undersampling is typical of
modalities, such as T2-FLAIR, that aim to characterize tissue
properties, even in research studies like ADNI [15].

In undersampled scans, the image is no longer smooth, and
the anatomical structure may change substantially between
consecutive slices (Fig. 1). Since such clinically acquired
scans violate underlying assumptions of many algorithms, even
basic tasks such as skull stripping and deformable registration
present signiﬁcant challenges, yet are often necessary for
downstream analysis [4], [7], [12], [15], [23], [30], [31].

We present a novel method for constructing high resolution
anatomically plausible volumetric images consistent with the
available slices in sparsely sampled clinical scans. Importantly,
our method does not require any high resolution scans or
expert annotations for training. It instead imputes the missing
structure by learning solely from the available collection of
sparsely sampled clinical scans. The restored images represent
plausible anatomy. They promise to act as a medium for
enabling computational analysis of clinical scans with existing
techniques originally developed for high resolution, isotropic
research scans. For example, although imputed data should
not be used in clinical evaluation, the brain mask obtained
through skull stripping of the restored scan can be applied to
the original clinical scan to improve subsequent analyses.

Mert R. Sabuncu is with the the School of Electrical and Computer Engi-
neering, and Meinig School of Biomedical Engineering, Cornell University.
Natalia S. Rost is with the Department of Neurology, Massachusetts General

A. Prior Work

Hospital, HMS.

*Data used in preparation of this article were obtained from the Alzheimers
Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). As
such,
the investigators within the ADNI contributed to the design and
implementation of ADNI and/or provided data but did not participate in
analysis or writing of this report. A complete listing of ADNI investigators
can be found at: http://adni.loni.usc.edu/wp-content/uploads/how to apply/
ADNI Acknowledgement List.pdf

Many image restoration techniques depend on having
enough information in a single image to synthesize data.
Traditional
interpolation methods, such as linear, cubic or
spline [28], assume a functional representation of the image.
They treat the low resolution voxels as samples, or observa-
tions, and estimate function parameters to infer missing voxel
values. Patch-based superresolution algorithms use ﬁne-scale

redundancy within a single scan [10], [11], [19], [20], [22].
The key idea is to ﬁll in the missing details by identifying
similar image patches in the same image that might contain
relevant detail [19], [22]. This approach depends on having
enough repetitive detail in a scan to capture and re-synthesize
high frequency information. Unfortunately, clinical images are
often characterized by sampling that is too sparse to adequately
ﬁt functional representations or provide enough ﬁne-scale
information to recover the lost detail. For example, 6mm
slice spacing, typical of many clinical scans including our
motivating example, is far too high to accurately estimate
approximating functions without prior knowledge. In such
cases, a single image is unlikely to contain enough ﬁne-scale
information to provide anatomically plausible reconstructions
in the direction of slice acquisition, as we demonstrate later
in the paper.

Alternatively, one can use additional data to synthesize
better images. Many superresolution algorithms use multiple
scans of the same subject, such as multiple low resolution
acquisitions with small shift differences to synthesize a single
volume [2], [16], [22]. However, such acquisitions are not
commonly available in the clinical setting.

Nonparametric and convolutional neural-network (CNN)
based upsampling methods that tackle the problem of super-
resolution often rely on an external dataset of high resolution
data or cannot handle extreme undersampling present in clin-
ical scans. For example, some methods ﬁll in missing data
by matching a low resolution image patch from the input
scan with a high resolution image patch from the training
dataset [3], [13], [16], [17], [25], [24]. Similarly, CNN-based
upsampling methods approximate completion functions, but
require high resolution scans for training [8], [21]. A recent
approach to improve resolution from a collection of scans
with sparse slices jointly upsamples all images using non-local
means [26]. However this method has only been demonstrated
on slice spacing of roughly three times the in-plane resolution,
and in our experience similar non-parametric methods fail to
upsample clinical scans with more signiﬁcant undersampling.

Our work relies on a low dimensional embedding of im-
age patches with missing voxels. Parametric patch methods
and low dimensional embeddings have been used to model
the common structure of image patches from full resolution
images, but are typically not designed to handle missing data.
Speciﬁcally, priors [33] and Gaussian Mixture Models [35],
[36] have been used in both medical and natural images for
classiﬁcation [1] and denoising [9], [36]. The procedures used
for training of these models rely on having full resolution
patches with no missing data in the training phase.

Unfortunately, high (full) resolution training datasets are not
readily available for many image contrasts and scanners, and
may not adequately represent pathology or other properties of
clinical populations. Acquiring the appropriate high resolution
training image data is often infeasible, and here we explicitly
focus on the realistic clinical scenario where only sparsely
sampled images are available.

2

B. Method Overview

We take advantage of the fact that local ﬁne scale structure is
shared in a population of medical images, and each scan with
sparse slices captures some partial aspect of this structure. We
borrow ideas from Gaussian Mixture Model (GMM) for image
patch priors [36], low dimensional Gaussian embeddings [14],
[34], and missing data models [14], [18] to develop a proba-
bilistic generative model for sparse 3D image patches around a
particular location using a low-dimensional GMM with partial
observations. We derive the EM algorithm for maximum like-
lihood estimation of the model parameters and discuss related
modeling choices. Given a new sparsely sampled scan, the
maximum a posteriori estimate of the latent structure yields
the imputed high resolution image. We evaluate our algorithm
using scans from the ADNI cohort, and demonstrate its utility
in the context of the motivating stroke study. We investigate
the behaviour of our model under different parameter settings,
and illustrate an example of potential improvements in the
downstream analysis using an example task of skull stripping.
This paper extends the preliminary version of the method
presented at the 2017 Conference on Information Processing
in Medical Imaging [5]. Here, we improve model inference
by removing parameter co-dependency between iterations and
providing new parameter initialization. We provide detailed
derivations and discuss an alternative related model. Finally,
we provide an analysis of important model parameters, present
results for more subjects, and illustrate more example re-
constructions. The paper is organized as follows. Section II
introduces the model and learning algorithm. Section III
discusses implementation details. We present experiments and
analysis of the algorithm’s behavior in Section IV. We discuss
important modeling aspects and related models in Section V.
We include an Appendix and Supplementary Material with
detailed derivations of the EM algorithm for the proposed
models.

II. METHOD
In this section, we construct a generative model for sparse
image patches, present the resulting learning algorithm, and
describe our image restoration procedure.

Let tY1, ..., YN u be a collection of scans with large inter-
slice spaces, roughly aligned into a common atlas space
(we use afﬁne transformations in our experiments). For each
image Yi in the collection, only a few slices are observed.
We seek to restore an anatomically plausible high resolution
volume by imputing the missing voxel values.

We capture local structure using image patches. We as-
sume a constant patch shape, and in our experiments use a
3D 11x11x11 shape. We use yi to denote a D-length vector
that contains voxels of the image patch centered at a certain
location in image Yi. We perform inference at each location
independently and stitch the results into the ﬁnal image as
described later in this section. Fig. 2 provides an overview of
the method.

A. Generative Model

We treat an image patch as a high dimensional manifes-
tation of a low dimensional representation, with the intuition

3

Fig. 2: Image imputation for a subvolume. (a) Full resolution images, shown for illustration only. These are unobserved by the algorithm. (b) Sparse planes
acquired in clinical scans. (c) During learning, we train a GMM that captures the low dimensional nature of patch variability in a region around a particular
location (white dot). (d) Given a sparsely sampled scan, we infer the most likely cluster for each 3D patch, and restore the missing data using the learned
model and the observed voxels. We form the ﬁnal volume from overlapping restored patches. 2D images are shown for illustration only, the algorithms operate
fully in 3D.

xi „ N p0, Idˆdq,

(1)

i

k

that the covariation within image patches has small intrinsic
dimensionality relative to the number of voxels in the patch. To
capture the anatomical variability across subjects, we employ a
Gaussian Mixture Model (GMM) to represent local structure
of 3D patches in the vicinity of a particular location across
the entire collection. We then explicitly model the observed
and missing information. Fig 3 presents the corresponding
graphical model.

We model the latent low dimensional patch representation xi

of length d ă D as a normal random variable

where N pµ, Σq denotes the multivariate Gaussian distribution
with mean µ and covariance Σ. We draw latent cluster assign-
ment k from a categorical distribution deﬁned by a length-
K vector π of cluster probabilities, and treat image patch yi
as a high dimensional observation of xi drawn from a K-
component multivariate GMM. Speciﬁcally, conditioned on
the drawn cluster k,

yi “ µk ` Wkxi ` (cid:15)i, where
(cid:15)i „ N p0, σ2
kIDˆDq,

and (cid:15)i |ù xi.

(2)

Vector µk is the patch mean of cluster k, matrix Wk
shapes the covariance structure of yi, and σ2
k is the variance
implies IEryi|ks “ µk and
of image noise. This model
k ` σ2
Ck

∆
“ IErpyi ´ µkqpyj ´ µkqT |ks “ WkW T
Deﬁning θ “ tµk, Wk, σ2

k“1, the likelihood of all
patches Y “ tyiu at this location under the mixture model
is

k, πkuK

kIDˆD.

ppY; θq “

πkN pyi; µk, Ckq.

(3)

ź

ÿ

i

k

In our clinical images, only a few slices are known. To
model sparse observations, we let Oi be the set of observed
voxels in patch yi, and yOi
be the corresponding vector of
i
their intensity values:

k ` W Oi

i “ µOi
yOi

k xi ` (cid:15)Oi
i
comprises rows of Wk that correspond to the
the observed

where W Oi
k
observed voxel set Oi. The likelihood of
data Y O “ tyOi

(4)

,

i u is therefore
ÿ

ź

ppY O; θq “

πkN pyOi
i

; µOi

k , C OiOi
k

q,

(5)

where matrix C OiOi
correspond to the observed voxel subset Oi.

extracts the rows and columns of Ck that

k

We do not explicitly model slice thickness, as in many
clinical datasets this thickness is unknown or varies by site,
scanner or acquisition. Instead, we simply treat the original
data as high resolution thin planes and analyze the effects
of varying slice thickness on the results in the experimental
evaluation of the method.

We also investigated an alternative modeling choice where
each missing voxel of patch yi
is modelled as a latent
variable. This assumption can optionally be combined with the
latent low-dimensional patch representation. We discuss this
alternative choice in Section V, and provide parameter updates
in the Supplementary Material. Unfortunately, the resulting
algorithm is prohibitively slow.

B. Learning

Given a collection of observed patches Y O, we seek
the maximum likelihood estimates of the model parame-
ters tµk, Wk, σ2
ku and π under the likelihood (5). We derive the

4

ı

.

(13)

(15)

from (10) and (11):
ÿ
W j

δikpyj

k Ð

ikA´1
j

,

i ´ µj
kqpxT
”
pyj

γik

ř

iPPj
ř
j

iPPj

σ2
k Ð

i ´ µj
ř

k ´ W j
ř

k

j

i1PPj

pxikq2 ` W j
γi1k

k SikpW j

k qT

(14)
k is the jth row of matrix Wk. Finally, we update the

where W j
cluster proportions:

πk “

γik.

1
N

ÿ

i

Intuitively, learning our model with sparse data is possi-
ble because each image patch provides a slightly different
subset of voxel observations that contribute to the parameter
estimation (Fig. 2). In our experiments, all subject scans
have the same acquisition direction. Despite different afﬁne
transformations to the atlas space for each subject, some voxel
pairs are still never observed in the same patch, resulting
in missing entries of the covariance matrix. Using a low-
rank approximation for the covariance matrix regularized the
estimates.

Upon convergence of the EM updates, we compute the

cluster covariance Ck “ WkW T

k ` σ2

kIDˆD for each k.

C. Imputation

To restore an individual patch yi, we compute the maximum-

a-posteriori (MAP) estimate of the image patch:

ˆyi “ arg max

“ arg max

ppyi|yOi
i
ÿ

; θq

ż

ppk|yOi
i q
ż

xi

ppyi|xiqppxi|k, yOi

i qdxi

“ arg max

γik

ppyi|xiqppxi|k, yOi

i qdxi

xi

“ arg max

γikN pyi; µk ` Wk pxik, Σikq,

yi

yi

yi

yi

k
ÿ

k
ÿ

k

ikqW T

kIDˆD ` WkpSik ` pxik pxT
where Σik “ σ2
k . Due to the
high-dimensional nature of the data, most cluster membership
estimates are very close to 0 or 1. We therefore ﬁrst estimate
the most likely cluster pk for patch yi by selecting the cluster
with the highest membership γik. We estimate the low dimen-
sional representation pxipk given the observed voxels yOi
i using
(7), which yields the high resolution imputed patch:

ˆyi “ µpk ` Wpk

pxipk.

(16)

By restoring the scans using this MAP solution, we perform
conditional mean imputation (c.f. 17, Sec.4.2.2), and demon-
strate the reconstructions in our experiments. In addition, our
model enables imputation of each patch by sampling the
pxipk, Σipkq, providing a
posterior pp¨|yOi
i
better estimation of the residual noise. Depending on the
desired downstream application, sampling-based imputation
may be desired.

; θq « N p¨; µpk ` Wpk

We average overlapping restored patches using standard

techniques [18] to form the restored volume.

Fig. 3: Graphical representation of our model. Circles indicate random vari-
ables and rounded squares represent parameters. Shading represents observed
quantities and the plate indicates replication. The observed patch voxels yOi
form a subset of patch yi extracted by the mask Oi and are generated from
a multivariate Gaussian distribution conditioned on the latent cluster ki and
the latent patch representation xi. Parameters µ and W deﬁne the mean and
the variance of the Gaussian components of the mixture, and σ2 is the image
noise variance.

i

Expectation Maximization algorithm [6] in Appendix A, and
present the update equations and their interpretations below.

The expectation step updates the class memberships:

γik

∆
“ ppk|yOi
i

; θq
πkN pyOi
i
k1 πk1N pyOi
i

; µOi

k , C OiOi
q
k
k1 , C OiOi
; µOi
k1

,

q

ř

“

and the statistics of the low dimensional representation xi for
each image patch yOi

as ”explained” by cluster k:

i

pxik

Sik

`

∆
“ IErxi|ks
pW Oi
“
∆
“ IErxixT
`
“ σ2
k

k qT pW Oi

k q ` σ2

kIdˆd

pW Oi

k qT pyOi

i ´ µOi

k q,

˘

´1

i |ks ´ pxik pxT
ik
k qT pW Oi

pW Oi

k q ` σ2

kIdˆd

˘

´1

.

We let Pj be the set of patches in which voxel j is observed,
and form the following normalized mean statistics:

δik “

γikř
i1PPj
ÿ

γi1k

bj “

δikIErxi|ks “

ÿ

δik pxik
ÿ

iPPj
i |ks “

iPPj

iPPj
ÿ

iPPj

Aj “

δikIErxixT

δikppxik pxT

ik ` Sikq.

(11)

(6)

(7)

(8)

(9)

(10)

The maximization step uses the observed voxels to update
the model parameters. We let yj
i be the jth element of vector yi,
and update the cluster mean as a convex combination of
observed voxels:

ř

µj
k Ð

iPPj

ř

i1PPj

γikp1 ´ pxT
γi1kp1 ´ pxT

i A´1

j bjqyj
i
i1 A´1
j bjq

.

(12)

The covariance factors and image noise variance are updated
based on the statistics of the low dimensional representation

5

Fig. 4: Representative restorations in the ADNI dataset. Reconstruction by NLM, linear interpolation, and our method, and the original high resolution
images for two representative subjects in the study. Our method reconstructs more anatomically plausible substructures as can be especially seen in the close-up
panels of the skull, ventricles, and temporal lobe. Additional examples are available in the Supplementary Materials.

III. IMPLEMENTATION

We work in the atlas space, and approximate voxels as either
observed or missing in this space by thresholding interpolation
weights. To limit interpolation effects due to afﬁne alignment
on the results, we set a higher threshold for regions with high
image gradients than in regions with low gradients. Parameter
estimation could be implemented to include transformation
of the model parameters into the subject-speciﬁc space in
order to optimally use the observed voxels, but this leads to
computationally prohibitive updates.

We stack together the afﬁnely registered sparse images from
the entire collection. We learn a single set of mixture model
parameters within overlapping subvolumes of 21 ˆ 21 ˆ 21
voxels in the isotropically sampled common atlas space.
Subvolumes are centered 11 voxels apart in each direction.
We use a cubic patch of size 11 ˆ 11 ˆ 11 voxels, and
instead of selecting just one patch from each volume at a
given location, we collect all overlapping patches within the
subvolume centered at that location. This aggregation provides
more data for each model, which is crucial when working with
severely undersampled volumes. Moreover, including nearby
voxels offers robustness in the face of image misalignment.
Given the learned parameters at each location, we restore all
overlapping patches within a subvolume.

While learning is performed in the common atlas space,
we restore each volume in its original image space to limit
the effects of interpolation. Speciﬁcally, we apply the inverse
of the estimated subject-speciﬁc afﬁne transformation to the

cluster statistics prior to performing subject-speciﬁc inference.
Our implementation is freely available at https://github.com/

adalca/papago.

IV. EXPERIMENTS

We demonstrate the proposed imputation algorithm on two
datasets and evaluate the results both visually and quantita-
tively. We also include an example of how imputation can aid
in a skull stripping task.

A. Data: ADNI dataset

We evaluate our algorithm using 826 T1-weighted brain
MR images from ADNI [15] 1. We downsample the isotropic
1mm3 images to slice separation of 6mm (1mm ˆ 1mm in-
plane) in the axial direction to be of comparable quality
with the clinical dataset. We use these low resolution images
as input. All downsampled scans are afﬁnely registered to
a T1 atlas. The original images serve as the ground truth
for quantitative comparisons. After learning model parameters
using the data set, we evaluate the quality of the resulting
imputations.

1Data used in the preparation of
this article were obtained from
the Alzheimers Disease Neuroimaging
database
(adni.loni.usc.edu). The primary goal of ADNI has been to test whether serial
magnetic resonance imaging (MRI), positron emission tomography (PET),
other biological markers, and clinical and neuropsychological assessment
can be combined to measure the progression of mild cognitive impairment
(MCI) and early Alzheimers disease (AD).

Initiative

(ADNI)

6

Fig. 6: Regions used for hyper-parameter analysis. Representative example
of four subvolumes used in analyses, shown in saggital, coronal and axial
views.

structure. The method restores anatomical structures that are
almost entirely missing in the other reconstructions, such
as the dura or the sulci of the temporal lobe by learning
about these structures from the image collection. We provide
additional example results in the Supplementary Materials.

Fig. 5 reports the error statistics in the ADNI data. Due
to high variability of MSE among subject scans, we report
improvements of each method over the nearest neighbor
interpolation baseline in the same scan. Our algorithm of-
fers signiﬁcant improvement compared to nearest neighbor,
NLM, and linear interpolation (p ď 10´5, 10´42, 10´27,
respectively). Our method performs signiﬁcantly better on all
subjects. The improvement in MSE is observed in every single
scan. Similarly, our method performs consistently better using
the PSNR metric (not shown), with mean improvements of up
to 1.4 ˘ 0.44 compared to the next best restored scan.

Fig. 5: Reconstruction accuracy statistics. Accuracy for different image
restoration methods (top), and improvement over nearest neighbor interpola-
tion using MSE (bottom). All statistics were computed over 50 scans randomly
chosen from the ADNI dataset. Image intensities are scaled to a r0, 1s range.

B. Evaluation

D. Parameter Setting

We compare our algorithm to three upsampling methods:
nearest neighbour (NN) interpolation, non-local means (NLM)
upsampling, and linear interpolation [19]. We compare the
reconstructed images to the original isotropic volumes both
visually and quantitatively. We use the mean squared error,

ÿ

MSE pZ, Zoq “

1
N
of the reconstructed image Z relative to the original high
resolution scan Zo. We also compute the related peak signal
to noise ratio,

||Z ´ Zo||2,

(17)

PSNR “ log10

maxpZoq
M SEpZ, Zoq

.

(18)

Both metrics are commonly used in measuring the quality of
reconstruction of compressed or noisy signals.

C. Results

Fig. 4 illustrates representative restored images for subjects
in the ADNI dataset. Our method produces more plausible

We analyze the performance of our algorithm while varying
the values of the parameters, and the sparsity patterns of the
observed voxels. For these experiments, we use four distinct
subvolumes that encompass diverse anatomy from ADNI data,
as illustrated in Fig. 6. We start with isotropic data and use
different observation masks as described in each experiment.
Hyper-parameters. We evaluate the sensitivity of our
method under different hyper parameters:
the number of
clusters, k P r1, 2, 5, 10, 15s and the number of dimensions
of the low dimensional embedding d P r10, 20, 30, 40, 50s.
While different regions give optimal results with different
settings, overall our algorithm produces comparable results
for the middle range of these parameters. We run all of our
experiments with k “ 5 and d “ 30.

Sparsity patterns. First, we evaluate how our algorithm
performs under three different mask patterns, all of which
allow for the same number of observed voxels. Speciﬁcally,
we (i) use the true sparsely observed planes as in the ﬁrst
experiment; (ii) simulate random rotations of the observation
planes mimicking acquisitions in different directions; and (iii)

7

Fig. 7: Mask Analysis. Top: example masks for each simulation, shown in the
saggital plane. The ﬁrst experiment reﬂects the limited variability of axial-only
acquisitions, whereas the second and third experiments represent increasingly
more varied patterns of observed voxels. Bottom: imputation errors. More
varied masks leads to improved reconstructions.

simulate random mask patterns. The latter setup is useful for
denoising or similar tasks, and is instructive of the perfor-
mance of our algorithm. Fig. 7 demonstrates that our algorithm
performs better under acquisition with different directions,
and similarly under truly random observations as more entries
of the cluster covariance matrices are directly observed.This
demonstrates a promising application of this model to other
settings where different patterns of image voxels are observed.
Slice Thickness. We also investigate the effects of slice
thickness on the results. The model treats the original data as
high resolution planes. Here, we simulate varying slice thick-
ness by blurring isotropic data in the direction perpendicular
to the slice acquisition direction. We then use the sampling
masks of the scans used in the main experiments to identify
observed, albeit blurred, voxels. Fig. 8 shows that although
the algorithm performs worse with larger slice thickness, it
provides plausible imputation results. For example, results
show minimal noticeable differences, even for a blur kernel
of σ “ 1mm, simulating a slice with signiﬁcant signal
contribution from 4mm away. Our method, which treats ob-
served slices as thin, is nevertheless robust to slice thicknesses
variations.

Fig. 8: Slice thickness simulation. Top: saggital close-up of a region where
axial slices were blurred in the direction perpendicular to the acquisition
direction; followed by respective imputed results. Bottom: performance of our
algorithm under different slice thickness simulations are shown MSE (solid
line) and standard deviation interval (shaded region).

E. Skull Stripping

We also illustrate how imputed data might facilitate down-
stream image analysis. Speciﬁcally, the ﬁrst step in many
analysis pipelines is brain extraction – isolating the brain from
the rest of the anatomy. Typical algorithms assume that the
brain consists of a single connected component separated from
the skull and dura by cerebral spinal ﬂuid [29]. Thus, they
often fail on sparsely sampled scans that no longer include
a clear contrast between these regions. Fig. 9 provides an
example where the brain extraction fails on the original subject
scan but succeeds on our reconstructed image.

F. Clinical Dataset

We also demonstrate our algorithm on a clinical set of 766
T2-FLAIR brain MR scans in a stroke patient cohort. These
scans are severely anisotropic (0.85 ˆ 0.85mm in-plane, slice
separation of 6mm). All subjects are afﬁnely registered to an
atlas and the intensity is normalized.

Fig. 10 illustrates representative restoration improvements
in T2-FLAIR scans from a clinical population. Our method
produces more plausible structure, as can be especially seen in
the close-up panels focusing on anatomical details. We provide
additional example results in the Supplementary Materials.

8

Fig. 9: Skull Stripping Example. Example of a skull stripping failure for linear and NLM interpolation. Skull stripping dramatically improves when applied
to the imputed image for this example.

V. DISCUSSION

explicitly model

Modeling Choices. We

and esti-
low-dimensional embedding for each patch.
mate a latent
include the latent
(5) does not
The likelihood model
patch representation xi,
leading to observed patch covari-
ance C Oi,Oi
k pW Oi
kI. Since the set of observed
voxels Oi varies across subjects,
the resulting Expecta-
tion Maximization algorithm [6] becomes intractable if we
marginalize the latent representation out before estimation.
Introducing the latent structure simpliﬁes the optimization
problem.

k qT ` σ2

“ W Oi

k

We investigated an alternative modeling choice that instead
treats each missing voxel as a latent variable. In particular
we consider the missing values of patch yi as latent vari-
ables, which can be optionally combined with the latent low-
dimensional patch representation. These assumptions lead to
an Expectation Conditional Maximization (ECM) [14], [18],
a variant of the Generalized Expectation Maximization where
parameter updates depend on the previous parameter estimates.
The resulting algorithm estimates the expected missing voxel
mean and covariance directly, and then updates the cluster pa-
rameters (see Supplementary Materials for a complete deriva-
tion). The most notable difference between this formulation
and simpler algorithms that iteratively ﬁll in missing voxels
and then estimate GMM model parameters is in the estimation
of the expected data covariance, which captures the covariance
of the missing and observed data (c.f. [18], Ch.8). We found
that compared to the method presented in Section II, this
variant often got stuck in local minima, had difﬁculty moving
away from the initial missing voxel estimates, and was an order
of magnitude slower than the presented method. We provide
both implementations in our code.

Restoration. Our restoration method assumes that the ob-
served voxels are noisy manifestations of the low dimen-
sional patch representation, and reconstructs the entire patch,
including the observed voxels, leading to smoother images.
This formulation assumes the original observed voxels are
noisy observations of the true data. Depending on the down-
stream analyses,
in the
reconstruction. In addition, we also investigated an alternative
reconstruction method of ﬁlling in the missing voxels given
the observed voxels as noiseless ground truth (not shown).
This formulation leads to sharper but noisier results. The

the original voxels could be kept

two restoration methods therefore yield images with different
characteristics. This tradeoff is a function of the noise in the
original acquisition: higher noise in the clinical acquisition
leads to noisier reconstructions using the alternative method,
whereas in the ADNI dataset the two methods perform sim-
ilarly. In addition, imputation can be achieved by sampling
the posterior distribution rather than using conditional mean
estimation, enabling a better estimate of the residual noise for
downstream analysis.

Usability. Our model assumes that whether a voxel is ob-
served is independent of the intensity of that voxel. Although
the voxels missing in the sparsely sampled images clearly form
a spatial pattern, we assume there is no correlation with the
actual intensity of the voxels. The model can therefore be
learned from data with varying sparseness patterns, including
restoring data in all acquisition directions simultaneously.

The proposed method can be used for general image im-
putation using datasets of varying resolution. For example,
although acquiring a large high resolution dataset for a clinical
study is often infeasible, our algorithm will naturally make use
of any additional image data available. Even a small number of
acquisitions in different directions or higher resolution than the
study scans promise to improve the accuracy of the resulting
reconstruction.

The presented model depends on the image collection
containing similar anatomical structures roughly aligned, such
as afﬁnely aligned brain or cardiac MR scans. Smaller datasets
that contain vastly different scans, such as traumatic brain in-
juries or tumors, may not contain enough consistency to enable
the model to learn meaningful covariation. However, a wide
range of clinical datasets contain the anatomical consistency
required, and can beneﬁt from the proposed method.

Initialization. We experimented with several initialization
schemes, and provide them in our implementation. A natural
initialization is to ﬁrst learn a simple GMM from the linearly
interpolated volumes, and use the resulting parameter values
as initializations for our method. This leads to results that
improve on the linear interpolation but still maintain some-
what blocky effects caused by interpolation. More agnostic
initializations, such as random parameter values, lead to more
realistic anatomy but noisier ﬁnal estimates. Different methods
perform well in different regions of the brain. The experi-
mental results are initialized by ﬁrst learning a simple GMM

9

Fig. 10: Representative restorations in the clinical dataset. Reconstruction using NLM, linear interpolation and our method for two representative subjects.
Our method reconstructs more plausible substructures, as can be especially seen in the close-up panels of the skull and the periventricular region. Additional
examples are available in the Supplementary Materials.

ACKNOWLEDGMENT

We acknowledge the following funding sources: NIH
NINDS R01NS086905, NIH NICHD U01HD087211,
NIH NIBIB NAC P41EB015902, NIH R41AG052246-01,
1K25EB013649-01, 1R21AG050122-01, NSF IIS 1447473,
Wistron Corporation, and SIP.

Data collection and sharing for this project was funded
by the Alzheimer’s Disease Neuroimaging Initiative (ADNI)
(National Institutes of Health Grant U01 AG024904) and DOD
ADNI (Department of Defense award number W81XWH-12-
2-0012). ADNI is funded by the National Institute on Aging,
the National Institute of Biomedical Imaging and Bioengineer-
ing, and through generous contributions from several agencies
listed at http://adni.loni.usc.edu/about/.

from the linearly interpolated volumes, and using the resulting
means with diagonal covariances as an initial setting of the
parameters. We start with a low dimensional representation to
be of dimension 1, and grow it with every iteration up to the
desired dimension. We found that this approach outperforms
all other strategies.

VI. CONCLUSIONS

We propose an image imputation method that employs a
large collection of low-resolution images to infer ﬁne-scale
anatomy of a particular subject. We introduce a model that
captures anatomical similarity across subjects in large clinical
image collections, and imputes, or ﬁlls in, the missing data
in low resolution scans. The method produces anatomically
plausible volumetric images consistent with sparsely sampled
input scans.

Our approach does not require high resolution scans or
expert annotations for training. We demonstrate that our algo-
rithm is robust to many data variations, including varying slice
thickness. The resulting method enables the use of untapped
clinical data for large scale scientiﬁc studies and promises to
facilitate novel clinical analyses.

APPENDIX A
EXPECTATION MAXIMIZATION UPDATES

ÿ

i,k
1
2σ2
k
d
2

d
2

1
2

Following (5), the complete likelihood of our model is:

ppY O, X ; θq “

πkN pyOi
i

, xi; µOi

k , C OiOi
k

q,

(19)

ź

ÿ

i

k

where X “ txiu. The expectation of this probability is then

Qpθ|θq “ IEX |Y O,θ rlog ppY O, X ; θqs

“

IErkp´

log 2π ´

1
2

log |σ2

kI|

´

pyOi

i ´ W O

k xi ´ µOi

k qT pyOi

i ´ W O

k xi ´ µOi
k q

´

log 2π ´

log |I| ´

(20)

1
2

xixT

i qs.

Computing this expectation requires evaluating IErks, IErxi|ks,
and IErxixT
i |ks, which is trivially done to obtain the expecta-
tion step updates (6) -(8) .

For the maximization step, we optimize (20) with respect

to the model parameters.

“

ÿ

iPPj
ÿ

B
Bµk
“

BQ
Bµk

9

9

IE

kpyOi

i ´ W Oi

k xi ´ µOi
k q

‰

IE

kpyOi

i ´ W Oi

k xi ´ µOi

k qT pyOi

i ´ W Oi

iPPj
ÿ

“

iPPj

γikpyOi

i ´ W Oi
k

pxik ´ µOi

k q “ 0,

iPPj
ÿ

“

iPPj
ÿ

iPPj
»

ÿ

iPPj

ÿ

iPPj

1ř

µj
k “

ÿ

i1 γi1k

iPPj

γikpyj

i ´ W j

k

pxikq

(21)

“

ÿ

BIE

kpyOi

i ´ W Oi

k xi ´ µOi

i ´ W Oi

‰
k xi ´ µOi
k q

BQ
BWk

9

9

k qT pyOi
BWk

‰

IE

kpW Oi

k xi ´ pyOi

i ´ µOi

k qqxT

i

“

γikW Oippxik pxT

i ´ pµOi

k qqpxT

ik “ 0

ik ` Sikq ´ pyOi
ﬁ

´1

ÿ

iPPj

W j

k “

–

γikppxik pxT

ik ` Sikq

ﬂ

γikpyj

i ´ µj

kqpxT

ik

“

δikpyj

i ´ µj

kqpxT

ikA´1
j

(22)

where δ and A are deﬁned in (9) and (11), respectively. By
combining (22) and (21), we obtain

γik “

γikyj

i ´ W j

k

γik pxik

ÿ

iPPj

µj
k

ÿ

i

ÿ

iPPj
ÿ

iPPj
ÿ

iPPj

µj
k “

µj
k “

δikyj

k bj

i ´ W j
ÿ

iPPj

δikyj

i ´

δikpyj

i ´ µj

kqpxT

ikA´1

j bj

µj
kp1 ´

δik pxT

ikA´1

j bjq “

δikyj

i p1 ´ pxT

ikA´1

j bjq

ÿ

ÿ

iPPj
ř

iPPj
ikA´1
ikA´1

δikyj
i p1 ´ pxT
δikp1 ´ pxT

j bjq
j bjq
k via (23), followed by W j

.

µj
k “

iPPj
ř

iPPj

We therefore update µj
Finally,

k using (22).

10

(23)

‰

k xi ´ µOi

k qT pyOi

i ´ W Oi

k xi ´ µOi
k q

IE

kpyOi

i ´ W Oi

k xi ´ µOi

k qT pyOi

i ´ W Oi

k xi ´ µOi
k q

‰

BQ
Bσ2
k

9

´

1
B
Bσ2
σ2
k
k
i ´ W Oi

kpyOi

N log σ2
k

“

ÿ

iPPj
“
IE
B
Bσ2
k
ÿ

iPPj
N
σ2
k
ÿ

´

“

´

1
σ4
k

“ 0

σ2
k “

“
kpyOi

IE

i ´ W Oi
”
pyj

γik

iPPj
ř

ř

j

iPPj

k xi ´ µOi

k qT pyOi

i ´ W Oi

k ´ W j
ř

k

i ´ µj
ř
j

iPPj

pxikq2 ` W j
γik

k xi ´ µOi
k q
ı

k SikpW j

k qT

‰

.

(24)

σ2
k “
‰
k xi ´ µOi
k q

REFERENCES

[1] Komal Kumar Bhatia, Akhila Rao, Anthony N Price, Robin Wolz,
Joseph V Hajnal, and Daniel Rueckert. Hierarchical manifold learning
for regional image analysis. TMI, 33(2):444–461, 2014.

[2] Eyal Carmi, Siuyan Liu, Noga Alon, Amos Fiat, and Daniel Fiat. Resolu-
tion enhancement in MRI. Magnetic resonance imaging, 24(2):133–154,
2006.

[3] Pierrick Coup´e, Jos´e V Manj´on, Vladimir Fonov, Jens Pruessner,
Montserrat Robles, and Louis D Collins. Patch-based segmentation using
expert priors: Application to hippocampus and ventricle segmentation.
NeuroImage, 54(2):940–954, 2011.

[4] Adrian V Dalca, Andreea Bobu, Natalia S Rost, and Polina Golland.
In Interna-
Patch-based discrete registration of clinical brain images.
tional Workshop on Patch-based Techniques in Medical Imaging, pages
60–67. Springer, 2016.

[5] Adrian V Dalca, Katherine L Bouman, William T Freeman, Natalia S
Rost, Mert R Sabuncu, and Polina Golland. Population based image
In Information Processing in Medical Imaging. Springer,
imputation.
2017.

[6] Arthur P Dempster, Nan M Laird, and Donald B Rubin. Maximum
likelihood from incomplete data via the EM algorithm. Journal of the
royal statistical society. Series B (methodological), 39(1):1–38, 1977.

[7] Adriana Di Martino, Chao-Gan Yan, Qingyang Li, Erin Denio, Fran-
cisco X Castellanos, Kaat Alaerts, et al. The autism brain imaging
data exchange: towards a large-scale evaluation of the intrinsic brain
architecture in autism. Molecular psychiatry, 19(6):659–667, 2014.
[8] Chao Dong, Chen Change Loy, Kaiming He, and Xiaoou Tang. Learning
a deep convolutional network for image super-resolution. In European
Conference on Computer Vision, pages 184–199. Springer, 2014.
[9] Michael Elad and Michal Aharon. Image denoising via sparse and redun-
dant representations over learned dictionaries. IEEE TMI, 15(12):3736–
3745, 2006.

[10] William T Freeman, Thouis R Jones, and Egon C Pasztor. Example-
IEEE Computer graphics and Applications,

based super-resolution.
22(2):56–65, 2002.

[11] Daniel Glasner, Shai Bagon, and Michal Irani. Super-resolution from a
single image. In Computer Vision, International Conference on, pages
349–356. IEEE, 2009.

[12] Derek LG Hill, Philipp G Batchelor, Mark Holden, and David J Hawkes.
Medical image registration. Physics in medicine and biology, 46(3):R1,
2001.

11

[13] Juan E Iglesias, Ender Konukoglu, Darko Zikic, Ben Glocker, Koen
Van Leemput, and Bruce Fischl. Is synthesizing mri contrast useful for
inter-modality analysis? MICCAI, LNCS 8149:631–638, 2013.

[14] Alexander Ilin and Tapani Raiko. Practical approaches to principal
component analysis in the presence of missing values. J Mach Learn
Res, 11:1957–2000, 2010.

[15] Clifford R Jack, Matt A Bernstein, Nick C Fox, Paul Thompson,
Gene Alexander, Danielle Harvey, et al. The Alzheimer’s disease
neuroimaging initiative (ADNI): MRI methods. Journal of Magnetic
Resonance Imaging, 27(4):685–691, 2008.
[16] Amod Jog, Aaron Carass, and Jerry L Prince.

Improving magnetic
resonance resolution with supervised learning. In ISBI, pages 987–990.
IEEE, 2014.

[17] Ender Konukoglu, Andre van der Kouwe, Mert R Sabuncu, and Bruce
Fischl. Example-based restoration of high-resolution magnetic resonance
image acquisitions. MICCAI, LNCS 8149:131–138, 2013.

[18] Roderick JA Little and Donald B Rubin. Statistical analysis with missing

data. Wiley, 2014.

[19] Jos´e V Manj´on, Pierrick Coup´e, Antonio Buades, Vladimir Fonov,
D Louis Collins, and Montserrat Robles. Non-local MRI upsampling.
Medical image analysis, 14(6):784–792, 2010.

[20] Jos´e V Manj´on, Pierrick Coup´e, Antonio Buades, D Louis Collins,
and Montserrat Robles. New methods for MRI denoising based on
sparseness and self-similarity. Med. I.A., 16(1):18–27, 2012.

[21] Ozan Oktay, Wenjia Bai, Matthew Lee, Ricardo Guerrero, Konstantinos
Kamnitsas, Jose Caballero, Antonio de Marvao, Stuart Cook, Declan
ORegan, and Daniel Rueckert. Multi-input cardiac image super-
resolution using convolutional neural networks. In International Confer-
ence on Medical Image Computing and Computer-Assisted Intervention,
pages 246–254. Springer, 2016.

[22] Esben Plenge, Dirk HJ Poot, Wiro J Niessen, and Erik Meijering.
Super-resolution reconstruction using cross-scale self-similarity in multi-
slice MRI. MICCAI: Medical Image Computing and Computer-Assisted
Intervention, LNCS 8151:123–130, 2013.

[23] Natalia S Rost, Kaitlin Fitzpatrick, Alessandro Bifﬁ, Allison Kanakis,
William Devan, Christopher D Anderson, Lynelle Cortellini, Karen L
Furie, and Jonathan Rosand. White matter hyperintensity burden and
susceptibility to cerebral ischemia. Stroke, 41(12):2807–2811, 2010.

[24] Francois Rousseau, Piotr A Habas, and Colin Studholme. A supervised
patch-based approach for human brain labeling. IEEE Tran. Med. Imag.,
30(10):1852–1862, 2011.

[25] Franc¸ois Rousseau, Alzheimers Disease Neuroimaging Initiative, et al.
A non-local approach for image super-resolution using intermodality
priors. Medical image analysis, 14(4):594–605, 2010.

[26] Franc¸ois Rousseau, Kio Kim, and Colin Studholme. A groupwise super-
resolution approach: application to brain MRI. In ISBI, pages 860–863.
IEEE, 2010.

[27] Paul Schmidt, Christian Gaser, Milan Arsic, Dorothea Buck, Annette
F¨orschler, Achim Berthele, Muna Hoshi, R¨udiger Ilg, Volker J Schmid,
Claus Zimmer, et al. An automated tool for detection of ﬂair-
hyperintense white-matter lesions in multiple sclerosis. Neuroimage,
59(4):3774–3783, 2012.

[28] Isaac Jacob Schoenberg. Cardinal spline interpolation. 12. SIAM, 1973.
[29] Florent S´egonne, Anders M Dale, Evelina Busa, Maureen Glessner,
David Salat, Horst K Hahn, and Bruce Fischl. A hybrid approach to the
skull stripping problem in MRI. Neuroimage, 22(3):1060–1075, 2004.
[30] Wenzhe Shi, Jose Caballero, Christian Ledig, Xiahai Zhuang, Wenjia
Bai, et al. Cardiac image super-resolution with global correspondence
using multi-atlas patchmatch. MICCAI: Medical Image Computing and
Computer-Assisted Intervention, LNCS 8151:9–16, 2013.

[31] Ramesh Sridharan, Adrian V Dalca, Kaitlin M Fitzpatrick, Lisa Cloonan,
Allison Kanakis, Ona Wu, et al. Quantiﬁcation and analysis of large
multimodal clinical image studies: Application to stroke. MICCAI -
MBIA Workshop, LNCS 8159:18–30, 2013.

[32] Koen Van Leemput, Frederik Maes, Dirk Vandermeulen, Alan Colch-
ester, and Paul Suetens. Automated segmentation of multiple sclerosis
IEEE transactions on medical
lesions by model outlier detection.
imaging, 20(8):677–688, 2001.

[33] Jianchao Yang, John Wright, Thomas S Huang, and Yi Ma.

Image
super-resolution via sparse representation. IEEE Transactions on Image
Processing, 19(11):2861–2873, 2010.

[34] Ruoqiao Zhang, Charles A Bouman, Jean-Baptiste Thibault, and Ken D
Sauer. Gaussian mixture markov random ﬁeld for image denoising and
reconstruction. In IEEE Global Conference on Signal and Information
Processing (GlobalSIP), pages 1089–1092. IEEE, 2013.

[35] Daniel Zoran and Yair Weiss. From learning models of natural image
patches to whole image restoration. In Computer Vision (ICCV), 2011
IEEE International Conference on, pages 479–486. IEEE, 2011.
[36] Daniel Zoran and Yair Weiss. Natural images, gaussian mixtures and
In Advances in Neural Information Processing Systems,

dead leaves.
pages 1736–1744, 2012.

SUPPLEMENTARY MATERIAL

DERIVATION OF ALTERNATIVE MODEL
In this section, we explore the parameter estimation for
an alternative model. Speciﬁcally, letting Mi be the set of
missing voxels of patch yi, we treat yMi
as latent variables,
instead of explicitly modeling a low-dimensional representa-
tion x. We show the maximum likelihood updates of the model
parameters under the likelihood (5). We employ the Expecta-
tion Conditional Maximization (ECM) [14], [18] variant of
the Generalized Expectation Maximization, where parameter
updates depend on the previous parameter estimates.

i

The complete data likelihood is
ź

ÿ

ppY; θq “

πkN pyOi
i

, yMi
i

; µOi

k , ΣOiOi
k

q.

(25)

i

k

The expectation step updates the statistics of the missing
data, computed based on covariates of the known and unknown
voxels:

γik ” IErkis

ř

“

πkN pyOi
i
k πkN pyOi
i

; µOi

k , ΣOi
k q
k , ΣOi
; µOi
k q

pyij ” IEryijs
#
yij
µij ` ΣjOi

“

i

pΣOiOi
i

q´1pyOi

i ´ µOiq otherwise

if yij
is observed

(26)

(27)

psijl ” IE ryijyils ´ IEryijsIEryils

#

“

0
i ´ pΣOij
Σjl

i

qT pΣOiOi
i

q´1ΣOil

i

if yij or yil
is observed
otherwise

(28)
where the correction in psijl can be interpreted as the uncer-
tainty in the covariance estimation due to the missing values.

12

(29)

(30)

(31)

Given estimates for the missing data, the maximization step
leads to familiar Gaussian Mixture Model parameters updates:

γik

ppyik ´ µkqppyik ´ µkqT ` ST
i

‰

.

µk “

Σk “

ÿ

i
ÿ

γik pyik

“

1
γik
1
γik
1
N

i
ÿ

i

πk “

γik

where rSisjl “ psijl.

In additional to the latent missing voxels, we can still model
each patch as coming from a low dimensional representation.
We form Ck “ WkW T
kI as in (3), leading to the complete
data likelihood:

k `σ2

ppY; θq “

πkN pyOi
i

, yMi
i

; µOi

k , C OiOi
k

q.

(32)

ź

ÿ

i

k

The expectation steps are then unchanged from (26)-(28)
with Ck replacing Σk. The maximization steps are unchanged
from (29)-(31), with Σk now the empirical covariance in (30).
We let U ΛV T “ SVDpΣkq be the singular value decomposi-
tion of Σk, leading to the low dimensional updates

σ2
k Ð

1
d ´ q

dÿ

j“d`1

Λpj, jq

Wk Ð U pΛ ´ σ2Iq1{2.

(33)

(34)

Finally, we let Ck “ WkW T

k ` σ2
Unfortunately, both learning procedures involve estimating
all of the missing voxel covariances, leading to a large and
unstable optimization.

kI.

13

Fig. 11: Additional restorations in the ADNI dataset. Reconstruction by NLM, linear interpolation, and our method, and the original high resolution images.

14

Fig. 12: Additional restorations in the clinical dataset. Reconstruction using NLM, linear interpolation and our method.

