9
1
0
2
 
t
c
O
9

 

 
 
]
L
M

.
t
a
t
s
[
 
 
1
v
9
0
1
4
0
.
0
1
9
1
:
v
i
X
r
a

Optimal Training of Fair Predictive Models

Razieh Nabi, Daniel Malinsky, Ilya Shpitser
Department of Computer Science,
Johns Hopkins University, Baltimore, MD, USA
(rnabi@, malinsky@, ilyas@cs.)jhu.edu

Abstract

Recently there has been sustained interest
in modifying prediction algorithms to sat-
isfy fairness constraints. These constraints
are typically complex nonlinear functionals
of the observed data distribution. Focus-
ing on the causal constraints proposed by
Nabi and Shpitser (2018), we introduce new
theoretical results and optimization tech-
niques to make model training easier and
more accurate. Speciﬁcally, we show how
to reparameterize the observed data likeli-
hood such that fairness constraints corre-
spond directly to parameters that appear in
the likelihood, transforming a complex con-
strained optimization objective into a simple
optimization problem with box constraints.
We also exploit methods from empirical like-
lihood theory in statistics to improve predic-
tive performance, without requiring paramet-
ric models for high-dimensional feature vec-
tors.

1

INTRODUCTION

Predictive models trained on imperfect data are in-
creasingly being used in socially-impactful settings.
Predictions (such as risk scores) have been used
to inform high-stakes decisions in criminal
justice
(Perry et al., 2013), healthcare (Kappen et al., 2018),
and ﬁnance (Khandani et al., 2010). While automa-
tion may bring many potential beneﬁts – such as speed
and accuracy – it is also fraught with risks. Predictive
models introduce two dangers in particular: the illu-
sion of objectivity and violation of fairness norms. Pre-
dictive models may appear to be “neutral,” since hu-
mans are less involved and because they are products
of a seemingly impartial optimization process. How-

ever, predictive models are trained on data that re-
ﬂects the structural inequities, historical disparities,
and other imperfections of our society. Often data
includes sensitive attributes (e.g., race, gender, age,
disability status), or proxies for such attributes. A
particular worry in the context of data-driven decision-
making is “perpetuating injustice,” which occurs when
unfair dependence between sensitive features and out-
comes is maintained, introduced, or reinforced by au-
tomated tools.

We study how to construct fair predictive models by
correcting for the unfair causal dependence of pre-
dicted outcomes on sensitive features. We work with
the proposed fairness criteria in Nabi and Shpitser
(2018), where the authors propose that fair predic-
tion requires imposing hard constraints on the pre-
diction problem in the form of restricting certain
causal path-speciﬁc eﬀects.
Impermissible pathways
are user-speciﬁed and context-speciﬁc, hence require
input from policymakers, legal experts, or the gen-
Some alternative but also causally-
eral public.
motivated constrained prediction methods are pro-
posed in Chiappa (2019); Kusner et al. (2017a) and
Zhang and Bareinboim (2018). For a survey and dis-
cussion of distinct fairness criteria (both causal and
associative) see Mitchell et al. (2018).

We advance the state of the art in two ways. First, we
give a novel reparameterization of the observed data
likelihood in which unfair path-speciﬁc eﬀects appear
directly as parameters. This allows us to greatly sim-
plify the constrained optimization problem, which has
previously required complex or ineﬃcient algorithms.
Second, we demonstrate how tools from the empir-
ical likelihood literature (Owen, 2001) can be read-
ily adapted to construct hybrid (semi-parametric) ob-
served data likelihoods that satisfy given fairness cri-
teria. With this approach, the entire likelihood is con-
strained, rather than only part of the likelihood as in
past proposals (Nabi and Shpitser, 2018). As a result,
we use the data more eﬃciently and achieve better
performance. Finally, we show how both innovations

may be combined into a single procedure.

As a guiding example, we consider a setting such as
automated hiring, in which we want to predict job suc-
cess from applicant data. We have historical data on
job success, resumes, and demographics, as well as new
individuals for which we only see resumes and demo-
graphics for whom we would like to estimate a risk
score with our predictive model. This may be consid-
ered a variant of semi-supervised learning or prediction
with missing labels on a subset of the population. We
aim to estimate those scores subject to path-speciﬁc
fairness constraints. In order to describe the various
components of this proposal, we must review some
background on causal inference, path-speciﬁc eﬀects,
and constrained prediction.

2 CAUSAL INFERENCE AND A
CAUSAL APPROACH TO
FAIRNESS

Causal inference is concerned with quantities which
describe the consequences of interventions. Causal
models are often represented graphically, e.g. by di-
rected acyclic graphs (DAGs). We will use capital let-
ters (V ) to denote sets of random variables as well
as corresponding vertices in graphs and lowercase let-
ters (v) to denote values or assignments to those ran-
dom variables. A DAG consists of a set of vertices
V connected by directed edges (Vi → Vj for some
{Vi, Vj} ⊆ V ) such that there are no cycles. The set
paG(Vi) ≡ {Vj ∈ V | Vj → Vi} denotes the parents of
Vi in DAG G. XA denotes the statespace of A ⊆ V .

A causal model of a DAG G is a set of distributions
deﬁned on potential outcomes (a.k.a. counterfactuals).
For example, we consider distributions p(V (a)) sub-
ject to some restrictions, where V (a) represents the
value of V had all variables in paG(V ) been set, pos-
sibly contrary to fact, to value a.
In this paper, we
assume Pearl’s functional model (Pearl, 2009) for a
DAG G which stipulates that the sets of potential out-
come variables
(cid:9)
are mutually independent. All other counterfactuals
may be deﬁned using recursive substitution. For any
A ⊆ V \ {Vi},

{Vi(ai) | ai ∈ XpaG(Vi)} | Vi ∈ V

(cid:8)

Vi(a) ≡ Vi(apaG (Vi)∩A, {Vj(a) : Vj ∈ paG(Vi) \ A}),

where {Vj(a) : Vj ∈ paG(Vi) \ A} is taken to mean
the (recursively deﬁned) set of counterfactuals associ-
ated with variables in paG(Vi) \ A, had A been set to
a. Equivalently, Pearl’s model may be described by
a system of nonparametric structural equations with
independent errors.

A causal parameter is said to be identiﬁed in a causal

model if it is a function of the observed data distri-
bution p(V ). In the functional model of a DAG G (as
well as some weaker causal models), all interventional
distributions p(V (a)), for any A ⊆ V , are identiﬁed by
the extended g-formula:

p(V (a)) =

Y
Vi∈V

p(Vi| paG(Vi))
(cid:12)
(cid:12)

A=a .

consider

the DAG in Fig. 1(a).
For example,
Y (a) is deﬁned to be Y (a, M (a, X), X) by recur-
sive substitution and its distribution is identiﬁed as
PX,M p(Y |a, M, X)p(M |a, X)p(X). The mean diﬀer-
ence between Y (a) and Y (a′) for some treatment value
a of interest and reference value a′ is E[Y (a)]−E[Y (a′)]
and quantiﬁes the average causal eﬀect of treatment A
on the outcome Y .

2.1 Mediation Analysis and Path-Speciﬁc

Eﬀects

An important goal in causal inference is to understand
the mechanisms by which some treatment A inﬂuences
some outcome Y . A common framework for studying
mechanisms is mediation analysis which seeks to de-
compose the eﬀect of A on Y into the direct eﬀect
and the indirect eﬀect mediated by a third variable, or
more generally into components associated with par-
ticular causal pathways. As an example, the direct
eﬀect of A on Y in Fig. 1(a) corresponds to the eﬀect
along the edge A → Y and the indirect eﬀect corre-
sponds to the eﬀect along the path A → M → Y ,
mediated by M .

In the potential outcome notation, the direct and in-
direct eﬀects can be deﬁned using nested counterfac-
tuals such as Y (a, M (a′)) for a, a′ ∈ XA, which de-
notes the value of Y when A is set to a while M is set
to whatever value it would have attained had A been
set to a′. Given p(a, M (a′)), the natural direct eﬀect
(NDE) (on the expectation diﬀerence scale) is deﬁned
as E[Y (a, M (a′))] − E[Y (a′)], and the natural indirect
eﬀect (NID) is deﬁned as E[Y (a)] − E[Y (a, M (a′))].
Under certain identiﬁcation assumptions discussed by
(Pearl, 2001), the distribution of Y (a, M (a′)) (and
thereby direct and indirect eﬀects) can be nonparamet-
rically identiﬁed from observed data by the following
formula:

p(Y (a, M (a′)) =

p(Y | a, X, M ) p(M | a′, X) p(X).

XX,M

More generally, when there are multiple pathways from
A to Y one may deﬁne various path-speciﬁc eﬀects
(PSEs).
In this case, eﬀect along a particular path
will be obtained by comparing two potential outcomes,
one where for the selected paths all nodes behave as
if A = a, and along all other paths nodes behave as if
A = a′.

PSEs are deﬁned by means of nested, path-speciﬁc po-
tential outcomes. Fix a set of treatment variables A,
and a subset of proper causal paths π from any ele-
ment in A. A proper causal path only intersects A
at the source node. Next, pick a pair of value sets
a and a′ for elements in A. For any Vi ∈ V , deﬁne
the potential outcome Vi(π, a, a′) by setting A to a
for the purposes of paths in π, and to a′ for the pur-
poses of proper causal paths from A to Y not in π.
Formally, the deﬁnition is as follows, for any Vi ∈ V ,
Vi(π, a, a′) ≡ a if Vi ∈ A, otherwise

Vi(π, a, a′) ≡Vi

Vj (π, a, a′) | Vj ∈ paπ

G(Vi)

,

(cid:16)(cid:8)

(cid:9)
Vj(a′) | Vj ∈ paπ
G(Vi)

(1)

(cid:9)(cid:17)

(cid:8)
where Vj (a′) ≡ a′ if Vj ∈ A, and given by recursive
substitution otherwise, paπ
G(Vi) is the set of parents of
Vi along an edge which is a part of a path in π, and
paπ

G(Vi) is the set of all other parents of Vi.

A counterfactual Vi(π, a, a′) is said to be edge in-
consistent if counterfactuals of the form Vj(ak, . . .)
k, . . .) occur in Vi(π, a, a′), otherwise it is
and Vj(a′
said to be edge consistent.
It is well known that a
joint distribution p(V (π, a, a′)) containing an edge-
inconsistent counterfactual Vi(π, a, a′) is not identi-
ﬁed in the functional causal model (nor weaker causal
models) with a corresponding graphical criterion on
π and G(V ) called the ‘recanting witness’ (Shpitser,
2013; Shpitser and Tchetgen Tchetgen, 2016). Under
some assumptions, PSEs are nonparametrically iden-
tiﬁed by means of the edge g-formula described in
Shpitser and Tchetgen Tchetgen (2016).

As an example, consider the DAG in Fig. 1(b). The
PSE of A on Y along the paths π = {A → Y, A → L →
Y } is encoded by a counterfactual contrast of the form
Y (π, a, a′) = Y (a, M (a′), L(a, M (a′))). This counter-
factual density is identiﬁed by the edge g-formula as
follows:

p(Y (a, M (a′), L(a, M (a′))) =

p(Y | a, X, M ) p(L | a, M, X) p(M | a′, X) p(X).

XX,M,L

For more details on PSEs,
andShpitser and Sherman (2018),
(2018).

see Shpitser

(2013)
and Nabi et al.

2.2 Algorithmic Fairness via Constraining

Path-Speciﬁc Eﬀects

fairness

in machine

There has been a growing interest in the issue
learning (Pedreshi et al.,
of
2008; Feldman et al.,
2016;
Corbett-Davies et al.,
Kamiran et al.,
2017; Jabbari et al.,
2017b;
Zhang and Bareinboim, 2018; Zhang et al., 2017). In
this paper, we adopt the causal notion of fairness

2017; Kusner et al.,

2015; Hardt et al.,

2013;

described in Nabi and Shpitser (2018) and Nabi et al.
(2019), where unfairness corresponds to the presence
of undesirable or impermissble path-speciﬁc eﬀects
of sensitive attributes on outcomes – a view which
generalizes an example discussed in Pearl (2009).
We provide a brief summary of their perspective on
fairness in the following without defending it for lack
of space; see Nabi and Shpitser for more details.

Consider an observed data distribution p(Y, Z) in-
duced by a causal model, where Y is an outcome
and Z = {X, A, M } includes all baseline factors X,
sensitive features A, and post-treatment pre-outcome
mediators M . Context and background ethical con-
siderations pick out some path-speciﬁc eﬀect of the
sensitive feature A on the outcome Y as unfair; we as-
sume this eﬀect is identiﬁed as a functional g(p(Y, Z)).
Fix upper and lower bounds ǫl, ǫu for the PSE, repre-
senting a tolerable range. The most relevant bounds
in practice are ǫl = ǫu = 0 or approximately zero.
Nabi and Shpitser propose to transform the inference
problem on p(Y, Z), the “unfair world,” into an infer-
ence problem on another distribution p∗(Y, Z), called
the “fair world,” which is close in the sense of min-
imal KL-divergence to p(Y, Z) while also having the
property that the PSE lies within (ǫl, ǫu).

Given a dataset D = {(Yi, Zi), i = 1, . . . , n} drawn
from p(Y, Z), a likelihood function L(D; α), an es-
timator
g(D) of the unfair PSE, and bounds ǫl, ǫu,
Nabi and Shpitser suggest to approximate p∗(Y, Z) by
b
solving the following constrained maximum likelihood
problem:

α = arg max

LY,Z (D; α),

α

subject to ǫl ≤
b

g(D) ≤ ǫu.

(2)

b

b

Having approximated the fair world p∗(Y, Z;
α) in
this way, Nabi and Shpitser point out a key diﬃ-
culty for using these estimated parameters to pre-
dict outcomes for new instances (e.g., new job ap-
plicants). A new set of observations Z is not sam-
pled from the “fair world” p∗(Z) but from “unfair
world” p(Z). Nabi and Shpitser propose to map new
instances from p to p∗ and to use the result for predict-
ing Y with model parameters
α. They assume Z can
be partitioned into Z1 and Z2 such that p∗(Y, Z) =
p∗(Y, Z1|Z2)p(Z2).
In other words, variables in Z2
are shared between p and p∗: p∗(Z2) = p(Z2) but
p∗(Z1|Z2) 6= p(Z1|Z2). Z1 typically corresponds to
variables that appear in the estimator
g(D). There is
no obvious principled way of knowing exactly what val-
ues of Z1 the “fair version” of the new instance would
attain. Consequently, all such possible values are av-
eraged out, weighted appropriately by how likely they
are according to the estimated p∗. This entails predict-
ing Y as the expected value E∗[Y |Z2] (with respect to
PZ1 p∗(Y, Z1|Z2)).
the distribution

b

b

A

Y

A

Y

X

M

(a)

X

M

U

L

(b)

(a) A simple causal DAG, with treatment
Figure 1:
A, outcome Y , baseline variables X, and a mediator
M. (b) A causal graph with two mediators M and L
and unmeasured confounders captured in U .

Next, we explain some limitations of the inference pro-
cedure described here and present our main contribu-
tions to address these limitations.

3 FAIR PREDICTIVE MODELS IN

A BATCH SETTING

Prediction problems in machine learning are typi-
cally tackled from the perspective of nonparametric
risk minimization and the “train-and-test” framework.
Here, we instead take the perspective of maximum like-
lihood and missing data, i.e., we treat unknown out-
comes as missing values which we hope to impute in
a way that is consistent with our speciﬁed likelihood
for the entire data set. Our motivation for doing so
is the nature of our constrained prediction problem.
Speciﬁcally, our causal constraints contain “nuisance”
components (conditional expectations and conditional
distributions derived from the observed data distribu-
tion) which must be modeled correctly to ensure the
causal eﬀects are reliably estimated. In the subsequent
prediction step, we should predict in a way that is con-
sistent with what has already been modeled – or else
we fail to exploit all the information we have already
committed to in the constraint estimation step. We
chose the maximum likelihood framework as the most
natural and simplest approach to accomplish this. Al-
ternative methods for coherently combining nuisance
estimation with nonparametric risk minimization are
left to future work.

Unlike Nabi and Shpitser (2018), we consider a batch
prediction setting – this allows us to avoid the in-
eﬃcient averaging described in the previous section.
In our case, historical data (of sample size n1) con-
sists of observations on {X, A, M, Y } and new in-
stances (of size n2) comprise a set of observations
with just {X, A, M }. The outcome labels for new in-
stances are missing data which we aim to predict, sub-
ject to fairness constraints.
Instead of training our
constrained model on historical data alone, we train
on the combination of historical data and new in-
stances. This seems complicated since the observed

data likelihood for the combined data set includes
some complete rows and some partially incomplete
rows. However, we can borrow ideas from the liter-
ature on missing data to accomplish this task. Specif-
ically, we can impute missing outcomes (“labels”) us-
ing appropriate functions of observed data.
In this
paper we assume the labels are missing at random
(MAR) (Little and Rubin, 2002). However, our meth-
ods extend to any identiﬁable missing not at random
(MNAR) model. Let the random variable R denote the
missingness status of the outcome variable Y for each
instance. That is, R = 1 for all rows in the historical
data (since Y is observed) and R = 0 for all rows in
the new instances. Then the observed data likelihood
is

p(Xi, Ai, Mi) p(Yi|Xi, Ai, Mi)Ri .

n=n1+n2
i=1

Q

This likelihood function describes the probability of
the entire data set, though only uses Y values from
historical data. We can then maximize the likelihood
subject to the speciﬁed path-speciﬁc constraints, and
associate predicted values ˆYnew to the new instances.
Note that the setting where new instances arrive se-
quentially one-at-a-time is a special case of this general
setup, which would require retraining on the full com-
bined data after the arrival of each instance. Though
this is computationally more intensive than the pro-
posal in Nabi and Shpitser (2018) (where they only
train once), it will deliver signiﬁcantly more accurate
predictions because it uses all available information.
We will elaborate on this point in Section 4.

suﬀers

(2018)

approach to

fair prediction outlined in
The
Nabi and Shpitser
from two prob-
lems: one general and one speciﬁc to our setting here.
First, their approach requires solving a computation-
ally challenging constrained optimization problem.
Likelihood functions are not in general convex and the
constraints on path-speciﬁc eﬀects involve nonlinear
and complicated functionals of the observed data
distribution. This makes the proposed constrained
optimization a daunting task that relies on complex
optimization software (or computationally expensive
methods such as rejection sampling), which does
not always ﬁnd high quality local optima. Second,
Nabi and Shpitser propose to constrain only part of
the likelihood. Speciﬁcally they do not constrain the
density p(X) over the baseline features (since this is
high-dimensional and thus inplausible to model ac-
curately in their parametric approach). The baseline
density is instead estimated by placing 1/n mass at
every observed data point. This is sub-optimal in the
speciﬁc setting we consider, where we do not need
to average over constrained variables. Constraining
a larger part of the joint should lead to a fair world
distribution KL-closer to the observed distribution,
which leads to better predictive performance as long

as the likelihood is correctly speciﬁed. This intuition
is formalized in the following result:

p(Z)

Theorem 1 Let
denote
served data distribution, M1 =
arg maxq(Z) DKL(p||q) s.t. ǫl
ǫu,
q(Z1) = p(Z1)
arg maxq(Z) DKL(p||q) s.t. ǫl
ǫu, q(Z2) = p(Z2)
DKL(p||p∗

the
ob-
p∗
1(Z) =
g(q(Z))
≤
p∗
2(Z) =
(cid:8)
≤
g(q(Z))
then
If Z2 ⊆ Z1 ⊆ Z,

, and M2 =

2) ≤ DKL(p||p∗

1).

≤

≤

(cid:8)

(cid:9)

(cid:9)

.

In other words, if a larger part of the joint is being
constrained in M2 compared to M1, then p∗
2(Z) is at
least as close to p(Z) as p∗

1(Z).

To address the ﬁrst diﬃculty, we provide a novel repa-
rameterization of the observed data likelihood such
that the causal parameter corresponding to the un-
fair PSE appears directly in the likelihood. This ap-
proach generalizes previous work on reparameteriza-
tions implied by structural nested models (Robins,
1999; Tchetgen Tchetgen and Shpitser, 2014) to apply
to a wide class of PSEs. With such a reparameteriza-
tion, the MLE with a constrained PSE simply corre-
sponds to maximum likelihood inference in a submodel
where a certain likelihood parameter is set to 0. This
type of inference can be implemented with standard
software.

To address the second diﬃculty, we propose an ap-
proach to constraining the density p(X). An alterna-
tive to fully parametric modeling is to consider non-
parametric representations of p(X). It is well known
that the nonparametric maximum likelihood estimate
of any p(X) given a set of i.i.d draws is the empirical
distribution which places mass 1/n at every observed
point. Empirical likelihood methods have been devel-
oped for settings where the nonparametric and para-
metric (hybrid) likelihood must be maximized subject
to moment constraints (Owen, 2001). We describe be-
low how these methods may be adapted to our setting.

Finally, we show how both the reparameterization
method and the empirical likelihood method can be
combined to yield a constrained optimization method
that maximizes a semi-parametric (hybrid reparame-
terized) likelihood using standard software.

4 EFFICIENT APPROXIMATION

OF FAIR WORLDS

4.1 Imposing Fairness Constraints With
Reparameterized Likelihoods

In this section, we describe how to reparameterize the
observed data likelihood in terms of causal parame-
ters that correspond to the eﬀect of A on Y along cer-

tain causal pathways. The results presented in the fol-
lowing theorem greatly simpliﬁes the constrained op-
timization problem shown in (2) in settings where the
PSE includes the direct inﬂuence of A on Y . This is
due to the fact that the constrained parameter, cor-
responding to the PSE of interest, now appears as a
single coeﬃcient in the outcome regression model.

Theorem 2 Assume the observed data distribution
p(Y, Z) is induced by a causal model, where Z =
{X, A, M } includes pre-treatment measures X, treat-
ment A, and post-treatment pre-outcome mediators M .
Let p(Y (π, a, a′)) denote the potential outcome distri-
bution that corresponds to the eﬀect of A on Y along
proper causal paths in π, where π includes the direct
inﬂuence of A on Y , and let p(Y0(π, a, a′)) denote the
identifying functional for p(Y (π, a, a′)) obtained from
the edge-formula in (1), where the term p(Y |Z) is eval-
uated at {Z \ A} = 0. Then E[Y |Z] can be written as
follows:

E[Y |Z] = f (Z) −

E[Y (π, a, a′)] − E[Y0(π, a, a′)]
(cid:1)
(cid:0)

+ φ(A),

where f (Z) := E[Y |Z] − E[Y |A, {Z \ A} = 0] and
φ(A) = w0 + waA. Furthermore, wa corresponds to
π-speciﬁc eﬀect of A on Y .

To illustrate the above reparameterization, consider
the graph in Fig. 1(b), discussed in Nabi and Shpitser
(2018) and Chiappa (2019). Assume the direct path
and the paths through M of A on Y are the impermis-
sible pathways (depicted with green edges). The corre-
sponding PSE is encoded by a counterfactual contrast
with respect to Y (a, M (a), L(a′, M (a))). The reparam-
eterization in Theorem 2 amounts to:

E[Y |Z] = f (Z) −

f (Z) × p(L|M, X, A = 0)×

XZ\A (cid:8)

p(M |X, A = 1) × p(X)

+ w0 + waA,

(3)

(cid:9)

where wa represents the PSE of interest; see the
appendix for more details. A special case of this
reparameterization when π includes only the di-
rect edge A → Y is implicit in the work of
Tchetgen Tchetgen and Shpitser (2014).

Under linearity assumptions, the PSE of interest in
Fig. 1(b) has a simple form. Assume the data gen-
erating process in Fig. 1(b) is the same as the one
given in display (2) of Chiappa (2019), where PSE =
θy
l θl
a + θy
a . In this case, our reparameteriza-
tion takes the following form:

a + θy

mθm

mθm

E[Y |X, A, M, L] =

xX + θy
θy

mM + θy

l L

−

(cid:16)

(cid:17)

0 θy
θm

m + (θl

0 + θl

|
mθm

0 )θy

l

}
l θl
a + θy

mθm
a

f (Z)
{z

+

mθm
θy
(cid:0)

(cid:1)

+

A
(cid:1)

(cid:17)

f (Z)p(L|M,X,A=0)p(M |X,A=1)p(X)

PZ\A

0 θy
θm

(cid:8)
m +(θl

0 +θl

mθm

{z
0 )θy

l

(cid:9)
a +θy

mθm

l θl

}
mθm
a

+

a +θy
θy
(cid:0)

(cid:1)

}

|

wa≡PSE
{z

A
(cid:17)
(cid:1)

}

w0
{z

(cid:16)(cid:0)

|
θy
0 +
(cid:16)

(cid:0)

|

In order to move away from the linear setting and ex-
ploit more ﬂexible techniques, Chiappa (2019) makes
assumptions on the latent variables. However, such
assumptions are often hard to verify in practice.
In
contrast, our result is entirely nonparametric and does
not rely on any assumptions beyond what is encoded
in the causal DAG.

By Theorem 2, the constrained optimization problem
in eq. (2) simpliﬁes signiﬁcantly to the following opti-
mization problem:

α = arg max

LY,Z(D; α)

subject to wa = 0.

(4)

α

b

In the prediction setting, i.e., ﬁnding optimal parame-
ters for E[Y |Z; αy], this amounts to an unconstrained
maximum likelihood problem with outcome regression
taking the speciﬁc form:

f (Z; αf ) −

f (Z; αf ) p(M |A = 0, X; αm) p(X) + w0,

(5)

E[Y |Z; αy] =

XX,M

where f (Z) := E[Y |Z] − E[Y |A, X = 0, M = 0] and
is parameterized by αf .
In practice, for each Xi in
the data p(Xi) is replaced with its empirical approx-
imation 1/n, since a parametric speciﬁcation of p(X)
is not feasible. In next section, we explain how p(X)
can be incorporated into the constrained optimization
problem using empirical likelihood methods.

then be identiﬁed by Ex[m(X; α)], where

m(X; α) =

E[Y |A = 1, M, X; αy]−

(6)

XM n

E[Y |A = 0, M, X; αy]

p(M |A = 0, X; αm).

o

likelihood ratio parameters

The proﬁle empirical
({pi,

α}opt) are then given by
b

arg max
pi,α

n

Yi=1

pip(Yi|Mi,Ai,Xi;αy)p(Mi|Ai,Xi;αm)p(A|Xi;αa)

such that

pi = 1,

pi m(Xi; α) = 0

(7)

n

Xi=1

n

Xi=1

The above optimization problem involves a semi-
parametric hybrid likelihood (Owen, 2001), that con-
tains both nonparametric and parametric terms.
In
order to solve the above optimization problem (formu-
lated on both α and pi parameters), we can apply the
Lagrange multiplier method and solve its dual form
(formulated on both α and the Lagrange multipliers);
see the appendix for more details. Empirical likelihood
methods provide a natural extension to imposing con-
straints on arbitrary PSEs, since these can be written
in the form of Ex[m(X; α)] for some m(·).
If outcomes are missing at random, the NDE is iden-
tiﬁed by Ex[m(X; α)], where

4.2 Imposing Fairness Constraints With

m(X; α) =

E[Y |A = 1, M, X, R = 1; αy]−

Hybrid Likelihoods

XM n

In light of Theorem 1, we are interested in constrain-
ing the nonparameteric form of p(X). Following work
in Owen (2001), we use hybrid/semi-parametric em-
pirical likelihood methods to estimate p(X) nonpara-
metrically which is a novel idea in the fairness set-
ting. First, according to Theorem 1, constraining p(X)
would bring our learned distribution closer to the ob-
served (unfair) distribution, and hence results in im-
provement of model performance, as we demonstrate
in our simulations. Second, p(X) is often a high di-
mensional object that is diﬃcult to estimate due to the
curse of dimensionality. For simplicity of presentation,
we focus on the DAG in Fig. 1(a), and the constraint
represented by the NDE, although the methods we de-
scribe generalize without diﬃculty to arbitrary causal
models and constraints represented by arbitrary PSEs.

Let (Xi, Ai, Mi, Yi), i = 1, . . . , n be independent ran-
dom vectors with common distribution p = p(X) ×
p(A, M, Y |X). We assume a known parametric form
for p(A, M, Y |X), and leave p(X) unrestricted. As-
suming the unfair eﬀect is NDE, the only constraint
on the observed distribution is for NDE to be zero.
Let p(Y |M, A, X), p(M |A, X), p(A|X) be parameter-
ized by αy, αm, αa, respectively. The direct eﬀect can

E[Y |A = 0, M, X, R = 1; αy]

p(M |A = 0, X; αm).

o

The resulting functional is then used in the proﬁle em-
pirical likelihood in (7).

Unlike the standard unconstrained prediction setting
where it is common to use nonparametric methods to
estimate an arbitrary regression function, our task re-
quires a combination of prediction and estimation of
the relevant causal parameter (constraint). Estimat-
ing the causal parameter requires estimating certain
nuisance components (like E[Y |Z] in eq. 6) which we
choose to do parametrically in part because we de-
sire certain frequentist properties, namely fast rates
of convergence. More fundamentally, the empirical
likelihood optimization problem in (7) ﬁnds optimal
parameter values α, where α appears also in the con-
Pi pim(Xi; pi, α) = 0. That is, the structure
straint
of the empirical likelihood optimization problem re-
quires that Y and M models are speciﬁed paramet-
rically. Though some combination of nonparametric
risk minimization and empirical likelihood would be
an interesting extension, how to accomplish this is an
open question.

4.3 Imposing Fairness Constraints With
Hybrid Reparameterized Likelihoods

In Section 4.1, we reformulated the constrained opti-
mization problem of interest by rewriting the likeli-
hood in terms of the parameters we were interested
in constraining, and directly setting those parameters
to zero. However, we did not place any constraints
on p(X).
In Section 4.2, we used hybrid likelihoods
to constrain a nonparametric estimate of p(X), but
did not provide a convenient reparameterization of the
likelihood in terms of relevant parameters. In this sec-
tion we describe an approach to optimizing a hybrid
reparameterized likelihood that combines the advan-
tages of both proposals. This allows us to constrain
the entire likelihood and do so with standard maxi-
mum likelihood software, since the constraint we must
satisfy directly corresponds to a parameter in the hy-
brid likelihood.

For simplicity of presentation, we again focus on the
constraining the NDE, although the methods we de-
scribe generalize without diﬃculty to arbitrary con-
straints represented by arbitrary PSEs. The direct
eﬀect can then be estimated by Ex[m(X; α)], where
m(X; α) is given in (6), and E[Y |A, M, X; αy] is given
in (5). Assuming p(Xi = xi) = pi as in (5), m(X; α)
will be a function of pis as well. The proﬁle empirical
α}opt) in this setting is then given
likelihood ratio ({pi,
by
b

pip(Yi|Mi,Ai,Xi;αy)p(Mi|Ai,Xi;αm)p(A|Xi;αa)

arg max
pi,α

n

Yi=1

such that

pi = 1,

pi m(Xi; pi, α) = 0

(8)

n

Xi=1

n

Xi=1

Unlike the constrained optimization problem in (7), it
is not straightforward to ﬁnd the dual form of the opti-
mization problem in (8), which is a standard approach
for solving such problems in the empirical likelihood
literature. The reason is that pi appears in multiple
places in the constraint corresponding to setting PSE
to zero; that is m(X; α) is now a function of both α
and pi’s. As an alternative, we provide a heuristic ap-
proach for optimizing (8) via an iterative procedure
that starts with initialization of α and pis, and at the
kth iteration updates the values for αk and pk
i s by
treating m(Xi; pi, α) as a function of m(Xi; pk−1
, α).
The procedure terminates when the diﬀerence between
the two updates is suﬃciently small. In Algorithm 1,
we provide a detailed description of our proposed it-
erative procedure to address this issue, which behaves
well in experiments.

i

5 EXPERIMENTS

Given Theorem 1, the accuracy of the prediction pro-
cedure depends on what components of p(Z, Y ; α) are

Algorithm 1 Hybrid Reparameterized Likeli-
hood

Input: D = {Xi, Ai, Mi, Yi}, i = 1, . . . , n and speciﬁ-
cation of a PSE of the form EX [m(X; α)].
Output:

α,

R(pi, α) = max

log pi + log p(Yi, Mi, Ai|Xi; α)

(cid:17)

pi by solving
n
b

Xi=1 (cid:16)

b

n

pi m

Xi, ; pi, α
(cid:1)
(cid:0)

Xi=1

= 0,

pi = 1.

n

Xi=1

1: Pick starting values for p(1)
2: At kth iteration, given ﬁxed p(k−1)
i
timate the following (in order)

i

and α(1).

and α(k−1), es-

I. m(cid:16)Xi; {p(k−1)
II. λ by solving

i

}, α(k−1)

(cid:17)
m(Xi;θ)

n
i=1

1+λ m(Xi;θ) = 0, which is

a monotone function in λ.

P
III. p(k)
i = 1
n
IV. α(k) by maximizing the following

using p(k)

1

i

1+λm(Xi;θ) , ∀i = 1, . . . , n,

α(k) = arg max

LY,M,A|X (D; α)

α
subject to wa = 0,

b

n

where E[Y |X, A, M ;αy] = w0 + f (Z;αf ) −
p(k)
i and
i=1(cid:8)Pm f (Zi; αf )p(M |A = 0, Xi; αm)
(cid:9)
P
f (Z) := E[Y |X, A, M ] − E[Y |X = 0, A, M = 0].

3: Repeat Step (2) until convergence.

b

constrained, and following Nabi and Shpitser (2018)
g(D). Here, we
this depends on the chosen estimator
illustrate this dependence via experiments by consid-
ering four consistent estimators of the NDE presented
in Tchetgen Tchetgen and Shpitser (2012) (assuming
the model shown in Fig. 1(a) is correct). We ﬁt models
E[Y |A, M, X; αy], p(M |A, X; αm), and p(A|X; αa) by
maximum likelihood. The ﬁrst estimator (G-formula),
is the MLE plug-in estimator and uses Y and M mod-
els to estimate NDE. The second one is the inverse
probability weighted (IPW) estimator that uses A and
M models. The “mixed” estimator uses the A and Y
models, and the augmented IPW estimator (AIPW)
uses all three models. See the appendix for details on
these estimators.

We generated a sample of size 6, 000 using the data
generating process described in the appendix. We ap-
proximate the fair world, p∗, by constraining MLE
given in Section 2. We estimated the NDE using the
four methods described above and evaluated the per-
formance of the approximated p∗ for each case.
In
Table 1 we show the estimated NDE with respect to
p∗, the log likelihood, KL-divergence between p∗ and

Table 1: Comparing diﬀerent versions of p∗ estimated by constraining diﬀerent parts of the likelihood.

Method

Estimator Direct Eﬀect

Log L DKL(p||p∗) MSE

Constrained MLE

Unconstrained MLE G-formula

G-formula

IPW

Mixed

AIPW

0.000
0.000
0.000
0.000

2.235

−53359
−51695
−52754
−51630

−51160

0.4220
0.1146
0.2993
0.0935

0.0018

3.5045
5.0409
2.7505
4.9545

0.9331

Table 2: Evaluating diﬀerent p∗ estimation methods by KL divergence and predictive accuracy (MSE).

Likelihood Method

Direct Eﬀect DKL(p||p∗) MSE

M0: Unconstrained MLE

M1: Constrained MLE (sec. 2.2)

M2: Reparameterized MLE (sec. 4.1)

M3: Hybrid MLE (sec. 4.2)

M4: Hybrid reparameterized MLE (sec. 4.3)

2.1946
0.000
0.000
0.034
0.019

0.000
0.415
0.282
0.352
0.284

1.002
3.546
3.410
1.165
1.541

p, and the mean squared error between the observed
outcomes and the predicted ones. We contrast these
results with the unconstrained prediction model. Un-
constrained MLE is KL-closest to the true distribution
and yields the lowest MSE, as expected. However, it
suﬀers from being unfair: NDE = 2.235. AIPW pro-
duces the second closest approximation to the true dis-
tribution while being fair. However, the MSE under
AIPW is relatively large, since new instances are be-
ing mapped and more information are averaged out
from the predictions. The approximated fair distribu-
tions under the other three estimators are KL-farther
from the true distribution, and the accuracy of predic-
tion varies, underscoring how the performance of the
learned prediction model depends strongly on what
part of the information is being averaged out and what
estimator is being used.

Next, we illustrate that even in simple settings our
proposed methods for solving constrained maximum
likelihood problems considerably outperform the ex-
isting method described in Nabi and Shpitser (2018).
We will use continuous outcomes for simplicity, but
our results are not substantially aﬀected if outcomes
are discrete. We generated synthetic data (n = 7000
with 20% missing outcomes) according to the causal
model shown in Fig. 1(a), where A, M are binary and
X, Y are continuous variables. The model speciﬁca-
tion details are reported in Appendix D and the code
is attached to the submission. For illustration pur-
poses, we assume that the direct eﬀect of sensitive fea-
ture A on outcome Y is unfair and estimate it via
the g-formula. We approximate the fair world, p∗, by
constrained MLE using the three methods described in
Section 4 and contrast them with the constrained MLE
described in Section 2 as well as unconstrained MLE.
We evaluated the performance of all ﬁve methods by

computing the direct eﬀect with respect to p∗, KL-
divergence between p∗ and p, and the mean squared
error between the observed and predicted outcomes.

Results are displayed in Table 2 (averaged over 20
repetitions). We see that all three proposed meth-
ods achieve an approximatation to the fair distribution
p∗ KL-closer to the true unfair distribution p, com-
pared to standard constrained MLE. Using the repa-
rameterized MLE by itself requires averaging over the
constrained covariates as in Nabi and Shpitser (2018),
so there is only minimal improvement in prediction
accuracy (measured by MSE). However, the last two
methods involve prediction in batch mode as described
above – that is, use all information in the data – and
so can achieve substantial improvements in prediction
accuracy.

6 CONCLUSION

Imposing hard fairness constraints on predictive mod-
els involves a balance of parametric modeling, non-
parametric methods, and constrained optimization. In
this paper we have proposed two innovations to make
the problem easier and make predictions more ac-
curate: a reparameterization of the likelihood such
that nonlinear constraints appear explictly as likeli-
hood parameters constrained to be zero and an in-
corporation of techniques from empirical
likelihood
theory to make the constrained distribution closer
to the unconstrained unfair distribution. Our sim-
ulations show that even in a relatively simple set-
ting, we can improve signiﬁcantly on prior proposals,
achieving prediction performance comparable to un-
constrained (unfair) maximum likelihood, particularly
with the hybrid approach. Though we focus primar-
ily on the path-speciﬁc fairness constraints proposed

in Nabi and Shpitser (2018), the ideas presented here
should be applicable more broadly to fair prediction
proposals that require imposing constraints on predic-
tive models. At this stage, our method which combines
reparameterization with hybrid likelihood is somewhat
heuristic; in future work, we hope to develop an ap-
proach for optimizing EL weights and likelihood pa-
rameters jointly without the need for iteration.

References

Silvia Chiappa. Path-speciﬁc counterfactual fairness.

In
Proceedings of the Thirty-Third AAAI Conference on
Artiﬁcial Intelligence, 2019.

Sam Corbett-Davies, Emma Pierson, Avi Feller, Sharad
Goel, and Aziz Huq. Algorithmic decision making and
In Proceedings of the 23rd ACM
the cost of fairness.
SIGKDD International Conference on Knowledge Dis-
covery and Data Mining, pages 797–806, 2017.

Michael Feldman, Sorelle A Friedler, John Moeller, Car-
los Scheidegger, and Suresh Venkatasubramanian. Cer-
tifying and removing disparate impact. In Proceedings
of the 21th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, pages 259–268,
2015.

Moritz Hardt, Eric Price, and Nati Srebro. Equality of op-
portunity in supervised learning. In Advances In Neural
Information Processing Systems, pages 3315–3323, 2016.

Shahin Jabbari, Matthew Joseph, Michael Kearns, Jamie
Morgenstern, , and Aaron Roth. Fairness in reinforce-
ment learning. In Proceedings of International Confer-
ence on Machine Learning, 2017.

Faisal Kamiran, Indre Zliobaite, and Toon Calders. Quan-
tifying explainable discrimination and removing illegal
discrimination in automated decision making. Knowl-
edge and Information Systems, 35(3):613–644, 2013.

Teus H Kappen, Wilton A van Klei, Leo van Wolfswinkel,
Cor J Kalkman, Yvonne Vergouwe, and Karel GM
Moons. Evaluating the impact of prediction models:
lessons learned, challenges, and recommendations. Di-
agnostic and Prognostic Research, 2(1):11, 2018.

Amir E. Khandani, Adlar J. Kim, and Andrew W. Lo.
Consumer credit-risk models via machine learning algo-
rithms. Journal of Banking & Finance, 34:2767–2787,
2010.

Matt J. Kusner, Joshua R. Loftus, Chris Russell, and Ri-
cardo Silva. Counterfactual fairness. Advances in Neural
Information Processing Systems, 2017a.

Matt J. Kusner, Joshua R. Loftus, Chris Russell, and Ri-
In Advances In

cardo Silva. Counterfactual fairness.
Neural Information Processing Systems, 2017b.

Rodrick J.A. Little and Donald B. Rubin. Statistical Anal-

ysis with Missing Data. Wiley, 2002.

Shira Mitchell, Eric Potash,

and Solon Barocas.
Prediction-based decisions and fairness: A catalogue of
choices, assumptions, and deﬁnitions. arXiv preprint
arXiv:1811.07867, 2018.

Razieh Nabi and Ilya Shpitser. Fair inference on outcomes.
In Proceedings of the Thirty-Second AAAI Conference
on Artiﬁcial Intelligence, 2018.

Razieh Nabi, Phyllis Kanki, and Ilya Shpitser. Estima-
tion of personalized eﬀects associated with causal path-
ways. In Proceedings of the Thirty Fourth Conference on
Uncertainty in Artiﬁcial Intelligence (UAI-34th). AUAI
Press, 2018.

Razieh Nabi, Daniel Malinsky, and Ilya Shpitser. Learning
optimal fair policies. In Proceedings of the 36th Interna-
tional Conference on Machine Learning (ICML), 2019.

Art Owen. Empirical Likelihood. Chapman & Hall, 2001.

Judea Pearl. Direct and indirect eﬀects. In Proceedings of
the Seventeenth Conference on Uncertainty in Artiﬁcial
Intelligence, pages 411–420, 2001.

Judea Pearl. Causality: Models, Reasoning, and Inference.

Cambridge University Press, 2nd edition, 2009.

Dino Pedreshi, Salvatore Ruggieri, and Franco Turini.
In Proceedings of
Discrimination-aware data mining.
the 14th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, pages 560–568,
2008.

Walter L. Perry, Brian McInnis, Carter C. Price,
Predic-
crime
forecasting in
RAND Corporation,

Susan Smith, and John S. Hollywood.
tive policing:
law enforcement operations.
http://www.rand.org/pubs/research_reports/RR233.html,
2013.

role of

The

Jing Qin. Biased Sampling, Over-identiﬁed Parameter

Problems and Beyond. Springer, 2017.

James M. Robins. Marginal structural models versus struc-
tural nested models as tools for causal inference. In Sta-
tistical Models in Epidemiology: The Environment and
Clinical Trials. NY: Springer-Verlag, 1999.

Ilya Shpitser. Counterfactual graphical models for longi-
tudinal mediation analysis with unobserved confound-
ing. Cognitive Science (Rumelhart special issue), 37:
1011–1035, 2013.

Ilya Shpitser and Eli Sherman.

Identiﬁcation of person-
alized eﬀects associated with causal pathways. In Pro-
ceedings of the 34th Annual Conference on Uncertainty
in Artiﬁcial Intelligence, 2018.

Ilya Shpitser and Eric J. Tchetgen Tchetgen. Causal infer-
ence with a graphical hierarchy of interventions. Annals
of Statistics, 44(6):2433–2466, 2016.

Eric J. Tchetgen Tchetgen and Ilya Shpitser. Semipara-
metric theory for causal mediation analysis: eﬃciency
bounds, multiple robustness, and sensitivity analysis.
Annals of Statistics, 2012.

Eric J. Tchetgen Tchetgen and Ilya Shpitser. Estimation
of a semiparametric natural direct eﬀect model incorpo-
rating baseline covariates. Biometrika, 101(4):849–864,
2014.

Larry Wasserman. All of statistics: a concise course in
statistical inference. Springer Science & Business Media,
2013.

Junzhe Zhang and Elias Bareinboim. Fairness in decision-
making – the causal explanation formula. In Proceedings
of the Thirty-Second AAAI Conference on Association
for the Advancement of Artiﬁcial Intelligence, 2018.

Lu Zhang, Yongkai Wu, and Xintao Wu. A causal frame-
work for discovering and removing direct and indirect
discrimination. In Proceedings of the Twenty-Sixth In-
ternational Joint Conference on Artiﬁcial Intelligence,
pages 3929–3935, 2017.

APPENDIX

In Appendix A, we provide additional details for the direct eﬀect reparameterization example (illustrating
Theorem 2) discussed in the main paper. In Appendix B, we provide a brief overview of empirical likelihood
methods and some additional theoretical details useful for understanding our proposed hybrid likelihood ap-
proach. In Appendix C, we state the statistical modeling assumptions we made in our simulation experiments.
In Appendix D, we give some relevant details for the ﬁrst simulation reported in the main paper. Appendix E
contains proofs of our theorems. For a clearer presentation of materials in this supplement, we use a one-column
format.

A. Reparameterized Likelihood Example: Additional Details

Consider the DAG in Fig. 1(a), and assume the natural direct eﬀect is the unfair PSE we wish to constrain to
be 0. Theorem 2 leads to the following reparameterization of the regression function:

E[Y | X, A, M ] = E[Y | X, A, M ] − E[Y | X = 0, A, M = 0]

|
−

+

XX,M

XX,M

|

f (X,A,M )
{z

}
f (X, A, M ) p(M | A = 0, X) p(X)

E[Y | X, A, M ] p(M | A = 0, C) p(X)

.

φ(A)=w0+waA
{z

}

The coeﬃcient wa corresponds to the direct eﬀect, since

NDE =

E[Y | X, A = 1, M ] − E[Y | X, A = 0, M ]

p(M | A = 0, X) p(X)

=

E[Y | X, A = 1, M ] p(M | A = 0, X) p(X) −

E[Y | X, A = 0, M ] p(M | A = 0, X) p(X)

XX,M n

XX,M

= φ(A = 1) − φ(A = 0)
= wa.

o

XX,M

The observed data likelihood is given by

LY,M,A,X (D; α) =

p(Yi|Mi, Ai, Xi; αy) p(Mi|Ai, Xi; αm) p(Ai|Xi; αa) p(Xi),

n

Yi=1

where p(Y |M, A, X; αy) has mean

E[Y |X, A, M ; αy] = f (X, A, M ; αf ) −

f (X, A, M ; αf ) p(M |A = 0, X; αm) p(X) + w0.

Xx,m

The constrained optimization problem in eq. (2) then simpliﬁes to the following optimization problem:

arg max

LY,M,A,X (D; α)

α

subject to wa = 0.

B. Hybrid Likelihood: Overview and Details

Empirical Likelihood

We brieﬂy review empirical likelihood methods, described in detail in Owen (2001). Let X1, . . . , Xn be indepen-
dent random vectors with common distribution F0. Let F be any CDF, where F (x) = p(X ≤ x), and Fn be the
empirical distribution. Suppose that we are interested in F through θ = T (F ), where T is a real-valued function
of the distribution. The true unknown parameter is θ0 = T (F0). Proceeding by analogy to parametric MLE, the

non-parametric MLE of θ is ˆθ = T (Fn). The nonparametric likelihood ratio, R(F ) = L(F )
for hypothesis testing and deriving conﬁdence intervals. The proﬁle likelihood ratio function is deﬁned as

L(Fn) , is used as a basis

R(θ) = sup

R(F ) | T (F ) = θ, F ∈ F

,

(cid:8)
where F denotes the set of all distributions on R.
Often, θ ≡ θ(F ) is the solution to an estimating equation of the form E[m(X, θ)] = 0. A natural estimator for θ is
produced by solving the empirical estimating equation 1
θ) = 0. Assuming pi = f (X = xi) for i =
1, . . . , n, the proﬁle empirical likelihood ratio function of θ is deﬁned as
b

n
i=1 m(Xi,
n P

(cid:9)

R(θ) = max

npi

such that

pi m(Xi, θ) = 0, pi ≥ 0,

pi = 1

.

(9)

Since maximizing the likelihood is equivalent to maximizing the logarithm of the likelihood, the proﬁle empirical
likelihood ratio is rewritten in terms of log likelihood as follows.

R(θ) = max

log pi

such that

pi m(Xi, θ) = 0, pi ≥ 0,

pi = 1

.

(10)

n

Xi=1

n

Xi=1

o

o

n

n

Yi=1

n

n

Xi=1

In order to solve the above optimization problem, we can apply the Lagrange multiplier method.

T ({pi}, λ, λ1) =

log pi + λ1(

pi − 1) − nλ

pi m(Xi; θ),

n

Xi=1

n

Xi=1

where λ, λ1 are the Lagrange multipliers. We take the derivative of T ({pi}, λ, λ1), with respect to the pi’s, and
set them to zero. Solving the system of equations reveals that λ1 = −n, and

n

Xi=1

n

Xi=1

n

Xi=1

where λ is the solution to

which is a monotone function in λ. Maximizing the proﬁle empirical log-likelihood ration in (10) is equivalent
to maximizing the following (substituting pi from (11) into (10)):

pi =

1
n

1
1 + λm(Xi; θ)

, ∀i = 1, . . . , n,

m(Xi; θ)
1 + λ m(Xi; θ)

= 0,

n

X
i=1

n

Xi=1

l(θ) = −

log(1 + λ m(Xi; θ)) − n log n.

(11)

(12)

(13)

Maximizing l(θ) over a small set of parameters θ, is a much simpler optimization problem than maximizing (10)
over n unknowns. Equation 13 is known as the dual representation of 10. See Owen (2001) for more details.

Hybrid Likelihood

Now, consider independent pairs (X1, Y1), . . . , (Xn, Yn). Suppose that all n observations are independent, and
that we have a correctly speciﬁed parametric model for p(Y |X; θy) but p(X) is unspeciﬁed. Let pi = p(X = xi).
A natural approach for estimating θy and the pis is to form a hybrid likelihood that is nonparametric in the
distribution of Xi but is parametric in the conditional distribution of Yi|Xi:

n

Y
i=1
Suppose we are interested in parameter θ through the estimating equation E[m(X, Y ; θ)] = 0. Hence, the
equivalent form of (10) for the proﬁle hybrid likelihood ratio function is as follows:

L(D; {pi}, θ) =

pi p(Yi|Xi; θ).

R(θ) = max

log pi + log p(Yi|Xi; θ)

such that

pi m(Xi, Yi; θ) = 0, pi ≥ 0,

pi = 1

.

(14)

n

n

Xi=1 (cid:16)

(cid:17)

n

Xi=1

n

Xi=1

o

Similar to the empirical likelihood, we can apply the Lagrange multiplier method to solve the above optimization
problem. For more details, see Owen (2001) and Qin (2017).

C. Simulation details

Here we report the precise parameter settings used in our simulation studies. We trained our models on a batch
size of 7, 000 using the following data generating process, where outcome Y is treated as missing on 20% of the
data. Mean squared errors in Tables 1 and 2 are computed only on the missing portion of the outcome Y .

X ∼ N (0, 1)

logit(p(A = 1|X)) ∼ 0.5 + 0.5X

logit(p(M = 1|A, X)) ∼ 0.5 + X + 0.5A − AX

Y = 1 + X + 2A − 2AX + M + 3XM + AM + XAM + N (0, 1)

(15)

D. Details on Estimation Strategies

Given Theorem 1, the accuracy of the prediction procedure will depend on what parts of p(Z, Y ; α) are
constrained, and following Nabi and Shpitser (2018) this depends on the estimator
g(D). Here, we deﬁne
several consistent estimators of the NDE (assuming the model shown in Fig. 1(a) is correct) presented in
Tchetgen Tchetgen and Shpitser (2012).

b

G-formula: The ﬁrst estimator is the MLE plug in estimator, where we use the Y and M models to estimate
NDE. We ﬁt models E[Y |A, M, X; αy] and p(M |A, X; αm) by maximum likelihood, and use the following formula:

Pn

E[Yi | A = 1, Xi, M ;

αy] − E[Yi | A = 0, Xi, M ;

αy]

p(M | A = 0, Xi;

αm)

(16)

b

(cid:17)

b

.

(cid:19)

b

Since solving (2) using (16) entails constraining E[Y |A, M, X] and p(M |A, X), classifying a new instance entails
using E[Y |A, X] =

E[Y |A, M, X] p(M |A, X).

(cid:18) Xm (cid:16)

PM

Inverse probability weighting (IPW): The second estimator is the IPW estimator where we use the A and M
models to estimate NDE. We can ﬁt the models p(A|X; αa) and p(M |A, X; αm) by MLE, and use the following
weighted empirical average as our estimate of the NDE:

Pn

I(Ai = 1)
p(Ai = 1|Xi;

(cid:18)

αa)

·

p(Xi|A = 0, Xi;
p(Mi|A = 1, Xi;

Yi −

I(Ai = 0)
p(Ai = 0|Xi;

αa)

Yi

.

(cid:19)

(17)

Since solving the constrained MLE problem using this estimator entails only restricting parameters of A and M
models, predicting a new instance is done using E[Y |X] =

b
E[Y |A, M, X] p(M |A, X) p(A|X).

b

Mixed approach: The third way of computing the NDE is using A and Y models. In this estimator, we ﬁt the
models p(A|X; αa) and E[Y |A, M, X; αy] by MLE, as usual, and combine the edge G-formula and IPW in the
following way:

Pn

I(Ai = 0)
p(Ai = 0|Xi;

(cid:18)

αa)

E[Yi|A = 1, Mi, Xi;

αy] − E[Yi|A = 0, Mi;

αy]

(18)

,

(cid:19)

b

Since solving the constrained MLE problem using this estimator entails only restricting parameters of A and Y
models, predicting a new instance is done using E[Y |M, X] =

E[Y |A, M, X]

b

p(M|A,X)·p(A|X)
PA p(M|A,X)·p(A|X) .

Augmented inverse probability weighting (AIPW): The ﬁnal estimator uses all three models, as follows:

αm)
αm)
b
b
PA,M

b

PA

Pn

(cid:18)

αa)

I(Ai = 1)
p(Ai = 1|Xi;
I(Ai = 0)
b
p(Ai = 0|Xi) n
I(Ai = 0)
p(Ai = 0|Xi;

+

−

p(Mi | A = 0, Xi;
p(Mi|A = 1, Xi;

αm)
αm) n
b
E[Yi|A = 1, Mi, Xi;
b

αy] − η(1, 0, Xi)

+ η(1, 0, Xi)

o

b

Yi − E[Yi|A = 1, Mi, Xi;

αy]

(19)

Yi − η(0, 0, Xi)

b
+ η(0, 0, Xi)

αa) n

o

o

,

(cid:19)

with η(a, a′, X) ≡
estimator, predicting Y for a new instance is via E[Y |X] =

PM

b

E[Y |a, M, X]p(M |a′, X). Since the models of A, M , and Y are all constrained with this

E[Y |A, M, X] p(M |A, X) p(A|X).

PA,M

E. Proofs

Theorem 1 Let p(Z) denote the observed data distribution, M1 =
g(q(Z)) ≤ ǫu, q(Z1) = p(Z1)
p(Z2)
in M2 compared to M1, then p∗

p∗
1(Z) = arg maxq(Z) DKL(p||q) s.t. ǫl ≤
p∗
2(Z) = arg maxq(Z) DKL(p||q) s.t. ǫl ≤ g(q(Z)) ≤ ǫu, q(Z2) =
2) ≤ DKL(p||p∗
1). In other words, if more densities are being constrained

. If Z2 ⊆ Z1 ⊆ Z, then DKL(p||p∗

2(Z) is closer to p(Z) than p∗

, and M2 =

1(Z).

(cid:9)

(cid:9)

(cid:8)

(cid:8)

Proof: M1 is a submodel of M2, hence maximizing the likelihood under model M1 yields a likelihood that is less
than or equal to the one under model M2: max LM1 (D) ≤ max LM2 (D). Maximizing the likelihood of observed
data with respect to the model parameters is equivalent to minimizing KL-divergence between the likelihood and
the true distribution of the data Wasserman (2013). Consequently, KL-divergence between p∗ and p is smaller
in M2 compared to M1, i.e DKL(p||p∗
(cid:3)

2) ≤ DKL(p||p∗

1).

Theorem 2 Assume the observed data distribution p(Y, Z) is induced by a causal model, where Z = {X, A, M }
includes pre-treatment measures X, treatment A, and post-treatment pre-outcome mediators M . Let p(Y (π, a, a′))
denote the potential outcome distribution that corresponds to the eﬀect of A on Y along proper causal paths in
π, where π includes the direct inﬂuence of A on Y , and let p(Y0(π, a, a′)) denote the identifying functional for
p(Y (π, a, a′)) obtained from the edge-formula in (1), where the term p(Y |Z) is evaluated at {Z \ A} = 0. Then
E[Y |Z] can be written as follows:

E[Y |Z] = f (Z) −

E[Y (π, a, a′)] − E[Y0(π, a, a′)]
(cid:1)
(cid:0)

+ φ(A),

where f (Z) := E[Y |Z] − E[Y |A, {Z \ A} = 0] and φ(A) = w0 + waA. Furthermore, wa corresponds to π-speciﬁc
eﬀect of A on Y .

Proof: By letting φ(A = a) = E[Y (π, a, a′)], it suﬃces to show that E[Y0(π, a, a′)] = E[Y |A, {Z \ A} = 0]. Given
the identiﬁcation result for edge-consistent counterfactuals in Shpitser and Tchetgen Tchetgen (2016), we can
write the identiﬁcation functional as follows.

E[Y0(π, a, a′)] =

E[Y |A = a, {Z \ A} = 0] × h(V ∈ XV \ Y ),

X
V ∈XV \{A,Y }

where h(V ∈ XV \ Y ) is a function of all variables excluding Y . Note that h, does not include any density where
A appears on the LHS of the conditioning bar. Therefore, we have:

E[Y0(π, a, a′)] = E[Y |A = a, {Z \ A} = 0] ×

h(V ∈ XV \ Y )

X
V ∈XV \{A,Y }

= E[Y |A = a, {Z \ A} = 0].

(cid:3)

