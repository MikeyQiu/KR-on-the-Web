7
1
0
2
 
g
u
A
 
1
1
 
 
]

V
C
.
s
c
[
 
 
1
v
0
8
6
4
0
.
8
0
7
1
:
v
i
X
r
a

Augmentor

Augmentor: An Image Augmentation Library for Machine
Learning

Marcus D. Bloice

Christof Stocker

Andreas Holzinger
Institute for Medical Informatics, Statistics, and Documentation
Medical University of Graz
Graz, Austria

marcus.bloice@medunigraz.at

stocker.christof@gmail.com

andreas.holzinger@medunigraz.at

Abstract
The generation of artiﬁcial data based on existing observations, known as data augmen-
tation, is a technique used in machine learning to improve model accuracy, generalisation,
and to control overﬁtting. Augmentor is a software package, available in both Python
and Julia versions, that provides a high level API for the expansion of image data using
a stochastic, pipeline-based approach which eﬀectively allows for images to be sampled
from a distribution of augmented images at runtime. Augmentor provides methods for
most standard augmentation practices as well as several advanced features such as label-
preserving, randomised elastic distortions, and provides many helper functions for typical
augmentation tasks used in machine learning.
Keywords:

Image Augmentation, Artiﬁcial Data Generation, Image Preprocessing

1. Introduction

Data augmentation is the artiﬁcial generation of data through the introduction of new
samples created by the perturbation of the original dataset, while preserving the label of
newly generated samples. It is a convenient and frequently employed method for generating
more training data at low eﬀort, or when the accumulation of new samples is no longer
feasible, such as in a discontinued clinical trial. Data augmentation is most commonly
utilised in the branch of machine learning that concerns image analysis (Hauberg et al.,
2016).

The Augmentor project uses a stochastic, pipeline-based approach to image augmen-
tation. The pipeline approach allows the user to chain augmentation operations together,
such as shears, rotations, and crops, and pass images through this pipeline in order to create
new data. All operations in the pipeline are applied stochastically, both in terms of the
probability of the operations being applied to each image as the image passes through the
pipeline, and in terms of each operation’s parameters, which are also randomised within
user speciﬁed ranges. This eﬀectively allows you to sample from a distribution of possible
images, generated by the pipeline at runtime.

Therefore, the aim of the package is to provide a comprehensive and highly customisable
image augmentation library, which is platform independent but also independent from any
particular machine learning framework. Crucial to the successful application of augmen-
tation is the generation of realistically feasible training data, meaning tight control of the

1

Bloice, Stocker, and Holzinger

pipeline is a necessity when creating new data. Augmentor’s operations are therefore highly
parametric, allowing ﬁne control over how images are created.

2. Documentation and Availability

The Augmentor package is available for Python and Julia. Sources are available on GitHub,
while comprehensive documentation is hosted on Read The Docs (see Table 1). Both
versions of the Augmentor package are available under the terms of the MIT Licence.

Table 1: Augmentor availability.

Source

Documentation

Python https://github.com/mdbloice/Augmentor
Julia

https://github.com/Evizero/Augmentor.jl http://augmentorjl.readthedocs.io

http://augmentor.readthedocs.io

To install Augmentor:

• Python: pip install Augmentor

• Julia: Pkg.clone("https://github.com/Evizero/Augmentor.jl.git")

3. Design

We took into account typical augmentation techniques from the literature, and techniques
reported on various competition sites such as Kaggle, when developing the API. Standard
operations include arbitrary rotations, transformations through the horizontal and verti-
cal axes, cropping, scaling, perspective shifting, shearing, and zooming (Dosovitskiy et al.,
2013; Simard et al., 2003; Krizhevsky et al., 2012; Howard, 2013). Less frequently used oper-
ations were also implemented (Dosovitskiy et al., 2015), as well a number of pre-processing
techniques in common use. Also, a large number of convenience functions have been imple-
mented that take into account typical augmentation techniques.

Because image augmentation is often performed accumulatively, a pipeline-based API
was developed (see Figure 1). To use Augmentor, you begin with an empty pipeline. The
user adds operations to this pipeline in the order they wish the operations to be applied
to images that are passed through the pipeline. As well as this, the user can specify the
probability that each operation should be applied to images as they pass through. Also, the
range of each operation’s freedom of movement is likewise deﬁned by the user, for example
by specifying that a rotation operation can operate within the range of −10◦ to 10◦. Once
a pipeline has been generated, an image or set of images are repeatedly passed though
the pipeline until the desired amount of new images have been generated. The stochastic
nature of the pipeline approach will produce diﬀerent image data each time an image passed
through the pipeline. This stochastic approach allows for a potentially very large amount
of images to be generated from even a small initial dataset.

2

Augmentor

Figure 1: An example pipeline, with three operations. From a single image on the left, vari-
ants can be generated by passing the image multiple times through the pipeline.
Each time the image is passed through, operations are either applied or skipped
based on the user-deﬁned probability parameter. If an operation is applied, the
parameters of the operation itself are chosen randomly within a user speciﬁed
range—for example, the rotate operation’s rotation angle is chosen at random
from between −10◦ and +10◦.

3.1 Main Features

A complete list of features can be found in the project’s documentation. Some commonly
used features are random rotations, transforms through the horizontal and vertical axes,
cropping (randomly positioned or centred), random zoom levels, random scaling and resiz-
ing. Other transforms, such as shearing by random angles in random directions and through
random axes, as well as perspective transformations are also implemented. Operations have
been implemented with machine learning in mind. For example, arbitrary rotations will not
result in images with black or transparent regions around the newly rotated image, as the
images are optimally cropped and then resized to their original input size. The same is true
of the shear and perspective tilt operations.

Augmentor also has the capability of producing random elastic transforms (Simard et al.,
2003), and to perform these in a highly conﬁgurable way. The user may specify a grid size
which controls the granularity of the distortions and the strength of the displacement within
the grid (the magnitude of the arrows shown in Figure 2).

Figure 2: Randomised, label-preserving elastic distortions.

3.2 Practical Example

To demonstrate the API and to highlight the eﬀectiveness of augmentation on a well-known
dataset, a short experiment was performed. Using the MNIST dataset, a CNN was trained
on 1000 random images (100 samples per class) extracted from the 60,000 image training

3

Bloice, Stocker, and Holzinger

Table 2: Augmentation Example

Experiment Dataset

Test Set Accuracy

Baseline
Augmented

1,000 image training set
11,000 image augmented training set

93.94%
97.28%

set and tested on the standard 10,000 image test set. Then this set of 1000 images was
augmented to produce 10,000 new images, a separate CNN was trained using the augmented
dataset, and the results of the models were compared. As shown in Table 2 this resulted in
an almost 4% improvement in performance on the same test set.

This augmentation experiment was perform using randomised elastic transforms and
random rotations. To show how the Augmentor API works in practice, we will demonstrate
how this augmented dataset was generated. To begin, a pipeline object is created, pointing
to a folder containing the images:

1 import Augmentor
2 p = Augmentor . Pipeline ("/ path / to / mnist /1")

Now that a pipeline object, p, has been created, operations are added to the pipeline as

follows:

1 p . ra n dom _di stor tio n ( probability =1 , grid_width =4 , grid_height =4 , magnitude =5)
2 p . rotate ( probability =0.5 , m a x_ l ef t _r o ta t io n =10 , m a x_ r ig ht _ ro t at io n =10)

Every operation has at least a probability parameter. This was set to 1.0 for the ran-
domised distortions and 0.5 for the rotation operation. Finally, the sample function is called
to generate the data:

This generates 1000 new augmented images. The procedure was repeated 10 times, once

per digit, for 10,000 augmented images in total.

1 p . sample (1000)

4. Conclusions

Image augmentation is an important constituent of many machine learning tasks, partic-
ularly deep learning. Augmentor makes it easier to perform artiﬁcial data generation, by
providing a stochastic, pipeline-based API that allows for ﬁne-grained control over the cre-
ation of augmented data and provides many functions for augmentation techniques found in
the literature. Future work will entail expanding functionality, such as the ability to mirror
augmentation on a reference data set, or mimicking more advanced preprocessing and aug-
mentation methods such as the specialised contrast manipulation techniques or vignetting
shown in Wu et al. (2015).

References

Alexey Dosovitskiy, Jost Tobias Springenberg, and Thomas Brox. Unsupervised Feature

Learning by Augmenting Single Images. arXiv preprint arXiv:1312.5242, 2013.

4

Augmentor

Alexey Dosovitskiy, Philipp Fischer, Jost Tobias Springenberg, Martin Riedmiller, and
Thomas Brox. Discriminative Unsupervised Feature Learning with Exemplar Convo-
lutional Neural Networks. arXiv preprint arXiv:1406.6909v2, 2015.

Søren Hauberg, Oren Freifeld, Anders Boesen Lindbo Larsen, John W Fisher III, and
Lars Kai Hansen. Dreaming More Data: Class-dependent Distributions over Diﬀeomor-
phisms for Learned Data Augmentation. In Proceedings of the 19th International Con-
ference on Artiﬁcial Intelligence and Statistics. Journal of Machine Learning Research,
2016.

Andrew G Howard. Some Improvements on Deep Convolutional Neural Network Based

Image Classiﬁcation. arXiv preprint arXiv:1312.5402, 2013.

Alex Krizhevsky, Ilya Sutskever, and Geoﬀrey E Hinton. Imagenet Classiﬁcation with Deep
Convolutional Neural Networks. In Advances in Neural Information Processing Systems,
pages 1097–1105, 2012.

Patrice Y Simard, David Steinkraus, John C Platt, et al. Best Practices for Convolutional
In ICDAR, volume 3, pages

Neural Networks Applied to Visual Document Analysis.
958–962, 2003.

Ren Wu, Shengen Yan, Yi Shan, Qingqing Dang, and Gang Sun. Deep Image: Scaling up

Image Recognition. arXiv preprint arXiv:1501.02876, 7(8), 2015.

5

