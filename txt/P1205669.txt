Towards Universal Dialogue State Tracking

Liliang Ren, Kaige Xie, Lu Chen and Kai Yu
Key Lab. of Shanghai Education Commission for Intelligent Interaction and Cognitive Eng.
SpeechLab, Department of Computer Science and Engineering
Brain Science and Technology Research Center
Shanghai Jiao Tong University, Shanghai, China
{renll204,lightyear0117,chenlusz,kai.yu}@sjtu.edu.cn

Abstract

Dialogue state tracking is the core part of a
spoken dialogue system. It estimates the be-
liefs of possible user’s goals at every dialogue
turn. However, for most current approaches,
it’s difﬁcult to scale to large dialogue domains.
They have one or more of following limita-
tions: (a) Some models don’t work in the sit-
uation where slot values in ontology changes
dynamically; (b) The number of model param-
eters is proportional to the number of slots;
(c) Some models extract features based on
hand-crafted lexicons. To tackle these chal-
lenges, we propose StateNet, a universal di-
alogue state tracker. It is independent of the
number of values, shares parameters across all
slots, and uses pre-trained word vectors in-
stead of explicit semantic dictionaries. Our
experiments on two datasets show that our ap-
proach not only overcomes the limitations, but
also signiﬁcantly outperforms the performance
of state-of-the-art approaches.

1

Introduction

A task-oriented spoken dialogue system (SDS) is
a system that can continuously interact with a
human to accomplish a predeﬁned task through
speech. It usually consists of three modules: in-
put, output, and control. The control module is
also referred to as dialogue management (Young
et al., 2010; Yu et al., 2014). It has two missions:
dialogue state tracking (DST) and decision mak-
ing. At each dialogue turn, a state tracker main-
tains the internal state of the system based on the
information received from the input module. Then
a machine action is chosen based on the dialogue
state according to a dialogue policy to direct the
dialogue (Chen et al., 2018).

The dialogue state is an encoding of the ma-
chine’s understanding of the whole conversation.
Traditionally, it is usually factorized into three dis-
tinct components (Young et al., 2013): the user’s
goal, the user’s action, and the dialogue history.

Among them, the user’s goal is most important,
which is often simply represented by slot-value
pairs. In this paper, we focus on the tracking of
the user’s goal.

Recently, the dialogue state tracking challenges
(DSTCs) (Williams et al., 2013; Henderson et al.,
2014a,d) are organized to provide shared tasks for
comparing DST algorithms. A various of mod-
els are proposed, e.g. rule-based models (Wang
and Lemon, 2013; Sun et al., 2014a; Yu et al.,
2015, 2016; Sun et al., 2016b), generative statis-
tical models (Thomson and Young, 2010; Young
et al., 2010, 2013), and discriminative statistical
models (Lee and Eskenazi, 2013; Lee, 2013; Sun
et al., 2014b; Xie et al., 2015; Sun et al., 2016a;
Xie et al., 2018). And the state-of-the-art one is
the deep learning-based approach. However, most
of these models have some limitations. First, some
models can only work on a ﬁxed domain ontology,
i.e. the slots and values are deﬁned in advance, and
can’t change dynamically. However, this is not
ﬂexible in practice (Xu and Hu, 2018). For exam-
ple, in the tourist information domain, new restau-
rants or hotels are often added, which results in
the change of the ontology. Second, in many ap-
proaches the models for every slot are different.
Therefore, the number of parameters is propor-
tional to the number of slots. Third, some mod-
els extract features based on text delexicalisation
(Henderson et al., 2014b), which depends on pre-
deﬁned semantic dictionaries. In large scale do-
mains, it’s hard to manually construct the semantic
dictionaries for all slots and values (Mrkˇsi´c et al.,
2017).

To tackle these challenges, here we propose a
universal dialogue state tracker, StateNet. For
each state slot, StateNet generates a ﬁxed-length
representation of the dialogue history, and then
compares the distances between this representa-
tion and the value vectors in the candidate set for
making prediction. The set of candidate values

8
1
0
2
 
t
c
O
 
2
2
 
 
]
L
C
.
s
c
[
 
 
1
v
7
8
5
9
0
.
0
1
8
1
:
v
i
X
r
a

Figure 1: General model architecture of StateNet.

can change dynamically. StateNet only needs the
following three parts of the data: (1) the original
ASR information (or the transcript) of the user ut-
terance; (2) the information of the machine act;
(3) the literal names of the slots and the values.
The manually-tagging of the user utterance is not
needed as a part of the data. StateNet shares pa-
rameters among all slots, through which we can
not only transfer knowledge among slots but also
reduce the number of parameters.

2 StateNet: A Universal Dialogue State

Tracker

For each dialogue turn, StateNet takes the multi-
ple n-gram user utterance representation, rn
u, the
m-gram machine act representation, rm
a , the value
set, Vs, and the word vector of the slot, s, as the
input. Then StateNet applies the Long Short-Term
Memory (LSTM) (Hochreiter and Schmidhuber,
1997) to track the inner dialogue states among the
dialogue turns. And for each slot, StateNet out-
puts a corresponding probability distribution, ps,
over the set of possible values, Vs, at each of the
dialogue turn,

ps = StateNet(rn

u, rm

a , s, Vs).

The general model architecture is shown in Fig-

ure 1.

2.1 User Utterance Representation

At the t-th dialogue turn, the user utterance, Ut,
may consist of l number of words, ui, with their
corresponding word vectors, ui, (1 ≤ i ≤ l). The
user utterance may also have its corresponding m-
best ASR hypotheses with the normalized conﬁ-
dence scores (Chen et al., 2017), qj,(1 ≤ j ≤ m).

In this case, we can calculate the weighted word
vectors, u(cid:48)

i,

m
(cid:88)

u(cid:48)

i =

qjui,j,

j=1
where ui,j represents the word vector ui presented
at the j-th ASR hypothesis, and the zero vectors
are padded at the end of all the hypotheses that are
shorter than the longest one to have a same length
of the utterance.

Based on the weighted word vectors generaliz-
ing the information from the ASR hypothesis, we
can then construct the n-gram weighted word vec-
tors, as proposed by Mrkˇsi´c et al. (2017),

u(cid:48)n

i = u(cid:48)

i ⊕ ... ⊕ u(cid:48)

i+n−1,

where ⊕ is the concatenation operator between the
word vectors.

An n-gram user utterance representation is then
constructed through a sum of the n-gram weighted
word vectors,

rn
u =

l−n+1
(cid:88)

i=1

u(cid:48)n
i .

2.2 Multi-scale Receptors Layer

Figure 2: Multi-scale Receptors Layer.

For each gram k of the user utterance represen-
tation, rk
u, (1 ≤ k ≤ n), the Multi-scale Recep-
tors Layer has c number of linear neural networks

(with the same number of neurons, Nc). Each of
them takes the representation as input and is ex-
pected to work as the specialized receptor to am-
plify the signals from some of the word vectors in
the utterance representation,
j=1(Wj

u = ⊕c
ˆrk

u + bj

krk

k),

where Wj
k means the weight of the j-th linear
layer, bj
k means the corresponding bias, and ⊕ is
the concatenation operator between the neurons of
these linear layers. Note that each receptor does
not necessarily has to be a single linear neural net-
work and can be sophisticated with multiple layers
and non-linearity for better detection performance.
Here we only use the linear layer to provide a base-
line of this kind of structure design.

These c number of linear layers (or receptors)
for different grams (or scales) of the representation
ˆrk
u is then summed together to be layer-normalized
(Ba et al., 2016). After that, the ReLU activation
function is applied, followed by a linear layer with
the size Nc that maps all the receptors to a user
feature vector, fu,

fu = Linear(ReLU(LayerNorm(

n
(cid:88)

k=1

ˆrk
u))).

2.3 Machine Act Representation

We represent the machine act in the m order n-
gram of bag of words, rm
a , based on the vocab-
ularies generalized from the machine acts in the
training set of a given data set. The machine act
feature, fa, is then simply generated through a lin-
ear layer of size Nc with the ReLU activation func-
tion,

fa = ReLU(Linear(rm

a )).

2.4 Slot Information Decoding

Since a slot, e.g. area or food, is usually indicated
as a word or a short word group, then it can be
represented as a single word vector (with multiple
word vectors summed together), s. A single lin-
ear layer with the size 2Nc is applied to the word
vector s, followed by the ReLU non-linear layer,

fs = ReLU(Linear(s)).

The turn-level feature vector, is, is then gen-
erated through a point-wise multiplication ⊗ be-
tween the slot feature and the concatenation of the
user feature and the machine act feature,

is = fs ⊗ (fu ⊕ fa).

In this way, the turn-level feature vector is in-
tended to amplify the large magnitude signals that
are from both the user and machine act feature
vector and the slot feature vector.

2.5 Fixed-length Value Prediction

Given the turn-level feature vector, is, we can now
track the dialogue state throughout the dialogue
turns by LSTM. For the current turn t, the LSTM
takes the is and the previous hidden state, qt−1, as
the input. We can then obtain a ﬁxed-length value
prediction vector, os, whose length is equal to Nw,
i.e. the dimension of the word vectors which are
fed into the model,

os = ReLU(Linear(LSTM(is, qt−1))),

where the linear layer has Nw neurons.
In this
way, the prediction of the model is independent
of the number of the given values, so it is possible
for the model to perform parameter sharing among
each of the slots. The ﬁxed-length prediction can
somehow be interpreted as a word vector that is
ready for the calculation of the similarity between
the prediction and the true value label.

2.6

2-Norm Distance

For a speciﬁc semantic slot, since there may be
no corresponding value in a given dialogue turn,
thus we always add a literally “none” value to the
value set for the model to track this state. For
the evaluation of the similarity between the pre-
diction and the value, we calculate the 2-Norm
distance between the prediction vector and each
of the word vectors of the values in the value set.
Softmax function is performed with respect to all
the negative relative distances to give a distribu-
tion of probabilities for the values, vi ∈ Vs,

ps(vi) = Softmax(−||os − vi||),

where vi is the representation vector of vi. If the
slot value vi consists of more than one word, vi
will then be the summation of all corresponding
word vectors. When training the model, we mini-
mize the Cross-Entropy (CE) loss between the out-
put probabilities and the given label.

StateNet requires the user utterance, the seman-
tic slots, and slot values to be able to be expressed
in words and have their corresponding word vec-
tors. We use the ﬁxed word embedding for ev-
ery word, and do not ﬁne-tune the word embed-
dings in the model. Since the word embeddings

are distributed on a ﬁxed-dimension vector space
and hold rich semantic information, StateNet may
have the ability to track the dialogue state for any
new slot or value, as long as the corresponding
word embedding can be found. This is the rea-
son why we call the StateNet a universal dialogue
state tracker.

3 Experiments

Experiments are conducted to assess the perfor-
mance on joint goal. Two datasets are used by
us for training and evaluation. One is the sec-
ond Dialogue State Tracking Challenge (DSTC2)
dataset (Henderson et al., 2014a), and the other is
the second version of Wizard-of-Oz (WOZ 2.0)
dataset (Wen et al., 2017). Both of them are the
conversations between users and a machine sys-
tem. The user’s goal is to ﬁnd a suitable restau-
rant around Cambridge. The ontology of these two
datasets is identical, which is composed of three
informable slots: food, pricerange and area. The
main difference between them is that in WOZ 2.0,
users typed instead of using speech directly. This
means the users can use far more sophisticated lan-
guage than they can in the DSTC2, which is a big
challenge for the language understanding ability
of the model. Thus, it allows WOZ 2.0 to be more
indicative of the model’s actual performance since
it is immune to ASR errors.

Based on the model structure as described in
Section 2, we implement three kinds of dialogue
state tracker. The difference among them lies in
the utilization of parameter sharing and parameter
initialization.

• StateNet: It doesn’t have shared param-
eters among different slots. In other words,
three models for three slots are trained sep-
arately using RMSProp optimizer, learning
rate set to 0.0005. And its parameters are not
initialized with any pre-trained model.

• StateNet PS: Parameter sharing is con-
ducted among three slots.
For each slot
in a batch, we infer the model with the
slot information and the same dialogue in-
formation. The losses are calculated based
on the corresponding value set. After each
slot is inferred, we back-propagate all the
losses and do the optimization. So we just
train one model in total using RMSProp op-
learning rate set
timizer,
to 0.0005. As
the amount of model parameters
a result,

• StateNet PSI: Parameter

is one third of that of StateNet, which
means StateNet PS can signiﬁcantly save
the memory usage during inferring.

sharing

is
same as
conducted within this model,
StateNet PS, but
are
its parameters
initialized with a pre-trained model.
For
pre-training, we only allow the model to
track one single slot and make predictions on
its value set. After the training ends, we save
the model parameters and use them to ini-
tialize the model parameters for the training
of the multi-slot tracking. The pre-trained
model with the best performance on the
validation set is selected for initialization.
Here, we choose the food slot for pre-training
since StateNet has the lowest prediction
accuracy on the food slot. StateNet PSI
is trained using Adam optimizer and learning
rate is set to 0.001. Since the model has
obtained the basic knowledge from the
pre-trained model, then a more aggressive
learning process is preferred. Adam with a
higher learning rate can help a lot compared
to RMSProp optimizer.

The hyperparameters are identical for all three
models, Nc = 128, Nw = 300, n = 2, m = 3.
We use c = 4 for the number of the receptors for
each slot, where the number is determined through
the grid search. The word embeddings used by us
is the semantically specialised Paragram-SL999
vectors (Wieting et al., 2015) with the dimension
of 300, which contain richer semantic contents
compared to other kinds of word embeddings. Im-
plemented with the MXNet deep learning frame-
work of Version 1.1.0, the model is trained with
a batch size of 32 for 150 epochs on a single
NVIDIA GTX 1080Ti GPU.

It

The results in Table 1 show the effective-
ness of parameter sharing and initialization.
StateNet PS outperforms StateNet, and
StateNet PSI performs best among all 3 mod-
els.
is because the parameter sharing can
not only prevent the model diverging from the
right learning process but also transfer necessary
knowledge among different slots. And the param-
eter initialization provides the model with the op-
portunity to gain some basic while essential se-
mantic information at the very beginning since
the food slot is the most important and difﬁcult
one. Besides, StateNet PSI beats all the mod-

DST Models

Delexicalisation-Based (DB) Model (Mrkˇsi´c et al., 2017)
DB Model + Semantic Dictionary (Mrkˇsi´c et al., 2017)
Scalable Multi-domain DST (Rastogi et al., 2017)
MemN2N (Perez and Liu, 2017)
PtrNet (Xu and Hu, 2018)
Neural Belief Tracker: NBT-DNN (Mrkˇsi´c et al., 2017)
Neural Belief Tracker: NBT-CNN (Mrkˇsi´c et al., 2017)
Belief Tracking: Bi-LSTM (Ramadan et al., 2018)
Belief Tracking: CNN (Ramadan et al., 2018)
GLAD (Zhong et al., 2018)
StateNet
StateNet PS
StateNet PSI

Joint Acc.
DSTC2
69.1
72.9
70.3
74.0
72.1
72.6
73.4
-
-
74.5
74.1
74.5
75.5

Joint Acc.
WOZ 2.0
70.8
83.7
-
-
-
84.4
84.2
85.1
85.5
88.1
87.8
88.2
88.9

Table 1: Joint goal accuracy on DSTC2 and WOZ 2.0 test set vs. various approaches as reported in the literature.

els reported in the previous literature, whether
the model with delexicalisation (Henderson et al.,
2014b,c; Rastogi et al., 2017) or not (Mrkˇsi´c et al.,
2017; Perez and Liu, 2017; Xu and Hu, 2018; Ra-
madan et al., 2018; Zhong et al., 2018).

Initialization

food
pricerange
area

Joint Acc.
DSTC2
75.5
73.6
73.5

Joint Acc.
WOZ 2.0
88.9
88.2
87.8

Table 2: Joint goal accuracy on DSTC2 and WOZ 2.0
of StateNet PSI using different pre-trained models
based on different single slot.

We also test StateNet PSI with different
pre-trained models, as shown in Table 2. The
fact that the food initialization has the best perfor-
mance veriﬁes our selection of the slot with the
worst performance for pre-training. This is be-
cause the good performance on joint goal requires
a model to make correct predictions on all of the
slots. A slot on which the model has the worst
accuracy, i.e. the most difﬁcult slot, will dramat-
ically limit the overall model performance on the
metric of the joint goal accuracy. Thus, the initial-
ization with a model pre-trained on the most difﬁ-
cult slot can improve the performance of the model
on its weakness slot and boost the joint goal accu-
racy, while the initialization of a strength slot may
not help much for the overall accuracy but in turn
causes the over-ﬁtting problem of the slot itself.

4 Conclusion

In this paper, we propose a novel dialogue state
tracker that has the state-of-the-art accuracy as
well as the following three advantages: 1) the
model does not need manually-tagged user utter-
ance; 2) the model is scalable for the slots that
need tracking, and the number of the model pa-
rameters will not increase as the number of the
slots increases, because the model can share pa-
rameters among different slots; 3) the model is
independent of the number of slot values, which
means for a given slot, the model can make the
prediction on a new value as long as we have the
corresponding word vector of this new value. If
there are a great number of values for a certain
slot, to reduce the computational complexity, we
can utilize a ﬁxed-size candidate set (Rastogi et al.,
2017), which dynamically changes as the dialogue
goes on. Experiment results demonstrate the ef-
fectiveness of parameter sharing & initialization.
Our future work is to evaluate the performance
of our models in the scenario where there are new
slots and more unobserved slot values, and to eval-
uate the domain-transferring ability of our models.

Acknowledgments

The corresponding author is Kai Yu. This work
has been supported by the National Key Re-
search and Development Program of China
(Grant No. 2017YFB1002102) and the China
NSFC project (No. 61573241). Experiments have
been carried out on the PI supercomputer at
Shanghai Jiao Tong University.

References

Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hin-
arXiv preprint

ton. 2016. Layer normalization.
arXiv:1607.06450.

Lu Chen, Bowen Tan, Sishan Long, and Kai Yu.
2018. Structured dialogue policy with graph neu-
In Proceedings of the 27th Inter-
ral networks.
national Conference on Computational Linguistics,
pages 1257–1268.

Zhehuai Chen, Yimeng Zhuang, and Kai Yu. 2017.
Conﬁdence measures for ctc-based phone syn-
In IEEE International Con-
chronous decoding.
ference on Acoustics, Speech and Signal Process-
ing(ICASSP), pages 4850–4854.

Matthew Henderson, Blaise Thomson, and Jason D
Williams. 2014a. The second dialog state tracking
challenge. In Proceedings of the 15th Annual Meet-
ing of the Special Interest Group on Discourse and
Dialogue (SIGDIAL), pages 263–272, Philadelphia,
PA, U.S.A. Association for Computational Linguis-
tics.

Matthew Henderson, Blaise Thomson, and Steve
Young. 2014b. Robust dialog state tracking using
delexicalised recurrent neural networks and unsu-
pervised adaptation. In Proceedings of IEEE Spoken
Language Technology Workshop (SLT).

Matthew Henderson, Blaise Thomson, and Steve
Young. 2014c. Word-based dialog state tracking
In Proceedings
with recurrent neural networks.
of the 15th Annual Meeting of the Special Inter-
est Group on Discourse and Dialogue (SIGDIAL),
pages 292–299, Philadelphia, PA, U.S.A. Associa-
tion for Computational Linguistics.

Mettew Henderson, Blaise Thomson, and Jason D.
Williams. 2014d. The third dialog state tracking
In Proceedings of IEEE Spoken Lan-
challenge.
guage Technology Workshop (SLT).

Sepp Hochreiter and J¨urgen Schmidhuber. 1997.
Neural computation,

Long short-term memory.
9(8):1735–1780.

Sungjin Lee. 2013. Structured discriminative model
In Proceedings of the
for dialog state tracking.
SIGDIAL 2013 Conference, pages 442–451, Metz,
France. Association for Computational Linguistics.

Sungjin Lee and Maxine Eskenazi. 2013. Recipe for
building robust spoken dialog state trackers: Dialog
state tracking challenge system description. In Pro-
ceedings of the SIGDIAL 2013 Conference, pages
414–422, Metz, France. Association for Computa-
tional Linguistics.

(Volume 1: Long Papers), volume 1, pages 1777–
1788.

Julien Perez and Fei Liu. 2017. Dialog state track-
ing, a machine reading approach using memory net-
work. In Proceedings of the 15th Conference of the
European Chapter of the Association for Compu-
tational Linguistics: Volume 1, Long Papers, vol-
ume 1, pages 305–314.

Osman Ramadan, Paweł Budzianowski, and Milica
Gasic. 2018. Large-scale multi-domain belief track-
ing with knowledge sharing. In Proceedings of the
56th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 2: Short Papers), vol-
ume 2, pages 432–437.

Abhinav Rastogi, Dilek Hakkani-Tur, and Larry Heck.
2017. Scalable multi-domain dialogue state track-
ing. arXiv preprint arXiv:1712.10224.

Kai Sun, Lu Chen, Su Zhu, and Kai Yu. 2014a. A gen-
eralized rule based tracker for dialogue state track-
ing. In Proceedings of IEEE Spoken Language Tech-
nology Workshop (SLT).

Kai Sun, Lu Chen, Su Zhu, and Kai Yu. 2014b. The
SJTU system for dialog state tracking challenge
In Proceedings of the 15th Annual Meeting of
2.
the Special Interest Group on Discourse and Dia-
logue (SIGDIAL), pages 318–326, Philadelphia, PA,
U.S.A. Association for Computational Linguistics.

Kai Sun, Qizhe Xie, and Kai Yu. 2016a. Recurrent
polynomial network for dialogue state tracking. Di-
alogue & Discourse, 7(3):65–88.

Kai Sun, Su Zhu, Lu Chen, Siqiu Yao, Xueyang Wu,
and Kai Yu. 2016b. Hybrid dialogue state track-
In
ing for real world human-to-human dialogues.
Proc. InterSpeech, pages 2060–2064, San Francisco,
America.

Blaise Thomson and Steve Young. 2010. Bayesian up-
date of dialogue state: A POMDP framework for
spoken dialogue systems. Computer Speech & Lan-
guage, 24(4):562–588.

Zhuoran Wang and Oliver Lemon. 2013. A simple
and generic belief tracking mechanism for the dialog
state tracking challenge: On the believability of ob-
served information. In Proceedings of the SIGDIAL
2013 Conference, pages 423–432, Metz, France. As-
sociation for Computational Linguistics.

Tsung-Hsien Wen, David Vandyke, Nikola Mrkˇsi´c,
Milica Gasic, Lina M. Rojas Barahona, Pei-Hao Su,
Stefan Ultes, and Steve Young. 2017. A network-
based end-to-end trainable task-oriented dialogue
system. In EACL, pages 438–449, Valencia, Spain.
Association for Computational Linguistics.

Nikola Mrkˇsi´c, Diarmuid ´O S´eaghdha, Tsung-Hsien
Wen, Blaise Thomson, and Steve Young. 2017.
Neural belief tracker: Data-driven dialogue state
tracking. In Proceedings of the 55th Annual Meet-
ing of the Association for Computational Linguistics

John Wieting, Mohit Bansal, Kevin Gimpel, Karen
Livescu, and Dan Roth. 2015. From paraphrase
database to compositional paraphrase model and
back. Transactions of the Association for Compu-
tational Linguistics, 3:345–358.

Jason Williams, Antoine Raux, Deepak Ramachan-
dran, and Alan Black. 2013. The dialog state track-
ing challenge. In Proceedings of the SIGDIAL 2013
Conference, pages 404–413, Metz, France. Associa-
tion for Computational Linguistics.

Kaige Xie, Cheng Chang, Liliang Ren, Lu Chen, and
Kai Yu. 2018. Cost-sensitive active learning for di-
In Proceedings of the 19th
alogue state tracking.
Annual Meeting of the Special Interest Group on
Discourse and Dialogue (SIGDIAL), pages 209–
213, Melbourne, Australia. Association for Compu-
tational Linguistics.

Qizhe Xie, Kai Sun, Su Zhu, Lu Chen, and Kai Yu.
2015. Recurrent polynomial network for dialogue
state tracking with mismatched semantic parsers.
In Proceedings of the 16th Annual Meeting of the
Special Interest Group on Discourse and Dialogue,
pages 295–304, Prague, Czech Republic. Associa-
tion for Computational Linguistics.

Puyang Xu and Qi Hu. 2018. An end-to-end approach
for handling unknown slot values in dialogue state
tracking. In Proceedings of the 56th Annual Meet-
ing of the Association for Computational Linguistics
(Volume 1: Long Papers), volume 1.

Steve Young, Milica Gaˇsi´c, Simon Keizer, Franc¸ois
Mairesse, Jost Schatzmann, Blaise Thomson, and
Kai Yu. 2010. The hidden information state model:
A practical framework for POMDP-based spoken
dialogue management. Computer Speech & Lan-
guage, 24(2):150–174.

Steve Young, Milica Gasic, Blaise Thomson, and Ja-
son D. Williams. 2013. POMDP-based statistical
spoken dialog systems: A review. Proceedings of
the IEEE, 101(5):1160–1179.

Kai Yu, Lu Chen, Bo Chen, Kai Sun, and Su Zhu. 2014.
Cognitive technology in task-oriented dialogue sys-
tems: Concepts, advances and future. Chinese Jour-
nal of Computers, 37(18):1–17.

Kai Yu, Lu Chen, Kai Sun, Qizhe Xie, and Su Zhu.
2016. Evolvable dialogue state tracking for statis-
tical dialogue management. Frontiers of Computer
Science, 10(2):201–215.

Kai Yu, Kai Sun, Lu Chen, and Su Zhu. 2015.
Constrained markov bayesian polynomial for efﬁ-
cient dialogue state tracking. IEEE/ACM Transac-
tions on Audio, Speech and Language Processing,
23(12):2177–2188.

Victor Zhong, Caiming Xiong, and Richard Socher.
2018. Global-locally self-attentive encoder for dia-
logue state tracking. In Proceedings of the 56th An-
nual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), volume 1,
pages 1458–1467.

