7
1
0
2
 
b
e
F
 
0
1
 
 
]

G
L
.
s
c
[
 
 
1
v
0
4
0
3
0
.
2
0
7
1
:
v
i
X
r
a

Following the Leader and Fast Rates in Linear Prediction: Curved
Constraint Sets and Other Regularities∗

Ruitong Huang

Tor Lattimore

András György

Csaba Szepesvári

February 13, 2017

Abstract

The follow the leader (FTL) algorithm, perhaps the simplest of all online learning algorithms, is
known to perform well when the loss functions it is used on are convex and positively curved. In this
paper we ask whether there are other “lucky” settings when FTL achieves sublinear, “small” regret. In
particular, we study the fundamental problem of linear prediction over a non-empty convex, compact
domain. Amongst other results, we prove that the curvature of the boundary of the domain can act
as if the losses were curved: In this case, we prove that as long as the mean of the loss vectors have
positive lengths bounded away from zero, FTL enjoys a logarithmic growth rate of regret, while, e.g., for
polytope domains and stochastic data it enjoys ﬁnite expected regret. Building on a previously known
meta-algorithm, we also get an algorithm that simultaneously enjoys the worst-case guarantees and the
bound available for FTL.

1

Introduction

Learning theory traditionally has been studied in a statistical framework, discussed at length, for example, by
Shalev-Shwartz and Ben-David (2014). The issue with this approach is that the analysis of the performance
of learning methods seems to critically depend on whether the data generating mechanism satisﬁes some
probabilistic assumptions. Realizing that these assumptions are not necessarily critical, much work has been
devoted recently to studying learning algorithms in the so-called online learning framework (Cesa-Bianchi
and Lugosi, 2006). The online learning framework makes minimal assumptions about the data generating
mechanism, while allowing one to replicate results of the statistical framework through online-to-batch
conversions (Cesa-Bianchi et al., 2004). By following a minimax approach, however, results proven in the
online learning setting, at least initially, led to rather conservative results and algorithm designs, failing to
capture how more regular, “easier” data, may give rise to faster learning speed. This is problematic as it
may suggest overly conservative learning strategies, missing opportunities to extract more information when
the data is nicer. Also, it is hard to argue that data resulting from passive data collection, such as weather
data, would ever be adversarially generated (though it is equally hard to defend that such data satisﬁes
precise stochastic assumptions). Realizing this issue, during recent years much work has been devoted to
understanding what regularities and how can lead to faster learning speed. For example, much work has
been devoted to showing that faster learning speed (smaller “regret”) can be achieved in the online convex
optimization setting when the loss functions are “curved”, such as when the loss functions are strongly convex
or exp-concave, or when the losses show small variations, or the best prediction in hindsight has a small total
loss, and that these properties can be exploited in an adaptive manner (e.g., Merhav and Feder 1992, Freund
and Schapire 1997, Gaivoronski and Stella 2000, Cesa-Bianchi and Lugosi 2006, Hazan et al. 2007, Bartlett

∗R. Huang and Cs. Szepesvári are with the Department of Computing Science, University of Alberta, AB, Canada, email:
ruitong@ualberta.ca, szepesva@ualberta.ca. T. Lattimore was with the School of Informatics and Computing, Indiana
University, IN, USA, email: tor.lattimore@gmail.com. A. György is with the Department of Electrical and Electronic
Engineering, Imperial College London, UK, email: a.gyorgy@imperial.ac.uk.

1

et al. 2007, Kakade and Shalev-Shwartz 2009, Orabona et al. 2012, Rakhlin and Sridharan 2013, van Erven
et al. 2015, Foster et al. 2015).

In this paper we contribute to this growing literature by studying online linear prediction and the follow
the leader (FTL) algorithm. Online linear prediction is arguably the simplest yet fundamental of all the
learning settings, and lies at the heart of online convex optimization, while it also serves as an abstraction
of core learning problems such as prediction with expert advice. FTL, the online analogue of empirical
risk minimization of statistical learning, is the simplest learning strategy, one can think of. Although the
linear setting of course removes the possibility of exploiting the curvature of losses, as we will see, there are
multiple ways online learning problems can present data that allows for small regret, even for FTL. As is
it well known, in the worst case, FTL suﬀers a linear regret (e.g., Example 2.2 of Shalev-Shwartz (2012)).
However, for “curved” losses (e.g., exp-concave losses), FTL was shown to achieve small (logarithmic) regret
(see, e.g., Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan
et al. (2007)).

In this paper we take a thorough look at FTL in the case when the losses are linear, but the problem
perhaps exhibits other regularities. The motivation comes from the simple observation that, for prediction
over the simplex, when the loss vectors are selected independently of each other from a distribution with
a bounded support with a nonzero mean, FTL quickly locks onto selecting the loss-minimizing vertex of
the simplex, achieving ﬁnite expected regret. In this case, FTL is arguably an excellent algorithm. In fact,
FTL is shown to be the minimax optimizer for the binary losses in the stochastic expert setting in the paper
of Kotłowski (2016). Thus, we ask the question of whether there are other regularities that allow FTL to
achieve nontrivial performance guarantees. Our main result shows that when the decision set (or constraint
set) has a suﬃciently “curved” boundary (equivalently, if it is strongly convex) and the linear loss is bounded
away from 0, FTL is able to achieve logarithmic regret even in the adversarial setting, thus opening up a new
way to prove fast rates not based on the curvature of losses, but on that of the boundary of the constraint
set and non-singularity of the linear loss. In a matching lower bound we show that this regret bound is
essentially unimprovable. We also show an alternate bound for polytope constraint sets, which allows us to
prove that (under certain technical conditions) for stochastic problems the expected regret of FTL will be
ﬁnite. To ﬁnish, we use (A, B)-prod of Sani et al. (2014) to design an algorithm that adaptively interpolates
between the worst case O(
n log n) regret and the smaller regret bounds, which we prove here for “easy
data.” We also show that if the constraint set is the unit ball, both the follow the regularized leader (FTRL)
algorithm and a combination of FTL and shrinkage, which we call follow the shrunken leader (FTSL), achieve
logarithmic regret for easy data. Simulation results on artiﬁcial data complement the theoretical ﬁndings.

√

While we believe that we are the ﬁrst to point out that the curvature of the constraint set W can help in
speeding up learning, this eﬀect is known in convex optimization since at least the work of Levitin and Polyak
(1966), who showed that exponential rates are attainable for strongly convex constraint sets if the norm
of the gradients of the objective function admit a uniform lower bound. More recently, Garber and Hazan
(2015) proved an O(1/n2) optimization error bound (with problem-dependent constants) for the Frank-Wolfe
algorithm for strongly convex and smooth objectives and strongly convex constraint sets. The eﬀect of the
n) regret in
shape of the constraint set was also discussed by Abbasi-Yadkori (2010) who demonstrated O(
the linear bandit setting. While these results at a high level are similar to ours, our proof technique is rather
diﬀerent than that used there.

√

2 Preliminaries, online learning and the follow the leader algo-

rithm

We consider the standard framework of online convex optimization, where a learner and an environment
interact in a sequential manner in n rounds: In round every round t = 1, . . . , n, ﬁrst the learner predicts
wt ∈ W. Then the environment picks a loss function ‘t ∈ L, and the learner suﬀers loss ‘t(wt) and observes
‘t. Here, W is a non-empty, compact convex subset of Rd and L is a set of convex functions, mapping W to
the reals. The elements of L are called loss functions. The performance of the learner is measured in terms of

2

its regret,

Rn =

‘t(wt) − min
w∈W

‘t(w) .

n
X

t=1

n
X

t=1

The simplest possible case, which will be the focus of this paper, is when the losses are linear, i.e., when
‘t(w) = hft, wi for some ft ∈ F ⊂ Rd.
In fact, the linear case is not only simple, but is also fundamental
since the case of nonlinear loss functions can be reduced to it: Indeed, even if the losses are nonlinear, deﬁning
ft ∈ ∂‘t(wt) to be a subgradient1 of ‘t at wt and letting ˜‘t(u) = hft, ui, by the deﬁnition of subgradients,
‘t(wt) − ‘t(u) ≤ ‘t(wt) − (‘t(wt) + hft, u − wti) = ˜‘t(wt) − ˜‘t(u), hence for any u ∈ W,

‘t(wt) −

‘t(u) ≤

X

˜‘t(wt) −

X

˜‘t(u) .

X

t

X

t

t

t

In particular, if an algorithm keeps the regret small no matter how the linear losses are selected (even when
allowing the environment to pick losses based on the choices of the learner), the algorithm can also be used to
keep the regret small in the nonlinear case. Hence, in what follows we will study the linear case ‘t(w) = hft, wi
and, in particular, we will study the regret of the so-called “Follow The Leader” (FTL) learner, which, in
round t ≥ 2 picks

wt = argmin

‘i(w) .

w∈W

t−1
X

i=1

For the ﬁrst round, w1 ∈ W is picked in an arbitrary manner. When W is compact, the optimal w of
minw∈W
i=1hw, fti is attainable, which we will assume henceforth. If multiple minimizers exist, we simply
ﬁx one of them as wt. We will also assume that F is non-empty, compact and convex.

Pt−1

2.1 Support functions
Pt
Let Θt = − 1
t
deﬁne Θ0 := 0. Thus, for t ≥ 2,

i=1 fi be the negative average of the ﬁrst t vectors in (ft)n

t=1, ft ∈ F. For convenience, we

wt = argmin

hw, fii = argmin

hw, −Θt−1i = argmax

hw, Θt−1i .

w∈W

w∈W

w∈W

t−1
X

i=1

Denote by Φ(Θ) = maxw∈W hw, Θi the so-called support function of W. The support function, being the
maximum of linear and hence convex functions, is itself convex. Further Φ is positive homogenous: for a ≥ 0
and θ ∈ Rd, Φ(aθ) = aΦ(θ). It follows then that the epigraph epi(Φ) = (cid:8)(θ, z) | z ≥ Φ(θ), z ∈ R, θ ∈ Rd(cid:9) of Φ
is a cone, since for any (θ, z) ∈ epi(Φ) and a ≥ 0, az ≥ aΦ(θ) = Φ(aθ), (aθ, az) ∈ epi(Φ) also holds.

The diﬀerentiability of the support function is closely tied to whether in the FTL algorithm the choice of

wt is uniquely determined:

Proposition 2.1. Let W 6= ∅ be convex and closed. Fix Θ and let Z := {w ∈ W | hw, Θi = Φ(Θ)}. Then,
∂Φ(Θ) = Z and, in particular, Φ(Θ) is diﬀerentiable at Θ if and only if maxw∈W hw, Θi has a unique
optimizer. In this case, ∇Φ(Θ) = argmaxw∈W hw, Θi.

The proposition follows from Danskin’s theorem when W is compact (e.g., Proposition B.25 of Bertsekas
1999), but a simple direct argument can also be used to show that it also remains true even when W is
unbounded. 2 By Proposition 2.1, when Φ is diﬀerentiable at Θt−1, wt = ∇Φ(Θt−1).

1 We let ∂g(x) denote the subdiﬀerential of a convex function g

(cid:8)θ ∈ Rd | g(x0) ≥ g(x) + hθ, x0 − xi ∀x0 ∈ dom(g)(cid:9), where dom(g) ⊂ Rd is the domain of g.

2 The proofs not given in the main text can be found in the appendix.

: dom(g) → R at x,

i.e., ∂g(x) =

3

3 Non-stochastic analysis of FTL

We start by rewriting the regret of FTL in an equivalent form, which shows that we can expect FTL to enjoy
a small regret when successive weight vectors move little. A noteworthy feature of the next proposition is
that rather than bounding the regret from above, it gives an equivalent expression for it.

Proposition 3.1. The regret Rn of FTL satisﬁes

Rn =

t hwt+1 − wt, Θti .

n
X

t=1

The result is a direct corollary of Lemma 9 of McMahan (2010), which holds for any sequence of losses,
even in the lack of convexity. It is also a tightening of the well-known inequality Rn ≤ Pn
t=1 ‘t(wt) − ‘t(wt+1),
which again holds for arbitrary loss sequences (e.g., Lemma 2.1 of Shalev-Shwartz (2012)). To keep the paper
self-contained, we give an elegant, short direct proof, based on the summation by parts formula:
Proof. The summation by parts formula states that for any u1, v1, . . . , un+1, vn+1 reals, Pn
(ut+1vt+1 − u1v1) − Pn
vt+1 := tΘt, we get

t=1 ut (vt+1 − vt) =
t=1(ut+1 − ut) vt+1. Applying this to the deﬁnition of regret with ut := wt,· and

n
X

Rn = −

hwt, tΘt − (t − 1)Θt−1i + hwn+1, nΘni

t=1
(
(cid:104)(cid:104)(cid:104)(cid:104)(cid:104)(cid:104)
hwn+1, nΘni − 0 −

= −

n
X

t=1

hwt+1 − wt, tΘti

)

(cid:104)(cid:104)(cid:104)(cid:104)(cid:104)(cid:104)
hwn+1, nΘni.

+

Our next proposition gives another formula that is equal to the regret. As opposed to the previous
result, this formula is appealing as it is independent of wt; but it directly connects the sequence (Θt)t to the
geometric properties of W through the support function Φ. For this proposition we will momentarily assume
that Φ is diﬀerentiable at (Θt)t≥1; a more general statement will follow later.

Proposition 3.2. If Φ is diﬀerentiable at Θ1, . . . , Θn,

Rn =

t DΦ(Θt, Θt−1) ,

n
X

t=1

where DΦ(θ0, θ) = Φ(θ0) − Φ(θ) − h∇Φ(θ), θ0 − θi is the Bregman divergence of Φ and we use the convention
that ∇Φ(0) = w1.

Proof. Let v = argmaxw∈W hw, θi, v0 = argmaxw∈W hw, θ0i. When Φ is diﬀerentiable at θ,

DΦ(θ0, θ) = Φ(θ0) − Φ(θ) − h∇Φ(θ), θ0 − θi = hv0, θ0i− hv, θi − hv, θ0 − θi = hv0 − v, θ0i .
t=1 thwt+1 − wt, Θti = Pn

t=1 t DΦ(Θt, Θt−1).

Therefore, by Proposition 3.1, Rn = Pn

When Φ is non-diﬀerentiable at some of the points Θ1, . . . , Θn, the equality in the above proposition can
be replaced with inequalities. Deﬁning the upper Bregman divergence DΦ(θ0, θ) = supw∈∂Φ(θ) Φ(θ0) − Φ(θ) −
hw, θ0 − θi and the lower Bregman divergence DΦ(θ0, θ) similarly with inf instead of sup, we can easily obtain
an analogue of Proposition 3.2:

(1)

(2)

(3)

n
X

t=1

t DΦ(Θt, Θt−1) ≤ Rn ≤

t DΦ(Θt, Θt−1) .

n
X

t=1

4

3.1 Constraint sets with positive curvature

The previous results show in an implicit fashion that the curvature of W controls the regret. Before presenting
our ﬁrst main result, which makes this connection explicit, we deﬁne some basic notions from diﬀerential
geometry related to the curvature (all diﬀerential geometry concept and results that we need can be found in
Section 2.5 of Schneider, 2014).

Given a C 2 (twice continuously diﬀerentiable) planar curve γ in R2, there exists a parametrization with
respect to the curve length s, such that kγ0(s)k = k (x0(s), y0(s)) k = x0(s)2+y0(s)2 = 1. Under the curve length
parametrization, the curvature of γ at γ(s) is kγ00(s)k. Deﬁne the unit normal vector n(s) as the unit vector
that is perpendicular to γ0(s).3 Note that n(s) · γ0(s) = 0. Thus 0 = (n(s) · γ0(s))0 = n0(s) · γ0(s) + n(s) · γ00(s),
and kγ00(s)k = kn(s) · γ00(s)k = kn0(s) · γ0(s)k = kn0(s)k. Therefore, the curvature of γ at point γ(s) is the
length of the diﬀerential of its unit normal vector.

Denote the boundary of W by bd(W). We shall assume that W is C 2, that is, bd(W) is a twice
continuously diﬀerentiable submanifold of Rd. We denote the tangent plane of bd(W) at point w by TwW.
Now there exists a unique unit vector at w that is perpendicular to TwW and points outward of W. In
fact, one can deﬁne a continously diﬀerentiable normal unit vector ﬁeld on bd(W), uW : bd(W) → Sd−1,
the so-called Gauss map, which maps a boundary point w ∈ bd(W) to the unique outer normal vector to
W at w, where Sd−1 = (cid:8)x ∈ Rd | kxk2 = 1(cid:9) denotes the unit sphere in d-dimensions. The diﬀerential of the
Gauss map, ∇uW (w), deﬁnes a linear endomorphism of TwW. Moreover, ∇uW (w) is a self-adjoint operator,
with nonnegative eigenvalues. The diﬀerential of the Gauss map, ∇uW (w), describes the curvature of bd(W)
via the second fundamental form. In particular, the principal curvatures of bd(W) at w ∈ bd(W) is deﬁned
as the eigenvalues of ∇uW (w). Perhaps a more intuitive, yet equivalent deﬁnition, is that the principal
curvatures are the eigenvalues of the Hessian of f = fw in the parameterization t 7→ w + t − fw(t)uW (w) of
bd(W) which is valid in a small open neighborhood of w, where fw : TwW → [0, ∞) is a suitable convex,
nonnegative valued function that also satisﬁes fw(0) = 0 and where TwW, a hyperplane of Rd, denotes the
tangent space of W at w, obtained by taking the support plane H of W at w and shifting it by −w. Thus,
the principal curvatures at some point w ∈ bd(W) describe the local shape of bd(W) up to the second order.
In this paper, we are interested in the minimum principal curvature at w ∈ bd(W), which can be intepreated
as the minimum curvature at w over all the planar curves γ ∈ bd(W) that go through w.

A related concept that has been used in convex optimization to show fast rates is that of a strongly
convex constraint set (Levitin and Polyak, 1966; Garber and Hazan, 2015): W is λ-strongly convex with
respect to the norm k·k if, for any x, y ∈ W and γ ∈ [0, 1], the k·k-ball with origin γx + (1 − γ)y and radius
γ(1 − γ)λ kx − yk2 /2 is included in W. We show in Proposition A.1 in the appendix that a convex body
W ∈ C 2 is λ-strongly convex with respect to k·k2 if and only if the principal curvatures of the surface bd(W)
are all at least λ.

As promised, our next result connects the principal curvatures of bd(W) to the regret of FTL and shows
that FTL enjoys logarithmic regret for highly curved surfaces, as long as kΘtk2 is bounded away from zero.
Theorem 3.3. Let W ⊂ Rd be a C 2 convex body4 with d ≥ 2. Let M = maxf ∈F kf k2 and assume that Φ is
diﬀerentiable at (Θt)t. Assume that the principal curvatures of the surface bd(W) are all at least λ0 for some
constant λ0 > 0 and Ln := min1≤t≤n kΘtk2 > 0. Choose w1 ∈ bd(W). Then

Rn ≤

(1 + log(n)) .

2M 2
λ0Ln

As we will show later in an essentially matching lower bound, this bound is tight, showing that the
forte of FTL is when Ln is bounded away from zero and λ0 is large. Note that the bound is vacuous as
n). One
soon as Ln = O(log(n)/n) and is worse than the minimax bound of O(
possibility to reduce the bound’s sensitivity to Ln is to use the trivial bound hwt+1 − wt, Θti ≤ LW =
L supw,w0∈W kw − w0k2 for indices t when kΘtk ≤ L. Then, by optimizing the bound over L, one gets

n) when Ln = o(log(n)/

√

√

3There exist two unit vectors that are perpendicular to γ0(s) for each point on γ. Pick the ones that are consistently oriented.
4Following Schneider (2014), a convex body of Rd is any non-empty, compact, convex subset of Rd.

5

(cid:16) 2M 2
λ0L (1 + log(n)) + LW Pn

(cid:17)
t=1 t I (kΘtk ≤ L)

, which is more
a data-dependent bound of the form inf L>0
complex, but is free of Ln and thus reﬂects the nature of FTL better. Note that in the case of stochastic
problems, where f1, . . . , fn are independent and identically distributed (i.i.d.) with µ := −E [Θt] 6= 0, the
probability that kΘtk2 < kµk2 /2 is exponentially small in t. Thus, selecting L = kµk2 /2 in the previous
bound, the contribution of the expectation of the second term is O(kµk2 W ), giving an overall bound of the
form O( M 2
log(n) + kµk2 W ). After the proof we will provide some simple examples that should make it
more intuitive how the curvature of W helps keeping the regret of FTL small.

λ0kµk2

Proof. Fix θ1, θ2 ∈ Rd and let w(1) = argmaxw∈W hw, θ1i, w(2) = argmaxw∈W hw, θ2i. Note that if θ1, θ2 6= 0
then w(1), w(2) ∈ bd(W). Below we will show that

hw(1) − w(2), θ1i ≤

1
2λ0

kθ2 − θ1k2
2
kθ2k2

.

Proposition 3.1 suggests that it suﬃces to bound hwt+1 − wt, Θti. By (4), we see that it suﬃces to bound
how much Θt moves. A straightforward calculation shows that Θt cannot move much: for any norm k·k on
F, we have

kΘt − Θt−1k =

fi −

fi

=

−

fi −

ft

t−1
X

1
t − 1

i=1
(cid:18) 1

t−1
X

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

≤

=

−

t − 1

i=1
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
t

1
t − 1

t−1
X

i=1

1
t
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

t−1
X

(cid:18) 1

t
X

1
t

i=1
(cid:13)
(cid:19)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

fi

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

i=1
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
t

+

ft

=

t − 1
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

t−1
X

i=1

(cid:19)

1
t

1
t

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
t(t − 1)

fi

+

(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
t

(cid:13)
(cid:13)
(cid:13)
(cid:13)

ft

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

fi

+

kftk ≤

M .

1
t

2
t

where M = maxf ∈F kf k is a constant that depends on F and the norm k·k.

Combining inequality (4) with Proposition 3.1 and (5), we get

Rn =

thwt+1 − wt, Θti ≤

n
X

t=1
2M 2
λ0

≤

n
X

t=1
2M 2
λ0Ln

t
2λ0
n
X

t=1

kΘt − Θt−1k2
2
kΘt−1k2

1
t

≤

2M 2
λ0Ln

(1 + log(n)) .

n
X

t=1

1
tkΘt−1k2

≤

To ﬁnish the proof, it thus remains to show (4).

The following elementary lemma relates the cosine of the angle between two vectors θ1 and θ2 to the
squared normalized distance between the two vectors, thereby reducing our problem to bounding the cosine
of this angle. For brevity, we denote by cos(θ1, θ2) the cosine of the angle between θ1 and θ2.
Lemma 3.4. For any non-zero vectors θ1, θ2 ∈ Rd,

1 − cos(θ1, θ2) ≤

1
2

kθ1 − θ2k2
2
kθ1k2kθ2k2

.

Proof. Note that kθ1k2kθ2k2 cos(θ1, θ2) = hθ1, θ2i. Therefore, (6) is equivalent to 2kθ1k2kθ2k2 − 2hθ1, θ2i ≤
kθ1 − θ2k2

2, which, by algebraic manipulations, is itself equivalent to 0 ≤ (kθ1k2 − kθ2k2)2.

With this result, we see that it suﬃces to upper bound cos(θ1, θ2) by 1 − λ0hw(1) − w(2),

i. To
develop this bound, let ˜θi = θi
for i = 1, 2. The angle between θ1 and θ2 is the same as the angle between
kθik2
the normalized vectors ˜θ1 and ˜θ2. To calculate the cosine of the angle between ˜θ1 and ˜θ2, let P be a plane
spanned by ˜θ1 and w(1) − w(2) and passing through w(1) (P is uniquely determined if ˜θ1 is not parallel to

θ1
kθ1k2

6

(4)

(5)

(6)

Figure 1: Illustration of the construction used in the proof of (4).

w(1) − w(2); if there are multiple planes, just pick any of them). Further, let ˆθ2 ∈ Sd−1 be the unit vector
along the projection of ˜θ2 onto the plane P , as indicated in Fig. 1. Clearly, cos(˜θ1, ˜θ2) ≤ cos(˜θ1, ˆθ2).

Consider a curve γ(s) on bd(W) connecting w(1) and w(2) that is deﬁned by the intersection of bd(W)
and P and is parametrized by its curve length s so that γ(0) = w(1) and γ(l) = w(2), where l is the length of
the curve γ between w(1) and w(2). Let uW (w) denote the outer normal vector to W at w as before, and let
uγ : [0, l] → Sd−1 be such that uγ(s) = ˆθ where ˆθ is the unit vector parallel to the projection of uW (γ(s)) on
the plane P . By deﬁnition, uγ(0) = ˜θ1 and uγ(l) = ˆθ2. Note that in fact γ exists in two versions since W is a
compact convex body, hence the intersection of P and bd(W) is a closed curve. Of these two versions we
choose the one that satisﬁes that hγ0(s), ˜θ1i ≤ 0 for s ∈ [0, l].5 Given the above, we have

cos(˜θ1, ˆθ2) = hˆθ2, ˜θ1i = 1+ hˆθ2 − ˜θ1, ˜θ1i = 1+

γ(s) ds, ˜θ1
u0

= 1+

hu0

γ(s), ˜θ1i ds.

(7)

D Z l

0

E

Z l

0

Note that γ is a planar curve on bd(W), thus its curvature λ(s) satisﬁes λ(s) ≥ λ0 for s ∈ [0, l]. Also, for any
w on the curve γ, γ0(s) is a unit vector parallel to P . Moreover, u0
γ(s)k2.
Therefore,

γ(s) is parallel to γ0(s) and λ(s) = ku0

hu0

γ(s), ˜θ1i = ku0

γ(s)k2hγ0(s), ˜θ1i ≤ λ0hγ0(s), ˜θ1i,

where the last inequality holds because hγ0(s), ˜θ1i ≤ 0. Plugging this into (7), we get the desired

cos(˜θ1, ˆθ2) ≤ 1 + λ0

hγ0(s), ˜θ1i ds = 1 + λ0

γ0(s) ds, ˜θ1

= 1 − λ0hw(1) − w(2), ˜θ1i .

Z l

0

D Z l

0

E

Reordering and combining with (6) we obtain

hw(1) − w(2), ˜θ1i ≤

1 − cos(˜θ1, ˆθ2)

(1 − cos(θ1, θ2)) ≤

(cid:16)

1
λ0

(cid:17)

≤

1
λ0

1
2λ0

kθ1 − θ2k2
2
kθ1k2kθ2k2

.

Multiplying both sides by kθ1k2 gives (4), thus, ﬁnishing the proof.

Example 3.5. The smallest principal curvature of some common convex bodies are as follows:

• The smallest principal curvature λ0 of the Euclidean ball W = {w | kwk2 ≤ r} of radius r satisﬁes

λ0 = 1
r .

• Let Q be a positive deﬁnite matrix. If W = (cid:8)w | w>Qw ≤ 1(cid:9) then λ0 = λmin/

λmax, where λmin and
λmax are the minimal, respectively, maximal eigenvalues of Q. (Polovinkin 1996 also derived this result
for the strong convexity deﬁnition (ii) in Proposition A.1.)

√

• In general, let φ : Rd → R be a C 2 convex function. Then, for W = {w | φ(w) ≤ 1}, λ0 =

minw∈bd(W) minv : kvk2=1,v⊥φ0(w)

v>∇2φ(w)v
kφ0(w)k2
γ denote the derivatives of γ and u, respectively, which exist since W is C2.

.

5γ0 and u0

7

We only prove the last statement, since it implies the other two.

Proof. Fix w ∈ bd(W). Note that φ0(w) is a normal vector at w for bd(W), thus TwW = {v : v ⊥ φ0(w)}.
Then the Gauss map uW of W satisﬁes uW (w) = φ0(w)
kφ0(w)k2

for w ∈ bd(W).

Next we compute the Weingarten map Ww(v) : TwW → TwW, which, by deﬁnition, is the diﬀerential of

uW (w) restricted to TwW. Note that the Weingarten map is a linear map.

Ww(v) =

d uW
d w

(cid:12)
(cid:12)
(cid:12)
(cid:12)TwW

(v) =

∇2(w)v
kφ0(w)k2

−

φ0(w)∇2φ(w)φ0(w)T v
kφ0(w)k3
2

=

∇2(w)v
kφ0(w)k2

.

By (Schneider, 2014, page 105), the principal curvature of W at w are the eigenvalues of the Weingarten
. Taking

map Ww(v). Therefore, the smallest principal curvature at w is minv : kvk2=1,v⊥φ0(w)
minimum over all w ∈ bd(W) ﬁnishes the proof.

v>∇2φ(w)v
kφ0(w)k2

√

In the stochastic i.i.d. case, when E [Θt] = −µ, we have
kΘt + µk2 = O(1/
t) with high probability. Thus say, for W being
the unit ball of Rd, one has wt = Θt/ kΘtk2; therefore, a crude
bound suggests that kwt − w∗k2 = O(1/
t), overall predicting that
E [Rn] = O(
n), while the previous result predicts that Rn is much
smaller. In the next example we look at the unit ball, to explain
geometrically, what “causes” the smaller regret.

√

√

Example 3.6. Let W = {w | kwk2 ≤ 1} and consider a stochastic
setting where the fi are i.i.d. samples from some underlying distribu-
tion with expectation E [fi] = µ = (−1, 0, . . . , 0) and kfik∞ ≤ M . It is
straightforward to see that w∗ = (1, 0, . . . , 0), and thus hw∗, µi = −1.
Let E = {−θ | kθ − µk2 ≤ (cid:15)}. As suggested beforehand, we expect
−µt ∈ E with high probability. As shown in Fig. 2, the excess loss of
#    »
#    »
ODi − 1 = | ˜BD|. Similarly, the excess loss
OA is h
an estimate
#     »
OA0 in the ﬁgure is |CD|. Therefore, for an estimate
of an estimate
−µt ∈ E, the point A is where the largest excess loss is incurred. The
triangle OAD is similar to the triangle ADB. Thus |BD|
|AD| = |AD|
|OD| .
Therefore, |BD| = (cid:15)2 and since | ˜BD| ≤ |BD|, if kµt − µk2 ≤ (cid:15), the
excess error is at most (cid:15)2 = O(1/t), making the regret Rn = O(log n).

#    »
O ˜A,

Figure 2: Illustration of how curva-
ture helps to keep the regret small.

Our last result in this section is an asymptotic lower bound for the linear game, showing that FTL achieves

the optimal rate under the condition that mint kΘtk2 ≥ L > 0.

Theorem 3.7. Let λ, L ∈ (0, 1). Assume that {(1, −L), (−1, −L)} ⊂ F and let

(cid:26)

W =

(x, y) ∈ R2 : x2 +

(cid:27)

y2
λ2 ≤ 1

be an ellipsoid with principal curvature h. Then, for any learning strategy, there exists a sequence of losses in
F such that Rn = Ω (log(n)/(Lh)) and kΘtk2 ≥ L for all t.

Note that by Example 3.5, the minimal principal curvature of W in the above theorem is λ. In fact, it is
not too hard to extend the above argument for any set W such that there is w ∈ bd(W) where the curvature
is h, and the curvature is a continuous function in a neighborhood of w over the boundary bd(W). The
constants in the bound then depend on how fast the curvature changes within this neighborhood.

Proof. We deﬁne a random loss sequence, and we will show that no algorithm on this sequence can achieve
an o(log n/(λ0L) regret. Let P be a random variable with Beta(K, K) distribution for some K > 0,

8

and, given P , assume that Xt, t ≥ 1 are i.i.d. Bernoulli random variables with parameter P . Let ft =
Xt(1, −L) + (1 − Xt)(−1, −L) = (2Xt − 1, −L). Thus, the second coordinate of ft is always −L, and so
= E [ ft| P = p] =
kΘtk2 =
(2p − 1, −L).

≥ L. Furthermore, the conditional expectation of the loss vector is f p 4

i=1 fi

(cid:13)
(cid:13)
(cid:13)2

Pt

(cid:13)
(cid:13)
(cid:13)

1
t

Note that Xt is a function of ft for all t; thus the conditional expectation of P , given f1, . . . , ft−1, can be

determined by the well-known formula ˆPt−1 = E [ P | f1 . . . ft−1] =
of f p by wp, that is, wp = argminw∈W hw, f pi. Then the Bayesian optimal choice in round t is

. Given p, denote the optimizer

K+Pt−1
2K+t−1

i=1

Xi

argmin
w∈W

E (cid:2) [(cid:10)w, f P (cid:11)(cid:12)

(cid:12) f1 . . . ft−1

(cid:3) = argmin

(cid:10)w, E (cid:2) f P (cid:12)

(cid:12) f1 . . . ft−1

(cid:3)(cid:11)

D

w, f ˆPt−1

E

w∈W

= argmin

w∈W
= w ˆPt−1 ,

where the ﬁrst equality follows by linearity of the inner product, the second since f p is a linear function of p
and the third by the deﬁnition of wp.

Thus, denoting by Wt the prediction of an arbitrary algorithm in round t, the expected regret can be

bounded from below as
"

E [Rn] = E

hWt − w, fti

= E

E

#

"

"

n
X

t=1

(cid:12)
(cid:12)
(cid:12)
hWt − w, fti
(cid:12)
(cid:12)

P

##

(cid:10)Wt − wP , ft

P

= E

E (cid:2) (cid:10)Wt − wP , ft

(cid:11)(cid:12)
(cid:12) P, f1, . . . , ft−1

#
(cid:3)

##

(cid:12)
(cid:12)
(cid:11)
(cid:12)
(cid:12)
(cid:12)

max
w∈W

" n
X

t=1
#
(cid:3)

max
w∈W

n
X

t=1

"

" n
X

≥ E

E

t=1

= E

≥ E

= E

" n
X

t=1
" n
X

t=1
" n
X

t=1

=

n
X

t=1

E (cid:2) (cid:10)Wt − wP , f P (cid:11)(cid:12)

(cid:12) f1, . . . , ft−1

E (cid:2) (cid:10)w − wP , f P (cid:11)(cid:12)

(cid:12) f1, . . . , ft−1

min
w∈W

h D

E

w ˆPt−1 − wP , f P E(cid:12)
(cid:12)
(cid:12) f1, . . . , ft−1

#
(cid:3)

#

i

hD

w ˆPt−1 − wP , f P Ei

E

,

where (9) holds because of the independence of the fs given P and since Wt is chosen based on f1, . . . , tt−1
(but not on P ), and (10) holds by (8).

By Lemma A.4 we have

hD

w ˆPt−1 − wP , f P Ei

E

≥

n
X

t=1

hL
2

n
X

E

t=1

(cid:16) 2 ˆPt−1−2P
hL

(cid:17)2

q

1 + (cid:0) 1−2P

hL

(cid:1)2 (cid:18)

1 +

(cid:16) 1−2 ˆPt−1
hL

(cid:17)2(cid:19)

(8)

(9)

(10)

(11)























(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)





P







=

2
hL

n
X

E

t=1

q

1
1 + (cid:0) 1−2P

hL

E

(cid:1)2

( ˆPt−1 − P )2
(cid:16) 1−2 ˆPt−1
hL

1 +

(cid:17)2

≥

2
hL

n
X

E

t=1

q

1
1 + (cid:0) 1−2P

hL

E

(cid:1)2

( ˆPt−1 − P )2

1 + 2 (cid:0) 1−2P

(cid:1)2

+ 2

hL

(cid:16) 2P −2 ˆPt−1
hL

(cid:17)2





P



 ,


(12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)











9

where in the last step we used (a + b)2 ≤ a2 + b2. Let Gt be the event that | ˆPt − P | ≤ K|1−2P |
2K+t ; note
that Gt holds with high probability by Lemma A.2. Then, lower bounding the ﬁrst term by 0, (12) can be
lower bounded by

2K+t + thL






2
hL

n−1
X

E

t=1






E

(cid:1)2

q

1
1 + (cid:0) 1−2P


hL

( ˆPt − P )2

1 + 2 (cid:0) 1−2P

(cid:1)2

+ 2

hL

(cid:16) 2P −2 ˆPt
hL

(cid:17)2





I(Gt)

P







(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)







≥

2
hL

n−1
X

E

t=1

q

1
1 + (cid:0) 1−2P

hL

(cid:18)

(cid:1)2

h

E

i

(cid:12)
( ˆPt − P )2I(Gt)
(cid:12)
(cid:12) P
(cid:16) 2K
2K+t

+ 2

1 + 2 (cid:0) 1−2P

(cid:1)2

hL

≥

2
hL

n−1
X

t=1

E



q

1
1 + (cid:0) 1−2P

hL

(cid:16)

(cid:1)2

h

E

i

( ˆPt − P )2I(Gt)
(cid:1)2

(cid:12)
(cid:12)
(cid:12) P
+ 8 |1−2P |

9 + 4 (cid:0) 1−2P

hL

hL

 .

(cid:17)

|1−2P |

hL + 2t


2K+t







(cid:17)2(cid:19)

Combining the above, and using ( ˆPt − P )2 ≤ 1 together with the upper bound on the probability of the event
Gc
t , the complement of Gt, given in Lemma A.2, we get

E [Rn] ≥

2
hL



E



q




E



q

n−1
X

t=1

n−1
X

t=1

1
1 + (cid:0) 1−2P

hL

(cid:16)

(cid:1)2

1
1 + (cid:0) 1−2P

hL

(cid:1)2

1
1 + (cid:0) 1−2P

hL

(cid:1)2





E

h

i

E

hL
h

− P [Gc
t ]
(cid:17)

+ 8 |1−2P |
hL
i

( ˆPt − P )2(cid:12)
(cid:12)
(cid:12) P
(cid:1)2
9 + 4 (cid:0) 1−2P
( ˆPt − P )2(cid:12)
(cid:12)
(cid:12) P
(cid:1)2
+ 8 |1−2P |
hL
( ˆPt − P )2(cid:12)
i
(cid:12)
(cid:12) P
(cid:1)2
+ 8 |1−2P |

9 + 4 (cid:0) 1−2P
h

9 + 4 (cid:0) 1−2P

hL

E

(cid:16)

(cid:16)

hL

hL

≥

2
hL





n−1
X

t=1



E



q

≥

2
hL


 − e−(t−1)h2L2





(cid:17)



 −

(cid:17)

1
1 − e−h2L2



 .

(13)

Now, by Lemma A.3, we have

E

h

( ˆPt − P )2(cid:12)
(cid:12)
(cid:12) P

i

=

K 2(1 − 2P )2
(2K + t)2 +

tP (1 − P )
(2K + t)2 ≥ P (1 − P )

(cid:18) 1
t

−

2
t(2K + t)

(cid:19)

.

Combining this with (13) and introducing the constant



C = E



q

1
1 + (cid:0) 1−2P

hL

P (1 − P )
(cid:1)2

(cid:16)

(cid:1)2

9 + 4 (cid:0) 1−2P

hL

+ 8 |1−2P |

hL





(cid:17)

we obtain, for any K > 0,

lim inf
n→∞

E [Rn]
log n

≥ lim inf
n→∞

2
hL log n

−

1
1 − e−h2L2 +

"

n−1
X

t=1

(cid:18) 1
t

C

(cid:19)#

−

2
t(2K + t)

=

2C
hL

.

(14)

It remains to calculate a constant lower bound for C that is independent of h and L. Denote |1−2P |
then 0 ≤ P (1 − P ) = 1−Y 2h2L2
distribution, E [P ] = 1

by Y ;
≤ 1/4. Deﬁne bG to be the event when |Y | ≤ 1. Since P has Beta(K, K)

hL

4

2 and Var(P ) = 1
bGci
h

P

8K . Therefore, by Chebyshev’s inequality,
(cid:21)

= P

P −

(cid:20)(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
2

>

hL
2

≤

1
2Kh2L2 .

10

Therefore,

Therefore,

(cid:20)

C = E

√

1 − Y 2h2L2
4(9 + 4Y 2 + 8Y )

1
1 + Y 2
i
h
(1 − Y 2h2L2)I( bG)
(cid:18)

E

1 − E (cid:2)(1 − 2P )2(cid:3) −

≥

(cid:21)

(cid:20)

≥ E

√

(cid:16)

1
√
84

2
1
2Kh2L2

1
1 + Y 2
E (cid:2)1 − Y 2h2L2(cid:3) − P

1 − Y 2h2L2
4(9 + 4Y 2 + 8Y )
bGci(cid:17)
h
(cid:19)

(cid:19)

1
√
84

2

(cid:18) 1
2

−

h2L2
2

=

.

≥

1
√
84

2
1
√
84

2

≥

(cid:21)
I( bG)

lim inf
n→∞

E [Rn]
log n

≥

1
√
84

2

(cid:18) 1
hL

(cid:19)

− hL

≥

1
√
84

2

(cid:18) 1
hL

(cid:19)

− 1

.

The result is completed by noting that the worst-case regret is at least as big as the expected regret, thus,
for every n, there exist a P and a sequence of loss vectors f1, . . . , fn such that the regret Rn is at least
Ω( log n

hL ).

3.2 Other regularities

So far we have looked at the case when FTL achieves a low regret due to the curvature of bd(W). The next
result characterizes the regret of FTL when W is a polytope, which has a ﬂat, non-smooth boundary and
thus Theorem 3.3 is not applicable. For this statement recall that given some norm k · k, its dual norm is
deﬁned by kwk∗ = supkvk≤1hv, wi.

Theorem 3.8. Assume that W is a polytope and that Φ is diﬀerentiable at Θi, i = 1, . . . , n. Let wt =
argmaxw∈W hw, Θt−1i, W = supw1,w2∈W kw1 − w2k∗ and F = supf1,f2∈F kf1 − f2k. Then the regret of FTL
is

Rn ≤ W

t I(wt+1 6= wt)kΘt − Θt−1k ≤ F W

I(wt+1 6= wt) .

n
X

t=1

n
X

t=1

Note that when W is a polytope, wt is expected to “snap” to some vertex of W. Hence, we expect the
regret bound to be non-vacuous, if, e.g., Θt “stabilizes” around some value. Some examples after the proof
will illustrate this.

Proof. Let v = argmaxw∈W hw, θi, v0 = argmaxw∈W hw, θ0i. Similarly to the proof of Theorem 3.3,

hv0 − v, θ0i = hv0, θ0i − hv0, θi + hv0, θi − hv, θi + hv, θi − hv, θ0i

≤ hv0, θ0i − hv0, θi + hv, θi − hv, θ0i = hv0 − v, θ0 − θi ≤ W I(v0 6= v)kθ0 − θk,

where the ﬁrst inequality holds because hv0, θi ≤ hv, θi. Therefore, by Eq. (5),

Rn =

t hwt+1 − wt, Θti ≤ W

t I(wt+1 6= wt)kΘt − Θt−1k ≤ F W

I(wt+1 6= wt) .

n
X

t=1

n
X

t=1

n
X

t=1

As noted before, since W is a polytope, wt is (generally) attained at the vertices. In this case, the epigraph
of Φ is a polyhedral cone. Then, the event when wt+1 6= wt, i.e., when the “leader” switches corresponds to
when Θt and Θt−1 belong to diﬀerent linear regions corresponding to diﬀerent linear pieces of the graph of Φ.
We now spell out a corollary for the stochastic setting. In particular, in this case FTL will often enjoy a

constant regret:

11

Corollary 3.9 (Stochastic setting). Assume that W is a polytope and that (ft)1≤t≤n is an i.i.d. sequence of
random variables such that E [fi] = µ and kfik∞ ≤ M . Let W = supw1,w2∈W kw1 − w2k1. Further assume
that there exists a constant r > 0 such that Φ is diﬀerentiable for any ν such that kν − µk∞ ≤ r. Then,

E [Rn] ≤ 2M W (1 + 4dM 2/r2) .

The condition on Φ means that r can be selected to be the radius of the largest ball such that the optimal
decisions for expected losses µ and ν (i.e., the maximizers deﬁning Φ(−µ) and Φ(−ν)) belong to the same
face of W.

Proof. Let V = {ν | kν − µk∞ ≤ r}. Note that the epigraph of the function Φ is a polyhedral cone. Since
Φ is diﬀerentiable in the interior of V , {(θ, Φ(θ)) | θ ∈ V } is a subset of a linear subspace. Therefore, for
−Θt, −Θt−1 ∈ V , wt+1 = wt. Hence, by Theorem 3.8,

E [Rn] ≤ 2M W

P [−Θt, −Θt−1 /∈ V ] ≤ 4M W

1 +

P [−Θt /∈ V ]

.

 

n
X

t=1

!

n
X

t=1

On the other hand, note that kfik∞ ≤ M . Then

P [−Θt /∈ V ] = P

fi − µ

≥ r

≤

"(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
t

t
X

i=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)∞

#

d
X

P

j=1

"(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
t

t
X

i=1

fi,j − µj

≥ r

≤ 2de− tr2

2M 2 ,

#

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

where the last inequality is due to Hoeﬀding’s inequality. Now, using that for α > 0, Pn
R n
0 exp(−αt)dt ≤ 1

α , we get E [Rn] ≤ 2M W (1 + 4dM 2/r2).

t=1 exp(−αt) ≤

The condition that Φ is diﬀerentiable for any ν such that kν − µk∞ ≤ r is equivalent to that Φ is
diﬀerentiable at µ. By Proposition 2.1, this condition requires that at µ, maxw∈W hw, θi has a unique
optimizer. Note that the volume of the set of vectors θ with multiple optimizers is zero.

4 Adaptive algorithm for the linear game

While as shown in Theorem 3.3, FTL can exploit the curvature of the surface of the constraint set to achieve
O(log n) regret, it requires the curvature condition and mint kΘtk2 ≥ L being bounded away from zero, or
it may suﬀer even linear regret. On the other hand, many algorithms, such as the "Follow the regularized
leader" (FTRL) algorithm (see,e.g., Shalev-Shwartz, 2012), are known to achieve a regret guarantee of O(
n)
even for the worst-case data in the linear setting. This raises the question whether one can have an algorithm
that can achieve constant or O(log n) regret in the respective settings of Corollary 3.9 or Theorem 3.3, while
it still maintains O(
n) regret for worst-case data. One way to design an adaptive algorithm is to use the
(A, B)-prod algorithm of Sani et al. (2014), trivially leading to the following result:

√

√

Proposition 4.1. Consider (A, B)-prod of Sani et al. (2014), where algorithm A is chosen to be FTRL
with an appropriate regularization term, while B is chosen to be FTL. Then the regret of the resulting hybrid
algorithm H enjoys the following guarantees:

• If FTL achieves constant regret as in the setting of Corollary 3.9, then the regret of H is also constant.

• If FTL achieves a regret of O(log n) as in the setting of Theorem 3.3, then the regret of H is also

O(log n).

• Otherwise, the regret of H is at most O(

n log n).

√

In the next section we show that if the constraint set is the unit ball, it is possible to design adaptive

algorithms directly.

12

Algorithm 1 Follow The Shrunken Leader (FTSL

1: Predict w1 = 0;
2: for t = 2, ..., n − 1 do
3:

FTL: Compute ˜wt = argminw∈W hw, Ft−1i
Shrinkage: Predict wt =

kFt−1k2

˜wt

√

4:

kFt−1k2

2+t+2

5: end for
6: FTL: Compute ˜wn = argminw∈W hw, Fn−1i
7: Shrinkage: Predict wn = kFn−1k2
kFn−1k2

˜wn

√

2+n

4.1 Adaptive Algorithms for the Unit Ball Constraint Set

In this section we provide some interesting results about adaptive algorithms for the case when W is the unit
ball in Rd (naturally, the results easily generalize to any ball centered at the origin). First, we show that a
variant of FTL using shrinkage as regularization has O(log(n)) regret when kΘtk2 ≥ L > 0 for all t, but it
also has O(
n) worst case guarantee. Furthermore, we show that the standard FTRL algorithm is adaptive
if the constraint set is the unit ball and the loss vectors are stochastic. Throughout the section we will use
the notation Ft = −(t − 1)Θt = Pt−1

√

i=1 fi.

4.1.1 Follow the Shrunken Leader

In this section we are going to analyze a combination of the FTL algorithm and the idea of shrinkage often
used for regularization purposes in statistics. We assume that W = (cid:8)x ∈ Rd | kxk2 ≤ 1(cid:9) is the unit ball and,
without loss of generality, we further assume that kf k2 ≤ 1 for all f ∈ F.

Theorem 4.2. The Follow The Shrunken Leader (FTSL) algorithm is given in Algorithm 1. The main idea
of the algorithm is to predict a shrunken version of the FTL prediction, in this way keeping it away from
the boundary of W. The next theorem shows that the right amount of shrinkage leads to a robust, adaptive
algorithm:

• If there exists L such that kΘtk2 ≥ L > 0 for 1 ≤ t ≤ n, then the regret of FTSL is O(log(n)/L).

• Otherwise, the regret of FTSL is at most O(

n).

√

Proof. By the deﬁnition of Ft and W, ˜wt = −Ft−1/kFt−1k2. Let σn = kFn−1k2
kFn−1k2
idea of Abernethy et al. (2008). We compute the upper bound on the value of the game for each round
backwards for t = n, n − 1, . . . , 1, by solving the optimal strategies for ft. The value of the game using FTSL
is deﬁned as

. Our proof follows the

2+n

√

n
X

t=1

n−1
X

t=1

Vn = max
f1,...,fn

hwt, fti − min
w∈W

hw, Fni

= max

f1,...,fn−1

hwt, fti + max
fn

kFn−1 + fnk2 + hfn, wni

|

{z
=:Un

}

We ﬁrst prove that Un, the second term above, is bounded from above by pkFn−1k2
2 + n. To see this, let
fn = an ˜Fn−1 + bnΩn−1 where ˜Fn−1 is the unit vector parallel to Fn−1 and Ωn−1 is a unit vector orthogonal

13

to Fn−1. Furthermore, since kfnk2 ≤ 1, we have a2

n + b2

n ≤ 1. Thus,

Un = max
fn

q

q

kFn−1k2

2 + 2ankFn−1k2 + a2

n + b2

n − anσn

≤ max

kFn−1k2

2 + 2akFn−1k2 + n − aσn

a
q

=

kFn−1k2

2 + n,

where the last equality follows since the maximum is attained at a = 0. A similar statement holds for the
other time indices: for any t ≥ 1,

q

max
ft

kFt−1 + ftk2

2 + t + 1 + hft, wti ≤

kFt−1k2

2 + t +

q

1
√
t

.

(15)

Before proving this inequality, let us see how it implies the second statement of the theorem:

Moreover, if kΘtk2 ≥ L for 1 ≤ t ≤ n, a stronger version of (15) also holds:

q

max
ft

kFt−1 + ftk2

2 + t + 1 + hft, wti ≤

kFt−1k2

2 + t +

q

1
(t − 1)L

.

(16)

This implies the ﬁrst statement of the theorem, since

Vn ≤ max

f1,...,fn−1

hwt, fti +

kFn−1k2

2 + n

≤ max

f1,...,fn−2

hwt, fti +

kFn−2k2

2 + n − 1 +

1
√
n

n−1
X

t=1

n−2
X

t=1

q

q

≤ . . .

≤ 1 +

n
X

t=1

1
√
t

√

= O(

n).

Vn ≤ max

f1,...,fn−1

hwt, fti +

kFn−1k2

2 + n

hwt, fti +

kFn−2k2

2 + n − 1 +

1
(n − 1)L

n−1
X

t=1

n−2
X

t=1

≤ max

f1,...,fn−2

≤ . . .

n−1
X

t=1

1
tL

≤ 1 +

= O(log(n)/L).

q

q

14

To ﬁnish the proof, it remains to show (15) and (16). Let ft = at ˜Ft−1 + btΩt−1 where ˜Ft−1 is the
unit vector parallel to Ft−1 and Ωt−1 is a unit vector orthogonal to Ft−1. Since kftk2 ≤ 1, observe that

t + b2
a2

t = kftk2 ≤ 1. Furthermore, let σt =

√

kFt−1k2

kFt−1k2

2+t+2

. Then, for any t ≥ 1,

∆t = max

ft

kFt−1k2

2 + 2atkFt−1k2 + a2

t + b2

t + t + 1 − atσt −
q

q

kFt−1k2

2 + t

≤ max

kFt−1k2

2 + 2atkFt−1k2 + t + 2 − atσt −

kFt−1k2

2 + t

q

q

at
q

=

=

≤

pkFt−1k2
1
√
t

.

kFt−1k2

2 + t + 2 −

kFt−1k2

2 + t

q

2

2 + t + 2 + pkFt−1k2

2 + t

(17)

This proves (15). Moreover, if kFt−1k2 = k(t − 1)Θk2 ≥ (t − 1)L, by (17) we obtain

∆t ≤

pkFt−1k2

2 + t + 2 + pkFt−1k2

2 + t

2

≤

1
kFt−1k2

≤

1
(t − 1)L

,

proving (16).

4.1.2 FTRL for the case of the unit ball constraint set

This section is to show that in the case when W is the unit ball in ‘2 norm, FTRL with R(w) = 1
regularization is an adaptive algorithm. To ﬁx the notation, in round t, FTLR predicts

2 kwk2 as its

wt = argmin

ηthFt−1, wi + R(w),

w∈W

if t > 1 and w1 = 0. It has been well known that FTRL with ηt = 1/
n)
regret in the adversarial setting, see, e.g., (Shalev-Shwartz, 2012). It remains to prove that FTRL indeed
achieves a fast rate in the stochastic setting.

t − 1 is guaranteed to achieve O(

√

√

Theorem 4.3. Assume that the sequence of loss vectors, f1, . . . , fn ∈ Rd satisﬁes kftk2 ≤ 1 almost surely
and E [ft] = µ for all t with some kµk2 > 0. Then FTRL with ηt = 1/

t − 1 suﬀers O(log n) regret .

√

Proof. Using R(w) = 1

2 kwk2 as its regularization, in round t > 1 FTRL predicts

wt = argmin

ηthFt−1, wi + R(w) =

w∈W

( 1√

Ft−1

t−1
Ft−1
kFt−1k

√

t − 1

if kFt−1k ≤
otherwise.

√

√

(18)

For any 1 ≤ t ≤ n, denote the event kFtk ≥
the same wt as FTL. Denote the accumulate loss of FTL in n rounds by LF T L

t by Et. Note that if kFt−1k ≥

t − 1, FTRL predicts exactly
. Thus, the regret of FTRL is

n

E [Rn] = E

hft, wti − min
w∈W

hft, wi

#

= E

hft, wti − LF T L

n

+ E

#

(cid:20)
LF T L

n − min
w∈W

hft, wi

(cid:21)

≤ 2

P [E c

t ] + O(log n),

" n
X

t=1
" n
X

t=1
n
X

t=1

15

where, to obtain the last inequality, we applied (18) for the ﬁrst term, while the second term is O(log n) by
the discussion following Theorem 3.3. It remains to bound the ﬁrst term, 2 Pn
t ] in the above. For any
t > 4

P [E c

t=1

,

kµk2
2

P

h
kFtk2 ≤

√

i

t

≤ P

(cid:20)
kFtk2 <

(cid:21)

kµk2

≤

d
X

(cid:20)
|Ft,i| <

P

t
2

(cid:21)

|µi|

t
2

d
X

(cid:20)
|Ft,i − tµi| >

P

≤

i=1

i=1
(cid:21)

|µi|

≤ 2

t
2

µ2
i
4 t

e−

d
X

i=1

Thus,

n
X

t=1

P [E c

t ] =

P [E c

t ] +

P [E c
t ]

n
X

t=4/kµk2
2

d
X

n
X

µ2
i
4 t

e−

+ 2

i=1

t=0

+ 2

+ 2

d
X

i=1

d
X

i=1

1

µ2
i
4

1 − e−
µ2
i
4

=

4/kµk2
2X

t=1

4
kµk2
2

4
kµk2
2

4
kµk2
2

≤

≤

≤

8
kµk2
2

E [Rn] ≤

+ kµk2

2 + O(log n) = O(log n).

4
kµk2
2

+

kµk2
2
2

.

where in the last inequality we used 1/(1 − e−a) ≤ a. Therefore, if kµk > 0, the regret of FTRL satisﬁes

5 Simulations

We performed three simulations to illustrate the diﬀerences between FTL, FTRL with the regularizer
R(w) = 1
i=1hfi−1, wi + R(w), and the adaptive algorithm (A, B)-prod (AB)
using FTL and FTRL as its candidates, which we shall call AB(FTL,FTRL).

2 when wt = argminw∈W

2 kwk2

Pt−1

For the experiments the constraint set W was chosen to be a slightly elongated ellipsoid in the 4-dimensional
Euclidean space, with volume matching that of the 4-dimensional unit ball. The actual ellipsoid is given by
W = (cid:8)w ∈ R4 | w>Qw ≤ 1(cid:9) where Q is randomly generated as







Q =

4.3367
3.6346
−2.2250 −2.3613
3.5628

3.6346 −2.2250
3.9966 −2.3613

3.5628
3.2817
2.0589 −2.1295
3.4206

3.2817 −2.1295







.

We experimented with 3 types of data to illustrate the behavior of the diﬀerent algorithms: stochastic,
“half-adversarial”, and “worst-case” data (worst-case for FTL), as will be explained below. The ﬁrst two
datasets are random, so the experiments were repeated 100 times, and we report the average regret with
its standard deviation; the worst case data is deterministic, so there no repetition was needed. For each
experiment, we set n = 2500. The regularization coeﬃcient for the FTRL, and the learning rate for AB were
chosen based on their theoretical bounds minimizing the worst-case regret.

16

In this setting we used the following model to generate ft: Let ( ˆft)t be an i.i.d. sequence
. Then, ft is deﬁned as

Stochastic data.
drawn from the 4-dimensional standard normal distribution, and let ˜ft = ˆft/
ft = ˜ft + Le1 where e1 = (1, 0, . . . , 0)>. Therefore, E
picked L ∈ {0, 0.1}.

→ L as t → ∞. In the experiments we

s=1 fs

(cid:13)
ˆft
(cid:13)
(cid:13)

(cid:13)
(cid:13)
(cid:13)2

(cid:13)
(cid:13)
(cid:13)2

h(cid:13)
(cid:13)
(cid:13)

Pt

1
t

i

The results are shown in Fig. 3. On the left-hand side we plotted the regret against the logarithm of the
number of rounds, while on the right-hand side we plotted the regret against the square root of the number
of rounds, together with the standard deviation of the results over the 100 independent runs. As can be seen
from the ﬁgures, when L = 0.1, the growth-rate of the regret of FTL is indeed logarithmic, while when L = 0,
the growth-rate is Θ(
n). In particular, when L = 0.1, FTL enjoys a major advantage compared to FTRL,
while for L = 0, FTL and FTRL perform essentially the same (in this special case, the regret of FTL will
indeed be O(
t)). As expected, AB(FTL,FTRL), gets the
better of the two regrets with little to no extra penalty.

n) as wt will stay bounded but kΘtk = O(1/

√

√

√

Figure 3: Regret of FTL, FTRL and AB(FTL,FTRL) against time for stochastic data.

“Half-adversarial” data The half-adversarial data used in this experiment is the optimal solution for
the adversary in the linear game when W is the unit ball (Abernethy et al., 2008). This data is generated
as follows: The sequence ˆft for t = 1, . . . , n is generated randomly in the (d − 1)-dimensional subspace
S = span{e2, . . . , ed} (here ei is the ith unit vector in Rd) as follows: ˆf1 is drawn from the uniform distribution
on the unit sphere of S (actually Sd−2. For t = 2, . . . , n, ˆft is drawn from the uniform distribution on the unit
sphere of the intersection of S and the hyperplane perpendicular to Pt−1
ˆfi and going through the origin.
i=1
Then, ft = Le1 +

1 − L2 ˆft for some L ≥ 0.

√

The results are reported in Fig. 4. When L = 0, the regret of both FTL and FTRL grows as O(

√

√

n). When
n). AB(FTL,FTRL)

L = 0.1, FTL achieves O(log n) regret, while the regret of FTRL appears to be O(
closely matches the regret of FTL.

Worst-case data We also tested the algorithms on data where FTL is known to suﬀer linear regret, mainly
to see how well AB(FTL,FTRL) is able to deal with this setting. In this case, we set ft,i = 0 for all t and
i ≥ 2, while for the ﬁrst coordinate, f1,1 = 0.9, and ft,1 = 2(t mod 2) − 1 for t ≥ 2.

The results are reported in Fig. 5. It can be seen that the regret of FTL is linear (as one can easily
verify theoretically), and AB(FTL,FTRL) succeeds to adapt to FTRL, and they both achieve a much smaller

17

Figure 4: Experimental results for “half-adversarial” data.

√

O(

n) regret.

Figure 5: Experimental results for worst-case data.

The unit ball We close this section by comparing the performance of our adaptive algorithms on the unit
ball, namely, FTL, FTSL, FTLR, and AB(FTL,FTRL). All these algorithms are parametrized as above. The
problem setup is similar to the stochastic data setting and the worst-case data setting. Again, we consider
a 4-dimensional setting, that is, W is the unit ball in R4 centered at the origin. The worst-case data is
generated exactly as above, while the generation process of the stochastic data is slightly modiﬁed to increase
the diﬀerence between FTLR and FTL: we sample the i.i.d. vectors ˆft from a zero-mean normal distribution
with independent components whose variance is 1/16, and let ˜ft = ˆft if k ˆftk2 ≤ 1 and ˜ft = ˆft/
when
(cid:13)
> 1 (i.e., we only normalize if ˆft falls outside of the unit ball). The reason of this modiﬁcation is to
ˆft
(cid:13)
(cid:13)
encourage the occurrence of the event kFt−1k2 <
t − 1, the prediction
of FTRL matches that of FTL, so we are trying to create some data where their behavior is actually diﬀerent.

t − 1. Recall that when kFt−1k2 ≥

(cid:13)
ˆft
(cid:13)
(cid:13)

(cid:13)
(cid:13)
(cid:13)2

(cid:13)
(cid:13)
(cid:13)2

√

√

18

As a result, we will be able to observe that the predictions of FTL and FTRL are diﬀerent in the early rounds.
Finally, as before, we let ft = ˜ft + Le1, and set the time horizon to n = 20, 000.

The results of the simulation of the stochastic data setting are shown in Figure 6. In the case of L = 0.1,
FTRL suﬀers more regret at the beginning for some rounds, but then succeeds to match the performance of
FTL. The results of the simulation of the worst-case data setting are shown in Figure 7, where FTSL has
similar performance as FTRL.

Figure 6: Experimental results for stochastic data when W is the unit ball.

Figure 7: Experimental results for worst-case data when W is the unit ball.

19

6 Conclusion

FTL is a simple method that is known to perform well in many settings, while existing worst-case results fail to
explain its good performance. While taking a thorough look at why and when FTL can be expected to achieve
small regret, we discovered that the curvature of the boundary of the constraint and having average loss
vectors bounded away from zero help keep the regret of FTL small. These conditions are signiﬁcantly diﬀerent
from previous conditions on the curvature of the loss functions which have been considered extensively in the
literature. It would be interesting to further investigate this phenomenon for other algorithms or in other
learning settings.

A Appendix: Technical results

A.1 Strongly convex sets and principal curvatures

Recall that a convex set W ⊂ Rd is λ-strongly convex if for any x, y ∈ W, γ ∈ [0, 1], W contains the ball
2 kx − yk2. That is, for any z ∈ Rd with kzk = 1,
of center γx + (1 − γ)y that has a radius of γ(1 − γ) λ
2 kx − yk2 z ∈ W. Let Br(x) = (cid:8)y ∈ Rd | kx − yk2 ≤ r(cid:9) denote the Euclidean ball
γx + (1 − γ)y + γ(1 − γ) λ
of radius r centered at x.

Proposition A.1. Let W ⊂ Rd be a C 2 convex body with support function ϕ, and let λ be an arbitrary
positive number. Then the following statements are equivalent:

(i) The smallest principal curvature of W is at least λ.

(ii) W = ∩θ∈Sd−1B1/λ(wθ − θ/λ) where wθ ∈ ∂ϕ(θ) ⊂ bd(W).

(iii) W is λ-strongly convex.

Condition (ii), which is actually the deﬁnition of Polovinkin (1996) for strongly convex sets, means that
W can be obtained as the intersection of closed balls of radius 1/λ, such that there is one ball for every
boundary point w and tangent hyperplane P where the ball touches P in w. Note that a ball with radius 1/λ
satisﬁes all conditions: (i) and (ii) by deﬁnition, while (iii) holds, e.g., by Example 13 of Journée et al. (2010).

Proof. We show that (i) implies (ii), (ii) implies (iii), and (iii) implies (i).

We start with showing that (i) implies (ii). First note that all principal curvatures of the d-dimensional
ball B = B1/λ(0) with radius 1/λ (centered at the origin) are λ. Therefore, (i) and Theorem 3.2.9 of Schneider
(2014) implies that there is a convex body M such that W + M = B, where for two sets, S1, S2 ⊂ Rd,
S1 + S2 is deﬁned as {s1 + s2 | s1 ∈ S1, s2 ∈ S2}. For any θ ∈ Sd−1, let mθ ∈ argmaxm∈Mhm, θi. Then clearly
wθ + mθ maximizes hb, θi for b ∈ W + M. Therefore, W + mθ is a subset of B and touches it at wθ + mθ, or
equivalently W ⊂ B − mθ and they touch each other, and a tangent hyperplane with normal vector θ, in wθ.
This proves that (i) implies (ii).

Next we prove that (ii) implies (iii). Assuming (ii) holds, let w ∈ W be any point in the interior of W,
and let p ∈ bd(W) be the closest boundary point to w, and recall that TpW is the tangent space of W at
p. By construction, Bkw−pk2 (w) touches the boundary of W at p (in the sense that they do not intersect,
but they can have multiple common points), and so w − p is orthogonal to TpW. Therefore, Bkw−pk2(w)
also touches the boundary of the ball B = B1/λ(p + w−p
), which contains W by assumption (ii). Now
consider any two points x, y ∈ W and γ ∈ [0, 1] such that w = γx + (1 − γ)y. Then the ball with radius
λγ(1 − γ)kx − yk2
2/2 centered at w is contained in B, since B is λ-strongly convex. But then its radius is at
most kp − wk2, and so it is also contained in W. This shows that W is λ-strongly convex, thus (iii) holds.

λkw−pk2

To ﬁnish the proof of the proposition, assume (iii). To prove that (i) holds, we have to show, that for
any point p on bd(W) and for any unit vector v ∈ TpW, the curvature of the boundary along v is at least
λ. Let P be the hyperplane spanned by v and the outer normal vector u of W at point p, and consider the
planar curve γ deﬁned by bd(W) ∩ P . Using v as the axis of a local coordinate system, a point w(s) on the

20

Figure 8: The local coordinate system at p.

curve γ in the neighborhood of p can be expressed as w(s) = p + sv − f (s)u for an appropriate function f , as
illustrated in Fig. 8.

Note that f 0(0) = 0, and by Proposition 2.1 of Pressley (2010), the curvature of γ at p can be obtained as

f 00(s)
p1 + f 0(s)2

3

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)s=0

= f 00(0) .

Now since w(s), w(−s) ∈ W for a suﬃciently small s, the strong convexity of W applied to w(s) and w(−s)
with γ = 1/2 implies that q = w(s)+w(−s)
8 kw(s) − w(−s)k2
2u ∈ W. Substituting the deﬁnition of w(s)
and w(−s), we get

+ λ

2

q = p − u

(cid:20) f (s) + f (−s)
2

−

λ
8

(cid:16)

4s2 + (f (s) − f (−s))2(cid:17)(cid:21)

.

Therefore, q ∈ W implies f (s) + f (−s) ≥ λs2, and so

f 00(0) = lim
s→0

f (s)−f (0)
s

− f (0)−f (−s)
s
s

=

f (s) + f (−s)
s2

≥ λ.

Thus (i) holds, ﬁnishing the proof of the proposition.

A.2 Proof of Proposition 2.1

Under the extra condition that W is compact the result follows from Danskin’s theorem (e.g., Proposition
B.25 of Bertsekas 1999). However, compactness is not required. For completeness, we provide a short, direct
proof. We need to show that Z = ∂ϕ(Θ) where recall that

∂ϕ(Θ) = (cid:8)u ∈ Rd | ϕ(Θ) + hu, · − Θi ≤ ϕ(·)(cid:9) = (cid:8)u ∈ Rd | ϕ(Θ) ≤ hu, Θi + ϕ(·) − hu, ·i(cid:9) .

Since Z ⊂ W, if w ∈ Z, ϕ(Θ0) ≥ hw, Θ0i for any Θ0 by the deﬁnition of ϕ. Hence, ϕ(Θ) = hw, Θi ≤
hw, Θi + ϕ(Θ0) − hw, Θ0i for any Θ0, implying that w ∈ ∂ϕ(Θ).

On the other hand, assume w ∈ ∂ϕ(Θ). Then ϕ(Θ) ≤ hw, Θi since ϕ(0) = hw, 0i = 0. Since W is closed,
Z is also closed. Therefore, if w 6∈ Z, the strict separation theorem (applied to {w}, a convex compact set,
and Z, a convex closed set) implies that there exists ρ ∈ Rd such that hz, ρi < hw, ρi for all z ∈ Z. Let
Θ0 = Θ + ρ. Then, ϕ(Θ0) = maxu∈W hu, Θi + hu, ρi < ϕ(Θ) + hw, Θ0 − Θi ≤ hw, Θ0i ≤ ϕ(Θ0), a contradiction.
Hence, w ∈ Z.

21

A.3 Technical lemmas for the lower bound Theorem 3.7
Lemma A.2 (Concentration of ˆPt). For any u > 0,

(cid:20)

P

| ˆPt − P | >

K
2K + t

|1 − 2P | +

u

P

≤ 2 exp(−tu2) .

t
2K + t

(cid:21)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

Proof. Recall that ˆPt =

K+Pt

Xi

i=1
2K+t

. Thus,

h

P

| ˆPt − P | > u

i

(cid:12)
(cid:12)
(cid:12) P

= P

K + Pt

i=1 Xi

2K + t

− P

>

|1 − 2P | +

" (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
" (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
" (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

t
X

i=1
t
X

i=1

= P

≤ P

K
2K + t
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
Xi − P t
(cid:12)
(cid:12)

#

> tu

P

,

Xi − P t + K(1 − 2P )

> K|1 − 2P | + tu

#

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

u

P

t
2K + t
(cid:12)
#
(cid:12)
(cid:12)
(cid:12)
(cid:12)

P

(19)

where the last inequality is due to P [|A + b| > c] ≤ P [|A| > c − |b|]. Note that conditioned on P , X1, . . . , Xt
are independent Bernoulli random variables with expectation P , thus (19) holds by Hoeﬀding’s inequality
(see, e.g., (Cesa-Bianchi and Lugosi, 2006, Corollary A.1)).

Lemma A.3.

E

h

(P − ˆPt)2(cid:12)
(cid:12)
(cid:12) P

i

=

K 2(1 − 2P )2
(2K + t)2 +

tP (1 − P )
(2K + t)2 .

Proof. Recall that ˆPt =

K+Pt

Xi

i=1
2K+t

.Thus,

E

h

(P − ˆPt)2(cid:12)
(cid:12)
(cid:12) P

i

= E

 





K(1 − 2P )
2K + t

+

Pt

i=1 Xi − P t
2K + t



P



!2(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

  t

X





i=1

Xi − tP



P



!2(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

=

K 2(1 − 2P )2
(2K + t)2 +

1
(2K + t)2

E

=

K 2(1 − 2P )2
(2K + t)2 +
(cid:12)
(cid:12)
(cid:12) P
i=1 Xi − P t

h Pt

tP (1 − P )
(2K + t)2 ,
i

where the second equality is due to E
on P , Pt

i=1 Xi has a Binomial distribution with parameters t and P .

= 0, and the last equality is due to that conditioned

Lemma A.4. Under the assumptions of Theorem 3.7, for any 0 < P1, P2 < 1,

(cid:10)wP2 − wP1, f P1 (cid:11) ≥

hL
2

q

(cid:1)2

(cid:0) 2P2−2P1
hL
(cid:1)2 (cid:16)

1 + (cid:0) 1−2P1

hL

1 + (cid:0) 1−2P2

hL

.

(cid:1)2(cid:17)

Proof. It is easy to see that for any p, wp is on the boundary of W, that is, wp = argminw∈W hw, f pi =
(cos(ϕp), h sin(ϕp)) for some ϕp. Then hwp, f pi = (2p − 1) cos(ϕp) − Lh sin(ϕp), and so taking the derivative
it is easy to verify that tan(ϕp) = Lh
. To

> 0. Thus, 1 − 2P1 = Lh cos(ϕP1 )
sin(ϕP1 )

1−2p and sin(ϕp) =

√

Lh

(Lh)2+(1−2p)2

22

simplify notation, let ϕ1 = ϕP1 and ϕ2 = ϕP2. Then,

hwP2 − wP1 , f P1 i =

(cid:28)(cid:18) cos ϕ2 − cos ϕ1
h (sin ϕ2 − sin ϕ1)
(cid:18)

(cid:19)

(cid:18) −hL cos ϕ1

(cid:19)(cid:29)

,

sin ϕ1
−L

cos(ϕ1)
sin(ϕ1)

= −hL

(cos(ϕ2) − cos(ϕ1))

+ (sin(ϕ2) − sin(ϕ1))

(cid:19)

(cid:0)cos(ϕ2) cos(ϕ1) − cos2(ϕ1) + sin(ϕ1) sin(ϕ2) − sin2(ϕ1)(cid:1)

=

=

=

=

≥

=

−hL
sin(ϕ1)
hL
sin(ϕ1)
hL
sin(ϕ1)
hL
sin(ϕ1)
hL
2 sin(ϕ1)
hL
2

(cid:18) 1
2

(1 − cos(ϕ2) cos(ϕ1) − sin(ϕ1) sin(ϕ2))

(1 − cos(ϕ1 − ϕ2))

(cos(ϕ1 − ϕ2) − 1)2 +

sin2(ϕ1 − ϕ2)

(cid:19)

1
2

sin2(ϕ1 − ϕ2)

sin(ϕ1) sin2 ϕ2 (cot(ϕ1) − cot(ϕ2))2 .

(20)

(21)

The proof is ﬁnished by substituting cot(ϕi) = 1−2Pi

hL , sin(ϕ1) =

q

1
1+( 1−2P1

Lh )2

and sin2(ϕ2) =

1
1+( 1−2P2

Lh )2 .

Acknowledgements

This work was supported in part by the Alberta Innovates Technology Futures through the Alberta Ingenuity
Centre for Machine Learning and by NSERC. During part of this work, T. Lattimore was with the Department
of Computing Science, University of Alberta.

References

and Archives Canada, 2010.

Y. Abbasi-Yadkori. Forced-exploration based algorithms for playing in bandits with large action sets. Library

J. Abernethy, P.L. Bartlett, A. Rakhlin, and A. Tewari. Optimal strategies and minimax lower bounds for

online convex games. In 21st Annual Conference on Learning Theory (COLT), 2008.

P.L. Bartlett, E. Hazan, and A. Rakhlin. Adaptive online gradient descent. In Advances in Neural Information

Processing Systems (NIPS), pages 65–72, 2007.

D. Bertsekas. Nonlinear Programming. Athena Scientiﬁc, Belmont, MA, 1999.

N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University Press, New York,

NY, USA, 2006.

N. Cesa-Bianchi, A. Conconi, and C. Gentile. On the generalization ability of on-line learning algorithms.

IEEE Trans. Information Theory, 50(9):2050–2057, 2004.

D.J. Foster, A. Rakhlin, and K. Sridharan. Adaptive online learning. In Advances in Neural Information

Processing Systems (NIPS), pages 3357–3365, 2015.

Y. Freund and R. Schapire. A decision-theoretic generalization of on-line learning and an application to

boosting. Journal of Computer and System Sciences, 55:119–139, 1997.

A.A. Gaivoronski and F. Stella. Stochastic nonstationary optimization for ﬁnding universal portfolios. Annals

of Operations Research, 100(1–4):165–188, 2000.

23

D. Garber and E. Hazan. Faster rates for the frank-wolfe method over strongly-convex sets. In Proceedings
of the 32nd International Conference on Machine Learning (ICML), volume 951, pages 541–549, 2015.

E. Hazan, A. Agarwal, and S. Kale. Logarithmic regret algorithms for online convex optimization. Machine

Learning, 69(2-3):169–192, 2007.

M. Journée, Y. Nesterov, P. Richtárik, and R. Sepulchre. Generalized power method for sparse principal

component analysis. Journal of Machine Learning Research, 11:517–553, 2010.

S. M. Kakade and S. Shalev-Shwartz. Mind the duality gap: Logarithmic regret algorithms for online
optimization. In Advances in Neural Information Processing Systems (NIPS), pages 1457–1464, 2009.

W. Kotłowski. Minimax strategy for prediction with expert advice under stochastic assumptions. Algorithmic

Learning Theory (ALT), 2016.

Mathematical Physics, 6(5):1–50, 1966.

E.S. Levitin and B.T. Polyak. Constrained minimization methods. USSR Computational Mathematics and

H.B. McMahan. Follow-the-regularized-leader and mirror descent: Equivalence theorems and implicit updates.

arXiv, 2010. URL http://arxiv.org/abs/1009.3240.

N. Merhav and M. Feder. Universal sequential learning and decision from individual data sequences. In 5th
Annual ACM Workshop on Computational Learning Theory (COLT), pages 413—427. ACM Press, 1992.

F. Orabona, N. Cesa-Bianchi, and C. Gentile. Beyond logarithmic bounds in online learning. In Proceedings of
the Fifteenth International Conference on Artiﬁcial Intelligence and Statistics (AISTATS), pages 823–831,
2012.

E. S. Polovinkin. Strongly convex analysis. Sbornik: Mathematics, 187(2):259, 1996. URL http://stacks.

iop.org/1064-5616/187/i=2/a=A06.

A. N. Pressley. Elementary diﬀerential geometry. Springer Science & Business Media, 2010.

A. Rakhlin and K. Sridharan. Online learning with predictable sequences. In 26th Annual Conference on

Learning Theory (COLT), pages 993–1019, 2013.

A. Sani, G. Neu, and A. Lazaric. Exploiting easy data in online optimization. In Advances in Neural

Information Processing Systems (NIPS), pages 810–818, 2014.

R. Schneider. Convex Bodies: The Brunn–Minkowski Theory. Encyclopedia of Mathematics and its

Applications. Cambridge Univ. Press, 2nd edition, 2014.

S. Shalev-Shwartz. Online learning and online convex optimization. Foundations and trends in Machine

Learning, 4(2):107–194, 2012.

S. Shalev-Shwartz and S. Ben-David. Understanding Machine Learning: From Theory to Algorithms.

Cambridge University Press, New York, NY, USA, 2014.

T. van Erven, P. Grünwald, N. Mehta, M. Reid, and R. Williamson. Fast rates in statistical and online
learning. Journal of Machine Learning Research (JMLR), 16:1793–1861, 2015. Special issue in Memory of
Alexey Chervonenkis.

24

