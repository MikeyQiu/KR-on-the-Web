Easy First Relation Extraction with Information Redundancy

Shuai Ma1,2 Gang Wang1,2 Yansong Feng3

Jinpeng Huai1,2

1SKLSDE Lab, Beihang University, China
2 Beijing Advanced Innovation Center for Big Data and Brain Computing, Beijing, China
3Peking University, China

{mashuai, iegwang, huaijp}@buaa.edu.cn

fengyansong@pku.edu.cn

Abstract

Many existing relation extraction (RE) models
make decisions globally using integer linear
programming (ILP). However, it is nontrivial
to make use of integer linear programming as
a blackbox solver for RE. Its cost of time and
memory may become unacceptable with the
increase of data scale, and redundant informa-
tion needs to be encoded cautiously for ILP. In
this paper, we propose an easy ﬁrst approach
for relation extraction with information redun-
dancies, embedded in the results produced by
local sentence level extractors, during which
conﬂict decisions are resolved with domain
and uniqueness constraints.
Information re-
dundancies are leveraged to support both easy
ﬁrst collective inference for easy decisions in
the ﬁrst stage and ILP for hard decisions in a
subsequent stage. Experimental study shows
that our approach improves the efﬁciency and
accuracy of RE, and outperforms both ILP and
neural network-based methods.

1

Introduction

Relation extraction (RE) has been extensively
studied due to its crucial role for many knowl-
edge based applications (Fan et al., 2012; Zhang
et al., 2012; Chen et al., 2014a), such as ques-
tion answering and knowledge graph. There are
two types of relation extractors: local and global.
The former identify relationships between en-
tity pairs individually according to the local fea-
tures of sentences, e.g., lexical and syntactic fea-
tures (Bunescu and Mooney, 2007; Mintz et al.,
2009; Surdeanu et al., 2010; Hoffmann et al.,
2011; Surdeanu et al., 2012; Zeng et al., 2015; Lin
et al., 2016). The latter make decisions by further
considering joint features of the entire corpus (Yao
et al., 2010; Li et al., 2011, 2013; de Lacalle and
Lapata, 2013; Chen et al., 2014a). Global rela-
tion extractors are able to resolve conﬂict deci-
sions, and to utilize the dependencies among ex-

tracted facts to improve the performance (Li et al.,
2011; Chen et al., 2014a), commonly by formal-
izing RE as a constrained optimization problem
and solving RE with integer linear programming
(Roth and Yih, 2004; Choi et al., 2006;
(ILP)
Roth and Yih, 2007; Li et al., 2011; Ji et al., 2013;
Chen et al., 2014a,b). However, global optimiza-
tion remains dominated by the ILP solvers, suffer-
ing from heavy time expenses.

Using integer linear programming for RE as a
blackbox solver is a challenging task. First, with
the increase of entity pairs and candidate relations,
the variables and constraints encoded for ILP in-
crease dramatically, which in return may consume
too much computing time and memory. Second,
redundant information needs to be encoded cau-
tiously. Consider <United States, capital : 0.6,
New York>, <United States, capital : 0.7, New
York> and <United States, capital : 0.96, Wash-
ington D.C.> in Table 1. Simple statistical meth-
ods, such as conﬁdence summation, may easily
lead to a wrong decision in this case.

To address the above issues, we propose to
make easy (most conﬁdent) decisions ﬁrst, and
then to make hard decisions with ILP. The ratio-
nale lies in that easy decisions should be made
early, and eliminating conﬂicts with constraints
aids hard decision making. We leverage informa-
tion redundancies, embedded in the results pro-
duced by sentence level extractors, to compute
the conﬁdences of candidate relations for entity
pairs. Redundancy commonly exists in various
corpora, e.g., subject “United States” and object
“New York” appear multiple times in Table 1.
Even if there exists a speciﬁc relation between a
subject and an object, the relation may not be re-
ﬂected in certain mentions due to the lack of em-
bedded evidence in single mentions, and informa-
tion redundancies are essentially to alleviate such
insufﬁciency for decision making.

ID Entity Pair
1
2
3
4
5
6
7

Australia, Canberra
United States, New York
United States, New York
United States, Washington D.C.
Australia, Sydney
University of Sydney, Sydney
Geoff Ogilvy, Australia

capital : 0.7
capital : 0.6
capital : 0.7
capital : 0.96
locationCountry : 0.6
locationCity : 0.7
nationality : 0.4

Top-3 Candidate Relations
locationCity : 0.2
birthPlace : 0.35
country : 0.23
country : 0.03
capital : 0.2
locationCountry : 0.2
locationCountry : 0.3

nationality : 0.1
nationality : 0.05
deathPlace : 0.07
birthPlace : 0.01
largestCity : 0.2
city : 0.1
city : 0.3

Table 1: Example entity pairs and their candidate relations.

When making easy decisions, we keep the con-
sistency among candidate relations by making use
of constraints (i.e., domain and uniqueness con-
straints) to eliminate conﬂicts directly, instead of
implicitly encoding constraints in ILP (Yao et al.,
2010; de Lacalle and Lapata, 2013; Chen et al.,
2014a; Koch et al., 2014; Chen et al., 2014b). As
a result, the number of variables and constraints to
be encoded in ILP is signiﬁcantly reduced, which
speeds up the entire decision making process.

In short, our approach employs an easy-ﬁrst
strategy with information redundancies to make
most conﬁdent decisions ﬁrst during which con-
ﬂict candidate relations are resolved directly by
domain and uniqueness constraints, and it only
makes the remaining hard decisions with ILP. Our
approach is an important improvement of ILP-
models, and it is not a new RE model, but an efﬁ-
cient and effective approach to fully exploiting the
results of (any) local RE extractors. As shown in
the experiments, our approach improves the per-
formance, on average (4.58%, 17.90%) more ac-
curate and (21, 37) times faster than existing ILP
and neural network-based methods, respectively.

In the rest, we ﬁrst introduce constraints and re-
dundancies in Section 2, then present our detailed
approach in Section 3, followed by experimental
study in Section 4, related work in Section 5, and
conclusions in Section 6.

2 Constraints and Redundancies

Consider a set M of mentions and a set R of prede-
ﬁned relations {r1, . . . , rk}. For each mention m,
a sentence level extractor produces an entity pair
(subject s and object o) and a conﬁdence score ci
for each relation ri (i ∈ [1, k]), which represents
the probability that s and o have relation ri (Berger
et al., 1996; Hoffmann et al., 2011). Here an NA
(unknown) relation is typically included in R.

A mention m preprocessed by a sentence level
extractor is essentially a k + 2 tuple (s, o, r1 :
c1, . . . , rk : ck), as illustrated in Table 1, where

1 ≥ ci ≥ cj ≥ 0 for any i > j ∈ [1, k] and
(cid:80)k
i=1 ci = 1. Observe that an entity pair (sub-
ject s and object o) with a relation r ∈ R can be
treated as an SRO triple (s, r, o), and a mention m
contains k SRO triples. For convenience, given a
mention m and a relation r ∈ R, we also denote
the score of relation r in m as m[r].c.

Given a set M of mentions preprocessed by a
sentence level extractor, our task for relation ex-
traction is to determine the set of correct relations
for each entity pair in M , and our approach adopts
an easy-ﬁrst strategy to make fast and accurate de-
cisions, by leveraging constraints and redundan-
cies that are to be introduced below.

In the following, a mention is referred to the one

preprocessed by a sentence level extractor.

2.1 Constraints

We consider two types of constraints: domain and
uniqueness constraints, commonly used to enforce
agreements on decisions for RE (Yao et al., 2010;
de Lacalle and Lapata, 2013; Chen et al., 2014a;
Koch et al., 2014; Chen et al., 2014b).
Domain constraints. This type of constrains en-
forces constraints among the subject and object
domains of relations. Given relations ri and rj
(1 ≤ i, j ≤ k), (1) an S-S domain constraint en-
sures that ri and rj share no common entities be-
tween their subjects, i.e., ri.subject ∩ rj.subject
= ∅, (2) an O-O domain constraint ensures that ri
and rj share no common entities between their ob-
jects, i.e., ri.object ∩ rj.object = ∅, and (3) an S-
O domain constraint ensures that ri and rj share
no common entities between the subject of ri and
the object of rj, i.e., ri.subject ∩ rj.object = ∅.

For example, (1) relations largestCity and lo-
cationCity have their subjects as countries (e.g.,
“Australia”) and organizations (e.g., “University
of Sydney”), respectively. They hold an S-S do-
(2) relations locationCity and
main constraint;
locationCountry have their objects as cities and
countries, respectively. They hold an O-O domain
constraint; (3) locationCity has its subjects as or-

# of
mentions

# of
entity
pairs

# of
subjects

# of
objects

53162

30864

11360

9709

# / ratio of entity
pairs mentioned
multiple times

≥ 3
2754/
8.92%

≥ 5
1225/
3.97%

# / ratio of sub-
jects mentioned
multiple times
≥ 5
≥ 3
1591/
2914/
14.01%
25.65%

# / ratio of ob-
jects mentioned
multiple times
≥ 5
≥ 3
1351/
2442/
13.91%
25.15%

Top 3 relation
precision (%)

DB_me: 77.3/ 11.8/ 5.0
DB_nn: 76.5/ 10.6/ 5.0

Table 2: Redundancy statistics of DBpedia - ( see Section 4 for details about the datasets).

ganizations and nationality has its objects as coun-
tries. It holds an S-O domain constraint.
Uniqueness constraints. This type of constrains
enforces the uniqueness of the subjects and objects
of relations. Given a relation ri (1 ≤ i ≤ k), (1)
an S uniqueness constraint ensures that there ex-
ist no subject s and objects oh (cid:54)= ol such that both
(s, ri, oh) and (s, ri, ol) hold, and (2) an O unique-
ness constraint ensures that there exist no object o
and subjects sh (cid:54)= sl such that both (sh, ri, o) and
(sl, ri, o) hold, respectively.

For example, relation capital holds both S and
O uniqueness constraints, since a country as the
subject of capital has only one capital, and a city
as the object of capital can only be the capital of
one country.

We refer to the total set of relations with S-S
(resp. O-O and S-O) domain constraints as DCss
(resp. DCoo and DCso). We also refer to the total
set of relations with S (resp. O) uniqueness con-
straints as U Cs (resp. U Co).

2.2

Information Redundancies

Redundancies are used to pick up hidden informa-
tion (Downey et al., 2005; Banko et al., 2007; Li
et al., 2011), and are very common in the corpus,
as revealed by the statistics in Table 2. They are es-
sentially the statistical characteristics (knowledge)
of the results produced by local sentence level ex-
tractors, and are very important for global predic-
tions. In this study, we introduce and leverage four
classes of information redundancies: S-O, S-R, O-
R and R redundancies.
S-O redundancies are introduced to aid the deci-
sion making of the top-one relations of mentions
with the same subjects and objects. For a men-
tion m = (s, o, r1 : c1, . . . , rk : ck) preprocessed
by a sentence level extractor, its certainty degree
ent(m) is deﬁned as follows.

ent(m) = −

ci ln ci.

(1)

k
(cid:88)

i=1

The redundancy score RC(s, r1, o) of the top-one
relation r1 for subject s and object o in m, based

on its S-O redundancies, is deﬁned as

RC(s, r1, o) =

(cid:88)

αent(m(cid:48)),

(2)

m(cid:48)∈Ms,o,r1

where Ms,o,r1 is the set of mentions in M whose
subjects are s, objects are o, and top-one relations
are r1, and α is a small positive number in (0, 1)
(set to 0.05 by default) to enforce that αent(m(cid:48))
falls into (0, 1). Informally, RC(s, r1, o) is a col-
lective score based on its S-O redundancies, which
makes use of information entropy to judge the con-
ﬁdence, and considers both the relative conﬁdence
scores and repeated times.
S-R redundancies are introduced to aid the deci-
sion making whether a subject meets the domain
requirement of a relation. The likelihood score
LC(s, r) for subject s and relation r, based on its
S-R redundancies, is

LC(s, r) =

(cid:80)

(cid:80)

m∈Ms
(cid:80)

m[r].c
r(cid:48)∈R\{N A} m[r(cid:48)].c

,

m∈Ms

(3)

where Ms is the set of mentions with the same sub-
ject s. Informally, LC(s, r) measures the probabil-
ity that relation r has a subject s among all rela-
tions except NA.
O-R redundancies are introduced to aid the deci-
sion making whether an object meets the domain
requirement of a relation. The likelihood score
LC(o, r) for object o and relation r, based on its
O-R redundancies, is

LC(o, r) =

(cid:80)

(cid:80)

m∈Mo
(cid:80)

m[r].c
r(cid:48)∈R\{N A} m[r(cid:48)].c

,

m∈Mo

(4)

where Mo is the set of mentions with the same ob-
ject o. Informally, LC(o, r) measures the probabil-
ity that relation r has an object o among all rela-
tions except NA.
R redundancies are introduced to aid the deci-
sion making whether a subject and an object have
a non-NA relation. The likelihood score LC(s, o)
for subject s and object o, based on its R redun-
dancies, is

LC(s, o) = max
m∈Ms,o

r∈R\{N A}

(cid:88)

m[r].c,

(5)

Input: a set M of mentions, a set of domain and uniqueness

constraints, and a threshold (cid:15).
Output: a set E of decision and updated M .
1. E := ∅;
2. Compute redundancy scores and sort with a max-heap MH;
3. while MH.Max() > (cid:15) do
4.
5. E := E ∪ {(s, r, o, c)} ;
6.
7. return E, M .

Conﬂict resolving by updating MH and M ;

(s, r, o, c) := MH.popMax();

Figure 1: Framework of our approach eFIRE.

Figure 2: Algorithm for making easy decisions.

where Ms,o is the set of mentions with the same
subject s and object o.
Informally, LC(s, o) se-
lects prominent information from local decisions
to measure the probability of having at least one
non-NA relation between s and o.

As will be seen in the next section, redundancy
scores RC(s, r1, o) are used for making easy deci-
sions, and likelihood scores LC(s, r), LC(o, r) and
LC(s, o) are used for hard decisions, respectively.

3 Easy First Relation Extraction

We propose a novel easy FIrst approach for
Relation Extraction with information redundan-
cies, referred to as eFIRE. As shown by the frame-
work in Figure 1, our approach obtains S-O re-
dundancies, and makes easy decisions with easy
ﬁrst collective inference in the ﬁrst stage. Then it
derives S-R, O-R and R redundancies, and makes
hard decisions with ILP in the second stage. We
next introduce our approach in detail.

3.1 Easy First Collective Inference

In the ﬁrst stage, decisions must be highly accurate
to avoid error propagation. As revealed by Table
2, the decisions produced by local extractors are
only reliable for top-one relations. Hence, eFIRE
ﬁrst makes decisions for entity pairs using their
top-one relations only. The conﬁdences are the re-
dundancy scores obtained with the S-O redundan-
cies (Section 2.2). Once a decision is made, dis-
agreements are resolved immediately with domain
and uniqueness constraints directly (Section 2.1).
Conﬁdence computing and ordering.
It com-
putes the redundancy scores RC(s, r1, o) of all the
entity pairs (s, o) with their top-one relations r1 in
mentions M , using S-O redundancies. The higher
the redundancy scores RC(s, r1, o) are, the more
conﬁdent subject s and object o have a relation r1.
Hence, entity pairs with their top-one relations are
sorted in a descending order of their redundancy

scores. As updating operations happen very of-
ten during the process of decision making, we in-
troduce a max-heap MH to maintain all the entity
pairs with their top-one relations and redundancy
scores for the sake of efﬁciency.
Decision making and conﬂict resolving. It ﬁrst
makes a decision for the entity pair (s, o) by
choosing its top-one relation r1 such that the re-
dundancy score RC(s, r1, o) is the highest in MH.
Then it resolves conﬂicts accordingly. (1) For
any relation r ∈ R having an S-S domain con-
straint with r1, all entity pairs with subject s and
top-one relation r are deleted from MH, and for
entity pairs with subject s in M , their scores of re-
lation r are set to zeroes. It is similar for O-O and
S-O domain constraints. (2) If relation r1 has an S
uniqueness constraint, all entity pairs with subject
s and top-one relation r1 are deleted from MH, and
for entity pairs with subject s and object o(cid:48) (cid:54)= o in
M , their scores of relation r1 are set to zeroes. It
is similar for O uniqueness constraints.

The above process is repeated until the high-
est redundancy score in the max-heap MH is less
than a predeﬁned threshold (cid:15), which is to ensure
the correctness of decisions. For the beneﬁt of ef-
ﬁciency, we also index mentions by subjects, by
objects and by entity pairs, separately.

The intention of threshold (cid:15) is to distinguish
easy decisions from hard ones based on S-O re-
dundancies. This indeed can be reﬂected from
the redundancy scores. Consider an extreme case
when there is only one mention m in M with sub-
ject s, object o and top-one relation r1 whose score
is 1.0, i.e., there are no S-O redundancies for men-
tion m. In this case, we have RC(s, r1, o) = 1.0.
However, for cases when multiple mentions with
the same subject s, object o and top-one relation
r1, it is likely that the redundancy score is less than
1.0. Hence, threshold (cid:15) is typically set to a value a

little less than 1.0.

Our approach makes a better use of information
redundancies in the corpus to aid the decision
making process. Recall the example on deter-
mining whether the capital of “United States” is
“New York” or “Washington D.C.” in Section 1.
With the S-O redundancies, “Washington D.C.”
is chosen as the capital of “United States”, as
RC(United States, capital, New York) = 0.18 and
RC(United States, capital, Washington D.C.) =
0.57, which justiﬁes the rationale of introducing
the certainty degree ent(m) for mentions m.
Complete algorithm for easy ﬁrst inference.
The complete algorithm is presented in Figure 2.
It ﬁrst initializes the set E of easy decisions
empty (line 1). It then computes the redundancy
scores of all the entity pairs with their top-one rela-
tions in mentions M , using S-O redundancies, and
these entity pairs with their top-one relations are
sorted in a descending order of their redundancy
scores with a max heap MH (line 2). It repeatedly
deals with entity pairs and their top-one relations
in MH one by one until the highest redundancy
score in MH is no more than (cid:15) (lines 3-6). Once
a decision is made (lines 4, 5), conﬂicts are re-
solved immediately by updating MH and M (line
6). Finally, the modiﬁed mentions M and a set E
of easy decisions are returned (line 7).
Time and space complexity analyses. The al-
gorithm runs in O(|M |2(|R| + log |M |)) time,
where |M | and |R| are the numbers of mentions
and predeﬁned relations, respectively. Observe the
following. For a mention, (1) it takes O(|R| +
log |M |) time to compute the redundancy scores
for all entity pairs with their top-one relations,
(2) maintaining MH can be done in O(log |M |)
time, and (3) decision making and conﬂict resolv-
ing take O(|M |(|R|+log |M |)) time. As there are
in total |M | mentions, we have the conclusion.

It is easy to see that the algorithm takes a space

in the linear size of the set M of mentions.

3.2

Integer Linear Programming

In the second stage, our goal is to ﬁnd an optimal
conﬁguration for the remaining mentions, mak-
ing use of S-R, O-R and R redundancies, solving
the disagreements by domain and uniqueness con-
straints, and maximizing the overall conﬁdence
of the made decisions. This is an NP-hard opti-
mization problem, and many optimization models
can be used to obtain approximate solutions. The

tricky part is the design of the objective functions.
Here, we adopt the ILP tool “IBM ILOG CPLEX”.
More speciﬁcally, for each mention m and each
of its candidate relations r in the set M of remain-
ing mentions returned in the ﬁrst stage, we deﬁne a
binary decision variable vr
m indicating whether re-
lation r is chosen for the entity pair (s, o) in m by
the solver. For each mention m in M , we choose
its top three relations with scores no less than 0.1
as the candidate relations. As revealed by Table 2,
candidates beyond top-3 are very unreliable.

Our objective is to maximize the total conﬁ-
dence of all the selected candidates based on the
S-R, O-R and R redundancies, and the objective
function can be written as:

(cid:88)

max

(cid:0)LC(s, r)+LC(o, r)+LC(s, o)

m∈M,r∈Rm

(cid:88)

+

m(cid:48)[r].c(cid:1)vr
m,

m(cid:48)∈Mm

(6)

where s and o are the subject and object in m,
Rm is the set of candidate relations for s and o
in m, and Mm is the set of mentions in M hav-
ing the same subject and object as m. The ﬁrst
component is the sum of S-R, O-R, and R redun-
dancies of the selected candidates, and the second
one is the sum of the original conﬁdence scores of
the selected candidates. The former is designed to
encourage the model to select candidates meeting
the domain requirements of relations, and the lat-
ter is designed to give consideration to decisions
produced by sentence level extractors. That is,
although the sentence level extractors may make
wrong decisions, the global statistics of their deci-
sions are reliable, and should be preserved.

The domain and uniqueness constraints are en-

coded to avoid conﬂict decisions as follows.

where mi and mj have the same subject, rmi ∈
Rmi, rmj ∈ Rmj , and rmi and rmj have an S-S
domain constraint in DCss.

where mi and mj have the same object, rmi ∈
Rmi, rmj ∈ Rmj , and rmi and rmj have an O-O
domain constraint in DCoo.

mi + vrmj
vrmi

mj ≤ 1,

mi + vrmj
vrmi

mj ≤ 1,

mi + vrmj
vrmi

mj ≤ 1,

(7)

(8)

(9)

Datasets Methods

Running
time(s)
52.70
1.88
1.90
52.35
69.49
34.55
15.82
1.11
1.20
15.81
69.49
34.55

# of ILP
variables
12353
8185
8185
12353
-
-
11770
9678
9678
11770
-
-

# of ILP
constraints
293361
34931
34931
293361
-
-
94498
24314
24314
94498
-
-

baseline
eFIRE
eFIRE-1S
eFIRE-2S
CNN+ATT
PCNN+ATT
baseline
eFIRE
eFIRE-1S
eFIRE-2S
CNN+ATT
PCNN+ATT

DB_me

DB_nn

Table 3: Efﬁciency of eFIRE and comparison methods.

where the subject of mi is the object of mj, rmi ∈
Rmi, rmj ∈ Rmj , and rmi and rmj have an S-O
domain constraint in DCso.

where Mr,s is the set of mentions with candidate
relation r, subject s and pairwise distinct objects,
and r has an S uniqueness constraint in U Cs.

(cid:88)

vr
m ≤ 1,

m∈Mr,s

(cid:88)

vr
m ≤ 1,

m∈Mr,o

(10)

(11)

where Mr,o is the set of mentions with candidate
relation r, object o and pairwise distinct subjects,
and r has an O uniqueness constraint in U Co.

By adopting ILP, eFIRE combines the scores re-
ﬁned in the ﬁrst stage and the constraints to make
hard decisions. After the optimization problem is
solved, together with the easy decisions obtained
in the ﬁrst stage, eFIRE ﬁnally produces a list of
selected candidate relations for each entity pair.

4 Experimental Study

In this section, we present an extensive experimen-
tal study of our easy ﬁrst approach eFIRE.

4.1 Experimental Settings

We ﬁrst present our experimental settings.
Datasets. The two datasets, DB_me and DB_nn,
stem from DBpedia (Bizer et al., 2009), mapping
the triples in DBpedia to sentences in the New
York Time corpus. We map 51 different rela-
tions to the dataset. We use both a maximum
entropy model MaxEnt (Chen et al., 2014a) and
neural network model NN (Lin et al., 2016) as
the sentence level extractors to output conﬁdence
scores, denoted as DB_me and DB_nn, respec-
tively. The features of these two datasets are re-
ported in Table 2. There are 53162 mentions in

each dataset, including 38654 mentions with NA
relations. We learn domain and uniqueness con-
straints from Freebase as knowledge base (KB).
Algorithms for comparison. To evaluate our
the
approach, we compare with three methods:
ILP based global method for RE in (Chen et al.,
2014a) as baseline that use the global clues to
help resolve the disagreements, and CNN+ATT
and PCNN+ATT in (Lin et al., 2016) that are neu-
ral network-based methods with attention mecha-
nism to use all informative sentences.
Implementation. All algorithms were imple-
mented with C++. All experiments were run on
a PC with 2 Intel(R) Xeon(R) E5´lC2640 2.6GHz
CPUs and 64 GB of memory. When running time
is measured, the test was repeated over 5 times and
the average is reported.

4.2 Experimental Results

We next present our ﬁndings of the effectiveness
and efﬁciency of our easy ﬁrst approach eFIRE.
Following previous work, we also use the preci-
sion in the low recall portion of the P-R curve as
the effectiveness criterion.
Exp-1: Overall performance.
In the ﬁrst set
of tests, we evaluated the effectiveness and efﬁ-
ciency, and the results are reported in Figures 3(a),
3(b) and Table 3, respectively.

Our approach eFIRE outperforms the methods
eFIRE is on average (4.80%,
for comparison.
4.36%), (17.99%, 28.10%) and (7.69%, 17.82%)
more accurate than baseline, CNN+ATT and
PCNN+ATT on (DB_me, DB_nn) in the low-
recall portion [0, 0.25] of the P-R curves, respec-
tively. eFIRE consistently outperforms CNN+ATT
and PCNN+ATT over the entire range of recall.
While baseline tends to have results with a higher
recall, it has a weakness of low precision, which
is alleviated by eFIRE that is able to obtain more
correct decisions. It is difﬁcult to guarantee high
precision and recall at the same time. For most KB
population applications, only the high precision
part is considered for the effectiveness evaluation.
It is worth pointing out that we only compare the
testing time of CNN+ATT and PCNN+ATT here.
Our method eFIRE also reduces the running
eFIRE is on average
time on all datasets.
(28, 14),
(37, 63) and (18, 31) times faster
than baseline, CNN+ATT and PCNN+ATT on
(DB_me, DB_nn), respectively. This is because
the easy-ﬁrst strategy of eFIRE signiﬁcantly re-

(a) on DB_me dataset

(b) on DB_nn dataset

(c) on DB_me dataset

(d) on DB_nn dataset

(e) on DB_me dataset

(f) on DB_nn dataset

Figure 3: Overall performances: eFIRE vs. its variants vs. baseline vs. CNN+ATT vs. PCNN+ATT.

duces the number of variables and constraints en-
coded in the ILP solver, as shown in Table 3.

level extractors, is an effective and efﬁcient com-
plement for RE using ILP solvers.

Note that the running time has no obvious lin-
ear relationships with the number of variables and
constraints among different datasets. In addition
to the number of variables and constraints, objec-
tive functions have a impact on the running time of
ILP too. Further, CPLEX is used as a black box,
which makes it hard to have a precise analysis.

These results tell us that the easy-ﬁrst strategy
for RE, by making use of the redundancy infor-
mation embedded in the local results of sentence

Exp-2: Performance of easy ﬁrst collective in-
ference with S-O redundancies.
In the second
set of tests, in order to evaluate the impacts of S-O
redundancies, we implemented a variant of our ap-
proach, referred to as eFIRE-1S, that makes easy
decisions with the easy ﬁrst collective inference,
and then adopts the same ILP method in baseline
for making the rest decisions. The results are re-
ported in Figures 3(c), 3(d), and Table 3.

Method eFIRE-1S outperforms baseline in the

(a) The running time

(b) The number of variables

(c) The number of constraints

Figure 4: Impacts of threshold (cid:15) on time, variables and constraints.

low-recall portions of the P-R curves on all two
datasets. These results tell us that the easy ﬁrst col-
lective inference using S-O redundancies can not
only improve the effectiveness of decision mak-
ing for RE, but also improve the efﬁciency, as it
signiﬁcantly reduces the constraints and variables
encoded in the ILP solver.
Exp-3: Performance of ILP with S-R, O-R and
R redundancies. In the third set of tests, to eval-
uate the impacts of S-R, O-R and R redundancies,
we implemented a variant of eFIRE, referred to as
eFIRE-2S, that only consists of the second stage
of eFIRE. That is, all decisions of eFIRE-2S are
made by the ILP solver. The results are reported
in Figures 3(c), 3(d) and Table 3.

Method eFIRE-2S outperforms baseline on all
two datasets. It essentially improves the precision
without sacriﬁcing the recall. For ILP based meth-
ods, their key differences are the objective func-
tions. eFIRE-2S incorporates more reliable statis-
tics of sentence level extractors, i.e., S-R, O-R and
R redundancies, while baseline only uses maxi-
mal scores to encourage choosing the candidates
with higher individual sentence level conﬁdence
scores. So, S-R, O-R and R redundancies beneﬁt
the decision making of ILP solvers. The efﬁciency
of eFIRE-2S and baseline are comparable, which
implies that the efﬁciency beneﬁt of eFIRE comes
from its ﬁrst stage easy ﬁrst collective inference.
Exp-4: Setting veriﬁcation of threshold (cid:15). In the
last set of tests, to verify the setting of threshold

(cid:15), we varied its values to [0.4, 1.6]. The results
of effectiveness and running time are reported in
Figures 3(e), 3(f) and Figure 4, respectively.

The results show that our approach eFIRE is ef-
fective and efﬁcient when (cid:15) falls into [0.5, 0.9],
during which eFIRE outperforms baseline in the
low-recall portion. This justiﬁes our setting for
threshold (cid:15), which is typically a little less than 1.0
to distinguish easy decisions from hard ones (Sec-
tion 3.1). Threshold (cid:15) obviously has an impact on
the running time, as the smaller (cid:15) is, the more run-
ning time eFIRE has in the ﬁrst stage, and the less
it has in the second stage.
Summary. From these tests, we ﬁnd followings.

(1) Our approach eFIRE is both effective and
efﬁcient. It is more accurate than baseline in the
low-recall portion [0, 0.25] and CNN+ATT and
eFIRE is on average
PCNN+ATT consistently.
(4.58%, 23.05%, 12.76%) more accurate in the
low-recall portion and (21, 50, 25) times faster
than baseline, CNN+ATT and PCNN+ATT, re-
(2) The use of the easy-ﬁrst strategy
spectively.
and S-O redundancies both improves the accuracy
of RE and reduces the running time, and the use of
S-R, O-R and R redundancies improves the accu-
racy of RE. (3) The setting of threshold (cid:15) is ﬂexible
in a range of [0.5, 0.9] for our approach eFIRE.

5 Related Work

Relation extraction has been studied extensively
in recent years, and can be divided into local re-

lation extractors (Mintz et al., 2009; Surdeanu
et al., 2010; Hoffmann et al., 2011; Surdeanu et al.,
2012; Søgaard et al., 2015) using the lexical fea-
tures, syntactic features, and other local features of
sentences, and global relation extractors utilizing
the corpus features and relationships among lo-
cal decisions (Kate and Mooney, 2010; Yao et al.,
2010; Li et al., 2011; Singh et al., 2013; Li and
Ji, 2014; Nguyen et al., 2017; Su et al., 2017).
Global relation extractors leverage more informa-
tion to resolve conﬂict decisions, which typically
leads to more accurate decisions than local ones.

Recently, neural network-based models (Zeng
et al., 2014; Ji et al., 2017) have been proposed
for RE. Lin et al. (2016) proposes an attention
mechanism to calculate weights for all sentences
of one entity pair and selects plausible sentences
from noisy sentences. Different from these are su-
pervised methods that need label data for training,
we propose an unsupervised method in this study.
Disagreements among decisions can be re-
solved by constraints. Yao et al. (2010) propose a
relation extraction model that captures selectional
preferences and functionality constraints to inte-
grate information across documents. Fader et al.
(2011) implement syntactic and lexical constraints
on binary relations expressed by verbs in Open IE
systems. Koch et al. (2014) impose type (or do-
main) constraints to only allow relations over ap-
propriately typed mentions for relation extraction.
Similar to (Chen et al., 2014a), our approach uti-
lizes both domain and uniqueness constraints to
resolve disagreements.

Many global relation extractors use integer lin-
ear programming as a blackbox solver (Roth and
Yih, 2004; Choi et al., 2006; Roth and Yih, 2007;
Li et al., 2011; Ji et al., 2013; Chen et al., 2014a,b;
Wang et al., 2015). The ILP solver derives deci-
sions through a well designed objective function,
and resolves conﬂict decisions by encoding con-
straints into ILP. Our easy ﬁrst approach is com-
plimentary to these methods with each other, as
these methods can take the easy ﬁrst collective in-
ference of our approach for making easy decisions
as a ﬁrst step, and our approach can make use of
any of these methods as its solution for making
hard decisions in its second stage.

Redundancies in the corpus have been used to
pick up hidden information. Downey et al. (2005)
consider redundant extractions for judging the cor-
rectness of extractions. Li et al. (2011) take ad-

vantage of redundant information to conduct rea-
soning across documents based on the information
network structure. We introduce four classes of in-
formation redundancies: S-O, S-R, O-R and R re-
dundancies, and we leverage S-O redundancies for
making easy decisions, and the others to aid hard
decision making.

Easy-ﬁrst strategy relies on the intuition that
“easy decisions should be made early, while
harder decisions should be left for later when
more information is available (Stoyanov and Eis-
ner, 2012)”. Their method makes easy decisions
ﬁrst for coreference resolution, and further makes
use of the information from coreference clusters
in the form of features to make later decisions. In
this study, we propose to make easy (most con-
ﬁdent) decisions ﬁrst for relation extraction, and
then to make hard decisions with ILP, where easy
decisions are distinguished from hard ones with
redundance scores based on S-O redundancies.

Data dependencies have well studied for im-
proving data quality (Ma, 2011; Ma et al., 2015;
Fan and Geerts, 2012), which essentially make use
of data redundancies and dependencies. Our ap-
proach is partially inspired by these studies. In-
deed, the uniqueness constraints deﬁned in this
study can be treated as functional dependen-
cies (Abiteboul et al., 1995).

6 Conclusions

In this paper, we have proposed a fast easy ﬁrst
approach for relation extraction by making use of
information redundancies, embedded in the results
produced by local sentence level extractors, under
domain and uniqueness constraints. We have in-
troduced four classes of information redundancies
to aid both easy ﬁrst collective inference for easy
decisions in the ﬁrst stage and ILP for hard deci-
sions in the second stage. Finally, using datasets
processed by sentence level extractors with differ-
ent models, we have experimentally veriﬁed that
our easy ﬁrst approach is both effective and efﬁ-
cient compared with state-of-the-art both ILP and
neural network-based methods.

Acknowledgments

This work is supported in part by National
Key R&D Program of China 2018YFB1700403,
NSFC U1636210&61421003, and Shenzhen In-
stitute of Computing Sciences.

References

Serge Abiteboul, Richard Hull, and Victor Vianu. 1995.

Foundations of Databases. Addison-Wesley.

Michele Banko, Michael J. Cafarella, Stephen Soder-
land, Matthew Broadhead, and Oren Etzioni. 2007.
Open information extraction from the web. In Pro-
ceedings of the 20th International Joint Conference
on Artiﬁcial Intelligence, pages 2670–2676.

Adam L. Berger, Stephen Della Pietra, and Vincent
J. Della Pietra. 1996. A maximum entropy approach
to natural language processing. Computational Lin-
guistics, 22(1):39–71.

Christian Bizer, Jens Lehmann, Georgi Kobilarov,
Sören Auer, Christian Becker, Richard Cyganiak,
and Sebastian Hellmann. 2009. Dbpedia - A crys-
tallization point for the web of data. Journal of Web
Semantics, 7(3):154–165.

Razvan C. Bunescu and Raymond J. Mooney. 2007.
Learning to extract relations from the web using
minimal supervision. In Proceedings of the 45th An-
nual Meeting of the Association for Computational
Linguistics, pages 576–583. Association for Com-
putational Linguistics.

Liwei Chen, Yansong Feng, Songfang Huang, Yong
Qin, and Dongyan Zhao. 2014a. Encoding relation
requirements for relation extraction via joint infer-
ence. In Proceedings of the 52nd Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers), pages 818–827. Association
for Computational Linguistics.

Liwei Chen, Yansong Feng, Jinghui Mo, Songfang
Huang, and Dongyan Zhao. 2014b. Joint inference
In Proceedings of
for knowledge base population.
the 2014 Conference on Empirical Methods in Nat-
ural Language Processing, pages 1912–1923. Asso-
ciation for Computational Linguistics.

Yejin Choi, Eric Breck, and Claire Cardie. 2006. Joint
extraction of entities and relations for opinion recog-
In Proceedings of the 2006 Conference on
nition.
Empirical Methods in Natural Language Process-
ing, pages 431–439. Association for Computational
Linguistics.

Doug Downey, Oren Etzioni, and Stephen Soderland.
2005. A probabilistic model of redundancy in infor-
mation extraction. In Proceedings of the Nineteenth
International Joint Conference on Artiﬁcial Intelli-
gence, pages 1034–1041. Professional Book Center.

Anthony Fader, Stephen Soderland, and Oren Etzioni.
2011. Identifying relations for open information ex-
traction. In Proceedings of the 2011 Conference on
Empirical Methods in Natural Language Process-
ing, pages 1535–1545. Association for Computa-
tional Linguistics.

James Fan, Raphael Hoffman, Aditya Kalyanpur, Se-
bastian Riedel, Fabian M. Suchanek, and Partha Pra-
tim Talukdar, editors. 2012. Proceedings of the Joint
Workshop on Automatic Knowledge Base Construc-
tion and Web-scale Knowledge Extraction, AKBC-
WEKEX@NAACL-HLT 2012, Montrèal, Canada,
June 7-8, 2012. Association for Computational Lin-
guistics.

Wenfei Fan and Floris Geerts. 2012. Foundations of
Data Quality Management. Synthesis Lectures on
Data Management. Morgan & Claypool Publishers.

Raphael Hoffmann, Congle Zhang, Xiao Ling,
Luke S. Zettlemoyer, and Daniel S. Weld. 2011.
Knowledge-based weak supervision for information
extraction of overlapping relations. In Proceedings
of ACL 2011, the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, pages 541–550. Association for
Computational Linguistics.

Guoliang Ji, Kang Liu, Shizhu He, and Jun Zhao.
2017. Distant supervision for relation extraction
with sentence-level attention and entity descriptions.
In Proceedings of the Thirty-First AAAI Conference
on Artiﬁcial Intelligence, pages 3060–3066. AAAI
Press.

Heng Ji, Benoît Favre, Wen-Pin Lin, Dan Gillick, Dilek
Hakkani-Tür, and Ralph Grishman. 2013. Open-
domain multi-document summarization via infor-
mation extraction: Challenges and prospects.
In
Multi-source, Multilingual Information Extraction
and Summarization, pages 177–201. Springer.

Rohit J. Kate and Raymond J. Mooney. 2010. Joint en-
tity and relation extraction using card-pyramid pars-
ing. In Proceedings of the Fourteenth Conference on
Computational Natural Language Learning, pages
203–212. Association for Computational Linguis-
tics.

Mitchell Koch, John Gilmer, Stephen Soderland, and
Daniel S. Weld. 2014. Type-aware distantly su-
pervised relation extraction with linked arguments.
In Proceedings of the 2014 Conference on Empiri-
cal Methods in Natural Language Processing, pages
1891–1901. Association for Computational Linguis-
tics.

Oier Lopez de Lacalle and Mirella Lapata. 2013. Un-
supervised relation extraction with general domain
knowledge. In Proceedings of the 2013 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 415–425. Association for Computa-
tional Linguistics.

Qi Li, Sam Anzaroot, Wen-Pin Lin, Xiang Li, and
Heng Ji. 2011. Joint inference for cross-document
information extraction. In Proceedings of the 20th
ACM Conference on Information and Knowledge
Management, pages 2225–2228. Association for
Computing Machinery.

Qi Li and Heng Ji. 2014.

Incremental joint extrac-
In Proceed-
tion of entity mentions and relations.
ings of the 52nd Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers), pages 402–412. Association for Computa-
tional Linguistics.

Qi Li, Heng Ji, and Liang Huang. 2013. Joint event
extraction via structured prediction with global fea-
tures. In Proceedings of the 51st Annual Meeting of
the Association for Computational Linguistics, (Vol-
ume 1: Long Papers), pages 73–82. Association for
Computational Linguistics.

Yankai Lin, Shiqi Shen, Zhiyuan Liu, Huanbo Luan,
and Maosong Sun. 2016. Neural relation extraction
with selective attention over instances. In Proceed-
ings of the 54th Annual Meeting of the Association
for Computational Linguistics, (Volume 1: Long Pa-
pers), pages 2124–2133. Association for Computa-
tional Linguistics.

Shuai Ma. 2011. Extending dependencies for improv-
ing data quality. Ph.D. thesis, University of Edin-
burgh, UK.

Shuai Ma, Liang Duan, Wenfei Fan, Chunming Hu,
and Wenguang Chen. 2015.
Extending condi-
tional dependencies with built-in predicates. IEEE
Transactions on Knowledge and Data Engineering,
27(12):3274–3288.

Mike Mintz, Steven Bills, Rion Snow, and Daniel Ju-
rafsky. 2009. Distant supervision for relation ex-
traction without labeled data. In Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP, pages
1003–1011. Association for Computational Linguis-
tics.

Dat Ba Nguyen, Martin Theobald, and Gerhard
joint relation extrac-
J-REED:
Weikum. 2017.
In Proceedings of
tion and entity disambiguation.
the 2017 ACM on Conference on Information and
Knowledge Management, pages 2227–2230. Asso-
ciation for Computing Machinery.

Dan Roth and Wen-tau Yih. 2004. A linear program-
ming formulation for global inference in natural lan-
guage tasks. In Proceedings of the Eighth Confer-
ence on Computational Natural Language Learning
at HLT-NAACL 2004, pages 1–8. Association for
Computational Linguistics.

Dan Roth and Wen-tau Yih. 2007. Global inference
for entity and relation identiﬁcation via a linear pro-
Introduction to statistical
gramming formulation.
relational learning, pages 553–580.

Sameer Singh, Sebastian Riedel, Brian Martin, Jiaping
Zheng, and Andrew McCallum. 2013. Joint infer-
ence of entities, relations, and coreference. In Pro-
ceedings of the 2013 workshop on Automated knowl-
edge base construction, AKBC@CIKM, pages 1–6.
Association for Computing Machinery.

Anders Søgaard, Barbara Plank, and Héctor Martínez
Alonso. 2015. Using frame semantics for knowl-
edge extraction from twitter. In Proceedings of the
Twenty-Ninth AAAI Conference on Artiﬁcial Intelli-
gence, pages 2447–2452. AAAI Press.

Veselin Stoyanov and Jason Eisner. 2012. Easy-ﬁrst
coreference resolution. In Proceedings of COLING
2012, the 24th International Conference on Compu-
tational Linguistics: Technical Papers, pages 2519–
2534. The COLING 2012 Organizing Committee.

Yu Su, Honglei Liu, Semih Yavuz, Izzeddin Gur, Huan
Sun, and Xifeng Yan. 2017. Global relation embed-
ding for relation extraction. CoRR, abs/1704.05958.

Mihai Surdeanu, David McClosky, Julie Tibshirani,
John Bauer, Angel X. Chang, Valentin I. Spitkovsky,
and Christopher D. Manning. 2010. A simple dis-
tant supervision approach for the TAC-KBP slot ﬁll-
In Proceedings of the Third Text Analy-
ing task.
sis Conference. National Institute of Standards and
Technology.

Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati,
and Christopher D. Manning. 2012. Multi-instance
multi-label learning for relation extraction. In Pro-
ceedings of the 2012 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning, pages 455–
465. Association for Computational Linguistics.

Quan Wang, Bin Wang, and Li Guo. 2015. Knowl-
edge base completion using embeddings and rules.
In Proceedings of the Twenty-Fourth International
Joint Conference on Artiﬁcial Intelligence, pages
1859–1866. AAAI Press.

Limin Yao, Sebastian Riedel, and Andrew McCallum.
2010. Collective cross-document relation extrac-
In Proceedings of the
tion without labelled data.
2010 Conference on Empirical Methods in Natural
Language Processing, pages 1013–1023. Associa-
tion for Computational Linguistics.

Daojian Zeng, Kang Liu, Yubo Chen, and Jun Zhao.
2015. Distant supervision for relation extraction via
In Pro-
piecewise convolutional neural networks.
ceedings of the 2015 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1753–
1762. Association for Computational Linguistics.

Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou,
and Jun Zhao. 2014. Relation classiﬁcation via con-
volutional deep neural network. In Proceedings of
COLING 2014, the 25th International Conference
on Computational Linguistics: Technical Papers,
pages 2335–2344. Dublin City University and As-
sociation for Computational Linguistics.

Congle Zhang, Raphael Hoffmann, and Daniel S.
Weld. 2012. Ontological smoothing for relation ex-
traction with minimal supervision. In Proceedings
of the Twenty-Sixth AAAI Conference on Artiﬁcial
Intelligence. AAAI Press.

