Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

Aditi Raghunathan * 1 Sang Michael Xie * 1 Fanny Yang 2 John C. Duchi 1 Percy Liang 1

0
2
0
2
 
b
e
F
 
5
2
 
 
]

G
L
.
s
c
[
 
 
1
v
6
1
7
0
1
.
2
0
0
2
:
v
i
X
r
a

Abstract
Adversarial training augments the training set
with perturbations to improve the robust error
(over worst-case perturbations), but it often leads
to an increase in the standard error (on unper-
turbed test inputs). Previous explanations for this
tradeoff rely on the assumption that no predic-
tor in the hypothesis class has low standard and
robust error. In this work, we precisely charac-
terize the effect of augmentation on the standard
error in linear regression when the optimal linear
predictor has zero standard and robust error. In
particular, we show that the standard error could
increase even when the augmented perturbations
have noiseless observations from the optimal lin-
ear predictor. We then prove that the recently
proposed robust self-training (RST) estimator im-
proves robust error without sacriﬁcing standard
error for noiseless linear regression. Empirically,
for neural networks, we ﬁnd that RST with dif-
ferent adversarial training methods improves both
standard and robust error for random and adver-
sarial rotations and adversarial (cid:96)∞ perturbations
in CIFAR-10.

1. Introduction

Adversarial training methods (Goodfellow et al., 2015;
Madry et al., 2017) attempt to improve the robustness of neu-
ral networks against adversarial examples (Szegedy et al.,
2014) by augmenting the training set (on-the-ﬂy) with per-
turbed examples that preserve the label but that fool the
current model. While such methods decrease the robust er-
ror, the error on worst-case perturbed inputs, they have been
observed to cause an undesirable increase in the standard
error, the error on unperturbed inputs (Madry et al., 2018;
Zhang et al., 2019; Tsipras et al., 2019).

Previous works attempt to explain the tradeoff between stan-
dard error and robust error in two settings: when no accurate

*Equal contribution, in alphabetical order 1Stanford Univer-
sity 2ETH Zurich. Correspondence to: Aditi Raghunathan <adi-
tir@stanford.edu>, Sang Michael Xie <xie@cs.stanford.edu>.

Figure 1. Gap between the stan-
dard error of adversarial
train-
ning (Madry et al., 2018) with (cid:96)∞
perturbations, and standard training.
The gap decreases with increase in
training set size, suggesting that the
tradeoff between standard and ro-
bust error should disappear with in-
ﬁnite data.

classiﬁer is consistent with the perturbed data (Tsipras et al.,
2019; Zhang et al., 2019; Fawzi et al., 2018), and when
the hypothesis class is not expressive enough to contain the
true classiﬁer (Nakkiran, 2019). In both cases, the tradeoff
persists even with inﬁnite data. However, adversarial pertur-
bations in practice are typically deﬁned to be imperceptible
to humans (e.g. small (cid:96)∞ perturbations in vision). Hence
by deﬁnition, there exists a classiﬁer (the human) that is
both robust and accurate with no tradeoff in the inﬁnite data
limit. Furthermore, since deep neural networks are expres-
sive enough to ﬁt not only adversarial but also randomly
labeled data perfectly (Zhang et al., 2017), the explanation
of a restricted hypothesis class does not perfectly capture
empirical observations either. Empirically on CIFAR-10, we
ﬁnd that the gap between the standard error of adversarial
training and standard training decreases as we increase the
labeled data size, thereby also suggesting the tradeoff could
disappear with inﬁnite data (See Figure 1).

In this work, we provide a different explanation for the
tradeoff between standard and robust error that takes gen-
eralization from ﬁnite data into account. We ﬁrst consider
a linear model where the true linear function has zero stan-
dard and robust error. Adversarial training augments the
original training set with extra data, consisting of sam-
ples (xext, y) where the perturbations xext are consistent,
meaning that the conditional distribution stays constant
Py(
x). We show that even in this simple
setting, the augmented estimator, i.e. the minimum norm
interpolant of the augmented data (standard + extra data),
could have a larger standard error than that of the standard
estimator, which is the minimum norm interpolant of the
standard data alone. We found this surprising given that
adding consistent perturbations enforces the predictor to
satisfy invariances that the true model exhibits. One might
think adding this information would only restrict the hypoth-

xext) = Py(

· |

· |

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

Figure 2. We consider function interpolation via cubic splines. (Left) The underlying distribution Px denoted by sizes of the circles. The
true function is a staircase. (Middle) With a small number of standard training samples (purple circles), an augmented estimator that ﬁts
local perturbations (green crosses) has a large error. In constrast, the standard estimator that does not ﬁt perturbations is a simple straight
line and has small error. (Right) Robust self-training (RST) regularizes the predictions of an augmented estimator towards the predictions
of the standard estimator thereby obtaining both small error on test points and their perturbations.

esis class and thus enable better generalization, not worse.

We show that this tradeoff stems from overparameterization.
If the restricted hypothesis class (by enforcing invariances)
is still overparameterized, the inductive bias of the estima-
tion procedure (e.g., the norm being minimized) plays a key
role in determining the generalization of a model.

Figure 2 shows an illustrative example of this phenomenon
with cubic smoothing splines. The predictor obtained via
standard training (dashed blue) is a line that captures the
global structure and obtains low error. Training on aug-
mented data with locally consistent perturbations of the
training data (crosses) restricts the hypothesis class by en-
couraging the predictor to ﬁt the local structure of the high
density points. Within this set, the cubic splines predic-
tor (solid orange) minimizes the second derivative on the
augmented data, compromising the global structure and per-
forming badly on the tails (Figure 2(b)). More generally,
as we characterize in Section 3, the tradeoff stems from
the inductive bias of the minimum norm interpolant, which
minimizes a ﬁxed norm independent of the data, while the
standard error depends on the geometry of the covariates.

Recent works (Carmon et al., 2019; Najaﬁ et al., 2019; Ue-
sato et al., 2019) introduced robust self-training (RST), a
robust variant of self-training that overcomes the sample
complexity barrier of learning a model with low robust error
by leveraging extra unlabeled data. In this paper, our theo-
retical understanding of the tradeoff between standard and
robust error in linear regression motivates RST as a method
to improve robust error without sacriﬁcing standard error.
In Section 4.2, we prove that RST eliminates the tradeoff
for linear regression—RST does not increase standard error
compared to the standard estimator while simultaneously
achieving the best possible robust error, matching the stan-
dard error (see Figure 2(c) for the effect of RST on the spline
problem). Intuitively, RST regularizes the predictions of the
robust estimator towards that of the standard estimator on
the unlabeled data thereby eliminating the tradeoff.

As previous works only focus on the empirical evaluation
of the gains in robustness via RST, we systematically evalu-
ate the effect of RST on both the standard and robust error
on CIFAR-10 when using unlabeled data from Tiny Images
as sourced in Carmon et al. (2019). We expand upon em-
pirical results in two ways. First, we study the effect of the
labeled training set sizes and and ﬁnd that the RST improves
both robust and standard error over vanilla adversarial train-
ing across all sample sizes. RST offers maximum gains
at smaller sample sizes where vanilla adversarial training
increases the standard error the most. Second, we consider
an additional family of perturbations over random and ad-
versarial rotation/translations and ﬁnd that RST offers gains
in both robust and standard error.

2. Setup

Y

Y

· |

∈ Y

∈ X ⊆

Rd to a target y

We consider the problem of learning a mapping from an
input x
. For our theoreti-
= R while
cal analysis, we focus on regression where
. Let Pxy be the
our empirical studies consider general
underlying distribution, Px the marginal on the inputs and
x) the conditional distribution of the targets given
Py(
Pxy, we use Xstd to
inputs. Given n training pairs (xi, yi)
Rn×d
denote the measurement matrix [x1, x2, . . . xn](cid:62)
∈
Rn.
and ystd to denote the target vector [y1, y2, . . . yn](cid:62)
∈
Our goal is to learn a predictor fθ :
that (i) has
low standard error on inputs x and (ii) low robust error
with respect to a set of perturbations T (x). Formally, the
error metrics for a predictor fθ and a loss function (cid:96) are the
standard error

X → Y

∼

Lstd(θ) = EPxy [(cid:96)(fθ(x), y)]

and the robust error

Lrob(θ) = EPxy [ max

(cid:96)(fθ(xext), y)],

xext∈T (x)

for consistent perturbations T (x) that satisfy

Py(

xext) = Py(

x),

· |

· |

xext

∀

∈

T (x).

(1)

(2)

(3)

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

Such transformations may consist of small rotations, hor-
izontal ﬂips, brightness or contrast changes (Krizhevsky
et al., 2012; Yaeger et al., 1996), or small (cid:96)p perturbations
in vision (Szegedy et al., 2014; Goodfellow et al., 2015) or
word synonym replacements in NLP (Jia & Liang, 2017;
Alzantot et al., 2018).

linear regression. We begin with a simple toy example that
describes the intuition behind our results (Section 3.1) and
provide a more complete characterization in Section 3.2.
This section focuses only on the standard error of both esti-
mators; we revisit the robust error together with the standard
error in Section 4.

Noiseless linear regression.
In section 3, we analyze
noiseless linear regression on inputs x with targets y =
Rk.1 For linear regres-
x(cid:62)θ(cid:63) with true parameter θ(cid:63)
sion, (cid:96) is the squared loss which leads to the standard error
(Equation 1) taking the form

∈

Lstd(θ) = EPx[(x(cid:62)θ

x(cid:62)θ(cid:63))2] = (θ

θ(cid:63))(cid:62)Σ(θ

θ(cid:63)), (4)

−
where Σ = EPx[xx(cid:62)] is the population covariance.

−

−

Minimum norm estimators.
In this work, we focus on
interpolating estimators in highly overparameterized mod-
els, motivated by modern machine learning models that
achieve near zero training loss (on both standard and extra
data). Interpolating estimators for linear regression have
been studied in many recent works such as (Ma et al., 2018;
Belkin et al., 2018; Hastie et al., 2019; Liang & Rakhlin,
2018; Bartlett et al., 2019). We present our results for in-
terpolating estimators with minimum Euclidean norm, but
our analysis directly applies to more general Mahalanobis
norms via suitable reparameterization (see Appendix A).

∈

∈

×

×

Rn×d

∈
Rm×d

T (x), x

xext : xext
{

We consider robust training approaches that augment the
R with some
standard training data Xstd, ystd
R where the rows
extra training data Xext, yext
of Xext consist of vectors in the set
∈
.2 We call the standard data together with the extra
Xstd
}
data as augmented data. We compare the following min-
norm estimators: (i) the standard estimator ˆθstd interpolating
[Xstd, ystd] and (ii) the augmented estimator ˆθaug interpolat-
ing X = [Xstd; Xext], Y = [ystd; yext]:
(cid:110)
θ
(cid:107)
(cid:110)
θ
(cid:107)

2 : Xstdθ = ystd
(cid:107)
2 : Xstdθ = ystd, Xextθ = yext
(cid:107)

ˆθstd = arg min
θ
ˆθaug = arg min
θ

(cid:111)
.

(5)

(cid:111)

Notation. For any vector z
ith coordinate of z.

∈

Rn, we use zi to denote the

3. Analysis in the linear regression setting

In this section, we compare the standard errors of the stan-
dard estimator and the augmented estimator in noiseless

1Our analysis extends naturally to arbitrary feature maps φ(x).
2In practice, Xext is typically generated via iterative optimiza-
tion such as in adversarial training (Madry et al., 2018), or by
random sampling as in data augmentation (Krizhevsky et al., 2012;
Yaeger et al., 1996).

3.1. Simple illustrative problem

∈

R3 is
We consider a simple example in 3D where θ(cid:63)
the true parameter. Let e1 = [1, 0, 0]; e2 = [0, 1, 0]; e3 =
[0, 0, 1] denote the standard basis vectors in R3. Suppose we
have one point in the standard training data Xstd = [0, 0, 1].
ˆθstd = ystd and hence
By deﬁnition (5), ˆθstd satisﬁes Xstd
(ˆθstd)3 = θ(cid:63)
3. However, ˆθstd is unconstrained on the subspace
spanned by e1, e2 (the nullspace Null(Xstd)). The min-norm
objective chooses the solution with (ˆθstd)1 = (ˆθstd)2 = 0.
Figure 3 visualizes the projection of various quantities on
Null(Xstd). For simplicity of presentation, we omit the
projection operator in the ﬁgure. The projection of ˆθstd onto
Null(Xstd) is the blue dot at the origin, and the parameter
error θ(cid:63)

ˆθstd is the projection of θ(cid:63) onto Null(Xstd).

−

Effect of augmentation on parameter error. Suppose
we augment with an extra data point Xext = [1, 1, 0] =
e1 + e2 which lies in Null(Xstd) (black dashed line in Fig-
ure 3). The augmented estimator ˆθaug still ﬁts the standard
data Xstd and thus (ˆθaug)3 = θ(cid:63)
3 = (ˆθstd)3. Due to ﬁtting
the extra data Xext, ˆθaug (orange vector in Figure 3) must
ˆθaug = Xextθ(cid:63). The
also satisfy an additional constraint Xext
crucial observation is that additional constraints along one
direction (e1 + e2 in this case) could actually increase pa-
rameter error along other directions. For example, let’s
consider the direction e2 in Figure 3. Note that ﬁtting Xext
makes ˆθaug have a large component along e2. Now if θ(cid:63)
2 is
1/3), ˆθaug has a larger parameter
small (precisely, θ(cid:63)
error along e2 than ˆθstd, which was simply zero (Figure 3
(a)). Conversely, if the true component θ(cid:63)
2 is large enough
1/3), the parameter error of ˆθaug along e2
(precisely, θ(cid:63)
is smaller than that of ˆθstd.

2 < θ(cid:63)

2 > θ(cid:63)

Effect of parameter error on standard error. The con-
tribution of different components of the parameter error to
the standard error is scaled by the population covariance Σ
(see Equation 4). For simplicity, let Σ = diag([λ1, λ2, λ3]).
the parameter error along e3 is zero
In our example,
since both estimators interpolate the standard training point
Xstd = e1 = 3. Then, the ratio between λ1 and λ2 deter-
mines which component of the parameter error contributes
more to the standard error.

When is Lstd(ˆθaug) > Lstd(ˆθstd)? Putting the two effects
2 is small as in Fig 3(a), ˆθaug
together, we see that when θ(cid:63)

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

(a) θ(cid:63)

1 (cid:29) θ(cid:63)
2

(b) θ(cid:63)

2 (cid:29) θ(cid:63)
1

(c) Σ = diag([1, 4])

(d) Σ = diag([1, 25])

Figure 3. Illustration of the 3-D example described in Sec. 3.1. (a)-
(b) Effect of augmentation on parameter error for different θ(cid:63).
We show the projections of the standard estimator ˆθstd (blue circle),
augmented estimator ˆθaug (orange arrow), and true parameters θ(cid:63)
(black arrow) on Null(Xstd), spanned by e1 and e2. For simplicity
of presentation, we omit the projection operator in the ﬁgure labels.
Depending on θ(cid:63), the parameter error of ˆθaug along e2 could be
larger or smaller than the parameter error of ˆθstd along e2. (c)–(d)
Dependence of space of safe augmentations on Σ. Visualization
of the space of extra data points xext (orange), that do not cause an
increase in the standard error for the illustrated θ(cid:63) (black vector),
as result of Theorem 1.

has larger parameter error than ˆθstd in the direction e2. If
λ1, error in e2 is weighted much more heavily in the
λ2
standard error and consequently ˆθaug would have a larger
standard error. Precisely, we have

(cid:29)

Lstd(ˆθaug) > Lstd(ˆθstd)

λ2(θ(cid:63)

1 −

⇐⇒

3θ(cid:63)

2) > λ1(3θ(cid:63)

θ(cid:63)
2).

1 −

We present a formal characterization of this tradeoff in gen-
eral in the next section.

3.2. General characterizations

In this section, we precisely characterize when the aug-
mented estimator ˆθaug that ﬁts extra training data points Xext
in addition to the standard points Xstd has higher standard
error than the standard estimator ˆθstd that only ﬁts Xstd. In
particular, this enables us to understand when there is a
“tradeoff” where the augmented estimator ˆθaug has lower
robust error than ˆθstd by virtue of ﬁtting perturbations, but
has higher standard error. In Section 3.1, we illustrated how
the parameter error of ˆθaug could be larger than ˆθstd in some
directions, and if these directions are weighted heavily in the
population covariance Σ, the standard error of ˆθaug would
be larger.

Formally, let us deﬁne the parameter errors ∆std

def= ˆθstd

θ(cid:63)

−

and ∆aug

def= ˆθaug

θ(cid:63). Recall that the standard errors are

−
stdΣ∆std, Lstd(ˆθaug) = ∆(cid:62)
Lstd(ˆθstd) = ∆(cid:62)

augΣ∆aug,

(6)

where Σ is the population covariance of the underlying
inputs drawn from Px.

To characterize the effect of the inductive bias of mini-
mum norm interpolation on the standard errors, we de-
ﬁne the following projection operators: Π⊥
std, the projec-
tion matrix onto Null(Xstd) and Π⊥
aug, the projection ma-
trix onto Null([Xext; Xstd]) (see formal deﬁnition in Ap-
pendix B). Since ˆθaug and ˆθstd are minimum norm inter-
ˆθaug = 0. Further, in noiseless
ˆθstd = 0 and Π⊥
polants, Π⊥
aug
std
linear regression, ˆθstd and ˆθaug have no error in the span of
Xstd and [Xstd; Xext] respectively. Hence,

∆std = Π⊥

stdθ(cid:63), ∆aug = Π⊥

augθ(cid:63).

(7)

Our main result relies on the key observation that for any
vector u, Π⊥
stdu can be decomposed into a sum of two or-
thogonal components v and w such that Π⊥
stdu = v + w
augu and v = Π⊥
with w = Π⊥
stdΠaugu. This is because
aug = Π⊥
stdΠ⊥
Null([Xstd; Xext])
aug.
Now setting u = θ(cid:63) and using the error expressions in Equa-
tion 6 and Equation 7 gives a precise characterization of the
difference in the standard errors of ˆθstd and ˆθaug.
Theorem 1. The difference in the standard errors of the
standard estimator ˆθstd and augmented estimator ˆθaug can
be written as follows.

Null(Xstd) and thus Π⊥

⊆

Lstd(ˆθstd)

Lstd(ˆθaug) = v(cid:62)Σv + 2w(cid:62)Σv,

(8)

−

where v = Π⊥

stdΠaugθ(cid:63) and w = Π⊥

augθ(cid:63).

The proof of Theorem 1 is in Appendix B.3. The increase in
standard error of the augmented estimator can be understood
in terms of the vectors w and v deﬁned in Theorem 1. The
ﬁrst term v(cid:62)Σv is always positive, and corresponds to the
decrease in the standard error of the augmented estimator
ˆθaug by virtue of ﬁtting extra training points in some direc-
tions. However, the second term 2w(cid:62)Σv can be negative
and intuitively measures the cost of a possible increase in
the parameter error along other directions (similar to the in-
crease along e2 in the simple setting of Figure 3(a)). When
the cost outweighs the beneﬁt, the standard error of ˆθaug is
larger. Note that both the cost and beneﬁt is determined
by Σ which governs how the parameter error affects the
standard error.

We can use the above expression (Theorem 1) for the dif-
ference in standard errors of ˆθaug and ˆθstd to characterize
different “safe” conditions under which augmentation with
extra data does not increase the standard error. See Ap-
pendix B.7 for a proof.

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

Corollary 1. The following conditions are sufﬁcient for
Lstd(ˆθaug)
the standard error does not
increase when ﬁtting augmented data.

Lstd(ˆθstd), i.e.

≤

1. The population covariance Σ is identity.

2. The augmented data [Xstd; Xext] spans the entire space,

or equivalently Π⊥

aug = 0.

3. The extra data xext

xext is an eigenvector of Σ.

∈

Rd is a single point such that

Matching inductive bias. We would like to draw special
attention to the ﬁrst condition. When Σ = I, notice that the
norm that governs the standard error (Equation 6) matches
the norm that is minimized by the interpolants (Equation 5).
Intuitively, the estimators have the “right” inductive bias;
under this condition, the augmented estimator ˆθaug does not
have higher standard error. In other words, the observed
increase in the standard error of ˆθaug can be attributed to
the “wrong” inductive bias. In Section 4, we will use this
understanding to propose a method of robust training which
does not increase standard error over standard training.

∈

Safe extra points. We use Theorem 1 to plot the safe
Rd that do not lead to an increase in
extra points xext
standard error for any θ(cid:63) in the simple 3D setting described
in Section 3.1 for two different Σ (Figure 3 (c), (d)). The
safe points lie in cones which contain the eigenvectors of Σ
(as expected from Corollary 1). The width and alignment
of the cones depends on the alignment between θ(cid:63) and
the eigenvectors of Σ. As the eigenvalues of Σ become
less skewed, the space of safe points expands, eventually
covering the entire space when Σ = I (see Corollary 1).

Local versus global structure. We now tie our analysis
back to the cubic splines interpolation problem from Fig-
ure 2. The inputs can be appropriately rotated and scaled
such that the cubic spline interpolant is the minimum Eu-
clidean norm interpolant (as in Equation 5). Under this
transformation, the different eigenvectors of the nullspace
of the training data Null(Xstd) represent the “local” high
frequency components with small eigenvalues or “global”
low frequency components with large eigenvalues (see Fig-
ure 4). An augmentation that encourages the ﬁtting local
components in Null(Xstd) could potentially increase the er-
ror along other global components (like the increase in error
along e2 in Figure 3(a)). Such an increase, coupled with
the fact that global components have larger eigenvalue in
Σ, results in the standard error of ˆθaug being larger than that
of ˆθstd. See Figure 8 and Appendix C.3.1 for more details.
This is similar to the recent observation that adversarial
training with (cid:96)∞ perturbations encourages neural networks
to ﬁt the high frequency components of the signal while

Figure 4. Top 4 eigenvectors of Σ in the splines problem (from
Figure 2), representing wave functions in the input space. The
“global” eigenfunctions, varying less over the domain, correspond
to larger eigenvalues, making errors in global dimensions costly in
terms of test error.

compromising on the low-frequency components (Yin et al.,
2019).

Model complexity. Finally, we relate the magnitude of
increase in standard error of the augmented estimator to the
complexity of the true model.
Proposition 1. For a given Xstd, Xext, Σ,

Lstd(ˆθaug)

Lstd(ˆθstd) > c =

−

θ(cid:63)

2
2 − (cid:107)
(cid:107)

ˆθstd

2
2 > γc
(cid:107)

⇒ (cid:107)

for some scalar γ > 0 that depends on Xstd, Xext, Σ.

In other words, for a large increase in standard error upon
augmentation, the true parameter θ(cid:63) needs to be sufﬁciently
more complex (in the (cid:96)2 norm) than the standard estimator
ˆθstd. For example, the construction of the cubic splines in-
terpolation problem relies on the underlying function (stair-
case) being more complex with additional local structure
than the standard estimator—a linear function that ﬁts most
points and can be learned with few samples. Proposition 1
states that this requirement holds more generally. The proof
of Proposition 1 appears in Appendix B.5. A similar intu-
ition can be used to construct an example where augmen-
tation can increase standard error for minimum (cid:96)1-norm
interpolants when θ(cid:63) is dense (Appendix G).

4. Robust self-training

We now use insights from Section 3 to construct estimators
with low robust error without increasing the standard error.
While Section 3 characterized the effect of adding extra data
Xext in general, in this section we consider robust training
which augments the dataset with extra data Xext that are
consistent perturbations of the standard training data Xstd.

Since the standard estimator has small standard error, a
natural strategy to mitigate the tradeoff is to regularize the
augmented estimator to be closer to the standard estimator.
The choice of distance between the estimators we regularize
is very important. Recall from Section 3.1 that the pop-
ulation covariance Σ determines how the parameter error
affects the standard error. This suggests using a regularizer
that incorporates information about Σ.

We ﬁrst revisit the recently proposed robust self-training
(RST) (Carmon et al., 2019; Najaﬁ et al., 2019; Uesato

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

et al., 2019) that incorporates additional unlabeled data via
pseudo-labels from a standard estimator. Previous work only
focused on the effectiveness of RST in improving the robust
error. In Section 4.2, we prove that in linear regression, RST
eliminates the tradeoff between standard and robust error
(Theorem 2). The proof hinges on the connection between
RST and the idea of regularizing towards the standard es-
timator discussed above. In particular, we show that the
RST objective can be rewritten as minimizing a suitable
Σ-induced distance to the standard estimator.

In Section 4.3, we expand upon previous empirical RST
results for CIFAR-10 across various training set sizes and
perturbations (rotations/translations in addition to (cid:96)∞). We
observe that across all settings, RST substantially improves
the standard error while also improving the robust error over
the vanilla supervised robust training counterparts.

4.1. General formulation of RST

We ﬁrst describe the general two-step robust self-training
(RST) procedure (Carmon et al., 2019; Uesato et al., 2019)
for a parameteric model fθ:

1. Perform standard training on labeled data

to obtain ˆθstd = arg minθ

n
(xi, yi)
i=1
}
{
(cid:96)(cid:0)fθ(xi), yi).

n
(cid:80)
i=1

The second stage typically involves a combination of the
standard loss (cid:96) and a robust loss (cid:96)rob. The robust loss en-
courages invariance of the model over perturbations T (x),
and is generally deﬁned as

(cid:96)rob(fθ(xi), yi) = max

(cid:96)(fθ(xadv), yi).

(9)

xadv∈T (xi)

It is convenient to summarize the robust self-training esti-
mator ˆθrst as the minimizer of a weighted combination of
four separate losses as follows. We deﬁne the losses on the
n
(xi, yi)
i=1 as
labeled dataset
}
{

ˆLstd-lab(θ) =

(cid:96)(fθ(xi), yi),

ˆLrob-lab(θ) =

(cid:96)rob(fθ(xi), yi).

1
n

1
n

n
(cid:88)

i=1
n
(cid:88)

i=1

Figure 5. Illustration shows the four components of the RST loss
(Equation (10)) in the special case of linear regression (Eq. (11)).
Green cells contain hard constraints where the optimal θ(cid:63) obtains
zero loss. The orange cell contains the soft constraint that is
minimized while satisfying hard constraints to obtain the ﬁnal
linear RST estimator.

m
The losses on the unlabeled samples
i=1 which are
}
psuedo-labeled by the standard estimator are

˜xi
{

ˆLstd-unlab(θ; ˆθstd) =

(cid:96)(fθ(˜xi), fˆθstd

(˜xi)),

ˆLrob-unlab(θ; ˆθstd) =

(cid:96)rob(fθ(˜xi), fˆθstd

(˜xi)).

1
m

1
m

m
(cid:88)

i=1
m
(cid:88)

i=1

Putting it all together, we have

ˆθrst := arg min

α ˆLstd-lab(θ) + β ˆLrob-lab(θ)

(10)

(cid:16)

θ

(cid:17)
+ γ ˆLstd-unlab(θ; ˆθstd) + λ ˆLrob-unlab(θ; ˆθstd)

,

4.2. Robust self-training for linear regression

We now return to the noiseless linear regression as described
in Section 2 and specialize the general RST estimator de-
scribed in Equation (10) to this setting. We prove that RST
eliminates the decrease in standard error in this setting while
achieving low robust error by showing that RST appropri-
ately regularizes the augmented estimator towards the stan-
dard estimator.

Our theoretical results hold for RST procedures where the
pseudo-labels can be generated from any interpolating esti-
mator θint-std satisfying Xstdθint-std = ystd. This includes but
is not restricted to the mininum-norm standard estimator ˆθstd
deﬁned in (5). We use the squared loss as the loss function (cid:96).
For consistent perturbations T (
), we analyze the following
·
RST estimator for linear regression

ˆθrst = arg min

θ

Lstd-unlab(θ; θint-std) : Lrob-unlab(θ) = 0,
{
ˆLstd-lab(θ) = 0, ˆLrob-lab(θ) = 0
.
}

(11)

Figure 5 shows the four losses of RST in this special case
of linear regression.

2. Perform robust training on both the labeled data and
m
i=1 with pseudo-labels ˜yi =
}

(˜xi) generated from the standard estimator ˆθstd.

unlabeled inputs
fˆθstd

˜xi
{

for ﬁxed scalars α, β, γ, λ

0.

≥

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

Obtaining this specialized estimator from the general RST
estimator in Equation (10) involves the following steps.
First, for convenience of analysis, we assume access to
the population covariance Σ via inﬁnite unlabeled data
and thus replace the ﬁnite sample losses on the unlabeled
data ˆLstd-unlab(θ), ˆLrob-unlab(θ) by their population losses
Lstd-unlab(θ), Lrob-unlab(θ). Second, the general RST objec-
tive minimizes some weighted combination of four losses.
When specializing to the case of noiseless linear regression,
since ˆLstd, lab(θ(cid:63)) = 0, rather than minimizing α ˆLstd-lab(θ(cid:63)),
we set the coefﬁcients on the losses such that the estima-
tor satisﬁes a hard constraint ˆLstd-lab(θ(cid:63)) = 0. This con-
straint which enforces interpolation on the labeled dataset
yi = x(cid:62)
i = 1, . . . n allows us to rewrite the robust
i θ
loss (Equation 9) on the labeled examples equivalently as a
self-consistency loss deﬁned independent of labels.

∀

ˆLrob-lab(θ) =

max
xadv∈T (x)

(x(cid:62)
i θ

−

advθ)2.
x(cid:62)

1
n

n
(cid:88)

i=1

Since θ(cid:63) is invariant on perturbations T (x) by deﬁnition,
we have ˆLrob-lab(θ(cid:63)) = 0 and thus we introduce a constraint
ˆLrob-lab(θ) = 0 in the estimator.

For the losses on the unlabeled data, since the pseudo-labels
are not perfect, we minimize Lstd-unlab in the objective in-
stead of enforcing a hard constraint on Lstd-unlab. However,
similarly to the robust loss on labeled data, we can re-
formulate the robust loss on unlabeled samples Lrob-unlab
as a self-consistency loss that does not use pseudo-labels.
By deﬁnition, Lrob-unlab(θ(cid:63)) = 0 and thus we enforce
Lrob-unlab(θ) = 0 in the specialized estimator.

We now study the standard and robust error of the linear
regression RST estimator deﬁned above in Equation (11).
Theorem 2. Assume the noiseless linear model y = x(cid:62)θ(cid:63).
Let θint-std be an arbitrary interpolant of the standard data,
i.e. Xstdθint-std = ystd. Then
(cid:0)ˆθrst)

Lstd(θint-std).

Lstd

≤

Simultaneously, Lrob(ˆθrst) = Lstd(ˆθrst).

See Appendix D for a full proof.

The crux of the proof is that the optimization objective of
RST is an inductive bias that regularizes the estimator to
be close to the standard estimator, weighing directions by
their contribution to the standard error via Σ. To see this,
we rewrite

Lstd-unlab(θ; θint-std) = EPx[(˜x(cid:62)θint-std

˜x(cid:62)θ)2]

= (θint-std

−

−
θ)(cid:62)Σ(θint-std

θ).

−

By incorporating an appropriate Σ-induced regularizer
while satisfying constraints on the robust losses, RST en-
sures that the standard error of the estimator never exceeds

(a) Spline Staircase

(b) CIFAR-10 (AT)

Figure 6. Effect of data augmentation on test error as we vary the
number of training samples. (a)-(b) We plot the difference in er-
rors of the augmented estimator and standard estimator. In both
the spline staircase simulations and data augmentation with adver-
sarial (cid:96)∞ perturbations via adversarial training (AT) on CIFAR-10,
the increase in test error decreases as the training sample size in-
creases. In (b), robust self-training (RST+AT) not only mitigates
the increase in test error from AT but even improves test error
beyond that of the standard estimator.

the standard error of ˆθstd. The robust error of any estimator
is lower bounded by its standard error, and this gap can be
arbitrarily large for the standard estimator. However, the
robust error of the RST estimator matches the lower bound
of its standard error which in turn is bounded by the stan-
dard error of the standard estimator and hence is small. To
provide some graphical intuition for the result, see Figure 2
that visualizes the RST estimator on the cubic splines inter-
polation problem that exempliﬁes the increase in standard
error upon augmentation. RST captures the global structure
and obtains low standard error by matching ˆθstd (straight
line) on unlabeled inputs. Simultaneously, RST enforces
invariance on local transformations on both labeled and un-
labeled inputs, and obtains low robust error by capturing the
local structure across the domain.

Implementation of linear RST. The constraint on the
standard loss on labeled data simply corresponds to interpo-
lation on the standard labeled data. The constraints on the
robust self-consistency losses involve a maximization over
a set of transformations. In the case of linear regression,
such constraints can be equivalently represented by a set of
at most d linear constraints, where d is the dimension of the
covariates. Further, with this ﬁnite set of constraints, we
only require access to the covariance Σ in order to constrain
the population robust loss. Appendix D gives a practical
iterative algorithm that computes the RST estimator for
linear regression reminiscent of adversarial training in the
semi-supervised setting.

4.3. Empirical evaluation of RST

Carmon et al. (2019) empirically evaluate RST with a fo-
cus on studying gains in the robust error. In this work, we
focus on both the standard and robust error and expand
upon results from previous work. Carmon et al. (2019) used

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

Method

Standard Training
PG-AT (Madry et al., 2018)
TRADES (Zhang et al.,
2019)
Standard Self-Training
Robust Consistency Training
(Carmon et al., 2019)
RST + PG-AT (this paper)
RST + TRADES (this
paper)
(Carmon et al., 2019)
Interpolated AT
(Lamb et al., 2019)3
Neural Arch. Search
(Cubuk et al., 2017)

Robust
Test Acc.

0.8%
45.8%
55.4%

0.3%
56.5%

58.5%
63.1%

45.1%

50.1%

Standard
Test Acc.
95.2% 

87.3%
84.0%



96.4% 

83.2%


91.8%
89.7%

93.6% 


93.2%



Semisupervised
with same
unlabeled data

Modiﬁed
supervised

Vanilla
Supervised

Method

Standard Training
Worst-of-10
Random
RST + Worst-of-10 (this
paper)
RST + Random (this
paper)
Worst-of-10
(Engstrom et al., 2019)4
Random (Yang et al., 2019)5

Robust
Test Acc.

0.2%
73.9%
67.7%
75.1%

Standard
Test Acc.
94.6% 

95.0%

95.1%
95.8% (cid:27)

70.9%

95.8%

69.2%

58.3%

91.3% 


91.8%



Vanilla
Supervised

Semisupervised

Existing baselines
(smaller model)

Table 1. Performance of robust self-training (RST) applied to different perturbations and adversarial training algorithms. (Left) CIFAR-
10 standard and robust test accuracy against (cid:96)∞ perturbations of size (cid:15) = 8/255. All methods use (cid:15) = 8/255 while training and use
the WRN-28-10 model. Robust accuracies are against a PG based attack with 20 steps. (Right) CIFAR-10 standard and robust test
accuracy against a grid attack of rotations up to 30 degrees and translations up to ∼ 10% of the image size, following (Engstrom et al.,
2019). All adversarial and random methods use the same parameters during training and use the WRN-40-2 model. For both tables,
shaded rows make use of 500K unlabeled images from 80M Tiny Images sourced in (Carmon et al., 2019). RST improves both the
standard and robust accuracy over the vanilla counterparts for different algorithms (AT and TRADES) and different perturbations ((cid:96)∞ and
rotation/translations).

TRADES (Zhang et al., 2019) as the robust loss in the gen-
eral RST formulation (10); we additionally evaluate RST
with Projected Gradient Adversarial Training (AT) (Madry
et al., 2018) as the robust loss. Carmon et al. (2019) con-
sidered (cid:96)∞ and (cid:96)2 perturbations. We study rotations and
translations in addition to (cid:96)∞ perturbations, and also study
the effect of labeled training set size on standard and robust
error. Table 1 presents the main results. More experiment
details appear in Appendix D.3.

Both RST+AT and RST+TRADES have lower robust and
standard error than their supervised counterparts AT and
TRADES across all perturbation types. This mirrors the
theoretical analysis of RST in linear regression (Theorem 2)
where the RST estimator has small robust error while prov-
ably not sacriﬁcing standard error, and never obtaining
larger standard error than the standard estimator.

Effect of labeled sample size. Recall that our work mo-
tivates studying the tradeoff between robust and standard
error while taking generalization from ﬁnite data into ac-
count. We showed that the gap in the standard error of a
standard estimator and that of a robust estimator is large for
small training set sizes and decreases as the labeled dataset
is larger (Figure 1). We now study the effect of RST as we
vary the training set size in Figure 6. We ﬁnd that RST+AT
has lower standard error than standard training across all
sample sizes for small (cid:15), while simultaneously achieving
lower robust error than AT (see Appendix E.2.1). In the

small data regime where vanilla adversarial training hurts
the standard error the most, we ﬁnd that RST+AT gives
about 3x more absolute improvement than in the large data
regime. We note that this set of experiments are comple-
mentary to the experiments in (Schmidt et al., 2018) which
study the effect of the training set size only on robust error.

Effect on transformations that do not hurt standard er-
ror. We also test the effect of RST on perturbations where
robust training slightly improves standard error rather than
hurting it. Since RST regularizes towards the standard esti-
mator, one might suspect that the improvements from robust
training disappear with RST. In particular, we consider spa-
tial transformations T (x) that consist of simultaneous rota-
tions and translations. We use two common forms of robust
training for spatial perturbations, where we approximately
maximize over T (x) with either adversarial (worst-of-10) or
random augmentations (Yang et al., 2019; Engstrom et al.,
2019). Table 1 (right) presents the results. In the regime
where vanilla robust training does not hurt standard error,
RST in fact further improves the standard error by almost
1% and the robust error by 2-3% over the standard and
robust estimators for both forms of robust training. Thus
in settings where vanilla robust training improves standard
error, RST seems to further amplify the gains while in set-
tings where vanilla robust training hurts standard error, RST
mitigates the harmful effect.

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

Comparison to other semi-supervised approaches.
The RST estimator minimizes both a robust loss and a stan-
dard loss on the unlabeled data with pseudo-labels (bottom
row, Figure 5). Both of these losses are necessary to si-
multaneously improve both the standard and robust error
over the vanilla supervised robust training. Standard self-
training, which only uses standard loss on unlabeled data,
100%). Similarly, Robust
has very high robust error (
≈
Consistency Training, an extension of Virtual Adversarial
Training (Miyato et al., 2018) that only minimizes a ro-
bust self-consistency loss on unlabeled data, marginally
improves the robust error but actually hurts standard error.
See Table 1.

Complementary methods for robustness and accuracy.
In Table 1, we also report the standard and robust errors
of other methods that improve the tradeoff between stan-
dard and robust error. Interpolated Adversarial Training
(IAT) (Lamb et al., 2019) considers a different training al-
gorithm based on Mixup, and Neural Architecture Search
(NAS) (Cubuk et al., 2017) uses RL to search for more ro-
bust architectures. RST, IAT and NAS are incomparable
as they ﬁnd different tradeoffs between standard and ro-
bust error. However, we believe that since RST provides a
complementary statistical perspective on the tradeoff, it can
be combined with methods like IAT or NAS to see further
gains. We leave this to future work.

5. Conclusion

We studied the commonly observed increase in standard
error upon adversarial training taking generalization from ﬁ-
nite data into account. We showed that augmenting training
data with perturbations, like in adversarial training can sur-
prisingly increase the standard error even in a simple setting
of noiseless linear regression where the true linear function
has zero standard and robust error. Our analysis reveals
that the interplay between the inductive bias of models and
the underlying geometry of the inputs causes the standard
error to increase even when the augmented data is perfectly
labeled. This insight provides a method that provably elimi-
nates the increase in standard error upon augmentation in
linear regression by incorporating an appropriate regularizer
based on the geometry of the inputs. While not immedi-
ately apparent, we show that this is a special case of the
recently proposed robust self-training (RST) procedure that
uses additional unlabeled data. Previous works view RST
as a method to improve the robust error by effectively using
more samples. Our work provides some theoretical justiﬁ-
cation for why RST improves both the standard and robust
error thereby mitigating the tradeoff between accuracy and
robustness in practice. How to best utilize unlabeled data,
and whether sufﬁcient unlabeled data would completely
eliminate the tradeoff remain open questions.

References

Alzantot, M., Sharma, Y., Elgohary, A., Ho, B., Srivastava,
M., and Chang, K. Generating natural language adversar-
ial examples. In Empirical Methods in Natural Language
Processing (EMNLP), 2018.

Bartlett, P. L., Long, P. M., Lugosi, G., and Tsigler, A.
Benign overﬁtting in linear regression. arXiv, 2019.

Belkin, M., Ma, S., and Mandal, S. To understand deep
learning we need to understand kernel learning. In In-
ternational Conference on Machine Learning (ICML),
2018.

Carmon, Y., Raghunathan, A., Schmidt, L., Liang, P., and
Duchi, J. C. Unlabeled data improves adversarial ro-
bustness. In Advances in Neural Information Processing
Systems (NeurIPS), 2019.

Cubuk, E. D., Zoph, B., Schoenholz, S. S., and Le, Q. V.
Intriguing properties of adversarial examples. arXiv
preprint arXiv:1711.02846, 2017.

Diamond, S. and Boyd, S. CVXPY: A Python-embedded
modeling language for convex optimization. Journal of
Machine Learning Research (JMLR), 17(83):1–5, 2016.

Engstrom, L., Tran, B., Tsipras, D., Schmidt, L., and Madry,
A. Exploring the landscape of spatial robustness.
In
International Conference on Machine Learning (ICML),
pp. 1802–1811, 2019.

Fawzi, A., Fawzi, O., and Frossard, P. Analysis of classi-
ﬁers’ robustness to adversarial perturbations. Machine
Learning, 107(3):481–508, 2018.

Friedman, J., Hastie, T., and Tibshirani, R. The elements of
statistical learning, volume 1. Springer series in statistics
New York, NY, USA: Springer series in statistics New
York, NY, USA:, 2001.

Goodfellow, I. J., Shlens, J., and Szegedy, C. Explaining
and harnessing adversarial examples. In International
Conference on Learning Representations (ICLR), 2015.

Hastie, T., Montanari, A., Rosset, S., and Tibshirani, R. J.
Surprises in high-dimensional ridgeless least squares in-
terpolation. arXiv preprint arXiv:1903.08560, 2019.

Jia, R. and Liang, P. Adversarial examples for evaluating
reading comprehension systems. In Empirical Methods
in Natural Language Processing (EMNLP), 2017.

Krizhevsky, A., Sutskever, I., and Hinton, G. E. Imagenet
classiﬁcation with deep convolutional neural networks.
In Advances in Neural Information Processing Systems
(NeurIPS), pp. 1097–1105, 2012.

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

Tsipras, D., Santurkar, S., Engstrom, L., Turner, A., and
Madry, A. Robustness may be at odds with accuracy. In
International Conference on Learning Representations
(ICLR), 2019.

Uesato, J., Alayrac, J., Huang, P., Stanforth, R., Fawzi, A.,
and Kohli, P. Are labels required for improving adver-
sarial robustness? In Advances in Neural Information
Processing Systems (NeurIPS), 2019.

Xie, Q., Dai, Z., Hovy, E., Luong, M., and Le, Q. V.
arXiv preprint

Unsupervised data augmentation.
arXiv:1904.12848, 2019.

Yaeger, L., Lyon, R., and Webb, B. Effective training of a
neural network character classiﬁer for word recognition.
In Advances in Neural Information Processing Systems
(NeurIPS), pp. 807–813, 1996.

Yang, F., Wang, Z., and Heinze-Deml, C.

Invariance-
inducing regularization using worst-case transformations
sufﬁces to boost accuracy and spatial robustness.
In
Advances in Neural Information Processing Systems
(NeurIPS), 2019.

Yin, D., Lopes, R. G., Shlens, J., Cubuk, E. D., and Gilmer,
J. A fourier perspective on model robustness in computer
vision. arXiv preprint arXiv:1906.08988, 2019.

Zagoruyko, S. and Komodakis, N. Wide residual networks.

In British Machine Vision Conference, 2016.

Zhang, C., Bengio, S., Hardt, M., Recht, B., and Vinyals,
O. Understanding deep learning requires rethinking gen-
In International Conference on Learning
eralization.
Representations (ICLR), 2017.

Zhang, H., Yu, Y., Jiao, J., Xing, E. P., Ghaoui, L. E., and
Jordan, M. I. Theoretically principled trade-off between
robustness and accuracy. In International Conference on
Machine Learning (ICML), 2019.

Laine, S. and Aila, T. Temporal ensembling for semi-
In International Conference on

supervised learning.
Learning Representations (ICLR), 2017.

Lamb, A., Verma, V., Kannala, J., and Bengio, Y. Inter-
polated adversarial training: Achieving robust neural
networks without sacriﬁcing too much accuracy. arXiv,
2019.

Liang, T. and Rakhlin, A.

Just interpolate: Kernel”
ridgeless” regression can generalize. arXiv preprint
arXiv:1808.00387, 2018.

Ma, S., Bassily, R., and Belkin, M. The power of interpola-
tion: Understanding the effectiveness of SGD in modern
over-parametrized learning. In International Conference
on Machine Learning (ICML), 2018.

Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and
Vladu, A. Towards deep learning models resistant to
adversarial attacks (published at ICLR 2018). arXiv,
2017.

Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and
Vladu, A. Towards deep learning models resistant to
adversarial attacks. In International Conference on Learn-
ing Representations (ICLR), 2018.

Miyato, T., Maeda, S., Ishii, S., and Koyama, M. Virtual
adversarial training: a regularization method for super-
vised and semi-supervised learning. IEEE Transactions
on Pattern Analysis and Machine Intelligence, 2018.

Najaﬁ, A., Maeda, S., Koyama, M., and Miyato, T. Robust-
ness to adversarial perturbations in learning from incom-
plete data. In Advances in Neural Information Processing
Systems (NeurIPS), 2019.

Nakkiran, P. Adversarial robustness may be at odds with
simplicity. arXiv preprint arXiv:1901.00532, 2019.

Sajjadi, M., Javanmardi, M., and Tasdizen, T. Regulariza-
tion with stochastic transformations and perturbations for
deep semi-supervised learning. In Advances in Neural In-
formation Processing Systems (NeurIPS), pp. 1163–1171,
2016.

Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., and
Madry, A. Adversarially robust generalization requires
more data. In Advances in Neural Information Processing
Systems (NeurIPS), pp. 5014–5026, 2018.

Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan,
D., Goodfellow, I., and Fergus, R.
Intriguing proper-
ties of neural networks. In International Conference on
Learning Representations (ICLR), 2014.

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

A. Transformations to handle arbitrary matrix norms

Consider a more general minimum norm estimator of the following form. Given inputs X and corresponding targets y as
training data, we study the interpolation estimator,

ˆθ = arg min

θ(cid:62)M θ : Xθ = y

(cid:111)
,

(cid:110)

θ

where M is a positive deﬁnite (PD) matrix that incorporates prior knowledge about the true model. For simplicity, we
present our results in terms of the (cid:96)2 norm (ridgeless regression) as deﬁned in Equation 12. However, all our results hold for
M −1/2x and
arbitrary M –norms via appropriate rotations. Given an arbitrary PD matrix M , the rotated covariates x
rotated parameters θ

M 1/2θ maintain y = Xθ and the M -norm of parameters simpliﬁes to

←

θ

2.

(cid:107)

(cid:107)

←

B. Standard error of minimum norm interpolants

B.1. Projection operators

The projection operators Π⊥

std and Π⊥

aug are formally deﬁned as follows.

Σstd = X (cid:62)
stdXstd + X (cid:62)

stdXstd, Π⊥
extXext, Π⊥

std = I
aug = I

Σaug = X (cid:62)

Σ+
stdΣstd
Σ+
augΣaug.

−

−

B.2. Invariant transformations may have arbitrary nullspace components

We show that the transformations which satisfy the invariance condition (˜x
of x may have arbitrary nullspace components for general transfomation mappings T . Let Πstd and Π⊥
and nullspace projections for the original data Xstd. The invariance condition is equivalent to

x)(cid:62)θ(cid:63) = 0 where ˜x

−

∈

T (x) is a transformation
std be the column space

(˜x

x)(cid:62)θ(cid:63) = (Πstd(˜x

x) + Π⊥

std(˜x

−
= 0, then for any choice of nullspace component Π⊥

−

−

x))(cid:62)θ(cid:63) = 0

which implies that as long as Π⊥
stdXstd), there is a
choice of Πstd ˜x which satisﬁes the condition. Thus, we consider augmented points Xext with arbitrary components in the
nullspace of Xstd.

Null(X (cid:62)

std(˜x)

stdθ(cid:63)

∈

B.3. Proof of Theorem 1

Inequality (8) follows from

Lstd(ˆθaug)

−

Lstd(ˆθstd) = (θ(cid:63)
−
= (Π⊥
augθ(cid:63))(cid:62)ΣΠ⊥
= w(cid:62)Σw

ˆθaug)(cid:62)Σ(θ(cid:63)
−
augθ(cid:63)

−
(w + v)(cid:62)Σ(w + v)

ˆθaug)
(Π⊥

(θ(cid:63)
−
stdθ(cid:63))(cid:62)ΣΠ⊥

ˆθstd)(cid:62)Σ(θ(cid:63)
stdθ(cid:63)

−

ˆθstd)

−

−
2w(cid:62)Σv

=

−

v(cid:62)Σv

−

by decomposition of Π⊥
with

θ(cid:63)
(cid:107)

2, although the sign of the difference does not.
(cid:107)

stdθ(cid:63) = v + w where v = Π⊥

stdΠaugθ(cid:63) and w = Π⊥

stdΠ⊥

augθ(cid:63). Note that the error difference does scale

B.4. Proof of Corollary 1
Corollary 1 presents three sufﬁcient conditions under which the standard error of the augmented estimator Lstd(ˆθaug) is never
larger than the standard error of the standard estimator Lstd(ˆθstd).

1. When the population covariance Σ = I, from Theorem 1, we see that

since v = Π⊥

stdΠaugθ(cid:63) and w = Π⊥

Lstd(ˆθstd)

Lstd(ˆθaug) = v(cid:62)v + 2w(cid:62)v = v(cid:62)v

0,

≥

−
augθ(cid:63) are orthogonal.

(12)

(13)

(14)

(15)

(16)

(17)

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

2. When Π⊥

aug = 0, the vector w in Theorem 1 is 0, and hence we get

Lstd(ˆθstd)

Lstd(ˆθaug) = v(cid:62)v

−

0.

≥

(18)

3. We prove the eigenvector condition in Section B.7 which studies the effect of augmenting with a single extra point in

general.

B.5. Proof of Proposition 1

The proof of Proposition 1 is based on the following two lemmas that are also useful for characterization purposes in
Corollary 2.

Lemma 1. If a PSD matrix Σ has non-equal eigenvalues, one can ﬁnd two unit vectors w, v for which the following holds

w(cid:62)v = 0

and

w(cid:62)Σv

= 0

(19)

Hence, there exists a combination of original and augmentation dataset Xstd, Xext such that condition (19) holds for two
directions v

Col(Π⊥

Col(Π⊥

stdΠ⊥

aug) = Col(Π⊥

aug).

stdΠaug) and w

∈

∈

Note that neither w nor v can be eigenvectors of Σ in order for both conditions in equation (19) to hold. Given a population
covariance, ﬁxed original and augmentation data for which condition (19) holds, we can now explicitly construct θ(cid:63) for
which augmentation increases standard error.

Lemma 2. Assume Σ, Xstd, Xext are ﬁxed. Then condition (19) holds for two directions v
aug) iff there exists a θ(cid:63) such that Lstd(ˆθaug)
Col(Π⊥
needs to satisfy the following lower bounds with c1 :=

stdΠ⊥

≥
ˆθstd

∈
∈
c for some c > 0. Furthermore, the (cid:96)2 norm of θ(cid:63)
2
(cid:107)

Lstd(ˆθstd)
−
ˆθaug
2
(cid:107)
(cid:107)

stdΠaug) and w

− (cid:107)

Col(Π⊥

θ(cid:63)

2

(cid:107)

(cid:107)

− (cid:107)

ˆθaug

θ(cid:63)
(cid:107)

2
(cid:107)

− (cid:107)

ˆθstd

2
(cid:107)

2
(cid:107)

≥

≥

β1c1 + β2

c2
c1

(β1 + 1)c1 + β2

c2
c1

(20)

where βi are constants that depend on Xstd, Xext, Σ.

Proposition 1 follows directly from the second statement of Lemma 2 by minimizing the bound (20) with respect to c1
which is a free parameter to be chosen during construction of θ(cid:63) (see proof of Lemma (2). The minimum is attained for
c1 = 2(cid:112)(β1 + 1)(β2c2). We hence conclude that θ(cid:63) needs to be sufﬁciently more complex than a good standard solution,
i.e.

2
2 > γc where γ > 0 is a constant that depends on the Xstd, Xext.
(cid:107)

2
2 − (cid:107)
(cid:107)

θ(cid:63)
(cid:107)

ˆθstd

In this section we prove the technical lemmas that are used to prove Theorem 1.

B.6. Proof of technical lemmas

B.6.1. PROOF OF LEMMA 2

stdθ

Any vector Π⊥
Null(Σstd) can be decomposed into orthogonal components Π⊥
the minimum-norm property, we can then always decompose the (rotated) augmented estimator ˆθaug
Col(Π⊥

aug) and true parameter θ(cid:63) by

stdθ = Π⊥

stdΠ⊥

stdΠ⊥

∈

augθ + Π⊥

∈

stdΠaugθ. Using
Col(Π⊥
aug) =

ˆθaug = ˆθstd +

(cid:88)

ζivi

θ(cid:63) = ˆθaug +

ξjwj,

vi∈ext
(cid:88)

wj ∈rest

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

where we deﬁne “ext” as the set of basis vectors which span Col(Π⊥
the standard error increase to be some constant c > 0 can be rewritten using identity (16) as follows

stdΠaug) and respectively “rest” for Null(Σaug). Requiring

Lstd(ˆθaug)

Lstd(ˆθstd) = c

ζivi)(cid:62)Σ(

ζivi) + c =

2(

(cid:88)

ξjwj)Σ(

ζivi)

(cid:88)

(cid:88)

(
vi∈ext
(cid:88)

(

vi∈ext

⇐⇒

⇐⇒

−
(cid:88)

vi∈ext
(cid:88)

vi∈ext

ζivi)(cid:62)Σ(

ζivi) + c =

−

2

−

wj ∈rest
(cid:88)

vi∈ext
ξjζiw(cid:62)

j Σvi

wj ∈rest,vi∈ext

The left hand side of equation (21) is always positive, hence it is necessary for this equality to hold with any c > 0, that
there exists at least one pair i, j such that w(cid:62)

= 0 and one direction of the iff statement is proved.

j Σvi

For the other direction, we show that if there exist v
(wlog we assume that the w(cid:62)Σv < 0) we can construct a θ(cid:63) for which the inequality (8) in Theorem 1 holds as follows:

aug) for which condition (19) holds

stdΠaug) and w

∈

∈

Col(Π⊥

stdΠ⊥

Col(Π⊥

It is then necessary by our assumption that ξjζiw(cid:62)
ˆθaug
(cid:107)
there can be no difference in error and equality (21) cannot be satisﬁed for any desired error increase c > 0).

j Σvi > 0 for at least some i, j. We can then set ζi > 0 such that
2 = c1 > 0, i.e. that the augmented estimator is not equal to the standard estimator (else obviously
(cid:107)

2 =
(cid:107)

ˆθstd

ζ
(cid:107)

−

The choice of ξ minimizing
j that also satisﬁes equation (21) is an appropriately scaled vector in the
direction of x = W (cid:62)ΣV ζ where we deﬁne W := [w1, . . . , w|rest|] and V := [v1, . . . , v|ext|]. Deﬁning c0 = ζ (cid:62)V (cid:62)ΣV ζ for
convenience and then setting

−

θ(cid:63)
(cid:107)

ˆθaug

2 = (cid:80)
(cid:107)

j ξ2

which is well-deﬁned since x
Lstd(ˆθstd) = c that
Lstd(ˆθaug)

−

= 0, yields a θ(cid:63) such that augmentation increases standard error. It is thus necessary for

ξ =

c0 + c
2
x
2
2
(cid:107)
(cid:107)

x

−

(21)

(22)

(cid:88)

ξ2
j =

j

(c0 + c)2
W (cid:62)ΣV ζ
4
(cid:107)

(cid:107)

2 =

(ζ (cid:62)V (cid:62)ΣV ζ + c)2
4ζ (cid:62)V (cid:62)ΣW W (cid:62)ΣV ζ

(ζ (cid:62)V (cid:62)ΣV ζ)2
4ζ (cid:62)V (cid:62)ΣW W (cid:62)ΣV ζ
λ2
min(V (cid:62)ΣV )
c1
max(W (cid:62)ΣV )
λ2
4

+

≥

≥

+

c2
4ζ (cid:62)V (cid:62)ΣW W (cid:62)ΣV ζ

c2

4c1λ2

max(W (cid:62)ΣV )

.

By assuming existence of i, j such that ξjζiw(cid:62)

= 0, we are guaranteed that λ2

max(W (cid:62)ΣV ) > 0.

Note due to construction we have
have

θ(cid:63)
(cid:107)

2
2 =
(cid:107)

j Σvi
ˆθstd
(cid:107)

2 + (cid:80)
2
(cid:107)

i ζ 2

i + (cid:80)

j ξ2

j and plugging in the choice of ξj in equation (22) we

θ(cid:63)

2
2 − (cid:107)

(cid:107)

(cid:107)

ˆθstd

2
2 ≥

(cid:107)

(cid:20)

c1

1 +

λ2
min(V (cid:62)ΣV )
max(W (cid:62)ΣV )
4λ2

(cid:21)

+

c2
max(W (cid:62)ΣV )

1
c1

.

4λ2

Setting β1 =

(cid:104)
1 + λ2
4λ2

min(V (cid:62)ΣV )
max(W (cid:62)ΣV )

(cid:105)

, β2 =

max(W (cid:62)ΣV ) yields the result.

4λ2

1

B.6.2. PROOF OF LEMMA 1

Let λ1, . . . , λm be the m non-zero eigenvalues of Σ and ui be the corresponding eigenvectors. Then choose v to be any
combination of the eigenvectors v = U β where U = [u1, . . . , um] where at least βi, βj
= λj. We next construct
w = U α by choosing α as follows such that the inequality in (19) holds:

= 0 for λi

αi =

βj
i + β2
β2
j
βi
i + β2
β2
j

αj = −

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

and αk = 0 for k

= i, j. Then we have that α(cid:62)β = 0 and hence w(cid:62)v = 0. Simultaneously

w(cid:62)Σv = λiβiαi + λjβjαj
βiβj
i + β2
β2
j (cid:54)

= (λi

λj)

−

= 0

which concludes the proof of the ﬁrst statement.

We now prove the second statement by constructing Σstd = X (cid:62)
extXext using w, v. We can then obtain
Xstd, Xext using any standard decomposition method to obtain Xstd, Xext. We construct Σstd, Σext using w, v. Without loss
of generality, we can make them simultaneously diagonalizable. We construct a set of eigenvectors that is the same for
both matrices paired with different eigenvalues. Let the shared eigenvectors include w, v. Then if we set the corresponding
eigenvalues λw(Σext) = 0, λv(Σext) > 0 and λw(Σstd) = 0, λv(Σstd) = 0, then λw(Σaug) = 0 such that w
aug)
stdΠaug). This shows the second statement. With this, we can design a θ(cid:63) for which augmentation increases
and v
standard error as in Lemma 2.

stdXstd, Σext = X (cid:62)

Col(Π⊥

Col(Π⊥

stdΠ⊥

∈

∈

B.7. Characterization Corollary 2

A simpler case to analyze is when we only augment with one extra data point. The following corollary characterizes which
single augmentation directions lead to higher prediction error for the augmented estimator.

Corollary 2. The following characterizations hold for augmentation directions that do not cause the standard error of the
augmented estimator to be higher than the original estimator.

(a) (in terms of ratios of inner products) For a given θ(cid:63), data augmentation does not increase the standard error of the

augmented estimator for a single augmentation direction xext if

extΠ⊥
stdΣΠ⊥
x(cid:62)
extΠ⊥
x(cid:62)
stdxext

stdxext

2

(Π⊥

stdxext)(cid:62)ΣΠ⊥
extΠ⊥
x(cid:62)

stdθ(cid:63)

stdθ(cid:63)

−

0

≤

(23)

(b) (in terms of eigenvectors) Data augmentation does not increase standard error for any θ(cid:63) if Π⊥

stdxext is an eigenvector
of Σ. However if one augments in the direction of a mixture of eigenvectors of Σ with different eigenvalues, there exists
θ(cid:63) such that augmentation increases standard error.

(c) (depending on well-conditioning of Σ) If λmax(Σ)

2 and Π⊥

stdθ(cid:63) is an eigenvector of Σ, then no augmentations xext

increase standard error.

λmin(Σ) ≤

The form in Equation (23) compares ratios of inner products of Π⊥
stdθ(cid:63) in two spaces: the one in the numerator is
weighted by Σ whereas the denominator is the standard inner product. Thus, if Σ scales and rotates rather inhomogeneously,
then augmenting with xext may hurt standard error. Here again, if Σ = γI for γ > 0, then the condition must hold.

stdxext and Π⊥

B.7.1. PROOF OF COROLLARY 2 (A)

Note that for a single augmentation point Xext = x(cid:62)
Col(Π⊥
then yields the following condition for safe augmentations:

stdΠaug) is deﬁned by v = Π⊥

(cid:62)θ(cid:63)
stdxext
stdxext(cid:107)2 Π⊥

stdxext and w = Π⊥

(cid:107)Π⊥

stdθ(cid:63)

−

ext, the orthogonal decomposition of Π⊥

aug) and
v respectively. Plugging back into into identity (16)

stdθ(cid:63) into Col(Π⊥

2(v
−
v(cid:62)Σv

Π⊥

stdθ(cid:63))(cid:62)Σv
2(Π⊥

stdθ(cid:63))(cid:62)Σv

−

−
(cid:62)
stdxext

Π⊥

⇐⇒

ΣΠ⊥

stdxext

≤

0

≤

v(cid:62)Σv

0

≤
2(Π⊥

stdθ(cid:63))(cid:62)ΣΠ⊥

stdxext

Π⊥

stdxext
stdxext

2
(cid:107)
(cid:62)θ(cid:63)

(cid:107)
Π⊥

·

(24)

Rearranging the terms yields inequality (23).

Safe augmentation directions for speciﬁc choices of θ(cid:63) and Σ are illustrated in Figure 3.

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

B.7.2. PROOF OF COROLLARY 2 (B)

Assume that Π⊥

stdxext is an eigevector of Σ with eigenvalue λ > 0. We have

stdΣΠ⊥
extΠ⊥
x(cid:62)
extΠ⊥
x(cid:62)
stdxext

stdxext

2

(Π⊥

stdxext)(cid:62)ΣΠ⊥
extΠ⊥
x(cid:62)

stdθ(cid:63)

stdθ(cid:63)

−

=

λ < 0

−

for any θ(cid:63). Hence by Corollary 2 (a), the standard error doesn’t increase by augmenting with eigenvectors of Σ for any θ(cid:63).

When the single augmentation direction v is not an eigenvector of Σ, by Lemma 1 one can ﬁnd w such that w(cid:62)Σv
= 0. The
proof in Lemma 1 gives an explicit construction for w such that condition (19) holds and the result then follows directly by
Lemma 2.

B.7.3. PROOF OF COROLLARY 2 (C)

Suppose ΣΠ⊥

stdθ(cid:63) = λΠ⊥

stdθ(cid:63) for some λmin(Σ)

λ

λmax(Σ). Then starting with the expression (23),

stdΣΠ⊥
extΠ⊥
x(cid:62)
extΠ⊥
x(cid:62)
stdxext

stdxext

−

≤
(Π⊥

≤
stdxext)(cid:62)ΣΠ⊥
extΠ⊥
x(cid:62)

stdθ(cid:63)

2

stdθ(cid:63)

stdxext

stdΣΠ⊥
extΠ⊥
x(cid:62)
extΠ⊥
x(cid:62)
stdxext
λmax(Σ)

−
2λ < 0

2λ

−

=

≤

2. Thus when Π⊥

stdθ(cid:63) is an eigenvector of Σ, there are no augmentations xext that increase the

by applying λmax(Σ)
standard error.

λmin(Σ) ≤

C. Details for spline staircase

C.1. True model

We consider a ﬁnite input domain

We describe the data distribution, augmentations, and model details for the spline experiment in Figure 1 and toy scenario in
Figure 2. Finally, we show that we can construct a simpliﬁed family of spline problems where the ratio between standard
errors of the augmented and standard estimators increases unboundedly as the number of stairs.

0, (cid:15), 1, 1 + (cid:15), . . . , s
{
for some integer s corresponding to the total number of “stairs” in the staircase problem. Let
We deﬁne the underlying function f (cid:63) : R
restricted to

R as f (cid:63)(t) =

1 + (cid:15)
}

1, s

(cid:55)→

−

−

=

T

(cid:99)

(cid:98)

t

1
.
}
T
. This function takes a staircase shape, and is linear when

0, 1, . . . , s
{

⊂ T

−

=

line

(25)

line.

T

Sampling training data Xstd We describe the data distribution in terms of the one-dimensional input t, and by the
one-to-one correspondence with spline basis features x = X(t), this also deﬁnes the distribution of spline features x
.
∈ X
line where ∆s is the probability simplex of dimension s. We deﬁne the data
Let w
distribution with the following generative process for one sample t. First, sample a point i from
line according to the
Categorical(w). Second, sample t by perturbing i with probability δ
categorical distribution described by w, such that i
such that

∆s deﬁne a distribution over

∼

∈

T

T

(cid:40)

t =

i
w.p. 1
i + (cid:15) w.p. δ.

−

δ

The sampled t is in

line with probability 1

δ and

c
line with probability δ, where we choose δ to be small.

T

−

T
Sampling augmented points Xext For each element ti in the training set, we augment with ˜Ti = [uu.a.r
B(ti)], an input
∼
ti
chosen uniformly at random from B(ti) =
. Recall that in our work, we consider data augmentation where
the targets associated with the augmented points are from the ground truth oracle. Notice that by deﬁnition, f (cid:63)(˜ti) = f (cid:63)(ti)
for all ˜t
B(ti), and thus we can set the augmented targets to be ˜yi = yi. This is similar to random data augmentation in
images (Yaeger et al., 1996; Krizhevsky et al., 2012), where inputs are perturbed in a way that preserves the label.

+ (cid:15)

{(cid:98)

ti

∈

}

(cid:98)

(cid:99)

(cid:99)

,

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

(a) Augment with x = Φ(3.5)

(b) Augment with x = Φ(4.5)

Figure 7. Visualization of the effect of single augmentation points in the noiseless spline problem given an initial dataset Xstd = {Φ(t) :
t ∈ {0, 1, 2, 3, 4}}. The standard estimator deﬁned by Xstd is linear. (a) Plot of the difference term in Corollary 2 (a), is positive when
augmenting a single point causes higher test error. Augmenting with points on Xline does not affect the bias, but augmenting with any
element of {X(t) : t ∈ {2.5, 3.5, 4.5}} hurts the bias of the augmented estimator dramatically. (b), (c) Augmenting with X(3.5) or
X(4.5) hurts the bias by changing the direction of extrapolation.

C.2. Spline model

We parameterize the spline predictors as fθ(t) = θ(cid:62)X(t) where X : R
Rd is the cubic B-spline feature mapping (Fried-
man et al., 2001) and the norm of fθ(t) can be expressed as θ(cid:62)M θ for a matrix M that penalizes a large second derivative
norm where [M ]ij = (cid:82) X
j (u)du. Notice that the splines problem is a linear regression problem from Rd to R in the
feature domain X(t), allowing direct application of Theorem 1. As a linear regression problem, we deﬁne the ﬁnite domain
containing 2s elements in Rd. There is a one-to-one correspondence between t and X(t), such that
as
X −1 is well-deﬁned. We deﬁne the features that correspond to inputs in
. Using this
}
feature mapping, there exists a θ(cid:63) such that fθ(cid:63) (t) = f (cid:63)(t) for t

x : X −1(x)
{

X(t) : t
{

i (u)X

line =

line as

∈ T }

∈ T

→

=

line

X

X

T

.

(cid:48)(cid:48)

(cid:48)(cid:48)

∈ T

Our hypothesis class is the family of cubic B-splines as deﬁned in (Friedman et al., 2001). Cubic B-splines are piecewise
cubic functions, where the endpoints of each cubic function are called the knots. In our example, we ﬁx the knots to be
[0, (cid:15), 1, . . . , s
. This ensures that the function class contains an
−
interpolating function on all t

1 + (cid:15)], which places a knot on every point in

, i.e. for some θ(cid:63),

1, s

−

T

∈ T

fθ(cid:63) (t) = θ(cid:63)(cid:62)X(t) = f (cid:63)(t) =

.

t
(cid:98)

(cid:99)

We solve the minimum norm problem

ˆθstd = arg min

θ(cid:62)M θ : Xstdθ = ystd

θ

{

}

(26)

for the standard estimator and the corresponding augmented problem to obtain the augmented estimator.

C.3. Evaluating Corollary 2 (a) for splines

{
∈ {

X(t) : t

0, 1, 2, 3, 4

∈ {
0, 1, 2, 3, 4
}

. Let local perturbations be spline features for ˜t /

We now illustrate the characterization for the effect of augmentation with different single points in Theorem 2 (a) on
as deﬁned in equation 25 with s = 10 and our training data to be
the splines problem. We assume the domain to
line where ˜t = t + (cid:15) is (cid:15) away from
Xstd =
some t
from the training set. We examine all possible single augmentation points in Figure 7 (a) and plot
the calculated standard error difference as deﬁned in equation (24). Figure 7 shows that augmenting with an additional point
X(t) : t
from
where
{
˜t /
line increases the error signiﬁcantly by changing the direction in which the estimator extrapolates. Particularly, local
augmentations near the boundary of the original dataset hurt the most while other augmentations do not signiﬁcantly affect
the bias of the augmented estimator.

does not affect the bias, but adding any perturbation point in

X(˜t) : ˜t
{

2.5, 3.5, 4.5

∈ T

∈ T

∈ T

∈ {

}}

}}

line

T

}

C.3.1. LOCAL AND GLOBAL STRUCTURE IN THE SPLINE STAIRCASE

In the spline staircase, the local perturbations can be thought of as ﬁtting high frequency noise in the function space, where
ﬁtting them causes a global change in the function.

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

Figure 8. Nullspace projections onto global direction q3 and local direction q2s in Null(Σ) via Πlg, representing global and local
eigenvectors respectively. The local perturbation Πlg ˆΦ(1.5) has both local and global components, creating a high-error component in the
global direction.

To see this, we transform the problem to minimum (cid:96)2 norm linear interpolation using features XM (t) = X(t)M −1/2 so
that the results from Section 3.2 apply directly. Let Σ be the population covariance of XM for a uniform distribution over
the discrete domain consisting of s stairs and their perturbations (Figure 2). Let Q = [qi]2s
i=1 be the eigenvectors of Σ in
decreasing order of their corresponding eigenvalues. The visualization in Figure 4 shows that qi are wave functions in the
original input space; the “frequency” of the wave increases as i increases.

stdq1 = Π⊥

Suppose the original training set consists of two points, Xstd = [XM (0), XM (1)](cid:62). We study the effect of augmenting
point xext in terms of qi above. First, we ﬁnd that the ﬁrst two eigenvectors corresponding to linear functions satisfy
Π⊥
stdq2 = 0. Intuitively, this is because the standard estimator is linear. For ease of visualization, we consider the
2D space in Null(Σ) spanned by Π⊥
stdq2s (local direction, high frequency). The
matrix Πlg = [Π⊥
stdqi in
Null(Σ).

stdq2s](cid:62) projects onto this space. Note that the same results hold when projecting onto all Π⊥

stdq3 (global direction, low frequency) and Π⊥

stdq3, Π⊥

In terms of the simple 3-D example in Section 3.1, the global direction corresponds to the costly direction with large
eigenvalue, as changes in global structure heavily affect the standard error. Figure 8 plots the projections Πlgθ(cid:63) and ΠlgXext
ˆθstd) is aligned with the local
for different Xext. When θ(cid:63) has high frequency variations and is complex, Πlgθ(cid:63) = (θ(cid:63)
dimension. For xext immediately local to training points, the projection Πlgxext (orange vector in Figure 8) has both local
and global components. Augmenting these local perturbations introduces error in the global component. For other xext
ˆθstd, leaving
farther from training points, Πlgxext (blue vector in Figure 8) is almost entirely global and perpendicular to θ(cid:63)
bias unchanged. Thus, augmenting data close to original data cause estimators to ﬁt local components at the cost of the
costly global component which changes overall structure of the predictor like in Figure 2(middle). The choice of inductive
bias in the M –norm being minimized results in eigenvectors of Σ that correspond to local and global components, dictating
this tradeoff.

−

−

C.4. Data augmentation can be quite painful for splines

We construct a family of spline problems such that as the number the augmented estimator has much higher error than the
standard estimator. We assume that our predictors are from the full family of cubic splines.

s−1
t=0 [t, t + (cid:15)]. Considering only s
Sampling distribution. We deﬁne a modiﬁed domain with continuous intervals
which is a multiple of 2, we sample the original data set as described in Section C.1 with the following probability mass w:

=

∪

T

w(t) =

(cid:40) 1−γ
s/2
γ
s/2

t < s/2, t

t

s/2, t

∈ T

line
line.

∈ T

≥
for a random variable T by setting T = Z + S(Z) where

(27)

(28)

for γ
Z

[0, 1). We deﬁne a probability distribution PT on

∈
Categorical(w) and the Z-dependent perturbation S(z) is deﬁned as

T

∼

We obtain the training dataset Xstd =

X(t1), . . . , X(tn)
}
{

by sampling ti

∼

(cid:40)

S(z)

∼

Uniform([z, z + (cid:15)])
z,

w.p. δ
w.p. 1

δ.

−
PT .

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

Augmenting with an interval. Consider a modiﬁed augmented estimator for the splines problem, where for each point ti
ti
we augment with the entire interval [
(cid:99)
(cid:98)
for all x in the interval [
+ (cid:15)]. Additionally, suppose that the ratio s/n = O(1) between the number of stairs s and
(cid:98)
the number of samples n is constant.

[0, 1/2) and the estimator is enforced to output fˆθ(x) = yi =

+(cid:15)] with (cid:15)

ti

ti

ti

ti

∈

(cid:98)

(cid:99)

(cid:99)

(cid:99)

(cid:99)

(cid:98)

(cid:98)

,

,

In this simpliﬁed setting, we can show that the standard error of the augmented estimator grows while the standard error of
the standard estimator decays to 0.
Theorem 3. Let the setting be deﬁned as above. Then with the choice of δ = log(s7)−log(s7−1)
c

[0, 1), the ratio between standard errors is lower bounded as

and γ = c/s for a constant

s

∈

R(ˆθaug)
R(ˆθstd)

= Ω(s2)

(29)

which goes to inﬁnity as s

. Furthermore, R(ˆθstd)

→ ∞

0 as s

.
→ ∞

→

Proof. We ﬁrst lower bound the standard error of the augmented estimator. Deﬁne E1 as the event that only the lower
half of the stairs is sampled, i.e.
be the largest
“stair” value seen in the training set. Note that the min-norm augmented estimator will extrapolate with zero derivative for
. This is because on the interval [t(cid:63), t(cid:63) + (cid:15)], the augmented estimator is forced to have zero derivative, and the
t
t(cid:63). In the event E1,
solution minimizing the second derivative of the prediction continues with zero derivative for all t
t(cid:63)
1 achieves the lowest error in this event. As a result, on the points in the second half of the
staircase, i.e. t =

(cid:99)
1, where t∗ = s/2

, which occurs with probability (1

γ)n. Let t(cid:63) = maxi

t : t < s/2
}
{

maxi

ti
(cid:98)

s/2

≥

−

−

≤

≥

ti

1

(cid:98)

(cid:99)

, the augmented estimator incurs large error:
}

t
{

∈ T

−
: t > s
2 −

R(ˆθaug

E1)

|

s
(cid:88)

t=s/2

(t

(s/2

1))2

−

γ
s/2

·

≥

=

s/2
(cid:88)

t=1

t2

γ
s/2

·

−

γ
6

=

(s2 + 2s + 1).

Therefore the standard error of the augmented estimator is bounded by

R(ˆθaug)

R(ˆθaug

E1)P (E1) =

(s2 + 2s + 1)(1

γ)n

≥

|

−

γ
6
1
6

≥

= Ω(

−
c2

c

−
s

γ(1

γn)(s2 + 2s + 1)

(s2 + 2s + 1)) = Ω(s)

γ

s/2 .

s/2 = γ

where in the ﬁrst line, we note that the error on each interval is the same and the probability of each interval is (1
(cid:15) δ
(cid:15) ·
Next we upper bound the standard error of the standard estimator. Deﬁne E2 to be the event where all points are sampled
from
line
with zero error, while incurring error for all points not in
line. Note that the probability density of sampling a point not in
γ
line is either δ

δ)n. In this case, the standard estimator is linear and ﬁts the points on

line, which occurs with probability (1

−
T
s/2 , which we upper bound as δ
(cid:15) ·

s/2 or δ
(cid:15) ·

1
s/2 .

s/2 +

(cid:15) ·

1−γ

−

T

T

T

δ) γ

R(ˆθstd

E2) =

|

s−1
(cid:88)

t=1

δ
(cid:15) ·

1
s/2

(cid:90) (cid:15)

0

u2du =

δ
(cid:15) ·

1
s/2

O(s(cid:15)3)

= O(δ)

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

Therefore for event E2, the standard error is bounded as

R(ˆθstd

|

E2)P (E2) = O(δ)(1

δ)n

−
= O(δ)e−δn

= O(δ

s7

1

)

−
s7

·

= O(δ) = O(

log(s7)

−

log(s7
s

1)

−

) = O(1/s)

since log(s7)
≥
only as O(t3), with error at most O(t6). Therefore the standard error for case Ec

2. For the complementary event Ec

log(s7

1 for s

1)

−

≤

−

2 is bounded as

2, note that cubic spline predictors can grow

R(ˆθstd

Ec

2)P (Ec
2)

|

O(t6)(1

≤
= O(t6)O(

e−δn)

−
1
s7 ) = O(1/s)

Putting the parts together yields

R(ˆθstd) = R(ˆθstd

E2)P (E2) + R(ˆθstd

2)P (Ec
2)
O(1/s) + O(1/s) = O(1/s).

Ec

|

|

≤

Thus overall, R(ˆθstd) = O(1/s) and combining the bounds yields the result.

D. Robust Self-Training

We deﬁne the linear robust self-training estimator from Equation (11) and expand all the terms.

(cid:110)
EPx[(x(cid:62)θint-std

ˆθrst

arg min
θ

∈
Xstdθ = ystd, max

xadv∈T (x)

x(cid:62)θ)2] :

−

y)2 = 0

x, y

Xstd, ystd,

∀

∈

(x(cid:62)

advθ

−
x(cid:62)θ)2] = 0

(cid:111)
.

EPx[ max

xadv∈T (x)

(x(cid:62)

advθ

−

(30)

(31)

Notice that for unlabeled components of the estimator, we assume access to the data distribution Px and thus optimize the
population quantities.

As we show in the next subsection, we can rewrite the robust self-training estimator into the following reduced form, more
directly connecting to the general analysis of adding extra data Xext in min-norm linear regression.

ˆθrst

arg min
θ

∈

(cid:110)

(θ

−

θint-std)(cid:62)Σ(θ

θint-std) : Xstdθ = ystd, Xextθ = 0

(cid:111)

−

for the appropriate choice of Xext, as shown in Section D.1. Here, we can interpret Xext as the difference between the
perturbed inputs and original inputs. These are perturbations which we want the model to be invariant to, and hence output
zero.

D.1. Robust self-training algorithm in linear regression

We give an algorithm for constructing Xext which enforces the population robustness constraints. Suppose we are given Σ,
the population covariance of Px. In robust self-training, we enforce that the model is consistent over perturbations of the
x(cid:62)θ = 0, where
labeled data Xstd and (inﬁnite) unlabeled data. To do this, we add linear constraints of the form x(cid:62)
xadv
T (x) for all x. We can view these linear constraints as augmenting the dataset with input-target pairs (xext, 0) where
∈
xext = xadv

extθ(cid:63) = 0 so these augmentations ﬁt into our data augmentation framework.

x. By assumption, x(cid:62)

advθ

−

−

However, when we enforce these constraints over the entire population Px or when there are an inﬁnite number of
transformations in T (x), a naive implementation requires augmenting with inﬁnitely many points. Noting that the space of

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

augmentations xext satisfying x(cid:62)
extθ(cid:63) = 0 is a linear subspace, we can instead summarize the augmentations with a basis
x. Note that this space of
that spans the transformations. Let the space of perturbations be
perturbations also contains perturbations of the original data Xstd if Xstd is in the support of Px. If Xstd is not in the support
of Px, the behavior of the estimator on these points do not affect standard or robust error. Assuming that we can efﬁciently
optimize over

, we construct the basis by an iterative procedure reminiscent of adversarial training.

∪x∈supp(Px),xadv∈T (x)xadv

=

−

T

T

1. Set t = 0. Initialize θt = θint-std and (Xext)0 as an empty matrix.

2. At iteration t, solve for xt

ext = arg maxxext∈T (x(cid:62)

extθt)2. If the objective is unbounded, choose any xt

ext such that

= 0.

extθt
x(cid:62)
3. If θt(cid:62)xt

ext = 0, stop and return (Xext)t.

5. Return to step 2.

4. Otherwise, add xt

ext as a row in (Xext)t. Increment t and let θt solve (31) with Xext = (Xext)t.

. The ﬁnal RST estimator solves (31) using Xext returned from this procedure.

In each iteration, we search for a perturbation that the current θt is not invariant to. If we can ﬁnd such a perturbation, we
add it to the constraint set in (Xext)t. We stop when we cannot ﬁnd such a perturbation, implying that the rows of (Xext)t
and Xstd span
This procedure terminates within O(d) iterations. To see this, note that θt is orthogonal to all rows of (Xext)t. Any vector
in the span of (Xext)t is orthogonal to θt. Thus, if θt(cid:62)xt
ext must not be in the span of (Xext)t. At most
ext = 0 must hold
d
and the algorithm terminates.

rank(Xstd) such new directions can be added until (Xext)t is full rank. When (Xext)t is full rank, θt(cid:62)xt

= 0, then xt

−

ext

T

D.2. Proof of Theorem 2

In this section, we prove Theorem 2, which we reproduce here.
Theorem 2. Assume the noiseless linear model y = x(cid:62)θ(cid:63). Let θint-std be an arbitrary interpolant of the standard data, i.e.
Xstdθint-std = ystd. Then

Simultaneously, Lrob(ˆθrst) = Lstd(ˆθrst).

Lstd

(cid:0)ˆθrst)

≤

Lstd(θint-std).

Proof. We work with the RST estimator in the form from Equation (31). We note that our result applies generally to any
extra data Xext, yext. We deﬁne Σstd = X (cid:62)
extXext) and
i uiwi
be an orthonormal basis for Null(Σstd)
vi
{
and V w = (cid:80)
stdΣstd) to be the projection onto the null
space of Xstd, we see that there are unique vectors ρ, α such that

be an orthonormal basis of the kernel Null(Σstd + X (cid:62)
}
). Let U and V be the linear operators deﬁned by U w = (cid:80)
}

i viwi, respectively, noting that U (cid:62)V = 0. Deﬁning Π⊥

stdXstd. Let
ui
{
ui
span(
{

std := (I

Σ†

−

}

\

As θint-std interpolates the standard data, we also have

as XstdU w = XstdV z = 0, and ﬁnally,

where we note the common ρ between Eqs. (32a) and (32c).

θ(cid:63) = (I

Π⊥

std)θ(cid:63) + U ρ + V α.

θint-std = (I

Π⊥

std)θ(cid:63) + U w + V z,

ˆθrst = (I

Π⊥

std)θ(cid:63) + U ρ + V λ

−

−

−

(32a)

(32b)

(32c)

Using the representations (32) we may provide an alternative formulation for the augmented estimator (30), using this to
λ), we immediately have that the estimator has the
prove the theorem. Indeed, writing θint-std
form (32c), with the choice

ˆθrst = U (w

ρ) + V (z

−

−

−

λ = arg min

(cid:8)(U (w

ρ) + V (z

λ))(cid:62)Σ(U (w

ρ) + V (z

λ

−

−

−

λ))(cid:9) .

−

(33)

(34)

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

The optimality conditions for this quadratic imply that

Now, recall that the standard error of a vector θ is R(θ) = (θ
notation. In particular, a few quadratic expansions yield

−

θ(cid:63)) =

θ
(cid:107)

−

(cid:107)

−

θ(cid:63)

2
Σ, using Mahalanobis norm

V (cid:62)ΣV (λ

z) = V (cid:62)ΣU (w

ρ).

−

−
θ(cid:63))(cid:62)Σ(θ

R(θint-std)

=

=

(i)
=

=

U (w
(cid:107)
U (w
(cid:107)

U (w
(cid:107)
U (w
(cid:107)

−

−

−

−

−

R(ˆθrst)
ρ) + V (z

ρ) + V z

(cid:107)
ρ) + V z

ρ) + V z

2
Σ

α)
(cid:107)

−
2(U (w

−
V λ

− (cid:107)

(cid:107)

α)

V (λ

2
Σ − (cid:107)
(cid:107)
−
2
2
V α
Σ +
Σ −
(cid:107)
2
2(V λ)(cid:62)ΣV α
Σ −
(cid:107)
2
2
Σ ,
Σ − (cid:107)
(cid:107)
(cid:107)
ρ))(cid:62)ΣV = (V (λ

V λ

−

−

ρ) + V z)(cid:62)ΣV α

V λ

2
Σ − (cid:107)
(cid:107)

V α

2
Σ + 2(V λ)(cid:62)ΣV α
(cid:107)

− (cid:107)

2
Σ + 2(V λ)(cid:62)V α
(cid:107)

where step (i) used that (U (w

z))(cid:62)ΣV from the optimality conditions (33).

Finally, we consider the rightmost term in equality (34). Again using the optimality conditions (33), we have

2
Σ = λ(cid:62)V (cid:62)Σ1/2Σ1/2(U (w
(cid:107)
by Cauchy-Schwarz. Revisiting equality (34), we obtain

V λ

(cid:107)

−

ρ) + V z)

V λ

U (w

ρ) + V z

≤ (cid:107)

(cid:107)Σ (cid:107)

−

(cid:107)Σ

R(θint-std)

R(ˆθrst) =

U (w

ρ) + V z

−

(cid:107)

−

−

U (w

ρ) + V z

≥ (cid:107)

V λ
(cid:107)
V λ

V λ

(cid:107)

(cid:107)

4
Σ
(cid:107)
2
Σ
(cid:107)
2
Σ (cid:107)
(cid:107)

2
Σ −
(cid:107)

2
Σ −
(cid:107)

U (w

ρ) + V z
−
2
Σ
(cid:107)

V λ
(cid:107)

2
Σ
(cid:107)

= 0,

as desired.
Finally, we show that Lstd(ˆθrst) = Lrob(ˆθrst). Here, choose Xext to contain at most d basis vectors which span
T (x),
supp(Px)
}
By ﬁtting Xext, we thus have x(cid:62)
adv
the robust error is

∈
x(cid:62) ˆθrst)] = 0 is satisﬁed by ﬁtting Xext.
. Thus, the robustness constraint EPx[maxxadv∈T (x)(x(cid:62)
adv
x(cid:62) ˆθrst = 0 for all xadv
supp(Px) up to a measure zero set of x. Thus,

xadv : xadv
{

T (x), x

ˆθrst

ˆθrst

−

−

∈

∈

∈

x

∀

Lrob(ˆθrst) = EPx[ max

(x(cid:62)
adv

ˆθrst

advθ(cid:63))2] = EPx[(x(cid:62) ˆθrst
x(cid:62)

x(cid:62)θ)] = Lstd(ˆθrst)

xadv∈T (x)

−

−

where we used that x(cid:62)
lowest possible robust error (matching the standard error).

advθ(cid:63) = x(cid:62)θ(cid:63) by assumption. Since Lrob(ˆθrst)

≥

Lstd(ˆθrst), ˆθrst has perfect consistency, achieving the

D.3. Different instantiations of the general RST procedure

The general RST estimator (Equation 10) is simply a weighted combination of some standard loss and some robust loss
on the labeled and unlabeled data. Throughout, we assume the same notation as that used in the deﬁnition of the general
estimator. Xstd, ystd denote the standard training set and we have access to m unlabeled points ˜xi, i = 1, . . . m.

D.3.1. PROJECTED GRADIENT ADVERSARIAL TRAINING

In the ﬁrst variant, RST + PG-AT, we use multiclass logistic loss (cross-entropy) as the standard loss. The robust loss is the
maximum cross-entropy loss between any perturbed input (within the set of tranformations T (
)) and the label (pseudo-label
·
in the case of unlabeled data). We set the weights such that the estimator can be written as follows.

ˆθrst+pg-at := arg min

θ

(cid:26) 1

λ

−
n

(cid:88)

(x,y)∈[Xstd,ystd]

−

(1

β)(cid:96)(fθ(x), y) + β (cid:96)(fθ(xadv), y)

+

λ
m

m
(cid:88)

i=1

(1

−

β)(cid:96)(fθ(˜xi), fˆθstd

(˜xi)) + β (cid:96)(fθ(˜xadvi), fˆθstd

(˜xi))

(35)

(cid:27)

,

In practice, xadv is found by performing a few steps of projected gradient method on (cid:96)(fθ(x), y), and similarly ˜xadv by
performing a few steps of projected gradient method on (cid:96)(fθ(˜x), fˆθstd

(˜x)).

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

D.3.2. TRADES

TRADES (Zhang et al., 2019) was proposed as a modiﬁcation of the projected gradient adversarial training algorithm
of (Madry et al., 2018). The robust loss is deﬁned slightly differently–it -operates on the normalized logits, which can be
thought of as probabilities of different labels. The TRADES loss minimizes the maximum KL divergence between the
T (x). Setting the weights of the different loss of the general
probability over labels for input x and a perturbaed input ˜x
RST estimator (10) similar to RST+PG-AT above gives the following estimator.
(cid:26) (1

λ)

∈

(cid:88)

(cid:96)(fθ(x), y) + β KL(pθ(xadv)

pθ(x))

ˆθrst+trades := arg min

θ

−
n

(x,y)∈[Xstd,ystd]

+

λ
m

m
(cid:88)

i=1

(cid:96)(fθ(˜xi), fˆθstd

(˜xi)) + β KL(pθ(˜xadvi)

(36)

||

(cid:27)

pˆθstd
||

(˜xi))

.

In practice, xadv and ˜xadv are obtained by performing a few steps of projected gradient method on the respective KL
divergence terms.

E. Experimental Details

E.1. Spline simulations

E.2. RST experiments

E.2.1. SUBSAMPLING CIFAR-10

For spline simulations in Figure 2 and Figure 1, we implement the optimization of the standard and robust objectives
using the basis described in (Friedman et al., 2001). The penalty matrix M computes second-order ﬁnite differences of the
parameters θ. We solve the min-norm objective directly using CVXPY (Diamond & Boyd, 2016). Each point in Figure 1(a)
represents the average standard error over 25 trials of randomly sampled training datasets between 22 and 1000 samples.
Shaded regions represent 1 standard deviation.

We evaluate the performance of RST applied to (cid:96)∞ adversarial perturbations, adversarial rotations, and random rotations.

We augment with (cid:96)∞ adversarial perturbations of various sizes. In each epoch, we ﬁnd the augmented examples via
Projected Gradient Ascent on the multiclass logistic loss (cross-entropy loss) of the incorrect class. Training the augmented
estimator in this setup uses essentially the adversarial training procedure of (Madry et al., 2018), with equal weight on both
the ”clean” and adversarial examples during training.

We compare the standard error of the augmented estimator with an estimator trained using RST. We apply RST to adversarial
training algorithms in CIFAR-10 using 500k unlabeled examples sourced from Tiny Images, as in (Carmon et al., 2019).

We use Wide ResNet 40-2 models (Zagoruyko & Komodakis, 2016) while varying the number of samples in CIFAR-10.
We sub-sample CIFAR-10 by factors of
in Figure 1(b). We report
}
results averaged from 2 trials for each sub-sample factor. All models are trained for 200 epochs with respect to the size of
the labeled training dataset and all achieve almost 100% standard and robust training accuracy.

1, 2, 5, 8, 10, 20, 40

in Figure 1(a) and

1, 2, 5, 8, 10

{

{

}

We evaluate the robustness of models to the strong PGD-attack with 40 steps and 5 restarts. In Figure 1(b), we used a simple
heuristic to set the regularization strength on unlabeled data λ in Equation (35) to be λ = min(0.9, p) where p
[0, 1] is the
fraction of the original CIFAR-10 dataset sampled. We set β = 0.5. Intuitively, we give more weight to the unlabeled data
when the original dataset is larger, meaning that the standard estimator produces more accurate pseudo-labels.

∈

Figure 9 shows that the robust accuracy of the RST model improves about 5-15% percentage points above the robust model
(trained using PGD adversarial training) for all subsamples, including the full dataset (Tables 2,3).

We use a smaller model due to computational constraints enforced by adversarial training. Since the model is small, we
could only ﬁt adversarially augmented examples with small (cid:15) = 2/255, while existing baselines use (cid:15) = 8/255. Note that
even for (cid:15) = 2/255, adversarial data augmentation leads to an increase in standard error. We show that RST can ﬁx this.
While ensuring models are robust is an important goal in itself, in this work, we view adversarial training through the lens of
covariate-shifted data augmentation and study how to use augmented data without increasing standard error. We show that

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

(a) Robust error, CIFAR-10

(b) Relative standard error, CIFAR-10

Figure 9. (a) Difference in robust error between the RST adversarial training model and the vanilla adversarial training (AT) model for
CIFAR-10. RST improves upon the robust error of the AT model by approximately a 15% percentage point increase for small subsamples
and 5% percentage point increase for larger subsamples of CIFAR-10. (b) Relative difference in standard error between augmented
estimators (the RST model and the AT model) and the standard estimator on CIFAR-10. We achieve up to 20% better standard error than
the standard model for small subsamples.

Standard

AT

RST+AT

Standard Acc
Robust Acc ((cid:15) = 1/255)

94.63% 94.15% 95.58%
85.59% 88.74%

-

Table 2. Test accuracies for the standard, vanilla adversarial training (AT), and AT with RST for (cid:15) = 1/255 on the full CIFAR-10 dataset.
Accuracies are averaged over two trials. The robust accuracy of the standard model is near 0%.

RST preserves the other beneﬁts of some kinds of data augmentation like increased robustness to adversarial examples.

E.2.2. (cid:96)∞ ADVERSARIAL PERTURBATIONS

In Table 1, we evaluate RST applied to PGD and TRADES adversarial training. The models are trained on the full CIFAR-
10 dataset, and models which use unlabeled data (self-training and RST) also use 500k unlabeled examples from Tiny
Images. All models except the Interpolated AT and Neural Architecture Search model use the same base model WideResNet
28-10. To evaluate robust accuracy, we use a strong PGD-attack with 40 steps and 5 restarts against (cid:96)∞ perturbations of size
8/255. For RST models, we set β = 0.5 in Equation (35) and Equation (36), following the heuristic λ = min(0.9, p) with
p = 1 since we use the entire labeled trainign set. We train for 200 epochs such that 100% training standard accuracy is
attained.

E.2.3. ADVERSARIAL AND RANDOM ROTATION/TRANSLATIONS

In Table 1 (right), we use RST for adversarial and random rotation/translations, denoting these transformations as xadv in
10% of the image size.
Equation (35). The attack model is a grid of rotations of up to 30 degrees and translations of up to
The grid consists of 31 linearly spaced rotations and 5 linearly spaced translations in both dimensions. The Worst-of-10
model samples 10 uniformly random transformations of each input and augment with the one where the model performs the
worst (causes an incorrect prediction, if it exists). The Random model samples 1 random transformation as the augmented
input. All models (besides cited models) use the WRN-40-2 architecture and are trained for 200 epochs. We use the same
hyperparameters λ, β as in E.2.2 for Equation (35).

∼

F. Comparison to standard self-training algorithms

The main objective of RST is to allow to perform robust training without sacriﬁcing standard accuracy. This is done by
regularizing an augmented estimator to provide labels close to a standard estimator on the unlabeled data. This is closely
related to but different two broad kinds of semi-supervised learning.

1. Self-training (pseudo-labeling): Classical self-training does not deal with data augmentation or robustness. We view
RST as a a generalization of self-training in the context of data augmentations. Here the pseudolabels are generated
by a standard non-augmented estimator that is not trained on the labeled augmented points. In contrast, standard

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

Standard

AT

RST+AT

Standard Acc
Robust Acc ((cid:15) = 2/255)

94.63% 92.69% 95.15%
77.87% 83.50%

-

Table 3. Test accuracies for the standard, vanilla adversarial training (AT), and AT with RST for (cid:15) = 2/255 on the full CIFAR-10 dataset.
Accuracies are averaged over two trials. The robust test accuracy of the standard model is near 0%.

self-training would just use all labeled data to generate pseudo-labels. However, since some augmentations cause a
drop in standard accuracy, and hence this would generate worse pseudo-labels than RST.

2. Robust consistency training: Another popular semi-supervised learning strategy is based on enforcing consistency in a
model’s predictions across various perturbations of the unlabeled data (Miyato et al., 2018; Xie et al., 2019; Sajjadi
et al., 2016; Laine & Aila, 2017)). RST is similar in spirit, but has an additional crucial component. We generate
pseudo-labels ﬁrst by performing standard training, and rather than enforcing simply consistency across perturbations,
RST enforces that the unlabeled data and perturbations are matched with the pseudo-labels generated.

G. Minimum (cid:96)1-norm problem where data augmentation hurts standard error

We present a problem where data augmentation increases standard error for minimum (cid:96)1-norm estimators, showing that the
phenomenon is not special to minimum Mahalanobis norm estimators.

G.1. Setup in 3 dimensions

Deﬁne the minimum (cid:96)1-norm estimators

ˆθstd = arg min
θ
ˆθaug = arg min
θ

(cid:110)
θ
(cid:107)
(cid:110)
θ
(cid:107)

(cid:111)

1 : Xstdθ = ystd
(cid:107)
1 : Xstdθ = ystd, Xextθ = yext
(cid:107)

(cid:111)
.

We begin with a 3-dimensional construction and then increase the number of dimensions. Let the domain of possible values
be

where

x1, x2, x3

=

X

{

}

x1 = [1 + δ, 1, 0], x2 = [0, 1, 1 + δ], x3 = [1 + δ, 0, 1].

Deﬁne the data distribution through the generative process for the random feature vector x

x =






x1 w.p. 1
x2 w.p. (cid:15)
x3 w.p. p

p

(cid:15)

−

−

T (x) =

(cid:40)
{
{

x1, x2
x3

}

}

x
o.w.

∈ {

x1, x2

}

where 0 < δ < 1 and (cid:15) > 0. Deﬁne the optimal linear predictor θ(cid:63) = 1 to be the all-ones vector, such that in all cases,
x(cid:62)θ(cid:63) = 2 + δ. We deﬁne the consistent perturbations as

The augmented estimator will add all possible consistent perturbations of the training set as extra data Xext. For example, if
T (x1). The standard error is
x1 is in the training set, then the augmented estimator will add x2 as extra data since x2
measured by mean squared error.

∈

We give some intuition for how augmentation can hurt standard error in this 3-dimensional example. Deﬁne E1 to be the
event that we draw n samples with value x1. Given E1, the standard and augmented estimators are
(cid:20) 2 + δ
1 + δ

, ˆθaug = [0, 2 + δ, 0].

ˆθstd =

, 0, 0

(37)

(cid:21)

Understanding and Mitigating the Tradeoff Between Robustness and Accuracy

ˆθaug

(cid:62) ˆθaug

1 = 2 + δ > 2+δ
(cid:107)

(cid:62) ˆθaug = 0 in this case, the squared
Note that the ˆθaug has slightly higher norm (
(cid:107)
error of ˆθaug wrt to x3 is (x3
2 + δ)2 = (2 + δ)2. The standard estimator ﬁts x3 perfectly, but has high error on
x2. If the probability of E1 occurring is high and the probability of x3 is higher relative to x2, then the ˆθaug will have high
standard error relative to ˆθstd. Here, due to the inductive bias that minimizes the (cid:96)1 norm, certain augmentations can cause
large changes in the sparsity pattern of the solution, drastically affecting the error. Furthermore, the optimal solution θ(cid:63)
is quite large with respect to the (cid:96)1 norm, satisfying the conditions of Proposition 1 in spirit and suggesting that the (cid:96)1
inductive bias (promoting sparsity) is mismatched with the problem.

1). Since x3
(cid:107)

ˆθstd
(cid:107)

1+δ =

−

G.2. Construction for general d

We construct the example by sampling x in 3 dimensions and then repeating the vector d times. In particular, the samples
are realizations of the random vector [x; x; x; . . . ; x] which have dimension 3d and every block of 3 coordinates have the
same values. Under this setup, we can show that there is a family of problems such that the difference between standard
errors of the augmented and standard estimators grows to inﬁnity as d, n
Theorem 4. Let the setting be deﬁned as above, where the dimension d and number of samples n are such that n/d
γ
approaches a constant. Let p = 1/d2, (cid:15) = 1/d3, and δ be a constant. Then the ratio between standard errors of the
augmented and standard estimators grows as

.
→ ∞

→

Lstd(ˆθaug)
Lstd(ˆθstd)

= Ω(d)

(38)

as d, n

.
→ ∞

Proof. We deﬁne an event where the augmented estimator has high error relative to the standard estimator and bound the
ratio between the standard errors of the standard and augmented estimators given this event. Deﬁne E1 as the event that
we have n samples where all samples are [x1; x1; . . . ; x1]. The standard and augmented estimators are the corresponding
repeated versions

ˆθstd =

(cid:20) 2 + δ
1 + δ

(cid:21)

2 + δ
1 + δ

−

The event E1 occurs with probability (1
are

−

, 0, 0, . . . ,

, 0, 0

, ˆθaug = [0, 2 + δ, 0, . . . , 0, 2 + δ, 0].

(39)

p)n + (p

(cid:15))n. It is straightforward to verify that the respective standard errors

and that the ratio between standard errors is

Lstd(ˆθstd

E1) = (cid:15)d2(2 + δ)2, Lstd(ˆθaug

E1) = (p

(cid:15))d2(2 + δ)2

|

−

|

The ratio between standard errors is bounded by
Lstd(ˆθaug)
Lstd(ˆθstd)

Lstd(ˆθaug
Lstd(ˆθstd

E1)
E1)

|

|

p

=

(cid:15)

.

−
(cid:15)

(cid:88)

=

P (E)

E∈{E1,Ec

Lstd(ˆθaug
Lstd(ˆθstd

E)

E)

|

|

1 }
Lstd(ˆθaug
Lstd(ˆθstd
p)n + (p

E1)
E1)

|

|

p

(cid:15))n)(

(cid:15)

)

−
(cid:15)

> P (E1)

= ((1

−

> (1

(1

≥
= d

−

−

p)n(d
n
d3 )(d
n
d2 −

−

−
1 +

−
1)

1)

n
d3 = Ω(d)
, where we used Bernoulli’s inequality in the second to last step.

−

as n, d

→ ∞

