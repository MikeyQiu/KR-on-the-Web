9
1
0
2
 
r
a

M
 
4
 
 
]

G
L
.
s
c
[
 
 
4
v
7
0
4
0
1
.
5
0
8
1
:
v
i
X
r
a

Semi-supervised Deep Kernel Learning:
Regression with Unlabeled Data by Minimizing
Predictive Variance

Neal Jean∗, Sang Michael Xie∗, Stefano Ermon
Department of Computer Science
Stanford University
Stanford, CA 94305
{nealjean, xie, ermon}@cs.stanford.edu

Abstract

Large amounts of labeled data are typically required to train deep learning models.
For many real-world problems, however, acquiring additional data can be expensive
or even impossible. We present semi-supervised deep kernel learning (SSDKL), a
semi-supervised regression model based on minimizing predictive variance in the
posterior regularization framework. SSDKL combines the hierarchical represen-
tation learning of neural networks with the probabilistic modeling capabilities of
Gaussian processes. By leveraging unlabeled data, we show improvements on a
diverse set of real-world regression tasks over supervised deep kernel learning and
semi-supervised methods such as VAT and mean teacher adapted for regression.

1

Introduction

The prevailing trend in machine learning is to automatically discover good feature representations
through end-to-end optimization of neural networks. However, most success stories have been enabled
by vast quantities of labeled data [1]. This need for supervision poses a major challenge when we
encounter critical scientiﬁc and societal problems where ﬁne-grained labels are difﬁcult to obtain.
Accurately measuring the outcomes that we care about—e.g., childhood mortality, environmental
damage, or extreme poverty—can be prohibitively expensive [2, 3, 4]. Although these problems
have limited data, they often contain underlying structure that can be used for learning; for example,
poverty and other socioeconomic outcomes are strongly correlated over both space and time.

Semi-supervised learning approaches offer promise when few labels are available by allowing models
to supplement their training with unlabeled data [5]. Mostly focusing on classiﬁcation tasks, these
methods often rely on strong assumptions about the structure of the data (e.g., cluster assumptions,
low data density at decision boundaries [6]) that generally do not apply to regression [7, 8, 9, 10, 11].

In this paper, we present semi-supervised deep kernel learning, which addresses the challenge of semi-
supervised regression by building on previous work combining the feature learning capabilities of
deep neural networks with the ability of Gaussian processes to capture uncertainty [12, 3, 13]. SSDKL
incorporates unlabeled training data by minimizing predictive variance in the posterior regularization
framework, a ﬂexible way of encoding prior knowledge in Bayesian models [14, 15, 16].

Our main contributions are the following:

• We introduce semi-supervised deep kernel learning (SSDKL) for the largely unexplored
domain of deep semi-supervised regression. SSDKL is a regression model that combines

∗denotes equal contribution

Preprint. Work in progress.

Figure 1: Depiction of the variance minimization approach behind semi-supervised deep kernel
learning (SSDKL). The x-axis represents one dimension of a neural network embedding and the
y-axis represents the corresponding output. Left: Without unlabeled data, the model learns an
embedding by maximizing the likelihood of labeled data. The black and gray dotted lines show the
posterior distribution after conditioning. Right: Embedding learned by SSDKL tries to minimize
the predictive variance of unlabeled data, encouraging unlabeled embeddings to be near labeled
embeddings. Observe that the representations of both labeled and unlabeled data are free to change.

the strengths of heavily parameterized deep neural networks and nonparametric Gaussian
processes. While the deep Gaussian process kernel induces structure in an embedding space,
the model also allows a priori knowledge of structure (i.e., spatial or temporal) in the input
features to be naturally incorporated through kernel composition.

• By formalizing the semi-supervised variance minimization objective in the posterior regular-
ization framework, we unify previous semi-supervised approaches such as minimum entropy
and minimum variance regularization under a common framework. To our knowledge, this
is the ﬁrst paper connecting semi-supervised methods to posterior regularization.

• We demonstrate that SSDKL can use unlabeled data to learn more generalizable features
and improve performance on a range of regression tasks, outperforming the supervised deep
kernel learning method and semi-supervised methods such as virtual adversarial training
(VAT) and mean teacher [17, 18]. In a challenging real-world task of predicting poverty
from satellite images, SSDKL outperforms the state-of-the-art by 15.5%—by incorporating
prior knowledge of spatial structure, the median improvement increases to 17.9%.

2 Preliminaries

i=1 and m unlabeled examples {xj}n+m
We assume a training set of n labeled examples {(xi, yi)}n
j=n+1
with instances x ∈ Rd and labels y ∈ R. Let XL, yL, XU refer to the aggregated features and targets,
where XL ∈ Rn×d, yL ∈ Rn, and XU ∈ Rm×d. At test time, we are given examples XT ∈ Rt×d
that we would like to predict.

There are two major paradigms in semi-supervised learning, inductive and transductive. In inductive
semi-supervised learning, the labeled data (XL, yL) and unlabeled data XU are used to learn a
function f : X (cid:55)→ Y that generalizes well and is a good predictor on unseen test examples XT [5].
In transductive semi-supervised learning, the unlabeled examples are exactly the test data that we
would like to predict, i.e., XT = XU [19]. A transductive learning approach tries to ﬁnd a function
f : X n+m (cid:55)→ Y n+m, with no requirement of generalizing to additional test examples. Although the
theoretical development of SSDKL is general to both the inductive and transductive regimes, we
only test SSDKL in the inductive setting in our experiments for direct comparison against supervised
learning methods.

Gaussian processes A Gaussian process (GP) is a collection of random variables, any ﬁnite number
of which form a multivariate Gaussian distribution. Following the notation of [20], a Gaussian process
deﬁnes a distribution over functions f : Rd → R from inputs to target values. If

f (x) ∼ GP (µ(x), kφ(xi, xj))

2

with mean function µ(x) and covariance kernel function kφ(xi, xj) parameterized by φ, then any
collection of function values is jointly Gaussian,

f (X) = [f (x1), . . . , f (xn)]T ∼ N (µ, KX,X ),

with mean vector and covariance matrix deﬁned by the GP, s.t. µi = µ(xi) and (KX,X )ij =
kφ(xi, xj). In practice, we often assume that observations include i.i.d. Gaussian noise, i.e., y(x) =
f (x) + (cid:15)(x) where (cid:15) ∼ N (0, φ2

n), and the covariance function becomes

Cov(y(xi), y(xj)) = k(xi, xj) + φ2
where δij = I[i = j]. To make predictions at unlabeled points XU , we can compute a Gaussian
posterior distribution in closed form by conditioning on the observed data (XL, yL). For a more
thorough introduction, we refer readers to [21].

nδij

Deep kernel learning Deep kernel learning (DKL) combines neural networks with GPs by using a
neural network embedding as input to a deep kernel [12]. Given input data x ∈ X , a neural network
parameterized by w is used to extract features hw(x) ∈ Rp. The outputs are modeled as

f (x) ∼ GP(µ(hw(x)), kφ(hw(xi), hw(xj)))

for some mean function µ(·) and base kernel function kφ(·, ·) with parameters φ. Parameters θ =
(w, φ) of the deep kernel are learned jointly by minimizing the negative log likelihood of the labeled
data [20]:

Llikelihood(θ) = − log p(yL | XL, θ)
(1)
For Gaussian distributions, the marginal likelihood is a closed-form, differentiable expression, allow-
ing DKL models to be trained via backpropagation.

Posterior regularization In probabilistic models, domain knowledge is generally imposed through
the speciﬁcation of priors. These priors, along with the observed data, determine the posterior
distribution through the application of Bayes’ rule. However, it can be difﬁcult to encode our
knowledge in a Bayesian prior. Posterior regularization offers a more direct and ﬂexible mechanism
for controlling the posterior distribution.

Let D = (XL, yL) be a collection of observed data. [15] present a regularized optimization formula-
tion called regularized Bayesian inference, or RegBayes. In this framework, the regularized posterior
is the solution of the following optimization problem:

RegBayes:

inf
q(M |D)∈Pprob

L(q(M |D)) + Ω(q(M |D))

(2)

where L(q(M |D)) is deﬁned as the KL-divergence between the desired post-data posterior q(M |D)
over models M and the standard Bayesian posterior p(M |D) and Ω(q(M |D)) is a posterior regu-
larizer. The goal is to learn a posterior distribution that is not too far from the standard Bayesian
posterior while also fulﬁlling some requirements imposed by the regularization.

3 Semi-supervised deep kernel learning

We introduce semi-supervised deep kernel learning (SSDKL) for problems where labeled data is
limited but unlabeled data is plentiful. To learn from unlabeled data, we observe that a Bayesian
approach provides us with a predictive posterior distribution—i.e., we are able to quantify predictive
uncertainty. Thus, we regularize the posterior by adding an unsupervised loss term that minimizes the
predictive variance at unlabeled data points:

Lsemisup(θ) =

Llikelihood(θ) +

Lvariance(θ)

1
n

α
m

Lvariance(θ) =

Var(f (x))

(cid:88)

x∈XU

(3)

(4)

where n and m are the numbers of labeled and unlabeled training examples, α is a hyperparameter
controlling the trade-off between supervised and unsupervised components, and θ represents the
model parameters.

3

3.1 Variance minimization as posterior regularization

Optimizing Lsemisup is equivalent to computing a regularized posterior through solving a speciﬁc
instance of the RegBayes optimization problem (2), where our choice of regularizer corresponds to
variance minimization.

Let X = (XL, XU ) be the observed input data and D = (X, yL) be the input data with labels for
the labeled part XL. Let F denote a space of functions where for f ∈ F, f : Rd → R maps from the
inputs to the target values. Note that here, M = (f, θ) is the model in the RegBayes framework, where
θ are the model parameters. We assume that the prior is π(f, θ) and a likelihood density p(D|f, θ)
exists. Given observed data D, the Bayesian posterior is p(f, θ|D), while RegBayes computes a
different, regularized posterior.
Let ¯θ be a speciﬁc instance of the model parameters. Instead of maximizing the marginal likelihood
of the labeled training data in a purely supervised approach, we train our model in a semi-supervised
fashion by minimizing the compound objective

Lsemisup(¯θ) = −

log p(yL|XL, ¯θ) +

Varf ∼p(f (x))

(5)

1
n

α
m

(cid:88)

x∈XU

where the variance is with respect to p(f |¯θ, D), the Bayesian posterior given ¯θ and D.
Theorem 1. Let observed data D, a suitable space of functions F, and a bounded parameter space
Θ be given. As in [15], we assume that F is a complete separable metric space and Π is an absolutely
continuous probability measure (with respect to background measure η) on (F, B(F)), where B(F)
is the Borel σ-algebra, such that a density π exists where dΠ = πdη and we have prior density
π(f, θ) and likelihood density p(D|f, θ). Assume we choose the prior such that π(θ) is uniform on Θ.
Then the semi-supervised variance minimization problem (5)

Lsemisup(¯θ)

inf
¯θ

is equivalent to the RegBayes optimization problem (2)

inf
q(f,θ|D)∈Pprob

L(q(f, θ|D)) + Ω(q(f, θ|D))

Ω(q(f, θ|D)) = α(cid:48)

p(f |θ, D)q(θ|D)(f (XU )i − Ep[f (XU )i])2dη(f, θ)

(cid:19)
,

m
(cid:88)

(cid:18) (cid:90)

i=1

f,θ

where α(cid:48) = αn
distributions where q(θ|D) is restricted to be a Dirac delta centered on ¯θ ∈ Θ.

m , and Pprob = {q : q(f, θ|D) = q(f |θ, D)δ¯θ(θ|D), ¯θ ∈ Θ} is a variational family of

We include a formal derivation in Appendix A.1 and give a brief outline here. It can be shown that
solving the variational optimization objective

inf
q(f,θ|D)

DKL(q(f, θ|D)(cid:107)π(f, θ)) −

q(f, θ|D) log p(D|f, θ)dη(f, θ)

(6)

(cid:90)

f,θ

is equivalent to minimizing the unconstrained form of the ﬁrst term L(q(f, θ|D)) of the RegBayes
objective in Theorem 1, and the minimizer is precisely the Bayesian posterior p(f, θ|D). When we
restrict the optimization to q ∈ Pprob the solution is of the form q∗(f, θ|D) = p(f |θ, D)δ¯θ(θ|D) for
some ¯θ. This allows us to show that (6) is also equivalent to minimizing the ﬁrst term of Lsemisup(¯θ).
Finally, noting that the regularization function Ω only depends on ¯θ (through q(θ|D) = δ¯θ(θ)), the
form of q∗(f, θ|D) is unchanged after adding Ω. Therefore the choice of Ω reduces to minimizing
the predictive variance with respect to q∗(f |θ, D) = p(f |¯θ, D).

Intuition for variance minimization By minimizing Lsemisup, we trade off maximizing the
likelihood of our observations with minimizing the posterior variance on unlabeled data that we wish
to predict. The posterior variance acts as a proxy for distance with respect to the kernel function
in the deep feature space, and the regularizer is an inductive bias on the structure of the feature
space. Since the deep kernel parameters are jointly learned, the neural net is encouraged to learn a
feature representation in which the unlabeled examples are closer to the labeled examples, thereby

4

reducing the variance on our predictions. If we imagine the labeled data as “supports” for the
surface representing the posterior mean, we are optimizing for embeddings where unlabeled data
tend to cluster around these labeled supports. In contrast, the variance regularizer would not beneﬁt
conventional GP learning since ﬁxed kernels would not allow for adapting the relative distances
between data points.

Another interpretation is that the semi-supervised objective is a regularizer that reduces overﬁtting
to labeled data. The model is discouraged from learning features from labeled data that are not also
useful for making low-variance predictions at unlabeled data points. In settings where unlabeled data
provide additional variation beyond labeled examples, this can improve model generalization.

Training and inference Semi-supervised deep kernel learning scales well with large amounts
of unlabeled data since the unsupervised objective Lvariance naturally decomposes into a sum
over conditionally independent terms. This allows for mini-batch training on unlabeled data with
stochastic gradient descent. Since all of the labeled examples are interdependent, computing exact
gradients for labeled examples requires full batch gradient descent on the labeled data. Therefore,
assuming a constant batch size, each iteration of training requires O(n3) computations for a Cholesky
decomposition, where n is the number of labeled training examples. Performing the GP inference
requires O(n3) one-time cost in the labeled points. However, existing approximation methods based
on kernel interpolation and structured matrices used in DKL can be directly incorporated in SSDKL
and would reduce the training complexity to close to linear in labeled dataset size and inference to
constant time per test point [12, 22]. While DKL is designed for the supervised setting where scaling
to large labeled datasets is a very practical concern, our focus is on semi-supervised settings where
labels are limited but unlabeled data is abundant.

4 Experiments and results

We apply SSDKL to a variety of real-world regression tasks in the inductive semi-supervised learning
setting, beginning with eight datasets from the UCI repository [23]. We also explore the challenging
task of predicting local poverty measures from high-resolution satellite imagery [24]. In our reported
results, we use the squared exponential or radial basis function kernel. We also experimented with
polynomial kernels, but saw generally worse performance. Our SSDKL model is implemented in
TensorFlow [25]. Additional training details are provided in Appendix A.3, and code and data for
reproducing experimental results can be found on GitHub.2

4.1 Baselines

We ﬁrst compare SSDKL to the purely supervised DKL, showing the contribution of unlabeled data.
In addition to the supervised DKL method, we compare against semi-supervised methods including
co-training, consistency regularization, generative modeling, and label propagation. Many of these
methods were originally developed for semi-supervised classiﬁcation, so we adapt them here for
regression. All models, including SSDKL, were trained from random initializations.

COREG, or CO-training REGressors, uses two k-nearest neighbor (kNN) regressors, each of which
generates labels for the other during the learning process [26]. Unlike traditional co-training, which
requires splitting features into sufﬁcient and redundant views, COREG achieves regressor diversity by
using different distance metrics for its two regressors [27].

Consistency regularization methods aim to make model outputs invariant to local input perturbations
[17, 28, 18]. For semi-supervised classiﬁcation, [29] found that VAT and mean teacher were the best
methods using fair evaluation guidelines. Virtual adversarial training (VAT) via local distributional
smoothing (LDS) enforces consistency by training models to be robust to adversarial local input
perturbations [17, 30]. Unlike adversarial training [31], the virtual adversarial perturbation is found
without labels, making semi-supervised learning possible. We adapt VAT for regression by choosing
the output distribution N (hθ(x), σ2) for input x, where hθ : Rd → R is a parameterized mapping
and σ is ﬁxed. Optimizing the likelihood term is then equivalent to minimizing squared error; the LDS
term is the KL-divergence between the model distribution and a perturbed Gaussian (see Appendix

2https://github.com/ermongroup/ssdkl

5

SSDKL COREG

Label Prop

VAE Mean Teacher

VAT SSDKL COREG

Label Prop

VAE Mean Teacher

VAT

Dataset

Skillcraft
Parkinsons
Elevators
Protein
Blog
CTslice
Buzz
Electric

Median

N

3,325
5,875
16,599
45,730
52,397
53,500
583,250
2,049,280

d

18
20
18
9
280
384
77
6

3.44
-2.51
7.99
-3.34
5.65
-22.48
5.59
4.96

1.87
-27.45
-5.22
-2.37
11.15
-12.11
13.80
-126.95

n = 100

5.12
-43.43
2.28
0.77
9.01
-17.12
1.33
-201.18

0.11
-122.23
-22.68
-8.65
8.96
-47.59
-19.26
-285.61

Percent reduction in RMSE compared to DKL

-19.72
-91.54
-27.27
-5.11
7.05
-60.71
-77.08
-399.85

-21.97
-143.60
-31.25
-6.44
1.87
-64.75
-82.66
-513.95

5.97
5.97
6.92
1.23
5.34
5.64
11.33
-13.93

5.81

0.60
-22.50
-25.98
0.89
9.60
2.94
10.41
-154.07

0.75

n = 300

5.78
-51.35
-22.08
2.61
12.44
-2.59
-2.22
-303.21

4.36
-167.93
-53.40
-9.24
8.14
-60.18
-28.65
-460.48

-18.17
-132.68
-82.01
-8.98
7.87
-58.97
-104.88
-627.83

-20.13
-202.79
-63.68
-10.38
9.08
-84.60
-100.82
-828.35

4.20

-3.80

1.05

-20.97

-43.99

-48.00

-2.41

-41.02

-70.49

-74.14

Table 1: Percent reduction in RMSE compared to baseline supervised deep kernel learning (DKL)
model for semi-supervised deep kernel learning (SSDKL), COREG, label propagation, variational auto-
encoder (VAE), mean teacher, and virtual adversarial training (VAT) models. Results are averaged
across 10 trials for each UCI regression dataset. Here N is the total number of examples, d is the
input feature dimension, and n is the number of labeled training examples. Final row shows median
percent reduction in RMSE achieved by using unlabeled data.

A.2). Mean teacher enforces consistency by penalizing deviation from the outputs of a model with
the exponential weighted average of the parameters over SGD iterations [18].

Label propagation deﬁnes a graph structure over the data with edges that deﬁne the probability
for a categorical label to propagate from one data point to another [32]. If we encode this graph
in a transition matrix T and let the current class probabilities be y, then the algorithm iteratively
propagates y ← T y, row-normalizes y, clamps the labeled data to their known values, and repeats
until convergence. We make the extension to regression by letting y be real-valued labels and
normalizing T . As in [32], we use a fully-connected graph and the radial-basis kernel for edge
weights. The kernel scale hyperparameter is chosen using a validation set.

Generative models such as the variational autoencoder (VAE) have shown promise in semi-supervised
classiﬁcation especially for visual and sequential tasks [33, 34, 35, 36]. We compare against a
semi-supervised VAE by ﬁrst learning an unsupervised embedding of the data and then using the
embeddings as input to a supervised multilayer perceptron.

4.2 UCI regression experiments

We evaluate SSDKL on eight regression datasets from the UCI repository. For each dataset, we train
on n = {50, 100, 200, 300, 400, 500} labeled examples, retain 1000 examples as the hold out test set,
and treat the remaining data as unlabeled examples. Following [29], the labeled data is randomly split
90-10 into training and validation samples, giving a realistically small validation set. For example,
for n = 100 labeled examples, we use 90 random examples for training and the remaining 10 for
validation in every random split. We report test RMSE averaged over 10 trials of random splits to
combat the small data sizes. All kernel hyperparameters are optimized directly through Lsemisup, and
we use the validation set for early stopping to prevent overﬁtting and for selecting α ∈ {0.1, 1, 10}.
We did not use approximate GP procedures in our SSDKL or DKL experiments, so the only difference
is the addition of the variance regularizer. For all combinations of input feature dimensions and
labeled data sizes in the UCI experiments, each SSDKL trial (including all training and testing) ran
on the order of minutes.

Following [20], we choose a neural network with a similar [d-100-50-50-2] architecture and two-
dimensional embedding. Following [29], we use this same base model for all deep models, including
SSDKL, DKL, VAT, mean teacher, and the VAE encoder, in order to make results comparable across
methods. Since label propagation creates a kernel matrix of all data points, we limit the number of
unlabeled examples for label propagation to a maximum of 20000 due to memory constraints. We
initialize labels in label propagation with a kNN regressor with k = 5 to speed up convergence.

Table 1 displays the results for n = 100 and n = 300; full results are included in Appendix A.3.
SSDKL gives a 4.20% and 5.81% median RMSE improvement over the supervised DKL in the
n = 100, 300 cases respectively, superior to other semi-supervised methods adapted for regression.
A Wilcoxon signed-rank test versus DKL shows signiﬁcance at the p = 0.05 level for at least one
labeled training set size for all 8 datasets.

6

Figure 2: Left: Average test RMSE vs. number of labeled examples for UCI Elevators dataset,
n = {50, 100, 200, 300, 400, 500}. SSDKL generally outperforms supervised DKL, co-training
regressors (COREG), and virtual adversarial training (VAT). Right: SSDKL performance on poverty
prediction (Section 4.3) as a function of α, which controls the trade-off between labeled and unlabeled
objectives, for n = 300. The dotted lines plot the performance of DKL and COREG. All results
averaged over 10 trials. In both panels, shading represents one standard deviation.

The same learning rates and initializations are used across all UCI datasets for SSDKL. We use
learning rates of 1 × 10−3 and 0.1 for the neural network and GP parameters respectively and
initialize all GP parameters to 1. In Fig. 2 (right), we study the effect of varying α to trade off
between maximizing the likelihood of labeled data and minimizing the variance of unlabeled data. A
large α emphasizes minimization of the predictive variance while a small α focuses on ﬁtting labeled
data. SSDKL improves on DKL for values of α between 0.1 and 10.0, indicating that performance
is not overly reliant on the choice of this hyperparameter. Fig. 2 (left) compares SSDKL to purely
supervised DKL, COREG, and VAT as we vary the labeled training set size. For the Elevators dataset,
DKL is able to close the gap on SSDKL as it gains access to more labeled data. Relative to the other
methods, which require more data to ﬁt neural network parameters, COREG performs well in the
low-data regime.

Surprisingly, COREG outperformed SSDKL on the Blog, CTslice, and Buzz datasets. We found that
these datasets happen to be better-suited for nearest neighbors-based methods such as COREG. A
kNN regressor using only the labeled data outperformed DKL on two of three datasets for n = 100,
beat SSDKL on all three for n = 100, beat DKL on two of three for n = 300, and beat SSDKL on
one of three for n = 300. Thus, the kNN regressor is often already outperforming SSDKL with only
labeled data—it is unsurprising that SSDKL is unable to close the gap on a semi-supervised nearest
neighbors method like COREG.

Representation learning To gain some intuition about how the unlabeled data helps in the learning
process, we visualize the neural network embeddings learned by the DKL and SSDKL models on the
Skillcraft dataset. In Fig. 3 (left), we ﬁrst train DKL on n = 100 labeled training examples and plot
the two-dimensional neural network embedding that is learned. In Fig. 3 (right), we train SSDKL
on n = 100 labeled training examples along with m = 1000 additional unlabeled data points and
plot the resulting embedding. In the left panel, DKL learns a poor embedding—different colors
representing different output magnitudes are intermingled. In the right panel, SSDKL is able to use
the unlabeled data for regularization, and learns a better representation of the dataset.

4.3 Poverty prediction

High-resolution satellite imagery offers the potential for cheap, scalable, and accurate tracking of
changing socioeconomic indicators. In this task, we predict local poverty measures from satellite
images using limited amounts of poverty labels. As described in [2], the dataset consists of 3, 066
villages across ﬁve Africa countries: Nigeria, Tanzania, Uganda, Malawi, and Rwanda. These include

7

Figure 3: Left: Two-dimensional embeddings learned by supervised deep kernel learning (DKL)
model on the Skillcraft dataset using n = 100 labeled training examples. The colorbar shows the
magnitude of the normalized outputs. Right: Embeddings learned by semi-supervised deep kernel
learning (SSDKL) model using n = 100 labeled examples plus an additional m = 1000 unlabeled
examples. By using unlabeled data for regularization, SSDKL learns a better representation.

Percent reduction in RMSE (n = 300)

Country

Spatial SSDKL SSDKL

DKL

Malawi
Nigeria
Tanzania
Uganda
Rwanda

Median

13.7
17.9
10.0
25.2
27.0

17.9

16.4
4.6
15.5
12.1
25.4

15.5

15.7
1.7
9.2
13.8
21.3

13.8

Table 2: Percent RMSE reduction in a poverty measure prediction task compared to baseline ridge
regression model used in [2]. SSDKL and DKL models use only satellite image data. Spatial SSDKL
incorporates both location and image data through kernel composition. Final row shows median
RMSE reduction of each model averaged over 10 trials.

some of the poorest countries in the world (Malawi and Rwanda) as well as some that are relatively
better off (Nigeria), making for a challenging and realistically diverse problem.

In this experiment, we use n = 300 labeled satellite images for training. With such a small dataset,
we can not expect to train a deep convolutional neural network (CNN) from scratch. Instead we take
a transfer learning approach as in [24], extracting 4096-dimensional visual features and using these
as input. More details are provided in Appendix A.5.

Incorporating spatial information In order to highlight the usefulness of kernel composition, we
explore extending SSDKL with a spatial kernel. Spatial SSDKL composes two kernels by summing
an image feature kernel and a separate location kernel that operates on location coordinates (lat/lon).
By treating them separately, it explicitly encodes the knowledge that location coordinates are spatially
structured and distinct from image features.

As shown in Table 2, all models outperform the baseline state-of-the-art ridge regression model from
[2]. Spatial SSDKL signiﬁcantly outperforms the DKL and SSDKL models that use only image
features. Spatial SSDKL outperforms the other models by directly modeling location coordinates
as spatial features, showing that kernel composition can effectively incorporate prior knowledge of
structure.

8

5 Related work

[37] introduced deep Gaussian processes, which stack GPs in a hierarchy by modeling the outputs of
one layer with a Gaussian process in the next layer. Despite the suggestive name, these models do not
integrate deep neural networks and Gaussian processes.

[12] proposed deep kernel learning, combining neural networks with the non-parametric ﬂexibility
of GPs and training end-to-end in a fully supervised setting. Extensions have explored approximate
inference, stochastic gradient training, and recurrent deep kernels for sequential data [22, 38, 39].

Our method draws inspiration from transductive experimental design, which chooses the most
informative points (experiments) to measure by seeking data points that are both hard to predict and
informative for the unexplored test data [40]. Similar prediction uncertainty approaches have been
explored in semi-supervised classiﬁcation models, such as minimum entropy and minimum variance
regularization, which can now also be understood in the posterior regularization framework [7, 41].

Recent work in generative adversarial networks (GANs) [33], variational autoencoders (VAEs) [34],
and other generative models have achieved promising results on various semi-supervised classiﬁcation
tasks [35, 36]. However, we ﬁnd that these models are not as well-suited for generic regression tasks
such as in the UCI repository as for audio-visual tasks.

Consistency regularization posits that the model’s output should be invariant to reasonable perturba-
tions of the input [17, 28, 18]. Combining adversarial training [31] with consistency regularization,
virtual adversarial training uses a label-free regularization term that allows for semi-supervised
training [17]. Mean teacher adds a regularization term that penalizes deviation from a exponential
weighted average of the parameters over SGD iterations [18]. For semi-supervised classiﬁcation, [29]
found that VAT and mean teacher were the best methods across a series of fair evaluations.

Label propagation deﬁnes a graph structure over the data points and propagates labels from labeled
data over the graph. The method must assume a graph structure and edge distances on the input
feature space without the ability to adapt the space to the assumptions. Label propagation is also
subject to memory constraints since it forms a kernel matrix over all data points, requiring quadratic
space in general, although sparser graph structures can reduce this to a linear scaling.

Co-training regressors trains two kNN regressors with different distance metrics that label each others’
unlabeled data. This works when neighbors in the given input space have similar target distributions,
but unlike kernel learning approaches, the features are ﬁxed. Thus, COREG cannot adapt the space to
a misspeciﬁed distance measure. In addition, as a fully nonparametric method, inference requires
retaining the full dataset.

Much of the previous work in semi-supervised learning is in classiﬁcation and the assumptions do
not generally translate to regression. Our experiments show that SSDKL outperforms other adapted
semi-supervised methods in a battery of regression tasks.

6 Conclusions

Many important problems are challenging because of the limited availability of training data, making
the ability to learn from unlabeled data critical. In experiments with UCI datasets and a real-world
poverty prediction task, we ﬁnd that minimizing posterior variance can be an effective way to
incorporate unlabeled data when labeled training data is scarce. SSDKL models are naturally suited
for many real-world problems, as spatial and temporal structure can be explicitly modeled through the
composition of kernel functions. While our focus is on regression problems, we believe the SSDKL
framework is equally applicable to classiﬁcation problems—we leave this to future work.

Acknowledgements

This research was supported by NSF (#1651565, #1522054, #1733686), ONR, Sony, and FLI. NJ was
supported by the Department of Defense (DoD) through the National Defense Science & Engineering
Graduate Fellowship (NDSEG) Program. We are thankful to Volodymyr Kuleshov and Aditya Grover
for helpful discussions.

9

References

[1] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classiﬁcation with deep
convolutional neural networks. In Advances in neural information processing systems, pages
1097–1105, 2012.

[2] Neal Jean, Marshall Burke, Michael Xie, W Matthew Davis, David B Lobell, and Stefano Ermon.
Combining satellite imagery and machine learning to predict poverty. Science, 353(6301):790–
794, 2016.

[3] Jiaxuan You, Xiaocheng Li, Melvin Low, David Lobell, and Stefano Ermon. Deep gaussian
process for crop yield prediction based on remote sensing data. In AAAI, pages 4559–4566,
2017.

[4] Barak Oshri, Annie Hu, Peter Adelson, Xiao Chen, Pascaline Dupas, Jeremy Weinstein, Marshall
Burke, David Lobell, and Stefano Ermon. Infrastructure quality assessment in africa using
satellite imagery and deep learning. Proc. 24th ACM SIGKDD Conference, 2018.

[5] Xiaojin Zhu and Andrew B Goldberg. Introduction to semi-supervised learning. Synthesis

lectures on artiﬁcial intelligence and machine learning, 3(1):1–130, 2009.

[6] Rui Shu, Hung H Bui, Hirokazu Narui, and Stefano Ermon. A DIRT-T approach to unsupervised

domain adaptation. In International Conference on Learning Representations, 2018.

[7] Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In

Advances in neural information processing systems, pages 529–536, 2004.

[8] Olivier Chapelle and Alexander Zien. Semi-supervised classiﬁcation by low density separation.

In AISTATS, pages 57–64, 2005.

[9] Aarti Singh, Robert Nowak, and Xiaojin Zhu. Unlabeled data: Now it helps, now it doesn’t. In

Advances in neural information processing systems, pages 1513–1520, 2009.

[10] Volodymyr Kuleshov and Stefano Ermon. Deep hybrid models: Bridging discriminative and

generative approaches. In Proceedings of the Conference on Uncertainty in AI (UAI), 2017.

[11] Russell Ren, Hongyu Stewart, Jiaming Song, Volodymyr Kuleshov, and Stefano Ermon. Adver-
sarial constraint learning for structured prediction. Proc. 27th International Joint Conference
on Artiﬁcial Intelligence, 2018.

[12] Andrew Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, and Eric P. Xing. Deep kernel

learning. The Journal of Machine Learning Research, 2015.

[13] Stephan Eissman and Stefano Ermon. Bayesian optimization and attribute adjustment. Proc.

34th Conference on Uncertainty in Artiﬁcial Intelligence, 2018.

[14] Kuzman Ganchev, Jennifer Gillenwater, Ben Taskar, et al. Posterior regularization for structured
latent variable models. Journal of Machine Learning Research, 11(Jul):2001–2049, 2010.
[15] Jun Zhu, Ning Chen, and Eric P Xing. Bayesian inference with posterior regularization and
applications to inﬁnite latent svms. Journal of Machine Learning Research, 15(1):1799–1847,
2014.

[16] Rui Shu, Hung H Bui, Shengjia Zhao, Mykel J Kochenderfer, and Stefano Ermon. Amortized

inference regularization. NIPS, 2018.

[17] Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, Ken Nakae, and Shin Ishii. Distributional

smoothing with virtual adversarial training. arXiv preprint arXiv:1507.00677, 2015.

[18] Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged
consistency targets improve semi-supervised deep learning results. In I. Guyon, U. V. Luxburg,
S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural
Information Processing Systems 30, pages 1195–1204. Curran Associates, Inc., 2017.

[19] Andrew Arnold, Ramesh Nallapati, and William W. Cohen. A comparative study of methods for
transductive transfer learning. Proc. Seventh IEEE Int’,l Conf. Data Mining Workshops, 2007.
[20] Andrew Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, and Eric P Xing. Deep kernel
learning. In Proceedings of the 19th International Conference on Artiﬁcial Intelligence and
Statistics, pages 370–378, 2016.

[21] Carl Edward Rasmussen and Christopher KI Williams. Gaussian processes for machine learning.

The MIT Press, 2006.

10

[22] Andrew Gordon Wilson and Hannes Nickisch. Kernel interpolation for scalable structured
gaussian processes (KISS-GP). In Proceedings of the 32nd International Conference on Machine
Learning, ICML 2015, Lille, France, 6-11 July 2015, pages 1775–1784, 2015.

[23] M. Lichman. UCI machine learning repository, 2013.

[24] Michael Xie, Neal Jean, Marshall Burke, David Lobell, and Stefano Ermon. Transfer learning
from deep features for remote sensing and poverty mapping. AAAI Conference on Artiﬁcial
Intelligence, 2016.

[25] Martın Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro,
Greg S Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, et al. Tensorﬂow: Large-scale
machine learning on heterogeneous distributed systems. arXiv preprint arXiv:1603.04467,
2016.

[26] Zhi-Hua Zhou and Ming Li. Semi-supervised regression with co-training. In IJCAI, volume 5,

pages 908–913, 2005.

[27] Avrim Blum and Tom Mitchell. Combining labeled and unlabeled data with co-training. In
Proceedings of the eleventh annual conference on Computational learning theory, pages 92–100.
ACM, 1998.

[28] Samuli Laine and Timo Aila. Temporal ensembling for semi-supervised learning. ICLR 2017,

2017.

[29] Augustus Odena, Avital Oliver, Colin Raffel, Ekin Dogus Cubuk, and Ian Goodfellow. Realistic

evaluation of semi-supervised learning algorithms. 2018.

[30] Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual adversarial train-
ing: a regularization method for supervised and semi-supervised learning. arXiv preprint
arXiv:1704.03976, 2017.

[31] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversar-

ial examples. arXiv preprint arXiv:1412.6572, 2014.

[32] Xiaojin Zhu and Zoubin Ghahramani. Learning from labeled and unlabeled data with label

propagation. Technical report, 2002.

[33] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil
Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural
information processing systems, pages 2672–2680, 2014.

[34] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint

arXiv:1312.6114, 2013.

[35] Lars Maaløe, Casper Kaae Sønderby, Søren Kaae Sønderby, and Ole Winther. Auxiliary deep

generative models. arXiv preprint arXiv:1602.05473, 2016.

[36] Antti Rasmus, Mathias Berglund, Mikko Honkala, Harri Valpola, and Tapani Raiko. Semi-
supervised learning with ladder networks. In Advances in Neural Information Processing
Systems, pages 3546–3554, 2015.

[37] Andreas C. Damianou and Neil D. Lawrence. Deep gaussian processes. The Journal of Machine

Learning Research, 2013.

[38] Andrew G Wilson, Zhiting Hu, Ruslan R Salakhutdinov, and Eric P Xing. Stochastic variational
deep kernel learning. In Advances in Neural Information Processing Systems, pages 2586–2594,
2016.

[39] Maruan Al-Shedivat, Andrew Gordon Wilson, Yunus Saatchi, Zhiting Hu, and Eric P Xing.
Learning scalable deep kernels with recurrent structure. arXiv preprint arXiv:1610.08936, 2016.

[40] Kai Yu, Jinbo Bi, and Volker Tresp. Active learning via transductive experimental design. The

International Conference on Machine Learning (ICML), 2006.

[41] Chenyang Zhao and Shaodan Zhai. Minimum variance semi-supervised boosting for multi-
label classiﬁcation. In 2015 IEEE Global Conference on Signal and Information Processing
(GlobalSIP), pages 1342–1346. IEEE, 2015.

[42] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. 3rd International

Conference for Learning Representations, 2015.

11

[43] Morten Jerven. Poor numbers: how we are misled by African development statistics and what

to do about it. Cornell University Press, 2013.

[44] ICF International. Demographic and health surveys (various) [datasets], 2015.
[45] Deon Filmer and Lant H Pritchett. Estimating wealth effects without expenditure data—or tears:
An application to educational enrollments in states of india*. Demography, 38(1):115–132,
2001.

A Appendix

A.1 Posterior regularization

Proof of Theorem 1. Let D = (XL, yL, XU ) be a collection of observed data. Let X = (XL, XU )
be the observed input data points. As in [15], we assume that F is a complete separable metric space
and Π is an absolutely continuous probability measure (with respect to background measure η) on
(F, B(F)), where B(F) is the the Borel σ-algebra, such that a density π exists where dΠ = πdη. Let
Θ be a space of parameters to the model, where we treat θ ∈ Θ as random variables. With regards to
the notation in the RegBayes framework, the model is the pair M = (f, θ). We assume as in [15] that
the likelihood function P (·|M ) is the likelihood distribution which is dominated by a σ-ﬁnite measure
λ for all M with positive density, such that a density p(·|M ) exists where dP (·|M ) = p(·|M )dλ.

We would like to compute the posterior distribution

p(f, θ|D) =

p(D|f, θ)π(f, θ)
f,θ p(f, θ, D)dη(f, θ)

(cid:82)

which involves an intractable integral.

We claim that the solution of the following optimization problem is precisely the Bayesian posterior
p(f, θ|D):

inf
q(f,θ|D)

DKL(q(f, θ|D)(cid:107)π(f, θ)) −

q(f, θ|D) log p(D|f, θ)dη(f, θ).

By adding the constant log p(D) to the objective,

DKL(q(f, θ|D)(cid:107)π(f, θ)) −

q(f, θ|D) log p(D|f, θ)dη(f, θ) + log p(D)

(cid:90)

f,θ

(cid:90)

f,θ

inf
q(f,θ|D)

= inf

q(f,θ|D)

= inf

q(f,θ|D)

(cid:90)

(cid:90)

f,θ

f,θ

q(f, θ|D) log

dη(f, θ) + log p(D)

q(f, θ|D)
p(f, θ, D)

q(f, θ|D)
p(f, θ|D)

q(f, θ|D) log

dη(f, θ)

= inf

DKL(q(f, θ|D)(cid:107)p(f, θ|D))

q(f,θ|D)

= inf

L(q(f, θ|D)),

q(f,θ|D)

where by deﬁnition p(f, θ, D) = p(D|f, θ)π(f, θ) and we see that the objective is minimized when
q(f, θ|D) = p(f, θ|D) as claimed. We note that the objective is equivalent to the ﬁrst term of the
RegBayes objective (Section 2.3).
We introduce a variational approximation q ∈ Pprob which approximates p(f, θ|D), where Pprob =
{q : q(f, θ|D) = q(f |θ, D)δ¯θ(θ|D)} is the family of approximating distributions such that q(θ|D) is
restricted to be a Dirac delta centered on ¯θ. When we restrict q ∈ Pprob,

DKL(q(f, θ|D)(cid:107)π(f, θ)) −

q(f, θ|D) log p(D|f, θ)dη(f, θ)

δ ¯θ(θ)

q(f |θ, D)

log

(cid:18)

q(f |θ, D)δ ¯θ(θ)
p(f, θ|D)

(cid:19)

dη(f, θ) + O(1)

(cid:90)

f,θ

δ ¯θ(θ)

DKL(q(f |θ, D)(cid:107)p(f |θ, D)) + log δ ¯θ(θ) − log p(θ|D)

dη(θ) + O(1)

(14)

(cid:19)

(cid:19)

= inf

q(f |θ,D), ¯θ

δ ¯θ(θ)

DKL(q(f |θ, D)(cid:107)p(f |θ, D)) − log p(θ|D)

dη(θ) + O(1)

(15)

inf
q(f,θ|D)∈Pprob

= inf

q(f |θ,D), ¯θ

= inf

q(f |θ,D), ¯θ

(cid:90)

θ

(cid:90)

θ

(cid:90)

θ

(cid:90)

f
(cid:18)

(cid:18)

(7)

(8)

(9)

(10)

(11)

(12)

(13)

12

where in equation (13) we use the form from equation (9), and in equation (15) we note that
(cid:82)
θ δ¯θ(θ) log δ¯θ(θ) does not vary with ¯θ or q, and can be removed from the optimization. For every
¯θ, the optimizing distribution is q∗(f |θ, D) = p(f |¯θ, D), which is the Bayesian posterior given the
model parameters. Substituting this optimal value into (15),
(cid:18)

(cid:19)

(cid:90)

DKL(q∗(f |θ, D)(cid:107)p(f |θ, D)) − log p(θ|D)

dη(θ) + O(1)

inf
q(f |θ,D),¯θ

δ¯θ(θ)

θ

(cid:90)

θ
(cid:90)

θ
(cid:90)

θ

= inf
¯θ

−

= inf
¯θ

−

= inf
¯θ
= inf
¯θ
= inf
¯θ

δ¯θ(θ) log p(θ|D)dη(θ) + O(1)

δ¯θ(θ)(log p(θ|X, yL) + log p(yL|X))dη(θ) + O(1)

−

δ¯θ(θ) log p(yL, θ|X)dη(θ) + O(1)

− log p(yL|¯θ, X) − log p(¯θ|X) + O(1)

− log p(yL|¯θ, X) + O(1)

(16)

(17)

(18)

(19)

(20)

(21)

using that DKL(q∗(f |θ, D)(cid:107)p(f |θ, D)) = 0 in (17) and (cid:82)
θ δ¯θ(θ) log p(yL|X) is a constant. We also
treat log p(¯θ|X) as a constant since ¯θ is independent of X without any observations yL, and we
choose a uniform prior over ¯θ. The optimization problem over ¯θ reﬂects maximizing the likelihood of
the data.

We deﬁned the regularization function as

Ω(q(f, θ|D)) = α(cid:48)

p(f |θ, D)q(θ|D)(f (XU )i − Ep[f (XU )i])2dη(f, θ)

.

Note that the regularization function only depends on ¯θ, through q(θ | D) = δ¯θ(θ). Therefore
the optimal post-data posterior q in the regularized objective is still in the form q∗(f, θ|D) =
p(f |θ, D)δ¯θ(θ), and q is modiﬁed by the regularization function only through δ¯θ(θ).
Thus, using the optimal post-data posterior q∗(f, θ|D) = p(f |θ, D)δ¯θ(θ), the RegBayes problem is
equivalent to the objective optimized by SSDKL:

inf
q(f,θ|D)∈Pprob

L(q(f, θ|D)) + Ω(q(f, θ|D))

− log p(yL|¯θ, X) + α(cid:48)

(f (XU )i − Ep[f (XU )i])2

δ ¯θ(θ)p(f |θ, D)dη(f, θ)

+ O(1)

(cid:90)

θ

− log p(yL|¯θ, X) + α(cid:48)

p(f |¯θ, D)(f (XU )i − Ep[f (XU )i])2dη(f ) + O(1)

(cid:19)

(cid:19)

m
(cid:88)

(cid:18) (cid:90)

i=1

f,θ

m
(cid:88)

(cid:18)(cid:90)

f

i=1
m
(cid:88)

(cid:90)

f

i=1
m
(cid:88)

i=1

− log p(yL|¯θ, X) + α(cid:48)

Varp(f ((XU )i)) + O(1)

Lsemisup(¯θ) + O(1).

A.2 Virtual Adversarial Training

Virtual adversarial training (VAT) is a general training mechanism which enforces local distributional
smoothness (LDS) by optimizing the model to be less sensitive to adversarial perturbations of the
input [17]. The VAT objective is to augment the marginal likelihood with an LDS objective:

= inf
¯θ

= inf
¯θ

= inf
¯θ

= inf
¯θ

where

1
n

n
(cid:88)

i=1

log p(yL|XL, ¯θ) +

LDS(Xi, ¯θ)

λ
n

n
(cid:88)

i=1

LDS(Xi, ¯θ) = −∆KL(rv-adv(i), Xi, ¯θ)

13

Dataset

Skillcraft
Parkinsons
Elevators
Protein
Blog
CTslice
Buzz
Electric

Median

N

3,325
5,875
16,599
45,730
52,397
53,500
583,250
2,049,280

d

18
20
18
9
280
384
77
6

5.67
-8.34
4.92
-0.54
7.69
-13.92
5.56
32.41

5.24

8.52
-18.18
5.83
5.05
8.66
-2.14
22.21
-34.82

5.44

Percent reduction in RMSE compared to DKL

SSDKL COREG

Label Prop

VAT Mean Teacher

VAE

n = 50

7.60
-32.85
11.28
7.52
8.71
-17.83
18.52
-64.45

3.92
-83.51
-8.19
0.22
8.40
-36.95
1.64
-105.74

-12.01
-69.98
-20.91
5.51
6.89
-35.45
-62.65
-179.13

-19.93
-95.57
-16.35
4.57
6.26
-33.24
-41.81
-201.51

7.56

-3.99

-28.18

-26.59

Table 3: Percent reduction in RMSE compared to baseline supervised deep kernel learning (DKL)
model for semi-supervised deep kernel learning (SSDKL), COREG, label propagation, variational auto-
encoder (VAE), mean teacher, and virtual adversarial training (VAT) models. Results are averaged
across 10 trials for each UCI regression dataset. Here N is the total number of examples, d is the
input feature dimension, and n = 50 is the number of labeled training examples. Final row shows
median percent reduction in RMSE achieved by using unlabeled data.

∆KL(r, Xi, ¯θ) = DKL(p(y|Xi, ¯θ)(cid:107)p(y|Xi + r, ¯θ))

rv-adv(i) = arg max

{∆KL(r, Xi, ¯θ); (cid:107)r(cid:107)2 ≤ (cid:15)}

r

and y is the output of the model given the input Xi (or perturbed input Xi + r) and parameters
¯θ. Note that the LDS objective does not require labels, so that unlabeled data can be incorporated.
The experiments in the original paper are for classiﬁcation, although VAT is general. We use VAT
for regression by choosing p(y|Xi, ¯θ) = N (h¯θ(Xi), σ2) where h¯θ : Rd → RH is a parameterized
mapping (a neural network), and σ is ﬁxed. Optimizing the likelihood term is then equivalent to
minimizing the squared error and the LDS term is the KL-divergence between the model’s Gaussian
distribution and a perturbed Gaussian distribution, which is also in the form of a squared difference.
To calculate the adversarial perturbation rv-adv(i), ﬁrst we take the second-order Taylor approximation
at r = 0 of ∆KL(r, Xi, ¯θ), assuming that p(y|Xi, ¯θ) is twice differentiable:

DKL(p(y|Xi, ¯θ)(cid:107)p(y|Xi + r, ¯θ) ≈

(22)
where Hi = ∇∇rDKL(p(y|Xi, ¯θ)|r=0. Note that the ﬁrst derivative is zero since DKL(p(y|Xi, ¯θ)
is minimized at r = 0. Therefore rv-adv(i) can be approximated with the ﬁrst dominant eigenvector of
the Hi scaled to norm (cid:15). The eigenvector calculation is done via a ﬁnite-difference approximation to
the power iteration method. As in [17], one step of the ﬁnite-difference approximation was used in all
of our experiments.

rT Hir

1
2

A.3 Training details

In our reported results, we use the standard squared exponential or radial basis function (RBF) kernel,

k(xi, xj) = φ2

f exp

−

(cid:18)

(cid:107)xi − xj(cid:107)2
2
2φ2
l

(cid:19)

,

f and φ2

where φ2
l represent the signal variance and characteristic length scale. We also experimented
i xj +φl)p, p ∈ Z+, but found that performance generally
with polynomial kernels, k(xi, xj) = (φf xT
decreased. To enforce positivity constraints on the kernel parameters and positive deﬁniteness of
the covariance, we train these parameters in the log-domain. Although the information capacity
of a non-parametric model increases with the dataset size, the marginal likelihood automatically
constrains model complexity without additional regularization [21]. The parametric neural networks
are regularized with L2 weight decay to reduce overﬁtting, and models are implemented and trained
in TensorFlow using the ADAM optimizer [25, 42].

A.4 UCI results

In section 4.2 of the main text, we include results on the UCI datasets for n = 100 and n = 300.
Here we include the rest of the experimental results, for n ∈ {50, 200, 400, 500}. For n = 50, we

14

Percent reduction in RMSE compared to DKL

SSDKL COREG

Label Prop

VAT Mean Teacher

VAE

n = 200

7.96
-48.93
-5.51
1.99
14.78
-7.82
-2.93
-292.88

4.43
-160.51
-33.00
-8.96
14.01
-43.25
-30.94
-432.04

-22.26
-132.12
-32.94
-8.57
8.09
-67.95
-106.85
-580.78

-20.11
-195.88
-42.74
-8.65
7.88
-55.53
-103.69
-722.28

Dataset

Skillcraft
Parkinsons
Elevators
Protein
Blog
CTslice
Buzz
Electric

Median

N

3,325
5,875
16,599
45,730
52,397
53,500
583,250
2,049,280

d

18
20
18
9
280
384
77
6

7.79
1.45
12.80
2.49
4.16
-11.96
4.78
-2.72

0.51
-29.86
-10.23
-0.56
9.87
-3.05
8.60
-166.86

3.32

-1.81

-4.22

-31.97

-50.45

-49.13

Table 4: See Table 1 above and section 4.2 in the main text for details, results for n = 200 labeled
examples.

Percent reduction in RMSE compared to DKL

SSDKL COREG

Label Prop

VAT Mean Teacher

VAE

Dataset

Skillcraft
Parkinsons
Elevators
Protein
Blog
CTslice
Buzz
Electric

Median

N

3,325
5,875
16,599
45,730
52,397
53,500
583,250
2,049,280

d

18
20
18
9
280
384
77
6

-0.21
7.92
-1.19
-1.57
-2.47
15.21
3.94
-5.47

-0.70

-5.28
-20.65
-38.84
-0.02
4.48
5.35
3.37
-159.98

-2.65

n = 400

0.76
-75.10
-32.25
0.35
6.05
7.38
-9.86
-319.97

-2.56
-191.56
-72.48
-12.02
5.28
-42.73
-40.47
-504.63

-34.21
-154.43
-83.24
-10.90
0.60
-68.37
-118.13
-680.03

-33.01
-234.07
-72.90
-11.59
-0.68
-66.05
-119.55
-866.89

-4.76

-41.60

-75.81

-69.47

Table 5: See Table 1 above and section 4.2 in the main text for details, results for n = 400 labeled
examples.

note that both COREG and label propagation perform quite well — we expect that this is true because
these methods do not require learning neural network parameters from data.

A.5 Poverty prediction

High-resolution satellite imagery offers the potential for cheap, scalable, and accurate tracking of
changing socioeconomic indicators. The United Nations has set 17 Sustainable Development Goals
(SDGs) for the year 2030—the ﬁrst of these is the worldwide elimination of extreme poverty, but a
lack of reliable data makes it difﬁcult to distribute aid and target interventions effectively. Traditional
data collection methods such as large-scale household surveys or censuses are slow and expensive,
requiring years to complete and costing billions of dollars [43]. Because data on the outputs that we
care about are scarce, it is difﬁcult to train models on satellite imagery using traditional supervised
methods. In this task, we attempt to predict local poverty measures from satellite images using limited
amounts of poverty labels. As described in [2], the dataset consists of 3, 066 villages across ﬁve
Africa countries: Nigeria, Tanzania, Uganda, Malawi, and Rwanda. These countries include some of
the poorest in the world (Malawi, Rwanda) as well as regions of Africa that are relatively better off
(Nigeria), making for a challenging and realistically diverse problem. The raw satellite inputs consist
of 400 × 400 pixel RGB satellite images downloaded from Google Static Maps at zoom level 16,
corresponding to 2.4 m ground resolution. The target variable that we attempt to predict is a wealth
index provided in the publicly available Demographic and Health Surveys (DHS) [44, 45].

15

Percent reduction in RMSE compared to DKL

SSDKL COREG

Label Prop

VAT Mean Teacher

VAE

Dataset

Skillcraft
Parkinsons
Elevators
Protein
Blog
CTslice
Buzz
Electric

Median

N

3,325
5,875
16,599
45,730
52,397
53,500
583,250
2,049,280

d

18
20
18
9
280
384
77
6

-5.59
9.42
0.82
-1.19
3.37
5.80
7.38
-8.71

2.09

-10.35
-15.48
-43.95
-3.36
7.58
3.50
2.83
-136.52

-6.85

n = 500

-6.64
-56.79
-39.11
-3.24
12.85
-4.35
-13.52
-301.95

-9.11
-198.14
-80.17
-17.73
10.56
-73.67
-42.03
-472.13

-31.52
-157.34
-93.15
-14.64
2.23
-86.25
-137.47
-635.63

-32.09
-240.18
-96.91
-16.60
5.01
-115.66
-112.36
-836.90

-10.08

-57.85

-89.70

-104.63

Table 6: See Table 1 above and section 4.2 in the main text for details, results for n = 500 labeled
examples.

16

9
1
0
2
 
r
a

M
 
4
 
 
]

G
L
.
s
c
[
 
 
4
v
7
0
4
0
1
.
5
0
8
1
:
v
i
X
r
a

Semi-supervised Deep Kernel Learning:
Regression with Unlabeled Data by Minimizing
Predictive Variance

Neal Jean∗, Sang Michael Xie∗, Stefano Ermon
Department of Computer Science
Stanford University
Stanford, CA 94305
{nealjean, xie, ermon}@cs.stanford.edu

Abstract

Large amounts of labeled data are typically required to train deep learning models.
For many real-world problems, however, acquiring additional data can be expensive
or even impossible. We present semi-supervised deep kernel learning (SSDKL), a
semi-supervised regression model based on minimizing predictive variance in the
posterior regularization framework. SSDKL combines the hierarchical represen-
tation learning of neural networks with the probabilistic modeling capabilities of
Gaussian processes. By leveraging unlabeled data, we show improvements on a
diverse set of real-world regression tasks over supervised deep kernel learning and
semi-supervised methods such as VAT and mean teacher adapted for regression.

1

Introduction

The prevailing trend in machine learning is to automatically discover good feature representations
through end-to-end optimization of neural networks. However, most success stories have been enabled
by vast quantities of labeled data [1]. This need for supervision poses a major challenge when we
encounter critical scientiﬁc and societal problems where ﬁne-grained labels are difﬁcult to obtain.
Accurately measuring the outcomes that we care about—e.g., childhood mortality, environmental
damage, or extreme poverty—can be prohibitively expensive [2, 3, 4]. Although these problems
have limited data, they often contain underlying structure that can be used for learning; for example,
poverty and other socioeconomic outcomes are strongly correlated over both space and time.

Semi-supervised learning approaches offer promise when few labels are available by allowing models
to supplement their training with unlabeled data [5]. Mostly focusing on classiﬁcation tasks, these
methods often rely on strong assumptions about the structure of the data (e.g., cluster assumptions,
low data density at decision boundaries [6]) that generally do not apply to regression [7, 8, 9, 10, 11].

In this paper, we present semi-supervised deep kernel learning, which addresses the challenge of semi-
supervised regression by building on previous work combining the feature learning capabilities of
deep neural networks with the ability of Gaussian processes to capture uncertainty [12, 3, 13]. SSDKL
incorporates unlabeled training data by minimizing predictive variance in the posterior regularization
framework, a ﬂexible way of encoding prior knowledge in Bayesian models [14, 15, 16].

Our main contributions are the following:

• We introduce semi-supervised deep kernel learning (SSDKL) for the largely unexplored
domain of deep semi-supervised regression. SSDKL is a regression model that combines

∗denotes equal contribution

Preprint. Work in progress.

Figure 1: Depiction of the variance minimization approach behind semi-supervised deep kernel
learning (SSDKL). The x-axis represents one dimension of a neural network embedding and the
y-axis represents the corresponding output. Left: Without unlabeled data, the model learns an
embedding by maximizing the likelihood of labeled data. The black and gray dotted lines show the
posterior distribution after conditioning. Right: Embedding learned by SSDKL tries to minimize
the predictive variance of unlabeled data, encouraging unlabeled embeddings to be near labeled
embeddings. Observe that the representations of both labeled and unlabeled data are free to change.

the strengths of heavily parameterized deep neural networks and nonparametric Gaussian
processes. While the deep Gaussian process kernel induces structure in an embedding space,
the model also allows a priori knowledge of structure (i.e., spatial or temporal) in the input
features to be naturally incorporated through kernel composition.

• By formalizing the semi-supervised variance minimization objective in the posterior regular-
ization framework, we unify previous semi-supervised approaches such as minimum entropy
and minimum variance regularization under a common framework. To our knowledge, this
is the ﬁrst paper connecting semi-supervised methods to posterior regularization.

• We demonstrate that SSDKL can use unlabeled data to learn more generalizable features
and improve performance on a range of regression tasks, outperforming the supervised deep
kernel learning method and semi-supervised methods such as virtual adversarial training
(VAT) and mean teacher [17, 18]. In a challenging real-world task of predicting poverty
from satellite images, SSDKL outperforms the state-of-the-art by 15.5%—by incorporating
prior knowledge of spatial structure, the median improvement increases to 17.9%.

2 Preliminaries

i=1 and m unlabeled examples {xj}n+m
We assume a training set of n labeled examples {(xi, yi)}n
j=n+1
with instances x ∈ Rd and labels y ∈ R. Let XL, yL, XU refer to the aggregated features and targets,
where XL ∈ Rn×d, yL ∈ Rn, and XU ∈ Rm×d. At test time, we are given examples XT ∈ Rt×d
that we would like to predict.

There are two major paradigms in semi-supervised learning, inductive and transductive. In inductive
semi-supervised learning, the labeled data (XL, yL) and unlabeled data XU are used to learn a
function f : X (cid:55)→ Y that generalizes well and is a good predictor on unseen test examples XT [5].
In transductive semi-supervised learning, the unlabeled examples are exactly the test data that we
would like to predict, i.e., XT = XU [19]. A transductive learning approach tries to ﬁnd a function
f : X n+m (cid:55)→ Y n+m, with no requirement of generalizing to additional test examples. Although the
theoretical development of SSDKL is general to both the inductive and transductive regimes, we
only test SSDKL in the inductive setting in our experiments for direct comparison against supervised
learning methods.

Gaussian processes A Gaussian process (GP) is a collection of random variables, any ﬁnite number
of which form a multivariate Gaussian distribution. Following the notation of [20], a Gaussian process
deﬁnes a distribution over functions f : Rd → R from inputs to target values. If

f (x) ∼ GP (µ(x), kφ(xi, xj))

2

with mean function µ(x) and covariance kernel function kφ(xi, xj) parameterized by φ, then any
collection of function values is jointly Gaussian,

f (X) = [f (x1), . . . , f (xn)]T ∼ N (µ, KX,X ),

with mean vector and covariance matrix deﬁned by the GP, s.t. µi = µ(xi) and (KX,X )ij =
kφ(xi, xj). In practice, we often assume that observations include i.i.d. Gaussian noise, i.e., y(x) =
f (x) + (cid:15)(x) where (cid:15) ∼ N (0, φ2

n), and the covariance function becomes

Cov(y(xi), y(xj)) = k(xi, xj) + φ2
where δij = I[i = j]. To make predictions at unlabeled points XU , we can compute a Gaussian
posterior distribution in closed form by conditioning on the observed data (XL, yL). For a more
thorough introduction, we refer readers to [21].

nδij

Deep kernel learning Deep kernel learning (DKL) combines neural networks with GPs by using a
neural network embedding as input to a deep kernel [12]. Given input data x ∈ X , a neural network
parameterized by w is used to extract features hw(x) ∈ Rp. The outputs are modeled as

f (x) ∼ GP(µ(hw(x)), kφ(hw(xi), hw(xj)))

for some mean function µ(·) and base kernel function kφ(·, ·) with parameters φ. Parameters θ =
(w, φ) of the deep kernel are learned jointly by minimizing the negative log likelihood of the labeled
data [20]:

Llikelihood(θ) = − log p(yL | XL, θ)
(1)
For Gaussian distributions, the marginal likelihood is a closed-form, differentiable expression, allow-
ing DKL models to be trained via backpropagation.

Posterior regularization In probabilistic models, domain knowledge is generally imposed through
the speciﬁcation of priors. These priors, along with the observed data, determine the posterior
distribution through the application of Bayes’ rule. However, it can be difﬁcult to encode our
knowledge in a Bayesian prior. Posterior regularization offers a more direct and ﬂexible mechanism
for controlling the posterior distribution.

Let D = (XL, yL) be a collection of observed data. [15] present a regularized optimization formula-
tion called regularized Bayesian inference, or RegBayes. In this framework, the regularized posterior
is the solution of the following optimization problem:

RegBayes:

inf
q(M |D)∈Pprob

L(q(M |D)) + Ω(q(M |D))

(2)

where L(q(M |D)) is deﬁned as the KL-divergence between the desired post-data posterior q(M |D)
over models M and the standard Bayesian posterior p(M |D) and Ω(q(M |D)) is a posterior regu-
larizer. The goal is to learn a posterior distribution that is not too far from the standard Bayesian
posterior while also fulﬁlling some requirements imposed by the regularization.

3 Semi-supervised deep kernel learning

We introduce semi-supervised deep kernel learning (SSDKL) for problems where labeled data is
limited but unlabeled data is plentiful. To learn from unlabeled data, we observe that a Bayesian
approach provides us with a predictive posterior distribution—i.e., we are able to quantify predictive
uncertainty. Thus, we regularize the posterior by adding an unsupervised loss term that minimizes the
predictive variance at unlabeled data points:

Lsemisup(θ) =

Llikelihood(θ) +

Lvariance(θ)

1
n

α
m

Lvariance(θ) =

Var(f (x))

(cid:88)

x∈XU

(3)

(4)

where n and m are the numbers of labeled and unlabeled training examples, α is a hyperparameter
controlling the trade-off between supervised and unsupervised components, and θ represents the
model parameters.

3

3.1 Variance minimization as posterior regularization

Optimizing Lsemisup is equivalent to computing a regularized posterior through solving a speciﬁc
instance of the RegBayes optimization problem (2), where our choice of regularizer corresponds to
variance minimization.

Let X = (XL, XU ) be the observed input data and D = (X, yL) be the input data with labels for
the labeled part XL. Let F denote a space of functions where for f ∈ F, f : Rd → R maps from the
inputs to the target values. Note that here, M = (f, θ) is the model in the RegBayes framework, where
θ are the model parameters. We assume that the prior is π(f, θ) and a likelihood density p(D|f, θ)
exists. Given observed data D, the Bayesian posterior is p(f, θ|D), while RegBayes computes a
different, regularized posterior.
Let ¯θ be a speciﬁc instance of the model parameters. Instead of maximizing the marginal likelihood
of the labeled training data in a purely supervised approach, we train our model in a semi-supervised
fashion by minimizing the compound objective

Lsemisup(¯θ) = −

log p(yL|XL, ¯θ) +

Varf ∼p(f (x))

(5)

1
n

α
m

(cid:88)

x∈XU

where the variance is with respect to p(f |¯θ, D), the Bayesian posterior given ¯θ and D.
Theorem 1. Let observed data D, a suitable space of functions F, and a bounded parameter space
Θ be given. As in [15], we assume that F is a complete separable metric space and Π is an absolutely
continuous probability measure (with respect to background measure η) on (F, B(F)), where B(F)
is the Borel σ-algebra, such that a density π exists where dΠ = πdη and we have prior density
π(f, θ) and likelihood density p(D|f, θ). Assume we choose the prior such that π(θ) is uniform on Θ.
Then the semi-supervised variance minimization problem (5)

Lsemisup(¯θ)

inf
¯θ

is equivalent to the RegBayes optimization problem (2)

inf
q(f,θ|D)∈Pprob

L(q(f, θ|D)) + Ω(q(f, θ|D))

Ω(q(f, θ|D)) = α(cid:48)

p(f |θ, D)q(θ|D)(f (XU )i − Ep[f (XU )i])2dη(f, θ)

(cid:19)
,

m
(cid:88)

(cid:18) (cid:90)

i=1

f,θ

where α(cid:48) = αn
distributions where q(θ|D) is restricted to be a Dirac delta centered on ¯θ ∈ Θ.

m , and Pprob = {q : q(f, θ|D) = q(f |θ, D)δ¯θ(θ|D), ¯θ ∈ Θ} is a variational family of

We include a formal derivation in Appendix A.1 and give a brief outline here. It can be shown that
solving the variational optimization objective

inf
q(f,θ|D)

DKL(q(f, θ|D)(cid:107)π(f, θ)) −

q(f, θ|D) log p(D|f, θ)dη(f, θ)

(6)

(cid:90)

f,θ

is equivalent to minimizing the unconstrained form of the ﬁrst term L(q(f, θ|D)) of the RegBayes
objective in Theorem 1, and the minimizer is precisely the Bayesian posterior p(f, θ|D). When we
restrict the optimization to q ∈ Pprob the solution is of the form q∗(f, θ|D) = p(f |θ, D)δ¯θ(θ|D) for
some ¯θ. This allows us to show that (6) is also equivalent to minimizing the ﬁrst term of Lsemisup(¯θ).
Finally, noting that the regularization function Ω only depends on ¯θ (through q(θ|D) = δ¯θ(θ)), the
form of q∗(f, θ|D) is unchanged after adding Ω. Therefore the choice of Ω reduces to minimizing
the predictive variance with respect to q∗(f |θ, D) = p(f |¯θ, D).

Intuition for variance minimization By minimizing Lsemisup, we trade off maximizing the
likelihood of our observations with minimizing the posterior variance on unlabeled data that we wish
to predict. The posterior variance acts as a proxy for distance with respect to the kernel function
in the deep feature space, and the regularizer is an inductive bias on the structure of the feature
space. Since the deep kernel parameters are jointly learned, the neural net is encouraged to learn a
feature representation in which the unlabeled examples are closer to the labeled examples, thereby

4

reducing the variance on our predictions. If we imagine the labeled data as “supports” for the
surface representing the posterior mean, we are optimizing for embeddings where unlabeled data
tend to cluster around these labeled supports. In contrast, the variance regularizer would not beneﬁt
conventional GP learning since ﬁxed kernels would not allow for adapting the relative distances
between data points.

Another interpretation is that the semi-supervised objective is a regularizer that reduces overﬁtting
to labeled data. The model is discouraged from learning features from labeled data that are not also
useful for making low-variance predictions at unlabeled data points. In settings where unlabeled data
provide additional variation beyond labeled examples, this can improve model generalization.

Training and inference Semi-supervised deep kernel learning scales well with large amounts
of unlabeled data since the unsupervised objective Lvariance naturally decomposes into a sum
over conditionally independent terms. This allows for mini-batch training on unlabeled data with
stochastic gradient descent. Since all of the labeled examples are interdependent, computing exact
gradients for labeled examples requires full batch gradient descent on the labeled data. Therefore,
assuming a constant batch size, each iteration of training requires O(n3) computations for a Cholesky
decomposition, where n is the number of labeled training examples. Performing the GP inference
requires O(n3) one-time cost in the labeled points. However, existing approximation methods based
on kernel interpolation and structured matrices used in DKL can be directly incorporated in SSDKL
and would reduce the training complexity to close to linear in labeled dataset size and inference to
constant time per test point [12, 22]. While DKL is designed for the supervised setting where scaling
to large labeled datasets is a very practical concern, our focus is on semi-supervised settings where
labels are limited but unlabeled data is abundant.

4 Experiments and results

We apply SSDKL to a variety of real-world regression tasks in the inductive semi-supervised learning
setting, beginning with eight datasets from the UCI repository [23]. We also explore the challenging
task of predicting local poverty measures from high-resolution satellite imagery [24]. In our reported
results, we use the squared exponential or radial basis function kernel. We also experimented with
polynomial kernels, but saw generally worse performance. Our SSDKL model is implemented in
TensorFlow [25]. Additional training details are provided in Appendix A.3, and code and data for
reproducing experimental results can be found on GitHub.2

4.1 Baselines

We ﬁrst compare SSDKL to the purely supervised DKL, showing the contribution of unlabeled data.
In addition to the supervised DKL method, we compare against semi-supervised methods including
co-training, consistency regularization, generative modeling, and label propagation. Many of these
methods were originally developed for semi-supervised classiﬁcation, so we adapt them here for
regression. All models, including SSDKL, were trained from random initializations.

COREG, or CO-training REGressors, uses two k-nearest neighbor (kNN) regressors, each of which
generates labels for the other during the learning process [26]. Unlike traditional co-training, which
requires splitting features into sufﬁcient and redundant views, COREG achieves regressor diversity by
using different distance metrics for its two regressors [27].

Consistency regularization methods aim to make model outputs invariant to local input perturbations
[17, 28, 18]. For semi-supervised classiﬁcation, [29] found that VAT and mean teacher were the best
methods using fair evaluation guidelines. Virtual adversarial training (VAT) via local distributional
smoothing (LDS) enforces consistency by training models to be robust to adversarial local input
perturbations [17, 30]. Unlike adversarial training [31], the virtual adversarial perturbation is found
without labels, making semi-supervised learning possible. We adapt VAT for regression by choosing
the output distribution N (hθ(x), σ2) for input x, where hθ : Rd → R is a parameterized mapping
and σ is ﬁxed. Optimizing the likelihood term is then equivalent to minimizing squared error; the LDS
term is the KL-divergence between the model distribution and a perturbed Gaussian (see Appendix

2https://github.com/ermongroup/ssdkl

5

SSDKL COREG

Label Prop

VAE Mean Teacher

VAT SSDKL COREG

Label Prop

VAE Mean Teacher

VAT

Dataset

Skillcraft
Parkinsons
Elevators
Protein
Blog
CTslice
Buzz
Electric

Median

N

3,325
5,875
16,599
45,730
52,397
53,500
583,250
2,049,280

d

18
20
18
9
280
384
77
6

3.44
-2.51
7.99
-3.34
5.65
-22.48
5.59
4.96

1.87
-27.45
-5.22
-2.37
11.15
-12.11
13.80
-126.95

n = 100

5.12
-43.43
2.28
0.77
9.01
-17.12
1.33
-201.18

0.11
-122.23
-22.68
-8.65
8.96
-47.59
-19.26
-285.61

Percent reduction in RMSE compared to DKL

-19.72
-91.54
-27.27
-5.11
7.05
-60.71
-77.08
-399.85

-21.97
-143.60
-31.25
-6.44
1.87
-64.75
-82.66
-513.95

5.97
5.97
6.92
1.23
5.34
5.64
11.33
-13.93

5.81

0.60
-22.50
-25.98
0.89
9.60
2.94
10.41
-154.07

0.75

n = 300

5.78
-51.35
-22.08
2.61
12.44
-2.59
-2.22
-303.21

4.36
-167.93
-53.40
-9.24
8.14
-60.18
-28.65
-460.48

-18.17
-132.68
-82.01
-8.98
7.87
-58.97
-104.88
-627.83

-20.13
-202.79
-63.68
-10.38
9.08
-84.60
-100.82
-828.35

4.20

-3.80

1.05

-20.97

-43.99

-48.00

-2.41

-41.02

-70.49

-74.14

Table 1: Percent reduction in RMSE compared to baseline supervised deep kernel learning (DKL)
model for semi-supervised deep kernel learning (SSDKL), COREG, label propagation, variational auto-
encoder (VAE), mean teacher, and virtual adversarial training (VAT) models. Results are averaged
across 10 trials for each UCI regression dataset. Here N is the total number of examples, d is the
input feature dimension, and n is the number of labeled training examples. Final row shows median
percent reduction in RMSE achieved by using unlabeled data.

A.2). Mean teacher enforces consistency by penalizing deviation from the outputs of a model with
the exponential weighted average of the parameters over SGD iterations [18].

Label propagation deﬁnes a graph structure over the data with edges that deﬁne the probability
for a categorical label to propagate from one data point to another [32]. If we encode this graph
in a transition matrix T and let the current class probabilities be y, then the algorithm iteratively
propagates y ← T y, row-normalizes y, clamps the labeled data to their known values, and repeats
until convergence. We make the extension to regression by letting y be real-valued labels and
normalizing T . As in [32], we use a fully-connected graph and the radial-basis kernel for edge
weights. The kernel scale hyperparameter is chosen using a validation set.

Generative models such as the variational autoencoder (VAE) have shown promise in semi-supervised
classiﬁcation especially for visual and sequential tasks [33, 34, 35, 36]. We compare against a
semi-supervised VAE by ﬁrst learning an unsupervised embedding of the data and then using the
embeddings as input to a supervised multilayer perceptron.

4.2 UCI regression experiments

We evaluate SSDKL on eight regression datasets from the UCI repository. For each dataset, we train
on n = {50, 100, 200, 300, 400, 500} labeled examples, retain 1000 examples as the hold out test set,
and treat the remaining data as unlabeled examples. Following [29], the labeled data is randomly split
90-10 into training and validation samples, giving a realistically small validation set. For example,
for n = 100 labeled examples, we use 90 random examples for training and the remaining 10 for
validation in every random split. We report test RMSE averaged over 10 trials of random splits to
combat the small data sizes. All kernel hyperparameters are optimized directly through Lsemisup, and
we use the validation set for early stopping to prevent overﬁtting and for selecting α ∈ {0.1, 1, 10}.
We did not use approximate GP procedures in our SSDKL or DKL experiments, so the only difference
is the addition of the variance regularizer. For all combinations of input feature dimensions and
labeled data sizes in the UCI experiments, each SSDKL trial (including all training and testing) ran
on the order of minutes.

Following [20], we choose a neural network with a similar [d-100-50-50-2] architecture and two-
dimensional embedding. Following [29], we use this same base model for all deep models, including
SSDKL, DKL, VAT, mean teacher, and the VAE encoder, in order to make results comparable across
methods. Since label propagation creates a kernel matrix of all data points, we limit the number of
unlabeled examples for label propagation to a maximum of 20000 due to memory constraints. We
initialize labels in label propagation with a kNN regressor with k = 5 to speed up convergence.

Table 1 displays the results for n = 100 and n = 300; full results are included in Appendix A.3.
SSDKL gives a 4.20% and 5.81% median RMSE improvement over the supervised DKL in the
n = 100, 300 cases respectively, superior to other semi-supervised methods adapted for regression.
A Wilcoxon signed-rank test versus DKL shows signiﬁcance at the p = 0.05 level for at least one
labeled training set size for all 8 datasets.

6

Figure 2: Left: Average test RMSE vs. number of labeled examples for UCI Elevators dataset,
n = {50, 100, 200, 300, 400, 500}. SSDKL generally outperforms supervised DKL, co-training
regressors (COREG), and virtual adversarial training (VAT). Right: SSDKL performance on poverty
prediction (Section 4.3) as a function of α, which controls the trade-off between labeled and unlabeled
objectives, for n = 300. The dotted lines plot the performance of DKL and COREG. All results
averaged over 10 trials. In both panels, shading represents one standard deviation.

The same learning rates and initializations are used across all UCI datasets for SSDKL. We use
learning rates of 1 × 10−3 and 0.1 for the neural network and GP parameters respectively and
initialize all GP parameters to 1. In Fig. 2 (right), we study the effect of varying α to trade off
between maximizing the likelihood of labeled data and minimizing the variance of unlabeled data. A
large α emphasizes minimization of the predictive variance while a small α focuses on ﬁtting labeled
data. SSDKL improves on DKL for values of α between 0.1 and 10.0, indicating that performance
is not overly reliant on the choice of this hyperparameter. Fig. 2 (left) compares SSDKL to purely
supervised DKL, COREG, and VAT as we vary the labeled training set size. For the Elevators dataset,
DKL is able to close the gap on SSDKL as it gains access to more labeled data. Relative to the other
methods, which require more data to ﬁt neural network parameters, COREG performs well in the
low-data regime.

Surprisingly, COREG outperformed SSDKL on the Blog, CTslice, and Buzz datasets. We found that
these datasets happen to be better-suited for nearest neighbors-based methods such as COREG. A
kNN regressor using only the labeled data outperformed DKL on two of three datasets for n = 100,
beat SSDKL on all three for n = 100, beat DKL on two of three for n = 300, and beat SSDKL on
one of three for n = 300. Thus, the kNN regressor is often already outperforming SSDKL with only
labeled data—it is unsurprising that SSDKL is unable to close the gap on a semi-supervised nearest
neighbors method like COREG.

Representation learning To gain some intuition about how the unlabeled data helps in the learning
process, we visualize the neural network embeddings learned by the DKL and SSDKL models on the
Skillcraft dataset. In Fig. 3 (left), we ﬁrst train DKL on n = 100 labeled training examples and plot
the two-dimensional neural network embedding that is learned. In Fig. 3 (right), we train SSDKL
on n = 100 labeled training examples along with m = 1000 additional unlabeled data points and
plot the resulting embedding. In the left panel, DKL learns a poor embedding—different colors
representing different output magnitudes are intermingled. In the right panel, SSDKL is able to use
the unlabeled data for regularization, and learns a better representation of the dataset.

4.3 Poverty prediction

High-resolution satellite imagery offers the potential for cheap, scalable, and accurate tracking of
changing socioeconomic indicators. In this task, we predict local poverty measures from satellite
images using limited amounts of poverty labels. As described in [2], the dataset consists of 3, 066
villages across ﬁve Africa countries: Nigeria, Tanzania, Uganda, Malawi, and Rwanda. These include

7

Figure 3: Left: Two-dimensional embeddings learned by supervised deep kernel learning (DKL)
model on the Skillcraft dataset using n = 100 labeled training examples. The colorbar shows the
magnitude of the normalized outputs. Right: Embeddings learned by semi-supervised deep kernel
learning (SSDKL) model using n = 100 labeled examples plus an additional m = 1000 unlabeled
examples. By using unlabeled data for regularization, SSDKL learns a better representation.

Percent reduction in RMSE (n = 300)

Country

Spatial SSDKL SSDKL

DKL

Malawi
Nigeria
Tanzania
Uganda
Rwanda

Median

13.7
17.9
10.0
25.2
27.0

17.9

16.4
4.6
15.5
12.1
25.4

15.5

15.7
1.7
9.2
13.8
21.3

13.8

Table 2: Percent RMSE reduction in a poverty measure prediction task compared to baseline ridge
regression model used in [2]. SSDKL and DKL models use only satellite image data. Spatial SSDKL
incorporates both location and image data through kernel composition. Final row shows median
RMSE reduction of each model averaged over 10 trials.

some of the poorest countries in the world (Malawi and Rwanda) as well as some that are relatively
better off (Nigeria), making for a challenging and realistically diverse problem.

In this experiment, we use n = 300 labeled satellite images for training. With such a small dataset,
we can not expect to train a deep convolutional neural network (CNN) from scratch. Instead we take
a transfer learning approach as in [24], extracting 4096-dimensional visual features and using these
as input. More details are provided in Appendix A.5.

Incorporating spatial information In order to highlight the usefulness of kernel composition, we
explore extending SSDKL with a spatial kernel. Spatial SSDKL composes two kernels by summing
an image feature kernel and a separate location kernel that operates on location coordinates (lat/lon).
By treating them separately, it explicitly encodes the knowledge that location coordinates are spatially
structured and distinct from image features.

As shown in Table 2, all models outperform the baseline state-of-the-art ridge regression model from
[2]. Spatial SSDKL signiﬁcantly outperforms the DKL and SSDKL models that use only image
features. Spatial SSDKL outperforms the other models by directly modeling location coordinates
as spatial features, showing that kernel composition can effectively incorporate prior knowledge of
structure.

8

5 Related work

[37] introduced deep Gaussian processes, which stack GPs in a hierarchy by modeling the outputs of
one layer with a Gaussian process in the next layer. Despite the suggestive name, these models do not
integrate deep neural networks and Gaussian processes.

[12] proposed deep kernel learning, combining neural networks with the non-parametric ﬂexibility
of GPs and training end-to-end in a fully supervised setting. Extensions have explored approximate
inference, stochastic gradient training, and recurrent deep kernels for sequential data [22, 38, 39].

Our method draws inspiration from transductive experimental design, which chooses the most
informative points (experiments) to measure by seeking data points that are both hard to predict and
informative for the unexplored test data [40]. Similar prediction uncertainty approaches have been
explored in semi-supervised classiﬁcation models, such as minimum entropy and minimum variance
regularization, which can now also be understood in the posterior regularization framework [7, 41].

Recent work in generative adversarial networks (GANs) [33], variational autoencoders (VAEs) [34],
and other generative models have achieved promising results on various semi-supervised classiﬁcation
tasks [35, 36]. However, we ﬁnd that these models are not as well-suited for generic regression tasks
such as in the UCI repository as for audio-visual tasks.

Consistency regularization posits that the model’s output should be invariant to reasonable perturba-
tions of the input [17, 28, 18]. Combining adversarial training [31] with consistency regularization,
virtual adversarial training uses a label-free regularization term that allows for semi-supervised
training [17]. Mean teacher adds a regularization term that penalizes deviation from a exponential
weighted average of the parameters over SGD iterations [18]. For semi-supervised classiﬁcation, [29]
found that VAT and mean teacher were the best methods across a series of fair evaluations.

Label propagation deﬁnes a graph structure over the data points and propagates labels from labeled
data over the graph. The method must assume a graph structure and edge distances on the input
feature space without the ability to adapt the space to the assumptions. Label propagation is also
subject to memory constraints since it forms a kernel matrix over all data points, requiring quadratic
space in general, although sparser graph structures can reduce this to a linear scaling.

Co-training regressors trains two kNN regressors with different distance metrics that label each others’
unlabeled data. This works when neighbors in the given input space have similar target distributions,
but unlike kernel learning approaches, the features are ﬁxed. Thus, COREG cannot adapt the space to
a misspeciﬁed distance measure. In addition, as a fully nonparametric method, inference requires
retaining the full dataset.

Much of the previous work in semi-supervised learning is in classiﬁcation and the assumptions do
not generally translate to regression. Our experiments show that SSDKL outperforms other adapted
semi-supervised methods in a battery of regression tasks.

6 Conclusions

Many important problems are challenging because of the limited availability of training data, making
the ability to learn from unlabeled data critical. In experiments with UCI datasets and a real-world
poverty prediction task, we ﬁnd that minimizing posterior variance can be an effective way to
incorporate unlabeled data when labeled training data is scarce. SSDKL models are naturally suited
for many real-world problems, as spatial and temporal structure can be explicitly modeled through the
composition of kernel functions. While our focus is on regression problems, we believe the SSDKL
framework is equally applicable to classiﬁcation problems—we leave this to future work.

Acknowledgements

This research was supported by NSF (#1651565, #1522054, #1733686), ONR, Sony, and FLI. NJ was
supported by the Department of Defense (DoD) through the National Defense Science & Engineering
Graduate Fellowship (NDSEG) Program. We are thankful to Volodymyr Kuleshov and Aditya Grover
for helpful discussions.

9

References

[1] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classiﬁcation with deep
convolutional neural networks. In Advances in neural information processing systems, pages
1097–1105, 2012.

[2] Neal Jean, Marshall Burke, Michael Xie, W Matthew Davis, David B Lobell, and Stefano Ermon.
Combining satellite imagery and machine learning to predict poverty. Science, 353(6301):790–
794, 2016.

[3] Jiaxuan You, Xiaocheng Li, Melvin Low, David Lobell, and Stefano Ermon. Deep gaussian
process for crop yield prediction based on remote sensing data. In AAAI, pages 4559–4566,
2017.

[4] Barak Oshri, Annie Hu, Peter Adelson, Xiao Chen, Pascaline Dupas, Jeremy Weinstein, Marshall
Burke, David Lobell, and Stefano Ermon. Infrastructure quality assessment in africa using
satellite imagery and deep learning. Proc. 24th ACM SIGKDD Conference, 2018.

[5] Xiaojin Zhu and Andrew B Goldberg. Introduction to semi-supervised learning. Synthesis

lectures on artiﬁcial intelligence and machine learning, 3(1):1–130, 2009.

[6] Rui Shu, Hung H Bui, Hirokazu Narui, and Stefano Ermon. A DIRT-T approach to unsupervised

domain adaptation. In International Conference on Learning Representations, 2018.

[7] Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In

Advances in neural information processing systems, pages 529–536, 2004.

[8] Olivier Chapelle and Alexander Zien. Semi-supervised classiﬁcation by low density separation.

In AISTATS, pages 57–64, 2005.

[9] Aarti Singh, Robert Nowak, and Xiaojin Zhu. Unlabeled data: Now it helps, now it doesn’t. In

Advances in neural information processing systems, pages 1513–1520, 2009.

[10] Volodymyr Kuleshov and Stefano Ermon. Deep hybrid models: Bridging discriminative and

generative approaches. In Proceedings of the Conference on Uncertainty in AI (UAI), 2017.

[11] Russell Ren, Hongyu Stewart, Jiaming Song, Volodymyr Kuleshov, and Stefano Ermon. Adver-
sarial constraint learning for structured prediction. Proc. 27th International Joint Conference
on Artiﬁcial Intelligence, 2018.

[12] Andrew Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, and Eric P. Xing. Deep kernel

learning. The Journal of Machine Learning Research, 2015.

[13] Stephan Eissman and Stefano Ermon. Bayesian optimization and attribute adjustment. Proc.

34th Conference on Uncertainty in Artiﬁcial Intelligence, 2018.

[14] Kuzman Ganchev, Jennifer Gillenwater, Ben Taskar, et al. Posterior regularization for structured
latent variable models. Journal of Machine Learning Research, 11(Jul):2001–2049, 2010.
[15] Jun Zhu, Ning Chen, and Eric P Xing. Bayesian inference with posterior regularization and
applications to inﬁnite latent svms. Journal of Machine Learning Research, 15(1):1799–1847,
2014.

[16] Rui Shu, Hung H Bui, Shengjia Zhao, Mykel J Kochenderfer, and Stefano Ermon. Amortized

inference regularization. NIPS, 2018.

[17] Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, Ken Nakae, and Shin Ishii. Distributional

smoothing with virtual adversarial training. arXiv preprint arXiv:1507.00677, 2015.

[18] Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged
consistency targets improve semi-supervised deep learning results. In I. Guyon, U. V. Luxburg,
S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural
Information Processing Systems 30, pages 1195–1204. Curran Associates, Inc., 2017.

[19] Andrew Arnold, Ramesh Nallapati, and William W. Cohen. A comparative study of methods for
transductive transfer learning. Proc. Seventh IEEE Int’,l Conf. Data Mining Workshops, 2007.
[20] Andrew Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, and Eric P Xing. Deep kernel
learning. In Proceedings of the 19th International Conference on Artiﬁcial Intelligence and
Statistics, pages 370–378, 2016.

[21] Carl Edward Rasmussen and Christopher KI Williams. Gaussian processes for machine learning.

The MIT Press, 2006.

10

[22] Andrew Gordon Wilson and Hannes Nickisch. Kernel interpolation for scalable structured
gaussian processes (KISS-GP). In Proceedings of the 32nd International Conference on Machine
Learning, ICML 2015, Lille, France, 6-11 July 2015, pages 1775–1784, 2015.

[23] M. Lichman. UCI machine learning repository, 2013.

[24] Michael Xie, Neal Jean, Marshall Burke, David Lobell, and Stefano Ermon. Transfer learning
from deep features for remote sensing and poverty mapping. AAAI Conference on Artiﬁcial
Intelligence, 2016.

[25] Martın Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro,
Greg S Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, et al. Tensorﬂow: Large-scale
machine learning on heterogeneous distributed systems. arXiv preprint arXiv:1603.04467,
2016.

[26] Zhi-Hua Zhou and Ming Li. Semi-supervised regression with co-training. In IJCAI, volume 5,

pages 908–913, 2005.

[27] Avrim Blum and Tom Mitchell. Combining labeled and unlabeled data with co-training. In
Proceedings of the eleventh annual conference on Computational learning theory, pages 92–100.
ACM, 1998.

[28] Samuli Laine and Timo Aila. Temporal ensembling for semi-supervised learning. ICLR 2017,

2017.

[29] Augustus Odena, Avital Oliver, Colin Raffel, Ekin Dogus Cubuk, and Ian Goodfellow. Realistic

evaluation of semi-supervised learning algorithms. 2018.

[30] Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual adversarial train-
ing: a regularization method for supervised and semi-supervised learning. arXiv preprint
arXiv:1704.03976, 2017.

[31] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversar-

ial examples. arXiv preprint arXiv:1412.6572, 2014.

[32] Xiaojin Zhu and Zoubin Ghahramani. Learning from labeled and unlabeled data with label

propagation. Technical report, 2002.

[33] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil
Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural
information processing systems, pages 2672–2680, 2014.

[34] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint

arXiv:1312.6114, 2013.

[35] Lars Maaløe, Casper Kaae Sønderby, Søren Kaae Sønderby, and Ole Winther. Auxiliary deep

generative models. arXiv preprint arXiv:1602.05473, 2016.

[36] Antti Rasmus, Mathias Berglund, Mikko Honkala, Harri Valpola, and Tapani Raiko. Semi-
supervised learning with ladder networks. In Advances in Neural Information Processing
Systems, pages 3546–3554, 2015.

[37] Andreas C. Damianou and Neil D. Lawrence. Deep gaussian processes. The Journal of Machine

Learning Research, 2013.

[38] Andrew G Wilson, Zhiting Hu, Ruslan R Salakhutdinov, and Eric P Xing. Stochastic variational
deep kernel learning. In Advances in Neural Information Processing Systems, pages 2586–2594,
2016.

[39] Maruan Al-Shedivat, Andrew Gordon Wilson, Yunus Saatchi, Zhiting Hu, and Eric P Xing.
Learning scalable deep kernels with recurrent structure. arXiv preprint arXiv:1610.08936, 2016.

[40] Kai Yu, Jinbo Bi, and Volker Tresp. Active learning via transductive experimental design. The

International Conference on Machine Learning (ICML), 2006.

[41] Chenyang Zhao and Shaodan Zhai. Minimum variance semi-supervised boosting for multi-
label classiﬁcation. In 2015 IEEE Global Conference on Signal and Information Processing
(GlobalSIP), pages 1342–1346. IEEE, 2015.

[42] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. 3rd International

Conference for Learning Representations, 2015.

11

[43] Morten Jerven. Poor numbers: how we are misled by African development statistics and what

to do about it. Cornell University Press, 2013.

[44] ICF International. Demographic and health surveys (various) [datasets], 2015.
[45] Deon Filmer and Lant H Pritchett. Estimating wealth effects without expenditure data—or tears:
An application to educational enrollments in states of india*. Demography, 38(1):115–132,
2001.

A Appendix

A.1 Posterior regularization

Proof of Theorem 1. Let D = (XL, yL, XU ) be a collection of observed data. Let X = (XL, XU )
be the observed input data points. As in [15], we assume that F is a complete separable metric space
and Π is an absolutely continuous probability measure (with respect to background measure η) on
(F, B(F)), where B(F) is the the Borel σ-algebra, such that a density π exists where dΠ = πdη. Let
Θ be a space of parameters to the model, where we treat θ ∈ Θ as random variables. With regards to
the notation in the RegBayes framework, the model is the pair M = (f, θ). We assume as in [15] that
the likelihood function P (·|M ) is the likelihood distribution which is dominated by a σ-ﬁnite measure
λ for all M with positive density, such that a density p(·|M ) exists where dP (·|M ) = p(·|M )dλ.

We would like to compute the posterior distribution

p(f, θ|D) =

p(D|f, θ)π(f, θ)
f,θ p(f, θ, D)dη(f, θ)

(cid:82)

which involves an intractable integral.

We claim that the solution of the following optimization problem is precisely the Bayesian posterior
p(f, θ|D):

inf
q(f,θ|D)

DKL(q(f, θ|D)(cid:107)π(f, θ)) −

q(f, θ|D) log p(D|f, θ)dη(f, θ).

By adding the constant log p(D) to the objective,

DKL(q(f, θ|D)(cid:107)π(f, θ)) −

q(f, θ|D) log p(D|f, θ)dη(f, θ) + log p(D)

(cid:90)

f,θ

(cid:90)

f,θ

inf
q(f,θ|D)

= inf

q(f,θ|D)

= inf

q(f,θ|D)

(cid:90)

(cid:90)

f,θ

f,θ

q(f, θ|D) log

dη(f, θ) + log p(D)

q(f, θ|D)
p(f, θ, D)

q(f, θ|D)
p(f, θ|D)

q(f, θ|D) log

dη(f, θ)

= inf

DKL(q(f, θ|D)(cid:107)p(f, θ|D))

q(f,θ|D)

= inf

L(q(f, θ|D)),

q(f,θ|D)

where by deﬁnition p(f, θ, D) = p(D|f, θ)π(f, θ) and we see that the objective is minimized when
q(f, θ|D) = p(f, θ|D) as claimed. We note that the objective is equivalent to the ﬁrst term of the
RegBayes objective (Section 2.3).
We introduce a variational approximation q ∈ Pprob which approximates p(f, θ|D), where Pprob =
{q : q(f, θ|D) = q(f |θ, D)δ¯θ(θ|D)} is the family of approximating distributions such that q(θ|D) is
restricted to be a Dirac delta centered on ¯θ. When we restrict q ∈ Pprob,

DKL(q(f, θ|D)(cid:107)π(f, θ)) −

q(f, θ|D) log p(D|f, θ)dη(f, θ)

δ ¯θ(θ)

q(f |θ, D)

log

(cid:18)

q(f |θ, D)δ ¯θ(θ)
p(f, θ|D)

(cid:19)

dη(f, θ) + O(1)

(cid:90)

f,θ

δ ¯θ(θ)

DKL(q(f |θ, D)(cid:107)p(f |θ, D)) + log δ ¯θ(θ) − log p(θ|D)

dη(θ) + O(1)

(14)

(cid:19)

(cid:19)

= inf

q(f |θ,D), ¯θ

δ ¯θ(θ)

DKL(q(f |θ, D)(cid:107)p(f |θ, D)) − log p(θ|D)

dη(θ) + O(1)

(15)

inf
q(f,θ|D)∈Pprob

= inf

q(f |θ,D), ¯θ

= inf

q(f |θ,D), ¯θ

(cid:90)

θ

(cid:90)

θ

(cid:90)

θ

(cid:90)

f
(cid:18)

(cid:18)

(7)

(8)

(9)

(10)

(11)

(12)

(13)

12

where in equation (13) we use the form from equation (9), and in equation (15) we note that
(cid:82)
θ δ¯θ(θ) log δ¯θ(θ) does not vary with ¯θ or q, and can be removed from the optimization. For every
¯θ, the optimizing distribution is q∗(f |θ, D) = p(f |¯θ, D), which is the Bayesian posterior given the
model parameters. Substituting this optimal value into (15),
(cid:18)

(cid:19)

(cid:90)

DKL(q∗(f |θ, D)(cid:107)p(f |θ, D)) − log p(θ|D)

dη(θ) + O(1)

inf
q(f |θ,D),¯θ

δ¯θ(θ)

θ

(cid:90)

θ
(cid:90)

θ
(cid:90)

θ

= inf
¯θ

−

= inf
¯θ

−

= inf
¯θ
= inf
¯θ
= inf
¯θ

δ¯θ(θ) log p(θ|D)dη(θ) + O(1)

δ¯θ(θ)(log p(θ|X, yL) + log p(yL|X))dη(θ) + O(1)

−

δ¯θ(θ) log p(yL, θ|X)dη(θ) + O(1)

− log p(yL|¯θ, X) − log p(¯θ|X) + O(1)

− log p(yL|¯θ, X) + O(1)

(16)

(17)

(18)

(19)

(20)

(21)

using that DKL(q∗(f |θ, D)(cid:107)p(f |θ, D)) = 0 in (17) and (cid:82)
θ δ¯θ(θ) log p(yL|X) is a constant. We also
treat log p(¯θ|X) as a constant since ¯θ is independent of X without any observations yL, and we
choose a uniform prior over ¯θ. The optimization problem over ¯θ reﬂects maximizing the likelihood of
the data.

We deﬁned the regularization function as

Ω(q(f, θ|D)) = α(cid:48)

p(f |θ, D)q(θ|D)(f (XU )i − Ep[f (XU )i])2dη(f, θ)

.

Note that the regularization function only depends on ¯θ, through q(θ | D) = δ¯θ(θ). Therefore
the optimal post-data posterior q in the regularized objective is still in the form q∗(f, θ|D) =
p(f |θ, D)δ¯θ(θ), and q is modiﬁed by the regularization function only through δ¯θ(θ).
Thus, using the optimal post-data posterior q∗(f, θ|D) = p(f |θ, D)δ¯θ(θ), the RegBayes problem is
equivalent to the objective optimized by SSDKL:

inf
q(f,θ|D)∈Pprob

L(q(f, θ|D)) + Ω(q(f, θ|D))

− log p(yL|¯θ, X) + α(cid:48)

(f (XU )i − Ep[f (XU )i])2

δ ¯θ(θ)p(f |θ, D)dη(f, θ)

+ O(1)

(cid:90)

θ

− log p(yL|¯θ, X) + α(cid:48)

p(f |¯θ, D)(f (XU )i − Ep[f (XU )i])2dη(f ) + O(1)

(cid:19)

(cid:19)

m
(cid:88)

(cid:18) (cid:90)

i=1

f,θ

m
(cid:88)

(cid:18)(cid:90)

f

i=1
m
(cid:88)

(cid:90)

f

i=1
m
(cid:88)

i=1

− log p(yL|¯θ, X) + α(cid:48)

Varp(f ((XU )i)) + O(1)

Lsemisup(¯θ) + O(1).

A.2 Virtual Adversarial Training

Virtual adversarial training (VAT) is a general training mechanism which enforces local distributional
smoothness (LDS) by optimizing the model to be less sensitive to adversarial perturbations of the
input [17]. The VAT objective is to augment the marginal likelihood with an LDS objective:

= inf
¯θ

= inf
¯θ

= inf
¯θ

= inf
¯θ

where

1
n

n
(cid:88)

i=1

log p(yL|XL, ¯θ) +

LDS(Xi, ¯θ)

λ
n

n
(cid:88)

i=1

LDS(Xi, ¯θ) = −∆KL(rv-adv(i), Xi, ¯θ)

13

Dataset

Skillcraft
Parkinsons
Elevators
Protein
Blog
CTslice
Buzz
Electric

Median

N

3,325
5,875
16,599
45,730
52,397
53,500
583,250
2,049,280

d

18
20
18
9
280
384
77
6

5.67
-8.34
4.92
-0.54
7.69
-13.92
5.56
32.41

5.24

8.52
-18.18
5.83
5.05
8.66
-2.14
22.21
-34.82

5.44

Percent reduction in RMSE compared to DKL

SSDKL COREG

Label Prop

VAT Mean Teacher

VAE

n = 50

7.60
-32.85
11.28
7.52
8.71
-17.83
18.52
-64.45

3.92
-83.51
-8.19
0.22
8.40
-36.95
1.64
-105.74

-12.01
-69.98
-20.91
5.51
6.89
-35.45
-62.65
-179.13

-19.93
-95.57
-16.35
4.57
6.26
-33.24
-41.81
-201.51

7.56

-3.99

-28.18

-26.59

Table 3: Percent reduction in RMSE compared to baseline supervised deep kernel learning (DKL)
model for semi-supervised deep kernel learning (SSDKL), COREG, label propagation, variational auto-
encoder (VAE), mean teacher, and virtual adversarial training (VAT) models. Results are averaged
across 10 trials for each UCI regression dataset. Here N is the total number of examples, d is the
input feature dimension, and n = 50 is the number of labeled training examples. Final row shows
median percent reduction in RMSE achieved by using unlabeled data.

∆KL(r, Xi, ¯θ) = DKL(p(y|Xi, ¯θ)(cid:107)p(y|Xi + r, ¯θ))

rv-adv(i) = arg max

{∆KL(r, Xi, ¯θ); (cid:107)r(cid:107)2 ≤ (cid:15)}

r

and y is the output of the model given the input Xi (or perturbed input Xi + r) and parameters
¯θ. Note that the LDS objective does not require labels, so that unlabeled data can be incorporated.
The experiments in the original paper are for classiﬁcation, although VAT is general. We use VAT
for regression by choosing p(y|Xi, ¯θ) = N (h¯θ(Xi), σ2) where h¯θ : Rd → RH is a parameterized
mapping (a neural network), and σ is ﬁxed. Optimizing the likelihood term is then equivalent to
minimizing the squared error and the LDS term is the KL-divergence between the model’s Gaussian
distribution and a perturbed Gaussian distribution, which is also in the form of a squared difference.
To calculate the adversarial perturbation rv-adv(i), ﬁrst we take the second-order Taylor approximation
at r = 0 of ∆KL(r, Xi, ¯θ), assuming that p(y|Xi, ¯θ) is twice differentiable:

DKL(p(y|Xi, ¯θ)(cid:107)p(y|Xi + r, ¯θ) ≈

(22)
where Hi = ∇∇rDKL(p(y|Xi, ¯θ)|r=0. Note that the ﬁrst derivative is zero since DKL(p(y|Xi, ¯θ)
is minimized at r = 0. Therefore rv-adv(i) can be approximated with the ﬁrst dominant eigenvector of
the Hi scaled to norm (cid:15). The eigenvector calculation is done via a ﬁnite-difference approximation to
the power iteration method. As in [17], one step of the ﬁnite-difference approximation was used in all
of our experiments.

rT Hir

1
2

A.3 Training details

In our reported results, we use the standard squared exponential or radial basis function (RBF) kernel,

k(xi, xj) = φ2

f exp

−

(cid:18)

(cid:107)xi − xj(cid:107)2
2
2φ2
l

(cid:19)

,

f and φ2

where φ2
l represent the signal variance and characteristic length scale. We also experimented
i xj +φl)p, p ∈ Z+, but found that performance generally
with polynomial kernels, k(xi, xj) = (φf xT
decreased. To enforce positivity constraints on the kernel parameters and positive deﬁniteness of
the covariance, we train these parameters in the log-domain. Although the information capacity
of a non-parametric model increases with the dataset size, the marginal likelihood automatically
constrains model complexity without additional regularization [21]. The parametric neural networks
are regularized with L2 weight decay to reduce overﬁtting, and models are implemented and trained
in TensorFlow using the ADAM optimizer [25, 42].

A.4 UCI results

In section 4.2 of the main text, we include results on the UCI datasets for n = 100 and n = 300.
Here we include the rest of the experimental results, for n ∈ {50, 200, 400, 500}. For n = 50, we

14

Percent reduction in RMSE compared to DKL

SSDKL COREG

Label Prop

VAT Mean Teacher

VAE

n = 200

7.96
-48.93
-5.51
1.99
14.78
-7.82
-2.93
-292.88

4.43
-160.51
-33.00
-8.96
14.01
-43.25
-30.94
-432.04

-22.26
-132.12
-32.94
-8.57
8.09
-67.95
-106.85
-580.78

-20.11
-195.88
-42.74
-8.65
7.88
-55.53
-103.69
-722.28

Dataset

Skillcraft
Parkinsons
Elevators
Protein
Blog
CTslice
Buzz
Electric

Median

N

3,325
5,875
16,599
45,730
52,397
53,500
583,250
2,049,280

d

18
20
18
9
280
384
77
6

7.79
1.45
12.80
2.49
4.16
-11.96
4.78
-2.72

0.51
-29.86
-10.23
-0.56
9.87
-3.05
8.60
-166.86

3.32

-1.81

-4.22

-31.97

-50.45

-49.13

Table 4: See Table 1 above and section 4.2 in the main text for details, results for n = 200 labeled
examples.

Percent reduction in RMSE compared to DKL

SSDKL COREG

Label Prop

VAT Mean Teacher

VAE

Dataset

Skillcraft
Parkinsons
Elevators
Protein
Blog
CTslice
Buzz
Electric

Median

N

3,325
5,875
16,599
45,730
52,397
53,500
583,250
2,049,280

d

18
20
18
9
280
384
77
6

-0.21
7.92
-1.19
-1.57
-2.47
15.21
3.94
-5.47

-0.70

-5.28
-20.65
-38.84
-0.02
4.48
5.35
3.37
-159.98

-2.65

n = 400

0.76
-75.10
-32.25
0.35
6.05
7.38
-9.86
-319.97

-2.56
-191.56
-72.48
-12.02
5.28
-42.73
-40.47
-504.63

-34.21
-154.43
-83.24
-10.90
0.60
-68.37
-118.13
-680.03

-33.01
-234.07
-72.90
-11.59
-0.68
-66.05
-119.55
-866.89

-4.76

-41.60

-75.81

-69.47

Table 5: See Table 1 above and section 4.2 in the main text for details, results for n = 400 labeled
examples.

note that both COREG and label propagation perform quite well — we expect that this is true because
these methods do not require learning neural network parameters from data.

A.5 Poverty prediction

High-resolution satellite imagery offers the potential for cheap, scalable, and accurate tracking of
changing socioeconomic indicators. The United Nations has set 17 Sustainable Development Goals
(SDGs) for the year 2030—the ﬁrst of these is the worldwide elimination of extreme poverty, but a
lack of reliable data makes it difﬁcult to distribute aid and target interventions effectively. Traditional
data collection methods such as large-scale household surveys or censuses are slow and expensive,
requiring years to complete and costing billions of dollars [43]. Because data on the outputs that we
care about are scarce, it is difﬁcult to train models on satellite imagery using traditional supervised
methods. In this task, we attempt to predict local poverty measures from satellite images using limited
amounts of poverty labels. As described in [2], the dataset consists of 3, 066 villages across ﬁve
Africa countries: Nigeria, Tanzania, Uganda, Malawi, and Rwanda. These countries include some of
the poorest in the world (Malawi, Rwanda) as well as regions of Africa that are relatively better off
(Nigeria), making for a challenging and realistically diverse problem. The raw satellite inputs consist
of 400 × 400 pixel RGB satellite images downloaded from Google Static Maps at zoom level 16,
corresponding to 2.4 m ground resolution. The target variable that we attempt to predict is a wealth
index provided in the publicly available Demographic and Health Surveys (DHS) [44, 45].

15

Percent reduction in RMSE compared to DKL

SSDKL COREG

Label Prop

VAT Mean Teacher

VAE

Dataset

Skillcraft
Parkinsons
Elevators
Protein
Blog
CTslice
Buzz
Electric

Median

N

3,325
5,875
16,599
45,730
52,397
53,500
583,250
2,049,280

d

18
20
18
9
280
384
77
6

-5.59
9.42
0.82
-1.19
3.37
5.80
7.38
-8.71

2.09

-10.35
-15.48
-43.95
-3.36
7.58
3.50
2.83
-136.52

-6.85

n = 500

-6.64
-56.79
-39.11
-3.24
12.85
-4.35
-13.52
-301.95

-9.11
-198.14
-80.17
-17.73
10.56
-73.67
-42.03
-472.13

-31.52
-157.34
-93.15
-14.64
2.23
-86.25
-137.47
-635.63

-32.09
-240.18
-96.91
-16.60
5.01
-115.66
-112.36
-836.90

-10.08

-57.85

-89.70

-104.63

Table 6: See Table 1 above and section 4.2 in the main text for details, results for n = 500 labeled
examples.

16

