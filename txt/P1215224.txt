8
1
0
2
 
c
e
D
 
3
 
 
]
L
M

.
t
a
t
s
[
 
 
3
v
1
2
3
5
0
.
9
0
7
1
:
v
i
X
r
a

Learning Functional Causal Models with Generative Neural
Networks ∗

Olivier Goudet †
TAU, LRI, CNRS, INRIA, Universit´e Paris-Sud
Gif-Sur-Yvette, 91190, France
Diviyan Kalainathan†
TAU, LRI, CNRS, INRIA, Universit´e Paris-Sud
Gif-Sur-Yvette, 91190, France

Philippe Caillou
TAU, LRI, CNRS, INRIA, Universit´e Paris-Sud
Gif-Sur-Yvette, 91190, France

Isabelle Guyon
TAU, LRI, CNRS, INRIA, Universit´e Paris-Sud
Gif-Sur-Yvette, 91190, France

David Lopez-Paz
Facebook AI Research
Paris, 75002, France

Mich`ele Sebag
TAU, LRI, CNRS, INRIA, Universit´e Paris-Sud
Gif-Sur-Yvette, 91190, France

OLIVIER.GOUDET@INRIA.FR

DIVIYAN.KALAINATHAN@INRIA.FR

CAILLOU@LRI.FR

ISABELLE.GUYON@U-PSUD.FR

DLP@FB.FR

MICHELE.SEBAG@LRI.FR

Abstract
We introduce a new approach to functional causal modeling from observational data, called
Causal Generative Neural Networks (CGNN). CGNN leverages the power of neural networks
to learn a generative model of the joint distribution of the observed variables, by minimizing the
Maximum Mean Discrepancy between generated and observed data. An approximate learning
criterion is proposed to scale the computational cost of the approach to linear complexity in the
number of observations. The performance of CGNN is studied throughout three experiments.
Firstly, CGNN is applied to cause-effect inference, where the task is to identify the best causal
hypothesis out of “X
X”. Secondly, CGNN is applied to the problem of iden-
tifying v-structures and conditional independences. Thirdly, CGNN is applied to multivariate
functional causal modeling: given a skeleton describing the direct dependences in a set of ran-
dom variables X = [X1, . . . , Xd], CGNN orients the edges in the skeleton to uncover the directed
acyclic causal graph describing the causal structure of the random variables. On all three tasks,
CGNN is extensively assessed on both artiﬁcial and real-world data, comparing favorably to
the state-of-the-art. Finally, CGNN is extended to handle the case of confounders, where latent
variables are involved in the overall causal model.

Y ” and “Y

→

→

Keywords: generative neural networks

causal structure discovery

cause-effect pair problem

functional causal models

structural equation models

·

·

·

·

∗∗ This article is a preprint of the chapter with the same name in the book Explainable and Interpretable Models
in Computer Vision and Machine Learning. Springer Series on Challenges in Machine Learning. 2018. Cham:
Springer International Publishing. Editors: Hugo Jair Escalante, Sergio Escalera, Isabelle Guyon, Xavier Bar´o and
Ya ‘gmur G¨uc¸l¨ut¨urk. https://doi.org/10.1007/978-3-319-98131-4
† First joint author. Rest of authors ordered alphabetically.

1

1. Introduction

Deep learning models have shown extraordinary predictive abilities, breaking records in im-
age classiﬁcation (Krizhevsky et al., 2012), speech recognition (Hinton et al., 2012), language
translation (Cho et al., 2014), and reinforcement learning (Silver et al., 2016). However, the
predictive focus of black-box deep learning models leaves little room for explanatory power.
More generally, current machine learning paradigms offer no protection to avoid mistaking cor-
relation by causation. For example, consider the prediction of target variable Y given features
X and Z, assuming that the underlying generative process is described by the equations:

X, EY , EZ ∼
←

Y

Z

←

Uniform(0, 1),
0.5X + EY ,
Y + EZ,

with (EY , EZ) additive noise variables. The above model states that the values of Y are
computed as a function of the values of X (we say that X causes Y ), and that the values of Z are
computed as a function of the values of Y (Y causes Z). The “assignment arrows” emphasize the
asymmetric relations between all three random variables. However, as Z provides a stronger
signal-to-noise ratio than X for the prediction of Y , the best regression solution in terms of
least-square error is

ˆY = 0.25X + 0.5Z

The above regression model, a typical case of inverse regression after Goldberger (1984), would
wrongly explain some changes in Y as a function of changes in Z, although Z does not cause
Y . In this simple case, there exists approaches overcoming the inverse regression mistake and
uncovering all true cause-effect relations (Hoyer et al., 2009). In the general case however,
mainstream machine learning approaches fail to understand the relationships between all three
distributions, and might attribute some effects on Y to changes in Z.

Mistaking correlation for causation can be catastrophic for agents who must plan, reason,
and decide based on observations. Thus, discovering causal structures is of crucial importance.
The gold standard to discover causal relations is to perform experiments (Pearl, 2003).
However, experiments are in many cases expensive, unethical, or impossible to realize. In these
situations, there is a need for observational causal discovery, that is, the estimation of causal
relations from observations alone (Spirtes et al., 2000; Peters et al., 2017).

In the considered setting, observational empirical data (drawn independent and identically
distributed from an unknown distribution) is given as a set of n samples of real valued fea-
ture vectors of dimension d. We denote the corresponding random vector as X = [X1, ..., Xd].
We seek a Functional Causal Model (FCM), also known as Structural Equation Model (SEM),
that best matches the underlying data-generating mechanism(s) in the following sense: un-
der relevant manipulations/interventions/experiments the FCM would produce data distributed
similarly to the real data obtained in similar conditions.

Let intervention do(X=x) be deﬁned as the operation on distribution obtained by clamping
variable X to value x, while the rest of the system remains unchanged (Pearl, 2009). It is said
that variable Xi is a direct cause of X j with respect to X1, ..., Xd iff different interventions on
variable X result in different marginal distributions on X j, everything else being equal:

PX j|

do(Xi=x,X

= PX j|
i, j the set of all variables except Xi and X j, scalar values x

do(Xi=x(cid:48),X

i j=c) (cid:54)

i j=c)

\

\

with X
= x(cid:48), and vector
i j := X
1,...,d
{
\
value c. Distribution PX j|
i j=c) is the resulting interventional distribution of the variable
X j when the variable Xi is clamped to value x, while keeping all other variables at a ﬁxed value
(Mooij et al., 2016).

do(Xi=x,X

}\

\

As said, conducting such interventions to determine direct causes and effects raises some
limitations. For this reason, this paper focuses on learning the causal structure from observa-
tional data only, where the goal and validation of the proposed approach is to match the known
“ground truth” model structure.

(1)

2

A contribution of the paper is to unify several state-of-art methods into one single consistent
and more powerful approach. On the one hand, leading researchers at UCLA, Carnegie Mel-
lon, University of Crete and elsewhere have developed powerful algorithms exploiting Markov
properties of directed acyclic graphs (DAGs). (Spirtes et al., 2000; Tsamardinos et al., 2006;
Pearl, 2009) On the other hand, the T¨ubingen School has proposed new and powerful func-
tional causal models (FCM) algorithms exploiting the asymmetries in the joint distribution of
cause-effect pairs. (Hoyer et al., 2009; Stegle et al., 2010; Daniusis et al., 2012; Mooij et al.,
2016)

In this paper, the learning of functional causal models is tackled in the search space of
generative neural networks (Kingma and Welling, 2013; Goodfellow et al., 2014), and aims at
the functional causal model (structure and parameters), best ﬁtting the underlying data genera-
tive process. The merits of the proposed approach, called Causal Generative Neural Network
(CGNN) are extensively and empirically demonstrated compared to the state of the art on arti-
ﬁcial and real-world benchmarks.

This paper is organized as follows: Section 2 introduces the problem of learning an FCM
and the underlying assumptions. Section 3 brieﬂy reviews and discusses the state of the art in
causal modeling. The FCM modeling framework within the search space of generative neural
networks is presented in Section 4. Section 5 reports on an extensive experimental validation of
the approach comparatively to the state of the art for pairwise cause-effect inference and graph
recovery. An extension of the proposed framework to deal with potential confounding variables
is presented in Section 6. The paper concludes in Section 7 with some perspectives for future
works.

2. Problem setting

A Functional Causal Model (FCM) upon a random variable vector X = [X1, . . . , Xd] is a triplet
(G , f , E ), representing a set of equations:

Xi ←

fi(XPa(i;G ), Ei), Ei ∼

E , for i = 1, . . . , d

(2)

Each equation characterizes the direct causal relation explaining variable Xi from the set
of its causes XPa(i;G ) ⊂ {
, based on some causal mechanism fi involving besides
XPa(i;G ) some random variable Ei drawn after distribution E , meant to account for all unob-
served variables.

X1, . . . , Xd}

Letting G denote the causal graph obtained by drawing arrows from causes XPa(i;G ) towards
their effects Xi, we restrict ourselves to directed acyclic graphs (DAG), where the propagation of
interventions to end nodes is assumed to be instantaneous. This assumption suitably represents
causal phenomena in cross-sectional studies. An example of functional causal model with ﬁve
variables is illustrated on Fig. 1.

2.1 Notations

↔

→

Y or Y

X); ii) a causal relationship in either direction (X

→
Y ) due to external common causes (Richardson and Spirtes, 2002).

By abuse of notation and for simplicity, a variable X and the associated node in the causal graph,
in one-to-one correspondence, are noted in the same way. Variables X and Y are adjacent iff
there exists an edge between both nodes in the graph. This edge can model i) a direct causal
relationship (X
Y ); iii) a non-
causal association (X
Conditional independence: (X
⊥⊥
tionally to Z, i.e. P(X,Y
Z) = P(X
|
V-structure, a.k.a. unshielded collider: Three variables
causal structure is: X
Skeleton of the DAG: the skeleton of the DAG is the undirected graph obtained by replacing all
edges by undirected edges.
Markov equivalent DAG: two DAGs with same skeleton and same v-structures are said to be
Markov equivalent (Pearl and Verma, 1991). A Markov equivalence class is represented by
a Completed Partially Directed Acyclic Graph (CPDAG) having both directed and undirected
edges.

Z) is meant as variables X and Y are independent condi-
Y
|
Z)P(Y
|

form a v-structure iff their

X,Y, Z

Z).
|

←

→

Y .

−

Z

{

}

3

E1

f1

X1

E2

E3

f2

X2

f3

X3

E4

f4

X4

E5

f5

X5

X1 = f1(E1)
X2 = f2(X1, E2)
X3 = f3(X1, E3)
X4 = f4(E4)
X5 = f5(X3, X4, E5)






Figure 1: Example of a Functional Causal Model (FCM) on X = [X1, . . . , X5]: Left: causal graph
G ; right: causal mechanisms.

2.2 Assumptions and Properties

in X has a common cause external to X

The state of the art in causal modeling most commonly involves four assumptions:
Causal sufﬁciency assumption (CSA): X is said to be causally sufﬁcient if no pair of variables
Xi, X j}
i, j.
{
\
Causal Markov assumption (CMA): all variables are independent of their non-effects (non
descendants in the causal graph) conditionally to their direct causes (parents) (Spirtes et al.,
2000). For an FCM, this assumption holds if the graph is a DAG and error terms Ei in the FCM
are independent on each other (Pearl, 2009).
Conditional independence relations in an FCM: if CMA applies, the data generated by the
FCM satisfy all conditional independence (CI) relations among variables in X via the notion of
d-separation (Pearl, 2009). CIs are called Markov properties. Note that there may be more CIs
in data than present in the graph (see the Faithfulness assumption below). The joint distribution
of the variables is expressed as the product of the distribution of each variable conditionally on
its parents in the graph.
Causal Faithfulness Assumption (CFA): the joint distribution P(X) is faithful to the graph
G of an FCM iff every conditional independence relation that holds true in P is entailed by
G (Spirtes and Zhang, 2016). Therefore, if there exists an independence relation in X that is
not a consequence of the Causal Markov assumption, then X is unfaithful (Scheines, 1997). It
follows from CMA and CFA that every causal path in the graph corresponds to a dependency
between variables, and vice versa.
V-structure property. Under CSA, CMA and CFA, if variables
Y, Z
{
}
v-structure (X

and
satisfy: i)
Y , then their causal structure is a
|

are NOT adjacent; iii) X

are adjacent; ii)

X, Z
{
Z).

X,Y
{

X,Y, Z

⊥(cid:54)⊥

Z

Y

}

}

{

}

→

←

3. State of the art

3.1 Learning the CPDAG

This section reviews methods to infer causal relationships, based on either the Markov proper-
ties of a DAG such as v-structures or asymmetries in the joint distributions of pairs of variables.

Structure learning methods classically use conditional independence (CI) relations in order to
identify the Markov equivalence class of the sought Directed Acyclic Graph, referred to as
CPDAG, under CSA, CMA and CFA.

Considering the functional model on X = [X1, . . . , X5] on Fig. 1, the associated DAG G and
graph skeleton are respectively depicted on Fig. 2(a) and (b). Causal modeling exploits ob-

4

servational data to recover the G structure from all CI (Markov properties) between variables.1
Under CSA, CMA and CFA, as (X3 ⊥⊥
X4 is
X5 ←
X1). Thus the DAGs
identiﬁed (Fig. 2(c)). However, one also has (X1 ⊥⊥
on Figs. 2(d) and (e) encode the same conditional independences as the true DAG (Fig. 2(a)).
Therefore the true DAG cannot be fully identiﬁed based only on independence tests, and the
X1, X2}
edges between the pairs of nodes
are left undirected. The identiﬁca-
and
tion process thus yields the partially undirected graph depicted on Fig. 2(c), called Completed
Partially Directed Acyclic Graph (CPDAG).

X5) does not hold, a v-structure X3 →
X3) and (X2 ⊥⊥

X1, X3}
{

X5|

X4|

X3|

{

X1

X1

X1

X5

X2

X3

X4

X2

X3

X4

X2

X3

X4

(a) The exact DAG of G .

(b) The skeleton of G .

(c) The CPDAG of G .

X5

X5

X1

X2

X3

X4

X2

X3

X4

X5

X1

X5

(d) A Markov equivalent DAG of G .

(e) Another Markov equivalent DAG of G .

Figure 2: Example of a Markov equivalent class. There exists three graphs (a, d, e) consistent
with a given graph skeleton (b); the set of these consistent graphs deﬁnes the Markov equivalent
class (c).

The main three families of methods used to recover the CPDAG of an FCM with contin-
uous data are constraint-based methods, score-based methods, and hybrid methods (Drton and
Maathuis, 2016).

3.1.1 CONSTRAINT-BASED METHODS

Constraint-based methods exploit conditional independences between variables to identify all
v-structures. One of the most well-known constraint-based algorithms is the PC algorithm
(Spirtes et al., 1993). PC ﬁrst builds the DAG skeleton based on conditional independences
among variables and subsets of variables. Secondly, it identiﬁes v-structures (Fig. 2(c)). Fi-
nally, it uses propagation rules to orient remaining edges, avoiding the creation of directed
cycles or new v-structures. Under CSA, CMA and CFA, and assuming an oracle indicating all
conditional independences, PC returns the CPDAG of the functional causal model. In prac-
tice, PC uses statistical tests to accept or reject conditional independence at a given conﬁdence
level. Besides mainstream tests (e.g., s Z-test or T-Test for continuous Gaussian variables,
and χ-squared or G-test for categorical variables), non-parametric independence tests based
on machine learning are becoming increasingly popular, such as kernel-based conditional in-
dependence tests (Zhang et al., 2012). The FCI algorithm (Spirtes et al., 1999) extends PC;
it relaxes the causal sufﬁciency assumption and deals with latent variables. The RFCI algo-
rithm (Colombo et al., 2012) is faster than FCI and handles high-dimensional DAGs with latent
variables. Achilles’ heel of constraint-based algorithms is their reliance on conditional inde-
pendence tests. The CI accuracy depends on the amount of available data, with exponentially

1The so-called constraint-based methods base the recovery of graph structure on conditional independence tests.
In general, proofs of model identiﬁability assume the existence of an “oracle” providing perfect knowledge of the
CIs, i.e. de facto assuming an inﬁnite amount of training data.

5

increasing size with the number of variables. Additionally, the use of propagation rules to direct
edges is prone to error propagation.

3.1.2 SCORE-BASED METHODS

Score-based methods explore the space of CPDAGs and minimize a global score. For example,
the space of graph structures is explored using operators (add edge, remove edge, and reverse
edge) by the Greedy Equivalent Search (GES) algorithm (Chickering, 2002), returning the op-
timal structure in the sense of the Bayesian Information Criterion.2

In order to ﬁnd the optimal CPDAG corresponding to the minimum score, the GES algo-
rithm starts with an empty graph. A ﬁrst forward phase is performed, iteratively adding edges
to the model in order to improve the global score. A second backward phase iteratively removes
edges to improve the score. Under CSA, CMA and CFA, GES identiﬁes the true CPDAG in the
large sample limit, if the score used is decomposable, score-equivalent and consistent (Chick-
ering, 2002). More recently, Ramsey (2015) proposed a GES extension called Fast Greedy
Equivalence Search (FGES) algorithm. FGES uses the same scores and search algorithm with
different data structures; it greatly speeds up GES by caching information about scores during
each phase of the process.

3.1.3 HYBRID ALGORITHMS

Hybrid algorithms combine ideas from constraint-based and score-based algorithms. Accord-
ing to Nandy et al. (2015), such methods often use a greedy search like the GES method on
a restricted search space for the sake of computational efﬁciency. This restricted space is de-
ﬁned using conditional independence tests. For instance the Max-Min Hill climbing (MMHC)
algorithm (Tsamardinos et al., 2006) ﬁrstly builds the skeleton of a Bayesian network using con-
ditional independence tests and then performs a Bayesian-scoring greedy hill-climbing search
to orient the edges. The Greedy Fast Causal Inference (GFCI) algorithm proceeds in the other
way around, using FGES to get rapidly a ﬁrst sketch of the graph (shown to be more accurate
than those obtained with constraint-based methods), then using the FCI constraint-based rules
to orient the edges in presence of potential confounders (Ogarrio et al., 2016).

3.2 Exploiting asymmetry between cause and effect

The abovementioned score-based and constraint-based methods do not take into account the full
information from the observational data (Spirtes and Zhang, 2016), such as data asymmetries
induced by the causal directions.

3.2.1 THE INTUITION

−

Y edge as both graphs X

Let us consider FCM Y = X + E, with E a random noise independent of X by construction.
Graph constraints cannot orient the X
X are Markov
E can be exploited provided that either
equivalent. However, the implicit v-structure X
X or E does not follow a Gaussian distribution. Consider the linear regression Y = aX + b
(blue curve in Fig. 3); the residual is independent of X. Quite the contrary, the residual of
the linear regression X = a(cid:48)Y + b(cid:48) (red curve in Fig. 3) is not independent of Y as far as the
In this toy example, the
independence of the error term holds true (Shimizu et al., 2006).
asymmetries in the joint distribution of X and Y can be exploited to recover the causal direction
X

Y (Spirtes and Zhang, 2016).

Y and Y

→

→

→

←

Y

→

2After Ramsey (2015), in the linear model with Gaussian variable case the individual BIC score to minimize for
a variable X given its parents is up to a constant n ln(s) + c k ln(n), where n ln(s) is the likelihood term, with s the
residual variance after regressing X onto its parents, and n the number of data samples. c k ln(n) is a penalty term for
the complexity of the graph (here the number of edges). k = 2p + 1, with p the total number of parents of the variable
X in the graph. c = 2 by default, chosen empirically. The global score minimized by the algorithm is the sum over
all variables of the individual BIC score given the parent variables in the graph.

6

Figure 3: Left: Joint distribution P(X,Y ) generated from DAG X
Y + E, with E a uniform
noise variable. The linear regression of Y on X (respectively of X on Y ) is depicted as a blue
(resp. red) curve. Middle: Error f (X)
X is not
Y . Better seen
independent of Y . The asymmetry establishes that the true causal model is X
in color.

Y is independent of X. Right: Error g(Y )

→

→

−

−

3.2.2 RESTRICTION ON THE CLASS OF CAUSAL MECHANISMS CONSIDERED

Causal inference is bound to rely on assumptions such as non-Gaussianity or additive noise. In
the absence of any such assumption, Zhang et al. (2016) show that, even in the bivariate case, for
any function f and noise variable E independent of X such that Y = f (X, E), it is always feasible
to construct some ˜f and ˜E, with ˜E independent of Y , such that X = ˜f (Y, ˜E). An alternative,
supporting asymmetry detection and hinting at a causal direction, is based on restricting the
class of functions f (e.g. only considering regular functions). According to Quinn et al. (2011),
the ﬁrst approach in this direction is LiNGAM (Shimizu et al., 2006). LiNGAM handles linear
structural equation models, where each variable is continuous and modeled as:

Xi = ∑
k

αkPk

a (Xi) + Ei, i

1, n

(cid:75)

∈ (cid:74)

(3)

with Pk

a (Xi) the k-th parent of Xi and αk a real value. Assuming further that all probability
distributions of source nodes in the causal graph are non-Gaussian, Shimizu et al. (2006) show
that the causal structure is fully identiﬁable (all edges can be oriented).

3.2.3 PAIRWISE METHODS

In the continuous, non-linear bivariate case, speciﬁc methods have been developed to orient
the variable edge.3 A well known example of bivariate model is the additive noise model
(ANM) (Hoyer et al., 2009), with data generative model Y = f (X)+E, f a (possibly non-linear)
function and E a noise independent of X. The authors prove the identiﬁability of the ANM in
the following sense: if P(X,Y ) is consistent with ANM Y = f (X) + E, then i) there exists no
AMN X = g(Y ) + E(cid:48) consistent with P(X,Y ); ii) the true causal direction is X
Y . Under the
independence assumption between E and X, the ANM admits a single non-identiﬁable case,
the linear model with Gaussian input and Gaussian noise (Mooij et al., 2016).

→

A more general model is the post-nonlinear model (PNL) (Zhang and Hyv¨arinen, 2009),
involving an additional nonlinear function on the top of an additive noise: Y = g( f (X) + E),
with g an invertible function. The price to pay for this higher generality is an increase in the
number of non identiﬁable cases.

The Gaussian Process Inference model (GPI) (Stegle et al., 2010) infers the causal direction
without explicitly restricting the class of possible causal mechanisms. The authors build two
X, where the distribution of the
Bayesian generative models, one for X
cause is modeled with a Gaussian mixture model, and the causal mechanism f is a Gaussian
process. The causal direction is determined from the generative model best ﬁtting the data
(maximizing the data likelihood). Identiﬁability here follows from restricting the underlying
class of functions and enforcing their smoothness (regularity). Other causal inference methods

Y and one for Y

→

→

3These methods can be extended to the multivariate case and used for causal graph identiﬁcation by orienting

each edge in turn.

7

Y , the marginal probability distribution
(Sgouritsa et al., 2015) are based on the idea that if X
X), hence estimating P(Y
X)
of the cause P(X) is independent of the causal mechanism P(Y
|
|
from P(X) should hardly be possible, while estimating P(X
Y ) based on P(Y ) may be possible.
|
The reader is referred to Statnikov et al. (2012) and Mooij et al. (2016) for a thorough review
and benchmark of the pairwise methods in the bivariate case.

→

A new ML-based approach tackles causal inference as a pattern recognition problem. This
setting was introduced in the Causality challenges (Guyon, 2013, 2014), which released 16,200
, each pair being described by a sample of their joint distribution,
pairs of variables
and labeled with the true (cid:96)i value of their causal relationship, with (cid:96)i ranging in
Yi,
Yi →
. The causality classiﬁers trained from the
}
challenge pairs yield encouraging results on test pairs. The limitation of this ML-based causal
modeling approach is that causality classiﬁers intrinsically depend on the representativity of
the training pairs, assumed to be drawn from a same “Mother distribution” (Lopez-Paz et al.,
2015).

Xi,Yi}
{
Yi (presence of a confounder)
Yi, Xi ↔

Xi, Xi ⊥⊥

Xi →

{

Note that bivariate methods can be used to uncover the full DAG, and independently orient
each edge, with the advantage that an error on one edge does not propagate to the rest of the
graph (as opposed to constraint and score-based methods). However, bivariate methods do not
leverage the full information available in the dependence relations. For example in the linear
Gaussian case (linear model and Gaussian distributed inputs and noises), if a triplet of vari-
C), a
ables
C (unshielded collider); still,
constraint-based method would identify the v-structure A
a bivariate model based on cause-effect asymmetry would neither identify A

is such that A, B (respectively B,C) are dependent on each other but A

A, B,C
{

B nor B

←

→

⊥⊥

C.

B

}

→

←

3.3 Discussion

This brief survey has shown the complementarity of CPDAG and pairwise methods. The former
ones can at best return partially directed graphs; the latter ones do not optimally exploit the
interactions between all variables.

To overcome these limitations, an extension of the bivariate post-nonlinear model (PNL)
has been proposed (Zhang and Hyv¨arinen, 2009), where an FCM is trained for any plausible
causal structure, and each model is tested a posteriori for the required independence between
errors and causes. The main PNL limitation is its super-exponential cost with the number
of variables (Zhang and Hyv¨arinen, 2009). Another hybrid approach uses a constraint based
algorithm to identify a Markov equivalence class, and thereafter uses bivariate modelling to
orient the remaining edges (Zhang and Hyv¨arinen, 2009). For example, the constraint-based
X4 in an FCM (Fig. 2), enabling the
PC algorithm can identify the v-structure X3 →
X3. Note that an
X2 and X1 →
bivariate PNL method to further infer the remaining arrows X1 →
effective combination of constraint-based and bivariate approaches requires a ﬁnal veriﬁcation
phase to test the consistency between the v-structures and the edge orientations.

X5 ←

This paper aims to propose a uniﬁed framework getting the best out of both worlds of

CPDAG and bivariate approaches.

An inspiration of the approach is the CAM algorithm (B¨uhlmann et al., 2014), which is an
extension to the graph setting of the pairwise additive model (ANM) (Hoyer et al., 2009). In
CAM the FCM is modeled as:

Xi = ∑
k
∈

Pa(i;G )

fk(Xk) + Ei, for i = 1, . . . , d

Our method can be seen an extension of CAM, as it allows non-additive noise terms and
non-additive contributions of causes, in order to model ﬂexible conditional distributions, and
addresses the problem of learning FCMs (Section 2):

Xi = fi(XPa(i;G ), Ei), for i = 1, . . . , d

An other inspiration of our framework is the recent method of Lopez-Paz and Oquab
Y and

(2016), where a conditional generative adversarial network is trained to model X
Y

X in order to infer the causal direction based on the Occam’s razor principle.

→

→

(4)

(5)

8

This approach, called Causal Generative Neural Network (CGNN), features two original
contributions. Firstly, multivariate causal mechanisms fi are learned as generative neural
networks (as opposed to, regression networks). The novelty is to use neural nets to model
the joint distribution of the observed variables and learn a continuous FCM. This approach
does not explicitly restrict the class of functions used to represent the causal models (see also
(Stegle et al., 2010)), since neural networks are universal approximators. Instead, a regularity
argument is used to enforce identiﬁability, in the spirit of supervised learning: the methods
searches a trade-off between data ﬁtting and model complexity.

Secondly, the data generative models are trained using a non-parametric score, the Maxi-
mum Mean Discrepancy (Gretton et al., 2007). This criterion is used instead of likelihood based
criteria, hardly suited to complex data structures, or mean square criteria, implicitly assuming
an additive noise (e.g. as in CAM, Eq. 4).

Starting from a known skeleton, Section 4 presents a version of the proposed approach
under the usual Markov, faithfulness, and causal sufﬁciency assumptions. The empirical vali-
dation of the approach is detailed in Section 5. In Section 6, the causal sufﬁciency assumption
is relaxed and the model is extended to handle possible hidden confounding factors. Section 7
concludes the paper with some perspectives for future work.

4. Causal Generative Neural Networks

Let X = [X1, . . . , Xd] denote a set of continuous random variables with joint distribution P, and
further assume that the joint density function h of P is continuous and strictly positive on a
compact subset of Rd and zero elsewhere.

This section ﬁrst presents the modeling of continuous FCMs with generative neural net-
works with a given graph structure (Section 4.1), the evaluation of a candidate model (Section
4.2), and ﬁnally, the learning of a best candidate from observational data (Section 4.3).

4.1 Modeling continuous FCMs with generative neural networks

We ﬁrst show that there exists a (non necessarily unique) continuous functional causal model
(G , f , E ) such that the associated data generative process ﬁts the distribution P of the observa-
tional data.

Proposition 1 Let X = [X1, . . . , Xd] denote a set of continuous random variables with joint distribution P,
and further assume that the joint density function h of P is continuous and strictly positive on a compact
and convex subset of Rd, and zero elsewhere. Letting G be a DAG such that P can be factorized along G ,

P(X) = ∏
i

P(Xi|

XPa(i;G ))

there exists f = ( f1, . . . , fd) with fi a continuous function with compact support in R|
[0, 1] such
that P(X) equals the generative model deﬁned from FCM (G , f , E ), with E = U [0, 1] the uniform distri-
bution on [0, 1].

| ×

Pa(i;G )

Proof In Appendix 8.2

In order to model such continuous FCM (G , f , E ) on d random variables X = [X1, . . . , Xd],

we introduce the CGNN (Causal Generative Neural Network) depicted on Figure 4.

Deﬁnition 1 A CGNN over d variables [ ˆX1, . . . , ˆXd] is a triplet C

G , ˆf = (

G , ˆf , E ) where:

1.

G is a Directed Acyclic Graph (DAG) associating to each variable ˆXi its set of parents noted
ˆXPa(i; ˆG ) for i
(cid:98)

[[1, d]]

∈

(cid:98)

(cid:98)

9

2. For i

∈ (cid:74)
neurons:

(cid:75)

1, d

, causal mechanism ˆfi is a 1-hidden layer regression neural network with nh hidden

ˆXi = ˆfi( ˆXPa(i; ˆG ), Ei) =

¯wi

kσ

nh
∑
k=1

N

k, ˆwi
with nh ∈
work, and σ a continuous activation function .

the number of hidden units, ¯wi

∗

∑
Pa(i;G )

(cid:32)

j

∈
jk, wi

k, bi

k, ¯bi

∈

ˆwi
jk

ˆX j + wi

kEi + bi
k

+ ¯bi

(cid:33)

(6)

R the parameters of the neural net-

3. Each variable Ei is independent of the cause Xi. Furthermore, all noise variables are mutually

independent and drawn after same distribution E .

E1

ˆX1

ˆf1

E2

ˆf2

ˆX2

ˆX3

E4

ˆX4

E3

ˆf3

ˆf5

ˆf4

E5

ˆX5

ˆX1 = ˆf1(E1)
ˆX2 = ˆf2( ˆX1, E2)
ˆX3 = ˆf3( ˆX1, E3)
ˆX4 = ˆf4(E4)
ˆX5 = ˆf5( ˆX3, ˆX4, E5)






Figure 4: Left: Causal Generative Neural Network over variables ˆX = ( ˆX1, . . . , ˆX5). Right:
Corresponding Functional Causal Model equations.

It is clear from its deﬁnition that a CGNN deﬁnes a continuous FCM.

4.1.1 GENERATIVE MODEL AND INTERVENTIONS

G , ˆf = (

A CGNN C
G , ˆf , E ) is a generative model in the sense that any sample [e1, j, . . . , ed, j] of
the “noise” random vector E = [E1, . . . , Ed] can be used as “input” to the network to generate
a data sample [ ˆx1, j, . . . , ˆxd, j] of the estimated distribution ˆP( ˆX = [ ˆX1, . . . , ˆXd]) by proceeding as
follow:

(cid:98)

(cid:98)

1. Draw

n
[e1, j, . . . , ed, j]
j=1, n samples independent identically distributed from the joint distribution
}
{

of independent noise variables E = [E1, . . . , Ed].

2. Generate n samples

j=1, where each estimate sample ˆxi, j of variable ˆXi is computed
n
[ ˆx1, j, . . . , ˆxd, j]
}
{
G from ˆfi with the j-th estimate samples ˆxPa(i; ˆG ), j of ˆXPa(i; ˆG ) and the

in the topological order of
j-th sample ei, j of the random noise variable Ei.

(cid:98)

G , as the graph

Notice that a CGNN generates a probability distribution ˆP which is Markov with respect to
G is acyclic and the noise variables Ei are mutually independent.
Importantly, CGNN supports interventions, that is, freezing a variable Xi to some constant
vi. The resulting joint distribution noted ˆPdo( ˆXi=vi)( ˆX), called interventional distribution (Pearl,
(cid:98)
2009), can be computed from CGNN by discarding all causal inﬂuences on ˆXi and clamping its
value to vi. It is emphasized that intervening is different from conditioning (correlation does
not imply causation). The knowledge of interventional distributions is essential for e.g., public
policy makers, wanting to estimate the overall effects of a decision on a given variable.

(cid:98)

10

4.2 Model evaluation

G , ˆf , E ) a score reﬂecting how well
The goal is to associate to each candidate solution C
this candidate solution describes the observational data. Firstly we deﬁne the model scoring
function (Section 4.2), then we show that this model scoring function allows to build a CGNN
generating a distribution ˆP( ˆX) that approximates P(X) with arbitrary accuracy (Section 4.2.2).

G , ˆf = (

(cid:98)

(cid:98)

4.2.1 SCORING METRIC

The ideal score, to be minimized, is the distance between the joint distribution P associated
P deﬁned by the CGNN candidate C ˆG , ˆf =
with the ground truth FCM, and the joint distribution
( ˆG , ˆf , E ). A tractable approximation thereof is given by the Maximum Mean Discrepancy
D
(MMD) (Gretton et al., 2007) between the n-sample observational data D, and an n-sample
sampled after

P. Overall, the CGNN C ˆG , ˆf is trained by minimizing

(cid:98)

(cid:98)

S(C ˆG , ˆf , D) = (cid:92)MMDk(D,

D) + λ

with (cid:92)MMDk(D,

D) deﬁned as:

(cid:92)MMDk(D,
(cid:98)

D) =

1
n2

n
∑
i, j=1

(cid:98)

1
n2

n
∑
i, j=1

G
|

,
|

(cid:98)

2
n2

n
∑
i, j=1

−

k(xi, x j) +

k( ˆxi, ˆx j)

k(xi, ˆx j)

(8)

(cid:98)

(7)

(cid:98)

2
where kernel k usually is taken as the Gaussian kernel (k(x, x(cid:48)) = exp(
2)). The MMD
statistic, with quadratic complexity in the sample size, has the good property that as n goes to
inﬁnity, it goes to zero iff P = ˆP (Gretton et al., 2007). For scalability, a linear approximation
m
of the MMD statistics based on m = 100 random features (Lopez-Paz, 2016), called (cid:92)MMD
k ,
will also be used in the experiments (more in Appendix 8.1).

γ
−

x(cid:48)(cid:107)

−

(cid:107)

x

Due to the Gaussian kernel being differentiable, (cid:92)MMDk and (cid:92)MMD

m
k are differentiable, and

backpropagation can be used to learn the CGNN made of networks ˆfi structured along ˆG .

In order to compare candidate solutions with different structures in a fair manner, the eval-
the number of

uation score of Equation 7 is augmented with a penalization term λ
edges in ˆG . Penalization weight λ is a hyper-parameter of the approach.

, with
|

G
|

G
|

|

(cid:98)

(cid:98)

4.2.2 REPRESENTATIONAL POWER OF CGNN

{

We note D =
(unknown) joint distribution P(X = [X1, . . . , Xd]), also referred to as observational data.

n
[x1, j, . . . , xd, j]
j=1, the data samples independent identically distributed after the
}

Under same conditions as in Proposition 1, (P(X) being decomposable along graph G , with
continuous and strictly positive joint density function on a compact in Rd and zero elsewhere),
there exists a CGNN (

G , ˆf , E ), that approximates P(X) with arbitrary accuracy:

Proposition 2 For m
[[1, d]], let Zm denote the set of variables with topological order less than m and
let dm be its size. For any dm-dimensional vector of noise values e(m), let zm(e(m)) (resp.
zm(e(m))) be the
vector of values computed in topological order from the FCM (G , f , E ) (resp. the CGNN (G , ˆf , E )). For
any ε > 0, there exists a set of networks ˆf with architecture G such that

∈

(cid:98)

(cid:98)

e(m),
∀

zm(e(m))
(cid:107)

−

zm(e(m))
(cid:107)

< ε

(9)

Proof In Appendix 8.2

(cid:98)

Using this proposition and the (cid:92)MMDk scoring criterion presented in Equation 8, it is shown
that the distribution ˆP of the CGNN can estimate the true observational distribution of the
(unknown) FCM up to an arbitrary precision, under the assumption of an inﬁnite observational
sample:

11

Proposition 3 Let D be an inﬁnite observational sample generated from (G , f , E ). With same notations
∞, there exists a set
as in Prop. 2, for every sequence εt , such that εt > 0 and goes to zero when t
Dt generated from the CGNN
ft = ( ˆf t
(G ,
(cid:98)

d) such that (cid:92)MMDk between D and an inﬁnite size sample

ft , E ) is less than εt .

1 . . . ˆf t

→

(cid:98)

Proof In Appendix 8.2
(cid:98)

→

→

0, as t

Under these assumptions, as (cid:92)MMDk(D, ˆDt )

∞, it implies that the sequence of
generated ˆPt converges in distribution toward the distribution P of the observed sample (Gretton
et al., 2007). This result highlights the generality of this approach as we can model any kind
of continuous FCM from observational data (assuming access to inﬁnite observational data).
Our class of model is not restricted to simplistic assumptions on the data generative process
such as the additivity of the noise or linear causal mechanisms. But this strength comes with a
new challenge relative to identiﬁability of such CGNNs as the result of proposition 3 holds for
G such that P can be factorized along G and then for any any DAG in the Markov
any DAG
equivalence class of G (under classical assumption of CMA, CFA and CSA). In particular in
the pairwise setting, when only 2 variables X and Y are observed, the joint distribution P(X,Y )
X)
can be factorized in two Markov equivalent DAGs X
Y or Y
|
and P(X,Y ) = P(Y )P(X
Y ). Then the CGNN can reproduce equally well the observational
|
distribution in both directions (under the assumption of proposition 1). We refer the reader to
Zhang and Hyv¨arinen (2009) for more details on this problem of identiﬁability in the bivariate
case.

X as P(X,Y ) = P(X)P(Y

→

→

(cid:98)

As shown in Section 4.3.3, the proposed approach enforces the discovery of causal models
in the Markov equivalence class. Within this class, the non-identiﬁability issue is empirically
mitigated by restricting the class of CGNNs considered, and speciﬁcally limiting the number
nh of hidden neurons in each causal mechanism (Eq. 6). Formally, we restrict ourselves to
G , ˆf nh, E ) with exactly nh hidden neurons in each
the sub-class of CGNNs, noted C ˆG , ˆf nh = (
ˆfi mechanism. Accordingly, any candidate ˆG with number of edges
ˆG
involves the same
|
|
(cid:98)
ˆG
number of parameters: (2d +
(nh + 1) bias parameters. As shown
)
nh weights and d
|
|
experimentally in Section 5, this parameter nh is crucial as it governs the CGNN ability to
model the causal mechanisms: too small nh, and data patterns may be missed; too large nh, and
overly complicated causal mechanisms may be retained.

×

×

4.3 Model optimization

Model optimization consists at ﬁnding a (nearly) optimum solution ( ˆG , ˆf ) in the sense of the
score deﬁned in the previous section. The so-called parametric optimization of the CGNN,
where structure estimate ˆG is ﬁxed and the goal is to ﬁnd the best neural estimates ˆf condition-
ally to ˆG is tackled in Section 4.3.1. The non-parametric optimization, aimed at ﬁnding the best
structure estimate, is considered in Section 4.3.2. In Section 4.3.3, we present an identiﬁability
result for CGNN up to Markov equivalence classes.

4.3.1 PARAMETRIC (WEIGHT) OPTIMIZATION

Given the acyclic structure estimate ˆG , the neural networks ˆf1, . . . , ˆfd of the CGNN are learned
end-to-end using backpropagation with Adam optimizer (Kingma and Ba, 2014) by minimizing
m
losses (cid:92)MMDk (Eq. (8), referred to as CGNN ((cid:92)MMDk) ) or (cid:92)MMD
k (see Appendix 8.1,CGNN
((cid:92)MMD

m
k )).

The procedure closely follows that of supervised continuous learning (regression), except
for the fact that the loss to be minimized is the MMD loss instead of the mean squared error.
Neural nets ˆfi, i
[[1, d]] are trained during ntrain epochs, where the noise samples, independent
m
and identically distributed, are drawn in each epoch. In the (cid:92)MMD
k variant, the parameters of
the random kernel are resampled from their respective distributions in each training epoch (see
Appendix 8.1). After training, the score is computed and averaged over neval estimated samples
of size n. Likewise, the noise samples are re-sampled anew for each evaluation sample. The

∈

12

overall process with training and evaluation is repeated nbrun times to reduce stochastic effects
relative to random initialization of neural network weights and stochastic gradient descent.

4.3.2 NON-PARAMETRIC (STRUCTURE) OPTIMIZATION

ˆG over d nodes is super-exponential in d, making the
The number of directed acyclic graphs
non-parametric optimization of the CGNN structure an intractable computational and statistical
problem. Taking inspiration from Tsamardinos et al. (2006); Nandy et al. (2015), we start from
a graph skeleton recovered by other methods such as feature selection (Yamada et al., 2014).
We focus on optimizing the edge orientations. Letting L denote the number of edges in the
graph, it deﬁnes a combinatorial optimization problem of complexity O(2L) (note however that
not all orientations are admissible since the eventual oriented graph must be a DAG).

The motivation for this approach is to decouple the edge selection task and the causal

modeling (edge orientation) tasks, and enable their independent assessment.

Any Xi −

X j edge in the graph skeleton stands for a direct dependency between variables Xi
and X j. Given Causal Markov and Faithfulness assumptions, such a direct dependency either
reﬂects a direct causal relationship between the two variables (Xi →
X j), or is due to
X j or Xi ←
X j). Under the assumption
the fact that Xi and X j admit a latent (unknown) common cause (Xi ↔
X j link is associated with a
of causal sufﬁciency, the latter does not hold. Therefore the Xi −
causal relationship in one or the other direction. The causal sufﬁciency assumption will be
relaxed in Section 6.

The edge orientation phase proceeds as follows:

•

•

•

X j edge is ﬁrst considered in isolation, and its orientation is evaluated using CGNN.
Each Xi −
Both score S(C
n
[xi,l, x j,l]
l=1. The
}
best orientation corresponding to a minimum score is retained. After this step, an initial graph is
built with complexity 2L with L the number of edges in the skeleton graph.

Xi, ˆf , Di j) are computed, where Di j =

X j, ˆf , Di j) and S(C

X j→

Xi→

{

The initial graph is revised to remove all cycles. Starting from a set of random nodes, all paths
are followed iteratively until all nodes are reached; an edge pointing toward an already visited
node and forming a cycle is reversed. The resulting DAG is used as initial DAG for the structured
optimization, below.

The optimization of the DAG structure is achieved using a hill-climbing algorithm aimed to opti-
mize the global score S(C ˆG , ˆf , D). Iteratively, i) an edge Xi −
X j is uniformly randomly selected
in the current graph; ii) the graph obtained by reversing this edge is considered (if it is still a
DAG and has not been considered before) and the associated global CGNN is retrained; iii) if
this graph obtains a lower global score than the former one, it becomes the current graph and the
process is iterated until reaching a (local) optimum. More sophisticated combinatorial optimiza-
tion approaches, e.g. Tabu search, will be considered in further work. In this paper, hill-climbing
is used for a proof of concept of the proposed approach, achieving a decent trade-off between
computational time and accuracy.

At the end of the process each causal edge Xi →

suring its contribution to the global score:

X j in G is associated with a score, mea-

X j = S(C ˆG

SXi→

, ˆf , D)

S(C ˆG , ˆf , D)

−{

Xi→

X j}
During the structure (non-parametric) optimization, the graph skeleton is ﬁxed; no edge
G
is added or removed. The penalization term λ
entering in the score evaluation (eq. 7) can
|
thus be neglected at this stage and only the MMD-losses are used to compare two graphs. The
penalization term will be used in Section 6 to compare structures with different skeletons, as
the potential confounding factors will be dealt with by removing edges.

−

(cid:98)

|

(10)

4.3.3 IDENTIFIABILITY OF CGNN UP TO MARKOV EQUIVALENCE CLASSES

Assuming an inﬁnite number of observational data, and assuming further that the generative
distribution belongs to the CGNN class CG , f , then there exists a DAG reaching an MMD score
of 0 in the Markov equivalence class of G :

13

Proposition 4 Let X = [X1, . . . , Xd] denote a set of continuous random variables with joint distribution
P, generated by a CGNN CG , f = (G , f , E ) with G a directed acyclic graph. Let D be an inﬁnite observa-
tional sample generated from this CGNN. We assume that P is Markov and faithful to the graph G , and
D an
that every pair of variables (Xi, X j) that are d-connected in the graph are not independent. We note
inﬁnite sample generated by a candidate CGNN, C

G , ˆf , E ). Then,

(cid:98)

G characterized by the same adjacencies but not belonging to the Markov equivalence

G , ˆf = (

(cid:98)

(cid:98)

G = G and ˆf = f , then (cid:92)MMDk(D,

(i) If
(ii) For any graph
class of G , for all ˆf , (cid:92)MMDk(D,

= 0.

D)

(cid:98)

(cid:98)

D) = 0.

(cid:98)

Proof In Appendix 8.2

(cid:98)

This result does not establish the CGNN identiﬁability within the Markov class of equiv-
alence, that is left for future work. As shown experimentally in Section 5.1, there is a need to
control the model capacity in order to recover the directed graph in the Markov equivalence
class.4

5. Experiments

This section reports on the empirical validation of CGNN compared to the state of the art under
the no confounding assumption. The experimental setting is ﬁrst discussed. Thereafter, the
results obtained in the bivariate case, where only asymmetries in the joint distribution can be
used to infer the causal relationship, are discussed. The variable triplet case, where conditional
independence can be used to uncover causal orientations, and the general case of d > 2 variables
are ﬁnally considered. All computational times are measured on Intel Xeon 2.7Ghz (CPU) or
on Nvidia GTX 1080Ti graphics card (GPU).

5.1 Experimental setting

0.005, 0.05, 0.25, 0.5, 1, 5, 50
}
{

.

The CGNN architecture is a 1-hidden layer network with ReLU activation function. The multi-
scale Gaussian kernel used in the MMD scores has bandwidth γ ranging in
The number nbrun used to average the score is set to 32 for CGNN-MMD (respectively 64 for
CGNN-Fourier). In this section the distribution E of the noise variables is set to N (0, 1). The
number nh of neurons in the hidden layer, controlling the identiﬁability of the model, is the most
sensitive hyper-parameter of the presented approach. Preliminary experiments are conducted
to adjust its range, as follows. A 1,500 sample dataset is generated from the linear structural
equation model with additive uniform noise Y = X + U (0, 0.5), X
2, 2]) (Fig. 5). Both
X are trained until reaching convergence (nepoch = 1, 000)
CGNNs associated to X
using Adam (Kingma and Ba, 2014) with a learning rate of 0.01 and evaluated over neval = 500
generated samples. The distributions generated from both generative models are displayed on
Fig. 5 for nh = 2, 5, 20, 100. The associated scores (averaged on 32 runs) are displayed on Fig.
6a, conﬁrming that the model space must be restricted for the sake of identiﬁability (cf. Section
4.3.3 above).

Y and Y

U([

→

→

−

∼

5.2 Learning bivariate causal structures

As said, under the no-confounder assumption a dependency between variables X and Y exists iff
either X causes Y (Y = f (X, E)) or Y causes X (X = f (Y, E)). The identiﬁcation of a Bivariate
Structural Causal Model is based on comparing the model scores (Section 4.2) attached to both
CGNNs.

4In some speciﬁc cases, such as in the bivariate linear FCM with Gaussian noise and Gaussian input, even by
restricting the class of functions considered, the DAG cannot be identiﬁed from purely observational data (Mooij
et al., 2016).

14

Figure 5: Leftmost: Data samples. Columns 2 to 5: Estimate samples generated from CGNN
X (bottom row) for number of hidden neurons nh =
with direction X
2, 5, 20, 100.

Y (top row) and Y

→

→

(b) Scores CX
Y and CY
X with their
difference. (cid:63)(cid:63)(cid:63) denotes the signiﬁcance
at the 0.001 threshold with the t-test.

→

→

Y

X

nh

2
5
10
20
30
40
50
100

CX

→
32.0
29.6
25.9
25.7
24.4
25.6
25.0
24.9

CY

→
43.9
35.2
32.5
28.3
26.8
25.6
25.0
24.4

Diff.
11.9(cid:63)(cid:63)(cid:63)
5.6(cid:63)(cid:63)(cid:63)
6.6(cid:63)(cid:63)(cid:63)
2.6(cid:63)(cid:63)(cid:63)
2.4(cid:63)(cid:63)(cid:63)
0.7
0.6

0.5

−

(a) CX

Y , CY

X with various nh values.

→

→

Figure 6: CGNN sensitivity w.r.t. the number of hidden neurons nh: Scores associated to both
causal models (average and standard deviation over 32 runs).

Benchmarks. Five datasets with continuous variables are considered:5

CE-Cha: 300 continuous variable pairs from the cause effect pair challenge (Guyon, 2013),

•
restricted to pairs with label +1 (X

Y ) and

1 (Y

X).

−

→

→

CE-Net: 300 artiﬁcial pairs generated with a neural network initialized with random weights

•
and random distribution for the cause (exponential, gamma, lognormal, laplace...).

CE-Gauss: 300 artiﬁcial pairs without confounder sampled with the generator of Mooij
•
et al. (2016): Y = fY (X, EY ) and X = fX (EX ) with EX ∼
pEY . pEX and pEY are
randomly generated Gaussian mixture distributions. Causal mechanism fX and fY are randomly
generated Gaussian processes.

pEX and EY ∼

CE-Multi: 300 artiﬁcial pairs generated with linear and polynomial mechanisms. The effect
•
variables are built with post additive noise setting (Y = f (X) + E), post multiplicative noise
E)).
(Y = f (X)
CE-Tueb: 99 real-world cause-effect pairs from the Tuebingen cause-effect pairs dataset,
•
version August 2016 (Mooij et al., 2016). This version of this dataset is taken from 37 different
data sets coming from various domain: climate, census, medicine data.

E), pre-additive noise (Y = f (X + E)) or pre-multiplicative noise (Y = f (X

×

×

For all variable pairs, the size n of the data sample is set to 1,500 for the sake of an accept-

able overall computational load.

5The ﬁrst four datasets are available at http://dx.doi.org/10.7910/DVN/3757KX. The Tuebingen

cause-effect pairs dataset is available at https://webdav.tuebingen.mpg.de/cause-effect/

15

Baseline approaches. CGNN is assessed comparatively to the following algorithms:6 i)
ANM (Mooij et al., 2016) with Gaussian process regression and HSIC independence test of
the residual; ii) a pairwise version of LiNGAM (Shimizu et al., 2006) relying on Independent
Component Analysis to identify the linear relations between variables; iii) IGCI (Daniusis et al.,
2012) with entropy estimator and Gaussian reference measure; iv) the post-nonlinear model
(PNL) with HSIC test (Zhang and Hyv¨arinen, 2009); v) GPI-MML (Stegle et al., 2010); where
the Gaussian process regression with higher marginal likelihood is selected as causal direction;
vi) CDS, retaining the causal orientation with lowest variance of the conditional probability
distribution; vii) Jarfo (Fonollosa, 2016), using a random forest causal classiﬁer trained from
the ChaLearn Cause-effect pairs on top of 150 features including ANM, IGCI, CDS, LiNGAM,
regressions, HSIC tests.

Hyper-parameter selection. For a fair comparison, a leave-one-dataset-out procedure is
used to select the key best hyper-parameter for each algorithm. To avoid computational explo-
sion, a single hyper-parameter per algorithm is adjusted in this way; other hyper-parameters are
set to their default value. For CGNN, nh ranges over
. The leave-one-dataset-out
procedure sets this hyper-parameter nh to values between 20 and 40 for the different datasets.
For ANM and the bivariate ﬁt, the kernel parameter for the Gaussian process regression ranges
0.01, . . . , 10
. For PNL, the threshold parameter alpha for the HSIC independence test
over
}
{
. For CDS, the f f actor involved in the discretization step ranges
ranges over
over [[1, 10]]. For GPI-MML, its many parameters are set to their default value as none of them
appears to be more critical than others. Jarfo is trained from 4,000 variable pairs datasets with
same generator used for CE-Cha-train, CE-Net-train, CE-Gauss-train and CE-Multi-train;
the causal classiﬁer is trained on all datasets except the test set.

0.0005, . . . , 0.5
}

5, . . . , 100

{

{

}

Empirical results. Figure 7 reports the area under the precision/recall curve for each bench-
mark and all algorithms.

Figure 7: Bivariate Causal Modelling: Area under the precision/recall curve for the ﬁve datasets.
A full table of the scores is given in Appendix 3.

Methods based on simple regression like the bivariate ﬁt and Lingam are outperformed
as they underﬁt the data generative process. CDS and IGCI obtain very good results on few
datasets. Typically, IGCI takes advantage of some speciﬁc features of the dataset, (e.g.
the
cause entropy being lower than the effect entropy in CE-Multi), but remains at chance level
otherwise. ANM-HSIC yields good results when the additive assumption holds (e.g. on
CE-Gauss), but fails otherwise. PNL, less restrictive than ANM, yields overall good results
compared to the former methods. Jarfo, a voting procedure, can in principle yield the best of
the above methods and does obtain good results on artiﬁcial data. However, it does not per-
form well on the real dataset CE-Tueb; this counter-performance is blamed on the differences
between all ﬁve benchmark distributions and the lack of generalization / transfer learning.

Lastly, generative methods GPI and CGNN ((cid:92)MMDk) perform well on most datasets, in-
cluding the real-world cause-effect pairs CE-T¨ub, in counterpart for a higher computational
cost (resp. 32 min on CPU for GPI and 24 min on GPU for CGNN). Using the linear MMD

6Using the R program available at https://github.com/ssamot/causality for ANM, IGCI, PNL,

GPI and LiNGAM.

16

approximation Lopez-Paz (2016), CGNN ((cid:92)MMD
cost by a factor of 5 without hindering the performance.

m
k as explained in appendix 8.1) reduces the

Overall, CGNN demonstrates competitive performance on the cause-effect inference prob-

lem, where it is necessary to discover distributional asymmetries.

5.3 Identifying v-structures

A second series of experiments is conducted to investigate the method performances on variable
triplets, where multivariate effects and conditional variable independence must be taken into
account to identify the Markov equivalence class of a DAG. The considered setting is that
of variable triplets (A, B,C) in the linear Gaussian case, where asymmetries between cause
and effect cannot be exploited (Shimizu et al., 2006) and conditional independence tests are
required. In particular strict pairwise methods can hardly be used due to un-identiﬁability (as
each pair involves a linear mechanism with Gaussian input and additive Gaussian noise) (Hoyer
et al., 2009).

With no loss of generality, the graph skeleton involving variables (A, B,C) is A

C. All
three causal models (up to variable renaming) based on this skeleton are used to generate 500-
sample datasets, where the random noise variables are independent centered Gaussian variables.

−

−

B

(a) Chain structure

(c) reversed-V structure

(d) V-structure

A

B

C

A

B

C

A

B

C

A = EA
B = A + EB
C = B + EC






B = EB
A = B + EA
C = B + EC






A = EA
C = EC
B = A +C + EB






Figure 8: Datasets generated from the three DAG conﬁgurations with skeleton A

B

C

−

−

Given skeleton A

B

C, each dataset is used to model the possible four CGNN structures

(Fig. 8, with generative SEMs):

−

−

Chain structures ABC (A = f1(E1), B = f2(A, E2) , C = f3(B, E3) and CBA (C = f1(E1), B =
f2(C, E2) , A = f3(B, E3))

V structure: A = f1(E1), C = f2(E2) , B = f3(A,C, E3)

reversed V structure: B = f1(E1), A = f2(B, E2) , C = f3(B, E3)

•

•

•

Let CABC, CCBA, CV

structure and CreversedV denote the scores of the CGNN models respec-
tively attached to these structures. The scores computed on all three datasets are displayed in
Table 1 (average over 64 runs; the standard deviation is indicated in parenthesis).

−

non V-structures

Score

Chain str.

Reversed-V str.

CABC
CCBA
CreversedV
CV structure

0.122 (0.009)
0.121 (0.006)
0.122 (0.007)
0.202 (0.004)

0.124 (0.007)
0.127 (0.008)
0.125 (0.006)
0.180 (0.005)

V structure
V-structure

0.172 (0.005)
0.171 (0.004)
0.172 (0.004)
0.127 (0.005)

Table 1: CGNN-MMD scores for all models on all datasets. Smaller scores indicate a better
match. CGNN correctly identiﬁes V-structure vs. other structures.

17

CGNN scores support a clear and signiﬁcant discrimination between the V-structure and
all other structures (noting that the other structures are Markov equivalent and thus can hardly
be distinguished).

This second series of experiments thus shows that CGNN can effectively detect, and take

advantage of, conditional independence between variables.

5.4 Multivariate causal modeling under Causal Sufﬁciency Assumption

Let X = [X1, ..., Xd] be a set of continuous variables, satisfying the Causal Markov, faithfulness
and causal sufﬁciency assumptions. To that end, all experiments provide all algorithms the true
graph skeleton, so their ability to orient edges is compared in a fair way. This allows us to
separate the task of orienting the graph from that of uncovering the skeleton.

5.4.1 RESULTS ON ARTIFICIAL GRAPHS WITH ADDITIVE AND MULTIPLICATIVE NOISES

We draw 500 samples from 20 training artiﬁcial causal graphs and 20 test artiﬁcial causal
graphs on 20 variables. Each variable has a number of parents uniformly drawn in [[0, 5]]; fis
are randomly generated polynomials involving additive/multiplicative noise.7

We compare CGNN to the PC algorithm Spirtes et al. (1993), the score-based methods GES
Chickering (2002), LiNGAM Shimizu et al. (2006), causal additive model (CAM) B¨uhlmann
et al. (2014) and with the pairwise methods ANM and Jarfo. For PC, we employ the better-
performing, order-independent version of the PC algorithm proposed by Colombo and Maathuis
(2014). PC needs the speciﬁcation of a conditional independence test. We compare PC-
Gaussian, which employs a Gaussian conditional independence test on Fisher z-transformations,
and PC-HSIC, which uses the HSIC conditional independence test with the Gamma approxi-
mation Gretton et al. (2005). PC and GES are implemented in the pcalg package Kalisch et al.
(2012).

All hyperparameters are set on the training graphs in order to maximize the Area Under the
Precision/Recall score (AUPR). For the Gaussian conditional independence test and the HSIC
conditional independence test, the signiﬁcance level achieving best result on the training set are
respectively 0.1 and 0.05 . For GES, the penalization parameter is set to 3 on the training set.
For CGNN, nh is set to 20 on the training set. For CAM, the cutoff value is set to 0.001.

Figure 9 (left) displays the performance of all algorithms obtained by starting from the
exact skeleton on the test set of artiﬁcial graphs and measured from the AUPR (Area Under
the Precision/Recall curve), the Structural Hamming Distance (SHD, the number of edge mod-
iﬁcations to transform one graph into another) and the Structural Intervention Distance (SID,
the number of equivalent two-variable interventions between two graphs) Peters and B¨uhlmann
(2013).

CGNN obtains signiﬁcant better results with SHD and SID compared to the other algo-
rithms when the task is to discover the causal from the true skeleton. One resulting graph is
shown on Figure 10. There are 3 mistakes on this graph (red edges) (in lines with an SHD on
average of 2.5).

Constraints based method PC with powerful HSIC conditional independence test is the sec-
ond best performing method. It highlights the fact that when the skeleton is known, exploiting
the structure of the graph leads to good results compared to pairwise methods using only local
information. Notably, as seen on Figure 10, this type of DAG has a lot of v-structure, as many
nodes have more than one parent in the graph, but this is not always the case as shown in the
next subsection.

Overall CGNN and PC-HSIC are the most computationally expensive methods, taking an

average of 4 hours on GPU and 15 hours on CPU, respectively.

The robustness of the approach is validated by randomly perturbing 20% edges in the graph
skeletons provided to all algorithms (introducing about 10 false edges over 50 in each skeleton).
As shown on Table 4 (right) in Appendix, and as could be expected, the scores of all algorithms

7The data generator is available at https://github.com/GoudetOlivie/CGNN. The datasets consid-

ered are available at http://dx.doi.org/10.7910/DVN/UZMB69.

18

Figure 9: Average (std. dev.) AUPR results for the orientation of 20 artiﬁcial graphs given true
skeleton (left) and artiﬁcial graphs given skeleton with 20% error (right). A full table of the
scores, including the metrics Structural Hamming Distance (SHD) and Structural Intervention
(SID) (Peters and B¨uhlmann, 2013) is shown on Table 4 in section in section ”Table of Scores
for the Experiments on Graphs” in Appendix.

are lower when spurious edges are introduced. Among the least robust methods are constraint-
based methods; a tentative explanation is that they heavily rely on the graph structure to orient
edges. By comparison pairwise methods are more robust because each edge is oriented sep-
arately. As CGNN leverages conditional independence but also distributional asymmetry like
pairwise methods, it obtains overall more robust results when there are errors in the skeleton
compared to PC-HSIC. However one can notice that a better SHD score is obtained by CAM,
on the skeleton with 20% error. This is due to the exclusive last edge pruning step of CAM,
which removes spurious links in the skeleton.

CGNN obtains overall good results on these artiﬁcial datasets. It offers the advantage to
deliver a full generative model useful for simulation (while e.g., Jarfo and PC-HSIC only give
the causality graph). To explore the scalability of the approach, 5 artiﬁcial graphs with 100
variables have been considered, achieving an AUPRC of 85.5
4, in 30 hours of computation
on four NVIDIA 1080Ti GPUs.

±

Figure 10: Orientation by CGNN of artiﬁcial graph with 20 nodes. Green edges are good
orientation and red arrows false orientation. 3 edges are red and 42 are green. The strength
of the line refers to the conﬁdence of the algorithm.

5.4.2 RESULT ON BIOLOGICAL DATA

We now evaluate CGNN on biological networks. First we apply it on simulated gene expression
data and then on real protein network.

Syntren artiﬁcial simulator First we apply CGNN on SynTREN (Van den Bulcke et al.,
2006) from sub-networks of E. coli (Shen-Orr et al., 2002). SynTREN creates synthetic tran-
scriptional regulatory networks and produces simulated gene expression data that approxi-

19

mates experimental data. Interaction kinetics are modeled by complex mechanisms based on
Michaelis-Menten and Hill kinetics (Mendes et al., 2003).

With Syntren, we simulate 20 subnetworks of 20 nodes and 5 subnetworks with 50 nodes.
For the sake of reproducibility, we use the random seeds of 0, 1 . . . 19 and 0, 1 . . . 4 for each graph
generation with respectively 20 nodes and 50 nodes. The default Syntren parameters are used:
a probability of 0.3 for complex 2-regulator interactions and a value of 0.1 for Biological noise,
experimental noise and Noise on correlated inputs. For each graph, Syntren give us expression
datasets with 500 samples.

Figure 11: Average (std. dev.) AUPR results for the orientation of 20 artiﬁcial graphs generated
with the SynTReN simulator with 20 nodes (left), 50 nodes (middle), and real protein network
given true skeleton (right). A full table of the scores, including the metrics Structural Hamming
Distance (SHD) and Structural Intervention (SID) (Peters and B¨uhlmann, 2013) is included in
section ”Table of Scores for the Experiments on Graphs” in Appendix.

Figure 11 (left and middle) and Table 5 in section ”Table of Scores for the Experiments on
Graphs” in Appendix display the performance of all algorithms obtained by starting from the
exact skeleton of the causal graph with same hyper-parameters as in the previous subsection.
As a note, we canceled the PC-HSIC algorithm after 50 hours of running time.

Constraint based methods obtain low score on this type of graph dataset. It may be ex-
plained by the type of structure involved.
Indeed as seen of Figure 12, there are very few
v-structures in this type of network, making impossible the orientation of an important number
of edges by using only conditional independence tests. Overall the methods CAM and CGNN
that take into account of both distributional asymmetry and multivariate interactions, get the
best scores. CGNN obtain the best results in AUPR, SHD and SID for graph with 20 nodes and
50 nodes, showing that this method can be used to infer networks having complex distribution,
complex causal mechanisms and interactions. The Figure 12 shows the resulting graph obtain
with CGNN. Edges with good orientation are displayed in green and edge with false orientation
in red.

5.4.3 RESULTS ON BIOLOGICAL REAL-WORLD DATA

CGNN is applied to the protein network problem Sachs et al. (2005), using the Anti-CD3/CD28
dataset with 853 observational data points corresponding to general perturbations without spe-
ciﬁc interventions. All algorithms were given the skeleton of the causal graph (Sachs et al.,
2005, Fig. 2) with same hyper-parameters as in the previous subsection. We run each algorithm
on 10-fold cross-validation. Table 6 in Appendix reports average (std. dev.) results.

Constraint-based algorithms obtain surprisingly low scores, because they cannot identify
many V-structures in this graph. We conﬁrm this by evaluating conditional independence tests
for the adjacent tuples of nodes pip3-akt-pka, pka-pmek-pkc, pka-raf -pkc and we do not ﬁnd
strong evidences for V-structure. Therefore methods based on distributional asymmetry be-
tween cause and effect seem better suited to this dataset. CGNN obtains good results compared
to the other algorithms. Notably, Figure 13 shows that CGNN is able to recover the strong sig-
nal transduction pathway raf
erk reported in Sachs et al. (2005) and corresponding to
clear direct enzyme-substrate causal effect. CGNN gives important scores for edges with good

mek

→

→

20

Figure 12: Orientation by CGNN of E. coli subnetwork with 50 nodes and corresponding to
Syntren simulation with random seed 0. Green edges are good orientation and red arrows false
orientation. The strength of the line refers to the conﬁdence of the algorithm.

pip2

plcg

pip2

plcg

mek

ra f

jnk

mek

ra f

jnk

erk

akt

erk

akt

pip3

pka

pip3

pka

pkc

p38

(a) Ground truth

pip2

plcg

pkc

p38

(c) CAM

erk

akt

erk

akt

pip3

pka

pip3

pka

mek

ra f

jnk

mek

ra f

jnk

pkc

p38

(b) GES

pip2

plcg

pkc

p38

(d) CGNN

Figure 13: Causal protein network

orientation (green line), and low scores (thinnest edges) to the wrong edges (red line), suggest-
ing that false causal discoveries may be controlled by using the conﬁdence scores deﬁned in
Eq. (10).

21

6. Towards predicting confounding effects

In this subsection we propose an extension of our algorithm relaxing the causal sufﬁciency as-
sumption. We are still assuming the Causal Markov and faithfulness assumptions, thus three
options have to be considered for each edge (Xi, X j) of the skeleton representing a direct de-
X j (both variables are consequences of common hidden
pendency: Xi →
variables).

Xi and Xi ↔

X j, X j →

6.1 Principle

X j edge in the graph skeleton.

Hidden common causes are modeled through correlated random noise. Formally, an additional
noise variable Ei, j is associated to each Xi −
We use such new models with correlated noise to study the robustness of our graph recon-
struction algorithm to increasing violations of causal sufﬁciency, by occluding variables from
our datasets. For example, consider the FCM on X = [X1, . . . , X5] that was presented on Figure
1. If variable X1 would be missing from data, the correlated noise E2,3 would be responsible
X3 in the skeleton of our new type
for the existence of a double headed arrow connection X2 ↔
of model. The resulting FCM is shown in Figure 14. Notice that direct causal effects such as
X3 →

X5 may persist, even in presence of possible confounding effects.

X5 or X4 →

E2

E2,3

E3

f3 E3,5

E4,5

f4

f2

X2

X3

E4

X4

E5

f5

X5



X2 = f2(E2, E2,3)
X3 = f3(E3, E2,3, E3,5)

X4 = f4(E4, E4,5)
X5 = f5(X3, X4, E5, E3,5, E4,5)


Figure 14: The Functional Causal Model (FCM) on X = [X1, . . . , X5] with the missing variable
X1

Formally, given a graph skeleton S , the FCM with correlated noise variables is deﬁned as:

fi(XPa(i;G ), Ei, ENe(i;S )),
where Ne(i; S ) is the set of indices of all the variables adjacent to variable Xi in the skeleton

Xi ←

(11)

S .

One can notice that this model corresponds to the most general formulation of the FCM
with potential confounders for each pair of variables in a given skeleton (representing direct
dependencies) where each random variable Ei, j summarizes all the unknown inﬂuences of (pos-
sibly multiple) hidden variables inﬂuencing the two variables Xi and X j.

Here we make a clear distinction between the directed acyclic graph denoted G and the
skeleton S . Indeed, due to the presence of confounding correlated noise, any variable in G can
be removed without altering S . We use the same generative neural network to model the new
FCM presented in Equation 11. The difference is the new noise variables having effect on pairs
of variables simultaneously. However, since the correlated noise FCM is still deﬁned over a
directed acyclic graph G , the functions ˆf1, . . . , ˆfd of the model, which we implement as neural
networks, the model can still be learned end-to-end using backpropagation based on the CGNN
loss.

All edges are evaluated with these correlated noises, the goal being to see whether intro-

ducing a correlated noise explains the dependence between the two variables Xi and X j.

As mentioned before, the score used by CGNN is:
S(C ˆG , ˆf , D) = (cid:92)MMDk(D,

D) + λ

G
|

|

(cid:98)

22

(cid:98)

(12)

G
|

|

(cid:98)

where

is the total number of edges in the DAG. In the graph search, for any given
edge, we compare the score associated to the graph considered with and without this edge. If
the contribution of this edge is negligible compared to a given threshold lambda, the edge is
considered as spurious.

The non-parametric optimization of the ˆG structure is also achieved using a Hill-Climbing
algorithm; in each step an edge of S is randomly drawn and modiﬁed in ˆG using one out of the
possible three operators: reverse the edge, add an edge and remove an edge. Other algorithmic
details are as in Section 4.3.2: the greedy search optimizes the penalized loss function (Eq. 12).
For CGNN, we set the hyperparameter λ = 5

5 ﬁtted on the training graph dataset.

10−

The algorithm stops when no improvement is obtained. Each causal edge Xi →

associated with a score, measuring its contribution to the global score:

X j in G is

×

SXi→
X j}
Missing edges are associated with a score 0.

Xi→

X j = S(C ˆG

−{

, ˆf , D)

S(C ˆG , ˆf , D)

−

(13)

6.2 Experimental validation

Benchmarks. The empirical validation of this extension of CGNN is conducted on same
benchmarks as in Section 5.4 (Gi, i
[[2, 5]]), where 3 variables (causes for at least two other
variables in the graph) have been randomly removed.8 The true graph skeleton is augmented
Y for all X, Y that are consequences of a same removed cause. All algorithms
with edges X
are provided with the same graph skeleton for a fair comparison. The task is to both orient
the edges in the skeleton, and remove the spurious direct dependencies created by latent causal
variables.

−

∈

Baselines. CGNN is compared with state of art methods: i) constraint-based RFCI (Colombo
et al., 2012), extending the PC method equipped with Gaussian conditional independence test
(RFCI-Gaussian) and the gamma HSIC conditional independence test (Gretton et al., 2005)
(RFCI-HSIC). We use the order-independent constraint-based version proposed by Colombo
and Maathuis (2014) and the majority rules for the orientation of the edges. For CGNN, we set
5 ﬁtted on the training graph dataset. Jarfo is trained on the
the hyperparameter λ = 5
16,200 pairs of the cause-effect pair challenge (Guyon, 2013, 2014) to detect for each pair of
variable if Xi →

×
Xi or Xi ↔

Yi, Yi →

10−

Yi.

Table 2: AUPR, SHD and SID on causal discovery with confounders. ∗ denotes signiﬁcance at
p = 10−

2.

method

AUPR

SHD

SID

RFCI-Gaussian
RFCI-HSIC
Jarfo
CGNN ((cid:92)MMDk)

0.22 (0.08)
0.41 (0.09)
0.54 (0.21)

21.9 (7.5)
17.1 (6.2)
20.1 (14.8)

174.9 (58.2)
124.6 (52.3)
98.2 (49.6)

0.71* (0.13)

11.7* (5.5)

53.55* (48.1)

Results.
comparative performances are shown in Table 2, reporting the area under the preci-
sion/recall curve. Overall, these results conﬁrm the robustness of the CGNN proposed approach
w.r.t. confounders, and its competitiveness w.r.t. RFCI with powerful conditional independence
test (RFCI-HSIC). Interestingly, the effective causal relations between the visible variables are
associated with a high score; spurious links due to hidden latent variables get a low score or are
removed.

8The datasets considered are available at http://dx.doi.org/10.7910/DVN/UZMB69

23

7. Discussion and Perspectives

This paper introduces CGNN, a new framework and methodology for functional causal model
learning, leveraging the power and non-parametric ﬂexibility of Generative Neural Networks.
CGNN seamlessly accommodates causal modeling in presence of confounders, and its ex-
tensive empirical validation demonstrates its merits compared to the state of the art on medium-
size problems. We believe that our approach opens new avenues of research, both from the point
of view of leveraging the power of deep learning in causal discovery and from the point of view
of building deep networks with better structure interpretability. Once the model is learned, the
CGNNs present the advantage to be fully parametrized and may be used to simulate interven-
tions on one or more variables of the model and evaluate their impact on a set of target variables.
This usage is relevant in a wide variety of domains, typically among medical and sociological
domains.

The main limitation of CGNN is its computational cost, due to the quadratic complexity of
the CGNN learning criterion w.r.t. the data size, based on the Maximum Mean Discrepancy be-
tween the generated and the observed data. A linear approximation thereof has been proposed,
with comparable empirical performances.

The main perspective for further research aims at a better scalability of the approach from
medium to large problems. On the one hand, the computational scalability could be tackled by
using embedded framework for the structure optimization (inspired by lasso methods). Another
perspective regards the extension of the approach to categorical variables.

References

Peter B¨uhlmann, Jonas Peters, Jan Ernest, et al. Cam: Causal additive models, high-dimensional order

search and penalized regression. The Annals of Statistics, 42(6):2526–2556, 2014.

David Maxwell Chickering. Optimal structure identiﬁcation with greedy search. Journal of Machine

Learning Research, 3(Nov):507–554, 2002.

Kyunghyun Cho, Bart Van Merri¨enboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. Learning phrase representations using RNN encoder-decoder for sta-
tistical machine translation. arXiv, 2014.

Diego Colombo and Marloes H Maathuis. Order-independent constraint-based causal structure learning.

Journal of Machine Learning Research, 15(1):3741–3782, 2014.

Diego Colombo, Marloes H Maathuis, Markus Kalisch, and Thomas S Richardson. Learning high-
dimensional directed acyclic graphs with latent and selection variables. The Annals of Statistics, pages
294–321, 2012.

George Cybenko. Approximation by superpositions of a sigmoidal function. Mathematics of Control,

Signals, and Systems (MCSS), 2(4):303–314, 1989.

Povilas Daniusis, Dominik Janzing, Joris Mooij, Jakob Zscheischler, Bastian Steudel, Kun Zhang, and
Bernhard Sch¨olkopf. Inferring deterministic causal relations. arXiv preprint arXiv:1203.3475, 2012.

Mathias Drton and Marloes H Maathuis. Structure learning in graphical modeling. Annual Review of

Statistics and Its Application, (0), 2016.

RE Edwards. Fourier analysis on groups, 1964.

Jos´e AR Fonollosa. Conditional distribution variability measures for causality detection. arXiv preprint

arXiv:1601.06680, 2016.

Arthur S Goldberger. Reverse regression and salary discrimination. Journal of Human Resources, 1984.

Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. Generative adversarial nets. In Neural Information Processing Systems
(NIPS), pages 2672–2680, 2014.

24

Arthur Gretton, Ralf Herbrich, Alexander Smola, Olivier Bousquet, and Bernhard Sch¨olkopf. Kernel
methods for measuring independence. Journal of Machine Learning Research, 6(Dec):2075–2129,
2005.

Arthur Gretton, Karsten M Borgwardt, Malte Rasch, Bernhard Sch¨olkopf, Alexander J Smola, et al. A

kernel method for the two-sample-problem. 19:513, 2007.

Isabelle Guyon. Chalearn cause effect pairs challenge, 2013. URL http://www.causality.inf.

ethz.ch/cause-effect.php.

Isabelle Guyon. Chalearn fast causation coefﬁcient challenge. 2014.

Geoffrey Hinton, Li Deng, Dong Yu, George E Dahl, Abdel-rahman Mohamed, Navdeep Jaitly, Andrew
Senior, Vincent Vanhoucke, Patrick Nguyen, Tara N Sainath, et al. Deep neural networks for acoustic
modeling in speech recognition: The shared views of four research groups. IEEE Signal Processing
Magazine, 2012.

Patrik O Hoyer, Dominik Janzing, Joris M Mooij, Jonas Peters, and Bernhard Sch¨olkopf. Nonlinear
causal discovery with additive noise models. In Neural Information Processing Systems (NIPS), pages
689–696, 2009.

Markus Kalisch, Martin M¨achler, Diego Colombo, Marloes H Maathuis, Peter B¨uhlmann, et al. Causal
inference using graphical models with the r package pcalg. Journal of Statistical Software, 47(11):
1–26, 2012.

D. P. Kingma and J. Ba. Adam: A Method for Stochastic Optimization. ArXiv e-prints, December 2014.

Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114,

2013.

neural networks. NIPS, 2012.

Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classiﬁcation with deep convolutional

David Lopez-Paz. From dependence to causation. PhD thesis, University of Cambridge, 2016.

David Lopez-Paz and Maxime Oquab.

Revisiting classiﬁer two-sample tests.

arXiv preprint

arXiv:1610.06545, 2016.

David Lopez-Paz, Krikamol Muandet, Bernhard Sch¨olkopf, and Ilya O Tolstikhin. Towards a learning

theory of cause-effect inference. In ICML, pages 1452–1461, 2015.

Pedro Mendes, Wei Sha, and Keying Ye. Artiﬁcial gene networks for objective comparison of analysis

algorithms. Bioinformatics, 19(suppl 2):ii122–ii129, 2003.

Joris M Mooij, Jonas Peters, Dominik Janzing, Jakob Zscheischler, and Bernhard Sch¨olkopf. Distin-
guishing cause from effect using observational data: methods and benchmarks. Journal of Machine
Learning Research, 17(32):1–102, 2016.

Preetam Nandy, Alain Hauser, and Marloes H Maathuis. High-dimensional consistency in score-based

and hybrid structure learning. arXiv preprint arXiv:1507.02608, 2015.

Juan Miguel Ogarrio, Peter Spirtes, and Joe Ramsey. A hybrid causal search algorithm for latent variable

models. In Conference on Probabilistic Graphical Models, pages 368–379, 2016.

Judea Pearl. Causality: models, reasoning and inference. Econometric Theory, 19(675-685):46, 2003.

Judea Pearl. Causality. Cambridge university press, 2009.

Judea Pearl and Thomas Verma. A formal theory of inductive causation. University of California (Los

Angeles). Computer Science Department, 1991.

25

Jonas Peters and Peter B¨uhlmann. Structural intervention distance (sid) for evaluating causal graphs.

arXiv preprint arXiv:1306.1043, 2013.

Jonas Peters, Dominik Janzing, and Bernhard Sch¨olkopf. Elements of Causal Inference - Foundations

and Learning Algorithms. MIT Press, 2017.

John A Quinn, Joris M Mooij, Tom Heskes, and Michael Biehl. Learning of causal relations. In ESANN,

2011.

arXiv:1507.07749, 2015.

962–1030, 2002.

Joseph D Ramsey.

Scaling up greedy causal search for continuous variables.

arXiv preprint

Thomas Richardson and Peter Spirtes. Ancestral graph markov models. The Annals of Statistics, 30(4):

Karen Sachs, Omar Perez, Dana Pe’er, Douglas A Lauffenburger, and Garry P Nolan. Causal protein-
signaling networks derived from multiparameter single-cell data. Science, 308(5721):523–529, 2005.

Richard Scheines. An introduction to causal inference. 1997.

Eleni Sgouritsa, Dominik Janzing, Philipp Hennig, and Bernhard Sch¨olkopf. Inference of cause and effect

with unsupervised inverse regression. In AISTATS, 2015.

Shai S Shen-Orr, Ron Milo, Shmoolik Mangan, and Uri Alon. Network motifs in the transcriptional

regulation network of escherichia coli. Nature genetics, 31(1):64, 2002.

Shohei Shimizu, Patrik O Hoyer, Aapo Hyv¨arinen, and Antti Kerminen. A linear non-gaussian acyclic

model for causal discovery. Journal of Machine Learning Research, 7(Oct):2003–2030, 2006.

David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George Van Den Driessche,
Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, et al. Mastering the
game of Go with deep neural networks and tree search. Nature, 2016.

Peter Spirtes and Kun Zhang. Causal discovery and inference: concepts and recent methodological

advances. In Applied informatics, volume 3, page 3. Springer Berlin Heidelberg, 2016.

Peter Spirtes, Clark Glymour, and Richard Scheines. Causation, prediction and search. 1993. Lecture

Notes in Statistics, 1993.

Peter Spirtes, Christopher Meek, Thomas Richardson, and Chris Meek. An algorithm for causal inference

in the presence of latent variables and selection bias. 1999.

Peter Spirtes, Clark N Glymour, and Richard Scheines. Causation, prediction, and search. MIT press,

2000.

Alexander Statnikov, Mikael Henaff, Nikita I Lytkin, and Constantin F Aliferis. New methods for sepa-

rating causes from effects in genomics data. BMC genomics, 13(8):S22, 2012.

Oliver Stegle, Dominik Janzing, Kun Zhang, Joris M Mooij, and Bernhard Sch¨olkopf. Probabilistic
latent variable models for distinguishing between cause and effect. In Neural Information Processing
Systems (NIPS), pages 1687–1695, 2010.

Ioannis Tsamardinos, Laura E Brown, and Constantin F Aliferis. The max-min hill-climbing bayesian

network structure learning algorithm. Machine learning, 65(1):31–78, 2006.

Tim Van den Bulcke, Koenraad Van Leemput, Bart Naudts, Piet van Remortel, Hongwu Ma, Alain Ver-
schoren, Bart De Moor, and Kathleen Marchal. Syntren: a generator of synthetic gene expression data
for design and analysis of structure learning algorithms. BMC bioinformatics, 7(1):43, 2006.

26

Thomas Verma and Judea Pearl. Equivalence and synthesis of causal models. In Proceedings of the Sixth
Annual Conference on Uncertainty in Artiﬁcial Intelligence, UAI ’90, pages 255–270, New York, NY,
USA, 1991. Elsevier Science Inc. ISBN 0-444-89264-8. URL http://dl.acm.org/citation.
cfm?id=647233.719736.

Makoto Yamada, Wittawat Jitkrittum, Leonid Sigal, Eric P Xing, and Masashi Sugiyama. High-
dimensional feature selection by feature-wise kernelized lasso. Neural computation, 26(1):185–207,
2014.

Kun Zhang and Aapo Hyv¨arinen. On the identiﬁability of the post-nonlinear causal model. In Proceedings
of the twenty-ﬁfth conference on uncertainty in artiﬁcial intelligence, pages 647–655. AUAI Press,
2009.

Kun Zhang, Jonas Peters, Dominik Janzing, and Bernhard Sch¨olkopf. Kernel-based conditional indepen-

dence test and application in causal discovery. arXiv preprint arXiv:1202.3775, 2012.

Kun Zhang, Zhikun Wang, Jiji Zhang, and Bernhard Sch¨olkopf. On estimation of functional causal
models: general results and application to the post-nonlinear causal model. ACM Transactions on
Intelligent Systems and Technology (TIST), 7(2):13, 2016.

27

8. Appendix

8.1 The Maximum Mean Discrepancy (MMD) statistic

The Maximum Mean Discrepancy (MMD) statistic (Gretton et al., 2007) measures the distance
between two probability distributions P and ˆP, deﬁned over Rd, as the real-valued quantity

MMDk(P, ˆP) =

µk(P)

µk( ˆP)

−

.

H
k

(cid:13)
(cid:13)
)
H
(cid:105)
·

(cid:13)
(cid:13)

k(x,

Here, µk =
)dP(x) is the kernel mean embedding of the distribution P, according to the
·
real-valued symmetric kernel function k(x, x(cid:48)) =
), k(x(cid:48),
k(x,
k with associated reproducing
·
(cid:104)
kernel Hilbert space Hk. Therefore, µk summarizes P as the expected value of the features
computed by k over samples drawn from P.

(cid:82)

In practical applications, we do not have access to the distributions P and ˆP, but to their re-
spective sets of samples D and ˆD, deﬁned in Section 4.2.1. In this case, we approximate the ker-
nel mean embedding µk(P) by the empirical kernel mean embedding µk(D) = 1
),
D
·
|
and respectively for ˆP. Then, the empirical MMD statistic is

D k(x,
∈

∑x

|

(cid:92)MMDk(D, ˆD) =

µk(D)

µk( ˆD)

−

k(xi, x j) +

k( ˆxi, ˆx j)

k(xi, ˆx j).

1
n2

n
∑
i, j

2
n2

n
∑
i, j

−

=
H
k

1
n2

n
∑
i, j

(cid:13)
(cid:13)

(cid:13)
(cid:13)

→

Importantly, the empirical MMD tends to zero as n

∞ if and only if P = ˆP, as long as
k is a characteristic kernel (Gretton et al., 2007). This property makes the MMD an excellent
choice to model how close the observational distribution P is to the estimated observational
distribution ˆP. Throughout this paper, we will employ a particular characteristic kernel: the
2
2), where γ > 0 is a hyperparameter controlling the
Gaussian kernel k(x, x(cid:48)) = exp(
smoothness of the features.

In terms of computation, the evaluation of MMDk(D, ˆD) takes O(n2) time, which is pro-
hibitive for large n. When using a shift-invariant kernel, such as the Gaussian kernel, one can
invoke Bochner’s theorem (Edwards, 1964) to obtain a linear-time approximation to the empir-
ical MMD (Lopez-Paz et al., 2015), with form

γ
−

x(cid:48)(cid:107)

x
(cid:107)

−

(cid:92)MMD

m
k (D, ˆD) =

ˆµk(D)

ˆµk( ˆD)

Rm

−

(cid:13)
and O(mn) evaluation time. Here, the approximate empirical kernel mean embedding has form
(cid:13)

(cid:13)
(cid:13)

ˆµk(D) =

2
m

1
D
|

|

∑
D
x
∈

(cid:114)

w1, x
[cos(
(cid:104)

(cid:105)

wm, x
+ b1), . . . , cos(
(cid:104)

(cid:105)

+ bm)] ,

U[0, 2π], for i =
In our experiments, we compare the performance and computation times of both

where wi is drawn from the normalized Fourier transform of k, and bi ∼
1, . . . , m.
(cid:92)MMDk and (cid:92)MMD

m
k .

8.2 Proofs

Proposition 1 Let X = [X1, . . . , Xd] denote a set of continuous random variables with joint distribution P,
and further assume that the joint density function h of P is continuous and strictly positive on a compact
and convex subset of Rd, and zero elsewhere. Letting G be a DAG such that P can be factorized along G ,

P(X) = ∏
i

P(Xi|

XPa(i;G ))

there exists f = ( f1, . . . , fd) with fi a continuous function with compact support in R|
[0, 1] such
that P(X) equals the generative model deﬁned from FCM (G , f , E ), with E = U [0, 1] the uniform distri-
bution on [0, 1].

| ×

Pa(i;G )

Proof By induction on the topological order of G . Let Xi be such that
= 0 and
consider the cumulative distribution Fi(xi) deﬁned over the domain of Xi (Fi(xi) = Pr(Xi < xi)).

Pa(i; G )
|
|

28

(cid:55)→

(ei) and setting Qi = fi yields the result.

Fi is strictly monotonous as the joint density function is strictly positive therefore its inverse,
the quantile function Qi : [0, 1]
dom(Xi) is deﬁned and continuous. By construction, Qi(ei) =
1
F −
i
Assume fi be deﬁned for all variables Xi with topological order less than m. Let X j with
topological order m and Z the vector of its parent variables. For any noise vector e = (ei, i
∈
Pa( j; G )) be the value vector of variables in Z deﬁned from e. The
Pa( j; G )) let z = (xi, i
Z = z) is strictly continuous and
conditional cumulative distribution Fj(x j|
monotonous wrt x j, and can be inverted using the same argument as above. Then we can deﬁne
1
(z, e j).
f j(z, e j) = F −
j

Z = z) = Pr(X j < x j|

∈

Let K j = dom(X j) and KPa( j;G ) = dom(Z). We will show now that the function f j is con-

| ×
∈

[0, 1].
K j ×

tinuous on KPa( j;G ) ×

[0, 1], a compact subset of R|

Pa( j;G )

h j(u,z)
h j(z) du,

h j(u,z)
h j(z)

R such that, for (x j, z)

By assumption, there exist a j ∈

is continuous on the compact K j ×

x j
z) =
a j
with h j a continuous and strictly positive density function. For (a, b)
KPa( j;G ), as the
(cid:82)
h j(u,z)
a
z) =
function (u, z)
h j(z) du
KPa( j;G ), lim
a j
a
x j→
h j(u,b)
(cid:82)
h j(b) on K j, according to exchanging limits theo-

→
uniformly on KPa( j;G ) and lim
b
z
→
rem, F is continuous on (a, b).
For any sequence zn →
z) = u has unique root x j = f j(z, u), the root of F(x j|

two sequences un and x j,n, respectively on [0, 1] and K j, such that un →
F(x j|
converge to x j. Then the function (z, u)

x j
a j
(cid:82)
z, we have that F(x j|

z) uniformly in x j. Let deﬁne
x j. As
u and x j,n →
zn) = un, that is, x j,n = f j(zn, un)
[0, 1].

KPa( j;G ), F(x j|
K j ×
∈
F(x j|

F(x j|

F(x j|

z) =

zn)

→

f j(z, u) is continuous on KPa(i;G ) ×

→

Proposition 2 For m
[[1, d]], let Zm denote the set of variables with topological order less than m and
let dm be its size. For any dm-dimensional vector of noise values e(m), let zm(e(m)) (resp.
zm(e(m))) be the
vector of values computed in topological order from the FCM (G , f , E ) (resp. the CGNN (G , ˆf , E )). For
any ε > 0, there exists a set of networks ˆf with architecture G such that

∈

(cid:98)

e(m),
∀

zm(e(m))
(cid:107)

−

zm(e(m))
(cid:107)

< ε

(14)

(cid:98)

Pa(i; G )
|
|

Proof By induction on the topological order of G . Let Xi be such that
= 0. Follow-
ing the universal approximation theorem Cybenko (1989), as fi is a continuous function over a
compact of R, there exists a neural net ˆfi such that
∞ < ε/d1. Thus Eq. 14 holds for
the set of networks ˆfi for i ranging over variables with topological order 0.
Let us assume that Prop. 2 holds up to m, and let us assume for brevity that there exists a single
variable X j with topological order m + 1. Letting ˆf j be such that
∞ < ε/3 (based on
(cid:107)
the universal approximation property), letting δ be such that for all u
< ε/3
(by absolute continuity) and letting ˆfi satisfying Eq. 14 for i with topological order less than m
for min(ε/3, δ )/dm, it comes:
ˆf j(zm, e j)
|

ˆf j(cid:107)
f j −
ˆf j(u)
−
(cid:107)
(ˆzm, ˆf j( ˆzm, e j))
ˆzm(cid:107)
zm −
< ε/3 + ε/3 + ε/3, which ends the proof.

(zm, f j(zm, e j))
(cid:107)
ˆf j( ˆzm, e j)
|

ˆf j(u + δ )
(cid:107)

ˆf j(zm, e j)

f j(zm, e j)

fi −

(cid:107) ≤ (cid:107)

ˆfi(cid:107)

−

+

+

−

−

(cid:107)

|

|

1 . . . ˆf t

Proposition 3 Let D be an inﬁnite observational sample generated from (G , f , E ). With same notations
as in Prop. 2, for every sequence εt such that εt > 0 goes to zero when t
ft =
d) such that (cid:92)MMDk between D and an inﬁnite size sample
ft , E )
( ˆf t
(cid:98)
is less than εt .
(cid:98)
Proof According to Prop. 2 and with same notations, letting εt > 0 go to 0 as t goes to inﬁnity,
consider ˆft = ( ˆf t
< εt .
denote the inﬁnite sample generated after ˆft . The score of the CGNN (G , ˆft , E )
zt (e(cid:48))) + k(

∞, there exists a set
Dt generated from the CGNN (G ,

d) and ˆzt deﬁned from ˆft such that for all e

ˆDt }
is (cid:92)MMDk(D, ˆDt ) = E

[k(z(e), z(e(cid:48)))

zt (e)
(cid:107)

z(e)
(cid:107)

1 . . . ˆf t

zt (e(cid:48)))].

2k(z(e),

[0, 1]d,

zt (e),

Let

→

−

∈

(cid:98)

(cid:98)

{

e,e(cid:48)

As ˆft converges towards f on the compact [0, 1]d, using the bounded convergence theorem
∞, it follows from the Gaussian
z(e) uniformly for t
(cid:98)

on a compact subset of Rd,

zt (e)

(cid:98)

−

→

(cid:98)
→

(cid:98)

29

kernel function being bounded and continuous that (cid:92)MMDk(D, ˆDt )

0, when t

∞.

→

→

Proposition 4 Let X = [X1, . . . , Xd] denote a set of continuous random variables with joint distribution
P, generated by a CGNN CG , f = (G , f , E ) with G , a directed acyclic graph. And let D be an inﬁnite
observational sample generated from this CGNN. We assume that P is Markov and faithful to the graph
G , and that every pair of variables (Xi, X j) that are d-connected in the graph are not independent. We
note

G , ˆf , E ). Then,

D an inﬁnite sample generated by a candidate CGNN, C
G = G and ˆf = f , then (cid:92)MMDk(D,
(cid:98)

D) = 0.

G , ˆf = (

(cid:98)
G characterized by the same adjacencies but not belonging to the Markov equivalence

(cid:98)

(i) If
(ii) For any graph
class of G , for all ˆf , (cid:92)MMDk(D,

(cid:98)

D)

= 0.

(cid:98)

(cid:98)

(cid:98)

G , ˆf = (
(ii) Let consider
(cid:98)
(cid:98)

Proof The proof of (i) is obvious, as with
by C

G , ˆf , E ) is equal to P, thus we have (cid:92)MMDk(D,

(cid:98)

D) = 0.

G = G and ˆf = f , the joint distribution ˆP generated

}

(cid:98)

(cid:98)

X,Y, Z
{

exists in G , but not in

a) First, we consider that a v-structure

G a DAG characterized by the same adjacencies but that do not belong to
the Markov equivalence class of G . According to Verma and Pearl (1991), as the DAG G and
G have the same adjacencies but are not Markov equivalent, there are not characterized by the
same v-structures.
(cid:98)
P is faithful to G and X and Z are not d-separated by Y in G , we have that (X
Now we consider the graph
generated by the CGNN C
independent, ˆP is Markov with respect to
d-separated by Y . By using the causal Markov assumption, we obtain that (X

G . As the distribution
Y ) in P.
Z
|
G . Let ˆf be a set of neural networks. We note ˆP the distribution
G is a directed acyclic graph and the variables Ei are mutually
G , X and Z are
Y ) in ˆP.
Z
|
G , but not in G . As
(cid:98)
X,Y, Z

is
{
not a v-structure in G , there is an ”unblocked path” between the variables X and Z, the variables
X and Z are d-connected. By assumption, there do not exist a set D not containing Y such that
(cid:98)
G , as
(X
is a v-structure, there exists a set D not containing Y that
d-separates X and Z. As for all CGNN C
G , ˆf generating a distribution ˆP, ˆP is Markov with
(cid:98)
respect to

(cid:98)
b) Second, we consider that a v-structure

G , we have that X

is not a v-structure in

D) in P. In
|

G , ˆf . As
(cid:98)

X,Y, Z
{

exists in

G . As

X,Y, Z

X,Y, Z

⊥(cid:54)⊥

⊥⊥

⊥⊥

Z

Z

(cid:98)

(cid:98)

}

}

}

{

{

}

(cid:98)

In the two cases a) and b) considered above, P and ˆP do not encode the same conditional

D in ˆP.
|

⊥⊥

(cid:98)

independence relations, thus are not equal. We have then (cid:92)MMDk(D, D (cid:48))

(cid:98)

= 0.

30

8.3 Table of scores for the experiments on cause-effect pairs

Table 3: Cause-effect relations: Area Under the Precision Recall curve on 5 benchmarks for the
cause-effect experiments (weighted accuracy in parenthesis for T¨ub). Underline values corre-
spond to best scores.

method

Cha

Net

Gauss Multi

T¨ub

Best ﬁt
LiNGAM
CDS
IGCI
ANM
PNL
Jarfo
GPI
CGNN ((cid:92)MMDk)
m
CGNN ((cid:92)MMD
k )

56.4
54.3
55.4
54.4
66.3
73.1
79.5
67.4

73.6
76.5

77.6
43.7
89.5
54.7
85.1
75.5
92.7
88.4

89.6
87.0

36.3
66.5
84.3
33.2
88.9
83.0
85.3
89.1

82.9
88.3

55.4
59.3
37.2
80.7
35.5
49.0
94.6
65.8

96.6
94.2

58.4 (44.9)
39.7 (44.3)
59.8 (65.5)
60.7 (62.6)
53.7 (59.5)
68.1 (66.2)
54.5 (59.5)
66.4 (62.6)

79.8 (74.4)
76.9 (72.7)

8.4 Table of scores for the experiments on graphs

Table 4: Average (std. dev.) results for the orientation of 20 artiﬁcial graphs given true skeleton
(left), artiﬁcial graphs given skeleton with 20% error (middle). ∗ denotes statistical signiﬁcance
at p = 10−

2. Underline values correspond to best scores.

Skeleton without error
SHD

AUPR

SID

Skeleton with 20% of error
SHD

SID

AUPR

Constraints
PC-Gauss
PC-HSIC

Pairwise
ANM
Jarfo

Score-based
GES
LiNGAM
CAM
m
CGNN ((cid:92)MMD
k )
CGNN ((cid:92)MMDk)

0.67 (0.11)
0.80 (0.08)

9.0 (3.4)
6.7 (3.2)

131 (70)
80.1 (38)

0.42 (0.06)
0.49 (0.06)

21.8 (5.5)
19.8 (5.1)

191.3 (73)
165.1 (67)

0.67 (0.11)
0.74 (0.10)

7.5 (3.0)
8.1 (4.7)

135.4 (63)
147.1 (94)

0.52 (0.10)
0.58 (0.09)

19.2 (5.5)
20.0 (6.8)

171.6 (66)
184.8 (88)

0.48 (0.13)
0.65 (0.10)
0.69 (0.13)
0.77 (0.09)
0.89* (0.09)

14.1 (5.8)
9.6 (3.8)
7.0 (4.3)
7.1 (2.7)
2.5* (2.0)

186.4 (86)
171 (86)
122 (76)
141 (59)
50.45* (45)

0.37 (0.08)
0.53 (0.10)
0.51 (0.11)
0.54 (0.08)
0.62 (0.12)

20.9 (5.5)
20.9 (6.8)
15.6 (5.7)
20 (10)
16.9 (4.5)

209 (83)
196 (83)
175 (80)
179 (102)
134.0* (55)

31

Table 5: Average (std. dev.) results for the orientation of 20 and 50 artiﬁcial graphs coming from
2. Underline
Syntren simulator given true skeleton. ∗ denotes statistical signiﬁcance at p = 10−
values correspond to best scores.

Syntren network 20 nodes

AUPR

SHD

SID

Syntren network 50 nodes
SHD

AUPR

SID

Constraints
PC-Gauss
PC-HSIC

Pairwise
ANM
Jarfo

Score-based
GES
LiNGAM
CAM
m
CGNN ((cid:92)MMD
k )
CGNN ((cid:92)MMDk)

0.40 (0.16)
0.38 (0.15)

16.3 (3.1)
23 (1.7)

198 (57)
175 (16)

0.22 (0.03)
-

61.5 (32)
-

993 (546)
-

0.36 (0.17)
0.42 (0.17)

10.1 (4.2)
10.5 (2.6)

138 (56)
148 (64)

0.35 (0.12)
0.45 (0.13)

29.8 (13.5)
26.2 (14)

677 (313)
610 (355)

0.44 (0.17)
0.40 (0.22)
0.73 (0.08)
0.80* (0.12)
0.79 (0.12)

9.8 (5.0)
10.1 (4.4)
4.0 (2.5)
3.2 (1.6)
3.1* (2.2)

116 (64)
135 (57)
49 (24)
45 (25)
43 (26)

0.52 (0.03)
0.37 (0.28)
0.69 (0.05)
0.82* (0.1)
0.75 (0.09)

21 (11)
33.4 (19)
14.8 (7)
10.2* (5.3)
12.2 (5.5)

462 (248)
757 (433)
285 (136)
247 (134)
309 (140)

Table 6: Average (std. dev.) results for the orientation of the real protein network given true
2. Underline values correspond to best
skeleton. ∗ denotes statistical signiﬁcance at p = 10−
scores.

Causal protein network
SHD

SID

AUPR

0.19 (0.07)
0.18 (0.01)

16.4 (1.3)
17.1 (1.1)

91.9 (12.3)
90.8 (2.6)

0.34 (0.05)
0.33 (0.02)

8.6 (1.3)
10.2 (0.8)

85.9 (10.1)
92.2 (5.2)

0.26 (0.01)
0.29 (0.03)
0.37 (0.10)
0.68 (0.07)
0.74* (0.09)

12.1 (0.3)
10.5 (0.8)
8.5 (2.2)
5.7 (1.7)
4.3* (1.6)

92.3 (5.4)
83.1 (4.8)
78.1 (10.3)
56.6 (10.0)
46.6* (12.4)

Constraints
PC-Gauss
PC-HSIC

Pairwise
ANM
Jarfo

Score-based
GES
LiNGAM
CAM
m
CGNN ((cid:92)MMD
k )
CGNN ((cid:92)MMDk)

32

8
1
0
2
 
c
e
D
 
3
 
 
]
L
M

.
t
a
t
s
[
 
 
3
v
1
2
3
5
0
.
9
0
7
1
:
v
i
X
r
a

Learning Functional Causal Models with Generative Neural
Networks ∗

Olivier Goudet †
TAU, LRI, CNRS, INRIA, Universit´e Paris-Sud
Gif-Sur-Yvette, 91190, France
Diviyan Kalainathan†
TAU, LRI, CNRS, INRIA, Universit´e Paris-Sud
Gif-Sur-Yvette, 91190, France

Philippe Caillou
TAU, LRI, CNRS, INRIA, Universit´e Paris-Sud
Gif-Sur-Yvette, 91190, France

Isabelle Guyon
TAU, LRI, CNRS, INRIA, Universit´e Paris-Sud
Gif-Sur-Yvette, 91190, France

David Lopez-Paz
Facebook AI Research
Paris, 75002, France

Mich`ele Sebag
TAU, LRI, CNRS, INRIA, Universit´e Paris-Sud
Gif-Sur-Yvette, 91190, France

OLIVIER.GOUDET@INRIA.FR

DIVIYAN.KALAINATHAN@INRIA.FR

CAILLOU@LRI.FR

ISABELLE.GUYON@U-PSUD.FR

DLP@FB.FR

MICHELE.SEBAG@LRI.FR

Abstract
We introduce a new approach to functional causal modeling from observational data, called
Causal Generative Neural Networks (CGNN). CGNN leverages the power of neural networks
to learn a generative model of the joint distribution of the observed variables, by minimizing the
Maximum Mean Discrepancy between generated and observed data. An approximate learning
criterion is proposed to scale the computational cost of the approach to linear complexity in the
number of observations. The performance of CGNN is studied throughout three experiments.
Firstly, CGNN is applied to cause-effect inference, where the task is to identify the best causal
hypothesis out of “X
X”. Secondly, CGNN is applied to the problem of iden-
tifying v-structures and conditional independences. Thirdly, CGNN is applied to multivariate
functional causal modeling: given a skeleton describing the direct dependences in a set of ran-
dom variables X = [X1, . . . , Xd], CGNN orients the edges in the skeleton to uncover the directed
acyclic causal graph describing the causal structure of the random variables. On all three tasks,
CGNN is extensively assessed on both artiﬁcial and real-world data, comparing favorably to
the state-of-the-art. Finally, CGNN is extended to handle the case of confounders, where latent
variables are involved in the overall causal model.

Y ” and “Y

→

→

Keywords: generative neural networks

causal structure discovery

cause-effect pair problem

functional causal models

structural equation models

·

·

·

·

∗∗ This article is a preprint of the chapter with the same name in the book Explainable and Interpretable Models
in Computer Vision and Machine Learning. Springer Series on Challenges in Machine Learning. 2018. Cham:
Springer International Publishing. Editors: Hugo Jair Escalante, Sergio Escalera, Isabelle Guyon, Xavier Bar´o and
Ya ‘gmur G¨uc¸l¨ut¨urk. https://doi.org/10.1007/978-3-319-98131-4
† First joint author. Rest of authors ordered alphabetically.

1

1. Introduction

Deep learning models have shown extraordinary predictive abilities, breaking records in im-
age classiﬁcation (Krizhevsky et al., 2012), speech recognition (Hinton et al., 2012), language
translation (Cho et al., 2014), and reinforcement learning (Silver et al., 2016). However, the
predictive focus of black-box deep learning models leaves little room for explanatory power.
More generally, current machine learning paradigms offer no protection to avoid mistaking cor-
relation by causation. For example, consider the prediction of target variable Y given features
X and Z, assuming that the underlying generative process is described by the equations:

X, EY , EZ ∼
←

Y

Z

←

Uniform(0, 1),
0.5X + EY ,
Y + EZ,

with (EY , EZ) additive noise variables. The above model states that the values of Y are
computed as a function of the values of X (we say that X causes Y ), and that the values of Z are
computed as a function of the values of Y (Y causes Z). The “assignment arrows” emphasize the
asymmetric relations between all three random variables. However, as Z provides a stronger
signal-to-noise ratio than X for the prediction of Y , the best regression solution in terms of
least-square error is

ˆY = 0.25X + 0.5Z

The above regression model, a typical case of inverse regression after Goldberger (1984), would
wrongly explain some changes in Y as a function of changes in Z, although Z does not cause
Y . In this simple case, there exists approaches overcoming the inverse regression mistake and
uncovering all true cause-effect relations (Hoyer et al., 2009). In the general case however,
mainstream machine learning approaches fail to understand the relationships between all three
distributions, and might attribute some effects on Y to changes in Z.

Mistaking correlation for causation can be catastrophic for agents who must plan, reason,
and decide based on observations. Thus, discovering causal structures is of crucial importance.
The gold standard to discover causal relations is to perform experiments (Pearl, 2003).
However, experiments are in many cases expensive, unethical, or impossible to realize. In these
situations, there is a need for observational causal discovery, that is, the estimation of causal
relations from observations alone (Spirtes et al., 2000; Peters et al., 2017).

In the considered setting, observational empirical data (drawn independent and identically
distributed from an unknown distribution) is given as a set of n samples of real valued fea-
ture vectors of dimension d. We denote the corresponding random vector as X = [X1, ..., Xd].
We seek a Functional Causal Model (FCM), also known as Structural Equation Model (SEM),
that best matches the underlying data-generating mechanism(s) in the following sense: un-
der relevant manipulations/interventions/experiments the FCM would produce data distributed
similarly to the real data obtained in similar conditions.

Let intervention do(X=x) be deﬁned as the operation on distribution obtained by clamping
variable X to value x, while the rest of the system remains unchanged (Pearl, 2009). It is said
that variable Xi is a direct cause of X j with respect to X1, ..., Xd iff different interventions on
variable X result in different marginal distributions on X j, everything else being equal:

PX j|

do(Xi=x,X

= PX j|
i, j the set of all variables except Xi and X j, scalar values x

do(Xi=x(cid:48),X

i j=c) (cid:54)

i j=c)

\

\

with X
= x(cid:48), and vector
i j := X
1,...,d
{
\
value c. Distribution PX j|
i j=c) is the resulting interventional distribution of the variable
X j when the variable Xi is clamped to value x, while keeping all other variables at a ﬁxed value
(Mooij et al., 2016).

do(Xi=x,X

}\

\

As said, conducting such interventions to determine direct causes and effects raises some
limitations. For this reason, this paper focuses on learning the causal structure from observa-
tional data only, where the goal and validation of the proposed approach is to match the known
“ground truth” model structure.

(1)

2

A contribution of the paper is to unify several state-of-art methods into one single consistent
and more powerful approach. On the one hand, leading researchers at UCLA, Carnegie Mel-
lon, University of Crete and elsewhere have developed powerful algorithms exploiting Markov
properties of directed acyclic graphs (DAGs). (Spirtes et al., 2000; Tsamardinos et al., 2006;
Pearl, 2009) On the other hand, the T¨ubingen School has proposed new and powerful func-
tional causal models (FCM) algorithms exploiting the asymmetries in the joint distribution of
cause-effect pairs. (Hoyer et al., 2009; Stegle et al., 2010; Daniusis et al., 2012; Mooij et al.,
2016)

In this paper, the learning of functional causal models is tackled in the search space of
generative neural networks (Kingma and Welling, 2013; Goodfellow et al., 2014), and aims at
the functional causal model (structure and parameters), best ﬁtting the underlying data genera-
tive process. The merits of the proposed approach, called Causal Generative Neural Network
(CGNN) are extensively and empirically demonstrated compared to the state of the art on arti-
ﬁcial and real-world benchmarks.

This paper is organized as follows: Section 2 introduces the problem of learning an FCM
and the underlying assumptions. Section 3 brieﬂy reviews and discusses the state of the art in
causal modeling. The FCM modeling framework within the search space of generative neural
networks is presented in Section 4. Section 5 reports on an extensive experimental validation of
the approach comparatively to the state of the art for pairwise cause-effect inference and graph
recovery. An extension of the proposed framework to deal with potential confounding variables
is presented in Section 6. The paper concludes in Section 7 with some perspectives for future
works.

2. Problem setting

A Functional Causal Model (FCM) upon a random variable vector X = [X1, . . . , Xd] is a triplet
(G , f , E ), representing a set of equations:

Xi ←

fi(XPa(i;G ), Ei), Ei ∼

E , for i = 1, . . . , d

(2)

Each equation characterizes the direct causal relation explaining variable Xi from the set
of its causes XPa(i;G ) ⊂ {
, based on some causal mechanism fi involving besides
XPa(i;G ) some random variable Ei drawn after distribution E , meant to account for all unob-
served variables.

X1, . . . , Xd}

Letting G denote the causal graph obtained by drawing arrows from causes XPa(i;G ) towards
their effects Xi, we restrict ourselves to directed acyclic graphs (DAG), where the propagation of
interventions to end nodes is assumed to be instantaneous. This assumption suitably represents
causal phenomena in cross-sectional studies. An example of functional causal model with ﬁve
variables is illustrated on Fig. 1.

2.1 Notations

→

↔

Y or Y

X); ii) a causal relationship in either direction (X

→
Y ) due to external common causes (Richardson and Spirtes, 2002).

By abuse of notation and for simplicity, a variable X and the associated node in the causal graph,
in one-to-one correspondence, are noted in the same way. Variables X and Y are adjacent iff
there exists an edge between both nodes in the graph. This edge can model i) a direct causal
relationship (X
Y ); iii) a non-
causal association (X
Conditional independence: (X
⊥⊥
tionally to Z, i.e. P(X,Y
Z) = P(X
|
V-structure, a.k.a. unshielded collider: Three variables
causal structure is: X
Skeleton of the DAG: the skeleton of the DAG is the undirected graph obtained by replacing all
edges by undirected edges.
Markov equivalent DAG: two DAGs with same skeleton and same v-structures are said to be
Markov equivalent (Pearl and Verma, 1991). A Markov equivalence class is represented by
a Completed Partially Directed Acyclic Graph (CPDAG) having both directed and undirected
edges.

Z) is meant as variables X and Y are independent condi-
Y
|
Z)P(Y
|

form a v-structure iff their

X,Y, Z

Z).
|

→

←

Y .

−

Z

{

}

3

E1

f1

X1

E2

E3

f2

X2

f3

X3

E4

f4

X4

E5

f5

X5

X1 = f1(E1)
X2 = f2(X1, E2)
X3 = f3(X1, E3)
X4 = f4(E4)
X5 = f5(X3, X4, E5)






Figure 1: Example of a Functional Causal Model (FCM) on X = [X1, . . . , X5]: Left: causal graph
G ; right: causal mechanisms.

2.2 Assumptions and Properties

in X has a common cause external to X

The state of the art in causal modeling most commonly involves four assumptions:
Causal sufﬁciency assumption (CSA): X is said to be causally sufﬁcient if no pair of variables
Xi, X j}
i, j.
{
\
Causal Markov assumption (CMA): all variables are independent of their non-effects (non
descendants in the causal graph) conditionally to their direct causes (parents) (Spirtes et al.,
2000). For an FCM, this assumption holds if the graph is a DAG and error terms Ei in the FCM
are independent on each other (Pearl, 2009).
Conditional independence relations in an FCM: if CMA applies, the data generated by the
FCM satisfy all conditional independence (CI) relations among variables in X via the notion of
d-separation (Pearl, 2009). CIs are called Markov properties. Note that there may be more CIs
in data than present in the graph (see the Faithfulness assumption below). The joint distribution
of the variables is expressed as the product of the distribution of each variable conditionally on
its parents in the graph.
Causal Faithfulness Assumption (CFA): the joint distribution P(X) is faithful to the graph
G of an FCM iff every conditional independence relation that holds true in P is entailed by
G (Spirtes and Zhang, 2016). Therefore, if there exists an independence relation in X that is
not a consequence of the Causal Markov assumption, then X is unfaithful (Scheines, 1997). It
follows from CMA and CFA that every causal path in the graph corresponds to a dependency
between variables, and vice versa.
V-structure property. Under CSA, CMA and CFA, if variables
Y, Z
{
}
v-structure (X

and
satisfy: i)
Y , then their causal structure is a
|

are NOT adjacent; iii) X

are adjacent; ii)

X, Z
{
Z).

X,Y
{

X,Y, Z

⊥(cid:54)⊥

Y

Z

}

}

}

{

→

←

3. State of the art

3.1 Learning the CPDAG

This section reviews methods to infer causal relationships, based on either the Markov proper-
ties of a DAG such as v-structures or asymmetries in the joint distributions of pairs of variables.

Structure learning methods classically use conditional independence (CI) relations in order to
identify the Markov equivalence class of the sought Directed Acyclic Graph, referred to as
CPDAG, under CSA, CMA and CFA.

Considering the functional model on X = [X1, . . . , X5] on Fig. 1, the associated DAG G and
graph skeleton are respectively depicted on Fig. 2(a) and (b). Causal modeling exploits ob-

4

servational data to recover the G structure from all CI (Markov properties) between variables.1
Under CSA, CMA and CFA, as (X3 ⊥⊥
X4 is
X5 ←
X1). Thus the DAGs
identiﬁed (Fig. 2(c)). However, one also has (X1 ⊥⊥
on Figs. 2(d) and (e) encode the same conditional independences as the true DAG (Fig. 2(a)).
Therefore the true DAG cannot be fully identiﬁed based only on independence tests, and the
X1, X2}
edges between the pairs of nodes
are left undirected. The identiﬁca-
and
tion process thus yields the partially undirected graph depicted on Fig. 2(c), called Completed
Partially Directed Acyclic Graph (CPDAG).

X5) does not hold, a v-structure X3 →
X3) and (X2 ⊥⊥

X1, X3}
{

X5|

X4|

X3|

{

X1

X1

X1

X5

X2

X3

X4

X2

X3

X4

X2

X3

X4

(a) The exact DAG of G .

(b) The skeleton of G .

(c) The CPDAG of G .

X5

X5

X1

X2

X3

X4

X2

X3

X4

X5

X1

X5

(d) A Markov equivalent DAG of G .

(e) Another Markov equivalent DAG of G .

Figure 2: Example of a Markov equivalent class. There exists three graphs (a, d, e) consistent
with a given graph skeleton (b); the set of these consistent graphs deﬁnes the Markov equivalent
class (c).

The main three families of methods used to recover the CPDAG of an FCM with contin-
uous data are constraint-based methods, score-based methods, and hybrid methods (Drton and
Maathuis, 2016).

3.1.1 CONSTRAINT-BASED METHODS

Constraint-based methods exploit conditional independences between variables to identify all
v-structures. One of the most well-known constraint-based algorithms is the PC algorithm
(Spirtes et al., 1993). PC ﬁrst builds the DAG skeleton based on conditional independences
among variables and subsets of variables. Secondly, it identiﬁes v-structures (Fig. 2(c)). Fi-
nally, it uses propagation rules to orient remaining edges, avoiding the creation of directed
cycles or new v-structures. Under CSA, CMA and CFA, and assuming an oracle indicating all
conditional independences, PC returns the CPDAG of the functional causal model. In prac-
tice, PC uses statistical tests to accept or reject conditional independence at a given conﬁdence
level. Besides mainstream tests (e.g., s Z-test or T-Test for continuous Gaussian variables,
and χ-squared or G-test for categorical variables), non-parametric independence tests based
on machine learning are becoming increasingly popular, such as kernel-based conditional in-
dependence tests (Zhang et al., 2012). The FCI algorithm (Spirtes et al., 1999) extends PC;
it relaxes the causal sufﬁciency assumption and deals with latent variables. The RFCI algo-
rithm (Colombo et al., 2012) is faster than FCI and handles high-dimensional DAGs with latent
variables. Achilles’ heel of constraint-based algorithms is their reliance on conditional inde-
pendence tests. The CI accuracy depends on the amount of available data, with exponentially

1The so-called constraint-based methods base the recovery of graph structure on conditional independence tests.
In general, proofs of model identiﬁability assume the existence of an “oracle” providing perfect knowledge of the
CIs, i.e. de facto assuming an inﬁnite amount of training data.

5

increasing size with the number of variables. Additionally, the use of propagation rules to direct
edges is prone to error propagation.

3.1.2 SCORE-BASED METHODS

Score-based methods explore the space of CPDAGs and minimize a global score. For example,
the space of graph structures is explored using operators (add edge, remove edge, and reverse
edge) by the Greedy Equivalent Search (GES) algorithm (Chickering, 2002), returning the op-
timal structure in the sense of the Bayesian Information Criterion.2

In order to ﬁnd the optimal CPDAG corresponding to the minimum score, the GES algo-
rithm starts with an empty graph. A ﬁrst forward phase is performed, iteratively adding edges
to the model in order to improve the global score. A second backward phase iteratively removes
edges to improve the score. Under CSA, CMA and CFA, GES identiﬁes the true CPDAG in the
large sample limit, if the score used is decomposable, score-equivalent and consistent (Chick-
ering, 2002). More recently, Ramsey (2015) proposed a GES extension called Fast Greedy
Equivalence Search (FGES) algorithm. FGES uses the same scores and search algorithm with
different data structures; it greatly speeds up GES by caching information about scores during
each phase of the process.

3.1.3 HYBRID ALGORITHMS

Hybrid algorithms combine ideas from constraint-based and score-based algorithms. Accord-
ing to Nandy et al. (2015), such methods often use a greedy search like the GES method on
a restricted search space for the sake of computational efﬁciency. This restricted space is de-
ﬁned using conditional independence tests. For instance the Max-Min Hill climbing (MMHC)
algorithm (Tsamardinos et al., 2006) ﬁrstly builds the skeleton of a Bayesian network using con-
ditional independence tests and then performs a Bayesian-scoring greedy hill-climbing search
to orient the edges. The Greedy Fast Causal Inference (GFCI) algorithm proceeds in the other
way around, using FGES to get rapidly a ﬁrst sketch of the graph (shown to be more accurate
than those obtained with constraint-based methods), then using the FCI constraint-based rules
to orient the edges in presence of potential confounders (Ogarrio et al., 2016).

3.2 Exploiting asymmetry between cause and effect

The abovementioned score-based and constraint-based methods do not take into account the full
information from the observational data (Spirtes and Zhang, 2016), such as data asymmetries
induced by the causal directions.

3.2.1 THE INTUITION

−

Y edge as both graphs X

Let us consider FCM Y = X + E, with E a random noise independent of X by construction.
Graph constraints cannot orient the X
X are Markov
E can be exploited provided that either
equivalent. However, the implicit v-structure X
X or E does not follow a Gaussian distribution. Consider the linear regression Y = aX + b
(blue curve in Fig. 3); the residual is independent of X. Quite the contrary, the residual of
the linear regression X = a(cid:48)Y + b(cid:48) (red curve in Fig. 3) is not independent of Y as far as the
In this toy example, the
independence of the error term holds true (Shimizu et al., 2006).
asymmetries in the joint distribution of X and Y can be exploited to recover the causal direction
X

Y (Spirtes and Zhang, 2016).

Y and Y

→

→

→

←

Y

→

2After Ramsey (2015), in the linear model with Gaussian variable case the individual BIC score to minimize for
a variable X given its parents is up to a constant n ln(s) + c k ln(n), where n ln(s) is the likelihood term, with s the
residual variance after regressing X onto its parents, and n the number of data samples. c k ln(n) is a penalty term for
the complexity of the graph (here the number of edges). k = 2p + 1, with p the total number of parents of the variable
X in the graph. c = 2 by default, chosen empirically. The global score minimized by the algorithm is the sum over
all variables of the individual BIC score given the parent variables in the graph.

6

Figure 3: Left: Joint distribution P(X,Y ) generated from DAG X
Y + E, with E a uniform
noise variable. The linear regression of Y on X (respectively of X on Y ) is depicted as a blue
(resp. red) curve. Middle: Error f (X)
X is not
Y . Better seen
independent of Y . The asymmetry establishes that the true causal model is X
in color.

Y is independent of X. Right: Error g(Y )

→

→

−

−

3.2.2 RESTRICTION ON THE CLASS OF CAUSAL MECHANISMS CONSIDERED

Causal inference is bound to rely on assumptions such as non-Gaussianity or additive noise. In
the absence of any such assumption, Zhang et al. (2016) show that, even in the bivariate case, for
any function f and noise variable E independent of X such that Y = f (X, E), it is always feasible
to construct some ˜f and ˜E, with ˜E independent of Y , such that X = ˜f (Y, ˜E). An alternative,
supporting asymmetry detection and hinting at a causal direction, is based on restricting the
class of functions f (e.g. only considering regular functions). According to Quinn et al. (2011),
the ﬁrst approach in this direction is LiNGAM (Shimizu et al., 2006). LiNGAM handles linear
structural equation models, where each variable is continuous and modeled as:

Xi = ∑
k

αkPk

a (Xi) + Ei, i

1, n

(cid:75)

∈ (cid:74)

(3)

with Pk

a (Xi) the k-th parent of Xi and αk a real value. Assuming further that all probability
distributions of source nodes in the causal graph are non-Gaussian, Shimizu et al. (2006) show
that the causal structure is fully identiﬁable (all edges can be oriented).

3.2.3 PAIRWISE METHODS

In the continuous, non-linear bivariate case, speciﬁc methods have been developed to orient
the variable edge.3 A well known example of bivariate model is the additive noise model
(ANM) (Hoyer et al., 2009), with data generative model Y = f (X)+E, f a (possibly non-linear)
function and E a noise independent of X. The authors prove the identiﬁability of the ANM in
the following sense: if P(X,Y ) is consistent with ANM Y = f (X) + E, then i) there exists no
AMN X = g(Y ) + E(cid:48) consistent with P(X,Y ); ii) the true causal direction is X
Y . Under the
independence assumption between E and X, the ANM admits a single non-identiﬁable case,
the linear model with Gaussian input and Gaussian noise (Mooij et al., 2016).

→

A more general model is the post-nonlinear model (PNL) (Zhang and Hyv¨arinen, 2009),
involving an additional nonlinear function on the top of an additive noise: Y = g( f (X) + E),
with g an invertible function. The price to pay for this higher generality is an increase in the
number of non identiﬁable cases.

The Gaussian Process Inference model (GPI) (Stegle et al., 2010) infers the causal direction
without explicitly restricting the class of possible causal mechanisms. The authors build two
X, where the distribution of the
Bayesian generative models, one for X
cause is modeled with a Gaussian mixture model, and the causal mechanism f is a Gaussian
process. The causal direction is determined from the generative model best ﬁtting the data
(maximizing the data likelihood). Identiﬁability here follows from restricting the underlying
class of functions and enforcing their smoothness (regularity). Other causal inference methods

Y and one for Y

→

→

3These methods can be extended to the multivariate case and used for causal graph identiﬁcation by orienting

each edge in turn.

7

Y , the marginal probability distribution
(Sgouritsa et al., 2015) are based on the idea that if X
X), hence estimating P(Y
X)
of the cause P(X) is independent of the causal mechanism P(Y
|
|
from P(X) should hardly be possible, while estimating P(X
Y ) based on P(Y ) may be possible.
|
The reader is referred to Statnikov et al. (2012) and Mooij et al. (2016) for a thorough review
and benchmark of the pairwise methods in the bivariate case.

→

A new ML-based approach tackles causal inference as a pattern recognition problem. This
setting was introduced in the Causality challenges (Guyon, 2013, 2014), which released 16,200
, each pair being described by a sample of their joint distribution,
pairs of variables
and labeled with the true (cid:96)i value of their causal relationship, with (cid:96)i ranging in
Yi,
Yi →
. The causality classiﬁers trained from the
}
challenge pairs yield encouraging results on test pairs. The limitation of this ML-based causal
modeling approach is that causality classiﬁers intrinsically depend on the representativity of
the training pairs, assumed to be drawn from a same “Mother distribution” (Lopez-Paz et al.,
2015).

Xi,Yi}
{
Yi (presence of a confounder)
Yi, Xi ↔

Xi, Xi ⊥⊥

Xi →

{

Note that bivariate methods can be used to uncover the full DAG, and independently orient
each edge, with the advantage that an error on one edge does not propagate to the rest of the
graph (as opposed to constraint and score-based methods). However, bivariate methods do not
leverage the full information available in the dependence relations. For example in the linear
Gaussian case (linear model and Gaussian distributed inputs and noises), if a triplet of vari-
C), a
ables
C (unshielded collider); still,
constraint-based method would identify the v-structure A
a bivariate model based on cause-effect asymmetry would neither identify A

is such that A, B (respectively B,C) are dependent on each other but A

A, B,C
{

B nor B

←

→

⊥⊥

C.

B

}

→

←

3.3 Discussion

This brief survey has shown the complementarity of CPDAG and pairwise methods. The former
ones can at best return partially directed graphs; the latter ones do not optimally exploit the
interactions between all variables.

To overcome these limitations, an extension of the bivariate post-nonlinear model (PNL)
has been proposed (Zhang and Hyv¨arinen, 2009), where an FCM is trained for any plausible
causal structure, and each model is tested a posteriori for the required independence between
errors and causes. The main PNL limitation is its super-exponential cost with the number
of variables (Zhang and Hyv¨arinen, 2009). Another hybrid approach uses a constraint based
algorithm to identify a Markov equivalence class, and thereafter uses bivariate modelling to
orient the remaining edges (Zhang and Hyv¨arinen, 2009). For example, the constraint-based
X4 in an FCM (Fig. 2), enabling the
PC algorithm can identify the v-structure X3 →
X3. Note that an
X2 and X1 →
bivariate PNL method to further infer the remaining arrows X1 →
effective combination of constraint-based and bivariate approaches requires a ﬁnal veriﬁcation
phase to test the consistency between the v-structures and the edge orientations.

X5 ←

This paper aims to propose a uniﬁed framework getting the best out of both worlds of

CPDAG and bivariate approaches.

An inspiration of the approach is the CAM algorithm (B¨uhlmann et al., 2014), which is an
extension to the graph setting of the pairwise additive model (ANM) (Hoyer et al., 2009). In
CAM the FCM is modeled as:

Xi = ∑
k
∈

Pa(i;G )

fk(Xk) + Ei, for i = 1, . . . , d

Our method can be seen an extension of CAM, as it allows non-additive noise terms and
non-additive contributions of causes, in order to model ﬂexible conditional distributions, and
addresses the problem of learning FCMs (Section 2):

Xi = fi(XPa(i;G ), Ei), for i = 1, . . . , d

An other inspiration of our framework is the recent method of Lopez-Paz and Oquab
Y and

(2016), where a conditional generative adversarial network is trained to model X
Y

X in order to infer the causal direction based on the Occam’s razor principle.

→

→

(4)

(5)

8

This approach, called Causal Generative Neural Network (CGNN), features two original
contributions. Firstly, multivariate causal mechanisms fi are learned as generative neural
networks (as opposed to, regression networks). The novelty is to use neural nets to model
the joint distribution of the observed variables and learn a continuous FCM. This approach
does not explicitly restrict the class of functions used to represent the causal models (see also
(Stegle et al., 2010)), since neural networks are universal approximators. Instead, a regularity
argument is used to enforce identiﬁability, in the spirit of supervised learning: the methods
searches a trade-off between data ﬁtting and model complexity.

Secondly, the data generative models are trained using a non-parametric score, the Maxi-
mum Mean Discrepancy (Gretton et al., 2007). This criterion is used instead of likelihood based
criteria, hardly suited to complex data structures, or mean square criteria, implicitly assuming
an additive noise (e.g. as in CAM, Eq. 4).

Starting from a known skeleton, Section 4 presents a version of the proposed approach
under the usual Markov, faithfulness, and causal sufﬁciency assumptions. The empirical vali-
dation of the approach is detailed in Section 5. In Section 6, the causal sufﬁciency assumption
is relaxed and the model is extended to handle possible hidden confounding factors. Section 7
concludes the paper with some perspectives for future work.

4. Causal Generative Neural Networks

Let X = [X1, . . . , Xd] denote a set of continuous random variables with joint distribution P, and
further assume that the joint density function h of P is continuous and strictly positive on a
compact subset of Rd and zero elsewhere.

This section ﬁrst presents the modeling of continuous FCMs with generative neural net-
works with a given graph structure (Section 4.1), the evaluation of a candidate model (Section
4.2), and ﬁnally, the learning of a best candidate from observational data (Section 4.3).

4.1 Modeling continuous FCMs with generative neural networks

We ﬁrst show that there exists a (non necessarily unique) continuous functional causal model
(G , f , E ) such that the associated data generative process ﬁts the distribution P of the observa-
tional data.

Proposition 1 Let X = [X1, . . . , Xd] denote a set of continuous random variables with joint distribution P,
and further assume that the joint density function h of P is continuous and strictly positive on a compact
and convex subset of Rd, and zero elsewhere. Letting G be a DAG such that P can be factorized along G ,

P(X) = ∏
i

P(Xi|

XPa(i;G ))

there exists f = ( f1, . . . , fd) with fi a continuous function with compact support in R|
[0, 1] such
that P(X) equals the generative model deﬁned from FCM (G , f , E ), with E = U [0, 1] the uniform distri-
bution on [0, 1].

| ×

Pa(i;G )

Proof In Appendix 8.2

In order to model such continuous FCM (G , f , E ) on d random variables X = [X1, . . . , Xd],

we introduce the CGNN (Causal Generative Neural Network) depicted on Figure 4.

Deﬁnition 1 A CGNN over d variables [ ˆX1, . . . , ˆXd] is a triplet C

G , ˆf = (

G , ˆf , E ) where:

1.

G is a Directed Acyclic Graph (DAG) associating to each variable ˆXi its set of parents noted
ˆXPa(i; ˆG ) for i
(cid:98)

[[1, d]]

∈

(cid:98)

(cid:98)

9

2. For i

∈ (cid:74)
neurons:

(cid:75)

1, d

, causal mechanism ˆfi is a 1-hidden layer regression neural network with nh hidden

ˆXi = ˆfi( ˆXPa(i; ˆG ), Ei) =

¯wi

kσ

nh
∑
k=1

N

k, ˆwi
with nh ∈
work, and σ a continuous activation function .

the number of hidden units, ¯wi

∗

∑
Pa(i;G )

(cid:32)

j

∈
jk, wi

k, bi

k, ¯bi

∈

ˆwi
jk

ˆX j + wi

kEi + bi
k

+ ¯bi

(cid:33)

(6)

R the parameters of the neural net-

3. Each variable Ei is independent of the cause Xi. Furthermore, all noise variables are mutually

independent and drawn after same distribution E .

E1

ˆX1

ˆf1

E2

ˆf2

ˆX2

ˆX3

E4

ˆX4

E3

ˆf3

ˆf5

ˆf4

E5

ˆX5

ˆX1 = ˆf1(E1)
ˆX2 = ˆf2( ˆX1, E2)
ˆX3 = ˆf3( ˆX1, E3)
ˆX4 = ˆf4(E4)
ˆX5 = ˆf5( ˆX3, ˆX4, E5)






Figure 4: Left: Causal Generative Neural Network over variables ˆX = ( ˆX1, . . . , ˆX5). Right:
Corresponding Functional Causal Model equations.

It is clear from its deﬁnition that a CGNN deﬁnes a continuous FCM.

4.1.1 GENERATIVE MODEL AND INTERVENTIONS

G , ˆf = (

A CGNN C
G , ˆf , E ) is a generative model in the sense that any sample [e1, j, . . . , ed, j] of
the “noise” random vector E = [E1, . . . , Ed] can be used as “input” to the network to generate
a data sample [ ˆx1, j, . . . , ˆxd, j] of the estimated distribution ˆP( ˆX = [ ˆX1, . . . , ˆXd]) by proceeding as
follow:

(cid:98)

(cid:98)

1. Draw

n
[e1, j, . . . , ed, j]
j=1, n samples independent identically distributed from the joint distribution
}
{

of independent noise variables E = [E1, . . . , Ed].

2. Generate n samples

j=1, where each estimate sample ˆxi, j of variable ˆXi is computed
n
[ ˆx1, j, . . . , ˆxd, j]
}
{
G from ˆfi with the j-th estimate samples ˆxPa(i; ˆG ), j of ˆXPa(i; ˆG ) and the

in the topological order of
j-th sample ei, j of the random noise variable Ei.

(cid:98)

G , as the graph

Notice that a CGNN generates a probability distribution ˆP which is Markov with respect to
G is acyclic and the noise variables Ei are mutually independent.
Importantly, CGNN supports interventions, that is, freezing a variable Xi to some constant
vi. The resulting joint distribution noted ˆPdo( ˆXi=vi)( ˆX), called interventional distribution (Pearl,
(cid:98)
2009), can be computed from CGNN by discarding all causal inﬂuences on ˆXi and clamping its
value to vi. It is emphasized that intervening is different from conditioning (correlation does
not imply causation). The knowledge of interventional distributions is essential for e.g., public
policy makers, wanting to estimate the overall effects of a decision on a given variable.

(cid:98)

10

4.2 Model evaluation

G , ˆf , E ) a score reﬂecting how well
The goal is to associate to each candidate solution C
this candidate solution describes the observational data. Firstly we deﬁne the model scoring
function (Section 4.2), then we show that this model scoring function allows to build a CGNN
generating a distribution ˆP( ˆX) that approximates P(X) with arbitrary accuracy (Section 4.2.2).

G , ˆf = (

(cid:98)

(cid:98)

4.2.1 SCORING METRIC

The ideal score, to be minimized, is the distance between the joint distribution P associated
P deﬁned by the CGNN candidate C ˆG , ˆf =
with the ground truth FCM, and the joint distribution
( ˆG , ˆf , E ). A tractable approximation thereof is given by the Maximum Mean Discrepancy
D
(MMD) (Gretton et al., 2007) between the n-sample observational data D, and an n-sample
sampled after

P. Overall, the CGNN C ˆG , ˆf is trained by minimizing

(cid:98)

(cid:98)

S(C ˆG , ˆf , D) = (cid:92)MMDk(D,

D) + λ

with (cid:92)MMDk(D,

D) deﬁned as:

(cid:92)MMDk(D,
(cid:98)

D) =

1
n2

n
∑
i, j=1

(cid:98)

1
n2

n
∑
i, j=1

G
|

,
|

(cid:98)

2
n2

n
∑
i, j=1

−

k(xi, x j) +

k( ˆxi, ˆx j)

k(xi, ˆx j)

(8)

(cid:98)

(7)

(cid:98)

2
where kernel k usually is taken as the Gaussian kernel (k(x, x(cid:48)) = exp(
2)). The MMD
statistic, with quadratic complexity in the sample size, has the good property that as n goes to
inﬁnity, it goes to zero iff P = ˆP (Gretton et al., 2007). For scalability, a linear approximation
m
of the MMD statistics based on m = 100 random features (Lopez-Paz, 2016), called (cid:92)MMD
k ,
will also be used in the experiments (more in Appendix 8.1).

γ
−

x(cid:48)(cid:107)

−

(cid:107)

x

Due to the Gaussian kernel being differentiable, (cid:92)MMDk and (cid:92)MMD

m
k are differentiable, and

backpropagation can be used to learn the CGNN made of networks ˆfi structured along ˆG .

In order to compare candidate solutions with different structures in a fair manner, the eval-
the number of

uation score of Equation 7 is augmented with a penalization term λ
edges in ˆG . Penalization weight λ is a hyper-parameter of the approach.

, with
|

G
|

G
|

|

(cid:98)

(cid:98)

4.2.2 REPRESENTATIONAL POWER OF CGNN

{

We note D =
(unknown) joint distribution P(X = [X1, . . . , Xd]), also referred to as observational data.

n
[x1, j, . . . , xd, j]
j=1, the data samples independent identically distributed after the
}

Under same conditions as in Proposition 1, (P(X) being decomposable along graph G , with
continuous and strictly positive joint density function on a compact in Rd and zero elsewhere),
there exists a CGNN (

G , ˆf , E ), that approximates P(X) with arbitrary accuracy:

Proposition 2 For m
[[1, d]], let Zm denote the set of variables with topological order less than m and
let dm be its size. For any dm-dimensional vector of noise values e(m), let zm(e(m)) (resp.
zm(e(m))) be the
vector of values computed in topological order from the FCM (G , f , E ) (resp. the CGNN (G , ˆf , E )). For
any ε > 0, there exists a set of networks ˆf with architecture G such that

∈

(cid:98)

(cid:98)

e(m),
∀

zm(e(m))
(cid:107)

−

zm(e(m))
(cid:107)

< ε

(9)

Proof In Appendix 8.2

(cid:98)

Using this proposition and the (cid:92)MMDk scoring criterion presented in Equation 8, it is shown
that the distribution ˆP of the CGNN can estimate the true observational distribution of the
(unknown) FCM up to an arbitrary precision, under the assumption of an inﬁnite observational
sample:

11

Proposition 3 Let D be an inﬁnite observational sample generated from (G , f , E ). With same notations
∞, there exists a set
as in Prop. 2, for every sequence εt , such that εt > 0 and goes to zero when t
Dt generated from the CGNN
ft = ( ˆf t
(G ,
(cid:98)

d) such that (cid:92)MMDk between D and an inﬁnite size sample

ft , E ) is less than εt .

1 . . . ˆf t

→

(cid:98)

Proof In Appendix 8.2
(cid:98)

→

→

0, as t

Under these assumptions, as (cid:92)MMDk(D, ˆDt )

∞, it implies that the sequence of
generated ˆPt converges in distribution toward the distribution P of the observed sample (Gretton
et al., 2007). This result highlights the generality of this approach as we can model any kind
of continuous FCM from observational data (assuming access to inﬁnite observational data).
Our class of model is not restricted to simplistic assumptions on the data generative process
such as the additivity of the noise or linear causal mechanisms. But this strength comes with a
new challenge relative to identiﬁability of such CGNNs as the result of proposition 3 holds for
G such that P can be factorized along G and then for any any DAG in the Markov
any DAG
equivalence class of G (under classical assumption of CMA, CFA and CSA). In particular in
the pairwise setting, when only 2 variables X and Y are observed, the joint distribution P(X,Y )
X)
can be factorized in two Markov equivalent DAGs X
Y or Y
|
and P(X,Y ) = P(Y )P(X
Y ). Then the CGNN can reproduce equally well the observational
|
distribution in both directions (under the assumption of proposition 1). We refer the reader to
Zhang and Hyv¨arinen (2009) for more details on this problem of identiﬁability in the bivariate
case.

X as P(X,Y ) = P(X)P(Y

→

→

(cid:98)

As shown in Section 4.3.3, the proposed approach enforces the discovery of causal models
in the Markov equivalence class. Within this class, the non-identiﬁability issue is empirically
mitigated by restricting the class of CGNNs considered, and speciﬁcally limiting the number
nh of hidden neurons in each causal mechanism (Eq. 6). Formally, we restrict ourselves to
G , ˆf nh, E ) with exactly nh hidden neurons in each
the sub-class of CGNNs, noted C ˆG , ˆf nh = (
ˆfi mechanism. Accordingly, any candidate ˆG with number of edges
ˆG
involves the same
|
|
(cid:98)
ˆG
number of parameters: (2d +
(nh + 1) bias parameters. As shown
)
nh weights and d
|
|
experimentally in Section 5, this parameter nh is crucial as it governs the CGNN ability to
model the causal mechanisms: too small nh, and data patterns may be missed; too large nh, and
overly complicated causal mechanisms may be retained.

×

×

4.3 Model optimization

Model optimization consists at ﬁnding a (nearly) optimum solution ( ˆG , ˆf ) in the sense of the
score deﬁned in the previous section. The so-called parametric optimization of the CGNN,
where structure estimate ˆG is ﬁxed and the goal is to ﬁnd the best neural estimates ˆf condition-
ally to ˆG is tackled in Section 4.3.1. The non-parametric optimization, aimed at ﬁnding the best
structure estimate, is considered in Section 4.3.2. In Section 4.3.3, we present an identiﬁability
result for CGNN up to Markov equivalence classes.

4.3.1 PARAMETRIC (WEIGHT) OPTIMIZATION

Given the acyclic structure estimate ˆG , the neural networks ˆf1, . . . , ˆfd of the CGNN are learned
end-to-end using backpropagation with Adam optimizer (Kingma and Ba, 2014) by minimizing
m
losses (cid:92)MMDk (Eq. (8), referred to as CGNN ((cid:92)MMDk) ) or (cid:92)MMD
k (see Appendix 8.1,CGNN
((cid:92)MMD

m
k )).

The procedure closely follows that of supervised continuous learning (regression), except
for the fact that the loss to be minimized is the MMD loss instead of the mean squared error.
Neural nets ˆfi, i
[[1, d]] are trained during ntrain epochs, where the noise samples, independent
m
and identically distributed, are drawn in each epoch. In the (cid:92)MMD
k variant, the parameters of
the random kernel are resampled from their respective distributions in each training epoch (see
Appendix 8.1). After training, the score is computed and averaged over neval estimated samples
of size n. Likewise, the noise samples are re-sampled anew for each evaluation sample. The

∈

12

overall process with training and evaluation is repeated nbrun times to reduce stochastic effects
relative to random initialization of neural network weights and stochastic gradient descent.

4.3.2 NON-PARAMETRIC (STRUCTURE) OPTIMIZATION

ˆG over d nodes is super-exponential in d, making the
The number of directed acyclic graphs
non-parametric optimization of the CGNN structure an intractable computational and statistical
problem. Taking inspiration from Tsamardinos et al. (2006); Nandy et al. (2015), we start from
a graph skeleton recovered by other methods such as feature selection (Yamada et al., 2014).
We focus on optimizing the edge orientations. Letting L denote the number of edges in the
graph, it deﬁnes a combinatorial optimization problem of complexity O(2L) (note however that
not all orientations are admissible since the eventual oriented graph must be a DAG).

The motivation for this approach is to decouple the edge selection task and the causal

modeling (edge orientation) tasks, and enable their independent assessment.

Any Xi −

X j edge in the graph skeleton stands for a direct dependency between variables Xi
and X j. Given Causal Markov and Faithfulness assumptions, such a direct dependency either
reﬂects a direct causal relationship between the two variables (Xi →
X j), or is due to
X j or Xi ←
X j). Under the assumption
the fact that Xi and X j admit a latent (unknown) common cause (Xi ↔
X j link is associated with a
of causal sufﬁciency, the latter does not hold. Therefore the Xi −
causal relationship in one or the other direction. The causal sufﬁciency assumption will be
relaxed in Section 6.

The edge orientation phase proceeds as follows:

•

•

•

X j edge is ﬁrst considered in isolation, and its orientation is evaluated using CGNN.
Each Xi −
Both score S(C
n
[xi,l, x j,l]
l=1. The
}
best orientation corresponding to a minimum score is retained. After this step, an initial graph is
built with complexity 2L with L the number of edges in the skeleton graph.

Xi, ˆf , Di j) are computed, where Di j =

X j, ˆf , Di j) and S(C

X j→

Xi→

{

The initial graph is revised to remove all cycles. Starting from a set of random nodes, all paths
are followed iteratively until all nodes are reached; an edge pointing toward an already visited
node and forming a cycle is reversed. The resulting DAG is used as initial DAG for the structured
optimization, below.

The optimization of the DAG structure is achieved using a hill-climbing algorithm aimed to opti-
mize the global score S(C ˆG , ˆf , D). Iteratively, i) an edge Xi −
X j is uniformly randomly selected
in the current graph; ii) the graph obtained by reversing this edge is considered (if it is still a
DAG and has not been considered before) and the associated global CGNN is retrained; iii) if
this graph obtains a lower global score than the former one, it becomes the current graph and the
process is iterated until reaching a (local) optimum. More sophisticated combinatorial optimiza-
tion approaches, e.g. Tabu search, will be considered in further work. In this paper, hill-climbing
is used for a proof of concept of the proposed approach, achieving a decent trade-off between
computational time and accuracy.

At the end of the process each causal edge Xi →

suring its contribution to the global score:

X j in G is associated with a score, mea-

X j = S(C ˆG

SXi→

, ˆf , D)

S(C ˆG , ˆf , D)

−{

Xi→

X j}
During the structure (non-parametric) optimization, the graph skeleton is ﬁxed; no edge
G
is added or removed. The penalization term λ
entering in the score evaluation (eq. 7) can
|
thus be neglected at this stage and only the MMD-losses are used to compare two graphs. The
penalization term will be used in Section 6 to compare structures with different skeletons, as
the potential confounding factors will be dealt with by removing edges.

−

(cid:98)

|

(10)

4.3.3 IDENTIFIABILITY OF CGNN UP TO MARKOV EQUIVALENCE CLASSES

Assuming an inﬁnite number of observational data, and assuming further that the generative
distribution belongs to the CGNN class CG , f , then there exists a DAG reaching an MMD score
of 0 in the Markov equivalence class of G :

13

Proposition 4 Let X = [X1, . . . , Xd] denote a set of continuous random variables with joint distribution
P, generated by a CGNN CG , f = (G , f , E ) with G a directed acyclic graph. Let D be an inﬁnite observa-
tional sample generated from this CGNN. We assume that P is Markov and faithful to the graph G , and
D an
that every pair of variables (Xi, X j) that are d-connected in the graph are not independent. We note
inﬁnite sample generated by a candidate CGNN, C

G , ˆf , E ). Then,

(cid:98)

G characterized by the same adjacencies but not belonging to the Markov equivalence

G , ˆf = (

(cid:98)

(cid:98)

G = G and ˆf = f , then (cid:92)MMDk(D,

(i) If
(ii) For any graph
class of G , for all ˆf , (cid:92)MMDk(D,

= 0.

D)

(cid:98)

(cid:98)

D) = 0.

(cid:98)

Proof In Appendix 8.2

(cid:98)

This result does not establish the CGNN identiﬁability within the Markov class of equiv-
alence, that is left for future work. As shown experimentally in Section 5.1, there is a need to
control the model capacity in order to recover the directed graph in the Markov equivalence
class.4

5. Experiments

This section reports on the empirical validation of CGNN compared to the state of the art under
the no confounding assumption. The experimental setting is ﬁrst discussed. Thereafter, the
results obtained in the bivariate case, where only asymmetries in the joint distribution can be
used to infer the causal relationship, are discussed. The variable triplet case, where conditional
independence can be used to uncover causal orientations, and the general case of d > 2 variables
are ﬁnally considered. All computational times are measured on Intel Xeon 2.7Ghz (CPU) or
on Nvidia GTX 1080Ti graphics card (GPU).

5.1 Experimental setting

0.005, 0.05, 0.25, 0.5, 1, 5, 50
}
{

.

The CGNN architecture is a 1-hidden layer network with ReLU activation function. The multi-
scale Gaussian kernel used in the MMD scores has bandwidth γ ranging in
The number nbrun used to average the score is set to 32 for CGNN-MMD (respectively 64 for
CGNN-Fourier). In this section the distribution E of the noise variables is set to N (0, 1). The
number nh of neurons in the hidden layer, controlling the identiﬁability of the model, is the most
sensitive hyper-parameter of the presented approach. Preliminary experiments are conducted
to adjust its range, as follows. A 1,500 sample dataset is generated from the linear structural
equation model with additive uniform noise Y = X + U (0, 0.5), X
2, 2]) (Fig. 5). Both
X are trained until reaching convergence (nepoch = 1, 000)
CGNNs associated to X
using Adam (Kingma and Ba, 2014) with a learning rate of 0.01 and evaluated over neval = 500
generated samples. The distributions generated from both generative models are displayed on
Fig. 5 for nh = 2, 5, 20, 100. The associated scores (averaged on 32 runs) are displayed on Fig.
6a, conﬁrming that the model space must be restricted for the sake of identiﬁability (cf. Section
4.3.3 above).

Y and Y

U([

→

→

∼

−

5.2 Learning bivariate causal structures

As said, under the no-confounder assumption a dependency between variables X and Y exists iff
either X causes Y (Y = f (X, E)) or Y causes X (X = f (Y, E)). The identiﬁcation of a Bivariate
Structural Causal Model is based on comparing the model scores (Section 4.2) attached to both
CGNNs.

4In some speciﬁc cases, such as in the bivariate linear FCM with Gaussian noise and Gaussian input, even by
restricting the class of functions considered, the DAG cannot be identiﬁed from purely observational data (Mooij
et al., 2016).

14

Figure 5: Leftmost: Data samples. Columns 2 to 5: Estimate samples generated from CGNN
X (bottom row) for number of hidden neurons nh =
with direction X
2, 5, 20, 100.

Y (top row) and Y

→

→

(b) Scores CX
Y and CY
X with their
difference. (cid:63)(cid:63)(cid:63) denotes the signiﬁcance
at the 0.001 threshold with the t-test.

→

→

Y

X

nh

2
5
10
20
30
40
50
100

CX

→
32.0
29.6
25.9
25.7
24.4
25.6
25.0
24.9

CY

→
43.9
35.2
32.5
28.3
26.8
25.6
25.0
24.4

Diff.
11.9(cid:63)(cid:63)(cid:63)
5.6(cid:63)(cid:63)(cid:63)
6.6(cid:63)(cid:63)(cid:63)
2.6(cid:63)(cid:63)(cid:63)
2.4(cid:63)(cid:63)(cid:63)
0.7
0.6

0.5

−

(a) CX

Y , CY

X with various nh values.

→

→

Figure 6: CGNN sensitivity w.r.t. the number of hidden neurons nh: Scores associated to both
causal models (average and standard deviation over 32 runs).

Benchmarks. Five datasets with continuous variables are considered:5

CE-Cha: 300 continuous variable pairs from the cause effect pair challenge (Guyon, 2013),

•
restricted to pairs with label +1 (X

Y ) and

1 (Y

X).

−

→

→

CE-Net: 300 artiﬁcial pairs generated with a neural network initialized with random weights

•
and random distribution for the cause (exponential, gamma, lognormal, laplace...).

CE-Gauss: 300 artiﬁcial pairs without confounder sampled with the generator of Mooij
•
et al. (2016): Y = fY (X, EY ) and X = fX (EX ) with EX ∼
pEY . pEX and pEY are
randomly generated Gaussian mixture distributions. Causal mechanism fX and fY are randomly
generated Gaussian processes.

pEX and EY ∼

CE-Multi: 300 artiﬁcial pairs generated with linear and polynomial mechanisms. The effect
•
variables are built with post additive noise setting (Y = f (X) + E), post multiplicative noise
E)).
(Y = f (X)
CE-Tueb: 99 real-world cause-effect pairs from the Tuebingen cause-effect pairs dataset,
•
version August 2016 (Mooij et al., 2016). This version of this dataset is taken from 37 different
data sets coming from various domain: climate, census, medicine data.

E), pre-additive noise (Y = f (X + E)) or pre-multiplicative noise (Y = f (X

×

×

For all variable pairs, the size n of the data sample is set to 1,500 for the sake of an accept-

able overall computational load.

5The ﬁrst four datasets are available at http://dx.doi.org/10.7910/DVN/3757KX. The Tuebingen

cause-effect pairs dataset is available at https://webdav.tuebingen.mpg.de/cause-effect/

15

Baseline approaches. CGNN is assessed comparatively to the following algorithms:6 i)
ANM (Mooij et al., 2016) with Gaussian process regression and HSIC independence test of
the residual; ii) a pairwise version of LiNGAM (Shimizu et al., 2006) relying on Independent
Component Analysis to identify the linear relations between variables; iii) IGCI (Daniusis et al.,
2012) with entropy estimator and Gaussian reference measure; iv) the post-nonlinear model
(PNL) with HSIC test (Zhang and Hyv¨arinen, 2009); v) GPI-MML (Stegle et al., 2010); where
the Gaussian process regression with higher marginal likelihood is selected as causal direction;
vi) CDS, retaining the causal orientation with lowest variance of the conditional probability
distribution; vii) Jarfo (Fonollosa, 2016), using a random forest causal classiﬁer trained from
the ChaLearn Cause-effect pairs on top of 150 features including ANM, IGCI, CDS, LiNGAM,
regressions, HSIC tests.

Hyper-parameter selection. For a fair comparison, a leave-one-dataset-out procedure is
used to select the key best hyper-parameter for each algorithm. To avoid computational explo-
sion, a single hyper-parameter per algorithm is adjusted in this way; other hyper-parameters are
set to their default value. For CGNN, nh ranges over
. The leave-one-dataset-out
procedure sets this hyper-parameter nh to values between 20 and 40 for the different datasets.
For ANM and the bivariate ﬁt, the kernel parameter for the Gaussian process regression ranges
0.01, . . . , 10
. For PNL, the threshold parameter alpha for the HSIC independence test
over
}
{
. For CDS, the f f actor involved in the discretization step ranges
ranges over
over [[1, 10]]. For GPI-MML, its many parameters are set to their default value as none of them
appears to be more critical than others. Jarfo is trained from 4,000 variable pairs datasets with
same generator used for CE-Cha-train, CE-Net-train, CE-Gauss-train and CE-Multi-train;
the causal classiﬁer is trained on all datasets except the test set.

0.0005, . . . , 0.5
}

5, . . . , 100

{

{

}

Empirical results. Figure 7 reports the area under the precision/recall curve for each bench-
mark and all algorithms.

Figure 7: Bivariate Causal Modelling: Area under the precision/recall curve for the ﬁve datasets.
A full table of the scores is given in Appendix 3.

Methods based on simple regression like the bivariate ﬁt and Lingam are outperformed
as they underﬁt the data generative process. CDS and IGCI obtain very good results on few
datasets. Typically, IGCI takes advantage of some speciﬁc features of the dataset, (e.g.
the
cause entropy being lower than the effect entropy in CE-Multi), but remains at chance level
otherwise. ANM-HSIC yields good results when the additive assumption holds (e.g. on
CE-Gauss), but fails otherwise. PNL, less restrictive than ANM, yields overall good results
compared to the former methods. Jarfo, a voting procedure, can in principle yield the best of
the above methods and does obtain good results on artiﬁcial data. However, it does not per-
form well on the real dataset CE-Tueb; this counter-performance is blamed on the differences
between all ﬁve benchmark distributions and the lack of generalization / transfer learning.

Lastly, generative methods GPI and CGNN ((cid:92)MMDk) perform well on most datasets, in-
cluding the real-world cause-effect pairs CE-T¨ub, in counterpart for a higher computational
cost (resp. 32 min on CPU for GPI and 24 min on GPU for CGNN). Using the linear MMD

6Using the R program available at https://github.com/ssamot/causality for ANM, IGCI, PNL,

GPI and LiNGAM.

16

approximation Lopez-Paz (2016), CGNN ((cid:92)MMD
cost by a factor of 5 without hindering the performance.

m
k as explained in appendix 8.1) reduces the

Overall, CGNN demonstrates competitive performance on the cause-effect inference prob-

lem, where it is necessary to discover distributional asymmetries.

5.3 Identifying v-structures

A second series of experiments is conducted to investigate the method performances on variable
triplets, where multivariate effects and conditional variable independence must be taken into
account to identify the Markov equivalence class of a DAG. The considered setting is that
of variable triplets (A, B,C) in the linear Gaussian case, where asymmetries between cause
and effect cannot be exploited (Shimizu et al., 2006) and conditional independence tests are
required. In particular strict pairwise methods can hardly be used due to un-identiﬁability (as
each pair involves a linear mechanism with Gaussian input and additive Gaussian noise) (Hoyer
et al., 2009).

With no loss of generality, the graph skeleton involving variables (A, B,C) is A

C. All
three causal models (up to variable renaming) based on this skeleton are used to generate 500-
sample datasets, where the random noise variables are independent centered Gaussian variables.

−

−

B

(a) Chain structure

(c) reversed-V structure

(d) V-structure

A

B

C

A

B

C

A

B

C

A = EA
B = A + EB
C = B + EC






B = EB
A = B + EA
C = B + EC






A = EA
C = EC
B = A +C + EB






Figure 8: Datasets generated from the three DAG conﬁgurations with skeleton A

B

C

−

−

Given skeleton A

B

C, each dataset is used to model the possible four CGNN structures

(Fig. 8, with generative SEMs):

−

−

Chain structures ABC (A = f1(E1), B = f2(A, E2) , C = f3(B, E3) and CBA (C = f1(E1), B =
f2(C, E2) , A = f3(B, E3))

V structure: A = f1(E1), C = f2(E2) , B = f3(A,C, E3)

reversed V structure: B = f1(E1), A = f2(B, E2) , C = f3(B, E3)

•

•

•

Let CABC, CCBA, CV

structure and CreversedV denote the scores of the CGNN models respec-
tively attached to these structures. The scores computed on all three datasets are displayed in
Table 1 (average over 64 runs; the standard deviation is indicated in parenthesis).

−

non V-structures

Score

Chain str.

Reversed-V str.

CABC
CCBA
CreversedV
CV structure

0.122 (0.009)
0.121 (0.006)
0.122 (0.007)
0.202 (0.004)

0.124 (0.007)
0.127 (0.008)
0.125 (0.006)
0.180 (0.005)

V structure
V-structure

0.172 (0.005)
0.171 (0.004)
0.172 (0.004)
0.127 (0.005)

Table 1: CGNN-MMD scores for all models on all datasets. Smaller scores indicate a better
match. CGNN correctly identiﬁes V-structure vs. other structures.

17

CGNN scores support a clear and signiﬁcant discrimination between the V-structure and
all other structures (noting that the other structures are Markov equivalent and thus can hardly
be distinguished).

This second series of experiments thus shows that CGNN can effectively detect, and take

advantage of, conditional independence between variables.

5.4 Multivariate causal modeling under Causal Sufﬁciency Assumption

Let X = [X1, ..., Xd] be a set of continuous variables, satisfying the Causal Markov, faithfulness
and causal sufﬁciency assumptions. To that end, all experiments provide all algorithms the true
graph skeleton, so their ability to orient edges is compared in a fair way. This allows us to
separate the task of orienting the graph from that of uncovering the skeleton.

5.4.1 RESULTS ON ARTIFICIAL GRAPHS WITH ADDITIVE AND MULTIPLICATIVE NOISES

We draw 500 samples from 20 training artiﬁcial causal graphs and 20 test artiﬁcial causal
graphs on 20 variables. Each variable has a number of parents uniformly drawn in [[0, 5]]; fis
are randomly generated polynomials involving additive/multiplicative noise.7

We compare CGNN to the PC algorithm Spirtes et al. (1993), the score-based methods GES
Chickering (2002), LiNGAM Shimizu et al. (2006), causal additive model (CAM) B¨uhlmann
et al. (2014) and with the pairwise methods ANM and Jarfo. For PC, we employ the better-
performing, order-independent version of the PC algorithm proposed by Colombo and Maathuis
(2014). PC needs the speciﬁcation of a conditional independence test. We compare PC-
Gaussian, which employs a Gaussian conditional independence test on Fisher z-transformations,
and PC-HSIC, which uses the HSIC conditional independence test with the Gamma approxi-
mation Gretton et al. (2005). PC and GES are implemented in the pcalg package Kalisch et al.
(2012).

All hyperparameters are set on the training graphs in order to maximize the Area Under the
Precision/Recall score (AUPR). For the Gaussian conditional independence test and the HSIC
conditional independence test, the signiﬁcance level achieving best result on the training set are
respectively 0.1 and 0.05 . For GES, the penalization parameter is set to 3 on the training set.
For CGNN, nh is set to 20 on the training set. For CAM, the cutoff value is set to 0.001.

Figure 9 (left) displays the performance of all algorithms obtained by starting from the
exact skeleton on the test set of artiﬁcial graphs and measured from the AUPR (Area Under
the Precision/Recall curve), the Structural Hamming Distance (SHD, the number of edge mod-
iﬁcations to transform one graph into another) and the Structural Intervention Distance (SID,
the number of equivalent two-variable interventions between two graphs) Peters and B¨uhlmann
(2013).

CGNN obtains signiﬁcant better results with SHD and SID compared to the other algo-
rithms when the task is to discover the causal from the true skeleton. One resulting graph is
shown on Figure 10. There are 3 mistakes on this graph (red edges) (in lines with an SHD on
average of 2.5).

Constraints based method PC with powerful HSIC conditional independence test is the sec-
ond best performing method. It highlights the fact that when the skeleton is known, exploiting
the structure of the graph leads to good results compared to pairwise methods using only local
information. Notably, as seen on Figure 10, this type of DAG has a lot of v-structure, as many
nodes have more than one parent in the graph, but this is not always the case as shown in the
next subsection.

Overall CGNN and PC-HSIC are the most computationally expensive methods, taking an

average of 4 hours on GPU and 15 hours on CPU, respectively.

The robustness of the approach is validated by randomly perturbing 20% edges in the graph
skeletons provided to all algorithms (introducing about 10 false edges over 50 in each skeleton).
As shown on Table 4 (right) in Appendix, and as could be expected, the scores of all algorithms

7The data generator is available at https://github.com/GoudetOlivie/CGNN. The datasets consid-

ered are available at http://dx.doi.org/10.7910/DVN/UZMB69.

18

Figure 9: Average (std. dev.) AUPR results for the orientation of 20 artiﬁcial graphs given true
skeleton (left) and artiﬁcial graphs given skeleton with 20% error (right). A full table of the
scores, including the metrics Structural Hamming Distance (SHD) and Structural Intervention
(SID) (Peters and B¨uhlmann, 2013) is shown on Table 4 in section in section ”Table of Scores
for the Experiments on Graphs” in Appendix.

are lower when spurious edges are introduced. Among the least robust methods are constraint-
based methods; a tentative explanation is that they heavily rely on the graph structure to orient
edges. By comparison pairwise methods are more robust because each edge is oriented sep-
arately. As CGNN leverages conditional independence but also distributional asymmetry like
pairwise methods, it obtains overall more robust results when there are errors in the skeleton
compared to PC-HSIC. However one can notice that a better SHD score is obtained by CAM,
on the skeleton with 20% error. This is due to the exclusive last edge pruning step of CAM,
which removes spurious links in the skeleton.

CGNN obtains overall good results on these artiﬁcial datasets. It offers the advantage to
deliver a full generative model useful for simulation (while e.g., Jarfo and PC-HSIC only give
the causality graph). To explore the scalability of the approach, 5 artiﬁcial graphs with 100
variables have been considered, achieving an AUPRC of 85.5
4, in 30 hours of computation
on four NVIDIA 1080Ti GPUs.

±

Figure 10: Orientation by CGNN of artiﬁcial graph with 20 nodes. Green edges are good
orientation and red arrows false orientation. 3 edges are red and 42 are green. The strength
of the line refers to the conﬁdence of the algorithm.

5.4.2 RESULT ON BIOLOGICAL DATA

We now evaluate CGNN on biological networks. First we apply it on simulated gene expression
data and then on real protein network.

Syntren artiﬁcial simulator First we apply CGNN on SynTREN (Van den Bulcke et al.,
2006) from sub-networks of E. coli (Shen-Orr et al., 2002). SynTREN creates synthetic tran-
scriptional regulatory networks and produces simulated gene expression data that approxi-

19

mates experimental data. Interaction kinetics are modeled by complex mechanisms based on
Michaelis-Menten and Hill kinetics (Mendes et al., 2003).

With Syntren, we simulate 20 subnetworks of 20 nodes and 5 subnetworks with 50 nodes.
For the sake of reproducibility, we use the random seeds of 0, 1 . . . 19 and 0, 1 . . . 4 for each graph
generation with respectively 20 nodes and 50 nodes. The default Syntren parameters are used:
a probability of 0.3 for complex 2-regulator interactions and a value of 0.1 for Biological noise,
experimental noise and Noise on correlated inputs. For each graph, Syntren give us expression
datasets with 500 samples.

Figure 11: Average (std. dev.) AUPR results for the orientation of 20 artiﬁcial graphs generated
with the SynTReN simulator with 20 nodes (left), 50 nodes (middle), and real protein network
given true skeleton (right). A full table of the scores, including the metrics Structural Hamming
Distance (SHD) and Structural Intervention (SID) (Peters and B¨uhlmann, 2013) is included in
section ”Table of Scores for the Experiments on Graphs” in Appendix.

Figure 11 (left and middle) and Table 5 in section ”Table of Scores for the Experiments on
Graphs” in Appendix display the performance of all algorithms obtained by starting from the
exact skeleton of the causal graph with same hyper-parameters as in the previous subsection.
As a note, we canceled the PC-HSIC algorithm after 50 hours of running time.

Constraint based methods obtain low score on this type of graph dataset. It may be ex-
plained by the type of structure involved.
Indeed as seen of Figure 12, there are very few
v-structures in this type of network, making impossible the orientation of an important number
of edges by using only conditional independence tests. Overall the methods CAM and CGNN
that take into account of both distributional asymmetry and multivariate interactions, get the
best scores. CGNN obtain the best results in AUPR, SHD and SID for graph with 20 nodes and
50 nodes, showing that this method can be used to infer networks having complex distribution,
complex causal mechanisms and interactions. The Figure 12 shows the resulting graph obtain
with CGNN. Edges with good orientation are displayed in green and edge with false orientation
in red.

5.4.3 RESULTS ON BIOLOGICAL REAL-WORLD DATA

CGNN is applied to the protein network problem Sachs et al. (2005), using the Anti-CD3/CD28
dataset with 853 observational data points corresponding to general perturbations without spe-
ciﬁc interventions. All algorithms were given the skeleton of the causal graph (Sachs et al.,
2005, Fig. 2) with same hyper-parameters as in the previous subsection. We run each algorithm
on 10-fold cross-validation. Table 6 in Appendix reports average (std. dev.) results.

Constraint-based algorithms obtain surprisingly low scores, because they cannot identify
many V-structures in this graph. We conﬁrm this by evaluating conditional independence tests
for the adjacent tuples of nodes pip3-akt-pka, pka-pmek-pkc, pka-raf -pkc and we do not ﬁnd
strong evidences for V-structure. Therefore methods based on distributional asymmetry be-
tween cause and effect seem better suited to this dataset. CGNN obtains good results compared
to the other algorithms. Notably, Figure 13 shows that CGNN is able to recover the strong sig-
nal transduction pathway raf
erk reported in Sachs et al. (2005) and corresponding to
clear direct enzyme-substrate causal effect. CGNN gives important scores for edges with good

mek

→

→

20

Figure 12: Orientation by CGNN of E. coli subnetwork with 50 nodes and corresponding to
Syntren simulation with random seed 0. Green edges are good orientation and red arrows false
orientation. The strength of the line refers to the conﬁdence of the algorithm.

pip2

plcg

pip2

plcg

mek

ra f

jnk

mek

ra f

jnk

erk

akt

erk

akt

pip3

pka

pip3

pka

pkc

p38

(a) Ground truth

pip2

plcg

pkc

p38

(c) CAM

erk

akt

erk

akt

pip3

pka

pip3

pka

mek

ra f

jnk

mek

ra f

jnk

pkc

p38

(b) GES

pip2

plcg

pkc

p38

(d) CGNN

Figure 13: Causal protein network

orientation (green line), and low scores (thinnest edges) to the wrong edges (red line), suggest-
ing that false causal discoveries may be controlled by using the conﬁdence scores deﬁned in
Eq. (10).

21

6. Towards predicting confounding effects

In this subsection we propose an extension of our algorithm relaxing the causal sufﬁciency as-
sumption. We are still assuming the Causal Markov and faithfulness assumptions, thus three
options have to be considered for each edge (Xi, X j) of the skeleton representing a direct de-
X j (both variables are consequences of common hidden
pendency: Xi →
variables).

Xi and Xi ↔

X j, X j →

6.1 Principle

X j edge in the graph skeleton.

Hidden common causes are modeled through correlated random noise. Formally, an additional
noise variable Ei, j is associated to each Xi −
We use such new models with correlated noise to study the robustness of our graph recon-
struction algorithm to increasing violations of causal sufﬁciency, by occluding variables from
our datasets. For example, consider the FCM on X = [X1, . . . , X5] that was presented on Figure
1. If variable X1 would be missing from data, the correlated noise E2,3 would be responsible
X3 in the skeleton of our new type
for the existence of a double headed arrow connection X2 ↔
of model. The resulting FCM is shown in Figure 14. Notice that direct causal effects such as
X3 →

X5 may persist, even in presence of possible confounding effects.

X5 or X4 →

E2

E2,3

E3

f3 E3,5

E4,5

f4

f2

X2

X3

E4

X4

E5

f5

X5



X2 = f2(E2, E2,3)
X3 = f3(E3, E2,3, E3,5)

X4 = f4(E4, E4,5)
X5 = f5(X3, X4, E5, E3,5, E4,5)


Figure 14: The Functional Causal Model (FCM) on X = [X1, . . . , X5] with the missing variable
X1

Formally, given a graph skeleton S , the FCM with correlated noise variables is deﬁned as:

fi(XPa(i;G ), Ei, ENe(i;S )),
where Ne(i; S ) is the set of indices of all the variables adjacent to variable Xi in the skeleton

Xi ←

(11)

S .

One can notice that this model corresponds to the most general formulation of the FCM
with potential confounders for each pair of variables in a given skeleton (representing direct
dependencies) where each random variable Ei, j summarizes all the unknown inﬂuences of (pos-
sibly multiple) hidden variables inﬂuencing the two variables Xi and X j.

Here we make a clear distinction between the directed acyclic graph denoted G and the
skeleton S . Indeed, due to the presence of confounding correlated noise, any variable in G can
be removed without altering S . We use the same generative neural network to model the new
FCM presented in Equation 11. The difference is the new noise variables having effect on pairs
of variables simultaneously. However, since the correlated noise FCM is still deﬁned over a
directed acyclic graph G , the functions ˆf1, . . . , ˆfd of the model, which we implement as neural
networks, the model can still be learned end-to-end using backpropagation based on the CGNN
loss.

All edges are evaluated with these correlated noises, the goal being to see whether intro-

ducing a correlated noise explains the dependence between the two variables Xi and X j.

As mentioned before, the score used by CGNN is:
S(C ˆG , ˆf , D) = (cid:92)MMDk(D,

D) + λ

G
|

|

(cid:98)

22

(cid:98)

(12)

G
|

|

(cid:98)

where

is the total number of edges in the DAG. In the graph search, for any given
edge, we compare the score associated to the graph considered with and without this edge. If
the contribution of this edge is negligible compared to a given threshold lambda, the edge is
considered as spurious.

The non-parametric optimization of the ˆG structure is also achieved using a Hill-Climbing
algorithm; in each step an edge of S is randomly drawn and modiﬁed in ˆG using one out of the
possible three operators: reverse the edge, add an edge and remove an edge. Other algorithmic
details are as in Section 4.3.2: the greedy search optimizes the penalized loss function (Eq. 12).
For CGNN, we set the hyperparameter λ = 5

5 ﬁtted on the training graph dataset.

10−

The algorithm stops when no improvement is obtained. Each causal edge Xi →

associated with a score, measuring its contribution to the global score:

X j in G is

×

SXi→
X j}
Missing edges are associated with a score 0.

Xi→

X j = S(C ˆG

−{

, ˆf , D)

S(C ˆG , ˆf , D)

−

(13)

6.2 Experimental validation

Benchmarks. The empirical validation of this extension of CGNN is conducted on same
benchmarks as in Section 5.4 (Gi, i
[[2, 5]]), where 3 variables (causes for at least two other
variables in the graph) have been randomly removed.8 The true graph skeleton is augmented
Y for all X, Y that are consequences of a same removed cause. All algorithms
with edges X
are provided with the same graph skeleton for a fair comparison. The task is to both orient
the edges in the skeleton, and remove the spurious direct dependencies created by latent causal
variables.

−

∈

Baselines. CGNN is compared with state of art methods: i) constraint-based RFCI (Colombo
et al., 2012), extending the PC method equipped with Gaussian conditional independence test
(RFCI-Gaussian) and the gamma HSIC conditional independence test (Gretton et al., 2005)
(RFCI-HSIC). We use the order-independent constraint-based version proposed by Colombo
and Maathuis (2014) and the majority rules for the orientation of the edges. For CGNN, we set
5 ﬁtted on the training graph dataset. Jarfo is trained on the
the hyperparameter λ = 5
16,200 pairs of the cause-effect pair challenge (Guyon, 2013, 2014) to detect for each pair of
variable if Xi →

×
Xi or Xi ↔

Yi, Yi →

10−

Yi.

Table 2: AUPR, SHD and SID on causal discovery with confounders. ∗ denotes signiﬁcance at
p = 10−

2.

method

AUPR

SHD

SID

RFCI-Gaussian
RFCI-HSIC
Jarfo
CGNN ((cid:92)MMDk)

0.22 (0.08)
0.41 (0.09)
0.54 (0.21)

21.9 (7.5)
17.1 (6.2)
20.1 (14.8)

174.9 (58.2)
124.6 (52.3)
98.2 (49.6)

0.71* (0.13)

11.7* (5.5)

53.55* (48.1)

Results.
comparative performances are shown in Table 2, reporting the area under the preci-
sion/recall curve. Overall, these results conﬁrm the robustness of the CGNN proposed approach
w.r.t. confounders, and its competitiveness w.r.t. RFCI with powerful conditional independence
test (RFCI-HSIC). Interestingly, the effective causal relations between the visible variables are
associated with a high score; spurious links due to hidden latent variables get a low score or are
removed.

8The datasets considered are available at http://dx.doi.org/10.7910/DVN/UZMB69

23

7. Discussion and Perspectives

This paper introduces CGNN, a new framework and methodology for functional causal model
learning, leveraging the power and non-parametric ﬂexibility of Generative Neural Networks.
CGNN seamlessly accommodates causal modeling in presence of confounders, and its ex-
tensive empirical validation demonstrates its merits compared to the state of the art on medium-
size problems. We believe that our approach opens new avenues of research, both from the point
of view of leveraging the power of deep learning in causal discovery and from the point of view
of building deep networks with better structure interpretability. Once the model is learned, the
CGNNs present the advantage to be fully parametrized and may be used to simulate interven-
tions on one or more variables of the model and evaluate their impact on a set of target variables.
This usage is relevant in a wide variety of domains, typically among medical and sociological
domains.

The main limitation of CGNN is its computational cost, due to the quadratic complexity of
the CGNN learning criterion w.r.t. the data size, based on the Maximum Mean Discrepancy be-
tween the generated and the observed data. A linear approximation thereof has been proposed,
with comparable empirical performances.

The main perspective for further research aims at a better scalability of the approach from
medium to large problems. On the one hand, the computational scalability could be tackled by
using embedded framework for the structure optimization (inspired by lasso methods). Another
perspective regards the extension of the approach to categorical variables.

References

Peter B¨uhlmann, Jonas Peters, Jan Ernest, et al. Cam: Causal additive models, high-dimensional order

search and penalized regression. The Annals of Statistics, 42(6):2526–2556, 2014.

David Maxwell Chickering. Optimal structure identiﬁcation with greedy search. Journal of Machine

Learning Research, 3(Nov):507–554, 2002.

Kyunghyun Cho, Bart Van Merri¨enboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. Learning phrase representations using RNN encoder-decoder for sta-
tistical machine translation. arXiv, 2014.

Diego Colombo and Marloes H Maathuis. Order-independent constraint-based causal structure learning.

Journal of Machine Learning Research, 15(1):3741–3782, 2014.

Diego Colombo, Marloes H Maathuis, Markus Kalisch, and Thomas S Richardson. Learning high-
dimensional directed acyclic graphs with latent and selection variables. The Annals of Statistics, pages
294–321, 2012.

George Cybenko. Approximation by superpositions of a sigmoidal function. Mathematics of Control,

Signals, and Systems (MCSS), 2(4):303–314, 1989.

Povilas Daniusis, Dominik Janzing, Joris Mooij, Jakob Zscheischler, Bastian Steudel, Kun Zhang, and
Bernhard Sch¨olkopf. Inferring deterministic causal relations. arXiv preprint arXiv:1203.3475, 2012.

Mathias Drton and Marloes H Maathuis. Structure learning in graphical modeling. Annual Review of

Statistics and Its Application, (0), 2016.

RE Edwards. Fourier analysis on groups, 1964.

Jos´e AR Fonollosa. Conditional distribution variability measures for causality detection. arXiv preprint

arXiv:1601.06680, 2016.

Arthur S Goldberger. Reverse regression and salary discrimination. Journal of Human Resources, 1984.

Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. Generative adversarial nets. In Neural Information Processing Systems
(NIPS), pages 2672–2680, 2014.

24

Arthur Gretton, Ralf Herbrich, Alexander Smola, Olivier Bousquet, and Bernhard Sch¨olkopf. Kernel
methods for measuring independence. Journal of Machine Learning Research, 6(Dec):2075–2129,
2005.

Arthur Gretton, Karsten M Borgwardt, Malte Rasch, Bernhard Sch¨olkopf, Alexander J Smola, et al. A

kernel method for the two-sample-problem. 19:513, 2007.

Isabelle Guyon. Chalearn cause effect pairs challenge, 2013. URL http://www.causality.inf.

ethz.ch/cause-effect.php.

Isabelle Guyon. Chalearn fast causation coefﬁcient challenge. 2014.

Geoffrey Hinton, Li Deng, Dong Yu, George E Dahl, Abdel-rahman Mohamed, Navdeep Jaitly, Andrew
Senior, Vincent Vanhoucke, Patrick Nguyen, Tara N Sainath, et al. Deep neural networks for acoustic
modeling in speech recognition: The shared views of four research groups. IEEE Signal Processing
Magazine, 2012.

Patrik O Hoyer, Dominik Janzing, Joris M Mooij, Jonas Peters, and Bernhard Sch¨olkopf. Nonlinear
causal discovery with additive noise models. In Neural Information Processing Systems (NIPS), pages
689–696, 2009.

Markus Kalisch, Martin M¨achler, Diego Colombo, Marloes H Maathuis, Peter B¨uhlmann, et al. Causal
inference using graphical models with the r package pcalg. Journal of Statistical Software, 47(11):
1–26, 2012.

D. P. Kingma and J. Ba. Adam: A Method for Stochastic Optimization. ArXiv e-prints, December 2014.

Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114,

2013.

neural networks. NIPS, 2012.

Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classiﬁcation with deep convolutional

David Lopez-Paz. From dependence to causation. PhD thesis, University of Cambridge, 2016.

David Lopez-Paz and Maxime Oquab.

Revisiting classiﬁer two-sample tests.

arXiv preprint

arXiv:1610.06545, 2016.

David Lopez-Paz, Krikamol Muandet, Bernhard Sch¨olkopf, and Ilya O Tolstikhin. Towards a learning

theory of cause-effect inference. In ICML, pages 1452–1461, 2015.

Pedro Mendes, Wei Sha, and Keying Ye. Artiﬁcial gene networks for objective comparison of analysis

algorithms. Bioinformatics, 19(suppl 2):ii122–ii129, 2003.

Joris M Mooij, Jonas Peters, Dominik Janzing, Jakob Zscheischler, and Bernhard Sch¨olkopf. Distin-
guishing cause from effect using observational data: methods and benchmarks. Journal of Machine
Learning Research, 17(32):1–102, 2016.

Preetam Nandy, Alain Hauser, and Marloes H Maathuis. High-dimensional consistency in score-based

and hybrid structure learning. arXiv preprint arXiv:1507.02608, 2015.

Juan Miguel Ogarrio, Peter Spirtes, and Joe Ramsey. A hybrid causal search algorithm for latent variable

models. In Conference on Probabilistic Graphical Models, pages 368–379, 2016.

Judea Pearl. Causality: models, reasoning and inference. Econometric Theory, 19(675-685):46, 2003.

Judea Pearl. Causality. Cambridge university press, 2009.

Judea Pearl and Thomas Verma. A formal theory of inductive causation. University of California (Los

Angeles). Computer Science Department, 1991.

25

Jonas Peters and Peter B¨uhlmann. Structural intervention distance (sid) for evaluating causal graphs.

arXiv preprint arXiv:1306.1043, 2013.

Jonas Peters, Dominik Janzing, and Bernhard Sch¨olkopf. Elements of Causal Inference - Foundations

and Learning Algorithms. MIT Press, 2017.

John A Quinn, Joris M Mooij, Tom Heskes, and Michael Biehl. Learning of causal relations. In ESANN,

2011.

arXiv:1507.07749, 2015.

962–1030, 2002.

Joseph D Ramsey.

Scaling up greedy causal search for continuous variables.

arXiv preprint

Thomas Richardson and Peter Spirtes. Ancestral graph markov models. The Annals of Statistics, 30(4):

Karen Sachs, Omar Perez, Dana Pe’er, Douglas A Lauffenburger, and Garry P Nolan. Causal protein-
signaling networks derived from multiparameter single-cell data. Science, 308(5721):523–529, 2005.

Richard Scheines. An introduction to causal inference. 1997.

Eleni Sgouritsa, Dominik Janzing, Philipp Hennig, and Bernhard Sch¨olkopf. Inference of cause and effect

with unsupervised inverse regression. In AISTATS, 2015.

Shai S Shen-Orr, Ron Milo, Shmoolik Mangan, and Uri Alon. Network motifs in the transcriptional

regulation network of escherichia coli. Nature genetics, 31(1):64, 2002.

Shohei Shimizu, Patrik O Hoyer, Aapo Hyv¨arinen, and Antti Kerminen. A linear non-gaussian acyclic

model for causal discovery. Journal of Machine Learning Research, 7(Oct):2003–2030, 2006.

David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George Van Den Driessche,
Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, et al. Mastering the
game of Go with deep neural networks and tree search. Nature, 2016.

Peter Spirtes and Kun Zhang. Causal discovery and inference: concepts and recent methodological

advances. In Applied informatics, volume 3, page 3. Springer Berlin Heidelberg, 2016.

Peter Spirtes, Clark Glymour, and Richard Scheines. Causation, prediction and search. 1993. Lecture

Notes in Statistics, 1993.

Peter Spirtes, Christopher Meek, Thomas Richardson, and Chris Meek. An algorithm for causal inference

in the presence of latent variables and selection bias. 1999.

Peter Spirtes, Clark N Glymour, and Richard Scheines. Causation, prediction, and search. MIT press,

2000.

Alexander Statnikov, Mikael Henaff, Nikita I Lytkin, and Constantin F Aliferis. New methods for sepa-

rating causes from effects in genomics data. BMC genomics, 13(8):S22, 2012.

Oliver Stegle, Dominik Janzing, Kun Zhang, Joris M Mooij, and Bernhard Sch¨olkopf. Probabilistic
latent variable models for distinguishing between cause and effect. In Neural Information Processing
Systems (NIPS), pages 1687–1695, 2010.

Ioannis Tsamardinos, Laura E Brown, and Constantin F Aliferis. The max-min hill-climbing bayesian

network structure learning algorithm. Machine learning, 65(1):31–78, 2006.

Tim Van den Bulcke, Koenraad Van Leemput, Bart Naudts, Piet van Remortel, Hongwu Ma, Alain Ver-
schoren, Bart De Moor, and Kathleen Marchal. Syntren: a generator of synthetic gene expression data
for design and analysis of structure learning algorithms. BMC bioinformatics, 7(1):43, 2006.

26

Thomas Verma and Judea Pearl. Equivalence and synthesis of causal models. In Proceedings of the Sixth
Annual Conference on Uncertainty in Artiﬁcial Intelligence, UAI ’90, pages 255–270, New York, NY,
USA, 1991. Elsevier Science Inc. ISBN 0-444-89264-8. URL http://dl.acm.org/citation.
cfm?id=647233.719736.

Makoto Yamada, Wittawat Jitkrittum, Leonid Sigal, Eric P Xing, and Masashi Sugiyama. High-
dimensional feature selection by feature-wise kernelized lasso. Neural computation, 26(1):185–207,
2014.

Kun Zhang and Aapo Hyv¨arinen. On the identiﬁability of the post-nonlinear causal model. In Proceedings
of the twenty-ﬁfth conference on uncertainty in artiﬁcial intelligence, pages 647–655. AUAI Press,
2009.

Kun Zhang, Jonas Peters, Dominik Janzing, and Bernhard Sch¨olkopf. Kernel-based conditional indepen-

dence test and application in causal discovery. arXiv preprint arXiv:1202.3775, 2012.

Kun Zhang, Zhikun Wang, Jiji Zhang, and Bernhard Sch¨olkopf. On estimation of functional causal
models: general results and application to the post-nonlinear causal model. ACM Transactions on
Intelligent Systems and Technology (TIST), 7(2):13, 2016.

27

8. Appendix

8.1 The Maximum Mean Discrepancy (MMD) statistic

The Maximum Mean Discrepancy (MMD) statistic (Gretton et al., 2007) measures the distance
between two probability distributions P and ˆP, deﬁned over Rd, as the real-valued quantity

MMDk(P, ˆP) =

µk(P)

µk( ˆP)

−

.

H
k

(cid:13)
(cid:13)
)
H
(cid:105)
·

(cid:13)
(cid:13)

k(x,

Here, µk =
)dP(x) is the kernel mean embedding of the distribution P, according to the
·
real-valued symmetric kernel function k(x, x(cid:48)) =
), k(x(cid:48),
k(x,
k with associated reproducing
·
(cid:104)
kernel Hilbert space Hk. Therefore, µk summarizes P as the expected value of the features
computed by k over samples drawn from P.

(cid:82)

In practical applications, we do not have access to the distributions P and ˆP, but to their re-
spective sets of samples D and ˆD, deﬁned in Section 4.2.1. In this case, we approximate the ker-
nel mean embedding µk(P) by the empirical kernel mean embedding µk(D) = 1
),
D
·
|
and respectively for ˆP. Then, the empirical MMD statistic is

D k(x,
∈

∑x

|

(cid:92)MMDk(D, ˆD) =

µk(D)

µk( ˆD)

−

k(xi, x j) +

k( ˆxi, ˆx j)

k(xi, ˆx j).

1
n2

n
∑
i, j

2
n2

n
∑
i, j

−

=
H
k

1
n2

n
∑
i, j

(cid:13)
(cid:13)

(cid:13)
(cid:13)

→

Importantly, the empirical MMD tends to zero as n

∞ if and only if P = ˆP, as long as
k is a characteristic kernel (Gretton et al., 2007). This property makes the MMD an excellent
choice to model how close the observational distribution P is to the estimated observational
distribution ˆP. Throughout this paper, we will employ a particular characteristic kernel: the
2
2), where γ > 0 is a hyperparameter controlling the
Gaussian kernel k(x, x(cid:48)) = exp(
smoothness of the features.

In terms of computation, the evaluation of MMDk(D, ˆD) takes O(n2) time, which is pro-
hibitive for large n. When using a shift-invariant kernel, such as the Gaussian kernel, one can
invoke Bochner’s theorem (Edwards, 1964) to obtain a linear-time approximation to the empir-
ical MMD (Lopez-Paz et al., 2015), with form

γ
−

x(cid:48)(cid:107)

x
(cid:107)

−

(cid:92)MMD

m
k (D, ˆD) =

ˆµk(D)

ˆµk( ˆD)

Rm

−

(cid:13)
and O(mn) evaluation time. Here, the approximate empirical kernel mean embedding has form
(cid:13)

(cid:13)
(cid:13)

ˆµk(D) =

2
m

1
D
|

|

∑
D
x
∈

(cid:114)

w1, x
[cos(
(cid:104)

(cid:105)

wm, x
+ b1), . . . , cos(
(cid:104)

(cid:105)

+ bm)] ,

U[0, 2π], for i =
In our experiments, we compare the performance and computation times of both

where wi is drawn from the normalized Fourier transform of k, and bi ∼
1, . . . , m.
(cid:92)MMDk and (cid:92)MMD

m
k .

8.2 Proofs

Proposition 1 Let X = [X1, . . . , Xd] denote a set of continuous random variables with joint distribution P,
and further assume that the joint density function h of P is continuous and strictly positive on a compact
and convex subset of Rd, and zero elsewhere. Letting G be a DAG such that P can be factorized along G ,

P(X) = ∏
i

P(Xi|

XPa(i;G ))

there exists f = ( f1, . . . , fd) with fi a continuous function with compact support in R|
[0, 1] such
that P(X) equals the generative model deﬁned from FCM (G , f , E ), with E = U [0, 1] the uniform distri-
bution on [0, 1].

| ×

Pa(i;G )

Proof By induction on the topological order of G . Let Xi be such that
= 0 and
consider the cumulative distribution Fi(xi) deﬁned over the domain of Xi (Fi(xi) = Pr(Xi < xi)).

Pa(i; G )
|
|

28

(cid:55)→

(ei) and setting Qi = fi yields the result.

Fi is strictly monotonous as the joint density function is strictly positive therefore its inverse,
the quantile function Qi : [0, 1]
dom(Xi) is deﬁned and continuous. By construction, Qi(ei) =
1
F −
i
Assume fi be deﬁned for all variables Xi with topological order less than m. Let X j with
topological order m and Z the vector of its parent variables. For any noise vector e = (ei, i
∈
Pa( j; G )) be the value vector of variables in Z deﬁned from e. The
Pa( j; G )) let z = (xi, i
Z = z) is strictly continuous and
conditional cumulative distribution Fj(x j|
monotonous wrt x j, and can be inverted using the same argument as above. Then we can deﬁne
1
(z, e j).
f j(z, e j) = F −
j

Z = z) = Pr(X j < x j|

∈

Let K j = dom(X j) and KPa( j;G ) = dom(Z). We will show now that the function f j is con-

| ×
∈

[0, 1].
K j ×

tinuous on KPa( j;G ) ×

[0, 1], a compact subset of R|

Pa( j;G )

h j(u,z)
h j(z) du,

h j(u,z)
h j(z)

R such that, for (x j, z)

By assumption, there exist a j ∈

is continuous on the compact K j ×

x j
z) =
a j
with h j a continuous and strictly positive density function. For (a, b)
KPa( j;G ), as the
(cid:82)
h j(u,z)
a
z) =
function (u, z)
h j(z) du
KPa( j;G ), lim
a j
a
x j→
h j(u,b)
(cid:82)
h j(b) on K j, according to exchanging limits theo-

→
uniformly on KPa( j;G ) and lim
b
z
→
rem, F is continuous on (a, b).
For any sequence zn →
z) = u has unique root x j = f j(z, u), the root of F(x j|

two sequences un and x j,n, respectively on [0, 1] and K j, such that un →
F(x j|
converge to x j. Then the function (z, u)

x j
a j
(cid:82)
z, we have that F(x j|

z) uniformly in x j. Let deﬁne
x j. As
u and x j,n →
zn) = un, that is, x j,n = f j(zn, un)
[0, 1].

KPa( j;G ), F(x j|
K j ×
∈
F(x j|

F(x j|

F(x j|

z) =

zn)

→

f j(z, u) is continuous on KPa(i;G ) ×

→

Proposition 2 For m
[[1, d]], let Zm denote the set of variables with topological order less than m and
let dm be its size. For any dm-dimensional vector of noise values e(m), let zm(e(m)) (resp.
zm(e(m))) be the
vector of values computed in topological order from the FCM (G , f , E ) (resp. the CGNN (G , ˆf , E )). For
any ε > 0, there exists a set of networks ˆf with architecture G such that

∈

(cid:98)

e(m),
∀

zm(e(m))
(cid:107)

−

zm(e(m))
(cid:107)

< ε

(14)

(cid:98)

Pa(i; G )
|
|

Proof By induction on the topological order of G . Let Xi be such that
= 0. Follow-
ing the universal approximation theorem Cybenko (1989), as fi is a continuous function over a
compact of R, there exists a neural net ˆfi such that
∞ < ε/d1. Thus Eq. 14 holds for
the set of networks ˆfi for i ranging over variables with topological order 0.
Let us assume that Prop. 2 holds up to m, and let us assume for brevity that there exists a single
variable X j with topological order m + 1. Letting ˆf j be such that
∞ < ε/3 (based on
(cid:107)
the universal approximation property), letting δ be such that for all u
< ε/3
(by absolute continuity) and letting ˆfi satisfying Eq. 14 for i with topological order less than m
for min(ε/3, δ )/dm, it comes:
ˆf j(zm, e j)
|

ˆf j(cid:107)
f j −
ˆf j(u)
−
(cid:107)
(ˆzm, ˆf j( ˆzm, e j))
ˆzm(cid:107)
zm −
< ε/3 + ε/3 + ε/3, which ends the proof.

(zm, f j(zm, e j))
(cid:107)
ˆf j( ˆzm, e j)
|

ˆf j(u + δ )
(cid:107)

ˆf j(zm, e j)

f j(zm, e j)

fi −

(cid:107) ≤ (cid:107)

ˆfi(cid:107)

−

+

+

−

−

(cid:107)

|

|

1 . . . ˆf t

Proposition 3 Let D be an inﬁnite observational sample generated from (G , f , E ). With same notations
as in Prop. 2, for every sequence εt such that εt > 0 goes to zero when t
ft =
d) such that (cid:92)MMDk between D and an inﬁnite size sample
ft , E )
( ˆf t
(cid:98)
is less than εt .
(cid:98)
Proof According to Prop. 2 and with same notations, letting εt > 0 go to 0 as t goes to inﬁnity,
consider ˆft = ( ˆf t
< εt .
denote the inﬁnite sample generated after ˆft . The score of the CGNN (G , ˆft , E )
zt (e(cid:48))) + k(

∞, there exists a set
Dt generated from the CGNN (G ,

d) and ˆzt deﬁned from ˆft such that for all e

ˆDt }
is (cid:92)MMDk(D, ˆDt ) = E

[k(z(e), z(e(cid:48)))

zt (e)
(cid:107)

z(e)
(cid:107)

1 . . . ˆf t

zt (e(cid:48)))].

2k(z(e),

[0, 1]d,

zt (e),

Let

→

−

∈

(cid:98)

(cid:98)

{

e,e(cid:48)

As ˆft converges towards f on the compact [0, 1]d, using the bounded convergence theorem
∞, it follows from the Gaussian
z(e) uniformly for t
(cid:98)

on a compact subset of Rd,

zt (e)

(cid:98)

−

→

(cid:98)
→

(cid:98)

29

kernel function being bounded and continuous that (cid:92)MMDk(D, ˆDt )

0, when t

∞.

→

→

Proposition 4 Let X = [X1, . . . , Xd] denote a set of continuous random variables with joint distribution
P, generated by a CGNN CG , f = (G , f , E ) with G , a directed acyclic graph. And let D be an inﬁnite
observational sample generated from this CGNN. We assume that P is Markov and faithful to the graph
G , and that every pair of variables (Xi, X j) that are d-connected in the graph are not independent. We
note

G , ˆf , E ). Then,

D an inﬁnite sample generated by a candidate CGNN, C
G = G and ˆf = f , then (cid:92)MMDk(D,
(cid:98)

D) = 0.

G , ˆf = (

(cid:98)
G characterized by the same adjacencies but not belonging to the Markov equivalence

(cid:98)

(i) If
(ii) For any graph
class of G , for all ˆf , (cid:92)MMDk(D,

(cid:98)

D)

= 0.

(cid:98)

(cid:98)

(cid:98)

G , ˆf = (
(ii) Let consider
(cid:98)
(cid:98)

Proof The proof of (i) is obvious, as with
by C

G , ˆf , E ) is equal to P, thus we have (cid:92)MMDk(D,

(cid:98)

D) = 0.

G = G and ˆf = f , the joint distribution ˆP generated

}

(cid:98)

(cid:98)

X,Y, Z
{

exists in G , but not in

a) First, we consider that a v-structure

G a DAG characterized by the same adjacencies but that do not belong to
the Markov equivalence class of G . According to Verma and Pearl (1991), as the DAG G and
G have the same adjacencies but are not Markov equivalent, there are not characterized by the
same v-structures.
(cid:98)
P is faithful to G and X and Z are not d-separated by Y in G , we have that (X
Now we consider the graph
generated by the CGNN C
independent, ˆP is Markov with respect to
d-separated by Y . By using the causal Markov assumption, we obtain that (X

G . As the distribution
Y ) in P.
Z
|
G . Let ˆf be a set of neural networks. We note ˆP the distribution
G is a directed acyclic graph and the variables Ei are mutually
G , X and Z are
Y ) in ˆP.
Z
|
G , but not in G . As
(cid:98)
X,Y, Z

is
{
not a v-structure in G , there is an ”unblocked path” between the variables X and Z, the variables
X and Z are d-connected. By assumption, there do not exist a set D not containing Y such that
(cid:98)
G , as
(X
is a v-structure, there exists a set D not containing Y that
d-separates X and Z. As for all CGNN C
G , ˆf generating a distribution ˆP, ˆP is Markov with
(cid:98)
respect to

(cid:98)
b) Second, we consider that a v-structure

G , we have that X

is not a v-structure in

D) in P. In
|

G , ˆf . As
(cid:98)

X,Y, Z
{

exists in

G . As

X,Y, Z

X,Y, Z

⊥⊥

⊥(cid:54)⊥

⊥⊥

Z

Z

(cid:98)

(cid:98)

}

}

{

{

}

}

(cid:98)

In the two cases a) and b) considered above, P and ˆP do not encode the same conditional

D in ˆP.
|

⊥⊥

(cid:98)

independence relations, thus are not equal. We have then (cid:92)MMDk(D, D (cid:48))

(cid:98)

= 0.

30

8.3 Table of scores for the experiments on cause-effect pairs

Table 3: Cause-effect relations: Area Under the Precision Recall curve on 5 benchmarks for the
cause-effect experiments (weighted accuracy in parenthesis for T¨ub). Underline values corre-
spond to best scores.

method

Cha

Net

Gauss Multi

T¨ub

Best ﬁt
LiNGAM
CDS
IGCI
ANM
PNL
Jarfo
GPI
CGNN ((cid:92)MMDk)
m
CGNN ((cid:92)MMD
k )

56.4
54.3
55.4
54.4
66.3
73.1
79.5
67.4

73.6
76.5

77.6
43.7
89.5
54.7
85.1
75.5
92.7
88.4

89.6
87.0

36.3
66.5
84.3
33.2
88.9
83.0
85.3
89.1

82.9
88.3

55.4
59.3
37.2
80.7
35.5
49.0
94.6
65.8

96.6
94.2

58.4 (44.9)
39.7 (44.3)
59.8 (65.5)
60.7 (62.6)
53.7 (59.5)
68.1 (66.2)
54.5 (59.5)
66.4 (62.6)

79.8 (74.4)
76.9 (72.7)

8.4 Table of scores for the experiments on graphs

Table 4: Average (std. dev.) results for the orientation of 20 artiﬁcial graphs given true skeleton
(left), artiﬁcial graphs given skeleton with 20% error (middle). ∗ denotes statistical signiﬁcance
at p = 10−

2. Underline values correspond to best scores.

Skeleton without error
SHD

AUPR

SID

Skeleton with 20% of error
SHD

SID

AUPR

Constraints
PC-Gauss
PC-HSIC

Pairwise
ANM
Jarfo

Score-based
GES
LiNGAM
CAM
m
CGNN ((cid:92)MMD
k )
CGNN ((cid:92)MMDk)

0.67 (0.11)
0.80 (0.08)

9.0 (3.4)
6.7 (3.2)

131 (70)
80.1 (38)

0.42 (0.06)
0.49 (0.06)

21.8 (5.5)
19.8 (5.1)

191.3 (73)
165.1 (67)

0.67 (0.11)
0.74 (0.10)

7.5 (3.0)
8.1 (4.7)

135.4 (63)
147.1 (94)

0.52 (0.10)
0.58 (0.09)

19.2 (5.5)
20.0 (6.8)

171.6 (66)
184.8 (88)

0.48 (0.13)
0.65 (0.10)
0.69 (0.13)
0.77 (0.09)
0.89* (0.09)

14.1 (5.8)
9.6 (3.8)
7.0 (4.3)
7.1 (2.7)
2.5* (2.0)

186.4 (86)
171 (86)
122 (76)
141 (59)
50.45* (45)

0.37 (0.08)
0.53 (0.10)
0.51 (0.11)
0.54 (0.08)
0.62 (0.12)

20.9 (5.5)
20.9 (6.8)
15.6 (5.7)
20 (10)
16.9 (4.5)

209 (83)
196 (83)
175 (80)
179 (102)
134.0* (55)

31

Table 5: Average (std. dev.) results for the orientation of 20 and 50 artiﬁcial graphs coming from
2. Underline
Syntren simulator given true skeleton. ∗ denotes statistical signiﬁcance at p = 10−
values correspond to best scores.

Syntren network 20 nodes

AUPR

SHD

SID

Syntren network 50 nodes
SHD

AUPR

SID

Constraints
PC-Gauss
PC-HSIC

Pairwise
ANM
Jarfo

Score-based
GES
LiNGAM
CAM
m
CGNN ((cid:92)MMD
k )
CGNN ((cid:92)MMDk)

0.40 (0.16)
0.38 (0.15)

16.3 (3.1)
23 (1.7)

198 (57)
175 (16)

0.22 (0.03)
-

61.5 (32)
-

993 (546)
-

0.36 (0.17)
0.42 (0.17)

10.1 (4.2)
10.5 (2.6)

138 (56)
148 (64)

0.35 (0.12)
0.45 (0.13)

29.8 (13.5)
26.2 (14)

677 (313)
610 (355)

0.44 (0.17)
0.40 (0.22)
0.73 (0.08)
0.80* (0.12)
0.79 (0.12)

9.8 (5.0)
10.1 (4.4)
4.0 (2.5)
3.2 (1.6)
3.1* (2.2)

116 (64)
135 (57)
49 (24)
45 (25)
43 (26)

0.52 (0.03)
0.37 (0.28)
0.69 (0.05)
0.82* (0.1)
0.75 (0.09)

21 (11)
33.4 (19)
14.8 (7)
10.2* (5.3)
12.2 (5.5)

462 (248)
757 (433)
285 (136)
247 (134)
309 (140)

Table 6: Average (std. dev.) results for the orientation of the real protein network given true
2. Underline values correspond to best
skeleton. ∗ denotes statistical signiﬁcance at p = 10−
scores.

Causal protein network
SHD

SID

AUPR

0.19 (0.07)
0.18 (0.01)

16.4 (1.3)
17.1 (1.1)

91.9 (12.3)
90.8 (2.6)

0.34 (0.05)
0.33 (0.02)

8.6 (1.3)
10.2 (0.8)

85.9 (10.1)
92.2 (5.2)

0.26 (0.01)
0.29 (0.03)
0.37 (0.10)
0.68 (0.07)
0.74* (0.09)

12.1 (0.3)
10.5 (0.8)
8.5 (2.2)
5.7 (1.7)
4.3* (1.6)

92.3 (5.4)
83.1 (4.8)
78.1 (10.3)
56.6 (10.0)
46.6* (12.4)

Constraints
PC-Gauss
PC-HSIC

Pairwise
ANM
Jarfo

Score-based
GES
LiNGAM
CAM
m
CGNN ((cid:92)MMD
k )
CGNN ((cid:92)MMDk)

32

