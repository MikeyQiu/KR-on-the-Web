6
1
0
2
 
g
u
A
 
4
1
 
 
]

V
C
.
s
c
[
 
 
1
v
1
5
0
4
0
.
8
0
6
1
:
v
i
X
r
a

SSHMT: Semi-supervised Hierarchical Merge
Tree for Electron Microscopy Image
Segmentation

Ting Liu1, Miaomiao Zhang2, Mehran Javanmardi1, Nisha Ramesh1, and
Tolga Tasdizen1

1 Scientiﬁc Computing and Imaging Institute, University of Utah, USA
{ting,mehran,nshramesh,tolga}@sci.utah.edu
2 CSAIL, Massachusetts Institute of Technology, USA
miao86@mit.edu

Abstract. Region-based methods have proven necessary for improv-
ing segmentation accuracy of neuronal structures in electron microscopy
(EM) images. Most region-based segmentation methods use a scoring
function to determine region merging. Such functions are usually learned
with supervised algorithms that demand considerable ground truth data,
which are costly to collect. We propose a semi-supervised approach that
reduces this demand. Based on a merge tree structure, we develop a dif-
ferentiable unsupervised loss term that enforces consistent predictions
from the learned function. We then propose a Bayesian model that com-
bines the supervised and the unsupervised information for probabilistic
learning. The experimental results on three EM data sets demonstrate
that by using a subset of only 3% to 7% of the entire ground truth data,
our approach consistently performs close to the state-of-the-art super-
vised method with the full labeled data set, and signiﬁcantly outperforms
the supervised method with the same labeled subset.

Keywords: Image segmentation, electron microscopy, semi-supervised
learning, hierarchical segmentation, connectomics

1 Introduction

Connectomics researchers study structures of nervous systems to understand
their function [1]. Electron microscopy (EM) is the only modality capable of
imaging substantial tissue volumes at suﬃcient resolution and has been used for
the reconstruction of neural circuitry [2,3,4]. The high resolution leads to image
data sets at enormous scale, for which manual analysis is extremely laborious
and can take decades to complete [5]. Therefore, reliable automatic connectome
reconstruction from EM images, and as the ﬁrst step, automatic segmentation
of neuronal structures is crucial. However, due to the anisotropic nature, defor-
mation, complex cellular structures and semantic ambiguity of the image data,
automatic segmentation still remains challenging after years of active research.

2

Similar to the boundary detection/region segmentation pipeline for natu-
ral image segmentation [6,7,8,9], most recent EM image segmentation meth-
ods use a membrane detection/cell segmentation pipeline. First, a membrane
detector generates pixel-wise conﬁdence maps of membrane predictions using
local image cues [10,11,12]. Next, region-based methods are applied to trans-
forming the membrane conﬁdence maps into cell segments. It has been shown
that region-based methods are necessary for improving the segmentation ac-
curacy from membrane detections for EM images [13]. A common approach to
region-based segmentation is to transform a membrane conﬁdence map into over-
segmenting superpixels and use them as “building blocks” for ﬁnal segmentation.
To correctly combine superpixels, greedy region agglomeration based on certain
boundary saliency has been shown to work [14]. Meanwhile, structures, such as
loopy graphs [15,16] or trees [17,18,19], are more often imposed to represent the
region merging hierarchy and help transform the superpixel combination search
into graph labeling problems. To this end, local [17,16] or structured [18,19]
learning based methods are developed.

Most current region-based segmentation methods use a scoring function to
determine how likely two adjacent regions should be combined. Such scoring
functions are usually learned in a supervised manner that demands considerable
amount of high-quality ground truth data. Obtaining such ground truth data,
however, involves manual labeling of image pixels and is very labor intensive, es-
pecially given the large scale and complex structures of EM images. To alleviate
this demand, Parag et al. recently propose an active learning framework [20,21]
that starts with small sets of labeled samples and constantly measures the dis-
agreement between a supervised classiﬁer and a semi-supervised label propa-
gation algorithm on unlabeled samples. Only the most disagreed samples are
pushed to users for interactive labeling. The authors demonstrate that by us-
ing 15% to 20% of all labeled samples, the method can perform similar to the
underlying fully supervised method with full training set. One disadvantage of
this framework is that it does not directly explore the unsupervised informa-
tion while searching for the optimal classiﬁcation function. Also, retraining is
required for the supervised algorithm at each iteration, which can be time con-
suming especially when more iterations with fewer samples per iteration are used
to maximize the utilization of supervised information and minimize human ef-
fort. Moreover, repeated human interactions may lead to extra cost overhead in
practice.

In this paper, we propose a semi-supervised learning framework for region-
based neuron segmentation that seeks to reduce the demand for labeled data by
exploiting the underlying correlation between unsupervised data samples. Based
on the merge tree structure [17,18,19], we redeﬁne the labeling constraint and
formulate it into a diﬀerentiable loss function that can be eﬀectively used to guide
the unsupervised search in the function hypothesis space. We then develop a
Bayesian model that incorporates both unsupervised and supervised information
for probabilistic learning. The parameters that are essential to balancing the
learning can be estimated from the data automatically. Our method works with

very small amount of supervised data and requires no further human interaction.
We show that by using only 3% to 7% of the labeled data, our method performs
stably close to the state-of-the-art fully supervised algorithm with the entire
supervised data set (Section 4). Also, our method can be conveniently adopted
to replace the supervised algorithm in the active learning framework [20,21] and
further improve the overall segmentation performance.

3

2 Hierarchical Merge Tree

Starting with an initial superpixel segmentation So of an image, a merge tree
T = (V, E) is a graphical representation of superpixel merging order. Each node
vi ∈ V corresponds to an image region si. Each leaf node aligns with an initial
superpixel in So. A non-leaf node corresponds to an image region combined by
multiple superpixels, and the root node represents the whole image as a single
region. An edge ei,c ∈ E between vi and one of its child vc indicates sc ⊂ si.
Assuming only two regions are merged each time, we have T as a full binary
tree. A clique pi = ({vi, vc1 , vc2}, {ei,c1, ei,c2 }) represents si = sc1 ∪ sc2. In this
paper, we call clique pi is at node vi. We call the cliques pc1 and pc2 at vc1 and
vc2 the child cliques of pi, and pi the parent clique of pc1 and pc2. If vi is a leaf
node, pi = ({vi}, ∅) is called a leaf clique. We call pi a non-leaf/root/non-root
clique if vi is a non-leaf/root/non-root node. An example merge tree, as shown
in Fig. 1c, represents the merging of superpixels in Fig. 1a. The red box in
Fig. 1c shows a non-leaf clique p7 = ({v7, v1, v2}, {e7,1, e7,2}) as the child clique
of p9 = ({v9, v7, v3}, {e9,7, e9,3}). A common approach to building a merge tree
is to greedily merge regions based on certain boundary saliency measurement in
an iterative fashion [17,18,19].

(a)

(b)

(c)

Fig. 1: Example of (a) an initial superpixel segmentation, (b) a consistent ﬁnal
segmentation, and (c) the corresponding merge tree. The red nodes are selected
(z = 1) for the ﬁnal segmentation, and the black nodes are not (z = 0). The red
box shows a clique.

4

Given the merge tree, the problem of ﬁnding a ﬁnal segmentation is equivalent
to ﬁnding a complete label assignment z = {zi}|V|
i=1 for every node being a ﬁnal
segment (z = 1) or not (z = 0). Let ρ(i) be a query function that returns the
index of the parent node of vi. The k-th (k = 1, . . . di) ancestor of vi is denoted as
ρk(i) with di being the depth of vi in the tree, and ρ0(i) = i. For every leaf-to-root
path, we enforce the region consistency constraint that requires (cid:80)di
k=0 zρk(i) = 1
for any leaf node vi. As an example shown in Fig. 1c, the red nodes (v6, v8,
and v9) are labeled z = 1 and correspond to the ﬁnal segmentation in Fig. 1b.
The rest black nodes are labeled z = 0. Supervised algorithms are proposed to
learn scoring functions in a local [17,9] or a structured [18,19] fashion, followed
by greedy [17] or global [18,9,19] inference techniques for ﬁnding the optimal
label assignment under the constraint. We refer to the local learning and greedy
search inference framework in [17] as the hierarchical merge tree (HMT) method
and follow its settings in the rest of this paper, as it has been shown to achieve
state-of-the-art results in the public challenges [13,22].

A binary label yi is used to denote whether the region merging at clique pi
occurs (“merge”, yi = 1) or not (“split”, yi = 0). For a leaf clique, y = 1. At
training time, y = {yi}|V|
i=1 is generated by comparing both the “merge” and
“split” cases for non-leaf cliques against the ground truth segmentation under
certain error metric (e.g. adapted Rand error [13]). The one that causes the lower
error is adopted. A binary classiﬁcation function called the boundary classiﬁer is
trained with (X, y), where X = {xi}|V|
i=1 is a collection of feature vectors. Shape
and image appearance features are commonly used.

At testing time, each non-leaf clique pi is assigned a likelihood score P (yi|xi)

by the classiﬁer. A potential for each node vi is deﬁned as

ui = P (yi = 1|xi) · P (yρ(i) = 0|xρ(i)).

(1)

The greedy inference algorithm iteratively assigns z = 1 to an unlabeled node
with the highest potential and z = 0 to its ancestor and descendant nodes until
every node in the merge tree receives a label. The nodes with z = 1 forms a ﬁnal
segmentation.

Note that HMT is not limited to segmenting images of any speciﬁc dimen-
sionality. In practice, it has been successfully applied to both 2D [17,13] and 3D
segmentation [22] of EM images.

3 SSHMT: Semi-supervised Hierarchical Merge Tree

The performance of HMT largely depends on accurate boundary predictions
given ﬁxed initial superpixels and tree structures. In this section, we propose
a semi-supervised learning based HMT framework, named SSHMT, to learn
accurate boundary classiﬁers with limited supervised data.

5

(2)

3.1 Merge consistency constraint

Following the HMT notation (Section 2), we ﬁrst deﬁne the merge consistency
constraint for non-root cliques:

yi ≥ yρ(i), ∀i.

Clearly, a set of consistent node labeling z can be transformed to a consistent y
by assigning y = 1 to the cliques at the nodes with z = 1 and their descendant
cliques and y = 0 to the rest. A consistent y can be transformed to z by assigning
z = 1 to the nodes in {vi ∈ V|∀i, s.t. yi = 1 ∧ (vi is the root ∨ yρ(i) = 0)} and
z = 0 to the rest, vice versa.

Deﬁne a clique path of length L that starts at pi as an ordered set πL

i =

{pρl(i)}L−1

l=0 . We then have

i = {yρl(i)}L−1
Theorem 1. Any consistent label sequence yL
merge consistency constraint is monotonically non-increasing.

l=0 for πL

i under the

Proof. Assume there exists a label sequence yL
i subject to the merge consistency
constraint that is not monotonically non-increasing. By deﬁnition, there must
exist k ≥ 0, s.t. yρk(i) < yρk+1(i). Let j = ρk(i), then ρk+1(i) = ρ(j), and thus
yj < yρ(j). This violates the merge consistency constraint (2), which contradicts
the initial assumption that yL
is subject to the merge consistency constraint.
i
Therefore, the initial assumption must be false, and all label sequences that
are subject to the merge consistency constraint must be monotonically non-
(cid:117)(cid:116)
increasing.

Intuitively, Theorem 1 states that while moving up in a merge tree, once a
split occurs, no merge shall occur again among the ancestor cliques in that path.
As an example, a consistent label sequence for the clique path {p7, p9, p11} in
Fig. 1c can only be {y7, y9, y11} = {0, 0, 0}, {1, 0, 0}, {1, 1, 0}, or {1, 1, 1}. Any
other label sequence, such as {1, 0, 1}, is not consistent. In contrast to the region
consistency constraint, the merge consistency constraint is a local constraint that
holds for the entire leaf-to-root clique paths as well as any of their subparts. This
allows certain computations to be decomposed as shown later in Section 4.

Let fi be a predicate that denotes whether yi = 1. We can express the non-
in disjunctive

increasing monotonicity of any consistent label sequence for πL
i
normal form (DNF) as

F L

i =

L
(cid:95)

j−1
(cid:94)





j=0

k=0

L−1
(cid:94)

k=j



fρk(i) ∧

¬fρk(i)

 ,

(3)

which always holds true by Theorem 1. We approximate F L
i with real-valued
variables and operators by replacing true with 1, f alse with 0, and f with
real-valued ˜f . A negation ¬f is replaced by 1 − ˜f ; conjunctions are replaced
by multiplications; disjunctions are transformed into negations of conjunctions

6

using De Morgan’s laws and then replaced. The real-valued DNF approximation
is

˜F L

i = 1 −



1 −

L
(cid:89)

j=0

j−1
(cid:89)

k=0

˜fρk(i) ·

1 − ˜fρk(i)

L−1
(cid:89)

(cid:16)

k=j

(cid:17)



 ,

which is valued 1 for any consistent label assignments. Observing ˜f is exactly
a binary boundary classiﬁer in HMT, we further relax it to be a classiﬁcation
function that predicts P (y = 1|x) ∈ [0, 1]. The choice of ˜f can be arbitrary
as long as it is (piecewise) diﬀerentiable (Section 3.2). In this paper, we use a
logistic sigmoid function with a linear discriminant

(4)

(5)

˜f (x; w) =

1
1 + exp(−w(cid:62)x)

,

which is parameterized by w.

We would like to ﬁnd an ˜f so that its predictions satisfy the DNF (4) for
any path in a merge tree. We will introduce the learning of such ˜f in a semi-
supervised manner in Section 3.2.

3.2 Bayesian semi-supervised learning

To learn the boundary classiﬁcation function ˜f , we use both supervised and
unsupervised data. Supervised data are the clique samples with labels that are
generated from ground truth segmentations. Unsupervised samples are those
we do not have labels for. They can be from the images that we do not have
the ground truth for or wish to segment. We use Xs to denote the collection of
supervised sample feature vectors and ys for their true labels. X is the collection
of all supervised and unsupervised samples.

Let ˜f w = [ ˜fj1, . . . , ˜fjNs

](cid:62) be the predictions about the supervised samples
in Xs, and ˜F w = [ ˜F L
](cid:62) be the DNF values (4) for all paths from X.
i1
We are now ready to build a probabilistic model that includes a regularization
prior, an unsupervised likelihood, and a supervised likelihood.

, . . . , ˜F L
iNu

The prior is an i.i.d. Gaussian N (0, 1) that regularizes w to prevent overﬁt-
ting. The unsupervised likelihood is an i.i.d. Gaussian N (0, σu) on the diﬀerences
between each element of ˜F w and 1. It requires the predictions of ˜f to conform
the merge consistency constraint for every path. Maximizing the unsupervised
likelihood allows us to narrow down the potential solutions to a subset in the
classiﬁer hypothesis space without label information by exploring the sample
feature representation commonality. The supervised likelihood is an i.i.d. Gaus-
sian N (0, σs) on the prediction errors for supervised samples to enforce accurate
predictions. It helps avoid consistent but trivial solutions of ˜f , such as the ones
that always predict y = 1 or y = 0, and guides the search towards the correct
solution. The standard deviation parameters σu and σs control the contributions
of the three terms. They can be preset to reﬂect our prior knowledge about the
model distributions, tuned using a holdout set, or estimated from data.

7

(6)

(7)

(9)

By applying Bayes’ rule, we have the posterior distribution of w as

P (w | X, Xs, ys, σu, σs) ∝ P (w) · P (1 | X, w, σu) · P (ys | Xs, w, σs)

(cid:18)

∝ exp

−

(cid:19)

(cid:107)w(cid:107)2
2
2

·

·

1

1

(cid:0)√

(cid:1)Nu

2πσu

exp

−

(cid:0)√

(cid:1)Ns

2πσs

exp

−

(cid:32)

(cid:32)

(cid:33)

(cid:107)1 − ˜F w(cid:107)2
2
2σ2
u

(cid:107)ys − ˜f w(cid:107)2
2σ2
s

2

(cid:33)

,

where Nu and Ns are the number of elements in ˜F w and ˜f w, respectively; 1 is
a Nu-dimensional vector of ones.

Inference We infer the model parameters w, σu, and σs using maximum a
posteriori estimation. We eﬀectively minimize the negative logarithm of the pos-
terior

J(w, σu, σs) =

(cid:107)w(cid:107)2

2 +

(cid:107)1 − ˜F w(cid:107)2

2 + Nu log σu

1
2σ2
u

1
2

+

1
2σ2
s

(cid:107)ys − ˜f w(cid:107)2

2 + Ns log σs.

Observe that the DNF formula in (4) is diﬀerentiable. With any (piecewise)
diﬀerentiable choice of ˜fw, we can minimize (7) using (sub-) gradient descent.
The gradient of (7) with respect to the classiﬁer parameter w is

∇wJ = w(cid:62) −

(cid:17)(cid:62)

1 − ˜F w

∇w ˜F w −

(cid:17)(cid:62)

ys − ˜f w

∇w ˜f w,

(8)

(cid:16)

1
σ2
u

(cid:16)

1
σ2
s

Since we choose ˜f to be a logistic sigmoid function with a linear discrimi-

nant (5), the j-th (j = 1, . . . , Ns) row of ∇w ˜f w is
˜fj = ˜fj(1 − ˜fj) · x(cid:62)
j .

∇w

where xj is the j-th element in Xs.
˜fρk(i) · (cid:81)L−1

Deﬁne gj = (cid:81)j−1

k=j (1 − ˜fρk(i)), j = 0, . . . , L, we write (4) as
j=0(1 − gj) as the i-th (i = 1, . . . , Nu) element of ˜F w. Then the i-th

k=0

i = 1 − (cid:81)L
˜F L
row of ∇w ˜F w is

∇w ˜F L

i =




gj

L
(cid:88)

j=0

L
(cid:89)

k=0
k(cid:54)=j










(1 − gk)

j−1
(cid:88)

∇w

˜fρk(i)

˜fρk(i)

k=0

−

L−1
(cid:88)

k=j

˜fρk(i)
∇w
1 − ˜fρk(i)



 ,

(10)

where ∇w

˜fρk(i) can be computed using (9).

8

We also alternately estimate σu and σs along with w. Setting ∇σu J = 0 and

∇σsJ = 0, we update σu and σs using the closed-form solutions

σu =

σs =

(cid:107)1 − ˜F w(cid:107)2
√
Nu
(cid:107)ys − ˜f w(cid:107)2
√
Ns

.

(11)

(12)

At testing time, we apply the learned ˜f to testing samples to predict their
merging likelihood. Eventually, we compute the node potentials with (1) and
apply the greedy inference algorithm to acquire the ﬁnal node label assignment
(Section 2).

We validate the proposed algorithm for 2D and 3D segmentation of neurons in
three EM image data sets. For each data set, we apply SSHMT to the same seg-
mentation tasks using diﬀerent amounts of randomly selected subsets of ground
truth data as the supervised sets.

4 Results

4.1 Data sets

Mouse neuropil data set [23] consists of 70 2D SBFSEM images of size
700 × 700 × 700 at 10 × 10 × 50 nm/pixel resolution. A random selection of 14
images are considered as the whole supervised set, and the rest 56 images are
used for testing. We test our algorithm using 14 (100%), 7 (50%), 3 (21.42%), 2
(14.29%), 1 (7.143%), and half (3.571%) ground truth image(s) as the supervised
data. We use all the 70 images as the unsupervised data for training. We target
at 2D segmentation for this data set.

Mouse cortex data set [22] is the original training set for the ISBI SNEMI3D
Challenge [22]. It is a 1024×1024×100 SSSEM image stack at 6×6×30 nm/pixel
resolution. We use the ﬁrst 1024 × 1024 × 50 substack as the supervised set and
the second 1024 × 1024 × 50 substack for testing. There are 327 ground truth
neuron segments that are larger than 1000 pixels in the supervised substack,
which we consider as all the available supervised data. We test the performance
of our algorithm by using 327 (100%), 163 (49.85%), 81 (24.77%), 40 (12.23%), 20
(6.116%), 10 (3.058%), and 5 (1.529%) true segments. Both the supervised and
the testing substack are used for the unsupervised term. Due to the unavailability
of the ground truth data, we did not experiment with the original testing image
stack from the challenge. We target at 3D segmentation for this data set.

9

Drosophila melanogaster larval neuropil data set [24] is a 500 × 500 × 500
FIBSEM image volume at 10 × 10 × 10 nm/pixel resolution. We divide the whole
volume evenly into eight 250 × 250 × 250 subvolumes and do eight-fold cross
validation using one subvolume each time as the supervised set and the whole
volume as the testing data. Each subvolume has from 204 to 260 ground truth
neuron segments that are larger than 100 pixels. Following the setting in the
mouse cortex data set experiment, we use subsets of 100%, 50%, 25%, 12.5%,
6.25%, and 3.125% of all true neuron segments from the respective supervised
subvolume in each fold of the cross validation as the supervised data to generate
boundary classiﬁcation labels. We use the entire volume to generate unsupervised
samples. We target at 3D segmentation for this data set.

4.2 Experiments

We use fully trained Cascaded Hierarchical Models [12] to generate membrane
detection conﬁdence maps and keep them ﬁxed for the HMT and SSHMT exper-
iments on each data set, respectively. To generate initial superpixels, we use the
watershed algorithm [25] over the membrane conﬁdence maps. For the boundary
classiﬁcation, we use features including shape information (region size, perime-
ter, bounding box, boundary length, etc.) and image intensity statistics (mean,
standard deviation, minimum, maximum, etc.) of region interior and boundary
pixels from both the original EM images and membrane detection conﬁdence
maps.

We use the adapted Rand error metric [13] to generate boundary classiﬁ-
cation labels using whole ground truth images (Section 2) for the 2D mouse
neuropil data set. For the 3D mouse cortex and Drosophila melanogaster lar-
val neuropil data sets, we determine the labels using individual ground truth
segments instead. We use this setting in order to match the actual process of
analyzing EM images by neuroscientists. Details about label generation using
individual ground truth segments are provided in Appendix A.

We can see in (4) and (10) that computing ˜F L

i and its gradient involves
multiplications of L ﬂoating point numbers, which can cause underﬂow problems
for leaf-to-root clique paths in a merge tree of even moderate height. To avoid
this problem, we exploit the local property of the merge consistency constraint
and compute ˜F L
for every path subpart of small length L. In this paper, we
i
use L = 3 for all experiments. For inference, we initialize w by running gradient
descent on (7) with only the supervised term and the regularizer before adding
the unsupervised term for the whole optimization. We update σu and σs in
between every 100 gradient descent steps on w.

We compare SSHMT with the fully supervised HMT [17] as the baseline
method. To make the comparison fair, we use the same logistic sigmoid func-
tion as the boundary classiﬁer for both HMT and SSHMT. The fully supervised
training uses the same Bayesian framework only without the unsupervised term
in (7) and alternately estimates σs to balance the regularization term and the su-
pervised term. All the hyperparameters are kept identical for HMT and SSHMT
and ﬁxed for all experiments. We use the adapted Rand error [13] following the

10

public EM image segmentation challenges [13,22]. Due to the randomness in
the selection of supervised data, we repeat each experiment 50 times, except in
the cases that there are fewer possible combinations. We report the mean and
standard deviation of errors for each set of repeats on the three data sets in
Table ??. For the 2D mouse neuropil data set, we also threshold the membrane
detection conﬁdence maps at the optimal level, and the adapted Rand error is
0.2023. Since the membrane detection conﬁdence maps are generated in 2D, we
do not measure the thresholding errors of the other 3D data sets. In addition,
we report the results from using the globally optimal tree inference [9] in the
supplementary materials for comparison.

Examples of 2D segmentation testing results from the mouse neuropil data
set using fully supervised HMT and SSHMT with 1 (7.143%) ground truth im-
age as supervised data are shown in Fig. 2. Examples of 3D individual neuron
segmentation testing results from the Drosophila melanogaster larval neuropil
data set using fully supervised HMT and SSHMT with 12 (6.25%) true neuron
segments as supervised data are shown in Fig. 3.

From Table ??, we can see that with abundant supervised data, the perfor-
mance of SSHMT is similar to HMT in terms of segmentation accuracy, and both
of them signiﬁcantly improve from optimally thresholding (Table 0a). When the
amount of supervised data becomes smaller, SSHMT signiﬁcantly outperforms
the fully supervised method with the accuracy close to the HMT results using
the full supervised sets. Moreover, the introduction of the unsupervised term
stabilizes the learning of the classiﬁcation function and results in much more
consistent segmentation performance, even when only very limited (3% to 7%)
label data are available. Increases in errors and large variations are observed in
the SSHMT results when the supervised data become too scarce. This is be-
cause the few supervised samples are incapable of providing suﬃcient guidance
to balance the unsupervised term, and the boundary classiﬁers are biased to give
trivial predictions.

Fig. 2 shows that SSHMT is capable of ﬁxing both over- and under-segmentation

errors that occur in the HMT results. Fig. 3 also shows that SSHMT can ﬁx over-
segmentation errors and generate highly accurate neuron segmentations. Note
that in our experiments, we always randomly select the supervised data subsets.
For realistic uses, we expect supervised samples of better representativeness to be
provided with expertise and the performance of SSHMT to be further improved.

We also conducted an experiment with the mouse neuropil data set in which
we use only 1 ground truth image to train the membrane detector, HMT, and
SSHMT to test a fully semi-supervised EM segmentation pipeline. We repeat 14
times for every ground truth image in the supervised set. The optimal thresh-
olding gives adapted Rand error 0.3603 ± 0.06827. The error of the HMT results
is 0.2904 ± 0.09303, and the error of the SSHMT results is 0.2373 ± 0.06827. De-
spite the increase of error, which is mainly due to the fully supervised nature of
the membrane detection algorithm, SSHMT again improves the region accuracy
from optimal thresholding and has a clear advantage over HMT.

11

Table 1: Means and standard deviations of the adapted Rand errors of HMT and
SSHMT segmentations for the three EM data sets. The left table columns show
the amount of used ground truth data, in terms of (a) the number of images, (b)
the number of segments, and (c) the percentage of all segments. Bold numbers in
the tables show the results of the higher accuracy under comparison. The ﬁgures
on the right visualize the means (dashed lines) and the standard deviations (solid
bars) of the errors of HMT (red) and SSHMT (blue) results for each data set.

(a) Mouse neuropil

HMT

SSHMT

Std. Mean
0.1196

-

Std.
-

#GT Mean
14 0.1135
7
3
2
1
0.5

0.1382 0.03238 0.1208 0.004033
0.1492 0.04851 0.1205 0.001383
0.1811 0.07346 0.1217 0.004116
0.2035 0.1029 0.1210 0.002206
0.2505 0.1062 0.1365 0.1079

Optimal thresholding: 0.2023

(b) Mouse cortex

HMT

SSHMT

-

Std.
-

Std. Mean
0.1104

#GT Mean
327 0.1101
163 0.1344 0.03660 0.1189 0.01506
0.1583 0.06909 0.1215 0.01661
81
0.1844 0.1019 0.1198 0.01690
40
0.2205 0.1226 0.1238 0.01466
20
0.2503 0.1561 0.1219 0.01273
10
0.4389 0.2769 0.2008 0.2285
5

(c) Drosophila melanogaster larval neuropil

HMT

SSHMT

-

0.05504

Std.
-

Std. Mean

%GT Mean
100% 0.06044
50% 0.09004 0.04476 0.05602 0.005550
25% 0.1240 0.07491 0.05803 0.007703
12.5% 0.1418 0.1055 0.05835 0.007797
6.25% 0.1748 0.1389 0.05756 0.008933
3.125% 0.2017 0.1871 0.06213 0.03660

12

(a) Original

(b) HMT

(c) SSHMT

(d) Ground truth

Fig. 2: Examples of the 2D segmentation testing results for the mouse neuropil
data set, including (a) original EM images, (b) HMT and (c) SSHMT results
using 1 ground truth image as supervised data, and (d) the corresponding ground
truth images. Diﬀerent colors indicate diﬀerent individual segments.

13

(a) HMT

(b) SSHMT

(c) Ground truth

Fig. 3: Examples of individual neurons from the 3D segmentation testing results
for the Drosophila melanogaster larval neuropil data set, including (a) HMT and
(b) SSHMT results using 12 (6.25%) 3D ground truth segments as supervised
data, and (c) the corresponding ground truth segments. Diﬀerent colors indicate
diﬀerent individual segments. The 3D visualizations are generated using Fiji [26].

14

We have open-sourced our code at https://github.com/tingliu/glia. It
takes approximately 80 seconds for our SSHMT implementation to train and
test on the whole mouse neuropil data set using 50 2.5 GHz Intel Xeon CPUs
and about 150 MB memory.

5 Conclusion

In this paper, we proposed a semi-supervised method that can consistently learn
boundary classiﬁers with very limited amount of supervised data for region-based
image segmentation. This dramatically reduces the high demands for ground
truth data by fully supervised algorithms. We applied our method to neuron
segmentation in EM images from three data sets and demonstrated that by us-
ing only a small amount of ground truth data, our method performed close to
the state-of-the-art fully supervised method with full labeled data sets. In our
future work, we will explore the integration of the proposed constraint based un-
supervised loss in structural learning settings to further exploit the structured
information for learning the boundary classiﬁcation function. Also, we may re-
place the current logistic sigmoid function with more complex classiﬁers and
combine our method with active learning frameworks to improve segmentation
accuracy.

Acknowledgment This work was supported by NSF IIS-1149299 and NIH
1R01NS075314-01. We thank the National Center for Microscopy and Imaging
Research at the University of California, San Diego, for providing the mouse
neuropil data set. We also thank Mehdi Sajjadi at the University of Utah for the
constructive discussions.

A Appendix: Generating Boundary Classiﬁcation Labels

Using Individual Ground Truth Segments

Assume we only have individual annotated image segments instead of entire
image volumes as ground truth. Given a merge tree, we generate the best-eﬀort
ground truth classiﬁcation labels for a subset of cliques as follows:

1. For every region represented by a tree node, compute the Jaccard indices of
this region against all the annotated ground truth segments. Use the highest
Jaccard index of each node as its eligible score.

2. Mark every node in the tree as “eligible” if its eligible score is above certain

threshold (0.75 in practice) or “ineligible” otherwise.

3. Iteratively select a currently “eligible” node with the highest eligible score;
mark it and its ancestors and descendants as “ineligible”, until every node
is “ineligible”. This procedure generates a set of selected nodes.

4. For every selected node, label the cliques at itself and its descendants as

y = 1 (“merge”) and the cliques at its ancestors as y = 0 (“split”).

Eventually, the clique samples that receive merge/split labels are considered

as the supervised data.

15

References

1. Sporns, O., Tononi, G., K¨otter, R.: The human connectome: a structural descrip-

tion of the human brain. PLoS Computational Biology 1(4) (2005) e42

2. Famiglietti, E.V.: Synaptic organization of starburst amacrine cells in rabbit retina:
analysis of serial thin sections by electron microscopy and graphic reconstruction.
Journal of Comparative Neurology 309(1) (1991) 40–70

3. Briggman, K.L., Helmstaedter, M., Denk, W.: Wiring speciﬁcity in the direction-

selectivity circuit of the retina. Nature 471(7337) (2011) 183–188

4. Helmstaedter, M.: Cellular-resolution connectomics: challenges of dense neural

circuit reconstruction. Nature Methods 10(6) (2013) 501–507

5. Briggman, K.L., Denk, W.: Towards neural circuit reconstruction with volume
electron microscopy techniques. Current Opinion in Neurobiology 16(5) (2006)
562–570

6. Arbelaez, P., Maire, M., Fowlkes, C., Malik, J.: Contour detection and hierarchical
image segmentation. Pattern Analysis and Machine Intelligence, IEEE Transac-
tions on 33(5) (2011) 898–916

7. Ren, Z., Shakhnarovich, G.: Image segmentation by cascaded region agglomera-
tion. In: Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition. (2013) 2011–2018

8. Arbel´aez, P., Pont-Tuset, J., Barron, J., Marques, F., Malik, J.: Multiscale com-
binatorial grouping. In: Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition. (2014) 328–335

9. Liu, T., Seyedhosseini, M., Tasdizen, T.: Image segmentation using hierarchical
merge tree. Image Processing, IEEE Transactions on 25(10) (2016) 4596–4607
10. Sommer, C., Straehle, C., Koethe, U., Hamprecht, F.A.: ilastik: Interactive learning
In: Biomedical Imaging: From Nano to Macro, 2011

and segmentation toolkit.
IEEE International Symposium on, IEEE (2011) 230–233

11. Ciresan, D., Giusti, A., Gambardella, L.M., Schmidhuber, J.: Deep neural net-
works segment neuronal membranes in electron microscopy images. In: Advances
in Neural Information Processing Systems 25. (2012) 2852–2860

12. Seyedhosseini, M., Sajjadi, M., Tasdizen, T.: Image segmentation with cascaded
hierarchical models and logistic disjunctive normal networks. In: Proceedings of
the IEEE International Conference on Computer Vision. (2013) 2168–2175

13. Arganda-Carreras, I., Turaga, S.C., Berger, D.R., Cire¸san, D., Giusti, A., Gam-
bardella, L.M., Schmidhuber, J., Laptev, D., Dwivedi, S., Buhmann, J.M., et al.:
Crowdsourcing the creation of image segmentation algorithms for connectomics.
Frontiers in Neuroanatomy 9 (2015)

14. Nunez-Iglesias, J., Kennedy, R., Parag, T., Shi, J., Chklovskii, D.B.: Machine
learning of hierarchical clustering to segment 2D and 3D images. PLoS ONE 8(8)
(2013) e71715

15. Kaynig, V., Vazquez-Reina, A., Knowles-Barley, S., Roberts, M., Jones, T.R.,
Kasthuri, N., Miller, E., Lichtman, J., Pﬁster, H.: Large-scale automatic recon-
struction of neuronal processes from electron microscopy images. Medical Image
Analysis 22(1) (2015) 77–88

16. Krasowski, N., Beier, T., Knott, G., Koethe, U., Hamprecht, F., Kreshuk, A.:
Improving 3D EM data segmentation by joint optimization over boundary evidence
and biological priors. In: Biomedical Imaging (ISBI), 2015 IEEE 12th International
Symposium on, IEEE (2015) 536–539

16

17. Liu, T., Jones, C., Seyedhosseini, M., Tasdizen, T.: A modular hierarchical ap-
proach to 3D electron microscopy image segmentation. Journal of Neuroscience
Methods 226 (2014) 88–102

18. Funke, J., Hamprecht, F.A., Zhang, C.: Learning to segment: Training hierar-
chical segmentation under a topological loss. In: Medical Image Computing and
Computer-Assisted Intervention–MICCAI 2015. Springer (2015) 268–275

19. Uzunbas, M.G., Chen, C., Metaxas, D.: An eﬃcient conditional random ﬁeld ap-
proach for automatic and interactive neuron segmentation. Medical Image Analysis
27 (2016) 31–44

20. Parag, T., Plaza, S., Scheﬀer, L.: Small sample learning of superpixel classi-
ﬁers for em segmentation. In: Medical Image Computing and Computer-Assisted
Intervention–MICCAI 2014. Springer (2014) 389–397

21. Parag, T., Ciresan, D.C., Giusti, A.: Eﬃcient classiﬁer training to minimize false
merges in electron microscopy segmentation. In: Proceedings of the IEEE Inter-
national Conference on Computer Vision. (2015) 657–665

22. Arganda-Carreras, I., Seung, H.S., Vishwanathan, A., Berger, D.: 3D segmentation
of neurites in EM images challenge - ISBI 2013. http://brainiac2.mit.edu/
SNEMI3D/ (2013) accessed on Feburary 16, 2016.

23. Deerinck, T.J., Bushong, E.A., Lev-Ram, V., Shu, X., Tsien, R.Y., Ellisman, M.H.:
Enhancing serial block-face scanning electron microscopy to enable high resolution
3-D nanohistology of cells and tissues. Microscopy and Microanalysis 16(S2) (2010)
1138–1139

24. Knott, G., Marchman, H., Wall, D., Lich, B.: Serial section scanning electron
microscopy of adult brain tissue using focused ion beam milling. The Journal of
Neuroscience 28(12) (2008) 2959–2964

25. Beucher, S., Meyer, F.: The morphological approach to segmentation: the wa-
tershed transformation. In: Mathematical Morphology in Image Processing. Vol-
ume 34. Marcel Dekker AG (1993) 433–481

26. Schindelin, J., Arganda-Carreras, I., Frise, E., Kaynig, V., Longair, M., Pietzsch,
T., Preibisch, S., Rueden, C., Saalfeld, S., Schmid, B., et al.: Fiji: an open-source
platform for biological-image analysis. Nature methods 9(7) (2012) 676–682

SSHMT: Semi-supervised Hierarchical Merge
Tree for Electron Microscopy Image
Segmentation
Supplementary Materials

Ting Liu1, Miaomiao Zhang2, Mehran Javanmardi1, Nisha Ramesh1, and
Tolga Tasdizen1

1 Scientiﬁc Computing and Imaging Institute, University of Utah, USA
{ting,mehran,nshramesh,tolga}@sci.utah.edu
2 CSAIL, Massachusetts Institute of Technology, USA
miao86@mit.edu

Under the same experiment setting as in Section 4.2, we report the re-
sults from using [9] in Table S1, which considers the merge tree structure as a
constrained conditional model (CCM) and computes globally optimal solutions
based on supervised learning for inference.

Table S1: Means and standard deviations of the adapted Rand errors of CCM
segmentations for (a) the mouse neuropil and (b) the Drosophila melanogaster
larval neuropil data sets. The left table columns show the amount of used ground
truth data, in terms of (a) the number of images and (b) the percentage of all
segments.

(a) Mouse neuropil

(b) Drosophila

CCM

Std.
-

#GT Mean
0.1166
14
0.1238 0.01548
7
0.1278 0.02957
3
0.1412 0.03900
2
1
0.1465 0.03738
0.5 0.1900 0.08586

CCM

Std.
-

#GT Mean
100% 0.05812
50% 0.06612 0.01868
25% 0.08067 0.05281
12.5% 0.08262 0.04714
6.25% 0.08186 0.04463
3.125% 0.09784 0.09035

Comparing Table S1 with Table 1 in Section 4.2, we can see that even though
the supervised CCM improves from HMT, our SSHMT still consistently outper-
forms it with a clear margin. Also, the globally optimal inference algorithm in
CCM can be used in combination with the proposed semi-supervised learning
framework conveniently. We experienced a data loss of the mouse cortex dataset
due to power outage, so we did not experiment on this dataset, but we expect
similar results.

6
1
0
2
 
g
u
A
 
4
1
 
 
]

V
C
.
s
c
[
 
 
1
v
1
5
0
4
0
.
8
0
6
1
:
v
i
X
r
a

SSHMT: Semi-supervised Hierarchical Merge
Tree for Electron Microscopy Image
Segmentation

Ting Liu1, Miaomiao Zhang2, Mehran Javanmardi1, Nisha Ramesh1, and
Tolga Tasdizen1

1 Scientiﬁc Computing and Imaging Institute, University of Utah, USA
{ting,mehran,nshramesh,tolga}@sci.utah.edu
2 CSAIL, Massachusetts Institute of Technology, USA
miao86@mit.edu

Abstract. Region-based methods have proven necessary for improv-
ing segmentation accuracy of neuronal structures in electron microscopy
(EM) images. Most region-based segmentation methods use a scoring
function to determine region merging. Such functions are usually learned
with supervised algorithms that demand considerable ground truth data,
which are costly to collect. We propose a semi-supervised approach that
reduces this demand. Based on a merge tree structure, we develop a dif-
ferentiable unsupervised loss term that enforces consistent predictions
from the learned function. We then propose a Bayesian model that com-
bines the supervised and the unsupervised information for probabilistic
learning. The experimental results on three EM data sets demonstrate
that by using a subset of only 3% to 7% of the entire ground truth data,
our approach consistently performs close to the state-of-the-art super-
vised method with the full labeled data set, and signiﬁcantly outperforms
the supervised method with the same labeled subset.

Keywords: Image segmentation, electron microscopy, semi-supervised
learning, hierarchical segmentation, connectomics

1 Introduction

Connectomics researchers study structures of nervous systems to understand
their function [1]. Electron microscopy (EM) is the only modality capable of
imaging substantial tissue volumes at suﬃcient resolution and has been used for
the reconstruction of neural circuitry [2,3,4]. The high resolution leads to image
data sets at enormous scale, for which manual analysis is extremely laborious
and can take decades to complete [5]. Therefore, reliable automatic connectome
reconstruction from EM images, and as the ﬁrst step, automatic segmentation
of neuronal structures is crucial. However, due to the anisotropic nature, defor-
mation, complex cellular structures and semantic ambiguity of the image data,
automatic segmentation still remains challenging after years of active research.

2

Similar to the boundary detection/region segmentation pipeline for natu-
ral image segmentation [6,7,8,9], most recent EM image segmentation meth-
ods use a membrane detection/cell segmentation pipeline. First, a membrane
detector generates pixel-wise conﬁdence maps of membrane predictions using
local image cues [10,11,12]. Next, region-based methods are applied to trans-
forming the membrane conﬁdence maps into cell segments. It has been shown
that region-based methods are necessary for improving the segmentation ac-
curacy from membrane detections for EM images [13]. A common approach to
region-based segmentation is to transform a membrane conﬁdence map into over-
segmenting superpixels and use them as “building blocks” for ﬁnal segmentation.
To correctly combine superpixels, greedy region agglomeration based on certain
boundary saliency has been shown to work [14]. Meanwhile, structures, such as
loopy graphs [15,16] or trees [17,18,19], are more often imposed to represent the
region merging hierarchy and help transform the superpixel combination search
into graph labeling problems. To this end, local [17,16] or structured [18,19]
learning based methods are developed.

Most current region-based segmentation methods use a scoring function to
determine how likely two adjacent regions should be combined. Such scoring
functions are usually learned in a supervised manner that demands considerable
amount of high-quality ground truth data. Obtaining such ground truth data,
however, involves manual labeling of image pixels and is very labor intensive, es-
pecially given the large scale and complex structures of EM images. To alleviate
this demand, Parag et al. recently propose an active learning framework [20,21]
that starts with small sets of labeled samples and constantly measures the dis-
agreement between a supervised classiﬁer and a semi-supervised label propa-
gation algorithm on unlabeled samples. Only the most disagreed samples are
pushed to users for interactive labeling. The authors demonstrate that by us-
ing 15% to 20% of all labeled samples, the method can perform similar to the
underlying fully supervised method with full training set. One disadvantage of
this framework is that it does not directly explore the unsupervised informa-
tion while searching for the optimal classiﬁcation function. Also, retraining is
required for the supervised algorithm at each iteration, which can be time con-
suming especially when more iterations with fewer samples per iteration are used
to maximize the utilization of supervised information and minimize human ef-
fort. Moreover, repeated human interactions may lead to extra cost overhead in
practice.

In this paper, we propose a semi-supervised learning framework for region-
based neuron segmentation that seeks to reduce the demand for labeled data by
exploiting the underlying correlation between unsupervised data samples. Based
on the merge tree structure [17,18,19], we redeﬁne the labeling constraint and
formulate it into a diﬀerentiable loss function that can be eﬀectively used to guide
the unsupervised search in the function hypothesis space. We then develop a
Bayesian model that incorporates both unsupervised and supervised information
for probabilistic learning. The parameters that are essential to balancing the
learning can be estimated from the data automatically. Our method works with

very small amount of supervised data and requires no further human interaction.
We show that by using only 3% to 7% of the labeled data, our method performs
stably close to the state-of-the-art fully supervised algorithm with the entire
supervised data set (Section 4). Also, our method can be conveniently adopted
to replace the supervised algorithm in the active learning framework [20,21] and
further improve the overall segmentation performance.

3

2 Hierarchical Merge Tree

Starting with an initial superpixel segmentation So of an image, a merge tree
T = (V, E) is a graphical representation of superpixel merging order. Each node
vi ∈ V corresponds to an image region si. Each leaf node aligns with an initial
superpixel in So. A non-leaf node corresponds to an image region combined by
multiple superpixels, and the root node represents the whole image as a single
region. An edge ei,c ∈ E between vi and one of its child vc indicates sc ⊂ si.
Assuming only two regions are merged each time, we have T as a full binary
tree. A clique pi = ({vi, vc1 , vc2}, {ei,c1, ei,c2 }) represents si = sc1 ∪ sc2. In this
paper, we call clique pi is at node vi. We call the cliques pc1 and pc2 at vc1 and
vc2 the child cliques of pi, and pi the parent clique of pc1 and pc2. If vi is a leaf
node, pi = ({vi}, ∅) is called a leaf clique. We call pi a non-leaf/root/non-root
clique if vi is a non-leaf/root/non-root node. An example merge tree, as shown
in Fig. 1c, represents the merging of superpixels in Fig. 1a. The red box in
Fig. 1c shows a non-leaf clique p7 = ({v7, v1, v2}, {e7,1, e7,2}) as the child clique
of p9 = ({v9, v7, v3}, {e9,7, e9,3}). A common approach to building a merge tree
is to greedily merge regions based on certain boundary saliency measurement in
an iterative fashion [17,18,19].

(a)

(b)

(c)

Fig. 1: Example of (a) an initial superpixel segmentation, (b) a consistent ﬁnal
segmentation, and (c) the corresponding merge tree. The red nodes are selected
(z = 1) for the ﬁnal segmentation, and the black nodes are not (z = 0). The red
box shows a clique.

4

Given the merge tree, the problem of ﬁnding a ﬁnal segmentation is equivalent
to ﬁnding a complete label assignment z = {zi}|V|
i=1 for every node being a ﬁnal
segment (z = 1) or not (z = 0). Let ρ(i) be a query function that returns the
index of the parent node of vi. The k-th (k = 1, . . . di) ancestor of vi is denoted as
ρk(i) with di being the depth of vi in the tree, and ρ0(i) = i. For every leaf-to-root
path, we enforce the region consistency constraint that requires (cid:80)di
k=0 zρk(i) = 1
for any leaf node vi. As an example shown in Fig. 1c, the red nodes (v6, v8,
and v9) are labeled z = 1 and correspond to the ﬁnal segmentation in Fig. 1b.
The rest black nodes are labeled z = 0. Supervised algorithms are proposed to
learn scoring functions in a local [17,9] or a structured [18,19] fashion, followed
by greedy [17] or global [18,9,19] inference techniques for ﬁnding the optimal
label assignment under the constraint. We refer to the local learning and greedy
search inference framework in [17] as the hierarchical merge tree (HMT) method
and follow its settings in the rest of this paper, as it has been shown to achieve
state-of-the-art results in the public challenges [13,22].

A binary label yi is used to denote whether the region merging at clique pi
occurs (“merge”, yi = 1) or not (“split”, yi = 0). For a leaf clique, y = 1. At
training time, y = {yi}|V|
i=1 is generated by comparing both the “merge” and
“split” cases for non-leaf cliques against the ground truth segmentation under
certain error metric (e.g. adapted Rand error [13]). The one that causes the lower
error is adopted. A binary classiﬁcation function called the boundary classiﬁer is
trained with (X, y), where X = {xi}|V|
i=1 is a collection of feature vectors. Shape
and image appearance features are commonly used.

At testing time, each non-leaf clique pi is assigned a likelihood score P (yi|xi)

by the classiﬁer. A potential for each node vi is deﬁned as

ui = P (yi = 1|xi) · P (yρ(i) = 0|xρ(i)).

(1)

The greedy inference algorithm iteratively assigns z = 1 to an unlabeled node
with the highest potential and z = 0 to its ancestor and descendant nodes until
every node in the merge tree receives a label. The nodes with z = 1 forms a ﬁnal
segmentation.

Note that HMT is not limited to segmenting images of any speciﬁc dimen-
sionality. In practice, it has been successfully applied to both 2D [17,13] and 3D
segmentation [22] of EM images.

3 SSHMT: Semi-supervised Hierarchical Merge Tree

The performance of HMT largely depends on accurate boundary predictions
given ﬁxed initial superpixels and tree structures. In this section, we propose
a semi-supervised learning based HMT framework, named SSHMT, to learn
accurate boundary classiﬁers with limited supervised data.

5

(2)

3.1 Merge consistency constraint

Following the HMT notation (Section 2), we ﬁrst deﬁne the merge consistency
constraint for non-root cliques:

yi ≥ yρ(i), ∀i.

Clearly, a set of consistent node labeling z can be transformed to a consistent y
by assigning y = 1 to the cliques at the nodes with z = 1 and their descendant
cliques and y = 0 to the rest. A consistent y can be transformed to z by assigning
z = 1 to the nodes in {vi ∈ V|∀i, s.t. yi = 1 ∧ (vi is the root ∨ yρ(i) = 0)} and
z = 0 to the rest, vice versa.

Deﬁne a clique path of length L that starts at pi as an ordered set πL

i =

{pρl(i)}L−1

l=0 . We then have

i = {yρl(i)}L−1
Theorem 1. Any consistent label sequence yL
merge consistency constraint is monotonically non-increasing.

l=0 for πL

i under the

Proof. Assume there exists a label sequence yL
i subject to the merge consistency
constraint that is not monotonically non-increasing. By deﬁnition, there must
exist k ≥ 0, s.t. yρk(i) < yρk+1(i). Let j = ρk(i), then ρk+1(i) = ρ(j), and thus
yj < yρ(j). This violates the merge consistency constraint (2), which contradicts
the initial assumption that yL
is subject to the merge consistency constraint.
i
Therefore, the initial assumption must be false, and all label sequences that
are subject to the merge consistency constraint must be monotonically non-
(cid:117)(cid:116)
increasing.

Intuitively, Theorem 1 states that while moving up in a merge tree, once a
split occurs, no merge shall occur again among the ancestor cliques in that path.
As an example, a consistent label sequence for the clique path {p7, p9, p11} in
Fig. 1c can only be {y7, y9, y11} = {0, 0, 0}, {1, 0, 0}, {1, 1, 0}, or {1, 1, 1}. Any
other label sequence, such as {1, 0, 1}, is not consistent. In contrast to the region
consistency constraint, the merge consistency constraint is a local constraint that
holds for the entire leaf-to-root clique paths as well as any of their subparts. This
allows certain computations to be decomposed as shown later in Section 4.

Let fi be a predicate that denotes whether yi = 1. We can express the non-
in disjunctive

increasing monotonicity of any consistent label sequence for πL
i
normal form (DNF) as

F L

i =

L
(cid:95)

j−1
(cid:94)





j=0

k=0

L−1
(cid:94)

k=j



fρk(i) ∧

¬fρk(i)

 ,

(3)

which always holds true by Theorem 1. We approximate F L
i with real-valued
variables and operators by replacing true with 1, f alse with 0, and f with
real-valued ˜f . A negation ¬f is replaced by 1 − ˜f ; conjunctions are replaced
by multiplications; disjunctions are transformed into negations of conjunctions

6

using De Morgan’s laws and then replaced. The real-valued DNF approximation
is

˜F L

i = 1 −



1 −

L
(cid:89)

j=0

j−1
(cid:89)

k=0

˜fρk(i) ·

1 − ˜fρk(i)

L−1
(cid:89)

(cid:16)

k=j

(cid:17)



 ,

which is valued 1 for any consistent label assignments. Observing ˜f is exactly
a binary boundary classiﬁer in HMT, we further relax it to be a classiﬁcation
function that predicts P (y = 1|x) ∈ [0, 1]. The choice of ˜f can be arbitrary
as long as it is (piecewise) diﬀerentiable (Section 3.2). In this paper, we use a
logistic sigmoid function with a linear discriminant

(4)

(5)

˜f (x; w) =

1
1 + exp(−w(cid:62)x)

,

which is parameterized by w.

We would like to ﬁnd an ˜f so that its predictions satisfy the DNF (4) for
any path in a merge tree. We will introduce the learning of such ˜f in a semi-
supervised manner in Section 3.2.

3.2 Bayesian semi-supervised learning

To learn the boundary classiﬁcation function ˜f , we use both supervised and
unsupervised data. Supervised data are the clique samples with labels that are
generated from ground truth segmentations. Unsupervised samples are those
we do not have labels for. They can be from the images that we do not have
the ground truth for or wish to segment. We use Xs to denote the collection of
supervised sample feature vectors and ys for their true labels. X is the collection
of all supervised and unsupervised samples.

Let ˜f w = [ ˜fj1, . . . , ˜fjNs

](cid:62) be the predictions about the supervised samples
in Xs, and ˜F w = [ ˜F L
](cid:62) be the DNF values (4) for all paths from X.
i1
We are now ready to build a probabilistic model that includes a regularization
prior, an unsupervised likelihood, and a supervised likelihood.

, . . . , ˜F L
iNu

The prior is an i.i.d. Gaussian N (0, 1) that regularizes w to prevent overﬁt-
ting. The unsupervised likelihood is an i.i.d. Gaussian N (0, σu) on the diﬀerences
between each element of ˜F w and 1. It requires the predictions of ˜f to conform
the merge consistency constraint for every path. Maximizing the unsupervised
likelihood allows us to narrow down the potential solutions to a subset in the
classiﬁer hypothesis space without label information by exploring the sample
feature representation commonality. The supervised likelihood is an i.i.d. Gaus-
sian N (0, σs) on the prediction errors for supervised samples to enforce accurate
predictions. It helps avoid consistent but trivial solutions of ˜f , such as the ones
that always predict y = 1 or y = 0, and guides the search towards the correct
solution. The standard deviation parameters σu and σs control the contributions
of the three terms. They can be preset to reﬂect our prior knowledge about the
model distributions, tuned using a holdout set, or estimated from data.

7

(6)

(7)

(9)

By applying Bayes’ rule, we have the posterior distribution of w as

P (w | X, Xs, ys, σu, σs) ∝ P (w) · P (1 | X, w, σu) · P (ys | Xs, w, σs)

(cid:18)

∝ exp

−

(cid:19)

(cid:107)w(cid:107)2
2
2

·

·

1

1

(cid:0)√

(cid:1)Nu

2πσu

exp

−

(cid:0)√

(cid:1)Ns

2πσs

exp

−

(cid:32)

(cid:32)

(cid:33)

(cid:107)1 − ˜F w(cid:107)2
2
2σ2
u

(cid:107)ys − ˜f w(cid:107)2
2σ2
s

2

(cid:33)

,

where Nu and Ns are the number of elements in ˜F w and ˜f w, respectively; 1 is
a Nu-dimensional vector of ones.

Inference We infer the model parameters w, σu, and σs using maximum a
posteriori estimation. We eﬀectively minimize the negative logarithm of the pos-
terior

J(w, σu, σs) =

(cid:107)w(cid:107)2

2 +

(cid:107)1 − ˜F w(cid:107)2

2 + Nu log σu

1
2σ2
u

1
2

+

1
2σ2
s

(cid:107)ys − ˜f w(cid:107)2

2 + Ns log σs.

Observe that the DNF formula in (4) is diﬀerentiable. With any (piecewise)
diﬀerentiable choice of ˜fw, we can minimize (7) using (sub-) gradient descent.
The gradient of (7) with respect to the classiﬁer parameter w is

∇wJ = w(cid:62) −

(cid:17)(cid:62)

1 − ˜F w

∇w ˜F w −

(cid:17)(cid:62)

ys − ˜f w

∇w ˜f w,

(8)

(cid:16)

1
σ2
u

(cid:16)

1
σ2
s

Since we choose ˜f to be a logistic sigmoid function with a linear discrimi-

nant (5), the j-th (j = 1, . . . , Ns) row of ∇w ˜f w is
˜fj = ˜fj(1 − ˜fj) · x(cid:62)
j .

∇w

where xj is the j-th element in Xs.
˜fρk(i) · (cid:81)L−1

Deﬁne gj = (cid:81)j−1

k=j (1 − ˜fρk(i)), j = 0, . . . , L, we write (4) as
j=0(1 − gj) as the i-th (i = 1, . . . , Nu) element of ˜F w. Then the i-th

k=0

i = 1 − (cid:81)L
˜F L
row of ∇w ˜F w is

∇w ˜F L

i =




gj

L
(cid:88)

j=0

L
(cid:89)

k=0
k(cid:54)=j










(1 − gk)

j−1
(cid:88)

∇w

˜fρk(i)

˜fρk(i)

k=0

−

L−1
(cid:88)

k=j

˜fρk(i)
∇w
1 − ˜fρk(i)



 ,

(10)

where ∇w

˜fρk(i) can be computed using (9).

8

We also alternately estimate σu and σs along with w. Setting ∇σu J = 0 and

∇σsJ = 0, we update σu and σs using the closed-form solutions

σu =

σs =

(cid:107)1 − ˜F w(cid:107)2
√
Nu
(cid:107)ys − ˜f w(cid:107)2
√
Ns

.

(11)

(12)

At testing time, we apply the learned ˜f to testing samples to predict their
merging likelihood. Eventually, we compute the node potentials with (1) and
apply the greedy inference algorithm to acquire the ﬁnal node label assignment
(Section 2).

We validate the proposed algorithm for 2D and 3D segmentation of neurons in
three EM image data sets. For each data set, we apply SSHMT to the same seg-
mentation tasks using diﬀerent amounts of randomly selected subsets of ground
truth data as the supervised sets.

4 Results

4.1 Data sets

Mouse neuropil data set [23] consists of 70 2D SBFSEM images of size
700 × 700 × 700 at 10 × 10 × 50 nm/pixel resolution. A random selection of 14
images are considered as the whole supervised set, and the rest 56 images are
used for testing. We test our algorithm using 14 (100%), 7 (50%), 3 (21.42%), 2
(14.29%), 1 (7.143%), and half (3.571%) ground truth image(s) as the supervised
data. We use all the 70 images as the unsupervised data for training. We target
at 2D segmentation for this data set.

Mouse cortex data set [22] is the original training set for the ISBI SNEMI3D
Challenge [22]. It is a 1024×1024×100 SSSEM image stack at 6×6×30 nm/pixel
resolution. We use the ﬁrst 1024 × 1024 × 50 substack as the supervised set and
the second 1024 × 1024 × 50 substack for testing. There are 327 ground truth
neuron segments that are larger than 1000 pixels in the supervised substack,
which we consider as all the available supervised data. We test the performance
of our algorithm by using 327 (100%), 163 (49.85%), 81 (24.77%), 40 (12.23%), 20
(6.116%), 10 (3.058%), and 5 (1.529%) true segments. Both the supervised and
the testing substack are used for the unsupervised term. Due to the unavailability
of the ground truth data, we did not experiment with the original testing image
stack from the challenge. We target at 3D segmentation for this data set.

9

Drosophila melanogaster larval neuropil data set [24] is a 500 × 500 × 500
FIBSEM image volume at 10 × 10 × 10 nm/pixel resolution. We divide the whole
volume evenly into eight 250 × 250 × 250 subvolumes and do eight-fold cross
validation using one subvolume each time as the supervised set and the whole
volume as the testing data. Each subvolume has from 204 to 260 ground truth
neuron segments that are larger than 100 pixels. Following the setting in the
mouse cortex data set experiment, we use subsets of 100%, 50%, 25%, 12.5%,
6.25%, and 3.125% of all true neuron segments from the respective supervised
subvolume in each fold of the cross validation as the supervised data to generate
boundary classiﬁcation labels. We use the entire volume to generate unsupervised
samples. We target at 3D segmentation for this data set.

4.2 Experiments

We use fully trained Cascaded Hierarchical Models [12] to generate membrane
detection conﬁdence maps and keep them ﬁxed for the HMT and SSHMT exper-
iments on each data set, respectively. To generate initial superpixels, we use the
watershed algorithm [25] over the membrane conﬁdence maps. For the boundary
classiﬁcation, we use features including shape information (region size, perime-
ter, bounding box, boundary length, etc.) and image intensity statistics (mean,
standard deviation, minimum, maximum, etc.) of region interior and boundary
pixels from both the original EM images and membrane detection conﬁdence
maps.

We use the adapted Rand error metric [13] to generate boundary classiﬁ-
cation labels using whole ground truth images (Section 2) for the 2D mouse
neuropil data set. For the 3D mouse cortex and Drosophila melanogaster lar-
val neuropil data sets, we determine the labels using individual ground truth
segments instead. We use this setting in order to match the actual process of
analyzing EM images by neuroscientists. Details about label generation using
individual ground truth segments are provided in Appendix A.

We can see in (4) and (10) that computing ˜F L

i and its gradient involves
multiplications of L ﬂoating point numbers, which can cause underﬂow problems
for leaf-to-root clique paths in a merge tree of even moderate height. To avoid
this problem, we exploit the local property of the merge consistency constraint
and compute ˜F L
for every path subpart of small length L. In this paper, we
i
use L = 3 for all experiments. For inference, we initialize w by running gradient
descent on (7) with only the supervised term and the regularizer before adding
the unsupervised term for the whole optimization. We update σu and σs in
between every 100 gradient descent steps on w.

We compare SSHMT with the fully supervised HMT [17] as the baseline
method. To make the comparison fair, we use the same logistic sigmoid func-
tion as the boundary classiﬁer for both HMT and SSHMT. The fully supervised
training uses the same Bayesian framework only without the unsupervised term
in (7) and alternately estimates σs to balance the regularization term and the su-
pervised term. All the hyperparameters are kept identical for HMT and SSHMT
and ﬁxed for all experiments. We use the adapted Rand error [13] following the

10

public EM image segmentation challenges [13,22]. Due to the randomness in
the selection of supervised data, we repeat each experiment 50 times, except in
the cases that there are fewer possible combinations. We report the mean and
standard deviation of errors for each set of repeats on the three data sets in
Table ??. For the 2D mouse neuropil data set, we also threshold the membrane
detection conﬁdence maps at the optimal level, and the adapted Rand error is
0.2023. Since the membrane detection conﬁdence maps are generated in 2D, we
do not measure the thresholding errors of the other 3D data sets. In addition,
we report the results from using the globally optimal tree inference [9] in the
supplementary materials for comparison.

Examples of 2D segmentation testing results from the mouse neuropil data
set using fully supervised HMT and SSHMT with 1 (7.143%) ground truth im-
age as supervised data are shown in Fig. 2. Examples of 3D individual neuron
segmentation testing results from the Drosophila melanogaster larval neuropil
data set using fully supervised HMT and SSHMT with 12 (6.25%) true neuron
segments as supervised data are shown in Fig. 3.

From Table ??, we can see that with abundant supervised data, the perfor-
mance of SSHMT is similar to HMT in terms of segmentation accuracy, and both
of them signiﬁcantly improve from optimally thresholding (Table 0a). When the
amount of supervised data becomes smaller, SSHMT signiﬁcantly outperforms
the fully supervised method with the accuracy close to the HMT results using
the full supervised sets. Moreover, the introduction of the unsupervised term
stabilizes the learning of the classiﬁcation function and results in much more
consistent segmentation performance, even when only very limited (3% to 7%)
label data are available. Increases in errors and large variations are observed in
the SSHMT results when the supervised data become too scarce. This is be-
cause the few supervised samples are incapable of providing suﬃcient guidance
to balance the unsupervised term, and the boundary classiﬁers are biased to give
trivial predictions.

Fig. 2 shows that SSHMT is capable of ﬁxing both over- and under-segmentation

errors that occur in the HMT results. Fig. 3 also shows that SSHMT can ﬁx over-
segmentation errors and generate highly accurate neuron segmentations. Note
that in our experiments, we always randomly select the supervised data subsets.
For realistic uses, we expect supervised samples of better representativeness to be
provided with expertise and the performance of SSHMT to be further improved.

We also conducted an experiment with the mouse neuropil data set in which
we use only 1 ground truth image to train the membrane detector, HMT, and
SSHMT to test a fully semi-supervised EM segmentation pipeline. We repeat 14
times for every ground truth image in the supervised set. The optimal thresh-
olding gives adapted Rand error 0.3603 ± 0.06827. The error of the HMT results
is 0.2904 ± 0.09303, and the error of the SSHMT results is 0.2373 ± 0.06827. De-
spite the increase of error, which is mainly due to the fully supervised nature of
the membrane detection algorithm, SSHMT again improves the region accuracy
from optimal thresholding and has a clear advantage over HMT.

11

Table 1: Means and standard deviations of the adapted Rand errors of HMT and
SSHMT segmentations for the three EM data sets. The left table columns show
the amount of used ground truth data, in terms of (a) the number of images, (b)
the number of segments, and (c) the percentage of all segments. Bold numbers in
the tables show the results of the higher accuracy under comparison. The ﬁgures
on the right visualize the means (dashed lines) and the standard deviations (solid
bars) of the errors of HMT (red) and SSHMT (blue) results for each data set.

(a) Mouse neuropil

HMT

SSHMT

Std. Mean
0.1196

-

Std.
-

#GT Mean
14 0.1135
7
3
2
1
0.5

0.1382 0.03238 0.1208 0.004033
0.1492 0.04851 0.1205 0.001383
0.1811 0.07346 0.1217 0.004116
0.2035 0.1029 0.1210 0.002206
0.2505 0.1062 0.1365 0.1079

Optimal thresholding: 0.2023

(b) Mouse cortex

HMT

SSHMT

-

Std.
-

Std. Mean
0.1104

#GT Mean
327 0.1101
163 0.1344 0.03660 0.1189 0.01506
0.1583 0.06909 0.1215 0.01661
81
0.1844 0.1019 0.1198 0.01690
40
0.2205 0.1226 0.1238 0.01466
20
0.2503 0.1561 0.1219 0.01273
10
0.4389 0.2769 0.2008 0.2285
5

(c) Drosophila melanogaster larval neuropil

HMT

SSHMT

-

0.05504

Std.
-

Std. Mean

%GT Mean
100% 0.06044
50% 0.09004 0.04476 0.05602 0.005550
25% 0.1240 0.07491 0.05803 0.007703
12.5% 0.1418 0.1055 0.05835 0.007797
6.25% 0.1748 0.1389 0.05756 0.008933
3.125% 0.2017 0.1871 0.06213 0.03660

12

(a) Original

(b) HMT

(c) SSHMT

(d) Ground truth

Fig. 2: Examples of the 2D segmentation testing results for the mouse neuropil
data set, including (a) original EM images, (b) HMT and (c) SSHMT results
using 1 ground truth image as supervised data, and (d) the corresponding ground
truth images. Diﬀerent colors indicate diﬀerent individual segments.

13

(a) HMT

(b) SSHMT

(c) Ground truth

Fig. 3: Examples of individual neurons from the 3D segmentation testing results
for the Drosophila melanogaster larval neuropil data set, including (a) HMT and
(b) SSHMT results using 12 (6.25%) 3D ground truth segments as supervised
data, and (c) the corresponding ground truth segments. Diﬀerent colors indicate
diﬀerent individual segments. The 3D visualizations are generated using Fiji [26].

14

We have open-sourced our code at https://github.com/tingliu/glia. It
takes approximately 80 seconds for our SSHMT implementation to train and
test on the whole mouse neuropil data set using 50 2.5 GHz Intel Xeon CPUs
and about 150 MB memory.

5 Conclusion

In this paper, we proposed a semi-supervised method that can consistently learn
boundary classiﬁers with very limited amount of supervised data for region-based
image segmentation. This dramatically reduces the high demands for ground
truth data by fully supervised algorithms. We applied our method to neuron
segmentation in EM images from three data sets and demonstrated that by us-
ing only a small amount of ground truth data, our method performed close to
the state-of-the-art fully supervised method with full labeled data sets. In our
future work, we will explore the integration of the proposed constraint based un-
supervised loss in structural learning settings to further exploit the structured
information for learning the boundary classiﬁcation function. Also, we may re-
place the current logistic sigmoid function with more complex classiﬁers and
combine our method with active learning frameworks to improve segmentation
accuracy.

Acknowledgment This work was supported by NSF IIS-1149299 and NIH
1R01NS075314-01. We thank the National Center for Microscopy and Imaging
Research at the University of California, San Diego, for providing the mouse
neuropil data set. We also thank Mehdi Sajjadi at the University of Utah for the
constructive discussions.

A Appendix: Generating Boundary Classiﬁcation Labels

Using Individual Ground Truth Segments

Assume we only have individual annotated image segments instead of entire
image volumes as ground truth. Given a merge tree, we generate the best-eﬀort
ground truth classiﬁcation labels for a subset of cliques as follows:

1. For every region represented by a tree node, compute the Jaccard indices of
this region against all the annotated ground truth segments. Use the highest
Jaccard index of each node as its eligible score.

2. Mark every node in the tree as “eligible” if its eligible score is above certain

threshold (0.75 in practice) or “ineligible” otherwise.

3. Iteratively select a currently “eligible” node with the highest eligible score;
mark it and its ancestors and descendants as “ineligible”, until every node
is “ineligible”. This procedure generates a set of selected nodes.

4. For every selected node, label the cliques at itself and its descendants as

y = 1 (“merge”) and the cliques at its ancestors as y = 0 (“split”).

Eventually, the clique samples that receive merge/split labels are considered

as the supervised data.

15

References

1. Sporns, O., Tononi, G., K¨otter, R.: The human connectome: a structural descrip-

tion of the human brain. PLoS Computational Biology 1(4) (2005) e42

2. Famiglietti, E.V.: Synaptic organization of starburst amacrine cells in rabbit retina:
analysis of serial thin sections by electron microscopy and graphic reconstruction.
Journal of Comparative Neurology 309(1) (1991) 40–70

3. Briggman, K.L., Helmstaedter, M., Denk, W.: Wiring speciﬁcity in the direction-

selectivity circuit of the retina. Nature 471(7337) (2011) 183–188

4. Helmstaedter, M.: Cellular-resolution connectomics: challenges of dense neural

circuit reconstruction. Nature Methods 10(6) (2013) 501–507

5. Briggman, K.L., Denk, W.: Towards neural circuit reconstruction with volume
electron microscopy techniques. Current Opinion in Neurobiology 16(5) (2006)
562–570

6. Arbelaez, P., Maire, M., Fowlkes, C., Malik, J.: Contour detection and hierarchical
image segmentation. Pattern Analysis and Machine Intelligence, IEEE Transac-
tions on 33(5) (2011) 898–916

7. Ren, Z., Shakhnarovich, G.: Image segmentation by cascaded region agglomera-
tion. In: Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition. (2013) 2011–2018

8. Arbel´aez, P., Pont-Tuset, J., Barron, J., Marques, F., Malik, J.: Multiscale com-
binatorial grouping. In: Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition. (2014) 328–335

9. Liu, T., Seyedhosseini, M., Tasdizen, T.: Image segmentation using hierarchical
merge tree. Image Processing, IEEE Transactions on 25(10) (2016) 4596–4607
10. Sommer, C., Straehle, C., Koethe, U., Hamprecht, F.A.: ilastik: Interactive learning
In: Biomedical Imaging: From Nano to Macro, 2011

and segmentation toolkit.
IEEE International Symposium on, IEEE (2011) 230–233

11. Ciresan, D., Giusti, A., Gambardella, L.M., Schmidhuber, J.: Deep neural net-
works segment neuronal membranes in electron microscopy images. In: Advances
in Neural Information Processing Systems 25. (2012) 2852–2860

12. Seyedhosseini, M., Sajjadi, M., Tasdizen, T.: Image segmentation with cascaded
hierarchical models and logistic disjunctive normal networks. In: Proceedings of
the IEEE International Conference on Computer Vision. (2013) 2168–2175

13. Arganda-Carreras, I., Turaga, S.C., Berger, D.R., Cire¸san, D., Giusti, A., Gam-
bardella, L.M., Schmidhuber, J., Laptev, D., Dwivedi, S., Buhmann, J.M., et al.:
Crowdsourcing the creation of image segmentation algorithms for connectomics.
Frontiers in Neuroanatomy 9 (2015)

14. Nunez-Iglesias, J., Kennedy, R., Parag, T., Shi, J., Chklovskii, D.B.: Machine
learning of hierarchical clustering to segment 2D and 3D images. PLoS ONE 8(8)
(2013) e71715

15. Kaynig, V., Vazquez-Reina, A., Knowles-Barley, S., Roberts, M., Jones, T.R.,
Kasthuri, N., Miller, E., Lichtman, J., Pﬁster, H.: Large-scale automatic recon-
struction of neuronal processes from electron microscopy images. Medical Image
Analysis 22(1) (2015) 77–88

16. Krasowski, N., Beier, T., Knott, G., Koethe, U., Hamprecht, F., Kreshuk, A.:
Improving 3D EM data segmentation by joint optimization over boundary evidence
and biological priors. In: Biomedical Imaging (ISBI), 2015 IEEE 12th International
Symposium on, IEEE (2015) 536–539

16

17. Liu, T., Jones, C., Seyedhosseini, M., Tasdizen, T.: A modular hierarchical ap-
proach to 3D electron microscopy image segmentation. Journal of Neuroscience
Methods 226 (2014) 88–102

18. Funke, J., Hamprecht, F.A., Zhang, C.: Learning to segment: Training hierar-
chical segmentation under a topological loss. In: Medical Image Computing and
Computer-Assisted Intervention–MICCAI 2015. Springer (2015) 268–275

19. Uzunbas, M.G., Chen, C., Metaxas, D.: An eﬃcient conditional random ﬁeld ap-
proach for automatic and interactive neuron segmentation. Medical Image Analysis
27 (2016) 31–44

20. Parag, T., Plaza, S., Scheﬀer, L.: Small sample learning of superpixel classi-
ﬁers for em segmentation. In: Medical Image Computing and Computer-Assisted
Intervention–MICCAI 2014. Springer (2014) 389–397

21. Parag, T., Ciresan, D.C., Giusti, A.: Eﬃcient classiﬁer training to minimize false
merges in electron microscopy segmentation. In: Proceedings of the IEEE Inter-
national Conference on Computer Vision. (2015) 657–665

22. Arganda-Carreras, I., Seung, H.S., Vishwanathan, A., Berger, D.: 3D segmentation
of neurites in EM images challenge - ISBI 2013. http://brainiac2.mit.edu/
SNEMI3D/ (2013) accessed on Feburary 16, 2016.

23. Deerinck, T.J., Bushong, E.A., Lev-Ram, V., Shu, X., Tsien, R.Y., Ellisman, M.H.:
Enhancing serial block-face scanning electron microscopy to enable high resolution
3-D nanohistology of cells and tissues. Microscopy and Microanalysis 16(S2) (2010)
1138–1139

24. Knott, G., Marchman, H., Wall, D., Lich, B.: Serial section scanning electron
microscopy of adult brain tissue using focused ion beam milling. The Journal of
Neuroscience 28(12) (2008) 2959–2964

25. Beucher, S., Meyer, F.: The morphological approach to segmentation: the wa-
tershed transformation. In: Mathematical Morphology in Image Processing. Vol-
ume 34. Marcel Dekker AG (1993) 433–481

26. Schindelin, J., Arganda-Carreras, I., Frise, E., Kaynig, V., Longair, M., Pietzsch,
T., Preibisch, S., Rueden, C., Saalfeld, S., Schmid, B., et al.: Fiji: an open-source
platform for biological-image analysis. Nature methods 9(7) (2012) 676–682

SSHMT: Semi-supervised Hierarchical Merge
Tree for Electron Microscopy Image
Segmentation
Supplementary Materials

Ting Liu1, Miaomiao Zhang2, Mehran Javanmardi1, Nisha Ramesh1, and
Tolga Tasdizen1

1 Scientiﬁc Computing and Imaging Institute, University of Utah, USA
{ting,mehran,nshramesh,tolga}@sci.utah.edu
2 CSAIL, Massachusetts Institute of Technology, USA
miao86@mit.edu

Under the same experiment setting as in Section 4.2, we report the re-
sults from using [9] in Table S1, which considers the merge tree structure as a
constrained conditional model (CCM) and computes globally optimal solutions
based on supervised learning for inference.

Table S1: Means and standard deviations of the adapted Rand errors of CCM
segmentations for (a) the mouse neuropil and (b) the Drosophila melanogaster
larval neuropil data sets. The left table columns show the amount of used ground
truth data, in terms of (a) the number of images and (b) the percentage of all
segments.

(a) Mouse neuropil

(b) Drosophila

CCM

Std.
-

#GT Mean
0.1166
14
0.1238 0.01548
7
0.1278 0.02957
3
0.1412 0.03900
2
1
0.1465 0.03738
0.5 0.1900 0.08586

CCM

Std.
-

#GT Mean
100% 0.05812
50% 0.06612 0.01868
25% 0.08067 0.05281
12.5% 0.08262 0.04714
6.25% 0.08186 0.04463
3.125% 0.09784 0.09035

Comparing Table S1 with Table 1 in Section 4.2, we can see that even though
the supervised CCM improves from HMT, our SSHMT still consistently outper-
forms it with a clear margin. Also, the globally optimal inference algorithm in
CCM can be used in combination with the proposed semi-supervised learning
framework conveniently. We experienced a data loss of the mouse cortex dataset
due to power outage, so we did not experiment on this dataset, but we expect
similar results.

