HoMM: Higher-order Moment Matching for Unsupervised Domain Adaptation

Chao Chen1,2∗, Zhihang Fu2, Zhihong Chen1, Sheng Jin2,
Zhaowei Cheng1, Xinyu Jin1, Xian-Sheng Hua2†

1 Zhejiang University,

2 Alibaba DAMO Academy, Alibaba Group

chench@zju.edu.cn, xiansheng.hxs@alibaba-inc.com

9
1
0
2
 
c
e
D
 
7
2
 
 
]

V
C
.
s
c
[
 
 
1
v
6
7
9
1
1
.
2
1
9
1
:
v
i
X
r
a

Abstract

Minimizing the discrepancy of feature distributions be-
tween different domains is one of
the most promising
From
directions in unsupervised domain adaptation.
the perspective of distribution matching, most existing
discrepancy-based methods are designed to match the
second-order or lower statistics, which however, have
limited expression of statistical characteristic for non-
Gaussian distributions. In this work, we explore the beneﬁts
of using higher-order statistics (mainly refer to third-order
and fourth-order statistics) for domain matching. We pro-
pose a Higher-order Moment Matching (HoMM) method,
and further extend the HoMM into reproducing kernel
Hilbert spaces (RKHS). In particular, our proposed HoMM
can perform arbitrary-order moment tensor matching, we
show that the ﬁrst-order HoMM is equivalent to Maximum
Mean Discrepancy (MMD) and the second-order HoMM
is equivalent to Correlation Alignment (CORAL). More-
over, the third-order and the fourth-order moment tensor
matching are expected to perform comprehensive domain
alignment as higher-order statistics can approximate more
complex, non-Gaussian distributions. Besides, we also ex-
ploit the pseudo-labeled target samples to learn discrimi-
native representations in the target domain, which further
improves the transfer performance. Extensive experiments
are conducted, showing that our proposed HoMM con-
sistently outperforms the existing moment matching meth-
ods by a large margin. Codes are available at https:
//github.com/chenchao666/HoMM-Master

1. Introduction

Convolutional neural networks (CNNs) have shown
promising results on supervised learning tasks. How-
ever, the performance of a learned model always degrades

∗This work was done as a research intern in Alibaba Group. This work
is supported by the opening foundation of the State Key Laboratory (No.
2014KF06) and CSC Scholarship.

†This is the corresponding author.

Figure 1: The metrics of using higher-order moment tensor
for domain alignment. 300 points in R2 and the level set of
the moment tensor with different order. As observed, using
higher-order moment tenser captures the shape of the cloud
of samples more accurately.

severely when dealing with data from the other domains.
Considering that constantly annotating massive samples
from new domains is expensive and impractical, unsuper-
vised domain adaptation (UDA), therefore, has emerged as
a new learning framework to address this problem [7]. UDA
aims to utilize full-labeled samples in source domain to
annotate the completely-unlabeled target domain samples.
Thanks to deep CNNs, recent advances in UDA show satis-
factory performance in several computer vision tasks [15].
Among them, most methods bridge the source and target
domain by learning domain-invariant features. These domi-
nant methods can be further divided into two categories: (1)
Learning domain-invariant features by minimizing the dis-
crepancy between feature distributions [25, 36, 26, 46, 4].
(2) Encouraging domain confusion by a domain adversar-
ial objectives whereby a discriminator (domain classiﬁer) is
trained to distinguish between the source and target repre-
sentations. [10, 37, 34, 15].

From the perspective of moment matching, most of the
existing discrepancy-based methods in UDA are based on
Maximum Mean Discrepancy (MMD) [26] or Correlation
Alignment (CORAL) [36], which are designed to match the
ﬁrst-order (Mean) and second-order (Covariance) statistics
of different distributions. However, for the real world ap-
plications (such as image recognition), the deep features
are always a complex, non-Gaussian distribution [17, 44],
which can not be completely characterized by its ﬁrst-order
or second-order statistics. Therefore, aligning the second-

4321

order or lower statistics only guarantees coarse-grained
alignment of two distributions. To address this limitation,
we propose to perform domain alignment by matching the
higher-order moment tensor (mainly refer to third-order and
fourth-order moment tensor), which contain more discrimi-
native information and can better represent the feature dis-
tribution [30, 12]. Inspired by [30], Fig.1 illustrates the met-
rics of higher-order moment tensor, where we plot a cloud
of points (consists of three different Gaussians) and the level
sets of moment tensor with different order. As observed,
the higher-order moment tensor characterizes the distribu-
tion more accurately.

Our contribution can be concluded as: (1) We propose a
Higher-order Moment Matching (HoMM) method to mini-
mize the domain discrepancy, which is expected to perform
ﬁne-grained domain alignment. The HoMM integrates the
MMD and CORAL into a uniﬁed framework and general-
izes the ﬁrst-order and second-order moment matching to
higher-order moment tensor matching. Without bells and
whistles, the third- and fourth-order moment matching out-
perform all existing discrepancy-based methods by a large
margin. The source code of the HoMM is released. (2) Due
to lack of labels in the target domain, we propose to learn
discriminative clusters in the target domain by assigning the
pseudo-labels for the reliable target samples, which also im-
proves the transfer performance.

2. Related Work

Learning Domain-Invariant Features To minimize the
domain discrepancy and learn domain-invariant features,
various distribution discrepancy metrics have been intro-
duced. The representative ones include Maximal Mean Dis-
crepancy (MMD) [14, 38, 25, 26], Correlation Alignment
[36, 28, 3, 5] and Wasserstein distance [20, 6]. MMD was
ﬁrst introduced for the two-sample tests problem [14], and
is currently the most widely used metric to measure the dis-
tance between two feature distributions. Speciﬁcally, Long
et al. proposed DAN [25] and JAN [26] which perform
domain matching via multi-kernel MMD or a joint MMD
criteria in multiple domain-speciﬁc layers across domains.
Sun et al. proposed the correlation alignment (CORAL)
[35, 36] to align the second order statistics of the source
and target distributions. Some recent work also extended
the CORAL into reproducing kernel Hilbert spaces (RKHS)
[47] or deployed alignment along geodesics by considering
the log-Euclidean distance [28]. Interestingly, [23] theoret-
ically demonstrated that matching the second order statis-
tics is equivalent to minimizing MMD with the second or-
der polynomial kernel. Besides, the approach most rele-
vant to our proposal is the Central Moment Discrepancy
(CMD) [46], which matches the higher order central mo-
ments of probability distributions by means of order-wise
moment differences. Both CMD and our HoMM propose

to match the higher-order statistics for domain alignment.
The CMD matches the higher-order central moment while
our HoMM matches the higher-order cumulant tensor. An-
other fruitful line of work tries to learn the domain-invariant
features through adversarial training [10, 37]. These efforts
encourage domain confusion by a domain adversarial objec-
tive whereby a discriminator (domain classiﬁer) is trained to
distinguish between the source and target representations.
Also, recent work performing pixel-level adaptation by
image-to-image transformation [29, 15] has achieved sat-
isfactory performance and obtained much attention. In this
work, we propose a higher-order moment tensor matching
approach to minimize the domain discrepancy, which shows
great superiority over existing discrepancy-based methods.

Higher-order Statistics The statistics higher than ﬁrst-
order has been success fully used in many classical and deep
learning methods [9, 19, 30, 22, 12]. Especially in the ﬁeld
of ﬁne-grained image/video recognition [24, 8], second-
order statistics such as Covariance and Gaussian descrip-
tors, have demonstrated better performance than descrip-
tors exploiting zeroth- or ﬁrst-order statistics [22, 24, 40].
However, using second-order or lower statistical informa-
tion might not be enough when the feature distribution is
non-Gaussian [12]. Therefore, the higher-order (greater
than two) statistics have been explored in many signal pro-
In the ﬁeld of Blind
cessing problems [27, 16, 9, 12].
Source Separation (BSS) [9, 27], for example, the fourth-
order statistics are widely used to identify different signals
from mixtures. Gou et al. utilizes the third-order statistics
for person ReID [12], Xu et al. exploits the third-order cu-
mulant for blind image quality assessment [44]. In [16, 19],
the authors exploit higher-order statistics for image recog-
nition and detection. Matching the second order statistics
can not always ensure two distributions inseparable, just as
using the second order statistics can not identiﬁes different
signals from underdetermined mixtures [9]. That’s why we
explore higher-order moment tensor for domain alignment.

Discriminative Clustering Discriminative clustering is a
critical task in the unsupervised and semi-supervised learn-
ing paradigms [13, 21, 42, 2]. Due to the paucity of labels
in the target domain, how to obtain the discriminative rep-
resentations in the target domain is of great importance for
the UDA tasks. Therefore, a large body of work pays at-
tention to learn the discriminative clusters in the target do-
main via entropy minimization [13, 28, 34], pseudo label
[21, 32, 43] or distance-based metrics [3, 18]. Speciﬁcally,
Saito et al. [32] assign pseudo-labels to the reliable unla-
beled samples to learn discriminative representations for the
target domain. Shu et al. [34] consider the cluster assump-
tion and minimize the conditional entropy to ensure the de-
cision boundaries not cross high-density data regions. MCD
[33] also considers to align distributions of source and target
by utilizing the task-speciﬁc decision boundaries. Besides,

4322

Figure 2: Two-stream CNNs with shared parameters are
adopted for unsupervised deep domain adaptation. The ﬁrst
stream operates the source data and the second stream op-
erates the target data. The last FC layer (the input of the
output layer) is used as the adapted layer.

JDDA [3] and CAN [18] propose to model the intra-class
domain discrepancy and the inter-class domain discrepancy
to learn more discriminative features.

3. Method

s}ns

In this work, we consider the unsupervised domain adap-
s, yi
tation problem. Let Ds = {xi
i=1 denotes the source
t}nt
domain with ns labeled samples and Dt = {xi
i=1 denotes
the target domain with nt unlabeled samples. Given Ds ∪
Dt, we aim to train a cross-domain CNN classiﬁer fθ(x)
which can minimize the target risks (cid:15)t = Ex∈Dt[fθ(x) (cid:54)=
yt]. Here fθ(x) denotes the outputs of the deep neural net-
works, θ denotes the model parameter to be learned. Fol-
lowing [26, 3], we adopt the two-stream CNNs architec-
ture for unsupervised deep domain adaptation. As shown
in Fig. 2, the two streams share the same parameters (tied
weights), operating the source and target domain samples
respectively. And we perform the domain alignment in the
last full-connected (FC) layer [36, 3]. According to the the-
ory proposed by Ben-David et al. [1], a basic domain adap-
tation model should, at least, involve the source domain loss
and the domain discrepancy loss, i.e.,

L(θ|Xs, Ys, Xt) = Ls + λdLd

Ls =

J(fθ(xs

i ), ys
i )

1
ns

ns(cid:88)

i=1

(1)

(2)

where Ls represents the classiﬁcation loss in the source
domain, J(·, ·) represents the cross-entropy loss function.
Ld represents the domain discrepancy loss and λd is the
trade-off parameter. As aforementioned, most of existing
discrepancy-based methods are designed to minimize dis-
tance of the second-order or lower statistics between dif-
In this work, we propose a higher-order
ferent domains.
moment matching method, which matches the higher-order
statistics of different domains.

Figure 3: An illustration of ﬁrst-order, second-order and
third-order moments in the source domain. HoMM matches
the higher-order (p ≥ 3) moment across different domains.

3.1. Higher-order Moment Matching

To perform ﬁne-grained domain alignment, we propose

a higher-order moment matching as

Ld =

1
Lp (cid:107)

1
ns

ns(cid:88)

i=1

1
nt

nt(cid:88)

i=1

φθ(xi

s)⊗p −

φθ(xi

t)⊗p(cid:107)2
F

(3)

where ns = nt = b (b is the batch size) during the train-
ing process. φθ(x) denotes the activation outputs of the
adapted layer. As illustrated in Fig. 2, hi = φθ(xi) =
[hi(1), hi(2), · · · , hi(L)] ∈ RL denotes the activation out-
puts of the i-th sample, L is the number of hidden neurons
in the adapted layer. Here, u⊗p denotes the p-level tensor
power of the vector u ∈ Rc. That is

u⊗p = u ⊗ u · · · ⊗ u
(cid:125)

(cid:124)

(cid:123)(cid:122)
p times

∈ Rcp

where ⊗ denotes the outer product (or tensor product). We
have u⊗0 = 1, u⊗1 = u and u⊗2 = u ⊗ u. The 2-level
tensor product u⊗2 ∈ Rc2

deﬁned as

u⊗2 = uT u =








u1u1 u1u2
u2u1 u2u2
...
...
ucu1 ucu2

· · ·
· · ·
. . .
· · ·








u1uc
u2uc
...
ucuc

when p ≥ 3, T = u⊗p is a p-level
T[i, j, · · · , k] = uiuj · · · uk.

tensor with

Instantiations According to Eq.

(3), when p = 1,
the ﬁrst-order moment matching is equivalent to the linear
MMD [38], which is expressed as

(4)

(5)

(6)

Ld =

1
L

(cid:107)

1
b

b
(cid:88)

i=1

hi

s −

t(cid:107)2
hi
F

1
b

b
(cid:88)

i=1

4323

When p = 2, the second-order HoMM is formulated as,

Ld =

b
(cid:88)

b
(cid:88)

1
b

1
b

hi
s

s −

T hi

1
L2 (cid:107)
1
b2L2 (cid:107)G(hs) − G(ht)(cid:107)2

i=1

F

i=1

=

hi
t

T hi

t(cid:107)2
F

(7)

where G(h) = H T H ∈ RL×L is the Gram matrix,
H = [h1; h2; · · · , hb] ∈ Rb×L, b is the batch size. There-
fore, the second-order HoMM is equivalent to the Gram ma-
trix matching, which is also widely used for cross-domain
matching in neural style transfer [11, 23] and knowledge
distillation [45]. Li et al. [23] theoretically demonstrate that
matching the Gram matrix of feature maps is equivalent to
minimize the MMD with the second order polynomial ker-
nel. Besides, when the activation outputs are normalized
by subtracting the mean value, the centralized Gram matrix
turns into the Covariance matrix. In this respect, the second-
order HoMM is also equivalent to CORAL, which matches
the Covariance matrix for domain matching [36].

As illustrated in Fig. 3, in addition to the ﬁrst-order
moment matching (e.g. MMD) and the second-order mo-
ment matching (e.g. CORAL and Gram matrix matching),
our proposed HoMM can also perform higher-order mo-
ment tensor matching when p ≥ 3. Since higher-order
statistics can characterize the non-Gaussian distributions
better, applying higher-order moment matching is expected
to perform ﬁne-grained domain alignment. However, the
space complexity of calculating the higher-order tensor u⊗p
(p ≥ 3) reaches O(Lp), which makes the higher-order mo-
ment matching infeasible in many real-world applications.
Adding bottleneck layers to shrink the length of adaptive
layer does not even solve the problem. When L = 128, for
example, the dimension of a third-order tensor still reaches
O(106), and the dimension of a fourth-order tensor reaches
O(108), which is absolutely computational-unfriendly. To
address this problem, we propose two practical techniques
to perform the compact tensor matching.

Group Moment Matching. As the space complexity
grows exponentially with the number of neurons L, one
practical approach is to divide the hidden neurons in the
adapted layer into ng groups, with each group (cid:98)L/ng(cid:99) neu-
rons. Then we can calculate and match the high-level tensor
in each group respectively. That is,

Ld =

1
b2(cid:98)L/ng(cid:99)p

ng
(cid:88)

b
(cid:88)

(cid:107)

k=1

i=1

b
(cid:88)

i=1

hi

s,k

⊗p −

hi

t,k

⊗p(cid:107)2

F (8)

:,k ∈ R(cid:98)L/ng(cid:99) is the activation outputs of k-th
where hi
group. In this way, the space complexity can be reduced
from O(Lp) to O(ng · (cid:98)L/ng(cid:99)p). In practice, (cid:98)L/ng(cid:99) ≥ 25
need to be satisﬁed to ensure satisfactory performance.

Random Sampling Matching. The group moment
matching can work well when p = 3 and p = 4, but it

tends to fail when p ≥ 5. Therefore, we also propose a ran-
dom sampling matching strategy which is able to perform
arbitrary-order moment matching.
Instead of calculating
and matching two high-dimensional tensors, we randomly
select N values in the high-level tensor, and only calculate
and align these N values in the source and target domains.
In this respect, the p-order moment matching with random
sampling strategy can be formulated as,

Ld =

1
b2N

N
(cid:88)

[
k=1

b
(cid:88)

rnd[k,p]
(cid:89)

b
(cid:88)

rnd[k,p]
(cid:89)

hi

s(j) −

hi

t(j)]2

i=1

j=rnd[k,1]

i=1

j=rnd[k,1]

(9)
where rnd ∈ RN ×p denotes the randomly generated posi-
tion index matrix, rnd[k, j] ∈ {1, 2, 3, · · · , L}. Therefore,
(cid:81)rnd[k,p]
j=rnd[k,1] hi
s(j) denotes a randomly sampled value in the
p-level tensor hi
⊗p. With the random sampling strategy,
s
we can perform arbitrarily-order moment matching, and the
space complexity can be reduced from O(Lp) to O(N ).
In practice, the model can achieve very competitive results
even N = 1000.

3.2. Higher-order Moment Matching in RKHS

Similar to the KMMD [26], we generalize the higher-
order moment matching into reproducing kernel Hilbert
spaces (RKHS). That is,

Ld =

1
Lp (cid:107)

1
b

b
(cid:88)

i=1

1
b

b
(cid:88)

i=1

ψ(hi
s

⊗p) −

ψ(hi
t

⊗p)(cid:107)2
F

(10)

⊗p) denotes the feature representation of i-th
where ψ(hi
s
source sample in RKHS. According to the proposed random
⊗p can be approximated by
sampling strategy, hi
⊗p and hi
t
s
tp ∈ RN ,
sp ∈ RN and hi
two N -dimensional vectors hi
sp(k) = (cid:81)rnd[k,p]
j=rnd[k,1] hi
where hi
s(j), k = 1, · · · , N . In this
respect, the domain matching loss can be formulated as

k(hi

sp, hj

sp) −

k(hi

sp, hj

tp)

2
b2

b
(cid:88)

b
(cid:88)

i=1

j=1

Ld =

1
b2

1
b2

b
(cid:88)

b
(cid:88)

i=1

j=1

b
(cid:88)

b
(cid:88)

i=1

j=1

+

k(hi

tp, hj

tp)

(11)

where k(x, y) = exp(−γ(cid:107)x − y(cid:107)2) is the RBF kernel
function. Particularly, when p = 1, the kernelized HoMM
(KHoMM) is equivalent to the KMMD.

3.3. Discriminative Clustering

When the target domain features are well aligned with
the source domain features, the unsupervised domain adap-
tation turns into the semi-supervised classiﬁcation problem,
where the discriminative clustering in the unlabeled data is

4324

always encouraged [13, 42]. There have been a lot of work
trying to learn the discriminative clusters in the target do-
main [34, 28], most of which minimize the conditional en-
tropy to ensure the decision boundaries do not cross high-
density data regions,

clustering loss. Note that in order to obtain reliable pseudo-
labels for discriminative clustering, we set λdc = 0 during
the initial iterations, and enable the clustering loss Ldc after
the total loss tends to be stable.

Lent =

−pj log pj

(12)

1
nt

nt(cid:88)

c
(cid:88)

i=1

j=1

4. Experiments

4.1. Setup

where c is the number of classes, pj is the softmax output
of j-th node in the output layer. We ﬁnd that the entropy
regularization works well when the target domain has high
test accuracy, but it helps little or even downgrades the ac-
curacy when the test accuracy is unsatisfactory. The reason
can be drawn that the classiﬁer may be misled as a result of
entropy regularization enforcing over-conﬁdent probability
on some misclassiﬁed samples. Instead of clustering in the
output layer by minimizing the conditional entropy, we pro-
pose to cluster in the shared feature space. First, we pick up
highly conﬁdent predicted target samples whose predicted
probabilities are greater than a given threshold η, and assign
pseudo-labels to these reliable samples. Then, we penalize
the distance of each pseudo-labeled sample to its class cen-
ter. The discriminative clustering loss can be given as
nt(cid:88)

(cid:107)hi

t − cˆyi

t

(cid:107)2
2

(13)

Ldc =

1
nt

i=1
t is the assigned pseudo-label of xi

∈ RL
where ˆyi
denotes its estimated class center. As we perform update
based on mini-batch, the centers can not be accurately esti-
mated by a small size of samples. Therefore, we update the
class center in each iteration via moving average method.
That is,

t, cˆyi

t

ct+1
j = αct
(cid:80)b
1 + (cid:80)b

j + (1 − α)∆ct
j
i=1 δ(ˆyi = j)hi
t
i=1 δ(ˆyi
t = j)

∆cj =

(14)

(15)

where α is the learning rate of the center. ct
center of j-th class in t-th iteration. δ(ˆyi
belongs to j-th class, otherwise it should be 0.

j is the class
t = j) = 1 if xi
t

3.4. Full Objective Function

Based on the aforementioned analysis, to enable effec-
tive unsupervised domain adaptation, we propose a holis-
tic approach with an integration of (1) source domain loss
minimization, (2) domain alignment with the higher-order
moment matching and (3) discriminative clustering in the
target domain. The full objective function is as follows,

L = Ls + λdLd + λdcLdc

(16)

where Ls is the classiﬁcation loss in the source domain,
Ld is the domain discrepancy loss measured by the higher-
order moment matching, and Ldc denotes the discriminative

Dataset. We conduct experiments on three public visual
adaptation datasets: digits recognition dataset, Ofﬁce-31
dataset, and Ofﬁce-Home dataset. The digits recognition
dataset includes four widely used benchmarks: MNIST,
USPS, Street View House Numbers (SVHN), and SYN
(synthetic digits dataset). We evaluate our proposal across
three typical transfer tasks, including: SVHN→MNIST,
USPS→MNIST and SYN→MNIST. The details of this
dataset can be seen in [3]. Ofﬁce-31 is another com-
monly used dataset for real-world domain adaptation sce-
nario, which contains 31 categories acquired from the of-
ﬁce environment in three distinct image domains: Amazon
(product images download from amazon.com), Webcam
(low-resolution images taken by a webcam) and Dslr (high-
resolution images taken by a digital SLR camera). The
ofﬁce-31 dataset contains 4110 images in total, with 2817
images in A domain, 795 images in W domain and 498
images in D domain. We evaluate our method on all the
six transfer tasks as [26]. The Ofﬁce-Home dataset [39] is
a more challenging dataset for domain adaptation, which
consists of images from four different domains: Artistic
images (A), Clip Art images (C), Product images (P) and
Real-world images (R). The dataset contains around 15500
images in total from 65 object categories in ofﬁce and home
scenes.
Baseline Methods. We compare our proposal with the fol-
lowing methods, which are most related to our work: Deep
Domain Confusion (DDC) [38], Deep Adaptation Network
(DAN) [25], Deep Correlation Alignment (CORAL) [36],
Domain-adversarial Neural Network (DANN) [10], Ad-
versarial Discriminative Domain Adaptation (ADDA) [37],
Joint Adaptation Network (JAN) [26], Central Moment
Discrepancy (CMD) [46] Cycle-consistent Adversarial Do-
main Adaptation (CyCADA) [15], Joint Discriminative fea-
ture Learning and Domain Adaptation (JDDA) [3]. Specif-
ically, DDC, DAN, JAN, CORAL and CMD are repre-
sentative moment matching based methods, while DANN,
ADDA and CyCADA are representative adversarial training
based methods.
Implementation Details.
In our experiments on digits
recognition dataset, we utilize the modiﬁed LeNet whereby
a bottleneck layer with 90 hidden neurons is added before
the output layer. Since the image size is different across
different domains, we resize all the images to 32 × 32 and
convert the RGB images to grayscale. For the experiments

4325

Table 1: Test accuracy (%) on digits recognition dataset for
unsupervised domain adaptation based on modiﬁed LeNet

Method

SN→MT

US→MT

SYN→MT Avg

Source Only
DDC
DAN
DANN
CMD
ADDA
CORAL
CyCADA
JDDA

HoMM(p=3)
HoMM(p=4)
KHoMM(p=3)
Full

67.3±0.3
71.9±0.4
79.5±0.3
70.6±0.2
86.5±0.3
72.3±0.2
89.5±0.2
92.8±0.1
94.2 ±0.1

96.5±0.2
95.7±0.2
97.2±0.1
98.8±0.1

66.4±0.4
75.8±0.3
89.8±0.2
76.6±0.3
86.3±0.4
92.1±0.2
96.5±0.3
97.4±0.3
96.7±0.1

97.8±0.0
97.6±0.0
97.9±0.1
99.0±0.1

89.7±0.2
89.9±0.2
75.2±0.1
90.2±0.2
96.1±0.2
96.3±0.4
96.5±0.2
97.5±0.1
97.7±0.0

97.6±0.1
97.6±0.0
98.2±0.1
99.0±0.0

KHoMM+Lent

99.0±0.0

99.1±0.1

99.2±0.0

We denote SVHN, MNIST, USPS as SN, MT and US.

74.5
79.2
81.5
79.1
89.6
86.9
94.2
95.9
96.2

97.3
96.9
97.8
98.9

99.1

on Ofﬁce-31, we use ResNet-50 pretrained on ImageNet as
our backbone networks. And we add a bottleneck layer with
180 hidden nodes before the output layer for domain match-
ing. It is worth noting that the relu activation function can
not be applied to the adapted layer, as relu activation func-
tion will make most of the values in the high-level tensor
hi
⊗p to be zero, which will make our HoMM fail. There-
s
fore, we adopt tanh activation function in the adapted layer.
Due to the small samples size of Ofﬁce-31 and Ofﬁce-Home
datasets, we only update the weights of the full-connected
layers (fc) as well as the ﬁnal block (scale5/block3), and ﬁx
other parameters pretrained on ImageNet. Follow the stan-
dard protocol of [26], we use all the labeled source domain
samples and all the unlabeled target domain samples for
training. All the comparison methods are based on the same
CNN architecture for a fair comparison. For DDC, DAN,
CORAL and CMD, we embed the ofﬁcial implementation
code into our model and carefully select the trade-off pa-
rameters to get the best results. When training with ADDA,
our adversarial discriminator consists of 3 fully connected
layers: two layers with 500 hidden units followed by the ﬁ-
nal discriminator output. For other compared methods, we
report the results in the original paper directly.

Our model

Parameters.
is trained with Adam Op-
timizer based on Tensorﬂow.
Regarding the optimal
hyper-parameters, they are determined by applying mul-
tiple experiments using grid search strategy. The op-
timal hyper-parameters may be distinct across differ-
ent transfer tasks. Speciﬁcally, the trade-off parameters
are selected from λd = {1, 10, 102, · · · , 108}, λdc ∈
{0.01, 0.03, 0.1, 0.3, 1.0}. For the digits recognition tasks,
the hyper-parameter λd is set to 104 for third-order HoMM

and set to 107 for fourth-order HoMM 1. For the exper-
iments on Ofﬁce-31 and Ofﬁce-Home, λd is set to 300
for the third-order HoMM and set to 3000 for the fourth-
order HoMM. Besides, the hyper-parameter γ in RBF ker-
nel is set to 1e-4 across the experiments, the learning rate
of the centers is set to α = 0.5 for digits dataset and
set to α = 0.3 for Ofﬁce-31 and Ofﬁce-Home dataset.
The threshold η of the predicted probability is chosen from
{0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95}, and the best re-
sults are reported. The parameter sensitivity can be seen
in Fig. 5.

4.2. Experimental results

Digits Dataset For the experiments on digits recognition
dataset, we set the batch size as 128 for each domain and set
the learning rate as 1e-4 throughout the experiments. Table
1 shows the adaptation performance on three typical trans-
fer tasks based on the modiﬁed LeNet. As can be seen,
our proposed HoMM yields notable improvement over the
comparison methods on all of the transfer tasks. In partic-
ular, our method improves the adaption performance sig-
niﬁcantly in the hard transfer tasks SVHN→MNIST. With-
out bells and whistles, the proposed third-order KHoMM
achieve 97.2% accuracy, improving the second-order mo-
ment matching (CORAL) by +8%. Besides, the results also
indicate that the third-order HoMM outperforms the fourth-
order HoMM and slightly underperforms the KHoMM.
Ofﬁce-31 Table 2 lists the test accuracies on Ofﬁce-31
dataset. We set the batchsize as 70 for each domain. The
learning rate of the fc layer parameters is set as 3e-4 and the
learning rate of the conv layer (scale5/block3) parameters
is set as 3e-5. As we can see, the fourth-order HoMM out-
performs the third-order HoMM and achieves the best re-
sults among all the moment-matching based methods. Be-
sides, it is worth noting that the fourth-order HoMM out-
performs the second-order statistics matching (CORAL)
by more than 10% on several representative transfer tasks
A→W, A→D and D→A, which demonstrates the merits of
our proposed higher-order moment matching.
Ofﬁce-Home Table 3 gives the results on the challenged
Ofﬁce-Home dataset. The parameter settings are the same
as in Ofﬁce-31. We only evaluate our method on 5 out of
12 representative transfer tasks due to the space limitation.
As we can see, on all the ﬁve transfer tasks, the HoMM
outperforms the DAN, CORAL, DANN by a large margin
and also outperforms the JAN by 3%-5%. Note that the
experimental results of the compared methods are reported
from [41] directly.

1Note that the trade-off on the fourth-order HoMM is much larger than
the third-order HoMM. This is because most deep features of the digits are
very small, higher-order moments calculating the cumulative multiplica-
tion between different features become very close to zeros. Therefore, on
digits dataset, the higher the order, the larger the trade-off should be.

4326

Table 2: Test accuracy (%) on Ofﬁce-31 dataset for unsupervised domain adaptation based on ResNet-50

Method

A→W

D→W

W→D

A→D

D→A

W→A

Source Only
DDC [38]
DAN [25]
DANN [10]
CORAL [36]
JAN [26]
CMD [46]
CyCADA [15]
JDDA[3]

HoMM(p=3)
HoMM(p=4)
KHoMM(p=4)
Full

73.1±0.2
74.4±0.3
78.3±0.3
73.6±0.3
79.3±0.3
85.4±0.3
76.9±0.4
82.2±0.3
82.6±0.4

87.6±0.2
89.8±0.3
90.5±0.2
91.7±0.3

93.2±0.2
94.0±0.1
95.2±0.2
94.5±0.1
94.3±0.2
97.4±0.2
94.6±0.3
94.6±0.2
95.2±0.2

96.3±0.1
97.1±0.1
98.3±0.1
98.8±0.0

98.8±0.1
98.2±0.1
99.0±0.1
99.5±0.1
99.4±0.2
99.8±0.2
99.2±0.2
99.7±0.1
99.7±0.0

99.8±0.0
100.0±0.0
100.0±0.0
100.0±0.0

72.6±0.2
74.6±0.4
75.2±0.2
74.4±0.5
74.8±0.1
84.7±0.4
75.4±0.4
78.7±0.1
79.8±0.1

83.9±0.2
86.6±0.1
87.7±0.2
89.1±0.3

55.8±0.1
56.4±0.1
58.9±0.2
57.2±0.1
56.4±0.2
68.6±0.3
56.8±0.1
60.5±0.2
57.4±0.0

66.5±0.1
69.6±0.3
70.4±0.2
71.2±0.2

56.4±0.3
56.9±0.1
64.2±0.3
60.8±0.2
63.4±0.2
70.0±0.4
61.9±0.2
67.8±0.2
66.7±0.2

68.5±0.3
69.7±0.3
70.3±0.2
70.6±0.3

KHoMM+Lent

90.8±0.1

99.3±0.1

100.0±0.0

87.9±0.2

69.3±0.3

69.5±0.4

Avg

75.0
75.8
78.5
76.7
78.0
84.3
77.5
80.6
80.2

83.7
85.5
86.2
86.9

86.1

Table 3: Test accuracy (%) on Ofﬁce-Home dataset for un-
supervised domain adaptation based on ResNet-50

Method

A→P A→R C→R P→R R→P

Source Only
DDC
DAN
DANN
CORAL
JAN

HoMM(p=3)
HoMM(p=4)
KHoMM(p=4)
Full

KHoMM+Lent

50.0
54.9
57.0
59.3
58.6
61.2

60.7
63.5
63.9
64.7

64.2

58.0
61.3
67.9
70.1
65.4
68.9

68.3
70.2
70.5
71.8

70.1

46.2
50.5
60.4
60.9
59.8
61.0

61.4
64.6
65.3
66.1

65.5

60.4
64.1
67.7
68.5
68.3
70.3

69.2
72.6
73.3
74.5

73.2

59.5
65.9
74.3
76.8
74.7
76.8

76.7
79.3
79.8
81.2

80.1

The results in Table 1, Table 2 and Table 3 reveal sev-
eral interesting observations: (1) All the domain adapta-
tion methods outperform the source only model by a large
margin, which demonstrates that minimizing the domain
discrepancy contributes to learning more transferable rep-
resentations.
(2) Our proposed HoMM signiﬁcantly out-
performs the discrepancy-based methods (DDC, CORAL,
CMD), and the adversarial training based methods (DANN,
ADDA and CyCADA), which reveals the advantages of
matching the higher-order statistics for domain adaptation.
(3) The JAN performs slightly better than the third-order
HoMM on several transfer tasks, but it’s always not as good
as the fourth-order HoMM in spite of aligning the joint
distributions of multiple domain-speciﬁc layers across do-
mains. The performance of our HoMM will be improved as

well if we utilize such a strategy. (4) The kernelized HoMM
(KHoMM) consistently outperforms the plain HoMM, but
the improvement seems limited. We believe the reason
is that, the higher-order statistics are originally the high-
dimensional features, which conceals the advantages of em-
bedding the features into RKHS. (5) In all transfer tasks, the
performance increases consistently by employing the dis-
criminative clustering in target domain. In contrast, entropy
regularization improves the transfer performance when the
test accuracy is high, but it helps little or even downgrades
the performance when the test accuracy is not that conﬁ-
dent.

4.3. Analysis

Feature Visualization We utilize t-SNE to visualize the
deep features on the tasks SVHN→MNIST by ResNet-50,
KMMD, CORAL, HoMM(p=3) and the Full Loss model.
As shown in Fig. 4, the feature distributions of the source
only model in (a) suggests that the domain shift between
SVNH and MNIST is signiﬁcant, which demonstrates the
necessity of performing domain adaptation. Besides, the
global distributions of the source and target samples are
well aligned with the KMMD (b) and CORAL (c), but there
are still many samples being misclassiﬁed. With our pro-
posed HoMM, the source and target samples are aligned
better and categories are discriminated better as well.
First/Second-order versus Higher-order Since our pro-
posed HoMM can perform arbitrary-order moment match-
ing, we compare the performance of different order moment
matching on three typical transfer tasks. As shown in table
4, the order is chosen from p ∈ {1, 2, 3, 4, 5, 6, 10}. The
results show that the third-order and fourth-order moment
matching signiﬁcantly outperform the other order moment

4327

(a) Source Only

(b) KMMD

(c) CORAL

(d) HoMM(p=3)

(e) Full Loss

(f) Source Only

(g) KMMD

(h) CORAL

(i) HoMM(p=3)

(j) Full Loss

Figure 4: 2D visualization of the deep features generated by different model on SVHN→MNIST. The ﬁrst row illustrates the
t-SNE embedding of deep features which are marked by category information, each color represents a category. The second
row illustrates the t-SNE embedding of deep features which are marked by domain information, red and blue points represent
the samples drawn from the source and target domains.

(a) λd

(b) λdc

(c) N

(d) η

(e) Convergence

Figure 5: Analysis of parameter sensitivity (a)-(d) and convergence analysis (e). The dash line in (b) and (d) indicate the
performance of HoMM without the clustering loss Ldc

matching. When p ≤ 3, the higher the order, the higher the
accuracy. When p ≥ 4, the accuracy will decrease as the
order increases. Besides, the ﬁfth-order moment matching
also achieves very competitive results. Regarding why the
ﬁfth-order and above perform worse than the fourth-order,
one reason we believe is that the ﬁfth-order and above mo-
ments cant be accurately estimated due to the small sample
size problem [31].

Table 4: Test accuracy (%) comparison of different-order
moment matching on three transfer tasks

values in Random Sampling Matching N , and the threshold
η of the predicted probability. As we can see, our model
is quite sensitive to the change of λdc and the bellshaped
curve illustrates the regularization effect of λd and λdc. The
convergence performance is provided in Fig. 5(e), which
shows that our proposal converges fastest compared with
other methods. It is worth noting that, the test error of the
Full Loss model has a obvious mutation at the 2.0 × 104 it-
eration where we enable the clustering loss Ldc, which also
demonstrates the effectiveness of the proposed discrimina-
tive clustering loss.

order

1

2

3

4

5

6

10

SN→MT
96.5
A→W
87.6
A→P
60.7
We denote SVHN and MNIST as SN and MT respectively.

91.5
85.3
58.2

94.8
86.6
60.9

89.5
79.3
58.6

71.9
74.4
54.9

95.7
89.8
63.5

58.6
80.2
57.3

Parameter Sensitivity and Convergence We conduct
empirical parameter sensitivity on SVHN→MNIST and
A→W in Fig. 5(a)-(d). The evaluated parameters include
two trade-off parameters λc, λdc, the number of selected

5. Conclusion

Minimizing statistic distance between source and target
distributions is an important line of work for domain adapta-
tion. Unlike previous methods that utilize the second-order
or lower statistics for domain alignment, this paper exploits
the higher-order statistics for domain alignment. Speciﬁ-
cally, a higher-order moment matching method has been
presented, which integrates the MMD and CORAL into a
uniﬁed framework and generalizes the existing ﬁrst-order

4328

and second-order moment matching to arbitrary-order mo-
ment matching. We experimentally demonstrate that the
third-order and fourth-order moment matching signiﬁcantly
outperform the existing moment matching methods. Be-
sides, we also extend the HoMM into RKHS and learn
the discriminative clusters in the target domain, which fur-
ther improves the adaptation performance. The proposed
HoMM can be easily integrated into other domain adapta-
tion model, and it is also expected to beneﬁt the knowledge
distillation and image style transfer.

References

[1] Shai Ben-David,

John Blitzer, Koby Crammer, Alex
Kulesza, Fernando Pereira, and Vaughan. A theory of learn-
ing from different domains. Machine learning, 79(1-2):151–
175, 2010.

[2] Mathilde Caron, Piotr Bojanowski, Armand Joulin, and
Matthijs Douze. Deep clustering for unsupervised learning
of visual features. In Proceedings of the European Confer-
ence on Computer Vision (ECCV), pages 132–149, 2018.
[3] Chao Chen, Zhihong Chen, Boyuan Jiang, and Xinyu Jin.
Joint domain alignment and discriminative feature learning
for unsupervised deep domain adaptation. In Proceedings of
the AAAI Conference on Artiﬁcial Intelligence, volume 33,
pages 3296–3303, 2019.

[4] Chao Chen, Zhihang Fu, Zhihong Chen, Zhaowei Cheng,
Xinyu Jin, and Xian-Sheng Hua. Towards self-similarity
consistency and feature discrimination for unsupervised do-
main adaptation. arXiv preprint arXiv:1904.06490, 2019.
[5] Zhihong Chen, Chao Chen, Zhaowei Cheng, Ke Fang,
and Xinyu Jin. Selective transfer with reinforced trans-
fer network for partial domain adaptation. arXiv preprint
arXiv:1905.10756, 2019.

[6] Zhihong Chen, Chao Chen, Xinyu Jin, Yifu Liu, and
Zhaowei Cheng. Deep joint two-stream wasserstein auto-
encoder and selective attention alignment for unsupervised
domain adaptation. Neural Computing and Applications,
pages 1–14.

[7] Gabriela Csurka. Domain adaptation for visual applications:
A comprehensive survey. arXiv preprint arXiv:1702.05374,
2017.

[8] Yin Cui, Feng Zhou, Jiang Wang, Xiao Liu, Yuanqing Lin,
and Serge Belongie. Kernel pooling for convolutional neu-
In Proceedings of the IEEE conference on
ral networks.
computer vision and pattern recognition, pages 2921–2930,
2017.

[9] Lieven De Lathauwer, Josphine Castaing, and Jean-Franois
Cardoso. Fourth-order cumulant-based blind identiﬁcation
of underdetermined mixtures. IEEE Transactions on Signal
Processing, 55(6):2965–2973, 2007.

[10] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pas-
cal Germain, Hugo Larochelle, Franc¸ois Laviolette, Mario
Marchand, and Victor Lempitsky. Domain-adversarial train-
ing of neural networks. The Journal of Machine Learning
Research, 17(1):2096–2030, 2016.

[11] Leon A Gatys, Alexander S Ecker, and Matthias Bethge. Im-
age style transfer using convolutional neural networks.
In
Proceedings of the IEEE conference on computer vision and
pattern recognition, pages 2414–2423, 2016.

[12] Mengran Gou, Octavia Camps, and Mario Sznaier. mom:
In
Mean of moments feature for person re-identiﬁcation.
Proceedings of the IEEE International Conference on Com-
puter Vision, pages 1294–1303, 2017.

Semi-supervised
In Advances in neural

[13] Yves Grandvalet and Yoshua Bengio.
learning by entropy minimization.
information processing systems, pages 529–536, 2005.
[14] Arthur Gretton, Karsten M Borgwardt, Malte J Rasch, Bern-
hard Sch¨olkopf, and Alexander Smola. A kernel two-sample
test. Journal of Machine Learning Research, 13(Mar):723–
773, 2012.

[15] Judy Hoffman, Eric Tzeng, Taesung Park, Jun-Yan Zhu,
Phillip Isola, Kate Saenko, Alexei Efros, and Trevor Dar-
rell. Cycada: Cycle-consistent adversarial domain adap-
In International Conference on Machine Learning,
tation.
pages 1994–2003, 2018.

[16] Jacek Jakubowski, Krzystof Kwiatos, Augustyn Chwaleba,
and Stanislaw Osowski. Higher order statistics and neu-
IEEE Transactions on
ral network for tremor recognition.
Biomedical Engineering, 49(2):152–159, 2002.

[17] Yangqing Jia and Trevor Darrell. Heavy-tailed distances for
gradient based image descriptors. In Advances in Neural In-
formation Processing Systems, pages 397–405, 2011.
[18] Guoliang Kang, Lu Jiang, Yi Yang, and Alexander G Haupt-
mann. Contrastive adaptation network for unsupervised do-
In Proceedings of the IEEE Conference
main adaptation.
on Computer Vision and Pattern Recognition, pages 4893–
4902, 2019.

[19] Piotr Koniusz, Fei Yan, Philippe-Henri Gosselin, and Krys-
tian Mikolajczyk. Higher-order occurrence pooling for bags-
IEEE transactions on
of-words: Visual concept detection.
pattern analysis and machine intelligence, 39(2):313–326,
2016.

[20] Chen-Yu Lee, Tanmay Batra, Mohammad Haris Baig, and
Daniel Ulbricht. Sliced wasserstein discrepancy for unsuper-
vised domain adaptation. In Proceedings of the IEEE Con-
ference on Computer Vision and Pattern Recognition, pages
10285–10295, 2019.

[21] Dong-Hyun Lee. Pseudo-label: The simple and efﬁcient
semi-supervised learning method for deep neural networks.
In Workshop on Challenges in Representation Learning,
ICML, volume 3, page 2, 2013.

[22] Peihua Li, Jiangtao Xie, Qilong Wang, and Wangmeng Zuo.
Is second-order information helpful for large-scale visual
recognition? In Proceedings of the IEEE International Con-
ference on Computer Vision, pages 2070–2078, 2017.
[23] Yanghao Li, Naiyan Wang, Jiaying Liu, and Xiaodi Hou.
In Proceedings of the
Demystifying neural style transfer.
26th International Joint Conference on Artiﬁcial Intelli-
gence, pages 2230–2236. AAAI Press, 2017.

[24] Tsung-Yu Lin, Aruni RoyChowdhury, and Subhransu Maji.
Bilinear cnn models for ﬁne-grained visual recognition. In
Proceedings of the IEEE international conference on com-
puter vision, pages 1449–1457, 2015.

4329

Conference on Computer Vision and Pattern Recognition,
pages 5018–5027, 2017.

[40] Qilong Wang, Peihua Li, and Lei Zhang. G2denet: Global
gaussian distribution embedding network and its application
to visual recognition. In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition, pages 2730–
2739, 2017.

[41] Ximei Wang, Liang Li, Weirui Ye, Mingsheng Long, and
Jianmin Wang. Transferable attention for domain adaptation.
In AAAI Conference on Artiﬁcial Intelligence (AAAI), 2019.
[42] Junyuan Xie, Ross Girshick, and Ali Farhadi. Unsupervised
In International

deep embedding for clustering analysis.
conference on machine learning, pages 478–487, 2016.
[43] Shaoan Xie, Zibin Zheng, Liang Chen, and Chuan Chen.
Learning semantic representations for unsupervised domain
adaptation. In International Conference on Machine Learn-
ing, pages 5419–5428, 2018.

[44] Jingtao Xu, Peng Ye, Qiaohong Li, Haiqing Du, Yong Liu,
and David Doermann. Blind image quality assessment based
on high order statistics aggregation. IEEE Transactions on
Image Processing, 25(9):4444–4457, 2016.

[45] Junho Yim, Donggyu Joo, Jihoon Bae, and Junmo Kim. A
gift from knowledge distillation: Fast optimization, network
In Proceedings of the
minimization and transfer learning.
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 4133–4141, 2017.

[46] Werner Zellinger, Thomas Grubinger, Edwin Lughofer,
Thomas Natschl¨ager, and Susanne Saminger-Platz. Central
moment discrepancy (cmd) for domain-invariant representa-
tion learning. arXiv preprint arXiv:1702.08811, 2017.
[47] Zhen Zhang, Mianzhi Wang, Yan Huang, and Arye Nehorai.
Aligning inﬁnite-dimensional covariance matrices in repro-
ducing kernel hilbert spaces for domain adaptation. In Pro-
ceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pages 3437–3445, 2018.

[25] Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jor-
dan. Learning transferable features with deep adaptation net-
works. In International Conference on Machine Learning,
pages 97–105, 2015.

[26] Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I
Jordan. Deep transfer learning with joint adaptation net-
works. In International Conference on Machine Learning,
pages 2208–2217, 2017.

[27] Ali Mansour and Christian Jutten. Fourth-order criteria for
blind sources separation. IEEE transactions on signal pro-
cessing, 43(8):2022–2025, 1995.

[28] Pietro Morerio, Jacopo Cavazza, and Vittorio Murino.
Minimal-entropy correlation alignment for unsupervised
deep domain adaptation. international conference on learn-
ing representations.

[29] Zak Murez, Soheil Kolouri, David Kriegman, Ravi Ra-
mamoorthi, and Kyungnam Kim. Image to image translation
In Proceedings of the IEEE Con-
for domain adaptation.
ference on Computer Vision and Pattern Recognition, pages
4500–4509, 2018.

[30] Edouard Pauwels and Jean B Lasserre. Sorting out typicality
with the inverse moment matrix sos polynomial. In Advances
in Neural Information Processing Systems, pages 190–198,
2016.

[31] Sarunas J Raudys and Anil K. Jain. Small sample size effects
in statistical pattern recognition: Recommendations for prac-
titioners. IEEE Transactions on Pattern Analysis & Machine
Intelligence, (3):252–264, 1991.

[32] Kuniaki Saito, Yoshitaka Ushiku, and Tatsuya Harada.
Asymmetric tri-training for unsupervised domain adaptation.
In Proceedings of the 34th International Conference on Ma-
chine Learning-Volume 70, pages 2988–2997. JMLR. org,
2017.

[33] Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, and Tat-
suya Harada. Maximum classiﬁer discrepancy for unsuper-
vised domain adaptation. In Proceedings of the IEEE Con-
ference on Computer Vision and Pattern Recognition, pages
3723–3732, 2018.

[34] Rui Shu, Hung H Bui, Hirokazu Narui, and Stefano Ermon.
A dirt-t approach to unsupervised domain adaptation. arXiv
preprint arXiv:1802.08735, 2018.

[35] Baochen Sun, Jiashi Feng, and Kate Saenko. Return of frus-
tratingly easy domain adaptation. In AAAI, volume 6, page 8,
2016.

[36] Baochen Sun and Kate Saenko. Deep coral: Correlation
In European Con-
alignment for deep domain adaptation.
ference on Computer Vision, pages 443–450. Springer, 2016.
[37] Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell.
Adversarial discriminative domain adaptation. In Computer
Vision and Pattern Recognition (CVPR), volume 1, page 4,
2017.

[38] Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, and
Trevor Darrell. Deep domain confusion: Maximizing for
domain invariance. arXiv preprint arXiv:1412.3474, 2014.

[39] Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty,
and Sethuraman Panchanathan. Deep hashing network for
unsupervised domain adaptation. In Proceedings of the IEEE

4330

