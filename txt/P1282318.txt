6
1
0
2
 
t
c
O
 
8
1
 
 
]
L
M

.
t
a
t
s
[
 
 
1
v
5
7
7
5
0
.
0
1
6
1
:
v
i
X
r
a

Modeling the Dynamics of Online Learning Activity

Charalampos Mavroforakis∗1, Isabel Valera2, and Manuel Gomez-Rodriguez2

1Boston University, cmav@bu.edu
2Max Planck Institute for Software Systems, ivalera@mpi-sws.org, manuelgr@mpi-sws.org

Abstract

People are increasingly relying on the Web and social media to ﬁnd solutions to their problems in a
wide range of domains. In this online setting, closely related problems often lead to the same characteristic
learning pattern, in which people sharing these problems visit related pieces of information, perform almost
identical queries or, more generally, take a series of similar actions. In this paper, we introduce a novel
modeling framework for clustering continuous-time grouped streaming data, the hierarchical Dirichlet
Hawkes process (HDHP), which allows us to automatically uncover a wide variety of learning patterns
from detailed traces of learning activity. Our model allows for eﬃcient inference, scaling to millions of
actions taken by thousands of users. Experiments on real data gathered from Stack Overﬂow reveal that
our framework can recover meaningful learning patterns in terms of both content and temporal dynamics,
as well as accurately track users’ interests and goals over time.

1

Introduction

Learning has become an online activity – people routinely use a wide variety of online learning platforms,
ranging from wikis and question answering (Q&A) sites to online communities and blogs, to learn about a
large range of topics. In this context, people ﬁnd solutions to their problems by looking for closely related
pieces of information, executing a sequence of queries or, more generally, performing a series of online actions.
For example, a high school student may study several closely related wiki pages to prepare an essay about
a historical event; a software developer may read several answers within a Q&A site to solve a speciﬁc
programming problem; and, a researcher may check a specialized blog written by one of her peers to learn
about a new concept or technique. All the above are examples of learning patterns, in which people perform
a series of online actions – reading a wiki page, an answer, or a blog – to achieve a predeﬁned goal – writing
an essay, solving a programming problem, or learning about a new concept or technique. In this context,
one may expect that people with similar goals undertake similar sequences of online actions and thus adopt
similar learning patterns. Therefore, one could leverage the vast availability of online traces of users’ learning
activity to disambiguate among interleaved learning patterns adopted by individuals over time, as well as to
automatically identify and track those people’s interests and goals over time.

In this work, we introduce a novel probabilistic model, the Hierarchical Dirichlet Hawkes Process
(HDHP), for clustering continuous-time grouped streaming data, which we use to uncover the dynamics
of learning activity on the web. The HDHP leverages the properties of the Hierarchical Dirichlet Process
(HDP) [18], a popular Bayesian nonparametric model for clustering problems involving multiple groups of
data, combined with the Hawkes process [13], a temporal point process particularly well ﬁtted to model
social activity [11, 19, 20]. In particular, the former is used to account for an inﬁnite number of learning
patterns, which are shared across users (groups) of an online learning platform. The latter is used to capture

∗This work was done during the author’s internship at Max Planck Institute for Software Systems.

1

the temporal dynamics of the learning activity, which alternate between bursts of rapidly occurring events
and relatively long periods of inactivity [4].

In more detail, in the case of the HDHP, the learning pattern distribution that determines the content
and temporal parameters of each learning pattern is drawn from a Dirichlet process (DP) [12]. Each user’s
learning activity is modeled as a multivariate Hawkes process, with as many dimensions as the number of
learning patterns (i.e., inﬁnite), whose parameters are given by the DP and thus shared across all the users.
Every time a user decides to perform a new action, she may opt for starting a new task or follow-up on one of
her previous ones. Here, tasks refer to sequences of related actions performed closely in time, which in turn
can be viewed as realizations of learning patterns. Our model allows for an eﬃcient inference algorithm, based
on sequential Monte Carlo [15], which scales to millions of actions and thousands of users. We experiment on
real-world data from Stack Overﬂow, using ∼1.6 million questions performed by 16,000 users over a four year
period. Our results show that our model, taking advantage of the temporal information in the data, does
not only allow us to accurately track users’ interest over time, but also provides more meaningful learning
patterns in terms of content (20% gain in perplexity) compared to the HDP. A Python implementation of the
proposed HDHP is available in GitHub.1
Related work. The Hierarchical Dirichlet Hawkes process (HDHP) can be viewed as a model for clustering
grouped continuous-time streaming data. In our application domain, each group of data corresponds to a
user’s online actions and the clusters correspond to learning patterns, shared across all the users. Therefore,
our work relates, on the one hand, to models for clustering groups of data [6, 17], and, on the other hand, to
models for clustering (single) streaming data [3, 5, 2, 10]. To the best of our knowledge, models for clustering
grouped streaming data are nonexistent to date.

The most popular models for clustering groups of data, the Latent Dirichlet Allocation (LDA) [6] and, its
nonparametric counterpart, the HDP [18], originate from the topic modeling literature. There, each document
is transformed into a bag-of-words and is modeled as a mixture of topics that are shared across all documents.
More generally, models for clustering groups of data typically consider that each observation (word) within a
group (document) is a sample from a mixture model, and the mixture components are shared among groups.
One could use such models to cluster users’ activity on the Web, however observations are assumed to be
exchangeable and thus these models cannot account for the temporal dynamics of learning activity. As a
consequence, they are unable to track users’ interests and goals over time.

Models for clustering streaming data can incorporate temporal dynamics [2, 3], however they can only
handle a single stream of data and thus cannot be used to jointly model several users’ learning activity.
Additionally, most of these models discretize the time dimension into bins [2, 3], introducing additional tuning
parameters, and ignoring the self-excitation across events [5], a phenomenon regularly observed in social
activity data [11]. Perhaps the most closely related work to ours is the recently proposed Dirichlet Hawkes
Process (DHP) [10], a continuous-time model for streaming data that allows for self-excitation. However,
DHP suﬀers from a signiﬁcant limitation: the lack of an underlying DP (or, in fact, any other Bayesian
nonparametric) prior on the cluster distribution compromises the identiﬁability and reproducibility of the
model. Additionally, from the perspective of our application, DHP only allows for single data stream (user)
and enforces clusters to be forgotten after some time. The latter is an overly restrictive assumption, since a
user may perform similar actions, i.e., belonging to the same learning pattern, over widely spaced intervals of
time.

2 Preliminaries

In this section, we brieﬂy review the major building blocks of the Hierarchical Dirichlet Hawkes process
(HDHP): the Hierachical Dirichlet process (HDP) [18] and the Hawkes process [1].

1https://github.com/Networks-Learning/hdhp.py

2

2.1 Hierarchical Dirichlet Process

The HDP is a Bayesian nonparametrics prior, useful for clustering grouped data [18], which allows for an
unbounded number of clusters whose parameters are shared across all the groups. It has been broadly applied
for topic modeling as the nonparametric counterpart of the Latent Dirichlet Allocation (LDA), where the
number of topics is ﬁnite and predeﬁned. More speciﬁcally, this process deﬁnes a hierarchy of Dirichlet
processes (DPs), in which a set of random probability measures Gj ∼ DP (β1, G0) (one for each group of
data) are distributed as DPs with concentration parameter β1 and base distribution G0. The latter is also
distributed as a DP, i.e., G0 ∼ DP (β0, H). In the HDP, the distributions Gj share the same support as G0,
and are conditionally independent given G0.
Chinese Restaurant Franchise. An alternative representation of the HDP is the Chinese Restaurant
Franchise Process (CRFP), which allows us not only to obtain samples from the HDP but also to derive
eﬃcient inference algorithms. The CRFP assumes a franchise with as many restaurants as the groups of data
(e.g., number of documents), where all of the restaurants share the same menu with an inﬁnite number of
dishes (or clusters). In particular, one can obtain samples from the HDP as follows:

1. Initialize the total number of dishes L = 0, and the total number of tables in each restaurant Kr = 0,

for r = 1, . . . , R, with R being the total number of restaurants in the franchise.

2. For each restaurant r = 1, . . . , R:

For customer i = 1, . . . , Nr (Nr is the total number of customers entering restaurant r):
– Sample the table for the i-th customer in restaurant r from a multinomial distribution with probabilities

=
Pr(bri = k)
Pr(bri = Kr + 1) =

nrk
β1+i−1
β1
β1+i−1

for k = 1, . . . , Kr

I(brj = k) is the number of customers seated at the k-th table of the r-th

– If bri = Kr + 1, i.e., the i-th customer sits at a new table, sample its dish from a multinomial

where nrk = (cid:80)i−1
restaurant.

j=1

distribution with probabilities

=
Pr(φr(Kr+1) = ϕ(cid:96))
Pr(φr(Kr+1) = ϕL+1) =

m(cid:96)
K+β0
β0
K+β0

for (cid:96) = 1, . . . , L

j=1 Kj is the total number of tables in the franchise, m(cid:96) = (cid:80)r

where K = (cid:80)r
I(φjk = ϕ(cid:96)) is
the total number of tables serving dish ϕ(cid:96) in the franchise, and ϕL+1 ∼ H(ϕ) is the new dish, i.e.,
the parameters of the new cluster.

(cid:80)Kj
k=1

j=1

– Increase the number of tables in the r-th restaurant Kr = Kr + 1 and, if φrKr = ϕL+1 (i.e., the new
table is assigned to a new dish/cluster), increase also the total number of clusters in the franchise
L = L + 1.

Note that, although in the process above we have generated the data (customers) for each group (restaurant)
sequentially, due to the exchangeability properties of the HDP, the resulting distribution of the data is
invariant to the order at which customers are assumed to enter any of the restaurants [18].

2.2 Hawkes Process

A Hawkes process is a stochastic process in the family of temporal point processes [1], whose realizations
consist of lists of discrete events localized in time, {t1, t2, . . . , tn} with ti ∈ R+. A temporal point process can
be equivalently represented as a counting process, N (t), which records the number of events before time t. The
probability of an event happening in a small time window [t, t + dt) is given by P(dN (t) = 1|H(t)) = λ∗(t)dt,
where dN (t) ∈ {0, 1} denotes the increment of the process, H(t) denotes the history of events up to but not
including time t, λ∗(t) is the conditional intensity function (intensity, in short), and the sign ∗ indicates that
the intensity may depend on the history H(t). In the case of Hawkes processes, the intensity function adopts

(1)

(2)

3

the following form:

λ∗(t) = µ +

(cid:88)

κα(t, ti),

ti∈H(t)

where µ is the base intensity and κα(t, ti) is the triggering kernel, which is parametrized by α. Note that this
intensity captures the self-excitation phenomenon across events and thus allows modeling bursts of activity.
As a consequence, the Hawkes process has been increasingly used to model social activity [11, 19, 20], which
is characterized by bursts of rapidly occurring events separated by long periods of inactivity [4]. Finally, given
the history of events in an observation window [0, T ), denoted by H(T ), we can express the log-likelihood of
the observed data as

LT =

(cid:88)

log λ∗(ti) −

λ∗(τ ) dτ.

(cid:90) T

0

i:ti∈H(T )

3 Learning activity model

In an online learning platform, users ﬁnd solutions to their problems by sequentially looking for closely related
pieces of information within the site, executing a sequence of queries or, more generally, performing a series
of online actions. In this context, one may expect people with similar goals to undertake similar sequences
of actions, which in turn can be viewed as realizations of an unbounded number of learning patterns. Here,
we assume that each action is linked to some particular content and we propose a modeling framework that
characterizes sequences of actions by means of the timestamps as well as the associated content of these
actions. Next, we formulate our model for online learning activity, starting by describing the data it is
designed for.
Learning activity data and generative process. Given an online learning platform with a set of users
U, we represent the learning actions of each user as a triplet

e := (

learning pattern
↓
p ),

time
↓
,
t , ω
↑
content

which means that at time t the user took an action linked to content ω and this action is associated to the
learning pattern p, which is hidden. Then, we denote the history of learning actions taken by each user u up
to, but not including, time t as Hu(t).

u(t) = [λ∗

We represent the times of each user u’s learning actions within the platform as a set of counting processes,
Nu(t), in which the (cid:96)-th entry counts the number of times up to time t that user u took an action associated
to the learning pattern (cid:96). Then, we characterize these counting processes using their corresponding intensities
as E[dNu(t)|Hu(t)] = λ∗
u(t) dt, where dNu(t) = [dNu,(cid:96)(t)](cid:96)∈[L] denotes the number of learning actions in the
time window [t, t + dt) for each learning pattern, λ∗
u,(cid:96)(t)](cid:96)∈[L] denotes the corresponding pattern
intensities, L is the number of learning patterns, and the sign ∗ indicates that the intensities may depend on
the user’s history, Hu(t). Additionally, for each learning action e = (t, ω, p), the content ω is sampled from a
distribution f (ω|p), which depends on the corresponding learning pattern p. Here, in order to account for
an unbounded number of learning patterns, i.e., L → ∞, we assume that the learning pattern distribution
follows a Dirichlet process (DP). Next, we specify the functional form of the user intensity associated to each
learning pattern and the content distribution, and we elaborate further on the learning pattern distribution.
Intensity of the user learning activity. Every time user u performs a learning action, she may opt to
either start a new task, deﬁned as a sequence of learning actions similar in content and performed closely in
time (i.e., a realization of a learning pattern), or to follow-up on an already on-going task. The multivariate
Hawkes process [1], described in Section 2.2, presents itself as a natural choice to model this behavior. This
way, each dimension (cid:96) corresponds to a learning pattern (cid:96) and its associated intensity is given by

(3)

(4)

(5)

(6)

λ∗
u,(cid:96)(t) = µu π(cid:96)
(cid:124) (cid:123)(cid:122) (cid:125)
new task

(cid:122)

+

follow-up
(cid:125)(cid:124)

(cid:88)

(cid:123)
κ(cid:96)(t, tj) .

j:tj ∈Hu(t), pj =(cid:96)

4

(7)

(8)

(9)

(10)

Here, the parameter µu ≥ 0 accounts for the rate at which user u starts new tasks, π(cid:96) ∈ [0, 1] is the probability
that a user adopts learning pattern (cid:96) (referred to as learning pattern popularity from now on), and κ(cid:96)(t, t(cid:48)) is
a nonnegative kernel function that models the decaying inﬂuence of past events in the pattern’s intensity.
Due to convenience in terms of both theoretical properties and model inference, we opt for an exponential
kernel function in the form κ(cid:96)(t, t(cid:48)) = α(cid:96) exp(−ν(t − t(cid:48))), where α(cid:96) controls the self-excitation (or burstiness)
of the Hawkes process and ν controls the decay. Finally, note that we can compute user u’s average intensity
at time t analytically as [11]:

EHu(t)[λ∗

u(t)] =

e(A−νI)t + ν(A − νI)−1 (cid:16)
(cid:104)

e(A−νI)t − I

(cid:17) (cid:105)

µu,

where A = diag([α1, . . . , αL]), µu = [µuπ1, . . . , µuπL](cid:62), I is the identity matrix, and the expectation is taken
over all possible histories Hu(t). We can also compute the expected number of actions performed by user u
until time T as

EHu(T )[Nu(T )] =

EHu(τ )[λ∗

u(τ )] dτ.

(cid:90) T

0
Content distribution. We gather the content associated to each learning action e = (t, ω, p) as a vector
ω, in which each element is a word sampled from a vocabulary W as

ωj ∼ M ultinomial(θp),

where θp is a |W|-length vector indicating the probability of each word to appear in content from pattern p.
Learning pattern parameters.
The distribution of the learning patterns is sampled from a DP,
G0 ∼ DP (β, H), which can be alternatively written as
∞
(cid:88)

G0 =

π(cid:96)δϕ(cid:96),

(cid:96)=1

(cid:96)=1 ∼ GEM (β) is sampled from a stick breaking process [14] and ϕ(cid:96) = {α(cid:96), θ(cid:96)} ∼ H(ϕ).

where π = (π(cid:96))L=∞
Remarks. Overall, the proposed learning activity model, which we refer to as the Hierarchical Dirichlet
Hawkes process (HDHP), is based on a 2-layer hierarchical design. The top layer is a Dirichlet process that
determines the learning pattern distribution, and the bottom layer corresponds to a collection of independent
multivariate Hawkes processes, one per user, with as many dimensions as the number of learning patterns, i.e.,
inﬁnite. In the HDHP, the popularity of each learning pattern, or equivalently the probability of assigning a
new task to it, is constant over time and given by the distribution G0. However, the probability distribution
of the learning patterns for each speciﬁc user evolves continuously over time and directly depends on her
instantaneous intensity. Finally, we remark that, due to the inﬁnite dimensionality of the Hawkes process
that captures the learning activity of each user, sampling or performing inference directly on this model is
intractable. Fortunately, we can beneﬁt from the properties of both the Hawkes and the DP, and propose an
alternative generative process that we can then utilize to eﬃciently obtain samples of the HDHP.

3.1 Tractable model representation

Similarly to the HDP, we can generate samples from the proposed HDHP by following a generative process
similar to the CRFP. To this end, we leverage the properties of the Hawkes process and represent the learning
actions of all the users in the learning platform as a multivariate Hawkes process, with as many dimensions
as the users, from which we sample the user and the timestamp associated to the next learning action. This
action is then assigned to either an existing or a new task with a probability that depends on the history of
that user up to, but not including, the time of the action. When initiating a new task, the associated learning
pattern is sampled from a distribution that accounts for the overall popularity of all the learning patterns.
We ﬁnally sample the action content ω as we discussed previously.

In the process described above, each user can be viewed as a restaurant, each action as a customer, each
task as a table, and each pattern as a dish, as in the original CRFP. Hence, if we assume a set of users U and
vocabulary W for the content, we can generate N learning actions as follows:

5

(11)

(12)

(13)

1. Initialize the total number of tasks K = 0 and the total number of learning patterns L = 0.
2. For n = 1, . . . , N :

(a) Sample the time tn and user un ∈ U for the new action, such that tn > tn−1, as in [19]

(b) Sample the task bn for the new action from a multinomial distribution with probabilities

(tn, un) ∼ Hawkes

µ1 +

κbi(tn, ti)I(ui = 1)










n−1
(cid:80)
i=1

n−1
(cid:80)
i=1

...

µU +

κbi(tn, ti)I(ui = U)










Pr(bn = k)

=

Pr(bn = K + 1) =

λ∗
un ,k(tn)
(tn) ,
λ∗
un
µun
un

(tn)

λ∗

for k = 1, . . . , K

un,k(tn) = (cid:80)n−1

where λ∗
un) is the total intensity of user un at time tn.

i=1 κbi(tn, ti)I(ui = un, bi = k), and λ∗
un

(tn) = µun + (cid:80)n−1

i=1 κbi (tn, ti)I(ui =

(c) If bn = K + 1, assign the new task to a learning pattern with probability

Pr(φK+1 = ϕ(cid:96))

for (cid:96) = 1, . . . , L

Pr(φK+1 = ϕL+1) =

= m(cid:96)
K+β ,
β
K+β

k=1

where m(cid:96) = (cid:80)K
I(φk = ϕ(cid:96)) is the number of tasks assigned to learning pattern (cid:96) across all users,
and ϕL+1 = {αL+1, θL+1} is the set of parameters of the new learning pattern L + 1, which we
sample from αL+1 ∼ Gamma(τ1, τ2) and θL+1 ∼ Dirichlet(η0). Then, increase the number of
tasks K = K + 1 and, if φK+1 = ϕL+1, increase also the number of clusters L = L + 1.

(d) Sample each word in the content ωn from ωn,j ∼ M ultinomial(θbn ).

Remarks. Note that, in the process above, both users and learning patterns are exchangeable. However,
contrary to the CRFP, the generated data consist of a sequence of discrete events localized in time, which
therefore do not satisfy the exchangeability property. Moreover, the complexity of this generative process
diﬀers from the standard CRFP only in two steps. First, it needs to sample the event time and user from
a Hawkes process as in Eq. 11, which can be done in linear time with respect to the number of users [11].
Second, while the CRFP only accounts for the number of customers at each table, the above process needs
to evaluate the intensity associated with each table (see Eq. 12), which can be updated in O(1) using the
properties of the exponential function.

We also want to stress that although the above generative process resembles the one for the Dirichlet
Hawkes process (DHP) [10], they diﬀer in two key factors. First, the DHP can only generate a single sequence
of events, while the above process can generate an independent sequence for each user. Second, the DHP
does not instantiate an explicit prior distribution on the clusters, which results in a lack of identiﬁability and
reproducibility of the model. In other words, new events in the DHP are only allowed to join a new or a
currently active cluster – once a cluster “dies” (i.e., its intensity becomes negligible), no new event can be
assigned to it anymore. As a result, two bursts of events that are similar in content and dynamics but widely
separated in time will be assigned to diﬀerent clusters, leading to multiple copies of the same cluster. In
contrast, our generative process ensures the identiﬁability and reproducibility of the model by placing a DP
prior on the cluster distribution, and using the CRFP to integrate out the learning pattern popularity.

3.2

Inference

Given a collection of N observed learning actions performed by a set of users U during a time period [0, T ),
our goal is to infer the learning patterns that these actions belong to. To eﬃciently sample from the posterior
distribution, similarly to [10], we leverage the generative process described in Section 3.1. We derive a

6

(a) Estimation of µu

(b) Estimation of α(cid:96)

(c) Clustering accuracy

Figure 1: Evaluation of the inference algorithm at recovering the model parameters and latent learning
pattern associated to each learning event on 150k synthetically generated data.

sequential Monte Carlo (SMC) algorithm that exploits the temporal dependencies in the observed data to
sequentially sample the latent variables associated with each learning action. In particular, the posterior
distribution p(b1:N |t1:N , u1:N , ω1:N ) is sequentially approximated with a set of P particles, which are sampled
from a proposal distribution q(b1:N |t1:N , u1:N , ω1:N ). To infer the global parameters, µu and α(cid:96), we follow
the literature in SMC devoted to the estimation of a static parameter [7, 8], and sequentially update the
former by maximum likelihood estimation and the latter by sampling from its posterior distribution. The
inference algorithm, which is detailed in Appendix A, has complexity O(P(U + L + K) + P) per observed
learning action, where L and K are respectively the number of learning patterns and the number of tasks
uncovered up to this action.

4 Experiments

4.1 Experiments on synthetic data

In this section, we experiment with synthetic data and show that our inference algorithm can accurately
recover the model parameters as well as assign each generated learning action to the true learning pattern
given only the times and content of the learning events.
Experimental setup. We assume a set of 200 users, L = 50 learning patterns and a vocabulary of size
|W| = 100. We then sample the base intensity of each user µu from Gamma(10, 0.2), and the learning pattern
popularity vector π from a Dirichlet distribution with concentration parameters equal to 1. For each learning
pattern, we sample the kernel parameter α(cid:96) from Gamma(8, 0.25), we randomly pick 30 words that will be
used by the pattern and sample their distribution from a Dirichlet distribution with parameters equal to
3. We assume a kernel decay of ν = 5. Then, for each user we generate online learning actions from the
corresponding multivariate Hawkes process.
Results. Figure 1 summarizes the results by showing the true and the estimated values of the base intensity
of each user µu and the kernel parameter of each pattern α(cid:96), using a total of 150k events. Moreover, it also
shows the normalized mutual information (NMI) between the true and inferred clusters of actions against the
number of events seen by our inference algorithm. Here, we report the results for the particle which provided
the maximum likelihood, and match the inferred learning patterns to the true ones by maximizing the NMI
score. Our inference algorithm accurately recovers the model parameters and, as expected, using more events
when inferring the model parameters leads to more accurate assignment of events to learning patterns.

4.2 Experiments on real data

In this section, we experiment on real data gathered from Stack Overﬂow, a popular question answering (Q&A)
site, where users can post questions – with topics ranging from C# programming to Bayesian nonparametrics

7

(a) Dynamics

(b) Content

Figure 2: Goodness of ﬁt of the HDHP model in terms of (a) dynamics and (b) content.

– which are, in turn, answered by other users of the site. We infer our proposed HDHP on a large set of
learning actions, and show that the proposed HDHP recovers meaningful learning patterns and allows us to
accurately track users’ interests over time.
Experimental setup. We gather the times and content of all the questions posted by all Stack Overﬂow
users during a four year period, from September 1, 2010 to September 1 2014. Here, we consider each user’s
question as a learning action. The reason for this choice is primarily the availability of public datasets, and,
secondarily, the fact that a question provides clear evidence of the user’s current interest at the time of asking.
By looking only at the questions, we are underestimating the number of actions taken on each task, however,
this bias is shared across all the tasks and, thus, we can still compare the dynamics of diﬀerent patterns in
a sensible way. For each question, we use the set of (up to) ﬁve tags (or keywords) that the user used to
describe her question as the content associated to the learning action. To ensure that the inferred parameters
are reliable and accurate, we only consider users who posted at least 50 questions and tags that were used
in at least 100 questions. After these preprocessing steps, our dataset consists of ∼1.6 million questions
performed by ∼16,000 users, and a vocabulary of ∼31,400 tags. Finally, we run our inference algorithm on
the ﬁrst 45 months of data and evaluate its performance on the last three months, used as held-out set. In
our experiments we set the time scale to be one month, the kernel decay ν = 5 and the number of particles
|P| = 200 particles, which worked well in practice. Our implementation of the SMC algorithms for the
proposed HDHP and the HDP requires, respectively, 71ms and 65ms per question on average, which implies
that accounting for the temporal information in the data leads to an increase in runtime of approximately
10%.
Goodness of ﬁt. We evaluate the goodness of ﬁt of our proposed model on learning activity data, in terms
of both content and temporal dynamics. To this end, we ﬁrst evaluate the performance of the HDHP at
capturing the temporal dynamics of the learning activity and compare it with the standard Hawkes process
that only accounts for the temporal information of the data and, therefore, cannot cluster learning actions
into learning patterns. In the latter, we model the learning activity of each user as an independent univariate
Hawkes process, disregarding the content of each learning action. In other words, for each user, we learn
both a base intensity µ and a self-excitation parameter α, as deﬁned in Eq. 3, per user active in the test
set Utest. In order to compare the performance of the models, we ﬁrst apply the time changing theorem [9],
which states that the integral of the intensity of a point process between two consecutive events (cid:82) ti+1
λ∗
u(t)dt
should conform to the unit-rate exponential distribution. Then, we resort to two goodness of ﬁt tests, the
Kolmogorov-Smirnov and the Anderson-Darling [16], to measure how well the transformed action times ﬁt the
target distribution. Figure 2a summarizes the results by showing the percentage of the users in the held-out
set that each test rejects at a signiﬁcance level of 5%. While the Hawkes process performs slightly better (5%
for the KS-test and 11% for the AD-test) than our model, it does so by using almost 2× more parameters —
2|Utest| ∼ 5k for the Hawkes vs |Utest| + L∗ ∼ 2.7k for the HDHP, where L∗ = 227 is the number of inferred
learning patterns.

ti

8

(a) Machine Learning

(b) Python

(c) Version Control

Figure 3: Three inferred learning patterns in Stack Overﬂow. The top row shows the content associated to
each pattern, in the form of clouds of words, while the bottom row shows two samples of its characteristic
temporal dynamics, by means of the intensities of two users using the pattern.

Second, we focus on evaluating the performance of the HDHP at clustering learning activity, and compare
it with the HDP [18], which only makes use of the content information in the data. We resort to the marginal
likelihood of the inferred parameters evaluated on the held-out set of questions ωi ∈ Dtest, i.e.,

p(ωi|Dtrain, ui, ti) =

p(ωi|Dtrain, (cid:96))p((cid:96)|Dtrain, ui, ti).

L
(cid:88)

(cid:96)=1

Above, the ﬁrst term is deﬁned in the same way for both models. However, for the HDP, the second term
is simply the topic popularity π(cid:96), while for the HDHP it depends on the complete user history up to but
not including ti, i.e., p((cid:96)|Dtrain, ui, ti) ∝ λ∗
ui,(cid:96)(ti) is given by Eq. 6. Figure 2b shows the
log-likelihood values obtained under the proposed HDHP and the HDP on the held-out set. Here, higher
log-likelihood values mean better goodness of ﬁt and, therefore, all the points above the x = y line correspond
to questions that are better captured by the HDHP, which are in turn 60% of the held-out questions.
Additionally, we also compute the perplexity [6] as

ui,(cid:96)(ti), where λ∗

perplexity = exp

−

(cid:26)

(cid:80)

i:ei∈Dtest

log p(ωi|Dtrain)
|Dtest|

(cid:27)

.

The perplexity values for the HDHP and the HDP are 204 and 243, respectively, where here lower perplexity
values mean better goodness of ﬁt. These results show that by modeling temporal information, in addition to
content information, the HDHP ﬁts better the content in the data than the HDP (20% gain in perplexity),
and therefore, it provides more meaningful learning patterns in terms of content.
In this section, our goal is to understand the characteristic properties of the learning
Learning patterns.
patterns that Stack Overﬂow users follow for problem solving. To this end, we ﬁrst pay attention to three
particular examples of learning patterns, ‘Machine Learning’, ‘Python’ and ‘Version Control ’, among the
uncovered L∗ = 227 learning patterns, and investigate their characteristic properties. Figure 3 compares the
above mentioned patterns in terms of content, by means of word clouds, and in terms of temporal dynamics,
by means of the learning pattern intensities associated to two diﬀerent users active on each of the patterns.
Here, we observe that: i) the cloud of words associated to each inferred learning pattern corresponds to
meaningful topics; and ii) despite the stochastic nature of the temporal dynamics, the user intensities within
the same learning pattern tend to exhibit striking similarities in terms of burstiness and periods of inactivity.
For example, we observe that the Machine Learning and Python tasks exhibit much larger bursts of events
than Version Control. A plausible explanation is that version control problems tend to be more speciﬁc and
simple, e.g., resolving a conﬂict while merging versions, and, thus, can be quickly solved with one or just

9

(a) Popularity

(b) Burstiness

(c) Popularity vs. Burstiness

Figure 4: Learning patterns. Panels (a) and (b) show the popularity and burstiness of the top-50 most
popular learning patterns, and panel (c) shows the popularity and burstiness for all the inferred patterns. We
highlight the learning pattern examples in Figure 3, as well as some others from Table 1.

a few questions. On the contrary, a user interested in machine learning or Python may face more complex
problems whose solution requires asking several questions in a relatively short period of time.

Next, we investigate whether more popular learning patterns are also the ones that trigger larger bursts
of events, i.e., the learning patterns that engage users to perform long sequences of closely related learning
actions in shorts period of time. Figure 4 shows the popularity and burstiness of the 50 most popular
learning patterns sorted in decreasing order of popularity, as well as a scatter plot which shows the popularity
against burstiness for all the inferred patterns. Here, we compute the burstiness as the expected number of
learning events triggered by self-excitation during the ﬁrst month after the adoption of the pattern using
Eq. 8. Figure 4 reveals that the burstiness is not correlated with the popularity of each pattern. On the
contrary, even among the top 20 most popular patterns, several learning patterns trigger on average less
than 0.5 follow-up questions. It is also worth noticing that there is a small set of learning patterns which
are much more popular than the rest. In particular, the most popular learning pattern, which is related
to Web design, captures approximatively 12% of the attention of Stack Overﬂow users, and the 20 most
popular learning patterns gather more than 60% of the popularity. Moreover, Figure 4c highlights examples
of learning patterns that are very popular and bursty – Web design; examples of bursty learning patterns
that are not very popular – machine learning; and learning patterns that are not popular nor bursty – UI
libs. Table 1 shows the top-20 most probable words in the seven learning patterns highlighted in Figure 4c.
User behavior.
In this section, we use our model to identify diﬀerent types of users and derive insights
about the learning patterns they use over time, as well as the evolution of their interests. Two natural
questions emerge in this context: (i) Do users stick to just a few learning patterns for all their tasks, or
perhaps they explore a diﬀerent pattern every time they start a task? And, (ii) how long do they commit on
their chosen task?

First, we visualize the inferred intensities for two speciﬁc real users, among the several that we found, in

Figures 6a - 6b. These are examples of two very distinctive behaviors:

– Explorers: They shift over many diﬀerent learning patterns and rarely adopt the same pattern more
than once. For example, the user in Figure 6a adopts over 10 patterns in less than a year, and rarely
adopt the same learning pattern more than once.

– Loyals: They remain loyal to a few learning patterns over the whole observation period. For example,
the user in Figure 6b asks questions associated to two learning patterns over a period of 4 years period
and rarely adopts new learning patterns.

We investigate to which extent we ﬁnd explorers and loyals throughout Stack Overﬂow at large. To this
end, we compute the user base intensities, µu, which can be viewed as the number of new tasks that a user
starts per month, and the distribution of the total number of learning patterns adopted by each user over the
observation period. Figures 5a and 5b summarize the results, showing several interesting patterns. First,
there is a high variability across users in terms of new task rate – while most of users start one to two new
tasks every month, there are users who start up to more than 8 tasks monthly. Second, while approximately
5% of the users remain loyal to at most 5 learning patterns and another 10% of the user explores more than

10

(a) Base intensity µu (tasks/month)

(b) # of adopted patterns per user

(c) Average time in months per task

Figure 5: User behavior: (a) the inferred user base intensities, (b) the number of learning patterns adopted
by the users over the 4 years, and (c) the average time users spent for the completion of their tasks.

25 learning patterns over the 4 years, the average user (∼87%) adopts between 5 and 25 patterns.

Finally, we investigate how long do users commit on their chosen task. To answer this question, we
compute the average time between the initial and the ﬁnal event for each task of our users. Figure 5c show
the distribution of the average time spent per task. Here we observe that while approximatively 10% of the
user tasks are concluded in less than a month, most of the users (over 75% of the users) spend one to four
months to complete a task.

5 Conclusions

In this paper, we proposed a novel probabilistic model, the Hierarchical Dirichlet Hawkes Process (HDHP),
for clustering grouped streaming data. In our application, each group corresponds to a speciﬁc user’s learning
activity. The clusters correspond to learning patterns, characterized by both the content and temporal
information and shared across all users. We then developed an eﬃcient inference algorithm, which scales
linearly with the number of users and learning actions, and accurately recovers both the pattern associated
with each learning user action and the model parameters. Our experiments on large-scale data from Stack
Overﬂow show that the HDHP recovers meaningful learning patterns, both in terms of content and temporal
dynamics, and oﬀers a characterization of diﬀerent user behaviors.

We remark that, the proposed HDHP could be run within the learning platform in an online fashion
to track users’ interest in real time. With this, one could get both a characterization of the diﬀerent user
behaviors, and recommendations on questions that might be of interest at any given time. Finally, although
here we focused on modeling online learning activity data, the proposed HDHP can be easily used to cluster
a wide variety of streaming data, ranging from news articles, in which there is a single stream (group) of
data, to web browsing, where one could identify groups of websites that provide similar services or content.

References

[1] O. Aalen, O. Borgan, and H. Gjessing. Survival and event history analysis: a process point of view. Springer

Science & Business Media, 2008.

[2] A. Ahmed, Q. Ho, C. H. Teo, J. Eisenstein, A. J. Smola, and E. P. Xing. Online Inference for the Inﬁnite

Topic-Cluster Model: Storylines from Streaming Text. In AISTATS, 2011.

[3] A. Ahmed and E. Xing. Dynamic Non-Parametric Mixture Models and The Recurrent Chinese Restaurant

Process : with Applications to Evolutionary Clustering. SDM, 2008.

[4] A.-L. Barabási. The origin of bursts and heavy tails in human dynamics. Nature, 435:207, 2005.

[5] D. M. Blei and P. I. Frazier. Distance dependent chinese restaurant processes. The Journal of Machine Learning

[6] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. The Journal of Machine Learning Research,

Research, 12:2461–2488, Nov. 2011.

3:993–1022, 2003.

[7] O. Cappé, S. J. Godsill, and E. Moulines. An overview of existing methods and recent advances in sequential

monte carlo. Proceedings of the IEEE, 95(5):899–924, 2007.

11

(a) Explorer user

(b) Loyal user

Figure 6: Real-world examples of user behavior. An explorer user (panel (a)), shifts over many diﬀerent
learning patterns over time, while a loyal user (panel (b)) sticks to a small selection of patterns.

[8] C. Carvalho, M. S. Johannes, H. F. Lopes, and N. Polson. Particle learning and smoothing. Statistical Science,

25(1):88–106, 2010.

[9] D. J. Daley and D. Vere-Jones. An introduction to the theory of point processes. Vol. II. Probability and its

Applications (New York). Springer, New York, second edition, 2008.

[10] N. Du, M. Farajtabar, A. Ahmed, A. J. Smola, and L. Song. Dirichlet-hawkes processes with applications to

clustering continuous-time document streams. In ACM SIGKDD, 2015.

[11] M. Farajtabar, N. Du, M. Gomez-Rodriguez, I. Valera, L. Song, and H. Zha. Shaping social activity by incentivizing

[12] T. S. Ferguson. A bayesian analysis of some nonparametric problems. The annals of statistics, pages 209–230,

users. In NIPS, 2014.

1973.

[13] A. G. Hawkes. Spectra of some self-exciting and mutually exciting point processes. Biometrika, 58(1):83–90, 1971.

[14] J. Sethuraman. A constructive deﬁnition of Dirichlet priors. Statistica Sinica, 4:639–650, 1994.

[15] A. Smith, A. Doucet, N. de Freitas, and N. Gordon. Sequential Monte Carlo methods in practice. Springer Science

& Business Media, 2013.

[16] M. A. Stephens. Goodness of ﬁt with special reference to tests for exponentiality. Stanford University, 1978.

[17] Y. W. Teh and M. I. Jordan. Hierarchical Bayesian nonparametric models with applications. In N. Hjort,
C. Holmes, P. Müller, and S. Walker, editors, Bayesian Nonparametrics: Principles and Practice. Cambridge
University Press, 2010.

[18] Y. W. Teh, M. I. Jordan, M. J. Beal, and D. M. Blei. Hierarchical Dirichlet processes. Journal of the American

Statistical Association, 101(476):1566–1581, 2006.

[19] I. Valera and M. Gomez-Rodriguez. Modeling adoption and usage of competing products. In ICDM, 2015.

[20] K. Zhou, H. Zha, and L. Song. Learning triggering kernels for multi-dimensional hawkes processes. In ICML,

2013.

12

Top-20 most probable words in the learning pattern

‘Web design’: jquery javascript html php css ajax jquery-ui json forms arrays asp.net html5 jquery-mobile mysql
dom regex jquery-plugins internet-explorer jquery-selectors wordpress

‘sql’: sql mysql sql-server php sql-server-2008 database tsql oracle postgresql sql-server-2005 database-design join
stored-procedures c# select sqlite sql-server-2008-r2 java performance datetime

‘iOS’: ios objective-c iphone xcode cocoa-touch ipad uitableview cocoa core-data osx ios4 ios5 uiview uitableviewcell
uiviewcontroller ios7 ios6 uinavigationcontroller uiscrollview nsstring

‘Python’: python numpy python-2.7 matplotlib django pandas python-3.x scipy tkinter ﬂask sqlalchemy list arrays
wxpython regex dictionary multithreading osx import google-app-engine

‘Version control’: git svn github version-control mercurial eclipse tortoisesvn merge branch repository ssh bitbucket
xcode git-branch commit git-svn osx windows java gitignore

‘Machine learning’ (ML): matlab python algorithm r machine-learning java matrix plot artiﬁcial-intelligence
numpy arrays image-processing nlp statistics opencv math octave data-mining scikit-learn neural-network

‘UI Libraries’: knockout.js javascript kendo-ui jquery asp.net-mvc knockout-2.0 kendo-grid durandal asp.net-
mvc-4 knockout-mapping-plugin kendo-asp.net-mvc breeze single-page-application typescript mvvm asp.net-mvc-3
data-binding signalr json twitter-bootstrap

Table 1: The 20 most probable words for the seven patterns highlighted in Figure 4c.

Appendix

A Details on the Inference

Given a collection of n observed learning actions performed by the users of an online learning site during
a time period [0, T ), our goal is to infer the learning patterns that these events belong to. To eﬃciently
sample from the posterior distribution, we derive a sequential Monte Carlo (SMC) algorithm that exploits the
temporal dependencies in the observed data to sequentially sample the latent variables associated with each
learning action. In particular, the posterior distribution p(b1:n|t1:n, u1:n, q1:n) is sequentially approximated
with a set of |P| particles, which are sampled from a proposal distribution that factorizes as

q(b1:n|t1:n, u1:n, ω1:n) = q(bn|b1:n−1, t1:n, u1:n, ω1:n)q(b1:n−1|t1:n−1, u1:n−1, ω1:n−1),

where

q(bn|ω1:n, t1:n, u1:n) =

p(ωn|ω1:n−1, b1:n)p(bn|t1:n, u1:n, b1:n−1)
(bn) p(ωn|ω1:n−1, b1:n)p(bn|t1:n, u1:n, b1:n−1)

(cid:80)

(14)

In the above expression, we can exploit the conjugacy between the multinomial and the Dirichlet distributions
to integrate out the word distributions θ(cid:96) and obtain the marginal likelihood

p(ωn|ω1:n−1, b1:n) =

Γ (cid:0)C n−1

(cid:96) + η0|W|(cid:1) (cid:81)
(cid:96) + η0|W|) (cid:81)

Γ (C n

w∈W Γ
(cid:16)

w∈W Γ

C n−1

w,(cid:96) + η0

(cid:16)

C n

w,(cid:96) + η0

(cid:17)

(cid:17) ,

where C n−1
(cid:96)
and C n−1
For each particle p, the importance weight can be iteratively computed as

(cid:96) are the number of words in the pieces of content (or queries) ω1:n−1 and ω1:n, respectively,
w,(cid:96) count the number of times that the w appears in queries ω1:n−1 and ω1:n, respectively.

and C n
w,(cid:96) and C n

n = w(p)
w(p)

n−1p(tn, un|t1:n−1, u1:n−1, b(p)

1:n−1, {α(p)

(cid:96) }L

(cid:96)=1)Q(p)
n ,

(15)

13

Algorithm 1 Inference algorithm for the HDHP
Initialize w(p)
for i = 1, . . . , n do
for p ∈ P do

1 = 1/|P|, K (p) = 0 and L(p) = 0 for all p ∈ P.

for (cid:96) = 1, . . . , L(p) and the user base intensities µ(p)

u for all u ∈ U.

Update the kernel parameters α(p)
Draw b(p)
if b(p)

from (14).

(cid:96)

i

i = K (p) + 1 then
Draw the new task parameters φ(p)
Increase the number of tasks K (p) = K (p) + 1.
if φ(p)
then

= ϕ(p)

K(p)+1

according to (13).

L(p)+1

K(p)+1
Draw the triggering kernel for the new topic α(p)
Increase the total number of learning patterns L(p) = L(p) + 1.

L(p)+1

from the prior.

Update the particle weight w(p)

according to (15).

i

Normalize particle weights.
if (cid:107)wi(cid:107)2
2 < threshold then

Resample particles.

where w(p)

1 = 1/|P| and

Q(p)

n =

p(ωn|ω1:n−1, b1:n)p(bn|t1:n, u1:n, b(p)

1:n−1)

(16)

(cid:88)

(bn)

Since the likelihood term depends on the user base intensities µu and the kernel parameters {α(p)
(cid:96)=1, following
the literature in SMC devoted to the estimation of a static parameter [7, 8], we infer these parameters in an
online manner. In particular, we sample the kernel parameters from their posterior distribution up to, but
not including, time t, and we update the user base intensities at time t as µnew
u + (1 − r)ˆµu, where
ˆµu is the maximum likelihood estimation of this parameter given the user history Hu(t) and r ∈ [0, 1] is a
factor that controls how much the updated parameter µnew

u
Algorithm 1 summarizes the overall inference procedure, which presents complexity O(P(U + L + K) + P)
per learning action i fed to the algorithm, where L and K are the total number of learning patterns and tasks
inferred up to the (i − 1)-th action. Note also that, the for-loop across the particles p ∈ P can be parallelized,
reducing the complexity per learning action to O(U + L + K + P) .

diﬀers from its previous value µold
u .

u = rµold

(cid:96) }L

14

6
1
0
2
 
t
c
O
 
8
1
 
 
]
L
M

.
t
a
t
s
[
 
 
1
v
5
7
7
5
0
.
0
1
6
1
:
v
i
X
r
a

Modeling the Dynamics of Online Learning Activity

Charalampos Mavroforakis∗1, Isabel Valera2, and Manuel Gomez-Rodriguez2

1Boston University, cmav@bu.edu
2Max Planck Institute for Software Systems, ivalera@mpi-sws.org, manuelgr@mpi-sws.org

Abstract

People are increasingly relying on the Web and social media to ﬁnd solutions to their problems in a
wide range of domains. In this online setting, closely related problems often lead to the same characteristic
learning pattern, in which people sharing these problems visit related pieces of information, perform almost
identical queries or, more generally, take a series of similar actions. In this paper, we introduce a novel
modeling framework for clustering continuous-time grouped streaming data, the hierarchical Dirichlet
Hawkes process (HDHP), which allows us to automatically uncover a wide variety of learning patterns
from detailed traces of learning activity. Our model allows for eﬃcient inference, scaling to millions of
actions taken by thousands of users. Experiments on real data gathered from Stack Overﬂow reveal that
our framework can recover meaningful learning patterns in terms of both content and temporal dynamics,
as well as accurately track users’ interests and goals over time.

1

Introduction

Learning has become an online activity – people routinely use a wide variety of online learning platforms,
ranging from wikis and question answering (Q&A) sites to online communities and blogs, to learn about a
large range of topics. In this context, people ﬁnd solutions to their problems by looking for closely related
pieces of information, executing a sequence of queries or, more generally, performing a series of online actions.
For example, a high school student may study several closely related wiki pages to prepare an essay about
a historical event; a software developer may read several answers within a Q&A site to solve a speciﬁc
programming problem; and, a researcher may check a specialized blog written by one of her peers to learn
about a new concept or technique. All the above are examples of learning patterns, in which people perform
a series of online actions – reading a wiki page, an answer, or a blog – to achieve a predeﬁned goal – writing
an essay, solving a programming problem, or learning about a new concept or technique. In this context,
one may expect that people with similar goals undertake similar sequences of online actions and thus adopt
similar learning patterns. Therefore, one could leverage the vast availability of online traces of users’ learning
activity to disambiguate among interleaved learning patterns adopted by individuals over time, as well as to
automatically identify and track those people’s interests and goals over time.

In this work, we introduce a novel probabilistic model, the Hierarchical Dirichlet Hawkes Process
(HDHP), for clustering continuous-time grouped streaming data, which we use to uncover the dynamics
of learning activity on the web. The HDHP leverages the properties of the Hierarchical Dirichlet Process
(HDP) [18], a popular Bayesian nonparametric model for clustering problems involving multiple groups of
data, combined with the Hawkes process [13], a temporal point process particularly well ﬁtted to model
social activity [11, 19, 20]. In particular, the former is used to account for an inﬁnite number of learning
patterns, which are shared across users (groups) of an online learning platform. The latter is used to capture

∗This work was done during the author’s internship at Max Planck Institute for Software Systems.

1

the temporal dynamics of the learning activity, which alternate between bursts of rapidly occurring events
and relatively long periods of inactivity [4].

In more detail, in the case of the HDHP, the learning pattern distribution that determines the content
and temporal parameters of each learning pattern is drawn from a Dirichlet process (DP) [12]. Each user’s
learning activity is modeled as a multivariate Hawkes process, with as many dimensions as the number of
learning patterns (i.e., inﬁnite), whose parameters are given by the DP and thus shared across all the users.
Every time a user decides to perform a new action, she may opt for starting a new task or follow-up on one of
her previous ones. Here, tasks refer to sequences of related actions performed closely in time, which in turn
can be viewed as realizations of learning patterns. Our model allows for an eﬃcient inference algorithm, based
on sequential Monte Carlo [15], which scales to millions of actions and thousands of users. We experiment on
real-world data from Stack Overﬂow, using ∼1.6 million questions performed by 16,000 users over a four year
period. Our results show that our model, taking advantage of the temporal information in the data, does
not only allow us to accurately track users’ interest over time, but also provides more meaningful learning
patterns in terms of content (20% gain in perplexity) compared to the HDP. A Python implementation of the
proposed HDHP is available in GitHub.1
Related work. The Hierarchical Dirichlet Hawkes process (HDHP) can be viewed as a model for clustering
grouped continuous-time streaming data. In our application domain, each group of data corresponds to a
user’s online actions and the clusters correspond to learning patterns, shared across all the users. Therefore,
our work relates, on the one hand, to models for clustering groups of data [6, 17], and, on the other hand, to
models for clustering (single) streaming data [3, 5, 2, 10]. To the best of our knowledge, models for clustering
grouped streaming data are nonexistent to date.

The most popular models for clustering groups of data, the Latent Dirichlet Allocation (LDA) [6] and, its
nonparametric counterpart, the HDP [18], originate from the topic modeling literature. There, each document
is transformed into a bag-of-words and is modeled as a mixture of topics that are shared across all documents.
More generally, models for clustering groups of data typically consider that each observation (word) within a
group (document) is a sample from a mixture model, and the mixture components are shared among groups.
One could use such models to cluster users’ activity on the Web, however observations are assumed to be
exchangeable and thus these models cannot account for the temporal dynamics of learning activity. As a
consequence, they are unable to track users’ interests and goals over time.

Models for clustering streaming data can incorporate temporal dynamics [2, 3], however they can only
handle a single stream of data and thus cannot be used to jointly model several users’ learning activity.
Additionally, most of these models discretize the time dimension into bins [2, 3], introducing additional tuning
parameters, and ignoring the self-excitation across events [5], a phenomenon regularly observed in social
activity data [11]. Perhaps the most closely related work to ours is the recently proposed Dirichlet Hawkes
Process (DHP) [10], a continuous-time model for streaming data that allows for self-excitation. However,
DHP suﬀers from a signiﬁcant limitation: the lack of an underlying DP (or, in fact, any other Bayesian
nonparametric) prior on the cluster distribution compromises the identiﬁability and reproducibility of the
model. Additionally, from the perspective of our application, DHP only allows for single data stream (user)
and enforces clusters to be forgotten after some time. The latter is an overly restrictive assumption, since a
user may perform similar actions, i.e., belonging to the same learning pattern, over widely spaced intervals of
time.

2 Preliminaries

In this section, we brieﬂy review the major building blocks of the Hierarchical Dirichlet Hawkes process
(HDHP): the Hierachical Dirichlet process (HDP) [18] and the Hawkes process [1].

1https://github.com/Networks-Learning/hdhp.py

2

2.1 Hierarchical Dirichlet Process

The HDP is a Bayesian nonparametrics prior, useful for clustering grouped data [18], which allows for an
unbounded number of clusters whose parameters are shared across all the groups. It has been broadly applied
for topic modeling as the nonparametric counterpart of the Latent Dirichlet Allocation (LDA), where the
number of topics is ﬁnite and predeﬁned. More speciﬁcally, this process deﬁnes a hierarchy of Dirichlet
processes (DPs), in which a set of random probability measures Gj ∼ DP (β1, G0) (one for each group of
data) are distributed as DPs with concentration parameter β1 and base distribution G0. The latter is also
distributed as a DP, i.e., G0 ∼ DP (β0, H). In the HDP, the distributions Gj share the same support as G0,
and are conditionally independent given G0.
Chinese Restaurant Franchise. An alternative representation of the HDP is the Chinese Restaurant
Franchise Process (CRFP), which allows us not only to obtain samples from the HDP but also to derive
eﬃcient inference algorithms. The CRFP assumes a franchise with as many restaurants as the groups of data
(e.g., number of documents), where all of the restaurants share the same menu with an inﬁnite number of
dishes (or clusters). In particular, one can obtain samples from the HDP as follows:

1. Initialize the total number of dishes L = 0, and the total number of tables in each restaurant Kr = 0,

for r = 1, . . . , R, with R being the total number of restaurants in the franchise.

2. For each restaurant r = 1, . . . , R:

For customer i = 1, . . . , Nr (Nr is the total number of customers entering restaurant r):
– Sample the table for the i-th customer in restaurant r from a multinomial distribution with probabilities

=
Pr(bri = k)
Pr(bri = Kr + 1) =

nrk
β1+i−1
β1
β1+i−1

for k = 1, . . . , Kr

I(brj = k) is the number of customers seated at the k-th table of the r-th

– If bri = Kr + 1, i.e., the i-th customer sits at a new table, sample its dish from a multinomial

where nrk = (cid:80)i−1
restaurant.

j=1

distribution with probabilities

=
Pr(φr(Kr+1) = ϕ(cid:96))
Pr(φr(Kr+1) = ϕL+1) =

m(cid:96)
K+β0
β0
K+β0

for (cid:96) = 1, . . . , L

j=1 Kj is the total number of tables in the franchise, m(cid:96) = (cid:80)r

where K = (cid:80)r
I(φjk = ϕ(cid:96)) is
the total number of tables serving dish ϕ(cid:96) in the franchise, and ϕL+1 ∼ H(ϕ) is the new dish, i.e.,
the parameters of the new cluster.

(cid:80)Kj
k=1

j=1

– Increase the number of tables in the r-th restaurant Kr = Kr + 1 and, if φrKr = ϕL+1 (i.e., the new
table is assigned to a new dish/cluster), increase also the total number of clusters in the franchise
L = L + 1.

Note that, although in the process above we have generated the data (customers) for each group (restaurant)
sequentially, due to the exchangeability properties of the HDP, the resulting distribution of the data is
invariant to the order at which customers are assumed to enter any of the restaurants [18].

2.2 Hawkes Process

A Hawkes process is a stochastic process in the family of temporal point processes [1], whose realizations
consist of lists of discrete events localized in time, {t1, t2, . . . , tn} with ti ∈ R+. A temporal point process can
be equivalently represented as a counting process, N (t), which records the number of events before time t. The
probability of an event happening in a small time window [t, t + dt) is given by P(dN (t) = 1|H(t)) = λ∗(t)dt,
where dN (t) ∈ {0, 1} denotes the increment of the process, H(t) denotes the history of events up to but not
including time t, λ∗(t) is the conditional intensity function (intensity, in short), and the sign ∗ indicates that
the intensity may depend on the history H(t). In the case of Hawkes processes, the intensity function adopts

(1)

(2)

3

the following form:

λ∗(t) = µ +

(cid:88)

κα(t, ti),

ti∈H(t)

where µ is the base intensity and κα(t, ti) is the triggering kernel, which is parametrized by α. Note that this
intensity captures the self-excitation phenomenon across events and thus allows modeling bursts of activity.
As a consequence, the Hawkes process has been increasingly used to model social activity [11, 19, 20], which
is characterized by bursts of rapidly occurring events separated by long periods of inactivity [4]. Finally, given
the history of events in an observation window [0, T ), denoted by H(T ), we can express the log-likelihood of
the observed data as

LT =

(cid:88)

log λ∗(ti) −

λ∗(τ ) dτ.

(cid:90) T

0

i:ti∈H(T )

3 Learning activity model

In an online learning platform, users ﬁnd solutions to their problems by sequentially looking for closely related
pieces of information within the site, executing a sequence of queries or, more generally, performing a series
of online actions. In this context, one may expect people with similar goals to undertake similar sequences
of actions, which in turn can be viewed as realizations of an unbounded number of learning patterns. Here,
we assume that each action is linked to some particular content and we propose a modeling framework that
characterizes sequences of actions by means of the timestamps as well as the associated content of these
actions. Next, we formulate our model for online learning activity, starting by describing the data it is
designed for.
Learning activity data and generative process. Given an online learning platform with a set of users
U, we represent the learning actions of each user as a triplet

e := (

learning pattern
↓
p ),

time
↓
,
t , ω
↑
content

which means that at time t the user took an action linked to content ω and this action is associated to the
learning pattern p, which is hidden. Then, we denote the history of learning actions taken by each user u up
to, but not including, time t as Hu(t).

u(t) = [λ∗

We represent the times of each user u’s learning actions within the platform as a set of counting processes,
Nu(t), in which the (cid:96)-th entry counts the number of times up to time t that user u took an action associated
to the learning pattern (cid:96). Then, we characterize these counting processes using their corresponding intensities
as E[dNu(t)|Hu(t)] = λ∗
u(t) dt, where dNu(t) = [dNu,(cid:96)(t)](cid:96)∈[L] denotes the number of learning actions in the
time window [t, t + dt) for each learning pattern, λ∗
u,(cid:96)(t)](cid:96)∈[L] denotes the corresponding pattern
intensities, L is the number of learning patterns, and the sign ∗ indicates that the intensities may depend on
the user’s history, Hu(t). Additionally, for each learning action e = (t, ω, p), the content ω is sampled from a
distribution f (ω|p), which depends on the corresponding learning pattern p. Here, in order to account for
an unbounded number of learning patterns, i.e., L → ∞, we assume that the learning pattern distribution
follows a Dirichlet process (DP). Next, we specify the functional form of the user intensity associated to each
learning pattern and the content distribution, and we elaborate further on the learning pattern distribution.
Intensity of the user learning activity. Every time user u performs a learning action, she may opt to
either start a new task, deﬁned as a sequence of learning actions similar in content and performed closely in
time (i.e., a realization of a learning pattern), or to follow-up on an already on-going task. The multivariate
Hawkes process [1], described in Section 2.2, presents itself as a natural choice to model this behavior. This
way, each dimension (cid:96) corresponds to a learning pattern (cid:96) and its associated intensity is given by

(3)

(4)

(5)

(6)

λ∗
u,(cid:96)(t) = µu π(cid:96)
(cid:124) (cid:123)(cid:122) (cid:125)
new task

(cid:122)

+

follow-up
(cid:125)(cid:124)

(cid:88)

(cid:123)
κ(cid:96)(t, tj) .

j:tj ∈Hu(t), pj =(cid:96)

4

(7)

(8)

(9)

(10)

Here, the parameter µu ≥ 0 accounts for the rate at which user u starts new tasks, π(cid:96) ∈ [0, 1] is the probability
that a user adopts learning pattern (cid:96) (referred to as learning pattern popularity from now on), and κ(cid:96)(t, t(cid:48)) is
a nonnegative kernel function that models the decaying inﬂuence of past events in the pattern’s intensity.
Due to convenience in terms of both theoretical properties and model inference, we opt for an exponential
kernel function in the form κ(cid:96)(t, t(cid:48)) = α(cid:96) exp(−ν(t − t(cid:48))), where α(cid:96) controls the self-excitation (or burstiness)
of the Hawkes process and ν controls the decay. Finally, note that we can compute user u’s average intensity
at time t analytically as [11]:

EHu(t)[λ∗

u(t)] =

e(A−νI)t + ν(A − νI)−1 (cid:16)
(cid:104)

e(A−νI)t − I

(cid:17) (cid:105)

µu,

where A = diag([α1, . . . , αL]), µu = [µuπ1, . . . , µuπL](cid:62), I is the identity matrix, and the expectation is taken
over all possible histories Hu(t). We can also compute the expected number of actions performed by user u
until time T as

EHu(T )[Nu(T )] =

EHu(τ )[λ∗

u(τ )] dτ.

(cid:90) T

0
Content distribution. We gather the content associated to each learning action e = (t, ω, p) as a vector
ω, in which each element is a word sampled from a vocabulary W as

ωj ∼ M ultinomial(θp),

where θp is a |W|-length vector indicating the probability of each word to appear in content from pattern p.
Learning pattern parameters.
The distribution of the learning patterns is sampled from a DP,
G0 ∼ DP (β, H), which can be alternatively written as
∞
(cid:88)

G0 =

π(cid:96)δϕ(cid:96),

(cid:96)=1

(cid:96)=1 ∼ GEM (β) is sampled from a stick breaking process [14] and ϕ(cid:96) = {α(cid:96), θ(cid:96)} ∼ H(ϕ).

where π = (π(cid:96))L=∞
Remarks. Overall, the proposed learning activity model, which we refer to as the Hierarchical Dirichlet
Hawkes process (HDHP), is based on a 2-layer hierarchical design. The top layer is a Dirichlet process that
determines the learning pattern distribution, and the bottom layer corresponds to a collection of independent
multivariate Hawkes processes, one per user, with as many dimensions as the number of learning patterns, i.e.,
inﬁnite. In the HDHP, the popularity of each learning pattern, or equivalently the probability of assigning a
new task to it, is constant over time and given by the distribution G0. However, the probability distribution
of the learning patterns for each speciﬁc user evolves continuously over time and directly depends on her
instantaneous intensity. Finally, we remark that, due to the inﬁnite dimensionality of the Hawkes process
that captures the learning activity of each user, sampling or performing inference directly on this model is
intractable. Fortunately, we can beneﬁt from the properties of both the Hawkes and the DP, and propose an
alternative generative process that we can then utilize to eﬃciently obtain samples of the HDHP.

3.1 Tractable model representation

Similarly to the HDP, we can generate samples from the proposed HDHP by following a generative process
similar to the CRFP. To this end, we leverage the properties of the Hawkes process and represent the learning
actions of all the users in the learning platform as a multivariate Hawkes process, with as many dimensions
as the users, from which we sample the user and the timestamp associated to the next learning action. This
action is then assigned to either an existing or a new task with a probability that depends on the history of
that user up to, but not including, the time of the action. When initiating a new task, the associated learning
pattern is sampled from a distribution that accounts for the overall popularity of all the learning patterns.
We ﬁnally sample the action content ω as we discussed previously.

In the process described above, each user can be viewed as a restaurant, each action as a customer, each
task as a table, and each pattern as a dish, as in the original CRFP. Hence, if we assume a set of users U and
vocabulary W for the content, we can generate N learning actions as follows:

5

(11)

(12)

(13)

1. Initialize the total number of tasks K = 0 and the total number of learning patterns L = 0.
2. For n = 1, . . . , N :

(a) Sample the time tn and user un ∈ U for the new action, such that tn > tn−1, as in [19]

(b) Sample the task bn for the new action from a multinomial distribution with probabilities

(tn, un) ∼ Hawkes

µ1 +

κbi(tn, ti)I(ui = 1)










n−1
(cid:80)
i=1

n−1
(cid:80)
i=1

...

µU +

κbi(tn, ti)I(ui = U)










Pr(bn = k)

=

Pr(bn = K + 1) =

λ∗
un ,k(tn)
(tn) ,
λ∗
un
µun
un

(tn)

λ∗

for k = 1, . . . , K

un,k(tn) = (cid:80)n−1

where λ∗
un) is the total intensity of user un at time tn.

i=1 κbi(tn, ti)I(ui = un, bi = k), and λ∗
un

(tn) = µun + (cid:80)n−1

i=1 κbi (tn, ti)I(ui =

(c) If bn = K + 1, assign the new task to a learning pattern with probability

Pr(φK+1 = ϕ(cid:96))

for (cid:96) = 1, . . . , L

Pr(φK+1 = ϕL+1) =

= m(cid:96)
K+β ,
β
K+β

k=1

where m(cid:96) = (cid:80)K
I(φk = ϕ(cid:96)) is the number of tasks assigned to learning pattern (cid:96) across all users,
and ϕL+1 = {αL+1, θL+1} is the set of parameters of the new learning pattern L + 1, which we
sample from αL+1 ∼ Gamma(τ1, τ2) and θL+1 ∼ Dirichlet(η0). Then, increase the number of
tasks K = K + 1 and, if φK+1 = ϕL+1, increase also the number of clusters L = L + 1.

(d) Sample each word in the content ωn from ωn,j ∼ M ultinomial(θbn ).

Remarks. Note that, in the process above, both users and learning patterns are exchangeable. However,
contrary to the CRFP, the generated data consist of a sequence of discrete events localized in time, which
therefore do not satisfy the exchangeability property. Moreover, the complexity of this generative process
diﬀers from the standard CRFP only in two steps. First, it needs to sample the event time and user from
a Hawkes process as in Eq. 11, which can be done in linear time with respect to the number of users [11].
Second, while the CRFP only accounts for the number of customers at each table, the above process needs
to evaluate the intensity associated with each table (see Eq. 12), which can be updated in O(1) using the
properties of the exponential function.

We also want to stress that although the above generative process resembles the one for the Dirichlet
Hawkes process (DHP) [10], they diﬀer in two key factors. First, the DHP can only generate a single sequence
of events, while the above process can generate an independent sequence for each user. Second, the DHP
does not instantiate an explicit prior distribution on the clusters, which results in a lack of identiﬁability and
reproducibility of the model. In other words, new events in the DHP are only allowed to join a new or a
currently active cluster – once a cluster “dies” (i.e., its intensity becomes negligible), no new event can be
assigned to it anymore. As a result, two bursts of events that are similar in content and dynamics but widely
separated in time will be assigned to diﬀerent clusters, leading to multiple copies of the same cluster. In
contrast, our generative process ensures the identiﬁability and reproducibility of the model by placing a DP
prior on the cluster distribution, and using the CRFP to integrate out the learning pattern popularity.

3.2

Inference

Given a collection of N observed learning actions performed by a set of users U during a time period [0, T ),
our goal is to infer the learning patterns that these actions belong to. To eﬃciently sample from the posterior
distribution, similarly to [10], we leverage the generative process described in Section 3.1. We derive a

6

(a) Estimation of µu

(b) Estimation of α(cid:96)

(c) Clustering accuracy

Figure 1: Evaluation of the inference algorithm at recovering the model parameters and latent learning
pattern associated to each learning event on 150k synthetically generated data.

sequential Monte Carlo (SMC) algorithm that exploits the temporal dependencies in the observed data to
sequentially sample the latent variables associated with each learning action. In particular, the posterior
distribution p(b1:N |t1:N , u1:N , ω1:N ) is sequentially approximated with a set of P particles, which are sampled
from a proposal distribution q(b1:N |t1:N , u1:N , ω1:N ). To infer the global parameters, µu and α(cid:96), we follow
the literature in SMC devoted to the estimation of a static parameter [7, 8], and sequentially update the
former by maximum likelihood estimation and the latter by sampling from its posterior distribution. The
inference algorithm, which is detailed in Appendix A, has complexity O(P(U + L + K) + P) per observed
learning action, where L and K are respectively the number of learning patterns and the number of tasks
uncovered up to this action.

4 Experiments

4.1 Experiments on synthetic data

In this section, we experiment with synthetic data and show that our inference algorithm can accurately
recover the model parameters as well as assign each generated learning action to the true learning pattern
given only the times and content of the learning events.
Experimental setup. We assume a set of 200 users, L = 50 learning patterns and a vocabulary of size
|W| = 100. We then sample the base intensity of each user µu from Gamma(10, 0.2), and the learning pattern
popularity vector π from a Dirichlet distribution with concentration parameters equal to 1. For each learning
pattern, we sample the kernel parameter α(cid:96) from Gamma(8, 0.25), we randomly pick 30 words that will be
used by the pattern and sample their distribution from a Dirichlet distribution with parameters equal to
3. We assume a kernel decay of ν = 5. Then, for each user we generate online learning actions from the
corresponding multivariate Hawkes process.
Results. Figure 1 summarizes the results by showing the true and the estimated values of the base intensity
of each user µu and the kernel parameter of each pattern α(cid:96), using a total of 150k events. Moreover, it also
shows the normalized mutual information (NMI) between the true and inferred clusters of actions against the
number of events seen by our inference algorithm. Here, we report the results for the particle which provided
the maximum likelihood, and match the inferred learning patterns to the true ones by maximizing the NMI
score. Our inference algorithm accurately recovers the model parameters and, as expected, using more events
when inferring the model parameters leads to more accurate assignment of events to learning patterns.

4.2 Experiments on real data

In this section, we experiment on real data gathered from Stack Overﬂow, a popular question answering (Q&A)
site, where users can post questions – with topics ranging from C# programming to Bayesian nonparametrics

7

(a) Dynamics

(b) Content

Figure 2: Goodness of ﬁt of the HDHP model in terms of (a) dynamics and (b) content.

– which are, in turn, answered by other users of the site. We infer our proposed HDHP on a large set of
learning actions, and show that the proposed HDHP recovers meaningful learning patterns and allows us to
accurately track users’ interests over time.
Experimental setup. We gather the times and content of all the questions posted by all Stack Overﬂow
users during a four year period, from September 1, 2010 to September 1 2014. Here, we consider each user’s
question as a learning action. The reason for this choice is primarily the availability of public datasets, and,
secondarily, the fact that a question provides clear evidence of the user’s current interest at the time of asking.
By looking only at the questions, we are underestimating the number of actions taken on each task, however,
this bias is shared across all the tasks and, thus, we can still compare the dynamics of diﬀerent patterns in
a sensible way. For each question, we use the set of (up to) ﬁve tags (or keywords) that the user used to
describe her question as the content associated to the learning action. To ensure that the inferred parameters
are reliable and accurate, we only consider users who posted at least 50 questions and tags that were used
in at least 100 questions. After these preprocessing steps, our dataset consists of ∼1.6 million questions
performed by ∼16,000 users, and a vocabulary of ∼31,400 tags. Finally, we run our inference algorithm on
the ﬁrst 45 months of data and evaluate its performance on the last three months, used as held-out set. In
our experiments we set the time scale to be one month, the kernel decay ν = 5 and the number of particles
|P| = 200 particles, which worked well in practice. Our implementation of the SMC algorithms for the
proposed HDHP and the HDP requires, respectively, 71ms and 65ms per question on average, which implies
that accounting for the temporal information in the data leads to an increase in runtime of approximately
10%.
Goodness of ﬁt. We evaluate the goodness of ﬁt of our proposed model on learning activity data, in terms
of both content and temporal dynamics. To this end, we ﬁrst evaluate the performance of the HDHP at
capturing the temporal dynamics of the learning activity and compare it with the standard Hawkes process
that only accounts for the temporal information of the data and, therefore, cannot cluster learning actions
into learning patterns. In the latter, we model the learning activity of each user as an independent univariate
Hawkes process, disregarding the content of each learning action. In other words, for each user, we learn
both a base intensity µ and a self-excitation parameter α, as deﬁned in Eq. 3, per user active in the test
set Utest. In order to compare the performance of the models, we ﬁrst apply the time changing theorem [9],
which states that the integral of the intensity of a point process between two consecutive events (cid:82) ti+1
λ∗
u(t)dt
should conform to the unit-rate exponential distribution. Then, we resort to two goodness of ﬁt tests, the
Kolmogorov-Smirnov and the Anderson-Darling [16], to measure how well the transformed action times ﬁt the
target distribution. Figure 2a summarizes the results by showing the percentage of the users in the held-out
set that each test rejects at a signiﬁcance level of 5%. While the Hawkes process performs slightly better (5%
for the KS-test and 11% for the AD-test) than our model, it does so by using almost 2× more parameters —
2|Utest| ∼ 5k for the Hawkes vs |Utest| + L∗ ∼ 2.7k for the HDHP, where L∗ = 227 is the number of inferred
learning patterns.

ti

8

(a) Machine Learning

(b) Python

(c) Version Control

Figure 3: Three inferred learning patterns in Stack Overﬂow. The top row shows the content associated to
each pattern, in the form of clouds of words, while the bottom row shows two samples of its characteristic
temporal dynamics, by means of the intensities of two users using the pattern.

Second, we focus on evaluating the performance of the HDHP at clustering learning activity, and compare
it with the HDP [18], which only makes use of the content information in the data. We resort to the marginal
likelihood of the inferred parameters evaluated on the held-out set of questions ωi ∈ Dtest, i.e.,

p(ωi|Dtrain, ui, ti) =

p(ωi|Dtrain, (cid:96))p((cid:96)|Dtrain, ui, ti).

L
(cid:88)

(cid:96)=1

Above, the ﬁrst term is deﬁned in the same way for both models. However, for the HDP, the second term
is simply the topic popularity π(cid:96), while for the HDHP it depends on the complete user history up to but
not including ti, i.e., p((cid:96)|Dtrain, ui, ti) ∝ λ∗
ui,(cid:96)(ti) is given by Eq. 6. Figure 2b shows the
log-likelihood values obtained under the proposed HDHP and the HDP on the held-out set. Here, higher
log-likelihood values mean better goodness of ﬁt and, therefore, all the points above the x = y line correspond
to questions that are better captured by the HDHP, which are in turn 60% of the held-out questions.
Additionally, we also compute the perplexity [6] as

ui,(cid:96)(ti), where λ∗

perplexity = exp

−

(cid:26)

(cid:80)

i:ei∈Dtest

log p(ωi|Dtrain)
|Dtest|

(cid:27)

.

The perplexity values for the HDHP and the HDP are 204 and 243, respectively, where here lower perplexity
values mean better goodness of ﬁt. These results show that by modeling temporal information, in addition to
content information, the HDHP ﬁts better the content in the data than the HDP (20% gain in perplexity),
and therefore, it provides more meaningful learning patterns in terms of content.
In this section, our goal is to understand the characteristic properties of the learning
Learning patterns.
patterns that Stack Overﬂow users follow for problem solving. To this end, we ﬁrst pay attention to three
particular examples of learning patterns, ‘Machine Learning’, ‘Python’ and ‘Version Control ’, among the
uncovered L∗ = 227 learning patterns, and investigate their characteristic properties. Figure 3 compares the
above mentioned patterns in terms of content, by means of word clouds, and in terms of temporal dynamics,
by means of the learning pattern intensities associated to two diﬀerent users active on each of the patterns.
Here, we observe that: i) the cloud of words associated to each inferred learning pattern corresponds to
meaningful topics; and ii) despite the stochastic nature of the temporal dynamics, the user intensities within
the same learning pattern tend to exhibit striking similarities in terms of burstiness and periods of inactivity.
For example, we observe that the Machine Learning and Python tasks exhibit much larger bursts of events
than Version Control. A plausible explanation is that version control problems tend to be more speciﬁc and
simple, e.g., resolving a conﬂict while merging versions, and, thus, can be quickly solved with one or just

9

(a) Popularity

(b) Burstiness

(c) Popularity vs. Burstiness

Figure 4: Learning patterns. Panels (a) and (b) show the popularity and burstiness of the top-50 most
popular learning patterns, and panel (c) shows the popularity and burstiness for all the inferred patterns. We
highlight the learning pattern examples in Figure 3, as well as some others from Table 1.

a few questions. On the contrary, a user interested in machine learning or Python may face more complex
problems whose solution requires asking several questions in a relatively short period of time.

Next, we investigate whether more popular learning patterns are also the ones that trigger larger bursts
of events, i.e., the learning patterns that engage users to perform long sequences of closely related learning
actions in shorts period of time. Figure 4 shows the popularity and burstiness of the 50 most popular
learning patterns sorted in decreasing order of popularity, as well as a scatter plot which shows the popularity
against burstiness for all the inferred patterns. Here, we compute the burstiness as the expected number of
learning events triggered by self-excitation during the ﬁrst month after the adoption of the pattern using
Eq. 8. Figure 4 reveals that the burstiness is not correlated with the popularity of each pattern. On the
contrary, even among the top 20 most popular patterns, several learning patterns trigger on average less
than 0.5 follow-up questions. It is also worth noticing that there is a small set of learning patterns which
are much more popular than the rest. In particular, the most popular learning pattern, which is related
to Web design, captures approximatively 12% of the attention of Stack Overﬂow users, and the 20 most
popular learning patterns gather more than 60% of the popularity. Moreover, Figure 4c highlights examples
of learning patterns that are very popular and bursty – Web design; examples of bursty learning patterns
that are not very popular – machine learning; and learning patterns that are not popular nor bursty – UI
libs. Table 1 shows the top-20 most probable words in the seven learning patterns highlighted in Figure 4c.
User behavior.
In this section, we use our model to identify diﬀerent types of users and derive insights
about the learning patterns they use over time, as well as the evolution of their interests. Two natural
questions emerge in this context: (i) Do users stick to just a few learning patterns for all their tasks, or
perhaps they explore a diﬀerent pattern every time they start a task? And, (ii) how long do they commit on
their chosen task?

First, we visualize the inferred intensities for two speciﬁc real users, among the several that we found, in

Figures 6a - 6b. These are examples of two very distinctive behaviors:

– Explorers: They shift over many diﬀerent learning patterns and rarely adopt the same pattern more
than once. For example, the user in Figure 6a adopts over 10 patterns in less than a year, and rarely
adopt the same learning pattern more than once.

– Loyals: They remain loyal to a few learning patterns over the whole observation period. For example,
the user in Figure 6b asks questions associated to two learning patterns over a period of 4 years period
and rarely adopts new learning patterns.

We investigate to which extent we ﬁnd explorers and loyals throughout Stack Overﬂow at large. To this
end, we compute the user base intensities, µu, which can be viewed as the number of new tasks that a user
starts per month, and the distribution of the total number of learning patterns adopted by each user over the
observation period. Figures 5a and 5b summarize the results, showing several interesting patterns. First,
there is a high variability across users in terms of new task rate – while most of users start one to two new
tasks every month, there are users who start up to more than 8 tasks monthly. Second, while approximately
5% of the users remain loyal to at most 5 learning patterns and another 10% of the user explores more than

10

(a) Base intensity µu (tasks/month)

(b) # of adopted patterns per user

(c) Average time in months per task

Figure 5: User behavior: (a) the inferred user base intensities, (b) the number of learning patterns adopted
by the users over the 4 years, and (c) the average time users spent for the completion of their tasks.

25 learning patterns over the 4 years, the average user (∼87%) adopts between 5 and 25 patterns.

Finally, we investigate how long do users commit on their chosen task. To answer this question, we
compute the average time between the initial and the ﬁnal event for each task of our users. Figure 5c show
the distribution of the average time spent per task. Here we observe that while approximatively 10% of the
user tasks are concluded in less than a month, most of the users (over 75% of the users) spend one to four
months to complete a task.

5 Conclusions

In this paper, we proposed a novel probabilistic model, the Hierarchical Dirichlet Hawkes Process (HDHP),
for clustering grouped streaming data. In our application, each group corresponds to a speciﬁc user’s learning
activity. The clusters correspond to learning patterns, characterized by both the content and temporal
information and shared across all users. We then developed an eﬃcient inference algorithm, which scales
linearly with the number of users and learning actions, and accurately recovers both the pattern associated
with each learning user action and the model parameters. Our experiments on large-scale data from Stack
Overﬂow show that the HDHP recovers meaningful learning patterns, both in terms of content and temporal
dynamics, and oﬀers a characterization of diﬀerent user behaviors.

We remark that, the proposed HDHP could be run within the learning platform in an online fashion
to track users’ interest in real time. With this, one could get both a characterization of the diﬀerent user
behaviors, and recommendations on questions that might be of interest at any given time. Finally, although
here we focused on modeling online learning activity data, the proposed HDHP can be easily used to cluster
a wide variety of streaming data, ranging from news articles, in which there is a single stream (group) of
data, to web browsing, where one could identify groups of websites that provide similar services or content.

References

[1] O. Aalen, O. Borgan, and H. Gjessing. Survival and event history analysis: a process point of view. Springer

Science & Business Media, 2008.

[2] A. Ahmed, Q. Ho, C. H. Teo, J. Eisenstein, A. J. Smola, and E. P. Xing. Online Inference for the Inﬁnite

Topic-Cluster Model: Storylines from Streaming Text. In AISTATS, 2011.

[3] A. Ahmed and E. Xing. Dynamic Non-Parametric Mixture Models and The Recurrent Chinese Restaurant

Process : with Applications to Evolutionary Clustering. SDM, 2008.

[4] A.-L. Barabási. The origin of bursts and heavy tails in human dynamics. Nature, 435:207, 2005.

[5] D. M. Blei and P. I. Frazier. Distance dependent chinese restaurant processes. The Journal of Machine Learning

[6] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. The Journal of Machine Learning Research,

Research, 12:2461–2488, Nov. 2011.

3:993–1022, 2003.

[7] O. Cappé, S. J. Godsill, and E. Moulines. An overview of existing methods and recent advances in sequential

monte carlo. Proceedings of the IEEE, 95(5):899–924, 2007.

11

(a) Explorer user

(b) Loyal user

Figure 6: Real-world examples of user behavior. An explorer user (panel (a)), shifts over many diﬀerent
learning patterns over time, while a loyal user (panel (b)) sticks to a small selection of patterns.

[8] C. Carvalho, M. S. Johannes, H. F. Lopes, and N. Polson. Particle learning and smoothing. Statistical Science,

25(1):88–106, 2010.

[9] D. J. Daley and D. Vere-Jones. An introduction to the theory of point processes. Vol. II. Probability and its

Applications (New York). Springer, New York, second edition, 2008.

[10] N. Du, M. Farajtabar, A. Ahmed, A. J. Smola, and L. Song. Dirichlet-hawkes processes with applications to

clustering continuous-time document streams. In ACM SIGKDD, 2015.

[11] M. Farajtabar, N. Du, M. Gomez-Rodriguez, I. Valera, L. Song, and H. Zha. Shaping social activity by incentivizing

[12] T. S. Ferguson. A bayesian analysis of some nonparametric problems. The annals of statistics, pages 209–230,

users. In NIPS, 2014.

1973.

[13] A. G. Hawkes. Spectra of some self-exciting and mutually exciting point processes. Biometrika, 58(1):83–90, 1971.

[14] J. Sethuraman. A constructive deﬁnition of Dirichlet priors. Statistica Sinica, 4:639–650, 1994.

[15] A. Smith, A. Doucet, N. de Freitas, and N. Gordon. Sequential Monte Carlo methods in practice. Springer Science

& Business Media, 2013.

[16] M. A. Stephens. Goodness of ﬁt with special reference to tests for exponentiality. Stanford University, 1978.

[17] Y. W. Teh and M. I. Jordan. Hierarchical Bayesian nonparametric models with applications. In N. Hjort,
C. Holmes, P. Müller, and S. Walker, editors, Bayesian Nonparametrics: Principles and Practice. Cambridge
University Press, 2010.

[18] Y. W. Teh, M. I. Jordan, M. J. Beal, and D. M. Blei. Hierarchical Dirichlet processes. Journal of the American

Statistical Association, 101(476):1566–1581, 2006.

[19] I. Valera and M. Gomez-Rodriguez. Modeling adoption and usage of competing products. In ICDM, 2015.

[20] K. Zhou, H. Zha, and L. Song. Learning triggering kernels for multi-dimensional hawkes processes. In ICML,

2013.

12

Top-20 most probable words in the learning pattern

‘Web design’: jquery javascript html php css ajax jquery-ui json forms arrays asp.net html5 jquery-mobile mysql
dom regex jquery-plugins internet-explorer jquery-selectors wordpress

‘sql’: sql mysql sql-server php sql-server-2008 database tsql oracle postgresql sql-server-2005 database-design join
stored-procedures c# select sqlite sql-server-2008-r2 java performance datetime

‘iOS’: ios objective-c iphone xcode cocoa-touch ipad uitableview cocoa core-data osx ios4 ios5 uiview uitableviewcell
uiviewcontroller ios7 ios6 uinavigationcontroller uiscrollview nsstring

‘Python’: python numpy python-2.7 matplotlib django pandas python-3.x scipy tkinter ﬂask sqlalchemy list arrays
wxpython regex dictionary multithreading osx import google-app-engine

‘Version control’: git svn github version-control mercurial eclipse tortoisesvn merge branch repository ssh bitbucket
xcode git-branch commit git-svn osx windows java gitignore

‘Machine learning’ (ML): matlab python algorithm r machine-learning java matrix plot artiﬁcial-intelligence
numpy arrays image-processing nlp statistics opencv math octave data-mining scikit-learn neural-network

‘UI Libraries’: knockout.js javascript kendo-ui jquery asp.net-mvc knockout-2.0 kendo-grid durandal asp.net-
mvc-4 knockout-mapping-plugin kendo-asp.net-mvc breeze single-page-application typescript mvvm asp.net-mvc-3
data-binding signalr json twitter-bootstrap

Table 1: The 20 most probable words for the seven patterns highlighted in Figure 4c.

Appendix

A Details on the Inference

Given a collection of n observed learning actions performed by the users of an online learning site during
a time period [0, T ), our goal is to infer the learning patterns that these events belong to. To eﬃciently
sample from the posterior distribution, we derive a sequential Monte Carlo (SMC) algorithm that exploits the
temporal dependencies in the observed data to sequentially sample the latent variables associated with each
learning action. In particular, the posterior distribution p(b1:n|t1:n, u1:n, q1:n) is sequentially approximated
with a set of |P| particles, which are sampled from a proposal distribution that factorizes as

q(b1:n|t1:n, u1:n, ω1:n) = q(bn|b1:n−1, t1:n, u1:n, ω1:n)q(b1:n−1|t1:n−1, u1:n−1, ω1:n−1),

where

q(bn|ω1:n, t1:n, u1:n) =

p(ωn|ω1:n−1, b1:n)p(bn|t1:n, u1:n, b1:n−1)
(bn) p(ωn|ω1:n−1, b1:n)p(bn|t1:n, u1:n, b1:n−1)

(cid:80)

(14)

In the above expression, we can exploit the conjugacy between the multinomial and the Dirichlet distributions
to integrate out the word distributions θ(cid:96) and obtain the marginal likelihood

p(ωn|ω1:n−1, b1:n) =

Γ (cid:0)C n−1

(cid:96) + η0|W|(cid:1) (cid:81)
(cid:96) + η0|W|) (cid:81)

Γ (C n

w∈W Γ
(cid:16)

w∈W Γ

C n−1

w,(cid:96) + η0

(cid:16)

C n

w,(cid:96) + η0

(cid:17)

(cid:17) ,

where C n−1
(cid:96)
and C n−1
For each particle p, the importance weight can be iteratively computed as

(cid:96) are the number of words in the pieces of content (or queries) ω1:n−1 and ω1:n, respectively,
w,(cid:96) count the number of times that the w appears in queries ω1:n−1 and ω1:n, respectively.

and C n
w,(cid:96) and C n

n = w(p)
w(p)

n−1p(tn, un|t1:n−1, u1:n−1, b(p)

1:n−1, {α(p)

(cid:96) }L

(cid:96)=1)Q(p)
n ,

(15)

13

Algorithm 1 Inference algorithm for the HDHP
Initialize w(p)
for i = 1, . . . , n do
for p ∈ P do

1 = 1/|P|, K (p) = 0 and L(p) = 0 for all p ∈ P.

for (cid:96) = 1, . . . , L(p) and the user base intensities µ(p)

u for all u ∈ U.

Update the kernel parameters α(p)
Draw b(p)
if b(p)

from (14).

(cid:96)

i

i = K (p) + 1 then
Draw the new task parameters φ(p)
Increase the number of tasks K (p) = K (p) + 1.
if φ(p)
then

= ϕ(p)

K(p)+1

according to (13).

L(p)+1

K(p)+1
Draw the triggering kernel for the new topic α(p)
Increase the total number of learning patterns L(p) = L(p) + 1.

L(p)+1

from the prior.

Update the particle weight w(p)

according to (15).

i

Normalize particle weights.
if (cid:107)wi(cid:107)2
2 < threshold then

Resample particles.

where w(p)

1 = 1/|P| and

Q(p)

n =

p(ωn|ω1:n−1, b1:n)p(bn|t1:n, u1:n, b(p)

1:n−1)

(16)

(cid:88)

(bn)

Since the likelihood term depends on the user base intensities µu and the kernel parameters {α(p)
(cid:96)=1, following
the literature in SMC devoted to the estimation of a static parameter [7, 8], we infer these parameters in an
online manner. In particular, we sample the kernel parameters from their posterior distribution up to, but
not including, time t, and we update the user base intensities at time t as µnew
u + (1 − r)ˆµu, where
ˆµu is the maximum likelihood estimation of this parameter given the user history Hu(t) and r ∈ [0, 1] is a
factor that controls how much the updated parameter µnew

u
Algorithm 1 summarizes the overall inference procedure, which presents complexity O(P(U + L + K) + P)
per learning action i fed to the algorithm, where L and K are the total number of learning patterns and tasks
inferred up to the (i − 1)-th action. Note also that, the for-loop across the particles p ∈ P can be parallelized,
reducing the complexity per learning action to O(U + L + K + P) .

diﬀers from its previous value µold
u .

u = rµold

(cid:96) }L

14

