A Revisit of Sparse Coding Based Anomaly Detection
in Stacked RNN Framework

Weixin Luo∗
ShanghaiTech University
luowx@shanghaitech.edu.cn

Wen Liu∗
ShanghaiTech University
liuwen@shanghaitech.edu.cn

Shenghua Gao†
ShanghaiTech University
gaoshh@shanghaitech.edu.cn

Abstract

Motivated by the capability of sparse coding based
anomaly detection, we propose a Temporally-coherent
Sparse Coding (TSC) where we enforce similar neighbour-
ing frames be encoded with similar reconstruction coefﬁ-
cients. Then we map the TSC with a special type of stacked
Recurrent Neural Network (sRNN). By taking advantage of
sRNN in learning all parameters simultaneously, the non-
trivial hyper-parameter selection to TSC can be avoided,
meanwhile with a shallow sRNN, the reconstruction coef-
ﬁcients can be inferred within a forward pass, which re-
duces the computational cost for learning sparse coefﬁ-
cients. The contributions of this paper are two-fold: i) We
propose a TSC, which can be mapped to a sRNN which
facilitates the parameter optimization and accelerates the
anomaly prediction. ii) We build a very large dataset which
is even larger than the summation of all existing dataset for
anomaly detection in terms of both the volume of data and
the diversity of scenes. Extensive experiments on both a toy
dataset and real datasets demonstrate that our TSC based
and sRNN based method consistently outperform existing
methods, which validates the effectiveness of our method.

1. Introduction

Anomaly detection has been extensively studied in com-
puter vision because of its potential applications in video
surveillance, activity recognition and scene understanding,
etc. An anomaly detection system would greatly reduce hu-
man labor and time. However, anomaly detection is still
an extremely challenging task because of the unbounded
property of anomaly. In real applications, on the one hand,
compared with normal events, anomaly is rare and it is ex-
tremely expensive to collect abnormal events; On the other
hand, it is infeasible to collect all possible abnormal events.
Therefore for a typical anomaly detection dataset, only nor-

∗The authors contributed equally and are listed in alphabetical order.
†Corresponding author.

mal scenarios are given in a training set. To identify whether
an abnormal event occurs, a common approach is to exploit
regular patterns in terms of appearance and motion on the
training set. Any pattern that does not agree with these reg-
ular ones would be classiﬁed as irregular ones.

Dictionary learning based approaches have demon-
strated their success for anomaly detection [17][29].
In
these approaches, learning a dictionary to encode all nor-
mal events on the training set and an abnormal event would
result in a large reconstruction error. However, the opti-
mization of sparse coefﬁcients is extremely time consum-
ing, which becomes the bottleneck of dictionary learning
based anomaly detection approaches. Further, features gov-
ern the performance of anomaly detection, while dictionary
learning based approaches are mainly based on hand-crafted
features, which may not be optimal for video representation.
Recently, in light of the great successes of deep learning in
many computer vision tasks[15][22], it has been introduced
to the anomaly detection. Speciﬁcally, an Auto-Encoder is
learnt on the normal training data under an assumption that
regular data can be reconstructed by themselves while irreg-
ular ones cannot [11]. However, such a solution is based on
a 3D Convolutional Neural Network (ConvNet), while pre-
vious work has shown that extracting appearance and mo-
tion information separately with a two-stream network is a
better solution for feature extraction in videos [7]. Further,
such a solution either takes a video cube as its input, and
regular/irregular frames in this cube may affect the classi-
ﬁcation of each other. To avoid this, video cubes have to
be sampled by centering the cube over all frames, which is
computationally expensive.

In this paper, we propose a sparse coding based approach
for anomaly detection. More speciﬁcally, a dictionary is
learnt to encode regular patterns in terms of appearance, and
features corresponding to normal events be sparsely recon-
structed by this dictionary with a small reconstruction er-
ror. Further, to improve the smoothness of prediction over
neighboring frames, a temporally-coherent term is imposed.
Then we arrive at a Temporally-coherent Sparse Coding
It is interesting that our TSC formu-
(TSC) formulation.

1341

lation can be interpreted as one special stacked Recurrent
Neural Network (sRNN): the optimization of sparse coef-
ﬁcients to an Iterative Soft-thresholding Algorithm(ISTA)
algorithm corresponds with to a stacked network, and the
temporally-coherent term makes the reconstruction coefﬁ-
cients of current frame depend on that of previous frame.
In order to directly optimize the reconstruction coefﬁcients
rather than elaborately choosing the hyper-parameters in
TSC, we propose to optimize all parameters in sRNN si-
multaneously, which avoids the nontrivial hyper-parameter
selection in TSC. In addition, sRNN is a feed-forward net-
work that would greatly accelerate the anomaly prediction
in testing phase.

It is desirable to learn an anomaly detection model which
works well under multiple scenes with multiple view an-
gles. However, almost all existing datasets are not suitable
for such kind of evaluation because of the lack of scene di-
versity. In fact, almost all existing datasets only have con-
tained videos captured by one ﬁxed camera.
In this pa-
per, we build a new dataset, named ShanghaiTech Campus,
for anomaly detection. Rather than deliberately designing
some abnormal events in videos, we use multiple surveil-
lance cameras with different view angles installed at differ-
ent spots, to capture the real events happened in the living
area of our university campus. To the best of our knowl-
edge, it is the largest one in terms of the volume of frames,
scene diversity and the change of view angles. Therefore
this new dataset would greatly facilitate the anomaly detec-
tion in real scenarios.

Contributions: We summarized the contributions of
our work as follow: i) We develop a TSC formulation for
anomaly detection, which can be interpreted as a special
sRNN. With the help of sRNN, the anomaly prediction in
testing phase is greatly accelerated.
ii) We build a new
anomaly detection dataset, which contains more diverse
scenes and pushes the study of anomaly detection towards
the usage in real applications.

2. Related Work

Most previous approaches for anomaly detection are
mainly comprised of two modules: i) Feature extraction; In
this module, we can extract hand-crafted or learnt features
on a training set. ii) Learn a model to characterize the distri-
bution of normal events and classify the outliers of normal
distribution as anomalies.

Feature extraction. Early work utilizes the low-level
trajectory features to represent the regular patterns[24].
these methods are not robust in complex or
However,
crowded scenes.
In order to solve this problem, spatial-
temporal features, such as a histogram of oriented gradi-
ents (HOG)[20], the histogram of oriented ﬂows (HOF)[6],
are widely used. Based on these spatial-temporal features,
Zhang et al. [28] model the normal patterns with a Markov

random ﬁeld (MRF). Adam at al. [1] ﬁt the regular his-
tograms of optical ﬂow in local regions with an exponential
distribution. To represent the local optical ﬂow patterns,
Kim and Grauman [14] utilize a mixture of probabilistic
PCA models.

Model selection and anomaly prediction. Dictionary
learning based approaches are widely used in anomaly
detection[29][17][5][21]. A fundamental assumption of
these methods is that any feature can be linearly represented
as a linear combination of basis of a dictionary which en-
codes regular patterns on the training set. [29][17][5] use
the reconstruction error to determine whether a frame is ab-
normal or not. Ren et al. [21] point out that reconstruction
error, such as least square error, dose not take sparsity term
into consideration, and in fact, it does help the anomaly de-
tection accuracy. To avoid this, Ren et al. [21] propose two
solutions, i.e. maximum coordinate (MC) and non-zero con-
centration(NC), to detect anomaly. However, sparse recon-
struction based methods are usually time-consuming in the
optimization of sparse coefﬁcients. To solve this problem,
Jia et al. [17] propose to discard the sparse constraint and
learn multiple dictionaries to encode the patches at multi-
ple scales, which inevitably brings additional costs in the
training phase.

Deep learning based anomaly detection. Deep learn-
ing approaches have demonstrated its successes for im-
age classiﬁcation [15], object recognition [9], as well as
anomaly detection [11][27]. In [11], Hasan et al. propose
a 3D convolutional Auto-Encoder (Conv-AE) to model the
regular frames, however, 3D convolution cannot character-
ize the spatial and temporal information very well, as shown
in the activity recognition [13]. In light of the capability
of convolutional neural networks (ConvNets) to learn spa-
tial features and the strong capability of recurrent neural
network (RNN) and long short term memory (LSTM) to
model temporal patterns, [3] [19] make attempts to leverage
a convolutional LSTMS Auto-Encoder (ConvLSTM-AE) to
characterize both appearance and motion information. Al-
though RNNs or LSTMs are powerful and effective for pro-
cessing sequential data, they are actually ”black box” whose
internal structures are hard to be interpreted. Recently, Scott
et al. [26] show that a special type of RNN actually en-
forces a sparse constraint on the features. Inspired by the
work of sparse coding based anomaly detection and inter-
pretable RNN, we propose a TSC and its sRNN counterpart
for anomaly detection.

3. Our Approach

Detection

3.1. A Revisit of Sparse Coding Based Anomaly

Sparse coding based anomaly detection aims to learn a
dictionary to encode all normal events with small recon-

2342

struction error [29][17]. Mathematically, denote a feature
corresponding to a normal event as xi, then it is desir-
able that xi can be linearly reconstructed by a dictionary
A with small reconstruction error ǫi, i.e., xi = Aαi + ǫi.
Under the assumption that ǫi ∼ N (0, σ2I), and αi ∼
Laplace(0, 2σ2/λ), we arrive at the following objective
function:

min
A,xi

1
2

kxi − Aαik2

2 + λkαik1

(1)

In this formulation, the ﬁrst term corresponds to a recon-
struction error, and it measures how well the feature can be
reconstructed by the dictionary, and the second term corre-
sponds to a sparsity term, and λ balances the sparsity and
the reconstruction error. Larger λ corresponds to a even
more sparse solution. To avoid trivial solutions of the prob-
lem, usually a L2 norm constraint is imposed on each col-
umn of A: kA(:, j)k ≤ 1. By alternatively optimizing
the dictionary and the sparse coefﬁcients on the training
set [29], the dictionary can be learnt and it encodes all nor-
mal patterns. In the testing phase, when a feature comes in,
we ﬁrst compute the sparse coefﬁcients based on dictionary
A. Then based on its reconstruction error, we can classify
whether it belongs to normal or abnormal events.

3.2. Temporally coherent Sparse Coding (TSC) for

Anomaly Detection

One advantage of sparse coding based anomaly detection
is that it learns a dictionary to encode all normal events with
small reconstruction errors, and an abnormal event would
be associated with a large reconstruction error. However, it
does not consider the temporal coherence between neigh-
boring frames within normal/abnormal events. However,
as shown previous works [17][18], in sparse coding, sim-
ilar features may be encoded as dissimilar sparse codes,
i.e., the locality information is lost. To preserve the sim-
ilarity between the neighboring frames, motivated by the
work [29], we propose a Temporally-coherent Sparse Cod-
ing (TSC). Speciﬁcally, if two neighboring frames are sim-
ilar, it is desirable that their sparse coefﬁcients are simi-
lar too. To achieve this goal, we use the similarity be-
tween neighboring frames to weight the distance between
their sparse coefﬁcients. Speciﬁcally, we denote xt−1 and
xt as features corresponding the (t − 1)-th frame and t-th
frame respectively, and denote the similarity between them
2
as St−1,t = exp(− kxt−xt−1k
), where δ2 = 100 in our ex-
2
periments. It is worth mentioning that since St−1,t would
be multiplied by λ2, therefore, we can set δ to any value
and tune λ2 accordingly. Then we use St−1,t to weight
kαt−αt−1k2
2 and substitutes temporally coherent constraint
into the objective function of sparse coding, we arrive at the
objective function of TSC:

δ2

min
A,αt

T

X
t=1

kxt − Aαtk

2
2+λ1kαtk1 + λ2St,t−1kαt − αt−1k

2
2

(2)

s.t. kA(:, i)k ≤ 1

This objective 2 is not convex. Following the classical op-
timization strategy in sparse coding [2][16], we can alterna-

tively update A and αt (t = {1, . . . , T }).

Optimization of A. When all αt (t = {1, . . . , T }) are
ﬁxed, the objective function corresponding to A can be writ-
ten as follows:

T

min
A

kxt − Aαtk2
2

t=1
X
s.t. kA(:, i)k ≤ 1

(3)

Then, we use a projected gradient descent algorithm to op-
timize A.

Optimization of αt. When A is ﬁxed, we arrive at the fol-
lowing objective function w.r.t. reconstruction coefﬁcients
of all features:
T

kxt − Aαtk

2
2 + λ1kαtk1 + λ2St,t−1kαt − αt−1k

2
2

(4)

min
αt

X
t=1

After that, we update αt (t = {1, . . . , T }) with a Sequential
Iterative Soft-Thresholding Algorithm(SISTA) [26] whose
main steps are algorithm 1. In this algorithm, softb(x) =
max(x − b, 0) = ReLU(x − b), K corresponds to the steps
of ISTA algorithm. γ is a hyper parameter.

Algorithm 1 Sequential iterative soft-thresholding algo-
rithm.
Input: extracted feature x1:T , hyper-parameter λ1, λ2, γ,

initial ˆα0, the steps of ISTA K

1: for t = 1 to T do
2:
3:
4:

t = αt−1

ˆα0
for k = 1 to K do
z = [I − 1
ˆα(k)
t = softλ1/γ(z + St−1,tλ2
end for
αt = ˆαK
t

γ (AT A + St−1,tλ2I)]ˆαk−1
αt−1)

γ

5:
6:
7:
8: end for
9: return α1:T ;

t + 1

γ AT xt

3.3. Interpreting TSC with a Stacked RNN (sRNN)

A traditional RNN is based on an assumption that ht =
f (xt, ht−1), which introduces a recurrent structure. Many
previous works [10][4] show that by stacking multiple
RNNs on top of each other, the performance of classiﬁca-
tion or regression can be further boosted. We denote xt
as an input at time t and denote hk
t as an output of hid-
den nodes in the k-th layer at time t. σb is the nonlin-
ear activation function parameterized by b. In this paper,
we choose σb(x) = softb(x). Mathematically, the stacked
RNN (sRNN) can be written as follows [26]:

h(k)
t =

σb(W (1)h(1)
σb(W (k)h(k)

t−1 + V xt),
t−1 + U (k)h(k−1)

t

(

k = 1,
), k > 1.

(5)

3343

...

...

...

...

...

...

...

...

(a) Vanilla stacked RNN [26]

(b) Stacked RNN couterpart of TSC

Figure 1. The blue boxes represent the input xt of stacked RNNs. The green and orange boxes represent coding vectors αk
circles are similarities between neighboring frames.

t . The yellow

t

The ﬁrst layer accepts the last moment output at the same
layer h1
t−1 and the current moment input xt as its inputs.
Similarly, the rest of the stacked layers accept the last mo-
ment output hk
t−1 at the same layer and the previous layer
output hk−1

at the same moment as their inputs.
By comparing the optimization procedure in Algorithm 1
with stacked RNN, we can see that Equation (2) can be in-
terpreted with sRNN: The K steps in Sequential Iterative
Soft-Thresholding Algorithm correspond to the number of
layers in sRNN. Compared the proposed sRNN to classical
RNN [10], the difference between them is that xt is fed into
to all sRNN layers in our sRNN, while vanilla RNN only
takes xt as its input in the ﬁrst layer. Further, St,t−1 takes
xt and xt−1 as inputs, which means that hk
t also depends on
the input of last moment xt−1. And St,t−1 is the input of
each hidden state hk
t . We illustrate the stacked RNN in our
problem in Figure 1.

More speciﬁcally, the mapping from the variables in

TSC to variables in sRNN in Equation (5) is:

U (k) = I −

(AT A + St−1,tλ2I), k > 1

W (1) = I −

AT A

W (k) =

I, k > 1

λ2
γ
St−1,tλ2
γ
1
γ

V (k) =

AT , k = 1, ..., K

1
γ
b = λ1/γ

h(k)
t = αk
t

3.4. Learning Parameters with Our sRNN

If the number of layers in stacked RNN (K) is very
high, our network is identical with the TSC, which guar-
antees that all αt’s are sparse. Nevertheless, we also

4344

need to choose proper hyper-parameters in TSC to guar-
antee its good performance for anomaly detection. How-
ever, such hyper-parameter selection is nontrivial. Rather
than optimizing the objective in TSC with the ﬁxed hyper-
parameters, we propose to optimize all parameters in sRNN
simultaneously. Speciﬁcally, we optimize parameters in
our sRNN by using an Auto-Encoder way, i.e., we use
the last layer output (hK
t ) of sRNN to reconstruct the in-
put xt with the mapping function parameterized by Z,
i.e., xt = ZhK
t . We denote the parameters in sRNN as
θ = {A, λ1, λ2, Z, α0, γ}. Then we can optimize all pa-
rameters as follows:

min
θ

T

t=1
X

kxt − ZhK

t k2

F + βkθk2
F

(6)

To solve the Equation (6), we use a min-batch based
Stochastic Gradient Descent (SGD) algorithm. Speciﬁ-
cally, we use the RMSPROP [23] based SGD method, and
the weight for weight decay term β = 0.005. Further,
a larger K will inevitably introduces more computational
cost. Therefore, rather than using a very large K, we use a
small one (K=3). As shown in experiments section, such a
shallow architecture achieves much better performance than
all existing methods. Our sRNN has two advantages: i) we
can learn all parameters in sRNN rather than choosing the
hyper-parameters in TSC; ii) the architecture of our sRNN
is not that deep. In the testing phase, we can get αt = hK
t
in one forward pass, which greatly accelerates anomaly de-
tection.

3.5. Multiple Patches Sampled at Multiple Scales

Sampling multiple patches at multiple scales has been
shown to be a very effective way for improving the anomaly
detection [17]. We also use the same strategy. Speciﬁcally,
in our work, we use the spatial ConvNet pretrained on the
UCF101 dataset to extract spatial features for each frame,

and the size of output feature map is 7×7×2048 ∗. Then we
gradually partition the feature map into increasingly ﬁner
regions: 1×1, 2×2, and 4×4. We use the max pooling over
each subregion. So the feature dimension of all subregions
are the same, i.e., 2048. Rather than learning multiple dic-
tionaries for features at different scales [17], which brings
additional computational cost, features at all scales share
the same dictionary in our method. For the features at mul-
tiple scales, we only enforce a temporal coherent constraint
for features at the same scale and same spatial location.

3.6. Anomaly Detection on Testing Set

In training phase, we can learn the dictionary A which
well encodes the normal events. In testing phase, we feed
the feature of each patch corresponding to time t into our
special sRNN, and with one forward pass, we can get the αt.
So we can calculate the reconstruction error corresponding
to patch xt: l(t) = kxt − Aαtk2
2. Then, we pick the max-
imum reconstruction error among all patches within this
frame as the frame level reconstruction error. Following the
work [11][3], after calculating all frame level reconstruc-
tion errors for all testing videos, we normalize the errors to
range [0, 1], and calculate regularity score for each frame
based on the following equation:

• CUHK Avenue [17] dataset contains 16 training videos
and 21 testing videos with a total of 47 abnormal
events, including throwing objects, loitering and run-
ning. The size of people may change because of the
camera position and angle.

• UCSD Pedestrian 1 (Ped1) [18] dataset includes 34
training videos and 36 testing videos with 40 irregular
events. All of these abnormal cases are about vehicles
such as bicycles and cars. Pedestrian 2 (Ped2) [18]
dataset contains 16 training videos and 12 testing
videos with 12 abnormal events. The deﬁnition of
anomaly for Ped2 is the same with Ped1.

• Subway [1] dataset are 2 hours long in total. There
are two categories, i.e. Entrance and Exit. Unusual
events contain walking in wrong directions and loi-
tering. More importantly, this dataset is recorded in
indoor environment while above ones are recorded in
outdoor environment.

• Our new proposed dataset has 13 scenes with complex
It contains 130
light conditions and camera angles.
abnormal events and over 270, 000 training frames.
Moreover, pixel level ground truth of abnormal events
is also annotated in our dataset.

s(t) = 1 −

l(t) − mint l(t)
maxt l(t) − mint l(t)

(7)

We show some samples of our dataset to Figure 2 and

some statistics of different datasets to Table 1.

Smaller s(t) means the t-th frame is more likely corre-
sponding to an abnormal event.

5. Experiments

4. ShanghaiTech Campus Dataset

It is desirable that the anomaly detection model trained
can be directly applied in multiple scenes with multiple
view angles. However, almost all existing datasets only
contain videos captured with one ﬁxed angle camera, and it
lacks diversity of scenes and view angles. To increase scene
diversity, we build a new anomaly detection dataset. To the
best of our knowledge, it is the biggest one for anomaly
detection, and it is even bigger than the summarization of
all existing datasets in terms of the volume of data and the
diversity of scenes. Further we introduce the anomalies
caused by sudden motion in this dataset, such as chasing
and brawling in our dataset, which are not included in exist-
ing datasets. These characteristics make our dataset more
suitable in real scenarios. To better understand the dif-
ferences between our dataset and existing anomaly detec-
tion datasets, we brieﬂy summarize all anomaly detection
datasets as follows:

∗Similar to the work in Conv-AE [11], we also ﬁnd that the mo-
tion feature, such as optical ﬂow or CNN feature extracted from optical
ﬂow [12] does not help the anomaly prediction.

In this paper, we ﬁrst empirically evaluate our proposed
method under a controlled setting on a synthesized dataset,
then we compare our method with other state-of-the-art
methods on real anomaly detection datasets. Different pa-
rameters in TSC and sRNN are also empirically evaluated.
All codes and dataset will be released ∗.

5.1. Experimental Setup

Parameters.
In our experiments, for real anomaly detec-
tion dataset, the dimensionality of feature is 2048, and we
ﬁx the size of dictionary A to 2048 × 2048. For TSC, we
set λ1, λ2, γ to 0.2, 2.0, and 1, respectively. For sRNN, we
set K = 3. We set the length of each video clip T to 10
frames.

Measurements. We can predict whether abnormal event
occurs based on s(t). One can set a threshold and if the
score of the frame is smaller than the threshold, the frame
can be categorized to an abnormal case. Obviously a higher
threshold may cause a higher false negative ratio, while a
lower one may lead to more false alarms. By changing the

∗https://github.com/StevenLiuWen/sRNN TSC Anomaly Detection

5345

UCSD Ped1 Ped2

CUHK Avenue

Subway Enter/Exit

(cid:28610)(cid:28643)(cid:28646)(cid:28641)(cid:28629)(cid:28640)(cid:28637)(cid:28648)(cid:28653)

(cid:28597)(cid:28642)(cid:28643)(cid:28641)(cid:28629)(cid:28640)(cid:28653)

(cid:28610)(cid:28643)(cid:28646)(cid:28641)(cid:28629)(cid:28640)(cid:28637)(cid:28648)(cid:28653)

(cid:28597)(cid:28642)(cid:28643)(cid:28641)(cid:28629)(cid:28640)(cid:28653)

Our dataset

Figure 2. Some samples from our new proposed dataset and other datasets. The ﬁrst row represents some samples from the UCSD Ped1,
UCSD Ped2, CUHK Avenue and Subway Entrance and Subway Exit datasets, respectively. The second row represents normal scenes from
our proposed dataset (ShanghaiTech Campus). The third row stands for the related abnormal cases where green dots are abnormal regions.

Table 1. Comparision of our dataset with other released datasets.

#Frames

#Abnormal Events

#Scenes

Dataset

Our Dataset
CUHK Avenue
UCSD Ped2
UCSD Ped1
Subway Entrance
Subway Exit

Total
317,398
30,652
4,560
14,000
136,524
72,401

Training
274,515
15,328
2,550
6,800
20,000
7,500

Testing
42,883
15,324
2,010
7,200
116,524
64,901

Regularity
300,308
26,832
2,924
9,995
134,124
71,681

Irregularity
17,090
3,820
1,636
4,005
2,400
720

130
47
12
40
66
19

13
1
1
1
1
1

threshold gradually, we can arrive at a ROC curve. The Area
Under Curve(AUC) is a commonly used measurement for
detecting irregularity [18]. In this paper, we use frame-level
AUC to evaluate the performance of different methods.

5.2. Evaluate with a Synthesized Dataset

To evaluate the performance of our method for the
anomaly caused by a sudden change of appearance, we de-
ploy experiments on a synthesized Moving-MNIST dataset.
Speciﬁcally, we randomly choose two digits from the
MNIST dataset, and put them in the center of a black image
whose size is 225×225 pixels. Then in the next 19 frames,
the digits randomly moving horizontally or vertically.
In
this way, we can get a sequence with 20 frames. In our ex-

(cid:49)(cid:82)(cid:85)(cid:80)(cid:68)(cid:79)(cid:76)(cid:87)(cid:92)

(cid:36)(cid:81)(cid:82)(cid:80)(cid:68)(cid:79)(cid:92)

(cid:72)
(cid:85)
(cid:82)
(cid:70)
(cid:54)

(cid:41)(cid:68)(cid:79)(cid:86)(cid:72)(cid:3)(cid:68)(cid:79)(cid:68)(cid:85)(cid:80)(cid:11)(cid:38)(cid:82)(cid:81)(cid:89)(cid:16)(cid:36)(cid:40)(cid:12)

(cid:6)(cid:41)(cid:85)(cid:68)(cid:80)(cid:72)(cid:86)

Figure 3. A sample on the Moving-MNIST dataset.

periments, we synthesize 10,000 sequences for training data
and train the network. For each testing sequence, 5 consec-
utive frames are randomly occluded by randomly inserting

6346

a 3×3 white box. We generate 3,000 sequences in total as
testing data. Then we use the intensity of the images as
features and normalized it with L2 normalization.

Our model achieves 86.52% and Conv-AE achieves
74.3%, which illustrates that our method signiﬁcantly out-
performs Conv-AE in terms of AUC. We also show the
curve of s(t) w.r.t. different events in Figure 3. We can
see that our method achieves a more smooth prediction.

5.3. Evaluation with Real Anomaly Datasets

We also evaluate both TSC based and sRNN based
methods on real datasets. Speciﬁcally, we conduct exper-
iments on our own dataset as well as two recently most
used datasets, including CUHK Avenue [17] and UCSD
Ped2 [18] ∗.

We list the performance of different methods on these
datasets in Table 2. It clearly shows that both our methods
outperform all existing methods, including ConvAE [11]
and Del et al. [8] which are recently proposed methods
which achieve state-of-the-art performance for anomaly de-
tection. Speciﬁcally, since our dataset contains multiple
scenes, which makes our dataset more realistic and chal-
lenging. On this dataset, our TSC based method outper-
forms Conv-AE by about 6% in terms of AUC. On the Ped2
dataset, the improvement of our TSC outperforms Conv-
AE by more than 10%. The improvement is obvious. Fur-
ther, by comparing TSC and sRNN, we can see that per-
formance of sRNN is even better than that of TSC. How-
ever, for sRNN, we don’t need to elaborately choose hyper-
parameters, and the testing phase is more sufﬁcient than
TSC.

Table 2. AUC of different methods on the Avenue, Ped2 and our
dataset (ShanghaiTech Campus).

MPPCA [18]
MPPC+SFA [18]
HOFME [25]
Conv-AE [11]
Del et al. [8]
TSC
sRNN

Ped2
Avenue
69.3%
N/A
61.3%
N/A
87.5%
N/A
81.1%
74.5%
N/A
78.3%
80.56%
91.03%
81.71% 92.21%

Our dataset
N/A
N/A
N/A
60.85%
N/A
67.94%
68.00%

We also compare our sRNN with LSTM based Auto-
Encoder where the same features are used, and ConvLSTM
based Auto-Encoder which extracts features with ConvL-

∗The reason for not using the subway dataset because different ground
truth is annotated in different work [17][11], and different ground truth
favors the performance evaluation of different methods. As for UCSD
pedestrain datasets, Ped1 is more frequently used for pixel-wise anomaly
detection [27] and our work focuses on frame-level prediction, so we only
conduct experiments on Ped2.

STM from raw pixels. The AUC of these methods on Av-
enue and Ped2 is listed in Table 3: We can see that our
sRNN also outperforms these baselines.

Table 3. AUC of two baselines on the Avenue and Ped2.

LSTM-AE
ConvLSTM-AE
sRNN

Avenue
75.33%
77.00%
81.71%

Ped2
83.62%
88.10%
92.21%

Finally, we show the change of score (s(t)), similarities
between neighboring frames (St,t−1), distances between
sparse codes of neighboring frames (kαt − αt−1k) for some
normal and abnormal events on the Ped2 dataset in Figure 3.
We can see that a smooth similarity and distance can be
found for the frames within the normal or abnormal events,
which agrees with the motivation of our TSC.

5.4. The Effect of Different Hyper Parameters

Weight of Sparsity Term(λ1). λ1 in Equation (2) con-
trols the sparsity of αt. As shown in Algorithm 1, αk
t is op-
timized based on a soft-thresholding operator. The bigger
λ1 is, the more sparse αt will be. We ﬁx λ2 and dictionary
size to 2.0 and 2048 × 2048, respectively, and change λ1
to observe how this parameter affect AUC on ped2 and Av-
enue. As shown in ﬁgure 5(a), bigger λ1 does not always
improve the AUC for both datasets.

Weight of Temporally-coherent Term (λ2). λ2 in Equa-
tion (2) controls the smoothness of the sparse codes be-
tween neighboring frames. Figure 5(b) demonstrates that
a small λ2 would harm the AUC for both the Avenue and
Ped2 datasets.

Dictionary Size. We show the change of the TSC perfor-
mance w.r.t.
the change of dictionary size on the Avenue
dataset in Figure 5(c). We can see that a larger dictionary
can not always improve AUC and the optimal dictionary
size varies from different datasets.

Number of Layers in Stacked RNN. The optimization
of SISTA algorithm requires a very large K to achieve a
sparse solution with a small reconstruction error. Fewer it-
erative steps may harm the optimization of TSC. Larger K
means a deeper sRNN is needed for its TSC counterpart.
However, a very deep sRNN may lead to gradient vanish-
ing or explosion, which is harder to optimize. To validate
how K affect the performance of our sRNN, we set it to 3
and 30, respectively. The sparsity (percentage of zero en-
tries) of 3 layers based sRNN and that of 30 layers based
sRNN is 80.0% and 92.7%, respectively, while the AUC for
3 layers based sRNN and 30 layers based sRNN is 91.03%

7347

Figure 4. Scores, similarities and distances between neighboring frames for a video sample on Ped2. We can see that the similarities
between neighboring frames can be kept for normal events. We highlight the abnormal events with red boxes. (Best viewed in color)

0.90

0.85

C
U
A

0.80

0.75

Avenue
Ped2

(a) AUC versus λ1

(b) AUC versus λ2
Figure 5. The change of AUC w.r.t. λ1, λ2 and the size of dictionary. (Best viewed in color)

1000

2000

3000
Dictionary Size (λ1 = 0.1, λ2 = 1.0)
(c) AUC versus dictionary size

4000

5000

and 88.10%, respectively. This experiment shows that spar-
sity does not necessarily lead better performance in sRNN.
In our experiments, we set K = 3 for all datasets. Such a
shallow architecture also accelerates the inference of αt(ht)
in testing phase.

5.5. Running Time

Our sRNN model takes about one hour to train on Av-
enue for 10,000 steps.It takes about 0.02s for anomaly de-
tection of a frame. While the prediction of a frame for a
TSC based method is about 10 times slower than that of
sRNN if we set K = 30 in SISTA algorithm. Therefore,
our sRNN is an effective and efﬁcient solution for anomaly
detection.

6. Conclusion

In this paper, we propose a TCS framework for anomaly
detection which preserves the similarities between the
frames within the normal/abnormal events. Our TCS can
be interpreted with a special sRNN. By optimizing all pa-
rameters in sRNN simultaneously, we can avoid the nontriv-
ial parameter selection, and reduce the computational cost
for inferring the reconstruction coefﬁcients in testing phase.
Considering the fact that most anomaly detection datasets
only contain one scene with the same view angle, we build
a datasets which is the most challenging one in terms of
data volume and scene diversity. Extensive experiments on
both a synthesized dataset and real datasets validate the ef-
fectiveness of our TCS and sRNN methods.
Acknowledgements. This work was supported by
NSFC (No. 61502304).

8348

[18] V. Mahadevan, W. Li, V. Bhalodia, and N. Vasconcelos.
In CVPR, volume

Anomaly detection in crowded scenes.
249, page 250, 2010.

[19] J. R. Medel and A. Savakis. Anomaly detection in video
using predictive convolutional long short-term memory net-
works. arXiv preprint arXiv:1612.00390, 2016.

[20] N. Navneet and B. Triggs. Histograms of oriented gradients
for human detection. In Computer Vision and Pattern Recog-
nition, 2005. CVPR 2005. IEEE Computer Society Confer-
ence on, volume 1, pages 886–893. IEEE, 2005.

[21] H. Ren, H. Pan, S. I. Olsen, and T. B. Moeslund. A com-
prehensive study of sparse codes on abnormality detection.
arXiv preprint arXiv:1603.04026, 2016.

[22] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards
real-time object detection with region proposal networks. In
NIPS, pages 91–99, 2015.

[23] T. Tieleman and G. E. Hinton. Lecture 6.5-rmsprop: Divide
the gradient by a running average of its recent magnitude. In
COURSERA: Neural Networks for Machine Learning, 2012.
[24] F. Tung, J. S. Zelek, and D. A. Clausi. Goal-based trajec-
tory analysis for unusual behaviour detection in intelligent
surveillance. Image and Vision Computing, 29(4):230–240,
2011.

[25] T. Wang and H. Snoussi. Histograms of optical ﬂow orienta-
tion for abnormal events detection. In Performance Evalua-
tion of Tracking and Surveillance (PETS), 2013 IEEE Inter-
national Workshop on, pages 45–52. IEEE, 2013.

[26] S. Wisdom, T. Powers, J. Pitton, and L. Atlas. Interpretable
recurrent neural networks using sequential sparse recovery.
arXiv preprint arXiv:1611.07252, 2016.

[27] D. Xu, E. Ricci, Y. Yan, J. Song, and N. Sebe. Learning deep
representations of appearance and motion for anomalous
event detection. arXiv preprint arXiv:1510.01553, 2015.
[28] D. Zhang, D. Gatica-Perez, S. Bengio, and I. McCowan.
Semi-supervised adapted hmms for unusual event detection.
In CVPR, volume 1, pages 611–618. IEEE, 2005.

[29] B. Zhao, F. Li, and E. P. Xing. Online detection of unusual
events in videos via dynamic sparse coding. In CVPR, pages
3313–3320. IEEE, 2011.

References

[1] A. Adam, E. Rivlin, I. Shimshoni, and D. Reinitz. Ro-
bust real-time unusual event detection using multiple ﬁxed-
location monitors. TPAMI, 30(3):555–560, 2008.

[2] M. Aharon, M. Elad, and A. Bruckstein. rmk-svd: An al-
gorithm for designing overcomplete dictionaries for sparse
IEEE Transactions on signal processing,
representation.
54(11):4311–4322, 2006.

[3] Y. S. Chong and Y. H. Tay. Abnormal event detection in
arXiv preprint

videos using spatiotemporal autoencoder.
arXiv:1701.01546, 2017.

[4] J. Chung, C. G¨ulc¸ehre, K. Cho, and Y. Bengio. Gated feed-
back recurrent neural networks. In ICML, pages 2067–2075,
2015.

[5] Y. Cong, J. Yuan, and J. Liu. Sparse reconstruction cost
for abnormal event detection. In Computer Vision and Pat-
tern Recognition (CVPR), 2011 IEEE Conference on, pages
3449–3456. IEEE, 2011.

[6] N. Dalal, B. Triggs, and C. Schmid. Human detection using
In European
oriented histograms of ﬂow and appearance.
conference on computer vision, pages 428–441. Springer,
2006.

[7] C. Feichtenhofer, A. Pinz, and A. Zisserman. Convolu-
tional two-stream network fusion for video action recogni-
tion. arXiv preprint arXiv:1604.06573, 2016.

[8] A. D. Giorno, J. A. Bagnell, and M. Hebert. A discriminative
framework for anomaly detection in large videos. In ECCV,
pages 334–349. Springer, 2016.

[9] R. Girshick. Fast r-cnn. In Proceedings of the IEEE Inter-
national Conference on Computer Vision, pages 1440–1448,
2015.

[10] A. Graves, A. Mohamed, and G. Hinton. Speech recognition
In Acoustics, speech
with deep recurrent neural networks.
and signal processing (icassp), 2013 ieee international con-
ference on, pages 6645–6649. IEEE, 2013.

[11] M. Hasan, J. Choi, J. Neumann, A. K. Roy-Chowdhury,
and L. S. Davis. Learning temporal regularity in video se-
quences. In CVPR, 2016.

[12] B. K. Horn and B. G. Schunck. Determining optical ﬂow.

Artiﬁcial intelligence, 17(1-3):185–203, 1981.

[13] S. Ji, W. Xu, M. Yang, and K. Yu. 3d convolutional neural

networks for human action recognition. TPAMI.

[14] J. Kim and K. Grauman. Observe locally, infer globally: a
space-time mrf for detecting abnormal activities with incre-
In Computer Vision and Pattern Recogni-
mental updates.
tion, 2009. CVPR 2009. IEEE Conference on, pages 2921–
2928. IEEE, 2009.

[15] A. Krizhevsky, I. Sutskever, and G. E. Hinton.

classiﬁcation with deep convolutional neural networks.
NIPS, pages 1097–1105, 2012.

Imagenet
In

[16] H. Lee, A. Battle, R. Raina, and A. Y. Ng. Efﬁcient sparse
coding algorithms. Advances in neural information process-
ing systems, 19:801, 2007.

[17] C. Lu, J. Shi, and J. Jia. Abnormal event detection at 150 fps
in matlab. In Proceedings of the IEEE International Confer-
ence on Computer Vision, pages 2720–2727, 2013.

9349

A Revisit of Sparse Coding Based Anomaly Detection
in Stacked RNN Framework

Weixin Luo∗
ShanghaiTech University
luowx@shanghaitech.edu.cn

Wen Liu∗
ShanghaiTech University
liuwen@shanghaitech.edu.cn

Shenghua Gao†
ShanghaiTech University
gaoshh@shanghaitech.edu.cn

Abstract

Motivated by the capability of sparse coding based
anomaly detection, we propose a Temporally-coherent
Sparse Coding (TSC) where we enforce similar neighbour-
ing frames be encoded with similar reconstruction coefﬁ-
cients. Then we map the TSC with a special type of stacked
Recurrent Neural Network (sRNN). By taking advantage of
sRNN in learning all parameters simultaneously, the non-
trivial hyper-parameter selection to TSC can be avoided,
meanwhile with a shallow sRNN, the reconstruction coef-
ﬁcients can be inferred within a forward pass, which re-
duces the computational cost for learning sparse coefﬁ-
cients. The contributions of this paper are two-fold: i) We
propose a TSC, which can be mapped to a sRNN which
facilitates the parameter optimization and accelerates the
anomaly prediction. ii) We build a very large dataset which
is even larger than the summation of all existing dataset for
anomaly detection in terms of both the volume of data and
the diversity of scenes. Extensive experiments on both a toy
dataset and real datasets demonstrate that our TSC based
and sRNN based method consistently outperform existing
methods, which validates the effectiveness of our method.

1. Introduction

Anomaly detection has been extensively studied in com-
puter vision because of its potential applications in video
surveillance, activity recognition and scene understanding,
etc. An anomaly detection system would greatly reduce hu-
man labor and time. However, anomaly detection is still
an extremely challenging task because of the unbounded
property of anomaly. In real applications, on the one hand,
compared with normal events, anomaly is rare and it is ex-
tremely expensive to collect abnormal events; On the other
hand, it is infeasible to collect all possible abnormal events.
Therefore for a typical anomaly detection dataset, only nor-

∗The authors contributed equally and are listed in alphabetical order.
†Corresponding author.

mal scenarios are given in a training set. To identify whether
an abnormal event occurs, a common approach is to exploit
regular patterns in terms of appearance and motion on the
training set. Any pattern that does not agree with these reg-
ular ones would be classiﬁed as irregular ones.

Dictionary learning based approaches have demon-
strated their success for anomaly detection [17][29].
In
these approaches, learning a dictionary to encode all nor-
mal events on the training set and an abnormal event would
result in a large reconstruction error. However, the opti-
mization of sparse coefﬁcients is extremely time consum-
ing, which becomes the bottleneck of dictionary learning
based anomaly detection approaches. Further, features gov-
ern the performance of anomaly detection, while dictionary
learning based approaches are mainly based on hand-crafted
features, which may not be optimal for video representation.
Recently, in light of the great successes of deep learning in
many computer vision tasks[15][22], it has been introduced
to the anomaly detection. Speciﬁcally, an Auto-Encoder is
learnt on the normal training data under an assumption that
regular data can be reconstructed by themselves while irreg-
ular ones cannot [11]. However, such a solution is based on
a 3D Convolutional Neural Network (ConvNet), while pre-
vious work has shown that extracting appearance and mo-
tion information separately with a two-stream network is a
better solution for feature extraction in videos [7]. Further,
such a solution either takes a video cube as its input, and
regular/irregular frames in this cube may affect the classi-
ﬁcation of each other. To avoid this, video cubes have to
be sampled by centering the cube over all frames, which is
computationally expensive.

In this paper, we propose a sparse coding based approach
for anomaly detection. More speciﬁcally, a dictionary is
learnt to encode regular patterns in terms of appearance, and
features corresponding to normal events be sparsely recon-
structed by this dictionary with a small reconstruction er-
ror. Further, to improve the smoothness of prediction over
neighboring frames, a temporally-coherent term is imposed.
Then we arrive at a Temporally-coherent Sparse Coding
It is interesting that our TSC formu-
(TSC) formulation.

1341

lation can be interpreted as one special stacked Recurrent
Neural Network (sRNN): the optimization of sparse coef-
ﬁcients to an Iterative Soft-thresholding Algorithm(ISTA)
algorithm corresponds with to a stacked network, and the
temporally-coherent term makes the reconstruction coefﬁ-
cients of current frame depend on that of previous frame.
In order to directly optimize the reconstruction coefﬁcients
rather than elaborately choosing the hyper-parameters in
TSC, we propose to optimize all parameters in sRNN si-
multaneously, which avoids the nontrivial hyper-parameter
selection in TSC. In addition, sRNN is a feed-forward net-
work that would greatly accelerate the anomaly prediction
in testing phase.

It is desirable to learn an anomaly detection model which
works well under multiple scenes with multiple view an-
gles. However, almost all existing datasets are not suitable
for such kind of evaluation because of the lack of scene di-
versity. In fact, almost all existing datasets only have con-
tained videos captured by one ﬁxed camera.
In this pa-
per, we build a new dataset, named ShanghaiTech Campus,
for anomaly detection. Rather than deliberately designing
some abnormal events in videos, we use multiple surveil-
lance cameras with different view angles installed at differ-
ent spots, to capture the real events happened in the living
area of our university campus. To the best of our knowl-
edge, it is the largest one in terms of the volume of frames,
scene diversity and the change of view angles. Therefore
this new dataset would greatly facilitate the anomaly detec-
tion in real scenarios.

Contributions: We summarized the contributions of
our work as follow: i) We develop a TSC formulation for
anomaly detection, which can be interpreted as a special
sRNN. With the help of sRNN, the anomaly prediction in
testing phase is greatly accelerated.
ii) We build a new
anomaly detection dataset, which contains more diverse
scenes and pushes the study of anomaly detection towards
the usage in real applications.

2. Related Work

Most previous approaches for anomaly detection are
mainly comprised of two modules: i) Feature extraction; In
this module, we can extract hand-crafted or learnt features
on a training set. ii) Learn a model to characterize the distri-
bution of normal events and classify the outliers of normal
distribution as anomalies.

Feature extraction. Early work utilizes the low-level
trajectory features to represent the regular patterns[24].
these methods are not robust in complex or
However,
crowded scenes.
In order to solve this problem, spatial-
temporal features, such as a histogram of oriented gradi-
ents (HOG)[20], the histogram of oriented ﬂows (HOF)[6],
are widely used. Based on these spatial-temporal features,
Zhang et al. [28] model the normal patterns with a Markov

random ﬁeld (MRF). Adam at al. [1] ﬁt the regular his-
tograms of optical ﬂow in local regions with an exponential
distribution. To represent the local optical ﬂow patterns,
Kim and Grauman [14] utilize a mixture of probabilistic
PCA models.

Model selection and anomaly prediction. Dictionary
learning based approaches are widely used in anomaly
detection[29][17][5][21]. A fundamental assumption of
these methods is that any feature can be linearly represented
as a linear combination of basis of a dictionary which en-
codes regular patterns on the training set. [29][17][5] use
the reconstruction error to determine whether a frame is ab-
normal or not. Ren et al. [21] point out that reconstruction
error, such as least square error, dose not take sparsity term
into consideration, and in fact, it does help the anomaly de-
tection accuracy. To avoid this, Ren et al. [21] propose two
solutions, i.e. maximum coordinate (MC) and non-zero con-
centration(NC), to detect anomaly. However, sparse recon-
struction based methods are usually time-consuming in the
optimization of sparse coefﬁcients. To solve this problem,
Jia et al. [17] propose to discard the sparse constraint and
learn multiple dictionaries to encode the patches at multi-
ple scales, which inevitably brings additional costs in the
training phase.

Deep learning based anomaly detection. Deep learn-
ing approaches have demonstrated its successes for im-
age classiﬁcation [15], object recognition [9], as well as
anomaly detection [11][27]. In [11], Hasan et al. propose
a 3D convolutional Auto-Encoder (Conv-AE) to model the
regular frames, however, 3D convolution cannot character-
ize the spatial and temporal information very well, as shown
in the activity recognition [13]. In light of the capability
of convolutional neural networks (ConvNets) to learn spa-
tial features and the strong capability of recurrent neural
network (RNN) and long short term memory (LSTM) to
model temporal patterns, [3] [19] make attempts to leverage
a convolutional LSTMS Auto-Encoder (ConvLSTM-AE) to
characterize both appearance and motion information. Al-
though RNNs or LSTMs are powerful and effective for pro-
cessing sequential data, they are actually ”black box” whose
internal structures are hard to be interpreted. Recently, Scott
et al. [26] show that a special type of RNN actually en-
forces a sparse constraint on the features. Inspired by the
work of sparse coding based anomaly detection and inter-
pretable RNN, we propose a TSC and its sRNN counterpart
for anomaly detection.

3. Our Approach

Detection

3.1. A Revisit of Sparse Coding Based Anomaly

Sparse coding based anomaly detection aims to learn a
dictionary to encode all normal events with small recon-

2342

struction error [29][17]. Mathematically, denote a feature
corresponding to a normal event as xi, then it is desir-
able that xi can be linearly reconstructed by a dictionary
A with small reconstruction error ǫi, i.e., xi = Aαi + ǫi.
Under the assumption that ǫi ∼ N (0, σ2I), and αi ∼
Laplace(0, 2σ2/λ), we arrive at the following objective
function:

min
A,xi

1
2

kxi − Aαik2

2 + λkαik1

(1)

In this formulation, the ﬁrst term corresponds to a recon-
struction error, and it measures how well the feature can be
reconstructed by the dictionary, and the second term corre-
sponds to a sparsity term, and λ balances the sparsity and
the reconstruction error. Larger λ corresponds to a even
more sparse solution. To avoid trivial solutions of the prob-
lem, usually a L2 norm constraint is imposed on each col-
umn of A: kA(:, j)k ≤ 1. By alternatively optimizing
the dictionary and the sparse coefﬁcients on the training
set [29], the dictionary can be learnt and it encodes all nor-
mal patterns. In the testing phase, when a feature comes in,
we ﬁrst compute the sparse coefﬁcients based on dictionary
A. Then based on its reconstruction error, we can classify
whether it belongs to normal or abnormal events.

3.2. Temporally coherent Sparse Coding (TSC) for

Anomaly Detection

One advantage of sparse coding based anomaly detection
is that it learns a dictionary to encode all normal events with
small reconstruction errors, and an abnormal event would
be associated with a large reconstruction error. However, it
does not consider the temporal coherence between neigh-
boring frames within normal/abnormal events. However,
as shown previous works [17][18], in sparse coding, sim-
ilar features may be encoded as dissimilar sparse codes,
i.e., the locality information is lost. To preserve the sim-
ilarity between the neighboring frames, motivated by the
work [29], we propose a Temporally-coherent Sparse Cod-
ing (TSC). Speciﬁcally, if two neighboring frames are sim-
ilar, it is desirable that their sparse coefﬁcients are simi-
lar too. To achieve this goal, we use the similarity be-
tween neighboring frames to weight the distance between
their sparse coefﬁcients. Speciﬁcally, we denote xt−1 and
xt as features corresponding the (t − 1)-th frame and t-th
frame respectively, and denote the similarity between them
2
as St−1,t = exp(− kxt−xt−1k
), where δ2 = 100 in our ex-
2
periments. It is worth mentioning that since St−1,t would
be multiplied by λ2, therefore, we can set δ to any value
and tune λ2 accordingly. Then we use St−1,t to weight
kαt−αt−1k2
2 and substitutes temporally coherent constraint
into the objective function of sparse coding, we arrive at the
objective function of TSC:

δ2

min
A,αt

T

X
t=1

kxt − Aαtk

2
2+λ1kαtk1 + λ2St,t−1kαt − αt−1k

2
2

(2)

s.t. kA(:, i)k ≤ 1

This objective 2 is not convex. Following the classical op-
timization strategy in sparse coding [2][16], we can alterna-

tively update A and αt (t = {1, . . . , T }).

Optimization of A. When all αt (t = {1, . . . , T }) are
ﬁxed, the objective function corresponding to A can be writ-
ten as follows:

T

min
A

kxt − Aαtk2
2

t=1
X
s.t. kA(:, i)k ≤ 1

(3)

Then, we use a projected gradient descent algorithm to op-
timize A.

Optimization of αt. When A is ﬁxed, we arrive at the fol-
lowing objective function w.r.t. reconstruction coefﬁcients
of all features:
T

kxt − Aαtk

2
2 + λ1kαtk1 + λ2St,t−1kαt − αt−1k

2
2

(4)

min
αt

X
t=1

After that, we update αt (t = {1, . . . , T }) with a Sequential
Iterative Soft-Thresholding Algorithm(SISTA) [26] whose
main steps are algorithm 1. In this algorithm, softb(x) =
max(x − b, 0) = ReLU(x − b), K corresponds to the steps
of ISTA algorithm. γ is a hyper parameter.

Algorithm 1 Sequential iterative soft-thresholding algo-
rithm.
Input: extracted feature x1:T , hyper-parameter λ1, λ2, γ,

initial ˆα0, the steps of ISTA K

1: for t = 1 to T do
2:
3:
4:

t = αt−1

ˆα0
for k = 1 to K do
z = [I − 1
ˆα(k)
t = softλ1/γ(z + St−1,tλ2
end for
αt = ˆαK
t

γ (AT A + St−1,tλ2I)]ˆαk−1
αt−1)

γ

5:
6:
7:
8: end for
9: return α1:T ;

t + 1

γ AT xt

3.3. Interpreting TSC with a Stacked RNN (sRNN)

A traditional RNN is based on an assumption that ht =
f (xt, ht−1), which introduces a recurrent structure. Many
previous works [10][4] show that by stacking multiple
RNNs on top of each other, the performance of classiﬁca-
tion or regression can be further boosted. We denote xt
as an input at time t and denote hk
t as an output of hid-
den nodes in the k-th layer at time t. σb is the nonlin-
ear activation function parameterized by b. In this paper,
we choose σb(x) = softb(x). Mathematically, the stacked
RNN (sRNN) can be written as follows [26]:

h(k)
t =

σb(W (1)h(1)
σb(W (k)h(k)

t−1 + V xt),
t−1 + U (k)h(k−1)

t

(

k = 1,
), k > 1.

(5)

3343

...

...

...

...

...

...

...

...

(a) Vanilla stacked RNN [26]

(b) Stacked RNN couterpart of TSC

Figure 1. The blue boxes represent the input xt of stacked RNNs. The green and orange boxes represent coding vectors αk
circles are similarities between neighboring frames.

t . The yellow

t

The ﬁrst layer accepts the last moment output at the same
layer h1
t−1 and the current moment input xt as its inputs.
Similarly, the rest of the stacked layers accept the last mo-
ment output hk
t−1 at the same layer and the previous layer
output hk−1

at the same moment as their inputs.
By comparing the optimization procedure in Algorithm 1
with stacked RNN, we can see that Equation (2) can be in-
terpreted with sRNN: The K steps in Sequential Iterative
Soft-Thresholding Algorithm correspond to the number of
layers in sRNN. Compared the proposed sRNN to classical
RNN [10], the difference between them is that xt is fed into
to all sRNN layers in our sRNN, while vanilla RNN only
takes xt as its input in the ﬁrst layer. Further, St,t−1 takes
xt and xt−1 as inputs, which means that hk
t also depends on
the input of last moment xt−1. And St,t−1 is the input of
each hidden state hk
t . We illustrate the stacked RNN in our
problem in Figure 1.

More speciﬁcally, the mapping from the variables in

TSC to variables in sRNN in Equation (5) is:

U (k) = I −

(AT A + St−1,tλ2I), k > 1

W (1) = I −

AT A

W (k) =

I, k > 1

λ2
γ
St−1,tλ2
γ
1
γ

V (k) =

AT , k = 1, ..., K

1
γ
b = λ1/γ

h(k)
t = αk
t

3.4. Learning Parameters with Our sRNN

If the number of layers in stacked RNN (K) is very
high, our network is identical with the TSC, which guar-
antees that all αt’s are sparse. Nevertheless, we also

4344

need to choose proper hyper-parameters in TSC to guar-
antee its good performance for anomaly detection. How-
ever, such hyper-parameter selection is nontrivial. Rather
than optimizing the objective in TSC with the ﬁxed hyper-
parameters, we propose to optimize all parameters in sRNN
simultaneously. Speciﬁcally, we optimize parameters in
our sRNN by using an Auto-Encoder way, i.e., we use
the last layer output (hK
t ) of sRNN to reconstruct the in-
put xt with the mapping function parameterized by Z,
i.e., xt = ZhK
t . We denote the parameters in sRNN as
θ = {A, λ1, λ2, Z, α0, γ}. Then we can optimize all pa-
rameters as follows:

min
θ

T

t=1
X

kxt − ZhK

t k2

F + βkθk2
F

(6)

To solve the Equation (6), we use a min-batch based
Stochastic Gradient Descent (SGD) algorithm. Speciﬁ-
cally, we use the RMSPROP [23] based SGD method, and
the weight for weight decay term β = 0.005. Further,
a larger K will inevitably introduces more computational
cost. Therefore, rather than using a very large K, we use a
small one (K=3). As shown in experiments section, such a
shallow architecture achieves much better performance than
all existing methods. Our sRNN has two advantages: i) we
can learn all parameters in sRNN rather than choosing the
hyper-parameters in TSC; ii) the architecture of our sRNN
is not that deep. In the testing phase, we can get αt = hK
t
in one forward pass, which greatly accelerates anomaly de-
tection.

3.5. Multiple Patches Sampled at Multiple Scales

Sampling multiple patches at multiple scales has been
shown to be a very effective way for improving the anomaly
detection [17]. We also use the same strategy. Speciﬁcally,
in our work, we use the spatial ConvNet pretrained on the
UCF101 dataset to extract spatial features for each frame,

and the size of output feature map is 7×7×2048 ∗. Then we
gradually partition the feature map into increasingly ﬁner
regions: 1×1, 2×2, and 4×4. We use the max pooling over
each subregion. So the feature dimension of all subregions
are the same, i.e., 2048. Rather than learning multiple dic-
tionaries for features at different scales [17], which brings
additional computational cost, features at all scales share
the same dictionary in our method. For the features at mul-
tiple scales, we only enforce a temporal coherent constraint
for features at the same scale and same spatial location.

3.6. Anomaly Detection on Testing Set

In training phase, we can learn the dictionary A which
well encodes the normal events. In testing phase, we feed
the feature of each patch corresponding to time t into our
special sRNN, and with one forward pass, we can get the αt.
So we can calculate the reconstruction error corresponding
to patch xt: l(t) = kxt − Aαtk2
2. Then, we pick the max-
imum reconstruction error among all patches within this
frame as the frame level reconstruction error. Following the
work [11][3], after calculating all frame level reconstruc-
tion errors for all testing videos, we normalize the errors to
range [0, 1], and calculate regularity score for each frame
based on the following equation:

• CUHK Avenue [17] dataset contains 16 training videos
and 21 testing videos with a total of 47 abnormal
events, including throwing objects, loitering and run-
ning. The size of people may change because of the
camera position and angle.

• UCSD Pedestrian 1 (Ped1) [18] dataset includes 34
training videos and 36 testing videos with 40 irregular
events. All of these abnormal cases are about vehicles
such as bicycles and cars. Pedestrian 2 (Ped2) [18]
dataset contains 16 training videos and 12 testing
videos with 12 abnormal events. The deﬁnition of
anomaly for Ped2 is the same with Ped1.

• Subway [1] dataset are 2 hours long in total. There
are two categories, i.e. Entrance and Exit. Unusual
events contain walking in wrong directions and loi-
tering. More importantly, this dataset is recorded in
indoor environment while above ones are recorded in
outdoor environment.

• Our new proposed dataset has 13 scenes with complex
It contains 130
light conditions and camera angles.
abnormal events and over 270, 000 training frames.
Moreover, pixel level ground truth of abnormal events
is also annotated in our dataset.

s(t) = 1 −

l(t) − mint l(t)
maxt l(t) − mint l(t)

(7)

We show some samples of our dataset to Figure 2 and

some statistics of different datasets to Table 1.

Smaller s(t) means the t-th frame is more likely corre-
sponding to an abnormal event.

5. Experiments

4. ShanghaiTech Campus Dataset

It is desirable that the anomaly detection model trained
can be directly applied in multiple scenes with multiple
view angles. However, almost all existing datasets only
contain videos captured with one ﬁxed angle camera, and it
lacks diversity of scenes and view angles. To increase scene
diversity, we build a new anomaly detection dataset. To the
best of our knowledge, it is the biggest one for anomaly
detection, and it is even bigger than the summarization of
all existing datasets in terms of the volume of data and the
diversity of scenes. Further we introduce the anomalies
caused by sudden motion in this dataset, such as chasing
and brawling in our dataset, which are not included in exist-
ing datasets. These characteristics make our dataset more
suitable in real scenarios. To better understand the dif-
ferences between our dataset and existing anomaly detec-
tion datasets, we brieﬂy summarize all anomaly detection
datasets as follows:

∗Similar to the work in Conv-AE [11], we also ﬁnd that the mo-
tion feature, such as optical ﬂow or CNN feature extracted from optical
ﬂow [12] does not help the anomaly prediction.

In this paper, we ﬁrst empirically evaluate our proposed
method under a controlled setting on a synthesized dataset,
then we compare our method with other state-of-the-art
methods on real anomaly detection datasets. Different pa-
rameters in TSC and sRNN are also empirically evaluated.
All codes and dataset will be released ∗.

5.1. Experimental Setup

Parameters.
In our experiments, for real anomaly detec-
tion dataset, the dimensionality of feature is 2048, and we
ﬁx the size of dictionary A to 2048 × 2048. For TSC, we
set λ1, λ2, γ to 0.2, 2.0, and 1, respectively. For sRNN, we
set K = 3. We set the length of each video clip T to 10
frames.

Measurements. We can predict whether abnormal event
occurs based on s(t). One can set a threshold and if the
score of the frame is smaller than the threshold, the frame
can be categorized to an abnormal case. Obviously a higher
threshold may cause a higher false negative ratio, while a
lower one may lead to more false alarms. By changing the

∗https://github.com/StevenLiuWen/sRNN TSC Anomaly Detection

5345

UCSD Ped1 Ped2

CUHK Avenue

Subway Enter/Exit

(cid:28610)(cid:28643)(cid:28646)(cid:28641)(cid:28629)(cid:28640)(cid:28637)(cid:28648)(cid:28653)

(cid:28597)(cid:28642)(cid:28643)(cid:28641)(cid:28629)(cid:28640)(cid:28653)

(cid:28610)(cid:28643)(cid:28646)(cid:28641)(cid:28629)(cid:28640)(cid:28637)(cid:28648)(cid:28653)

(cid:28597)(cid:28642)(cid:28643)(cid:28641)(cid:28629)(cid:28640)(cid:28653)

Our dataset

Figure 2. Some samples from our new proposed dataset and other datasets. The ﬁrst row represents some samples from the UCSD Ped1,
UCSD Ped2, CUHK Avenue and Subway Entrance and Subway Exit datasets, respectively. The second row represents normal scenes from
our proposed dataset (ShanghaiTech Campus). The third row stands for the related abnormal cases where green dots are abnormal regions.

Table 1. Comparision of our dataset with other released datasets.

#Frames

#Abnormal Events

#Scenes

Dataset

Our Dataset
CUHK Avenue
UCSD Ped2
UCSD Ped1
Subway Entrance
Subway Exit

Total
317,398
30,652
4,560
14,000
136,524
72,401

Training
274,515
15,328
2,550
6,800
20,000
7,500

Testing
42,883
15,324
2,010
7,200
116,524
64,901

Regularity
300,308
26,832
2,924
9,995
134,124
71,681

Irregularity
17,090
3,820
1,636
4,005
2,400
720

130
47
12
40
66
19

13
1
1
1
1
1

threshold gradually, we can arrive at a ROC curve. The Area
Under Curve(AUC) is a commonly used measurement for
detecting irregularity [18]. In this paper, we use frame-level
AUC to evaluate the performance of different methods.

5.2. Evaluate with a Synthesized Dataset

To evaluate the performance of our method for the
anomaly caused by a sudden change of appearance, we de-
ploy experiments on a synthesized Moving-MNIST dataset.
Speciﬁcally, we randomly choose two digits from the
MNIST dataset, and put them in the center of a black image
whose size is 225×225 pixels. Then in the next 19 frames,
the digits randomly moving horizontally or vertically.
In
this way, we can get a sequence with 20 frames. In our ex-

(cid:49)(cid:82)(cid:85)(cid:80)(cid:68)(cid:79)(cid:76)(cid:87)(cid:92)

(cid:36)(cid:81)(cid:82)(cid:80)(cid:68)(cid:79)(cid:92)

(cid:72)
(cid:85)
(cid:82)
(cid:70)
(cid:54)

(cid:41)(cid:68)(cid:79)(cid:86)(cid:72)(cid:3)(cid:68)(cid:79)(cid:68)(cid:85)(cid:80)(cid:11)(cid:38)(cid:82)(cid:81)(cid:89)(cid:16)(cid:36)(cid:40)(cid:12)

(cid:6)(cid:41)(cid:85)(cid:68)(cid:80)(cid:72)(cid:86)

Figure 3. A sample on the Moving-MNIST dataset.

periments, we synthesize 10,000 sequences for training data
and train the network. For each testing sequence, 5 consec-
utive frames are randomly occluded by randomly inserting

6346

a 3×3 white box. We generate 3,000 sequences in total as
testing data. Then we use the intensity of the images as
features and normalized it with L2 normalization.

Our model achieves 86.52% and Conv-AE achieves
74.3%, which illustrates that our method signiﬁcantly out-
performs Conv-AE in terms of AUC. We also show the
curve of s(t) w.r.t. different events in Figure 3. We can
see that our method achieves a more smooth prediction.

5.3. Evaluation with Real Anomaly Datasets

We also evaluate both TSC based and sRNN based
methods on real datasets. Speciﬁcally, we conduct exper-
iments on our own dataset as well as two recently most
used datasets, including CUHK Avenue [17] and UCSD
Ped2 [18] ∗.

We list the performance of different methods on these
datasets in Table 2. It clearly shows that both our methods
outperform all existing methods, including ConvAE [11]
and Del et al. [8] which are recently proposed methods
which achieve state-of-the-art performance for anomaly de-
tection. Speciﬁcally, since our dataset contains multiple
scenes, which makes our dataset more realistic and chal-
lenging. On this dataset, our TSC based method outper-
forms Conv-AE by about 6% in terms of AUC. On the Ped2
dataset, the improvement of our TSC outperforms Conv-
AE by more than 10%. The improvement is obvious. Fur-
ther, by comparing TSC and sRNN, we can see that per-
formance of sRNN is even better than that of TSC. How-
ever, for sRNN, we don’t need to elaborately choose hyper-
parameters, and the testing phase is more sufﬁcient than
TSC.

Table 2. AUC of different methods on the Avenue, Ped2 and our
dataset (ShanghaiTech Campus).

MPPCA [18]
MPPC+SFA [18]
HOFME [25]
Conv-AE [11]
Del et al. [8]
TSC
sRNN

Ped2
Avenue
69.3%
N/A
61.3%
N/A
87.5%
N/A
81.1%
74.5%
N/A
78.3%
80.56%
91.03%
81.71% 92.21%

Our dataset
N/A
N/A
N/A
60.85%
N/A
67.94%
68.00%

We also compare our sRNN with LSTM based Auto-
Encoder where the same features are used, and ConvLSTM
based Auto-Encoder which extracts features with ConvL-

∗The reason for not using the subway dataset because different ground
truth is annotated in different work [17][11], and different ground truth
favors the performance evaluation of different methods. As for UCSD
pedestrain datasets, Ped1 is more frequently used for pixel-wise anomaly
detection [27] and our work focuses on frame-level prediction, so we only
conduct experiments on Ped2.

STM from raw pixels. The AUC of these methods on Av-
enue and Ped2 is listed in Table 3: We can see that our
sRNN also outperforms these baselines.

Table 3. AUC of two baselines on the Avenue and Ped2.

LSTM-AE
ConvLSTM-AE
sRNN

Avenue
75.33%
77.00%
81.71%

Ped2
83.62%
88.10%
92.21%

Finally, we show the change of score (s(t)), similarities
between neighboring frames (St,t−1), distances between
sparse codes of neighboring frames (kαt − αt−1k) for some
normal and abnormal events on the Ped2 dataset in Figure 3.
We can see that a smooth similarity and distance can be
found for the frames within the normal or abnormal events,
which agrees with the motivation of our TSC.

5.4. The Effect of Different Hyper Parameters

Weight of Sparsity Term(λ1). λ1 in Equation (2) con-
trols the sparsity of αt. As shown in Algorithm 1, αk
t is op-
timized based on a soft-thresholding operator. The bigger
λ1 is, the more sparse αt will be. We ﬁx λ2 and dictionary
size to 2.0 and 2048 × 2048, respectively, and change λ1
to observe how this parameter affect AUC on ped2 and Av-
enue. As shown in ﬁgure 5(a), bigger λ1 does not always
improve the AUC for both datasets.

Weight of Temporally-coherent Term (λ2). λ2 in Equa-
tion (2) controls the smoothness of the sparse codes be-
tween neighboring frames. Figure 5(b) demonstrates that
a small λ2 would harm the AUC for both the Avenue and
Ped2 datasets.

Dictionary Size. We show the change of the TSC perfor-
mance w.r.t.
the change of dictionary size on the Avenue
dataset in Figure 5(c). We can see that a larger dictionary
can not always improve AUC and the optimal dictionary
size varies from different datasets.

Number of Layers in Stacked RNN. The optimization
of SISTA algorithm requires a very large K to achieve a
sparse solution with a small reconstruction error. Fewer it-
erative steps may harm the optimization of TSC. Larger K
means a deeper sRNN is needed for its TSC counterpart.
However, a very deep sRNN may lead to gradient vanish-
ing or explosion, which is harder to optimize. To validate
how K affect the performance of our sRNN, we set it to 3
and 30, respectively. The sparsity (percentage of zero en-
tries) of 3 layers based sRNN and that of 30 layers based
sRNN is 80.0% and 92.7%, respectively, while the AUC for
3 layers based sRNN and 30 layers based sRNN is 91.03%

7347

Figure 4. Scores, similarities and distances between neighboring frames for a video sample on Ped2. We can see that the similarities
between neighboring frames can be kept for normal events. We highlight the abnormal events with red boxes. (Best viewed in color)

0.90

0.85

C
U
A

0.80

0.75

Avenue
Ped2

(a) AUC versus λ1

(b) AUC versus λ2
Figure 5. The change of AUC w.r.t. λ1, λ2 and the size of dictionary. (Best viewed in color)

1000

2000

3000
Dictionary Size (λ1 = 0.1, λ2 = 1.0)
(c) AUC versus dictionary size

4000

5000

and 88.10%, respectively. This experiment shows that spar-
sity does not necessarily lead better performance in sRNN.
In our experiments, we set K = 3 for all datasets. Such a
shallow architecture also accelerates the inference of αt(ht)
in testing phase.

5.5. Running Time

Our sRNN model takes about one hour to train on Av-
enue for 10,000 steps.It takes about 0.02s for anomaly de-
tection of a frame. While the prediction of a frame for a
TSC based method is about 10 times slower than that of
sRNN if we set K = 30 in SISTA algorithm. Therefore,
our sRNN is an effective and efﬁcient solution for anomaly
detection.

6. Conclusion

In this paper, we propose a TCS framework for anomaly
detection which preserves the similarities between the
frames within the normal/abnormal events. Our TCS can
be interpreted with a special sRNN. By optimizing all pa-
rameters in sRNN simultaneously, we can avoid the nontriv-
ial parameter selection, and reduce the computational cost
for inferring the reconstruction coefﬁcients in testing phase.
Considering the fact that most anomaly detection datasets
only contain one scene with the same view angle, we build
a datasets which is the most challenging one in terms of
data volume and scene diversity. Extensive experiments on
both a synthesized dataset and real datasets validate the ef-
fectiveness of our TCS and sRNN methods.
Acknowledgements. This work was supported by
NSFC (No. 61502304).

8348

[18] V. Mahadevan, W. Li, V. Bhalodia, and N. Vasconcelos.
In CVPR, volume

Anomaly detection in crowded scenes.
249, page 250, 2010.

[19] J. R. Medel and A. Savakis. Anomaly detection in video
using predictive convolutional long short-term memory net-
works. arXiv preprint arXiv:1612.00390, 2016.

[20] N. Navneet and B. Triggs. Histograms of oriented gradients
for human detection. In Computer Vision and Pattern Recog-
nition, 2005. CVPR 2005. IEEE Computer Society Confer-
ence on, volume 1, pages 886–893. IEEE, 2005.

[21] H. Ren, H. Pan, S. I. Olsen, and T. B. Moeslund. A com-
prehensive study of sparse codes on abnormality detection.
arXiv preprint arXiv:1603.04026, 2016.

[22] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards
real-time object detection with region proposal networks. In
NIPS, pages 91–99, 2015.

[23] T. Tieleman and G. E. Hinton. Lecture 6.5-rmsprop: Divide
the gradient by a running average of its recent magnitude. In
COURSERA: Neural Networks for Machine Learning, 2012.
[24] F. Tung, J. S. Zelek, and D. A. Clausi. Goal-based trajec-
tory analysis for unusual behaviour detection in intelligent
surveillance. Image and Vision Computing, 29(4):230–240,
2011.

[25] T. Wang and H. Snoussi. Histograms of optical ﬂow orienta-
tion for abnormal events detection. In Performance Evalua-
tion of Tracking and Surveillance (PETS), 2013 IEEE Inter-
national Workshop on, pages 45–52. IEEE, 2013.

[26] S. Wisdom, T. Powers, J. Pitton, and L. Atlas. Interpretable
recurrent neural networks using sequential sparse recovery.
arXiv preprint arXiv:1611.07252, 2016.

[27] D. Xu, E. Ricci, Y. Yan, J. Song, and N. Sebe. Learning deep
representations of appearance and motion for anomalous
event detection. arXiv preprint arXiv:1510.01553, 2015.
[28] D. Zhang, D. Gatica-Perez, S. Bengio, and I. McCowan.
Semi-supervised adapted hmms for unusual event detection.
In CVPR, volume 1, pages 611–618. IEEE, 2005.

[29] B. Zhao, F. Li, and E. P. Xing. Online detection of unusual
events in videos via dynamic sparse coding. In CVPR, pages
3313–3320. IEEE, 2011.

References

[1] A. Adam, E. Rivlin, I. Shimshoni, and D. Reinitz. Ro-
bust real-time unusual event detection using multiple ﬁxed-
location monitors. TPAMI, 30(3):555–560, 2008.

[2] M. Aharon, M. Elad, and A. Bruckstein. rmk-svd: An al-
gorithm for designing overcomplete dictionaries for sparse
IEEE Transactions on signal processing,
representation.
54(11):4311–4322, 2006.

[3] Y. S. Chong and Y. H. Tay. Abnormal event detection in
arXiv preprint

videos using spatiotemporal autoencoder.
arXiv:1701.01546, 2017.

[4] J. Chung, C. G¨ulc¸ehre, K. Cho, and Y. Bengio. Gated feed-
back recurrent neural networks. In ICML, pages 2067–2075,
2015.

[5] Y. Cong, J. Yuan, and J. Liu. Sparse reconstruction cost
for abnormal event detection. In Computer Vision and Pat-
tern Recognition (CVPR), 2011 IEEE Conference on, pages
3449–3456. IEEE, 2011.

[6] N. Dalal, B. Triggs, and C. Schmid. Human detection using
In European
oriented histograms of ﬂow and appearance.
conference on computer vision, pages 428–441. Springer,
2006.

[7] C. Feichtenhofer, A. Pinz, and A. Zisserman. Convolu-
tional two-stream network fusion for video action recogni-
tion. arXiv preprint arXiv:1604.06573, 2016.

[8] A. D. Giorno, J. A. Bagnell, and M. Hebert. A discriminative
framework for anomaly detection in large videos. In ECCV,
pages 334–349. Springer, 2016.

[9] R. Girshick. Fast r-cnn. In Proceedings of the IEEE Inter-
national Conference on Computer Vision, pages 1440–1448,
2015.

[10] A. Graves, A. Mohamed, and G. Hinton. Speech recognition
In Acoustics, speech
with deep recurrent neural networks.
and signal processing (icassp), 2013 ieee international con-
ference on, pages 6645–6649. IEEE, 2013.

[11] M. Hasan, J. Choi, J. Neumann, A. K. Roy-Chowdhury,
and L. S. Davis. Learning temporal regularity in video se-
quences. In CVPR, 2016.

[12] B. K. Horn and B. G. Schunck. Determining optical ﬂow.

Artiﬁcial intelligence, 17(1-3):185–203, 1981.

[13] S. Ji, W. Xu, M. Yang, and K. Yu. 3d convolutional neural

networks for human action recognition. TPAMI.

[14] J. Kim and K. Grauman. Observe locally, infer globally: a
space-time mrf for detecting abnormal activities with incre-
In Computer Vision and Pattern Recogni-
mental updates.
tion, 2009. CVPR 2009. IEEE Conference on, pages 2921–
2928. IEEE, 2009.

[15] A. Krizhevsky, I. Sutskever, and G. E. Hinton.

classiﬁcation with deep convolutional neural networks.
NIPS, pages 1097–1105, 2012.

Imagenet
In

[16] H. Lee, A. Battle, R. Raina, and A. Y. Ng. Efﬁcient sparse
coding algorithms. Advances in neural information process-
ing systems, 19:801, 2007.

[17] C. Lu, J. Shi, and J. Jia. Abnormal event detection at 150 fps
in matlab. In Proceedings of the IEEE International Confer-
ence on Computer Vision, pages 2720–2727, 2013.

9349

