Differentially Private Database Release via Kernel Mean Embeddings

Matej Balog 1 2 Ilya Tolstikhin 1 Bernhard Sch¨olkopf 1

8
1
0
2
 
y
a
M
 
1
3
 
 
]
L
M

.
t
a
t
s
[
 
 
2
v
1
4
6
1
0
.
0
1
7
1
:
v
i
X
r
a

Abstract

We lay theoretical foundations for new database
release mechanisms that allow third-parties to con-
struct consistent estimators of population statis-
tics, while ensuring that the privacy of each indi-
vidual contributing to the database is protected.
The proposed framework rests on two main ideas.
First, releasing (an estimate of) the kernel mean
embedding of the data generating random vari-
able instead of the database itself still allows third-
parties to construct consistent estimators of a wide
class of population statistics. Second, the algo-
rithm can satisfy the deﬁnition of differential pri-
vacy by basing the released kernel mean embed-
ding on entirely synthetic data points, while con-
trolling accuracy through the metric available in a
Reproducing Kernel Hilbert Space. We describe
two instantiations of the proposed framework,
suitable under different scenarios, and prove the-
oretical results guaranteeing differential privacy
of the resulting algorithms and the consistency of
estimators constructed from their outputs.

1. Introduction

We aim to contribute to the body of research on the trade-off
between releasing datasets from which publicly beneﬁcial
statistical inferences can be drawn, and between protecting
the privacy of individuals who contribute to such datasets.
Currently the most successful formalisation of protecting
user privacy is provided by differential privacy (Dwork &
Roth, 2014), which is a deﬁnition that any algorithm operat-
ing on a database may or may not satisfy. An algorithm that
does satisfy the deﬁnition ensures that a particular individ-
ual does not lose too much privacy by deciding to contribute
to the database on which the algorithm operates.

While differentially private algorithms for releasing entire

1MPI-IS, T¨ubingen, Germany 2University of Cambridge, UK.
Correspondence to: Matej Balog <ﬁrst.surname@gmail.com>.
Code: https://github.com/matejbalog/RKHS-private-database/.

Proceedings of the 35 th International Conference on Machine
Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018
by the author(s).

databases have been studied previously (Blum et al., 2008;
Wasserman & Zhou, 2010; Zhou et al., 2009), most algo-
rithms focus on releasing a privacy-protected version of a
particular summary statistic, or of a statistical model trained
on the private dataset. In this work we revisit the more difﬁ-
cult non-interactive, or ofﬂine setting, where the database
owner aims to release a privacy-protected version of the
entire database without knowing what statistics third-parties
may wish to compute in the future.

In our new framework we propose to use the kernel mean
embedding (Smola et al., 2007) as an intermediate represen-
tation of a database. It is (1) sufﬁciently rich in the sense that
it captures a wide class of statistical properties of the data,
while at the same time (2) it lives in a Reproducing Kernel
Hilbert Space (RKHS), where it can be handled mathemati-
cally in a principled way and privacy-protected in a uniﬁed
manner, independently of the type of data appearing in the
database. Although kernel mean embeddings are functions
in an abstract Hilbert space, in practice they can be (at least
approximately) represented using a possibly weighted set of
data points in input space (i.e. a set of database rows). The
privacy-protected kernel mean embedding is released to the
public in this representation, however, using synthetic data-
points instead of the private ones. As a result, our framework
can be seen as leading to synthetic database algorithms.

We validate our approach by instantiating two concrete algo-
rithms and proving that they output consistent estimators of
the true kernel mean embedding of the data generating pro-
cess, while satisfying the deﬁnition of differential privacy.
The consistency results ensure that third-parties can carry
out a wide variety of statistically founded computation on
the released data, such as constructing consistent estimators
of population statistics, estimating the Maximum Mean Dis-
crepancy (MMD) between distributions, and two-sample
testing (Gretton et al., 2012), or using the data in the kernel
probabilistic programming framework for random variable
arithmetics (Sch¨olkopf et al., 2015; Simon-Gabriel et al.,
2016, Section 3), repeatedly and unlimitedly without being
able to, or having to worry about, violating user privacy.

One of our algorithms is especially suited to the interesting
scenario where a (small) subset of a database has already
been published. This situation can arise in a wide variety of
settings, for example, due to weaker privacy protections in

Differentially Private Database Release via Kernel Mean Embeddings

the past, due to a leak, or due to the presence of an incentive,
ﬁnancial or otherwise, for users to publish their data. In such
a situation our algorithm provides a principled approach for
reweighting the public data in such a way that the accu-
racy of statistical inferences on this dataset beneﬁts from
the larger sample size (including the private data), while
maintaining differential privacy for the undisclosed data.

The Laplace mechanism adds i.i.d. Lap(∆1/ε) noise to
each of the J coordinates of the output vector and ensures
pure ε-differential privacy, while the Gaussian mechanism
adds i.i.d. N (0, σ2) noise to each coordinate, where σ2 >
2∆2
2 ln(1.25/δ)/ε2, and ensures (ε, δ)-differential privacy.
Applying these mechanisms thus requires computing (an
upper bound on) the relevant sensitivity.

In summary, the contributions of this paper are:

1. A new framework for designing database release algo-
rithms with the guarantee of differential privacy. The
framework uses kernel mean embeddings as intermedi-
ate database representations, so that the RKHS metric
can be used to control accuracy of the released syn-
thetic database in a principled manner (Section 3).

2. Two instantiations of our framework in the form of
two synthetic database algorithms, with proofs of their
consistency, convergence rates and differential privacy,
as well as basic empirical illustrations of their perfor-
mance on synthetic datasets (Sections 4 and 5).

2. Background

2.1. Differential Privacy

Deﬁnition 1 (Dwork, 2006). For ε > 0, δ ≥ 0, algorithm A
is said to be (ε, δ)-differentially private if for all neighbour-
ing databases D ∼ D(cid:48) (differing in at most one element)
and all measurable subsets S of the co-domain of A,

P (A(D) ∈ S) ≤ eεP (A(D(cid:48)) ∈ S) + δ.

(1)

The parameter ε controls the amount of information the
algorithm can leak about an individual, while a positive δ
allows the algorithm to produce an unlikely output that leaks
more information, but only with probability up to δ. This
notion is sometimes called approximate differential privacy;
an algorithm that is (ε, 0)-differentially private is simply
said to be ε-differentially private. Note that any non-trivial
differentially private algorithm must be randomised; the
deﬁnition asserts that the distribution of algorithm outputs
is not too sensitive to changing one row in the database.
When the algorithm’s output is a ﬁnite vector A(D) ∈ RJ ,
two standard random perturbation mechanisms for making
this output differentially private are the Laplace and Gaus-
sian mechanisms. As the perturbation needs to mask the
contribution of each individual entry of the database D, the
scale of the added noise is closely linked to the notion of
sensitivity, measuring how much the algorithm’s output can
change due to changing a single data point:

∆1 := sup
D∼D(cid:48)
∆2 := sup
D∼D(cid:48)

(cid:107)A(D) − A(D(cid:48))(cid:107)1 ,

(cid:107)A(D) − A(D(cid:48))(cid:107)2 .

(2)

(3)

Differential privacy is preserved under post-processing: if
an algorithm A is (ε, δ)-differentially private, then so is its
sequential composition B(A(·)) with any other algorithm
B that does not have direct or indirect access to the private
database D (Dwork & Roth, 2014).

2.2. Kernels, RKHS, and Kernel Mean Embeddings

A kernel on a non-empty set (data type) X is a binary
positive-deﬁnite function k(·, ·) : X × X → R. Intuitively
it can be thought of as expressing the similarity between
any two elements in X . The literature on kernels is vast
and their properties are well studied (Sch¨olkopf & Smola,
2002); many kernels are known for a large variety of data
types such as vectors, strings, time series, graphs, etc, and
kernels can be composed to yield valid kernels for compos-
ite data types (e.g. the type of a database row containing
both numerical and string data).

The kernel mean embedding (KME) of an X -valued random
X : X → R,
variable X in the RKHS is the function µk
y (cid:55)→ EX [k(X, y)], deﬁned whenever EX [(cid:112)k(X, X)] <
∞ (Smola et al., 2007). Several popular kernels have been
proved to be characteristic (Fukumizu et al., 2008), in which
case the map pX (cid:55)→ µk
X , where pX is the distribution of
X, is injective. This means that no information about the
distribution of X is lost when passing to its KME µk
X .

(cid:80)N

In practice, the KME of a random variable X is approx-
imated using a sample x1, . . . , xN drawn from X, which
can be used to construct an empirical KME ˆµk
X of X in
the RKHS: a function given by y (cid:55)→ 1
n=1 k(xn, y).
N
When the xn’s are i.i.d., under a boundedness condition ˆµk
X
converges to the true KME µk
X at rate Op(N −1/2), inde-
pendently of the dimension of X (Lopez-Paz et al., 2015)1.
Our approach relies on the metric of the RKHS in which
these KMEs live. The RKHS Hk is a space of functions,
endowed with an inner product (cid:104)·, ·(cid:105)Hk that satisﬁes the
reproducing property (cid:104)k(x, ·), h(cid:105) = h(x) for all x ∈ X and
h ∈ Hk. The inner product induces a norm (cid:107) · (cid:107)Hk , which
can be used to measure distances (cid:107)µk
Y (cid:107)Hk between
distributions of X and Y . This can be exploited for various

X − µk

1The KME can be viewed as a smoothed version of the density,
which is easier to estimate than the density itself; rates of nonpara-
metric density estimation or statistical powers of two-sample or
independence tests involving pX are known to necessarily degrade
with growing dimension (Tolstikhin et al., 2017, Section 4.3).

Differentially Private Database Release via Kernel Mean Embeddings

purposes such as two-sample tests (Gretton et al., 2012), in-
dependence testing (Gretton et al., 2005), or one can attempt
to minimise this distance in order to match one distribution
to another.

An example of such minimisation are reduced set meth-
ods (Burges, 1996; Sch¨olkopf & Smola, 2002, Chap. 18),
which replace a set of points S = {x1, . . . , xN } ⊆ X with
a weighted set R = {(z1, w1), . . . , (zM , wM )} ⊆ X × R
(of potentially smaller size), where the new points zm can,
but need not equal any of the xns, such that the KME com-
puted using the reduced set R is close to the KME computed
using the original set S, as measured by the RKHS norm:

(cid:13)
(cid:13)µk

S − µk
R

(cid:13)
(cid:13)Hk

=

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
N

N
(cid:88)

n=1

M
(cid:88)

m=1

k(xn, ·) −

wmk(zm, ·)

Reduced set methods are usually motivated by the computa-
tional savings arising when |R| < |S|; we will invoke them
mainly to replace a collection S of private data points with
a (possibly weighted) set R of synthetic data points.

3. Framework

3.1. Problem Formulation

Throughout this work, we assume the following setup.
A database curator wishes to publicly release a database
D = {x1, . . . xN } ∈ X N containing private data about N
individuals, with each data point (database row) xn taking
values in a non-empty set X . The set X can be arbitrarily
rich, for example, it could be a product of Euclidean spaces,
integer spaces, sets of strings, etc.; we only require avail-
ability of a kernel function k : X × X → R on X . We
assume that the N rows x1, . . . , xN in the database D can
be thought of as i.i.d. observations from some X -valued
data-generating random variable X (but see Section 7 for
a discussion about relaxing this assumption). The database
curator, wishing to protect the privacy of individuals in the
database, seeks a database release mechanism that satisﬁes
the deﬁnition of (ε, δ)-differential privacy, with ε > 0 and
δ ≥ 0 given. The main purpose of releasing the database
is to allow third parties to construct estimators of popula-
tion statistics (i.e. properties of the distribution of X), but
it is not known at the time of release what statistics the
third-parties will be interested in.

To lighten notation, henceforth we drop the superscript k
from KMEs (such as µk
X ) and the subscript k from the
RKHS Hk, whenever k is the kernel on X chosen by the
database curator.

3.2. Algorithm Template

We propose the following general algorithm template for
differentially private database release:

1. Construct a consistent estimator ˆµX of the KME µX

of X using the private database.

2. Obtain a perturbed version ˜µX of the constructed esti-

mate ˆµX to ensure differential privacy.

3. Release a (potentially approximate) representation
of ˜µX in terms of a (possibly weighted) dataset
{(z1, w1), . . . , (zM , wM )} ⊆ X × R.

released representation should be

The
such that
(cid:80)M
m=1 wmk(zm, ·) is a consistent estimator of
the
true KME µX , i.e. such that the RKHS distance between
the two converges to 0 in probability as the private database
size N , and together with it the synthetic database size M ,
go to inﬁnity.

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)Hk

.

(cid:80)N

Each step of this template admits several possibilities. For
the ﬁrst step we have discussed the standard empirical KME
1
n=1 k(xn, ·) with x1, . . . , xN i.i.d. observations of X,
N
but the framework remains valid with improved estimators
such as kernel-based quadrature (Chen et al., 2010) or the
shrinkage kernel mean estimators of (Muandet et al., 2016).

As the KMEs ˆµX and µX live in the RKHS H of the kernel
k, a natural mechanism for privatising ˆµX in the second
step would be to follow (Hall et al., 2013) and pointwise
add to ˆµX a suitably scaled sample path g of a Gaussian
process with covariance function k(·, ·). This does ensure
(ε, δ)-differential privacy of the resulting function ˜µX =
ˆµX + g, but unfortunately ˜µX (cid:54)∈ H, because the RKHS
norm (cid:107)g(cid:107)H of a Gaussian process sample path with the same
kernel k is inﬁnite almost surely (Rasmussen & Williams,
2005). While our framework allows pursuing this direction
by, for example, moving to a larger function space that does
contain the Gaussian process sample path, in this work we
will present algorithms that achieve differential privacy by
mapping ˆµX into a ﬁnite-dimensional Hilbert space and then
employing the standard Laplace or Gaussian mechanisms
to the ﬁnite coordinate vector.

Differential privacy is preserved under post-processing, but
the third step does require some care to ensure that pri-
vate data is not leaked. Speciﬁcally, when several possible
(approximate) representations ˜µX ≈ (cid:80)M
m=1 wmk(zm, ·)
in terms of a weighted dataset (w1, z1), . . . , (wM , zM ) are
possible, committing to a particular one reveals more infor-
mation than just the function ˜µX (consider, for example, the
extreme case where the representation would be in terms
of the private points x1, . . . , xN ). One thus needs to either
control the privacy leak due to choosing a representation in
a way that depends on the private data, or, as we do in our
concrete algorithms below, choose a representation indepen-
dently of the private data (but still minimising its RKHS
distance to the privacy-protected ˜µX ).

Differentially Private Database Release via Kernel Mean Embeddings

3.3. Versatility

Algorithms in our framework release a possibly weighted
synthetic dataset {(z1, w1), . . . , (zM , wM )} ⊆ X × R such
that (cid:80)M
m=1 wmk(zm, ·) is a consistent estimator of the true
KME µX of the data generating random variable X. This
allows third-parties to perform a wide spectrum of statistical
computation, all without having to worry about violating
differential privacy:

1. Kernel probabilistic programming (Sch¨olkopf et al.,
2015): The versatility of our approach is greatly ex-
panded thanks to the result of (Simon-Gabriel et al.,
2016), who showed that under technical conditions,
applying a continuous function f to all points zm
in the synthetic dataset yields a consistent estima-
tor (cid:80)M
m=1 wmkf (f (zm), ·) of the KME µf (X) of the
transformed random variable f (X), even when the
points z1, . . . , zM are not i.i.d. (as they may not be,
depending on the particular synthetic database release
algorithm).

2. Consistent estimation of population statistics: For
any RKHS function h ∈ H, we have (cid:104)µX , h(cid:105)H =
E[h(X)], so a consistent estimator of µX yields a con-
sistent estimator of the expectation of h(X). It can be
evaluated using the reproducing kernel property:

E[h(X)] = (cid:104)µX , h(cid:105)H ≈

wmk(zm, ·), h

(cid:42) M
(cid:88)

m=1

=

wmh(zm).

M
(cid:88)

m=1

(cid:43)

H

(4)

For example, approximating the indicator function 1S
of a set S ⊆ X with functions in the RKHS allows
estimating probabilities: E[1S(X)] = P[X ∈ S] (note
that 1S itself may not be an element of the RKHS).

3. MMD estimation and two-sample testing (Gretton et al.,
2012): Given another random variable Y on X , one
can consistently estimate the Maximum Mean Discrep-
ancy (MMD) distance (cid:107)µX − µY (cid:107)H between the dis-
tributions of X and Y , and in particular to construct a
two-sample test based on this distance. Given a sample
y1, . . . , yL ∼ Y :

(cid:107)µX − µY (cid:107)H ≈

wmk(zm, ·) −

k(yl, ·)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

M
(cid:88)

m=1

1
L

L
(cid:88)

l=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)H

,

which can again be evaluated using the reproducing
property.

4. Subsequent use of synthetic data: Since the output of
the algorithm is a (possibly weighted) database, third-
parties are free to use this data for arbitrary purposes,

such as training any machine learning model on this
data. Models trained purely on this data can be released
with differential privacy guaranteed; however, the accu-
racy of such models on real data remains an empirical
question that is beyond the scope of this work.

An orthogonal spectrum of versatility arises from the fact
that the third step in the algorithm template can constrain the
released dataset (z1, w1), . . . , (zM , wM ) to be more conve-
nient or more computationally efﬁcient for further process-
ing. For example, one could ﬁx the weights to uniform
wm = 1
M to obtain an unweighted dataset, or to replace an
expensive data type with a cheaper subset, such as request-
ing ﬂoats instead of doubles in the zm’s. All this can be
performed while an RKHS distance is available to control
accuracy between ˜µX and its released representation.

3.4. Concrete Algorithms

As a ﬁrst illustrative example, we describe how a partic-
ular case of an existing, but inefﬁcient synthetic database
algorithm already ﬁts into our framework. The exponen-
tial mechanism (McSherry & Talwar, 2007) is a general
mechanism for ensuring ε-differential privacy, and in our
setting it operates as follows: given a similarity measure
s : X N × X M → R between (private) databases of size
N and (synthetic) databases of size M , output a random
(synthetic) database R with probability proportional to
exp( ε
s(D, R)), where D is the actual private database
2∆1
and ∆1 is the L1 sensitivity of s w.r.t. D. This ensures
ε-differential privacy (McSherry & Talwar, 2007).

To ﬁt this into our framework, we can take s(D, R) =
−(cid:107)µD − µR(cid:107)H to be the negative RKHS distance be-
tween the KMEs computed using D and R, and achieve
ε-differential privacy by releasing R with probability pro-
portional to exp(− ε
(cid:107)µD − µR(cid:107)H). This solves steps
2∆1
2 and 3 of our general algorithm template simultaneously,
as it directly samples a concrete representation of a “per-
turbed” KME µR. The algorithm essentially corresponds
to the SmallDB algorithm of Blum et al. (2008), except for
choosing the RKHS distance as a well-studied similarity
measure between two databases.

The principal issue with this algorithm is its computational
infeasibility except in trivial cases, as it requires sampling
from a probability distribution supported on all potential
synthetic databases, and employing an approximate sam-
pling scheme can break the differential privacy guarantee of
the exponential mechanism. In Sections 4 and 5 respectively,
we describe two concrete synthetic database release algo-
rithms that may possess failure modes where they become
inefﬁcient, but employing approximations in those cases
can only affect their statistical accuracy, not the promise of
differential privacy.

Differentially Private Database Release via Kernel Mean Embeddings

Algorithm 1 Differentially private database release via a synthetic data subspace of the RKHS

Input: database D = {x1, . . . , xN } ⊆ X , kernel k on X , privacy parameters ε > 0 and δ > 0
Output: (ε, δ)-differentially private, weighted synthetic database (representing an estimate of µX in the RKHS H of k)
1: M ← M (N ) ∈ ω(1) ∩ o(N 2), number of synthetic data points to use
2: z1, . . . , zM ← initialised deterministically or randomly from some distribution q on X
3: HM ← Span({k(z1, ·), . . . , k(zM , ·)}) ≤ H
4: b1, . . . , bF ← orthonormal basis of HM (obtained using, e.g. Gram-Schmidt)
5: ˆµX ← 1
N
6: µX ← (cid:80)F
7: β ← α + N (0, 8 ln(1.25/δ)
8: ˜µX ← (cid:80)F
f =1 βf bf = (cid:80)M
9: return (z1, w1), . . . , (zM , wM )

(cid:80)N
f =1(cid:104)bf , ˆµX (cid:105)Hbf =: (cid:80)F

IF ), an (ε, δ)-differentially private version of the coordinate vector α (Gaussian mechanism)

m=1 wmk(zm, ·), re-expressed in terms of k(zm, ·)’s

n=1 k(xn, ·), empirical KME of X in H

f =1 αf bf , projection of ˆµX onto HM

N 2ε2

4. Perturbation in Synthetic-Data Subspace

In this section we describe an instantiation of the frame-
work proposed in Section 3 that achieves differential privacy
of the KME by projecting it onto a ﬁnite-dimensional sub-
space of the RKHS spanned by feature maps k(zm, ·) of
synthetic data points z1, . . . , zM , and perturbing the result-
ing ﬁnite coordinate vector. To ensure differential privacy,
the synthetic data points are chosen independently of the
private database. As a result, statistical efﬁciency of this
approach will depend on the choice of synthetic data points,
with efﬁciency increasing if there are enough synthetic data
points to capture the patterns in the private data. Therefore
this algorithm is especially suited to the scenario discussed
in Section 1, where a part of the database (or of a similar
one) has already been published, as this can serve as a good
starting set for the synthetic data points.

The setting where some observations from X have already
been released highlights the fact that differential privacy
only protects against additional privacy violation due to an
individual deciding to contribute to the private database; if a
particular user’s data has already been published, differential
privacy does not protect against privacy violations based on
exploiting this previously published data.

The algorithm is formalised as Algorithm 1 above. Lines 1-
2 choose synthetic data points z1, . . . , zM independently of
the private data (only using the database size N ). Lines 3-4
construct the linear subspace HM of H spanned by feature
maps of the chosen synthetic data points, and compute a (ﬁ-
nite) basis for it. Only then the private data is accessed: the
empirical KME ˆµX is computed (line 5), projected onto the
subspace HM and expressed in terms of the precomputed
basis (line 6). The basis coefﬁcients of the projection are
then perturbed to achieve differential privacy (line 7), and
the perturbed element ˜µX ∈ HM is then re-expressed in
terms of the spanning set containing feature maps of syn-
thetic data points (line 8). This expansion is ﬁnally released
to the public (line 9).

Line 1 stipulates that the number of synthetic data points
M → ∞ as N → ∞, but asymptotically slower than N 2.
This is to ensure that the privatisation noise added in the
subspace HM to each coordinate is small enough overall
to preserve consistency, as stated in the following Theo-
rem 2. This theorem assures us that Algorithm 1 produces
a consistent estimator of the true KME µX , if the synthetic
data points are sampled from a distribution with sufﬁciently
large support. Due to space constraints, all proofs appear in
Appendix A.

Theorem 2. Let X be a compact metric space and k a con-
tinuous kernel on X . If the synthetic data points z1, z2, . . .
are sampled i.i.d. from a distribution q on X such that
the support of X is included in the support of q, then Al-
gorithm 1 outputs a consistent estimator of the KME µX :
P
(cid:80)M
→ µX as N → ∞.

m=1 wmk(zm, ·)

As discussed by Simon-Gabriel et al. (2016), these assump-
tions are usually satisﬁed: X can be taken to be compact
whenever the data comes from measurements with any
bounded range, and many kernels are continuous, including
all kernels on discrete spaces (w.r.t. to the discrete topology).

In order to use the output of Algorithm 1 in the very general
kernel probabilistic programming framework and obtain a
consistent estimator of the KME µf (X) of f (X) for any
continuous function f , there is a technical condition that the
L1 norm (cid:80)M
m=1 |wm| of the released weights may need to
remain bounded by a constant as N → ∞ (Simon-Gabriel
et al., 2016). This is not enforced by Algorithm 1, but Theo-
rem 11 in Appendix A.1 shows how a simple regularisation
in the ﬁnal stage of the algorithm achieves this without
breaking consistency (or privacy).

The next result about Algorithm 1 shows that it is differen-
tially private whenever k(x, x) ≤ 1 for all x ∈ X . This is a
weak assumption that holds for all normalised kernels, and
can be achieved by simple rescaling for any bounded kernel
(such that supx∈X k(x, x) < ∞). When X is a compact
domain, all continuous kernels are bounded.

Differentially Private Database Release via Kernel Mean Embeddings

Figure 1: RKHS distance (lower is better) to the (private) empirical KME ˆµX computed using the entire private database of size
N = 100, 000. The dimension of the database was D = 2 (left) or D = 5 (right); please see Appendix B for further details of the setup.
Horizontally we varied M , the number of publicly releasable data points. Stricter privacy requirements (lower ε) naturally lead to lower
accuracy. Increasing M does not always necessarily improve accuracy, since a new public data point always increases the total amount of
privatising noise that needs to be added, but this might not be outweighed by its positive contribution towards covering relevant parts of
the input space. In all cases, for sufﬁciently small M Algorithm 1 provided a signiﬁcantly more accurate estimate than µbaseline.

Proposition 3. If k(x, x) ≤ 1 for all x ∈ X , then Algo-
rithm 1 is (ε, δ)-differentially private.

Remark 4. One usually requires that δ decreases faster than
polynomially with the database size N (Dwork & Roth,
2014). The proof of Theorem 2 remains valid whenever
M (N ) ∈ o(N 2/ ln(1.25/δ(N ))), so for example we could
have δ(N ) = e−

N and M (N ) ∈ o(N 3/2).

√

For a ﬁnite private database, actual performance will heavily
depend on how the synthetic data points are chosen. We
consider the following two extreme scenarios:

1. No publishable subset: No rows of the private database

are, or can be made public unmodiﬁed.

2. Publishable subset: A small proportion of the private
database is already public, or can be made public.

Proposition 5 (Algorithm 1, No publishable subset). Say
X is a bounded subset of RD, the kernel k is Lipschitz, and
the synthetic data points z1, z2, . . . are sampled i.i.d. from
a distribution q with density bounded away from 0 on any
bounded subset of RD. Then M = M (N ) can be chosen
so that the output of Algorithm 1 converges to the true KME
µX in RKHS norm at a rate Op(N −1/(D+1+c)), where c is
any ﬁxed positive number c > 0.

Unsurprisingly, the convergence rate deteriorates with input
dimension D, since without prior information about the pri-
vate data manifold it is increasingly difﬁcult for randomly
sampled synthetic points to capture patterns in the private
data. One of the main strengths of KMEs is that the em-
pirical estimator converges to the true embedding at a rate

Op(N −1/2) independently of the input dimension D, so we
see that in this unfavourable scenario Algorithm 1 incurs a
substantial privacy cost in high dimensions. On the other
hand, if a small, but ﬁxed proportion of the private database
is publishable, then Algorithm 1 incurs no privacy cost in
terms of the convergence rate:

Proposition 6 (Algorithm 1, Publishable subset). Say that a
ﬁxed proportion η of the private database can be published
unmodiﬁed. Using this part of the database as the synthetic
data points, Algorithm 1 outputs a consistent estimator of
µX that converges in RKHS norm at a rate Op(N −1/2).

(cid:80)M

Note that in this scenario the rate Op(N −1/2) can be also
achieved by uniform weighting of the synthetic data points,
since ˆµbaseline := 1
m=1 k(zm, ·) with zm = xm is al-
M
ready a consistent estimator of µX (although based on a
much smaller sample size M = ηN (cid:28) N ). The purpose of
Algorithm 1 is to ﬁnd (generally non-uniform) w1, . . . , wM
that reweight the public data points using the information in
the large private dataset, but respecting differential privacy.
Proposition 6 conﬁrmed theoretically that this does not hurt
the convergence rate, while Figure 1 shows empirically on
two synthetic datasets of dimensions D = 2 and D = 5
that Algorithm 1 can in fact yield more accurate estimates
of the KME than ˆµbaseline, especially when the proportion
of public data points is small. This is encouraging, since
obtaining permission to publish a larger subset of the pri-
vate data unchanged will usually come at an increased cost.
The ability to instead reweight a smaller public dataset in a
differentially private manner using Algorithm 1 is therefore
useful.

Differentially Private Database Release via Kernel Mean Embeddings

Algorithm 2 Differentially private database release via a random features RKHS

Input: database D = {x1, . . . , xN } ⊆ X , kernel k on X , privacy parameters ε > 0 and δ > 0
Output: (ε, δ)-differentially private, weighted synthetic database (representing an estimate of µX in the RKHS H of k)
1: J ← J(N ) ∈ ω(1) ∩ o(N 2), number of random features to use
2: φ ← random feature map X (cid:55)→ RJ for kernel k with J features
3: ˆµφ
4: ˜µφ
5: M ← M (N ) ≥ N , number of synthetic expansion points to use for representing ˜µφ
X
6: (z1, w1), . . . , (zM , wM ) ← approximate ˜µφ

n=1 φ(xn) ∈ RJ , empirical KME of X in RKHS Hφ of the random features kernel kφ(·, ·) := φ(·)T φ(·)

IJ ), an (ε, δ)-differentially private version of the vector ˆµφ

(cid:80)N
X + N (0, 8 ln(1.25/δ)

X in the RKHS Hφ using a Reduced set method:

X (Gaussian mechanism)

X ← 1
N
X ← ˆµφ

N 2ε2

(z1, w1), . . . , (zM , wM ) ≈

(z(cid:48)

1,w(cid:48)

1),...,(z(cid:48)

argmin
M ,w(cid:48)

M ) s.t. (cid:80)

m |w(cid:48)

m|≤1

m=1

w(cid:48)

mφ(z(cid:48)

m) − ˜µφ

X

(5)

M
(cid:88)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)Hφ

7: return (z1, w1), . . . , (zM , wM )

5. Perturbation in Random-Features RKHS

Another approach to ensuring differential privacy is to map
the potentially inﬁnite dimensional RKHS H of k into a
different, ﬁnite-dimensional RKHS Hφ using random fea-
tures (Rahimi & Recht, 2007), privacy-protect the ﬁnite
coordinate vector in this space (Chaudhuri et al., 2011),
and then employ a reduced set method to ﬁnd an expansion
of the resulting RKHS element in terms of synthetic data
points. In contrast to Algorithm 1, both the weights and
locations of synthetic data points can be optimised here.

The algorithm is formalised as Algorithm 2 above. Lines 1-
2 pick the number J = J(N ) of random features to use, and
construct a random feature map φ with that many features.
Lines 3-4 compute the empirical KME of X in the RKHS
Hφ corresponding to the kernel induced by the random
features, and then privacy-protect the resulting ﬁnite, real-
valued vector. Lines 5-6 run a blindly initialised Reduced
set method to ﬁnd a weighted synthetic dataset whose KME
in Hφ is close to the privacy-protected KME of the private
database. Line 7 releases this weighted dataset to the public.

The following theorem conﬁrms that Algorithm 2 outputs a
consistent estimator of the true KME µX , provided that the
optimisation problem (5) is solved exactly, and the random
features converge to the kernel k uniformly on X . On com-
pact sets X this requirement is satisﬁed by general schemes
such as random Fourier features and random binning for
shift-invariant kernels (Rahimi & Recht, 2007), or by ran-
dom features for dot product kernels (Kar & Karnick, 2012).
Theorem 7. If φ(·)T φ(·) → k(·, ·) converges uniformly in
X × X as J → ∞, then the output of Algorithm 2 is a
consistent estimator of the true KME µX as N → ∞.

Moreover, a uniform convergence rate for the random fea-
tures, such as the one for random Fourier features by Sripe-
rumbudur & Szabo (2015), can be used to derive a conver-
gence rate for the output of Algorithm 2:

Proposition 8. If φ(·)T φ(·) → k(·, ·) converges uniformly
in X × X at a rate Op(J −1/2) as J → ∞, then J = J(N )
can be chosen so that the output of Algorithm 2 converges
to the true KME µX at a rate Op(N −1/3).

The empirical KME of the private database ˆµX converges at
a rate Op(N −1/2), so we see that under perfect optimisation,
the privacy cost incurred by Algorithm 2 is a factor of N 1/6.
In practice performance will also depend on the Reduced
set method used, and the computational budget allocated
to it. Figure 2 shows how the incurred error (in terms of
RKHS distance) varies with the number of synthetic data
points M . The additional ability of Algorithm 2 to optimise
the locations of the synthetic data points (rather than just
the weights, as in Algorithm 1) seems to be more helpful
in the higher-dimensional case D = 5, where the randomly
sampled synthetic data points are less likely to land close to
private data points.
Proposition 9. If (cid:107)φ(x)(cid:107)2 ≤ 1 for all x ∈ X , then Algo-
rithm 2 is (ε, δ)-differentially private.

This L2-boundedness requirement on the random feature
vectors φ(x) is reasonable under the weak assumption
k(x, x) ≤ 1 for all x ∈ X discussed in Section 4, as in
that case (cid:107)φ(x)(cid:107)2

2 = φ(x)T φ(x) ≈ k(x, x) ≤ 1.

6. Related Work

Synthetic database release algorithms with a differential
privacy guarantee have been studied in the literature before.
Machanavajjhala et al. (2008) analyzed such a procedure for
count data, ensuring privacy by sampling a distribution and
then synthetic counts from a Dirichlet-Multinomial poste-
rior. Blum et al. (2008) studied the exponential mechanism
applied to synthetic database generation, which leads to a
very general, but unfortunately inefﬁcient algorithm (see
also Section 3.4). Wasserman & Zhou (2010) provided a the-
oretical comparison of this algorithm to sampling synthetic

Differentially Private Database Release via Kernel Mean Embeddings

Figure 2: RKHS distance (lower is better) to the (private) empirical KME ˆµX computed using the same databases as in Figure 1, of
dimensions D = 2 (left) and D = 5 (right), but this time without a publishable subset. The synthetic data points for Algorithm 1 were
therefore sampled from a wide Gaussian distribution; please see Appendix B for further details. Algorithm 2 is capable of outperforming
Algorithm 1 thanks to its ability to optimise the synthetic data point locations, but this depends on the precise optimisation procedure used
and the optimisation problem becomes harder in higher dimensions.

databases from deterministically smoothed, or randomly
perturbed histograms. Unlike our approach, these algo-
rithms achieve differential privacy by sampling synthetic
data points from a speciﬁc distribution, where resorting to
approximate sampling can break the privacy guarantee. In
our framework we propose to arrive at the synthetic database
using a reduced set method, where poor performance could
affect statistical usefulness of the synthetic database, but
cannot break its differential privacy.

Zhou et al. (2009) and Kenthapadi et al. (2012) proposed
randomised database compression schemes that yield syn-
thetic databases useful for particular types of algorithms,
while guaranteeing differential privacy. The former com-
presses the number of data points using a random linear or
afﬁne transformation of the entire database, and the result
can be used by procedures that rely on the empirical covari-
ance of the original data. The latter compresses the number
of data point dimensions while approximately preserving
distances between original, private data points.

Differentially private learning in a RKHS has also been stud-
ied, with Chaudhuri et al. (2011) and Rubinstein et al. (2012)
having independently presented release mechanisms for the
result of an empirical risk minimisation procedure (such
as a SVM). Similarly to our Algorithm 2, they map data
points into a ﬁnite-dimensional space deﬁned by random
features and carry out the privacy-protecting perturbation
there. However, they do not require the ﬁnal stage of invok-
ing a Reduced set method to construct a synthetic database,
because the output (such as a trained SVM) is only used for
evaluation on test points, for which it sufﬁces to additionally
release the used random feature map φ.

As our framework stipulates privacy-protecting an empirical

KME, which is a function X → R, the work on differential
privacy for functional data is of relevance. Hall et al. (2013)
showed how an RKHS element can be made differentially
private via pointwise addition of a Gaussian process sample
path, but as discussed in Section 3.2, the resulting function
is no longer an element of the RKHS. Recently, Ald`a & Ru-
binstein (2017) proposed a general Bernstein mechanism for
ε-differentially private function release. The released func-
tion can be evaluated pointwise arbitrarily many times, but
again, the geometry of the RKHS to which the unperturbed
function belonged cannot be easily exploited anymore.

7. Discussion

We proposed a framework for constructing differentially
private synthetic database release algorithms, based on the
idea of using KMEs in RKHS as intermediate database rep-
resentations. To justify our framework, we presented two
concrete algorithms and proved theoretical results guaran-
teeing their consistency and differential privacy. We also
studied their ﬁnite-sample convergence rates, and provided
empirical illustrations of their performance on synthetic
datasets. We believe that exploring other instantiations of
this framework, and comparing them theoretically and em-
pirically, can be a fruitful direction for future research.

The i.i.d. assumption on database rows can be relaxed. For
example, if they are identically distributed (as a random
variable X), but not necessarily independent, the framework
remains valid as long as a consistent estimator of the KME
µX can be constructed from the database rows. A common
situation where this arises is, for example, duplication of
database rows due to user error.

Differentially Private Database Release via Kernel Mean Embeddings

Acknowledgements

The authors would like to thank Bharath Sriperumbudur and
the anonymous reviewers for helpful feedback.

References

Ald`a, F. and Rubinstein, B. I. P. The Bernstein mechanism: Func-

tion release under differential privacy. In AAAI, 2017.

Blum, A., Ligett, K., and Roth, A. A learning theory approach to
non-interactive database privacy. In 40th ACM Symposium on
Theory of Computing, 2008.

Burges, C. J. C. Simpliﬁed support vector decision rules. In ICML,

1996.

Chaudhuri, K., Monteleoni, C., and Sarwate, A. D. Differentially

private empirical risk minimization. JMLR, 12, 2011.

Rasmussen, C. E. and Williams, C. K. I. Gaussian Processes for

Machine Learning. The MIT Press, 2005.

Rubinstein, B. I. P., Bartlett, P. L., Huang, L., and Taft, N. Learning
in a large function space: Privacy-preserving mechanisms for
SVM learning. The Journal of Privacy and Conﬁdentiality, 4
(1), 2012.

Sch¨olkopf, B. and Smola, A. J. Learning with Kernels: Support
Vector Machines, Regularization, Optimization, and Beyond.
MIT Press, 2002.

Sch¨olkopf, B., Muandet, K., Fukumizu, K., Harmeling, S., and
Peters, J. Computing functions of random variables via Re-
producing Kernel Hilbert Space representations. Statistics and
Computing, 25, 2015.

Simon-Gabriel, C.-J., ´Scibior, A., Tolstikhin, I., and Sch¨olkopf, B.
Consistent Kernel Mean Estimation for Functions of Random
Variables. In NIPS, 2016.

Chen, Y., Welling, M., and Smola, A. Super-samples from kernel

herding. In UAI, 2010.

Smola, A., Gretton, A., Song, L., and Sch¨olkopf, B. A Hilbert

space embedding for distributions. In ALT, 2007.

Dwork, C. Differential privacy. In 33rd International Conference
on Automata, Languages and Programming (ICALP), 2006.

Sriperumbudur, B. and Szabo, Z. Optimal rates for random Fourier

features. In NIPS. 2015.

Sriperumbudur, B. K., Fukumizu, K., and Lanckriet, G. R. G.
Universality, characteristic kernels and RKHS embedding of
measures. JMLR, 2011.

Tolstikhin, I., Sriperumbudur, B. K., and Muandet, K. Minimax

estimation of kernel mean embeddings. JMLR, 18, 2017.

Wasserman, L. and Zhou, S. A statistical framework for differential
privacy. Journal of the American Statistical Association, 105,
2010.

Zhou, S., Ligett, K., and Wasserman, L. Differential privacy with
compression. In IEEE International Conference on Symposium
on Information Theory (ISIT), 2009.

Dwork, C. and Roth, A. The Algorithmic Foundations of Differen-
tial Privacy. Foundations and Trends in Theoretical Computer
Science, 9, 2014.

Fukumizu, K., Gretton, A., Sun, X., and Sch¨olkopf, B. Kernel

measures of conditional dependence. In NIPS, 2008.

Gretton, A., Bousquet, O., Smola, A., and Sch¨olkopf, B. Measur-
ing statistical dependence with Hilbert-Schmidt norms. In ALT,
2005.

Gretton, A., Borgwardt, K. M., Rasch, M. J., Sch¨olkopf, B., and

Smola, A. A kernel two-sample test. JMLR, 13, 2012.

Hall, R., Rinaldo, A., and Wasserman, L. Differential Privacy for

Functions and Functional Data. JMLR, 14, 2013.

Kar, P. and Karnick, H. Random feature maps for dot product

kernels. In AISTATS, 2012.

Kenthapadi, K., Korolova, A., Mironov, I., and Mishra, N. Privacy
via the Johnson-Lindenstrauss transform. arXiv:1204.2606 [cs],
2012.

Lopez-Paz, D., Muandet, K., Sch¨olkopf, B., and Tolstikhin, I.
Towards a learning theory of cause-effect inference. In ICML,
2015.

Machanavajjhala, A., Kifer, D., Abowd, J., Gehrke, J., and Vilhu-
ber, L. Privacy: Theory meets practice on the map. In IEEE
24th International Conference on Data Engineering, 2008.

McSherry, F. and Talwar, K. Mechanism design via differential
privacy. In 48th Annual IEEE Symposium on Foundations of
Computer Science (FOCS), 2007.

Muandet, K., Sriperumbudur, B., Fukumizu, K., Gretton, A., and
Sch¨olkopf, B. Kernel mean shrinkage estimators. JMLR, 17,
2016.

Rahimi, A. and Recht, B. Random features for large scale kernel

machines. In NIPS, 2007.

Differentially Private Database Release via Kernel Mean Embeddings

APPENDIX: Differentially Private Database Release via Kernel Mean Embeddings

A. Proofs

Here we provide proofs for the results stated in the main text, together with additional supporting lemmas required for these
proofs.

A.1. Algorithm 1 (Synthetic Data Subspace): Consistency

Before proving Theorem 2, we obtain a Lemma showing that the “projection error” incurred due to projecting the KME ˆµX
onto the ﬁnite-dimensional subspace HM spanned by the synthetic data points, quantiﬁed by the RKHS distance between
ˆµX and the projection µX , converges to 0 as N → ∞:
Lemma 10. Let X be a compact metric space and k : X × X → R a continuous kernel on X . Suppose that the synthetic
data points z1, z2, . . . are sampled i.i.d. from a probability distribution q on X . If the support supp(X) of X is included in
the support of q, then

(cid:107)µX − ˆµX (cid:107)H

P
→ 0 as N → ∞.

(6)

Proof. Let ε > 0. As k is continuous on X × X , which as a product of compact spaces is itself compact by Tychonoff’s
theorem, the kernel k is uniformly continuous and in particular there exists δ > 0 such that for all x, x(cid:48) ∈ X we have
|k(x, x) − k(x, x(cid:48))| < ε2/2 whenever (cid:107)x − x(cid:48)(cid:107)X < δ. As X is compact, it is totally bounded, and thus so is its subset
supp(X). Therefore supp(X) can be covered with ﬁnitely many open balls B1, . . . , BK of radius δ/2. Let the sequence
z1, z2, . . . be sampled i.i.d. from q, and let EM be the event that at least ones of these K balls contains no element of
z1, . . . , zM . Since supp(X) ⊆ supp(q) by assumption, we have q(Bk) > 0 for all k = 1, . . . , K and therefore P[EM ] → 0
as M → ∞.

Note that if all K balls contain an element of z1, . . . , zM (i.e., EC
1 ≤ m(x) ≤ M such that (cid:107)x − zm(x)(cid:107) < δ/2 + δ/2 = δ. In that case

M holds), then for each x ∈ supp(X) one can ﬁnd

(cid:107)h − ˆµX (cid:107)H

(cid:107)µX − ˆµX (cid:107)H = inf
h∈HM
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
N

≤

N
(cid:88)

n=1

k(zm(xn), ·) − ˆµX

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)H

(cid:13)k(zm(xn), ·) − k(xn, ·)(cid:13)
(cid:13)
(cid:13)H

≤

<

1
N

1
N

N
(cid:88)

n=1

N
(cid:88)

n=1

ε

= ε,

[property of projection]

[as 1
N

(cid:80)N

n=1 k(zm(xn), ·) ∈ HM ]

[Triangle inequality]

[see below]

where we have used the reproducing property, the Triangle inequality and our choices of δ and zm(xn) to see that for all
1 ≤ n ≤ N ,

(cid:13)
(cid:13)k(zm(xn), ·) − k(xn, ·)(cid:13)

(cid:13)H = (cid:104)k(zm(xn),· − k(xn, ·), k(zm(xn),· − k(xn, ·)(cid:105)1/2

H

(cid:16)

k(zm(xn), zm(xn)) − 2k(zm(xn), xn) + k(xn, xn)

=
≤ (cid:0)|k(zm(xn), zm(xn)) − k(zm(xn), xn)| + |k(xn, xn) − k(zm(xn), xn)|(cid:1)1/2

(cid:17)1/2

<

(cid:18) ε2
2

+

ε2
2

(cid:19)1/2

= ε.

Hence we have that P [(cid:107)µX − ˆµX (cid:107)H > ε] ≤ P[EM ] → 0 as M → ∞. But since ε > 0 was arbitrary and M → ∞ as
N → ∞ by construction, the claimed convergence in probability result follows from deﬁnition.

(7)

(8)

(9)

(10)

(11)

Differentially Private Database Release via Kernel Mean Embeddings

Theorem 2. Let X be a compact metric space and k : X × X → R a continuous kernel on X . Suppose that the synthetic
data points z1, z2, . . . are sampled i.i.d. from a probability distribution q on X . If the support of X is included in the support
of q, then Algorithm 1 outputs a consistent estimator of the kernel mean embedding µX in the sense that

M
(cid:88)

m=1

wmk(zm, ·)

P
→ µX

as N → ∞.

Proof. Using the Triangle inequality, we can upper bound the RKHS distance between the output ˜µX of Algorithm 1 and
the true kernel mean embedding µX as follows:

(cid:107)˜µX − µX (cid:107)H ≤ (cid:107)˜µX − µX (cid:107)H
(cid:125)

(cid:124)

(cid:123)(cid:122)
privacy error

+ (cid:107)µX − ˆµX (cid:107)H
(cid:123)(cid:122)
(cid:125)
projection error

(cid:124)

+ (cid:107)ˆµX − µX (cid:107)H
(cid:124)
(cid:125)
(cid:123)(cid:122)
ﬁnite sample error

.

The ﬁnite sample error tends to 0 as N → ∞ by the law of large numbers, while the projection error tends to 0 as N → ∞
by Lemma 10. For the privacy error, using orthonormality of the basis {b1, . . . , bF } we have

(cid:107)˜µX − µX (cid:107)2

H =

(βf − αf )bf

=

(βf − αf )2 =

N (0, 1)2.

(14)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

F
(cid:88)

f =1

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

H

F
(cid:88)

f =1

8 ln(1.25/δ)
N 2ε2

F

1
F

F
(cid:88)

f =1

As a function of N , the size of the basis F ∈ N is a non-decreasing function, so it either converges to some L ∈ N, in
which case the obtained expression clearly tends to 0 as N → ∞ with probability 1, or F → ∞ as N → ∞. In this
latter case 1
f =1 N (0, 1)2 → 1 as N → ∞ a.s. by the strong law of large numbers, and F/N 2 → 0 as N → ∞ since
F
F ≤ M = o(N 2). Hence the privacy error goes to 0 as N → ∞ either way, as required to complete the proof.

(cid:80)F

Theorem 11. Suppose that the kernel k is c0-universal (Sriperumbudur et al., 2011) and f is any continuous function
mapping from X to some space Y. Let C ≥ 1 be any ﬁnite constant. If line 7 of Algorithm 1 is replaced with a regularised
reduced set method solving the constrained minimisation problem

then the points output by Algorithm 1 yield a consistent estimator of the kernel mean embedding E[k(f (X), ·)] of f (X) in
the sense that

w = argmin
u:(cid:107)u(cid:107)1≤C

˜µX −

umk(zm, ·)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

M
(cid:88)

m=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)H

,

M
(cid:88)

m=1

wmk(f (zm), ·)

P
→ µf (X)

as N → ∞.

X := (cid:80)M

Proof. Let µout
First we show that despite the regularisation, µout
N → ∞.

m=1 wmk(zm, ·) be the RKHS element output by Algorithm 1 after adding the stated regularisation.
X remains a consistent estimator of the true kernel mean embedding µX as

The modiﬁcation introduces an additional regularisation error term (cid:107)µout
X − µX (cid:107),
compared to the corresponding bound (13) in the proof of Theorem 2. So to show the ﬁrst desired consistency result, it
remains to show that this extra regularisation error term converges to 0 in probability as N → ∞. To this end, let ε > 0
be arbitrary. Deﬁne δ > 0, the sequence z1, z2, . . . and m(x) for x ∈ X as in the proof of Lemma 10. Note that the
RKHS element 1
n=1 k(zm(xn), ·) is in the feasible set of the regularised minimisation problem (15), because the sum of
N
absolute values of expansions coefﬁcients is

X − ˜µX (cid:107)H into the upper bound on (cid:107)µout

(cid:80)N

M
(cid:88)

(cid:88)

m=1

n:m(xn)=n

1
M

=

N
(cid:88)

n=1

1
N

= 1 ≤ C

(12)

(13)

(15)

(16)

(17)

Differentially Private Database Release via Kernel Mean Embeddings

Therefore the regularisation error can be upper bounded as
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)H
N
(cid:88)

k(zm(xn), ·) − ˜µX

X − ˜µX (cid:107)H ≤

(cid:107)µout

N
(cid:88)

1
N

n=1

≤ (cid:107)˜µX − ˆµX (cid:107)H +

ˆµX −

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
N

n=1

(cid:13)
(cid:13)
(cid:13)
k(zm(xn), ·)
(cid:13)
(cid:13)H

[property of min]

[Triangle inequality]

The ﬁrst term goes to 0 as N → ∞ by the argument given in the proof of Theorem 2. The probability that the second term
is larger than ε converges to 0 as N → ∞ using the argument given in the proof of Lemma 10. Hence we have the desired
convergence of the modiﬁed Algorithm 1’s output µout
X to the true kernel mean embedding µX as N → ∞, in probability.
This means that the modiﬁed algorithm still outputs a consistent estimator of the kernel mean embedding of µX . Moreover,
the weights in the released ﬁnite expansion now have their L1 norm (cid:80)M
m=1 |wm| bounded by the constant C by construction,
so Theorem 1 of (Simon-Gabriel et al., 2016) applies and gives the desired conclusion regarding consistency of the estimator
for the kernel mean embedding µf (X) of f (X).

A.2. Algorithm 1 (Synthetic Data Subspace): Convergence Rates

Towards proving the convergence rate of Proposition 5, we will make use of the following Lemma 12, which is a reﬁnement
of the corresponding consistency result of Lemma 10 above. It uses the Lipschitz assumption on the kernel to establish a
quantitative dependence between ε and δ, and the condition on q to establish a dependence between δ, K and P[EM ].
Lemma 12. Suppose that X is a bounded subset of RD, the kernel k is Lipschitz with some Lipschitz constant L ∈ R+,
and the synthetic data points z1, z2, . . . are sampled i.i.d. from a distribution q whose density is bounded away from 0 on
any bounded subset of RD. Then

∀γ ∈ (0, 1), a > 0

∃C ∈ R, ε0 > 0

∀ε ∈ (0, ε0) M ≥ Cε−2D−a ⇒ P [(cid:107)ˆµX − ¯µX (cid:107)H ≥ ε] ≤ γ.

Proof. Let γ ∈ (0, 1) and a > 0. Suppose for the moment that C and ε0 have already been chosen based on X , q, γ, a and
based on the Lipschitz constant L of the kernel k. Let ε ∈ (0, ε0) and suppose that M ≥ Cε−2D−a.
Deﬁne δ = ε2

2L and let B1, . . . , BK be a covering of supp(X) with K open balls of radii δ

2 . By the Lipschitz property

(cid:107)x − x(cid:48)(cid:107)X < δ ⇒ |k(x, x(cid:48)) − k(x, x)| ≤ L(cid:107)x − x(cid:48)(cid:107)X < Lδ =

ε2
2

and so by the argument appearing in the proof of Lemma 10, if each ball Bk contains at least one synthetic data point zm,
then (cid:107)ˆµX − ¯µX (cid:107)H < ε. Therefore it sufﬁces to show that if M ≥ Cε−2D(1+a), then the probability of some of the balls
not containing any synthetic data point is at most γ.

To this end, let us look at the number of balls K, and the probability that a synthetic data point lands in a particular ball, as
2 ). First, since X is a bounded subset of RD, there exists C1 ∈ R such that for all δ > 0,
functions of ε (via the ball radius δ
the space X can be covered with (cid:98)C1δ−D(cid:99) open balls of radii δ/2. Second, since the density of q is assumed to be bounded
away from 0 on any bounded subset of RD, there exists C2 ∈ R such that q(Bk) ≥ C2δD for all k.
Let AM
probability of the event EM that any of the K balls remains empty can be upper bounded by a union bound as

k be the event that the ball Bk remains without a synthetic data point after M of them have been sampled. Then the

P[EM ] ≤

P[AM

k ] =

(1 − q(Bk))M ≤

(1 − C2δD)M ≤ K exp (cid:0)−M C2δD(cid:1) ≤ C1δ−D exp (cid:0)−M C2δD(cid:1) .

K
(cid:88)

k=1

K
(cid:88)

k=1

K
(cid:88)

k=1

Solving for M , we can easily verify that P[EM ] ≤ γ is ensured whenever
(cid:18)
(cid:18)

(cid:19)

M ≥

1
C2δD

1
ε2D
εa for all sufﬁciently small ε, we see that we could have chosen ε0 > 0 and C ∈ R such that the right-hand
Since ln 1
side is at most Cε−2D−a for all ε ∈ (0, ε0). But the condition M ≥ Cε−2D−a is satisﬁed by supposition, and so we
conclude that P [(cid:107)ˆµX − ¯µX (cid:107)H] ≤ P[EM ] ≤ γ.

ε < 1

C1(2L)D
γ

(2L)D
C2

C1
γ

D ln

+ ln

+ ln

2 ln

1
δ

1
ε

=

(cid:19)

Differentially Private Database Release via Kernel Mean Embeddings

Proposition 5 Suppose that X is a bounded subset of RD, the kernel k is Lipschitz, and the synthetic data points z1, z2, . . .
are sampled i.i.d. from a distribution q whose density is bounded away from 0 on any bounded subset of RD. Then M (N )
can be chosen so that Algorithm 1 outputs an estimator that converges to the true kernel mean embedding µX in RKHS
norm at a rate Op(N −1/(D+1+c)), where c is any ﬁxed positive number c > 0.

Proof. As in the proof of Theorem 2, we can decompose the error between the released element ˜µX and the true µX as

(cid:107)˜µX − µX (cid:107)H ≤ (cid:107)ˆµX − µX (cid:107)H
(cid:124)
(cid:125)
(cid:123)(cid:122)
ﬁnite sample error

+ (cid:107)µX − ˆµX (cid:107)H
(cid:123)(cid:122)
(cid:125)
projection error

(cid:124)

+ (cid:107)˜µX − µX (cid:107)H
(cid:123)(cid:122)
(cid:125)
privacy error

(cid:124)

.

(18)

Using the standard empirical kernel mean embedding estimator, the ﬁnite sample error vanishes as Op(N −1/2) (Muandet
et al., 2016). From the proof of Theorem 2 we can see that the privacy error vanishes as Op(
M /N ).
Solving for ε in the statement of the preceding Lemma 12 we have that for all γ ∈ (0, 1), a > 0 and all sufﬁciently large M ,

F /N ) ⊆ Op(

√

√

(cid:20)
(cid:107)ˆµX − ¯µX (cid:107)H ≥

P

(cid:21)

M − 1

2D+a

≤ γ.

1
C

The projection error thus vanishes at a rate Op(M −1/(2D+a)), for any arbitrarily small a > 0. To achieve the claimed total
rate Op(N −1/(D+1+c)) we choose M (N ) = N k with k = 1 − 4/(2D + a + 2), and verify that

(cid:32)

1
√
N

Op

+ M

−1
2D+a +

√

(cid:33)

M
N

= Op

(cid:32)

1
√
N

+ N

−k
2D+a +

√

(cid:33)

N k
N

= Op

(cid:18) 1
√
N

+ N −

1
D+1+a/2

(cid:19)

= Op

(cid:16)

N −

1
D+1+a/2

(cid:17)

and the claimed result follows by taking a = 2c > 0.

Proposition 6 Suppose that a ﬁxed proportion η of the private database can be published without modiﬁcation. Using this
part of the database as the synthetic data points, Algorithm 1 outputs a consistent estimator of µX that converges in RKHS
norm at a rate Op(N −1/2).

Proof. Let ˆµbaseline := 1
m=1 k(zm, ·) be the baseline estimator that weights the M public points uniformly. Noting that
M
ˆµbaseline ∈ HM lies in the span of feature maps of synthetic data points, for the projection error as deﬁned in equation (18)
we have:

(cid:80)M

(cid:107)µX − ˆµX (cid:107)H = (cid:13)
= (cid:13)

(cid:13)ˆµbaseline − ˆµX
(cid:13)ˆµbaseline − µX
M −1/2(cid:17)

(cid:16)

(cid:13)
(cid:13)H
(cid:13)
(cid:13)H + (cid:107)ˆµX − µX (cid:107)H
N −1/2(cid:17)
+ Op

(cid:16)

∈ Op

[ property of projection ]

[ Triangle inequality ]

Using the error decomposition of equation (18) we thus have

(cid:107)˜µX − µX (cid:107)H ∈ Op

N −1/2 + (M −1/2 + N −1/2) +

M /N

(cid:16)

√

(cid:17)

and this is in Op(N −1/2) when M = ηN is proportional to N .

A.3. Algorithm 1 (Synthetic Data Subspace): Differential Privacy

The proof of Proposition 3 rests on the following simple calculation:

Lemma 13. If k(x, x) ≤ 1 for all x ∈ X , then the RKHS norm sensitivity of the empirical kernel mean embedding ˆµX with
respect to changing one data point is at most 2
N .

Proof. Let D = {x1, . . . , xN } and D(cid:48) = {x(cid:48)
row. Without loss of generality xn = x(cid:48)

1, . . . , x(cid:48)

n for 1 ≤ n ≤ N − 1. Let ˆµX and ˆµ(cid:48)

N } be two databases of the same cardinality N , differing in a single
X be the empirical kernel mean embeddings

Differentially Private Database Release via Kernel Mean Embeddings

computed using D and D(cid:48), respectively. Then

(cid:107)ˆµX − ˆµ(cid:48)

X (cid:107)H =

k(xn, ·) −

k(x(cid:48)

n, ·)

(cid:107)k(xN , ·) − k(x(cid:48)

N , ·)(cid:107)H

N
(cid:88)

n=1

1
N

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
1
N

1
N

N
(cid:88)

n=1

=

1
N

(cid:16)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)H
1
N

≤

((cid:107)k(xN , ·)(cid:107)H + (cid:107)k(xN , ·)(cid:107)H) =

k(xN , xN )1/2 + k(x(cid:48)

N , x(cid:48)

N )1/2(cid:17)

≤

2
N

.

(19)

(20)

As D and D(cid:48) were arbitrary neighbouring databases, the claimed result follows.

Proposition 3.

If k(x, x) ≤ 1 for all x ∈ X , then Algorithm 1 is (ε, δ)-differentially private.

Proof. As the synthetic data points z1, . . . , zM do not depend on the private data, it sufﬁces to show that the weights
w1, . . . , wM are (ε, δ)-differentially private. However, these weights result from data-independent post-processing of the
coefﬁcients β, which are a perturbed version of the coefﬁcients α, with the perturbation provided by the privacy-protecting
Gaussian mechanism (Dwork & Roth, 2014). It remains to verify that the Gaussian mechanism employs sufﬁciently scaled
noise; in particular we need to verify that 2/N ≥ ∆2 := supD,D(cid:48):D∼D(cid:48) (cid:107)α − α(cid:48)(cid:107)2.
But indeed, since b1, . . . , bF are orthonormal, for any α and α(cid:48) computed using neighbouring databases,

(cid:107)α − α(cid:48)(cid:107)2 =

(αf − α(cid:48)

f )2



=

(cid:13)
(cid:13)
(cid:13)ˆµN − ˆµ(cid:48)

N

(cid:13)
(cid:13)
(cid:13)H

≤ (cid:107)ˆµN − ˆµ(cid:48)

N (cid:107)H ≤

2
N

,

(21)



1/2





F
(cid:88)

f =1

(last inequality is Lemma 13) as required to verify the Gaussian mechanism. Then (ε, δ)-differential privacy for the entire
algorithm follows.

A.4. Algorithm 2 (Random Features RKHS Algorithm): Consistency

As a preliminary lemma, we ﬁrst show that a uniform convergence result for the random features φ translates into a bound
on the error incurred by Algorithm 2 due to using random features instead of the original kernel k.
Lemma 14. Let ˆµout
X := (cid:80)M
ˆµφ,out
φ is such that supx,x(cid:48)∈X |φ(x)T φ(x(cid:48)) − k(x, x(cid:48))| < δ, then the following bound on the “random features error” holds:

m=1 wmk(zm, ·) ∈ H be the element in H represented by the output of Algorithm 2. Let
m=1 wmφ(zm) be the corresponding element in the random features RKHS Hφ. If the random feature scheme

X := (cid:80)M

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:13)
(cid:13)ˆµφ,out
(cid:13)

X − ˆµφ

X

(cid:13)
(cid:13)
(cid:13)Hφ

− (cid:107)ˆµout

X − ˆµX (cid:107)H

√

≤ 2

δ.

(cid:12)
(cid:12)
(cid:12)
(cid:12)

Proof. Expanding the RKHS norms using bilinearity of inner products, we have
(cid:12)
(cid:12)
(cid:12)
(cid:12)

X − ˆµφ

(cid:13)
(cid:13)
(cid:13)Hφ

X − ˆµX

(cid:13)ˆµout

− (cid:13)

(cid:13)
(cid:13)H

(cid:12)
(cid:12)
(cid:12)
(cid:12)

X

(cid:13)
(cid:13)ˆµφ,out
(cid:13)
(cid:12)
(cid:32) M
(cid:12)
(cid:88)
(cid:12)
(cid:12)
(cid:12)

=

M
(cid:88)

m1=1

m2=1

(cid:32) M
(cid:88)

M
(cid:88)

−

m2=1

m1=1
Since (cid:80)M

wm1wm2 φ(zm1)T φ(zm2) +

φ(xn1)T φ(xn2) − 2

wm

φ(zm)T φ(xn)

N
(cid:88)

N
(cid:88)

n1=1

n2=1

1
N

1
N

N
(cid:88)

N
(cid:88)

n1=1

n2=1

1
N

1
N

M
(cid:88)

N
(cid:88)

m=1

n=1

1
N

M
(cid:88)

N
(cid:88)

m=1

n=1

1
N

(cid:33)1/2 (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

wm1wm2k(zm1, zm2) +

k(xn1 , xn2 ) − 2

wm

k(zm, xn)

(cid:33)1/2

m=1 |wm| ≤ 1 by construction and (cid:80)N

n=1

1
N = 1, thanks to the assumption on φ this expression is of the form

(cid:12)
(cid:12)

(cid:12)(a + b + 2c)1/2 − (A + B + 2C)1/2(cid:12)
for suitable a, A, b, B, c, C ∈ R with |a − A|, |b − B|, |c − C| < δ. By monotonicity of the square root function, this
expression is maximised when A = a + δ, B = b + δ, C = c + δ. Writing s := a + b + 2C, we have
(cid:12)
(cid:12)

(cid:12) ≤ |s1/2 − (s + 4δ)1/2| = (s + 4δ)1/2 − s1/2 ≤ s1/2 + 2δ1/2 − s1/2 = 2δ1/2.
(cid:12)

(cid:12)(a + b + 2c)1/2 − (A + B + 2C)1/2(cid:12)

(cid:12)
(cid:12)

Differentially Private Database Release via Kernel Mean Embeddings

Theorem 7 Suppose that the random features φ converge φ(·)T φ(·) → k(·, ·) uniformly in X as the number of random
features J → ∞. Assume also availability of an approximate Reduced set construction method that solves the minimisation
(5) either up to a constant multiplicative error, or with an absolute error that can be made arbitrarily small. Then Algorithm 2
outputs a consistent estimator of the kernel mean embedding µX in the sense that

M
(cid:88)

m=1

wmk(zm, ·)

P
→ µX

as N → ∞.

Proof. The output of Algorithm 2 speciﬁes an element ˆµout
m=1 wmk(zm, ·) ∈ H in the RKHS H of k. Its RKHS
distance to the true kernel mean embedding µX of X can be upper bounded by a decomposition using the Triangle inequality,
X := (cid:80)M
where we write ˆµφ,out
m=1 wmφ(zm) for the element of Hφ that the Reduced set method constructs to approximate
the privacy-protected ˜µφ
X :

X := (cid:80)M

(cid:13)
(cid:13)µX − ˆµout
X

(cid:13)
(cid:13)H ≤ (cid:107)µX − ˆµX (cid:107)H
(cid:124)
(cid:125)
(cid:123)(cid:122)
ﬁnite sample error

(cid:13)
(cid:13)H
(cid:125)

X − ˆµφ

+

(cid:123)(cid:122)
other errors

+ (cid:13)
(cid:13)ˆµX − ˆµout
X
(cid:124)
(cid:12)
(cid:13)
(cid:12)
(cid:13)ˆµφ,out
(cid:13)
(cid:12)
(cid:12)
(cid:124)
(cid:12)
(cid:13)
(cid:12)
(cid:13)ˆµφ,out
(cid:13)
(cid:12)
(cid:12)
(cid:124)

+

X − ˆµφ

X

− (cid:13)

(cid:13)
(cid:13)
(cid:13)Hφ
(cid:123)(cid:122)
random features error

X

− (cid:13)

(cid:13)
(cid:13)
(cid:13)Hφ
(cid:123)(cid:122)
random features error

(cid:13)ˆµN − ˆµout
X

+

(cid:13)
(cid:13)ˆµφ,out
(cid:13)
(cid:124)

X − ˆµφ
(cid:123)(cid:122)
other errors

X

(cid:13)
(cid:13)
(cid:13)Hφ
(cid:125)

(cid:13)ˆµN − ˆµout
X

(cid:12)
(cid:12)
(cid:13)
(cid:12)
(cid:13)H
(cid:12)
(cid:125)
(cid:12)
(cid:12)
(cid:13)
(cid:12)
(cid:13)H
(cid:12)
(cid:125)

≤ (cid:107)µX − ˆµX (cid:107)H
(cid:124)
(cid:125)
(cid:123)(cid:122)
ﬁnite sample error

≤ (cid:107)µX − ˆµX (cid:107)H
(cid:124)
(cid:125)
(cid:123)(cid:122)
ﬁnite sample error

+

(cid:13)
(cid:13)ˆµφ,out
(cid:13)
(cid:124)

X − ˜µφ
(cid:123)(cid:122)
reduced set error

(cid:13)
(cid:13)
(cid:13)Hφ
(cid:125)

X

+

(cid:13)
(cid:13)˜µφ
(cid:13)
(cid:124)

X

X − ˆµφ
(cid:123)(cid:122)
privacy error

(cid:13)
(cid:13)
(cid:13)Hφ
(cid:125)

.

The ﬁnite sample error tends to 0 as N → ∞ in probability by consistency of the empirical kernel mean estimate. The
random features error goes to 0 as N → ∞ by Lemma 14, since J → ∞ as N → ∞ and φ(·)T φ(·) → k(·, ·) uniformly in
X as J → ∞. The privacy error goes to 0 as N → ∞ by the same argument as in the proof of Theorem 2, with F replaced
by J. So it remains to show that the reduced set error also goes to 0 as N → ∞, in probability.
First, note that the private empirical kernel mean embedding ˆµφ
n=1 φ(xn) is in the feasible set of the constrained
minimisation problem solved by the reduced set method, as the sum of absolute values of weights in this expansion is
X to the optimisation target ˜µφ
N | 1
X equals the privacy error, so it follows that the
reduced set error is upper bounded by the privacy error, and hence also goes to 0 as N → ∞:

N | = 1 ≤ 1. The RKHS Hφ distance of ˆµφ

X = 1
N

(cid:80)N

(cid:13)
(cid:13)ˆµφ,out
(cid:13)
(cid:124)

X − ˜µφ
(cid:123)(cid:122)
reduced set error

(cid:13)
(cid:13)
(cid:13)Hφ
(cid:125)

X

≤

(cid:13)
(cid:13)˜µφ
(cid:13)
(cid:124)

X

X − ˆµφ
(cid:123)(cid:122)
privacy error

(cid:13)
(cid:13)
(cid:13)Hφ
(cid:125)

P
→ 0 as N → ∞,

as required to complete the proof.

Corollary 15. Let f be any continuous function. Then whenever k is a c0-universal kernel, applying f to the points output
by Algorithm 2 yields a consistent estimator of the kernel mean embedding µf (X) of f (X).

Proof. Noting that the sum of absolute values of weights wm output by Algorithm 2 is at most C by construction, in light of
Theorem 7 we see that Theorem 1 of (Simon-Gabriel et al., 2016) applies and gives the desired conclusion.

A.5. Algorithm 2 (Random Features RKHS Algorithm): Convergence Rate

Proposition 7 Suppose that φ is a random feature scheme for the kernel k that converges uniformly on any compact set at
a rate Op(J −1/2) with the number J of random features. Then J(N ) can be chosen such that if the employed Reduced set
method ﬁnds a global optimum of (5), Algorithm 2 outputs an element that converges to the true kernel mean embedding
µX at a rate Op(N −1/3).

(22)

(23)

(24)

Differentially Private Database Release via Kernel Mean Embeddings

Proof. Equation (23) shows that the error (cid:107)µX − ˆµout
X and the true kernel mean
embedding µX can be upper bounded by the sum of four terms: the ﬁnite sample error, the random features error, the
reduced set error, and the privacy error. Arguing as in the proof of Proposition 5, the ﬁnite sample error vanishes at a rate
Op(N −1/2). The proof of Theorem 7 shows that the reduced set error is upper bounded by the privacy error, which itself
vanishes at a rate of Op(
J/N ) by the argument given in the proof of Theorem 2, with F replaced by J. Lemma 14
implies that if the random features converge uniformly at a rate Op(J −1/2), then the random features error vanishes at a rate
Op(J −1/4). The total convergence rate is thus

X (cid:107)H between the released element ˆµout

√

(cid:32)

(cid:33)

Op

N −1/2 +

+ J −1/4

√

J
N

and we can check that this becomes Op(N −1/3) by setting J = (cid:98)N 4/3(cid:99).

A.6. Algorithm 2 (Random Features RKHS Algorithm): Differential Privacy

Proposition 9 Assume that the random feature vectors produced by φ are bounded by 1 in L2 norm ((cid:107)φ(x)(cid:107)2 ≤ 1 for all
x ∈ X ). Then Algorithm 2 is (ε, δ)-differentially private.

Proof. The output of the algorithm is produced by a Reduced set method that is initialised blindly to the database and
optimises RKHS distance to the element ˜µφ
X ∈ Hφ, while only having access to the distance to it, rather than any
representation of ˜µφ
X . As ˜µφ
X using the Gaussian mechanism with
∆2 = 2
N . To this end, assume D = {x1, . . . , xN }
and D(cid:48) = {x(cid:48)
N } are two neighbouring databases of cardinality N , differing w.l.o.g. in their last element only. Then

X can be seen as a vector in RJ obtained by perturbing ˆµφ

N , it sufﬁces to show that the L2-sensitivity of ˆµφ

X is upper bounded by 2

1, . . . , x(cid:48)

(cid:107)ˆµφ

D − ˆµφ

D(cid:48)(cid:107)2 =

φ(xn) −

1
N

N
(cid:88)

n=1

φ(x(cid:48)

(cid:13)
(cid:13)
(cid:13)
n)
(cid:13)
(cid:13)2

1
N

N
(cid:88)

n=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
1
N
1
N

=

≤

(cid:107)φ(xN ) − φ(x(cid:48)

(cid:107)φ(xN )(cid:107)2 +

N )(cid:107)2 ≤

2
N

,

N )(cid:107)2
1
N

(cid:107)φ(x(cid:48)

(25)

(26)

(27)

as required to complete the proof.

B. Setup of Empirical Illustrations

We considered two scenarios in our basic empirical evaluations shown in Sections 4 and 5:

1. No publishable subset: No rows of the private database are, or can be made public without some privacy-ensuring

modiﬁcation.

2. Publishable subset: A small part of the private database is already public, or can be made public, perhaps for one of the

several possible reasons outlined in Section 1.

2 , . . . , 1

To illustrate the impact of data dimensionality on the performance of the proposed algorithms, we provide results on datasets
with data dimension D = 2 and D = 5. In both cases we constructed a synthetic private dataset by sampling N = 100, 000
data points from a multivariate Gaussian mixture distribution. The mixture had 10 components, with mixing weights
proportional to 1, 1
10 , and the means of the components were chosen randomly themselves from a spherical Gaussian
distribution with mean [100, . . . , 100] and covariance 200ID. Each of the N private data points was simulated by ﬁrst
sampling its mixture component using the mixing weights as probabilities, and then the point itself was sampled from a
spherical Gaussian centered at the mean of the chosen mixture component and with covariance 30ID.
We chose to work with the widely popular exponentiated quadratic kernel k(x1, x2) = e−γ(cid:107)x1−x2(cid:107)2
2 for RD-valued data
(also known as a Gaussian kernel, or a squared exponential kernel), with the parameter setting γ = 10−4/D. This kernel
is known to be characteristic (Fukumizu et al., 2008), and so as discussed in Section 2.2, no information about the data
generating distribution pX is lost by working with its kernel mean embedding µX .

Differentially Private Database Release via Kernel Mean Embeddings

We used our proposed algorithms to release an approximate version of the empirical KME of the private database, in such a
way that the output satisﬁes the deﬁnition of (ε, δ)-differential privacy. We investigated the common privacy levels given by
ε ∈ {0.01, 0.1, 1.0}, and used the ﬁxed value of δ = 10−6, which satisﬁes the usual requirement that δ (cid:28) 1
N .

B.1. Evaluation Metric

The geometry of the RKHS H allows comparing the performance of different algorithms by computing the RKHS distance
∆ between the empirical KME ˆµX computed using all N private data points (and which could not have been released
without violating differential privacy) and the element of the RKHS represented by the actually released weighted set of
synthetic data points (z1, w1), . . . , (zM , wM ):

∆ :=

ˆµX −

wmk(zm, ·)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

M
(cid:88)

m=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)H

.

Moreover, as the empirical KME ˆµX is based on a large sample size of N = 100, 000 i.i.d. data points, it can be expected to
be a good proxy for the true KME µX of the data-generating random variable X. In that case ∆ is also a good proxy for the
RKHS distance between the true KME µX and the RKHS element represented by the released dataset.

B.2. Scenario 1: No Publishable Subset

Algorithm 1 requires specifying the synthetic data points z1, . . . , zM in advance, before seeing the private data. If no part
of the private data has already been published (which could then be used for the synthetic data points), one can construct
the synthetic data points by sampling them randomly from a suitable probability distribution q. For the consistency result
of Theorem 2 to apply, the support of q must include all possible private data points. In our case the private data takes
values in RD, and so this requirement is satisﬁed by any distribution on RD with full support. We used a spherical Gaussian
distribution q = N (0, σqID) with σq = 500 for sampling the synthetic data points.

The implementation of Algorithm 2 used J = 10, 000 random features for accurate approximation of the kernel, and an
iterative gradient-based optimisation procedure to solve the reduced set problem (Equation (5) in Algorithm 2).

Figure 2 shows how the RKHS distance ∆ changes with the number of synthetic data points M , for different requested
privacy level ε for Algorithm 1 (solid lines) and Algorithm 2 (dashed lines), on datasets with dimensionality D = 2 (left
subﬁgure) and D = 5 (right subﬁgure). We observe that the additional ability of Algorithm 2 to optimise the locations of the
synthetic data points (rather than just the weights, as is the case for Algorithm 1) is more helpful in the higher-dimensional
case D = 5, where the randomly sampled synthetic data points are less likely to land close to private data points.

B.3. Scenario 2: Publishable Subset

Here we explored the interesting scenario where one can exploit the fact that a small part of the private database is actually
public, and use the public rows as the ﬁxed synthetic data points in Algorithm 1. Speciﬁcally, we assume (without loss of
generality) that the ﬁrst M rows of the private database (where M (cid:28) N ) are public, and we take the synthetic data points to
be z1 ← x1, . . . , zM ← xM .
Observe that in this case ˆµbaseline := 1
m=1 k(zm, ·), i.e., uniform weighting of the synthetic data points, is already
M
expected to be a strong baseline since ˆµbaseline is itself a consistent estimator of µX , (although based on a much smaller
sample size M (cid:28) N ). The purpose of Algorithm 1 is to ﬁnd (generally non-uniform) w1, . . . , wM that reweight the public
data points using the information in the large private dataset, but respecting differential privacy. Figure 1 shows how the
RKHS distance ∆ changes with the number of public data points M , for different privacy levels ε.

(cid:80)M

For comparison, the ﬁgures also show the RKHS distances ∆ achieved by the baseline that simply weights the public points
uniformly. We can see that in both cases D = 2 and D = 5, if the ratio of public to private points is low enough, Algorithm 1
provides a substantial beneﬁt over this baseline (note the logarithmic scaling). Since usually obtaining permission to publish
a larger subset of the private data unchanged will come at an increased cost, the ability to instead reweight a smaller public
dataset using Algorithm 1 in a differentially private manner is useful.

