Use of Domain-Speciﬁc Language Resources in Machine Translation

Sanja ˇStajner, Andreia Querido, Nuno Rendeiro, Jo˜ao Rodrigues, and Ant´onio Branco
Department of Informatics, Faculty of Sciences
University of Lisbon, Portugal
{sanja.stajner, joao.rodrigues, andreia.querido, nuno.rendeiro, antonio.branco}@di.fc.ul.pt

Abstract
In this paper, we address the problem of Machine Translation (MT) for a specialised domain in a language pair for which only a very
small domain-speciﬁc parallel corpus is available. We conduct a series of experiments using a purely phrase-based SMT (PBSMT)
system and a hybrid MT system (TectoMT), testing three different strategies to overcome the problem of the small amount of in-domain
training data. Our results show that adding a small size in-domain bilingual terminology to the small in-domain training corpus leads to
the best improvements of a hybrid MT system, while the PBSMT system achieves the best results by adding a combination of in-domain
bilingual terminology and a larger out-of-domain corpus. We focus on qualitative human evaluation of the output of two best systems
(one for each approach) and perform a systematic in-depth error analysis which revealed advantages of the hybrid MT system over the
pure PBSMT system for this speciﬁc task.

Keywords: Qualitative human evaluation, domain-speciﬁc machine translation, hybrid machine translation, TectoMT

1.

Introduction

Phrase-based statistical machine translation (PBSMT) sys-
tems are considered the state of the art for language pairs
for which large amounts of parallel data for training are
available. For vast majority of language pairs (English-
Portuguese among them), however, the available corpora
are usually limited on one or two particular domains, e.g.
legal documents (JRC-Acquis corpus), or parliamentary
discussions (Europarl corpus). In those cases, for domain-
speciﬁc MT, it is believed that rule-based or hybrid MT
systems have higher potential to overcome the problems of
data sparsity.
In this paper, we focus on English to Portuguese MT for
Information Technology (IT) domain, motivated by the fol-
lowing real world usage scenario: an user asks a question
in Portuguese, the question is machine translated into En-
glish, the answer is searched for in an English database,
automatically translated back to Portuguese and presented
to the user (Figure 1).

Figure 1: The task.

All experiments have been performed within the QTLeap
project,1 which aims to investigate an articulated method-
ology for machine translation based on deep language engi-
neering approaches. As no freely available corpora for the
EN-PT language pair exists for the IT domain, a small EN-
PT corpus was compiled under the QTLeap project in order
to enable in-domain examples and guide the hand-crafted
rules for the synthesis phase of the hybrid MT system being

developed. This QTLeap corpus consists of recorded inter-
actions of real users with experts to obtain technical support
via chat, which were translated by professional translators
into the eight languages of the project.2
We perform a series of MT experiments using two sys-
tems: (1) the TectoMT ( ˇZabokrtsk´y et al., 2008) adapted
to English-Portuguese translation (Silva et al., 2015), as
a hybrid system with hybrid analysis, rule-based synthesis
and statistically based transfer, and (2) the standard PBSMT
system in Moses (Koehn et al., 2007). We vary the training
datasets exploring three different strategies to overcome the
problem of small amount of training data: (1) adding larger
out-of-domain dataset, (2) adding in-domain bilingual ter-
minology, (3) adding both.
The main contribution of this paper is the in-depth error
analysis, showing the error patterns in each of the systems
(TectoMT and PBSMT) when trained on the same datasets,
thus directly contrasting those two approaches and showing
the main advantages of the hybrid MT system. We further
propose a set of rules for improving the synthesis stage in
the TectoMT system to eliminate those errors in the future
versions of the system.
The next contribution lies in better understanding how dif-
ferent (ﬁne-grained) types of errors inﬂuence ﬂuency and
adequacy, which relies on the combination of human as-
sessment of ﬂuency and adequacy and detailed error anal-
ysis of each group of sentence pairs (depending on the ﬂu-
ency and adequacy scores).
Finally, our results conﬁrm the hypothesis that TectoMT
achieves best improvements with adding only bilingual ter-
minology to the small in-domain training dataset, while PB-
SMT achieves best improvements with adding a combina-
tion of a larger out-of-domain corpus and bilingual termi-
nology, regardless of the out-of-domain corpora used (Eu-
roparl or scientiﬁc news).

1www.qtleap.eu

2The corpus is freely available through METASHARE:

http://metashare.metanet4u.eu/.

592

2. Related Work

We divide the related work into two sections. The ﬁrst sec-
tion (Section 2.1.) gives a brief introduction to the hybrid
MT system used in our study (TectoMT) providing the nec-
essary background for a better understanding of the results
and discussion. The second section (Section 2.2.) sum-
marises previous studies on English to Portuguese machine
translation task.

2.1. TectoMT – A Hybrid MT System

TectoMT ( ˇZabokrtsk´y et al., 2008) is a modular hybrid MT
system which uses two levels of structural representation:
a shallow analytical layer (a-layer), and a deep tectogram-
matical layer (t-layer). It consists of three phases: analysis,
transfer, and synthesis.
The analysis phase consists of two steps. In the ﬁrst step,
standard dependency parsers are used to construct the a-
layer. In the second step, the dependency trees of the a-
layer (a-trees) are converted into the dependency trees of
the t-layer (t-trees) using a set of rule-based modules. The
a-layer is represented by a labeled dependency tree (a-tree)
which contains all tokens of the sentence as its nodes. Each
node contains several types of information: word form,
lemma, part-of-speech tag and morphological information,
and afun, a surface dependency label denoting syntactic
function (subject, object, predicate, etc.). The t-layer is
a deep syntactic/semantic layer represented by a depen-
dency tree (t-tree) which describes the linguistic meaning
of the sentence according to the FGD (Functional Gener-
ative Description) theory (Sgall et al., 1986). The nodes
of the t-tree contain only content words of the sentence
and added information (not contained in the sentence) as
pro-dropped subject personal pronouns. Each t-node has
four attributes: t-lemma (“deep lemma” which is in most
cases identical to surface lemma), functor (a semantic role
label based on the FGD theory), grammateme (contains in-
formation such as person, number, tense, modality, etc.),
and formeme (morpho-syntactic form information, such as
v:to+inf for inﬁnitive verbs or n:into+X for a prepo-
sitional phrase). Auxiliary words are not represented as
nodes in the t-tree but rather inﬂuence the attributes of the
t-nodes.
The transfer phase in TectoMT is performed on the t-layer
by translating t-lemmas and conversion of formemes and
grammatemes (Bojar and T´ynovsk´y, 2009; ˇZabokrtsk´y et
al., 2008) . This phase is mostly statistical, based on max-
imum entropy (MaxEnt) model (Mareˇcek et al., 2010), en-
hanced with translation dictionaries and a small number of
handcrafted rules for handling out-of-vocabulary words.
Finally, the synthesis phase consists of series of small,
mostly rule-based modules which have a goal of trans-
forming the translated t-tree into an a-tree and then lin-
earise the a-tree into a plain surface form of the output sen-
tence. These modules are language-speciﬁc and take care
of word order, agreement (e.g.
subject-predicate agree-
ment or noun-adjective agreement), insertion of grammat-
ical words (such as prepositions, articles, particles, etc.),
inﬂections, and capitalisation.

2.2. English to Portuguese Machine Translation
The studies concerning EN-PT MT are very scarce and
mostly report on results of the PBSMT systems. The best
results (BLEU = 0.55) were obtained on the JRC-Acquis
corpus (Koehn et al., 2009), followed by the results ob-
tained using a signiﬁcantly smaller FAPESP corpus (Aziz
and Specia, 2011) of scientiﬁc news texts (BLEU = 0.46).
The PBSMT systems trained on Europarl corpus (and inter-
polated with models trained on datasets from the same do-
main as the test datasets) and tested on domain-speciﬁc cor-
pora – TED talks and TAP (Portuguese airline) magazine
– achieved signiﬁcantly lower BLEU scores, 0.20 and 0.19
respectively (Costa et al., 2014). Google Translate achieved
better, but still not very high, BLEU scores (0.28 and 0.26,
respectively) on the same task (Costa et al., 2014).
There have been two studies comparing a hybrid and a PB-
SMT system for EN-PT language pair (Silva et al., 2015;
ˇStajner et al., 2015), reporting the performances of the two
approaches as comparable. None of those studies, however,
performs an error analysis to directly compare the errors
made by those systems.

3. Machine Translation Experiments
The corpora used in MT experiments, experimental setup
and the results of the automatic evaluation of all MT sys-
tems are presented in the next three subsections.

3.1. Corpora
We used six corpora in this study:

1. EP1 – Full Europarl corpus (Koehn, 2005) with En-
glish on the source side and Portuguese on the target
side (1,960,407 sentence pairs).

2. EP2 – A smaller portion of Europarl corpus which has
the same size as the FAPESP corpus (162,350 sen-
tence pairs).

3. FAPESP – A Portuguese-English bilingual collec-
tion of the online issue of the scientiﬁc news Brazil-
ian magazine “Revista Pesquisa FAPESP”3 (Aziz and
Specia, 2011).

4. IT1 – An in-domain IT corpus with 2,000 sentence
pairs (1,000 questions and 1,000 answers) compiled
under the QTLeap project (QTLeap corpus, batch 1).
This corpus was used as the training dataset (or a part
of the training dataset) in our translation experiments.

5. IT2 – Another in-domain IT corpus, with 1,000
sentence pairs (answers only) compiled under the
QTLeap project (QTLeap corpus, batch 2), and com-
parable with the IT1 corpus. This corpus was used as
the test dataset in all our translation experiments.

6. TERM – A parallel corpus of IT terminology (uni-
grams or multiword expressions), which consists of
the Microsoft Terminology Collection4 (13,030 terms)

3http://revistapesquisa.fapesp.br/
4https://www.microsoft.com/Language/

en-US/Terminology.aspx

593

Corpora

Source (EN)

Target (PT)

EP

I am pleased that the Council and the Commission
have responded to this concern of Parliament.

Congratulo-me por ver que o Conselho e a
Comiss˜ao atenderam a esta preocupac¸ ˜ao do Par-
lamento.

Do you make use of these procedures at Alellyx?

Na Alellyx utilizam-se esses procedimentos?

FAPESP

At this stage Simpson had already began to get
involved in the project.

Nessa ´epoca, o Simpson j´a estava comec¸ando a se
envolver no projeto.

IT1

IT2

Remove the wireless network and try reconnect-
ing again using valid credentials.

Remova a rede sem ﬁos e ligue novamente com
dados v´alidos.

How can I delete Skype’s conversation history?

Como posso apagar o hist´orico de conversas do
Skype?

In the Insert menu, select Table.

No menu inserir selecione Tabela.

Select the cells you want to format, then click
the right mouse button on one that is selected and
choose Format Cells.

Selecione as c´elulas que pretende formatar, depois
clique com o bot˜ao direito do rato numa que esteja
selecionada e escolha Formatar C´elulas.

shift key

TERM

ﬁle system

tecla shift

sistema de ﬁcheiros

command line options

opc¸ ˜oes da linha de comandos

Table 1: Examples from the corpora

Experiment

EP1
EP2
FAPESP
IT1
IT1+EP2
IT1+FAPESP
IT1+TERM
IT1+EP2+TERM
IT1+FAPESP+TERM

Training dataset

BLEU score

EP1/EP2
1,960,407
162,350
/
/
162,350
/
/
162,350
/

FAPESP
/
/
162,350
/
/
162,350
/
/
162,350

IT1
/
/
/
2,000
2,000
2,000
2,000
2,000
2,000

TERM
/
/
/
/
/
/
14,025
14,025
178,375

Total
1,960,407
162,350
162, 350
2,000
164,350
164,350
16,025
178,375
14,025

TectoMT
19.34
17.76
19.43
20.77
19.77
20.53
*21.89
*21.04
*21.63

PBSMT
18.99
17.53
19.20
21.55
20.79
*22.64
*22.73
*22.25
*23.53

Table 2: Number of sentence pairs (terms and MWE in the case of the TERM corpus) used for the training and the achieved
BLEU score. Best results of each system are shown in bold. Results of the systems which signiﬁcantly (using paired
bootstrap resampling (Koehn, 2004)) outperformed all four baselines are shown with an ‘*’.

and a small portion of LibreOfﬁce terminology (995
terms).5

Several examples from each corpus are given in Table 1.

3.2. Experimental Setup
We performed a series of MT experiments for English to
Portuguese translation using two different approaches: a
hybrid MT system (TectoMT) and a PBSMT system in the
Moses toolkit. All models were tested on the same dataset
(IT2).
For the TectoMT system, we used the English to Portuguese
TectoMT system (Silva et al., 2015) developed under the
QTLeap project.
For the PBSMT system, we used the GIZA++ implemen-
tation of IBM word alignment model 4 (Och and Ney,

5We would like to thank Eleftherios Avramidis and Lukas

Poustka for making the LibreOfﬁce corpus available to us.

2003), and the reﬁnement and phrase-extraction heuristics
described further by Koehn et al. (2003). All PBSMT sys-
tems were tuned on the IT1 corpus using minimum error
rate training (MERT) (Och, 2003). Their language models
were built on a 2,121,382 sentence corpus (target side of
the full EP+FAPESP corpora) using the KenLM (Heaﬁeld,
2011) 5-gram language model. The stack size was limited
to 100 hypotheses during decoding.

For each of the two systems (TectoMT and PBSMT),
we performed four baseline experiments (using the EP1,
EP2, FAPESP, or IT1 corpus as the training dataset) and
ﬁve experiments which exploited three different strategies
for enlarging the small in-domain training dataset (IT1)
by adding: (1) a larger out-of-domain dataset (IT1+EP2
or IT1+FAPESP), (2) quasi in-domain data (IT1+TERM),
and (3) a combination of both (IT1+EP2+TERM or
IT1+FAPESP+TERM).

594

Group

Fluency Adequacy

TectoMT better rated than PBSMT

TectoMT and PBSMT rated the same

PBSMT better rated than TectoMT

Description
Both good (TectoMT = 4, PBSMT = 3)
TectoMT good (3 or 4), PBSMT bad (1 or 2)
Both bad (TectoMT = 2, PBSMT = 1)
Both good (both = 3 or both = 4)
Both bad (both = 2 or both = 1)
Both good (TectoMT = 3, PBSMT = 4)
TectoMT bad (1 or 2), PBSMT good (3 or 4)
Both bad (TectoMT = 1, PBSMT = 2)

1a
1b
1c
2a
2b
3a
3b
3c

0
10
17
4
55
0
8
6

0
20
10
11
40
3
12
4

Table 3: Number of sentence pairs analysed in each group.

Code
SENS

Error
Incorrect sense

WRTR Wrong translation
UNTR
Left untranslated
ADDW Added words

MISW Missing words
Capitalisation
CAP
Missing commas
COM
Missing quotation marks
QUO
Missing relative pronoun
REL
DEF
Missing deﬁnite articles
WRA Wrong article
VMD Wrong verb mood
WVM Wrong verb morphology
INP
MIP
WRP
GCA
GCP
NUC
WWO Wrong word order

Inserted preposition
Missing preposition
Wrong preposition
Gender concordance (article)
Gender concordance (pronoun)
Number concordance

Example
“phones” (with the meaning “headphones”) translated as “telem´oveis”
(mobile phones) instead of correct “auscultadores”
“Unidade de Google” instead of “Google Drive”
“format”, “connect”...
“Sign into the YouTube account.” translated as “Num ISP na conta no
youtube.”
“double-click” translated as “clique” (click)
that says, “Starred” → que diz estrela
that says, “Starred” → que diz estrela
that says, “Starred” → que diz estrela
“escolha a l´ıngua quer” instead of “escolha a l´ıngua que quer”
“em seu teclado” instead of “em o seu teclado”
“a pesquisa” instead of “uma pesquisa”
“seleciona voltar a” instead of “selecione voltar a”
wrong tense, person or number
“Alt key” → “tecla de alt”
“carregar bot˜ao” instead of “carregar no bot˜ao”
“ir em de codiﬁcac¸ ˜ao” instead of “ir a codiﬁcac¸ ˜ao”
“escolha a canal” instead of “escolha o canal”
“junto de sua perﬁl” instead of “junto ao seu perﬁl”
“bot˜oes que diz” instead of “dizem”
Open Network Broadcast → “Difus˜ao de rede de abrir”, instead of
“Abrir Difus˜ao de Rede”

Table 4: Classiﬁcation of adequacy and ﬂuency errors.

3.3. Results of the Translation Experiments
The training datasets of each of the nine experiments (per-
formed for both MT systems) are presented in Table 2, to-
gether with the results of the automatic evaluation of both
systems (TectoMT and PBSMT) in terms of the BLEU
score (Papineni et al., 2002).
Our results indicated that addition of a larger out-of-domain
corpus only improves the performance of the PBSMT sys-
tem, while it deteriorates the performance of the TectoMT
system. The TectoMT achieves best improvements with ad-
dition of the bilingual terminology only.

4. Hybrid vs Statistical MT System
It is known that BLEU scores cannot be used for compar-
ing two MT systems with different architectures (TectoMT
and PBSMT in our case), but only for comparing differ-
ent versions of the same system (either PBSMT or Tec-
toMT in our case). Therefore, we focused on the results of
the IT1+TERM experiments – which led to the best BLEU

score for the TectoMT system, and the second best BLEU
score for the PBSMT system (Table 2) – and performed hu-
man evaluation and in-depth error analysis in order to com-
pare the performances of the TectoMT and PBSMT systems
on the same datasets.

4.1. Human Evaluation

We randomly selected 100 original sentences from the test
set and asked two linguists, native speakers of Portuguese,
to rate their corresponding outputs produced by the Tec-
toMT and PBSMT systems trained on IT1+TERM dataset
(a total of 200 output sentences) in terms of their Fluency
and Adequacy on a 1–4 scale (where 1 denotes very bad,
and 4 very good output). The output sentences of the Tec-
toMT and PBSMT systems were presented to the annota-
tors in random order. The annotators favoured the output
of the TectoMT system (Fluency = 1.78, Adequacy = 2.28)
over the output of the PBSMT system (Fluency = 1.74, Ad-

595

Error

1b

2b
Tecto PBSMT Tecto PBSMT Tecto PBSMT Tecto PBSMT Tecto PBSMT Tecto PBSMT Tecto PBSMT

3b

1c

2a

3a

3c

1
SENS
5
WRTR
UNTR
2
ADDW 0
MISW 4

4
7
16
1
3

2
3
6
0
0

1
4
6
4
2

1
2
2
0
1

1
3
5
4
2

8
14
33
0
1

0
1
1
0
0

0
1
1
0
0

0
3
5
0
0

0
2
9
1
2

0
2
2
0
0

0
1
4
1
1

Table 5: Distribution of adequacy errors.

1b

1c

2a

2b

3b

3c

Tecto PBSMT Tecto PBSMT Tecto PBSMT Tecto PBSMT Tecto PBSMT Tecto PNSMT

Error

9
CAP
7
COM
2
QUO
0
REL
3
DEF
0
WRA
VMD
2
WVM 4
3
INP
3
MIP
0
WRP
1
GCA
0
GCP
0
NUC
0
WWO

3
2
0
1
1
2
8
0
9
3
3
3
0
1
9

14
11
1
2
9
0
4
3
4
7
4
0
0
4
6

9
1
1
3
0
1
10
1
8
4
1
4
1
3
20

6
1
0
0
2
0
0
2
1
2
0
0
0
0
0

2
0
0
0
0
1
2
1
1
0
0
1
0
0
0

27
10
0
6
26
5
13
1
21
35
8
21
8
8
45

5
3
0
0
0
0
0
1
1
5
1
0
0
0
6

1
2
0
0
0
1
1
0
3
0
0
0
1
0
0

5
0
0
1
1
0
1
0
2
3
0
1
0
1
5

5
0
0
0
0
0
2
0
4
0
2
0
0
0
4

4
20
44
10
8

50
32
0
5
23
0
40
5
26
27
3
6
0
14
39

Table 6: Distribution of ﬂuency errors.

equacy = 2.24).6
In order to gain more insights into problems of each ap-
proach and assess the possibility to overcome them in the
future, we divided those 100 sentence pairs in eight groups
(Table 3) according to the scores obtained by the annota-
tors. The sentences which were not classiﬁed in the same
group by both annotators were additionally annotated by a
third annotator (again a linguist and native speaker of Por-
tuguese). The sentences were ﬁnally assigned to the group
chosen by the majority of annotators.

4.2. Error Analysis
We ﬁrst analysed the sentences in each group in more de-
tails searching for the repetitive error patterns and made a
classiﬁcation of most frequent adequacy and ﬂuency errors
(Table 4). Next, we quantiﬁed each error type, for ﬂuency
and for adequacy separately (Tables 5 and 6).

4.2.1. Adequacy Errors
In terms of adequacy, it seems that the main difference in
the performance of the TectoMT system and the PBSMT
system lies in the number of untranslated words – UNTR
(Table 5). In the cases where the output of both systems
was rated as equally good (group 2a), the PBSMT sys-
tem was found to have a slightly higher number of un-
translated words (UNTR) and additional words (ADDW).

6The difference in adequacy scores was signiﬁcant at a 0.05

level.

In the cases where the output of both systems was rated
as equally bad (group 2b), the output of the PBSMT sys-
tem had a signiﬁcantly higher number of wrongly translated
words (WRTR), untranslated words (UNTR), added words
(ADDW), and missing words (MISW), while the output of
the TectoMT system had two times higher number of word
sense errors (SENS).

4.2.2. Fluency Errors
Overall, it seems that the hybrid system more often fails in
punctual cases like capitalisation (CAP), missing punctua-
tion (COM, QUO), while the PBSMT system leads to more
reordering errors (WWO) by inverting the verb+object or-
der. In those cases where the output of both systems was
rated as bad, but the output of the hybrid system was rated
as slightly less bad (group 1c), it seems that human evalu-
ators put more weight on the errors in word order (WWO)
and wrong verb mood (WVM) made by the PBSMT system
than on the capitalisation errors (CAP), punctuation errors
(COM), and errors in prepositions (MIP and WRP) made
by the hybrid system.

5. Discussion

As this error analysis was performed with the goal of dis-
covering the shortcomings of the current version of the hy-
brid system in order to improve the system in its next ver-
sion, we further focused on the most frequent ﬂuency errors
made by the TectoMT system (capitalisation, wrong verb

596

Figure 2: The target t-tree with a wrong word order (the node correcto should be placed after the node bot˜ao).

mood, and wrong word order) in order to search for their
origin (whether they are the result of mistakes made during
the analysis, transfer, or synthesis phase).

target tree with a missing #perspron (personal and posses-
sive pronouns) node.

(4) Source: In the Google Drive site go to the tab Re-

5.1. Capitalisation errors (CAP)
By inspecting the a-trees and t-trees of the sentences con-
taining capitalisation errors, e.g. Examples (1) – (3), we
noticed that this type of errors originates from the transfer
phase. In the current version of the TectoMT system, the
capitalisation is maintained only for the tokens at the be-
ginning of a sentence.

(1) Source: You have to go to Format > Uppercase.

(2) Translation: Dever´a ir a formato > Uppercase.

(3) Reference: Dever´a ir a Formatar > Mai´usculas.

Our examination revealed that the correctly capitalised tar-
get words (within the sentence) appear only in the cases
of the wrong transfer of the original source lemmas (when
the transfer is done by simply cloning the source lemma).
This error is fairly easy to avoid. A possible solution would
be to implement a block which forces all the nodes of the
source tree with a capitalised letter to be capitalised in the
corresponding node in the target tree.

5.2. Wrong verb mood (VMD)
This type of errors, e.g. Examples (4) – (6), appear due to
mistakes in the analysis and transfer phases which lead to a

(5) Translation: No site de conduc¸ ˜ao de Google vai ao

(6) Reference: No site do Google drive v´a at´e ao sepa-

cent.

separador recente.

rador Recente.

This prevents the identiﬁcation of the grammatical values
of the subject and the correct agreement between subject
and verb.

5.3. Wrong word order (WWO)
In most cases, the wrong word order in the output of the
TectoMT system, e.g. Examples (7) – (9), originates from
the wrong analysis phase which leads to an incorrect part-
of-speech tagging or from the missing block (currently be-
ing implemented) for handling the :postnom formeme.

(7) Source: Click the right mouse button.

(8) Translation: Clique no correcto bot˜ao de rato.

(9) Reference: Clique no bot˜ao direito do rato.

the node correcto with the formeme
In this case,
:postnom should be reordered and placed after de bot˜ao
node (Figure 2). Note that in this example the word cor-
recto is also badly translated (the lemma correct should
have been translated into direito).

597

Koehn, P., Birch, A., and Steinberger, R. (2009). 462 Ma-
chine Translation Systems for Europe. In Proceedings of
the MT Summit XII, pages 65–72.

Koehn, P. (2004). Statistical Signiﬁcance Tests for Ma-
In Proceedings of the
chine Translation Evaluation.
Empirical Methods in Natural Language Processing
(EMNLP), pages 388–395.

Koehn, P. (2005). Europarl: A Parallel Corpus for Statis-
tical Machine Translation. In Proceedings of the Tenth
Machine Translation Summit, pages 79–86.

Mareˇcek, D., Popel, M., and ˇZabokrtsk´y, Z. (2010). Max-
imum entropy translation model in dependency-based
MT framework. In Proceedings of the Joint 5th Work-
shop on Statistical Machine Translation and Metrics-
MATR, pages 201–206.

Och, F. J. and Ney, H. (2003). A systematic comparison
of various statistical alignment models. Computational
Linguistics, 29(1):19–51.

Och, F. (2003). Minimum Error Rate Training in Statisti-
cal Machine Translation. In Proceedings of the 41st An-
nual Meeting of the Association for Computational Lin-
guistics (ACL), pages 160–167. Association for Compu-
tational Linguistics.

Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J. (2002).
BLEU: a Method for Automatic Evaluation of Machine
Translation. In Proceedings of the 40th Annual Meeting
of the Association for Computational Linguistics (ACL),
pages 311–318.

Sgall, P., Hajicov´a, E., and Panevov´a, J. (1986). The Mean-
ing of the Sentence in Its Semantic and Pragmatic As-
pects. Springer Science & Business Media.

Silva, J., Rodrigues, J., Gomes, L., and Branco, A. (2015).
Bootstrapping a hybrid deep MT system. In Proceedings
of the Fourth Workshop on Hybrid Approaches to Trans-
lation (HyTra), pages 1–5. ACL.

ˇStajner, S., Rodrigues, J., Gomes, L., and Branco, A.
(2015). Machine Translation for Multilingual Trou-
bleshooting in the IT Domain: A Comparison of Dif-
ferent Strategies. In Proceedings of the Deep Machine
Translation Workshop (DMTW), pages 106–115.

ˇZabokrtsk´y, Z., Pt´aˇcek, J., and Pajas, P. (2008). TectoMT:
Highly modular MT system with tectogrammatics used
as transfer layer. In Proceedings of the Third Workshop
on Statistical Machine Translation, pages 167–170.

6. Conclusions
We addressed the problem of domain-speciﬁc MT for a lan-
guage pair for which only very small amount of training
data is available. The results of our experiments showed
that, in such case, performance of a hybrid MT system sig-
niﬁcantly improves with addition of a small amount of in-
domain bilingual terminology (approx. 14,000 entries) to
the very small in-domain training corpus (2,000 sentence
pairs). They also indicated that addition of a larger out-of-
domain corpus only improves the performance of the PB-
SMT system and not the hybrid MT system.
The extensive in-depth error analysis of the output of the
hybrid and PBSMT systems trained on the same dataset
(small in-domain corpus with added bilingual terminol-
ogy), directly compared and analysed sentence by sentence,
reported the output of the hybrid system as better than the
output of the PBSMT system. The hybrid system mostly
failed in capitalisation and retaining punctuation marks,
while the PBSMT system had a greater number of reorder-
ing errors, untranslated tokens and missing words.

Acknowledgements
This work has received support by the EC’s FP7 (FP7/2007-
2013) under grant agreement number 610516: “QTLeap:
Quality Translation by Deep Language Engineering Ap-
proaches”.

7. References
Aziz, W. and Specia, L. (2011). Fully Automatic Compi-
lation of a Portuguese-English Parallel Corpus for Sta-
tistical Machine Translation. In Proceedings of the 8th
Brazilian Symposium in Information and Human Lan-
guage Technology, Cuiab´a, MT, October.

Bojar, O. and T´ynovsk´y, M. (2009). Evaluation of Tree
Transfer System. Euromatrix project (statistical and
hybrid machine translation between all european lan-
guages), deliverable 3.4, Charles University in Prague.
Costa, A., Lu´ıs, T., and Coheur, L. (2014). Translation
Errors from English to Portuguese: an Annotated Cor-
pus. In Proceedings of the 9th International Conference
on Language Resources and Evaluation (LREC), pages
1231–1234.

Heaﬁeld, K.

(2011). KenLM: Faster and Smaller Lan-
guage Model Queries. In Proceedings of the EMNLP
2011 Sixth Workshop on Statistical Machine Translation,
pages 187–197, Edinburgh, Scotland, United Kingdom,
July.

Koehn, P., Och, F. J., and Marcu, D.

(2003). Statisti-
cal phrase-based translation. In Proceedings of the Con-
ference of the North American Chapter of the Associa-
tion for Computational Linguistics on Human Language
Technology - Volume 1, pages 48–54. Association for
Computational Linguistics.

Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Fed-
erico, M., Bertoldi, N., Cowan, B., Shen, W., Moran, C.,
Zens, R., Dyer, C., Bojar, O., Constantin, A., and Herbst,
E. (2007). Moses: Open source toolkit for statistical
machine translation. In Proceedings of the 45th Annual
Meeting of the Association for Computational Linguis-
tics (ACL). ACL.

598

