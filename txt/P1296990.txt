7
1
0
2
 
y
a
M
 
1
 
 
]

V
C
.
s
c
[
 
 
1
v
9
0
6
0
0
.
5
0
7
1
:
v
i
X
r
a

Mind the Class Weight Bias: Weighted Maximum Mean Discrepancy
for Unsupervised Domain Adaptation

Hongliang Yan1, Yukang Ding1, Peihua Li2, Qilong Wang2, Yong Xu3, Wangmeng Zuo1,∗
1School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China
2School of Information and Communication Engineering, Dalian University of Technology, Dalian, China
3Bio-Computing Research Center, Shenzhen Graduate School, Harbin Institute of Technology, Shenzhen, China
yanhl@hit.edu.cn, dingyukang921@163.com, peihuali@dlut.edu.cn,

qlwang@mail.dlut.edu.cn, laterfall@hitsz.edu.cn, wmzuo@hit.edu.cn

 

MNIST
USPS
SVHN

0.2

0.16

t
h
g
i
e
w

0.12

0.08

0.04

 

Abstract

In domain adaptation, maximum mean discrepancy
(MMD) has been widely adopted as a discrepancy met-
ric between the distributions of source and target domains.
However, existing MMD-based domain adaptation methods
generally ignore the changes of class prior distributions,
i.e., class weight bias across domains. This remains an
open problem but ubiquitous for domain adaptation, which
can be caused by changes in sample selection criteria and
application scenarios. We show that MMD cannot account
for class weight bias and results in degraded domain adap-
tation performance. To address this issue, a weighted MMD
model is proposed in this paper. Speciﬁcally, we introduce
class-speciﬁc auxiliary weights into the original MMD for
exploiting the class prior probability on source and target
domains, whose challenge lies in the fact that the class label
in target domain is unavailable. To account for it, our pro-
posed weighted MMD model is deﬁned by introducing an
auxiliary weight for each class in the source domain, and
a classiﬁcation EM algorithm is suggested by alternating
between assigning the pseudo-labels, estimating auxiliary
weights and updating model parameters. Extensive exper-
iments demonstrate the superiority of our weighted MMD
over conventional MMD for domain adaptation.

1. Introduction

Deep convolutional neural networks (CNNs) have
achieved great success in various computer vision tasks
such as image classiﬁcation [21], object detection [12] and
semantic segmentation [24]. Besides the inspiring progress
in model and learning, the achievement of CNN is un-
doubtedly attributed to the availability of massive labeled

∗Corresponding author.

0

1

2

3

6

7

8

9

4

5

class

Figure 1. Class prior distributions of three domains for digit recog-
nition. As is shown, class bias exists across domains. It is natural
to see that the class weight of 0 and 1 are relatively high in postal
service (USPS), and the class weight of 1 and 2 are relatively high
in house numbers (SVHN).

datasets. For a CNN trained on large scale datasets [8],
while the lower layers of features are safely transferable, the
learned features gradually moves from general to speciﬁc
along the network [40]. When the source and target tasks
are signiﬁcantly diverse, the CNN pretrained on the source
task may not generalize well to the target task. Such sce-
nario leads to an emerging topic to transfer the CNN from
the source task to the target task with the enhanced and dis-
criminative representation [2]. In this work, we study a spe-
cial type of transfer learning task, i.e., domain adaptation
(DA) [30].

One of the most fruitful lines for DA is MMD-based
method [26, 29, 3, 41, 36]. Despite the great success
achieved, existing ones generally ignore the changes of
class prior distributions, dubbed by class weight bias.
It
is ubiquitous for domain adaptation and can be caused by
changes in sample selection criteria [19] and application
scenarios [28]. As shown in Fig. 1, the class prior dis-
tributions (i.e., class weights) vary with domains for digit
recognition. Moreover, a special case of class weight bias

Figure 2. Results of minimizing MMD and WMMD regularizer under class weight bias are illustrated in (a) and (b), respectively. Mini-
mizing MMD preserves the class weights in source domain and thus the target samples will be wrongly estimated, as indicated by yellow
samples. On the contrary, the proposed weighted MMD removes the effect of class bias by ﬁrst reweighting source data.

is the imbalanced cross-domain data problem [28] where
several classes in source domain do not appear in tar-
get domain, as shown in Fig. 2. The Closest Common
Space Learning (CCSL) method in [28] is suggested for
imbalanced and multiple cross-domain visual classiﬁca-
tion. However, CCSL just combines conventional MMD
with domain-dependent MMD without explicitly consider-
ing class weight bias.

For MMD-based methods, the ignorance of class weight
bias can deteriorate the domain adaptation performance. In
the case of class weight bias, the MMD can be minimized
by either learning domain-invariant representation or pre-
serving the class weights in source domain. As illustrated
in Fig. 2 (a), it is unreasonable for domain adaptation to re-
quire that the class weights in target domain should keep
the same as those in source domain. Our empirical exper-
iments also reveal the limitation of MMD in coping with
class weight bias (See Fig. 4).

In this paper, we propose a weighted MMD (WMMD)
method to address the issue of class weight bias. As for
DA, the challenge is that the class labels in target domain
are unknown. So we ﬁrst introduce class-speciﬁc auxil-
iary weights to reweight the source samples. In this way,
the reweighted source data are expected to share the same
class weights with target data. The auxiliary weights es-
timation and model parameters learning are jointly opti-
mized by minimizing the objective function of weighted
MMD. Different from MMD, the objective function based
on our weighted MMD involves additional weight parame-
ters, and we present a classiﬁcation EM (CEM) scheme to
estimate it. Inspired by the semi-supervised logistic regres-
sion in [1], we propose a weighted Domain Adapation Net-
work (WDAN) by both incorporating the weighted MMD

into CNN and taking into account the empirical loss on tar-
get samples. The CEM algorithm are developed for learning
WDAN in three steps, i.e., E-step, C-step, and M-step. In
the E-step and the C-step, we calculate the class posterior
probability, assign the pseudo-labels to the target samples,
and estimate the auxiliary weight.
In the M-step, model
parameters are updated by minimizing the objective loss.
Experimental results show our weighted MMD can learn
better domain-invariant representation for domain adapta-
tion. Moreover, the models based on weighted MMD also
outperforms the MMD-based counterparts. In summary, the
main contributions of this work are three-fold:

1. A weighted MMD model is proposed to alleviate the
effect of class weight bias in domain adaptation. By
taking class prior distributions into account, weighted
MMD can provide a better metric for domain discrep-
ancy.

2. Using unbiased estimate of multi-kernel MMD [15,
17], our proposed weighted MMD can be computed as
mean embedding matching with linear time complex-
ity and be incorporated into CNN for unsupervised do-
main adaptation. We further develop a CEM algorithm
for training the weighted MMD model.

3. Experiments demonstrate that weighted MMD outper-
forms MMD for domain adaptation. The superiority of
weighted MMD over MMD has been veriﬁed on vari-
ous CNN architectures and different datasets.

In the remainder of this paper, we begin with a brief
introduction to the preliminaries and related work in Sec-
tion 2.
In Section 3, by considering class weight bias,
we propose weighted MMD on the basis of conventional

MMD. After that, in Section 4, we apply weighted MMD
to unsupervised domain adaptation and present a model
named WDAN. Extensive experimental results are given
in Section 5 to verify the effectiveness of our proposed
weighted MMD model and detailed empirical analysis to
our proposed model is provided. Finally, we conclude this
work in Section 6.

2. Preliminaries and Related Work

In this section, we ﬁrst review MMD and its application
in domain adaptation, and then survey several other meth-
ods used to measure domain discrepancy.

2.1. MMD and Its Application in Domain Adapta 

tion

Domain adaptation aims at adapting the discriminative
model learned on source domain into target domain. De-
pending on the accessibility of class labels for target sam-
ples during training, research lines can be grouped into three
categories: supervised, semi-supervised, and unsupervised
domain adaptation.
In this paper, we focus on learning
transferable CNN features for unsupervised domain adap-
tation (UDA), where the labels of all target samples are un-
known during training. Compared with the other settings,
UDA is more ubiquitous in real-world applications.

Due to the unavailability of labels in the target domain,
one commonly used strategy of UDA is to learn domain in-
variant representation via minimizing the domain distribu-
tion discrepancy. Maximum Mean Discrepancy (MMD) is
an effective non-parametric metric for comparing the distri-
butions based on two sets of data [4]. Given two distribu-
tions s and t, by mapping the data to a reproducing kernel
Hilbert space (RKHS) using function φ(·), the MMD be-
tween s and t is deﬁned as,

2

MMD

(s, t) = sup

kφkH≤1 (cid:13)
(cid:13)

Exs∼s [φ(xs)] − Ext∼t (cid:2)φ(xt)(cid:3)(cid:13)
(cid:13)

2

H

,

(1)
where Exs∼s [·] denotes the expectation with regard to the
distribution s, and kφkH ≤ 1 deﬁnes a set of functions in the
unit ball of a RKHS H. Based on the statistical tests deﬁned
by MMD, we have MMD(s, t) = 0 iff s = t. Denote
by Ds = {xs
i=1 two sets of samples
drawn i.i.d. from the distributions s and t, respectively. An
empirical estimate of MMD can be given by [16],

i=1 and Dt = {xt

i }M

i}N

2
MMD

(Ds, Dt) =

1
M

M

X
i=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

φ(xs

i ) − 1
N

N

X
j=1

φ(xt
j)

,

(2)

2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

H

where φ(·) denotes the feature map associated with the ker-
nel map k(xs, xt) = hφ(xs), φ(xt)i. k(xs, xt) is usu-
ally deﬁned as the convex combination of L basis kernels

kl(xs, xt) [25],

L

Xl=1

k(xs, xt) =

βlkl(xs, xt), s.t.βl ≥ 0,

βl = 1.

(3)

L

Xl=1

Most existing domain adaptation methods [26, 29, 3, 41,
36] are based on the MMD deﬁned in Eqn. (2) and only
linear kernel is adopted for simplicity. Because the formu-
lation of MMD in Eqn. (2) is based on pairwise similar-
ity and is computed in quadratic time complexity, it is pro-
hibitively time-consuming and unsuitable for using mini-
batch stochastic gradient descent (SGD) in CNN-based do-
main adaptation methods. Gretton et al. [16] further sug-
gest an unbiased approximation to MMDl with linear com-
plexity. Without loss of generality, by assuming M = N ,
MMDl can then be computed as,

MMD2

l (s, t) =

hl(zi),

(4)

2
M

M/2

Xi=1

where hl is an operator deﬁned on a quad-tuple zi =
(xs

2i−1, xs

2i, xt

2j−1, xt

2j),

hl(zi) =k(xs

2i−1, xs

2i) + k(xt

− k(xs

2i−1, xt

2j ) − k(xs

2j−1, xt
2i, xt

2j )
2j−1).

(5)

The approximation in Eqn. (4) takes a summation form and
is suitable for gradient computation in a mini-batch man-
ner. Based on the work in [16], Long et al. [25] propose
deep adaptation networks and residual transfer networks for
UDA by introducing MMDl based adaptation layers into
deep CNNs. However, the existing MMD-based UDA ap-
proaches all assume that the source and target data have the
same class prior distributions, which does not always hold
in real-world applications, as illustrated in Fig. 1. Our em-
pirical experiments show that class weight bias can result in
performance degradation for MMD-based UDA.

2.2. Metrics for Domain Discrepancy

Besides MMD, there are several other metrics for mea-
suring domain discrepancy. Baktashmotlagh et al. [3] pro-
pose a distribution-matching embedding (DME) approach
for UDA, where both MMD and the Hellinger distance are
adopted to measure the discrepancy between the source
and target distributions.
Instead of embedding of distri-
butions, discriminative methods such as domain classiﬁca-
tion [11] and domain confusion [35] have also been intro-
duced to learn domain invariant representation. However,
class weight bias is also not yet considered in these meth-
ods.

Several sample reweighting or selection methods [13,
19] are similar to our weighted MMD in spirit, and have
been proposed to match the source and target distributions.

C

Xc=1
C

Xc=1

These methods aim to learn sample-speciﬁc weights or se-
lect appropriate source samples for target data. Different
from them, our proposed weighted MMD alleviates class
weight bias by assigning class-speciﬁc weights to source
data.

3. Weighted Maximum Mean Discrepancy

In this section, we will introduce the proposed weighted
MMD. Denote by ps(xs) and pt(xt) the probability density
functions of the source data xs and the target data xt, ys and
yt be the class labels of xs and xt, respectively. Actually,
both ps(xs) and pt(xt) can be further represented as the
mixtures of class conditional distributions,

pu(xu) =

pu(yu = c)pu(xu|yu = c)

=

wu

c pu(xu|yu = c), u ∈ {s, t},

(6)

c = ps(ys = c) and wt

where ws
c = pt(yt = c) denote the
class prior probability (i.e., class weights) of the source and
target samples, respectively, and C denotes the number of
classes.

c = wt

Note that, the difference between the class conditional
distributions ps(xs|ys = c) and pt(xt|yt = c) serves as
a proper metric of domain discrepancy. However, due to
the unavailability of class labels for target data in UDA, the
MMD between ps(xs) and pt(xt) is usually adopted as a
domain discrepancy metric. When ws
c (c = 1, 2, ...,
C), we argue that it is a suitable alternative. Unfortunately,
as shown in Fig. 1, the assumption ws
c generally does
not hold. For this case, MMD cannot cope with class weight
bias across domains. We propose to construct a reference
source distribution ps,α(xs) for comparing the discrepancy
between the source and target domains. Speciﬁcally, we
require that ps,α(xs) has the same class weights with the
target domain but owns the class conditional distributions
in source domain. Let αc = wt
c . In order to eliminate
c
the effect of class weight bias, we deﬁne ps,α(xs) as,

c = wt

ws

(cid:14)

C

ps,α(xs) =

αcws

c ps(xs|ys = c).

(7)

Xc=1
Denote by Ds = {(xs
i )}M
i , ys
i=1 the training set from source
domain and Dt = {xt
j}N
j=1 the test set from the target do-
main. Given the class weights of the target samples, the em-
pirical estimation of weighted MMD ps,α(xs) and pt(xt)
can be given by,

MMD

2
w(Ds, Dt) =

1
M
i=1 αys

i

M

X
i=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

P

αys
i

φ(xs

i ) − 1
N

N

X
j=1

φ(xt
j)

2

H

.

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(8)

Assuming M = N , the linear time complexity approxima-
tion of weighted MMD can then be computed as,

MMD2

l,w(Ds, Dt) =

hl,w(zi),

(9)

2
M

M/2

Xi=1

where hl,w(zi) is an operator deﬁned on a quad-tuple zi =
(xs

2i−1, xs

2i, xt

2j−1, xt

2j),

hl,w(zi) = αys
− αys

2i

2i−1 αys
2i−1 k(xs

k(xs
2i−1, xt

2i−1, xs

2i) + k(xt
k(xs

2i−1, xt
2i, xt

2i)
2j−1).

2j) − αys
2i

(10)

4. Weighted Domain Adaptation Network

By far, we have introduced our weighted MMD for mea-
suring domain discrepancy. But there are two remained is-
sues to be addressed. On one hand, the proposed weighted
MMD, similar to MMD, should be incorporated into some
classiﬁers for domain adaptation. On the other hand, the
class distribution on target domain is generally unknown
during training. In this section, we propose a weighted do-
main adaptation network (WDAN) model, which is in es-
sential an extension of the semi-supervised logistic regres-
sion [1] by adding the WMMD term and incorporating with
CNN. Meanwhile, we employ the CEM [6] framework and
show how we optimize the proposed WDAN without the
label information of the target samples.

First, based on the research in [40, 25], the features grad-
ually become task speciﬁc as the layers go toward the top
one, resulting in increasing dataset bias for the higher layers
of features. Therefore, to generalize CNN for domain adap-
tation, the weighted MMD-based regularizers are added to
the higher layers of CNN. Second, the relationship between
semi-supervised learning and domain adaptation has been
studied in [33]. To further exploit the unlabelled data on
target domain, we follow the semi-supervised CEM model
in [1], leading to the following WDAN model,

min
W,{ˆyj}N

j=1,α

ℓ(xs

i , ys

i ; W) + γ

ℓ(xt

j , ˆyt

j; W)

1
N

N

Xj=1

+ λ

MMDl,w(Dl

s, Dl

t),

(11)

1
M

M

Xi=1
l2

Xl=l1

where W denotes the model parameters to be learned, and
{ˆyj}N
j=1 represent the assigned labels of target samples. λ
and γ are two tradeoff parameters. Dl
t denote the
l-th layer features of the source and target domains, respec-
tively. ws
c is estimated based on the source data Dl
s, i.e.,
ws
c = Mc/M , where Mc is the number of samples of the
c-th class. The ﬁrst two terms of Eqn. (11) are the soft-max
loss items on the source and target samples, respectively.

s and Dl

And the third term is the weighted MMD regularizers for
the l1 ∼ l2-th layers deﬁned in Eqn. (8).

j}N

Next, we explain the optimization procedure of the pro-
posed WDAN model. Following the CEM algorithm in [6],
the WDAN model is optimized by alternating between:
(i) E-step: estimating the class posterior probability of
{xt
j=1, (ii) C-step: assigning pseudo-labels {ˆyj}N
j=1 and
estimating auxiliary weights α, (iii) M-step: updating the
model parameters W. Given the model parameters W,
for each xt
j , we ﬁrst estimate the class posterior probability
based on the output of softmax classiﬁer. The pseudo-label
to ˆyj is assigned to xt
j based on the maximum posterior
probability, and the auxiliary weights α are then estimated
based on pseudo-labels. Given {ˆyj}N
j=1 and α, the conven-
tional backpropagation algorithm is then deployed to update
W. In the following, we give more details on the E-step, C-
step, and M-step.

E-step: Fixed W, for each sample xt

j from target do-
main, the CNN output to the cth class is represented as
gc(xt
j ; W). Here we simply deﬁne the class posterior prob-
ability p(yt

j = c|xt

j) as,

p(yt

j = c|xt

j) = gc(xt

j; W).

C-step: With p(yt
j by,

to xt

j = c|xt

j), we assign pseudo-label ˆyj

ˆyj = arg max

p(yt

j = c|xt

j).

c

Let 1c(ˆyj) be an indicator function,

(12)

(13)

(14)

1c(ˆyj) =

1, if ˆyj = c
0, otherwise.

(cid:26)

1c(ˆyj)

The class weight ˆwt

c can be estimated by ˆwt

c =
N , where N is the number of target samples.
ws
c

j
P
Then the auxiliary weight can be updated with αc = ˆwt
c
.

.

(cid:14)

M-step: Fixed α, the subproblem on W can be formu-

lated as,

L(W) =

min
W

ℓ(xs

i , ys

i ; W) + γ

ℓ(xt

j, ˆyt

j; W)

1
N

N

Xj=1

+ λ

MMDl,w(Dl

s, Dl

t).

(15)

1
M

M

Xi=1
l2

Xl=l1

Since the gradients of the three terms in Eqn. (15) are com-
putable, W can be updated with mini-batch SGD. Let zi =
(xs
2i−1, xs
i= (zl
i,1 =
f s,l
2i−1, zl
2i−1, zl
2i ) be the l-th layer
feature representation of zi. Given zi, the gradient with re-
spect to the l-th layer parameter Wl can be written as,

2j ) be a quad-tuple and zl

2i, xt
i,2 = f s,l

2j−1, xt
2i , zl

i,4 = f t,l

i,3 = f t,l

∂L(W)
∂Wl =

1
2

2

∂ℓ(z

i,j, yi,j; W)
∂zl
i,j

∂zl
i,j
∂Wl

4

∂ℓ(z

+

γ
2

Xj=3

Xj=1
i,j , ˆyi,j; W)
∂zl
i,j

4

∂zl
i,j
∂Wl + λ

Xk=1

∂hl,w(zi)
∂zl

i,k

i,k

∂zl
∂Wl .
(16)

Taking k = 1 for example, ∂hl,w(zl
i)

can be computed as,

∂zl

i,1

∂hl,w(zi)
∂f s,l

2i−1

=αys

2i−1 αys

2i

2i−1, f s,l
∂k(f s,l
2i )
∂f s,l
∂k(f s,l
2i−1, f t,l
2i )
∂f s,l

2i−1

.

2i−1

− αys

2i−1

(17)

i,k

∂zl

can also be computed for other k

Similarly, ∂hl,w(zl
i)
values. Thus, the model parameters can be updated via
backpropagaton with a mini-batch of quad-tuple. More-
over, following [25, 17], the multiple kernel parameters β
can also be updated during training.

The algorithm described above actually is an extension
of classiﬁcation EM. The C-step in [6] only assigns pseudo-
label to each unlabeled sample, while in this work we fur-
ther estimate the auxiliary weights α with the pseudo-labels.
As shown in [6], such a optimization procedure can con-
verge to a stationary value. The experiment also empiri-
cally validate that our algorithm works well in estimating
the auxiliary weights α.

5. Experiments

In this section, we ﬁrst evaluate our proposed WDAN
on four widely used benchmarks in UDA, i.e., Ofﬁce-
10+Caltech-10 [14], Ofﬁce31 [31], ImageCLEF [5] and
Digit Recognition. Moreover, we also provide empirical
analysis to our proposed WDAN model from three as-
pects, i.e., hyper-parameter sensitivity, robustness to class
weight bias, and feature visualization.

Following the common setting in UDA, we implement
our WDAN model based on four widely used CNN archi-
tectures, i.e., LeNet [22], AlexNet [21], GoogLeNet [34]
and VGGnet-16 [32]. As suggested in [25], we train
our method based on pre-trained AlexNet, VGGNet-16,
or GoogLeNet on ImageNet, with the layers from conv1
to conv3 ﬁxed for AlexNet and inception layers from
inc1 to inc3 ﬁxed for GoogLeNet. The WDAN (LeNet)
In
is trained from the scratch (random initialization).
addition, the auxiliary weight is initialized with αc = 1
for each class. For l1 and l2, we follow the setting in [25].

Method
AlexNet [21]
LapCNN (AlexNet) [38]
DDC (AlexNet) [36]
DAN (AlexNet) [25]
WDAN (AlexNet)
WDAN⋆ (AlexNet)
GoogLeNet [34]
DDC (GoogLeNet) [36]
DAN (GoogLeNet) [25]
WDAN (GoogLeNet)
VGGnet-16 [32]
DAN (VGGnet-16) [25]
WDAN (VGGnet-16)

A→C
84.0±0.3
83.6±0.6
84.3±0.5
86.0±0.5
86.9±0.1
87.1±0.2
91.3±0.2
91.4±0.2
91.4±0.3
92.2±0.2
89.6±0.4
91.2±0.2
91.4±0.2

W→C
77.9±0.4
77.8±0.5
76.9±0.4
81.5±0.3
84.1±0.2
85.1±0.3
88.2±0.3
88.7±0.3
89.7±0.2
91.0±0.5
88.1±0.4
90.6±0.3
91.0±0.2

D→C
81.0±0.4
80.6±0.4
80.5±0.2
82.0±0.4
83.9±0.1
85.2±0.2
88.9±0.3
89.0±0.4
89.1±0.4
89.8±0.3
85.4±0.5
87.1±0.4
89.0±0.3

C→A
91.3±0.2
92.1±0.3
91.3±0.3
92.0±0.3
93.1±0.2
93.2±0.1
95.2±0.1
95.3±0.2
95.5±0.2
95.5±0.3
93.7±0.2
95.7±0.2
95.7±0.1

C→W
83.2±0.3
81.6±0.4
85.5±0.3
92.6±0.4
93.6±0.2
93.5±0.3
92.5±0.2
93.0±0.1
93.1±0.3
95.4±0.2
94.3±0.2
95.3±0.3
95.8±0.2

C→D
89.1±0.2
87.8±0.4
89.1±0.3
90.5±0.2
93.4±0.2
94.5±0.2
94.7±0.3
94.9±0.4
95.3±0.1
95.5±0.5
93.7±0.2
94.7±0.1
95.9±0.3

Avg.
84.0
83.9
84.6
87.3
89.2
89.8
91.8
92.1
92.3
93.2
90.8
92.4
93.1

Table 1. Results (in %) of different methods based on AlexNet, GoogleNet and VGGnet-16 on Ofﬁce-10+Caltech-10. Note that the results
of LapCNN, DDC and DAN are duplicated from [25]. ⋆ indicates that the ground truth class distributions in both source and target domain
are used as prior.

three fully connected layers for AlexNet,

Concretely, WMMD-based regularizers are added to the
the last
last
inception and fully connected layers for GoogleNet, and
the last fully connected layer for LeNet. All experiments
are implemented by using Caffe Toolbox [20], and run
on a PC equipped with a NVIDIA GTX 1080 GPU and
32G RAM. We set the batch size to 64 for all methods,
and optimize the learning rate for each model indepen-
dently. The tradeoff parameters λ and γ are optimized
in sets {0, 0.03, 0.07, 0.1, 0.4, 0.7, 1.4, 1.7, 2} and
{0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0}
The
by
source
at:
https://github.com/yhldhit/WMMD-Caffe.

respectively.
our WDAN is

cross-validation,

available

code

of

5.1. Comparison with State of the arts

For UDA, we employ the standard protocols as [25, 23,
27], where all the samples in source and target domain are
used for training. The averaged results over 10 trials on
target domain set are reported for comparison.

5.1.1 Ofﬁce-10+Caltech-10

Ofﬁce-10+Caltech-10 [14] is widely used for domain adap-
tation, which picks up 10 classes shared in Ofﬁce-31 [31]
and Caltech-256 [18].
It consists of four domains where
Amazon (A), Webcam (W) and DSLR (D) are from Ofﬁce-
31, and the another one is Caltech-256 (C). On this dataset,
we conduct experiments based on AlexNet, GoogLeNet and
VGGnet-16, and exploit the same setting as [25] for perfor-
mance comparison.

We compare our WDAN with several state-of-the-art
methods as listed in Table 1, including its MMD counter-

part DAN [25]. By AlexNet, GoogLeNet, and VGGnet-
16 we indicate to ﬁne-tune the pre-trained CNN models
for special tasks. LapCNN [38] can be seen as a variant
of CNN, which ﬁrst shows deep structure learning can be
improved by jointly learning an embedding with the unla-
beled data, and then exploits the embedding as a regularizer.
By embedding a single kernel MMD layer into CNN struc-
ture, DDC [36] develops a uniﬁed deep framework to jointly
learn semantically meaningful feature and perform adaption
cross domain.

Numerical results in Table 1 show that our weighted
DAN achieves the best performance, independently of the
employed CNN structure. Moreover, the WDAN is superior
to DAN by 1.9%, 0.9% and 0.7%, respectively. We con-
tribute this improvement to that our weighted MMD model
can alleviate the effect of class weight bias.
In addition,
the superiority over other state-of-the-art methods demon-
strate the effectiveness of the proposed WDAN. Finally, we
exploit the ground truth class distributions in both source
and target domains as prior of the proposed WDAN based
on AlexNet, which is indicated as WDAN⋆ (AlexNet) in
Table 1. Although WDAN⋆ can further improve the perfor-
mance of WDAN, the smaller gap between them than one
between weighted DAN and DAN validate the effectiveness
of our proposed learning and estimation method.

5.1.2 ImageCLEF

ImageCLEF [5] is developed for the ImageCLEF domain
adaptation task1. This dataset collects images from ﬁve
widely used image benchmarks, including Caltech256 [18],
ImageNet2012 [7] and
Bing, PASCAL VOC2012 [9],

1http://www.imageclef.org/2014/adaptation

Method

GoogLeNet
DDC [36]
DAN
WDAN

P→C

91.0±0.5
91.2±0.4
91.4±0.2
91.4±0.1

B→C

92.4±0.3
92.6±0.4
93.0±0.1
93.8±0.2

C→B

61.2±0.4
62.0±0.3
62.5±0.3
62.9±0.3

P→B

55.3±0.3
54.3±0.3
54.5±0.2
55.2±0.3

C→P

61.2±0.2
61.7±0.4
62.2±0.3
65.0±0.2

B→P

58.1±0.3
58.6±0.3
59.0±0.3
59.5±0.3

Avg.

69.9
70.1
70.4
71.3

Table 2. Results (in %) of different methods based on GoogLeNet
on ImageCLEF dataset.

Method

LeNet
SA [10]
DAN
WDAN

M→S
17.2±0.3
21.1±0.2
19.3±0.4
23.4±0.2

S→M
56.8±0.5
59.3±0.3
65.2±0.3
67.4±0.4

M→U
61.5±0.4
55.0±0.4
69.1±0.5
72.6±0.3

U→M
46.5±0.6
51.6±0.6
60.5±0.7
65.4±0.4

Avg

45.5
46.8
53.5
57.2

Table 3. Results (in %) of different methods based on LeNet on
Digit Classiﬁcation.

Method

A→W

D→W

W→D

A→D

D→A

W→A

Avg.

94.0±0.3
94.3±0.3
95.9±0.1

60.4±0.5
66.0±0.5
66.8±0.3

AlexNet
DAN
WDAN

66.7
70.0
72.1
Table 4. Results (in %) of different methods based on AlexNet on
Ofﬁce-31 dataset.

92.2±0.3
95.2±0.3
98.7±0.4

58.6±0.6
63.2±0.4
64.5±0.2

46.0±0.6
50.0±0.5
53.8±0.1

49.0±0.5
51.1±0.5
52.7±0.2

SUN [39]. This dataset is thought to be more difﬁcult, since
some domains contain low-quality images, making this
benchmark a good compliance to the Ofﬁce-10+Caltech-10,
where the domain is more similar. Different from the orig-
inal experimental setting, in this paper, we use a subset of
ImageCLEF, which contains three datasets, i.e., Caltech256
(C), Bing (B) and PASCAL VOC2012 (P). Meanwhile, we
exploit all images in each subset rather than follow the stan-
dard protocol to sample the same number of images for each
class. Such setting results in six domain adaptation tasks.

We compare WDAN with three related methods based
on GoogLeNet, i.e., GoogLeNet, DDC and DAN. We im-
plement them by using the codes released by authors2, and
try our best to optimize them. The results of the competing
methods are shown in Table 2, from which we can see that
our proposed weighted DAN obtains the best performance
in most of the cases, and achieves 1.4%, 1.2% and 0.9%
gains over GoogLeNet, DDC and DAN on average, respec-
tively. The above results show the proposed weighted MMD
is helpful to improve the performance of domain adaptation
task.

5.1.3 Digit Recognition

Furthermore, we conduct experiment on digit recognition,
which is usually adopted to domain adaptation. In this pa-
per, we only considering training images of three bench-
marks, i.e., MNIST (M), SVHN (S) and USPS (U) and con-
duct experiments on four tasks. As LeNet [22] is usually
used for digit recognition, we implement our WDAN and
the competing methods based on it. Among them, SA [10]
proposes a subspace alignment method for domain adap-
tation, which aims at learning a feature mapping to align

2https://github.com/longmingsheng/mmd-caffe

Figure 3. Performance (in %) of different methods w.r.t. λ.

source samples with target samples. For fair comparison,
we implement SA by using the features from the ﬁne-tuned
LeNet. The results reported in Table 3 clearly show that
our proposed WDAN achieves the best performance on all
tasks, and outperforms LeNet, SA and DAN by 11.7%,
10.4% and 3.7% on average, respectively. The signiﬁcant
improvements over competing methods show the proposed
weighted MMD model is effective and meaningful.

5.1.4 Ofﬁce-31

Finally, experiments are further conducted to assess WDAN
on datasets with more classes. We conduct experiments on
a dataset with 31 classes (i.e. Ofﬁce-31). There are three
domains, i.e., Amazon (A), Webcam (W) and DSLR (D),
In this part, we consider all the six UDA
in Ofﬁce-31.
tasks, and report the results using Alexnet. Table 4 shows
the results of AlexNet, DAN, and WDAN. It can be seen
that the proposed WMMD achieves better results than its
MMD counterpart, indicating that WMMD also works well
on dataset with more classes. To sum up, the promising
performance of our weighted MMD model can be veriﬁed
on various CNN architectures (i.e., AlexNet, GoogLeNet
and LeNet) and various datasets with different number of
classes.

5.2. Empirical Analysis

In this subsection, we perform empirical analysis of the
proposed WDAN from three aspects. Firstly, we evaluate
the effect of hyper-parameter λ on our proposed WDAN
model in Eqn. (11). Secondly, compared with its baselines,
i.e., Alexnet and DAN, we show our proposed WDAN is
robust to class weight bias. Finally, we make a visualization
of learned feature representations.

5.2.1 Effect of Parameter λ

The objective in Eqn. (11) of WDAN consists of three
i.e., conventional empirical losses on the source
terms,

and target domains, and MMD-based regularizer. Gener-
ally speaking, the empirical risk term keeps the learned
deep feature to be discriminative on source domain while
the MMD-based regularizer encourages domain invariant
feature representation. Both of this two aspects are of
essential importance for domain adaptation. The param-
eter λ in the objective Eqn. (11) makes a tradeoff be-
tween this two parts, and could greatly impact the per-
formance of domain adaptation. To have a closer look at
this parameter, we evaluate our proposed WDAN based on
AlexNet on the task W→C from Ofﬁce-10+Caltech-10 un-
der various λ. As suggested above, λ belongs to the set
{0.0, 0.03, 0.07, 0.1, 0.4, 0.7, 1, 1.4, 1.7, 2}. Meanwhile,
we also compared our WDAN model with DAN under var-
ious λ. AlexNet is reported as baseline and corresponds to
the case λ = 0. The results are illustrated in Fig. 3.

Obvious conclusions can be drawn from the results: (i)
our proposed WDAN consistently outperforms the DAN,
demonstrating that mining the class weight bias in MMD
is meaningful and beneﬁcial; (ii) WDAN and DAN achieve
the best results at λ = 0.4 and λ = 0.1, and outperforms the
baseline, i.e., AlexNet, when λ < 1.2 and λ < 1.0, respec-
tively, indicating that an appropriate balance is important
and necessary.

5.2.2 Impact of Class Weight Bias

To further clarify the impact of class weight bias on MMD-
based domain adaptation methods, we conduct experiments
on a variant of the task V→C from ImageCLEF based
on AlexNet. Speciﬁcally, we pick up two shared classes,
i.e., airplane and motorbike, in the source domain PASCAL
VOC2012 (V) and target domain Caltech256 (C), which
forms a two-class classiﬁcation problem.

Then we ﬁx the class weights as 0.5 for each class on
source domain and train different methods with gradually
changing the class distribution on target domain, which can
be interpreted as different level of the class weight bias
cross source and target domains. Fig. 4 show the results
of WDAN, DAN and AlexNet under different levels of the
class weighted bias. From it we can see that the class weight
bias has great inﬂuence on performance of MMD-based
domain adaptation methods. Moreover, the conventional
MMD-based methods (e.g., DAN) are limited in handling
the class weight bias, as its results signiﬁcantly degrade
with increasing class weighted bias. In addition, our pro-
posed WDAN is more robust to class weighted bias.

5.2.3 Feature Visualization

Following the work in [25], we visualize the features
learned by WDAN and DAN on target domain in the D→C
task from Ofﬁce-10+Caltech-10. For feature visualization,
we employ the t-SNE visualization method [37] whose

Figure 4. Performance (in %) of different methods w.r.t. class
weight bias.

Figure 5. The t-SNE visualization of learned features of different
methods.

source codes are provided3. The results of feature visualiza-
tion for DAN and weighted DAN are illustrated in Fig. 5 (a)
and Fig. 5 (b), respectively. As shown in the orange boxes of
Fig. 5, features learned by the proposed WDAN can reserve
more class discrepancy distance than ones learned by DAN.
The underlying reason lies in the fact that WDAN, by con-
sidering a weighted MMD regularizer, does not minimize
the class weight bias as DAN does, which also accounts for
that weighted DAN can outperform DAN on a variety of
unsupervised domain adaptation tasks.

6. Conclusion

In this paper, we focus on the uninvestigated issue of
class weight bias in UDA, which has adverse effect on
MMD-based domain adaptation methods. We ﬁrst propose
a novel weighted MMD to reduce the effect of class weight
bias by constructing a reference source distribution based
on target distribution. For UDA, we present a weighted
DAN (WDAN) based on the proposed weighted MMD, and
develop modiﬁed the CEM learning algorithm to jointly as-
sign pseudo-labels, estimate the auxiliary weights and learn
model parameters. Empirical results show that our proposed
WDAN outperforms its MMD counterpart, i.e., DAN, in
various domain adaptation tasks. In future, there remains
several issues to be investigated: (i) evaluation of weighted

3https://lvdmaaten.github.io/tsne/

MMD on non-CNN based UDA models, (ii) applications to
other tasks (e.g., image generation) based on measuring the
discrepancy between distributions.

7. Acknowledgment

This work is

supported in part by NSFC grant
(61671182, 61471082, and 61370163). The authors also
thank NVIDIA corporation for the donation of GTX 1080
GPU.

References

[1] M.-R. Amini and P. Gallinari. Semi-supervised logistic re-
gression. In Proceedings of the 15th European Conference
on Artiﬁcial Intelligence, pages 390–394. IOS Press, 2002.
2, 4

[2] H. Azizpour, A. Sharif Razavian, J. Sullivan, A. Maki, and
S. Carlsson. From generic to speciﬁc deep representations
for visual recognition. In Proceedings of the IEEE Confer-
ence on Computer Vision and Pattern Recognition, pages 36–
45, 2015. 1

[3] M. Baktashmotlagh, M. T. Harandi, and M. Salzmann.
Distribution-matching embedding for visual domain adapta-
tion. Journal of Machine Learning Research, 2016. 1, 3
[4] K. M. Borgwardt, A. Gretton, M. J. Rasch, H.-P. Kriegel,
B. Sch¨olkopf, and A. J. Smola. Integrating structured bio-
logical data by kernel maximum mean discrepancy. Bioin-
formatics, 22(14):e49–e57, 2006. 3

[5] B. Caputo and N. Patricia. Overview of the imageclef 2014
domain adaptation task. In ImageCLEF 2014: Overview and
analysis of the results, number EPFL-CONF-201812, 2014.
5, 6

[6] G. Celeux and G. Govaert. A classiﬁcation em algorithm
for clustering and two stochastic versions. Computational
statistics & Data analysis, 14(3):315–332, 1992. 4, 5

[7] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-
Imagenet: A large-scale hierarchical image database.
Fei.
In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, pages 248–255, 2009. 6

[8] J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang,
E. Tzeng, and T. Darrell. Decaf: A deep convolutional acti-
vation feature for generic visual recognition. In Proceedings
the International Conference on Machine Learning, pages
647–655, 2014. 1

[9] M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and
A. Zisserman. The pascal visual object classes (voc) chal-
lenge. International journal of computer vision, 88(2):303–
338, 2010. 6

[10] B. Fernando, A. Habrard, M. Sebban, and T. Tuytelaars. Un-
supervised visual domain adaptation using subspace align-
ment. In Proceedings of the IEEE International Conference
on Computer Vision, pages 2960–2967, 2013. 7

[11] Y. Ganin and V. Lempitsky. Unsupervised domain adaptation
by backpropagation. arXiv preprint arXiv:1409.7495, 2014.
3

[12] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich fea-
ture hierarchies for accurate object detection and semantic

In Proceedings of the IEEE Conference on
segmentation.
Computer Vision and Pattern Recognition, pages 580–587,
2014. 1

[13] B. Gong, K. Grauman, and F. Sha. Connecting the dots with
landmarks: Discriminatively learning domain-invariant fea-
In Proceedings
tures for unsupervised domain adaptation.
the International Conference on Machine Learning, pages
222–230, 2013. 3

[14] B. Gong, Y. Shi, F. Sha, and K. Grauman. Geodesic ﬂow
kernel for unsupervised domain adaptation. In Proceedings
of the IEEE Conference on Computer Vision and Pattern
Recognition, pages 2066–2073, 2012. 5, 6

[15] A. Gretton, K. M. Borgwardt, M. Rasch, B. Sch¨olkopf, and
A. J. Smola. A kernel method for the two-sample-problem.
In Advances in neural information processing systems, pages
513–520, 2006. 2

[16] A. Gretton, K. M. Borgwardt, M. J. Rasch, B. Sch¨olkopf, and
A. Smola. A kernel two-sample test. Journal of Machine
Learning Research, 2012. 3

[17] A. Gretton, D. Sejdinovic, H. Strathmann, S. Balakrishnan,
M. Pontil, K. Fukumizu, and B. K. Sriperumbudur. Optimal
kernel choice for large-scale two-sample tests. In Advances
in neural information processing systems, pages 1205–1213,
2012. 2, 5

[18] G. Grifﬁn, A. Holub, and P. Perona. Caltech-256 object cat-

egory dataset. 2007. 6

[19] J. Huang, A. Gretton, K. M. Borgwardt, B. Sch¨olkopf, and
A. J. Smola. Correcting sample selection bias by unlabeled
data. In Advances in neural information processing systems,
pages 601–608, 2006. 1, 3

[20] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Gir-
shick, S. Guadarrama, and T. Darrell. Caffe: Convolu-
tional architecture for fast feature embedding. arXiv preprint
arXiv:1408.5093, 2014. 6

[21] A. Krizhevsky, I. Sutskever, and G. E. Hinton.

Imagenet
classiﬁcation with deep convolutional neural networks.
In
Advances in neural information processing systems, pages
1097–1105, 2012. 1, 5, 6

[22] Y. Lecun, L. E. Bottou, Y. Bengio, and P. Haaner. Gradient-
based learning applied to document recognition. 1998. 5,
7

[23] Y. Li, K. Swersky, and R. Zemel. Generative moment match-
ing networks. In Proceedings the International Conference
on Machine Learning, pages 1718–1727, 2015. 6

[24] J. Long, E. Shelhamer, and T. Darrell. Fully convolutional
networks for semantic segmentation. In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 3431–3440, 2015. 1

[25] M. Long and J. Wang. Learning transferable features with
deep adaptation networks. CoRR, abs/1502.02791, 1:2,
2015. 3, 4, 5, 6, 8

[26] M. Long, J. Wang, G. Ding, J. Sun, and P. S. Yu. Transfer
In Pro-
feature learning with joint distribution adaptation.
ceedings of the IEEE International Conference on Computer
Vision, pages 2200–2207, 2013. 1, 3

[27] M. Long, J. Wang, and M. I. Jordan. Unsupervised domain
adaptation with residual transfer networks. arXiv preprint
arXiv:1602.04433, 2016. 6

[28] T. Ming Harry Hsu, W. Yu Chen, C.-A. Hou, Y.-H. Hu-
bert Tsai, Y.-R. Yeh, and Y.-C. Frank Wang. Unsupervised
domain adaptation with imbalanced cross-domain data.
In
Proceedings of the IEEE International Conference on Com-
puter Vision, pages 4121–4129, 2015. 1, 2

[29] S. J. Pan, I. W. Tsang, J. T. Kwok, and Q. Yang. Domain
adaptation via transfer component analysis. IEEE Transac-
tions on Neural Networks, 22(2):199–210, 2011. 1, 3
[30] S. J. Pan and Q. Yang. A survey on transfer learning.
IEEE Transactions on knowledge and data engineering,
22(10):1345–1359, 2010. 1

[31] K. Saenko, B. Kulis, M. Fritz, and T. Darrell. Adapting vi-
sual category models to new domains. In European confer-
ence on computer vision, pages 213–226. Springer, 2010. 5,
6

[32] K. Simonyan and A. Zisserman. Very deep convolutional
networks for large-scale image recognition. arXiv preprint
arXiv:1409.1556, 2014. 5, 6

[33] A. Søgaard. Semi-supervised learning and domain adapta-
tion in natural language processing. Synthesis Lectures on
Human Language Technologies, 6(2):1–103, 2013. 4
[34] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed,
D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich.
Going deeper with convolutions. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition,
pages 1–9, 2015. 5, 6

[35] E. Tzeng, J. Hoffman, T. Darrell, and K. Saenko. Simultane-
ous deep transfer across domains and tasks. In Proceedings
of the IEEE International Conference on Computer Vision,
pages 4068–4076, 2015. 3

[36] E. Tzeng, J. Hoffman, N. Zhang, K. Saenko, and T. Darrell.
Deep domain confusion: Maximizing for domain invariance.
arXiv preprint arXiv:1412.3474, 2014. 1, 3, 6, 7

[37] L. Van Der Maaten. Accelerating t-sne using tree-based al-
gorithms. Journal of machine learning research, 2014. 8
[38] J. Weston, F. Ratle, H. Mobahi, and R. Collobert. Deep learn-
In Neural Networks:

ing via semi-supervised embedding.
Tricks of the Trade, pages 639–655. Springer, 2012. 6
[39] J. Xiao, J. Hays, K. A. Ehinger, A. Oliva, and A. Torralba.
Sun database: Large-scale scene recognition from abbey to
zoo. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, pages 3485–3492, 2010. 7
[40] J. Yosinski, J. Clune, Y. Bengio, and H. Lipson. How trans-
ferable are features in deep neural networks? In Advances
in neural information processing systems, pages 3320–3328,
2014. 1, 4

[41] E. Zhong, W. Fan, J. Peng, K. Zhang, J. Ren, D. Turaga,
and O. Verscheure. Cross domain distribution adaptation via
kernel mapping. In Proceedings of the 15th ACM SIGKDD
international conference on Knowledge discovery and data
mining, pages 1027–1036, 2009. 1, 3

7
1
0
2
 
y
a
M
 
1
 
 
]

V
C
.
s
c
[
 
 
1
v
9
0
6
0
0
.
5
0
7
1
:
v
i
X
r
a

Mind the Class Weight Bias: Weighted Maximum Mean Discrepancy
for Unsupervised Domain Adaptation

Hongliang Yan1, Yukang Ding1, Peihua Li2, Qilong Wang2, Yong Xu3, Wangmeng Zuo1,∗
1School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China
2School of Information and Communication Engineering, Dalian University of Technology, Dalian, China
3Bio-Computing Research Center, Shenzhen Graduate School, Harbin Institute of Technology, Shenzhen, China
yanhl@hit.edu.cn, dingyukang921@163.com, peihuali@dlut.edu.cn,

qlwang@mail.dlut.edu.cn, laterfall@hitsz.edu.cn, wmzuo@hit.edu.cn

 

MNIST
USPS
SVHN

0.2

0.16

t
h
g
i
e
w

0.12

0.08

0.04

 

Abstract

In domain adaptation, maximum mean discrepancy
(MMD) has been widely adopted as a discrepancy met-
ric between the distributions of source and target domains.
However, existing MMD-based domain adaptation methods
generally ignore the changes of class prior distributions,
i.e., class weight bias across domains. This remains an
open problem but ubiquitous for domain adaptation, which
can be caused by changes in sample selection criteria and
application scenarios. We show that MMD cannot account
for class weight bias and results in degraded domain adap-
tation performance. To address this issue, a weighted MMD
model is proposed in this paper. Speciﬁcally, we introduce
class-speciﬁc auxiliary weights into the original MMD for
exploiting the class prior probability on source and target
domains, whose challenge lies in the fact that the class label
in target domain is unavailable. To account for it, our pro-
posed weighted MMD model is deﬁned by introducing an
auxiliary weight for each class in the source domain, and
a classiﬁcation EM algorithm is suggested by alternating
between assigning the pseudo-labels, estimating auxiliary
weights and updating model parameters. Extensive exper-
iments demonstrate the superiority of our weighted MMD
over conventional MMD for domain adaptation.

1. Introduction

Deep convolutional neural networks (CNNs) have
achieved great success in various computer vision tasks
such as image classiﬁcation [21], object detection [12] and
semantic segmentation [24]. Besides the inspiring progress
in model and learning, the achievement of CNN is un-
doubtedly attributed to the availability of massive labeled

∗Corresponding author.

0

1

2

3

6

7

8

9

4

5

class

Figure 1. Class prior distributions of three domains for digit recog-
nition. As is shown, class bias exists across domains. It is natural
to see that the class weight of 0 and 1 are relatively high in postal
service (USPS), and the class weight of 1 and 2 are relatively high
in house numbers (SVHN).

datasets. For a CNN trained on large scale datasets [8],
while the lower layers of features are safely transferable, the
learned features gradually moves from general to speciﬁc
along the network [40]. When the source and target tasks
are signiﬁcantly diverse, the CNN pretrained on the source
task may not generalize well to the target task. Such sce-
nario leads to an emerging topic to transfer the CNN from
the source task to the target task with the enhanced and dis-
criminative representation [2]. In this work, we study a spe-
cial type of transfer learning task, i.e., domain adaptation
(DA) [30].

One of the most fruitful lines for DA is MMD-based
method [26, 29, 3, 41, 36]. Despite the great success
achieved, existing ones generally ignore the changes of
class prior distributions, dubbed by class weight bias.
It
is ubiquitous for domain adaptation and can be caused by
changes in sample selection criteria [19] and application
scenarios [28]. As shown in Fig. 1, the class prior dis-
tributions (i.e., class weights) vary with domains for digit
recognition. Moreover, a special case of class weight bias

Figure 2. Results of minimizing MMD and WMMD regularizer under class weight bias are illustrated in (a) and (b), respectively. Mini-
mizing MMD preserves the class weights in source domain and thus the target samples will be wrongly estimated, as indicated by yellow
samples. On the contrary, the proposed weighted MMD removes the effect of class bias by ﬁrst reweighting source data.

is the imbalanced cross-domain data problem [28] where
several classes in source domain do not appear in tar-
get domain, as shown in Fig. 2. The Closest Common
Space Learning (CCSL) method in [28] is suggested for
imbalanced and multiple cross-domain visual classiﬁca-
tion. However, CCSL just combines conventional MMD
with domain-dependent MMD without explicitly consider-
ing class weight bias.

For MMD-based methods, the ignorance of class weight
bias can deteriorate the domain adaptation performance. In
the case of class weight bias, the MMD can be minimized
by either learning domain-invariant representation or pre-
serving the class weights in source domain. As illustrated
in Fig. 2 (a), it is unreasonable for domain adaptation to re-
quire that the class weights in target domain should keep
the same as those in source domain. Our empirical exper-
iments also reveal the limitation of MMD in coping with
class weight bias (See Fig. 4).

In this paper, we propose a weighted MMD (WMMD)
method to address the issue of class weight bias. As for
DA, the challenge is that the class labels in target domain
are unknown. So we ﬁrst introduce class-speciﬁc auxil-
iary weights to reweight the source samples. In this way,
the reweighted source data are expected to share the same
class weights with target data. The auxiliary weights es-
timation and model parameters learning are jointly opti-
mized by minimizing the objective function of weighted
MMD. Different from MMD, the objective function based
on our weighted MMD involves additional weight parame-
ters, and we present a classiﬁcation EM (CEM) scheme to
estimate it. Inspired by the semi-supervised logistic regres-
sion in [1], we propose a weighted Domain Adapation Net-
work (WDAN) by both incorporating the weighted MMD

into CNN and taking into account the empirical loss on tar-
get samples. The CEM algorithm are developed for learning
WDAN in three steps, i.e., E-step, C-step, and M-step. In
the E-step and the C-step, we calculate the class posterior
probability, assign the pseudo-labels to the target samples,
and estimate the auxiliary weight.
In the M-step, model
parameters are updated by minimizing the objective loss.
Experimental results show our weighted MMD can learn
better domain-invariant representation for domain adapta-
tion. Moreover, the models based on weighted MMD also
outperforms the MMD-based counterparts. In summary, the
main contributions of this work are three-fold:

1. A weighted MMD model is proposed to alleviate the
effect of class weight bias in domain adaptation. By
taking class prior distributions into account, weighted
MMD can provide a better metric for domain discrep-
ancy.

2. Using unbiased estimate of multi-kernel MMD [15,
17], our proposed weighted MMD can be computed as
mean embedding matching with linear time complex-
ity and be incorporated into CNN for unsupervised do-
main adaptation. We further develop a CEM algorithm
for training the weighted MMD model.

3. Experiments demonstrate that weighted MMD outper-
forms MMD for domain adaptation. The superiority of
weighted MMD over MMD has been veriﬁed on vari-
ous CNN architectures and different datasets.

In the remainder of this paper, we begin with a brief
introduction to the preliminaries and related work in Sec-
tion 2.
In Section 3, by considering class weight bias,
we propose weighted MMD on the basis of conventional

MMD. After that, in Section 4, we apply weighted MMD
to unsupervised domain adaptation and present a model
named WDAN. Extensive experimental results are given
in Section 5 to verify the effectiveness of our proposed
weighted MMD model and detailed empirical analysis to
our proposed model is provided. Finally, we conclude this
work in Section 6.

2. Preliminaries and Related Work

In this section, we ﬁrst review MMD and its application
in domain adaptation, and then survey several other meth-
ods used to measure domain discrepancy.

2.1. MMD and Its Application in Domain Adapta 

tion

Domain adaptation aims at adapting the discriminative
model learned on source domain into target domain. De-
pending on the accessibility of class labels for target sam-
ples during training, research lines can be grouped into three
categories: supervised, semi-supervised, and unsupervised
domain adaptation.
In this paper, we focus on learning
transferable CNN features for unsupervised domain adap-
tation (UDA), where the labels of all target samples are un-
known during training. Compared with the other settings,
UDA is more ubiquitous in real-world applications.

Due to the unavailability of labels in the target domain,
one commonly used strategy of UDA is to learn domain in-
variant representation via minimizing the domain distribu-
tion discrepancy. Maximum Mean Discrepancy (MMD) is
an effective non-parametric metric for comparing the distri-
butions based on two sets of data [4]. Given two distribu-
tions s and t, by mapping the data to a reproducing kernel
Hilbert space (RKHS) using function φ(·), the MMD be-
tween s and t is deﬁned as,

2

MMD

(s, t) = sup

kφkH≤1 (cid:13)
(cid:13)

Exs∼s [φ(xs)] − Ext∼t (cid:2)φ(xt)(cid:3)(cid:13)
(cid:13)

2

H

,

(1)
where Exs∼s [·] denotes the expectation with regard to the
distribution s, and kφkH ≤ 1 deﬁnes a set of functions in the
unit ball of a RKHS H. Based on the statistical tests deﬁned
by MMD, we have MMD(s, t) = 0 iff s = t. Denote
by Ds = {xs
i=1 two sets of samples
drawn i.i.d. from the distributions s and t, respectively. An
empirical estimate of MMD can be given by [16],

i=1 and Dt = {xt

i }M

i}N

2
MMD

(Ds, Dt) =

1
M

M

X
i=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

φ(xs

i ) − 1
N

N

X
j=1

φ(xt
j)

,

(2)

2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

H

where φ(·) denotes the feature map associated with the ker-
nel map k(xs, xt) = hφ(xs), φ(xt)i. k(xs, xt) is usu-
ally deﬁned as the convex combination of L basis kernels

kl(xs, xt) [25],

L

Xl=1

k(xs, xt) =

βlkl(xs, xt), s.t.βl ≥ 0,

βl = 1.

(3)

L

Xl=1

Most existing domain adaptation methods [26, 29, 3, 41,
36] are based on the MMD deﬁned in Eqn. (2) and only
linear kernel is adopted for simplicity. Because the formu-
lation of MMD in Eqn. (2) is based on pairwise similar-
ity and is computed in quadratic time complexity, it is pro-
hibitively time-consuming and unsuitable for using mini-
batch stochastic gradient descent (SGD) in CNN-based do-
main adaptation methods. Gretton et al. [16] further sug-
gest an unbiased approximation to MMDl with linear com-
plexity. Without loss of generality, by assuming M = N ,
MMDl can then be computed as,

MMD2

l (s, t) =

hl(zi),

(4)

2
M

M/2

Xi=1

where hl is an operator deﬁned on a quad-tuple zi =
(xs

2i−1, xs

2i, xt

2j−1, xt

2j),

hl(zi) =k(xs

2i−1, xs

2i) + k(xt

− k(xs

2i−1, xt

2j ) − k(xs

2j−1, xt
2i, xt

2j )
2j−1).

(5)

The approximation in Eqn. (4) takes a summation form and
is suitable for gradient computation in a mini-batch man-
ner. Based on the work in [16], Long et al. [25] propose
deep adaptation networks and residual transfer networks for
UDA by introducing MMDl based adaptation layers into
deep CNNs. However, the existing MMD-based UDA ap-
proaches all assume that the source and target data have the
same class prior distributions, which does not always hold
in real-world applications, as illustrated in Fig. 1. Our em-
pirical experiments show that class weight bias can result in
performance degradation for MMD-based UDA.

2.2. Metrics for Domain Discrepancy

Besides MMD, there are several other metrics for mea-
suring domain discrepancy. Baktashmotlagh et al. [3] pro-
pose a distribution-matching embedding (DME) approach
for UDA, where both MMD and the Hellinger distance are
adopted to measure the discrepancy between the source
and target distributions.
Instead of embedding of distri-
butions, discriminative methods such as domain classiﬁca-
tion [11] and domain confusion [35] have also been intro-
duced to learn domain invariant representation. However,
class weight bias is also not yet considered in these meth-
ods.

Several sample reweighting or selection methods [13,
19] are similar to our weighted MMD in spirit, and have
been proposed to match the source and target distributions.

C

Xc=1
C

Xc=1

These methods aim to learn sample-speciﬁc weights or se-
lect appropriate source samples for target data. Different
from them, our proposed weighted MMD alleviates class
weight bias by assigning class-speciﬁc weights to source
data.

3. Weighted Maximum Mean Discrepancy

In this section, we will introduce the proposed weighted
MMD. Denote by ps(xs) and pt(xt) the probability density
functions of the source data xs and the target data xt, ys and
yt be the class labels of xs and xt, respectively. Actually,
both ps(xs) and pt(xt) can be further represented as the
mixtures of class conditional distributions,

pu(xu) =

pu(yu = c)pu(xu|yu = c)

=

wu

c pu(xu|yu = c), u ∈ {s, t},

(6)

c = ps(ys = c) and wt

where ws
c = pt(yt = c) denote the
class prior probability (i.e., class weights) of the source and
target samples, respectively, and C denotes the number of
classes.

c = wt

Note that, the difference between the class conditional
distributions ps(xs|ys = c) and pt(xt|yt = c) serves as
a proper metric of domain discrepancy. However, due to
the unavailability of class labels for target data in UDA, the
MMD between ps(xs) and pt(xt) is usually adopted as a
domain discrepancy metric. When ws
c (c = 1, 2, ...,
C), we argue that it is a suitable alternative. Unfortunately,
as shown in Fig. 1, the assumption ws
c generally does
not hold. For this case, MMD cannot cope with class weight
bias across domains. We propose to construct a reference
source distribution ps,α(xs) for comparing the discrepancy
between the source and target domains. Speciﬁcally, we
require that ps,α(xs) has the same class weights with the
target domain but owns the class conditional distributions
in source domain. Let αc = wt
c . In order to eliminate
c
the effect of class weight bias, we deﬁne ps,α(xs) as,

c = wt

ws

(cid:14)

C

ps,α(xs) =

αcws

c ps(xs|ys = c).

(7)

Xc=1
Denote by Ds = {(xs
i )}M
i , ys
i=1 the training set from source
domain and Dt = {xt
j}N
j=1 the test set from the target do-
main. Given the class weights of the target samples, the em-
pirical estimation of weighted MMD ps,α(xs) and pt(xt)
can be given by,

MMD

2
w(Ds, Dt) =

1
M
i=1 αys

i

M

X
i=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

P

αys
i

φ(xs

i ) − 1
N

N

X
j=1

φ(xt
j)

2

H

.

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(8)

Assuming M = N , the linear time complexity approxima-
tion of weighted MMD can then be computed as,

MMD2

l,w(Ds, Dt) =

hl,w(zi),

(9)

2
M

M/2

Xi=1

where hl,w(zi) is an operator deﬁned on a quad-tuple zi =
(xs

2i−1, xs

2i, xt

2j−1, xt

2j),

hl,w(zi) = αys
− αys

2i

2i−1 αys
2i−1 k(xs

k(xs
2i−1, xt

2i−1, xs

2i) + k(xt
k(xs

2i−1, xt
2i, xt

2i)
2j−1).

2j) − αys
2i

(10)

4. Weighted Domain Adaptation Network

By far, we have introduced our weighted MMD for mea-
suring domain discrepancy. But there are two remained is-
sues to be addressed. On one hand, the proposed weighted
MMD, similar to MMD, should be incorporated into some
classiﬁers for domain adaptation. On the other hand, the
class distribution on target domain is generally unknown
during training. In this section, we propose a weighted do-
main adaptation network (WDAN) model, which is in es-
sential an extension of the semi-supervised logistic regres-
sion [1] by adding the WMMD term and incorporating with
CNN. Meanwhile, we employ the CEM [6] framework and
show how we optimize the proposed WDAN without the
label information of the target samples.

First, based on the research in [40, 25], the features grad-
ually become task speciﬁc as the layers go toward the top
one, resulting in increasing dataset bias for the higher layers
of features. Therefore, to generalize CNN for domain adap-
tation, the weighted MMD-based regularizers are added to
the higher layers of CNN. Second, the relationship between
semi-supervised learning and domain adaptation has been
studied in [33]. To further exploit the unlabelled data on
target domain, we follow the semi-supervised CEM model
in [1], leading to the following WDAN model,

min
W,{ˆyj}N

j=1,α

ℓ(xs

i , ys

i ; W) + γ

ℓ(xt

j , ˆyt

j; W)

1
N

N

Xj=1

+ λ

MMDl,w(Dl

s, Dl

t),

(11)

1
M

M

Xi=1
l2

Xl=l1

where W denotes the model parameters to be learned, and
{ˆyj}N
j=1 represent the assigned labels of target samples. λ
and γ are two tradeoff parameters. Dl
t denote the
l-th layer features of the source and target domains, respec-
tively. ws
c is estimated based on the source data Dl
s, i.e.,
ws
c = Mc/M , where Mc is the number of samples of the
c-th class. The ﬁrst two terms of Eqn. (11) are the soft-max
loss items on the source and target samples, respectively.

s and Dl

And the third term is the weighted MMD regularizers for
the l1 ∼ l2-th layers deﬁned in Eqn. (8).

j}N

Next, we explain the optimization procedure of the pro-
posed WDAN model. Following the CEM algorithm in [6],
the WDAN model is optimized by alternating between:
(i) E-step: estimating the class posterior probability of
{xt
j=1, (ii) C-step: assigning pseudo-labels {ˆyj}N
j=1 and
estimating auxiliary weights α, (iii) M-step: updating the
model parameters W. Given the model parameters W,
for each xt
j , we ﬁrst estimate the class posterior probability
based on the output of softmax classiﬁer. The pseudo-label
to ˆyj is assigned to xt
j based on the maximum posterior
probability, and the auxiliary weights α are then estimated
based on pseudo-labels. Given {ˆyj}N
j=1 and α, the conven-
tional backpropagation algorithm is then deployed to update
W. In the following, we give more details on the E-step, C-
step, and M-step.

E-step: Fixed W, for each sample xt

j from target do-
main, the CNN output to the cth class is represented as
gc(xt
j ; W). Here we simply deﬁne the class posterior prob-
ability p(yt

j = c|xt

j) as,

p(yt

j = c|xt

j) = gc(xt

j; W).

C-step: With p(yt
j by,

to xt

j = c|xt

j), we assign pseudo-label ˆyj

ˆyj = arg max

p(yt

j = c|xt

j).

c

Let 1c(ˆyj) be an indicator function,

(12)

(13)

(14)

1c(ˆyj) =

1, if ˆyj = c
0, otherwise.

(cid:26)

1c(ˆyj)

The class weight ˆwt

c can be estimated by ˆwt

c =
N , where N is the number of target samples.
ws
c

j
P
Then the auxiliary weight can be updated with αc = ˆwt
c
.

.

(cid:14)

M-step: Fixed α, the subproblem on W can be formu-

lated as,

L(W) =

min
W

ℓ(xs

i , ys

i ; W) + γ

ℓ(xt

j, ˆyt

j; W)

1
N

N

Xj=1

+ λ

MMDl,w(Dl

s, Dl

t).

(15)

1
M

M

Xi=1
l2

Xl=l1

Since the gradients of the three terms in Eqn. (15) are com-
putable, W can be updated with mini-batch SGD. Let zi =
(xs
2i−1, xs
i= (zl
i,1 =
f s,l
2i−1, zl
2i−1, zl
2i ) be the l-th layer
feature representation of zi. Given zi, the gradient with re-
spect to the l-th layer parameter Wl can be written as,

2j ) be a quad-tuple and zl

2i, xt
i,2 = f s,l

2j−1, xt
2i , zl

i,4 = f t,l

i,3 = f t,l

∂L(W)
∂Wl =

1
2

2

∂ℓ(z

i,j, yi,j; W)
∂zl
i,j

∂zl
i,j
∂Wl

4

∂ℓ(z

+

γ
2

Xj=3

Xj=1
i,j , ˆyi,j; W)
∂zl
i,j

4

∂zl
i,j
∂Wl + λ

Xk=1

∂hl,w(zi)
∂zl

i,k

i,k

∂zl
∂Wl .
(16)

Taking k = 1 for example, ∂hl,w(zl
i)

can be computed as,

∂zl

i,1

∂hl,w(zi)
∂f s,l

2i−1

=αys

2i−1 αys

2i

2i−1, f s,l
∂k(f s,l
2i )
∂f s,l
∂k(f s,l
2i−1, f t,l
2i )
∂f s,l

2i−1

.

2i−1

− αys

2i−1

(17)

i,k

∂zl

can also be computed for other k

Similarly, ∂hl,w(zl
i)
values. Thus, the model parameters can be updated via
backpropagaton with a mini-batch of quad-tuple. More-
over, following [25, 17], the multiple kernel parameters β
can also be updated during training.

The algorithm described above actually is an extension
of classiﬁcation EM. The C-step in [6] only assigns pseudo-
label to each unlabeled sample, while in this work we fur-
ther estimate the auxiliary weights α with the pseudo-labels.
As shown in [6], such a optimization procedure can con-
verge to a stationary value. The experiment also empiri-
cally validate that our algorithm works well in estimating
the auxiliary weights α.

5. Experiments

In this section, we ﬁrst evaluate our proposed WDAN
on four widely used benchmarks in UDA, i.e., Ofﬁce-
10+Caltech-10 [14], Ofﬁce31 [31], ImageCLEF [5] and
Digit Recognition. Moreover, we also provide empirical
analysis to our proposed WDAN model from three as-
pects, i.e., hyper-parameter sensitivity, robustness to class
weight bias, and feature visualization.

Following the common setting in UDA, we implement
our WDAN model based on four widely used CNN archi-
tectures, i.e., LeNet [22], AlexNet [21], GoogLeNet [34]
and VGGnet-16 [32]. As suggested in [25], we train
our method based on pre-trained AlexNet, VGGNet-16,
or GoogLeNet on ImageNet, with the layers from conv1
to conv3 ﬁxed for AlexNet and inception layers from
inc1 to inc3 ﬁxed for GoogLeNet. The WDAN (LeNet)
In
is trained from the scratch (random initialization).
addition, the auxiliary weight is initialized with αc = 1
for each class. For l1 and l2, we follow the setting in [25].

Method
AlexNet [21]
LapCNN (AlexNet) [38]
DDC (AlexNet) [36]
DAN (AlexNet) [25]
WDAN (AlexNet)
WDAN⋆ (AlexNet)
GoogLeNet [34]
DDC (GoogLeNet) [36]
DAN (GoogLeNet) [25]
WDAN (GoogLeNet)
VGGnet-16 [32]
DAN (VGGnet-16) [25]
WDAN (VGGnet-16)

A→C
84.0±0.3
83.6±0.6
84.3±0.5
86.0±0.5
86.9±0.1
87.1±0.2
91.3±0.2
91.4±0.2
91.4±0.3
92.2±0.2
89.6±0.4
91.2±0.2
91.4±0.2

W→C
77.9±0.4
77.8±0.5
76.9±0.4
81.5±0.3
84.1±0.2
85.1±0.3
88.2±0.3
88.7±0.3
89.7±0.2
91.0±0.5
88.1±0.4
90.6±0.3
91.0±0.2

D→C
81.0±0.4
80.6±0.4
80.5±0.2
82.0±0.4
83.9±0.1
85.2±0.2
88.9±0.3
89.0±0.4
89.1±0.4
89.8±0.3
85.4±0.5
87.1±0.4
89.0±0.3

C→A
91.3±0.2
92.1±0.3
91.3±0.3
92.0±0.3
93.1±0.2
93.2±0.1
95.2±0.1
95.3±0.2
95.5±0.2
95.5±0.3
93.7±0.2
95.7±0.2
95.7±0.1

C→W
83.2±0.3
81.6±0.4
85.5±0.3
92.6±0.4
93.6±0.2
93.5±0.3
92.5±0.2
93.0±0.1
93.1±0.3
95.4±0.2
94.3±0.2
95.3±0.3
95.8±0.2

C→D
89.1±0.2
87.8±0.4
89.1±0.3
90.5±0.2
93.4±0.2
94.5±0.2
94.7±0.3
94.9±0.4
95.3±0.1
95.5±0.5
93.7±0.2
94.7±0.1
95.9±0.3

Avg.
84.0
83.9
84.6
87.3
89.2
89.8
91.8
92.1
92.3
93.2
90.8
92.4
93.1

Table 1. Results (in %) of different methods based on AlexNet, GoogleNet and VGGnet-16 on Ofﬁce-10+Caltech-10. Note that the results
of LapCNN, DDC and DAN are duplicated from [25]. ⋆ indicates that the ground truth class distributions in both source and target domain
are used as prior.

three fully connected layers for AlexNet,

Concretely, WMMD-based regularizers are added to the
the last
last
inception and fully connected layers for GoogleNet, and
the last fully connected layer for LeNet. All experiments
are implemented by using Caffe Toolbox [20], and run
on a PC equipped with a NVIDIA GTX 1080 GPU and
32G RAM. We set the batch size to 64 for all methods,
and optimize the learning rate for each model indepen-
dently. The tradeoff parameters λ and γ are optimized
in sets {0, 0.03, 0.07, 0.1, 0.4, 0.7, 1.4, 1.7, 2} and
{0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0}
The
by
source
at:
https://github.com/yhldhit/WMMD-Caffe.

respectively.
our WDAN is

cross-validation,

available

code

of

5.1. Comparison with State of the arts

For UDA, we employ the standard protocols as [25, 23,
27], where all the samples in source and target domain are
used for training. The averaged results over 10 trials on
target domain set are reported for comparison.

5.1.1 Ofﬁce-10+Caltech-10

Ofﬁce-10+Caltech-10 [14] is widely used for domain adap-
tation, which picks up 10 classes shared in Ofﬁce-31 [31]
and Caltech-256 [18].
It consists of four domains where
Amazon (A), Webcam (W) and DSLR (D) are from Ofﬁce-
31, and the another one is Caltech-256 (C). On this dataset,
we conduct experiments based on AlexNet, GoogLeNet and
VGGnet-16, and exploit the same setting as [25] for perfor-
mance comparison.

We compare our WDAN with several state-of-the-art
methods as listed in Table 1, including its MMD counter-

part DAN [25]. By AlexNet, GoogLeNet, and VGGnet-
16 we indicate to ﬁne-tune the pre-trained CNN models
for special tasks. LapCNN [38] can be seen as a variant
of CNN, which ﬁrst shows deep structure learning can be
improved by jointly learning an embedding with the unla-
beled data, and then exploits the embedding as a regularizer.
By embedding a single kernel MMD layer into CNN struc-
ture, DDC [36] develops a uniﬁed deep framework to jointly
learn semantically meaningful feature and perform adaption
cross domain.

Numerical results in Table 1 show that our weighted
DAN achieves the best performance, independently of the
employed CNN structure. Moreover, the WDAN is superior
to DAN by 1.9%, 0.9% and 0.7%, respectively. We con-
tribute this improvement to that our weighted MMD model
can alleviate the effect of class weight bias.
In addition,
the superiority over other state-of-the-art methods demon-
strate the effectiveness of the proposed WDAN. Finally, we
exploit the ground truth class distributions in both source
and target domains as prior of the proposed WDAN based
on AlexNet, which is indicated as WDAN⋆ (AlexNet) in
Table 1. Although WDAN⋆ can further improve the perfor-
mance of WDAN, the smaller gap between them than one
between weighted DAN and DAN validate the effectiveness
of our proposed learning and estimation method.

5.1.2 ImageCLEF

ImageCLEF [5] is developed for the ImageCLEF domain
adaptation task1. This dataset collects images from ﬁve
widely used image benchmarks, including Caltech256 [18],
ImageNet2012 [7] and
Bing, PASCAL VOC2012 [9],

1http://www.imageclef.org/2014/adaptation

Method

GoogLeNet
DDC [36]
DAN
WDAN

P→C

91.0±0.5
91.2±0.4
91.4±0.2
91.4±0.1

B→C

92.4±0.3
92.6±0.4
93.0±0.1
93.8±0.2

C→B

61.2±0.4
62.0±0.3
62.5±0.3
62.9±0.3

P→B

55.3±0.3
54.3±0.3
54.5±0.2
55.2±0.3

C→P

61.2±0.2
61.7±0.4
62.2±0.3
65.0±0.2

B→P

58.1±0.3
58.6±0.3
59.0±0.3
59.5±0.3

Avg.

69.9
70.1
70.4
71.3

Table 2. Results (in %) of different methods based on GoogLeNet
on ImageCLEF dataset.

Method

LeNet
SA [10]
DAN
WDAN

M→S
17.2±0.3
21.1±0.2
19.3±0.4
23.4±0.2

S→M
56.8±0.5
59.3±0.3
65.2±0.3
67.4±0.4

M→U
61.5±0.4
55.0±0.4
69.1±0.5
72.6±0.3

U→M
46.5±0.6
51.6±0.6
60.5±0.7
65.4±0.4

Avg

45.5
46.8
53.5
57.2

Table 3. Results (in %) of different methods based on LeNet on
Digit Classiﬁcation.

Method

A→W

D→W

W→D

A→D

D→A

W→A

Avg.

94.0±0.3
94.3±0.3
95.9±0.1

60.4±0.5
66.0±0.5
66.8±0.3

AlexNet
DAN
WDAN

66.7
70.0
72.1
Table 4. Results (in %) of different methods based on AlexNet on
Ofﬁce-31 dataset.

92.2±0.3
95.2±0.3
98.7±0.4

58.6±0.6
63.2±0.4
64.5±0.2

46.0±0.6
50.0±0.5
53.8±0.1

49.0±0.5
51.1±0.5
52.7±0.2

SUN [39]. This dataset is thought to be more difﬁcult, since
some domains contain low-quality images, making this
benchmark a good compliance to the Ofﬁce-10+Caltech-10,
where the domain is more similar. Different from the orig-
inal experimental setting, in this paper, we use a subset of
ImageCLEF, which contains three datasets, i.e., Caltech256
(C), Bing (B) and PASCAL VOC2012 (P). Meanwhile, we
exploit all images in each subset rather than follow the stan-
dard protocol to sample the same number of images for each
class. Such setting results in six domain adaptation tasks.

We compare WDAN with three related methods based
on GoogLeNet, i.e., GoogLeNet, DDC and DAN. We im-
plement them by using the codes released by authors2, and
try our best to optimize them. The results of the competing
methods are shown in Table 2, from which we can see that
our proposed weighted DAN obtains the best performance
in most of the cases, and achieves 1.4%, 1.2% and 0.9%
gains over GoogLeNet, DDC and DAN on average, respec-
tively. The above results show the proposed weighted MMD
is helpful to improve the performance of domain adaptation
task.

5.1.3 Digit Recognition

Furthermore, we conduct experiment on digit recognition,
which is usually adopted to domain adaptation. In this pa-
per, we only considering training images of three bench-
marks, i.e., MNIST (M), SVHN (S) and USPS (U) and con-
duct experiments on four tasks. As LeNet [22] is usually
used for digit recognition, we implement our WDAN and
the competing methods based on it. Among them, SA [10]
proposes a subspace alignment method for domain adap-
tation, which aims at learning a feature mapping to align

2https://github.com/longmingsheng/mmd-caffe

Figure 3. Performance (in %) of different methods w.r.t. λ.

source samples with target samples. For fair comparison,
we implement SA by using the features from the ﬁne-tuned
LeNet. The results reported in Table 3 clearly show that
our proposed WDAN achieves the best performance on all
tasks, and outperforms LeNet, SA and DAN by 11.7%,
10.4% and 3.7% on average, respectively. The signiﬁcant
improvements over competing methods show the proposed
weighted MMD model is effective and meaningful.

5.1.4 Ofﬁce-31

Finally, experiments are further conducted to assess WDAN
on datasets with more classes. We conduct experiments on
a dataset with 31 classes (i.e. Ofﬁce-31). There are three
domains, i.e., Amazon (A), Webcam (W) and DSLR (D),
In this part, we consider all the six UDA
in Ofﬁce-31.
tasks, and report the results using Alexnet. Table 4 shows
the results of AlexNet, DAN, and WDAN. It can be seen
that the proposed WMMD achieves better results than its
MMD counterpart, indicating that WMMD also works well
on dataset with more classes. To sum up, the promising
performance of our weighted MMD model can be veriﬁed
on various CNN architectures (i.e., AlexNet, GoogLeNet
and LeNet) and various datasets with different number of
classes.

5.2. Empirical Analysis

In this subsection, we perform empirical analysis of the
proposed WDAN from three aspects. Firstly, we evaluate
the effect of hyper-parameter λ on our proposed WDAN
model in Eqn. (11). Secondly, compared with its baselines,
i.e., Alexnet and DAN, we show our proposed WDAN is
robust to class weight bias. Finally, we make a visualization
of learned feature representations.

5.2.1 Effect of Parameter λ

The objective in Eqn. (11) of WDAN consists of three
i.e., conventional empirical losses on the source
terms,

and target domains, and MMD-based regularizer. Gener-
ally speaking, the empirical risk term keeps the learned
deep feature to be discriminative on source domain while
the MMD-based regularizer encourages domain invariant
feature representation. Both of this two aspects are of
essential importance for domain adaptation. The param-
eter λ in the objective Eqn. (11) makes a tradeoff be-
tween this two parts, and could greatly impact the per-
formance of domain adaptation. To have a closer look at
this parameter, we evaluate our proposed WDAN based on
AlexNet on the task W→C from Ofﬁce-10+Caltech-10 un-
der various λ. As suggested above, λ belongs to the set
{0.0, 0.03, 0.07, 0.1, 0.4, 0.7, 1, 1.4, 1.7, 2}. Meanwhile,
we also compared our WDAN model with DAN under var-
ious λ. AlexNet is reported as baseline and corresponds to
the case λ = 0. The results are illustrated in Fig. 3.

Obvious conclusions can be drawn from the results: (i)
our proposed WDAN consistently outperforms the DAN,
demonstrating that mining the class weight bias in MMD
is meaningful and beneﬁcial; (ii) WDAN and DAN achieve
the best results at λ = 0.4 and λ = 0.1, and outperforms the
baseline, i.e., AlexNet, when λ < 1.2 and λ < 1.0, respec-
tively, indicating that an appropriate balance is important
and necessary.

5.2.2 Impact of Class Weight Bias

To further clarify the impact of class weight bias on MMD-
based domain adaptation methods, we conduct experiments
on a variant of the task V→C from ImageCLEF based
on AlexNet. Speciﬁcally, we pick up two shared classes,
i.e., airplane and motorbike, in the source domain PASCAL
VOC2012 (V) and target domain Caltech256 (C), which
forms a two-class classiﬁcation problem.

Then we ﬁx the class weights as 0.5 for each class on
source domain and train different methods with gradually
changing the class distribution on target domain, which can
be interpreted as different level of the class weight bias
cross source and target domains. Fig. 4 show the results
of WDAN, DAN and AlexNet under different levels of the
class weighted bias. From it we can see that the class weight
bias has great inﬂuence on performance of MMD-based
domain adaptation methods. Moreover, the conventional
MMD-based methods (e.g., DAN) are limited in handling
the class weight bias, as its results signiﬁcantly degrade
with increasing class weighted bias. In addition, our pro-
posed WDAN is more robust to class weighted bias.

5.2.3 Feature Visualization

Following the work in [25], we visualize the features
learned by WDAN and DAN on target domain in the D→C
task from Ofﬁce-10+Caltech-10. For feature visualization,
we employ the t-SNE visualization method [37] whose

Figure 4. Performance (in %) of different methods w.r.t. class
weight bias.

Figure 5. The t-SNE visualization of learned features of different
methods.

source codes are provided3. The results of feature visualiza-
tion for DAN and weighted DAN are illustrated in Fig. 5 (a)
and Fig. 5 (b), respectively. As shown in the orange boxes of
Fig. 5, features learned by the proposed WDAN can reserve
more class discrepancy distance than ones learned by DAN.
The underlying reason lies in the fact that WDAN, by con-
sidering a weighted MMD regularizer, does not minimize
the class weight bias as DAN does, which also accounts for
that weighted DAN can outperform DAN on a variety of
unsupervised domain adaptation tasks.

6. Conclusion

In this paper, we focus on the uninvestigated issue of
class weight bias in UDA, which has adverse effect on
MMD-based domain adaptation methods. We ﬁrst propose
a novel weighted MMD to reduce the effect of class weight
bias by constructing a reference source distribution based
on target distribution. For UDA, we present a weighted
DAN (WDAN) based on the proposed weighted MMD, and
develop modiﬁed the CEM learning algorithm to jointly as-
sign pseudo-labels, estimate the auxiliary weights and learn
model parameters. Empirical results show that our proposed
WDAN outperforms its MMD counterpart, i.e., DAN, in
various domain adaptation tasks. In future, there remains
several issues to be investigated: (i) evaluation of weighted

3https://lvdmaaten.github.io/tsne/

MMD on non-CNN based UDA models, (ii) applications to
other tasks (e.g., image generation) based on measuring the
discrepancy between distributions.

7. Acknowledgment

This work is

supported in part by NSFC grant
(61671182, 61471082, and 61370163). The authors also
thank NVIDIA corporation for the donation of GTX 1080
GPU.

References

[1] M.-R. Amini and P. Gallinari. Semi-supervised logistic re-
gression. In Proceedings of the 15th European Conference
on Artiﬁcial Intelligence, pages 390–394. IOS Press, 2002.
2, 4

[2] H. Azizpour, A. Sharif Razavian, J. Sullivan, A. Maki, and
S. Carlsson. From generic to speciﬁc deep representations
for visual recognition. In Proceedings of the IEEE Confer-
ence on Computer Vision and Pattern Recognition, pages 36–
45, 2015. 1

[3] M. Baktashmotlagh, M. T. Harandi, and M. Salzmann.
Distribution-matching embedding for visual domain adapta-
tion. Journal of Machine Learning Research, 2016. 1, 3
[4] K. M. Borgwardt, A. Gretton, M. J. Rasch, H.-P. Kriegel,
B. Sch¨olkopf, and A. J. Smola. Integrating structured bio-
logical data by kernel maximum mean discrepancy. Bioin-
formatics, 22(14):e49–e57, 2006. 3

[5] B. Caputo and N. Patricia. Overview of the imageclef 2014
domain adaptation task. In ImageCLEF 2014: Overview and
analysis of the results, number EPFL-CONF-201812, 2014.
5, 6

[6] G. Celeux and G. Govaert. A classiﬁcation em algorithm
for clustering and two stochastic versions. Computational
statistics & Data analysis, 14(3):315–332, 1992. 4, 5

[7] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-
Imagenet: A large-scale hierarchical image database.
Fei.
In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, pages 248–255, 2009. 6

[8] J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang,
E. Tzeng, and T. Darrell. Decaf: A deep convolutional acti-
vation feature for generic visual recognition. In Proceedings
the International Conference on Machine Learning, pages
647–655, 2014. 1

[9] M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and
A. Zisserman. The pascal visual object classes (voc) chal-
lenge. International journal of computer vision, 88(2):303–
338, 2010. 6

[10] B. Fernando, A. Habrard, M. Sebban, and T. Tuytelaars. Un-
supervised visual domain adaptation using subspace align-
ment. In Proceedings of the IEEE International Conference
on Computer Vision, pages 2960–2967, 2013. 7

[11] Y. Ganin and V. Lempitsky. Unsupervised domain adaptation
by backpropagation. arXiv preprint arXiv:1409.7495, 2014.
3

[12] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich fea-
ture hierarchies for accurate object detection and semantic

In Proceedings of the IEEE Conference on
segmentation.
Computer Vision and Pattern Recognition, pages 580–587,
2014. 1

[13] B. Gong, K. Grauman, and F. Sha. Connecting the dots with
landmarks: Discriminatively learning domain-invariant fea-
In Proceedings
tures for unsupervised domain adaptation.
the International Conference on Machine Learning, pages
222–230, 2013. 3

[14] B. Gong, Y. Shi, F. Sha, and K. Grauman. Geodesic ﬂow
kernel for unsupervised domain adaptation. In Proceedings
of the IEEE Conference on Computer Vision and Pattern
Recognition, pages 2066–2073, 2012. 5, 6

[15] A. Gretton, K. M. Borgwardt, M. Rasch, B. Sch¨olkopf, and
A. J. Smola. A kernel method for the two-sample-problem.
In Advances in neural information processing systems, pages
513–520, 2006. 2

[16] A. Gretton, K. M. Borgwardt, M. J. Rasch, B. Sch¨olkopf, and
A. Smola. A kernel two-sample test. Journal of Machine
Learning Research, 2012. 3

[17] A. Gretton, D. Sejdinovic, H. Strathmann, S. Balakrishnan,
M. Pontil, K. Fukumizu, and B. K. Sriperumbudur. Optimal
kernel choice for large-scale two-sample tests. In Advances
in neural information processing systems, pages 1205–1213,
2012. 2, 5

[18] G. Grifﬁn, A. Holub, and P. Perona. Caltech-256 object cat-

egory dataset. 2007. 6

[19] J. Huang, A. Gretton, K. M. Borgwardt, B. Sch¨olkopf, and
A. J. Smola. Correcting sample selection bias by unlabeled
data. In Advances in neural information processing systems,
pages 601–608, 2006. 1, 3

[20] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Gir-
shick, S. Guadarrama, and T. Darrell. Caffe: Convolu-
tional architecture for fast feature embedding. arXiv preprint
arXiv:1408.5093, 2014. 6

[21] A. Krizhevsky, I. Sutskever, and G. E. Hinton.

Imagenet
classiﬁcation with deep convolutional neural networks.
In
Advances in neural information processing systems, pages
1097–1105, 2012. 1, 5, 6

[22] Y. Lecun, L. E. Bottou, Y. Bengio, and P. Haaner. Gradient-
based learning applied to document recognition. 1998. 5,
7

[23] Y. Li, K. Swersky, and R. Zemel. Generative moment match-
ing networks. In Proceedings the International Conference
on Machine Learning, pages 1718–1727, 2015. 6

[24] J. Long, E. Shelhamer, and T. Darrell. Fully convolutional
networks for semantic segmentation. In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 3431–3440, 2015. 1

[25] M. Long and J. Wang. Learning transferable features with
deep adaptation networks. CoRR, abs/1502.02791, 1:2,
2015. 3, 4, 5, 6, 8

[26] M. Long, J. Wang, G. Ding, J. Sun, and P. S. Yu. Transfer
In Pro-
feature learning with joint distribution adaptation.
ceedings of the IEEE International Conference on Computer
Vision, pages 2200–2207, 2013. 1, 3

[27] M. Long, J. Wang, and M. I. Jordan. Unsupervised domain
adaptation with residual transfer networks. arXiv preprint
arXiv:1602.04433, 2016. 6

[28] T. Ming Harry Hsu, W. Yu Chen, C.-A. Hou, Y.-H. Hu-
bert Tsai, Y.-R. Yeh, and Y.-C. Frank Wang. Unsupervised
domain adaptation with imbalanced cross-domain data.
In
Proceedings of the IEEE International Conference on Com-
puter Vision, pages 4121–4129, 2015. 1, 2

[29] S. J. Pan, I. W. Tsang, J. T. Kwok, and Q. Yang. Domain
adaptation via transfer component analysis. IEEE Transac-
tions on Neural Networks, 22(2):199–210, 2011. 1, 3
[30] S. J. Pan and Q. Yang. A survey on transfer learning.
IEEE Transactions on knowledge and data engineering,
22(10):1345–1359, 2010. 1

[31] K. Saenko, B. Kulis, M. Fritz, and T. Darrell. Adapting vi-
sual category models to new domains. In European confer-
ence on computer vision, pages 213–226. Springer, 2010. 5,
6

[32] K. Simonyan and A. Zisserman. Very deep convolutional
networks for large-scale image recognition. arXiv preprint
arXiv:1409.1556, 2014. 5, 6

[33] A. Søgaard. Semi-supervised learning and domain adapta-
tion in natural language processing. Synthesis Lectures on
Human Language Technologies, 6(2):1–103, 2013. 4
[34] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed,
D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich.
Going deeper with convolutions. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition,
pages 1–9, 2015. 5, 6

[35] E. Tzeng, J. Hoffman, T. Darrell, and K. Saenko. Simultane-
ous deep transfer across domains and tasks. In Proceedings
of the IEEE International Conference on Computer Vision,
pages 4068–4076, 2015. 3

[36] E. Tzeng, J. Hoffman, N. Zhang, K. Saenko, and T. Darrell.
Deep domain confusion: Maximizing for domain invariance.
arXiv preprint arXiv:1412.3474, 2014. 1, 3, 6, 7

[37] L. Van Der Maaten. Accelerating t-sne using tree-based al-
gorithms. Journal of machine learning research, 2014. 8
[38] J. Weston, F. Ratle, H. Mobahi, and R. Collobert. Deep learn-
In Neural Networks:

ing via semi-supervised embedding.
Tricks of the Trade, pages 639–655. Springer, 2012. 6
[39] J. Xiao, J. Hays, K. A. Ehinger, A. Oliva, and A. Torralba.
Sun database: Large-scale scene recognition from abbey to
zoo. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, pages 3485–3492, 2010. 7
[40] J. Yosinski, J. Clune, Y. Bengio, and H. Lipson. How trans-
ferable are features in deep neural networks? In Advances
in neural information processing systems, pages 3320–3328,
2014. 1, 4

[41] E. Zhong, W. Fan, J. Peng, K. Zhang, J. Ren, D. Turaga,
and O. Verscheure. Cross domain distribution adaptation via
kernel mapping. In Proceedings of the 15th ACM SIGKDD
international conference on Knowledge discovery and data
mining, pages 1027–1036, 2009. 1, 3

7
1
0
2
 
y
a
M
 
1
 
 
]

V
C
.
s
c
[
 
 
1
v
9
0
6
0
0
.
5
0
7
1
:
v
i
X
r
a

Mind the Class Weight Bias: Weighted Maximum Mean Discrepancy
for Unsupervised Domain Adaptation

Hongliang Yan1, Yukang Ding1, Peihua Li2, Qilong Wang2, Yong Xu3, Wangmeng Zuo1,∗
1School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China
2School of Information and Communication Engineering, Dalian University of Technology, Dalian, China
3Bio-Computing Research Center, Shenzhen Graduate School, Harbin Institute of Technology, Shenzhen, China
yanhl@hit.edu.cn, dingyukang921@163.com, peihuali@dlut.edu.cn,

qlwang@mail.dlut.edu.cn, laterfall@hitsz.edu.cn, wmzuo@hit.edu.cn

 

MNIST
USPS
SVHN

0.2

0.16

t
h
g
i
e
w

0.12

0.08

0.04

 

Abstract

In domain adaptation, maximum mean discrepancy
(MMD) has been widely adopted as a discrepancy met-
ric between the distributions of source and target domains.
However, existing MMD-based domain adaptation methods
generally ignore the changes of class prior distributions,
i.e., class weight bias across domains. This remains an
open problem but ubiquitous for domain adaptation, which
can be caused by changes in sample selection criteria and
application scenarios. We show that MMD cannot account
for class weight bias and results in degraded domain adap-
tation performance. To address this issue, a weighted MMD
model is proposed in this paper. Speciﬁcally, we introduce
class-speciﬁc auxiliary weights into the original MMD for
exploiting the class prior probability on source and target
domains, whose challenge lies in the fact that the class label
in target domain is unavailable. To account for it, our pro-
posed weighted MMD model is deﬁned by introducing an
auxiliary weight for each class in the source domain, and
a classiﬁcation EM algorithm is suggested by alternating
between assigning the pseudo-labels, estimating auxiliary
weights and updating model parameters. Extensive exper-
iments demonstrate the superiority of our weighted MMD
over conventional MMD for domain adaptation.

1. Introduction

Deep convolutional neural networks (CNNs) have
achieved great success in various computer vision tasks
such as image classiﬁcation [21], object detection [12] and
semantic segmentation [24]. Besides the inspiring progress
in model and learning, the achievement of CNN is un-
doubtedly attributed to the availability of massive labeled

∗Corresponding author.

0

1

2

3

6

7

8

9

4

5

class

Figure 1. Class prior distributions of three domains for digit recog-
nition. As is shown, class bias exists across domains. It is natural
to see that the class weight of 0 and 1 are relatively high in postal
service (USPS), and the class weight of 1 and 2 are relatively high
in house numbers (SVHN).

datasets. For a CNN trained on large scale datasets [8],
while the lower layers of features are safely transferable, the
learned features gradually moves from general to speciﬁc
along the network [40]. When the source and target tasks
are signiﬁcantly diverse, the CNN pretrained on the source
task may not generalize well to the target task. Such sce-
nario leads to an emerging topic to transfer the CNN from
the source task to the target task with the enhanced and dis-
criminative representation [2]. In this work, we study a spe-
cial type of transfer learning task, i.e., domain adaptation
(DA) [30].

One of the most fruitful lines for DA is MMD-based
method [26, 29, 3, 41, 36]. Despite the great success
achieved, existing ones generally ignore the changes of
class prior distributions, dubbed by class weight bias.
It
is ubiquitous for domain adaptation and can be caused by
changes in sample selection criteria [19] and application
scenarios [28]. As shown in Fig. 1, the class prior dis-
tributions (i.e., class weights) vary with domains for digit
recognition. Moreover, a special case of class weight bias

Figure 2. Results of minimizing MMD and WMMD regularizer under class weight bias are illustrated in (a) and (b), respectively. Mini-
mizing MMD preserves the class weights in source domain and thus the target samples will be wrongly estimated, as indicated by yellow
samples. On the contrary, the proposed weighted MMD removes the effect of class bias by ﬁrst reweighting source data.

is the imbalanced cross-domain data problem [28] where
several classes in source domain do not appear in tar-
get domain, as shown in Fig. 2. The Closest Common
Space Learning (CCSL) method in [28] is suggested for
imbalanced and multiple cross-domain visual classiﬁca-
tion. However, CCSL just combines conventional MMD
with domain-dependent MMD without explicitly consider-
ing class weight bias.

For MMD-based methods, the ignorance of class weight
bias can deteriorate the domain adaptation performance. In
the case of class weight bias, the MMD can be minimized
by either learning domain-invariant representation or pre-
serving the class weights in source domain. As illustrated
in Fig. 2 (a), it is unreasonable for domain adaptation to re-
quire that the class weights in target domain should keep
the same as those in source domain. Our empirical exper-
iments also reveal the limitation of MMD in coping with
class weight bias (See Fig. 4).

In this paper, we propose a weighted MMD (WMMD)
method to address the issue of class weight bias. As for
DA, the challenge is that the class labels in target domain
are unknown. So we ﬁrst introduce class-speciﬁc auxil-
iary weights to reweight the source samples. In this way,
the reweighted source data are expected to share the same
class weights with target data. The auxiliary weights es-
timation and model parameters learning are jointly opti-
mized by minimizing the objective function of weighted
MMD. Different from MMD, the objective function based
on our weighted MMD involves additional weight parame-
ters, and we present a classiﬁcation EM (CEM) scheme to
estimate it. Inspired by the semi-supervised logistic regres-
sion in [1], we propose a weighted Domain Adapation Net-
work (WDAN) by both incorporating the weighted MMD

into CNN and taking into account the empirical loss on tar-
get samples. The CEM algorithm are developed for learning
WDAN in three steps, i.e., E-step, C-step, and M-step. In
the E-step and the C-step, we calculate the class posterior
probability, assign the pseudo-labels to the target samples,
and estimate the auxiliary weight.
In the M-step, model
parameters are updated by minimizing the objective loss.
Experimental results show our weighted MMD can learn
better domain-invariant representation for domain adapta-
tion. Moreover, the models based on weighted MMD also
outperforms the MMD-based counterparts. In summary, the
main contributions of this work are three-fold:

1. A weighted MMD model is proposed to alleviate the
effect of class weight bias in domain adaptation. By
taking class prior distributions into account, weighted
MMD can provide a better metric for domain discrep-
ancy.

2. Using unbiased estimate of multi-kernel MMD [15,
17], our proposed weighted MMD can be computed as
mean embedding matching with linear time complex-
ity and be incorporated into CNN for unsupervised do-
main adaptation. We further develop a CEM algorithm
for training the weighted MMD model.

3. Experiments demonstrate that weighted MMD outper-
forms MMD for domain adaptation. The superiority of
weighted MMD over MMD has been veriﬁed on vari-
ous CNN architectures and different datasets.

In the remainder of this paper, we begin with a brief
introduction to the preliminaries and related work in Sec-
tion 2.
In Section 3, by considering class weight bias,
we propose weighted MMD on the basis of conventional

MMD. After that, in Section 4, we apply weighted MMD
to unsupervised domain adaptation and present a model
named WDAN. Extensive experimental results are given
in Section 5 to verify the effectiveness of our proposed
weighted MMD model and detailed empirical analysis to
our proposed model is provided. Finally, we conclude this
work in Section 6.

2. Preliminaries and Related Work

In this section, we ﬁrst review MMD and its application
in domain adaptation, and then survey several other meth-
ods used to measure domain discrepancy.

2.1. MMD and Its Application in Domain Adapta 

tion

Domain adaptation aims at adapting the discriminative
model learned on source domain into target domain. De-
pending on the accessibility of class labels for target sam-
ples during training, research lines can be grouped into three
categories: supervised, semi-supervised, and unsupervised
domain adaptation.
In this paper, we focus on learning
transferable CNN features for unsupervised domain adap-
tation (UDA), where the labels of all target samples are un-
known during training. Compared with the other settings,
UDA is more ubiquitous in real-world applications.

Due to the unavailability of labels in the target domain,
one commonly used strategy of UDA is to learn domain in-
variant representation via minimizing the domain distribu-
tion discrepancy. Maximum Mean Discrepancy (MMD) is
an effective non-parametric metric for comparing the distri-
butions based on two sets of data [4]. Given two distribu-
tions s and t, by mapping the data to a reproducing kernel
Hilbert space (RKHS) using function φ(·), the MMD be-
tween s and t is deﬁned as,

2

MMD

(s, t) = sup

kφkH≤1 (cid:13)
(cid:13)

Exs∼s [φ(xs)] − Ext∼t (cid:2)φ(xt)(cid:3)(cid:13)
(cid:13)

2

H

,

(1)
where Exs∼s [·] denotes the expectation with regard to the
distribution s, and kφkH ≤ 1 deﬁnes a set of functions in the
unit ball of a RKHS H. Based on the statistical tests deﬁned
by MMD, we have MMD(s, t) = 0 iff s = t. Denote
by Ds = {xs
i=1 two sets of samples
drawn i.i.d. from the distributions s and t, respectively. An
empirical estimate of MMD can be given by [16],

i=1 and Dt = {xt

i }M

i}N

2
MMD

(Ds, Dt) =

1
M

M

X
i=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

φ(xs

i ) − 1
N

N

X
j=1

φ(xt
j)

,

(2)

2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

H

where φ(·) denotes the feature map associated with the ker-
nel map k(xs, xt) = hφ(xs), φ(xt)i. k(xs, xt) is usu-
ally deﬁned as the convex combination of L basis kernels

kl(xs, xt) [25],

L

Xl=1

k(xs, xt) =

βlkl(xs, xt), s.t.βl ≥ 0,

βl = 1.

(3)

L

Xl=1

Most existing domain adaptation methods [26, 29, 3, 41,
36] are based on the MMD deﬁned in Eqn. (2) and only
linear kernel is adopted for simplicity. Because the formu-
lation of MMD in Eqn. (2) is based on pairwise similar-
ity and is computed in quadratic time complexity, it is pro-
hibitively time-consuming and unsuitable for using mini-
batch stochastic gradient descent (SGD) in CNN-based do-
main adaptation methods. Gretton et al. [16] further sug-
gest an unbiased approximation to MMDl with linear com-
plexity. Without loss of generality, by assuming M = N ,
MMDl can then be computed as,

MMD2

l (s, t) =

hl(zi),

(4)

2
M

M/2

Xi=1

where hl is an operator deﬁned on a quad-tuple zi =
(xs

2i−1, xs

2i, xt

2j−1, xt

2j),

hl(zi) =k(xs

2i−1, xs

2i) + k(xt

− k(xs

2i−1, xt

2j ) − k(xs

2j−1, xt
2i, xt

2j )
2j−1).

(5)

The approximation in Eqn. (4) takes a summation form and
is suitable for gradient computation in a mini-batch man-
ner. Based on the work in [16], Long et al. [25] propose
deep adaptation networks and residual transfer networks for
UDA by introducing MMDl based adaptation layers into
deep CNNs. However, the existing MMD-based UDA ap-
proaches all assume that the source and target data have the
same class prior distributions, which does not always hold
in real-world applications, as illustrated in Fig. 1. Our em-
pirical experiments show that class weight bias can result in
performance degradation for MMD-based UDA.

2.2. Metrics for Domain Discrepancy

Besides MMD, there are several other metrics for mea-
suring domain discrepancy. Baktashmotlagh et al. [3] pro-
pose a distribution-matching embedding (DME) approach
for UDA, where both MMD and the Hellinger distance are
adopted to measure the discrepancy between the source
and target distributions.
Instead of embedding of distri-
butions, discriminative methods such as domain classiﬁca-
tion [11] and domain confusion [35] have also been intro-
duced to learn domain invariant representation. However,
class weight bias is also not yet considered in these meth-
ods.

Several sample reweighting or selection methods [13,
19] are similar to our weighted MMD in spirit, and have
been proposed to match the source and target distributions.

C

Xc=1
C

Xc=1

These methods aim to learn sample-speciﬁc weights or se-
lect appropriate source samples for target data. Different
from them, our proposed weighted MMD alleviates class
weight bias by assigning class-speciﬁc weights to source
data.

3. Weighted Maximum Mean Discrepancy

In this section, we will introduce the proposed weighted
MMD. Denote by ps(xs) and pt(xt) the probability density
functions of the source data xs and the target data xt, ys and
yt be the class labels of xs and xt, respectively. Actually,
both ps(xs) and pt(xt) can be further represented as the
mixtures of class conditional distributions,

pu(xu) =

pu(yu = c)pu(xu|yu = c)

=

wu

c pu(xu|yu = c), u ∈ {s, t},

(6)

c = ps(ys = c) and wt

where ws
c = pt(yt = c) denote the
class prior probability (i.e., class weights) of the source and
target samples, respectively, and C denotes the number of
classes.

c = wt

Note that, the difference between the class conditional
distributions ps(xs|ys = c) and pt(xt|yt = c) serves as
a proper metric of domain discrepancy. However, due to
the unavailability of class labels for target data in UDA, the
MMD between ps(xs) and pt(xt) is usually adopted as a
domain discrepancy metric. When ws
c (c = 1, 2, ...,
C), we argue that it is a suitable alternative. Unfortunately,
as shown in Fig. 1, the assumption ws
c generally does
not hold. For this case, MMD cannot cope with class weight
bias across domains. We propose to construct a reference
source distribution ps,α(xs) for comparing the discrepancy
between the source and target domains. Speciﬁcally, we
require that ps,α(xs) has the same class weights with the
target domain but owns the class conditional distributions
in source domain. Let αc = wt
c . In order to eliminate
c
the effect of class weight bias, we deﬁne ps,α(xs) as,

c = wt

ws

(cid:14)

C

ps,α(xs) =

αcws

c ps(xs|ys = c).

(7)

Xc=1
Denote by Ds = {(xs
i )}M
i , ys
i=1 the training set from source
domain and Dt = {xt
j}N
j=1 the test set from the target do-
main. Given the class weights of the target samples, the em-
pirical estimation of weighted MMD ps,α(xs) and pt(xt)
can be given by,

MMD

2
w(Ds, Dt) =

1
M
i=1 αys

i

M

X
i=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

P

αys
i

φ(xs

i ) − 1
N

N

X
j=1

φ(xt
j)

2

H

.

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(8)

Assuming M = N , the linear time complexity approxima-
tion of weighted MMD can then be computed as,

MMD2

l,w(Ds, Dt) =

hl,w(zi),

(9)

2
M

M/2

Xi=1

where hl,w(zi) is an operator deﬁned on a quad-tuple zi =
(xs

2i−1, xs

2i, xt

2j−1, xt

2j),

hl,w(zi) = αys
− αys

2i

2i−1 αys
2i−1 k(xs

k(xs
2i−1, xt

2i−1, xs

2i) + k(xt
k(xs

2i−1, xt
2i, xt

2i)
2j−1).

2j) − αys
2i

(10)

4. Weighted Domain Adaptation Network

By far, we have introduced our weighted MMD for mea-
suring domain discrepancy. But there are two remained is-
sues to be addressed. On one hand, the proposed weighted
MMD, similar to MMD, should be incorporated into some
classiﬁers for domain adaptation. On the other hand, the
class distribution on target domain is generally unknown
during training. In this section, we propose a weighted do-
main adaptation network (WDAN) model, which is in es-
sential an extension of the semi-supervised logistic regres-
sion [1] by adding the WMMD term and incorporating with
CNN. Meanwhile, we employ the CEM [6] framework and
show how we optimize the proposed WDAN without the
label information of the target samples.

First, based on the research in [40, 25], the features grad-
ually become task speciﬁc as the layers go toward the top
one, resulting in increasing dataset bias for the higher layers
of features. Therefore, to generalize CNN for domain adap-
tation, the weighted MMD-based regularizers are added to
the higher layers of CNN. Second, the relationship between
semi-supervised learning and domain adaptation has been
studied in [33]. To further exploit the unlabelled data on
target domain, we follow the semi-supervised CEM model
in [1], leading to the following WDAN model,

min
W,{ˆyj}N

j=1,α

ℓ(xs

i , ys

i ; W) + γ

ℓ(xt

j , ˆyt

j; W)

1
N

N

Xj=1

+ λ

MMDl,w(Dl

s, Dl

t),

(11)

1
M

M

Xi=1
l2

Xl=l1

where W denotes the model parameters to be learned, and
{ˆyj}N
j=1 represent the assigned labels of target samples. λ
and γ are two tradeoff parameters. Dl
t denote the
l-th layer features of the source and target domains, respec-
tively. ws
c is estimated based on the source data Dl
s, i.e.,
ws
c = Mc/M , where Mc is the number of samples of the
c-th class. The ﬁrst two terms of Eqn. (11) are the soft-max
loss items on the source and target samples, respectively.

s and Dl

And the third term is the weighted MMD regularizers for
the l1 ∼ l2-th layers deﬁned in Eqn. (8).

j}N

Next, we explain the optimization procedure of the pro-
posed WDAN model. Following the CEM algorithm in [6],
the WDAN model is optimized by alternating between:
(i) E-step: estimating the class posterior probability of
{xt
j=1, (ii) C-step: assigning pseudo-labels {ˆyj}N
j=1 and
estimating auxiliary weights α, (iii) M-step: updating the
model parameters W. Given the model parameters W,
for each xt
j , we ﬁrst estimate the class posterior probability
based on the output of softmax classiﬁer. The pseudo-label
to ˆyj is assigned to xt
j based on the maximum posterior
probability, and the auxiliary weights α are then estimated
based on pseudo-labels. Given {ˆyj}N
j=1 and α, the conven-
tional backpropagation algorithm is then deployed to update
W. In the following, we give more details on the E-step, C-
step, and M-step.

E-step: Fixed W, for each sample xt

j from target do-
main, the CNN output to the cth class is represented as
gc(xt
j ; W). Here we simply deﬁne the class posterior prob-
ability p(yt

j = c|xt

j) as,

p(yt

j = c|xt

j) = gc(xt

j; W).

C-step: With p(yt
j by,

to xt

j = c|xt

j), we assign pseudo-label ˆyj

ˆyj = arg max

p(yt

j = c|xt

j).

c

Let 1c(ˆyj) be an indicator function,

(12)

(13)

(14)

1c(ˆyj) =

1, if ˆyj = c
0, otherwise.

(cid:26)

1c(ˆyj)

The class weight ˆwt

c can be estimated by ˆwt

c =
N , where N is the number of target samples.
ws
c

j
P
Then the auxiliary weight can be updated with αc = ˆwt
c
.

.

(cid:14)

M-step: Fixed α, the subproblem on W can be formu-

lated as,

L(W) =

min
W

ℓ(xs

i , ys

i ; W) + γ

ℓ(xt

j, ˆyt

j; W)

1
N

N

Xj=1

+ λ

MMDl,w(Dl

s, Dl

t).

(15)

1
M

M

Xi=1
l2

Xl=l1

Since the gradients of the three terms in Eqn. (15) are com-
putable, W can be updated with mini-batch SGD. Let zi =
(xs
2i−1, xs
i= (zl
i,1 =
f s,l
2i−1, zl
2i−1, zl
2i ) be the l-th layer
feature representation of zi. Given zi, the gradient with re-
spect to the l-th layer parameter Wl can be written as,

2j ) be a quad-tuple and zl

2i, xt
i,2 = f s,l

2j−1, xt
2i , zl

i,4 = f t,l

i,3 = f t,l

∂L(W)
∂Wl =

1
2

2

∂ℓ(z

i,j, yi,j; W)
∂zl
i,j

∂zl
i,j
∂Wl

4

∂ℓ(z

+

γ
2

Xj=3

Xj=1
i,j , ˆyi,j; W)
∂zl
i,j

4

∂zl
i,j
∂Wl + λ

Xk=1

∂hl,w(zi)
∂zl

i,k

i,k

∂zl
∂Wl .
(16)

Taking k = 1 for example, ∂hl,w(zl
i)

can be computed as,

∂zl

i,1

∂hl,w(zi)
∂f s,l

2i−1

=αys

2i−1 αys

2i

2i−1, f s,l
∂k(f s,l
2i )
∂f s,l
∂k(f s,l
2i−1, f t,l
2i )
∂f s,l

2i−1

.

2i−1

− αys

2i−1

(17)

i,k

∂zl

can also be computed for other k

Similarly, ∂hl,w(zl
i)
values. Thus, the model parameters can be updated via
backpropagaton with a mini-batch of quad-tuple. More-
over, following [25, 17], the multiple kernel parameters β
can also be updated during training.

The algorithm described above actually is an extension
of classiﬁcation EM. The C-step in [6] only assigns pseudo-
label to each unlabeled sample, while in this work we fur-
ther estimate the auxiliary weights α with the pseudo-labels.
As shown in [6], such a optimization procedure can con-
verge to a stationary value. The experiment also empiri-
cally validate that our algorithm works well in estimating
the auxiliary weights α.

5. Experiments

In this section, we ﬁrst evaluate our proposed WDAN
on four widely used benchmarks in UDA, i.e., Ofﬁce-
10+Caltech-10 [14], Ofﬁce31 [31], ImageCLEF [5] and
Digit Recognition. Moreover, we also provide empirical
analysis to our proposed WDAN model from three as-
pects, i.e., hyper-parameter sensitivity, robustness to class
weight bias, and feature visualization.

Following the common setting in UDA, we implement
our WDAN model based on four widely used CNN archi-
tectures, i.e., LeNet [22], AlexNet [21], GoogLeNet [34]
and VGGnet-16 [32]. As suggested in [25], we train
our method based on pre-trained AlexNet, VGGNet-16,
or GoogLeNet on ImageNet, with the layers from conv1
to conv3 ﬁxed for AlexNet and inception layers from
inc1 to inc3 ﬁxed for GoogLeNet. The WDAN (LeNet)
In
is trained from the scratch (random initialization).
addition, the auxiliary weight is initialized with αc = 1
for each class. For l1 and l2, we follow the setting in [25].

Method
AlexNet [21]
LapCNN (AlexNet) [38]
DDC (AlexNet) [36]
DAN (AlexNet) [25]
WDAN (AlexNet)
WDAN⋆ (AlexNet)
GoogLeNet [34]
DDC (GoogLeNet) [36]
DAN (GoogLeNet) [25]
WDAN (GoogLeNet)
VGGnet-16 [32]
DAN (VGGnet-16) [25]
WDAN (VGGnet-16)

A→C
84.0±0.3
83.6±0.6
84.3±0.5
86.0±0.5
86.9±0.1
87.1±0.2
91.3±0.2
91.4±0.2
91.4±0.3
92.2±0.2
89.6±0.4
91.2±0.2
91.4±0.2

W→C
77.9±0.4
77.8±0.5
76.9±0.4
81.5±0.3
84.1±0.2
85.1±0.3
88.2±0.3
88.7±0.3
89.7±0.2
91.0±0.5
88.1±0.4
90.6±0.3
91.0±0.2

D→C
81.0±0.4
80.6±0.4
80.5±0.2
82.0±0.4
83.9±0.1
85.2±0.2
88.9±0.3
89.0±0.4
89.1±0.4
89.8±0.3
85.4±0.5
87.1±0.4
89.0±0.3

C→A
91.3±0.2
92.1±0.3
91.3±0.3
92.0±0.3
93.1±0.2
93.2±0.1
95.2±0.1
95.3±0.2
95.5±0.2
95.5±0.3
93.7±0.2
95.7±0.2
95.7±0.1

C→W
83.2±0.3
81.6±0.4
85.5±0.3
92.6±0.4
93.6±0.2
93.5±0.3
92.5±0.2
93.0±0.1
93.1±0.3
95.4±0.2
94.3±0.2
95.3±0.3
95.8±0.2

C→D
89.1±0.2
87.8±0.4
89.1±0.3
90.5±0.2
93.4±0.2
94.5±0.2
94.7±0.3
94.9±0.4
95.3±0.1
95.5±0.5
93.7±0.2
94.7±0.1
95.9±0.3

Avg.
84.0
83.9
84.6
87.3
89.2
89.8
91.8
92.1
92.3
93.2
90.8
92.4
93.1

Table 1. Results (in %) of different methods based on AlexNet, GoogleNet and VGGnet-16 on Ofﬁce-10+Caltech-10. Note that the results
of LapCNN, DDC and DAN are duplicated from [25]. ⋆ indicates that the ground truth class distributions in both source and target domain
are used as prior.

three fully connected layers for AlexNet,

Concretely, WMMD-based regularizers are added to the
the last
last
inception and fully connected layers for GoogleNet, and
the last fully connected layer for LeNet. All experiments
are implemented by using Caffe Toolbox [20], and run
on a PC equipped with a NVIDIA GTX 1080 GPU and
32G RAM. We set the batch size to 64 for all methods,
and optimize the learning rate for each model indepen-
dently. The tradeoff parameters λ and γ are optimized
in sets {0, 0.03, 0.07, 0.1, 0.4, 0.7, 1.4, 1.7, 2} and
{0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0}
The
by
source
at:
https://github.com/yhldhit/WMMD-Caffe.

respectively.
our WDAN is

cross-validation,

available

code

of

5.1. Comparison with State of the arts

For UDA, we employ the standard protocols as [25, 23,
27], where all the samples in source and target domain are
used for training. The averaged results over 10 trials on
target domain set are reported for comparison.

5.1.1 Ofﬁce-10+Caltech-10

Ofﬁce-10+Caltech-10 [14] is widely used for domain adap-
tation, which picks up 10 classes shared in Ofﬁce-31 [31]
and Caltech-256 [18].
It consists of four domains where
Amazon (A), Webcam (W) and DSLR (D) are from Ofﬁce-
31, and the another one is Caltech-256 (C). On this dataset,
we conduct experiments based on AlexNet, GoogLeNet and
VGGnet-16, and exploit the same setting as [25] for perfor-
mance comparison.

We compare our WDAN with several state-of-the-art
methods as listed in Table 1, including its MMD counter-

part DAN [25]. By AlexNet, GoogLeNet, and VGGnet-
16 we indicate to ﬁne-tune the pre-trained CNN models
for special tasks. LapCNN [38] can be seen as a variant
of CNN, which ﬁrst shows deep structure learning can be
improved by jointly learning an embedding with the unla-
beled data, and then exploits the embedding as a regularizer.
By embedding a single kernel MMD layer into CNN struc-
ture, DDC [36] develops a uniﬁed deep framework to jointly
learn semantically meaningful feature and perform adaption
cross domain.

Numerical results in Table 1 show that our weighted
DAN achieves the best performance, independently of the
employed CNN structure. Moreover, the WDAN is superior
to DAN by 1.9%, 0.9% and 0.7%, respectively. We con-
tribute this improvement to that our weighted MMD model
can alleviate the effect of class weight bias.
In addition,
the superiority over other state-of-the-art methods demon-
strate the effectiveness of the proposed WDAN. Finally, we
exploit the ground truth class distributions in both source
and target domains as prior of the proposed WDAN based
on AlexNet, which is indicated as WDAN⋆ (AlexNet) in
Table 1. Although WDAN⋆ can further improve the perfor-
mance of WDAN, the smaller gap between them than one
between weighted DAN and DAN validate the effectiveness
of our proposed learning and estimation method.

5.1.2 ImageCLEF

ImageCLEF [5] is developed for the ImageCLEF domain
adaptation task1. This dataset collects images from ﬁve
widely used image benchmarks, including Caltech256 [18],
ImageNet2012 [7] and
Bing, PASCAL VOC2012 [9],

1http://www.imageclef.org/2014/adaptation

Method

GoogLeNet
DDC [36]
DAN
WDAN

P→C

91.0±0.5
91.2±0.4
91.4±0.2
91.4±0.1

B→C

92.4±0.3
92.6±0.4
93.0±0.1
93.8±0.2

C→B

61.2±0.4
62.0±0.3
62.5±0.3
62.9±0.3

P→B

55.3±0.3
54.3±0.3
54.5±0.2
55.2±0.3

C→P

61.2±0.2
61.7±0.4
62.2±0.3
65.0±0.2

B→P

58.1±0.3
58.6±0.3
59.0±0.3
59.5±0.3

Avg.

69.9
70.1
70.4
71.3

Table 2. Results (in %) of different methods based on GoogLeNet
on ImageCLEF dataset.

Method

LeNet
SA [10]
DAN
WDAN

M→S
17.2±0.3
21.1±0.2
19.3±0.4
23.4±0.2

S→M
56.8±0.5
59.3±0.3
65.2±0.3
67.4±0.4

M→U
61.5±0.4
55.0±0.4
69.1±0.5
72.6±0.3

U→M
46.5±0.6
51.6±0.6
60.5±0.7
65.4±0.4

Avg

45.5
46.8
53.5
57.2

Table 3. Results (in %) of different methods based on LeNet on
Digit Classiﬁcation.

Method

A→W

D→W

W→D

A→D

D→A

W→A

Avg.

94.0±0.3
94.3±0.3
95.9±0.1

60.4±0.5
66.0±0.5
66.8±0.3

AlexNet
DAN
WDAN

66.7
70.0
72.1
Table 4. Results (in %) of different methods based on AlexNet on
Ofﬁce-31 dataset.

49.0±0.5
51.1±0.5
52.7±0.2

46.0±0.6
50.0±0.5
53.8±0.1

58.6±0.6
63.2±0.4
64.5±0.2

92.2±0.3
95.2±0.3
98.7±0.4

SUN [39]. This dataset is thought to be more difﬁcult, since
some domains contain low-quality images, making this
benchmark a good compliance to the Ofﬁce-10+Caltech-10,
where the domain is more similar. Different from the orig-
inal experimental setting, in this paper, we use a subset of
ImageCLEF, which contains three datasets, i.e., Caltech256
(C), Bing (B) and PASCAL VOC2012 (P). Meanwhile, we
exploit all images in each subset rather than follow the stan-
dard protocol to sample the same number of images for each
class. Such setting results in six domain adaptation tasks.

We compare WDAN with three related methods based
on GoogLeNet, i.e., GoogLeNet, DDC and DAN. We im-
plement them by using the codes released by authors2, and
try our best to optimize them. The results of the competing
methods are shown in Table 2, from which we can see that
our proposed weighted DAN obtains the best performance
in most of the cases, and achieves 1.4%, 1.2% and 0.9%
gains over GoogLeNet, DDC and DAN on average, respec-
tively. The above results show the proposed weighted MMD
is helpful to improve the performance of domain adaptation
task.

5.1.3 Digit Recognition

Furthermore, we conduct experiment on digit recognition,
which is usually adopted to domain adaptation. In this pa-
per, we only considering training images of three bench-
marks, i.e., MNIST (M), SVHN (S) and USPS (U) and con-
duct experiments on four tasks. As LeNet [22] is usually
used for digit recognition, we implement our WDAN and
the competing methods based on it. Among them, SA [10]
proposes a subspace alignment method for domain adap-
tation, which aims at learning a feature mapping to align

2https://github.com/longmingsheng/mmd-caffe

Figure 3. Performance (in %) of different methods w.r.t. λ.

source samples with target samples. For fair comparison,
we implement SA by using the features from the ﬁne-tuned
LeNet. The results reported in Table 3 clearly show that
our proposed WDAN achieves the best performance on all
tasks, and outperforms LeNet, SA and DAN by 11.7%,
10.4% and 3.7% on average, respectively. The signiﬁcant
improvements over competing methods show the proposed
weighted MMD model is effective and meaningful.

5.1.4 Ofﬁce-31

Finally, experiments are further conducted to assess WDAN
on datasets with more classes. We conduct experiments on
a dataset with 31 classes (i.e. Ofﬁce-31). There are three
domains, i.e., Amazon (A), Webcam (W) and DSLR (D),
In this part, we consider all the six UDA
in Ofﬁce-31.
tasks, and report the results using Alexnet. Table 4 shows
the results of AlexNet, DAN, and WDAN. It can be seen
that the proposed WMMD achieves better results than its
MMD counterpart, indicating that WMMD also works well
on dataset with more classes. To sum up, the promising
performance of our weighted MMD model can be veriﬁed
on various CNN architectures (i.e., AlexNet, GoogLeNet
and LeNet) and various datasets with different number of
classes.

5.2. Empirical Analysis

In this subsection, we perform empirical analysis of the
proposed WDAN from three aspects. Firstly, we evaluate
the effect of hyper-parameter λ on our proposed WDAN
model in Eqn. (11). Secondly, compared with its baselines,
i.e., Alexnet and DAN, we show our proposed WDAN is
robust to class weight bias. Finally, we make a visualization
of learned feature representations.

5.2.1 Effect of Parameter λ

The objective in Eqn. (11) of WDAN consists of three
i.e., conventional empirical losses on the source
terms,

and target domains, and MMD-based regularizer. Gener-
ally speaking, the empirical risk term keeps the learned
deep feature to be discriminative on source domain while
the MMD-based regularizer encourages domain invariant
feature representation. Both of this two aspects are of
essential importance for domain adaptation. The param-
eter λ in the objective Eqn. (11) makes a tradeoff be-
tween this two parts, and could greatly impact the per-
formance of domain adaptation. To have a closer look at
this parameter, we evaluate our proposed WDAN based on
AlexNet on the task W→C from Ofﬁce-10+Caltech-10 un-
der various λ. As suggested above, λ belongs to the set
{0.0, 0.03, 0.07, 0.1, 0.4, 0.7, 1, 1.4, 1.7, 2}. Meanwhile,
we also compared our WDAN model with DAN under var-
ious λ. AlexNet is reported as baseline and corresponds to
the case λ = 0. The results are illustrated in Fig. 3.

Obvious conclusions can be drawn from the results: (i)
our proposed WDAN consistently outperforms the DAN,
demonstrating that mining the class weight bias in MMD
is meaningful and beneﬁcial; (ii) WDAN and DAN achieve
the best results at λ = 0.4 and λ = 0.1, and outperforms the
baseline, i.e., AlexNet, when λ < 1.2 and λ < 1.0, respec-
tively, indicating that an appropriate balance is important
and necessary.

5.2.2 Impact of Class Weight Bias

To further clarify the impact of class weight bias on MMD-
based domain adaptation methods, we conduct experiments
on a variant of the task V→C from ImageCLEF based
on AlexNet. Speciﬁcally, we pick up two shared classes,
i.e., airplane and motorbike, in the source domain PASCAL
VOC2012 (V) and target domain Caltech256 (C), which
forms a two-class classiﬁcation problem.

Then we ﬁx the class weights as 0.5 for each class on
source domain and train different methods with gradually
changing the class distribution on target domain, which can
be interpreted as different level of the class weight bias
cross source and target domains. Fig. 4 show the results
of WDAN, DAN and AlexNet under different levels of the
class weighted bias. From it we can see that the class weight
bias has great inﬂuence on performance of MMD-based
domain adaptation methods. Moreover, the conventional
MMD-based methods (e.g., DAN) are limited in handling
the class weight bias, as its results signiﬁcantly degrade
with increasing class weighted bias. In addition, our pro-
posed WDAN is more robust to class weighted bias.

5.2.3 Feature Visualization

Following the work in [25], we visualize the features
learned by WDAN and DAN on target domain in the D→C
task from Ofﬁce-10+Caltech-10. For feature visualization,
we employ the t-SNE visualization method [37] whose

Figure 4. Performance (in %) of different methods w.r.t. class
weight bias.

Figure 5. The t-SNE visualization of learned features of different
methods.

source codes are provided3. The results of feature visualiza-
tion for DAN and weighted DAN are illustrated in Fig. 5 (a)
and Fig. 5 (b), respectively. As shown in the orange boxes of
Fig. 5, features learned by the proposed WDAN can reserve
more class discrepancy distance than ones learned by DAN.
The underlying reason lies in the fact that WDAN, by con-
sidering a weighted MMD regularizer, does not minimize
the class weight bias as DAN does, which also accounts for
that weighted DAN can outperform DAN on a variety of
unsupervised domain adaptation tasks.

6. Conclusion

In this paper, we focus on the uninvestigated issue of
class weight bias in UDA, which has adverse effect on
MMD-based domain adaptation methods. We ﬁrst propose
a novel weighted MMD to reduce the effect of class weight
bias by constructing a reference source distribution based
on target distribution. For UDA, we present a weighted
DAN (WDAN) based on the proposed weighted MMD, and
develop modiﬁed the CEM learning algorithm to jointly as-
sign pseudo-labels, estimate the auxiliary weights and learn
model parameters. Empirical results show that our proposed
WDAN outperforms its MMD counterpart, i.e., DAN, in
various domain adaptation tasks. In future, there remains
several issues to be investigated: (i) evaluation of weighted

3https://lvdmaaten.github.io/tsne/

MMD on non-CNN based UDA models, (ii) applications to
other tasks (e.g., image generation) based on measuring the
discrepancy between distributions.

7. Acknowledgment

This work is

supported in part by NSFC grant
(61671182, 61471082, and 61370163). The authors also
thank NVIDIA corporation for the donation of GTX 1080
GPU.

References

[1] M.-R. Amini and P. Gallinari. Semi-supervised logistic re-
gression. In Proceedings of the 15th European Conference
on Artiﬁcial Intelligence, pages 390–394. IOS Press, 2002.
2, 4

[2] H. Azizpour, A. Sharif Razavian, J. Sullivan, A. Maki, and
S. Carlsson. From generic to speciﬁc deep representations
for visual recognition. In Proceedings of the IEEE Confer-
ence on Computer Vision and Pattern Recognition, pages 36–
45, 2015. 1

[3] M. Baktashmotlagh, M. T. Harandi, and M. Salzmann.
Distribution-matching embedding for visual domain adapta-
tion. Journal of Machine Learning Research, 2016. 1, 3
[4] K. M. Borgwardt, A. Gretton, M. J. Rasch, H.-P. Kriegel,
B. Sch¨olkopf, and A. J. Smola. Integrating structured bio-
logical data by kernel maximum mean discrepancy. Bioin-
formatics, 22(14):e49–e57, 2006. 3

[5] B. Caputo and N. Patricia. Overview of the imageclef 2014
domain adaptation task. In ImageCLEF 2014: Overview and
analysis of the results, number EPFL-CONF-201812, 2014.
5, 6

[6] G. Celeux and G. Govaert. A classiﬁcation em algorithm
for clustering and two stochastic versions. Computational
statistics & Data analysis, 14(3):315–332, 1992. 4, 5

[7] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-
Imagenet: A large-scale hierarchical image database.
Fei.
In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, pages 248–255, 2009. 6

[8] J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang,
E. Tzeng, and T. Darrell. Decaf: A deep convolutional acti-
vation feature for generic visual recognition. In Proceedings
the International Conference on Machine Learning, pages
647–655, 2014. 1

[9] M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and
A. Zisserman. The pascal visual object classes (voc) chal-
lenge. International journal of computer vision, 88(2):303–
338, 2010. 6

[10] B. Fernando, A. Habrard, M. Sebban, and T. Tuytelaars. Un-
supervised visual domain adaptation using subspace align-
ment. In Proceedings of the IEEE International Conference
on Computer Vision, pages 2960–2967, 2013. 7

[11] Y. Ganin and V. Lempitsky. Unsupervised domain adaptation
by backpropagation. arXiv preprint arXiv:1409.7495, 2014.
3

[12] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich fea-
ture hierarchies for accurate object detection and semantic

In Proceedings of the IEEE Conference on
segmentation.
Computer Vision and Pattern Recognition, pages 580–587,
2014. 1

[13] B. Gong, K. Grauman, and F. Sha. Connecting the dots with
landmarks: Discriminatively learning domain-invariant fea-
In Proceedings
tures for unsupervised domain adaptation.
the International Conference on Machine Learning, pages
222–230, 2013. 3

[14] B. Gong, Y. Shi, F. Sha, and K. Grauman. Geodesic ﬂow
kernel for unsupervised domain adaptation. In Proceedings
of the IEEE Conference on Computer Vision and Pattern
Recognition, pages 2066–2073, 2012. 5, 6

[15] A. Gretton, K. M. Borgwardt, M. Rasch, B. Sch¨olkopf, and
A. J. Smola. A kernel method for the two-sample-problem.
In Advances in neural information processing systems, pages
513–520, 2006. 2

[16] A. Gretton, K. M. Borgwardt, M. J. Rasch, B. Sch¨olkopf, and
A. Smola. A kernel two-sample test. Journal of Machine
Learning Research, 2012. 3

[17] A. Gretton, D. Sejdinovic, H. Strathmann, S. Balakrishnan,
M. Pontil, K. Fukumizu, and B. K. Sriperumbudur. Optimal
kernel choice for large-scale two-sample tests. In Advances
in neural information processing systems, pages 1205–1213,
2012. 2, 5

[18] G. Grifﬁn, A. Holub, and P. Perona. Caltech-256 object cat-

egory dataset. 2007. 6

[19] J. Huang, A. Gretton, K. M. Borgwardt, B. Sch¨olkopf, and
A. J. Smola. Correcting sample selection bias by unlabeled
data. In Advances in neural information processing systems,
pages 601–608, 2006. 1, 3

[20] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Gir-
shick, S. Guadarrama, and T. Darrell. Caffe: Convolu-
tional architecture for fast feature embedding. arXiv preprint
arXiv:1408.5093, 2014. 6

[21] A. Krizhevsky, I. Sutskever, and G. E. Hinton.

Imagenet
classiﬁcation with deep convolutional neural networks.
In
Advances in neural information processing systems, pages
1097–1105, 2012. 1, 5, 6

[22] Y. Lecun, L. E. Bottou, Y. Bengio, and P. Haaner. Gradient-
based learning applied to document recognition. 1998. 5,
7

[23] Y. Li, K. Swersky, and R. Zemel. Generative moment match-
ing networks. In Proceedings the International Conference
on Machine Learning, pages 1718–1727, 2015. 6

[24] J. Long, E. Shelhamer, and T. Darrell. Fully convolutional
networks for semantic segmentation. In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 3431–3440, 2015. 1

[25] M. Long and J. Wang. Learning transferable features with
deep adaptation networks. CoRR, abs/1502.02791, 1:2,
2015. 3, 4, 5, 6, 8

[26] M. Long, J. Wang, G. Ding, J. Sun, and P. S. Yu. Transfer
In Pro-
feature learning with joint distribution adaptation.
ceedings of the IEEE International Conference on Computer
Vision, pages 2200–2207, 2013. 1, 3

[27] M. Long, J. Wang, and M. I. Jordan. Unsupervised domain
adaptation with residual transfer networks. arXiv preprint
arXiv:1602.04433, 2016. 6

[28] T. Ming Harry Hsu, W. Yu Chen, C.-A. Hou, Y.-H. Hu-
bert Tsai, Y.-R. Yeh, and Y.-C. Frank Wang. Unsupervised
domain adaptation with imbalanced cross-domain data.
In
Proceedings of the IEEE International Conference on Com-
puter Vision, pages 4121–4129, 2015. 1, 2

[29] S. J. Pan, I. W. Tsang, J. T. Kwok, and Q. Yang. Domain
adaptation via transfer component analysis. IEEE Transac-
tions on Neural Networks, 22(2):199–210, 2011. 1, 3
[30] S. J. Pan and Q. Yang. A survey on transfer learning.
IEEE Transactions on knowledge and data engineering,
22(10):1345–1359, 2010. 1

[31] K. Saenko, B. Kulis, M. Fritz, and T. Darrell. Adapting vi-
sual category models to new domains. In European confer-
ence on computer vision, pages 213–226. Springer, 2010. 5,
6

[32] K. Simonyan and A. Zisserman. Very deep convolutional
networks for large-scale image recognition. arXiv preprint
arXiv:1409.1556, 2014. 5, 6

[33] A. Søgaard. Semi-supervised learning and domain adapta-
tion in natural language processing. Synthesis Lectures on
Human Language Technologies, 6(2):1–103, 2013. 4
[34] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed,
D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich.
Going deeper with convolutions. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition,
pages 1–9, 2015. 5, 6

[35] E. Tzeng, J. Hoffman, T. Darrell, and K. Saenko. Simultane-
ous deep transfer across domains and tasks. In Proceedings
of the IEEE International Conference on Computer Vision,
pages 4068–4076, 2015. 3

[36] E. Tzeng, J. Hoffman, N. Zhang, K. Saenko, and T. Darrell.
Deep domain confusion: Maximizing for domain invariance.
arXiv preprint arXiv:1412.3474, 2014. 1, 3, 6, 7

[37] L. Van Der Maaten. Accelerating t-sne using tree-based al-
gorithms. Journal of machine learning research, 2014. 8
[38] J. Weston, F. Ratle, H. Mobahi, and R. Collobert. Deep learn-
In Neural Networks:

ing via semi-supervised embedding.
Tricks of the Trade, pages 639–655. Springer, 2012. 6
[39] J. Xiao, J. Hays, K. A. Ehinger, A. Oliva, and A. Torralba.
Sun database: Large-scale scene recognition from abbey to
zoo. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, pages 3485–3492, 2010. 7
[40] J. Yosinski, J. Clune, Y. Bengio, and H. Lipson. How trans-
ferable are features in deep neural networks? In Advances
in neural information processing systems, pages 3320–3328,
2014. 1, 4

[41] E. Zhong, W. Fan, J. Peng, K. Zhang, J. Ren, D. Turaga,
and O. Verscheure. Cross domain distribution adaptation via
kernel mapping. In Proceedings of the 15th ACM SIGKDD
international conference on Knowledge discovery and data
mining, pages 1027–1036, 2009. 1, 3

7
1
0
2
 
y
a
M
 
1
 
 
]

V
C
.
s
c
[
 
 
1
v
9
0
6
0
0
.
5
0
7
1
:
v
i
X
r
a

Mind the Class Weight Bias: Weighted Maximum Mean Discrepancy
for Unsupervised Domain Adaptation

Hongliang Yan1, Yukang Ding1, Peihua Li2, Qilong Wang2, Yong Xu3, Wangmeng Zuo1,∗
1School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China
2School of Information and Communication Engineering, Dalian University of Technology, Dalian, China
3Bio-Computing Research Center, Shenzhen Graduate School, Harbin Institute of Technology, Shenzhen, China
yanhl@hit.edu.cn, dingyukang921@163.com, peihuali@dlut.edu.cn,

qlwang@mail.dlut.edu.cn, laterfall@hitsz.edu.cn, wmzuo@hit.edu.cn

 

MNIST
USPS
SVHN

0.2

0.16

t
h
g
i
e
w

0.12

0.08

0.04

 

Abstract

In domain adaptation, maximum mean discrepancy
(MMD) has been widely adopted as a discrepancy met-
ric between the distributions of source and target domains.
However, existing MMD-based domain adaptation methods
generally ignore the changes of class prior distributions,
i.e., class weight bias across domains. This remains an
open problem but ubiquitous for domain adaptation, which
can be caused by changes in sample selection criteria and
application scenarios. We show that MMD cannot account
for class weight bias and results in degraded domain adap-
tation performance. To address this issue, a weighted MMD
model is proposed in this paper. Speciﬁcally, we introduce
class-speciﬁc auxiliary weights into the original MMD for
exploiting the class prior probability on source and target
domains, whose challenge lies in the fact that the class label
in target domain is unavailable. To account for it, our pro-
posed weighted MMD model is deﬁned by introducing an
auxiliary weight for each class in the source domain, and
a classiﬁcation EM algorithm is suggested by alternating
between assigning the pseudo-labels, estimating auxiliary
weights and updating model parameters. Extensive exper-
iments demonstrate the superiority of our weighted MMD
over conventional MMD for domain adaptation.

1. Introduction

Deep convolutional neural networks (CNNs) have
achieved great success in various computer vision tasks
such as image classiﬁcation [21], object detection [12] and
semantic segmentation [24]. Besides the inspiring progress
in model and learning, the achievement of CNN is un-
doubtedly attributed to the availability of massive labeled

∗Corresponding author.

0

1

2

3

6

7

8

9

4

5

class

Figure 1. Class prior distributions of three domains for digit recog-
nition. As is shown, class bias exists across domains. It is natural
to see that the class weight of 0 and 1 are relatively high in postal
service (USPS), and the class weight of 1 and 2 are relatively high
in house numbers (SVHN).

datasets. For a CNN trained on large scale datasets [8],
while the lower layers of features are safely transferable, the
learned features gradually moves from general to speciﬁc
along the network [40]. When the source and target tasks
are signiﬁcantly diverse, the CNN pretrained on the source
task may not generalize well to the target task. Such sce-
nario leads to an emerging topic to transfer the CNN from
the source task to the target task with the enhanced and dis-
criminative representation [2]. In this work, we study a spe-
cial type of transfer learning task, i.e., domain adaptation
(DA) [30].

One of the most fruitful lines for DA is MMD-based
method [26, 29, 3, 41, 36]. Despite the great success
achieved, existing ones generally ignore the changes of
class prior distributions, dubbed by class weight bias.
It
is ubiquitous for domain adaptation and can be caused by
changes in sample selection criteria [19] and application
scenarios [28]. As shown in Fig. 1, the class prior dis-
tributions (i.e., class weights) vary with domains for digit
recognition. Moreover, a special case of class weight bias

Figure 2. Results of minimizing MMD and WMMD regularizer under class weight bias are illustrated in (a) and (b), respectively. Mini-
mizing MMD preserves the class weights in source domain and thus the target samples will be wrongly estimated, as indicated by yellow
samples. On the contrary, the proposed weighted MMD removes the effect of class bias by ﬁrst reweighting source data.

is the imbalanced cross-domain data problem [28] where
several classes in source domain do not appear in tar-
get domain, as shown in Fig. 2. The Closest Common
Space Learning (CCSL) method in [28] is suggested for
imbalanced and multiple cross-domain visual classiﬁca-
tion. However, CCSL just combines conventional MMD
with domain-dependent MMD without explicitly consider-
ing class weight bias.

For MMD-based methods, the ignorance of class weight
bias can deteriorate the domain adaptation performance. In
the case of class weight bias, the MMD can be minimized
by either learning domain-invariant representation or pre-
serving the class weights in source domain. As illustrated
in Fig. 2 (a), it is unreasonable for domain adaptation to re-
quire that the class weights in target domain should keep
the same as those in source domain. Our empirical exper-
iments also reveal the limitation of MMD in coping with
class weight bias (See Fig. 4).

In this paper, we propose a weighted MMD (WMMD)
method to address the issue of class weight bias. As for
DA, the challenge is that the class labels in target domain
are unknown. So we ﬁrst introduce class-speciﬁc auxil-
iary weights to reweight the source samples. In this way,
the reweighted source data are expected to share the same
class weights with target data. The auxiliary weights es-
timation and model parameters learning are jointly opti-
mized by minimizing the objective function of weighted
MMD. Different from MMD, the objective function based
on our weighted MMD involves additional weight parame-
ters, and we present a classiﬁcation EM (CEM) scheme to
estimate it. Inspired by the semi-supervised logistic regres-
sion in [1], we propose a weighted Domain Adapation Net-
work (WDAN) by both incorporating the weighted MMD

into CNN and taking into account the empirical loss on tar-
get samples. The CEM algorithm are developed for learning
WDAN in three steps, i.e., E-step, C-step, and M-step. In
the E-step and the C-step, we calculate the class posterior
probability, assign the pseudo-labels to the target samples,
and estimate the auxiliary weight.
In the M-step, model
parameters are updated by minimizing the objective loss.
Experimental results show our weighted MMD can learn
better domain-invariant representation for domain adapta-
tion. Moreover, the models based on weighted MMD also
outperforms the MMD-based counterparts. In summary, the
main contributions of this work are three-fold:

1. A weighted MMD model is proposed to alleviate the
effect of class weight bias in domain adaptation. By
taking class prior distributions into account, weighted
MMD can provide a better metric for domain discrep-
ancy.

2. Using unbiased estimate of multi-kernel MMD [15,
17], our proposed weighted MMD can be computed as
mean embedding matching with linear time complex-
ity and be incorporated into CNN for unsupervised do-
main adaptation. We further develop a CEM algorithm
for training the weighted MMD model.

3. Experiments demonstrate that weighted MMD outper-
forms MMD for domain adaptation. The superiority of
weighted MMD over MMD has been veriﬁed on vari-
ous CNN architectures and different datasets.

In the remainder of this paper, we begin with a brief
introduction to the preliminaries and related work in Sec-
tion 2.
In Section 3, by considering class weight bias,
we propose weighted MMD on the basis of conventional

MMD. After that, in Section 4, we apply weighted MMD
to unsupervised domain adaptation and present a model
named WDAN. Extensive experimental results are given
in Section 5 to verify the effectiveness of our proposed
weighted MMD model and detailed empirical analysis to
our proposed model is provided. Finally, we conclude this
work in Section 6.

2. Preliminaries and Related Work

In this section, we ﬁrst review MMD and its application
in domain adaptation, and then survey several other meth-
ods used to measure domain discrepancy.

2.1. MMD and Its Application in Domain Adapta 

tion

Domain adaptation aims at adapting the discriminative
model learned on source domain into target domain. De-
pending on the accessibility of class labels for target sam-
ples during training, research lines can be grouped into three
categories: supervised, semi-supervised, and unsupervised
domain adaptation.
In this paper, we focus on learning
transferable CNN features for unsupervised domain adap-
tation (UDA), where the labels of all target samples are un-
known during training. Compared with the other settings,
UDA is more ubiquitous in real-world applications.

Due to the unavailability of labels in the target domain,
one commonly used strategy of UDA is to learn domain in-
variant representation via minimizing the domain distribu-
tion discrepancy. Maximum Mean Discrepancy (MMD) is
an effective non-parametric metric for comparing the distri-
butions based on two sets of data [4]. Given two distribu-
tions s and t, by mapping the data to a reproducing kernel
Hilbert space (RKHS) using function φ(·), the MMD be-
tween s and t is deﬁned as,

2

MMD

(s, t) = sup

kφkH≤1 (cid:13)
(cid:13)

Exs∼s [φ(xs)] − Ext∼t (cid:2)φ(xt)(cid:3)(cid:13)
(cid:13)

2

H

,

(1)
where Exs∼s [·] denotes the expectation with regard to the
distribution s, and kφkH ≤ 1 deﬁnes a set of functions in the
unit ball of a RKHS H. Based on the statistical tests deﬁned
by MMD, we have MMD(s, t) = 0 iff s = t. Denote
by Ds = {xs
i=1 two sets of samples
drawn i.i.d. from the distributions s and t, respectively. An
empirical estimate of MMD can be given by [16],

i=1 and Dt = {xt

i }M

i}N

2
MMD

(Ds, Dt) =

1
M

M

X
i=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

φ(xs

i ) − 1
N

N

X
j=1

φ(xt
j)

,

(2)

2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

H

where φ(·) denotes the feature map associated with the ker-
nel map k(xs, xt) = hφ(xs), φ(xt)i. k(xs, xt) is usu-
ally deﬁned as the convex combination of L basis kernels

kl(xs, xt) [25],

L

Xl=1

k(xs, xt) =

βlkl(xs, xt), s.t.βl ≥ 0,

βl = 1.

(3)

L

Xl=1

Most existing domain adaptation methods [26, 29, 3, 41,
36] are based on the MMD deﬁned in Eqn. (2) and only
linear kernel is adopted for simplicity. Because the formu-
lation of MMD in Eqn. (2) is based on pairwise similar-
ity and is computed in quadratic time complexity, it is pro-
hibitively time-consuming and unsuitable for using mini-
batch stochastic gradient descent (SGD) in CNN-based do-
main adaptation methods. Gretton et al. [16] further sug-
gest an unbiased approximation to MMDl with linear com-
plexity. Without loss of generality, by assuming M = N ,
MMDl can then be computed as,

MMD2

l (s, t) =

hl(zi),

(4)

2
M

M/2

Xi=1

where hl is an operator deﬁned on a quad-tuple zi =
(xs

2i−1, xs

2i, xt

2j−1, xt

2j),

hl(zi) =k(xs

2i−1, xs

2i) + k(xt

− k(xs

2i−1, xt

2j ) − k(xs

2j−1, xt
2i, xt

2j )
2j−1).

(5)

The approximation in Eqn. (4) takes a summation form and
is suitable for gradient computation in a mini-batch man-
ner. Based on the work in [16], Long et al. [25] propose
deep adaptation networks and residual transfer networks for
UDA by introducing MMDl based adaptation layers into
deep CNNs. However, the existing MMD-based UDA ap-
proaches all assume that the source and target data have the
same class prior distributions, which does not always hold
in real-world applications, as illustrated in Fig. 1. Our em-
pirical experiments show that class weight bias can result in
performance degradation for MMD-based UDA.

2.2. Metrics for Domain Discrepancy

Besides MMD, there are several other metrics for mea-
suring domain discrepancy. Baktashmotlagh et al. [3] pro-
pose a distribution-matching embedding (DME) approach
for UDA, where both MMD and the Hellinger distance are
adopted to measure the discrepancy between the source
and target distributions.
Instead of embedding of distri-
butions, discriminative methods such as domain classiﬁca-
tion [11] and domain confusion [35] have also been intro-
duced to learn domain invariant representation. However,
class weight bias is also not yet considered in these meth-
ods.

Several sample reweighting or selection methods [13,
19] are similar to our weighted MMD in spirit, and have
been proposed to match the source and target distributions.

C

Xc=1
C

Xc=1

These methods aim to learn sample-speciﬁc weights or se-
lect appropriate source samples for target data. Different
from them, our proposed weighted MMD alleviates class
weight bias by assigning class-speciﬁc weights to source
data.

3. Weighted Maximum Mean Discrepancy

In this section, we will introduce the proposed weighted
MMD. Denote by ps(xs) and pt(xt) the probability density
functions of the source data xs and the target data xt, ys and
yt be the class labels of xs and xt, respectively. Actually,
both ps(xs) and pt(xt) can be further represented as the
mixtures of class conditional distributions,

pu(xu) =

pu(yu = c)pu(xu|yu = c)

=

wu

c pu(xu|yu = c), u ∈ {s, t},

(6)

c = ps(ys = c) and wt

where ws
c = pt(yt = c) denote the
class prior probability (i.e., class weights) of the source and
target samples, respectively, and C denotes the number of
classes.

c = wt

Note that, the difference between the class conditional
distributions ps(xs|ys = c) and pt(xt|yt = c) serves as
a proper metric of domain discrepancy. However, due to
the unavailability of class labels for target data in UDA, the
MMD between ps(xs) and pt(xt) is usually adopted as a
domain discrepancy metric. When ws
c (c = 1, 2, ...,
C), we argue that it is a suitable alternative. Unfortunately,
as shown in Fig. 1, the assumption ws
c generally does
not hold. For this case, MMD cannot cope with class weight
bias across domains. We propose to construct a reference
source distribution ps,α(xs) for comparing the discrepancy
between the source and target domains. Speciﬁcally, we
require that ps,α(xs) has the same class weights with the
target domain but owns the class conditional distributions
in source domain. Let αc = wt
c . In order to eliminate
c
the effect of class weight bias, we deﬁne ps,α(xs) as,

c = wt

ws

(cid:14)

C

ps,α(xs) =

αcws

c ps(xs|ys = c).

(7)

Xc=1
Denote by Ds = {(xs
i )}M
i , ys
i=1 the training set from source
domain and Dt = {xt
j}N
j=1 the test set from the target do-
main. Given the class weights of the target samples, the em-
pirical estimation of weighted MMD ps,α(xs) and pt(xt)
can be given by,

MMD

2
w(Ds, Dt) =

1
M
i=1 αys

i

M

X
i=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

P

αys
i

φ(xs

i ) − 1
N

N

X
j=1

φ(xt
j)

2

H

.

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(8)

Assuming M = N , the linear time complexity approxima-
tion of weighted MMD can then be computed as,

MMD2

l,w(Ds, Dt) =

hl,w(zi),

(9)

2
M

M/2

Xi=1

where hl,w(zi) is an operator deﬁned on a quad-tuple zi =
(xs

2i−1, xs

2i, xt

2j−1, xt

2j),

hl,w(zi) = αys
− αys

2i

2i−1 αys
2i−1 k(xs

k(xs
2i−1, xt

2i−1, xs

2i) + k(xt
k(xs

2i−1, xt
2i, xt

2i)
2j−1).

2j) − αys
2i

(10)

4. Weighted Domain Adaptation Network

By far, we have introduced our weighted MMD for mea-
suring domain discrepancy. But there are two remained is-
sues to be addressed. On one hand, the proposed weighted
MMD, similar to MMD, should be incorporated into some
classiﬁers for domain adaptation. On the other hand, the
class distribution on target domain is generally unknown
during training. In this section, we propose a weighted do-
main adaptation network (WDAN) model, which is in es-
sential an extension of the semi-supervised logistic regres-
sion [1] by adding the WMMD term and incorporating with
CNN. Meanwhile, we employ the CEM [6] framework and
show how we optimize the proposed WDAN without the
label information of the target samples.

First, based on the research in [40, 25], the features grad-
ually become task speciﬁc as the layers go toward the top
one, resulting in increasing dataset bias for the higher layers
of features. Therefore, to generalize CNN for domain adap-
tation, the weighted MMD-based regularizers are added to
the higher layers of CNN. Second, the relationship between
semi-supervised learning and domain adaptation has been
studied in [33]. To further exploit the unlabelled data on
target domain, we follow the semi-supervised CEM model
in [1], leading to the following WDAN model,

min
W,{ˆyj}N

j=1,α

ℓ(xs

i , ys

i ; W) + γ

ℓ(xt

j , ˆyt

j; W)

1
N

N

Xj=1

+ λ

MMDl,w(Dl

s, Dl

t),

(11)

1
M

M

Xi=1
l2

Xl=l1

where W denotes the model parameters to be learned, and
{ˆyj}N
j=1 represent the assigned labels of target samples. λ
and γ are two tradeoff parameters. Dl
t denote the
l-th layer features of the source and target domains, respec-
tively. ws
c is estimated based on the source data Dl
s, i.e.,
ws
c = Mc/M , where Mc is the number of samples of the
c-th class. The ﬁrst two terms of Eqn. (11) are the soft-max
loss items on the source and target samples, respectively.

s and Dl

And the third term is the weighted MMD regularizers for
the l1 ∼ l2-th layers deﬁned in Eqn. (8).

j}N

Next, we explain the optimization procedure of the pro-
posed WDAN model. Following the CEM algorithm in [6],
the WDAN model is optimized by alternating between:
(i) E-step: estimating the class posterior probability of
{xt
j=1, (ii) C-step: assigning pseudo-labels {ˆyj}N
j=1 and
estimating auxiliary weights α, (iii) M-step: updating the
model parameters W. Given the model parameters W,
for each xt
j , we ﬁrst estimate the class posterior probability
based on the output of softmax classiﬁer. The pseudo-label
to ˆyj is assigned to xt
j based on the maximum posterior
probability, and the auxiliary weights α are then estimated
based on pseudo-labels. Given {ˆyj}N
j=1 and α, the conven-
tional backpropagation algorithm is then deployed to update
W. In the following, we give more details on the E-step, C-
step, and M-step.

E-step: Fixed W, for each sample xt

j from target do-
main, the CNN output to the cth class is represented as
gc(xt
j ; W). Here we simply deﬁne the class posterior prob-
ability p(yt

j = c|xt

j) as,

p(yt

j = c|xt

j) = gc(xt

j; W).

C-step: With p(yt
j by,

to xt

j = c|xt

j), we assign pseudo-label ˆyj

ˆyj = arg max

p(yt

j = c|xt

j).

c

Let 1c(ˆyj) be an indicator function,

(12)

(13)

(14)

1c(ˆyj) =

1, if ˆyj = c
0, otherwise.

(cid:26)

1c(ˆyj)

The class weight ˆwt

c can be estimated by ˆwt

c =
N , where N is the number of target samples.
ws
c

j
P
Then the auxiliary weight can be updated with αc = ˆwt
c
.

.

(cid:14)

M-step: Fixed α, the subproblem on W can be formu-

lated as,

L(W) =

min
W

ℓ(xs

i , ys

i ; W) + γ

ℓ(xt

j, ˆyt

j; W)

1
N

N

Xj=1

+ λ

MMDl,w(Dl

s, Dl

t).

(15)

1
M

M

Xi=1
l2

Xl=l1

Since the gradients of the three terms in Eqn. (15) are com-
putable, W can be updated with mini-batch SGD. Let zi =
(xs
2i−1, xs
i= (zl
i,1 =
f s,l
2i−1, zl
2i−1, zl
2i ) be the l-th layer
feature representation of zi. Given zi, the gradient with re-
spect to the l-th layer parameter Wl can be written as,

2j ) be a quad-tuple and zl

2i, xt
i,2 = f s,l

2j−1, xt
2i , zl

i,4 = f t,l

i,3 = f t,l

∂L(W)
∂Wl =

1
2

2

∂ℓ(z

i,j, yi,j; W)
∂zl
i,j

∂zl
i,j
∂Wl

4

∂ℓ(z

+

γ
2

Xj=3

Xj=1
i,j , ˆyi,j; W)
∂zl
i,j

4

∂zl
i,j
∂Wl + λ

Xk=1

∂hl,w(zi)
∂zl

i,k

i,k

∂zl
∂Wl .
(16)

Taking k = 1 for example, ∂hl,w(zl
i)

can be computed as,

∂zl

i,1

∂hl,w(zi)
∂f s,l

2i−1

=αys

2i−1 αys

2i

2i−1, f s,l
∂k(f s,l
2i )
∂f s,l
∂k(f s,l
2i−1, f t,l
2i )
∂f s,l

2i−1

.

2i−1

− αys

2i−1

(17)

i,k

∂zl

can also be computed for other k

Similarly, ∂hl,w(zl
i)
values. Thus, the model parameters can be updated via
backpropagaton with a mini-batch of quad-tuple. More-
over, following [25, 17], the multiple kernel parameters β
can also be updated during training.

The algorithm described above actually is an extension
of classiﬁcation EM. The C-step in [6] only assigns pseudo-
label to each unlabeled sample, while in this work we fur-
ther estimate the auxiliary weights α with the pseudo-labels.
As shown in [6], such a optimization procedure can con-
verge to a stationary value. The experiment also empiri-
cally validate that our algorithm works well in estimating
the auxiliary weights α.

5. Experiments

In this section, we ﬁrst evaluate our proposed WDAN
on four widely used benchmarks in UDA, i.e., Ofﬁce-
10+Caltech-10 [14], Ofﬁce31 [31], ImageCLEF [5] and
Digit Recognition. Moreover, we also provide empirical
analysis to our proposed WDAN model from three as-
pects, i.e., hyper-parameter sensitivity, robustness to class
weight bias, and feature visualization.

Following the common setting in UDA, we implement
our WDAN model based on four widely used CNN archi-
tectures, i.e., LeNet [22], AlexNet [21], GoogLeNet [34]
and VGGnet-16 [32]. As suggested in [25], we train
our method based on pre-trained AlexNet, VGGNet-16,
or GoogLeNet on ImageNet, with the layers from conv1
to conv3 ﬁxed for AlexNet and inception layers from
inc1 to inc3 ﬁxed for GoogLeNet. The WDAN (LeNet)
In
is trained from the scratch (random initialization).
addition, the auxiliary weight is initialized with αc = 1
for each class. For l1 and l2, we follow the setting in [25].

Method
AlexNet [21]
LapCNN (AlexNet) [38]
DDC (AlexNet) [36]
DAN (AlexNet) [25]
WDAN (AlexNet)
WDAN⋆ (AlexNet)
GoogLeNet [34]
DDC (GoogLeNet) [36]
DAN (GoogLeNet) [25]
WDAN (GoogLeNet)
VGGnet-16 [32]
DAN (VGGnet-16) [25]
WDAN (VGGnet-16)

A→C
84.0±0.3
83.6±0.6
84.3±0.5
86.0±0.5
86.9±0.1
87.1±0.2
91.3±0.2
91.4±0.2
91.4±0.3
92.2±0.2
89.6±0.4
91.2±0.2
91.4±0.2

W→C
77.9±0.4
77.8±0.5
76.9±0.4
81.5±0.3
84.1±0.2
85.1±0.3
88.2±0.3
88.7±0.3
89.7±0.2
91.0±0.5
88.1±0.4
90.6±0.3
91.0±0.2

D→C
81.0±0.4
80.6±0.4
80.5±0.2
82.0±0.4
83.9±0.1
85.2±0.2
88.9±0.3
89.0±0.4
89.1±0.4
89.8±0.3
85.4±0.5
87.1±0.4
89.0±0.3

C→A
91.3±0.2
92.1±0.3
91.3±0.3
92.0±0.3
93.1±0.2
93.2±0.1
95.2±0.1
95.3±0.2
95.5±0.2
95.5±0.3
93.7±0.2
95.7±0.2
95.7±0.1

C→W
83.2±0.3
81.6±0.4
85.5±0.3
92.6±0.4
93.6±0.2
93.5±0.3
92.5±0.2
93.0±0.1
93.1±0.3
95.4±0.2
94.3±0.2
95.3±0.3
95.8±0.2

C→D
89.1±0.2
87.8±0.4
89.1±0.3
90.5±0.2
93.4±0.2
94.5±0.2
94.7±0.3
94.9±0.4
95.3±0.1
95.5±0.5
93.7±0.2
94.7±0.1
95.9±0.3

Avg.
84.0
83.9
84.6
87.3
89.2
89.8
91.8
92.1
92.3
93.2
90.8
92.4
93.1

Table 1. Results (in %) of different methods based on AlexNet, GoogleNet and VGGnet-16 on Ofﬁce-10+Caltech-10. Note that the results
of LapCNN, DDC and DAN are duplicated from [25]. ⋆ indicates that the ground truth class distributions in both source and target domain
are used as prior.

three fully connected layers for AlexNet,

Concretely, WMMD-based regularizers are added to the
the last
last
inception and fully connected layers for GoogleNet, and
the last fully connected layer for LeNet. All experiments
are implemented by using Caffe Toolbox [20], and run
on a PC equipped with a NVIDIA GTX 1080 GPU and
32G RAM. We set the batch size to 64 for all methods,
and optimize the learning rate for each model indepen-
dently. The tradeoff parameters λ and γ are optimized
in sets {0, 0.03, 0.07, 0.1, 0.4, 0.7, 1.4, 1.7, 2} and
{0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0}
The
by
source
at:
https://github.com/yhldhit/WMMD-Caffe.

respectively.
our WDAN is

cross-validation,

available

code

of

5.1. Comparison with State of the arts

For UDA, we employ the standard protocols as [25, 23,
27], where all the samples in source and target domain are
used for training. The averaged results over 10 trials on
target domain set are reported for comparison.

5.1.1 Ofﬁce-10+Caltech-10

Ofﬁce-10+Caltech-10 [14] is widely used for domain adap-
tation, which picks up 10 classes shared in Ofﬁce-31 [31]
and Caltech-256 [18].
It consists of four domains where
Amazon (A), Webcam (W) and DSLR (D) are from Ofﬁce-
31, and the another one is Caltech-256 (C). On this dataset,
we conduct experiments based on AlexNet, GoogLeNet and
VGGnet-16, and exploit the same setting as [25] for perfor-
mance comparison.

We compare our WDAN with several state-of-the-art
methods as listed in Table 1, including its MMD counter-

part DAN [25]. By AlexNet, GoogLeNet, and VGGnet-
16 we indicate to ﬁne-tune the pre-trained CNN models
for special tasks. LapCNN [38] can be seen as a variant
of CNN, which ﬁrst shows deep structure learning can be
improved by jointly learning an embedding with the unla-
beled data, and then exploits the embedding as a regularizer.
By embedding a single kernel MMD layer into CNN struc-
ture, DDC [36] develops a uniﬁed deep framework to jointly
learn semantically meaningful feature and perform adaption
cross domain.

Numerical results in Table 1 show that our weighted
DAN achieves the best performance, independently of the
employed CNN structure. Moreover, the WDAN is superior
to DAN by 1.9%, 0.9% and 0.7%, respectively. We con-
tribute this improvement to that our weighted MMD model
can alleviate the effect of class weight bias.
In addition,
the superiority over other state-of-the-art methods demon-
strate the effectiveness of the proposed WDAN. Finally, we
exploit the ground truth class distributions in both source
and target domains as prior of the proposed WDAN based
on AlexNet, which is indicated as WDAN⋆ (AlexNet) in
Table 1. Although WDAN⋆ can further improve the perfor-
mance of WDAN, the smaller gap between them than one
between weighted DAN and DAN validate the effectiveness
of our proposed learning and estimation method.

5.1.2 ImageCLEF

ImageCLEF [5] is developed for the ImageCLEF domain
adaptation task1. This dataset collects images from ﬁve
widely used image benchmarks, including Caltech256 [18],
ImageNet2012 [7] and
Bing, PASCAL VOC2012 [9],

1http://www.imageclef.org/2014/adaptation

Method

GoogLeNet
DDC [36]
DAN
WDAN

P→C

91.0±0.5
91.2±0.4
91.4±0.2
91.4±0.1

B→C

92.4±0.3
92.6±0.4
93.0±0.1
93.8±0.2

C→B

61.2±0.4
62.0±0.3
62.5±0.3
62.9±0.3

P→B

55.3±0.3
54.3±0.3
54.5±0.2
55.2±0.3

C→P

61.2±0.2
61.7±0.4
62.2±0.3
65.0±0.2

B→P

58.1±0.3
58.6±0.3
59.0±0.3
59.5±0.3

Avg.

69.9
70.1
70.4
71.3

Table 2. Results (in %) of different methods based on GoogLeNet
on ImageCLEF dataset.

Method

LeNet
SA [10]
DAN
WDAN

M→S
17.2±0.3
21.1±0.2
19.3±0.4
23.4±0.2

S→M
56.8±0.5
59.3±0.3
65.2±0.3
67.4±0.4

M→U
61.5±0.4
55.0±0.4
69.1±0.5
72.6±0.3

U→M
46.5±0.6
51.6±0.6
60.5±0.7
65.4±0.4

Avg

45.5
46.8
53.5
57.2

Table 3. Results (in %) of different methods based on LeNet on
Digit Classiﬁcation.

Method

A→W

D→W

W→D

A→D

D→A

W→A

Avg.

94.0±0.3
94.3±0.3
95.9±0.1

60.4±0.5
66.0±0.5
66.8±0.3

AlexNet
DAN
WDAN

66.7
70.0
72.1
Table 4. Results (in %) of different methods based on AlexNet on
Ofﬁce-31 dataset.

92.2±0.3
95.2±0.3
98.7±0.4

46.0±0.6
50.0±0.5
53.8±0.1

58.6±0.6
63.2±0.4
64.5±0.2

49.0±0.5
51.1±0.5
52.7±0.2

SUN [39]. This dataset is thought to be more difﬁcult, since
some domains contain low-quality images, making this
benchmark a good compliance to the Ofﬁce-10+Caltech-10,
where the domain is more similar. Different from the orig-
inal experimental setting, in this paper, we use a subset of
ImageCLEF, which contains three datasets, i.e., Caltech256
(C), Bing (B) and PASCAL VOC2012 (P). Meanwhile, we
exploit all images in each subset rather than follow the stan-
dard protocol to sample the same number of images for each
class. Such setting results in six domain adaptation tasks.

We compare WDAN with three related methods based
on GoogLeNet, i.e., GoogLeNet, DDC and DAN. We im-
plement them by using the codes released by authors2, and
try our best to optimize them. The results of the competing
methods are shown in Table 2, from which we can see that
our proposed weighted DAN obtains the best performance
in most of the cases, and achieves 1.4%, 1.2% and 0.9%
gains over GoogLeNet, DDC and DAN on average, respec-
tively. The above results show the proposed weighted MMD
is helpful to improve the performance of domain adaptation
task.

5.1.3 Digit Recognition

Furthermore, we conduct experiment on digit recognition,
which is usually adopted to domain adaptation. In this pa-
per, we only considering training images of three bench-
marks, i.e., MNIST (M), SVHN (S) and USPS (U) and con-
duct experiments on four tasks. As LeNet [22] is usually
used for digit recognition, we implement our WDAN and
the competing methods based on it. Among them, SA [10]
proposes a subspace alignment method for domain adap-
tation, which aims at learning a feature mapping to align

2https://github.com/longmingsheng/mmd-caffe

Figure 3. Performance (in %) of different methods w.r.t. λ.

source samples with target samples. For fair comparison,
we implement SA by using the features from the ﬁne-tuned
LeNet. The results reported in Table 3 clearly show that
our proposed WDAN achieves the best performance on all
tasks, and outperforms LeNet, SA and DAN by 11.7%,
10.4% and 3.7% on average, respectively. The signiﬁcant
improvements over competing methods show the proposed
weighted MMD model is effective and meaningful.

5.1.4 Ofﬁce-31

Finally, experiments are further conducted to assess WDAN
on datasets with more classes. We conduct experiments on
a dataset with 31 classes (i.e. Ofﬁce-31). There are three
domains, i.e., Amazon (A), Webcam (W) and DSLR (D),
In this part, we consider all the six UDA
in Ofﬁce-31.
tasks, and report the results using Alexnet. Table 4 shows
the results of AlexNet, DAN, and WDAN. It can be seen
that the proposed WMMD achieves better results than its
MMD counterpart, indicating that WMMD also works well
on dataset with more classes. To sum up, the promising
performance of our weighted MMD model can be veriﬁed
on various CNN architectures (i.e., AlexNet, GoogLeNet
and LeNet) and various datasets with different number of
classes.

5.2. Empirical Analysis

In this subsection, we perform empirical analysis of the
proposed WDAN from three aspects. Firstly, we evaluate
the effect of hyper-parameter λ on our proposed WDAN
model in Eqn. (11). Secondly, compared with its baselines,
i.e., Alexnet and DAN, we show our proposed WDAN is
robust to class weight bias. Finally, we make a visualization
of learned feature representations.

5.2.1 Effect of Parameter λ

The objective in Eqn. (11) of WDAN consists of three
i.e., conventional empirical losses on the source
terms,

and target domains, and MMD-based regularizer. Gener-
ally speaking, the empirical risk term keeps the learned
deep feature to be discriminative on source domain while
the MMD-based regularizer encourages domain invariant
feature representation. Both of this two aspects are of
essential importance for domain adaptation. The param-
eter λ in the objective Eqn. (11) makes a tradeoff be-
tween this two parts, and could greatly impact the per-
formance of domain adaptation. To have a closer look at
this parameter, we evaluate our proposed WDAN based on
AlexNet on the task W→C from Ofﬁce-10+Caltech-10 un-
der various λ. As suggested above, λ belongs to the set
{0.0, 0.03, 0.07, 0.1, 0.4, 0.7, 1, 1.4, 1.7, 2}. Meanwhile,
we also compared our WDAN model with DAN under var-
ious λ. AlexNet is reported as baseline and corresponds to
the case λ = 0. The results are illustrated in Fig. 3.

Obvious conclusions can be drawn from the results: (i)
our proposed WDAN consistently outperforms the DAN,
demonstrating that mining the class weight bias in MMD
is meaningful and beneﬁcial; (ii) WDAN and DAN achieve
the best results at λ = 0.4 and λ = 0.1, and outperforms the
baseline, i.e., AlexNet, when λ < 1.2 and λ < 1.0, respec-
tively, indicating that an appropriate balance is important
and necessary.

5.2.2 Impact of Class Weight Bias

To further clarify the impact of class weight bias on MMD-
based domain adaptation methods, we conduct experiments
on a variant of the task V→C from ImageCLEF based
on AlexNet. Speciﬁcally, we pick up two shared classes,
i.e., airplane and motorbike, in the source domain PASCAL
VOC2012 (V) and target domain Caltech256 (C), which
forms a two-class classiﬁcation problem.

Then we ﬁx the class weights as 0.5 for each class on
source domain and train different methods with gradually
changing the class distribution on target domain, which can
be interpreted as different level of the class weight bias
cross source and target domains. Fig. 4 show the results
of WDAN, DAN and AlexNet under different levels of the
class weighted bias. From it we can see that the class weight
bias has great inﬂuence on performance of MMD-based
domain adaptation methods. Moreover, the conventional
MMD-based methods (e.g., DAN) are limited in handling
the class weight bias, as its results signiﬁcantly degrade
with increasing class weighted bias. In addition, our pro-
posed WDAN is more robust to class weighted bias.

5.2.3 Feature Visualization

Following the work in [25], we visualize the features
learned by WDAN and DAN on target domain in the D→C
task from Ofﬁce-10+Caltech-10. For feature visualization,
we employ the t-SNE visualization method [37] whose

Figure 4. Performance (in %) of different methods w.r.t. class
weight bias.

Figure 5. The t-SNE visualization of learned features of different
methods.

source codes are provided3. The results of feature visualiza-
tion for DAN and weighted DAN are illustrated in Fig. 5 (a)
and Fig. 5 (b), respectively. As shown in the orange boxes of
Fig. 5, features learned by the proposed WDAN can reserve
more class discrepancy distance than ones learned by DAN.
The underlying reason lies in the fact that WDAN, by con-
sidering a weighted MMD regularizer, does not minimize
the class weight bias as DAN does, which also accounts for
that weighted DAN can outperform DAN on a variety of
unsupervised domain adaptation tasks.

6. Conclusion

In this paper, we focus on the uninvestigated issue of
class weight bias in UDA, which has adverse effect on
MMD-based domain adaptation methods. We ﬁrst propose
a novel weighted MMD to reduce the effect of class weight
bias by constructing a reference source distribution based
on target distribution. For UDA, we present a weighted
DAN (WDAN) based on the proposed weighted MMD, and
develop modiﬁed the CEM learning algorithm to jointly as-
sign pseudo-labels, estimate the auxiliary weights and learn
model parameters. Empirical results show that our proposed
WDAN outperforms its MMD counterpart, i.e., DAN, in
various domain adaptation tasks. In future, there remains
several issues to be investigated: (i) evaluation of weighted

3https://lvdmaaten.github.io/tsne/

MMD on non-CNN based UDA models, (ii) applications to
other tasks (e.g., image generation) based on measuring the
discrepancy between distributions.

7. Acknowledgment

This work is

supported in part by NSFC grant
(61671182, 61471082, and 61370163). The authors also
thank NVIDIA corporation for the donation of GTX 1080
GPU.

References

[1] M.-R. Amini and P. Gallinari. Semi-supervised logistic re-
gression. In Proceedings of the 15th European Conference
on Artiﬁcial Intelligence, pages 390–394. IOS Press, 2002.
2, 4

[2] H. Azizpour, A. Sharif Razavian, J. Sullivan, A. Maki, and
S. Carlsson. From generic to speciﬁc deep representations
for visual recognition. In Proceedings of the IEEE Confer-
ence on Computer Vision and Pattern Recognition, pages 36–
45, 2015. 1

[3] M. Baktashmotlagh, M. T. Harandi, and M. Salzmann.
Distribution-matching embedding for visual domain adapta-
tion. Journal of Machine Learning Research, 2016. 1, 3
[4] K. M. Borgwardt, A. Gretton, M. J. Rasch, H.-P. Kriegel,
B. Sch¨olkopf, and A. J. Smola. Integrating structured bio-
logical data by kernel maximum mean discrepancy. Bioin-
formatics, 22(14):e49–e57, 2006. 3

[5] B. Caputo and N. Patricia. Overview of the imageclef 2014
domain adaptation task. In ImageCLEF 2014: Overview and
analysis of the results, number EPFL-CONF-201812, 2014.
5, 6

[6] G. Celeux and G. Govaert. A classiﬁcation em algorithm
for clustering and two stochastic versions. Computational
statistics & Data analysis, 14(3):315–332, 1992. 4, 5

[7] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-
Imagenet: A large-scale hierarchical image database.
Fei.
In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, pages 248–255, 2009. 6

[8] J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang,
E. Tzeng, and T. Darrell. Decaf: A deep convolutional acti-
vation feature for generic visual recognition. In Proceedings
the International Conference on Machine Learning, pages
647–655, 2014. 1

[9] M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and
A. Zisserman. The pascal visual object classes (voc) chal-
lenge. International journal of computer vision, 88(2):303–
338, 2010. 6

[10] B. Fernando, A. Habrard, M. Sebban, and T. Tuytelaars. Un-
supervised visual domain adaptation using subspace align-
ment. In Proceedings of the IEEE International Conference
on Computer Vision, pages 2960–2967, 2013. 7

[11] Y. Ganin and V. Lempitsky. Unsupervised domain adaptation
by backpropagation. arXiv preprint arXiv:1409.7495, 2014.
3

[12] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich fea-
ture hierarchies for accurate object detection and semantic

In Proceedings of the IEEE Conference on
segmentation.
Computer Vision and Pattern Recognition, pages 580–587,
2014. 1

[13] B. Gong, K. Grauman, and F. Sha. Connecting the dots with
landmarks: Discriminatively learning domain-invariant fea-
In Proceedings
tures for unsupervised domain adaptation.
the International Conference on Machine Learning, pages
222–230, 2013. 3

[14] B. Gong, Y. Shi, F. Sha, and K. Grauman. Geodesic ﬂow
kernel for unsupervised domain adaptation. In Proceedings
of the IEEE Conference on Computer Vision and Pattern
Recognition, pages 2066–2073, 2012. 5, 6

[15] A. Gretton, K. M. Borgwardt, M. Rasch, B. Sch¨olkopf, and
A. J. Smola. A kernel method for the two-sample-problem.
In Advances in neural information processing systems, pages
513–520, 2006. 2

[16] A. Gretton, K. M. Borgwardt, M. J. Rasch, B. Sch¨olkopf, and
A. Smola. A kernel two-sample test. Journal of Machine
Learning Research, 2012. 3

[17] A. Gretton, D. Sejdinovic, H. Strathmann, S. Balakrishnan,
M. Pontil, K. Fukumizu, and B. K. Sriperumbudur. Optimal
kernel choice for large-scale two-sample tests. In Advances
in neural information processing systems, pages 1205–1213,
2012. 2, 5

[18] G. Grifﬁn, A. Holub, and P. Perona. Caltech-256 object cat-

egory dataset. 2007. 6

[19] J. Huang, A. Gretton, K. M. Borgwardt, B. Sch¨olkopf, and
A. J. Smola. Correcting sample selection bias by unlabeled
data. In Advances in neural information processing systems,
pages 601–608, 2006. 1, 3

[20] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Gir-
shick, S. Guadarrama, and T. Darrell. Caffe: Convolu-
tional architecture for fast feature embedding. arXiv preprint
arXiv:1408.5093, 2014. 6

[21] A. Krizhevsky, I. Sutskever, and G. E. Hinton.

Imagenet
classiﬁcation with deep convolutional neural networks.
In
Advances in neural information processing systems, pages
1097–1105, 2012. 1, 5, 6

[22] Y. Lecun, L. E. Bottou, Y. Bengio, and P. Haaner. Gradient-
based learning applied to document recognition. 1998. 5,
7

[23] Y. Li, K. Swersky, and R. Zemel. Generative moment match-
ing networks. In Proceedings the International Conference
on Machine Learning, pages 1718–1727, 2015. 6

[24] J. Long, E. Shelhamer, and T. Darrell. Fully convolutional
networks for semantic segmentation. In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 3431–3440, 2015. 1

[25] M. Long and J. Wang. Learning transferable features with
deep adaptation networks. CoRR, abs/1502.02791, 1:2,
2015. 3, 4, 5, 6, 8

[26] M. Long, J. Wang, G. Ding, J. Sun, and P. S. Yu. Transfer
In Pro-
feature learning with joint distribution adaptation.
ceedings of the IEEE International Conference on Computer
Vision, pages 2200–2207, 2013. 1, 3

[27] M. Long, J. Wang, and M. I. Jordan. Unsupervised domain
adaptation with residual transfer networks. arXiv preprint
arXiv:1602.04433, 2016. 6

[28] T. Ming Harry Hsu, W. Yu Chen, C.-A. Hou, Y.-H. Hu-
bert Tsai, Y.-R. Yeh, and Y.-C. Frank Wang. Unsupervised
domain adaptation with imbalanced cross-domain data.
In
Proceedings of the IEEE International Conference on Com-
puter Vision, pages 4121–4129, 2015. 1, 2

[29] S. J. Pan, I. W. Tsang, J. T. Kwok, and Q. Yang. Domain
adaptation via transfer component analysis. IEEE Transac-
tions on Neural Networks, 22(2):199–210, 2011. 1, 3
[30] S. J. Pan and Q. Yang. A survey on transfer learning.
IEEE Transactions on knowledge and data engineering,
22(10):1345–1359, 2010. 1

[31] K. Saenko, B. Kulis, M. Fritz, and T. Darrell. Adapting vi-
sual category models to new domains. In European confer-
ence on computer vision, pages 213–226. Springer, 2010. 5,
6

[32] K. Simonyan and A. Zisserman. Very deep convolutional
networks for large-scale image recognition. arXiv preprint
arXiv:1409.1556, 2014. 5, 6

[33] A. Søgaard. Semi-supervised learning and domain adapta-
tion in natural language processing. Synthesis Lectures on
Human Language Technologies, 6(2):1–103, 2013. 4
[34] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed,
D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich.
Going deeper with convolutions. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition,
pages 1–9, 2015. 5, 6

[35] E. Tzeng, J. Hoffman, T. Darrell, and K. Saenko. Simultane-
ous deep transfer across domains and tasks. In Proceedings
of the IEEE International Conference on Computer Vision,
pages 4068–4076, 2015. 3

[36] E. Tzeng, J. Hoffman, N. Zhang, K. Saenko, and T. Darrell.
Deep domain confusion: Maximizing for domain invariance.
arXiv preprint arXiv:1412.3474, 2014. 1, 3, 6, 7

[37] L. Van Der Maaten. Accelerating t-sne using tree-based al-
gorithms. Journal of machine learning research, 2014. 8
[38] J. Weston, F. Ratle, H. Mobahi, and R. Collobert. Deep learn-
In Neural Networks:

ing via semi-supervised embedding.
Tricks of the Trade, pages 639–655. Springer, 2012. 6
[39] J. Xiao, J. Hays, K. A. Ehinger, A. Oliva, and A. Torralba.
Sun database: Large-scale scene recognition from abbey to
zoo. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, pages 3485–3492, 2010. 7
[40] J. Yosinski, J. Clune, Y. Bengio, and H. Lipson. How trans-
ferable are features in deep neural networks? In Advances
in neural information processing systems, pages 3320–3328,
2014. 1, 4

[41] E. Zhong, W. Fan, J. Peng, K. Zhang, J. Ren, D. Turaga,
and O. Verscheure. Cross domain distribution adaptation via
kernel mapping. In Proceedings of the 15th ACM SIGKDD
international conference on Knowledge discovery and data
mining, pages 1027–1036, 2009. 1, 3

