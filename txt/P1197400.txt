Li et al. Probabilistic Map Guided Bi-directional Recurrent UNet for Pancreas Segmentation                                                                                                                     1 

Probabilistic Map Guided Bi-directional 
Recurrent U-Net for Pancreas Segmentation 

Jun Li, Xiaozhu Lin, Hui Che, Hao Li, and Xiaohua Qian  

 Abstract—Pancreas  segmentation  in  medical  imaging 
data is of great significance for clinical pancreas diagnos-
tics and treatment. However, the large population variations 
in  the  pancreas  shape  and  volume  cause  enormous  seg-
mentation  difficulties,  even  for  state-of-the-art  algorithms 
utilizing fully-convolutional neural networks (FCNs). Specif-
ically, pancreas segmentation suffers from the loss of spa-
tial information in 2D methods, and the high computational 
cost  of  3D  methods.  To  alleviate  these  problems,  we  pro-
pose a probabilistic-map-guided bi-directional recurrent U-
Net (PBR-UNet) architecture, which fuses intra-slice infor-
mation and inter-slice probabilistic maps into a local 3D hy-
brid  regularization scheme, which is  followed  by  bi-direc-
tional  recurrent  network  optimization.  The  PBR-UNet 
method  consists  of  an  initial  estimation  module  for  effi-
ciently extracting  pixel-level  probabilistic  maps  and  a  pri-
mary  segmentation  module  for  propagating  hybrid  infor-
mation through a 2.5D U-Net architecture. Specifically, local 
3D information is inferred by combining an input image with 
the  probabilistic  maps  of  the  adjacent  slices  into  multi-
channel  hybrid  data,  and  then  hierarchically  aggregating 
the hybrid information of the entire segmentation network. 
Besides, a bi-directional recurrent optimization mechanism 
is developed to update the hybrid information in both the 
forward and the backward directions. This allows the pro-
posed network to make full and optimal use of the local con-
text  information.  Quantitative  and  qualitative  evaluation 
was  performed  on  the  NIH  Pancreas-CT  dataset,  and  our 
proposed PBR-UNet method achieved better segmentation 
results  with  less  computational  cost  compared  to  other 
state-of-the-art methods. 
 

Indexed  terms:  Pancreas  segmentation,  Deep  learning, 

Medical image segmentation. 
 

I.  INTRODUCTION 

A 

ccurate  segmentation  of  the  human  pancreas  in  medical 
imaging data is an essential prerequisite for relevant med-
ical image analysis and surgical navigation systems. However, 
pancreas segmentation is quite challenging due to the consider-
able variations in the pancreas shape, and the pancreas vulner-
ability  to  elastic  deformations  resulting  from  breathing  and 
 

J.  Li,  H,  Li  and  X.  Qian  is  with  School  of  Biomedical  Engineering, 
Shanghai  Jiao  Tong  University,  Shanghai  200240,  China.  (e-mail: 
xiaohua.qian@sjtu.edu.cn).  

X. Qian is the corresponding author. 
X. Lin is with Department of Radiology, Ruijin Hospital, Shanghai Jiao 

Tong University School of Medicine, Shanghai, China.  

H.  Che  is  with  the  Biomedical  Engineering  Department,  Rutgers 

University, New Jersey 08901, USA.  

 
 

 

Fig. 1.  Examples of pancreas CT scans from the NIH Pancreas-CT da-
taset: (a) Three adjacent slices with high correlation; (b) 3D pancreas 
data from different subjects showing different spatial shapes; (c) A small 
correlation exists between the shapes of the pancreas head and tail.  

heartbeat. Therefore, developing more robust and accurate pan-
creas segmentation methods is of profound significance for per-
formance improvement and risk reduction in computer-assisted 
surgery techniques. 

Nowadays,  developing  satisfactory  methods  for  pancreas 
segmentation  is  still  challenging.  Compared  with  some  other 
human organs such as the heart and liver, the pancreas exhibits 
a higher anatomical variability [1], as shown in Fig. 1. Varia-
tions in the background tissues and dramatic volume changes 
can undermine the performance of any start-of-the-art method 
for pancreas segmentation [2]. Consequently, the pancreas has 
been typically considered among the most complex organs for 
segmentation [3]. 

Pancreas segmentation methods can be roughly divided into 
two categories, namely methods based on top-down multi-atlas 
registration  and  label  fusion  (MALF)  [4]–[7],  and  methods 
based on deep learning [1]–[3]. For a MALF method, volumet-
ric multiple-atlas registration is combined with a robust label-
fusion scheme to optimize the per-pixel pancreas segmentation 
[8]. Due to the high shape variability and blurred boundaries of 
the pancreas, the accuracies of MALF-based methods on bench-
mark datasets range merely from 69.6% to 78.5% [4]–[7]. Nev-
ertheless,  this  performance  can  be  considerably  improved  by 
deep learning methods. Currently, such methods are commonly 
used to apply natural image semantic segmentation models in 
medical image segmentation tasks. State-of-the-art deep-learn-
ing segmentation models have been proposed, such as FCN [9], 
U-Net [10], and DeepLab [11]. The encoder-decoder and skip-
connection techniques are widely used in these models to in-
crease the final output resolution, and accurately locate and dis-
tinguish the pancreas from surrounding tissues [12], [13]. 

Many  existing  deep-learning  segmentation  methods  are 
based on two-dimensional (2D) data. For example, 2D segmen-
tation methods in computerized tomography (CT) process each 

Li et al. Probabilistic Map Guided Bi-directional Recurrent UNet for Pancreas Segmentation                                                                                                                     2 

slice of a CT volume as a separate input. Then, the segmentation 
results  of  all  slices  are  combined  to  construct  a  three-dimen-
sional (3D) pancreas object [1], [8], [14], [15]. Because three 
non-identical views give quite different images of the pancreas, 
Zhou et al. [1] proposed training three 2D FCN models for seg-
mentation in each of the coronal, sagittal, and axial views, and 
then merged these three segmentation results via majority vot-
ing to produce coarse 3D segmentation. While this method in-
troduces 3D features, it does not make full use of the 3D infor-
mation. Fu et al. [8] proposed a richer convolutional feature net-
work,  which  performs  pancreas  segmentation  by  extracting 
multiscale information via a multi-layer upsampling structure. 
Although this method enhances the extraction of intra-slice in-
formation, it completely ignores the 3D information.Thus, 2D 
networks neglect the relationship between adjacent slices, and 
the output of such networks cannot be interpreted in a 3D con-
text [16]. This impedes the extraction of high-level features and 
restricts the pancreas segmentation performance.  

Since 2D networks cannot capture 3D volume information, 
3D networks were proposed by using the CT volume as the net-
work input [17]–[23]. However, these 3D networks require sig-
nificant  computational  and  memory  resources  and  hence  rely 
excessively on high-performance servers [16], [24]. Oktay et al. 
[17] proposed  an  attention gate  model, based  on  a  3D  U-Net 
architecture. While this model can suppress irrelevant regions 
in the network input and highlight useful salient features, the 
model  suffers  from  irreversible  positioning  errors  and  large 
computational costs. To reduce GPU memory requirements and 
acquire 3D information, Roth et al. [25] proposed using two-
stage segmentation scheme, in which the second 3D FCN has 
reduced computations and is focused on the segmentation of the 
target  organ.  However,  due  to  the  GPU  memory  limitations, 
sub-volumes were adopted to process each original CT volume, 
which may cause segmentation discontinuities or inconsisten-
cies at overlapping window boundaries [26]. The result of the 
82.2% Dice similarity coefficient (DSC) indicated that the per-
formance of a 3D segmentation network is limited by compu-
ting resource constraints. The performance and costs of a com-
plete 3D convolutional architecture was further investigated. It 
was  found  that  such  3D  architecture  provided  slightly  better 
performance in comparison to 2D methods, but caused a signif-
icant  and  disproportionate  increase  in  computing  costs  [27]. 
The requirement of a high-memory footprint limits two perfor-
mance improvement factors, namely the network depth and the 
filter field of view [28]. So, the basic 3D networks can hardly 
achieve satisfactory performance in pancreas segmentation. 

Two-stage learning frameworks for coarse-to-fine pancreas 
segmentation were also proposed to overcome the susceptibility 
of one-pass learning strategies to background interference [1], 
[20], [24]–[27]. In such frameworks, the region of interest (ROI) 
is roughly localized by the initial segmentation, and then a finer 
segmentation is carried out by focusing on the localized ROI. 
However, a part of the pancreas could be irreversibly discarded 
at the initial segmentation. This results in unreliable and unsta-
ble pancreas localization, due to the lack of an effective error 
correction  mechanism.  Yu  et  al.  [29]  presented  two  failure 
cases of pancreas segmentation using the coarse-to-fine scheme 
in  [1]  and  indicated  that  the  fine-scale  segmentation  deterio-
rated in some cases due to the lack of contextual information. 
Overall, the performance of a two-stage learning framework for 

pancreas segmentation is limited by overlooking the contextual 
information and possibly missing the target area.  

The  success  of  the  long  short-term  memory  (LSTM)  net-
works is essentially due to their effective consideration of long-
span  dependencies  [30],  and  contextual  information.  In  [14], 
[31], [32], LSTM networks were applied to directly embed con-
textual information as time series into medical image segmen-
tation models. However, this strategy produces a large number 
of training parameters and increases computational costs heav-
ily.  In  the  LSTM-based  segmentation  framework,  the  LSTM 
module usually serves as a single refinement module following 
the main segmentation networks [31]. Indeed, the LSTM makes 
limited segmentation improvement, enlarges the entire network, 
and requires more computing resources. 

The pancreas globally shows a significant anatomical varia-
bility, while it locally exhibits strong morphology and pattern 
correlation among adjacent CT slices (Fig. 1(a)). These global 
and local pancreas characteristics demonstrate that the local 3D 
information or inter-slice information is critical for developing 
pancreas segmentation models of high precision and robustness. 
However, while earlier segmentation models exploited 2D fea-
tures or global 3D information, few models accounted for the 
local 3D context without incurring high computational costs. In 
general,  multi-channel  networks  have  achieved  better  results 
than single-channel networks without a significant increase in 
the computational burden [27].  

Motivated by the above observations, we developed a novel 
pancreas segmentation model based on local 3D hybrid infor-
mation and a bi-directional recurrent 2.5D U-Net architecture, 
namely  the  probabilistic-map-guided  bi-directional  recurrent 
U-Net  (PBR-UNet).  In  this  model,  the  original  map  of  a  CT 
slice is combined with probabilistic maps of the adjacent slices 
to infer local 3D hybrid information that can be used for guiding 
the segmentation of the center slice. This information is propa-
gated in the 2.5D U-Net, and then optimized through a bi-direc-
tional recurrent structure in order to improve and refine the seg-
mentation results. Specifically, we firstly apply an initial esti-
mation model to extract, for each slice, a pixel-level probabilis-
tic map, which represents the per-pixel probability of belonging 
to the pancreas. Then, the initial probabilistic maps of the adja-
cent slices are combined with the map of the center slice into 
multi-channel hybrid data, which contains local 3D hybrid in-
formation of the center slice. Under the constraints of the local 
3D context, the segmentation of the center slice could be con-
strained, resulting in stable results. Finally, a bi-directional re-
current structure is applied to the primary segmentation to opti-
mize the local 3D hybrid information. We use each primary seg-
mentation output to update the probabilistic maps in the multi-
channel data, make the local 3D hybrid information more pre-
cise, and boost the final segmentation performance. 

In  summary,  our  PBR-UNet  framework  has  the  following 

two technical contributions:  

 

Introducing  local  3D  hybrid  information.  A  proba-
bilistic-map-guided  segmentation  model  is  developed 
to  combines  intra-slice  information  and  probabilistic 
maps of adjacent CT slices to form the local 3D hybrid 
information. The proposed model balances the require-
ments for high efficiency in spatial information utiliza-
tion and low computational costs, and thus avoids the 
problems of lack of context in 2D models, and high  

Li et al. Probabilistic Map Guided Bi-directional Recurrent UNet for Pancreas Segmentation                                                                                                                     3 

Fig. 2.  Illustration of the PBR-UNet pipeline for pancreas segmentation. The pipeline includes modules for the initial estimation (E), the primary 
segmentation  (F)  using the  local 3D  hybrid  information  from the combination  (S)  of  the  original  map and  probabilistic maps, followed by the  bi-
directional recurrent update (R) scheme..

 

computational costs in 3D ones.  

  Constructing a bi-directional recurrent 2.5D U-Net. 
A bi-directional recurrent update scheme was proposed 
to optimize local 3D hybrid information in 2.5D U-Net. 
This information is propagated and updated in both the 
forward and backward directions to make full use of the 
local context. Under the guidance of the optimized local 
contextual information, the burden of searching for the 
optimal  pancreas  segmentation  is  well-relieved,  and 
high-precision results can be achieved. In addition, this 
bi-directional recurrent update scheme can be embed-
ded in most segmentation models. 

The remainder of this paper is organized as follows. Section 
II gives the details of the methods used in our proposed model. 
Section  III  presents  the  experimental  results,  Section  IV  dis-
cusses our findings, and Section VI highlights key conclusions. 

II.  METHODOLOGY 

Figure 2 shows the flowchart of the PBR-UNet framework 
for pancreas segmentation. We begin by a problem definition 
(Sec. A), followed by a detailed description of the initial esti-
mation (Sec. B) and primary segmentation (Sec. C) stages. Fi-
nally, we summarize our inference schemes (Sec. D)  

A.  Problem Definition  

In  this  section,  we  formulate the  problem  of  pancreas  seg-
mentation  from  3D  CT  scans  in  terms  of  basic  mathematical 
 be the 3D scan data of a patient, 
notations. Let 
where 
 refer to the 
 and 
slice height and width, respectively, and c denotes the number 
 is a binary segmentation mask 
of channels. The annotation of 

 denotes the total number of slices, 

𝑚𝑚×ℎ×𝑤𝑤×𝑐𝑐

𝐼𝐼 ∈ 𝑅𝑅

𝑚𝑚

𝑤𝑤

ℎ

, and it is defined as 
𝐼𝐼

𝑚𝑚×ℎ×𝑤𝑤×𝑐𝑐

𝑌𝑌�𝑚𝑚,ℎ,𝑤𝑤,𝑐𝑐 ∈ 𝑅𝑅

           (1) 

where a value of 1 means that the voxel belongs to the pancreas, 
while a value of 0 means that the voxel belongs to the back-
based on the 
ground. The mapping function 
,  and  this  function  outputs  the  pixel-wise  seg-
ground  truth 
Ω  is constructed 
mentation maps Ω(I) of the pancreas for given 3D scan 
.The 

𝑌𝑌�

𝐼𝐼

𝑭𝑭

𝑬𝑬

𝑬𝑬

 and 

. The function 

mapping function should be constructed such that the similarity 
between Ω(I) and the ground truth map 
 is as high as possible. 
The mapping function Ω can be written as the composition of 
𝑌𝑌�
two functions: 
 returns the initial seg-
. The function 
mentation  estimate,  i.e.,  the  pixel-wise  probabilistic  map  of 
 returns the primary 
each slice in the 3D scan 
segmentation  resulting  from  bi-directionally  propagating  and 
optimizing local 3D hybrid information. In particular, to make 
full use of the local context information and spread the local 3D 
hybrid information, we design the primary segmentation func-
 in both forward and backwarddirections. This design can 
tion 
be expressed as 
, and the design de-
tails will be given in the next section. Moreover, we denote by 
 the threshold of evaluation, where a pixel with a probability 
 will be labeled as a pancreas pixel.Thus, the pan-
higher than 
𝜃𝜃
creas segmentation problem can be formulated as the problem 
of minimizing the loss function  

𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑤𝑤𝑏𝑏𝑏𝑏𝑏𝑏(𝑓𝑓𝑓𝑓𝑏𝑏𝑤𝑤𝑏𝑏𝑏𝑏𝑏𝑏(𝐼𝐼))

𝑭𝑭

𝑭𝑭

𝜃𝜃

𝐼𝐼

  (2) 

B. 

Initial Estimation of Probabilistic Maps 

In the first stage of the proposed PBR-UNet framework, in-
tra-slice  features  are  extracted  and  a  probabilistic  map  is  ob-
tained  for  each  CT  slice  using  the  initial  estimation  module, 
which is represented by the function 
 (Fig. 2). The probabilis-
 can be denoted mathematically as 
tic maps of a CT volume 
.  Specifi-
cally,  to  fully  utilize  the  CT  volume  information,  we  use  a 
multi-view 2D U-Net (Multi-UNet) architecture [11] to quickly 
obtain  pixel-wise  probabilistic  maps.  The  Multi-UNet  model 
contains three 2D U-Net modules for conducting segmentation 
along the coronal, sagittal, and axial views. These three mod-
ules  have  the  same  structure,  and  they  are  trained  separately 
with data associated with their respective views. Then, arithme-
tic averaging is applied to merge these three results. 

𝑬𝑬

𝐼𝐼

Fig. 3 shows the overall 2D segmentation structure, which is 
composed  of  a  pair  of  encoder  and  decoder  modules,  where 
each module consists of 4 blocks. Each block contains two con-
volutional layers and two rectified linear unit activation func-
tions. A pooling layer is added at the end of each block in the 
encoder module, while a deconvolutional layer is added at the 

Li et al. Probabilistic Map Guided Bi-directional Recurrent UNet for Pancreas Segmentation                                                                                                                     4 

update the corresponding part of the multi-channel hybrid data. 
The final segmentation result is obtained after the bi-directional 
recurrent update and binarization steps. 

start of each block in the decoder module. Moreover, skip con-
nections (indicated by across-block arrows in Fig. 3) are used 
to restore the full spatial resolution of the network output [9]. 
With these skip connections, high-resolution and deep semantic 
information obtained by the encoder module is transferred di-
rectly  to  the  decoder  module.  Thus,  the  output  probabilistic 
maps  will  contain  more  discriminative  features  for  semantic 
segmentation,  including  deep  and  shallow  semantic  infor-
mation, which represents useful contextual information for the 
next segmentation stage. 

Fig. 3.  The 2D U-Net architecture for extracting probabilistic maps from 
the axial view. The outputs are the pixel-wise probabilistic maps, which 
indicates the likelihood that the pixel belongs to the pancreas. 

C.  Bi-directional recurrent segmentation  

In this section, we present details of combining multi-chan-
nel data and refining segmentation with the bi-directional recur-
rent structure. Due to the volumetric continuity of the pancreas, 
experienced radiologists typically localize the pancreas in a CT 
slice according to the adjacent slices along the Z-axis. However, 
the 2D U-Net architecture can only capture intra-slice features 
but not the context information along the Z-axis. Some 3D seg-
mentation networks [17][19]–[22], [33] were proposed for ex-
tracting context information. However, these networks require 
extensive computing resources, and have limited kernel views 
and network depths [16]. As shown in Fig. 1, the pancreas con-
text information is not generally relevant but there is a greater 
similarity between adjacent slices. Thus, we propose to lever-
age the probabilistic maps of adjacent slices to guide the seg-
mentation process with local 3D hybrid information. This ap-
proach can improve the segmentation performance without the 
need for high computational resources. 

To fuse the intra-slice and context information into local 3D 
hybrid information, each center slice is combined with the prob-
abilistic  maps  of  its  adjacent  slices  into  multi-channel  hybrid 
data, which can guide the bi-directional recurrent segmentation 
process without introducing irrelevant information. Specifically, 
 is formed by combining the 
the multi-channel hybrid data 
 and the original data I using the 
estimated probabilistic map 
𝐼𝐼𝑚𝑚𝜗𝜗
transformation 
, i.e., the 3-channel hybrid data can be written 
as

𝐼𝐼𝐼𝐼𝜗𝜗

. 

𝑺𝑺

Fig.  4  describes  the  transformation  process  for  3-channel 
 𝑺𝑺(𝐼𝐼, 𝐼𝐼𝐼𝐼𝜗𝜗) =   [�𝐼𝐼𝐼𝐼𝜗𝜗,1, 𝐼𝐼1, 𝐼𝐼𝐼𝐼𝜗𝜗,2�, ⋯ ⋯ , �𝐼𝐼𝐼𝐼𝜗𝜗,𝑛𝑛−1, 𝐼𝐼𝑛𝑛, 𝐼𝐼𝐼𝐼𝜗𝜗,𝑛𝑛�]
data. Since the first slice does not have a preceding slice and the 
last slice does not have a succeeding slice, the first and the last 
slices  are  duplicated.  After  fusion,  the  local 3D  hybrid  infor-
mation of the multi-channel data can be propagated through the 
2.5D U-Net architecture to guide the primary segmentation and 
update the multi-channel data through the bi-directional recur-
rent update scheme. The 2.5D U-Net has the same architecture 
as that of the initial estimation module, but c input and output 
channels are assumed. For a given CT slice, the output of the 
2.5D U-Net architecture is a probabilistic map, which is used to 

Fig. 4.  Construction of the local 3D hybrid information by combining the 
original map and the probabilistic map to form multi-channel hybrid data 
(in this case, 3 channels are used). To maintain the data integrity, the 
first and last slices are duplicated. 

 

 

 and 

 𝐼𝐼𝑡𝑡
 𝐼𝐼𝑡𝑡
𝐼𝐼𝑚𝑚𝑡𝑡

Fig. 5 illustrates the bi-directional recurrent update scheme 
with multi-channel data, where three channels are used for il-
 be the t-th slice of a 3D scan volume. As de-
lustration. Let
, 
 form a three-channel hybrid 
scribed above,
 (shown as a blue solid circle in Fig. 5), which 
data sample 
𝐼𝐼𝐼𝐼𝑡𝑡+1
is fed into the 2.5D U-Net architecture (indicated by F in Fig. 
 of the t-th slice (shown 
5) to output a new probabilistic map 
 is contained 
as an orange solid circle in Fig. 5). Moreover, 
𝐼𝐼𝐼𝐼𝑡𝑡
 (shown as blue solid cir-
in the data samples 
updates  the 
cles  in  Fig.  5).  So,  the  new  probabilistic  map 
𝐼𝐼𝑚𝑚𝑡𝑡−1
 based on the function R. 
corresponding part in 
The probabilistic map is updated by averaging to be 

𝐼𝐼𝑚𝑚𝑡𝑡+1

𝐼𝐼𝐼𝐼𝑡𝑡−1

 and 

 and 

𝐼𝐼𝐼𝐼𝑡𝑡 

𝐼𝐼𝐼𝐼𝑡𝑡

𝐼𝐼𝑚𝑚𝑡𝑡−1
.The segmentation output is binarized to 
𝐼𝐼𝐼𝐼𝑛𝑛𝑛𝑛𝑤𝑤 =
(indicated by φ in Fig. 5),  

𝐼𝐼𝑚𝑚𝑡𝑡+1

get the final result 
�𝐼𝐼𝐼𝐼𝑠𝑠𝑛𝑛𝑠𝑠𝑚𝑚𝑛𝑛𝑛𝑛𝑡𝑡 + 𝐼𝐼𝐼𝐼𝜗𝜗�/2
𝑍𝑍 

 

           (3) 

 
Fig. 5.  The pipeline for the primary segmentation stage with a bi-direc-
tional recurrent update scheme (where 3 channels are used in this case). 

where pixels with a probability greater than 0.5 are classified as 
pancreas pixels. Otherwise, pixels are labeled as background. 

A two-way propagation method is employed to propagate the 
local 3D hybrid information to each slice. As shown in Fig. 5, 
the blue and red arrows represent information flow in the for-
ward and backward directions, respectively.  This bi-directional 
flow  avoids  loss  of  local  3D  information  between  adjacent 
slices and ensures that this information is fully integrated in the 

Li et al. Probabilistic Map Guided Bi-directional Recurrent UNet for Pancreas Segmentation                                                                                                                     5 

primary  segmentation  stage.  When  the  segmentation  of  each 
slice is completed and made closer to the manual annotation, 
the  corresponding  probabilistic  map  of  multi-channel  data  is 
updated. This ensures that the final output is guided by the local 
optimal 3D hybrid information. 

ℎ𝑡𝑡

(⋯ , 𝑥𝑥𝑡𝑡−2, 𝑥𝑥𝑡𝑡−1, 𝑥𝑥𝑡𝑡+1, 𝑥𝑥𝑡𝑡+2, ⋯ )

Since any function involving a loop can be modeled by a re-
current  neural  network  (RNN)  [34],  we  compare  here  the bi-
directional  recurrent  update  structure  with  an  RNN  structure. 
Yu et al. [29] directly optimized an RNN-based segmentation 
model, at a high computational cost in the training phase. Yang 
et al. [31] used LSTM in the segmentation refinement module 
with serialized volume data. This approach required mapping 
 into  the  hid-
the  input  sequence 
, and this led to a large increase in model parameters 
den unit 
and complexity. In this work, we select the adjacent slices to 
guide  the  segmentation  process.  Thus,  unlike  using  a  RNN 
structure, our proposed model has the following two advantages 
[34]: a) the model does not need additional parameters because 
it only transfers the guidance information from one probability 
distribution  to  another;  b)  the  recurrent  update  process  is 
avoided in the training phase when the primary segmentation 
model F is used at each step. In brief, our PBR-UNet frame-
work  does  not  require  many  training  parameters  and  has  a 
greatly reduced computational cost in the training phase. More 
importantly, under the guidance of the effective contextual in-
formation within a certain range, the burden of obtaining an op-
timal refined pancreas segmentation result is highly reduced. 

D.  Loss Function and Inference Procedure 

Since the pancreas segmentation problem is a two-class prob-
lem with class imbalance, we follow the strategy of using the 
DSC instead of cross-entropy for training and similarity char-
acterization  [19].  Given  the  ground  truth  map 
 and  the  final 
output Ω(X), then the loss function can be defined as  

𝑌𝑌�

             (4) 

𝑗𝑗th 

(𝑖𝑖 − 1)st

channel  of  the 

  data  sample  in 

The overall flow of the PBR-UNet segmentation algorithm is 
shown in Algorithm 1. The variables used  are defined as fol-
lows. The volumetric CT data I is the input, and Z is the output. 
The probability threshold θ is used to binarize results. 
 
(𝑗𝑗)
denotes  the 
. 
𝐼𝐼𝑚𝑚𝜗𝜗,𝑖𝑖−1
Before  the  bi-directional  recurrent  update  scheme,  the  Multi-
𝐼𝐼𝑚𝑚𝜗𝜗
, 
UNet  architecture  is  used  to  get  the  probabilistic  map 
which is denoted as the output of the function 
 in Algorithm 1. 
𝐼𝐼𝐼𝐼𝜗𝜗
Next, each input I and the corresponding initial estimated prob-
are combined by the transformation function 
abilistic maps 
S  to  obtain  the  multi-channel  data  sample 
fed into the 2.5D U-Net architecture for the primary segmenta-
is then 
tion stage. Forward and backward information flow procedures 
in the segmentation process are described as follows:  
1)  Forward Flow 
The output of the 2.5D U-Net is a new probabilistic map 
, 
which  is  used  to  update  the  corresponding  part  of  the  multi-
𝐼𝐼𝐼𝐼𝜚𝜚,𝑖𝑖
 to get the new multi-
channel data samples 
channel  data  samples 
.  This 
update  process  is  performed after  each  primary  segmentation 
stage until all slices are segmented. 

 
and 𝐼𝐼𝑚𝑚𝜗𝜗,𝑖𝑖+1
and 𝐼𝐼𝑚𝑚𝜚𝜚,𝑖𝑖+1,  respectively

𝐼𝐼𝑚𝑚𝜗𝜗,𝑖𝑖−1
𝐼𝐼𝑚𝑚𝜚𝜚,𝑖𝑖−1

which 

𝐼𝐼𝑚𝑚𝜗𝜗 

𝐼𝐼𝐼𝐼𝜗𝜗 

𝐸𝐸

 

 

 

 

2)  Backward Flow 
 val-
After the forward flow procedure, most of the 
ues have been updated. But one-way flow only gets the infor-
mation from the previous slice while the information of the next 
slice is lost. Therefore, we repeat the same process in the back-
ward  direction  to  complete  a  bi-directional  recurrent  update 
scheme.  Finally,  the output  probabilistic  map  is  binarized (as 
defined in Equation 4) to obtain the final segmentation result Z.  

𝐼𝐼𝑚𝑚𝜗𝜗

 and 

𝐼𝐼𝐼𝐼𝜗𝜗

Algorithm 1：Probabilistic Maps Guided Bi-directional Recurrent U-Net 

Input：input volume I, probability threshold 
Output：segmentation volume Z; 

 

; 

𝜃𝜃

 

𝜃𝜃 ⟵ 𝜃𝜃𝑠𝑠𝑡𝑡𝑠𝑠𝑠𝑠𝑡𝑡;
𝑰𝑰𝑰𝑰𝝑𝝑 ⟵ 𝑬𝑬(𝑰𝑰), 𝑰𝑰, 𝑰𝑰𝑰𝑰𝜗𝜗 ∈ 𝑅𝑅
bi-directional process: 
𝑰𝑰𝑰𝑰𝜗𝜗 ⟵ 𝑺𝑺(𝑰𝑰, 𝑰𝑰𝑰𝑰𝜗𝜗), 𝑰𝑰𝑰𝑰𝜗𝜗 ∈ 𝑅𝑅
 to n (forward): 
   for 

𝑚𝑚×ℎ×𝑤𝑤×𝑐𝑐

;
𝑚𝑚×ℎ×𝑤𝑤×3𝑐𝑐

 

;

1: 
2: 
3: 
4: 
5: 
6: 
7: 
8: 

     

𝑖𝑖 ⟵ 1

        

 
𝑰𝑰𝑰𝑰𝜗𝜗,𝑖𝑖 = �𝑰𝑰𝑰𝑰𝜗𝜗,𝑖𝑖−1, 𝑰𝑰𝒊𝒊, 𝑰𝑰𝑰𝑰𝜗𝜗,𝑖𝑖+1�, 𝑰𝑰𝑰𝑰𝜗𝜗 ∈ 𝑅𝑅

𝑚𝑚×ℎ×𝑤𝑤×3𝑐𝑐

       

𝑰𝑰𝑰𝑰𝜚𝜚,𝑖𝑖 ⟵ 𝑭𝑭�𝑰𝑰𝑰𝑰𝜗𝜗,𝑖𝑖�;

(2)
𝑰𝑰𝑰𝑰𝜚𝜚,𝑖𝑖−1

(0)
, 𝑰𝑰𝑰𝑰𝜚𝜚,𝑖𝑖+1
 to 1 (backward): 

; 

𝑰𝑰𝑰𝑰𝜗𝜗,𝑖𝑖 ⟵ 𝑹𝑹(𝑰𝑰𝑰𝑰𝜚𝜚,𝑖𝑖, 𝑰𝑰𝑰𝑰𝜗𝜗,𝑖𝑖)

⟵ 𝑹𝑹�𝑰𝑰𝑰𝑰𝜚𝜚,𝑖𝑖, 𝑰𝑰𝑰𝑰𝜗𝜗,𝑖𝑖−1

(2)

(0)
, 𝑰𝑰𝑰𝑰𝜗𝜗,𝑖𝑖+1

�;

 

;

 

𝑗𝑗 ⟵ 𝑛𝑛
 
𝑰𝑰𝑰𝑰𝜗𝜗,𝑗𝑗 = �𝑰𝑰𝑰𝑰𝜗𝜗,𝑗𝑗−1, 𝑰𝑰𝑗𝑗, 𝑰𝑰𝑰𝑰𝜗𝜗,𝑗𝑗+1�,   𝑰𝑰𝑰𝑰𝜗𝜗 ∈ 𝑅𝑅
𝑰𝑰𝑰𝑰𝜚𝜚,𝑗𝑗 ⟵ 𝑭𝑭�𝑰𝑰𝑰𝑰𝜗𝜗,𝑗𝑗�;

𝑚𝑚×ℎ×𝑤𝑤×3𝑐𝑐

 

;

 

(2)
𝑰𝑰𝑰𝑰𝜚𝜚,𝑗𝑗−1

(0)
, 𝑰𝑰𝑰𝑰𝜚𝜚,𝑗𝑗+1

   

(2)

(0)
, 𝑰𝑰𝑰𝑰𝜗𝜗,𝑗𝑗+1

�;

;  

⟵ 𝑹𝑹�𝑰𝑰𝑰𝑰𝜚𝜚,𝑗𝑗, 𝑰𝑰𝑰𝑰𝜗𝜗,𝑗𝑗−1
 

       

9: 
10:      for 
11:          
12:    
13:    

   

   

14:    
15:     
Return：

𝑰𝑰𝑰𝑰𝜗𝜗,𝑗𝑗 ⟵ 𝑹𝑹(𝑰𝑰𝑰𝑰𝜚𝜚,𝑗𝑗, 𝑰𝑰𝑰𝑰𝜗𝜗,𝑗𝑗)
[𝑡𝑡]
= 𝜑𝜑(𝑰𝑰𝑰𝑰𝜗𝜗 ≥ 𝜃𝜃);

  

𝒁𝒁

[𝑡𝑡]

𝒁𝒁 ⟵ 𝒁𝒁

III.  EXPERIMENTS AND RESULTS 

We used three evaluation metrics (Sec. III.B) to evaluate the 
performance of our proposed model by quantitative and quali-
tative  analyses  (Sec.  III.D)  on  an  authoritative  public  dataset 
(Sec. III.A). Moreover, the experiments were timed to evaluate 
the efficiency of our model (Sec. III.E). The hardware setup and 
training settings were reported in Sec. III.C. 

A.  Dataset and Pre-processing  

Following  most  of  the  earlier  approaches  on  pancreas  seg-
mentation, we used the publically available NIH Pancreas-CT 
dataset [3] to extensively and quantitatively evaluate our pro-
posed algorithm. This dataset contains the abdominal CT scans 
, and 
of 82 patients where each scan has a size of 
 is the number of slices in each CT scan volume. 
We  empirically  truncated  the  CT  radio-density  values  to  the 
𝐿𝐿 ∈ [181, 466]
range of [-100, 200] HU and normalized them to have a zero 
mean and a unit variance. To improve the computational effi-
ciency, all CT scans were cropped to a size of [192, 240], which 
still  can  fully  cover  the  pancreas  in  the  CT  scans.  A  4-fold 
cross-validation (CV) scheme was used in this work to verify 
the reliability and stability of our model. To alleviate the over-
fitting problem, the data was augmented through rotations (be-
tween 0
), shear (between 0 and 0.2), and random hori-
zontal and vertical mirroring [16].  

512 × 512 × 𝐿𝐿

 and 25

˚

˚

Li et al. Probabilistic Map Guided Bi-directional Recurrent UNet for Pancreas Segmentation                                                                                                                     6 

B.  Evaluation metrics 

To  evaluate  the  pancreas  segmentation  performance,  we 
mainly used the DSC, whose range is [0, 1], where a value of 0 
indicates a completely failed segmentation, while a value of 1 
indicates a perfect segmentation. We also used the root-mean-
square error (RMSE) and the Hausdorff distance (HD) [35] to 
evaluate the results of modeling the inter-slice shape continuity. 
The RMSE metric is the square root of the sum of the squared 
deviations between the observed and true values where this sum 
is normalized by the number of observations, 

could improve the model generalization performance for differ-
ent  CT  volumes.  For  a  slice-wise  assessment  of  the  perfor-
mance of our model, we also investigated the DSC distribution 
of  each  slice  of  the  23rd  patient  at  a  DSC  value  of  79.61%, 
which is below the mean DSC value of the test cases (See Fig. 
7(b)). Except for the last two slices at the pancreas tail, and due 
to the small target area, the DSC values of most slices were all 
stable above 60%, which was still an encouraging performance. 
Thus, our model had excellent generalization performance for 
different patient data both on the volume and slice levels. 

 (5) 

TABLE I 
SEGMENTATION RESULT FOR THE NIH PANCREAS-CT DATASET. 

Evaluation 

Min 

Max 

Mean 

Std 

DSC (%) 

53.61 

91.08 

84.19 

HD (mm) 

RMSE (mm) 

2.24 

1.40 

4.32 

18.05 

3.19 

3.60 

5.73 

0.40 

2.57 

The  HD  index  represents  the  maximum  deviation  between 

two point sets or surfaces, 

We also used the recall, precision and intersection over union 
(IOU) to evaluate the pancreas localization performance. The 
IOU measure is the ratio of the intersection to the union of the 
predicted and real borders, 

    (6) 

        (7) 

The recall indicates the proportion of the pancreas pixels (or 
voxels) that are correctly segmented to the total number of true 
. 
pancreas pixels (or voxels), 
The precision reflects the proportion of the pancreas pixels that 
𝑅𝑅𝑅𝑅𝑏𝑏𝑏𝑏𝑅𝑅𝑅𝑅�𝑋𝑋, 𝑌𝑌�; 𝛺𝛺� = �𝛺𝛺(𝑋𝑋) ∩ 𝑌𝑌�� / 𝑌𝑌�
are correctly segmented to the total number of pixels that are 
labeled  as  a  part  of  the  pancreas, 

 Moreover, we measured the standard devi-
𝑃𝑃𝑏𝑏𝑅𝑅𝑏𝑏𝑖𝑖𝑃𝑃𝑖𝑖𝑓𝑓𝑛𝑛�𝑋𝑋, 𝑌𝑌�; 𝛺𝛺� =
ation, maximum and minimum values, and then calculated the 
�𝛺𝛺(𝑋𝑋) ∩ 𝑌𝑌�� / 𝛺𝛺(𝑋𝑋).
average of these metrics over all test cases.  

C. 

Implementation details 

Our model was implemented in the Keras framework based 
on TensorFlow [36]. We built the initial estimate model and the 
primary  segmentation  model  on  an  NVIDIA  GeForce  GTX 
1080Ti GPU. For the initial estimate model, the initial learning 
rate was 0.0001 for 300 epochs of the stochastic gradient de-
scent (SGD) algorithm, and 0.00001 for 400 epochs of the adap-
tive moment estimation (Adam) algorithm. The batch size was 
set to 1. For the primary segmentation model, the initial learn-
ing rate was 0.00001 for 300 epochs of the Adam optimizer. For 
the two models, the batch size was set to 1 and 1% of the train-
ing data samples were selected as a validation set in order to 
check for overfitting. To prevent the model from falling into a 
local minimum, we used a method of learning rate annealing.  

D.  Quantitative and Qualitative Analyses 
1)  Segmentation Performance:  

We  quantitatively  evaluated  the  segmentation results  using 
the DSC, RMSE, and HD indicators. The values of these indi-
cators are reported in Table I, which shows that the mean DSC, 
RMSE, and HD values of our model reached 84.19 ± 5.73%, 
3.60  ±  2.57  mm,  and  3.19  ±  0.40  mm,  respectively.  Fig.  6 
shows our segmentation results, most of the errors occurred at 
the pancreas edges, while the main part of the pancreas was cor-
rectly segmented. This demonstrates a satisfactory performance 
of our proposed method. 

Fig. 7(a) shows that the DSC values of most of our results 
were  distributed  above  85%.  This  indicates  that  our  method 

Fig. 6.  Three-dimensional representations of the PBR-UNet segmenta-
tion results compared to the manually labeled reference standards (best 
viewed in color). The first and second row show the segmentation results 
of  the  10th  patient  (DSC  90.74%)  and  the  7th  patient  (DSC  90.76%), 
respectively. The columns from left to right show the under-segmenta-
tion, over-segmentation, and overall segmentation results, respectively. 

 

 

Fig. 7.  The DSC distribution for the segmentation results of three differ-
ent deep architectures. (a) The DSC distribution for all test cases; (b) 
The DSC distribution for the 23rd patient.  

We applied the recall, precision, and IOU metrics to quanti-
tatively evaluate the pancreas localization performance of our 
model. These three metrics are mainly focused on the shape and 
position of the segmented object. As shown in Table II, the re-
call, precision, and IOU reached 82.23%, 81.44%, and 72.62%, 
respectively. This shows that our model could accurately locate 
the pancreas in a global search. We also noticed that the Multi-
UNet  architecture  achieved  the  best  precision  results  because 
the averging of the results of the three views would eliminate 
many uncertain pixels, as we discuss later. 

To justify the complementary roles of the initial estimation 
and the primary segmentation in our proposed framework, we 

Li et al. Probabilistic Map Guided Bi-directional Recurrent UNet for Pancreas Segmentation                                                                                                                     7 

IOU values for each patient (as shown in Fig. 8), the best per-
formance for most patients was achieved by the proposed PBR-
UNet. This highlights the effectiveness of the bi-directional re-
current  update  with  local  3D  hybrid  information.  Fig.  9(a) 
demonstrates that U-Net and Multi-UNet happened to obtain a 
DSC value of 0. This means that their segmentation ultimately 
failed, while our model still achieved a DSC of 77%. Irrespec-
tive of whether U-Net and Multi-UNet had poor or good results, 
our  proposed  model  still  achieved  better  performance  with  a 
DSC  exceeding  80%  (Fig.  9(b)  and  (c)).  Thus,  our  proposed 
PBR-UNet model did not only improve the performance of lo-
calization but also enhanced the pixel-level segmentation per-
formance. 

compared the results of the U-Net, Multi-UNet, and PBR-UNet 
architectures in ablation experiments. First, we focused on the 
role of the initial estimation stage. Specifically, the basic U-Net 
model was used for segmentation with respect to three views, 
and then the results from these views were averaged. To verify 
the validity of this averaging process, we compared the results 
of  Multi-UNet  and  U-Net.  As  shown  in  Fig.  7(a),  the  Multi-
UNet segmentation results were mostly concentrated at a DSC 
value of 0.85 compared to the dispersed results of U-Net. This 
indicates that most of the segmentation results were in this in-
terval. For the results of the 23rd patient, Fig. 7(b) shows a more 
significant improvement, with the DSC values of most of the 
slices  being  increased  from  0.62  to  around  0.78.  The  perfor-
mance  based  on  the  IOU  and  precision  metrics  was  also  im-
proved, while the IOU value of the Multi-UNet segmentation 
result was 5.58% higher than that obtained by U-Net as Table 
II shows. The above statistics illustrate the effectiveness of the 
adopted averaging mechanism in our proposed model. 

TABLE II 
COMPARISON  OF  THE  PANCREAS  LOCALIZATION  PERFORMANCE  BASED  ON 
THREE METRICS AND THREE DEEP ARCHITECTURES. 

Methods 

Recall [%] 

Precision [%] 

IOU [%] 

U-Net 

76.86 ± 11.40 

79.86 ± 7.33 

67.04 ± 10.78 

Multi-UNet 

74.58 ± 11.26 

85.65 ± 6.38 

72.03 ± 9.01 

PBR-UNet 

82.23 ± 9.14 

81.44 ± 7.53 

72.62 ± 9.09 

TABLE III 
THE NUMBER OF SLICES IN THE DSC INTERVALS FOR SEGMENTATION 
METHODS. 

Methods 

U-Net 

Multi-UNet 

PBR-UNet 

 
Fig. 9. Visual segmentation results for U-Net, Multi-UNet, and PBR-UNet. 
Parts a, b and c denote the 85th slice of the 6th patient, the 123rd slice 
of the 23rd patient, and the 83rd slice of the 20th patient, respectively. 

 

647 (9.42%) 

1540 (22.42%) 

357 (5.19%) 

2)  Reliability analysis: 

DSC ∈ [0,0.5)

 

338 (4.92%) 

483 (7.03%) 

202 (2.94%) 

 
DSC ∈ [0.5,0.6)

614 (8.94%) 

886 (12.90%) 

413 (6.01%) 

 
DSC ∈ [0.6,0.7)

1165 (16.96) 

1583 (23.04%) 

1159 (16.87%) 

 
DSC ∈ [0.7,0.8)

2764 (40.24%) 

1983 (28.87%) 

3133 (45.61%) 

 
DSC ∈ [0.8,0.9)

1340 (19.51%) 

393 (5.72%) 

1604 (23.35%) 

DSC ∈ [0.9,1)

Fig.  10  demonstrates  the  volume-wise  reliability  of  our 
model. The ordinate (reliability) of each point (DSC, reliability) 
shows the ratio of the test results whose DSC was greater than 
the  horizontal  coordinate  (DSC).  Our  proposed  PBR-UNet 
model achieved DSC values greater than 0.8 in 81% of the cases. 
The PBR-UNet curve showed a significant downward trend at 
DSC=0.75. This means that most segmentation results had DSC 
values higher than 75%. By contrast, the Multi-UNet model ex-
ceeded DSC = 0.8 for 72% of the cases, while the U-Net model 
reached a DSC value of 0.8 in only 61% of the cases. Therefore, 
our  proposed  PBR-UNet  method  could  significantly  improve 
the  segmentation  stability  and  ensure  that  most  test  cases 
achieve excellent segmentation performance. 

 
Fig. 8.  Comparison of the segmentation and localization per-formance 
for three deep architectures. (a) Comparison of the segmentation results; 
(b) Comparison of the localization results. 

Then, we assessed the performance of the bi-directional re-
current update scheme with local 3D hybrid information. Fig. 7 
and Table II indicate that, in comparison with the results ob-
tained  by  Multi-UNet,  our  PBR-UNet  achieved  further  im-
provements  in  the  pancreas  segmentation  and  localization  on 
the volume and slice levels as demonstrated by the recall and 
IOU values. Furthermore, according to the improved DSC and 

Fig. 10.  The segmentation reliability for the U-Net, Multi-UNet, and PBR-
UNet. 

 

Li et al. Probabilistic Map Guided Bi-directional Recurrent UNet for Pancreas Segmentation                                                                                                                     8 

standard deviation in the Bland-Altman test (as shown in Fig. 
11(f)). This further demonstrates our model reliability. 

The  slice-based  segmentation  performance  was  also  im-
portant for the integrity of pancreas segmentation. Thus, we an-
alyzed the distribution of the number of slices in the DSC inter-
vals for different models, as shown in Table III. The slices of 
69.96% of the cases for the proposed PBR-UNet method were 
distributed  in [0.8,1.0),  while  only  the  slices  of  5.19%  of  the 
cases had a DSC value below 0.5. Compared to the distributions 
of  the  U-Net  and  Multi-UNet  architectures,  our  method  suc-
cessfully  improved  the  segmentation  performance  for  a  large 
number of slices. Therefore, our model not only had excellent 
volume-wise performance but also had an acceptable slice-wise 
distribution of the results. This indicates that our model had a 
reliable performance at the volume and slice levels. 

TABLE IV 

THE DSC OF THE SEGMENTATION RESULTS FOR SLICES WITH SMALL 
PANCREAS SIZES. 

Methods 

Head and tail, 480 cases 

size 

 300, 496 cases 

Failed slices 

Mean 

Failed slices 

≤

Mean 

U-Net 

Multi-UNet 

PBR-UNet 

102 

175 

84 

50.07 ± 31.89 

27.80 ± 29.22 

54.40 ± 30.77 

112 

193 

90 

46.52 ± 30.94 

29.48 ± 31.37 

51.43 ± 29.73 

In Table III, we can still found that poorly segmented slices 
accounted for a small percentage of the results of the method 
we proposed. In fact, most of the poorly-segmented slices had 
a small target area. Thus, we focused on slices with small-sized 
targets. Without loss of generality, we calculated the segmenta-
tion  results  of  3  slices  of  the pancreas  head  and  tail  and  also 
slices  at  which  the  pancreas  size  is  less  than  300  pixels  (See 
Table IV). The segmentation results suffered a dramatic drop 
due to the small size in the selected slices. However, despite the 
lack of sufficient context information, our model could still use 
local 3D hybrid information to optimize the segmentation of the 
poorly-segmented slices and achieve the highest average DSC 
value of approximately 54%. Compared with the DSC results 
below 30% in Multi-UNet, our proposed method almost dou-
bled  the  DSC  values.  Moreover,  the  number  of  slices  with  a 
DSC segmentation result of 0 was reduced by more than one 
half compared to Multi-UNet. Overall, our approach could sig-
nificantly improve the segmentation performance of U-Net and 
Multi-UNet in terms of segmentation small target areas. 

To further assess the agreement between the automatic and 
human-guided segmentation results, we compared the volumet-
ric correlation between the expert annotation and the results of 
our model. Specifically, we adopted the correlation coefficient 
and the Bland-Altman agreement tests for a comprehensive as-
sessment. The slope of the linear regression curve represents the 
consistency of the model-based pancreas volume and the man-
ually-labeled  reference  volume.  The  closer  the  slope  of  the 
curve to 1 is, the better the segmentation result is. As Fig. 11(c) 
shows, the linear regression curves indicate a strong correlation 
between  the  automated  and  the  manual  segmentation  results. 
While the linear fitting results of Multi-UNet produced signifi-
cant  degradation,  our  model  could  still  correct  deviations  to 
achieve a high-correlation coefficient. Furthermore, our model 
not  only  achieved  a  high  correlation  coefficient  (0.9369), but 
more than 93% of the measurements were still within the ±1.96 

 
Fig. 11.  Segmentation volumes of the U-Net, Multi-UNet, and PBR-UNet 
architectures  versus  the  reference  standard  volumes.  The  first  row 
shows the  correlation  of the  segmentation volumes  with  the manually 
labeled volumes. The second row shows the results of the Bland-Altman 
agreement  test  which  again  compares  between  the  manually-seg-
mented volumes and the segmentation volumes. 

TABLE V  
COMPARISON OF THE PBR-UNET SEGMENTATION RESULTS WITH 
DIFFERENT GUIDANCE DEPTHS.  

Depth 

DSC [%] 

RMSE [mm] 

HD [mm] 

1 

2 

3 

84.19 ± 5.73 

83.06 ± 6.03 

84.03 ± 5.72 

3.60 ± 2.57 

3.25 ± 2.26 

3.77 ± 2.64 

3.19 ± 0.40 

3.22 ± 0.39 

3.19± 0.39 

3)  Parameter Selection: 

The range of contextual information used for guiding the seg-
mentation was limited to a fixed depth. We conducted compar-
ative experiments to explore the impact of the guidance depth 
on the segmentation results. We set the navigation depth to 1, 2, 
and 3, respectively, while the channels of the multi-channel data 
would be 3, 5, and 7, respectively. All experiments were con-
ducted under the same experimental settings. As seen in Table 
V,  PBR-UNet  with  a  guidance  depth  of  1  achieved  the  best 
overall performance. Obviously, the results at a guidance depth 
of 1 and 3 were much better than those at a depth of 2. Increas-
ing the guidance depth would enrich the local 3D hybrid infor-
mation, but would also introduce irrelevant information and in-
crease  the  computational  resource  consumption.  Thus,  we 
chose a guidance depth of 1 for subsequent experiments. 

TABLE VI 
TIME CONSUMPTION COMPARISON WITH DIFFERENT DEEP LEARNING 
MODELS.  

Methods 

Time [s] 

Min 

Max 

Mean 

U-Net 

1.05 

4.04 

1.49 ± 0.45 

Multi-UNet 

5.66 

12.74 

7.02 ± 1.14 

PBR-UNet 

7.95 

18.24 

10.18 ± 1.61 

4)  Time consumption: 

Our  proposed  bi-directional  recurrent  network  based  on 

Li et al. Probabilistic Map Guided Bi-directional Recurrent UNet for Pancreas Segmentation                                                                                                                     9 

probabilistic  map  guidance  represents  a  lightweight  solution 
with  low  computational  and  time  resource  consumption.  The 
data for different patients had different slices. So, we calculated 
the test time for each patient data sample to quantify the model 
efficiency. As shown in Table VI, after loading the model, the 
average,  minimum,  and  maximum  elapsed  times  per  volume 
were 10.18 s, 7.95 s, and 18.24 s, respectively. In conclusion, 
the time consumption of our model was much better than that 
of  cascaded  FCNs  with  3D  dense  conditional  random  fields 
(CRFs) [37], which took just below 100 s per volume. 

5)  Comparison with other methods: 

As shown in Table VII, our model exhibits a competitive per-
formance against recent state-of-the-art pancreas segmentation 
methods. For our model, a DSC value of 84.19% was achieved. 
This figure is exceedingly close to the highest result of 84.50% 
which was obtained by Yu et al. [31]. Although our results were 
0.31% worse than the best result, the relatively small number of 
parameters in our model made the test time much shorter. Yu et 
al.  [29]  needed  1.3  minutes,  and  Zhou  et  al.  [1]  needed  3 
minutes,  which  were  much  longer  than  the  average  time  (10 
seconds) of the proposed model.  

TABLE VII 
COMPARISON OF PANCREAS SEGMENTATION RESULTS WITH THE STATE-OF-
THE-ART METHODS (MEASURED BY DSC [%]). 

Models 

Year  Min DSC  Max DSC 

Mean DSC 

Roth et al. [3] 

2015 

23.99 

86.29 

71.42 ± 10.11 

Farag et al. [38] 

2016 

24.40 

85.30 

70.70 ± 13.00 

Zhou et al. [1] 

2017 

62.43 

90.85 

82.37 ± 5.68 

Karasawa et al. [7] 

2017 

78.50 ± 14.00 

Roth et al. [26] 

2018 

50.69 

88.96 

81.27 ± 6.27 

Oktay et al. [17] 

2018 

Fu et al. [8] 

2018 

81.48 ± 6.23 

76.36 ± 14.34 

/ 

/ 

/ 

/ 

/ 

/ 

Yu et al. [29] 

2018 

62.81 

91.02 

84.50 ± 4.97 

Asaturyan et al. [39] 

2019 

72.8 

86.0 

79.3 ± 4.4 

 
Fig.  12.   The segmentation  results  of three  adjacent  slices  with  small 
target areas. The parts a, b and c in the figure denote the 145th, 146th, 
and 147th slices, respectively for the 3rd patient. 

On the other hand, most pancreas segmentation approaches 
paid considerable attention to the overall segmentation perfor-
mance, with little focus on the segmentation of small  targets. 
However, due to the large shape and volume variability of the 
human pancreas, the ability to segment small-sized targets is an 
important  indicator  of  segmentation  stability.  Therefore,  we 
discussed the segmentation results of slices with small sizes in 
the  above  section  on  reliability  analysis.  Indeed,  our  model 
could  optimize  the  segmentation  results  by  propagating  local 
3D hybrid information. Fig. 12 shows the segmentation results 
of three adjacent slices (the 145th, 146th, and 147th slices) of 
the 3rd patient. Due to the small size of the pancreas in these 
three slices, the DSC value for the initial segmentation results 
was below 60%. Based on the excellent segmentation results of 
the  adjacent  slices  of  the  specified  three  slices  (e.g.  DSC  = 
91.56%  for  the  143th  slice),  the  segmentation  results  for  the 
three slices all reached a DSC exceeding 85%. This emphasized 
that  our  model  effectively  used  local  3D  hybrid  information, 
making large improvements in slices with poor segmentation. 

IV.  DISCUSSION 

A.  Comparison on computing resources 

Pancreas  segmentation  is  of  great  significance  for  clinical 
computer-aided  diagnosis.  The  segmentation  results  can  pro-
vide accurate location and contour information of the pancreas. 
However, due to the high demand for computing resources in 
3D networks, most of these networks cannot be efficiently ap-
plied in clinical practice. In this paper, we present a segmenta-
tion network guided by probabilistic maps, which aims to ex-
tract local 3D hybrid information without requiring excessive 
computational resources. Our model is thus quite beneficial in 
clinical practice, especially as large-sized 3D volumes and mul-
tiple slices are increasingly used in clinical applications [16]. 
We used two NVIDIA GeForce GTX 1080Ti GPUs with 11-
GB memories to explore the need for computing resources in 
3D networks. We adopted a basic 3D U-Net [21] model with an 
.  The  training  of  this  network 
input  size  of 
couldn’t continue because of memory insufficiency. This con-
firms that the 3D network demand for computing resources is 
enormous.  By  contrast,  our  proposed  network  can  work  well 
with only one such GPU device under the same conditions. So, 
our approach is more clinically practical.  

120 × 120 × 120

B.  On merging the segmentation results of three views 
In  Fig.  11(b),  we  find  that  the  linear  regression  curve  of 
Multi-UNet showed a large shift, with a correlation coefficient 
of only 0.47. This indicated that the volume of Multi-UNet seg-
mentation results was significantly different from the expert an-
notation. The reason for this result is the merging mechanism 
for  the  segmentation  results  of  the  three  views.  The  merging 
method in this paper is simply an averaging one. Hence, a pixel 
could  be  regarded  within  the  pancreas  area  only  when  two 
views assert its presence within the pancreas area. So, many un-
certain pixel areas could be discarded after averaging. Never-
theless, this mechanism gives higher confidence in the surviv-
ing pixels. As shown in Table II, the precision value of Multi-
UNet is the highest. Overall, the result of fusing the segmenta-
tion  outputs  of  the  three  views  is  a  valuable  and  practicable 
scheme [1], [29], as verified by our experiments. 

Li et al. Probabilistic Map Guided Bi-directional Recurrent UNet for Pancreas Segmentation                                                                                                                     10 

V.  CONCLUSIONS 

The current key challenge in pancreas segmentation is that 
3D networks require high computing resources, while 2D net-
works  cannot  capture  contextual  information.  Therefore,  we 
propose  a  PBR-UNet  for  pancreatic  segmentation.  This  net-
work  combines  the  intra-slice  information  and  probabilistic 
maps of the adjacent slices into local 3D hybrid information for 
guiding segmentation. This information could be optimized by 
a  bi-directional  recurrent  updating  scheme.  Extensive  experi-
ments have demonstrated that our proposed PBR-UNet method 
could achieve competitive results compared with other state-of-
the-art methods. Besides, this new paradigm with the local 3D 
hybrid  information  and  bi-directional  recurrent  updating 
scheme can be integrated with other segmentation models for 
compromising the trade-offs between 2D and 3D segmentation 
networks. Thus, our proposed PBR-UNet method not only pro-
vides a useful tool for pancreatic segmentation but also a poten-
tial paradigm for research in medical image segmentation.  

 REFERENCES 
[1]  Y. Zhou, L. Xie, W. Shen, Y. Wang, E. K. Fishman, and A. L. Yuille, “A 
fixed-point model for pancreas segmentation in abdominal CT scans,” in 
International Conference on Medical Image Computing and Computer-
Assisted Intervention. Springer, 2017, pp. 693–701, 2017. 

[2]  H. R. Roth, A. Farag, L. Lu, E. B. Turkbey, and R. M. Summers, “Deep 
convolutional  networks  for  pancreas  segmentation  in  CT  imaging,”  
in Medical Imaging 2015: Image Processing, Vol. 9413, pp. 94131G.  

[3]  H. R. Roth et al., “Deeporgan: Multi-level deep convolutional networks 
for  automated  pancreas  segmentation,”  in  International  conference  on 
medical  image  computingandcomputer-assistedintervention.  Springer, 
2015, pp. 556–564, 2015. 

[4]  M. Oda et al., “Regression Forest-Based Atlas Localization and Direction 
Specific  Atlas  Generation  for  Pancreas  Segmentation,”  in International 
Conference on Medical Image Computing and Computer-Assisted Inter-
vention, 2016, pp. 556-563. 

[5]  R.  Wolz, C. Chu, K. Misawa, M.  Fujiwara, K. Mori,  and  D. Rueckert, 
“Automated  abdominal  multi-organ  segmentation  with  subject-specific 
atlas generation,” IEEE Trans. Med. Imaging, vol. 32, no. 9, pp. 1723–
1730, 2013. 

[6]  T. Tong et al., “Discriminative dictionary learning for abdominal multi-
organ segmentation,” Med. Image Anal., vol. 23, no. 1, pp. 92–104, 2015. 
[7]  K. Karasawa et al., “Multi-atlas pancreas segmentation: Atlas selection 

based on vessel structure,” Med. Image Anal., vol. 39, pp. 18–28, 2017. 

[8]  M. Fu  et al., “Hierarchical combinatorial deep learning architecture for 
pancreas segmentation of medical computed tomography cancer images,” 
BMC Syst. Biol., vol. 12, no. Suppl 4, 2018. 

[9]  E. Shelhamer, J. Long, and T. Darrell, “Fully Convolutional Networks for 
Semantic Segmentation,” in IEEE conference on computer vision and pat-
tern recognition, 2015, pp. 3431-3440. 

[10]  O.  Ronneberger,  P.  Fischer,  and  T.  Brox,  “U-Net:  Convolutional 
Networks for Biomedical Image Segmentation,” in International Confer-
ence  on  Medical  image  computing  and  computer-assisted  intervention, 
2015, pp. 234-241.  

[11]  L. C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille, 
“DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, 
Atrous Convolution, and Fully Connected CRFs,”  IEEE Trans. Pattern 
Anal. Mach. Intell., vol. 40, no. 4, pp. 834–848, 2018. 

[12]  M. Drozdzal, E. Vorontsov, G. Chartrand, S. Kadoury, and C. Pal, “The 
Importance  of  Skip  Connections  in  Biomedical  Image  Segmentation,” 
in Deep Learning and Data Labeling for Medical Applications, 2016, pp. 
179-187. 

[13]  G.  González,  G. R.  Washko, and R. San José  Estépar,  “Multi-structure 
Segmentation  from  Partially  Labeled  Datasets.  Application  to  Body 
Composition Measurements on CT Scans,” in Image Analysis for Moving 
Organ, Breast, and Thoracic Images, 2018, pp. 215–224. 

[14]  J. Cai, L. Lu, Y. Xie, F. Xing, and L. Yang, “Improving Deep Pancreas 
Segmentation  in  CT  and  MRI  Images  via  Recurrent  Neural  Contextual 

Learning and  Direct Loss  Function,”  arXiv  preprint arXiv:1707.04912, 
2017. 

[15]  J. Cai, L. Lu, F. Xing, and L. Yang, “Pancreas Segmentation in CT and 
MRI  Images  via  Domain  Specific  Network  Designing  and  Recurrent 
Neural Contextual Learning,” arXiv preprint arXiv:1803.11303, 2018. 

[16]  X. Li, H. Chen, X. Qi, Q. Dou, C. W. Fu, and P. A. Heng, “H-DenseUNet: 
Hybrid Densely Connected UNet for Liver and Tumor Segmentation from 
CT Volumes,” IEEE Trans. Med. Imaging, no. 1, pp. 1–13, 2018. 
[17]  O.  Oktay  et  al.,  “Attention  U-Net:  Learning  Where  to  Look  for  the 

Pancreas,”  arXiv preprint arXiv:1804.03999, 2018. 

[18]  Q.  Dou,  H.  Chen,  Y.  Jin,  L.  Yu,  J.  Qin,  and  P.-A.  Heng,  “3D  Deeply 
Supervised  Network  for  Automatic  Liver  Segmentation  from  CT 
Volumes,”  in  Medical  Image  Computing  and  Computer-Assisted 
Intervention. Springer, 2016, pp. 149–157. 

[19]  S. Liu et al., “3D anisotropic hybrid network: Transferring convolutional 
features  from  2D  images  to  3D  anisotropic  volumes,”  in  International 
Conference  on  Medical  Image  Computing  and  Computer-Assisted 
Intervention. Springer, 2018, pp. 851–858. 

[20]  Z. Zhu, Y. Xia, W. Shen, E. Fishman, and A. Yuille, “A 3D coarse-to-fine 
framework for volumetric medical image segmentation,” in Proc. - 2018 
Int. Conf. 3D Vision, 3DV 2018, pp. 682–690, 2018. 

[21]  Ö. Çiçek, A. Abdulkadir, S. S. Lienkamp, T. Brox, and O. Ronneberger, 
“3D  U-net:  Learning  dense  volumetric  segmentation  from  sparse 
annotation,”  in  International Conference on  Medical  Image  Computing 
and Computer-Assisted Intervention. Springer, 2016, pp. 424–432. 
[22]  F. Milletari, N. Navab, and S. A. Ahmadi, “V-Net: Fully convolutional 
neural networks for volumetric medical image segmentation,” in Proc. - 
2016 4th Int. Conf. 3D Vision, 3DV 2016, pp. 565–571, 2016. 

[23]  Z.  Quo  et  al.,  “Deep  LOGISMOS:  Deep  learning  graph-based  3D 
segmentation  of  pancreatic  tumors  on  CT  scans,”  in  Proc.  -  Int.  Symp. 
Biomed. Imaging,  pp. 1230–1233, 2018. 

[24]  Q. Jin, Z. Meng, C. Sun, L. Wei, and R. Su, “RA-UNet: A hybrid deep 
attention-aware  network to extract liver  and  tumor  in CT  scans,” arXiv 
preprint arXiv:1811.01328. 

[25]  H.  R.  Roth  et  al.,  “An  application  of  cascaded  3D  fully  convolutional 
networks  for  medical  image  segmentation,”  Comput.  Med.  Imaging 
Graph., vol. 66, pp. 90–99, 2018. 

[26]  H. R. Roth et al., “Spatial aggregation of holistically-nested convolutional 
neural networks for automated pancreas localization and segmentation,” 
Med. Image Anal., vol. 45, pp. 94–107, 2018. 

[27]  M. Lai, “Deep Learning for Medical Image Segmentation,” arXiv preprint 

arXiv:1505.02000, 2015. 

[28]  C. Chung et al., “Very deep convolutional networks for large-scale image 

recognition,”  arXiv preprint arXiv:1409.1556. 

[29]  Q.  Yu,  L.  Xie,  Y.  Wang,  Y.  Zhou,  E.  K.  Fishman,  and  A.  L.  Yuille, 
“Recurrent Saliency Transformation Network: Incorporating Multi-Stage 
Visual  Cues  for  Small  Organ  Segmentation,”  in  IEEE  Conference  on 
Computer Vision and Pattern Recognition. 2018,  pp. 8280–8289. 
[30]  S. Hochreiter and J. Schmidhuber, “Long Short-term Memory,” Neural 

Comput., vol. 9, pp. 1735–1780, 1997. 

[31]  X. Yang et al., “Towards Automated Semantic Segmentation in Prenatal 
Volumetric Ultrasound,” IEEE Trans. Med. Imaging, vol. 38, no. 1. 180–
191, 2018. 

[32]  Y.  Hua,  L.  Mou,  and  X.  X.  Zhu,  “Recurrently  Exploring  Class-wise 
Attention in A Hybrid Convolutional and Bidirectional LSTM Network 
for  Multi-label  Aerial  Image  Classification,”   ISPRS  journal  of  photo-
grammetry and remote sensing, vol.149, pp.188-199, 2018. 

[33]  Y.  Xia  et  al.,  “3D  Semi-Supervised  Learning  with  Uncertainty-Aware 

Multi-View Co-Training,” arXiv preprint arXiv:1811.12506. 

[34]  I.  Goodfellow,  Y.  Bengio,  and  A.  Courville,  Deep  Learning.  The  MIT 

Press, 2016. 

[35]  A. A. Taha and A. Hanbury, “An Efficient Algorithm for Calculating the 
Exact Hausdorff Distance,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 
37, no. 11, pp. 2153–2163, 2015. 

[36]  F. Chollet et al, “Keras,” https://github.com/keras-team/keras, 2015. 
[37]  P. F. Christ et al., “Automatic Liver and Tumor Segmentation of CT and 
MRI  Volumes  using  Cascaded  Fully  Convolutional  Neural  Networks,” 
arXiv preprint arXiv:1702.05970. 

[38]  A. Farag et al., “A Bottom-up Approach for Pancreas Segmentation using 
Cascaded Superpixels and ( Deep ) Image Patch Labeling,” IEEE Trans. 
Image Process., vol. 26, no. 1, pp. 1–14, 2016. 

[39]  H.  Asaturyan,  A.  Gligorievski,  and  B.  Villarini,  “Morphological  and 
multi-level geometrical descriptor analysis in CT and MRI volumes for 
automatic pancreas segmentation,” Comput. Med. Imaging Graph., vol. 
75, pp. 1–13, 2019. 

