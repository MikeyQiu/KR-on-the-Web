Capsule Neural Network based Height Classiﬁcation
using Low-Cost Automotive Ultrasonic Sensors

Maximilian P¨opperl, Raghavendra Gulagundi, Senthil Yogamani and Stefan Milz
Valeo Schalter und Sensoren GmbH
Kronach, Germany
maximilian.poepperl@valeo.com

9
1
0
2
 
b
e
F
 
6
2
 
 
]

V
C
.
s
c
[
 
 
1
v
9
3
8
9
0
.
2
0
9
1
:
v
i
X
r
a

Abstract—High performance ultrasonic sensor hardware is
mainly used in medical applications. Although, the development
in automotive scenarios is towards autonomous driving, the ultra-
sonic sensor hardware still stays low-cost and low-performance,
respectively. To overcome the strict hardware limitations, we
propose to use capsule neural networks. By the high classiﬁ-
cation capability of this network architecture, we can achieve
outstanding results for performing a detailed height analysis
of detected objects. We apply a novel resorting and reshaping
method to feed the neural network with ultrasonic data. This
increases classiﬁcation performance and computation speed. We
tested the approach under different environmental conditions
to verify that the proposed method is working independent of
external parameters that is needed for autonomous driving.

Index Terms—CapsNets, ultrasonic sensors, autonomous driv-

ing

I. INTRODUCTION

Ultrasound is a relatively old technology used in automo-
tive applications. Starting from simple warning systems for
parking, ultrasonic sensors evolved rapidly to an essential
component of modern driving assistance [1]. One of the key
points of the high popularity of these sensors is for sure
the low production costs. Although this increases the spread
of ultrasonic technology, the focus in the ultrasonic sensor
development for automotive applications has mainly been on
cost reduction rather than on performance improvements [2].
To keep pace with the upcoming requirements for autonomous
driving, ultrasonic systems have a high need for new devel-
opments at the moment. However, major hardware changes
are prevented by existing standards and automotive low-cost
expectations. Consequently, another starting point for improve-
ments needs to be found.
A role model to solve the performance issues are medical
ultrasonic applications, such as prenatal diagnosis or screening
[3]. In contrast to automotive setups, the sensor hardware is
much more complex and costly. Nevertheless, some processing
approaches are adaptable to automotive scenarios. Especially,
the methods used for pattern recognition are of interest.
Whereas in automotive applications algorithms are mainly
based on thresholds, medical ones use classiﬁcation methods
like adaptive boosting or support vector machine [4].
In addition, deep learning based classiﬁcation is a highly
frequented topic in medical ultrasonic diagnosis. The ap-
plied approaches cover different network architectures includ-
ing multilayer perceptrons (MLP) [5], convolutional neural

networks (CNN) [6] as well as recurrent neural networks
(RNN) [7]. The applications are as manifold as the network
architectures and last from pattern detection and tracking to
segmentation [8] or image reconstruction [9].
Although approaches like image reconstruction and tracking
are thinkable using automotive ultrasonic sensors, their usage
is prevented by low-performance processing units in present
cars. Consequently, we need to improve the functionality
of ultrasonic sensors by a classiﬁcation of detected objects.
Basically different object properties can be determined with
a single sensor, e.g. width, material or height. As the object
height is most important for driving assistance systems, we use
it exemplary to evaluate our proposed classiﬁcation method.
The low-cost sensor and processing unit additionally restrict
the applicable network architectures to CNNs or similar
computational efﬁcient implementations. Due to the low per-
formance of a sensor, the requirements for a classiﬁcation
algorithm are very challenging. Thus, network architecture
like capsule neural networks (CapsNet) [10], [11] that achieve
improved performance by similar computational effort as
CNNs are suited well to solve our ultrasonic classiﬁcation
problem.
Subsequent to the description of our measurement setup, we
propose a special preprocessing and data preparation method.
This method is necessary to feed the neural network ade-
quately, but also to increase classiﬁcation accuracy and speed.
The neural network basically follows the capsule approach

Fig. 1. Preprocessing and classiﬁcations steps of the proposed approach

from [10]. We adapted it to the demands of ultrasonic data.
An overview of the method is given in Fig. 1. At the end we
verify our results and show the independence of environmental
inﬂuences of the proposed height estimation.

II. MEASUREMENT SETUP

A conventional automotive ultrasonic sensor is used. The
sensor has a single membrane. The transmit signal is a modu-
lated pulse at a center frequency of 51.2 kHz. The bandwidth
of the pulse is about 3 kHz. The sensor is shown in Fig. 2.
We use a monostatic measurement setup, i.e. the transmitting
sensor is also used to receive the reﬂected signals. The sensor
provides raw data from the piezoelectric element. An analog
ﬁlter bank is used for signal conditioning before the signal is
converted from analog to digital. Further processing steps are
done on a computer and are described in detail in section III.
In order to verify that the proposed algorithm is independent
of environmental inﬂuences, which is very important in auto-
motive applications due to changing conditions, we recorded
a wide variety of scenarios. Beside dry and wet ground, we
also measured different ground types, such as asphalt, gravel
and grass. The temperature in our measurements has varied
between 5 ˝C to 25 ˝C, so that temperature dependent effects
of the membrane are covered.
Furthermore, we use different objects, e.g. curbs, tubes and
walls. The objects itself also have different heights, as for
example some curbs can be driven over without braking or
at least require a reduced speed. We found that the object
distance and lateral position to the sensor also has a signiﬁcant
inﬂuence on the height classiﬁcation. Hence, we extended the
data set by considering object distances between 0.5 m and
2.5 m.
In total our dataset contains 21,600 measured responses from
a single sensor. On the one hand this amount of data is
needed to train the neural network adequately. But on the other
hand it is also necessary in order to cover all environmental
inﬂuences and achieve high robustness that is required in
driving assistance applications. We used a manual labeling
as we only consider static scenarios. Anyway, we need to

Fig. 3. Signal conditioning steps

generate each setup manually. The reason for this is that
typically high and very low objects are frequent in automotive
scenarios. Objects in between very low and high heights are
rare, so that they need to be placed artiﬁcially. The data is
labeled with respect to four different height classes that are
chosen according to automotive speciﬁcation. The ﬁrst height
is chosen below 10 cm, so that it is possible to drive over. The
next class is deﬁned between 10 cm and 30 cm. For objects in
this height, it is possible to drive over without damage using a
suitable car and reduced speed. The third class contains objects
with a height between 30 cm and 50 cm, where driving over
without damage is not possible anymore. A door can still be
opened. The fourth class includes all objects that are higher
than 50 cm. Again driving over is not possible. Furthermore a
door cannot be opened anymore, so that more space between
the car and such an object is required when parking.
Subsequent to the data acquisition and labeling, the data needs
to be preprocessed in a way that allows the feeding into the
proposed neural network and optimizes performance.

III. PREPROCESSING AND DATA PREPARATION

The output of the ultrasonic sensor is just

the voltage
of the piezoelectric element. After an active ﬁlter cascade,
the data is converted to digital. This allows us to analyze
different processing methods. We divided the processing into
two different steps:

1) Signal conditioning
2) Reorganization

they are described in more detail

As each part of the processing contains different processing
steps,
in the following.
Basically the signal conditioning is used to improve the
ultrasonic signal itself, whereas the restructuring is applied
to make the data suitable to be fed in a neural network.

A. Signal conditioning

The ultrasonic raw data sr is sampled with a sampling
frequency of 110 kHz to meet the Nyquist sampling theorem.
After the analog-to-digital conversion, a digital band-pass ﬁlter
is used to reduce noise and to remove the DC offset that
is necessary for the conversion. We use a high order ﬁnite
impulse response ﬁlter sb in order to avoid non-linear phase
distortion. The noise reduced signal sp1 results from:

sp1 “ sr ˚ sb

The signal is converted to the complex baseband afterwards.
This is done in two steps. First we use an IQ-mixer to remove
the carrier frequency fc of the signal:

(1)

(2)

Fig. 2. Valeo ultrasonic sensor used for measurements and classiﬁcation

sp2 “ sp1 ¨ expr´2jπfcts

Subsequently, we suppress image frequencies by a low-pass
ﬁlter with the ﬁlter response sl. The output of the ﬁlter is:

sp “ sp2 ˚ sl

(3)

This is in fact the complex envelope of the ultrasonic raw
signal. As the ﬁlters are adapted to the transmit signal, the
down conversion of the signal can be done without any
loss of information, i.e. all information of the signal that is
available in the raw data is also available in the complex
envelope [12]. The loss-free implementation is essential for
the following classiﬁcation, as the proposed method avoids
any reduction of the classiﬁcation accuracy in this way. The
signal conditioning is summarized in Fig. 3.

B. Reorganization

The previous processing was necessary to remove noise
and other unwanted disturbances from the signal. The aim of
the reorganization procedure is completely different. Beside
the reformatting of the data, so that it can be fed to the
neural network, we compress the envelope data and optimize
it for classiﬁcation speed. An overview over the reorganization
process is given in Fig. 4.
In a ﬁrst step we perform a down-sampling to reduce the
number of data points that need to be handled by the neural
network. Although the signal is in complex baseband, the
sampling frequency of the signal was not changed so far.
It is still 110 kHz. Using a measurement duration of 30 ms,
3,300 measurement points per measurement are available.
After the conversion to the complex baseband, the highest
available frequency is given by the bandwidth of the signal
that is 3 kHz. Consequently, we can reduce the number of data
points drastically. To avoid any loss of information even with
varying temperature that changes the resonance frequency of
the membrane, we choose a sampling frequency of 6.5 kHz.
This reduces the number data points of the envelope to 196.
The number of input neurons for the neural networks is
reduced by a factor of 16.8. Additionally the number of
calculations in deeper layers decreases, so that a signiﬁcant
improvement in the classiﬁcation speed is achieved.
To further optimize the prediction speed, we rearrange the
ultrasonic data. The ultrasonic data that is of dimension 196ˆ1
is reshaped to a complex data array of dimension 14 ˆ 14.
The two dimensional shape allows the use of two dimensional
convolutional kernels and a two dimensional pooling that
reduces computational complexity.
To apply methods from image classiﬁcation, where CNNs and
CapsNets are mainly used, the ultrasonic data is rescaled and
quantized to 16 bits. As the analog to digital conversion is

done using 12 bits, information is not lost. The advantage is
that the data can be stored in an suitable graphics format, such
as portal network graphics.
Principally, it is possible to just store the absolute values of
the envelope in a gray-scale graphic. We will show in section
V that this would lead to a degradation of the classiﬁcation
performance. Hence, real and imaginary part of the complex
envelope need to be considered. As we use standard graphics
format, the real and the imaginary parts can be saved in
different color channels of a graphic. An example that uses the
red and the green channel is shown in Fig. 5. The proposed
method is additionally advantageous as we can use the channel
representation in the neural network to handle the complex
input data.
Summarizing, the preprocessing and data preparation is used
to improve the signal quality of the raw signal by ﬁltering
and the conversion to the complex baseband. Downsampling
and reshaping lead to a reduction of the processing time. The
conversion of the complex ultrasonic data into a conventional
graphics format using two color channels allows the applica-
tion of existing network topologies that are mainly used in
image processing, e.g. CapsNets.

IV. CLASSIFICATION METHOD

Due to the format of the processed ultrasonic data as two
dimensional array with two channels, we can basically apply
a wide variety of neural networks. However, a computational
efﬁcient implementation must be used in order to meet the
requirements in automotive applications and to ﬁt in standard
processing units. Additionally, applying a two dimensional
CNN assumes that there is a physical meaning in the vertical
neighborhood of amplitude values in the reshaped data. As
this is obviously not the case, the application of conventional
CNNs is not effective.
CapsNets preserve the location of the amplitude values, so
that merging physically not linked amplitude values is avoided.
Furthermore CapsNets come up with an outstanding classiﬁca-
tion performance. This helps to compensate the low hardware
performance of automotive ultrasonic systems. Altogether
CapsNets turn out to be the best suited network topology to
perform the height classiﬁcation on our ultrasonic dataset. Due
to our particular dataset, we need to adjust the method that is
introduced in [10]. A detailed description of our used network
is given in the following.

Fig. 4. Reorganization steps

Fig. 5.
channel: imaginary part)

Complex image for network input (red channel: real part, green

Fig. 6. Architecture of CapsNet

The network consists of four layers. The ﬁrst layer is convo-
lutional layer with 128 convolutional kernels. Each kernel is
6ˆ6. The stride in this layer is one. We use a RELU activation
function for computational efﬁciency.
The second layer again applies a convolutional kernel. We
use a kernel of 4 ˆ 4. Again the stride is chosen to 1
and the activation function is RELU. Additionally,
to the
convolutional step, the second layer reshapes and rearranges
the data. The data is split into 32 separate parts. These parts
are called primary capsules in the following. Each capsule has
a dimension of 6 ˆ 6 ˆ 8.
The capsules are weighted by speciﬁc weight matrices W ij,
before the routing process is applied. The dimensions of the
weight matrices are 8 ˆ 8. The routing is the crucial step in
CapsNets. We use a standard routing-by-agreement approach.
This method is sufﬁcient. Indeed, the more advanced EM-
routing comes up with additional functionality that is on the
one hand not needed in our application and on the other hand is
computational more complex. Hence, we focus on the simpler
method. The results of the routing are digit capsules. As there
are four different height classes, we also get four digit capsules
of dimension 1 ˆ 8 each.
The loss of the network is calculated using a separate margin
loss, as described in [10]:

(4)

Lk “ Tk maxp0, m` ´ }vk}q2`
λp1 ´ Tkq maxp0, }vk} ´ m´q2
where Tk is a ﬂag if the sample is of class k and vk are the
digit capsules. m` and m´ are the decision factors and λ is
a weighting factor. For the training procedure, the overall loss
can be calculated from the sum of the individual losses.For
the decision in the prediction, the maximum of the L2-norms
of all digit capsules is decisive.
An illustrative summary of the proposed network architecture
is given in Fig. 6.

V. IMPLEMENTATION AND VALIDATION
To train the neural network and to validate the proposed
classiﬁcation method, a dataset of 21,600 different measure-
ments has been created. We equalize the number of mea-
surements per class in training and validation data set avoid

offsets in the classiﬁcation and interpretation. The equalized
dataset contains 4,800 shufﬂed measurements from the orig-
inal dataset. We split the shufﬂed dataset into training and
validation dataset. Due to the high amount of data, a holdout
validation is used with 960 measurements. By covering differ-
ent environmental conditions, we ensure the usability of the
trained network for realistic driving scenarios.
We implement the network using Tensorﬂow. Adam optimizer
is used to train the network. Stochastic batches with 100
elements are used to determine the weights and biases of the
network.
At ﬁrst, the network architecture is evaluated with the complex
ultrasonic data. To illustrate the outstanding performance of
the proposed approach,
the confusion matrix is shown in
Table I. The matrix is based on the validation data that has 960
measurements. The classes are named: ”lowest”, ”low”, ”high”
and ”highest”. The calculated overall validation accuracy is
99.6%. To evaluate the classiﬁcation in detail, we additionally
need to have a look on the confusion matrix. Our dataset
contains 480 actual ”low” and ”lowest” objects. The predicted
output of network has 476 objects that are of class ”low” and
”lowest”. Hence, the network tends to predict low objects to
high. As it is less bad stopping in front of a drivable object
than driving against a non-drivable object, this tendency is
acceptable for autonomous driving applications. Furthermore,
the confusion matrix shows that only ”lowest” objects are
wrongly classiﬁed as ”high”. A possible solution to handle
such cases is a conﬁrmation of the object height by at least
two measurements. This approach is applicable because of the
outstanding accuracy. By considering two or more sequential
measurements in a realistic scenario, the height classiﬁcation

TABLE I
CONFUSION MATRIX OF CAPSNET FOR VALIDATION DATASET

Actual

lowest
low
high
highest

lowest
236
0
4
0

low
0
240
0
0

high
0
0
240
0

highest
0
0
0
240

Predicted

achieves accuracies that are suitable for autonomous driving.
Autonomous driving additionally requires a real-time process-
ing of the ultrasonic data. The prediction time on a Nvidia
Quadro M2000M is about 178 µs per step. This value can be
further improved by optimizing the implementation. As one
measurement cycle of an ultrasonic signal requires at least
30 ms due to propagation effects and the detection range that
needs to be covered. Consequently, the proposed method is
already suited well for real-time classiﬁcation even if other
algorithms need to run simultaneously on the in-car processing
unit and the processing is low-performance.
If necessary, the processing effort and the amount of data
to be fed to the network can be further reduced by using
the absolute values of the envelope. This approach is of
increased interest, as automotive ultrasonic sensors do usually
not provide complex envelope data. By calculating the absolute
value of the envelope the signal phase is lost. This information
loss also affects the performance of the CapsNet. When
applying the same network architecture as before and the
same measurement samples, a validation accuracy of only
90.6% is achieved. Consequently,
the loss of information
leads to the expected drop of the classiﬁcation accuracy. Due
to the performance degradation it is recommended to use
complex input data if possible. However, the accuracy is still
sufﬁcient for ultrasonic height classiﬁcation, especially if the
classiﬁcation is supported by a conﬁrmation using subsequent
measurements.
In addition to the CapsNet approaches, we tested our data
using a conventional CNN. To create comparable results, we
use the same datasets than for the CapsNets. Also the network
architecture is very similar, as the ﬁrst two layers are the
same. After the second layer we use a conventional maximum
pooling layer with a size of 2 ˆ 2. The routing-by-agreement
step is replaced by a dense layer with 64 neurons followed by
an output layer that uses softmax activation. The cost function
is a categorical crossentropy.
As before, the network is tested with complex input data
ﬁrst. The yielded validation accuracy is 98.9%. The decrease
of the accuracy results from the pooling layer. In addition,
the CNN does not preserve the amplitude locations so that
an additional error is produced. The error in our dataset is
only 0.7%. The prediction time increased to 213 µs per step.
Consequently the proposed CapsNet approach does not only
provide better validation accuracy, but furthermore requires
less computational effort.
In case of feeding the network with the absolute valued data,
a decrease in the validation accuracy can be observed. The
reached accuracy is only 87.8%. Compared to the CapsNet
approach but also to the complex CNN method, the degrada-
tion of the accuracy is signiﬁcant. Although the calculation
time is 199 µs and thus lower than in the complex CNN
method, the accuracy is 2.8% lower than in the absolute valued
CapsNet approach. Even if subsequent measurements are used
to conﬁrm the classiﬁcation height,
the suitability of this
approach for autonomous driving must be strictly evaluated.
The results of the CapsNet- and CNN-based classiﬁcation

TABLE II
COMPARISON OF CAPSNET- AND CNN-BASED APPROACHES

Complex CapsNet
Absolute CapsNet
Complex CNN
Absolute CNN

Validation Accuracy
99.6%
90.6%
98.9%
87.8%

Prediction Time
178 µs
170 µs
213 µs
199 µs

are summarized in Table II. Considering both, accuracy and
computational effort, the proposed CapsNet-based classiﬁca-
tion approach that uses complex input data shows the best
performance. If absolute valued input data is available only,
the CapsNet method also performs better than the CNN-based
approach. As it can be seen from the table, our proposed
method shows an outstanding performance for classiﬁcation
and is suited well for the integration in real-time ultrasonic
systems for automotive scenarios due to the improved predic-
tion time.

VI. CONCLUSION

CapNets are an upcoming network architecture that can
be used in a wide variety of applications. In the paper, we
show how to apply this network type to ultrasonic data from
automotive ultrasonic sensors to classify object height. In
contrast to image-based classiﬁcation the ultrasonic raw data
does not allow an easy data interpretation by human. Thus
we apply a special preprocessing on the ultrasonic data ﬁrst.
The preprocessing improves the signal quality and optimizes
classiﬁcation performance. Subsequently, we use a CapsNet
with routing-by-agreement. By feeding the network with the
complex envelope data of ultrasonic measurements, validation
accuracies of more than 99% are reached. A comparison
to conventional CNN-based approaches additionally shows
improved classiﬁcation accuracy and reduced computational
effort of CapsNets.
Object classiﬁcation using automotive ultrasonic sensors is still
at the beginning. Height classiﬁcation is just one example
where deep learning is applicable. There are lots of other
object properties, such as width, material or speed, where
classiﬁcation algorithms can help to improve the functionality
of ultrasonic sensors.
The limitation to a single ultrasonic sensor is also not neces-
sary at all. Using a couple of sensors, e.g. in a front bumper, or
subsequent measurements allows to determine further object
properties and to increase the classiﬁcation accuracy.
Altogether the potential of classiﬁcation in automotive ul-
trasonic sensor technology is enormous. However, a lot of
research and testing is required to evaluate the scope of ultra-
sonic object classiﬁcation and to make ultrasonic technology
suitable for autonomous driving.

VII. ACKNOWLEDGMENT

For his constructive comments and input, we thank Martin
Simon. Further we are grateful to Paul Rostocki for providing
the ultrasonic sensors and Dr. Heinrich Gotzig for the technical
supervising.

REFERENCES

1 Lee, Y. and Chang, S., “Development of a veriﬁcation method on
ultrasonic-based perpendicular parking assist system,” in The 18th IEEE
International Symposium on Consumer Electronics (ISCE 2014), June
2014, pp. 1–3.

2 H. Jeong, S., G. Choi, C., and N. Oh, J., “Low cost design of parallel
parking assist system based on an ultrasonic sensor,” vol. 11, pp. 409–416,
06 2010.

3 Bozma, H. I. and Kemik, E., “Model-based multi-objective analysis of
ultrasound image sequences in prenatal diagnosis,” in Proceedings of
IEEE Computer Society Conference on Computer Vision and Pattern
Recognition, Jun 1997, pp. 942–947.

4 Wu, W.-J., Lin, S.-W., and Moon, W. K., “Combining support vector
tumor
machine with genetic algorithm to classify ultrasound breast
images,” Computerized Medical Imaging and Graphics, vol. 36, no. 8,
pp. 627 – 633, 2012. [Online]. Available: http://www.sciencedirect.com/
science/article/pii/S0895611112001310

5 Nugroho, H. A., Rahmawaty, M., Triyani, Y., Ardiyanto, I., Choridah, L.,
and Indrastuti, R., “Texture analysis and classiﬁcation in ultrasound
medical images for determining echo pattern characteristics,” in 2017 7th
IEEE International Conference on System Engineering and Technology
(ICSET), Oct 2017, pp. 23–26.

6 Yap, M. H., Pons, G., Mart´ı, J., Ganau, S., Sent´ıs, M., Zwiggelaar, R.,
Davison, A. K., and Mart´ı, R., “Automated breast ultrasound lesions de-
tection using convolutional neural networks,” IEEE Journal of Biomedical
and Health Informatics, pp. 1–1, 2018.

7 Yang, X., Yu, L., Wu, L., Wang, Y., Ni, D., Qin, J., and Heng, P.-A., “Fine-
grained recurrent neural networks for automatic prostate segmentation in
ultrasound images,” 2016.

8 Li, Y. D., “Segmentation of medical ultrasound images using convolutional

neural networks with noisy activating functions,” 2016.

9 Byra, M., Sznajder, T., Korzinek, D., Piotrzkowska-Wroblewska, H.,
Dobruch-Sobczak, K., Nowicki, A., and Marasek, K., “Impact of ultra-
sound image reconstruction method on breast lesion classiﬁcation with
neural transfer learning,” 2018.

10 Sabour, S., Frosst, N., and Hinton, G. E., “Dynamic routing between
[Online]. Available:

capsules,” CoRR, vol. abs/1710.09829, 2017.
http://arxiv.org/abs/1710.09829

11 Hinton, G. E., Sabour, S., and Frosst, N., “Matrix capsules with EM
routing,” in International Conference on Learning Representations, 2018.
[Online]. Available: https://openreview.net/forum?id=HJWLfGWRb
12 Proakis, J., Digital Communications, ser. Electrical engineering series.
McGraw-Hill, 2001. [Online]. Available: https://books.google.de/books?
id=sbr8QwAACAAJ

