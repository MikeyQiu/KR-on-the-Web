Semantic Relation Classiﬁcation via Convolutional Neural Networks with
Simple Negative Sampling

Kun Xu1, Yansong Feng1, Songfang Huang2, Dongyan Zhao1
1Institute of Computer Science & Technology, Peking University, Beijing, China
2IBM China Research Lab, Beijing, China
{xukun, fengyansong, zhaodongyan}@pku.edu.cn, huangsf@cn.ibm.com

Abstract

Syntactic features play an essential role
in identifying relationship in a sentence.
Previous neural network models often suf-
fer from irrelevant information introduced
when subjects and objects are in a long
distance.
In this paper, we propose to
learn more robust relation representations
from the shortest dependency path through
a convolution neural network. We fur-
ther propose a straightforward negative
sampling strategy to improve the assign-
ment of subjects and objects. Experimen-
tal results show that our method outper-
forms the state-of-the-art methods on the
SemEval-2010 Task 8 dataset.

1

Introduction

The relation extraction (RE) task can be deﬁned as
follows: given a sentence S with a pair of nomi-
nals e1 and e2, we aim to identify the relationship
between e1 and e2. RE is typically investigated
in a classiﬁcation style, where many features have
been proposed, e.g., Hendrickx et al. (2010) de-
signed 16 types of features including POS, Word-
Net, FrameNet, dependency parse features, etc.
Among them, syntactic features are considered to
bring signiﬁcant improvements in extraction accu-
racy (Bunescu and Mooney, 2005a). Earlier at-
tempts to encode syntactic information are mainly
kernel-based methods, such as the convolution tree
kernel (Qian et al., 2008), subsequence kernel
(Bunescu and Mooney, 2005b), and dependency
tree kernel (Bunescu and Mooney, 2005a).

With the recent success of neural networks in
NLP, different neural network models are pro-
posed to learn syntactic features from raw se-
quences of words or constituent parse trees(Zeng
et al., 2014; Socher et al., 2012), which have been
proved effective, but, often suffer from irrelevant

subsequences or clauses, especially when subjects
and objects are in a longer distance. For exam-
ple, in the sentence, “The [singer]e1 , who per-
formed three of the nominated songs, also caused a
[commotion]e2 on the red carpet”, the who clause
is used to modify subject e1, but is unrelated to
the Cause-Effect relationship between singer and
commotion. Incorporating such information into
the model will hurt the extraction performance.
We therefore propose to learn a more robust rela-
tion representation from a convolution neural net-
work model that works on the simple dependency
path between subjects and objects, which naturally
characterizes the relationship between two nomi-
nals and avoids negative effects from other irrele-
vant chunks or clauses.

Our second contribution is the introduction of
a negative sampling strategy into the CNN mod-
els to address the relation directionality, i.e., prop-
erly assigning the subject and object within a re-
lationship. In the above singer example, (singer,
commotion) hold the Cause-Effect relation, while
(commotion, singer) not. Previous works do not
fully investigate the differences between subjects
and objects in the utterance, and simply transform
a (K+1)-relation task into a (2×K+1) classiﬁca-
tion task, where 1 is the other relation. Interest-
ingly, we ﬁnd that dependency paths naturally of-
fer the relative positions of subjects and objects
through the path directions. In this paper, we pro-
pose to model the relation directionality by ex-
ploiting the dependency path to learn the assign-
ments of subjects and objects using a straightfor-
ward negative sampling method, which adopts the
shortest dependency path from the object to the
subject as a negative sample. Experimental results
show that the negative sampling method signiﬁ-
cantly improves the performance, and our model
outperforms the-state-of-the-art methods on the
SemEval-2010 Task 8 dataset.

5
1
0
2
 
n
u
J
 
5
2
 
 
]
L
C
.
s
c
[
 
 
1
v
0
5
6
7
0
.
6
0
5
1
:
v
i
X
r
a

Figure 1: The shortest dependency path representation for an example sentence from SemEval-08.

2 The Shortest Path Hypothesis

3 A Convolutional Neural Network

If e1 and e2 are two nominals mentioned in the
same sentence, we assume that the shortest path
between e1 and e2 describes their relationship.
This is because (1) if e1 and e2 are arguments of
the same predicate, then their shortest path should
pass through that predicate; (2) if e1 and e2 belong
to different predicate-argument structures,
their
shortest path will pass through a sequence of pred-
icates, and any consecutive predicates will share
a common argument. Note that, the order of the
predicates on the path indicates the proper assign-
ments of subjects and objects for that relation. For
example, in Figure 1, the dependency path consec-
utively passes through carried and receives, which
together implies that in the Instrument-Agency re-
lation, the subject and object play a sender and re-
ceiver role, respectively.

Model

Our model successively takes the shortest depen-
dency path (i.e, the words, dependency edge direc-
tions, and dependency labels) from the subject to
the object as input, passes it through the lookup
table layer, produces local features around each
node on the dependency path, and combines these
features into a global feature vector that are then
fed to a softmax classiﬁer. Each dimension of the
output vector indicates the conﬁdence score of the
corresponding relation.

In the lookup table step, each node (i.e. word,
label or arrow) in the dependency path is trans-
formed into a vector by looking up the embedding
matrix We ∈ Rd×|V|, where d is the dimension of
a vector and V is a set of all nodes we consider.

Convolution To capture the local
features
around each node of the dependency path, we con-
sider a ﬁxed size window of nodes around each
node in the window processing component, pro-
ducing a matrix of node features of ﬁxed size
dw × 1, where dw = d × w and w is the window
size. This matrix can be built by concatenating the
vectors of nodes within the window.

In the convolutional layer, we use a linear trans-
formation W1 ∈ Rn1×dw to extract local features
around each window of the given sequence, where
n1 is the size of hidden layer 1. The resulting ma-
trix Z has size of n1 × t, where t is the number of
nodes in the input dependency path.

We can see that Z captures local contextual in-
formation in the dependency path. Therefore, we
perform a max pooling over Z to produce a global
feature vector in order to capture the most useful
local features produced by the convolutional layer
(Collobert et al., 2011), which has a ﬁxed size of
n1, independent of the dependency path length.

Dependency based Relation Representation
To extract more meaningful features, we choose
hyperbolic tanh as the non-linearity function in the
second hidden layer, which has the advantage of
being slightly cheaper to compute, while leaving

Figure 2: Architecture of the convolution neural
network.

Train Strategy
Blind
Sighted
Sighted

Test Strategy
Blind
Blind
Sighted

F1(%)
79.3
81.3
89.2

Table 1: Performances on the development set
with different train and testing strategies.

the generalization performance unchanged. W2 ∈
Rn2×n1 is the linear transformation matrix, where
n2 is the size of hidden layer 2. The output vec-
tor can be considered as higher level syntactic fea-
tures, which is then fed to a softmax classiﬁer.

Objective Function and Learning The softmax
classiﬁer is used to predict a K-class distribution
d(x), where K is the size of all possible rela-
tion types, and the transformation matrix is W3 ∈
RK×n2. We denote t(x) ∈ RK×1 as the target
distribution vector1: the entry tk(x) is the proba-
bility that the dependency path describes the k-th
relation. We compute the cross entropy error be-
tween t(x) and d(x), and further deﬁne the objec-
tive function over all training data:

J(θ) = −

tk(x) log dk(x) + λ||θ||2

(cid:88)

K
(cid:88)

x

k=1

where θ = (We, W1, W2, W3) is the set of model
parameters to be learned, and λ is a vector of reg-
ularization parameters. The model parameters θ
can be efﬁciently computed via backpropagation
through network structures. To minimize J(θ),
we apply stochastic gradient descent (SGD) with
AdaGrad (Duchi et al., 2011) in our experiments2.

4 Negative Sampling

We start by presenting three pilot experiments on
the development set. In the ﬁrst one, we assume
that the assignment of the subject and object for
a relation is not given (blind), we simply extract
features from e1 to e2, and test it in a blind set-
ting as well. In the second one, we assume that
the assignment is given (sighted) during training,
but still blind in the test phase. The last one is as-
sumed to give the assignment during both training
and test steps. The results are listed in Table 1.

The third experiment can be seen as an upper
bound, where we do not need to worry about the

1Note that, there may be more than one relation existing
between two nominals. A dependency path thus may corre-
spond to multiple relations.

2We omit detailed formulas for the limitation of space.

assignments of subjects and objects. By com-
paring the ﬁrst and the second one, we can see
that when adding assignment information during
training, our model can be signiﬁcantly improved,
indicating that our dependency based representa-
tion can be used to learn the assignments of sub-
jects/objects, and injecting better understandings
of such assignments during training is crucial to
the performance. We admit that models with more
complex structures can better handle these con-
siderations. However, we ﬁnd that this can be
achieved by simply feeding typical negative sam-
ples to the model and let the model learn from such
negative examples to correctly choose the right as-
signments of subjects and objects. In practice, we
can treat the opposite assignments of subjects and
the objects as negative examples. Note that, the
dependency path of the wrong assignment is dif-
ferent from that of the correct assignment, which
essentially offers the information for the model to
learn to distinguish the subject and the object.

5 Experimental Evaluation

We evaluate our model on the SemEval-2010 Task
8 (Hendrickx et al., 2010), which contains 10,717
annotated examples, including 8,000 instances for
training and 2,717 for test. We randomly sampled
2,182 samples from the training data for valida-
tion.

Given a sentence, we ﬁrst ﬁnd the shortest de-
pendency path connecting two marked nominals,
resulting in two dependency paths corresponding
to two opposite subject/object directions, and then
make predictions for the two paths, respectively.
We choose the relation other if and only if both
predictions are other. And for the rest cases, we
choose the non-other relation with highest conﬁ-
dence as the output, since ideally, for a non-other
instance, our model will output the correct label
for the right subject/object direction and an other
label for the wrong direction. We evaluate our
models by macro-averaged F1 using the ofﬁcial
evaluation script.

We initialized We with 50-dimensional word
vectors trained by Turian et al. (2010). We tuned
the hyper parameters using the development set for
each experimental setting. The hyper parameters
include w, n1, n2, and regularization parameters
for We, W1, W2 and W3. The best setting was ob-
tained with the values: 3, 200, 100, 10−4, 10−3,
10−4 and 2 × 10−3, respectively.

Method
SVM
RNN

MVRNN

CNN
(Zeng et al., 2014)
depCNN
depLCNN
depLCNN
depLCNN+NS

Feature Sets
16 types of features
-
+POS, NER, WordNet
-
+POS, NER, WordNet
-
+WordNet,words around nominals
-
-
+WordNet,words around nominals
-
+WordNet,words around nominals

F1
82.2
74.8
77.6
79.1
82.4
78.9
82.7
81.3
81.9
83.7
84.0
85.6

Table 2: Comparisons of our models with other
methods on the SemEval 2010 task 8.

Negative sampling schemes
No negative examples
Randomly sampled negative examples from NYT
Dependency paths from the object to subject

F1
81.3
83.5
85.4

Table 3: Comparisons of different negtive sam-
pling methods on the development set.

Results and Discussion Table 2 summarizes the
performances of our model, depLCNN+NS(+),
and state-of-the-art models, SVM(Hendrickx et
al., 2010), RNN, MV-RNN(Socher et al., 2012),
and CNN(Zeng et al., 2014). For fair comparisons,
we also add two types of lexical features, WordNet
hypernyms and words around nominals, as part of
input vector to the ﬁnal softmax layer.

We can see that our vanilla depLCNN+NS,
without extra lexical features, still outperforms, by
a large margin, previously reported best systems,
MVRNN+ and CNN+, both of which have taken
extra lexical features into account, showing that
our treatment to dependency path can learn a ro-
bust and effective relation representation. When
augmented with similar lexical features, our de-
pLCNN+NS further improves by 1.6%, signiﬁ-
cantly better than any other systems.

Let us ﬁrst see the comparisons among plain
versions of depLCNN (taking both dependency di-
rections and labels into account), depCNN (con-
sidering the directions of dependency edges only),
MVRNN and CNN, which all work in a 2×K+1
fashion. We can see that the both of our depCNN
and depLCNN outperforms MVRNN and CNN by
at least 2.2%, indicating that our treatment is better
than previous conventions in capturing syntactic
structures for relation extraction. And note that de-
pLCNN, with extra considerations for dependency
labels, performs even better than depCNN, show-
ing that dependency labels offer more discrimina-

tive information that beneﬁts the relation extrac-
tion task.

And when we compare plain depLCNN and
depLCNN+NS (without lexical features), we can
see that our Negative Sampling strategy brings an
improvement of 2.1% in F1. When both of the
two models are augmented with extra lexical fea-
tures, our NS strategy still gives an improvement
of 1.9%. These comparisons further show that our
NS strategy can drive our model to learn proper
assignments of subjects/objects for a relation.

Next, we will have a close look at the effect
of our Negative Sampling method. We conduct
additional experiments on the development set to
compare two different negative sampling methods.
As a baseline, we randomly sampled 8,000 nega-
tive examples from the NYT dataset (Chen et al.,
2014). For our proposed NS, we create a nega-
tive example from each non-other instance in the
training set, 6,586 in total. As shown in Table 2,
it is no doubt that introducing more negative ex-
amples improves the performances. We can see
that our model still beneﬁts from the randomly
sampled negative examples, which may help our
model learn to reﬁne the margin between the pos-
itive and negative examples. However, with sim-
ilar amount of negative examples, treating the re-
versed dependency paths from objects to subjects
as negative examples can achieve a better perfor-
mance (85.4% F1), improving random samples by
1.9%. This again proves that dependency paths
provide useful clues to reveal the assignments of
subjects and objects, and a model can learn from
such reversed paths as negative examples to make
correct assignments. Beyond the relation extrac-
tion task, we believed the proposed Negative Sam-
pling method has the potential to beneﬁt other
NLP tasks, which we leave for future work.

6 Conclusion

In this paper, we exploit a convolution neural net-
work to learn more robust and effective relation
representations from shortest dependency paths
for relation extraction. We further propose a sim-
ple negative sampling method to help make cor-
rect assignments for subjects and objects within
a relationship. Experimental results show that
our model signiﬁcantly outperforms state-of-the-
art systems and our treatment to dependency paths
can well capture the syntactic features for relation
extraction.

[Turian et al.2010] Joseph P. Turian, Lev-Arie Ratinov,
and Yoshua Bengio. 2010. Word representations:
A simple and general method for semi-supervised
In ACL 2010, Proceedings of the 48th
learning.
Annual Meeting of the Association for Computa-
tional Linguistics, July 11-16, 2010, Uppsala, Swe-
den, pages 384–394.

[Zeng et al.2014] Daojian Zeng, Kang Liu, Siwei Lai,
Guangyou Zhou, and Jun Zhao. 2014. Relation
classiﬁcation via convolutional deep neural network.
In Proceedings of COLING 2014, the 25th Inter-
national Conference on Computational Linguistics:
Technical Papers, pages 2335–2344, Dublin, Ire-
land, August. Dublin City University and Associa-
tion for Computational Linguistics.

References

[Bunescu and Mooney2005a] Razvan C. Bunescu and
2005a. A shortest path
Raymond J. Mooney.
dependency kernel for relation extraction.
In
HLT/EMNLP 2005, Human Language Technology
Conference and Conference on Empirical Methods
in Natural Language Processing, Proceedings of the
Conference, 6-8 October 2005, Vancouver, British
Columbia, Canada.

[Bunescu and Mooney2005b] Razvan C. Bunescu and
Raymond J. Mooney. 2005b. Subsequence kernels
In Advances in Neural In-
for relation extraction.
formation Processing Systems 18 [Neural Informa-
tion Processing Systems, NIPS 2005, December 5-8,
2005, Vancouver, British Columbia, Canada], pages
171–178.

[Chen et al.2014] Liwei Chen, Yansong Feng, Song-
fang Huang, Yong Qin, and Dongyan Zhao. 2014.
Encoding relation requirements for relation extrac-
tion via joint inference. In Proceedings of the 52nd
Annual Meeting of the Association for Computa-
tional Linguistics, ACL 2014, June 22-27, 2014,
Baltimore, MD, USA, Volume 1: Long Papers, pages
818–827.

[Collobert et al.2011] Ronan Collobert, Jason Weston,
L´eon Bottou, Michael Karlen, Koray Kavukcuoglu,
and Pavel P. Kuksa. 2011. Natural language pro-
cessing (almost) from scratch. Journal of Machine
Learning Research, 12:2493–2537.

[Duchi et al.2011] John C. Duchi, Elad Hazan, and
Yoram Singer. 2011. Adaptive subgradient meth-
ods for online learning and stochastic optimization.
Journal of Machine Learning Research, 12:2121–
2159.

[Hendrickx et al.2010] Iris Hendrickx, Su Nam Kim,
Zornitsa Kozareva, Preslav Nakov, Diarmuid ´O
S´eaghdha, Sebastian Pad´o, Marco Pennacchiotti,
2010.
Lorenza Romano, and Stan Szpakowicz.
Semeval-2010 task 8: Multi-way classiﬁcation of se-
mantic relations between pairs of nominals. In Pro-
ceedings of SemEval-2, Uppsala, Sweden.

[Qian et al.2008] Longhua Qian, Guodong Zhou, Fang
Kong, Qiaoming Zhu, and Peide Qian. 2008. Ex-
ploiting constituent dependencies for tree kernel-
In COLING
based semantic relation extraction.
2008, 22nd International Conference on Computa-
tional Linguistics, Proceedings of the Conference,
18-22 August 2008, Manchester, UK, pages 697–
704.

[Socher et al.2012] Richard Socher, Brody Huval,
Christopher D. Manning, and Andrew Y. Ng.
2012. Semantic compositionality through recursive
In Proceedings of the 2012
matrix-vector spaces.
Joint Conference on Empirical Methods in Natural
Language Processing and Computational Natural
Language Learning, EMNLP-CoNLL 2012, July
12-14, 2012, Jeju Island, Korea, pages 1201–1211.

