5
1
0
2
 
n
u
J
 
0
3
 
 
]
L
C
.
s
c
[
 
 
3
v
9
9
5
7
0
.
5
0
5
1
:
v
i
X
r
a

Overview of the NLPCC 2015 Shared Task:
Chinese Word Segmentation and POS Tagging for
Micro-blog Texts

Xipeng Qiu, Peng Qian, Liusong Yin, Shiyu Wu, Xuanjing Huang
School of Computer Science, Fudan University
825 Zhangheng Road, Shanghai, China
{xpqiu,pqian11,lsyin14,sywu13,xjhuang}@fudan.edu.cn

Abstract

In this paper, we give an overview for the shared task at the 4th CCF
Conference on Natural Language Processing & Chinese Computing (NLPCC
2015): Chinese word segmentation and part-of-speech (POS) tagging for
micro-blog texts. Different with the popular used newswire datasets, the
dataset of this shared task consists of the relatively informal micro-texts. The
shared task has two sub-tasks: (1) individual Chinese word segmentation
and (2) joint Chinese word segmentation and POS Tagging. Each subtask
has three tracks to distinguish the systems with different resources. We ﬁrst
introduce the dataset and task, then we characterize the different approaches
of the participating systems, report the test results, and provide a overview
analysis of these results. An online system is available for open registration
and evaluation at http://nlp.fudan.edu.cn/nlpcc2015.

1 Introduction

Word segmentation and Part-of-Speech (POS) tagging are two fundamental tasks
for Chinese language processing. In recent years, word segmentation and POS tag-
ging have undergone great development. The popular method is to regard these two
tasks as sequence labeling problem [7, 5], which can be handled with supervised
learning algorithms such as Maximum Entropy (ME) [1], averaged perceptron [2],
Conditional Random Fields (CRF)[3]. After years of intensive researches, Chinese
word segmentation and POS tagging achieve a quite high precision. However, their
performance is not so satisfying for the practical demands to analyze Chinese texts,
especially for informal texts. The key reason is that most of annotated corpora are

1

drawn from news texts. Therefore, the system trained on these corpora cannot work
well with the out-of-domain texts.

In this shared task, we focus to evaluate the performances of word segmentation

and POS tagging on relatively informal micro-texts.

2 Data

Different with the popular used newswire dataset, we use relatively informal texts
from Sina Weibo1. The training and test data consist of micro-blogs from various
topics, such as ﬁnance, sports, entertainment, and so on. Both the training and test
ﬁles are UTF-8 encoded.

The information of dataset is shown in Table 1. The out-of-vocabulary (OOV)
rate is slight higher than the other benchmark datasets. For example, the OOV rate
is 5.58% in the popular division [9] of the Chinese Treebank (CTB 6.0) dataset [8],
while the OOV rate of our dataset is 7.25%.

Table 1: Statistical information of dataset.

Dataset
Training
Test
Total

Sents Words
215,027
10,000
106,327
5,000
322,410
15,000

Chars Word Types Char Types OOV Rate
347,984
171,652
520,555

28,208
18,696
35,277

-
7.25%
-

39,71
3,538
4,243

There are total 35 POS tags in this dataset. A detailed list of POS tags is shown

in Table 2.

1http://weibo.com/

2

Table 2: Statistical information of POS tags.

词性(POS)
名词

词性(POS)

Labels

En
NN
人名
PER
机构名
ORG
地名
LOC
其他
NR
邮件
EML
型号名
MOD
网址
URL
疑问副词 ADQ
副词
AD
形容词
JJ
形谓词
VA
动词
VV
情态词
MV
趋向动词 DV
被动词
BEI
把动词
BA
NT

Num
84,006
3,232
2,578
9,701
550
3
34
11
340
26,155
9,477
3,339
51,294
3,700
781
927
600
5,881

代词

连词

数量

助词

人称代词 PNP
疑问代词 PNQ
指示代词 PNI
并列连词 CC
从属连词 CS
数词
CD
量词
M
序数词
OD
方位词
LC
省略词
ETC
语气词
SP
限定词
DT
叹词
IJ
标点
PU
结构助词 DSP
介词
时态词

P
AS

Num
4,903
492
834
2,725
866
10,764
7,917
1,219
4,725
673
1,076
3,579
20
52,922
13,756
9,488
3,382

实体名

副词

形貌

动词

时间短语

2.1 Background Data

Besides the training data, we also provide the background data, from which the
training and test data are drawn. The purpose is to ﬁnd the more sophisticated
features by the unsupervised way.

3 Description of the Task

In this shared task, we wish to investigate the performances of Chinese word seg-
mentation and POS tagging for the micro-blog texts.

3.1 Subtasks

This task focus the two fundamental problems of Chinese language processing:
word segmentation and POS tagging, which can be divided into two subtasks:

1. SEG Chinese word segmentation

2. S&T Joint Chinese word segmentation and POS Tagging

3

3.2 Tracks

Each participant will be allowed to submit the three runs for each subtask: closed
track run, semi-open track run and open track run.

1. In the closed track, participants could only use information found in the
provided training data. Information such as externally obtained word counts,
part of speech information, or name lists was excluded.

2. In the semi-open track, participants could use the information extracted from
the provided background data in addition to the provided training data. Infor-
mation such as externally obtained word counts, part of speech information,
or name lists was excluded.

3. In the open track, participants could use the information which should be
public and be easily obtained. But it is not allowed to obtain the result by the
manual labeling or crowdsourcing way.

4 Participants

Sixteen teams have registered for this task. Finally, there are 27 qualiﬁed submitted
results from 10 teams. A summary of qualiﬁed participating teams are shown in
Table 3.

Table 3: Summary of the participants.

closed
√
√
√
√
√
√
√

SEG

open
√
√

√

√
√

NJU
BosonNLP
CIST
XUPT
CCNU
ICT-NLP
BJTU
SZU
ZZU
WHU

semi-open
√

closed

open

semi-open

S&T

√

√
√

√

√

√

√
√
√

√

√

√

√

√

4

5 Results

5.1 Evaluation Metrics

The evaluation measure are reported are precision, recall, and an evenly-weighted
F1.

5.2 Baseline Systems

Currently, the mainstream method of word segmentation is discriminative character-
based sequence labeling. Each character is labeled as one of {B, M, E, S} to indi-
cate the segmentation. {B, M, E} represent Begin, Middle, End of a multi-character
segmentation respectively, and S represents a Single character segmentation.

For the joint word segmentation and POS tagging, the state-of-the-art method
is also based on sequence learning with cross-labels, which can avoid the problem
of error propagation and achieve higher performance on both subtasks[4]. Each
label is the cross-product of a segmentation label and a tagging label, e.g. {B-NN,
I-NN, E-NN, S-NN, ...}. The features are generated by position-based templates
on character-level.

Sequence labeling is the task of assigning labels y = y1, . . . , yn to an input
sequence x = x1, . . . , xn. Given a sample x, we deﬁne the feature Φ(x, y). Thus,
we can label x with a score function,

ˆy = arg max

F (w, Φ(x, y)),

y

(1)

where w is the parameter of function F (·).

For sequence labeling, the feature can be denoted as φk(yi, yi−1, x, i), where
i stands for the position in the sequence and k stands for the number of feature
templates.

Here, we use two popular open source toolkits for sequence labeling task as
the baseline systems: FNLP2 [6] and CRF++3. Here, we use the default setting of
CRF++ toolkit with the feature templates as shown in Table 4. The same feature
templates are also used for FNLP.

5.3 Chinese word segmentation

In word segmentation task, the best F1 performances are 95.12, 95.52 and 96.65
for closed, semi-open and open tracks respectively. The best system outperforms
the baseline systems on closed track. The best system on semi-open track is better

2https://github.com/xpqiu/fnlp/
3http://taku910.github.io/crfpp/

5

Table 4: Templates of CRF++ and FNLP.

unigram feature

bigram feature
trigram feature

c−2, c−1, c0, c+1,
c+2
c−1 ◦ c0, c0 ◦ c+1
c−2 ◦ c−1 ◦ c0, c−1 ◦
c0◦c+1, c0◦c+1◦c+2

than that on closed track. Unsurprisingly, the performances boost greatly on open
track.

Table 5: Performances of word segmentation.

Systems
CRF++
FNLP
NJU
BosonNLP
CIST
XUPT
CCNU
ICT-NLP
BJTU
CIST
NJU
BJTU
ZZU
BosonNLP
NJU
SZU
CCNU
BJTU

Precision Recall
93.2
93.9
95.09
95.03
94.42
93.85
93.45
92.91
93.55
95.57
95.31
94.46
85.25
96.75
96.15
95.64
93.09
94.92

93.3
94.1
95.14
95.03
94.78
94.61
93.95
93.96
89.49
95.47
95.3
90.91
85.36
96.56
96.03
95.52
93.68
91.79

F1
93.3
94.0
95.12
95.03
94.6
94.22
93.7
93.43
91.48
95.52
95.3
92.65
85.31
96.65
96.09
95.58
93.38
93.33

Track

baseline, closed

closed

semi-open

open

5.4

Joint Chinese word segmentation and POS Tagging

In the joint word segmentation and POS tagging, the best performances are 88.93,
88.69 and 91.55 for closed, semi-open and open tracks respectively.

6

Table 6: Performances of joint word segmentation and POS tagging.

Systems
BosonNLP
XUPT
BJTU
CIST
BJTU
CIST
WHU
BJTU
BosonNLP
SZU
BJTU

Precision Recall
88.95
87.83
87.67
87.76
85.1
88.73
87.96
85.82
91.68
89.05
83.51

88.91
88.54
88.28
88.09
80.64
88.64
88.59
81.76
91.42
88.93
79.85

F1
88.93
88.19
87.97
87.92
82.81
88.69
88.27
83.74
91.55
88.99
81.64

Track

closed

semi-open

open

6 Analysis

7 Conclusion

After years of intensive researches, Chinese word segmentation and POS tagging
have achieved a quite high precision. However, the performances of the state-
of-the-art systems are still relatively low for the informal texts, such as micro-
blogs, forums. The NLPCC 2015 Shared Task on Chinese Word Segmentation and
POS Tagging for Micro-blog Texts focuses on the fundamental research in Chinese
language processing.

It is the ﬁrst time to use the micro-texts to evaluate the performance of the

state-of-the-art methods

In future work, we hope to run an online evaluation system to accept open
registration and submission. Currently, a simple system is available at http:
//nlp.fudan.edu.cn/nlpcc2015. The system also gives the leaderboards
for the up-to-date results under the different tasks and tracks. Besides, we also
wish to extend the scale of corpus and add more informal texts.

Acknowledgement

We are very grateful to the students from our lab for their efforts to annotate and
check the data. We would also like to thank the participants for their valuable
feedbacks and comments.

7

References

[1] A.L. Berger, V.J. Della Pietra, and S.A. Della Pietra. A maximum entropy ap-
proach to natural language processing. Computational Linguistics, 22(1):39–
71, 1996.

[2] Michael Collins. Discriminative training methods for hidden markov mod-
els: Theory and experiments with perceptron algorithms. In Proceedings of
the 2002 Conference on Empirical Methods in Natural Language Processing,
2002.

[3] John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira. Condi-
tional random ﬁelds: Probabilistic models for segmenting and labeling se-
In Proceedings of the Eighteenth International Conference on
quence data.
Machine Learning, 2001.

[4] H.T. Ng and J.K. Low. Chinese part-of-speech tagging: one-at-a-time or all-at-
once? word-based or character-based. In Proceedings of EMNLP, volume 4,
2004.

[5] F. Peng, F. Feng, and A. McCallum. Chinese segmentation and new word de-
tection using conditional random ﬁelds. Proceedings of the 20th international
conference on Computational Linguistics, 2004.

[6] Xipeng Qiu, Qi Zhang, and Xuanjing Huang. FudanNLP: A toolkit for Chi-
In Proceedings of Annual Meeting of the

nese natural language processing.
Association for Computational Linguistics, 2013.

[7] N. Xue. Chinese word segmentation as character tagging. Computational

Linguistics and Chinese Language Processing, 8(1):29–48, 2003.

[8] Naiwen Xue, Fei Xia, Fu-Dong Chiou, and Martha Palmer. The Penn Chinese
TreeBank: Phrase structure annotation of a large corpus. Natural language
engineering, 11(2):207–238, 2005.

[9] Yaqin Yang and Nianwen Xue. Chinese comma disambiguation for discourse
In Proceedings of the 50th Annual Meeting of the Association for
analysis.
Computational Linguistics: Long Papers-Volume 1, pages 786–794. Associa-
tion for Computational Linguistics, 2012.

8

