Robust, Deep and Inductive Anomaly Detection

Raghavendra Chalapathy1, Aditya Krishna Menon2, and Sanjay Chawla3

1 University of Sydney and Capital Markets Cooperative Research Centre (CMCRC)
2 Data61/CSIRO and the Australian National University
3 Qatar Computing Research Institute (QCRI), HBKU
rcha9612@uni.sydney.edu.au,aditya.menon@data61.csiro.au,schawla@qf.org.qa

Abstract. PCA is a classical statistical technique whose simplicity and
maturity has seen it ﬁnd widespread use for anomaly detection. However,
it is limited in this regard by being sensitive to gross perturbations of the
input, and by seeking a linear subspace that captures normal behaviour.
The ﬁrst issue has been dealt with by robust PCA, a variant of PCA
that explicitly allows for some data points to be arbitrarily corrupted;
however, this does not resolve the second issue, and indeed introduces
the new issue that one can no longer inductively ﬁnd anomalies on a
test set. This paper addresses both issues in a single model, the robust
autoencoder. This method learns a nonlinear subspace that captures the
majority of data points, while allowing for some data to have arbitrary
corruption. The model is simple to train and leverages recent advances
in the optimisation of deep neural networks. Experiments on a range of
real-world datasets highlight the model’s eﬀectiveness.

Keywords: anomaly detection, outlier detection, robust PCA, autoen-
coders, deep learning

1 Anomaly detection: motivation and challenges

A common need when analysing real-world datasets is determining which in-
stances stand out as being dramatically dissimilar to all others. Such instances
are known as anomalies, and the goal of anomaly detection (also known as out-
lier detection) is to determine all such instances in a data-driven fashion [9].
Anomalies can be caused by errors in the data but sometimes are indicative of
a new, previously unknown, underlying process; in fact Hawkins [14] deﬁnes an
outlier as an observation that deviates so signiﬁcantly from other observations
as to arouse suspicion that it was generated by a diﬀerent mechanism.

Principal Component Analysis (PCA) [15] is a core method for a range of
statistical inference tasks, including anomaly detection. The basic idea of PCA
is that while many data sets are high-dimensional, they tend to inhabit a low-
dimensional manifold. PCA thus operates by (linearly) projecting data into a
lower-dimensional space, so as to separate the signal from the noise; a data point
which is far away from its projection is deemed as anomalous.

While intuitive and popular, PCA has limitations as an anomaly detection
method. Notably, it is highly sensitive to data perturbation: one extreme data

7
1
0
2
 
l
u
J
 
0
3
 
 
]

G
L
.
s
c
[
 
 
3
v
3
4
7
6
0
.
4
0
7
1
:
v
i
X
r
a

2

Chalapathy, Menon and Chawla

point can completely change the orientation of the projection, often leading to
the masking of anomalies. A variant of PCA, known as a robust PCA (RPCA)
limits the impact of anomalies by using a clever decomposition of the data ma-
trix [8]. We will discuss RPCA in detail in Section 2, but note here that it still
carries out a linear projection, and further cannot be used to make predictions
on test instances; that is, we cannot perform inductive anomaly detection.

In this paper, we will relax the linear projection limitation of RPCA by us-
ing a deep and robust autoencoder [30,13]. The diﬀerence between RPCA and a
deep autoencoder will be the use of a nonlinear activation function and the po-
tential use of several hidden layers in the autoencoder. While this modiﬁcation is
conceptually simple, we show it yields noticeable improvements in anomaly de-
tection performance on complex real-world image data, where a linear projection
cannot capture suﬃcient structure in the data. Further, the robust autoencoder
is capable of performing inductive anomaly detection, unlike RPCA.

In the sequel, we provide an overview of anomaly detection methods (Sec-
tion 2), with a speciﬁc emphasis on matrix decomposition techniques such as
PCA and its robust extensions. We then proceed to describe our proposed model
based on autoencoders (Section 3), and present our experiment setup and results
(Section 4, 5). Finally, we describe directions for future work (Section 6).

2 Background and related work on anomaly detection

Consider a feature matrix X ∈ RN ×D, where N denotes the number of data
points and D the number of features for each point. For example, N could be
the number of images in some photo collection, and D the number of pixels used
to represent each image. The goal of anomaly detection is to determine which
rows of X are anomalous, in the sense of being dissimilar to all other rows. We
will use Xi: to denote the ith row of X.

2.1 A tour of anomaly detection methods

Anomaly detection is a widely researched topic in the data mining and machine
learning community [9,2]. The two primary strands of research have been the
design of novel algorithms to detect anomalies, and the design eﬃcient means of
discovering all anomalies in a large dataset. In the latter strand, starting from
the work of Bay and Schwabacher [4], several optimisations have been proposed
to discover anomalies in near linear time [12].

In the former strand, which is our primary focus, most emphasis has been on
non-parametric methods like distance and density based outliers [21,7]. For ex-
ample, distance-based methods deﬁne a domain-dependent dissimilarity metric,
and deem a point to be anomalous if it is relatively far away from its neigh-
bours [35]. Another popular approach is the one-class SVM, which learns a
smooth boundary that captures the majority of probability mass of the data [27].
In recent years, matrix factorization methods for anomaly detection have
become popular. These methods provide a reconstruction matrix ˆX ∈ RN ×D of

Robust, Deep and Inductive Anomaly Detection

3

the input X, and use the norm (cid:107)Xi: − ˆXi:(cid:107)2
2 as a measure of how anomalous
a particular point Xi: is; if the reconstruction is close to the input, then it is
deemed normal; else, anomalous. We describe several popular examples of this
approach, beginning with principal component analysis (PCA).

2.2 PCA for anomaly detection

PCA ﬁnds the directions of maximal variance of the data. Supposing without
loss of generality that the data matrix X has zero mean, this may be understood
as the result of a matrix factorisation [6]:

min
WT W=I,Z

(cid:107)X − WZ(cid:107)2

F = min
U

(cid:107)X − XUUT (cid:107)2
F .

(1)

Here, the reconstruction matrix is ˆX = XUUT , where U ∈ RD×K for some
number of latent dimensions K (cid:28) D. We can interpret XU as a projection (or
encoding) of X into a K-dimensional subspace, with the application of UT as
an inverse projection (or decoding) back into the original D dimensional space.

2.3 Autoencoders for anomaly detection

PCA assumes a linear subspace explains the data. To relax this assumption,
consider instead

min
U,V

(cid:107)X − f (XU)V(cid:107)2
F

(2)

for some non-decreasing activation function f : R → R, and U ∈ RD×K, V ∈
RK×D. For the purposes of anomaly detection, one can deﬁne the reconstruction
matrix as ˆX = f (XU)V.

Equation 2 corresponds to an autoencoder with a single hidden layer [13].
Popular choices of f (·) include the sigmoid f (a) = (1 + exp(−a))−1 and the
rectiﬁed linear unit or ReLU f (x) = max(0, a). As before, we can interpret XU
as an encoding of X into a K-dimensional subspace; however, by applying a
nonlinear f (·), the projection is implicitly onto a nonlinear manifold.

2.4 Robust PCA

Another way to generalise PCA is to solve, for a tuning parameter λ > 0,

min
S,N

(cid:107)S(cid:107)∗ + λ · (cid:107)N(cid:107)1 : X = S + N,

(3)

where (cid:107) · (cid:107)∗ denotes the trace or nuclear norm (cid:107)X(cid:107)∗ = tr((XT X)1/2), and (cid:107) · (cid:107)1
the elementwise (cid:96)1 norm. For the purposes of anomaly detection, one can deﬁne
the reconstruction matrix ˆX = X − N = S.

Intuitively, Equation 3 separates X into a signal matrix S and a noise matrix
N, where the signal matrix has low-rank structure, and the noise is assumed to
not overwhelm the signal for most of the matrix entries. The trace norm may

4

Chalapathy, Menon and Chawla

be seen as a convex relaxation of the rank function; thus, this objective can be
understood as a relaxed version of PCA.

Equation 3 corresponds to robust PCA (RPCA) [8]. Unlike standard PCA,
this objective can eﬀortlessly deal with a single entry perturbed arbitrarily. When
λ → +∞, we will end up with N = 0, S = X, i.e. we will claim that there is
no noise in the data, and so all points are deemed normal. On the other hand,
when λ → 0, we will end up with N = X, S = 0, i.e. we will claim that there is
no signal in the data, and so points with high norm are deemed anomalous.

2.5 Direct robust matrix factorization

Building upon RPCA, Xiong et. al. [32] introduced the direct robust matrix
factorization method (DRMF), where for tuning parameters K, e one solves:

min
S,N

(cid:107)X − (N + S)(cid:107)2

F : rank(S) ≤ K, (cid:107)N(cid:107)0 ≤ e.

(4)

As before, the matrix N captures the anomalies and S captures the signal. Unlike
RPCA, one explicitly constraints S to be low-rank, rather than merely having
low trace norm; and one explicitly constraints N to have a maximal number of
nonzeros, rather than merely having bounded (cid:96)1 norm. The lack of convexity of
the objective requires a bespoke algorithm for the optimisation.

2.6 Robust kernel PCA

Another way to overcome the linear assumption of PCA is the robust kernel PCA
(RKPCA) approach of [25]. For a feature mapping Φ into a reproducing kernel
Hilbert space, and projection operator P of a point into the KPCA subspace, it
is proposed to reconstruct an input x ∈ RD by solving the pre-image problem

ˆx = argmin

E0(x, z) + C · (cid:107)Φ(z) − PΦ(z)(cid:107)2,

(5)

z∈RD

where E0 is a robust measure of reconstruction error (i.e. not merely the Eu-
clidean norm), and C > 0 is a tuning parameter. RKPCA does not explicitly
handle gross outliers, unlike RPCA; however, by choosing a rich feature mapping
Φ, one can capture nonlinear anomalies. This choice of feature mapping must be
pre-speciﬁed, whereas autoencoder methods implicitly learn a good mapping.

3 From robust PCA to robust autoencoders

We now present our robust (convolutional) autoencoder model for anomaly de-
tection. The method can be seen as an extension of robust PCA to allow for a
nonlinear manifold that explains most of the data.

Robust, Deep and Inductive Anomaly Detection

5

3.1 Robust (convolutional) autoencoders
Let f : R → R be some non-decreasing activation function. Now consider the
following objective, which combines the salient elements of Equations 2 and 3:

min
U,V,N

(cid:107)X − (f (XU)V + N)(cid:107)2

F +

· ((cid:107)U(cid:107)2

F + (cid:107)V(cid:107)2

F ) + λ · (cid:107)N(cid:107)1,

(6)

µ
2

where f (·) is understood to act elementwise, and λ, µ > 0 are tuning parameters.
This is a form of robust autoencoder : one encodes the input into the latent
representation Z = f (XU), which is then decoded via V. The additional N
term captures gross outliers in the data, as with robust PCA. For the purposes
of anomaly detection, we have reconstruction matrix ˆX = f (XU)V.

When λ → +∞, we get N = 0, and the model reduces to a standard au-
toencoder (Equation 2). When λ → 0, then one possible solution is N = X and
U = V = 0, so that the model memorises the training data. For intermediate λ,
the model augments a standard autoencoder with a noise absorption term that
endows robustness.

More generally, Equation 6 can be seen as an instance of

(cid:107)X − ( ˆX(θ) + N)(cid:107)2

F +

· Ω(θ) + λ · (cid:107)N(cid:107)1,

min
θ,N

µ
2

(7)

where ˆX(θ) is some generic predictor with parameters θ, and Ω(·) a regularisa-
tion function. Observe that we could pick ˆX(θ) to be a convolutional autoen-
coder [19,30], which would be suitable when dealing with image data; such a
model will be studied extensively in our experiments. Further, the regulariser Ω
could involve more general matrix norms, such as the (cid:96)1,2 norm [16].

3.2 Training the model

The objective function of the model of Equation 6, 7 is non-convex, but un-
constrained and sub-diﬀerentiable. There are several ways of performing opti-
misation. For example, for diﬀerentiable activation f , one could compute sub-
gradients with respect to all model parameters and apply backpropagation. How-
ever, to leverage existing advances in training deep networks, we observe that:

– For ﬁxed N, the objective is equivalent to that of a standard (convolutional)
autoencoder on the matrix X − N. Thus, one can optimise the parameters
θ using any modern (stochastic) optimisation tool for deep learning that
exploits gradients, such as Adam [20].

– For ﬁxed θ (i.e. U, V in the standard autoencoder case), the objective is

(cid:107)N − (X − ˆX(θ))(cid:107)2

F + λ · (cid:107)N(cid:107)1,

min
θ,N

which trivially solvable via the soft thresholding operator on the matrix
X − ˆX(θ) [3], with solution

Nij =






(X − ˆX(θ))ij − λ
2
(X − ˆX(θ))ij + λ
2
0

if (X − ˆX(θ))ij > λ
2
if (X − ˆX(θ))ij < − λ
2
else.

6

Chalapathy, Menon and Chawla

We thus alternately optimise N and θ until the change in the overall objective is
below some threshold. The use of stochastic optimisation for the ﬁrst step, and
the simplicity of the optimisation for the second step, means that we can easily
train the model where data arrives in an online or streaming fashion.

3.3 Predicting with the model

One convenient property of our model is that the anomaly detector will be
inductive, i.e. it can generalise to unseen data points. One can interpret the
model as learning a robust representation of the input, which is unaﬀected by
gross noise; such a representation should thus be able to accurately model any
unseen points that lie on the same manifold as the data used to train the model.
∗ U)V to score this
point. The larger (cid:107)x∗ − VT f (UT x∗)(cid:107)2
2 is, the more likely the point is deemed
to be anomalous. We emphasise that such inductive predictions are simply not
possible with the robust PCA method, as it estimates parameters for the N × D
observations present in X, with no means of generalising to unseen data.

Formally, given a new x∗ ∈ RD, one simply computes f (xT

3.4 Connection to robust PCA

While the robust autoencoder of Equation 6 has clear conceptual similarity to
robust PCA, it may seem that choices such as the (cid:96)2 penalty on U, V are some-
what arbitrarily used in place of the trace norm. We now show how the objective
can in fact be naturally derived as an extension of RPCA.

The trace norm can be represented in the variational form [26] (cid:107)S(cid:107)∗ =
F ). The robust PCA objective is thus equivalently

F + (cid:107)V(cid:107)2

2 · ((cid:107)W(cid:107)2

minWV=S

1

min
W,V,N

1
2

· ((cid:107)W(cid:107)2

F + (cid:107)V(cid:107)2

F ) + λ · (cid:107)N(cid:107)1 : X = WV + N.

This objective has the disadvantage of being non-convex, but the advantage of
being amenable to extensions. Pick some µ > 0, and consider a relaxed version
of the robust PCA objective:

min
W,V,N,E

(cid:107)E(cid:107)2

F +

· ((cid:107)W(cid:107)2

F + (cid:107)V(cid:107)2

F ) + λ · (cid:107)N(cid:107)1 : X = WV + N + E.

µ
2

Here, we allow for further systematic errors E which have low average magnitude.
We can equally consider the unconstrained objective

min
W,V,N

(cid:107)X − (WV + N)(cid:107)2

F +

· ((cid:107)W(cid:107)2

F + (cid:107)V(cid:107)2

F ) + λ · (cid:107)N(cid:107)1

(8)

µ
2

This re-expression of robust PCA has been previously noted, for example in
Sprechmann et al. [29]. To derive the robust autoencoder from Equation 8, sup-
pose now that we constrain W = XU. This is a natural constraint in light of

Robust, Deep and Inductive Anomaly Detection

7

Equation 1, since for standard PCA we factorise X into ˆX = XUUT . Then, we
have the objective

min
U,V,N

(cid:107)X − (XUV + N)(cid:107)2

F +

· ((cid:107)XU(cid:107)2

F + (cid:107)V(cid:107)2

F ) + λ · (cid:107)N(cid:107)1.

Now suppose we modify the regulariser to only operate on U rather than XU:

min
U,V,N

(cid:107)X − (XUV + N)(cid:107)2

F +

· ((cid:107)U(cid:107)2

F + (cid:107)V(cid:107)2

F ) + λ · (cid:107)N(cid:107)1.

This is again natural in the context of standard PCA, since there we have W =
XU satisfying WT W = I. Observe now that we have derived Equation 6 for a
linear activation function f (x) = x. The robust autoencoder thus extends this
model by employing a nonlinear activation.

µ
2

µ
2

3.5 Relation to existing models

Our contribution is a nonlinear extension of RPCA for anomaly detection. As
noted above, the key advantages over RPCA are the ability to capture nonlinear
structure in the data, as well as the ability to detect anomalies in an inductive
setting. The price we have to pay is the lack of convexity of the objective func-
tion, unlike RPCA; nonetheless, we shall demonstrate that the model can be
eﬀectively trained using the procedure described in Section 3.2.

Some works have employed deep networks for anomaly detection [31,34],
but without explicitly accounting for gross anomalies. For example, the recent
work of [34] employed an autoencoder-inspired objective to train a probabilistic
neural network, with extensions to structured data; the use of an RPCA-style
noise matrix N may be useful to explore in conjunction with such methods.

Our method is also distinct to denoising autoencoders (DNA), wherein noise
is explicitly added to instances [30], whereas we infer the noise automatically.
The approaches have slightly diﬀerent goals: DNAs aim to extract good features
from the data, while our aim is to identify anomalies.

Finally, while nonlinear extensions of PCA-style matrix factorisation (in-
cluding via autoencoders) have been explored in contexts such as collaborative
ﬁltering [23,28], we are unaware of prior usage for anomaly detection.

4 Experimental setup

In this section we show the empirical eﬀectiveness of Robust Convolutional Au-
toencoder over the state-of-the-art methods on real-world data. Our primary
focus will be on non-trivial image datasets, although our method is applicable
in any context where autoencoders are useful e.g. speech.

4.1 Methods compared

We compare our proposed Robust Convolutional Autoencoder (RCAE) with the
following state-of-the art methods for anomaly detection:

8

Chalapathy, Menon and Chawla

• Truncated SVD, which for zero-mean features is equivalent to PCA.
• Robust PCA (RPCA) [8], as per Equation 3.
• Robust kernel PCA (RKPCA) [25], as per Equation 5.
• Autoencoder (AE) [5], as per Equation 2.
• Convolutional Autoencoder (CAE), a convolutional autoencoder with-

out any accounting for gross anomalies i.e. Equation 7 where λ = +∞.

• Robust Convolutional Autoencoder (RCAE), our proposed model as

per Equation 7.

We used TensorFlow [1] for the implementation of AE, CAE and RCAE4. For
RPCA and RKPCA, we used publicly available implementations5,6.

4.2 Datasets

We compare all methods on three real-world datasets:

• restaurant, comprising video background modelling and activity detection

consisting of snapshots of restaurant activities [32].
• usps, comprising the USPS handwritten digits [17].
• cifar-10 consisting of 60000 32 × 32 colour images in 10 classes, with 6000

images per class [22].

For each dataset, we perform further processing to create a well-posed anomaly
detection task, as described in the next section.

4.3 Evaluation methodology

As anomaly detection is an unsupervised learning problem, model evaluation is
challenging. For the restaurant dataset, there are no ground truth anomalies,
and so we perform a qualitative analysis by visually comparing the anomalies
ﬂagged by various methods, as done in the original robust PCA paper [8].

For the other two datasets, we follow a standard protocol (see e.g. [32])
wherein anomalies are explicitly identiﬁed in the training set. We can then eval-
uate the predictive performance of each method as measured against the ground
truth anomaly labels, using three standard metrics:

• the area under the precision-recall curve (AUPRC)
• the area under the ROC curve (AUROC)
• the precision at 10 (P@10).

AUPRC and AUROC measure ranking performance, with the former being pre-
ferred under class imbalance [11]. P@10 measures classiﬁcation performance,
being the fraction of the top 10 scored instances which are actually anomalous.

4 https://github.com/raghavchalapathy/rcae
5 http://perception.csl.illinois.edu/matrix-rank/sample_code.html
6 http://www3.cs.stonybrook.edu/~minhhoai/downloads.html

Robust, Deep and Inductive Anomaly Detection

9

Dataset

# instances # anomalies

# features

restaurant

usps

cifar-10

200

231

5000

Unknown (foreground)

19200

11 (‘7’)

50 (cats)

256

1024

Table 1. Summary of datasets used in experiments.

For CIFAR − 10, the labelled dataset is created by combining 5000 images of
dogs and 50 images of cats; a good anomaly detection method should thus ﬂag
the cats to be anomalous. Similarly, for usps, the dataset is created by a mixture
of 220 images of ‘1’s, and 11 images of ‘7’as in [33]. Details of the datasets are
summarised in Table 1.

Additionally, we also test the ability of our model to perform denoising of

images, as well as detecting inductive anomalies.

4.4 Network parameters

Although we have observed that deeper RCAE networks tend to achieve better
image reconstruction performance, there exist four fold options related to net-
work parameters to be chosen: (a) number of convolutional ﬁlters, (b) ﬁlter size,
(c) strides of convolution operation and (d) activation applied. We tuned via
grid search additional hyper-parameters, including the number of hidden-layer
nodes H ∈ {3, 64, 128}, and regularisation λ within range [0, 100]. The learning,
drop-out rates and regularization parameter µ were sampled from a uniform
distribution in the range [0.05, 0.1]. The embedding and initial weight matrices
were all sampled from the uniform distribution within range [−1, 1].

5 Experimental results

In this section, we present experiments for three scenarios: (a) non-inductive
anomaly detection, (b) inductive anomaly detection, and (c) image denoising.

5.1 Non-inductive anomaly detection results

We present results on the three datasets described in Section 4.

(1) restaurant dataset We work with the restaurant video activity detection
dataset [32], and consider the problem of inferring the background of videos via
removal of (anomalous) foreground pixels. Estimating the background in videos
is important for tasks such as anomalous activity detection. It is however diﬃcult
because of the variability of the background (e.g. due to lighting conditions) and
the presence of foreground objects such as moving objects and people.

10

Chalapathy, Menon and Chawla

(a) RCAE.

(b) RPCA.

Fig. 1. Top anomalous images containing original image (people walking in the lobby)
decomposed into background (lobby) and foreground (people), restaurant dataset.

For this experiment, we only compare the RPCA and RCAE methods, owing

to a lack of ground truth labels.

Parameter settings. For RPCA, rank K = 64 is used.
Per the success of the Batch Normalization architecture [18] and Exponential
Linear Units [10], we have found that convolutional+batch-normalization+elu
layers provide a better representation of convolutional ﬁlters. Hence, in this
experiment the RCAE adopts four layers of (conv-batch-normalization-elu) in
the encoder part and four layers of (conv-batch-normalization-elu) in the decoder
portion of the network. RCAE network parameters such as (number of ﬁlter, ﬁlter
size, strides) are chosen to be (16,3,1) for ﬁrst and second layers and (32,3,1) for
third and fourth layers of both encoder and decoder layers.

Results. While there are no ground truth anomalies in this dataset, a qual-
itative analysis reveals RCAE to outperforms its counterparts in capturing the
foreground objects. Figure 1 compares the top 6 most anomalous images for
RCAE and RPCA. We see that the most anomalous images contain high fore-
gound activity (which are recognised as anomalous). Visually, we see that the
background reconstruction produced by RPCA contains a few blemishes in some
cases, while for RCAE the backgrounds are smooth.

(2) usps dataset From the usps handwritten digit dataset, we create a dataset
with a mixture of 220 images of ‘1’s, and 11 images of ‘7’, as in [33]. Intuitively,
the latter images are treated as being anomalous, as the corresponding images

Robust, Deep and Inductive Anomaly Detection

11

(a) RCAE.

(b) RPCA.

Fig. 2. Top anomalous images, usps dataset.

(a) usps

(b) cifar-10

Methods AUPRC

AUROC

P@10

AUPRC

AUROC

P@10

RCAE

0.9614 ± 0.0025 0.9988± 0.0243 0.9108 ± 0.0113

0.9934 ± 0.0003 0.6255 ± 0.0055 0.8716 ± 0.0005

CAE

AE

0.7003 ± 0.0105 0.9712 ± 0.0002 0.8730 ± 0.0023

0.9011 ± 0.0000 0.6191 ± 0.0000 0.0000 ± 0.0000

0.8533 ± 0.0023 0.9927 ± 0.0022 0.8108 ± 0.0003

0.9341 ± 0.0029 0.5260 ± 0.0003 0.2000 ± 0.0003

RKPCA 0.5340 ± 0.0262 0.9717 ± 0.0024 0.5250 ± 0.0307

0.0557 ± 0.0037 0.5026 ± 0.0123 0.0550 ± 0.0185

DRMF

0.7737 ± 0.0351 0.9928 ± 0.0027 0.7150 ± 0.0342

0.0034 ± 0.0000 0.4847 ± 0.0000 0.0000 ± 0.0000

RPCA

0.7893 ± 0.0195 0.9942 ± 0.0012 0.7250 ± 0.0323

0.0036 ± 0.0000 0.5211 ± 0.0000 0.0000 ± 0.0000

SVD

0.6091 ± 0.1263 0.9800 ± 0.0105 0.5600 ± 0.0249

0.0024 ± 0.0000 0.5299 ± 0.0000 0.0000 ± 0.0000

Table 2. Comparison between the baseline (bottom four rows) and state-of-the-art
systems (top three rows). Results are the mean and standard error of performance
metrics over 20 random training set draws. Highlighted cells indicate best performer.

have diﬀerent characteristics to the majority of the training data. Each image is
ﬂattened as a row vector, yielding a 231 × 256 training matrix.

Parameter settings. For SVD and RPCA methods, rank K = 64 is used.
For AE, the inputs are ﬂattened images as a column vector of size 256, and the
hidden layer is a column vector of size 64 (matching the rank K).

For DRMF, we follow the settings of [33]. For RKPCA, we used a Gaussian
kernel with bandwidth 0.01, a cost parameter C = 1, and requested 60% of the
KPCA spectrum (which roughly selects 64 principal components).

For RCAE, we set two layers of convolution layers with the ﬁlter number to
be 32, ﬁlter size to be 3×3, with number of strides as 1 and rectiﬁed linear unit
(ReLU) as activation with max-pooling layer of dimension 2×2.

Results. From Table 2, we see that it is a near certainty for all ‘7’ are
accurately identiﬁed as outliers. Figure 2 shows the top anomalous images for
RCAE, where indeed the ‘7”s are correctly placed at the top of the list. By
contrast, for RPCA there are also some ‘1”s placed at the top.

(3) cifar-10 dataset We create a dataset with anomalies by combining 5000
random images of dogs and 50 images of cats, as illustrated in Figure 3. In
this scenario the cats are anomalies, and the goal is to detect all the cats in an
unsupervised manner.

12

Chalapathy, Menon and Chawla

(a) RCAE.

(b) RPCA.

Fig. 3. Top anomalous images, cifar-10 dataset.

Parameter settings. For SVD and RPCA methods, rank K = 64 is used.
We trained a three-hidden-layer autoencoder (AE) (1024-256-64-256-1024 neu-
rons). The middle hidden layer size is set to be same as rank K = 64, and the
model is trained using Adam [20]. The decoding layer uses sigmoid function in
order to capture the nonlinearity characteristics from latent representations pro-
duced by the hidden layer. Finally, we obtain the feature vector for each image
by obtaining the latent representation from the hidden layer.

For RKPCA, we used a Gaussian kernel with bandwidth 5 · 10−8, a cost
parameter C = 0.1, and requested 55% of the KPCA spectrum (which roughly
selects 64 principal components). The RKPCA runtime was prohibitive on the
full sample (see Sec 5.4), so we resorted to a subsample of 1000 dogs and 50 cats.
The RCAE architecture in this experiment is same as for restaurant, con-
taining four layers of (conv-batch-normalization-elu) in the encoder part and
four layers of (conv-batch-normalization-elu) in the decoder portion of the net-
work. RCAE network parameters such as (number of ﬁlter, ﬁlter size, strides)
are chosen to be (16,3,1) for ﬁrst and second layers and (32,3,1) for third and
fourth layers of both encoder and decoder.

Results. From Table 2, RCAE clearly outperforms all existing state-of-the
art methods in anomaly detection. Note that basic CAE, with no robustness
(eﬀectively λ = ∞), is also outperformed by our method, indicating that it is
crucial to explicitly handle anomalies with the N term.

Figure 3 illustrates the most anomalous images for our RCAE method, com-
pared to RPCA. Owing to the latter involving learning a linear subspace, the
model is unable to eﬀectively distinguish cats from dogs; by contrast, RCAE can
eﬀectively determine the manifold characterising most dogs, and identiﬁes cats
to be anomalous with respect to this.

5.2 Inductive anomaly detection results

We conduct an experiment to assess the detection of inductive anomalies. Recall
that this is a capability of our RCAE model, but not e.g. RPCA. We consider
the following setup: we train our model on 5000 dog images, and then evaluate
it on a test set comprising 500 dogs and 50 cat images. As before, we wish all
methods to accurately determine the cats to be anomalies.

Robust, Deep and Inductive Anomaly Detection

13

(a) RCAE.

(b) CAE.

Fig. 4. Top inductive anomalous images, cifar-10 dataset.

Table 3. Inductive anomaly detection results on cifar-10. Note that RPCA and
DRMF are inapplicable here. Highlighted cells indicate best performer.

SVD

RKPCA

AE

CAE

RCAE

AUPRC 0.1752 ± 0.0051 0.1006 ± 0.0045 0.6200 ± 0.0005 0.6423 ± 0.0005 0.6908 ± 0.0001

AUROC 0.4997 ± 0.0066 0.4988 ± 0.0125 0.5007 ± 0.0010 0.4708 ± 0.0003 0.5576 ± 0.0005

P@10

0.2150 ± 0.0310 0.0900 ± 0.0228 0.1086 ± 0.0001 0.2908 ± 0.0001 0.5986 ± 0.0001

Table 3 summarises the detection performance for all the methods on this
inductive task. The lower values compared to Table 2 are indicative that the
problem here is more challenging than anomaly detection on a single dataset;
nonetheless, we see that our RCAE method manages to convincingly outper-
form both the SVD and AE baselines. This is conﬁrmed qualitatively in Fig-
ure 4, where we see that RCAE correctly identiﬁes many cats in the test set as
anomalous, while the basic CAE method suﬀers.

5.3 Image denoising results

Finally, we test the ability of the model to de-noise images, which is a form
of anomaly detection on individual pixels (or more generally, features). In this
experiment, we train all models on a set of 5000 images of dogs from cifar-10.
For each image, we then add salt-and-pepper noise at a rate of 10%. Our goal is
to recover the original image as accurately as possible.

Figure 5 illustrates that the most anomalous images in the presence of noise
contain images of the variations of dog class images (e.g. containing person’s
face). Further, Figure 6 illustrates for various methods the mean square error
between the reconstructed and original images. RCAE eﬀectively suppresses the
noise as evident from the low error. The improvement over raw CAE is modest,
but suggests that there is beneﬁt to explicitly accounting for noise.

5.4 Comparison of training times

We remark ﬁnally that our RCAE method is comparable in training eﬃciency to
existing methods. For example, on the small-scale restaurant dataset, it takes

14

Chalapathy, Menon and Chawla

(a) RCAE.

(b) RPCA.

Fig. 5. Top anomalous images in original form (ﬁrst row), noisy form (second row),
image denoising task on cifar-10.

Fig. 6. Illustration of the mean square error boxplots obtained for various models on
image denoising task, cifar-10 dataset. In this setting, RCAE suppresses the noise
and detects the background and foreground images eﬀectively.

1 minute to train RPCA, and 8.5 minutes to train RKPCA, compared with 10
minutes for our RCAE method. The ability to leverage recent advances in deep
learning as part of our optimisation (e.g. training models on a GPU) is we believe
a salient feature of our approach.

We note that while the RKPCA method is fast to train on smaller datasets,
on larger datasets it suﬀers from the O(n2) complexity of kernel methods; for
example, it takes over an hour to train on the cifar-10 dataset. It is plausible
that one could leverage recent advances in fast approximations of kernel meth-
ods [24], and studying these would be of interest in future work. Note that the
issue of using a ﬁxed kernel function would remain, however.

Robust, Deep and Inductive Anomaly Detection

15

6 Conclusion

We have extended the robust PCA model to the nonlinear autoencoder setting.
To the best of our knowledge, ours is the ﬁrst approach which is robust, nonlinear
and inductive. The robustness ensures that the model is not over-sensitive to
anomalies; the nonlinearity helps discover potentially more subtle anomalies;
and being inductive makes it possible to deploy our model in a live setting.

While autoencoders are a powerful mechansim for data representation they
suﬀer from their “black-box” nature. There is a growing body of research on
outlier description, i.e., explain the reason why a data point is anomalous. A
direction of future reason is to extend deep autoencoders for outlier description.

References

1. Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G.S.,
Davis, A., Dean, J., Devin, M., et al.: Tensorﬂow: Large-scale machine learning on
heterogeneous distributed systems. arXiv preprint arXiv:1603.04467 (2016)

2. Aggarwal, C.C.: Outlier Analysis. Springer, 2nd edn. (2016)
3. Bach, F., Jenatton, R., Mairal, J., Obozinski, G.: Convex Optimization with
Sparsity-Inducing Norms. In: Optimization for Machine Learning, MIT Press
(2011)

4. Bay, S.D., Schwabacher, M.: Mining distance-based outliers in near linear time
with randomization and a simple pruning rule. In: International Conference on
Knowledge Discovery and Data Mining (KDD) (2003)

5. Bengio, Y., et al.: Learning deep architectures for ai. Foundations and trends R(cid:13) in

Machine Learning 2(1), 1–127 (2009)

6. Bishop, C.M.: Pattern Recognition and Machine Learning. Springer (2006)
7. Breunig, M.M., Kriegel, H.P., Ng, R.T., Sander, J.: Lof: identifying density-based

local outliers. In: ACM sigmod record. vol. 29, pp. 93–104. ACM (2000)

8. Cand´es, E., Li, X., Ma, Y., Wright, J.: Robust principal component analysis?: Re-
covering low-rank matrices from sparse errors. In: Sensor Array and Multichannel
Signal Processing Workshop (SAM), 2010 IEEE. pp. 201–204. IEEE (2010)

9. Chandola, V., Banerjee, A., Kumar, V.: Outlier detection: A survey. ACM Com-

puting Surveys (2007)

10. Clevert, D.A., Unterthiner, T., Hochreiter, S.: Fast and accurate deep network
learning by exponential linear units (elus). arXiv preprint arXiv:1511.07289 (2015)
11. Davis, J., Goadrich, M.: The relationship between precision-recall and roc curves.

In: International Conference on Machine Learning (ICML) (2006)

12. Ghoting, A., Parthasarathy, S., Otey, M., Ghoting, A., Parthasarathy, S., Otey,
M.E.: Fast mining of distance-based outliers in high-dimensional datasets. Data
Mining and Knowledge Discovery 16(3), 349–364 (2008)

13. Goodfellow, I., Bengio, Y., Courville, A.: Deep Learning. MIT Press (2016), http:

//www.deeplearningbook.org

14. Hawkins, D.: Identiﬁcation of Outliers. Chapman and Hall, London (1980)
15. Hotelling, H.: Analysis of a complex of statistical variables into principal compo-

16. Huang, J., Zhang, T.: The beneﬁt of group sparsity. Ann. Statist. 38(4), 1978–2004

nents. J. Educ. Psych. 24 (1933)

(08 2010)

16

Chalapathy, Menon and Chawla

17. Hull, J.J.: A database for handwritten text recognition research. IEEE Transactions

on pattern analysis and machine intelligence 16(5), 550–554 (1994)

18. Ioﬀe, S., Szegedy, C.: Batch normalization: Accelerating deep network training by

reducing internal covariate shift. arXiv preprint arXiv:1502.03167 (2015)

19. Jain, V., Seung, S.: Natural image denoising with convolutional networks. In: Ad-

vances in Neural Information Processing Systems 21, pp. 769–776 (2008)

20. Kingma, D., Ba, J.: Adam: A method for stochastic optimization. arXiv preprint

21. Knorr, E.M., Ng, R.T.: A uniﬁed notion of outliers: Properties and computation.

22. Krizhevsky, A., Hinton, G.: Learning multiple layers of features from tiny images.

arXiv:1412.6980 (2014)

In: KDD. pp. 219–222 (1997)

Tech. rep. (2009)

23. Lawrence, N.D., Urtasun, R.: Non-linear matrix factorization with gaussian pro-

cesses. In: International Conference on Machine Learning (ICML) (2009)

24. Lopez-Paz, D., Sra, S., Smola, A.J., Ghahramani, Z., Sch¨olkopf, B.: Randomized
nonlinear component analysis. In: International Conference on Machine Learning
(ICML) (2014)

25. Nguyen, M.H., Torre, F.: Robust kernel principal component analysis. In: Advances

in Neural Information Processing Systems (NIPS) (2009)

26. Recht, B., Fazel, M., Parrilo, P.A.: Guaranteed minimum-rank solutions of linear
matrix equations via nuclear norm minimization. SIAM review 52(3), 471–501
(2010)

27. Schlkopf, B., Platt, J.C., Shawe-Taylor, J.C., Smola, A.J., Williamson, R.C.: Esti-
mating the support of a high-dimensional distribution. Neural Computation 13(7),
14431471 (Jul 2001)

28. Sedhain, S., Menon, A.K., Sanner, S., Xie, L.: Autorec: Autoencoders meet col-
laborative ﬁltering. In: International Conference on World Wide Web (WWW)
(2015)

29. Sprechmann, P., Bronstein, A.M., Sapiro, G.: Learning eﬃcient sparse and low
rank models. IEEE Transactions on Pattern Analysis and Machine Intelligence
37(9), 1821–1833 (Sept 2015)

30. Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol, P.A.: Stacked denois-
ing autoencoders: Learning useful representations in a deep network with a local
denoising criterion. JMLR 11, 3371–3408 (2010)

31. Williams, G., Baxter, R., He, H., Hawkins, S., Gu, L.: A comparative study of rnn
for outlier detection in data mining. In: International Conference on Data Mining
(ICDM) (2002)

32. Xiong, L., Chen, X., Schneider, J.: Direct robust matrix factorizatoin for anomaly
detection. In: International Conference on Data Mining (ICDM). IEEE (2011)
33. Xu, H., Caramanis, C., Sanghavi, S.: Robust PCA via outlier pursuit. In: Advances

in Neural Information Processing Systems. pp. 2496–2504 (2010)

34. Zhai, S., Cheng, Y., Lu, W., Zhang, Z.: Deep structured energy based models
for anomaly detection. In: International Conference on Machine Learning (ICML)
(2016)

35. Zhao, M., Saligrama, V.: Anomaly detection with score functions based on nearest
neighbor graphs. In: Advances in Neural Information Processing Systems (NIPS).
pp. 2250–2258 (2009)

Robust, Deep and Inductive Anomaly Detection

Raghavendra Chalapathy1, Aditya Krishna Menon2, and Sanjay Chawla3

1 University of Sydney and Capital Markets Cooperative Research Centre (CMCRC)
2 Data61/CSIRO and the Australian National University
3 Qatar Computing Research Institute (QCRI), HBKU
rcha9612@uni.sydney.edu.au,aditya.menon@data61.csiro.au,schawla@qf.org.qa

Abstract. PCA is a classical statistical technique whose simplicity and
maturity has seen it ﬁnd widespread use for anomaly detection. However,
it is limited in this regard by being sensitive to gross perturbations of the
input, and by seeking a linear subspace that captures normal behaviour.
The ﬁrst issue has been dealt with by robust PCA, a variant of PCA
that explicitly allows for some data points to be arbitrarily corrupted;
however, this does not resolve the second issue, and indeed introduces
the new issue that one can no longer inductively ﬁnd anomalies on a
test set. This paper addresses both issues in a single model, the robust
autoencoder. This method learns a nonlinear subspace that captures the
majority of data points, while allowing for some data to have arbitrary
corruption. The model is simple to train and leverages recent advances
in the optimisation of deep neural networks. Experiments on a range of
real-world datasets highlight the model’s eﬀectiveness.

Keywords: anomaly detection, outlier detection, robust PCA, autoen-
coders, deep learning

1 Anomaly detection: motivation and challenges

A common need when analysing real-world datasets is determining which in-
stances stand out as being dramatically dissimilar to all others. Such instances
are known as anomalies, and the goal of anomaly detection (also known as out-
lier detection) is to determine all such instances in a data-driven fashion [9].
Anomalies can be caused by errors in the data but sometimes are indicative of
a new, previously unknown, underlying process; in fact Hawkins [14] deﬁnes an
outlier as an observation that deviates so signiﬁcantly from other observations
as to arouse suspicion that it was generated by a diﬀerent mechanism.

Principal Component Analysis (PCA) [15] is a core method for a range of
statistical inference tasks, including anomaly detection. The basic idea of PCA
is that while many data sets are high-dimensional, they tend to inhabit a low-
dimensional manifold. PCA thus operates by (linearly) projecting data into a
lower-dimensional space, so as to separate the signal from the noise; a data point
which is far away from its projection is deemed as anomalous.

While intuitive and popular, PCA has limitations as an anomaly detection
method. Notably, it is highly sensitive to data perturbation: one extreme data

7
1
0
2
 
l
u
J
 
0
3
 
 
]

G
L
.
s
c
[
 
 
3
v
3
4
7
6
0
.
4
0
7
1
:
v
i
X
r
a

2

Chalapathy, Menon and Chawla

point can completely change the orientation of the projection, often leading to
the masking of anomalies. A variant of PCA, known as a robust PCA (RPCA)
limits the impact of anomalies by using a clever decomposition of the data ma-
trix [8]. We will discuss RPCA in detail in Section 2, but note here that it still
carries out a linear projection, and further cannot be used to make predictions
on test instances; that is, we cannot perform inductive anomaly detection.

In this paper, we will relax the linear projection limitation of RPCA by us-
ing a deep and robust autoencoder [30,13]. The diﬀerence between RPCA and a
deep autoencoder will be the use of a nonlinear activation function and the po-
tential use of several hidden layers in the autoencoder. While this modiﬁcation is
conceptually simple, we show it yields noticeable improvements in anomaly de-
tection performance on complex real-world image data, where a linear projection
cannot capture suﬃcient structure in the data. Further, the robust autoencoder
is capable of performing inductive anomaly detection, unlike RPCA.

In the sequel, we provide an overview of anomaly detection methods (Sec-
tion 2), with a speciﬁc emphasis on matrix decomposition techniques such as
PCA and its robust extensions. We then proceed to describe our proposed model
based on autoencoders (Section 3), and present our experiment setup and results
(Section 4, 5). Finally, we describe directions for future work (Section 6).

2 Background and related work on anomaly detection

Consider a feature matrix X ∈ RN ×D, where N denotes the number of data
points and D the number of features for each point. For example, N could be
the number of images in some photo collection, and D the number of pixels used
to represent each image. The goal of anomaly detection is to determine which
rows of X are anomalous, in the sense of being dissimilar to all other rows. We
will use Xi: to denote the ith row of X.

2.1 A tour of anomaly detection methods

Anomaly detection is a widely researched topic in the data mining and machine
learning community [9,2]. The two primary strands of research have been the
design of novel algorithms to detect anomalies, and the design eﬃcient means of
discovering all anomalies in a large dataset. In the latter strand, starting from
the work of Bay and Schwabacher [4], several optimisations have been proposed
to discover anomalies in near linear time [12].

In the former strand, which is our primary focus, most emphasis has been on
non-parametric methods like distance and density based outliers [21,7]. For ex-
ample, distance-based methods deﬁne a domain-dependent dissimilarity metric,
and deem a point to be anomalous if it is relatively far away from its neigh-
bours [35]. Another popular approach is the one-class SVM, which learns a
smooth boundary that captures the majority of probability mass of the data [27].
In recent years, matrix factorization methods for anomaly detection have
become popular. These methods provide a reconstruction matrix ˆX ∈ RN ×D of

Robust, Deep and Inductive Anomaly Detection

3

the input X, and use the norm (cid:107)Xi: − ˆXi:(cid:107)2
2 as a measure of how anomalous
a particular point Xi: is; if the reconstruction is close to the input, then it is
deemed normal; else, anomalous. We describe several popular examples of this
approach, beginning with principal component analysis (PCA).

2.2 PCA for anomaly detection

PCA ﬁnds the directions of maximal variance of the data. Supposing without
loss of generality that the data matrix X has zero mean, this may be understood
as the result of a matrix factorisation [6]:

min
WT W=I,Z

(cid:107)X − WZ(cid:107)2

F = min
U

(cid:107)X − XUUT (cid:107)2
F .

(1)

Here, the reconstruction matrix is ˆX = XUUT , where U ∈ RD×K for some
number of latent dimensions K (cid:28) D. We can interpret XU as a projection (or
encoding) of X into a K-dimensional subspace, with the application of UT as
an inverse projection (or decoding) back into the original D dimensional space.

2.3 Autoencoders for anomaly detection

PCA assumes a linear subspace explains the data. To relax this assumption,
consider instead

min
U,V

(cid:107)X − f (XU)V(cid:107)2
F

(2)

for some non-decreasing activation function f : R → R, and U ∈ RD×K, V ∈
RK×D. For the purposes of anomaly detection, one can deﬁne the reconstruction
matrix as ˆX = f (XU)V.

Equation 2 corresponds to an autoencoder with a single hidden layer [13].
Popular choices of f (·) include the sigmoid f (a) = (1 + exp(−a))−1 and the
rectiﬁed linear unit or ReLU f (x) = max(0, a). As before, we can interpret XU
as an encoding of X into a K-dimensional subspace; however, by applying a
nonlinear f (·), the projection is implicitly onto a nonlinear manifold.

2.4 Robust PCA

Another way to generalise PCA is to solve, for a tuning parameter λ > 0,

min
S,N

(cid:107)S(cid:107)∗ + λ · (cid:107)N(cid:107)1 : X = S + N,

(3)

where (cid:107) · (cid:107)∗ denotes the trace or nuclear norm (cid:107)X(cid:107)∗ = tr((XT X)1/2), and (cid:107) · (cid:107)1
the elementwise (cid:96)1 norm. For the purposes of anomaly detection, one can deﬁne
the reconstruction matrix ˆX = X − N = S.

Intuitively, Equation 3 separates X into a signal matrix S and a noise matrix
N, where the signal matrix has low-rank structure, and the noise is assumed to
not overwhelm the signal for most of the matrix entries. The trace norm may

4

Chalapathy, Menon and Chawla

be seen as a convex relaxation of the rank function; thus, this objective can be
understood as a relaxed version of PCA.

Equation 3 corresponds to robust PCA (RPCA) [8]. Unlike standard PCA,
this objective can eﬀortlessly deal with a single entry perturbed arbitrarily. When
λ → +∞, we will end up with N = 0, S = X, i.e. we will claim that there is
no noise in the data, and so all points are deemed normal. On the other hand,
when λ → 0, we will end up with N = X, S = 0, i.e. we will claim that there is
no signal in the data, and so points with high norm are deemed anomalous.

2.5 Direct robust matrix factorization

Building upon RPCA, Xiong et. al. [32] introduced the direct robust matrix
factorization method (DRMF), where for tuning parameters K, e one solves:

min
S,N

(cid:107)X − (N + S)(cid:107)2

F : rank(S) ≤ K, (cid:107)N(cid:107)0 ≤ e.

(4)

As before, the matrix N captures the anomalies and S captures the signal. Unlike
RPCA, one explicitly constraints S to be low-rank, rather than merely having
low trace norm; and one explicitly constraints N to have a maximal number of
nonzeros, rather than merely having bounded (cid:96)1 norm. The lack of convexity of
the objective requires a bespoke algorithm for the optimisation.

2.6 Robust kernel PCA

Another way to overcome the linear assumption of PCA is the robust kernel PCA
(RKPCA) approach of [25]. For a feature mapping Φ into a reproducing kernel
Hilbert space, and projection operator P of a point into the KPCA subspace, it
is proposed to reconstruct an input x ∈ RD by solving the pre-image problem

ˆx = argmin

E0(x, z) + C · (cid:107)Φ(z) − PΦ(z)(cid:107)2,

(5)

z∈RD

where E0 is a robust measure of reconstruction error (i.e. not merely the Eu-
clidean norm), and C > 0 is a tuning parameter. RKPCA does not explicitly
handle gross outliers, unlike RPCA; however, by choosing a rich feature mapping
Φ, one can capture nonlinear anomalies. This choice of feature mapping must be
pre-speciﬁed, whereas autoencoder methods implicitly learn a good mapping.

3 From robust PCA to robust autoencoders

We now present our robust (convolutional) autoencoder model for anomaly de-
tection. The method can be seen as an extension of robust PCA to allow for a
nonlinear manifold that explains most of the data.

Robust, Deep and Inductive Anomaly Detection

5

3.1 Robust (convolutional) autoencoders
Let f : R → R be some non-decreasing activation function. Now consider the
following objective, which combines the salient elements of Equations 2 and 3:

min
U,V,N

(cid:107)X − (f (XU)V + N)(cid:107)2

F +

· ((cid:107)U(cid:107)2

F + (cid:107)V(cid:107)2

F ) + λ · (cid:107)N(cid:107)1,

(6)

µ
2

where f (·) is understood to act elementwise, and λ, µ > 0 are tuning parameters.
This is a form of robust autoencoder : one encodes the input into the latent
representation Z = f (XU), which is then decoded via V. The additional N
term captures gross outliers in the data, as with robust PCA. For the purposes
of anomaly detection, we have reconstruction matrix ˆX = f (XU)V.

When λ → +∞, we get N = 0, and the model reduces to a standard au-
toencoder (Equation 2). When λ → 0, then one possible solution is N = X and
U = V = 0, so that the model memorises the training data. For intermediate λ,
the model augments a standard autoencoder with a noise absorption term that
endows robustness.

More generally, Equation 6 can be seen as an instance of

(cid:107)X − ( ˆX(θ) + N)(cid:107)2

F +

· Ω(θ) + λ · (cid:107)N(cid:107)1,

min
θ,N

µ
2

(7)

where ˆX(θ) is some generic predictor with parameters θ, and Ω(·) a regularisa-
tion function. Observe that we could pick ˆX(θ) to be a convolutional autoen-
coder [19,30], which would be suitable when dealing with image data; such a
model will be studied extensively in our experiments. Further, the regulariser Ω
could involve more general matrix norms, such as the (cid:96)1,2 norm [16].

3.2 Training the model

The objective function of the model of Equation 6, 7 is non-convex, but un-
constrained and sub-diﬀerentiable. There are several ways of performing opti-
misation. For example, for diﬀerentiable activation f , one could compute sub-
gradients with respect to all model parameters and apply backpropagation. How-
ever, to leverage existing advances in training deep networks, we observe that:

– For ﬁxed N, the objective is equivalent to that of a standard (convolutional)
autoencoder on the matrix X − N. Thus, one can optimise the parameters
θ using any modern (stochastic) optimisation tool for deep learning that
exploits gradients, such as Adam [20].

– For ﬁxed θ (i.e. U, V in the standard autoencoder case), the objective is

(cid:107)N − (X − ˆX(θ))(cid:107)2

F + λ · (cid:107)N(cid:107)1,

min
θ,N

which trivially solvable via the soft thresholding operator on the matrix
X − ˆX(θ) [3], with solution

Nij =






(X − ˆX(θ))ij − λ
2
(X − ˆX(θ))ij + λ
2
0

if (X − ˆX(θ))ij > λ
2
if (X − ˆX(θ))ij < − λ
2
else.

6

Chalapathy, Menon and Chawla

We thus alternately optimise N and θ until the change in the overall objective is
below some threshold. The use of stochastic optimisation for the ﬁrst step, and
the simplicity of the optimisation for the second step, means that we can easily
train the model where data arrives in an online or streaming fashion.

3.3 Predicting with the model

One convenient property of our model is that the anomaly detector will be
inductive, i.e. it can generalise to unseen data points. One can interpret the
model as learning a robust representation of the input, which is unaﬀected by
gross noise; such a representation should thus be able to accurately model any
unseen points that lie on the same manifold as the data used to train the model.
∗ U)V to score this
point. The larger (cid:107)x∗ − VT f (UT x∗)(cid:107)2
2 is, the more likely the point is deemed
to be anomalous. We emphasise that such inductive predictions are simply not
possible with the robust PCA method, as it estimates parameters for the N × D
observations present in X, with no means of generalising to unseen data.

Formally, given a new x∗ ∈ RD, one simply computes f (xT

3.4 Connection to robust PCA

While the robust autoencoder of Equation 6 has clear conceptual similarity to
robust PCA, it may seem that choices such as the (cid:96)2 penalty on U, V are some-
what arbitrarily used in place of the trace norm. We now show how the objective
can in fact be naturally derived as an extension of RPCA.

The trace norm can be represented in the variational form [26] (cid:107)S(cid:107)∗ =
F ). The robust PCA objective is thus equivalently

F + (cid:107)V(cid:107)2

2 · ((cid:107)W(cid:107)2

minWV=S

1

min
W,V,N

1
2

· ((cid:107)W(cid:107)2

F + (cid:107)V(cid:107)2

F ) + λ · (cid:107)N(cid:107)1 : X = WV + N.

This objective has the disadvantage of being non-convex, but the advantage of
being amenable to extensions. Pick some µ > 0, and consider a relaxed version
of the robust PCA objective:

min
W,V,N,E

(cid:107)E(cid:107)2

F +

· ((cid:107)W(cid:107)2

F + (cid:107)V(cid:107)2

F ) + λ · (cid:107)N(cid:107)1 : X = WV + N + E.

µ
2

Here, we allow for further systematic errors E which have low average magnitude.
We can equally consider the unconstrained objective

min
W,V,N

(cid:107)X − (WV + N)(cid:107)2

F +

· ((cid:107)W(cid:107)2

F + (cid:107)V(cid:107)2

F ) + λ · (cid:107)N(cid:107)1

(8)

µ
2

This re-expression of robust PCA has been previously noted, for example in
Sprechmann et al. [29]. To derive the robust autoencoder from Equation 8, sup-
pose now that we constrain W = XU. This is a natural constraint in light of

Robust, Deep and Inductive Anomaly Detection

7

Equation 1, since for standard PCA we factorise X into ˆX = XUUT . Then, we
have the objective

min
U,V,N

(cid:107)X − (XUV + N)(cid:107)2

F +

· ((cid:107)XU(cid:107)2

F + (cid:107)V(cid:107)2

F ) + λ · (cid:107)N(cid:107)1.

Now suppose we modify the regulariser to only operate on U rather than XU:

min
U,V,N

(cid:107)X − (XUV + N)(cid:107)2

F +

· ((cid:107)U(cid:107)2

F + (cid:107)V(cid:107)2

F ) + λ · (cid:107)N(cid:107)1.

This is again natural in the context of standard PCA, since there we have W =
XU satisfying WT W = I. Observe now that we have derived Equation 6 for a
linear activation function f (x) = x. The robust autoencoder thus extends this
model by employing a nonlinear activation.

µ
2

µ
2

3.5 Relation to existing models

Our contribution is a nonlinear extension of RPCA for anomaly detection. As
noted above, the key advantages over RPCA are the ability to capture nonlinear
structure in the data, as well as the ability to detect anomalies in an inductive
setting. The price we have to pay is the lack of convexity of the objective func-
tion, unlike RPCA; nonetheless, we shall demonstrate that the model can be
eﬀectively trained using the procedure described in Section 3.2.

Some works have employed deep networks for anomaly detection [31,34],
but without explicitly accounting for gross anomalies. For example, the recent
work of [34] employed an autoencoder-inspired objective to train a probabilistic
neural network, with extensions to structured data; the use of an RPCA-style
noise matrix N may be useful to explore in conjunction with such methods.

Our method is also distinct to denoising autoencoders (DNA), wherein noise
is explicitly added to instances [30], whereas we infer the noise automatically.
The approaches have slightly diﬀerent goals: DNAs aim to extract good features
from the data, while our aim is to identify anomalies.

Finally, while nonlinear extensions of PCA-style matrix factorisation (in-
cluding via autoencoders) have been explored in contexts such as collaborative
ﬁltering [23,28], we are unaware of prior usage for anomaly detection.

4 Experimental setup

In this section we show the empirical eﬀectiveness of Robust Convolutional Au-
toencoder over the state-of-the-art methods on real-world data. Our primary
focus will be on non-trivial image datasets, although our method is applicable
in any context where autoencoders are useful e.g. speech.

4.1 Methods compared

We compare our proposed Robust Convolutional Autoencoder (RCAE) with the
following state-of-the art methods for anomaly detection:

8

Chalapathy, Menon and Chawla

• Truncated SVD, which for zero-mean features is equivalent to PCA.
• Robust PCA (RPCA) [8], as per Equation 3.
• Robust kernel PCA (RKPCA) [25], as per Equation 5.
• Autoencoder (AE) [5], as per Equation 2.
• Convolutional Autoencoder (CAE), a convolutional autoencoder with-

out any accounting for gross anomalies i.e. Equation 7 where λ = +∞.

• Robust Convolutional Autoencoder (RCAE), our proposed model as

per Equation 7.

We used TensorFlow [1] for the implementation of AE, CAE and RCAE4. For
RPCA and RKPCA, we used publicly available implementations5,6.

4.2 Datasets

We compare all methods on three real-world datasets:

• restaurant, comprising video background modelling and activity detection

consisting of snapshots of restaurant activities [32].
• usps, comprising the USPS handwritten digits [17].
• cifar-10 consisting of 60000 32 × 32 colour images in 10 classes, with 6000

images per class [22].

For each dataset, we perform further processing to create a well-posed anomaly
detection task, as described in the next section.

4.3 Evaluation methodology

As anomaly detection is an unsupervised learning problem, model evaluation is
challenging. For the restaurant dataset, there are no ground truth anomalies,
and so we perform a qualitative analysis by visually comparing the anomalies
ﬂagged by various methods, as done in the original robust PCA paper [8].

For the other two datasets, we follow a standard protocol (see e.g. [32])
wherein anomalies are explicitly identiﬁed in the training set. We can then eval-
uate the predictive performance of each method as measured against the ground
truth anomaly labels, using three standard metrics:

• the area under the precision-recall curve (AUPRC)
• the area under the ROC curve (AUROC)
• the precision at 10 (P@10).

AUPRC and AUROC measure ranking performance, with the former being pre-
ferred under class imbalance [11]. P@10 measures classiﬁcation performance,
being the fraction of the top 10 scored instances which are actually anomalous.

4 https://github.com/raghavchalapathy/rcae
5 http://perception.csl.illinois.edu/matrix-rank/sample_code.html
6 http://www3.cs.stonybrook.edu/~minhhoai/downloads.html

Robust, Deep and Inductive Anomaly Detection

9

Dataset

# instances # anomalies

# features

restaurant

usps

cifar-10

200

231

5000

Unknown (foreground)

19200

11 (‘7’)

50 (cats)

256

1024

Table 1. Summary of datasets used in experiments.

For CIFAR − 10, the labelled dataset is created by combining 5000 images of
dogs and 50 images of cats; a good anomaly detection method should thus ﬂag
the cats to be anomalous. Similarly, for usps, the dataset is created by a mixture
of 220 images of ‘1’s, and 11 images of ‘7’as in [33]. Details of the datasets are
summarised in Table 1.

Additionally, we also test the ability of our model to perform denoising of

images, as well as detecting inductive anomalies.

4.4 Network parameters

Although we have observed that deeper RCAE networks tend to achieve better
image reconstruction performance, there exist four fold options related to net-
work parameters to be chosen: (a) number of convolutional ﬁlters, (b) ﬁlter size,
(c) strides of convolution operation and (d) activation applied. We tuned via
grid search additional hyper-parameters, including the number of hidden-layer
nodes H ∈ {3, 64, 128}, and regularisation λ within range [0, 100]. The learning,
drop-out rates and regularization parameter µ were sampled from a uniform
distribution in the range [0.05, 0.1]. The embedding and initial weight matrices
were all sampled from the uniform distribution within range [−1, 1].

5 Experimental results

In this section, we present experiments for three scenarios: (a) non-inductive
anomaly detection, (b) inductive anomaly detection, and (c) image denoising.

5.1 Non-inductive anomaly detection results

We present results on the three datasets described in Section 4.

(1) restaurant dataset We work with the restaurant video activity detection
dataset [32], and consider the problem of inferring the background of videos via
removal of (anomalous) foreground pixels. Estimating the background in videos
is important for tasks such as anomalous activity detection. It is however diﬃcult
because of the variability of the background (e.g. due to lighting conditions) and
the presence of foreground objects such as moving objects and people.

10

Chalapathy, Menon and Chawla

(a) RCAE.

(b) RPCA.

Fig. 1. Top anomalous images containing original image (people walking in the lobby)
decomposed into background (lobby) and foreground (people), restaurant dataset.

For this experiment, we only compare the RPCA and RCAE methods, owing

to a lack of ground truth labels.

Parameter settings. For RPCA, rank K = 64 is used.
Per the success of the Batch Normalization architecture [18] and Exponential
Linear Units [10], we have found that convolutional+batch-normalization+elu
layers provide a better representation of convolutional ﬁlters. Hence, in this
experiment the RCAE adopts four layers of (conv-batch-normalization-elu) in
the encoder part and four layers of (conv-batch-normalization-elu) in the decoder
portion of the network. RCAE network parameters such as (number of ﬁlter, ﬁlter
size, strides) are chosen to be (16,3,1) for ﬁrst and second layers and (32,3,1) for
third and fourth layers of both encoder and decoder layers.

Results. While there are no ground truth anomalies in this dataset, a qual-
itative analysis reveals RCAE to outperforms its counterparts in capturing the
foreground objects. Figure 1 compares the top 6 most anomalous images for
RCAE and RPCA. We see that the most anomalous images contain high fore-
gound activity (which are recognised as anomalous). Visually, we see that the
background reconstruction produced by RPCA contains a few blemishes in some
cases, while for RCAE the backgrounds are smooth.

(2) usps dataset From the usps handwritten digit dataset, we create a dataset
with a mixture of 220 images of ‘1’s, and 11 images of ‘7’, as in [33]. Intuitively,
the latter images are treated as being anomalous, as the corresponding images

Robust, Deep and Inductive Anomaly Detection

11

(a) RCAE.

(b) RPCA.

Fig. 2. Top anomalous images, usps dataset.

(a) usps

(b) cifar-10

Methods AUPRC

AUROC

P@10

AUPRC

AUROC

P@10

RCAE

0.9614 ± 0.0025 0.9988± 0.0243 0.9108 ± 0.0113

0.9934 ± 0.0003 0.6255 ± 0.0055 0.8716 ± 0.0005

CAE

AE

0.7003 ± 0.0105 0.9712 ± 0.0002 0.8730 ± 0.0023

0.9011 ± 0.0000 0.6191 ± 0.0000 0.0000 ± 0.0000

0.8533 ± 0.0023 0.9927 ± 0.0022 0.8108 ± 0.0003

0.9341 ± 0.0029 0.5260 ± 0.0003 0.2000 ± 0.0003

RKPCA 0.5340 ± 0.0262 0.9717 ± 0.0024 0.5250 ± 0.0307

0.0557 ± 0.0037 0.5026 ± 0.0123 0.0550 ± 0.0185

DRMF

0.7737 ± 0.0351 0.9928 ± 0.0027 0.7150 ± 0.0342

0.0034 ± 0.0000 0.4847 ± 0.0000 0.0000 ± 0.0000

RPCA

0.7893 ± 0.0195 0.9942 ± 0.0012 0.7250 ± 0.0323

0.0036 ± 0.0000 0.5211 ± 0.0000 0.0000 ± 0.0000

SVD

0.6091 ± 0.1263 0.9800 ± 0.0105 0.5600 ± 0.0249

0.0024 ± 0.0000 0.5299 ± 0.0000 0.0000 ± 0.0000

Table 2. Comparison between the baseline (bottom four rows) and state-of-the-art
systems (top three rows). Results are the mean and standard error of performance
metrics over 20 random training set draws. Highlighted cells indicate best performer.

have diﬀerent characteristics to the majority of the training data. Each image is
ﬂattened as a row vector, yielding a 231 × 256 training matrix.

Parameter settings. For SVD and RPCA methods, rank K = 64 is used.
For AE, the inputs are ﬂattened images as a column vector of size 256, and the
hidden layer is a column vector of size 64 (matching the rank K).

For DRMF, we follow the settings of [33]. For RKPCA, we used a Gaussian
kernel with bandwidth 0.01, a cost parameter C = 1, and requested 60% of the
KPCA spectrum (which roughly selects 64 principal components).

For RCAE, we set two layers of convolution layers with the ﬁlter number to
be 32, ﬁlter size to be 3×3, with number of strides as 1 and rectiﬁed linear unit
(ReLU) as activation with max-pooling layer of dimension 2×2.

Results. From Table 2, we see that it is a near certainty for all ‘7’ are
accurately identiﬁed as outliers. Figure 2 shows the top anomalous images for
RCAE, where indeed the ‘7”s are correctly placed at the top of the list. By
contrast, for RPCA there are also some ‘1”s placed at the top.

(3) cifar-10 dataset We create a dataset with anomalies by combining 5000
random images of dogs and 50 images of cats, as illustrated in Figure 3. In
this scenario the cats are anomalies, and the goal is to detect all the cats in an
unsupervised manner.

12

Chalapathy, Menon and Chawla

(a) RCAE.

(b) RPCA.

Fig. 3. Top anomalous images, cifar-10 dataset.

Parameter settings. For SVD and RPCA methods, rank K = 64 is used.
We trained a three-hidden-layer autoencoder (AE) (1024-256-64-256-1024 neu-
rons). The middle hidden layer size is set to be same as rank K = 64, and the
model is trained using Adam [20]. The decoding layer uses sigmoid function in
order to capture the nonlinearity characteristics from latent representations pro-
duced by the hidden layer. Finally, we obtain the feature vector for each image
by obtaining the latent representation from the hidden layer.

For RKPCA, we used a Gaussian kernel with bandwidth 5 · 10−8, a cost
parameter C = 0.1, and requested 55% of the KPCA spectrum (which roughly
selects 64 principal components). The RKPCA runtime was prohibitive on the
full sample (see Sec 5.4), so we resorted to a subsample of 1000 dogs and 50 cats.
The RCAE architecture in this experiment is same as for restaurant, con-
taining four layers of (conv-batch-normalization-elu) in the encoder part and
four layers of (conv-batch-normalization-elu) in the decoder portion of the net-
work. RCAE network parameters such as (number of ﬁlter, ﬁlter size, strides)
are chosen to be (16,3,1) for ﬁrst and second layers and (32,3,1) for third and
fourth layers of both encoder and decoder.

Results. From Table 2, RCAE clearly outperforms all existing state-of-the
art methods in anomaly detection. Note that basic CAE, with no robustness
(eﬀectively λ = ∞), is also outperformed by our method, indicating that it is
crucial to explicitly handle anomalies with the N term.

Figure 3 illustrates the most anomalous images for our RCAE method, com-
pared to RPCA. Owing to the latter involving learning a linear subspace, the
model is unable to eﬀectively distinguish cats from dogs; by contrast, RCAE can
eﬀectively determine the manifold characterising most dogs, and identiﬁes cats
to be anomalous with respect to this.

5.2 Inductive anomaly detection results

We conduct an experiment to assess the detection of inductive anomalies. Recall
that this is a capability of our RCAE model, but not e.g. RPCA. We consider
the following setup: we train our model on 5000 dog images, and then evaluate
it on a test set comprising 500 dogs and 50 cat images. As before, we wish all
methods to accurately determine the cats to be anomalies.

Robust, Deep and Inductive Anomaly Detection

13

(a) RCAE.

(b) CAE.

Fig. 4. Top inductive anomalous images, cifar-10 dataset.

Table 3. Inductive anomaly detection results on cifar-10. Note that RPCA and
DRMF are inapplicable here. Highlighted cells indicate best performer.

SVD

RKPCA

AE

CAE

RCAE

AUPRC 0.1752 ± 0.0051 0.1006 ± 0.0045 0.6200 ± 0.0005 0.6423 ± 0.0005 0.6908 ± 0.0001

AUROC 0.4997 ± 0.0066 0.4988 ± 0.0125 0.5007 ± 0.0010 0.4708 ± 0.0003 0.5576 ± 0.0005

P@10

0.2150 ± 0.0310 0.0900 ± 0.0228 0.1086 ± 0.0001 0.2908 ± 0.0001 0.5986 ± 0.0001

Table 3 summarises the detection performance for all the methods on this
inductive task. The lower values compared to Table 2 are indicative that the
problem here is more challenging than anomaly detection on a single dataset;
nonetheless, we see that our RCAE method manages to convincingly outper-
form both the SVD and AE baselines. This is conﬁrmed qualitatively in Fig-
ure 4, where we see that RCAE correctly identiﬁes many cats in the test set as
anomalous, while the basic CAE method suﬀers.

5.3 Image denoising results

Finally, we test the ability of the model to de-noise images, which is a form
of anomaly detection on individual pixels (or more generally, features). In this
experiment, we train all models on a set of 5000 images of dogs from cifar-10.
For each image, we then add salt-and-pepper noise at a rate of 10%. Our goal is
to recover the original image as accurately as possible.

Figure 5 illustrates that the most anomalous images in the presence of noise
contain images of the variations of dog class images (e.g. containing person’s
face). Further, Figure 6 illustrates for various methods the mean square error
between the reconstructed and original images. RCAE eﬀectively suppresses the
noise as evident from the low error. The improvement over raw CAE is modest,
but suggests that there is beneﬁt to explicitly accounting for noise.

5.4 Comparison of training times

We remark ﬁnally that our RCAE method is comparable in training eﬃciency to
existing methods. For example, on the small-scale restaurant dataset, it takes

14

Chalapathy, Menon and Chawla

(a) RCAE.

(b) RPCA.

Fig. 5. Top anomalous images in original form (ﬁrst row), noisy form (second row),
image denoising task on cifar-10.

Fig. 6. Illustration of the mean square error boxplots obtained for various models on
image denoising task, cifar-10 dataset. In this setting, RCAE suppresses the noise
and detects the background and foreground images eﬀectively.

1 minute to train RPCA, and 8.5 minutes to train RKPCA, compared with 10
minutes for our RCAE method. The ability to leverage recent advances in deep
learning as part of our optimisation (e.g. training models on a GPU) is we believe
a salient feature of our approach.

We note that while the RKPCA method is fast to train on smaller datasets,
on larger datasets it suﬀers from the O(n2) complexity of kernel methods; for
example, it takes over an hour to train on the cifar-10 dataset. It is plausible
that one could leverage recent advances in fast approximations of kernel meth-
ods [24], and studying these would be of interest in future work. Note that the
issue of using a ﬁxed kernel function would remain, however.

Robust, Deep and Inductive Anomaly Detection

15

6 Conclusion

We have extended the robust PCA model to the nonlinear autoencoder setting.
To the best of our knowledge, ours is the ﬁrst approach which is robust, nonlinear
and inductive. The robustness ensures that the model is not over-sensitive to
anomalies; the nonlinearity helps discover potentially more subtle anomalies;
and being inductive makes it possible to deploy our model in a live setting.

While autoencoders are a powerful mechansim for data representation they
suﬀer from their “black-box” nature. There is a growing body of research on
outlier description, i.e., explain the reason why a data point is anomalous. A
direction of future reason is to extend deep autoencoders for outlier description.

References

1. Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G.S.,
Davis, A., Dean, J., Devin, M., et al.: Tensorﬂow: Large-scale machine learning on
heterogeneous distributed systems. arXiv preprint arXiv:1603.04467 (2016)

2. Aggarwal, C.C.: Outlier Analysis. Springer, 2nd edn. (2016)
3. Bach, F., Jenatton, R., Mairal, J., Obozinski, G.: Convex Optimization with
Sparsity-Inducing Norms. In: Optimization for Machine Learning, MIT Press
(2011)

4. Bay, S.D., Schwabacher, M.: Mining distance-based outliers in near linear time
with randomization and a simple pruning rule. In: International Conference on
Knowledge Discovery and Data Mining (KDD) (2003)

5. Bengio, Y., et al.: Learning deep architectures for ai. Foundations and trends R(cid:13) in

Machine Learning 2(1), 1–127 (2009)

6. Bishop, C.M.: Pattern Recognition and Machine Learning. Springer (2006)
7. Breunig, M.M., Kriegel, H.P., Ng, R.T., Sander, J.: Lof: identifying density-based

local outliers. In: ACM sigmod record. vol. 29, pp. 93–104. ACM (2000)

8. Cand´es, E., Li, X., Ma, Y., Wright, J.: Robust principal component analysis?: Re-
covering low-rank matrices from sparse errors. In: Sensor Array and Multichannel
Signal Processing Workshop (SAM), 2010 IEEE. pp. 201–204. IEEE (2010)

9. Chandola, V., Banerjee, A., Kumar, V.: Outlier detection: A survey. ACM Com-

puting Surveys (2007)

10. Clevert, D.A., Unterthiner, T., Hochreiter, S.: Fast and accurate deep network
learning by exponential linear units (elus). arXiv preprint arXiv:1511.07289 (2015)
11. Davis, J., Goadrich, M.: The relationship between precision-recall and roc curves.

In: International Conference on Machine Learning (ICML) (2006)

12. Ghoting, A., Parthasarathy, S., Otey, M., Ghoting, A., Parthasarathy, S., Otey,
M.E.: Fast mining of distance-based outliers in high-dimensional datasets. Data
Mining and Knowledge Discovery 16(3), 349–364 (2008)

13. Goodfellow, I., Bengio, Y., Courville, A.: Deep Learning. MIT Press (2016), http:

//www.deeplearningbook.org

14. Hawkins, D.: Identiﬁcation of Outliers. Chapman and Hall, London (1980)
15. Hotelling, H.: Analysis of a complex of statistical variables into principal compo-

16. Huang, J., Zhang, T.: The beneﬁt of group sparsity. Ann. Statist. 38(4), 1978–2004

nents. J. Educ. Psych. 24 (1933)

(08 2010)

16

Chalapathy, Menon and Chawla

17. Hull, J.J.: A database for handwritten text recognition research. IEEE Transactions

on pattern analysis and machine intelligence 16(5), 550–554 (1994)

18. Ioﬀe, S., Szegedy, C.: Batch normalization: Accelerating deep network training by

reducing internal covariate shift. arXiv preprint arXiv:1502.03167 (2015)

19. Jain, V., Seung, S.: Natural image denoising with convolutional networks. In: Ad-

vances in Neural Information Processing Systems 21, pp. 769–776 (2008)

20. Kingma, D., Ba, J.: Adam: A method for stochastic optimization. arXiv preprint

21. Knorr, E.M., Ng, R.T.: A uniﬁed notion of outliers: Properties and computation.

22. Krizhevsky, A., Hinton, G.: Learning multiple layers of features from tiny images.

arXiv:1412.6980 (2014)

In: KDD. pp. 219–222 (1997)

Tech. rep. (2009)

23. Lawrence, N.D., Urtasun, R.: Non-linear matrix factorization with gaussian pro-

cesses. In: International Conference on Machine Learning (ICML) (2009)

24. Lopez-Paz, D., Sra, S., Smola, A.J., Ghahramani, Z., Sch¨olkopf, B.: Randomized
nonlinear component analysis. In: International Conference on Machine Learning
(ICML) (2014)

25. Nguyen, M.H., Torre, F.: Robust kernel principal component analysis. In: Advances

in Neural Information Processing Systems (NIPS) (2009)

26. Recht, B., Fazel, M., Parrilo, P.A.: Guaranteed minimum-rank solutions of linear
matrix equations via nuclear norm minimization. SIAM review 52(3), 471–501
(2010)

27. Schlkopf, B., Platt, J.C., Shawe-Taylor, J.C., Smola, A.J., Williamson, R.C.: Esti-
mating the support of a high-dimensional distribution. Neural Computation 13(7),
14431471 (Jul 2001)

28. Sedhain, S., Menon, A.K., Sanner, S., Xie, L.: Autorec: Autoencoders meet col-
laborative ﬁltering. In: International Conference on World Wide Web (WWW)
(2015)

29. Sprechmann, P., Bronstein, A.M., Sapiro, G.: Learning eﬃcient sparse and low
rank models. IEEE Transactions on Pattern Analysis and Machine Intelligence
37(9), 1821–1833 (Sept 2015)

30. Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol, P.A.: Stacked denois-
ing autoencoders: Learning useful representations in a deep network with a local
denoising criterion. JMLR 11, 3371–3408 (2010)

31. Williams, G., Baxter, R., He, H., Hawkins, S., Gu, L.: A comparative study of rnn
for outlier detection in data mining. In: International Conference on Data Mining
(ICDM) (2002)

32. Xiong, L., Chen, X., Schneider, J.: Direct robust matrix factorizatoin for anomaly
detection. In: International Conference on Data Mining (ICDM). IEEE (2011)
33. Xu, H., Caramanis, C., Sanghavi, S.: Robust PCA via outlier pursuit. In: Advances

in Neural Information Processing Systems. pp. 2496–2504 (2010)

34. Zhai, S., Cheng, Y., Lu, W., Zhang, Z.: Deep structured energy based models
for anomaly detection. In: International Conference on Machine Learning (ICML)
(2016)

35. Zhao, M., Saligrama, V.: Anomaly detection with score functions based on nearest
neighbor graphs. In: Advances in Neural Information Processing Systems (NIPS).
pp. 2250–2258 (2009)

