Gauge Equivariant Mesh CNNs
Anisotropic convolutions on geometric graphs

Pim de Haan * 1 2 3 Maurice Weiler * 2 3 Taco Cohen 1 Max Welling 1 3

0
2
0
2
 
r
a

M
 
1
1
 
 
]

G
L
.
s
c
[
 
 
1
v
5
2
4
5
0
.
3
0
0
2
:
v
i
X
r
a

Abstract
A common approach to deﬁne convolutions on
meshes is to interpret them as a graph and ap-
ply graph convolutional networks (GCNs). Such
GCNs utilize isotropic kernels and are there-
fore insensitive to the relative orientation of
vertices and thus to the geometry of the mesh
as a whole. We propose Gauge Equivariant
Mesh CNNs which generalize GCNs to apply
anisotropic gauge equivariant kernels. Since
the resulting features carry orientation informa-
tion, we introduce a geometric message passing
scheme deﬁned by parallel transporting features
over mesh edges. Our experiments validate the
signiﬁcantly improved expressivity of the pro-
posed model over conventional GCNs and other
methods.

1. Introduction

Convolutional neural networks (CNNs) have been estab-
lished as the default method for many machine learning
tasks like speech recognition or planar and volumetric image
classiﬁcation and segmentation. Most CNNs are restricted
to ﬂat or spherical geometries, where convolutions are easily
deﬁned and optimized implementations are available. The
empirical success of CNNs on such spaces has generated
interest to generalize convolutions to more general spaces
like graphs or Riemannian manifolds, creating a ﬁeld now
known as geometric deep learning (Bronstein et al., 2017).

A case of speciﬁc interest is convolution on meshes, the
discrete analog of 2-dimensional embedded Riemannian
manifolds. Mesh CNNs can be applied to tasks such as
detecting shapes, registering different poses of the same
shape and shape segmentation. If we forget the positions of
vertices, and which vertices form faces, a mesh M can be

*Equal contribution 1Qualcomm AI Research, Amsterdam, NL.
Qualcomm AI Research is an initiative of Qualcomm Technolo-
gies, Inc. 2Qualcomm-University of Amsterdam (QUVA) Lab
3AMLab, University of Amsterdam. Correspondence to: Pim de
Haan <pim@qti.qualcomm.com>.

Figure 1. Two local neighbourhoods around vertices p and their
representations in the tangent planes TpM . The distinct geometry
of the neighbourhoods is reﬂected in the different angles θpqi of
incident edges from neighbours qi. Graph convolutional networks
apply isotropic kernels and can therefore not distinguish both
neighbourhoods. Gauge Equivariant Mesh CNNs apply anisotropic
kernels and are therefore sensitive to orientations. The arbitrariness
of reference orientations, determined by a choice of neighbour q0,
is accounted for by the gauge equivariance of the model.

represented by a graph G. This allows for the application of
graph convolutional networks (GCNs) to processing signals
on meshes.

However, when representing a mesh by a graph, we lose
important geometrical information. In particular, in a graph
there is no notion of angle between or ordering of two of
a node’s incident edges (see ﬁgure 1). Hence, a GCNs
output at a node p is designed to be independent of relative
angles and invariant to any permutation of its neighbours
qi ∈ N (p). A graph convolution on a mesh graph therefore
corresponds to applying an isotropic convolution kernel.
Isotropic ﬁlters are insensitive to the orientation of input
patterns, so their features are strictly less expressive than
those of orientation aware anisotropic ﬁlters.

To address this limitation of graph networks we pro-
pose Gauge Equivariant Mesh CNNs (GEM-CNN), which
minimally modify GCNs such that they are able to use
anisotropic ﬁlters while sharing weights across different
positions and respecting the local geometry. One obstacle in
sharing anisotropic kernels, which are functions of the angle
θpq of neighbour q with respect to vertex p, over multiple
vertices of a mesh is that there is no unique way of selecting
a reference neighbour q0, which has the direction θpq0 = 0.
The reference neighbour, and hence the orientation of the
neighbours, needs to be chosen arbitrarily. In order to guar-

Gauge Equivariant Mesh CNNs

antee the equivalence of the features resulting from different
choices of orientations, we adapt Gauge Equivariant CNNs
(Cohen et al., 2019b) to general meshes. The kernels of
our model are thus designed to be equivariant under gauge
transformations, that is, to guarantee that the responses for
different kernel orientations are related by a prespeciﬁed
transformation law. Such features are identiﬁed as geomet-
ric objects like scalars, vectors, tensors, etc., depending on
the speciﬁc choice of transformation law. In order to com-
pare such geometric features at neighbouring vertices, they
need to be parallel transported along the connecting edge.

In our implementation we ﬁrst specify the transformation
laws of the feature spaces and compute a space of gauge
equivariant kernels. Then we pick arbitrary reference orien-
tations at each node, relative to which we compute neigh-
bour orientations and compute the corresponding edge trans-
porters. Given these quantities, we deﬁne the forward pass
as a message passing step via edge transporters followed by
a contraction with the equivariant kernels evaluated at the
neighbour orientations. Algorithmically, Gauge Equivari-
ant Mesh CNNs are therefore just GCNs with anisotropic,
gauge equivariant kernels and message passing via parallel
transporters. Conventional GCNs are covered in this frame-
work for the speciﬁc choice of isotropic kernels and trivial
edge transporters, given by identity maps.

In Sec. 2, we will give an outline of our method, deferring
details to Secs. 3, 4 and 5. In our experiments in Sec. 7, we
ﬁnd that the enhanced expressiveness of Gauge Equivariant
Mesh CNNs enables them to outperform conventional GCNs
and other prior work in a shape correspondence task.

2. Convolutions on Graphs with Geometry

We consider the problem of processing signals on discrete
2-dimensional manifolds, or meshes M . Such meshes are
described by a set V of vertices in R3 together with a set F
of tuples, each consisting of the vertices at the corners of a
face. For a mesh to describe a proper manifold, each edge
needs to be connected to two faces, and the neighbourhood
of each vertex needs to be homeomorphic to a disk. Mesh
M induces a graph G by forgetting the coordinates of the
vertices while preserving the edges.

A conventional graph convolution between kernel K and
signal f , evaluated at a vertex p, can be deﬁned by

(K (cid:63) f )p = Kselffp +

Kneighfq,

(1)

(cid:88)

q∈Np

where Np is the set of neighbours of p in G, and Kself ∈
RCin×Cout and Kneigh ∈ RCin×Cout are two linear maps which
model a self interaction and the neighbour contribution,
respectively. Importantly, graph convolution does not distin-
guish different neighbours, because each feature vector fq

Algorithm 1 Gauge Equivariant Mesh CNN layer

Input: mesh M , input/output feature types ρin, ρout, reference
neighbours (qp
0 ∈ Np)p∈M .
Compute basis kernels K i
Initialise weights wi
For each neighbour pair, p ∈ M, q ∈ Np:

(cid:66) Sec. 4.
compute neighbor angles θpq relative to reference neighbor
compute parallel transporters gq→p
Forward(cid:0)input features (fp)p∈M , weights wi

self, K i
neigh.

self and wi

(cid:66) Sec. 3

neigh(θ)

(cid:1):

self, wi

p ← (cid:80)
f (cid:48)

wi

selfK i

selffp + (cid:80)

wi

neighK i

i

i,q∈Np

neigh
neigh(θpq)ρin(gq→p)fq

is multiplied by the same matrix Kneigh and then summed.
For this reason we say the kernel is isotropic.

Consider the example in ﬁgure 1, where on the left and right,
the neighbourhood of one vertex p, containing neighbours
q ∈ Np, is visualized. An isotropic kernel would propagate
the signal from the neighbours to p in exactly the same way
in both neighbourhoods, even though the neighbourhoods
are geometrically distinct. For this reason, our method uses
direction sensitive (anisotropic) kernels instead of isotropic
kernels. Anisotropic kernels are inherently more expressive
than isotropic ones which is why they are used universally
in conventional planar CNNs.

We propose the Gauge Equivariant Mesh Convolution, a
minimal modiﬁcation of graph convolution that allows for
anisotropic kernels K(θ) whose value depends on an orien-
tation θ ∈ [0, 2π). To deﬁne the orientations θpq of neigh-
bouring vertices q ∈ Np of p, we ﬁrst map them to the
tangent plane TpM at p, as visualized in ﬁgure 1. We then
pick an arbitrary reference neighbour qp
0 to determine a
reference orientation1 θpqp
:= 0, marked orange in ﬁgure 1.
This induces a basis on the tangent plane, which, when ex-
pressed in polar coordinates, deﬁnes the angles θpq of the
other neighbours.

0

As we will motivate in the next section, features in a Gauge
Equivariant CNN are coefﬁcients of geometric quantities.
For example, a tangent vector at vertex p can be described
either geometrically by a 3 dimensional vector orthogonal
to the normal at p or by two coefﬁcients in the basis on the
tangent plane. In order to perform convolution, geometric
features at different vertices need to be linearly combined,
for which it is required to ﬁrst “parallel transport” the fea-
tures to the same vertex. This is done by applying a matrix
ρ(gq→p) ∈ RCout×Cin to the coefﬁcients of the feature at
q, in order to obtain the coefﬁcients of the feature vector
transported to p, which can be used for the convolution at p.
The transporter depends on the geometric type of the feature,
denoted by ρ. Details of how the tangent space is deﬁned,

1 Mathematically, this corresponds to a choice of local refer-

ence frame or gauge.

Gauge Equivariant Mesh CNNs

qA

conv in
gauge A

qB

p

qC

qA

qB

p

qC

qA

conv in
gauge A

qB

p

qC

qA

qB

p

qC

pick gauge
q0 = qA

map back
to mesh

pick gauge
q0 = qA

map back
to mesh

geometric conv

geometric conv

g
a
u
g
e

t
r
a
n
s
f
o
r
m
a
t
i
o
n
A
→
B

g
a
u
g
e

t
r
a
n
s
f
r
o
m
a
t
i
o
n
A
→
B

pick gauge
q0 = qB

map back
to mesh

qB

qC

p

qA

conv in
gauge B

qB

qC

p

qA

pick gauge
q0 = qB

map back
to mesh

qB

qC

p

qA

conv in
gauge B

qB

qC

p

qA

g
a
u
g
e

t
r
a
n
s
f
r
o
m
a
t
i
o
n
A
→
B

g
a
u
g
e

t
r
a
n
s
f
o
r
m
a
t
i
o
n
A
→
B

(a) Convolution from scalar to scalar features.

(b) Convolution from scalar to vector features.

Figure 2. Visualization of the Gauge Equivariant Mesh Convolution in two conﬁgurations, scalar to scalar and scalar to vector. The
convolution operates in a gauge, so that vectors are expressed in coefﬁcients in a basis and neighbours have polar coordinates, but can
also be seen as a geometric convolution, a gauge-independent map from an input signal on the mesh to a output signal on the mesh. The
convolution is equivariant if this geometric convolution does not depend on the intermediate chosen gauge, so if the diagram commutes.

how to compute the map to the tangent space, angles θpq,
and the parallel transporter are given in Sec 4.

In combination, this leads to the GEM-CNN convolution

(K (cid:63) f )p = Kselffp +

(cid:88)

q∈Np

Kneigh(θpq)ρ(gq→p)fq

(2)

which differs from the conventional graph convolution, de-
ﬁned in Eq. 1 only by the use of an anisotropic kernel and
the parallel transport message passing.

We require the outcome of the convolution to be equiva-
lent for any choice of reference orientation. This is not the
case for any anisotropic kernel but only for those which are
equivariant under changes of reference orientations (gauge
transformations). Equivariance imposes a linear constraint
on the kernels. We therefore solve for complete sets of
self and K i
“basis-kernels” K i
neigh satisfying this constraint and
linearly combine them with parameters wi
neigh such
that Kself = (cid:80)
neighK i
selfK i
neigh.
Details on the computation of basis kernels are given in sec-
tion 3. The full algorithm for initialisation and forward pass,
which is of time and space complexity linear in the number
of vertices, for a GEM-CNN layer are listed in algorithm 1.
Gradients can be computed by automatic differentiation.

self and Kneigh = (cid:80)

self and wi
i wi

i wi

3. Gauge Equivariance & Geometric Features

On a general mesh, the choice of the reference neighbour, or
gauge, which deﬁnes the orientation of the kernel, can only
be made arbitrarily. However, this choice should not arbi-
trarily affect the outcome of the convolution, as this would
impede the generalization between different locations and
different meshes. Instead, Gauge Equivariant Mesh CNNs
have the property that their output transforms according to
a known rule as the gauge changes.

Consider the left hand side of ﬁgure 2(a). Given a neigh-
bourhood of vertex p, we want to express each neighbour
q in terms of its polar coordinates (rq, θq) on the tangent
plane, so that the kernel value at that neighbour Kneigh(θq)
is well deﬁned. This requires choosing a basis on the tan-
gent plane, determined by picking a neighbour as reference
neighbour (denoted q0), which has the zero angle θq0 = 0.
In the top path, we pick qA as reference neighbour. Let us
call this gauge A, in which neighbours have angles θA
q . In
the bottom path, we instead pick neighbour qB as reference
point and are in gauge B. We get a different basis for the
tangent plane and different angles θB
q for each neighbour.
Comparing the two gauges, we see that they are related by a
rotation, so that θB
q − θA
qB . This change of gauge is
called a gauge transformation of angle g := θA

q = θA

qB .

In ﬁgure 2(a), we illustrate a gauge equivariant convolution
that takes input and output features such as gray scale image

Gauge Equivariant Mesh CNNs

values on the mesh, which are called scalar features. The top
path represents the convolution in gauge A, the bottom path
in gauge B. In either case, the convolution can be interpreted
as consisting of three steps. First, for each vertex p, the value
of the scalar features on the mesh at each neighbouring
vertex q, represented by colors, is mapped to the tangent
plane at p at angle θq deﬁned by the gauge. Subsequently,
the convolutional kernel sums for each neighbour q, the
product of the feature at q and kernel K(θq). Finally the
output is mapped back to the mesh. These three steps can be
composed into a single step, which we could call a geometric
convolution, mapping from input features on the mesh to
output features on the mesh. The convolution is gauge
equivariant if this geometric convolution does not depend
on the gauge we pick in the interim, so in ﬁgure 2(a), if
the convolution in the top path in gauge A has same result
the convolution in the bottom path in gauge B, making the
diagram commute. In this case, however, we see that the
convolution output needs to be the same in both gauges, for
the convolution to be equivariant. Hence, we must have that
K(θq) = K(θq − g), as the orientations of the neighbours
differ by some angle g, and the kernel must be isotropic.

As we aim to design an anisotropic convolution, the output
feature of the convolution at p can, instead of a scalar, be two
numbers v ∈ R2, which can be interpreted as coefﬁcients of
a tangent feature vector in the tangent space at p, visualized
in ﬁgure 2(b). As shown on the right hand side, different
gauges induce a different basis of the tangent plane, so that
the same tangent vector (shown on the middle right on the
mesh), is represented by different coefﬁcients in the gauge
(shown on the top and bottom on the right). This gauge
equivariant convolution must be anisotropic: going from
the top row to the bottom row, if we change orientations of
the neighbours by −g, the coefﬁcients of the output vector
v ∈ R2 of the kernel must be also rotated by −g. This is
written as R(−g)v, where R(−g) ∈ R2×2 is the matrix that
rotates by angle −g.

Vectors and scalars are not the only kind of geometric
features that can be inputs and outputs of a GEM-CNN
layer.
In general, the coefﬁcients of a geometric fea-
ture of C dimensions changes by a linear transformation
ρ(−g) ∈ RC×C if the gauge is rotated by angle g. The map
ρ : [0, 2π) → RC×C is called the type of the geometric
quantity and is formally known as a group representation
of the planar rotation group SO(2). From the theory of
group representations, we know that any feature type can
be composed from “irreducible representations” (irreps).
For SO(2), these are the one dimensional invariant scalar
representation ρ0 and for all n ∈ N>0, a two dimensional
representation ρn,

ρ0(g) = 1,

ρn(g) =

(cid:18)cos ng
sin ng

(cid:57) sin ng
cos ng

(cid:19)

.

ρin → ρout
ρ0 → ρ0
ρn → ρ0

ρ0 → ρm

ρn → ρm

ρin → ρout
ρ0 → ρ0

ρn → ρn

linearly independent solutions for Kneigh(θ)
(1)
(cos nθ sin nθ) , (sin nθ (cid:57) cos nθ)

(cid:17)

(cid:17)

(cid:16)cos mθ
sin mθ
(cid:17)
(cid:16) s(cid:57) c(cid:57)
(cid:57)c(cid:57) s(cid:57)

,

(cid:16) sin mθ
(cid:57) cos mθ
(cid:17)

,
(cid:16)c+ s+
s+ (cid:57)c+

,

(cid:16) (cid:57)s+ c+
c+ s+

(cid:17)

(cid:16)c(cid:57) (cid:57)s(cid:57)
c(cid:57)

s(cid:57)

(cid:17)

,

linearly independent solutions for Kself
(1)
(cid:17)

(cid:17)

(cid:16)1 0
0 1

(cid:16) 0 1
(cid:57)1 0

,

Table 1. Solutions to the angular kernel constraint for kernels
that map from ρn to ρm. We denote c± = cos((m ± n)θ) and
s± = sin((m ± n)θ).

Scalars and tangent vector features correspond to ρ0 and ρ1
respectively and we have R(g) = ρ1(g).

The type of the feature at each layer in the network can thus
be fully speciﬁed (up to a change of basis) by the number
of copies of each irrep. Similar to the dimensionality in a
conventional CNN, the choice of type is a hyperparameter
that can be freely chosen to optimize performance.

We use a notation, such that, for example, ρ = 1ρ0 ⊕ 2ρ1
means that the feature contains one ρ0 irrep, which is a
scalar, and two ρ1 irreps, which are vectors. This feature is
ﬁve dimensional (1×dim ρ0 +2×dim ρ1 = 1×1+2×2 =
5) and transforms transforms with block diagonal matrix:

ρ(g) =

cos g (cid:57) sin g
cos g
sin g



1











cos g (cid:57) sin g
cos g
sin g

3.1. Kernel Constraint

Given an input type ρin and output type ρout of dimen-
sions Cin and Cout, the kernels are Kself ∈ RCout×Cin and
Kneigh : [0, 2π) → RCout×Cin. However, not all such ker-
nels are equivariant. Consider again examples ﬁgure 2(a)
and ﬁgure 2(b). If we map from a scalar to a scalar, we
get that Kneigh(θ − g) = Kneigh(θ) for all angles θ, g and
the convolution is isotropic. If we map from a scalar to a
vector, we get that rotating the angles θq results in the same
tangent vector as rotating the output vector coefﬁcients, so
that Kneigh(θ − g) = R(−g)Kneigh(θ).

In general, as derived by Cohen et al. (2019b) and in ap-
pendix A, the kernels must satisfy for any gauge transfor-
mation g ∈ [0, 2π) and angle θ ∈ [0, 2π), that

Kneigh(θ − g) = ρout(−g) Kneigh(θ) ρin(g),

Kself = ρout(−g) Kself ρin(g).

(3)

(4)

The kernel can be seen as consisting of multiple blocks,

Gauge Equivariant Mesh CNNs

where each block takes as input one irrep and outputs one
irrep. For example if ρin would be of type 1ρ0 ⊕ 2ρ1 and
ρout of type 1ρ1 ⊕ 1ρ3, we have

Kneigh(θ) =

(cid:18)K10(θ) K11(θ) K11(θ)
K30(θ) K31(θ) K31(θ)

(cid:19)

∈ R4×5.

where e.g. K31(θ) ∈ R2×2 is a kernel that takes as input
irrep ρ1 and as output irrep ρ3 and needs to satisfy Eq. 3. As
derived by Weiler & Cesa (2019) and in Appendix B, the ker-
nels Kneigh(θ) and Kself mapping from irrep ρn to irrep ρm
can be written as a linear combination of the basis kernels
listed in table 1. The table shows that equivariance requires
the self-interaction to only map from one irrep to the same
∈ R4×3.

irrep. Hence, we have Kself =

(cid:18)0 K11 K11
0
0
0

(cid:19)

All basis-kernels of all pairs of input irreps and output irreps
can be linearly combined to form an arbitrary equivariant
kernel from feature of type ρin to ρout. In the above example,
we have 2 × 2 + 4 × 4 = 20 basis kernels for Kneigh and 4
basis kernels for Kself. The layer thus has 24 parameters.

4. Geometry & Parallel Transport

A gauge, or choice of reference neighbor at each vertex,
fully determines the neighbor orientations θpq and the par-
allel transporters gq→p along edges. The following two
subsections give details on how to compute these quantities.

4.1. Local neighborhood geometry

Neighbours q of vertex p can be mapped uniquely to the
tangent plane at p using a map called the Riemannnian loga-
rithmic map, visualized in ﬁgure 1. A choice of reference
neighbor then determines a reference frame in the tangent
space which assigns polar coordinates to all other neighbors.
The neighbour orientations θpq are the angular components
of each neighbor in this polar coordinate system.

We deﬁne the tangent space TpM at vertex p as that two di-
mensional subspace of R3, which is determined by a normal
vector n given by the area weighted average of the normal
vectors of the adjacent mesh faces. While the tangent spaces
are two dimensional, we implement them as being embed-
ded in the ambient space R3 and therefore represent their
elements as three dimensional vectors. The reference frame
corresponding to the chosen gauge, deﬁned below, allows
to identify these 3-vectors by their coefﬁcient 2-vectors.

Each neighbor q is represented in the tangent space by the
vector logp(q) ∈ TpM which is computed via the discrete
analog of the Riemannian logarithm map. We deﬁne this
map logp : Np → TpM for neighbouring nodes as the
projection of the edge vector q − p on the tangent plane,
followed by a rescaling such that the norm | logp(q)| =
|q − p| is preserved. Writing the projection operator on the

tangent plane as (1 − nn(cid:62)), the logarithmic map is thus
given by:

logp(q) := |q − p|

(1 − nn(cid:62))(q − p)
|(1 − nn(cid:62))(q − p)|

Geometrically, this map can be seen as “folding” each edge
up to the tangent plane, and therefore encodes the orientation
of edges and preserves their lengths.

The normalized reference edge vector logp(q0) uniquely
determines a right handed, orthonormal reference frame
(ep,1, ep,2) of TpM by setting ep,1 := logp(q0)/| logp(q0)|
and ep,2 := n × ep,1. The angle θpq is then deﬁned as the
angle of logp(q) in polar coordinates corresponding to this
reference frame. Numerically, it can be computed by

θpq := atan2 (cid:0)e(cid:62)

p,2 logp(q), e(cid:62)

p,1 logp(q))(cid:1).

Given the reference frame (ep,1, ep,2), a 2-tuple of coefﬁ-
cients (v1, v2) ∈ R2 speciﬁes an (embedded) tangent vector
v1ep,1 + v2ep,2 ∈ TpM ⊂ R3. This assignment is formally
given by the gauge map Ep : R2 → TpM ⊂ R3 which is a
vector space isomorphism. In our case, it can be identiﬁed
with the matrix


 ep,1


 ∈ R3×2.

ep,2

Ep =

(5)

4.2. Parallel edge transporters

On curved meshes, feature vectors fq and fp at different
locations q and p are expressed in different gauges, which
makes it geometrically invalid to accumulate their informa-
tion directly. Instead, when computing a new feature at p,
the neighboring feature vectors at q ∈ Np ﬁrst have to be
parallel transported into the feature space at p before they
can be processed. The parallel transport along the edges
of a mesh is determined by the (discrete) Levi-Civita con-
nection corresponding to the metric induced by the ambient
space R3. This connection is given by parallel transporters
gq→p ∈ [0, 2π) on the mesh edges which map tangent vec-
tors vq ∈ TqM at q to tangent vectors R(gq→p)vq ∈ TpM
at p. Feature vectors fq of type ρ are similarly transported
to ρ(gq→p)fq by applying the corresponding feature vector
transporter ρ(gq→p).

In order to build some intuition, it is illustrative to ﬁrst
consider transporters on a planar mesh. In this case the
parallel transport can be thought of as moving a vector along
an edge without rotating it. The resulting abstract vector
is then parallel to the original vector in the usual sense on
ﬂat spaces, see ﬁgure 3(a). However, if the (transported)
source frame at q disagrees with the target frame at p, the
coefﬁcients of the transported vector have to be transformed
to the target coordinates. This coordinate transformation

Gauge Equivariant Mesh CNNs

(a) Parallel transport on a ﬂat mesh.

(b) Parallel transport along an edge of a general mesh.

Figure 3. Parallel transport of tangent vectors v ∈ TqM at q to R(gq→p)v ∈ TpM at p on meshes. On a ﬂat mesh, visualized in
ﬁgure 3(a), parallel transport moves a vector such that it stays parallel in the usual sense on ﬂat spaces. The parallel transporter
gq→p = ϕp − ϕq corrects the transported vector coefﬁcients for differing gauges at q and p. When transporting along the edge of a general
mesh, the tangent spaces at q and p might not be aligned, see ﬁgure 3(b). Before correcting for the relative frame orientation via gq→p, the
tangent space TqM , and thus v ∈ TqM , is rotated by an angle α around nq ×np such that its normal nq coincides with that of np.

from polar angles ϕq of v to ϕp of R(gq→p)v deﬁnes the
transporter gq→p = ϕp − ϕq.

On general meshes one additionally has to account for the
fact that the tangent spaces TqM ⊂ R3 and TpM ⊂ R3
are usually not parallel in the ambient space R3. The par-
allel transport therefore includes the additional step of ﬁrst
aligning the tangent space at q to be parallel to that at p,
before translating a vector between them, see ﬁgure 3(b). In
particular, given the normals nq and np of the source and
target tangent spaces TqM and TpM , the source space is
being aligned by rotating it via Rα ∈ SO(3) by an angle
α = arccos(n(cid:62)
q np) around the axis nq ×np in the ambient
space. Denote the rotated source frame by (Rαeq,1, Rαeq,2)
and the target frame by (ep,1, ep,2). The angle to account
for the parallel transport between the two frames, deﬁning
the discrete Levi-Civita connection on mesh edges, is then
found by computing

gq→p = atan2 (cid:0)(Rαeq,2)(cid:62)ep,1, (Rαeq,1)(cid:62)ep,1

(cid:1).

(6)

In practice we precompute these connections before training
a model.

Under gauge transformations by angles gp at p and gq at q
the parallel transporters transform according to

gq→p (cid:55)→ gp + gq→p − gq .

(7)

Intuitively, this transformation states that a transporter in
a transformed gauge is given by a gauge transformation
back to the original gauge via −gq followed by the original
transport by gq→p and a transformation back to the new
gauge via gp.

For more details on discrete connections and transporters,
extending to arbitrary paths e.g. over faces, we refer to (Lai
et al., 2009; Crane et al., 2010; 2013).

5. Non-linearity

Besides convolutional layers, the GEM-CNN contains non-
linear layers, which also need to be gauge equivariant, for
the entire network to be gauge equivariant. The coefﬁ-
cients of features built out of irreducible representaions, as
described in section 3, do not commute with point-wise non-
linearities (Worrall et al., 2017; Thomas et al., 2018; Weiler
et al., 2018a; Kondor et al., 2018). Norm non-linearities
and gated non-linearities (Weiler & Cesa, 2019) can be used
with such features, but generally perform worse in prac-
tice compared to point-wise non-linearities (Weiler & Cesa,
2019). Hence, we propose the RegularNonlinearity, which
uses point-wise non-linearities and is approximately gauge
equivariant.

This non-linearity is built on Fourier transformations. Con-
sider a continuous periodic signal, on which we perform a
band-limited Fourier transform with band limit b, obtaining
2b+1 Fourier coefﬁcients. If this continuous signal is shifted
by an arbitrary angle g, then the corresponding Fourier com-
ponents transform with linear transformation ρ0:b(−g), for
2b + 1 dimensional representation ρ0:b := ρ0 ⊕ ρ1 ⊕ ... ⊕ ρb.

It would be exactly equivariant to take a feature of type ρ0:b,
take a continuous inverse Fourier transform to a continuous
periodic signal, then apply a point-wise non-linearity to that
signal, and take the continuous Fourier transform, to recover
a feature of type ρ0:b. However, for implementation, we use
N intermediate samples and the discrete Fourier transform.
This is exactly gauge equivariant for gauge transformation
of angles multiple of 2π/N , but only approximately equiv-
ariant for other angles. It can be shown that as N → ∞, the
non-linearity is exactly gauge equivariant.

Gauge Equivariant Mesh CNNs

6. Related Work

The irregular structure of meshes leads to a variety of ap-
proaches to deﬁne convolutions. Closely related to our
method are graph based methods which are often based on
variations of graph convolutional networks (Kipf & Welling,
2017; Defferrard et al., 2016). GCNs have been applied
on spherical meshes (Perraudin et al., 2019) and cortical
surfaces (Cucurull et al., 2018; Zhao et al., 2019). Verma
et al. (2018) augment GCNs with anisotropic kernels which
are dynamically computed via an attention mechanism over
graph neighbours.

Instead of operating on the graph underlying a mesh, sev-
eral approaches leverage its geometry by treating it as a
discrete manifold. Convolution kernels can then be deﬁned
in geodesic polar coordinates which corresponds to a pro-
jection of kernels from the tangent space to the mesh via the
exponential map. This allows for kernels that are larger than
the immediate graph neighbourhood and message passing
over faces but does not resolve the issue of ambiguous ker-
nel orientation. Masci et al. (2015); Monti et al. (2016) and
Sun et al. (2018) address this issue by restricting the net-
work to orientation invariant features which are computed
by applying anisotropic kernels in several orientations and
pooling over the resulting responses. The models proposed
in (Boscaini et al., 2016) and (Schonsheck et al., 2018) are
explicitly gauge dependent with preferred orientations cho-
sen via the principal curvature direction and the parallel
transport of kernels, respectively. Poulenard & Ovsjanikov
(2018) proposed a non-trivially gauge equivariant network
based on geodesic convolutions, however, the model parallel
transports only partial information of the feature vectors,
corresponding to certain kernel orientations.

Another class of approaches deﬁnes spectral convolutions on
meshes However, as argued in (Bronstein et al., 2017), the
Fourier spectrum of a mesh depends heavily on its geometry,
which makes such methods instable under deformations and
impedes the generalization between different meshes. Spec-
tral convolutions further correspond to isotropic kernels.

A construction based on toric covering maps of topologically
spherical meshes was presented in (Maron et al., 2017). An
entirely different approach to mesh convolutions is to apply
a linear map to a spiral of neighbours (Bouritsas et al., 2019;
Gong et al., 2019), which works well only for meshes with
a similar graph structure.

On ﬂat Euclidean spaces our method corresponds to Steer-
able CNNs (Cohen & Welling, 2017; Weiler et al., 2018a;
Weiler & Cesa, 2019; Cohen et al., 2019a). As our model,
these networks process geometric feature ﬁelds of types ρ
and are equivariant under gauge transformations, however,
due to the ﬂat geometry, the parallel transporters become
trivial. Regular nonlinearities are on ﬂat spaces used in

Figure 4. Test errors for MNIST digit classiﬁcation on embedded
meshes. Except for the isotropic graph CNN, different curves
correspond to the same GEM-CNN model, trained on different
training geometries. The x-axis shows different test geometries
on which each model is tested. Shaded regions state the standard
errors of the means over 6 runs.

group convolutional networks (Cohen & Welling, 2016;
Weiler et al., 2018b; Hoogeboom et al., 2018; Bekkers et al.,
2018; Winkels & Cohen, 2018; Worrall & Brostow, 2018;
Worrall & Welling, 2019; Sosnovik et al., 2020).

7. Experiments

We examine the performance of the GEM-CNN and the
inﬂuence of varying geometry in two experiments.

7.1. Embedded MNIST

We ﬁrst investigate how Gauge Equivariant Mesh CNNs per-
form on, and generalize between, different mesh geometries.
For this purpose we conduct simple MNIST digit classiﬁca-
tion experiments on embedded rectangular meshes of 28×28
vertices. As a baseline geometry we consider a ﬂat mesh as
visualized in ﬁgure 5(a). A second type of geometry is de-
ﬁned as different isometric embeddings of the ﬂat mesh, see
ﬁgure 5(b). Note that this implies that the intrinsic geometry
of these isometrically embedded meshes is indistinguishable
from that of the ﬂat mesh. To generate geometries which are
intrinsically curved, we add random normal displacements
to the ﬂat mesh. We control the amount of curvature by
smoothing the resulting displacement ﬁelds with Gaussian
kernels of different widths σ and deﬁne the roughness of the
resulting mesh as 3 − σ. Figures 5(c)-5(h) show the results
for roughnesses of 0.5, 1, 1.5, 2, 2.25 and 2.5. For each of
the considered settings we generate 32 different train and
32 test geometries.

To test the performance on, and generalization between, dif-
ferent geometries, we train equivalent GEM-CNN models
on a ﬂat mesh and meshes with a roughness of 1, 1.5, 2,
2.25 and 2.5. Each model is tested individually on each
of the considered test geometries, which are the ﬂat mesh,
isometric embeddings and curved embeddings with a rough-
ness of 0.5, 1, 1.25, 1.5, 1.75, 2, 2.25 and 2.5. Figure 4

Gauge Equivariant Mesh CNNs

shows the test errors of the GEM-CNNs on the different
train geometries (different curves) for all test geometries
(shown on the x-axis). Since our model is purely deﬁned
in terms of the intrinsic geometry of a mesh, it is expected
to be insensitive to isometric changes in the embeddings.
This is empirically conﬁrmed by the fact that the test perfor-
mances on ﬂat and isometric embeddings are exactly equal.
As expected, the test error increases for most models with
the surface roughness. Models trained on more rough sur-
faces are hereby more robust to deformations. The models
generalize well from a rough training to smooth test geom-
etry up to a training roughness of 1.5. Beyond that point,
the test performances on smooth meshes degrades up to the
point of random guessing at a training roughness of 2.5.

As a baseline, we build an isotropic graph CNN with the
same network topology and number of parameters (≈ 163k).
This model is insensitive to the mesh geometry and therefore
performs exactly equal on all surfaces. While this enhances
its robustness on very rough meshes, its test error of 19.80±
3.43% is an extremely bad result on MNIST. In contrast, the
use of anisotropic ﬁlters of GEM-CNN allows it to reach
a test error of only 0.60 ± 0.05% on the ﬂat geometry. It
is therefore competitive with conventional CNNs on pixel
grids, which apply anisotropic kernels as well. More details
on the datasets, models and further experimental setup are
given in appendix C.1.

7.2. Shape Correspondence

As a second experiment, we perform non-rigid shape cor-
respondence on the FAUST dataset (Bogo et al., 2014),
following Masci et al. (2015) 2 . The data consists of 100
meshes of human bodies in various positions, split into 80
meshes for training and 20 for testing. The vertices are reg-
istered, such that vertices on the same position on the body,
such as the tip of the left thumb, have the same identiﬁer on
all meshes. All meshes have 6890 vertices, making this a
6890-class segmentation problem.

We use a simple architecture, which transforms the XY Z
coordinates of each vertex, which is of type 3ρ0, using 6 con-
volutional layers to a feature of type 64ρ0, with intermediate
features of type 16ρ0 ⊕ 16ρ1 ⊕ 16ρ2. The convolutional
layers use residual connections and the RegularNonlinearity
with N = 5 samples. Afterwards, we use two 1×1 convolu-
tions with ReLU to map ﬁrst to 256 channels and ﬁnally to
6890 channels, after which a softmax predicts the registra-
tion probabilities. The 1×1 convolutions use a dropout of
50% and 1E-4 weight decay. The network is trained with a
cross entropy loss with an initial learning rate of 0.01, which
is halved when training loss reaches a plateau.

As all ﬁgures in the FAUST data set are similarly meshed

2These experiments were executed on QUVA machines.

Model

Features Accuracy

ACNN (Boscaini et al., 2016)
Geodesic CNN (Masci et al., 2015)
MoNet (Monti et al., 2016)
FeaStNet (Verma et al., 2018)
ZerNet (Sun et al., 2018)
SpiralNet++ (Gong et al., 2019)

Graph CNN
Graph CNN

GEM-CNN
GEM-CNN (broken symmetry)

SHOT
SHOT
SHOT
XYZ
XYZ
XYZ

XYZ
SHOT

XYZ
XYZ

62.4 %
65.4 %
73.8 %
98.7%
96.9%
99.8%

1.40 ± 0.5 %
23.80 ± 8%

99.73 ± 0.04 %
99.89 ± 0.02 %

Table 2. Results of FAUST shape correspondence. Statistics are
means and standard errors of the mean of over three runs. All cited
results are from their respective papers.

and oriented, breaking the gauge equivariance in higher lay-
ers can actually be beneﬁcial. As shown in (Weiler & Cesa,
2019), symmetry can be broken by treating non-invariant
features as invariant features as input to the ﬁnal 1×1 con-
volution. Such architectures are equivariant on lower levels,
while allowing orientation sensitivity at higher layers.

As baselines, we compare to various models, some of which
use more complicated pipelines, such as (1) the computation
of geodesics over the mesh, which requires solving partial
differential equations, (2) pooling, which requires ﬁnding a
uniform sub-selection of vertices, (3) the pre-computation
of SHOT features which locally describe the geometry (Salti
et al., 2014), or (4) post-processing reﬁnement of the pre-
dictions. The GEM-CNN requires none of these additional
steps. In addition, we compare to SpiralNet++ (Gong et al.,
2019), which requires all inputs to be similarly meshed. Fi-
nally, we compare to an isotropic version of the GEM-CNN,
which reduces to a conventional graph CNN. The results in
table 2 show that the GEM-CNN outperforms prior works,
that isotropic graph CNNs are unable to solve the task and
that for this data set, breaking gauge symmetry in the ﬁnal
layers of the network is beneﬁcial.

8. Conclusions

Convolutions on meshes are commonly performed as a con-
volution on their underlying graph, by forgetting geometry,
such as orientation of neighbouring vertices. In this paper
we propose Gauge Equivariant Mesh CNNs, which endow
Graph Convolutional Networks on meshes with anisotropic
kernels and parallel transport. Hence, they are sensitive to
the mesh geometry, and result in equivalent outputs regard-
less of the arbitrary choice of kernel orientation.

We demonstrate that the inference of GEM-CNNs is invari-
ant under isometric deformations of meshes and generalizes
well over a range of non-isometric deformations. On the
FAUST shape correspondence task, we show that Gauge
equivariance, combined with symmetry breaking in the ﬁnal
layer, leads to state of the art performance.

Gauge Equivariant Mesh CNNs

References

Bekkers, E. J., Lafarge, M. W., Veta, M., Eppenhof, K. A.,
Pluim, J. P., and Duits, R. Roto-translation covariant
convolutional networks for medical image analysis. In
International Conference on Medical Image Computing
and Computer-Assisted Intervention (MICCAI), 2018.

Bogo, F., Romero, J., Loper, M., and Black, M. J. Faust:
Dataset and evaluation for 3d mesh registration. In Pro-
ceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, pp. 3794–3801, 2014.

Boscaini, D., Masci, J., Rodol`a, E., and Bronstein, M. M.
Learning shape correspondence with anisotropic convolu-
tional neural networks. In NIPS, 2016.

Bouritsas, G., Bokhnyak, S., Ploumpis, S., Bronstein, M.,
and Zafeiriou, S. Neural 3d morphable models: Spi-
ral convolutional networks for 3d shape representation
learning and generation. In Proceedings of the IEEE Inter-
national Conference on Computer Vision, pp. 7213–7222,
2019.

Bronstein, M. M., Bruna, J., LeCun, Y., Szlam, A., and Van-
dergheynst, P. Geometric deep learning: Going beyond
Euclidean data. IEEE Signal Processing Magazine, 2017.

Cohen, T. and Welling, M. Group equivariant convolutional

networks. In ICML, 2016.

Cohen, T. S. and Welling, M. Steerable CNNs. In ICLR,

2017.

Cohen, T. S., Geiger, M., and Weiler, M. A general the-
ory of equivariant CNNs on homogeneous spaces. In
Conference on Neural Information Processing Systems
(NeurIPS), 2019a.

Cohen, T. S., Weiler, M., Kicanaoglu, B., and Welling,
M. Gauge equivariant convolutional networks and the
Icosahedral CNN. 2019b.

Crane, K., Desbrun, M., and Schr¨oder, P. Trivial connections
on discrete surfaces. Computer Graphics Forum (SGP),
29(5):1525–1533, 2010.

Crane, K., de Goes, F., Desbrun, M., and Schr¨oder, P. Digital
geometry processing with discrete exterior calculus. In
ACM SIGGRAPH 2013 courses, SIGGRAPH ’13, New
York, NY, USA, 2013. ACM.

Defferrard, M., Bresson, X., and Vandergheynst, P. Con-
volutional neural networks on graphs with fast localized
spectral ﬁltering. In Advances in neural information pro-
cessing systems, pp. 3844–3852, 2016.

Gong, S., Chen, L., Bronstein, M., and Zafeiriou, S. Spi-
ralnet++: A fast and highly efﬁcient mesh convolution
operator. In Proceedings of the IEEE International Con-
ference on Computer Vision Workshops, pp. 0–0, 2019.

Hoogeboom, E., Peters, J. W. T., Cohen, T. S., and Welling,
M. HexaConv. In International Conference on Learning
Representations (ICLR), 2018.

Kipf, T. N. and Welling, M. Semi-Supervised Classiﬁcation
with Graph Convolutional Networks. In ICLR, 2017.

Kondor, R., Lin, Z., and Trivedi, S. Clebsch-gordan nets: a
fully fourier space spherical convolutional neural network.
In NIPS, 2018.

Lai, Y.-K., Jin, M., Xie, X., He, Y., Palacios, J., Zhang, E.,
Hu, S.-M., and Gu, X. Metric-driven rosy ﬁeld design
and remeshing. IEEE Transactions on Visualization and
Computer Graphics, 16(1):95–108, 2009.

Maron, H., Galun, M., Aigerman, N., Trope, M., Dym, N.,
Yumer, E., Kim, V. G., and Lipman, Y. Convolutional
neural networks on surfaces via seamless toric covers.
ACM Trans. Graph., 36(4):71–1, 2017.

Masci, J., Boscaini, D., Bronstein, M. M., and Van-
dergheynst, P. Geodesic convolutional neural networks
on riemannian manifolds. ICCVW, 2015.

Monti, F., Boscaini, D., Masci, J., Rodol`a, E., Svoboda,
J., and Bronstein, M. M. Geometric deep learning on
graphs and manifolds using mixture model cnns. CoRR,
abs/1611.08402, 2016. URL http://arxiv.org/
abs/1611.08402.

Perraudin, N., Defferrard, M., Kacprzak, T., and Sgier, R.
Deepsphere: Efﬁcient spherical convolutional neural net-
work with healpix sampling for cosmological applica-
tions. Astronomy and Computing, 27:130–146, 2019.

Poulenard, A. and Ovsjanikov, M. Multi-directional
geodesic neural networks via equivariant convolution.
ACM Transactions on Graphics, 2018.

Salti, S., Tombari, F., and Di Stefano, L. Shot: Unique
signatures of histograms for surface and texture descrip-
tion. Computer Vision and Image Understanding, 125:
251–264, 2014.

Cucurull, G., Wagstyl, K., Casanova, A., Veliˇckovi´c, P.,
Jakobsen, E., Drozdzal, M., Romero, A., Evans, A., and
Bengio, Y. Convolutional neural networks for mesh-based
parcellation of the cerebral cortex. 2018.

Schonsheck, S. C., Dong, B., and Lai, R. Parallel Transport
Convolution: A New Tool for Convolutional Neural Net-
works on Manifolds. arXiv:1805.07857 [cs, math, stat],
May 2018.

Gauge Equivariant Mesh CNNs

Sosnovik, I., Szmaja, M., and Smeulders, A.

equivariant steerable networks.
ference on Learning Representations (ICLR), 2020.

Scale-
In International Con-

Sun, Z., Rooke, E., Charton, J., He, Y., Lu, J., and Baek,
S. Zernet: Convolutional neural networks on arbitrary
surfaces via zernike local tangent space estimation. arXiv
preprint arXiv:1812.01082, 2018.

Thomas, N., Smidt, T., Kearnes, S., Yang, L., Li, L.,
Kohlhoff, K., and Riley, P. Tensor Field Networks:
Rotation- and Translation-Equivariant Neural Networks
for 3D Point Clouds. 2018.

Verma, N., Boyer, E., and Verbeek, J. Feastnet: Feature-
steered graph convolutions for 3d shape analysis.
In
Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, pp. 2598–2606, 2018.

Weiler, M. and Cesa, G. General E(2)-equivariant steerable
CNNs. In Conference on Neural Information Process-
ing Systems (NeurIPS), 2019. URL https://arxiv.
org/abs/1911.08251.

Weiler, M., Geiger, M., Welling, M., Boomsma, W., and
Cohen, T. 3D Steerable CNNs: Learning Rotationally
Equivariant Features in Volumetric Data. In NeurIPS,
2018a.

Weiler, M., Hamprecht, F. A., and Storath, M. Learn-
ing steerable ﬁlters for rotation equivariant CNNs. In
Conference on Computer Vision and Pattern Recognition
(CVPR), 2018b.

Winkels, M. and Cohen, T. S. 3D G-CNNs for pulmonary
nodule detection. In Conference on Medical Imaging with
Deep Learning (MIDL), 2018.

Worrall, D. and Welling, M. Deep scale-spaces: Equivari-
ance over scale. In Conference on Neural Information
Processing Systems (NeurIPS), 2019.

Worrall, D. E. and Brostow, G. J. Cubenet: Equivariance to
3D rotation and translation. In European Conference on
Computer Vision (ECCV), 2018.

Worrall, D. E., Garbin, S. J., Turmukhambetov, D., and
Brostow, G. J. Harmonic Networks: Deep Translation
and Rotation Equivariance. In CVPR, 2017.

Zhao, F., Xia, S., Wu, Z., Duan, D., Wang, L., Lin, W.,
Gilmore, J. H., Shen, D., and Li, G. Spherical u-net
on cortical surfaces: Methods and applications. CoRR,
abs/1904.00906, 2019. URL http://arxiv.org/
abs/1904.00906.

A. Deriving the Kernel Constraint

order n:

Gauge Equivariant Mesh CNNs

Given an input type ρin, corresponding to vector space
Vin of dimension Cin and output type ρout, corresponding
to vector space Vout of dimension Cout, we have kernels
Kself ∈ RCout×Cin and Kneigh : [0, 2π) → RCout×Cin . Follow-
ing Cohen et al. (2019b), we can derive a constraint on these
kernels such that the convolution is invariant.

First, note that for vertex p ∈ M and neighbour q ∈ Np, the
coefﬁcients of a feature vector fp at p of type ρ transforms
under gauge transformation fp (cid:55)→ ρ(−g)fp. The angle θpq
gauge transforms to θpq − g.
Next, note that ˆfq := ρin(gq→p)fq is the input feature at q
parallel transported to p. Hence, it transforms as a vector
at p. The output of the convolution f (cid:48)
p is also a feature at p,
transforming as ρout(−g)f (cid:48)
p.

The convolution then simply becomes:

f (cid:48)
p = Kselffp +

Kneigh(θpq) ˆfq

(cid:88)

q

Gauge transforming the left and right hand side, and substi-
tuting the equation in the left hand side, we obtain:

ρout(−g)f (cid:48)

p =

(cid:32)

(cid:33)

ρout(−g)

Kselffp +

Kneigh(θpq) ˆfq

=

Kselfρin(−g)fp +

Kneighθpq − g)ρin(−g) ˆfq

(cid:88)

q

(cid:88)

q

Which is true for any features, if ∀g ∈ [0, 2π), θ ∈ [0, 2π):

Kneigh(θ − g) = ρout(−g) Kneigh(θ) ρin(g),

Kself = ρout(−g) Kself ρin(g).

(8)

(9)

where we used the orthogonality of the representations
ρ(−g) = ρ(g)−1.

B. Solving the Kernel Constraint

As also derived in (Weiler & Cesa, 2019), we ﬁnd all angle-
parametrized linear maps between Cin dimensional feature
vector of type ρin to a Cout dimensional feature vector of
type ρout, that is, K : S1 → RCout×Cin , such that the above
equivariance constraint holds. We will solve for Kneigh(θ)
and discuss Kself afterwards.

The irreducible real representations (irreps) of SO(2) are the
one dimensional trivial representation ρ0(g) = 1 of order
zero and ∀n ∈ N the two dimensional representations of

ρn : SO(2) → GL(2, R) : g (cid:55)→

(cid:18)cos ng − sin ng
cos ng

sin ng

(cid:19)

.

Any representation ρ of SO(2) of D dimensions can be
written as a direct sum of irreducible representations
ρ ∼= ρl1 ⊕ ρl2 ⊕ ...

ρ(g) = A(ρl1 ⊕ ρl2 ⊕ ...)(g)A−1.
where li denotes the order of the irrep, A ∈ RD×D is some
invertible matrix and the direct sum ⊕ is the block diag-
onal concatenations of the one or two dimensional irreps.
Hence, if we solve the kernel constraint for all irrep pairs
for the in and out representations, the solution for arbitrary
representations, can be constructed. We let the input rep-
resentation be irrep ρn and the output representation be
irrep ρm. Note that K(g−1θ) = (ρreg(g)[K])(θ) for the
inﬁnite dimensional regular representation of SO(2), which
by the Peter-Weyl theorem is equal to the inﬁnite direct sum
ρ0 ⊕ ρ1 ⊕ ....

Using the fact that all SO(2) irreps are orthogonal, and using
that we can solve for θ = 0 and from the kernel constraints
we can obtain K(θ), we see that Eq. 8 is equivalent to

ˆρ(g)K := (ρreg ⊗ ρn ⊗ ρm)(g)K = K

where ⊗ denotes the tensor product, we write K := K(θ)
and ﬁlled in ρout = ρm, ρin = ρn. This constraint implies
that the space of equivariant kernels is exactly the trivial
subrepresentation of ˆρ. The representation ˆρ is inﬁnite di-
mensional, though, and the subspace can not be immediately
computed.

For SO(2), we have that for n ≥ 0, ρn ⊗ ρ0 = ρn, and for
∼= ρn+m ⊕ ρ|n−m|. Hence, the trivial
n, m > 0, ρn ⊗ ρm
subrepresentation of ˆρ is a subrepresentation of the ﬁnite
representation ˜ρ := (ρn+m ⊕ ρ|n−m|) ⊗ ρn ⊗ ρm, itself a
subrepresentation of ˆρ.

As SO(2) is a connected Lie group, any g ∈ SO(2) can
be written as g = exp tX for t ∈ R, X ∈ so(2), the Lie
algebra of SO(2), and exp : so(2) → SO(2) the Lie expo-
nential map. We can now ﬁnd the trivial subrepresentation
of ˜ρ looking inﬁnitesimally, ﬁnding

˜ρ(exp tX)K = K

⇐⇒ d˜ρ(X)K :=

˜ρ(exp tX)|t=0K = 0

∂
∂t

where we denote d˜ρ the Lie algebra representation corre-
sponding to Lie group representation ˜ρ. SO(2) is one di-
mensional, so for any single X ∈ so(2), K is an equivariant
map from ρm to ρn, if it is in the null space of matrix d˜ρ(X).
The null space can be easily found using a computer algebra
system or numerically, leading to the results in table 1.

Gauge Equivariant Mesh CNNs

C. Additional details on the experiments

C.1. Embedded MNIST

To create the intrinsically curved grids we start off with
the ﬂat, rectangular grid, shown in ﬁgure 5(a), which is
embedded in the XY -plane. An independent displacement
for each vertex in Z-direction is drawn from a uniform
distribution. A subsequent smoothing step of the normal
displacements with a Gaussian kernel of width σ yields
geometries with different levels of curvature. Figures 5(c)-
5(h) show the results for standard deviations of 2.5, 2, 1.5,
1, 0.75 and 0.5 pixels, which are denoted by their roughness
3 − σ as 0.5, 1, 1.5, 2, 2.25 and 2.5. In order to facilitate the
generalization between different geometries we normalize
the resulting average edge lengths.

The same GEM-CNN is used on all geometries. It con-
sists of seven convolution blocks, each of which applies
a convolution, followed by a RegularNonlinearity with
N = 7 orientations, batch normalization and dropout of
0.1. This depth is chosen since GEM-CNNs propagate in-
formation only between direct neighbors in each layer, such
that the ﬁeld of view after 7 layers is 2 × 7 + 1 = 15
pixel. The input and output types of the network are
scalar ﬁelds of multiplicity 1 and 64, respectively, which
transform under the trivial representation and ensure a
gauge invariant prediction. All intermediate layers use fea-
ture spaces of types M ρ0 ⊕ M ρ1 ⊕ M ρ2 ⊕ M ρ3) with
M = 4, 8, 12, 16, 24, 32. After a spatial max pooling, a
ﬁnal linear layer maps the 64 resulting features to 10 neu-
rons, on which a softmax function is applied. The model has
163k parameters. A baseline GCN, applying by isotropic
kernels, is deﬁned by replacing the irreps ρi of orders i ≥ 1
with trivial irreps ρ0 and rescaling the width of the model
such that the number of parameters is preserved. All models
are trained for 20 epochs with a weight decay of 1E-5 and
an initial learning rate of 1E-2. The learning rate is automat-
ically decayed by a factor of 2 when the validation loss did
not improve for 3 epochs.

The experiments were run on a single TitanX GPU.

C.2. Shape Correspondence experiment

All experiments were ran on single RTX 2080TI GPUs,
requiring 3 seconds / epoch.

Gauge Equivariant Mesh CNNs

(a) Flat embedding

(b) Isometric embedding

(c) Curved, roughness = 0.5

(d) Curved, roughness = 1

(e) Curved, roughness = 1.5

(f) Curved, roughness = 2

(g) Curved, roughness = 2.25

(h) Curved, roughness = 2.5

Figure 5. Examples of different grid geometries on which the MNIST dataset is evaluated. All grids have 28 × 28 vertices but are
embedded differently in the ambient space. Figure 5(a) shows a ﬂat embedding, corresponding to the usual pixel grid. The grid in
Figure 5(b) is isometric to the ﬂat embedding, its internal geometry is indistinguishable from that of the ﬂat embedding. Figures 5(c)-5(h)
show curved geometries which are not isometric to the ﬂat grid. They are produced by a random displacement of each vertex in its normal
direction, followed by a smoothing of displacements.

