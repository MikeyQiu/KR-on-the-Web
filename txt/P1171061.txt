Identiﬁcation of LTV Dynamical Models with
Smooth or Discontinuous Time Evolution
by means of Convex Optimization

Fredrik Bagge Carlson* Anders Robertsson Rolf Johansson

8
1
0
2
 
b
e
F
 
7
2
 
 
]

Y
S
.
s
c
[
 
 
1
v
4
9
7
9
0
.
2
0
8
1
:
v
i
X
r
a

Abstract— We establish a connection between trend
ﬁltering and system identiﬁcation which results in a
family of new identiﬁcation methods for linear, time-
varying (LTV) dynamical models based on convex
optimization. We demonstrate how the design of
the cost function promotes a model with either a
continuous change in dynamics over time, or causes
discontinuous changes in model coeﬃcients occurring
at a ﬁnite (sparse) set of time instances. We further
discuss the introduction of priors on the model pa-
rameters for situations where excitation is insuﬃcient
for identiﬁcation. The identiﬁcation problems are cast
as convex optimization problems and are applicable
to, e.g., ARX models and state-space models with
time-varying parameters. We illustrate usage of the
methods in simulations of jump-linear systems, a
nonlinear robot arm with non-smooth friction and stiﬀ
contacts as well as in model-based, trajectory centric
reinforcement learning on a smooth nonlinear system.

I. Introduction

The diﬃculty of the task of identifying time-varying
dynamical models of systems varies greatly with the
model considered and the availability of measurements
of the state sequence. For smoothly changing dynamics,
linear in the parameters, the recursive least-squares al-
gorithm with exponential forgetting (RLSλ) is a com-
mon option. If a Gaussian random-walk model for the
parameters is assumed, a Kalman ﬁltering/smoothing al-
gorithm [1] gives the ﬁltering/smoothing densities of the
parameters in closed form. The assumption of smoothly
(Gaussian) varying dynamics is often restrictive. Dis-
continuous dynamics changes occur, for instance, when
an external controller changes operation mode, when a
sudden contact between a robot and its environment is
established, an unmodeled disturbance enters the system
or when a system is suddenly damaged.

Identiﬁcation of systems with non-smooth dynamics
evolution has been studied extensively. The book [2]
treats the case where the dynamics are known, but the
state sequence unknown, i.e., state estimation. In [3], the

of

this

are made

*Open-source
examples

all presented methods
implementations
and
at
paper
in
github.com/baggepinnen/LTVModels.jl (Will be made available
in advance of paper publication). The reported research was
supported by the European Commission under the Framework
Programme Horizon 2020 under grant agreement 644938 SARAFun.
The authors are members of the LCCC Linnaeus Center and the
eLLIIT Excellence Center at Lund University, Dept Automatic
Control, Lund Sweden.
Fredrik.Bagge_Carlson@control.lth.se

available

authors examine the residuals from an initial constant
dynamics ﬁt to determine regions in time where improved
ﬁt is needed by the introduction of additional constant
dynamics models. Results on identiﬁability and observ-
ability in jump-linear systems in the non-controlled (au-
tonomous) setting are available in [4]. The main result
on identiﬁability in [4] was a rank condition on a Hankel
matrix constructed from the collected output data, simi-
lar to classical results on the least-squares identiﬁcation
of ARX models which appears as rank constraints on the,
typically Toeplitz or block-Toeplitz, regressor matrix.
Identiﬁability of the methods proposed in this article are
discussed in Sec. V.

An LTV model can be seen as a ﬁrst-order approxima-
tion of the dynamics of a nonlinear system around a tra-
jectory. We emphasize that such an approximation will
in general fail to generalize far from the this trajectory,
but many methods in reinforcement learning and control
make eﬃcient use of the linearized dynamics for opti-
mization, while ensuring validity of the approximation
by constraints or penalty terms. An example provided in
Sec. VIII highlights such a method.

An important class of identiﬁcation methods that has
been popularized lately is trend ﬁltering methods [5],
[6]. Trend ﬁltering methods work by specifying a ﬁtness
criterion that determines the goodness of ﬁt, as well as a
regularization term, often chosen with sparsity promoting
qualities. As a simple example, consider the reconstruc-
tion ˆy of a noisy signal y = {yt ∈ R}T
t=1 with piecewise
constant segments. To this end, we may formulate and
solve the convex optimization problem

minimize
ˆy

2
y − ˆy
2 + λ
(cid:13)
(cid:13)

(cid:13)
(cid:13)

Xt

|ˆyt+1 − ˆyt|

(1)

The ﬁrst term is the ﬁtness criterion or loss function,
whereas the second term is a sparsity-promoting regular-
izer which promotes small changes between consecutive
samples in the reconstructed signal. The sparsity promot-
ing eﬀect of the 1-norm regularizer is well known, and
stems from the constant length of the gradient whenever
the argument is non-zero [7]. Compare this to the squared
diﬀerence, for which the gradient rapidly vanishes as
the argument approaches zero. The squared diﬀerence
will thus promote small arguments, whereas the 1-norm
promotes sparse arguments.

In this work, we will draw inspiration from the trend-
ﬁltering literature to develop new system identiﬁcation

methods for LTV models, with interesting properties. In
trend ﬁltering, we decompose a curve as a set of poly-
nomial segments. In the identiﬁcation methods proposed
in this work, we instead decompose a multivariable state
sequence as the output of a set of LTV models, where
the model coeﬃcients evolve as polynomial functions
of time. We start by deﬁning a set of optimization
problems with a least-squares loss function and carefully
chosen regularization terms. We further discuss how prior
information can be utilized to increase the accuracy of
the identiﬁcation and end the article with identiﬁcation
of a nonlinear system with non-smooth friction and an
example of model-based reinforcement learning followed
by a discussion.

II. LTI identification

We start by considering the case of identiﬁcation of

the parameters in an LTI model on the form

t ∈ [1, T ]

xt+1 = Axt + But + vt,

(2)
where x ∈ Rn, u ∈ Rm are the state and input
respectively. A discussion around the noise term vt is
deferred until Sec. IV-A, where we indicate how sta-
tistical assumptions on vt inﬂuence the cost function
and the properties of the estimate. If the state and
input sequences are known, a plethora of methods for
estimating the parameters exists. A common method for
systems that are linear in the parameters is the least-
squares (LS) method, which in case of Gaussian noise, v,
coincides with the maximum likelihood (ML) estimate.
To facilitate estimation using the LS method, we write
the model on the form y = Φk, and arrange the data
according to



x1
...
y = 
xT


k = vec (
(cid:2)



AT BT

)

(cid:3)

In ⊗ xT
0
...
In ⊗ xT

T −1

Φ = 



In ⊗ uT
0
...
In ⊗ uT

T −1






∈ RT n

∈ RK

∈ RT n×K

where the parameters k are assumed to evolve according
to the dynamical system

kt+1 = Htkt + wt
t uT
xT
t
(cid:2)

In ⊗
(cid:0)

yt =

kt

(cid:3) (cid:1)

(6)

where, if no prior knowledge is available, the dynamics
matrix Ht can be taken as the identity matrix; H =
I implies that the model coeﬃcients follow a random
walk dictated by the properties of wt, i.e., the state
transition density function pw(kt+1|kt). The emission
density function pv(xt+1|xt, ut, kt) is determining the
drift of the state, which for the parameter estimation
problem can be seen as the distribution of measurements,
given the current state of the system. We emphasize here
that the state in the parameter evolution model refers
to the current parameters kt and not the system state
xt, hence, pv is called the emission density and not the
transition density. Particular choices of pv and pw emit
data likelihoods concave in the parameters and hence
amenable to convex optimization.

The following sections will introduce a number of opti-
mization problems with diﬀerent regularization functions,
corresponding to diﬀerent choices of pw, and diﬀerent reg-
ularization arguments, corresponding to diﬀerent choices
of H. We also discuss the quality of the identiﬁcation
resulting from the diﬀerent modeling choices.

A. Low frequency time evolution

A slowly varying signal is characterized by small ﬁrst-
order time diﬀerences. To identify slowly varying dynam-
ics parameters, we thus penalize the squared 2-norm of
the ﬁrst-order time diﬀerence of the model parameters,
and solve the optimization problem

minimize
k

2

2 + λ2
y − ˆy
(cid:13)
(cid:13)

(cid:13)
(cid:13)

Xt (cid:13)
(cid:13)

2
2
(cid:13)
(cid:13)

kt+1 − kt

(7)

t denotes the sum over relevant indices t, in this
where
case t ∈ [1, T −1]. This optimization problem has a closed
form solution given by

P

where ⊗ denotes the Kronecker product and K = n2 +
nm is the number of model parameters, and solve the
optimization problem (3) with closed-form solution (4).

˜k∗ = ( ˜ΦT ˜Φ + λ2DT
˜k = vec(k1, ... , kT )

1D1)−1 ˜ΦT ˜Y

(8)

k∗ = arg min

Φk − y

k
= (ΦTΦ)−1ΦTy

(cid:13)
(cid:13)

2
2
(cid:13)
(cid:13)

III. Time-varying dynamics

We now move on to the contribution of this work, and
extend our view to systems where the dynamics change
with time. We limit the scope of this article to models
on the form

xt+1 = Atxt + Btut + vt

kt = vec (
(cid:2)

AT

t BT
t

)

(cid:3)

(3)

(4)

(5)

2

D1˜k
(cid:13)
(cid:13)

where ˜Φ and ˜Y are appropriately constructed matrices
and the ﬁrst-order diﬀerentiation operator matrix D1
is constructed such that λ2
equals the second
(T K)3
term in (7). The computational complexity O
of computing k∗ using the closed-form solution (8) be-
(cid:1)
comes prohibitive for all but toy problems. We note
that the cost function in (7) is the negative data log-
likelihood of a Brownian random-walk parameter model
with H = I, which motivates us to develop a dynamic
programming algorithm based on a Kalman smoother,
detailed in Sec. IV-B.

2
(cid:13)
(cid:13)

(cid:0)

B. Smooth time evolution

A smoothly varying signal is characterized by small
second-order time diﬀerences. To identify smoothly time-
varying dynamics parameters, we thus penalize the
squared 2-norm of the second-order time diﬀerence of the
model parameters, and solve the optimization problem

minimize
k

2

2 + λ2
y − ˆy
(cid:13)
(cid:13)

(cid:13)
(cid:13)

Xt (cid:13)
(cid:13)

kt+2 − 2kt+1 + kt

(9)

2
2

(cid:13)
(cid:13)

Also this optimization problem has a closed form so-
lution on the form (8) with the corresponding second-
order diﬀerentiation operator D2. Equation (9) is the
negative data log-likelihood of a Brownian random-walk
parameter model with added momentum and H derived
in Sec. IV-C.2, where a Kalman smoother with aug-
mented state is developed to ﬁnd the optimal solution.
We also extend problem (9) to more general regulariza-
tion terms in Sec. IV-B.

C. Piecewise constant time evolution

In the presence of discontinuous or abrupt changes
in the dynamics, estimation method (9) might perform
poorly. A signal which is mostly ﬂat, with a small number
of distinct level changes, is characterized by a sparse
ﬁrst-order time diﬀerence. To detect sudden changes in
dynamics, we thus formulate and solve the problem

2
(cid:13)
(cid:13)

1
(cid:13)
(cid:13)

minimize
k

2
y − ˆy
2 + λ
(cid:13)
(cid:13)

(cid:13)
(cid:13)

Xt (cid:13)
(cid:13)

kt+1 − kt

(10)

We can give (10) an interpretation as a grouped-lasso cost
function, where instead of groups being formed out of
variables, our groups are deﬁned by diﬀerences between
variables. We thus have a penalty on the 1-norm on the
length of the diﬀerence vectors kt+1 − kt since
=
·
2. The 1-norm is a sparsity-promoting penalty, hence
a solution in which only a small number of non-zero ﬁrst-
(cid:13)
(cid:13)
(cid:13)
(cid:13)
order time diﬀerences in the model parameters is favored,
i.e., a piecewise constant dynamics evolution. At a ﬁrst
glance, one might consider the formulation

·
2
(cid:13)
(cid:13)

1
(cid:13)
(cid:13)

(cid:13)
(cid:13)

(cid:13)
(cid:13)

minimize
k

2
y − ˆy
2 + λ
(cid:13)
(cid:13)

(cid:13)
(cid:13)

Xt (cid:13)
(cid:13)

kt+1 − kt

(11)

which results in a dynamics evolution with sparse
changes in the coeﬃcients, but changes to diﬀerent en-
tries of kt are not necessarily occurring at the same
time instants. The formulation (10), however, promotes
a solution in which the change occurs at the same time
instants for all coeﬃcients in A and B, i.e., kt+1 = kt for
most t.

t

kt+1 − kt

1) Implementation: Due to the non-squared norm
2, problem (10) is signiﬁcantly
penalty
harder to solve than (9). An eﬃcient implementation us-
(cid:13)
(cid:13)
ing the linearized ADMM algorithm [8] is made available
in the accompanying repository.

P

(cid:13)
(cid:13)

TABLE I
Summary of optimization problem formulations. Dn refers
to parameter vector time-differentiation of order n.

Norm Dn Result

1
1
2
2

1
2
1
2

Small number of steps (piecewise constant)
Small number of bends (piecewise aﬃne)
Small steps (slowly varying)
Small bends (smooth)

D. Piecewise constant time evolution with known number
of steps

If the number of switches in dynamics parameters, M ,

is known in advance, the optimal problem to solve is

minimize
k

subject to

2
y − ˆy
2
(cid:13)
(cid:13)

(cid:13)
(cid:13)
Xt

1{kt+1 6= kt} ≤ M

(12)

(13)

where 1{·} is the indicator function. This problem is non-
convex and we propose solving it using dynamic program-
ming (DP). For this purpose we modify the algorithm
developed in [9], an algorithm frequently referred to as
segmented least-squares [10], where a curve is approx-
imated by piecewise linear segments. The modiﬁcation
lies in the association of each segment (set of consecutive
time indices during which the parameters are constant)
with a dynamics model, as opposed to a simple straight
line.1 Unfortunately, the computational complexity of
the dynamic programming solution, O(T 2K 3), becomes
prohibitive for large T .2

E. Piecewise linear time evolution

A piecewise linear signal is characterized by a sparse
second-order time diﬀerence, i.e., it has a small number
of changes in the slope. A piecewise linear time-evolution
of the dynamics parameters is hence obtained if we solve
the optimization problem.

minimize
k

(cid:13)
(cid:13)
F. Summary

2
y − ˆy
2 + λ
(cid:13)
(cid:13)

Xt (cid:13)
(cid:13)

kt+2 − 2kt+1 + kt

(14)

2
(cid:13)
(cid:13)

The proposed optimization problems are summarized
in Table I. The table illustrates how the choice of regu-
larizer and order of time-diﬀerentiation of the parameter
vector aﬀects the quality of the resulting solution.

G. Two-step reﬁnement

Since many of the proposed formulations of the opti-
mization problem penalize the size of the changes to the
parameters, solutions in which the changes are slightly
underestimated are favored. To mitigate this issue, a two-
step procedure can be implemented where in the ﬁrst

1Indeed, if a simple integrator is chosen as dynamics model and
a constant input is assumed, the result of our extended algorithm
reduces to the segmented least-squares solution.

2For details regarding the DP algorithm and implementation, the
reader is referred to the source-code repository accompanying this
article.

step, change points (knots) are identiﬁed. In the second
step, the penalty on the one-norm is removed and equal-
ity constraints are introduced between consecutive time-
indices for which no change in dynamics was indicated
by the ﬁrst step.

The second step can be computed very eﬃciently
by noticing that the problem can be split into several
identical sub-problems at the knots identiﬁed in the ﬁrst
step. The sub-problems have closed-form solutions if the
problem in Sec. III-C is considered.

To identify the points at which the dynamics change,
we observe the argument inside the sum of the reg-
kt+1 − kt
i.e., at1 =
2 or at2 =
ularization term,
kt+2 − 2kt+1 + kt
2. Time instances where at is taking
(cid:13)
(cid:13)
non-zero values indicate change points.
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:13)

IV. Dynamics prior and Kalman filtering

The identiﬁability of the parameters in a dynamical
model hinges on the observability of the dynamics sys-
tem (6), or more explicitly, only modes excited by the in-
put u will be satisfactorily identiﬁed. If the identiﬁcation
is part of an iterative learning and control scheme, e.g.,
ILC or reinforcement learning, it might be undesirable
to introduce additional noise in the input to improve
excitation for identiﬁcation. This section will introduce
prior information about the dynamics which mitigates
the issue of poor excitation of the system modes. The
prior information might come from, e.g., a nominal model
known to be inaccurate, or an estimated global model
such as a Gaussian mixture model (GMM). A statistical
model of the joint density p(xt+1, xt, ut) constructed
from previously collected tuples (xt+1, xt, ut) provides a
dynamical model of the system through the conditional
pdf p(xt+1|xt, ut).

We will see that for priors from certain families, the
resulting optimization problem remains convex. For the
special case of a Gaussian prior over the dynamics pa-
rameters or the output, the posterior mean of the pa-
rameter vector is conveniently obtained from a Kalman-
smoothing algorithm, modiﬁed to include the prior.

A. General case

If we introduce a parameter state k (c.f., (5)) and a
prior over all parameter-state variables p(kt|zt), where
the variable zt might be, for instance, the time index t
or state xt, we have the data log-likelihood

log p(k, y|x, z)1:T =

log p(yt|kt, xt)

+

log p(kt+1|kt) +

log p(kt|zt)

T −1

Xt=1

T

Xt=1
T

Xt=1

(15)

which factors conveniently due to the Markov property
of a state-space model. For particular choices of density
functions in (15), notably Gaussian and Laplacian, the
negative likelihood function becomes convex. The next
section will elaborate on the Gaussian case and introduce

a recursive algorithm that solves for the full posterior
eﬃciently. The Laplacian case, while convex, does not
admit an equally eﬃcient algorithm, but is more robust
to outliers in the data.

B. Gaussian case

If all densities in (15) are Gaussian and k is modeled
with the Brownian random walk model (6) (Gaussian
vt), (15) can be written on the form (scaling constants
omitted)

− log p(k, y|x, z)1:T =

yt − ˆy(kt, xt)

T

Xt=1 (cid:13)
(cid:13)
T −1

+

+

kt+1 − kt

Xt=1 (cid:13)
(cid:13)
(cid:13)
(cid:13)
T
µ0(zt) − kt

2
Σ

−1
y

(cid:13)
(cid:13)

2
Σ

−1
k

2
Σ

−1
0 (zt)

(16)

2

x

(cid:13)
(cid:13)

Xt=1 (cid:13)
(cid:13)
for some function µ0(zt) which produces the prior mean
of k given zt. Σy, Σk, Σ0(zt) are the covariance matrices
of the state-drift, parameter drift and prior respectively
and

Σ−1 = xTΣ−1x.

In this special case, we introduce a recursive solution
given by a modiﬁed Kalman smoothing algorithm, where
the conditional mean of the state is updated with the
prior. Consider the standard Kalman ﬁltering equations,
reproduced here to establish the notation

(cid:13)
(cid:13)

(cid:13)
(cid:13)

ˆxt|t−1 = Aˆxt−1|t−1 + But−1
Pt|t−1 = APt−1|t−1AT + R1

CPt|t−1CT + R2
Kt = Pt|t−1CT
(cid:0)
yt − C ˆxt|t−1
ˆxt|t = ˆxt|t−1 + Kt
(cid:0)
Pt|t = Pt|t−1 − KtCPt|t−1

(cid:1)

(cid:1)

−1

(17)
(18)

(19)

(20)
(21)

where x is the state vector, with state-drift covariance
R1 and C is a matrix that relates x to a measurement
y = Cx with covariance R2. The ﬁrst two equations
constitute the prediction step, and the last two equations
incorporate the measurement yt in the correction step.
The modiﬁcation required to incorporate a Gaussian
prior on the state variable p(xt|vt) = N (µ0(vt), Σ0(vt))
involves a repeated correction step and takes the form

−1

¯Kt = Pt|t
Pt|t + Σ0(vt)
¯xt|t = ˆxt|t + ¯Kt
(cid:0)
(cid:1)
¯Pt|t = Pt|t − ¯KtPt|t

µ0(vt) − ˆxt|t
(cid:0)

(cid:1)

(22)

(23)

(24)

where ¯· denotes the posterior value. This additional
correction can be interpreted as receiving a second mea-
surement µ0(vt) with covariance Σ0(vt). For the Kalman-
smoothing algorithm, ˆxt|t and Pt|t in (23) and (24) are
replaced with ˆxt|T and Pt|T .

A prior over the output of the system, or a subset
thereof, is straight forward to include in the estimation
by means of an extra update step, with C, R2 and y being
replaced with their corresponding values according to the
prior.

C. Kalman ﬁlter for identiﬁcation

We can employ the Kalman-based algorithm to solve

two of the proposed optimization problems:

1) Low frequency: The Kalman smoother can be used
for solving identiﬁcation problems like (7) by noting
that (7) is the negative log-likelihood of the dynamics
model (6). The identiﬁcation problem is thus reduced to
a standard state-estimation problem.

2) Smooth: To develop a Kalman-ﬁlter based algo-
rithm for solving (9), we augment the model (6) with the
state variable k′
t =
kt+1 −2kt +kt−1. We thus introduce the augmented-state
model

t = kt − kt−1 and note that k′

t+1 − k′

kt+1
k′
t+1(cid:21)

(cid:20)

=

IK IK
0K IK(cid:21) (cid:20)
(cid:20)

kt
k′
t(cid:21)

+

0
wt(cid:21)
(cid:20)

yt =

In ⊗

t uT
xT
t

0

kt
k′
t(cid:21)

(cid:20)

(25)

(26)

(cid:2)
which is on a form suitable for ﬁltering/smoothing with
the machinery developed above.

(cid:3) (cid:1)

(cid:2)(cid:0)

(cid:3)

3) General case: The Kalman-ﬁlter based identiﬁca-
tion method can be generalized to solving optimization
problems where the argument in the regularizer appear-
ing in (9) is replaced by a general linear operation on
the parameter vector, P (z)k, and we have the following
proposition

2

Proposition 1: Any optimization problem on the form
2 + λ2
y − ˆy
(cid:13)
(cid:13)

minimize
k

Xt (cid:13)
(cid:13)

P (z)kt

2
2
(cid:13)
(cid:13)

where P (z) is a polynomial of degree n > 0 in the time
diﬀerence operator z with z−nP (1) = 0, can be solved
with a Kalman smoother employed to an autonomous
state-space system.

(27)

(cid:13)
(cid:13)

Proof: Let P ∗(z−1) = z−nP (z). We assume without
loss of generality that P ∗(0) = 1 since any constant
P ∗(0) can be factored out of the polynomial. Q(z−1) =
P ∗(z−1)−1 is a strictly proper transfer function and has
a realization as a linear, Gaussian state-space system of
degree n. Since Q(z−1) is strictly proper, the realization
has no direct term. The negative data log-likelihood of
Q(z−1) is equal, up to constants idenpendent of k, to the
cost function in Eq. (27), hence the Kalman smoother
applied to Q optimizes Eq. (27).
For (9) P (z) equals z2 − 2z + 1 and Q(z−1) has a
realization on the form (25).

V. Well-posedness and identifiability

To assess the well-posedness of the proposed identi-
ﬁcation methods, we start by noting that the problem
of ﬁnding A in xt+1 = Axt given a pair (xt+1, xt)
is an ill-posed problem in the sense that the solution
is non unique. If we are given several pairs (xt+1, xt),
for diﬀerent t, while A remains constant, the problem
becomes over-determined and well-posed in the least-
squares sense, provided that the vectors {x(i)
t=1 span
Rn. The LTI-case in Sec. II is well posed according to
classical results, when Φ has full column rank.

t }T

When we extend our view to LTV models, the number
of free parameters is increased signiﬁcantly, and the
corresponding regressor matrix ˜Φ will never have full
column rank and the introduction of a regularization
term is necessary. Informally, for every n measurements,
we have K = n2 + nm free parameters. If we consider the
identiﬁcation problem of Eq. (10) and let λ → ∞, the reg-
ularizer terms essentially becomes equality constraints.
This will enforce a solution in which all parameters in k
are constant over time, and the problem reduces to the
LTI-problem. As λ decreases, the eﬀective number of free
parameters increases until the problem gets ill-posed for
λ = 0. We formalize the above arguments as

Proposition 2: Optimization problems (7) and (10)
have unique global minima for λ > 0 if and only if the
corresponding LTI optimization problem has a unique
solution.

Proof: The cost function is a sum of two con-
vex terms. For a global minimum to be non-unique,
the Hessians of the two terms must have intersecting
nullspaces. In the limit λ → ∞ the problem reduces
to the LTI problem. The nullspace of the regularization
Hessian, which is invariant to λ, does thus not share any
directions with the nullspace of ˜ΦT˜Φ which establishes the
equivalence of identiﬁability between the LTI problem
and the LTV problems.

Proposition 3: Optimization problems (9) and (14)
with higher order diﬀerentiation in the regularization
term have unique global minima for λ > 0 if and only if
there exists no vector v ∈ Rn+m such that

(cid:20)

(28)

Cxu

t v =

v = 0 ∀t

xtxT
utxT

t xtuT
t
t utuT
t(cid:21)
Proof: Again, the cost function is a sum of two
convex terms and for a global minimum to be non-
unique, the Hessians of the two terms must have inter-
secting nullspaces. In the limit λ → ∞ the regulariza-
tion term reduces to a linear constraint set, allowing
only parameter vectors that lie along a line through
time. Let ˜v 6= 0 be such a vector, parametrized by
∈ RT K where ¯v =
· · · T ¯vT
t as ˜v =
vec({v}N
1 ) ∈ RK and v is an arbitrary vector ∈ Rn+m.
(cid:3)
˜v ∈ null ( ˜ΦT ˜Φ) implies that the loss is invariant to the
pertubation α˜v to ˜k for an arbitrary α ∈ R. ( ˜ΦT˜Φ) is
t }T
given by blkdiag({In ⊗ Cxu
1 ) which means that ˜v ∈
null ( ˜ΦT ˜Φ) ⇐⇒ αt(In ⊗ Cxu
t )¯v = 0 ∀(α, t) ⇐⇒ ¯v ∈
null (In ⊗ Cxu
due to
the block-diagonal nature of In ⊗ Cxu

t ) ∀t, which implies v ∈ null Cxu

¯vT
(cid:2)

2¯vT

t

T

t

For the LTI problem to be well-posed, the system
must be identiﬁable and the input u must be persistently
exciting of suﬃcient order [11].

VI. Example – Jump-linear system

We now consider a simulated example. We generate a
state sequence from the following LTV system, where the

s
t
n
e
i
c
ﬃ
e
o
c

l
e
d
o
M

0.8

0.6

0.4

0.2

0.0

100

200
Time index

300

400

Fig. 1.
Piecewise constant state-space dynamics. True values
are shown with dashed, black lines. Gaussian state-transition and
measurement noise with σ = 0.2 were added.

change in dynamics, from

to

At =

0.95
0.0

(cid:20)

0.1
0.95 (cid:21)

, Bt =

0.2
1.0 (cid:21)

(cid:20)

At =

0.5 0.05
0.0

0.5 (cid:21)

(cid:20)

, Bt =

0.2
1.0 (cid:21)

(cid:20)

occurred at t = 200. The input was Gaussian noise
of zero mean and unit variance, state transition noise
and measuremet noise of zero mean and σ = 0.2 were
added. Figure 1 depicts the estimated coeﬃcients in the
dynamics matrices for a value of λ chosen using the L-
curve method [12].

VII. Example – Non-smooth robot arm with
stiff contact

To illustrate the ability of the proposed models to
represent the non-smooth dynamics along a trajectory of
a robot arm, we simulate a two-link robot with discon-
tinuous Coulomb friction. We also let the robot establish
a stiﬀ contact with the environment to illustrate both
strengths and weaknesses of the modeling approach.

The state of the robot arm consists of two joint
˙q. Figure 2
coordinates, q, and their time derivatives,
illustrates the state trajectories, control torques and
simulations of a model estimated by solving (10). The
ﬁgure clearly illustrates that the model is able to capture
the dynamics both during the non-smooth sign change
of the velocity, but also during establishment of the stiﬀ
contact. The learned dynamics of the contact is however
time-dependent, which is illustrated in Figure 3, where
the model is used on a validation trajectory where a
diﬀerent noise sequence was added to the control torque.
Due to the novel input signal, the contact is established
at a diﬀerent time-instant and as a consequence, there is
an error transient in the simulated data.

VIII. Example – Reinforcement learning

In this example, we use the proposed methods to
identify LTV dynamics models for reinforcement learn-
ing. The goal of the task is to dampen oscillations of

a pendulum attached to a moving cart by means of
moving the cart, with bounds on the control signal and a
quadratic cost on states and control. Due to the nonlinear
nature of the pendulum dynamics, linear expansions of
the dynamics in the upward (initial) position and down-
ward (ﬁnal) position have poles on opposite sides of the
imaginary axis. To this end, we employ a reinforcement-
learning framework inspired by [13], where we perform a
series of rollouts whereafter each we 1) ﬁt a dynamics
model along the last obtained trajectory, 2) optimize
the cost function under the model using iterative LQG
(diﬀerential dynamic programming),3 an algorithm that
calculates the value function exactly under the LTV
dynamics and a quadratic expansion of the cost function.
In order to stay close to the validity region of the linear
model, we put bounds on the deviation between each
new trajectory and the last trajectory. We compare three
diﬀerent models; the ground truth system model, an LTV
model (obtained by solving (9)) and an LTI model. The
total cost over T = 500 time steps is shown as a function
of learning iteration in Fig. 4. The ﬁgure illustrates how
the learning procedure reaches the optimal cost of the
ground truth model when an LTV model is used, whereas
when using an LTI model, the learning diverges. The
ﬁgure further illustrates that if the LTV model is ﬁt
using a prior (Sec. IV-B), the learning speed is increased.
The prior in this case was constructed from the true
system model, linearized around the last trajectory. This
strategy is unavailable in a real application, but the
experiment serves as an indication of the eﬀectiveness
of inclusion of a prior in this example. Future work is
targeting the incremental estimation of these priors.

IX. Discussion

This article presents methods for estimation of lin-
ear, time-varying models. The methods presented ex-
tend directly to nonlinear models that remain linear in
the parameters. When estimating an LTV model from
a trajectory obtained from a nonlinear system, one is
eﬀectively estimating the linearization of the system
around that trajectory. A ﬁrst-order approximation to a
nonlinear system is not guaranteed to generalize well as
deviations from the trajectory become large. Many non-
linear systems are, however, approximately locally linear,
such that they are well described by a linear model in a
small neighborhood around the linearization/operating
point. For certain methods, such as iterative learning
control and trajectory centric reinforcement learning, a
ﬁrst-order approximation to the dynamics is used for ef-
ﬁcient optimization, while the validity of the approxima-
tion is ensured by incorporating penalties or constraints
between two consecutive trajectories.

The methods presented allow very eﬃcient learning
of this ﬁrst-order approximation due to the prior belief
over the nature of the change in dynamics parameters,

3Implementation

made

available

at

github.com/baggepinnen/DiﬀerentialDynamicProgramming.jl

0.75
0.50
0.25
0.00
-0.25

1.5
1.0
0.5
0.0
-0.5
-1.0

1.0
0.5
0.0
-0.5
-1.0

1.5
1.0
0.5
0.0
-0.5
-1.0

1.0
0.5
0.0
-0.5
-1.0

˙q1

q1

˙q1

q1

End-eﬀector positions

Control torques

50
y

x

100

150

200

50

100

150

200

Constraint

Stiﬀ contact

Velocity sign change

50

100

150

200

50

100

150

200

States

Velocity sign change

Stiﬀ contact

Simulation

50

100

150

200

50

100

150

200

Fig. 2. Simulation of non-smooth robot dynamics with stiﬀ contact – training data vs. sample time index. The sign change in velocity,
and hence a discontinuous change in friction torque, occurs in the time interval 50-100 and the contact is established in the time interval
100-150. For numerical stability, all time-series are normalized to zero mean and unit variance, hence, the original velocity zero crossing
is explicitly marked with a dashed line. The control signal plot clearly indicates the discontinuity in torque around the unnormalized zero
crossing of ˙q2.

50

100

150

200

50

100

States

Original Velocity sign change

Original Stiﬀ contact

150
Simulation

200

50

100

150

200

50

100

150

200

Fig. 3. Simulation of non-smooth robot dynamics with stiﬀ contact – validation data vs. sample time index. The dashed lines indicate
the event times for the training data, highlighting that the model is able to deal eﬀortless with the non-smooth friction, but inaccurately
predicts the time evolution around the contact event which now occurs at a slightly diﬀerent time instance.

1.0

0.5

0.0

-0.5

1.5
1.0
0.5
0.0
-0.5
-1.0
-1.5

0.5
0.0
-0.5
-1.0
-1.5

1.5
1.0
0.5
0.0
-0.5
-1.0
-1.5

1.0
0.5
0.0
-0.5
-1.0
-1.5

˙q2

q2

˙q2

q2

LTV model
LTV with prior

LTI model
True model

·104

Median over 20 Monte-Carlo runs

t
s
o
C

1

0.8

0.6

0.4

0.2

2

4

6

10
Learning iteration

8

12

14

Fig. 4. Reinforcement learning example. Three diﬀerent model
types are used to iteratively optimize the trajectory of a pendulum
on a cart. Due to the nonlinear nature of the pendulum dynamics,
linear expansions of the dynamics in the upward and downward
positions have poles on opposite sides of the imaginary axis, why
the algorithm fails with an LTI model.

encoded by the regularization terms. By postulating a
prior belief that the dynamics parameters change in a
certain way, less demand is put on the data required
for identiﬁcation. The identiﬁcation process will thus not
interfere with normal operation in the same way as if
excessive noise would be added to the input for identi-
ﬁcation purposes. This allows learning of ﬂexible, over-
parametrized models that ﬁt available data well. This
makes the proposed identiﬁcation methods attractive in
applications such as guided policy search (GPS) [13],
[14] and non-linear iterative learning control (ILC) [15],
where they can lead to dramatically decreased sample
complexity.

When faced with a system where time-varying dynam-
ics is suspected and no particular knowledge regarding
the dynamics evolution is available, or when the dynam-
ics are known to vary slowly, a reasonable ﬁrst choice of
algorithm is (9). It is also by far the fastest of the pro-
posed methods due to the Kalman-ﬁlter implementation
of Sec. IV-B.4 Example use cases include when dynamics
are changing with a continuous auxiliary variable, such as
temperature, altitude or velocity. If a smooth parameter
drift is found to correlate with an auxiliary variable, LPV-
methodology can be employed to model the dependence
explicitly.

Dynamics may change abruptly as a result of, e.g.,
system failure, change of operating mode, or when a
sudden disturbance enters the system, such as a policy
change aﬀecting a market or a window opening aﬀecting
the indoor temperature. The identiﬁcation method (10)
can be employed to identify when such changes occur,

4The Kalman-ﬁlter implementation is often several orders of
magnitude faster than solving the optimization problems with an
iterative solver.

without specifying a priori how many changes are ex-
pected.

2

∆k

For simplicity, the regularization weights were kept
as simple scalars in this article. However, all terms
2 = (∆k)T(λI)(∆k) can be generalized to
λ
(∆k)TΛ(∆k), where Λ is an arbitrary positive deﬁnite
matrix. This allows incorporation of diﬀerent scales for
diﬀerent variables with little added implementation com-
plexity.

(cid:13)
(cid:13)

(cid:13)
(cid:13)

X. Conclusions

We have proposed a framework for identiﬁcation of
linear, time-varying models along trajectories of nonlin-
ear dynamical systems using convex optimization. We
showed how a Kalman smoother can be used to esti-
mate the dynamics eﬃciently in a few special cases,
and demonstrated the use of the proposed LTV mod-
els on three examples, highlighting their eﬃciency for
trajectory-centric, model-based reinforcement learning,
iterative learning control (ILC), and jump-linear system
identiﬁcation. We have also demonstrated the ability of
the models to handle non-smooth friction dynamics as
well as analyzed the identiﬁability of the models.

References

[1] H. E. Rauch, F. Tung, C. T. Striebel, et al., “Maximum like-
lihood estimates of linear dynamic systems,” AIAA journal,
vol. 3, no. 8, 1965.

[2] O. L. V. Costa, M. D. Fragoso, and R. P. Marques, Discrete-
time Markov jump linear systems. Springer Science & Busi-
ness Media, London, 2006.

[3] S. Nagarajaiah and Z. Li, “Time segmented least squares
identiﬁcation of base isolated buildings,” Soil Dynamics and
Earthquake Engineering, vol. 24, no. 8, 2004.

[4] R. Vidal, A. Chiuso, and S. Soatto, “Observability and identi-
ﬁability of jump linear systems,” in IEEE Conf. Decision and
Control (CDC), Las Vegas, vol. 4.

IEEE, 2002.

[5] S.-J. Kim, K. Koh, S. Boyd, and D. Gorinevsky, “ℓ1 trend

ﬁltering,” SIAM review, vol. 51, no. 2, 2009.

[6] R. J. Tibshirani et al., “Adaptive piecewise polynomial esti-
mation via trend ﬁltering,” The Annals of Statistics, vol. 42,
no. 1, 2014.

[7] K. P. Murphy, Machine learning: a probabilistic perspective.

MIT press, Cambridge, Massachusetts, 2012.

[8] N. Parikh, S. Boyd, et al., “Proximal algorithms,” Foundations

and Trends in Optimization, vol. 1, no. 3, 2014.

[9] R. Bellman, “On the approximation of curves by line segments
using dynamic programming,” Communications of the ACM,
vol. 4, no. 6, 1961.

[10] R. Bellman and R. Roth, “Curve ﬁtting by segmented straight
lines,” Journal of the American Statistical Association, vol. 64,
no. 327, 1969.

[11] R. Johansson, System modeling & identiﬁcation. Prentice-

Hall, Englewood Cliﬀs, NJ, 1993.

[12] P. C. Hansen, “Regularization tools: A matlab package for
analysis and solution of discrete ill-posed problems,” Numeri-
cal algorithms, vol. 6, no. 1, 1994.

[13] S. Levine and V. Koltun, “Guided policy search,” in Int. Conf.

Machine Learning (ICML), Atlanta, 2013.

[14] S. Levine, N. Wagener, and P. Abbeel, “Learning contact-rich
manipulation skills with guided policy search,” in Robotics and
Automation (ICRA), IEEE Int. Conf.

IEEE, 2015.

[15] D. A. Bristow, M. Tharayil, and A. G. Alleyne, “A survey
of iterative learning control,” IEEE Control Systems, vol. 26,
no. 3, 2006.

