Neural Ideal Point Estimation Network

Kyungwoo Song, Wonsung Lee, and Il-Chul Moon
Korea Advanced Institute of Science and Technology
291 Daehak-ro, Yuseong-gu
Daejeon 34141, South Korea
{gtshs2,aporia,icmoon}@kaist.ac.kr

9
1
0
2
 
r
p
A
 
6
2
 
 
]
I
S
.
s
c
[
 
 
1
v
7
2
7
1
1
.
4
0
9
1
:
v
i
X
r
a

Abstract

Understanding politics is challenging because the politics
take the inﬂuence from everything. Even we limit ourselves
to the political context in the legislative processes; we need
a better understanding of latent factors, such as legislators,
bills, their ideal points, and their relations. From the mod-
eling perspective, this is difﬁcult 1) because these observa-
tions lie in a high dimension that requires learning on low di-
mensional representations, and 2) because these observations
require complex probabilistic modeling with latent variables
to reﬂect the causalities. This paper presents a new model to
reﬂect and understand this political setting, NIPEN, includ-
ing factors mentioned above in the legislation. We propose
two versions of NIPEN: one is a hybrid model of deep learn-
ing and probabilistic graphical model, and the other model
is a neural tensor model. Our result indicates that NIPEN
successfully learns the manifold of the legislative bill texts,
and NIPEN utilizes the learned low-dimensional latent vari-
ables to increase the prediction performance of legislators’
votings. Additionally, by virtue of being a domain-rich proba-
bilistic model, NIPEN shows the hidden strength of the legis-
lators’ trust network and their various characteristics on cast-
ing votes.

Introduction
Recent developments in machine learning have enabled a
deeper understanding of human behavior in diverse contexts.
These advances include divulging intentions and sentiments
in dialogs (Bertero et al. 2016); predicting purchases from
online markets (Chong et al. 2017); recommending movies
to friends (Shah, Rao, and Ding 2017); and discovering so-
cial network links between individuals (Guo, Zhang, and
Yorke-Smith 2015). The recent machine learning models
provide the contexts of these behaviors, which have been
regarded as the latent aspects of human behavior.

One latent modeling of human behavior can be a form of
complex Bayesian probabilistic models, a.k.a. probabilistic
graphical model (PGM). The modelers used graphical nota-
tions, embedding the probabilistic variables and their causal-
ities, to represent the key factors and their relations. For in-
stance, latent Dirichlet allocation (LDA) models the genera-
tive process of documents, i.e. the composition of topics at

Copyright c(cid:13) 2018, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

large, a main topic of documents, and a word selection when
describing a topic (Blei, Ng, and Jordan 2003).

Another effort in modeling the latent variable is improv-
ing the quality of the latent representation of the data. While
the above probabilistic models focused on the contextual
modeling, the latent variables reside in a high dimensional
and nonlinear space, so the learning of the latent variables
have been limited. For example, the stacked de-noising au-
toencoder (SDAE) (Vincent et al. 2010) learns this mani-
fold space through encoding the noised inputs into the low
dimensional latent representations; and reconstructing the
original inputs with the latent representations with neural
network layers. Further advances have made through casting
this autoencoding mechanism to the variational inference
approaches, and a variational autoencoder (VAE) (Kingma
and Welling 2014) optimizes the variational distribution of
the latent representations with neural networks.

Supported by the two research advances, one distinct re-
search direction has been merging the latent representation
learning and the probabilistic graphical model on human be-
havior. Collaborative deep learning (CDL) (Wang, Wang,
and Yeung 2015) is one example merging SDAE with a
probabilistic model of matrix factorization that often used
to explain and predict the human behavior of recommen-
dations. Whereas CDL gives a clear passway on how we
can further develop various models of human behavior with
support from the deep learning, different application do-
mains require different latent modeling, so the model struc-
ture needs to be further customized and expanded.

This paper introduces Neural Ideal Point Estimation Net-
work (NIPEN) which models the generative process of po-
litical voting by estimating ideal points in diverse legisla-
tive aspects with learning the low dimensional representa-
tions from neural networks. Speciﬁcally, we propose two
versions of NIPEN. The ﬁrst version, NIPEN-PGM is a
hybrid model by representing the contextual causalities as
a PGM, and by learning the low dimensional representa-
tions with multi-layered perceptron (MLP) autoencoders,
i.e. SDAE and VAE. The second version, NIPEN-Tensor, is
a neural tensor model that substitutes the PGM part with the
neural tensor model. NIPEN-Tensor could be viewed as a
generalized version of NIPEN-PGM. NIPEN-Tensor mod-
els the legislative voting with the tensor composition and
the nonlinear operations between diverse legislative factors

Figure 1: The summarized procedure of NIPEN. NIPEN predicts the votes with the combination of contents and network
analyses. We can interpret not only an individual legislator’s ideal points but also trust networks between legislators

while NIPEN-PGM assumes the marginalization and the lin-
earized operation in the same modeling part.

Second, NIPEN is the most comprehensive model in the
latent modeling of the political domain. Assuming that we
model a voting process of legislators, NIPEN is the ﬁrst
model of unifying 1) the voting behavior, 2) the network in-
ﬂuence between congressmen, 3) the political ideal point of
bills and congressmen, 4) the textual topic of bills, and 5) the
relative strength of network inﬂuence and ideal points when
casting a vote. Some of these latent variables have been seen
in other models, (Gerrish and Blei 2012; Gu et al. 2014;
Chaney, Blei, and Eliassi-Rad 2015), but not as the uni-
ﬁed model to depict a whole political picture. Since di-
verse factors, such as the contents of the bill and the hu-
man relations, greatly inﬂuence the voting (Cohen and Mal-
loy 2014), an effective modeling of the legislative voting re-
quires an integrated model, such as NIPEN. We show that
NIPEN recorded signiﬁcant performance improvements in
all metrics compared to existing models. We also show vari-
ous qualitative analyses that can only obtained via this com-
prehensive model. The entire procedures and analyses of
NIPEN is summarized by Figure 1.

Previous Research

Modeling Political Network and Ideal Points

Network analyses and ideal point estimation have been
widely studied in computer science and quantitative polit-
ical science for its importance. In the line of political net-
work analyses, most studies analyzed co-sponsorship data
(Faust and Skvoretz 2002; Fowler 2006). Faust and Skvoretz
(2002) clariﬁed the topological structures in the network of
the U.S. Senate (1973-1974), and they found that the net-
work among U.S. Senator in 93rd Congress is O-star, I-
star and Trans structure (Faust and Skvoretz 2002). Fowler
(2006) inferred the relationship in U.S. Congress (1973-
2004) by measuring the centrality to ﬁnd the most central
legislators (Fowler 2006). In the community of ideal point
estimation, Poole and Rosenthal (1985) proposed a nonl-
inear logit model to account for political choices of legis-
lators (Poole and Rosenthal 1985). However, it was a one-
dimensional estimation, and the analysis could not identify

what the ideal dimension stands for. To overcome the lim-
itation, Clinton et al. (2004) proposed a multi-dimensional
ideal point estimation model, but these models still remained
at the simple logit model extensions (Heckman and Snyder
Jr 1996; Clinton, Jackman, and Rivers 2004).

With the advance of topic modeling, multi-dimensional
ideal point models were developed, and these models pro-
vide more accurate interpretations on the ideal points. Ger-
rish and Blei (2012) proposed an issue-adjusted model (Ger-
rish and Blei 2012) with the labeled LDA (Ramage et al.
2009), and Yupeng et al. (2014) proposed a topic-factorized
ideal point model (TFIPM) (Gu et al. 2014) with probabilis-
tic latent semantic analysis (PLSA) (Hofmann 1999) to esti-
mate the ideal points of legislators based on roll-call data.
Further extensions of TFIPM have made through includ-
ing available domain data. For instance, Islam et al. (2016)
proposed SCIPM by including co-sponsorship networks be-
tween judges in the supreme court (Islam et al. 2016). These
works have remained in the extension of the probabilistic
graphical model without the innovation from the deep learn-
ing community, which our work extends 1) the probabilis-
tic graphical model with variational autoencoders and 2) the
neural tensor model for the causality modeling of the leg-
islative voting.

Collaborative Filtering and Deep Learning
Collaborative Filtering is a recommendation algorithm that
considers the relationship between users and items (Koren,
Bell, and Volinsky 2009). One of representative approach is
a matrix factorization which factorizes the rating matrix as
user latent and item latent factors.Recently, the deep learn-
ing has initiated two theoretic developments. First, the ma-
trix factorization itself is a low-dimensional representation
method because of its latent vector learning, so does the au-
toencoding in the deep learning. For example, Sedhain et
al. (2015) proposed Autorec (Sedhain et al. 2015), a basic
autoencoder based CF algorithm, and Autorec outperforms
other state-of-the-art MF algorithms like LLORMA (Lee et
al. 2013). Wu et al. (2016) expand Autorec by concatenating
a user latent variable to the rating input information in the
encoder part of Autorec (Wu et al. 2016). Li et al. (2015)
adopted two autoencoders corresponding to users and items

(Li, Kawale, and Fu 2015), and they showed the interac-
tion mechanism between the two autoencoders by using the
marginalized SDAE (Chen et al. 2012). Second, the matrix
factorization is related to the low-dimensional feature rep-
resentation by adding the representation of the model as the
distilled version of the side information. For instance, Wang
et al. (2015) proposed a collaborative deep learning (CDL)
which combines SDAE with MF (Wang, Wang, and Yeung
2015). Furthermore, Ying (2016) proposed a model of col-
laborative deep ranking which combines ranking with algo-
rithm and SDAE (Ying et al. 2016). Wang et al. (2017) pro-
posed the relational deep learning with SDAE to link predic-
tion between items (Wang, Shi, and Yeung 2017).

Method
This section introduce the detailed descriptions of NIPEN-
PGM and NIPEN-Tensor in turn. Appendix A formulates
the assumptions and the research questions, and Appendix
C enumerates all symbols in this study.

NIPEN with Probabilistic Graphical Model and
Autoencoders
Figure 2 describes the model structure of NIPEN-PGM. We
start the detailed description from the bill low dimension
modeling part, which is the bill plate with the d ∈ D sub-
script. We apply either VAE or SDAE to learn the low di-
1 with the observed
mensional representation, or topic, of zdk
bill text wdv. zdk can be extracted through the probabilistic
encoder, qφ with parameter φ and decoder, pθ with param-
eter θ which is further described in Appendix B. The topic
representation of bills has two components: the bill latent
ydk and the latent offset ξdk, and we model the combination
of the two component as the below.

ydk = ξdk + zdk,

ξkd ∼ N (0, λ−1
y )

Since the bill itself and the bill text may have two differ-
ent latent variables, ξdk becomes the offset between the bill
latent variable and the bill text latent variable, or topic.

From the deﬁned bill latent ydk, we model how the bill
latent generates the voting observation rud. Here, u ∈ U is
the dimension of the legislators. We assumed that a legislator
cast votes considering three latent factors: the bill latent ydk,
the bill ideal point adk, and the legislators’ ideal point xuk.

adk ∼ N (0, λ−1

u ),

xuk ∼ N (0, λ−1
u )

Now, we deﬁne NIPEN-PGM without the network fac-
tor. This voting procedure is modeled as Eq. (1) where ηd
is a bias value of a legislative bill, and σ is a sigmoid func-
tion. Eq. (1) is designed to increase the probability of vot-
ing YEA when the ideal points of the bill and the legislator
have the same sign; and when an ideal-aligned dimension
of the bill latent variable is high. Additionally, ηd indicates
whether the bill is more broadly accepted or not, regardless
of ideal points.

p(rud = 1) = σ(

ydkadkxuk + ηd)

(1)

K
(cid:88)

k=1

1d, u, and k mean each document, legislator, topic respectively.

Small subscripts indicate the row and column index in order.

Figure 2: Graphical model representation of NIPEN-PGM

Finally, we add the network component to NIPEN-PGM.
The interest of a particular legislative group could be an im-
portant factor in the voting process. Following this impli-
cation, we modeled the network between two legislators as
below. Before the network modeling, we limited the network
inﬂuence between the legislators sharing the same term, and
this neighbor set, Iu, is deﬁned as a neighborhood of legis-
lator, u.

τuu(cid:48) ∼ N (0, λ−1

τ ) αu ∼ N (0, λ−1

α ) βu ∼ N (0, λ−1
α )
The legislator u’s voting is affected by two terms. The ﬁrst
term is the ideal alignment modeled in Eq. (1). The second
term is the voting record of the neighbor legislator, ru(cid:48)d, and
the second term is also weighted by the network strength,
τuu(cid:48), between the two legislators. Since this is a linear sum-
mation, τuu(cid:48) will model the degree of voting agreement be-
tween two legislators. These two terms are uniﬁed with scal-
ing parameters αu and βu. The purpose of modeling αu and
βu is analyzing whether a certain legislator is inﬂuenced
more either from the bill or from the network in casting
votes.

Eq. 2 is the overall voting formulation of NIPEN-PGM.

p(rud = 1) = σ(αu(

ydkadkxuk + ηd)

+ βu(

τuu(cid:48)ru(cid:48)d))

(2)

(cid:88)

k
(cid:88)

u(cid:48)∈Iu

NIPEN with Neural Tensor Model
Existing models, including NIPEN-PGM, do not directly
model the relationships between the topics, which means
that there is no cross-operiation between the dimension of
K. Some cases, i.e. correlated topic model (Lafferty and Blei
2006), model the correlation between topics via the logistic
normal distribution, but this is not an operation modeling of
topic inﬂuences, rather the variable modeling of topic co-
variance.

The recent introduction of neural tensor models (Socher
et al. 2013) enable the cross-operations between the latent

topic dimension. This topic cross-operation can model the
legislator’s ideal point non-linear inﬂuences when two top-
ics are combined within a bill. Here, we propose NIPEN-
Tensor to incorporate the cross-topic inﬂuence in casting a
vote, which could not be modeled in NIPEN-PGM. NIPEN-
Tensor and NIPEN-PGM are similar in the parts of docu-
ment and inﬂuence network modeling. The only different
part is the voting decision modeled as Eq. 2 which multiplies
the factors per a topic and marginalizes. NIPEN-Tensor con-
siders that the multiplication per a topic should be changed
to consider the nonlinear effect from the topic set, not a sin-
gle topic. Therefore, we represent the previous topic-wise
multiplcaiton of ydkadkxuk as a tensor E, and this tensor
still treats the topic dimension to be independent. Then, we
apply a fully-connected layer to cross-operate the topic di-
mension of E, and the neural network has C that is the out-
put of the cross-operation. The overall structure and formu-
lation for the NIPEN-Tensor are shown in Figure 3 and Eq.
3, respectively.

Eudk = xukydkzdk
(cid:88)

(cid:101)Eudl = tanh(

k

EudkW (T1)

kl + b(T1)

l

)

Cud =

(cid:101)EudlW (T2)

l1 + ηd

(cid:88)

k
(cid:88)

u(cid:48)∈U

Nud =

τuu(cid:48)vu(cid:48)d

(3)

W (T1), b(T1), W (T2) are weights and biases applied to Eudk,
(cid:101)Eudl tensor. In particular, W (T1) ∈ RK×K models the cor-
relation between topics, and W (T2) ∈ RK×1 models the
inﬂuence of each topic on the voting. Since the signs of
xuk, ydk, and adk are important, we use tanh instead of
ReLU (Rectiﬁed linear unit) to transform the outputs non-
linearly.

Parameter Inference of NIPEN

The parameters of both NIPENs are enumerated in the pre-
vious section, and we learn the parameters in two folds:
learning the autoencoder to represent the bill topic and
the CF, alternatively. The ﬁrst set of parameters related
to autoencoders is ψ(1) = (θ, φ); and the second set
of parameters related with the legislative-CF is ψ(2) =
(y, a, η, x, W (T1), W (T2), b(T1), τ, α, β).

The overall inference algorithm of both NIPENs fol-
lows the maximization of variational evidence lower bound
with two assumptions. Following CDL, the ﬁrst assump-
tion is connecting the autoencoder and CF through ξ, and
the strength is controlled by the variance of ξ, which is λy.
When learning ψ(1), we apply the stochastic gradient varia-
tional Bayes (SGVB) estimator.

Second, we assumed that the variational distribution of
ψ(2) as a point mass for simplicity, so the parameters of
the variational distribution are updated by each casted vote

Figure 3: Neural network view of NIPEN-Tensor. The con-
tents part is connected with the blue line (with content scal-
ing parameter αu ), and the network part is connected with
the purple line (with the network scaling parameter βu ).

record, which is traditional Bayesian belief updates. Speciﬁ-
cally, the likelihood of the posterior is presented as the lower
bound in the below. Then, the lower bound, which has real-
ized values of qφ(z|w), pθ(z) and an observed input, has
only ψ(2), so the gradient method can ﬁnd the maximum a-
posteriori, or MAP, of ψ(2).

As a summary, the objective function of both NIPENs is

LN IP EN = −DKL(qφ(z|w)(cid:107)pθ(z)) +

log pθ(w|zl)

1
L

L
(cid:88)

l=1

+

+

−

λf
2

λf
2

λy
2

(cid:88)

(u,d),rud(cid:54)=0
(cid:88)

(u,d),rud(cid:54)=0

1 + rud
2

1 − rud
2

log p(rud = 1)

log p(rud = −1)

D
(cid:88)

d=1

(cid:107)yd − zd(cid:107)2

2 −

((cid:107)a(cid:107)2

F + (cid:107)x(cid:107)2
F )

λu
2

−

λτ
2

F ) −

((cid:107)τ (cid:107)2

((cid:107)α(cid:107)2

2 + (cid:107)β(cid:107)2
2)

λα
2
Similar to (Wang and Blei 2011; Wang, Wang, and Yeung
2015), the parameters related with the autoencoder and the
legislative-CF are infered by coordinate ascents which maxi-
mizes LN IP EN . For legislative-CF related parameters ψ(2),
we take the gradient of LN IP EN w.r.t each parameters given
the current θ and φ. Given the legislative-CF related param-
eters ψ(2), we infer the autoencoder related parameters by
computing ∇ψ(1)LN IP EN . We utilized the Tensorﬂow li-
brary (Abadi et al. 2016) to optimize the parameters.

NIPEN-PGM and NIPEN-Tensor are only different in the
vote casting process, and the related term in the objective
function is the third and the fourth terms with log p(rud =
1). These terms could be computed as the conventional gra-
dient descent in two variants of NIPEN, so there is no change

p(rud = 1) = σ(αuCud + βu

Nu(cid:48)d)

speciﬁed as follows:

(cid:88)

u(cid:48)∈Iu

in the learning mechanism.

In the original deﬁnition, the network, τ , is a |U |-by-|U |
matrix, and the number of parameters becomes large given
O(U 2). To reduce the squared complexity, τ is approxi-
mated by the product of (cid:101)τ1 and (cid:101)τ2 where (cid:101)τ1 ∈ RU ×G, (cid:101)τ2
∈ RG×U . We assume that (cid:101)τ1 and (cid:101)τ2 are not related. G can
be interpreted as the number of groups containing the legis-
lators. This approximation results in O(GU ) for the network
parameter inference.

Table 1: Attributes of Politic2013 and Politic2016 dataset

# of legislators (|U |)
# of bills (|D|)
# of votings (|D|)
# of House
# of Senator
# of Republican
# of Democrat
# of unique word (|V |)

Average # of unique word
(cid:80)
d,v(Iwdv >0)
for each bill (

)

V

# of bills less than
10 unique words
Period
Source
Data type

Politic2013
1,540
7,162
2,779,703
1,299
241
767
767
10,000

Politic2016
1,537
7,975
2,999,844
1,266
271
778
752
13,581

192.77

378.66

65

0

1990-2013
THOMAS

1989-2016
GovTrack

1 (YEA), -1 (NAY)

Results

Datasets on Political Ideal Points
We used two roll-call datasets, whose source is explained in
Appendix D. Table 1 provides the descriptive statistics of the
two datasets: Politic2013 and Politic2016. Politic2013 limits
the number of a unique word to 10,000, and there are 65 bills
which have less than ten words, while Politic2016 chooses
13,581 unique words, and there are no bills with less than ten
words. Politic2013 is a more sparse dataset than Politic2016
in the ratings and the vocabulary sizes.

Baselines and Implementation Details
The variations of NIPEN were compared to ﬁve baseline
models as follows:
• TFIPM: Topic Factorized Ideal Point estimation Model
(Gu et al. 2014) is specialized in politics to analyze the
roll-call data.

• Autorec: A simple autoencoder model which is utilized to
predict the ratings. Autorec (Sedhain et al. 2015) encodes
and reconstructs the rating matrix. We used Item-based
Autorec.

• Trust SVD: Trust SVD (Guo, Zhang, and Yorke-Smith
2015), a type of trust-based matrix factorizations, is built
on SVD++ with trust information.

• CDAE: Collaborative Denoising Autoencoder (Wu et al.
2016) used a denoising autoencoder with user latent vari-
ables.

• CDL: Collaborative Deep Learning (Wang, Wang, and
Yeung 2015) used the deep learning and the CF, jointly.
CDL improves performance by using document informa-
tion additionally, and CDL uses SDAE to learn document
manifold.
Appendix E provides detailed speciﬁcations for replica-
tions of this work, and Appendix F illustrates the sensitivity
analysis of λy and λτ .

Quantitative Evaluations
We performed the ﬁve-fold cross-validation to quantita-
tively evaluate the variations of NIPENs, and the perfor-
mance measures are RMSE, MAE, accuracy, and nega-
tive average log-likelihood (NALL) measures. We compared
nine models: ﬁve baseline models in section 4.2, and four
NIPEN variations, which are NIPEN-PGM(SDAE), NIPEN-
PGM(VAE,approx.), NIPEN-PGM(VAE), and NIPEN-
Tensor. NIPEN-PGM has three variants by choosing either
SDAE or VAE as the autoencoder for the text modeling, and
by choosing either using the whole matrix for the inﬂuence
or the low-rank approximated matrix of the inﬂuence.

Table 2 statistically conﬁrms that the best performance
model in every metric is always a variation of NIPEN, which
is conﬁrmed with statistical signiﬁcance. In detail, ﬁrst,
we compare NIPEN-PGM(VAE) and NIPEN-PGM(SDAE),
and their performance gap is larger in Politic2013 than in
Politic2016 which is a relatively sparse setting as shown
in Table 1. We conjecture that NIPEN-PGM(VAE) is bet-
ter in handling the sparse dataset than NIPEN-PGM(SDAE).
Second, NIPEN-Tensor is a model that considers the cor-
relation between topics, and NIPEN-Tensor may have a
better performance when a bill text has multiple topics
with complex and rich textual information. As discussed
in Section Datasets on Political Ideal Points, Politic2016
has richer textual information than Politic2013, and we con-
jecture that this is the reason why NIPEN-PGM(VAE) in
Politic2013 and NIPEN-Tensor in Politic2016 show better
performances. Third, while the accuracy improvement is rel-
atively small, the improvements on other metrics, partic-
ularly RMSE and MAE, are relatively large. Already, the
baseline models achieve the accuracy higher than 95%, so
the accuracy improvement could seem minimal. However,
our likelihood estimation of YEA and NAY is considerably
improved given the RMSE and the MAE improvement.

Qualitative Evaluations
In addition to the quantitative results, we interpret the latent
variables of NIPEN-PGM(VAE) on Politic2016. First, to
comprehend the dataset and the qualitative results, we com-
puted the word-topic matrix from well-learned VAE vari-
ables, ψ1, as shown in Table 3. This table provides a snap-
shot of topics in the bills. Then, we relate this topic to the bill
ideal points, adk. The latent dimension, k, becomes the com-
mon dimension of an ideal point value and a topic weight
for each topic in the bill. Figure 5 shows an example of the
topic weight as the bar chart and the ideal point value as the
line chart. The illustrated bill, or H.Res.794 (114th), has the
largest absolute value, |adk(cid:101)zdk| in a ’Business and Finance’
topic where (cid:101)zdk denotes the normalized zdk.

Table 2: Quantitative evaluation on Politic2013 and Politic2016 datasets. Two-standard deviation is shown in parentheses

Politic2013

Politic2016

RMSE
0.2253
(±0.0007)
0.2110
(±0.0099)
0.2059
(±0.0007)
0.1872
(±0.0002)
0.1834†
(±0.0008)
0.1801**
(±0.0014)

MAE
0.1399
(±0.0011)
0.0975
(±0.0136)
0.0831
(±0.0009)
0.0682†
(±0.0002)
0.0786
(±0.0019)
0.0591**
(±0.0012)

Accuracy
0.9408
(±0.0003)
0.9411
(±0.0056)
0.9428
(±0.0006)
0.9526
(±0.0003)
0.9554†
(±0.0004)
0.9566**
(±0.0006)

NALL
0.1866
(±0.0011)
0.1466
(±0.0177)
0.1450
(±0.0009)
0.1213
(±0.0007)
0.1147†
(±0.0018)
0.1155
(±0.0018)

RMSE
0.2168
(±0.0011)
0.2031
(±0.0015)
0.1977
(±0.0037)
0.1794
(±0.0010)
0.1780†
(±0.0013)
0.1779
(±0.0005)

MAE
0.1353
(±0.0010)
0.0886
(±0.0110)
0.0802
(±0.0052)
0.0625†
(±0.0006)
0.0769
(±0.0012)
0.0560**
(±0.0004)

Accuracy
0.9463
(±0.0009)
0.9454
(±0.0007)
0.9475
(±0.0023)
0.9566
(±0.0005)
0.9583†
(±0.0008)
0.9581
(±0.0003)

NALL
0.1782
(±0.0015)
0.1349
(±0.0125)
0.1357
(±0.0046)
0.1121
(±0.0016)
0.1106†
(±0.0017)
0.1173
(±0.0015)

0.1804
(±0.0089)

0.0611*
(±0.0065)

0.9565
(±0.0047)

0.1165
(±0.0086)

0.1791
(±0.0076)

0.0599
(±0.0057)

0.9571
(±0.0039)

0.1152
(±0.0070)

0.1753**
(±0.0007)
0.1818**
(±0.0008)
4.41%

0.0588**
(±0.0008)
0.0663**
(±0.0003)
13.78%

0.9587**
(±0.0006)
0.9556**
(±0.0003)
0.35%

0.1075**
(±0.0011)
0.1155
(±0.0020)
6.27%

0.1753**
(±0.0017)
0.1729**
(±0.0015)
2.87%

0.0570**
(±0.0012)
0.0608**
(±0.0006)
10.40%

0.9590**
(±0.0010)
0.9600**
(±0.0008)
0.18%

0.1112
(±0.0024)
0.1057**
(±0.0022)
4.43%

Trust SVD

Autorec

CDAE

TFIPM

CDL

NIPEN-
PGM(SDAE)
NIPEN-
PGM(VAE,
approx.)
NIPEN-
PGM(VAE)
NIPEN-
Tensor
Improvement

NALL : Negative Average Log Likelihood
Improvement : Relative improvement of the best version of NIPEN compared to the best model, which is marked by †, among the baselines
P ∗ < 0.05; P ∗∗ < 0.01 (Student’s one-tailed t-test against the † model)

Table 3: Selected top-ﬁve words for each topic. The number
of listed topics was set to ten.

Topic Label
Business and
Finance
Disasters
Management
International
Relationship

Racism

Defense

Agriculture

Social

Health

Foregin

1

2

3

4

5

6

7

8

9

International
Trade

10

Topic Words
Forproﬁt, Nonrefundable, Govern,
SBDC, Financings
Stabilization, Homeless, Disasters,
Alerts, USPS
Kuwait, Distributes, Lawsuits,
Threatens, Spain
Contrary, Black, Compared,
Tuskegee, Reagan
United, Soviet, Antiterrorist, IDA,
NGA
Pima, Climate, Cropland, Bush,
Badlands
Contribute, Donors, Childcare,
Resettlement, DRR
FEHBP, Heroin, Stability,
Musculoskeletal, Transplantation
Agency, Lantos, FPI, fusion,
division
Clearinghouses, ESF,
Discrepancies, Repay, Charging

Figure 4: Individual legislators’ ideal points for each topic

This bill ideal point is correlated with the legislator ideal
point, xuk, to generate the vote records. Here, the dimen-
sion, k, is the same latent dimension of the topic in Table
3, and we provide the scatter plot of the legislators’ ideal
points per topic in the Figure 4. The prior mentioned bill
(H.Res.794 (114th)) considers the appropriations for ﬁnan-
cial services and general government, and the major topic is
Business and Finance, and the bill ideal point in Business
and Finance is -1.217. Together, the vote casting will be de-
termined by the legislators’ view on Business and Finance,
and this topic shows the greatest disagreement between the
Republicans and the Democrats according to the Figure 4. In
the real world, the voting results were same as expected: 1)
the voting was very partisan, 92.2% Republican voted YEA

Figure 5: Topic proportion and ideal points of H.Res.794
(114th) bill

Table 4: Top-ﬁve legislators who are affected by contents or
network factors a lot. The scaling variable (αu for contents
based, and βu for network based), political party, and district
of the member are indicated in parentheses.

Contents based
Ron Paul
(0.260, R, TX)
Virgil H. Goode
(0.220, R, VA)
Dennis J. Kucinich
(0.218, D, OH)
Henry Cuellar
(0.198, D, TX)
Walter B. Jones
(0.195, R, NC)

1

2

3

4

5

Network based
Ralph M. Hall
(0.304, R, TX)
Nick J. Rahall II
(0.250, D, WV)
Peter A. DeFazio
(0.247, D, OR)
Don Young
(0.228, R, AK)
Jim Sensenbrenner.
(0.227, R, WI)

action between the contents and the network parts. We
used two scaling variables αu and βu, which controls the
strengths of contents factor and network factor, respectively.
Table 4 shows the top-ﬁve legislators who were affected by
either contents or network factors. Since the variations of
NIPEN is an integrated model of network modeling as well
as the textual bill modeling, the NIPENs should better per-
form than the baseline models, i.e. CDL, which only models
the texts, and Figure 7 conﬁrms this hypothesis.

Figure 6: Trust network between legislators

and the 90.3% Democrat voted NAY.

The second qualitative interpretation focuses on the legis-
lators’ network. We selected 12 legislators who have either
strongly positive or negative relationships with each other,
shown in the Figure 6. In general, the legislators have a
strong positive relationship when they have the same dis-
trict and the party. Among the top-ﬁve positive relation-
ships, four of them have the same party and the same dis-
trict, i.e. ’Thomas E. Petri↔Jim Sensenbrenner’, ’Nick J.
Rahall II→Robert E. Wise’, and ’Nick J. Rahall II→Alan B.
Mollohan’2. The closest relations are ’Thomas E. Petri’ and
’Jim Sensenbrenner’. They were both republican representa-
tives from Wisconsin, and they share similar voting patterns.
They have voted 6,288 times for the same bill, and the 5,764
votes were same (91.6%). Especially, they voted NAY for
H.R.730 (111th) which is a ”suspension of the rules”, and
397 legislators votes YEA. For H.R.6063 (110th), ’Thomas
E. Petri’ and ’Jim Sensenbrenner’ voted NAY together while
94.4% legislators voted YEA. We report further analyses in
Appendix G.

The third qualitative analysis concentrates on the inter-

2τuu is asymmetric matrix. arrow(’→’) indicates the direction

of the trust

Figure 7: Accuracy of top ﬁve legislators who are affected
by network factor

Conclusion

We proposed two versions of machine learning models,
NIPEN-PGM and NIPEN-Tensor, to analyze the ideaology
in the legislation process. The variations of NIPEN show the
state-of-the-art performance in all measures on Politic2013
and Politic2016. Furthermore, NIPEN provides various in-
terpretations in why YEA or NAY is casted by illustrating 1)
the ideal point estimation of individual legislators and bills;
2) the trust network between legislators; and 3) the content
and network inﬂuence for each legislator. These supervised
and unsupervised tasks could be critical insights into quan-
titatively understanding politics in the legislative process.

Appendix A. Problem Formulation

In general, the inﬂuence on legislative voting originates from
1) the individual ideal points of the legislator, 2) the contents
of the bill, and 3) the interests of a political group that a leg-
islator belongs to. We operationalize these inﬂuence struc-
ture as the concepts deﬁned in the below.

Deﬁnition 1. Ideal point is a measure of legislator’s prefer-
ence for each topic when we have K topics in our bill texts.
The ideal point for a particular topic k of a particular mem-
ber u is represented by xuk, and it follows N (0, λ−1
u ). The
sign of xuk represents the preferred voting direction (posi-
tive or negative), and the size of |xuk| represents the pref-
erence strength. The ideal point for a particular topic k of a
particular bill d is represented by adk, and its distribution is
N (0, λ−1
u ). The interprestation of adk is same as xuk.

Deﬁnition 2. Contents refer to the bill elements, i.e. text
descriptions, which affect the voting result. The latent repre-
sentation of the contents is ydk which is the addition of zdk,
the topic of the bill; and ξdk, the deviation of the bill from
the topic of the bill text.

Deﬁnition 3. Network means the collection of relationships
between legislators whose vote affect the other’s vote. The
strength of network relationships is modeled as τuu(cid:48), which
follows N (0, λ−1
τ ). The sign of τuu(cid:48) indicates the voting
alignment between u and u(cid:48) legislators, and |τuu(cid:48)| means
its alignment strength. This study assumes that the network
relationships are asymmetric bidirectional, and only the leg-
islators in the same term affect each other.

Deﬁnition 4. Scaling parameters mean the inﬂuence of
contents and networks when a legislator votes. αu is a con-
tent scaling parameter, and βu is a network scaling parame-
ter. Each scaling parameter is a |U |-dimensional vector, fol-
lowed by N (0, λ−1
α ). This study assumed that the degree of
inﬂuence on the contents and the network would be different
per each legislator.

Now, given the above deﬁned concepts, we enumerates

the research questions to test with NIPEN.

Problem 1. NIPEN can predict the results of the voting by
inferring the bill topic, the bill ideal points, the legislator
ideal points, and the network relationships between the leg-
islators.

Problem 2. NIPEN provides the interpretation on the vot-
ing results of the bill. For example, NIPEN illustrates the
interpretable latent information from the bill topic, the bill
ideal point, and the legislator ideal point taking into account
the correlation between the topics.

Problem 3. NIPEN can 1) analyze the trust between legis-
lators (individual unit), and 2) the trust network comparison
between parties (group unit).

Problem 4. NIPEN provides the behavioral analyses on leg-
islators from the voting motivation perspective, which could
be motivated by either legislator ideal point or network rela-
tionship.

Appendix B. Document Modeling
Autoencoders

Appendix B.1. Variational Autoencoder (VAE)
NIPEN extracts the topics of the legislative bills with
VAE (Kingma and Welling 2014) which is a type of
deep generative model. VAE learns the disentangled and
low-dimensional representation of high dimensional data
through the probabilistic encoding, or qφ(z|w); and the
probabilistic decoding, or pθ(w|z). Therefore, the original
objective function of VAE is composed of the linear sum of
corresponding two terms. The ﬁrst term originating from the
encoding is the KL divergence between the probabilistic en-
coding and the prior for latent variable, or pθ(z); and this
term enforces the regularization. The second term is the ex-
pectation on the negative reconstruction error, and this term
is related to the decoding part. By putting both terms to-
gether, the objective function follows as Eq. (4).

L(θ, φ) = −DKL(qφ(z|w)(cid:107)pθ(z)) + Eqφ[log pθ(w|z)]

(4)
Given the high variance over φ, a direct optimization of
Eq. (4) is not efﬁcient. Hence, Kingma and Welling (2014)
suggested the re-parametrization trick as follows: 1) Draw
(cid:15)l ∼ N (0, I), and 2) Optimize the mean and standard devi-
ation of qφ(z|w), and 3) Compute zl = µ(w) + σ(w) (cid:12) (cid:15)l.
From the trick, the objective function of VAE is turned into
Eq. (5) where L is the number of samples.

(cid:101)L(θ, φ) = −DKL(qφ(z|w)(cid:107)pθ(z)) +

log pθ(w|zl)

1
L

L
(cid:88)

l=1

(5)

Appendix B.2. Stacked Denoising Autoencoder
(SDAE)
NIPEN-PGM(SDAE) extracts the topics of the legislative
bills with SDAE (Vincent et al. 2010). SDAE learns the
disentangled latent feature through the encoding and decod-
ing with bottleneck and corrupted input. SDAE use the cor-
rupted input wc instead of the original input w to force
the relationship learning. The SDAE is optimized for the
purpose of reconstructing the w resulting from the encod-
ing process(fe) through the encoder weight (W (e)) and the
decodingfd result through the decoder weight (W (d)). The
objective function follws as Eq. (6)

(cid:13)
(cid:13)
2
(cid:13)fd(fe(w, W (e)), W (d)) − wc)
(cid:13)
(cid:13)
(cid:13)
2

(6)

Appendix C. Notations

Table 5 summarizes all symbols used in this study.

Appendix D. Dataset Descriptions

is Politic2013, and it was collected
The ﬁrst dataset
from THOMAS3, and (Gu et al. 2014). For an additional
experiment, and for more up-to-date analyses, we col-
lected a new roll-call dataset, Politic2016 from GovTrack

3http://thomas.loc.gov/home/rollcallvotes.html

Table 5: Notation description

Symbol
D
V
U (= U (cid:48))
K
G
Iu
wdv
zdk
ydk
adk
ηd
rud
xuk
αu
βu
τuu(cid:48)
(cid:101)τ1, (cid:101)τ2
ξ
(cid:15)
φ(θ)
C(N )
E
W (T ), b(T )

Description
Set of bills
Set of Unique words
Set of legislators
Set of topics
Rank of (cid:101)τ1 and (cid:101)τ2
Other legislators within the same term as u
Frequency of vth token in document d
Topic proportion for each bill and topic
Bill latent vector
Ideal point for each bill and topic
Constant offset for each bill d
Voting record from legislator u to bill d
Ideal point for each legislator and topic
Contents scaling parameter for legislator u
Network scaling parameter for legislator u
Trust network between legislator u and u(cid:48)
Approximated matrix of τuu(cid:48)
Latent offset between zdk and ydk
Random noise vector drawn from N (0, I)
Parameter of encoder (decoder) in VAE
Contents (Network) information
The tensor combined with xuk, ydk, adk
Neural tensor network parameter

.GovTrack provides raw roll-call data, so we processed
the expanded part of Politic2016, manually. For the re-
search community, we released the code and dataset on
https://github.com/gtshs2/NIPEN

Appendix E. Experiment Settings
For TFIPM, we followed the optimal parameters that the au-
thor reported. We set the latent dimension(K), the trade-off
weight, and the regularization weight as 10, 0.8, and 22.4,
respectively. The latent dimension of CDL and NIPENs was
set to ten, equally. For Autorec, the optimal number of the
latent dimension and the regularization parameter are 100
and 0.001, respectively. Trust SVD shows the best perfor-
mance when the weights of CF and trust part are 1,000 and
0.001, respectively, while K is set to 10. For CDAE, we
set the regularization weight, the corruption ratio, and the
number of latent dimension as 0.001, 0.4, and 50, respec-
tively; and the encoder and the decoder activation functions
are sigmoid. For CDL, we ﬁnd that the optimal parameters
of λu,λv,λw,λn, the dropout rate and the activation func-
tions are 0.01, 100, 1, 100, 0.1 and the sigmoid function, re-
spectively. The neural network structure of Autorec, CDAE,
CDL, NIPENs are set to [512,128,K,128,512], equally. Fi-
nally, we set the parameters of NIPENs such as λf = 10,
λy = 10, λu = 0.1, λτ = 1, λα = 1, λn = 1000 G = 3, and
we performed grid searches to ﬁnd the optimized parameters
of NIPENs. Finally, NIPEN-Tensor has the two-layered ten-
sor E in the topic axis.

Appendix F. Hyperparameter Study
This quantitative improvement requires a well-tuned hyper-
parameter setting, illustrated in Figure 8. LN IP EN enumer-
ates multiple hyperparameters, and we found that λy and λτ
are the most important parameters to decide. λy speciﬁes the
causality strength from the bill text latent in VAE to the bill
latent in the legislative CF. The low value of λy will sepa-
rate VAE and CF, but its high value will disrupt the manifold
learning of VAE. Moreover, λτ speciﬁes the regularization
strength from the legislators’ network inﬂuence to the vot-
ing. The small value of λτ will overﬁt the network inﬂuence,
and its large value will limit the learning of network inﬂu-
ence model in CF.

Figure 8: (Top-Left) Accuracy for λy and λτ value, (Top-
Right) RMSE for each λy and λτ value, (Bottom-Left) Ac-
curacy for G value, (Bottom-Right) RMSE for each G value

Appendix G. Results in Network Inﬂuence
Analyses
To examine the network relationships within each party, Fig-
ure 9 illustrates the trust network parameter. A red node rep-
resents a Republican; a blue node stands for a Democrat;
a green solid line indicates an inferred close relationship;
and a purple dotted line indicates an inferred unfriendly re-
lationship. Taking a threshold at 0.1 and looking at τuu(cid:48) with
values greater than 0.1 and less than -0.1 (Figure 9d), John
J. Duncan Jr and Dana Rohrabacher have the greatest net-
work impact given their number of connected legislators in
the Republican party. The commonalities between the two
inﬂuential legislators are 1) being a member of the House of
Representatives; and 2) having been politically active for a
long time (Duncan started as a congressman in Tennessee in
1988 and Laura Baker as a California congressman in 1989.
Especially, Jimmy Duncan is the House’s longest-serving
Republicans.).

We compared and contrasted the network structure of Re-
publicans and Democrats. As shown in Table 6, the network
inﬂuence among the total members is greater in the Demo-
cratic Party given its mean value of |τuu(cid:48)|. However, the Re-

publican party has the higher number of inﬂuential legisla-
tors when we limit the network inﬂuence with thresholds,
i.e. when we limit |τuu(cid:48)| > 0.05 or |τuu(cid:48)| > 0.1 in Table 6.
This suggests that the Democrats have averagely higher and
more equal inﬂuences between the members while the Re-
publicans have a number of authorative inﬂuencers among
the members.

(a) Threshold = 0.03

(b) Threshold = 0.05

Table 6: Comparison of network inﬂuence by each Party

# of pair s.t. τuu(cid:48) > 0.05
# of pair s.t. τuu(cid:48) < −0.05
# of pair s.t. τuu(cid:48) > 0.1
# of pair s.t. τuu(cid:48) < −0.1
Mean of |τuu(cid:48)|
Variance of |τuu(cid:48)|

Republican
58
67
7
3
9.0E-04
2.49E-05

Democratic
49
53
1
3
0.0018
3.38E-05

Table 7: Content and Network scale comparison between the
Party. Average Ranking@K is the average of the ranking of
each legislator, by the party, when the ranking is made up to
the top K legislators, based on scaling parameter (αu βu).

Content (|αu|)

Network (|βu|)

R
6
40
52.87
774.6
0.149

NL@10
NL@100
AR@100
AR@All
Mean value of αu (βu)
R : Republican Party / D : Democratic Party
AR@K : Average Ranking at top K
NL@K : Number of legislators at top K

D
4
60
48.91
762.7
0.148

R
6
42
46
781.4
0.068

D
4
58
53.75
754.9
0.064

Republican Party generally relies on the network, and the
Democratic Party on contents, when they are voting. If we
associate this conclusion with Table 6, we can explain that
a Democratic have more inﬂuence in the network within the
party. However, the proportion of people who are dependent
on the network (including network from their own party and
opposing party) is relatively high in the Republican Party.

(c) Threshold = 0.07

(d) Threshold = 0.1

Figure 9: Network inﬂuence visualization within each party
in December 2016. The top visualizations represent the Re-
publican Party, and the bottom visualizations represent the
Democratic Party. If the network inﬂuence, τuu(cid:48), between
two legislators exceeds the threshold, the relationship is ex-
pressed as a green solid line. If the network inﬂuence, τuu(cid:48),
is less than the threshold, the relationship is noted as a purple
dotted line.

The United States has a two-party system. In order to an-
alyze this reality effectively, contents scaling parameter and
network scaling parameter are analyzed by each party. Com-
paring the mean value of |αu| and |βu| in the Table 7, we
can see that both parties are generally voting rather than net-
works, concentrating on their own politics and the contents
of the bill itself. To compare two political parties relative to
each other based on Average Ranking@100 in Table 7, the

Figure 10: Graphical model representation of NIPEN-PGM

According to the opinion of the reviewers who advised
on the analysis of αu and βu, the distribution of |αu| and
|βu| is shown in Figure 10, and the value of |αu|/|βu| over
time is shown in Figure 11. According to Figure 10, we can
infer that the majority of legislators are voting focusing on

of Roll Call Data. The American Political Science Review
98(2):355–370.
[Cohen and Malloy 2014] Cohen, L., and Malloy, C. J. 2014.
Friends in high places. American Economic Journal: Eco-
nomic Policy 6(3):63–91.
[Faust and Skvoretz 2002] Faust, K., and Skvoretz, J. 2002.
Comparing Networks Across Space and Time, Size and
Species. Networks 32(2002):267–299.
[Fowler 2006] Fowler, J. H. 2006. Connecting the congress:
Political Analysis
A study of cosponsorship networks.
14(4):456–487.
[Gerrish and Blei 2012] Gerrish, S., and Blei, D. M. 2012.
How they vote: Issue-adjusted models of legislative behav-
ior. Advances in Neural Information Processing Systems
25(1):2762–2770.
[Gu et al. 2014] Gu, Y.; Sun, Y.; Jiang, N.; Wang, B.; and
Chen, T.
2014. Topic-factorized ideal point estimation
model for legislative voting network. Proceedings of the
20th ACM SIGKDD international conference on Knowledge
discovery and data mining. ACM, 2014. 183–192.
[Guo, Zhang, and Yorke-Smith 2015] Guo, G.; Zhang, J.;
and Yorke-Smith, N. 2015. TrustSVD : Collaborative Fil-
tering with Both the Explicit and Implicit Inﬂuence of User
Trust and of Item Ratings. Proceedings of the Twenty-ninth
AAAI Conference on Artiﬁcial Intelligence (AAAI) 123–129.
[Heckman and Snyder Jr 1996] Heckman, J. J., and Snyder
Jr, J. M. 1996. Linear probability models of the demand
for attributes with an empirical application to estimating the
preferences of legislators. National bureau of economic re-
search 28(0).
[Hofmann 1999] Hofmann, T. 1999. Probabilistic latent se-
mantic indexing. Proceedings of the 22nd annual interna-
tional ACM SIGIR conference on Research and development
in information retrieval 50–57.
[Islam et al. 2016] Islam, M. R.; Hossain, K. T.; Krish-
nan, S.; and Ramakrishnan, N.
Inferring Multi-
dimensional Ideal Points for US Supreme Court Justices.
Proceedings of the 30th Conference on Artiﬁcial Intelligence
(AAAI) 4–12.
[Kingma and Welling 2014] Kingma, D. P., and Welling, M.
2014. Auto-encoding variational bayes. In Proceedings of
the International Conference on Learning Representations
(ICLR).
[Koren, Bell, and Volinsky 2009] Koren, Y.; Bell, R.; and
Volinsky, C. 2009. Matrix Factorization Techniques for Rec-
ommender Systems. Computer 42(8):42–49.
[Lafferty and Blei 2006] Lafferty, J. D., and Blei, D. M.
2006. Correlated topic models. In Advances in neural in-
formation processing systems, 147–154.
[Lee et al. 2013] Lee, J.; Kim, S.; Lebanon, G.; and Singer,
Y. 2013. Local Low-Rank Matrix Approximation. ICML
28.
[Li, Kawale, and Fu 2015] Li, S.; Kawale, J.; and Fu, Y.
2015. Deep collaborative ﬁltering via marginalized denois-
ing auto-encoder. In Proceedings of the 24th ACM Interna-

2016.

Figure 11: Graphical model representation of NIPEN-PGM

contents rather than network effect. However, since the the
number of element that |βu| > 0.2 is larger than the number
of |αu| > 0.2, we can infer that small number of legislators
are highly dependent on network effect. In addition, Figure
11 shows the change in a |αu/βu| over time, and we can in-
fer that the inﬂuence of contents over networks has become
more important in recent years.

References
[Abadi et al. 2016] Abadi, M.; Agarwal, A.; Barham, P.;
Brevdo, E.; Chen, Z.; Citro, C.; Corrado, G. S.; Davis, A.;
Dean, J.; Devin, M.; and Others. 2016. Tensorﬂow: Large-
scale machine learning on heterogeneous distributed sys-
tems. arXiv preprint arXiv:1603.04467.
[Bertero et al. 2016] Bertero, D.; Siddique, F. B.; Wu, C.-S.;
Wan, Y.; Chan, R. H. Y.; and Fung, P. 2016. Real-Time
Speech Emotion and Sentiment Recognition for Interactive
Dialogue Systems. ACL.
[Blei, Ng, and Jordan 2003] Blei, D. M.; Ng, A. Y.; and Jor-
dan, M. I. 2003. Latent Dirichlet Allocation. The Journal of
Machine Learning Research 3:993–1022.
[Chaney, Blei, and Eliassi-Rad 2015] Chaney, A. J.; Blei,
D. M.; and Eliassi-Rad, T. 2015. A probabilistic model for
using social networks in personalized item recommendation.
Proceedings of the 9th ACM Conference on Recommender
Systems 43–50.
[Chen et al. 2012] Chen, M.; Xu, Z.; Weinberger, K.; and
Sha, F. 2012. Marginalized Denoising Autoencoders for
Domain Adaptation. Proceedings of the 29th International
Conference on Machine Learning (ICML) 767—-774.
[Chong et al. 2017] Chong, A. Y. L.; Ch’ng, E.; Liu, M. J.;
and Li, B. 2017. Predicting consumer product demands via
Big Data: the roles of online promotional marketing and on-
line reviews. International Journal of Production Research
55(17):5142–5156.
[Clinton, Jackman, and Rivers 2004] Clinton, J. D.; Jack-
man, S.; and Rivers, D. 2004. The Statistical Analysis

tional on Conference on Information and Knowledge Man-
agement, 811–820. ACM.
[Poole and Rosenthal 1985] Poole, K. T., and Rosenthal, H.
1985. A spatial model for legislative roll call analysis. Amer-
ican Journal of Political Science 357–384.
[Ramage et al. 2009] Ramage, D.; Hall, D.; Nallapati, R.;
and Manning, C. D. 2009. Labeled LDA: A supervised
topic model for credit attribution in multi-labeled corpora.
Proceedings of the 2009 Conference on Empirical Methods
in Natural Language Processing 1(August):248–256.
[Sedhain et al. 2015] Sedhain, S.; Menon, A. K.; Sanner, S.;
and Xie, L. 2015. AutoRec : Autoencoders Meet Collabo-
rative Filtering. Proceedings of the 24th International Con-
ference on World Wide Web (WWW) 111–112.
[Shah, Rao, and Ding 2017] Shah, V.; Rao, N.; and Ding, W.
2017. Matrix Factorization with Side and Higher Order In-
formation. arXiv preprint arXiv:1705.02047.
[Socher et al. 2013] Socher, R.; Chen, D.; Manning, C. D.;
and Ng, A. 2013. Reasoning with neural tensor networks
for knowledge base completion. In Advances in neural in-
formation processing systems, 926–934.
[Vincent et al. 2010] Vincent, P.; Larochelle, H.; Lajoie, I.;
Bengio, Y.; and Manzagol, P.-A. 2010. Stacked Denoising
Autoencoders: Learning Useful Representations in a Deep
Network with a Local Denoising Criterion. Journal of Ma-
chine Learning Research 11:3371–3408.
[Wang and Blei 2011] Wang, C., and Blei, D. M. 2011. Col-
laborative topic modeling for recommending scientiﬁc arti-
cles. In Proceedings of the 17th ACM SIGKDD international
conference on Knowledge discovery and data mining, 448–
456. ACM.
[Wang, Shi, and Yeung 2017] Wang, H.; Shi, X.; and Yeung,
D.-y. 2017. Relational Deep Learning : A Deep Latent Vari-
able Model for Link Prediction. AAAI.
[Wang, Wang, and Yeung 2015] Wang, H.; Wang, N.; and
Yeung, D.-Y. 2015. Collaborative Deep Learning for Rec-
ommender Systems. KDD 1235–1244.
[Wu et al. 2016] Wu, Y.; DuBois, C.; Zheng, A. X.; and Es-
ter, M. 2016. Collaborative Denoising Auto-Encoders for
Top-N Recommender Systems. Proceedings of the Ninth
ACM International Conference on Web Search and Data
Mining - WSDM ’16 153–162.
[Ying et al. 2016] Ying, H.; Chen, L.; Xiong, Y.; and Wu, J.
2016. Collaborative deep ranking: A hybrid pair-wise rec-
ommendation algorithm with implicit feedback. Paciﬁc-Asia
Conference on Knowledge Discovery and Data Mining 9652
LNAI:555–567.

Neural Ideal Point Estimation Network

Kyungwoo Song, Wonsung Lee, and Il-Chul Moon
Korea Advanced Institute of Science and Technology
291 Daehak-ro, Yuseong-gu
Daejeon 34141, South Korea
{gtshs2,aporia,icmoon}@kaist.ac.kr

9
1
0
2
 
r
p
A
 
6
2
 
 
]
I
S
.
s
c
[
 
 
1
v
7
2
7
1
1
.
4
0
9
1
:
v
i
X
r
a

Abstract

Understanding politics is challenging because the politics
take the inﬂuence from everything. Even we limit ourselves
to the political context in the legislative processes; we need
a better understanding of latent factors, such as legislators,
bills, their ideal points, and their relations. From the mod-
eling perspective, this is difﬁcult 1) because these observa-
tions lie in a high dimension that requires learning on low di-
mensional representations, and 2) because these observations
require complex probabilistic modeling with latent variables
to reﬂect the causalities. This paper presents a new model to
reﬂect and understand this political setting, NIPEN, includ-
ing factors mentioned above in the legislation. We propose
two versions of NIPEN: one is a hybrid model of deep learn-
ing and probabilistic graphical model, and the other model
is a neural tensor model. Our result indicates that NIPEN
successfully learns the manifold of the legislative bill texts,
and NIPEN utilizes the learned low-dimensional latent vari-
ables to increase the prediction performance of legislators’
votings. Additionally, by virtue of being a domain-rich proba-
bilistic model, NIPEN shows the hidden strength of the legis-
lators’ trust network and their various characteristics on cast-
ing votes.

Introduction
Recent developments in machine learning have enabled a
deeper understanding of human behavior in diverse contexts.
These advances include divulging intentions and sentiments
in dialogs (Bertero et al. 2016); predicting purchases from
online markets (Chong et al. 2017); recommending movies
to friends (Shah, Rao, and Ding 2017); and discovering so-
cial network links between individuals (Guo, Zhang, and
Yorke-Smith 2015). The recent machine learning models
provide the contexts of these behaviors, which have been
regarded as the latent aspects of human behavior.

One latent modeling of human behavior can be a form of
complex Bayesian probabilistic models, a.k.a. probabilistic
graphical model (PGM). The modelers used graphical nota-
tions, embedding the probabilistic variables and their causal-
ities, to represent the key factors and their relations. For in-
stance, latent Dirichlet allocation (LDA) models the genera-
tive process of documents, i.e. the composition of topics at

Copyright c(cid:13) 2018, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

large, a main topic of documents, and a word selection when
describing a topic (Blei, Ng, and Jordan 2003).

Another effort in modeling the latent variable is improv-
ing the quality of the latent representation of the data. While
the above probabilistic models focused on the contextual
modeling, the latent variables reside in a high dimensional
and nonlinear space, so the learning of the latent variables
have been limited. For example, the stacked de-noising au-
toencoder (SDAE) (Vincent et al. 2010) learns this mani-
fold space through encoding the noised inputs into the low
dimensional latent representations; and reconstructing the
original inputs with the latent representations with neural
network layers. Further advances have made through casting
this autoencoding mechanism to the variational inference
approaches, and a variational autoencoder (VAE) (Kingma
and Welling 2014) optimizes the variational distribution of
the latent representations with neural networks.

Supported by the two research advances, one distinct re-
search direction has been merging the latent representation
learning and the probabilistic graphical model on human be-
havior. Collaborative deep learning (CDL) (Wang, Wang,
and Yeung 2015) is one example merging SDAE with a
probabilistic model of matrix factorization that often used
to explain and predict the human behavior of recommen-
dations. Whereas CDL gives a clear passway on how we
can further develop various models of human behavior with
support from the deep learning, different application do-
mains require different latent modeling, so the model struc-
ture needs to be further customized and expanded.

This paper introduces Neural Ideal Point Estimation Net-
work (NIPEN) which models the generative process of po-
litical voting by estimating ideal points in diverse legisla-
tive aspects with learning the low dimensional representa-
tions from neural networks. Speciﬁcally, we propose two
versions of NIPEN. The ﬁrst version, NIPEN-PGM is a
hybrid model by representing the contextual causalities as
a PGM, and by learning the low dimensional representa-
tions with multi-layered perceptron (MLP) autoencoders,
i.e. SDAE and VAE. The second version, NIPEN-Tensor, is
a neural tensor model that substitutes the PGM part with the
neural tensor model. NIPEN-Tensor could be viewed as a
generalized version of NIPEN-PGM. NIPEN-Tensor mod-
els the legislative voting with the tensor composition and
the nonlinear operations between diverse legislative factors

Figure 1: The summarized procedure of NIPEN. NIPEN predicts the votes with the combination of contents and network
analyses. We can interpret not only an individual legislator’s ideal points but also trust networks between legislators

while NIPEN-PGM assumes the marginalization and the lin-
earized operation in the same modeling part.

Second, NIPEN is the most comprehensive model in the
latent modeling of the political domain. Assuming that we
model a voting process of legislators, NIPEN is the ﬁrst
model of unifying 1) the voting behavior, 2) the network in-
ﬂuence between congressmen, 3) the political ideal point of
bills and congressmen, 4) the textual topic of bills, and 5) the
relative strength of network inﬂuence and ideal points when
casting a vote. Some of these latent variables have been seen
in other models, (Gerrish and Blei 2012; Gu et al. 2014;
Chaney, Blei, and Eliassi-Rad 2015), but not as the uni-
ﬁed model to depict a whole political picture. Since di-
verse factors, such as the contents of the bill and the hu-
man relations, greatly inﬂuence the voting (Cohen and Mal-
loy 2014), an effective modeling of the legislative voting re-
quires an integrated model, such as NIPEN. We show that
NIPEN recorded signiﬁcant performance improvements in
all metrics compared to existing models. We also show vari-
ous qualitative analyses that can only obtained via this com-
prehensive model. The entire procedures and analyses of
NIPEN is summarized by Figure 1.

Previous Research

Modeling Political Network and Ideal Points

Network analyses and ideal point estimation have been
widely studied in computer science and quantitative polit-
ical science for its importance. In the line of political net-
work analyses, most studies analyzed co-sponsorship data
(Faust and Skvoretz 2002; Fowler 2006). Faust and Skvoretz
(2002) clariﬁed the topological structures in the network of
the U.S. Senate (1973-1974), and they found that the net-
work among U.S. Senator in 93rd Congress is O-star, I-
star and Trans structure (Faust and Skvoretz 2002). Fowler
(2006) inferred the relationship in U.S. Congress (1973-
2004) by measuring the centrality to ﬁnd the most central
legislators (Fowler 2006). In the community of ideal point
estimation, Poole and Rosenthal (1985) proposed a nonl-
inear logit model to account for political choices of legis-
lators (Poole and Rosenthal 1985). However, it was a one-
dimensional estimation, and the analysis could not identify

what the ideal dimension stands for. To overcome the lim-
itation, Clinton et al. (2004) proposed a multi-dimensional
ideal point estimation model, but these models still remained
at the simple logit model extensions (Heckman and Snyder
Jr 1996; Clinton, Jackman, and Rivers 2004).

With the advance of topic modeling, multi-dimensional
ideal point models were developed, and these models pro-
vide more accurate interpretations on the ideal points. Ger-
rish and Blei (2012) proposed an issue-adjusted model (Ger-
rish and Blei 2012) with the labeled LDA (Ramage et al.
2009), and Yupeng et al. (2014) proposed a topic-factorized
ideal point model (TFIPM) (Gu et al. 2014) with probabilis-
tic latent semantic analysis (PLSA) (Hofmann 1999) to esti-
mate the ideal points of legislators based on roll-call data.
Further extensions of TFIPM have made through includ-
ing available domain data. For instance, Islam et al. (2016)
proposed SCIPM by including co-sponsorship networks be-
tween judges in the supreme court (Islam et al. 2016). These
works have remained in the extension of the probabilistic
graphical model without the innovation from the deep learn-
ing community, which our work extends 1) the probabilis-
tic graphical model with variational autoencoders and 2) the
neural tensor model for the causality modeling of the leg-
islative voting.

Collaborative Filtering and Deep Learning
Collaborative Filtering is a recommendation algorithm that
considers the relationship between users and items (Koren,
Bell, and Volinsky 2009). One of representative approach is
a matrix factorization which factorizes the rating matrix as
user latent and item latent factors.Recently, the deep learn-
ing has initiated two theoretic developments. First, the ma-
trix factorization itself is a low-dimensional representation
method because of its latent vector learning, so does the au-
toencoding in the deep learning. For example, Sedhain et
al. (2015) proposed Autorec (Sedhain et al. 2015), a basic
autoencoder based CF algorithm, and Autorec outperforms
other state-of-the-art MF algorithms like LLORMA (Lee et
al. 2013). Wu et al. (2016) expand Autorec by concatenating
a user latent variable to the rating input information in the
encoder part of Autorec (Wu et al. 2016). Li et al. (2015)
adopted two autoencoders corresponding to users and items

(Li, Kawale, and Fu 2015), and they showed the interac-
tion mechanism between the two autoencoders by using the
marginalized SDAE (Chen et al. 2012). Second, the matrix
factorization is related to the low-dimensional feature rep-
resentation by adding the representation of the model as the
distilled version of the side information. For instance, Wang
et al. (2015) proposed a collaborative deep learning (CDL)
which combines SDAE with MF (Wang, Wang, and Yeung
2015). Furthermore, Ying (2016) proposed a model of col-
laborative deep ranking which combines ranking with algo-
rithm and SDAE (Ying et al. 2016). Wang et al. (2017) pro-
posed the relational deep learning with SDAE to link predic-
tion between items (Wang, Shi, and Yeung 2017).

Method
This section introduce the detailed descriptions of NIPEN-
PGM and NIPEN-Tensor in turn. Appendix A formulates
the assumptions and the research questions, and Appendix
C enumerates all symbols in this study.

NIPEN with Probabilistic Graphical Model and
Autoencoders
Figure 2 describes the model structure of NIPEN-PGM. We
start the detailed description from the bill low dimension
modeling part, which is the bill plate with the d ∈ D sub-
script. We apply either VAE or SDAE to learn the low di-
1 with the observed
mensional representation, or topic, of zdk
bill text wdv. zdk can be extracted through the probabilistic
encoder, qφ with parameter φ and decoder, pθ with param-
eter θ which is further described in Appendix B. The topic
representation of bills has two components: the bill latent
ydk and the latent offset ξdk, and we model the combination
of the two component as the below.

ydk = ξdk + zdk,

ξkd ∼ N (0, λ−1
y )

Since the bill itself and the bill text may have two differ-
ent latent variables, ξdk becomes the offset between the bill
latent variable and the bill text latent variable, or topic.

From the deﬁned bill latent ydk, we model how the bill
latent generates the voting observation rud. Here, u ∈ U is
the dimension of the legislators. We assumed that a legislator
cast votes considering three latent factors: the bill latent ydk,
the bill ideal point adk, and the legislators’ ideal point xuk.

adk ∼ N (0, λ−1

u ),

xuk ∼ N (0, λ−1
u )

Now, we deﬁne NIPEN-PGM without the network fac-
tor. This voting procedure is modeled as Eq. (1) where ηd
is a bias value of a legislative bill, and σ is a sigmoid func-
tion. Eq. (1) is designed to increase the probability of vot-
ing YEA when the ideal points of the bill and the legislator
have the same sign; and when an ideal-aligned dimension
of the bill latent variable is high. Additionally, ηd indicates
whether the bill is more broadly accepted or not, regardless
of ideal points.

p(rud = 1) = σ(

ydkadkxuk + ηd)

(1)

K
(cid:88)

k=1

1d, u, and k mean each document, legislator, topic respectively.

Small subscripts indicate the row and column index in order.

Figure 2: Graphical model representation of NIPEN-PGM

Finally, we add the network component to NIPEN-PGM.
The interest of a particular legislative group could be an im-
portant factor in the voting process. Following this impli-
cation, we modeled the network between two legislators as
below. Before the network modeling, we limited the network
inﬂuence between the legislators sharing the same term, and
this neighbor set, Iu, is deﬁned as a neighborhood of legis-
lator, u.

τuu(cid:48) ∼ N (0, λ−1

τ ) αu ∼ N (0, λ−1

α ) βu ∼ N (0, λ−1
α )
The legislator u’s voting is affected by two terms. The ﬁrst
term is the ideal alignment modeled in Eq. (1). The second
term is the voting record of the neighbor legislator, ru(cid:48)d, and
the second term is also weighted by the network strength,
τuu(cid:48), between the two legislators. Since this is a linear sum-
mation, τuu(cid:48) will model the degree of voting agreement be-
tween two legislators. These two terms are uniﬁed with scal-
ing parameters αu and βu. The purpose of modeling αu and
βu is analyzing whether a certain legislator is inﬂuenced
more either from the bill or from the network in casting
votes.

Eq. 2 is the overall voting formulation of NIPEN-PGM.

p(rud = 1) = σ(αu(

ydkadkxuk + ηd)

+ βu(

τuu(cid:48)ru(cid:48)d))

(2)

(cid:88)

k
(cid:88)

u(cid:48)∈Iu

NIPEN with Neural Tensor Model
Existing models, including NIPEN-PGM, do not directly
model the relationships between the topics, which means
that there is no cross-operiation between the dimension of
K. Some cases, i.e. correlated topic model (Lafferty and Blei
2006), model the correlation between topics via the logistic
normal distribution, but this is not an operation modeling of
topic inﬂuences, rather the variable modeling of topic co-
variance.

The recent introduction of neural tensor models (Socher
et al. 2013) enable the cross-operations between the latent

topic dimension. This topic cross-operation can model the
legislator’s ideal point non-linear inﬂuences when two top-
ics are combined within a bill. Here, we propose NIPEN-
Tensor to incorporate the cross-topic inﬂuence in casting a
vote, which could not be modeled in NIPEN-PGM. NIPEN-
Tensor and NIPEN-PGM are similar in the parts of docu-
ment and inﬂuence network modeling. The only different
part is the voting decision modeled as Eq. 2 which multiplies
the factors per a topic and marginalizes. NIPEN-Tensor con-
siders that the multiplication per a topic should be changed
to consider the nonlinear effect from the topic set, not a sin-
gle topic. Therefore, we represent the previous topic-wise
multiplcaiton of ydkadkxuk as a tensor E, and this tensor
still treats the topic dimension to be independent. Then, we
apply a fully-connected layer to cross-operate the topic di-
mension of E, and the neural network has C that is the out-
put of the cross-operation. The overall structure and formu-
lation for the NIPEN-Tensor are shown in Figure 3 and Eq.
3, respectively.

Eudk = xukydkzdk
(cid:88)

(cid:101)Eudl = tanh(

k

EudkW (T1)

kl + b(T1)

l

)

Cud =

(cid:101)EudlW (T2)

l1 + ηd

(cid:88)

k
(cid:88)

u(cid:48)∈U

Nud =

τuu(cid:48)vu(cid:48)d

(3)

W (T1), b(T1), W (T2) are weights and biases applied to Eudk,
(cid:101)Eudl tensor. In particular, W (T1) ∈ RK×K models the cor-
relation between topics, and W (T2) ∈ RK×1 models the
inﬂuence of each topic on the voting. Since the signs of
xuk, ydk, and adk are important, we use tanh instead of
ReLU (Rectiﬁed linear unit) to transform the outputs non-
linearly.

Parameter Inference of NIPEN

The parameters of both NIPENs are enumerated in the pre-
vious section, and we learn the parameters in two folds:
learning the autoencoder to represent the bill topic and
the CF, alternatively. The ﬁrst set of parameters related
to autoencoders is ψ(1) = (θ, φ); and the second set
of parameters related with the legislative-CF is ψ(2) =
(y, a, η, x, W (T1), W (T2), b(T1), τ, α, β).

The overall inference algorithm of both NIPENs fol-
lows the maximization of variational evidence lower bound
with two assumptions. Following CDL, the ﬁrst assump-
tion is connecting the autoencoder and CF through ξ, and
the strength is controlled by the variance of ξ, which is λy.
When learning ψ(1), we apply the stochastic gradient varia-
tional Bayes (SGVB) estimator.

Second, we assumed that the variational distribution of
ψ(2) as a point mass for simplicity, so the parameters of
the variational distribution are updated by each casted vote

Figure 3: Neural network view of NIPEN-Tensor. The con-
tents part is connected with the blue line (with content scal-
ing parameter αu ), and the network part is connected with
the purple line (with the network scaling parameter βu ).

record, which is traditional Bayesian belief updates. Speciﬁ-
cally, the likelihood of the posterior is presented as the lower
bound in the below. Then, the lower bound, which has real-
ized values of qφ(z|w), pθ(z) and an observed input, has
only ψ(2), so the gradient method can ﬁnd the maximum a-
posteriori, or MAP, of ψ(2).

As a summary, the objective function of both NIPENs is

LN IP EN = −DKL(qφ(z|w)(cid:107)pθ(z)) +

log pθ(w|zl)

1
L

L
(cid:88)

l=1

+

+

−

λf
2

λf
2

λy
2

(cid:88)

(u,d),rud(cid:54)=0
(cid:88)

(u,d),rud(cid:54)=0

1 + rud
2

1 − rud
2

log p(rud = 1)

log p(rud = −1)

D
(cid:88)

d=1

(cid:107)yd − zd(cid:107)2

2 −

((cid:107)a(cid:107)2

F + (cid:107)x(cid:107)2
F )

λu
2

−

λτ
2

F ) −

((cid:107)τ (cid:107)2

((cid:107)α(cid:107)2

2 + (cid:107)β(cid:107)2
2)

λα
2
Similar to (Wang and Blei 2011; Wang, Wang, and Yeung
2015), the parameters related with the autoencoder and the
legislative-CF are infered by coordinate ascents which maxi-
mizes LN IP EN . For legislative-CF related parameters ψ(2),
we take the gradient of LN IP EN w.r.t each parameters given
the current θ and φ. Given the legislative-CF related param-
eters ψ(2), we infer the autoencoder related parameters by
computing ∇ψ(1)LN IP EN . We utilized the Tensorﬂow li-
brary (Abadi et al. 2016) to optimize the parameters.

NIPEN-PGM and NIPEN-Tensor are only different in the
vote casting process, and the related term in the objective
function is the third and the fourth terms with log p(rud =
1). These terms could be computed as the conventional gra-
dient descent in two variants of NIPEN, so there is no change

p(rud = 1) = σ(αuCud + βu

Nu(cid:48)d)

speciﬁed as follows:

(cid:88)

u(cid:48)∈Iu

in the learning mechanism.

In the original deﬁnition, the network, τ , is a |U |-by-|U |
matrix, and the number of parameters becomes large given
O(U 2). To reduce the squared complexity, τ is approxi-
mated by the product of (cid:101)τ1 and (cid:101)τ2 where (cid:101)τ1 ∈ RU ×G, (cid:101)τ2
∈ RG×U . We assume that (cid:101)τ1 and (cid:101)τ2 are not related. G can
be interpreted as the number of groups containing the legis-
lators. This approximation results in O(GU ) for the network
parameter inference.

Table 1: Attributes of Politic2013 and Politic2016 dataset

# of legislators (|U |)
# of bills (|D|)
# of votings (|D|)
# of House
# of Senator
# of Republican
# of Democrat
# of unique word (|V |)

Average # of unique word
(cid:80)
d,v(Iwdv >0)
for each bill (

)

V

# of bills less than
10 unique words
Period
Source
Data type

Politic2013
1,540
7,162
2,779,703
1,299
241
767
767
10,000

Politic2016
1,537
7,975
2,999,844
1,266
271
778
752
13,581

192.77

378.66

65

0

1990-2013
THOMAS

1989-2016
GovTrack

1 (YEA), -1 (NAY)

Results

Datasets on Political Ideal Points
We used two roll-call datasets, whose source is explained in
Appendix D. Table 1 provides the descriptive statistics of the
two datasets: Politic2013 and Politic2016. Politic2013 limits
the number of a unique word to 10,000, and there are 65 bills
which have less than ten words, while Politic2016 chooses
13,581 unique words, and there are no bills with less than ten
words. Politic2013 is a more sparse dataset than Politic2016
in the ratings and the vocabulary sizes.

Baselines and Implementation Details
The variations of NIPEN were compared to ﬁve baseline
models as follows:
• TFIPM: Topic Factorized Ideal Point estimation Model
(Gu et al. 2014) is specialized in politics to analyze the
roll-call data.

• Autorec: A simple autoencoder model which is utilized to
predict the ratings. Autorec (Sedhain et al. 2015) encodes
and reconstructs the rating matrix. We used Item-based
Autorec.

• Trust SVD: Trust SVD (Guo, Zhang, and Yorke-Smith
2015), a type of trust-based matrix factorizations, is built
on SVD++ with trust information.

• CDAE: Collaborative Denoising Autoencoder (Wu et al.
2016) used a denoising autoencoder with user latent vari-
ables.

• CDL: Collaborative Deep Learning (Wang, Wang, and
Yeung 2015) used the deep learning and the CF, jointly.
CDL improves performance by using document informa-
tion additionally, and CDL uses SDAE to learn document
manifold.
Appendix E provides detailed speciﬁcations for replica-
tions of this work, and Appendix F illustrates the sensitivity
analysis of λy and λτ .

Quantitative Evaluations
We performed the ﬁve-fold cross-validation to quantita-
tively evaluate the variations of NIPENs, and the perfor-
mance measures are RMSE, MAE, accuracy, and nega-
tive average log-likelihood (NALL) measures. We compared
nine models: ﬁve baseline models in section 4.2, and four
NIPEN variations, which are NIPEN-PGM(SDAE), NIPEN-
PGM(VAE,approx.), NIPEN-PGM(VAE), and NIPEN-
Tensor. NIPEN-PGM has three variants by choosing either
SDAE or VAE as the autoencoder for the text modeling, and
by choosing either using the whole matrix for the inﬂuence
or the low-rank approximated matrix of the inﬂuence.

Table 2 statistically conﬁrms that the best performance
model in every metric is always a variation of NIPEN, which
is conﬁrmed with statistical signiﬁcance. In detail, ﬁrst,
we compare NIPEN-PGM(VAE) and NIPEN-PGM(SDAE),
and their performance gap is larger in Politic2013 than in
Politic2016 which is a relatively sparse setting as shown
in Table 1. We conjecture that NIPEN-PGM(VAE) is bet-
ter in handling the sparse dataset than NIPEN-PGM(SDAE).
Second, NIPEN-Tensor is a model that considers the cor-
relation between topics, and NIPEN-Tensor may have a
better performance when a bill text has multiple topics
with complex and rich textual information. As discussed
in Section Datasets on Political Ideal Points, Politic2016
has richer textual information than Politic2013, and we con-
jecture that this is the reason why NIPEN-PGM(VAE) in
Politic2013 and NIPEN-Tensor in Politic2016 show better
performances. Third, while the accuracy improvement is rel-
atively small, the improvements on other metrics, partic-
ularly RMSE and MAE, are relatively large. Already, the
baseline models achieve the accuracy higher than 95%, so
the accuracy improvement could seem minimal. However,
our likelihood estimation of YEA and NAY is considerably
improved given the RMSE and the MAE improvement.

Qualitative Evaluations
In addition to the quantitative results, we interpret the latent
variables of NIPEN-PGM(VAE) on Politic2016. First, to
comprehend the dataset and the qualitative results, we com-
puted the word-topic matrix from well-learned VAE vari-
ables, ψ1, as shown in Table 3. This table provides a snap-
shot of topics in the bills. Then, we relate this topic to the bill
ideal points, adk. The latent dimension, k, becomes the com-
mon dimension of an ideal point value and a topic weight
for each topic in the bill. Figure 5 shows an example of the
topic weight as the bar chart and the ideal point value as the
line chart. The illustrated bill, or H.Res.794 (114th), has the
largest absolute value, |adk(cid:101)zdk| in a ’Business and Finance’
topic where (cid:101)zdk denotes the normalized zdk.

Table 2: Quantitative evaluation on Politic2013 and Politic2016 datasets. Two-standard deviation is shown in parentheses

Politic2013

Politic2016

RMSE
0.2253
(±0.0007)
0.2110
(±0.0099)
0.2059
(±0.0007)
0.1872
(±0.0002)
0.1834†
(±0.0008)
0.1801**
(±0.0014)

MAE
0.1399
(±0.0011)
0.0975
(±0.0136)
0.0831
(±0.0009)
0.0682†
(±0.0002)
0.0786
(±0.0019)
0.0591**
(±0.0012)

Accuracy
0.9408
(±0.0003)
0.9411
(±0.0056)
0.9428
(±0.0006)
0.9526
(±0.0003)
0.9554†
(±0.0004)
0.9566**
(±0.0006)

NALL
0.1866
(±0.0011)
0.1466
(±0.0177)
0.1450
(±0.0009)
0.1213
(±0.0007)
0.1147†
(±0.0018)
0.1155
(±0.0018)

RMSE
0.2168
(±0.0011)
0.2031
(±0.0015)
0.1977
(±0.0037)
0.1794
(±0.0010)
0.1780†
(±0.0013)
0.1779
(±0.0005)

MAE
0.1353
(±0.0010)
0.0886
(±0.0110)
0.0802
(±0.0052)
0.0625†
(±0.0006)
0.0769
(±0.0012)
0.0560**
(±0.0004)

Accuracy
0.9463
(±0.0009)
0.9454
(±0.0007)
0.9475
(±0.0023)
0.9566
(±0.0005)
0.9583†
(±0.0008)
0.9581
(±0.0003)

NALL
0.1782
(±0.0015)
0.1349
(±0.0125)
0.1357
(±0.0046)
0.1121
(±0.0016)
0.1106†
(±0.0017)
0.1173
(±0.0015)

0.1804
(±0.0089)

0.0611*
(±0.0065)

0.9565
(±0.0047)

0.1165
(±0.0086)

0.1791
(±0.0076)

0.0599
(±0.0057)

0.9571
(±0.0039)

0.1152
(±0.0070)

0.1753**
(±0.0007)
0.1818**
(±0.0008)
4.41%

0.0588**
(±0.0008)
0.0663**
(±0.0003)
13.78%

0.9587**
(±0.0006)
0.9556**
(±0.0003)
0.35%

0.1075**
(±0.0011)
0.1155
(±0.0020)
6.27%

0.1753**
(±0.0017)
0.1729**
(±0.0015)
2.87%

0.0570**
(±0.0012)
0.0608**
(±0.0006)
10.40%

0.9590**
(±0.0010)
0.9600**
(±0.0008)
0.18%

0.1112
(±0.0024)
0.1057**
(±0.0022)
4.43%

Trust SVD

Autorec

CDAE

TFIPM

CDL

NIPEN-
PGM(SDAE)
NIPEN-
PGM(VAE,
approx.)
NIPEN-
PGM(VAE)
NIPEN-
Tensor
Improvement

NALL : Negative Average Log Likelihood
Improvement : Relative improvement of the best version of NIPEN compared to the best model, which is marked by †, among the baselines
P ∗ < 0.05; P ∗∗ < 0.01 (Student’s one-tailed t-test against the † model)

Table 3: Selected top-ﬁve words for each topic. The number
of listed topics was set to ten.

Topic Label
Business and
Finance
Disasters
Management
International
Relationship

Racism

Defense

Agriculture

Social

Health

Foregin

1

2

3

4

5

6

7

8

9

International
Trade

10

Topic Words
Forproﬁt, Nonrefundable, Govern,
SBDC, Financings
Stabilization, Homeless, Disasters,
Alerts, USPS
Kuwait, Distributes, Lawsuits,
Threatens, Spain
Contrary, Black, Compared,
Tuskegee, Reagan
United, Soviet, Antiterrorist, IDA,
NGA
Pima, Climate, Cropland, Bush,
Badlands
Contribute, Donors, Childcare,
Resettlement, DRR
FEHBP, Heroin, Stability,
Musculoskeletal, Transplantation
Agency, Lantos, FPI, fusion,
division
Clearinghouses, ESF,
Discrepancies, Repay, Charging

Figure 4: Individual legislators’ ideal points for each topic

This bill ideal point is correlated with the legislator ideal
point, xuk, to generate the vote records. Here, the dimen-
sion, k, is the same latent dimension of the topic in Table
3, and we provide the scatter plot of the legislators’ ideal
points per topic in the Figure 4. The prior mentioned bill
(H.Res.794 (114th)) considers the appropriations for ﬁnan-
cial services and general government, and the major topic is
Business and Finance, and the bill ideal point in Business
and Finance is -1.217. Together, the vote casting will be de-
termined by the legislators’ view on Business and Finance,
and this topic shows the greatest disagreement between the
Republicans and the Democrats according to the Figure 4. In
the real world, the voting results were same as expected: 1)
the voting was very partisan, 92.2% Republican voted YEA

Figure 5: Topic proportion and ideal points of H.Res.794
(114th) bill

Table 4: Top-ﬁve legislators who are affected by contents or
network factors a lot. The scaling variable (αu for contents
based, and βu for network based), political party, and district
of the member are indicated in parentheses.

Contents based
Ron Paul
(0.260, R, TX)
Virgil H. Goode
(0.220, R, VA)
Dennis J. Kucinich
(0.218, D, OH)
Henry Cuellar
(0.198, D, TX)
Walter B. Jones
(0.195, R, NC)

1

2

3

4

5

Network based
Ralph M. Hall
(0.304, R, TX)
Nick J. Rahall II
(0.250, D, WV)
Peter A. DeFazio
(0.247, D, OR)
Don Young
(0.228, R, AK)
Jim Sensenbrenner.
(0.227, R, WI)

action between the contents and the network parts. We
used two scaling variables αu and βu, which controls the
strengths of contents factor and network factor, respectively.
Table 4 shows the top-ﬁve legislators who were affected by
either contents or network factors. Since the variations of
NIPEN is an integrated model of network modeling as well
as the textual bill modeling, the NIPENs should better per-
form than the baseline models, i.e. CDL, which only models
the texts, and Figure 7 conﬁrms this hypothesis.

Figure 6: Trust network between legislators

and the 90.3% Democrat voted NAY.

The second qualitative interpretation focuses on the legis-
lators’ network. We selected 12 legislators who have either
strongly positive or negative relationships with each other,
shown in the Figure 6. In general, the legislators have a
strong positive relationship when they have the same dis-
trict and the party. Among the top-ﬁve positive relation-
ships, four of them have the same party and the same dis-
trict, i.e. ’Thomas E. Petri↔Jim Sensenbrenner’, ’Nick J.
Rahall II→Robert E. Wise’, and ’Nick J. Rahall II→Alan B.
Mollohan’2. The closest relations are ’Thomas E. Petri’ and
’Jim Sensenbrenner’. They were both republican representa-
tives from Wisconsin, and they share similar voting patterns.
They have voted 6,288 times for the same bill, and the 5,764
votes were same (91.6%). Especially, they voted NAY for
H.R.730 (111th) which is a ”suspension of the rules”, and
397 legislators votes YEA. For H.R.6063 (110th), ’Thomas
E. Petri’ and ’Jim Sensenbrenner’ voted NAY together while
94.4% legislators voted YEA. We report further analyses in
Appendix G.

The third qualitative analysis concentrates on the inter-

2τuu is asymmetric matrix. arrow(’→’) indicates the direction

of the trust

Figure 7: Accuracy of top ﬁve legislators who are affected
by network factor

Conclusion

We proposed two versions of machine learning models,
NIPEN-PGM and NIPEN-Tensor, to analyze the ideaology
in the legislation process. The variations of NIPEN show the
state-of-the-art performance in all measures on Politic2013
and Politic2016. Furthermore, NIPEN provides various in-
terpretations in why YEA or NAY is casted by illustrating 1)
the ideal point estimation of individual legislators and bills;
2) the trust network between legislators; and 3) the content
and network inﬂuence for each legislator. These supervised
and unsupervised tasks could be critical insights into quan-
titatively understanding politics in the legislative process.

Appendix A. Problem Formulation

In general, the inﬂuence on legislative voting originates from
1) the individual ideal points of the legislator, 2) the contents
of the bill, and 3) the interests of a political group that a leg-
islator belongs to. We operationalize these inﬂuence struc-
ture as the concepts deﬁned in the below.

Deﬁnition 1. Ideal point is a measure of legislator’s prefer-
ence for each topic when we have K topics in our bill texts.
The ideal point for a particular topic k of a particular mem-
ber u is represented by xuk, and it follows N (0, λ−1
u ). The
sign of xuk represents the preferred voting direction (posi-
tive or negative), and the size of |xuk| represents the pref-
erence strength. The ideal point for a particular topic k of a
particular bill d is represented by adk, and its distribution is
N (0, λ−1
u ). The interprestation of adk is same as xuk.

Deﬁnition 2. Contents refer to the bill elements, i.e. text
descriptions, which affect the voting result. The latent repre-
sentation of the contents is ydk which is the addition of zdk,
the topic of the bill; and ξdk, the deviation of the bill from
the topic of the bill text.

Deﬁnition 3. Network means the collection of relationships
between legislators whose vote affect the other’s vote. The
strength of network relationships is modeled as τuu(cid:48), which
follows N (0, λ−1
τ ). The sign of τuu(cid:48) indicates the voting
alignment between u and u(cid:48) legislators, and |τuu(cid:48)| means
its alignment strength. This study assumes that the network
relationships are asymmetric bidirectional, and only the leg-
islators in the same term affect each other.

Deﬁnition 4. Scaling parameters mean the inﬂuence of
contents and networks when a legislator votes. αu is a con-
tent scaling parameter, and βu is a network scaling parame-
ter. Each scaling parameter is a |U |-dimensional vector, fol-
lowed by N (0, λ−1
α ). This study assumed that the degree of
inﬂuence on the contents and the network would be different
per each legislator.

Now, given the above deﬁned concepts, we enumerates

the research questions to test with NIPEN.

Problem 1. NIPEN can predict the results of the voting by
inferring the bill topic, the bill ideal points, the legislator
ideal points, and the network relationships between the leg-
islators.

Problem 2. NIPEN provides the interpretation on the vot-
ing results of the bill. For example, NIPEN illustrates the
interpretable latent information from the bill topic, the bill
ideal point, and the legislator ideal point taking into account
the correlation between the topics.

Problem 3. NIPEN can 1) analyze the trust between legis-
lators (individual unit), and 2) the trust network comparison
between parties (group unit).

Problem 4. NIPEN provides the behavioral analyses on leg-
islators from the voting motivation perspective, which could
be motivated by either legislator ideal point or network rela-
tionship.

Appendix B. Document Modeling
Autoencoders

Appendix B.1. Variational Autoencoder (VAE)
NIPEN extracts the topics of the legislative bills with
VAE (Kingma and Welling 2014) which is a type of
deep generative model. VAE learns the disentangled and
low-dimensional representation of high dimensional data
through the probabilistic encoding, or qφ(z|w); and the
probabilistic decoding, or pθ(w|z). Therefore, the original
objective function of VAE is composed of the linear sum of
corresponding two terms. The ﬁrst term originating from the
encoding is the KL divergence between the probabilistic en-
coding and the prior for latent variable, or pθ(z); and this
term enforces the regularization. The second term is the ex-
pectation on the negative reconstruction error, and this term
is related to the decoding part. By putting both terms to-
gether, the objective function follows as Eq. (4).

L(θ, φ) = −DKL(qφ(z|w)(cid:107)pθ(z)) + Eqφ[log pθ(w|z)]

(4)
Given the high variance over φ, a direct optimization of
Eq. (4) is not efﬁcient. Hence, Kingma and Welling (2014)
suggested the re-parametrization trick as follows: 1) Draw
(cid:15)l ∼ N (0, I), and 2) Optimize the mean and standard devi-
ation of qφ(z|w), and 3) Compute zl = µ(w) + σ(w) (cid:12) (cid:15)l.
From the trick, the objective function of VAE is turned into
Eq. (5) where L is the number of samples.

(cid:101)L(θ, φ) = −DKL(qφ(z|w)(cid:107)pθ(z)) +

log pθ(w|zl)

1
L

L
(cid:88)

l=1

(5)

Appendix B.2. Stacked Denoising Autoencoder
(SDAE)
NIPEN-PGM(SDAE) extracts the topics of the legislative
bills with SDAE (Vincent et al. 2010). SDAE learns the
disentangled latent feature through the encoding and decod-
ing with bottleneck and corrupted input. SDAE use the cor-
rupted input wc instead of the original input w to force
the relationship learning. The SDAE is optimized for the
purpose of reconstructing the w resulting from the encod-
ing process(fe) through the encoder weight (W (e)) and the
decodingfd result through the decoder weight (W (d)). The
objective function follws as Eq. (6)

(cid:13)
(cid:13)
2
(cid:13)fd(fe(w, W (e)), W (d)) − wc)
(cid:13)
(cid:13)
(cid:13)
2

(6)

Appendix C. Notations

Table 5 summarizes all symbols used in this study.

Appendix D. Dataset Descriptions

is Politic2013, and it was collected
The ﬁrst dataset
from THOMAS3, and (Gu et al. 2014). For an additional
experiment, and for more up-to-date analyses, we col-
lected a new roll-call dataset, Politic2016 from GovTrack

3http://thomas.loc.gov/home/rollcallvotes.html

Table 5: Notation description

Symbol
D
V
U (= U (cid:48))
K
G
Iu
wdv
zdk
ydk
adk
ηd
rud
xuk
αu
βu
τuu(cid:48)
(cid:101)τ1, (cid:101)τ2
ξ
(cid:15)
φ(θ)
C(N )
E
W (T ), b(T )

Description
Set of bills
Set of Unique words
Set of legislators
Set of topics
Rank of (cid:101)τ1 and (cid:101)τ2
Other legislators within the same term as u
Frequency of vth token in document d
Topic proportion for each bill and topic
Bill latent vector
Ideal point for each bill and topic
Constant offset for each bill d
Voting record from legislator u to bill d
Ideal point for each legislator and topic
Contents scaling parameter for legislator u
Network scaling parameter for legislator u
Trust network between legislator u and u(cid:48)
Approximated matrix of τuu(cid:48)
Latent offset between zdk and ydk
Random noise vector drawn from N (0, I)
Parameter of encoder (decoder) in VAE
Contents (Network) information
The tensor combined with xuk, ydk, adk
Neural tensor network parameter

.GovTrack provides raw roll-call data, so we processed
the expanded part of Politic2016, manually. For the re-
search community, we released the code and dataset on
https://github.com/gtshs2/NIPEN

Appendix E. Experiment Settings
For TFIPM, we followed the optimal parameters that the au-
thor reported. We set the latent dimension(K), the trade-off
weight, and the regularization weight as 10, 0.8, and 22.4,
respectively. The latent dimension of CDL and NIPENs was
set to ten, equally. For Autorec, the optimal number of the
latent dimension and the regularization parameter are 100
and 0.001, respectively. Trust SVD shows the best perfor-
mance when the weights of CF and trust part are 1,000 and
0.001, respectively, while K is set to 10. For CDAE, we
set the regularization weight, the corruption ratio, and the
number of latent dimension as 0.001, 0.4, and 50, respec-
tively; and the encoder and the decoder activation functions
are sigmoid. For CDL, we ﬁnd that the optimal parameters
of λu,λv,λw,λn, the dropout rate and the activation func-
tions are 0.01, 100, 1, 100, 0.1 and the sigmoid function, re-
spectively. The neural network structure of Autorec, CDAE,
CDL, NIPENs are set to [512,128,K,128,512], equally. Fi-
nally, we set the parameters of NIPENs such as λf = 10,
λy = 10, λu = 0.1, λτ = 1, λα = 1, λn = 1000 G = 3, and
we performed grid searches to ﬁnd the optimized parameters
of NIPENs. Finally, NIPEN-Tensor has the two-layered ten-
sor E in the topic axis.

Appendix F. Hyperparameter Study
This quantitative improvement requires a well-tuned hyper-
parameter setting, illustrated in Figure 8. LN IP EN enumer-
ates multiple hyperparameters, and we found that λy and λτ
are the most important parameters to decide. λy speciﬁes the
causality strength from the bill text latent in VAE to the bill
latent in the legislative CF. The low value of λy will sepa-
rate VAE and CF, but its high value will disrupt the manifold
learning of VAE. Moreover, λτ speciﬁes the regularization
strength from the legislators’ network inﬂuence to the vot-
ing. The small value of λτ will overﬁt the network inﬂuence,
and its large value will limit the learning of network inﬂu-
ence model in CF.

Figure 8: (Top-Left) Accuracy for λy and λτ value, (Top-
Right) RMSE for each λy and λτ value, (Bottom-Left) Ac-
curacy for G value, (Bottom-Right) RMSE for each G value

Appendix G. Results in Network Inﬂuence
Analyses
To examine the network relationships within each party, Fig-
ure 9 illustrates the trust network parameter. A red node rep-
resents a Republican; a blue node stands for a Democrat;
a green solid line indicates an inferred close relationship;
and a purple dotted line indicates an inferred unfriendly re-
lationship. Taking a threshold at 0.1 and looking at τuu(cid:48) with
values greater than 0.1 and less than -0.1 (Figure 9d), John
J. Duncan Jr and Dana Rohrabacher have the greatest net-
work impact given their number of connected legislators in
the Republican party. The commonalities between the two
inﬂuential legislators are 1) being a member of the House of
Representatives; and 2) having been politically active for a
long time (Duncan started as a congressman in Tennessee in
1988 and Laura Baker as a California congressman in 1989.
Especially, Jimmy Duncan is the House’s longest-serving
Republicans.).

We compared and contrasted the network structure of Re-
publicans and Democrats. As shown in Table 6, the network
inﬂuence among the total members is greater in the Demo-
cratic Party given its mean value of |τuu(cid:48)|. However, the Re-

publican party has the higher number of inﬂuential legisla-
tors when we limit the network inﬂuence with thresholds,
i.e. when we limit |τuu(cid:48)| > 0.05 or |τuu(cid:48)| > 0.1 in Table 6.
This suggests that the Democrats have averagely higher and
more equal inﬂuences between the members while the Re-
publicans have a number of authorative inﬂuencers among
the members.

(a) Threshold = 0.03

(b) Threshold = 0.05

Table 6: Comparison of network inﬂuence by each Party

# of pair s.t. τuu(cid:48) > 0.05
# of pair s.t. τuu(cid:48) < −0.05
# of pair s.t. τuu(cid:48) > 0.1
# of pair s.t. τuu(cid:48) < −0.1
Mean of |τuu(cid:48)|
Variance of |τuu(cid:48)|

Republican
58
67
7
3
9.0E-04
2.49E-05

Democratic
49
53
1
3
0.0018
3.38E-05

Table 7: Content and Network scale comparison between the
Party. Average Ranking@K is the average of the ranking of
each legislator, by the party, when the ranking is made up to
the top K legislators, based on scaling parameter (αu βu).

Content (|αu|)

Network (|βu|)

R
6
40
52.87
774.6
0.149

NL@10
NL@100
AR@100
AR@All
Mean value of αu (βu)
R : Republican Party / D : Democratic Party
AR@K : Average Ranking at top K
NL@K : Number of legislators at top K

D
4
60
48.91
762.7
0.148

R
6
42
46
781.4
0.068

D
4
58
53.75
754.9
0.064

Republican Party generally relies on the network, and the
Democratic Party on contents, when they are voting. If we
associate this conclusion with Table 6, we can explain that
a Democratic have more inﬂuence in the network within the
party. However, the proportion of people who are dependent
on the network (including network from their own party and
opposing party) is relatively high in the Republican Party.

(c) Threshold = 0.07

(d) Threshold = 0.1

Figure 9: Network inﬂuence visualization within each party
in December 2016. The top visualizations represent the Re-
publican Party, and the bottom visualizations represent the
Democratic Party. If the network inﬂuence, τuu(cid:48), between
two legislators exceeds the threshold, the relationship is ex-
pressed as a green solid line. If the network inﬂuence, τuu(cid:48),
is less than the threshold, the relationship is noted as a purple
dotted line.

The United States has a two-party system. In order to an-
alyze this reality effectively, contents scaling parameter and
network scaling parameter are analyzed by each party. Com-
paring the mean value of |αu| and |βu| in the Table 7, we
can see that both parties are generally voting rather than net-
works, concentrating on their own politics and the contents
of the bill itself. To compare two political parties relative to
each other based on Average Ranking@100 in Table 7, the

Figure 10: Graphical model representation of NIPEN-PGM

According to the opinion of the reviewers who advised
on the analysis of αu and βu, the distribution of |αu| and
|βu| is shown in Figure 10, and the value of |αu|/|βu| over
time is shown in Figure 11. According to Figure 10, we can
infer that the majority of legislators are voting focusing on

of Roll Call Data. The American Political Science Review
98(2):355–370.
[Cohen and Malloy 2014] Cohen, L., and Malloy, C. J. 2014.
Friends in high places. American Economic Journal: Eco-
nomic Policy 6(3):63–91.
[Faust and Skvoretz 2002] Faust, K., and Skvoretz, J. 2002.
Comparing Networks Across Space and Time, Size and
Species. Networks 32(2002):267–299.
[Fowler 2006] Fowler, J. H. 2006. Connecting the congress:
Political Analysis
A study of cosponsorship networks.
14(4):456–487.
[Gerrish and Blei 2012] Gerrish, S., and Blei, D. M. 2012.
How they vote: Issue-adjusted models of legislative behav-
ior. Advances in Neural Information Processing Systems
25(1):2762–2770.
[Gu et al. 2014] Gu, Y.; Sun, Y.; Jiang, N.; Wang, B.; and
Chen, T.
2014. Topic-factorized ideal point estimation
model for legislative voting network. Proceedings of the
20th ACM SIGKDD international conference on Knowledge
discovery and data mining. ACM, 2014. 183–192.
[Guo, Zhang, and Yorke-Smith 2015] Guo, G.; Zhang, J.;
and Yorke-Smith, N. 2015. TrustSVD : Collaborative Fil-
tering with Both the Explicit and Implicit Inﬂuence of User
Trust and of Item Ratings. Proceedings of the Twenty-ninth
AAAI Conference on Artiﬁcial Intelligence (AAAI) 123–129.
[Heckman and Snyder Jr 1996] Heckman, J. J., and Snyder
Jr, J. M. 1996. Linear probability models of the demand
for attributes with an empirical application to estimating the
preferences of legislators. National bureau of economic re-
search 28(0).
[Hofmann 1999] Hofmann, T. 1999. Probabilistic latent se-
mantic indexing. Proceedings of the 22nd annual interna-
tional ACM SIGIR conference on Research and development
in information retrieval 50–57.
[Islam et al. 2016] Islam, M. R.; Hossain, K. T.; Krish-
nan, S.; and Ramakrishnan, N.
Inferring Multi-
dimensional Ideal Points for US Supreme Court Justices.
Proceedings of the 30th Conference on Artiﬁcial Intelligence
(AAAI) 4–12.
[Kingma and Welling 2014] Kingma, D. P., and Welling, M.
2014. Auto-encoding variational bayes. In Proceedings of
the International Conference on Learning Representations
(ICLR).
[Koren, Bell, and Volinsky 2009] Koren, Y.; Bell, R.; and
Volinsky, C. 2009. Matrix Factorization Techniques for Rec-
ommender Systems. Computer 42(8):42–49.
[Lafferty and Blei 2006] Lafferty, J. D., and Blei, D. M.
2006. Correlated topic models. In Advances in neural in-
formation processing systems, 147–154.
[Lee et al. 2013] Lee, J.; Kim, S.; Lebanon, G.; and Singer,
Y. 2013. Local Low-Rank Matrix Approximation. ICML
28.
[Li, Kawale, and Fu 2015] Li, S.; Kawale, J.; and Fu, Y.
2015. Deep collaborative ﬁltering via marginalized denois-
ing auto-encoder. In Proceedings of the 24th ACM Interna-

2016.

Figure 11: Graphical model representation of NIPEN-PGM

contents rather than network effect. However, since the the
number of element that |βu| > 0.2 is larger than the number
of |αu| > 0.2, we can infer that small number of legislators
are highly dependent on network effect. In addition, Figure
11 shows the change in a |αu/βu| over time, and we can in-
fer that the inﬂuence of contents over networks has become
more important in recent years.

References
[Abadi et al. 2016] Abadi, M.; Agarwal, A.; Barham, P.;
Brevdo, E.; Chen, Z.; Citro, C.; Corrado, G. S.; Davis, A.;
Dean, J.; Devin, M.; and Others. 2016. Tensorﬂow: Large-
scale machine learning on heterogeneous distributed sys-
tems. arXiv preprint arXiv:1603.04467.
[Bertero et al. 2016] Bertero, D.; Siddique, F. B.; Wu, C.-S.;
Wan, Y.; Chan, R. H. Y.; and Fung, P. 2016. Real-Time
Speech Emotion and Sentiment Recognition for Interactive
Dialogue Systems. ACL.
[Blei, Ng, and Jordan 2003] Blei, D. M.; Ng, A. Y.; and Jor-
dan, M. I. 2003. Latent Dirichlet Allocation. The Journal of
Machine Learning Research 3:993–1022.
[Chaney, Blei, and Eliassi-Rad 2015] Chaney, A. J.; Blei,
D. M.; and Eliassi-Rad, T. 2015. A probabilistic model for
using social networks in personalized item recommendation.
Proceedings of the 9th ACM Conference on Recommender
Systems 43–50.
[Chen et al. 2012] Chen, M.; Xu, Z.; Weinberger, K.; and
Sha, F. 2012. Marginalized Denoising Autoencoders for
Domain Adaptation. Proceedings of the 29th International
Conference on Machine Learning (ICML) 767—-774.
[Chong et al. 2017] Chong, A. Y. L.; Ch’ng, E.; Liu, M. J.;
and Li, B. 2017. Predicting consumer product demands via
Big Data: the roles of online promotional marketing and on-
line reviews. International Journal of Production Research
55(17):5142–5156.
[Clinton, Jackman, and Rivers 2004] Clinton, J. D.; Jack-
man, S.; and Rivers, D. 2004. The Statistical Analysis

tional on Conference on Information and Knowledge Man-
agement, 811–820. ACM.
[Poole and Rosenthal 1985] Poole, K. T., and Rosenthal, H.
1985. A spatial model for legislative roll call analysis. Amer-
ican Journal of Political Science 357–384.
[Ramage et al. 2009] Ramage, D.; Hall, D.; Nallapati, R.;
and Manning, C. D. 2009. Labeled LDA: A supervised
topic model for credit attribution in multi-labeled corpora.
Proceedings of the 2009 Conference on Empirical Methods
in Natural Language Processing 1(August):248–256.
[Sedhain et al. 2015] Sedhain, S.; Menon, A. K.; Sanner, S.;
and Xie, L. 2015. AutoRec : Autoencoders Meet Collabo-
rative Filtering. Proceedings of the 24th International Con-
ference on World Wide Web (WWW) 111–112.
[Shah, Rao, and Ding 2017] Shah, V.; Rao, N.; and Ding, W.
2017. Matrix Factorization with Side and Higher Order In-
formation. arXiv preprint arXiv:1705.02047.
[Socher et al. 2013] Socher, R.; Chen, D.; Manning, C. D.;
and Ng, A. 2013. Reasoning with neural tensor networks
for knowledge base completion. In Advances in neural in-
formation processing systems, 926–934.
[Vincent et al. 2010] Vincent, P.; Larochelle, H.; Lajoie, I.;
Bengio, Y.; and Manzagol, P.-A. 2010. Stacked Denoising
Autoencoders: Learning Useful Representations in a Deep
Network with a Local Denoising Criterion. Journal of Ma-
chine Learning Research 11:3371–3408.
[Wang and Blei 2011] Wang, C., and Blei, D. M. 2011. Col-
laborative topic modeling for recommending scientiﬁc arti-
cles. In Proceedings of the 17th ACM SIGKDD international
conference on Knowledge discovery and data mining, 448–
456. ACM.
[Wang, Shi, and Yeung 2017] Wang, H.; Shi, X.; and Yeung,
D.-y. 2017. Relational Deep Learning : A Deep Latent Vari-
able Model for Link Prediction. AAAI.
[Wang, Wang, and Yeung 2015] Wang, H.; Wang, N.; and
Yeung, D.-Y. 2015. Collaborative Deep Learning for Rec-
ommender Systems. KDD 1235–1244.
[Wu et al. 2016] Wu, Y.; DuBois, C.; Zheng, A. X.; and Es-
ter, M. 2016. Collaborative Denoising Auto-Encoders for
Top-N Recommender Systems. Proceedings of the Ninth
ACM International Conference on Web Search and Data
Mining - WSDM ’16 153–162.
[Ying et al. 2016] Ying, H.; Chen, L.; Xiong, Y.; and Wu, J.
2016. Collaborative deep ranking: A hybrid pair-wise rec-
ommendation algorithm with implicit feedback. Paciﬁc-Asia
Conference on Knowledge Discovery and Data Mining 9652
LNAI:555–567.

Neural Ideal Point Estimation Network

Kyungwoo Song, Wonsung Lee, and Il-Chul Moon
Korea Advanced Institute of Science and Technology
291 Daehak-ro, Yuseong-gu
Daejeon 34141, South Korea
{gtshs2,aporia,icmoon}@kaist.ac.kr

9
1
0
2
 
r
p
A
 
6
2
 
 
]
I
S
.
s
c
[
 
 
1
v
7
2
7
1
1
.
4
0
9
1
:
v
i
X
r
a

Abstract

Understanding politics is challenging because the politics
take the inﬂuence from everything. Even we limit ourselves
to the political context in the legislative processes; we need
a better understanding of latent factors, such as legislators,
bills, their ideal points, and their relations. From the mod-
eling perspective, this is difﬁcult 1) because these observa-
tions lie in a high dimension that requires learning on low di-
mensional representations, and 2) because these observations
require complex probabilistic modeling with latent variables
to reﬂect the causalities. This paper presents a new model to
reﬂect and understand this political setting, NIPEN, includ-
ing factors mentioned above in the legislation. We propose
two versions of NIPEN: one is a hybrid model of deep learn-
ing and probabilistic graphical model, and the other model
is a neural tensor model. Our result indicates that NIPEN
successfully learns the manifold of the legislative bill texts,
and NIPEN utilizes the learned low-dimensional latent vari-
ables to increase the prediction performance of legislators’
votings. Additionally, by virtue of being a domain-rich proba-
bilistic model, NIPEN shows the hidden strength of the legis-
lators’ trust network and their various characteristics on cast-
ing votes.

Introduction
Recent developments in machine learning have enabled a
deeper understanding of human behavior in diverse contexts.
These advances include divulging intentions and sentiments
in dialogs (Bertero et al. 2016); predicting purchases from
online markets (Chong et al. 2017); recommending movies
to friends (Shah, Rao, and Ding 2017); and discovering so-
cial network links between individuals (Guo, Zhang, and
Yorke-Smith 2015). The recent machine learning models
provide the contexts of these behaviors, which have been
regarded as the latent aspects of human behavior.

One latent modeling of human behavior can be a form of
complex Bayesian probabilistic models, a.k.a. probabilistic
graphical model (PGM). The modelers used graphical nota-
tions, embedding the probabilistic variables and their causal-
ities, to represent the key factors and their relations. For in-
stance, latent Dirichlet allocation (LDA) models the genera-
tive process of documents, i.e. the composition of topics at

Copyright c(cid:13) 2018, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

large, a main topic of documents, and a word selection when
describing a topic (Blei, Ng, and Jordan 2003).

Another effort in modeling the latent variable is improv-
ing the quality of the latent representation of the data. While
the above probabilistic models focused on the contextual
modeling, the latent variables reside in a high dimensional
and nonlinear space, so the learning of the latent variables
have been limited. For example, the stacked de-noising au-
toencoder (SDAE) (Vincent et al. 2010) learns this mani-
fold space through encoding the noised inputs into the low
dimensional latent representations; and reconstructing the
original inputs with the latent representations with neural
network layers. Further advances have made through casting
this autoencoding mechanism to the variational inference
approaches, and a variational autoencoder (VAE) (Kingma
and Welling 2014) optimizes the variational distribution of
the latent representations with neural networks.

Supported by the two research advances, one distinct re-
search direction has been merging the latent representation
learning and the probabilistic graphical model on human be-
havior. Collaborative deep learning (CDL) (Wang, Wang,
and Yeung 2015) is one example merging SDAE with a
probabilistic model of matrix factorization that often used
to explain and predict the human behavior of recommen-
dations. Whereas CDL gives a clear passway on how we
can further develop various models of human behavior with
support from the deep learning, different application do-
mains require different latent modeling, so the model struc-
ture needs to be further customized and expanded.

This paper introduces Neural Ideal Point Estimation Net-
work (NIPEN) which models the generative process of po-
litical voting by estimating ideal points in diverse legisla-
tive aspects with learning the low dimensional representa-
tions from neural networks. Speciﬁcally, we propose two
versions of NIPEN. The ﬁrst version, NIPEN-PGM is a
hybrid model by representing the contextual causalities as
a PGM, and by learning the low dimensional representa-
tions with multi-layered perceptron (MLP) autoencoders,
i.e. SDAE and VAE. The second version, NIPEN-Tensor, is
a neural tensor model that substitutes the PGM part with the
neural tensor model. NIPEN-Tensor could be viewed as a
generalized version of NIPEN-PGM. NIPEN-Tensor mod-
els the legislative voting with the tensor composition and
the nonlinear operations between diverse legislative factors

Figure 1: The summarized procedure of NIPEN. NIPEN predicts the votes with the combination of contents and network
analyses. We can interpret not only an individual legislator’s ideal points but also trust networks between legislators

while NIPEN-PGM assumes the marginalization and the lin-
earized operation in the same modeling part.

Second, NIPEN is the most comprehensive model in the
latent modeling of the political domain. Assuming that we
model a voting process of legislators, NIPEN is the ﬁrst
model of unifying 1) the voting behavior, 2) the network in-
ﬂuence between congressmen, 3) the political ideal point of
bills and congressmen, 4) the textual topic of bills, and 5) the
relative strength of network inﬂuence and ideal points when
casting a vote. Some of these latent variables have been seen
in other models, (Gerrish and Blei 2012; Gu et al. 2014;
Chaney, Blei, and Eliassi-Rad 2015), but not as the uni-
ﬁed model to depict a whole political picture. Since di-
verse factors, such as the contents of the bill and the hu-
man relations, greatly inﬂuence the voting (Cohen and Mal-
loy 2014), an effective modeling of the legislative voting re-
quires an integrated model, such as NIPEN. We show that
NIPEN recorded signiﬁcant performance improvements in
all metrics compared to existing models. We also show vari-
ous qualitative analyses that can only obtained via this com-
prehensive model. The entire procedures and analyses of
NIPEN is summarized by Figure 1.

Previous Research

Modeling Political Network and Ideal Points

Network analyses and ideal point estimation have been
widely studied in computer science and quantitative polit-
ical science for its importance. In the line of political net-
work analyses, most studies analyzed co-sponsorship data
(Faust and Skvoretz 2002; Fowler 2006). Faust and Skvoretz
(2002) clariﬁed the topological structures in the network of
the U.S. Senate (1973-1974), and they found that the net-
work among U.S. Senator in 93rd Congress is O-star, I-
star and Trans structure (Faust and Skvoretz 2002). Fowler
(2006) inferred the relationship in U.S. Congress (1973-
2004) by measuring the centrality to ﬁnd the most central
legislators (Fowler 2006). In the community of ideal point
estimation, Poole and Rosenthal (1985) proposed a nonl-
inear logit model to account for political choices of legis-
lators (Poole and Rosenthal 1985). However, it was a one-
dimensional estimation, and the analysis could not identify

what the ideal dimension stands for. To overcome the lim-
itation, Clinton et al. (2004) proposed a multi-dimensional
ideal point estimation model, but these models still remained
at the simple logit model extensions (Heckman and Snyder
Jr 1996; Clinton, Jackman, and Rivers 2004).

With the advance of topic modeling, multi-dimensional
ideal point models were developed, and these models pro-
vide more accurate interpretations on the ideal points. Ger-
rish and Blei (2012) proposed an issue-adjusted model (Ger-
rish and Blei 2012) with the labeled LDA (Ramage et al.
2009), and Yupeng et al. (2014) proposed a topic-factorized
ideal point model (TFIPM) (Gu et al. 2014) with probabilis-
tic latent semantic analysis (PLSA) (Hofmann 1999) to esti-
mate the ideal points of legislators based on roll-call data.
Further extensions of TFIPM have made through includ-
ing available domain data. For instance, Islam et al. (2016)
proposed SCIPM by including co-sponsorship networks be-
tween judges in the supreme court (Islam et al. 2016). These
works have remained in the extension of the probabilistic
graphical model without the innovation from the deep learn-
ing community, which our work extends 1) the probabilis-
tic graphical model with variational autoencoders and 2) the
neural tensor model for the causality modeling of the leg-
islative voting.

Collaborative Filtering and Deep Learning
Collaborative Filtering is a recommendation algorithm that
considers the relationship between users and items (Koren,
Bell, and Volinsky 2009). One of representative approach is
a matrix factorization which factorizes the rating matrix as
user latent and item latent factors.Recently, the deep learn-
ing has initiated two theoretic developments. First, the ma-
trix factorization itself is a low-dimensional representation
method because of its latent vector learning, so does the au-
toencoding in the deep learning. For example, Sedhain et
al. (2015) proposed Autorec (Sedhain et al. 2015), a basic
autoencoder based CF algorithm, and Autorec outperforms
other state-of-the-art MF algorithms like LLORMA (Lee et
al. 2013). Wu et al. (2016) expand Autorec by concatenating
a user latent variable to the rating input information in the
encoder part of Autorec (Wu et al. 2016). Li et al. (2015)
adopted two autoencoders corresponding to users and items

(Li, Kawale, and Fu 2015), and they showed the interac-
tion mechanism between the two autoencoders by using the
marginalized SDAE (Chen et al. 2012). Second, the matrix
factorization is related to the low-dimensional feature rep-
resentation by adding the representation of the model as the
distilled version of the side information. For instance, Wang
et al. (2015) proposed a collaborative deep learning (CDL)
which combines SDAE with MF (Wang, Wang, and Yeung
2015). Furthermore, Ying (2016) proposed a model of col-
laborative deep ranking which combines ranking with algo-
rithm and SDAE (Ying et al. 2016). Wang et al. (2017) pro-
posed the relational deep learning with SDAE to link predic-
tion between items (Wang, Shi, and Yeung 2017).

Method
This section introduce the detailed descriptions of NIPEN-
PGM and NIPEN-Tensor in turn. Appendix A formulates
the assumptions and the research questions, and Appendix
C enumerates all symbols in this study.

NIPEN with Probabilistic Graphical Model and
Autoencoders
Figure 2 describes the model structure of NIPEN-PGM. We
start the detailed description from the bill low dimension
modeling part, which is the bill plate with the d ∈ D sub-
script. We apply either VAE or SDAE to learn the low di-
1 with the observed
mensional representation, or topic, of zdk
bill text wdv. zdk can be extracted through the probabilistic
encoder, qφ with parameter φ and decoder, pθ with param-
eter θ which is further described in Appendix B. The topic
representation of bills has two components: the bill latent
ydk and the latent offset ξdk, and we model the combination
of the two component as the below.

ydk = ξdk + zdk,

ξkd ∼ N (0, λ−1
y )

Since the bill itself and the bill text may have two differ-
ent latent variables, ξdk becomes the offset between the bill
latent variable and the bill text latent variable, or topic.

From the deﬁned bill latent ydk, we model how the bill
latent generates the voting observation rud. Here, u ∈ U is
the dimension of the legislators. We assumed that a legislator
cast votes considering three latent factors: the bill latent ydk,
the bill ideal point adk, and the legislators’ ideal point xuk.

adk ∼ N (0, λ−1

u ),

xuk ∼ N (0, λ−1
u )

Now, we deﬁne NIPEN-PGM without the network fac-
tor. This voting procedure is modeled as Eq. (1) where ηd
is a bias value of a legislative bill, and σ is a sigmoid func-
tion. Eq. (1) is designed to increase the probability of vot-
ing YEA when the ideal points of the bill and the legislator
have the same sign; and when an ideal-aligned dimension
of the bill latent variable is high. Additionally, ηd indicates
whether the bill is more broadly accepted or not, regardless
of ideal points.

p(rud = 1) = σ(

ydkadkxuk + ηd)

(1)

K
(cid:88)

k=1

1d, u, and k mean each document, legislator, topic respectively.

Small subscripts indicate the row and column index in order.

Figure 2: Graphical model representation of NIPEN-PGM

Finally, we add the network component to NIPEN-PGM.
The interest of a particular legislative group could be an im-
portant factor in the voting process. Following this impli-
cation, we modeled the network between two legislators as
below. Before the network modeling, we limited the network
inﬂuence between the legislators sharing the same term, and
this neighbor set, Iu, is deﬁned as a neighborhood of legis-
lator, u.

τuu(cid:48) ∼ N (0, λ−1

τ ) αu ∼ N (0, λ−1

α ) βu ∼ N (0, λ−1
α )
The legislator u’s voting is affected by two terms. The ﬁrst
term is the ideal alignment modeled in Eq. (1). The second
term is the voting record of the neighbor legislator, ru(cid:48)d, and
the second term is also weighted by the network strength,
τuu(cid:48), between the two legislators. Since this is a linear sum-
mation, τuu(cid:48) will model the degree of voting agreement be-
tween two legislators. These two terms are uniﬁed with scal-
ing parameters αu and βu. The purpose of modeling αu and
βu is analyzing whether a certain legislator is inﬂuenced
more either from the bill or from the network in casting
votes.

Eq. 2 is the overall voting formulation of NIPEN-PGM.

p(rud = 1) = σ(αu(

ydkadkxuk + ηd)

+ βu(

τuu(cid:48)ru(cid:48)d))

(2)

(cid:88)

k
(cid:88)

u(cid:48)∈Iu

NIPEN with Neural Tensor Model
Existing models, including NIPEN-PGM, do not directly
model the relationships between the topics, which means
that there is no cross-operiation between the dimension of
K. Some cases, i.e. correlated topic model (Lafferty and Blei
2006), model the correlation between topics via the logistic
normal distribution, but this is not an operation modeling of
topic inﬂuences, rather the variable modeling of topic co-
variance.

The recent introduction of neural tensor models (Socher
et al. 2013) enable the cross-operations between the latent

topic dimension. This topic cross-operation can model the
legislator’s ideal point non-linear inﬂuences when two top-
ics are combined within a bill. Here, we propose NIPEN-
Tensor to incorporate the cross-topic inﬂuence in casting a
vote, which could not be modeled in NIPEN-PGM. NIPEN-
Tensor and NIPEN-PGM are similar in the parts of docu-
ment and inﬂuence network modeling. The only different
part is the voting decision modeled as Eq. 2 which multiplies
the factors per a topic and marginalizes. NIPEN-Tensor con-
siders that the multiplication per a topic should be changed
to consider the nonlinear effect from the topic set, not a sin-
gle topic. Therefore, we represent the previous topic-wise
multiplcaiton of ydkadkxuk as a tensor E, and this tensor
still treats the topic dimension to be independent. Then, we
apply a fully-connected layer to cross-operate the topic di-
mension of E, and the neural network has C that is the out-
put of the cross-operation. The overall structure and formu-
lation for the NIPEN-Tensor are shown in Figure 3 and Eq.
3, respectively.

Eudk = xukydkzdk
(cid:88)

(cid:101)Eudl = tanh(

k

EudkW (T1)

kl + b(T1)

l

)

Cud =

(cid:101)EudlW (T2)

l1 + ηd

(cid:88)

k
(cid:88)

u(cid:48)∈U

Nud =

τuu(cid:48)vu(cid:48)d

(3)

W (T1), b(T1), W (T2) are weights and biases applied to Eudk,
(cid:101)Eudl tensor. In particular, W (T1) ∈ RK×K models the cor-
relation between topics, and W (T2) ∈ RK×1 models the
inﬂuence of each topic on the voting. Since the signs of
xuk, ydk, and adk are important, we use tanh instead of
ReLU (Rectiﬁed linear unit) to transform the outputs non-
linearly.

Parameter Inference of NIPEN

The parameters of both NIPENs are enumerated in the pre-
vious section, and we learn the parameters in two folds:
learning the autoencoder to represent the bill topic and
the CF, alternatively. The ﬁrst set of parameters related
to autoencoders is ψ(1) = (θ, φ); and the second set
of parameters related with the legislative-CF is ψ(2) =
(y, a, η, x, W (T1), W (T2), b(T1), τ, α, β).

The overall inference algorithm of both NIPENs fol-
lows the maximization of variational evidence lower bound
with two assumptions. Following CDL, the ﬁrst assump-
tion is connecting the autoencoder and CF through ξ, and
the strength is controlled by the variance of ξ, which is λy.
When learning ψ(1), we apply the stochastic gradient varia-
tional Bayes (SGVB) estimator.

Second, we assumed that the variational distribution of
ψ(2) as a point mass for simplicity, so the parameters of
the variational distribution are updated by each casted vote

Figure 3: Neural network view of NIPEN-Tensor. The con-
tents part is connected with the blue line (with content scal-
ing parameter αu ), and the network part is connected with
the purple line (with the network scaling parameter βu ).

record, which is traditional Bayesian belief updates. Speciﬁ-
cally, the likelihood of the posterior is presented as the lower
bound in the below. Then, the lower bound, which has real-
ized values of qφ(z|w), pθ(z) and an observed input, has
only ψ(2), so the gradient method can ﬁnd the maximum a-
posteriori, or MAP, of ψ(2).

As a summary, the objective function of both NIPENs is

LN IP EN = −DKL(qφ(z|w)(cid:107)pθ(z)) +

log pθ(w|zl)

1
L

L
(cid:88)

l=1

+

+

−

λf
2

λf
2

λy
2

(cid:88)

(u,d),rud(cid:54)=0
(cid:88)

(u,d),rud(cid:54)=0

1 + rud
2

1 − rud
2

log p(rud = 1)

log p(rud = −1)

D
(cid:88)

d=1

(cid:107)yd − zd(cid:107)2

2 −

((cid:107)a(cid:107)2

F + (cid:107)x(cid:107)2
F )

λu
2

−

λτ
2

F ) −

((cid:107)τ (cid:107)2

((cid:107)α(cid:107)2

2 + (cid:107)β(cid:107)2
2)

λα
2
Similar to (Wang and Blei 2011; Wang, Wang, and Yeung
2015), the parameters related with the autoencoder and the
legislative-CF are infered by coordinate ascents which maxi-
mizes LN IP EN . For legislative-CF related parameters ψ(2),
we take the gradient of LN IP EN w.r.t each parameters given
the current θ and φ. Given the legislative-CF related param-
eters ψ(2), we infer the autoencoder related parameters by
computing ∇ψ(1)LN IP EN . We utilized the Tensorﬂow li-
brary (Abadi et al. 2016) to optimize the parameters.

NIPEN-PGM and NIPEN-Tensor are only different in the
vote casting process, and the related term in the objective
function is the third and the fourth terms with log p(rud =
1). These terms could be computed as the conventional gra-
dient descent in two variants of NIPEN, so there is no change

p(rud = 1) = σ(αuCud + βu

Nu(cid:48)d)

speciﬁed as follows:

(cid:88)

u(cid:48)∈Iu

in the learning mechanism.

In the original deﬁnition, the network, τ , is a |U |-by-|U |
matrix, and the number of parameters becomes large given
O(U 2). To reduce the squared complexity, τ is approxi-
mated by the product of (cid:101)τ1 and (cid:101)τ2 where (cid:101)τ1 ∈ RU ×G, (cid:101)τ2
∈ RG×U . We assume that (cid:101)τ1 and (cid:101)τ2 are not related. G can
be interpreted as the number of groups containing the legis-
lators. This approximation results in O(GU ) for the network
parameter inference.

Table 1: Attributes of Politic2013 and Politic2016 dataset

# of legislators (|U |)
# of bills (|D|)
# of votings (|D|)
# of House
# of Senator
# of Republican
# of Democrat
# of unique word (|V |)

Average # of unique word
(cid:80)
d,v(Iwdv >0)
for each bill (

)

V

# of bills less than
10 unique words
Period
Source
Data type

Politic2013
1,540
7,162
2,779,703
1,299
241
767
767
10,000

Politic2016
1,537
7,975
2,999,844
1,266
271
778
752
13,581

192.77

378.66

65

0

1990-2013
THOMAS

1989-2016
GovTrack

1 (YEA), -1 (NAY)

Results

Datasets on Political Ideal Points
We used two roll-call datasets, whose source is explained in
Appendix D. Table 1 provides the descriptive statistics of the
two datasets: Politic2013 and Politic2016. Politic2013 limits
the number of a unique word to 10,000, and there are 65 bills
which have less than ten words, while Politic2016 chooses
13,581 unique words, and there are no bills with less than ten
words. Politic2013 is a more sparse dataset than Politic2016
in the ratings and the vocabulary sizes.

Baselines and Implementation Details
The variations of NIPEN were compared to ﬁve baseline
models as follows:
• TFIPM: Topic Factorized Ideal Point estimation Model
(Gu et al. 2014) is specialized in politics to analyze the
roll-call data.

• Autorec: A simple autoencoder model which is utilized to
predict the ratings. Autorec (Sedhain et al. 2015) encodes
and reconstructs the rating matrix. We used Item-based
Autorec.

• Trust SVD: Trust SVD (Guo, Zhang, and Yorke-Smith
2015), a type of trust-based matrix factorizations, is built
on SVD++ with trust information.

• CDAE: Collaborative Denoising Autoencoder (Wu et al.
2016) used a denoising autoencoder with user latent vari-
ables.

• CDL: Collaborative Deep Learning (Wang, Wang, and
Yeung 2015) used the deep learning and the CF, jointly.
CDL improves performance by using document informa-
tion additionally, and CDL uses SDAE to learn document
manifold.
Appendix E provides detailed speciﬁcations for replica-
tions of this work, and Appendix F illustrates the sensitivity
analysis of λy and λτ .

Quantitative Evaluations
We performed the ﬁve-fold cross-validation to quantita-
tively evaluate the variations of NIPENs, and the perfor-
mance measures are RMSE, MAE, accuracy, and nega-
tive average log-likelihood (NALL) measures. We compared
nine models: ﬁve baseline models in section 4.2, and four
NIPEN variations, which are NIPEN-PGM(SDAE), NIPEN-
PGM(VAE,approx.), NIPEN-PGM(VAE), and NIPEN-
Tensor. NIPEN-PGM has three variants by choosing either
SDAE or VAE as the autoencoder for the text modeling, and
by choosing either using the whole matrix for the inﬂuence
or the low-rank approximated matrix of the inﬂuence.

Table 2 statistically conﬁrms that the best performance
model in every metric is always a variation of NIPEN, which
is conﬁrmed with statistical signiﬁcance. In detail, ﬁrst,
we compare NIPEN-PGM(VAE) and NIPEN-PGM(SDAE),
and their performance gap is larger in Politic2013 than in
Politic2016 which is a relatively sparse setting as shown
in Table 1. We conjecture that NIPEN-PGM(VAE) is bet-
ter in handling the sparse dataset than NIPEN-PGM(SDAE).
Second, NIPEN-Tensor is a model that considers the cor-
relation between topics, and NIPEN-Tensor may have a
better performance when a bill text has multiple topics
with complex and rich textual information. As discussed
in Section Datasets on Political Ideal Points, Politic2016
has richer textual information than Politic2013, and we con-
jecture that this is the reason why NIPEN-PGM(VAE) in
Politic2013 and NIPEN-Tensor in Politic2016 show better
performances. Third, while the accuracy improvement is rel-
atively small, the improvements on other metrics, partic-
ularly RMSE and MAE, are relatively large. Already, the
baseline models achieve the accuracy higher than 95%, so
the accuracy improvement could seem minimal. However,
our likelihood estimation of YEA and NAY is considerably
improved given the RMSE and the MAE improvement.

Qualitative Evaluations
In addition to the quantitative results, we interpret the latent
variables of NIPEN-PGM(VAE) on Politic2016. First, to
comprehend the dataset and the qualitative results, we com-
puted the word-topic matrix from well-learned VAE vari-
ables, ψ1, as shown in Table 3. This table provides a snap-
shot of topics in the bills. Then, we relate this topic to the bill
ideal points, adk. The latent dimension, k, becomes the com-
mon dimension of an ideal point value and a topic weight
for each topic in the bill. Figure 5 shows an example of the
topic weight as the bar chart and the ideal point value as the
line chart. The illustrated bill, or H.Res.794 (114th), has the
largest absolute value, |adk(cid:101)zdk| in a ’Business and Finance’
topic where (cid:101)zdk denotes the normalized zdk.

Table 2: Quantitative evaluation on Politic2013 and Politic2016 datasets. Two-standard deviation is shown in parentheses

Politic2013

Politic2016

RMSE
0.2253
(±0.0007)
0.2110
(±0.0099)
0.2059
(±0.0007)
0.1872
(±0.0002)
0.1834†
(±0.0008)
0.1801**
(±0.0014)

MAE
0.1399
(±0.0011)
0.0975
(±0.0136)
0.0831
(±0.0009)
0.0682†
(±0.0002)
0.0786
(±0.0019)
0.0591**
(±0.0012)

Accuracy
0.9408
(±0.0003)
0.9411
(±0.0056)
0.9428
(±0.0006)
0.9526
(±0.0003)
0.9554†
(±0.0004)
0.9566**
(±0.0006)

NALL
0.1866
(±0.0011)
0.1466
(±0.0177)
0.1450
(±0.0009)
0.1213
(±0.0007)
0.1147†
(±0.0018)
0.1155
(±0.0018)

RMSE
0.2168
(±0.0011)
0.2031
(±0.0015)
0.1977
(±0.0037)
0.1794
(±0.0010)
0.1780†
(±0.0013)
0.1779
(±0.0005)

MAE
0.1353
(±0.0010)
0.0886
(±0.0110)
0.0802
(±0.0052)
0.0625†
(±0.0006)
0.0769
(±0.0012)
0.0560**
(±0.0004)

Accuracy
0.9463
(±0.0009)
0.9454
(±0.0007)
0.9475
(±0.0023)
0.9566
(±0.0005)
0.9583†
(±0.0008)
0.9581
(±0.0003)

NALL
0.1782
(±0.0015)
0.1349
(±0.0125)
0.1357
(±0.0046)
0.1121
(±0.0016)
0.1106†
(±0.0017)
0.1173
(±0.0015)

0.1804
(±0.0089)

0.0611*
(±0.0065)

0.9565
(±0.0047)

0.1165
(±0.0086)

0.1791
(±0.0076)

0.0599
(±0.0057)

0.9571
(±0.0039)

0.1152
(±0.0070)

0.1753**
(±0.0007)
0.1818**
(±0.0008)
4.41%

0.0588**
(±0.0008)
0.0663**
(±0.0003)
13.78%

0.9587**
(±0.0006)
0.9556**
(±0.0003)
0.35%

0.1075**
(±0.0011)
0.1155
(±0.0020)
6.27%

0.1753**
(±0.0017)
0.1729**
(±0.0015)
2.87%

0.0570**
(±0.0012)
0.0608**
(±0.0006)
10.40%

0.9590**
(±0.0010)
0.9600**
(±0.0008)
0.18%

0.1112
(±0.0024)
0.1057**
(±0.0022)
4.43%

Trust SVD

Autorec

CDAE

TFIPM

CDL

NIPEN-
PGM(SDAE)
NIPEN-
PGM(VAE,
approx.)
NIPEN-
PGM(VAE)
NIPEN-
Tensor
Improvement

NALL : Negative Average Log Likelihood
Improvement : Relative improvement of the best version of NIPEN compared to the best model, which is marked by †, among the baselines
P ∗ < 0.05; P ∗∗ < 0.01 (Student’s one-tailed t-test against the † model)

Table 3: Selected top-ﬁve words for each topic. The number
of listed topics was set to ten.

Topic Label
Business and
Finance
Disasters
Management
International
Relationship

Racism

Defense

Agriculture

Social

Health

Foregin

1

2

3

4

5

6

7

8

9

International
Trade

10

Topic Words
Forproﬁt, Nonrefundable, Govern,
SBDC, Financings
Stabilization, Homeless, Disasters,
Alerts, USPS
Kuwait, Distributes, Lawsuits,
Threatens, Spain
Contrary, Black, Compared,
Tuskegee, Reagan
United, Soviet, Antiterrorist, IDA,
NGA
Pima, Climate, Cropland, Bush,
Badlands
Contribute, Donors, Childcare,
Resettlement, DRR
FEHBP, Heroin, Stability,
Musculoskeletal, Transplantation
Agency, Lantos, FPI, fusion,
division
Clearinghouses, ESF,
Discrepancies, Repay, Charging

Figure 4: Individual legislators’ ideal points for each topic

This bill ideal point is correlated with the legislator ideal
point, xuk, to generate the vote records. Here, the dimen-
sion, k, is the same latent dimension of the topic in Table
3, and we provide the scatter plot of the legislators’ ideal
points per topic in the Figure 4. The prior mentioned bill
(H.Res.794 (114th)) considers the appropriations for ﬁnan-
cial services and general government, and the major topic is
Business and Finance, and the bill ideal point in Business
and Finance is -1.217. Together, the vote casting will be de-
termined by the legislators’ view on Business and Finance,
and this topic shows the greatest disagreement between the
Republicans and the Democrats according to the Figure 4. In
the real world, the voting results were same as expected: 1)
the voting was very partisan, 92.2% Republican voted YEA

Figure 5: Topic proportion and ideal points of H.Res.794
(114th) bill

Table 4: Top-ﬁve legislators who are affected by contents or
network factors a lot. The scaling variable (αu for contents
based, and βu for network based), political party, and district
of the member are indicated in parentheses.

Contents based
Ron Paul
(0.260, R, TX)
Virgil H. Goode
(0.220, R, VA)
Dennis J. Kucinich
(0.218, D, OH)
Henry Cuellar
(0.198, D, TX)
Walter B. Jones
(0.195, R, NC)

1

2

3

4

5

Network based
Ralph M. Hall
(0.304, R, TX)
Nick J. Rahall II
(0.250, D, WV)
Peter A. DeFazio
(0.247, D, OR)
Don Young
(0.228, R, AK)
Jim Sensenbrenner.
(0.227, R, WI)

action between the contents and the network parts. We
used two scaling variables αu and βu, which controls the
strengths of contents factor and network factor, respectively.
Table 4 shows the top-ﬁve legislators who were affected by
either contents or network factors. Since the variations of
NIPEN is an integrated model of network modeling as well
as the textual bill modeling, the NIPENs should better per-
form than the baseline models, i.e. CDL, which only models
the texts, and Figure 7 conﬁrms this hypothesis.

Figure 6: Trust network between legislators

and the 90.3% Democrat voted NAY.

The second qualitative interpretation focuses on the legis-
lators’ network. We selected 12 legislators who have either
strongly positive or negative relationships with each other,
shown in the Figure 6. In general, the legislators have a
strong positive relationship when they have the same dis-
trict and the party. Among the top-ﬁve positive relation-
ships, four of them have the same party and the same dis-
trict, i.e. ’Thomas E. Petri↔Jim Sensenbrenner’, ’Nick J.
Rahall II→Robert E. Wise’, and ’Nick J. Rahall II→Alan B.
Mollohan’2. The closest relations are ’Thomas E. Petri’ and
’Jim Sensenbrenner’. They were both republican representa-
tives from Wisconsin, and they share similar voting patterns.
They have voted 6,288 times for the same bill, and the 5,764
votes were same (91.6%). Especially, they voted NAY for
H.R.730 (111th) which is a ”suspension of the rules”, and
397 legislators votes YEA. For H.R.6063 (110th), ’Thomas
E. Petri’ and ’Jim Sensenbrenner’ voted NAY together while
94.4% legislators voted YEA. We report further analyses in
Appendix G.

The third qualitative analysis concentrates on the inter-

2τuu is asymmetric matrix. arrow(’→’) indicates the direction

of the trust

Figure 7: Accuracy of top ﬁve legislators who are affected
by network factor

Conclusion

We proposed two versions of machine learning models,
NIPEN-PGM and NIPEN-Tensor, to analyze the ideaology
in the legislation process. The variations of NIPEN show the
state-of-the-art performance in all measures on Politic2013
and Politic2016. Furthermore, NIPEN provides various in-
terpretations in why YEA or NAY is casted by illustrating 1)
the ideal point estimation of individual legislators and bills;
2) the trust network between legislators; and 3) the content
and network inﬂuence for each legislator. These supervised
and unsupervised tasks could be critical insights into quan-
titatively understanding politics in the legislative process.

Appendix A. Problem Formulation

In general, the inﬂuence on legislative voting originates from
1) the individual ideal points of the legislator, 2) the contents
of the bill, and 3) the interests of a political group that a leg-
islator belongs to. We operationalize these inﬂuence struc-
ture as the concepts deﬁned in the below.

Deﬁnition 1. Ideal point is a measure of legislator’s prefer-
ence for each topic when we have K topics in our bill texts.
The ideal point for a particular topic k of a particular mem-
ber u is represented by xuk, and it follows N (0, λ−1
u ). The
sign of xuk represents the preferred voting direction (posi-
tive or negative), and the size of |xuk| represents the pref-
erence strength. The ideal point for a particular topic k of a
particular bill d is represented by adk, and its distribution is
N (0, λ−1
u ). The interprestation of adk is same as xuk.

Deﬁnition 2. Contents refer to the bill elements, i.e. text
descriptions, which affect the voting result. The latent repre-
sentation of the contents is ydk which is the addition of zdk,
the topic of the bill; and ξdk, the deviation of the bill from
the topic of the bill text.

Deﬁnition 3. Network means the collection of relationships
between legislators whose vote affect the other’s vote. The
strength of network relationships is modeled as τuu(cid:48), which
follows N (0, λ−1
τ ). The sign of τuu(cid:48) indicates the voting
alignment between u and u(cid:48) legislators, and |τuu(cid:48)| means
its alignment strength. This study assumes that the network
relationships are asymmetric bidirectional, and only the leg-
islators in the same term affect each other.

Deﬁnition 4. Scaling parameters mean the inﬂuence of
contents and networks when a legislator votes. αu is a con-
tent scaling parameter, and βu is a network scaling parame-
ter. Each scaling parameter is a |U |-dimensional vector, fol-
lowed by N (0, λ−1
α ). This study assumed that the degree of
inﬂuence on the contents and the network would be different
per each legislator.

Now, given the above deﬁned concepts, we enumerates

the research questions to test with NIPEN.

Problem 1. NIPEN can predict the results of the voting by
inferring the bill topic, the bill ideal points, the legislator
ideal points, and the network relationships between the leg-
islators.

Problem 2. NIPEN provides the interpretation on the vot-
ing results of the bill. For example, NIPEN illustrates the
interpretable latent information from the bill topic, the bill
ideal point, and the legislator ideal point taking into account
the correlation between the topics.

Problem 3. NIPEN can 1) analyze the trust between legis-
lators (individual unit), and 2) the trust network comparison
between parties (group unit).

Problem 4. NIPEN provides the behavioral analyses on leg-
islators from the voting motivation perspective, which could
be motivated by either legislator ideal point or network rela-
tionship.

Appendix B. Document Modeling
Autoencoders

Appendix B.1. Variational Autoencoder (VAE)
NIPEN extracts the topics of the legislative bills with
VAE (Kingma and Welling 2014) which is a type of
deep generative model. VAE learns the disentangled and
low-dimensional representation of high dimensional data
through the probabilistic encoding, or qφ(z|w); and the
probabilistic decoding, or pθ(w|z). Therefore, the original
objective function of VAE is composed of the linear sum of
corresponding two terms. The ﬁrst term originating from the
encoding is the KL divergence between the probabilistic en-
coding and the prior for latent variable, or pθ(z); and this
term enforces the regularization. The second term is the ex-
pectation on the negative reconstruction error, and this term
is related to the decoding part. By putting both terms to-
gether, the objective function follows as Eq. (4).

L(θ, φ) = −DKL(qφ(z|w)(cid:107)pθ(z)) + Eqφ[log pθ(w|z)]

(4)
Given the high variance over φ, a direct optimization of
Eq. (4) is not efﬁcient. Hence, Kingma and Welling (2014)
suggested the re-parametrization trick as follows: 1) Draw
(cid:15)l ∼ N (0, I), and 2) Optimize the mean and standard devi-
ation of qφ(z|w), and 3) Compute zl = µ(w) + σ(w) (cid:12) (cid:15)l.
From the trick, the objective function of VAE is turned into
Eq. (5) where L is the number of samples.

(cid:101)L(θ, φ) = −DKL(qφ(z|w)(cid:107)pθ(z)) +

log pθ(w|zl)

1
L

L
(cid:88)

l=1

(5)

Appendix B.2. Stacked Denoising Autoencoder
(SDAE)
NIPEN-PGM(SDAE) extracts the topics of the legislative
bills with SDAE (Vincent et al. 2010). SDAE learns the
disentangled latent feature through the encoding and decod-
ing with bottleneck and corrupted input. SDAE use the cor-
rupted input wc instead of the original input w to force
the relationship learning. The SDAE is optimized for the
purpose of reconstructing the w resulting from the encod-
ing process(fe) through the encoder weight (W (e)) and the
decodingfd result through the decoder weight (W (d)). The
objective function follws as Eq. (6)

(cid:13)
(cid:13)
2
(cid:13)fd(fe(w, W (e)), W (d)) − wc)
(cid:13)
(cid:13)
(cid:13)
2

(6)

Appendix C. Notations

Table 5 summarizes all symbols used in this study.

Appendix D. Dataset Descriptions

is Politic2013, and it was collected
The ﬁrst dataset
from THOMAS3, and (Gu et al. 2014). For an additional
experiment, and for more up-to-date analyses, we col-
lected a new roll-call dataset, Politic2016 from GovTrack

3http://thomas.loc.gov/home/rollcallvotes.html

Table 5: Notation description

Symbol
D
V
U (= U (cid:48))
K
G
Iu
wdv
zdk
ydk
adk
ηd
rud
xuk
αu
βu
τuu(cid:48)
(cid:101)τ1, (cid:101)τ2
ξ
(cid:15)
φ(θ)
C(N )
E
W (T ), b(T )

Description
Set of bills
Set of Unique words
Set of legislators
Set of topics
Rank of (cid:101)τ1 and (cid:101)τ2
Other legislators within the same term as u
Frequency of vth token in document d
Topic proportion for each bill and topic
Bill latent vector
Ideal point for each bill and topic
Constant offset for each bill d
Voting record from legislator u to bill d
Ideal point for each legislator and topic
Contents scaling parameter for legislator u
Network scaling parameter for legislator u
Trust network between legislator u and u(cid:48)
Approximated matrix of τuu(cid:48)
Latent offset between zdk and ydk
Random noise vector drawn from N (0, I)
Parameter of encoder (decoder) in VAE
Contents (Network) information
The tensor combined with xuk, ydk, adk
Neural tensor network parameter

.GovTrack provides raw roll-call data, so we processed
the expanded part of Politic2016, manually. For the re-
search community, we released the code and dataset on
https://github.com/gtshs2/NIPEN

Appendix E. Experiment Settings
For TFIPM, we followed the optimal parameters that the au-
thor reported. We set the latent dimension(K), the trade-off
weight, and the regularization weight as 10, 0.8, and 22.4,
respectively. The latent dimension of CDL and NIPENs was
set to ten, equally. For Autorec, the optimal number of the
latent dimension and the regularization parameter are 100
and 0.001, respectively. Trust SVD shows the best perfor-
mance when the weights of CF and trust part are 1,000 and
0.001, respectively, while K is set to 10. For CDAE, we
set the regularization weight, the corruption ratio, and the
number of latent dimension as 0.001, 0.4, and 50, respec-
tively; and the encoder and the decoder activation functions
are sigmoid. For CDL, we ﬁnd that the optimal parameters
of λu,λv,λw,λn, the dropout rate and the activation func-
tions are 0.01, 100, 1, 100, 0.1 and the sigmoid function, re-
spectively. The neural network structure of Autorec, CDAE,
CDL, NIPENs are set to [512,128,K,128,512], equally. Fi-
nally, we set the parameters of NIPENs such as λf = 10,
λy = 10, λu = 0.1, λτ = 1, λα = 1, λn = 1000 G = 3, and
we performed grid searches to ﬁnd the optimized parameters
of NIPENs. Finally, NIPEN-Tensor has the two-layered ten-
sor E in the topic axis.

Appendix F. Hyperparameter Study
This quantitative improvement requires a well-tuned hyper-
parameter setting, illustrated in Figure 8. LN IP EN enumer-
ates multiple hyperparameters, and we found that λy and λτ
are the most important parameters to decide. λy speciﬁes the
causality strength from the bill text latent in VAE to the bill
latent in the legislative CF. The low value of λy will sepa-
rate VAE and CF, but its high value will disrupt the manifold
learning of VAE. Moreover, λτ speciﬁes the regularization
strength from the legislators’ network inﬂuence to the vot-
ing. The small value of λτ will overﬁt the network inﬂuence,
and its large value will limit the learning of network inﬂu-
ence model in CF.

Figure 8: (Top-Left) Accuracy for λy and λτ value, (Top-
Right) RMSE for each λy and λτ value, (Bottom-Left) Ac-
curacy for G value, (Bottom-Right) RMSE for each G value

Appendix G. Results in Network Inﬂuence
Analyses
To examine the network relationships within each party, Fig-
ure 9 illustrates the trust network parameter. A red node rep-
resents a Republican; a blue node stands for a Democrat;
a green solid line indicates an inferred close relationship;
and a purple dotted line indicates an inferred unfriendly re-
lationship. Taking a threshold at 0.1 and looking at τuu(cid:48) with
values greater than 0.1 and less than -0.1 (Figure 9d), John
J. Duncan Jr and Dana Rohrabacher have the greatest net-
work impact given their number of connected legislators in
the Republican party. The commonalities between the two
inﬂuential legislators are 1) being a member of the House of
Representatives; and 2) having been politically active for a
long time (Duncan started as a congressman in Tennessee in
1988 and Laura Baker as a California congressman in 1989.
Especially, Jimmy Duncan is the House’s longest-serving
Republicans.).

We compared and contrasted the network structure of Re-
publicans and Democrats. As shown in Table 6, the network
inﬂuence among the total members is greater in the Demo-
cratic Party given its mean value of |τuu(cid:48)|. However, the Re-

publican party has the higher number of inﬂuential legisla-
tors when we limit the network inﬂuence with thresholds,
i.e. when we limit |τuu(cid:48)| > 0.05 or |τuu(cid:48)| > 0.1 in Table 6.
This suggests that the Democrats have averagely higher and
more equal inﬂuences between the members while the Re-
publicans have a number of authorative inﬂuencers among
the members.

(a) Threshold = 0.03

(b) Threshold = 0.05

Table 6: Comparison of network inﬂuence by each Party

# of pair s.t. τuu(cid:48) > 0.05
# of pair s.t. τuu(cid:48) < −0.05
# of pair s.t. τuu(cid:48) > 0.1
# of pair s.t. τuu(cid:48) < −0.1
Mean of |τuu(cid:48)|
Variance of |τuu(cid:48)|

Republican
58
67
7
3
9.0E-04
2.49E-05

Democratic
49
53
1
3
0.0018
3.38E-05

Table 7: Content and Network scale comparison between the
Party. Average Ranking@K is the average of the ranking of
each legislator, by the party, when the ranking is made up to
the top K legislators, based on scaling parameter (αu βu).

Content (|αu|)

Network (|βu|)

R
6
40
52.87
774.6
0.149

NL@10
NL@100
AR@100
AR@All
Mean value of αu (βu)
R : Republican Party / D : Democratic Party
AR@K : Average Ranking at top K
NL@K : Number of legislators at top K

D
4
60
48.91
762.7
0.148

R
6
42
46
781.4
0.068

D
4
58
53.75
754.9
0.064

Republican Party generally relies on the network, and the
Democratic Party on contents, when they are voting. If we
associate this conclusion with Table 6, we can explain that
a Democratic have more inﬂuence in the network within the
party. However, the proportion of people who are dependent
on the network (including network from their own party and
opposing party) is relatively high in the Republican Party.

(c) Threshold = 0.07

(d) Threshold = 0.1

Figure 9: Network inﬂuence visualization within each party
in December 2016. The top visualizations represent the Re-
publican Party, and the bottom visualizations represent the
Democratic Party. If the network inﬂuence, τuu(cid:48), between
two legislators exceeds the threshold, the relationship is ex-
pressed as a green solid line. If the network inﬂuence, τuu(cid:48),
is less than the threshold, the relationship is noted as a purple
dotted line.

The United States has a two-party system. In order to an-
alyze this reality effectively, contents scaling parameter and
network scaling parameter are analyzed by each party. Com-
paring the mean value of |αu| and |βu| in the Table 7, we
can see that both parties are generally voting rather than net-
works, concentrating on their own politics and the contents
of the bill itself. To compare two political parties relative to
each other based on Average Ranking@100 in Table 7, the

Figure 10: Graphical model representation of NIPEN-PGM

According to the opinion of the reviewers who advised
on the analysis of αu and βu, the distribution of |αu| and
|βu| is shown in Figure 10, and the value of |αu|/|βu| over
time is shown in Figure 11. According to Figure 10, we can
infer that the majority of legislators are voting focusing on

of Roll Call Data. The American Political Science Review
98(2):355–370.
[Cohen and Malloy 2014] Cohen, L., and Malloy, C. J. 2014.
Friends in high places. American Economic Journal: Eco-
nomic Policy 6(3):63–91.
[Faust and Skvoretz 2002] Faust, K., and Skvoretz, J. 2002.
Comparing Networks Across Space and Time, Size and
Species. Networks 32(2002):267–299.
[Fowler 2006] Fowler, J. H. 2006. Connecting the congress:
Political Analysis
A study of cosponsorship networks.
14(4):456–487.
[Gerrish and Blei 2012] Gerrish, S., and Blei, D. M. 2012.
How they vote: Issue-adjusted models of legislative behav-
ior. Advances in Neural Information Processing Systems
25(1):2762–2770.
[Gu et al. 2014] Gu, Y.; Sun, Y.; Jiang, N.; Wang, B.; and
Chen, T.
2014. Topic-factorized ideal point estimation
model for legislative voting network. Proceedings of the
20th ACM SIGKDD international conference on Knowledge
discovery and data mining. ACM, 2014. 183–192.
[Guo, Zhang, and Yorke-Smith 2015] Guo, G.; Zhang, J.;
and Yorke-Smith, N. 2015. TrustSVD : Collaborative Fil-
tering with Both the Explicit and Implicit Inﬂuence of User
Trust and of Item Ratings. Proceedings of the Twenty-ninth
AAAI Conference on Artiﬁcial Intelligence (AAAI) 123–129.
[Heckman and Snyder Jr 1996] Heckman, J. J., and Snyder
Jr, J. M. 1996. Linear probability models of the demand
for attributes with an empirical application to estimating the
preferences of legislators. National bureau of economic re-
search 28(0).
[Hofmann 1999] Hofmann, T. 1999. Probabilistic latent se-
mantic indexing. Proceedings of the 22nd annual interna-
tional ACM SIGIR conference on Research and development
in information retrieval 50–57.
[Islam et al. 2016] Islam, M. R.; Hossain, K. T.; Krish-
nan, S.; and Ramakrishnan, N.
Inferring Multi-
dimensional Ideal Points for US Supreme Court Justices.
Proceedings of the 30th Conference on Artiﬁcial Intelligence
(AAAI) 4–12.
[Kingma and Welling 2014] Kingma, D. P., and Welling, M.
2014. Auto-encoding variational bayes. In Proceedings of
the International Conference on Learning Representations
(ICLR).
[Koren, Bell, and Volinsky 2009] Koren, Y.; Bell, R.; and
Volinsky, C. 2009. Matrix Factorization Techniques for Rec-
ommender Systems. Computer 42(8):42–49.
[Lafferty and Blei 2006] Lafferty, J. D., and Blei, D. M.
2006. Correlated topic models. In Advances in neural in-
formation processing systems, 147–154.
[Lee et al. 2013] Lee, J.; Kim, S.; Lebanon, G.; and Singer,
Y. 2013. Local Low-Rank Matrix Approximation. ICML
28.
[Li, Kawale, and Fu 2015] Li, S.; Kawale, J.; and Fu, Y.
2015. Deep collaborative ﬁltering via marginalized denois-
ing auto-encoder. In Proceedings of the 24th ACM Interna-

2016.

Figure 11: Graphical model representation of NIPEN-PGM

contents rather than network effect. However, since the the
number of element that |βu| > 0.2 is larger than the number
of |αu| > 0.2, we can infer that small number of legislators
are highly dependent on network effect. In addition, Figure
11 shows the change in a |αu/βu| over time, and we can in-
fer that the inﬂuence of contents over networks has become
more important in recent years.

References
[Abadi et al. 2016] Abadi, M.; Agarwal, A.; Barham, P.;
Brevdo, E.; Chen, Z.; Citro, C.; Corrado, G. S.; Davis, A.;
Dean, J.; Devin, M.; and Others. 2016. Tensorﬂow: Large-
scale machine learning on heterogeneous distributed sys-
tems. arXiv preprint arXiv:1603.04467.
[Bertero et al. 2016] Bertero, D.; Siddique, F. B.; Wu, C.-S.;
Wan, Y.; Chan, R. H. Y.; and Fung, P. 2016. Real-Time
Speech Emotion and Sentiment Recognition for Interactive
Dialogue Systems. ACL.
[Blei, Ng, and Jordan 2003] Blei, D. M.; Ng, A. Y.; and Jor-
dan, M. I. 2003. Latent Dirichlet Allocation. The Journal of
Machine Learning Research 3:993–1022.
[Chaney, Blei, and Eliassi-Rad 2015] Chaney, A. J.; Blei,
D. M.; and Eliassi-Rad, T. 2015. A probabilistic model for
using social networks in personalized item recommendation.
Proceedings of the 9th ACM Conference on Recommender
Systems 43–50.
[Chen et al. 2012] Chen, M.; Xu, Z.; Weinberger, K.; and
Sha, F. 2012. Marginalized Denoising Autoencoders for
Domain Adaptation. Proceedings of the 29th International
Conference on Machine Learning (ICML) 767—-774.
[Chong et al. 2017] Chong, A. Y. L.; Ch’ng, E.; Liu, M. J.;
and Li, B. 2017. Predicting consumer product demands via
Big Data: the roles of online promotional marketing and on-
line reviews. International Journal of Production Research
55(17):5142–5156.
[Clinton, Jackman, and Rivers 2004] Clinton, J. D.; Jack-
man, S.; and Rivers, D. 2004. The Statistical Analysis

tional on Conference on Information and Knowledge Man-
agement, 811–820. ACM.
[Poole and Rosenthal 1985] Poole, K. T., and Rosenthal, H.
1985. A spatial model for legislative roll call analysis. Amer-
ican Journal of Political Science 357–384.
[Ramage et al. 2009] Ramage, D.; Hall, D.; Nallapati, R.;
and Manning, C. D. 2009. Labeled LDA: A supervised
topic model for credit attribution in multi-labeled corpora.
Proceedings of the 2009 Conference on Empirical Methods
in Natural Language Processing 1(August):248–256.
[Sedhain et al. 2015] Sedhain, S.; Menon, A. K.; Sanner, S.;
and Xie, L. 2015. AutoRec : Autoencoders Meet Collabo-
rative Filtering. Proceedings of the 24th International Con-
ference on World Wide Web (WWW) 111–112.
[Shah, Rao, and Ding 2017] Shah, V.; Rao, N.; and Ding, W.
2017. Matrix Factorization with Side and Higher Order In-
formation. arXiv preprint arXiv:1705.02047.
[Socher et al. 2013] Socher, R.; Chen, D.; Manning, C. D.;
and Ng, A. 2013. Reasoning with neural tensor networks
for knowledge base completion. In Advances in neural in-
formation processing systems, 926–934.
[Vincent et al. 2010] Vincent, P.; Larochelle, H.; Lajoie, I.;
Bengio, Y.; and Manzagol, P.-A. 2010. Stacked Denoising
Autoencoders: Learning Useful Representations in a Deep
Network with a Local Denoising Criterion. Journal of Ma-
chine Learning Research 11:3371–3408.
[Wang and Blei 2011] Wang, C., and Blei, D. M. 2011. Col-
laborative topic modeling for recommending scientiﬁc arti-
cles. In Proceedings of the 17th ACM SIGKDD international
conference on Knowledge discovery and data mining, 448–
456. ACM.
[Wang, Shi, and Yeung 2017] Wang, H.; Shi, X.; and Yeung,
D.-y. 2017. Relational Deep Learning : A Deep Latent Vari-
able Model for Link Prediction. AAAI.
[Wang, Wang, and Yeung 2015] Wang, H.; Wang, N.; and
Yeung, D.-Y. 2015. Collaborative Deep Learning for Rec-
ommender Systems. KDD 1235–1244.
[Wu et al. 2016] Wu, Y.; DuBois, C.; Zheng, A. X.; and Es-
ter, M. 2016. Collaborative Denoising Auto-Encoders for
Top-N Recommender Systems. Proceedings of the Ninth
ACM International Conference on Web Search and Data
Mining - WSDM ’16 153–162.
[Ying et al. 2016] Ying, H.; Chen, L.; Xiong, Y.; and Wu, J.
2016. Collaborative deep ranking: A hybrid pair-wise rec-
ommendation algorithm with implicit feedback. Paciﬁc-Asia
Conference on Knowledge Discovery and Data Mining 9652
LNAI:555–567.

Neural Ideal Point Estimation Network

Kyungwoo Song, Wonsung Lee, and Il-Chul Moon
Korea Advanced Institute of Science and Technology
291 Daehak-ro, Yuseong-gu
Daejeon 34141, South Korea
{gtshs2,aporia,icmoon}@kaist.ac.kr

9
1
0
2
 
r
p
A
 
6
2
 
 
]
I
S
.
s
c
[
 
 
1
v
7
2
7
1
1
.
4
0
9
1
:
v
i
X
r
a

Abstract

Understanding politics is challenging because the politics
take the inﬂuence from everything. Even we limit ourselves
to the political context in the legislative processes; we need
a better understanding of latent factors, such as legislators,
bills, their ideal points, and their relations. From the mod-
eling perspective, this is difﬁcult 1) because these observa-
tions lie in a high dimension that requires learning on low di-
mensional representations, and 2) because these observations
require complex probabilistic modeling with latent variables
to reﬂect the causalities. This paper presents a new model to
reﬂect and understand this political setting, NIPEN, includ-
ing factors mentioned above in the legislation. We propose
two versions of NIPEN: one is a hybrid model of deep learn-
ing and probabilistic graphical model, and the other model
is a neural tensor model. Our result indicates that NIPEN
successfully learns the manifold of the legislative bill texts,
and NIPEN utilizes the learned low-dimensional latent vari-
ables to increase the prediction performance of legislators’
votings. Additionally, by virtue of being a domain-rich proba-
bilistic model, NIPEN shows the hidden strength of the legis-
lators’ trust network and their various characteristics on cast-
ing votes.

Introduction
Recent developments in machine learning have enabled a
deeper understanding of human behavior in diverse contexts.
These advances include divulging intentions and sentiments
in dialogs (Bertero et al. 2016); predicting purchases from
online markets (Chong et al. 2017); recommending movies
to friends (Shah, Rao, and Ding 2017); and discovering so-
cial network links between individuals (Guo, Zhang, and
Yorke-Smith 2015). The recent machine learning models
provide the contexts of these behaviors, which have been
regarded as the latent aspects of human behavior.

One latent modeling of human behavior can be a form of
complex Bayesian probabilistic models, a.k.a. probabilistic
graphical model (PGM). The modelers used graphical nota-
tions, embedding the probabilistic variables and their causal-
ities, to represent the key factors and their relations. For in-
stance, latent Dirichlet allocation (LDA) models the genera-
tive process of documents, i.e. the composition of topics at

Copyright c(cid:13) 2018, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

large, a main topic of documents, and a word selection when
describing a topic (Blei, Ng, and Jordan 2003).

Another effort in modeling the latent variable is improv-
ing the quality of the latent representation of the data. While
the above probabilistic models focused on the contextual
modeling, the latent variables reside in a high dimensional
and nonlinear space, so the learning of the latent variables
have been limited. For example, the stacked de-noising au-
toencoder (SDAE) (Vincent et al. 2010) learns this mani-
fold space through encoding the noised inputs into the low
dimensional latent representations; and reconstructing the
original inputs with the latent representations with neural
network layers. Further advances have made through casting
this autoencoding mechanism to the variational inference
approaches, and a variational autoencoder (VAE) (Kingma
and Welling 2014) optimizes the variational distribution of
the latent representations with neural networks.

Supported by the two research advances, one distinct re-
search direction has been merging the latent representation
learning and the probabilistic graphical model on human be-
havior. Collaborative deep learning (CDL) (Wang, Wang,
and Yeung 2015) is one example merging SDAE with a
probabilistic model of matrix factorization that often used
to explain and predict the human behavior of recommen-
dations. Whereas CDL gives a clear passway on how we
can further develop various models of human behavior with
support from the deep learning, different application do-
mains require different latent modeling, so the model struc-
ture needs to be further customized and expanded.

This paper introduces Neural Ideal Point Estimation Net-
work (NIPEN) which models the generative process of po-
litical voting by estimating ideal points in diverse legisla-
tive aspects with learning the low dimensional representa-
tions from neural networks. Speciﬁcally, we propose two
versions of NIPEN. The ﬁrst version, NIPEN-PGM is a
hybrid model by representing the contextual causalities as
a PGM, and by learning the low dimensional representa-
tions with multi-layered perceptron (MLP) autoencoders,
i.e. SDAE and VAE. The second version, NIPEN-Tensor, is
a neural tensor model that substitutes the PGM part with the
neural tensor model. NIPEN-Tensor could be viewed as a
generalized version of NIPEN-PGM. NIPEN-Tensor mod-
els the legislative voting with the tensor composition and
the nonlinear operations between diverse legislative factors

Figure 1: The summarized procedure of NIPEN. NIPEN predicts the votes with the combination of contents and network
analyses. We can interpret not only an individual legislator’s ideal points but also trust networks between legislators

while NIPEN-PGM assumes the marginalization and the lin-
earized operation in the same modeling part.

Second, NIPEN is the most comprehensive model in the
latent modeling of the political domain. Assuming that we
model a voting process of legislators, NIPEN is the ﬁrst
model of unifying 1) the voting behavior, 2) the network in-
ﬂuence between congressmen, 3) the political ideal point of
bills and congressmen, 4) the textual topic of bills, and 5) the
relative strength of network inﬂuence and ideal points when
casting a vote. Some of these latent variables have been seen
in other models, (Gerrish and Blei 2012; Gu et al. 2014;
Chaney, Blei, and Eliassi-Rad 2015), but not as the uni-
ﬁed model to depict a whole political picture. Since di-
verse factors, such as the contents of the bill and the hu-
man relations, greatly inﬂuence the voting (Cohen and Mal-
loy 2014), an effective modeling of the legislative voting re-
quires an integrated model, such as NIPEN. We show that
NIPEN recorded signiﬁcant performance improvements in
all metrics compared to existing models. We also show vari-
ous qualitative analyses that can only obtained via this com-
prehensive model. The entire procedures and analyses of
NIPEN is summarized by Figure 1.

Previous Research

Modeling Political Network and Ideal Points

Network analyses and ideal point estimation have been
widely studied in computer science and quantitative polit-
ical science for its importance. In the line of political net-
work analyses, most studies analyzed co-sponsorship data
(Faust and Skvoretz 2002; Fowler 2006). Faust and Skvoretz
(2002) clariﬁed the topological structures in the network of
the U.S. Senate (1973-1974), and they found that the net-
work among U.S. Senator in 93rd Congress is O-star, I-
star and Trans structure (Faust and Skvoretz 2002). Fowler
(2006) inferred the relationship in U.S. Congress (1973-
2004) by measuring the centrality to ﬁnd the most central
legislators (Fowler 2006). In the community of ideal point
estimation, Poole and Rosenthal (1985) proposed a nonl-
inear logit model to account for political choices of legis-
lators (Poole and Rosenthal 1985). However, it was a one-
dimensional estimation, and the analysis could not identify

what the ideal dimension stands for. To overcome the lim-
itation, Clinton et al. (2004) proposed a multi-dimensional
ideal point estimation model, but these models still remained
at the simple logit model extensions (Heckman and Snyder
Jr 1996; Clinton, Jackman, and Rivers 2004).

With the advance of topic modeling, multi-dimensional
ideal point models were developed, and these models pro-
vide more accurate interpretations on the ideal points. Ger-
rish and Blei (2012) proposed an issue-adjusted model (Ger-
rish and Blei 2012) with the labeled LDA (Ramage et al.
2009), and Yupeng et al. (2014) proposed a topic-factorized
ideal point model (TFIPM) (Gu et al. 2014) with probabilis-
tic latent semantic analysis (PLSA) (Hofmann 1999) to esti-
mate the ideal points of legislators based on roll-call data.
Further extensions of TFIPM have made through includ-
ing available domain data. For instance, Islam et al. (2016)
proposed SCIPM by including co-sponsorship networks be-
tween judges in the supreme court (Islam et al. 2016). These
works have remained in the extension of the probabilistic
graphical model without the innovation from the deep learn-
ing community, which our work extends 1) the probabilis-
tic graphical model with variational autoencoders and 2) the
neural tensor model for the causality modeling of the leg-
islative voting.

Collaborative Filtering and Deep Learning
Collaborative Filtering is a recommendation algorithm that
considers the relationship between users and items (Koren,
Bell, and Volinsky 2009). One of representative approach is
a matrix factorization which factorizes the rating matrix as
user latent and item latent factors.Recently, the deep learn-
ing has initiated two theoretic developments. First, the ma-
trix factorization itself is a low-dimensional representation
method because of its latent vector learning, so does the au-
toencoding in the deep learning. For example, Sedhain et
al. (2015) proposed Autorec (Sedhain et al. 2015), a basic
autoencoder based CF algorithm, and Autorec outperforms
other state-of-the-art MF algorithms like LLORMA (Lee et
al. 2013). Wu et al. (2016) expand Autorec by concatenating
a user latent variable to the rating input information in the
encoder part of Autorec (Wu et al. 2016). Li et al. (2015)
adopted two autoencoders corresponding to users and items

(Li, Kawale, and Fu 2015), and they showed the interac-
tion mechanism between the two autoencoders by using the
marginalized SDAE (Chen et al. 2012). Second, the matrix
factorization is related to the low-dimensional feature rep-
resentation by adding the representation of the model as the
distilled version of the side information. For instance, Wang
et al. (2015) proposed a collaborative deep learning (CDL)
which combines SDAE with MF (Wang, Wang, and Yeung
2015). Furthermore, Ying (2016) proposed a model of col-
laborative deep ranking which combines ranking with algo-
rithm and SDAE (Ying et al. 2016). Wang et al. (2017) pro-
posed the relational deep learning with SDAE to link predic-
tion between items (Wang, Shi, and Yeung 2017).

Method
This section introduce the detailed descriptions of NIPEN-
PGM and NIPEN-Tensor in turn. Appendix A formulates
the assumptions and the research questions, and Appendix
C enumerates all symbols in this study.

NIPEN with Probabilistic Graphical Model and
Autoencoders
Figure 2 describes the model structure of NIPEN-PGM. We
start the detailed description from the bill low dimension
modeling part, which is the bill plate with the d ∈ D sub-
script. We apply either VAE or SDAE to learn the low di-
1 with the observed
mensional representation, or topic, of zdk
bill text wdv. zdk can be extracted through the probabilistic
encoder, qφ with parameter φ and decoder, pθ with param-
eter θ which is further described in Appendix B. The topic
representation of bills has two components: the bill latent
ydk and the latent offset ξdk, and we model the combination
of the two component as the below.

ydk = ξdk + zdk,

ξkd ∼ N (0, λ−1
y )

Since the bill itself and the bill text may have two differ-
ent latent variables, ξdk becomes the offset between the bill
latent variable and the bill text latent variable, or topic.

From the deﬁned bill latent ydk, we model how the bill
latent generates the voting observation rud. Here, u ∈ U is
the dimension of the legislators. We assumed that a legislator
cast votes considering three latent factors: the bill latent ydk,
the bill ideal point adk, and the legislators’ ideal point xuk.

adk ∼ N (0, λ−1

u ),

xuk ∼ N (0, λ−1
u )

Now, we deﬁne NIPEN-PGM without the network fac-
tor. This voting procedure is modeled as Eq. (1) where ηd
is a bias value of a legislative bill, and σ is a sigmoid func-
tion. Eq. (1) is designed to increase the probability of vot-
ing YEA when the ideal points of the bill and the legislator
have the same sign; and when an ideal-aligned dimension
of the bill latent variable is high. Additionally, ηd indicates
whether the bill is more broadly accepted or not, regardless
of ideal points.

p(rud = 1) = σ(

ydkadkxuk + ηd)

(1)

K
(cid:88)

k=1

1d, u, and k mean each document, legislator, topic respectively.

Small subscripts indicate the row and column index in order.

Figure 2: Graphical model representation of NIPEN-PGM

Finally, we add the network component to NIPEN-PGM.
The interest of a particular legislative group could be an im-
portant factor in the voting process. Following this impli-
cation, we modeled the network between two legislators as
below. Before the network modeling, we limited the network
inﬂuence between the legislators sharing the same term, and
this neighbor set, Iu, is deﬁned as a neighborhood of legis-
lator, u.

τuu(cid:48) ∼ N (0, λ−1

τ ) αu ∼ N (0, λ−1

α ) βu ∼ N (0, λ−1
α )
The legislator u’s voting is affected by two terms. The ﬁrst
term is the ideal alignment modeled in Eq. (1). The second
term is the voting record of the neighbor legislator, ru(cid:48)d, and
the second term is also weighted by the network strength,
τuu(cid:48), between the two legislators. Since this is a linear sum-
mation, τuu(cid:48) will model the degree of voting agreement be-
tween two legislators. These two terms are uniﬁed with scal-
ing parameters αu and βu. The purpose of modeling αu and
βu is analyzing whether a certain legislator is inﬂuenced
more either from the bill or from the network in casting
votes.

Eq. 2 is the overall voting formulation of NIPEN-PGM.

p(rud = 1) = σ(αu(

ydkadkxuk + ηd)

+ βu(

τuu(cid:48)ru(cid:48)d))

(2)

(cid:88)

k
(cid:88)

u(cid:48)∈Iu

NIPEN with Neural Tensor Model
Existing models, including NIPEN-PGM, do not directly
model the relationships between the topics, which means
that there is no cross-operiation between the dimension of
K. Some cases, i.e. correlated topic model (Lafferty and Blei
2006), model the correlation between topics via the logistic
normal distribution, but this is not an operation modeling of
topic inﬂuences, rather the variable modeling of topic co-
variance.

The recent introduction of neural tensor models (Socher
et al. 2013) enable the cross-operations between the latent

topic dimension. This topic cross-operation can model the
legislator’s ideal point non-linear inﬂuences when two top-
ics are combined within a bill. Here, we propose NIPEN-
Tensor to incorporate the cross-topic inﬂuence in casting a
vote, which could not be modeled in NIPEN-PGM. NIPEN-
Tensor and NIPEN-PGM are similar in the parts of docu-
ment and inﬂuence network modeling. The only different
part is the voting decision modeled as Eq. 2 which multiplies
the factors per a topic and marginalizes. NIPEN-Tensor con-
siders that the multiplication per a topic should be changed
to consider the nonlinear effect from the topic set, not a sin-
gle topic. Therefore, we represent the previous topic-wise
multiplcaiton of ydkadkxuk as a tensor E, and this tensor
still treats the topic dimension to be independent. Then, we
apply a fully-connected layer to cross-operate the topic di-
mension of E, and the neural network has C that is the out-
put of the cross-operation. The overall structure and formu-
lation for the NIPEN-Tensor are shown in Figure 3 and Eq.
3, respectively.

Eudk = xukydkzdk
(cid:88)

(cid:101)Eudl = tanh(

k

EudkW (T1)

kl + b(T1)

l

)

Cud =

(cid:101)EudlW (T2)

l1 + ηd

(cid:88)

k
(cid:88)

u(cid:48)∈U

Nud =

τuu(cid:48)vu(cid:48)d

(3)

W (T1), b(T1), W (T2) are weights and biases applied to Eudk,
(cid:101)Eudl tensor. In particular, W (T1) ∈ RK×K models the cor-
relation between topics, and W (T2) ∈ RK×1 models the
inﬂuence of each topic on the voting. Since the signs of
xuk, ydk, and adk are important, we use tanh instead of
ReLU (Rectiﬁed linear unit) to transform the outputs non-
linearly.

Parameter Inference of NIPEN

The parameters of both NIPENs are enumerated in the pre-
vious section, and we learn the parameters in two folds:
learning the autoencoder to represent the bill topic and
the CF, alternatively. The ﬁrst set of parameters related
to autoencoders is ψ(1) = (θ, φ); and the second set
of parameters related with the legislative-CF is ψ(2) =
(y, a, η, x, W (T1), W (T2), b(T1), τ, α, β).

The overall inference algorithm of both NIPENs fol-
lows the maximization of variational evidence lower bound
with two assumptions. Following CDL, the ﬁrst assump-
tion is connecting the autoencoder and CF through ξ, and
the strength is controlled by the variance of ξ, which is λy.
When learning ψ(1), we apply the stochastic gradient varia-
tional Bayes (SGVB) estimator.

Second, we assumed that the variational distribution of
ψ(2) as a point mass for simplicity, so the parameters of
the variational distribution are updated by each casted vote

Figure 3: Neural network view of NIPEN-Tensor. The con-
tents part is connected with the blue line (with content scal-
ing parameter αu ), and the network part is connected with
the purple line (with the network scaling parameter βu ).

record, which is traditional Bayesian belief updates. Speciﬁ-
cally, the likelihood of the posterior is presented as the lower
bound in the below. Then, the lower bound, which has real-
ized values of qφ(z|w), pθ(z) and an observed input, has
only ψ(2), so the gradient method can ﬁnd the maximum a-
posteriori, or MAP, of ψ(2).

As a summary, the objective function of both NIPENs is

LN IP EN = −DKL(qφ(z|w)(cid:107)pθ(z)) +

log pθ(w|zl)

1
L

L
(cid:88)

l=1

+

+

−

λf
2

λf
2

λy
2

(cid:88)

(u,d),rud(cid:54)=0
(cid:88)

(u,d),rud(cid:54)=0

1 + rud
2

1 − rud
2

log p(rud = 1)

log p(rud = −1)

D
(cid:88)

d=1

(cid:107)yd − zd(cid:107)2

2 −

((cid:107)a(cid:107)2

F + (cid:107)x(cid:107)2
F )

λu
2

−

λτ
2

F ) −

((cid:107)τ (cid:107)2

((cid:107)α(cid:107)2

2 + (cid:107)β(cid:107)2
2)

λα
2
Similar to (Wang and Blei 2011; Wang, Wang, and Yeung
2015), the parameters related with the autoencoder and the
legislative-CF are infered by coordinate ascents which maxi-
mizes LN IP EN . For legislative-CF related parameters ψ(2),
we take the gradient of LN IP EN w.r.t each parameters given
the current θ and φ. Given the legislative-CF related param-
eters ψ(2), we infer the autoencoder related parameters by
computing ∇ψ(1)LN IP EN . We utilized the Tensorﬂow li-
brary (Abadi et al. 2016) to optimize the parameters.

NIPEN-PGM and NIPEN-Tensor are only different in the
vote casting process, and the related term in the objective
function is the third and the fourth terms with log p(rud =
1). These terms could be computed as the conventional gra-
dient descent in two variants of NIPEN, so there is no change

p(rud = 1) = σ(αuCud + βu

Nu(cid:48)d)

speciﬁed as follows:

(cid:88)

u(cid:48)∈Iu

in the learning mechanism.

In the original deﬁnition, the network, τ , is a |U |-by-|U |
matrix, and the number of parameters becomes large given
O(U 2). To reduce the squared complexity, τ is approxi-
mated by the product of (cid:101)τ1 and (cid:101)τ2 where (cid:101)τ1 ∈ RU ×G, (cid:101)τ2
∈ RG×U . We assume that (cid:101)τ1 and (cid:101)τ2 are not related. G can
be interpreted as the number of groups containing the legis-
lators. This approximation results in O(GU ) for the network
parameter inference.

Table 1: Attributes of Politic2013 and Politic2016 dataset

# of legislators (|U |)
# of bills (|D|)
# of votings (|D|)
# of House
# of Senator
# of Republican
# of Democrat
# of unique word (|V |)

Average # of unique word
(cid:80)
d,v(Iwdv >0)
for each bill (

)

V

# of bills less than
10 unique words
Period
Source
Data type

Politic2013
1,540
7,162
2,779,703
1,299
241
767
767
10,000

Politic2016
1,537
7,975
2,999,844
1,266
271
778
752
13,581

192.77

378.66

65

0

1990-2013
THOMAS

1989-2016
GovTrack

1 (YEA), -1 (NAY)

Results

Datasets on Political Ideal Points
We used two roll-call datasets, whose source is explained in
Appendix D. Table 1 provides the descriptive statistics of the
two datasets: Politic2013 and Politic2016. Politic2013 limits
the number of a unique word to 10,000, and there are 65 bills
which have less than ten words, while Politic2016 chooses
13,581 unique words, and there are no bills with less than ten
words. Politic2013 is a more sparse dataset than Politic2016
in the ratings and the vocabulary sizes.

Baselines and Implementation Details
The variations of NIPEN were compared to ﬁve baseline
models as follows:
• TFIPM: Topic Factorized Ideal Point estimation Model
(Gu et al. 2014) is specialized in politics to analyze the
roll-call data.

• Autorec: A simple autoencoder model which is utilized to
predict the ratings. Autorec (Sedhain et al. 2015) encodes
and reconstructs the rating matrix. We used Item-based
Autorec.

• Trust SVD: Trust SVD (Guo, Zhang, and Yorke-Smith
2015), a type of trust-based matrix factorizations, is built
on SVD++ with trust information.

• CDAE: Collaborative Denoising Autoencoder (Wu et al.
2016) used a denoising autoencoder with user latent vari-
ables.

• CDL: Collaborative Deep Learning (Wang, Wang, and
Yeung 2015) used the deep learning and the CF, jointly.
CDL improves performance by using document informa-
tion additionally, and CDL uses SDAE to learn document
manifold.
Appendix E provides detailed speciﬁcations for replica-
tions of this work, and Appendix F illustrates the sensitivity
analysis of λy and λτ .

Quantitative Evaluations
We performed the ﬁve-fold cross-validation to quantita-
tively evaluate the variations of NIPENs, and the perfor-
mance measures are RMSE, MAE, accuracy, and nega-
tive average log-likelihood (NALL) measures. We compared
nine models: ﬁve baseline models in section 4.2, and four
NIPEN variations, which are NIPEN-PGM(SDAE), NIPEN-
PGM(VAE,approx.), NIPEN-PGM(VAE), and NIPEN-
Tensor. NIPEN-PGM has three variants by choosing either
SDAE or VAE as the autoencoder for the text modeling, and
by choosing either using the whole matrix for the inﬂuence
or the low-rank approximated matrix of the inﬂuence.

Table 2 statistically conﬁrms that the best performance
model in every metric is always a variation of NIPEN, which
is conﬁrmed with statistical signiﬁcance. In detail, ﬁrst,
we compare NIPEN-PGM(VAE) and NIPEN-PGM(SDAE),
and their performance gap is larger in Politic2013 than in
Politic2016 which is a relatively sparse setting as shown
in Table 1. We conjecture that NIPEN-PGM(VAE) is bet-
ter in handling the sparse dataset than NIPEN-PGM(SDAE).
Second, NIPEN-Tensor is a model that considers the cor-
relation between topics, and NIPEN-Tensor may have a
better performance when a bill text has multiple topics
with complex and rich textual information. As discussed
in Section Datasets on Political Ideal Points, Politic2016
has richer textual information than Politic2013, and we con-
jecture that this is the reason why NIPEN-PGM(VAE) in
Politic2013 and NIPEN-Tensor in Politic2016 show better
performances. Third, while the accuracy improvement is rel-
atively small, the improvements on other metrics, partic-
ularly RMSE and MAE, are relatively large. Already, the
baseline models achieve the accuracy higher than 95%, so
the accuracy improvement could seem minimal. However,
our likelihood estimation of YEA and NAY is considerably
improved given the RMSE and the MAE improvement.

Qualitative Evaluations
In addition to the quantitative results, we interpret the latent
variables of NIPEN-PGM(VAE) on Politic2016. First, to
comprehend the dataset and the qualitative results, we com-
puted the word-topic matrix from well-learned VAE vari-
ables, ψ1, as shown in Table 3. This table provides a snap-
shot of topics in the bills. Then, we relate this topic to the bill
ideal points, adk. The latent dimension, k, becomes the com-
mon dimension of an ideal point value and a topic weight
for each topic in the bill. Figure 5 shows an example of the
topic weight as the bar chart and the ideal point value as the
line chart. The illustrated bill, or H.Res.794 (114th), has the
largest absolute value, |adk(cid:101)zdk| in a ’Business and Finance’
topic where (cid:101)zdk denotes the normalized zdk.

Table 2: Quantitative evaluation on Politic2013 and Politic2016 datasets. Two-standard deviation is shown in parentheses

Politic2013

Politic2016

RMSE
0.2253
(±0.0007)
0.2110
(±0.0099)
0.2059
(±0.0007)
0.1872
(±0.0002)
0.1834†
(±0.0008)
0.1801**
(±0.0014)

MAE
0.1399
(±0.0011)
0.0975
(±0.0136)
0.0831
(±0.0009)
0.0682†
(±0.0002)
0.0786
(±0.0019)
0.0591**
(±0.0012)

Accuracy
0.9408
(±0.0003)
0.9411
(±0.0056)
0.9428
(±0.0006)
0.9526
(±0.0003)
0.9554†
(±0.0004)
0.9566**
(±0.0006)

NALL
0.1866
(±0.0011)
0.1466
(±0.0177)
0.1450
(±0.0009)
0.1213
(±0.0007)
0.1147†
(±0.0018)
0.1155
(±0.0018)

RMSE
0.2168
(±0.0011)
0.2031
(±0.0015)
0.1977
(±0.0037)
0.1794
(±0.0010)
0.1780†
(±0.0013)
0.1779
(±0.0005)

MAE
0.1353
(±0.0010)
0.0886
(±0.0110)
0.0802
(±0.0052)
0.0625†
(±0.0006)
0.0769
(±0.0012)
0.0560**
(±0.0004)

Accuracy
0.9463
(±0.0009)
0.9454
(±0.0007)
0.9475
(±0.0023)
0.9566
(±0.0005)
0.9583†
(±0.0008)
0.9581
(±0.0003)

NALL
0.1782
(±0.0015)
0.1349
(±0.0125)
0.1357
(±0.0046)
0.1121
(±0.0016)
0.1106†
(±0.0017)
0.1173
(±0.0015)

0.1804
(±0.0089)

0.0611*
(±0.0065)

0.9565
(±0.0047)

0.1165
(±0.0086)

0.1791
(±0.0076)

0.0599
(±0.0057)

0.9571
(±0.0039)

0.1152
(±0.0070)

0.1753**
(±0.0007)
0.1818**
(±0.0008)
4.41%

0.0588**
(±0.0008)
0.0663**
(±0.0003)
13.78%

0.9587**
(±0.0006)
0.9556**
(±0.0003)
0.35%

0.1075**
(±0.0011)
0.1155
(±0.0020)
6.27%

0.1753**
(±0.0017)
0.1729**
(±0.0015)
2.87%

0.0570**
(±0.0012)
0.0608**
(±0.0006)
10.40%

0.9590**
(±0.0010)
0.9600**
(±0.0008)
0.18%

0.1112
(±0.0024)
0.1057**
(±0.0022)
4.43%

Trust SVD

Autorec

CDAE

TFIPM

CDL

NIPEN-
PGM(SDAE)
NIPEN-
PGM(VAE,
approx.)
NIPEN-
PGM(VAE)
NIPEN-
Tensor
Improvement

NALL : Negative Average Log Likelihood
Improvement : Relative improvement of the best version of NIPEN compared to the best model, which is marked by †, among the baselines
P ∗ < 0.05; P ∗∗ < 0.01 (Student’s one-tailed t-test against the † model)

Table 3: Selected top-ﬁve words for each topic. The number
of listed topics was set to ten.

Topic Label
Business and
Finance
Disasters
Management
International
Relationship

Racism

Defense

Agriculture

Social

Health

Foregin

1

2

3

4

5

6

7

8

9

International
Trade

10

Topic Words
Forproﬁt, Nonrefundable, Govern,
SBDC, Financings
Stabilization, Homeless, Disasters,
Alerts, USPS
Kuwait, Distributes, Lawsuits,
Threatens, Spain
Contrary, Black, Compared,
Tuskegee, Reagan
United, Soviet, Antiterrorist, IDA,
NGA
Pima, Climate, Cropland, Bush,
Badlands
Contribute, Donors, Childcare,
Resettlement, DRR
FEHBP, Heroin, Stability,
Musculoskeletal, Transplantation
Agency, Lantos, FPI, fusion,
division
Clearinghouses, ESF,
Discrepancies, Repay, Charging

Figure 4: Individual legislators’ ideal points for each topic

This bill ideal point is correlated with the legislator ideal
point, xuk, to generate the vote records. Here, the dimen-
sion, k, is the same latent dimension of the topic in Table
3, and we provide the scatter plot of the legislators’ ideal
points per topic in the Figure 4. The prior mentioned bill
(H.Res.794 (114th)) considers the appropriations for ﬁnan-
cial services and general government, and the major topic is
Business and Finance, and the bill ideal point in Business
and Finance is -1.217. Together, the vote casting will be de-
termined by the legislators’ view on Business and Finance,
and this topic shows the greatest disagreement between the
Republicans and the Democrats according to the Figure 4. In
the real world, the voting results were same as expected: 1)
the voting was very partisan, 92.2% Republican voted YEA

Figure 5: Topic proportion and ideal points of H.Res.794
(114th) bill

Table 4: Top-ﬁve legislators who are affected by contents or
network factors a lot. The scaling variable (αu for contents
based, and βu for network based), political party, and district
of the member are indicated in parentheses.

Contents based
Ron Paul
(0.260, R, TX)
Virgil H. Goode
(0.220, R, VA)
Dennis J. Kucinich
(0.218, D, OH)
Henry Cuellar
(0.198, D, TX)
Walter B. Jones
(0.195, R, NC)

1

2

3

4

5

Network based
Ralph M. Hall
(0.304, R, TX)
Nick J. Rahall II
(0.250, D, WV)
Peter A. DeFazio
(0.247, D, OR)
Don Young
(0.228, R, AK)
Jim Sensenbrenner.
(0.227, R, WI)

action between the contents and the network parts. We
used two scaling variables αu and βu, which controls the
strengths of contents factor and network factor, respectively.
Table 4 shows the top-ﬁve legislators who were affected by
either contents or network factors. Since the variations of
NIPEN is an integrated model of network modeling as well
as the textual bill modeling, the NIPENs should better per-
form than the baseline models, i.e. CDL, which only models
the texts, and Figure 7 conﬁrms this hypothesis.

Figure 6: Trust network between legislators

and the 90.3% Democrat voted NAY.

The second qualitative interpretation focuses on the legis-
lators’ network. We selected 12 legislators who have either
strongly positive or negative relationships with each other,
shown in the Figure 6. In general, the legislators have a
strong positive relationship when they have the same dis-
trict and the party. Among the top-ﬁve positive relation-
ships, four of them have the same party and the same dis-
trict, i.e. ’Thomas E. Petri↔Jim Sensenbrenner’, ’Nick J.
Rahall II→Robert E. Wise’, and ’Nick J. Rahall II→Alan B.
Mollohan’2. The closest relations are ’Thomas E. Petri’ and
’Jim Sensenbrenner’. They were both republican representa-
tives from Wisconsin, and they share similar voting patterns.
They have voted 6,288 times for the same bill, and the 5,764
votes were same (91.6%). Especially, they voted NAY for
H.R.730 (111th) which is a ”suspension of the rules”, and
397 legislators votes YEA. For H.R.6063 (110th), ’Thomas
E. Petri’ and ’Jim Sensenbrenner’ voted NAY together while
94.4% legislators voted YEA. We report further analyses in
Appendix G.

The third qualitative analysis concentrates on the inter-

2τuu is asymmetric matrix. arrow(’→’) indicates the direction

of the trust

Figure 7: Accuracy of top ﬁve legislators who are affected
by network factor

Conclusion

We proposed two versions of machine learning models,
NIPEN-PGM and NIPEN-Tensor, to analyze the ideaology
in the legislation process. The variations of NIPEN show the
state-of-the-art performance in all measures on Politic2013
and Politic2016. Furthermore, NIPEN provides various in-
terpretations in why YEA or NAY is casted by illustrating 1)
the ideal point estimation of individual legislators and bills;
2) the trust network between legislators; and 3) the content
and network inﬂuence for each legislator. These supervised
and unsupervised tasks could be critical insights into quan-
titatively understanding politics in the legislative process.

Appendix A. Problem Formulation

In general, the inﬂuence on legislative voting originates from
1) the individual ideal points of the legislator, 2) the contents
of the bill, and 3) the interests of a political group that a leg-
islator belongs to. We operationalize these inﬂuence struc-
ture as the concepts deﬁned in the below.

Deﬁnition 1. Ideal point is a measure of legislator’s prefer-
ence for each topic when we have K topics in our bill texts.
The ideal point for a particular topic k of a particular mem-
ber u is represented by xuk, and it follows N (0, λ−1
u ). The
sign of xuk represents the preferred voting direction (posi-
tive or negative), and the size of |xuk| represents the pref-
erence strength. The ideal point for a particular topic k of a
particular bill d is represented by adk, and its distribution is
N (0, λ−1
u ). The interprestation of adk is same as xuk.

Deﬁnition 2. Contents refer to the bill elements, i.e. text
descriptions, which affect the voting result. The latent repre-
sentation of the contents is ydk which is the addition of zdk,
the topic of the bill; and ξdk, the deviation of the bill from
the topic of the bill text.

Deﬁnition 3. Network means the collection of relationships
between legislators whose vote affect the other’s vote. The
strength of network relationships is modeled as τuu(cid:48), which
follows N (0, λ−1
τ ). The sign of τuu(cid:48) indicates the voting
alignment between u and u(cid:48) legislators, and |τuu(cid:48)| means
its alignment strength. This study assumes that the network
relationships are asymmetric bidirectional, and only the leg-
islators in the same term affect each other.

Deﬁnition 4. Scaling parameters mean the inﬂuence of
contents and networks when a legislator votes. αu is a con-
tent scaling parameter, and βu is a network scaling parame-
ter. Each scaling parameter is a |U |-dimensional vector, fol-
lowed by N (0, λ−1
α ). This study assumed that the degree of
inﬂuence on the contents and the network would be different
per each legislator.

Now, given the above deﬁned concepts, we enumerates

the research questions to test with NIPEN.

Problem 1. NIPEN can predict the results of the voting by
inferring the bill topic, the bill ideal points, the legislator
ideal points, and the network relationships between the leg-
islators.

Problem 2. NIPEN provides the interpretation on the vot-
ing results of the bill. For example, NIPEN illustrates the
interpretable latent information from the bill topic, the bill
ideal point, and the legislator ideal point taking into account
the correlation between the topics.

Problem 3. NIPEN can 1) analyze the trust between legis-
lators (individual unit), and 2) the trust network comparison
between parties (group unit).

Problem 4. NIPEN provides the behavioral analyses on leg-
islators from the voting motivation perspective, which could
be motivated by either legislator ideal point or network rela-
tionship.

Appendix B. Document Modeling
Autoencoders

Appendix B.1. Variational Autoencoder (VAE)
NIPEN extracts the topics of the legislative bills with
VAE (Kingma and Welling 2014) which is a type of
deep generative model. VAE learns the disentangled and
low-dimensional representation of high dimensional data
through the probabilistic encoding, or qφ(z|w); and the
probabilistic decoding, or pθ(w|z). Therefore, the original
objective function of VAE is composed of the linear sum of
corresponding two terms. The ﬁrst term originating from the
encoding is the KL divergence between the probabilistic en-
coding and the prior for latent variable, or pθ(z); and this
term enforces the regularization. The second term is the ex-
pectation on the negative reconstruction error, and this term
is related to the decoding part. By putting both terms to-
gether, the objective function follows as Eq. (4).

L(θ, φ) = −DKL(qφ(z|w)(cid:107)pθ(z)) + Eqφ[log pθ(w|z)]

(4)
Given the high variance over φ, a direct optimization of
Eq. (4) is not efﬁcient. Hence, Kingma and Welling (2014)
suggested the re-parametrization trick as follows: 1) Draw
(cid:15)l ∼ N (0, I), and 2) Optimize the mean and standard devi-
ation of qφ(z|w), and 3) Compute zl = µ(w) + σ(w) (cid:12) (cid:15)l.
From the trick, the objective function of VAE is turned into
Eq. (5) where L is the number of samples.

(cid:101)L(θ, φ) = −DKL(qφ(z|w)(cid:107)pθ(z)) +

log pθ(w|zl)

1
L

L
(cid:88)

l=1

(5)

Appendix B.2. Stacked Denoising Autoencoder
(SDAE)
NIPEN-PGM(SDAE) extracts the topics of the legislative
bills with SDAE (Vincent et al. 2010). SDAE learns the
disentangled latent feature through the encoding and decod-
ing with bottleneck and corrupted input. SDAE use the cor-
rupted input wc instead of the original input w to force
the relationship learning. The SDAE is optimized for the
purpose of reconstructing the w resulting from the encod-
ing process(fe) through the encoder weight (W (e)) and the
decodingfd result through the decoder weight (W (d)). The
objective function follws as Eq. (6)

(cid:13)
(cid:13)
2
(cid:13)fd(fe(w, W (e)), W (d)) − wc)
(cid:13)
(cid:13)
(cid:13)
2

(6)

Appendix C. Notations

Table 5 summarizes all symbols used in this study.

Appendix D. Dataset Descriptions

is Politic2013, and it was collected
The ﬁrst dataset
from THOMAS3, and (Gu et al. 2014). For an additional
experiment, and for more up-to-date analyses, we col-
lected a new roll-call dataset, Politic2016 from GovTrack

3http://thomas.loc.gov/home/rollcallvotes.html

Table 5: Notation description

Symbol
D
V
U (= U (cid:48))
K
G
Iu
wdv
zdk
ydk
adk
ηd
rud
xuk
αu
βu
τuu(cid:48)
(cid:101)τ1, (cid:101)τ2
ξ
(cid:15)
φ(θ)
C(N )
E
W (T ), b(T )

Description
Set of bills
Set of Unique words
Set of legislators
Set of topics
Rank of (cid:101)τ1 and (cid:101)τ2
Other legislators within the same term as u
Frequency of vth token in document d
Topic proportion for each bill and topic
Bill latent vector
Ideal point for each bill and topic
Constant offset for each bill d
Voting record from legislator u to bill d
Ideal point for each legislator and topic
Contents scaling parameter for legislator u
Network scaling parameter for legislator u
Trust network between legislator u and u(cid:48)
Approximated matrix of τuu(cid:48)
Latent offset between zdk and ydk
Random noise vector drawn from N (0, I)
Parameter of encoder (decoder) in VAE
Contents (Network) information
The tensor combined with xuk, ydk, adk
Neural tensor network parameter

.GovTrack provides raw roll-call data, so we processed
the expanded part of Politic2016, manually. For the re-
search community, we released the code and dataset on
https://github.com/gtshs2/NIPEN

Appendix E. Experiment Settings
For TFIPM, we followed the optimal parameters that the au-
thor reported. We set the latent dimension(K), the trade-off
weight, and the regularization weight as 10, 0.8, and 22.4,
respectively. The latent dimension of CDL and NIPENs was
set to ten, equally. For Autorec, the optimal number of the
latent dimension and the regularization parameter are 100
and 0.001, respectively. Trust SVD shows the best perfor-
mance when the weights of CF and trust part are 1,000 and
0.001, respectively, while K is set to 10. For CDAE, we
set the regularization weight, the corruption ratio, and the
number of latent dimension as 0.001, 0.4, and 50, respec-
tively; and the encoder and the decoder activation functions
are sigmoid. For CDL, we ﬁnd that the optimal parameters
of λu,λv,λw,λn, the dropout rate and the activation func-
tions are 0.01, 100, 1, 100, 0.1 and the sigmoid function, re-
spectively. The neural network structure of Autorec, CDAE,
CDL, NIPENs are set to [512,128,K,128,512], equally. Fi-
nally, we set the parameters of NIPENs such as λf = 10,
λy = 10, λu = 0.1, λτ = 1, λα = 1, λn = 1000 G = 3, and
we performed grid searches to ﬁnd the optimized parameters
of NIPENs. Finally, NIPEN-Tensor has the two-layered ten-
sor E in the topic axis.

Appendix F. Hyperparameter Study
This quantitative improvement requires a well-tuned hyper-
parameter setting, illustrated in Figure 8. LN IP EN enumer-
ates multiple hyperparameters, and we found that λy and λτ
are the most important parameters to decide. λy speciﬁes the
causality strength from the bill text latent in VAE to the bill
latent in the legislative CF. The low value of λy will sepa-
rate VAE and CF, but its high value will disrupt the manifold
learning of VAE. Moreover, λτ speciﬁes the regularization
strength from the legislators’ network inﬂuence to the vot-
ing. The small value of λτ will overﬁt the network inﬂuence,
and its large value will limit the learning of network inﬂu-
ence model in CF.

Figure 8: (Top-Left) Accuracy for λy and λτ value, (Top-
Right) RMSE for each λy and λτ value, (Bottom-Left) Ac-
curacy for G value, (Bottom-Right) RMSE for each G value

Appendix G. Results in Network Inﬂuence
Analyses
To examine the network relationships within each party, Fig-
ure 9 illustrates the trust network parameter. A red node rep-
resents a Republican; a blue node stands for a Democrat;
a green solid line indicates an inferred close relationship;
and a purple dotted line indicates an inferred unfriendly re-
lationship. Taking a threshold at 0.1 and looking at τuu(cid:48) with
values greater than 0.1 and less than -0.1 (Figure 9d), John
J. Duncan Jr and Dana Rohrabacher have the greatest net-
work impact given their number of connected legislators in
the Republican party. The commonalities between the two
inﬂuential legislators are 1) being a member of the House of
Representatives; and 2) having been politically active for a
long time (Duncan started as a congressman in Tennessee in
1988 and Laura Baker as a California congressman in 1989.
Especially, Jimmy Duncan is the House’s longest-serving
Republicans.).

We compared and contrasted the network structure of Re-
publicans and Democrats. As shown in Table 6, the network
inﬂuence among the total members is greater in the Demo-
cratic Party given its mean value of |τuu(cid:48)|. However, the Re-

publican party has the higher number of inﬂuential legisla-
tors when we limit the network inﬂuence with thresholds,
i.e. when we limit |τuu(cid:48)| > 0.05 or |τuu(cid:48)| > 0.1 in Table 6.
This suggests that the Democrats have averagely higher and
more equal inﬂuences between the members while the Re-
publicans have a number of authorative inﬂuencers among
the members.

(a) Threshold = 0.03

(b) Threshold = 0.05

Table 6: Comparison of network inﬂuence by each Party

# of pair s.t. τuu(cid:48) > 0.05
# of pair s.t. τuu(cid:48) < −0.05
# of pair s.t. τuu(cid:48) > 0.1
# of pair s.t. τuu(cid:48) < −0.1
Mean of |τuu(cid:48)|
Variance of |τuu(cid:48)|

Republican
58
67
7
3
9.0E-04
2.49E-05

Democratic
49
53
1
3
0.0018
3.38E-05

Table 7: Content and Network scale comparison between the
Party. Average Ranking@K is the average of the ranking of
each legislator, by the party, when the ranking is made up to
the top K legislators, based on scaling parameter (αu βu).

Content (|αu|)

Network (|βu|)

R
6
40
52.87
774.6
0.149

NL@10
NL@100
AR@100
AR@All
Mean value of αu (βu)
R : Republican Party / D : Democratic Party
AR@K : Average Ranking at top K
NL@K : Number of legislators at top K

D
4
60
48.91
762.7
0.148

R
6
42
46
781.4
0.068

D
4
58
53.75
754.9
0.064

Republican Party generally relies on the network, and the
Democratic Party on contents, when they are voting. If we
associate this conclusion with Table 6, we can explain that
a Democratic have more inﬂuence in the network within the
party. However, the proportion of people who are dependent
on the network (including network from their own party and
opposing party) is relatively high in the Republican Party.

(c) Threshold = 0.07

(d) Threshold = 0.1

Figure 9: Network inﬂuence visualization within each party
in December 2016. The top visualizations represent the Re-
publican Party, and the bottom visualizations represent the
Democratic Party. If the network inﬂuence, τuu(cid:48), between
two legislators exceeds the threshold, the relationship is ex-
pressed as a green solid line. If the network inﬂuence, τuu(cid:48),
is less than the threshold, the relationship is noted as a purple
dotted line.

The United States has a two-party system. In order to an-
alyze this reality effectively, contents scaling parameter and
network scaling parameter are analyzed by each party. Com-
paring the mean value of |αu| and |βu| in the Table 7, we
can see that both parties are generally voting rather than net-
works, concentrating on their own politics and the contents
of the bill itself. To compare two political parties relative to
each other based on Average Ranking@100 in Table 7, the

Figure 10: Graphical model representation of NIPEN-PGM

According to the opinion of the reviewers who advised
on the analysis of αu and βu, the distribution of |αu| and
|βu| is shown in Figure 10, and the value of |αu|/|βu| over
time is shown in Figure 11. According to Figure 10, we can
infer that the majority of legislators are voting focusing on

of Roll Call Data. The American Political Science Review
98(2):355–370.
[Cohen and Malloy 2014] Cohen, L., and Malloy, C. J. 2014.
Friends in high places. American Economic Journal: Eco-
nomic Policy 6(3):63–91.
[Faust and Skvoretz 2002] Faust, K., and Skvoretz, J. 2002.
Comparing Networks Across Space and Time, Size and
Species. Networks 32(2002):267–299.
[Fowler 2006] Fowler, J. H. 2006. Connecting the congress:
Political Analysis
A study of cosponsorship networks.
14(4):456–487.
[Gerrish and Blei 2012] Gerrish, S., and Blei, D. M. 2012.
How they vote: Issue-adjusted models of legislative behav-
ior. Advances in Neural Information Processing Systems
25(1):2762–2770.
[Gu et al. 2014] Gu, Y.; Sun, Y.; Jiang, N.; Wang, B.; and
Chen, T.
2014. Topic-factorized ideal point estimation
model for legislative voting network. Proceedings of the
20th ACM SIGKDD international conference on Knowledge
discovery and data mining. ACM, 2014. 183–192.
[Guo, Zhang, and Yorke-Smith 2015] Guo, G.; Zhang, J.;
and Yorke-Smith, N. 2015. TrustSVD : Collaborative Fil-
tering with Both the Explicit and Implicit Inﬂuence of User
Trust and of Item Ratings. Proceedings of the Twenty-ninth
AAAI Conference on Artiﬁcial Intelligence (AAAI) 123–129.
[Heckman and Snyder Jr 1996] Heckman, J. J., and Snyder
Jr, J. M. 1996. Linear probability models of the demand
for attributes with an empirical application to estimating the
preferences of legislators. National bureau of economic re-
search 28(0).
[Hofmann 1999] Hofmann, T. 1999. Probabilistic latent se-
mantic indexing. Proceedings of the 22nd annual interna-
tional ACM SIGIR conference on Research and development
in information retrieval 50–57.
[Islam et al. 2016] Islam, M. R.; Hossain, K. T.; Krish-
nan, S.; and Ramakrishnan, N.
Inferring Multi-
dimensional Ideal Points for US Supreme Court Justices.
Proceedings of the 30th Conference on Artiﬁcial Intelligence
(AAAI) 4–12.
[Kingma and Welling 2014] Kingma, D. P., and Welling, M.
2014. Auto-encoding variational bayes. In Proceedings of
the International Conference on Learning Representations
(ICLR).
[Koren, Bell, and Volinsky 2009] Koren, Y.; Bell, R.; and
Volinsky, C. 2009. Matrix Factorization Techniques for Rec-
ommender Systems. Computer 42(8):42–49.
[Lafferty and Blei 2006] Lafferty, J. D., and Blei, D. M.
2006. Correlated topic models. In Advances in neural in-
formation processing systems, 147–154.
[Lee et al. 2013] Lee, J.; Kim, S.; Lebanon, G.; and Singer,
Y. 2013. Local Low-Rank Matrix Approximation. ICML
28.
[Li, Kawale, and Fu 2015] Li, S.; Kawale, J.; and Fu, Y.
2015. Deep collaborative ﬁltering via marginalized denois-
ing auto-encoder. In Proceedings of the 24th ACM Interna-

2016.

Figure 11: Graphical model representation of NIPEN-PGM

contents rather than network effect. However, since the the
number of element that |βu| > 0.2 is larger than the number
of |αu| > 0.2, we can infer that small number of legislators
are highly dependent on network effect. In addition, Figure
11 shows the change in a |αu/βu| over time, and we can in-
fer that the inﬂuence of contents over networks has become
more important in recent years.

References
[Abadi et al. 2016] Abadi, M.; Agarwal, A.; Barham, P.;
Brevdo, E.; Chen, Z.; Citro, C.; Corrado, G. S.; Davis, A.;
Dean, J.; Devin, M.; and Others. 2016. Tensorﬂow: Large-
scale machine learning on heterogeneous distributed sys-
tems. arXiv preprint arXiv:1603.04467.
[Bertero et al. 2016] Bertero, D.; Siddique, F. B.; Wu, C.-S.;
Wan, Y.; Chan, R. H. Y.; and Fung, P. 2016. Real-Time
Speech Emotion and Sentiment Recognition for Interactive
Dialogue Systems. ACL.
[Blei, Ng, and Jordan 2003] Blei, D. M.; Ng, A. Y.; and Jor-
dan, M. I. 2003. Latent Dirichlet Allocation. The Journal of
Machine Learning Research 3:993–1022.
[Chaney, Blei, and Eliassi-Rad 2015] Chaney, A. J.; Blei,
D. M.; and Eliassi-Rad, T. 2015. A probabilistic model for
using social networks in personalized item recommendation.
Proceedings of the 9th ACM Conference on Recommender
Systems 43–50.
[Chen et al. 2012] Chen, M.; Xu, Z.; Weinberger, K.; and
Sha, F. 2012. Marginalized Denoising Autoencoders for
Domain Adaptation. Proceedings of the 29th International
Conference on Machine Learning (ICML) 767—-774.
[Chong et al. 2017] Chong, A. Y. L.; Ch’ng, E.; Liu, M. J.;
and Li, B. 2017. Predicting consumer product demands via
Big Data: the roles of online promotional marketing and on-
line reviews. International Journal of Production Research
55(17):5142–5156.
[Clinton, Jackman, and Rivers 2004] Clinton, J. D.; Jack-
man, S.; and Rivers, D. 2004. The Statistical Analysis

tional on Conference on Information and Knowledge Man-
agement, 811–820. ACM.
[Poole and Rosenthal 1985] Poole, K. T., and Rosenthal, H.
1985. A spatial model for legislative roll call analysis. Amer-
ican Journal of Political Science 357–384.
[Ramage et al. 2009] Ramage, D.; Hall, D.; Nallapati, R.;
and Manning, C. D. 2009. Labeled LDA: A supervised
topic model for credit attribution in multi-labeled corpora.
Proceedings of the 2009 Conference on Empirical Methods
in Natural Language Processing 1(August):248–256.
[Sedhain et al. 2015] Sedhain, S.; Menon, A. K.; Sanner, S.;
and Xie, L. 2015. AutoRec : Autoencoders Meet Collabo-
rative Filtering. Proceedings of the 24th International Con-
ference on World Wide Web (WWW) 111–112.
[Shah, Rao, and Ding 2017] Shah, V.; Rao, N.; and Ding, W.
2017. Matrix Factorization with Side and Higher Order In-
formation. arXiv preprint arXiv:1705.02047.
[Socher et al. 2013] Socher, R.; Chen, D.; Manning, C. D.;
and Ng, A. 2013. Reasoning with neural tensor networks
for knowledge base completion. In Advances in neural in-
formation processing systems, 926–934.
[Vincent et al. 2010] Vincent, P.; Larochelle, H.; Lajoie, I.;
Bengio, Y.; and Manzagol, P.-A. 2010. Stacked Denoising
Autoencoders: Learning Useful Representations in a Deep
Network with a Local Denoising Criterion. Journal of Ma-
chine Learning Research 11:3371–3408.
[Wang and Blei 2011] Wang, C., and Blei, D. M. 2011. Col-
laborative topic modeling for recommending scientiﬁc arti-
cles. In Proceedings of the 17th ACM SIGKDD international
conference on Knowledge discovery and data mining, 448–
456. ACM.
[Wang, Shi, and Yeung 2017] Wang, H.; Shi, X.; and Yeung,
D.-y. 2017. Relational Deep Learning : A Deep Latent Vari-
able Model for Link Prediction. AAAI.
[Wang, Wang, and Yeung 2015] Wang, H.; Wang, N.; and
Yeung, D.-Y. 2015. Collaborative Deep Learning for Rec-
ommender Systems. KDD 1235–1244.
[Wu et al. 2016] Wu, Y.; DuBois, C.; Zheng, A. X.; and Es-
ter, M. 2016. Collaborative Denoising Auto-Encoders for
Top-N Recommender Systems. Proceedings of the Ninth
ACM International Conference on Web Search and Data
Mining - WSDM ’16 153–162.
[Ying et al. 2016] Ying, H.; Chen, L.; Xiong, Y.; and Wu, J.
2016. Collaborative deep ranking: A hybrid pair-wise rec-
ommendation algorithm with implicit feedback. Paciﬁc-Asia
Conference on Knowledge Discovery and Data Mining 9652
LNAI:555–567.

Neural Ideal Point Estimation Network

Kyungwoo Song, Wonsung Lee, and Il-Chul Moon
Korea Advanced Institute of Science and Technology
291 Daehak-ro, Yuseong-gu
Daejeon 34141, South Korea
{gtshs2,aporia,icmoon}@kaist.ac.kr

9
1
0
2
 
r
p
A
 
6
2
 
 
]
I
S
.
s
c
[
 
 
1
v
7
2
7
1
1
.
4
0
9
1
:
v
i
X
r
a

Abstract

Understanding politics is challenging because the politics
take the inﬂuence from everything. Even we limit ourselves
to the political context in the legislative processes; we need
a better understanding of latent factors, such as legislators,
bills, their ideal points, and their relations. From the mod-
eling perspective, this is difﬁcult 1) because these observa-
tions lie in a high dimension that requires learning on low di-
mensional representations, and 2) because these observations
require complex probabilistic modeling with latent variables
to reﬂect the causalities. This paper presents a new model to
reﬂect and understand this political setting, NIPEN, includ-
ing factors mentioned above in the legislation. We propose
two versions of NIPEN: one is a hybrid model of deep learn-
ing and probabilistic graphical model, and the other model
is a neural tensor model. Our result indicates that NIPEN
successfully learns the manifold of the legislative bill texts,
and NIPEN utilizes the learned low-dimensional latent vari-
ables to increase the prediction performance of legislators’
votings. Additionally, by virtue of being a domain-rich proba-
bilistic model, NIPEN shows the hidden strength of the legis-
lators’ trust network and their various characteristics on cast-
ing votes.

Introduction
Recent developments in machine learning have enabled a
deeper understanding of human behavior in diverse contexts.
These advances include divulging intentions and sentiments
in dialogs (Bertero et al. 2016); predicting purchases from
online markets (Chong et al. 2017); recommending movies
to friends (Shah, Rao, and Ding 2017); and discovering so-
cial network links between individuals (Guo, Zhang, and
Yorke-Smith 2015). The recent machine learning models
provide the contexts of these behaviors, which have been
regarded as the latent aspects of human behavior.

One latent modeling of human behavior can be a form of
complex Bayesian probabilistic models, a.k.a. probabilistic
graphical model (PGM). The modelers used graphical nota-
tions, embedding the probabilistic variables and their causal-
ities, to represent the key factors and their relations. For in-
stance, latent Dirichlet allocation (LDA) models the genera-
tive process of documents, i.e. the composition of topics at

Copyright c(cid:13) 2018, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

large, a main topic of documents, and a word selection when
describing a topic (Blei, Ng, and Jordan 2003).

Another effort in modeling the latent variable is improv-
ing the quality of the latent representation of the data. While
the above probabilistic models focused on the contextual
modeling, the latent variables reside in a high dimensional
and nonlinear space, so the learning of the latent variables
have been limited. For example, the stacked de-noising au-
toencoder (SDAE) (Vincent et al. 2010) learns this mani-
fold space through encoding the noised inputs into the low
dimensional latent representations; and reconstructing the
original inputs with the latent representations with neural
network layers. Further advances have made through casting
this autoencoding mechanism to the variational inference
approaches, and a variational autoencoder (VAE) (Kingma
and Welling 2014) optimizes the variational distribution of
the latent representations with neural networks.

Supported by the two research advances, one distinct re-
search direction has been merging the latent representation
learning and the probabilistic graphical model on human be-
havior. Collaborative deep learning (CDL) (Wang, Wang,
and Yeung 2015) is one example merging SDAE with a
probabilistic model of matrix factorization that often used
to explain and predict the human behavior of recommen-
dations. Whereas CDL gives a clear passway on how we
can further develop various models of human behavior with
support from the deep learning, different application do-
mains require different latent modeling, so the model struc-
ture needs to be further customized and expanded.

This paper introduces Neural Ideal Point Estimation Net-
work (NIPEN) which models the generative process of po-
litical voting by estimating ideal points in diverse legisla-
tive aspects with learning the low dimensional representa-
tions from neural networks. Speciﬁcally, we propose two
versions of NIPEN. The ﬁrst version, NIPEN-PGM is a
hybrid model by representing the contextual causalities as
a PGM, and by learning the low dimensional representa-
tions with multi-layered perceptron (MLP) autoencoders,
i.e. SDAE and VAE. The second version, NIPEN-Tensor, is
a neural tensor model that substitutes the PGM part with the
neural tensor model. NIPEN-Tensor could be viewed as a
generalized version of NIPEN-PGM. NIPEN-Tensor mod-
els the legislative voting with the tensor composition and
the nonlinear operations between diverse legislative factors

Figure 1: The summarized procedure of NIPEN. NIPEN predicts the votes with the combination of contents and network
analyses. We can interpret not only an individual legislator’s ideal points but also trust networks between legislators

while NIPEN-PGM assumes the marginalization and the lin-
earized operation in the same modeling part.

Second, NIPEN is the most comprehensive model in the
latent modeling of the political domain. Assuming that we
model a voting process of legislators, NIPEN is the ﬁrst
model of unifying 1) the voting behavior, 2) the network in-
ﬂuence between congressmen, 3) the political ideal point of
bills and congressmen, 4) the textual topic of bills, and 5) the
relative strength of network inﬂuence and ideal points when
casting a vote. Some of these latent variables have been seen
in other models, (Gerrish and Blei 2012; Gu et al. 2014;
Chaney, Blei, and Eliassi-Rad 2015), but not as the uni-
ﬁed model to depict a whole political picture. Since di-
verse factors, such as the contents of the bill and the hu-
man relations, greatly inﬂuence the voting (Cohen and Mal-
loy 2014), an effective modeling of the legislative voting re-
quires an integrated model, such as NIPEN. We show that
NIPEN recorded signiﬁcant performance improvements in
all metrics compared to existing models. We also show vari-
ous qualitative analyses that can only obtained via this com-
prehensive model. The entire procedures and analyses of
NIPEN is summarized by Figure 1.

Previous Research

Modeling Political Network and Ideal Points

Network analyses and ideal point estimation have been
widely studied in computer science and quantitative polit-
ical science for its importance. In the line of political net-
work analyses, most studies analyzed co-sponsorship data
(Faust and Skvoretz 2002; Fowler 2006). Faust and Skvoretz
(2002) clariﬁed the topological structures in the network of
the U.S. Senate (1973-1974), and they found that the net-
work among U.S. Senator in 93rd Congress is O-star, I-
star and Trans structure (Faust and Skvoretz 2002). Fowler
(2006) inferred the relationship in U.S. Congress (1973-
2004) by measuring the centrality to ﬁnd the most central
legislators (Fowler 2006). In the community of ideal point
estimation, Poole and Rosenthal (1985) proposed a nonl-
inear logit model to account for political choices of legis-
lators (Poole and Rosenthal 1985). However, it was a one-
dimensional estimation, and the analysis could not identify

what the ideal dimension stands for. To overcome the lim-
itation, Clinton et al. (2004) proposed a multi-dimensional
ideal point estimation model, but these models still remained
at the simple logit model extensions (Heckman and Snyder
Jr 1996; Clinton, Jackman, and Rivers 2004).

With the advance of topic modeling, multi-dimensional
ideal point models were developed, and these models pro-
vide more accurate interpretations on the ideal points. Ger-
rish and Blei (2012) proposed an issue-adjusted model (Ger-
rish and Blei 2012) with the labeled LDA (Ramage et al.
2009), and Yupeng et al. (2014) proposed a topic-factorized
ideal point model (TFIPM) (Gu et al. 2014) with probabilis-
tic latent semantic analysis (PLSA) (Hofmann 1999) to esti-
mate the ideal points of legislators based on roll-call data.
Further extensions of TFIPM have made through includ-
ing available domain data. For instance, Islam et al. (2016)
proposed SCIPM by including co-sponsorship networks be-
tween judges in the supreme court (Islam et al. 2016). These
works have remained in the extension of the probabilistic
graphical model without the innovation from the deep learn-
ing community, which our work extends 1) the probabilis-
tic graphical model with variational autoencoders and 2) the
neural tensor model for the causality modeling of the leg-
islative voting.

Collaborative Filtering and Deep Learning
Collaborative Filtering is a recommendation algorithm that
considers the relationship between users and items (Koren,
Bell, and Volinsky 2009). One of representative approach is
a matrix factorization which factorizes the rating matrix as
user latent and item latent factors.Recently, the deep learn-
ing has initiated two theoretic developments. First, the ma-
trix factorization itself is a low-dimensional representation
method because of its latent vector learning, so does the au-
toencoding in the deep learning. For example, Sedhain et
al. (2015) proposed Autorec (Sedhain et al. 2015), a basic
autoencoder based CF algorithm, and Autorec outperforms
other state-of-the-art MF algorithms like LLORMA (Lee et
al. 2013). Wu et al. (2016) expand Autorec by concatenating
a user latent variable to the rating input information in the
encoder part of Autorec (Wu et al. 2016). Li et al. (2015)
adopted two autoencoders corresponding to users and items

(Li, Kawale, and Fu 2015), and they showed the interac-
tion mechanism between the two autoencoders by using the
marginalized SDAE (Chen et al. 2012). Second, the matrix
factorization is related to the low-dimensional feature rep-
resentation by adding the representation of the model as the
distilled version of the side information. For instance, Wang
et al. (2015) proposed a collaborative deep learning (CDL)
which combines SDAE with MF (Wang, Wang, and Yeung
2015). Furthermore, Ying (2016) proposed a model of col-
laborative deep ranking which combines ranking with algo-
rithm and SDAE (Ying et al. 2016). Wang et al. (2017) pro-
posed the relational deep learning with SDAE to link predic-
tion between items (Wang, Shi, and Yeung 2017).

Method
This section introduce the detailed descriptions of NIPEN-
PGM and NIPEN-Tensor in turn. Appendix A formulates
the assumptions and the research questions, and Appendix
C enumerates all symbols in this study.

NIPEN with Probabilistic Graphical Model and
Autoencoders
Figure 2 describes the model structure of NIPEN-PGM. We
start the detailed description from the bill low dimension
modeling part, which is the bill plate with the d ∈ D sub-
script. We apply either VAE or SDAE to learn the low di-
1 with the observed
mensional representation, or topic, of zdk
bill text wdv. zdk can be extracted through the probabilistic
encoder, qφ with parameter φ and decoder, pθ with param-
eter θ which is further described in Appendix B. The topic
representation of bills has two components: the bill latent
ydk and the latent offset ξdk, and we model the combination
of the two component as the below.

ydk = ξdk + zdk,

ξkd ∼ N (0, λ−1
y )

Since the bill itself and the bill text may have two differ-
ent latent variables, ξdk becomes the offset between the bill
latent variable and the bill text latent variable, or topic.

From the deﬁned bill latent ydk, we model how the bill
latent generates the voting observation rud. Here, u ∈ U is
the dimension of the legislators. We assumed that a legislator
cast votes considering three latent factors: the bill latent ydk,
the bill ideal point adk, and the legislators’ ideal point xuk.

adk ∼ N (0, λ−1

u ),

xuk ∼ N (0, λ−1
u )

Now, we deﬁne NIPEN-PGM without the network fac-
tor. This voting procedure is modeled as Eq. (1) where ηd
is a bias value of a legislative bill, and σ is a sigmoid func-
tion. Eq. (1) is designed to increase the probability of vot-
ing YEA when the ideal points of the bill and the legislator
have the same sign; and when an ideal-aligned dimension
of the bill latent variable is high. Additionally, ηd indicates
whether the bill is more broadly accepted or not, regardless
of ideal points.

p(rud = 1) = σ(

ydkadkxuk + ηd)

(1)

K
(cid:88)

k=1

1d, u, and k mean each document, legislator, topic respectively.

Small subscripts indicate the row and column index in order.

Figure 2: Graphical model representation of NIPEN-PGM

Finally, we add the network component to NIPEN-PGM.
The interest of a particular legislative group could be an im-
portant factor in the voting process. Following this impli-
cation, we modeled the network between two legislators as
below. Before the network modeling, we limited the network
inﬂuence between the legislators sharing the same term, and
this neighbor set, Iu, is deﬁned as a neighborhood of legis-
lator, u.

τuu(cid:48) ∼ N (0, λ−1

τ ) αu ∼ N (0, λ−1

α ) βu ∼ N (0, λ−1
α )
The legislator u’s voting is affected by two terms. The ﬁrst
term is the ideal alignment modeled in Eq. (1). The second
term is the voting record of the neighbor legislator, ru(cid:48)d, and
the second term is also weighted by the network strength,
τuu(cid:48), between the two legislators. Since this is a linear sum-
mation, τuu(cid:48) will model the degree of voting agreement be-
tween two legislators. These two terms are uniﬁed with scal-
ing parameters αu and βu. The purpose of modeling αu and
βu is analyzing whether a certain legislator is inﬂuenced
more either from the bill or from the network in casting
votes.

Eq. 2 is the overall voting formulation of NIPEN-PGM.

p(rud = 1) = σ(αu(

ydkadkxuk + ηd)

+ βu(

τuu(cid:48)ru(cid:48)d))

(2)

(cid:88)

k
(cid:88)

u(cid:48)∈Iu

NIPEN with Neural Tensor Model
Existing models, including NIPEN-PGM, do not directly
model the relationships between the topics, which means
that there is no cross-operiation between the dimension of
K. Some cases, i.e. correlated topic model (Lafferty and Blei
2006), model the correlation between topics via the logistic
normal distribution, but this is not an operation modeling of
topic inﬂuences, rather the variable modeling of topic co-
variance.

The recent introduction of neural tensor models (Socher
et al. 2013) enable the cross-operations between the latent

topic dimension. This topic cross-operation can model the
legislator’s ideal point non-linear inﬂuences when two top-
ics are combined within a bill. Here, we propose NIPEN-
Tensor to incorporate the cross-topic inﬂuence in casting a
vote, which could not be modeled in NIPEN-PGM. NIPEN-
Tensor and NIPEN-PGM are similar in the parts of docu-
ment and inﬂuence network modeling. The only different
part is the voting decision modeled as Eq. 2 which multiplies
the factors per a topic and marginalizes. NIPEN-Tensor con-
siders that the multiplication per a topic should be changed
to consider the nonlinear effect from the topic set, not a sin-
gle topic. Therefore, we represent the previous topic-wise
multiplcaiton of ydkadkxuk as a tensor E, and this tensor
still treats the topic dimension to be independent. Then, we
apply a fully-connected layer to cross-operate the topic di-
mension of E, and the neural network has C that is the out-
put of the cross-operation. The overall structure and formu-
lation for the NIPEN-Tensor are shown in Figure 3 and Eq.
3, respectively.

Eudk = xukydkzdk
(cid:88)

(cid:101)Eudl = tanh(

k

EudkW (T1)

kl + b(T1)

l

)

Cud =

(cid:101)EudlW (T2)

l1 + ηd

(cid:88)

k
(cid:88)

u(cid:48)∈U

Nud =

τuu(cid:48)vu(cid:48)d

(3)

W (T1), b(T1), W (T2) are weights and biases applied to Eudk,
(cid:101)Eudl tensor. In particular, W (T1) ∈ RK×K models the cor-
relation between topics, and W (T2) ∈ RK×1 models the
inﬂuence of each topic on the voting. Since the signs of
xuk, ydk, and adk are important, we use tanh instead of
ReLU (Rectiﬁed linear unit) to transform the outputs non-
linearly.

Parameter Inference of NIPEN

The parameters of both NIPENs are enumerated in the pre-
vious section, and we learn the parameters in two folds:
learning the autoencoder to represent the bill topic and
the CF, alternatively. The ﬁrst set of parameters related
to autoencoders is ψ(1) = (θ, φ); and the second set
of parameters related with the legislative-CF is ψ(2) =
(y, a, η, x, W (T1), W (T2), b(T1), τ, α, β).

The overall inference algorithm of both NIPENs fol-
lows the maximization of variational evidence lower bound
with two assumptions. Following CDL, the ﬁrst assump-
tion is connecting the autoencoder and CF through ξ, and
the strength is controlled by the variance of ξ, which is λy.
When learning ψ(1), we apply the stochastic gradient varia-
tional Bayes (SGVB) estimator.

Second, we assumed that the variational distribution of
ψ(2) as a point mass for simplicity, so the parameters of
the variational distribution are updated by each casted vote

Figure 3: Neural network view of NIPEN-Tensor. The con-
tents part is connected with the blue line (with content scal-
ing parameter αu ), and the network part is connected with
the purple line (with the network scaling parameter βu ).

record, which is traditional Bayesian belief updates. Speciﬁ-
cally, the likelihood of the posterior is presented as the lower
bound in the below. Then, the lower bound, which has real-
ized values of qφ(z|w), pθ(z) and an observed input, has
only ψ(2), so the gradient method can ﬁnd the maximum a-
posteriori, or MAP, of ψ(2).

As a summary, the objective function of both NIPENs is

LN IP EN = −DKL(qφ(z|w)(cid:107)pθ(z)) +

log pθ(w|zl)

1
L

L
(cid:88)

l=1

+

+

−

λf
2

λf
2

λy
2

(cid:88)

(u,d),rud(cid:54)=0
(cid:88)

(u,d),rud(cid:54)=0

1 + rud
2

1 − rud
2

log p(rud = 1)

log p(rud = −1)

D
(cid:88)

d=1

(cid:107)yd − zd(cid:107)2

2 −

((cid:107)a(cid:107)2

F + (cid:107)x(cid:107)2
F )

λu
2

−

λτ
2

F ) −

((cid:107)τ (cid:107)2

((cid:107)α(cid:107)2

2 + (cid:107)β(cid:107)2
2)

λα
2
Similar to (Wang and Blei 2011; Wang, Wang, and Yeung
2015), the parameters related with the autoencoder and the
legislative-CF are infered by coordinate ascents which maxi-
mizes LN IP EN . For legislative-CF related parameters ψ(2),
we take the gradient of LN IP EN w.r.t each parameters given
the current θ and φ. Given the legislative-CF related param-
eters ψ(2), we infer the autoencoder related parameters by
computing ∇ψ(1)LN IP EN . We utilized the Tensorﬂow li-
brary (Abadi et al. 2016) to optimize the parameters.

NIPEN-PGM and NIPEN-Tensor are only different in the
vote casting process, and the related term in the objective
function is the third and the fourth terms with log p(rud =
1). These terms could be computed as the conventional gra-
dient descent in two variants of NIPEN, so there is no change

p(rud = 1) = σ(αuCud + βu

Nu(cid:48)d)

speciﬁed as follows:

(cid:88)

u(cid:48)∈Iu

in the learning mechanism.

In the original deﬁnition, the network, τ , is a |U |-by-|U |
matrix, and the number of parameters becomes large given
O(U 2). To reduce the squared complexity, τ is approxi-
mated by the product of (cid:101)τ1 and (cid:101)τ2 where (cid:101)τ1 ∈ RU ×G, (cid:101)τ2
∈ RG×U . We assume that (cid:101)τ1 and (cid:101)τ2 are not related. G can
be interpreted as the number of groups containing the legis-
lators. This approximation results in O(GU ) for the network
parameter inference.

Table 1: Attributes of Politic2013 and Politic2016 dataset

# of legislators (|U |)
# of bills (|D|)
# of votings (|D|)
# of House
# of Senator
# of Republican
# of Democrat
# of unique word (|V |)

Average # of unique word
(cid:80)
d,v(Iwdv >0)
for each bill (

)

V

# of bills less than
10 unique words
Period
Source
Data type

Politic2013
1,540
7,162
2,779,703
1,299
241
767
767
10,000

Politic2016
1,537
7,975
2,999,844
1,266
271
778
752
13,581

192.77

378.66

65

0

1990-2013
THOMAS

1989-2016
GovTrack

1 (YEA), -1 (NAY)

Results

Datasets on Political Ideal Points
We used two roll-call datasets, whose source is explained in
Appendix D. Table 1 provides the descriptive statistics of the
two datasets: Politic2013 and Politic2016. Politic2013 limits
the number of a unique word to 10,000, and there are 65 bills
which have less than ten words, while Politic2016 chooses
13,581 unique words, and there are no bills with less than ten
words. Politic2013 is a more sparse dataset than Politic2016
in the ratings and the vocabulary sizes.

Baselines and Implementation Details
The variations of NIPEN were compared to ﬁve baseline
models as follows:
• TFIPM: Topic Factorized Ideal Point estimation Model
(Gu et al. 2014) is specialized in politics to analyze the
roll-call data.

• Autorec: A simple autoencoder model which is utilized to
predict the ratings. Autorec (Sedhain et al. 2015) encodes
and reconstructs the rating matrix. We used Item-based
Autorec.

• Trust SVD: Trust SVD (Guo, Zhang, and Yorke-Smith
2015), a type of trust-based matrix factorizations, is built
on SVD++ with trust information.

• CDAE: Collaborative Denoising Autoencoder (Wu et al.
2016) used a denoising autoencoder with user latent vari-
ables.

• CDL: Collaborative Deep Learning (Wang, Wang, and
Yeung 2015) used the deep learning and the CF, jointly.
CDL improves performance by using document informa-
tion additionally, and CDL uses SDAE to learn document
manifold.
Appendix E provides detailed speciﬁcations for replica-
tions of this work, and Appendix F illustrates the sensitivity
analysis of λy and λτ .

Quantitative Evaluations
We performed the ﬁve-fold cross-validation to quantita-
tively evaluate the variations of NIPENs, and the perfor-
mance measures are RMSE, MAE, accuracy, and nega-
tive average log-likelihood (NALL) measures. We compared
nine models: ﬁve baseline models in section 4.2, and four
NIPEN variations, which are NIPEN-PGM(SDAE), NIPEN-
PGM(VAE,approx.), NIPEN-PGM(VAE), and NIPEN-
Tensor. NIPEN-PGM has three variants by choosing either
SDAE or VAE as the autoencoder for the text modeling, and
by choosing either using the whole matrix for the inﬂuence
or the low-rank approximated matrix of the inﬂuence.

Table 2 statistically conﬁrms that the best performance
model in every metric is always a variation of NIPEN, which
is conﬁrmed with statistical signiﬁcance. In detail, ﬁrst,
we compare NIPEN-PGM(VAE) and NIPEN-PGM(SDAE),
and their performance gap is larger in Politic2013 than in
Politic2016 which is a relatively sparse setting as shown
in Table 1. We conjecture that NIPEN-PGM(VAE) is bet-
ter in handling the sparse dataset than NIPEN-PGM(SDAE).
Second, NIPEN-Tensor is a model that considers the cor-
relation between topics, and NIPEN-Tensor may have a
better performance when a bill text has multiple topics
with complex and rich textual information. As discussed
in Section Datasets on Political Ideal Points, Politic2016
has richer textual information than Politic2013, and we con-
jecture that this is the reason why NIPEN-PGM(VAE) in
Politic2013 and NIPEN-Tensor in Politic2016 show better
performances. Third, while the accuracy improvement is rel-
atively small, the improvements on other metrics, partic-
ularly RMSE and MAE, are relatively large. Already, the
baseline models achieve the accuracy higher than 95%, so
the accuracy improvement could seem minimal. However,
our likelihood estimation of YEA and NAY is considerably
improved given the RMSE and the MAE improvement.

Qualitative Evaluations
In addition to the quantitative results, we interpret the latent
variables of NIPEN-PGM(VAE) on Politic2016. First, to
comprehend the dataset and the qualitative results, we com-
puted the word-topic matrix from well-learned VAE vari-
ables, ψ1, as shown in Table 3. This table provides a snap-
shot of topics in the bills. Then, we relate this topic to the bill
ideal points, adk. The latent dimension, k, becomes the com-
mon dimension of an ideal point value and a topic weight
for each topic in the bill. Figure 5 shows an example of the
topic weight as the bar chart and the ideal point value as the
line chart. The illustrated bill, or H.Res.794 (114th), has the
largest absolute value, |adk(cid:101)zdk| in a ’Business and Finance’
topic where (cid:101)zdk denotes the normalized zdk.

Table 2: Quantitative evaluation on Politic2013 and Politic2016 datasets. Two-standard deviation is shown in parentheses

Politic2013

Politic2016

RMSE
0.2253
(±0.0007)
0.2110
(±0.0099)
0.2059
(±0.0007)
0.1872
(±0.0002)
0.1834†
(±0.0008)
0.1801**
(±0.0014)

MAE
0.1399
(±0.0011)
0.0975
(±0.0136)
0.0831
(±0.0009)
0.0682†
(±0.0002)
0.0786
(±0.0019)
0.0591**
(±0.0012)

Accuracy
0.9408
(±0.0003)
0.9411
(±0.0056)
0.9428
(±0.0006)
0.9526
(±0.0003)
0.9554†
(±0.0004)
0.9566**
(±0.0006)

NALL
0.1866
(±0.0011)
0.1466
(±0.0177)
0.1450
(±0.0009)
0.1213
(±0.0007)
0.1147†
(±0.0018)
0.1155
(±0.0018)

RMSE
0.2168
(±0.0011)
0.2031
(±0.0015)
0.1977
(±0.0037)
0.1794
(±0.0010)
0.1780†
(±0.0013)
0.1779
(±0.0005)

MAE
0.1353
(±0.0010)
0.0886
(±0.0110)
0.0802
(±0.0052)
0.0625†
(±0.0006)
0.0769
(±0.0012)
0.0560**
(±0.0004)

Accuracy
0.9463
(±0.0009)
0.9454
(±0.0007)
0.9475
(±0.0023)
0.9566
(±0.0005)
0.9583†
(±0.0008)
0.9581
(±0.0003)

NALL
0.1782
(±0.0015)
0.1349
(±0.0125)
0.1357
(±0.0046)
0.1121
(±0.0016)
0.1106†
(±0.0017)
0.1173
(±0.0015)

0.1804
(±0.0089)

0.0611*
(±0.0065)

0.9565
(±0.0047)

0.1165
(±0.0086)

0.1791
(±0.0076)

0.0599
(±0.0057)

0.9571
(±0.0039)

0.1152
(±0.0070)

0.1753**
(±0.0007)
0.1818**
(±0.0008)
4.41%

0.0588**
(±0.0008)
0.0663**
(±0.0003)
13.78%

0.9587**
(±0.0006)
0.9556**
(±0.0003)
0.35%

0.1075**
(±0.0011)
0.1155
(±0.0020)
6.27%

0.1753**
(±0.0017)
0.1729**
(±0.0015)
2.87%

0.0570**
(±0.0012)
0.0608**
(±0.0006)
10.40%

0.9590**
(±0.0010)
0.9600**
(±0.0008)
0.18%

0.1112
(±0.0024)
0.1057**
(±0.0022)
4.43%

Trust SVD

Autorec

CDAE

TFIPM

CDL

NIPEN-
PGM(SDAE)
NIPEN-
PGM(VAE,
approx.)
NIPEN-
PGM(VAE)
NIPEN-
Tensor
Improvement

NALL : Negative Average Log Likelihood
Improvement : Relative improvement of the best version of NIPEN compared to the best model, which is marked by †, among the baselines
P ∗ < 0.05; P ∗∗ < 0.01 (Student’s one-tailed t-test against the † model)

Table 3: Selected top-ﬁve words for each topic. The number
of listed topics was set to ten.

Topic Label
Business and
Finance
Disasters
Management
International
Relationship

Racism

Defense

Agriculture

Social

Health

Foregin

1

2

3

4

5

6

7

8

9

International
Trade

10

Topic Words
Forproﬁt, Nonrefundable, Govern,
SBDC, Financings
Stabilization, Homeless, Disasters,
Alerts, USPS
Kuwait, Distributes, Lawsuits,
Threatens, Spain
Contrary, Black, Compared,
Tuskegee, Reagan
United, Soviet, Antiterrorist, IDA,
NGA
Pima, Climate, Cropland, Bush,
Badlands
Contribute, Donors, Childcare,
Resettlement, DRR
FEHBP, Heroin, Stability,
Musculoskeletal, Transplantation
Agency, Lantos, FPI, fusion,
division
Clearinghouses, ESF,
Discrepancies, Repay, Charging

Figure 4: Individual legislators’ ideal points for each topic

This bill ideal point is correlated with the legislator ideal
point, xuk, to generate the vote records. Here, the dimen-
sion, k, is the same latent dimension of the topic in Table
3, and we provide the scatter plot of the legislators’ ideal
points per topic in the Figure 4. The prior mentioned bill
(H.Res.794 (114th)) considers the appropriations for ﬁnan-
cial services and general government, and the major topic is
Business and Finance, and the bill ideal point in Business
and Finance is -1.217. Together, the vote casting will be de-
termined by the legislators’ view on Business and Finance,
and this topic shows the greatest disagreement between the
Republicans and the Democrats according to the Figure 4. In
the real world, the voting results were same as expected: 1)
the voting was very partisan, 92.2% Republican voted YEA

Figure 5: Topic proportion and ideal points of H.Res.794
(114th) bill

Table 4: Top-ﬁve legislators who are affected by contents or
network factors a lot. The scaling variable (αu for contents
based, and βu for network based), political party, and district
of the member are indicated in parentheses.

Contents based
Ron Paul
(0.260, R, TX)
Virgil H. Goode
(0.220, R, VA)
Dennis J. Kucinich
(0.218, D, OH)
Henry Cuellar
(0.198, D, TX)
Walter B. Jones
(0.195, R, NC)

1

2

3

4

5

Network based
Ralph M. Hall
(0.304, R, TX)
Nick J. Rahall II
(0.250, D, WV)
Peter A. DeFazio
(0.247, D, OR)
Don Young
(0.228, R, AK)
Jim Sensenbrenner.
(0.227, R, WI)

action between the contents and the network parts. We
used two scaling variables αu and βu, which controls the
strengths of contents factor and network factor, respectively.
Table 4 shows the top-ﬁve legislators who were affected by
either contents or network factors. Since the variations of
NIPEN is an integrated model of network modeling as well
as the textual bill modeling, the NIPENs should better per-
form than the baseline models, i.e. CDL, which only models
the texts, and Figure 7 conﬁrms this hypothesis.

Figure 6: Trust network between legislators

and the 90.3% Democrat voted NAY.

The second qualitative interpretation focuses on the legis-
lators’ network. We selected 12 legislators who have either
strongly positive or negative relationships with each other,
shown in the Figure 6. In general, the legislators have a
strong positive relationship when they have the same dis-
trict and the party. Among the top-ﬁve positive relation-
ships, four of them have the same party and the same dis-
trict, i.e. ’Thomas E. Petri↔Jim Sensenbrenner’, ’Nick J.
Rahall II→Robert E. Wise’, and ’Nick J. Rahall II→Alan B.
Mollohan’2. The closest relations are ’Thomas E. Petri’ and
’Jim Sensenbrenner’. They were both republican representa-
tives from Wisconsin, and they share similar voting patterns.
They have voted 6,288 times for the same bill, and the 5,764
votes were same (91.6%). Especially, they voted NAY for
H.R.730 (111th) which is a ”suspension of the rules”, and
397 legislators votes YEA. For H.R.6063 (110th), ’Thomas
E. Petri’ and ’Jim Sensenbrenner’ voted NAY together while
94.4% legislators voted YEA. We report further analyses in
Appendix G.

The third qualitative analysis concentrates on the inter-

2τuu is asymmetric matrix. arrow(’→’) indicates the direction

of the trust

Figure 7: Accuracy of top ﬁve legislators who are affected
by network factor

Conclusion

We proposed two versions of machine learning models,
NIPEN-PGM and NIPEN-Tensor, to analyze the ideaology
in the legislation process. The variations of NIPEN show the
state-of-the-art performance in all measures on Politic2013
and Politic2016. Furthermore, NIPEN provides various in-
terpretations in why YEA or NAY is casted by illustrating 1)
the ideal point estimation of individual legislators and bills;
2) the trust network between legislators; and 3) the content
and network inﬂuence for each legislator. These supervised
and unsupervised tasks could be critical insights into quan-
titatively understanding politics in the legislative process.

Appendix A. Problem Formulation

In general, the inﬂuence on legislative voting originates from
1) the individual ideal points of the legislator, 2) the contents
of the bill, and 3) the interests of a political group that a leg-
islator belongs to. We operationalize these inﬂuence struc-
ture as the concepts deﬁned in the below.

Deﬁnition 1. Ideal point is a measure of legislator’s prefer-
ence for each topic when we have K topics in our bill texts.
The ideal point for a particular topic k of a particular mem-
ber u is represented by xuk, and it follows N (0, λ−1
u ). The
sign of xuk represents the preferred voting direction (posi-
tive or negative), and the size of |xuk| represents the pref-
erence strength. The ideal point for a particular topic k of a
particular bill d is represented by adk, and its distribution is
N (0, λ−1
u ). The interprestation of adk is same as xuk.

Deﬁnition 2. Contents refer to the bill elements, i.e. text
descriptions, which affect the voting result. The latent repre-
sentation of the contents is ydk which is the addition of zdk,
the topic of the bill; and ξdk, the deviation of the bill from
the topic of the bill text.

Deﬁnition 3. Network means the collection of relationships
between legislators whose vote affect the other’s vote. The
strength of network relationships is modeled as τuu(cid:48), which
follows N (0, λ−1
τ ). The sign of τuu(cid:48) indicates the voting
alignment between u and u(cid:48) legislators, and |τuu(cid:48)| means
its alignment strength. This study assumes that the network
relationships are asymmetric bidirectional, and only the leg-
islators in the same term affect each other.

Deﬁnition 4. Scaling parameters mean the inﬂuence of
contents and networks when a legislator votes. αu is a con-
tent scaling parameter, and βu is a network scaling parame-
ter. Each scaling parameter is a |U |-dimensional vector, fol-
lowed by N (0, λ−1
α ). This study assumed that the degree of
inﬂuence on the contents and the network would be different
per each legislator.

Now, given the above deﬁned concepts, we enumerates

the research questions to test with NIPEN.

Problem 1. NIPEN can predict the results of the voting by
inferring the bill topic, the bill ideal points, the legislator
ideal points, and the network relationships between the leg-
islators.

Problem 2. NIPEN provides the interpretation on the vot-
ing results of the bill. For example, NIPEN illustrates the
interpretable latent information from the bill topic, the bill
ideal point, and the legislator ideal point taking into account
the correlation between the topics.

Problem 3. NIPEN can 1) analyze the trust between legis-
lators (individual unit), and 2) the trust network comparison
between parties (group unit).

Problem 4. NIPEN provides the behavioral analyses on leg-
islators from the voting motivation perspective, which could
be motivated by either legislator ideal point or network rela-
tionship.

Appendix B. Document Modeling
Autoencoders

Appendix B.1. Variational Autoencoder (VAE)
NIPEN extracts the topics of the legislative bills with
VAE (Kingma and Welling 2014) which is a type of
deep generative model. VAE learns the disentangled and
low-dimensional representation of high dimensional data
through the probabilistic encoding, or qφ(z|w); and the
probabilistic decoding, or pθ(w|z). Therefore, the original
objective function of VAE is composed of the linear sum of
corresponding two terms. The ﬁrst term originating from the
encoding is the KL divergence between the probabilistic en-
coding and the prior for latent variable, or pθ(z); and this
term enforces the regularization. The second term is the ex-
pectation on the negative reconstruction error, and this term
is related to the decoding part. By putting both terms to-
gether, the objective function follows as Eq. (4).

L(θ, φ) = −DKL(qφ(z|w)(cid:107)pθ(z)) + Eqφ[log pθ(w|z)]

(4)
Given the high variance over φ, a direct optimization of
Eq. (4) is not efﬁcient. Hence, Kingma and Welling (2014)
suggested the re-parametrization trick as follows: 1) Draw
(cid:15)l ∼ N (0, I), and 2) Optimize the mean and standard devi-
ation of qφ(z|w), and 3) Compute zl = µ(w) + σ(w) (cid:12) (cid:15)l.
From the trick, the objective function of VAE is turned into
Eq. (5) where L is the number of samples.

(cid:101)L(θ, φ) = −DKL(qφ(z|w)(cid:107)pθ(z)) +

log pθ(w|zl)

1
L

L
(cid:88)

l=1

(5)

Appendix B.2. Stacked Denoising Autoencoder
(SDAE)
NIPEN-PGM(SDAE) extracts the topics of the legislative
bills with SDAE (Vincent et al. 2010). SDAE learns the
disentangled latent feature through the encoding and decod-
ing with bottleneck and corrupted input. SDAE use the cor-
rupted input wc instead of the original input w to force
the relationship learning. The SDAE is optimized for the
purpose of reconstructing the w resulting from the encod-
ing process(fe) through the encoder weight (W (e)) and the
decodingfd result through the decoder weight (W (d)). The
objective function follws as Eq. (6)

(cid:13)
(cid:13)
2
(cid:13)fd(fe(w, W (e)), W (d)) − wc)
(cid:13)
(cid:13)
(cid:13)
2

(6)

Appendix C. Notations

Table 5 summarizes all symbols used in this study.

Appendix D. Dataset Descriptions

is Politic2013, and it was collected
The ﬁrst dataset
from THOMAS3, and (Gu et al. 2014). For an additional
experiment, and for more up-to-date analyses, we col-
lected a new roll-call dataset, Politic2016 from GovTrack

3http://thomas.loc.gov/home/rollcallvotes.html

Table 5: Notation description

Symbol
D
V
U (= U (cid:48))
K
G
Iu
wdv
zdk
ydk
adk
ηd
rud
xuk
αu
βu
τuu(cid:48)
(cid:101)τ1, (cid:101)τ2
ξ
(cid:15)
φ(θ)
C(N )
E
W (T ), b(T )

Description
Set of bills
Set of Unique words
Set of legislators
Set of topics
Rank of (cid:101)τ1 and (cid:101)τ2
Other legislators within the same term as u
Frequency of vth token in document d
Topic proportion for each bill and topic
Bill latent vector
Ideal point for each bill and topic
Constant offset for each bill d
Voting record from legislator u to bill d
Ideal point for each legislator and topic
Contents scaling parameter for legislator u
Network scaling parameter for legislator u
Trust network between legislator u and u(cid:48)
Approximated matrix of τuu(cid:48)
Latent offset between zdk and ydk
Random noise vector drawn from N (0, I)
Parameter of encoder (decoder) in VAE
Contents (Network) information
The tensor combined with xuk, ydk, adk
Neural tensor network parameter

.GovTrack provides raw roll-call data, so we processed
the expanded part of Politic2016, manually. For the re-
search community, we released the code and dataset on
https://github.com/gtshs2/NIPEN

Appendix E. Experiment Settings
For TFIPM, we followed the optimal parameters that the au-
thor reported. We set the latent dimension(K), the trade-off
weight, and the regularization weight as 10, 0.8, and 22.4,
respectively. The latent dimension of CDL and NIPENs was
set to ten, equally. For Autorec, the optimal number of the
latent dimension and the regularization parameter are 100
and 0.001, respectively. Trust SVD shows the best perfor-
mance when the weights of CF and trust part are 1,000 and
0.001, respectively, while K is set to 10. For CDAE, we
set the regularization weight, the corruption ratio, and the
number of latent dimension as 0.001, 0.4, and 50, respec-
tively; and the encoder and the decoder activation functions
are sigmoid. For CDL, we ﬁnd that the optimal parameters
of λu,λv,λw,λn, the dropout rate and the activation func-
tions are 0.01, 100, 1, 100, 0.1 and the sigmoid function, re-
spectively. The neural network structure of Autorec, CDAE,
CDL, NIPENs are set to [512,128,K,128,512], equally. Fi-
nally, we set the parameters of NIPENs such as λf = 10,
λy = 10, λu = 0.1, λτ = 1, λα = 1, λn = 1000 G = 3, and
we performed grid searches to ﬁnd the optimized parameters
of NIPENs. Finally, NIPEN-Tensor has the two-layered ten-
sor E in the topic axis.

Appendix F. Hyperparameter Study
This quantitative improvement requires a well-tuned hyper-
parameter setting, illustrated in Figure 8. LN IP EN enumer-
ates multiple hyperparameters, and we found that λy and λτ
are the most important parameters to decide. λy speciﬁes the
causality strength from the bill text latent in VAE to the bill
latent in the legislative CF. The low value of λy will sepa-
rate VAE and CF, but its high value will disrupt the manifold
learning of VAE. Moreover, λτ speciﬁes the regularization
strength from the legislators’ network inﬂuence to the vot-
ing. The small value of λτ will overﬁt the network inﬂuence,
and its large value will limit the learning of network inﬂu-
ence model in CF.

Figure 8: (Top-Left) Accuracy for λy and λτ value, (Top-
Right) RMSE for each λy and λτ value, (Bottom-Left) Ac-
curacy for G value, (Bottom-Right) RMSE for each G value

Appendix G. Results in Network Inﬂuence
Analyses
To examine the network relationships within each party, Fig-
ure 9 illustrates the trust network parameter. A red node rep-
resents a Republican; a blue node stands for a Democrat;
a green solid line indicates an inferred close relationship;
and a purple dotted line indicates an inferred unfriendly re-
lationship. Taking a threshold at 0.1 and looking at τuu(cid:48) with
values greater than 0.1 and less than -0.1 (Figure 9d), John
J. Duncan Jr and Dana Rohrabacher have the greatest net-
work impact given their number of connected legislators in
the Republican party. The commonalities between the two
inﬂuential legislators are 1) being a member of the House of
Representatives; and 2) having been politically active for a
long time (Duncan started as a congressman in Tennessee in
1988 and Laura Baker as a California congressman in 1989.
Especially, Jimmy Duncan is the House’s longest-serving
Republicans.).

We compared and contrasted the network structure of Re-
publicans and Democrats. As shown in Table 6, the network
inﬂuence among the total members is greater in the Demo-
cratic Party given its mean value of |τuu(cid:48)|. However, the Re-

publican party has the higher number of inﬂuential legisla-
tors when we limit the network inﬂuence with thresholds,
i.e. when we limit |τuu(cid:48)| > 0.05 or |τuu(cid:48)| > 0.1 in Table 6.
This suggests that the Democrats have averagely higher and
more equal inﬂuences between the members while the Re-
publicans have a number of authorative inﬂuencers among
the members.

(a) Threshold = 0.03

(b) Threshold = 0.05

Table 6: Comparison of network inﬂuence by each Party

# of pair s.t. τuu(cid:48) > 0.05
# of pair s.t. τuu(cid:48) < −0.05
# of pair s.t. τuu(cid:48) > 0.1
# of pair s.t. τuu(cid:48) < −0.1
Mean of |τuu(cid:48)|
Variance of |τuu(cid:48)|

Republican
58
67
7
3
9.0E-04
2.49E-05

Democratic
49
53
1
3
0.0018
3.38E-05

Table 7: Content and Network scale comparison between the
Party. Average Ranking@K is the average of the ranking of
each legislator, by the party, when the ranking is made up to
the top K legislators, based on scaling parameter (αu βu).

Content (|αu|)

Network (|βu|)

R
6
40
52.87
774.6
0.149

NL@10
NL@100
AR@100
AR@All
Mean value of αu (βu)
R : Republican Party / D : Democratic Party
AR@K : Average Ranking at top K
NL@K : Number of legislators at top K

D
4
60
48.91
762.7
0.148

R
6
42
46
781.4
0.068

D
4
58
53.75
754.9
0.064

Republican Party generally relies on the network, and the
Democratic Party on contents, when they are voting. If we
associate this conclusion with Table 6, we can explain that
a Democratic have more inﬂuence in the network within the
party. However, the proportion of people who are dependent
on the network (including network from their own party and
opposing party) is relatively high in the Republican Party.

(c) Threshold = 0.07

(d) Threshold = 0.1

Figure 9: Network inﬂuence visualization within each party
in December 2016. The top visualizations represent the Re-
publican Party, and the bottom visualizations represent the
Democratic Party. If the network inﬂuence, τuu(cid:48), between
two legislators exceeds the threshold, the relationship is ex-
pressed as a green solid line. If the network inﬂuence, τuu(cid:48),
is less than the threshold, the relationship is noted as a purple
dotted line.

The United States has a two-party system. In order to an-
alyze this reality effectively, contents scaling parameter and
network scaling parameter are analyzed by each party. Com-
paring the mean value of |αu| and |βu| in the Table 7, we
can see that both parties are generally voting rather than net-
works, concentrating on their own politics and the contents
of the bill itself. To compare two political parties relative to
each other based on Average Ranking@100 in Table 7, the

Figure 10: Graphical model representation of NIPEN-PGM

According to the opinion of the reviewers who advised
on the analysis of αu and βu, the distribution of |αu| and
|βu| is shown in Figure 10, and the value of |αu|/|βu| over
time is shown in Figure 11. According to Figure 10, we can
infer that the majority of legislators are voting focusing on

of Roll Call Data. The American Political Science Review
98(2):355–370.
[Cohen and Malloy 2014] Cohen, L., and Malloy, C. J. 2014.
Friends in high places. American Economic Journal: Eco-
nomic Policy 6(3):63–91.
[Faust and Skvoretz 2002] Faust, K., and Skvoretz, J. 2002.
Comparing Networks Across Space and Time, Size and
Species. Networks 32(2002):267–299.
[Fowler 2006] Fowler, J. H. 2006. Connecting the congress:
Political Analysis
A study of cosponsorship networks.
14(4):456–487.
[Gerrish and Blei 2012] Gerrish, S., and Blei, D. M. 2012.
How they vote: Issue-adjusted models of legislative behav-
ior. Advances in Neural Information Processing Systems
25(1):2762–2770.
[Gu et al. 2014] Gu, Y.; Sun, Y.; Jiang, N.; Wang, B.; and
Chen, T.
2014. Topic-factorized ideal point estimation
model for legislative voting network. Proceedings of the
20th ACM SIGKDD international conference on Knowledge
discovery and data mining. ACM, 2014. 183–192.
[Guo, Zhang, and Yorke-Smith 2015] Guo, G.; Zhang, J.;
and Yorke-Smith, N. 2015. TrustSVD : Collaborative Fil-
tering with Both the Explicit and Implicit Inﬂuence of User
Trust and of Item Ratings. Proceedings of the Twenty-ninth
AAAI Conference on Artiﬁcial Intelligence (AAAI) 123–129.
[Heckman and Snyder Jr 1996] Heckman, J. J., and Snyder
Jr, J. M. 1996. Linear probability models of the demand
for attributes with an empirical application to estimating the
preferences of legislators. National bureau of economic re-
search 28(0).
[Hofmann 1999] Hofmann, T. 1999. Probabilistic latent se-
mantic indexing. Proceedings of the 22nd annual interna-
tional ACM SIGIR conference on Research and development
in information retrieval 50–57.
[Islam et al. 2016] Islam, M. R.; Hossain, K. T.; Krish-
nan, S.; and Ramakrishnan, N.
Inferring Multi-
dimensional Ideal Points for US Supreme Court Justices.
Proceedings of the 30th Conference on Artiﬁcial Intelligence
(AAAI) 4–12.
[Kingma and Welling 2014] Kingma, D. P., and Welling, M.
2014. Auto-encoding variational bayes. In Proceedings of
the International Conference on Learning Representations
(ICLR).
[Koren, Bell, and Volinsky 2009] Koren, Y.; Bell, R.; and
Volinsky, C. 2009. Matrix Factorization Techniques for Rec-
ommender Systems. Computer 42(8):42–49.
[Lafferty and Blei 2006] Lafferty, J. D., and Blei, D. M.
2006. Correlated topic models. In Advances in neural in-
formation processing systems, 147–154.
[Lee et al. 2013] Lee, J.; Kim, S.; Lebanon, G.; and Singer,
Y. 2013. Local Low-Rank Matrix Approximation. ICML
28.
[Li, Kawale, and Fu 2015] Li, S.; Kawale, J.; and Fu, Y.
2015. Deep collaborative ﬁltering via marginalized denois-
ing auto-encoder. In Proceedings of the 24th ACM Interna-

2016.

Figure 11: Graphical model representation of NIPEN-PGM

contents rather than network effect. However, since the the
number of element that |βu| > 0.2 is larger than the number
of |αu| > 0.2, we can infer that small number of legislators
are highly dependent on network effect. In addition, Figure
11 shows the change in a |αu/βu| over time, and we can in-
fer that the inﬂuence of contents over networks has become
more important in recent years.

References
[Abadi et al. 2016] Abadi, M.; Agarwal, A.; Barham, P.;
Brevdo, E.; Chen, Z.; Citro, C.; Corrado, G. S.; Davis, A.;
Dean, J.; Devin, M.; and Others. 2016. Tensorﬂow: Large-
scale machine learning on heterogeneous distributed sys-
tems. arXiv preprint arXiv:1603.04467.
[Bertero et al. 2016] Bertero, D.; Siddique, F. B.; Wu, C.-S.;
Wan, Y.; Chan, R. H. Y.; and Fung, P. 2016. Real-Time
Speech Emotion and Sentiment Recognition for Interactive
Dialogue Systems. ACL.
[Blei, Ng, and Jordan 2003] Blei, D. M.; Ng, A. Y.; and Jor-
dan, M. I. 2003. Latent Dirichlet Allocation. The Journal of
Machine Learning Research 3:993–1022.
[Chaney, Blei, and Eliassi-Rad 2015] Chaney, A. J.; Blei,
D. M.; and Eliassi-Rad, T. 2015. A probabilistic model for
using social networks in personalized item recommendation.
Proceedings of the 9th ACM Conference on Recommender
Systems 43–50.
[Chen et al. 2012] Chen, M.; Xu, Z.; Weinberger, K.; and
Sha, F. 2012. Marginalized Denoising Autoencoders for
Domain Adaptation. Proceedings of the 29th International
Conference on Machine Learning (ICML) 767—-774.
[Chong et al. 2017] Chong, A. Y. L.; Ch’ng, E.; Liu, M. J.;
and Li, B. 2017. Predicting consumer product demands via
Big Data: the roles of online promotional marketing and on-
line reviews. International Journal of Production Research
55(17):5142–5156.
[Clinton, Jackman, and Rivers 2004] Clinton, J. D.; Jack-
man, S.; and Rivers, D. 2004. The Statistical Analysis

tional on Conference on Information and Knowledge Man-
agement, 811–820. ACM.
[Poole and Rosenthal 1985] Poole, K. T., and Rosenthal, H.
1985. A spatial model for legislative roll call analysis. Amer-
ican Journal of Political Science 357–384.
[Ramage et al. 2009] Ramage, D.; Hall, D.; Nallapati, R.;
and Manning, C. D. 2009. Labeled LDA: A supervised
topic model for credit attribution in multi-labeled corpora.
Proceedings of the 2009 Conference on Empirical Methods
in Natural Language Processing 1(August):248–256.
[Sedhain et al. 2015] Sedhain, S.; Menon, A. K.; Sanner, S.;
and Xie, L. 2015. AutoRec : Autoencoders Meet Collabo-
rative Filtering. Proceedings of the 24th International Con-
ference on World Wide Web (WWW) 111–112.
[Shah, Rao, and Ding 2017] Shah, V.; Rao, N.; and Ding, W.
2017. Matrix Factorization with Side and Higher Order In-
formation. arXiv preprint arXiv:1705.02047.
[Socher et al. 2013] Socher, R.; Chen, D.; Manning, C. D.;
and Ng, A. 2013. Reasoning with neural tensor networks
for knowledge base completion. In Advances in neural in-
formation processing systems, 926–934.
[Vincent et al. 2010] Vincent, P.; Larochelle, H.; Lajoie, I.;
Bengio, Y.; and Manzagol, P.-A. 2010. Stacked Denoising
Autoencoders: Learning Useful Representations in a Deep
Network with a Local Denoising Criterion. Journal of Ma-
chine Learning Research 11:3371–3408.
[Wang and Blei 2011] Wang, C., and Blei, D. M. 2011. Col-
laborative topic modeling for recommending scientiﬁc arti-
cles. In Proceedings of the 17th ACM SIGKDD international
conference on Knowledge discovery and data mining, 448–
456. ACM.
[Wang, Shi, and Yeung 2017] Wang, H.; Shi, X.; and Yeung,
D.-y. 2017. Relational Deep Learning : A Deep Latent Vari-
able Model for Link Prediction. AAAI.
[Wang, Wang, and Yeung 2015] Wang, H.; Wang, N.; and
Yeung, D.-Y. 2015. Collaborative Deep Learning for Rec-
ommender Systems. KDD 1235–1244.
[Wu et al. 2016] Wu, Y.; DuBois, C.; Zheng, A. X.; and Es-
ter, M. 2016. Collaborative Denoising Auto-Encoders for
Top-N Recommender Systems. Proceedings of the Ninth
ACM International Conference on Web Search and Data
Mining - WSDM ’16 153–162.
[Ying et al. 2016] Ying, H.; Chen, L.; Xiong, Y.; and Wu, J.
2016. Collaborative deep ranking: A hybrid pair-wise rec-
ommendation algorithm with implicit feedback. Paciﬁc-Asia
Conference on Knowledge Discovery and Data Mining 9652
LNAI:555–567.

