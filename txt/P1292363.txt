8
1
0
2
 
y
a
M
 
1
 
 
]

V
C
.
s
c
[
 
 
1
v
7
8
8
1
0
.
5
0
8
1
:
v
i
X
r
a

Collaborations on YouTube: From Unsupervised Detection to the
Impact on Video and Channel Popularity
Christian Koch, Moritz Lode, Denny Stohr, Amr Rizk, Ralf Steinmetz
Multimedia Communications Lab (KOM), Technische Universität Darmstadt, Germany
E-Mail: {Christian.Koch | Denny.Stohr | Amr.Rizk | Ralf.Steinmetz}@kom.tu-darmstadt.de

Abstract

YouTube is one of the most popular platforms for streaming of user-generated video. Nowadays,
professional YouTubers are organized in so called multi-channel networks (MCNs). These networks
offer services such as brand deals, equipment, and strategic advice in exchange for a share of the
YouTubers’ revenue. A major strategy to gain more subscribers and, hence, revenue is collaborating
with other YouTubers. Yet, collaborations on YouTube have not been studied in a detailed quantita-
tive manner. This paper aims to close this gap with the following contributions. First, we collect a
YouTube dataset covering video statistics over three months for 7,942 channels. Second, we design
a framework for collaboration detection given a previously unknown number of persons featuring in
YouTube videos. We denote this framework for the analysis of collaborations in YouTube videos us-
ing a Deep Neural Network (DNN) based approach as CATANA. Third, we analyze about 2.4 years
of video content and use CATANA to answer research questions providing guidance for YouTubers
and MCNs for efficient collaboration strategies. Thereby, we focus on (i) collaboration frequency
and partner selectivity, (ii) the influence of MCNs on channel collaborations, (iii) collaborating
channel types, and (iv) the impact of collaborations on video and channel popularity. Our results
show that collaborations are in many cases significantly beneficial in terms of viewers and newly
attracted subscribers for both collaborating channels, showing often more than 100% popularity
growth compared with non-collaboration videos.

1 Introduction & Problem Statement

Collaborations are a key strategy to increase the dissemination and, hence, popularity of user-
generated videos on YouTube. Here, YouTuber A, i.e., a content creator, introduces a collaborating
YouTuber B to his viewers seeking to attract their interest to the content of YouTuber B. The rationale
here is that given the viewers interests, they are more likely to watch the introduced YouTuber’s
videos and eventually become subscribers [3, 4, 19]. Collaborations often occur in a reciprocal
manner on both of the collaborating channels to attract each other’s viewers and, thereby, increase
both YouTuber’s revenue. Video monetization can be activated through participating in the YouTube
Partner Program (YPP) [7]. Thereby, YouTubers can configure their videos allowing YouTube to

1/28

insert short ad clips before and within their videos. In return, YouTube pays a share of the resulting
revenues out to the YouTubers. With more than 10k people that were reported in 2016, the annual
growth of the number of YouTubers earning six figures per year amounts to ∼ 50% [20].

In contrast to works describing collaborations, e.g., within scientific communities or online
social networks, there are only few studies on the detection of collaborations in user-generated
videos and a lack of quantitative analysis of their desired impact on popularity. Note that Video-
on-Demand (VoD) platforms such as Netflix are not exposed to user-generated content (UGC)
which is more scattered, diverse, and generated at a much higher rate. While general metadata of
UGC videos is available, no explicit information on collaborations exists. Although mentions of
collaborating YouTubers in the video title or in the description are in general possible, they often
miss collaboration-related information and are, hence, not a reliable source of information.

Nowadays, popular YouTubers often belong to a multi-channel network (MCN), e.g., Broad-
bandTV, Studio71, and Maker Studios, which offer equipment, brand deals, and strategic advice to
increase the YouTubers’ popularity in exchange for a share of their revenue [7]. Essentially, such
strategic advice comprises collaboration policies that describe the most beneficial collaborations
with diverse YouTubers.

Until now, a public documentation on the efficiency of collaborations on YouTube does not exist.
A quantitative analysis of different types of collaborations, e.g., between YouTubers of different
popularity or content categories has the potential to guide YouTubers to popularity- and, hence,
revenue-maximizing behavior. To this end, this article addresses the challenging task of identifying
and analyzing content creator collaborations on large-scale UGC video platforms taking the example
of YouTube. Our analysis focuses on (i) collaboration frequency and partner selectivity, (ii) the
influence of MCNs on channel collaborations, (iii) collaborating channel types, and (iv) the impact
of collaborations on video and channel popularity. In the following sections we address these focus
points in a framework for collaboration detection and analysis denoted CATANA. For the design of
CATANA, we argue that the analysis of content creator collaborations on large-scale UGC video
platforms faces three key challenges:

• YouTube-suitable Face Detection: The YouTubers’ faces constitute the basis for identifying
collaborations. Hence, we require their inference and storage in an appropriate representation.
Changing lights, face expressions, and camera perspectives add to the difficulty of deriving
these representations.

• YouTuber Identification: In contrast to most face recognition tasks, in our scenario, an
unknown number of people appearing in user-generated videos needs to be identified based
on the detected faces. Therefore, an accurate association of face samples to people for a large
set of YouTubers needs to be obtained. Additionally, we need to identify which person is the
owner of the YouTube channel and which persons are potential guests.

• Collaboration Representation: The co-occurrence of YouTubers in a video indicates collab-
oration. However, people appearing sporadically, e.g., passersby do not carry strong evidence
of collaborations. Filtering outliers and storing inferred collaborations in an appropriate form
is essential for further analysis.

2/28

The remainder of this article is structured as follows. Section 2 provides an overview of used
benchmarking datasets, face recognition approaches, and existing works on YouTube collaborations.
In Section 3, we motivate and explain CATANA’s major building blocks. Section 4 presents our
data acquisition and selection process. In Section 5, we evaluate and discuss our results answering
relevant research questions. We conclude our article in Section 6 and discuss future work.

2 Related Work

The related work provides, first, an overview of existing datasets that are useful for benchmarking
face recognition methods on YouTube. Second, an overview of recent face recognition methods is
given. Third, existing works addressing YouTube collaboration analysis are presented and discussed.

2.1 YouTube Face Recognition Datasets

In this section we give a brief overview of the two face datasets used for optimizing CATANA. Both
datasets are frequently used in face recognition studies of the last years, as well as in related work.

Labeled Faces in the Wild (LFW) LFW is a publicly available face dataset introduced in [8]
and released as an effort to spur face recognition research. It has been referenced in more than 50
papers related to face recognition [10]. LFW’s provides a large set of face images in a large range of
variations. This includes variation in pose, lighting, expression, background, ethnicity, and age [9].
The dataset consists of 13,244 images of 5,749 people with images in 250x250 pixel JPEG format.
These face images were collected from the web and contain celebrities, politicians, athletes, and
other public figures. For training, validation, and testing, mutually exclusive splits are available
suited for usage in a 10-fold cross validation. Training and testing data are, thereby, presented as
either matching or mismatching face pairs. Hence, the proposed evaluation experiments aim at the
problem of pair matching, deciding whether the images are of the same person. In total 6,000 pairs
are provided, divided into 10 splits with each 300 match and 300 mismatch pairs.

YouTube Faces (YTF) YTF is a dataset of face videos introduced in [18] and designed for
studying the problem of face recognition in videos. The dataset contains 3,425 videos of 1,595
different people appearing in YouTube videos. These people are a subset of the 5,749 people from
the LFW dataset and for every person an average of 2.15 videos are available. The video duration
ranges between 48 and 6,070 frames and all video frames are stored individually as JPEG images.
Structure and design of YTF is heavily inspired by LFW. Similarly, matching and mismatching pair
are provided, for usage in a 10-fold cross validation pair-matching evaluation. In comparison to the
LFW evaluation, pairs consist of videos, allowing to decide if the pair of videos is subject of the
same person or not. Overall, 5,000 pairs are provided, divided into 10 splits, each containing 250
match and 250 mismatched pairs.

3/28

2.2 Face Recognition

Two kinds of fundamentally different face recognition approaches exist. The first kind that is widely-
spread relies on fixed mathematical models and structures, e.g., Eigenfaces [15] and Local Binary
Patterns Histograms (LBPH) [1]. While these classical approaches have shown solid performance,
the second kind of techniques, using deep neural networks (DNNs) is outperforming classical
approaches and beginning to replace them. As they are clearly superior in performance to classical
approaches and even compared with humans [10], we focus only on DNN-based approaches.

Parkhi et al. [11] present a deep learning-based face recognition method called VGG-Face. The
authors further propose how a very large-scale face dataset can be assembled by a combination
of automation and human in the loop. Focusing on celebrities for the dataset acquisition, they
extract a small number of images using the Google Image Search and the actors’ names. Then,
these images are audited through human annotators. In the next step, the actors are queried again
through image search, this time extracting a bigger amount of images. Instead of human annotation,
a linear Support Vector Machine (SVM) is pre-trained with the small number of images from the
first step and leveraged to classify the newly acquired images. Thereby, a dataset of 2,622 identities
and 2 million images is assembled. Furthermore, a CNN (Convolutional Neural Network) based
face recognition method is proposed, which is trained on the acquired dataset using the triplet-loss
function. The proposed method is then evaluated on the LFW and YTF datasets and compared
against other state-of-the-art methods, resulting in an accuracy of 98.95% for LFW and 97.3% for
YTF. We conclude that image acquisition through online image search can be a promising method
to acquire training data. In the context of this work, channel names could be queried, resulting in
face images of YouTubers. However, this would still require a human interaction for a potentially
large number of YouTubers and passersby in videos.

Schroff et al. [13] present a DNN model named FaceNet. They introduce the triplet loss
for training, i.e., a loss function designed to result in face representations, clustered based on
similarity. Triplet loss thereby works with triplets of matching / non-matching face images and
embeds these into a 128-dimensional Euclidean space. Thereby, the loss function ensures that an
anchor image of a specific person is closer to all other positive images of the same person, than it
is to any negative image from any other person. Thus, the network results in a 128-dimensional
face representation in a space where distances directly correspond to face similarity. Consequently,
classification and clustering are now straightforward by using standard Euclidean distance metrics.
Hence, accuracies of 99.63% on the LFW dataset and 95.1% on YTF were measured. Even though
similar in architecture than the previous DNN [11], a significantly larger private dataset of 200M
images was used for training.

Amos et al. [2] present OpenFace1, a CNN-based face detection and recognition framework
using only openly available training datasets for training. OpenFace builds up on the FaceNet [13]
architecture, combining it with computer vision and machine learning techniques, such as State
Vector Machine (SVM) for classification. For training the CNN model, public face datasets were
used, which licenses allow usage and publication of the resulting models. Hence, no training is

1http://cmusatyalab.github.io/openface [Accessed: 2018-05-08]

4/28

necessary for using the OpenFace framework. OpenFace is thereby trained with only 500,000 images
from combining the two largest labeled face recognition datasets for research, CASIA-WebFace2
and FaceScrub3. Overall, OpenFace achieves an accuracy of 92.92% on LFW.

A related framework to OpenFace is Facenet4, as both are based on FaceNet [13] and its
proposed DNN. Even though Facenet shares almost the same name as FaceNet [13], its developer
have no connection to the authors. In comparison to OpenFace, Facenet additionally implements
multiple additional ideas from different papers to tune accuracy. Amongst others, a different loss
function is used for training, the face representation is 1792-dimensional instead of 128-dimensional
and, furthermore, a different face detection technique is used [21]. Facenet implements the center
loss function [16], which is developed to improve the discriminative power of the learned features,
minimizing the intra-class variation while keeping the classes separable. To do so, it learns a center
for each feature class and penalizes distances between features and their center, resulting in high
accuracy. Facenet is trained using the MS-Celeb-1M face dataset [6], whose license allows model
reproducibility. Facenet is evaluated on the LFW dataset, showing an accuracy of 99.2%.

We conclude that DNN-based approaches show high accuracy on relevant datasets such as LFW
and YTF. As Facenet evidently outperforms the other reviewed approaches, we will deploy it as a
key component for CATANA’s face recognition capabilities.

2.3 Collaborations on YouTube

Mattias Holmbom [7] conducted a study on five YouTube channels, including interviews with their
content creators. He found that it is currently more difficult than ever for new content creators to
establish a YouTube channel, as already a large number of channels exist. Concerning collaborations
on YouTube, three of the five YouTubers associate their popularity directly or indirectly with
collaborations featuring other channels. Furthermore, MCNs were suggested as tool to get help in
finding other YouTubers addressing similar topics for collaboration.

In Brendan Gahan’s article "How to be successful on YouTube: The 3 steps" [3], the third
proposed step for new content creators is collaboration with other YouTubers, which already have an
established subscriber base as an essential step to expand a channel’s audience. YouTube’s official
Creator Academy5 also suggests collaboration as a powerful way to reach new users [19]. This is also
confirmed from MCNs’ side, as the MCN "Channel Frederator Network" recommends to facilitate
and instigate collaborations between network members [4]. We conclude that analyzing channels
registered in the same network can significantly improve the likelihood detecting collaborations.
This is important for our work to control the comparisons of videos with and without collaborations.
Bertram Gugel created a visualization of a share of the YouTube collaboration graph [5]. The
visualized graph provides insights into (i) the size of the respective YouTube channels, measured
by subscriptions, (ii) whether the association is uni- or bidirectional, as well as, (iii) to which

2http://www.cbsr.ia.ac.cn/english/CASIA-WebFace-Database.html [Accessed: 2018-05-08]
3http://vintage.winklerbros.net/facescrub.html [Accessed: 2018-05-08]
4https://github.com/davidsandberg/facenet [Accessed: 2018-05-08]
5YouTube website offering free online courses helping users creating better videos and improve channel performance.

5/28

Figure 1: CATANA’s system architecture.

MCN the channels belong. However, only the Featured Channel List of a YouTube channel is
used to determine a collaboration. On the one hand, this deliberate association between YouTube
channels does not necessarily indicate that channels collaborate. On the other hand, there exists
also collaborations with not featured channels. Furthermore, this work does not provide a thorough
analysis of individual videos and the effect of collaboration on their popularity. Hence, we conclude
that to the best of our knowledge no comprehensive analysis on YouTube collaboration and resulting
effects on popularity exists so far. We set this as the goal of this article.

3 System Design

In the related work, we have seen that it is common practice to recommend YouTubers to collaborate
to increase their audience and, hence, revenue. However, there is a lack of precise and detailed
analysis of the impact of YouTube collaborations on video and channel popularity. With CATANA,
we aim to close this gap. In the following, we motivate CATANA’s major building blocks, depicted
in Figure 1. As our focus is on video and channel popularity, we need the Metadata Crawler which
collects popularity time series, i.e., information of view counts in the case of videos and of the
subscriber counts in the case of channels. These time series are stored in the Database Storage.
Before analyzing the videos, the Video Downloader acquires the video data. In a next step, the
contained faces of the videos are detected and a dense representation is computed and stored in the
Database Storage, together with the video ID allowing to associate the contained faces with the
videos’ popularity time series. Then, the Clustering module determines face-person associations
by associating similar face representations with the same person. The most representative face
representations per person are stored in the Database Storage. The Collaboration Detection module
compares face representations of different videos, thereby allowing to find persons appearing in
different videos, as these videos contain the same face representations, i.e., the same persons. In a
last step, the collaborations detected are stored in form of a bidirectional graph used in the Analysis &
Evaluation module. In the following, we discuss the key processes and design choices of CATANA
in detail.

6/28

Table 1: Face recognition performance comparison with stDev, non-public are grayed out.

LFW

YTF

Eigenfaces
LBPH
Facenet
Openface
Human
FaceNet
VGG

0.6002 ± 0.00791
-
0.6782 ± 0.6300
-
0.9930 ± 0.0042
0.9980 ± 0.00134
0.9292 ± 0.01343 0.9971 ± 0.00264
0.97531
0.9963 ± 0.0009
0.9913

-
0.9512 ± 0.39
0.9740

1 [9]

2 [2]

3 [12]

4 this article

3.1 Face Detection and Recognition

We evaluated six recent approaches (ref. Section 2.2) to choose an appropriate face recognition
method. Eigenfaces [15] uses principal component analysis (PCA) to transform a high-dimensional
face image to a lower-dimensional representation, while Local Binary Patterns Histograms (LBPH)
[1] are histogram-based. In contrast to these traditional well-known methods, we also evaluate recent
DNN-based approaches: Facenet, Openface, FaceNet, and VGG. We compare the performance of
these approaches with two benchmark datasets: LFW and YTF (ref. Section 2.2). Both datasets
provide pairs of matching and non-matching faces useful to assess face recognition methods. The
results are presented in Table 1, depicting the accuracy of the pairwise match/mismatch between
subject pairs in a 10-fold cross-validation. As Facenet performs best on both datasets, and even
outperforms humans, we choose it for CATANA’s face detection and face recognition functionalities.

Frame Extraction and Selection

Typically, face recognition approaches are designed for images, not for video. Due to the large
number of frames per second with usually small changes, it is not efficient to process every frame.
Instead, we use a duration-based frame extraction rate f (n, r) taking the number of frames n in the
video and its frame rate r as inputs to reduce the number of images to process. We extract evenly
spaced frames with a usual rate of 10 frames per minute. For short video, we adapt the rate to extract
at least fmin = 600 frames which shows a good performance. For long videos, the number of frames
extracted is limited for storage reasons to fmax=8,000. One might argue that the frame extraction
approach used is quite simple and could benefit, e.g., from shot boundary detection or face tracking.
Therefore, we additionally tested a sophisticated approach, that does not analyze individual frames
but face tracks, i.e., the face is detected once and followed through the subsequent frames. Therefore,
we used Pyannote-Video6 as a framework to consider a face tracking approach as well in our design.
This framework is based on the face recognition framework Openface [2] and implements shot
boundary detection, face track extraction, and clustering via hierarchical agglomerative clustering.

6https://github.com/pyannote/pyannote-video [Accessed: 2018-05-08]

7/28

3.2 YouTuber Identification

In the previous section, we discussed how a set of face images per video is obtained using Facenet.
In a following step, we use clustering to create an association between images and people. In the
case of face tracks, these are already grouped per individual. However, due to shot boundaries, i.e.,
scene or camera switches, multiple face tracks per individual may exist.

In a next step, we evaluate five different clustering approaches: Pyannote-video in two con-
figurations, DBSCAN, HDBSCAN, and agglomerative clustering (AGG). Pyannote-video can
be configured with different frame extraction and face detection rates. Therefore, two settings
are chosen: C1: Every frame is used for face tracking and 1 frame per second is used for face
recognition. C2: Only 1 frame per second is extracted as well as used for face recognition. To assess
the performance, we evaluate metrics for error rate, number of not clustered images, number of
clusters found, and the clustering runtime.

Figure 2 depicts the evaluation results of the approaches based on the clustering error and number
of not clustered face images. In Figure 3, we show the evaluation results based on the number of
identified clusters and the clustering runtime. We can see that Pyannote-Video C1 has a high number
of erroneously clustered face images. Furthermore, clustering run-time is multiple times higher for
C1 than the video duration, and also multiple times higher than required by the other approaches.
The second configuration C2 performs better than C1, but still worse than the other approaches
regarding clustering errors and clustering runtime. Comparing the two similar approaches DBSCAN
and HDBSCAN a difference in noise handling, measured by the number of not clustered face images
can be noticed. DBSCAN identifies more images as noise than HDBSCAN and all other approaches.
The number of found clusters fits for both density-based approaches: DBSCAN and HDBSCAN,
being close to the optimal number. The major advantage of both density-based approaches, i.e.,
DBSCAN and HDBSCAN over the other approaches is that no estimation of the number of cluster
must be given. Finally, we conclude that both DBSCAN and HDBSCAN perform best amongst the
evaluated techniques. The face tracking approach, while promising in theory, did not perform well.
As the number of not clustered face images suggests, DBSCAN handles noise more conservative
than HDBSCAN, resulting in possible useful images being discarded. A significant advantage of
HDBSCAN over DBSCAN, besides handling varying cluster density, is that it returns probabilities
describing the strength of membership for every face image. This information can be leveraged
to further filter outliers and improve the clustering results. For these reasons we decided to use
HDBSCAN for clustering the face images.

While evaluating the performance measures above, we noticed non-compliant behavior of
HDBSCAN for class one videos, especially in which no other (external) actor appeared. HDBSCAN
thereby fails to create a single cluster and labels all data as noise. This observed effect is due to the
hierarchical approach and it could not be improved through parameter modification. As DBSCAN
performs well on a single cluster case, we use DBSCAN as a fallback solution, coming into effect
when HDBSCAN fails to detect a single cluster.

An alternative approach to clustering is classification. However, this approach was discarded,
as it does not fit our requirement that the face recognition technique should be able to distinguish

8/28

Figure 2: (Left) Number of clustering errors. (Right) Number of not clustered face images.

Figure 3: (Left) Number of clusters found compared to reference (optimal). (Right) clustering
run-time comparison.

between individuals without prior training data. For the sake of completeness, we will give a
brief overview of this alternative approach. Through classification, it is possible to assign detected
faces to known individuals. The problem with this approach in our setting is that training data
is needed for classification. As we have channel information, which is analyzed beforehand, we
could acquire training images through, for example, Google image search. The drawback with
this approach is that the number of content creators per channel is unknown. Thus, the automatic
retrieval of correct training data for multiple persons through image search is not viable. Furthermore,
appearing individuals that are not related to any analyzed channel would not be recognized. For these
reasons, the previously described clustering approach is utilized, incorporating both, HDBSCAN
and DBSCAN.

9/28

3.3 Collaboration Detection

We define a collaboration as the co-occurrence of a YouTuber from a different channel in a YouTu-
ber’s video, e.g., in a video showing both YouTubers or playing a (potentially) prerecorded clip of
the featured YouTuber. To identify collaborations, we build connections between videos using the
previously derived face clusters. Single videos may have multiple face clusters, i.e., at least one
per detected individual. Therefore, we compute a similarity matrix between face clusters using the
Euclidean distance as a similarity measure. In a next step, the similarity matrix is taken as an input
for HDBSCAN clustering which groups all face clusters of individual persons based on the similarity
measure. This gives us face cluster-wise connections showing that the same person appeared in all
connected videos. This information allows the investigation of collaborations between different
channels.

Although we can now connect the appearing individuals, we do not know yet which of the
persons is a content creator, i.e., owner of the channel, or an external actor appearing. To determine
the content creator of a channel, we can select the face cluster with the highest number of appearances
on the channel. However, this approach would be unable to assign multiple content creators to a
single channel. As do not want to restrict this method to single content creator channels and we
assume that some portion of the available channels already have multiple content creator, we use
the following approach. To decide if an individual is a content creator, we leverage the number of
appearances per individual and channel. In detail, a person may have appeared in different channels,
we assign the person as a content creator for the channel with the highest number of appearances.
Thereby, a channel with one or multiple content creators can be correctly detected.

Figure 4: Sample graph of PewDiePie’s YouTube channel and 1-hop neighbors7

10/28

Table 2: Overview of the available crawler tools, ∗are outdated

Scrapy

YTCrawl YOUStatAnalyzer HarVis

ytdata∗

TubeKit∗

Customizable
Documentation
Storage
API usage
Language

Highly
Extensive
Customizable
Yes
Python

limited
sparse
File
No
Python

limited
sparse
MongoDB
Yes
Python

limited
sparse
SQL
Yes
Java

limited
sparse

limited
sparse
SQLite MySQL
Yes
Python

Yes
PHP

Collaboration Graph

Inspired by [5, 17], the collaborations between channels are modeled as a graph with channels as
nodes and collaborations as directed edges connecting the nodes. The edge direction describes
that a content creator of the origin channel appeared, i.e., collaborated, in one or more videos of
the destination channel. Figure 4 depicts an example graph showing one the world’s most popular
YouTubers: PewDiePie. The edge label denotes how often collaborations between the two channels
were observed. We use a graph to visualize and model the collaborations as we can apply different
graph algorithms to analyze the underlying channel relations.

4 YouTube Statistics Data Acquisition

In the following, we briefly describe how we crawl the required information from YouTube and
specify how we select appropriate YouTube channels for crawling our dataset.

4.1 YouTube Data Crawling

To assess the effect of YouTuber collaborations, we need to acquire channel metadata such as
the subscriber count and video view counts. Additionally, we also want to acquire the video and
channel metadata, such as video titles, video and channel descriptions, and the channels’ featured
channel list. The crawled data is not filtered by a specific video topic but through a seed set of
YouTube channels and their uploaded videos. Under those requirements most of the existing tools
such as YTCrawl8, YOUStatAnalyzer9, or HarVis10 cannot be leveraged for our purpose without
significant code changes. Customizing the frameworks requires a solid documentation, which most
of the tools do not provide or only in sparse form. To this end, we decide to develop a YouTube

7Channel images taken from https://www.youtube.com/{PewDiePie, chadwildclay, channel/UCEYLdM2bdhmw-
TS3c0TjFNw, KickThePj, TheBigManTyrone, MrMccruddenmichael, user/LandonProduction, HerrNewstime,
iwantmylauren, iOTrendz, channel/UCIq3bpW-MaAzj4Y2G9ezPhA, channel/UCBINYCmwE29fBXCpUI8DgTA,
channel/UCm3GpkVRonpt2BHrt3GhwjQ,
channel/UCZA-
comicbookresources,
pDB9BW7ZjNcPb3Wu7rRg, imsannachanel, TokyoAtomic, CutiePieMarzia}

JoeCroninSHOW,

8https://github.com/yuhonglin/YTCrawl [Accessed: 2018-05-08]
9https://github.com/mattiazeni/youstatanalyzer [Accessed: 2018-05-08]
10https://github.com/DrUzair/HarVis [Accessed: 2018-05-08]

11/28

data crawling tool based on the Scrapy11 framework which is highly customizable and provides
extensive documentation, that allows to implement all requirements of our envisioned crawler in
reasonable time and with a comparable small effort. Scrapy is widely used and has a big open source
community. Table 2 shows a qualitative comparison of the considered YouTube data crawling tools,
including Scrappy.

Figure 5: Populate spider architecture, d is the user-defined maximum depth for channel recursion.

Next, we describe the design of the Scrapy-based crawling architecture. As we distinguish
between continuous and static data, we implemented two spiders, i.e., crawling modules in Scrapy.
The first spider, which we denote as Populate Spider, crawls static data and populates a database
with channel and video entries, e.g., the video and the channel name. Figure 5 illustrates the crawling
process. The populate spider takes an initial set of channel IDs for which it requests all static data
and subsequently creates a database entry for every crawled channel. Note that for fixed set of
channels d is set to zero to hinder Scrapy from adding additional channels to the set.

In the next step, a second spider denoted Daily Spider crawls continuous data created by the
channels and videos already known in a daily manner, i.e., view count and subscriber count. Here,
each channel’s Upload Playlist is crawled, which contains the videos uploaded by a channel to
identify newly uploaded videos. Crawling the popularity statistics for all videos uploaded on the
given channels allows constructing time series of popularity statistics. We record all interactions
on the monitored channels such as view, comment, and subscriber counts in the time span between
28.12.2016 and 28.03.2017 on a daily basis.

11https://scrapy.org [Accessed: 2018-05-08]

12/28

Figure 6: Daily spider architecture.

4.2 Data Selection and Representation

The Populate Spider needs an initial set of YouTube channel IDs. To create a qualitative and large
dataset of channels, we crawl three of the most popular MCNs [14] as channels associated to a
MCN have higher chances to collaborate [4]. These MCNs are described in table 3. We used
the website SocialBlade12 to derive the mapping of channels to MCN member lists. Here, we
take a random sample of 1.5 × 103 channels for every MCN in which the 100 channels with most
subscribers per MCN are included. In a next step, we use the so called Featured Channel List
of the crawled channels, which contains other channels defined by the channel owner to express
an acquaintanceship between his and other channels. This relationship is modeled in a graph
representation as described in section 3.3, containing roughly 44k channels. Here, channels are
represented by nodes, while the featured channel list comprises unidirectional edges from one node
to other nodes. Finally, non-mutual edges between channels are removed, while mutual edges,
i.e., nodes having each other in their Featured Channel List, are considered likely to collaborate
and, hence, are kept. We also excluded Gaming videos as we observed a lack of face presence in
these videos and, furthermore, often high resolution game figures depicted on covers or within the

12https://socialblade.com/youtube/top/networks/most-subscribed [Accessed: 2018-05-08]

Table 3: Most popular YouTube MCNs worldwide, measured by number of subscribers.

Name

Members

Subscribers (over 30 days) Views (over 30 days)

BroadbandTV
Studio71
Maker Studios

237,235
13,194
9,460

82,718,601
18,535,751
14,011,532

20,107,687,476
5,402,265,290
4,613,091,2598

13/28

videos would have led to increases imprecision. From the remaining subgraph, we extract the largest
connected component, resulting in a graph with roughly 8k nodes and about 10k edges indicating
potential collaborations. By applying CATANA to this subgraph, i.e., analyzing 2.4 years of video
uploaded on these channels for a period of three months, we identified 1,599 nodes and 1,728 edges
representing actual collaborations. The edge sum, which corresponds to the overall number of
collaborations sums up to 3,925, see Table 4.

Table 4: Collaborations observed in the three month’s time span.

Collaborations Duration Mean Median

75-percentile Max

3,925

3 months

2.8

1.0

3.0

134

5 Evaluation

In this section, we formulate and answer research questions with respect to the focus points
of: (i) collaboration frequency and partner selectivity (Section 5.1), (ii) the influence of multi-
channel networks (MCNs) on channel collaborations (Section 5.2), (iii) collaborating channel types
(Section 5.3), and (iv) the impact of collaborations on video and channel popularity (Section 5.4).

5.1 How often do collaborations happen and reoccur with the same partner?

(a) Number of pair-wise collaborations

(b) Number of collaborations per channel

Figure 7: Histograms of detected collaborations per channel pairs (a) and per channel (b)

Using the collaboration graphs, we can easily determine the overall number of collaborations by
summing up the edge weights between two YouTube channels. Analyzing the edge weights allows
us to examine the number of repeated collaborations. Table 4 depicts the derived collaboration
statistics where we observe that the distribution is skewed to the right, indicating the presence

14/28

of a few channel pairs with a comparably high number of collaborations. We confirm this by
drawing the histogram of the collaboration counts in Figure 7a, showing the distribution of repeated
collaborations between two YouTubers who have collaborated at least one. We deduce that over a
3-months observation period collaborations between two channels rarely happen more than once.
In a next step, we analyze the number of collaborations per channel instead of distinct channel
pairs. Therefore, we sum up the edge weights for every channel node. Taking the perspective of a
channel, we differentiate between collaborations taking place in own videos (internal) and videos of
other channels (external). If a collaboration between YouTuber A and B occurs on YouTuber A’s
channel, it is considered as an internal collaboration by A and as an external collaboration by B.
This distinction helps us later to detail the effects on both sides of a collaboration. Figure 7b shows
the corresponding distributions. We conclude that a small number of highly collaborating channels
denoted central channels exists, with most of the remaining channels having very few collaborations.
Thus, central channels show a high in-degree, demonstrating a key influencer role on YouTube.
These YouTubers are especially valuable for product placements, advertisements, and, hence, are
especially valuable assets for their MCNs. One weakness of the former analysis is that it compares
results based on the absolute number of collaborations. Thus, we investigate the relative ratio of a
YouTuber’s collaborations compared to the overall number of the channel uploads. Given the number
of internal collaborations of a channel k, denoting collaborations only occurring in its own videos,
and the number of videos of the channel n, we calculate the collaboration ratio as k/n. Figure 8a
shows the distribution of the collaboration ratio. Values around one imply that in nearly every video
of the channel, a collaboration is found. This may indicate that certain content creators regularly
work together, or share a common channel while also operating separate channels alone. Values
larger than one can occur if multiple collaborations were detected in a single video. In Figure 8b,
we observe only a few outliers with a ratio above one, while most of the channels have a ratio close
to zero. This indicates that a large portion of channels have only a single ingoing collaboration.
Summarizing our finding with respect to collaboration frequency we observe that a single channel
collaborates with other channels on average 2.8 times ([2.5 − 3.15] at a 99% confidence level). If

(a) Collaborations per uploaded videos

(b) Channel collaborations

Figure 8: Collaboration/Video ratio and separated in- and outgoing collaborations.

15/28

channels collaborate, we find in our 3-month dataset that they repeat their collaboration on average
2.3 times ([2.0 − 2.6] at a 99% confidence level). Overall, the distributions for collaboration metrics
are skewed as a consequence of a few highly influential YouTubers.

5.2 How do multi-channel networks (MCNs) influence channel collaborations?

To answer this question, we first analyze which collaborations take place between MCNs. To this end,
we first determine the respective MCN for each channel using publicly available information13 to
augment the channel information of our collaboration graph. Figure 9 depicts the most collaborating
MCNs in form of a MCN-collaboration matrix. Overall, we found 405 MCN pairs collaborating
with each other. Note that the entry None refers to channels for which we could not determine a
MCN association.

Figure 9: Absolute number of collaborations within and between MCNs.

13https://socialblade.com/ [Accessed: 2018-05-08]

16/28

Figure 10: Internal and external MCN collaborations.

Examining the diagonal of the matrix in Figure 9 we observe a distinct trend showing that most
collaborations occur within MCNs, and thus between their members. Further, we observe that
significant collaborations between networks are mainly confined to the three dominant networks,
namely, BroadbandTV, Studio71, and Maker Studios. We find many collaborations of unassociated
channels, i.e., with the label None, with the three dominant networks, which we attribute to the fact
that they are the world’s three largest MCNs and, hence, have YouTube channels associated which
are popular and an attractive target for collaboration. Furthermore, famous YouTubers are a popular
topic for other YouTuber’s that may show the popular YouTuber’s face or video sequences. We
deduce that belonging to a MCN strongly increases the probability of a YouTuber to collaborate.

Figure 10 shows the percentage share of collaborations separated by MCN in- and external
collaborations. Here, we observe that the three largest MCNs, i.e., BroadbandTV, Studio71, and
Maker Studios as well as PranksNetwork have much more internal collaborations compared with
the smaller MCNs. Hence, their YouTubers collaborate more in their own videos than on the
videos of other MCN’s YouTubers. Note that a large portion of the outgoing collaborations is with
channels that are not associated with a MCN. Channels not belonging to a MCN show a preference
to work with MCN-associated channels as more than 70 percent of their collaborations are outgoing.
We conclude that an influence of MCNs concerning YouTuber collaborations can be inferred. In
summary, we find that channels associated with a MCN collaborate more often with each other and
if collaborations occur outside the MCN, then they are usually with non-associated channels and
rarely with other MCNs’ YouTubers.

17/28

Table 5: Popularity class definitions and their number of observed channels.

Popularity Class

Subscriber Range

#Channels

0
1
2
3
4
5
6

[0, 103)
[103, 104)
[104, 105)
[105, 106)
[106, 107)
[107, 5x107)
[5x107, 108)

813
1,575
2,569
2,420
544
20
1

5.3 Which channel types collaborate?

In the following, we group YouTube channels with respect to popularity and content category. First,
we assign each channel to one out of seven popularity classes, based on their subscriber count. Here,
the chosen classes resemble the classes used for the YouTube awards14, which are awards shipped
to the YouTubers when they exceed a certain number of subscribers. Next, we analyze collaboration
behavior regarding the YouTube video category, a label which the YouTuber can select out of a set
of given categories during the video upload process.

YouTube Popularity Classes We assign a channel’s popularity class with respect to the number
of subscribers as depicted in Table 5. In column #Channels, the table shows also the number of
YouTube channels in our dataset which belong to the corresponding popularity class. We can see
that the major share of the channels observed belong to popularity class 1, 2, or 3. Class 6 is an
exception, as it only contains a single channel, i.e., PewDiePie, the most successful YouTuber in
terms of subscribers so far. Figure 11a depicts the share of observed channel collaborations between
popularity classes. Here, channels belonging to a numerically higher class have more subscribers
than channels belonging to numerically smaller classes. The matrix entry atf of row f and column
t denotes that the number of YouTubers from a channel of popularity class f appear in videos
belonging to channels of popularity class t. We can see that most collaborations happen within
class 3 and neighboring classes 2 and 4, which we ascribe to two factors. First, these channels
have reached a popularity in the YouTube environment that attracts collaborations. Second, these
channels do not yet belong to the most popular channels, i.e., categories 4, 5, and 6 but are likely to
try to increase their own popularity by attracting more viewers through collaborations with other
YouTubers.

YouTube Categories
In Figure 11b we show the share of collaborations between YouTube cate-
gories. Most collaborations are detected in, and between the Entertainment and People & Blogs
categories, which is reasonable as they prevalently contain human presence and interaction. The
same applies for categories like Comedy. In the figure, we observe asymmetric relations, e.g.,

14https://www.youtube.com/yt/creators/rewards.html [Accessed: 2018-05-08]

18/28

(a) Popularity classes.

(b) Video categories.

Figure 11: Collaborations within & between popularity classes and YouTube video categories (in
%).

between Comedy and Film & Animation, that collaborate more in with Entertainment channels than
within the same category. For collaborations within a category, i.e., the diagonal of the heat map, we
only notice a surge for Entertainment. We observe that the most frequent collaborations occurred
within the category Entertainment, which also shows the second most video uploads. Note that
Entertainment is a rather generic term and can therefore, depending on the YouTuber’s interpretation,
also include comedy, film, and animation related content.

5.4 How do collaborations impact video and channel popularity?

We investigate the two parts of this question separately, focusing, first, on the observed effects on
video popularity and, second, on channel popularity. Therefore, we use popularity statistics of a
3-months period for roughly 105 videos, considering videos for which we have at least 12 daily
popularity measurements, i.e, videos being older than 12 days. We chose 12 days as we observed
that most older videos do not receive much more views. Using CATANA, we deduce a collaboration
graph with roughly 104 edges indicating collaborations within the observed 8 × 103 channels. Using
two sets for collaboration and non-collaboration videos, we analyze the maximum values of view
and subscriber counts of the 12-days time-span and their gradient. The benefit of these gradients is
that they are not biased by absolute numbers but represent the relative popularity growth.

19/28

Figure 12: Number of views after 12 days for collab. (green) and non-collab. (blue) videos.

5.4.1 Video Popularity

First, we examine the maximum video view counts observed in the first 12 days. Figure 12 shows
the video view count distribution. By examining the left side of the figure, we see in the box plot that
the average view count is higher for videos with a collaboration compared with non-collaborations.
Note that the median is stretched nearly doubled (from about 26k to 45k views) for the cases of
present collaborations. Although the median is only slightly higher in case of a collaboration, the
upper 50% of video views are more scattered and show more views. Additionally, we plotted the
average view counts for both cases and their 95% confidence intervals on the right side of Figure 12
where we see a large gap. The figure suggests that a significantly higher view count can be expected
if a video contains a collaboration.

The generally higher popularity of collaboration videos can be reasoned in the generally higher
popularity of collaborating channels. As we previously examined, class 3 channels collaborate
more often than channels of lower popularity classes. If we therefore assume that more videos
with collaborations are uploaded by class 3 channels, the videos consequently tend to a higher
popularity compared for example with class 2 videos. To further substantiate this effect, we evaluate
the gradient and growth of the video view counts. Hence, we calculate the average view growth
factor between non-collaboration and collaboration videos. For this, we use the average maximal

Figure 13: View count growth factor between collaboration and non-collaborations videos. A
positive value indicates the superiority of collaborations.

20/28

Table 6: View growth of collaborations compared to non-collaborations.

Channels Duration Mean Median

75-percentile Min Max

1116

3 months

34.32

-6.73

32.47

-99.70

6,376.28

Figure 14: Video view count growth for the first five days of a collaboration vs. the
non-collaboration view growth on the first day.

12 day view value for every channel, differentiated by collaboration and non-collaboration. Next,
the percentaged growth from the non-collaboration value to the collaboration value is calculated
channel-wise. Figure 13 displays these results. As only channel with both collaboration and non-
collaboration data could be used for the percentaged growth calculation, samples of 1,116 channels
are used. The difference in number of channels is due to channel which only collaborate in external
videos, and do not host collaboration in their own. Statistics on the differences between the two
video groups on the video view growth are shown in table 6. In a next step, we investigate the
distributions of these view count differences depicted in Figure 13. Here, the 0.95 confidence interval
is between 19% and 51%, indicating that a significant growth of the views between collaboration
and non-collaboration videos can be expected.

Next, we compute the gradients between each pair of the 12 days of the videos’ view counts,
resulting in 11 gradient values. Additionally, we calculate the percentaged growth between these
values. The percentaged growth of the first 6 days after a collaboration vs. non-collaboration view
growth on the first day is depicted by Figure 14. This figure shows the longer lasting temporal
impact of collaborations. Further, Figure 15 shows the box and bar plots of the gradient values, i.e.
the absolute view count increase, using a 0.99 confidence level.

21/28

Figure 15: Video view count gradient.

Figure 16: Channel subscriber gradient and percentaged growth.

5.4.2 Channel Popularity

Here, we cannot directly differentiate between collaboration and non-collaboration channels as for
videos, since one channel may contain both, collaboration and non-collaboration videos. Therefore,
we filter channels, which uploaded videos with and without collaborations, resulting in 1,599
channels. The channel popularity is measured by the number of views of its videos and the number
of channel subscribers. We define a window of two days after a collaboration, for which we will
classify the subscriber counts as belonging to a collaboration, the remaining statistics measured
are classified as belonging to non-collaboration. Thereby, we gathered 9,086 channel subscriber
measurements for collaborations, and 78,877 for non-collaborations. Figure 16 shows the subscriber
count differentiated between collaborations and non-collaborations. From the figure we conclude
that collaborations have a slight positive effect on channel subscribers. Compared to the increase of
viewers, the increase of subscribers is only about one tenth of total users. Though, the relative growth
compared to non-collaborating video measures is about 30% larger in terms of newly attracted
subscribers compared with the newly attracted viewers.

In addition to the above evaluation of the two-day collaboration window, we evaluate a 6-day
window on a daily basis. Figure 17a shows the percentaged subscriber growth over 6 days starting
with day 0, which is the upload date of the collaboration video. Figure 17b depicts the percentaged
subscriber growth for each day and on the left side and the respective overall channel view growth

22/28

(a) Channel subscriber count growth.

(b) Channel view count growth.

Figure 17: Effect of collaboration over the first six days.

Figure 18: Subscriber growth for collaborations between YouTube channel categories.

on the right side. On both sides, also the growth of non-collaboration videos after day 0 is shown
to allow for a comparison. We note that the highest subscriber growth can be observed for days 0
and 1 with the growth slowly decreasing to approach the base line describing non-collaborations.
In addition to the channel subscriber growth, we apply the same evaluation methodology for the
overall channel views, an alternative measure of channel popularity. Here, we expect a similar
pattern as for the channel subscriber counts but we observe a very different pattern, depicted in
Figure 17b. For day zero and one, the view growth is quite low and close to non-collaboration
videos. In contrast to that, for day 2, we observe a significant increase. Despite the fact that more
people watch collaboration videos on day two, we found that users seem to be less engaged as for
day 2 overall less subscriptions are observed than for days 0 and 1.

23/28

Figure 19: View count growth for collaborations between YouTube channel categories.

5.5

Impact of Video Popularity Classes and Video Categories

YouTube Categories Figure 18 and 19 show the impact of a collaboration of YouTubers belonging
to different video categories and popularity classes. We observe that view and subscriber counts vary
strongly amongst different channels. Hence, we compute the relative popularity growth for videos
with and without collaborations. Here, we took only popularity measurements if a collaboration
video was uploaded and at the same day no other video was uploaded to guarantee that the channel
popularity measure is not impaired. In case different categories collaborate, we show the effects
for both categories separately. For all collaborations taking place between YouTubers uploading
mostly videos of the same category, a significant increase of subscriber and view count is observed.
Here, the category People & Blogs is an exception, as on average more subscribers can be attracted
by a collaboration but less video viewers. This is still beneficial as the subscribers are potentially
watching all videos uploaded by the YouTubers in the future.

YouTube Popularity Classes
In Figure 20 and 21 the impact of collaborations between channels
of different popularity classes is shown. In general, we observe a significant benefit of collaborations.
Note that lower popularity classes, especially class 1 and 2 YouTubers benefit significantly stronger
than higher popularity classes. It can be seen that for classes 3 and 4, the gain of a collaboration is
comparably low and often there is no significant difference. For class 4 YouTubers, no effect of
collaborations can be observed. Hence, we deduce that especially for YouTubers with less than 105
subscribers, i.e., class 1 or 2, collaborations significantly increase the number of views.

24/28

Figure 20: Subscriber growth for collaborations between channel popularity classes. The x-axis
denotes the depicted popularity class in the constellation depicted in brackets, e.g., (1 in 3) means
that a YouTuber of popularity class 1 appeared in a video published on a popularity class 3 channel.

Figure 21: View count growth for collaborations between YouTube channel popularity classes.

Concluding our popularity evaluation for videos and channels under collaborations, we state we
observe that collaborations have positive effects on video views and on engaging new subscribers.
Especially for YouTubers of low popularity classes such as class 1, a collaboration can add about
100% additional views and new channel subscribers. Concerning the impact on video views, we
calculated a percentaged growth through collaborations with a mean between 19% and 51% with
0.99 confidence. Also channels popularity is significantly increased through collaborations, i.e., for
both considered metrics, namely channel subscribers and total channel views.

25/28

6 Conclusion and Future Work

In this article, we first designed and implemented a system for the acquisition and analysis of
collaboration data in user generated content at the example of YouTube. We implemented a video-
based face recognition system named CATANA for which we examined and evaluated different face
recognition and clustering techniques. We applied CATANA to a collected dataset of videos over a
3-month period where we extracted appearing content creators and leveraged this information to
detect collaborations between channels.

We observed that out of 7,492 channels in our dataset 1,599 collaborated, with an average of
2.8 times per channel. Regarding the types of channels, which collaborate we found that channels
with a subscriber count between 105 - 106 collaborate the most and the Entertainment YouTube
category shows most collaborations. Furthermore, we inferred that multi-channel networks generally
exhibit collaborations within the same network or channels, which are not associated with any other,
potentially competing, network. We analyzed the acquired popularity statistics for both videos
and channels and found significant differences between collaboration and non-collaboration sets,
indicating a positive effect on the popularity that is measured by subscriber and view counts. In
this work we proposed a viable method for collaboration detection in user generated content that is
based on face recognition. A potential limitation of the proposed system is the differentiation with
respect to the collaboration context, which can be mapped to different types of face appearances, i.e.
posters or content usage. In future work, using voice recognition in addition to face recognition is
likely to increase detection rates as well as differentiate collaboration context.

Reproducibility

To enable other researchers to use, reproduce, and extend our research, we release our tool chain
at https://github.com/christiannkoch/CATANA. This contains: (i) the CATANA
framework and evaluation scripts used here, (ii) the 3-months collaboration graph used in this paper,
and (iii) an interactive web-based visualization of the collaboration graph.

Acknowledgements

This work has been funded in parts by the DFG as part of the Collaborative Research Centre 1053
MAKI (C3, B4).

26/28

References

[1] T. Ahonen, A. Hadid, and M. Pietikainen. Face Description with Local Binary Patterns:
IEEE Transactions on Pattern Analysis and Machine

Application to Face Recognition.
Intelligence, 28, 2006.

[2] B. Amos, B. Ludwiczuk, and M. Satyanarayanan. OpenFace: A general-purpose Face
Recognition Library with Mobile Applications. Technical report, CMU-CS-16-118, CMU
School of Computer Science, 2016.

[3] B. Gahan. How to be successful on YouTube: The 3 steps. http://thenextweb.com/
insider/2015/03/04/the-3-steps-to-success-on-youtube/, 2015. [Ac-
cessed: 2018-05-08].

[4] M. Gielen. Best Practices For A YouTube Multi-Channel Network 2.0. http://www.
tubefilter.com/2015/03/24/youtube-mcn-multi-channel-network/,
2015. [Accessed: 2018-05-08].

YouTube Universum. Die Vernetzung

[5] B. Gugel.
sualisiert.
youtube-universum-die-vernetzung-der-youtuber-visualisiert.
html, 2015. [Accessed: 2018-05-08].

vi-
http://www.gugelproductions.de/blog/2015/

der YouTuber

[6] Y. Guo, L. Zhang, Y. Hu, X. He, and J. Gao. Ms-celeb-1m: A Dataset and Benchmark for
large-scale Face Recognition. In European Conference on Computer Vision, pages 87–102.
Springer, 2016.

[7] M. Holmbom. The YouTuber A Qualitative Study of Popular Content Creators. Bachelor

thesis, Umea University, 2015.

[8] G. B. Huang, M. Ramesh, T. Berg, and E. Learned-Miller. Labeled Faces in the Wild: A
Database for Studying Face Recognition in Unconstrained Environments. Technical report,
University of Massachusetts, Amherst, 2007.

[9] E. Learned-Miller, G. B. Huang, A. R. Chowdhury, H. Li, and G. Hua. Labeled Faces in the
Wild Website. http://vis-www.cs.umass.edu/lfw/. [Accessed: 2018-05-08].

[10] E. Learned-Miller, G. B. Huang, A. RoyChowdhury, H. Li, and G. Hua. Labeled Faces in the
Wild: A Survey. In Advances in Face Detection and Facial Image Analysis, pages 189–248.
Springer, 2016.

[11] O. M. Parkhi, A. Vedaldi, and A. Zisserman. Deep Face Recognition. In Proceedings of the

British Machine Vision Conference (BMVC), 2015.

27/28

[12] D. Sandberg. Facenet Project Repository. https://github.com/davidsandberg/

facenet. [Accessed: 2018-05-08].

[13] F. Schroff, D. Kalenichenko, and J. Philbin. FaceNet : A Unified Embedding for Face
Recognition and Clustering. In IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), 2015.

[14] Social Blade LLC. SocialBlade Network Statistics. https://socialblade.com/

youtube/top/networks. [Accessed: 2018-05-08].

[15] M. Turk and A. Pentland. Eigenfaces for recognition. volume 3, pages 71–86. MIT Press,

1991.

Face Recognition. 2016.

[16] Y. Wen, K. Zhang, Z. Li, and Y. Qiao. A Discriminative Feature Learning Approach for Deep

[17] C. Wilson, B. Boe, A. Sala, K. P. N. Puttaswamy, and B. Y. Zhao. User Interactions in
Social Networks and Their Implications. In ACM European Conference on Computer Systems,
EuroSys’09, 2009.

[18] L. Wolf, T. Hassner, and I. Maoz. Face Recognition in Unconstrained Videos with Matched
Background Similarity. In IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), 2011.

[19] YouTube, LLC. Youtube Creator Academy: Collaboration. https://creatoracademy.

youtube.com/page/lesson/collaboration. [Accessed: 2018-05-08].

[20] YouTube, LLC. YouTube Statistics.

https://www.youtube.com/yt/press/

statistics.html. [Accessed: 2018-05-08].

[21] K. Zhang, Z. Zhang, Z. Li, and Y. Qiao. MTCNN Face Detection. https://kpzhang93.
[Accessed:

github.io/MTCNN_face_detection_alignment/index.html.
2018-05-08].

28/28

8
1
0
2
 
y
a
M
 
1
 
 
]

V
C
.
s
c
[
 
 
1
v
7
8
8
1
0
.
5
0
8
1
:
v
i
X
r
a

Collaborations on YouTube: From Unsupervised Detection to the
Impact on Video and Channel Popularity
Christian Koch, Moritz Lode, Denny Stohr, Amr Rizk, Ralf Steinmetz
Multimedia Communications Lab (KOM), Technische Universität Darmstadt, Germany
E-Mail: {Christian.Koch | Denny.Stohr | Amr.Rizk | Ralf.Steinmetz}@kom.tu-darmstadt.de

Abstract

YouTube is one of the most popular platforms for streaming of user-generated video. Nowadays,
professional YouTubers are organized in so called multi-channel networks (MCNs). These networks
offer services such as brand deals, equipment, and strategic advice in exchange for a share of the
YouTubers’ revenue. A major strategy to gain more subscribers and, hence, revenue is collaborating
with other YouTubers. Yet, collaborations on YouTube have not been studied in a detailed quantita-
tive manner. This paper aims to close this gap with the following contributions. First, we collect a
YouTube dataset covering video statistics over three months for 7,942 channels. Second, we design
a framework for collaboration detection given a previously unknown number of persons featuring in
YouTube videos. We denote this framework for the analysis of collaborations in YouTube videos us-
ing a Deep Neural Network (DNN) based approach as CATANA. Third, we analyze about 2.4 years
of video content and use CATANA to answer research questions providing guidance for YouTubers
and MCNs for efficient collaboration strategies. Thereby, we focus on (i) collaboration frequency
and partner selectivity, (ii) the influence of MCNs on channel collaborations, (iii) collaborating
channel types, and (iv) the impact of collaborations on video and channel popularity. Our results
show that collaborations are in many cases significantly beneficial in terms of viewers and newly
attracted subscribers for both collaborating channels, showing often more than 100% popularity
growth compared with non-collaboration videos.

1 Introduction & Problem Statement

Collaborations are a key strategy to increase the dissemination and, hence, popularity of user-
generated videos on YouTube. Here, YouTuber A, i.e., a content creator, introduces a collaborating
YouTuber B to his viewers seeking to attract their interest to the content of YouTuber B. The rationale
here is that given the viewers interests, they are more likely to watch the introduced YouTuber’s
videos and eventually become subscribers [3, 4, 19]. Collaborations often occur in a reciprocal
manner on both of the collaborating channels to attract each other’s viewers and, thereby, increase
both YouTuber’s revenue. Video monetization can be activated through participating in the YouTube
Partner Program (YPP) [7]. Thereby, YouTubers can configure their videos allowing YouTube to

1/28

insert short ad clips before and within their videos. In return, YouTube pays a share of the resulting
revenues out to the YouTubers. With more than 10k people that were reported in 2016, the annual
growth of the number of YouTubers earning six figures per year amounts to ∼ 50% [20].

In contrast to works describing collaborations, e.g., within scientific communities or online
social networks, there are only few studies on the detection of collaborations in user-generated
videos and a lack of quantitative analysis of their desired impact on popularity. Note that Video-
on-Demand (VoD) platforms such as Netflix are not exposed to user-generated content (UGC)
which is more scattered, diverse, and generated at a much higher rate. While general metadata of
UGC videos is available, no explicit information on collaborations exists. Although mentions of
collaborating YouTubers in the video title or in the description are in general possible, they often
miss collaboration-related information and are, hence, not a reliable source of information.

Nowadays, popular YouTubers often belong to a multi-channel network (MCN), e.g., Broad-
bandTV, Studio71, and Maker Studios, which offer equipment, brand deals, and strategic advice to
increase the YouTubers’ popularity in exchange for a share of their revenue [7]. Essentially, such
strategic advice comprises collaboration policies that describe the most beneficial collaborations
with diverse YouTubers.

Until now, a public documentation on the efficiency of collaborations on YouTube does not exist.
A quantitative analysis of different types of collaborations, e.g., between YouTubers of different
popularity or content categories has the potential to guide YouTubers to popularity- and, hence,
revenue-maximizing behavior. To this end, this article addresses the challenging task of identifying
and analyzing content creator collaborations on large-scale UGC video platforms taking the example
of YouTube. Our analysis focuses on (i) collaboration frequency and partner selectivity, (ii) the
influence of MCNs on channel collaborations, (iii) collaborating channel types, and (iv) the impact
of collaborations on video and channel popularity. In the following sections we address these focus
points in a framework for collaboration detection and analysis denoted CATANA. For the design of
CATANA, we argue that the analysis of content creator collaborations on large-scale UGC video
platforms faces three key challenges:

• YouTube-suitable Face Detection: The YouTubers’ faces constitute the basis for identifying
collaborations. Hence, we require their inference and storage in an appropriate representation.
Changing lights, face expressions, and camera perspectives add to the difficulty of deriving
these representations.

• YouTuber Identification: In contrast to most face recognition tasks, in our scenario, an
unknown number of people appearing in user-generated videos needs to be identified based
on the detected faces. Therefore, an accurate association of face samples to people for a large
set of YouTubers needs to be obtained. Additionally, we need to identify which person is the
owner of the YouTube channel and which persons are potential guests.

• Collaboration Representation: The co-occurrence of YouTubers in a video indicates collab-
oration. However, people appearing sporadically, e.g., passersby do not carry strong evidence
of collaborations. Filtering outliers and storing inferred collaborations in an appropriate form
is essential for further analysis.

2/28

The remainder of this article is structured as follows. Section 2 provides an overview of used
benchmarking datasets, face recognition approaches, and existing works on YouTube collaborations.
In Section 3, we motivate and explain CATANA’s major building blocks. Section 4 presents our
data acquisition and selection process. In Section 5, we evaluate and discuss our results answering
relevant research questions. We conclude our article in Section 6 and discuss future work.

2 Related Work

The related work provides, first, an overview of existing datasets that are useful for benchmarking
face recognition methods on YouTube. Second, an overview of recent face recognition methods is
given. Third, existing works addressing YouTube collaboration analysis are presented and discussed.

2.1 YouTube Face Recognition Datasets

In this section we give a brief overview of the two face datasets used for optimizing CATANA. Both
datasets are frequently used in face recognition studies of the last years, as well as in related work.

Labeled Faces in the Wild (LFW) LFW is a publicly available face dataset introduced in [8]
and released as an effort to spur face recognition research. It has been referenced in more than 50
papers related to face recognition [10]. LFW’s provides a large set of face images in a large range of
variations. This includes variation in pose, lighting, expression, background, ethnicity, and age [9].
The dataset consists of 13,244 images of 5,749 people with images in 250x250 pixel JPEG format.
These face images were collected from the web and contain celebrities, politicians, athletes, and
other public figures. For training, validation, and testing, mutually exclusive splits are available
suited for usage in a 10-fold cross validation. Training and testing data are, thereby, presented as
either matching or mismatching face pairs. Hence, the proposed evaluation experiments aim at the
problem of pair matching, deciding whether the images are of the same person. In total 6,000 pairs
are provided, divided into 10 splits with each 300 match and 300 mismatch pairs.

YouTube Faces (YTF) YTF is a dataset of face videos introduced in [18] and designed for
studying the problem of face recognition in videos. The dataset contains 3,425 videos of 1,595
different people appearing in YouTube videos. These people are a subset of the 5,749 people from
the LFW dataset and for every person an average of 2.15 videos are available. The video duration
ranges between 48 and 6,070 frames and all video frames are stored individually as JPEG images.
Structure and design of YTF is heavily inspired by LFW. Similarly, matching and mismatching pair
are provided, for usage in a 10-fold cross validation pair-matching evaluation. In comparison to the
LFW evaluation, pairs consist of videos, allowing to decide if the pair of videos is subject of the
same person or not. Overall, 5,000 pairs are provided, divided into 10 splits, each containing 250
match and 250 mismatched pairs.

3/28

2.2 Face Recognition

Two kinds of fundamentally different face recognition approaches exist. The first kind that is widely-
spread relies on fixed mathematical models and structures, e.g., Eigenfaces [15] and Local Binary
Patterns Histograms (LBPH) [1]. While these classical approaches have shown solid performance,
the second kind of techniques, using deep neural networks (DNNs) is outperforming classical
approaches and beginning to replace them. As they are clearly superior in performance to classical
approaches and even compared with humans [10], we focus only on DNN-based approaches.

Parkhi et al. [11] present a deep learning-based face recognition method called VGG-Face. The
authors further propose how a very large-scale face dataset can be assembled by a combination
of automation and human in the loop. Focusing on celebrities for the dataset acquisition, they
extract a small number of images using the Google Image Search and the actors’ names. Then,
these images are audited through human annotators. In the next step, the actors are queried again
through image search, this time extracting a bigger amount of images. Instead of human annotation,
a linear Support Vector Machine (SVM) is pre-trained with the small number of images from the
first step and leveraged to classify the newly acquired images. Thereby, a dataset of 2,622 identities
and 2 million images is assembled. Furthermore, a CNN (Convolutional Neural Network) based
face recognition method is proposed, which is trained on the acquired dataset using the triplet-loss
function. The proposed method is then evaluated on the LFW and YTF datasets and compared
against other state-of-the-art methods, resulting in an accuracy of 98.95% for LFW and 97.3% for
YTF. We conclude that image acquisition through online image search can be a promising method
to acquire training data. In the context of this work, channel names could be queried, resulting in
face images of YouTubers. However, this would still require a human interaction for a potentially
large number of YouTubers and passersby in videos.

Schroff et al. [13] present a DNN model named FaceNet. They introduce the triplet loss
for training, i.e., a loss function designed to result in face representations, clustered based on
similarity. Triplet loss thereby works with triplets of matching / non-matching face images and
embeds these into a 128-dimensional Euclidean space. Thereby, the loss function ensures that an
anchor image of a specific person is closer to all other positive images of the same person, than it
is to any negative image from any other person. Thus, the network results in a 128-dimensional
face representation in a space where distances directly correspond to face similarity. Consequently,
classification and clustering are now straightforward by using standard Euclidean distance metrics.
Hence, accuracies of 99.63% on the LFW dataset and 95.1% on YTF were measured. Even though
similar in architecture than the previous DNN [11], a significantly larger private dataset of 200M
images was used for training.

Amos et al. [2] present OpenFace1, a CNN-based face detection and recognition framework
using only openly available training datasets for training. OpenFace builds up on the FaceNet [13]
architecture, combining it with computer vision and machine learning techniques, such as State
Vector Machine (SVM) for classification. For training the CNN model, public face datasets were
used, which licenses allow usage and publication of the resulting models. Hence, no training is

1http://cmusatyalab.github.io/openface [Accessed: 2018-05-08]

4/28

necessary for using the OpenFace framework. OpenFace is thereby trained with only 500,000 images
from combining the two largest labeled face recognition datasets for research, CASIA-WebFace2
and FaceScrub3. Overall, OpenFace achieves an accuracy of 92.92% on LFW.

A related framework to OpenFace is Facenet4, as both are based on FaceNet [13] and its
proposed DNN. Even though Facenet shares almost the same name as FaceNet [13], its developer
have no connection to the authors. In comparison to OpenFace, Facenet additionally implements
multiple additional ideas from different papers to tune accuracy. Amongst others, a different loss
function is used for training, the face representation is 1792-dimensional instead of 128-dimensional
and, furthermore, a different face detection technique is used [21]. Facenet implements the center
loss function [16], which is developed to improve the discriminative power of the learned features,
minimizing the intra-class variation while keeping the classes separable. To do so, it learns a center
for each feature class and penalizes distances between features and their center, resulting in high
accuracy. Facenet is trained using the MS-Celeb-1M face dataset [6], whose license allows model
reproducibility. Facenet is evaluated on the LFW dataset, showing an accuracy of 99.2%.

We conclude that DNN-based approaches show high accuracy on relevant datasets such as LFW
and YTF. As Facenet evidently outperforms the other reviewed approaches, we will deploy it as a
key component for CATANA’s face recognition capabilities.

2.3 Collaborations on YouTube

Mattias Holmbom [7] conducted a study on five YouTube channels, including interviews with their
content creators. He found that it is currently more difficult than ever for new content creators to
establish a YouTube channel, as already a large number of channels exist. Concerning collaborations
on YouTube, three of the five YouTubers associate their popularity directly or indirectly with
collaborations featuring other channels. Furthermore, MCNs were suggested as tool to get help in
finding other YouTubers addressing similar topics for collaboration.

In Brendan Gahan’s article "How to be successful on YouTube: The 3 steps" [3], the third
proposed step for new content creators is collaboration with other YouTubers, which already have an
established subscriber base as an essential step to expand a channel’s audience. YouTube’s official
Creator Academy5 also suggests collaboration as a powerful way to reach new users [19]. This is also
confirmed from MCNs’ side, as the MCN "Channel Frederator Network" recommends to facilitate
and instigate collaborations between network members [4]. We conclude that analyzing channels
registered in the same network can significantly improve the likelihood detecting collaborations.
This is important for our work to control the comparisons of videos with and without collaborations.
Bertram Gugel created a visualization of a share of the YouTube collaboration graph [5]. The
visualized graph provides insights into (i) the size of the respective YouTube channels, measured
by subscriptions, (ii) whether the association is uni- or bidirectional, as well as, (iii) to which

2http://www.cbsr.ia.ac.cn/english/CASIA-WebFace-Database.html [Accessed: 2018-05-08]
3http://vintage.winklerbros.net/facescrub.html [Accessed: 2018-05-08]
4https://github.com/davidsandberg/facenet [Accessed: 2018-05-08]
5YouTube website offering free online courses helping users creating better videos and improve channel performance.

5/28

Figure 1: CATANA’s system architecture.

MCN the channels belong. However, only the Featured Channel List of a YouTube channel is
used to determine a collaboration. On the one hand, this deliberate association between YouTube
channels does not necessarily indicate that channels collaborate. On the other hand, there exists
also collaborations with not featured channels. Furthermore, this work does not provide a thorough
analysis of individual videos and the effect of collaboration on their popularity. Hence, we conclude
that to the best of our knowledge no comprehensive analysis on YouTube collaboration and resulting
effects on popularity exists so far. We set this as the goal of this article.

3 System Design

In the related work, we have seen that it is common practice to recommend YouTubers to collaborate
to increase their audience and, hence, revenue. However, there is a lack of precise and detailed
analysis of the impact of YouTube collaborations on video and channel popularity. With CATANA,
we aim to close this gap. In the following, we motivate CATANA’s major building blocks, depicted
in Figure 1. As our focus is on video and channel popularity, we need the Metadata Crawler which
collects popularity time series, i.e., information of view counts in the case of videos and of the
subscriber counts in the case of channels. These time series are stored in the Database Storage.
Before analyzing the videos, the Video Downloader acquires the video data. In a next step, the
contained faces of the videos are detected and a dense representation is computed and stored in the
Database Storage, together with the video ID allowing to associate the contained faces with the
videos’ popularity time series. Then, the Clustering module determines face-person associations
by associating similar face representations with the same person. The most representative face
representations per person are stored in the Database Storage. The Collaboration Detection module
compares face representations of different videos, thereby allowing to find persons appearing in
different videos, as these videos contain the same face representations, i.e., the same persons. In a
last step, the collaborations detected are stored in form of a bidirectional graph used in the Analysis &
Evaluation module. In the following, we discuss the key processes and design choices of CATANA
in detail.

6/28

Table 1: Face recognition performance comparison with stDev, non-public are grayed out.

LFW

YTF

Eigenfaces
LBPH
Facenet
Openface
Human
FaceNet
VGG

0.6002 ± 0.00791
-
0.6782 ± 0.6300
-
0.9930 ± 0.0042
0.9980 ± 0.00134
0.9292 ± 0.01343 0.9971 ± 0.00264
0.97531
0.9963 ± 0.0009
0.9913

-
0.9512 ± 0.39
0.9740

1 [9]

2 [2]

3 [12]

4 this article

3.1 Face Detection and Recognition

We evaluated six recent approaches (ref. Section 2.2) to choose an appropriate face recognition
method. Eigenfaces [15] uses principal component analysis (PCA) to transform a high-dimensional
face image to a lower-dimensional representation, while Local Binary Patterns Histograms (LBPH)
[1] are histogram-based. In contrast to these traditional well-known methods, we also evaluate recent
DNN-based approaches: Facenet, Openface, FaceNet, and VGG. We compare the performance of
these approaches with two benchmark datasets: LFW and YTF (ref. Section 2.2). Both datasets
provide pairs of matching and non-matching faces useful to assess face recognition methods. The
results are presented in Table 1, depicting the accuracy of the pairwise match/mismatch between
subject pairs in a 10-fold cross-validation. As Facenet performs best on both datasets, and even
outperforms humans, we choose it for CATANA’s face detection and face recognition functionalities.

Frame Extraction and Selection

Typically, face recognition approaches are designed for images, not for video. Due to the large
number of frames per second with usually small changes, it is not efficient to process every frame.
Instead, we use a duration-based frame extraction rate f (n, r) taking the number of frames n in the
video and its frame rate r as inputs to reduce the number of images to process. We extract evenly
spaced frames with a usual rate of 10 frames per minute. For short video, we adapt the rate to extract
at least fmin = 600 frames which shows a good performance. For long videos, the number of frames
extracted is limited for storage reasons to fmax=8,000. One might argue that the frame extraction
approach used is quite simple and could benefit, e.g., from shot boundary detection or face tracking.
Therefore, we additionally tested a sophisticated approach, that does not analyze individual frames
but face tracks, i.e., the face is detected once and followed through the subsequent frames. Therefore,
we used Pyannote-Video6 as a framework to consider a face tracking approach as well in our design.
This framework is based on the face recognition framework Openface [2] and implements shot
boundary detection, face track extraction, and clustering via hierarchical agglomerative clustering.

6https://github.com/pyannote/pyannote-video [Accessed: 2018-05-08]

7/28

3.2 YouTuber Identification

In the previous section, we discussed how a set of face images per video is obtained using Facenet.
In a following step, we use clustering to create an association between images and people. In the
case of face tracks, these are already grouped per individual. However, due to shot boundaries, i.e.,
scene or camera switches, multiple face tracks per individual may exist.

In a next step, we evaluate five different clustering approaches: Pyannote-video in two con-
figurations, DBSCAN, HDBSCAN, and agglomerative clustering (AGG). Pyannote-video can
be configured with different frame extraction and face detection rates. Therefore, two settings
are chosen: C1: Every frame is used for face tracking and 1 frame per second is used for face
recognition. C2: Only 1 frame per second is extracted as well as used for face recognition. To assess
the performance, we evaluate metrics for error rate, number of not clustered images, number of
clusters found, and the clustering runtime.

Figure 2 depicts the evaluation results of the approaches based on the clustering error and number
of not clustered face images. In Figure 3, we show the evaluation results based on the number of
identified clusters and the clustering runtime. We can see that Pyannote-Video C1 has a high number
of erroneously clustered face images. Furthermore, clustering run-time is multiple times higher for
C1 than the video duration, and also multiple times higher than required by the other approaches.
The second configuration C2 performs better than C1, but still worse than the other approaches
regarding clustering errors and clustering runtime. Comparing the two similar approaches DBSCAN
and HDBSCAN a difference in noise handling, measured by the number of not clustered face images
can be noticed. DBSCAN identifies more images as noise than HDBSCAN and all other approaches.
The number of found clusters fits for both density-based approaches: DBSCAN and HDBSCAN,
being close to the optimal number. The major advantage of both density-based approaches, i.e.,
DBSCAN and HDBSCAN over the other approaches is that no estimation of the number of cluster
must be given. Finally, we conclude that both DBSCAN and HDBSCAN perform best amongst the
evaluated techniques. The face tracking approach, while promising in theory, did not perform well.
As the number of not clustered face images suggests, DBSCAN handles noise more conservative
than HDBSCAN, resulting in possible useful images being discarded. A significant advantage of
HDBSCAN over DBSCAN, besides handling varying cluster density, is that it returns probabilities
describing the strength of membership for every face image. This information can be leveraged
to further filter outliers and improve the clustering results. For these reasons we decided to use
HDBSCAN for clustering the face images.

While evaluating the performance measures above, we noticed non-compliant behavior of
HDBSCAN for class one videos, especially in which no other (external) actor appeared. HDBSCAN
thereby fails to create a single cluster and labels all data as noise. This observed effect is due to the
hierarchical approach and it could not be improved through parameter modification. As DBSCAN
performs well on a single cluster case, we use DBSCAN as a fallback solution, coming into effect
when HDBSCAN fails to detect a single cluster.

An alternative approach to clustering is classification. However, this approach was discarded,
as it does not fit our requirement that the face recognition technique should be able to distinguish

8/28

Figure 2: (Left) Number of clustering errors. (Right) Number of not clustered face images.

Figure 3: (Left) Number of clusters found compared to reference (optimal). (Right) clustering
run-time comparison.

between individuals without prior training data. For the sake of completeness, we will give a
brief overview of this alternative approach. Through classification, it is possible to assign detected
faces to known individuals. The problem with this approach in our setting is that training data
is needed for classification. As we have channel information, which is analyzed beforehand, we
could acquire training images through, for example, Google image search. The drawback with
this approach is that the number of content creators per channel is unknown. Thus, the automatic
retrieval of correct training data for multiple persons through image search is not viable. Furthermore,
appearing individuals that are not related to any analyzed channel would not be recognized. For these
reasons, the previously described clustering approach is utilized, incorporating both, HDBSCAN
and DBSCAN.

9/28

3.3 Collaboration Detection

We define a collaboration as the co-occurrence of a YouTuber from a different channel in a YouTu-
ber’s video, e.g., in a video showing both YouTubers or playing a (potentially) prerecorded clip of
the featured YouTuber. To identify collaborations, we build connections between videos using the
previously derived face clusters. Single videos may have multiple face clusters, i.e., at least one
per detected individual. Therefore, we compute a similarity matrix between face clusters using the
Euclidean distance as a similarity measure. In a next step, the similarity matrix is taken as an input
for HDBSCAN clustering which groups all face clusters of individual persons based on the similarity
measure. This gives us face cluster-wise connections showing that the same person appeared in all
connected videos. This information allows the investigation of collaborations between different
channels.

Although we can now connect the appearing individuals, we do not know yet which of the
persons is a content creator, i.e., owner of the channel, or an external actor appearing. To determine
the content creator of a channel, we can select the face cluster with the highest number of appearances
on the channel. However, this approach would be unable to assign multiple content creators to a
single channel. As do not want to restrict this method to single content creator channels and we
assume that some portion of the available channels already have multiple content creator, we use
the following approach. To decide if an individual is a content creator, we leverage the number of
appearances per individual and channel. In detail, a person may have appeared in different channels,
we assign the person as a content creator for the channel with the highest number of appearances.
Thereby, a channel with one or multiple content creators can be correctly detected.

Figure 4: Sample graph of PewDiePie’s YouTube channel and 1-hop neighbors7

10/28

Table 2: Overview of the available crawler tools, ∗are outdated

Scrapy

YTCrawl YOUStatAnalyzer HarVis

ytdata∗

TubeKit∗

Customizable
Documentation
Storage
API usage
Language

Highly
Extensive
Customizable
Yes
Python

limited
sparse
File
No
Python

limited
sparse
MongoDB
Yes
Python

limited
sparse
SQL
Yes
Java

limited
sparse

limited
sparse
SQLite MySQL
Yes
Python

Yes
PHP

Collaboration Graph

Inspired by [5, 17], the collaborations between channels are modeled as a graph with channels as
nodes and collaborations as directed edges connecting the nodes. The edge direction describes
that a content creator of the origin channel appeared, i.e., collaborated, in one or more videos of
the destination channel. Figure 4 depicts an example graph showing one the world’s most popular
YouTubers: PewDiePie. The edge label denotes how often collaborations between the two channels
were observed. We use a graph to visualize and model the collaborations as we can apply different
graph algorithms to analyze the underlying channel relations.

4 YouTube Statistics Data Acquisition

In the following, we briefly describe how we crawl the required information from YouTube and
specify how we select appropriate YouTube channels for crawling our dataset.

4.1 YouTube Data Crawling

To assess the effect of YouTuber collaborations, we need to acquire channel metadata such as
the subscriber count and video view counts. Additionally, we also want to acquire the video and
channel metadata, such as video titles, video and channel descriptions, and the channels’ featured
channel list. The crawled data is not filtered by a specific video topic but through a seed set of
YouTube channels and their uploaded videos. Under those requirements most of the existing tools
such as YTCrawl8, YOUStatAnalyzer9, or HarVis10 cannot be leveraged for our purpose without
significant code changes. Customizing the frameworks requires a solid documentation, which most
of the tools do not provide or only in sparse form. To this end, we decide to develop a YouTube

7Channel images taken from https://www.youtube.com/{PewDiePie, chadwildclay, channel/UCEYLdM2bdhmw-
TS3c0TjFNw, KickThePj, TheBigManTyrone, MrMccruddenmichael, user/LandonProduction, HerrNewstime,
iwantmylauren, iOTrendz, channel/UCIq3bpW-MaAzj4Y2G9ezPhA, channel/UCBINYCmwE29fBXCpUI8DgTA,
channel/UCm3GpkVRonpt2BHrt3GhwjQ,
channel/UCZA-
comicbookresources,
pDB9BW7ZjNcPb3Wu7rRg, imsannachanel, TokyoAtomic, CutiePieMarzia}

JoeCroninSHOW,

8https://github.com/yuhonglin/YTCrawl [Accessed: 2018-05-08]
9https://github.com/mattiazeni/youstatanalyzer [Accessed: 2018-05-08]
10https://github.com/DrUzair/HarVis [Accessed: 2018-05-08]

11/28

data crawling tool based on the Scrapy11 framework which is highly customizable and provides
extensive documentation, that allows to implement all requirements of our envisioned crawler in
reasonable time and with a comparable small effort. Scrapy is widely used and has a big open source
community. Table 2 shows a qualitative comparison of the considered YouTube data crawling tools,
including Scrappy.

Figure 5: Populate spider architecture, d is the user-defined maximum depth for channel recursion.

Next, we describe the design of the Scrapy-based crawling architecture. As we distinguish
between continuous and static data, we implemented two spiders, i.e., crawling modules in Scrapy.
The first spider, which we denote as Populate Spider, crawls static data and populates a database
with channel and video entries, e.g., the video and the channel name. Figure 5 illustrates the crawling
process. The populate spider takes an initial set of channel IDs for which it requests all static data
and subsequently creates a database entry for every crawled channel. Note that for fixed set of
channels d is set to zero to hinder Scrapy from adding additional channels to the set.

In the next step, a second spider denoted Daily Spider crawls continuous data created by the
channels and videos already known in a daily manner, i.e., view count and subscriber count. Here,
each channel’s Upload Playlist is crawled, which contains the videos uploaded by a channel to
identify newly uploaded videos. Crawling the popularity statistics for all videos uploaded on the
given channels allows constructing time series of popularity statistics. We record all interactions
on the monitored channels such as view, comment, and subscriber counts in the time span between
28.12.2016 and 28.03.2017 on a daily basis.

11https://scrapy.org [Accessed: 2018-05-08]

12/28

Figure 6: Daily spider architecture.

4.2 Data Selection and Representation

The Populate Spider needs an initial set of YouTube channel IDs. To create a qualitative and large
dataset of channels, we crawl three of the most popular MCNs [14] as channels associated to a
MCN have higher chances to collaborate [4]. These MCNs are described in table 3. We used
the website SocialBlade12 to derive the mapping of channels to MCN member lists. Here, we
take a random sample of 1.5 × 103 channels for every MCN in which the 100 channels with most
subscribers per MCN are included. In a next step, we use the so called Featured Channel List
of the crawled channels, which contains other channels defined by the channel owner to express
an acquaintanceship between his and other channels. This relationship is modeled in a graph
representation as described in section 3.3, containing roughly 44k channels. Here, channels are
represented by nodes, while the featured channel list comprises unidirectional edges from one node
to other nodes. Finally, non-mutual edges between channels are removed, while mutual edges,
i.e., nodes having each other in their Featured Channel List, are considered likely to collaborate
and, hence, are kept. We also excluded Gaming videos as we observed a lack of face presence in
these videos and, furthermore, often high resolution game figures depicted on covers or within the

12https://socialblade.com/youtube/top/networks/most-subscribed [Accessed: 2018-05-08]

Table 3: Most popular YouTube MCNs worldwide, measured by number of subscribers.

Name

Members

Subscribers (over 30 days) Views (over 30 days)

BroadbandTV
Studio71
Maker Studios

237,235
13,194
9,460

82,718,601
18,535,751
14,011,532

20,107,687,476
5,402,265,290
4,613,091,2598

13/28

videos would have led to increases imprecision. From the remaining subgraph, we extract the largest
connected component, resulting in a graph with roughly 8k nodes and about 10k edges indicating
potential collaborations. By applying CATANA to this subgraph, i.e., analyzing 2.4 years of video
uploaded on these channels for a period of three months, we identified 1,599 nodes and 1,728 edges
representing actual collaborations. The edge sum, which corresponds to the overall number of
collaborations sums up to 3,925, see Table 4.

Table 4: Collaborations observed in the three month’s time span.

Collaborations Duration Mean Median

75-percentile Max

3,925

3 months

2.8

1.0

3.0

134

5 Evaluation

In this section, we formulate and answer research questions with respect to the focus points
of: (i) collaboration frequency and partner selectivity (Section 5.1), (ii) the influence of multi-
channel networks (MCNs) on channel collaborations (Section 5.2), (iii) collaborating channel types
(Section 5.3), and (iv) the impact of collaborations on video and channel popularity (Section 5.4).

5.1 How often do collaborations happen and reoccur with the same partner?

(a) Number of pair-wise collaborations

(b) Number of collaborations per channel

Figure 7: Histograms of detected collaborations per channel pairs (a) and per channel (b)

Using the collaboration graphs, we can easily determine the overall number of collaborations by
summing up the edge weights between two YouTube channels. Analyzing the edge weights allows
us to examine the number of repeated collaborations. Table 4 depicts the derived collaboration
statistics where we observe that the distribution is skewed to the right, indicating the presence

14/28

of a few channel pairs with a comparably high number of collaborations. We confirm this by
drawing the histogram of the collaboration counts in Figure 7a, showing the distribution of repeated
collaborations between two YouTubers who have collaborated at least one. We deduce that over a
3-months observation period collaborations between two channels rarely happen more than once.
In a next step, we analyze the number of collaborations per channel instead of distinct channel
pairs. Therefore, we sum up the edge weights for every channel node. Taking the perspective of a
channel, we differentiate between collaborations taking place in own videos (internal) and videos of
other channels (external). If a collaboration between YouTuber A and B occurs on YouTuber A’s
channel, it is considered as an internal collaboration by A and as an external collaboration by B.
This distinction helps us later to detail the effects on both sides of a collaboration. Figure 7b shows
the corresponding distributions. We conclude that a small number of highly collaborating channels
denoted central channels exists, with most of the remaining channels having very few collaborations.
Thus, central channels show a high in-degree, demonstrating a key influencer role on YouTube.
These YouTubers are especially valuable for product placements, advertisements, and, hence, are
especially valuable assets for their MCNs. One weakness of the former analysis is that it compares
results based on the absolute number of collaborations. Thus, we investigate the relative ratio of a
YouTuber’s collaborations compared to the overall number of the channel uploads. Given the number
of internal collaborations of a channel k, denoting collaborations only occurring in its own videos,
and the number of videos of the channel n, we calculate the collaboration ratio as k/n. Figure 8a
shows the distribution of the collaboration ratio. Values around one imply that in nearly every video
of the channel, a collaboration is found. This may indicate that certain content creators regularly
work together, or share a common channel while also operating separate channels alone. Values
larger than one can occur if multiple collaborations were detected in a single video. In Figure 8b,
we observe only a few outliers with a ratio above one, while most of the channels have a ratio close
to zero. This indicates that a large portion of channels have only a single ingoing collaboration.
Summarizing our finding with respect to collaboration frequency we observe that a single channel
collaborates with other channels on average 2.8 times ([2.5 − 3.15] at a 99% confidence level). If

(a) Collaborations per uploaded videos

(b) Channel collaborations

Figure 8: Collaboration/Video ratio and separated in- and outgoing collaborations.

15/28

channels collaborate, we find in our 3-month dataset that they repeat their collaboration on average
2.3 times ([2.0 − 2.6] at a 99% confidence level). Overall, the distributions for collaboration metrics
are skewed as a consequence of a few highly influential YouTubers.

5.2 How do multi-channel networks (MCNs) influence channel collaborations?

To answer this question, we first analyze which collaborations take place between MCNs. To this end,
we first determine the respective MCN for each channel using publicly available information13 to
augment the channel information of our collaboration graph. Figure 9 depicts the most collaborating
MCNs in form of a MCN-collaboration matrix. Overall, we found 405 MCN pairs collaborating
with each other. Note that the entry None refers to channels for which we could not determine a
MCN association.

Figure 9: Absolute number of collaborations within and between MCNs.

13https://socialblade.com/ [Accessed: 2018-05-08]

16/28

Figure 10: Internal and external MCN collaborations.

Examining the diagonal of the matrix in Figure 9 we observe a distinct trend showing that most
collaborations occur within MCNs, and thus between their members. Further, we observe that
significant collaborations between networks are mainly confined to the three dominant networks,
namely, BroadbandTV, Studio71, and Maker Studios. We find many collaborations of unassociated
channels, i.e., with the label None, with the three dominant networks, which we attribute to the fact
that they are the world’s three largest MCNs and, hence, have YouTube channels associated which
are popular and an attractive target for collaboration. Furthermore, famous YouTubers are a popular
topic for other YouTuber’s that may show the popular YouTuber’s face or video sequences. We
deduce that belonging to a MCN strongly increases the probability of a YouTuber to collaborate.

Figure 10 shows the percentage share of collaborations separated by MCN in- and external
collaborations. Here, we observe that the three largest MCNs, i.e., BroadbandTV, Studio71, and
Maker Studios as well as PranksNetwork have much more internal collaborations compared with
the smaller MCNs. Hence, their YouTubers collaborate more in their own videos than on the
videos of other MCN’s YouTubers. Note that a large portion of the outgoing collaborations is with
channels that are not associated with a MCN. Channels not belonging to a MCN show a preference
to work with MCN-associated channels as more than 70 percent of their collaborations are outgoing.
We conclude that an influence of MCNs concerning YouTuber collaborations can be inferred. In
summary, we find that channels associated with a MCN collaborate more often with each other and
if collaborations occur outside the MCN, then they are usually with non-associated channels and
rarely with other MCNs’ YouTubers.

17/28

Table 5: Popularity class definitions and their number of observed channels.

Popularity Class

Subscriber Range

#Channels

0
1
2
3
4
5
6

[0, 103)
[103, 104)
[104, 105)
[105, 106)
[106, 107)
[107, 5x107)
[5x107, 108)

813
1,575
2,569
2,420
544
20
1

5.3 Which channel types collaborate?

In the following, we group YouTube channels with respect to popularity and content category. First,
we assign each channel to one out of seven popularity classes, based on their subscriber count. Here,
the chosen classes resemble the classes used for the YouTube awards14, which are awards shipped
to the YouTubers when they exceed a certain number of subscribers. Next, we analyze collaboration
behavior regarding the YouTube video category, a label which the YouTuber can select out of a set
of given categories during the video upload process.

YouTube Popularity Classes We assign a channel’s popularity class with respect to the number
of subscribers as depicted in Table 5. In column #Channels, the table shows also the number of
YouTube channels in our dataset which belong to the corresponding popularity class. We can see
that the major share of the channels observed belong to popularity class 1, 2, or 3. Class 6 is an
exception, as it only contains a single channel, i.e., PewDiePie, the most successful YouTuber in
terms of subscribers so far. Figure 11a depicts the share of observed channel collaborations between
popularity classes. Here, channels belonging to a numerically higher class have more subscribers
than channels belonging to numerically smaller classes. The matrix entry atf of row f and column
t denotes that the number of YouTubers from a channel of popularity class f appear in videos
belonging to channels of popularity class t. We can see that most collaborations happen within
class 3 and neighboring classes 2 and 4, which we ascribe to two factors. First, these channels
have reached a popularity in the YouTube environment that attracts collaborations. Second, these
channels do not yet belong to the most popular channels, i.e., categories 4, 5, and 6 but are likely to
try to increase their own popularity by attracting more viewers through collaborations with other
YouTubers.

YouTube Categories
In Figure 11b we show the share of collaborations between YouTube cate-
gories. Most collaborations are detected in, and between the Entertainment and People & Blogs
categories, which is reasonable as they prevalently contain human presence and interaction. The
same applies for categories like Comedy. In the figure, we observe asymmetric relations, e.g.,

14https://www.youtube.com/yt/creators/rewards.html [Accessed: 2018-05-08]

18/28

(a) Popularity classes.

(b) Video categories.

Figure 11: Collaborations within & between popularity classes and YouTube video categories (in
%).

between Comedy and Film & Animation, that collaborate more in with Entertainment channels than
within the same category. For collaborations within a category, i.e., the diagonal of the heat map, we
only notice a surge for Entertainment. We observe that the most frequent collaborations occurred
within the category Entertainment, which also shows the second most video uploads. Note that
Entertainment is a rather generic term and can therefore, depending on the YouTuber’s interpretation,
also include comedy, film, and animation related content.

5.4 How do collaborations impact video and channel popularity?

We investigate the two parts of this question separately, focusing, first, on the observed effects on
video popularity and, second, on channel popularity. Therefore, we use popularity statistics of a
3-months period for roughly 105 videos, considering videos for which we have at least 12 daily
popularity measurements, i.e, videos being older than 12 days. We chose 12 days as we observed
that most older videos do not receive much more views. Using CATANA, we deduce a collaboration
graph with roughly 104 edges indicating collaborations within the observed 8 × 103 channels. Using
two sets for collaboration and non-collaboration videos, we analyze the maximum values of view
and subscriber counts of the 12-days time-span and their gradient. The benefit of these gradients is
that they are not biased by absolute numbers but represent the relative popularity growth.

19/28

Figure 12: Number of views after 12 days for collab. (green) and non-collab. (blue) videos.

5.4.1 Video Popularity

First, we examine the maximum video view counts observed in the first 12 days. Figure 12 shows
the video view count distribution. By examining the left side of the figure, we see in the box plot that
the average view count is higher for videos with a collaboration compared with non-collaborations.
Note that the median is stretched nearly doubled (from about 26k to 45k views) for the cases of
present collaborations. Although the median is only slightly higher in case of a collaboration, the
upper 50% of video views are more scattered and show more views. Additionally, we plotted the
average view counts for both cases and their 95% confidence intervals on the right side of Figure 12
where we see a large gap. The figure suggests that a significantly higher view count can be expected
if a video contains a collaboration.

The generally higher popularity of collaboration videos can be reasoned in the generally higher
popularity of collaborating channels. As we previously examined, class 3 channels collaborate
more often than channels of lower popularity classes. If we therefore assume that more videos
with collaborations are uploaded by class 3 channels, the videos consequently tend to a higher
popularity compared for example with class 2 videos. To further substantiate this effect, we evaluate
the gradient and growth of the video view counts. Hence, we calculate the average view growth
factor between non-collaboration and collaboration videos. For this, we use the average maximal

Figure 13: View count growth factor between collaboration and non-collaborations videos. A
positive value indicates the superiority of collaborations.

20/28

Table 6: View growth of collaborations compared to non-collaborations.

Channels Duration Mean Median

75-percentile Min Max

1116

3 months

34.32

-6.73

32.47

-99.70

6,376.28

Figure 14: Video view count growth for the first five days of a collaboration vs. the
non-collaboration view growth on the first day.

12 day view value for every channel, differentiated by collaboration and non-collaboration. Next,
the percentaged growth from the non-collaboration value to the collaboration value is calculated
channel-wise. Figure 13 displays these results. As only channel with both collaboration and non-
collaboration data could be used for the percentaged growth calculation, samples of 1,116 channels
are used. The difference in number of channels is due to channel which only collaborate in external
videos, and do not host collaboration in their own. Statistics on the differences between the two
video groups on the video view growth are shown in table 6. In a next step, we investigate the
distributions of these view count differences depicted in Figure 13. Here, the 0.95 confidence interval
is between 19% and 51%, indicating that a significant growth of the views between collaboration
and non-collaboration videos can be expected.

Next, we compute the gradients between each pair of the 12 days of the videos’ view counts,
resulting in 11 gradient values. Additionally, we calculate the percentaged growth between these
values. The percentaged growth of the first 6 days after a collaboration vs. non-collaboration view
growth on the first day is depicted by Figure 14. This figure shows the longer lasting temporal
impact of collaborations. Further, Figure 15 shows the box and bar plots of the gradient values, i.e.
the absolute view count increase, using a 0.99 confidence level.

21/28

Figure 15: Video view count gradient.

Figure 16: Channel subscriber gradient and percentaged growth.

5.4.2 Channel Popularity

Here, we cannot directly differentiate between collaboration and non-collaboration channels as for
videos, since one channel may contain both, collaboration and non-collaboration videos. Therefore,
we filter channels, which uploaded videos with and without collaborations, resulting in 1,599
channels. The channel popularity is measured by the number of views of its videos and the number
of channel subscribers. We define a window of two days after a collaboration, for which we will
classify the subscriber counts as belonging to a collaboration, the remaining statistics measured
are classified as belonging to non-collaboration. Thereby, we gathered 9,086 channel subscriber
measurements for collaborations, and 78,877 for non-collaborations. Figure 16 shows the subscriber
count differentiated between collaborations and non-collaborations. From the figure we conclude
that collaborations have a slight positive effect on channel subscribers. Compared to the increase of
viewers, the increase of subscribers is only about one tenth of total users. Though, the relative growth
compared to non-collaborating video measures is about 30% larger in terms of newly attracted
subscribers compared with the newly attracted viewers.

In addition to the above evaluation of the two-day collaboration window, we evaluate a 6-day
window on a daily basis. Figure 17a shows the percentaged subscriber growth over 6 days starting
with day 0, which is the upload date of the collaboration video. Figure 17b depicts the percentaged
subscriber growth for each day and on the left side and the respective overall channel view growth

22/28

(a) Channel subscriber count growth.

(b) Channel view count growth.

Figure 17: Effect of collaboration over the first six days.

Figure 18: Subscriber growth for collaborations between YouTube channel categories.

on the right side. On both sides, also the growth of non-collaboration videos after day 0 is shown
to allow for a comparison. We note that the highest subscriber growth can be observed for days 0
and 1 with the growth slowly decreasing to approach the base line describing non-collaborations.
In addition to the channel subscriber growth, we apply the same evaluation methodology for the
overall channel views, an alternative measure of channel popularity. Here, we expect a similar
pattern as for the channel subscriber counts but we observe a very different pattern, depicted in
Figure 17b. For day zero and one, the view growth is quite low and close to non-collaboration
videos. In contrast to that, for day 2, we observe a significant increase. Despite the fact that more
people watch collaboration videos on day two, we found that users seem to be less engaged as for
day 2 overall less subscriptions are observed than for days 0 and 1.

23/28

Figure 19: View count growth for collaborations between YouTube channel categories.

5.5

Impact of Video Popularity Classes and Video Categories

YouTube Categories Figure 18 and 19 show the impact of a collaboration of YouTubers belonging
to different video categories and popularity classes. We observe that view and subscriber counts vary
strongly amongst different channels. Hence, we compute the relative popularity growth for videos
with and without collaborations. Here, we took only popularity measurements if a collaboration
video was uploaded and at the same day no other video was uploaded to guarantee that the channel
popularity measure is not impaired. In case different categories collaborate, we show the effects
for both categories separately. For all collaborations taking place between YouTubers uploading
mostly videos of the same category, a significant increase of subscriber and view count is observed.
Here, the category People & Blogs is an exception, as on average more subscribers can be attracted
by a collaboration but less video viewers. This is still beneficial as the subscribers are potentially
watching all videos uploaded by the YouTubers in the future.

YouTube Popularity Classes
In Figure 20 and 21 the impact of collaborations between channels
of different popularity classes is shown. In general, we observe a significant benefit of collaborations.
Note that lower popularity classes, especially class 1 and 2 YouTubers benefit significantly stronger
than higher popularity classes. It can be seen that for classes 3 and 4, the gain of a collaboration is
comparably low and often there is no significant difference. For class 4 YouTubers, no effect of
collaborations can be observed. Hence, we deduce that especially for YouTubers with less than 105
subscribers, i.e., class 1 or 2, collaborations significantly increase the number of views.

24/28

Figure 20: Subscriber growth for collaborations between channel popularity classes. The x-axis
denotes the depicted popularity class in the constellation depicted in brackets, e.g., (1 in 3) means
that a YouTuber of popularity class 1 appeared in a video published on a popularity class 3 channel.

Figure 21: View count growth for collaborations between YouTube channel popularity classes.

Concluding our popularity evaluation for videos and channels under collaborations, we state we
observe that collaborations have positive effects on video views and on engaging new subscribers.
Especially for YouTubers of low popularity classes such as class 1, a collaboration can add about
100% additional views and new channel subscribers. Concerning the impact on video views, we
calculated a percentaged growth through collaborations with a mean between 19% and 51% with
0.99 confidence. Also channels popularity is significantly increased through collaborations, i.e., for
both considered metrics, namely channel subscribers and total channel views.

25/28

6 Conclusion and Future Work

In this article, we first designed and implemented a system for the acquisition and analysis of
collaboration data in user generated content at the example of YouTube. We implemented a video-
based face recognition system named CATANA for which we examined and evaluated different face
recognition and clustering techniques. We applied CATANA to a collected dataset of videos over a
3-month period where we extracted appearing content creators and leveraged this information to
detect collaborations between channels.

We observed that out of 7,492 channels in our dataset 1,599 collaborated, with an average of
2.8 times per channel. Regarding the types of channels, which collaborate we found that channels
with a subscriber count between 105 - 106 collaborate the most and the Entertainment YouTube
category shows most collaborations. Furthermore, we inferred that multi-channel networks generally
exhibit collaborations within the same network or channels, which are not associated with any other,
potentially competing, network. We analyzed the acquired popularity statistics for both videos
and channels and found significant differences between collaboration and non-collaboration sets,
indicating a positive effect on the popularity that is measured by subscriber and view counts. In
this work we proposed a viable method for collaboration detection in user generated content that is
based on face recognition. A potential limitation of the proposed system is the differentiation with
respect to the collaboration context, which can be mapped to different types of face appearances, i.e.
posters or content usage. In future work, using voice recognition in addition to face recognition is
likely to increase detection rates as well as differentiate collaboration context.

Reproducibility

To enable other researchers to use, reproduce, and extend our research, we release our tool chain
at https://github.com/christiannkoch/CATANA. This contains: (i) the CATANA
framework and evaluation scripts used here, (ii) the 3-months collaboration graph used in this paper,
and (iii) an interactive web-based visualization of the collaboration graph.

Acknowledgements

This work has been funded in parts by the DFG as part of the Collaborative Research Centre 1053
MAKI (C3, B4).

26/28

References

[1] T. Ahonen, A. Hadid, and M. Pietikainen. Face Description with Local Binary Patterns:
IEEE Transactions on Pattern Analysis and Machine

Application to Face Recognition.
Intelligence, 28, 2006.

[2] B. Amos, B. Ludwiczuk, and M. Satyanarayanan. OpenFace: A general-purpose Face
Recognition Library with Mobile Applications. Technical report, CMU-CS-16-118, CMU
School of Computer Science, 2016.

[3] B. Gahan. How to be successful on YouTube: The 3 steps. http://thenextweb.com/
insider/2015/03/04/the-3-steps-to-success-on-youtube/, 2015. [Ac-
cessed: 2018-05-08].

[4] M. Gielen. Best Practices For A YouTube Multi-Channel Network 2.0. http://www.
tubefilter.com/2015/03/24/youtube-mcn-multi-channel-network/,
2015. [Accessed: 2018-05-08].

YouTube Universum. Die Vernetzung

[5] B. Gugel.
sualisiert.
youtube-universum-die-vernetzung-der-youtuber-visualisiert.
html, 2015. [Accessed: 2018-05-08].

vi-
http://www.gugelproductions.de/blog/2015/

der YouTuber

[6] Y. Guo, L. Zhang, Y. Hu, X. He, and J. Gao. Ms-celeb-1m: A Dataset and Benchmark for
large-scale Face Recognition. In European Conference on Computer Vision, pages 87–102.
Springer, 2016.

[7] M. Holmbom. The YouTuber A Qualitative Study of Popular Content Creators. Bachelor

thesis, Umea University, 2015.

[8] G. B. Huang, M. Ramesh, T. Berg, and E. Learned-Miller. Labeled Faces in the Wild: A
Database for Studying Face Recognition in Unconstrained Environments. Technical report,
University of Massachusetts, Amherst, 2007.

[9] E. Learned-Miller, G. B. Huang, A. R. Chowdhury, H. Li, and G. Hua. Labeled Faces in the
Wild Website. http://vis-www.cs.umass.edu/lfw/. [Accessed: 2018-05-08].

[10] E. Learned-Miller, G. B. Huang, A. RoyChowdhury, H. Li, and G. Hua. Labeled Faces in the
Wild: A Survey. In Advances in Face Detection and Facial Image Analysis, pages 189–248.
Springer, 2016.

[11] O. M. Parkhi, A. Vedaldi, and A. Zisserman. Deep Face Recognition. In Proceedings of the

British Machine Vision Conference (BMVC), 2015.

27/28

[12] D. Sandberg. Facenet Project Repository. https://github.com/davidsandberg/

facenet. [Accessed: 2018-05-08].

[13] F. Schroff, D. Kalenichenko, and J. Philbin. FaceNet : A Unified Embedding for Face
Recognition and Clustering. In IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), 2015.

[14] Social Blade LLC. SocialBlade Network Statistics. https://socialblade.com/

youtube/top/networks. [Accessed: 2018-05-08].

[15] M. Turk and A. Pentland. Eigenfaces for recognition. volume 3, pages 71–86. MIT Press,

1991.

Face Recognition. 2016.

[16] Y. Wen, K. Zhang, Z. Li, and Y. Qiao. A Discriminative Feature Learning Approach for Deep

[17] C. Wilson, B. Boe, A. Sala, K. P. N. Puttaswamy, and B. Y. Zhao. User Interactions in
Social Networks and Their Implications. In ACM European Conference on Computer Systems,
EuroSys’09, 2009.

[18] L. Wolf, T. Hassner, and I. Maoz. Face Recognition in Unconstrained Videos with Matched
Background Similarity. In IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), 2011.

[19] YouTube, LLC. Youtube Creator Academy: Collaboration. https://creatoracademy.

youtube.com/page/lesson/collaboration. [Accessed: 2018-05-08].

[20] YouTube, LLC. YouTube Statistics.

https://www.youtube.com/yt/press/

statistics.html. [Accessed: 2018-05-08].

[21] K. Zhang, Z. Zhang, Z. Li, and Y. Qiao. MTCNN Face Detection. https://kpzhang93.
[Accessed:

github.io/MTCNN_face_detection_alignment/index.html.
2018-05-08].

28/28

8
1
0
2
 
y
a
M
 
1
 
 
]

V
C
.
s
c
[
 
 
1
v
7
8
8
1
0
.
5
0
8
1
:
v
i
X
r
a

Collaborations on YouTube: From Unsupervised Detection to the
Impact on Video and Channel Popularity
Christian Koch, Moritz Lode, Denny Stohr, Amr Rizk, Ralf Steinmetz
Multimedia Communications Lab (KOM), Technische Universität Darmstadt, Germany
E-Mail: {Christian.Koch | Denny.Stohr | Amr.Rizk | Ralf.Steinmetz}@kom.tu-darmstadt.de

Abstract

YouTube is one of the most popular platforms for streaming of user-generated video. Nowadays,
professional YouTubers are organized in so called multi-channel networks (MCNs). These networks
offer services such as brand deals, equipment, and strategic advice in exchange for a share of the
YouTubers’ revenue. A major strategy to gain more subscribers and, hence, revenue is collaborating
with other YouTubers. Yet, collaborations on YouTube have not been studied in a detailed quantita-
tive manner. This paper aims to close this gap with the following contributions. First, we collect a
YouTube dataset covering video statistics over three months for 7,942 channels. Second, we design
a framework for collaboration detection given a previously unknown number of persons featuring in
YouTube videos. We denote this framework for the analysis of collaborations in YouTube videos us-
ing a Deep Neural Network (DNN) based approach as CATANA. Third, we analyze about 2.4 years
of video content and use CATANA to answer research questions providing guidance for YouTubers
and MCNs for efficient collaboration strategies. Thereby, we focus on (i) collaboration frequency
and partner selectivity, (ii) the influence of MCNs on channel collaborations, (iii) collaborating
channel types, and (iv) the impact of collaborations on video and channel popularity. Our results
show that collaborations are in many cases significantly beneficial in terms of viewers and newly
attracted subscribers for both collaborating channels, showing often more than 100% popularity
growth compared with non-collaboration videos.

1 Introduction & Problem Statement

Collaborations are a key strategy to increase the dissemination and, hence, popularity of user-
generated videos on YouTube. Here, YouTuber A, i.e., a content creator, introduces a collaborating
YouTuber B to his viewers seeking to attract their interest to the content of YouTuber B. The rationale
here is that given the viewers interests, they are more likely to watch the introduced YouTuber’s
videos and eventually become subscribers [3, 4, 19]. Collaborations often occur in a reciprocal
manner on both of the collaborating channels to attract each other’s viewers and, thereby, increase
both YouTuber’s revenue. Video monetization can be activated through participating in the YouTube
Partner Program (YPP) [7]. Thereby, YouTubers can configure their videos allowing YouTube to

1/28

insert short ad clips before and within their videos. In return, YouTube pays a share of the resulting
revenues out to the YouTubers. With more than 10k people that were reported in 2016, the annual
growth of the number of YouTubers earning six figures per year amounts to ∼ 50% [20].

In contrast to works describing collaborations, e.g., within scientific communities or online
social networks, there are only few studies on the detection of collaborations in user-generated
videos and a lack of quantitative analysis of their desired impact on popularity. Note that Video-
on-Demand (VoD) platforms such as Netflix are not exposed to user-generated content (UGC)
which is more scattered, diverse, and generated at a much higher rate. While general metadata of
UGC videos is available, no explicit information on collaborations exists. Although mentions of
collaborating YouTubers in the video title or in the description are in general possible, they often
miss collaboration-related information and are, hence, not a reliable source of information.

Nowadays, popular YouTubers often belong to a multi-channel network (MCN), e.g., Broad-
bandTV, Studio71, and Maker Studios, which offer equipment, brand deals, and strategic advice to
increase the YouTubers’ popularity in exchange for a share of their revenue [7]. Essentially, such
strategic advice comprises collaboration policies that describe the most beneficial collaborations
with diverse YouTubers.

Until now, a public documentation on the efficiency of collaborations on YouTube does not exist.
A quantitative analysis of different types of collaborations, e.g., between YouTubers of different
popularity or content categories has the potential to guide YouTubers to popularity- and, hence,
revenue-maximizing behavior. To this end, this article addresses the challenging task of identifying
and analyzing content creator collaborations on large-scale UGC video platforms taking the example
of YouTube. Our analysis focuses on (i) collaboration frequency and partner selectivity, (ii) the
influence of MCNs on channel collaborations, (iii) collaborating channel types, and (iv) the impact
of collaborations on video and channel popularity. In the following sections we address these focus
points in a framework for collaboration detection and analysis denoted CATANA. For the design of
CATANA, we argue that the analysis of content creator collaborations on large-scale UGC video
platforms faces three key challenges:

• YouTube-suitable Face Detection: The YouTubers’ faces constitute the basis for identifying
collaborations. Hence, we require their inference and storage in an appropriate representation.
Changing lights, face expressions, and camera perspectives add to the difficulty of deriving
these representations.

• YouTuber Identification: In contrast to most face recognition tasks, in our scenario, an
unknown number of people appearing in user-generated videos needs to be identified based
on the detected faces. Therefore, an accurate association of face samples to people for a large
set of YouTubers needs to be obtained. Additionally, we need to identify which person is the
owner of the YouTube channel and which persons are potential guests.

• Collaboration Representation: The co-occurrence of YouTubers in a video indicates collab-
oration. However, people appearing sporadically, e.g., passersby do not carry strong evidence
of collaborations. Filtering outliers and storing inferred collaborations in an appropriate form
is essential for further analysis.

2/28

The remainder of this article is structured as follows. Section 2 provides an overview of used
benchmarking datasets, face recognition approaches, and existing works on YouTube collaborations.
In Section 3, we motivate and explain CATANA’s major building blocks. Section 4 presents our
data acquisition and selection process. In Section 5, we evaluate and discuss our results answering
relevant research questions. We conclude our article in Section 6 and discuss future work.

2 Related Work

The related work provides, first, an overview of existing datasets that are useful for benchmarking
face recognition methods on YouTube. Second, an overview of recent face recognition methods is
given. Third, existing works addressing YouTube collaboration analysis are presented and discussed.

2.1 YouTube Face Recognition Datasets

In this section we give a brief overview of the two face datasets used for optimizing CATANA. Both
datasets are frequently used in face recognition studies of the last years, as well as in related work.

Labeled Faces in the Wild (LFW) LFW is a publicly available face dataset introduced in [8]
and released as an effort to spur face recognition research. It has been referenced in more than 50
papers related to face recognition [10]. LFW’s provides a large set of face images in a large range of
variations. This includes variation in pose, lighting, expression, background, ethnicity, and age [9].
The dataset consists of 13,244 images of 5,749 people with images in 250x250 pixel JPEG format.
These face images were collected from the web and contain celebrities, politicians, athletes, and
other public figures. For training, validation, and testing, mutually exclusive splits are available
suited for usage in a 10-fold cross validation. Training and testing data are, thereby, presented as
either matching or mismatching face pairs. Hence, the proposed evaluation experiments aim at the
problem of pair matching, deciding whether the images are of the same person. In total 6,000 pairs
are provided, divided into 10 splits with each 300 match and 300 mismatch pairs.

YouTube Faces (YTF) YTF is a dataset of face videos introduced in [18] and designed for
studying the problem of face recognition in videos. The dataset contains 3,425 videos of 1,595
different people appearing in YouTube videos. These people are a subset of the 5,749 people from
the LFW dataset and for every person an average of 2.15 videos are available. The video duration
ranges between 48 and 6,070 frames and all video frames are stored individually as JPEG images.
Structure and design of YTF is heavily inspired by LFW. Similarly, matching and mismatching pair
are provided, for usage in a 10-fold cross validation pair-matching evaluation. In comparison to the
LFW evaluation, pairs consist of videos, allowing to decide if the pair of videos is subject of the
same person or not. Overall, 5,000 pairs are provided, divided into 10 splits, each containing 250
match and 250 mismatched pairs.

3/28

2.2 Face Recognition

Two kinds of fundamentally different face recognition approaches exist. The first kind that is widely-
spread relies on fixed mathematical models and structures, e.g., Eigenfaces [15] and Local Binary
Patterns Histograms (LBPH) [1]. While these classical approaches have shown solid performance,
the second kind of techniques, using deep neural networks (DNNs) is outperforming classical
approaches and beginning to replace them. As they are clearly superior in performance to classical
approaches and even compared with humans [10], we focus only on DNN-based approaches.

Parkhi et al. [11] present a deep learning-based face recognition method called VGG-Face. The
authors further propose how a very large-scale face dataset can be assembled by a combination
of automation and human in the loop. Focusing on celebrities for the dataset acquisition, they
extract a small number of images using the Google Image Search and the actors’ names. Then,
these images are audited through human annotators. In the next step, the actors are queried again
through image search, this time extracting a bigger amount of images. Instead of human annotation,
a linear Support Vector Machine (SVM) is pre-trained with the small number of images from the
first step and leveraged to classify the newly acquired images. Thereby, a dataset of 2,622 identities
and 2 million images is assembled. Furthermore, a CNN (Convolutional Neural Network) based
face recognition method is proposed, which is trained on the acquired dataset using the triplet-loss
function. The proposed method is then evaluated on the LFW and YTF datasets and compared
against other state-of-the-art methods, resulting in an accuracy of 98.95% for LFW and 97.3% for
YTF. We conclude that image acquisition through online image search can be a promising method
to acquire training data. In the context of this work, channel names could be queried, resulting in
face images of YouTubers. However, this would still require a human interaction for a potentially
large number of YouTubers and passersby in videos.

Schroff et al. [13] present a DNN model named FaceNet. They introduce the triplet loss
for training, i.e., a loss function designed to result in face representations, clustered based on
similarity. Triplet loss thereby works with triplets of matching / non-matching face images and
embeds these into a 128-dimensional Euclidean space. Thereby, the loss function ensures that an
anchor image of a specific person is closer to all other positive images of the same person, than it
is to any negative image from any other person. Thus, the network results in a 128-dimensional
face representation in a space where distances directly correspond to face similarity. Consequently,
classification and clustering are now straightforward by using standard Euclidean distance metrics.
Hence, accuracies of 99.63% on the LFW dataset and 95.1% on YTF were measured. Even though
similar in architecture than the previous DNN [11], a significantly larger private dataset of 200M
images was used for training.

Amos et al. [2] present OpenFace1, a CNN-based face detection and recognition framework
using only openly available training datasets for training. OpenFace builds up on the FaceNet [13]
architecture, combining it with computer vision and machine learning techniques, such as State
Vector Machine (SVM) for classification. For training the CNN model, public face datasets were
used, which licenses allow usage and publication of the resulting models. Hence, no training is

1http://cmusatyalab.github.io/openface [Accessed: 2018-05-08]

4/28

necessary for using the OpenFace framework. OpenFace is thereby trained with only 500,000 images
from combining the two largest labeled face recognition datasets for research, CASIA-WebFace2
and FaceScrub3. Overall, OpenFace achieves an accuracy of 92.92% on LFW.

A related framework to OpenFace is Facenet4, as both are based on FaceNet [13] and its
proposed DNN. Even though Facenet shares almost the same name as FaceNet [13], its developer
have no connection to the authors. In comparison to OpenFace, Facenet additionally implements
multiple additional ideas from different papers to tune accuracy. Amongst others, a different loss
function is used for training, the face representation is 1792-dimensional instead of 128-dimensional
and, furthermore, a different face detection technique is used [21]. Facenet implements the center
loss function [16], which is developed to improve the discriminative power of the learned features,
minimizing the intra-class variation while keeping the classes separable. To do so, it learns a center
for each feature class and penalizes distances between features and their center, resulting in high
accuracy. Facenet is trained using the MS-Celeb-1M face dataset [6], whose license allows model
reproducibility. Facenet is evaluated on the LFW dataset, showing an accuracy of 99.2%.

We conclude that DNN-based approaches show high accuracy on relevant datasets such as LFW
and YTF. As Facenet evidently outperforms the other reviewed approaches, we will deploy it as a
key component for CATANA’s face recognition capabilities.

2.3 Collaborations on YouTube

Mattias Holmbom [7] conducted a study on five YouTube channels, including interviews with their
content creators. He found that it is currently more difficult than ever for new content creators to
establish a YouTube channel, as already a large number of channels exist. Concerning collaborations
on YouTube, three of the five YouTubers associate their popularity directly or indirectly with
collaborations featuring other channels. Furthermore, MCNs were suggested as tool to get help in
finding other YouTubers addressing similar topics for collaboration.

In Brendan Gahan’s article "How to be successful on YouTube: The 3 steps" [3], the third
proposed step for new content creators is collaboration with other YouTubers, which already have an
established subscriber base as an essential step to expand a channel’s audience. YouTube’s official
Creator Academy5 also suggests collaboration as a powerful way to reach new users [19]. This is also
confirmed from MCNs’ side, as the MCN "Channel Frederator Network" recommends to facilitate
and instigate collaborations between network members [4]. We conclude that analyzing channels
registered in the same network can significantly improve the likelihood detecting collaborations.
This is important for our work to control the comparisons of videos with and without collaborations.
Bertram Gugel created a visualization of a share of the YouTube collaboration graph [5]. The
visualized graph provides insights into (i) the size of the respective YouTube channels, measured
by subscriptions, (ii) whether the association is uni- or bidirectional, as well as, (iii) to which

2http://www.cbsr.ia.ac.cn/english/CASIA-WebFace-Database.html [Accessed: 2018-05-08]
3http://vintage.winklerbros.net/facescrub.html [Accessed: 2018-05-08]
4https://github.com/davidsandberg/facenet [Accessed: 2018-05-08]
5YouTube website offering free online courses helping users creating better videos and improve channel performance.

5/28

Figure 1: CATANA’s system architecture.

MCN the channels belong. However, only the Featured Channel List of a YouTube channel is
used to determine a collaboration. On the one hand, this deliberate association between YouTube
channels does not necessarily indicate that channels collaborate. On the other hand, there exists
also collaborations with not featured channels. Furthermore, this work does not provide a thorough
analysis of individual videos and the effect of collaboration on their popularity. Hence, we conclude
that to the best of our knowledge no comprehensive analysis on YouTube collaboration and resulting
effects on popularity exists so far. We set this as the goal of this article.

3 System Design

In the related work, we have seen that it is common practice to recommend YouTubers to collaborate
to increase their audience and, hence, revenue. However, there is a lack of precise and detailed
analysis of the impact of YouTube collaborations on video and channel popularity. With CATANA,
we aim to close this gap. In the following, we motivate CATANA’s major building blocks, depicted
in Figure 1. As our focus is on video and channel popularity, we need the Metadata Crawler which
collects popularity time series, i.e., information of view counts in the case of videos and of the
subscriber counts in the case of channels. These time series are stored in the Database Storage.
Before analyzing the videos, the Video Downloader acquires the video data. In a next step, the
contained faces of the videos are detected and a dense representation is computed and stored in the
Database Storage, together with the video ID allowing to associate the contained faces with the
videos’ popularity time series. Then, the Clustering module determines face-person associations
by associating similar face representations with the same person. The most representative face
representations per person are stored in the Database Storage. The Collaboration Detection module
compares face representations of different videos, thereby allowing to find persons appearing in
different videos, as these videos contain the same face representations, i.e., the same persons. In a
last step, the collaborations detected are stored in form of a bidirectional graph used in the Analysis &
Evaluation module. In the following, we discuss the key processes and design choices of CATANA
in detail.

6/28

Table 1: Face recognition performance comparison with stDev, non-public are grayed out.

LFW

YTF

Eigenfaces
LBPH
Facenet
Openface
Human
FaceNet
VGG

0.6002 ± 0.00791
-
0.6782 ± 0.6300
-
0.9930 ± 0.0042
0.9980 ± 0.00134
0.9292 ± 0.01343 0.9971 ± 0.00264
0.97531
0.9963 ± 0.0009
0.9913

-
0.9512 ± 0.39
0.9740

1 [9]

2 [2]

3 [12]

4 this article

3.1 Face Detection and Recognition

We evaluated six recent approaches (ref. Section 2.2) to choose an appropriate face recognition
method. Eigenfaces [15] uses principal component analysis (PCA) to transform a high-dimensional
face image to a lower-dimensional representation, while Local Binary Patterns Histograms (LBPH)
[1] are histogram-based. In contrast to these traditional well-known methods, we also evaluate recent
DNN-based approaches: Facenet, Openface, FaceNet, and VGG. We compare the performance of
these approaches with two benchmark datasets: LFW and YTF (ref. Section 2.2). Both datasets
provide pairs of matching and non-matching faces useful to assess face recognition methods. The
results are presented in Table 1, depicting the accuracy of the pairwise match/mismatch between
subject pairs in a 10-fold cross-validation. As Facenet performs best on both datasets, and even
outperforms humans, we choose it for CATANA’s face detection and face recognition functionalities.

Frame Extraction and Selection

Typically, face recognition approaches are designed for images, not for video. Due to the large
number of frames per second with usually small changes, it is not efficient to process every frame.
Instead, we use a duration-based frame extraction rate f (n, r) taking the number of frames n in the
video and its frame rate r as inputs to reduce the number of images to process. We extract evenly
spaced frames with a usual rate of 10 frames per minute. For short video, we adapt the rate to extract
at least fmin = 600 frames which shows a good performance. For long videos, the number of frames
extracted is limited for storage reasons to fmax=8,000. One might argue that the frame extraction
approach used is quite simple and could benefit, e.g., from shot boundary detection or face tracking.
Therefore, we additionally tested a sophisticated approach, that does not analyze individual frames
but face tracks, i.e., the face is detected once and followed through the subsequent frames. Therefore,
we used Pyannote-Video6 as a framework to consider a face tracking approach as well in our design.
This framework is based on the face recognition framework Openface [2] and implements shot
boundary detection, face track extraction, and clustering via hierarchical agglomerative clustering.

6https://github.com/pyannote/pyannote-video [Accessed: 2018-05-08]

7/28

3.2 YouTuber Identification

In the previous section, we discussed how a set of face images per video is obtained using Facenet.
In a following step, we use clustering to create an association between images and people. In the
case of face tracks, these are already grouped per individual. However, due to shot boundaries, i.e.,
scene or camera switches, multiple face tracks per individual may exist.

In a next step, we evaluate five different clustering approaches: Pyannote-video in two con-
figurations, DBSCAN, HDBSCAN, and agglomerative clustering (AGG). Pyannote-video can
be configured with different frame extraction and face detection rates. Therefore, two settings
are chosen: C1: Every frame is used for face tracking and 1 frame per second is used for face
recognition. C2: Only 1 frame per second is extracted as well as used for face recognition. To assess
the performance, we evaluate metrics for error rate, number of not clustered images, number of
clusters found, and the clustering runtime.

Figure 2 depicts the evaluation results of the approaches based on the clustering error and number
of not clustered face images. In Figure 3, we show the evaluation results based on the number of
identified clusters and the clustering runtime. We can see that Pyannote-Video C1 has a high number
of erroneously clustered face images. Furthermore, clustering run-time is multiple times higher for
C1 than the video duration, and also multiple times higher than required by the other approaches.
The second configuration C2 performs better than C1, but still worse than the other approaches
regarding clustering errors and clustering runtime. Comparing the two similar approaches DBSCAN
and HDBSCAN a difference in noise handling, measured by the number of not clustered face images
can be noticed. DBSCAN identifies more images as noise than HDBSCAN and all other approaches.
The number of found clusters fits for both density-based approaches: DBSCAN and HDBSCAN,
being close to the optimal number. The major advantage of both density-based approaches, i.e.,
DBSCAN and HDBSCAN over the other approaches is that no estimation of the number of cluster
must be given. Finally, we conclude that both DBSCAN and HDBSCAN perform best amongst the
evaluated techniques. The face tracking approach, while promising in theory, did not perform well.
As the number of not clustered face images suggests, DBSCAN handles noise more conservative
than HDBSCAN, resulting in possible useful images being discarded. A significant advantage of
HDBSCAN over DBSCAN, besides handling varying cluster density, is that it returns probabilities
describing the strength of membership for every face image. This information can be leveraged
to further filter outliers and improve the clustering results. For these reasons we decided to use
HDBSCAN for clustering the face images.

While evaluating the performance measures above, we noticed non-compliant behavior of
HDBSCAN for class one videos, especially in which no other (external) actor appeared. HDBSCAN
thereby fails to create a single cluster and labels all data as noise. This observed effect is due to the
hierarchical approach and it could not be improved through parameter modification. As DBSCAN
performs well on a single cluster case, we use DBSCAN as a fallback solution, coming into effect
when HDBSCAN fails to detect a single cluster.

An alternative approach to clustering is classification. However, this approach was discarded,
as it does not fit our requirement that the face recognition technique should be able to distinguish

8/28

Figure 2: (Left) Number of clustering errors. (Right) Number of not clustered face images.

Figure 3: (Left) Number of clusters found compared to reference (optimal). (Right) clustering
run-time comparison.

between individuals without prior training data. For the sake of completeness, we will give a
brief overview of this alternative approach. Through classification, it is possible to assign detected
faces to known individuals. The problem with this approach in our setting is that training data
is needed for classification. As we have channel information, which is analyzed beforehand, we
could acquire training images through, for example, Google image search. The drawback with
this approach is that the number of content creators per channel is unknown. Thus, the automatic
retrieval of correct training data for multiple persons through image search is not viable. Furthermore,
appearing individuals that are not related to any analyzed channel would not be recognized. For these
reasons, the previously described clustering approach is utilized, incorporating both, HDBSCAN
and DBSCAN.

9/28

3.3 Collaboration Detection

We define a collaboration as the co-occurrence of a YouTuber from a different channel in a YouTu-
ber’s video, e.g., in a video showing both YouTubers or playing a (potentially) prerecorded clip of
the featured YouTuber. To identify collaborations, we build connections between videos using the
previously derived face clusters. Single videos may have multiple face clusters, i.e., at least one
per detected individual. Therefore, we compute a similarity matrix between face clusters using the
Euclidean distance as a similarity measure. In a next step, the similarity matrix is taken as an input
for HDBSCAN clustering which groups all face clusters of individual persons based on the similarity
measure. This gives us face cluster-wise connections showing that the same person appeared in all
connected videos. This information allows the investigation of collaborations between different
channels.

Although we can now connect the appearing individuals, we do not know yet which of the
persons is a content creator, i.e., owner of the channel, or an external actor appearing. To determine
the content creator of a channel, we can select the face cluster with the highest number of appearances
on the channel. However, this approach would be unable to assign multiple content creators to a
single channel. As do not want to restrict this method to single content creator channels and we
assume that some portion of the available channels already have multiple content creator, we use
the following approach. To decide if an individual is a content creator, we leverage the number of
appearances per individual and channel. In detail, a person may have appeared in different channels,
we assign the person as a content creator for the channel with the highest number of appearances.
Thereby, a channel with one or multiple content creators can be correctly detected.

Figure 4: Sample graph of PewDiePie’s YouTube channel and 1-hop neighbors7

10/28

Table 2: Overview of the available crawler tools, ∗are outdated

Scrapy

YTCrawl YOUStatAnalyzer HarVis

ytdata∗

TubeKit∗

Customizable
Documentation
Storage
API usage
Language

Highly
Extensive
Customizable
Yes
Python

limited
sparse
File
No
Python

limited
sparse
MongoDB
Yes
Python

limited
sparse
SQL
Yes
Java

limited
sparse

limited
sparse
SQLite MySQL
Yes
Python

Yes
PHP

Collaboration Graph

Inspired by [5, 17], the collaborations between channels are modeled as a graph with channels as
nodes and collaborations as directed edges connecting the nodes. The edge direction describes
that a content creator of the origin channel appeared, i.e., collaborated, in one or more videos of
the destination channel. Figure 4 depicts an example graph showing one the world’s most popular
YouTubers: PewDiePie. The edge label denotes how often collaborations between the two channels
were observed. We use a graph to visualize and model the collaborations as we can apply different
graph algorithms to analyze the underlying channel relations.

4 YouTube Statistics Data Acquisition

In the following, we briefly describe how we crawl the required information from YouTube and
specify how we select appropriate YouTube channels for crawling our dataset.

4.1 YouTube Data Crawling

To assess the effect of YouTuber collaborations, we need to acquire channel metadata such as
the subscriber count and video view counts. Additionally, we also want to acquire the video and
channel metadata, such as video titles, video and channel descriptions, and the channels’ featured
channel list. The crawled data is not filtered by a specific video topic but through a seed set of
YouTube channels and their uploaded videos. Under those requirements most of the existing tools
such as YTCrawl8, YOUStatAnalyzer9, or HarVis10 cannot be leveraged for our purpose without
significant code changes. Customizing the frameworks requires a solid documentation, which most
of the tools do not provide or only in sparse form. To this end, we decide to develop a YouTube

7Channel images taken from https://www.youtube.com/{PewDiePie, chadwildclay, channel/UCEYLdM2bdhmw-
TS3c0TjFNw, KickThePj, TheBigManTyrone, MrMccruddenmichael, user/LandonProduction, HerrNewstime,
iwantmylauren, iOTrendz, channel/UCIq3bpW-MaAzj4Y2G9ezPhA, channel/UCBINYCmwE29fBXCpUI8DgTA,
channel/UCm3GpkVRonpt2BHrt3GhwjQ,
channel/UCZA-
comicbookresources,
pDB9BW7ZjNcPb3Wu7rRg, imsannachanel, TokyoAtomic, CutiePieMarzia}

JoeCroninSHOW,

8https://github.com/yuhonglin/YTCrawl [Accessed: 2018-05-08]
9https://github.com/mattiazeni/youstatanalyzer [Accessed: 2018-05-08]
10https://github.com/DrUzair/HarVis [Accessed: 2018-05-08]

11/28

data crawling tool based on the Scrapy11 framework which is highly customizable and provides
extensive documentation, that allows to implement all requirements of our envisioned crawler in
reasonable time and with a comparable small effort. Scrapy is widely used and has a big open source
community. Table 2 shows a qualitative comparison of the considered YouTube data crawling tools,
including Scrappy.

Figure 5: Populate spider architecture, d is the user-defined maximum depth for channel recursion.

Next, we describe the design of the Scrapy-based crawling architecture. As we distinguish
between continuous and static data, we implemented two spiders, i.e., crawling modules in Scrapy.
The first spider, which we denote as Populate Spider, crawls static data and populates a database
with channel and video entries, e.g., the video and the channel name. Figure 5 illustrates the crawling
process. The populate spider takes an initial set of channel IDs for which it requests all static data
and subsequently creates a database entry for every crawled channel. Note that for fixed set of
channels d is set to zero to hinder Scrapy from adding additional channels to the set.

In the next step, a second spider denoted Daily Spider crawls continuous data created by the
channels and videos already known in a daily manner, i.e., view count and subscriber count. Here,
each channel’s Upload Playlist is crawled, which contains the videos uploaded by a channel to
identify newly uploaded videos. Crawling the popularity statistics for all videos uploaded on the
given channels allows constructing time series of popularity statistics. We record all interactions
on the monitored channels such as view, comment, and subscriber counts in the time span between
28.12.2016 and 28.03.2017 on a daily basis.

11https://scrapy.org [Accessed: 2018-05-08]

12/28

Figure 6: Daily spider architecture.

4.2 Data Selection and Representation

The Populate Spider needs an initial set of YouTube channel IDs. To create a qualitative and large
dataset of channels, we crawl three of the most popular MCNs [14] as channels associated to a
MCN have higher chances to collaborate [4]. These MCNs are described in table 3. We used
the website SocialBlade12 to derive the mapping of channels to MCN member lists. Here, we
take a random sample of 1.5 × 103 channels for every MCN in which the 100 channels with most
subscribers per MCN are included. In a next step, we use the so called Featured Channel List
of the crawled channels, which contains other channels defined by the channel owner to express
an acquaintanceship between his and other channels. This relationship is modeled in a graph
representation as described in section 3.3, containing roughly 44k channels. Here, channels are
represented by nodes, while the featured channel list comprises unidirectional edges from one node
to other nodes. Finally, non-mutual edges between channels are removed, while mutual edges,
i.e., nodes having each other in their Featured Channel List, are considered likely to collaborate
and, hence, are kept. We also excluded Gaming videos as we observed a lack of face presence in
these videos and, furthermore, often high resolution game figures depicted on covers or within the

12https://socialblade.com/youtube/top/networks/most-subscribed [Accessed: 2018-05-08]

Table 3: Most popular YouTube MCNs worldwide, measured by number of subscribers.

Name

Members

Subscribers (over 30 days) Views (over 30 days)

BroadbandTV
Studio71
Maker Studios

237,235
13,194
9,460

82,718,601
18,535,751
14,011,532

20,107,687,476
5,402,265,290
4,613,091,2598

13/28

videos would have led to increases imprecision. From the remaining subgraph, we extract the largest
connected component, resulting in a graph with roughly 8k nodes and about 10k edges indicating
potential collaborations. By applying CATANA to this subgraph, i.e., analyzing 2.4 years of video
uploaded on these channels for a period of three months, we identified 1,599 nodes and 1,728 edges
representing actual collaborations. The edge sum, which corresponds to the overall number of
collaborations sums up to 3,925, see Table 4.

Table 4: Collaborations observed in the three month’s time span.

Collaborations Duration Mean Median

75-percentile Max

3,925

3 months

2.8

1.0

3.0

134

5 Evaluation

In this section, we formulate and answer research questions with respect to the focus points
of: (i) collaboration frequency and partner selectivity (Section 5.1), (ii) the influence of multi-
channel networks (MCNs) on channel collaborations (Section 5.2), (iii) collaborating channel types
(Section 5.3), and (iv) the impact of collaborations on video and channel popularity (Section 5.4).

5.1 How often do collaborations happen and reoccur with the same partner?

(a) Number of pair-wise collaborations

(b) Number of collaborations per channel

Figure 7: Histograms of detected collaborations per channel pairs (a) and per channel (b)

Using the collaboration graphs, we can easily determine the overall number of collaborations by
summing up the edge weights between two YouTube channels. Analyzing the edge weights allows
us to examine the number of repeated collaborations. Table 4 depicts the derived collaboration
statistics where we observe that the distribution is skewed to the right, indicating the presence

14/28

of a few channel pairs with a comparably high number of collaborations. We confirm this by
drawing the histogram of the collaboration counts in Figure 7a, showing the distribution of repeated
collaborations between two YouTubers who have collaborated at least one. We deduce that over a
3-months observation period collaborations between two channels rarely happen more than once.
In a next step, we analyze the number of collaborations per channel instead of distinct channel
pairs. Therefore, we sum up the edge weights for every channel node. Taking the perspective of a
channel, we differentiate between collaborations taking place in own videos (internal) and videos of
other channels (external). If a collaboration between YouTuber A and B occurs on YouTuber A’s
channel, it is considered as an internal collaboration by A and as an external collaboration by B.
This distinction helps us later to detail the effects on both sides of a collaboration. Figure 7b shows
the corresponding distributions. We conclude that a small number of highly collaborating channels
denoted central channels exists, with most of the remaining channels having very few collaborations.
Thus, central channels show a high in-degree, demonstrating a key influencer role on YouTube.
These YouTubers are especially valuable for product placements, advertisements, and, hence, are
especially valuable assets for their MCNs. One weakness of the former analysis is that it compares
results based on the absolute number of collaborations. Thus, we investigate the relative ratio of a
YouTuber’s collaborations compared to the overall number of the channel uploads. Given the number
of internal collaborations of a channel k, denoting collaborations only occurring in its own videos,
and the number of videos of the channel n, we calculate the collaboration ratio as k/n. Figure 8a
shows the distribution of the collaboration ratio. Values around one imply that in nearly every video
of the channel, a collaboration is found. This may indicate that certain content creators regularly
work together, or share a common channel while also operating separate channels alone. Values
larger than one can occur if multiple collaborations were detected in a single video. In Figure 8b,
we observe only a few outliers with a ratio above one, while most of the channels have a ratio close
to zero. This indicates that a large portion of channels have only a single ingoing collaboration.
Summarizing our finding with respect to collaboration frequency we observe that a single channel
collaborates with other channels on average 2.8 times ([2.5 − 3.15] at a 99% confidence level). If

(a) Collaborations per uploaded videos

(b) Channel collaborations

Figure 8: Collaboration/Video ratio and separated in- and outgoing collaborations.

15/28

channels collaborate, we find in our 3-month dataset that they repeat their collaboration on average
2.3 times ([2.0 − 2.6] at a 99% confidence level). Overall, the distributions for collaboration metrics
are skewed as a consequence of a few highly influential YouTubers.

5.2 How do multi-channel networks (MCNs) influence channel collaborations?

To answer this question, we first analyze which collaborations take place between MCNs. To this end,
we first determine the respective MCN for each channel using publicly available information13 to
augment the channel information of our collaboration graph. Figure 9 depicts the most collaborating
MCNs in form of a MCN-collaboration matrix. Overall, we found 405 MCN pairs collaborating
with each other. Note that the entry None refers to channels for which we could not determine a
MCN association.

Figure 9: Absolute number of collaborations within and between MCNs.

13https://socialblade.com/ [Accessed: 2018-05-08]

16/28

Figure 10: Internal and external MCN collaborations.

Examining the diagonal of the matrix in Figure 9 we observe a distinct trend showing that most
collaborations occur within MCNs, and thus between their members. Further, we observe that
significant collaborations between networks are mainly confined to the three dominant networks,
namely, BroadbandTV, Studio71, and Maker Studios. We find many collaborations of unassociated
channels, i.e., with the label None, with the three dominant networks, which we attribute to the fact
that they are the world’s three largest MCNs and, hence, have YouTube channels associated which
are popular and an attractive target for collaboration. Furthermore, famous YouTubers are a popular
topic for other YouTuber’s that may show the popular YouTuber’s face or video sequences. We
deduce that belonging to a MCN strongly increases the probability of a YouTuber to collaborate.

Figure 10 shows the percentage share of collaborations separated by MCN in- and external
collaborations. Here, we observe that the three largest MCNs, i.e., BroadbandTV, Studio71, and
Maker Studios as well as PranksNetwork have much more internal collaborations compared with
the smaller MCNs. Hence, their YouTubers collaborate more in their own videos than on the
videos of other MCN’s YouTubers. Note that a large portion of the outgoing collaborations is with
channels that are not associated with a MCN. Channels not belonging to a MCN show a preference
to work with MCN-associated channels as more than 70 percent of their collaborations are outgoing.
We conclude that an influence of MCNs concerning YouTuber collaborations can be inferred. In
summary, we find that channels associated with a MCN collaborate more often with each other and
if collaborations occur outside the MCN, then they are usually with non-associated channels and
rarely with other MCNs’ YouTubers.

17/28

Table 5: Popularity class definitions and their number of observed channels.

Popularity Class

Subscriber Range

#Channels

0
1
2
3
4
5
6

[0, 103)
[103, 104)
[104, 105)
[105, 106)
[106, 107)
[107, 5x107)
[5x107, 108)

813
1,575
2,569
2,420
544
20
1

5.3 Which channel types collaborate?

In the following, we group YouTube channels with respect to popularity and content category. First,
we assign each channel to one out of seven popularity classes, based on their subscriber count. Here,
the chosen classes resemble the classes used for the YouTube awards14, which are awards shipped
to the YouTubers when they exceed a certain number of subscribers. Next, we analyze collaboration
behavior regarding the YouTube video category, a label which the YouTuber can select out of a set
of given categories during the video upload process.

YouTube Popularity Classes We assign a channel’s popularity class with respect to the number
of subscribers as depicted in Table 5. In column #Channels, the table shows also the number of
YouTube channels in our dataset which belong to the corresponding popularity class. We can see
that the major share of the channels observed belong to popularity class 1, 2, or 3. Class 6 is an
exception, as it only contains a single channel, i.e., PewDiePie, the most successful YouTuber in
terms of subscribers so far. Figure 11a depicts the share of observed channel collaborations between
popularity classes. Here, channels belonging to a numerically higher class have more subscribers
than channels belonging to numerically smaller classes. The matrix entry atf of row f and column
t denotes that the number of YouTubers from a channel of popularity class f appear in videos
belonging to channels of popularity class t. We can see that most collaborations happen within
class 3 and neighboring classes 2 and 4, which we ascribe to two factors. First, these channels
have reached a popularity in the YouTube environment that attracts collaborations. Second, these
channels do not yet belong to the most popular channels, i.e., categories 4, 5, and 6 but are likely to
try to increase their own popularity by attracting more viewers through collaborations with other
YouTubers.

YouTube Categories
In Figure 11b we show the share of collaborations between YouTube cate-
gories. Most collaborations are detected in, and between the Entertainment and People & Blogs
categories, which is reasonable as they prevalently contain human presence and interaction. The
same applies for categories like Comedy. In the figure, we observe asymmetric relations, e.g.,

14https://www.youtube.com/yt/creators/rewards.html [Accessed: 2018-05-08]

18/28

(a) Popularity classes.

(b) Video categories.

Figure 11: Collaborations within & between popularity classes and YouTube video categories (in
%).

between Comedy and Film & Animation, that collaborate more in with Entertainment channels than
within the same category. For collaborations within a category, i.e., the diagonal of the heat map, we
only notice a surge for Entertainment. We observe that the most frequent collaborations occurred
within the category Entertainment, which also shows the second most video uploads. Note that
Entertainment is a rather generic term and can therefore, depending on the YouTuber’s interpretation,
also include comedy, film, and animation related content.

5.4 How do collaborations impact video and channel popularity?

We investigate the two parts of this question separately, focusing, first, on the observed effects on
video popularity and, second, on channel popularity. Therefore, we use popularity statistics of a
3-months period for roughly 105 videos, considering videos for which we have at least 12 daily
popularity measurements, i.e, videos being older than 12 days. We chose 12 days as we observed
that most older videos do not receive much more views. Using CATANA, we deduce a collaboration
graph with roughly 104 edges indicating collaborations within the observed 8 × 103 channels. Using
two sets for collaboration and non-collaboration videos, we analyze the maximum values of view
and subscriber counts of the 12-days time-span and their gradient. The benefit of these gradients is
that they are not biased by absolute numbers but represent the relative popularity growth.

19/28

Figure 12: Number of views after 12 days for collab. (green) and non-collab. (blue) videos.

5.4.1 Video Popularity

First, we examine the maximum video view counts observed in the first 12 days. Figure 12 shows
the video view count distribution. By examining the left side of the figure, we see in the box plot that
the average view count is higher for videos with a collaboration compared with non-collaborations.
Note that the median is stretched nearly doubled (from about 26k to 45k views) for the cases of
present collaborations. Although the median is only slightly higher in case of a collaboration, the
upper 50% of video views are more scattered and show more views. Additionally, we plotted the
average view counts for both cases and their 95% confidence intervals on the right side of Figure 12
where we see a large gap. The figure suggests that a significantly higher view count can be expected
if a video contains a collaboration.

The generally higher popularity of collaboration videos can be reasoned in the generally higher
popularity of collaborating channels. As we previously examined, class 3 channels collaborate
more often than channels of lower popularity classes. If we therefore assume that more videos
with collaborations are uploaded by class 3 channels, the videos consequently tend to a higher
popularity compared for example with class 2 videos. To further substantiate this effect, we evaluate
the gradient and growth of the video view counts. Hence, we calculate the average view growth
factor between non-collaboration and collaboration videos. For this, we use the average maximal

Figure 13: View count growth factor between collaboration and non-collaborations videos. A
positive value indicates the superiority of collaborations.

20/28

Table 6: View growth of collaborations compared to non-collaborations.

Channels Duration Mean Median

75-percentile Min Max

1116

3 months

34.32

-6.73

32.47

-99.70

6,376.28

Figure 14: Video view count growth for the first five days of a collaboration vs. the
non-collaboration view growth on the first day.

12 day view value for every channel, differentiated by collaboration and non-collaboration. Next,
the percentaged growth from the non-collaboration value to the collaboration value is calculated
channel-wise. Figure 13 displays these results. As only channel with both collaboration and non-
collaboration data could be used for the percentaged growth calculation, samples of 1,116 channels
are used. The difference in number of channels is due to channel which only collaborate in external
videos, and do not host collaboration in their own. Statistics on the differences between the two
video groups on the video view growth are shown in table 6. In a next step, we investigate the
distributions of these view count differences depicted in Figure 13. Here, the 0.95 confidence interval
is between 19% and 51%, indicating that a significant growth of the views between collaboration
and non-collaboration videos can be expected.

Next, we compute the gradients between each pair of the 12 days of the videos’ view counts,
resulting in 11 gradient values. Additionally, we calculate the percentaged growth between these
values. The percentaged growth of the first 6 days after a collaboration vs. non-collaboration view
growth on the first day is depicted by Figure 14. This figure shows the longer lasting temporal
impact of collaborations. Further, Figure 15 shows the box and bar plots of the gradient values, i.e.
the absolute view count increase, using a 0.99 confidence level.

21/28

Figure 15: Video view count gradient.

Figure 16: Channel subscriber gradient and percentaged growth.

5.4.2 Channel Popularity

Here, we cannot directly differentiate between collaboration and non-collaboration channels as for
videos, since one channel may contain both, collaboration and non-collaboration videos. Therefore,
we filter channels, which uploaded videos with and without collaborations, resulting in 1,599
channels. The channel popularity is measured by the number of views of its videos and the number
of channel subscribers. We define a window of two days after a collaboration, for which we will
classify the subscriber counts as belonging to a collaboration, the remaining statistics measured
are classified as belonging to non-collaboration. Thereby, we gathered 9,086 channel subscriber
measurements for collaborations, and 78,877 for non-collaborations. Figure 16 shows the subscriber
count differentiated between collaborations and non-collaborations. From the figure we conclude
that collaborations have a slight positive effect on channel subscribers. Compared to the increase of
viewers, the increase of subscribers is only about one tenth of total users. Though, the relative growth
compared to non-collaborating video measures is about 30% larger in terms of newly attracted
subscribers compared with the newly attracted viewers.

In addition to the above evaluation of the two-day collaboration window, we evaluate a 6-day
window on a daily basis. Figure 17a shows the percentaged subscriber growth over 6 days starting
with day 0, which is the upload date of the collaboration video. Figure 17b depicts the percentaged
subscriber growth for each day and on the left side and the respective overall channel view growth

22/28

(a) Channel subscriber count growth.

(b) Channel view count growth.

Figure 17: Effect of collaboration over the first six days.

Figure 18: Subscriber growth for collaborations between YouTube channel categories.

on the right side. On both sides, also the growth of non-collaboration videos after day 0 is shown
to allow for a comparison. We note that the highest subscriber growth can be observed for days 0
and 1 with the growth slowly decreasing to approach the base line describing non-collaborations.
In addition to the channel subscriber growth, we apply the same evaluation methodology for the
overall channel views, an alternative measure of channel popularity. Here, we expect a similar
pattern as for the channel subscriber counts but we observe a very different pattern, depicted in
Figure 17b. For day zero and one, the view growth is quite low and close to non-collaboration
videos. In contrast to that, for day 2, we observe a significant increase. Despite the fact that more
people watch collaboration videos on day two, we found that users seem to be less engaged as for
day 2 overall less subscriptions are observed than for days 0 and 1.

23/28

Figure 19: View count growth for collaborations between YouTube channel categories.

5.5

Impact of Video Popularity Classes and Video Categories

YouTube Categories Figure 18 and 19 show the impact of a collaboration of YouTubers belonging
to different video categories and popularity classes. We observe that view and subscriber counts vary
strongly amongst different channels. Hence, we compute the relative popularity growth for videos
with and without collaborations. Here, we took only popularity measurements if a collaboration
video was uploaded and at the same day no other video was uploaded to guarantee that the channel
popularity measure is not impaired. In case different categories collaborate, we show the effects
for both categories separately. For all collaborations taking place between YouTubers uploading
mostly videos of the same category, a significant increase of subscriber and view count is observed.
Here, the category People & Blogs is an exception, as on average more subscribers can be attracted
by a collaboration but less video viewers. This is still beneficial as the subscribers are potentially
watching all videos uploaded by the YouTubers in the future.

YouTube Popularity Classes
In Figure 20 and 21 the impact of collaborations between channels
of different popularity classes is shown. In general, we observe a significant benefit of collaborations.
Note that lower popularity classes, especially class 1 and 2 YouTubers benefit significantly stronger
than higher popularity classes. It can be seen that for classes 3 and 4, the gain of a collaboration is
comparably low and often there is no significant difference. For class 4 YouTubers, no effect of
collaborations can be observed. Hence, we deduce that especially for YouTubers with less than 105
subscribers, i.e., class 1 or 2, collaborations significantly increase the number of views.

24/28

Figure 20: Subscriber growth for collaborations between channel popularity classes. The x-axis
denotes the depicted popularity class in the constellation depicted in brackets, e.g., (1 in 3) means
that a YouTuber of popularity class 1 appeared in a video published on a popularity class 3 channel.

Figure 21: View count growth for collaborations between YouTube channel popularity classes.

Concluding our popularity evaluation for videos and channels under collaborations, we state we
observe that collaborations have positive effects on video views and on engaging new subscribers.
Especially for YouTubers of low popularity classes such as class 1, a collaboration can add about
100% additional views and new channel subscribers. Concerning the impact on video views, we
calculated a percentaged growth through collaborations with a mean between 19% and 51% with
0.99 confidence. Also channels popularity is significantly increased through collaborations, i.e., for
both considered metrics, namely channel subscribers and total channel views.

25/28

6 Conclusion and Future Work

In this article, we first designed and implemented a system for the acquisition and analysis of
collaboration data in user generated content at the example of YouTube. We implemented a video-
based face recognition system named CATANA for which we examined and evaluated different face
recognition and clustering techniques. We applied CATANA to a collected dataset of videos over a
3-month period where we extracted appearing content creators and leveraged this information to
detect collaborations between channels.

We observed that out of 7,492 channels in our dataset 1,599 collaborated, with an average of
2.8 times per channel. Regarding the types of channels, which collaborate we found that channels
with a subscriber count between 105 - 106 collaborate the most and the Entertainment YouTube
category shows most collaborations. Furthermore, we inferred that multi-channel networks generally
exhibit collaborations within the same network or channels, which are not associated with any other,
potentially competing, network. We analyzed the acquired popularity statistics for both videos
and channels and found significant differences between collaboration and non-collaboration sets,
indicating a positive effect on the popularity that is measured by subscriber and view counts. In
this work we proposed a viable method for collaboration detection in user generated content that is
based on face recognition. A potential limitation of the proposed system is the differentiation with
respect to the collaboration context, which can be mapped to different types of face appearances, i.e.
posters or content usage. In future work, using voice recognition in addition to face recognition is
likely to increase detection rates as well as differentiate collaboration context.

Reproducibility

To enable other researchers to use, reproduce, and extend our research, we release our tool chain
at https://github.com/christiannkoch/CATANA. This contains: (i) the CATANA
framework and evaluation scripts used here, (ii) the 3-months collaboration graph used in this paper,
and (iii) an interactive web-based visualization of the collaboration graph.

Acknowledgements

This work has been funded in parts by the DFG as part of the Collaborative Research Centre 1053
MAKI (C3, B4).

26/28

References

[1] T. Ahonen, A. Hadid, and M. Pietikainen. Face Description with Local Binary Patterns:
IEEE Transactions on Pattern Analysis and Machine

Application to Face Recognition.
Intelligence, 28, 2006.

[2] B. Amos, B. Ludwiczuk, and M. Satyanarayanan. OpenFace: A general-purpose Face
Recognition Library with Mobile Applications. Technical report, CMU-CS-16-118, CMU
School of Computer Science, 2016.

[3] B. Gahan. How to be successful on YouTube: The 3 steps. http://thenextweb.com/
insider/2015/03/04/the-3-steps-to-success-on-youtube/, 2015. [Ac-
cessed: 2018-05-08].

[4] M. Gielen. Best Practices For A YouTube Multi-Channel Network 2.0. http://www.
tubefilter.com/2015/03/24/youtube-mcn-multi-channel-network/,
2015. [Accessed: 2018-05-08].

YouTube Universum. Die Vernetzung

[5] B. Gugel.
sualisiert.
youtube-universum-die-vernetzung-der-youtuber-visualisiert.
html, 2015. [Accessed: 2018-05-08].

vi-
http://www.gugelproductions.de/blog/2015/

der YouTuber

[6] Y. Guo, L. Zhang, Y. Hu, X. He, and J. Gao. Ms-celeb-1m: A Dataset and Benchmark for
large-scale Face Recognition. In European Conference on Computer Vision, pages 87–102.
Springer, 2016.

[7] M. Holmbom. The YouTuber A Qualitative Study of Popular Content Creators. Bachelor

thesis, Umea University, 2015.

[8] G. B. Huang, M. Ramesh, T. Berg, and E. Learned-Miller. Labeled Faces in the Wild: A
Database for Studying Face Recognition in Unconstrained Environments. Technical report,
University of Massachusetts, Amherst, 2007.

[9] E. Learned-Miller, G. B. Huang, A. R. Chowdhury, H. Li, and G. Hua. Labeled Faces in the
Wild Website. http://vis-www.cs.umass.edu/lfw/. [Accessed: 2018-05-08].

[10] E. Learned-Miller, G. B. Huang, A. RoyChowdhury, H. Li, and G. Hua. Labeled Faces in the
Wild: A Survey. In Advances in Face Detection and Facial Image Analysis, pages 189–248.
Springer, 2016.

[11] O. M. Parkhi, A. Vedaldi, and A. Zisserman. Deep Face Recognition. In Proceedings of the

British Machine Vision Conference (BMVC), 2015.

27/28

[12] D. Sandberg. Facenet Project Repository. https://github.com/davidsandberg/

facenet. [Accessed: 2018-05-08].

[13] F. Schroff, D. Kalenichenko, and J. Philbin. FaceNet : A Unified Embedding for Face
Recognition and Clustering. In IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), 2015.

[14] Social Blade LLC. SocialBlade Network Statistics. https://socialblade.com/

youtube/top/networks. [Accessed: 2018-05-08].

[15] M. Turk and A. Pentland. Eigenfaces for recognition. volume 3, pages 71–86. MIT Press,

1991.

Face Recognition. 2016.

[16] Y. Wen, K. Zhang, Z. Li, and Y. Qiao. A Discriminative Feature Learning Approach for Deep

[17] C. Wilson, B. Boe, A. Sala, K. P. N. Puttaswamy, and B. Y. Zhao. User Interactions in
Social Networks and Their Implications. In ACM European Conference on Computer Systems,
EuroSys’09, 2009.

[18] L. Wolf, T. Hassner, and I. Maoz. Face Recognition in Unconstrained Videos with Matched
Background Similarity. In IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), 2011.

[19] YouTube, LLC. Youtube Creator Academy: Collaboration. https://creatoracademy.

youtube.com/page/lesson/collaboration. [Accessed: 2018-05-08].

[20] YouTube, LLC. YouTube Statistics.

https://www.youtube.com/yt/press/

statistics.html. [Accessed: 2018-05-08].

[21] K. Zhang, Z. Zhang, Z. Li, and Y. Qiao. MTCNN Face Detection. https://kpzhang93.
[Accessed:

github.io/MTCNN_face_detection_alignment/index.html.
2018-05-08].

28/28

8
1
0
2
 
y
a
M
 
1
 
 
]

V
C
.
s
c
[
 
 
1
v
7
8
8
1
0
.
5
0
8
1
:
v
i
X
r
a

Collaborations on YouTube: From Unsupervised Detection to the
Impact on Video and Channel Popularity
Christian Koch, Moritz Lode, Denny Stohr, Amr Rizk, Ralf Steinmetz
Multimedia Communications Lab (KOM), Technische Universität Darmstadt, Germany
E-Mail: {Christian.Koch | Denny.Stohr | Amr.Rizk | Ralf.Steinmetz}@kom.tu-darmstadt.de

Abstract

YouTube is one of the most popular platforms for streaming of user-generated video. Nowadays,
professional YouTubers are organized in so called multi-channel networks (MCNs). These networks
offer services such as brand deals, equipment, and strategic advice in exchange for a share of the
YouTubers’ revenue. A major strategy to gain more subscribers and, hence, revenue is collaborating
with other YouTubers. Yet, collaborations on YouTube have not been studied in a detailed quantita-
tive manner. This paper aims to close this gap with the following contributions. First, we collect a
YouTube dataset covering video statistics over three months for 7,942 channels. Second, we design
a framework for collaboration detection given a previously unknown number of persons featuring in
YouTube videos. We denote this framework for the analysis of collaborations in YouTube videos us-
ing a Deep Neural Network (DNN) based approach as CATANA. Third, we analyze about 2.4 years
of video content and use CATANA to answer research questions providing guidance for YouTubers
and MCNs for efficient collaboration strategies. Thereby, we focus on (i) collaboration frequency
and partner selectivity, (ii) the influence of MCNs on channel collaborations, (iii) collaborating
channel types, and (iv) the impact of collaborations on video and channel popularity. Our results
show that collaborations are in many cases significantly beneficial in terms of viewers and newly
attracted subscribers for both collaborating channels, showing often more than 100% popularity
growth compared with non-collaboration videos.

1 Introduction & Problem Statement

Collaborations are a key strategy to increase the dissemination and, hence, popularity of user-
generated videos on YouTube. Here, YouTuber A, i.e., a content creator, introduces a collaborating
YouTuber B to his viewers seeking to attract their interest to the content of YouTuber B. The rationale
here is that given the viewers interests, they are more likely to watch the introduced YouTuber’s
videos and eventually become subscribers [3, 4, 19]. Collaborations often occur in a reciprocal
manner on both of the collaborating channels to attract each other’s viewers and, thereby, increase
both YouTuber’s revenue. Video monetization can be activated through participating in the YouTube
Partner Program (YPP) [7]. Thereby, YouTubers can configure their videos allowing YouTube to

1/28

insert short ad clips before and within their videos. In return, YouTube pays a share of the resulting
revenues out to the YouTubers. With more than 10k people that were reported in 2016, the annual
growth of the number of YouTubers earning six figures per year amounts to ∼ 50% [20].

In contrast to works describing collaborations, e.g., within scientific communities or online
social networks, there are only few studies on the detection of collaborations in user-generated
videos and a lack of quantitative analysis of their desired impact on popularity. Note that Video-
on-Demand (VoD) platforms such as Netflix are not exposed to user-generated content (UGC)
which is more scattered, diverse, and generated at a much higher rate. While general metadata of
UGC videos is available, no explicit information on collaborations exists. Although mentions of
collaborating YouTubers in the video title or in the description are in general possible, they often
miss collaboration-related information and are, hence, not a reliable source of information.

Nowadays, popular YouTubers often belong to a multi-channel network (MCN), e.g., Broad-
bandTV, Studio71, and Maker Studios, which offer equipment, brand deals, and strategic advice to
increase the YouTubers’ popularity in exchange for a share of their revenue [7]. Essentially, such
strategic advice comprises collaboration policies that describe the most beneficial collaborations
with diverse YouTubers.

Until now, a public documentation on the efficiency of collaborations on YouTube does not exist.
A quantitative analysis of different types of collaborations, e.g., between YouTubers of different
popularity or content categories has the potential to guide YouTubers to popularity- and, hence,
revenue-maximizing behavior. To this end, this article addresses the challenging task of identifying
and analyzing content creator collaborations on large-scale UGC video platforms taking the example
of YouTube. Our analysis focuses on (i) collaboration frequency and partner selectivity, (ii) the
influence of MCNs on channel collaborations, (iii) collaborating channel types, and (iv) the impact
of collaborations on video and channel popularity. In the following sections we address these focus
points in a framework for collaboration detection and analysis denoted CATANA. For the design of
CATANA, we argue that the analysis of content creator collaborations on large-scale UGC video
platforms faces three key challenges:

• YouTube-suitable Face Detection: The YouTubers’ faces constitute the basis for identifying
collaborations. Hence, we require their inference and storage in an appropriate representation.
Changing lights, face expressions, and camera perspectives add to the difficulty of deriving
these representations.

• YouTuber Identification: In contrast to most face recognition tasks, in our scenario, an
unknown number of people appearing in user-generated videos needs to be identified based
on the detected faces. Therefore, an accurate association of face samples to people for a large
set of YouTubers needs to be obtained. Additionally, we need to identify which person is the
owner of the YouTube channel and which persons are potential guests.

• Collaboration Representation: The co-occurrence of YouTubers in a video indicates collab-
oration. However, people appearing sporadically, e.g., passersby do not carry strong evidence
of collaborations. Filtering outliers and storing inferred collaborations in an appropriate form
is essential for further analysis.

2/28

The remainder of this article is structured as follows. Section 2 provides an overview of used
benchmarking datasets, face recognition approaches, and existing works on YouTube collaborations.
In Section 3, we motivate and explain CATANA’s major building blocks. Section 4 presents our
data acquisition and selection process. In Section 5, we evaluate and discuss our results answering
relevant research questions. We conclude our article in Section 6 and discuss future work.

2 Related Work

The related work provides, first, an overview of existing datasets that are useful for benchmarking
face recognition methods on YouTube. Second, an overview of recent face recognition methods is
given. Third, existing works addressing YouTube collaboration analysis are presented and discussed.

2.1 YouTube Face Recognition Datasets

In this section we give a brief overview of the two face datasets used for optimizing CATANA. Both
datasets are frequently used in face recognition studies of the last years, as well as in related work.

Labeled Faces in the Wild (LFW) LFW is a publicly available face dataset introduced in [8]
and released as an effort to spur face recognition research. It has been referenced in more than 50
papers related to face recognition [10]. LFW’s provides a large set of face images in a large range of
variations. This includes variation in pose, lighting, expression, background, ethnicity, and age [9].
The dataset consists of 13,244 images of 5,749 people with images in 250x250 pixel JPEG format.
These face images were collected from the web and contain celebrities, politicians, athletes, and
other public figures. For training, validation, and testing, mutually exclusive splits are available
suited for usage in a 10-fold cross validation. Training and testing data are, thereby, presented as
either matching or mismatching face pairs. Hence, the proposed evaluation experiments aim at the
problem of pair matching, deciding whether the images are of the same person. In total 6,000 pairs
are provided, divided into 10 splits with each 300 match and 300 mismatch pairs.

YouTube Faces (YTF) YTF is a dataset of face videos introduced in [18] and designed for
studying the problem of face recognition in videos. The dataset contains 3,425 videos of 1,595
different people appearing in YouTube videos. These people are a subset of the 5,749 people from
the LFW dataset and for every person an average of 2.15 videos are available. The video duration
ranges between 48 and 6,070 frames and all video frames are stored individually as JPEG images.
Structure and design of YTF is heavily inspired by LFW. Similarly, matching and mismatching pair
are provided, for usage in a 10-fold cross validation pair-matching evaluation. In comparison to the
LFW evaluation, pairs consist of videos, allowing to decide if the pair of videos is subject of the
same person or not. Overall, 5,000 pairs are provided, divided into 10 splits, each containing 250
match and 250 mismatched pairs.

3/28

2.2 Face Recognition

Two kinds of fundamentally different face recognition approaches exist. The first kind that is widely-
spread relies on fixed mathematical models and structures, e.g., Eigenfaces [15] and Local Binary
Patterns Histograms (LBPH) [1]. While these classical approaches have shown solid performance,
the second kind of techniques, using deep neural networks (DNNs) is outperforming classical
approaches and beginning to replace them. As they are clearly superior in performance to classical
approaches and even compared with humans [10], we focus only on DNN-based approaches.

Parkhi et al. [11] present a deep learning-based face recognition method called VGG-Face. The
authors further propose how a very large-scale face dataset can be assembled by a combination
of automation and human in the loop. Focusing on celebrities for the dataset acquisition, they
extract a small number of images using the Google Image Search and the actors’ names. Then,
these images are audited through human annotators. In the next step, the actors are queried again
through image search, this time extracting a bigger amount of images. Instead of human annotation,
a linear Support Vector Machine (SVM) is pre-trained with the small number of images from the
first step and leveraged to classify the newly acquired images. Thereby, a dataset of 2,622 identities
and 2 million images is assembled. Furthermore, a CNN (Convolutional Neural Network) based
face recognition method is proposed, which is trained on the acquired dataset using the triplet-loss
function. The proposed method is then evaluated on the LFW and YTF datasets and compared
against other state-of-the-art methods, resulting in an accuracy of 98.95% for LFW and 97.3% for
YTF. We conclude that image acquisition through online image search can be a promising method
to acquire training data. In the context of this work, channel names could be queried, resulting in
face images of YouTubers. However, this would still require a human interaction for a potentially
large number of YouTubers and passersby in videos.

Schroff et al. [13] present a DNN model named FaceNet. They introduce the triplet loss
for training, i.e., a loss function designed to result in face representations, clustered based on
similarity. Triplet loss thereby works with triplets of matching / non-matching face images and
embeds these into a 128-dimensional Euclidean space. Thereby, the loss function ensures that an
anchor image of a specific person is closer to all other positive images of the same person, than it
is to any negative image from any other person. Thus, the network results in a 128-dimensional
face representation in a space where distances directly correspond to face similarity. Consequently,
classification and clustering are now straightforward by using standard Euclidean distance metrics.
Hence, accuracies of 99.63% on the LFW dataset and 95.1% on YTF were measured. Even though
similar in architecture than the previous DNN [11], a significantly larger private dataset of 200M
images was used for training.

Amos et al. [2] present OpenFace1, a CNN-based face detection and recognition framework
using only openly available training datasets for training. OpenFace builds up on the FaceNet [13]
architecture, combining it with computer vision and machine learning techniques, such as State
Vector Machine (SVM) for classification. For training the CNN model, public face datasets were
used, which licenses allow usage and publication of the resulting models. Hence, no training is

1http://cmusatyalab.github.io/openface [Accessed: 2018-05-08]

4/28

necessary for using the OpenFace framework. OpenFace is thereby trained with only 500,000 images
from combining the two largest labeled face recognition datasets for research, CASIA-WebFace2
and FaceScrub3. Overall, OpenFace achieves an accuracy of 92.92% on LFW.

A related framework to OpenFace is Facenet4, as both are based on FaceNet [13] and its
proposed DNN. Even though Facenet shares almost the same name as FaceNet [13], its developer
have no connection to the authors. In comparison to OpenFace, Facenet additionally implements
multiple additional ideas from different papers to tune accuracy. Amongst others, a different loss
function is used for training, the face representation is 1792-dimensional instead of 128-dimensional
and, furthermore, a different face detection technique is used [21]. Facenet implements the center
loss function [16], which is developed to improve the discriminative power of the learned features,
minimizing the intra-class variation while keeping the classes separable. To do so, it learns a center
for each feature class and penalizes distances between features and their center, resulting in high
accuracy. Facenet is trained using the MS-Celeb-1M face dataset [6], whose license allows model
reproducibility. Facenet is evaluated on the LFW dataset, showing an accuracy of 99.2%.

We conclude that DNN-based approaches show high accuracy on relevant datasets such as LFW
and YTF. As Facenet evidently outperforms the other reviewed approaches, we will deploy it as a
key component for CATANA’s face recognition capabilities.

2.3 Collaborations on YouTube

Mattias Holmbom [7] conducted a study on five YouTube channels, including interviews with their
content creators. He found that it is currently more difficult than ever for new content creators to
establish a YouTube channel, as already a large number of channels exist. Concerning collaborations
on YouTube, three of the five YouTubers associate their popularity directly or indirectly with
collaborations featuring other channels. Furthermore, MCNs were suggested as tool to get help in
finding other YouTubers addressing similar topics for collaboration.

In Brendan Gahan’s article "How to be successful on YouTube: The 3 steps" [3], the third
proposed step for new content creators is collaboration with other YouTubers, which already have an
established subscriber base as an essential step to expand a channel’s audience. YouTube’s official
Creator Academy5 also suggests collaboration as a powerful way to reach new users [19]. This is also
confirmed from MCNs’ side, as the MCN "Channel Frederator Network" recommends to facilitate
and instigate collaborations between network members [4]. We conclude that analyzing channels
registered in the same network can significantly improve the likelihood detecting collaborations.
This is important for our work to control the comparisons of videos with and without collaborations.
Bertram Gugel created a visualization of a share of the YouTube collaboration graph [5]. The
visualized graph provides insights into (i) the size of the respective YouTube channels, measured
by subscriptions, (ii) whether the association is uni- or bidirectional, as well as, (iii) to which

2http://www.cbsr.ia.ac.cn/english/CASIA-WebFace-Database.html [Accessed: 2018-05-08]
3http://vintage.winklerbros.net/facescrub.html [Accessed: 2018-05-08]
4https://github.com/davidsandberg/facenet [Accessed: 2018-05-08]
5YouTube website offering free online courses helping users creating better videos and improve channel performance.

5/28

Figure 1: CATANA’s system architecture.

MCN the channels belong. However, only the Featured Channel List of a YouTube channel is
used to determine a collaboration. On the one hand, this deliberate association between YouTube
channels does not necessarily indicate that channels collaborate. On the other hand, there exists
also collaborations with not featured channels. Furthermore, this work does not provide a thorough
analysis of individual videos and the effect of collaboration on their popularity. Hence, we conclude
that to the best of our knowledge no comprehensive analysis on YouTube collaboration and resulting
effects on popularity exists so far. We set this as the goal of this article.

3 System Design

In the related work, we have seen that it is common practice to recommend YouTubers to collaborate
to increase their audience and, hence, revenue. However, there is a lack of precise and detailed
analysis of the impact of YouTube collaborations on video and channel popularity. With CATANA,
we aim to close this gap. In the following, we motivate CATANA’s major building blocks, depicted
in Figure 1. As our focus is on video and channel popularity, we need the Metadata Crawler which
collects popularity time series, i.e., information of view counts in the case of videos and of the
subscriber counts in the case of channels. These time series are stored in the Database Storage.
Before analyzing the videos, the Video Downloader acquires the video data. In a next step, the
contained faces of the videos are detected and a dense representation is computed and stored in the
Database Storage, together with the video ID allowing to associate the contained faces with the
videos’ popularity time series. Then, the Clustering module determines face-person associations
by associating similar face representations with the same person. The most representative face
representations per person are stored in the Database Storage. The Collaboration Detection module
compares face representations of different videos, thereby allowing to find persons appearing in
different videos, as these videos contain the same face representations, i.e., the same persons. In a
last step, the collaborations detected are stored in form of a bidirectional graph used in the Analysis &
Evaluation module. In the following, we discuss the key processes and design choices of CATANA
in detail.

6/28

Table 1: Face recognition performance comparison with stDev, non-public are grayed out.

LFW

YTF

Eigenfaces
LBPH
Facenet
Openface
Human
FaceNet
VGG

0.6002 ± 0.00791
-
0.6782 ± 0.6300
-
0.9930 ± 0.0042
0.9980 ± 0.00134
0.9292 ± 0.01343 0.9971 ± 0.00264
0.97531
0.9963 ± 0.0009
0.9913

-
0.9512 ± 0.39
0.9740

1 [9]

2 [2]

3 [12]

4 this article

3.1 Face Detection and Recognition

We evaluated six recent approaches (ref. Section 2.2) to choose an appropriate face recognition
method. Eigenfaces [15] uses principal component analysis (PCA) to transform a high-dimensional
face image to a lower-dimensional representation, while Local Binary Patterns Histograms (LBPH)
[1] are histogram-based. In contrast to these traditional well-known methods, we also evaluate recent
DNN-based approaches: Facenet, Openface, FaceNet, and VGG. We compare the performance of
these approaches with two benchmark datasets: LFW and YTF (ref. Section 2.2). Both datasets
provide pairs of matching and non-matching faces useful to assess face recognition methods. The
results are presented in Table 1, depicting the accuracy of the pairwise match/mismatch between
subject pairs in a 10-fold cross-validation. As Facenet performs best on both datasets, and even
outperforms humans, we choose it for CATANA’s face detection and face recognition functionalities.

Frame Extraction and Selection

Typically, face recognition approaches are designed for images, not for video. Due to the large
number of frames per second with usually small changes, it is not efficient to process every frame.
Instead, we use a duration-based frame extraction rate f (n, r) taking the number of frames n in the
video and its frame rate r as inputs to reduce the number of images to process. We extract evenly
spaced frames with a usual rate of 10 frames per minute. For short video, we adapt the rate to extract
at least fmin = 600 frames which shows a good performance. For long videos, the number of frames
extracted is limited for storage reasons to fmax=8,000. One might argue that the frame extraction
approach used is quite simple and could benefit, e.g., from shot boundary detection or face tracking.
Therefore, we additionally tested a sophisticated approach, that does not analyze individual frames
but face tracks, i.e., the face is detected once and followed through the subsequent frames. Therefore,
we used Pyannote-Video6 as a framework to consider a face tracking approach as well in our design.
This framework is based on the face recognition framework Openface [2] and implements shot
boundary detection, face track extraction, and clustering via hierarchical agglomerative clustering.

6https://github.com/pyannote/pyannote-video [Accessed: 2018-05-08]

7/28

3.2 YouTuber Identification

In the previous section, we discussed how a set of face images per video is obtained using Facenet.
In a following step, we use clustering to create an association between images and people. In the
case of face tracks, these are already grouped per individual. However, due to shot boundaries, i.e.,
scene or camera switches, multiple face tracks per individual may exist.

In a next step, we evaluate five different clustering approaches: Pyannote-video in two con-
figurations, DBSCAN, HDBSCAN, and agglomerative clustering (AGG). Pyannote-video can
be configured with different frame extraction and face detection rates. Therefore, two settings
are chosen: C1: Every frame is used for face tracking and 1 frame per second is used for face
recognition. C2: Only 1 frame per second is extracted as well as used for face recognition. To assess
the performance, we evaluate metrics for error rate, number of not clustered images, number of
clusters found, and the clustering runtime.

Figure 2 depicts the evaluation results of the approaches based on the clustering error and number
of not clustered face images. In Figure 3, we show the evaluation results based on the number of
identified clusters and the clustering runtime. We can see that Pyannote-Video C1 has a high number
of erroneously clustered face images. Furthermore, clustering run-time is multiple times higher for
C1 than the video duration, and also multiple times higher than required by the other approaches.
The second configuration C2 performs better than C1, but still worse than the other approaches
regarding clustering errors and clustering runtime. Comparing the two similar approaches DBSCAN
and HDBSCAN a difference in noise handling, measured by the number of not clustered face images
can be noticed. DBSCAN identifies more images as noise than HDBSCAN and all other approaches.
The number of found clusters fits for both density-based approaches: DBSCAN and HDBSCAN,
being close to the optimal number. The major advantage of both density-based approaches, i.e.,
DBSCAN and HDBSCAN over the other approaches is that no estimation of the number of cluster
must be given. Finally, we conclude that both DBSCAN and HDBSCAN perform best amongst the
evaluated techniques. The face tracking approach, while promising in theory, did not perform well.
As the number of not clustered face images suggests, DBSCAN handles noise more conservative
than HDBSCAN, resulting in possible useful images being discarded. A significant advantage of
HDBSCAN over DBSCAN, besides handling varying cluster density, is that it returns probabilities
describing the strength of membership for every face image. This information can be leveraged
to further filter outliers and improve the clustering results. For these reasons we decided to use
HDBSCAN for clustering the face images.

While evaluating the performance measures above, we noticed non-compliant behavior of
HDBSCAN for class one videos, especially in which no other (external) actor appeared. HDBSCAN
thereby fails to create a single cluster and labels all data as noise. This observed effect is due to the
hierarchical approach and it could not be improved through parameter modification. As DBSCAN
performs well on a single cluster case, we use DBSCAN as a fallback solution, coming into effect
when HDBSCAN fails to detect a single cluster.

An alternative approach to clustering is classification. However, this approach was discarded,
as it does not fit our requirement that the face recognition technique should be able to distinguish

8/28

Figure 2: (Left) Number of clustering errors. (Right) Number of not clustered face images.

Figure 3: (Left) Number of clusters found compared to reference (optimal). (Right) clustering
run-time comparison.

between individuals without prior training data. For the sake of completeness, we will give a
brief overview of this alternative approach. Through classification, it is possible to assign detected
faces to known individuals. The problem with this approach in our setting is that training data
is needed for classification. As we have channel information, which is analyzed beforehand, we
could acquire training images through, for example, Google image search. The drawback with
this approach is that the number of content creators per channel is unknown. Thus, the automatic
retrieval of correct training data for multiple persons through image search is not viable. Furthermore,
appearing individuals that are not related to any analyzed channel would not be recognized. For these
reasons, the previously described clustering approach is utilized, incorporating both, HDBSCAN
and DBSCAN.

9/28

3.3 Collaboration Detection

We define a collaboration as the co-occurrence of a YouTuber from a different channel in a YouTu-
ber’s video, e.g., in a video showing both YouTubers or playing a (potentially) prerecorded clip of
the featured YouTuber. To identify collaborations, we build connections between videos using the
previously derived face clusters. Single videos may have multiple face clusters, i.e., at least one
per detected individual. Therefore, we compute a similarity matrix between face clusters using the
Euclidean distance as a similarity measure. In a next step, the similarity matrix is taken as an input
for HDBSCAN clustering which groups all face clusters of individual persons based on the similarity
measure. This gives us face cluster-wise connections showing that the same person appeared in all
connected videos. This information allows the investigation of collaborations between different
channels.

Although we can now connect the appearing individuals, we do not know yet which of the
persons is a content creator, i.e., owner of the channel, or an external actor appearing. To determine
the content creator of a channel, we can select the face cluster with the highest number of appearances
on the channel. However, this approach would be unable to assign multiple content creators to a
single channel. As do not want to restrict this method to single content creator channels and we
assume that some portion of the available channels already have multiple content creator, we use
the following approach. To decide if an individual is a content creator, we leverage the number of
appearances per individual and channel. In detail, a person may have appeared in different channels,
we assign the person as a content creator for the channel with the highest number of appearances.
Thereby, a channel with one or multiple content creators can be correctly detected.

Figure 4: Sample graph of PewDiePie’s YouTube channel and 1-hop neighbors7

10/28

Table 2: Overview of the available crawler tools, ∗are outdated

Scrapy

YTCrawl YOUStatAnalyzer HarVis

ytdata∗

TubeKit∗

Customizable
Documentation
Storage
API usage
Language

Highly
Extensive
Customizable
Yes
Python

limited
sparse
File
No
Python

limited
sparse
MongoDB
Yes
Python

limited
sparse
SQL
Yes
Java

limited
sparse

limited
sparse
SQLite MySQL
Yes
Python

Yes
PHP

Collaboration Graph

Inspired by [5, 17], the collaborations between channels are modeled as a graph with channels as
nodes and collaborations as directed edges connecting the nodes. The edge direction describes
that a content creator of the origin channel appeared, i.e., collaborated, in one or more videos of
the destination channel. Figure 4 depicts an example graph showing one the world’s most popular
YouTubers: PewDiePie. The edge label denotes how often collaborations between the two channels
were observed. We use a graph to visualize and model the collaborations as we can apply different
graph algorithms to analyze the underlying channel relations.

4 YouTube Statistics Data Acquisition

In the following, we briefly describe how we crawl the required information from YouTube and
specify how we select appropriate YouTube channels for crawling our dataset.

4.1 YouTube Data Crawling

To assess the effect of YouTuber collaborations, we need to acquire channel metadata such as
the subscriber count and video view counts. Additionally, we also want to acquire the video and
channel metadata, such as video titles, video and channel descriptions, and the channels’ featured
channel list. The crawled data is not filtered by a specific video topic but through a seed set of
YouTube channels and their uploaded videos. Under those requirements most of the existing tools
such as YTCrawl8, YOUStatAnalyzer9, or HarVis10 cannot be leveraged for our purpose without
significant code changes. Customizing the frameworks requires a solid documentation, which most
of the tools do not provide or only in sparse form. To this end, we decide to develop a YouTube

7Channel images taken from https://www.youtube.com/{PewDiePie, chadwildclay, channel/UCEYLdM2bdhmw-
TS3c0TjFNw, KickThePj, TheBigManTyrone, MrMccruddenmichael, user/LandonProduction, HerrNewstime,
iwantmylauren, iOTrendz, channel/UCIq3bpW-MaAzj4Y2G9ezPhA, channel/UCBINYCmwE29fBXCpUI8DgTA,
channel/UCm3GpkVRonpt2BHrt3GhwjQ,
channel/UCZA-
comicbookresources,
pDB9BW7ZjNcPb3Wu7rRg, imsannachanel, TokyoAtomic, CutiePieMarzia}

JoeCroninSHOW,

8https://github.com/yuhonglin/YTCrawl [Accessed: 2018-05-08]
9https://github.com/mattiazeni/youstatanalyzer [Accessed: 2018-05-08]
10https://github.com/DrUzair/HarVis [Accessed: 2018-05-08]

11/28

data crawling tool based on the Scrapy11 framework which is highly customizable and provides
extensive documentation, that allows to implement all requirements of our envisioned crawler in
reasonable time and with a comparable small effort. Scrapy is widely used and has a big open source
community. Table 2 shows a qualitative comparison of the considered YouTube data crawling tools,
including Scrappy.

Figure 5: Populate spider architecture, d is the user-defined maximum depth for channel recursion.

Next, we describe the design of the Scrapy-based crawling architecture. As we distinguish
between continuous and static data, we implemented two spiders, i.e., crawling modules in Scrapy.
The first spider, which we denote as Populate Spider, crawls static data and populates a database
with channel and video entries, e.g., the video and the channel name. Figure 5 illustrates the crawling
process. The populate spider takes an initial set of channel IDs for which it requests all static data
and subsequently creates a database entry for every crawled channel. Note that for fixed set of
channels d is set to zero to hinder Scrapy from adding additional channels to the set.

In the next step, a second spider denoted Daily Spider crawls continuous data created by the
channels and videos already known in a daily manner, i.e., view count and subscriber count. Here,
each channel’s Upload Playlist is crawled, which contains the videos uploaded by a channel to
identify newly uploaded videos. Crawling the popularity statistics for all videos uploaded on the
given channels allows constructing time series of popularity statistics. We record all interactions
on the monitored channels such as view, comment, and subscriber counts in the time span between
28.12.2016 and 28.03.2017 on a daily basis.

11https://scrapy.org [Accessed: 2018-05-08]

12/28

Figure 6: Daily spider architecture.

4.2 Data Selection and Representation

The Populate Spider needs an initial set of YouTube channel IDs. To create a qualitative and large
dataset of channels, we crawl three of the most popular MCNs [14] as channels associated to a
MCN have higher chances to collaborate [4]. These MCNs are described in table 3. We used
the website SocialBlade12 to derive the mapping of channels to MCN member lists. Here, we
take a random sample of 1.5 × 103 channels for every MCN in which the 100 channels with most
subscribers per MCN are included. In a next step, we use the so called Featured Channel List
of the crawled channels, which contains other channels defined by the channel owner to express
an acquaintanceship between his and other channels. This relationship is modeled in a graph
representation as described in section 3.3, containing roughly 44k channels. Here, channels are
represented by nodes, while the featured channel list comprises unidirectional edges from one node
to other nodes. Finally, non-mutual edges between channels are removed, while mutual edges,
i.e., nodes having each other in their Featured Channel List, are considered likely to collaborate
and, hence, are kept. We also excluded Gaming videos as we observed a lack of face presence in
these videos and, furthermore, often high resolution game figures depicted on covers or within the

12https://socialblade.com/youtube/top/networks/most-subscribed [Accessed: 2018-05-08]

Table 3: Most popular YouTube MCNs worldwide, measured by number of subscribers.

Name

Members

Subscribers (over 30 days) Views (over 30 days)

BroadbandTV
Studio71
Maker Studios

237,235
13,194
9,460

82,718,601
18,535,751
14,011,532

20,107,687,476
5,402,265,290
4,613,091,2598

13/28

videos would have led to increases imprecision. From the remaining subgraph, we extract the largest
connected component, resulting in a graph with roughly 8k nodes and about 10k edges indicating
potential collaborations. By applying CATANA to this subgraph, i.e., analyzing 2.4 years of video
uploaded on these channels for a period of three months, we identified 1,599 nodes and 1,728 edges
representing actual collaborations. The edge sum, which corresponds to the overall number of
collaborations sums up to 3,925, see Table 4.

Table 4: Collaborations observed in the three month’s time span.

Collaborations Duration Mean Median

75-percentile Max

3,925

3 months

2.8

1.0

3.0

134

5 Evaluation

In this section, we formulate and answer research questions with respect to the focus points
of: (i) collaboration frequency and partner selectivity (Section 5.1), (ii) the influence of multi-
channel networks (MCNs) on channel collaborations (Section 5.2), (iii) collaborating channel types
(Section 5.3), and (iv) the impact of collaborations on video and channel popularity (Section 5.4).

5.1 How often do collaborations happen and reoccur with the same partner?

(a) Number of pair-wise collaborations

(b) Number of collaborations per channel

Figure 7: Histograms of detected collaborations per channel pairs (a) and per channel (b)

Using the collaboration graphs, we can easily determine the overall number of collaborations by
summing up the edge weights between two YouTube channels. Analyzing the edge weights allows
us to examine the number of repeated collaborations. Table 4 depicts the derived collaboration
statistics where we observe that the distribution is skewed to the right, indicating the presence

14/28

of a few channel pairs with a comparably high number of collaborations. We confirm this by
drawing the histogram of the collaboration counts in Figure 7a, showing the distribution of repeated
collaborations between two YouTubers who have collaborated at least one. We deduce that over a
3-months observation period collaborations between two channels rarely happen more than once.
In a next step, we analyze the number of collaborations per channel instead of distinct channel
pairs. Therefore, we sum up the edge weights for every channel node. Taking the perspective of a
channel, we differentiate between collaborations taking place in own videos (internal) and videos of
other channels (external). If a collaboration between YouTuber A and B occurs on YouTuber A’s
channel, it is considered as an internal collaboration by A and as an external collaboration by B.
This distinction helps us later to detail the effects on both sides of a collaboration. Figure 7b shows
the corresponding distributions. We conclude that a small number of highly collaborating channels
denoted central channels exists, with most of the remaining channels having very few collaborations.
Thus, central channels show a high in-degree, demonstrating a key influencer role on YouTube.
These YouTubers are especially valuable for product placements, advertisements, and, hence, are
especially valuable assets for their MCNs. One weakness of the former analysis is that it compares
results based on the absolute number of collaborations. Thus, we investigate the relative ratio of a
YouTuber’s collaborations compared to the overall number of the channel uploads. Given the number
of internal collaborations of a channel k, denoting collaborations only occurring in its own videos,
and the number of videos of the channel n, we calculate the collaboration ratio as k/n. Figure 8a
shows the distribution of the collaboration ratio. Values around one imply that in nearly every video
of the channel, a collaboration is found. This may indicate that certain content creators regularly
work together, or share a common channel while also operating separate channels alone. Values
larger than one can occur if multiple collaborations were detected in a single video. In Figure 8b,
we observe only a few outliers with a ratio above one, while most of the channels have a ratio close
to zero. This indicates that a large portion of channels have only a single ingoing collaboration.
Summarizing our finding with respect to collaboration frequency we observe that a single channel
collaborates with other channels on average 2.8 times ([2.5 − 3.15] at a 99% confidence level). If

(a) Collaborations per uploaded videos

(b) Channel collaborations

Figure 8: Collaboration/Video ratio and separated in- and outgoing collaborations.

15/28

channels collaborate, we find in our 3-month dataset that they repeat their collaboration on average
2.3 times ([2.0 − 2.6] at a 99% confidence level). Overall, the distributions for collaboration metrics
are skewed as a consequence of a few highly influential YouTubers.

5.2 How do multi-channel networks (MCNs) influence channel collaborations?

To answer this question, we first analyze which collaborations take place between MCNs. To this end,
we first determine the respective MCN for each channel using publicly available information13 to
augment the channel information of our collaboration graph. Figure 9 depicts the most collaborating
MCNs in form of a MCN-collaboration matrix. Overall, we found 405 MCN pairs collaborating
with each other. Note that the entry None refers to channels for which we could not determine a
MCN association.

Figure 9: Absolute number of collaborations within and between MCNs.

13https://socialblade.com/ [Accessed: 2018-05-08]

16/28

Figure 10: Internal and external MCN collaborations.

Examining the diagonal of the matrix in Figure 9 we observe a distinct trend showing that most
collaborations occur within MCNs, and thus between their members. Further, we observe that
significant collaborations between networks are mainly confined to the three dominant networks,
namely, BroadbandTV, Studio71, and Maker Studios. We find many collaborations of unassociated
channels, i.e., with the label None, with the three dominant networks, which we attribute to the fact
that they are the world’s three largest MCNs and, hence, have YouTube channels associated which
are popular and an attractive target for collaboration. Furthermore, famous YouTubers are a popular
topic for other YouTuber’s that may show the popular YouTuber’s face or video sequences. We
deduce that belonging to a MCN strongly increases the probability of a YouTuber to collaborate.

Figure 10 shows the percentage share of collaborations separated by MCN in- and external
collaborations. Here, we observe that the three largest MCNs, i.e., BroadbandTV, Studio71, and
Maker Studios as well as PranksNetwork have much more internal collaborations compared with
the smaller MCNs. Hence, their YouTubers collaborate more in their own videos than on the
videos of other MCN’s YouTubers. Note that a large portion of the outgoing collaborations is with
channels that are not associated with a MCN. Channels not belonging to a MCN show a preference
to work with MCN-associated channels as more than 70 percent of their collaborations are outgoing.
We conclude that an influence of MCNs concerning YouTuber collaborations can be inferred. In
summary, we find that channels associated with a MCN collaborate more often with each other and
if collaborations occur outside the MCN, then they are usually with non-associated channels and
rarely with other MCNs’ YouTubers.

17/28

Table 5: Popularity class definitions and their number of observed channels.

Popularity Class

Subscriber Range

#Channels

0
1
2
3
4
5
6

[0, 103)
[103, 104)
[104, 105)
[105, 106)
[106, 107)
[107, 5x107)
[5x107, 108)

813
1,575
2,569
2,420
544
20
1

5.3 Which channel types collaborate?

In the following, we group YouTube channels with respect to popularity and content category. First,
we assign each channel to one out of seven popularity classes, based on their subscriber count. Here,
the chosen classes resemble the classes used for the YouTube awards14, which are awards shipped
to the YouTubers when they exceed a certain number of subscribers. Next, we analyze collaboration
behavior regarding the YouTube video category, a label which the YouTuber can select out of a set
of given categories during the video upload process.

YouTube Popularity Classes We assign a channel’s popularity class with respect to the number
of subscribers as depicted in Table 5. In column #Channels, the table shows also the number of
YouTube channels in our dataset which belong to the corresponding popularity class. We can see
that the major share of the channels observed belong to popularity class 1, 2, or 3. Class 6 is an
exception, as it only contains a single channel, i.e., PewDiePie, the most successful YouTuber in
terms of subscribers so far. Figure 11a depicts the share of observed channel collaborations between
popularity classes. Here, channels belonging to a numerically higher class have more subscribers
than channels belonging to numerically smaller classes. The matrix entry atf of row f and column
t denotes that the number of YouTubers from a channel of popularity class f appear in videos
belonging to channels of popularity class t. We can see that most collaborations happen within
class 3 and neighboring classes 2 and 4, which we ascribe to two factors. First, these channels
have reached a popularity in the YouTube environment that attracts collaborations. Second, these
channels do not yet belong to the most popular channels, i.e., categories 4, 5, and 6 but are likely to
try to increase their own popularity by attracting more viewers through collaborations with other
YouTubers.

YouTube Categories
In Figure 11b we show the share of collaborations between YouTube cate-
gories. Most collaborations are detected in, and between the Entertainment and People & Blogs
categories, which is reasonable as they prevalently contain human presence and interaction. The
same applies for categories like Comedy. In the figure, we observe asymmetric relations, e.g.,

14https://www.youtube.com/yt/creators/rewards.html [Accessed: 2018-05-08]

18/28

(a) Popularity classes.

(b) Video categories.

Figure 11: Collaborations within & between popularity classes and YouTube video categories (in
%).

between Comedy and Film & Animation, that collaborate more in with Entertainment channels than
within the same category. For collaborations within a category, i.e., the diagonal of the heat map, we
only notice a surge for Entertainment. We observe that the most frequent collaborations occurred
within the category Entertainment, which also shows the second most video uploads. Note that
Entertainment is a rather generic term and can therefore, depending on the YouTuber’s interpretation,
also include comedy, film, and animation related content.

5.4 How do collaborations impact video and channel popularity?

We investigate the two parts of this question separately, focusing, first, on the observed effects on
video popularity and, second, on channel popularity. Therefore, we use popularity statistics of a
3-months period for roughly 105 videos, considering videos for which we have at least 12 daily
popularity measurements, i.e, videos being older than 12 days. We chose 12 days as we observed
that most older videos do not receive much more views. Using CATANA, we deduce a collaboration
graph with roughly 104 edges indicating collaborations within the observed 8 × 103 channels. Using
two sets for collaboration and non-collaboration videos, we analyze the maximum values of view
and subscriber counts of the 12-days time-span and their gradient. The benefit of these gradients is
that they are not biased by absolute numbers but represent the relative popularity growth.

19/28

Figure 12: Number of views after 12 days for collab. (green) and non-collab. (blue) videos.

5.4.1 Video Popularity

First, we examine the maximum video view counts observed in the first 12 days. Figure 12 shows
the video view count distribution. By examining the left side of the figure, we see in the box plot that
the average view count is higher for videos with a collaboration compared with non-collaborations.
Note that the median is stretched nearly doubled (from about 26k to 45k views) for the cases of
present collaborations. Although the median is only slightly higher in case of a collaboration, the
upper 50% of video views are more scattered and show more views. Additionally, we plotted the
average view counts for both cases and their 95% confidence intervals on the right side of Figure 12
where we see a large gap. The figure suggests that a significantly higher view count can be expected
if a video contains a collaboration.

The generally higher popularity of collaboration videos can be reasoned in the generally higher
popularity of collaborating channels. As we previously examined, class 3 channels collaborate
more often than channels of lower popularity classes. If we therefore assume that more videos
with collaborations are uploaded by class 3 channels, the videos consequently tend to a higher
popularity compared for example with class 2 videos. To further substantiate this effect, we evaluate
the gradient and growth of the video view counts. Hence, we calculate the average view growth
factor between non-collaboration and collaboration videos. For this, we use the average maximal

Figure 13: View count growth factor between collaboration and non-collaborations videos. A
positive value indicates the superiority of collaborations.

20/28

Table 6: View growth of collaborations compared to non-collaborations.

Channels Duration Mean Median

75-percentile Min Max

1116

3 months

34.32

-6.73

32.47

-99.70

6,376.28

Figure 14: Video view count growth for the first five days of a collaboration vs. the
non-collaboration view growth on the first day.

12 day view value for every channel, differentiated by collaboration and non-collaboration. Next,
the percentaged growth from the non-collaboration value to the collaboration value is calculated
channel-wise. Figure 13 displays these results. As only channel with both collaboration and non-
collaboration data could be used for the percentaged growth calculation, samples of 1,116 channels
are used. The difference in number of channels is due to channel which only collaborate in external
videos, and do not host collaboration in their own. Statistics on the differences between the two
video groups on the video view growth are shown in table 6. In a next step, we investigate the
distributions of these view count differences depicted in Figure 13. Here, the 0.95 confidence interval
is between 19% and 51%, indicating that a significant growth of the views between collaboration
and non-collaboration videos can be expected.

Next, we compute the gradients between each pair of the 12 days of the videos’ view counts,
resulting in 11 gradient values. Additionally, we calculate the percentaged growth between these
values. The percentaged growth of the first 6 days after a collaboration vs. non-collaboration view
growth on the first day is depicted by Figure 14. This figure shows the longer lasting temporal
impact of collaborations. Further, Figure 15 shows the box and bar plots of the gradient values, i.e.
the absolute view count increase, using a 0.99 confidence level.

21/28

Figure 15: Video view count gradient.

Figure 16: Channel subscriber gradient and percentaged growth.

5.4.2 Channel Popularity

Here, we cannot directly differentiate between collaboration and non-collaboration channels as for
videos, since one channel may contain both, collaboration and non-collaboration videos. Therefore,
we filter channels, which uploaded videos with and without collaborations, resulting in 1,599
channels. The channel popularity is measured by the number of views of its videos and the number
of channel subscribers. We define a window of two days after a collaboration, for which we will
classify the subscriber counts as belonging to a collaboration, the remaining statistics measured
are classified as belonging to non-collaboration. Thereby, we gathered 9,086 channel subscriber
measurements for collaborations, and 78,877 for non-collaborations. Figure 16 shows the subscriber
count differentiated between collaborations and non-collaborations. From the figure we conclude
that collaborations have a slight positive effect on channel subscribers. Compared to the increase of
viewers, the increase of subscribers is only about one tenth of total users. Though, the relative growth
compared to non-collaborating video measures is about 30% larger in terms of newly attracted
subscribers compared with the newly attracted viewers.

In addition to the above evaluation of the two-day collaboration window, we evaluate a 6-day
window on a daily basis. Figure 17a shows the percentaged subscriber growth over 6 days starting
with day 0, which is the upload date of the collaboration video. Figure 17b depicts the percentaged
subscriber growth for each day and on the left side and the respective overall channel view growth

22/28

(a) Channel subscriber count growth.

(b) Channel view count growth.

Figure 17: Effect of collaboration over the first six days.

Figure 18: Subscriber growth for collaborations between YouTube channel categories.

on the right side. On both sides, also the growth of non-collaboration videos after day 0 is shown
to allow for a comparison. We note that the highest subscriber growth can be observed for days 0
and 1 with the growth slowly decreasing to approach the base line describing non-collaborations.
In addition to the channel subscriber growth, we apply the same evaluation methodology for the
overall channel views, an alternative measure of channel popularity. Here, we expect a similar
pattern as for the channel subscriber counts but we observe a very different pattern, depicted in
Figure 17b. For day zero and one, the view growth is quite low and close to non-collaboration
videos. In contrast to that, for day 2, we observe a significant increase. Despite the fact that more
people watch collaboration videos on day two, we found that users seem to be less engaged as for
day 2 overall less subscriptions are observed than for days 0 and 1.

23/28

Figure 19: View count growth for collaborations between YouTube channel categories.

5.5

Impact of Video Popularity Classes and Video Categories

YouTube Categories Figure 18 and 19 show the impact of a collaboration of YouTubers belonging
to different video categories and popularity classes. We observe that view and subscriber counts vary
strongly amongst different channels. Hence, we compute the relative popularity growth for videos
with and without collaborations. Here, we took only popularity measurements if a collaboration
video was uploaded and at the same day no other video was uploaded to guarantee that the channel
popularity measure is not impaired. In case different categories collaborate, we show the effects
for both categories separately. For all collaborations taking place between YouTubers uploading
mostly videos of the same category, a significant increase of subscriber and view count is observed.
Here, the category People & Blogs is an exception, as on average more subscribers can be attracted
by a collaboration but less video viewers. This is still beneficial as the subscribers are potentially
watching all videos uploaded by the YouTubers in the future.

YouTube Popularity Classes
In Figure 20 and 21 the impact of collaborations between channels
of different popularity classes is shown. In general, we observe a significant benefit of collaborations.
Note that lower popularity classes, especially class 1 and 2 YouTubers benefit significantly stronger
than higher popularity classes. It can be seen that for classes 3 and 4, the gain of a collaboration is
comparably low and often there is no significant difference. For class 4 YouTubers, no effect of
collaborations can be observed. Hence, we deduce that especially for YouTubers with less than 105
subscribers, i.e., class 1 or 2, collaborations significantly increase the number of views.

24/28

Figure 20: Subscriber growth for collaborations between channel popularity classes. The x-axis
denotes the depicted popularity class in the constellation depicted in brackets, e.g., (1 in 3) means
that a YouTuber of popularity class 1 appeared in a video published on a popularity class 3 channel.

Figure 21: View count growth for collaborations between YouTube channel popularity classes.

Concluding our popularity evaluation for videos and channels under collaborations, we state we
observe that collaborations have positive effects on video views and on engaging new subscribers.
Especially for YouTubers of low popularity classes such as class 1, a collaboration can add about
100% additional views and new channel subscribers. Concerning the impact on video views, we
calculated a percentaged growth through collaborations with a mean between 19% and 51% with
0.99 confidence. Also channels popularity is significantly increased through collaborations, i.e., for
both considered metrics, namely channel subscribers and total channel views.

25/28

6 Conclusion and Future Work

In this article, we first designed and implemented a system for the acquisition and analysis of
collaboration data in user generated content at the example of YouTube. We implemented a video-
based face recognition system named CATANA for which we examined and evaluated different face
recognition and clustering techniques. We applied CATANA to a collected dataset of videos over a
3-month period where we extracted appearing content creators and leveraged this information to
detect collaborations between channels.

We observed that out of 7,492 channels in our dataset 1,599 collaborated, with an average of
2.8 times per channel. Regarding the types of channels, which collaborate we found that channels
with a subscriber count between 105 - 106 collaborate the most and the Entertainment YouTube
category shows most collaborations. Furthermore, we inferred that multi-channel networks generally
exhibit collaborations within the same network or channels, which are not associated with any other,
potentially competing, network. We analyzed the acquired popularity statistics for both videos
and channels and found significant differences between collaboration and non-collaboration sets,
indicating a positive effect on the popularity that is measured by subscriber and view counts. In
this work we proposed a viable method for collaboration detection in user generated content that is
based on face recognition. A potential limitation of the proposed system is the differentiation with
respect to the collaboration context, which can be mapped to different types of face appearances, i.e.
posters or content usage. In future work, using voice recognition in addition to face recognition is
likely to increase detection rates as well as differentiate collaboration context.

Reproducibility

To enable other researchers to use, reproduce, and extend our research, we release our tool chain
at https://github.com/christiannkoch/CATANA. This contains: (i) the CATANA
framework and evaluation scripts used here, (ii) the 3-months collaboration graph used in this paper,
and (iii) an interactive web-based visualization of the collaboration graph.

Acknowledgements

This work has been funded in parts by the DFG as part of the Collaborative Research Centre 1053
MAKI (C3, B4).

26/28

References

[1] T. Ahonen, A. Hadid, and M. Pietikainen. Face Description with Local Binary Patterns:
IEEE Transactions on Pattern Analysis and Machine

Application to Face Recognition.
Intelligence, 28, 2006.

[2] B. Amos, B. Ludwiczuk, and M. Satyanarayanan. OpenFace: A general-purpose Face
Recognition Library with Mobile Applications. Technical report, CMU-CS-16-118, CMU
School of Computer Science, 2016.

[3] B. Gahan. How to be successful on YouTube: The 3 steps. http://thenextweb.com/
insider/2015/03/04/the-3-steps-to-success-on-youtube/, 2015. [Ac-
cessed: 2018-05-08].

[4] M. Gielen. Best Practices For A YouTube Multi-Channel Network 2.0. http://www.
tubefilter.com/2015/03/24/youtube-mcn-multi-channel-network/,
2015. [Accessed: 2018-05-08].

YouTube Universum. Die Vernetzung

[5] B. Gugel.
sualisiert.
youtube-universum-die-vernetzung-der-youtuber-visualisiert.
html, 2015. [Accessed: 2018-05-08].

vi-
http://www.gugelproductions.de/blog/2015/

der YouTuber

[6] Y. Guo, L. Zhang, Y. Hu, X. He, and J. Gao. Ms-celeb-1m: A Dataset and Benchmark for
large-scale Face Recognition. In European Conference on Computer Vision, pages 87–102.
Springer, 2016.

[7] M. Holmbom. The YouTuber A Qualitative Study of Popular Content Creators. Bachelor

thesis, Umea University, 2015.

[8] G. B. Huang, M. Ramesh, T. Berg, and E. Learned-Miller. Labeled Faces in the Wild: A
Database for Studying Face Recognition in Unconstrained Environments. Technical report,
University of Massachusetts, Amherst, 2007.

[9] E. Learned-Miller, G. B. Huang, A. R. Chowdhury, H. Li, and G. Hua. Labeled Faces in the
Wild Website. http://vis-www.cs.umass.edu/lfw/. [Accessed: 2018-05-08].

[10] E. Learned-Miller, G. B. Huang, A. RoyChowdhury, H. Li, and G. Hua. Labeled Faces in the
Wild: A Survey. In Advances in Face Detection and Facial Image Analysis, pages 189–248.
Springer, 2016.

[11] O. M. Parkhi, A. Vedaldi, and A. Zisserman. Deep Face Recognition. In Proceedings of the

British Machine Vision Conference (BMVC), 2015.

27/28

[12] D. Sandberg. Facenet Project Repository. https://github.com/davidsandberg/

facenet. [Accessed: 2018-05-08].

[13] F. Schroff, D. Kalenichenko, and J. Philbin. FaceNet : A Unified Embedding for Face
Recognition and Clustering. In IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), 2015.

[14] Social Blade LLC. SocialBlade Network Statistics. https://socialblade.com/

youtube/top/networks. [Accessed: 2018-05-08].

[15] M. Turk and A. Pentland. Eigenfaces for recognition. volume 3, pages 71–86. MIT Press,

1991.

Face Recognition. 2016.

[16] Y. Wen, K. Zhang, Z. Li, and Y. Qiao. A Discriminative Feature Learning Approach for Deep

[17] C. Wilson, B. Boe, A. Sala, K. P. N. Puttaswamy, and B. Y. Zhao. User Interactions in
Social Networks and Their Implications. In ACM European Conference on Computer Systems,
EuroSys’09, 2009.

[18] L. Wolf, T. Hassner, and I. Maoz. Face Recognition in Unconstrained Videos with Matched
Background Similarity. In IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), 2011.

[19] YouTube, LLC. Youtube Creator Academy: Collaboration. https://creatoracademy.

youtube.com/page/lesson/collaboration. [Accessed: 2018-05-08].

[20] YouTube, LLC. YouTube Statistics.

https://www.youtube.com/yt/press/

statistics.html. [Accessed: 2018-05-08].

[21] K. Zhang, Z. Zhang, Z. Li, and Y. Qiao. MTCNN Face Detection. https://kpzhang93.
[Accessed:

github.io/MTCNN_face_detection_alignment/index.html.
2018-05-08].

28/28

