Measuring Thematic Fit with Distributional Feature Overlap

Enrico Santus1, Emmanuele Chersoni2, Alessandro Lenci3 and Philippe Blache2
enrico santus@sutd.edu.sg
emmanuelechersoni@gmail.com
alessandro.lenci@unipi.it
philippe.blache@univ-amu.fr
1 Singapore University of Technology and Design
2 Aix-Marseille University
3 University of Pisa

Abstract

In this paper, we introduce a new distri-
butional method for modeling predicate-
argument thematic ﬁt judgments. We use
a syntax-based DSM to build a prototyp-
ical representation of verb-speciﬁc roles:
for every verb, we extract the most salient
second order contexts for each of its roles
the most salient dimensions of typi-
(i.e.
cal role ﬁllers), and then we compute the-
matic ﬁt as a weighted overlap between
the top features of candidate ﬁllers and
role prototypes. Our experiments show
that our method consistently outperforms
a baseline re-implementing a state-of-the-
art system, and achieves better or compa-
rable results to those reported in the liter-
ature for the other unsupervised systems.
Moreover, it provides an explicit represen-
tation of the features characterizing verb-
speciﬁc semantic roles.

1

Introduction

Several psycholinguistic studies in the last two
decades have brought extensive evidence that hu-
mans activate a rich array of event knowledge dur-
ing sentence processing: verbs (e.g. arrest) ac-
tivate expectations about their typical arguments
(e.g. cop, thief ) (McRae et al., 1998; Altmann and
Kamide, 1999; Ferretti et al., 2001; McRae et al.,
2005; Hare et al., 2009; Matsuki et al., 2011), and
nouns activate other nouns typically co-occurring
in the same events (Kamide et al., 2003; Bick-
nell et al., 2010). Subjects are able to determine
the plausibility of a noun for a given argument
role and quickly use this knowledge to anticipate
upcoming linguistic input (McRae and Matsuki,
2009). This phenomenon is referred to in the lit-
erature as thematic ﬁt. Thematic ﬁt estimation

has been extensively used in sentence comprehen-
sion studies on constraint-based models, mainly as
a predictor variable allowing to disambiguate be-
tween possible structural analyses.1 More in gen-
eral, thematic ﬁt is considered as a key factor in a
variety of studies concerned with structural ambi-
guity (Vandekerckhove et al., 2009).

Starting from the work of Erk et al. (2010),
several distributional semantic methods have been
proposed to compute the extent to which nouns
fulﬁll the requirements of verb-speciﬁc thematic
roles, and their performances have been evaluated
against human-generated judgments (Baroni and
Lenci, 2010; Lenci, 2011; Sayeed and Demberg,
2014; Sayeed et al., 2015, 2016; Greenberg et al.,
2015a,b). Most research on thematic ﬁt estima-
tion has focused on count-based vector representa-
tions (as distinguished from prediction-based vec-
tors).2 Indeed, in their comparison between high-
dimensional explicit vectors and low-dimensional
neural embeddings, Baroni et al. (2014) found that
thematic ﬁt estimation is the only benchmark on
which prediction models are lagging behind state-
of-the-art performance. This is consistent with
Sayeed et al. (2016)’s observation that “thematic
ﬁt modeling is particularly sensitive to linguistic
detail and interpretability of the vector space”.

The present work sets itself among the un-
supervised approaches to thematic ﬁt estima-
tion. By relying on explicit and interpretable
count-based vector representations, we propose
a simple, cognitively-inspired, and efﬁcient the-
matic ﬁt model using information extracted from
dependency-parsed corpora. The key features of
our proposal are a) prototypical representations
of verb-speciﬁc thematic roles, based on feature
weighting and ﬁltering of second order contexts

1For an overview on constraint-based models, see Mac-

Donald and Seidenberg (2006).

2We adopt the terminology from Baroni et al. (2014).

7
1
0
2
 
l
u
J
 
6
2
 
 
]
L
C
.
s
c
[
 
 
2
v
7
6
9
5
0
.
7
0
7
1
:
v
i
X
r
a

(i.e. contexts that are salient for many of the typ-
ical ﬁllers of a given verb-speciﬁc thematic role),
and b) a similarity measure which computes the
Weighted Overlap (W O) between prototypes and
candidate ﬁllers.3

2 Related Work

Erk et al. (2010) were, at the best of our knowl-
edge, the ﬁrst authors to measure the correlation
between human-elicited thematic ﬁt ratings and
the scores assigned by a syntax-based Distribu-
tional Semantic Model (DSM). More speciﬁcally,
their gold standard consisted of the human judg-
ments collected by McRae et al. (1998) and Pad´o
(2007). The plausibility of each verb-ﬁller pair
was computed as the similarity between new can-
didate nouns and previously attested exemplars for
each speciﬁc verb-role pairing (as already pro-
posed in Erk (2007)).

Baroni and Lenci (2010) evaluated their Dis-
tributional Memory (henceforth DM)4 framework
on the same datasets, adopting an approach to the
task that has become dominant in the literature:
for each verb role, they built a prototype vector
by averaging the dependency-based vectors of its
most typical ﬁllers. The higher the similarity of
a noun with a role prototype, the higher its plau-
sibility as a ﬁller for that role. Lenci (2011) has
later extended the model to account for the dy-
namic update of the expectations on an argument,
depending on how another role is ﬁlled. By using
the same DM tensor, this study tested an additive
and a multiplicative model (Mitchell and Lapata,
2010) to compose and update the expectations on
the patient ﬁller of the subject-verb-object triples
of the Bicknell dataset (Bicknell et al., 2010).

The thematic ﬁt models proposed by Sayeed
and Demberg (2014) and Sayeed et al. (2015) are
similar to Baroni and Lenci’s, but their DSMs
were built by using the roles assigned by the
SENNA semantic role labeler (Collobert et al.,
2011) to deﬁne the feature space. These authors
argued that the prototype-based method with de-
pendencies works well when applied to the agent
and to the patient role (which are almost always
syntactically realized as subjects and objects), but

3Code: https://github.com/esantus/Thematic Fit
4In this paper, we will make reference to two different
models of DM: DepDM and TypeDM. DepDM counts the
frequency of dependency links between words (e.g. read, obj,
book), while TypeDM uses the variety of surface forms that
express the link between words, rather than the link itself.

that it might be problematic to apply it to dif-
ferent roles, such as instruments and locations,
as the construction of the prototype would have
to rely on prepositional complements as typical
ﬁllers, and the meaning of prepositions can be am-
biguous. Comparing their results with Baroni and
Lenci (2010), the authors showed that their system
outperforms the syntax-based model DepDM and
almost matches the scores of the best performing
TypeDM, which uses hand-crafted rules. More-
over, they were the ﬁrst to evaluate thematic role
plausibility for roles other than agent and patient,
as they computed the scores also for the instru-
ments and for the locations of the Ferretti datasets
(Ferretti et al., 2001).

Greenberg et al. (2015a,b) further developed the
TypeDM and the role-based models, investigat-
ing the effects of verb polysemy on human the-
matic ﬁt judgments and introducing a hierarchical
agglomerative clustering algorithm into the proto-
type creation process. Their goal was to cluster to-
gether typical ﬁllers into multiple prototypes, cor-
responding to different verb senses, and their re-
sults showed constant improvements of the perfor-
mance of the DM-based model.

Finally, Tilk et al. (2016) presented two neural
network architectures for generating probability
distributions over selectional preferences for each
thematic role. Their models took advantage of su-
pervised training on two role-labeled corpora to
optimize the distributional representation for the-
matic ﬁt modeling, and managed to obtain signif-
icant improvements over the other systems on al-
most all the evaluation datasets. They also eval-
uated their model on the task of composing and
updating verb argument expectations, obtaining a
performance comparable to Lenci (2011).

3 Methodology

As pointed out by Sayeed et al. (2016), most works
on unsupervised thematic ﬁt estimation vary in the
method adopted for constructing the prototypes.
The semantic role prototype is usually a vector,
obtained by averaging the most typical ﬁllers, and
plausibility of new ﬁllers depends on their similar-
ity to the prototype, assessed by means of vector
cosine (the standard similarity measure for DSMs;
see Turney and Pantel (2010)).

Its merits notwithstanding, we argue that this
method is not optimal for characterizing roles.
Distributional vectors are typically built as out-of-

context representations, and they conﬂate different
senses. By building the prototype as the centroid
of a cluster of vectors and measuring then the the-
matic ﬁt with vector cosine, the plausibility score
is inevitably affected by many contexts that are ir-
relevant for the speciﬁc verb-argument combina-
tion.5 This is likely to be one of the main reasons
behind the difﬁculties of modeling roles other than
agent and patient with syntax-based DSMs. We
claim that improving the prototype representation
might lead to a better characterization of thematic
roles, and to a better treatment of polysemy.

When a verb and an argument are composed,
humans are intuitively able to select only the part
of the potential meaning of the words that is rele-
vant for the concept being expressed (e.g. in The
player hit the ball, humans would certainly ex-
clude from the meaning of ball semantic dimen-
sions that are strictly related to its dancing sense).
In other words, not all the features of the seman-
tic representations are active, and the composition
process makes some features more ‘prominent’,
while moving others to the background.6

Although we are not aware of experimen-
tal works speciﬁcally dedicated to verb-argument
composition, a similar idea has been supported
in studies on conceptual combinations (Hampton,
1997, 2007): when a head and a modiﬁer are com-
bined, their interaction affects the saliency of the
features in the original concepts. For example,
in racing car, the most salient properties would
be those related to SPEED, whereas in family
car SPACE properties would probably be more
prominent. Yeh and Barsalou (2006) used a prop-
erty priming experiment to show how the concept
features activated during language comprehension
vary across the background situations described by
the sentence they occur in. When concepts are
combined in a sentence, the features that are rele-
vant for the speciﬁc combination are activated and
are then easier to verify for human subjects.

The same could be true for linguistically-
derived properties of lexical meaning: Simmons
et al. (2008) brought neuroimaging evidence of the
early activation of word association areas during
property generation tasks, and Santos et al. (2011)

5For an overview on the limitations of vector cosine, see:
Li and Han (2013); Dinu et al. (2015); Schnabel et al. (2015);
Faruqui et al. (2016); Santus et al. (2016a).

6An early proposal going in this direction is the predica-
tion theory by Kintsch (2001), which exploited Latent Se-
mantic Analysis to select only the vector features that are ap-
propriate for predicate-argument composition.

showed that word associates are often among the
properties generated for a given concept. Such
ﬁndings suggest that, while we combine concepts,
both embodied simulations and word distributions
inﬂuence property salience (Barsalou et al., 2008).
Our model makes the following assumptions:

• the composition between a verb role repre-
sentation and an argument shares the same
cognitive mechanism underlying conceptual
combinations;

• at least part of semantic representations is
derived from, and/or mirrored in, linguistic
data.7 Consistently, the process of selecting
the relevant features of the concepts being
composed corresponds to modify the salience
of the dimensions of distributional vectors;

• thematic ﬁt computation is carried out on the
basis of the activation and selection of salient
features of a verb thematic role prototype and
of the candidate argument ﬁller vectors.

We rely on syntax-based DSMs, using depen-
dency relations to approximate verb-speciﬁc roles
and to identify their most
for
agents/patients, we extract the most frequent sub-
jects/objects, for instruments we use the preposi-
tional complements introduced by with, and for
locations those introduced by either on, at or in.

typical ﬁllers:

Assuming that the linguistic features of distribu-
tional vectors correspond to the properties of con-
ceptual composition processes, a candidate ﬁller
can be represented as a sorted distributional vec-
tor of the ﬁller term, in which the most salient
contexts occupy the top positions. Similarly, the
abstract representation of a verb-speciﬁc role is
a sorted prototype-vector, whose features derive
from the sum of the most typical ﬁller vectors for
that verb-speciﬁc role.

Differently from Baroni and Lenci, the core and
novel aspect of our proposal, described in the fol-
lowing subsections, is that we do not simply mea-
sure the correlation between all the features of
candidate and prototype vectors (as vector cosine
would do on unsorted vectors), but rather we rank
and ﬁlter the features, computing the weighted
overlap with a rank-based similarity measure in-
spired by AP Syn, a recent proposal by Santus

7See also the so-called ’strong version’ of the Distribu-

tional Hypothesis (Miller and Charles, 1991; Lenci, 2008).

et al. (2016a,b,c) which has shown interesting re-
sults in synonymy detection and similarity estima-
tion. As we will show in the next sections, the new
metric assigns high scores to candidate ﬁllers shar-
ing many salient contexts with the verb-speciﬁc
role prototype.

3.1 Typical Fillers

The ﬁrst step of our method consists in identifying
the typical ﬁllers of a verb-speciﬁc role. Following
Baroni and Lenci (2010), we weighted the raw co-
occurrences between verbs, syntactic relations and
ﬁllers in the TypeDM tensor of DM with Positive
Local Mutual Information (PLMI; Evert (2004)).
Given the co-occurrence count Ovrf of the verb
v, a syntactic relation r and the ﬁller f , we com-
puted the expected count Evrf under the assump-
tion of statistical independence:

P LM I(v, r, f ) = log

∗ Ov,r,f

(1)

(cid:19)

(cid:18) Ov,r,f
Ev,r,f

From the ranked list of (v,r,f) tuples, for each slot,
we selected as typical ﬁllers the top k lexemes with
the highest PLMI scores (see examples in Table 1,
Typical Fillers column). In our experiments, we
report results for k = {10, 30, 50}.

3.2 Role Prototype Vectors

To represent the typical ﬁllers, the candidate ﬁllers
and the verb-speciﬁc role prototypes (which are
obtained by summing their typical ﬁller vectors),
we built a syntax-based DSM. This includes rela-
tion:word contexts, like sbj:dog, obj:apple, etc..

Contexts were weighted with Positive Pointwise
Mutual Information (PPMI; Church and Hanks
(1990), Bullinaria and Levy (2012), Levy et al.
(2015)). Given a context c and a word w, the PPMI
is deﬁned as follows:

P P M I(w, c) = max(P M I(w, c), 0)

(2)

P M I(w, c) = log

(cid:18) P (w, c)
P (w)P (c)

(cid:19)

= log

(cid:19)

(cid:18) |w, c|D
|w||c|

(3)

The context c of the prototype vector P repre-
senting a thematic role has a value corresponding
to the sum of the values of c for each of the k typ-
ical ﬁllers used to build P . The contexts of P
are then sorted according to their weight. Desir-
ably, the highest-ranking contexts for a role pro-
totype will be those that are more strongly associ-
ated with many of its typical ﬁllers. Such second
order contexts correspond to the most salient fea-
tures of the verb-speciﬁc thematic role, as they are
salient for many role ﬁllers (some examples are
reported in Table 1, Top Second Order Contexts
column).

In summary, we built centroid vectors for our
verb-speciﬁc thematic roles by means of second
order contexts, which are ﬁrst order dependency-
based contexts of the most typical ﬁllers of a verb-
speciﬁc role. Since we are interested only in the
most salient contexts, we ranked the centroid con-
texts according to their PPMI score, and we took
the resulting rank as a distributional characteriza-
tion of the thematic roles.

3.3 Filtering the Contexts

Filtering the prototype dimensions according to
syntactic criteria might be useful to improve our
It is, indeed, reasonable to
role representations.
hypothesize that predicates co-occurring with the
typical patients of a verb are more relevant for the
characterization of its patient role than – let’s say –
prepositional complements, as they correspond to
other actions that are typically performed on the
same patients.

Imagine that apple, pizza, cake etc. are among
the most salient ﬁllers for the OBJ slot of to eat,
and that OBJ-1:slice-v, OBJ-1:devour-v, SBJ:kid-
n, INSTRUMENT:fork-n, LOCATION:table-n are
some of the most salient contexts of the proto-
type.9 Things that are typically sliced and/or de-
voured are more likely to be good ﬁllers for the pa-
tient role to eat than things that are simply located
on a table or that are patients of actions performed
by kids. To test this hypothesis, we evaluated the
performance of the system in three different set-
tings, each of which selecting:

where w is the target word, c is the given context,
P(w,c) is the probability of co-occurrence, and D
is the collection of observed word-context pairs.8

8A variant of this DSM weighted with PLMI (which is
simply the PPMI multiplied by the word-context frequency)
was also built, but because of its lower and inconsistent per-

formance we will not discuss it further. Santus et al. (2016c)
previously showed that their rank-based measure performs
worse on PLMI-weighted vectors, as they are biased towards
frequent contexts.

9Our DSM also makes use of inverse syntactic dependen-
cies: target SYN-1 context means that target is linked to con-
text by the dependency relation SYN (e.g. meal OBJ-1 devour
means that meal is OBJ of devour).

subject: cure-v

object: abandon-v

instrument: eat-v

location: walk-v

Typical Fillers
treatment-n, drug-n, resin-n, doctor-n, surgery-n, medicine-
n, therapy-n, antibiotic-n, dose-n, operation-n, water-n...
plan-n, idea-n, project-n, attempt-n, position-n, principle-n,
policy-n, ship-n, practice-n, hope-n, fort-n, claim-n...
bread-n, hand-n, spoon-n, sauce-n, relish-n, fork-n, ﬁnger-
n, meal-n, knife-n, friend-n, chopstick-n, rice-n, food-n...
in:direction-n,
on:side-n, at:end, on:beach-n, on:leg, in:area, in:way...

at:pace-n, on:path-n,

at:night,

at:time,

sbj-

Top Second Order Contexts
obj-1:prescribe-v,
sbj-1:prescribe-v,
1:prevent-v, sbj-1:contraindicate-v, [...]
obj-1:revive-v, obj-1:defend-v, obj-1:renounce-
v, obj-1:espouse-v, sbj-1:entail-v...
obj-1:ﬂavour-v, obj-1:taste-v, obj-1:spoon-v,
sbj-1:taste-v, obj-1:slice-v in:bowl-n...
obj-1:wander-v, obj-1:stroll-v, obj-1:litter-v,
obj-1:sweep-v, sbj-1:slope-v, obj-1:tread-v...

Table 1: Typical ﬁllers and top second order contexts for several verb-speciﬁc roles.

• only predicates in a subject/object relation

(SO setting);

ting);

• only prepositional complements (PREP set-

Data
Pad´o
McRae
Instr.
Loc.

Our system
96
100
100
96

BL2010
100
95
93
99

SD2014
99
96
94
100

G2015
100
95
93
99

T2016
99
96
94
100

Table 2: Dataset coverage (%) for all systems.

• both of them (ALL setting).

3.4 Computing the Thematic Fit

4 Experiments

Our hypothesis is that ﬁllers whose salience-
ranked vector has a large overlap with the proto-
type representation should have a high thematic ﬁt.
Such overlap should take into account not only the
number of shared features, but also their respective
ranks in the salience-ranked vectors.

When the prototype has been computed and the
candidate ﬁller vector has also been sorted, we
can measure the Weighted Overlap by adapting
AP Syn (Santus et al., 2016a,b,c) to our needs:

W O(wx, wy) =

(cid:88)

1
avg(rx(f ), ry(f ))

(4)

∀f (cid:15)(x[1:N ]∩y[1:N ])

where for every feature f in the intersection be-
tween the top N features of the sorted vectors x,
x[1:N ], and y, y[1:N ], we sum 1 divided by the av-
erage rank of the shared feature in x and y, rx(f )
and ry(f ) (N is a tunable parameter).

This measure assigns the maximum score to
vectors sharing exactly the same dimensions, in
the same salience ranking. The lower the rank of a
shared context in the sorted vector, the smaller its
contribution to the thematic ﬁt score. If the feature
set intersection is empty, the score will be 0.

Differently from cosine similarity, which con-
ﬂates multiple senses, measuring the Weighted
Overlap between prototype and candidate ﬁller
can improve the estimation of the thematic ﬁt
by favoring the appropriate word senses: for ex-
ample, for a verb-argument pair like embrace-
v–communism-n, communism-n is likely to inter-
sect and to increase the saliency (through the av-
erage rank) only of the second-order features of
embrace-v referring to its abstract sense.

Datasets. We tested our method on three pop-
ular datasets for thematic ﬁt estimation, namely
McRae et al. (1998), Ferretti et al. (2001) and Pad´o
(2007). All the datasets contain human plausibility
judgments for verb-role-ﬁller triples. McRae and
Pad´o include scores for agent and patient roles,
whereas Ferretti includes instruments and loca-
tions (see Table 2 for the coverage of each system
for the datasets).
Metrics. Performance is evaluated as the Spear-
man correlation between the scores of the systems
and the human plausibility judgments.
Fillers. In order to make our results more compa-
rable with previous studies, the typical ﬁllers for
each verb role were extracted from the TypeDM
tensor of the Distributional Memory framework
(see Section 3.1).10 Those were the same ﬁllers
used by Baroni and Lenci (2010) and Greenberg
et al. (2015b).
DSM. Distributional information is derived from
the concatenation of two corpora: the British Na-
tional Corpus (Leech, 1992) and Ukwac (Baroni
et al., 2009). Both were parsed with the Malt-
parser (Nivre and Hall, 2005). From this con-
catenation, we built a dependency-based DSMs,
weighted with PPMI, containing 20,145 targets
(i.e. nouns and verbs with frequency above 1000)
and 94,860 contexts. The syntactic relations taken
into account were: sbj, sbj-1, obj, obj-1, at-1, in-1,
on-1, with-1.
Settings. To prove our hypotheses and verify the
consistency of the system, we tested a large range
of settings, varying:

10http://clic.cimec.unitn.it/dm/

Weight

N

# Fillers

PPMI

2000

Vector Cosine
(Baseline)

ALL
0.43
0.47
0.46

Pad´o
SO PREP ALL
0.25
0.26
0.45
0.26
0.33
0.49
0.50
0.27
0.35
0.43
0.47
0.48

Mcrae
SO PREP ALL
0.43
0.19
0.27
0.42
0.22
0.28
0.29
0.39
0.24
0.25
0.26
0.26

Ferretti - Instruments
PREP
0.46
0.50
0.47

SO
0.41
0.41
0.38

Ferretti - Locations
SO PREP
ALL
0.28
0.27
0.25
0.37
0.31
0.28
0.39
0.32
0.28
0.29
0.32
0.31

10
30
50
10
30
50

Baroni and Lenci (2010)
Sayeed and Demberg (2014)
Greenberg et al. (2015)
Tilk et al. (2016)

0.53
0.56
0.53
0.52

State of the Art

0.33
0.27
0.36
0.38

0.42
0.41
0.38

0.36
0.28
0.42
0.45

0.23
0.13
0.29
0.44

Table 3: Results for Pad´o, McRae and Ferretti, Instruments and Locations, with W O computed on PPMI
matrix, varying the number of ﬁllers (i.e. 10, 30 and 50) and the types of dependency contexts (i.e. ALL,
SO and PREP). The best results of our system are in bold. A baseline reimplementing Baroni and Lenci
(2010) – with 10, 30 and 50 ﬁllers – and state of the art results from previous literature are reported for
comparison.

• the number of ﬁllers used to build the proto-
type, with the most typical values in the liter-
ature ranging between 10 and 50. We report
the results for 10, 30 and 50 ﬁllers

• the types of the dependency relations used for
calculating the overlap: we report results for
the SO, PREP and ALL settings;

• the value of N , that is the number of top con-
texts that we take into account when comput-
ing the weighted overlap. Table 3 reports the
scores for our best setting, while the perfor-
mances for other values of N are discussed in
the Section 5.

Baseline and State of the Art. As a baseline, we
use the thematic ﬁt model by Baroni and Lenci
(2010), with no ranking of the features of the
prototypes and with vector cosine as a similarity
metric.11 Results are reported for 10, 30 and 50
ﬁllers. For reference, we also report the results
of state-of-the-art models, both the unsupervised
(Baroni and Lenci, 2010; Sayeed and Demberg,
2014; Greenberg et al., 2015b) and the supervised
ones (Tilk et al., 2016).

5 Results

Table 3 describes the performance of the best set-
ting (weight: PPMI; N=2000). In the ﬁrst three
rows, the table shows the scores obtained by our

11This baseline is equivalent to the approach of Baroni and
Lenci (2010), except for the fact that it is applied on a stan-
dard dependency-based DSM and not on TypeDM, which
combines dependency links and handcrafted lexico-syntactic
patterns: see Section 2.

system varying the types of dependency contexts
(i.e. ALL, SO, PREP) and the number of ﬁllers
considered for the prototype (i.e. 10, 30 and 50).
The other rows respectively show i) the scores ob-
tained by calculating the vector cosine between the
role prototype vector (i.e. the vector obtained by
summing the most typical ﬁllers, with no salience
ranking of the dimensions) and the candidate ﬁller
vector and ii) the scores reported in the literature
for the best unsupervised and supervised models.
At a glance, our best scores always outperform
the reimplementation of Baroni and Lenci, being
mostly competitive with the state of the art models.
More precisely, for agents and patients the per-
formance is close to the reported scores for DM,
when only predicates are used in the W O calcu-
lation, as hypothesized in Section 3.3. The neural
network of Tilk and colleagues retains a signiﬁ-
cant advantage on our models only for the McRae
dataset. Our system, however, shows a remark-
able improvements on the Ferretti’s datasets, and
speciﬁcally on Ferretti-Instruments, when only
complements are used (see Section 3.3), outper-
forming even the supervised and more complex
model by Tilk et al. (2016), which has access to
semantic roles information. Compared to the other
unsupervised models, our system has a statisti-
cally signiﬁcant advantage over Baroni and Lenci
(2010) on the locations dataset and over Sayeed
and Demberg (2014) on the locations and on the
instruments dataset (p < 0.05).12

At the best of our knowledge, the result for the

12p-values computed with Fisher’s r-to-z transformation.

Figure 1: Results for Pad´o, McRae and Ferretti, Instruments and Locations, with W O (respectively SO
and PREP) computed on PPMI matrix, varying the number of ﬁllers (i.e. 10, 30 and 50) and the value of
N (i.e. 500, 1000, 1500 and 2000). A baseline reimplementing Baroni and Lenci (2010) – with 10, 30
and 50 ﬁllers – is also reported in every test for comparison.

Figure 2: Results for the agent and patient roles in Pad´o and McRae, with W O (SO) computed on PPMI
matrix, varying the number of ﬁllers (i.e. 10, 30 and 50) and the value of N (i.e. 500, 1000, 1500 and
2000). A baseline reimplementing Baroni and Lenci (2010) – with 10, 30 and 50 ﬁllers – is also reported
in every test for comparison.

McRae
(k=50, Pred)
Pad´o
(k=50, Pred)
Ferretti - Instruments
(k=30, Compl)
Ferretti - Locations
(k=50, Compl)

Metric
Cos
W O 2000
Cos
W O 2000
Cos
W O 2000
Cos
W O 2000

4.90
4.20
4.07
4.35
4.53
5.06
5.15
4.97

Avg. Gold Overlap

Avg. Gold Overlap

BEST 35

Syntax
14 sbj, 21 obj
17 sbj, 18 obj
12 sbj, 23 obj
21 sbj, 14 obj
35 with
35 with
35 on/at/in
35 on/at/in

Lexemes
3 sentence, 2 devour, 2 scratch...
2 haunt
4 advise, 4 eat, 4 embarrass
3 confuse, 3 hear, 3 promise, 3 raise
3 hung, 3 eat, 3 teach
3 dig, 3 hunt
3 draw, 3 rescue
3 browse, 3 eat, 3 mingle, 3 rescue

3
4
10
10
16
15
11
11

4.75
4.15
4.77
4.68
4.51
4.49
4.72
4.47

WORST 35

Syntax
24 sbj, 11 obj
23 sbj, 12 obj
17 sbj, 18 obj
15 sbj, 20 obj
35 with
35 with
35 on/at/in
35 on/at/in

Lexemes
2 consider, 2 entertain, 2 scrub
2 admire, 2 arrest, 2 consider, 2 entertain
9 tell, 7 kill, 4 see
7 resent, 5 increase, 4 hear, 4 see
4 repair, 3 teach, 3 inﬂate
3 repair, 2 attract, 2 dig, 2 draw, 2 drink...
3 run, 2 wait, 2 wash, 2 shower...
3 run, 2 draw, 2 exercise, 2 shower, 2 wait...

26
26
16
16
22
22
23
23

Table 4: Average gold values, number of items listed for both metrics, and distribution of syntactic and
lexical forms among the 35 best and worst correlated items for every measure in the given datasets.

instruments is the best reported until now in the
literature. This is particularly interesting because
– as pointed out by Sayeed and Demberg (2014) –
instruments and locations are difﬁcult to model for
a dependency-based system, given the ambiguity
of prepositional phrases (e.g. with does not only
encode instruments, but it can also encode other
roles, such as in I ate a pizza with Mark). We think
this is the main reason behind the different trend
observed for the Instruments datasets with respect
to the number of the ﬁllers (see Table 3 and Fig-
ure 1). Unlike all the other datasets, instrument
prototypes built with more ﬁllers tend to be more
noisy and therefore to pull down both the vector
cosine and W O performance (this is partially true
also for locations, where the performances – for
cosine and W O with a lower number of contexts
– drop with more than 30 ﬁllers: see Figure 1).
Systems based on semantic role labeling have an
advantage in this sense, as they do not have to deal
with prepositional ambiguity.

Our

results show that, by weighting and
ﬁltering the features of
the role prototype,
dependency-based approaches can be successful
in modeling roles other than agent and patient,
eventually dealing also with the ambiguity of
prepositional phrases.

Settings. Apart from the above-mentioned ex-
ceptions,
the best scores are obtained building
the prototypes with a higher number of ﬁllers,
typically with 50, and calculating the W O only
with a syntactically-ﬁltered set of contexts. More
speciﬁcally, Pad´o and McRae beneﬁt from the
calculation of W O using only second order
subject-object predicates (i.e. SO), while Ferretti-
Instruments and Ferretti-Locations beneﬁt from
the exclusive use of prepositional complements
(i.e. PREP). On the other hand, the opposite set-
ting (e.g. SO for Ferretti-Instruments and Ferretti-
Locations and PREP for Pad´o and McRae) leads
to much lower scores, whereas the full vectors (i.e.

ALL) tend to have a stable-but-not-excellent per-
formances on all datasets.

As brieﬂy mentioned above, in our experiments,
we tested both PPMI and PLMI as weighting mea-
sures. Table 3 only reports PPMI scores because
it performs more regularly than PLMI, whose be-
haviour is often unpredictable.

A parameter that has an impact on the perfor-
mance of our system is the value of N , which
is the number of second order contexts that are
considered when calculating the W O. We have
noticed that the performance of W O is directly
related to the growth of N , and this can be noticed
in Figure 1, where W O is plotted for the different
values of N with every combination of dataset
and number of ﬁllers. For space reasons, the plot
only contains the performance for the best type
of second order contexts for each dataset (i.e.
SO for Pad´o and McRae and COMP for Ferretti-
Locations and Ferretti-Instruments). As it can be
seen in Figure 1, the scores of W O tend to grow
with the growth of N in all datasets. Interestingly,
they are largely above the competitive baseline
in most of the cases, the only exceptions being
Pad´o (where a large N is necessary to outperform
the baseline) and Ferretti-Locations with 10 ﬁllers
(prepositional ambiguity might have caused the
introduction of noisy ﬁllers among the top ones).

Agent & Patient. In order to further evaluate our
system, we have split Pad´o and McRae datasets
into agent and patient subsets. Figure 2 describes
the performance of W O and vector cosine base-
line while varying N and the number of ﬁllers.
The plot shows a clearly better performance of
W O for the agent role (i.e. subject), especially
when N is equal or over 1000 (note that the value
of N has little impact in the agent subset of the
McRae dataset). Such advantage, however, is re-
duced for the patient role (i.e. object). This is
particularly interesting because we do not observe
large drops in performance for the vector cosine

between agent and patient role (except for Pad´o,
k = 10). The drop is particularly noticeable in
Pad´o, a dataset which has several non-constraining
verbs (especially for the patient role: a similar ob-
servation was also made by Tilk et al. (2016)). As
the constraints on the typical ﬁllers of such verbs
are very loose, we hypothesize that it is more difﬁ-
cult to ﬁnd a set of salient features that are shared
by many typical ﬁllers. Therefore, estimations
based on the whole vectors turn out to be more
reliable. This can be conﬁrmed by looking at the
worst correlated words reported in Lexemes col-
umn, in Table 4.

5.1 Error Analysis

We performed an error analysis to verify – for the
best settings of W O in each dataset – the corre-
lation between vector cosine and W O scores (see
Table 5), and the peculiarities of the entries with
the strongest and the weakest correlation (see Ta-
ble 4).

We found that W O and vector cosine always
have a high correlation (i.e. above 0.80), with
the highest correlations reported for McRae and
Ferretti-Instruments. Looking at Table 4 we can
also observe that:

• the average gold value of the 35 most (4.65)
and least (4.56) correlated items does not
substantially differ from the average gold
value calculated on the full datasets (4.31),
meaning that the distribution of likely and un-
likely ﬁllers among the best and worst corre-
lated items is similar to the one in the datasets
(i.e. no bias can be identiﬁed);

• both measures have difﬁculties on the same
test items (probably because of loose seman-
tic constraints), but report their best perfor-
mances on different pairs (see Overlap and
Lexemes columns);

• syntactically, vector cosine correlates better
with objects, while W O is more balanced be-
tween objects and subjects, often showing a
preference for the latter (see the distribution
in Syntax column).

6 Conclusions

In this paper, we have introduced an unsupervised
distributional method for modeling predicate-
argument
judgments which works
thematic ﬁt
purely on syntactic information.

Dataset
McRae
Pad´o
Ferretti - Instruments
Ferretti - Locations

Correlation
0.88
0.81
0.90
0.83

Table 5: Correlation between W O and vector co-
sine in W O best settings for all datasets

The method,

inspired by cognitive and psy-
cholinguistic ﬁndings, consists in:
i) extracting
and ﬁltering the most salient second order contexts
for each verb-speciﬁc role, i.e.
the most salient
semantic dimensions of typical verb-speciﬁc role
ﬁllers; and then ii) estimating the thematic ﬁt as
a weighted overlap between the top features of
the candidate ﬁllers and of the prototypes. Once
tested on some popular datasets of thematic ﬁt
judgments, our method consistently outperforms a
baseline re-implementing the thematic ﬁt model of
Baroni and Lenci (2010) and proves to be competi-
tive with state of the art models. It even registered
the best performance on the Ferretti-Instruments
dataset and it is the second best on the Ferretti-
Locations, which were known to be particularly
hard to model for dependency-based approaches.
Our method is simple, economic and efﬁcient, it
works purely on syntactic dependencies (so it does
not require a role-labeled corpus) and achieves
good results even with no supervised training.
Finally,
it offers linguistically and cognitively
grounded insights on the process of prototype cre-
ation and contextual feature salience, preparing
the ground for further speculations and optimiza-
tions. For example, future work might aim at iden-
tifying strategies for tuning the parameter N to
account for the different degrees of selectivity of
each verb-speciﬁc role. Another possible exten-
sion would be the inclusion of a mechanism for
updating the role prototypes depending on how the
other roles are ﬁlled, which would be the key for
a more realistic and dynamic model of thematic ﬁt
expectations (Lenci, 2011).

Acknowledgments

We would like to thank the anonymous reviewers
for their helpful suggestions.

This work has been carried out thanks to the
support of the A*MIDEX grant (nANR-11-IDEX-
0001-02) funded by the French Government “In-
vestissements d’Avenir” program.

References

Gerry T.M Altmann and Yuki Kamide. 1999.

In-
cremental Interpretation at Verbs: Restricting the
Cognition
Domain of Subsequent Reference .
73(3):247 – 264.

Marco Baroni, Silvia Bernardini, Adriano Ferraresi,
and Eros Zanchetta. 2009. The WaCky wide web:
a Collection of Very Large Linguistically Processed
Web-crawled Corpora. Language Resources and
Evaluation 43(3):209–226.

Marco Baroni, Georgiana Dinu,

and Germ´an
Kruszewski. 2014.
A
Systematic Comparison of Context-counting vs.
In Proceed-
Context-predicting Semantic Vectors.
ings of ACL. volume 1.

Dont Count, Predict!

Marco Baroni and Alessandro Lenci. 2010. Dis-
tributional Memory: A General Framework for
Corpus-based Semantics. Computational Linguis-
tics 36(4):673–721.

Lawrence W Barsalou, Ava Santos, W Kyle Simmons,
and Christine D Wilson. 2008. Language and Sim-
ulation in Conceptual Processing. Symbols, embod-
iment, and meaning pages 245–283.

Klinton Bicknell, Jeffrey L Elman, Mary Hare, Ken
McRae, and Marta Kutas. 2010. Effects of Event
Knowledge in Processing Verbal Arguments. Jour-
nal of Memory and Language 63(4):489–505.

John A. Bullinaria and Joseph P. Levy. 2012. Ex-
tracting Semantic Representations from Word Co-
occurrence Statistics: Stop-lists, Stemming, and
SVD. Behavior Research Methods 44(3):890–907.

Kenneth Ward Church and Patrick Hanks. 1990. Word
Association Norms, Mutual Information, and Lexi-
cography. Computational Linguistics 16(1):22–29.

Ronan Collobert, Jason Weston, L´eon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural Language Processing (Almost) from
Journal of Machine Learning Research
Scratch.
12:2493–2537.

Georgiana Dinu, Angeliki Lazaridou, and Marco Ba-
roni. 2015. Improving Zero-shot Learning by Mit-
In Proceedings of
igating the Hubness Problem.
ICLR.

Katrin Erk. 2007. A Simple, Similarity-based Model
for Selectional Preferences. In Proceedings of ACL.

Katrin Erk, Sebastian Pad´o, and Ulrike Pad´o. 2010. A
ﬂexible, corpus-driven model of regular and inverse
selectional preferences. Computational Linguistics
36:723–763.

Stefan Evert. 2004. The Statistics of Word Cooccur-
rences: Word Pairs and Collocations. Ph.D. thesis.

Manaal Faruqui, Yulia Tsvetkov, Pushpendre Rastogi,
and Chris Dyer. 2016. Problems With Evaluation of
Word Embeddings Using Word Similarity Tasks. In
Proceedings of ACL Workshop on Evaluating Vector
Space Representations for NLP.

Todd R. Ferretti, Ken McRae, and Andrea Hatherell.
2001.
Integrating Verbs, Situation Schemas, and
Thematic Role Concepts . Journal of Memory and
Language 44(4):516 – 547.

Clayton Greenberg, Vera Demberg, and Asad Sayeed.
2015a. Verb Polysemy and Frequency Effects in
Thematic Fit Modeling. In Proceedings of NAACL
Workshop on Cognitive Modeling and Computa-
tional Linguistics.

Clayton Greenberg, Asad B. Sayeed, and Vera Dem-
berg. 2015b. Improving Unsupervised Vector-space
Thematic Fit Evaluation via Role-ﬁller Prototype
Clustering. In Proceedings of HLT-NAACL.

James A Hampton. 1997. Conceptual Combination.
Knowledge, Concepts, and Categories pages 133–
159.

James A. Hampton. 2007. Typicality, Graded Mem-
bership, and Vagueness. Cognitive Science 31:355–
384.

Mary Hare, Michael Jones, Caroline Thomson, Sarah
Kelly, and Ken McRae. 2009. Activating Event
Knowledge. Cognition 111 2:151–67.

Yuki Kamide, Gerry T.M Altmann, and Sarah L Hay-
wood. 2003. The Time-course of Prediction in In-
cremental Sentence Processing: Evidence from An-
ticipatory Eye Movements . Journal of Memory and
Language 49(1):133 – 156.

Walter Kintsch. 2001. Predication. Cognitive Science

25:173–202.

Geoffrey Leech. 1992. 100 Million Words of English:
the British National Corpus (BNC). Language Re-
search 28(1):1–13.

Alessandro Lenci. 2008. Distributional Semantics in
Linguistic and Cognitive Research. Italian Journal
of Linguistics 20(1):1–31.

Alessandro Lenci. 2011. Composing and Updating
Verb Argument Expectations: A Distributional Se-
mantic Model. In Proceedings of ACL Workshop on
Cognitive Modeling and Computational Linguistics.

Omer Levy, Yoav Goldberg, and Ido Dagan. 2015.
Improving Distributional Similarity with Lessons
Learned from Word Embeddings. TACL 3:211–225.

Baoli Li and Liping Han. 2013. Distance Weighted Co-
sine Similarity Measure for Text Classiﬁcation. In
Intelligent Data Engineering and Automated Learn-
ing. Springer Berlin Heidelberg, Berlin, Heidelberg,
pages 611–618.

Maryellen C MacDonald and Mark S Seidenberg.
2006. Constraint Satisfaction Accounts of Lexical
and Sentence Comprehension. Handbook of psy-
cholinguistics 2:581–611.

Kazunaga Matsuki, Tracy Chow, Mary Hare, Jeffrey L
Elman, Christoph Scheepers, and Ken McRae.
2011. Event-based Plausibility Immediately Inﬂu-
ences On-line Language Comprehension. Journal
of experimental psychology. Learning, memory, and
cognition 37 4:913–34.

Ken McRae, Mary Hare, Jeffrey L. Elman, and Todd
Ferretti. 2005. A basis for generating expectan-
cies for verbs from nouns. Memory & Cognition
33(7):1174–1184.

Ken McRae and Kazunaga Matsuki. 2009. People Use
their Knowledge of Common Events to Understand
Language, and Do So as Quickly as Possible. Lan-
guage and Linguistics Compass 3(6):1417–1429.

Ken McRae, Michael

J. Spivey-Knowlton,

and
Michael K. Tanenhaus. 1998. Modeling the Inﬂu-
ence of Thematic Fit (and Other Constraints) in On-
line Sentence Comprehension. Journal of Memory
and Language 38(3):283–312.

George A. Miller and Walter G. Charles. 1991. Con-
textual Correlates of Semantic Similarity. Language
and Cognitive Processes 6(1):1–28.

Jeff Mitchell and Mirella Lapata. 2010. Composition
in Distributional Models of Semantics. Cognitive
science 34(8):1388–1429.

Asad Sayeed and Vera Demberg. 2014. Combining
Unsupervised Syntactic and Semantic Models of
Thematic Fit. In Proceedings of CLIC.

Asad Sayeed, Vera Demberg, and Pavel Shkadzko.
2015. An Exploration of Semantic Features in an
Unsupervised Thematic Fit Evaluation Framework.
In Italian Journal of Linguistics.

Asad Sayeed, Clayton Greenberg, and Vera Demberg.
2016. Thematic Fit Evaluation: an Aspect of Se-
lectional Preferences. In Proceedings of ACL Work-
shop for Evaluating Vector Space Representations
for NLP.

Tobias Schnabel, Igor Labutov, David M. Mimno, and
Thorsten Joachims. 2015. Evaluation Methods for
Unsupervised Word Embeddings. In Proceedings of
EMNLP.

W Kyle Simmons, Stephan B Hamann, Carla L Haren-
ski, Xiaoping P Hu, and Lawrence W Barsalou.
2008. fMRI Evidence for Word Association and Sit-
uated Simulation in Conceptual Processing. Journal
of Physiology 102 1-3:106–19.

Ottokar Tilk, Vera Demberg, Asad B. Sayeed, Dietrich
Klakow, and Stefan Thater. 2016. Event Participant
Modelling with Neural Networks. In Proceedings of
EMNLP.

Peter D. Turney and Patrick Pantel. 2010. From Fre-
quency to Meaning: Vector Space Models of Se-
mantics. Journal of Artiﬁcial Intelligence Research
37:141–188.

Joakim Nivre and Johan Hall. 2005. Maltparser: A
Language-independent System for Data-driven De-
pendency Parsing. In Proceedings of Workshop on
Treebanks and Linguistic Theories. pages 13–95.

Bram Vandekerckhove, Dominiek Sandra, and Wal-
ter Daelemans. 2009. A Robust and Extensible
In Pro-
Exemplar-Based Model of Thematic Fit.
ceedings of EACL.

Ulrike Pad´o. 2007. The Integration of Syntax and Se-
mantic Plausibility in a Wide-coverage Model of Hu-
man Sentence Processing. Ph.D. thesis.

Wenchi Yeh and Lawrence W Barsalou. 2006. The Sit-
uated Nature of Concepts. The American Journal of
Psychology 119:3:349–84.

Ava Santos, Sergio E. Chaigneau, W. Kyle Simmons,
and Lawrence W. Barsalou. 2011. Property Gener-
ation Reﬂects Word Association and Situated Simu-
lation. Language and Cognition 3(1):83119.

Enrico Santus, Emmanuele Chersoni, Alessandro
Lenci, Chu-Ren Huang, and Philippe Blache. 2016a.
Testing APSyn against Vector Cosine on Similarity
Estimation. In Proceedings of PACLIC.

Enrico Santus, Tin-Shing Chiu, Qin Lu, Alessandro
Lenci, and Chu-Ren Huang. 2016b. Unsupervised
Measure of Word Similarity: how to Outperform
Co-occurrence and Vector Cosine in VSMs. In Pro-
ceedings of the AAAI. AAAI Press, pages 4260–
4261.

Enrico Santus, Tin-Shing Chiu, Qin Lu, Alessandro
Lenci, and Chu-Ren Huang. 2016c. What a Nerd!
Beating Students and Vector Cosine in the ESL and
TOEFL Datasets. In Proceedings of LREC.

Measuring Thematic Fit with Distributional Feature Overlap

Enrico Santus1, Emmanuele Chersoni2, Alessandro Lenci3 and Philippe Blache2
enrico santus@sutd.edu.sg
emmanuelechersoni@gmail.com
alessandro.lenci@unipi.it
philippe.blache@univ-amu.fr
1 Singapore University of Technology and Design
2 Aix-Marseille University
3 University of Pisa

Abstract

In this paper, we introduce a new distri-
butional method for modeling predicate-
argument thematic ﬁt judgments. We use
a syntax-based DSM to build a prototyp-
ical representation of verb-speciﬁc roles:
for every verb, we extract the most salient
second order contexts for each of its roles
the most salient dimensions of typi-
(i.e.
cal role ﬁllers), and then we compute the-
matic ﬁt as a weighted overlap between
the top features of candidate ﬁllers and
role prototypes. Our experiments show
that our method consistently outperforms
a baseline re-implementing a state-of-the-
art system, and achieves better or compa-
rable results to those reported in the liter-
ature for the other unsupervised systems.
Moreover, it provides an explicit represen-
tation of the features characterizing verb-
speciﬁc semantic roles.

1

Introduction

Several psycholinguistic studies in the last two
decades have brought extensive evidence that hu-
mans activate a rich array of event knowledge dur-
ing sentence processing: verbs (e.g. arrest) ac-
tivate expectations about their typical arguments
(e.g. cop, thief ) (McRae et al., 1998; Altmann and
Kamide, 1999; Ferretti et al., 2001; McRae et al.,
2005; Hare et al., 2009; Matsuki et al., 2011), and
nouns activate other nouns typically co-occurring
in the same events (Kamide et al., 2003; Bick-
nell et al., 2010). Subjects are able to determine
the plausibility of a noun for a given argument
role and quickly use this knowledge to anticipate
upcoming linguistic input (McRae and Matsuki,
2009). This phenomenon is referred to in the lit-
erature as thematic ﬁt. Thematic ﬁt estimation

has been extensively used in sentence comprehen-
sion studies on constraint-based models, mainly as
a predictor variable allowing to disambiguate be-
tween possible structural analyses.1 More in gen-
eral, thematic ﬁt is considered as a key factor in a
variety of studies concerned with structural ambi-
guity (Vandekerckhove et al., 2009).

Starting from the work of Erk et al. (2010),
several distributional semantic methods have been
proposed to compute the extent to which nouns
fulﬁll the requirements of verb-speciﬁc thematic
roles, and their performances have been evaluated
against human-generated judgments (Baroni and
Lenci, 2010; Lenci, 2011; Sayeed and Demberg,
2014; Sayeed et al., 2015, 2016; Greenberg et al.,
2015a,b). Most research on thematic ﬁt estima-
tion has focused on count-based vector representa-
tions (as distinguished from prediction-based vec-
tors).2 Indeed, in their comparison between high-
dimensional explicit vectors and low-dimensional
neural embeddings, Baroni et al. (2014) found that
thematic ﬁt estimation is the only benchmark on
which prediction models are lagging behind state-
of-the-art performance. This is consistent with
Sayeed et al. (2016)’s observation that “thematic
ﬁt modeling is particularly sensitive to linguistic
detail and interpretability of the vector space”.

The present work sets itself among the un-
supervised approaches to thematic ﬁt estima-
tion. By relying on explicit and interpretable
count-based vector representations, we propose
a simple, cognitively-inspired, and efﬁcient the-
matic ﬁt model using information extracted from
dependency-parsed corpora. The key features of
our proposal are a) prototypical representations
of verb-speciﬁc thematic roles, based on feature
weighting and ﬁltering of second order contexts

1For an overview on constraint-based models, see Mac-

Donald and Seidenberg (2006).

2We adopt the terminology from Baroni et al. (2014).

7
1
0
2
 
l
u
J
 
6
2
 
 
]
L
C
.
s
c
[
 
 
2
v
7
6
9
5
0
.
7
0
7
1
:
v
i
X
r
a

(i.e. contexts that are salient for many of the typ-
ical ﬁllers of a given verb-speciﬁc thematic role),
and b) a similarity measure which computes the
Weighted Overlap (W O) between prototypes and
candidate ﬁllers.3

2 Related Work

Erk et al. (2010) were, at the best of our knowl-
edge, the ﬁrst authors to measure the correlation
between human-elicited thematic ﬁt ratings and
the scores assigned by a syntax-based Distribu-
tional Semantic Model (DSM). More speciﬁcally,
their gold standard consisted of the human judg-
ments collected by McRae et al. (1998) and Pad´o
(2007). The plausibility of each verb-ﬁller pair
was computed as the similarity between new can-
didate nouns and previously attested exemplars for
each speciﬁc verb-role pairing (as already pro-
posed in Erk (2007)).

Baroni and Lenci (2010) evaluated their Dis-
tributional Memory (henceforth DM)4 framework
on the same datasets, adopting an approach to the
task that has become dominant in the literature:
for each verb role, they built a prototype vector
by averaging the dependency-based vectors of its
most typical ﬁllers. The higher the similarity of
a noun with a role prototype, the higher its plau-
sibility as a ﬁller for that role. Lenci (2011) has
later extended the model to account for the dy-
namic update of the expectations on an argument,
depending on how another role is ﬁlled. By using
the same DM tensor, this study tested an additive
and a multiplicative model (Mitchell and Lapata,
2010) to compose and update the expectations on
the patient ﬁller of the subject-verb-object triples
of the Bicknell dataset (Bicknell et al., 2010).

The thematic ﬁt models proposed by Sayeed
and Demberg (2014) and Sayeed et al. (2015) are
similar to Baroni and Lenci’s, but their DSMs
were built by using the roles assigned by the
SENNA semantic role labeler (Collobert et al.,
2011) to deﬁne the feature space. These authors
argued that the prototype-based method with de-
pendencies works well when applied to the agent
and to the patient role (which are almost always
syntactically realized as subjects and objects), but

3Code: https://github.com/esantus/Thematic Fit
4In this paper, we will make reference to two different
models of DM: DepDM and TypeDM. DepDM counts the
frequency of dependency links between words (e.g. read, obj,
book), while TypeDM uses the variety of surface forms that
express the link between words, rather than the link itself.

that it might be problematic to apply it to dif-
ferent roles, such as instruments and locations,
as the construction of the prototype would have
to rely on prepositional complements as typical
ﬁllers, and the meaning of prepositions can be am-
biguous. Comparing their results with Baroni and
Lenci (2010), the authors showed that their system
outperforms the syntax-based model DepDM and
almost matches the scores of the best performing
TypeDM, which uses hand-crafted rules. More-
over, they were the ﬁrst to evaluate thematic role
plausibility for roles other than agent and patient,
as they computed the scores also for the instru-
ments and for the locations of the Ferretti datasets
(Ferretti et al., 2001).

Greenberg et al. (2015a,b) further developed the
TypeDM and the role-based models, investigat-
ing the effects of verb polysemy on human the-
matic ﬁt judgments and introducing a hierarchical
agglomerative clustering algorithm into the proto-
type creation process. Their goal was to cluster to-
gether typical ﬁllers into multiple prototypes, cor-
responding to different verb senses, and their re-
sults showed constant improvements of the perfor-
mance of the DM-based model.

Finally, Tilk et al. (2016) presented two neural
network architectures for generating probability
distributions over selectional preferences for each
thematic role. Their models took advantage of su-
pervised training on two role-labeled corpora to
optimize the distributional representation for the-
matic ﬁt modeling, and managed to obtain signif-
icant improvements over the other systems on al-
most all the evaluation datasets. They also eval-
uated their model on the task of composing and
updating verb argument expectations, obtaining a
performance comparable to Lenci (2011).

3 Methodology

As pointed out by Sayeed et al. (2016), most works
on unsupervised thematic ﬁt estimation vary in the
method adopted for constructing the prototypes.
The semantic role prototype is usually a vector,
obtained by averaging the most typical ﬁllers, and
plausibility of new ﬁllers depends on their similar-
ity to the prototype, assessed by means of vector
cosine (the standard similarity measure for DSMs;
see Turney and Pantel (2010)).

Its merits notwithstanding, we argue that this
method is not optimal for characterizing roles.
Distributional vectors are typically built as out-of-

context representations, and they conﬂate different
senses. By building the prototype as the centroid
of a cluster of vectors and measuring then the the-
matic ﬁt with vector cosine, the plausibility score
is inevitably affected by many contexts that are ir-
relevant for the speciﬁc verb-argument combina-
tion.5 This is likely to be one of the main reasons
behind the difﬁculties of modeling roles other than
agent and patient with syntax-based DSMs. We
claim that improving the prototype representation
might lead to a better characterization of thematic
roles, and to a better treatment of polysemy.

When a verb and an argument are composed,
humans are intuitively able to select only the part
of the potential meaning of the words that is rele-
vant for the concept being expressed (e.g. in The
player hit the ball, humans would certainly ex-
clude from the meaning of ball semantic dimen-
sions that are strictly related to its dancing sense).
In other words, not all the features of the seman-
tic representations are active, and the composition
process makes some features more ‘prominent’,
while moving others to the background.6

Although we are not aware of experimen-
tal works speciﬁcally dedicated to verb-argument
composition, a similar idea has been supported
in studies on conceptual combinations (Hampton,
1997, 2007): when a head and a modiﬁer are com-
bined, their interaction affects the saliency of the
features in the original concepts. For example,
in racing car, the most salient properties would
be those related to SPEED, whereas in family
car SPACE properties would probably be more
prominent. Yeh and Barsalou (2006) used a prop-
erty priming experiment to show how the concept
features activated during language comprehension
vary across the background situations described by
the sentence they occur in. When concepts are
combined in a sentence, the features that are rele-
vant for the speciﬁc combination are activated and
are then easier to verify for human subjects.

The same could be true for linguistically-
derived properties of lexical meaning: Simmons
et al. (2008) brought neuroimaging evidence of the
early activation of word association areas during
property generation tasks, and Santos et al. (2011)

5For an overview on the limitations of vector cosine, see:
Li and Han (2013); Dinu et al. (2015); Schnabel et al. (2015);
Faruqui et al. (2016); Santus et al. (2016a).

6An early proposal going in this direction is the predica-
tion theory by Kintsch (2001), which exploited Latent Se-
mantic Analysis to select only the vector features that are ap-
propriate for predicate-argument composition.

showed that word associates are often among the
properties generated for a given concept. Such
ﬁndings suggest that, while we combine concepts,
both embodied simulations and word distributions
inﬂuence property salience (Barsalou et al., 2008).
Our model makes the following assumptions:

• the composition between a verb role repre-
sentation and an argument shares the same
cognitive mechanism underlying conceptual
combinations;

• at least part of semantic representations is
derived from, and/or mirrored in, linguistic
data.7 Consistently, the process of selecting
the relevant features of the concepts being
composed corresponds to modify the salience
of the dimensions of distributional vectors;

• thematic ﬁt computation is carried out on the
basis of the activation and selection of salient
features of a verb thematic role prototype and
of the candidate argument ﬁller vectors.

We rely on syntax-based DSMs, using depen-
dency relations to approximate verb-speciﬁc roles
and to identify their most
for
agents/patients, we extract the most frequent sub-
jects/objects, for instruments we use the preposi-
tional complements introduced by with, and for
locations those introduced by either on, at or in.

typical ﬁllers:

Assuming that the linguistic features of distribu-
tional vectors correspond to the properties of con-
ceptual composition processes, a candidate ﬁller
can be represented as a sorted distributional vec-
tor of the ﬁller term, in which the most salient
contexts occupy the top positions. Similarly, the
abstract representation of a verb-speciﬁc role is
a sorted prototype-vector, whose features derive
from the sum of the most typical ﬁller vectors for
that verb-speciﬁc role.

Differently from Baroni and Lenci, the core and
novel aspect of our proposal, described in the fol-
lowing subsections, is that we do not simply mea-
sure the correlation between all the features of
candidate and prototype vectors (as vector cosine
would do on unsorted vectors), but rather we rank
and ﬁlter the features, computing the weighted
overlap with a rank-based similarity measure in-
spired by AP Syn, a recent proposal by Santus

7See also the so-called ’strong version’ of the Distribu-

tional Hypothesis (Miller and Charles, 1991; Lenci, 2008).

et al. (2016a,b,c) which has shown interesting re-
sults in synonymy detection and similarity estima-
tion. As we will show in the next sections, the new
metric assigns high scores to candidate ﬁllers shar-
ing many salient contexts with the verb-speciﬁc
role prototype.

3.1 Typical Fillers

The ﬁrst step of our method consists in identifying
the typical ﬁllers of a verb-speciﬁc role. Following
Baroni and Lenci (2010), we weighted the raw co-
occurrences between verbs, syntactic relations and
ﬁllers in the TypeDM tensor of DM with Positive
Local Mutual Information (PLMI; Evert (2004)).
Given the co-occurrence count Ovrf of the verb
v, a syntactic relation r and the ﬁller f , we com-
puted the expected count Evrf under the assump-
tion of statistical independence:

P LM I(v, r, f ) = log

∗ Ov,r,f

(1)

(cid:19)

(cid:18) Ov,r,f
Ev,r,f

From the ranked list of (v,r,f) tuples, for each slot,
we selected as typical ﬁllers the top k lexemes with
the highest PLMI scores (see examples in Table 1,
Typical Fillers column). In our experiments, we
report results for k = {10, 30, 50}.

3.2 Role Prototype Vectors

To represent the typical ﬁllers, the candidate ﬁllers
and the verb-speciﬁc role prototypes (which are
obtained by summing their typical ﬁller vectors),
we built a syntax-based DSM. This includes rela-
tion:word contexts, like sbj:dog, obj:apple, etc..

Contexts were weighted with Positive Pointwise
Mutual Information (PPMI; Church and Hanks
(1990), Bullinaria and Levy (2012), Levy et al.
(2015)). Given a context c and a word w, the PPMI
is deﬁned as follows:

P P M I(w, c) = max(P M I(w, c), 0)

(2)

P M I(w, c) = log

(cid:18) P (w, c)
P (w)P (c)

(cid:19)

= log

(cid:19)

(cid:18) |w, c|D
|w||c|

(3)

The context c of the prototype vector P repre-
senting a thematic role has a value corresponding
to the sum of the values of c for each of the k typ-
ical ﬁllers used to build P . The contexts of P
are then sorted according to their weight. Desir-
ably, the highest-ranking contexts for a role pro-
totype will be those that are more strongly associ-
ated with many of its typical ﬁllers. Such second
order contexts correspond to the most salient fea-
tures of the verb-speciﬁc thematic role, as they are
salient for many role ﬁllers (some examples are
reported in Table 1, Top Second Order Contexts
column).

In summary, we built centroid vectors for our
verb-speciﬁc thematic roles by means of second
order contexts, which are ﬁrst order dependency-
based contexts of the most typical ﬁllers of a verb-
speciﬁc role. Since we are interested only in the
most salient contexts, we ranked the centroid con-
texts according to their PPMI score, and we took
the resulting rank as a distributional characteriza-
tion of the thematic roles.

3.3 Filtering the Contexts

Filtering the prototype dimensions according to
syntactic criteria might be useful to improve our
It is, indeed, reasonable to
role representations.
hypothesize that predicates co-occurring with the
typical patients of a verb are more relevant for the
characterization of its patient role than – let’s say –
prepositional complements, as they correspond to
other actions that are typically performed on the
same patients.

Imagine that apple, pizza, cake etc. are among
the most salient ﬁllers for the OBJ slot of to eat,
and that OBJ-1:slice-v, OBJ-1:devour-v, SBJ:kid-
n, INSTRUMENT:fork-n, LOCATION:table-n are
some of the most salient contexts of the proto-
type.9 Things that are typically sliced and/or de-
voured are more likely to be good ﬁllers for the pa-
tient role to eat than things that are simply located
on a table or that are patients of actions performed
by kids. To test this hypothesis, we evaluated the
performance of the system in three different set-
tings, each of which selecting:

where w is the target word, c is the given context,
P(w,c) is the probability of co-occurrence, and D
is the collection of observed word-context pairs.8

8A variant of this DSM weighted with PLMI (which is
simply the PPMI multiplied by the word-context frequency)
was also built, but because of its lower and inconsistent per-

formance we will not discuss it further. Santus et al. (2016c)
previously showed that their rank-based measure performs
worse on PLMI-weighted vectors, as they are biased towards
frequent contexts.

9Our DSM also makes use of inverse syntactic dependen-
cies: target SYN-1 context means that target is linked to con-
text by the dependency relation SYN (e.g. meal OBJ-1 devour
means that meal is OBJ of devour).

subject: cure-v

object: abandon-v

instrument: eat-v

location: walk-v

Typical Fillers
treatment-n, drug-n, resin-n, doctor-n, surgery-n, medicine-
n, therapy-n, antibiotic-n, dose-n, operation-n, water-n...
plan-n, idea-n, project-n, attempt-n, position-n, principle-n,
policy-n, ship-n, practice-n, hope-n, fort-n, claim-n...
bread-n, hand-n, spoon-n, sauce-n, relish-n, fork-n, ﬁnger-
n, meal-n, knife-n, friend-n, chopstick-n, rice-n, food-n...
in:direction-n,
on:side-n, at:end, on:beach-n, on:leg, in:area, in:way...

at:pace-n, on:path-n,

at:night,

at:time,

sbj-

Top Second Order Contexts
obj-1:prescribe-v,
sbj-1:prescribe-v,
1:prevent-v, sbj-1:contraindicate-v, [...]
obj-1:revive-v, obj-1:defend-v, obj-1:renounce-
v, obj-1:espouse-v, sbj-1:entail-v...
obj-1:ﬂavour-v, obj-1:taste-v, obj-1:spoon-v,
sbj-1:taste-v, obj-1:slice-v in:bowl-n...
obj-1:wander-v, obj-1:stroll-v, obj-1:litter-v,
obj-1:sweep-v, sbj-1:slope-v, obj-1:tread-v...

Table 1: Typical ﬁllers and top second order contexts for several verb-speciﬁc roles.

• only predicates in a subject/object relation

(SO setting);

ting);

• only prepositional complements (PREP set-

Data
Pad´o
McRae
Instr.
Loc.

Our system
96
100
100
96

BL2010
100
95
93
99

SD2014
99
96
94
100

G2015
100
95
93
99

T2016
99
96
94
100

Table 2: Dataset coverage (%) for all systems.

• both of them (ALL setting).

3.4 Computing the Thematic Fit

4 Experiments

Our hypothesis is that ﬁllers whose salience-
ranked vector has a large overlap with the proto-
type representation should have a high thematic ﬁt.
Such overlap should take into account not only the
number of shared features, but also their respective
ranks in the salience-ranked vectors.

When the prototype has been computed and the
candidate ﬁller vector has also been sorted, we
can measure the Weighted Overlap by adapting
AP Syn (Santus et al., 2016a,b,c) to our needs:

W O(wx, wy) =

(cid:88)

1
avg(rx(f ), ry(f ))

(4)

∀f (cid:15)(x[1:N ]∩y[1:N ])

where for every feature f in the intersection be-
tween the top N features of the sorted vectors x,
x[1:N ], and y, y[1:N ], we sum 1 divided by the av-
erage rank of the shared feature in x and y, rx(f )
and ry(f ) (N is a tunable parameter).

This measure assigns the maximum score to
vectors sharing exactly the same dimensions, in
the same salience ranking. The lower the rank of a
shared context in the sorted vector, the smaller its
contribution to the thematic ﬁt score. If the feature
set intersection is empty, the score will be 0.

Differently from cosine similarity, which con-
ﬂates multiple senses, measuring the Weighted
Overlap between prototype and candidate ﬁller
can improve the estimation of the thematic ﬁt
by favoring the appropriate word senses: for ex-
ample, for a verb-argument pair like embrace-
v–communism-n, communism-n is likely to inter-
sect and to increase the saliency (through the av-
erage rank) only of the second-order features of
embrace-v referring to its abstract sense.

Datasets. We tested our method on three pop-
ular datasets for thematic ﬁt estimation, namely
McRae et al. (1998), Ferretti et al. (2001) and Pad´o
(2007). All the datasets contain human plausibility
judgments for verb-role-ﬁller triples. McRae and
Pad´o include scores for agent and patient roles,
whereas Ferretti includes instruments and loca-
tions (see Table 2 for the coverage of each system
for the datasets).
Metrics. Performance is evaluated as the Spear-
man correlation between the scores of the systems
and the human plausibility judgments.
Fillers. In order to make our results more compa-
rable with previous studies, the typical ﬁllers for
each verb role were extracted from the TypeDM
tensor of the Distributional Memory framework
(see Section 3.1).10 Those were the same ﬁllers
used by Baroni and Lenci (2010) and Greenberg
et al. (2015b).
DSM. Distributional information is derived from
the concatenation of two corpora: the British Na-
tional Corpus (Leech, 1992) and Ukwac (Baroni
et al., 2009). Both were parsed with the Malt-
parser (Nivre and Hall, 2005). From this con-
catenation, we built a dependency-based DSMs,
weighted with PPMI, containing 20,145 targets
(i.e. nouns and verbs with frequency above 1000)
and 94,860 contexts. The syntactic relations taken
into account were: sbj, sbj-1, obj, obj-1, at-1, in-1,
on-1, with-1.
Settings. To prove our hypotheses and verify the
consistency of the system, we tested a large range
of settings, varying:

10http://clic.cimec.unitn.it/dm/

Weight

N

# Fillers

PPMI

2000

Vector Cosine
(Baseline)

ALL
0.43
0.47
0.46

Pad´o
SO PREP ALL
0.25
0.26
0.45
0.26
0.33
0.49
0.50
0.27
0.35
0.43
0.47
0.48

Mcrae
SO PREP ALL
0.43
0.19
0.27
0.42
0.22
0.28
0.29
0.39
0.24
0.25
0.26
0.26

Ferretti - Instruments
PREP
0.46
0.50
0.47

SO
0.41
0.41
0.38

Ferretti - Locations
SO PREP
ALL
0.28
0.27
0.25
0.37
0.31
0.28
0.39
0.32
0.28
0.29
0.32
0.31

10
30
50
10
30
50

Baroni and Lenci (2010)
Sayeed and Demberg (2014)
Greenberg et al. (2015)
Tilk et al. (2016)

0.53
0.56
0.53
0.52

State of the Art

0.33
0.27
0.36
0.38

0.42
0.41
0.38

0.36
0.28
0.42
0.45

0.23
0.13
0.29
0.44

Table 3: Results for Pad´o, McRae and Ferretti, Instruments and Locations, with W O computed on PPMI
matrix, varying the number of ﬁllers (i.e. 10, 30 and 50) and the types of dependency contexts (i.e. ALL,
SO and PREP). The best results of our system are in bold. A baseline reimplementing Baroni and Lenci
(2010) – with 10, 30 and 50 ﬁllers – and state of the art results from previous literature are reported for
comparison.

• the number of ﬁllers used to build the proto-
type, with the most typical values in the liter-
ature ranging between 10 and 50. We report
the results for 10, 30 and 50 ﬁllers

• the types of the dependency relations used for
calculating the overlap: we report results for
the SO, PREP and ALL settings;

• the value of N , that is the number of top con-
texts that we take into account when comput-
ing the weighted overlap. Table 3 reports the
scores for our best setting, while the perfor-
mances for other values of N are discussed in
the Section 5.

Baseline and State of the Art. As a baseline, we
use the thematic ﬁt model by Baroni and Lenci
(2010), with no ranking of the features of the
prototypes and with vector cosine as a similarity
metric.11 Results are reported for 10, 30 and 50
ﬁllers. For reference, we also report the results
of state-of-the-art models, both the unsupervised
(Baroni and Lenci, 2010; Sayeed and Demberg,
2014; Greenberg et al., 2015b) and the supervised
ones (Tilk et al., 2016).

5 Results

Table 3 describes the performance of the best set-
ting (weight: PPMI; N=2000). In the ﬁrst three
rows, the table shows the scores obtained by our

11This baseline is equivalent to the approach of Baroni and
Lenci (2010), except for the fact that it is applied on a stan-
dard dependency-based DSM and not on TypeDM, which
combines dependency links and handcrafted lexico-syntactic
patterns: see Section 2.

system varying the types of dependency contexts
(i.e. ALL, SO, PREP) and the number of ﬁllers
considered for the prototype (i.e. 10, 30 and 50).
The other rows respectively show i) the scores ob-
tained by calculating the vector cosine between the
role prototype vector (i.e. the vector obtained by
summing the most typical ﬁllers, with no salience
ranking of the dimensions) and the candidate ﬁller
vector and ii) the scores reported in the literature
for the best unsupervised and supervised models.
At a glance, our best scores always outperform
the reimplementation of Baroni and Lenci, being
mostly competitive with the state of the art models.
More precisely, for agents and patients the per-
formance is close to the reported scores for DM,
when only predicates are used in the W O calcu-
lation, as hypothesized in Section 3.3. The neural
network of Tilk and colleagues retains a signiﬁ-
cant advantage on our models only for the McRae
dataset. Our system, however, shows a remark-
able improvements on the Ferretti’s datasets, and
speciﬁcally on Ferretti-Instruments, when only
complements are used (see Section 3.3), outper-
forming even the supervised and more complex
model by Tilk et al. (2016), which has access to
semantic roles information. Compared to the other
unsupervised models, our system has a statisti-
cally signiﬁcant advantage over Baroni and Lenci
(2010) on the locations dataset and over Sayeed
and Demberg (2014) on the locations and on the
instruments dataset (p < 0.05).12

At the best of our knowledge, the result for the

12p-values computed with Fisher’s r-to-z transformation.

Figure 1: Results for Pad´o, McRae and Ferretti, Instruments and Locations, with W O (respectively SO
and PREP) computed on PPMI matrix, varying the number of ﬁllers (i.e. 10, 30 and 50) and the value of
N (i.e. 500, 1000, 1500 and 2000). A baseline reimplementing Baroni and Lenci (2010) – with 10, 30
and 50 ﬁllers – is also reported in every test for comparison.

Figure 2: Results for the agent and patient roles in Pad´o and McRae, with W O (SO) computed on PPMI
matrix, varying the number of ﬁllers (i.e. 10, 30 and 50) and the value of N (i.e. 500, 1000, 1500 and
2000). A baseline reimplementing Baroni and Lenci (2010) – with 10, 30 and 50 ﬁllers – is also reported
in every test for comparison.

McRae
(k=50, Pred)
Pad´o
(k=50, Pred)
Ferretti - Instruments
(k=30, Compl)
Ferretti - Locations
(k=50, Compl)

Metric
Cos
W O 2000
Cos
W O 2000
Cos
W O 2000
Cos
W O 2000

4.90
4.20
4.07
4.35
4.53
5.06
5.15
4.97

Avg. Gold Overlap

Avg. Gold Overlap

BEST 35

Syntax
14 sbj, 21 obj
17 sbj, 18 obj
12 sbj, 23 obj
21 sbj, 14 obj
35 with
35 with
35 on/at/in
35 on/at/in

Lexemes
3 sentence, 2 devour, 2 scratch...
2 haunt
4 advise, 4 eat, 4 embarrass
3 confuse, 3 hear, 3 promise, 3 raise
3 hung, 3 eat, 3 teach
3 dig, 3 hunt
3 draw, 3 rescue
3 browse, 3 eat, 3 mingle, 3 rescue

3
4
10
10
16
15
11
11

4.75
4.15
4.77
4.68
4.51
4.49
4.72
4.47

WORST 35

Syntax
24 sbj, 11 obj
23 sbj, 12 obj
17 sbj, 18 obj
15 sbj, 20 obj
35 with
35 with
35 on/at/in
35 on/at/in

Lexemes
2 consider, 2 entertain, 2 scrub
2 admire, 2 arrest, 2 consider, 2 entertain
9 tell, 7 kill, 4 see
7 resent, 5 increase, 4 hear, 4 see
4 repair, 3 teach, 3 inﬂate
3 repair, 2 attract, 2 dig, 2 draw, 2 drink...
3 run, 2 wait, 2 wash, 2 shower...
3 run, 2 draw, 2 exercise, 2 shower, 2 wait...

26
26
16
16
22
22
23
23

Table 4: Average gold values, number of items listed for both metrics, and distribution of syntactic and
lexical forms among the 35 best and worst correlated items for every measure in the given datasets.

instruments is the best reported until now in the
literature. This is particularly interesting because
– as pointed out by Sayeed and Demberg (2014) –
instruments and locations are difﬁcult to model for
a dependency-based system, given the ambiguity
of prepositional phrases (e.g. with does not only
encode instruments, but it can also encode other
roles, such as in I ate a pizza with Mark). We think
this is the main reason behind the different trend
observed for the Instruments datasets with respect
to the number of the ﬁllers (see Table 3 and Fig-
ure 1). Unlike all the other datasets, instrument
prototypes built with more ﬁllers tend to be more
noisy and therefore to pull down both the vector
cosine and W O performance (this is partially true
also for locations, where the performances – for
cosine and W O with a lower number of contexts
– drop with more than 30 ﬁllers: see Figure 1).
Systems based on semantic role labeling have an
advantage in this sense, as they do not have to deal
with prepositional ambiguity.

Our

results show that, by weighting and
ﬁltering the features of
the role prototype,
dependency-based approaches can be successful
in modeling roles other than agent and patient,
eventually dealing also with the ambiguity of
prepositional phrases.

Settings. Apart from the above-mentioned ex-
ceptions,
the best scores are obtained building
the prototypes with a higher number of ﬁllers,
typically with 50, and calculating the W O only
with a syntactically-ﬁltered set of contexts. More
speciﬁcally, Pad´o and McRae beneﬁt from the
calculation of W O using only second order
subject-object predicates (i.e. SO), while Ferretti-
Instruments and Ferretti-Locations beneﬁt from
the exclusive use of prepositional complements
(i.e. PREP). On the other hand, the opposite set-
ting (e.g. SO for Ferretti-Instruments and Ferretti-
Locations and PREP for Pad´o and McRae) leads
to much lower scores, whereas the full vectors (i.e.

ALL) tend to have a stable-but-not-excellent per-
formances on all datasets.

As brieﬂy mentioned above, in our experiments,
we tested both PPMI and PLMI as weighting mea-
sures. Table 3 only reports PPMI scores because
it performs more regularly than PLMI, whose be-
haviour is often unpredictable.

A parameter that has an impact on the perfor-
mance of our system is the value of N , which
is the number of second order contexts that are
considered when calculating the W O. We have
noticed that the performance of W O is directly
related to the growth of N , and this can be noticed
in Figure 1, where W O is plotted for the different
values of N with every combination of dataset
and number of ﬁllers. For space reasons, the plot
only contains the performance for the best type
of second order contexts for each dataset (i.e.
SO for Pad´o and McRae and COMP for Ferretti-
Locations and Ferretti-Instruments). As it can be
seen in Figure 1, the scores of W O tend to grow
with the growth of N in all datasets. Interestingly,
they are largely above the competitive baseline
in most of the cases, the only exceptions being
Pad´o (where a large N is necessary to outperform
the baseline) and Ferretti-Locations with 10 ﬁllers
(prepositional ambiguity might have caused the
introduction of noisy ﬁllers among the top ones).

Agent & Patient. In order to further evaluate our
system, we have split Pad´o and McRae datasets
into agent and patient subsets. Figure 2 describes
the performance of W O and vector cosine base-
line while varying N and the number of ﬁllers.
The plot shows a clearly better performance of
W O for the agent role (i.e. subject), especially
when N is equal or over 1000 (note that the value
of N has little impact in the agent subset of the
McRae dataset). Such advantage, however, is re-
duced for the patient role (i.e. object). This is
particularly interesting because we do not observe
large drops in performance for the vector cosine

between agent and patient role (except for Pad´o,
k = 10). The drop is particularly noticeable in
Pad´o, a dataset which has several non-constraining
verbs (especially for the patient role: a similar ob-
servation was also made by Tilk et al. (2016)). As
the constraints on the typical ﬁllers of such verbs
are very loose, we hypothesize that it is more difﬁ-
cult to ﬁnd a set of salient features that are shared
by many typical ﬁllers. Therefore, estimations
based on the whole vectors turn out to be more
reliable. This can be conﬁrmed by looking at the
worst correlated words reported in Lexemes col-
umn, in Table 4.

5.1 Error Analysis

We performed an error analysis to verify – for the
best settings of W O in each dataset – the corre-
lation between vector cosine and W O scores (see
Table 5), and the peculiarities of the entries with
the strongest and the weakest correlation (see Ta-
ble 4).

We found that W O and vector cosine always
have a high correlation (i.e. above 0.80), with
the highest correlations reported for McRae and
Ferretti-Instruments. Looking at Table 4 we can
also observe that:

• the average gold value of the 35 most (4.65)
and least (4.56) correlated items does not
substantially differ from the average gold
value calculated on the full datasets (4.31),
meaning that the distribution of likely and un-
likely ﬁllers among the best and worst corre-
lated items is similar to the one in the datasets
(i.e. no bias can be identiﬁed);

• both measures have difﬁculties on the same
test items (probably because of loose seman-
tic constraints), but report their best perfor-
mances on different pairs (see Overlap and
Lexemes columns);

• syntactically, vector cosine correlates better
with objects, while W O is more balanced be-
tween objects and subjects, often showing a
preference for the latter (see the distribution
in Syntax column).

6 Conclusions

In this paper, we have introduced an unsupervised
distributional method for modeling predicate-
argument
judgments which works
thematic ﬁt
purely on syntactic information.

Dataset
McRae
Pad´o
Ferretti - Instruments
Ferretti - Locations

Correlation
0.88
0.81
0.90
0.83

Table 5: Correlation between W O and vector co-
sine in W O best settings for all datasets

The method,

inspired by cognitive and psy-
cholinguistic ﬁndings, consists in:
i) extracting
and ﬁltering the most salient second order contexts
for each verb-speciﬁc role, i.e.
the most salient
semantic dimensions of typical verb-speciﬁc role
ﬁllers; and then ii) estimating the thematic ﬁt as
a weighted overlap between the top features of
the candidate ﬁllers and of the prototypes. Once
tested on some popular datasets of thematic ﬁt
judgments, our method consistently outperforms a
baseline re-implementing the thematic ﬁt model of
Baroni and Lenci (2010) and proves to be competi-
tive with state of the art models. It even registered
the best performance on the Ferretti-Instruments
dataset and it is the second best on the Ferretti-
Locations, which were known to be particularly
hard to model for dependency-based approaches.
Our method is simple, economic and efﬁcient, it
works purely on syntactic dependencies (so it does
not require a role-labeled corpus) and achieves
good results even with no supervised training.
Finally,
it offers linguistically and cognitively
grounded insights on the process of prototype cre-
ation and contextual feature salience, preparing
the ground for further speculations and optimiza-
tions. For example, future work might aim at iden-
tifying strategies for tuning the parameter N to
account for the different degrees of selectivity of
each verb-speciﬁc role. Another possible exten-
sion would be the inclusion of a mechanism for
updating the role prototypes depending on how the
other roles are ﬁlled, which would be the key for
a more realistic and dynamic model of thematic ﬁt
expectations (Lenci, 2011).

Acknowledgments

We would like to thank the anonymous reviewers
for their helpful suggestions.

This work has been carried out thanks to the
support of the A*MIDEX grant (nANR-11-IDEX-
0001-02) funded by the French Government “In-
vestissements d’Avenir” program.

References

Gerry T.M Altmann and Yuki Kamide. 1999.

In-
cremental Interpretation at Verbs: Restricting the
Cognition
Domain of Subsequent Reference .
73(3):247 – 264.

Marco Baroni, Silvia Bernardini, Adriano Ferraresi,
and Eros Zanchetta. 2009. The WaCky wide web:
a Collection of Very Large Linguistically Processed
Web-crawled Corpora. Language Resources and
Evaluation 43(3):209–226.

Marco Baroni, Georgiana Dinu,

and Germ´an
Kruszewski. 2014.
A
Systematic Comparison of Context-counting vs.
In Proceed-
Context-predicting Semantic Vectors.
ings of ACL. volume 1.

Dont Count, Predict!

Marco Baroni and Alessandro Lenci. 2010. Dis-
tributional Memory: A General Framework for
Corpus-based Semantics. Computational Linguis-
tics 36(4):673–721.

Lawrence W Barsalou, Ava Santos, W Kyle Simmons,
and Christine D Wilson. 2008. Language and Sim-
ulation in Conceptual Processing. Symbols, embod-
iment, and meaning pages 245–283.

Klinton Bicknell, Jeffrey L Elman, Mary Hare, Ken
McRae, and Marta Kutas. 2010. Effects of Event
Knowledge in Processing Verbal Arguments. Jour-
nal of Memory and Language 63(4):489–505.

John A. Bullinaria and Joseph P. Levy. 2012. Ex-
tracting Semantic Representations from Word Co-
occurrence Statistics: Stop-lists, Stemming, and
SVD. Behavior Research Methods 44(3):890–907.

Kenneth Ward Church and Patrick Hanks. 1990. Word
Association Norms, Mutual Information, and Lexi-
cography. Computational Linguistics 16(1):22–29.

Ronan Collobert, Jason Weston, L´eon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural Language Processing (Almost) from
Journal of Machine Learning Research
Scratch.
12:2493–2537.

Georgiana Dinu, Angeliki Lazaridou, and Marco Ba-
roni. 2015. Improving Zero-shot Learning by Mit-
In Proceedings of
igating the Hubness Problem.
ICLR.

Katrin Erk. 2007. A Simple, Similarity-based Model
for Selectional Preferences. In Proceedings of ACL.

Katrin Erk, Sebastian Pad´o, and Ulrike Pad´o. 2010. A
ﬂexible, corpus-driven model of regular and inverse
selectional preferences. Computational Linguistics
36:723–763.

Stefan Evert. 2004. The Statistics of Word Cooccur-
rences: Word Pairs and Collocations. Ph.D. thesis.

Manaal Faruqui, Yulia Tsvetkov, Pushpendre Rastogi,
and Chris Dyer. 2016. Problems With Evaluation of
Word Embeddings Using Word Similarity Tasks. In
Proceedings of ACL Workshop on Evaluating Vector
Space Representations for NLP.

Todd R. Ferretti, Ken McRae, and Andrea Hatherell.
2001.
Integrating Verbs, Situation Schemas, and
Thematic Role Concepts . Journal of Memory and
Language 44(4):516 – 547.

Clayton Greenberg, Vera Demberg, and Asad Sayeed.
2015a. Verb Polysemy and Frequency Effects in
Thematic Fit Modeling. In Proceedings of NAACL
Workshop on Cognitive Modeling and Computa-
tional Linguistics.

Clayton Greenberg, Asad B. Sayeed, and Vera Dem-
berg. 2015b. Improving Unsupervised Vector-space
Thematic Fit Evaluation via Role-ﬁller Prototype
Clustering. In Proceedings of HLT-NAACL.

James A Hampton. 1997. Conceptual Combination.
Knowledge, Concepts, and Categories pages 133–
159.

James A. Hampton. 2007. Typicality, Graded Mem-
bership, and Vagueness. Cognitive Science 31:355–
384.

Mary Hare, Michael Jones, Caroline Thomson, Sarah
Kelly, and Ken McRae. 2009. Activating Event
Knowledge. Cognition 111 2:151–67.

Yuki Kamide, Gerry T.M Altmann, and Sarah L Hay-
wood. 2003. The Time-course of Prediction in In-
cremental Sentence Processing: Evidence from An-
ticipatory Eye Movements . Journal of Memory and
Language 49(1):133 – 156.

Walter Kintsch. 2001. Predication. Cognitive Science

25:173–202.

Geoffrey Leech. 1992. 100 Million Words of English:
the British National Corpus (BNC). Language Re-
search 28(1):1–13.

Alessandro Lenci. 2008. Distributional Semantics in
Linguistic and Cognitive Research. Italian Journal
of Linguistics 20(1):1–31.

Alessandro Lenci. 2011. Composing and Updating
Verb Argument Expectations: A Distributional Se-
mantic Model. In Proceedings of ACL Workshop on
Cognitive Modeling and Computational Linguistics.

Omer Levy, Yoav Goldberg, and Ido Dagan. 2015.
Improving Distributional Similarity with Lessons
Learned from Word Embeddings. TACL 3:211–225.

Baoli Li and Liping Han. 2013. Distance Weighted Co-
sine Similarity Measure for Text Classiﬁcation. In
Intelligent Data Engineering and Automated Learn-
ing. Springer Berlin Heidelberg, Berlin, Heidelberg,
pages 611–618.

Maryellen C MacDonald and Mark S Seidenberg.
2006. Constraint Satisfaction Accounts of Lexical
and Sentence Comprehension. Handbook of psy-
cholinguistics 2:581–611.

Kazunaga Matsuki, Tracy Chow, Mary Hare, Jeffrey L
Elman, Christoph Scheepers, and Ken McRae.
2011. Event-based Plausibility Immediately Inﬂu-
ences On-line Language Comprehension. Journal
of experimental psychology. Learning, memory, and
cognition 37 4:913–34.

Ken McRae, Mary Hare, Jeffrey L. Elman, and Todd
Ferretti. 2005. A basis for generating expectan-
cies for verbs from nouns. Memory & Cognition
33(7):1174–1184.

Ken McRae and Kazunaga Matsuki. 2009. People Use
their Knowledge of Common Events to Understand
Language, and Do So as Quickly as Possible. Lan-
guage and Linguistics Compass 3(6):1417–1429.

Ken McRae, Michael

J. Spivey-Knowlton,

and
Michael K. Tanenhaus. 1998. Modeling the Inﬂu-
ence of Thematic Fit (and Other Constraints) in On-
line Sentence Comprehension. Journal of Memory
and Language 38(3):283–312.

George A. Miller and Walter G. Charles. 1991. Con-
textual Correlates of Semantic Similarity. Language
and Cognitive Processes 6(1):1–28.

Jeff Mitchell and Mirella Lapata. 2010. Composition
in Distributional Models of Semantics. Cognitive
science 34(8):1388–1429.

Asad Sayeed and Vera Demberg. 2014. Combining
Unsupervised Syntactic and Semantic Models of
Thematic Fit. In Proceedings of CLIC.

Asad Sayeed, Vera Demberg, and Pavel Shkadzko.
2015. An Exploration of Semantic Features in an
Unsupervised Thematic Fit Evaluation Framework.
In Italian Journal of Linguistics.

Asad Sayeed, Clayton Greenberg, and Vera Demberg.
2016. Thematic Fit Evaluation: an Aspect of Se-
lectional Preferences. In Proceedings of ACL Work-
shop for Evaluating Vector Space Representations
for NLP.

Tobias Schnabel, Igor Labutov, David M. Mimno, and
Thorsten Joachims. 2015. Evaluation Methods for
Unsupervised Word Embeddings. In Proceedings of
EMNLP.

W Kyle Simmons, Stephan B Hamann, Carla L Haren-
ski, Xiaoping P Hu, and Lawrence W Barsalou.
2008. fMRI Evidence for Word Association and Sit-
uated Simulation in Conceptual Processing. Journal
of Physiology 102 1-3:106–19.

Ottokar Tilk, Vera Demberg, Asad B. Sayeed, Dietrich
Klakow, and Stefan Thater. 2016. Event Participant
Modelling with Neural Networks. In Proceedings of
EMNLP.

Peter D. Turney and Patrick Pantel. 2010. From Fre-
quency to Meaning: Vector Space Models of Se-
mantics. Journal of Artiﬁcial Intelligence Research
37:141–188.

Joakim Nivre and Johan Hall. 2005. Maltparser: A
Language-independent System for Data-driven De-
pendency Parsing. In Proceedings of Workshop on
Treebanks and Linguistic Theories. pages 13–95.

Bram Vandekerckhove, Dominiek Sandra, and Wal-
ter Daelemans. 2009. A Robust and Extensible
In Pro-
Exemplar-Based Model of Thematic Fit.
ceedings of EACL.

Ulrike Pad´o. 2007. The Integration of Syntax and Se-
mantic Plausibility in a Wide-coverage Model of Hu-
man Sentence Processing. Ph.D. thesis.

Wenchi Yeh and Lawrence W Barsalou. 2006. The Sit-
uated Nature of Concepts. The American Journal of
Psychology 119:3:349–84.

Ava Santos, Sergio E. Chaigneau, W. Kyle Simmons,
and Lawrence W. Barsalou. 2011. Property Gener-
ation Reﬂects Word Association and Situated Simu-
lation. Language and Cognition 3(1):83119.

Enrico Santus, Emmanuele Chersoni, Alessandro
Lenci, Chu-Ren Huang, and Philippe Blache. 2016a.
Testing APSyn against Vector Cosine on Similarity
Estimation. In Proceedings of PACLIC.

Enrico Santus, Tin-Shing Chiu, Qin Lu, Alessandro
Lenci, and Chu-Ren Huang. 2016b. Unsupervised
Measure of Word Similarity: how to Outperform
Co-occurrence and Vector Cosine in VSMs. In Pro-
ceedings of the AAAI. AAAI Press, pages 4260–
4261.

Enrico Santus, Tin-Shing Chiu, Qin Lu, Alessandro
Lenci, and Chu-Ren Huang. 2016c. What a Nerd!
Beating Students and Vector Cosine in the ESL and
TOEFL Datasets. In Proceedings of LREC.

