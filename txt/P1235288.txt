Hierarchically Robust Representation Learning

Qi Qian1

Juhua Hu2 Hao Li1

1Alibaba Group
2School of Engineering and Technology
University of Washington, Tacoma, USA
{qi.qian, lihao.lh}@alibaba-inc.com juhuah@uw.edu

0
2
0
2
 
r
a

M
 
7
2
 
 
]

V
C
.
s
c
[
 
 
2
v
7
4
0
4
0
.
1
1
9
1
:
v
i
X
r
a

Abstract

With the tremendous success of deep learning in visual
tasks, the representations extracted from intermediate lay-
ers of learned models, that is, deep features, attract much
attention of researchers. Previous empirical analysis shows
that those features can contain appropriate semantic infor-
mation. Therefore, with a model trained on a large-scale
benchmark data set (e.g., ImageNet), the extracted features
can work well on other tasks. In this work, we investigate
this phenomenon and demonstrate that deep features can be
suboptimal due to the fact that they are learned by minimiz-
ing the empirical risk. When the data distribution of the tar-
get task is different from that of the benchmark data set, the
performance of deep features can degrade. Hence, we pro-
pose a hierarchically robust optimization method to learn
more generic features. Considering the example-level and
concept-level robustness simultaneously, we formulate the
problem as a distributionally robust optimization problem
with Wasserstein ambiguity set constraints, and an efﬁcient
algorithm with the conventional training pipeline is pro-
posed. Experiments on benchmark data sets demonstrate
the effectiveness of the robust deep representations.

1. Introduction

Extracting appropriate representations is essential for vi-
sual recognition. In the past decades, various hand-crafted
features have been developed to capture semantics of im-
ages, e.g., SIFT [16], HOG [7], etc. The conventional
pipeline works in two phases. In the ﬁrst phase, represen-
tations are extracted from each image with a given schema.
Thereafter, a speciﬁc model (e.g., SVM [6]) is learned with
these features for a target task. Since the hand-crafted fea-
tures are task-independent, the performance of this pipeline
can be suboptimal.

Deep learning proposes to incorporate these phases by
training end-to-end convolutional neural networks. Without
an explicit feature design like SIFT [16], a task-dependent

Figure 1. Examples from ImageNet, CIFAR-10 and SOP.
Example-level distribution difference within a class can be ob-
served from the 7th image of ImageNet and 2nd image of CIFAR-
10 for the car class in various aspects, e.g., resolution and pose.
Concept-level distribution difference is signiﬁcant between Ima-
geNet and SOP. ImageNet includes many classes from the concept
“animal” while SOP only contains classes from “artifact”.

representation will be learned through multiple layers and a
fully connected layer is attached at the end as a linear classi-
ﬁer for recognition. Beneﬁted from this coherent structure,
deep learning promotes the performance on visual tasks dra-
matically, e.g., categorization [15], detection [21], etc. De-
spite the success of deep learning on large-scale data sets,
deep neural networks (DNNs) are easy to overﬁt small data
sets due to the large number of parameters. Besides, DNNs
require GPU for efﬁcient training, which is expensive.

Researchers attempt to leverage pre-trained DNNs to im-
prove the feature design mechanism. Surprisingly, it is
observed that the features extracted from the last few lay-
ers perform well on the generic tasks when the model is
pre-trained on a large-scale benchmark data set, e.g., Ima-
geNet [22]. Deep features, which are outputs from interme-
diate layers of a deep model, become popular as the sub-
stitute of training deep models for light computation. Sys-
tematic comparison shows that these deep features outper-
form the existing hand-crafted features with a large mar-
gin [8, 17, 20].

The objective of learning deep models for speciﬁc tasks
and deep features for generic tasks can be different, but little
efforts have been devoted to further investigating deep fea-

tures. When learning deep models, it focuses on optimizing
the performance on the current training data set. In contrast,
deep features should be learned for generic tasks rather than
a single data set. In the applications of deep features, it is
also noticed that the deep features can fail when the data dis-
tribution in a generic task is different from the benchmark
data set [28]. By studying the objective of learning models
for a given task, we ﬁnd that it is a standard empirical risk
minimization (ERM) problem that is optimized on the uni-
form distribution over examples. It is well known that the
models obtained by ERM can generalize well on the data
from the same distribution as training [3].

However, the data distribution from real applications can
be signiﬁcantly different from a benchmark data set, which
can result in the performance degeneration when adopt-
ing the representations learned from ERM. The differences
can come from at least two aspects. First, the distribu-
tion of examples in each class can be different between the
generic task and the benchmark data set, which is referred
as example-level distribution difference in this paper. Tak-
ing the 7th image of ImageNet and 2nd of CIFAR-10 in
Fig. 1 as an example, they are of different resolutions and
poses while they are both from the car class. This problem
attracts much attention recently and some approaches to op-
timize the worst-case performance are developed to handle
this issue [5, 18, 24]. Second, the distribution of concepts
in an application is also different from that in the bench-
mark data set.
It should be noted that each concept here
can contain multiple classes, e.g., bulldog, beagle and so
on under the concept “dog”. This concept-level distribution
difference has been less investigated but more crucial for
deploying deep features due to the fact that the concepts in
real applications may be only a subset of or partially over-
lapped by those in the benchmark data set. For instance,
the concepts in SOP is quite different from those covered in
ImageNet as shown in Fig. 1.

In this work, we propose to consider the difference in
examples and that in concepts simultaneously and learn hi-
erarchically robust representations from DNNs. Compared
with ERM, our algorithm is more consistent with the ob-
jective of learning generic deep features. For the example-
level robustness, we adopt Wasserstein ambiguity set [24]
to encode the uncertainty from examples for the efﬁcient
optimization. Our theoretical analysis also illustrates that
an appropriate augmentation can be better than the regu-
larization in training DNNs, since the former one provides
a tighter approximation for the optimization problem. For
the concept-level robustness, we formulate it as a game
between the deep model and the distribution over differ-
ent concepts to optimize the worst-case performance over
concepts. By learning deep features with the adversarial
distribution, the worst-case performance over concepts can
be improved. Finally, to keep the simplicity of the train-

ing pipeline, we develop an algorithm that leverages the
standard random sampling strategy at each iteration and re-
weights the obtained gradient for an unbiased estimation.
This step may increase the variance of the gradient and we
reduce the variance by setting the learning rate elaborately.
We show that the adversarial distribution can converge at
the rate of O(log(T )/T ), where T denotes the total number
of iterations. We employ ImageNet as a benchmark data set
for learning deep features and the empirical study on real-
world data sets conﬁrms the effectiveness of our method.

The rest of this paper is organized as follows. Section
2 reviews the related work. Section 3 introduces the pro-
posed method. Section 4 conducts the experiments on the
benchmark data sets and Section 5 concludes this work with
future directions.

2. Related Work

Deep Features: Deep learning becomes popular since
ImageNet ILSVRC12 and various architectures of DNNs
have been proposed, e.g., AlexNet
[15], VGG [23],
GoogLeNet [27], and ResNet [12]. Besides the success on
image categorization, features extracted from the last few
layers are applied for generic tasks.
[8] adopts the deep
features from the last two layers in AlexNet and shows the
impressive performance on visual recognition with different
applications. After that, [20] applies deep features for dis-
tance metric learning and achieves the overwhelming per-
formance to the hand-crafted features on ﬁne-grained visual
categorization. [17] compares deep features from different
neural networks and ResNet shows the best results. Besides
the model pre-trained on ImageNet, [28] proposes to learn
deep features with a large-scale scene data set to improve
the performance on the scene recognition task. All of these
work directly extract features from the model learned with
ERM as the objective. In contrast, we develop an algorithm
that is tailored to learn robust deep representations. Note
that deep features can be extracted from multiple layers of
deep models and we focus on the layer before the ﬁnal fully-
connected layer in this work.
Robust Optimization: Recently, distributionally robust
optimization that aims to optimize the worst-case perfor-
mance has attracted much attention [5, 18, 24]. [18] pro-
poses to optimize the performance with worst-case distri-
bution over examples that is derived from the empirical dis-
tribution.
[5] extends the problem to a non-convex loss
function, but they require a near-optimal oracle for the non-
convex problem to learn the robust model. [24] introduces
the adversarial perturbation on each example for robustness.
Most of these algorithms only consider the example-level
robustness. In contrast, we propose the hierarchically robust
optimization that considers the example-level and concept-
level robustness simultaneously, to learn the generic deep
representations for real applications.

3. Hierarchical Robustness

3.1. Problem Formulation

Let xi denote an image and yi ∈ {1, . . . , C} be its corre-
sponding label for a C-class classiﬁcation problem. Given
a benchmark data set {xi, yi} where i = 1, . . . , N , the pa-
rameter θ in a deep neural network can be learned by solv-
ing the optimization problem as

min
θ

1
N

(cid:88)

i

(cid:96)(xi, yi; θ)

(1)

where (cid:96)(·) is a non-negative loss function (e.g., cross en-
tropy loss). By decomposing the parameter θ as θ = {δ, ω},
where ω denotes the parameter of the ﬁnal fully-connected
layer and δ denotes the parameter from other layers and can
be considered as for a feature extraction function f (·), we
can rewrite the original problem as

min
θ

1
N

(cid:88)

i

(cid:96)(f (xi), yi; ω)

Considering that ω is for a linear classiﬁer, which is consis-
tent to the classiﬁers applied in real-world applications (e.g.,
SVM), the decomposition shows that the problem of learn-
ing generic deep features f (x) can be addressed by learning
a robust deep model on the benchmark data set.

The original problem in Eqn. 1 is an empirical risk min-
imization (ERM) problem that can be inappropriate for
learning generic representations. In the following, we ex-
plore the hierarchical robustness to obtain robust deep rep-
resentations for generic tasks.

First, we consider the example-level robustness. Unlike
ERM, a robust model is to minimize the loss with the worst-
case distribution derived from the empirical distribution.
The optimization problem can be cast as a game between
the prediction model and the adversarial distribution

min
θ

max
i

{(cid:96)(xi, yi; θ)}

which is equivalent to

min
θ

max
p∈RN ;p∈∆

pi(cid:96)(xi, yi; θ)

(cid:88)

i

where p is the adversarial distribution over training exam-
ples and ∆ is the simplex as ∆ = {p| (cid:80)
i pi = 1, ∀i, pi ≥
0}. When p is a uniform distribution, the distributioanlly
robust optimization becomes ERM.

Without any constraints, the adversarial distribution is
sensitive to the outlier and can be arbitrarily far way from
the empirical distribution, which has large variance from the
selected examples. Therefore, we introduce a regularizer
to constrain the space of the adversarial distribution, which
provides a trade-off between the bias (i.e., to the empirical

distribution) and variance for the adversarial distribution.
The problem can be written as

min
θ

max
p∈RN ;p∈∆

(cid:88)

i

pi(cid:96)(xi, yi; θ) − λeD(p||p0)

(2)

where p0 is the empirical distribution. D(·) measures the
distance between the learned adversarial distribution and
the empirical distribution. We apply squared L2 distance
in this work as D(p||p0) = (cid:107)p − p0(cid:107)2
2. The regularizer
is to guarantee that the generated adversarial distribution is
not too far way from the empirical distribution. It implies
that the adversarial distribution is from an ambiguity set as

p ∈ {p : D(p||p0) ≤ (cid:15)}

where (cid:15) is determined by λe.

Besides the example-level robustness, concept-level ro-
bustness is more important for learning the generic features.
A desired model should perform consistently well over dif-
ferent concepts. Assuming that there are K concepts in the
training set and each concept consists of Nk examples, the
concept-robust optimization problem is

min
θ

max
k

{

1
Nk

Nk(cid:88)

i

(cid:96)(xk

i , yk

i ; θ)}

With the similar analysis as the example-level robustness
and adopting the appropriate regularizer, the problem be-
comes

min
θ

max
q∈RK ;q∈∆

(cid:88)

k

qk
Nk

Nk(cid:88)

i

(cid:96)(xk

i , yk

i ; θ) − λcD(q||q0)

(3)

where q0 can be set as qk

0 = Nk/N .
Combined with the example-level robustness, the hierar-

chically robust optimization problem becomes

min
θ

max
p∈RN ;p∈∆
q∈RK ;q∈∆

(cid:88)

k

qk
Nk

Nk(cid:88)

i

pi(cid:96)(xk

i , yk

i ; θ)

−λeD(p||p0) − λcD(q||q0)

In this formulation, each example is associated with a pa-
rameter pi and qk. Therefore, a high dimensionality with
this coupling structure makes an efﬁcient optimization chal-
lenging. Due to the fact that K (cid:28) N , we decouple the hi-
erarchical robustness with an alternative formulation for the
example-level robustness as follows.

3.2. Wasserstein Ambiguity Set

In Eqn. 2, the ambiguity set is deﬁned with the dis-
tance to the uniform distribution over the training set.
It
introduces the adversarial distribution by re-weighting each

example, which couples the parameter with that of the
concept-level problem. To simplify the optimization, we
generate the ambiguity set for the adversarial distribution
with Wasserstein distance [24]. The property of Wasserstein
distance can help to decouple the example-level robustness
from concept-level robustness.

Assume that P is a data-generating distribution over the
data space and P0 is the empirical distribution from where
the training set is generated as x ∼ P0. The ambiguity set
for the distribution P can be deﬁned as

{P : W (P, P0) ≤ (cid:15)}

W (P, P0) = inf M ∈Π(P,P0) EM [d(ˆx, x)] is the Wasserstein
distance between distributions [24] and we denote the ex-
ample generated from P as ˆx. d(·, ·) is the transportation
cost between examples.

The problem of example-level robustness can be written

as

min
θ

max
P

EP [(cid:96)(ˆx, y; θ)] −

W (P, P0)

λw
2

According to the deﬁnition of Wasserstein distance [24] and
let the cost function be the squared Euclidean distance, the
problem is equivalent to

min
θ

max
ˆx∈X

(cid:88)

i

(cid:96)(ˆxi, yi; θ) −

(cid:107)ˆxi − xi(cid:107)2
F

λw
2

(cid:88)

i

where X is the data space. In [24], they obtain the optimal
ˆxi by solving the subproblem for each example at each it-
eration. To accelerate the optimization, we propose to min-
imize the upper bound of the subproblem, which also pro-
vides an insight for the comparison between regularization
and augmentation.

The main theoretical results are stated in the following
theorems and their proofs can be found in the appendix.
First, we give the deﬁnition of smoothness as

Deﬁnition 1. A function f is called Lz-smoothness in z
w.r.t. a norm (cid:107) · (cid:107) if there is a constant Lz such that for any
values of z as z(cid:48) and z(cid:48)(cid:48), it holds that

f (z(cid:48)(cid:48)) ≤ f (z(cid:48)) + (cid:104)∇f (z(cid:48)), z(cid:48)(cid:48) − z(cid:48)(cid:105) +

(cid:107)z(cid:48)(cid:48) − z(cid:48)(cid:107)2

Lz
2

Theorem 1. Assuming (cid:96)(·) is Lx-smoothness in x and ∇x(cid:96)
is Lθ-Lipschitz continuous for θ, we have

max
ˆxi∈X

(cid:96)(ˆxi, yi; θ) −

λw
2

(cid:107)ˆxi − xi(cid:107)2

F ≤ (cid:96)(xi, yi; θ) +

(cid:107)θ(cid:107)2
F

γ
2

.

where λw is sufﬁciently large such that λw > Lx and γ =

L2
θ
λw−Lx
Theorem 2. With the same assumption in Theorem 1 and
considering an additive augmentation with z for the origi-
nal image

˜xi = xi + τ zi

we have

max
ˆxi∈X

where

(cid:96)(ˆxi, yi; θ)−

(cid:107)ˆxi−xi(cid:107)2

F ≤ (cid:96)(˜xi, yi; θ)+

(cid:107)θ(cid:107)2

F −α

λw
2

γ
2

(cid:104)∇xi(cid:96), zi(cid:105)
3Lx(cid:107)zi(cid:107)2
F
and α is a non-negative constant as

τ =

α =

λw
λw − Lx

(cid:104)∇xi(cid:96), zi(cid:105)2
6Lx(cid:107)zi(cid:107)2
F

Theorem 1 shows that learning the model using the orig-
inal examples with a regularization on the complexity of
the model, e.g., weight decay with γ, can make the learned
model robust for examples from the ambiguity set. A simi-
lar result has been observed in the conventional robust opti-
mization [1]. However, the regularization is not sufﬁcient to
train good enough DNNs and many optimization algorithms
have to rely on augmented examples to obtain models with
better generalization performance.

Theorem 2 interprets the phenomenon by analyzing a
speciﬁc augmentation that adds a patch z to the original
image and shows that augmented examples can provide a
tighter bound for the loss of the examples in the ambiguity
set. Besides, the augmented patch zi is corresponding to the
gradient of the original example xi. To make the approxi-
mation tight, it should be identical to the direction of the
gradient. So we set zi = ∇xi (cid:96)
, which is similar to that
(cid:107)∇xi (cid:96)(cid:107)F
in adversarial training [11].

Combining with the concept-level robustness in Eqn. 3,
we have the ﬁnal objective for learning the hierarchically
robust representations as

min
θ

max
q∈RK ;q∈∆

L(q, θ) =

(cid:88)

(cid:88)

qk
Nk

i

(cid:96)(˜xk

i , yk

i ; θ)

+

γ
2

k
λ
2

(cid:107)θ(cid:107)2

F −

(cid:107)q − q0(cid:107)2
2

(4)

3.3. Efﬁcient Optimization

The problem in Eqn. 4 can be solved efﬁciently by
stochastic gradient descent (SGD). In the standard training
pipeline for ERM in Eqn. 1, a mini-batch of examples are
randomly sampled at each iteration and the model is up-
dated with gradient descent as

θt+1 = θt − ηθ

∇θ(cid:96)(xi, yi; θt)

1
m

m
(cid:88)

i

where m is the size of a mini-batch.

For the problem in Eqn. 4, each example has a weight as
qk/Nk and the gradient has to be weighted for an unbiased
estimation as

θt+1 = θt − ηθ(

qk∇θ(cid:96)(˜xk

i , yk

i ; θt) + γθt)

(5)

1
m

m
(cid:88)

i

N
Nk

For the adversarial distribution q, each concept has a
weight qk and the straightforward way is to sample a mini-
batch of examples from each concept to estimate the gra-
dient of the distribution. However, the number of concepts
varies and it can be larger than the size of a mini-batch.
Besides, it results in the different sampling strategies for
computing the gradient of deep models and the adversarial
distribution, which increases the complexity of the train-
ing system. To address the issue, we take the same random
sampling pipeline and update the distribution with weighted
gradient ascent as

ˆqt+1
k = qt

k + ηt
q

(cid:96)(˜xk

j , yk

j ; θt) − λ(qt

k − qk

0 )(cid:1)

(cid:0) 1
m

mk(cid:88)

j

N
Nk

qt+1 = P∆(ˆqt+1)

(6)

where mk is the number of examples from the k-th concept
in the mini-batch and (cid:80)
k mk = m. P∆(·) projects the
vector onto the simplex as in [9].

The re-weighting strategy makes the gradient unbi-
ased but introduces the additional variance. Since batch-
normalization [13] is inapplicable for the parameters of the
adversarial distribution that is from the simplex, we develop
a learning strategy to reduce the variance from gradients.

First, to illustrate the issue, let δ1 and δ2 be two binary

random variables as

Pr{δ1 = 1} =

; Pr{δ2 = 1} =

1
Nk

1
N

Obviously, we have E[δ1] = 1
It
Nk
demonstrates that the gradient after re-weighting is unbi-
ased. However, the variance can be different as

; E[ N δ2
Nk

] = 1
Nk

.

Var[δ1] =

−

; Var[

] =

−

1
Nk

1
N 2
k

N δ2
Nk

N
N 2
k

1
N 2
k

where the variance is roughly increased by a factor of
N/Nk.

By investigating the updating criterion in Eqn. 6, we ﬁnd
that the gradient is rescaled by the learning rate ηt
q. If we let
q = O( 1
ηt
t ), the norm of the gradient will be limited after a
sufﬁcient number of iterations. Besides, for any distribution
q(cid:48), the norm of (cid:107)q − q(cid:48)(cid:107)2
2 is bounded by a small value of
2 since the distribution is from the simplex. It inspires us
to deal with the ﬁrst several iterations by adopting a small
learning rate. The algorithm is summarized in Alg. 1. In
short, we use the learning rate as ηt = 1
cλt where c > 1 for
the ﬁrst s iterations and then the conventional learning rate
ηt = 1

λt is applied.

The convergence about the adversarial distribution is

stated as follows.

Theorem 3. Assume the gradient of the adversarial distri-
bution q is bounded as ∀t, (cid:107)gt
q(cid:107)2 ≤ µ and set the learning

Algorithm 1 Hierarchically Robust Representation Learn-
ing (HRRL)

1: Input: Dataset {xi, yi}, iterations T , mini-batch size

m, λ, γ, τ , s, c
2: for t = 1, · · · , T do
if t <= s then
3:
q = 1
ηt
4:
cλt
else
5:
q = 1
ηt
6:
λt
end if
7:
Sample a mini-batch of examples {xi, yi}i=1,...,m
Generate the augmented data as ˜xi = xi + τ zi
Update model with gradient descent as in Eqn. 5
Update distribution with gradient ascent as in Eqn. 6

8:
9:
10:
11:
12: end for
13: return A feature extraction function f (·) from θT

rate as

We have

ηt
q =

(cid:26) 1
cλt
1
λt

t ≤ s
o.w.

max
q∗∈∆

1
T

T
(cid:88)

t

≤

1
T

(

µ2
2λ

E[L(q∗, θt) − L(qt, θt)]

(log(T ) + 1) − β)

where β is a non-negative constant as β = (µ
√

sλ)2 and c = µ
λ

(cid:113) log(s)
2s

should be larger than 1.

(cid:113) log(s)

2λ −

Theorem 3 shows a O(log(T )/T ) convergence rate for
the adversarial distribution. The gain of the adaptive learn-
ing rate is indicated in β, that is, a larger β provides a better
convergence. When applying the conventional learning rate
i.e. c = 1, it is easy to show β = 0. To further investigate
the properties of β, we let h(s) = µ(cid:112)log(s)/(2λ) −
sλ,
i.e., β = h(s)2, and study its behavior.

√

Proposition 1. h(s) is non-negative.

Proof. Since c = µ
λ
Therefore

(cid:113) log(s)

2s > 1, we have µ > λ

(cid:113) 2s

log(s) .

h(s) = µ

(cid:114)

log(s)
2λ

√

√

√

−

sλ >

sλ −

sλ = 0

It implies that we can beneﬁt from the variance reduc-
tion as long as the variance µ is sufﬁciently large. Then,
we ﬁx λ = 1 and plot the curve of h(s) when varying µ in
Fig. 2. We can ﬁnd that h(s) achieves its maximum after

thousands of iterations, which suggests that s should not be
too large. It is consistent with our claim that the gradient
will be shrunk by the learning rate and the additional vari-
ance has little inﬂuence when t is large.

Figure 2. Curves of h(s) with different µ’s.

4. Experiments

We adopt ImageNet ILSVRC12 [22] as the benchmark
data set to learn models for generic feature extraction in the
experiments. ImageNet includes 1, 000 classes, where each
class has about 1, 200 images in training and 50 images in
test. We summarize these 1, 000 classes into 11 concepts ac-
cording to the structure of WordNet [10] that is the default
class structure of ImageNet. The statistics of the concepts
and classes are summarized in Table 1. Apparently, Ima-
geNet is biased to speciﬁc animals. For example, it contains
59 classes of birds and more than 100 classes of dogs. This
bias can result in the performance degeneration when apply-
ing the model learned by ERM to generate representations
for different tasks.

Concept
#Classes
Concepts
#Classes

An
121
I
106

B
Ar
107
59
M S
57
100

C
56
V
67

De
129
O
80

Do
118

Table 1. Concepts in ImageNet. The initials “An”, “Ar”, “B”, “C”,
“De”, “Do”, “I”, “M”, “S”, “V”, “O” denote “Animal”, “Artifact”,
“Bird”, “Container”, “Device”, “Dog”, “Instrumentality”, “Mam-
mal”, “Structure”, “Vehicle”, “Others”, respectively.

We apply ResNet-18 [12], which is a popular network as
the feature extractor [17], to learn the representations. We
train the model with stochastic gradient descent (SGD) on
2 GPUs. Following the common practice [12], we learn the
model with 90 epochs and set the size of mini-batch as 256.
The initial learning rate is set to 0.1, and then it is decayed
by a factor of 10 at {30, 60}. The weight decay is 10−4 and
the momentum in SGD is 0.9. All model training includes
random crop and horizontal ﬂipping as the data augmenta-
tion. We set s = 1000 as suggested by Fig. 2 for the pro-
posed algorithm. For the setting of c, we calculate the vari-

ance for µ from several mini-batches and set c = 10 accord-
ing to Theorem 3. After obtaining deep models, we extract
deep features from the layer before the last fully-connected
layer, which generates a 512-dimensional feature for a sin-
gle image. Given the features, we learn a linear SVM [4]
to categorize examples. τ , λ and the parameter of SVM
are searched in {10i}(i = −3, . . . , 1). Four different deep
features with SVM as follows are compared in the experi-
ments, where SVMERM is the conventional way to extract
features with models trained by ERM and the others are our
proposals.

• SVMERM: deep features learned with ERM.
• SVMEL: deep features learned with example-level ro-

bustness only.

bustness only.

• SVMCL: deep features learned with concept-level ro-

• SVMHRRL: deep features learned with both example-

level and concept-level robustness.

Experiments are repeated 3 times and the average results
with standard deviation are reported.

4.1. CIFAR-10

First, we study the scenario when example-level distribu-
tion difference exits between the target task and the bench-
mark data set. We conduct experiments on CIFAR-10 [14],
which contains 10 classes and 60, 000 images. 50, 000 of
them are for training and the rest are for test. CIFAR-10
has the similar concepts as those in ImageNet, e.g., “bird”,
“dog”, and the difference in concepts is negligible. On the
contrary, each image in CIFAR-10 has a size of 32 × 32,
which is signiﬁcantly smaller than that of images in Ima-
geNet. As shown in Fig. 1, the example-level distribution
changes dramatically and the example-level robustness is
important for this task.

Table 2 summarizes the comparison. First, we observe
that the accuracy of SVMERM can achieve 85.77%, which
surpasses the performance of SIFT features [2], i.e., 65.6%,
by more than 20%.
It conﬁrms that representations ex-
tracted from a DNN model trained on the benchmark data
set can be applicable for generic tasks. Compared with rep-
resentations from the model learned with ERM, SVMEL
outperforms it by a margin about 1%. It shows that optimiz-
ing with Wasserstein ambiguity set can learn the example-
level robust features and handle the difference in examples
better than ERM. SVMCL has the similar performance as
SVMERM. It is consistent with the fact that the difference
of concepts between CIFAR-10 and ImageNet is small. Fi-
nally, the performance of SVMHRRL is comparable to that
of SVMEL due to negligible concept-level distribution dif-
ference but it is signiﬁcantly better than SVMERM, which
demonstrates the effectiveness of the proposed algorithm.

Methods
SVMERM
SVMEL
SVMCL
SVMHRRL

Acc(mean±std)
85.77±0.12
86.62±0.18
85.64±0.26
86.49±0.19

Table 2. Comparison of accuracy (%) on CIFAR-10.

4.2. Stanford Online Products (SOP)

In this subsection, we demonstrate the importance of
concept-level robustness. We have Stanford Online Prod-
ucts (SOP) [25] as the target task to evaluate the learned rep-
resentations. SOP collects product images from eBay.com
and consists of 59, 551 images for training and 60, 502 im-
ages for test. We adopt the super class label for each im-
age, which leads to a 12-class classiﬁcation problem. As
shown in Fig. 1, we can ﬁnd that the example-level distri-
bution difference is not signiﬁcant (e.g., resolution), while
the distribution of concepts (i.e., concept-level distribution)
is relatively different. ImageNet includes many natural ob-
jects, e.g., animals, while SOP only contains artiﬁcial ones.
Handling the difference in concepts is challenging for this
task.

Table 3 shows the performance comparison. Apparently,
SVMEL has the similar performance as SVMERM due to the
minor changes in the example-level distribution. However,
SVMCL demonstrates a better accuracy, which is about 1%
better than SVMERM. It demonstrates that the deep features
learned with the proposed algorithm is more robust than
those from ERM when the distribution of concepts varies.
Besides, the performances of SVMHRRL and SVMCL are
comparable, which conﬁrms that deep features obtained
with hierarchical robustness work well consistently in dif-
ferent scenarios.

Methods
SVMERM
SVMEL
SVMCL
SVMHRRL

Acc(mean±std)
73.47±0.09
73.48±0.08
74.34±0.05
74.23±0.08

Table 3. Comparison of accuracy (%) on SOP.

4.3. Street View House Numbers (SVHN)

Finally, we deal with a task when both example-level and
concept-level distribution differences exist. We evaluate the
robustness of deep features on Street View House Numbers
It consists of 73, 257 images for
(SVHN) [19] data set.
training and 26, 032 for test. The target is to identify one
of 10 digits from each 32 × 32 image. The image has the
same size as CIFAR-10, which is very different from Ima-
geNet. Moreover, SVHN has the concepts of digits, which
is also different from ImageNet.

We compare the different deep features in Table 4. First,
as observed in CIFAR-10, SVMEL outperforms SVMERM
by a large margin.
It is because features learned with
example-level robustness is more applicable than those
from ERM when examples are from a different distribu-
tion. Second, SVMCL improves the performance by more
than 2%. It is consistent with the observation in SOP, where
features learned with concept-level robustness perform bet-
ter when concepts vary. Besides, we can observe that the
performance of SVMCL surpasses that of SVMEL. It im-
plies that controlling concept-level robustness, which has
not been investigated sufﬁciently, may be more important
than example-level robustness for representation learning.
Finally, by combining example-level and concept-level ro-
bustness, SVMHRRL shows an improvement of more than
4%. It demonstrates that example-level and concept-level
robustness are complementary. Incorporating both of them
can further improve the performance of deep features, when
the example-level and concept-level distributions are differ-
ent from these of the benchmark data set.

Methods
SVMERM
SVMEL
SVMCL
SVMHRRL

Acc(mean±std)
63.23±0.35
65.01±0.37
65.47±0.27
67.33±0.39

Table 4. Comparison of accuracy (%) on SVHN.

4.4. Fine-tuning

Besides extracting features, a pre-trained model is often
applied as an initialization for training DNNs on the target
task when GPUs are available. Since initialization is crucial
for the ﬁnal performance of DNNs [26], we conduct the ex-
periments that initialize the model with parameters trained
on ImageNet and then ﬁne-tune the model on CIFAR-10,
SOP and SVHN. After initialization, the model is ﬁne-tuned
with 100 epochs, where ERM is adopted as the objective
for each task. The learning rate is set as 0.01 and decayed
once by a factor of 10 after 50 epochs. Fig. 3 illustrates the
curve of test error. We let “ERM” denote the model initial-
ized with that pre-trained with ERM and “Robust” denote
the one initialized with the model pre-trained with the pro-
posed algorithm. Surprisingly, we observe that the models
initialized with the proposed algorithm still surpass those
with ERM. It implies that the learned robust models can be
used for initialization besides feature extraction.

4.5. Effect of Robustness

Finally, we investigate the effect of the proposed method
on ImageNet task itself to further illustrate the impact of ro-
bustness. First, we demonstrate the results of example-level
robustness. We generate the augmented examples for vali-

(a) CIFAR-10

(b) SOP
Figure 3. Comparison of ﬁne-tuning with different initializations.

(c) SVHN

dation set as in Theorem 2 and report the accuracy of differ-
ent models in Fig. 4. The horizontal axis shows the step size
for generating the augmented examples. When step size is
0, the original validation set is used for evaluation. Other-
wise, each image in the validation set is modiﬁed with the
corresponding step size, and only modiﬁed images are used
for evaluation.
Intuitively, larger step size implies larger
example-level distribution change compared to the original
ImageNet data set.

distribution of examples and ignores the distribution of con-
cepts. Consequently, certain concept, e.g., “bird”, has much
higher accuracy than others. When decreasing λ in our pro-
posed method, the freedom of adversarial distribution in-
creases. With more freedom, the proposed method will fo-
cus on the concepts with bad performance. By optimizing
the adversarial distribution, the model will balance the per-
formance between different concepts as illustrated in Fig. 5.

Figure 4. Comparison of accuracy on augmented examples.

Besides ERM, four different models are included in the
comparison. Each model is trained with the example-level
robustness and the corresponding parameter τ is denoted in
the legend, where larger τ should theoretically provide a
more robust model.

We can observe that ERM performs well when there is
no augmentation but its performance degrades signiﬁcantly
when the augmentation step size increases. It conﬁrms that
ERM cannot generalize well when the example-level dis-
tribution changes. Fortunately, we can observe that more
robust models (i.e., τ increases) can provide better gener-
alization performance as expected.
It is because that the
proposed algorithm focuses on optimizing the worst-case
performance among different distributions derived from the
original distribution.

Second, we show the inﬂuence of concept-level robust-
ness. We train models with different λ for regularization
and summarize the accuracy of concepts in Fig. 5. We sort
the accuracy in ascending order to make the comparison
clear. As illustrated, ERM aims to optimize the uniform

Figure 5. Comparison of accuracy on concepts in ImageNet.

In summary, Figs. 4 and 5 demonstrate the different in-
ﬂuences of example-level and concept-level robustness. Ev-
idently, our method can deal with the perturbation from dif-
ferent aspects. It further conﬁrms that improving the hierar-
chical robustness is important for applying deep features or
initializing models in real-world applications.

5. Conclusion

In this work, we study the problem of learning deep fea-
tures using a benchmark data set for generic tasks. We pro-
pose a hierarchically robust optimization algorithm to learn
robust representations from a large-scale benchmark data
set. The theoretical analysis also demonstrates the impor-
tance of augmentation when training DNNs. The exper-
iments on real-world data sets demonstrate the effective-
ness of the learned features from the proposed method. The
framework can be further improved when side information
is available. For example, given the concepts of the target
domain, we can obtain the speciﬁc reference distribution q0
accordingly, and then learn the features for the desired task.
This direction can be our future work.

References

[1] Aharon Ben-Tal, Laurent El Ghaoui, and Arkadi Ne-
mirovski. Robust optimization, volume 28. Princeton
University Press, 2009.

[2] Liefeng Bo, Xiaofeng Ren, and Dieter Fox. Kernel
descriptors for visual recognition. In NeurIPS, pages
244–252, 2010.

[3] Olivier Bousquet and Andr´e Elisseeff. Stability and
Journal of Machine Learning Re-

generalization.
search, 2:499–526, 2002.

[4] Chih-Chung Chang and Chih-Jen Lin. LIBSVM: A li-
brary for support vector machines. ACM Transactions
on Intelligent Systems and Technology, 2:27:1–27:27,
2011.

[5] Robert S. Chen, Brendan Lucier, Yaron Singer, and
Robust optimization for non-
In NeurIPS, pages 4708–4717,

Vasilis Syrgkanis.
convex objectives.
2017.

[6] Corinna Cortes and Vladimir Vapnik. Support-vector
networks. Machine Learning, 20(3):273–297, 1995.

[7] Navneet Dalal and Bill Triggs. Histograms of oriented
gradients for human detection. In CVPR, pages 886–
893, 2005.

[8] Jeff Donahue, Yangqing Jia, Oriol Vinyals, Judy Hoff-
man, Ning Zhang, Eric Tzeng, and Trevor Darrell.
Decaf: A deep convolutional activation feature for
generic visual recognition. In ICML, pages 647–655,
2014.

[9] John C. Duchi, Shai Shalev-Shwartz, Yoram Singer,
and Tushar Chandra. Efﬁcient projections onto the l1-
ball for learning in high dimensions. In ICML, pages
272–279, 2008.

[10] Christine Fellbaum. 1998, wordnet: An electronic lex-

ical database, 1998.

[11] Ian J. Goodfellow, Jonathon Shlens, and Christian
Szegedy. Explaining and harnessing adversarial ex-
amples. In ICLR, 2015.

[12] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian
Sun. Deep residual learning for image recognition. In
CVPR, pages 770–778, 2016.

[13] Sergey Ioffe and Christian Szegedy. Batch normal-
ization: Accelerating deep network training by reduc-
ing internal covariate shift. In ICML, pages 448–456,
2015.

[14] Alex Krizhevsky. Learning multiple layers of features

from tiny images. 2009.

[15] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hin-
ton. Imagenet classiﬁcation with deep convolutional
neural networks. In NeurIPS, pages 1106–1114, 2012.

[16] David G. Lowe. Distinctive image features from scale-
International Journal of Com-

invariant keypoints.
puter Vision, 60(2):91–110, 2004.

[17] Romain Mormont, Pierre Geurts, and Rapha¨el Mar´ee.
Comparison of deep transfer learning strategies for
digital pathology. In CVPR Workshops, pages 2262–
2271, 2018.

[18] Hongseok Namkoong and John C. Duchi. Stochas-
tic gradient methods for distributionally robust opti-
mization with f-divergences. In NeurIPS, pages 2208–
2216, 2016.

[19] Yuval Netzer, Tao Wang, Adam Coates, Alessandro
Bissacco, Bo Wu, and Andrew Y Ng. Reading digits
in natural images with unsupervised feature learning.
2011.

[20] Qi Qian, Rong Jin, Shenghuo Zhu, and Yuanqing
Lin. Fine-grained visual categorization via multi-stage
metric learning. In CVPR, pages 3716–3724, 2015.

[21] Shaoqing Ren, Kaiming He, Ross B. Girshick, and
Jian Sun. Faster R-CNN: towards real-time object de-
IEEE Trans.
tection with region proposal networks.
Pattern Anal. Mach. Intell., 39(6):1137–1149, 2017.

[22] Olga Russakovsky, Jia Deng, Hao Su, Jonathan
Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang,
Andrej Karpathy, Aditya Khosla, Michael Bernstein,
Alexander C. Berg, and Li Fei-Fei. ImageNet Large
International
Scale Visual Recognition Challenge.
Journal of Computer Vision, 115(3):211–252, 2015.

[23] Karen Simonyan and Andrew Zisserman. Very deep
convolutional networks for large-scale image recogni-
tion. In ICLR, 2015.

[24] Aman Sinha, Hongseok Namkoong, and John Duchi.
Certiﬁable distributional robustness with principled
adversarial training. In ICLR, 2018.

[25] Hyun Oh Song, Yu Xiang, Stefanie Jegelka, and Silvio
Savarese. Deep metric learning via lifted structured
feature embedding. In CVPR, 2016.

[26] Ilya Sutskever, James Martens, George E. Dahl, and
Geoffrey E. Hinton. On the importance of initializa-
tion and momentum in deep learning. In ICML, pages
1139–1147, 2013.

[27] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Ser-
manet, Scott E. Reed, Dragomir Anguelov, Dumitru
Erhan, Vincent Vanhoucke, and Andrew Rabinovich.
Going deeper with convolutions. In CVPR, pages 1–9,
2015.

[28] Bolei Zhou,

`Agata Lapedriza, Jianxiong Xiao, An-
tonio Torralba, and Aude Oliva. Learning deep fea-
tures for scene recognition using places database. In
NeurIPS, pages 487–495, 2014.

A. Proof of Theorem 1

According to the smoothness, we have

Proof. Due to the smoothness, we have

(cid:96)(ˆxi, yi; θ) −

(cid:107)ˆxi − xi(cid:107)2 ≤ (cid:96)(˜xi, yi; θ) + (cid:104)∇˜xi(cid:96), ˆxi − ˜xi(cid:105)

λw
2

(cid:96)(ˆxi, yi; θ) ≤ (cid:96)(xi, yi; θ)+(cid:104)∇xi(cid:96), ˆxi−xi(cid:105)+

Lx
2

(cid:107)ˆxi−xi(cid:107)2
F

So

λw
2

−

λw − Lx
2

(cid:107)ˆxi − xi(cid:107)2
F

(cid:96)(ˆxi, yi; θ) −

(cid:107)ˆxi − xi(cid:107)2

F ≤ (cid:96)(xi, yi; θ) + (cid:104)∇xi(cid:96), ˆxi − xi(cid:105)

When λw is sufﬁciently large as λw > Lx, R.H.S. is
bounded and

(cid:96)(ˆxi, yi; θ) −

λw
2

(cid:107)ˆxi − xi(cid:107)2
F

1
2(λw − Lx)

≤ (cid:96)(xi, yi; θ) +

(cid:107)∇xi (cid:96)(cid:107)2
F

Since ∇x(cid:96)(·) is Lθ-Lipschitz continuous, we have

(cid:107)∇x(cid:96)(x; θ)(cid:107)2

F ≤ 2(cid:107)∇x(cid:96)(x; θ) − ∇x(cid:96)(x; 0)(cid:107)2
F
+2(cid:107)∇x(cid:96)(x; 0)(cid:107)2
F
F + 2(cid:107)∇x(cid:96)(x; 0)(cid:107)2
F

≤ 2L2

θ(cid:107)θ(cid:107)2

Note that (cid:107)∇x(cid:96)(x; 0)(cid:107)F = 0 in many convolutional neu-
ral networks. The bound can be improved and the original
subproblem can be bounded as

+

Lx
2

(cid:107)ˆxi − ˜xi(cid:107) −

(cid:107)ˆxi − xi(cid:107)2

λw
2

= (cid:96)(˜xi, yi; θ) + (cid:104)∇˜xi(cid:96) − τ Lxzi, ˆxi − xi(cid:105) − τ (cid:104)∇˜xi(cid:96), zi(cid:105)

+

Lxτ 2
2

(cid:107)zi(cid:107)2 −

λw − Lx
2

(cid:107)ˆxi − xi(cid:107)2

(cid:107)∇˜xi(cid:96) − τ Lxzi(cid:107)2
F
2(λw − Lx)

− τ (cid:104)∇˜xi(cid:96), zi(cid:105)

(cid:107)∇˜xi (cid:96)(cid:107)2
F
2(λw − Lx)

− τ (cid:104)∇˜xi (cid:96), zi(cid:105))

≤ (cid:96)(˜xi, yi; θ) +

+

Lxτ 2
2

(cid:107)zi(cid:107)2
F

= (cid:96)(˜xi, yi; θ) +

(

+

λw
λw − Lx
≤ (cid:96)(˜xi, yi; θ) +

(

+

λw
λw − Lx
≤ (cid:96)(˜xi, yi; θ) +

(

+

λw
λw − Lx
≤ (cid:96)(˜xi, yi; θ) +

τ 2Lx(cid:107)zi(cid:107)2
F
2
γ
(cid:107)θ(cid:107)2
F
2
τ 2Lx(cid:107)zi(cid:107)2
F
2
γ
(cid:107)θ(cid:107)2
F
2
τ 2Lx(cid:107)zi(cid:107)2
F
2
(cid:107)θ(cid:107)2
F

γ
2

+

λw
λw − Lx

(

3τ 2Lx(cid:107)zi(cid:107)2
F
2

− τ (cid:104)∇xi(cid:96), zi(cid:105))

= (cid:96)(˜xi, yi; θ) +

(cid:107)θ(cid:107)2

F −

γ
2

λw
λw − Lx

(cid:104)∇xi(cid:96), zi(cid:105)2
6Lx(cid:107)zi(cid:107)2
F

The last equation is from setting τ to optimum as

τ =

(cid:104)∇xi(cid:96), zi(cid:105)
3Lx(cid:107)zi(cid:107)2
F

− τ (cid:104)∇˜xi (cid:96) − ∇xi(cid:96), zi(cid:105) − τ (cid:104)∇xi(cid:96), zi(cid:105))

+ τ (cid:107)∇˜xi (cid:96) − ∇xi(cid:96)(cid:107)(cid:107)zi(cid:107) − τ (cid:104)∇xi(cid:96), zi(cid:105))

max
ˆxi∈X

(cid:96)(ˆxi, yi; θ) −

λw
2

(cid:107)ˆxi − xi(cid:107)2

F ≤ (cid:96)(xi, yi; θ) +

(cid:107)θ(cid:107)2
F

γ
2

C. Proof of Theorem 3

Proof. For an arbitrary distribution q, we have

where γ = L2

θ
λw−Lx

.

B. Proof of Theorem 2

Proof. We consider the augmented examples as

2] = E[(cid:107)P∆(qt + ηtgt) − q(cid:107)2
2]

E[(cid:107)qt+1 − q(cid:107)2
≤ E[(cid:107)qt + ηtgt − q(cid:107)2
2]
= E[(cid:107)qt − q(cid:107)2
≤ E[(cid:107)qt − q(cid:107)2

2 + 2ηt(qt − q)(cid:62)gt + η2
2 + η2

t µ2

t (cid:107)gt(cid:107)2
2]

+ 2ηt(L(qt, θt) − L(q, θt) −

(cid:107)qt − q(cid:107)2

2)]

λ
2

˜xi = xi + τ zi

The last inequality is from the fact that the objective is λ-
strongly concave in q and the observed gradient is unbiased.

E[(cid:107)qt − q(cid:107)2

2] − E[(cid:107)qt+1 − q(cid:107)2
2]

2ηt

Therefore, we have

E[L(q, θt) − L(qt, θt)] ≤

−

(cid:107)qt − q(cid:107)2

2 +

ηt
2

µ2

When ηt = 1

λt , we have

−

(cid:107)qt − q(cid:107)2

2 +

1
2λt

µ2

When ηt = 1

λtc , we have

−

(cid:107)qt − q(cid:107)2

2 +

1
2λtc

µ2

λ
2

λ
2

λ
2

λt
2

λtc
2

E[L(q, θt) − L(qt, θt)] ≤

(E[(cid:107)qt − q(cid:107)2

2] − E[(cid:107)qt+1 − q(cid:107)2

2])

E[L(q, θt) − L(qt, θt)] ≤

(E[(cid:107)qt − q(cid:107)2

2] − E[(cid:107)qt+1 − q(cid:107)2

2])

T
(cid:88)

t

+

≤

T
(cid:88)

t=s+1

s
(cid:88)

t=1

(cid:0)(

cλ
2

We assume that ηt = 1

cλt and c > 1 for the ﬁrst s itera-

tions and then ηt = 1

λt . So we have

E[L(q, θt) − L(qt, θt)] =

E[L(q, θt) − L(qt, θt)]

s
(cid:88)

t=1

E[L(q, θt) − L(qt, θt)]

−

)E[(cid:107)qt − q(cid:107)2

2] +

λ
2

1
2λtc

µ2(cid:1) +

T
(cid:88)

t=s+1

1
2λt

µ2

≤ sλ(c − 1) +

log(s)(

− 1) +

(log(T ) + 1)

1
c

µ2
2λ
(cid:113) log(s)
2s

µ2
2λ

By setting c = µ
λ

and q to be optimum, we have

E[L(q∗, θt) − L(qt, θt)] ≤ µ(cid:112)2s log(s) − sλ

T
(cid:88)

max
q∗∈∆

t
µ2 log(s)
2λ

−

µ2
2λ

+

(log(T ) + 1)

µ2
2λ

=

(log(T ) + 1) − (µ

(cid:114)

log(s)
2λ

√

−

sλ)2

