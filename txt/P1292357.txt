Open Category Detection with PAC Guarantees

Si Liu * 1 Risheek Garrepalli * 2 Thomas G. Dietterich 2 Alan Fern 2 Dan Hendrycks 3

8
1
0
2
 
g
u
A
 
1
 
 
]

G
L
.
s
c
[
 
 
1
v
9
2
5
0
0
.
8
0
8
1
:
v
i
X
r
a

Abstract
Open category detection is the problem of detect-
ing “alien” test instances that belong to categories
or classes that were not present in the training
In many applications, reliably detecting
data.
such aliens is central to ensuring the safety and
accuracy of test set predictions. Unfortunately,
there are no algorithms that provide theoretical
guarantees on their ability to detect aliens under
general assumptions. Further, while there are al-
gorithms for open category detection, there are
few empirical results that directly report alien de-
tection rates. Thus, there are signiﬁcant theoret-
ical and empirical gaps in our understanding of
open category detection. In this paper, we take
a step toward addressing this gap by studying a
simple, but practically-relevant variant of open
category detection. In our setting, we are pro-
vided with a “clean” training set that contains
only the target categories of interest and an un-
labeled “contaminated” training set that contains
a fraction α of alien examples. Under the as-
sumption that we know an upper bound on α, we
develop an algorithm with PAC-style guarantees
on the alien detection rate, while aiming to mini-
mize false alarms. Empirical results on synthetic
and standard benchmark datasets demonstrate the
regimes in which the algorithm can be effective
and provide a baseline for further advancements.

1. Introduction

Most machine learning systems implicitly or explicitly as-
sume that their training experience is representative of their
test experience. This assumption is rarely true in real-world
deployments of machine learning, where “unknown un-
knowns”, or “alien” data, can arise without warning. Ig-

*Equal contribution 1Department of Statistics, Oregon State
University, Oregon, USA 2School of EECS, Oregon State Univer-
sity, Oregon, USA 3University of California, Berkeley, California,
USA. Correspondence to: Si Liu <lius2@oregonstate.edu>.

Proceedings of the 35 th International Conference on Machine
Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018
by the author(s).

noring the potential for such aliens can lead to serious safety
concerns in many applications and signiﬁcantly degrade
the accuracy of test set predictions in others. For exam-
ple, consider a scientiﬁc application where a classiﬁer is
trained to recognize speciﬁc categories of insects in fresh-
water samples in order to detect important environmental
changes (Lytle et al., 2010). Test samples will typically
contain some fraction of specimens belonging to species
not represented in the training data. A classiﬁer that is un-
aware of these new species will misclassify the specimens
as belonging to existing species. This will produce incorrect
scientiﬁc conclusions.

The problem of open category detection is to detect such
alien examples at test time. An ideal algorithm for this prob-
lem would guarantee a user-speciﬁed alien-detection rate
(e.g., 95%), while attempting to minimize the false alarm
rate. Unfortunately, no existing algorithm provides such
guarantees under general conditions. In addition, empir-
ical evaluations of existing algorithms for open category
detection typically do not directly evaluate alien detection
rates, which are perhaps the most relevant for safety-critical
applications. Overall, our current theoretical and practical
understanding of open category detection is lacking from a
safety and accuracy perspective.

Is it possible to achieve open category detection with guar-
antees? In this paper, we take a step toward answering
this question by studying a simpliﬁed, but practically rel-
evant, problem setting. To motivate our setting, consider
the above insect identiﬁcation problem. At training time it
is reasonable to expect that a clean training set is available
that contains only the insect categories of interest. At test
time, a new sample will include insects from the training
categories along with some percentage of insects from new
alien categories. Further, scientists may have reasonable
estimates for this percentage based on their scientiﬁc knowl-
edge and practical experience. We would like to guarantee
that the system is able to raise an alarm for, say, 95% of the
insects from alien classes, with each alarm being examined
by a scientist. At the same time, we would like to avoid as
many “false alarms” as possible, since each alarm requires
scientist effort.

To formalize the example, our setting assumes two training
sets: a clean training dataset involving a ﬁnite set of cate-

Open Category Detection with PAC Guarantees

gories and a contaminated dataset that contains a fraction α
of aliens. Our ﬁrst contribution is to show that, in this setting,
theoretical guarantees are possible given knowledge of an
upper bound on α. In particular, we give an algorithm that
uses this knowledge to provide Probably Approximately
Correct (PAC) guarantees for achieving a user-speciﬁed
alien detection rate. While knowledge of a non-trivial upper
bound on α may not always be possible, in many situations
it will be possible to select a reasonable value based on
domain knowledge, prior data, or by inspecting a sample of
the test data.

The key idea behind our algorithm is to leverage modern
anomaly detectors, which are trained on the clean data. Our
algorithm combines the anomaly-score distributions over
the clean and contaminated training data in order to derive
an alarm threshold that achieves the desired guarantee on
the alien detection rate on new test queries. In theory the
detection rate guarantee will be met regardless of the quality
of the anomaly detector. The quality of the detector, how-
ever, has a signiﬁcant impact on the false alarm rate, with
better detectors leading to fewer false alarms.

We carry out experiments1 on synthetic and benchmark
datasets using a state-of-the-art anomaly detector, the Iso-
lation Forest (Liu et al., 2008). We vary the amount of
training data, the fraction α of alien data points, along with
the accuracy of the upper bound on α provided to our algo-
rithm. The results indicate that our algorithm can achieve
the guaranteed performance when enough data is available,
as predicted by the theory. The results also show that for
the considered benchmarks, the Isolation Forest anomaly
detector is able to support non-trivial false positive rates
given enough data. The results also illustrate the inherent
difﬁculty of the problem for small datasets and/or small
values of α. Overall, our results provide a useful baseline
for driving future work on open category detection with
guarantees.

2. Related Work

Open category detection is related to the problem of one-
class classiﬁcation, which aims to detect outliers relative
to a single training class. One-class SVMs (OCSVMs)
(Sch¨olkopf et al., 2001) are popular for this problem. How-
ever, they have been found to perform poorly for open
category detection due to poor generalization (Zhou &
Huang, 2003), which has been partly addressed by later
work (Manevitz & Yousef, 2002; Wu & Ye, 2009; Jin et al.,
2004; Cevikalp & Triggs, 2012). OCSVMs have been em-
ployed in a multi-class setting similar to open category de-
tection (Heﬂin et al., 2012; Pritsos & Stamatatos, 2013).

1Code for reproducing our experiments can be found at

https://github.com/liusi2019/ocd.

However, there are no direct mechanisms to control the alien
detection rate of these methods, which is a key requirement
for our problem setting.

Work on classiﬁcation with rejection/abstaining options
(Chow, 1970; Wegkamp, 2007; Tax & Duin, 2008;
Pietraszek, 2005; Geifman & El-Yaniv, 2017) allows classi-
ﬁers to abstain from making predictions when they are not
conﬁdent. While loosely related to open category detection,
these approaches do not directly consider the possibility of
novel categories, but rather focus on assessing conﬁdence
with respect to the known categories. Due to their closed-
world discriminative nature, it is easy to construct scenarios
where such methods are incorrectly conﬁdent about the class
of an alien and do not abstain.

A variety of prior work has addressed variants of open cat-
egory detection. This includes work on formalizing the
concept of “open space” to characterize the region of the fea-
ture space outside of the support of the training set (Scheirer
et al., 2013). Variants of SVMs have also been developed,
such as the One-vs-Set Machine (Scheirer et al., 2013) and
the Weibull-calibrated SVM (Scheirer et al., 2014). Ad-
ditional work has addressed open category detection by
tuning the decision boundary based on unlabeled data which
contains data from novel categories (Da et al., 2014). Ap-
proaches based on nearest neighbor methods have also been
proposed (Mendes J´unior et al., 2017). None of these meth-
ods, however, allow for the direct control of alien detection
rates, nor do they provide theoretical guarantees.

There is also recent interest in open category detection for
deep neural networks applied to vision and text classiﬁcation
(Bendale & Boult, 2016; Shu et al., 2017). These methods
usually train a neural network in a standard closed-world
setting, but then analyze various activations in the network
in order to detect aliens. Another related line of work is
detection of out-of-distribution instances, which is similar
to open category detection but assumes that the test data
come from a completely different distribution compared to
the training distribution (Hendrycks & Gimpel, 2017; Liang
et al., 2018). All of this work is quite specialized to deep
neural networks and does not provide direct control of alien
detection rates or theoretical guarantees.

3. Problem Setup

We consider open category detection where there is an un-
known nominal data distribution D0 over labeled examples
from a known set of category labels. We receive as input
a “clean” nominal training set S0 containing k i.i.d. draws
from D0. In practice, S0 will correspond to some curated
labeled data that contains only known categories of interest.

We also receive as input an unlabeled “mixture” dataset
Sm that contains n points drawn i.i.d. from a mixture dis-

Open Category Detection with PAC Guarantees

tribution Dm. Speciﬁcally, the mixture distribution Dm is
a combination of the nominal distribution D0 and an un-
known alien distribution Da, which is a distribution over
novel categories (alien data points). We assume that Da is
stationary, so that all alien points that appear as future test
queries will also be drawn from Da.

At training time, we assume that Dm is a mixture distribu-
tion, with probability α of generating an alien data point
from Da and probability of 1 − α of generating a nominal
point. Our results hold even if the test queries come from a
mixture with a different value of α as long as the alien test
points are drawn from Da.

Given these datasets, our problem is to label test instances
from Dm as either “alien” or “nominal”. In particular, we
wish to achieve a speciﬁed alien detection rate, which is
the fraction of alien data points in Dm that are classiﬁed as
“alien” (e.g., 95%). At the same time we would like the false
positive rate to be small, which is the fraction of nominal
data points incorrectly classiﬁed as aliens.

Our approach to this problem assumes the availability of an
anomaly detector that is trained on S0 and assigns anomaly
scores to all data points in both S0 and Sm. Intuitively, the
anomaly scores order the test examples according to how
anomalous they appear relative to the nominal data (higher
scores being more anomalous). An ideal detector would
rank all alien data points higher than all nominals, though
in practice, the ordering will not be so clean. Our approach
labels data in Sm by selecting a threshold on the anomaly
scores and labeling all data points with scores above the
threshold as aliens and the remaining points as nominals.
Our key challenge is to select a threshold that provides a
guarantee on the alien detection rate.

4. Algorithms for Open Category Detection

In order to obtain theoretical guarantees, our algorithm as-
sumes knowledge of the alien mixture probability α that
generates the mixture data Sm. Later, we will show that
knowing an upper bound on α is sufﬁcient to obtain a guar-
antee.

Our approach is based on considering the cumulative dis-
tribution functions (CDFs) over anomaly scores of a ﬁxed
anomaly detector. Let F0, Fa, and Fm be the CDFs of
anomaly scores for the nominal data distribution D0, alien
distribution Da, and mixture distribution Dm respectively.
Since Dm is a simple mixture of D0 and Da, we can write
Fm as

Fm(x) = (1 − α)F0(x) + αFa(x).

From this we can derive the CDF for Fa in terms of Fm and
F0:

Fa(x) =

Fm(x) − (1 − α)F0(x)
α

.

Given the ability to derive Fa, it is straightforward to achieve
an alien detection rate of 1 − q (e.g. 95%) by selecting an
anomaly score threshold τq that is the q quantile of Fa and
raising an alarm on all test queries whose anomaly score is
greater than τq.

In reality, we do not have access to Fm or F0 and hence
cannot exactly determine Fa. Rather, we have samples
Sm and S0. Thus, our algorithm works with the empirical
CDFs ˆF0 and ˆFm, which are simple step-wise constant
approximations, and estimates an empirical CDF over aliens:

ˆFa(x) =

ˆFm(x) − (1 − α) ˆF0(x)
α

.

(1)

Our algorithm computes the above estimate of ˆFa and uses
it to select a threshold ˆτq to be the largest threshold such
that ˆFa(ˆτq) ≤ q, where 1 − q is the target alien detection
rate. This choice will minimize the number of false alarms.
The steps of this algorithm are as follows.

Algorithm 1
1: Get anomaly scores for all points in S0 and Sm, denoted

x1, x2, . . . , xk and y1, y2, . . . , yn respectively.

2: Compute empirical CDFs ˆF0 and ˆFm.
3: Calculate ˆFa using equation 1.
4: Output detection threshold

ˆτq = max{u ∈ S : ˆFa(u) ≤ q},

where S = {x1, x2, . . . , xk, y1, y2, . . . , yn}.

Although ˆFm and ˆF0 are both legal CDFs, the estimate
for ˆFa from step 3 may not be a legal CDF, because it is
the difference of two noisy estimates—it may not increase
monotonically and it may even be negative. A good tech-
nique for dealing with this problem is to employ isotoniza-
tion (Barlow & Brunk, 1972) and clipping. Isotonization
ﬁnds the monotonically increasing function ˆF ∗
a closest to
ˆFa in squared error. To convert ˆFa into a legal CDF, deﬁne
ˇFa = min{max{ ˆF ∗
a , 0}, 1}, where the min and max opera-
tors are applied pointwise to their arguments. We performed
experiments (shown in the supplementary materials) to test
whether using ˇFa in Step 4 would improve the performance
of the overall algorithm. We found that it did not.

5. Finite Sample Guarantee

In the limit of inﬁnite data (both nominal and mixture) and
perfect knowledge of α, ˆFa will converge to the true alien
CDF, and our algorithm will achieve the desired alien de-
tection rate. In this section, we consider the ﬁnite data case
where |S0| = |Sm| = n. We derive a value for the sample
size n that guarantees with high probability over random

Open Category Detection with PAC Guarantees

draws of S0 and Sm, that fraction 1 − q − (cid:15) of the alien
test points will be detected, where (cid:15) is an additional error
incurred because of the ﬁnite sample size n.

Our key theoretical tool is a ﬁnite sample result on the
uniform convergence of empirical CDF functions (Massart,
1990). To use this result, we make the reasonable technical
assumption that the nominal and alien CDFs, F0 and Fa,
are continuous. In the following, let η be the target alien
detection rate, q be the input to Algorithm 1, ˆτq be the
estimated q-quantile of the alien CDF (step 4 of Alg. 1),
and (cid:15) be an error parameter. The following theorem gives
the sample complexity for guaranteeing that 1 − η of the
alien examples will be detected using threshold ˆτq.
Theorem 1. Let S0 and Sm be nominal and mixture
datasets containing n i.i.d. samples from the nominal and
mixture data distributions respectively. For any (cid:15) ∈ (0, 1−q)
and δ ∈ (0, 1), if

n >

ln

1
2

2
√
1 − δ

(cid:18) 1
(cid:15)

1 −

(cid:19)2 (cid:18) 2 − α

(cid:19)2

,

α

the alien CDF will typically concentrate more mass toward
larger anomaly score values compared to F0. Indeed, if this
is not the case, there is little hope since there is effectively
no signal to distinguish between aliens and nominals.

Corollary 1. Consider running Algorithm 1 using an upper
bound α(cid:48) on the true α. Under the same assumptions as
Theorem 1, if the anomaly detector is admissible and

n >

ln

1
2

2
√
1 − δ

(cid:18) 1
(cid:15)

1 −

(cid:19)2 (cid:18) 2 − α(cid:48)

(cid:19)2

,

α(cid:48)

then with probability at least 1 − δ, Algorithm 1 will return
a threshold ˆτq that achieves an alien detection rate of at
least 1 − η, where η = q + (cid:15).

The proof is in the Appendix. While we can achieve a guar-
antee using an upper bound on α(cid:48), the returned threshold
will be more conservative (smaller) than if we had used the
true α. This will result in higher false alarm rates, since
more nominal points will be above the threshold. Thus it is
desirable to use a value of α(cid:48) that is as close to α as possible.

then with probability at least 1 − δ, Algorithm 1 will return
a threshold ˆτq that achieves an alien detection rate of at
least 1 − η, where η = q + (cid:15).

6. Experiments

(cid:15)2α2 log 1

The proof is in the Appendix. Note that n grows as
O( 1
δ ). Hence, this guarantee is polynomial in all
relevant parameters, which we believe is the ﬁrst such guar-
antee for open category detection. The result can be gener-
alized to the case where n0 < nm; in practice, the larger
the mixture sample Sm is, the easier it is to estimate τq,
because this provides more alien points for estimating the
q-th quantile of Fa.

The theorem gives us ﬂexibility in setting (cid:15) and q (the algo-
rithm input) to achieve a guarantee of 1−η. The (cid:15) parameter
controls a trade-off between sample size and false alarm rate.
To minimize the false alarm rate, we want to make q large
(to obtain a larger threshold), so we want to set q close to η.
But, as q → η, (cid:15) → 0, and n → ∞. To minimize the sample
size n, we want to make q as small as possible, because that
allows (cid:15) to be larger and hence n becomes smaller. The
optimal setting of (cid:15) depends on how the false alarm rate
grows with τq, which in turn depends on the relative shape
of F0 and Fa. In a real safety application, we can estimate
these from S0 and Sm and choose an appropriate q value.

What if we don’t know the exact value of α? If our algorithm
uses an upper bound α(cid:48) on the true α to compute ˆFa, we
can still provide a guarantee. In this case, in addition to the
assumptions in Theorem 1, we need a concept of an anomaly
detector being admissible. We say that an anomaly detector
is admissible for a problem, if the anomaly score CDFs
satisfy F0(x) ≥ Fm(x) for all x ∈ R. Most reasonable
anomaly detectors will be admissible in this sense, since

We performed experiments to answer four questions. Ques-
tion Q1: how accurate is our estimate of ˆτq as a function of
n and α? Question Q2: how loose are the bounds from The-
orem 1? Question Q3: what are typical values of the false
alarm rates for various settings of n and α on real datasets?
Question Q4: how do these observed values change if we
employ an overestimate α(cid:48) > α?

All of our experiments employ the Isolation Forest anomaly
detector (Liu et al., 2008), which has been demonstrated
to be a state-of-the-art detector in recent empirical studies
In the Supplementary Materials
(Emmott et al., 2013).
we show similar results with the LODA anomaly detector
(Pevn´y, 2015).

To address Q1 and Q2, we run controlled experiments
on synthetic data. The data points are generated from 9-
dimensional normal distributions. The dimensions of the
nominal distribution D0 are independently distributed as
N (0, 1). The alien distribution is similar, but with probabil-
ity 0.4, 3 of the 9 dimensions (chosen uniformly at random)
are distributed as N (3, 1) and with probability 0.6, 4 of the
9 dimensions (chosen uniformly at random) follow N (3, 1).
This ensures that the anomalies are not highly similar to
each other and models the situation in which there are many
different kinds of alien objects, not just a single alien class
forming a tight cluster.

In each experiment, the nominal dataset and the mixture
dataset are of the same size n, and the mixture dataset
contains a proportion α of anomaly points. We ﬁxed
the target quantile to be q = 0.05. The experiments are

Open Category Detection with PAC Guarantees

Figure 1. Comparison of recall achieved by ˆτq compared to oracle
recall of 0.95. Error bars are 95% conﬁdence intervals. Settings
of n and α increase from left to right starting with α = 0.01 and
n ∈ {100, 500, 1K, 5K, 10K} up to α = 0.5 and n = 10K.

carried out for n ∈ {100, 500, 1K, 5K, 10K} and α ∈
{0.01, 0.05, 0.10, 0.20, 0.50}. For testing, we create two
large datasets G0 and Ga, with G0 being a pure nominal
dataset, Ga being a pure alien dataset, and |G0| = |Ga| =
20K. The Isolation Forest algorithm computes 1000 full
depth isolation trees on the nominal data. Each tree is grown
on a randomly-selected 20% subsample of the clean data
points. We compute anomaly scores for the nominal points
via out-of-bag estimates and anomaly scores for the mix-
ture points, G0, and Ga using the full isolation forest. For
each combination of n and α, we repeat the experiment
100 times. We measure the fraction of aliens detected (the
“recall”) and the fraction of nominal points declared to be
alien (the “false positive rate”) by applying the ˆτq estimate
to threshold the anomaly scores in G0 and Ga.

To assess the accuracy of our ˆτq estimates (Q1), we could
compare them to the true values. However, this comparison
is hard to interpret, because τ is expressed on the scale
of anomaly scores, which are somewhat arbitrary. Instead,
Figure 1 plots the recall achieved by ˆτq. If ˆτq had been
estimated perfectly, the recall would always be 1−q = 0.95.
However, we see that the recall is often less than 0.95, which
indicates that ˆτq is over-estimated, especially when n and α
are small. This behavior is predicted by our theory, where
we see that the sample size requirements grow inversely
with α2. For larger α and n, the recall guarantee is generally
achieved. Figure 2 compares the false positive rate of the
true oracle τq to the false positive rate of the estimate ˆτq. For
each combination of α and n, we have 100 replications of
the experiment and therefore 100 estimates ˆτa and 100 FPR
rates. For each of these, the true FPR is computed using G0.

Figure 2. Comparison of oracle FPR to the FPR achieved by ˆτq.
Error bars span from the 25th to 75th percentile with the blue dot
marking the median of the 100 trials. Orange markers indicate the
oracle FPR. Settings of n and α increase from left to right starting
with α = 0.01 and n ∈ {100, 500, 1K, 5K, 10K} up to α = 0.5
and n = 10K.

The error bars summarize the resulting 100 FPR values by
the median and inter-quartile range. We see that for small n
and α, the FPR can be quite different from the oracle rate,
but for larger n and α, the estimates are very good.

To assess the looseness of the bounds (Q2), for each combi-
nation of n and α, we ﬁx δ = 0.05 and compute the value
of η such that 95 of the 100 runs achieved a recall of at least
1 − η (thus η empirially achieves the 1 − δ guarantee). We
then compute (cid:15) = η − q and the corresponding required
sample size n∗ according to Theorem 1. Figure 3 shows a

Figure 3. The log sample size n∗ required by Theorem 1 in order
to guarantee the actual observed recall versus the log actual sample
size n.

Open Category Detection with PAC Guarantees

plot of n∗ versus the actual n. The distance of these points
from the n∗ = n diagonal line show that the theory is fairly
loose, although it becomes tighter as n gets large.

Figure 4. False positive rates on six UCI datasets as a function of
α (q = 0.05, δ = 0.05).

Benchmark Data Experiments. To address our third and
fourth questions, we performed experiments on six UCI
multiclass datasets: Landsat, Opt.digits, pageb, Shuttle,
Covertype and MNIST. In addition to these, we provide
results for the Tiny ImageNet dataset. In each multiclass
dataset, we split the classes into two groups: nominal and
alien. For Tiny ImageNet, we train a deep neural network
classiﬁer on 200 nominal classes and treat the remaining
800 as aliens. The nominal classes for UCI datasets are
MNIST(1,3,7), Landsat(1,7), OCR(1,3,4,5,7), pageb(1,5),
Letter recognition(1,3), and Shuttle(1,4). We generated

Figure 5. Recall rates on six UCI datasets as a function of α (q =
0.05, δ = 0.05)

Figure 6. False positive rates on two image datasets as a function
of α (q = 0.05, δ = 0.05).

nominal and mixture datasets for various values of α. The
value of n for each dataset is 1532 for Landsat,788 for Letter
recognition, 568 for OCR, 4912 for pageb, 5000 for Shuttle,
13,624 for Covertype, 11,154 for MNIST, and 10,000 for
Tiny ImageNet. Because we cannot create datasets with
large n, we cannot measure the true value of τq.

After computing the anomaly scores for both nominal and
mixture datasets, we applied Algorithm 1 within a 10-fold
cross validation. We divide the mixture data points at ran-
dom into 10 groups. For each fold, we estimate ˆFa and ˆτa
from 9 of the 10 groups and then score the mixture points in
the held-out fold according to ˆτa. In all other respects, the
experimental protocol is the same as for the synthetic data.
For Tiny ImageNet, the anomaly scores are obtained by
applying a baseline method (Hendrycks & Gimpel, 2017).

To answer Q3, Figures 4 and 6 plot the false positive rate as
a function of α for the UCI and vision datasets, respectively.
We see that the FPR ranges from 3.6% to 26.9% on UCI
depending on the dataset and the level of α. The vision
datasets have higher FPR, especially MNIST, which has a
large number of alien classes that are not distinguished well
by the anomaly detector. The FPR depends primarily on
the domain, because the key issue is how well the anomaly
detector distinguishes between nominal and alien examples.
The false alarm rate generally improves as α increases. In
some applications, it may be possible to enrich Sm so that
α is larger on the training set to take advantage of this
phenomenon. It is interesting to note that once ˆτa has been
computed, it can be applied to test datasets having different
(or unknown) values of α.

Figures 5 and 7 plot the recall rate as a function of α for
the UCI and vision datasets. We set q = 0.05 in these
experiments. Theorem 1 only guarantees a recall of 1−q −(cid:15),

Open Category Detection with PAC Guarantees

of α(cid:48) − α. Two points are plotted for each combination
of α(cid:48) and dataset, the change in Recall and the change in
FPR. We observe that the recall increases slightly (in the
range from 0.01 to 0.05). However, the false positive rate
increases by much larger amounts (from 0.01 to 0.336). This
demonstrates that it is very important to determine the value
of α accurately.

7. Summary

We have taken a step toward open category detection with
guarantees by providing a PAC-style guarantee on the prob-
ability of detecting 1 − η of the aliens on the test data. This
is the ﬁrst such guarantee under any similarly general con-
ditions. We have shown that this guarantee is satisﬁed in
our experiments, although the guarantee is somewhat loose,
especially on small training sets. Obtaining a guarantee re-
quires more data than standard PAC guarantees on expected
prediction accuracy. This is because we must estimate the
q quantile of the alien anomaly score distribution, where
q is typically quite small. Nonetheless, our experiments
show that our algorithm gives good recall performance and
non-trivial false alarm rates on datasets of reasonable size.

It is important to note that the very formulation of a PAC-
style guarantee on the probability of detecting aliens re-
quires assuming that the aliens are drawn from a well-
deﬁned distribution Da. While this is appropriate in some
applications, such as the insect survey application described
in the introduction, it is not appropriate for adversarial set-
tings. In such settings, a PAC-style guarantee does not make
sense, and some other form of safety guarantee needs to be
formulated.

To obtain the guarantee, we employ two training datasets:
a clean dataset that contains no aliens and an (unlabeled)
contaminated dataset that contains a known fraction α of
aliens. An important theoretical problem for future research
is to develop a method that can estimate a tight upper bound
on ˆα > α. We believe this is possible, but we have not yet
found a method that guarantees that ˆα > α.

Our guarantee requires more data as α becomes small. For-
tunately, when α is small, it may be possible in some appli-
cations to afford lower recall rates, since the frequency of
aliens will be smaller. However, in safety-critical applica-
tions where a single undetected alien poses a serious threat,
there is little recourse other than to collect more data or
allow for higher false positive rates.

Acknowledgements

This research was supported by a gift from Huawei, Inc.,
and grants from the Future of Life Institute and the NSF
Grant 1514550. Any opinions, ﬁndings, and conclusions

Figure 7. Recall rates on two image datasets as a function of α
(q = 0.05, δ = 0.05).

Figure 8. Change in recall and false positive rate as a function of
α(cid:48) − α for six UCI datasets; α ∈ {0.1, 0.2, 0.4}

where (cid:15) depends on n. Hence, it is nice to see that for
three of the domains (Shuttle, Covertype, and Landsat) in
UCI and for both vision datasets, the recall is very close to
1 − q = 0.95. These are the domains with the largest values
of n. The value of α has a bigger impact on recall than it
does on FPR. This is because the effective number of alien
training examples is αn, which can be very small for some
datasets when α = 0.1. This shows that in applications such
as fraud detection, where α may be very small, the mixture
dataset Sm needs to be very large.

To answer Q4 regarding the impact of using an incorrect
value α(cid:48) > α, we repeated these experiments with α(cid:48) =
α+ξ, for ξ ∈ {0.002, 0.004, 0.006, 0.008, 0.010}. Figure 8
plots the change in false positive rate and recall as a function

Open Category Detection with PAC Guarantees

or recommendations expressed in this material are those of
the author(s) and do not necessarily reﬂect the views of the
sponsors.

we will have

A. Proof for Theorem 1

Suppose there are n random variables which are i.i.d. from
the distribution with CDF F and let ˆFn be the empirical
CDF calculated from this sample. Then Massart (1990)
shows that

√

P (

n sup
x

| ˆFn(x) − F (x)| > λ) ≤ 2 exp(−2λ2)

(2)

holds without any restriction on λ. Making use of this,
and assuming we use the same sample size n for both the
mixture dataset and the clean data set, for any (cid:15) ∈ (0, 1 − q),
we seek to determine how large n needs to be in order to
guarantee that with probability at least 1 − δ our quantile
estimate ˆτq satisﬁes Fa(ˆτq) ≤ q + (cid:15). To achieve this, we
want to have

P (sup

| ˆFa(x) − Fa(x)| > (cid:15)) ≤ δ.

We have

x

x

x

x

x

1
2

P (sup

| ˆFa(x) − Fa(x)| > (cid:15))

= P (sup

|

ˆFm(x) − (1 − α) ˆF0(x)
α

−

Fm(x) − (1 − α)F0(x)
α
( ˆFm(x) − Fm(x)) −

| > (cid:15))

|

= P (sup

1
α

( ˆF0(x) − F0(x))| > (cid:15))

≤ P ((

| ˆFm(x) − Fm(x)| +

x
1 − α
α

1
α
1 − α
α

sup
x

sup
x

1
sup
α
x
1 − α
α

sup
x

∪ {

1
2 − α

(cid:15)}

1 − α
2 − α

(cid:15)})

≤ P ({

| ˆFm(x) − Fm(x)| >

= P ({sup

| ˆFm(x) − Fm(x)| >

∪ {sup

| ˆF0(x) − F0(x)| >

| ˆF0(x) − F0(x)| >
α
2 − α
α
2 − α

(cid:15)}

(cid:15)}).

| ˆF0(x) − F0(x)|) > (cid:15))

But

Making use of (2), when

n >

ln

2
√
1 − δ

(

1
(cid:15)

)2(

2 − α
α

)2,

1 −

P (sup

| ˆFm(x) − Fm(x)| >

(cid:15)) ≤ 1 −

1 − δ,

P (sup

| ˆF0(x) − F0(x)| >

(cid:15)) ≤ 1 −

1 − δ.

α
2 − α
α
2 − α

√

√

x

x

In this case we will have

P (sup

| ˆFa(x) − Fa(x)| > (cid:15))

x

≤ 1 − P ({sup

x

| ˆFm(x) − Fm(x)| ≤
α
2 − α

| ˆF0(x) − F0(x)| ≤

(cid:15)})

α
2 − α

(cid:15)}

∩ {sup

x
≤ 1 − (1 − 1 +

√

1 − δ)2

= δ.

Now we have with probability at least 1 − δ,

| ˆFa(x) − Fa(x)| ≤ (cid:15), ∀x ∈ R.

If this inequality holds, then for any value ˆτq such that
ˆFa(ˆτq) ≤ q, we have

Fa(ˆτq) ≤ ˆFa(ˆτq) + (cid:15) ≤ q + (cid:15).

So we have with probability at least 1 − δ, any ˆτq satisfying
ˆFa(ˆτq) ≤ q will satisfy Fa(ˆτq) ≤ q + (cid:15).
(cid:3)

B. Proof for Corollary 1

If α(cid:48) ≥ α, and if we write

F (cid:48)

a(x) =

Fm(x) − (1 − α(cid:48))F0(x)
α(cid:48)

,

then F (cid:48)

a is still a legal CDF, because

a(−∞) = 0, F (cid:48)
F (cid:48)

a(∞) = 1,

and it is easy to show that F (cid:48)
ing.

a is monotonically nondecreas-

F (cid:48)

≥ 0, ∀x ∈ R,

a(x)−Fa(x) =

(α − α(cid:48))(Fm(x) − F0(x))
αα(cid:48)
and because of this, if we let ˆτ (cid:48)
q denote the threshold we
get from using α(cid:48), we will have Fa(ˆτ (cid:48)
q) ≤ F (cid:48)
q). By
the proof of previous theorem, we know that when n >
2
1
α(cid:48) )2, we have with probability at least
2 ln
√
1−δ
q) ≤ q + (cid:15).(cid:3)
a(ˆτ (cid:48)
1 − δ, F (cid:48)

(cid:15) )2( 2−α(cid:48)
( 1
q) ≤ q + (cid:15), and thus we have Fa(ˆτ (cid:48)

a(ˆτ (cid:48)

1−

References

Barlow, RE and Brunk, HD. The isotonic regression prob-
lem and its dual. Journal of the American Statistical
Association, 67(337):140–147, 1972.

Open Category Detection with PAC Guarantees

Bendale, A. and Boult, T. E. Towards open set deep net-
works. In 2016 IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), pp. 1563–1572, June
2016.

Cevikalp, H. and Triggs, B. Efﬁcient object detection using
cascades of nearest convex model classiﬁers. In 2012
IEEE Conference on Computer Vision and Pattern Recog-
nition, pp. 3138–3145, June 2012.

Chow, C. On optimum recognition error and reject tradeoff.
IEEE Transactions on Information Theory, 16(1):41–46,
Jan 1970. ISSN 0018-9448.

Da, Qing, Yu, Yang, and Zhou, Zhi-Hua. Learning with
augmented class by exploiting unlabeled data. In Pro-
ceedings of the Twenty-Eighth AAAI Conference on Artiﬁ-
cial Intelligence, AAAI’14, pp. 1760–1766. AAAI Press,
2014.

Emmott, Andrew F, Das, Shubhomoy, Dietterich, Thomas,
Fern, Alan, and Wong, Weng-Keen. Systematic construc-
tion of anomaly detection benchmarks from real data. In
Proceedings of the ACM SIGKDD workshop on outlier
detection and description, pp. 16–21. ACM, 2013.

Geifman, Yonatan and El-Yaniv, Ran. Selective classiﬁca-
tion for deep neural networks. In Guyon, I., Luxburg,
U. V., Bengio, S., Wallach, H., Fergus, R., Vishwanathan,
S., and Garnett, R. (eds.), Advances in Neural Informa-
tion Processing Systems 30, pp. 4885–4894. Curran As-
sociates, Inc., 2017.

Heﬂin, B., Scheirer, W., and Boult, T. E. Detecting and
classifying scars, marks, and tattoos found in the wild. In
2012 IEEE Fifth International Conference on Biometrics:
Theory, Applications and Systems (BTAS), pp. 31–38,
Sept 2012.

Hendrycks, Dan and Gimpel, Kevin. A baseline for de-
tecting misclassiﬁed and out-of-distribution examples in
neural networks. In Proceedings of International Confer-
ence on Learning Representations, 2017.

Jin, Hongliang, Liu, Qingshan, and Lu, Hanqing. Face
detection using one-class-based support vectors. In Sixth
IEEE International Conference on Automatic Face and
Gesture Recognition, 2004. Proceedings., pp. 457–462,
May 2004.

Liang, Shiyu, Li, Yixuan, and Srikant, R. Enhancing the
reliability of out-of-distribution image detection in neural
networks. International Conference on Learning Repre-
sentations, 2018.

Lytle, David A, Mart´ınez-Mu˜noz, Gonzalo, Zhang, Wei,
Larios, Natalia, Shapiro, Linda, Paasch, Robert, Mold-
enke, Andrew, Mortensen, Eric N, Todorovic, Sinisa, and
Dietterich, Thomas G. Automated processing and identi-
ﬁcation of benthic invertebrate samples. Journal of the
North American Benthological Society, 29(3):867–874,
2010.

Manevitz, Larry M. and Yousef, Malik. One-class svms for
document classiﬁcation. J. Mach. Learn. Res., 2:139–154,
March 2002. ISSN 1532-4435.

Massart, P. The tight constant in the dvoretzky-kiefer-
wolfowitz inequality. The Annals of Probability, 18(3):
1269–1283, 1990. ISSN 00911798.

Mendes J´unior, Pedro R., de Souza, Roberto M., Werneck,
Rafael de O., Stein, Bernardo V., Pazinato, Daniel V.,
de Almeida, Waldir R., Penatti, Ot´avio A. B., Torres,
Ricardo da S., and Rocha, Anderson. Nearest neighbors
distance ratio open-set classiﬁer. Machine Learning, 106
(3):359–386, Mar 2017. ISSN 1573-0565.

Pevn´y, Tom´aˇs. Loda: Lightweight on-line detector of
anomalies. Machine Learning, (November 2014), 2015.

Pietraszek, Tadeusz. Optimizing abstaining classiﬁers using
roc analysis. In Proceedings of the 22Nd International
Conference on Machine Learning, ICML ’05, pp. 665–
672, New York, NY, USA, 2005. ACM. ISBN 1-59593-
180-5.

Pritsos, Dimitrios A. and Stamatatos, Efstathios. Open-
Set Classiﬁcation for Automated Genre Identiﬁcation, pp.
207–217. Springer Berlin Heidelberg, Berlin, Heidelberg,
2013. ISBN 978-3-642-36973-5.

Scheirer, W. J., de Rezende Rocha, A., Sapkota, A., and
Boult, T. E. Toward open set recognition. IEEE Transac-
tions on Pattern Analysis and Machine Intelligence, 35
(7):1757–1772, July 2013. ISSN 0162-8828.

Scheirer, W. J., Jain, L. P., and Boult, T. E. Probability
models for open set recognition. IEEE Transactions on
Pattern Analysis and Machine Intelligence, 36(11):2317–
2324, Nov 2014. ISSN 0162-8828.

Sch¨olkopf, Bernhard, Platt, John C., Shawe-Taylor, John C.,
Smola, Alex J., and Williamson, Robert C. Estimating
the support of a high-dimensional distribution. Neural
Comput., 13(7):1443–1471, July 2001. ISSN 0899-7667.

Shu, Lei, Xu, Hu, and Liu, Bing. DOC: deep open classiﬁ-
cation of text documents. CoRR, abs/1709.08716, 2017.

Liu, Fei Tony, Ting, Kai Ming, and Zhou, Zhi-Hua. Isolation
forest. In Data Mining, 2008. ICDM’08. Eighth IEEE
International Conference on, pp. 413–422. IEEE, 2008.

Tax, D.M.J. and Duin, R.P.W. Growing a multi-class classi-
ﬁer with a reject option. Pattern Recognition Letters, 29
(10):1565 – 1570, 2008. ISSN 0167-8655.

Open Category Detection with PAC Guarantees

Wegkamp, Marten H. Lasso type classiﬁers with a reject

option. 2007.

Wu, M. and Ye, J. A small sphere and large margin ap-
proach for novelty detection using training data with out-
liers. IEEE Transactions on Pattern Analysis and Ma-
chine Intelligence, 31(11):2088–2092, Nov 2009. ISSN
0162-8828.

Zhou, Xiang Sean and Huang, Thomas S. Relevance feed-
back in image retrieval: A comprehensive review. Mul-
timedia Systems, 8(6):536–544, Apr 2003. ISSN 1432-
1882.

Open Category Detection with PAC Guarantees

A. Experimental Results from Synthetic

Datasets

In this section we include the simulation results on synthetic
datasets from using two different anomaly detectors, Isola-
tion Forest and LODA in table 1-3 and 4-6 respectively. For
using LODA, when training it on the nominal dataset, we
build 1 000 random projections, and each of them is built
using a bootstrap resample of the nominal dataset. After
ﬁnishing building all projections, we calculate the anomaly
score for each point in nominal dataset only using the pro-
jections that didn’t use this point, and calculate the anomaly
scores for mixture dataset, G0 and Ga using all the projec-
tions. For all cases, we include results from targeting on
different recalls which are 98%, 95% and 90%. In table 1-6,
the oracle FPR column is the mean of 100 oracle FPRs in
each setting.

In table 7, we include the results we used for plotting ﬁgure
2. The results are the 1st quartile, median and 3rd quartile of
FPR from experiments using Iforest with target recall 95%.
Here the oracle FPR column is the median of 100 oracle
FPRs.

B. Experimental Results from UCI and Image

Datasets

In this section we include results of performance on UCI
benchmarks, MNIST and Tiny Imagenet and Tables 8-22
illustrate the results. The experimental protocol is similar
to synthetic datasets and two state of the art anomaly de-
tectors Isolation forest, LODA are applied. For Isolation
forest we train Forest with 1000 trees on nominal dataset
and use out of bag estimates of this dataset to estimate the
nominal datasets anomaly score distribution. For LODA we
build 1000 projections and similar to Isolation forest we get
anomaly score for each point in nominal dataset using the
projections that didn’t use this point.Tables 11-16 illustrate
the results of LODA for 6 different datasets for varying val-
ues of η and report the observed recall, False positive rate
averaged over 100 runs of each experiment. Tables 17-22
report the results for Isolation Forest and it can be observed
the performance of both LODA,Isolation Forest are similar.

For Image datasets we follow the same protocol as UCI for
MNIST and apply Isolation Forest on the input image but for
Tiny Imagenet the anomaly scores are obtained differently.
We ﬁrst train a Wide Residual Network (40-2) classiﬁer
on the 200 nominal classes of Tiny Imagenet and apply
baseline method (Hendrycks & Gimpel, 2017) on validation
data to get the nominal dataset distribution and later apply
the same method on the mixture dataset which will have α
proportion of aliens which are basically from 800 held out
classes.Tables 8-10 illustrate the results for these datasets
for target recall of 98%,95% and 90%.

Open Category Detection with PAC Guarantees

Table 1. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 98%, iForest

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

247818
1167215
1829649
4236646
6363404
23373
239656
259309
1067189
1536752
20178
107381
196205
456821
861861
7550
80449
110875
498016
670130
7053
34712
70925
167019
451373

0.710±0.033
0.862±0.019
0.884±0.015
0.920±0.010
0.932±0.009
0.826±0.027
0.939±0.009
0.940±0.008
0.961±0.005
0.965±0.004
0.907±0.017
0.951±0.007
0.960±0.005
0.970±0.004
0.975±0.003
0.946±0.011
0.971±0.005
0.972±0.004
0.977±0.002
0.977±0.002
0.970±0.005
0.977±0.003
0.979±0.002
0.978±0.001
0.979±0.001

0.033±0.027
0.033±0.024
0.031±0.024
0.060±0.038
0.065±0.034
0.088±0.037
0.064±0.032
0.046±0.025
0.083±0.039
0.063±0.026
0.105±0.033
0.071±0.035
0.062±0.023
0.075±0.031
0.088±0.034
0.158±0.045
0.131±0.045
0.098±0.038
0.048±0.010
0.051±0.019
0.156±0.036
0.056±0.009
0.053±0.014
0.039±0.002
0.036±0.001

0.102
0.042
0.036
0.039
0.037
0.101
0.042
0.037
0.039
0.037
0.100
0.042
0.037
0.039
0.037
0.101
0.042
0.037
0.039
0.037
0.102
0.042
0.036
0.039
0.037

0.929±0.029
0.972±0.016
0.980±0.009
0.985±0.007
0.984±0.007
0.950±0.022
0.979±0.007
0.977±0.007
0.984±0.005
0.987±0.004
0.977±0.010
0.985±0.005
0.982±0.005
0.988±0.004
0.989±0.003
0.974±0.010
0.988±0.004
0.989±0.004
0.985±0.003
0.984±0.003
0.982±0.005
0.984±0.003
0.985±0.003
0.979±0.001
0.979±0.001

0.512±0.080
0.543±0.079
0.574±0.080
0.506±0.079
0.520±0.080
0.502±0.081
0.465±0.081
0.477±0.085
0.411±0.080
0.434±0.076
0.549±0.075
0.482±0.080
0.419±0.081
0.403±0.075
0.433±0.077
0.496±0.075
0.484±0.078
0.475±0.079
0.254±0.066
0.216±0.060
0.395±0.073
0.256±0.065
0.196±0.052
0.049±0.014
0.047±0.016

0.102
0.042
0.036
0.039
0.037
0.101
0.042
0.037
0.039
0.037
0.100
0.042
0.037
0.039
0.037
0.101
0.042
0.037
0.039
0.037
0.102
0.042
0.036
0.039
0.037

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Open Category Detection with PAC Guarantees

Table 2. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 95%, iForest

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

275039
1474209
2462157
6171393
9309633
27589
243154
307512
1356124
1553411
28043
109029
157112
1232102
861861
8666
121266
177212
581132
776090
6349
56529
111994
292413
379279

0.710±0.033
0.862±0.019
0.884±0.015
0.911±0.010
0.918±0.010
0.826±0.027
0.920±0.010
0.923±0.009
0.943±0.005
0.945±0.005
0.906±0.016
0.933±0.009
0.934±0.006
0.949±0.004
0.951±0.003
0.929±0.012
0.953±0.006
0.949±0.004
0.949±0.002
0.949±0.002
0.952±0.006
0.951±0.003
0.951±0.002
0.950 ±0.001
0.950 ±0.001

0.033±0.027
0.033±0.024
0.030±0.024
0.039±0.030
0.054±0.032
0.082±0.035
0.035±0.020
0.022±0.011
0.040±0.028
0.024±0.009
0.101±0.033
0.055±0.032
0.017±0.006
0.027±0.018
0.027±0.016
0.126±0.042
0.054±0.025
0.018±0.004
0.014±0.001
0.014±0.001
0.084±0.021
0.018±0.002
0.013±0.001
0.014± 0.000
0.014± 0.000

0.052
0.015
0.012
0.014
0.014
0.051
0.015
0.012
0.014
0.014
0.050
0.015
0.012
0.014
0.014
0.051
0.015
0.012
0.014
0.014
0.052
0.015
0.012
0.014
0.014

0.929±0.029
0.972±0.016
0.978±0.010
0.982±0.008
0.981±0.008
0.947±0.022
0.975±0.009
0.966±0.010
0.973±0.007
0.972±0.006
0.969±0.013
0.974±0.008
0.969±0.007
0.967±0.006
0.964±0.005
0.963±0.013
0.977±0.006
0.968±0.006
0.953±0.003
0.952±0.003
0.966±0.007
0.954±0.004
0.952±0.002
0.950±0.001
0.950± 0.001

0.509±0.080
0.533±0.079
0.557±0.081
0.496±0.080
0.495±0.081
0.489±0.081
0.440±0.079
0.420±0.084
0.351±0.079
0.314±0.074
0.511±0.077
0.397±0.078
0.313±0.075
0.194±0.061
0.192±0.063
0.428±0.073
0.360±0.075
0.273±0.072
0.039±0.024
0.042±0.028
0.262±0.061
0.038±0.021
0.014±0.001
0.014±0.000
0.014±0.000

0.052
0.015
0.012
0.014
0.014
0.051
0.015
0.012
0.014
0.014
0.050
0.015
0.012
0.014
0.014
0.051
0.015
0.012
0.014
0.014
0.052
0.015
0.012
0.014
0.014

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Open Category Detection with PAC Guarantees

Table 3. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 90%, iForest

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

331513
2340744
3222506
5918805
12543171
37658
403920
482922
2307205
2629242
39085
139647
156669
1867515
1232102
6481
63235
153077
397467
1088542
4400
22825
44373
229795
374065

0.710±0.033
0.862±0.019
0.859±0.014
0.869±0.011
0.884±0.010
0.826±0.027
0.893±0.011
0.888±0.010
0.901±0.006
0.898±0.005
0.879±0.017
0.900±0.010
0.888±0.008
0.902±0.003
0.900± 0.003
0.881±0.017
0.909±0.007
0.902±0.004
0.898±0.002
0.899±0.002
0.912±0.008
0.904±0.004
0.903±0.003
0.900±0.001
0.900± 0.001

0.033±0.027
0.033±0.024
0.011±0.008
0.012±0.017
0.012±0.009
0.081±0.034
0.02 ±0.015
0.015±0.011
0.007±0.004
0.005±0.001
0.059±0.021
0.019±0.014
0.005±0.001
0.004±0.000
0.005±0.000
0.060±0.022
0.010±0.003
0.005±0.000
0.003±0.000
0.005±0.000
0.038±0.005
0.006±0.000
0.004±0.000
0.004±0.000
0.005±0.000

0.026
0.005
0.004
0.004
0.005
0.026
0.006
0.004
0.004
0.005
0.025
0.005
0.004
0.003
0.005
0.026
0.005
0.004
0.004
0.005
0.026
0.005
0.004
0.004
0.005

0.929±0.029
0.970±0.016
0.976±0.011
0.976±0.01
0.971±0.011
0.936±0.024
0.960±0.012
0.945±0.014
0.939±0.011
0.923±0.009
0.957±0.016
0.944±0.013
0.925±0.012
0.911±0.006
0.903±0.004
0.942±0.016
0.937±0.010
0.913±0.007
0.898±0.002
0.900± 0.002
0.920±0.010
0.904±0.004
0.903±0.003
0.900±0.001
0.900±0.001

0.509±0.080
0.517±0.078
0.542±0.081
0.476±0.079
0.458±0.080
0.468±0.081
0.372±0.075
0.381±0.082
0.228±0.070
0.139±0.056
0.463±0.076
0.297±0.073
0.166±0.058
0.060 ±0.039
0.016±0.015
0.359±0.072
0.170±0.057
0.066±0.040
0.004±0.000
0.005±0.000
0.107±0.042
0.006±0.000
0.004±0.000
0.004±0.000
0.005±0.000

0.026
0.005
0.004
0.004
0.005
0.026
0.006
0.004
0.004
0.005
0.025
0.005
0.004
0.003
0.005
0.026
0.005
0.004
0.004
0.005
0.026
0.005
0.004
0.004
0.005

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Open Category Detection with PAC Guarantees

Table 4. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 98%, bootstrap
LODA

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

188760
1065490
1891769
5874989
8907859
17905
177557
340061
2051058
2362910
13692
79982
191346
1069912
2042503
7818
54275
121904
612305
922499
4604
25350
101036
431535
615923

0.719±0.048
0.872±0.022
0.899±0.016
0.942±0.010
0.954±0.008
0.842±0.031
0.940±0.011
0.952±0.008
0.971±0.004
0.975±0.004
0.933±0.017
0.955±0.008
0.967±0.005
0.977±0.003
0.980±0.003
0.949±0.013
0.970±0.005
0.977±0.004
0.980±0.002
0.980±0.002
0.973±0.006
0.980±0.003
0.981±0.002
0.980±0.001
0.980±0.001

0.095±0.039
0.083±0.038
0.060±0.031
0.067±0.030
0.069±0.027
0.165±0.051
0.118±0.043
0.090±0.035
0.089±0.034
0.079±0.027
0.213±0.046
0.097±0.037
0.070±0.023
0.072±0.028
0.087±0.030
0.257±0.057
0.125±0.039
0.102±0.031
0.059±0.015
0.073±0.030
0.223±0.042
0.093±0.024
0.065±0.014
0.037±0.002
0.034±0.002

0.135
0.048
0.041
0.034
0.033
0.132
0.049
0.041
0.034
0.034
0.142
0.049
0.041
0.034
0.034
0.131
0.048
0.040
0.034
0.034
0.135
0.049
0.041
0.034
0.034

0.972±0.017
0.974±0.013
0.980±0.009
0.988±0.005
0.990±0.005
0.942±0.024
0.983±0.007
0.980±0.007
0.988±0.004
0.989±0.003
0.977±0.011
0.984±0.006
0.985±0.005
0.989±0.003
0.990±0.003
0.970±0.010
0.987±0.004
0.992±0.003
0.986±0.003
0.986±0.002
0.983±0.005
0.986±0.003
0.986±0.002
0.981±0.001
0.980±0.001

0.569±0.073
0.491±0.079
0.511±0.078
0.447±0.078
0.444±0.075
0.498±0.077
0.430±0.073
0.462±0.081
0.384±0.076
0.360±0.070
0.537±0.070
0.456±0.077
0.402±0.076
0.351±0.070
0.342±0.070
0.481±0.076
0.451±0.076
0.462±0.075
0.217±0.058
0.215±0.057
0.422±0.067
0.258±0.061
0.177±0.047
0.047±0.013
0.038±0.006

0.135
0.048
0.041
0.034
0.033
0.132
0.049
0.041
0.034
0.034
0.142
0.049
0.041
0.034
0.034
0.131
0.048
0.040
0.034
0.034
0.135
0.049
0.041
0.034
0.034

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Open Category Detection with PAC Guarantees

Table 5. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 95%, bootstrap
LODA

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

206671
1330996
2559525
7369343
8307313
20685
175626
463720
3619299
2934537
17884
85131
142860
1578820
2255301
11831
65192
174441
802440
2068150
5099
30120
80278
465368
686935

0.719±0.048
0.872±0.022
0.899±0.016
0.933±0.010
0.943±0.009
0.841±0.031
0.921±0.013
0.940±0.009
0.952±0.005
0.956±0.004
0.929±0.017
0.940±0.009
0.943±0.007
0.955±0.004
0.957±0.003
0.940±0.013
0.955±0.007
0.956±0.005
0.952±0.002
0.952±0.001
0.954±0.007
0.953±0.003
0.952±0.002
0.951±0.001
0.950±0.001

0.095±0.039
0.083±0.038
0.060±0.031
0.052±0.023
0.059±0.025
0.164±0.050
0.092±0.038
0.057±0.026
0.038±0.022
0.024±0.007
0.205±0.046
0.083±0.036
0.039±0.014
0.029±0.018
0.022±0.009
0.204±0.049
0.077±0.029
0.041±0.018
0.013±0.002
0.011±0.001
0.123±0.022
0.025±0.003
0.017±0.001
0.011±0.000
0.011±0.000

0.077
0.020
0.015
0.011
0.010
0.076
0.020
0.015
0.011
0.010
0.083
0.020
0.015
0.011
0.010
0.075
0.020
0.015
0.011
0.010
0.078
0.020
0.015
0.011
0.010

0.972±0.017
0.974±0.013
0.978±0.010
0.985±0.006
0.987±0.006
0.939±0.025
0.978±0.009
0.973±0.009
0.978±0.005
0.976±0.005
0.976±0.011
0.976±0.008
0.973±0.008
0.971±0.005
0.967±0.005
0.964±0.012
0.979±0.006
0.975±0.006
0.956±0.003
0.954±0.002
0.971±0.007
0.956±0.004
0.952±0.002
0.951±0.001
0.950±0.001

0.566±0.073
0.487±0.078
0.505±0.079
0.442±0.078
0.413±0.074
0.487±0.075
0.392±0.070
0.410±0.079
0.308±0.072
0.246±0.063
0.530±0.070
0.376±0.074
0.304±0.072
0.175±0.057
0.146±0.053
0.441±0.073
0.352±0.070
0.271±0.066
0.041±0.025
0.031±0.023
0.325±0.061
0.049±0.022
0.017±0.001
0.011±0.000
0.011±0.000

0.077
0.020
0.015
0.011
0.010
0.076
0.020
0.015
0.011
0.010
0.083
0.020
0.015
0.011
0.010
0.075
0.020
0.015
0.011
0.010
0.078
0.020
0.015
0.011
0.010

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Open Category Detection with PAC Guarantees

Table 6. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 90%, bootstrap
LODA

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

242739
2059638
3398545
9739214
11575949
27002
255234
426176
2440377
4972658
18177
123537
140581
2329443
2968332
9199
59467
178906
786472
1349754
13581
13945
96151
227331
537171

0.719±0.048
0.872±0.022
0.863±0.017
0.900±0.013
0.911±0.012
0.841±0.031
0.892±0.014
0.900±0.011
0.914±0.006
0.907±0.005
0.898±0.020
0.910±0.011
0.897±0.009
0.906±0.003
0.905±0.003
0.915±0.016
0.914±0.008
0.911±0.005
0.901±0.002
0.901±0.001
0.921±0.008
0.902±0.004
0.904±0.003
0.900±0.001
0.901±0.001

0.095±0.039
0.082±0.038
0.033±0.020
0.032±0.019
0.030±0.016
0.157±0.048
0.058±0.033
0.018±0.009
0.010±0.005
0.004±0.001
0.152±0.040
0.049±0.027
0.013±0.006
0.004±0.000
0.003±0.000
0.149±0.043
0.021±0.014
0.008±0.001
0.004±0.000
0.003±0.000
0.067±0.010
0.009±0.001
0.006±0.000
0.003±0.000
0.003±0.000

0.045
0.008
0.006
0.003
0.003
0.044
0.008
0.006
0.003
0.003
0.049
0.008
0.006
0.003
0.003
0.043
0.008
0.006
0.003
0.003
0.045
0.008
0.006
0.003
0.003

0.972±0.017
0.969±0.015
0.973±0.012
0.981±0.007
0.980±0.009
0.936±0.026
0.964±0.013
0.957±0.012
0.945±0.009
0.933±0.009
0.969±0.013
0.954±0.012
0.936±0.012
0.915±0.006
0.908±0.004
0.953±0.014
0.942±0.010
0.923±0.008
0.901±0.002
0.901±0.001
0.934±0.009
0.902±0.004
0.904±0.003
0.900±0.001
0.901±0.001

0.564±0.073
0.484±0.079
0.487±0.079
0.411±0.076
0.359±0.072
0.460±0.074
0.359±0.070
0.365±0.077
0.188±0.063
0.130±0.052
0.487±0.070
0.303±0.069
0.175±0.057
0.053±0.033
0.014±0.016
0.393±0.071
0.189±0.059
0.078±0.039
0.004±0.000
0.003±0.000
0.148±0.042
0.009±0.001
0.006±0.000
0.003±0.000
0.003±0.000

0.045
0.008
0.006
0.003
0.003
0.044
0.008
0.006
0.003
0.003
0.049
0.008
0.006
0.003
0.003
0.043
0.008
0.006
0.003
0.003
0.045
0.008
0.006
0.003
0.003

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Table 7. 1st quartile, median, 3rd quartile of false positive rate from experiments using 9-dimensional normal data, 95%, Iforest

Open Category Detection with PAC Guarantees

Basic CDF
False Positive Rate

n 1st quartile median

3rd quartile Oracle(median)

α

0.01

0.05

0.1

0.2

0.5

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

0.004
0.002
0.002
0.002
0.003
0.006
0.004
0.004
0.006
0.008
0.015
0.006
0.005
0.009
0.011
0.025
0.010
0.008
0.010
0.012
0.040
0.012
0.011
0.013
0.013

0.006
0.004
0.004
0.004
0.006
0.014
0.008
0.008
0.010
0.011
0.032
0.012
0.009
0.013
0.014
0.043
0.018
0.011
0.013
0.013
0.058
0.016
0.012
0.014
0.014

0.014
0.015
0.010
0.013
0.014
0.043
0.023
0.015
0.020
0.019
0.094
0.021
0.014
0.020
0.017
0.105
0.031
0.018
0.015
0.015
0.090
0.021
0.016
0.016
0.015

0.051
0.015
0.012
0.014
0.014
0.050
0.015
0.012
0.014
0.014
0.049
0.015
0.012
0.014
0.014
0.049
0.015
0.012
0.014
0.014
0.051
0.015
0.012
0.014
0.014

Open Category Detection with PAC Guarantees

Table 8. Recall (i.e. alien detection rate) & False Positive Rate for Image Datasets,98%

Dataset

α

ˆα

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Tiny Image Net
n=10000

MNIST
n=11154

Tiny Image Net
n=10000

MNIST
n=11154

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.926 ± 0.014
0.933 ± 0.013
0.941 ± 0.012
0.965 ± 0.005
0.970 ± 0.004
0.977 ± 0.004
0.976 ± 0.003
0.982 ± 0.002
0.987 ± 0.002

0.981 ± 0.006
0.987 ± 0.005
0.991 ± 0.004
0.983 ± 0.004
0.990 ± 0.003
0.997 ± 0.001
0.983 ± 0.003
0.993 ± 0.002
0.999 ± 0.001

0.677 ± 0.030
0.695 ± 0.030
0.715 ± 0.029
0.738 ± 0.018
0.761 ± 0.018
0.787 ± 0.017
0.766 ± 0.011
0.793 ± 0.011
0.822 ± 0.010

0.466 ± 0.041
0.518 ± 0.044
0.573 ± 0.049
0.444 ± 0.030
0.511 ± 0.037
0.610 ± 0.038
0.416 ± 0.014
0.504 ± 0.024
0.655 ± 0.030

0.944 ± 0.013
0.952 ± 0.012
0.959 ± 0.011
0.972 ± 0.005
0.977 ± 0.004
0.983 ± 0.003
0.978 ± 0.003
0.983 ± 0.002
0.988 ± 0.002

0.987 ± 0.006
0.991 ± 0.005
0.994 ± 0.003
0.986 ± 0.004
0.992 ± 0.003
0.998 ± 0.001
0.983 ± 0.003
0.993 ± 0.002
0.999 ± 0.001

0.746 ± 0.034
0.766 ± 0.033
0.786 ± 0.031
0.774 ± 0.021
0.798 ± 0.019
0.825 ± 0.018
0.776 ± 0.012
0.802 ± 0.011
0.833 ± 0.010

0.569 ± 0.061
0.628 ± 0.061
0.691 ± 0.060
0.483 ± 0.041
0.567 ± 0.045
0.684 ± 0.040
0.421 ± 0.015
0.519 ± 0.028
0.683 ± 0.032

0.902 ± 0.014
0.912 ± 0.014
0.923 ± 0.013
0.942 ± 0.006
0.949 ± 0.005
0.957 ± 0.005
0.948 ± 0.003
0.956 ± 0.003
0.964 ± 0.002

0.971 ± 0.007
0.977 ± 0.006
0.984 ± 0.005
0.966 ± 0.005
0.976 ± 0.004
0.986 ± 0.003
0.957 ± 0.003
0.972 ± 0.003
0.987 ± 0.002

0.620 ± 0.025
0.639 ± 0.026
0.660 ± 0.026
0.667 ± 0.016
0.683 ± 0.014
0.706 ± 0.014
0.669 ± 0.007
0.689 ± 0.007
0.714 ± 0.007

0.404 ± 0.032
0.432 ± 0.033
0.477 ± 0.036
0.361 ± 0.017
0.397 ± 0.018
0.455 ± 0.023
0.334 ± 0.005
0.373 ± 0.007
0.441 ± 0.012

0.924 ± 0.014
0.930 ± 0.014
0.939 ± 0.012
0.948 ± 0.006
0.954 ± 0.005
0.962 ± 0.005
0.949 ± 0.003
0.957 ± 0.003
0.965 ± 0.002

0.975 ± 0.007
0.982 ± 0.006
0.988 ± 0.005
0.967 ± 0.005
0.977 ± 0.004
0.988 ± 0.003
0.957 ± 0.003
0.973 ± 0.003
0.988 ± 0.002

0.686 ± 0.032
0.697 ± 0.031
0.716 ± 0.031
0.682 ± 0.016
0.700 ± 0.015
0.722 ± 0.015
0.672 ± 0.007
0.692 ± 0.007
0.718 ± 0.007

0.448 ± 0.042
0.488 ± 0.045
0.542 ± 0.048
0.368 ± 0.018
0.410 ± 0.022
0.477 ± 0.028
0.334 ± 0.005
0.375 ± 0.007
0.444 ± 0.012

Table 9. Recall (i.e. alien detection rate) & False Positive Rate for Image Datasets,95%

Dataset

α

ˆα

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Open Category Detection with PAC Guarantees

Table 10. Recall (i.e. alien detection rate) & False Positive Rate for Image Datasets,90%

Dataset

α

ˆα

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Tiny Image Net
n=10000

MNIST
n=11154

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.862 ± 0.015
0.873 ± 0.015
0.885 ± 0.014
0.894 ± 0.007
0.904 ± 0.007
0.915 ± 0.006
0.898 ± 0.003
0.907 ± 0.003
0.919 ± 0.003

0.949 ± 0.008
0.958 ± 0.007
0.967 ± 0.007
0.928 ± 0.005
0.942 ± 0.004
0.958 ± 0.004
0.912 ± 0.003
0.929 ± 0.003
0.949 ± 0.003

0.545 ± 0.021
0.562 ± 0.021
0.579 ± 0.021
0.578 ± 0.011
0.593 ± 0.010
0.609 ± 0.010
0.577 ± 0.004
0.590 ± 0.004
0.608 ± 0.004

0.328 ± 0.020
0.352 ± 0.022
0.378 ± 0.024
0.282 ± 0.006
0.306 ± 0.007
0.341 ± 0.010
0.260 ± 0.003
0.284 ± 0.003
0.317 ± 0.004

0.883 ± 0.016
0.892 ± 0.015
0.902 ± 0.014
0.898 ± 0.007
0.909 ± 0.006
0.919 ± 0.006
0.899 ± 0.003
0.908 ± 0.003
0.920 ± 0.003

0.954 ± 0.008
0.962 ± 0.007
0.971 ± 0.007
0.929 ± 0.005
0.944 ± 0.004
0.960 ± 0.004
0.912 ± 0.003
0.930 ± 0.003
0.949 ± 0.003

0.590 ± 0.027
0.602 ± 0.026
0.617 ± 0.025
0.584 ± 0.011
0.600 ± 0.011
0.617 ± 0.011
0.578 ± 0.004
0.591 ± 0.004
0.609 ± 0.004

0.342 ± 0.024
0.366 ± 0.025
0.395 ± 0.027
0.285 ± 0.007
0.309 ± 0.008
0.345 ± 0.011
0.260 ± 0.003
0.284 ± 0.003
0.317 ± 0.004

Open Category Detection with PAC Guarantees

Table 11. Recall & False Positive Rate for Landsat Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Landsat
n=1532

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.937 ± 0.024
0.949 ± 0.024
0.960 ± 0.024
0.965 ± 0.005
0.980 ± 0.003
0.989 ± 0.002
0.971 ± 0.013
0.985 ± 0.012
0.991 ± 0.012

0.924 ± 0.024
0.936 ± 0.024
0.950 ± 0.024
0.942 ± 0.006
0.964 ± 0.004
0.981 ± 0.003
0.948 ± 0.013
0.969 ± 0.012
0.986 ± 0.012

0.888 ± 0.025
0.906 ± 0.024
0.927 ± 0.024
0.902 ± 0.007
0.928 ± 0.005
0.953 ± 0.005
0.899 ± 0.012
0.927 ± 0.012
0.957 ± 0.012

0.162 ± 0.047
0.203 ± 0.048
0.255 ± 0.050
0.128 ± 0.033
0.204 ± 0.040
0.301 ± 0.047
0.114 ± 0.021
0.267 ± 0.033
0.480 ± 0.039

0.127 ± 0.041
0.157 ± 0.044
0.202 ± 0.047
0.069 ± 0.020
0.112 ± 0.027
0.201 ± 0.039
0.046 ± 0.008
0.095 ± 0.015
0.250 ± 0.029

0.089 ± 0.036
0.106 ± 0.038
0.136 ± 0.041
0.034 ± 0.008
0.047 ± 0.012
0.076 ± 0.018
0.029 ± 0.008
0.035 ± 0.008
0.055 ± 0.008

0.960 ± 0.024
0.967 ± 0.024
0.972 ± 0.024
0.983 ± 0.005
0.991 ± 0.003
0.996 ± 0.001
0.981 ± 0.013
0.989 ± 0.012
0.993 ± 0.012

0.952 ± 0.025
0.959 ± 0.024
0.966 ± 0.024
0.964 ± 0.006
0.980 ± 0.004
0.991 ± 0.002
0.952 ± 0.013
0.976 ± 0.012
0.989 ± 0.012

0.924 ± 0.025
0.938 ± 0.025
0.953 ± 0.025
0.918 ± 0.009
0.941 ± 0.007
0.966 ± 0.005
0.899 ± 0.012
0.927 ± 0.012
0.960 ± 0.012

0.495 ± 0.068
0.543 ± 0.064
0.583 ± 0.062
0.404 ± 0.062
0.478 ± 0.061
0.557 ± 0.057
0.323 ± 0.055
0.491 ± 0.051
0.658 ± 0.041

0.430 ± 0.067
0.463 ± 0.065
0.506 ± 0.064
0.271 ± 0.057
0.337 ± 0.056
0.425 ± 0.055
0.094 ± 0.028
0.209 ± 0.038
0.385 ± 0.041

0.323 ± 0.064
0.345 ± 0.064
0.380 ± 0.063
0.115 ± 0.037
0.151 ± 0.040
0.216 ± 0.044
0.030 ± 0.008
0.036 ± 0.008
0.076 ± 0.015

Open Category Detection with PAC Guarantees

Table 12. Recall & False Positive Rate for page.blocks Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

pageblocks
n=4912

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.963 ± 0.021
0.969 ± 0.017
0.976 ± 0.013
0.966 ± 0.005
0.978 ± 0.004
0.989 ± 0.003
0.971 ± 0.004
0.986 ± 0.002
0.994 ± 0.001

0.945 ± 0.031
0.958 ± 0.024
0.967 ± 0.018
0.945 ± 0.007
0.963 ± 0.005
0.978 ± 0.004
0.945 ± 0.004
0.966 ± 0.003
0.985 ± 0.002

0.908 ± 0.027
0.928 ± 0.021
0.947 ± 0.022
0.899 ± 0.007
0.922 ± 0.007
0.946 ± 0.006
0.901 ± 0.005
0.922 ± 0.004
0.948 ± 0.004

0.254 ± 0.084
0.315 ± 0.138
0.357 ± 0.137
0.287 ± 0.031
0.367 ± 0.038
0.468 ± 0.041
0.261 ± 0.028
0.384 ± 0.035
0.531 ± 0.038

0.218 ± 0.070
0.259 ± 0.100
0.304 ± 0.117
0.204 ± 0.019
0.258 ± 0.025
0.338 ± 0.031
0.173 ± 0.012
0.228 ± 0.020
0.339 ± 0.027

0.153 ± 0.030
0.187 ± 0.049
0.222 ± 0.071
0.139 ± 0.007
0.161 ± 0.010
0.201 ± 0.016
0.125 ± 0.004
0.143 ± 0.005
0.174 ± 0.008

0.983 ± 0.013
0.991 ± 0.006
0.995 ± 0.004
0.978 ± 0.005
0.987 ± 0.003
0.994 ± 0.002
0.980 ± 0.004
0.991 ± 0.002
0.996 ± 0.001

0.964 ± 0.029
0.975 ± 0.018
0.985 ± 0.012
0.955 ± 0.007
0.972 ± 0.005
0.985 ± 0.004
0.950 ± 0.005
0.972 ± 0.004
0.989 ± 0.002

0.939 ± 0.027
0.943 ± 0.024
0.959 ± 0.023
0.905 ± 0.008
0.929 ± 0.007
0.954 ± 0.006
0.903 ± 0.005
0.924 ± 0.004
0.951 ± 0.004

0.555 ± 0.201
0.624 ± 0.181
0.712 ± 0.159
0.452 ± 0.053
0.529 ± 0.050
0.626 ± 0.045
0.411 ± 0.048
0.532 ± 0.047
0.655 ± 0.043

0.419 ± 0.210
0.458 ± 0.201
0.551 ± 0.185
0.291 ± 0.040
0.362 ± 0.042
0.448 ± 0.043
0.217 ± 0.029
0.303 ± 0.034
0.423 ± 0.036

0.245 ± 0.105
0.253 ± 0.102
0.305 ± 0.119
0.162 ± 0.017
0.190 ± 0.020
0.243 ± 0.026
0.127 ± 0.005
0.148 ± 0.008
0.190 ± 0.013

Open Category Detection with PAC Guarantees

Table 13. Recall & False Positive Rate for Optical.digits Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Optical.digits
n=568

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.898 ± 0.016
0.906 ± 0.013
0.917 ± 0.013
0.938 ± 0.011
0.953 ± 0.008
0.968 ± 0.007
0.966 ± 0.006
0.979 ± 0.004
0.989 ± 0.003

0.887 ± 0.016
0.892 ± 0.014
0.906 ± 0.013
0.924 ± 0.011
0.936 ± 0.009
0.955 ± 0.008
0.946 ± 0.006
0.964 ± 0.005
0.980 ± 0.004

0.840 ± 0.021
0.866 ± 0.015
0.879 ± 0.014
0.883 ± 0.013
0.905 ± 0.010
0.926 ± 0.010
0.904 ± 0.007
0.925 ± 0.006
0.951 ± 0.006

0.167 ± 0.035
0.186 ± 0.036
0.214 ± 0.036
0.177 ± 0.033
0.220 ± 0.039
0.270 ± 0.041
0.254 ± 0.041
0.339 ± 0.045
0.439 ± 0.048

0.146 ± 0.033
0.166 ± 0.033
0.188 ± 0.034
0.135 ± 0.025
0.165 ± 0.029
0.212 ± 0.034
0.149 ± 0.024
0.219 ± 0.031
0.319 ± 0.040

0.119 ± 0.029
0.132 ± 0.031
0.151 ± 0.032
0.080 ± 0.012
0.104 ± 0.018
0.138 ± 0.024
0.072 ± 0.006
0.096 ± 0.009
0.150 ± 0.019

0.947 ± 0.016
0.950 ± 0.013
0.957 ± 0.012
0.964 ± 0.010
0.973 ± 0.008
0.983 ± 0.006
0.978 ± 0.006
0.986 ± 0.004
0.994 ± 0.002

0.948 ± 0.015
0.944 ± 0.014
0.952 ± 0.013
0.954 ± 0.010
0.963 ± 0.009
0.974 ± 0.007
0.959 ± 0.007
0.974 ± 0.006
0.986 ± 0.004

0.910 ± 0.021
0.928 ± 0.016
0.937 ± 0.015
0.916 ± 0.015
0.936 ± 0.011
0.953 ± 0.010
0.916 ± 0.009
0.936 ± 0.008
0.960 ± 0.006

0.502 ± 0.070
0.519 ± 0.066
0.549 ± 0.065
0.434 ± 0.065
0.466 ± 0.063
0.511 ± 0.061
0.441 ± 0.061
0.517 ± 0.058
0.606 ± 0.053

0.459 ± 0.068
0.481 ± 0.066
0.504 ± 0.065
0.342 ± 0.059
0.381 ± 0.059
0.432 ± 0.060
0.290 ± 0.049
0.356 ± 0.049
0.443 ± 0.049

0.403 ± 0.067
0.413 ± 0.065
0.430 ± 0.065
0.237 ± 0.050
0.264 ± 0.050
0.300 ± 0.050
0.129 ± 0.026
0.168 ± 0.031
0.233 ± 0.036

Open Category Detection with PAC Guarantees

Table 14. Recall & False Positive Rate for Letter Recognition Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Letter recognition
n=788

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.897 ± 0.018
0.918 ± 0.013
0.931 ± 0.012
0.940 ± 0.011
0.954 ± 0.008
0.969 ± 0.006
0.968 ± 0.006
0.983 ± 0.004
0.993 ± 0.003

0.885 ± 0.020
0.904 ± 0.015
0.919 ± 0.013
0.912 ± 0.013
0.934 ± 0.010
0.954 ± 0.008
0.946 ± 0.006
0.967 ± 0.005
0.984 ± 0.004

0.857 ± 0.020
0.875 ± 0.017
0.892 ± 0.016
0.875 ± 0.014
0.900 ± 0.011
0.923 ± 0.010
0.901 ± 0.007
0.925 ± 0.006
0.953 ± 0.005

0.232 ± 0.044
0.255 ± 0.045
0.291 ± 0.047
0.197 ± 0.032
0.235 ± 0.035
0.281 ± 0.039
0.242 ± 0.029
0.335 ± 0.038
0.448 ± 0.044

0.205 ± 0.042
0.223 ± 0.041
0.252 ± 0.043
0.156 ± 0.024
0.188 ± 0.027
0.229 ± 0.034
0.147 ± 0.012
0.208 ± 0.020
0.306 ± 0.032

0.152 ± 0.031
0.172 ± 0.033
0.197 ± 0.036
0.111 ± 0.016
0.132 ± 0.018
0.158 ± 0.022
0.099 ± 0.004
0.117 ± 0.005
0.155 ± 0.010

0.953 ± 0.016
0.967 ± 0.010
0.975 ± 0.008
0.964 ± 0.011
0.974 ± 0.007
0.983 ± 0.006
0.977 ± 0.006
0.989 ± 0.003
0.996 ± 0.002

0.949 ± 0.015
0.958 ± 0.012
0.965 ± 0.010
0.944 ± 0.013
0.960 ± 0.009
0.973 ± 0.008
0.956 ± 0.007
0.974 ± 0.005
0.988 ± 0.004

0.929 ± 0.018
0.939 ± 0.016
0.949 ± 0.014
0.905 ± 0.015
0.928 ± 0.012
0.950 ± 0.010
0.906 ± 0.008
0.932 ± 0.006
0.959 ± 0.006

0.596 ± 0.069
0.613 ± 0.067
0.633 ± 0.065
0.457 ± 0.066
0.490 ± 0.063
0.537 ± 0.061
0.430 ± 0.056
0.525 ± 0.055
0.639 ± 0.049

0.550 ± 0.069
0.570 ± 0.066
0.587 ± 0.065
0.375 ± 0.060
0.407 ± 0.059
0.455 ± 0.059
0.245 ± 0.039
0.334 ± 0.043
0.432 ± 0.046

0.473 ± 0.067
0.490 ± 0.066
0.519 ± 0.066
0.236 ± 0.045
0.280 ± 0.048
0.326 ± 0.051
0.110 ± 0.008
0.145 ± 0.015
0.203 ± 0.023

Open Category Detection with PAC Guarantees

Table 15. Recall & False Positive Rate for Shuttle Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Shuttle
n=5000

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.959 ± 0.008
0.971 ± 0.006
0.984 ± 0.005
0.975 ± 0.004
0.990 ± 0.002
0.998 ± 0.001
0.980 ± 0.002
0.996 ± 0.001
1.000 ± 0.000

0.937 ± 0.009
0.958 ± 0.007
0.974 ± 0.006
0.949 ± 0.005
0.973 ± 0.004
0.992 ± 0.002
0.949 ± 0.002
0.976 ± 0.002
0.997 ± 0.001

0.901 ± 0.012
0.923 ± 0.010
0.947 ± 0.008
0.903 ± 0.004
0.928 ± 0.004
0.958 ± 0.004
0.899 ± 0.002
0.925 ± 0.002
0.959 ± 0.002

0.145 ± 0.031
0.205 ± 0.038
0.287 ± 0.048
0.100 ± 0.016
0.195 ± 0.033
0.355 ± 0.042
0.090 ± 0.014
0.238 ± 0.028
0.540 ± 0.032

0.095 ± 0.017
0.137 ± 0.027
0.200 ± 0.036
0.064 ± 0.004
0.093 ± 0.011
0.186 ± 0.028
0.061 ± 0.001
0.082 ± 0.006
0.220 ± 0.022

0.056 ± 0.006
0.072 ± 0.010
0.105 ± 0.019
0.047 ± 0.001
0.054 ± 0.002
0.068 ± 0.004
0.047 ± 0.001
0.054 ± 0.001
0.065 ± 0.001

0.973 ± 0.007
0.984 ± 0.006
0.991 ± 0.003
0.982 ± 0.004
0.994 ± 0.002
0.999 ± 0.001
0.982 ± 0.002
0.997 ± 0.001
1.000 ± 0.000

0.957 ± 0.009
0.972 ± 0.007
0.983 ± 0.005
0.956 ± 0.006
0.979 ± 0.004
0.995 ± 0.002
0.949 ± 0.002
0.977 ± 0.002
0.998 ± 0.001

0.917 ± 0.013
0.939 ± 0.011
0.960 ± 0.009
0.905 ± 0.004
0.931 ± 0.005
0.963 ± 0.004
0.899 ± 0.002
0.925 ± 0.002
0.959 ± 0.002

0.425 ± 0.065
0.490 ± 0.065
0.550 ± 0.064
0.317 ± 0.058
0.451 ± 0.058
0.578 ± 0.052
0.154 ± 0.031
0.396 ± 0.042
0.642 ± 0.034

0.326 ± 0.059
0.370 ± 0.059
0.435 ± 0.059
0.142 ± 0.034
0.224 ± 0.043
0.365 ± 0.045
0.061 ± 0.001
0.104 ± 0.016
0.290 ± 0.028

0.187 ± 0.047
0.216 ± 0.047
0.266 ± 0.049
0.048 ± 0.002
0.064 ± 0.008
0.111 ± 0.020
0.047 ± 0.001
0.054 ± 0.001
0.066 ± 0.001

Open Category Detection with PAC Guarantees

Table 16. Recall & False Positive Rate for Covertype Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Covertype
n=13624

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.979 ± 0.002
0.995 ± 0.001
0.999 ± 0.000
0.980 ± 0.001
0.998 ± 0.000
1.000 ± 0.000
0.981 ± 0.001
0.998 ± 0.000
1.000 ± 0.000

0.951 ± 0.002
0.978 ± 0.001
0.997 ± 0.001
0.951 ± 0.001
0.979 ± 0.001
0.999 ± 0.000
0.952 ± 0.001
0.980 ± 0.001
0.999 ± 0.000

0.900 ± 0.003
0.930 ± 0.001
0.965 ± 0.001
0.901 ± 0.002
0.929 ± 0.001
0.965 ± 0.001
0.901 ± 0.002
0.929 ± 0.001
0.965 ± 0.001

0.010 ± 0.003
0.098 ± 0.025
0.292 ± 0.045
0.007 ± 0.002
0.142 ± 0.026
0.423 ± 0.044
0.009 ± 0.001
0.212 ± 0.029
0.560 ± 0.037

0.002 ± 0.000
0.012 ± 0.004
0.112 ± 0.026
0.003 ± 0.000
0.008 ± 0.002
0.153 ± 0.025
0.006 ± 0.000
0.012 ± 0.002
0.199 ± 0.023

0.002 ± 0.000
0.002 ± 0.000
0.004 ± 0.001
0.002 ± 0.000
0.002 ± 0.000
0.004 ± 0.000
0.005 ± 0.000
0.005 ± 0.000
0.007 ± 0.000

0.989 ± 0.002
0.998 ± 0.001
0.999 ± 0.000
0.987 ± 0.002
0.999 ± 0.000
1.000 ± 0.000
0.984 ± 0.002
0.999 ± 0.000
1.000 ± 0.000

0.963 ± 0.004
0.987 ± 0.002
0.998 ± 0.000
0.952 ± 0.002
0.983 ± 0.001
1.000 ± 0.000
0.952 ± 0.001
0.981 ± 0.001
1.000 ± 0.000

0.904 ± 0.004
0.937 ± 0.004
0.973 ± 0.003
0.901 ± 0.002
0.929 ± 0.001
0.965 ± 0.001
0.901 ± 0.002
0.929 ± 0.001
0.965 ± 0.001

0.373 ± 0.072
0.470 ± 0.066
0.586 ± 0.059
0.220 ± 0.056
0.419 ± 0.057
0.618 ± 0.047
0.134 ± 0.044
0.438 ± 0.050
0.676 ± 0.036

0.164 ± 0.051
0.277 ± 0.059
0.411 ± 0.060
0.017 ± 0.016
0.114 ± 0.035
0.319 ± 0.045
0.006 ± 0.000
0.050 ± 0.015
0.307 ± 0.034

0.025 ± 0.019
0.055 ± 0.029
0.121 ± 0.038
0.002 ± 0.000
0.002 ± 0.000
0.011 ± 0.004
0.005 ± 0.000
0.005 ± 0.000
0.008 ± 0.001

Open Category Detection with PAC Guarantees

Table 17. Recall & False Positive Rate for Landsat Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Landsat
n=1532

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.941 ± 0.024
0.950 ± 0.024
0.960 ± 0.024
0.965 ± 0.005
0.979 ± 0.003
0.989 ± 0.002
0.970 ± 0.012
0.985 ± 0.012
0.991 ± 0.012

0.923 ± 0.024
0.936 ± 0.024
0.951 ± 0.024
0.945 ± 0.006
0.964 ± 0.004
0.980 ± 0.003
0.949 ± 0.012
0.969 ± 0.012
0.986 ± 0.012

0.887 ± 0.024
0.906 ± 0.024
0.926 ± 0.024
0.903 ± 0.007
0.927 ± 0.005
0.952 ± 0.005
0.901 ± 0.012
0.926 ± 0.012
0.957 ± 0.012

0.164 ± 0.045
0.197 ± 0.048
0.254 ± 0.051
0.130 ± 0.033
0.199 ± 0.040
0.304 ± 0.048
0.109 ± 0.018
0.266 ± 0.034
0.477 ± 0.039

0.130 ± 0.042
0.161 ± 0.045
0.204 ± 0.047
0.074 ± 0.022
0.117 ± 0.029
0.198 ± 0.037
0.044 ± 0.007
0.094 ± 0.015
0.253 ± 0.029

0.088 ± 0.036
0.107 ± 0.038
0.135 ± 0.041
0.032 ± 0.005
0.047 ± 0.012
0.075 ± 0.018
0.030 ± 0.008
0.034 ± 0.008
0.054 ± 0.008

0.964 ± 0.025
0.968 ± 0.024
0.971 ± 0.024
0.982 ± 0.004
0.991 ± 0.003
0.996 ± 0.002
0.979 ± 0.012
0.989 ± 0.012
0.993 ± 0.012

0.950 ± 0.025
0.959 ± 0.025
0.967 ± 0.024
0.965 ± 0.006
0.979 ± 0.004
0.991 ± 0.003
0.953 ± 0.012
0.976 ± 0.012
0.989 ± 0.012

0.919 ± 0.025
0.936 ± 0.025
0.953 ± 0.025
0.915 ± 0.009
0.942 ± 0.007
0.967 ± 0.005
0.901 ± 0.012
0.927 ± 0.012
0.960 ± 0.012

0.503 ± 0.066
0.545 ± 0.065
0.584 ± 0.063
0.402 ± 0.063
0.477 ± 0.060
0.556 ± 0.057
0.323 ± 0.054
0.488 ± 0.051
0.655 ± 0.042

0.423 ± 0.069
0.467 ± 0.066
0.509 ± 0.064
0.265 ± 0.056
0.332 ± 0.055
0.425 ± 0.054
0.095 ± 0.028
0.212 ± 0.038
0.386 ± 0.041

0.309 ± 0.063
0.346 ± 0.064
0.388 ± 0.063
0.110 ± 0.036
0.153 ± 0.040
0.216 ± 0.044
0.030 ± 0.008
0.037 ± 0.009
0.081 ± 0.016

Open Category Detection with PAC Guarantees

Table 18. Recall & False Positive Rate for page.blocks Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

page.blocks
n=4912

0.100
0.100
0.100

0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108

0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020

0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.951 ± 0.029
0.968 ± 0.018
0.976 ± 0.013

0.965 ± 0.005
0.979 ± 0.004
0.989 ± 0.002
0.970 ± 0.004
0.985 ± 0.002
0.995 ± 0.001

0.949 ± 0.025
0.958 ± 0.021
0.969 ± 0.018
0.946 ± 0.007
0.962 ± 0.005
0.978 ± 0.004
0.945 ± 0.005
0.966 ± 0.003
0.985 ± 0.002

0.903 ± 0.035
0.927 ± 0.025
0.951 ± 0.024
0.900 ± 0.007
0.922 ± 0.007
0.947 ± 0.006
0.900 ± 0.005
0.922 ± 0.004
0.948 ± 0.004

0.269 ± 0.106
0.314 ± 0.130
0.366 ± 0.138

0.283 ± 0.030
0.366 ± 0.037
0.465 ± 0.041
0.260 ± 0.028
0.381 ± 0.035
0.530 ± 0.039

0.239 ± 0.096
0.261 ± 0.101
0.297 ± 0.117
0.207 ± 0.019
0.258 ± 0.025
0.338 ± 0.031
0.173 ± 0.013
0.228 ± 0.019
0.339 ± 0.028

0.155 ± 0.040
0.177 ± 0.044
0.222 ± 0.068
0.138 ± 0.006
0.160 ± 0.010
0.201 ± 0.016
0.128 ± 0.004
0.143 ± 0.006
0.174 ± 0.008

0.975 ± 0.017
0.991 ± 0.007
0.994 ± 0.005

0.976 ± 0.005
0.986 ± 0.004
0.994 ± 0.002
0.978 ± 0.004
0.990 ± 0.002
0.996 ± 0.001

0.968 ± 0.022
0.975 ± 0.018
0.986 ± 0.012
0.956 ± 0.007
0.971 ± 0.005
0.984 ± 0.003
0.951 ± 0.005
0.972 ± 0.004
0.989 ± 0.002

0.927 ± 0.030
0.948 ± 0.027
0.962 ± 0.022
0.906 ± 0.008
0.930 ± 0.007
0.955 ± 0.006
0.902 ± 0.006
0.924 ± 0.004
0.951 ± 0.004

0.511 ± 0.220
0.641 ± 0.184
0.692 ± 0.175

0.443 ± 0.052
0.527 ± 0.051
0.622 ± 0.046
0.403 ± 0.049
0.531 ± 0.048
0.655 ± 0.042

0.401 ± 0.176
0.448 ± 0.189
0.529 ± 0.179
0.298 ± 0.040
0.364 ± 0.042
0.446 ± 0.042
0.215 ± 0.027
0.299 ± 0.034
0.424 ± 0.037

0.216 ± 0.111
0.248 ± 0.117
0.317 ± 0.123
0.158 ± 0.016
0.192 ± 0.020
0.246 ± 0.027
0.130 ± 0.006
0.147 ± 0.008
0.190 ± 0.014

Open Category Detection with PAC Guarantees

Table 19. Recall & False Positive Rate for Optical.digits Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Optical.digits
n=568

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.891 ± 0.018
0.904 ± 0.013
0.917 ± 0.012
0.941 ± 0.010
0.951 ± 0.008
0.965 ± 0.007
0.968 ± 0.006
0.979 ± 0.004
0.990 ± 0.003

0.882 ± 0.018
0.896 ± 0.014
0.910 ± 0.013
0.920 ± 0.012
0.938 ± 0.009
0.954 ± 0.008
0.946 ± 0.007
0.963 ± 0.005
0.979 ± 0.004

0.856 ± 0.017
0.867 ± 0.015
0.886 ± 0.014
0.883 ± 0.012
0.907 ± 0.010
0.927 ± 0.009
0.899 ± 0.008
0.926 ± 0.005
0.952 ± 0.005

0.172 ± 0.036
0.191 ± 0.036
0.214 ± 0.037
0.178 ± 0.032
0.218 ± 0.037
0.268 ± 0.040
0.250 ± 0.039
0.338 ± 0.045
0.442 ± 0.047

0.148 ± 0.033
0.164 ± 0.034
0.192 ± 0.036
0.139 ± 0.026
0.168 ± 0.030
0.211 ± 0.034
0.149 ± 0.024
0.220 ± 0.033
0.315 ± 0.039

0.113 ± 0.027
0.127 ± 0.030
0.146 ± 0.031
0.083 ± 0.014
0.106 ± 0.018
0.140 ± 0.025
0.071 ± 0.005
0.097 ± 0.009
0.151 ± 0.018

0.940 ± 0.017
0.952 ± 0.012
0.961 ± 0.011
0.964 ± 0.010
0.974 ± 0.008
0.983 ± 0.006
0.978 ± 0.006
0.986 ± 0.004
0.994 ± 0.002

0.933 ± 0.018
0.945 ± 0.013
0.952 ± 0.012
0.953 ± 0.012
0.964 ± 0.009
0.973 ± 0.008
0.960 ± 0.007
0.974 ± 0.005
0.986 ± 0.004

0.920 ± 0.018
0.928 ± 0.016
0.938 ± 0.014
0.917 ± 0.014
0.935 ± 0.011
0.953 ± 0.009
0.911 ± 0.009
0.937 ± 0.007
0.961 ± 0.006

0.504 ± 0.068
0.521 ± 0.066
0.548 ± 0.065
0.424 ± 0.065
0.465 ± 0.064
0.520 ± 0.063
0.451 ± 0.061
0.519 ± 0.058
0.608 ± 0.054

0.462 ± 0.068
0.481 ± 0.066
0.500 ± 0.065
0.365 ± 0.061
0.386 ± 0.059
0.441 ± 0.060
0.288 ± 0.050
0.357 ± 0.049
0.443 ± 0.049

0.387 ± 0.066
0.407 ± 0.065
0.433 ± 0.064
0.227 ± 0.050
0.264 ± 0.049
0.305 ± 0.050
0.123 ± 0.024
0.163 ± 0.030
0.230 ± 0.035

Open Category Detection with PAC Guarantees

Table 20. Recall & False Positive Rate for Letter Recognition Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Letter recog
n=788

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.911 ± 0.016
0.919 ± 0.013
0.931 ± 0.012
0.936 ± 0.011
0.954 ± 0.008
0.968 ± 0.007
0.971 ± 0.005
0.984 ± 0.004
0.993 ± 0.003

0.884 ± 0.019
0.903 ± 0.015
0.918 ± 0.014
0.915 ± 0.013
0.936 ± 0.009
0.955 ± 0.008
0.944 ± 0.007
0.966 ± 0.005
0.984 ± 0.004

0.862 ± 0.020
0.876 ± 0.018
0.891 ± 0.016
0.879 ± 0.013
0.899 ± 0.011
0.922 ± 0.010
0.902 ± 0.007
0.924 ± 0.006
0.951 ± 0.006

0.234 ± 0.044
0.262 ± 0.046
0.297 ± 0.048
0.203 ± 0.034
0.236 ± 0.036
0.288 ± 0.042
0.240 ± 0.029
0.334 ± 0.039
0.448 ± 0.044

0.208 ± 0.041
0.223 ± 0.041
0.252 ± 0.043
0.162 ± 0.025
0.190 ± 0.029
0.231 ± 0.034
0.152 ± 0.013
0.208 ± 0.019
0.307 ± 0.031

0.160 ± 0.034
0.174 ± 0.034
0.198 ± 0.036
0.113 ± 0.016
0.132 ± 0.019
0.160 ± 0.022
0.098 ± 0.004
0.117 ± 0.005
0.154 ± 0.010

0.960 ± 0.013
0.965 ± 0.011
0.973 ± 0.009
0.961 ± 0.011
0.975 ± 0.008
0.983 ± 0.006
0.979 ± 0.005
0.989 ± 0.003
0.996 ± 0.002

0.949 ± 0.017
0.959 ± 0.012
0.966 ± 0.011
0.943 ± 0.013
0.960 ± 0.009
0.974 ± 0.007
0.954 ± 0.007
0.974 ± 0.005
0.988 ± 0.004

0.930 ± 0.019
0.939 ± 0.016
0.951 ± 0.013
0.906 ± 0.014
0.928 ± 0.012
0.949 ± 0.010
0.907 ± 0.007
0.931 ± 0.006
0.959 ± 0.006

0.588 ± 0.070
0.603 ± 0.067
0.627 ± 0.065
0.444 ± 0.065
0.487 ± 0.064
0.534 ± 0.062
0.429 ± 0.057
0.525 ± 0.054
0.636 ± 0.048

0.552 ± 0.069
0.563 ± 0.067
0.582 ± 0.065
0.376 ± 0.062
0.410 ± 0.060
0.455 ± 0.059
0.250 ± 0.040
0.328 ± 0.042
0.435 ± 0.046

0.475 ± 0.067
0.492 ± 0.066
0.512 ± 0.065
0.238 ± 0.047
0.281 ± 0.049
0.324 ± 0.050
0.110 ± 0.009
0.139 ± 0.013
0.203 ± 0.024

Open Category Detection with PAC Guarantees

Table 21. Recall & False Positive Rate for Shuttle Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Shuttle
n=5000

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.959 ± 0.008
0.972 ± 0.006
0.984 ± 0.004
0.975 ± 0.004
0.990 ± 0.002
0.998 ± 0.001
0.979 ± 0.002
0.996 ± 0.001
1.000 ± 0.000

0.941 ± 0.009
0.957 ± 0.008
0.973 ± 0.006
0.949 ± 0.005
0.973 ± 0.004
0.992 ± 0.002
0.948 ± 0.002
0.976 ± 0.002
0.997 ± 0.001

0.899 ± 0.011
0.923 ± 0.010
0.946 ± 0.009
0.902 ± 0.005
0.928 ± 0.004
0.958 ± 0.004
0.899 ± 0.002
0.925 ± 0.002
0.958 ± 0.002

0.147 ± 0.031
0.206 ± 0.039
0.287 ± 0.047
0.103 ± 0.016
0.192 ± 0.033
0.361 ± 0.043
0.089 ± 0.013
0.237 ± 0.028
0.541 ± 0.032

0.097 ± 0.018
0.135 ± 0.027
0.202 ± 0.037
0.063 ± 0.004
0.093 ± 0.011
0.187 ± 0.028
0.060 ± 0.002
0.083 ± 0.006
0.218 ± 0.022

0.057 ± 0.005
0.073 ± 0.010
0.104 ± 0.018
0.047 ± 0.001
0.054 ± 0.001
0.069 ± 0.004
0.049 ± 0.001
0.054 ± 0.001
0.065 ± 0.001

0.974 ± 0.007
0.985 ± 0.005
0.991 ± 0.003
0.983 ± 0.004
0.994 ± 0.002
0.999 ± 0.001
0.981 ± 0.002
0.997 ± 0.001
1.000 ± 0.000

0.956 ± 0.009
0.971 ± 0.007
0.984 ± 0.005
0.957 ± 0.005
0.979 ± 0.004
0.995 ± 0.002
0.949 ± 0.002
0.977 ± 0.002
0.998 ± 0.001

0.917 ± 0.013
0.938 ± 0.011
0.960 ± 0.009
0.904 ± 0.005
0.931 ± 0.004
0.963 ± 0.004
0.899 ± 0.002
0.926 ± 0.002
0.959 ± 0.002

0.419 ± 0.066
0.490 ± 0.065
0.545 ± 0.064
0.326 ± 0.058
0.457 ± 0.058
0.572 ± 0.053
0.151 ± 0.030
0.394 ± 0.042
0.642 ± 0.034

0.319 ± 0.059
0.371 ± 0.059
0.439 ± 0.060
0.150 ± 0.035
0.221 ± 0.042
0.368 ± 0.044
0.061 ± 0.002
0.106 ± 0.016
0.291 ± 0.027

0.180 ± 0.046
0.211 ± 0.047
0.273 ± 0.050
0.048 ± 0.001
0.066 ± 0.009
0.114 ± 0.020
0.049 ± 0.001
0.054 ± 0.001
0.066 ± 0.001

Open Category Detection with PAC Guarantees

Table 22. Recall & False Positive Rate for Covertype Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Covertype
n=13624

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.979 ± 0.002
0.995 ± 0.001
0.999 ± 0.000
0.980 ± 0.001
0.998 ± 0.000
1.000 ± 0.000
0.981 ± 0.001
0.998 ± 0.000
1.000 ± 0.000

0.950 ± 0.002
0.978 ± 0.001
0.997 ± 0.001
0.950 ± 0.001
0.980 ± 0.001
0.999 ± 0.000
0.951 ± 0.001
0.980 ± 0.001
0.999 ± 0.000

0.901 ± 0.002
0.930 ± 0.001
0.965 ± 0.001
0.902 ± 0.002
0.929 ± 0.001
0.964 ± 0.001
0.903 ± 0.001
0.929 ± 0.001
0.964 ± 0.001

0.012 ± 0.007
0.095 ± 0.025
0.292 ± 0.045
0.006 ± 0.002
0.143 ± 0.027
0.427 ± 0.043
0.010 ± 0.001
0.206 ± 0.030
0.555 ± 0.038

0.002 ± 0.000
0.012 ± 0.004
0.110 ± 0.025
0.003 ± 0.000
0.008 ± 0.002
0.154 ± 0.026
0.006 ± 0.000
0.012 ± 0.002
0.200 ± 0.022

0.002 ± 0.000
0.002 ± 0.000
0.004 ± 0.001
0.002 ± 0.000
0.002 ± 0.000
0.003 ± 0.000
0.005 ± 0.000
0.005 ± 0.000
0.007 ± 0.000

0.989 ± 0.002
0.998 ± 0.001
0.999 ± 0.000
0.986 ± 0.002
0.999 ± 0.000
1.000 ± 0.000
0.985 ± 0.002
0.999 ± 0.000
1.000 ± 0.000

0.962 ± 0.004
0.987 ± 0.002
0.998 ± 0.000
0.952 ± 0.002
0.983 ± 0.001
1.000 ± 0.000
0.951 ± 0.001
0.981 ± 0.001
1.000 ± 0.000

0.905 ± 0.004
0.937 ± 0.004
0.973 ± 0.003
0.902 ± 0.002
0.929 ± 0.001
0.965 ± 0.001
0.903 ± 0.001
0.929 ± 0.001
0.964 ± 0.001

0.359 ± 0.072
0.479 ± 0.067
0.586 ± 0.059
0.211 ± 0.055
0.420 ± 0.058
0.615 ± 0.047
0.136 ± 0.044
0.437 ± 0.051
0.677 ± 0.036

0.166 ± 0.051
0.276 ± 0.058
0.409 ± 0.060
0.018 ± 0.014
0.115 ± 0.035
0.319 ± 0.045
0.006 ± 0.000
0.050 ± 0.015
0.310 ± 0.034

0.028 ± 0.022
0.055 ± 0.029
0.123 ± 0.038
0.002 ± 0.000
0.002 ± 0.000
0.011 ± 0.003
0.005 ± 0.000
0.005 ± 0.000
0.007 ± 0.001

Open Category Detection with PAC Guarantees

Si Liu * 1 Risheek Garrepalli * 2 Thomas G. Dietterich 2 Alan Fern 2 Dan Hendrycks 3

8
1
0
2
 
g
u
A
 
1
 
 
]

G
L
.
s
c
[
 
 
1
v
9
2
5
0
0
.
8
0
8
1
:
v
i
X
r
a

Abstract
Open category detection is the problem of detect-
ing “alien” test instances that belong to categories
or classes that were not present in the training
In many applications, reliably detecting
data.
such aliens is central to ensuring the safety and
accuracy of test set predictions. Unfortunately,
there are no algorithms that provide theoretical
guarantees on their ability to detect aliens under
general assumptions. Further, while there are al-
gorithms for open category detection, there are
few empirical results that directly report alien de-
tection rates. Thus, there are signiﬁcant theoret-
ical and empirical gaps in our understanding of
open category detection. In this paper, we take
a step toward addressing this gap by studying a
simple, but practically-relevant variant of open
category detection. In our setting, we are pro-
vided with a “clean” training set that contains
only the target categories of interest and an un-
labeled “contaminated” training set that contains
a fraction α of alien examples. Under the as-
sumption that we know an upper bound on α, we
develop an algorithm with PAC-style guarantees
on the alien detection rate, while aiming to mini-
mize false alarms. Empirical results on synthetic
and standard benchmark datasets demonstrate the
regimes in which the algorithm can be effective
and provide a baseline for further advancements.

1. Introduction

Most machine learning systems implicitly or explicitly as-
sume that their training experience is representative of their
test experience. This assumption is rarely true in real-world
deployments of machine learning, where “unknown un-
knowns”, or “alien” data, can arise without warning. Ig-

*Equal contribution 1Department of Statistics, Oregon State
University, Oregon, USA 2School of EECS, Oregon State Univer-
sity, Oregon, USA 3University of California, Berkeley, California,
USA. Correspondence to: Si Liu <lius2@oregonstate.edu>.

Proceedings of the 35 th International Conference on Machine
Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018
by the author(s).

noring the potential for such aliens can lead to serious safety
concerns in many applications and signiﬁcantly degrade
the accuracy of test set predictions in others. For exam-
ple, consider a scientiﬁc application where a classiﬁer is
trained to recognize speciﬁc categories of insects in fresh-
water samples in order to detect important environmental
changes (Lytle et al., 2010). Test samples will typically
contain some fraction of specimens belonging to species
not represented in the training data. A classiﬁer that is un-
aware of these new species will misclassify the specimens
as belonging to existing species. This will produce incorrect
scientiﬁc conclusions.

The problem of open category detection is to detect such
alien examples at test time. An ideal algorithm for this prob-
lem would guarantee a user-speciﬁed alien-detection rate
(e.g., 95%), while attempting to minimize the false alarm
rate. Unfortunately, no existing algorithm provides such
guarantees under general conditions. In addition, empir-
ical evaluations of existing algorithms for open category
detection typically do not directly evaluate alien detection
rates, which are perhaps the most relevant for safety-critical
applications. Overall, our current theoretical and practical
understanding of open category detection is lacking from a
safety and accuracy perspective.

Is it possible to achieve open category detection with guar-
antees? In this paper, we take a step toward answering
this question by studying a simpliﬁed, but practically rel-
evant, problem setting. To motivate our setting, consider
the above insect identiﬁcation problem. At training time it
is reasonable to expect that a clean training set is available
that contains only the insect categories of interest. At test
time, a new sample will include insects from the training
categories along with some percentage of insects from new
alien categories. Further, scientists may have reasonable
estimates for this percentage based on their scientiﬁc knowl-
edge and practical experience. We would like to guarantee
that the system is able to raise an alarm for, say, 95% of the
insects from alien classes, with each alarm being examined
by a scientist. At the same time, we would like to avoid as
many “false alarms” as possible, since each alarm requires
scientist effort.

To formalize the example, our setting assumes two training
sets: a clean training dataset involving a ﬁnite set of cate-

Open Category Detection with PAC Guarantees

gories and a contaminated dataset that contains a fraction α
of aliens. Our ﬁrst contribution is to show that, in this setting,
theoretical guarantees are possible given knowledge of an
upper bound on α. In particular, we give an algorithm that
uses this knowledge to provide Probably Approximately
Correct (PAC) guarantees for achieving a user-speciﬁed
alien detection rate. While knowledge of a non-trivial upper
bound on α may not always be possible, in many situations
it will be possible to select a reasonable value based on
domain knowledge, prior data, or by inspecting a sample of
the test data.

The key idea behind our algorithm is to leverage modern
anomaly detectors, which are trained on the clean data. Our
algorithm combines the anomaly-score distributions over
the clean and contaminated training data in order to derive
an alarm threshold that achieves the desired guarantee on
the alien detection rate on new test queries. In theory the
detection rate guarantee will be met regardless of the quality
of the anomaly detector. The quality of the detector, how-
ever, has a signiﬁcant impact on the false alarm rate, with
better detectors leading to fewer false alarms.

We carry out experiments1 on synthetic and benchmark
datasets using a state-of-the-art anomaly detector, the Iso-
lation Forest (Liu et al., 2008). We vary the amount of
training data, the fraction α of alien data points, along with
the accuracy of the upper bound on α provided to our algo-
rithm. The results indicate that our algorithm can achieve
the guaranteed performance when enough data is available,
as predicted by the theory. The results also show that for
the considered benchmarks, the Isolation Forest anomaly
detector is able to support non-trivial false positive rates
given enough data. The results also illustrate the inherent
difﬁculty of the problem for small datasets and/or small
values of α. Overall, our results provide a useful baseline
for driving future work on open category detection with
guarantees.

2. Related Work

Open category detection is related to the problem of one-
class classiﬁcation, which aims to detect outliers relative
to a single training class. One-class SVMs (OCSVMs)
(Sch¨olkopf et al., 2001) are popular for this problem. How-
ever, they have been found to perform poorly for open
category detection due to poor generalization (Zhou &
Huang, 2003), which has been partly addressed by later
work (Manevitz & Yousef, 2002; Wu & Ye, 2009; Jin et al.,
2004; Cevikalp & Triggs, 2012). OCSVMs have been em-
ployed in a multi-class setting similar to open category de-
tection (Heﬂin et al., 2012; Pritsos & Stamatatos, 2013).

1Code for reproducing our experiments can be found at

https://github.com/liusi2019/ocd.

However, there are no direct mechanisms to control the alien
detection rate of these methods, which is a key requirement
for our problem setting.

Work on classiﬁcation with rejection/abstaining options
(Chow, 1970; Wegkamp, 2007; Tax & Duin, 2008;
Pietraszek, 2005; Geifman & El-Yaniv, 2017) allows classi-
ﬁers to abstain from making predictions when they are not
conﬁdent. While loosely related to open category detection,
these approaches do not directly consider the possibility of
novel categories, but rather focus on assessing conﬁdence
with respect to the known categories. Due to their closed-
world discriminative nature, it is easy to construct scenarios
where such methods are incorrectly conﬁdent about the class
of an alien and do not abstain.

A variety of prior work has addressed variants of open cat-
egory detection. This includes work on formalizing the
concept of “open space” to characterize the region of the fea-
ture space outside of the support of the training set (Scheirer
et al., 2013). Variants of SVMs have also been developed,
such as the One-vs-Set Machine (Scheirer et al., 2013) and
the Weibull-calibrated SVM (Scheirer et al., 2014). Ad-
ditional work has addressed open category detection by
tuning the decision boundary based on unlabeled data which
contains data from novel categories (Da et al., 2014). Ap-
proaches based on nearest neighbor methods have also been
proposed (Mendes J´unior et al., 2017). None of these meth-
ods, however, allow for the direct control of alien detection
rates, nor do they provide theoretical guarantees.

There is also recent interest in open category detection for
deep neural networks applied to vision and text classiﬁcation
(Bendale & Boult, 2016; Shu et al., 2017). These methods
usually train a neural network in a standard closed-world
setting, but then analyze various activations in the network
in order to detect aliens. Another related line of work is
detection of out-of-distribution instances, which is similar
to open category detection but assumes that the test data
come from a completely different distribution compared to
the training distribution (Hendrycks & Gimpel, 2017; Liang
et al., 2018). All of this work is quite specialized to deep
neural networks and does not provide direct control of alien
detection rates or theoretical guarantees.

3. Problem Setup

We consider open category detection where there is an un-
known nominal data distribution D0 over labeled examples
from a known set of category labels. We receive as input
a “clean” nominal training set S0 containing k i.i.d. draws
from D0. In practice, S0 will correspond to some curated
labeled data that contains only known categories of interest.

We also receive as input an unlabeled “mixture” dataset
Sm that contains n points drawn i.i.d. from a mixture dis-

Open Category Detection with PAC Guarantees

tribution Dm. Speciﬁcally, the mixture distribution Dm is
a combination of the nominal distribution D0 and an un-
known alien distribution Da, which is a distribution over
novel categories (alien data points). We assume that Da is
stationary, so that all alien points that appear as future test
queries will also be drawn from Da.

At training time, we assume that Dm is a mixture distribu-
tion, with probability α of generating an alien data point
from Da and probability of 1 − α of generating a nominal
point. Our results hold even if the test queries come from a
mixture with a different value of α as long as the alien test
points are drawn from Da.

Given these datasets, our problem is to label test instances
from Dm as either “alien” or “nominal”. In particular, we
wish to achieve a speciﬁed alien detection rate, which is
the fraction of alien data points in Dm that are classiﬁed as
“alien” (e.g., 95%). At the same time we would like the false
positive rate to be small, which is the fraction of nominal
data points incorrectly classiﬁed as aliens.

Our approach to this problem assumes the availability of an
anomaly detector that is trained on S0 and assigns anomaly
scores to all data points in both S0 and Sm. Intuitively, the
anomaly scores order the test examples according to how
anomalous they appear relative to the nominal data (higher
scores being more anomalous). An ideal detector would
rank all alien data points higher than all nominals, though
in practice, the ordering will not be so clean. Our approach
labels data in Sm by selecting a threshold on the anomaly
scores and labeling all data points with scores above the
threshold as aliens and the remaining points as nominals.
Our key challenge is to select a threshold that provides a
guarantee on the alien detection rate.

4. Algorithms for Open Category Detection

In order to obtain theoretical guarantees, our algorithm as-
sumes knowledge of the alien mixture probability α that
generates the mixture data Sm. Later, we will show that
knowing an upper bound on α is sufﬁcient to obtain a guar-
antee.

Our approach is based on considering the cumulative dis-
tribution functions (CDFs) over anomaly scores of a ﬁxed
anomaly detector. Let F0, Fa, and Fm be the CDFs of
anomaly scores for the nominal data distribution D0, alien
distribution Da, and mixture distribution Dm respectively.
Since Dm is a simple mixture of D0 and Da, we can write
Fm as

Fm(x) = (1 − α)F0(x) + αFa(x).

From this we can derive the CDF for Fa in terms of Fm and
F0:

Fa(x) =

Fm(x) − (1 − α)F0(x)
α

.

Given the ability to derive Fa, it is straightforward to achieve
an alien detection rate of 1 − q (e.g. 95%) by selecting an
anomaly score threshold τq that is the q quantile of Fa and
raising an alarm on all test queries whose anomaly score is
greater than τq.

In reality, we do not have access to Fm or F0 and hence
cannot exactly determine Fa. Rather, we have samples
Sm and S0. Thus, our algorithm works with the empirical
CDFs ˆF0 and ˆFm, which are simple step-wise constant
approximations, and estimates an empirical CDF over aliens:

ˆFa(x) =

ˆFm(x) − (1 − α) ˆF0(x)
α

.

(1)

Our algorithm computes the above estimate of ˆFa and uses
it to select a threshold ˆτq to be the largest threshold such
that ˆFa(ˆτq) ≤ q, where 1 − q is the target alien detection
rate. This choice will minimize the number of false alarms.
The steps of this algorithm are as follows.

Algorithm 1
1: Get anomaly scores for all points in S0 and Sm, denoted

x1, x2, . . . , xk and y1, y2, . . . , yn respectively.

2: Compute empirical CDFs ˆF0 and ˆFm.
3: Calculate ˆFa using equation 1.
4: Output detection threshold

ˆτq = max{u ∈ S : ˆFa(u) ≤ q},

where S = {x1, x2, . . . , xk, y1, y2, . . . , yn}.

Although ˆFm and ˆF0 are both legal CDFs, the estimate
for ˆFa from step 3 may not be a legal CDF, because it is
the difference of two noisy estimates—it may not increase
monotonically and it may even be negative. A good tech-
nique for dealing with this problem is to employ isotoniza-
tion (Barlow & Brunk, 1972) and clipping. Isotonization
ﬁnds the monotonically increasing function ˆF ∗
a closest to
ˆFa in squared error. To convert ˆFa into a legal CDF, deﬁne
ˇFa = min{max{ ˆF ∗
a , 0}, 1}, where the min and max opera-
tors are applied pointwise to their arguments. We performed
experiments (shown in the supplementary materials) to test
whether using ˇFa in Step 4 would improve the performance
of the overall algorithm. We found that it did not.

5. Finite Sample Guarantee

In the limit of inﬁnite data (both nominal and mixture) and
perfect knowledge of α, ˆFa will converge to the true alien
CDF, and our algorithm will achieve the desired alien de-
tection rate. In this section, we consider the ﬁnite data case
where |S0| = |Sm| = n. We derive a value for the sample
size n that guarantees with high probability over random

Open Category Detection with PAC Guarantees

draws of S0 and Sm, that fraction 1 − q − (cid:15) of the alien
test points will be detected, where (cid:15) is an additional error
incurred because of the ﬁnite sample size n.

Our key theoretical tool is a ﬁnite sample result on the
uniform convergence of empirical CDF functions (Massart,
1990). To use this result, we make the reasonable technical
assumption that the nominal and alien CDFs, F0 and Fa,
are continuous. In the following, let η be the target alien
detection rate, q be the input to Algorithm 1, ˆτq be the
estimated q-quantile of the alien CDF (step 4 of Alg. 1),
and (cid:15) be an error parameter. The following theorem gives
the sample complexity for guaranteeing that 1 − η of the
alien examples will be detected using threshold ˆτq.
Theorem 1. Let S0 and Sm be nominal and mixture
datasets containing n i.i.d. samples from the nominal and
mixture data distributions respectively. For any (cid:15) ∈ (0, 1−q)
and δ ∈ (0, 1), if

n >

ln

1
2

2
√
1 − δ

(cid:18) 1
(cid:15)

1 −

(cid:19)2 (cid:18) 2 − α

(cid:19)2

,

α

the alien CDF will typically concentrate more mass toward
larger anomaly score values compared to F0. Indeed, if this
is not the case, there is little hope since there is effectively
no signal to distinguish between aliens and nominals.

Corollary 1. Consider running Algorithm 1 using an upper
bound α(cid:48) on the true α. Under the same assumptions as
Theorem 1, if the anomaly detector is admissible and

n >

ln

1
2

2
√
1 − δ

(cid:18) 1
(cid:15)

1 −

(cid:19)2 (cid:18) 2 − α(cid:48)

(cid:19)2

,

α(cid:48)

then with probability at least 1 − δ, Algorithm 1 will return
a threshold ˆτq that achieves an alien detection rate of at
least 1 − η, where η = q + (cid:15).

The proof is in the Appendix. While we can achieve a guar-
antee using an upper bound on α(cid:48), the returned threshold
will be more conservative (smaller) than if we had used the
true α. This will result in higher false alarm rates, since
more nominal points will be above the threshold. Thus it is
desirable to use a value of α(cid:48) that is as close to α as possible.

then with probability at least 1 − δ, Algorithm 1 will return
a threshold ˆτq that achieves an alien detection rate of at
least 1 − η, where η = q + (cid:15).

6. Experiments

(cid:15)2α2 log 1

The proof is in the Appendix. Note that n grows as
O( 1
δ ). Hence, this guarantee is polynomial in all
relevant parameters, which we believe is the ﬁrst such guar-
antee for open category detection. The result can be gener-
alized to the case where n0 < nm; in practice, the larger
the mixture sample Sm is, the easier it is to estimate τq,
because this provides more alien points for estimating the
q-th quantile of Fa.

The theorem gives us ﬂexibility in setting (cid:15) and q (the algo-
rithm input) to achieve a guarantee of 1−η. The (cid:15) parameter
controls a trade-off between sample size and false alarm rate.
To minimize the false alarm rate, we want to make q large
(to obtain a larger threshold), so we want to set q close to η.
But, as q → η, (cid:15) → 0, and n → ∞. To minimize the sample
size n, we want to make q as small as possible, because that
allows (cid:15) to be larger and hence n becomes smaller. The
optimal setting of (cid:15) depends on how the false alarm rate
grows with τq, which in turn depends on the relative shape
of F0 and Fa. In a real safety application, we can estimate
these from S0 and Sm and choose an appropriate q value.

What if we don’t know the exact value of α? If our algorithm
uses an upper bound α(cid:48) on the true α to compute ˆFa, we
can still provide a guarantee. In this case, in addition to the
assumptions in Theorem 1, we need a concept of an anomaly
detector being admissible. We say that an anomaly detector
is admissible for a problem, if the anomaly score CDFs
satisfy F0(x) ≥ Fm(x) for all x ∈ R. Most reasonable
anomaly detectors will be admissible in this sense, since

We performed experiments to answer four questions. Ques-
tion Q1: how accurate is our estimate of ˆτq as a function of
n and α? Question Q2: how loose are the bounds from The-
orem 1? Question Q3: what are typical values of the false
alarm rates for various settings of n and α on real datasets?
Question Q4: how do these observed values change if we
employ an overestimate α(cid:48) > α?

All of our experiments employ the Isolation Forest anomaly
detector (Liu et al., 2008), which has been demonstrated
to be a state-of-the-art detector in recent empirical studies
In the Supplementary Materials
(Emmott et al., 2013).
we show similar results with the LODA anomaly detector
(Pevn´y, 2015).

To address Q1 and Q2, we run controlled experiments
on synthetic data. The data points are generated from 9-
dimensional normal distributions. The dimensions of the
nominal distribution D0 are independently distributed as
N (0, 1). The alien distribution is similar, but with probabil-
ity 0.4, 3 of the 9 dimensions (chosen uniformly at random)
are distributed as N (3, 1) and with probability 0.6, 4 of the
9 dimensions (chosen uniformly at random) follow N (3, 1).
This ensures that the anomalies are not highly similar to
each other and models the situation in which there are many
different kinds of alien objects, not just a single alien class
forming a tight cluster.

In each experiment, the nominal dataset and the mixture
dataset are of the same size n, and the mixture dataset
contains a proportion α of anomaly points. We ﬁxed
the target quantile to be q = 0.05. The experiments are

Open Category Detection with PAC Guarantees

Figure 1. Comparison of recall achieved by ˆτq compared to oracle
recall of 0.95. Error bars are 95% conﬁdence intervals. Settings
of n and α increase from left to right starting with α = 0.01 and
n ∈ {100, 500, 1K, 5K, 10K} up to α = 0.5 and n = 10K.

carried out for n ∈ {100, 500, 1K, 5K, 10K} and α ∈
{0.01, 0.05, 0.10, 0.20, 0.50}. For testing, we create two
large datasets G0 and Ga, with G0 being a pure nominal
dataset, Ga being a pure alien dataset, and |G0| = |Ga| =
20K. The Isolation Forest algorithm computes 1000 full
depth isolation trees on the nominal data. Each tree is grown
on a randomly-selected 20% subsample of the clean data
points. We compute anomaly scores for the nominal points
via out-of-bag estimates and anomaly scores for the mix-
ture points, G0, and Ga using the full isolation forest. For
each combination of n and α, we repeat the experiment
100 times. We measure the fraction of aliens detected (the
“recall”) and the fraction of nominal points declared to be
alien (the “false positive rate”) by applying the ˆτq estimate
to threshold the anomaly scores in G0 and Ga.

To assess the accuracy of our ˆτq estimates (Q1), we could
compare them to the true values. However, this comparison
is hard to interpret, because τ is expressed on the scale
of anomaly scores, which are somewhat arbitrary. Instead,
Figure 1 plots the recall achieved by ˆτq. If ˆτq had been
estimated perfectly, the recall would always be 1−q = 0.95.
However, we see that the recall is often less than 0.95, which
indicates that ˆτq is over-estimated, especially when n and α
are small. This behavior is predicted by our theory, where
we see that the sample size requirements grow inversely
with α2. For larger α and n, the recall guarantee is generally
achieved. Figure 2 compares the false positive rate of the
true oracle τq to the false positive rate of the estimate ˆτq. For
each combination of α and n, we have 100 replications of
the experiment and therefore 100 estimates ˆτa and 100 FPR
rates. For each of these, the true FPR is computed using G0.

Figure 2. Comparison of oracle FPR to the FPR achieved by ˆτq.
Error bars span from the 25th to 75th percentile with the blue dot
marking the median of the 100 trials. Orange markers indicate the
oracle FPR. Settings of n and α increase from left to right starting
with α = 0.01 and n ∈ {100, 500, 1K, 5K, 10K} up to α = 0.5
and n = 10K.

The error bars summarize the resulting 100 FPR values by
the median and inter-quartile range. We see that for small n
and α, the FPR can be quite different from the oracle rate,
but for larger n and α, the estimates are very good.

To assess the looseness of the bounds (Q2), for each combi-
nation of n and α, we ﬁx δ = 0.05 and compute the value
of η such that 95 of the 100 runs achieved a recall of at least
1 − η (thus η empirially achieves the 1 − δ guarantee). We
then compute (cid:15) = η − q and the corresponding required
sample size n∗ according to Theorem 1. Figure 3 shows a

Figure 3. The log sample size n∗ required by Theorem 1 in order
to guarantee the actual observed recall versus the log actual sample
size n.

Open Category Detection with PAC Guarantees

plot of n∗ versus the actual n. The distance of these points
from the n∗ = n diagonal line show that the theory is fairly
loose, although it becomes tighter as n gets large.

Figure 4. False positive rates on six UCI datasets as a function of
α (q = 0.05, δ = 0.05).

Benchmark Data Experiments. To address our third and
fourth questions, we performed experiments on six UCI
multiclass datasets: Landsat, Opt.digits, pageb, Shuttle,
Covertype and MNIST. In addition to these, we provide
results for the Tiny ImageNet dataset. In each multiclass
dataset, we split the classes into two groups: nominal and
alien. For Tiny ImageNet, we train a deep neural network
classiﬁer on 200 nominal classes and treat the remaining
800 as aliens. The nominal classes for UCI datasets are
MNIST(1,3,7), Landsat(1,7), OCR(1,3,4,5,7), pageb(1,5),
Letter recognition(1,3), and Shuttle(1,4). We generated

Figure 5. Recall rates on six UCI datasets as a function of α (q =
0.05, δ = 0.05)

Figure 6. False positive rates on two image datasets as a function
of α (q = 0.05, δ = 0.05).

nominal and mixture datasets for various values of α. The
value of n for each dataset is 1532 for Landsat,788 for Letter
recognition, 568 for OCR, 4912 for pageb, 5000 for Shuttle,
13,624 for Covertype, 11,154 for MNIST, and 10,000 for
Tiny ImageNet. Because we cannot create datasets with
large n, we cannot measure the true value of τq.

After computing the anomaly scores for both nominal and
mixture datasets, we applied Algorithm 1 within a 10-fold
cross validation. We divide the mixture data points at ran-
dom into 10 groups. For each fold, we estimate ˆFa and ˆτa
from 9 of the 10 groups and then score the mixture points in
the held-out fold according to ˆτa. In all other respects, the
experimental protocol is the same as for the synthetic data.
For Tiny ImageNet, the anomaly scores are obtained by
applying a baseline method (Hendrycks & Gimpel, 2017).

To answer Q3, Figures 4 and 6 plot the false positive rate as
a function of α for the UCI and vision datasets, respectively.
We see that the FPR ranges from 3.6% to 26.9% on UCI
depending on the dataset and the level of α. The vision
datasets have higher FPR, especially MNIST, which has a
large number of alien classes that are not distinguished well
by the anomaly detector. The FPR depends primarily on
the domain, because the key issue is how well the anomaly
detector distinguishes between nominal and alien examples.
The false alarm rate generally improves as α increases. In
some applications, it may be possible to enrich Sm so that
α is larger on the training set to take advantage of this
phenomenon. It is interesting to note that once ˆτa has been
computed, it can be applied to test datasets having different
(or unknown) values of α.

Figures 5 and 7 plot the recall rate as a function of α for
the UCI and vision datasets. We set q = 0.05 in these
experiments. Theorem 1 only guarantees a recall of 1−q −(cid:15),

Open Category Detection with PAC Guarantees

of α(cid:48) − α. Two points are plotted for each combination
of α(cid:48) and dataset, the change in Recall and the change in
FPR. We observe that the recall increases slightly (in the
range from 0.01 to 0.05). However, the false positive rate
increases by much larger amounts (from 0.01 to 0.336). This
demonstrates that it is very important to determine the value
of α accurately.

7. Summary

We have taken a step toward open category detection with
guarantees by providing a PAC-style guarantee on the prob-
ability of detecting 1 − η of the aliens on the test data. This
is the ﬁrst such guarantee under any similarly general con-
ditions. We have shown that this guarantee is satisﬁed in
our experiments, although the guarantee is somewhat loose,
especially on small training sets. Obtaining a guarantee re-
quires more data than standard PAC guarantees on expected
prediction accuracy. This is because we must estimate the
q quantile of the alien anomaly score distribution, where
q is typically quite small. Nonetheless, our experiments
show that our algorithm gives good recall performance and
non-trivial false alarm rates on datasets of reasonable size.

It is important to note that the very formulation of a PAC-
style guarantee on the probability of detecting aliens re-
quires assuming that the aliens are drawn from a well-
deﬁned distribution Da. While this is appropriate in some
applications, such as the insect survey application described
in the introduction, it is not appropriate for adversarial set-
tings. In such settings, a PAC-style guarantee does not make
sense, and some other form of safety guarantee needs to be
formulated.

To obtain the guarantee, we employ two training datasets:
a clean dataset that contains no aliens and an (unlabeled)
contaminated dataset that contains a known fraction α of
aliens. An important theoretical problem for future research
is to develop a method that can estimate a tight upper bound
on ˆα > α. We believe this is possible, but we have not yet
found a method that guarantees that ˆα > α.

Our guarantee requires more data as α becomes small. For-
tunately, when α is small, it may be possible in some appli-
cations to afford lower recall rates, since the frequency of
aliens will be smaller. However, in safety-critical applica-
tions where a single undetected alien poses a serious threat,
there is little recourse other than to collect more data or
allow for higher false positive rates.

Acknowledgements

This research was supported by a gift from Huawei, Inc.,
and grants from the Future of Life Institute and the NSF
Grant 1514550. Any opinions, ﬁndings, and conclusions

Figure 7. Recall rates on two image datasets as a function of α
(q = 0.05, δ = 0.05).

Figure 8. Change in recall and false positive rate as a function of
α(cid:48) − α for six UCI datasets; α ∈ {0.1, 0.2, 0.4}

where (cid:15) depends on n. Hence, it is nice to see that for
three of the domains (Shuttle, Covertype, and Landsat) in
UCI and for both vision datasets, the recall is very close to
1 − q = 0.95. These are the domains with the largest values
of n. The value of α has a bigger impact on recall than it
does on FPR. This is because the effective number of alien
training examples is αn, which can be very small for some
datasets when α = 0.1. This shows that in applications such
as fraud detection, where α may be very small, the mixture
dataset Sm needs to be very large.

To answer Q4 regarding the impact of using an incorrect
value α(cid:48) > α, we repeated these experiments with α(cid:48) =
α+ξ, for ξ ∈ {0.002, 0.004, 0.006, 0.008, 0.010}. Figure 8
plots the change in false positive rate and recall as a function

Open Category Detection with PAC Guarantees

or recommendations expressed in this material are those of
the author(s) and do not necessarily reﬂect the views of the
sponsors.

we will have

A. Proof for Theorem 1

Suppose there are n random variables which are i.i.d. from
the distribution with CDF F and let ˆFn be the empirical
CDF calculated from this sample. Then Massart (1990)
shows that

√

P (

n sup
x

| ˆFn(x) − F (x)| > λ) ≤ 2 exp(−2λ2)

(2)

holds without any restriction on λ. Making use of this,
and assuming we use the same sample size n for both the
mixture dataset and the clean data set, for any (cid:15) ∈ (0, 1 − q),
we seek to determine how large n needs to be in order to
guarantee that with probability at least 1 − δ our quantile
estimate ˆτq satisﬁes Fa(ˆτq) ≤ q + (cid:15). To achieve this, we
want to have

P (sup

| ˆFa(x) − Fa(x)| > (cid:15)) ≤ δ.

We have

x

x

x

x

x

1
2

P (sup

| ˆFa(x) − Fa(x)| > (cid:15))

= P (sup

|

ˆFm(x) − (1 − α) ˆF0(x)
α

−

Fm(x) − (1 − α)F0(x)
α
( ˆFm(x) − Fm(x)) −

| > (cid:15))

|

= P (sup

1
α

( ˆF0(x) − F0(x))| > (cid:15))

≤ P ((

| ˆFm(x) − Fm(x)| +

x
1 − α
α

1
α
1 − α
α

sup
x

sup
x

1
sup
α
x
1 − α
α

sup
x

∪ {

1
2 − α

(cid:15)}

1 − α
2 − α

(cid:15)})

≤ P ({

| ˆFm(x) − Fm(x)| >

= P ({sup

| ˆFm(x) − Fm(x)| >

∪ {sup

| ˆF0(x) − F0(x)| >

| ˆF0(x) − F0(x)| >
α
2 − α
α
2 − α

(cid:15)}

(cid:15)}).

| ˆF0(x) − F0(x)|) > (cid:15))

But

Making use of (2), when

n >

ln

2
√
1 − δ

(

1
(cid:15)

)2(

2 − α
α

)2,

1 −

P (sup

| ˆFm(x) − Fm(x)| >

(cid:15)) ≤ 1 −

1 − δ,

P (sup

| ˆF0(x) − F0(x)| >

(cid:15)) ≤ 1 −

1 − δ.

α
2 − α
α
2 − α

√

√

x

x

In this case we will have

P (sup

| ˆFa(x) − Fa(x)| > (cid:15))

x

≤ 1 − P ({sup

x

| ˆFm(x) − Fm(x)| ≤
α
2 − α

| ˆF0(x) − F0(x)| ≤

(cid:15)})

α
2 − α

(cid:15)}

∩ {sup

x
≤ 1 − (1 − 1 +

√

1 − δ)2

= δ.

Now we have with probability at least 1 − δ,

| ˆFa(x) − Fa(x)| ≤ (cid:15), ∀x ∈ R.

If this inequality holds, then for any value ˆτq such that
ˆFa(ˆτq) ≤ q, we have

Fa(ˆτq) ≤ ˆFa(ˆτq) + (cid:15) ≤ q + (cid:15).

So we have with probability at least 1 − δ, any ˆτq satisfying
ˆFa(ˆτq) ≤ q will satisfy Fa(ˆτq) ≤ q + (cid:15).
(cid:3)

B. Proof for Corollary 1

If α(cid:48) ≥ α, and if we write

F (cid:48)

a(x) =

Fm(x) − (1 − α(cid:48))F0(x)
α(cid:48)

,

then F (cid:48)

a is still a legal CDF, because

a(−∞) = 0, F (cid:48)
F (cid:48)

a(∞) = 1,

and it is easy to show that F (cid:48)
ing.

a is monotonically nondecreas-

F (cid:48)

≥ 0, ∀x ∈ R,

a(x)−Fa(x) =

(α − α(cid:48))(Fm(x) − F0(x))
αα(cid:48)
and because of this, if we let ˆτ (cid:48)
q denote the threshold we
get from using α(cid:48), we will have Fa(ˆτ (cid:48)
q) ≤ F (cid:48)
q). By
the proof of previous theorem, we know that when n >
2
1
α(cid:48) )2, we have with probability at least
2 ln
√
1−δ
q) ≤ q + (cid:15).(cid:3)
a(ˆτ (cid:48)
1 − δ, F (cid:48)

(cid:15) )2( 2−α(cid:48)
( 1
q) ≤ q + (cid:15), and thus we have Fa(ˆτ (cid:48)

a(ˆτ (cid:48)

1−

References

Barlow, RE and Brunk, HD. The isotonic regression prob-
lem and its dual. Journal of the American Statistical
Association, 67(337):140–147, 1972.

Open Category Detection with PAC Guarantees

Bendale, A. and Boult, T. E. Towards open set deep net-
works. In 2016 IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), pp. 1563–1572, June
2016.

Cevikalp, H. and Triggs, B. Efﬁcient object detection using
cascades of nearest convex model classiﬁers. In 2012
IEEE Conference on Computer Vision and Pattern Recog-
nition, pp. 3138–3145, June 2012.

Chow, C. On optimum recognition error and reject tradeoff.
IEEE Transactions on Information Theory, 16(1):41–46,
Jan 1970. ISSN 0018-9448.

Da, Qing, Yu, Yang, and Zhou, Zhi-Hua. Learning with
augmented class by exploiting unlabeled data. In Pro-
ceedings of the Twenty-Eighth AAAI Conference on Artiﬁ-
cial Intelligence, AAAI’14, pp. 1760–1766. AAAI Press,
2014.

Emmott, Andrew F, Das, Shubhomoy, Dietterich, Thomas,
Fern, Alan, and Wong, Weng-Keen. Systematic construc-
tion of anomaly detection benchmarks from real data. In
Proceedings of the ACM SIGKDD workshop on outlier
detection and description, pp. 16–21. ACM, 2013.

Geifman, Yonatan and El-Yaniv, Ran. Selective classiﬁca-
tion for deep neural networks. In Guyon, I., Luxburg,
U. V., Bengio, S., Wallach, H., Fergus, R., Vishwanathan,
S., and Garnett, R. (eds.), Advances in Neural Informa-
tion Processing Systems 30, pp. 4885–4894. Curran As-
sociates, Inc., 2017.

Heﬂin, B., Scheirer, W., and Boult, T. E. Detecting and
classifying scars, marks, and tattoos found in the wild. In
2012 IEEE Fifth International Conference on Biometrics:
Theory, Applications and Systems (BTAS), pp. 31–38,
Sept 2012.

Hendrycks, Dan and Gimpel, Kevin. A baseline for de-
tecting misclassiﬁed and out-of-distribution examples in
neural networks. In Proceedings of International Confer-
ence on Learning Representations, 2017.

Jin, Hongliang, Liu, Qingshan, and Lu, Hanqing. Face
detection using one-class-based support vectors. In Sixth
IEEE International Conference on Automatic Face and
Gesture Recognition, 2004. Proceedings., pp. 457–462,
May 2004.

Liang, Shiyu, Li, Yixuan, and Srikant, R. Enhancing the
reliability of out-of-distribution image detection in neural
networks. International Conference on Learning Repre-
sentations, 2018.

Lytle, David A, Mart´ınez-Mu˜noz, Gonzalo, Zhang, Wei,
Larios, Natalia, Shapiro, Linda, Paasch, Robert, Mold-
enke, Andrew, Mortensen, Eric N, Todorovic, Sinisa, and
Dietterich, Thomas G. Automated processing and identi-
ﬁcation of benthic invertebrate samples. Journal of the
North American Benthological Society, 29(3):867–874,
2010.

Manevitz, Larry M. and Yousef, Malik. One-class svms for
document classiﬁcation. J. Mach. Learn. Res., 2:139–154,
March 2002. ISSN 1532-4435.

Massart, P. The tight constant in the dvoretzky-kiefer-
wolfowitz inequality. The Annals of Probability, 18(3):
1269–1283, 1990. ISSN 00911798.

Mendes J´unior, Pedro R., de Souza, Roberto M., Werneck,
Rafael de O., Stein, Bernardo V., Pazinato, Daniel V.,
de Almeida, Waldir R., Penatti, Ot´avio A. B., Torres,
Ricardo da S., and Rocha, Anderson. Nearest neighbors
distance ratio open-set classiﬁer. Machine Learning, 106
(3):359–386, Mar 2017. ISSN 1573-0565.

Pevn´y, Tom´aˇs. Loda: Lightweight on-line detector of
anomalies. Machine Learning, (November 2014), 2015.

Pietraszek, Tadeusz. Optimizing abstaining classiﬁers using
roc analysis. In Proceedings of the 22Nd International
Conference on Machine Learning, ICML ’05, pp. 665–
672, New York, NY, USA, 2005. ACM. ISBN 1-59593-
180-5.

Pritsos, Dimitrios A. and Stamatatos, Efstathios. Open-
Set Classiﬁcation for Automated Genre Identiﬁcation, pp.
207–217. Springer Berlin Heidelberg, Berlin, Heidelberg,
2013. ISBN 978-3-642-36973-5.

Scheirer, W. J., de Rezende Rocha, A., Sapkota, A., and
Boult, T. E. Toward open set recognition. IEEE Transac-
tions on Pattern Analysis and Machine Intelligence, 35
(7):1757–1772, July 2013. ISSN 0162-8828.

Scheirer, W. J., Jain, L. P., and Boult, T. E. Probability
models for open set recognition. IEEE Transactions on
Pattern Analysis and Machine Intelligence, 36(11):2317–
2324, Nov 2014. ISSN 0162-8828.

Sch¨olkopf, Bernhard, Platt, John C., Shawe-Taylor, John C.,
Smola, Alex J., and Williamson, Robert C. Estimating
the support of a high-dimensional distribution. Neural
Comput., 13(7):1443–1471, July 2001. ISSN 0899-7667.

Shu, Lei, Xu, Hu, and Liu, Bing. DOC: deep open classiﬁ-
cation of text documents. CoRR, abs/1709.08716, 2017.

Liu, Fei Tony, Ting, Kai Ming, and Zhou, Zhi-Hua. Isolation
forest. In Data Mining, 2008. ICDM’08. Eighth IEEE
International Conference on, pp. 413–422. IEEE, 2008.

Tax, D.M.J. and Duin, R.P.W. Growing a multi-class classi-
ﬁer with a reject option. Pattern Recognition Letters, 29
(10):1565 – 1570, 2008. ISSN 0167-8655.

Open Category Detection with PAC Guarantees

Wegkamp, Marten H. Lasso type classiﬁers with a reject

option. 2007.

Wu, M. and Ye, J. A small sphere and large margin ap-
proach for novelty detection using training data with out-
liers. IEEE Transactions on Pattern Analysis and Ma-
chine Intelligence, 31(11):2088–2092, Nov 2009. ISSN
0162-8828.

Zhou, Xiang Sean and Huang, Thomas S. Relevance feed-
back in image retrieval: A comprehensive review. Mul-
timedia Systems, 8(6):536–544, Apr 2003. ISSN 1432-
1882.

Open Category Detection with PAC Guarantees

A. Experimental Results from Synthetic

Datasets

In this section we include the simulation results on synthetic
datasets from using two different anomaly detectors, Isola-
tion Forest and LODA in table 1-3 and 4-6 respectively. For
using LODA, when training it on the nominal dataset, we
build 1 000 random projections, and each of them is built
using a bootstrap resample of the nominal dataset. After
ﬁnishing building all projections, we calculate the anomaly
score for each point in nominal dataset only using the pro-
jections that didn’t use this point, and calculate the anomaly
scores for mixture dataset, G0 and Ga using all the projec-
tions. For all cases, we include results from targeting on
different recalls which are 98%, 95% and 90%. In table 1-6,
the oracle FPR column is the mean of 100 oracle FPRs in
each setting.

In table 7, we include the results we used for plotting ﬁgure
2. The results are the 1st quartile, median and 3rd quartile of
FPR from experiments using Iforest with target recall 95%.
Here the oracle FPR column is the median of 100 oracle
FPRs.

B. Experimental Results from UCI and Image

Datasets

In this section we include results of performance on UCI
benchmarks, MNIST and Tiny Imagenet and Tables 8-22
illustrate the results. The experimental protocol is similar
to synthetic datasets and two state of the art anomaly de-
tectors Isolation forest, LODA are applied. For Isolation
forest we train Forest with 1000 trees on nominal dataset
and use out of bag estimates of this dataset to estimate the
nominal datasets anomaly score distribution. For LODA we
build 1000 projections and similar to Isolation forest we get
anomaly score for each point in nominal dataset using the
projections that didn’t use this point.Tables 11-16 illustrate
the results of LODA for 6 different datasets for varying val-
ues of η and report the observed recall, False positive rate
averaged over 100 runs of each experiment. Tables 17-22
report the results for Isolation Forest and it can be observed
the performance of both LODA,Isolation Forest are similar.

For Image datasets we follow the same protocol as UCI for
MNIST and apply Isolation Forest on the input image but for
Tiny Imagenet the anomaly scores are obtained differently.
We ﬁrst train a Wide Residual Network (40-2) classiﬁer
on the 200 nominal classes of Tiny Imagenet and apply
baseline method (Hendrycks & Gimpel, 2017) on validation
data to get the nominal dataset distribution and later apply
the same method on the mixture dataset which will have α
proportion of aliens which are basically from 800 held out
classes.Tables 8-10 illustrate the results for these datasets
for target recall of 98%,95% and 90%.

Open Category Detection with PAC Guarantees

Table 1. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 98%, iForest

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

247818
1167215
1829649
4236646
6363404
23373
239656
259309
1067189
1536752
20178
107381
196205
456821
861861
7550
80449
110875
498016
670130
7053
34712
70925
167019
451373

0.710±0.033
0.862±0.019
0.884±0.015
0.920±0.010
0.932±0.009
0.826±0.027
0.939±0.009
0.940±0.008
0.961±0.005
0.965±0.004
0.907±0.017
0.951±0.007
0.960±0.005
0.970±0.004
0.975±0.003
0.946±0.011
0.971±0.005
0.972±0.004
0.977±0.002
0.977±0.002
0.970±0.005
0.977±0.003
0.979±0.002
0.978±0.001
0.979±0.001

0.033±0.027
0.033±0.024
0.031±0.024
0.060±0.038
0.065±0.034
0.088±0.037
0.064±0.032
0.046±0.025
0.083±0.039
0.063±0.026
0.105±0.033
0.071±0.035
0.062±0.023
0.075±0.031
0.088±0.034
0.158±0.045
0.131±0.045
0.098±0.038
0.048±0.010
0.051±0.019
0.156±0.036
0.056±0.009
0.053±0.014
0.039±0.002
0.036±0.001

0.102
0.042
0.036
0.039
0.037
0.101
0.042
0.037
0.039
0.037
0.100
0.042
0.037
0.039
0.037
0.101
0.042
0.037
0.039
0.037
0.102
0.042
0.036
0.039
0.037

0.929±0.029
0.972±0.016
0.980±0.009
0.985±0.007
0.984±0.007
0.950±0.022
0.979±0.007
0.977±0.007
0.984±0.005
0.987±0.004
0.977±0.010
0.985±0.005
0.982±0.005
0.988±0.004
0.989±0.003
0.974±0.010
0.988±0.004
0.989±0.004
0.985±0.003
0.984±0.003
0.982±0.005
0.984±0.003
0.985±0.003
0.979±0.001
0.979±0.001

0.512±0.080
0.543±0.079
0.574±0.080
0.506±0.079
0.520±0.080
0.502±0.081
0.465±0.081
0.477±0.085
0.411±0.080
0.434±0.076
0.549±0.075
0.482±0.080
0.419±0.081
0.403±0.075
0.433±0.077
0.496±0.075
0.484±0.078
0.475±0.079
0.254±0.066
0.216±0.060
0.395±0.073
0.256±0.065
0.196±0.052
0.049±0.014
0.047±0.016

0.102
0.042
0.036
0.039
0.037
0.101
0.042
0.037
0.039
0.037
0.100
0.042
0.037
0.039
0.037
0.101
0.042
0.037
0.039
0.037
0.102
0.042
0.036
0.039
0.037

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Open Category Detection with PAC Guarantees

Table 2. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 95%, iForest

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

275039
1474209
2462157
6171393
9309633
27589
243154
307512
1356124
1553411
28043
109029
157112
1232102
861861
8666
121266
177212
581132
776090
6349
56529
111994
292413
379279

0.710±0.033
0.862±0.019
0.884±0.015
0.911±0.010
0.918±0.010
0.826±0.027
0.920±0.010
0.923±0.009
0.943±0.005
0.945±0.005
0.906±0.016
0.933±0.009
0.934±0.006
0.949±0.004
0.951±0.003
0.929±0.012
0.953±0.006
0.949±0.004
0.949±0.002
0.949±0.002
0.952±0.006
0.951±0.003
0.951±0.002
0.950 ±0.001
0.950 ±0.001

0.033±0.027
0.033±0.024
0.030±0.024
0.039±0.030
0.054±0.032
0.082±0.035
0.035±0.020
0.022±0.011
0.040±0.028
0.024±0.009
0.101±0.033
0.055±0.032
0.017±0.006
0.027±0.018
0.027±0.016
0.126±0.042
0.054±0.025
0.018±0.004
0.014±0.001
0.014±0.001
0.084±0.021
0.018±0.002
0.013±0.001
0.014± 0.000
0.014± 0.000

0.052
0.015
0.012
0.014
0.014
0.051
0.015
0.012
0.014
0.014
0.050
0.015
0.012
0.014
0.014
0.051
0.015
0.012
0.014
0.014
0.052
0.015
0.012
0.014
0.014

0.929±0.029
0.972±0.016
0.978±0.010
0.982±0.008
0.981±0.008
0.947±0.022
0.975±0.009
0.966±0.010
0.973±0.007
0.972±0.006
0.969±0.013
0.974±0.008
0.969±0.007
0.967±0.006
0.964±0.005
0.963±0.013
0.977±0.006
0.968±0.006
0.953±0.003
0.952±0.003
0.966±0.007
0.954±0.004
0.952±0.002
0.950±0.001
0.950± 0.001

0.509±0.080
0.533±0.079
0.557±0.081
0.496±0.080
0.495±0.081
0.489±0.081
0.440±0.079
0.420±0.084
0.351±0.079
0.314±0.074
0.511±0.077
0.397±0.078
0.313±0.075
0.194±0.061
0.192±0.063
0.428±0.073
0.360±0.075
0.273±0.072
0.039±0.024
0.042±0.028
0.262±0.061
0.038±0.021
0.014±0.001
0.014±0.000
0.014±0.000

0.052
0.015
0.012
0.014
0.014
0.051
0.015
0.012
0.014
0.014
0.050
0.015
0.012
0.014
0.014
0.051
0.015
0.012
0.014
0.014
0.052
0.015
0.012
0.014
0.014

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Open Category Detection with PAC Guarantees

Table 3. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 90%, iForest

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

331513
2340744
3222506
5918805
12543171
37658
403920
482922
2307205
2629242
39085
139647
156669
1867515
1232102
6481
63235
153077
397467
1088542
4400
22825
44373
229795
374065

0.710±0.033
0.862±0.019
0.859±0.014
0.869±0.011
0.884±0.010
0.826±0.027
0.893±0.011
0.888±0.010
0.901±0.006
0.898±0.005
0.879±0.017
0.900±0.010
0.888±0.008
0.902±0.003
0.900± 0.003
0.881±0.017
0.909±0.007
0.902±0.004
0.898±0.002
0.899±0.002
0.912±0.008
0.904±0.004
0.903±0.003
0.900±0.001
0.900± 0.001

0.033±0.027
0.033±0.024
0.011±0.008
0.012±0.017
0.012±0.009
0.081±0.034
0.02 ±0.015
0.015±0.011
0.007±0.004
0.005±0.001
0.059±0.021
0.019±0.014
0.005±0.001
0.004±0.000
0.005±0.000
0.060±0.022
0.010±0.003
0.005±0.000
0.003±0.000
0.005±0.000
0.038±0.005
0.006±0.000
0.004±0.000
0.004±0.000
0.005±0.000

0.026
0.005
0.004
0.004
0.005
0.026
0.006
0.004
0.004
0.005
0.025
0.005
0.004
0.003
0.005
0.026
0.005
0.004
0.004
0.005
0.026
0.005
0.004
0.004
0.005

0.929±0.029
0.970±0.016
0.976±0.011
0.976±0.01
0.971±0.011
0.936±0.024
0.960±0.012
0.945±0.014
0.939±0.011
0.923±0.009
0.957±0.016
0.944±0.013
0.925±0.012
0.911±0.006
0.903±0.004
0.942±0.016
0.937±0.010
0.913±0.007
0.898±0.002
0.900± 0.002
0.920±0.010
0.904±0.004
0.903±0.003
0.900±0.001
0.900±0.001

0.509±0.080
0.517±0.078
0.542±0.081
0.476±0.079
0.458±0.080
0.468±0.081
0.372±0.075
0.381±0.082
0.228±0.070
0.139±0.056
0.463±0.076
0.297±0.073
0.166±0.058
0.060 ±0.039
0.016±0.015
0.359±0.072
0.170±0.057
0.066±0.040
0.004±0.000
0.005±0.000
0.107±0.042
0.006±0.000
0.004±0.000
0.004±0.000
0.005±0.000

0.026
0.005
0.004
0.004
0.005
0.026
0.006
0.004
0.004
0.005
0.025
0.005
0.004
0.003
0.005
0.026
0.005
0.004
0.004
0.005
0.026
0.005
0.004
0.004
0.005

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Open Category Detection with PAC Guarantees

Table 4. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 98%, bootstrap
LODA

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

188760
1065490
1891769
5874989
8907859
17905
177557
340061
2051058
2362910
13692
79982
191346
1069912
2042503
7818
54275
121904
612305
922499
4604
25350
101036
431535
615923

0.719±0.048
0.872±0.022
0.899±0.016
0.942±0.010
0.954±0.008
0.842±0.031
0.940±0.011
0.952±0.008
0.971±0.004
0.975±0.004
0.933±0.017
0.955±0.008
0.967±0.005
0.977±0.003
0.980±0.003
0.949±0.013
0.970±0.005
0.977±0.004
0.980±0.002
0.980±0.002
0.973±0.006
0.980±0.003
0.981±0.002
0.980±0.001
0.980±0.001

0.095±0.039
0.083±0.038
0.060±0.031
0.067±0.030
0.069±0.027
0.165±0.051
0.118±0.043
0.090±0.035
0.089±0.034
0.079±0.027
0.213±0.046
0.097±0.037
0.070±0.023
0.072±0.028
0.087±0.030
0.257±0.057
0.125±0.039
0.102±0.031
0.059±0.015
0.073±0.030
0.223±0.042
0.093±0.024
0.065±0.014
0.037±0.002
0.034±0.002

0.135
0.048
0.041
0.034
0.033
0.132
0.049
0.041
0.034
0.034
0.142
0.049
0.041
0.034
0.034
0.131
0.048
0.040
0.034
0.034
0.135
0.049
0.041
0.034
0.034

0.972±0.017
0.974±0.013
0.980±0.009
0.988±0.005
0.990±0.005
0.942±0.024
0.983±0.007
0.980±0.007
0.988±0.004
0.989±0.003
0.977±0.011
0.984±0.006
0.985±0.005
0.989±0.003
0.990±0.003
0.970±0.010
0.987±0.004
0.992±0.003
0.986±0.003
0.986±0.002
0.983±0.005
0.986±0.003
0.986±0.002
0.981±0.001
0.980±0.001

0.569±0.073
0.491±0.079
0.511±0.078
0.447±0.078
0.444±0.075
0.498±0.077
0.430±0.073
0.462±0.081
0.384±0.076
0.360±0.070
0.537±0.070
0.456±0.077
0.402±0.076
0.351±0.070
0.342±0.070
0.481±0.076
0.451±0.076
0.462±0.075
0.217±0.058
0.215±0.057
0.422±0.067
0.258±0.061
0.177±0.047
0.047±0.013
0.038±0.006

0.135
0.048
0.041
0.034
0.033
0.132
0.049
0.041
0.034
0.034
0.142
0.049
0.041
0.034
0.034
0.131
0.048
0.040
0.034
0.034
0.135
0.049
0.041
0.034
0.034

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Open Category Detection with PAC Guarantees

Table 5. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 95%, bootstrap
LODA

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

206671
1330996
2559525
7369343
8307313
20685
175626
463720
3619299
2934537
17884
85131
142860
1578820
2255301
11831
65192
174441
802440
2068150
5099
30120
80278
465368
686935

0.719±0.048
0.872±0.022
0.899±0.016
0.933±0.010
0.943±0.009
0.841±0.031
0.921±0.013
0.940±0.009
0.952±0.005
0.956±0.004
0.929±0.017
0.940±0.009
0.943±0.007
0.955±0.004
0.957±0.003
0.940±0.013
0.955±0.007
0.956±0.005
0.952±0.002
0.952±0.001
0.954±0.007
0.953±0.003
0.952±0.002
0.951±0.001
0.950±0.001

0.095±0.039
0.083±0.038
0.060±0.031
0.052±0.023
0.059±0.025
0.164±0.050
0.092±0.038
0.057±0.026
0.038±0.022
0.024±0.007
0.205±0.046
0.083±0.036
0.039±0.014
0.029±0.018
0.022±0.009
0.204±0.049
0.077±0.029
0.041±0.018
0.013±0.002
0.011±0.001
0.123±0.022
0.025±0.003
0.017±0.001
0.011±0.000
0.011±0.000

0.077
0.020
0.015
0.011
0.010
0.076
0.020
0.015
0.011
0.010
0.083
0.020
0.015
0.011
0.010
0.075
0.020
0.015
0.011
0.010
0.078
0.020
0.015
0.011
0.010

0.972±0.017
0.974±0.013
0.978±0.010
0.985±0.006
0.987±0.006
0.939±0.025
0.978±0.009
0.973±0.009
0.978±0.005
0.976±0.005
0.976±0.011
0.976±0.008
0.973±0.008
0.971±0.005
0.967±0.005
0.964±0.012
0.979±0.006
0.975±0.006
0.956±0.003
0.954±0.002
0.971±0.007
0.956±0.004
0.952±0.002
0.951±0.001
0.950±0.001

0.566±0.073
0.487±0.078
0.505±0.079
0.442±0.078
0.413±0.074
0.487±0.075
0.392±0.070
0.410±0.079
0.308±0.072
0.246±0.063
0.530±0.070
0.376±0.074
0.304±0.072
0.175±0.057
0.146±0.053
0.441±0.073
0.352±0.070
0.271±0.066
0.041±0.025
0.031±0.023
0.325±0.061
0.049±0.022
0.017±0.001
0.011±0.000
0.011±0.000

0.077
0.020
0.015
0.011
0.010
0.076
0.020
0.015
0.011
0.010
0.083
0.020
0.015
0.011
0.010
0.075
0.020
0.015
0.011
0.010
0.078
0.020
0.015
0.011
0.010

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Open Category Detection with PAC Guarantees

Table 6. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 90%, bootstrap
LODA

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

242739
2059638
3398545
9739214
11575949
27002
255234
426176
2440377
4972658
18177
123537
140581
2329443
2968332
9199
59467
178906
786472
1349754
13581
13945
96151
227331
537171

0.719±0.048
0.872±0.022
0.863±0.017
0.900±0.013
0.911±0.012
0.841±0.031
0.892±0.014
0.900±0.011
0.914±0.006
0.907±0.005
0.898±0.020
0.910±0.011
0.897±0.009
0.906±0.003
0.905±0.003
0.915±0.016
0.914±0.008
0.911±0.005
0.901±0.002
0.901±0.001
0.921±0.008
0.902±0.004
0.904±0.003
0.900±0.001
0.901±0.001

0.095±0.039
0.082±0.038
0.033±0.020
0.032±0.019
0.030±0.016
0.157±0.048
0.058±0.033
0.018±0.009
0.010±0.005
0.004±0.001
0.152±0.040
0.049±0.027
0.013±0.006
0.004±0.000
0.003±0.000
0.149±0.043
0.021±0.014
0.008±0.001
0.004±0.000
0.003±0.000
0.067±0.010
0.009±0.001
0.006±0.000
0.003±0.000
0.003±0.000

0.045
0.008
0.006
0.003
0.003
0.044
0.008
0.006
0.003
0.003
0.049
0.008
0.006
0.003
0.003
0.043
0.008
0.006
0.003
0.003
0.045
0.008
0.006
0.003
0.003

0.972±0.017
0.969±0.015
0.973±0.012
0.981±0.007
0.980±0.009
0.936±0.026
0.964±0.013
0.957±0.012
0.945±0.009
0.933±0.009
0.969±0.013
0.954±0.012
0.936±0.012
0.915±0.006
0.908±0.004
0.953±0.014
0.942±0.010
0.923±0.008
0.901±0.002
0.901±0.001
0.934±0.009
0.902±0.004
0.904±0.003
0.900±0.001
0.901±0.001

0.564±0.073
0.484±0.079
0.487±0.079
0.411±0.076
0.359±0.072
0.460±0.074
0.359±0.070
0.365±0.077
0.188±0.063
0.130±0.052
0.487±0.070
0.303±0.069
0.175±0.057
0.053±0.033
0.014±0.016
0.393±0.071
0.189±0.059
0.078±0.039
0.004±0.000
0.003±0.000
0.148±0.042
0.009±0.001
0.006±0.000
0.003±0.000
0.003±0.000

0.045
0.008
0.006
0.003
0.003
0.044
0.008
0.006
0.003
0.003
0.049
0.008
0.006
0.003
0.003
0.043
0.008
0.006
0.003
0.003
0.045
0.008
0.006
0.003
0.003

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Table 7. 1st quartile, median, 3rd quartile of false positive rate from experiments using 9-dimensional normal data, 95%, Iforest

Open Category Detection with PAC Guarantees

Basic CDF
False Positive Rate

n 1st quartile median

3rd quartile Oracle(median)

α

0.01

0.05

0.1

0.2

0.5

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

0.004
0.002
0.002
0.002
0.003
0.006
0.004
0.004
0.006
0.008
0.015
0.006
0.005
0.009
0.011
0.025
0.010
0.008
0.010
0.012
0.040
0.012
0.011
0.013
0.013

0.006
0.004
0.004
0.004
0.006
0.014
0.008
0.008
0.010
0.011
0.032
0.012
0.009
0.013
0.014
0.043
0.018
0.011
0.013
0.013
0.058
0.016
0.012
0.014
0.014

0.014
0.015
0.010
0.013
0.014
0.043
0.023
0.015
0.020
0.019
0.094
0.021
0.014
0.020
0.017
0.105
0.031
0.018
0.015
0.015
0.090
0.021
0.016
0.016
0.015

0.051
0.015
0.012
0.014
0.014
0.050
0.015
0.012
0.014
0.014
0.049
0.015
0.012
0.014
0.014
0.049
0.015
0.012
0.014
0.014
0.051
0.015
0.012
0.014
0.014

Open Category Detection with PAC Guarantees

Table 8. Recall (i.e. alien detection rate) & False Positive Rate for Image Datasets,98%

Dataset

α

ˆα

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Tiny Image Net
n=10000

MNIST
n=11154

Tiny Image Net
n=10000

MNIST
n=11154

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.926 ± 0.014
0.933 ± 0.013
0.941 ± 0.012
0.965 ± 0.005
0.970 ± 0.004
0.977 ± 0.004
0.976 ± 0.003
0.982 ± 0.002
0.987 ± 0.002

0.981 ± 0.006
0.987 ± 0.005
0.991 ± 0.004
0.983 ± 0.004
0.990 ± 0.003
0.997 ± 0.001
0.983 ± 0.003
0.993 ± 0.002
0.999 ± 0.001

0.677 ± 0.030
0.695 ± 0.030
0.715 ± 0.029
0.738 ± 0.018
0.761 ± 0.018
0.787 ± 0.017
0.766 ± 0.011
0.793 ± 0.011
0.822 ± 0.010

0.466 ± 0.041
0.518 ± 0.044
0.573 ± 0.049
0.444 ± 0.030
0.511 ± 0.037
0.610 ± 0.038
0.416 ± 0.014
0.504 ± 0.024
0.655 ± 0.030

0.944 ± 0.013
0.952 ± 0.012
0.959 ± 0.011
0.972 ± 0.005
0.977 ± 0.004
0.983 ± 0.003
0.978 ± 0.003
0.983 ± 0.002
0.988 ± 0.002

0.987 ± 0.006
0.991 ± 0.005
0.994 ± 0.003
0.986 ± 0.004
0.992 ± 0.003
0.998 ± 0.001
0.983 ± 0.003
0.993 ± 0.002
0.999 ± 0.001

0.746 ± 0.034
0.766 ± 0.033
0.786 ± 0.031
0.774 ± 0.021
0.798 ± 0.019
0.825 ± 0.018
0.776 ± 0.012
0.802 ± 0.011
0.833 ± 0.010

0.569 ± 0.061
0.628 ± 0.061
0.691 ± 0.060
0.483 ± 0.041
0.567 ± 0.045
0.684 ± 0.040
0.421 ± 0.015
0.519 ± 0.028
0.683 ± 0.032

0.902 ± 0.014
0.912 ± 0.014
0.923 ± 0.013
0.942 ± 0.006
0.949 ± 0.005
0.957 ± 0.005
0.948 ± 0.003
0.956 ± 0.003
0.964 ± 0.002

0.971 ± 0.007
0.977 ± 0.006
0.984 ± 0.005
0.966 ± 0.005
0.976 ± 0.004
0.986 ± 0.003
0.957 ± 0.003
0.972 ± 0.003
0.987 ± 0.002

0.620 ± 0.025
0.639 ± 0.026
0.660 ± 0.026
0.667 ± 0.016
0.683 ± 0.014
0.706 ± 0.014
0.669 ± 0.007
0.689 ± 0.007
0.714 ± 0.007

0.404 ± 0.032
0.432 ± 0.033
0.477 ± 0.036
0.361 ± 0.017
0.397 ± 0.018
0.455 ± 0.023
0.334 ± 0.005
0.373 ± 0.007
0.441 ± 0.012

0.924 ± 0.014
0.930 ± 0.014
0.939 ± 0.012
0.948 ± 0.006
0.954 ± 0.005
0.962 ± 0.005
0.949 ± 0.003
0.957 ± 0.003
0.965 ± 0.002

0.975 ± 0.007
0.982 ± 0.006
0.988 ± 0.005
0.967 ± 0.005
0.977 ± 0.004
0.988 ± 0.003
0.957 ± 0.003
0.973 ± 0.003
0.988 ± 0.002

0.686 ± 0.032
0.697 ± 0.031
0.716 ± 0.031
0.682 ± 0.016
0.700 ± 0.015
0.722 ± 0.015
0.672 ± 0.007
0.692 ± 0.007
0.718 ± 0.007

0.448 ± 0.042
0.488 ± 0.045
0.542 ± 0.048
0.368 ± 0.018
0.410 ± 0.022
0.477 ± 0.028
0.334 ± 0.005
0.375 ± 0.007
0.444 ± 0.012

Table 9. Recall (i.e. alien detection rate) & False Positive Rate for Image Datasets,95%

Dataset

α

ˆα

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Open Category Detection with PAC Guarantees

Table 10. Recall (i.e. alien detection rate) & False Positive Rate for Image Datasets,90%

Dataset

α

ˆα

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Tiny Image Net
n=10000

MNIST
n=11154

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.862 ± 0.015
0.873 ± 0.015
0.885 ± 0.014
0.894 ± 0.007
0.904 ± 0.007
0.915 ± 0.006
0.898 ± 0.003
0.907 ± 0.003
0.919 ± 0.003

0.949 ± 0.008
0.958 ± 0.007
0.967 ± 0.007
0.928 ± 0.005
0.942 ± 0.004
0.958 ± 0.004
0.912 ± 0.003
0.929 ± 0.003
0.949 ± 0.003

0.545 ± 0.021
0.562 ± 0.021
0.579 ± 0.021
0.578 ± 0.011
0.593 ± 0.010
0.609 ± 0.010
0.577 ± 0.004
0.590 ± 0.004
0.608 ± 0.004

0.328 ± 0.020
0.352 ± 0.022
0.378 ± 0.024
0.282 ± 0.006
0.306 ± 0.007
0.341 ± 0.010
0.260 ± 0.003
0.284 ± 0.003
0.317 ± 0.004

0.883 ± 0.016
0.892 ± 0.015
0.902 ± 0.014
0.898 ± 0.007
0.909 ± 0.006
0.919 ± 0.006
0.899 ± 0.003
0.908 ± 0.003
0.920 ± 0.003

0.954 ± 0.008
0.962 ± 0.007
0.971 ± 0.007
0.929 ± 0.005
0.944 ± 0.004
0.960 ± 0.004
0.912 ± 0.003
0.930 ± 0.003
0.949 ± 0.003

0.590 ± 0.027
0.602 ± 0.026
0.617 ± 0.025
0.584 ± 0.011
0.600 ± 0.011
0.617 ± 0.011
0.578 ± 0.004
0.591 ± 0.004
0.609 ± 0.004

0.342 ± 0.024
0.366 ± 0.025
0.395 ± 0.027
0.285 ± 0.007
0.309 ± 0.008
0.345 ± 0.011
0.260 ± 0.003
0.284 ± 0.003
0.317 ± 0.004

Open Category Detection with PAC Guarantees

Table 11. Recall & False Positive Rate for Landsat Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Landsat
n=1532

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.937 ± 0.024
0.949 ± 0.024
0.960 ± 0.024
0.965 ± 0.005
0.980 ± 0.003
0.989 ± 0.002
0.971 ± 0.013
0.985 ± 0.012
0.991 ± 0.012

0.924 ± 0.024
0.936 ± 0.024
0.950 ± 0.024
0.942 ± 0.006
0.964 ± 0.004
0.981 ± 0.003
0.948 ± 0.013
0.969 ± 0.012
0.986 ± 0.012

0.888 ± 0.025
0.906 ± 0.024
0.927 ± 0.024
0.902 ± 0.007
0.928 ± 0.005
0.953 ± 0.005
0.899 ± 0.012
0.927 ± 0.012
0.957 ± 0.012

0.162 ± 0.047
0.203 ± 0.048
0.255 ± 0.050
0.128 ± 0.033
0.204 ± 0.040
0.301 ± 0.047
0.114 ± 0.021
0.267 ± 0.033
0.480 ± 0.039

0.127 ± 0.041
0.157 ± 0.044
0.202 ± 0.047
0.069 ± 0.020
0.112 ± 0.027
0.201 ± 0.039
0.046 ± 0.008
0.095 ± 0.015
0.250 ± 0.029

0.089 ± 0.036
0.106 ± 0.038
0.136 ± 0.041
0.034 ± 0.008
0.047 ± 0.012
0.076 ± 0.018
0.029 ± 0.008
0.035 ± 0.008
0.055 ± 0.008

0.960 ± 0.024
0.967 ± 0.024
0.972 ± 0.024
0.983 ± 0.005
0.991 ± 0.003
0.996 ± 0.001
0.981 ± 0.013
0.989 ± 0.012
0.993 ± 0.012

0.952 ± 0.025
0.959 ± 0.024
0.966 ± 0.024
0.964 ± 0.006
0.980 ± 0.004
0.991 ± 0.002
0.952 ± 0.013
0.976 ± 0.012
0.989 ± 0.012

0.924 ± 0.025
0.938 ± 0.025
0.953 ± 0.025
0.918 ± 0.009
0.941 ± 0.007
0.966 ± 0.005
0.899 ± 0.012
0.927 ± 0.012
0.960 ± 0.012

0.495 ± 0.068
0.543 ± 0.064
0.583 ± 0.062
0.404 ± 0.062
0.478 ± 0.061
0.557 ± 0.057
0.323 ± 0.055
0.491 ± 0.051
0.658 ± 0.041

0.430 ± 0.067
0.463 ± 0.065
0.506 ± 0.064
0.271 ± 0.057
0.337 ± 0.056
0.425 ± 0.055
0.094 ± 0.028
0.209 ± 0.038
0.385 ± 0.041

0.323 ± 0.064
0.345 ± 0.064
0.380 ± 0.063
0.115 ± 0.037
0.151 ± 0.040
0.216 ± 0.044
0.030 ± 0.008
0.036 ± 0.008
0.076 ± 0.015

Open Category Detection with PAC Guarantees

Table 12. Recall & False Positive Rate for page.blocks Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

pageblocks
n=4912

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.963 ± 0.021
0.969 ± 0.017
0.976 ± 0.013
0.966 ± 0.005
0.978 ± 0.004
0.989 ± 0.003
0.971 ± 0.004
0.986 ± 0.002
0.994 ± 0.001

0.945 ± 0.031
0.958 ± 0.024
0.967 ± 0.018
0.945 ± 0.007
0.963 ± 0.005
0.978 ± 0.004
0.945 ± 0.004
0.966 ± 0.003
0.985 ± 0.002

0.908 ± 0.027
0.928 ± 0.021
0.947 ± 0.022
0.899 ± 0.007
0.922 ± 0.007
0.946 ± 0.006
0.901 ± 0.005
0.922 ± 0.004
0.948 ± 0.004

0.254 ± 0.084
0.315 ± 0.138
0.357 ± 0.137
0.287 ± 0.031
0.367 ± 0.038
0.468 ± 0.041
0.261 ± 0.028
0.384 ± 0.035
0.531 ± 0.038

0.218 ± 0.070
0.259 ± 0.100
0.304 ± 0.117
0.204 ± 0.019
0.258 ± 0.025
0.338 ± 0.031
0.173 ± 0.012
0.228 ± 0.020
0.339 ± 0.027

0.153 ± 0.030
0.187 ± 0.049
0.222 ± 0.071
0.139 ± 0.007
0.161 ± 0.010
0.201 ± 0.016
0.125 ± 0.004
0.143 ± 0.005
0.174 ± 0.008

0.983 ± 0.013
0.991 ± 0.006
0.995 ± 0.004
0.978 ± 0.005
0.987 ± 0.003
0.994 ± 0.002
0.980 ± 0.004
0.991 ± 0.002
0.996 ± 0.001

0.964 ± 0.029
0.975 ± 0.018
0.985 ± 0.012
0.955 ± 0.007
0.972 ± 0.005
0.985 ± 0.004
0.950 ± 0.005
0.972 ± 0.004
0.989 ± 0.002

0.939 ± 0.027
0.943 ± 0.024
0.959 ± 0.023
0.905 ± 0.008
0.929 ± 0.007
0.954 ± 0.006
0.903 ± 0.005
0.924 ± 0.004
0.951 ± 0.004

0.555 ± 0.201
0.624 ± 0.181
0.712 ± 0.159
0.452 ± 0.053
0.529 ± 0.050
0.626 ± 0.045
0.411 ± 0.048
0.532 ± 0.047
0.655 ± 0.043

0.419 ± 0.210
0.458 ± 0.201
0.551 ± 0.185
0.291 ± 0.040
0.362 ± 0.042
0.448 ± 0.043
0.217 ± 0.029
0.303 ± 0.034
0.423 ± 0.036

0.245 ± 0.105
0.253 ± 0.102
0.305 ± 0.119
0.162 ± 0.017
0.190 ± 0.020
0.243 ± 0.026
0.127 ± 0.005
0.148 ± 0.008
0.190 ± 0.013

Open Category Detection with PAC Guarantees

Table 13. Recall & False Positive Rate for Optical.digits Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Optical.digits
n=568

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.898 ± 0.016
0.906 ± 0.013
0.917 ± 0.013
0.938 ± 0.011
0.953 ± 0.008
0.968 ± 0.007
0.966 ± 0.006
0.979 ± 0.004
0.989 ± 0.003

0.887 ± 0.016
0.892 ± 0.014
0.906 ± 0.013
0.924 ± 0.011
0.936 ± 0.009
0.955 ± 0.008
0.946 ± 0.006
0.964 ± 0.005
0.980 ± 0.004

0.840 ± 0.021
0.866 ± 0.015
0.879 ± 0.014
0.883 ± 0.013
0.905 ± 0.010
0.926 ± 0.010
0.904 ± 0.007
0.925 ± 0.006
0.951 ± 0.006

0.167 ± 0.035
0.186 ± 0.036
0.214 ± 0.036
0.177 ± 0.033
0.220 ± 0.039
0.270 ± 0.041
0.254 ± 0.041
0.339 ± 0.045
0.439 ± 0.048

0.146 ± 0.033
0.166 ± 0.033
0.188 ± 0.034
0.135 ± 0.025
0.165 ± 0.029
0.212 ± 0.034
0.149 ± 0.024
0.219 ± 0.031
0.319 ± 0.040

0.119 ± 0.029
0.132 ± 0.031
0.151 ± 0.032
0.080 ± 0.012
0.104 ± 0.018
0.138 ± 0.024
0.072 ± 0.006
0.096 ± 0.009
0.150 ± 0.019

0.947 ± 0.016
0.950 ± 0.013
0.957 ± 0.012
0.964 ± 0.010
0.973 ± 0.008
0.983 ± 0.006
0.978 ± 0.006
0.986 ± 0.004
0.994 ± 0.002

0.948 ± 0.015
0.944 ± 0.014
0.952 ± 0.013
0.954 ± 0.010
0.963 ± 0.009
0.974 ± 0.007
0.959 ± 0.007
0.974 ± 0.006
0.986 ± 0.004

0.910 ± 0.021
0.928 ± 0.016
0.937 ± 0.015
0.916 ± 0.015
0.936 ± 0.011
0.953 ± 0.010
0.916 ± 0.009
0.936 ± 0.008
0.960 ± 0.006

0.502 ± 0.070
0.519 ± 0.066
0.549 ± 0.065
0.434 ± 0.065
0.466 ± 0.063
0.511 ± 0.061
0.441 ± 0.061
0.517 ± 0.058
0.606 ± 0.053

0.459 ± 0.068
0.481 ± 0.066
0.504 ± 0.065
0.342 ± 0.059
0.381 ± 0.059
0.432 ± 0.060
0.290 ± 0.049
0.356 ± 0.049
0.443 ± 0.049

0.403 ± 0.067
0.413 ± 0.065
0.430 ± 0.065
0.237 ± 0.050
0.264 ± 0.050
0.300 ± 0.050
0.129 ± 0.026
0.168 ± 0.031
0.233 ± 0.036

Open Category Detection with PAC Guarantees

Table 14. Recall & False Positive Rate for Letter Recognition Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Letter recognition
n=788

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.897 ± 0.018
0.918 ± 0.013
0.931 ± 0.012
0.940 ± 0.011
0.954 ± 0.008
0.969 ± 0.006
0.968 ± 0.006
0.983 ± 0.004
0.993 ± 0.003

0.885 ± 0.020
0.904 ± 0.015
0.919 ± 0.013
0.912 ± 0.013
0.934 ± 0.010
0.954 ± 0.008
0.946 ± 0.006
0.967 ± 0.005
0.984 ± 0.004

0.857 ± 0.020
0.875 ± 0.017
0.892 ± 0.016
0.875 ± 0.014
0.900 ± 0.011
0.923 ± 0.010
0.901 ± 0.007
0.925 ± 0.006
0.953 ± 0.005

0.232 ± 0.044
0.255 ± 0.045
0.291 ± 0.047
0.197 ± 0.032
0.235 ± 0.035
0.281 ± 0.039
0.242 ± 0.029
0.335 ± 0.038
0.448 ± 0.044

0.205 ± 0.042
0.223 ± 0.041
0.252 ± 0.043
0.156 ± 0.024
0.188 ± 0.027
0.229 ± 0.034
0.147 ± 0.012
0.208 ± 0.020
0.306 ± 0.032

0.152 ± 0.031
0.172 ± 0.033
0.197 ± 0.036
0.111 ± 0.016
0.132 ± 0.018
0.158 ± 0.022
0.099 ± 0.004
0.117 ± 0.005
0.155 ± 0.010

0.953 ± 0.016
0.967 ± 0.010
0.975 ± 0.008
0.964 ± 0.011
0.974 ± 0.007
0.983 ± 0.006
0.977 ± 0.006
0.989 ± 0.003
0.996 ± 0.002

0.949 ± 0.015
0.958 ± 0.012
0.965 ± 0.010
0.944 ± 0.013
0.960 ± 0.009
0.973 ± 0.008
0.956 ± 0.007
0.974 ± 0.005
0.988 ± 0.004

0.929 ± 0.018
0.939 ± 0.016
0.949 ± 0.014
0.905 ± 0.015
0.928 ± 0.012
0.950 ± 0.010
0.906 ± 0.008
0.932 ± 0.006
0.959 ± 0.006

0.596 ± 0.069
0.613 ± 0.067
0.633 ± 0.065
0.457 ± 0.066
0.490 ± 0.063
0.537 ± 0.061
0.430 ± 0.056
0.525 ± 0.055
0.639 ± 0.049

0.550 ± 0.069
0.570 ± 0.066
0.587 ± 0.065
0.375 ± 0.060
0.407 ± 0.059
0.455 ± 0.059
0.245 ± 0.039
0.334 ± 0.043
0.432 ± 0.046

0.473 ± 0.067
0.490 ± 0.066
0.519 ± 0.066
0.236 ± 0.045
0.280 ± 0.048
0.326 ± 0.051
0.110 ± 0.008
0.145 ± 0.015
0.203 ± 0.023

Open Category Detection with PAC Guarantees

Table 15. Recall & False Positive Rate for Shuttle Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Shuttle
n=5000

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.959 ± 0.008
0.971 ± 0.006
0.984 ± 0.005
0.975 ± 0.004
0.990 ± 0.002
0.998 ± 0.001
0.980 ± 0.002
0.996 ± 0.001
1.000 ± 0.000

0.937 ± 0.009
0.958 ± 0.007
0.974 ± 0.006
0.949 ± 0.005
0.973 ± 0.004
0.992 ± 0.002
0.949 ± 0.002
0.976 ± 0.002
0.997 ± 0.001

0.901 ± 0.012
0.923 ± 0.010
0.947 ± 0.008
0.903 ± 0.004
0.928 ± 0.004
0.958 ± 0.004
0.899 ± 0.002
0.925 ± 0.002
0.959 ± 0.002

0.145 ± 0.031
0.205 ± 0.038
0.287 ± 0.048
0.100 ± 0.016
0.195 ± 0.033
0.355 ± 0.042
0.090 ± 0.014
0.238 ± 0.028
0.540 ± 0.032

0.095 ± 0.017
0.137 ± 0.027
0.200 ± 0.036
0.064 ± 0.004
0.093 ± 0.011
0.186 ± 0.028
0.061 ± 0.001
0.082 ± 0.006
0.220 ± 0.022

0.056 ± 0.006
0.072 ± 0.010
0.105 ± 0.019
0.047 ± 0.001
0.054 ± 0.002
0.068 ± 0.004
0.047 ± 0.001
0.054 ± 0.001
0.065 ± 0.001

0.973 ± 0.007
0.984 ± 0.006
0.991 ± 0.003
0.982 ± 0.004
0.994 ± 0.002
0.999 ± 0.001
0.982 ± 0.002
0.997 ± 0.001
1.000 ± 0.000

0.957 ± 0.009
0.972 ± 0.007
0.983 ± 0.005
0.956 ± 0.006
0.979 ± 0.004
0.995 ± 0.002
0.949 ± 0.002
0.977 ± 0.002
0.998 ± 0.001

0.917 ± 0.013
0.939 ± 0.011
0.960 ± 0.009
0.905 ± 0.004
0.931 ± 0.005
0.963 ± 0.004
0.899 ± 0.002
0.925 ± 0.002
0.959 ± 0.002

0.425 ± 0.065
0.490 ± 0.065
0.550 ± 0.064
0.317 ± 0.058
0.451 ± 0.058
0.578 ± 0.052
0.154 ± 0.031
0.396 ± 0.042
0.642 ± 0.034

0.326 ± 0.059
0.370 ± 0.059
0.435 ± 0.059
0.142 ± 0.034
0.224 ± 0.043
0.365 ± 0.045
0.061 ± 0.001
0.104 ± 0.016
0.290 ± 0.028

0.187 ± 0.047
0.216 ± 0.047
0.266 ± 0.049
0.048 ± 0.002
0.064 ± 0.008
0.111 ± 0.020
0.047 ± 0.001
0.054 ± 0.001
0.066 ± 0.001

Open Category Detection with PAC Guarantees

Table 16. Recall & False Positive Rate for Covertype Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Covertype
n=13624

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.979 ± 0.002
0.995 ± 0.001
0.999 ± 0.000
0.980 ± 0.001
0.998 ± 0.000
1.000 ± 0.000
0.981 ± 0.001
0.998 ± 0.000
1.000 ± 0.000

0.951 ± 0.002
0.978 ± 0.001
0.997 ± 0.001
0.951 ± 0.001
0.979 ± 0.001
0.999 ± 0.000
0.952 ± 0.001
0.980 ± 0.001
0.999 ± 0.000

0.900 ± 0.003
0.930 ± 0.001
0.965 ± 0.001
0.901 ± 0.002
0.929 ± 0.001
0.965 ± 0.001
0.901 ± 0.002
0.929 ± 0.001
0.965 ± 0.001

0.010 ± 0.003
0.098 ± 0.025
0.292 ± 0.045
0.007 ± 0.002
0.142 ± 0.026
0.423 ± 0.044
0.009 ± 0.001
0.212 ± 0.029
0.560 ± 0.037

0.002 ± 0.000
0.012 ± 0.004
0.112 ± 0.026
0.003 ± 0.000
0.008 ± 0.002
0.153 ± 0.025
0.006 ± 0.000
0.012 ± 0.002
0.199 ± 0.023

0.002 ± 0.000
0.002 ± 0.000
0.004 ± 0.001
0.002 ± 0.000
0.002 ± 0.000
0.004 ± 0.000
0.005 ± 0.000
0.005 ± 0.000
0.007 ± 0.000

0.989 ± 0.002
0.998 ± 0.001
0.999 ± 0.000
0.987 ± 0.002
0.999 ± 0.000
1.000 ± 0.000
0.984 ± 0.002
0.999 ± 0.000
1.000 ± 0.000

0.963 ± 0.004
0.987 ± 0.002
0.998 ± 0.000
0.952 ± 0.002
0.983 ± 0.001
1.000 ± 0.000
0.952 ± 0.001
0.981 ± 0.001
1.000 ± 0.000

0.904 ± 0.004
0.937 ± 0.004
0.973 ± 0.003
0.901 ± 0.002
0.929 ± 0.001
0.965 ± 0.001
0.901 ± 0.002
0.929 ± 0.001
0.965 ± 0.001

0.373 ± 0.072
0.470 ± 0.066
0.586 ± 0.059
0.220 ± 0.056
0.419 ± 0.057
0.618 ± 0.047
0.134 ± 0.044
0.438 ± 0.050
0.676 ± 0.036

0.164 ± 0.051
0.277 ± 0.059
0.411 ± 0.060
0.017 ± 0.016
0.114 ± 0.035
0.319 ± 0.045
0.006 ± 0.000
0.050 ± 0.015
0.307 ± 0.034

0.025 ± 0.019
0.055 ± 0.029
0.121 ± 0.038
0.002 ± 0.000
0.002 ± 0.000
0.011 ± 0.004
0.005 ± 0.000
0.005 ± 0.000
0.008 ± 0.001

Open Category Detection with PAC Guarantees

Table 17. Recall & False Positive Rate for Landsat Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Landsat
n=1532

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.941 ± 0.024
0.950 ± 0.024
0.960 ± 0.024
0.965 ± 0.005
0.979 ± 0.003
0.989 ± 0.002
0.970 ± 0.012
0.985 ± 0.012
0.991 ± 0.012

0.923 ± 0.024
0.936 ± 0.024
0.951 ± 0.024
0.945 ± 0.006
0.964 ± 0.004
0.980 ± 0.003
0.949 ± 0.012
0.969 ± 0.012
0.986 ± 0.012

0.887 ± 0.024
0.906 ± 0.024
0.926 ± 0.024
0.903 ± 0.007
0.927 ± 0.005
0.952 ± 0.005
0.901 ± 0.012
0.926 ± 0.012
0.957 ± 0.012

0.164 ± 0.045
0.197 ± 0.048
0.254 ± 0.051
0.130 ± 0.033
0.199 ± 0.040
0.304 ± 0.048
0.109 ± 0.018
0.266 ± 0.034
0.477 ± 0.039

0.130 ± 0.042
0.161 ± 0.045
0.204 ± 0.047
0.074 ± 0.022
0.117 ± 0.029
0.198 ± 0.037
0.044 ± 0.007
0.094 ± 0.015
0.253 ± 0.029

0.088 ± 0.036
0.107 ± 0.038
0.135 ± 0.041
0.032 ± 0.005
0.047 ± 0.012
0.075 ± 0.018
0.030 ± 0.008
0.034 ± 0.008
0.054 ± 0.008

0.964 ± 0.025
0.968 ± 0.024
0.971 ± 0.024
0.982 ± 0.004
0.991 ± 0.003
0.996 ± 0.002
0.979 ± 0.012
0.989 ± 0.012
0.993 ± 0.012

0.950 ± 0.025
0.959 ± 0.025
0.967 ± 0.024
0.965 ± 0.006
0.979 ± 0.004
0.991 ± 0.003
0.953 ± 0.012
0.976 ± 0.012
0.989 ± 0.012

0.919 ± 0.025
0.936 ± 0.025
0.953 ± 0.025
0.915 ± 0.009
0.942 ± 0.007
0.967 ± 0.005
0.901 ± 0.012
0.927 ± 0.012
0.960 ± 0.012

0.503 ± 0.066
0.545 ± 0.065
0.584 ± 0.063
0.402 ± 0.063
0.477 ± 0.060
0.556 ± 0.057
0.323 ± 0.054
0.488 ± 0.051
0.655 ± 0.042

0.423 ± 0.069
0.467 ± 0.066
0.509 ± 0.064
0.265 ± 0.056
0.332 ± 0.055
0.425 ± 0.054
0.095 ± 0.028
0.212 ± 0.038
0.386 ± 0.041

0.309 ± 0.063
0.346 ± 0.064
0.388 ± 0.063
0.110 ± 0.036
0.153 ± 0.040
0.216 ± 0.044
0.030 ± 0.008
0.037 ± 0.009
0.081 ± 0.016

Open Category Detection with PAC Guarantees

Table 18. Recall & False Positive Rate for page.blocks Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

page.blocks
n=4912

0.100
0.100
0.100

0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108

0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020

0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.951 ± 0.029
0.968 ± 0.018
0.976 ± 0.013

0.965 ± 0.005
0.979 ± 0.004
0.989 ± 0.002
0.970 ± 0.004
0.985 ± 0.002
0.995 ± 0.001

0.949 ± 0.025
0.958 ± 0.021
0.969 ± 0.018
0.946 ± 0.007
0.962 ± 0.005
0.978 ± 0.004
0.945 ± 0.005
0.966 ± 0.003
0.985 ± 0.002

0.903 ± 0.035
0.927 ± 0.025
0.951 ± 0.024
0.900 ± 0.007
0.922 ± 0.007
0.947 ± 0.006
0.900 ± 0.005
0.922 ± 0.004
0.948 ± 0.004

0.269 ± 0.106
0.314 ± 0.130
0.366 ± 0.138

0.283 ± 0.030
0.366 ± 0.037
0.465 ± 0.041
0.260 ± 0.028
0.381 ± 0.035
0.530 ± 0.039

0.239 ± 0.096
0.261 ± 0.101
0.297 ± 0.117
0.207 ± 0.019
0.258 ± 0.025
0.338 ± 0.031
0.173 ± 0.013
0.228 ± 0.019
0.339 ± 0.028

0.155 ± 0.040
0.177 ± 0.044
0.222 ± 0.068
0.138 ± 0.006
0.160 ± 0.010
0.201 ± 0.016
0.128 ± 0.004
0.143 ± 0.006
0.174 ± 0.008

0.975 ± 0.017
0.991 ± 0.007
0.994 ± 0.005

0.976 ± 0.005
0.986 ± 0.004
0.994 ± 0.002
0.978 ± 0.004
0.990 ± 0.002
0.996 ± 0.001

0.968 ± 0.022
0.975 ± 0.018
0.986 ± 0.012
0.956 ± 0.007
0.971 ± 0.005
0.984 ± 0.003
0.951 ± 0.005
0.972 ± 0.004
0.989 ± 0.002

0.927 ± 0.030
0.948 ± 0.027
0.962 ± 0.022
0.906 ± 0.008
0.930 ± 0.007
0.955 ± 0.006
0.902 ± 0.006
0.924 ± 0.004
0.951 ± 0.004

0.511 ± 0.220
0.641 ± 0.184
0.692 ± 0.175

0.443 ± 0.052
0.527 ± 0.051
0.622 ± 0.046
0.403 ± 0.049
0.531 ± 0.048
0.655 ± 0.042

0.401 ± 0.176
0.448 ± 0.189
0.529 ± 0.179
0.298 ± 0.040
0.364 ± 0.042
0.446 ± 0.042
0.215 ± 0.027
0.299 ± 0.034
0.424 ± 0.037

0.216 ± 0.111
0.248 ± 0.117
0.317 ± 0.123
0.158 ± 0.016
0.192 ± 0.020
0.246 ± 0.027
0.130 ± 0.006
0.147 ± 0.008
0.190 ± 0.014

Open Category Detection with PAC Guarantees

Table 19. Recall & False Positive Rate for Optical.digits Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Optical.digits
n=568

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.891 ± 0.018
0.904 ± 0.013
0.917 ± 0.012
0.941 ± 0.010
0.951 ± 0.008
0.965 ± 0.007
0.968 ± 0.006
0.979 ± 0.004
0.990 ± 0.003

0.882 ± 0.018
0.896 ± 0.014
0.910 ± 0.013
0.920 ± 0.012
0.938 ± 0.009
0.954 ± 0.008
0.946 ± 0.007
0.963 ± 0.005
0.979 ± 0.004

0.856 ± 0.017
0.867 ± 0.015
0.886 ± 0.014
0.883 ± 0.012
0.907 ± 0.010
0.927 ± 0.009
0.899 ± 0.008
0.926 ± 0.005
0.952 ± 0.005

0.172 ± 0.036
0.191 ± 0.036
0.214 ± 0.037
0.178 ± 0.032
0.218 ± 0.037
0.268 ± 0.040
0.250 ± 0.039
0.338 ± 0.045
0.442 ± 0.047

0.148 ± 0.033
0.164 ± 0.034
0.192 ± 0.036
0.139 ± 0.026
0.168 ± 0.030
0.211 ± 0.034
0.149 ± 0.024
0.220 ± 0.033
0.315 ± 0.039

0.113 ± 0.027
0.127 ± 0.030
0.146 ± 0.031
0.083 ± 0.014
0.106 ± 0.018
0.140 ± 0.025
0.071 ± 0.005
0.097 ± 0.009
0.151 ± 0.018

0.940 ± 0.017
0.952 ± 0.012
0.961 ± 0.011
0.964 ± 0.010
0.974 ± 0.008
0.983 ± 0.006
0.978 ± 0.006
0.986 ± 0.004
0.994 ± 0.002

0.933 ± 0.018
0.945 ± 0.013
0.952 ± 0.012
0.953 ± 0.012
0.964 ± 0.009
0.973 ± 0.008
0.960 ± 0.007
0.974 ± 0.005
0.986 ± 0.004

0.920 ± 0.018
0.928 ± 0.016
0.938 ± 0.014
0.917 ± 0.014
0.935 ± 0.011
0.953 ± 0.009
0.911 ± 0.009
0.937 ± 0.007
0.961 ± 0.006

0.504 ± 0.068
0.521 ± 0.066
0.548 ± 0.065
0.424 ± 0.065
0.465 ± 0.064
0.520 ± 0.063
0.451 ± 0.061
0.519 ± 0.058
0.608 ± 0.054

0.462 ± 0.068
0.481 ± 0.066
0.500 ± 0.065
0.365 ± 0.061
0.386 ± 0.059
0.441 ± 0.060
0.288 ± 0.050
0.357 ± 0.049
0.443 ± 0.049

0.387 ± 0.066
0.407 ± 0.065
0.433 ± 0.064
0.227 ± 0.050
0.264 ± 0.049
0.305 ± 0.050
0.123 ± 0.024
0.163 ± 0.030
0.230 ± 0.035

Open Category Detection with PAC Guarantees

Table 20. Recall & False Positive Rate for Letter Recognition Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Letter recog
n=788

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.911 ± 0.016
0.919 ± 0.013
0.931 ± 0.012
0.936 ± 0.011
0.954 ± 0.008
0.968 ± 0.007
0.971 ± 0.005
0.984 ± 0.004
0.993 ± 0.003

0.884 ± 0.019
0.903 ± 0.015
0.918 ± 0.014
0.915 ± 0.013
0.936 ± 0.009
0.955 ± 0.008
0.944 ± 0.007
0.966 ± 0.005
0.984 ± 0.004

0.862 ± 0.020
0.876 ± 0.018
0.891 ± 0.016
0.879 ± 0.013
0.899 ± 0.011
0.922 ± 0.010
0.902 ± 0.007
0.924 ± 0.006
0.951 ± 0.006

0.234 ± 0.044
0.262 ± 0.046
0.297 ± 0.048
0.203 ± 0.034
0.236 ± 0.036
0.288 ± 0.042
0.240 ± 0.029
0.334 ± 0.039
0.448 ± 0.044

0.208 ± 0.041
0.223 ± 0.041
0.252 ± 0.043
0.162 ± 0.025
0.190 ± 0.029
0.231 ± 0.034
0.152 ± 0.013
0.208 ± 0.019
0.307 ± 0.031

0.160 ± 0.034
0.174 ± 0.034
0.198 ± 0.036
0.113 ± 0.016
0.132 ± 0.019
0.160 ± 0.022
0.098 ± 0.004
0.117 ± 0.005
0.154 ± 0.010

0.960 ± 0.013
0.965 ± 0.011
0.973 ± 0.009
0.961 ± 0.011
0.975 ± 0.008
0.983 ± 0.006
0.979 ± 0.005
0.989 ± 0.003
0.996 ± 0.002

0.949 ± 0.017
0.959 ± 0.012
0.966 ± 0.011
0.943 ± 0.013
0.960 ± 0.009
0.974 ± 0.007
0.954 ± 0.007
0.974 ± 0.005
0.988 ± 0.004

0.930 ± 0.019
0.939 ± 0.016
0.951 ± 0.013
0.906 ± 0.014
0.928 ± 0.012
0.949 ± 0.010
0.907 ± 0.007
0.931 ± 0.006
0.959 ± 0.006

0.588 ± 0.070
0.603 ± 0.067
0.627 ± 0.065
0.444 ± 0.065
0.487 ± 0.064
0.534 ± 0.062
0.429 ± 0.057
0.525 ± 0.054
0.636 ± 0.048

0.552 ± 0.069
0.563 ± 0.067
0.582 ± 0.065
0.376 ± 0.062
0.410 ± 0.060
0.455 ± 0.059
0.250 ± 0.040
0.328 ± 0.042
0.435 ± 0.046

0.475 ± 0.067
0.492 ± 0.066
0.512 ± 0.065
0.238 ± 0.047
0.281 ± 0.049
0.324 ± 0.050
0.110 ± 0.009
0.139 ± 0.013
0.203 ± 0.024

Open Category Detection with PAC Guarantees

Table 21. Recall & False Positive Rate for Shuttle Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Shuttle
n=5000

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.959 ± 0.008
0.972 ± 0.006
0.984 ± 0.004
0.975 ± 0.004
0.990 ± 0.002
0.998 ± 0.001
0.979 ± 0.002
0.996 ± 0.001
1.000 ± 0.000

0.941 ± 0.009
0.957 ± 0.008
0.973 ± 0.006
0.949 ± 0.005
0.973 ± 0.004
0.992 ± 0.002
0.948 ± 0.002
0.976 ± 0.002
0.997 ± 0.001

0.899 ± 0.011
0.923 ± 0.010
0.946 ± 0.009
0.902 ± 0.005
0.928 ± 0.004
0.958 ± 0.004
0.899 ± 0.002
0.925 ± 0.002
0.958 ± 0.002

0.147 ± 0.031
0.206 ± 0.039
0.287 ± 0.047
0.103 ± 0.016
0.192 ± 0.033
0.361 ± 0.043
0.089 ± 0.013
0.237 ± 0.028
0.541 ± 0.032

0.097 ± 0.018
0.135 ± 0.027
0.202 ± 0.037
0.063 ± 0.004
0.093 ± 0.011
0.187 ± 0.028
0.060 ± 0.002
0.083 ± 0.006
0.218 ± 0.022

0.057 ± 0.005
0.073 ± 0.010
0.104 ± 0.018
0.047 ± 0.001
0.054 ± 0.001
0.069 ± 0.004
0.049 ± 0.001
0.054 ± 0.001
0.065 ± 0.001

0.974 ± 0.007
0.985 ± 0.005
0.991 ± 0.003
0.983 ± 0.004
0.994 ± 0.002
0.999 ± 0.001
0.981 ± 0.002
0.997 ± 0.001
1.000 ± 0.000

0.956 ± 0.009
0.971 ± 0.007
0.984 ± 0.005
0.957 ± 0.005
0.979 ± 0.004
0.995 ± 0.002
0.949 ± 0.002
0.977 ± 0.002
0.998 ± 0.001

0.917 ± 0.013
0.938 ± 0.011
0.960 ± 0.009
0.904 ± 0.005
0.931 ± 0.004
0.963 ± 0.004
0.899 ± 0.002
0.926 ± 0.002
0.959 ± 0.002

0.419 ± 0.066
0.490 ± 0.065
0.545 ± 0.064
0.326 ± 0.058
0.457 ± 0.058
0.572 ± 0.053
0.151 ± 0.030
0.394 ± 0.042
0.642 ± 0.034

0.319 ± 0.059
0.371 ± 0.059
0.439 ± 0.060
0.150 ± 0.035
0.221 ± 0.042
0.368 ± 0.044
0.061 ± 0.002
0.106 ± 0.016
0.291 ± 0.027

0.180 ± 0.046
0.211 ± 0.047
0.273 ± 0.050
0.048 ± 0.001
0.066 ± 0.009
0.114 ± 0.020
0.049 ± 0.001
0.054 ± 0.001
0.066 ± 0.001

Open Category Detection with PAC Guarantees

Table 22. Recall & False Positive Rate for Covertype Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Covertype
n=13624

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.979 ± 0.002
0.995 ± 0.001
0.999 ± 0.000
0.980 ± 0.001
0.998 ± 0.000
1.000 ± 0.000
0.981 ± 0.001
0.998 ± 0.000
1.000 ± 0.000

0.950 ± 0.002
0.978 ± 0.001
0.997 ± 0.001
0.950 ± 0.001
0.980 ± 0.001
0.999 ± 0.000
0.951 ± 0.001
0.980 ± 0.001
0.999 ± 0.000

0.901 ± 0.002
0.930 ± 0.001
0.965 ± 0.001
0.902 ± 0.002
0.929 ± 0.001
0.964 ± 0.001
0.903 ± 0.001
0.929 ± 0.001
0.964 ± 0.001

0.012 ± 0.007
0.095 ± 0.025
0.292 ± 0.045
0.006 ± 0.002
0.143 ± 0.027
0.427 ± 0.043
0.010 ± 0.001
0.206 ± 0.030
0.555 ± 0.038

0.002 ± 0.000
0.012 ± 0.004
0.110 ± 0.025
0.003 ± 0.000
0.008 ± 0.002
0.154 ± 0.026
0.006 ± 0.000
0.012 ± 0.002
0.200 ± 0.022

0.002 ± 0.000
0.002 ± 0.000
0.004 ± 0.001
0.002 ± 0.000
0.002 ± 0.000
0.003 ± 0.000
0.005 ± 0.000
0.005 ± 0.000
0.007 ± 0.000

0.989 ± 0.002
0.998 ± 0.001
0.999 ± 0.000
0.986 ± 0.002
0.999 ± 0.000
1.000 ± 0.000
0.985 ± 0.002
0.999 ± 0.000
1.000 ± 0.000

0.962 ± 0.004
0.987 ± 0.002
0.998 ± 0.000
0.952 ± 0.002
0.983 ± 0.001
1.000 ± 0.000
0.951 ± 0.001
0.981 ± 0.001
1.000 ± 0.000

0.905 ± 0.004
0.937 ± 0.004
0.973 ± 0.003
0.902 ± 0.002
0.929 ± 0.001
0.965 ± 0.001
0.903 ± 0.001
0.929 ± 0.001
0.964 ± 0.001

0.359 ± 0.072
0.479 ± 0.067
0.586 ± 0.059
0.211 ± 0.055
0.420 ± 0.058
0.615 ± 0.047
0.136 ± 0.044
0.437 ± 0.051
0.677 ± 0.036

0.166 ± 0.051
0.276 ± 0.058
0.409 ± 0.060
0.018 ± 0.014
0.115 ± 0.035
0.319 ± 0.045
0.006 ± 0.000
0.050 ± 0.015
0.310 ± 0.034

0.028 ± 0.022
0.055 ± 0.029
0.123 ± 0.038
0.002 ± 0.000
0.002 ± 0.000
0.011 ± 0.003
0.005 ± 0.000
0.005 ± 0.000
0.007 ± 0.001

Open Category Detection with PAC Guarantees

Si Liu * 1 Risheek Garrepalli * 2 Thomas G. Dietterich 2 Alan Fern 2 Dan Hendrycks 3

8
1
0
2
 
g
u
A
 
1
 
 
]

G
L
.
s
c
[
 
 
1
v
9
2
5
0
0
.
8
0
8
1
:
v
i
X
r
a

Abstract
Open category detection is the problem of detect-
ing “alien” test instances that belong to categories
or classes that were not present in the training
In many applications, reliably detecting
data.
such aliens is central to ensuring the safety and
accuracy of test set predictions. Unfortunately,
there are no algorithms that provide theoretical
guarantees on their ability to detect aliens under
general assumptions. Further, while there are al-
gorithms for open category detection, there are
few empirical results that directly report alien de-
tection rates. Thus, there are signiﬁcant theoret-
ical and empirical gaps in our understanding of
open category detection. In this paper, we take
a step toward addressing this gap by studying a
simple, but practically-relevant variant of open
category detection. In our setting, we are pro-
vided with a “clean” training set that contains
only the target categories of interest and an un-
labeled “contaminated” training set that contains
a fraction α of alien examples. Under the as-
sumption that we know an upper bound on α, we
develop an algorithm with PAC-style guarantees
on the alien detection rate, while aiming to mini-
mize false alarms. Empirical results on synthetic
and standard benchmark datasets demonstrate the
regimes in which the algorithm can be effective
and provide a baseline for further advancements.

1. Introduction

Most machine learning systems implicitly or explicitly as-
sume that their training experience is representative of their
test experience. This assumption is rarely true in real-world
deployments of machine learning, where “unknown un-
knowns”, or “alien” data, can arise without warning. Ig-

*Equal contribution 1Department of Statistics, Oregon State
University, Oregon, USA 2School of EECS, Oregon State Univer-
sity, Oregon, USA 3University of California, Berkeley, California,
USA. Correspondence to: Si Liu <lius2@oregonstate.edu>.

Proceedings of the 35 th International Conference on Machine
Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018
by the author(s).

noring the potential for such aliens can lead to serious safety
concerns in many applications and signiﬁcantly degrade
the accuracy of test set predictions in others. For exam-
ple, consider a scientiﬁc application where a classiﬁer is
trained to recognize speciﬁc categories of insects in fresh-
water samples in order to detect important environmental
changes (Lytle et al., 2010). Test samples will typically
contain some fraction of specimens belonging to species
not represented in the training data. A classiﬁer that is un-
aware of these new species will misclassify the specimens
as belonging to existing species. This will produce incorrect
scientiﬁc conclusions.

The problem of open category detection is to detect such
alien examples at test time. An ideal algorithm for this prob-
lem would guarantee a user-speciﬁed alien-detection rate
(e.g., 95%), while attempting to minimize the false alarm
rate. Unfortunately, no existing algorithm provides such
guarantees under general conditions. In addition, empir-
ical evaluations of existing algorithms for open category
detection typically do not directly evaluate alien detection
rates, which are perhaps the most relevant for safety-critical
applications. Overall, our current theoretical and practical
understanding of open category detection is lacking from a
safety and accuracy perspective.

Is it possible to achieve open category detection with guar-
antees? In this paper, we take a step toward answering
this question by studying a simpliﬁed, but practically rel-
evant, problem setting. To motivate our setting, consider
the above insect identiﬁcation problem. At training time it
is reasonable to expect that a clean training set is available
that contains only the insect categories of interest. At test
time, a new sample will include insects from the training
categories along with some percentage of insects from new
alien categories. Further, scientists may have reasonable
estimates for this percentage based on their scientiﬁc knowl-
edge and practical experience. We would like to guarantee
that the system is able to raise an alarm for, say, 95% of the
insects from alien classes, with each alarm being examined
by a scientist. At the same time, we would like to avoid as
many “false alarms” as possible, since each alarm requires
scientist effort.

To formalize the example, our setting assumes two training
sets: a clean training dataset involving a ﬁnite set of cate-

Open Category Detection with PAC Guarantees

gories and a contaminated dataset that contains a fraction α
of aliens. Our ﬁrst contribution is to show that, in this setting,
theoretical guarantees are possible given knowledge of an
upper bound on α. In particular, we give an algorithm that
uses this knowledge to provide Probably Approximately
Correct (PAC) guarantees for achieving a user-speciﬁed
alien detection rate. While knowledge of a non-trivial upper
bound on α may not always be possible, in many situations
it will be possible to select a reasonable value based on
domain knowledge, prior data, or by inspecting a sample of
the test data.

The key idea behind our algorithm is to leverage modern
anomaly detectors, which are trained on the clean data. Our
algorithm combines the anomaly-score distributions over
the clean and contaminated training data in order to derive
an alarm threshold that achieves the desired guarantee on
the alien detection rate on new test queries. In theory the
detection rate guarantee will be met regardless of the quality
of the anomaly detector. The quality of the detector, how-
ever, has a signiﬁcant impact on the false alarm rate, with
better detectors leading to fewer false alarms.

We carry out experiments1 on synthetic and benchmark
datasets using a state-of-the-art anomaly detector, the Iso-
lation Forest (Liu et al., 2008). We vary the amount of
training data, the fraction α of alien data points, along with
the accuracy of the upper bound on α provided to our algo-
rithm. The results indicate that our algorithm can achieve
the guaranteed performance when enough data is available,
as predicted by the theory. The results also show that for
the considered benchmarks, the Isolation Forest anomaly
detector is able to support non-trivial false positive rates
given enough data. The results also illustrate the inherent
difﬁculty of the problem for small datasets and/or small
values of α. Overall, our results provide a useful baseline
for driving future work on open category detection with
guarantees.

2. Related Work

Open category detection is related to the problem of one-
class classiﬁcation, which aims to detect outliers relative
to a single training class. One-class SVMs (OCSVMs)
(Sch¨olkopf et al., 2001) are popular for this problem. How-
ever, they have been found to perform poorly for open
category detection due to poor generalization (Zhou &
Huang, 2003), which has been partly addressed by later
work (Manevitz & Yousef, 2002; Wu & Ye, 2009; Jin et al.,
2004; Cevikalp & Triggs, 2012). OCSVMs have been em-
ployed in a multi-class setting similar to open category de-
tection (Heﬂin et al., 2012; Pritsos & Stamatatos, 2013).

1Code for reproducing our experiments can be found at

https://github.com/liusi2019/ocd.

However, there are no direct mechanisms to control the alien
detection rate of these methods, which is a key requirement
for our problem setting.

Work on classiﬁcation with rejection/abstaining options
(Chow, 1970; Wegkamp, 2007; Tax & Duin, 2008;
Pietraszek, 2005; Geifman & El-Yaniv, 2017) allows classi-
ﬁers to abstain from making predictions when they are not
conﬁdent. While loosely related to open category detection,
these approaches do not directly consider the possibility of
novel categories, but rather focus on assessing conﬁdence
with respect to the known categories. Due to their closed-
world discriminative nature, it is easy to construct scenarios
where such methods are incorrectly conﬁdent about the class
of an alien and do not abstain.

A variety of prior work has addressed variants of open cat-
egory detection. This includes work on formalizing the
concept of “open space” to characterize the region of the fea-
ture space outside of the support of the training set (Scheirer
et al., 2013). Variants of SVMs have also been developed,
such as the One-vs-Set Machine (Scheirer et al., 2013) and
the Weibull-calibrated SVM (Scheirer et al., 2014). Ad-
ditional work has addressed open category detection by
tuning the decision boundary based on unlabeled data which
contains data from novel categories (Da et al., 2014). Ap-
proaches based on nearest neighbor methods have also been
proposed (Mendes J´unior et al., 2017). None of these meth-
ods, however, allow for the direct control of alien detection
rates, nor do they provide theoretical guarantees.

There is also recent interest in open category detection for
deep neural networks applied to vision and text classiﬁcation
(Bendale & Boult, 2016; Shu et al., 2017). These methods
usually train a neural network in a standard closed-world
setting, but then analyze various activations in the network
in order to detect aliens. Another related line of work is
detection of out-of-distribution instances, which is similar
to open category detection but assumes that the test data
come from a completely different distribution compared to
the training distribution (Hendrycks & Gimpel, 2017; Liang
et al., 2018). All of this work is quite specialized to deep
neural networks and does not provide direct control of alien
detection rates or theoretical guarantees.

3. Problem Setup

We consider open category detection where there is an un-
known nominal data distribution D0 over labeled examples
from a known set of category labels. We receive as input
a “clean” nominal training set S0 containing k i.i.d. draws
from D0. In practice, S0 will correspond to some curated
labeled data that contains only known categories of interest.

We also receive as input an unlabeled “mixture” dataset
Sm that contains n points drawn i.i.d. from a mixture dis-

Open Category Detection with PAC Guarantees

tribution Dm. Speciﬁcally, the mixture distribution Dm is
a combination of the nominal distribution D0 and an un-
known alien distribution Da, which is a distribution over
novel categories (alien data points). We assume that Da is
stationary, so that all alien points that appear as future test
queries will also be drawn from Da.

At training time, we assume that Dm is a mixture distribu-
tion, with probability α of generating an alien data point
from Da and probability of 1 − α of generating a nominal
point. Our results hold even if the test queries come from a
mixture with a different value of α as long as the alien test
points are drawn from Da.

Given these datasets, our problem is to label test instances
from Dm as either “alien” or “nominal”. In particular, we
wish to achieve a speciﬁed alien detection rate, which is
the fraction of alien data points in Dm that are classiﬁed as
“alien” (e.g., 95%). At the same time we would like the false
positive rate to be small, which is the fraction of nominal
data points incorrectly classiﬁed as aliens.

Our approach to this problem assumes the availability of an
anomaly detector that is trained on S0 and assigns anomaly
scores to all data points in both S0 and Sm. Intuitively, the
anomaly scores order the test examples according to how
anomalous they appear relative to the nominal data (higher
scores being more anomalous). An ideal detector would
rank all alien data points higher than all nominals, though
in practice, the ordering will not be so clean. Our approach
labels data in Sm by selecting a threshold on the anomaly
scores and labeling all data points with scores above the
threshold as aliens and the remaining points as nominals.
Our key challenge is to select a threshold that provides a
guarantee on the alien detection rate.

4. Algorithms for Open Category Detection

In order to obtain theoretical guarantees, our algorithm as-
sumes knowledge of the alien mixture probability α that
generates the mixture data Sm. Later, we will show that
knowing an upper bound on α is sufﬁcient to obtain a guar-
antee.

Our approach is based on considering the cumulative dis-
tribution functions (CDFs) over anomaly scores of a ﬁxed
anomaly detector. Let F0, Fa, and Fm be the CDFs of
anomaly scores for the nominal data distribution D0, alien
distribution Da, and mixture distribution Dm respectively.
Since Dm is a simple mixture of D0 and Da, we can write
Fm as

Fm(x) = (1 − α)F0(x) + αFa(x).

From this we can derive the CDF for Fa in terms of Fm and
F0:

Fa(x) =

Fm(x) − (1 − α)F0(x)
α

.

Given the ability to derive Fa, it is straightforward to achieve
an alien detection rate of 1 − q (e.g. 95%) by selecting an
anomaly score threshold τq that is the q quantile of Fa and
raising an alarm on all test queries whose anomaly score is
greater than τq.

In reality, we do not have access to Fm or F0 and hence
cannot exactly determine Fa. Rather, we have samples
Sm and S0. Thus, our algorithm works with the empirical
CDFs ˆF0 and ˆFm, which are simple step-wise constant
approximations, and estimates an empirical CDF over aliens:

ˆFa(x) =

ˆFm(x) − (1 − α) ˆF0(x)
α

.

(1)

Our algorithm computes the above estimate of ˆFa and uses
it to select a threshold ˆτq to be the largest threshold such
that ˆFa(ˆτq) ≤ q, where 1 − q is the target alien detection
rate. This choice will minimize the number of false alarms.
The steps of this algorithm are as follows.

Algorithm 1
1: Get anomaly scores for all points in S0 and Sm, denoted

x1, x2, . . . , xk and y1, y2, . . . , yn respectively.

2: Compute empirical CDFs ˆF0 and ˆFm.
3: Calculate ˆFa using equation 1.
4: Output detection threshold

ˆτq = max{u ∈ S : ˆFa(u) ≤ q},

where S = {x1, x2, . . . , xk, y1, y2, . . . , yn}.

Although ˆFm and ˆF0 are both legal CDFs, the estimate
for ˆFa from step 3 may not be a legal CDF, because it is
the difference of two noisy estimates—it may not increase
monotonically and it may even be negative. A good tech-
nique for dealing with this problem is to employ isotoniza-
tion (Barlow & Brunk, 1972) and clipping. Isotonization
ﬁnds the monotonically increasing function ˆF ∗
a closest to
ˆFa in squared error. To convert ˆFa into a legal CDF, deﬁne
ˇFa = min{max{ ˆF ∗
a , 0}, 1}, where the min and max opera-
tors are applied pointwise to their arguments. We performed
experiments (shown in the supplementary materials) to test
whether using ˇFa in Step 4 would improve the performance
of the overall algorithm. We found that it did not.

5. Finite Sample Guarantee

In the limit of inﬁnite data (both nominal and mixture) and
perfect knowledge of α, ˆFa will converge to the true alien
CDF, and our algorithm will achieve the desired alien de-
tection rate. In this section, we consider the ﬁnite data case
where |S0| = |Sm| = n. We derive a value for the sample
size n that guarantees with high probability over random

Open Category Detection with PAC Guarantees

draws of S0 and Sm, that fraction 1 − q − (cid:15) of the alien
test points will be detected, where (cid:15) is an additional error
incurred because of the ﬁnite sample size n.

Our key theoretical tool is a ﬁnite sample result on the
uniform convergence of empirical CDF functions (Massart,
1990). To use this result, we make the reasonable technical
assumption that the nominal and alien CDFs, F0 and Fa,
are continuous. In the following, let η be the target alien
detection rate, q be the input to Algorithm 1, ˆτq be the
estimated q-quantile of the alien CDF (step 4 of Alg. 1),
and (cid:15) be an error parameter. The following theorem gives
the sample complexity for guaranteeing that 1 − η of the
alien examples will be detected using threshold ˆτq.
Theorem 1. Let S0 and Sm be nominal and mixture
datasets containing n i.i.d. samples from the nominal and
mixture data distributions respectively. For any (cid:15) ∈ (0, 1−q)
and δ ∈ (0, 1), if

n >

ln

1
2

2
√
1 − δ

(cid:18) 1
(cid:15)

1 −

(cid:19)2 (cid:18) 2 − α

(cid:19)2

,

α

the alien CDF will typically concentrate more mass toward
larger anomaly score values compared to F0. Indeed, if this
is not the case, there is little hope since there is effectively
no signal to distinguish between aliens and nominals.

Corollary 1. Consider running Algorithm 1 using an upper
bound α(cid:48) on the true α. Under the same assumptions as
Theorem 1, if the anomaly detector is admissible and

n >

ln

1
2

2
√
1 − δ

(cid:18) 1
(cid:15)

1 −

(cid:19)2 (cid:18) 2 − α(cid:48)

(cid:19)2

,

α(cid:48)

then with probability at least 1 − δ, Algorithm 1 will return
a threshold ˆτq that achieves an alien detection rate of at
least 1 − η, where η = q + (cid:15).

The proof is in the Appendix. While we can achieve a guar-
antee using an upper bound on α(cid:48), the returned threshold
will be more conservative (smaller) than if we had used the
true α. This will result in higher false alarm rates, since
more nominal points will be above the threshold. Thus it is
desirable to use a value of α(cid:48) that is as close to α as possible.

then with probability at least 1 − δ, Algorithm 1 will return
a threshold ˆτq that achieves an alien detection rate of at
least 1 − η, where η = q + (cid:15).

6. Experiments

(cid:15)2α2 log 1

The proof is in the Appendix. Note that n grows as
O( 1
δ ). Hence, this guarantee is polynomial in all
relevant parameters, which we believe is the ﬁrst such guar-
antee for open category detection. The result can be gener-
alized to the case where n0 < nm; in practice, the larger
the mixture sample Sm is, the easier it is to estimate τq,
because this provides more alien points for estimating the
q-th quantile of Fa.

The theorem gives us ﬂexibility in setting (cid:15) and q (the algo-
rithm input) to achieve a guarantee of 1−η. The (cid:15) parameter
controls a trade-off between sample size and false alarm rate.
To minimize the false alarm rate, we want to make q large
(to obtain a larger threshold), so we want to set q close to η.
But, as q → η, (cid:15) → 0, and n → ∞. To minimize the sample
size n, we want to make q as small as possible, because that
allows (cid:15) to be larger and hence n becomes smaller. The
optimal setting of (cid:15) depends on how the false alarm rate
grows with τq, which in turn depends on the relative shape
of F0 and Fa. In a real safety application, we can estimate
these from S0 and Sm and choose an appropriate q value.

What if we don’t know the exact value of α? If our algorithm
uses an upper bound α(cid:48) on the true α to compute ˆFa, we
can still provide a guarantee. In this case, in addition to the
assumptions in Theorem 1, we need a concept of an anomaly
detector being admissible. We say that an anomaly detector
is admissible for a problem, if the anomaly score CDFs
satisfy F0(x) ≥ Fm(x) for all x ∈ R. Most reasonable
anomaly detectors will be admissible in this sense, since

We performed experiments to answer four questions. Ques-
tion Q1: how accurate is our estimate of ˆτq as a function of
n and α? Question Q2: how loose are the bounds from The-
orem 1? Question Q3: what are typical values of the false
alarm rates for various settings of n and α on real datasets?
Question Q4: how do these observed values change if we
employ an overestimate α(cid:48) > α?

All of our experiments employ the Isolation Forest anomaly
detector (Liu et al., 2008), which has been demonstrated
to be a state-of-the-art detector in recent empirical studies
In the Supplementary Materials
(Emmott et al., 2013).
we show similar results with the LODA anomaly detector
(Pevn´y, 2015).

To address Q1 and Q2, we run controlled experiments
on synthetic data. The data points are generated from 9-
dimensional normal distributions. The dimensions of the
nominal distribution D0 are independently distributed as
N (0, 1). The alien distribution is similar, but with probabil-
ity 0.4, 3 of the 9 dimensions (chosen uniformly at random)
are distributed as N (3, 1) and with probability 0.6, 4 of the
9 dimensions (chosen uniformly at random) follow N (3, 1).
This ensures that the anomalies are not highly similar to
each other and models the situation in which there are many
different kinds of alien objects, not just a single alien class
forming a tight cluster.

In each experiment, the nominal dataset and the mixture
dataset are of the same size n, and the mixture dataset
contains a proportion α of anomaly points. We ﬁxed
the target quantile to be q = 0.05. The experiments are

Open Category Detection with PAC Guarantees

Figure 1. Comparison of recall achieved by ˆτq compared to oracle
recall of 0.95. Error bars are 95% conﬁdence intervals. Settings
of n and α increase from left to right starting with α = 0.01 and
n ∈ {100, 500, 1K, 5K, 10K} up to α = 0.5 and n = 10K.

carried out for n ∈ {100, 500, 1K, 5K, 10K} and α ∈
{0.01, 0.05, 0.10, 0.20, 0.50}. For testing, we create two
large datasets G0 and Ga, with G0 being a pure nominal
dataset, Ga being a pure alien dataset, and |G0| = |Ga| =
20K. The Isolation Forest algorithm computes 1000 full
depth isolation trees on the nominal data. Each tree is grown
on a randomly-selected 20% subsample of the clean data
points. We compute anomaly scores for the nominal points
via out-of-bag estimates and anomaly scores for the mix-
ture points, G0, and Ga using the full isolation forest. For
each combination of n and α, we repeat the experiment
100 times. We measure the fraction of aliens detected (the
“recall”) and the fraction of nominal points declared to be
alien (the “false positive rate”) by applying the ˆτq estimate
to threshold the anomaly scores in G0 and Ga.

To assess the accuracy of our ˆτq estimates (Q1), we could
compare them to the true values. However, this comparison
is hard to interpret, because τ is expressed on the scale
of anomaly scores, which are somewhat arbitrary. Instead,
Figure 1 plots the recall achieved by ˆτq. If ˆτq had been
estimated perfectly, the recall would always be 1−q = 0.95.
However, we see that the recall is often less than 0.95, which
indicates that ˆτq is over-estimated, especially when n and α
are small. This behavior is predicted by our theory, where
we see that the sample size requirements grow inversely
with α2. For larger α and n, the recall guarantee is generally
achieved. Figure 2 compares the false positive rate of the
true oracle τq to the false positive rate of the estimate ˆτq. For
each combination of α and n, we have 100 replications of
the experiment and therefore 100 estimates ˆτa and 100 FPR
rates. For each of these, the true FPR is computed using G0.

Figure 2. Comparison of oracle FPR to the FPR achieved by ˆτq.
Error bars span from the 25th to 75th percentile with the blue dot
marking the median of the 100 trials. Orange markers indicate the
oracle FPR. Settings of n and α increase from left to right starting
with α = 0.01 and n ∈ {100, 500, 1K, 5K, 10K} up to α = 0.5
and n = 10K.

The error bars summarize the resulting 100 FPR values by
the median and inter-quartile range. We see that for small n
and α, the FPR can be quite different from the oracle rate,
but for larger n and α, the estimates are very good.

To assess the looseness of the bounds (Q2), for each combi-
nation of n and α, we ﬁx δ = 0.05 and compute the value
of η such that 95 of the 100 runs achieved a recall of at least
1 − η (thus η empirially achieves the 1 − δ guarantee). We
then compute (cid:15) = η − q and the corresponding required
sample size n∗ according to Theorem 1. Figure 3 shows a

Figure 3. The log sample size n∗ required by Theorem 1 in order
to guarantee the actual observed recall versus the log actual sample
size n.

Open Category Detection with PAC Guarantees

plot of n∗ versus the actual n. The distance of these points
from the n∗ = n diagonal line show that the theory is fairly
loose, although it becomes tighter as n gets large.

Figure 4. False positive rates on six UCI datasets as a function of
α (q = 0.05, δ = 0.05).

Benchmark Data Experiments. To address our third and
fourth questions, we performed experiments on six UCI
multiclass datasets: Landsat, Opt.digits, pageb, Shuttle,
Covertype and MNIST. In addition to these, we provide
results for the Tiny ImageNet dataset. In each multiclass
dataset, we split the classes into two groups: nominal and
alien. For Tiny ImageNet, we train a deep neural network
classiﬁer on 200 nominal classes and treat the remaining
800 as aliens. The nominal classes for UCI datasets are
MNIST(1,3,7), Landsat(1,7), OCR(1,3,4,5,7), pageb(1,5),
Letter recognition(1,3), and Shuttle(1,4). We generated

Figure 5. Recall rates on six UCI datasets as a function of α (q =
0.05, δ = 0.05)

Figure 6. False positive rates on two image datasets as a function
of α (q = 0.05, δ = 0.05).

nominal and mixture datasets for various values of α. The
value of n for each dataset is 1532 for Landsat,788 for Letter
recognition, 568 for OCR, 4912 for pageb, 5000 for Shuttle,
13,624 for Covertype, 11,154 for MNIST, and 10,000 for
Tiny ImageNet. Because we cannot create datasets with
large n, we cannot measure the true value of τq.

After computing the anomaly scores for both nominal and
mixture datasets, we applied Algorithm 1 within a 10-fold
cross validation. We divide the mixture data points at ran-
dom into 10 groups. For each fold, we estimate ˆFa and ˆτa
from 9 of the 10 groups and then score the mixture points in
the held-out fold according to ˆτa. In all other respects, the
experimental protocol is the same as for the synthetic data.
For Tiny ImageNet, the anomaly scores are obtained by
applying a baseline method (Hendrycks & Gimpel, 2017).

To answer Q3, Figures 4 and 6 plot the false positive rate as
a function of α for the UCI and vision datasets, respectively.
We see that the FPR ranges from 3.6% to 26.9% on UCI
depending on the dataset and the level of α. The vision
datasets have higher FPR, especially MNIST, which has a
large number of alien classes that are not distinguished well
by the anomaly detector. The FPR depends primarily on
the domain, because the key issue is how well the anomaly
detector distinguishes between nominal and alien examples.
The false alarm rate generally improves as α increases. In
some applications, it may be possible to enrich Sm so that
α is larger on the training set to take advantage of this
phenomenon. It is interesting to note that once ˆτa has been
computed, it can be applied to test datasets having different
(or unknown) values of α.

Figures 5 and 7 plot the recall rate as a function of α for
the UCI and vision datasets. We set q = 0.05 in these
experiments. Theorem 1 only guarantees a recall of 1−q −(cid:15),

Open Category Detection with PAC Guarantees

of α(cid:48) − α. Two points are plotted for each combination
of α(cid:48) and dataset, the change in Recall and the change in
FPR. We observe that the recall increases slightly (in the
range from 0.01 to 0.05). However, the false positive rate
increases by much larger amounts (from 0.01 to 0.336). This
demonstrates that it is very important to determine the value
of α accurately.

7. Summary

We have taken a step toward open category detection with
guarantees by providing a PAC-style guarantee on the prob-
ability of detecting 1 − η of the aliens on the test data. This
is the ﬁrst such guarantee under any similarly general con-
ditions. We have shown that this guarantee is satisﬁed in
our experiments, although the guarantee is somewhat loose,
especially on small training sets. Obtaining a guarantee re-
quires more data than standard PAC guarantees on expected
prediction accuracy. This is because we must estimate the
q quantile of the alien anomaly score distribution, where
q is typically quite small. Nonetheless, our experiments
show that our algorithm gives good recall performance and
non-trivial false alarm rates on datasets of reasonable size.

It is important to note that the very formulation of a PAC-
style guarantee on the probability of detecting aliens re-
quires assuming that the aliens are drawn from a well-
deﬁned distribution Da. While this is appropriate in some
applications, such as the insect survey application described
in the introduction, it is not appropriate for adversarial set-
tings. In such settings, a PAC-style guarantee does not make
sense, and some other form of safety guarantee needs to be
formulated.

To obtain the guarantee, we employ two training datasets:
a clean dataset that contains no aliens and an (unlabeled)
contaminated dataset that contains a known fraction α of
aliens. An important theoretical problem for future research
is to develop a method that can estimate a tight upper bound
on ˆα > α. We believe this is possible, but we have not yet
found a method that guarantees that ˆα > α.

Our guarantee requires more data as α becomes small. For-
tunately, when α is small, it may be possible in some appli-
cations to afford lower recall rates, since the frequency of
aliens will be smaller. However, in safety-critical applica-
tions where a single undetected alien poses a serious threat,
there is little recourse other than to collect more data or
allow for higher false positive rates.

Acknowledgements

This research was supported by a gift from Huawei, Inc.,
and grants from the Future of Life Institute and the NSF
Grant 1514550. Any opinions, ﬁndings, and conclusions

Figure 7. Recall rates on two image datasets as a function of α
(q = 0.05, δ = 0.05).

Figure 8. Change in recall and false positive rate as a function of
α(cid:48) − α for six UCI datasets; α ∈ {0.1, 0.2, 0.4}

where (cid:15) depends on n. Hence, it is nice to see that for
three of the domains (Shuttle, Covertype, and Landsat) in
UCI and for both vision datasets, the recall is very close to
1 − q = 0.95. These are the domains with the largest values
of n. The value of α has a bigger impact on recall than it
does on FPR. This is because the effective number of alien
training examples is αn, which can be very small for some
datasets when α = 0.1. This shows that in applications such
as fraud detection, where α may be very small, the mixture
dataset Sm needs to be very large.

To answer Q4 regarding the impact of using an incorrect
value α(cid:48) > α, we repeated these experiments with α(cid:48) =
α+ξ, for ξ ∈ {0.002, 0.004, 0.006, 0.008, 0.010}. Figure 8
plots the change in false positive rate and recall as a function

Open Category Detection with PAC Guarantees

or recommendations expressed in this material are those of
the author(s) and do not necessarily reﬂect the views of the
sponsors.

we will have

A. Proof for Theorem 1

Suppose there are n random variables which are i.i.d. from
the distribution with CDF F and let ˆFn be the empirical
CDF calculated from this sample. Then Massart (1990)
shows that

√

P (

n sup
x

| ˆFn(x) − F (x)| > λ) ≤ 2 exp(−2λ2)

(2)

holds without any restriction on λ. Making use of this,
and assuming we use the same sample size n for both the
mixture dataset and the clean data set, for any (cid:15) ∈ (0, 1 − q),
we seek to determine how large n needs to be in order to
guarantee that with probability at least 1 − δ our quantile
estimate ˆτq satisﬁes Fa(ˆτq) ≤ q + (cid:15). To achieve this, we
want to have

P (sup

| ˆFa(x) − Fa(x)| > (cid:15)) ≤ δ.

We have

x

x

x

x

x

1
2

P (sup

| ˆFa(x) − Fa(x)| > (cid:15))

= P (sup

|

ˆFm(x) − (1 − α) ˆF0(x)
α

−

Fm(x) − (1 − α)F0(x)
α
( ˆFm(x) − Fm(x)) −

| > (cid:15))

|

= P (sup

1
α

( ˆF0(x) − F0(x))| > (cid:15))

≤ P ((

| ˆFm(x) − Fm(x)| +

x
1 − α
α

1
α
1 − α
α

sup
x

sup
x

1
sup
α
x
1 − α
α

sup
x

∪ {

1
2 − α

(cid:15)}

1 − α
2 − α

(cid:15)})

≤ P ({

| ˆFm(x) − Fm(x)| >

= P ({sup

| ˆFm(x) − Fm(x)| >

∪ {sup

| ˆF0(x) − F0(x)| >

| ˆF0(x) − F0(x)| >
α
2 − α
α
2 − α

(cid:15)}

(cid:15)}).

| ˆF0(x) − F0(x)|) > (cid:15))

But

Making use of (2), when

n >

ln

2
√
1 − δ

(

1
(cid:15)

)2(

2 − α
α

)2,

1 −

P (sup

| ˆFm(x) − Fm(x)| >

(cid:15)) ≤ 1 −

1 − δ,

P (sup

| ˆF0(x) − F0(x)| >

(cid:15)) ≤ 1 −

1 − δ.

α
2 − α
α
2 − α

√

√

x

x

In this case we will have

P (sup

| ˆFa(x) − Fa(x)| > (cid:15))

x

≤ 1 − P ({sup

x

| ˆFm(x) − Fm(x)| ≤
α
2 − α

| ˆF0(x) − F0(x)| ≤

(cid:15)})

α
2 − α

(cid:15)}

∩ {sup

x
≤ 1 − (1 − 1 +

√

1 − δ)2

= δ.

Now we have with probability at least 1 − δ,

| ˆFa(x) − Fa(x)| ≤ (cid:15), ∀x ∈ R.

If this inequality holds, then for any value ˆτq such that
ˆFa(ˆτq) ≤ q, we have

Fa(ˆτq) ≤ ˆFa(ˆτq) + (cid:15) ≤ q + (cid:15).

So we have with probability at least 1 − δ, any ˆτq satisfying
ˆFa(ˆτq) ≤ q will satisfy Fa(ˆτq) ≤ q + (cid:15).
(cid:3)

B. Proof for Corollary 1

If α(cid:48) ≥ α, and if we write

F (cid:48)

a(x) =

Fm(x) − (1 − α(cid:48))F0(x)
α(cid:48)

,

then F (cid:48)

a is still a legal CDF, because

a(−∞) = 0, F (cid:48)
F (cid:48)

a(∞) = 1,

and it is easy to show that F (cid:48)
ing.

a is monotonically nondecreas-

F (cid:48)

≥ 0, ∀x ∈ R,

a(x)−Fa(x) =

(α − α(cid:48))(Fm(x) − F0(x))
αα(cid:48)
and because of this, if we let ˆτ (cid:48)
q denote the threshold we
get from using α(cid:48), we will have Fa(ˆτ (cid:48)
q) ≤ F (cid:48)
q). By
the proof of previous theorem, we know that when n >
2
1
α(cid:48) )2, we have with probability at least
2 ln
√
1−δ
q) ≤ q + (cid:15).(cid:3)
a(ˆτ (cid:48)
1 − δ, F (cid:48)

(cid:15) )2( 2−α(cid:48)
( 1
q) ≤ q + (cid:15), and thus we have Fa(ˆτ (cid:48)

a(ˆτ (cid:48)

1−

References

Barlow, RE and Brunk, HD. The isotonic regression prob-
lem and its dual. Journal of the American Statistical
Association, 67(337):140–147, 1972.

Open Category Detection with PAC Guarantees

Bendale, A. and Boult, T. E. Towards open set deep net-
works. In 2016 IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), pp. 1563–1572, June
2016.

Cevikalp, H. and Triggs, B. Efﬁcient object detection using
cascades of nearest convex model classiﬁers. In 2012
IEEE Conference on Computer Vision and Pattern Recog-
nition, pp. 3138–3145, June 2012.

Chow, C. On optimum recognition error and reject tradeoff.
IEEE Transactions on Information Theory, 16(1):41–46,
Jan 1970. ISSN 0018-9448.

Da, Qing, Yu, Yang, and Zhou, Zhi-Hua. Learning with
augmented class by exploiting unlabeled data. In Pro-
ceedings of the Twenty-Eighth AAAI Conference on Artiﬁ-
cial Intelligence, AAAI’14, pp. 1760–1766. AAAI Press,
2014.

Emmott, Andrew F, Das, Shubhomoy, Dietterich, Thomas,
Fern, Alan, and Wong, Weng-Keen. Systematic construc-
tion of anomaly detection benchmarks from real data. In
Proceedings of the ACM SIGKDD workshop on outlier
detection and description, pp. 16–21. ACM, 2013.

Geifman, Yonatan and El-Yaniv, Ran. Selective classiﬁca-
tion for deep neural networks. In Guyon, I., Luxburg,
U. V., Bengio, S., Wallach, H., Fergus, R., Vishwanathan,
S., and Garnett, R. (eds.), Advances in Neural Informa-
tion Processing Systems 30, pp. 4885–4894. Curran As-
sociates, Inc., 2017.

Heﬂin, B., Scheirer, W., and Boult, T. E. Detecting and
classifying scars, marks, and tattoos found in the wild. In
2012 IEEE Fifth International Conference on Biometrics:
Theory, Applications and Systems (BTAS), pp. 31–38,
Sept 2012.

Hendrycks, Dan and Gimpel, Kevin. A baseline for de-
tecting misclassiﬁed and out-of-distribution examples in
neural networks. In Proceedings of International Confer-
ence on Learning Representations, 2017.

Jin, Hongliang, Liu, Qingshan, and Lu, Hanqing. Face
detection using one-class-based support vectors. In Sixth
IEEE International Conference on Automatic Face and
Gesture Recognition, 2004. Proceedings., pp. 457–462,
May 2004.

Liang, Shiyu, Li, Yixuan, and Srikant, R. Enhancing the
reliability of out-of-distribution image detection in neural
networks. International Conference on Learning Repre-
sentations, 2018.

Lytle, David A, Mart´ınez-Mu˜noz, Gonzalo, Zhang, Wei,
Larios, Natalia, Shapiro, Linda, Paasch, Robert, Mold-
enke, Andrew, Mortensen, Eric N, Todorovic, Sinisa, and
Dietterich, Thomas G. Automated processing and identi-
ﬁcation of benthic invertebrate samples. Journal of the
North American Benthological Society, 29(3):867–874,
2010.

Manevitz, Larry M. and Yousef, Malik. One-class svms for
document classiﬁcation. J. Mach. Learn. Res., 2:139–154,
March 2002. ISSN 1532-4435.

Massart, P. The tight constant in the dvoretzky-kiefer-
wolfowitz inequality. The Annals of Probability, 18(3):
1269–1283, 1990. ISSN 00911798.

Mendes J´unior, Pedro R., de Souza, Roberto M., Werneck,
Rafael de O., Stein, Bernardo V., Pazinato, Daniel V.,
de Almeida, Waldir R., Penatti, Ot´avio A. B., Torres,
Ricardo da S., and Rocha, Anderson. Nearest neighbors
distance ratio open-set classiﬁer. Machine Learning, 106
(3):359–386, Mar 2017. ISSN 1573-0565.

Pevn´y, Tom´aˇs. Loda: Lightweight on-line detector of
anomalies. Machine Learning, (November 2014), 2015.

Pietraszek, Tadeusz. Optimizing abstaining classiﬁers using
roc analysis. In Proceedings of the 22Nd International
Conference on Machine Learning, ICML ’05, pp. 665–
672, New York, NY, USA, 2005. ACM. ISBN 1-59593-
180-5.

Pritsos, Dimitrios A. and Stamatatos, Efstathios. Open-
Set Classiﬁcation for Automated Genre Identiﬁcation, pp.
207–217. Springer Berlin Heidelberg, Berlin, Heidelberg,
2013. ISBN 978-3-642-36973-5.

Scheirer, W. J., de Rezende Rocha, A., Sapkota, A., and
Boult, T. E. Toward open set recognition. IEEE Transac-
tions on Pattern Analysis and Machine Intelligence, 35
(7):1757–1772, July 2013. ISSN 0162-8828.

Scheirer, W. J., Jain, L. P., and Boult, T. E. Probability
models for open set recognition. IEEE Transactions on
Pattern Analysis and Machine Intelligence, 36(11):2317–
2324, Nov 2014. ISSN 0162-8828.

Sch¨olkopf, Bernhard, Platt, John C., Shawe-Taylor, John C.,
Smola, Alex J., and Williamson, Robert C. Estimating
the support of a high-dimensional distribution. Neural
Comput., 13(7):1443–1471, July 2001. ISSN 0899-7667.

Shu, Lei, Xu, Hu, and Liu, Bing. DOC: deep open classiﬁ-
cation of text documents. CoRR, abs/1709.08716, 2017.

Liu, Fei Tony, Ting, Kai Ming, and Zhou, Zhi-Hua. Isolation
forest. In Data Mining, 2008. ICDM’08. Eighth IEEE
International Conference on, pp. 413–422. IEEE, 2008.

Tax, D.M.J. and Duin, R.P.W. Growing a multi-class classi-
ﬁer with a reject option. Pattern Recognition Letters, 29
(10):1565 – 1570, 2008. ISSN 0167-8655.

Open Category Detection with PAC Guarantees

Wegkamp, Marten H. Lasso type classiﬁers with a reject

option. 2007.

Wu, M. and Ye, J. A small sphere and large margin ap-
proach for novelty detection using training data with out-
liers. IEEE Transactions on Pattern Analysis and Ma-
chine Intelligence, 31(11):2088–2092, Nov 2009. ISSN
0162-8828.

Zhou, Xiang Sean and Huang, Thomas S. Relevance feed-
back in image retrieval: A comprehensive review. Mul-
timedia Systems, 8(6):536–544, Apr 2003. ISSN 1432-
1882.

Open Category Detection with PAC Guarantees

A. Experimental Results from Synthetic

Datasets

In this section we include the simulation results on synthetic
datasets from using two different anomaly detectors, Isola-
tion Forest and LODA in table 1-3 and 4-6 respectively. For
using LODA, when training it on the nominal dataset, we
build 1 000 random projections, and each of them is built
using a bootstrap resample of the nominal dataset. After
ﬁnishing building all projections, we calculate the anomaly
score for each point in nominal dataset only using the pro-
jections that didn’t use this point, and calculate the anomaly
scores for mixture dataset, G0 and Ga using all the projec-
tions. For all cases, we include results from targeting on
different recalls which are 98%, 95% and 90%. In table 1-6,
the oracle FPR column is the mean of 100 oracle FPRs in
each setting.

In table 7, we include the results we used for plotting ﬁgure
2. The results are the 1st quartile, median and 3rd quartile of
FPR from experiments using Iforest with target recall 95%.
Here the oracle FPR column is the median of 100 oracle
FPRs.

B. Experimental Results from UCI and Image

Datasets

In this section we include results of performance on UCI
benchmarks, MNIST and Tiny Imagenet and Tables 8-22
illustrate the results. The experimental protocol is similar
to synthetic datasets and two state of the art anomaly de-
tectors Isolation forest, LODA are applied. For Isolation
forest we train Forest with 1000 trees on nominal dataset
and use out of bag estimates of this dataset to estimate the
nominal datasets anomaly score distribution. For LODA we
build 1000 projections and similar to Isolation forest we get
anomaly score for each point in nominal dataset using the
projections that didn’t use this point.Tables 11-16 illustrate
the results of LODA for 6 different datasets for varying val-
ues of η and report the observed recall, False positive rate
averaged over 100 runs of each experiment. Tables 17-22
report the results for Isolation Forest and it can be observed
the performance of both LODA,Isolation Forest are similar.

For Image datasets we follow the same protocol as UCI for
MNIST and apply Isolation Forest on the input image but for
Tiny Imagenet the anomaly scores are obtained differently.
We ﬁrst train a Wide Residual Network (40-2) classiﬁer
on the 200 nominal classes of Tiny Imagenet and apply
baseline method (Hendrycks & Gimpel, 2017) on validation
data to get the nominal dataset distribution and later apply
the same method on the mixture dataset which will have α
proportion of aliens which are basically from 800 held out
classes.Tables 8-10 illustrate the results for these datasets
for target recall of 98%,95% and 90%.

Open Category Detection with PAC Guarantees

Table 1. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 98%, iForest

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

247818
1167215
1829649
4236646
6363404
23373
239656
259309
1067189
1536752
20178
107381
196205
456821
861861
7550
80449
110875
498016
670130
7053
34712
70925
167019
451373

0.710±0.033
0.862±0.019
0.884±0.015
0.920±0.010
0.932±0.009
0.826±0.027
0.939±0.009
0.940±0.008
0.961±0.005
0.965±0.004
0.907±0.017
0.951±0.007
0.960±0.005
0.970±0.004
0.975±0.003
0.946±0.011
0.971±0.005
0.972±0.004
0.977±0.002
0.977±0.002
0.970±0.005
0.977±0.003
0.979±0.002
0.978±0.001
0.979±0.001

0.033±0.027
0.033±0.024
0.031±0.024
0.060±0.038
0.065±0.034
0.088±0.037
0.064±0.032
0.046±0.025
0.083±0.039
0.063±0.026
0.105±0.033
0.071±0.035
0.062±0.023
0.075±0.031
0.088±0.034
0.158±0.045
0.131±0.045
0.098±0.038
0.048±0.010
0.051±0.019
0.156±0.036
0.056±0.009
0.053±0.014
0.039±0.002
0.036±0.001

0.102
0.042
0.036
0.039
0.037
0.101
0.042
0.037
0.039
0.037
0.100
0.042
0.037
0.039
0.037
0.101
0.042
0.037
0.039
0.037
0.102
0.042
0.036
0.039
0.037

0.929±0.029
0.972±0.016
0.980±0.009
0.985±0.007
0.984±0.007
0.950±0.022
0.979±0.007
0.977±0.007
0.984±0.005
0.987±0.004
0.977±0.010
0.985±0.005
0.982±0.005
0.988±0.004
0.989±0.003
0.974±0.010
0.988±0.004
0.989±0.004
0.985±0.003
0.984±0.003
0.982±0.005
0.984±0.003
0.985±0.003
0.979±0.001
0.979±0.001

0.512±0.080
0.543±0.079
0.574±0.080
0.506±0.079
0.520±0.080
0.502±0.081
0.465±0.081
0.477±0.085
0.411±0.080
0.434±0.076
0.549±0.075
0.482±0.080
0.419±0.081
0.403±0.075
0.433±0.077
0.496±0.075
0.484±0.078
0.475±0.079
0.254±0.066
0.216±0.060
0.395±0.073
0.256±0.065
0.196±0.052
0.049±0.014
0.047±0.016

0.102
0.042
0.036
0.039
0.037
0.101
0.042
0.037
0.039
0.037
0.100
0.042
0.037
0.039
0.037
0.101
0.042
0.037
0.039
0.037
0.102
0.042
0.036
0.039
0.037

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Open Category Detection with PAC Guarantees

Table 2. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 95%, iForest

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

275039
1474209
2462157
6171393
9309633
27589
243154
307512
1356124
1553411
28043
109029
157112
1232102
861861
8666
121266
177212
581132
776090
6349
56529
111994
292413
379279

0.710±0.033
0.862±0.019
0.884±0.015
0.911±0.010
0.918±0.010
0.826±0.027
0.920±0.010
0.923±0.009
0.943±0.005
0.945±0.005
0.906±0.016
0.933±0.009
0.934±0.006
0.949±0.004
0.951±0.003
0.929±0.012
0.953±0.006
0.949±0.004
0.949±0.002
0.949±0.002
0.952±0.006
0.951±0.003
0.951±0.002
0.950 ±0.001
0.950 ±0.001

0.033±0.027
0.033±0.024
0.030±0.024
0.039±0.030
0.054±0.032
0.082±0.035
0.035±0.020
0.022±0.011
0.040±0.028
0.024±0.009
0.101±0.033
0.055±0.032
0.017±0.006
0.027±0.018
0.027±0.016
0.126±0.042
0.054±0.025
0.018±0.004
0.014±0.001
0.014±0.001
0.084±0.021
0.018±0.002
0.013±0.001
0.014± 0.000
0.014± 0.000

0.052
0.015
0.012
0.014
0.014
0.051
0.015
0.012
0.014
0.014
0.050
0.015
0.012
0.014
0.014
0.051
0.015
0.012
0.014
0.014
0.052
0.015
0.012
0.014
0.014

0.929±0.029
0.972±0.016
0.978±0.010
0.982±0.008
0.981±0.008
0.947±0.022
0.975±0.009
0.966±0.010
0.973±0.007
0.972±0.006
0.969±0.013
0.974±0.008
0.969±0.007
0.967±0.006
0.964±0.005
0.963±0.013
0.977±0.006
0.968±0.006
0.953±0.003
0.952±0.003
0.966±0.007
0.954±0.004
0.952±0.002
0.950±0.001
0.950± 0.001

0.509±0.080
0.533±0.079
0.557±0.081
0.496±0.080
0.495±0.081
0.489±0.081
0.440±0.079
0.420±0.084
0.351±0.079
0.314±0.074
0.511±0.077
0.397±0.078
0.313±0.075
0.194±0.061
0.192±0.063
0.428±0.073
0.360±0.075
0.273±0.072
0.039±0.024
0.042±0.028
0.262±0.061
0.038±0.021
0.014±0.001
0.014±0.000
0.014±0.000

0.052
0.015
0.012
0.014
0.014
0.051
0.015
0.012
0.014
0.014
0.050
0.015
0.012
0.014
0.014
0.051
0.015
0.012
0.014
0.014
0.052
0.015
0.012
0.014
0.014

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Open Category Detection with PAC Guarantees

Table 3. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 90%, iForest

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

331513
2340744
3222506
5918805
12543171
37658
403920
482922
2307205
2629242
39085
139647
156669
1867515
1232102
6481
63235
153077
397467
1088542
4400
22825
44373
229795
374065

0.710±0.033
0.862±0.019
0.859±0.014
0.869±0.011
0.884±0.010
0.826±0.027
0.893±0.011
0.888±0.010
0.901±0.006
0.898±0.005
0.879±0.017
0.900±0.010
0.888±0.008
0.902±0.003
0.900± 0.003
0.881±0.017
0.909±0.007
0.902±0.004
0.898±0.002
0.899±0.002
0.912±0.008
0.904±0.004
0.903±0.003
0.900±0.001
0.900± 0.001

0.033±0.027
0.033±0.024
0.011±0.008
0.012±0.017
0.012±0.009
0.081±0.034
0.02 ±0.015
0.015±0.011
0.007±0.004
0.005±0.001
0.059±0.021
0.019±0.014
0.005±0.001
0.004±0.000
0.005±0.000
0.060±0.022
0.010±0.003
0.005±0.000
0.003±0.000
0.005±0.000
0.038±0.005
0.006±0.000
0.004±0.000
0.004±0.000
0.005±0.000

0.026
0.005
0.004
0.004
0.005
0.026
0.006
0.004
0.004
0.005
0.025
0.005
0.004
0.003
0.005
0.026
0.005
0.004
0.004
0.005
0.026
0.005
0.004
0.004
0.005

0.929±0.029
0.970±0.016
0.976±0.011
0.976±0.01
0.971±0.011
0.936±0.024
0.960±0.012
0.945±0.014
0.939±0.011
0.923±0.009
0.957±0.016
0.944±0.013
0.925±0.012
0.911±0.006
0.903±0.004
0.942±0.016
0.937±0.010
0.913±0.007
0.898±0.002
0.900± 0.002
0.920±0.010
0.904±0.004
0.903±0.003
0.900±0.001
0.900±0.001

0.509±0.080
0.517±0.078
0.542±0.081
0.476±0.079
0.458±0.080
0.468±0.081
0.372±0.075
0.381±0.082
0.228±0.070
0.139±0.056
0.463±0.076
0.297±0.073
0.166±0.058
0.060 ±0.039
0.016±0.015
0.359±0.072
0.170±0.057
0.066±0.040
0.004±0.000
0.005±0.000
0.107±0.042
0.006±0.000
0.004±0.000
0.004±0.000
0.005±0.000

0.026
0.005
0.004
0.004
0.005
0.026
0.006
0.004
0.004
0.005
0.025
0.005
0.004
0.003
0.005
0.026
0.005
0.004
0.004
0.005
0.026
0.005
0.004
0.004
0.005

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Open Category Detection with PAC Guarantees

Table 4. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 98%, bootstrap
LODA

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

188760
1065490
1891769
5874989
8907859
17905
177557
340061
2051058
2362910
13692
79982
191346
1069912
2042503
7818
54275
121904
612305
922499
4604
25350
101036
431535
615923

0.719±0.048
0.872±0.022
0.899±0.016
0.942±0.010
0.954±0.008
0.842±0.031
0.940±0.011
0.952±0.008
0.971±0.004
0.975±0.004
0.933±0.017
0.955±0.008
0.967±0.005
0.977±0.003
0.980±0.003
0.949±0.013
0.970±0.005
0.977±0.004
0.980±0.002
0.980±0.002
0.973±0.006
0.980±0.003
0.981±0.002
0.980±0.001
0.980±0.001

0.095±0.039
0.083±0.038
0.060±0.031
0.067±0.030
0.069±0.027
0.165±0.051
0.118±0.043
0.090±0.035
0.089±0.034
0.079±0.027
0.213±0.046
0.097±0.037
0.070±0.023
0.072±0.028
0.087±0.030
0.257±0.057
0.125±0.039
0.102±0.031
0.059±0.015
0.073±0.030
0.223±0.042
0.093±0.024
0.065±0.014
0.037±0.002
0.034±0.002

0.135
0.048
0.041
0.034
0.033
0.132
0.049
0.041
0.034
0.034
0.142
0.049
0.041
0.034
0.034
0.131
0.048
0.040
0.034
0.034
0.135
0.049
0.041
0.034
0.034

0.972±0.017
0.974±0.013
0.980±0.009
0.988±0.005
0.990±0.005
0.942±0.024
0.983±0.007
0.980±0.007
0.988±0.004
0.989±0.003
0.977±0.011
0.984±0.006
0.985±0.005
0.989±0.003
0.990±0.003
0.970±0.010
0.987±0.004
0.992±0.003
0.986±0.003
0.986±0.002
0.983±0.005
0.986±0.003
0.986±0.002
0.981±0.001
0.980±0.001

0.569±0.073
0.491±0.079
0.511±0.078
0.447±0.078
0.444±0.075
0.498±0.077
0.430±0.073
0.462±0.081
0.384±0.076
0.360±0.070
0.537±0.070
0.456±0.077
0.402±0.076
0.351±0.070
0.342±0.070
0.481±0.076
0.451±0.076
0.462±0.075
0.217±0.058
0.215±0.057
0.422±0.067
0.258±0.061
0.177±0.047
0.047±0.013
0.038±0.006

0.135
0.048
0.041
0.034
0.033
0.132
0.049
0.041
0.034
0.034
0.142
0.049
0.041
0.034
0.034
0.131
0.048
0.040
0.034
0.034
0.135
0.049
0.041
0.034
0.034

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Open Category Detection with PAC Guarantees

Table 5. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 95%, bootstrap
LODA

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

206671
1330996
2559525
7369343
8307313
20685
175626
463720
3619299
2934537
17884
85131
142860
1578820
2255301
11831
65192
174441
802440
2068150
5099
30120
80278
465368
686935

0.719±0.048
0.872±0.022
0.899±0.016
0.933±0.010
0.943±0.009
0.841±0.031
0.921±0.013
0.940±0.009
0.952±0.005
0.956±0.004
0.929±0.017
0.940±0.009
0.943±0.007
0.955±0.004
0.957±0.003
0.940±0.013
0.955±0.007
0.956±0.005
0.952±0.002
0.952±0.001
0.954±0.007
0.953±0.003
0.952±0.002
0.951±0.001
0.950±0.001

0.095±0.039
0.083±0.038
0.060±0.031
0.052±0.023
0.059±0.025
0.164±0.050
0.092±0.038
0.057±0.026
0.038±0.022
0.024±0.007
0.205±0.046
0.083±0.036
0.039±0.014
0.029±0.018
0.022±0.009
0.204±0.049
0.077±0.029
0.041±0.018
0.013±0.002
0.011±0.001
0.123±0.022
0.025±0.003
0.017±0.001
0.011±0.000
0.011±0.000

0.077
0.020
0.015
0.011
0.010
0.076
0.020
0.015
0.011
0.010
0.083
0.020
0.015
0.011
0.010
0.075
0.020
0.015
0.011
0.010
0.078
0.020
0.015
0.011
0.010

0.972±0.017
0.974±0.013
0.978±0.010
0.985±0.006
0.987±0.006
0.939±0.025
0.978±0.009
0.973±0.009
0.978±0.005
0.976±0.005
0.976±0.011
0.976±0.008
0.973±0.008
0.971±0.005
0.967±0.005
0.964±0.012
0.979±0.006
0.975±0.006
0.956±0.003
0.954±0.002
0.971±0.007
0.956±0.004
0.952±0.002
0.951±0.001
0.950±0.001

0.566±0.073
0.487±0.078
0.505±0.079
0.442±0.078
0.413±0.074
0.487±0.075
0.392±0.070
0.410±0.079
0.308±0.072
0.246±0.063
0.530±0.070
0.376±0.074
0.304±0.072
0.175±0.057
0.146±0.053
0.441±0.073
0.352±0.070
0.271±0.066
0.041±0.025
0.031±0.023
0.325±0.061
0.049±0.022
0.017±0.001
0.011±0.000
0.011±0.000

0.077
0.020
0.015
0.011
0.010
0.076
0.020
0.015
0.011
0.010
0.083
0.020
0.015
0.011
0.010
0.075
0.020
0.015
0.011
0.010
0.078
0.020
0.015
0.011
0.010

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Open Category Detection with PAC Guarantees

Table 6. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 90%, bootstrap
LODA

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

242739
2059638
3398545
9739214
11575949
27002
255234
426176
2440377
4972658
18177
123537
140581
2329443
2968332
9199
59467
178906
786472
1349754
13581
13945
96151
227331
537171

0.719±0.048
0.872±0.022
0.863±0.017
0.900±0.013
0.911±0.012
0.841±0.031
0.892±0.014
0.900±0.011
0.914±0.006
0.907±0.005
0.898±0.020
0.910±0.011
0.897±0.009
0.906±0.003
0.905±0.003
0.915±0.016
0.914±0.008
0.911±0.005
0.901±0.002
0.901±0.001
0.921±0.008
0.902±0.004
0.904±0.003
0.900±0.001
0.901±0.001

0.095±0.039
0.082±0.038
0.033±0.020
0.032±0.019
0.030±0.016
0.157±0.048
0.058±0.033
0.018±0.009
0.010±0.005
0.004±0.001
0.152±0.040
0.049±0.027
0.013±0.006
0.004±0.000
0.003±0.000
0.149±0.043
0.021±0.014
0.008±0.001
0.004±0.000
0.003±0.000
0.067±0.010
0.009±0.001
0.006±0.000
0.003±0.000
0.003±0.000

0.045
0.008
0.006
0.003
0.003
0.044
0.008
0.006
0.003
0.003
0.049
0.008
0.006
0.003
0.003
0.043
0.008
0.006
0.003
0.003
0.045
0.008
0.006
0.003
0.003

0.972±0.017
0.969±0.015
0.973±0.012
0.981±0.007
0.980±0.009
0.936±0.026
0.964±0.013
0.957±0.012
0.945±0.009
0.933±0.009
0.969±0.013
0.954±0.012
0.936±0.012
0.915±0.006
0.908±0.004
0.953±0.014
0.942±0.010
0.923±0.008
0.901±0.002
0.901±0.001
0.934±0.009
0.902±0.004
0.904±0.003
0.900±0.001
0.901±0.001

0.564±0.073
0.484±0.079
0.487±0.079
0.411±0.076
0.359±0.072
0.460±0.074
0.359±0.070
0.365±0.077
0.188±0.063
0.130±0.052
0.487±0.070
0.303±0.069
0.175±0.057
0.053±0.033
0.014±0.016
0.393±0.071
0.189±0.059
0.078±0.039
0.004±0.000
0.003±0.000
0.148±0.042
0.009±0.001
0.006±0.000
0.003±0.000
0.003±0.000

0.045
0.008
0.006
0.003
0.003
0.044
0.008
0.006
0.003
0.003
0.049
0.008
0.006
0.003
0.003
0.043
0.008
0.006
0.003
0.003
0.045
0.008
0.006
0.003
0.003

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Table 7. 1st quartile, median, 3rd quartile of false positive rate from experiments using 9-dimensional normal data, 95%, Iforest

Open Category Detection with PAC Guarantees

Basic CDF
False Positive Rate

n 1st quartile median

3rd quartile Oracle(median)

α

0.01

0.05

0.1

0.2

0.5

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

0.004
0.002
0.002
0.002
0.003
0.006
0.004
0.004
0.006
0.008
0.015
0.006
0.005
0.009
0.011
0.025
0.010
0.008
0.010
0.012
0.040
0.012
0.011
0.013
0.013

0.006
0.004
0.004
0.004
0.006
0.014
0.008
0.008
0.010
0.011
0.032
0.012
0.009
0.013
0.014
0.043
0.018
0.011
0.013
0.013
0.058
0.016
0.012
0.014
0.014

0.014
0.015
0.010
0.013
0.014
0.043
0.023
0.015
0.020
0.019
0.094
0.021
0.014
0.020
0.017
0.105
0.031
0.018
0.015
0.015
0.090
0.021
0.016
0.016
0.015

0.051
0.015
0.012
0.014
0.014
0.050
0.015
0.012
0.014
0.014
0.049
0.015
0.012
0.014
0.014
0.049
0.015
0.012
0.014
0.014
0.051
0.015
0.012
0.014
0.014

Open Category Detection with PAC Guarantees

Table 8. Recall (i.e. alien detection rate) & False Positive Rate for Image Datasets,98%

Dataset

α

ˆα

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Tiny Image Net
n=10000

MNIST
n=11154

Tiny Image Net
n=10000

MNIST
n=11154

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.926 ± 0.014
0.933 ± 0.013
0.941 ± 0.012
0.965 ± 0.005
0.970 ± 0.004
0.977 ± 0.004
0.976 ± 0.003
0.982 ± 0.002
0.987 ± 0.002

0.981 ± 0.006
0.987 ± 0.005
0.991 ± 0.004
0.983 ± 0.004
0.990 ± 0.003
0.997 ± 0.001
0.983 ± 0.003
0.993 ± 0.002
0.999 ± 0.001

0.677 ± 0.030
0.695 ± 0.030
0.715 ± 0.029
0.738 ± 0.018
0.761 ± 0.018
0.787 ± 0.017
0.766 ± 0.011
0.793 ± 0.011
0.822 ± 0.010

0.466 ± 0.041
0.518 ± 0.044
0.573 ± 0.049
0.444 ± 0.030
0.511 ± 0.037
0.610 ± 0.038
0.416 ± 0.014
0.504 ± 0.024
0.655 ± 0.030

0.944 ± 0.013
0.952 ± 0.012
0.959 ± 0.011
0.972 ± 0.005
0.977 ± 0.004
0.983 ± 0.003
0.978 ± 0.003
0.983 ± 0.002
0.988 ± 0.002

0.987 ± 0.006
0.991 ± 0.005
0.994 ± 0.003
0.986 ± 0.004
0.992 ± 0.003
0.998 ± 0.001
0.983 ± 0.003
0.993 ± 0.002
0.999 ± 0.001

0.746 ± 0.034
0.766 ± 0.033
0.786 ± 0.031
0.774 ± 0.021
0.798 ± 0.019
0.825 ± 0.018
0.776 ± 0.012
0.802 ± 0.011
0.833 ± 0.010

0.569 ± 0.061
0.628 ± 0.061
0.691 ± 0.060
0.483 ± 0.041
0.567 ± 0.045
0.684 ± 0.040
0.421 ± 0.015
0.519 ± 0.028
0.683 ± 0.032

0.902 ± 0.014
0.912 ± 0.014
0.923 ± 0.013
0.942 ± 0.006
0.949 ± 0.005
0.957 ± 0.005
0.948 ± 0.003
0.956 ± 0.003
0.964 ± 0.002

0.971 ± 0.007
0.977 ± 0.006
0.984 ± 0.005
0.966 ± 0.005
0.976 ± 0.004
0.986 ± 0.003
0.957 ± 0.003
0.972 ± 0.003
0.987 ± 0.002

0.620 ± 0.025
0.639 ± 0.026
0.660 ± 0.026
0.667 ± 0.016
0.683 ± 0.014
0.706 ± 0.014
0.669 ± 0.007
0.689 ± 0.007
0.714 ± 0.007

0.404 ± 0.032
0.432 ± 0.033
0.477 ± 0.036
0.361 ± 0.017
0.397 ± 0.018
0.455 ± 0.023
0.334 ± 0.005
0.373 ± 0.007
0.441 ± 0.012

0.924 ± 0.014
0.930 ± 0.014
0.939 ± 0.012
0.948 ± 0.006
0.954 ± 0.005
0.962 ± 0.005
0.949 ± 0.003
0.957 ± 0.003
0.965 ± 0.002

0.975 ± 0.007
0.982 ± 0.006
0.988 ± 0.005
0.967 ± 0.005
0.977 ± 0.004
0.988 ± 0.003
0.957 ± 0.003
0.973 ± 0.003
0.988 ± 0.002

0.686 ± 0.032
0.697 ± 0.031
0.716 ± 0.031
0.682 ± 0.016
0.700 ± 0.015
0.722 ± 0.015
0.672 ± 0.007
0.692 ± 0.007
0.718 ± 0.007

0.448 ± 0.042
0.488 ± 0.045
0.542 ± 0.048
0.368 ± 0.018
0.410 ± 0.022
0.477 ± 0.028
0.334 ± 0.005
0.375 ± 0.007
0.444 ± 0.012

Table 9. Recall (i.e. alien detection rate) & False Positive Rate for Image Datasets,95%

Dataset

α

ˆα

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Open Category Detection with PAC Guarantees

Table 10. Recall (i.e. alien detection rate) & False Positive Rate for Image Datasets,90%

Dataset

α

ˆα

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Tiny Image Net
n=10000

MNIST
n=11154

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.862 ± 0.015
0.873 ± 0.015
0.885 ± 0.014
0.894 ± 0.007
0.904 ± 0.007
0.915 ± 0.006
0.898 ± 0.003
0.907 ± 0.003
0.919 ± 0.003

0.949 ± 0.008
0.958 ± 0.007
0.967 ± 0.007
0.928 ± 0.005
0.942 ± 0.004
0.958 ± 0.004
0.912 ± 0.003
0.929 ± 0.003
0.949 ± 0.003

0.545 ± 0.021
0.562 ± 0.021
0.579 ± 0.021
0.578 ± 0.011
0.593 ± 0.010
0.609 ± 0.010
0.577 ± 0.004
0.590 ± 0.004
0.608 ± 0.004

0.328 ± 0.020
0.352 ± 0.022
0.378 ± 0.024
0.282 ± 0.006
0.306 ± 0.007
0.341 ± 0.010
0.260 ± 0.003
0.284 ± 0.003
0.317 ± 0.004

0.883 ± 0.016
0.892 ± 0.015
0.902 ± 0.014
0.898 ± 0.007
0.909 ± 0.006
0.919 ± 0.006
0.899 ± 0.003
0.908 ± 0.003
0.920 ± 0.003

0.954 ± 0.008
0.962 ± 0.007
0.971 ± 0.007
0.929 ± 0.005
0.944 ± 0.004
0.960 ± 0.004
0.912 ± 0.003
0.930 ± 0.003
0.949 ± 0.003

0.590 ± 0.027
0.602 ± 0.026
0.617 ± 0.025
0.584 ± 0.011
0.600 ± 0.011
0.617 ± 0.011
0.578 ± 0.004
0.591 ± 0.004
0.609 ± 0.004

0.342 ± 0.024
0.366 ± 0.025
0.395 ± 0.027
0.285 ± 0.007
0.309 ± 0.008
0.345 ± 0.011
0.260 ± 0.003
0.284 ± 0.003
0.317 ± 0.004

Open Category Detection with PAC Guarantees

Table 11. Recall & False Positive Rate for Landsat Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Landsat
n=1532

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.937 ± 0.024
0.949 ± 0.024
0.960 ± 0.024
0.965 ± 0.005
0.980 ± 0.003
0.989 ± 0.002
0.971 ± 0.013
0.985 ± 0.012
0.991 ± 0.012

0.924 ± 0.024
0.936 ± 0.024
0.950 ± 0.024
0.942 ± 0.006
0.964 ± 0.004
0.981 ± 0.003
0.948 ± 0.013
0.969 ± 0.012
0.986 ± 0.012

0.888 ± 0.025
0.906 ± 0.024
0.927 ± 0.024
0.902 ± 0.007
0.928 ± 0.005
0.953 ± 0.005
0.899 ± 0.012
0.927 ± 0.012
0.957 ± 0.012

0.162 ± 0.047
0.203 ± 0.048
0.255 ± 0.050
0.128 ± 0.033
0.204 ± 0.040
0.301 ± 0.047
0.114 ± 0.021
0.267 ± 0.033
0.480 ± 0.039

0.127 ± 0.041
0.157 ± 0.044
0.202 ± 0.047
0.069 ± 0.020
0.112 ± 0.027
0.201 ± 0.039
0.046 ± 0.008
0.095 ± 0.015
0.250 ± 0.029

0.089 ± 0.036
0.106 ± 0.038
0.136 ± 0.041
0.034 ± 0.008
0.047 ± 0.012
0.076 ± 0.018
0.029 ± 0.008
0.035 ± 0.008
0.055 ± 0.008

0.960 ± 0.024
0.967 ± 0.024
0.972 ± 0.024
0.983 ± 0.005
0.991 ± 0.003
0.996 ± 0.001
0.981 ± 0.013
0.989 ± 0.012
0.993 ± 0.012

0.952 ± 0.025
0.959 ± 0.024
0.966 ± 0.024
0.964 ± 0.006
0.980 ± 0.004
0.991 ± 0.002
0.952 ± 0.013
0.976 ± 0.012
0.989 ± 0.012

0.924 ± 0.025
0.938 ± 0.025
0.953 ± 0.025
0.918 ± 0.009
0.941 ± 0.007
0.966 ± 0.005
0.899 ± 0.012
0.927 ± 0.012
0.960 ± 0.012

0.495 ± 0.068
0.543 ± 0.064
0.583 ± 0.062
0.404 ± 0.062
0.478 ± 0.061
0.557 ± 0.057
0.323 ± 0.055
0.491 ± 0.051
0.658 ± 0.041

0.430 ± 0.067
0.463 ± 0.065
0.506 ± 0.064
0.271 ± 0.057
0.337 ± 0.056
0.425 ± 0.055
0.094 ± 0.028
0.209 ± 0.038
0.385 ± 0.041

0.323 ± 0.064
0.345 ± 0.064
0.380 ± 0.063
0.115 ± 0.037
0.151 ± 0.040
0.216 ± 0.044
0.030 ± 0.008
0.036 ± 0.008
0.076 ± 0.015

Open Category Detection with PAC Guarantees

Table 12. Recall & False Positive Rate for page.blocks Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

pageblocks
n=4912

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.963 ± 0.021
0.969 ± 0.017
0.976 ± 0.013
0.966 ± 0.005
0.978 ± 0.004
0.989 ± 0.003
0.971 ± 0.004
0.986 ± 0.002
0.994 ± 0.001

0.945 ± 0.031
0.958 ± 0.024
0.967 ± 0.018
0.945 ± 0.007
0.963 ± 0.005
0.978 ± 0.004
0.945 ± 0.004
0.966 ± 0.003
0.985 ± 0.002

0.908 ± 0.027
0.928 ± 0.021
0.947 ± 0.022
0.899 ± 0.007
0.922 ± 0.007
0.946 ± 0.006
0.901 ± 0.005
0.922 ± 0.004
0.948 ± 0.004

0.254 ± 0.084
0.315 ± 0.138
0.357 ± 0.137
0.287 ± 0.031
0.367 ± 0.038
0.468 ± 0.041
0.261 ± 0.028
0.384 ± 0.035
0.531 ± 0.038

0.218 ± 0.070
0.259 ± 0.100
0.304 ± 0.117
0.204 ± 0.019
0.258 ± 0.025
0.338 ± 0.031
0.173 ± 0.012
0.228 ± 0.020
0.339 ± 0.027

0.153 ± 0.030
0.187 ± 0.049
0.222 ± 0.071
0.139 ± 0.007
0.161 ± 0.010
0.201 ± 0.016
0.125 ± 0.004
0.143 ± 0.005
0.174 ± 0.008

0.983 ± 0.013
0.991 ± 0.006
0.995 ± 0.004
0.978 ± 0.005
0.987 ± 0.003
0.994 ± 0.002
0.980 ± 0.004
0.991 ± 0.002
0.996 ± 0.001

0.964 ± 0.029
0.975 ± 0.018
0.985 ± 0.012
0.955 ± 0.007
0.972 ± 0.005
0.985 ± 0.004
0.950 ± 0.005
0.972 ± 0.004
0.989 ± 0.002

0.939 ± 0.027
0.943 ± 0.024
0.959 ± 0.023
0.905 ± 0.008
0.929 ± 0.007
0.954 ± 0.006
0.903 ± 0.005
0.924 ± 0.004
0.951 ± 0.004

0.555 ± 0.201
0.624 ± 0.181
0.712 ± 0.159
0.452 ± 0.053
0.529 ± 0.050
0.626 ± 0.045
0.411 ± 0.048
0.532 ± 0.047
0.655 ± 0.043

0.419 ± 0.210
0.458 ± 0.201
0.551 ± 0.185
0.291 ± 0.040
0.362 ± 0.042
0.448 ± 0.043
0.217 ± 0.029
0.303 ± 0.034
0.423 ± 0.036

0.245 ± 0.105
0.253 ± 0.102
0.305 ± 0.119
0.162 ± 0.017
0.190 ± 0.020
0.243 ± 0.026
0.127 ± 0.005
0.148 ± 0.008
0.190 ± 0.013

Open Category Detection with PAC Guarantees

Table 13. Recall & False Positive Rate for Optical.digits Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Optical.digits
n=568

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.898 ± 0.016
0.906 ± 0.013
0.917 ± 0.013
0.938 ± 0.011
0.953 ± 0.008
0.968 ± 0.007
0.966 ± 0.006
0.979 ± 0.004
0.989 ± 0.003

0.887 ± 0.016
0.892 ± 0.014
0.906 ± 0.013
0.924 ± 0.011
0.936 ± 0.009
0.955 ± 0.008
0.946 ± 0.006
0.964 ± 0.005
0.980 ± 0.004

0.840 ± 0.021
0.866 ± 0.015
0.879 ± 0.014
0.883 ± 0.013
0.905 ± 0.010
0.926 ± 0.010
0.904 ± 0.007
0.925 ± 0.006
0.951 ± 0.006

0.167 ± 0.035
0.186 ± 0.036
0.214 ± 0.036
0.177 ± 0.033
0.220 ± 0.039
0.270 ± 0.041
0.254 ± 0.041
0.339 ± 0.045
0.439 ± 0.048

0.146 ± 0.033
0.166 ± 0.033
0.188 ± 0.034
0.135 ± 0.025
0.165 ± 0.029
0.212 ± 0.034
0.149 ± 0.024
0.219 ± 0.031
0.319 ± 0.040

0.119 ± 0.029
0.132 ± 0.031
0.151 ± 0.032
0.080 ± 0.012
0.104 ± 0.018
0.138 ± 0.024
0.072 ± 0.006
0.096 ± 0.009
0.150 ± 0.019

0.947 ± 0.016
0.950 ± 0.013
0.957 ± 0.012
0.964 ± 0.010
0.973 ± 0.008
0.983 ± 0.006
0.978 ± 0.006
0.986 ± 0.004
0.994 ± 0.002

0.948 ± 0.015
0.944 ± 0.014
0.952 ± 0.013
0.954 ± 0.010
0.963 ± 0.009
0.974 ± 0.007
0.959 ± 0.007
0.974 ± 0.006
0.986 ± 0.004

0.910 ± 0.021
0.928 ± 0.016
0.937 ± 0.015
0.916 ± 0.015
0.936 ± 0.011
0.953 ± 0.010
0.916 ± 0.009
0.936 ± 0.008
0.960 ± 0.006

0.502 ± 0.070
0.519 ± 0.066
0.549 ± 0.065
0.434 ± 0.065
0.466 ± 0.063
0.511 ± 0.061
0.441 ± 0.061
0.517 ± 0.058
0.606 ± 0.053

0.459 ± 0.068
0.481 ± 0.066
0.504 ± 0.065
0.342 ± 0.059
0.381 ± 0.059
0.432 ± 0.060
0.290 ± 0.049
0.356 ± 0.049
0.443 ± 0.049

0.403 ± 0.067
0.413 ± 0.065
0.430 ± 0.065
0.237 ± 0.050
0.264 ± 0.050
0.300 ± 0.050
0.129 ± 0.026
0.168 ± 0.031
0.233 ± 0.036

Open Category Detection with PAC Guarantees

Table 14. Recall & False Positive Rate for Letter Recognition Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Letter recognition
n=788

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.897 ± 0.018
0.918 ± 0.013
0.931 ± 0.012
0.940 ± 0.011
0.954 ± 0.008
0.969 ± 0.006
0.968 ± 0.006
0.983 ± 0.004
0.993 ± 0.003

0.885 ± 0.020
0.904 ± 0.015
0.919 ± 0.013
0.912 ± 0.013
0.934 ± 0.010
0.954 ± 0.008
0.946 ± 0.006
0.967 ± 0.005
0.984 ± 0.004

0.857 ± 0.020
0.875 ± 0.017
0.892 ± 0.016
0.875 ± 0.014
0.900 ± 0.011
0.923 ± 0.010
0.901 ± 0.007
0.925 ± 0.006
0.953 ± 0.005

0.232 ± 0.044
0.255 ± 0.045
0.291 ± 0.047
0.197 ± 0.032
0.235 ± 0.035
0.281 ± 0.039
0.242 ± 0.029
0.335 ± 0.038
0.448 ± 0.044

0.205 ± 0.042
0.223 ± 0.041
0.252 ± 0.043
0.156 ± 0.024
0.188 ± 0.027
0.229 ± 0.034
0.147 ± 0.012
0.208 ± 0.020
0.306 ± 0.032

0.152 ± 0.031
0.172 ± 0.033
0.197 ± 0.036
0.111 ± 0.016
0.132 ± 0.018
0.158 ± 0.022
0.099 ± 0.004
0.117 ± 0.005
0.155 ± 0.010

0.953 ± 0.016
0.967 ± 0.010
0.975 ± 0.008
0.964 ± 0.011
0.974 ± 0.007
0.983 ± 0.006
0.977 ± 0.006
0.989 ± 0.003
0.996 ± 0.002

0.949 ± 0.015
0.958 ± 0.012
0.965 ± 0.010
0.944 ± 0.013
0.960 ± 0.009
0.973 ± 0.008
0.956 ± 0.007
0.974 ± 0.005
0.988 ± 0.004

0.929 ± 0.018
0.939 ± 0.016
0.949 ± 0.014
0.905 ± 0.015
0.928 ± 0.012
0.950 ± 0.010
0.906 ± 0.008
0.932 ± 0.006
0.959 ± 0.006

0.596 ± 0.069
0.613 ± 0.067
0.633 ± 0.065
0.457 ± 0.066
0.490 ± 0.063
0.537 ± 0.061
0.430 ± 0.056
0.525 ± 0.055
0.639 ± 0.049

0.550 ± 0.069
0.570 ± 0.066
0.587 ± 0.065
0.375 ± 0.060
0.407 ± 0.059
0.455 ± 0.059
0.245 ± 0.039
0.334 ± 0.043
0.432 ± 0.046

0.473 ± 0.067
0.490 ± 0.066
0.519 ± 0.066
0.236 ± 0.045
0.280 ± 0.048
0.326 ± 0.051
0.110 ± 0.008
0.145 ± 0.015
0.203 ± 0.023

Open Category Detection with PAC Guarantees

Table 15. Recall & False Positive Rate for Shuttle Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Shuttle
n=5000

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.959 ± 0.008
0.971 ± 0.006
0.984 ± 0.005
0.975 ± 0.004
0.990 ± 0.002
0.998 ± 0.001
0.980 ± 0.002
0.996 ± 0.001
1.000 ± 0.000

0.937 ± 0.009
0.958 ± 0.007
0.974 ± 0.006
0.949 ± 0.005
0.973 ± 0.004
0.992 ± 0.002
0.949 ± 0.002
0.976 ± 0.002
0.997 ± 0.001

0.901 ± 0.012
0.923 ± 0.010
0.947 ± 0.008
0.903 ± 0.004
0.928 ± 0.004
0.958 ± 0.004
0.899 ± 0.002
0.925 ± 0.002
0.959 ± 0.002

0.145 ± 0.031
0.205 ± 0.038
0.287 ± 0.048
0.100 ± 0.016
0.195 ± 0.033
0.355 ± 0.042
0.090 ± 0.014
0.238 ± 0.028
0.540 ± 0.032

0.095 ± 0.017
0.137 ± 0.027
0.200 ± 0.036
0.064 ± 0.004
0.093 ± 0.011
0.186 ± 0.028
0.061 ± 0.001
0.082 ± 0.006
0.220 ± 0.022

0.056 ± 0.006
0.072 ± 0.010
0.105 ± 0.019
0.047 ± 0.001
0.054 ± 0.002
0.068 ± 0.004
0.047 ± 0.001
0.054 ± 0.001
0.065 ± 0.001

0.973 ± 0.007
0.984 ± 0.006
0.991 ± 0.003
0.982 ± 0.004
0.994 ± 0.002
0.999 ± 0.001
0.982 ± 0.002
0.997 ± 0.001
1.000 ± 0.000

0.957 ± 0.009
0.972 ± 0.007
0.983 ± 0.005
0.956 ± 0.006
0.979 ± 0.004
0.995 ± 0.002
0.949 ± 0.002
0.977 ± 0.002
0.998 ± 0.001

0.917 ± 0.013
0.939 ± 0.011
0.960 ± 0.009
0.905 ± 0.004
0.931 ± 0.005
0.963 ± 0.004
0.899 ± 0.002
0.925 ± 0.002
0.959 ± 0.002

0.425 ± 0.065
0.490 ± 0.065
0.550 ± 0.064
0.317 ± 0.058
0.451 ± 0.058
0.578 ± 0.052
0.154 ± 0.031
0.396 ± 0.042
0.642 ± 0.034

0.326 ± 0.059
0.370 ± 0.059
0.435 ± 0.059
0.142 ± 0.034
0.224 ± 0.043
0.365 ± 0.045
0.061 ± 0.001
0.104 ± 0.016
0.290 ± 0.028

0.187 ± 0.047
0.216 ± 0.047
0.266 ± 0.049
0.048 ± 0.002
0.064 ± 0.008
0.111 ± 0.020
0.047 ± 0.001
0.054 ± 0.001
0.066 ± 0.001

Open Category Detection with PAC Guarantees

Table 16. Recall & False Positive Rate for Covertype Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Covertype
n=13624

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.979 ± 0.002
0.995 ± 0.001
0.999 ± 0.000
0.980 ± 0.001
0.998 ± 0.000
1.000 ± 0.000
0.981 ± 0.001
0.998 ± 0.000
1.000 ± 0.000

0.951 ± 0.002
0.978 ± 0.001
0.997 ± 0.001
0.951 ± 0.001
0.979 ± 0.001
0.999 ± 0.000
0.952 ± 0.001
0.980 ± 0.001
0.999 ± 0.000

0.900 ± 0.003
0.930 ± 0.001
0.965 ± 0.001
0.901 ± 0.002
0.929 ± 0.001
0.965 ± 0.001
0.901 ± 0.002
0.929 ± 0.001
0.965 ± 0.001

0.010 ± 0.003
0.098 ± 0.025
0.292 ± 0.045
0.007 ± 0.002
0.142 ± 0.026
0.423 ± 0.044
0.009 ± 0.001
0.212 ± 0.029
0.560 ± 0.037

0.002 ± 0.000
0.012 ± 0.004
0.112 ± 0.026
0.003 ± 0.000
0.008 ± 0.002
0.153 ± 0.025
0.006 ± 0.000
0.012 ± 0.002
0.199 ± 0.023

0.002 ± 0.000
0.002 ± 0.000
0.004 ± 0.001
0.002 ± 0.000
0.002 ± 0.000
0.004 ± 0.000
0.005 ± 0.000
0.005 ± 0.000
0.007 ± 0.000

0.989 ± 0.002
0.998 ± 0.001
0.999 ± 0.000
0.987 ± 0.002
0.999 ± 0.000
1.000 ± 0.000
0.984 ± 0.002
0.999 ± 0.000
1.000 ± 0.000

0.963 ± 0.004
0.987 ± 0.002
0.998 ± 0.000
0.952 ± 0.002
0.983 ± 0.001
1.000 ± 0.000
0.952 ± 0.001
0.981 ± 0.001
1.000 ± 0.000

0.904 ± 0.004
0.937 ± 0.004
0.973 ± 0.003
0.901 ± 0.002
0.929 ± 0.001
0.965 ± 0.001
0.901 ± 0.002
0.929 ± 0.001
0.965 ± 0.001

0.373 ± 0.072
0.470 ± 0.066
0.586 ± 0.059
0.220 ± 0.056
0.419 ± 0.057
0.618 ± 0.047
0.134 ± 0.044
0.438 ± 0.050
0.676 ± 0.036

0.164 ± 0.051
0.277 ± 0.059
0.411 ± 0.060
0.017 ± 0.016
0.114 ± 0.035
0.319 ± 0.045
0.006 ± 0.000
0.050 ± 0.015
0.307 ± 0.034

0.025 ± 0.019
0.055 ± 0.029
0.121 ± 0.038
0.002 ± 0.000
0.002 ± 0.000
0.011 ± 0.004
0.005 ± 0.000
0.005 ± 0.000
0.008 ± 0.001

Open Category Detection with PAC Guarantees

Table 17. Recall & False Positive Rate for Landsat Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Landsat
n=1532

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.941 ± 0.024
0.950 ± 0.024
0.960 ± 0.024
0.965 ± 0.005
0.979 ± 0.003
0.989 ± 0.002
0.970 ± 0.012
0.985 ± 0.012
0.991 ± 0.012

0.923 ± 0.024
0.936 ± 0.024
0.951 ± 0.024
0.945 ± 0.006
0.964 ± 0.004
0.980 ± 0.003
0.949 ± 0.012
0.969 ± 0.012
0.986 ± 0.012

0.887 ± 0.024
0.906 ± 0.024
0.926 ± 0.024
0.903 ± 0.007
0.927 ± 0.005
0.952 ± 0.005
0.901 ± 0.012
0.926 ± 0.012
0.957 ± 0.012

0.164 ± 0.045
0.197 ± 0.048
0.254 ± 0.051
0.130 ± 0.033
0.199 ± 0.040
0.304 ± 0.048
0.109 ± 0.018
0.266 ± 0.034
0.477 ± 0.039

0.130 ± 0.042
0.161 ± 0.045
0.204 ± 0.047
0.074 ± 0.022
0.117 ± 0.029
0.198 ± 0.037
0.044 ± 0.007
0.094 ± 0.015
0.253 ± 0.029

0.088 ± 0.036
0.107 ± 0.038
0.135 ± 0.041
0.032 ± 0.005
0.047 ± 0.012
0.075 ± 0.018
0.030 ± 0.008
0.034 ± 0.008
0.054 ± 0.008

0.964 ± 0.025
0.968 ± 0.024
0.971 ± 0.024
0.982 ± 0.004
0.991 ± 0.003
0.996 ± 0.002
0.979 ± 0.012
0.989 ± 0.012
0.993 ± 0.012

0.950 ± 0.025
0.959 ± 0.025
0.967 ± 0.024
0.965 ± 0.006
0.979 ± 0.004
0.991 ± 0.003
0.953 ± 0.012
0.976 ± 0.012
0.989 ± 0.012

0.919 ± 0.025
0.936 ± 0.025
0.953 ± 0.025
0.915 ± 0.009
0.942 ± 0.007
0.967 ± 0.005
0.901 ± 0.012
0.927 ± 0.012
0.960 ± 0.012

0.503 ± 0.066
0.545 ± 0.065
0.584 ± 0.063
0.402 ± 0.063
0.477 ± 0.060
0.556 ± 0.057
0.323 ± 0.054
0.488 ± 0.051
0.655 ± 0.042

0.423 ± 0.069
0.467 ± 0.066
0.509 ± 0.064
0.265 ± 0.056
0.332 ± 0.055
0.425 ± 0.054
0.095 ± 0.028
0.212 ± 0.038
0.386 ± 0.041

0.309 ± 0.063
0.346 ± 0.064
0.388 ± 0.063
0.110 ± 0.036
0.153 ± 0.040
0.216 ± 0.044
0.030 ± 0.008
0.037 ± 0.009
0.081 ± 0.016

Open Category Detection with PAC Guarantees

Table 18. Recall & False Positive Rate for page.blocks Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

page.blocks
n=4912

0.100
0.100
0.100

0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108

0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020

0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.951 ± 0.029
0.968 ± 0.018
0.976 ± 0.013

0.965 ± 0.005
0.979 ± 0.004
0.989 ± 0.002
0.970 ± 0.004
0.985 ± 0.002
0.995 ± 0.001

0.949 ± 0.025
0.958 ± 0.021
0.969 ± 0.018
0.946 ± 0.007
0.962 ± 0.005
0.978 ± 0.004
0.945 ± 0.005
0.966 ± 0.003
0.985 ± 0.002

0.903 ± 0.035
0.927 ± 0.025
0.951 ± 0.024
0.900 ± 0.007
0.922 ± 0.007
0.947 ± 0.006
0.900 ± 0.005
0.922 ± 0.004
0.948 ± 0.004

0.269 ± 0.106
0.314 ± 0.130
0.366 ± 0.138

0.283 ± 0.030
0.366 ± 0.037
0.465 ± 0.041
0.260 ± 0.028
0.381 ± 0.035
0.530 ± 0.039

0.239 ± 0.096
0.261 ± 0.101
0.297 ± 0.117
0.207 ± 0.019
0.258 ± 0.025
0.338 ± 0.031
0.173 ± 0.013
0.228 ± 0.019
0.339 ± 0.028

0.155 ± 0.040
0.177 ± 0.044
0.222 ± 0.068
0.138 ± 0.006
0.160 ± 0.010
0.201 ± 0.016
0.128 ± 0.004
0.143 ± 0.006
0.174 ± 0.008

0.975 ± 0.017
0.991 ± 0.007
0.994 ± 0.005

0.976 ± 0.005
0.986 ± 0.004
0.994 ± 0.002
0.978 ± 0.004
0.990 ± 0.002
0.996 ± 0.001

0.968 ± 0.022
0.975 ± 0.018
0.986 ± 0.012
0.956 ± 0.007
0.971 ± 0.005
0.984 ± 0.003
0.951 ± 0.005
0.972 ± 0.004
0.989 ± 0.002

0.927 ± 0.030
0.948 ± 0.027
0.962 ± 0.022
0.906 ± 0.008
0.930 ± 0.007
0.955 ± 0.006
0.902 ± 0.006
0.924 ± 0.004
0.951 ± 0.004

0.511 ± 0.220
0.641 ± 0.184
0.692 ± 0.175

0.443 ± 0.052
0.527 ± 0.051
0.622 ± 0.046
0.403 ± 0.049
0.531 ± 0.048
0.655 ± 0.042

0.401 ± 0.176
0.448 ± 0.189
0.529 ± 0.179
0.298 ± 0.040
0.364 ± 0.042
0.446 ± 0.042
0.215 ± 0.027
0.299 ± 0.034
0.424 ± 0.037

0.216 ± 0.111
0.248 ± 0.117
0.317 ± 0.123
0.158 ± 0.016
0.192 ± 0.020
0.246 ± 0.027
0.130 ± 0.006
0.147 ± 0.008
0.190 ± 0.014

Open Category Detection with PAC Guarantees

Table 19. Recall & False Positive Rate for Optical.digits Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Optical.digits
n=568

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.891 ± 0.018
0.904 ± 0.013
0.917 ± 0.012
0.941 ± 0.010
0.951 ± 0.008
0.965 ± 0.007
0.968 ± 0.006
0.979 ± 0.004
0.990 ± 0.003

0.882 ± 0.018
0.896 ± 0.014
0.910 ± 0.013
0.920 ± 0.012
0.938 ± 0.009
0.954 ± 0.008
0.946 ± 0.007
0.963 ± 0.005
0.979 ± 0.004

0.856 ± 0.017
0.867 ± 0.015
0.886 ± 0.014
0.883 ± 0.012
0.907 ± 0.010
0.927 ± 0.009
0.899 ± 0.008
0.926 ± 0.005
0.952 ± 0.005

0.172 ± 0.036
0.191 ± 0.036
0.214 ± 0.037
0.178 ± 0.032
0.218 ± 0.037
0.268 ± 0.040
0.250 ± 0.039
0.338 ± 0.045
0.442 ± 0.047

0.148 ± 0.033
0.164 ± 0.034
0.192 ± 0.036
0.139 ± 0.026
0.168 ± 0.030
0.211 ± 0.034
0.149 ± 0.024
0.220 ± 0.033
0.315 ± 0.039

0.113 ± 0.027
0.127 ± 0.030
0.146 ± 0.031
0.083 ± 0.014
0.106 ± 0.018
0.140 ± 0.025
0.071 ± 0.005
0.097 ± 0.009
0.151 ± 0.018

0.940 ± 0.017
0.952 ± 0.012
0.961 ± 0.011
0.964 ± 0.010
0.974 ± 0.008
0.983 ± 0.006
0.978 ± 0.006
0.986 ± 0.004
0.994 ± 0.002

0.933 ± 0.018
0.945 ± 0.013
0.952 ± 0.012
0.953 ± 0.012
0.964 ± 0.009
0.973 ± 0.008
0.960 ± 0.007
0.974 ± 0.005
0.986 ± 0.004

0.920 ± 0.018
0.928 ± 0.016
0.938 ± 0.014
0.917 ± 0.014
0.935 ± 0.011
0.953 ± 0.009
0.911 ± 0.009
0.937 ± 0.007
0.961 ± 0.006

0.504 ± 0.068
0.521 ± 0.066
0.548 ± 0.065
0.424 ± 0.065
0.465 ± 0.064
0.520 ± 0.063
0.451 ± 0.061
0.519 ± 0.058
0.608 ± 0.054

0.462 ± 0.068
0.481 ± 0.066
0.500 ± 0.065
0.365 ± 0.061
0.386 ± 0.059
0.441 ± 0.060
0.288 ± 0.050
0.357 ± 0.049
0.443 ± 0.049

0.387 ± 0.066
0.407 ± 0.065
0.433 ± 0.064
0.227 ± 0.050
0.264 ± 0.049
0.305 ± 0.050
0.123 ± 0.024
0.163 ± 0.030
0.230 ± 0.035

Open Category Detection with PAC Guarantees

Table 20. Recall & False Positive Rate for Letter Recognition Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Letter recog
n=788

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.911 ± 0.016
0.919 ± 0.013
0.931 ± 0.012
0.936 ± 0.011
0.954 ± 0.008
0.968 ± 0.007
0.971 ± 0.005
0.984 ± 0.004
0.993 ± 0.003

0.884 ± 0.019
0.903 ± 0.015
0.918 ± 0.014
0.915 ± 0.013
0.936 ± 0.009
0.955 ± 0.008
0.944 ± 0.007
0.966 ± 0.005
0.984 ± 0.004

0.862 ± 0.020
0.876 ± 0.018
0.891 ± 0.016
0.879 ± 0.013
0.899 ± 0.011
0.922 ± 0.010
0.902 ± 0.007
0.924 ± 0.006
0.951 ± 0.006

0.234 ± 0.044
0.262 ± 0.046
0.297 ± 0.048
0.203 ± 0.034
0.236 ± 0.036
0.288 ± 0.042
0.240 ± 0.029
0.334 ± 0.039
0.448 ± 0.044

0.208 ± 0.041
0.223 ± 0.041
0.252 ± 0.043
0.162 ± 0.025
0.190 ± 0.029
0.231 ± 0.034
0.152 ± 0.013
0.208 ± 0.019
0.307 ± 0.031

0.160 ± 0.034
0.174 ± 0.034
0.198 ± 0.036
0.113 ± 0.016
0.132 ± 0.019
0.160 ± 0.022
0.098 ± 0.004
0.117 ± 0.005
0.154 ± 0.010

0.960 ± 0.013
0.965 ± 0.011
0.973 ± 0.009
0.961 ± 0.011
0.975 ± 0.008
0.983 ± 0.006
0.979 ± 0.005
0.989 ± 0.003
0.996 ± 0.002

0.949 ± 0.017
0.959 ± 0.012
0.966 ± 0.011
0.943 ± 0.013
0.960 ± 0.009
0.974 ± 0.007
0.954 ± 0.007
0.974 ± 0.005
0.988 ± 0.004

0.930 ± 0.019
0.939 ± 0.016
0.951 ± 0.013
0.906 ± 0.014
0.928 ± 0.012
0.949 ± 0.010
0.907 ± 0.007
0.931 ± 0.006
0.959 ± 0.006

0.588 ± 0.070
0.603 ± 0.067
0.627 ± 0.065
0.444 ± 0.065
0.487 ± 0.064
0.534 ± 0.062
0.429 ± 0.057
0.525 ± 0.054
0.636 ± 0.048

0.552 ± 0.069
0.563 ± 0.067
0.582 ± 0.065
0.376 ± 0.062
0.410 ± 0.060
0.455 ± 0.059
0.250 ± 0.040
0.328 ± 0.042
0.435 ± 0.046

0.475 ± 0.067
0.492 ± 0.066
0.512 ± 0.065
0.238 ± 0.047
0.281 ± 0.049
0.324 ± 0.050
0.110 ± 0.009
0.139 ± 0.013
0.203 ± 0.024

Open Category Detection with PAC Guarantees

Table 21. Recall & False Positive Rate for Shuttle Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Shuttle
n=5000

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.959 ± 0.008
0.972 ± 0.006
0.984 ± 0.004
0.975 ± 0.004
0.990 ± 0.002
0.998 ± 0.001
0.979 ± 0.002
0.996 ± 0.001
1.000 ± 0.000

0.941 ± 0.009
0.957 ± 0.008
0.973 ± 0.006
0.949 ± 0.005
0.973 ± 0.004
0.992 ± 0.002
0.948 ± 0.002
0.976 ± 0.002
0.997 ± 0.001

0.899 ± 0.011
0.923 ± 0.010
0.946 ± 0.009
0.902 ± 0.005
0.928 ± 0.004
0.958 ± 0.004
0.899 ± 0.002
0.925 ± 0.002
0.958 ± 0.002

0.147 ± 0.031
0.206 ± 0.039
0.287 ± 0.047
0.103 ± 0.016
0.192 ± 0.033
0.361 ± 0.043
0.089 ± 0.013
0.237 ± 0.028
0.541 ± 0.032

0.097 ± 0.018
0.135 ± 0.027
0.202 ± 0.037
0.063 ± 0.004
0.093 ± 0.011
0.187 ± 0.028
0.060 ± 0.002
0.083 ± 0.006
0.218 ± 0.022

0.057 ± 0.005
0.073 ± 0.010
0.104 ± 0.018
0.047 ± 0.001
0.054 ± 0.001
0.069 ± 0.004
0.049 ± 0.001
0.054 ± 0.001
0.065 ± 0.001

0.974 ± 0.007
0.985 ± 0.005
0.991 ± 0.003
0.983 ± 0.004
0.994 ± 0.002
0.999 ± 0.001
0.981 ± 0.002
0.997 ± 0.001
1.000 ± 0.000

0.956 ± 0.009
0.971 ± 0.007
0.984 ± 0.005
0.957 ± 0.005
0.979 ± 0.004
0.995 ± 0.002
0.949 ± 0.002
0.977 ± 0.002
0.998 ± 0.001

0.917 ± 0.013
0.938 ± 0.011
0.960 ± 0.009
0.904 ± 0.005
0.931 ± 0.004
0.963 ± 0.004
0.899 ± 0.002
0.926 ± 0.002
0.959 ± 0.002

0.419 ± 0.066
0.490 ± 0.065
0.545 ± 0.064
0.326 ± 0.058
0.457 ± 0.058
0.572 ± 0.053
0.151 ± 0.030
0.394 ± 0.042
0.642 ± 0.034

0.319 ± 0.059
0.371 ± 0.059
0.439 ± 0.060
0.150 ± 0.035
0.221 ± 0.042
0.368 ± 0.044
0.061 ± 0.002
0.106 ± 0.016
0.291 ± 0.027

0.180 ± 0.046
0.211 ± 0.047
0.273 ± 0.050
0.048 ± 0.001
0.066 ± 0.009
0.114 ± 0.020
0.049 ± 0.001
0.054 ± 0.001
0.066 ± 0.001

Open Category Detection with PAC Guarantees

Table 22. Recall & False Positive Rate for Covertype Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Covertype
n=13624

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.979 ± 0.002
0.995 ± 0.001
0.999 ± 0.000
0.980 ± 0.001
0.998 ± 0.000
1.000 ± 0.000
0.981 ± 0.001
0.998 ± 0.000
1.000 ± 0.000

0.950 ± 0.002
0.978 ± 0.001
0.997 ± 0.001
0.950 ± 0.001
0.980 ± 0.001
0.999 ± 0.000
0.951 ± 0.001
0.980 ± 0.001
0.999 ± 0.000

0.901 ± 0.002
0.930 ± 0.001
0.965 ± 0.001
0.902 ± 0.002
0.929 ± 0.001
0.964 ± 0.001
0.903 ± 0.001
0.929 ± 0.001
0.964 ± 0.001

0.012 ± 0.007
0.095 ± 0.025
0.292 ± 0.045
0.006 ± 0.002
0.143 ± 0.027
0.427 ± 0.043
0.010 ± 0.001
0.206 ± 0.030
0.555 ± 0.038

0.002 ± 0.000
0.012 ± 0.004
0.110 ± 0.025
0.003 ± 0.000
0.008 ± 0.002
0.154 ± 0.026
0.006 ± 0.000
0.012 ± 0.002
0.200 ± 0.022

0.002 ± 0.000
0.002 ± 0.000
0.004 ± 0.001
0.002 ± 0.000
0.002 ± 0.000
0.003 ± 0.000
0.005 ± 0.000
0.005 ± 0.000
0.007 ± 0.000

0.989 ± 0.002
0.998 ± 0.001
0.999 ± 0.000
0.986 ± 0.002
0.999 ± 0.000
1.000 ± 0.000
0.985 ± 0.002
0.999 ± 0.000
1.000 ± 0.000

0.962 ± 0.004
0.987 ± 0.002
0.998 ± 0.000
0.952 ± 0.002
0.983 ± 0.001
1.000 ± 0.000
0.951 ± 0.001
0.981 ± 0.001
1.000 ± 0.000

0.905 ± 0.004
0.937 ± 0.004
0.973 ± 0.003
0.902 ± 0.002
0.929 ± 0.001
0.965 ± 0.001
0.903 ± 0.001
0.929 ± 0.001
0.964 ± 0.001

0.359 ± 0.072
0.479 ± 0.067
0.586 ± 0.059
0.211 ± 0.055
0.420 ± 0.058
0.615 ± 0.047
0.136 ± 0.044
0.437 ± 0.051
0.677 ± 0.036

0.166 ± 0.051
0.276 ± 0.058
0.409 ± 0.060
0.018 ± 0.014
0.115 ± 0.035
0.319 ± 0.045
0.006 ± 0.000
0.050 ± 0.015
0.310 ± 0.034

0.028 ± 0.022
0.055 ± 0.029
0.123 ± 0.038
0.002 ± 0.000
0.002 ± 0.000
0.011 ± 0.003
0.005 ± 0.000
0.005 ± 0.000
0.007 ± 0.001

Open Category Detection with PAC Guarantees

Si Liu * 1 Risheek Garrepalli * 2 Thomas G. Dietterich 2 Alan Fern 2 Dan Hendrycks 3

8
1
0
2
 
g
u
A
 
1
 
 
]

G
L
.
s
c
[
 
 
1
v
9
2
5
0
0
.
8
0
8
1
:
v
i
X
r
a

Abstract
Open category detection is the problem of detect-
ing “alien” test instances that belong to categories
or classes that were not present in the training
In many applications, reliably detecting
data.
such aliens is central to ensuring the safety and
accuracy of test set predictions. Unfortunately,
there are no algorithms that provide theoretical
guarantees on their ability to detect aliens under
general assumptions. Further, while there are al-
gorithms for open category detection, there are
few empirical results that directly report alien de-
tection rates. Thus, there are signiﬁcant theoret-
ical and empirical gaps in our understanding of
open category detection. In this paper, we take
a step toward addressing this gap by studying a
simple, but practically-relevant variant of open
category detection. In our setting, we are pro-
vided with a “clean” training set that contains
only the target categories of interest and an un-
labeled “contaminated” training set that contains
a fraction α of alien examples. Under the as-
sumption that we know an upper bound on α, we
develop an algorithm with PAC-style guarantees
on the alien detection rate, while aiming to mini-
mize false alarms. Empirical results on synthetic
and standard benchmark datasets demonstrate the
regimes in which the algorithm can be effective
and provide a baseline for further advancements.

1. Introduction

Most machine learning systems implicitly or explicitly as-
sume that their training experience is representative of their
test experience. This assumption is rarely true in real-world
deployments of machine learning, where “unknown un-
knowns”, or “alien” data, can arise without warning. Ig-

*Equal contribution 1Department of Statistics, Oregon State
University, Oregon, USA 2School of EECS, Oregon State Univer-
sity, Oregon, USA 3University of California, Berkeley, California,
USA. Correspondence to: Si Liu <lius2@oregonstate.edu>.

Proceedings of the 35 th International Conference on Machine
Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018
by the author(s).

noring the potential for such aliens can lead to serious safety
concerns in many applications and signiﬁcantly degrade
the accuracy of test set predictions in others. For exam-
ple, consider a scientiﬁc application where a classiﬁer is
trained to recognize speciﬁc categories of insects in fresh-
water samples in order to detect important environmental
changes (Lytle et al., 2010). Test samples will typically
contain some fraction of specimens belonging to species
not represented in the training data. A classiﬁer that is un-
aware of these new species will misclassify the specimens
as belonging to existing species. This will produce incorrect
scientiﬁc conclusions.

The problem of open category detection is to detect such
alien examples at test time. An ideal algorithm for this prob-
lem would guarantee a user-speciﬁed alien-detection rate
(e.g., 95%), while attempting to minimize the false alarm
rate. Unfortunately, no existing algorithm provides such
guarantees under general conditions. In addition, empir-
ical evaluations of existing algorithms for open category
detection typically do not directly evaluate alien detection
rates, which are perhaps the most relevant for safety-critical
applications. Overall, our current theoretical and practical
understanding of open category detection is lacking from a
safety and accuracy perspective.

Is it possible to achieve open category detection with guar-
antees? In this paper, we take a step toward answering
this question by studying a simpliﬁed, but practically rel-
evant, problem setting. To motivate our setting, consider
the above insect identiﬁcation problem. At training time it
is reasonable to expect that a clean training set is available
that contains only the insect categories of interest. At test
time, a new sample will include insects from the training
categories along with some percentage of insects from new
alien categories. Further, scientists may have reasonable
estimates for this percentage based on their scientiﬁc knowl-
edge and practical experience. We would like to guarantee
that the system is able to raise an alarm for, say, 95% of the
insects from alien classes, with each alarm being examined
by a scientist. At the same time, we would like to avoid as
many “false alarms” as possible, since each alarm requires
scientist effort.

To formalize the example, our setting assumes two training
sets: a clean training dataset involving a ﬁnite set of cate-

Open Category Detection with PAC Guarantees

gories and a contaminated dataset that contains a fraction α
of aliens. Our ﬁrst contribution is to show that, in this setting,
theoretical guarantees are possible given knowledge of an
upper bound on α. In particular, we give an algorithm that
uses this knowledge to provide Probably Approximately
Correct (PAC) guarantees for achieving a user-speciﬁed
alien detection rate. While knowledge of a non-trivial upper
bound on α may not always be possible, in many situations
it will be possible to select a reasonable value based on
domain knowledge, prior data, or by inspecting a sample of
the test data.

The key idea behind our algorithm is to leverage modern
anomaly detectors, which are trained on the clean data. Our
algorithm combines the anomaly-score distributions over
the clean and contaminated training data in order to derive
an alarm threshold that achieves the desired guarantee on
the alien detection rate on new test queries. In theory the
detection rate guarantee will be met regardless of the quality
of the anomaly detector. The quality of the detector, how-
ever, has a signiﬁcant impact on the false alarm rate, with
better detectors leading to fewer false alarms.

We carry out experiments1 on synthetic and benchmark
datasets using a state-of-the-art anomaly detector, the Iso-
lation Forest (Liu et al., 2008). We vary the amount of
training data, the fraction α of alien data points, along with
the accuracy of the upper bound on α provided to our algo-
rithm. The results indicate that our algorithm can achieve
the guaranteed performance when enough data is available,
as predicted by the theory. The results also show that for
the considered benchmarks, the Isolation Forest anomaly
detector is able to support non-trivial false positive rates
given enough data. The results also illustrate the inherent
difﬁculty of the problem for small datasets and/or small
values of α. Overall, our results provide a useful baseline
for driving future work on open category detection with
guarantees.

2. Related Work

Open category detection is related to the problem of one-
class classiﬁcation, which aims to detect outliers relative
to a single training class. One-class SVMs (OCSVMs)
(Sch¨olkopf et al., 2001) are popular for this problem. How-
ever, they have been found to perform poorly for open
category detection due to poor generalization (Zhou &
Huang, 2003), which has been partly addressed by later
work (Manevitz & Yousef, 2002; Wu & Ye, 2009; Jin et al.,
2004; Cevikalp & Triggs, 2012). OCSVMs have been em-
ployed in a multi-class setting similar to open category de-
tection (Heﬂin et al., 2012; Pritsos & Stamatatos, 2013).

1Code for reproducing our experiments can be found at

https://github.com/liusi2019/ocd.

However, there are no direct mechanisms to control the alien
detection rate of these methods, which is a key requirement
for our problem setting.

Work on classiﬁcation with rejection/abstaining options
(Chow, 1970; Wegkamp, 2007; Tax & Duin, 2008;
Pietraszek, 2005; Geifman & El-Yaniv, 2017) allows classi-
ﬁers to abstain from making predictions when they are not
conﬁdent. While loosely related to open category detection,
these approaches do not directly consider the possibility of
novel categories, but rather focus on assessing conﬁdence
with respect to the known categories. Due to their closed-
world discriminative nature, it is easy to construct scenarios
where such methods are incorrectly conﬁdent about the class
of an alien and do not abstain.

A variety of prior work has addressed variants of open cat-
egory detection. This includes work on formalizing the
concept of “open space” to characterize the region of the fea-
ture space outside of the support of the training set (Scheirer
et al., 2013). Variants of SVMs have also been developed,
such as the One-vs-Set Machine (Scheirer et al., 2013) and
the Weibull-calibrated SVM (Scheirer et al., 2014). Ad-
ditional work has addressed open category detection by
tuning the decision boundary based on unlabeled data which
contains data from novel categories (Da et al., 2014). Ap-
proaches based on nearest neighbor methods have also been
proposed (Mendes J´unior et al., 2017). None of these meth-
ods, however, allow for the direct control of alien detection
rates, nor do they provide theoretical guarantees.

There is also recent interest in open category detection for
deep neural networks applied to vision and text classiﬁcation
(Bendale & Boult, 2016; Shu et al., 2017). These methods
usually train a neural network in a standard closed-world
setting, but then analyze various activations in the network
in order to detect aliens. Another related line of work is
detection of out-of-distribution instances, which is similar
to open category detection but assumes that the test data
come from a completely different distribution compared to
the training distribution (Hendrycks & Gimpel, 2017; Liang
et al., 2018). All of this work is quite specialized to deep
neural networks and does not provide direct control of alien
detection rates or theoretical guarantees.

3. Problem Setup

We consider open category detection where there is an un-
known nominal data distribution D0 over labeled examples
from a known set of category labels. We receive as input
a “clean” nominal training set S0 containing k i.i.d. draws
from D0. In practice, S0 will correspond to some curated
labeled data that contains only known categories of interest.

We also receive as input an unlabeled “mixture” dataset
Sm that contains n points drawn i.i.d. from a mixture dis-

Open Category Detection with PAC Guarantees

tribution Dm. Speciﬁcally, the mixture distribution Dm is
a combination of the nominal distribution D0 and an un-
known alien distribution Da, which is a distribution over
novel categories (alien data points). We assume that Da is
stationary, so that all alien points that appear as future test
queries will also be drawn from Da.

At training time, we assume that Dm is a mixture distribu-
tion, with probability α of generating an alien data point
from Da and probability of 1 − α of generating a nominal
point. Our results hold even if the test queries come from a
mixture with a different value of α as long as the alien test
points are drawn from Da.

Given these datasets, our problem is to label test instances
from Dm as either “alien” or “nominal”. In particular, we
wish to achieve a speciﬁed alien detection rate, which is
the fraction of alien data points in Dm that are classiﬁed as
“alien” (e.g., 95%). At the same time we would like the false
positive rate to be small, which is the fraction of nominal
data points incorrectly classiﬁed as aliens.

Our approach to this problem assumes the availability of an
anomaly detector that is trained on S0 and assigns anomaly
scores to all data points in both S0 and Sm. Intuitively, the
anomaly scores order the test examples according to how
anomalous they appear relative to the nominal data (higher
scores being more anomalous). An ideal detector would
rank all alien data points higher than all nominals, though
in practice, the ordering will not be so clean. Our approach
labels data in Sm by selecting a threshold on the anomaly
scores and labeling all data points with scores above the
threshold as aliens and the remaining points as nominals.
Our key challenge is to select a threshold that provides a
guarantee on the alien detection rate.

4. Algorithms for Open Category Detection

In order to obtain theoretical guarantees, our algorithm as-
sumes knowledge of the alien mixture probability α that
generates the mixture data Sm. Later, we will show that
knowing an upper bound on α is sufﬁcient to obtain a guar-
antee.

Our approach is based on considering the cumulative dis-
tribution functions (CDFs) over anomaly scores of a ﬁxed
anomaly detector. Let F0, Fa, and Fm be the CDFs of
anomaly scores for the nominal data distribution D0, alien
distribution Da, and mixture distribution Dm respectively.
Since Dm is a simple mixture of D0 and Da, we can write
Fm as

Fm(x) = (1 − α)F0(x) + αFa(x).

From this we can derive the CDF for Fa in terms of Fm and
F0:

Fa(x) =

Fm(x) − (1 − α)F0(x)
α

.

Given the ability to derive Fa, it is straightforward to achieve
an alien detection rate of 1 − q (e.g. 95%) by selecting an
anomaly score threshold τq that is the q quantile of Fa and
raising an alarm on all test queries whose anomaly score is
greater than τq.

In reality, we do not have access to Fm or F0 and hence
cannot exactly determine Fa. Rather, we have samples
Sm and S0. Thus, our algorithm works with the empirical
CDFs ˆF0 and ˆFm, which are simple step-wise constant
approximations, and estimates an empirical CDF over aliens:

ˆFa(x) =

ˆFm(x) − (1 − α) ˆF0(x)
α

.

(1)

Our algorithm computes the above estimate of ˆFa and uses
it to select a threshold ˆτq to be the largest threshold such
that ˆFa(ˆτq) ≤ q, where 1 − q is the target alien detection
rate. This choice will minimize the number of false alarms.
The steps of this algorithm are as follows.

Algorithm 1
1: Get anomaly scores for all points in S0 and Sm, denoted

x1, x2, . . . , xk and y1, y2, . . . , yn respectively.

2: Compute empirical CDFs ˆF0 and ˆFm.
3: Calculate ˆFa using equation 1.
4: Output detection threshold

ˆτq = max{u ∈ S : ˆFa(u) ≤ q},

where S = {x1, x2, . . . , xk, y1, y2, . . . , yn}.

Although ˆFm and ˆF0 are both legal CDFs, the estimate
for ˆFa from step 3 may not be a legal CDF, because it is
the difference of two noisy estimates—it may not increase
monotonically and it may even be negative. A good tech-
nique for dealing with this problem is to employ isotoniza-
tion (Barlow & Brunk, 1972) and clipping. Isotonization
ﬁnds the monotonically increasing function ˆF ∗
a closest to
ˆFa in squared error. To convert ˆFa into a legal CDF, deﬁne
ˇFa = min{max{ ˆF ∗
a , 0}, 1}, where the min and max opera-
tors are applied pointwise to their arguments. We performed
experiments (shown in the supplementary materials) to test
whether using ˇFa in Step 4 would improve the performance
of the overall algorithm. We found that it did not.

5. Finite Sample Guarantee

In the limit of inﬁnite data (both nominal and mixture) and
perfect knowledge of α, ˆFa will converge to the true alien
CDF, and our algorithm will achieve the desired alien de-
tection rate. In this section, we consider the ﬁnite data case
where |S0| = |Sm| = n. We derive a value for the sample
size n that guarantees with high probability over random

Open Category Detection with PAC Guarantees

draws of S0 and Sm, that fraction 1 − q − (cid:15) of the alien
test points will be detected, where (cid:15) is an additional error
incurred because of the ﬁnite sample size n.

Our key theoretical tool is a ﬁnite sample result on the
uniform convergence of empirical CDF functions (Massart,
1990). To use this result, we make the reasonable technical
assumption that the nominal and alien CDFs, F0 and Fa,
are continuous. In the following, let η be the target alien
detection rate, q be the input to Algorithm 1, ˆτq be the
estimated q-quantile of the alien CDF (step 4 of Alg. 1),
and (cid:15) be an error parameter. The following theorem gives
the sample complexity for guaranteeing that 1 − η of the
alien examples will be detected using threshold ˆτq.
Theorem 1. Let S0 and Sm be nominal and mixture
datasets containing n i.i.d. samples from the nominal and
mixture data distributions respectively. For any (cid:15) ∈ (0, 1−q)
and δ ∈ (0, 1), if

n >

ln

1
2

2
√
1 − δ

(cid:18) 1
(cid:15)

1 −

(cid:19)2 (cid:18) 2 − α

(cid:19)2

,

α

the alien CDF will typically concentrate more mass toward
larger anomaly score values compared to F0. Indeed, if this
is not the case, there is little hope since there is effectively
no signal to distinguish between aliens and nominals.

Corollary 1. Consider running Algorithm 1 using an upper
bound α(cid:48) on the true α. Under the same assumptions as
Theorem 1, if the anomaly detector is admissible and

n >

ln

1
2

2
√
1 − δ

(cid:18) 1
(cid:15)

1 −

(cid:19)2 (cid:18) 2 − α(cid:48)

(cid:19)2

,

α(cid:48)

then with probability at least 1 − δ, Algorithm 1 will return
a threshold ˆτq that achieves an alien detection rate of at
least 1 − η, where η = q + (cid:15).

The proof is in the Appendix. While we can achieve a guar-
antee using an upper bound on α(cid:48), the returned threshold
will be more conservative (smaller) than if we had used the
true α. This will result in higher false alarm rates, since
more nominal points will be above the threshold. Thus it is
desirable to use a value of α(cid:48) that is as close to α as possible.

then with probability at least 1 − δ, Algorithm 1 will return
a threshold ˆτq that achieves an alien detection rate of at
least 1 − η, where η = q + (cid:15).

6. Experiments

(cid:15)2α2 log 1

The proof is in the Appendix. Note that n grows as
O( 1
δ ). Hence, this guarantee is polynomial in all
relevant parameters, which we believe is the ﬁrst such guar-
antee for open category detection. The result can be gener-
alized to the case where n0 < nm; in practice, the larger
the mixture sample Sm is, the easier it is to estimate τq,
because this provides more alien points for estimating the
q-th quantile of Fa.

The theorem gives us ﬂexibility in setting (cid:15) and q (the algo-
rithm input) to achieve a guarantee of 1−η. The (cid:15) parameter
controls a trade-off between sample size and false alarm rate.
To minimize the false alarm rate, we want to make q large
(to obtain a larger threshold), so we want to set q close to η.
But, as q → η, (cid:15) → 0, and n → ∞. To minimize the sample
size n, we want to make q as small as possible, because that
allows (cid:15) to be larger and hence n becomes smaller. The
optimal setting of (cid:15) depends on how the false alarm rate
grows with τq, which in turn depends on the relative shape
of F0 and Fa. In a real safety application, we can estimate
these from S0 and Sm and choose an appropriate q value.

What if we don’t know the exact value of α? If our algorithm
uses an upper bound α(cid:48) on the true α to compute ˆFa, we
can still provide a guarantee. In this case, in addition to the
assumptions in Theorem 1, we need a concept of an anomaly
detector being admissible. We say that an anomaly detector
is admissible for a problem, if the anomaly score CDFs
satisfy F0(x) ≥ Fm(x) for all x ∈ R. Most reasonable
anomaly detectors will be admissible in this sense, since

We performed experiments to answer four questions. Ques-
tion Q1: how accurate is our estimate of ˆτq as a function of
n and α? Question Q2: how loose are the bounds from The-
orem 1? Question Q3: what are typical values of the false
alarm rates for various settings of n and α on real datasets?
Question Q4: how do these observed values change if we
employ an overestimate α(cid:48) > α?

All of our experiments employ the Isolation Forest anomaly
detector (Liu et al., 2008), which has been demonstrated
to be a state-of-the-art detector in recent empirical studies
In the Supplementary Materials
(Emmott et al., 2013).
we show similar results with the LODA anomaly detector
(Pevn´y, 2015).

To address Q1 and Q2, we run controlled experiments
on synthetic data. The data points are generated from 9-
dimensional normal distributions. The dimensions of the
nominal distribution D0 are independently distributed as
N (0, 1). The alien distribution is similar, but with probabil-
ity 0.4, 3 of the 9 dimensions (chosen uniformly at random)
are distributed as N (3, 1) and with probability 0.6, 4 of the
9 dimensions (chosen uniformly at random) follow N (3, 1).
This ensures that the anomalies are not highly similar to
each other and models the situation in which there are many
different kinds of alien objects, not just a single alien class
forming a tight cluster.

In each experiment, the nominal dataset and the mixture
dataset are of the same size n, and the mixture dataset
contains a proportion α of anomaly points. We ﬁxed
the target quantile to be q = 0.05. The experiments are

Open Category Detection with PAC Guarantees

Figure 1. Comparison of recall achieved by ˆτq compared to oracle
recall of 0.95. Error bars are 95% conﬁdence intervals. Settings
of n and α increase from left to right starting with α = 0.01 and
n ∈ {100, 500, 1K, 5K, 10K} up to α = 0.5 and n = 10K.

carried out for n ∈ {100, 500, 1K, 5K, 10K} and α ∈
{0.01, 0.05, 0.10, 0.20, 0.50}. For testing, we create two
large datasets G0 and Ga, with G0 being a pure nominal
dataset, Ga being a pure alien dataset, and |G0| = |Ga| =
20K. The Isolation Forest algorithm computes 1000 full
depth isolation trees on the nominal data. Each tree is grown
on a randomly-selected 20% subsample of the clean data
points. We compute anomaly scores for the nominal points
via out-of-bag estimates and anomaly scores for the mix-
ture points, G0, and Ga using the full isolation forest. For
each combination of n and α, we repeat the experiment
100 times. We measure the fraction of aliens detected (the
“recall”) and the fraction of nominal points declared to be
alien (the “false positive rate”) by applying the ˆτq estimate
to threshold the anomaly scores in G0 and Ga.

To assess the accuracy of our ˆτq estimates (Q1), we could
compare them to the true values. However, this comparison
is hard to interpret, because τ is expressed on the scale
of anomaly scores, which are somewhat arbitrary. Instead,
Figure 1 plots the recall achieved by ˆτq. If ˆτq had been
estimated perfectly, the recall would always be 1−q = 0.95.
However, we see that the recall is often less than 0.95, which
indicates that ˆτq is over-estimated, especially when n and α
are small. This behavior is predicted by our theory, where
we see that the sample size requirements grow inversely
with α2. For larger α and n, the recall guarantee is generally
achieved. Figure 2 compares the false positive rate of the
true oracle τq to the false positive rate of the estimate ˆτq. For
each combination of α and n, we have 100 replications of
the experiment and therefore 100 estimates ˆτa and 100 FPR
rates. For each of these, the true FPR is computed using G0.

Figure 2. Comparison of oracle FPR to the FPR achieved by ˆτq.
Error bars span from the 25th to 75th percentile with the blue dot
marking the median of the 100 trials. Orange markers indicate the
oracle FPR. Settings of n and α increase from left to right starting
with α = 0.01 and n ∈ {100, 500, 1K, 5K, 10K} up to α = 0.5
and n = 10K.

The error bars summarize the resulting 100 FPR values by
the median and inter-quartile range. We see that for small n
and α, the FPR can be quite different from the oracle rate,
but for larger n and α, the estimates are very good.

To assess the looseness of the bounds (Q2), for each combi-
nation of n and α, we ﬁx δ = 0.05 and compute the value
of η such that 95 of the 100 runs achieved a recall of at least
1 − η (thus η empirially achieves the 1 − δ guarantee). We
then compute (cid:15) = η − q and the corresponding required
sample size n∗ according to Theorem 1. Figure 3 shows a

Figure 3. The log sample size n∗ required by Theorem 1 in order
to guarantee the actual observed recall versus the log actual sample
size n.

Open Category Detection with PAC Guarantees

plot of n∗ versus the actual n. The distance of these points
from the n∗ = n diagonal line show that the theory is fairly
loose, although it becomes tighter as n gets large.

Figure 4. False positive rates on six UCI datasets as a function of
α (q = 0.05, δ = 0.05).

Benchmark Data Experiments. To address our third and
fourth questions, we performed experiments on six UCI
multiclass datasets: Landsat, Opt.digits, pageb, Shuttle,
Covertype and MNIST. In addition to these, we provide
results for the Tiny ImageNet dataset. In each multiclass
dataset, we split the classes into two groups: nominal and
alien. For Tiny ImageNet, we train a deep neural network
classiﬁer on 200 nominal classes and treat the remaining
800 as aliens. The nominal classes for UCI datasets are
MNIST(1,3,7), Landsat(1,7), OCR(1,3,4,5,7), pageb(1,5),
Letter recognition(1,3), and Shuttle(1,4). We generated

Figure 5. Recall rates on six UCI datasets as a function of α (q =
0.05, δ = 0.05)

Figure 6. False positive rates on two image datasets as a function
of α (q = 0.05, δ = 0.05).

nominal and mixture datasets for various values of α. The
value of n for each dataset is 1532 for Landsat,788 for Letter
recognition, 568 for OCR, 4912 for pageb, 5000 for Shuttle,
13,624 for Covertype, 11,154 for MNIST, and 10,000 for
Tiny ImageNet. Because we cannot create datasets with
large n, we cannot measure the true value of τq.

After computing the anomaly scores for both nominal and
mixture datasets, we applied Algorithm 1 within a 10-fold
cross validation. We divide the mixture data points at ran-
dom into 10 groups. For each fold, we estimate ˆFa and ˆτa
from 9 of the 10 groups and then score the mixture points in
the held-out fold according to ˆτa. In all other respects, the
experimental protocol is the same as for the synthetic data.
For Tiny ImageNet, the anomaly scores are obtained by
applying a baseline method (Hendrycks & Gimpel, 2017).

To answer Q3, Figures 4 and 6 plot the false positive rate as
a function of α for the UCI and vision datasets, respectively.
We see that the FPR ranges from 3.6% to 26.9% on UCI
depending on the dataset and the level of α. The vision
datasets have higher FPR, especially MNIST, which has a
large number of alien classes that are not distinguished well
by the anomaly detector. The FPR depends primarily on
the domain, because the key issue is how well the anomaly
detector distinguishes between nominal and alien examples.
The false alarm rate generally improves as α increases. In
some applications, it may be possible to enrich Sm so that
α is larger on the training set to take advantage of this
phenomenon. It is interesting to note that once ˆτa has been
computed, it can be applied to test datasets having different
(or unknown) values of α.

Figures 5 and 7 plot the recall rate as a function of α for
the UCI and vision datasets. We set q = 0.05 in these
experiments. Theorem 1 only guarantees a recall of 1−q −(cid:15),

Open Category Detection with PAC Guarantees

of α(cid:48) − α. Two points are plotted for each combination
of α(cid:48) and dataset, the change in Recall and the change in
FPR. We observe that the recall increases slightly (in the
range from 0.01 to 0.05). However, the false positive rate
increases by much larger amounts (from 0.01 to 0.336). This
demonstrates that it is very important to determine the value
of α accurately.

7. Summary

We have taken a step toward open category detection with
guarantees by providing a PAC-style guarantee on the prob-
ability of detecting 1 − η of the aliens on the test data. This
is the ﬁrst such guarantee under any similarly general con-
ditions. We have shown that this guarantee is satisﬁed in
our experiments, although the guarantee is somewhat loose,
especially on small training sets. Obtaining a guarantee re-
quires more data than standard PAC guarantees on expected
prediction accuracy. This is because we must estimate the
q quantile of the alien anomaly score distribution, where
q is typically quite small. Nonetheless, our experiments
show that our algorithm gives good recall performance and
non-trivial false alarm rates on datasets of reasonable size.

It is important to note that the very formulation of a PAC-
style guarantee on the probability of detecting aliens re-
quires assuming that the aliens are drawn from a well-
deﬁned distribution Da. While this is appropriate in some
applications, such as the insect survey application described
in the introduction, it is not appropriate for adversarial set-
tings. In such settings, a PAC-style guarantee does not make
sense, and some other form of safety guarantee needs to be
formulated.

To obtain the guarantee, we employ two training datasets:
a clean dataset that contains no aliens and an (unlabeled)
contaminated dataset that contains a known fraction α of
aliens. An important theoretical problem for future research
is to develop a method that can estimate a tight upper bound
on ˆα > α. We believe this is possible, but we have not yet
found a method that guarantees that ˆα > α.

Our guarantee requires more data as α becomes small. For-
tunately, when α is small, it may be possible in some appli-
cations to afford lower recall rates, since the frequency of
aliens will be smaller. However, in safety-critical applica-
tions where a single undetected alien poses a serious threat,
there is little recourse other than to collect more data or
allow for higher false positive rates.

Acknowledgements

This research was supported by a gift from Huawei, Inc.,
and grants from the Future of Life Institute and the NSF
Grant 1514550. Any opinions, ﬁndings, and conclusions

Figure 7. Recall rates on two image datasets as a function of α
(q = 0.05, δ = 0.05).

Figure 8. Change in recall and false positive rate as a function of
α(cid:48) − α for six UCI datasets; α ∈ {0.1, 0.2, 0.4}

where (cid:15) depends on n. Hence, it is nice to see that for
three of the domains (Shuttle, Covertype, and Landsat) in
UCI and for both vision datasets, the recall is very close to
1 − q = 0.95. These are the domains with the largest values
of n. The value of α has a bigger impact on recall than it
does on FPR. This is because the effective number of alien
training examples is αn, which can be very small for some
datasets when α = 0.1. This shows that in applications such
as fraud detection, where α may be very small, the mixture
dataset Sm needs to be very large.

To answer Q4 regarding the impact of using an incorrect
value α(cid:48) > α, we repeated these experiments with α(cid:48) =
α+ξ, for ξ ∈ {0.002, 0.004, 0.006, 0.008, 0.010}. Figure 8
plots the change in false positive rate and recall as a function

Open Category Detection with PAC Guarantees

or recommendations expressed in this material are those of
the author(s) and do not necessarily reﬂect the views of the
sponsors.

we will have

A. Proof for Theorem 1

Suppose there are n random variables which are i.i.d. from
the distribution with CDF F and let ˆFn be the empirical
CDF calculated from this sample. Then Massart (1990)
shows that

√

P (

n sup
x

| ˆFn(x) − F (x)| > λ) ≤ 2 exp(−2λ2)

(2)

holds without any restriction on λ. Making use of this,
and assuming we use the same sample size n for both the
mixture dataset and the clean data set, for any (cid:15) ∈ (0, 1 − q),
we seek to determine how large n needs to be in order to
guarantee that with probability at least 1 − δ our quantile
estimate ˆτq satisﬁes Fa(ˆτq) ≤ q + (cid:15). To achieve this, we
want to have

P (sup

| ˆFa(x) − Fa(x)| > (cid:15)) ≤ δ.

We have

x

x

x

x

x

1
2

P (sup

| ˆFa(x) − Fa(x)| > (cid:15))

= P (sup

|

ˆFm(x) − (1 − α) ˆF0(x)
α

−

Fm(x) − (1 − α)F0(x)
α
( ˆFm(x) − Fm(x)) −

| > (cid:15))

|

= P (sup

1
α

( ˆF0(x) − F0(x))| > (cid:15))

≤ P ((

| ˆFm(x) − Fm(x)| +

x
1 − α
α

1
α
1 − α
α

sup
x

sup
x

1
sup
α
x
1 − α
α

sup
x

∪ {

1
2 − α

(cid:15)}

1 − α
2 − α

(cid:15)})

≤ P ({

| ˆFm(x) − Fm(x)| >

= P ({sup

| ˆFm(x) − Fm(x)| >

∪ {sup

| ˆF0(x) − F0(x)| >

| ˆF0(x) − F0(x)| >
α
2 − α
α
2 − α

(cid:15)}

(cid:15)}).

| ˆF0(x) − F0(x)|) > (cid:15))

But

Making use of (2), when

n >

ln

2
√
1 − δ

(

1
(cid:15)

)2(

2 − α
α

)2,

1 −

P (sup

| ˆFm(x) − Fm(x)| >

(cid:15)) ≤ 1 −

1 − δ,

P (sup

| ˆF0(x) − F0(x)| >

(cid:15)) ≤ 1 −

1 − δ.

α
2 − α
α
2 − α

√

√

x

x

In this case we will have

P (sup

| ˆFa(x) − Fa(x)| > (cid:15))

x

≤ 1 − P ({sup

x

| ˆFm(x) − Fm(x)| ≤
α
2 − α

| ˆF0(x) − F0(x)| ≤

(cid:15)})

α
2 − α

(cid:15)}

∩ {sup

x
≤ 1 − (1 − 1 +

√

1 − δ)2

= δ.

Now we have with probability at least 1 − δ,

| ˆFa(x) − Fa(x)| ≤ (cid:15), ∀x ∈ R.

If this inequality holds, then for any value ˆτq such that
ˆFa(ˆτq) ≤ q, we have

Fa(ˆτq) ≤ ˆFa(ˆτq) + (cid:15) ≤ q + (cid:15).

So we have with probability at least 1 − δ, any ˆτq satisfying
ˆFa(ˆτq) ≤ q will satisfy Fa(ˆτq) ≤ q + (cid:15).
(cid:3)

B. Proof for Corollary 1

If α(cid:48) ≥ α, and if we write

F (cid:48)

a(x) =

Fm(x) − (1 − α(cid:48))F0(x)
α(cid:48)

,

then F (cid:48)

a is still a legal CDF, because

a(−∞) = 0, F (cid:48)
F (cid:48)

a(∞) = 1,

and it is easy to show that F (cid:48)
ing.

a is monotonically nondecreas-

F (cid:48)

≥ 0, ∀x ∈ R,

a(x)−Fa(x) =

(α − α(cid:48))(Fm(x) − F0(x))
αα(cid:48)
and because of this, if we let ˆτ (cid:48)
q denote the threshold we
get from using α(cid:48), we will have Fa(ˆτ (cid:48)
q) ≤ F (cid:48)
q). By
the proof of previous theorem, we know that when n >
2
1
α(cid:48) )2, we have with probability at least
2 ln
√
1−δ
q) ≤ q + (cid:15).(cid:3)
a(ˆτ (cid:48)
1 − δ, F (cid:48)

(cid:15) )2( 2−α(cid:48)
( 1
q) ≤ q + (cid:15), and thus we have Fa(ˆτ (cid:48)

a(ˆτ (cid:48)

1−

References

Barlow, RE and Brunk, HD. The isotonic regression prob-
lem and its dual. Journal of the American Statistical
Association, 67(337):140–147, 1972.

Open Category Detection with PAC Guarantees

Bendale, A. and Boult, T. E. Towards open set deep net-
works. In 2016 IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), pp. 1563–1572, June
2016.

Cevikalp, H. and Triggs, B. Efﬁcient object detection using
cascades of nearest convex model classiﬁers. In 2012
IEEE Conference on Computer Vision and Pattern Recog-
nition, pp. 3138–3145, June 2012.

Chow, C. On optimum recognition error and reject tradeoff.
IEEE Transactions on Information Theory, 16(1):41–46,
Jan 1970. ISSN 0018-9448.

Da, Qing, Yu, Yang, and Zhou, Zhi-Hua. Learning with
augmented class by exploiting unlabeled data. In Pro-
ceedings of the Twenty-Eighth AAAI Conference on Artiﬁ-
cial Intelligence, AAAI’14, pp. 1760–1766. AAAI Press,
2014.

Emmott, Andrew F, Das, Shubhomoy, Dietterich, Thomas,
Fern, Alan, and Wong, Weng-Keen. Systematic construc-
tion of anomaly detection benchmarks from real data. In
Proceedings of the ACM SIGKDD workshop on outlier
detection and description, pp. 16–21. ACM, 2013.

Geifman, Yonatan and El-Yaniv, Ran. Selective classiﬁca-
tion for deep neural networks. In Guyon, I., Luxburg,
U. V., Bengio, S., Wallach, H., Fergus, R., Vishwanathan,
S., and Garnett, R. (eds.), Advances in Neural Informa-
tion Processing Systems 30, pp. 4885–4894. Curran As-
sociates, Inc., 2017.

Heﬂin, B., Scheirer, W., and Boult, T. E. Detecting and
classifying scars, marks, and tattoos found in the wild. In
2012 IEEE Fifth International Conference on Biometrics:
Theory, Applications and Systems (BTAS), pp. 31–38,
Sept 2012.

Hendrycks, Dan and Gimpel, Kevin. A baseline for de-
tecting misclassiﬁed and out-of-distribution examples in
neural networks. In Proceedings of International Confer-
ence on Learning Representations, 2017.

Jin, Hongliang, Liu, Qingshan, and Lu, Hanqing. Face
detection using one-class-based support vectors. In Sixth
IEEE International Conference on Automatic Face and
Gesture Recognition, 2004. Proceedings., pp. 457–462,
May 2004.

Liang, Shiyu, Li, Yixuan, and Srikant, R. Enhancing the
reliability of out-of-distribution image detection in neural
networks. International Conference on Learning Repre-
sentations, 2018.

Lytle, David A, Mart´ınez-Mu˜noz, Gonzalo, Zhang, Wei,
Larios, Natalia, Shapiro, Linda, Paasch, Robert, Mold-
enke, Andrew, Mortensen, Eric N, Todorovic, Sinisa, and
Dietterich, Thomas G. Automated processing and identi-
ﬁcation of benthic invertebrate samples. Journal of the
North American Benthological Society, 29(3):867–874,
2010.

Manevitz, Larry M. and Yousef, Malik. One-class svms for
document classiﬁcation. J. Mach. Learn. Res., 2:139–154,
March 2002. ISSN 1532-4435.

Massart, P. The tight constant in the dvoretzky-kiefer-
wolfowitz inequality. The Annals of Probability, 18(3):
1269–1283, 1990. ISSN 00911798.

Mendes J´unior, Pedro R., de Souza, Roberto M., Werneck,
Rafael de O., Stein, Bernardo V., Pazinato, Daniel V.,
de Almeida, Waldir R., Penatti, Ot´avio A. B., Torres,
Ricardo da S., and Rocha, Anderson. Nearest neighbors
distance ratio open-set classiﬁer. Machine Learning, 106
(3):359–386, Mar 2017. ISSN 1573-0565.

Pevn´y, Tom´aˇs. Loda: Lightweight on-line detector of
anomalies. Machine Learning, (November 2014), 2015.

Pietraszek, Tadeusz. Optimizing abstaining classiﬁers using
roc analysis. In Proceedings of the 22Nd International
Conference on Machine Learning, ICML ’05, pp. 665–
672, New York, NY, USA, 2005. ACM. ISBN 1-59593-
180-5.

Pritsos, Dimitrios A. and Stamatatos, Efstathios. Open-
Set Classiﬁcation for Automated Genre Identiﬁcation, pp.
207–217. Springer Berlin Heidelberg, Berlin, Heidelberg,
2013. ISBN 978-3-642-36973-5.

Scheirer, W. J., de Rezende Rocha, A., Sapkota, A., and
Boult, T. E. Toward open set recognition. IEEE Transac-
tions on Pattern Analysis and Machine Intelligence, 35
(7):1757–1772, July 2013. ISSN 0162-8828.

Scheirer, W. J., Jain, L. P., and Boult, T. E. Probability
models for open set recognition. IEEE Transactions on
Pattern Analysis and Machine Intelligence, 36(11):2317–
2324, Nov 2014. ISSN 0162-8828.

Sch¨olkopf, Bernhard, Platt, John C., Shawe-Taylor, John C.,
Smola, Alex J., and Williamson, Robert C. Estimating
the support of a high-dimensional distribution. Neural
Comput., 13(7):1443–1471, July 2001. ISSN 0899-7667.

Shu, Lei, Xu, Hu, and Liu, Bing. DOC: deep open classiﬁ-
cation of text documents. CoRR, abs/1709.08716, 2017.

Liu, Fei Tony, Ting, Kai Ming, and Zhou, Zhi-Hua. Isolation
forest. In Data Mining, 2008. ICDM’08. Eighth IEEE
International Conference on, pp. 413–422. IEEE, 2008.

Tax, D.M.J. and Duin, R.P.W. Growing a multi-class classi-
ﬁer with a reject option. Pattern Recognition Letters, 29
(10):1565 – 1570, 2008. ISSN 0167-8655.

Open Category Detection with PAC Guarantees

Wegkamp, Marten H. Lasso type classiﬁers with a reject

option. 2007.

Wu, M. and Ye, J. A small sphere and large margin ap-
proach for novelty detection using training data with out-
liers. IEEE Transactions on Pattern Analysis and Ma-
chine Intelligence, 31(11):2088–2092, Nov 2009. ISSN
0162-8828.

Zhou, Xiang Sean and Huang, Thomas S. Relevance feed-
back in image retrieval: A comprehensive review. Mul-
timedia Systems, 8(6):536–544, Apr 2003. ISSN 1432-
1882.

Open Category Detection with PAC Guarantees

A. Experimental Results from Synthetic

Datasets

In this section we include the simulation results on synthetic
datasets from using two different anomaly detectors, Isola-
tion Forest and LODA in table 1-3 and 4-6 respectively. For
using LODA, when training it on the nominal dataset, we
build 1 000 random projections, and each of them is built
using a bootstrap resample of the nominal dataset. After
ﬁnishing building all projections, we calculate the anomaly
score for each point in nominal dataset only using the pro-
jections that didn’t use this point, and calculate the anomaly
scores for mixture dataset, G0 and Ga using all the projec-
tions. For all cases, we include results from targeting on
different recalls which are 98%, 95% and 90%. In table 1-6,
the oracle FPR column is the mean of 100 oracle FPRs in
each setting.

In table 7, we include the results we used for plotting ﬁgure
2. The results are the 1st quartile, median and 3rd quartile of
FPR from experiments using Iforest with target recall 95%.
Here the oracle FPR column is the median of 100 oracle
FPRs.

B. Experimental Results from UCI and Image

Datasets

In this section we include results of performance on UCI
benchmarks, MNIST and Tiny Imagenet and Tables 8-22
illustrate the results. The experimental protocol is similar
to synthetic datasets and two state of the art anomaly de-
tectors Isolation forest, LODA are applied. For Isolation
forest we train Forest with 1000 trees on nominal dataset
and use out of bag estimates of this dataset to estimate the
nominal datasets anomaly score distribution. For LODA we
build 1000 projections and similar to Isolation forest we get
anomaly score for each point in nominal dataset using the
projections that didn’t use this point.Tables 11-16 illustrate
the results of LODA for 6 different datasets for varying val-
ues of η and report the observed recall, False positive rate
averaged over 100 runs of each experiment. Tables 17-22
report the results for Isolation Forest and it can be observed
the performance of both LODA,Isolation Forest are similar.

For Image datasets we follow the same protocol as UCI for
MNIST and apply Isolation Forest on the input image but for
Tiny Imagenet the anomaly scores are obtained differently.
We ﬁrst train a Wide Residual Network (40-2) classiﬁer
on the 200 nominal classes of Tiny Imagenet and apply
baseline method (Hendrycks & Gimpel, 2017) on validation
data to get the nominal dataset distribution and later apply
the same method on the mixture dataset which will have α
proportion of aliens which are basically from 800 held out
classes.Tables 8-10 illustrate the results for these datasets
for target recall of 98%,95% and 90%.

Open Category Detection with PAC Guarantees

Table 1. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 98%, iForest

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

247818
1167215
1829649
4236646
6363404
23373
239656
259309
1067189
1536752
20178
107381
196205
456821
861861
7550
80449
110875
498016
670130
7053
34712
70925
167019
451373

0.710±0.033
0.862±0.019
0.884±0.015
0.920±0.010
0.932±0.009
0.826±0.027
0.939±0.009
0.940±0.008
0.961±0.005
0.965±0.004
0.907±0.017
0.951±0.007
0.960±0.005
0.970±0.004
0.975±0.003
0.946±0.011
0.971±0.005
0.972±0.004
0.977±0.002
0.977±0.002
0.970±0.005
0.977±0.003
0.979±0.002
0.978±0.001
0.979±0.001

0.033±0.027
0.033±0.024
0.031±0.024
0.060±0.038
0.065±0.034
0.088±0.037
0.064±0.032
0.046±0.025
0.083±0.039
0.063±0.026
0.105±0.033
0.071±0.035
0.062±0.023
0.075±0.031
0.088±0.034
0.158±0.045
0.131±0.045
0.098±0.038
0.048±0.010
0.051±0.019
0.156±0.036
0.056±0.009
0.053±0.014
0.039±0.002
0.036±0.001

0.102
0.042
0.036
0.039
0.037
0.101
0.042
0.037
0.039
0.037
0.100
0.042
0.037
0.039
0.037
0.101
0.042
0.037
0.039
0.037
0.102
0.042
0.036
0.039
0.037

0.929±0.029
0.972±0.016
0.980±0.009
0.985±0.007
0.984±0.007
0.950±0.022
0.979±0.007
0.977±0.007
0.984±0.005
0.987±0.004
0.977±0.010
0.985±0.005
0.982±0.005
0.988±0.004
0.989±0.003
0.974±0.010
0.988±0.004
0.989±0.004
0.985±0.003
0.984±0.003
0.982±0.005
0.984±0.003
0.985±0.003
0.979±0.001
0.979±0.001

0.512±0.080
0.543±0.079
0.574±0.080
0.506±0.079
0.520±0.080
0.502±0.081
0.465±0.081
0.477±0.085
0.411±0.080
0.434±0.076
0.549±0.075
0.482±0.080
0.419±0.081
0.403±0.075
0.433±0.077
0.496±0.075
0.484±0.078
0.475±0.079
0.254±0.066
0.216±0.060
0.395±0.073
0.256±0.065
0.196±0.052
0.049±0.014
0.047±0.016

0.102
0.042
0.036
0.039
0.037
0.101
0.042
0.037
0.039
0.037
0.100
0.042
0.037
0.039
0.037
0.101
0.042
0.037
0.039
0.037
0.102
0.042
0.036
0.039
0.037

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Open Category Detection with PAC Guarantees

Table 2. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 95%, iForest

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

275039
1474209
2462157
6171393
9309633
27589
243154
307512
1356124
1553411
28043
109029
157112
1232102
861861
8666
121266
177212
581132
776090
6349
56529
111994
292413
379279

0.710±0.033
0.862±0.019
0.884±0.015
0.911±0.010
0.918±0.010
0.826±0.027
0.920±0.010
0.923±0.009
0.943±0.005
0.945±0.005
0.906±0.016
0.933±0.009
0.934±0.006
0.949±0.004
0.951±0.003
0.929±0.012
0.953±0.006
0.949±0.004
0.949±0.002
0.949±0.002
0.952±0.006
0.951±0.003
0.951±0.002
0.950 ±0.001
0.950 ±0.001

0.033±0.027
0.033±0.024
0.030±0.024
0.039±0.030
0.054±0.032
0.082±0.035
0.035±0.020
0.022±0.011
0.040±0.028
0.024±0.009
0.101±0.033
0.055±0.032
0.017±0.006
0.027±0.018
0.027±0.016
0.126±0.042
0.054±0.025
0.018±0.004
0.014±0.001
0.014±0.001
0.084±0.021
0.018±0.002
0.013±0.001
0.014± 0.000
0.014± 0.000

0.052
0.015
0.012
0.014
0.014
0.051
0.015
0.012
0.014
0.014
0.050
0.015
0.012
0.014
0.014
0.051
0.015
0.012
0.014
0.014
0.052
0.015
0.012
0.014
0.014

0.929±0.029
0.972±0.016
0.978±0.010
0.982±0.008
0.981±0.008
0.947±0.022
0.975±0.009
0.966±0.010
0.973±0.007
0.972±0.006
0.969±0.013
0.974±0.008
0.969±0.007
0.967±0.006
0.964±0.005
0.963±0.013
0.977±0.006
0.968±0.006
0.953±0.003
0.952±0.003
0.966±0.007
0.954±0.004
0.952±0.002
0.950±0.001
0.950± 0.001

0.509±0.080
0.533±0.079
0.557±0.081
0.496±0.080
0.495±0.081
0.489±0.081
0.440±0.079
0.420±0.084
0.351±0.079
0.314±0.074
0.511±0.077
0.397±0.078
0.313±0.075
0.194±0.061
0.192±0.063
0.428±0.073
0.360±0.075
0.273±0.072
0.039±0.024
0.042±0.028
0.262±0.061
0.038±0.021
0.014±0.001
0.014±0.000
0.014±0.000

0.052
0.015
0.012
0.014
0.014
0.051
0.015
0.012
0.014
0.014
0.050
0.015
0.012
0.014
0.014
0.051
0.015
0.012
0.014
0.014
0.052
0.015
0.012
0.014
0.014

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Open Category Detection with PAC Guarantees

Table 3. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 90%, iForest

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

331513
2340744
3222506
5918805
12543171
37658
403920
482922
2307205
2629242
39085
139647
156669
1867515
1232102
6481
63235
153077
397467
1088542
4400
22825
44373
229795
374065

0.710±0.033
0.862±0.019
0.859±0.014
0.869±0.011
0.884±0.010
0.826±0.027
0.893±0.011
0.888±0.010
0.901±0.006
0.898±0.005
0.879±0.017
0.900±0.010
0.888±0.008
0.902±0.003
0.900± 0.003
0.881±0.017
0.909±0.007
0.902±0.004
0.898±0.002
0.899±0.002
0.912±0.008
0.904±0.004
0.903±0.003
0.900±0.001
0.900± 0.001

0.033±0.027
0.033±0.024
0.011±0.008
0.012±0.017
0.012±0.009
0.081±0.034
0.02 ±0.015
0.015±0.011
0.007±0.004
0.005±0.001
0.059±0.021
0.019±0.014
0.005±0.001
0.004±0.000
0.005±0.000
0.060±0.022
0.010±0.003
0.005±0.000
0.003±0.000
0.005±0.000
0.038±0.005
0.006±0.000
0.004±0.000
0.004±0.000
0.005±0.000

0.026
0.005
0.004
0.004
0.005
0.026
0.006
0.004
0.004
0.005
0.025
0.005
0.004
0.003
0.005
0.026
0.005
0.004
0.004
0.005
0.026
0.005
0.004
0.004
0.005

0.929±0.029
0.970±0.016
0.976±0.011
0.976±0.01
0.971±0.011
0.936±0.024
0.960±0.012
0.945±0.014
0.939±0.011
0.923±0.009
0.957±0.016
0.944±0.013
0.925±0.012
0.911±0.006
0.903±0.004
0.942±0.016
0.937±0.010
0.913±0.007
0.898±0.002
0.900± 0.002
0.920±0.010
0.904±0.004
0.903±0.003
0.900±0.001
0.900±0.001

0.509±0.080
0.517±0.078
0.542±0.081
0.476±0.079
0.458±0.080
0.468±0.081
0.372±0.075
0.381±0.082
0.228±0.070
0.139±0.056
0.463±0.076
0.297±0.073
0.166±0.058
0.060 ±0.039
0.016±0.015
0.359±0.072
0.170±0.057
0.066±0.040
0.004±0.000
0.005±0.000
0.107±0.042
0.006±0.000
0.004±0.000
0.004±0.000
0.005±0.000

0.026
0.005
0.004
0.004
0.005
0.026
0.006
0.004
0.004
0.005
0.025
0.005
0.004
0.003
0.005
0.026
0.005
0.004
0.004
0.005
0.026
0.005
0.004
0.004
0.005

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Open Category Detection with PAC Guarantees

Table 4. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 98%, bootstrap
LODA

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

188760
1065490
1891769
5874989
8907859
17905
177557
340061
2051058
2362910
13692
79982
191346
1069912
2042503
7818
54275
121904
612305
922499
4604
25350
101036
431535
615923

0.719±0.048
0.872±0.022
0.899±0.016
0.942±0.010
0.954±0.008
0.842±0.031
0.940±0.011
0.952±0.008
0.971±0.004
0.975±0.004
0.933±0.017
0.955±0.008
0.967±0.005
0.977±0.003
0.980±0.003
0.949±0.013
0.970±0.005
0.977±0.004
0.980±0.002
0.980±0.002
0.973±0.006
0.980±0.003
0.981±0.002
0.980±0.001
0.980±0.001

0.095±0.039
0.083±0.038
0.060±0.031
0.067±0.030
0.069±0.027
0.165±0.051
0.118±0.043
0.090±0.035
0.089±0.034
0.079±0.027
0.213±0.046
0.097±0.037
0.070±0.023
0.072±0.028
0.087±0.030
0.257±0.057
0.125±0.039
0.102±0.031
0.059±0.015
0.073±0.030
0.223±0.042
0.093±0.024
0.065±0.014
0.037±0.002
0.034±0.002

0.135
0.048
0.041
0.034
0.033
0.132
0.049
0.041
0.034
0.034
0.142
0.049
0.041
0.034
0.034
0.131
0.048
0.040
0.034
0.034
0.135
0.049
0.041
0.034
0.034

0.972±0.017
0.974±0.013
0.980±0.009
0.988±0.005
0.990±0.005
0.942±0.024
0.983±0.007
0.980±0.007
0.988±0.004
0.989±0.003
0.977±0.011
0.984±0.006
0.985±0.005
0.989±0.003
0.990±0.003
0.970±0.010
0.987±0.004
0.992±0.003
0.986±0.003
0.986±0.002
0.983±0.005
0.986±0.003
0.986±0.002
0.981±0.001
0.980±0.001

0.569±0.073
0.491±0.079
0.511±0.078
0.447±0.078
0.444±0.075
0.498±0.077
0.430±0.073
0.462±0.081
0.384±0.076
0.360±0.070
0.537±0.070
0.456±0.077
0.402±0.076
0.351±0.070
0.342±0.070
0.481±0.076
0.451±0.076
0.462±0.075
0.217±0.058
0.215±0.057
0.422±0.067
0.258±0.061
0.177±0.047
0.047±0.013
0.038±0.006

0.135
0.048
0.041
0.034
0.033
0.132
0.049
0.041
0.034
0.034
0.142
0.049
0.041
0.034
0.034
0.131
0.048
0.040
0.034
0.034
0.135
0.049
0.041
0.034
0.034

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Open Category Detection with PAC Guarantees

Table 5. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 95%, bootstrap
LODA

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

206671
1330996
2559525
7369343
8307313
20685
175626
463720
3619299
2934537
17884
85131
142860
1578820
2255301
11831
65192
174441
802440
2068150
5099
30120
80278
465368
686935

0.719±0.048
0.872±0.022
0.899±0.016
0.933±0.010
0.943±0.009
0.841±0.031
0.921±0.013
0.940±0.009
0.952±0.005
0.956±0.004
0.929±0.017
0.940±0.009
0.943±0.007
0.955±0.004
0.957±0.003
0.940±0.013
0.955±0.007
0.956±0.005
0.952±0.002
0.952±0.001
0.954±0.007
0.953±0.003
0.952±0.002
0.951±0.001
0.950±0.001

0.095±0.039
0.083±0.038
0.060±0.031
0.052±0.023
0.059±0.025
0.164±0.050
0.092±0.038
0.057±0.026
0.038±0.022
0.024±0.007
0.205±0.046
0.083±0.036
0.039±0.014
0.029±0.018
0.022±0.009
0.204±0.049
0.077±0.029
0.041±0.018
0.013±0.002
0.011±0.001
0.123±0.022
0.025±0.003
0.017±0.001
0.011±0.000
0.011±0.000

0.077
0.020
0.015
0.011
0.010
0.076
0.020
0.015
0.011
0.010
0.083
0.020
0.015
0.011
0.010
0.075
0.020
0.015
0.011
0.010
0.078
0.020
0.015
0.011
0.010

0.972±0.017
0.974±0.013
0.978±0.010
0.985±0.006
0.987±0.006
0.939±0.025
0.978±0.009
0.973±0.009
0.978±0.005
0.976±0.005
0.976±0.011
0.976±0.008
0.973±0.008
0.971±0.005
0.967±0.005
0.964±0.012
0.979±0.006
0.975±0.006
0.956±0.003
0.954±0.002
0.971±0.007
0.956±0.004
0.952±0.002
0.951±0.001
0.950±0.001

0.566±0.073
0.487±0.078
0.505±0.079
0.442±0.078
0.413±0.074
0.487±0.075
0.392±0.070
0.410±0.079
0.308±0.072
0.246±0.063
0.530±0.070
0.376±0.074
0.304±0.072
0.175±0.057
0.146±0.053
0.441±0.073
0.352±0.070
0.271±0.066
0.041±0.025
0.031±0.023
0.325±0.061
0.049±0.022
0.017±0.001
0.011±0.000
0.011±0.000

0.077
0.020
0.015
0.011
0.010
0.076
0.020
0.015
0.011
0.010
0.083
0.020
0.015
0.011
0.010
0.075
0.020
0.015
0.011
0.010
0.078
0.020
0.015
0.011
0.010

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Open Category Detection with PAC Guarantees

Table 6. n∗, recall (i.e. alien detection rate) and false positive rate from experiments using 9-dimensional normal data, 90%, bootstrap
LODA

Basic CDF

Iso CDF

Recall

False Positive Rate

Recall

False Positive Rate

n∗

Recall±CI

FPR±CI

Oracle

Recall±CI

FPR±CI

Oracle

242739
2059638
3398545
9739214
11575949
27002
255234
426176
2440377
4972658
18177
123537
140581
2329443
2968332
9199
59467
178906
786472
1349754
13581
13945
96151
227331
537171

0.719±0.048
0.872±0.022
0.863±0.017
0.900±0.013
0.911±0.012
0.841±0.031
0.892±0.014
0.900±0.011
0.914±0.006
0.907±0.005
0.898±0.020
0.910±0.011
0.897±0.009
0.906±0.003
0.905±0.003
0.915±0.016
0.914±0.008
0.911±0.005
0.901±0.002
0.901±0.001
0.921±0.008
0.902±0.004
0.904±0.003
0.900±0.001
0.901±0.001

0.095±0.039
0.082±0.038
0.033±0.020
0.032±0.019
0.030±0.016
0.157±0.048
0.058±0.033
0.018±0.009
0.010±0.005
0.004±0.001
0.152±0.040
0.049±0.027
0.013±0.006
0.004±0.000
0.003±0.000
0.149±0.043
0.021±0.014
0.008±0.001
0.004±0.000
0.003±0.000
0.067±0.010
0.009±0.001
0.006±0.000
0.003±0.000
0.003±0.000

0.045
0.008
0.006
0.003
0.003
0.044
0.008
0.006
0.003
0.003
0.049
0.008
0.006
0.003
0.003
0.043
0.008
0.006
0.003
0.003
0.045
0.008
0.006
0.003
0.003

0.972±0.017
0.969±0.015
0.973±0.012
0.981±0.007
0.980±0.009
0.936±0.026
0.964±0.013
0.957±0.012
0.945±0.009
0.933±0.009
0.969±0.013
0.954±0.012
0.936±0.012
0.915±0.006
0.908±0.004
0.953±0.014
0.942±0.010
0.923±0.008
0.901±0.002
0.901±0.001
0.934±0.009
0.902±0.004
0.904±0.003
0.900±0.001
0.901±0.001

0.564±0.073
0.484±0.079
0.487±0.079
0.411±0.076
0.359±0.072
0.460±0.074
0.359±0.070
0.365±0.077
0.188±0.063
0.130±0.052
0.487±0.070
0.303±0.069
0.175±0.057
0.053±0.033
0.014±0.016
0.393±0.071
0.189±0.059
0.078±0.039
0.004±0.000
0.003±0.000
0.148±0.042
0.009±0.001
0.006±0.000
0.003±0.000
0.003±0.000

0.045
0.008
0.006
0.003
0.003
0.044
0.008
0.006
0.003
0.003
0.049
0.008
0.006
0.003
0.003
0.043
0.008
0.006
0.003
0.003
0.045
0.008
0.006
0.003
0.003

α

0.01

0.05

0.10

0.20

0.50

n

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

Table 7. 1st quartile, median, 3rd quartile of false positive rate from experiments using 9-dimensional normal data, 95%, Iforest

Open Category Detection with PAC Guarantees

Basic CDF
False Positive Rate

n 1st quartile median

3rd quartile Oracle(median)

α

0.01

0.05

0.1

0.2

0.5

100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000
100
500
1000
5000
10000

0.004
0.002
0.002
0.002
0.003
0.006
0.004
0.004
0.006
0.008
0.015
0.006
0.005
0.009
0.011
0.025
0.010
0.008
0.010
0.012
0.040
0.012
0.011
0.013
0.013

0.006
0.004
0.004
0.004
0.006
0.014
0.008
0.008
0.010
0.011
0.032
0.012
0.009
0.013
0.014
0.043
0.018
0.011
0.013
0.013
0.058
0.016
0.012
0.014
0.014

0.014
0.015
0.010
0.013
0.014
0.043
0.023
0.015
0.020
0.019
0.094
0.021
0.014
0.020
0.017
0.105
0.031
0.018
0.015
0.015
0.090
0.021
0.016
0.016
0.015

0.051
0.015
0.012
0.014
0.014
0.050
0.015
0.012
0.014
0.014
0.049
0.015
0.012
0.014
0.014
0.049
0.015
0.012
0.014
0.014
0.051
0.015
0.012
0.014
0.014

Open Category Detection with PAC Guarantees

Table 8. Recall (i.e. alien detection rate) & False Positive Rate for Image Datasets,98%

Dataset

α

ˆα

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Tiny Image Net
n=10000

MNIST
n=11154

Tiny Image Net
n=10000

MNIST
n=11154

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.926 ± 0.014
0.933 ± 0.013
0.941 ± 0.012
0.965 ± 0.005
0.970 ± 0.004
0.977 ± 0.004
0.976 ± 0.003
0.982 ± 0.002
0.987 ± 0.002

0.981 ± 0.006
0.987 ± 0.005
0.991 ± 0.004
0.983 ± 0.004
0.990 ± 0.003
0.997 ± 0.001
0.983 ± 0.003
0.993 ± 0.002
0.999 ± 0.001

0.677 ± 0.030
0.695 ± 0.030
0.715 ± 0.029
0.738 ± 0.018
0.761 ± 0.018
0.787 ± 0.017
0.766 ± 0.011
0.793 ± 0.011
0.822 ± 0.010

0.466 ± 0.041
0.518 ± 0.044
0.573 ± 0.049
0.444 ± 0.030
0.511 ± 0.037
0.610 ± 0.038
0.416 ± 0.014
0.504 ± 0.024
0.655 ± 0.030

0.944 ± 0.013
0.952 ± 0.012
0.959 ± 0.011
0.972 ± 0.005
0.977 ± 0.004
0.983 ± 0.003
0.978 ± 0.003
0.983 ± 0.002
0.988 ± 0.002

0.987 ± 0.006
0.991 ± 0.005
0.994 ± 0.003
0.986 ± 0.004
0.992 ± 0.003
0.998 ± 0.001
0.983 ± 0.003
0.993 ± 0.002
0.999 ± 0.001

0.746 ± 0.034
0.766 ± 0.033
0.786 ± 0.031
0.774 ± 0.021
0.798 ± 0.019
0.825 ± 0.018
0.776 ± 0.012
0.802 ± 0.011
0.833 ± 0.010

0.569 ± 0.061
0.628 ± 0.061
0.691 ± 0.060
0.483 ± 0.041
0.567 ± 0.045
0.684 ± 0.040
0.421 ± 0.015
0.519 ± 0.028
0.683 ± 0.032

0.902 ± 0.014
0.912 ± 0.014
0.923 ± 0.013
0.942 ± 0.006
0.949 ± 0.005
0.957 ± 0.005
0.948 ± 0.003
0.956 ± 0.003
0.964 ± 0.002

0.971 ± 0.007
0.977 ± 0.006
0.984 ± 0.005
0.966 ± 0.005
0.976 ± 0.004
0.986 ± 0.003
0.957 ± 0.003
0.972 ± 0.003
0.987 ± 0.002

0.620 ± 0.025
0.639 ± 0.026
0.660 ± 0.026
0.667 ± 0.016
0.683 ± 0.014
0.706 ± 0.014
0.669 ± 0.007
0.689 ± 0.007
0.714 ± 0.007

0.404 ± 0.032
0.432 ± 0.033
0.477 ± 0.036
0.361 ± 0.017
0.397 ± 0.018
0.455 ± 0.023
0.334 ± 0.005
0.373 ± 0.007
0.441 ± 0.012

0.924 ± 0.014
0.930 ± 0.014
0.939 ± 0.012
0.948 ± 0.006
0.954 ± 0.005
0.962 ± 0.005
0.949 ± 0.003
0.957 ± 0.003
0.965 ± 0.002

0.975 ± 0.007
0.982 ± 0.006
0.988 ± 0.005
0.967 ± 0.005
0.977 ± 0.004
0.988 ± 0.003
0.957 ± 0.003
0.973 ± 0.003
0.988 ± 0.002

0.686 ± 0.032
0.697 ± 0.031
0.716 ± 0.031
0.682 ± 0.016
0.700 ± 0.015
0.722 ± 0.015
0.672 ± 0.007
0.692 ± 0.007
0.718 ± 0.007

0.448 ± 0.042
0.488 ± 0.045
0.542 ± 0.048
0.368 ± 0.018
0.410 ± 0.022
0.477 ± 0.028
0.334 ± 0.005
0.375 ± 0.007
0.444 ± 0.012

Table 9. Recall (i.e. alien detection rate) & False Positive Rate for Image Datasets,95%

Dataset

α

ˆα

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Open Category Detection with PAC Guarantees

Table 10. Recall (i.e. alien detection rate) & False Positive Rate for Image Datasets,90%

Dataset

α

ˆα

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Tiny Image Net
n=10000

MNIST
n=11154

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.862 ± 0.015
0.873 ± 0.015
0.885 ± 0.014
0.894 ± 0.007
0.904 ± 0.007
0.915 ± 0.006
0.898 ± 0.003
0.907 ± 0.003
0.919 ± 0.003

0.949 ± 0.008
0.958 ± 0.007
0.967 ± 0.007
0.928 ± 0.005
0.942 ± 0.004
0.958 ± 0.004
0.912 ± 0.003
0.929 ± 0.003
0.949 ± 0.003

0.545 ± 0.021
0.562 ± 0.021
0.579 ± 0.021
0.578 ± 0.011
0.593 ± 0.010
0.609 ± 0.010
0.577 ± 0.004
0.590 ± 0.004
0.608 ± 0.004

0.328 ± 0.020
0.352 ± 0.022
0.378 ± 0.024
0.282 ± 0.006
0.306 ± 0.007
0.341 ± 0.010
0.260 ± 0.003
0.284 ± 0.003
0.317 ± 0.004

0.883 ± 0.016
0.892 ± 0.015
0.902 ± 0.014
0.898 ± 0.007
0.909 ± 0.006
0.919 ± 0.006
0.899 ± 0.003
0.908 ± 0.003
0.920 ± 0.003

0.954 ± 0.008
0.962 ± 0.007
0.971 ± 0.007
0.929 ± 0.005
0.944 ± 0.004
0.960 ± 0.004
0.912 ± 0.003
0.930 ± 0.003
0.949 ± 0.003

0.590 ± 0.027
0.602 ± 0.026
0.617 ± 0.025
0.584 ± 0.011
0.600 ± 0.011
0.617 ± 0.011
0.578 ± 0.004
0.591 ± 0.004
0.609 ± 0.004

0.342 ± 0.024
0.366 ± 0.025
0.395 ± 0.027
0.285 ± 0.007
0.309 ± 0.008
0.345 ± 0.011
0.260 ± 0.003
0.284 ± 0.003
0.317 ± 0.004

Open Category Detection with PAC Guarantees

Table 11. Recall & False Positive Rate for Landsat Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Landsat
n=1532

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.937 ± 0.024
0.949 ± 0.024
0.960 ± 0.024
0.965 ± 0.005
0.980 ± 0.003
0.989 ± 0.002
0.971 ± 0.013
0.985 ± 0.012
0.991 ± 0.012

0.924 ± 0.024
0.936 ± 0.024
0.950 ± 0.024
0.942 ± 0.006
0.964 ± 0.004
0.981 ± 0.003
0.948 ± 0.013
0.969 ± 0.012
0.986 ± 0.012

0.888 ± 0.025
0.906 ± 0.024
0.927 ± 0.024
0.902 ± 0.007
0.928 ± 0.005
0.953 ± 0.005
0.899 ± 0.012
0.927 ± 0.012
0.957 ± 0.012

0.162 ± 0.047
0.203 ± 0.048
0.255 ± 0.050
0.128 ± 0.033
0.204 ± 0.040
0.301 ± 0.047
0.114 ± 0.021
0.267 ± 0.033
0.480 ± 0.039

0.127 ± 0.041
0.157 ± 0.044
0.202 ± 0.047
0.069 ± 0.020
0.112 ± 0.027
0.201 ± 0.039
0.046 ± 0.008
0.095 ± 0.015
0.250 ± 0.029

0.089 ± 0.036
0.106 ± 0.038
0.136 ± 0.041
0.034 ± 0.008
0.047 ± 0.012
0.076 ± 0.018
0.029 ± 0.008
0.035 ± 0.008
0.055 ± 0.008

0.960 ± 0.024
0.967 ± 0.024
0.972 ± 0.024
0.983 ± 0.005
0.991 ± 0.003
0.996 ± 0.001
0.981 ± 0.013
0.989 ± 0.012
0.993 ± 0.012

0.952 ± 0.025
0.959 ± 0.024
0.966 ± 0.024
0.964 ± 0.006
0.980 ± 0.004
0.991 ± 0.002
0.952 ± 0.013
0.976 ± 0.012
0.989 ± 0.012

0.924 ± 0.025
0.938 ± 0.025
0.953 ± 0.025
0.918 ± 0.009
0.941 ± 0.007
0.966 ± 0.005
0.899 ± 0.012
0.927 ± 0.012
0.960 ± 0.012

0.495 ± 0.068
0.543 ± 0.064
0.583 ± 0.062
0.404 ± 0.062
0.478 ± 0.061
0.557 ± 0.057
0.323 ± 0.055
0.491 ± 0.051
0.658 ± 0.041

0.430 ± 0.067
0.463 ± 0.065
0.506 ± 0.064
0.271 ± 0.057
0.337 ± 0.056
0.425 ± 0.055
0.094 ± 0.028
0.209 ± 0.038
0.385 ± 0.041

0.323 ± 0.064
0.345 ± 0.064
0.380 ± 0.063
0.115 ± 0.037
0.151 ± 0.040
0.216 ± 0.044
0.030 ± 0.008
0.036 ± 0.008
0.076 ± 0.015

Open Category Detection with PAC Guarantees

Table 12. Recall & False Positive Rate for page.blocks Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

pageblocks
n=4912

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.963 ± 0.021
0.969 ± 0.017
0.976 ± 0.013
0.966 ± 0.005
0.978 ± 0.004
0.989 ± 0.003
0.971 ± 0.004
0.986 ± 0.002
0.994 ± 0.001

0.945 ± 0.031
0.958 ± 0.024
0.967 ± 0.018
0.945 ± 0.007
0.963 ± 0.005
0.978 ± 0.004
0.945 ± 0.004
0.966 ± 0.003
0.985 ± 0.002

0.908 ± 0.027
0.928 ± 0.021
0.947 ± 0.022
0.899 ± 0.007
0.922 ± 0.007
0.946 ± 0.006
0.901 ± 0.005
0.922 ± 0.004
0.948 ± 0.004

0.254 ± 0.084
0.315 ± 0.138
0.357 ± 0.137
0.287 ± 0.031
0.367 ± 0.038
0.468 ± 0.041
0.261 ± 0.028
0.384 ± 0.035
0.531 ± 0.038

0.218 ± 0.070
0.259 ± 0.100
0.304 ± 0.117
0.204 ± 0.019
0.258 ± 0.025
0.338 ± 0.031
0.173 ± 0.012
0.228 ± 0.020
0.339 ± 0.027

0.153 ± 0.030
0.187 ± 0.049
0.222 ± 0.071
0.139 ± 0.007
0.161 ± 0.010
0.201 ± 0.016
0.125 ± 0.004
0.143 ± 0.005
0.174 ± 0.008

0.983 ± 0.013
0.991 ± 0.006
0.995 ± 0.004
0.978 ± 0.005
0.987 ± 0.003
0.994 ± 0.002
0.980 ± 0.004
0.991 ± 0.002
0.996 ± 0.001

0.964 ± 0.029
0.975 ± 0.018
0.985 ± 0.012
0.955 ± 0.007
0.972 ± 0.005
0.985 ± 0.004
0.950 ± 0.005
0.972 ± 0.004
0.989 ± 0.002

0.939 ± 0.027
0.943 ± 0.024
0.959 ± 0.023
0.905 ± 0.008
0.929 ± 0.007
0.954 ± 0.006
0.903 ± 0.005
0.924 ± 0.004
0.951 ± 0.004

0.555 ± 0.201
0.624 ± 0.181
0.712 ± 0.159
0.452 ± 0.053
0.529 ± 0.050
0.626 ± 0.045
0.411 ± 0.048
0.532 ± 0.047
0.655 ± 0.043

0.419 ± 0.210
0.458 ± 0.201
0.551 ± 0.185
0.291 ± 0.040
0.362 ± 0.042
0.448 ± 0.043
0.217 ± 0.029
0.303 ± 0.034
0.423 ± 0.036

0.245 ± 0.105
0.253 ± 0.102
0.305 ± 0.119
0.162 ± 0.017
0.190 ± 0.020
0.243 ± 0.026
0.127 ± 0.005
0.148 ± 0.008
0.190 ± 0.013

Open Category Detection with PAC Guarantees

Table 13. Recall & False Positive Rate for Optical.digits Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Optical.digits
n=568

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.898 ± 0.016
0.906 ± 0.013
0.917 ± 0.013
0.938 ± 0.011
0.953 ± 0.008
0.968 ± 0.007
0.966 ± 0.006
0.979 ± 0.004
0.989 ± 0.003

0.887 ± 0.016
0.892 ± 0.014
0.906 ± 0.013
0.924 ± 0.011
0.936 ± 0.009
0.955 ± 0.008
0.946 ± 0.006
0.964 ± 0.005
0.980 ± 0.004

0.840 ± 0.021
0.866 ± 0.015
0.879 ± 0.014
0.883 ± 0.013
0.905 ± 0.010
0.926 ± 0.010
0.904 ± 0.007
0.925 ± 0.006
0.951 ± 0.006

0.167 ± 0.035
0.186 ± 0.036
0.214 ± 0.036
0.177 ± 0.033
0.220 ± 0.039
0.270 ± 0.041
0.254 ± 0.041
0.339 ± 0.045
0.439 ± 0.048

0.146 ± 0.033
0.166 ± 0.033
0.188 ± 0.034
0.135 ± 0.025
0.165 ± 0.029
0.212 ± 0.034
0.149 ± 0.024
0.219 ± 0.031
0.319 ± 0.040

0.119 ± 0.029
0.132 ± 0.031
0.151 ± 0.032
0.080 ± 0.012
0.104 ± 0.018
0.138 ± 0.024
0.072 ± 0.006
0.096 ± 0.009
0.150 ± 0.019

0.947 ± 0.016
0.950 ± 0.013
0.957 ± 0.012
0.964 ± 0.010
0.973 ± 0.008
0.983 ± 0.006
0.978 ± 0.006
0.986 ± 0.004
0.994 ± 0.002

0.948 ± 0.015
0.944 ± 0.014
0.952 ± 0.013
0.954 ± 0.010
0.963 ± 0.009
0.974 ± 0.007
0.959 ± 0.007
0.974 ± 0.006
0.986 ± 0.004

0.910 ± 0.021
0.928 ± 0.016
0.937 ± 0.015
0.916 ± 0.015
0.936 ± 0.011
0.953 ± 0.010
0.916 ± 0.009
0.936 ± 0.008
0.960 ± 0.006

0.502 ± 0.070
0.519 ± 0.066
0.549 ± 0.065
0.434 ± 0.065
0.466 ± 0.063
0.511 ± 0.061
0.441 ± 0.061
0.517 ± 0.058
0.606 ± 0.053

0.459 ± 0.068
0.481 ± 0.066
0.504 ± 0.065
0.342 ± 0.059
0.381 ± 0.059
0.432 ± 0.060
0.290 ± 0.049
0.356 ± 0.049
0.443 ± 0.049

0.403 ± 0.067
0.413 ± 0.065
0.430 ± 0.065
0.237 ± 0.050
0.264 ± 0.050
0.300 ± 0.050
0.129 ± 0.026
0.168 ± 0.031
0.233 ± 0.036

Open Category Detection with PAC Guarantees

Table 14. Recall & False Positive Rate for Letter Recognition Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Letter recognition
n=788

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.897 ± 0.018
0.918 ± 0.013
0.931 ± 0.012
0.940 ± 0.011
0.954 ± 0.008
0.969 ± 0.006
0.968 ± 0.006
0.983 ± 0.004
0.993 ± 0.003

0.885 ± 0.020
0.904 ± 0.015
0.919 ± 0.013
0.912 ± 0.013
0.934 ± 0.010
0.954 ± 0.008
0.946 ± 0.006
0.967 ± 0.005
0.984 ± 0.004

0.857 ± 0.020
0.875 ± 0.017
0.892 ± 0.016
0.875 ± 0.014
0.900 ± 0.011
0.923 ± 0.010
0.901 ± 0.007
0.925 ± 0.006
0.953 ± 0.005

0.232 ± 0.044
0.255 ± 0.045
0.291 ± 0.047
0.197 ± 0.032
0.235 ± 0.035
0.281 ± 0.039
0.242 ± 0.029
0.335 ± 0.038
0.448 ± 0.044

0.205 ± 0.042
0.223 ± 0.041
0.252 ± 0.043
0.156 ± 0.024
0.188 ± 0.027
0.229 ± 0.034
0.147 ± 0.012
0.208 ± 0.020
0.306 ± 0.032

0.152 ± 0.031
0.172 ± 0.033
0.197 ± 0.036
0.111 ± 0.016
0.132 ± 0.018
0.158 ± 0.022
0.099 ± 0.004
0.117 ± 0.005
0.155 ± 0.010

0.953 ± 0.016
0.967 ± 0.010
0.975 ± 0.008
0.964 ± 0.011
0.974 ± 0.007
0.983 ± 0.006
0.977 ± 0.006
0.989 ± 0.003
0.996 ± 0.002

0.949 ± 0.015
0.958 ± 0.012
0.965 ± 0.010
0.944 ± 0.013
0.960 ± 0.009
0.973 ± 0.008
0.956 ± 0.007
0.974 ± 0.005
0.988 ± 0.004

0.929 ± 0.018
0.939 ± 0.016
0.949 ± 0.014
0.905 ± 0.015
0.928 ± 0.012
0.950 ± 0.010
0.906 ± 0.008
0.932 ± 0.006
0.959 ± 0.006

0.596 ± 0.069
0.613 ± 0.067
0.633 ± 0.065
0.457 ± 0.066
0.490 ± 0.063
0.537 ± 0.061
0.430 ± 0.056
0.525 ± 0.055
0.639 ± 0.049

0.550 ± 0.069
0.570 ± 0.066
0.587 ± 0.065
0.375 ± 0.060
0.407 ± 0.059
0.455 ± 0.059
0.245 ± 0.039
0.334 ± 0.043
0.432 ± 0.046

0.473 ± 0.067
0.490 ± 0.066
0.519 ± 0.066
0.236 ± 0.045
0.280 ± 0.048
0.326 ± 0.051
0.110 ± 0.008
0.145 ± 0.015
0.203 ± 0.023

Open Category Detection with PAC Guarantees

Table 15. Recall & False Positive Rate for Shuttle Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Shuttle
n=5000

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.959 ± 0.008
0.971 ± 0.006
0.984 ± 0.005
0.975 ± 0.004
0.990 ± 0.002
0.998 ± 0.001
0.980 ± 0.002
0.996 ± 0.001
1.000 ± 0.000

0.937 ± 0.009
0.958 ± 0.007
0.974 ± 0.006
0.949 ± 0.005
0.973 ± 0.004
0.992 ± 0.002
0.949 ± 0.002
0.976 ± 0.002
0.997 ± 0.001

0.901 ± 0.012
0.923 ± 0.010
0.947 ± 0.008
0.903 ± 0.004
0.928 ± 0.004
0.958 ± 0.004
0.899 ± 0.002
0.925 ± 0.002
0.959 ± 0.002

0.145 ± 0.031
0.205 ± 0.038
0.287 ± 0.048
0.100 ± 0.016
0.195 ± 0.033
0.355 ± 0.042
0.090 ± 0.014
0.238 ± 0.028
0.540 ± 0.032

0.095 ± 0.017
0.137 ± 0.027
0.200 ± 0.036
0.064 ± 0.004
0.093 ± 0.011
0.186 ± 0.028
0.061 ± 0.001
0.082 ± 0.006
0.220 ± 0.022

0.056 ± 0.006
0.072 ± 0.010
0.105 ± 0.019
0.047 ± 0.001
0.054 ± 0.002
0.068 ± 0.004
0.047 ± 0.001
0.054 ± 0.001
0.065 ± 0.001

0.973 ± 0.007
0.984 ± 0.006
0.991 ± 0.003
0.982 ± 0.004
0.994 ± 0.002
0.999 ± 0.001
0.982 ± 0.002
0.997 ± 0.001
1.000 ± 0.000

0.957 ± 0.009
0.972 ± 0.007
0.983 ± 0.005
0.956 ± 0.006
0.979 ± 0.004
0.995 ± 0.002
0.949 ± 0.002
0.977 ± 0.002
0.998 ± 0.001

0.917 ± 0.013
0.939 ± 0.011
0.960 ± 0.009
0.905 ± 0.004
0.931 ± 0.005
0.963 ± 0.004
0.899 ± 0.002
0.925 ± 0.002
0.959 ± 0.002

0.425 ± 0.065
0.490 ± 0.065
0.550 ± 0.064
0.317 ± 0.058
0.451 ± 0.058
0.578 ± 0.052
0.154 ± 0.031
0.396 ± 0.042
0.642 ± 0.034

0.326 ± 0.059
0.370 ± 0.059
0.435 ± 0.059
0.142 ± 0.034
0.224 ± 0.043
0.365 ± 0.045
0.061 ± 0.001
0.104 ± 0.016
0.290 ± 0.028

0.187 ± 0.047
0.216 ± 0.047
0.266 ± 0.049
0.048 ± 0.002
0.064 ± 0.008
0.111 ± 0.020
0.047 ± 0.001
0.054 ± 0.001
0.066 ± 0.001

Open Category Detection with PAC Guarantees

Table 16. Recall & False Positive Rate for Covertype Dataset using LODA for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Covertype
n=13624

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.979 ± 0.002
0.995 ± 0.001
0.999 ± 0.000
0.980 ± 0.001
0.998 ± 0.000
1.000 ± 0.000
0.981 ± 0.001
0.998 ± 0.000
1.000 ± 0.000

0.951 ± 0.002
0.978 ± 0.001
0.997 ± 0.001
0.951 ± 0.001
0.979 ± 0.001
0.999 ± 0.000
0.952 ± 0.001
0.980 ± 0.001
0.999 ± 0.000

0.900 ± 0.003
0.930 ± 0.001
0.965 ± 0.001
0.901 ± 0.002
0.929 ± 0.001
0.965 ± 0.001
0.901 ± 0.002
0.929 ± 0.001
0.965 ± 0.001

0.010 ± 0.003
0.098 ± 0.025
0.292 ± 0.045
0.007 ± 0.002
0.142 ± 0.026
0.423 ± 0.044
0.009 ± 0.001
0.212 ± 0.029
0.560 ± 0.037

0.002 ± 0.000
0.012 ± 0.004
0.112 ± 0.026
0.003 ± 0.000
0.008 ± 0.002
0.153 ± 0.025
0.006 ± 0.000
0.012 ± 0.002
0.199 ± 0.023

0.002 ± 0.000
0.002 ± 0.000
0.004 ± 0.001
0.002 ± 0.000
0.002 ± 0.000
0.004 ± 0.000
0.005 ± 0.000
0.005 ± 0.000
0.007 ± 0.000

0.989 ± 0.002
0.998 ± 0.001
0.999 ± 0.000
0.987 ± 0.002
0.999 ± 0.000
1.000 ± 0.000
0.984 ± 0.002
0.999 ± 0.000
1.000 ± 0.000

0.963 ± 0.004
0.987 ± 0.002
0.998 ± 0.000
0.952 ± 0.002
0.983 ± 0.001
1.000 ± 0.000
0.952 ± 0.001
0.981 ± 0.001
1.000 ± 0.000

0.904 ± 0.004
0.937 ± 0.004
0.973 ± 0.003
0.901 ± 0.002
0.929 ± 0.001
0.965 ± 0.001
0.901 ± 0.002
0.929 ± 0.001
0.965 ± 0.001

0.373 ± 0.072
0.470 ± 0.066
0.586 ± 0.059
0.220 ± 0.056
0.419 ± 0.057
0.618 ± 0.047
0.134 ± 0.044
0.438 ± 0.050
0.676 ± 0.036

0.164 ± 0.051
0.277 ± 0.059
0.411 ± 0.060
0.017 ± 0.016
0.114 ± 0.035
0.319 ± 0.045
0.006 ± 0.000
0.050 ± 0.015
0.307 ± 0.034

0.025 ± 0.019
0.055 ± 0.029
0.121 ± 0.038
0.002 ± 0.000
0.002 ± 0.000
0.011 ± 0.004
0.005 ± 0.000
0.005 ± 0.000
0.008 ± 0.001

Open Category Detection with PAC Guarantees

Table 17. Recall & False Positive Rate for Landsat Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Landsat
n=1532

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.941 ± 0.024
0.950 ± 0.024
0.960 ± 0.024
0.965 ± 0.005
0.979 ± 0.003
0.989 ± 0.002
0.970 ± 0.012
0.985 ± 0.012
0.991 ± 0.012

0.923 ± 0.024
0.936 ± 0.024
0.951 ± 0.024
0.945 ± 0.006
0.964 ± 0.004
0.980 ± 0.003
0.949 ± 0.012
0.969 ± 0.012
0.986 ± 0.012

0.887 ± 0.024
0.906 ± 0.024
0.926 ± 0.024
0.903 ± 0.007
0.927 ± 0.005
0.952 ± 0.005
0.901 ± 0.012
0.926 ± 0.012
0.957 ± 0.012

0.164 ± 0.045
0.197 ± 0.048
0.254 ± 0.051
0.130 ± 0.033
0.199 ± 0.040
0.304 ± 0.048
0.109 ± 0.018
0.266 ± 0.034
0.477 ± 0.039

0.130 ± 0.042
0.161 ± 0.045
0.204 ± 0.047
0.074 ± 0.022
0.117 ± 0.029
0.198 ± 0.037
0.044 ± 0.007
0.094 ± 0.015
0.253 ± 0.029

0.088 ± 0.036
0.107 ± 0.038
0.135 ± 0.041
0.032 ± 0.005
0.047 ± 0.012
0.075 ± 0.018
0.030 ± 0.008
0.034 ± 0.008
0.054 ± 0.008

0.964 ± 0.025
0.968 ± 0.024
0.971 ± 0.024
0.982 ± 0.004
0.991 ± 0.003
0.996 ± 0.002
0.979 ± 0.012
0.989 ± 0.012
0.993 ± 0.012

0.950 ± 0.025
0.959 ± 0.025
0.967 ± 0.024
0.965 ± 0.006
0.979 ± 0.004
0.991 ± 0.003
0.953 ± 0.012
0.976 ± 0.012
0.989 ± 0.012

0.919 ± 0.025
0.936 ± 0.025
0.953 ± 0.025
0.915 ± 0.009
0.942 ± 0.007
0.967 ± 0.005
0.901 ± 0.012
0.927 ± 0.012
0.960 ± 0.012

0.503 ± 0.066
0.545 ± 0.065
0.584 ± 0.063
0.402 ± 0.063
0.477 ± 0.060
0.556 ± 0.057
0.323 ± 0.054
0.488 ± 0.051
0.655 ± 0.042

0.423 ± 0.069
0.467 ± 0.066
0.509 ± 0.064
0.265 ± 0.056
0.332 ± 0.055
0.425 ± 0.054
0.095 ± 0.028
0.212 ± 0.038
0.386 ± 0.041

0.309 ± 0.063
0.346 ± 0.064
0.388 ± 0.063
0.110 ± 0.036
0.153 ± 0.040
0.216 ± 0.044
0.030 ± 0.008
0.037 ± 0.009
0.081 ± 0.016

Open Category Detection with PAC Guarantees

Table 18. Recall & False Positive Rate for page.blocks Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

page.blocks
n=4912

0.100
0.100
0.100

0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108

0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020

0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.951 ± 0.029
0.968 ± 0.018
0.976 ± 0.013

0.965 ± 0.005
0.979 ± 0.004
0.989 ± 0.002
0.970 ± 0.004
0.985 ± 0.002
0.995 ± 0.001

0.949 ± 0.025
0.958 ± 0.021
0.969 ± 0.018
0.946 ± 0.007
0.962 ± 0.005
0.978 ± 0.004
0.945 ± 0.005
0.966 ± 0.003
0.985 ± 0.002

0.903 ± 0.035
0.927 ± 0.025
0.951 ± 0.024
0.900 ± 0.007
0.922 ± 0.007
0.947 ± 0.006
0.900 ± 0.005
0.922 ± 0.004
0.948 ± 0.004

0.269 ± 0.106
0.314 ± 0.130
0.366 ± 0.138

0.283 ± 0.030
0.366 ± 0.037
0.465 ± 0.041
0.260 ± 0.028
0.381 ± 0.035
0.530 ± 0.039

0.239 ± 0.096
0.261 ± 0.101
0.297 ± 0.117
0.207 ± 0.019
0.258 ± 0.025
0.338 ± 0.031
0.173 ± 0.013
0.228 ± 0.019
0.339 ± 0.028

0.155 ± 0.040
0.177 ± 0.044
0.222 ± 0.068
0.138 ± 0.006
0.160 ± 0.010
0.201 ± 0.016
0.128 ± 0.004
0.143 ± 0.006
0.174 ± 0.008

0.975 ± 0.017
0.991 ± 0.007
0.994 ± 0.005

0.976 ± 0.005
0.986 ± 0.004
0.994 ± 0.002
0.978 ± 0.004
0.990 ± 0.002
0.996 ± 0.001

0.968 ± 0.022
0.975 ± 0.018
0.986 ± 0.012
0.956 ± 0.007
0.971 ± 0.005
0.984 ± 0.003
0.951 ± 0.005
0.972 ± 0.004
0.989 ± 0.002

0.927 ± 0.030
0.948 ± 0.027
0.962 ± 0.022
0.906 ± 0.008
0.930 ± 0.007
0.955 ± 0.006
0.902 ± 0.006
0.924 ± 0.004
0.951 ± 0.004

0.511 ± 0.220
0.641 ± 0.184
0.692 ± 0.175

0.443 ± 0.052
0.527 ± 0.051
0.622 ± 0.046
0.403 ± 0.049
0.531 ± 0.048
0.655 ± 0.042

0.401 ± 0.176
0.448 ± 0.189
0.529 ± 0.179
0.298 ± 0.040
0.364 ± 0.042
0.446 ± 0.042
0.215 ± 0.027
0.299 ± 0.034
0.424 ± 0.037

0.216 ± 0.111
0.248 ± 0.117
0.317 ± 0.123
0.158 ± 0.016
0.192 ± 0.020
0.246 ± 0.027
0.130 ± 0.006
0.147 ± 0.008
0.190 ± 0.014

Open Category Detection with PAC Guarantees

Table 19. Recall & False Positive Rate for Optical.digits Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Optical.digits
n=568

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.891 ± 0.018
0.904 ± 0.013
0.917 ± 0.012
0.941 ± 0.010
0.951 ± 0.008
0.965 ± 0.007
0.968 ± 0.006
0.979 ± 0.004
0.990 ± 0.003

0.882 ± 0.018
0.896 ± 0.014
0.910 ± 0.013
0.920 ± 0.012
0.938 ± 0.009
0.954 ± 0.008
0.946 ± 0.007
0.963 ± 0.005
0.979 ± 0.004

0.856 ± 0.017
0.867 ± 0.015
0.886 ± 0.014
0.883 ± 0.012
0.907 ± 0.010
0.927 ± 0.009
0.899 ± 0.008
0.926 ± 0.005
0.952 ± 0.005

0.172 ± 0.036
0.191 ± 0.036
0.214 ± 0.037
0.178 ± 0.032
0.218 ± 0.037
0.268 ± 0.040
0.250 ± 0.039
0.338 ± 0.045
0.442 ± 0.047

0.148 ± 0.033
0.164 ± 0.034
0.192 ± 0.036
0.139 ± 0.026
0.168 ± 0.030
0.211 ± 0.034
0.149 ± 0.024
0.220 ± 0.033
0.315 ± 0.039

0.113 ± 0.027
0.127 ± 0.030
0.146 ± 0.031
0.083 ± 0.014
0.106 ± 0.018
0.140 ± 0.025
0.071 ± 0.005
0.097 ± 0.009
0.151 ± 0.018

0.940 ± 0.017
0.952 ± 0.012
0.961 ± 0.011
0.964 ± 0.010
0.974 ± 0.008
0.983 ± 0.006
0.978 ± 0.006
0.986 ± 0.004
0.994 ± 0.002

0.933 ± 0.018
0.945 ± 0.013
0.952 ± 0.012
0.953 ± 0.012
0.964 ± 0.009
0.973 ± 0.008
0.960 ± 0.007
0.974 ± 0.005
0.986 ± 0.004

0.920 ± 0.018
0.928 ± 0.016
0.938 ± 0.014
0.917 ± 0.014
0.935 ± 0.011
0.953 ± 0.009
0.911 ± 0.009
0.937 ± 0.007
0.961 ± 0.006

0.504 ± 0.068
0.521 ± 0.066
0.548 ± 0.065
0.424 ± 0.065
0.465 ± 0.064
0.520 ± 0.063
0.451 ± 0.061
0.519 ± 0.058
0.608 ± 0.054

0.462 ± 0.068
0.481 ± 0.066
0.500 ± 0.065
0.365 ± 0.061
0.386 ± 0.059
0.441 ± 0.060
0.288 ± 0.050
0.357 ± 0.049
0.443 ± 0.049

0.387 ± 0.066
0.407 ± 0.065
0.433 ± 0.064
0.227 ± 0.050
0.264 ± 0.049
0.305 ± 0.050
0.123 ± 0.024
0.163 ± 0.030
0.230 ± 0.035

Open Category Detection with PAC Guarantees

Table 20. Recall & False Positive Rate for Letter Recognition Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Letter recog
n=788

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.911 ± 0.016
0.919 ± 0.013
0.931 ± 0.012
0.936 ± 0.011
0.954 ± 0.008
0.968 ± 0.007
0.971 ± 0.005
0.984 ± 0.004
0.993 ± 0.003

0.884 ± 0.019
0.903 ± 0.015
0.918 ± 0.014
0.915 ± 0.013
0.936 ± 0.009
0.955 ± 0.008
0.944 ± 0.007
0.966 ± 0.005
0.984 ± 0.004

0.862 ± 0.020
0.876 ± 0.018
0.891 ± 0.016
0.879 ± 0.013
0.899 ± 0.011
0.922 ± 0.010
0.902 ± 0.007
0.924 ± 0.006
0.951 ± 0.006

0.234 ± 0.044
0.262 ± 0.046
0.297 ± 0.048
0.203 ± 0.034
0.236 ± 0.036
0.288 ± 0.042
0.240 ± 0.029
0.334 ± 0.039
0.448 ± 0.044

0.208 ± 0.041
0.223 ± 0.041
0.252 ± 0.043
0.162 ± 0.025
0.190 ± 0.029
0.231 ± 0.034
0.152 ± 0.013
0.208 ± 0.019
0.307 ± 0.031

0.160 ± 0.034
0.174 ± 0.034
0.198 ± 0.036
0.113 ± 0.016
0.132 ± 0.019
0.160 ± 0.022
0.098 ± 0.004
0.117 ± 0.005
0.154 ± 0.010

0.960 ± 0.013
0.965 ± 0.011
0.973 ± 0.009
0.961 ± 0.011
0.975 ± 0.008
0.983 ± 0.006
0.979 ± 0.005
0.989 ± 0.003
0.996 ± 0.002

0.949 ± 0.017
0.959 ± 0.012
0.966 ± 0.011
0.943 ± 0.013
0.960 ± 0.009
0.974 ± 0.007
0.954 ± 0.007
0.974 ± 0.005
0.988 ± 0.004

0.930 ± 0.019
0.939 ± 0.016
0.951 ± 0.013
0.906 ± 0.014
0.928 ± 0.012
0.949 ± 0.010
0.907 ± 0.007
0.931 ± 0.006
0.959 ± 0.006

0.588 ± 0.070
0.603 ± 0.067
0.627 ± 0.065
0.444 ± 0.065
0.487 ± 0.064
0.534 ± 0.062
0.429 ± 0.057
0.525 ± 0.054
0.636 ± 0.048

0.552 ± 0.069
0.563 ± 0.067
0.582 ± 0.065
0.376 ± 0.062
0.410 ± 0.060
0.455 ± 0.059
0.250 ± 0.040
0.328 ± 0.042
0.435 ± 0.046

0.475 ± 0.067
0.492 ± 0.066
0.512 ± 0.065
0.238 ± 0.047
0.281 ± 0.049
0.324 ± 0.050
0.110 ± 0.009
0.139 ± 0.013
0.203 ± 0.024

Open Category Detection with PAC Guarantees

Table 21. Recall & False Positive Rate for Shuttle Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Shuttle
n=5000

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.959 ± 0.008
0.972 ± 0.006
0.984 ± 0.004
0.975 ± 0.004
0.990 ± 0.002
0.998 ± 0.001
0.979 ± 0.002
0.996 ± 0.001
1.000 ± 0.000

0.941 ± 0.009
0.957 ± 0.008
0.973 ± 0.006
0.949 ± 0.005
0.973 ± 0.004
0.992 ± 0.002
0.948 ± 0.002
0.976 ± 0.002
0.997 ± 0.001

0.899 ± 0.011
0.923 ± 0.010
0.946 ± 0.009
0.902 ± 0.005
0.928 ± 0.004
0.958 ± 0.004
0.899 ± 0.002
0.925 ± 0.002
0.958 ± 0.002

0.147 ± 0.031
0.206 ± 0.039
0.287 ± 0.047
0.103 ± 0.016
0.192 ± 0.033
0.361 ± 0.043
0.089 ± 0.013
0.237 ± 0.028
0.541 ± 0.032

0.097 ± 0.018
0.135 ± 0.027
0.202 ± 0.037
0.063 ± 0.004
0.093 ± 0.011
0.187 ± 0.028
0.060 ± 0.002
0.083 ± 0.006
0.218 ± 0.022

0.057 ± 0.005
0.073 ± 0.010
0.104 ± 0.018
0.047 ± 0.001
0.054 ± 0.001
0.069 ± 0.004
0.049 ± 0.001
0.054 ± 0.001
0.065 ± 0.001

0.974 ± 0.007
0.985 ± 0.005
0.991 ± 0.003
0.983 ± 0.004
0.994 ± 0.002
0.999 ± 0.001
0.981 ± 0.002
0.997 ± 0.001
1.000 ± 0.000

0.956 ± 0.009
0.971 ± 0.007
0.984 ± 0.005
0.957 ± 0.005
0.979 ± 0.004
0.995 ± 0.002
0.949 ± 0.002
0.977 ± 0.002
0.998 ± 0.001

0.917 ± 0.013
0.938 ± 0.011
0.960 ± 0.009
0.904 ± 0.005
0.931 ± 0.004
0.963 ± 0.004
0.899 ± 0.002
0.926 ± 0.002
0.959 ± 0.002

0.419 ± 0.066
0.490 ± 0.065
0.545 ± 0.064
0.326 ± 0.058
0.457 ± 0.058
0.572 ± 0.053
0.151 ± 0.030
0.394 ± 0.042
0.642 ± 0.034

0.319 ± 0.059
0.371 ± 0.059
0.439 ± 0.060
0.150 ± 0.035
0.221 ± 0.042
0.368 ± 0.044
0.061 ± 0.002
0.106 ± 0.016
0.291 ± 0.027

0.180 ± 0.046
0.211 ± 0.047
0.273 ± 0.050
0.048 ± 0.001
0.066 ± 0.009
0.114 ± 0.020
0.049 ± 0.001
0.054 ± 0.001
0.066 ± 0.001

Open Category Detection with PAC Guarantees

Table 22. Recall & False Positive Rate for Covertype Dataset using Iforest for varying q (target recall 1 − q)

Dataset

α

ˆα

q

recall±CI

FPR±CI

recall±CI

FPR±CI

Basic CDF

Iso CDF

Recall

False Positive Rate Recall

False Positive Rate

Covertype
n=13624

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.100
0.100
0.200
0.200
0.200
0.400
0.400
0.400

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.100
0.104
0.108
0.200
0.204
0.208
0.400
0.404
0.408

0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020
0.020

0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050
0.050

0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100
0.100

0.979 ± 0.002
0.995 ± 0.001
0.999 ± 0.000
0.980 ± 0.001
0.998 ± 0.000
1.000 ± 0.000
0.981 ± 0.001
0.998 ± 0.000
1.000 ± 0.000

0.950 ± 0.002
0.978 ± 0.001
0.997 ± 0.001
0.950 ± 0.001
0.980 ± 0.001
0.999 ± 0.000
0.951 ± 0.001
0.980 ± 0.001
0.999 ± 0.000

0.901 ± 0.002
0.930 ± 0.001
0.965 ± 0.001
0.902 ± 0.002
0.929 ± 0.001
0.964 ± 0.001
0.903 ± 0.001
0.929 ± 0.001
0.964 ± 0.001

0.012 ± 0.007
0.095 ± 0.025
0.292 ± 0.045
0.006 ± 0.002
0.143 ± 0.027
0.427 ± 0.043
0.010 ± 0.001
0.206 ± 0.030
0.555 ± 0.038

0.002 ± 0.000
0.012 ± 0.004
0.110 ± 0.025
0.003 ± 0.000
0.008 ± 0.002
0.154 ± 0.026
0.006 ± 0.000
0.012 ± 0.002
0.200 ± 0.022

0.002 ± 0.000
0.002 ± 0.000
0.004 ± 0.001
0.002 ± 0.000
0.002 ± 0.000
0.003 ± 0.000
0.005 ± 0.000
0.005 ± 0.000
0.007 ± 0.000

0.989 ± 0.002
0.998 ± 0.001
0.999 ± 0.000
0.986 ± 0.002
0.999 ± 0.000
1.000 ± 0.000
0.985 ± 0.002
0.999 ± 0.000
1.000 ± 0.000

0.962 ± 0.004
0.987 ± 0.002
0.998 ± 0.000
0.952 ± 0.002
0.983 ± 0.001
1.000 ± 0.000
0.951 ± 0.001
0.981 ± 0.001
1.000 ± 0.000

0.905 ± 0.004
0.937 ± 0.004
0.973 ± 0.003
0.902 ± 0.002
0.929 ± 0.001
0.965 ± 0.001
0.903 ± 0.001
0.929 ± 0.001
0.964 ± 0.001

0.359 ± 0.072
0.479 ± 0.067
0.586 ± 0.059
0.211 ± 0.055
0.420 ± 0.058
0.615 ± 0.047
0.136 ± 0.044
0.437 ± 0.051
0.677 ± 0.036

0.166 ± 0.051
0.276 ± 0.058
0.409 ± 0.060
0.018 ± 0.014
0.115 ± 0.035
0.319 ± 0.045
0.006 ± 0.000
0.050 ± 0.015
0.310 ± 0.034

0.028 ± 0.022
0.055 ± 0.029
0.123 ± 0.038
0.002 ± 0.000
0.002 ± 0.000
0.011 ± 0.003
0.005 ± 0.000
0.005 ± 0.000
0.007 ± 0.001

