L2-Net: Deep Learning of Discriminative Patch Descriptor in Euclidean Space

Yurun Tian1,2 Bin Fan1

Fuchao Wu1

1National Laboratory of Pattern Recognition, Institute of Automation,
Chinese Academy of Sciences, Beijing, China
2University of Chinese Academy of Science, Beijing, China
{yurun.tian,bfan,fcwu}@nlpr.ia.ac.cn

Abstract

The research focus of designing local patch descriptors
has gradually shifted from handcrafted ones (e.g., SIFT) to
learned ones. In this paper, we propose to learn high per-
formance descriptor in Euclidean space via the Convolu-
tional Neural Network (CNN). Our method is distinctive in
four aspects: (i) We propose a progressive sampling strat-
egy which enables the network to access billions of train-
ing samples in a few epochs.
(ii) Derived from the ba-
sic concept of local patch matching problem, we empha-
(iii) Extra
size the relative distance between descriptors.
supervision is imposed on the intermediate feature maps.
(iv) Compactness of the descriptor is taken into account.
The proposed network is named as L2-Net since the out-
put descriptor can be matched in Euclidean space by L2
distance. L2-Net achieves state-of-the-art performance on
the Brown datasets [16], Oxford dataset [18] and the new-
ly proposed Hpatches dataset [11]. The good generaliza-
tion ability shown by experiments indicates that L2-Net can
serve as a direct substitution of the existing handcrafted de-
scriptors. The pre-trained L2-Net is publicly available1.

1. Introduction

Comparing local patches across images is at the base of
various computer vision problems, such as wide-baseline
matching [17], image retrieval [19] and object recognition
[8]. Ever since the advent of the famous SIFT [15] de-
scriptor, encoding local image patches into representative
vectors, i.e., descriptors, has been the dominating method.
Desired descriptors should be invariant (e.g., robust to view
point change, illumination change, or other photometric and
geometric changes) for matching patches and distinctive for
non-matching patches.

Along with the booming of handcrafted descriptors in
the past decade, more and more learning based descriptors

1https://github.com/yuruntian/L2-Net

appear [12, 24, 20, 16, 21, 7]. Different from handcraft-
ed descriptors which are mostly driven by intuition or re-
searcher’s expertise, learning based methods are driven by
data. Deep learning has revolutionized many research areas
[6, 14], and the public available of large scale dataset with
ground truth correspondences [16, 18] makes deep learning
possible for local patch matching. The application of Con-
volutional Neural Network (CNN) for local patch match-
ing can be divided into two categories by whether there are
metric learning layers. CNNs with metric learning layers
[10, 25, 9] typically treat the matching of local patch pairs
as binary classiﬁcation, so there does not exist the concept
of descriptor. An obvious drawback of these models is that
they can not perform nearest neighbor search (NNS). On the
other hand, CNNs without metric learning layers [2, 5, 9]
(i.e., the output descriptors can be matched by L2 distance)
can be used as a direct replacement to previous handcrafted
descriptors in many applications, such as the fast approx-
imate nearest neighbor matching (e.g., KD-tree) for large
scale structure from motion and the bag of visual words re-
lated applications. On the widely used Brown dataset [16],
however, models with metric learning generally perform
better, and the gap is non-ignorable. Moreover, the general-
ization of the CNN based descriptors to other datasets(e.g.,
Oxford dataset [18]) does not show overwhelming superior-
ity to handcrafted descriptors.

As most matching tasks require NNS, we aim at learning
high performance descriptor that can be matched by L2 dis-
tance. The proposed L2-Net is a CNN based model without
metric learning layers, and it outputs 128 dimensional de-
scriptors, which can be directly matched by L2 distance.
In this paper, we draw inspiration from the basic concept
of matching: for a certain local patch, to ﬁnd its matching
counterpart is to do NNS in the descriptor space. Thus, all
we need to do is to make sure that the descriptors of match-
ing pairs to be the nearest neighbor (under speciﬁc metric
like L2 distance in this paper) of each other, while the mag-
nitude of distance does not really matters. The essence be-
hind this inspiration is relative distance. Although the con-

1661

cept of relative distance is not new, its potentiality in de-
scriptor matching and other related applications is far from
being fully explored. Following this idea, we train L2-Net
by optimizing the relative distance among descriptors in a
batch. Speciﬁcally, L2-Net transforms a batch of patches
into a batch of descriptors, for each descriptor, our training
strategy aims at making its nearest neighbor in a batch to
be its correct matching descriptor. In this way, it is actu-
ally a one-vs-many operation which considers distances a-
mong many patch pairs, going beyond the widely used pair-
wise or triplet-wise operation [10, 25, 2, 5]. The training of
L2-Net is built on a progressive sampling strategy (section
3.3) and a loss function (section 3.4) consists of three error
terms. The proposed progressive sampling strategy can be
implemented by just one matrix multiplication, which en-
ables fast access to billions of patch pairs in a few dozens
of training epochs. As far as we know, the only method-
s that may share some common concept with ours are [9]
and [27]. However, [9] works on the distribution of match-
ing and non-matching pairs while we emphasis on speciﬁc
pairs, which is more sensitive. The sampling strategy of
[27] leads to a non-convex loss function that can not be op-
timized directly. By comparison, our sampling strategy is
fast, efﬁcient and easy to implement. Besides, we integrate
three error terms in the loss function: one term accounts for
the relative distance among descriptors, one term controls
descriptor compactness as well as overﬁtting, and one term
is an extra supervision imposed on the intermediate feature
maps, which is named as Discriminative Intermediate Fea-
ture maps (DIF). The proposed network is very powerful
although not very deep, it achieves state-of-the-art perfor-
mance on several standard benchmark datasets, receiving
signiﬁcant improvement over previous descriptors and even
surpassing those CNN models with metric learning layers.
The L2-Net descriptor can be used as a direct substitution
of existing handcrafted descriptors since it also uses L2 dis-
tance.

2. Related work

The research of designing local descriptor has gradually
moved from handcrafted ones to learning based ones. Since
the purpose of this paper is descriptor learning, below we
give a brief review of descriptor learning methods in the
literatures, ranging from traditional methods to the recently
proposed CNN based methods. For handcrafted descriptors,
please refer to [18] for an overview of classical methods and
[13] for recent advances.

Traditional descriptor learning. Early efforts in learn-
ing descriptors are not restricted to any speciﬁc machine
learning method, thus leading to a lot of unique works.
PCA-SIFT [12] applies Principal Components Analysis (P-
CA) to the normalized gradient patch instead of directly
using smoothed weighted histograms like SIFT. ASD [24]

assumes that local patches under various afﬁne transforma-
tions lie in a subspace and PCA is used to extract the base of
the subspace as descriptor. [20, 16] emphasizes the learning
of pooling region and dimensionality reduction, achieving
remarkable performance. Besides ﬂoat descriptors, there
are also learned binary descriptors. BOLD [3] presents a
method for adaptive online selection of binary intensity tests
so that each bit ensures low variance for intra-class and high
variance for inter-class. In Binboost [21], each bit of the
descriptor is computed by a boosted binary hash function.
RFD [7] proposes to do binary test on the most discrim-
inative receptive ﬁelds based on the labeled training data.
RMGD [26] introduces a kind of spatial ring-region based
pooling method for binary intensity tests, together with an
extended Adaboost bit selection. [29] presents a formula-
tion for patch description based on sparse quantization. All
the descriptors mentioned above start learning from low lev-
el features like gradient or pure binary intensity test, thus,
inevitably suffering from information loss. With the help of
CNN, we can learn descriptor directly from the raw image
patches.

CNN based descriptor learning. Recently, Siamese
and triplet networks are the main stream architectures in C-
NN based descriptor learning. To improve performance, a
fully connected layer acting as a metric network is favored
by many researchers. MatchNet [10], a typical Siamese
network, consists of a feature network for extracting fea-
ture representation, a bottleneck layer for reducing feature
dimension, and a metric network for measuring similarity
of features pairs. It signiﬁcantly improves previous results,
showing a great potential of CNN in descriptor learning. Al-
so based on Siamese network, [25] gose further than Match-
Net. It explores different kinds of network architectures and
proposes to use a kind of central-surround structure to im-
prove performance. [9] uses triplet network and proposes a
global loss function to separate the distribution of matching
and non-matching pairs. Together with the metric learn-
ing layer and the central surround structure, [9] achieves
the currently best performance on the Brown [16] dataset.
Despite metric learning improves matching ability, it also
limits the versatility of the network. To solve this problem,
networks trained without metric learning layers have been
proposed. DeepDesc [5] trains the network using L2 dis-
tance by adopting a mining strategy to select hard patches.
However, it essentially requires huge amounts of training
data to ensure performance. PN-Net [2] uses triplet CNN
with a softPN loss that optimizes the distances among patch
triplets. Our work also aims to get rid of the metric network
and learn high performance descriptor that can be matched
by L2 distance.

662

at least 2 matching patches. Brown dataset consists of three
subsets, namely, Yosemite, Notredame, and Liberty. Usu-
ally, one of the subsets is picked as training set and the
other two subsets are used for testing. The training data
of HPatches dataset is composed of four subsets, namely,
train-hard (easy) -viewpoint, and train-hard (easy) -illum,
indicating that the patches exhibit viewpoint and illumina-
tion changes with different degrees. Since the label of its
test data is not published at the time we ﬁnish this paper,
we just use HPatches as training set. There are approxi-
mately 500K (1.5M) and 190K (1.2M) 3D points (patch-
es) in Brown dataset and HPatches dataset respectively. All
patches are down sampled to the size of 32 × 32 for train-
ing. Based on our experiments, we did not notice any per-
formance degeneration caused by shrinking the patch size.
For each patch, we remove the pixel mean calculated across
all the training patches, and then contrast normalization is
applied, i.e., subtracted by the mean and divided by the s-
tandard deviation.

3.3. Progressive sampling of training data

In local patch matching problem, the number of poten-
tial non-matching (negative) patches is orders of magni-
tude larger than the number of matching (positive) patch-
es. Due to the so large amount of negative pairs, it is im-
possible to traverse all of them, therefore a good sampling
strategy is very crucial. Existing methods typically sam-
ple equal numbers of positive and negative pairs in train-
ing, while the proposed progressive sampling strategy is to
break the balance by sampling more negative pairs. Sup-
pose there are P 3D points in the training set. In each it-
eration, we take p1 points from the whole set sequentially
to traverse all the P points, and then we take an extra of
p2 points form the rest P − p1 points randomly. The ran-
domness brought by the extra p2 points gives the network
a chance to go over what it has learned and be prepared for
what it will learn. To form a training batch, we randomly
pick a pair of matching patches for each of the p (equals
to p1 + p2) points (thus there are 2p patches in a batch).
Let X =
be the
2D patches in a batch, where the subscript is the 3D point
index and the superscript is the 2D patch index (e.g., x1
i
and x2
i represents a matching pair from 3D point i). Given
X as input to L2-Net, the output descriptors is denoted as
Y =
i , · · · , y1
, where q is the
dimension of the descriptor (128 in this paper). Note that
Y is a batch of unit vectors as the output layer of L2-Net
is LRN. Thus, we deﬁne the distance matrix D = [dij]p×p,
(∥∥2 is L2 norm), and D can be
where dij =
2
computed by one simple matrix multiplication as
(cid:13)
(cid:13)

1, · · ·, y1

1, · · ·, x1

i , · · · , x1

y2
i − y1
j

1, y2
y1

1, x2
x1

32×32×2p

p, y2
p

p, x2
p

i , x2

i , y2

q×2p

(cid:13)
(cid:13)

{

}

[

]

D =

2

1 − YT

1 Y2

√

(

)

(1)

663

Figure 1. Network Architecture. 3×3 Conv = Convolution +Batch
Normalization + Relu. 8 × 8 Conv = Convolution +Batch Normal-
ization.

3. L2-Net

In this section, we describe in detail of the architecture,
training data, sampling strategy, loss function and training
of the proposed L2-Net.

3.1. Network architecture

The architecture of L2-Net is depicted in Fig. 1-(a). It
takes an all convolution structure, and down sampling is
achieved by stride 2 convolution. Batch normalization (B-
N) [28] is used after each convolutional layer, but with mi-
nor modiﬁcations, i.e., we do not update the weighting and
bias parameters of the BN layers and ﬁx them to be 1 and
0 respectively. Since normalization is an important step in
designing descriptors, we use a Local Response Normal-
ization layer (LRN) as the output layer to produce unit de-
scriptors. L2-Net converts 32 × 32 input patches to 128
dimensional descriptors . As in [25, 9], we also implement
a central-surround (CS) L2-Net. It is the concatenation of
two separate L2-Nets with a two tower structure as shown
in Fig. 1-(b). The input of the tower on the left is the same
with a solo L2-Net, while the input of the tower on the right
is generated by cropping and resizing the central part of the
original patches.

3.2. Training data and preprocessing

For network training, we use the Brown dataset [16]
and the newly proposed HPatches dataset [11]. These two
datasets are composed of local patches extracted from dif-
ferent scenes. Although diverse in properties, they organize
patches in the same way: (i) Each patch in the dataset has
a unique 3D point index, patches with identical 3D point
index are matching ones. (ii) For each 3D point, there are

[

]

1, · · ·, ys
ys

where Ys =
i , · · · , ys
q×p, (s = 1, 2). As a re-
p
sult, D contains distances of p2 pairs, namely p positive
pairs as the diagonal elements and p2 − p negative pairs as
the off-diagonal elements. For a typical training set with
160K 3D points, with p set to be 128, it means that each
training epoch consists of 2500 batches.
In each epoch,
over 40M (1282 × 2500) pairs are fed to the network. In
our experiments, L2-Net typically needs about 40 training
epochs. This indicates that about 1.6 billions pairs (despite
the inevitable repetition as a result of randomness, it is still a
huge number) are used for training, with the overwhelming
majority to be negative pairs and positive pairs only takes
up 12.8M (128 × 2500 × 40).

A possible question would be why we use YT
1

Y2 instead
of YTY to compute D. It is because that if YTY is used,
the diagonal elements of D will be all zeros (distances be-
tween identical patches), and all positive and negative pairs
would be distributed on the off-diagonal elements, making
the calculation of the gradient troublesome. In fact, our ear-
ly work used YTY, however, it does not show superiority
in performance than using YT

1 Y2.

3.4. Loss function

Built upon the progressive sampling strategy, our loss
function integrates three objectives. First, we use relative
distance to separate matching and non-matching pairs. Sec-
ond, we emphasize compactness of the output descriptor,
which means that all dimensions of the descriptor should be
less correlated. Finally, instead of just concentrating on the
ﬁnal output, we also impose constraints on the intermedi-
ate feature maps to achieve better performance. According
to these objectives, we design three error terms in the loss
function.

1) Error term for descriptor similarity. This error ter-
m is based on relative distance, i.e., the nearest neighbor of
each descriptor in the batch should be its matching counter-
part. In D, it would be ideal if

min
(i,j)∈[1,p]

{dik, dkj} = dkk

Equation (2) means that the diagonal element dkk should
be the smallest among the kth row and kth coloum. It is
equivalent to

min
i∈[1,p]
min
j∈[1,p]

{dik} = dkk

{dkj} = dkk






For easy implementation, we operate on columns and
rows separately. Deﬁne the column similarity matrix
Sc = [sc
ij]p×p and the row similarity matrix Sr = [sr
ij]p×p
as

sc
ij = exp(2 − dij)/
sr
ij = exp(2 − dij)/

exp(2 − dmj)

exp(2 − djn)

m
∑
n
∑

(2)

(3)

(4)

664

i is matched to y1

where 2 is the maximum L2 distance between two unit vec-
tors. In equation (4), sc
ij can be interpreted as the probabili-
ty that y2
ij is the probability that y1
i
is matched to y2
j . By applying softmax function to each col-
umn and each row of D, we can get Sc and Sr respectively.
The error term for descriptor similarity is deﬁned as

j , and sr

E1 = −

log sc

ii +

log sr
ii

(5)

1
2 (

i
∑

i
∑

)

E1 encourages the descriptors to be closer to their matching
counterparts in Euclidean space, while ignoring the speciﬁc
magnitude of distances, which is the essence of NNS.

2) Error term for descriptor compactness. As the pro-
gressive sampling strategy gives L2-Net the access to mas-
sive training samples, overﬁtting becomes inevitable in our
initial experiments. An interesting ﬁnding is that the degree
of overﬁtting is directly related to the degree of correlation
among descriptor dimensions. Thus we introduce an error
term that accounts for compactness of the descriptor. By
compactness we mean that there should be less redundancy
among different dimensions and each dimension should car-
ry as much information as possible so that fewer dimension-
s could be used to achieve the same performance. In fact,
compactness is commonly used in the learning of binary de-
scriptors (such as BOLD [7], RFD [3]), which is typically
achieved by greedy selection of bits with high variation. To
make it differentiable, we adopt the correlation matrix. A-
gain, we use Ys instead of Y to guarantee that the descrip-
tors for the computation of correlation matrix come from d-
ifferent 3D points. We denote YT
,
where bs
i is the row vector.

1, · · ·, bs
bs

i , · · ·, bs
q

s as

The correlation matrix Rs = [rs

ij]q×q is deﬁned as

[

]

rs
ij =

(bs

i − ¯bs
i )
i − ¯bs
(bs
i )

T

T

(bs

j − ¯bs
j)
j − ¯bs
(bs
j)

(6)

T

(bj − ¯bs
j)

(bs

i − ¯bs
i )

√
√
where ¯bs
i refers to the mean of the ith row of Ys. The off-
diagonal elements of Rs is expected to be 0, thus we simply
minimize the sum of the squared off-diagonal elements.

E2 =

1
2 

r1
ij

2

+

2

r2
ij



(7)

i̸=j
∑

i̸=j
∑

)

(

(





)
We ﬁnd it is more efﬁcient to put E2 before the LRN
layer, i.e., after the last BN layer. This is because that BN
will normalize each channel by subtracting the mean and
dividing the standard deviation (note that the weighing and
bias are ﬁxed to be 1 and 0). As a result, the computation of
correlation matrix can be simpliﬁed as

Rs = YsYT

s /q

(8)

(9)

(10)

(11)

3) Error term for intermediate feature maps. Existing
CNN based methods only focus on the ﬁnal output descrip-
tors, ignoring the importance of intermediate feature maps.
In this paper, we ﬁnd that it is possible to further increase
the performance of L2-Net with extra supervision informa-
tion provided by the intermediate feature maps. The design
of this error term is driven by the same motivation of E1,
i.e., the intermediate feature maps of a patch should also be
similar for matching pairs, while distinct for non-matching
pairs. Denote the batch of feature maps of the kth layer as
F =
i is the
vectorized feature map with width w and height h, and in-
dex k is omitted for concision. The inner product matrix
G = [gij]p×p for intermediate feature maps is computed as

1, · · ·, f1

i , · · · , f1

, where fs

1, f2
f1

(wh)×2p

p, f2
p

i , f2

[

]

G = (F1)
i , , · · · , fs
where Fs =
p
in equation (3), it would be ideal if
]

1, · · ·, fs
fs

[

TF2

(wh)×p

(s = 1, 2). Like

min
i∈[1,p]
min
j∈[1,p]

{gik} = gkk

{gkj} = gkk






Similarly, relative distance (here measured by inner prod-
uct) is used to build an error term on G. Same to the
deﬁnition of E1, we deﬁne the column similarity ma-
trix Vc = [vc
ij]p×p as well as the row similarity matrix
Vr = [vr

ij]p×p on G, where

vc
ij = exp(gij)/
vr
ij = exp(gij)/

exp(gmj)

exp(gjn)

m
∑
n
∑

Thus, the error term for intermediate feature maps is de-

ﬁned as

E3 = −

log vc

ii +

log vr
ii

(12)

1
2 (

i
∑

i
∑

)

We name this method as Discriminative Intermediate Fea-
ture maps (DIF). Experiments show that it is better to use
DIF on normalized feature maps, so we put DIF on the fea-
ture maps after BN layers, speciﬁcally, only after the ﬁrst
and the last BN layers. This is because that before the ﬁrst
and after the last convolutional layers there are no other
convolutional layers, so the order of feature maps is ﬁxed,
i.e., the ﬁrst convolution is directly applied to the input data
(each channel of the input data has ﬁxed mathematical or
physical meaning) and the output of the last convolutional
layer corresponds to the ﬁnal descriptor. Except for these
two, we do not restrict the ﬂexibility of all other feature
maps.

To sum up, E1 is computed on the ﬁnal output, E2
is computed after the last BN layer, and E3 is comput-
ed after the ﬁrst and the last BN layers. The total loss is
E1 + E2 + E3.

3.5. Training

We train the network from scratch using SGD with a s-
tarting learning rate of 0.01, momentum of 0.9 and weight
decay of 0.0001. The learning rate is divided by 10 every
20 epochs, and the training is done with no more than 50
epochs. For the training of CS L2-Net, we initialize the t-
wo towers using the well trained L2-Net. The parameters of
the left tower in Fig. 1-(b) is ﬁxed and we ﬁne tune the right
tower until convergence. We let p1 = p2 = q/2 = 64, Da-
ta augmentation (optional) is achieved online by randomly
rotating (90, 180, 270 degree) and ﬂipping.

4. Experiments

In this section, we provide comparison of the proposed
model to the state-of-the-arts. Meanwhile, a series of exper-
iments are conducted to analyze the proposed model.

4.1. Brown dataset

We follow the evaluation protocol of [16] by using the
100K pairs provided by the authors and report the false pos-
itive rate at 95% recall. L2-Net is compared with other CN-
N based models with SIFT(results provided by [10]) as the
baseline. Accompany with the ﬂoat L2-Net descriptor, we
further obtain a binary descriptor by simply taking the sign
of the ﬂoat descriptor (±1). The resulting binary descrip-
tors are denoted as Binary L2-Net and Binary CS L2-Net.
To testify the generalization ability of L2-Net, we also train
it on HPatches dataset [11]. Results are listed in Table 1 and
Table 2.

As can be clearly seen from Table 1, L2-Net performs
the best across all the training/testing splits, with remark-
able improvement. Besides CS L2-Net, L2-Net already sur-
passes all models. For the other methods, CS SNet-GLoss
clearly outperforms the remaining ones. However, applying
CS structure to the models with metric learning will intro-
duce extra parameters to the fully connected layers, thus
increasing the time of feature extraction and matching. On
the contrary, for CS L2-Net, we use simple concatenation
without introducing any extra parameter and the two tow-
ers can be used independently. At the same time, binary
L2-Net descriptor signiﬁcantly outperforms those specially
designed binary descriptors, and even surpass all ﬂoat de-
scriptors. Note that the performance of the proposed bina-
ry descriptor can be further increased by a better threshold
rather than 0 or a better hashing method. Although trained
on a totally different dataset (Table 2), L2-Net still achieves
state-of-the-art performance, showing its great generaliza-
tion ability.

4.2. Oxford dataset

In order to further validate the generalization ability of
the proposed network, we test it on another totally different

665

Training
Test

Feature Notredame Yosemite Liberty Yosemite Liberty Notredame

Liberty

Notredame

Yosemite

Mean

SIFT [15]
MatchNet [10]
DeepCompare 2ch-2stream [25] +
DeepCompare 2ch-deep [25] +
SNet-GLoss [9] +
CS SNet-GLoss [9] +

TNet-TGLoss [9] +
TNet-TLoss [9] +
PN-Net [2]
DeepDesc [5]
L2-Net
L2-Net +
CS L2-Net
CS L2-Net +

RFDR [7]
RFDG [7]
BinBoost [21]
RMGD [26]
Boixet al [29]
Binary L2-Net
Binary L2-Net +
Binary CS L2-Net
Binary CS L2-Net +

Dim

128
4096
256
256
256
384

256
256
256
128
128
128
256
256

293-598
406-563
64
1376-1600
1360
128
128
256
256

Metric Learning

29.84

6.9
4.85
4.55
6.39
3.69

10.77
7.20
7.40
8.43
4.91
Float Descriptors
13.45
13.90
9.65

9.91
10.77
8.13

3.64
2.36
2.55
1.71

5.29
4.7
4.24
3.87
Binary Descriptors
19.40
19.03
21.67
17.42
15.52
11.71
10.29
7.83
6.65

19.35
17.77
20.49
15.09
15.6
10.3
7.44
5.25
4.01

22.53

27.29

3.87
1.90
2.01
1.84
0.77

3.91
4.47
3.71

1.15
0.72
0.87
0.56

13.23
12.49
16.90
10.15
-
6.37
3.81
3.07
1.9

5.67
2.11
2.52
2.83
1.14

5.43
5.58
4.23

1.62
1.29
1.39
1.09

11.68
11.37
14.54
10.86
8.52
6.76
4.31
3.52
2.51

10.88
5.00
4.75
6.61
3.09

10.65
11.82
8.99

4.43
2.57
3.81
2.07

16.99
17.62
22.88
14.46
-
13.5
8.81
8.49
5.61

26.55
7.74
4.19
4.26
5.27
2.71

8.8
9.58
6.98
6.99
3.23
2.22
2.61
1.76

15.85
15.4
19.24
13.63
12.12
10.03
7.01
5.84
4.12

8.39
4.10
4.38
5.57
2.67

9.47
10.96
7.21

3.30
1.71
2.84
1.3

14.50
14.14
18.97
13.82
8.87
11.57
7.45
6.92
4.04

10.9

4.40

5.69

Table 1. Performance on the Brown dataset. The numbers are false positive rate at 95% recall. + indicates data augmentation.

Test
L2-Net
L2-Net+
CS L2-Net
CS L2-Net+
Binary L2-Net
Binary L2-Net+
Binary CS L2-Net
Binary CS L2-Net+

Liberty Notredame Yosemite Mean
3.37
2.7
1.97
1.49
10.65
9.08
5.4
4.57

4.41
3.6
2.58
1.85
13.16
11.07
6.91
5.88

4.16
3.2
2.43
1.9
12.4
10.74
6.43
5.4

1.54
1.3
0.92
0.73
6.4
5.44
2.88
2.44

Table 2. Performance of networks on the Brown dataset when they
are trained on HPatches dataset .

dataset, i.e., the Oxford dataset [18]. We evaluate L2-Net on
six image sequences, namely, graf (viewpoint), bikes(blur),
ubc(JPEG compression), leuven(light), boat(zoom and ro-
tation), and wall(viewpoint). In each image sequence, there
are six images sorted in an order of increasing degree of
distortions with respect to the ﬁrst image. Keypoints are de-
tected by Harris-Afﬁne detector and local patches are nor-
malized to the size of 32 × 32 (64 × 64 for DeepDesc [5]

and TNet-TGLoss [9] ) with a scaling factor of 3. We fol-
low strictly the evaluation protocol of [18]. The results of
other methods such as [10, 25] on the same dataset can be
found in [2], where no improvement over PN-Net is ob-
served. One should note that CNN models with speciﬁc
learned metric are not suitable for evaluation on the Oxford
dataset, as the nearest neighbor search can not be well per-
formed using similarity score. For a fair comparison and
without lose of generality, all models are trained on Liberty
(DeepDesc [5] is trained on Liberty and Notredame). Be-
sides learned descriptors, we use LIOP [23] as the baseline
of handcrafted descriptors, since it was reported to surpass
most of the handcrafted descriptors on this dataset. Mean-
while, Binary L2-Net and Binary CS L2-Net are compared
to other state-of-the-art binary descriptors. Moreover, we
report results with different training data. Experimental re-
sults are shown in Fig 2 with mean average precision (mAP)
as performance indicator.

As can be clearly seen from Fig 2, L2-Net outperforms
all the other descriptors on average and even the binary L2-
Net descriptor surpasses all other ﬂoat descriptors. More-
over, there are some other interesting observations: i) The

666

P
A
m

0.9

0.8

0.7

0.6

0.5

0.4

0.3
0.2
0.1

0

graf

bikes

ubc

leuven

wall

boat

average

LIB

ND

YOS

HP

LIOP

DeepDesc

 PN-Net

TNet-TGLoss

L2-Net

CS L2-Net

RFDR

RFDG

 BinBoost

 Binary L2-Net

Binary CS L2-Net

Figure 2. Performance comparison on Oxford dataset in terms of mAP. Performance with respect to different training set is shown in the
right part of the ﬁgure (the average mAP over six image sequence).

CS structure does not guarantee performance improvement
on all datasets and all types of descriptors (ﬂoat and bina-
ry). Since CS structure needs to crop the central part of the
patch, how to choose the scale of the patch becomes a prob-
lem. Patches in Brown dataset and Hpatches dataset are of
similar scale, thus CS structure works ﬁne. However, with
different detector and scale, arbitrarily cropping the central
50% of the patch (can be less textured) may not be a good
choice. ii) In accordance with [4], we also ﬁnd that CNN
based methods is very sensitive to image blur. iii) Hpatches
dataset shows better generalization ability.

4.3. Hpatches dataset

Results of the prototype L2-Net (casia-yt) on the test da-
ta of Hpatches dataset can be found at the webpage of EC-
CV 2016 workshop “Local Features: state of the art, open
problems and performance evaluation” 2, where our method
ranked No.1 in all the three tasks.

4.4. Discussion and analysis

In this section, we discuss how each of the proposed er-
ror terms contributes to the ﬁnal performance and give some
qualitative analysis for the binarized descriptor.

Importance of compactness. We try to train L2-Net
without E2, however, the network does not converge. Due
to the large amount of training samples fed to the network, it
is easier for the network to memorize the training data rather
than learn to generalize. Without E2, strong overﬁtting hap-
pens and the dimensions of the output descriptor are highly
correlated. Therefore, compactness is of crucial importance
to the progressive sampling strategy. By restricting com-
pactness, the network actually tends to extract uncorrelated
features containing more information.

Advantage of relative distance. E1 is quite different
from the widely used hinge loss. Typically, hinge loss for

2http://www.iis.ee.ic.ac.uk/ComputerVision/DescrWorkshop/index.html

patch pair and triplet can be written as

Epair = δij max

0,

yi − yj

− tp

2

+ (1 − δij) max

(
(cid:13)
(cid:13)
0, tn −

(cid:13)
(cid:13)
yi − yj

Etriplet = max

0, 1 −

(

(

−

(cid:13)
(cid:13)
∥yi−y
∥yi−y+

(cid:13)
(cid:13)
i ∥2
i ∥2
+t

)

2

)

)

(13)

where δij equals to 1 if yi and yj are matching, otherwise
δij equals to 0. t, tp, tn are thresholds, whose optimal val-
ues are difﬁcult or even impossible to ﬁnd, so they are most-
ly decided by experience. A major drawback of hinge loss
is the unstable gradient caused by thresholding. As training
proceeds, it is not sure how many samples in a batch are
contributing to the overall gradient, and unstable gradien-
t may lead to a bad local minima. To tackle this problem,
many researchers resort to hard sample mining, however,
the nature of mining is still thresholding (more strict). By
utilizing relative distance, the absolute value of distances
becomes useless, thus there is no need to use thresholds.

Effectiveness of DIF. First, we simply remove E3 from
the error function to prove the effectiveness of DIF, and then
we impose DIF after every BN layer to test its performance.
Comparing curve A with curve B and D in Fig. 3-(b), it
can be found that since DIF can provide more supervision
in training, L2-Net with DIF works consistently better than
that without it. However, DIF can not be over used as it will
limit the solution space of the network.

Batch normalization. The weighting α and bias β are
ﬁxed to be 1 and 0 in our BN layers, as we ﬁnd learn-
ing them makes the output feature maps (and descriptors)
in poor distribution. In this experiment, the weighing and
bias parameters of all BN layers is learned except the two
BN layers before DIF (as DIF depends on the normalized
features). The training procedure is shown by curve C in
Fig. 3-(a). Comparing curve A with C, we can ﬁnd that up-
dating α and bias β leads to minor performance decline. As
an illustration to this phenomenon, suppose a ∼ N (µ1, σ1)
and b ∼ N (µ2, σ2) are two random variables obeying gaus-

667

0.99

0.985

0.98

C
U
A

0.975

0.97

0.965

5

4

3

2

1

4.5

3.5

2.5

1.5

0.5

y
t
i
s
n
e
D
 
y
t
i
l
i

b
a
b
o
r
P

A
B
C
D

0.5

0.4

0.3

0.2

0.1

0

-0.1

-0.2

n
a
e
M

0.96

0

10

40

50

0
-0.5

0.5

-0.3

0

20

20
30
Training Epoch
(a)

0
Range of Value
(b)

40
80
60
Binary Descriptor Bits

(c)

100

120

Figure 3. Model analysis. L2-Net is trained on Hpatches dataset and tested on Brown dataset. (a): Effect of DIF and BN. Area under the
ROC curve (AUC) of different training epoch (averaged over three subsets of Brown dataset) is served as an indicator. Curve A: default
setting. Curve B: default - DIF. Curve C: default + learned BN parameters. Curve D: default + extra DIF. (b): Distribution of the ﬂoat
L2-Net descriptor. (c): Mean of each bit of the binary L2-Net descriptor.

It is not difﬁcult to understand that the
sian distribution.
easiest way to separate them is to increase |µ1 − µ2| while
decrease |σ1| and |σ2|. As a result, learning α and β may
cause the extracted feature to be sharp and non-zero dis-
tributed, which damages the performance. Fixing them is
based on the principal that we want the feature maps (and
descriptors) of different patches to be independent identical-
ly distributed. In this way, the network is forced to extract
features that are highly discriminative rather than biased.

Property of the binarized descriptor. We aim to pro-
vide an insightful explanation for the good performance of
the binarized descriptor, despite the fact that it is just a by-
product of the proposed ﬂoat descriptor. Thus, we randomly
select 100K patches from different 3D points to investigate
the value distribution of the proposed descriptor. Fig. 3-(b)
shows that the output values of the L2-Net approximately
obey the Gaussion distribution with zero mean. In Fig. 3-
(c), each bit of the binarized descriptor has a mean near
0, which is highly desirable for a good binary descriptor.
Moreover, we know that hamming distance can be comput-
ed by inner product (for vectors consist of +1 and -1) and
DIF is just built on inner product, which means there could
be strong connections between DIF and the performance of
the binary descriptor. We will leave the in depth analysis in
the future work.

4.5. Trianing and extraction speed

We use a GTX 970 GPU in MatConvNet [22]. L2-Net
reaches maximum performance in 20 to 50 epochs. With-
out online data augmentation, it takes only 2 to 4 hours (4
to 6 hours with online data augmentation). Note that with
a more powerful GPU, the training time will undoubtedly
reduce. L2-Net can extract descriptors at the speed of ap-
proximately 21.3K patch/sec.

5. Conclsion

In this paper, we propose a new data-driven descriptor
that can be matched in Euclidean space and signiﬁcant-
ly outperforms state-of-the-arts.
Its good performance is
mainly attributed to a new progressive sampling strategy
and a dedicated loss function containing three terms. By
progressive sampling, we manage to visit billions of train-
ing samples. By going back to the basic concept of match-
ing (NNS), we thoroughly explore the information in each
batch. By requiring compactness, we successfully handle
overﬁtting. By utilizing intermediate feature maps, we fur-
ther boost the performance. Moreover, a powerful bina-
ry descriptor is obtained by directly taking the sign of the
learned ﬂoat descriptor, which gives the best performance
among existing binary descriptors and even outperforms
most ﬂoat descriptors. Finally, L2-Net should be further
extended to more applications such as image classiﬁcation
and retrieval. We will leave these problems as the future
work.

6. Acknowledgments

This work was supported by the National High Tech-
nology Research and Development Program of China (863
Program 2015AA020504) and the National Natural Sci-
ence Foundation of China (Nos. 61375043, 61672032,
61472119, 61403375). Y. Tian thanks Shenglong Guo and
Chenhua Li for some useful discussions.

References

[1] J. Bromley, I. Guyon,Y. LeCun, E. Sckinger, and
R. Shah. Signature veriﬁcation using a siamese time
delay neural network. In NIPS, 1994.

[2] V. Balntas, E. Johns, L. Tangand K. Mikolajczyk. PN-
Net: Conjoined triple deep network for learning local
image descriptors. Arxiv, 2016. 1, 2, 6

668

[3] V. Balntas, L. Tang, and K. Mikolajczyk. Bold: binary
online learned descriptor for efﬁcient image matching.
In CVPR, 2015. 2, 4

[18] K. Mikolajczyk and C. Schmid. A performance e-
valuation of local descriptors. PAMI, pages 257–263,
2003. 1, 2, 6

[19] J. Philbin, O. Chum, M. Isard, J. Sivic, and A. Zisser-
man. Object retrieval with large vocabularies and fast
spatial matching. In CVPR, 2007. 1

[20] K. Simonyan, A. Vedaldi, and A. Zisserman. Learn-
ing local feature descriptors using convex optimisa-
tion. IEEE Transactions on Pattern Analysis and Ma-
chine Intelligence, 2014. 1, 2

[21] T. Trzcinski, M. Christoudias, P. Fua, and V. Lep-
etit. Boosting Binary Keypoint Descriptors. In CVPR,
2013. 1, 2, 6

[22] A. Vedaldi and K. Lenc. Matconvnet - convolutional
neural net-works for matlab. CoRR, abs/1412.4564. 8
[23] Z. Wang, B. Fan, and F. Wu. Local intensity order
pattern for feature description. In ICCV, 2011. 6
[24] Z. Wang, B. Fan, and F. Wu. Afﬁne subspace repre-
sentation for feature description. In ECCV, 2014. 1,
2

[25] S. Zagoruyko and N. Komodakis. Learning to com-
pare image patches via convolutional neural networks.
In CVPR, 2015. 1, 2, 3, 6

[26] Y. Gao, W. Huang, and Y. Qiao Local Multi-Grouped
Binary Descriptor with Ring-based Pooling Conﬁgu-
ration and Optimization. IEEE Transactions on Image
Processing, 24(12):4280–4833, Jan 2014. 2, 6
[27] H. O. Song, Y. Xiang, S. Jegelka, S. Savarese Deep
Metric Learning via Lifted structured feature Embed-
ding. In CVPR, 2016 2

[28] Ioffe, Sergey and Szegedy, Christian. Batch normal-
ization: Accelerating deep network training by reduc-
ing internal covariate shift. Arxiv, 2015. 3

[29] X. Boix, M. Gygli, G. Roig and L. V. Gool. Sparse
Quantization for Patch Description. In CVPR, 2013.
2, 6

[4] A. Dosovitskiy, P. Fischer,

Jost. Springenberg,
M. Riedmiller, and T. Brox Discriminative Unsuper-
vised Feature Learning with Exemplar Convolutional
Neural Network Arxiv, 2015 7

[5] E. Simo-Serra, E. Trulls, L. Ferraz, I. Kokkinos,
P. Fua, and F. Moreno-Noguer. Discriminative learn-
ing of deep convolutional feature point descriptors. In
ICCV, 2015. 1, 2, 6

[6] D. Erhan, C. Szegedy, A. Toshev, and D. Anguelov
Scalable object detection using deep neural networks.
In CVPR, 2014. 1

[7] B. Fan, Q. Kong, T. Trzcinski, Z. Wang, C. Pan, and
P. Fua. Receptive ﬁelds selection for binary feature
description. TIP, 23(6):2583–2595, 2014. 1, 2, 4, 6

[8] R. Fergus, P. Perona, and A. Zisserman. Object class
recognition by unsupervised scale-invariant learning.
In CVPR, 2003. 1

[9] V. Kumar B G, G. Carneiro, and I. Reid. Learn-
ing local image descriptors with deep siamese and
triplet convolutional networks by minimising global
loss functions. In CVPR, 2016. 1, 2, 3, 6

[10] X. Han, T. Leung, Y. Jia, R. Sukthankar, and
A.C. Berg. Matchnet: Unifying feature and metric
learning for patch-based matching. In CVPR, 2015. 1,
2, 5, 6

[11] V. Balntas, K. Lenc, A. Vedaldi and K. Mikolajczyk.
HPatches: A benchmark and evaluation of handcraft-
ed and learned local descriptors. In CVPR, 2017. 1, 3,
5

[12] Y. Ke and R. Sukthankar. Pca-sift: A more distinctive
representation for local image descriptors. In CVPR,
2004. 1, 2

[13] B. Fan, Z. Wang and F. Wu. Local Image Descriptor:

Modern Approaches. Springer, 2015. 2

[14] A. Krizhevsky, I. Sutskever, and G. E. Hinton.

Im-
agenet classiﬁcation with deep convolutional neural
networks. In NIPS, 2012. 1

[15] D. Lowe. Distinctive image features from scale-

invariant keypoints. IJCV, 20(2), 2004. 1, 6

[16] M. Brown, G. Hua and S.A.G. Winder. Discrimina-
tive learning of local image descriptors. IEEE Trans-
actions on Pattern Analysis and Machine Intelligence,
2010. 1, 2, 3, 5

[17] J. Matas and O. Chum. Robust wide-baseline stereo
from maximally stable extremal regions. Image and
Vision Computing, 22(10), 2004. 1

669

L2-Net: Deep Learning of Discriminative Patch Descriptor in Euclidean Space

Yurun Tian1,2 Bin Fan1

Fuchao Wu1

1National Laboratory of Pattern Recognition, Institute of Automation,
Chinese Academy of Sciences, Beijing, China
2University of Chinese Academy of Science, Beijing, China
{yurun.tian,bfan,fcwu}@nlpr.ia.ac.cn

Abstract

The research focus of designing local patch descriptors
has gradually shifted from handcrafted ones (e.g., SIFT) to
learned ones. In this paper, we propose to learn high per-
formance descriptor in Euclidean space via the Convolu-
tional Neural Network (CNN). Our method is distinctive in
four aspects: (i) We propose a progressive sampling strat-
egy which enables the network to access billions of train-
ing samples in a few epochs.
(ii) Derived from the ba-
sic concept of local patch matching problem, we empha-
(iii) Extra
size the relative distance between descriptors.
supervision is imposed on the intermediate feature maps.
(iv) Compactness of the descriptor is taken into account.
The proposed network is named as L2-Net since the out-
put descriptor can be matched in Euclidean space by L2
distance. L2-Net achieves state-of-the-art performance on
the Brown datasets [16], Oxford dataset [18] and the new-
ly proposed Hpatches dataset [11]. The good generaliza-
tion ability shown by experiments indicates that L2-Net can
serve as a direct substitution of the existing handcrafted de-
scriptors. The pre-trained L2-Net is publicly available1.

1. Introduction

Comparing local patches across images is at the base of
various computer vision problems, such as wide-baseline
matching [17], image retrieval [19] and object recognition
[8]. Ever since the advent of the famous SIFT [15] de-
scriptor, encoding local image patches into representative
vectors, i.e., descriptors, has been the dominating method.
Desired descriptors should be invariant (e.g., robust to view
point change, illumination change, or other photometric and
geometric changes) for matching patches and distinctive for
non-matching patches.

Along with the booming of handcrafted descriptors in
the past decade, more and more learning based descriptors

1https://github.com/yuruntian/L2-Net

appear [12, 24, 20, 16, 21, 7]. Different from handcraft-
ed descriptors which are mostly driven by intuition or re-
searcher’s expertise, learning based methods are driven by
data. Deep learning has revolutionized many research areas
[6, 14], and the public available of large scale dataset with
ground truth correspondences [16, 18] makes deep learning
possible for local patch matching. The application of Con-
volutional Neural Network (CNN) for local patch match-
ing can be divided into two categories by whether there are
metric learning layers. CNNs with metric learning layers
[10, 25, 9] typically treat the matching of local patch pairs
as binary classiﬁcation, so there does not exist the concept
of descriptor. An obvious drawback of these models is that
they can not perform nearest neighbor search (NNS). On the
other hand, CNNs without metric learning layers [2, 5, 9]
(i.e., the output descriptors can be matched by L2 distance)
can be used as a direct replacement to previous handcrafted
descriptors in many applications, such as the fast approx-
imate nearest neighbor matching (e.g., KD-tree) for large
scale structure from motion and the bag of visual words re-
lated applications. On the widely used Brown dataset [16],
however, models with metric learning generally perform
better, and the gap is non-ignorable. Moreover, the general-
ization of the CNN based descriptors to other datasets(e.g.,
Oxford dataset [18]) does not show overwhelming superior-
ity to handcrafted descriptors.

As most matching tasks require NNS, we aim at learning
high performance descriptor that can be matched by L2 dis-
tance. The proposed L2-Net is a CNN based model without
metric learning layers, and it outputs 128 dimensional de-
scriptors, which can be directly matched by L2 distance.
In this paper, we draw inspiration from the basic concept
of matching: for a certain local patch, to ﬁnd its matching
counterpart is to do NNS in the descriptor space. Thus, all
we need to do is to make sure that the descriptors of match-
ing pairs to be the nearest neighbor (under speciﬁc metric
like L2 distance in this paper) of each other, while the mag-
nitude of distance does not really matters. The essence be-
hind this inspiration is relative distance. Although the con-

1661

cept of relative distance is not new, its potentiality in de-
scriptor matching and other related applications is far from
being fully explored. Following this idea, we train L2-Net
by optimizing the relative distance among descriptors in a
batch. Speciﬁcally, L2-Net transforms a batch of patches
into a batch of descriptors, for each descriptor, our training
strategy aims at making its nearest neighbor in a batch to
be its correct matching descriptor. In this way, it is actu-
ally a one-vs-many operation which considers distances a-
mong many patch pairs, going beyond the widely used pair-
wise or triplet-wise operation [10, 25, 2, 5]. The training of
L2-Net is built on a progressive sampling strategy (section
3.3) and a loss function (section 3.4) consists of three error
terms. The proposed progressive sampling strategy can be
implemented by just one matrix multiplication, which en-
ables fast access to billions of patch pairs in a few dozens
of training epochs. As far as we know, the only method-
s that may share some common concept with ours are [9]
and [27]. However, [9] works on the distribution of match-
ing and non-matching pairs while we emphasis on speciﬁc
pairs, which is more sensitive. The sampling strategy of
[27] leads to a non-convex loss function that can not be op-
timized directly. By comparison, our sampling strategy is
fast, efﬁcient and easy to implement. Besides, we integrate
three error terms in the loss function: one term accounts for
the relative distance among descriptors, one term controls
descriptor compactness as well as overﬁtting, and one term
is an extra supervision imposed on the intermediate feature
maps, which is named as Discriminative Intermediate Fea-
ture maps (DIF). The proposed network is very powerful
although not very deep, it achieves state-of-the-art perfor-
mance on several standard benchmark datasets, receiving
signiﬁcant improvement over previous descriptors and even
surpassing those CNN models with metric learning layers.
The L2-Net descriptor can be used as a direct substitution
of existing handcrafted descriptors since it also uses L2 dis-
tance.

2. Related work

The research of designing local descriptor has gradually
moved from handcrafted ones to learning based ones. Since
the purpose of this paper is descriptor learning, below we
give a brief review of descriptor learning methods in the
literatures, ranging from traditional methods to the recently
proposed CNN based methods. For handcrafted descriptors,
please refer to [18] for an overview of classical methods and
[13] for recent advances.

Traditional descriptor learning. Early efforts in learn-
ing descriptors are not restricted to any speciﬁc machine
learning method, thus leading to a lot of unique works.
PCA-SIFT [12] applies Principal Components Analysis (P-
CA) to the normalized gradient patch instead of directly
using smoothed weighted histograms like SIFT. ASD [24]

assumes that local patches under various afﬁne transforma-
tions lie in a subspace and PCA is used to extract the base of
the subspace as descriptor. [20, 16] emphasizes the learning
of pooling region and dimensionality reduction, achieving
remarkable performance. Besides ﬂoat descriptors, there
are also learned binary descriptors. BOLD [3] presents a
method for adaptive online selection of binary intensity tests
so that each bit ensures low variance for intra-class and high
variance for inter-class. In Binboost [21], each bit of the
descriptor is computed by a boosted binary hash function.
RFD [7] proposes to do binary test on the most discrim-
inative receptive ﬁelds based on the labeled training data.
RMGD [26] introduces a kind of spatial ring-region based
pooling method for binary intensity tests, together with an
extended Adaboost bit selection. [29] presents a formula-
tion for patch description based on sparse quantization. All
the descriptors mentioned above start learning from low lev-
el features like gradient or pure binary intensity test, thus,
inevitably suffering from information loss. With the help of
CNN, we can learn descriptor directly from the raw image
patches.

CNN based descriptor learning. Recently, Siamese
and triplet networks are the main stream architectures in C-
NN based descriptor learning. To improve performance, a
fully connected layer acting as a metric network is favored
by many researchers. MatchNet [10], a typical Siamese
network, consists of a feature network for extracting fea-
ture representation, a bottleneck layer for reducing feature
dimension, and a metric network for measuring similarity
of features pairs. It signiﬁcantly improves previous results,
showing a great potential of CNN in descriptor learning. Al-
so based on Siamese network, [25] gose further than Match-
Net. It explores different kinds of network architectures and
proposes to use a kind of central-surround structure to im-
prove performance. [9] uses triplet network and proposes a
global loss function to separate the distribution of matching
and non-matching pairs. Together with the metric learn-
ing layer and the central surround structure, [9] achieves
the currently best performance on the Brown [16] dataset.
Despite metric learning improves matching ability, it also
limits the versatility of the network. To solve this problem,
networks trained without metric learning layers have been
proposed. DeepDesc [5] trains the network using L2 dis-
tance by adopting a mining strategy to select hard patches.
However, it essentially requires huge amounts of training
data to ensure performance. PN-Net [2] uses triplet CNN
with a softPN loss that optimizes the distances among patch
triplets. Our work also aims to get rid of the metric network
and learn high performance descriptor that can be matched
by L2 distance.

662

at least 2 matching patches. Brown dataset consists of three
subsets, namely, Yosemite, Notredame, and Liberty. Usu-
ally, one of the subsets is picked as training set and the
other two subsets are used for testing. The training data
of HPatches dataset is composed of four subsets, namely,
train-hard (easy) -viewpoint, and train-hard (easy) -illum,
indicating that the patches exhibit viewpoint and illumina-
tion changes with different degrees. Since the label of its
test data is not published at the time we ﬁnish this paper,
we just use HPatches as training set. There are approxi-
mately 500K (1.5M) and 190K (1.2M) 3D points (patch-
es) in Brown dataset and HPatches dataset respectively. All
patches are down sampled to the size of 32 × 32 for train-
ing. Based on our experiments, we did not notice any per-
formance degeneration caused by shrinking the patch size.
For each patch, we remove the pixel mean calculated across
all the training patches, and then contrast normalization is
applied, i.e., subtracted by the mean and divided by the s-
tandard deviation.

3.3. Progressive sampling of training data

In local patch matching problem, the number of poten-
tial non-matching (negative) patches is orders of magni-
tude larger than the number of matching (positive) patch-
es. Due to the so large amount of negative pairs, it is im-
possible to traverse all of them, therefore a good sampling
strategy is very crucial. Existing methods typically sam-
ple equal numbers of positive and negative pairs in train-
ing, while the proposed progressive sampling strategy is to
break the balance by sampling more negative pairs. Sup-
pose there are P 3D points in the training set. In each it-
eration, we take p1 points from the whole set sequentially
to traverse all the P points, and then we take an extra of
p2 points form the rest P − p1 points randomly. The ran-
domness brought by the extra p2 points gives the network
a chance to go over what it has learned and be prepared for
what it will learn. To form a training batch, we randomly
pick a pair of matching patches for each of the p (equals
to p1 + p2) points (thus there are 2p patches in a batch).
Let X =
be the
2D patches in a batch, where the subscript is the 3D point
index and the superscript is the 2D patch index (e.g., x1
i
and x2
i represents a matching pair from 3D point i). Given
X as input to L2-Net, the output descriptors is denoted as
Y =
i , · · · , y1
, where q is the
dimension of the descriptor (128 in this paper). Note that
Y is a batch of unit vectors as the output layer of L2-Net
is LRN. Thus, we deﬁne the distance matrix D = [dij]p×p,
(∥∥2 is L2 norm), and D can be
where dij =
2
computed by one simple matrix multiplication as
(cid:13)
(cid:13)

1, · · ·, y1

1, · · ·, x1

i , · · · , x1

y2
i − y1
j

1, y2
y1

1, x2
x1

32×32×2p

p, y2
p

p, x2
p

i , x2

i , y2

q×2p

(cid:13)
(cid:13)

}

{

]

[

D =

2

1 − YT

1 Y2

√

(

)

(1)

663

Figure 1. Network Architecture. 3×3 Conv = Convolution +Batch
Normalization + Relu. 8 × 8 Conv = Convolution +Batch Normal-
ization.

3. L2-Net

In this section, we describe in detail of the architecture,
training data, sampling strategy, loss function and training
of the proposed L2-Net.

3.1. Network architecture

The architecture of L2-Net is depicted in Fig. 1-(a). It
takes an all convolution structure, and down sampling is
achieved by stride 2 convolution. Batch normalization (B-
N) [28] is used after each convolutional layer, but with mi-
nor modiﬁcations, i.e., we do not update the weighting and
bias parameters of the BN layers and ﬁx them to be 1 and
0 respectively. Since normalization is an important step in
designing descriptors, we use a Local Response Normal-
ization layer (LRN) as the output layer to produce unit de-
scriptors. L2-Net converts 32 × 32 input patches to 128
dimensional descriptors . As in [25, 9], we also implement
a central-surround (CS) L2-Net. It is the concatenation of
two separate L2-Nets with a two tower structure as shown
in Fig. 1-(b). The input of the tower on the left is the same
with a solo L2-Net, while the input of the tower on the right
is generated by cropping and resizing the central part of the
original patches.

3.2. Training data and preprocessing

For network training, we use the Brown dataset [16]
and the newly proposed HPatches dataset [11]. These two
datasets are composed of local patches extracted from dif-
ferent scenes. Although diverse in properties, they organize
patches in the same way: (i) Each patch in the dataset has
a unique 3D point index, patches with identical 3D point
index are matching ones. (ii) For each 3D point, there are

[

]

1, · · ·, ys
ys

where Ys =
i , · · · , ys
q×p, (s = 1, 2). As a re-
p
sult, D contains distances of p2 pairs, namely p positive
pairs as the diagonal elements and p2 − p negative pairs as
the off-diagonal elements. For a typical training set with
160K 3D points, with p set to be 128, it means that each
training epoch consists of 2500 batches.
In each epoch,
over 40M (1282 × 2500) pairs are fed to the network. In
our experiments, L2-Net typically needs about 40 training
epochs. This indicates that about 1.6 billions pairs (despite
the inevitable repetition as a result of randomness, it is still a
huge number) are used for training, with the overwhelming
majority to be negative pairs and positive pairs only takes
up 12.8M (128 × 2500 × 40).

A possible question would be why we use YT
1

Y2 instead
of YTY to compute D. It is because that if YTY is used,
the diagonal elements of D will be all zeros (distances be-
tween identical patches), and all positive and negative pairs
would be distributed on the off-diagonal elements, making
the calculation of the gradient troublesome. In fact, our ear-
ly work used YTY, however, it does not show superiority
in performance than using YT

1 Y2.

3.4. Loss function

Built upon the progressive sampling strategy, our loss
function integrates three objectives. First, we use relative
distance to separate matching and non-matching pairs. Sec-
ond, we emphasize compactness of the output descriptor,
which means that all dimensions of the descriptor should be
less correlated. Finally, instead of just concentrating on the
ﬁnal output, we also impose constraints on the intermedi-
ate feature maps to achieve better performance. According
to these objectives, we design three error terms in the loss
function.

1) Error term for descriptor similarity. This error ter-
m is based on relative distance, i.e., the nearest neighbor of
each descriptor in the batch should be its matching counter-
part. In D, it would be ideal if

min
(i,j)∈[1,p]

{dik, dkj} = dkk

Equation (2) means that the diagonal element dkk should
be the smallest among the kth row and kth coloum. It is
equivalent to

min
i∈[1,p]
min
j∈[1,p]

{dik} = dkk

{dkj} = dkk






For easy implementation, we operate on columns and
rows separately. Deﬁne the column similarity matrix
Sc = [sc
ij]p×p and the row similarity matrix Sr = [sr
ij]p×p
as

sc
ij = exp(2 − dij)/
sr
ij = exp(2 − dij)/

exp(2 − dmj)

exp(2 − djn)

m
∑
n
∑

(2)

(3)

(4)

664

i is matched to y1

where 2 is the maximum L2 distance between two unit vec-
tors. In equation (4), sc
ij can be interpreted as the probabili-
ty that y2
ij is the probability that y1
i
is matched to y2
j . By applying softmax function to each col-
umn and each row of D, we can get Sc and Sr respectively.
The error term for descriptor similarity is deﬁned as

j , and sr

E1 = −

log sc

ii +

log sr
ii

(5)

1
2 (

i
∑

i
∑

)

E1 encourages the descriptors to be closer to their matching
counterparts in Euclidean space, while ignoring the speciﬁc
magnitude of distances, which is the essence of NNS.

2) Error term for descriptor compactness. As the pro-
gressive sampling strategy gives L2-Net the access to mas-
sive training samples, overﬁtting becomes inevitable in our
initial experiments. An interesting ﬁnding is that the degree
of overﬁtting is directly related to the degree of correlation
among descriptor dimensions. Thus we introduce an error
term that accounts for compactness of the descriptor. By
compactness we mean that there should be less redundancy
among different dimensions and each dimension should car-
ry as much information as possible so that fewer dimension-
s could be used to achieve the same performance. In fact,
compactness is commonly used in the learning of binary de-
scriptors (such as BOLD [7], RFD [3]), which is typically
achieved by greedy selection of bits with high variation. To
make it differentiable, we adopt the correlation matrix. A-
gain, we use Ys instead of Y to guarantee that the descrip-
tors for the computation of correlation matrix come from d-
ifferent 3D points. We denote YT
,
where bs
i is the row vector.

1, · · ·, bs
bs

i , · · ·, bs
q

s as

The correlation matrix Rs = [rs

ij]q×q is deﬁned as

[

]

rs
ij =

(bs

i − ¯bs
i )
i − ¯bs
(bs
i )

T

T

(bs

j − ¯bs
j)
j − ¯bs
(bs
j)

(6)

T

(bj − ¯bs
j)

(bs

i − ¯bs
i )

√
√
where ¯bs
i refers to the mean of the ith row of Ys. The off-
diagonal elements of Rs is expected to be 0, thus we simply
minimize the sum of the squared off-diagonal elements.

E2 =

1
2 

r1
ij

2

+

2

r2
ij



(7)

i̸=j
∑

i̸=j
∑

)

(

(





)
We ﬁnd it is more efﬁcient to put E2 before the LRN
layer, i.e., after the last BN layer. This is because that BN
will normalize each channel by subtracting the mean and
dividing the standard deviation (note that the weighing and
bias are ﬁxed to be 1 and 0). As a result, the computation of
correlation matrix can be simpliﬁed as

Rs = YsYT

s /q

(8)

(9)

(10)

(11)

3) Error term for intermediate feature maps. Existing
CNN based methods only focus on the ﬁnal output descrip-
tors, ignoring the importance of intermediate feature maps.
In this paper, we ﬁnd that it is possible to further increase
the performance of L2-Net with extra supervision informa-
tion provided by the intermediate feature maps. The design
of this error term is driven by the same motivation of E1,
i.e., the intermediate feature maps of a patch should also be
similar for matching pairs, while distinct for non-matching
pairs. Denote the batch of feature maps of the kth layer as
F =
i is the
vectorized feature map with width w and height h, and in-
dex k is omitted for concision. The inner product matrix
G = [gij]p×p for intermediate feature maps is computed as

1, · · ·, f1

i , · · · , f1

, where fs

1, f2
f1

(wh)×2p

p, f2
p

i , f2

[

]

G = (F1)
i , , · · · , fs
where Fs =
p
in equation (3), it would be ideal if
]

1, · · ·, fs
fs

[

TF2

(wh)×p

(s = 1, 2). Like

min
i∈[1,p]
min
j∈[1,p]

{gik} = gkk

{gkj} = gkk






Similarly, relative distance (here measured by inner prod-
uct) is used to build an error term on G. Same to the
deﬁnition of E1, we deﬁne the column similarity ma-
trix Vc = [vc
ij]p×p as well as the row similarity matrix
Vr = [vr

ij]p×p on G, where

vc
ij = exp(gij)/
vr
ij = exp(gij)/

exp(gmj)

exp(gjn)

m
∑
n
∑

Thus, the error term for intermediate feature maps is de-

ﬁned as

E3 = −

log vc

ii +

log vr
ii

(12)

1
2 (

i
∑

i
∑

)

We name this method as Discriminative Intermediate Fea-
ture maps (DIF). Experiments show that it is better to use
DIF on normalized feature maps, so we put DIF on the fea-
ture maps after BN layers, speciﬁcally, only after the ﬁrst
and the last BN layers. This is because that before the ﬁrst
and after the last convolutional layers there are no other
convolutional layers, so the order of feature maps is ﬁxed,
i.e., the ﬁrst convolution is directly applied to the input data
(each channel of the input data has ﬁxed mathematical or
physical meaning) and the output of the last convolutional
layer corresponds to the ﬁnal descriptor. Except for these
two, we do not restrict the ﬂexibility of all other feature
maps.

To sum up, E1 is computed on the ﬁnal output, E2
is computed after the last BN layer, and E3 is comput-
ed after the ﬁrst and the last BN layers. The total loss is
E1 + E2 + E3.

3.5. Training

We train the network from scratch using SGD with a s-
tarting learning rate of 0.01, momentum of 0.9 and weight
decay of 0.0001. The learning rate is divided by 10 every
20 epochs, and the training is done with no more than 50
epochs. For the training of CS L2-Net, we initialize the t-
wo towers using the well trained L2-Net. The parameters of
the left tower in Fig. 1-(b) is ﬁxed and we ﬁne tune the right
tower until convergence. We let p1 = p2 = q/2 = 64, Da-
ta augmentation (optional) is achieved online by randomly
rotating (90, 180, 270 degree) and ﬂipping.

4. Experiments

In this section, we provide comparison of the proposed
model to the state-of-the-arts. Meanwhile, a series of exper-
iments are conducted to analyze the proposed model.

4.1. Brown dataset

We follow the evaluation protocol of [16] by using the
100K pairs provided by the authors and report the false pos-
itive rate at 95% recall. L2-Net is compared with other CN-
N based models with SIFT(results provided by [10]) as the
baseline. Accompany with the ﬂoat L2-Net descriptor, we
further obtain a binary descriptor by simply taking the sign
of the ﬂoat descriptor (±1). The resulting binary descrip-
tors are denoted as Binary L2-Net and Binary CS L2-Net.
To testify the generalization ability of L2-Net, we also train
it on HPatches dataset [11]. Results are listed in Table 1 and
Table 2.

As can be clearly seen from Table 1, L2-Net performs
the best across all the training/testing splits, with remark-
able improvement. Besides CS L2-Net, L2-Net already sur-
passes all models. For the other methods, CS SNet-GLoss
clearly outperforms the remaining ones. However, applying
CS structure to the models with metric learning will intro-
duce extra parameters to the fully connected layers, thus
increasing the time of feature extraction and matching. On
the contrary, for CS L2-Net, we use simple concatenation
without introducing any extra parameter and the two tow-
ers can be used independently. At the same time, binary
L2-Net descriptor signiﬁcantly outperforms those specially
designed binary descriptors, and even surpass all ﬂoat de-
scriptors. Note that the performance of the proposed bina-
ry descriptor can be further increased by a better threshold
rather than 0 or a better hashing method. Although trained
on a totally different dataset (Table 2), L2-Net still achieves
state-of-the-art performance, showing its great generaliza-
tion ability.

4.2. Oxford dataset

In order to further validate the generalization ability of
the proposed network, we test it on another totally different

665

Training
Test

Feature Notredame Yosemite Liberty Yosemite Liberty Notredame

Liberty

Notredame

Yosemite

Mean

SIFT [15]
MatchNet [10]
DeepCompare 2ch-2stream [25] +
DeepCompare 2ch-deep [25] +
SNet-GLoss [9] +
CS SNet-GLoss [9] +

TNet-TGLoss [9] +
TNet-TLoss [9] +
PN-Net [2]
DeepDesc [5]
L2-Net
L2-Net +
CS L2-Net
CS L2-Net +

RFDR [7]
RFDG [7]
BinBoost [21]
RMGD [26]
Boixet al [29]
Binary L2-Net
Binary L2-Net +
Binary CS L2-Net
Binary CS L2-Net +

Dim

128
4096
256
256
256
384

256
256
256
128
128
128
256
256

293-598
406-563
64
1376-1600
1360
128
128
256
256

Metric Learning

29.84

6.9
4.85
4.55
6.39
3.69

10.77
7.20
7.40
8.43
4.91
Float Descriptors
13.45
13.90
9.65

9.91
10.77
8.13

3.64
2.36
2.55
1.71

5.29
4.7
4.24
3.87
Binary Descriptors
19.40
19.03
21.67
17.42
15.52
11.71
10.29
7.83
6.65

19.35
17.77
20.49
15.09
15.6
10.3
7.44
5.25
4.01

22.53

27.29

3.87
1.90
2.01
1.84
0.77

3.91
4.47
3.71

1.15
0.72
0.87
0.56

13.23
12.49
16.90
10.15
-
6.37
3.81
3.07
1.9

5.67
2.11
2.52
2.83
1.14

5.43
5.58
4.23

1.62
1.29
1.39
1.09

11.68
11.37
14.54
10.86
8.52
6.76
4.31
3.52
2.51

10.88
5.00
4.75
6.61
3.09

10.65
11.82
8.99

4.43
2.57
3.81
2.07

16.99
17.62
22.88
14.46
-
13.5
8.81
8.49
5.61

26.55
7.74
4.19
4.26
5.27
2.71

8.8
9.58
6.98
6.99
3.23
2.22
2.61
1.76

15.85
15.4
19.24
13.63
12.12
10.03
7.01
5.84
4.12

8.39
4.10
4.38
5.57
2.67

9.47
10.96
7.21

3.30
1.71
2.84
1.3

14.50
14.14
18.97
13.82
8.87
11.57
7.45
6.92
4.04

10.9

4.40

5.69

Table 1. Performance on the Brown dataset. The numbers are false positive rate at 95% recall. + indicates data augmentation.

Test
L2-Net
L2-Net+
CS L2-Net
CS L2-Net+
Binary L2-Net
Binary L2-Net+
Binary CS L2-Net
Binary CS L2-Net+

Liberty Notredame Yosemite Mean
3.37
2.7
1.97
1.49
10.65
9.08
5.4
4.57

4.41
3.6
2.58
1.85
13.16
11.07
6.91
5.88

4.16
3.2
2.43
1.9
12.4
10.74
6.43
5.4

1.54
1.3
0.92
0.73
6.4
5.44
2.88
2.44

Table 2. Performance of networks on the Brown dataset when they
are trained on HPatches dataset .

dataset, i.e., the Oxford dataset [18]. We evaluate L2-Net on
six image sequences, namely, graf (viewpoint), bikes(blur),
ubc(JPEG compression), leuven(light), boat(zoom and ro-
tation), and wall(viewpoint). In each image sequence, there
are six images sorted in an order of increasing degree of
distortions with respect to the ﬁrst image. Keypoints are de-
tected by Harris-Afﬁne detector and local patches are nor-
malized to the size of 32 × 32 (64 × 64 for DeepDesc [5]

and TNet-TGLoss [9] ) with a scaling factor of 3. We fol-
low strictly the evaluation protocol of [18]. The results of
other methods such as [10, 25] on the same dataset can be
found in [2], where no improvement over PN-Net is ob-
served. One should note that CNN models with speciﬁc
learned metric are not suitable for evaluation on the Oxford
dataset, as the nearest neighbor search can not be well per-
formed using similarity score. For a fair comparison and
without lose of generality, all models are trained on Liberty
(DeepDesc [5] is trained on Liberty and Notredame). Be-
sides learned descriptors, we use LIOP [23] as the baseline
of handcrafted descriptors, since it was reported to surpass
most of the handcrafted descriptors on this dataset. Mean-
while, Binary L2-Net and Binary CS L2-Net are compared
to other state-of-the-art binary descriptors. Moreover, we
report results with different training data. Experimental re-
sults are shown in Fig 2 with mean average precision (mAP)
as performance indicator.

As can be clearly seen from Fig 2, L2-Net outperforms
all the other descriptors on average and even the binary L2-
Net descriptor surpasses all other ﬂoat descriptors. More-
over, there are some other interesting observations: i) The

666

P
A
m

0.9

0.8

0.7

0.6

0.5

0.4

0.3
0.2
0.1

0

graf

bikes

ubc

leuven

wall

boat

average

LIB

ND

YOS

HP

LIOP

DeepDesc

 PN-Net

TNet-TGLoss

L2-Net

CS L2-Net

RFDR

RFDG

 BinBoost

 Binary L2-Net

Binary CS L2-Net

Figure 2. Performance comparison on Oxford dataset in terms of mAP. Performance with respect to different training set is shown in the
right part of the ﬁgure (the average mAP over six image sequence).

CS structure does not guarantee performance improvement
on all datasets and all types of descriptors (ﬂoat and bina-
ry). Since CS structure needs to crop the central part of the
patch, how to choose the scale of the patch becomes a prob-
lem. Patches in Brown dataset and Hpatches dataset are of
similar scale, thus CS structure works ﬁne. However, with
different detector and scale, arbitrarily cropping the central
50% of the patch (can be less textured) may not be a good
choice. ii) In accordance with [4], we also ﬁnd that CNN
based methods is very sensitive to image blur. iii) Hpatches
dataset shows better generalization ability.

4.3. Hpatches dataset

Results of the prototype L2-Net (casia-yt) on the test da-
ta of Hpatches dataset can be found at the webpage of EC-
CV 2016 workshop “Local Features: state of the art, open
problems and performance evaluation” 2, where our method
ranked No.1 in all the three tasks.

4.4. Discussion and analysis

In this section, we discuss how each of the proposed er-
ror terms contributes to the ﬁnal performance and give some
qualitative analysis for the binarized descriptor.

Importance of compactness. We try to train L2-Net
without E2, however, the network does not converge. Due
to the large amount of training samples fed to the network, it
is easier for the network to memorize the training data rather
than learn to generalize. Without E2, strong overﬁtting hap-
pens and the dimensions of the output descriptor are highly
correlated. Therefore, compactness is of crucial importance
to the progressive sampling strategy. By restricting com-
pactness, the network actually tends to extract uncorrelated
features containing more information.

Advantage of relative distance. E1 is quite different
from the widely used hinge loss. Typically, hinge loss for

2http://www.iis.ee.ic.ac.uk/ComputerVision/DescrWorkshop/index.html

patch pair and triplet can be written as

Epair = δij max

0,

yi − yj

− tp

2

+ (1 − δij) max

(
(cid:13)
(cid:13)
0, tn −

(cid:13)
(cid:13)
yi − yj

Etriplet = max

0, 1 −

(

(

−

(cid:13)
(cid:13)
∥yi−y
∥yi−y+

(cid:13)
(cid:13)
i ∥2
i ∥2
+t

)

2

)

)

(13)

where δij equals to 1 if yi and yj are matching, otherwise
δij equals to 0. t, tp, tn are thresholds, whose optimal val-
ues are difﬁcult or even impossible to ﬁnd, so they are most-
ly decided by experience. A major drawback of hinge loss
is the unstable gradient caused by thresholding. As training
proceeds, it is not sure how many samples in a batch are
contributing to the overall gradient, and unstable gradien-
t may lead to a bad local minima. To tackle this problem,
many researchers resort to hard sample mining, however,
the nature of mining is still thresholding (more strict). By
utilizing relative distance, the absolute value of distances
becomes useless, thus there is no need to use thresholds.

Effectiveness of DIF. First, we simply remove E3 from
the error function to prove the effectiveness of DIF, and then
we impose DIF after every BN layer to test its performance.
Comparing curve A with curve B and D in Fig. 3-(b), it
can be found that since DIF can provide more supervision
in training, L2-Net with DIF works consistently better than
that without it. However, DIF can not be over used as it will
limit the solution space of the network.

Batch normalization. The weighting α and bias β are
ﬁxed to be 1 and 0 in our BN layers, as we ﬁnd learn-
ing them makes the output feature maps (and descriptors)
in poor distribution. In this experiment, the weighing and
bias parameters of all BN layers is learned except the two
BN layers before DIF (as DIF depends on the normalized
features). The training procedure is shown by curve C in
Fig. 3-(a). Comparing curve A with C, we can ﬁnd that up-
dating α and bias β leads to minor performance decline. As
an illustration to this phenomenon, suppose a ∼ N (µ1, σ1)
and b ∼ N (µ2, σ2) are two random variables obeying gaus-

667

0.99

0.985

0.98

C
U
A

0.975

0.97

0.965

5

4

3

2

1

4.5

3.5

2.5

1.5

0.5

y
t
i
s
n
e
D
 
y
t
i
l
i

b
a
b
o
r
P

A
B
C
D

0.5

0.4

0.3

0.2

0.1

0

-0.1

-0.2

n
a
e
M

0.96

0

10

40

50

0
-0.5

0.5

-0.3

0

20

20
30
Training Epoch
(a)

0
Range of Value
(b)

40
80
60
Binary Descriptor Bits

(c)

100

120

Figure 3. Model analysis. L2-Net is trained on Hpatches dataset and tested on Brown dataset. (a): Effect of DIF and BN. Area under the
ROC curve (AUC) of different training epoch (averaged over three subsets of Brown dataset) is served as an indicator. Curve A: default
setting. Curve B: default - DIF. Curve C: default + learned BN parameters. Curve D: default + extra DIF. (b): Distribution of the ﬂoat
L2-Net descriptor. (c): Mean of each bit of the binary L2-Net descriptor.

It is not difﬁcult to understand that the
sian distribution.
easiest way to separate them is to increase |µ1 − µ2| while
decrease |σ1| and |σ2|. As a result, learning α and β may
cause the extracted feature to be sharp and non-zero dis-
tributed, which damages the performance. Fixing them is
based on the principal that we want the feature maps (and
descriptors) of different patches to be independent identical-
ly distributed. In this way, the network is forced to extract
features that are highly discriminative rather than biased.

Property of the binarized descriptor. We aim to pro-
vide an insightful explanation for the good performance of
the binarized descriptor, despite the fact that it is just a by-
product of the proposed ﬂoat descriptor. Thus, we randomly
select 100K patches from different 3D points to investigate
the value distribution of the proposed descriptor. Fig. 3-(b)
shows that the output values of the L2-Net approximately
obey the Gaussion distribution with zero mean. In Fig. 3-
(c), each bit of the binarized descriptor has a mean near
0, which is highly desirable for a good binary descriptor.
Moreover, we know that hamming distance can be comput-
ed by inner product (for vectors consist of +1 and -1) and
DIF is just built on inner product, which means there could
be strong connections between DIF and the performance of
the binary descriptor. We will leave the in depth analysis in
the future work.

4.5. Trianing and extraction speed

We use a GTX 970 GPU in MatConvNet [22]. L2-Net
reaches maximum performance in 20 to 50 epochs. With-
out online data augmentation, it takes only 2 to 4 hours (4
to 6 hours with online data augmentation). Note that with
a more powerful GPU, the training time will undoubtedly
reduce. L2-Net can extract descriptors at the speed of ap-
proximately 21.3K patch/sec.

5. Conclsion

In this paper, we propose a new data-driven descriptor
that can be matched in Euclidean space and signiﬁcant-
ly outperforms state-of-the-arts.
Its good performance is
mainly attributed to a new progressive sampling strategy
and a dedicated loss function containing three terms. By
progressive sampling, we manage to visit billions of train-
ing samples. By going back to the basic concept of match-
ing (NNS), we thoroughly explore the information in each
batch. By requiring compactness, we successfully handle
overﬁtting. By utilizing intermediate feature maps, we fur-
ther boost the performance. Moreover, a powerful bina-
ry descriptor is obtained by directly taking the sign of the
learned ﬂoat descriptor, which gives the best performance
among existing binary descriptors and even outperforms
most ﬂoat descriptors. Finally, L2-Net should be further
extended to more applications such as image classiﬁcation
and retrieval. We will leave these problems as the future
work.

6. Acknowledgments

This work was supported by the National High Tech-
nology Research and Development Program of China (863
Program 2015AA020504) and the National Natural Sci-
ence Foundation of China (Nos. 61375043, 61672032,
61472119, 61403375). Y. Tian thanks Shenglong Guo and
Chenhua Li for some useful discussions.

References

[1] J. Bromley, I. Guyon,Y. LeCun, E. Sckinger, and
R. Shah. Signature veriﬁcation using a siamese time
delay neural network. In NIPS, 1994.

[2] V. Balntas, E. Johns, L. Tangand K. Mikolajczyk. PN-
Net: Conjoined triple deep network for learning local
image descriptors. Arxiv, 2016. 1, 2, 6

668

[3] V. Balntas, L. Tang, and K. Mikolajczyk. Bold: binary
online learned descriptor for efﬁcient image matching.
In CVPR, 2015. 2, 4

[18] K. Mikolajczyk and C. Schmid. A performance e-
valuation of local descriptors. PAMI, pages 257–263,
2003. 1, 2, 6

[19] J. Philbin, O. Chum, M. Isard, J. Sivic, and A. Zisser-
man. Object retrieval with large vocabularies and fast
spatial matching. In CVPR, 2007. 1

[20] K. Simonyan, A. Vedaldi, and A. Zisserman. Learn-
ing local feature descriptors using convex optimisa-
tion. IEEE Transactions on Pattern Analysis and Ma-
chine Intelligence, 2014. 1, 2

[21] T. Trzcinski, M. Christoudias, P. Fua, and V. Lep-
etit. Boosting Binary Keypoint Descriptors. In CVPR,
2013. 1, 2, 6

[22] A. Vedaldi and K. Lenc. Matconvnet - convolutional
neural net-works for matlab. CoRR, abs/1412.4564. 8
[23] Z. Wang, B. Fan, and F. Wu. Local intensity order
pattern for feature description. In ICCV, 2011. 6
[24] Z. Wang, B. Fan, and F. Wu. Afﬁne subspace repre-
sentation for feature description. In ECCV, 2014. 1,
2

[25] S. Zagoruyko and N. Komodakis. Learning to com-
pare image patches via convolutional neural networks.
In CVPR, 2015. 1, 2, 3, 6

[26] Y. Gao, W. Huang, and Y. Qiao Local Multi-Grouped
Binary Descriptor with Ring-based Pooling Conﬁgu-
ration and Optimization. IEEE Transactions on Image
Processing, 24(12):4280–4833, Jan 2014. 2, 6
[27] H. O. Song, Y. Xiang, S. Jegelka, S. Savarese Deep
Metric Learning via Lifted structured feature Embed-
ding. In CVPR, 2016 2

[28] Ioffe, Sergey and Szegedy, Christian. Batch normal-
ization: Accelerating deep network training by reduc-
ing internal covariate shift. Arxiv, 2015. 3

[29] X. Boix, M. Gygli, G. Roig and L. V. Gool. Sparse
Quantization for Patch Description. In CVPR, 2013.
2, 6

[4] A. Dosovitskiy, P. Fischer,

Jost. Springenberg,
M. Riedmiller, and T. Brox Discriminative Unsuper-
vised Feature Learning with Exemplar Convolutional
Neural Network Arxiv, 2015 7

[5] E. Simo-Serra, E. Trulls, L. Ferraz, I. Kokkinos,
P. Fua, and F. Moreno-Noguer. Discriminative learn-
ing of deep convolutional feature point descriptors. In
ICCV, 2015. 1, 2, 6

[6] D. Erhan, C. Szegedy, A. Toshev, and D. Anguelov
Scalable object detection using deep neural networks.
In CVPR, 2014. 1

[7] B. Fan, Q. Kong, T. Trzcinski, Z. Wang, C. Pan, and
P. Fua. Receptive ﬁelds selection for binary feature
description. TIP, 23(6):2583–2595, 2014. 1, 2, 4, 6

[8] R. Fergus, P. Perona, and A. Zisserman. Object class
recognition by unsupervised scale-invariant learning.
In CVPR, 2003. 1

[9] V. Kumar B G, G. Carneiro, and I. Reid. Learn-
ing local image descriptors with deep siamese and
triplet convolutional networks by minimising global
loss functions. In CVPR, 2016. 1, 2, 3, 6

[10] X. Han, T. Leung, Y. Jia, R. Sukthankar, and
A.C. Berg. Matchnet: Unifying feature and metric
learning for patch-based matching. In CVPR, 2015. 1,
2, 5, 6

[11] V. Balntas, K. Lenc, A. Vedaldi and K. Mikolajczyk.
HPatches: A benchmark and evaluation of handcraft-
ed and learned local descriptors. In CVPR, 2017. 1, 3,
5

[12] Y. Ke and R. Sukthankar. Pca-sift: A more distinctive
representation for local image descriptors. In CVPR,
2004. 1, 2

[13] B. Fan, Z. Wang and F. Wu. Local Image Descriptor:

Modern Approaches. Springer, 2015. 2

[14] A. Krizhevsky, I. Sutskever, and G. E. Hinton.

Im-
agenet classiﬁcation with deep convolutional neural
networks. In NIPS, 2012. 1

[15] D. Lowe. Distinctive image features from scale-

invariant keypoints. IJCV, 20(2), 2004. 1, 6

[16] M. Brown, G. Hua and S.A.G. Winder. Discrimina-
tive learning of local image descriptors. IEEE Trans-
actions on Pattern Analysis and Machine Intelligence,
2010. 1, 2, 3, 5

[17] J. Matas and O. Chum. Robust wide-baseline stereo
from maximally stable extremal regions. Image and
Vision Computing, 22(10), 2004. 1

669

