Concentration and Conﬁdence for Discrete Bayesian Sequence
Predictors

Tor Lattimore and Marcus Hutter and Peter Sunehag

Research School of Computer Science
Australian National University

@anu.edu.au
tor.lattimore,marcus.hutter,peter.sunehag
}
{

October 31, 2018

Abstract

Bayesian sequence prediction is a simple technique for predicting future symbols sampled
from an unknown measure on inﬁnite sequences over a countable alphabet. While strong
bounds on the expected cumulative error are known, there are only limited results on the dis-
tribution of this error. We prove tight high-probability bounds on the cumulative error, which
is measured in terms of the Kullback-Leibler (KL) divergence. We also consider the problem
of constructing upper conﬁdence bounds on the KL and Hellinger errors similar to those con-
structed from Hoeffding-like bounds in the i.i.d. case. The new results are applied to show that
Bayesian sequence prediction can be used in the Knows What It Knows (KWIK) framework
with bounds that match the state-of-the-art.

Contents

Introduction

1
2 Notation
3 Convergence
4 Conﬁdence
5 KWIK Learning
6 Conclusions
A Technical Lemmas
B Proof of Theorem 1
C Proof of Theorem 6
D Proof of Proposition 7
E Experiments
F Table of Notation

1 Introduction

1
2
3
6
9
10
11
12
12
15
15
17

3
1
0
2
 
n
u
J
 
9
2
 
 
]

G
L
.
s
c
[
 
 
1
v
7
2
1
0
.
7
0
3
1
:
v
i
X
r
a

ωt−1
Sequence prediction is the task of predicting symbol ωt having observed ω<t = ω1ω2ω3 · · ·
where the underlying distribution from which the sequence is sampled is unknown and may be
non-stationary. We assume sequences are sampled from an unknown measure µ known to be
. At time-step t having observed ω<t a predictor ρ should
contained in a countable model class
output a distribution ρt over the next symbol ωt. A predictor may be considered good if for all
µ

the predictive distribution of ρ converges fast to that of µ

M

∈ M

∆(ρt, µt)

f ast
−→

0

1

where ∆(ρt, µt) is some measure of the distance between ρt and µt, typically either the Kullback-
Leibler (KL) divergence dt or the squared Hellinger distance ht. One such predictor is the Bayesian
mixture ξ over all ν
with strictly positive prior. A great deal is already known about ξ. In
particular the predictive distribution ξt converges to µt with µ-probability one and does so with
ﬁnite expected cumulative error with respect to both the KL divergence and the squared Hellinger
distance [BD62, Sol78, Hut01, Hut03, Hut05].

∈ M

The paper is divided into three sections. In the ﬁrst we review the main results bounding the
expected cumulative error between µt and ξt and prove high-probability bounds on this quantity.
Such bounds are already known for the squared Hellinger distance, but not the KL divergence
until now [HM07]. We also bound the cumulative ξ-expected information gain. The second sec-
tion relates to the conﬁdence of the Bayes predictor. Even though ht and dt converge fast to zero,
these quantities cannot be computed without knowing µ. We construct conﬁdence bounds ˆht and
ˆdt that are computable from the observations and upper bound ht and dt with high probability
respectively. Furthermore we show that ˆht and ˆdt also converge fast to zero and so can be used
in the place of the unknown ht and dt. The results serve a similar purpose to upper conﬁdence
bounds obtained from Hoeffding-like bounds in the i.i.d. case to which our bounds are roughly
comparable (Appendix E). Finally we present a simple application of the new results by showing
that Bayesian sequence prediction can be applied to the Knows What It Knows (KWIK) frame-
work [LLWS11] where we achieve a state-of-the-art bound using a simple, efﬁcient and principled
algorithm.

2 Notation

A table summarising the notation presented in this section may be found in Appendix F. The
natural numbers are denoted by N. Logarithms are taken with respect to base e. The indicator
function is JexprK, which is equal to 1 if expr is true and 0 otherwise. The alphabet X is a ﬁnite
or countable set of symbols. A ﬁnite string x over alphabet X is a sequence x1x2x3 · · ·
xn where
. We denote the set of all ﬁnite strings by X ∗
xk ∈
and the set of inﬁnite strings by X∞. The length of ﬁnite string x
X ∗ is denoted by ℓ(x). Strings
X∞, then xy is the concatenation of x and y. For
X ∗ and y
can be concatenated. If x
X ∗
string x
xt and x<t = x1:t−1. The empty
string of length zero is denoted by ǫ.

∈
X∞, substrings are denoted by x1:t = x1x2 · · ·

X. An inﬁnite string is a sequence ω1ω2ω3 · · ·

X ∗

∈

∪

∈

∈

∪

(cid:8)

∈

F

X t−1

) and

Γx : x

Γx : x

:= σ(
{

Measures. The cylinder set of ﬁnite string x is Γx :=
F<t :=
σ(
) is a ﬁltered probability
space. Let µ be a probability measure on this space. We abuse notation by using the shorthands
x) := µ(xy)/µ(x). The intuition is that µ(x) represents the µ-probability
µ(x) := µ(Γx) and µ(y
|
x) is the µ-probability that an
that an inﬁnite sequence sampled from µ starts with x and µ(y
|
inﬁnite sequence sampled from µ starts with xy given that it starts with x. We write µ
ξ if µ
is absolutely continuous with respect to ξ. From now on, unless otherwise speciﬁed, all measures
will be probability measures on ﬁltered probability space (X∞,

xω : ω
{
). Then (X∞,
}

. Deﬁne σ-algebra

X∞
∈
}
,
{F<t}
F

X ∗

≪

∈

).

(cid:9)

,

be a countable set of measures and w :

M

Bayes mixture. Let
tion on
deﬁnition ξ(A)
data x

M

≥

∈

. The Bayes mixture measure ξ :
wνν(A) for all A

F →

and ν

[0, 1] is deﬁned by ξ(A) :=
, which implies that ν

∈ M
X ∗ the prior w is updated using Bayes rule to be wν(x) := wν ν(x)/ξ(x). Then ξ(y

∈ F

(0, 1] be a probability distribu-
ν∈M wνν(A). By the
ξ. Having observed
x) can
|

≪
P

{F<t}

F

M →

2

be written ξ(y

x) =
|

ν∈M wν (x)ν(y

x). The entropy of the prior is Ent(w) :=
|

−

ν∈M wν ln wν .

P

x))2.
ξ(a
|
a∈X µ(a

If µ
≪
x) ln µ(a|x)
|

Distances between measures. Let µ and ξ be measures. The squared Hellinger distance between
the predictive distributions of µ and ξ given x

x)
|
−
ξ) :=
ξ, then the Kullback-Leibler (KL) divergence is deﬁned by dx(µ
k
ξ(a|x) . The KL divergence is not a metric because it satisﬁes neither the symme-
p
try nor the triangle inequality properties. Nevertheless, it is a useful measure of the difference
P
between measures and is occasionally more convenient than the Hellinger distance. Let ξ be the
Bayes mixture over ν
, then deﬁne random variables on
X∞ by

X ∗ is deﬁned by hx(µ, ξ) :=

with prior w :

(0, 1]. If ρ

a∈X(

M →

∈ M

∈ M

µ(a

P

P

p

∈

ρ1:t(ω) := ρ(ω1:t)

ρ<t(ω) := ρ(ω<t)

ρt(ω) := ρ(ωt|

ω<t)

ht(ρ, ξ) (ω) := hω<t(ρ, ξ)

ξ) (ω) := dω<t(ρ
dt(ρ
ξ)
k
k

The latter term can be rewritten as

ξ) = Eρ
dt(ρ
k

ρ1:t
ρ<t ·

ln

(cid:20)

= Eρ

F<t

(cid:21)

+ ln

ξ<t
ρ<t

.

F<t

(cid:21)

(1)

Now ﬁx an unknown µ

and deﬁne random variables (also on X∞).

∈ M

dt := dt(µ

ξ)
k

ht := ht(µ, ξ)

wν (ω<t)dω<t (ν

ξ)
k

ξ<t
ξ1:t (cid:12)
(cid:12)
(cid:12)
(cid:12)

∞

t=1
X

(cid:20)

ln

ρ1:t
ξ1:t (cid:12)
(cid:12)
(cid:12)
(cid:12)
ct(ω) :=

Xν∈M
∞

t=1
X

D∞ :=

dt

H∞ :=

ht

C∞ :=

ct.

∞

t=1
X

Both ht and dt are well-known “distances” between the predictive distributions of ξ and µ at time
t. The other quantity ct is the ξ-expected information gain of the posterior between times t and
t + 1 given the observed sequence at time t.

ct =

wν

ν<t
ξ<t

dt(ν

ξ) = Eξ
k

wν

ν1:t
ξ1:t

ln

νt
ξt

F<t
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
}
An important observation is that ct is independent of the unknown µ.

information gain

Xν∈M

Xν∈M

{z

"

|

#

3 Convergence

In this section we consider the convergence of ξt −
where convergence holds
with µ-probability 1, in mean sum or with high µ-probability of a small cumulative error. The ﬁrst
theorem is a version of the celebrated result of Solomonoff that the predictive distribution of the
Bayes mixture ξ converges fast to the truth in expectation [Sol78, Hut05]. The only modiﬁcation is
the alphabet is now permitted to be countable rather than ﬁnite.

0 for all µ

µt →

∈ M

Theorem 1 (Sol78, Hut05). The following hold:

EµH∞ ≤

EµD∞ ≤

ln

1
wµ

lim
t→∞

dt = lim
t→∞

ht = 0, w.µ.p.1.

3

The proof can be found in Appendix B. Theorem 1 shows that the predictive distribution
of ξ converges to µ asymptotically and that it does so fast (with ﬁnite cumulative squared
Hellinger/KL error) in expectation. We now move on to the question of high-probability bounds
on D∞ and H∞. The following theorem is already known and essentially unimprovable.

Theorem 2 (HM07). For all δ

(0, 1) it holds with µ-probability at least 1

∈

δ that H∞ ≤

−

ln 1
wµ

+ 2 ln 1
δ .

We contribute a comparable concentration bound for D∞. A weak bound can be obtained by
1
δ, but
δ ·

applying Markov’s inequality to show that D∞ ≤
a stronger result is possible.

) with µ-probability at least 1

ln( 1
wµ

−

Theorem 3. For all δ

(0, 1) it holds with µ-probability at least 1

∈

Proof. A stopping time is a random variable t : X∞
for all n. For stopping time t let X(t)

F<n measurable
X ∗ be the set of ﬁnite sequences where t becomes known

∪{∞}

→

N

−

e

δ that D∞ ≤
such that t−1(n) is

·

(ln 6
δ )

(ln 2

δ + ln 1
wµ

).

·

⊂
X(t) :=

x : t(xω) = ℓ(x) + 1,
{

ω

∀

}

.

Deﬁne random variable z<t := ξ<t/µ<t and L :=
inductively by

ln(2/δ)
⌈

⌉ ≤

ln(6/δ) and stopping times

tk}
{

t1 := 1

tk+1 := min

s :

dt > e

ln z<tk + ln

s

t=tk
P

(

·

(cid:18)

1
wµ (cid:19))

.

The result follows from two claims, which are proven later.

µ

sup
t

ln z<t ≥

ln

(cid:18)

2
δ

≤

(cid:19)

δ/2

(⋆)

µ

tL+1 <

δ/2

(⋆⋆)

(cid:18)

∞

≤

(cid:19)

∈

∞

t=1
X

By the union bound we obtain that if A is the event that tL+1 =
µ(A)

δ and for ω

A

1

and supt ln z<t ≤

∞

ln 2

δ , then

≥

−

D∞(ω) =

dt(ω)

(a)
=

dt(ω)

ln z<tk (ω) + ln

1
wµ (cid:19)

L

tk+1(ω)−1

Xk=1
+ ln

Xt=tk(ω)
(d)
1
wµ (cid:19)

≤

(b)

≤

L

Xk=1

e

·

(cid:18)
2
δ

·

(c)

e

e

L

(cid:18)

≤

ln

2
δ

1
wµ (cid:19)
where (a) follows from the deﬁnition of tk and because tL+1(ω) =
. (b) follows from the deﬁ-
∞
δ . (d) by the deﬁnition of L. The theorem is completed
nition of tk. (c) because supt ln z<t ≤
by proving (⋆) and (⋆⋆). The ﬁrst follows immediately from Lemma 14. For the second we use
induction and Theorem 1. After observing x
x) where
ν

x)) = wν ν(x)/ξ(x). Therefore by Theorem 1

x) is a Bayes mixture over ν(

with prior weight w(ν(

X(tn), ξ(

+ ln

ln 2

6
δ

ln

ln

(cid:19)

(cid:18)

(cid:18)

∈

·|

·|

·

·

∈ M

·|

∞

Eµ

"

t=ℓ(x)+1
P

dt

x
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

4

ln

1
w(µ(

# ≤

x))

·|

= ln

+ ln

ξ(x)
µ(x)

1
wµ

.

Therefore by Markov’s inequality

 
N and assume µ(tn <

t=ℓ(x)+1
P
)

Let n

∈

µ

tn+1 <

(cid:18)

∞

(cid:19)

∞

µ

1
e

.

! ≤
tn we have

·

(cid:18)

ln

+ ln

dt > e

ξ(x)
1
x
wµ (cid:19) (cid:12)
µ(x)
(cid:12)
(cid:12)
e1−n. By the deﬁnition tn+1 ≥
(cid:12)
(cid:12)
ln
µ(x)

dt > e

µ

∞

·

 

t=ℓ(x)+1
P
1
e

µ(x) =

µ(tn <

e−n.

)

∞

≤

∞

≤

=
Xx∈X(tn)
1
e

≤

ξ(x)
µ(x)

+ ln

·

(cid:18)

1
x
wµ (cid:19) (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

!

Xx∈X(tn)
e1−n for all n and so µ(tL+1 <

Therefore µ(tn <
of (⋆⋆) and so also the theorem.

∞

≤

)

Theorem 3 is close to unimprovable.

)

∞

≤

e−L

≤

δ/2, which completes the proof
(cid:4)

δ

1

=

ln 1

M
.

3 ln 2

µ, ν
{

δ + 2 ln 1−w

such that with µ-probability at least δ it holds that D∞ >

Proposition 4. There exists an
4 ln 2 ln 1
Proof. Let X =
where the true measure µ is the Lebesgue measure and
(cid:0)
ν is the measure deterministically producing an inﬁnite sequence of ones, which are deﬁned by
µ(x) := 2−ℓ(x) and ν(x) := Jx = 1ℓ(x)K where 1n is the sequence of n ones.. Let w = wµ and
wν = 1

N, then µ(Γ1n)

w −
and

δ and for ω

0, 1
}
{

w. If n =

Γ1n

µ, ν

M

:=
(cid:1)

{

}

}

1

−

(cid:4)
D∞(ω)

∈

(cid:5)
d1t−1(µ

(b)
=

ξ)
k

ln 2 ln 1

δ
n+1

(a)

≥

t=1
X

n+1

t=1
X
n+1

(c)
>

(e)

≥

1
2

1
2

ln

1
1t−1)
4ξ(0
|

(cid:18)

(cid:19)

(t

2) ln 2 + ln

−

∈

≥
1
2 ·

ln

n+1

t=1
X
w

ln

(f)
=

1
2
1t−1)
ξ(1
|
w

(cid:18)
(n + 1)

n+1

t=1  
X
(d)
=

1
2

1

−
w

+

ln

1
2 ·

1
2
1t−1) !
ξ(0
|

21−t + (1
2−t

4w

·

−

w)

(cid:19)
·
2 ln 1−w
w + (n
4

(cid:0)

2) ln 2

−

(cid:1)

t=1 (cid:18)
X

(cid:19)
(a) follows from the deﬁnition of D∞(ω) and the positivity of the KL divergence, which allows the
sum to be truncated. (b) follows by inserting the deﬁnitions of µ and the KL divergence. (c) by
1t−1) < 1. (d) follows from the deﬁnition of ξ while (e) and (f)
basic algebra and the fact that ξ(1
|
(cid:4)
are basic algebra. Finally substitute n + 1

ln 2 ln 1
δ .
In the next section we will bound dt by a function of ct, which can be computed without know-
ing µ. For this result to be useful we need to show that ct converges to zero, which is established
by the following theorems.

≥

1

Theorem 5. If Ent(w) <

, then EµC∞ ≤
Proof. We make use of the dominance ξ(x)

∞

Ent(w)/wµ and limt→∞ ct = 0 with µ-probability 1.

wµµ(x), properties of expectation and Theorem 1.

EµC∞ := Eµ

ct

(a)

≤

1
wµ

Eξ

(b)
=

ct

1
wµ

Eξ

∞

∞

t=1
X

Xν∈M

(c)
=

1
wµ

wνEν

∞

Xk=1

≥
∞

t=1
X
dt(ν

(d)

≤

1
wµ

ξ)
k

t=1
X

Xν∈M
wν ln

Xν∈M

wν

ν<t
ξ<t

dt(ν

ξ)
k

1
wν

(e)
=

Ent(w)
wµ

5

ξ(A)/wµ and linearity of expectation. (b) is the deﬁnition of ct.
(a) follows by dominance µ(A)
(c) by exchanging sums and the deﬁnition of expectation. (d) is true by substituting the result in
Theorem 1. Finally (e) follows from the deﬁnition of the entropy Ent(w). That limt→∞ ct = 0 with
µ-probability 1 follows from the ﬁrst result by applying Markov’s inequality to bound C∞ <
with probability 1.

∞
(cid:4)

≤

In the ﬁnite case a stronger result is possible.

Theorem 6. If

= K <

|M|

and w is the uniform prior, then EµC∞ ≤

∞

6 ln2 K + 14 ln K + 8.

Theorem 6 is tight in the following sense.

Proposition 7. For each K
, then EµC∞ > 1
prior on

M

N there exists an
1.

∈
2 ln2 K

−

M

See the appendix for the proofs of Theorem 6 and Proposition 7.

of size K and µ

such that if w is the uniform

∈ M

4 Conﬁdence

In the previous section we showed that ξt converges fast to µt. One disadvantage of these results
is that errors dt and ht cannot be determined without knowing µ. In this section we deﬁne ˆdt and
ˆht that upper bound dt and ht respectively with high probability and may be computed without
knowing µ. Let
Mt
contains the set of plausible models at time-step t and is deﬁned by

be a narrowing sequence of hypothesis classes where

M ⊇ M1 ⊇ M2 · · ·

Mt :=

ν
(cid:26)

∈ M

:

τ

∀

≤

t,

ν<τ
ξ<τ ≥

δ

wµ
wν (cid:27)

Then ˆht is deﬁned as the value maximising the weighted squared Hellinger distance between ν
and ξ for all plausible ν

∈ Mt and ˆdt is deﬁned in terms of the expected information gain.

ˆdt :=

ct
wµδ

ˆht := sup

ht(ν, ξ)

ν∈Mt (cid:26)

(cid:27)

wν
wµ

Both dt and ht depend on wµ, which is also typically unknown. If
is ﬁnite, then the problem
is easily side-stepped by choosing w to be uniform. The countable case is discussed brieﬂy in
ˆdt with high probability after which we
ˆht and dt ≤
the conclusion. First we prove that ht ≤
demonstrate that they are non-vacuous by proving that ˆht and ˆdt converge fast to zero with high
probability. Now is a good time to remark that hypothesis testing using the factor ν<t/ξ<t is not
exactly a new idea. For discussion, results, history and references see [SSVV11].

M

Theorem 8. For all δ

[0, 1] it holds that:

∈
t : dt ≤

µ(

∀

ˆdt)

1

δ

≥

−

(⋆)

µ(

t : ht ≤

∀

ˆht)

1

δ

≥

−

(⋆⋆)

6

Proof. To prove (⋆) deﬁne event A :=
we have that µ(A)

δ. If ω

1

ω : supt ξ(ω<t)/µ(ω<t) < 1
δ
A, then µ(ω<t)/ξ(ω<t) > δ for all t and

. By Lemma 14 in the appendix

≥

−

∈

ct(ω)

(a)
=

wν

dω<t(ν

(cid:8)
ν(ω<t)
ξ(ω<t)

(b)

≥

ξ)
k

wµ

(cid:9)
µ(ω<t)
ξ(ω<t)

dω<t (µ

ξ)
k

(c)

Xν∈M
> wµ ·

(d)

·

δ

ξ)
k

dω<t(µ

= wµ ·
(a) is the deﬁnition of ct. (b) follows by dropping all elements of the sum except µ. (c) by substi-
ct with µ-probability
tuting the bound on µ/ξ. (d) is the deﬁnition of dt. Therefore dt ·
ˆht.
at least 1
∈ Mt, then ht ≤
The result is completed by applying Lemma 14 in the appendix to show that µ
∈ Mt for all t with
(cid:4)
probability at least 1

≤
δ as required. For (⋆⋆) we note that by the deﬁnition of ˆht, if µ

wµ ·

dt.

−

δ.

δ

δ

·

1. Eµ

Theorem 9. The following hold:
ˆdt ≤
2. w.µ.p. at least 1

Ent(w)
δw2
µ

∞
t=1

P

.

δ it holds that

∞
t=1

ˆdt ≤

Ent(w)
δ2w2
µ

.

P

1. Eµ

Theorem 10. The following hold:
ˆht ≤
2. w.µ.p. at least 1

ln 1
wµ

∞
t=1

(cid:16)
δ,

2
wµ

P

∞
t=1

+ ln 1

ˆht ≤

δ + Ent(w)
(cid:17)
2 ln 1
wµ

2
wµ

(cid:16)

+ 5 ln 1

δ + 3 Ent(w)
(cid:17)

.

−

−

−

P

The consequences of Thereoms 6, 9 and 10 are summarised in Figure 1 for both countable
and ﬁnite hypothesis classes. The proof of Theorem 9 follows immediately from Theorem 5 and
is ﬁnite and w uniform, then one can use Theorem 6 instead to improve
Markov’s inequality. If
dependence on 1/wµ. For Theorem 10 we use Theorem 2 and the following lemma, which is a
generalization of Lemma 4 in [HM07].

M

Lemma 11. Let κ > 0 and stopping time τ := mint {
2 ln Eµ exp

τ −1
t=1 ht(ν, µ)

ln 1
κ .

1
2

(cid:16)

P

≤

(cid:17)

ν(a

x)µ(a
|

x)/
|

b∈X

ν(b

x)µ(b
|

x).
|

p

t : ν<t/µ<t < κ
}

. Then Eµ

τ −1
t=1 ht(ν, µ)

≤

P

x) :=
|

Proof. We borrow some tricks from [Vov87] and [HM07, Lem 4]. Deﬁne ρ inductively by ρ(a

√νtµt exp

ht(ν, µ)

1
2

(cid:18)

P
ρ<τ

(a)
=

ρt

(b)

≥

p
τ −1

t=1
Y
τ −1

r

Yt=1
µ<τ √κ

τ −1

t=1
Y
νt
µt

τ −1

t=1
Y

(c)
=

(e)

≥

1
2

1
2

(cid:18)

(cid:18)

µt

exp

ht(ν, µ)

(cid:19)

(d)
= µ<τ

ν<τ
µ<τ

r

exp

ht(ν, µ)

(f)
= µ<τ √κ exp

τ −1

Yt=1
1
2

(cid:18)

exp

ht(ν, µ)

1
2

(cid:18)

(cid:19)

τ −1

t=1
P

ht(ν, µ)

(cid:19)

where (a) and (d) follow from the deﬁnition of conditional probability. (b) by inserting the def-
κ by the
inition of ρt and applying Lemma 13. (c) by factoring. (e) by noting that ν<τ /µ<τ ≥

(cid:19)

(cid:19)

7

deﬁnition of τ .
Taking the expectation with respect to µ

(f) by exchanging

Q

exp = exp

. Therefore √κ exp( 1
2

τ −1
t=1 ht(ν, µ))

ρ<τ
µ<τ

.

≤

Eµ exp

1
2

τ −1

t=1
P

(cid:18)

ht(ν, µ)

≤

(cid:19)

P
1
√κ

Eµ

ρ<τ
µ<τ ≤

Eρ

1
√κ

=

1
√κ

.

P

By Jensen’s inequality EX = 2 ln exp E 1

2 X

≤

2 ln E exp 1

2 X and so

Eµ

ht(ν, µ)

2 ln Eµ exp

≤

τ

t=1
P

1
2

τ

t=1
P

(cid:18)

ht(ν, µ)

2 ln

= ln

1
√κ

1
κ

≤

(cid:19)

as required.

Proof of Theorem 10. Deﬁne stopping times τν and ¯τν by

τν := min

t : ν<t/ξ<t < wν /wµδ

}

¯τν := min

t : ν<t/µ<t < wνδ

t {

}

t {
First we show that ¯τν ≥

τν. By dominance ξ<t ≥
ν<t
ν<tξ<t
µ<tξ<t
µ<t

< wν δ =

⇒

wµµ<t we have that

< wνδ =

⇒

ν<t
ξ<t

<

wν
wµ

δ

Therefore ¯τν ≥

τν. Let νt := arg maxν∈Mt ht(ν, ξ) and bound

(wνtht(µ, ξ) + wνtht(µ, νt))

∞

∞

ˆht

(a)
=

t=1
X

∞

t=1  
X

2
wµ

t=1
X
(c)

≤

(d)
=

2
wµ  

wνt
wµ

ht(νt, ξ)

(b)

≤

2
wµ

∞

t=1
X

ht(µ, ξ) +

wνht(ν, µ)

Xν∈Mt

τν −1

Xν∈M

t=1
X

!

(e)

≤

2
wµ  

!

H∞ +

wν ht(ν, µ)

H∞ +

wν

ht(ν, µ)

¯τν −1

Xν∈M

t=1
X

!

(cid:4)

(2)

where (a) is the deﬁnition of ˆht. (b) follows by the inequality ht(νt, ξ) < 2(ht(νt, µ)+ht(µ, ξ)). (c) by
dropping wνt ≤
1 and bounding the single term wνtht(νt, µ) by the sum over all ν in the plausible
Mt. (d) by the deﬁnitions of H∞,
τν as previously shown.
Mt and τν. (e) by the fact that ¯τν ≥
class
¯τν −1
Let ∆ν :=
t=1 ht(ν, µ). The ﬁrst claim is proven by taking the expectation with respect to µ and
substituting Theorem 1 to bound EµH∞ ≤
wµ and Lemma 11 with τ = ¯τν and κ = wνδ to bound
Eµ∆ν ≤
wµ and apply Lemma
11 and Markov’s inequality.

ln 1
δ . For the high probability bound let λν := 3 ln 1
δwν

P
ln 1
wν

+ ln 1

+ ln 1

µ (∆ν ≥

λν ) = µ

e∆ν /2
(cid:16)

≥

≤

(cid:17)

eλν /2

e−λν /2Eµ[e∆ν /2]

e−λν /2
√wνδ

≤

= wνδ.

By Theorem 2 we have that H∞ ≤
by the union bound and the fact that
ln 1
λν for all ν and H∞ ≤
∆ν ≤
wµ
ˆht ≤
+ 5 ln 1
(2 ln 1
wµ

ln 1/wµ + 2 ln 1/δwµ with µ-probability at least 1

−
ν wν = 1 we obtain with probability at least 1

wµδ and
δ that
δ , which when substituted into Equation (2) leads to
(cid:4)

+ 2 ln 1
P
δ + 3 Ent(w)) as required.

∞
t=1

2
wµ

−

P

8

ˆht . 1

wµ (cid:16)Ent(w) + ln 1

wµδ (cid:17)

ˆht . 1

wµ (cid:16)Ent(w) + ln 1

wµδ (cid:17)

|M|

∞

K

wν = 1
K

Expectation

Eµ

Eµ

Eµ

Eµ

∞
t=1

∞
t=1

∞
t=1

∞
t=1

P

P

P

P

ˆdt . Ent(w)

δw2
µ

ˆdt . K

δ ln2 K

ˆht . K

ln K + ln 1

(cid:0)

δ (cid:1)

. ignores constant multiplicative factors

5 KWIK Learning

High Probability

ˆdt . Ent(w)
δ2w2
µ

∞
t=1

∞
t=1

∞
t=1

∞
t=1

P

P

P

P

ˆdt . K

δ2 ln2 K

ˆht . K

ln K + ln 1
(cid:0)

δ (cid:1)

Figure 1: Conﬁdence bounds

∞

|M|

∈ M

= K <

The KWIK learning framework involves an environment
and agent interacting sequentially as depicted below. Sup-
and ε, δ > 0 are known to both parties.
pose
A run starts with the environment choosing an unknown
. At each time-step t thereafter the agent chooses be-
µ
tween outputting a predictive distribution ρ(
ω<t) and spe-
. The run is failed if the agent outputs ρ and
cial symbol
hω<t(ρ, µ) > ε, otherwise ωt is observed and the run contin-
ues. An agent is said to be KWIK if it fails the run with probability at most δ and chooses
most B(ε, δ) times with probability at least 1
1/δ [LLWS11].

Algorithm 1 KWIK Learner
1: Inputs: ε, δ and M := {ν1, ν2, · · · , νK }.
2: t ← 1 and ω<t ← ǫ and wν = 1
K
3: loop
4:
5:
6:
7:
8:

at
δ. Ideally, B(ε, δ) should be polynomial in 1/ε and

if ˆht(ω<t) ≤ ε then
output ξ(·|ω<t)

observe ωt and t ← t + 1

output ⊥

else

−

⊥

⊥

·|

t
n
e
m
n
o
r
i
v
n
E

t
n
e
g
A

agent fails run

no

yes

hω<t (ρ, µ) ≤ ε?

present ωt to agent

choose µ ∈ M

output ρ(·|ω<t)

Am I conﬁdent?

yes

no

output ⊥

Figure 2: KWIK learning framework

Theorem 12. Algorithm 1 is KWIK.

Proof. By Theorem 8, Algorithm 1 fails a run with probability at most δ. Using & to ignore constant
multiplicative factors, by Theorem 10 we have that

∞

K
ε

K
δ
≤
(cid:19)
ε ln K

ε

µ

µ

&

ln

(cid:18)(cid:12)
n
(cid:12)
(cid:12)

ˆht & K ln

t : ˆht ≥
o(cid:12)
(cid:12)
at most O
Therefore the agent will choose
(cid:12)
The Hellinger distance upper bounds the total variation distance. δx (µ, ξ) = 1
2
−
ξ(a
1, then with high probability when
predicting it will be ε1-optimal with respect to the total variation distance and it will output
at most O
[DLL09].

⊥
times, which is the same bound achieved by the k-meteorologist algorithm

(cid:18)
times with probability at least 1

hx(µ, ξ). Therefore if Algorithm 1 is run with ε = ε2

−
a∈X |

ln K
δ

t=1
P

x)
|

x)
|

µ(a

| ≤

K
ε2
1

P

p

≤

⊥

(cid:4)

δ.

(cid:19)

δ.

K

(cid:0)

(cid:1)

δ

(cid:16)

(cid:17)

K
δ

9

6 Conclusions

The bound on the squared Hellinger distance ˆht is especially nice because the results are rather
clean. While the super-linear dependence on the size of the model class in Figure 1 is unfortunate,
it is a worst-case bound that is only achieved when at each time-step only one model differs from ξ
(see the proof of Proposition 7 for an example environment class when this occurs). For Bernoulli
classes the estimator performs comparably with the Hoeffding bound (Appendix E). In the case
is countable ˆht is independent of µ, but not wµ, which is also typically unknown. Either
when
choose a conservatively small w and pay the 1
w price, or decrease w with t at some slow rate,
say w = √1⁄t. Analyzing this situation is interesting future work.

w ln 1

There is opportunity for some improvement on the bound ˆd. Intuitively we expect the real
dependence on 1/δ ought to be logarithmic, not linear. The unimprovable result of Theorem 3
is interesting when compared to Theorem 2. Researchers frequently bound the total variation
distance via the KL divergence. These results show that this is sometimes weaker than using the
Hellinger distance when high-probability bounds are required.

M

KWIK learning for sequence prediction was chosen because our new results can easily be ap-
plied to prove a state-of-the-art bound in that setting. Although we have the same theoretical
guarantee as the k-meteorologist algorithm [DLL09], our simple algorithm eliminates environ-
ments smoothly as they become unlikely while in that work no model (expert) is discarded before
at least m = O( 1
δ ) differentiating samples have been observed. This distinction makes us
suspect that Algorithm 1 may perform more efﬁciently in practice. Additionally, assuming ν(
x)
can be computed in constant time, then Algorithm 1 runs in O(K) time per time-step, while a
naive implementation of the k-meteorologist algorithm appears to have O(K 2) running time per
time-step.

ε2 ln 1

·|

Finally, we want to emphasize the generality of the results, especially Theorem 10, which al-
though tight in a minimax sense, can likely be improved in easier cases without changing the deﬁ-
nition of ˆht. An interesting continuation is the parametric case that is intuitively straight-forward,
but technically challenging (see [CB90] and [Hut05, §3] for some of the required techniques).

References

[BD62]

[CB90]

David Blackwell and Lester Dubins. Merging of opinions with increasing information.
The Annals of Mathematical Statistics, 33(3):882–886, 1962.

Bertrand Clarke and Andrew Barron.
methods. IEEE Transactions on Information Theory, 36:453–471, 1990.

Information-theoretic asymptotics of Bayes

[DLL09] Carlos Diuk, Lihong Li, and Bethany Lefﬂer. The adaptive k-meteorologists problem
and its application to structure learning and feature selection in reinforcement learn-
ing.
In Andrea Pohoreckyj Danyluk, L´eon Bottou, and Michael L. Littman, editors,
Proceedings of the 26th Annual International Conference on Machine Learning (ICML 2009),
pages 249–256. ACM, 2009.

[HM07] Marcus Hutter and Andrei Muchnik. On semimeasures predicting Martin-L ¨of random

sequences. Theoretical Computer Science, 382(3):247–261, 2007.

10

[Hut01] Marcus Hutter. Convergence and error bounds for universal prediction of nonbinary
sequences. In Proc. 12th European Conf. on Machine Learning (ECML-2001), volume 2167
of LNAI, Freiburg, 2001. Springer, Berlin.

[Hut03] Marcus Hutter. Optimality of universal Bayesian prediction for general loss and alpha-

bet. Journal of Machine Learning Research, 4:971–997, 2003.

[Hut05] Marcus Hutter. Universal Artiﬁcial Intelligence: Sequential Decisions based on Algorithmic

Probability. Springer, Berlin, 2005.

[LLWS11] Lihong Li, Michael Littman, Thomas Walsh, and Alexander Strehl. Knows what it

knows: a framework for self-aware learning. Machine Learning, 82(3):399–443, 2011.

[Sol78]

Ray Solomonoff. Complexity-based induction systems: Comparisons and convergence
theorems. IEEE Transactions on Information Theory, 24(4):422–432, 1978.

[SSVV11] Glenn Shafer, Alexander Shen, Nikolai Vereshchagin, and Vladimir Vovk. Test martin-

gales, Bayes factors and p-values. Statistical Science, 26(1):84–101, 2011.

[Vil39]

Jean Ville. Etude critique de la notion de collectif. Gauthier-Villars, Paris, 1939.

[Vov87]

Vladimir Vovk. On a randomness criterion. Soviet Mathematics Doklady, 35:656–660,
1987.

A Technical Lemmas

Lemma 13 (Vov87). Let p and q be distribution on X, then

p(a)q(a)

exp

≤

a∈X
P

p

1
2

−

(cid:18)

p(a)

−

2

q(a)

.

p

(cid:19)

(cid:17)

a∈X
P

(cid:16)p

supt z<t ≥

1
δ

(cid:0)

≤

(cid:1)

Lemma 14 (Vil39). If z<t := ξ<t/µ<t, then z<t is a µ-super-martingale, µ (limt→∞ z<t <
µ

δ.

∞

) = 1 and

Proof. The proof is straight-forward and is included for the sake of completeness. Deﬁne A
to be the set of ﬁnite strings deﬁned by

⊂

X ∗

A :=

x

{

∈

X ∗ : ξ(x)/µ(x)

1/δ

t

ℓ(x), ξ(x<t)/µ(x<t) < 1/δ

≥

∧ ∀

≤

}

So A is the set of ﬁnite strings where ξ(x)/µ(x) ﬁrst drops below δ. Let ω
∈
A : µ(x) > 0
then there exists a t such that ω1:t ∈
, then
}

A. Therefore if ¯A =

x
{

∈

X∞ and zt(ω)

1/δ,

≥

µ( lim
t→∞

zt ≥

1/δ)

(a)
=

µ(x)

(b)
=

µ(x)

(c)
=

µ(x)ξ(x)/ξ(x)

(d)

≤

δ

ξ(x)

(e)

≤

δ

Xx∈ ¯A
where (a) follows from the deﬁnition of A and zt. (b) since µ(x) = 0 when x
ξ(x)

¯A. (d) by the bound µ(x)/ξ(x)

wµµ(x) > 0 for x

δ for x

Xx∈ ¯A

Xx∈ ¯A

Xx∈A

¯A. (c) since
A
A. (e) since ξ is a measure. (cid:4)

−

∈

≥

≤
Lemma 15. Both Eµ ln(µ<n/ξ<n) and Eµdn exist and are ﬁnite.

∈

∈

11

Let A :=

Proof.
x
{
ﬁned similarly, then

x
∈
. If 1B is the indicator event 1B(ω) := Jω
A : µ(x)/ξ(x) < 1
(cid:8)
(cid:9)
}

and B =

X n−1 : µ(x) > 0

x
{

∈

∈

∈

A : µ(x)/ξ(x)
Γx : x

1
}

and C =
≥
BK and 1C is de-

∈

Eµ [
|

ln µ<n/ξ<n|

] = Eµ [1B ln µ<n/ξ<n] + Eµ [1C ln ξ<n/µ<n]
1B ln wµ] + Eµ [1Cξ<n/µ<n]

Eµ [

≤

−

ln wµ + 1

≤ −

where the ﬁrst inequality is due to the dominance ξ<n ≥
all x
note that dn+1 is positive and by Equation (1) that dn ≤
Then proceed as in the ﬁrst part.

x for
1. The second inequality follows from basic properties of expectation. For the second part
ln wµ.
(cid:4)

≤
ln µ<n/ξ<n| −

wµµ<n and the inequality ln x

ln ξ<n/µ<n −

ln wµ ≤ |

≥

B Proof of Theorem 1

First we note that the squared Hellinger distances is bounded by the KL divergence, so H∞ ≤
D∞.
We now bound EµD∞, which follows from the chain rule for the conditional relative entropy. Fix
n

N and assume that

∈

∆n−1 := Eµ

dt = Eµ ln

µ<n
ξ<n

,

n

t=1
P

(⋆)

which is easily veriﬁed when n = 1. Therefore

∆n

(a)
= Eµ ln

+ Eµdn

(b)
= Eµ

Eµ

ln

µ<n
ξ<n

(c)
= Eµ ln

µ1:n
ξ1:n

.

(cid:20)

(cid:20)
(a) holds by Lemma 15. (b) by Equation (1) and the deﬁnition of expectation. (c) by the deﬁnition
of (conditional) expectation. Therefore (⋆) holds for all n by induction. By substituting dominance
Eµ ln wµ =
ξn ≥
ln wµ. The proof is completed by taking
the limit as n
and applying the Lebesgue monotone convergence theorem to show that
EµD∞ = limn→∞ ∆n ≤ −
ln wµ. That dt and ht converge to 0 with µ-probability 1 follows from
Markov’s inequality applied to D∞ and H∞ respectively.

wµµn into (⋆) one obtains that ∆n ≤ −

→ ∞

(cid:21)(cid:21)

−

µ1:n
F<n
ξ1:n (cid:12)
(cid:12)
(cid:12)
(cid:12)

C Proof of Theorem 6

t′ are stopping times, then I(ω) = [t(ω), t′(ω)) is called a stopping interval and X(I) := X(t)
If t
is the set of ﬁnite sequences when the start of I becomes known. If ρ is a measure, then ρ(I) :=

≤

x∈X(I) ρ(x) is the ρ-probability of encountering interval I at some point.

P
Lemma 16. Let ν

and I be a stopping interval. Then

∈ M

dt(ν

ξ)
k

≤

Eν

t∈I
P

ν(x)

ln

+ ln

1
wν

ξ(x)
ν(x)

.

(cid:19)

x∈X(I)
P

(cid:18)

12

Proof. The result follows from Theorem 1 and deﬁnitions. Let t be the stopping time governing
the start of interval I. Then

dt(ν

ξ)
k

Eν

t∈I
P

(a)
=
x∈X(I)
P

(b)

≤
x∈X(I)
P

(c)

≤
x∈X(I)
P

ν(x)Eν

dt(ν

"

t∈I
P

∞

ν(x)Eν

x

#

ξ)
k

(cid:12)
(cid:12)
(cid:12)
(cid:12)
dt(ν
(cid:12)

ξ)
k

"

t=ℓ(x)+1
P
1
wν(x)

(d)
=
x∈X(I)
P

#

x

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:18)

1
wν

ν(x) ln

ν(x)

ln

+ ln

ξ(x)
ν(x)

.

(cid:19)

(a) follows by by the deﬁnition of expectation. (b) by increasing the size of the interval. (c) follows
from Theorem 1 by noting that ξ(
(d)
·|
(cid:4)
because wν (x) = wν ν(x)/ξ(x) and by expanding the logarithm.

x) is a mixture over

with prior w(

∈ M}

x) : ν

x).

ν(

·|

·|

{

Proof of Theorem 6. First, the quantity to be bounded can be rewritten as an average of ν-
expectations of a certain random variable.

∆ := Eµ

(a)
=

ct

Eµct

(b)
=

∞

∞

t=1
P

∞

∞

t=1
P

µ(x)

x∈X t−1
P
dx(ν

t=1
P
µ(x)
ξ(x)

ξ)
k

ν∈M
P
1
K

(d)
=

ν(x)

1
K ·

ν(x)
ξ(x)
∞

Eν

ν∈M
P

t=1
P

dx(ν

ξ)
k

µ<t
ξ<t

dt(ν

ξ)
k

(c)
=

(e)
=

1
K
1
K

ν∈M
P

ν∈M
P

t=1
P
Eν

x∈X t−1
P
∞
µ<t
ξ<t

t=1
P

dt(ν

.

ξ)
k

∆(ν)

{z

(a) follows by the linearity of expectation and positivity of ct. (b) by writing out the deﬁnition
of the expectation. (c), (d) and (e) exchanging sums and the deﬁnition of expectation. Deﬁne
at, bt : X∞

N by

|

}

→
at(ω) := sup

≤
≥
Iβ(ω) :=

ln ξ(ω<t′)/ν(ω<t′)
⌋

t′≤t ⌊

bt(ω) := sup

ln µ(ω<t′)/ξ(ω<t′ )
⌋

,

t′≤t ⌊

which are monotone non-decreasing. By the deﬁnition of ξ as a uniform mixture over
µ(x)/ξ(x)
at(ω), bt(ω)

,
M
ln K =: L. Furthermore, µ(ǫ) = ν(ǫ) = ξ(ǫ) = 1 implies that

K, so bt(ω)
0. Deﬁne intervals of the following form

≤

}
Then N can be divided into disjoint intervals of the form Iβ and Iα,β where α > β.

∧

∧

Iα,β(ω) :=

t : at = α
{

bt = β

.

}

t : bt = β
{

at ≤

β

(ω

∀

∈

X∞), N =

Iβ(ω)



∪

Iα,β(ω)



[α>β∈N

L

[β=0

(3)


See Figure 3 for an example of the deﬁnition of Iβ and Iα,β. Then ∆(ν) can be decomposed as



13

follows

∆(ν)

≡
L

∞

Eν

t=1
P

Eν

=

µ<t
ξ<t

dt(ν

ξ)
k

µ<t
ξ<t

dt(ν

+

ξ)
k

L

∞

Eν

β=0
P

α=β+1
P

t∈Iα,β
P
∆2(ν)

β=0
P

t∈Iβ
P

∆1(ν)

µ<t
ξ<t

dt(ν

ξ)
k

|
where the second equality follows from Equation (3) and by linearity of the expectation. We now
bound ∆1(ν) and ∆2(ν).

{z

{z

|

}

}

∆1(ν)

L

Eν

µ<t
ξ<t

dt(ν

ξ)
k

(a)

≤

ν(x)

L + ln

L

β=0
P
ξ(x)
ν(x)

t∈Iβ
P
eβ+1

≡

(b)

≤

β=0
P
L

β=0
P

x∈X(Iβ )
P

(cid:18)

(c)

≤

(cid:19)

β=0
P

eβ+1Eν

dt(ν

ξ)
k

L

t∈Iβ
P
eβ+1ν(Iβ) (L + β + 1) .

(a) follows since on the interval Iβ the quantity µ<t/ξ<t < eβ+1. (b) follows from Lemma 16 and
by noting that ln 1/wµ = ln K = L. (c) by the deﬁnition of ν(Iβ) and because ξ<t/ν<t < eβ+1 on the
interval Iβ. ∆2(ν) is bounded in a similar fashion.

L

∞

β=0
P
L

α=β+1
P
eβ+1

Eν

t∈Iα,β
P

∞

µ<t
ξ<t

dt(ν

ξ)
k

ν(x)

x∈X(Iα,β )
P

α=β+1
P
ν(Iα,β) (L + α + 1)

(cid:18)

∞

eβ+1

α=β+1
P

∞

eβ+1

Eν

α=β+1
P

t∈Iα,β
P

dt(ν

ξ)
k

(a)

L

≤

β=0
P
L + ln

(d)

L

≤

β=0
P

ξ(x)
ν(x)

(cid:19)
∞

α=β+1
P

eβ+1

e−α (L + α + 1)

eβ+1e−β (L + β + 3)

(f)
= 3(L + 1)(L + 2).

∆2(ν)

≡

(b)

≤

(c)

≤

(e)
=

β=0
P
L

β=0
P
L

β=0
P

(a) follows because µ<t/ξ<t < eβ+1 on the interval Iα,β and by expanding the interval. (b) by
X(Iα,β), then a ξ(x)/ν(x)
Lemma 16. (c) because ν(Iα,β) =
≥
eα. By Lemma 14 the ν-probability of this ever occurring is at most e−α, which implies ν(Iα,β)
≤
e−α and so gives (d). (e) and (f) follow from simple algebra. Combining the bounds of ∆1(ν) and
∆2(ν) leads to

x∈X(Iα,β ) ν(x). By deﬁnition, if x

P

∈

wν∆(ν)

wν (∆1(ν) + ∆2(ν))

ν∈M
P

≡

ν∈M
P
3(L + 1)(L + 2) +

wν

eβ+1ν(Iβ)(L + β + 1)

(b)
= 3(L + 1)(L + 2) +

eβ+1ξ(Iβ)(L + β + 1)

3(L + 1)(L + 2) +

2(L + β + 1)

(d)
= 6L2 + 14L + 8

(a)

≤

(c)

≤

L

β=0
P

ν∈M
P
L

β=0
P
L

β=0
P

14

ν∈M wν ν(A) = ξ(A) for all measurable A. (c) from Lemma 14 applied to bound ξ(Iβ)

(a) by substituting the bounds for ∆1(ν) and ∆2(ν). (b) by exchanging sums and recalling that
e−β
in the same way as ν(Iα,β) was bounded. (d) by simple algebra. The theorem is completed by
P
substituting L := ln K.
(cid:4)

≤

time, t
ξ(ω<t)/ν(ω<t)
µ(ω<t)/ξ(ω<t)
at
bt

3
5
2
2
1

2
2
2
1
1
I1

1
1
1
0
0
I0
Figure 3: Example Iα,β and Iβ

4
5
1
2
1
I2,1

5
5
5
2
2

6
3
2
2
2
I2

7
2
1
2
2

8
3
9
2
3
I3

D Proof of Proposition 7

{

Let X =
0, 1
}
by zeros νk(1
x) := Jℓ(x) < kK. Let
|
The Bayes mixture over
M
then by substituting deﬁnitions one obtains ξ(1t) = (K

and deﬁne measure νk to be the deterministic measure producing k ones followed
and the true measure be µ := νK−1.
K
K−1
k=0 νk(x). If t < K,
t). Therefore

k
under the uniform prior becomes ξ(x) := 1
K
1t) = 1/(K
t)/K and ξ(0
|
P

νk : 0

M

:=

≤

−

≤

−

(cid:8)

(cid:9)

1

Eµ

∞

(a)

ct

≥
K−1

t=1
P
(c)

≥

Eµ

t=1
P
νt(1t)
Kξ(1t)

K

K−1

K−1

(b)
=

ct

k=0
P
(d)
=

t=0
P
ξ
k

d1t

νt

νk(1t)
ξ(1t)
ln t
(e)
t

≥

d1t

νk
(cid:16)
ln K

1
2

ξ
k

−

(cid:17)
1.

−
1
K
K

t=0
(cid:1)
P
(a) follows by truncating the sum and positivity of ct. (b) by the deﬁnition of ct, the expectation
and because µ(1t) = 1 for all t
1. (c) by dropping all terms in the sum over k except for
k = t and positivity of all quantities. (d) and (e) follow by substituting deﬁnitions and simple
calculus/algebra.

t=1
P

K

−

≤

(cid:0)

E Experiments

=

M

ν0,
{

, ν40}

We set δ = 1/10 and
where νk is the Bernoulli
· · ·
measure with parameter θk := k/40. We then sampled 20,000 se-
quences of length 100 from the Lebesgue measure µ = ν20 and
computed the average value of ˆht. For each t we computed the
estimated quantile ˆqt as the value such that ht(µ, ξ) < ˆqt for 90%
of the samples. We compare to

0.6

0.4

0.2

r
o
r
r
E
r
e
g
n
i
l
l
e
H

ft :=

1
2t

ln

2
δ

r

gt :=

r

1
2t

ln

2t(t + 1)
δ

which are obtained from the Hoeffding and union bounds and satisfy

gt
ft
ˆht
ˆqt

20

40

80 100

60
Time

µ

ˆθt −
≥
(cid:17)
where ˆθt is the empiric estimator of parameter θ. Some remarks:

1/2

ˆθt −
(cid:16)(cid:12)
(cid:12)
(cid:12)

t :

ft

≤

−

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

µ

(cid:16)

∀

1

δ

1/2

gt

≤

1

δ

≥

−

(cid:17)

(cid:12)
(cid:12)
(cid:12)

15

• The frequentist estimator ˆθt(ω<t)

ω<t) is very tight with high probability. Therefore
ξ(1
|
comparing error between ˆθt and the true parameter 1/2 is essentially the same as comparing
ξ(

ω<t) and µ(

ω<t).

≈

·|

·|

• The comparison to ft is not entirely fair to ˆht for two reasons. First because ˆht upper bounds
ht with high probability for all t while ft does so only for each t and secondly because ft was
based on the total variation distance, which is smaller than the Hellinger distance.

• The comparison between ˆht and gt is not fair to gt because the application of the union bound

was rather weak.

• The comparison to the quantile is not entirely fair to ˆht, since ˆqt is computed for a single θ

and individually for each t, while ˆht must work for all models in

and all t.

M

• We also ran the experiment with 21 uniformly distributed environments with almost identi-
cal results showing that ˆht is an excellent bound and strengthening our belief that at least in
this simple setting the bound of Theorem 10 can be substantially improved in the i.i.d. case.

• The results indicate that ˆht tracks close to ft and ˆqt, which essentially lower-bounds the
optimum. We expect the deﬁnition of gt can be improved to follow close to ˆht and ft without
weakening the bound (holding for all t), but doubt that anything does much better than ˆht.

16

F Table of Notation
N
JexprK
ln
X
X ∗
X∞
x, y
ℓ(x)
ǫ
Γx
F<t
F

1

}

∈

−

X∞

xω : ω
{

natural numbers
indicator function of expression expr
natural logarithm
ﬁnite or countable alphabet
set of ﬁnite strings on X
set of inﬁnite strings on X
symbols or strings in X ∗
length of string x
empty string of length 0
cylinder set of x, Γx :=
sigma algebra generated by cylinders on strings of length t
sigma algebra generated by by cylinders on strings of all ﬁnite
lengths
environment class of hypothesis measures
true measure from which sequences are sampled
bayes mixture over all ν
measures in
random variable deﬁned by ρt(ω) := ρ(ωt|
random variable deﬁned by ρ<t(ω) := ρ(ω<t)
expectation w.r.t. µ
prior distribution w :
prior weight of measure ν
posterior of measure ν
∈ M
shannons entropy function
µ is absolutely continuous w.r.t. ξ
KL divergence between predictive distributions of µ and ξ given
ﬁnite sequence x
squared Hellinger distance between predictive distributions of µ
and ξ given ﬁnite sequence x
random variable ht(ω) := hω<t(µ, ξ)
random variable dt(ω) := dω<t(µ
ξ)
k
random variable ct(ω) :=
∞
t=1 dt and

ν∈M wν(ω<t)dω<t(ν
∞
t=1 ct respectively

having observed x

∞
t=1 ht and

with prior w :

M →

M →

ξ)
k

∈ M

∈ M

ω<t)

(0, 1]

(0, 1]

M

M

number of models in
P
P
upper conﬁdence bound on ht
upper conﬁdence bound on dt
small positive reals with ε typically an accuracy parameter and δ
a conﬁdence (probability)

P
P

M
µ
ξ
ν, ρ
ρt
ρ<t
Eµ
w
wν
wν(x)
Ent
µ
≪
dx(µ

ξ
ξ)
k

hx(µ, ξ)

ht
dt
ct
Ht, Dt, Ct
K
ˆht
ˆdt
ε, δ

17

