Adversarial Multi-lingual Neural Relation Extraction

Xiaozhi Wang1∗ , Xu Han1∗, Yankai Lin1, Zhiyuan Liu1†, Maosong Sun1,2
1Department of Computer Science and Technology,
State Key Lab on Intelligent Technology and Systems,
Beijing National Research Center for Information Science and Technology,
Tsinghua University, Beijing, China
2Beijing Advanced Innovation Center for Imaging Technology,
Capital Normal University, Beijing, China

Abstract

Multi-lingual relation extraction aims to ﬁnd unknown relational facts from text in various lan-
guages. Existing models cannot well capture the consistency and diversity of relation patterns in
different languages. To address these issues, we propose an adversarial multi-lingual neural rela-
tion extraction (AMNRE) model, which builds both consistent and individual representations for
each sentence to consider the consistency and diversity among languages. Further, we adopt an
adversarial training strategy to ensure those consistent sentence representations could effectively
extract the language-consistent relation patterns. The experimental results on real-world datasets
demonstrate that our AMNRE model signiﬁcantly outperforms the state-of-the-art models. The
source code of this paper can be obtained from https://github.com/thunlp/AMNRE.

1

Introduction

Relation extraction (RE) is a crucial task in NLP, which aims to extract semantic relations between entity
pairs from the sentences containing them. For example, given an entity pair (Bill Gates, Microsoft)
and a sentence “Bill Gates is the co-founder and CEO of Microsoft”, we want to ﬁgure out the relation
Founder between the two entities. RE can potentially beneﬁt many applications, such as knowledge
base construction (Zhong et al., 2015; Han et al., 2018) and question answering (Xiang et al., 2017).

Recently, neural models have shown their great abilities in RE. Zeng et al. (2014) introduce a convolu-
tional neural network (CNN) to extract relational facts with automatically learning features from text. To
address the issue of lack of data, Zeng et al. (2015) incorporate multi-instance learning with a piece-wise
convolutional neural network (PCNN) to extract relations in distantly supervised data. Because distant
supervision suffer from wrong labeling problems, Lin et al. (2016) further employ a sentence-level selec-
tive attention to ﬁlter out those noisy sentences in distantly supervised data and achieve state-of-the-art
performance. All these neural relation extraction (NRE) models merely focus on extracting relational
facts from mono-lingual data, ignoring the rich information in multi-lingual data.

Lin et al. (2017) propose a multi-lingual attention-based neural relation extraction (MNRE) model,
which considers the consistency and complementarity in multi-lingual data. MNRE builds a sentence
representation for each sentence in various languages and employs a multi-lingual attention to capture
the pattern consistency and complementarity among languages.

Although MNRE achieves great success in multi-lingual RE, it still has some problems. MNRE learns
a single representation for each sentence in various languages, which cannot well capture both the con-
sistency and diversity of relation patterns in different languages. Moreover, MNRE simply utilizes a
multi-lingual attention mechanism and a global relation predictor to capture the consistent relation pat-
terns among multiple languages. From the experimental data, we ﬁnd that the sentence representations in
different languages are still far from each other and linearly separable. Therefore, it is hard for the multi-

∗ indicates equal contribution
† Corresponding author: Zhiyuan Liu (liuzy@tsinghua.edu.cn).

This work is
http://creativecommons.org/licenses/by/4.0/

licensed under a Creative Commons Attribution 4.0 International License.

License details:

Figure 1: Overall architecture of our adversarial multi-lingual neural relation extraction (AMNRE) which
contains two languages.

lingual attention mechanism and global relation predictor to extract relation consistency from distinct
sentence representations.

To address these issues, we propose an adversarial multi-lingual NRE (AMNRE) model. As shown
in Figure 1, for an entity pair, we encode its corresponding sentences in various languages through
neural sentence encoders. For each sentence, we build an individual representation to grasp its indi-
vidual language features and a consistent representation to encode its substantially consistent features
among languages. Further, we adopt an adversarial training strategy to ensure AMNRE can extract the
language-consistent relation patterns from the consistent representations. Orthogonality constraints are
also adopted to enhance differences between individual representations and consistent representations
for each language.

In experiments, we take Chinese and English to show the effectiveness of AMNRE. The experimen-
tal results show that AMNRE outperforms all baseline models signiﬁcantly by explicitly encoding the
consistency and diversity among languages. And we further give a case study and an ablation study to
demonstrate the adversarial training strategy could help AMNRE to capture language-consistent relation
patterns.

2 Related Works

2.1 Relation Extraction

Traditional supervised RE models (Zelenko et al., 2003; Socher et al., 2012; Santos et al., 2015) heavily
rely on abundant amounts of high-quality annotated data. Hence, Mintz et al. (2009) propose a distantly
supervised model for RE. Distant supervision aligns knowledge bases (KBs) and text to automatically
annotate data, and thus distantly supervised models inevitably suffer from wrong labeling problems.

To alleviate the noise issue, Riedel et al. (2010) and Hoffmann et al. (2011) propose multi-instance
learning (MIL) mechanisms for single-label and multi-label problems respectively. Then, Zeng et al.
(2015) attempt to integrate neural models into distant supervision. Lin et al. (2016) further propose
a sentence-level attention to jointly consider all sentences containing same entity pairs for RE. The
attention-based neural relation extraction (NRE) model has become a foundation for some recent works
(Ji et al., 2017; Zeng et al., 2017; Liu et al., 2017b; Wu et al., 2017; Feng et al., 2018; Zeng et al., 2018).
Most existing RE models are devoted to extracting relations from mono-lingual data and ignore in-
formation lying in text of multiple languages. Faruqui and Kumar (2015) and Verga et al. (2016) ﬁrst
attempt to adopt multi-lingual transfer learning for RE. However, both of these works learn predictive

models on a new language for existing KBs, without fully leveraging semantic information in text. Then,
Lin et al. (2017) construct a multi-lingual NRE (MNRE) model to jointly represent text of multiple
languages to enhance RE. In this paper, we propose a novel multi-lingual NRE framework to explic-
itly encode language consistency and diversity into different semantic spaces, which can achieve more
effective representations for RE.

2.2 Adversarial Training

Goodfellow et al. (2015) propose adversarial training for image classiﬁcation tasks. Afterwards, Good-
fellow et al. (2014) propose a mature adversarial training framework and use the framework to train
generative models. Adversarial networks have recently been used as methods to narrow probability dis-
tributions and proven effective in some tasks. In domain adaptation, Ganin et al. (2016) and Bousmalis
et al. (2016) adopt adverarial training strategies to transfer the features of one source domain to its cor-
responding target domain.

Inspired by Ganin et al. (2016), adversarial training has also been explored in some typical NLP tasks
for multi-feature fusion. Park and Im (2016) propose a multi-modal representation learning model based
on adversarial training. Then, Liu et al. (2017a) employ adversarial training to construct a multi-task
learning model for text classiﬁcation by extending the original binary adversarial training to the multi-
class version. And a similar adversarial framework is also adapted by Chen et al. (2017) to learn features
from different datasets for chinese word segmentation. In this paper, we adopt adversarial training to
boost feature fusion to grasp the consistency among different languages.

3 Methodology

In this section, we introduce the overall framework of our proposed AMNRE in detail. As shown in
Figure 1, for each entity pair, AMNRE encodes its corresponding sentences in different languages into
several semantic spaces to grasp their individual language patterns. Meanwhile, a uniﬁed space is also set
up to encode consistent features among languages. By explicitly encoding the consistency and diversity
among languages, AMNRE can achieve better extraction results in the multi-lingual scenario.

For each given entity pair, we deﬁne its corresponding sentences in n different languages as T =
{S1, . . . , Sn}, where Sj = {x1
j } denotes the sentence set in the j-th language. All these
sentences are labeled with the relation r ∈ R by heuristical labeling algorithms in distant supervision
(Mintz et al., 2009). Our model aims to learn a relation extractor by maximizing the conditional proba-
bility p(r|T ) with the following three components:

j , . . . , x|Sj |

Sentence Encoder. Given a sentence and its target entity pair, we employ neural networks to encode
the sentence into a embedding. In this paper, we implement the sentence encoder with both convolutional
(CNN) and recurrent (RNN) architectures. Speciﬁcally, we set the encoders EI
to encode each
sentence in the j-th language into its individual and consistent embeddings respectively, and expect these
embeddings to capture the diversity and consistency among languages.

j and EC
j

Multi-lingual Attention. Since not all sentences are labeled correctly in distant supervision, we
adopt multi-lingual attention mechanisms to capture those informative sentences. In practice, we ap-
ply language-individual and language-consistent attentions to compute local and global textual relation
representations respectively for ﬁnal prediction.

Adversarial Training. Under the framework of AMNRE, we encode the sentences in various lan-
guages into a uniﬁed consistent semantic space. We further adopt adversarial training to ensure these
sentences are well fused in the uniﬁed space after encoding so that our model can effectively extract the
language-consistent relation patterns.

We will introduce the three components in detail as follows.

3.1 Sentence Encoder

Given a sentence x = {w1, w2, . . .} containing two entities, we apply neural architectures including both
CNN and RNN to encode the sentence into a continuous low-dimensional space to capture its implicit
semantics.

Input Layer

3.1.1
The input layer transforms all input words in the sentence into corresponding input embeddings by
concatenating their word embeddings and position embeddings. The word embeddings are pre-trained
by Skip-Gram (Mikolov et al., 2013). The position embeddings are a widely-used technique in RE
proposed by Zeng et al. (2014), representing each word’s relative distances to the two entities into two
kp-dimensional vectors. The input layer represents the input sentence as a ki-dimensional embedding
sequence x = {w1, w2, . . .}, where ki = kw +kp ×2, kw and kp are the dimensions of word embeddings
and position embeddings respectively.

3.1.2 Encoding Layer
After representing the input sentence as a ki-dimensional embedding sequence, we select both CNN
(Zeng et al., 2014) and RNN (Zhang and Wang, 2015) to encode the input embedding sequence x =
{w1, w2, . . .} to its sentence embedding.

CNN slides a convolution kernel with the window size m to extract the kh-dimensional local features,

A max-pooling is then adopted to obtain the ﬁnal sentence embedding y as follows,

hi = CNN(cid:0)wi− m−1

, . . . , wi+ m−1

2

2

(cid:1).

[y]j = max{[h1]j, . . . , [hn]j}.

RNN is mainly designed for modeling sequential data. In this paper, we adopt bidirectional RNN

(Bi-RNN) to incorporate information from both sides of the sentence sequence as follows,

−→
h i = RNNf (xi,

−→
h i−1),

←−
h i = RNNb(xi,

←−
h i+1),

−→
h i and

←−
h i are the kh-dimensional hidden states at the position i of the forward and backward
where
RNN respectively. RNN(·) is the recurrent unit and we select gated recurrent unit (GRU) (Cho et al.,
2014) as the recurrent unit in this paper. We concatenate both the forward and backward hidden states as
the sentence embedding y,

For simplicity, we denote such a sentence encoding operation as the following equation,

y = [

−→
h n;

←−
h 1].

y = E(x).

For each sentence xi
encoder EC

j ∈ Sj, we adopt the individual sentence encoder EI

j and the consistent sentence

j to embed the sentence into its individual and consistent representations respectively,

{y1

j , y2

j , . . .} = {EI

j (x1

j ), EI

j (x2

j ), . . .},

{¯y1

j , ¯y2

j , . . .} = {EC

j (x1

j ), EC

j (x2

j ), . . .}.

3.2 Multi-lingual Selective Attention

For each given entity pair, AMNRE adopts multi-lingual selective attention mechanisms to exploit in-
formative sentences in T . We explicitly encode languages’ consistency and diversity into individual and
consistent representations, thus our attentions are more simple than those proposed in Lin et al. (2017).

3.2.1 Language-individual Attention
Since it is intuitive that each language has its own characteristic, we set language-individual attention
mechanisms for different languages. In the individual semantic space of the j-th language, we assign a
query vector rj to each relation r ∈ R. The attention score for each sentence in Sj = {x1
j , . . .} is
deﬁned as follows,

j , x2

The attention scores can be used to compute language-individual textual relation representations,

(1)

(2)

(3)

(4)

(5)

(6)

(7)

(8)

αi

j =

exp(r(cid:62)
j yi
j)
j yk
k=1 exp(r(cid:62)
j )

(cid:80)|Sj |

.

sj =

j yk
αk
j .

|Sj |
(cid:88)

k=1

βi
j =

exp(¯r(cid:62)¯yi
j)
(cid:80)|Sl|
k=1 exp(¯r(cid:62)¯yk
l )

.

(cid:80)n

l=1

¯s =

n
(cid:88)

|Sl|
(cid:88)

l=1

k=1

l ¯yk
βk
l .

p(r|T ) = p(r|¯s)

p(r|sj).

n
(cid:89)

j=1

3.2.2 Language-consistent Attention
Besides language-individual attention mechanisms, we also adopt a language-consistent attention to take
all sentences in all languages into consideration. In the consistent semantic space, we also assign a query
vector ¯r to each relation r ∈ R and the attention score for each sentence is deﬁned as follows,

The attention scores can be used to compute language-consistent textual relation representations,

3.3 Relation Prediction

With the language-individual textual relation representations {s1, s2, . . .} and the language-consistent
textual relation representation ¯s, we can estimate the probability p(r|T ) over each relation r ∈ R,

p(r|¯s) and p(r|sj) can be deﬁned as follows,

p(r|sj) = softmax[Rjsj + dj],

p(r|¯s) = softmax[ ¯R¯s + ¯d],

where dj and ¯d are bias vectors, Rj is the speciﬁc relation matrix of the j-th language, and ¯R is the
consistent relation matrix. We deﬁne the objective function to train the relation extractor as follows,

min
θ

Lnre(θ) = −

log p(rl|Tl),

(cid:88)

l

where θ is all parameters in the framework. In the training phase, p(r|T ) is computed using the labeled
relations as the attention queries. In the test phase, we need to use each possible relation as attention
queries to compute p(r|T ) for relation prediction since the relations are unknown in advance.

3.4 Adversarial Training

In our framework, we encode sentences of various languages into a consistent semantic space to grasp
the consistency among languages. One possible situation is that sentences of different languages are
aggregated in different places of the space and linearly separable. In this case, our purpose of mining
substantially consistent relation patterns in different languages is difﬁcult to be reached. Inspired by
Ganin et al. (2016), we adopt adversarial training into our framework to address this problem.

In the adversarial training, we deﬁne a discriminator to estimate which kind of languages the sentences

from. The probability distributions over these sentences are formalized as follows,

D(¯si

j) = softmax(MLP(¯si

j)),

where MLP is a two-layer multilayer perceptron network.

Contrary to the discriminator, the consistent sentence encoders are expected to produce sentence em-
beddings that cannot be reliably predicted by the discriminator. Hence, the adversarial training process
is a min-max game and can be formalized as follows,

min
θC
E

max
θD

n
(cid:88)

|Sj |
(cid:88)

j=1

i=1

log[D(EC

j (xi

j))]j,

where [·]j is the j-th value of the vector.

The formula means that given a sentence of any language, the corresponding sentence encoder of its
language generates the sentence embedding to confuse the discriminator. Meanwhile, the discriminator

(9)

(10)

(11)

(12)

(13)

(14)

(15)

tries its best to predict the language of the sentence according to the sentence embedding. After sufﬁcient
training, the encoders and the discriminator reach a balance, and sentences of different languages con-
taining similar semantic information can be well encoded into adjacent places of the space. In training,
we optimize the following loss functions instead of Eq. 15,

LE

adv(θC

E ) =

min
θC
E

(cid:88)

(cid:88)

(cid:88)

l

Sj ∈Tl

xi

j ∈Sj

log[D(EC

j (xi

j))]j, min
θD

LD

adv(θD) = −

(cid:88)

(cid:88)

(cid:88)

l

Sj ∈Tl

xi

j ∈Sj

log[D(EC

j (xi

j))]j,

(16)

where θC

E and θD are all parameters of the consistent sentence encoders and the discriminator.

We notice that language-individual semantics could be wrongly encoded into the consistent semantic
space, and may have negative effects on extracting language-consistent features. Inspired by Bousmalis
et al. (2016), we adopt orthogonality constraints to alleviate this issue. We minimize the following
penalty function:

min
θE

Lpenalty(θE) =

n
(cid:88)

j=1

(cid:13)
(cid:13)IT
(cid:13)

j Cj

(cid:13)
(cid:13)
(cid:13)F

,

(17)

where Ij and Cj are two matrices whose row vectors are the embeddings of sentences in the j-th language
encoded by EI
respectively. θE is parameters of the all encoders. And (cid:107)·(cid:107)F is the squared
Frobenius norm.

j and EC
j

3.5

Implementation Details

During training process, we combine the extraction and adversarial objective functions as follows,

L = Lnre(θ) + λ1LD

adv(θD) + λ2LE

adv(θC

E ) + λ3Lpenalty(θE),

(18)

where λ1, λ2, and λ3 are harmonic factors. All models are optimized using stochastic gradient descent
(SGD). In practice, we integrate λ1 and λ2 into the alternating ratio among the loss functions, and we
calibrate a 1:1:5 ratio among Lnre(θ) + λ3Lpenalty(θE), LD

E ). λ3 is set as 0.02.

adv(θD) and LE

adv(θC

4 Experiments

4.1 Datasets and Evaluation

We evaluate our models on a multi-lingual relation extraction dataset developed by Lin et al. (2017).
The dataset consists of English and Chinese data, and has 176 relations including a special relation NA
indicating that there is no relation between entities. The whole dataset is divided into three parts for
training, validation and test. The statistics of the dataset are listed in Table 1.

Dataset

#Rel

#Sent

#Fact

Dataset

#Rel

#Sent

#Fact

English

Training
Validation
Test

176
176
176

1,022,239
80,191
162,018

47,638
2,192
4,326

Chinese

Training
Validation
Test

176
176
176

940,595
82,699
167,224

42,536
2,192
4,326

Table 1: Statistics of the dataset

We evaluate all models by the held-out evaluation following previous works (Mintz et al., 2009; Lin et
al., 2017). In experiments, we report precision-recall curves of recall under 0.3 since we focus more on
the performance of those top-ranked results. To give a complete view of the performance, we also report
the area under the curve (AUC).

4.2 Experiment Settings

Following the settings of previous works, we use the pre-trained word embeddings learned by Skip-Gram
as the initial word embeddings. We implement the MNRE framework proposed by Lin et al. (2017) by
ourselves. For fair comparision, we set most of the hyperparameters following Lin et al. (2017). We list
the best setting of hyperparameters in Table 2.

