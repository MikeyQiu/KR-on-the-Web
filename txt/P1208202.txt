1
1
0
2
 
g
u
A
 
4
1
 
 
]
I

A
.
s
c
[
 
 
1
v
5
6
8
2
.
8
0
1
1
:
v
i
X
r
a

Conscious Machines and Consciousness Oriented
Programming

Norbert B´atfai
University of Debrecen
Department of Information Technology
batfai.norbert@inf.unideb.hu

August 16, 2011

Abstract

In this paper, we investigate the following question: how could you
write such computer programs that can work like conscious beings?
The motivation behind this question is that we want to create such
applications that can see the future. The aim of this paper is to provide
an overall conceptual framework for this new approach to machine
consciousness. So we introduce a new programming paradigm called
Consciousness Oriented Programming (COP).

Keywords: programming paradigm, machine consciousness, conscious
computer programs, intuitive computer programs, quasi-intuitive Tu-
ring machines, ConsciousJ programming language.

Contents

1 Introduction

1.1 Previous and Similar Works . . . . . . . . . . . . . . . . . . .

2 Machine Consciousness

2.1 Some Intuitive Examples for Deﬁnitions . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . .
2.2 The Trick of Consciousness
. . .
2.2.1 An Evolutionary Aspect of the living in the past
2.3 The Consciousness as a Computing Paradigm . . . . . . . . .

3 Consciousness Oriented Programming

4 Use Cases for the COP

4.1 Programming on Paper

. . . . . . . . . . . . . . . . . . . . .
4.1.1 Quasi-Intuitive Machines and Languages . . . . . . . .
4.2 Programming on Computer . . . . . . . . . . . . . . . . . . .
4.2.1 ConsciousJ . . . . . . . . . . . . . . . . . . . . . . . .

2
3

4
4
7
11
12

12

13
13
13
18
19

1

21

21

5

8

12

14

15
16
16
17

5 Conclusion

6 Acknowledgements

List of Figures

1
2

3

4

5

6
7
8

1

1
2
3
4
5
6

7

. . . . . . . . . .

The author walks across the zebra crossing.
This drawing is an illustration based on the match between
FC Barcelona and Levante UD in the Primera Divisi´on on
February 24, 2008.
It is created with the FerSML football
simulation platform B´atfai [2010a], B´atfai [2010b].
A simple schematic drawing of the well-known conception of
”living in the past”. . . . . . . . . . . . . . . . . . . . . . . . .
An architectural model for the universal quasi-intuitive ma-
chine.
An architectural model for a machine QIM that accepts the
language QIM . . . . . . . . . . . . . . . . . . . . . . . . . . .
The Turing machine SLM for the case E ∈ R.
. . . . . . . .
The Turing machine SLM (cid:48) for the case E ∈ RE \ R. . . . . .
. . . . . . . . . . . . . . . . . . .
The Turing machine SWM .

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

. . . . . .

List of Tables

Listings

Execution results of the delay aspect (with the variable BALL-
LIFESPAN set to 100.000). . . . . . . . . . . . . . . . . . . .

11

The source code for the Game class.
The source code for the Ball class.
The source code for the Sensory interface.
The source code for the Player class.
The source code for the Delay aspect.
A ”conscious” code snippet written in a ﬁctitious language
called ConsciousJ.
. . . . . . . . . . . . . . . . . . . . . . . .
A ”conscious” class written in ConsciousJ. . . . . . . . . . . .

. . . . . . . . . . . . . .
. . . . . . . . . . . . . . .
. . . . . . . . . . .
. . . . . . . . . . . . . .
. . . . . . . . . . . . .

7
9
9
10
10

19
19

1

Introduction

Eugen Wigner wrote in his essay [Wigner, 1967] that ”observation of infants
where we may be able to sense the progress of the awakening of conscious-
ness” is a possible method to solve the mind-body problem. I have three

2

children and I have been observing them when I can. They are now 3 and
5 years old. The older child has already been perfectly able to arrange the
everyday events in time, the younger two haven’t been able to speak about
it with any degree of accuracy yet. With hindsight, moreover, at the age of
2, they couldn’t handle the term timeliness.

In the course of human cognition, there has been a need to know the
future from time immemorial. The success of this eﬀort has been culminating
at Newton’s mechanical world-view in the late 19th century. But since
then the quantum mechanics has turned this deterministic world-view upside
down, opening the way to use new quantum phenomena of a deeper level
of reality. But even though the Orch OR [Penrose and Hameroﬀ, 1998]
model of quantum consciousness is an exciting and promising theory, we
have to restrict ourselves to investigate computer programs and machine
consciousness because computers of nowadays have no quantum computing
parts.

We believe that one of the drivers of evolutionary evolving of natural
intelligence was the process of replacing, by natural selection, the automatic
response of living matter with foresight.

In this work, in compliance with this outlined motivation, we emphasize
the pursuit of predicting the future as the cornerstone of the deﬁnition of
machine consciousness.

1.1 Previous and Similar Works

Several recent studies have included deﬁnitions of machine consciousness.
For example, [Starzyk and Prasad, 2011] outlined an architectural model
inspired by the functional organization of the human brain. Their deﬁnition
[Starzyk and Prasad, 2011, pp. 9] says that a machine is conscious if the
functional components concerned are present at the machine in question.
This and similar (for example, CogAﬀ [Sloman and Chrisley, 2002], Lida
of GW [Baars and Franklin, 2009]) models typically involve a detailed de-
scription of a sophisticated architectural system and focus on the question
of ”How”.

By contrast, in our opinion, the conditions of the deﬁnition should be in
a format that the fulﬁllment of these can be easily checked. Accordingly, in
this paper we are not interested in the question of ”How”. We place only
one aspect at the heart of the deﬁnition of machine consciousness, namely
conscious machines must be able to see the future. This aspect is not totally
unknown because it is used in creating the goal- and utility-based agents
[Russell and Norvig, 1995, pp. 42-45], but we will go further than that.

Our approach for machine (self-) consciousness supposedly will be very
compute intensive, so it may be interesting that in [B´atfai, 2009] we outlined
an idea about where the necessary computations should be performed in the
case of the operating systems.

3

2 Machine Consciousness

First, we give the general frames of deﬁnitions in which the term ”computer
program” is interpreted broadly, that is the Turing-like machines, the vari-
ous web applications, the command-line interfaces, the GUIs, the kernel of
operating systems and goal- or utility-based agents are regarded as computer
programs.

Deﬁnition 1 (Knowing the Future Input). A computer program knows its
future input if it can predict that better than a random guess.

Deﬁnition 2 (Knowing the Future State). A computer program knows its
future state if it can predict that better than a random guess.

Deﬁnition 3 (Conscious Computer Programs). The behavior of a computer
program is considered conscious if it knows its future input.

Deﬁnition 4 (Self-Conscious Computer Programs). The behavior of a com-
puter program is considered self-conscious if it knows its future state.

Deﬁnition 5 (Intuitive Computer Programs). The behavior of a conscious
computer program is considered intuitive if its operation is based on its own
predicted input rather than the real input.

It is obvious that the consciousness is not an a priori property by our
discussion. In addition, several levels of consciousness should be examined
in given time intervals. Typically, the examination has two aspects, ﬁrst
we must study the source code. Second, we must observe the operation of
the program. These remarks also indicate that our deﬁnitions are framed
at a very, very high abstract level, in the concrete cases we probably will
need to apply some inner simulation like the one introduced in [Hesslow and
Jirenhed, 2007]. In conclusion, as regards the fulﬁllment of the deﬁnitions
set out above, developers will obviously need to use sophisticated functional
structures in the particular cases.

2.1 Some Intuitive Examples for Deﬁnitions

The intuitive usage of the deﬁnitions will be illustrated in this section. First,
let’s have a look at the following trivial examples in relation to the question
of what data may be the input of a computer program. The input of a
Turing machine is a word placed on its tape. The input of a CLI may be a
set of commands entered by the user. The input of a GUI may be the set
of user’s activities. The input of a RoboCup [Kitano et al., 1997] agent is a
set of information received from its aural (what it can hear), visual (what
it can see) and body (what is its physical status) sensors. And ﬁnally, the
activities of processes may be regarded as the input of the scheduler of an
operating system.

4

But in the case of a Turing machine, interpreting of the term ”knowing
the future input” is worthy of further discussions, because the interpretation
of its operation is not wholly straightforward. As an initial approximation,
the concatenation of the former input words and the Turing machine in
question should be given as an input to a ”conscious” and modiﬁed universal
Turing machine. Another approach is to apply a preﬁx Turing machine,
where the current future input should be to the right of the input head on
the unidirectional input tape.

Example 1 (Walking Across the Zebra Crossing). This is a trivial example
of daily life. Every day the author goes across the zebra crossing shown in
Figure 1. Here I am standing (at a safe) 3-4 meters away from the kerb.
Then I am going to start to go when the traﬃc light for cars has changed to
yellow, because I know from former personal experience that the traﬃc light
for pedestrians changes to green soon afterwards.

This ”conscious” behavior represents an advantage for the author over
the other pedestrians, because while he are already on the move, others will
be waiting for the green signal of the traﬃc light for pedestrians.

Figure 1: The author walks across the zebra crossing.

Example 2 (Conscious Stock Market Charts). In a given time period, a
stock market chart may be regarded as a conscious program if it can also
successfully predict the time series of stock data in question. However, we
can mention that another diﬀerent type of input may be interpreted as further
input data in an interactive case. For example, an interactive chart program
may also examine and successfully predict the habits of its user. In general,

5

we may remark that investigating the user’s habits and patterns is an existing
research ﬁeld, for example see [Tseng et al., 2007], [Velayathan and Yamada,
2006] and [Blouin et al., 2011].

Example 3 (Conscious Databases). In a naive approach, for example, the
next couple of rows might be predicted by the table of a relational database
that will contain the rows in question. But perhaps it makes more sense to
think in terms of conscious behavior of OLAP systems, because the prediction
is crucial to achieve good results in this ﬁeld.

Example 4 (Conscious Text Editors). A successfully predicted input of a
conscious text editor may be the next couple of words that will be entered by
the user. In the world of text editing on mobile devices, it was a natural phase
of development, for example, typing in predictive (iTap) mode is widely used
in mobile phones to sending SMS or searching on the Web. We may notice
that, nowadays, the investigation of several word prediction systems is an
active research area, particularly with regard to mobile telephony [Kamvar
and Baluja, 2007], [Agarwal and Arora, 2007].

Example 5 (Self-Conscious Chatter Bots). In this example, we are in a
fortunate position that allows us to ask directly the questions about (knowing)
the future.
In compliance with this, we asked chatterbot Alice [Wallace,
2011], [Wallace, 2003], who won the Loebner Prize [Powers, 1998] 3 times
in 2000, 2001 and 2004, the next questions about her future.

Human: Hello, Alice!
ALICE: Hi there!
Human: I am writing a paper about machine consciousness,

do you mind if I ask you a few questions?

ALICE: Will you include me in your essay?
Human: Yes, I will.
ALICE: I understand. Go ahead.
Human: What are you going to do tomorrow?
ALICE: You can find out if you become a botmaster.
Human: Will you be conversing with me tomorrow?
ALICE: I’ll burn that bridge when I come to it. OK I will

try to be conversing with you tomorrow.

If a conscious Alice had responsed the following answer based on some

analytics, our satisfaction would increase.

Human: What are you going to do tomorrow?
CX ALICE: I will be expected to talk to someone.

Example 6 (Self-Conscious RoboCup Agents). A player agent may be re-
garded as a self-conscious program if it can run inner and simpliﬁed future

6

simulation cycles of Soccer Server [Chen et al., 2002] and based on it can
also successfully predict the future state of itself.

Example 7 (Intuitive RoboCup Agents). In the situation shown in Figure
2, a self-conscious RoboCup agent may be regarded as an intuitive program
if it can pass the ball to an open space so that a teammate able to reach
it as an unexpected through pass. These are the magical moments of real
football. Figure 2 schematically shows such a situation that happened in the
match between FC Barcelona and Levante UD at the Camp Nou stadium
on February 24, 2008 [YouTube, 2011], where the goal of Samuel Eto’o was
assisted by Lionel Messi in the 55th min.

2.2 The Trick of Consciousness

A computer program can be trivially made conscious, if we shift its virtual
present to the true past. In other words this means that its all input has
been delayed in time and in the meantime, we open a loophole to access
input data of the present.
It is a use case of the well-known conception
of ”living in the past”. This latter is described, for example, in [Hameroﬀ,
2006], [Hameroﬀ, 2003].

The following AspectJ Java code illustrates exactly this conception of
time shifting. It is a simple game in which the two players P and Q try to
catch the ball that moves with random walk on a ﬁeld of ﬁxed 80x24 size.
Players win a point when they catch the ball.

public c l a s s Game {

public s t a t i c f i n a l
public s t a t i c f i n a l
public s t a t i c f i n a l

int FIELD X = 8 0 ;
int FIELD Y = 2 4 ;
int BALL LIFESPAN = 1 0 0 0 ;

public s t a t i c void main ( S t r i n g [ ] a r g s ) {

f i n a l B a l l b a l l = new B a l l ( ) ;
f i n a l P l a y e r p l a y e r P = new P l a y e r ( 0 ) ,
playerQ = new P l a y e r ( FIELD X − 1 ) ;

int p o i n t s P = 0 , pointsQ = 0 ;
for ( int i = 0 ;

i < BALL LIFESPAN ; ++i ) {

b a l l . move ( ) ;

new Thread ( ) {

public void run ( ) {

7

Figure 2: This drawing is an illustration based on the match between FC
Barcelona and Levante UD in the Primera Divisi´on on February 24, 2008.
It is created with the FerSML football simulation platform B´atfai [2010a],
B´atfai [2010b].

p l a y e r P . p e r c e p t i o n ( b a l l . y ) ;

} . s t a r t ( ) ;

}

}

new Thread ( ) {

public void run ( ) {

playerQ . p e r c e p t i o n ( b a l l . y ) ;

8

i f

( b a l l . x == 0 && p l a y e r P . y == b a l l . y ) {

( b a l l . x == FIELD X − 1 && playerQ . y == b a l l . y ) {

} . s t a r t ( ) ;

++p o i n t s P ;

++pointsQ ;

}
i f

}

}

System . out . p r i n t l n ( p o i n t s P + ” ” + pointsQ ) ;

}

}

Listing 1: The source code for the Game class.

The ball can move all four directions with the same probability or, to be

more precise, its movement is a random walk.

c l a s s B a l l {

int x = Game . FIELD X / 2 , y = Game . FIELD Y / 2 ;

void move ( ) {

int dx = ( int )
int dy = ( int )

( Math . random ( ) ∗ 3 ) − 1 ;
( Math . random ( ) ∗ 3 ) − 1 ;

i f

( x + dx < Game . FIELD X && x + dx >= 0 ) {

( y + dy < Game . FIELD Y && y + dy >= 0 ) {

x += dx ;

y += dy ;

}
i f

}

}

}

Listing 2: The source code for the Ball class.

The players can only move up and down on the sides of the ﬁeld. They
endeavor to catch the ball when it reaches the sides of the ﬁeld. Our ex-
amples, the players P and Q are aware of the reality via an interface called
Sensory.

i n t e r f a c e S e n s o r y {

void p e r c e p t i o n ( int b a l l Y ) ;

9

}

}

}

}

}

}

}

}

Listing 3: The source code for the Sensory interface.

c l a s s P l a y e r implements S e n s o r y {

int x = 0 , y = Game . FIELD Y / 2 ;

public P l a y e r ( int x ) {

t h i s . x = x ;

public void p e r c e p t i o n ( int b a l l Y ) {

move ( b a l l Y ) ;

protected void move ( int b a l l Y ) {

i f

( y < b a l l Y ) {

++y ;
} e l s e i f
−−y ;

( y > b a l l Y ) {

Listing 4: The source code for the Player class.

The execution of the perception method of the interface Sensory is

blocked for 500 millisecond by the following AspectJ aspect.

aspect Delay {

public pointcut p e r c e p t i o n C a l l ( ) :

c a l l ( public void P l a y e r . p e r c e p t i o n ( int ) ) ;

before ( ) : p e r c e p t i o n C a l l ( ) {

try {

Thread . s l e e p ( 5 0 0 ) ;

} catch ( I n t e r r u p t e d E x c e p t i o n e ) { e . p r i n t S t a c k T r a c e ( ) ; }

Listing 5: The source code for the Delay aspect.

It may be noted, as a curiosity, that using the 500 millisecond duration
in the inserted code snippet was suggested by [Penrose, 1989] which presents

10

Libet and Kornhuber’s results on the timing of consciousness [Libet et al.,
1979], [Kornhuber et al., 1976]. But it is immaterial in this case where
the results were observed are shown in Table 1. In addition, our living in
the past aspect implementation is suﬃciently buggy, for example, it has no
mutual exclusion for protecting scores and coords. Nevertheless, this simple
example delivers the expected results, namely that the scores decrease as we
increase the amount of delay time.

Table 1: Execution results of the delay aspect (with the variable BALL-
LIFESPAN set to 100.000).

Naive example of the living in the past

Time [ms]

Aver. Scores

Exec. Time [min]

9.7

10.0

9.6

9.7

11.2

10.0

10.2

9.9

10.0

9.9

10.1

11.3

16.9

23.5

33.7

no aspect

no blocking

javac

javac

0.001

0.01

0.1

0.5

1

2

5

50

200

500

1000

1088

1156

1162

1036

249

246

239

227

226

183

142

68

57

53

52.5

11

The reader can easily see that our example aspect does not contain any
loopholes and any analytic codes, either. But, for example, in the case in
which the movement of the ball is smooth (that is well predictable) writing
some successful analytics and prediction codes, of course, could be trivial.

2.2.1 An Evolutionary Aspect of the living in the past

Why may this approach be interesting from the point of view of the awak-
ening of consciousness? Because it may be possible that living matter could

have developed such living in the past aspects, in which they can run ana-
lytics and prediction methods. Doing so can start the evolutionary process
simply and solely because the organisms who make wrong predictions be-
come extinct. In this sense, applying living in the past oﬀers an ability for
the organisms to develop a successful prediction mechanism, since a pre-
dicted, interesting event that occurs in the ”delay window” shown in Figure
3 can be eﬀectively veriﬁable, because it has already happened.

Figure 3: A simple schematic drawing of the well-known conception of ”living
in the past”.

Finally, it may be mentioned that the most recent sensational and para-
doxical results of precognition [Bem, 2010] perhaps may be easily explained
in the context of the living in the past.

2.3 The Consciousness as a Computing Paradigm

In the world of computer programs, the barbarian methods of natural selec-
tion may be partially waived because computers have the necessary comput-
ing resources that they can subsequently execute analytical computations,
that is, for developing good solutions it is not necessary to extinct whole
generations or races of living species.

In our opinion, a paradigm shift is needed to achieve the age of intelligent
machines. The base of a new paradigm may be using our simple deﬁnitions
of machine consciousness, that may be called consciousness oriented pro-
gramming.

3 Consciousness Oriented Programming

Consciousness oriented programming is a new way of approaching software
development, in which two basic situations can be distinguished today.

• Existing computer programs should be further developed to be con-
scious or self-conscious computer programs in line with our previous

12

In general case, it is nearly impossible to modify com-
deﬁnitions.
puter programs, but the situation is not hopeless if modiﬁcations are
implemented as new aspects in the sense of AOP [Kiczales et al., 1997].

• New computer programs should be developed in conformity with the

spirit of our deﬁnitions.

In both cases, the development of consciousness will require using predic-
tion methods and the development of self-consciousness will require applying
inner simulation in the sense mentioned in Section 2.

4 Use Cases for the COP

In this section, we follow the spirit of the deﬁnitions outlined previously.

4.1 Programming on Paper

Notation 1 (Predicted and Real Input). Denote (cid:104)p(redicted)i(cid:105) : N (⊆ N) →
I(nput) the sequence of the predicted input and (cid:104)r(eal)i(cid:105) : N (⊆ N) →
I(nput) the sequence of the real input, where I denotes the set of all possible
inputs.

Deﬁnition 6 (Consciousness Indicator Sequence). We deﬁne the conscious-
ness indicator sequence (cid:104)ci(cid:105) : N (⊆ N) → {0, 1} as follows

ci =

(cid:40)0

if pi (cid:54)= ri,

1

if pi = ri.

Deﬁnition 7 (Conscious Computer Programs). In a given time interval,
the behavior of a computer program is referred to as conscious if its con-
sciousness indicator sequence is not Kolmogorov-Chaitin random [Li and
Vit´anyi, 2008].

We should remark that this deﬁnition does not kill the consciousness,
because the Kolmogorov-Chaitin randomness is algorithmically undecidable.
The next section will diverge from the proposed inner prediction mech-
anism to a simpler way, and meanwhile we will stay within the classical
framework of Turing machines.

4.1.1 Quasi-Intuitive Machines and Languages

In the majority of cases in this subsection, a comma between words denotes
the concatenation of these words which are suitable encoded if necessary.

13

Deﬁnition 8 (Universal Quasi-Intuitive Machines). Let T be a Turing ma-
chine and let p be a positive real number. An universal quasi-intuitive ma-
chine Qx,p is created by the following scheme shown in Figure 4, provided
that there exists a sequence of words x1, . . . , xn(= x) having the properties
that

i = 1,

T (xi) = yes

2 ≤ i ≤ n, Qxi−1,p(T, xi) = yes

(1)

(2)

In Figure 4, U denotes an universal Turing machine and ”d(x, y) < p”
denotes a Turing machine that can indicate that the input words x and y
If this machine Qx,p stops it makes the com-
are similar to each other.
putation of the function Qx,p(T, y) = QIM (x1, . . . , xn−1, x, y, T, p), QIM :
{0, 1}∗n+3 → {yes, no}. The architectural model for the machine QIM is
shown in Figure 5.

Figure 4: An architectural model for the universal quasi-intuitive machine.

Remark 1 (Comparisons of the Words). Using the normalized information
distance (NID) [Li et al., 2003] as the metric distance d(x, y) of the two
words x and y is theoretically exciting, but in this case we cannot build the
Turing machine Qx,p that contains such a ”d(x, y) < p” machine, because
this is not an existing machine due to the Kolmogorov complexity function is
not partial recursive [Li and Vit´anyi, 2008, pp. 127, pp. 216]. Speciﬁcally,
the computability of NID is discussed in [Terwijn et al., 2011, 2010]. But
then we can successfully use the normalized compression distance (NCD) [Li
et al., 2003, Vit´anyi et al., 2008, Cilibrasi and Vit´anyi, 2005] instead of the
theoretical normalized information distance because the compression distance
is trivially partial recursive [Terwijn et al., 2011]. Another trivial option
may be to use the Google similarity distance (NGD) [Cilibrasi and Vit´anyi,
2007] or the normalized web distance (NWD) [Cilibrasi and Vit´anyi, 2009]
as the metric d. In the following, we suppose that the predicate d(x, y) < p
is recursive.

14

Remark 2. In the intuitive sense, x ∈ {0, 1}∗ is such a word that has
already been accepted by the Turing machines T or Q.

Deﬁnition 9 (The Universal Quasi-Intuitive Language). The universal quasi-
intuitive language

QIL = {x1, . . . , xn(= x), y, T, p | T is deﬁned, T (x1) = yes,

Qxi−1,p(T, xi) = yes, 2 ≤ i ≤ n and Qx,p(T, y) = yes}.

Theorem 1. QIL ∈ RE.

Proof. To verify assertion QIL ∈ RE, it is suﬃcient to observe that the
language accepted by the machine QIM shown in Figure 5 is equal to QIL.
(We believe that we can prove a bit stronger theorem QIL ∈ RE \ R.)

Figure 5: An architectural model for a machine QIM that accepts the
language QIM .

Deﬁnition 10 (Similar Languages). Let E ⊆ {0, 1}∗ be a given language
and let p ∈ R be a positive real number. The language SLE = {y | y ∈
{0, 1}∗, d(x, y) < p, x ∈ E} is said to be similar to E.

Theorem 2. E ∈ RE ⇒ SLE ∈ RE \ R.

Proof. In the case E ∈ R, we can construct a new Turing machine SLM
shown in Figure 6 which accepts SLE.

To see why the language SLE is not recursive, consider the case of y /∈
SLE, it is possible that the new machine SLM will never halt, because it is
possible that the part labelled ”For all x/d(x, y)<p” will continue searching
for suitable x for ever. It may be noted that the the canonical ordering of
{0, 1}∗, for example shown in [R´onyai et al., 2004], can be applied to help
to enumerate the words of the language E by the part labelled ”For all x”.
In the case E ∈ RE \ R, we can construct a new Turing machine SLM (cid:48)
shown in Figure 7 which accepts SLE. It may be also noted here that a

15

Figure 6: The Turing machine SLM for the case E ∈ R.

Figure 7: The Turing machine SLM (cid:48) for the case E ∈ RE \ R.

procedure based on Cantor’s ﬁrst diagonal argument, for example shown in
[R´onyai et al., 2004], can be applied to enumerate the words of the language
E by the part labelled ”For all x is in E”.

Deﬁnition 11 (Quasi-Intuitive Languages). With the notation already in-
troduced in Deﬁnition 8, a quasi-intuitive language QILT is deﬁned as
p,i, where I T
QILT (= ∪∞
p,i is constructed by the follow-
ing scheme:

i=1QILTi) = ∪∞

i=1I T

I T
p,1 = {x | T (x) = yes}
p,i+1 = {y | x ∈ I T
I T

p,i, Qx,p(T, y) = yes}, i ≥ 1

where y ∈ {0, 1}∗ is an arbitrary word or, for example, y ∈ L(G) generated
by some generative grammar G.

Theorem 3. Let n ∈ N be a given natural number and let T be a Turing
machine. Then LT ∈ RE ⇒ QILTn ∈ RE \ R.

Proof. Let us observe that

(3)

(4)

(5)

(6)

I T
p,1 = LT

I T
p,i+1 = LT ∪ SLI T

p,i

16

Deﬁnition 12 (Similar Words). Let L ⊆ {0, 1}∗ be a given language and
let p ∈ R be a positive real number. We deﬁne the language of similar words
as follows SWL = {x, y | x ∈ L, y ∈ {0, 1}∗, d(x, y) < p}.

Theorem 4. L ∈ R ⇒ SWL ∈ R.

Proof. We can construct a new Turing machine SWM shown in Figure 8
which accepts SWL and always halts.

Figure 8: The Turing machine SWM .

Deﬁnition 13 (Quasi-Intuitive or Self-Similar Words). Let T be a given
Turing machine and let s ∈ {0, 1}∗ be a word such that T (s) = yes. Finally,
let (cid:104)ri(cid:105) : N (⊆ N) → {0, 1}∗ be a ﬁnite or inﬁnite sequence of arbitrary words.
The union of the elements of the sequence of sets Ii is said to be self-similar,
if the sequence is created by the following method:

I1 = {s}

(cid:40)Ii ∪ {ri},

if ∃x ∈ Ii : Qx,p(T, ri) = yes

i ≥ 1, Ii+1 =

Ii,

otherwise.

Remark 3 (Consciousness Indicator Sequence). In the case of the self-
similar words, the consciousness indicator sequence may be interpreted as
cn = (cid:87)

Qx,p(T, rn).

x∈In+1

Example 8. Let T be a Turing Machine, which accepts the language {anbncn

17

| n ≥ 1}, d = 1/4 and the word s = aaaaaabbbbbbcccccc = a6b6c6.

I1 = {s}

r1 = aaaaaabbbbbbaaaaaa = a6b6a6, I2 = {s}, c1 = no
r2 = aaaaaabbbbbbccc = a6b6c3, I3 = {s, r2}, c2 = yes
r3 = aaaaabbbbbccccc = a5b5c5, I4 = {s, r2, r3}, c3 = yes
r4 = a7b7c7, I5 = {s, r2, r3, r4}, c4 = yes
r5 = c1a5b5c4, I6 = {s, r2, r3, r4, r5}, c5 = yes
r6 = c3a6b5c4b2, I7 = {s, r2, r3, r4, r5}, c6 = no
r7 = c3a6b5c3, I8 = {s, r2, r3, r4, r5, r7}, c7 = yes
r8 = r6, I9 = {s, r2, r3, r4, r5, r7, r8}, c8 = yes

where the CompLearn package [Cilibrasi, 2011] is used to compute NCD:

N CD(s, r1) = 0.3125
N CD(s, r2) = 0.176471
N CD(s, r3) = 0.25, N CD(r2, r3) = 0.294118
N CD(s, r4) = 0.4375, N CD(r2, r4) = 0.470588,
N CD(r3, r4) = 0.5625
N CD(s, r5) = 0.25, N CD(r2, r5) = 0.235294,

N CD(r3, r5) = 0.1875, N CD(r4, r5) = 0.25

N CD(s, r6) = 0.35, N CD(r2, r6) = 0.3, N CD(r3, r6) = 0.3,

N CD(r4, r6) = 0.3, N CD(r5, r6) = 0.25

N CD(s, r7) = 0.263158, N CD(r2, r7) = 0.210526,

N CD(r3, r7) = 0.210526, N CD(r4, r7) = 0.210526
N CD(r5, r7) = 0.157895

N CD(r7, r8) = 0.15

We should remark that the symmetry of NCD may be violated among short
words [Cilibrasi and Vit´anyi, 2005]. For example, N CD(a7b7c7, a6b6c3) =
0, 235294 (cid:54)= 0, 470588 = N CD(a6b6c3, a7b7c7).

4.2 Programming on Computer

In the world of real programming, we do have plan to develop such APIs
which can be used to successfully implement our deﬁnitions of machine con-
sciousness. For some given types of applications, we are going to investigate
the development of a suitable, open source Java and AspectJ APIs to enable
seeing the future.

18

4.2.1 ConsciousJ

Designing a new programming language is another exciting possibility. At
the conceptual level, the following ConsciousJ code snippet illustrates the
usage of two new keywords ”conscious” and ”predicted”, though certainly
the language ConsciousJ does not exist yet. In our case, this new language
to be developed can be imagined as an extension of Java or AspectJ.

conscious c l a s s P l a y e r {

int x = 0 , y = Game . FIELD Y / 2 ;

protected void move ( predicted int b a l l Y ) {

i f

( y < b a l l Y ) {

( y > b a l l Y ) {

++y ;
} e l s e i f
−−y ;

}

}

}
Listing 6: A ”conscious” code snippet written in a ﬁctitious language called
ConsciousJ.

In practice, this code snippet shows that the uncertainty is appeared
at the level of the programming language. A ConsciousJ class consists of
attributes and methods, plus it may contain predicted attributes. This
conception is shown in the following ﬁctitious code snippet in Listing 7.

conscious c l a s s P l a y e r implements Runnable {

int x = 0 , y = GameS . FIELD Y / 2 ;
int p o i n t s = 0 ;
B a l l b a l l ;

int time = 0 ;
int next = 6 ;
int b a l l Y H e l p e r = 0 ;

o r g . c o n s c i o u s j . pred . K a l m a n F i l t e r kp ;
o r g . c o n s c i o u s j . pred .ARMA ap ;
o r g . c o n s c i o u s j . pred . SimplePa st sp ;

predicted o r g . c o n s c i o u s j . p r i m i t i v e t y p e . I n t b a l l Y ;

public p o i n t c u t moveCall ( ) :

c a l l ( protected void move ( predicted int b a l l Y ) ) ;

19

input ( ) : moveCall ( ) {

t h i s . b a l l Y . r e c e i v e ( b a l l Y ) ;

i f (++time < 1 0 0 0 ) {

} e l s e i f

t h i s . b a l l Y . method ( sp ) ;
( time < 5 0 0 0 ) {
t h i s . b a l l Y . method ( ap ) ;

} e l s e {

}

t h i s . b a l l Y . method ( kp ) ;

i f

( time % next == 0 ) {

b a l l Y H e l p e r = t h i s . b a l l Y . next ( ) ;

}
b a l l Y = b a l l Y H e l p e r ;

public P l a y e r ( int x , B a l l b a l l ) {

t h i s . x = x ;
t h i s . b a l l = b a l l ;

new Thread ( t h i s ) . s t a r t ( ) ;

}

}

public void run ( ) {

for ( ; ; ) {

move ( b a l l . y ) ;

try {

Thread . s l e e p ( 2 0 ) ;

} catch ( I n t e r r u p t e d E x c e p t i o n e ) {

e . p r i n t S t a c k T r a c e ( ) ;

i f

( b a l l . y < 0 ) {

break ;

}

}

}

}

20

protected void move ( predicted int b a l l Y ) {

i f

( y < b a l l Y ) {

++y ;
} e l s e {
−−y ;

}

}

}

5 Conclusion

Listing 7: A ”conscious” class written in ConsciousJ.

The idealized objective of COP is to integrate the agent-based approach into
daily software development practices. What is more, the agents should be
able to see the future, or, using words of Alan Turing’s [Turing, 1995] essay,
everyday softwares should be able to see a short distances ahead. Naturally
these words by Turing were really meant for humans.

The present paper presented an overall conceptual framework so that it

could contribute to the attainment of this objective.

6 Acknowledgements

The work is partially supported by T ´AMOP 4.2.1./B-09/1/KONV-2010-
0007/IK/IT project. The project is partially implemented through the New
Hungary Development Plan co-ﬁnanced by the European Social Fund, and
the European Regional Development Fund.

References

S. Agarwal and S. Arora. Context based word prediction for texting
language.
In Large Scale Semantic Access to Content (Text, Image,
Video, and Sound), RIAO ’07, pages 360–368, Paris, France, France,
2007. LE CENTRE DE HAUTES ETUDES INTERNATIONALES
D’INFORMATIQUE DOCUMENTAIRE. URL http://portal.acm.
org/citation.cfm?id=1931390.1931426.

B. J. Baars and S. Franklin. Consciousness is computational:

the lida
model of global workspace theory. International Journal of Machine Con-
sciousness, 01(01):23, 2009. URL http://www.worldscinet.com/ijmc/
01/0101/S1793843009000050.html.

21

N. B´atfai. A conceivable origin of machine consciousness in the idle process.
CoRR, abs/0909.5064, 2009. URL http://arxiv.org/abs/0909.5064.

N. B´atfai. Footballer and football simulation markup language and related
simulation software development. Journal of Computer Science and Con-
trol Systems, 3(1):13–18, 2010a. URL http://electroinf.uoradea.ro/
reviste\20CSCS/documente/JCSCS_2010/JCSCS_Nr_1_integral.pdf.

N. B´atfai. The socceral force. CoRR, abs/1004.2003, 2010b. URL http:

//arxiv.org/abs/1004.2003.

D. J. Bem. Feeling the future: Experimental evidence for anomalous retroac-
tive inﬂuences on cognition and aﬀect. Journal of Personality and Social
Psychology, 100(3):407– 425, 2010. URL http://doi.apa.org/getdoi.
cfm?doi=10.1037/a0021524.

A. Blouin, B. Morin, O. Beaudoux, G. Nain, P. Albers, and J.-M. J´ez´equel.
Combining aspect-oriented modeling with property-based reasoning to
improve user interface adaptation.
In Proceedings of the 3rd ACM
SIGCHI symposium on Engineering interactive computing systems, EICS
ISBN 978-1-
’11, pages 85–94, New York, NY, USA, 2011. ACM.
4503-0670-6. doi: http://doi.acm.org/10.1145/1996461.1996500. URL
http://doi.acm.org/10.1145/1996461.1996500.

M. Chen, E. Foroughi, F. Heintz, Z. Huang, S. Kapetanakis, K. Kostiadis,
J. Kummenje, I. Noda, O. Obst, P. Riley, T. Steﬀens, Y. Wang, and
X. Yin. RoboCup Soccer Server. The RoboCup Federation, 2002. URL
http://sserver.sourceforge.net.

R. Cilibrasi. Complearn, 2011. URL http://www.complearn.org/.

R. Cilibrasi and P. M. B. Vit´anyi. Clustering by compression. IEEE Trans-

actions on Information Theory, 51:1523–1545, 2005.

R. Cilibrasi and P. M. B. Vit´anyi. Normalized web distance and word simi-

larity. CoRR, abs/0905.4039, 2009.

R. L. Cilibrasi and P. M. B. Vit´anyi. The google similarity distance.
IEEE Trans. on Knowl. and Data Eng., 19:370–383, March 2007. ISSN
1041-4347. doi: 10.1109/TKDE.2007.48. URL http://portal.acm.org/
citation.cfm?id=1263132.1263333.

S. Hameroﬀ. Time, Consciousness and Quantum Events in Fundamental
Spacetime Geometry. In The nature of time: Physics, geometry and per-
ception. Proceedings of a NATO Advanced Research Workshop, 2003.

S. Hameroﬀ. Consciousness, Neurobiology and Quantum Mechanics: The
Case for a Connection. pages 193–253. 2006. doi: 10.1007/3-540-36723-3\
6. URL http://dx.doi.org/10.1007/3-540-36723-3_6.

22

G. Hesslow and D.-A. Jirenhed. Must machines be zombies? internal simu-
lation as a mechanism for machine consciousness. In AI and Conscious-
ness: Theoretical Foundations and Current Approaches, Proceedings of
the AAAI fall symposium on machine consciousness, page 78?83. AAAI
Press, 2007. URL http://www.aaai.org/Papers/Symposia/Fall/2007/
FS-07-01/FS07-01-014.pdf.

M. Kamvar and S. Baluja. The role of context in query input: using con-
textual signals to complete queries on mobile devices. In Proceedings of
the 9th international conference on Human computer interaction with mo-
bile devices and services, MobileHCI ’07, pages 405–412, New York, NY,
USA, 2007. ACM. ISBN 978-1-59593-862-6. doi: http://doi.acm.org/10.
1145/1377999.1378046. URL http://doi.acm.org/10.1145/1377999.
1378046.

G. Kiczales, J. Lamping, A. Mendhekar, C. Maeda, C. Lopes, J. marc
In ECOOP.

Loingtier, and J. Irwin. Aspect-oriented programming.
SpringerVerlag, 1997.

H. Kitano, M. Asada, Y. Kuniyoshi, I. Noda, and E. Osawa. Robocup: The
robot world cup initiative. In Proceedings of the ﬁrst international confer-
ence on Autonomous agents, AGENTS ’97, pages 340–347, New York, NY,
USA, 1997. ACM. ISBN 0-89791-877-0. doi: http://doi.acm.org/10.1145/
267658.267738. URL http://doi.acm.org/10.1145/267658.267738.

H. H. Kornhuber, L. Deecke, and P. Scheid. Voluntary ﬁnger movement in
man: Cerebral potentials and theory. Biological Cybernetics, (23), 1976.

M. Li and P. M. Vit´anyi. An Introduction to Kolmogorov Complexity and
Its Applications. Springer Publishing Company, Incorporated, 3 edition,
2008. ISBN 0387339981, 9780387339986.

M. Li, X. Chen, X. Li, B. Ma, and P. Vit´anyi. The similarity metric. In
Proceedings of the fourteenth annual ACM-SIAM symposium on Discrete
algorithms, SODA ’03, pages 863–872, Philadelphia, PA, USA, 2003. So-
ciety for Industrial and Applied Mathematics. ISBN 0-89871-538-5. URL
http://portal.acm.org/citation.cfm?id=644108.644253.

B. Libet, E. Wright, B. Feinstein, , and D. K. Pearl. Subjective referral of
the timing for a conscious sensory experience. Brain, (102):193–224, 1979.

R. Penrose. The emperor’s new mind: concerning computers, minds, and
the laws of physics. Oxford University Press, Inc., New York, NY, USA,
1989. ISBN 0-19-851973-7.

R. Penrose and S. Hameroﬀ. Quantum computation in brain microtubules?
the penrose-hameroﬀ Orch OR model of consciousness. Philosophical
Transactions Royal Society London (A), 356:1869–1896, 1998.

23

D. M. W. Powers. The total turing test and the loebner prize. In Proceed-
ings of the Joint Conferences on New Methods in Language Processing
and Computational Natural Language Learning, NeMLaP3/CoNLL ’98,
pages 279–280, Stroudsburg, PA, USA, 1998. Association for Computa-
tional Linguistics. ISBN 0-7258-0634-6. URL http://portal.acm.org/
citation.cfm?id=1603899.1603947.

L. R´onyai, G. Iv´anyos, and R. Szab´o. Algoritmusok. Typotex, Budapest,

2004.

S. Russell and P. Norvig. Artiﬁcial Intelligence: A Modern Approach.

Prentice-Hall, Englewood Cliﬀs, NJ, 2nd edition edition, 1995.

A. Sloman and R. Chrisley. Virtual machines and consciousness. Journal of

Consciousness Studies, 10:4–5, 2002.

J. Starzyk and D. Prasad. A computational model of machine consciousness.
International Journal of Machine Consciousness, in press, 2011. URL
http://www.ohio.edu/people/starzykj/network/Research/Papers/
AComputationalModelofMachineConsciousness.pdf.

S. Terwijn, L. Torenvliet, and P. M. B. Vit´anyi. Normalized information

distance is not semicomputable. CoRR, abs/1006.3275, 2010.

S. A. Terwijn, L. Torenvliet, and P. M. B. Vit´anyi. Nonapproximability of
the normalized information distance. J. Comput. Syst. Sci., 77:738–742,
July 2011. ISSN 0022-0000. doi: http://dx.doi.org/10.1016/j.jcss.2010.
06.018. URL http://dx.doi.org/10.1016/j.jcss.2010.06.018.

V. S. Tseng, K. W. Lin, and J.-C. Chang. Prediction of user navigation pat-
terns by mining the temporal web usage evolution. Soft Comput., 12:157–
163, September 2007. ISSN 1432-7643. doi: 10.1007/s00500-007-0190-y.
URL http://portal.acm.org/citation.cfm?id=1290506.1290511.

A. M. Turing. Computing machinery and intelligence, pages 11–35. MIT
ISBN 0-262-56092-5. URL http:

Press, Cambridge, MA, USA, 1995.
//portal.acm.org/citation.cfm?id=216408.216410.

G. Velayathan and S. Yamada. Behavior-based web page evaluation.

In
Proceedings of the 15th international conference on World Wide Web,
ISBN
WWW ’06, pages 841–842, New York, NY, USA, 2006. ACM.
1-59593-323-9. doi: http://doi.acm.org/10.1145/1135777.1135905. URL
http://doi.acm.org/10.1145/1135777.1135905.

P. M. B. Vit´anyi, F. J. Balbach, R. Cilibrasi, and M. Li. Normalized infor-

mation distance. CoRR, abs/0809.2553, 2008.

24

R. Wallace. The Elements of AIML Style, 2003. URL http://www.

alicebot.org/style.pdf.

R. Wallace. Alicebot, 2011. URL http://alicebot.blogspot.com.

E. P. Wigner. Remarks on the mind-body question. Symmetries and Re-

ﬂections, page 179, 1967.

YouTube.

The match between FC Barcelona and Levante UD
URL

the Camp Nou stadium on february 24, 2008, 2011.

at
http://www.youtube.com/watch?v=oTIEpqMwCbk,\from\3:20\to\3:
30,http://www.youtube.com/watch?v=VfJT2U3OUps,\from\1:00\to\
1:04,\http://www.youtube.com/watch?v=wkUYcOPBoz8,\from\0:19.

25

