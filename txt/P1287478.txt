Acquisition of Phrase Correspondences using Natural Deduction Proofs

Hitomi Yanaka1
hitomiyanaka@g.ecc.u-tokyo.ac.jp

Koji Mineshima2
mineshima.koji@ocha.ac.jp

Pascual Mart´ınez-G´omez3
pascual.mg@aist.go.jp

Daisuke Bekki2
bekki@is.ocha.ac.jp

1The University of Tokyo
2Ochanomizu University
3Artiﬁcial Intelligence Research Center, AIST
Tokyo, Japan

Abstract

How to identify, extract, and use phrasal
knowledge is a crucial problem for the
task of Recognizing Textual Entailment
(RTE). To solve this problem, we pro-
pose a method for detecting paraphrases
via natural deduction proofs of semantic
relations between sentence pairs. Our so-
lution relies on a graph reformulation of
partial variable uniﬁcations and an algo-
rithm that induces subgraph alignments
between meaning representations. Experi-
ments show that our method can automat-
ically detect various paraphrases that are
absent from existing paraphrase databases.
In addition, the detection of paraphrases
using proof information improves the ac-
curacy of RTE tasks.

1

Introduction

Recognizing Textual Entailment (RTE) is a chal-
lenging natural language processing task that aims
to judge whether one text fragment logically fol-
lows from another text fragment (Dagan et al.,
2013). Logic-based approaches have been suc-
cessful in representing the meanings of complex
sentences, ultimately having a positive impact on
RTE (Bjerva et al., 2014; Beltagy et al., 2014;
Mineshima et al., 2015, 2016; Abzianidze, 2015,
2016). Although logic-based approaches succeed
in capturing the meanings of functional or logi-
cal words, it is difﬁcult to capture the meanings
of content words or phrases using genuine logical
inference alone. This remains a crucial problem
in accounting for lexical relations between content
words or phrases via logical inference. To solve
this problem, previous logic-based approaches use
knowledge databases such as WordNet (Miller,
1995) to identify lexical relations within a sen-

tence pair. While this solution has been success-
ful in handling word-level paraphrases, its exten-
sion to phrase-level semantic relations is still an
unsolved problem. There are three main difﬁcul-
ties that prevent an effective identiﬁcation and use
of phrasal linguistic knowledge.

The ﬁrst difﬁculty is the presence of out-of-
context phrase relations in popular databases such
as the Paraphrase Database (PPDB) (Ganitkevitch
et al., 2013). PPDB may suggest paraphrases that
do not adhere to the context of our relevant text
segments nor to their semantic structure, which
might be problematic.

The second difﬁculty is ﬁnding semantic phrase
correspondences between the relevant text seg-
Typical approaches only rely on sur-
ments.
face (Beltagy et al., 2013) or syntactic correspon-
dences (Arase and Tsujii, 2017), often producing
inaccurate alignments that signiﬁcantly impact our
inference capabilities.
Instead, a mechanism to
compute semantic phrase correspondences could
potentially produce, if available, more coherent
phrase pairs and solve the recurring issue of dis-
continuity.

The third difﬁculty is the intrinsic lack of cov-
erage of databases for logical inference despite
their large size. Whereas there is a relatively
small number of possible word-to-word corre-
spondences and thus their semantic relations can
be enumerated, the same is not true for all phrase
pairs that might be of interest. One alternative is to
use functions of inﬁnite domain (e.g., cosine simi-
larity) between phrase representations (Tian et al.,
2016), but these techniques are still under devel-
opment, and we have not seen deﬁnitive successful
applications when combined with logic systems.

In this study, we tackle these three problems.
The contributions of this paper are summarized
as follows: First, we propose a new method of
detecting phrase correspondences through natu-

8
1
0
2
 
r
p
A
 
0
2
 
 
]
L
C
.
s
c
[
 
 
1
v
6
5
6
7
0
.
4
0
8
1
:
v
i
X
r
a

ral deduction proofs of semantic relations for a
given sentence pair. Second, we show that our
method automatically extracts various paraphrases
that compensate for a shortage in previous para-
phrase databases. Experiments show that ex-
tracted paraphrases using proof information im-
prove the accuracy of RTE tasks.

2 Related Work

In this section, we review previous logical in-
ference systems that are combined with lexi-
cal knowledge. The RTE system developed by
Abzianidze (2016) uses WordNet as axioms and
adds missing knowledge manually from the train-
ing dataset; however, this technique requires con-
siderable human effort and is not extended to han-
dle phrasal knowledge.

Mart´ınez-G´omez et al. (2017) proposed an RTE
system with an on-the-ﬂy axiom injection mech-
anism guided by a natural deduction theorem
prover. Pairs of unprovable sub-goals and plau-
sible single premises are identiﬁed by means of
a variable uniﬁcation routine and then linguis-
tic relations between their logical predicates are
checked using lexical knowledge such as Word-
Net and VerbOcean (Chklovski and Pantel, 2004).
However, this mechanism is limited to capturing
word-to-word relations within a sentence pair.

Bjerva et al. (2014) proposes an RTE system
where WordNet relations are used as axioms for
word-to-word knowledge in theorem proving. For
phrasal knowledge, PPDB is used to rephrase an
input sentence pair instead of translating para-
phrases into axioms. However, this solution ig-
nores logical contexts that might be necessary
when applying phrasal knowledge. Moreover, it
does not apply to discontinuous phrases.

Beltagy et al. (2016) uses WordNet and PPDB
as lexical knowledge in the RTE system. To in-
crease their coverage of phrasal knowledge, the
system combines a resolution strategy to align
clauses and literals in a sentence pair and a sta-
tistical classiﬁer to identify their semantic relation.
However, this strategy only considers one possible
set of alignments between fragments of a sentence
pair, possibly causing inaccuracies when there are
repetitions of content words and meta-predicates.
In our research, we propose an automatic phrase
abduction mechanism to inject phrasal knowledge
during the proof construction process. In addition,
we consider multiple alignments by backtracking

the decisions on variable and predicate uniﬁca-
tions, which is a more ﬂexible strategy. We rep-
resent logical formulas using graphs, since this is
a general formalism that is easy to visualize and
analyze. However, we use natural deduction (see
Section 3.2) as a proof system instead of Markov
Logic Networks for inference. Some research has
investigated graph operations for semantic pars-
ing (Reddy et al., 2014, 2016) and abstractive sum-
marization (Liu et al., 2015); we contribute to
these ideas by proposing a subgraph mapping al-
gorithm that is useful for performing natural lan-
guage inferences.

Considerable research efforts have been focused
on the identiﬁcation and extraction of paraphrases.
One successful technique is associated with bilin-
gual pivoting (Bannard and Callison-Burch, 2005;
Zhao et al., 2008), in which alternative phrase
translations are used as paraphrases at a certain
this technique requires
probability. However,
large bilingual parallel corpora; moreover, word
alignment errors likely cause noisy paraphrases.
Another strategy is to extract phrase pairs from
a monolingual paraphrase corpus using align-
ments between syntactic trees, guided by a lin-
guistically motivated grammar (Arase and Tsujii,
2017). The main difference between these stud-
ies and ours is that they typically attempt align-
ment between words or syntactic trees, whereas
we perform alignments between meaning repre-
sentations, which enables the acquisition of more
general paraphrases by distinguishing functional
words from content words. This point is impor-
tant in distinguishing among different semantic re-
lations (e.g., antonyms and synonyms). In addi-
tion, word and syntactic alignments potentially ig-
nore coreferences, making it difﬁcult to ﬁnd rela-
tions between many-to-many sentences. Semantic
alignments enable this because coreferences must
refer to the same variable as the original entity.

3 Logic-based Approach to RTE

3.1 Meaning representation

In logic-based approaches to RTE, a text T and a
hypothesis H are mapped onto logical formulas T (cid:48)
and H (cid:48). To judge whether T entails H, we check
whether T (cid:48) ⇒ H (cid:48) is a theorem in a logical system.
For meaning representations, we use Neo-
Davidsonian event semantics (Parsons, 1990). In
this approach, a verb is analyzed as a one-place
predicate over events. Both the arguments of a

subj

x1

girl

skip

y1

x2

rope

obj

on

x3

sidewalk

Figure 1: A graph for the basic formula (2).

verb and modiﬁers are linked to events by seman-
tic roles, and the entire sentence is closed by ex-
istential quantiﬁcation over events. For example,
(1) is mapped onto (2).

(1) A girl is skipping rope on a sidewalk.

(2)

∃x1∃x2∃x3∃y1 (girl(x1) ∧ rope(x2)∧
sidewalk(x3) ∧ skip(y1) ∧ (subj(y1) = x1) ∧
(obj(y1) = x2) ∧ on(y1, x3))

We use xi as a variable for entities and yj for
events.
In this semantics, we represent all con-
tent words (e.g., girl and skip) as one-place predi-
cates. Regarding functional words, we represent a
preposition like on as a two-place predicate, e.g.,
on(y1, x3). We also use a small set of semantic
roles such as subj and obj as a functional term
and use equality (=) to connect an event and its
participant, as in subj(y1) = x1.

To be precise, the set of atomic formulas A in

this event semantics is deﬁned by the rule

A ::= F(t) | G(t, u) | t = u

where F(t) is a one-place predicate (for con-
tent words), G(t, u) is a two-place predicate (for
prepositions), t and u are a term. A term is de-
ﬁned as a constant, a variable, or a functional term
of the form f (t) where f is a semantic role and t
is a term.

We call a formula constructed by conjunctions
and existential quantiﬁers a basic formula in event
semantics. Thus, a set of basic formulas ϕ in event
semantics is deﬁned as:

ϕ ::= A | ϕ ∧ ϕ | ∃t ϕ

The formula in (2) is an instance of a basic
formula, which captures the predicate-argument
structure of a sentence.

On top of the system of basic formulas, we have
a full language of event semantics with negation
(¬), disjunction (∨), implication (→), and a uni-
versal quantiﬁer (∀). These operators are used to
represent additional logical features.

There is a natural correspondence between ba-
sic formulas and directed acyclic graphs (DAGs).
Figure 1 shows an example1.
In the graph rep-
resentation, constants and variables correspond to
vertices; both two-place predicates for preposi-
tions (e.g., on(y1, x1)) and functional terms for
semantic roles (e.g., subj(y1) = x1) are repre-
sented as edges. A one-place predicate F(t) in a
logical formula can be represented as a functional
relation isa(t, F), where isa is an expression re-
lating a term t and a predicate F represented as a
vertex. The isa edges are unlabeled for simplicity.

3.2 Natural deduction and word abduction

We use the system of natural deduction (Prawitz,
1965; Troelstra and Schwichtenberg, 2000) to cap-
ture phrase correspondences from a sentence pair
(T, H), following the strategies for word axiom
injection developed by Mart´ınez-G´omez et al.
(2017) and Yanaka et al. (2017). The sentence
pair (T, H) is ﬁrst mapped to a pair of formulas
(T (cid:48), H (cid:48)). T (cid:48) is initially set to the premise P , and
H (cid:48) is set to the goal G to be proved.

If formulas P and G are basic formulas, then the
proving strategy is to decompose them into a set
of atomic formulas using inference rules for con-
junctions and existential quantiﬁers. The premise
P is decomposed into a pool of premises P =
{pi(θi) | i ∈ {1, . . . , m}}, where each pi(θi) is
an atomic formula and θi is a list of terms appear-
ing in pi(θi). The goal G is also decomposed into
a set of sub-goals G = {gj(θ(cid:48)
j) | j ∈ {1, . . . , n}},
where θ(cid:48)

j is a list of terms appearing in gj(θ(cid:48)
The proof is performed by searching for a
premise pi(θi) whose predicate matches that of a
sub-goal gj(θ(cid:48)
j). If such a premise is found, then
variables in θ(cid:48)
j are uniﬁed to those in θi and the
sub-goal gj(θ(cid:48)
j) can be removed from G. If all the
sub-goals can be removed, we prove T (cid:48) → H (cid:48).
In the presence of two or more variables with the
same predicate, there might be multiple possible
variable uniﬁcations. Modern theorem provers ex-
plore these multiple possibilities in search of a
conﬁguration that proves a theorem.

j).

Sub-goals may remain unproved when T log-
ically does not entail H i.e., when there are no
premise predicates pi that are matched with gj. In
this case, the system tries word axiom injection,
called word abduction. More speciﬁcally, if there

1See Jones (2016) for some variants of graphical repre-

sentations of logical formulas.

is a premise pi(θi) whose predicate has a linguis-
tic relation (according to linguistic knowledge2)
with that of a sub-goal gj(θ(cid:48)
j), then variables in θ(cid:48)
j
are uniﬁed with those in θi and the sub-goal gj(θ(cid:48)
j)
can be removed from G.

3.3 Graph illustration

Figure 2 shows an example to illustrate how the
system works. To begin with, the input sentence
pair (T, H) is mapped onto a pair of formulas,
(T (cid:48), H (cid:48)). T (cid:48) is initially placed to the premise P ,
and H (cid:48) to the goal G. Note that these are basic
formulas, and they are thus decomposed to the fol-
lowing sets of formulas P and G, respectively:
P = {lady(x1), meat(x2), cut(y1), up(y1),

precisely(y1), subj(y1) = x1, obj(y1) = x2}
G = {woman(x3), meat(x4), cut(y2), piece(x5),

into(y2, x5), subj(y2) = x3, obj(y2) = x4}
Steps 1 to 3 in Figure 2 demonstrate the vari-
able uniﬁcation routine and word axiom injection
using graphs. Note that in step 1, all variables in
formulas in P or G are initially different.

In step 2, we run a theorem proving mecha-
nism that uses graph terminal vertices as anchors
to unify variables between formulas in P and those
in G. The premise meat(x2) in P matches the
predicate meat of the sub-goal meat(x4) in G
and the variable uniﬁcation x4 := x2 is applied
(and similarly for the sub-goal cut(y2) in G with
the variable uniﬁcation y2 := y1).

In step 3, we use the previous variable uniﬁca-
tion on y1, the subj edge in P and G and the ax-
iom ∀x.lady(x) → woman(x) from external knowl-
edge to infer that x3 := x1.

4 Phrase Abduction

There is one critical reason that
the word-to-
word axiom injection described in Section 3.2
fails to detect phrase-to-phrase correspondences.
That is, the natural deduction mechanism decom-
poses the goal G into atomic sub-goals that are
then proved one-by-one (word-by-word), indepen-
dently of each other except for the variable uniﬁ-
cation effect. This mechanism is particularly prob-
lematic when we attempt to prove phrases that
resist decomposition, two-place predicates (e.g.,
into(x, y)), or failures in variable uniﬁcation (e.g.,
due to inaccurate semantics). Thus, we propose a
method to detect phrase-to-phrase correspondence
through natural deduction proofs.

2As given in a linguistic ontology or database such as

WordNet or VerbOcean.

4.1 Phrase pair detection

We detect phrase-to-phrase entailing relations be-
tween T (cid:48) and H (cid:48) by ﬁnding alignments between
the subgraphs of their meaning representations
when T (cid:48) ⇒ H (cid:48) or T (cid:48) ⇒ ¬H (cid:48) hold. Find-
ing subgraph alignments is a generalization of
the subgraph isomorphism problem, which is NP-
complete3. In this paper, we approximate a solu-
tion to this problem by using a combination of a
backtracking variable uniﬁcation and a determin-
istic graph search on the neighborhood of non-
uniﬁed variables.

Using our running example in Figure 2, step 4
displays our proposed subgraph alignment. The
variable x5 in the graph of G cannot be uniﬁed
with any variable in the graph of P. This is a
very common case in natural language inferences,
as there might be concepts in H that are not di-
rectly supported by concepts in T . In this research,
we propose spanning a subgraph starting at non-
uniﬁed variables (e.g., x5 in G) whose boundaries
are semantic roles (e.g., subj, obj). Its candidate
semantics from P are then the attributes of its cor-
responding uniﬁed variables from G (e.g. cut up
precisely → cut into pieces).

4.2 Graph alignments

To formalize this solution we introduce some
graph notation. Let V = V u ∪ V ¯u ∪ L be the
set of vertices, where V u is the set of uniﬁed vari-
ables (e.g. x1, x2, y1), V ¯u is the set of non-uniﬁed
variables (e.g. x5), and L is a set of predicates
(e.g., lady, woman). Let E be the set of labeled,
directed edges (cid:104)v, l, v(cid:48)(cid:105) where v, v(cid:48) ∈ V and l are
labels that may represent a functional relation isa,
a preposition or a semantic role. We denote a set
of two-place predicates for prepositions as PREP
and a set of functional terms for semantic roles as
ARGS; e.g., ARGS = {subj, obj}. A graph that
represents P is then a tuple GP = (cid:104)VP , EP (cid:105), and
similarly, for G, GG = (cid:104)VG, EG(cid:105).

We can now deﬁne a function to span a
subgraph in the neighborhood of non-uniﬁed
variables v ∈ V ¯u
G in the graph of G. We call
a connected set of edges in which no semantic
a
roles appear,
phrase set. Let E(x) be the phrase set in E
such that each vertex is connected to x with
an incoming or outgoing edge, that is, E(x) =
{(vi, l, vk) ∈ E | (x = vi ∨ x = vk) ∧ l (cid:54)∈ ARGS} .

i.e., {(cid:104)v, l, v(cid:48)(cid:105) | l (cid:54)∈ ARGS},

3Emmert-Streib et al. (2016) gives a good overview.

T : A lady is cutting up some meat precisely
T (cid:48) : ∃x1∃x2∃y1(lady(x1) ∧ meat(x2) ∧ cut(y1) ∧
up(y1) ∧ precisely(y1) ∧ subj(y1, x1) ∧ obj(y1, x2))

H: Some meat is being cut into pieces by a woman
H (cid:48) : ∃x3∃x4∃x5∃y2(meat(x4) ∧ woman(x3) ∧ cut(y2) ∧
piece(x5) ∧ into(y2, x5) ∧ subj(y2, x3) ∧ obj(y2, x4))

lady

x1

x2

meat

woman

x3

x4

meat

lady

x1

x2

meat

woman

x3

x2

meat

subj

obj

cut

precisely

Step 1:
Make graphs
from formulas.

subj

obj

cut

precisely

Step 2:
Anchor terminal
vertices and unify
variables x4 := x2
and y2 := y1.

subj

obj

cut

precisely

Step 3:
Use graph constraints
and knowledge
(lady is a woman)
to unify x3 := x1.

subj

obj

cut

precisely

Step 4:
Induce subgraph
alignment with non-
uniﬁed variable x5.

y1

up

y1

up

y1

up

y1

up

y2

x5

piece

obj

into

obj

into

obj

into

obj

into

y1

x5

piece

y1

x5

piece

y1

x5

piece

subj

cut

subj

cut

subj

cut

subj

cut

lady

x1

x2

meat

woman

x1

x2

meat

lady

x1

x2

meat

woman

x1

x2

meat

Figure 2: A graph representation of a theorem proving routine on basic formulas and variable uniﬁcation.
Dotted circles represent non-uniﬁed variables at each step, whereas edges without labels are attributes.
The graph of the left side is the set of premises P and the graph of the right side is the set of sub-goals
G. Colored subgraphs represent a word or a phrase to which our axiom injection mechanism applies.

Note that E(x) induces a subgraph in a given
graph G and the condition l /∈ ARGS sets the
boundaries of the subgraph by excluding the
semantic roles of verb phrases. Given two phrase
sets E and E(cid:48), we say E(cid:48) is reachable from E,
written E ∼ E(cid:48), if E and E(cid:48) share at least one
variable vertex. Let ∼∗ be the transitive closure of
∼. Given a set of edges EG and a variable v, we
deﬁne the extended phrase set, written Reach(v),
as follows:

Reach(v) = {e ∈ E | EG(v) ∼∗ E}
that is, the set of edges e that can be reached from
v without crossing an edge with a semantic role

label. This function deﬁnes a partition or equiva-
lence class for non-uniﬁed variables v ∈ V ¯u
G , and
each of these partitions induce a (possibly discon-
tinuous) phrase in G that remains unproved.

The corresponding subgraph in P to each of
these partitions is given by the vertices and edges
connected with a path of length one to the uniﬁed
variables that appear in Reach(v). That is,

Corr(v) = {e ∈ EP (v(cid:48)), v(cid:48) ∈ V [v]

G ∩ VP }

where V [v]
G induced by the partition Reach(v).

G denotes the vertices in the subgraph of

A subgraph alignment between P and G is given
by the pair of (cid:104)Corr(v), Reach(v)(cid:105) for all v ∈ V ¯u
G ,
where the phrases can be read from the predicates
in the vertices and edges labeled with prepositions.
We deﬁne a mapping (·)• from a labeled edge




(cid:104)v, l, v(cid:48)(cid:105)• =

(cid:104)v, l, v(cid:48)(cid:105) to an atomic formula as follows.
if l is isa
if l ∈ PREP
if l ∈ ARGS

v(cid:48)(v)
l(v, v(cid:48))
l(v) = v(cid:48)
Let E be a set of labeled edges, and let E• be
(cid:8)(cid:104)v, l, v(cid:48)(cid:105)• | (cid:104)v, l, v(cid:48)(cid:105) ∈ E(cid:9). The phrase axiom
generated for each non-uniﬁed variable v ∈ V ¯u
G
is deﬁned as



∀θC.( (cid:86) Corr(v)• → ∃θR. ((cid:86) Reach(v)•)),
where θC is a set of free variables appearing in
Corr(v)• (which includes v) and θR is a set of
free variables appearing in Reach(v)• but not in
Corr(v)•.

In Figure 2, the only non-uniﬁed variable in the
G = {x5}. Then,

sub-goal in step 4 is x5, that is, V ¯u
starting from the variable x5, Reach(x5) is

Now V [x5]

{(cid:104)y1, into, x5(cid:105) , (cid:104)x5, isa, piece(cid:105)} .
G = {y1, x5}, and thus Corr(x5) is
{(cid:104)y1, isa, cut(cid:105) , (cid:104)y1, isa, up(cid:105) , (cid:104)y1, isa, precisely(cid:105)} .

Finally, the following is the axiom generated from
(cid:104)Corr(x5), Reach(x5)(cid:105)4.

4.3 Non-basic formulas

If formulas P and G are not basic formulas (i.e.,
they contain logical operators other than ∧ and
∃), they are decomposed according to inference
rules of natural deduction. There are two types
of inference rules: introduction rules decompose
a goal formula into smaller sub-goals, and elimi-
nation rules decompose a formula in the pool of
premises into smaller ones. Figure 3 shows intro-
duction rules and elimination rules for decompos-
ing non-basic formulas including negation, dis-
junction, implication, and a universal quantiﬁer.
By applying inference rules, a proof of non-basic
formulas appearing in sub-goals can be decom-
posed to a set of subproofs that only have basic
formulas in sub-goals. If a universal quantiﬁer ap-
pears in premises, it is treated in the same way as
other premises.

4Note that this axiom is logically equivalent to

∀y1(cut(y1) ∧ up(y1) ∧ precisely(y1) →
∃x5(cut(y1) ∧ into(y1, x5) ∧ piece(x5)))

indicated in the colored subgraphs in step 4 of Figure 2.

P :
G : A ∨ B

P :
G : A ∨ B

P : A ∨ B
G : C

∨-I

∨-I

P :
G : A

P :
G : B

P : A
G : C

∨-E

P : B
G : C

P :
G : A → B

P : A → B
G : B

P :
G : ¬A

P : ¬A
G : False

→-I

→-E

¬-I

¬-E

P : A
G : B

P :
G : A

P : A
G : False

P :
G : A

P :

P : ∀xA(x)

G : ∀xA(x)

G :

∀-I

∀-E

P :

G : A(x)

P : A(t)

G :

Figure 3: Inference rules used for decomposing
non-basic formulas. P is a premise and G is a sub-
goal. The initial formulas are at the top, with the
formulas obtained by applying the inference rules
shown below.

P : ¬∃y1∃x1(man(x1) ∧ cut(y1) ∧ potato(x2)

∧ (subj(y1) = x1) ∧ (obj(y1) = x2)

G : ¬∃y1∃x1∃x2∃x3(man(x1) ∧ slice(y1) ∧ potato(x2)

∧ into(y1, x3)∧piece(x3)∧(subj(y1) = x1)∧ (obj(y1) = x2)

P : ¬∃y1∃x1(man(x1) ∧ cut(y1) ∧ potato(x2)

∧ (subj(y1) = x1) ∧ (obj(y1) = x2)

P0 : ∃y1∃x1∃x2∃x3(man(x1) ∧ slice(y1) ∧ potato(x2)

∧ into(y1, x3)∧piece(x3)∧(subj(y1) = x1)∧ (obj(y1) = x2)

¬-I (G)

¬-E (P )

P0 : ∃y1∃x1∃x2∃x3(man(x1) ∧ slice(y1) ∧ potato(x2)

∧ into(y1, x3)∧piece(x3)∧(subj(y1) = x1)∧ (obj(y1) = x2)

G1 : ∃y1∃x1(man(x1) ∧ cut(y1) ∧ potato(x2)

∧ (subj(y1) = x1) ∧ (obj(y1) = x2)

Figure 4: Proof process for the contradiction.

For example, consider the following sentence

pair with the gold label “no” (contradiction):
T : A man is not cutting a potato
H: A man is slicing a potato into pieces

Figure 4 shows the proof process of T (cid:48) ⇒ ¬H (cid:48).
To prove the contradiction, the formulas T (cid:48) and
¬H (cid:48) are set to P and G, respectively. Then, the
negation in G is removed by applying the intro-
duction rule (¬-I) to G. Here, False is the propo-
sitional constant denoting the contradiction.
In
the second stage of the proof, the goal is to prove
False in G0 from the two premises P and P0. By
applying (¬-E) to P , we can eliminate the nega-
tion from P , resulting in the new goal G1.

As both the premise P0 and the sub-goal G1 are

∀y1(cut(y1) ∧ up(y1) ∧ precisely(y1) →
∃x5(into(y1, x5) ∧ piece(x5))).

G0 : False

basic formulas, the procedure described in the pre-
vious sections applies to the pair (P0, G1); these
basic formulas are decomposed into atomic ones,
and then the word-to-word abduction generates the
desired axiom ∀y1(cut(y1) → slice(y1)). Finally,
the graph alignment applies in the same way as
described in Figure 2, which generates the phrase
axiom:

∀y1(cut(y1) → ∃x5(into(y1, x5) ∧ piece(x5)))

Using this axiom, one can complete the proof of
the contradiction between T (cid:48) and H (cid:48).

5 Experiments

5.1 Dataset selection

We use the SemEval-2014 version of the SICK
dataset (Marelli et al., 2014) for evaluation. The
SICK dataset is a dataset for semantic textual sim-
ilarity (STS) as well as for RTE. It was origi-
nally designed for evaluating compositional distri-
butional semantics, so it contains logically chal-
lenging problems involving quantiﬁers, negation,
conjunction, and disjunction, as well as inferences
with lexical and phrasal knowledge.

The SNLI dataset (Bowman et al., 2015) con-
tains inference problems requiring phrasal knowl-
edge. However, it is not concerned with logi-
cally challenging expressions; the semantic rela-
tionships between a premise and a hypothesis are
often limited to synonym/hyponym lexical sub-
stitution, replacements of short phrases, or exact
word matching. This is because hypotheses are of-
ten parallel to the premise in structures and vocab-
ularies. The FraCaS dataset (Cooper et al., 1994)
also contains logically complex problems. How-
ever, it is conﬁned to purely logical inferences
and thus does not contain problems requiring in-
ferences with lexical and phrasal knowledge. For
these reasons, we choose the SICK dataset to eval-
uate our method of using logical inference to ex-
tract phrasal knowledge.

The SICK dataset contains 9927 sentence pairs
with a 5000/4927 training/test split. These sen-
tence pairs are manually annotated with three
types of labels yes (entailment), no (contradic-
tion), or unknown (neutral) (see Table 1 for exam-
ples). In RTE tasks, we need to consider a direc-
tional relation between words such as hypernym
and hyponym to prove entailment and contradic-
tion. Hence, to extract phrasal knowledge for RTE
tasks, we use the training data whose gold label is

entailment or contradiction, excluding those with
the neutral label.

5.2 Experimental setup

the natural deduction proofs, we used
For
ccg2lambda (Mart´ınez-G´omez et al., 2016)5, a
higher-order automatic inference system, which
converts CCG derivation trees into semantic rep-
resentations and conducts natural deduction proofs
automatically. We parsed the tokenized sentences
of the premises and hypotheses using three wide-
coverage CCG parsers: C&C (Clark and Curran,
2007), EasyCCG (Lewis and Steedman, 2014),
and depccg (Yoshikawa et al., 2017). CCG deriva-
tion trees (parses) were converted into logical se-
mantic representations based on Neo-Davidsonian
event semantics (Section 3.1). The validation of
semantic templates used for semantic representa-
tions was conducted exclusively on the trial split
of the SICK dataset. We used Coq (Bertot and
Castran, 2010), an interactive natural deduction
theorem prover that we run fully automatically
with a number of built-in theorem-proving rou-
tines called tactics, which include ﬁrst-order logic.
We compare phrase abduction with different ex-
perimental conditions. No axioms is our sys-
tem without axiom injection. W2W is the previ-
ous strategy of word abduction (Mart´ınez-G´omez
et al., 2017). P2P is our strategy of phrase ab-
duction; W2W+P2P combines phrase abduction
In addition, we compare
with word abduction.
our system with three purely logic-based (unsuper-
vised) approaches: The Meaning Factory (Bjerva
et al., 2014), LangPro (Abzianidze, 2015), and
UTexas (Beltagy et al., 2014). We also com-
pare our system with machine learning-based ap-
proaches: the current state-of-the-art deep learn-
ing model GRU (Yin and Sch¨utze, 2017), a log-
linear regression model SemEval-2014 best (Lai
and Hockenmaier, 2014), and a hybrid approach
combining a logistic regression model and proba-
bilistic logic PL+eclassif (Beltagy et al., 2016).

5.3 Extracted paraphrases

We extracted 9445 axioms from the SICK train-
ing dataset. The proving time average to extract
phrasal axioms was only 3.0 seconds for a one-
sentence pair6. Table 2 shows some examples of

5Available at https://github.com/mynlp/ccg2lambda.
6Ours is a polynomial-time instance of the graph match-
ing problem, where the vertex cover set (maximum number
of variables in a phrase) is bounded to a small constant.

Text
A boy is looking at a calendar

ID
3941
5938 Vegetables are being put into a pot by a man
5930

The man is not doing exercises

Hypothesis
There is nobody checking a calendar
Someone is pouring ingredients into a pot
Two men are ﬁghting

Entailment
No
Yes
Unknown

Table 1: Examples in the SICK dataset with different entailment labels and similarity scores.

Kind

noun phrase

Text
A blond woman is sitting on the roof of
a yellow vehicle, and two people are inside

verb phrase

The person is setting ﬁre to the cameras

verb phrase

prepositional phrase

antonym

A man and a woman are walking together
through the woods
A child, who is small, is outdoors climbing
steps outdoors in an area full of grass
A woman is putting make-up on

Hypothesis
A woman with blond hair is sitting on the roof of
a yellow vehicle, and two people are inside
Some cameras are being burned by a person
with a blow torch
A man and a woman are hiking
through a wooded area
A small child is outdoors climbing steps
in a grassy area
The woman is removing make-up

Table 2: Examples of phrase alignments constructed by phrasal axiom injection.

Prec. Rec. Acc.
87.1
−
GRU
85.1
−
PL+eclassif
84.6
81.9
SemEval2014 Best Score
81.6
60.6
The Meaning Factory
81.4
58.1
LangPro
80.4
−
UTexas
84.3
77.3
W2W+P2P
83.1
63.6
W2W
83.0
72.1
P2P
76.7
46.5
No axioms
Table 3: RTE results on the SICK dataset.

−
−
81.6
93.6
98.0
−
84.2
97.1
85.6
98.9

paraphrases we extracted from the natural deduc-
tion proof in the training set.
In particular, the
examples of verb phrases show our method has
the potential to capture long paraphrases. Each
paraphrase in Table 2 is not contained in Word-
Net and PPDB. There are many instances of non-
contiguous phrases in the SICK dataset, in par-
ticular, verb-particle phrases. Shown in Table 2,
our semantic alignment can detect non-contiguous
phrases through the variable uniﬁcation process,
which is one of the main advantages over other
shallow/syntactic methods.
In addition, Table 2
shows our method is not limited to hypernym or
hyponym relations, but it is also capable for de-
tecting antonym phrases.

5.4 RTE evaluation results

Table 3 shows the experimental results. The re-
sults show that the combination of word abduc-
tion and phrase abduction improved the accuracy.
When the W2W+P2P result is substituted for the
W2W result, there is a 1.1% increase in accuracy

(from 83.1% to 84.3%). The accuracy of P2P
is almost equal to that of W2W. This is because
the recall improves from 63.6% to 72.1% while
the precision decreases from 97.1% to 85.6%.
The increase in false positive cases caused this
result; some details of false positive cases are
described in the next subsection. W2W+P2P
outperformed other purely logic-based systems.
The machine learning-based approaches outper-
form W2W+P2P, but unlike these approaches, pa-
rameter estimation is not used in our method. This
suggests that our method has the potential to in-
crease the accuracy by using a classiﬁer.

5.5 Positive examples and error analysis

Table 4 shows some positive and negative exam-
ples on RTE with the SICK dataset. For ID 9491,
the sentence pair requires the paraphrase from a
ﬁeld of brown grass to a grassy area, not included
in previous lexical knowledges. Our phrasal ax-
iom injection can correctly generate this para-
phrase from a natural deduction proof, and the sys-
tem proves the entailment relation.

ID 2367 is also a positive example of phrasal ax-
iom injection. The phrasal axiom between set ﬁre
to cameras and burn cameras with a blow torch
was generated. This example shows that our se-
mantic alignment succeeds in acquiring a general
paraphrase by separating logical expressions such
as some from content words and also by account-
ing for syntactic structures such as the passive-
active alternation.

For ID 3628, the axiom shown in the table was
extracted from the following sentence pair with

ID Sentence Pair

Gold

Pred Axiom

9491

2367

3628

96

408

A group of four brown dogs are playing in a ﬁeld of brown grass
Four dogs are playing in a grassy area
A person is burning some cameras with a blow torch
The person is setting ﬁre to the cameras
A pan is being dropped over the meat
The meat is being dropped into a pan
A man is jumping into an empty pool
There is no biker jumping in the air
A group of explorers is walking through the grass
Some people are walking

Yes

Yes

Yes

Yes

∀x1(ﬁeld(x1) ∧ brown(x1) ∧ grass(x1)
→ grassy(x1) ∧ area(x1))
∀x1∀y1(burn(y1) ∧ with(y1, x1) ∧ blow torch(x1) ∧ camera(obj(y1))
→ set(y1) ∧ ﬁre(obj(y1)) ∧ to(y1, obj(y1)) ∧ camera(obj(y1)))

Unk

Yes

∀y1(pan(obj(y1)) → into(y1, obj(y1)))

∀y1(jump(y1) → ∃x1(in(y1, x1) ∧ air(x1)))
∀y1(man(y1) → biker(y1))

Unk

No

Yes

Unk

Table 4: Positive and negative examples on RTE from the SICK dataset.

their entailment label:
T1: A woman is putting meat in a pan
H1: Someone is dropping the meat into a pan
But the phrase drop over does not entail the phrase
drop into, and a proof for the inference is over-
generated in ID 3628. We extracted all possible
phrasal axioms from the training dataset, so noisy
axioms can be extracted as a consequence of mul-
tiple factors such as parsing errors or potential dis-
ambiguation in the training dataset. One possible
solution for decreasing such noisy axioms would
be to use additive composition models (Tian et al.,
2016) and asymmetric learnable scoring functions
to calculate the conﬁdence on these asymmetric
entailing relations between phrases.

ID 96 is also an example of over-generation
of axioms. The ﬁrst axiom, ∀y1(jump(y1) →
∃x1(in(y1, x1) ∧ air(x1))) was extracted from the
proof of T1 ⇒ H1:
T1: A child in a red outﬁt is jumping on a trampoline
H1: A little boy in red clothes is jumping in the air
The second axiom ∀y1(man(y1) → biker(y1)) was
extracted from the proof of T2 ⇒ H2:
T2: A man on a yellow sport bike is doing a wheelie and a
friend on a black bike is catching up
H2: A biker on a yellow sport bike is doing a wheelie and a
friend on a black bike is catching up
Although these axioms play a role in the proofs
of T1 ⇒ H1 and T2 ⇒ H2, the wrong ax-
iom ∀y1(man(y1) → biker(y1)) causes the over-
generation of a proof for the inference in ID 96.
The correct one would rather be ∀x1∀y1(man(y1) ∧
on(y1, x1) ∧ bike(x1) → biker(y1)). In this case, it is
necessary to bundle predicates in a noun-phrase by
specifying the types of a variable (entity or event)
when making phrase alignments.

For ID 408,

the word explorer is not con-
tained in the training entailment dataset and
hence the relevant axiom ∀x1(explorer(x1) →
people(x1)) was not generated. While our logic-
based method enables detecting semantic phrase
correspondences in a sentence pair in an unsuper-

vised way, our next step is to predict unseen para-
phrases of this type.

6 Conclusion

In this paper, we proposed a method of detect-
ing phrase correspondences through natural de-
duction proofs of semantic relations between sen-
tence pairs. The key idea is to attempt a proof with
automatic phrasal axiom injection by the careful
management of variable sharing during the proof
construction process. Our method identiﬁes se-
mantic phrase alignments by monitoring the proof
of a theorem and detecting unproved sub-goals
and logical premises. The method of detecting se-
mantic phrase alignments would be applicable to
other semantic parsing formalisms and meaning
representation languages such as abstract meaning
representations (AMR) (Banarescu et al., 2013).
Experiment results showed that our method de-
tected various phrase alignments including non-
contiguous phrases and antonym phrases. This re-
sult may contribute to previous phrase alignment
approaches. The extracted phrasal axioms im-
proved the accuracy of RTE tasks.

In future work, we shall enhance this method-
ology of phrasal axiom injection to predict unseen
paraphrases. The pairs of premises and sub-goals
that can be detected through the proof process con-
duct semantic alignments in a sentence pair. With
the use of an additive composition model of dis-
tributional vectors, we can evaluate the validity of
such semantic alignments. A combination of our
phrasal axiom injection and additive composition
model of distributional vectors has the potential to
detect unseen paraphrases in a sentence pair.

Acknowledgments

We thank the three anonymous reviewers for their
detailed comments. This work was supported by
JST CREST Grant Number JPMJCR1301 and AIP
Challenge Program, Japan.

References

Lasha Abzianidze. 2015. A tableau prover for natural
logic and language. In Proceedings of the 2015 Con-
ference on Empirical Methods in Natural Language
Processing. Association for Computational Linguis-
tics, Lisbon, Portugal, pages 2492–2502.

Lasha Abzianidze. 2016. Natural solution to FraCaS
In Proceedings of the 5th
entailment problems.
Joint Conference on Lexical and Computational Se-
mantics. Association for Computational Linguistics,
Berlin, Germany, pages 64–74.

Yuki Arase and Jun’ichi Tsujii. 2017. Monolingual
phrase alignment on parse forests. In Proceedings of
the 2017 Conference on Empirical Methods in Nat-
ural Language Processing. Association for Compu-
tational Linguistics, Copenhagen, Denmark, pages
1–11.

Laura Banarescu, Claire Bonial, Shu Cai, Madalina
Georgescu, Kira Grifﬁtt, Ulf Hermjakob, Kevin
Knight, Philipp Koehn, Martha Palmer, and Nathan
Schneider. 2013. Abstract meaning representation
for sembanking. In Proceedings of the 7th Linguis-
tic Annotation Workshop and Interoperability with
Discourse. Association for Computational Linguis-
tics, Soﬁa, Bulgaria, pages 178–186.

Colin Bannard and Chris Callison-Burch. 2005. Para-
In Pro-
phrasing with bilingual parallel corpora.
ceedings of the 43rd Annual Meeting on Associa-
tion for Computational Linguistics. Association for
Computational Linguistics, Stroudsburg, PA, USA,
pages 597–604.

Islam Beltagy, Cuong Chau, Gemma Boleda, Dan
Garrette, Katrin Erk, and Raymond Mooney. 2013.
Montague meets Markov: Deep semantics with
In Proceedings of the
probabilistic logical form.
Second Joint Conference on Lexical and Computa-
tional Semantics (*Sem-2013). Atlanta, GA, pages
11–21.

Islam Beltagy, Stephen Roller, Gemma Boleda, Ka-
trin Erk, and Raymond J. Mooney. 2014. UTexas:
Natural language semantics using distributional se-
In Proceedings
mantics and probabilistic logic.
of
the 8th International Workshop on Semantic
Evaluation (SemEval-2014). Association for Com-
putational Linguistics and Dublin City University,
Dublin, Ireland, pages 796–801.

Islam Beltagy, Stephen Roller, Pengxiang Cheng, Ka-
trin Erk, and Raymond J. Mooney. 2016. Repre-
senting meaning with a combination of logical and
distributional models. Computational Linguistics
42(4):763–808.

Yves Bertot and Pierre Castran. 2010.

Interac-
tive Theorem Proving and Program Development:
Coq’Art The Calculus of Inductive Constructions.
Springer Publishing Company, Incorporated, New
York, USA.

Johannes Bjerva, Johan Bos, Rob van der Goot, and
Malvina Nissim. 2014. The Meaning Factory: For-
mal semantics for recognizing textual entailment
In Proceed-
and determining semantic similarity.
ings of the 8th International Workshop on Semantic
Evaluation (SemEval-2014). Association for Com-
putational Linguistics and Dublin City University,
Dublin, Ireland, pages 642–646.

Samuel R. Bowman, Gabor Angeli, Christopher Potts,
and Christopher D. Manning. 2015. A large anno-
tated corpus for learning natural language inference.
In Proceedings of the 2015 Conference on Empirical
Methods in Natural Language Processing. Associa-
tion for Computational Linguistics, Lisbon, Portu-
gal, pages 632–642.

Timothy Chklovski and Patrick Pantel. 2004. Verbo-
cean: Mining the web for ﬁne-grained semantic verb
In Proceedings of the 2004 Conference
relations.
on Empirical Methods in Natural Language Pro-
cessing. Association for Computational Linguistics,
Barcelona, Spain, pages 33–40.

Stephen Clark and James R. Curran. 2007. Wide-
coverage efﬁcient statistical parsing with CCG
and log-linear models. Computational Linguistics
33(4):493–552.

Robin Cooper, Richard Crouch, Jan van Eijck, Chris
Fox, Josef van Genabith, Jan Jaspers, Hans Kamp,
Manfred Pinkal, Massimo Poesio, Stephen Pulman,
et al. 1994. FraCaS–a framework for computational
semantics. Deliverable D6.

Ido Dagan, Dan Roth, Mark Sammons, and Fabio Mas-
simo Zanzotto. 2013. Recognizing Textual Entail-
ment: Models and Applications. Synthesis Lectures
on Human Language Technologies. Morgan & Clay-
pool Publishers.

Frank Emmert-Streib, Matthias Dehmer, and Yongtang
Shi. 2016. Fifty years of graph matching, network
Information
alignment and network comparison.
Sciences 346-347(Supplement C):180 – 197.

Juri Ganitkevitch, Benjamin Van Durme, and Chris
PPDB: The paraphrase
Callison-Burch. 2013.
database. In Proceedings of the 2013 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologie. Association for Computational Linguistics,
Atlanta, Georgia, pages 758–764.

Bevan Keeley Jones. 2016. Learning words and syn-
tactic cues in highly ambiguous contexts. Ph.D. the-
sis, The University of Edinburgh.

Alice Lai and Julia Hockenmaier. 2014. Illinois-lh: A
denotational and distributional approach to seman-
tics. In Proceedings of the 8th International Work-
shop on Semantic Evaluation (SemEval 2014). As-
sociation for Computational Linguistics and Dublin
City University, Dublin, Ireland, pages 329–334.

Dag Prawitz. 1965. Natural Deduction – A Proof-
Theoretical Study. Almqvist & Wiksell, Stockholm,
Sweden.

Siva Reddy, Mirella Lapata, and Mark Steedman. 2014.
Large-scale semantic parsing without question-
answer pairs. Transactions of the Association for
Computational Linguistics 2:377–392.

Siva Reddy, Oscar T¨ackstr¨om, Michael Collins, Tom
Kwiatkowski, Dipanjan Das, Mark Steedman, and
Mirella Lapata. 2016. Transforming Dependency
Structures to Logical Forms for Semantic Parsing.
Transactions of the Association for Computational
Linguistics 4:127–140.

Ran Tian, Naoaki Okazaki, and Kentaro Inui. 2016.
Learning semantically and additively compositional
distributional representations. In Proceedings of the
54th Annual Meeting of the Association for Compu-
tational Linguistics. Association for Computational
Linguistics, Berlin, Germany, pages 1277–1287.

Anne Troelstra and Helmut Schwichtenberg. 2000. Ba-
sic Proof Theory. Cambridge University Press.

Hitomi Yanaka, Koji Mineshima, Pascual Mart´ınez-
G´omez, and Daisuke Bekki. 2017. Determining
semantic textual similarity using natural deduction
In Proceedings of the 2017 Conference
proofs.
on Empirical Methods in Natural Language Pro-
cessing. Association for Computational Linguistics,
Copenhagen, Denmark, pages 692–702.

Wenpeng Yin and Hinrich Sch¨utze. 2017.

Task-
speciﬁc attentive pooling of phrase alignments con-
In Proceedings of
tributes to sentence matching.
the 15th Conference of the European Chapter of the
Association for Computational Linguistics: Volume
1, Long Papers. Association for Computational Lin-
guistics, Valencia, Spain, pages 699–709.

Masashi Yoshikawa, Hiroshi Noji, and Yuji Mat-
sumoto. 2017. A* CCG parsing with a supertag and
dependency factored model. In Proceedings of the
55nd Annual Meeting of the Association for Compu-
tational Linguistics. Association for Computational
Linguistics, Vancouver, Canada, pages 277–287.

Shiqi Zhao, Cheng Niu, Ming Zhou, Ting Liu, and
Sheng Li. 2008. Combining multiple resources to
In Pro-
improve SMT-based paraphrasing model.
ceedings of the 46rd Annual Meeting on Associa-
tion for Computational Linguistics. Association for
Computational Linguistics, Columbus, Ohio, pages
1021–1029.

Mike Lewis and Mark Steedman. 2014. A* CCG pars-
In Proceed-
ing with a supertag-factored model.
ings of the 2014 Conference on Empirical Meth-
ods in Natural Language Processing. Association
for Computational Linguistics, Doha, Qatar, pages
990–1000.

Fei Liu, Jeffrey Flanigan, Sam Thomson, Norman M.
Sadeh, and Noah A. Smith. 2015. Toward abstrac-
tive summarization using semantic representations.
In Proceedings of the 2015 Conference of the North
American Chapter of the Association for Compu-
tational Linguistics: Human Language Technolo-
gies. The Association for Computational Linguis-
tics, pages 1077–1086.

Marco Marelli, Stefano Menini, Marco Baroni, Luisa
Bentivogli, Raffaella Bernardi, and Roberto Zam-
parelli. 2014. A SICK cure for the evaluation of
compositional distributional semantic models.
In
Proceedings of the 9th International Conference
on Language Resources and Evaluation. European
Language Resources Association, Reykjavik, Ice-
land, pages 216–223.

Pascual Mart´ınez-G´omez, Koji Mineshima, Yusuke
Miyao, and Daisuke Bekki. 2016. ccg2lambda: A
In Proceedings
compositional semantics system.
of the 2016 System Demonstrations of the Associa-
tion for Computational Linguistics. Association for
Computational Linguistics, Berlin, Germany, pages
85–90.

Pascual Mart´ınez-G´omez, Koji Mineshima, Yusuke
Miyao, and Daisuke Bekki. 2017. On-demand injec-
tion of lexical knowledge for recognising textual en-
tailment. In Proceedings of the 15th Conference of
the European Chapter of the Association for Compu-
tational Linguistics. Association for Computational
Linguistics, Valencia, Spain, pages 710–720.

George A. Miller. 1995. WordNet: A lexical
database for English. Communications of the ACM
38(11):39–41.

Koji Mineshima, Pascual Mart´ınez-G´omez, Yusuke
Miyao, and Daisuke Bekki. 2015. Higher-order
logical inference with compositional semantics. In
Proceedings of the 2015 Conference on Empirical
Methods in Natural Language Processing. Associ-
ation for Computational Linguistics, Lisbon, Portu-
gal, pages 2055–2061.

Koji Mineshima, Ribeka Tanaka, Pascual Mart´ınez-
G´omez, Yusuke Miyao, and Daisuke Bekki. 2016.
Building compositional semantics and higher-order
inference system for a wide-coverage japanese CCG
In Proceedings of the 2016 Conference
parser.
on Empirical Methods in Natural Language Pro-
cessing. Association for Computational Linguistics,
Austin, Texas, pages 2236–2242.

Terence Parsons. 1990. Events in The Semantics of En-
glish: a Study in Subatomic Semantics. MIT Press,
Cambridge, USA.

