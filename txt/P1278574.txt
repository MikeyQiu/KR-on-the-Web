9
1
0
2
 
n
u
J
 
8
1
 
 
]

C
D
.
s
c
[
 
 
4
v
3
8
8
4
0
.
8
0
8
1
:
v
i
X
r
a

COLA: Decentralized Linear Learning

Lie He∗
EPFL
lie.he@epfl.ch

An Bian∗ †
ETH Zurich
ybian@inf.ethz.ch

Martin Jaggi
EPFL
martin.jaggi@epfl.ch

Abstract

Decentralized machine learning is a promising emerging paradigm in view of
global challenges of data ownership and privacy. We consider learning of linear
classiﬁcation and regression models, in the setting where the training data is
decentralized over many user devices, and the learning algorithm must run on-
device, on an arbitrary communication network, without a central coordinator. We
propose COLA, a new decentralized training algorithm with strong theoretical
guarantees and superior practical performance. Our framework overcomes many
limitations of existing methods, and achieves communication efﬁciency, scalability,
elasticity as well as resilience to changes in data and allows for unreliable and
heterogeneous participating devices.

1

Introduction

With the immense growth of data, decentralized machine learning has become not only attractive but
a necessity. Personal data from, for example, smart phones, wearables and many other mobile devices
is sensitive and exposed to a great risk of data breaches and abuse when collected by a centralized
authority or enterprise. Nevertheless, many users have gotten accustomed to giving up control over
their data in return for useful machine learning predictions (e.g. recommendations), which beneﬁts
from joint training on the data of all users combined in a centralized fashion.

In contrast, decentralized learning aims at learning this same global machine learning model, without
any central server. Instead, we only rely on distributed computations of the devices themselves, with
each user’s data never leaving its device of origin. While increasing research progress has been made
towards this goal, major challenges in terms of the privacy aspects as well as algorithmic efﬁciency,
robustness and scalability remain to be addressed. Motivated by aforementioned challenges, we make
progress in this work addressing the important problem of training generalized linear models in a
fully decentralized environment.

Existing research on decentralized optimization, minx∈Rn F (x), can be categorized into two main
directions. The seminal line of work started by Bertsekas and Tsitsiklis in the 1980s, cf. [Tsitsiklis
et al., 1986], tackles this problem by splitting the parameter vector x by coordinates/components
among the devices. A second more recent line of work including e.g. [Nedic and Ozdaglar, 2009,
Duchi et al., 2012, Shi et al., 2015, Mokhtari and Ribeiro, 2016, Nedic et al., 2017] addresses
sum-structured F (x) = (cid:80)
k Fk(x) where Fk is the local cost function of node k. This structure is
closely related to empirical risk minimization in a learning setting. See e.g. [Cevher et al., 2014]
for an overview of both directions. While the ﬁrst line of work typically only provides convergence
guarantees for smooth objectives F , the second approach often suffers from a “lack of consensus”,
that is, the minimizers of {Fk}k are typically different since the data is not distributed i.i.d. between
devices in general.

∗These two authors contributed equally
†Now known as Yatao A. Bian. ORCID: orcid.org/0000-0002-2368-4084

32nd Conference on Neural Information Processing Systems (NeurIPS 2018), Montréal, Canada.

Contributions.
In this paper, our main contribution is to propose COLA, a new decentralized
framework for training generalized linear models with convergence guarantees. Our scheme resolves
both described issues in existing approaches, using techniques from primal-dual optimization, and
can be seen as a generalization of COCOA [Smith et al., 2018] to the decentralized setting. More
speciﬁcally, the proposed algorithm offers

- Convergence Guarantees: Linear and sublinear convergence rates are guaranteed for strongly
convex and general convex objectives respectively. Our results are free of the restrictive
assumptions made by stochastic methods [Zhang et al., 2015, Wang et al., 2017], which
requires i.i.d. data distribution over all devices.

- Communication Efﬁciency and Usability: Employing a data-local subproblem between each
communication round, COLA not only achieves communication efﬁciency but also allows
the re-use of existing efﬁcient single-machine solvers for on-device learning. We provide
practical decentralized primal-dual certiﬁcates to diagnose the learning progress.

- Elasticity and Fault Tolerance: Unlike sum-structured approaches such as SGD, COLA is
provably resilient to changes in the data, in the network topology, and participating devices
disappearing, straggling or re-appearing in the network.

Our implementation is publicly available under github.com/epfml/cola .

1.1 Problem statement

Setup. Many machine learning and signal processing models are formulated as a composite convex
optimization problem of the form

min
u

l(u) + r(u),

where l is a convex loss function of a linear predictor over data and r is a convex regularizer. Some
cornerstone applications include e.g. logistic regression, SVMs, Lasso, generalized linear models,
each combined with or without L1, L2 or elastic-net regularization. Following the setup of [Dünner
et al., 2016, Smith et al., 2018], these training problems can be mapped to either of the two following
formulations, which are dual to each other

(cid:2)FA(x) := f (Ax) + (cid:80)
(cid:2)FB(w) := f ∗(w) + (cid:80)

i gi(xi) (cid:3)
i (−A(cid:62)
i g∗

i w)(cid:3),

min
x∈Rn
min
w∈Rd

(A)

(B)

i are the convex conjugates of f and gi, respectively. Here x ∈ Rn is a parameter vector
where f ∗, g∗
and A := [A1; . . . ; An] ∈ Rd×n is a data matrix with column vectors Ai ∈ Rd, i ∈ [n]. We assume
that f is smooth (Lipschitz gradient) and g(x) := (cid:80)n
Data partitioning. As in [Jaggi et al., 2014, Dünner et al., 2016, Smith et al., 2018], we assume
the dataset A is distributed over K machines according to a partition {Pk}K
k=1 of the columns of
A. Note that this convention maintains the ﬂexibility of partitioning the training dataset either by
samples (through mapping applications to (B), e.g. for SVMs) or by features (through mapping
applications to (A), e.g. for Lasso or L1-regularized logistic regression). For x ∈ Rn, we write
x[k] ∈ Rn for the n-vector with elements (x[k])i := xi if i ∈ Pk and (x[k])i := 0 otherwise, and
analogously A[k] ∈ Rd×nk for the corresponding set of local data columns on node k, which is of
size nk = |Pk|.

i=1 gi(xi) is separable.

Network topology. We consider the task of joint training of a global machine learning model in a
decentralized network of K nodes. Its connectivity is modelled by a mixing matrix W ∈ RK×K
.
More precisely, Wij ∈ [0, 1] denotes the connection strength between nodes i and j, with a non-zero
weight indicating the existence of a pairwise communication link. We assume W to be symmetric
and doubly stochastic, which means each row and column of W sums to one.

+

The spectral properties of W used in this paper are that the eigenvalues of W are real, and 1 =
λ1(W) ≥ · · · ≥ λn(W) ≥ −1. Let the second largest magnitude of the eigenvalues of W be
β := max{|λ2(W)|, |λn(W)|}. 1 − β is called the spectral gap, a quantity well-studied in graph
theory and network analysis. The spectral gap measures the level of connectivity among nodes. In
the extreme case when W is diagonal, and thus an identity matrix, the spectral gap is 0 and there is
no communication among nodes. To ensure convergence of decentralized algorithms, we impose

2

the standard assumption of positive spectral gap of the network which includes all connected graphs,
such as e.g. a ring or 2-D grid topology, see also Appendix B for details.

1.2 Related work

Research in decentralized optimization dates back to the 1980s with the seminal work of Bertsekas
and Tsitsiklis, cf. [Tsitsiklis et al., 1986]. Their framework focuses on the minimization of a (smooth)
function by distributing the components of the parameter vector x among agents. In contrast, a
second more recent line of work [Nedic and Ozdaglar, 2009, Duchi et al., 2012, Shi et al., 2015,
Mokhtari and Ribeiro, 2016, Nedic et al., 2017, Scaman et al., 2017, 2018] considers minimization of
a sum of individual local cost-functions F (x) = (cid:80)
i Fi(x), which are potentially non-smooth. Our
work here can be seen as bridging the two scenarios to the primal-dual setting (A) and (B).

While decentralized optimization is a relatively mature area in the operations research and automatic
control communities, it has recently received a surge of attention for machine learning applications,
see e.g. [Cevher et al., 2014]. Decentralized gradient descent (DGD) with diminishing stepsizes
was proposed by [Nedic and Ozdaglar, 2009, Jakovetic et al., 2012], showing convergence to the
optimal solution at a sublinear rate. [Yuan et al., 2016] further prove that DGD will converge to the
neighborhood of a global optimum at a linear rate when used with a constant stepsize for strongly
convex objectives. [Shi et al., 2015] present EXTRA, which offers a signiﬁcant performance boost
compared to DGD by using a gradient tracking technique. [Nedic et al., 2017] propose the DIGing
algorithm to handle a time-varying network topology. For a static and symmetric W, DIGing recovers
EXTRA by redeﬁning the two mixing matrices in EXTRA. The dual averaging method [Duchi
et al., 2012] converges at a sublinear rate with a dynamic stepsize. Under a strong convexity
assumption, decomposition techniques such as decentralized ADMM (DADMM, also known as
consensus ADMM) have linear convergence for time-invariant undirected graphs, if subproblems
are solved exactly [Shi et al., 2014, Wei and Ozdaglar, 2013]. DADMM+ [Bianchi et al., 2016] is a
different primal-dual approach with more efﬁcient closed-form updates in each step (as compared to
ADMM), and is proven to converge but without a rate. Compared to COLA, neither of DADMM
and DADMM+ can be ﬂexibly adapted to the communication-computation tradeoff due to their ﬁxed
update deﬁnition, and both require additional hyperparameters to tune in each use-case (including the
ρ from ADMM). Notably COLA shows superior performance compared to DIGing and decentralized
ADMM in our experiments. [Scaman et al., 2017, 2018] present lower complexity bounds and optimal
algorithms for objectives in the form F (x) = (cid:80)
i Fi(x). Speciﬁcally, [Scaman et al., 2017] assumes
each Fi(x) is smooth and strongly convex, and [Scaman et al., 2018] assumes each Fi(x) is Lipschitz
continuous and convex. Additionally [Scaman et al., 2018] needs a boundedness constraint for the
input problem. In contrast, COLA can handle non-smooth and non-strongly convex objectives (A)
and (B), suited to the mentioned applications in machine learning and signal processing. For smooth
nonconvex models, [Lian et al., 2017] demonstrate that a variant of decentralized parallel SGD can
outperform the centralized variant when the network latency is high. They further extend it to the
asynchronous setting [Lian et al., 2018] and to deal with large data variance among nodes [Tang et al.,
2018a] or with unreliable network links [Tang et al., 2018b]. For the decentralized, asynchronous
consensus optimization, [Wu et al., 2018] extends the existing PG-EXTRA and proves convergence
of the algorithm. [Sirb and Ye, 2018] proves a O(K/(cid:15)2) rate for stale and stochastic gradients. [Lian
et al., 2018] achieves O(1/(cid:15)) rate and has linear speedup with respect to number of workers.

In the distributed setting with a central server, algorithms of the COCOA family [Yang, 2013, Jaggi
et al., 2014, Ma et al., 2015, Dünner et al., 2018]—see [Smith et al., 2018] for a recent overview—
are targeted for problems of the forms (A) and (B). For convex models, COCOA has shown to
signiﬁcantly outperform competing methods including e.g., ADMM, distributed SGD etc. Other
centralized algorithm representatives are parallel SGD variants such as [Agarwal and Duchi, 2011,
Zinkevich et al., 2010] and more recent distributed second-order methods [Zhang and Lin, 2015,
Reddi et al., 2016, Gargiani, 2017, Lee and Chang, 2017, Dünner et al., 2018, Lee et al., 2018].

In this paper we extend COCOA to the challenging decentralized environment—with no central
coordinator—while maintaining all of its nice properties. We are not aware of any existing primal-
dual methods in the decentralized setting, except the recent work of [Smith et al., 2017] on federated
learning for the special case of multi-task learning problems. Federated learning was ﬁrst described
by [Konecn`y et al., 2015, 2016, McMahan et al., 2017] as decentralized learning for on-device
learning applications, combining a global shared model with local personalized models. Current

3

Algorithm 1: COLA: Communication-Efﬁcient Decentralized Linear Learning

1 Input: Data matrix A distributed column-wise according to partition {Pk}K

k=1. Mixing matrix W.

Aggregation parameter γ ∈ [0, 1], and local subproblem parameter σ(cid:48) as in (1). Starting point
x(0) := 0 ∈ Rn, v(0) := 0 ∈ Rd, v(0)
k

:= 0 ∈ Rd ∀ k = 1, . . . K;

2 for t = 0, 1, 2, . . . , T do
3

for k ∈ {1, 2, . . . , K} in parallel over all nodes do
compute locally averaged shared vector v(t+ 1
2 )
l=1 Wklv(t)
∆x[k] ← Θ-approximate solution to subproblem (1) at v(t+ 1
2 )
update local variable x(t+1)
:= x(t)
compute update of local estimate ∆vk := A[k]∆x[k]
v(t+1)
k

[k] + γ ∆x[k]

:= v(t+ 1
2 )

+ γK∆vk

:= (cid:80)K

[k]

k

k

k

l

4

5

6

7

8

end

9
10 end

federated optimization algorithms (like FedAvg in [McMahan et al., 2017]) are still close to the
centralized setting. In contrast, our work provides a fully decentralized alternative algorithm for
federated learning with generalized linear models.

2 The decentralized algorithm: COLA

The COLA framework is summarized in Algorithm 1. For a given input problem we map it to either
of the (A) or (B) formulation, and deﬁne the locally stored dataset A[k] and local part of the weight
vector x[k] in node k accordingly. While v = Ax is the shared state being communicated in COCOA,
this is generally unknown to a node in the fully decentralized setting. Instead, we maintain vk, a local
estimate of v in node k, and use it as a surrogate in the algorithm.

(1)

(2)

New data-local quadratic subproblems. During a computation step, node k locally solves the
following minimization problem

min
∆x[k]∈Rn

G σ(cid:48)

k (∆x[k]; vk, x[k]),

where

G σ(cid:48)
k (∆x[k]; vk, x[k]) := 1

K f (vk) + ∇f (vk)(cid:62)A[k]∆x[k]
+ σ(cid:48)
2τ

i∈Pk

(cid:13)
2
(cid:13)

+ (cid:80)

gi(xi + (∆x[k])i).

(cid:13)
(cid:13)A[k]∆x[k]
Crucially, this subproblem only depends on the local data A[k], and local vectors vl from the
neighborhood of the current node k. In contrast, in COCOA [Smith et al., 2018] the subproblem is
deﬁned in terms of a global aggregated shared vector vc := Ax ∈ Rd, which is not available in the
decentralized setting.3 The aggregation parameter γ ∈ [0, 1] does not need to be tuned; in fact, we
use the default γ := 1 throughout the paper, see [Ma et al., 2015] for a discussion. Once γ is settled,
a safe choice of the subproblem relaxation parameter σ(cid:48) is given as σ(cid:48) := γK. σ(cid:48) can be additionally
tightened using an improved Hessian subproblem (Appendix E.3).
Algorithm description. At time t on node k, v(t+ 1
2 )
is a local estimate of the shared variable after a
communication step (i.e. gossip mixing). The local subproblem (1) based on this estimate is solved

k

3Subproblem interpretation: Note that for the special case of γ := 1, σ(cid:48) := K, by smoothness of f , our

subproblem in (2) is an upper bound on

min∆x[k]∈Rn

1

K f (A(x + K∆x[k])) + (cid:80)

i∈Pk

gi(xi + (∆x[k])i),

(3)

which is a scaled block-coordinate update of block k of the original objective (A). This assumes that we have
consensus vk ≡ Ax ∀ k. For quadratic objectives (i.e. when f ≡ (cid:107).(cid:107)2
2 and A describes the quadratic), the
equality of the formulations (2) and (3) holds. Furthermore, by convexity of f , the sum of (3) is an upper
bound on the centralized updates f (x + ∆x) + g(x + ∆x). Both inequalities quantify the overhead of the
distributed algorithm over the centralized version, see also [Yang, 2013, Ma et al., 2015, Smith et al., 2018] for
the non-decentralized case.

4

and yields ∆x[k]. Then we calculate ∆vk := A[k]∆x[k], and update the local shared vector v(t+1)
We allow the local subproblem to be solved approximately:
Assumption 1 (Θ-approximation solution). Let Θ ∈ [0, 1] be the relative accuracy of the local solver
(potentially randomized), in the sense of returning an approximate solution ∆x[k] at each step t, s.t.

k

.

k (∆x[k]; vk, x[k]) − G σ(cid:48)
E[G σ(cid:48)
k ( 0 ; vk, x[k]) − G σ(cid:48)
G σ(cid:48)

k (∆x(cid:63)
k (∆x(cid:63)

[k]; vk, x[k])]
[k]; vk, x[k])

≤ Θ,

where ∆x(cid:63)

[k] ∈ arg min∆x∈Rn G σ(cid:48)

k (∆x[k]; vk, x[k]), for each k ∈ [K].

Elasticity to network size, compute resources and changing data—and fault tolerance. Real-
world communication networks are not homogeneous and static, but greatly vary in availability,
computation, communication and storage capacity. Also, the training data is subject to changes.
While these issues impose signiﬁcant challenges for most existing distributed training algorithms, we
hereby show that COLA offers adaptivity to such dynamic and heterogenous scenarios.

Scalability and elasticity in terms of availability and computational capacity can be modelled by a
node-speciﬁc local accuracy parameter Θk in Assumption 1, as proposed by [Smith et al., 2017]. The
more resources node k has, the more accurate (smaller) Θk we can use. The same mechanism also
allows dealing with fault tolerance and stragglers, which is crucial e.g. on a network of personal
devices. More speciﬁcally, when a new node k joins the network, its x[k] variables are initialized
to 0; when node k leaves, its x[k] is frozen, and its subproblem is not touched anymore (i.e. Θk = 1).
Using the same approach, we can adapt to dynamic changes in the dataset—such as additions and
removal of local data columns—by adjusting the size of the local weight vector accordingly. Unlike
gradient-based methods and ADMM, COLA does not require parameter tuning to converge, increasing
resilience to drastic changes.

Extension to improved second-order subproblems. In the centralized setting, it has recently been
shown that the Hessian information of f can be properly utilized to deﬁne improved local subproblems
[Lee and Chang, 2017, Dünner et al., 2018]. Similar techniques can be applied to COLA as well,
details on which are left in Appendix E.

Extension to time-varying graphs. Similar to scalability and elasticity, it is also straightforward to
extend COLA to a time varying graph under proper assumptions. If we use the time-varying model
in [Nedic et al., 2017, Assumption 1], where an undirected graph is connected with B gossip steps,
then changing COLA to perform B communication steps and one computation step per round still
guarantees convergence. Details of this setup are provided in Appendix E.

3 On the convergence of COLA

In this section we present a convergence analysis of the proposed decentralized algorithm COLA for
both general convex and strongly convex objectives. In order to capture the evolution of COLA, we
reformulate the original problem (A) by incorporating both x and local estimates {vk}K

k=1

minx,{vk}K
such that

k=1

HA(x, {vk}K
vk = Ax, k = 1, ..., K.

k=1) := 1
K

(cid:80)K

k=1 f (vk) + g(x),

(DA)

While the consensus is not always satisﬁed during Algorithm 1, the following relations between the
decentralized objective and the original one (A) always hold. All proofs are deferred to Appendix C.
Lemma 1. Let {vk} and x be the iterates generated during the execution of Algorithm 1. At any
timestep, it holds that

(cid:80)K

1
k=1 vk = Ax,
K
FA(x) ≤ HA(x, {vk}K

k=1) ≤ FA(x) + 1
2τ K

(cid:80)K

k=1 (cid:107)vk − Ax(cid:107)2 .

(4)

(5)

The dual problem and duality gap of the decentralized objective (DA) are given in Lemma 2.
Lemma 2 (Decentralized Dual Function and Duality Gap). The Lagrangian dual of the decentralized
formation (DA) is

min{wk}K

k=1

HB({wk}K

k=1) := 1
K

(cid:80)K

k=1 f ∗(wk) + (cid:80)n

i=1 g∗
i

−A(cid:62)

i ( 1
K

(cid:80)K

k=1 wk)

(cid:16)

(cid:17)

.

(DB)

5

Given primal variables {x, {vk}K
k=1) := 1
K

GH(x, {vk}K

k=1, {wk}K

k=1} and dual variables {wk}K

k=1, the duality gap is:

(cid:80)

k(f (vk)+f ∗(wk)) + g(x)+(cid:80)n

i=1 g∗
i

(cid:0)− 1

K

(cid:80)

k A(cid:62)

i wk

(cid:1) . (6)

If the dual variables are ﬁxed to the optimality condition wk = ∇f (vk), then the dual variables can
be omitted in the argument list of duality gap, namely GH(x, {vk}K
k=1). Note that the decentralized
duality gap generalizes the duality gap of COCOA: when consensus is ensured, i.e., vk ≡ Ax and
wk ≡ ∇f (Ax), the decentralized duality gap recovers that of COCOA.

3.1 Linear rate for strongly convex objectives

We use the following data-dependent quantities in our main theorems

σk := maxx[k]∈Rn

(cid:13)
(cid:13)A[k]x[k]

(cid:13)
2
(cid:13)

/(cid:107)x[k](cid:107)2, σmax = maxk=1,...,K σk, σ := (cid:80)K

k=1 σknk.

(7)

If {gi} are strongly convex, COLA achieves the following linear rate of convergence.
Theorem 1 (Strongly Convex gi). Consider Algorithm 1 with γ := 1 and let Θ be the quality of the
local solver in Assumption 1. Let gi be µg-strongly convex for all i ∈ [n] and let f be 1/τ -smooth.
Let ¯σ(cid:48) := (1 + β)σ(cid:48), α := (1 + (1−β)2

36(1+Θ)β )−1 and η := γ(1 − Θ)(1 − α)

s0 =

τ µg+σmax ¯σ(cid:48) ∈ [0, 1].

τ µg

(8)

Then after T iterations of Algorithm 1 with4

it holds that E(cid:2)HA(x(T ), {v(T )
with

k }K

k=1)(cid:3) ≤ εH. Furthermore, after T iterations

T ≥ 1+ηs0
ηs0

log ε(0)
H
εH

,

k=1) − HA(x(cid:63), {v(cid:63)
k}K
(cid:18)

T ≥ 1+ηs0
ηs0

log

(cid:19)

1
ηs0

ε(0)
H
εGH

,

we have the expected duality gap E[GH(x(T ), {(cid:80)K

k=1 Wklv(T )

l

}K
k=1)] ≤ εGH.

3.2 Sublinear rate for general convex objectives

Models such as sparse logistic regression, Lasso, group Lasso are non-strongly convex. For such
models, we show that COLA enjoys a O(1/T ) sublinear rate of convergence for all network topologies
with a positive spectral gap.
Theorem 2 (Non-strongly Convex Case). Consider Algorithm 1, using a local solver of quality Θ.
Let gi(·) have L-bounded support, and let f be (1/τ )-smooth. Let εGH > 0 be the desired duality
gap. Then after T iterations where
(cid:26) (cid:108) 1

(cid:17) (cid:21)

(cid:27)

(cid:109)

(cid:20)

T ≥ T0 + max

(cid:26)

(cid:24)

t0 ≥ max

0,

,

η

, 4L2σ¯σ(cid:48)
τ εGH η
η log 2τ (HA(x(0),{v(0)

1+η

T0 ≥ t0 +

l })−HA(x(cid:63),{v(cid:63)}))
4L2σ ¯σ(cid:48)

2
η

(cid:16) 8L2σ ¯σ(cid:48)
τ εGH
(cid:25)(cid:27)

− 1

+

and ¯σ(cid:48) := (1 + β)σ(cid:48), α := (1 + (1−β)2
duality gap satisﬁes

36(1+Θ)β )−1 and η := γ(1 − Θ)(1 − α). We have that the expected

E(cid:2)GH(¯x, {¯vk}K
(cid:80)T −1

k=1, { ¯wk}K

k=1)(cid:3) ≤ εGH

at the averaged iterate ¯x :=

1
T −T0
k)(t) and ¯wk := 1

T −T0

t=T0+1 x(t), and v(cid:48)
k
t=T0+1 ∇f ((v(cid:48)
k)(t)).

(cid:80)T −1

1
T −T0

(cid:80)T −1

t=T0+1(v(cid:48)

:= (cid:80)K

l=1 Wklvl and ¯vk

:=

Note that the assumption of bounded support for the gi functions is not restrictive in the general
convex case, as discussed e.g. in [Dünner et al., 2016].

4ε(0)

H := HA(x(0), {v(0)

k }K

k=1) − HA(x(cid:63), {v(cid:63)

k}K

k=1) is the initial suboptimality.

6

3.3 Local certiﬁcates for global accuracy

Accuracy certiﬁcates for the training error are very useful for practitioners to diagnose the learning
progress. In the centralized setting, the duality gap serves as such a certiﬁcate, and is available as
a stopping criterion on the master node. In the decentralized setting of our interest, this is more
challenging as consensus is not guaranteed. Nevertheless, we show in the following Proposition 1
that certiﬁcates for the decentralized objective (DA) can be computed from local quantities:
Proposition 1 (Local Certiﬁcates). Assume gi has L-bounded support, and let Nk := {j : Wjk > 0}
be the set of nodes accessible to node k. Then for any given ε > 0, we have

GH(x; {vk}K

k=1) ≤ ε,

if for all k = 1, . . . , K the following two local conditions are satisﬁed:
(cid:0)gi(xi) + g∗

i ∇f (vk))(cid:1) ≤

k ∇f (vk) +

i (−A(cid:62)

v(cid:62)

(cid:88)

ε
2K

i∈Pk

(cid:13)
(cid:13)∇f (vk) − 1
(cid:13)

|Nk|

(cid:80)

∇f (vj)

≤

j∈Nk

(cid:13)
(cid:13)
(cid:13)2

(cid:16)(cid:80)K

k=1 n2

kσk

(cid:17)−1/2

1−β
√

2L

K

ε,

The local conditions (9) and (10) have a clear interpretation. The ﬁrst one ensures the duality gap of
the local subproblem given by vk as on the left hand side of (9) is small. The second condition (10)
guarantees that consensus violation is bounded, by ensuring that the gradient of each node is similar
to its neighborhood nodes.
Remark 1. The resulting certiﬁcate from Proposition 1 is local, in the sense that no global vector
aggregations are needed to compute it. For a certiﬁcate on the global objective, the boolean ﬂag
of each local condition (9) and (10) being satisﬁed or not needs to be shared with all nodes, but
this requires extremely little communication. Exact values of the parameters β and (cid:80)K
kσk are
not required to be known, and any valid upper bound can be used instead. We can use the local
certiﬁcates to avoid unnecessary work on local problems which are already optimized, as well as
to continuously quantify how newly arriving local data has to be re-optimized in the case of online
training. The local certiﬁcates can also be used to quantify the contribution of newly joining or
departing nodes, which is particularly useful in the elastic scenario described above.

k=1 n2

(9)

(10)

4 Experimental results

Here we illustrate the advantages of COLA in three respects: ﬁrstly we investigate the application in
different network topologies and with varying subproblem quality Θ; secondly, we compare COLA
with state-of-the-art decentralized baselines: 1(cid:13), DIGing [Nedic et al., 2017], which generalizes the
gradient-tracking technique of the EXTRA algorithm [Shi et al., 2015], and 2(cid:13), Decentralized ADMM
(aka. consensus ADMM), which extends the classical ADMM (Alternating Direction Method of

Figure 1: Suboptimality for solving Lasso (λ=10−6) for the RCV1 dataset on a ring of 16 nodes. We
illustrate the performance of COLA: a) number of iterations; b) time. κ here denotes the number of
local data passes per communication round.

7

Figure 2: Convergence of COLA for solving problems on a ring of K=16 nodes. Left) Ridge
regression on URL reputation dataset (λ=10−4); Right) Lasso on webspam dataset (λ=10−5).

Multipliers) method [Boyd et al., 2011] to the decentralized setting [Shi et al., 2014, Wei and Ozdaglar,
2013]; Finally, we show that COLA works in the challenging unreliable network environment where
each node has a certain chance to drop out of the network.

We implement all algorithms in PyTorch with MPI backend. The decentralized network topology is
simulated by running one thread per graph node, on a 2×12 core Intel Xeon CPU E5-2680 v3 server
with 256 GB RAM. Table 1 describes the datasets5 used in the experiments. For Lasso, the columns
of A are features. For ridge regression, the columns are features and samples for COLA primal and
COLA dual, respectively. The order of columns is shufﬂed once before being distributed across the
nodes. Due to space limit, details on the experimental conﬁgurations are included in Appendix D.

Table 1: Datasets Used for Empirical Study

Effect of approximation quality Θ. We
study the convergence behavior in terms of
the approximation quality Θ. Here, Θ is
controlled by the number of data passes κ
on subproblem (1) per node. Figure 1
shows that increasing κ always results in
less number of iterations (less communica-
tion rounds) for COLA. However, given a
ﬁxed network bandwidth, it leads to a clear
trade-off for the overall wall-clock time, showing the cost of both communication and computation.
Larger κ leads to less communication rounds, however, it also takes more time to solve subproblems.
The observations suggest that one can adjust Θ for each node to handle system heterogeneity, as what
we have discussed at the end of Section 2.

#Training #Features Sparsity
3.5e-5
2.0e-4
1.0
1.6e-3

Dataset
URL
Webspam
Epsilon
RCV1 Binary

2M
350K
400K
677K

3M
16M
2K
47K

Effect of graph topology. Fixing K=16, we test the performance of COLA on 5 different topologies:
ring, 2-connected cycle, 3-connected cycle, 2D grid and complete graph. The mixing matrix W
is given by Metropolis weights for all test cases (details in Appendix B). Convergence curves are
plotted in Figure 3. One can observe that for all topologies, COLA converges monotonically and
especailly when all nodes in the network are equal, smaller β leads to a faster convergence rate. This
is consistent with the intuition that 1 − β measures the connectivity level of the topology.

Superior performance compared to baselines. We compare COLA with DIGing and D-ADMM
for strongly and general convex problems. For general convex objectives, we use Lasso regression
with λ = 10−4 on the webspam dataset; for the strongly convex objective, we use Ridge regression
with λ = 10−5 on the URL reputation dataset. For Ridge regression, we can map COLA to both
primal and dual problems. Figure 2 traces the results on log-suboptimality. One can observe that
for both generally and strongly convex objectives, COLA signiﬁcantly outperforms DIGing and
decentralized ADMM in terms of number of communication rounds and computation time. While
DIGing and D-ADMM need parameter tuning to ensure convergence and efﬁciency, COLA is much
easier to deploy as it is parameter free. Additionally, convergence guarantees of ADMM relies on
exact subproblem solvers, whereas inexact solver is allowed for COLA.

5https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/

8

Figure 3: Performance comparison of COLA on
different topologies. Solving Lasso regression
(λ=10−6) for RCV1 dataset with 16 nodes.

Figure 4: Performance of COLA when nodes have
p chance of staying in the network on the URL
dataset (λ=10−4). Freezing x[k] when node k
leaves the network.

Fault tolerance to unreliable nodes. Assume each node of a network only has a chance of p to
participate in each round. If a new node k joins the network, then local variables are initialized as
x[k] = 0; if node k leaves the network, then x[k] will be frozen with Θk = 1. All remaining nodes
dynamically adjust their weights to maintain the doubly stochastic property of W. We run COLA on
such unreliable networks of different ps and show the results in Figure 4. First, one can observe that
for all p > 0 the suboptimality decreases monotonically as COLA progresses. It is also clear from the
result that a smaller dropout rate (a larger p) leads to a faster convergence of COLA.

5 Discussion and conclusions

In this work we have studied training generalized linear models in the fully decentralized setting.
We proposed a communication-efﬁcient decentralized framework, termed COLA, which is free of
parameter tuning. We proved that it has a sublinear rate of convergence for general convex problems,
allowing e.g. L1 regularizers, and has a linear rate of convergence for strongly convex objectives. Our
scheme offers primal-dual certiﬁcates which are useful in the decentralized setting. We demonstrated
that COLA offers full adaptivity to heterogenous distributed systems on arbitrary network topologies,
and is adaptive to changes in network size and data, and offers fault tolerance and elasticity. Future
research directions include improving subproblems, as well as extension to the network topology
with directed graphs, as well as recent communication compression schemes [Stich et al., 2018].

Acknowledgments. We thank Prof. Bharat K. Bhargava for fruitful discussions. We acknowledge
funding from SNSF grant 200021_175796, Microsoft Research JRC project ‘Coltrain’, as well as a
Google Focused Research Award.

References

John N Tsitsiklis, Dimitri P Bertsekas, and Michael Athans. Distributed asynchronous deterministic and
stochastic gradient optimization algorithms. IEEE Transactions on Automatic Control, 31(9):803–812, 1986.

Angelia Nedic and Asuman Ozdaglar. Distributed subgradient methods for multi-agent optimization. IEEE

Transactions on Automatic Control, 54(1):48–61, 2009.

J C Duchi, A Agarwal, and M J Wainwright. Dual Averaging for Distributed Optimization: Convergence
Analysis and Network Scaling. IEEE Transactions on Automatic Control, 57(3):592–606, March 2012.

Wei Shi, Qing Ling, Gang Wu, and Wotao Yin. Extra: An exact ﬁrst-order algorithm for decentralized consensus

optimization. SIAM Journal on Optimization, 25(2):944–966, 2015.

Aryan Mokhtari and Alejandro Ribeiro. DSA: Decentralized double stochastic averaging gradient algorithm.

Journal of Machine Learning Research, 17(61):1–35, 2016.

9

Angelia Nedic, Alex Olshevsky, and Wei Shi. Achieving geometric convergence for distributed optimization

over time-varying graphs. SIAM Journal on Optimization, 27(4):2597–2633, 2017.

Volkan Cevher, Stephen Becker, and Mark Schmidt. Convex Optimization for Big Data: Scalable, randomized,

and parallel algorithms for big data analytics. IEEE Signal Processing Magazine, 31(5):32–43, 2014.

Virginia Smith, Simone Forte, Chenxin Ma, Martin Takác, Michael I Jordan, and Martin Jaggi. CoCoA: A
General Framework for Communication-Efﬁcient Distributed Optimization. Journal of Machine Learning
Research, 18(230):1–49, 2018.

Sixin Zhang, Anna E Choromanska, and Yann LeCun. Deep learning with Elastic Averaging SGD. In NIPS

2015 - Advances in Neural Information Processing Systems 28, pages 685–693, 2015.

Jialei Wang, Weiran Wang, and Nathan Srebro. Memory and Communication Efﬁcient Distributed Stochastic
Optimization with Minibatch Prox. In ICML 2017 - Proceedings of the 34th International Conference on
Machine Learning, pages 1882–1919, June 2017.

Celestine Dünner, Simone Forte, Martin Takác, and Martin Jaggi. Primal-Dual Rates and Certiﬁcates. In ICML

2016 - Proceedings of the 33th International Conference on Machine Learning, pages 783–792, 2016.

Martin Jaggi, Virginia Smith, Martin Takác, Jonathan Terhorst, Sanjay Krishnan, Thomas Hofmann, and
In Advances in Neural

Michael I Jordan. Communication-efﬁcient distributed dual coordinate ascent.
Information Processing Systems, pages 3068–3076, 2014.

Kevin Scaman, Francis R. Bach, Sébastien Bubeck, Yin Tat Lee, and Laurent Massoulié. Optimal algorithms for
smooth and strongly convex distributed optimization in networks. In Proceedings of the 34th International
Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017, pages 3027–3036,
2017.

Kevin Scaman, Francis Bach, Sébastien Bubeck, Yin Tat Lee, and Laurent Massoulié. Optimal algorithms for

non-smooth distributed optimization in networks. arXiv preprint arXiv:1806.00291, 2018.

Dusan Jakovetic, Joao Xavier, and Jose MF Moura. Convergence rate analysis of distributed gradient methods
for smooth optimization. In Telecommunications Forum (TELFOR), 2012 20th, pages 867–870. IEEE, 2012.

Kun Yuan, Qing Ling, and Wotao Yin. On the convergence of decentralized gradient descent. SIAM Journal on

Optimization, 26(3):1835–1854, 2016.

Wei Shi, Qing Ling, Kun Yuan, Gang Wu, and Wotao Yin. On the Linear Convergence of the ADMM in
Decentralized Consensus Optimization. IEEE Transactions on Signal Processing, 62(7):1750–1761, 2014.

Ermin Wei and Asuman Ozdaglar. On the O(1/k) Convergence of Asynchronous Distributed Alternating

Direction Method of Multipliers. arXiv, July 2013.

Pascal Bianchi, Walid Hachem, and Franck Iutzeler. A coordinate descent primal-dual algorithm and application
to distributed asynchronous optimization. IEEE Transactions on Automatic Control, 61(10):2947–2957, 2016.

Xiangru Lian, Ce Zhang, Huan Zhang, Cho-Jui Hsieh, Wei Zhang, and Ji Liu. Can decentralized algorithms
outperform centralized algorithms? a case study for decentralized parallel stochastic gradient descent. In
Advances in Neural Information Processing Systems, pages 5336–5346, 2017.

Xiangru Lian, Wei Zhang, Ce Zhang, and Ji Liu. Asynchronous decentralized parallel stochastic gradient descent.

In ICML 2018 - Proceedings of the 35th International Conference on Machine Learning, 2018.

Hanlin Tang, Xiangru Lian, Ming Yan, Ce Zhang, and Ji Liu. D2: Decentralized training over decentralized data.

arXiv preprint arXiv:1803.07068, 2018a.

Hanlin Tang, Shaoduo Gan, Ce Zhang, Tong Zhang, and Ji Liu. Communication compression for decentralized

training. In NIPS 2018 - Advances in Neural Information Processing Systems, 2018b.

Tianyu Wu, Kun Yuan, Qing Ling, Wotao Yin, and Ali H Sayed. Decentralized consensus optimization with
asynchrony and delays. IEEE Transactions on Signal and Information Processing over Networks, 4(2):
293–307, 2018.

Benjamin Sirb and Xiaojing Ye. Decentralized consensus algorithm with delayed and stochastic gradients. SIAM

Journal on Optimization, 28(2):1232–1254, 2018.

Tianbao Yang. Trading Computation for Communication: Distributed Stochastic Dual Coordinate Ascent. In

NIPS 2014 - Advances in Neural Information Processing Systems 27, 2013.

10

Chenxin Ma, Virginia Smith, Martin Jaggi, Michael I Jordan, Peter Richtárik, and Martin Takác. Adding vs.
Averaging in Distributed Primal-Dual Optimization. In ICML 2015 - Proceedings of the 32th International
Conference on Machine Learning, pages 1973–1982, 2015.

Celestine Dünner, Aurelien Lucchi, Matilde Gargiani, An Bian, Thomas Hofmann, and Martin Jaggi. A
Distributed Second-Order Algorithm You Can Trust. In ICML 2018 - Proceedings of the 35th International
Conference on Machine Learning, pages 1357–1365, July 2018.

Alekh Agarwal and John C Duchi. Distributed delayed stochastic optimization.

In Advances in Neural

Information Processing Systems, pages 873–881, 2011.

Martin Zinkevich, Markus Weimer, Lihong Li, and Alex J Smola. Parallelized stochastic gradient descent. In

Advances in Neural Information Processing Systems, pages 2595–2603, 2010.

Yuchen Zhang and Xiao Lin. Disco: Distributed optimization for self-concordant empirical loss. In International

conference on machine learning, pages 362–370, 2015.

Sashank J Reddi, Jakub Konecn`y, Peter Richtárik, Barnabás Póczós, and Alex Smola. Aide: Fast and communi-

cation efﬁcient distributed optimization. arXiv preprint arXiv:1608.06879, 2016.

Matilde Gargiani. Hessian-CoCoA: a general parallel and distributed framework for non-strongly convex

regularizers. Master’s thesis, ETH Zurich, June 2017.

Ching-pei Lee and Kai-Wei Chang. Distributed block-diagonal approximation methods for regularized empirical

risk minimization. arXiv preprint arXiv:1709.03043, 2017.

Ching-pei Lee, Cong Han Lim, and Stephen J Wright. A distributed quasi-newton algorithm for empirical risk
minimization with nonsmooth regularization. In ACM International Conference on Knowledge Discovery
and Data Mining, 2018.

Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet Talwalkar. Federated Multi-Task Learning. In

NIPS 2017 - Advances in Neural Information Processing Systems 30, 2017.

Jakub Konecn`y, Brendan McMahan, and Daniel Ramage. Federated optimization: Distributed optimization

beyond the datacenter. arXiv preprint arXiv:1511.03575, 2015.

Jakub Konecn`y, H Brendan McMahan, Felix X Yu, Peter Richtarik, Ananda Theertha Suresh, and Dave Bacon.
Federated learning: Strategies for improving communication efﬁciency. arXiv preprint arXiv:1610.05492,
2016.

Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-
efﬁcient learning of deep networks from decentralized data. In Artiﬁcial Intelligence and Statistics, pages
1273–1282, 2017.

Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, Jonathan Eckstein, et al. Distributed optimization and
statistical learning via the alternating direction method of multipliers. Foundations and Trends R(cid:13) in Machine
learning, 3(1):1–122, 2011.

Sebastian U. Stich, Jean-Baptiste Cordonnier, and Martin Jaggi. Sparsiﬁed sgd with memory. In NIPS 2018 -

Advances in Neural Information Processing Systems, 2018.

Ralph Tyrell Rockafellar. Convex analysis. Princeton university press, 2015.

W Keith Hastings. Monte carlo sampling methods using markov chains and their applications. Biometrika, 57

(1):97–109, 1970.

Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin,
Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. In NIPS Workshop on
Autodiff, 2017.

F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss,
V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn:
Machine learning in Python. Journal of Machine Learning Research, 12:2825–2830, 2011.

11

Appendix

A Deﬁnitions

Deﬁnition 1 (L-Lipschitz continuity). A function h : Rn → R is L-Lipschitz continuous if ∀ u, v ∈
Rn, it holds that

|h(u) − h(v)| ≤ L(cid:107)u − v(cid:107).
Deﬁnition 2 (1/τ -Smoothness). A differentiable function f : Rn → R is 1/τ -smooth if its gradient
is 1/τ -Lipschitz continuous, or equivalently, ∀ u, v it holds

2τ (cid:107)u − v(cid:107)2.

f (u) ≤ f (v) + (cid:104)∇f (v), u − v(cid:105) + 1

(11)
Deﬁnition 3 (L-Bounded support). The function g : Rn → R ∪ {+∞} has L-bounded support if it
holds g(u) < +∞ ⇒ (cid:107)u(cid:107) ≤ L.
Deﬁnition 4 (µ-Strong convexity). A function h : Rn → R is µ-strongly convex for µ ≥ 0 if ∀ u, v, it
holds h(u) ≥ h(v) + (cid:104)s, u − v(cid:105) + µ
2 (cid:107)u − v(cid:107)2, for any s ∈ ∂h(v), where ∂h(v) is the subdifferential
of h at v.
Lemma 3 (Duality between Lipschitzness and L-Bounded Support). A generalization of [Rockafellar,
2015, Corollary 13.3.3]. Given a proper convex function g it holds that g has L-bounded support
w.r.t. the norm (cid:107).(cid:107) if and only if g∗ is L-Lipschitz w.r.t. the dual norm (cid:107).(cid:107)∗.

B Graph topology

Let E be the set of edges of a graph. For time-invariant undirected graph the mixing matrix should
satisfy the following properties:

1. (Double stochasticity) W1 = 1, 1(cid:62)W = 1(cid:62);
2. (Symmetrization) For all i, j, Wij = Wji;
3. (Edge utilization) If (i, j) ∈ E, then Wij > 0; otherwise Wij = 0.

A desired mixing matrix can be constructed using Metropolis-Hastings weights [Hastings, 1970]:

Wij =






1/(1 + max{di, dj}),
0,
1 − (cid:80)

Wil,

l∈Ni

if (i, j) ∈ E
if (i, j) (cid:54)∈ E and j (cid:54)= i
if j = i,

where di = |Ni| is the degree of node i.

C Proofs

This section consists of three parts. Tools and observations are provided in Appendix C.1; The
main lemmas for the convergence analysis are proved in Appendix C.2 ; The main theorems and
implications are proved in Appendix C.3.

In some circumstances, it is convenient to use notations of array of stack column vectors. For
example, one can stack local estimates vk to matrix V := [v1; · · · ; vK], ∆V = [∆v1; · · · ; ∆vK].
The consensus vector vc is repeated K times which will be stacked similarly: Vc := Ax1(cid:62)
K = VE
where E = 1

K. The consensus violation under the two notations is written as

K 1K1(cid:62)

Then Step 8 in COLA is equivalent to

(cid:107)V − Vc(cid:107)2

F = (cid:80)K

k=1 (cid:107)vk − Ax(cid:107)2
2 .

V(t+1) = V(t)W + γK∆V(t)

(12)

Besides, we also adopt following notations in the proof when there is no ambiguity: v(cid:48)
(cid:80)K

k :=
k=1 gk. For the decentralized duality

l=1 Wklvl, gk := ∇f (vk), g(cid:48)

k) and ¯g := 1
K

k := ∇f (v(cid:48)

(cid:80)K

12

k=1, {wk}K
k=1) in the sequel.

k=1), when wk = ∇f (vk), we simplify GH(x, {vk}K

gap GH(x, {vk}K
be GH(x, {vk}K
On a high level, we prove the convergence rates by bounding per-iteration reduction E[H(t)
A − H(t+1)
]
using decentralized duality gap and other related terms, then try to obtain the ﬁnal rates by properly
using speciﬁc properties of the objectives.

k=1, {wk}K

k=1) to

A

However, the speciﬁc analysis of the new fully decentralized algorithm COLA poses many new
challenges, and we propose signiﬁcantly new proof techniques in the analysis. Speciﬁcally, i) we
introduce the decentralized duality gap, which is suited for the decentralized algorithm COLA; ii)
consensus violation is the usually challenging part in analyzing decentralized algorithms. Unlike
using uniform bounds for consensus violations, e.g., [Yuan et al., 2016], we properly combine the
consensus violation term and the objective decrease term (c.f. Lemmas 6 and 8), thus reaching
arguably tight convergence bounds for both the consensus violation term and the objective.

C.1 Observations and properties

In this subsection we introduce basic lemmas. Lemma 1 establishes the relation between {vk}K
and vc and bounds FA(x) using HA(x) and the consensus violation.
Lemma 1. Let {vk} and x be the iterates generated during the execution of Algorithm 1. At any
timestep, it holds that

k=1

(cid:80)K

1
k=1 vk = Ax,
K
FA(x) ≤ HA(x, {vk}K

k=1) ≤ FA(x) + 1
2τ K

(cid:80)K

k=1 (cid:107)vk − Ax(cid:107)2 .

(4)

(5)

Proof of Lemma 1. Let (cid:101)v := 1

K

(cid:80)K

k=1 vk. Using the doubly stochastic property of the matrix W

(cid:101)v(t+1) =

v(t+1)
k

=

K
(cid:88)

(cid:32) K
(cid:88)

k=1

l=1

Wklv(t)

l + γK∆v(t)

k

(cid:33)

1
K

1
K

K
(cid:88)

k=1

K
(cid:88)

l=1

1
K

K
(cid:88)

k=1

=

v(t)
l + γ

∆v(t)

k = (cid:101)v(t) + γ

∆v(t)
k

K
(cid:88)

k=1

On the other hand, v(t)
c

:= Ax(t) is updated based on all changes of local variables {x[k]}K

k=1

v(t+1)
c

= v(t)

c + γ

∆v(t)
k .

K
(cid:88)

k=1

Since (cid:101)v(0) = v(0)

c

, we can conclude that (cid:101)v(t) = v(t)
c ∀ t. From convexity of f we know
(cid:33)

(cid:32)

FA(x) = f (vc) + g(x) = f

vk

+ g(x) ≤

f (vk) + g(x) = H(x)

1
K

K
(cid:88)

k=1

1
K

K
(cid:88)

k=1

f (vc) + ∇f (vc)(cid:62)(vk − vc) +

(cid:107)vk − vc(cid:107)2

+ g(x)

1
2τ

(cid:19)

Using 1/τ -smoothness of f gives

HA(x) =

f (vk) + g(x)

1
K

1
K

K
(cid:88)

k=1

K
(cid:88)

k=1

≤

(cid:18)

=FA(x) +

1
2τ K

K
(cid:88)

k=1

(cid:107)vk − vc(cid:107)2 .

13

The following lemma introduces the dual problem and the duality gap of (DA).

Lemma 2 (Decentralized Dual Function and Duality Gap). The Lagrangian dual of the decentralized
formation (DA) is

min{wk}K

k=1

HB({wk}K

k=1) := 1
K

(cid:80)K

k=1 f ∗(wk) + (cid:80)n

i=1 g∗
i

−A(cid:62)

i ( 1
K

(cid:80)K

k=1 wk)

(cid:16)

(cid:17)

.

(DB)

Given primal variables {x, {vk}K

k=1} and dual variables {wk}K

k=1, the duality gap is:

GH(x, {vk}K

k=1, {wk}K

k=1) := 1
K

(cid:80)

k(f (vk)+f ∗(wk)) + g(x)+(cid:80)n

i=1 g∗
i

(cid:0)− 1

K

(cid:80)

k A(cid:62)

i wk

(cid:1) . (6)

Proof. Let λk be the Lagrangian multiplier for the constraint vk = Ax, the Lagrangian function is

L(x, {vk}K

k=1, {λk}K

k=1) =

f (vk) +

gi(xi) +

(cid:104)λk, Ax − vk(cid:105)

1
K

K
(cid:88)

k=1

n
(cid:88)

i=1

K
(cid:88)

k=1

The dual problem of (DA) follows by taking the inﬁmum with respect to both x and {vk}K

k=1:

inf
x,{vk}K

k=1

L(x, {vk}K

k=1, {λk}K

k=1)

f (vk) +

gi(xi) +

(cid:104)λk, Ax − vk(cid:105)

n
(cid:88)

i=1

f (vk) − (cid:104)λk, vk(cid:105)) + inf
x

gi(xi) +

(cid:104)λk, Ax(cid:105))

K
(cid:88)

k=1

K
(cid:88)

k=1

n
(cid:88)
(

i=1

sup
{vk}K

k=1

((cid:104)λk, vk(cid:105) −

1
K

f (vk)) − sup
x

(−

K
(cid:88)

k=1

(cid:104)ak, Ax(cid:105) −

gi(xi))

n
(cid:88)

i=1

= inf

x,{vk}K

k=1

1
K

K
(cid:88)

k=1

=

K
(cid:88)

k=1

inf
{vk}K

k=1

(

1
K

= −

= −

K
(cid:88)

k=1

K
(cid:88)

k=1

1
K

f ∗(Kλk) −

g∗
i (−

A(cid:62)

i λk)

n
(cid:88)

i=1

K
(cid:88)

k=1

Let us change variables from λk to wk by setting wk := Kλk. If written in terms of minimization,
the Lagrangian dual of HA is

min{wk}K

k=1

HB{wk}K

k=1 = 1
K

(cid:80)K

k=1 f ∗(wk) + (cid:80)n

i=1 g∗
i

− 1
K

(cid:80)K

k=1 A(cid:62)

i wk

(cid:16)

(cid:17)

(13)

The optimality condition is that wk = ∇f (vk). Now we can see the duality gap is

GH =HA + HB

=

1
K

K
(cid:88)

k=1

n
(cid:88)

i=1

1
K

K
(cid:88)

k=1

f (vk) +

gi(xi) +

f ∗(wk) +

n
(cid:88)

i=1

g∗
i

(cid:32)

−

1
K

K
(cid:88)

k=1

(cid:33)

A(cid:62)

i wk

The following lemma correlates the consensus violation with the magnitude of the v parameter
updates (cid:107)∆vk(cid:107)2
2.
Lemma 4. The consensus violation during the execution of Algorithm 1 can be bound by

K
(cid:88)

k=1

(cid:13)
(cid:13)v(t+1)
(cid:13)

k

− Ax(t+1)(cid:13)
2
(cid:13)
(cid:13)
2

≤ β

(cid:13)
(cid:13)v(t)
(cid:13)

k − Ax(t)(cid:13)
2
(cid:13)
(cid:13)
2

K
(cid:88)

k=1

+ (1 − β)c1(β, γ, K)

K
(cid:88)

k=1

(cid:13)
(cid:13)∆v(t)
(cid:13)

k

(cid:13)
2
(cid:13)
(cid:13)
2

(14)

where c1(β, γ, K) := γ2K 2/(1 − β)2.

Proof. Consider the norm of consensus violation at time t + 1 and apply Algo. Step 8

(cid:13)
(cid:13)V(t+1) − V(t+1)
(cid:13)

c

(cid:13)
2
(cid:13)
(cid:13)

F

=

(cid:13)
(cid:13)V(t+1)(I − E)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

F

=

(cid:13)
(cid:13)
2
(cid:13)(V(t)W + γK∆V(t))(I − E)
(cid:13)
(cid:13)
(cid:13)

.

F

14

Further, use W(I − E) = (I − E)(W − E), (cid:107)I − E(cid:107)∞ = 1, and Young’s inequality with εv
(cid:13)∆V(t)(cid:13)

(cid:13)
(cid:13)
2
(cid:13)V(t)(I − E)(W − E)
(cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:13)V(t+1) − V(t+1)
(cid:13)

)γ2K 2 (cid:13)
(cid:13)

≤ (1 + εv)

+ (1 +

(cid:13)
2
(cid:13)
(cid:13)

2
(cid:13)
(cid:13)

c

F

.

F

1
εv

F
Use the spectral property of W we therefore have:
(cid:13)
2
(cid:13)
(cid:13)
Recursively apply (15) for i = 0, . . . , t − 1 gives

(cid:13)
(cid:13)V(t+1) − V(t+1)
(cid:13)

≤ (1 + εv)β2 (cid:13)
(cid:13)V(t) − V(t)
(cid:13)

F

c

c

(cid:13)
2
(cid:13)
(cid:13)

F

+ (1 +

1
εv

)γ2K 2 (cid:13)
(cid:13)

(cid:13)∆V(t)(cid:13)

2
(cid:13)
(cid:13)

.

F

(cid:13)
(cid:13)V(t) − V(t)
(cid:13)

c

(cid:13)
2
(cid:13)
(cid:13)

F

≤ (1 +

)γ2K 2

1
εv

((1 + εv)β2)t−1−i (cid:13)
(cid:13)

(cid:13)∆V(i)(cid:13)

2
(cid:13)
(cid:13)

F

.

t−1
(cid:88)

i=0

Consider (cid:13)
coefﬁcients 1, (1 + εv)β2, ((1 + εv)β2)2, . . .. Sum of such coefﬁcients are ﬁnite

(cid:13)∆V(t)(cid:13)
2
F generated at time t, it will be used in (16) from time t + 1, t + 2, . . . , with
(cid:13)

(1 +

)γ2K 2

1 − (1 + εv)β2 =: c1(β, γ, K)
where we need (1 + εv)β2 < 1. To minimize c1(β, γ, K) we can choose εv = 1/β − 1

((1 + εv)β2)t−T ≤ γ2K 2

t=T

1 + 1/εv

∞
(cid:88)

1
εv

c1(β, γ, K) = γ2K 2/(1 − β)2

Then (15) becomes

K
(cid:88)

k=1

(cid:13)
(cid:13)v(t+1)
(cid:13)

k

− Ax(t+1)(cid:13)
2
(cid:13)
(cid:13)
2

≤ β

(cid:13)
(cid:13)v(t)
(cid:13)

k − Ax(t)(cid:13)
2
(cid:13)
(cid:13)
2

K
(cid:88)

k=1

+ (1 − β)c1(β, γ, K)

K
(cid:88)

k=1

(cid:13)
(cid:13)∆v(t)
(cid:13)

k

(cid:13)
2
(cid:13)
(cid:13)
2

Lemma 5. Let ∆x(cid:63)
The change of iterates satisﬁes the following inequality

[k] and ∆x[k] be the exact and Θ-inexact solution of subproblem G σ(cid:48)

k ( · ; vk, x[k]).

σ(cid:48)
4τ

K
(cid:88)

k=1

(cid:13)
(cid:13)A∆x[k]

(cid:13)
2
2 ≤ (1 + Θ)(HA(0; {vk}) − HA(∆x(cid:63); {vk}))
(cid:13)

(19)

Proof. First use the Taylor expansion of G σ(cid:48)

k ( · ; vk, x[k]) and the defnition of ∆x(cid:63)

(20)
for all ∆z[k] ∈ Rn and k = 1, . . . , K. Apply (20) with ∆z[k] = 0 for all k and sum them up yields

[k]; vk, x[k]

k

k

(cid:13)
(cid:13)A(∆z − ∆x(cid:63))[k]

(cid:13)
2
2 ≤ G σ(cid:48)
(cid:13)

(cid:0)∆z[k]; vk, x[k]

(cid:1) − G σ(cid:48)

(cid:16)

∆x(cid:63)

σ(cid:48)
2τ

[k] we have
(cid:17)

σ(cid:48)
2τ

K
(cid:88)

k=1

(cid:13)
(cid:13)A∆x(cid:63)
(cid:13)

[k]

(cid:13)
2
(cid:13)
(cid:13)
2

≤ HA(0; {vk}) − HA(∆x(cid:63); {vk})

Similarly, apply (20) for ∆z[k] = ∆x[k] for all k and sum them up gives

(cid:13)
(cid:13)A(∆x − ∆x(cid:63))[k]

(cid:13)
2
2 ≤ HA(∆x; {vk}) − HA(∆x(cid:63); {vk})
(cid:13)

By Assumption 1 the previous inequality becomes

(cid:13)
(cid:13)A(∆x − ∆x(cid:63))[k]

(cid:13)
2
2 ≤ Θ(HA(0; {vk}) − HA(∆x(cid:63); {vk}))
(cid:13)

k=1
The following inequality is straightforward
K
(cid:88)

K
(cid:88)

(cid:13)
(cid:13)A∆x[k]

(cid:13)
2
2 ≤
(cid:13)

Multiply (24) with σ(cid:48)/(2τ ) and use (21) and (23)

(cid:13)
(cid:13)A∆x(cid:63)
(cid:13)

[k]

(cid:13)
2
(cid:13)
(cid:13)
2

+

K
(cid:88)

k=1

k=1

(cid:13)
(cid:13)A(∆x − ∆x(cid:63))[k]

(cid:13)
2
(cid:13)
2

(cid:13)
(cid:13)A∆x[k]

(cid:13)
2
2 ≤ (1 + Θ)(HA(0; {vk}) − HA(∆x(cid:63); {vk}))
(cid:13)

σ(cid:48)
2τ

K
(cid:88)

k=1

K
(cid:88)

σ(cid:48)
2τ

1
2

k=1

σ(cid:48)
4τ

K
(cid:88)

k=1

15

(15)

(16)

(17)

(18)

(21)

(22)

(23)

(24)

(25)

C.2 Main lemmas

We ﬁrst present two main lemmas for the per-iteration improvement.
Lemma 6. Let gi be strongly convex with convexity parameter µg ≥ 0 with respect to the norm
(cid:107)·(cid:107) , ∀ i ∈ [n]. Then for all iterations t of outer loop, and any s ∈ [0, 1], it holds that
(cid:35)

(cid:34)
HA(x(t); v(t)

E

k ) − HA(x(t+1); v(t+1)

k

) − α

γσ(cid:48)
1
2τ

(cid:13)
(cid:13)A∆x(t)
(cid:13)

[k]

(cid:13)
2
(cid:13)
(cid:13)
2

(cid:18)

≥η

sGH(x(t); {v(cid:48)(t)

k }K

k=1) −

(cid:19)

R(t)

−

s2 ¯σ(cid:48)
2τ

9βη
2τ σ(cid:48)

(cid:13)
(cid:13)v(t)
(cid:13)

k − Ax(t)(cid:13)
2
(cid:13)
(cid:13)
2

K
(cid:88)

k=1

K
(cid:88)

k=1

where α ∈ [0, 1] is a constant and η := γ(1 − Θ)(1 − α) and σ(cid:48)
and v(cid:48)

k := (cid:80)K

l=1 Wklvl.

1 := (1−Θ)

2(1+Θ) σ(cid:48) and ¯σ(cid:48) := (1 + β)σ(cid:48)

R(t) := − τ µg(1−s)
¯σ(cid:48)s
(cid:80)K

(cid:13)u(t) − x(t)(cid:13)
(cid:13)
2
(cid:13)

+ (cid:80)K

k=1

(cid:13)
(cid:13)A(u(t) − x(t))[k]

(cid:13)
2
(cid:13)

for u(t) ∈ Rn with ¯g(cid:48)(t) := 1
K
u(t)
i ∈ ∂g∗

k=1 ∇f (v(cid:48)(t)
k )
i ¯g(cid:48)(t))
i (−A(cid:62)

k s.t. i ∈ Pk

Proof of Lemma 6. For simplicity, we write H(t)
(cid:80)K

A instead of HA(x(t); {v(t)

k }K

k=1) and v(cid:48)

k :=

(26)

(27)

(28)

f (vk) −

f (cid:0)v(cid:48)

k + γK∆v[k]

(cid:1) + g(x) − g(x + γ∆x)

A − H(t+1)

A

]

i=1 Wikvi.
E[H(t)
K
(cid:88)

=

1
K

1
K

1
K

K
(cid:88)

k=1

K
(cid:88)

k=1

(cid:123)(cid:122)
D1

k=1

K
(cid:88)

k=1

1
K
(cid:124)

+

(cid:26) 1
K

K
(cid:88)

k=1
(cid:124)

=

f (vk) −

f (v(cid:48)

k)

f (v(cid:48)

k) + g(x[k])

−

f (cid:0)v(cid:48)

k + γK∆v[k]

(cid:27)
(cid:1) + g(x[k] + γ∆x[k])

(cid:125)

(cid:125)

(cid:27)

K
(cid:88)

k=1

(cid:26) 1
K

(cid:123)(cid:122)
D2

By the convexity of f , D1 ≥ 0. Using the convexity of f and g in D2 we have

1
γ

D2 ≥

K
(cid:88)

k=1

(cid:26) 1
K

f (v(cid:48)

k) + g(x[k])

−

(cid:27)

K
(cid:88)

k=1

(cid:26) 1
K

f (cid:0)v(cid:48)

k + K∆v[k]

(cid:27)
(cid:1) + g(x[k] + ∆x[k])

≥E

(cid:34) K
(cid:88)

k=1

G σ(cid:48)
k

(cid:0)0; v(cid:48)

k, x[k]

(cid:1) −

G σ(cid:48)
k

(cid:0)∆x[k]; v(cid:48)

k, x[k]

(cid:1)

(cid:35)

K
(cid:88)

k=1

Use the Assumption 1 we have
(cid:34) K
(cid:88)

D2 ≥γE

G σ(cid:48)
k

(cid:0)0; v(cid:48)

k, x[k]

(cid:1) −

G σ(cid:48)
k

(cid:0)∆x[k]; v(cid:48)

k, x[k]

(cid:1)

G σ(cid:48)
k

2

(cid:0)0; v(cid:48)

k, x[k]

(cid:1) − G σ(cid:48)

2

k

∆x(cid:63)

[k]; v(cid:48)

k, x[k]

(cid:16)

k=1

≥γ(1 − Θ)

K
(cid:88)

(cid:110)

k=1
(cid:124)

K
(cid:88)

k=1

(cid:123)(cid:122)
C

(cid:35)

(cid:17)(cid:111)

(cid:125)

Let α ∈ [0, 1] and apply Lemma 5, the previous inequality becomes

D2 ≥ γ(1 − Θ)(1 − α)C + α

(29)

γσ(cid:48)
1
2τ

K
(cid:88)

k=1

(cid:13)
(cid:13)A∆x[k]

(cid:13)
2
(cid:13)
2

16

(30)

(cid:41)

(cid:41)

σ(cid:48)
2τ

where σ(cid:48)

1 := (1−Θ)

2(1+Θ) σ(cid:48). From the deﬁnition of ui we know
i ¯g(cid:48)) − g∗

gi(ui) = ui(−A(cid:62)

i (−A(cid:62)

i ¯g(cid:48))

Replacing ∆xi = s(ui − xi) in C gives

(gi(xi) − gi(xi + ∆xi)) − (cid:10)g(cid:48)

k, A∆x[k]

(cid:11) −

(cid:13)
(cid:13)A∆x[k]

(cid:13)
2
(cid:13)

(sgi(xi) − sgi(ui) +

(1 − s)s(ui − xi)2) − (cid:10)g(cid:48)

k, A∆x[k]

(cid:11) −

(cid:13)
(cid:13)A∆x[k]

(cid:13)
2
(cid:13)

µg
2τ

(cid:0)sgi(xi) + sg∗

i (−A(cid:62)

i ¯g(cid:48))) + s(cid:104)vk/K, g(cid:48)

k(cid:105)(cid:1) − s

((cid:104)vk/K, g(cid:48)

k(cid:105) − (cid:104)Au[k], ¯g(cid:48)(cid:105))

K
(cid:88)

(cid:88)

k=1

i∈Pk

(cid:110) µg
2τ

(1 − s)s(ui − xi)2(cid:111)

−

(cid:10)g(cid:48)

k, A∆x[k]

(cid:11) −

(cid:13)
(cid:13)A∆x[k]

(cid:13)
2
(cid:13)

K
(cid:88)

k=1

K
(cid:88)

k=1

σ(cid:48)
2τ

(cid:0)sgi(xi) + sg∗

i (−A(cid:62)

i ¯g(cid:48))(cid:1) + s(cid:104)vk/K, g(cid:48)

k(cid:105)(cid:9) +

(1 − s)s (cid:107)u − x(cid:107)2

((cid:104)vk/K, g(cid:48)

k(cid:105) − (cid:104)Au[k], ¯g(cid:48)(cid:105) + (cid:104)g(cid:48)

k, A(u − x)[k](cid:105))

σ(cid:48)
2τ

K
(cid:88)

k=1

µg
2

(cid:40)

K
(cid:88)

(cid:88)

C ≥

≥

(30)=

(cid:40)

i∈Pk

(cid:88)

i∈Pk

(cid:88)

(
i∈Pk

k=1

K
(cid:88)

k=1

K
(cid:88)

k=1

+

K
(cid:88)

(cid:8) (cid:88)

=

k=1

i∈Pk

K
(cid:88)

−

s2σ(cid:48)
2τ

k=1
=sGH(x; {v(cid:48)

−

s2σ(cid:48)
2τ

K
(cid:88)

k=1

(cid:13)
(cid:13)A(u − x)[k]

(cid:13)
2
(cid:13)

− s

K
(cid:88)

k}K

k=1) +

µg
2

k=1
(1 − s)s (cid:107)u − x(cid:107)2

K
(cid:88)

k=1

(cid:13)
(cid:13)A(u − x)[k]

(cid:13)
2
(cid:13)

− s

((cid:104)v(cid:48)

k/K, g(cid:48)

k(cid:105) − (cid:104)Au[k], ¯g(cid:48)(cid:105) + (cid:104)g(cid:48)

k, A(u − x)[k](cid:105))

We can bound the last term of the previous equation as D3

1
s

D3 =

((cid:104)v(cid:48)

k/K, g(cid:48)

k(cid:105) − (cid:104)Au[k], ¯g(cid:48)(cid:105) + (cid:104)g(cid:48)

k, A(u − x)[k](cid:105))

K
(cid:88)

k=1

K
(cid:88)

k=1

=

=

=

1
K

1
K

K
(cid:88)

k=1

K
(cid:88)

k=1

((cid:104)g(cid:48)

k, v(cid:48)

k/K(cid:105) − (cid:104)g(cid:48)

k, Au/K(cid:105) + (cid:104)g(cid:48)

k, A(u − x)[k](cid:105))

(cid:104)g(cid:48)

k, v(cid:48)

k − Ax(cid:105) −

(cid:104)¯g(cid:48), A(u − x)[k](cid:105) +

(cid:104)g(cid:48)

k, A(u − x)[k](cid:105)

K
(cid:88)

k=1

(cid:104)g(cid:48)

k − ¯g(cid:48), v(cid:48)

k − Ax(cid:105) +

(cid:104)g(cid:48)

k − ¯g(cid:48), A(u − x)[k](cid:105)

K
(cid:88)

k=1

K
(cid:88)

k=1

Bound the gradient terms with consensus violation. First bound (cid:80)K
∇f (Ax)

k=1 (cid:107)g(cid:48)

k − ¯g(cid:48)(cid:107)2

2, deﬁne gc :=

K
(cid:88)

K
(cid:88)

(cid:16)

(cid:107)g(cid:48)

k − ¯g(cid:48)(cid:107)2

2 ≤2

(cid:107)g(cid:48)

k − gc(cid:107)2

2 + (cid:107)gc − ¯g(cid:48)(cid:107)2

2

(cid:107)g(cid:48)

k − gc(cid:107)2

2 + 2

(cid:107)gc − g(cid:48)

k(cid:107)2

2

(cid:17)

≤ 2

K
(cid:88)

k=1

1
K

K
(cid:88)

k=1

k=1
Apply the 1/τ -smoothness of f we have

k=1

(cid:107)g(cid:48)

k − ¯g(cid:48)(cid:107)2

2 ≤

(cid:107)v(cid:48)

k − Ax(cid:107)2

2 ≤

(cid:107)vk − Ax(cid:107)2
2

(31)

4
τ 2

K
(cid:88)

k=1

4β2
τ 2

K
(cid:88)

k=1

Bound the ﬁrst term in D3

K
(cid:88)

k=1

s

1
K

K
(cid:88)

k=1

(cid:104)g(cid:48)

k − ¯g(cid:48), v(cid:48)

k − Ax(cid:105) ≤

τ (cid:107)g(cid:48)

k − ¯g(cid:48)(cid:107)2

2 +

(cid:107)v(cid:48)

k − Ax(cid:107)2

2

1
τ

(cid:19)

K
(cid:88)

(cid:18)

s
2K

k=1

17

(31)
≤

5β2s
2τ K

K
(cid:88)

k=1

(cid:107)vk − Ax(cid:107)2
2

Bound the second term in D3

s

K
(cid:88)

k=1

(cid:104)g(cid:48)

k − ¯g(cid:48), A(u − x)[k](cid:105) ≤

(cid:107)g(cid:48)

k − ¯g(cid:48)(cid:107)2

2 +

τ
2σ(cid:48)β

K
(cid:88)

k=1

s2σ(cid:48)β
2τ

K
(cid:88)

k=1

(cid:13)
(cid:13)A(u − x)[k]

(cid:13)
2
(cid:13)
2

(31)
≤

4β
2τ σ(cid:48)

K
(cid:88)

k=1

(cid:107)vk − Ax(cid:107)2

2 +

s2σ(cid:48)β
2τ

K
(cid:88)

k=1

(cid:13)
(cid:13)A(u − x)[k]

(cid:13)
2
(cid:13)
2

Then

C ≥sGH(x, {v(cid:48)

k}K

k=1) +

(1 − s)s (cid:107)u − x(cid:107)2 −

µg
2

s2(σ(cid:48) + βσ(cid:48))
2τ

K
(cid:88)

k=1

(cid:13)
(cid:13)A(u − x)[k]

(cid:13)
2
(cid:13)

−

9β
2τ σ(cid:48)

K
(cid:88)

k=1

(cid:107)vk − Ax(cid:107)2
2

Then let ¯σ(cid:48) := (1 + β)σ(cid:48) and η := γ(1 − Θ)(1 − α) we have

E[H(t)

A − H(t+1)

A

− α

γσ(cid:48)
1
2τ

K
(cid:88)

k=1

(cid:13)
(cid:13)A∆x(t)
(cid:13)

[k]

(cid:13)
2
(cid:13)
(cid:13)
2

]

(cid:18)

≥η

sGH(x(t); {v(cid:48)(t)

k }K

k=1) −

(cid:19)

R(t)

−

s2 ¯σ(cid:48)
2τ

9ηβ
2τ σ(cid:48)

K
(cid:88)

k=1

(cid:13)
(cid:13)v(t)
(cid:13)

k − Ax(t)(cid:13)
2
(cid:13)
(cid:13)
2

The following lemma correlates the consensus violation with the size of updates
Lemma 7. Let c > 0 be any constant value. Deﬁne δ(0) := 0 and

Then the consensus violation has an upper bound.

δ(t+1) := βδ(t) + cc1

K
(cid:88)

k=1

(cid:13)
(cid:13)∆v(t)
(cid:13)

k

(cid:13)
2
(cid:13)
(cid:13)
2

K
(cid:88)

k=1

(cid:13)
(cid:13)v(t)
(cid:13)

k − v(t)(cid:13)
2
(cid:13)
(cid:13)
2

≤ e1δ(t)

where e1 := (1 − β)/c.

Proof. Let

We want to prove that

at :=

K
(cid:88)

k=1

(cid:13)
(cid:13)∆v(t)
(cid:13)

k

(cid:13)
2
(cid:13)
(cid:13)
2

, bt :=

K
(cid:88)

k=1

(cid:13)
(cid:13)v(t)
(cid:13)

k − v(t)(cid:13)
2
(cid:13)
(cid:13)
2

bt ≤ e1δ(t)
(35)
First t = 0, b0 = δ(0) = 0. If the claim holds for time t − 1, then bt−1 ≤ e1δ(t−1). At time t, we
have

(14)
≤ βbt−1 + (1 − β)c1at−1

bt

δ(t−1) + (1 − β)c1at−1

(βδ(t−1) + cc1at−1)

≤β

≤

1 − β
c
1 − β
c

(32)
≤ e1δ(t)

18

Thus we proved the lemma.

(32)

(33)

(34)

(36)

(37)

(38)

(39)

Lemma 8. Let gi be strongly convex with convexity parameter µg ≥ 0 with respect to the norm
(cid:107)·(cid:107) , ∀ i ∈ [n]. Then for all iterations t of outer loop, and s ∈ [0, 1], it holds that

E[HA(x(t); {v(t)

k }K
sGH(x(t); {(cid:80)K

(cid:16)

≥η

k=1) − HA(x(t+1); {v(t+1)

i=1 Wkiv(t)

i }K

k=1) − s2 ¯σ(cid:48)

k

}K
k=1) +
2τ R(t)(cid:17)

1 + β
2

δ(t) − δ(t+1)]

where α := (1 + (1−β)2

36(1+Θ)β )−1 ∈ [0, 1], η := γ(1 − Θ)(1 − α), ¯σ(cid:48) := (1 + β)σ(cid:48) and

R(t) := − τ µg(1−s)

¯σ(cid:48)s
for u(t) ∈ Rn with ¯g(cid:48)(t) := (cid:80)K

(cid:13)u(t) − x(t)(cid:13)
(cid:13)
2
(cid:13)
i=1 Wikv(t)
i )
i ¯g(cid:48)(t))

i (−A(cid:62)

k=1 ∇f ((cid:80)K
u(t)
i ∈ ∂g∗

where δ(t) is deﬁned in Lemma 7.

k s.t. i ∈ Pk.

+ (cid:80)K

k=1

(cid:13)
(cid:13)A(u(t) − x(t))[k]

(cid:13)
2
(cid:13)

Proof. In this proof we use v(cid:48)

i Wkivi. From Lemma 6 we know that

(cid:20)
A − H(t+1)
H(t)

A

E

k := (cid:80)
γσ(cid:48)
1
2τ

− α

(cid:18)

≥η

sGH(x(t); {v(cid:48)(t)

k }K

k=1) −

K
(cid:88)

k=1

(cid:13)
2
(cid:13)
(cid:13)
2

(cid:13)
(cid:13)A∆x(t)
(cid:13)
(cid:19)

[k]

s2 ¯σ(cid:48)
2τ

R(t)

Use the following notations to simplify the calculation

+

9ηβ
2τ σ(cid:48)

K
(cid:88)

k=1

(cid:13)
(cid:13)v(t)
(cid:13)

k − Ax(t)(cid:13)
2
(cid:13)
(cid:13)
2

(cid:21)

at :=

K
(cid:88)

k=1

(cid:13)
(cid:13)∆v(t)
(cid:13)

k

(cid:13)
2
(cid:13)
(cid:13)
2

, bt :=

K
(cid:88)

k=1

(cid:13)
(cid:13)v(t)
(cid:13)

k − v(t)(cid:13)
2
(cid:13)
(cid:13)
2

, f1 := α

, f2 :=

(43)

f2bt − f1at ≤ f2e1δ(t) − f1(δ(t+1) − βδ(t))/(cc1) = (f2e1 +

)δ(t) −

δ(t+1)

(44)

From Lemma 7 we know that

Fix constant c such that f1
cc1

= 1 in (44)

γσ(cid:48)
1
2τ

f1β
cc1

9ηβ
2τ σ(cid:48)

f1
cc1

c =

= α

f1
c1

(1 − β)2σ(cid:48)
1
2τ γK 2

Fix (f2e1 + f1β
cc1

) = 1+β

2 < 1 in (44), to determine α ∈ [0, 1]. First consider f2e1
γK
1 − β
σ(cid:48)
c
1

9γ(1 − Θ)(1 − α)β
2τ σ(cid:48)

9(1 − Θ)β
1 − β

1 − α
α

(45)=

f2e1 =

Then we have

f1β
cc1
Thus we can ﬁx α ∈ [0, 1] to be

f2e1 +

=

1 − α
α

9(1 − Θ)β
1 − β

γK
σ(cid:48)
1

+ β =

< 1.

1 + β
2

(cid:18)

α :=

1 +

(cid:19)−1

(1 − β)2
36(1 + Θ)β

So when have these information.

1 + β
2
Finally, using all of the previous equations we know
(cid:18)

f2bt − f1at ≤

(cid:21)

(cid:20)
A − H(t+1)
H(t)

A

E

+

1 + β
2

δ(t) − δ(t+1)

δ(t) − δ(t+1)

≥ η

sGH(x(t); {v(cid:48)(t)

k }K

k=1) −

(cid:19)

R(t)

s2 ¯σ(cid:48)
2τ

(40)

(41)

(42)

(45)

(46)

(47)

(48)

(49)

(50)

19

C.3 Main theorems

Here we present the proofs of Theorem 1 and Theorem 2.
Lemma 9. If g∗

i are L-Lipschitz continuous for all i ∈ [n], then

∀ t : R(t) ≤ 4L2

σknk = 4L2σ,

(51)

K
(cid:88)

k=1

where σk := maxx[k]∈Rn

(cid:13)
(cid:13)A[k]x[k]

(cid:13)
2
(cid:13)

/ (cid:13)
(cid:13)x[k]

(cid:13)
2
(cid:13)

.

Proof. For general convex functions, the strong convexity parameter is µg = 0, and hence the
deﬁnition (41) of the complexity constant R(t) becomes

R(t) =

K
(cid:88)

k=1

(cid:13)
(cid:13)A(u(t) − x(t))[k]
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

=

σk

(cid:13)
(cid:13)(u(t) − x(t))[k]
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

≤

σk|Pk|4L2 = 4L2σ

K
(cid:88)

k=1

K
(cid:88)

k=1

Here the last inequality follows from L-Lipschitz property of g∗.

Theorem 1 (Strongly Convex gi). Consider Algorithm 1 with γ := 1 and let Θ be the quality of the
local solver in Assumption 1. Let gi be µg-strongly convex for all i ∈ [n] and let f be 1/τ -smooth.
Let ¯σ(cid:48) := (1 + β)σ(cid:48), α := (1 + (1−β)2

36(1+Θ)β )−1 and η := γ(1 − Θ)(1 − α)

s0 =

τ µg+σmax ¯σ(cid:48) ∈ [0, 1].

τ µg

(8)

Then after T iterations of Algorithm 1 with6

it holds that E(cid:2)HA(x(T ), {v(T )
with

k }K

k=1)(cid:3) ≤ εH. Furthermore, after T iterations

T ≥ 1+ηs0
ηs0

log ε(0)
H
εH

,

k}K
k=1) − HA(x(cid:63), {v(cid:63)
(cid:18)

T ≥ 1+ηs0
ηs0

log

(cid:19)

1
ηs0

ε(0)
H
εGH

,

we have the expected duality gap E[GH(x(T ), {(cid:80)K

k=1 Wklv(T )

l

}K
k=1)] ≤ εGH.

Proof. If gi(·) are µg-strongly convex, one can use the deﬁnition of σk and σmax to ﬁnd
(cid:13)u(t) − x(t)(cid:13)
(cid:19) (cid:13)
(cid:13)u(t) − x(t)(cid:13)
(cid:13)

(cid:13)
(cid:13)A(u(t) − x(t))[k]
(cid:13)

τ µg(1 − s)
¯σ(cid:48)s

R(t) ≤ −

+ σmax

τ µg(1 − s)
¯σ(cid:48)s

K
(cid:88)

(cid:13)
2
(cid:13)
(cid:13)

2
(cid:13)
(cid:13)

2
(cid:13)
(cid:13)

k=1

(cid:13)
(cid:13)

+

≤

−

(cid:18)

.

s0 =

τ µg
τ µg + σmax ¯σ(cid:48)

then R(t) ≤ 0. The duality gap has a lower bound duality gap

GH(x(t), {v(cid:48)(t)

k }K

k=1) ≥ HA(x(t), {v(cid:48)(t)

k }K

k=1) − H∗

A ≥ HA(x(t+1), {v(t+1)

k

k=1) − H∗
}K
A

(54)

and use Lemma 8, we have

E[H(t)

A − H(t+1)

A

+

δ(t) − δ(t+1)] ≥ ηs0GH ≥ ηs0(H(t+1)

− HA

(cid:63))

A

If we set

Then

(52)

(53)

(55)

(56)

E[H(t)

A − HA

(cid:63) +

δ(t)] ≥ (1 + ηs0)E[H(t+1)

− HA

(cid:63) + δ(t+1)]

A

6ε(0)

H := HA(x(0), {v(0)

k }K

k=1) − HA(x(cid:63), {v(cid:63)

k}K

k=1) is the initial suboptimality.

1 + β
2

1 + β
2

20

Therefore if we denote ε(t)

H := H(t)
(cid:18)

E[ε(t)

H ] ≤

1 −

A − H(cid:63)

A + δ(t) we have recursively that
(cid:19)
t

ε(0)
H ≤ exp

(cid:19)t

−

(cid:18)

ηs0
1 + ηs0

ηs0
1 + ηs0

ε(0)
H

The right hand side will be smaller than some εH if

Moreover, to bound the duality gap G(t)

ηs0G(t)
H

(55)
≤ E[H(t)

A − H(t+1)

A

δ(t) − δ(t+1)] ≤ E[H(t)

A − HA

∗ + δ(t)]

T ≥

1 + ηs0
ηs0

log

ε(0)
H
εH

H , we have
1 + β
2

+

Hence if εH ≤ ηs0εGH then G(t)

H ≤ εGH. Therefore after

T ≥

1 + ηs0
ηs0

log

(cid:33)

(cid:32)

1
ηs0

ε(0)
H
εGH

iterations we have obtained a duality gap less then εGH .

Theorem 2 (Non-strongly Convex Case). Consider Algorithm 1, using a local solver of quality Θ.
Let gi(·) have L-bounded support, and let f be (1/τ )-smooth. Let εGH > 0 be the desired duality
gap. Then after T iterations where
(cid:26) (cid:108) 1

(cid:17) (cid:21)

(cid:27)

(cid:20)

(cid:109)

T ≥ T0 + max

(cid:26)

(cid:24)

t0 ≥ max

0,

,

η

, 4L2σ¯σ(cid:48)
τ εGH η
η log 2τ (HA(x(0),{v(0)

1+η

T0 ≥ t0 +

l })−HA(x(cid:63),{v(cid:63)}))
4L2σ ¯σ(cid:48)

2
η

(cid:16) 8L2σ ¯σ(cid:48)
τ εGH
(cid:25)(cid:27)

− 1

+

and ¯σ(cid:48) := (1 + β)σ(cid:48), α := (1 + (1−β)2
duality gap satisﬁes

36(1+Θ)β )−1 and η := γ(1 − Θ)(1 − α). We have that the expected

E(cid:2)GH(¯x, {¯vk}K
(cid:80)T −1

k=1, { ¯wk}K

k=1)(cid:3) ≤ εGH

at the averaged iterate ¯x :=

1
T −T0
k)(t) and ¯wk := 1

T −T0

t=T0+1 x(t), and v(cid:48)
k
k)(t)).
t=T0+1 ∇f ((v(cid:48)

(cid:80)T −1

1
T −T0

(cid:80)T −1

t=T0+1(v(cid:48)

:= (cid:80)K

l=1 Wklvl and ¯vk

:=

Proof. We write H(t)
k }K
k=1). We
begin by estimating the expected change of feasibility for HA. We can bound this above by using
Lemma 8 and the fact that FB(·) is always a lower bound for −FA(·) and then applying (51) to ﬁnd

A instead of HA(x(t); {v(t)

A instead of HA(x(cid:63); {vk

k=1) and H(cid:63)

(cid:63)}K

(1 + ηs)E[H(t+1)

A

− H(cid:63)

A + δ(t+1)] ≤ (H(t)

A − H(cid:63)

A + δ(t)) + η

Use (57) recursively we have

E[H(t)

A − H(cid:63)

A + δ(t)] ≤ (1 + ηs)−t(H(0)

A − H(cid:63)

A + δ(0)) + s

We know that δ(0) = 0. Choose s = 1 and
(cid:40)

(cid:38)

t = t0 := max

0,

1 + η
η

log

2τ (H(0)

A − H(cid:63)
A)
4L2σ¯σ(cid:48)

(cid:39)(cid:41)

¯σ(cid:48)s2
2τ

4L2σ

4L2 ¯σ(cid:48)σ
2τ

leads to

(57)

(58)

(59)

(60)

E[H(t)

A − H(cid:63)

A + δ(t)] ≤

4L2 ¯σ(cid:48)σ
τ

21

Next, we show inductively that

∀ t ≥ t0 : E[H(t)

A − H(cid:63)

A + δ(t)] ≤

4L2 ¯σ(cid:48)σ

τ (1 + 1

2 η(t − t0))

.

Clearly, (60) implies that (61) holds for t = t0. Assuming that it holds for any t ≥ t0, we show that
it must also hold for t + 1. Indeed, using

1

s =

1 + 1

2 η(t − t0)

∈ [0, 1],

we obtain

E[H(t+1)
A

− H(cid:63)

A + δ(t+1)] ≤

4L2σ¯σ(cid:48)
τ

(cid:18) 1 + 1

2 η(t − t0) − 1
(1 + 1

2 η(t − t0))2

2 γ(1 − Θ)

(cid:124)

(cid:123)(cid:122)
D

by applying the bounds (57) and (61), plugging in the deﬁnition of s (62), and simplifying. We upper
bound the term D using the fact that geometric mean is less or equal to arithmetic mean:
(1 + 1

2 η(t − 1 − t0))

1

1

D =

1 + 1

2 η(t + 1 − t0)

(cid:124)

.

≤

1 + 1

2 η(t + 1 − t0)

2 η(t + 1 − t0))(1 + 1
(1 + 1

2 η(t − t0))2

(cid:123)(cid:122)
≤1

(cid:19)

(cid:125)

(cid:125)

We can apply the results of Lemma 8 to get

ηsGH(x(t), {v(t)

k }K

k=1) ≤ H(t)

A − H(t+1)

A

+ δ(t) − δ(t+1)

Deﬁne the following iterate

¯x :=

1
T − T0

T −1
(cid:88)

t=T0+1

x(t), ¯vk :=

1
T − T0

T −1
(cid:88)

t=T0+1

v(t)
k , ¯wk :=

1
T − T0

T −1
(cid:88)

t=T0+1

∇f (v(t)
k )

use Lemma 9 to obtain

E[GH(¯x, {¯vk}K

k=1, { ¯wk}K

k=1)] ≤

(cid:16)

E[GH

x(t), {v(t)

k }K

k=1

(cid:17)

]

1
T − T0

T −1
(cid:88)

t=T0

≤

1
ηs

1
T − T0

E[H(T0)

A − H(cid:63)

A + δ(T0)] +

4L2σ¯σ(cid:48)s
2τ

If T ≥ (cid:100) 1

η (cid:101) + T0 such that T0 ≥ t0 we have

E[GH(¯x, {¯vk}K

k=1, { ¯wk}K

k=1)] ≤

(cid:18)

1
T − T0

1
ηs
4L2σ¯σ(cid:48)
τ

(cid:18) 1
ηs

=

τ (1 + 1
1
T − T0

4L2 ¯σ(cid:48)σ
2 η(T0 − t0)
1

(1 + 1

2 η(T0 − t0))

(cid:19)

+

4L2σ¯σ(cid:48)s
2τ

+

(cid:19)

.

s
2

s =

1
(T − T0)η

∈ [0, 1]

Choosing

gives us

E[GH(¯x, {¯vk}K

k=1, { ¯wk}K

k=1)] ≤

(cid:18)

4L2σ¯σ(cid:48)
τ

1

1 + 1

2 η(T0 − t0)

+

1
2

1
(T − T0)η

(cid:19)

.

To have right hand side of (64) smaller then εGH it is sufﬁcient to choose T0 and T such that

(61)

(62)

(63)

(64)

(65)

(cid:18)

4L2σ¯σ(cid:48)
τ

1 + 1

2 η(T0 − t0)

(cid:19)

≤

εGH

1
2

1

22

4L2σ¯σ(cid:48)
τ

(cid:18) 1
2

1
(T − T0)η

(cid:19)

≤

εGH

1
2

Hence if T0 ≥ t0 + 2
η

(cid:16) 8L2σ ¯σ(cid:48)
τ εGH

(cid:17)

− 1

and T ≥ T0 + 4L2σ ¯σ(cid:48)

τ εGH η then (65) and (66) are satisﬁed.

Proposition 1 (Local Certiﬁcates). Assume gi has L-bounded support, and let Nk := {j : Wjk > 0}
be the set of nodes accessible to node k. Then for any given ε > 0, we have

GH(x; {vk}K

k=1) ≤ ε,

if for all k = 1, . . . , K the following two local conditions are satisﬁed:
(cid:0)gi(xi) + g∗

i ∇f (vk))(cid:1) ≤

k ∇f (vk) +

i (−A(cid:62)

v(cid:62)

(cid:88)

ε
2K

i∈Pk

(cid:13)
(cid:13)∇f (vk) − 1
(cid:13)

|Nk|

(cid:80)

∇f (vj)

≤

j∈Nk

(cid:13)
(cid:13)
(cid:13)2

(cid:16)(cid:80)K

k=1 n2

kσk

(cid:17)−1/2

1−β
√

2L

K

ε,

Proof. If the wk variable in the duality gap (6) is ﬁxed to wk = gk := ∇f (vk), then using the
equality condition of the Fenchel-Young inequality on f , the duality gap can be written as follows

GH(x; {vk}K

k=1) :=

(cid:104)vk, gk(cid:105) +

gi(xi) + g∗

i (−A(cid:62)

i ¯g)

(67)

(cid:32)

K
(cid:88)

k=1

(cid:88)

i∈Pk

(cid:33)

(cid:80)K

K
(cid:88)

GH ≤

where ¯g = 1
K
(cid:32)

k=1 gk is the only term locally unavailable.
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(68)
If both terms in (68) are less than ε/2, then GH ≤ ε. Since the ﬁrst term can be calculated locally,
we only need for all k = 1, . . . K

gi(xi) + g∗

i ¯g) − g∗

(cid:104)vk, gk(cid:105) +

i (−A(cid:62)

i (−A(cid:62)

i (−A(cid:62)

i gk)(cid:1)

i gk)

K
(cid:88)

(cid:0)g∗

(cid:88)

(cid:88)

i∈Pk

i∈Pk

k=1

k=1

(cid:33)

+

(cid:104)vk, gk(cid:105) +

gi(xi) + g∗

i (−A(cid:62)

i gk) ≤

ε
2K

.

(cid:88)

i∈Pk

Consider the second term in (68). Compute the difference between g∗

|g∗

i (−A(cid:62)

i ¯g) − g∗

i (−A(cid:62)

i gk)| ≤ L| − A(cid:62)

i ¯g) and g∗
i (¯g − gk)| ≤ L (cid:107)Ai(cid:107)2 (cid:107)¯g − gk(cid:107)2

i (−A(cid:62)

i (−A(cid:62)

i gk)

where we use Lemma 3 and L-Lipschitz continuity. Then sum up coordinates i ∈ Pk on node k

Sum up (71) for all k = 1, . . . , K and apply the Cauchy-Schwarz inequality

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:88)

i∈Pk

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

K
(cid:88)

(cid:88)

k=1

i∈Pk

(cid:0)g∗

i (−A(cid:62)

i ¯g) − g∗

i (−A(cid:62)

i gk)(cid:1)

≤ L (cid:107)¯g − gk(cid:107)2

(cid:107)Ai(cid:107)2 .

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:118)
(cid:117)
(cid:117)
(cid:116)

K
(cid:88)

k=1

(cid:88)

i∈Pk

(cid:118)
(cid:117)
(cid:117)
(cid:116)

K
(cid:88)

k=1

(cid:88)

(
i∈Pk

(cid:0)g∗

i (−A(cid:62)

i ¯g) − g∗

i (−A(cid:62)

i gk)(cid:1)

≤ L

(cid:107)¯g − gk(cid:107)2
2

(cid:107)Ai(cid:107)2)2.

(72)

We will upper bound (cid:80)
(cid:88)

i∈Pk

(cid:107)Ai(cid:107)2 and (cid:107)¯g − gk(cid:107)2 separately. First we have
√

√

(cid:13)
(cid:13)A[k]

(cid:13)
(cid:13)F ≤ nk

(cid:13)
(cid:13)A[k]

(cid:13)
(cid:13)∞,2 ≤ nk

nk

(cid:107)Ai(cid:107)2 ≤

σk,

i∈Pk

where we write (cid:107).(cid:107)∞,2 for the largest Euclidean norm of a column of the argument matrix, and then
used the deﬁnition of σk as in (7). Let us write G := [g1; · · · ; gK], E := 1
K [1; · · · ; 1], then apply
Young’s inequality with δ
k=1 (cid:107)gk − ¯g(cid:107)2

2 = (cid:107)G − GE(cid:107)2

(cid:80)K

F

(66)

(9)

(10)

(69)

(70)

(71)

(73)

23

≤(1 +

) (cid:107)G − GW(cid:107)2

F + (1 + δ) (cid:107)GW − GE(cid:107)2

F

=(1 +

) (cid:107)G − GW(cid:107)2

F + (1 + δ) (cid:107)G(I − E)(W − E)(cid:107)2

F

≤(1 +

) (cid:107)G − GW(cid:107)2

F + (1 + δ)β2 (cid:107)G(I − E)(cid:107)2

F

1
δ
1
δ
1
δ
δ ) (cid:80)K

=(1 + 1

(cid:13)
(cid:13)gk − 1
(cid:13)

|Nk|

(cid:80)

k=1

j∈Nk

gj

(cid:13)
2
(cid:13)
(cid:13)
2

+ (1 + δ)β2 (cid:80)K

k=1 (cid:107)gk − ¯g(cid:107)2

2

Take δ := (1 − β)/β, then we have

K
(cid:88)

k=1

(cid:107)gk − ¯g(cid:107)2

2 ≤

1
1 − β

K
(cid:88)

k=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

gk −

1
|Nk|

(cid:88)

j∈Nk

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
2

K
(cid:88)

k=1

gj

+ β

(cid:107)gk − ¯g(cid:107)2
2

≤

1
(1 − β)2

K
(cid:88)

k=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

gk −

1
|Nk|

(cid:88)

gj

j∈Nk

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
2

We now use (73) and (74) and impose

1
(1 − β)2

K
(cid:88)

k=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

gk −

1
|Nk|

(cid:88)

gj

j∈Nk

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
2

K
(cid:88)

k=1

n2

kσk ≤

(cid:17)2

(cid:16) ε
2L

then (72) is less than ε/2. Finally, (75) can be guaranteed by imposing the following restrictions for
all k = 1, . . . , K

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

gk −

1
|Nk|

(cid:88)

gj

j∈Nk

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
2

≤ (1 − β)2

(cid:33)−1

ε2
4KL2

(cid:32) K
(cid:88)

k=1

n2

kσk

(74)

(75)

(76)

D Experiment details

In this section we provide greater details about the experimental setup and implementations. All the
codes are written in PyTorch (0.4.0a0+cc9d3b2) with MPI backend [Paszke et al., 2017]. In each
experiment, we run centralized CoCoA for a sufﬁciently long time until progress stalled; then use
their minimal value as the approximate optima.

DIGing. DIGing is a distributed algorithm based on inexact gradient and a gradient tracking
technique. [Nedic et al., 2017] proves linear convergence of DIGing when the distributed optimization
objective is strongly convex over time-varying graphs with a ﬁxed learning rate. In this experiments,
we only consider the time-invariant graph. The stepsize is chosen via a grid search. [Nedic et al.,
2017] mentioned that the EXTRA algorithm [Shi et al., 2015] is almost identical to that of the DIGing
algorithm when the same stepsize is chosen for both algorithms, so we only present with DIGing
here.

COLA. We implement COLA framework with local solvers from Scikit-Learn [Pedregosa et al.,
2011]. Their ElasticNet solver uses coordinate descent internally. We note that since the framework
and theory allow any internal solver to be used, COLA could beneﬁt even beyond the results shown
by using existing fast solvers. We implement COCOA as a special case of COLA. The aggregation
parameter γ is ﬁxed to 1 for all experiments.

ADMM. Alternating Direction Method of Multipliers (ADMM) [Boyd et al., 2011] is a classical
approach in distributed optimization problems. Applying ADMM to decentralized settings [Shi et al.,
2014] involves solving

minxi,zij

(cid:80)L

i=1 fi(xi)

s.t. xi = zij, xj = zij,

∀ (i, j) ∈ E

24

Figure 5: The consensus violation curve of
COLA in Figure 2.

Figure 6: Same settings as Figure 4 except that
x[k] are reset after node k leaving the network.

where zij is an auxiliary variable imposing the consensus constraint on neighbors i and j. We
therefore employ the coordinate descent algorithm to solve the local problem. The number of
coordinates chosen in each round is the same as that of COLA. We choose the penalty parameter
from the conclusion of [Shi et al., 2014].

k=1 (cid:107)vk − vc(cid:107)2

Additional experiments. We provide additional experimental results here. First the consensus
violation (cid:80)K
2 curve for Figure 2 is displayed in Figure 5. As we can see, the consensus
violation starts with 0 and soon becomes very large, then gradually drops down. This is because we
are minimizing the sum of H(t)
A and δ(t), see the proof of Theorem 1. Then another model under
failing nodes is tested in Figure 6 where x[k] are initialized to 0 when node k leave the network. Note
that we assume the leaving node k will inform its neighborhood and modify their own local estimates
k vk = vc. This failure model, however, oscillates and
so that the rest nodes still satisfy
does not converge fast.

1
#nodes

(cid:80)

E Details regarding extensions

E.1 Fault tolerance and time varying graphs

In this section we extend framework COLA to handle fault tolerance and time varying graphs. Here we
assume when a node leave the network, their local variables x are frozen. We use same assumptions
about the fault tolerance model in [Smith et al., 2017].
Deﬁnition 5 (Per-Node-Per-Iteration-Approximation Parameter). At each iteration t, we deﬁne the
accuracy level of the solution calculated by node k to its subproblem as

θt
k :=

k ; x(t)

k (∆x(t)
G σ(cid:48)
k (0; x(t)
G σ(cid:48)

[k], v(t)

k ) − G σ(cid:48)

k (∆x(cid:63)

[k], v(t)

k ) − G σ(cid:48)

k (∆x(cid:63)

[k], v(t)
k; x(t)
k )
[k], v(t)
k )

k; x(t)

(77)

where ∆x(cid:63)
[0, 1] with θt

k is the minimizer of the subproblem G σ(cid:48)

[k], v(t)
k := 1 meaning that no updates to subproblem G σ(cid:48)

k (·; x(t)

k ). We allow this value to vary between
k are made by node k at iteration t.

k allows the consideration of stragglers and fault tolerance. We also need the

The ﬂexible choice of θt
following assumption on θt
k.
Assumption 2 (Fault Tolerance Model). Let {x(t)}T
of iteration T . For all nodes k and all iterations t, we assume pt
ˆΘT

k < 1] ≤ Θmax < 1.

k := E[θT

k |{x(t)}T

t=0, θT

t=0 be the history of iterates until the beginning
k = 1] ≤ pmax < 1 and

k := P[θt

In addition we write ¯Θ := pmax + (1 − pmax)Θmax < 1. Another assumption on time varying model
is necessary in order to maintain the same linear and sublinear convergence rate. It is from [Nedic
et al., 2017, Assumption 1]:

25

Assumption 3 (Time Varying Model). Assume the mixing matrix W(t) is a function of time t. There
exist a positive integer B such that the spectral gap satisﬁes the following condition

σmax

(cid:110)(cid:81)t+B−1

i=t W(i) − 1

K 11(cid:62)(cid:111)

≤ βmax

∀ t ≥ 0.

We change the Algorithm 1 such that it performs gossip step for B times between solving subproblems.
In this way, the convergence rate on time varying mixing matrix is similar to a static graph with
mixing matrix (cid:81)t+B−1
i=t W(i). The sublinear/linear rate can be proved similarly.

E.2 Data dependent aggregation parameter

Deﬁnition 6 (Data-dependent aggregation parameter). In Algorithm 1, the aggregation parameter γ
controls the level of adding γ versus averaging γ := 1
K of the partial solution from all machines. For
the convergence discussed below to hold, the subproblem parameter σ(cid:48) must be chosen not smaller
than

σ(cid:48) ≥ σ(cid:48)

min := γ max
x∈Rn

(cid:107)Ax(cid:107)2
(cid:13)
(cid:13)Ax[k]

(cid:13)
2
(cid:13)

(cid:80)K

k=1

(78)

The simple choice of σ(cid:48) := γK is valid for (78), closer to the actual bound given in σ(cid:48)

min.

E.3 Hessian subproblem

If the Hessian matrix of f is available, it can be used to deﬁne better local subproblems, as done in
the classical distributed setting by [Gargiani, 2017, Lee and Chang, 2017, Dünner et al., 2018, Lee
et al., 2018]. We use same idea in the decentralized setting, deﬁning the improved subproblem

G σ(cid:48)
k (∆x; x[k], vk) := 1

K f (vk) +

(cid:68)(cid:80)K
2 (A∆x[k])(cid:62) (cid:16)(cid:80)K

+ 1

l=1 Wkl∇f (vl), A∆x[k]
(cid:17)

l=1 Wkl∇2f (vl)

(cid:69)

The sum of previous subproblems satisﬁes the following relations

A∆x[k] + (cid:80)

gi(xi + ∆xi)

i∈Pk

(79)

Wklv(t)

l + γKA∆x[k]

gi(x(t)

i + (∆x[k])i)

(cid:33)

(cid:88)

+

i∈Pk

Wkl

f (v(t)

l ) + (cid:104)∇f (v(t)

l ), γKA∆x[k](cid:105) +

(A∆x[k])(cid:62)∇2f (v(t)

l )A∆x[k]

(cid:27)

1
2

G σ(cid:48)
k (0; x(t+1)

[k]

, v(t+1)
k

)

(cid:32) K
(cid:88)

K
(cid:88)

f

k=1

l=1

K
(cid:88)

K
(cid:88)

(cid:26)

k=1
(cid:88)

l=1
gi(x(t)

i∈Pk

i + (∆x[k])i)

K
(cid:88)

k=1

=

≤

1
K

1
K

+

=

K
(cid:88)

k=1

G σ(cid:48)
k (∆x; x(t)

[k], v(t)

k ) ≤

G σ(cid:48)
k (0; x(t)

[k], v(t)
k )

K
(cid:88)

k=1

This means that the sequence (cid:8) (cid:80)K
[k], v(t)
t=0 is monotonically non-increasing. Fol-
lowing the reasoning in this paper, we can have similar convergence guarantees for both strongly
convex and general convex problems. Formalizing all detailed implications here would be out of the
scope of this paper, but the main point is that the second-order techniques developed for the COCOA
framework also have their analogon in the decentralized setting.

k (0; x(t)
G σ(cid:48)

k )(cid:9)∞

k=1

26

