HFT-CNN: Learning Hierarchical Category Structure for Multi-label
Short Text Categorization

Kazuya Shimura1, Jiyi Li2 and Fumiyo Fukumoto2
Graduate School of Engineering1
Interdisciplinary Graduate School2
University of Yamanashi
4-3-11, Takeda, Kofu, 400-8511 Japan
fg17tk008,jyli,fukumotog@yamanashi.ac.jp

Abstract

We focus on the multi-label categorization task
for short texts and explore the use of a hierar-
chical structure (HS) of categories. In contrast
to the existing work using non-hierarchical ﬂat
model, the method leverages the hierarchical
relations between the categories to tackle the
data sparsity problem. The lower the HS level,
the worse the categorization performance. Be-
cause lower categories are ﬁne-grained and the
amount of training data per category is much
smaller than that in an upper level. We propose
an approach which can effectively utilize the
data in the upper levels to contribute catego-
rization in the lower levels by applying a Con-
volutional Neural Network (CNN) with a ﬁne-
tuning technique. The results using two bench-
mark datasets show that the proposed method,
Hierarchical Fine-Tuning based CNN (HFT-
CNN) is competitive with the state-of-the-art
CNN based methods.

1

Introduction

Major attempts

Short text categorization is widely studied since
the recent explosive growth of online social net-
working applications (Song et al., 2014).
In
texts are less
contrast with documents, short
to
topic-focused in texts.
tackle the problem is to expand short
texts
with knowledge extracted from the textual cor-
pus, machine-readable dictionaries, and thesauri
(Phan et al., 2008; Wang et al., 2008; Chen et al.,
2011; Wu et al., 2012). However, because of
domain-independent nature of dictionaries and
thesauri, it is often the case that the data distri-
bution of the external knowledge is different from
the test data collected from some speciﬁc domain,
which deteriorates the overall performance of cat-
egorization. A methodology which maximizes
the impact of pre-deﬁned domains/categories is
needed to improve categorization performance.

More recently, many authors have attempted
to apply deep learning techniques including CNN
(Wang et al., 2015; Zhang and Wallace, 2015;
Zhang et al., 2017; Wang et al., 2017), the atten-
tion based CNN (Yang et al., 2016), bag-of-words
based CNN (Johnson and Zhang, 2015a), and the
combination of CNN and recurrent neural network
(Lee and Dernoncourt, 2016; Zhang et al., 2016)
to text categorization. Most of them demon-
strated that neural network models are powerful
for learning features from texts, while they fo-
cused on single-label or a few labels problem.
Several efforts have been made to multi-labels
(Johnson and Zhang, 2015b; Liu et al., 2017). Liu
et al.
explored a family of new CNN models
which are tailored for extreme multi-label classi-
ﬁcation (Liu et al., 2017). They used a dynamic
max pooling scheme, a binary cross-entropy loss,
and a hidden bottleneck layer to improve the
overall performance. The results by using six
benchmark datasets where the label-set sizes are
up to 670K showed that their method attained
at the best or second best in comparison with
seven state-of-the-art methods including FastText
(Joulin et al., 2017) and bag-of-words based CNN
(Johnson and Zhang, 2015a). However, all of
these attempts aimed at utilizing a large volume
of data.

We address the problem of multi-label short text
categorization and explore the use of a HS of cat-
egories. The lower level of categories are ﬁne-
grained compared to the upper level of categories.
Moreover, it is often the case that the amount of
training data in a lower level is much smaller than
that in an upper level which deteriorates the over-
all performance of categorization. We propose
an approach which can effectively utilize the data
in the upper levels to contribute categorization in
lower levels by applying ﬁne-tuning to the CNN
which can learn a HS of categories and incorporate

features. These features form a pooling layer and
are passed to a fully connected layer. In the fully
connected layer, we applied dropout (Hinton et al.,
2012). The dropout randomly sets values in the
layer to 0. Finally, we obtained the probability dis-
tribution over categories. The network is trained
with the objective that minimizes the binary cross-
entropy (BCE) of the predicted distributions and
the actual distributions by performing stochastic
gradient descent.

2.2 Hierarchical structure learning

Our key idea is to use a ﬁne-tuning technique in
CNN to tackle the data sparsity problem, espe-
cially a lower level of a HS. Following a HS, we
transferred the parameters of CNN trained in the
upper levels to the lower levels which are worse
trained because of the lack of data, and then ﬁnely
tuned parameters of CNN for lower levels (Figure
1). This approach can effectively utilize the data
in the upper levels to contribute categorization in
the lower levels.

Fine-tuning is motivated by the observation that
the earlier features of CNN contain more generic
features that should be effective for many tasks,
but later layers of the CNN becomes progressively
more speciﬁc to the details of the classes contained
in the original dataset. The motivation is identical
to a HS of categories as we ﬁrst learn to distinguish
among generic categories at the upper level of a
hierarchy, then learns lower level distinctions by
using only within the appropriate top level of the
HS. We note that ﬁne-tuning the last few layers are
usually sufﬁcient for transfer learning as the last
few layers become more speciﬁc features. How-
ever, the HS consisting of deep level needs to ﬁne-
tune the early layers as well because the distance
between the upper and lower level of categories
is signiﬁcant. For this reason, we transferred two
layers shown in Figure 1, i.e., a layer obtained by
word embedding and the convolutional layer. We
used them as an initial parameter to learn the sec-
ond level of a hierarchy. We repeated this pro-
cedure from the top level to the bottom level of
a hierarchy. We note that a HS consists of many
levels. We ﬁne-tune between adjacent layers only
because they are more correlated with each other
compared to distant layers.

2.3 Multi-label categorization

Each test instance is classiﬁed into categories with
probabilities/scores by applying HFT-CNN. We

Figure 1: HFT-CNN model

granularity of categories into categorization. We
transferred the parameters of CNN trained from
upper to lower levels according to the HS, and
ﬁnely tuned parameters. The main contributions
of our work can be summarized: (1) We propose a
method that maximizes the impact of pre-deﬁned
categories to alleviate data sparsity in multi-label
short texts. (2) We empirically examined a ﬁne-
tuning with CNN that ﬁts to learn a HS of cate-
gories deﬁned by lexicographers, and (3) The re-
sults show that our method is competitive to the
state-of-the-art CNN based methods by using two
benchmark datasets, especially it is effective for
categorization of short texts consisting of a few
words with a large number of labels.

2 Hierarchical Fine-Tuning based CNN

2.1 CNN architecture

Similar to other CNN (Johnson and Zhang, 2015a;
Liu et al., 2017), our HFT-CNN model shown in
Figure 1 is based on (Kim, 2014). Let xi 2 Rk be
the k-dimensional word vector with the i-th word
in a sentence obtained by applying skip-gram
model provided in fastText1. A sentence with
length n is represented as x1:n = [x1; x2; (cid:1) (cid:1) (cid:1) ; xn]
2 Rnk. A convolution ﬁlter w 2 Rhk is applied
to a window size of h words to produce a new fea-
ture, ci = f (w(cid:1)xi:i+h(cid:0)1 +b) where b 2 R indicates
a bias term and f refers to a non-linear activation
function. We applied this convolution ﬁlter to each
possible window size in the sentence and obtained
a feature map, m 2 Rn(cid:0)h+1. As shown in Fig-
ure 1, we then apply a max pooling operation over
the feature map and obtain the maximum value
^m as a feature of this ﬁlter. We obtained multi-
ple ﬁlters by varying window sizes and multiple

1https://github.com/facebookresearch/fastText

Dataset
RCV1
Amazon670K

#L
4
9

Tr
23,149
490,449

Te
781,265
153,025

C
103
670,091

Table 1: Data Statistics: #L shows the depth of a hier-
archy. Tr and Te refer to the # of training and test data,
respectively. C indicates the total # of categories.

then utilize a constraint of a HS to obtain ﬁnal
results which differs from the existing work on
non-hierarchical ﬂat model (Johnson and Zhang,
2015a; Liu et al., 2017). This is done by using
two scoring functions: One is a Boolean Scoring
Function (BSF). Another is a Multiplicative Scor-
ing Function (MSF). Both functions set a thresh-
old value and categories whose scores exceed the
threshold value are considered for selection. The
difference is that BSF has a constraint that a cate-
gory can only be selected if its ancestor categories
are selected. MSF does not have such a constraint,
i.e., we extracted all the categories whose scores
exceeded the threshold value and sorted them in
descending order as the system’s assignments.

3 Experiments

3.1 Data and HFT-CNN model setting

We selected two benchmark datasets having a
HS from the extreme classiﬁcation repository2:
RCV1 (Lewis et al., 2004) and Amazon670K
(Leskovec and Krevl, 2015). All the documents in
RCV1 and item descriptions in Amazon670K are
tagged by using Tree Tagger (Schmid, 1995). We
used nouns, verbs, and adjectives. We then applied
fastText. Each dataset has an ofﬁcial training and
test sets. We used each fold in the experiments.
We choose titles from the training and test set on
RCV1. The maximum number of words in the ti-
tle was 13 words. Each text of Amazon670K con-
sists of a product name and its item description.
We extracted the ﬁrst 13 words from each item de-
scription and used them in the experiments. Table
1 presents the statistics on the datasets. We di-
vided the training data into two folds; we used 5%
to tuning the parameters, and the remains to train
the models. Our model setting is shown in Table
23. In the experiments, we run three times for each
model and obtained the averaged performance.

3.2 Evaluation Metrics

the precision at

We used the standard F1 measure. Furthermore,
we evaluated our method by two rank-based eval-
top k, P@k
uation metrics:
and the Normalized Discounted Cumulated Gains,
NDCG@k which are commonly used for com-
paring extreme multi-label classiﬁcation meth-
ods (Liu et al., 2017). We calculated P@k and
NDCG@k for each test data and then obtained an
average over all the test data.

3.3 Basic results

We compared HFT-CNN with a method which
has hierarchical-based categorization but without
ﬁne-tuning (WoFT-CNN) and Flat model to ex-
amine the effect of the ﬁne-tuning. WoFT-CNN
shows that we independently trained parameters
of CNN for each level and trained parameters are
not transferred. Flat means that we simply applied
our CNN model. The results are shown in Ta-
ble 3. The HFT-CNN is better than WoFT-CNN
and Flat model except for Micro-F1 obtained by
WoFT-CNN(M) in Amazon670K. We also found
that the overall results obtained by MSF were bet-
ter to those obtained by BSF.

3.4 Comparison with state-of-the-art method

We chose XML-CNN as a comparative method
because their method attained at the best or sec-
ond best compared to the seven existing methods
in six benchmark datasets (Liu et al., 2017). Origi-
nal XML-CNN is implemented by using Theano4,
while we implemented HFT-CNN by Chainer5. In
order to avoid the inﬂuence of differences in li-
braries, we implemented XML-CNN by Chainer
and compared it with HFT-CNN. We used the
author-provided implementation in Chainer’s ver-
sion of XML-CNN. We recall that we set convo-
lutional ﬁlters with the window sizes to (2,3,4)
and the stride size to 1 because of short text. To
make a fair comparison, we also evaluated XML-
CNN with the same window sizes and stride size
as HFT-CNN.

Liu et al. evaluated their method by using P@k
and NDCG@k. We used their metrics as well as
F1 measure. We did not set a threshold value on
BSF and MSF when we evaluated by using these
metrics, but instead, we used a ranked list of cate-

2manikvarma.org/downloads/XC/XMLRepository.html
3Our source code including Chainer’s version of XML-
CNN is available at: HTTP://github.com/ShimShim46/HFT-
CNN.

ZNywa94c2-iEh 6U/view
5https://chainer.org

4https://drive.google.com/ﬁle/d/1Wwy1MNkrJRXZM3WN

Description
Input word vectors
Stride size
Filters
Pooling
Dropout rate1
Hidden layers
Learning rate
Loss function

Values
fastText
1
128 (cid:2) 3
1-max pooling
0.25
1,024
Predicted by Adam
BCE loss over sigmoid activation

Description
Filter region size
Feature maps (m)
Activation function
Dropout
Dropout rate2
Batch sizes
Epoch
Threshold value for BSF and MSF

Values
(2,3,4)
128
ReLu
Randomly selected
0.5
100
40 with early stopping
0.5

Table 2: HFT-CNN model settings: Dropout rate1 shows dropout immediately after embedding layer, and Dropout
rate2 refers to dropout in a fully connected layer.

Metric
F1
Micro
Macro

HFT(B) WoFT(B) HFT(M) WoFT(M)

RCV1

79.87
50.31

79.69
49.59

80.29
51.40

Amazon670K

Flat
80.06 79.51
50.64 47.71

Metrics HFT(B) WoFT(B) HFT(M) WoFT(M)
50.12
Micro
6.37
Macro

Flat
50.94 49.10
5.73
8.68

(cid:3)50.94
9.87

49.74
6.78

Table 3: Basic results: (B) and (M) refer to a BSF
and MSF, respectively. Bold font shows the best result
within each line. The method marked with “(cid:3)” indi-
cates the score is not statistically signiﬁcant compared
to the best one. We used a t-test, p-value < 0.05.

gories assigned to the test instance. The results are
shown in Table 4. HFT-CNN with BSF/MSF has
the best scores with statistical signiﬁcance com-
pared to both of the XML-CNNs. On RCV1,
HFT-CNN(B) in P@1 and NDCG@1 were worse
than XML-CNN(1), while HFT-CNN(M) with the
same metrics were statistically signiﬁcant com-
pared to XML-CNN(1). This is not surprising be-
cause hierarchical ﬁne-tuning does not contribute
to the accuracy at the top level as the trained pa-
rameters on the top level have not changed in the
level.

We also examined the affection on each system
performance by the depth of a hierarchical struc-
ture. Figure 2 shows Micro-F1 at each hierarchi-
cal level. The deeper the hierarchical level, the
worse the system’s performance. However, HFT-
CNN is still better than XML-CNNs. The im-
provement by MSF was 1.00 (cid:24) 1.34% by Micro-
F1 and 3.77 (cid:24) 10.07% by Macro-F1 on RCV1.
On Amazon670K, the improvement was 1.10 (cid:24)
9.26% by Micro-F1 and 1.10 (cid:24) 3.60% by Macro-
F1. This shows that hierarchical ﬁne-tuning ﬁts to
learn the hierarchical category structure.

We recall that we focused on the multi-label
Figures 3 illustrates Micro-F1 and
problem.
Macro-F1 against the number of categories per
short text. We can see from RCV1 in Figure 3

Metric

P@1
P@3
P@5
G@1
G@3
G@5

Metric

P@1
P@3
P@5
G@1
G@3
G@5

92.93
77.18
53.85
92.93
88.16
89.19

92.60
(cid:3)77.56
(cid:3)53.96
92.60
(cid:3)88.47
89.37

RCV1
HFT(B) HFT(M) XML(1) XML(2)
92.55
76.80
53.60
92.55
87.75
88.80

93.29
77.70
54.23
93.29
88.79
89.81
Amazon670K
HFT(B) HFT(M) XML(1) XML(2)
84.12
64.48
49.75
84.12
74.13
70.74

85.39
65.34
(cid:3)50.84
85.39
75.05
71.46

86.54
66.25
51.09
86.54
76.26
72.84

84.62
64.83
49.93
84.62
74.50
70.99

Table 4: Comparative results: “1” and “2” of XML
show the stride size=1 and 2 by XML-CNN, respec-
tively. “G” stands for NDCG.

that Micro-F1 obtained by HFT-CNN and XML-
CNNs were not statistically signiﬁcant difference
in the number of categories, while Macro-F1 by
HFT-CNN except for the number of 13 categories
was constantly better to XML-CNNs. On Ama-
zon670K data, when the number of categories as-
signed to the short text is less than 38, HFT-CNN
was better than XML-CNNs or HFT-CNN was not
statistically signiﬁcant compared to XML-CNNs
by both F1-scores. However, when it exceeds 39,
HFT-CNN was worse than XML-CNNs. One pos-
sible reason is the use of BSF: a category can only
be selected if its ancestor categories are selected.
Therefore, once the test data could not be classi-
ﬁed into categories correctly, their child categories
also cannot be correctly assigned to the test data.
In contrast, as shown in Figure 5, HFT-CNN by
MSF was better than XML-CNNs in both Micro
and Macro F1 even in the deep level of a hierarchy.
From the observations, a robust scoring function is
needed for further improvement.

It is important to note that how the ratio of
training data affects the overall performance as
we focused on the data sparsity problem. Figure

(a) Micro-F1 (RCV1)

(b) Macro-F1(RCV1)

(c) Micro-F1 (Amazon670K)

(d) Macro-F1 (Amazon670K)

Figure 2: Performance in each hierarchical level: HFT-CNN used BSF

(a) Micro-F1 (RCV1)

(b) Macro-F1 (RCV1)

(c) Micro-F1 (Amazon670K)

(d) Macro-F1 (Amazon670K)

Figure 3: Performance against the # of categories per short text: HFT-CNN used BSF

(a) Micro-F1 (RCV1)

(b) Macro-F1 (RCV1)

(c) Micro-F1 (Amazon670K)

(d) Macro-F1 (Amazon670K)

Figure 4: Performance against a ratio of the training data

4 Conclusion

We have presented an approach to multi-label cat-
egorization for short text. The comparative re-
sults with XML-CNN showed that HFT-CNN is
competitive, especially for the cases that there ex-
ists only a small amount of training data. Fu-
ture work will include: (i) incorporating lexical
semantics such as named entities and domain-
speciﬁc senses for further improvement, (ii) ex-
tending the method to utilize label dependency
constraints (Bi and Kwok, 2011), and (iii) improv-
ing the accuracy of the top ranking categories to
deal with P@1 and NDCG@1 metrics.

Acknowledgments

We would like to thank the anonymous review-
ers for their helpful comments. This work is sup-
ported in part by Support Center for Advanced
Telecommunications Technology Research, Foun-
dation and the Grant-in-aid for the Japan Society
for the Promotion of Science, No.17K00299.

(a) Micro-F1 (Amazon670K) (b) Macro-F1 (Amazon670K)

Figure 5: Performance against the # of categories per
short text: Comparison with HFT-CNN by MSF and
other methods

4 shows Micro and Macro-F1 against a ratio of
the training data. Overall, the curves show that
more training helps the performance, while the
curves obtained by HFT-CNN drop slowly com-
pared to other methods in both datasets and evalu-
ation metrics. From the observations mentioned in
the above, we can conclude that ﬁne-tuning works
well, especially in the cases that the number of the
training data per category is small.

References

W. Bi and J. T. Kwok. 2011. Multi-Label Classiﬁca-
tion on Tree- and DAG-Structured Hierarchies. In
Proc. of the 28th Internation Conference on Math-
ine Learning, pages 17–24.

M. Chen, X. Jin, and D. Shen. 2011. Short Text Clas-
siﬁcation Improved by Learning Multi-Granularity
In Proc. of the 22nd International Joint
Topics.
Conference on Artiﬁcial Intelligence, pages 1776–
1781.

G. E. Hinton, N. Srivastava, A. Krizhevsky,
H. Sutskever, and R. R. Salakhutdinov. 2012.
Improving Neural Networks by Preventing Co-
Adaptation of Feature Detectors. In arXiv preprint
arXiv:1207.0580.

R. Johnson and T. Zhang. 2015a. Effective Use of
Word Order for Text Categorization with Convolu-
tional Neural Networks. In Proc of the 2015 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, pages 103–112.

R. Johnson and T. Zhang. 2015b. Semi-Supervised
Convolutional Neural Networks for Text Catego-
rization vis Region Embedding. Advances in Neural
Information Processing Systems, 28:919–927.

A. Joulin, E. Grave, P. Bojanowski, and T. Mikolov.
2017. Bag of Tricks for Efﬁcient Text Classiﬁca-
tion. In Proc. of the 15th Conference of the Euro-
pean Chapter of the Association for Conputational
Linguistics, pages 427–431.

Y. Kim. 2014. Convolutional Neural Networks for Sen-
In Proc. of the 2014 Confer-
tence Classiﬁcation.
ence on Empirical Methods in Natural Language
Processing, pages 1746–1751.

J. Y. Lee and F. Dernoncourt. 2016. Sequential Short-
Text classiﬁcation with Recurrent and Convolu-
tional Neural Networks. In Proc. of the 2016 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics Human Lan-
guage Technologies, pages 515–520.

J. Leskovec and A. Krevl. 2015. SNAP Datasets: Stan-

ford Large Network Dataset Collection.

D. D. Lewis, Y. Yang, T. G. Rose, and F. Li. 2004.
RCV1: A New Benchmark Collection for Text Cat-
egorization Research. Journal of Machine Learning
Research, 5:361–397.

J. Liu, W-C. Chang, Y. Wu, and Y. Yang. 2017. Deep
Learning for Extreme Multi-Label Text Classiﬁca-
tion. In Proc. of the 40th International ACM SIGIR
Conference on Research and Development in Infor-
mation Retrieval, pages 115–124.

X. H. Phan, L. M. Nguyen, and S. Horiguchi. 2008.
Learning to Classify Short and Sparse Text & Web

with Hidden Topics from Large-Scale Data Collec-
tions. In Proc. of the 17th International World Wide
Web Conference, pages 91–100.

H. Schmid. 1995.

Tagging with an Application to German.
of the EACL SIGDAT Workshop, pages 47–50.

Improvements in Part-of-Speech
In Proc.

G. Song, Y. Ye, X. Du, X. Huang, and S. Bie. 2014.
Short Text Classiﬁcation: A Survey. Multimedia,
9(5):635–643.

F. Wang, Z. Wang, Z. Li, and J-R. Wen. 2008. Concept-
Based Short Text Classiﬁcation and Ranking.
In
Proc. of the 23rd ACM International Conference
on Information and Knowledge Management, pages
1069–1078.

J. Wang, Z. Wang, D. Zhang, and J. Yan. 2017. Com-
bining Knowledge with Deep Convolutional Neural
Networks for Short Text Classiﬁcation. In Proc. of
the 26th International Joint Conference on Artiﬁcial
Intelligence, pages 2915–2921.

P. Wang, J. Xu, B. Xu, C-L. Liu, H. Zhang, F. Wang,
and H. Hao. 2015. Semantic Clustering and Con-
volutional Neural Network for Short Text Catego-
rization. In Proc. of the 53rd Annual Meeting of the
Association for Computational Linguistics and the
7th International Joint Conference on Natural Lan-
guage Processing, pages 352–357.

W. Wu, H. Li, H. Wang, and K. Q. Zhu. 2012. A
Probabilistic Taxonomy for Text Understanding. In
Proc. of the 2012 ACM SIGMOD International Con-
ference on Management of Data, pages 481–492.

Z. Yang, D. Yang, C. Dyer, X. He, A. Smola, and
E. Hovy. 2016. Hierarchical Attention Networks for
Document Classiﬁcation. In Proc. of the 2016 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics Human Lan-
guage Technologies, pages 1480–1489.

R. Zhang, H. Lee, and D. Radev. 2016. Dependency
Sensitive Convolutional Neural Networks for Mod-
In Proc. of the
eling Sentences and Documents.
2016 Conference of the North American Chapter of
the Association for Computational Linguistics Hu-
man Language Technologies, pages 1512–1521.

Y. Zhang, M. Lease, and B. C. Wallace. 2017. Ex-
ploiting Domain Knowledge via Grouped Weight
Sharing with Application to Text Categorization. In
Proc. of the 55th Annual Meeting of the Association
for Computational Linguistics, pages 155–160.

Y. Zhang and B. C. Wallace. 2015. A Sensitivity Anal-
ysis of (and Practitioners’ Guide to) Convolutional
Neural Networks for Sentence Classiﬁcation.
In
Proc. of the 8th International Joint Conference on
Natural Language Processing, pages 253–263.

HFT-CNN: Learning Hierarchical Category Structure for Multi-label
Short Text Categorization

Kazuya Shimura1, Jiyi Li2 and Fumiyo Fukumoto2
Graduate School of Engineering1
Interdisciplinary Graduate School2
University of Yamanashi
4-3-11, Takeda, Kofu, 400-8511 Japan
fg17tk008,jyli,fukumotog@yamanashi.ac.jp

Abstract

We focus on the multi-label categorization task
for short texts and explore the use of a hierar-
chical structure (HS) of categories. In contrast
to the existing work using non-hierarchical ﬂat
model, the method leverages the hierarchical
relations between the categories to tackle the
data sparsity problem. The lower the HS level,
the worse the categorization performance. Be-
cause lower categories are ﬁne-grained and the
amount of training data per category is much
smaller than that in an upper level. We propose
an approach which can effectively utilize the
data in the upper levels to contribute catego-
rization in the lower levels by applying a Con-
volutional Neural Network (CNN) with a ﬁne-
tuning technique. The results using two bench-
mark datasets show that the proposed method,
Hierarchical Fine-Tuning based CNN (HFT-
CNN) is competitive with the state-of-the-art
CNN based methods.

1

Introduction

Major attempts

Short text categorization is widely studied since
the recent explosive growth of online social net-
working applications (Song et al., 2014).
In
texts are less
contrast with documents, short
to
topic-focused in texts.
tackle the problem is to expand short
texts
with knowledge extracted from the textual cor-
pus, machine-readable dictionaries, and thesauri
(Phan et al., 2008; Wang et al., 2008; Chen et al.,
2011; Wu et al., 2012). However, because of
domain-independent nature of dictionaries and
thesauri, it is often the case that the data distri-
bution of the external knowledge is different from
the test data collected from some speciﬁc domain,
which deteriorates the overall performance of cat-
egorization. A methodology which maximizes
the impact of pre-deﬁned domains/categories is
needed to improve categorization performance.

More recently, many authors have attempted
to apply deep learning techniques including CNN
(Wang et al., 2015; Zhang and Wallace, 2015;
Zhang et al., 2017; Wang et al., 2017), the atten-
tion based CNN (Yang et al., 2016), bag-of-words
based CNN (Johnson and Zhang, 2015a), and the
combination of CNN and recurrent neural network
(Lee and Dernoncourt, 2016; Zhang et al., 2016)
to text categorization. Most of them demon-
strated that neural network models are powerful
for learning features from texts, while they fo-
cused on single-label or a few labels problem.
Several efforts have been made to multi-labels
(Johnson and Zhang, 2015b; Liu et al., 2017). Liu
et al.
explored a family of new CNN models
which are tailored for extreme multi-label classi-
ﬁcation (Liu et al., 2017). They used a dynamic
max pooling scheme, a binary cross-entropy loss,
and a hidden bottleneck layer to improve the
overall performance. The results by using six
benchmark datasets where the label-set sizes are
up to 670K showed that their method attained
at the best or second best in comparison with
seven state-of-the-art methods including FastText
(Joulin et al., 2017) and bag-of-words based CNN
(Johnson and Zhang, 2015a). However, all of
these attempts aimed at utilizing a large volume
of data.

We address the problem of multi-label short text
categorization and explore the use of a HS of cat-
egories. The lower level of categories are ﬁne-
grained compared to the upper level of categories.
Moreover, it is often the case that the amount of
training data in a lower level is much smaller than
that in an upper level which deteriorates the over-
all performance of categorization. We propose
an approach which can effectively utilize the data
in the upper levels to contribute categorization in
lower levels by applying ﬁne-tuning to the CNN
which can learn a HS of categories and incorporate

features. These features form a pooling layer and
are passed to a fully connected layer. In the fully
connected layer, we applied dropout (Hinton et al.,
2012). The dropout randomly sets values in the
layer to 0. Finally, we obtained the probability dis-
tribution over categories. The network is trained
with the objective that minimizes the binary cross-
entropy (BCE) of the predicted distributions and
the actual distributions by performing stochastic
gradient descent.

2.2 Hierarchical structure learning

Our key idea is to use a ﬁne-tuning technique in
CNN to tackle the data sparsity problem, espe-
cially a lower level of a HS. Following a HS, we
transferred the parameters of CNN trained in the
upper levels to the lower levels which are worse
trained because of the lack of data, and then ﬁnely
tuned parameters of CNN for lower levels (Figure
1). This approach can effectively utilize the data
in the upper levels to contribute categorization in
the lower levels.

Fine-tuning is motivated by the observation that
the earlier features of CNN contain more generic
features that should be effective for many tasks,
but later layers of the CNN becomes progressively
more speciﬁc to the details of the classes contained
in the original dataset. The motivation is identical
to a HS of categories as we ﬁrst learn to distinguish
among generic categories at the upper level of a
hierarchy, then learns lower level distinctions by
using only within the appropriate top level of the
HS. We note that ﬁne-tuning the last few layers are
usually sufﬁcient for transfer learning as the last
few layers become more speciﬁc features. How-
ever, the HS consisting of deep level needs to ﬁne-
tune the early layers as well because the distance
between the upper and lower level of categories
is signiﬁcant. For this reason, we transferred two
layers shown in Figure 1, i.e., a layer obtained by
word embedding and the convolutional layer. We
used them as an initial parameter to learn the sec-
ond level of a hierarchy. We repeated this pro-
cedure from the top level to the bottom level of
a hierarchy. We note that a HS consists of many
levels. We ﬁne-tune between adjacent layers only
because they are more correlated with each other
compared to distant layers.

2.3 Multi-label categorization

Each test instance is classiﬁed into categories with
probabilities/scores by applying HFT-CNN. We

Figure 1: HFT-CNN model

granularity of categories into categorization. We
transferred the parameters of CNN trained from
upper to lower levels according to the HS, and
ﬁnely tuned parameters. The main contributions
of our work can be summarized: (1) We propose a
method that maximizes the impact of pre-deﬁned
categories to alleviate data sparsity in multi-label
short texts. (2) We empirically examined a ﬁne-
tuning with CNN that ﬁts to learn a HS of cate-
gories deﬁned by lexicographers, and (3) The re-
sults show that our method is competitive to the
state-of-the-art CNN based methods by using two
benchmark datasets, especially it is effective for
categorization of short texts consisting of a few
words with a large number of labels.

2 Hierarchical Fine-Tuning based CNN

2.1 CNN architecture

Similar to other CNN (Johnson and Zhang, 2015a;
Liu et al., 2017), our HFT-CNN model shown in
Figure 1 is based on (Kim, 2014). Let xi 2 Rk be
the k-dimensional word vector with the i-th word
in a sentence obtained by applying skip-gram
model provided in fastText1. A sentence with
length n is represented as x1:n = [x1; x2; (cid:1) (cid:1) (cid:1) ; xn]
2 Rnk. A convolution ﬁlter w 2 Rhk is applied
to a window size of h words to produce a new fea-
ture, ci = f (w(cid:1)xi:i+h(cid:0)1 +b) where b 2 R indicates
a bias term and f refers to a non-linear activation
function. We applied this convolution ﬁlter to each
possible window size in the sentence and obtained
a feature map, m 2 Rn(cid:0)h+1. As shown in Fig-
ure 1, we then apply a max pooling operation over
the feature map and obtain the maximum value
^m as a feature of this ﬁlter. We obtained multi-
ple ﬁlters by varying window sizes and multiple

1https://github.com/facebookresearch/fastText

Dataset
RCV1
Amazon670K

#L
4
9

Tr
23,149
490,449

Te
781,265
153,025

C
103
670,091

Table 1: Data Statistics: #L shows the depth of a hier-
archy. Tr and Te refer to the # of training and test data,
respectively. C indicates the total # of categories.

then utilize a constraint of a HS to obtain ﬁnal
results which differs from the existing work on
non-hierarchical ﬂat model (Johnson and Zhang,
2015a; Liu et al., 2017). This is done by using
two scoring functions: One is a Boolean Scoring
Function (BSF). Another is a Multiplicative Scor-
ing Function (MSF). Both functions set a thresh-
old value and categories whose scores exceed the
threshold value are considered for selection. The
difference is that BSF has a constraint that a cate-
gory can only be selected if its ancestor categories
are selected. MSF does not have such a constraint,
i.e., we extracted all the categories whose scores
exceeded the threshold value and sorted them in
descending order as the system’s assignments.

3 Experiments

3.1 Data and HFT-CNN model setting

We selected two benchmark datasets having a
HS from the extreme classiﬁcation repository2:
RCV1 (Lewis et al., 2004) and Amazon670K
(Leskovec and Krevl, 2015). All the documents in
RCV1 and item descriptions in Amazon670K are
tagged by using Tree Tagger (Schmid, 1995). We
used nouns, verbs, and adjectives. We then applied
fastText. Each dataset has an ofﬁcial training and
test sets. We used each fold in the experiments.
We choose titles from the training and test set on
RCV1. The maximum number of words in the ti-
tle was 13 words. Each text of Amazon670K con-
sists of a product name and its item description.
We extracted the ﬁrst 13 words from each item de-
scription and used them in the experiments. Table
1 presents the statistics on the datasets. We di-
vided the training data into two folds; we used 5%
to tuning the parameters, and the remains to train
the models. Our model setting is shown in Table
23. In the experiments, we run three times for each
model and obtained the averaged performance.

3.2 Evaluation Metrics

the precision at

We used the standard F1 measure. Furthermore,
we evaluated our method by two rank-based eval-
top k, P@k
uation metrics:
and the Normalized Discounted Cumulated Gains,
NDCG@k which are commonly used for com-
paring extreme multi-label classiﬁcation meth-
ods (Liu et al., 2017). We calculated P@k and
NDCG@k for each test data and then obtained an
average over all the test data.

3.3 Basic results

We compared HFT-CNN with a method which
has hierarchical-based categorization but without
ﬁne-tuning (WoFT-CNN) and Flat model to ex-
amine the effect of the ﬁne-tuning. WoFT-CNN
shows that we independently trained parameters
of CNN for each level and trained parameters are
not transferred. Flat means that we simply applied
our CNN model. The results are shown in Ta-
ble 3. The HFT-CNN is better than WoFT-CNN
and Flat model except for Micro-F1 obtained by
WoFT-CNN(M) in Amazon670K. We also found
that the overall results obtained by MSF were bet-
ter to those obtained by BSF.

3.4 Comparison with state-of-the-art method

We chose XML-CNN as a comparative method
because their method attained at the best or sec-
ond best compared to the seven existing methods
in six benchmark datasets (Liu et al., 2017). Origi-
nal XML-CNN is implemented by using Theano4,
while we implemented HFT-CNN by Chainer5. In
order to avoid the inﬂuence of differences in li-
braries, we implemented XML-CNN by Chainer
and compared it with HFT-CNN. We used the
author-provided implementation in Chainer’s ver-
sion of XML-CNN. We recall that we set convo-
lutional ﬁlters with the window sizes to (2,3,4)
and the stride size to 1 because of short text. To
make a fair comparison, we also evaluated XML-
CNN with the same window sizes and stride size
as HFT-CNN.

Liu et al. evaluated their method by using P@k
and NDCG@k. We used their metrics as well as
F1 measure. We did not set a threshold value on
BSF and MSF when we evaluated by using these
metrics, but instead, we used a ranked list of cate-

2manikvarma.org/downloads/XC/XMLRepository.html
3Our source code including Chainer’s version of XML-
CNN is available at: HTTP://github.com/ShimShim46/HFT-
CNN.

ZNywa94c2-iEh 6U/view
5https://chainer.org

4https://drive.google.com/ﬁle/d/1Wwy1MNkrJRXZM3WN

Description
Input word vectors
Stride size
Filters
Pooling
Dropout rate1
Hidden layers
Learning rate
Loss function

Values
fastText
1
128 (cid:2) 3
1-max pooling
0.25
1,024
Predicted by Adam
BCE loss over sigmoid activation

Description
Filter region size
Feature maps (m)
Activation function
Dropout
Dropout rate2
Batch sizes
Epoch
Threshold value for BSF and MSF

Values
(2,3,4)
128
ReLu
Randomly selected
0.5
100
40 with early stopping
0.5

Table 2: HFT-CNN model settings: Dropout rate1 shows dropout immediately after embedding layer, and Dropout
rate2 refers to dropout in a fully connected layer.

Metric
F1
Micro
Macro

HFT(B) WoFT(B) HFT(M) WoFT(M)

RCV1

79.87
50.31

79.69
49.59

80.29
51.40

Amazon670K

Flat
80.06 79.51
50.64 47.71

Metrics HFT(B) WoFT(B) HFT(M) WoFT(M)
50.12
Micro
6.37
Macro

Flat
50.94 49.10
5.73
8.68

(cid:3)50.94
9.87

49.74
6.78

Table 3: Basic results: (B) and (M) refer to a BSF
and MSF, respectively. Bold font shows the best result
within each line. The method marked with “(cid:3)” indi-
cates the score is not statistically signiﬁcant compared
to the best one. We used a t-test, p-value < 0.05.

gories assigned to the test instance. The results are
shown in Table 4. HFT-CNN with BSF/MSF has
the best scores with statistical signiﬁcance com-
pared to both of the XML-CNNs. On RCV1,
HFT-CNN(B) in P@1 and NDCG@1 were worse
than XML-CNN(1), while HFT-CNN(M) with the
same metrics were statistically signiﬁcant com-
pared to XML-CNN(1). This is not surprising be-
cause hierarchical ﬁne-tuning does not contribute
to the accuracy at the top level as the trained pa-
rameters on the top level have not changed in the
level.

We also examined the affection on each system
performance by the depth of a hierarchical struc-
ture. Figure 2 shows Micro-F1 at each hierarchi-
cal level. The deeper the hierarchical level, the
worse the system’s performance. However, HFT-
CNN is still better than XML-CNNs. The im-
provement by MSF was 1.00 (cid:24) 1.34% by Micro-
F1 and 3.77 (cid:24) 10.07% by Macro-F1 on RCV1.
On Amazon670K, the improvement was 1.10 (cid:24)
9.26% by Micro-F1 and 1.10 (cid:24) 3.60% by Macro-
F1. This shows that hierarchical ﬁne-tuning ﬁts to
learn the hierarchical category structure.

We recall that we focused on the multi-label
Figures 3 illustrates Micro-F1 and
problem.
Macro-F1 against the number of categories per
short text. We can see from RCV1 in Figure 3

Metric

P@1
P@3
P@5
G@1
G@3
G@5

Metric

P@1
P@3
P@5
G@1
G@3
G@5

92.93
77.18
53.85
92.93
88.16
89.19

92.60
(cid:3)77.56
(cid:3)53.96
92.60
(cid:3)88.47
89.37

RCV1
HFT(B) HFT(M) XML(1) XML(2)
92.55
76.80
53.60
92.55
87.75
88.80

93.29
77.70
54.23
93.29
88.79
89.81
Amazon670K
HFT(B) HFT(M) XML(1) XML(2)
84.12
64.48
49.75
84.12
74.13
70.74

85.39
65.34
(cid:3)50.84
85.39
75.05
71.46

86.54
66.25
51.09
86.54
76.26
72.84

84.62
64.83
49.93
84.62
74.50
70.99

Table 4: Comparative results: “1” and “2” of XML
show the stride size=1 and 2 by XML-CNN, respec-
tively. “G” stands for NDCG.

that Micro-F1 obtained by HFT-CNN and XML-
CNNs were not statistically signiﬁcant difference
in the number of categories, while Macro-F1 by
HFT-CNN except for the number of 13 categories
was constantly better to XML-CNNs. On Ama-
zon670K data, when the number of categories as-
signed to the short text is less than 38, HFT-CNN
was better than XML-CNNs or HFT-CNN was not
statistically signiﬁcant compared to XML-CNNs
by both F1-scores. However, when it exceeds 39,
HFT-CNN was worse than XML-CNNs. One pos-
sible reason is the use of BSF: a category can only
be selected if its ancestor categories are selected.
Therefore, once the test data could not be classi-
ﬁed into categories correctly, their child categories
also cannot be correctly assigned to the test data.
In contrast, as shown in Figure 5, HFT-CNN by
MSF was better than XML-CNNs in both Micro
and Macro F1 even in the deep level of a hierarchy.
From the observations, a robust scoring function is
needed for further improvement.

It is important to note that how the ratio of
training data affects the overall performance as
we focused on the data sparsity problem. Figure

(a) Micro-F1 (RCV1)

(b) Macro-F1(RCV1)

(c) Micro-F1 (Amazon670K)

(d) Macro-F1 (Amazon670K)

Figure 2: Performance in each hierarchical level: HFT-CNN used BSF

(a) Micro-F1 (RCV1)

(b) Macro-F1 (RCV1)

(c) Micro-F1 (Amazon670K)

(d) Macro-F1 (Amazon670K)

Figure 3: Performance against the # of categories per short text: HFT-CNN used BSF

(a) Micro-F1 (RCV1)

(b) Macro-F1 (RCV1)

(c) Micro-F1 (Amazon670K)

(d) Macro-F1 (Amazon670K)

Figure 4: Performance against a ratio of the training data

4 Conclusion

We have presented an approach to multi-label cat-
egorization for short text. The comparative re-
sults with XML-CNN showed that HFT-CNN is
competitive, especially for the cases that there ex-
ists only a small amount of training data. Fu-
ture work will include: (i) incorporating lexical
semantics such as named entities and domain-
speciﬁc senses for further improvement, (ii) ex-
tending the method to utilize label dependency
constraints (Bi and Kwok, 2011), and (iii) improv-
ing the accuracy of the top ranking categories to
deal with P@1 and NDCG@1 metrics.

Acknowledgments

We would like to thank the anonymous review-
ers for their helpful comments. This work is sup-
ported in part by Support Center for Advanced
Telecommunications Technology Research, Foun-
dation and the Grant-in-aid for the Japan Society
for the Promotion of Science, No.17K00299.

(a) Micro-F1 (Amazon670K) (b) Macro-F1 (Amazon670K)

Figure 5: Performance against the # of categories per
short text: Comparison with HFT-CNN by MSF and
other methods

4 shows Micro and Macro-F1 against a ratio of
the training data. Overall, the curves show that
more training helps the performance, while the
curves obtained by HFT-CNN drop slowly com-
pared to other methods in both datasets and evalu-
ation metrics. From the observations mentioned in
the above, we can conclude that ﬁne-tuning works
well, especially in the cases that the number of the
training data per category is small.

References

W. Bi and J. T. Kwok. 2011. Multi-Label Classiﬁca-
tion on Tree- and DAG-Structured Hierarchies. In
Proc. of the 28th Internation Conference on Math-
ine Learning, pages 17–24.

M. Chen, X. Jin, and D. Shen. 2011. Short Text Clas-
siﬁcation Improved by Learning Multi-Granularity
In Proc. of the 22nd International Joint
Topics.
Conference on Artiﬁcial Intelligence, pages 1776–
1781.

G. E. Hinton, N. Srivastava, A. Krizhevsky,
H. Sutskever, and R. R. Salakhutdinov. 2012.
Improving Neural Networks by Preventing Co-
Adaptation of Feature Detectors. In arXiv preprint
arXiv:1207.0580.

R. Johnson and T. Zhang. 2015a. Effective Use of
Word Order for Text Categorization with Convolu-
tional Neural Networks. In Proc of the 2015 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, pages 103–112.

R. Johnson and T. Zhang. 2015b. Semi-Supervised
Convolutional Neural Networks for Text Catego-
rization vis Region Embedding. Advances in Neural
Information Processing Systems, 28:919–927.

A. Joulin, E. Grave, P. Bojanowski, and T. Mikolov.
2017. Bag of Tricks for Efﬁcient Text Classiﬁca-
tion. In Proc. of the 15th Conference of the Euro-
pean Chapter of the Association for Conputational
Linguistics, pages 427–431.

Y. Kim. 2014. Convolutional Neural Networks for Sen-
In Proc. of the 2014 Confer-
tence Classiﬁcation.
ence on Empirical Methods in Natural Language
Processing, pages 1746–1751.

J. Y. Lee and F. Dernoncourt. 2016. Sequential Short-
Text classiﬁcation with Recurrent and Convolu-
tional Neural Networks. In Proc. of the 2016 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics Human Lan-
guage Technologies, pages 515–520.

J. Leskovec and A. Krevl. 2015. SNAP Datasets: Stan-

ford Large Network Dataset Collection.

D. D. Lewis, Y. Yang, T. G. Rose, and F. Li. 2004.
RCV1: A New Benchmark Collection for Text Cat-
egorization Research. Journal of Machine Learning
Research, 5:361–397.

J. Liu, W-C. Chang, Y. Wu, and Y. Yang. 2017. Deep
Learning for Extreme Multi-Label Text Classiﬁca-
tion. In Proc. of the 40th International ACM SIGIR
Conference on Research and Development in Infor-
mation Retrieval, pages 115–124.

X. H. Phan, L. M. Nguyen, and S. Horiguchi. 2008.
Learning to Classify Short and Sparse Text & Web

with Hidden Topics from Large-Scale Data Collec-
tions. In Proc. of the 17th International World Wide
Web Conference, pages 91–100.

H. Schmid. 1995.

Tagging with an Application to German.
of the EACL SIGDAT Workshop, pages 47–50.

Improvements in Part-of-Speech
In Proc.

G. Song, Y. Ye, X. Du, X. Huang, and S. Bie. 2014.
Short Text Classiﬁcation: A Survey. Multimedia,
9(5):635–643.

F. Wang, Z. Wang, Z. Li, and J-R. Wen. 2008. Concept-
Based Short Text Classiﬁcation and Ranking.
In
Proc. of the 23rd ACM International Conference
on Information and Knowledge Management, pages
1069–1078.

J. Wang, Z. Wang, D. Zhang, and J. Yan. 2017. Com-
bining Knowledge with Deep Convolutional Neural
Networks for Short Text Classiﬁcation. In Proc. of
the 26th International Joint Conference on Artiﬁcial
Intelligence, pages 2915–2921.

P. Wang, J. Xu, B. Xu, C-L. Liu, H. Zhang, F. Wang,
and H. Hao. 2015. Semantic Clustering and Con-
volutional Neural Network for Short Text Catego-
rization. In Proc. of the 53rd Annual Meeting of the
Association for Computational Linguistics and the
7th International Joint Conference on Natural Lan-
guage Processing, pages 352–357.

W. Wu, H. Li, H. Wang, and K. Q. Zhu. 2012. A
Probabilistic Taxonomy for Text Understanding. In
Proc. of the 2012 ACM SIGMOD International Con-
ference on Management of Data, pages 481–492.

Z. Yang, D. Yang, C. Dyer, X. He, A. Smola, and
E. Hovy. 2016. Hierarchical Attention Networks for
Document Classiﬁcation. In Proc. of the 2016 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics Human Lan-
guage Technologies, pages 1480–1489.

R. Zhang, H. Lee, and D. Radev. 2016. Dependency
Sensitive Convolutional Neural Networks for Mod-
In Proc. of the
eling Sentences and Documents.
2016 Conference of the North American Chapter of
the Association for Computational Linguistics Hu-
man Language Technologies, pages 1512–1521.

Y. Zhang, M. Lease, and B. C. Wallace. 2017. Ex-
ploiting Domain Knowledge via Grouped Weight
Sharing with Application to Text Categorization. In
Proc. of the 55th Annual Meeting of the Association
for Computational Linguistics, pages 155–160.

Y. Zhang and B. C. Wallace. 2015. A Sensitivity Anal-
ysis of (and Practitioners’ Guide to) Convolutional
Neural Networks for Sentence Classiﬁcation.
In
Proc. of the 8th International Joint Conference on
Natural Language Processing, pages 253–263.

HFT-CNN: Learning Hierarchical Category Structure for Multi-label
Short Text Categorization

Kazuya Shimura1, Jiyi Li2 and Fumiyo Fukumoto2
Graduate School of Engineering1
Interdisciplinary Graduate School2
University of Yamanashi
4-3-11, Takeda, Kofu, 400-8511 Japan
fg17tk008,jyli,fukumotog@yamanashi.ac.jp

Abstract

We focus on the multi-label categorization task
for short texts and explore the use of a hierar-
chical structure (HS) of categories. In contrast
to the existing work using non-hierarchical ﬂat
model, the method leverages the hierarchical
relations between the categories to tackle the
data sparsity problem. The lower the HS level,
the worse the categorization performance. Be-
cause lower categories are ﬁne-grained and the
amount of training data per category is much
smaller than that in an upper level. We propose
an approach which can effectively utilize the
data in the upper levels to contribute catego-
rization in the lower levels by applying a Con-
volutional Neural Network (CNN) with a ﬁne-
tuning technique. The results using two bench-
mark datasets show that the proposed method,
Hierarchical Fine-Tuning based CNN (HFT-
CNN) is competitive with the state-of-the-art
CNN based methods.

1

Introduction

Major attempts

Short text categorization is widely studied since
the recent explosive growth of online social net-
working applications (Song et al., 2014).
In
texts are less
contrast with documents, short
to
topic-focused in texts.
tackle the problem is to expand short
texts
with knowledge extracted from the textual cor-
pus, machine-readable dictionaries, and thesauri
(Phan et al., 2008; Wang et al., 2008; Chen et al.,
2011; Wu et al., 2012). However, because of
domain-independent nature of dictionaries and
thesauri, it is often the case that the data distri-
bution of the external knowledge is different from
the test data collected from some speciﬁc domain,
which deteriorates the overall performance of cat-
egorization. A methodology which maximizes
the impact of pre-deﬁned domains/categories is
needed to improve categorization performance.

More recently, many authors have attempted
to apply deep learning techniques including CNN
(Wang et al., 2015; Zhang and Wallace, 2015;
Zhang et al., 2017; Wang et al., 2017), the atten-
tion based CNN (Yang et al., 2016), bag-of-words
based CNN (Johnson and Zhang, 2015a), and the
combination of CNN and recurrent neural network
(Lee and Dernoncourt, 2016; Zhang et al., 2016)
to text categorization. Most of them demon-
strated that neural network models are powerful
for learning features from texts, while they fo-
cused on single-label or a few labels problem.
Several efforts have been made to multi-labels
(Johnson and Zhang, 2015b; Liu et al., 2017). Liu
et al.
explored a family of new CNN models
which are tailored for extreme multi-label classi-
ﬁcation (Liu et al., 2017). They used a dynamic
max pooling scheme, a binary cross-entropy loss,
and a hidden bottleneck layer to improve the
overall performance. The results by using six
benchmark datasets where the label-set sizes are
up to 670K showed that their method attained
at the best or second best in comparison with
seven state-of-the-art methods including FastText
(Joulin et al., 2017) and bag-of-words based CNN
(Johnson and Zhang, 2015a). However, all of
these attempts aimed at utilizing a large volume
of data.

We address the problem of multi-label short text
categorization and explore the use of a HS of cat-
egories. The lower level of categories are ﬁne-
grained compared to the upper level of categories.
Moreover, it is often the case that the amount of
training data in a lower level is much smaller than
that in an upper level which deteriorates the over-
all performance of categorization. We propose
an approach which can effectively utilize the data
in the upper levels to contribute categorization in
lower levels by applying ﬁne-tuning to the CNN
which can learn a HS of categories and incorporate

features. These features form a pooling layer and
are passed to a fully connected layer. In the fully
connected layer, we applied dropout (Hinton et al.,
2012). The dropout randomly sets values in the
layer to 0. Finally, we obtained the probability dis-
tribution over categories. The network is trained
with the objective that minimizes the binary cross-
entropy (BCE) of the predicted distributions and
the actual distributions by performing stochastic
gradient descent.

2.2 Hierarchical structure learning

Our key idea is to use a ﬁne-tuning technique in
CNN to tackle the data sparsity problem, espe-
cially a lower level of a HS. Following a HS, we
transferred the parameters of CNN trained in the
upper levels to the lower levels which are worse
trained because of the lack of data, and then ﬁnely
tuned parameters of CNN for lower levels (Figure
1). This approach can effectively utilize the data
in the upper levels to contribute categorization in
the lower levels.

Fine-tuning is motivated by the observation that
the earlier features of CNN contain more generic
features that should be effective for many tasks,
but later layers of the CNN becomes progressively
more speciﬁc to the details of the classes contained
in the original dataset. The motivation is identical
to a HS of categories as we ﬁrst learn to distinguish
among generic categories at the upper level of a
hierarchy, then learns lower level distinctions by
using only within the appropriate top level of the
HS. We note that ﬁne-tuning the last few layers are
usually sufﬁcient for transfer learning as the last
few layers become more speciﬁc features. How-
ever, the HS consisting of deep level needs to ﬁne-
tune the early layers as well because the distance
between the upper and lower level of categories
is signiﬁcant. For this reason, we transferred two
layers shown in Figure 1, i.e., a layer obtained by
word embedding and the convolutional layer. We
used them as an initial parameter to learn the sec-
ond level of a hierarchy. We repeated this pro-
cedure from the top level to the bottom level of
a hierarchy. We note that a HS consists of many
levels. We ﬁne-tune between adjacent layers only
because they are more correlated with each other
compared to distant layers.

2.3 Multi-label categorization

Each test instance is classiﬁed into categories with
probabilities/scores by applying HFT-CNN. We

Figure 1: HFT-CNN model

granularity of categories into categorization. We
transferred the parameters of CNN trained from
upper to lower levels according to the HS, and
ﬁnely tuned parameters. The main contributions
of our work can be summarized: (1) We propose a
method that maximizes the impact of pre-deﬁned
categories to alleviate data sparsity in multi-label
short texts. (2) We empirically examined a ﬁne-
tuning with CNN that ﬁts to learn a HS of cate-
gories deﬁned by lexicographers, and (3) The re-
sults show that our method is competitive to the
state-of-the-art CNN based methods by using two
benchmark datasets, especially it is effective for
categorization of short texts consisting of a few
words with a large number of labels.

2 Hierarchical Fine-Tuning based CNN

2.1 CNN architecture

Similar to other CNN (Johnson and Zhang, 2015a;
Liu et al., 2017), our HFT-CNN model shown in
Figure 1 is based on (Kim, 2014). Let xi 2 Rk be
the k-dimensional word vector with the i-th word
in a sentence obtained by applying skip-gram
model provided in fastText1. A sentence with
length n is represented as x1:n = [x1; x2; (cid:1) (cid:1) (cid:1) ; xn]
2 Rnk. A convolution ﬁlter w 2 Rhk is applied
to a window size of h words to produce a new fea-
ture, ci = f (w(cid:1)xi:i+h(cid:0)1 +b) where b 2 R indicates
a bias term and f refers to a non-linear activation
function. We applied this convolution ﬁlter to each
possible window size in the sentence and obtained
a feature map, m 2 Rn(cid:0)h+1. As shown in Fig-
ure 1, we then apply a max pooling operation over
the feature map and obtain the maximum value
^m as a feature of this ﬁlter. We obtained multi-
ple ﬁlters by varying window sizes and multiple

1https://github.com/facebookresearch/fastText

Dataset
RCV1
Amazon670K

#L
4
9

Tr
23,149
490,449

Te
781,265
153,025

C
103
670,091

Table 1: Data Statistics: #L shows the depth of a hier-
archy. Tr and Te refer to the # of training and test data,
respectively. C indicates the total # of categories.

then utilize a constraint of a HS to obtain ﬁnal
results which differs from the existing work on
non-hierarchical ﬂat model (Johnson and Zhang,
2015a; Liu et al., 2017). This is done by using
two scoring functions: One is a Boolean Scoring
Function (BSF). Another is a Multiplicative Scor-
ing Function (MSF). Both functions set a thresh-
old value and categories whose scores exceed the
threshold value are considered for selection. The
difference is that BSF has a constraint that a cate-
gory can only be selected if its ancestor categories
are selected. MSF does not have such a constraint,
i.e., we extracted all the categories whose scores
exceeded the threshold value and sorted them in
descending order as the system’s assignments.

3 Experiments

3.1 Data and HFT-CNN model setting

We selected two benchmark datasets having a
HS from the extreme classiﬁcation repository2:
RCV1 (Lewis et al., 2004) and Amazon670K
(Leskovec and Krevl, 2015). All the documents in
RCV1 and item descriptions in Amazon670K are
tagged by using Tree Tagger (Schmid, 1995). We
used nouns, verbs, and adjectives. We then applied
fastText. Each dataset has an ofﬁcial training and
test sets. We used each fold in the experiments.
We choose titles from the training and test set on
RCV1. The maximum number of words in the ti-
tle was 13 words. Each text of Amazon670K con-
sists of a product name and its item description.
We extracted the ﬁrst 13 words from each item de-
scription and used them in the experiments. Table
1 presents the statistics on the datasets. We di-
vided the training data into two folds; we used 5%
to tuning the parameters, and the remains to train
the models. Our model setting is shown in Table
23. In the experiments, we run three times for each
model and obtained the averaged performance.

3.2 Evaluation Metrics

the precision at

We used the standard F1 measure. Furthermore,
we evaluated our method by two rank-based eval-
top k, P@k
uation metrics:
and the Normalized Discounted Cumulated Gains,
NDCG@k which are commonly used for com-
paring extreme multi-label classiﬁcation meth-
ods (Liu et al., 2017). We calculated P@k and
NDCG@k for each test data and then obtained an
average over all the test data.

3.3 Basic results

We compared HFT-CNN with a method which
has hierarchical-based categorization but without
ﬁne-tuning (WoFT-CNN) and Flat model to ex-
amine the effect of the ﬁne-tuning. WoFT-CNN
shows that we independently trained parameters
of CNN for each level and trained parameters are
not transferred. Flat means that we simply applied
our CNN model. The results are shown in Ta-
ble 3. The HFT-CNN is better than WoFT-CNN
and Flat model except for Micro-F1 obtained by
WoFT-CNN(M) in Amazon670K. We also found
that the overall results obtained by MSF were bet-
ter to those obtained by BSF.

3.4 Comparison with state-of-the-art method

We chose XML-CNN as a comparative method
because their method attained at the best or sec-
ond best compared to the seven existing methods
in six benchmark datasets (Liu et al., 2017). Origi-
nal XML-CNN is implemented by using Theano4,
while we implemented HFT-CNN by Chainer5. In
order to avoid the inﬂuence of differences in li-
braries, we implemented XML-CNN by Chainer
and compared it with HFT-CNN. We used the
author-provided implementation in Chainer’s ver-
sion of XML-CNN. We recall that we set convo-
lutional ﬁlters with the window sizes to (2,3,4)
and the stride size to 1 because of short text. To
make a fair comparison, we also evaluated XML-
CNN with the same window sizes and stride size
as HFT-CNN.

Liu et al. evaluated their method by using P@k
and NDCG@k. We used their metrics as well as
F1 measure. We did not set a threshold value on
BSF and MSF when we evaluated by using these
metrics, but instead, we used a ranked list of cate-

2manikvarma.org/downloads/XC/XMLRepository.html
3Our source code including Chainer’s version of XML-
CNN is available at: HTTP://github.com/ShimShim46/HFT-
CNN.

ZNywa94c2-iEh 6U/view
5https://chainer.org

4https://drive.google.com/ﬁle/d/1Wwy1MNkrJRXZM3WN

Description
Input word vectors
Stride size
Filters
Pooling
Dropout rate1
Hidden layers
Learning rate
Loss function

Values
fastText
1
128 (cid:2) 3
1-max pooling
0.25
1,024
Predicted by Adam
BCE loss over sigmoid activation

Description
Filter region size
Feature maps (m)
Activation function
Dropout
Dropout rate2
Batch sizes
Epoch
Threshold value for BSF and MSF

Values
(2,3,4)
128
ReLu
Randomly selected
0.5
100
40 with early stopping
0.5

Table 2: HFT-CNN model settings: Dropout rate1 shows dropout immediately after embedding layer, and Dropout
rate2 refers to dropout in a fully connected layer.

Metric
F1
Micro
Macro

HFT(B) WoFT(B) HFT(M) WoFT(M)

RCV1

79.87
50.31

79.69
49.59

80.29
51.40

Amazon670K

Flat
80.06 79.51
50.64 47.71

Metrics HFT(B) WoFT(B) HFT(M) WoFT(M)
50.12
Micro
6.37
Macro

Flat
50.94 49.10
5.73
8.68

(cid:3)50.94
9.87

49.74
6.78

Table 3: Basic results: (B) and (M) refer to a BSF
and MSF, respectively. Bold font shows the best result
within each line. The method marked with “(cid:3)” indi-
cates the score is not statistically signiﬁcant compared
to the best one. We used a t-test, p-value < 0.05.

gories assigned to the test instance. The results are
shown in Table 4. HFT-CNN with BSF/MSF has
the best scores with statistical signiﬁcance com-
pared to both of the XML-CNNs. On RCV1,
HFT-CNN(B) in P@1 and NDCG@1 were worse
than XML-CNN(1), while HFT-CNN(M) with the
same metrics were statistically signiﬁcant com-
pared to XML-CNN(1). This is not surprising be-
cause hierarchical ﬁne-tuning does not contribute
to the accuracy at the top level as the trained pa-
rameters on the top level have not changed in the
level.

We also examined the affection on each system
performance by the depth of a hierarchical struc-
ture. Figure 2 shows Micro-F1 at each hierarchi-
cal level. The deeper the hierarchical level, the
worse the system’s performance. However, HFT-
CNN is still better than XML-CNNs. The im-
provement by MSF was 1.00 (cid:24) 1.34% by Micro-
F1 and 3.77 (cid:24) 10.07% by Macro-F1 on RCV1.
On Amazon670K, the improvement was 1.10 (cid:24)
9.26% by Micro-F1 and 1.10 (cid:24) 3.60% by Macro-
F1. This shows that hierarchical ﬁne-tuning ﬁts to
learn the hierarchical category structure.

We recall that we focused on the multi-label
Figures 3 illustrates Micro-F1 and
problem.
Macro-F1 against the number of categories per
short text. We can see from RCV1 in Figure 3

Metric

P@1
P@3
P@5
G@1
G@3
G@5

Metric

P@1
P@3
P@5
G@1
G@3
G@5

92.93
77.18
53.85
92.93
88.16
89.19

92.60
(cid:3)77.56
(cid:3)53.96
92.60
(cid:3)88.47
89.37

RCV1
HFT(B) HFT(M) XML(1) XML(2)
92.55
76.80
53.60
92.55
87.75
88.80

93.29
77.70
54.23
93.29
88.79
89.81
Amazon670K
HFT(B) HFT(M) XML(1) XML(2)
84.12
64.48
49.75
84.12
74.13
70.74

85.39
65.34
(cid:3)50.84
85.39
75.05
71.46

86.54
66.25
51.09
86.54
76.26
72.84

84.62
64.83
49.93
84.62
74.50
70.99

Table 4: Comparative results: “1” and “2” of XML
show the stride size=1 and 2 by XML-CNN, respec-
tively. “G” stands for NDCG.

that Micro-F1 obtained by HFT-CNN and XML-
CNNs were not statistically signiﬁcant difference
in the number of categories, while Macro-F1 by
HFT-CNN except for the number of 13 categories
was constantly better to XML-CNNs. On Ama-
zon670K data, when the number of categories as-
signed to the short text is less than 38, HFT-CNN
was better than XML-CNNs or HFT-CNN was not
statistically signiﬁcant compared to XML-CNNs
by both F1-scores. However, when it exceeds 39,
HFT-CNN was worse than XML-CNNs. One pos-
sible reason is the use of BSF: a category can only
be selected if its ancestor categories are selected.
Therefore, once the test data could not be classi-
ﬁed into categories correctly, their child categories
also cannot be correctly assigned to the test data.
In contrast, as shown in Figure 5, HFT-CNN by
MSF was better than XML-CNNs in both Micro
and Macro F1 even in the deep level of a hierarchy.
From the observations, a robust scoring function is
needed for further improvement.

It is important to note that how the ratio of
training data affects the overall performance as
we focused on the data sparsity problem. Figure

(a) Micro-F1 (RCV1)

(b) Macro-F1(RCV1)

(c) Micro-F1 (Amazon670K)

(d) Macro-F1 (Amazon670K)

Figure 2: Performance in each hierarchical level: HFT-CNN used BSF

(a) Micro-F1 (RCV1)

(b) Macro-F1 (RCV1)

(c) Micro-F1 (Amazon670K)

(d) Macro-F1 (Amazon670K)

Figure 3: Performance against the # of categories per short text: HFT-CNN used BSF

(a) Micro-F1 (RCV1)

(b) Macro-F1 (RCV1)

(c) Micro-F1 (Amazon670K)

(d) Macro-F1 (Amazon670K)

Figure 4: Performance against a ratio of the training data

4 Conclusion

We have presented an approach to multi-label cat-
egorization for short text. The comparative re-
sults with XML-CNN showed that HFT-CNN is
competitive, especially for the cases that there ex-
ists only a small amount of training data. Fu-
ture work will include: (i) incorporating lexical
semantics such as named entities and domain-
speciﬁc senses for further improvement, (ii) ex-
tending the method to utilize label dependency
constraints (Bi and Kwok, 2011), and (iii) improv-
ing the accuracy of the top ranking categories to
deal with P@1 and NDCG@1 metrics.

Acknowledgments

We would like to thank the anonymous review-
ers for their helpful comments. This work is sup-
ported in part by Support Center for Advanced
Telecommunications Technology Research, Foun-
dation and the Grant-in-aid for the Japan Society
for the Promotion of Science, No.17K00299.

(a) Micro-F1 (Amazon670K) (b) Macro-F1 (Amazon670K)

Figure 5: Performance against the # of categories per
short text: Comparison with HFT-CNN by MSF and
other methods

4 shows Micro and Macro-F1 against a ratio of
the training data. Overall, the curves show that
more training helps the performance, while the
curves obtained by HFT-CNN drop slowly com-
pared to other methods in both datasets and evalu-
ation metrics. From the observations mentioned in
the above, we can conclude that ﬁne-tuning works
well, especially in the cases that the number of the
training data per category is small.

References

W. Bi and J. T. Kwok. 2011. Multi-Label Classiﬁca-
tion on Tree- and DAG-Structured Hierarchies. In
Proc. of the 28th Internation Conference on Math-
ine Learning, pages 17–24.

M. Chen, X. Jin, and D. Shen. 2011. Short Text Clas-
siﬁcation Improved by Learning Multi-Granularity
In Proc. of the 22nd International Joint
Topics.
Conference on Artiﬁcial Intelligence, pages 1776–
1781.

G. E. Hinton, N. Srivastava, A. Krizhevsky,
H. Sutskever, and R. R. Salakhutdinov. 2012.
Improving Neural Networks by Preventing Co-
Adaptation of Feature Detectors. In arXiv preprint
arXiv:1207.0580.

R. Johnson and T. Zhang. 2015a. Effective Use of
Word Order for Text Categorization with Convolu-
tional Neural Networks. In Proc of the 2015 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, pages 103–112.

R. Johnson and T. Zhang. 2015b. Semi-Supervised
Convolutional Neural Networks for Text Catego-
rization vis Region Embedding. Advances in Neural
Information Processing Systems, 28:919–927.

A. Joulin, E. Grave, P. Bojanowski, and T. Mikolov.
2017. Bag of Tricks for Efﬁcient Text Classiﬁca-
tion. In Proc. of the 15th Conference of the Euro-
pean Chapter of the Association for Conputational
Linguistics, pages 427–431.

Y. Kim. 2014. Convolutional Neural Networks for Sen-
In Proc. of the 2014 Confer-
tence Classiﬁcation.
ence on Empirical Methods in Natural Language
Processing, pages 1746–1751.

J. Y. Lee and F. Dernoncourt. 2016. Sequential Short-
Text classiﬁcation with Recurrent and Convolu-
tional Neural Networks. In Proc. of the 2016 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics Human Lan-
guage Technologies, pages 515–520.

J. Leskovec and A. Krevl. 2015. SNAP Datasets: Stan-

ford Large Network Dataset Collection.

D. D. Lewis, Y. Yang, T. G. Rose, and F. Li. 2004.
RCV1: A New Benchmark Collection for Text Cat-
egorization Research. Journal of Machine Learning
Research, 5:361–397.

J. Liu, W-C. Chang, Y. Wu, and Y. Yang. 2017. Deep
Learning for Extreme Multi-Label Text Classiﬁca-
tion. In Proc. of the 40th International ACM SIGIR
Conference on Research and Development in Infor-
mation Retrieval, pages 115–124.

X. H. Phan, L. M. Nguyen, and S. Horiguchi. 2008.
Learning to Classify Short and Sparse Text & Web

with Hidden Topics from Large-Scale Data Collec-
tions. In Proc. of the 17th International World Wide
Web Conference, pages 91–100.

H. Schmid. 1995.

Tagging with an Application to German.
of the EACL SIGDAT Workshop, pages 47–50.

Improvements in Part-of-Speech
In Proc.

G. Song, Y. Ye, X. Du, X. Huang, and S. Bie. 2014.
Short Text Classiﬁcation: A Survey. Multimedia,
9(5):635–643.

F. Wang, Z. Wang, Z. Li, and J-R. Wen. 2008. Concept-
Based Short Text Classiﬁcation and Ranking.
In
Proc. of the 23rd ACM International Conference
on Information and Knowledge Management, pages
1069–1078.

J. Wang, Z. Wang, D. Zhang, and J. Yan. 2017. Com-
bining Knowledge with Deep Convolutional Neural
Networks for Short Text Classiﬁcation. In Proc. of
the 26th International Joint Conference on Artiﬁcial
Intelligence, pages 2915–2921.

P. Wang, J. Xu, B. Xu, C-L. Liu, H. Zhang, F. Wang,
and H. Hao. 2015. Semantic Clustering and Con-
volutional Neural Network for Short Text Catego-
rization. In Proc. of the 53rd Annual Meeting of the
Association for Computational Linguistics and the
7th International Joint Conference on Natural Lan-
guage Processing, pages 352–357.

W. Wu, H. Li, H. Wang, and K. Q. Zhu. 2012. A
Probabilistic Taxonomy for Text Understanding. In
Proc. of the 2012 ACM SIGMOD International Con-
ference on Management of Data, pages 481–492.

Z. Yang, D. Yang, C. Dyer, X. He, A. Smola, and
E. Hovy. 2016. Hierarchical Attention Networks for
Document Classiﬁcation. In Proc. of the 2016 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics Human Lan-
guage Technologies, pages 1480–1489.

R. Zhang, H. Lee, and D. Radev. 2016. Dependency
Sensitive Convolutional Neural Networks for Mod-
In Proc. of the
eling Sentences and Documents.
2016 Conference of the North American Chapter of
the Association for Computational Linguistics Hu-
man Language Technologies, pages 1512–1521.

Y. Zhang, M. Lease, and B. C. Wallace. 2017. Ex-
ploiting Domain Knowledge via Grouped Weight
Sharing with Application to Text Categorization. In
Proc. of the 55th Annual Meeting of the Association
for Computational Linguistics, pages 155–160.

Y. Zhang and B. C. Wallace. 2015. A Sensitivity Anal-
ysis of (and Practitioners’ Guide to) Convolutional
Neural Networks for Sentence Classiﬁcation.
In
Proc. of the 8th International Joint Conference on
Natural Language Processing, pages 253–263.

HFT-CNN: Learning Hierarchical Category Structure for Multi-label
Short Text Categorization

Kazuya Shimura1, Jiyi Li2 and Fumiyo Fukumoto2
Graduate School of Engineering1
Interdisciplinary Graduate School2
University of Yamanashi
4-3-11, Takeda, Kofu, 400-8511 Japan
fg17tk008,jyli,fukumotog@yamanashi.ac.jp

Abstract

We focus on the multi-label categorization task
for short texts and explore the use of a hierar-
chical structure (HS) of categories. In contrast
to the existing work using non-hierarchical ﬂat
model, the method leverages the hierarchical
relations between the categories to tackle the
data sparsity problem. The lower the HS level,
the worse the categorization performance. Be-
cause lower categories are ﬁne-grained and the
amount of training data per category is much
smaller than that in an upper level. We propose
an approach which can effectively utilize the
data in the upper levels to contribute catego-
rization in the lower levels by applying a Con-
volutional Neural Network (CNN) with a ﬁne-
tuning technique. The results using two bench-
mark datasets show that the proposed method,
Hierarchical Fine-Tuning based CNN (HFT-
CNN) is competitive with the state-of-the-art
CNN based methods.

1

Introduction

Major attempts

Short text categorization is widely studied since
the recent explosive growth of online social net-
working applications (Song et al., 2014).
In
texts are less
contrast with documents, short
to
topic-focused in texts.
tackle the problem is to expand short
texts
with knowledge extracted from the textual cor-
pus, machine-readable dictionaries, and thesauri
(Phan et al., 2008; Wang et al., 2008; Chen et al.,
2011; Wu et al., 2012). However, because of
domain-independent nature of dictionaries and
thesauri, it is often the case that the data distri-
bution of the external knowledge is different from
the test data collected from some speciﬁc domain,
which deteriorates the overall performance of cat-
egorization. A methodology which maximizes
the impact of pre-deﬁned domains/categories is
needed to improve categorization performance.

More recently, many authors have attempted
to apply deep learning techniques including CNN
(Wang et al., 2015; Zhang and Wallace, 2015;
Zhang et al., 2017; Wang et al., 2017), the atten-
tion based CNN (Yang et al., 2016), bag-of-words
based CNN (Johnson and Zhang, 2015a), and the
combination of CNN and recurrent neural network
(Lee and Dernoncourt, 2016; Zhang et al., 2016)
to text categorization. Most of them demon-
strated that neural network models are powerful
for learning features from texts, while they fo-
cused on single-label or a few labels problem.
Several efforts have been made to multi-labels
(Johnson and Zhang, 2015b; Liu et al., 2017). Liu
et al.
explored a family of new CNN models
which are tailored for extreme multi-label classi-
ﬁcation (Liu et al., 2017). They used a dynamic
max pooling scheme, a binary cross-entropy loss,
and a hidden bottleneck layer to improve the
overall performance. The results by using six
benchmark datasets where the label-set sizes are
up to 670K showed that their method attained
at the best or second best in comparison with
seven state-of-the-art methods including FastText
(Joulin et al., 2017) and bag-of-words based CNN
(Johnson and Zhang, 2015a). However, all of
these attempts aimed at utilizing a large volume
of data.

We address the problem of multi-label short text
categorization and explore the use of a HS of cat-
egories. The lower level of categories are ﬁne-
grained compared to the upper level of categories.
Moreover, it is often the case that the amount of
training data in a lower level is much smaller than
that in an upper level which deteriorates the over-
all performance of categorization. We propose
an approach which can effectively utilize the data
in the upper levels to contribute categorization in
lower levels by applying ﬁne-tuning to the CNN
which can learn a HS of categories and incorporate

features. These features form a pooling layer and
are passed to a fully connected layer. In the fully
connected layer, we applied dropout (Hinton et al.,
2012). The dropout randomly sets values in the
layer to 0. Finally, we obtained the probability dis-
tribution over categories. The network is trained
with the objective that minimizes the binary cross-
entropy (BCE) of the predicted distributions and
the actual distributions by performing stochastic
gradient descent.

2.2 Hierarchical structure learning

Our key idea is to use a ﬁne-tuning technique in
CNN to tackle the data sparsity problem, espe-
cially a lower level of a HS. Following a HS, we
transferred the parameters of CNN trained in the
upper levels to the lower levels which are worse
trained because of the lack of data, and then ﬁnely
tuned parameters of CNN for lower levels (Figure
1). This approach can effectively utilize the data
in the upper levels to contribute categorization in
the lower levels.

Fine-tuning is motivated by the observation that
the earlier features of CNN contain more generic
features that should be effective for many tasks,
but later layers of the CNN becomes progressively
more speciﬁc to the details of the classes contained
in the original dataset. The motivation is identical
to a HS of categories as we ﬁrst learn to distinguish
among generic categories at the upper level of a
hierarchy, then learns lower level distinctions by
using only within the appropriate top level of the
HS. We note that ﬁne-tuning the last few layers are
usually sufﬁcient for transfer learning as the last
few layers become more speciﬁc features. How-
ever, the HS consisting of deep level needs to ﬁne-
tune the early layers as well because the distance
between the upper and lower level of categories
is signiﬁcant. For this reason, we transferred two
layers shown in Figure 1, i.e., a layer obtained by
word embedding and the convolutional layer. We
used them as an initial parameter to learn the sec-
ond level of a hierarchy. We repeated this pro-
cedure from the top level to the bottom level of
a hierarchy. We note that a HS consists of many
levels. We ﬁne-tune between adjacent layers only
because they are more correlated with each other
compared to distant layers.

2.3 Multi-label categorization

Each test instance is classiﬁed into categories with
probabilities/scores by applying HFT-CNN. We

Figure 1: HFT-CNN model

granularity of categories into categorization. We
transferred the parameters of CNN trained from
upper to lower levels according to the HS, and
ﬁnely tuned parameters. The main contributions
of our work can be summarized: (1) We propose a
method that maximizes the impact of pre-deﬁned
categories to alleviate data sparsity in multi-label
short texts. (2) We empirically examined a ﬁne-
tuning with CNN that ﬁts to learn a HS of cate-
gories deﬁned by lexicographers, and (3) The re-
sults show that our method is competitive to the
state-of-the-art CNN based methods by using two
benchmark datasets, especially it is effective for
categorization of short texts consisting of a few
words with a large number of labels.

2 Hierarchical Fine-Tuning based CNN

2.1 CNN architecture

Similar to other CNN (Johnson and Zhang, 2015a;
Liu et al., 2017), our HFT-CNN model shown in
Figure 1 is based on (Kim, 2014). Let xi 2 Rk be
the k-dimensional word vector with the i-th word
in a sentence obtained by applying skip-gram
model provided in fastText1. A sentence with
length n is represented as x1:n = [x1; x2; (cid:1) (cid:1) (cid:1) ; xn]
2 Rnk. A convolution ﬁlter w 2 Rhk is applied
to a window size of h words to produce a new fea-
ture, ci = f (w(cid:1)xi:i+h(cid:0)1 +b) where b 2 R indicates
a bias term and f refers to a non-linear activation
function. We applied this convolution ﬁlter to each
possible window size in the sentence and obtained
a feature map, m 2 Rn(cid:0)h+1. As shown in Fig-
ure 1, we then apply a max pooling operation over
the feature map and obtain the maximum value
^m as a feature of this ﬁlter. We obtained multi-
ple ﬁlters by varying window sizes and multiple

1https://github.com/facebookresearch/fastText

Dataset
RCV1
Amazon670K

#L
4
9

Tr
23,149
490,449

Te
781,265
153,025

C
103
670,091

Table 1: Data Statistics: #L shows the depth of a hier-
archy. Tr and Te refer to the # of training and test data,
respectively. C indicates the total # of categories.

then utilize a constraint of a HS to obtain ﬁnal
results which differs from the existing work on
non-hierarchical ﬂat model (Johnson and Zhang,
2015a; Liu et al., 2017). This is done by using
two scoring functions: One is a Boolean Scoring
Function (BSF). Another is a Multiplicative Scor-
ing Function (MSF). Both functions set a thresh-
old value and categories whose scores exceed the
threshold value are considered for selection. The
difference is that BSF has a constraint that a cate-
gory can only be selected if its ancestor categories
are selected. MSF does not have such a constraint,
i.e., we extracted all the categories whose scores
exceeded the threshold value and sorted them in
descending order as the system’s assignments.

3 Experiments

3.1 Data and HFT-CNN model setting

We selected two benchmark datasets having a
HS from the extreme classiﬁcation repository2:
RCV1 (Lewis et al., 2004) and Amazon670K
(Leskovec and Krevl, 2015). All the documents in
RCV1 and item descriptions in Amazon670K are
tagged by using Tree Tagger (Schmid, 1995). We
used nouns, verbs, and adjectives. We then applied
fastText. Each dataset has an ofﬁcial training and
test sets. We used each fold in the experiments.
We choose titles from the training and test set on
RCV1. The maximum number of words in the ti-
tle was 13 words. Each text of Amazon670K con-
sists of a product name and its item description.
We extracted the ﬁrst 13 words from each item de-
scription and used them in the experiments. Table
1 presents the statistics on the datasets. We di-
vided the training data into two folds; we used 5%
to tuning the parameters, and the remains to train
the models. Our model setting is shown in Table
23. In the experiments, we run three times for each
model and obtained the averaged performance.

3.2 Evaluation Metrics

the precision at

We used the standard F1 measure. Furthermore,
we evaluated our method by two rank-based eval-
top k, P@k
uation metrics:
and the Normalized Discounted Cumulated Gains,
NDCG@k which are commonly used for com-
paring extreme multi-label classiﬁcation meth-
ods (Liu et al., 2017). We calculated P@k and
NDCG@k for each test data and then obtained an
average over all the test data.

3.3 Basic results

We compared HFT-CNN with a method which
has hierarchical-based categorization but without
ﬁne-tuning (WoFT-CNN) and Flat model to ex-
amine the effect of the ﬁne-tuning. WoFT-CNN
shows that we independently trained parameters
of CNN for each level and trained parameters are
not transferred. Flat means that we simply applied
our CNN model. The results are shown in Ta-
ble 3. The HFT-CNN is better than WoFT-CNN
and Flat model except for Micro-F1 obtained by
WoFT-CNN(M) in Amazon670K. We also found
that the overall results obtained by MSF were bet-
ter to those obtained by BSF.

3.4 Comparison with state-of-the-art method

We chose XML-CNN as a comparative method
because their method attained at the best or sec-
ond best compared to the seven existing methods
in six benchmark datasets (Liu et al., 2017). Origi-
nal XML-CNN is implemented by using Theano4,
while we implemented HFT-CNN by Chainer5. In
order to avoid the inﬂuence of differences in li-
braries, we implemented XML-CNN by Chainer
and compared it with HFT-CNN. We used the
author-provided implementation in Chainer’s ver-
sion of XML-CNN. We recall that we set convo-
lutional ﬁlters with the window sizes to (2,3,4)
and the stride size to 1 because of short text. To
make a fair comparison, we also evaluated XML-
CNN with the same window sizes and stride size
as HFT-CNN.

Liu et al. evaluated their method by using P@k
and NDCG@k. We used their metrics as well as
F1 measure. We did not set a threshold value on
BSF and MSF when we evaluated by using these
metrics, but instead, we used a ranked list of cate-

2manikvarma.org/downloads/XC/XMLRepository.html
3Our source code including Chainer’s version of XML-
CNN is available at: HTTP://github.com/ShimShim46/HFT-
CNN.

ZNywa94c2-iEh 6U/view
5https://chainer.org

4https://drive.google.com/ﬁle/d/1Wwy1MNkrJRXZM3WN

Description
Input word vectors
Stride size
Filters
Pooling
Dropout rate1
Hidden layers
Learning rate
Loss function

Values
fastText
1
128 (cid:2) 3
1-max pooling
0.25
1,024
Predicted by Adam
BCE loss over sigmoid activation

Description
Filter region size
Feature maps (m)
Activation function
Dropout
Dropout rate2
Batch sizes
Epoch
Threshold value for BSF and MSF

Values
(2,3,4)
128
ReLu
Randomly selected
0.5
100
40 with early stopping
0.5

Table 2: HFT-CNN model settings: Dropout rate1 shows dropout immediately after embedding layer, and Dropout
rate2 refers to dropout in a fully connected layer.

Metric
F1
Micro
Macro

HFT(B) WoFT(B) HFT(M) WoFT(M)

RCV1

79.87
50.31

79.69
49.59

80.29
51.40

Amazon670K

Flat
80.06 79.51
50.64 47.71

Metrics HFT(B) WoFT(B) HFT(M) WoFT(M)
50.12
Micro
6.37
Macro

Flat
50.94 49.10
5.73
8.68

(cid:3)50.94
9.87

49.74
6.78

Table 3: Basic results: (B) and (M) refer to a BSF
and MSF, respectively. Bold font shows the best result
within each line. The method marked with “(cid:3)” indi-
cates the score is not statistically signiﬁcant compared
to the best one. We used a t-test, p-value < 0.05.

gories assigned to the test instance. The results are
shown in Table 4. HFT-CNN with BSF/MSF has
the best scores with statistical signiﬁcance com-
pared to both of the XML-CNNs. On RCV1,
HFT-CNN(B) in P@1 and NDCG@1 were worse
than XML-CNN(1), while HFT-CNN(M) with the
same metrics were statistically signiﬁcant com-
pared to XML-CNN(1). This is not surprising be-
cause hierarchical ﬁne-tuning does not contribute
to the accuracy at the top level as the trained pa-
rameters on the top level have not changed in the
level.

We also examined the affection on each system
performance by the depth of a hierarchical struc-
ture. Figure 2 shows Micro-F1 at each hierarchi-
cal level. The deeper the hierarchical level, the
worse the system’s performance. However, HFT-
CNN is still better than XML-CNNs. The im-
provement by MSF was 1.00 (cid:24) 1.34% by Micro-
F1 and 3.77 (cid:24) 10.07% by Macro-F1 on RCV1.
On Amazon670K, the improvement was 1.10 (cid:24)
9.26% by Micro-F1 and 1.10 (cid:24) 3.60% by Macro-
F1. This shows that hierarchical ﬁne-tuning ﬁts to
learn the hierarchical category structure.

We recall that we focused on the multi-label
Figures 3 illustrates Micro-F1 and
problem.
Macro-F1 against the number of categories per
short text. We can see from RCV1 in Figure 3

Metric

P@1
P@3
P@5
G@1
G@3
G@5

Metric

P@1
P@3
P@5
G@1
G@3
G@5

92.93
77.18
53.85
92.93
88.16
89.19

92.60
(cid:3)77.56
(cid:3)53.96
92.60
(cid:3)88.47
89.37

RCV1
HFT(B) HFT(M) XML(1) XML(2)
92.55
76.80
53.60
92.55
87.75
88.80

93.29
77.70
54.23
93.29
88.79
89.81
Amazon670K
HFT(B) HFT(M) XML(1) XML(2)
84.12
64.48
49.75
84.12
74.13
70.74

85.39
65.34
(cid:3)50.84
85.39
75.05
71.46

86.54
66.25
51.09
86.54
76.26
72.84

84.62
64.83
49.93
84.62
74.50
70.99

Table 4: Comparative results: “1” and “2” of XML
show the stride size=1 and 2 by XML-CNN, respec-
tively. “G” stands for NDCG.

that Micro-F1 obtained by HFT-CNN and XML-
CNNs were not statistically signiﬁcant difference
in the number of categories, while Macro-F1 by
HFT-CNN except for the number of 13 categories
was constantly better to XML-CNNs. On Ama-
zon670K data, when the number of categories as-
signed to the short text is less than 38, HFT-CNN
was better than XML-CNNs or HFT-CNN was not
statistically signiﬁcant compared to XML-CNNs
by both F1-scores. However, when it exceeds 39,
HFT-CNN was worse than XML-CNNs. One pos-
sible reason is the use of BSF: a category can only
be selected if its ancestor categories are selected.
Therefore, once the test data could not be classi-
ﬁed into categories correctly, their child categories
also cannot be correctly assigned to the test data.
In contrast, as shown in Figure 5, HFT-CNN by
MSF was better than XML-CNNs in both Micro
and Macro F1 even in the deep level of a hierarchy.
From the observations, a robust scoring function is
needed for further improvement.

It is important to note that how the ratio of
training data affects the overall performance as
we focused on the data sparsity problem. Figure

(a) Micro-F1 (RCV1)

(b) Macro-F1(RCV1)

(c) Micro-F1 (Amazon670K)

(d) Macro-F1 (Amazon670K)

Figure 2: Performance in each hierarchical level: HFT-CNN used BSF

(a) Micro-F1 (RCV1)

(b) Macro-F1 (RCV1)

(c) Micro-F1 (Amazon670K)

(d) Macro-F1 (Amazon670K)

Figure 3: Performance against the # of categories per short text: HFT-CNN used BSF

(a) Micro-F1 (RCV1)

(b) Macro-F1 (RCV1)

(c) Micro-F1 (Amazon670K)

(d) Macro-F1 (Amazon670K)

Figure 4: Performance against a ratio of the training data

4 Conclusion

We have presented an approach to multi-label cat-
egorization for short text. The comparative re-
sults with XML-CNN showed that HFT-CNN is
competitive, especially for the cases that there ex-
ists only a small amount of training data. Fu-
ture work will include: (i) incorporating lexical
semantics such as named entities and domain-
speciﬁc senses for further improvement, (ii) ex-
tending the method to utilize label dependency
constraints (Bi and Kwok, 2011), and (iii) improv-
ing the accuracy of the top ranking categories to
deal with P@1 and NDCG@1 metrics.

Acknowledgments

We would like to thank the anonymous review-
ers for their helpful comments. This work is sup-
ported in part by Support Center for Advanced
Telecommunications Technology Research, Foun-
dation and the Grant-in-aid for the Japan Society
for the Promotion of Science, No.17K00299.

(a) Micro-F1 (Amazon670K) (b) Macro-F1 (Amazon670K)

Figure 5: Performance against the # of categories per
short text: Comparison with HFT-CNN by MSF and
other methods

4 shows Micro and Macro-F1 against a ratio of
the training data. Overall, the curves show that
more training helps the performance, while the
curves obtained by HFT-CNN drop slowly com-
pared to other methods in both datasets and evalu-
ation metrics. From the observations mentioned in
the above, we can conclude that ﬁne-tuning works
well, especially in the cases that the number of the
training data per category is small.

References

W. Bi and J. T. Kwok. 2011. Multi-Label Classiﬁca-
tion on Tree- and DAG-Structured Hierarchies. In
Proc. of the 28th Internation Conference on Math-
ine Learning, pages 17–24.

M. Chen, X. Jin, and D. Shen. 2011. Short Text Clas-
siﬁcation Improved by Learning Multi-Granularity
In Proc. of the 22nd International Joint
Topics.
Conference on Artiﬁcial Intelligence, pages 1776–
1781.

G. E. Hinton, N. Srivastava, A. Krizhevsky,
H. Sutskever, and R. R. Salakhutdinov. 2012.
Improving Neural Networks by Preventing Co-
Adaptation of Feature Detectors. In arXiv preprint
arXiv:1207.0580.

R. Johnson and T. Zhang. 2015a. Effective Use of
Word Order for Text Categorization with Convolu-
tional Neural Networks. In Proc of the 2015 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, pages 103–112.

R. Johnson and T. Zhang. 2015b. Semi-Supervised
Convolutional Neural Networks for Text Catego-
rization vis Region Embedding. Advances in Neural
Information Processing Systems, 28:919–927.

A. Joulin, E. Grave, P. Bojanowski, and T. Mikolov.
2017. Bag of Tricks for Efﬁcient Text Classiﬁca-
tion. In Proc. of the 15th Conference of the Euro-
pean Chapter of the Association for Conputational
Linguistics, pages 427–431.

Y. Kim. 2014. Convolutional Neural Networks for Sen-
In Proc. of the 2014 Confer-
tence Classiﬁcation.
ence on Empirical Methods in Natural Language
Processing, pages 1746–1751.

J. Y. Lee and F. Dernoncourt. 2016. Sequential Short-
Text classiﬁcation with Recurrent and Convolu-
tional Neural Networks. In Proc. of the 2016 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics Human Lan-
guage Technologies, pages 515–520.

J. Leskovec and A. Krevl. 2015. SNAP Datasets: Stan-

ford Large Network Dataset Collection.

D. D. Lewis, Y. Yang, T. G. Rose, and F. Li. 2004.
RCV1: A New Benchmark Collection for Text Cat-
egorization Research. Journal of Machine Learning
Research, 5:361–397.

J. Liu, W-C. Chang, Y. Wu, and Y. Yang. 2017. Deep
Learning for Extreme Multi-Label Text Classiﬁca-
tion. In Proc. of the 40th International ACM SIGIR
Conference on Research and Development in Infor-
mation Retrieval, pages 115–124.

X. H. Phan, L. M. Nguyen, and S. Horiguchi. 2008.
Learning to Classify Short and Sparse Text & Web

with Hidden Topics from Large-Scale Data Collec-
tions. In Proc. of the 17th International World Wide
Web Conference, pages 91–100.

H. Schmid. 1995.

Tagging with an Application to German.
of the EACL SIGDAT Workshop, pages 47–50.

Improvements in Part-of-Speech
In Proc.

G. Song, Y. Ye, X. Du, X. Huang, and S. Bie. 2014.
Short Text Classiﬁcation: A Survey. Multimedia,
9(5):635–643.

F. Wang, Z. Wang, Z. Li, and J-R. Wen. 2008. Concept-
Based Short Text Classiﬁcation and Ranking.
In
Proc. of the 23rd ACM International Conference
on Information and Knowledge Management, pages
1069–1078.

J. Wang, Z. Wang, D. Zhang, and J. Yan. 2017. Com-
bining Knowledge with Deep Convolutional Neural
Networks for Short Text Classiﬁcation. In Proc. of
the 26th International Joint Conference on Artiﬁcial
Intelligence, pages 2915–2921.

P. Wang, J. Xu, B. Xu, C-L. Liu, H. Zhang, F. Wang,
and H. Hao. 2015. Semantic Clustering and Con-
volutional Neural Network for Short Text Catego-
rization. In Proc. of the 53rd Annual Meeting of the
Association for Computational Linguistics and the
7th International Joint Conference on Natural Lan-
guage Processing, pages 352–357.

W. Wu, H. Li, H. Wang, and K. Q. Zhu. 2012. A
Probabilistic Taxonomy for Text Understanding. In
Proc. of the 2012 ACM SIGMOD International Con-
ference on Management of Data, pages 481–492.

Z. Yang, D. Yang, C. Dyer, X. He, A. Smola, and
E. Hovy. 2016. Hierarchical Attention Networks for
Document Classiﬁcation. In Proc. of the 2016 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics Human Lan-
guage Technologies, pages 1480–1489.

R. Zhang, H. Lee, and D. Radev. 2016. Dependency
Sensitive Convolutional Neural Networks for Mod-
In Proc. of the
eling Sentences and Documents.
2016 Conference of the North American Chapter of
the Association for Computational Linguistics Hu-
man Language Technologies, pages 1512–1521.

Y. Zhang, M. Lease, and B. C. Wallace. 2017. Ex-
ploiting Domain Knowledge via Grouped Weight
Sharing with Application to Text Categorization. In
Proc. of the 55th Annual Meeting of the Association
for Computational Linguistics, pages 155–160.

Y. Zhang and B. C. Wallace. 2015. A Sensitivity Anal-
ysis of (and Practitioners’ Guide to) Convolutional
Neural Networks for Sentence Classiﬁcation.
In
Proc. of the 8th International Joint Conference on
Natural Language Processing, pages 253–263.

