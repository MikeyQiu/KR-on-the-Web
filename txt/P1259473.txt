5
1
0
2
 
r
p
A
 
6
 
 
]

G
L
.
s
c
[
 
 
4
v
2
0
3
2
.
2
1
4
1
:
v
i
X
r
a

Accepted as a workshop contribution at ICLR 2015

THEANO-BASED LARGE-SCALE VISUAL RECOGNI-
TION WITH MULTIPLE GPUS

Weiguang Ding & Ruoyan Wang
School of Engineering, University of Guelph
{wding, ruoyanry}@uoguelph.ca

Fei Mao
Sharcnet, Compute Canada
feimao@sharcnet.ca

Graham Taylor
School of Engineering, University of Guelph
gwtaylor@uoguelph.ca

ABSTRACT

In this report, we describe a Theano-based AlexNet (Krizhevsky et al., 2012) im-
plementation and its naive data parallelism on multiple GPUs. Our performance
on 2 GPUs is comparable with the state-of-art Caffe library (Jia et al., 2014) run
on 1 GPU. To the best of our knowledge, this is the ﬁrst open-source Python-based
AlexNet implementation to-date.

1

INTRODUCTION

In particular, AlexNet
Deep neural networks have greatly impacted many application areas.
(Krizhevsky et al., 2012), a type of convolutional neural network (LeCun et al., 1998) (ConvNet),
has signiﬁcantly improved the performance of image classiﬁcation by winning the 2012 ImageNet
Large Scale Visual Recognition Challenge (Russakovsky et al., 2014) (ILSVRC 2012). With the
increasing popularity of deep learning, many open-source frameworks have emerged with the capa-
bility to train deep ConvNets on datasets with over 1M examples. These include Caffe (Jia et al.,
2014), Torch7 (Collobert et al., 2011) and cuda-convnet (Krizhevsky et al., 2012). However, the con-
venience of using them are limited to building “standard” architectures. To experiment with brand
new architectures, researchers have to derive and implement the corresponding gradient functions in
order to do backpropagation or other types of gradient descent optimizations.

Theano (Bergstra et al., 2010; Bastien et al., 2012), on the other hand, provides the automatic differ-
entiation feature, which saves researchers from tedious derivations and can help in avoiding errors
in such calculations. The other advantage of Theano is that it has a huge existing user and developer
base which leverages the comprehensive scientiﬁc Python stack (102 contributors at the time of writ-
ing). However, there is no previously reported work of using Theano to do large scale experiments,
such as the above mentioned ILSVRC 2012.

Here, we report a Theano-based AlexNet trained on ImageNet data1. We also introduce a naive data
parallelism implementation on multiple GPUs, to further accelerate training.

2 METHODS

“AlexNet” is a now a standard architecture known in the deep learning community and often used for
benchmarking. It contains 5 convolutional layers, 3 of which are followed by max pooling layers,

1The code is open sourced at https://github.com/uoguelph-mlrg/theano_alexnet. In ad-
dition, a toy example is provided at https://github.com/uoguelph-mlrg/theano_multi_gpu.

1

Accepted as a workshop contribution at ICLR 2015

Figure 1: Illustration of parallelized training and loading (1 or 2 GPUs)

Figure 2: Illustration of exchanging and averaging weights (2 GPUs)

2 fully connected layers, and 1 softmax layer (Krizhevsky et al., 2012). In our AlexNet implemen-
tation, we used 2 types of convolution and max pooling operators. The 1st is from the Pylearn2
(Goodfellow et al., 2013) wrapper of cuda-convnet, the original implementation of AlexNet. The
2nd is the recently developed Theano wrapper of cuDNN (Chetlur et al., 2014). We also use func-
tions in the PyCUDA library (Kl¨ockner et al., 2012) to transfer Theano shared variables between
different python processes for two tasks: 1. loading image mini-batches into GPUs during training;
and 2. exchanging weights between models trained on multiple-GPUs.

2.1 PARALLEL DATA LOADING

Figure 1 illustrates the process of parallelized training and data loading. Two processes run at the
same time, one is for training, and the other one is for loading image mini-batches. While the training
process is working on the current minibatch, the loading process is copying the next minibatch from
disk to host memory, preprocessing2 it and copying it from host memory to GPU memory. After
training on the current minibatch ﬁnishes, the data batch will be moved “instantly” from the loading
process to the training process, as they access the same GPU.

2.2 DATA PARALLELISM

In this implementation, 2 AlexNets are trained on 2 GPUs. They are initialized identically. At each
step, they are updated on different minibatches respectively, and then their parameters (weights,
biases) as well as momentum are exchanged and averaged.

2Preprocessing includes subtracting the mean image, randomly cropping and ﬂipping images (Krizhevsky

et al., 2012).

2

Accepted as a workshop contribution at ICLR 2015

Table 1: Training time per 20 iterations (sec)

Parallel
loading
Yes
No

cuda-convnet

cuDNN-R1
2-GPU 1-GPU 2-GPU 1-GPU 2-GPU 1-GPU
32.76
23.39
43.52
28.92

19.72
26.23

39.72
49.11

20.58
27.31

34.71
45.45

cuDNN-R2

Caffe

Caffe with
cuDNN

26.26

20.25

Figure 2 illustrates the steps involved in training on one minibatch. For each weight3 matrix in the
model, there are 2 shared variables allocated: one for updating, and one for storing weights copied
from the other GPU. The shared variables for updating on 2 GPUs start the same. In the 1st step,
they are updated separately on different data batches. In the 2nd step, weights are exchanged between
GPUs. In the 3rd step, these weights (no longer the same) are averaged on both GPUs. At this point,
2 AlexNets sharing the same parameters are ready for training on the next mini-batch.

3 RESULTS

Our experimental system contains 2 Intel Xeon E5-2620 CPUs (6-core each and 2.10GHz), and
3 Nvidia Titan Black GPUs. 2 of the GPUs are under the same PCI-E switch and are used for
the 2-GPU implementation. We did not use the third GPU. For the cuDNN library, we performed
experiments on both the version of R1 and R2.

For the experiments on a single GPU, we used batch size 256. Equivalently, we used batch size 128
for experiments on 2 GPUs. We recorded the time to train 20 batches (5,120 images) under different
settings and compared them with Caffe4 in Table 1.

We can see that both parallel loading and data parallelism on 2 GPUs bring signiﬁcant speed ups.
The 2-GPU & parallel loading implementation (cuDNN-R2) is on par with the “Caffe with cuDNN”
implementation.

After 65 epochs of training, the top-1 class validation error rate is 42.6%, and the top-5 error rate is
19.9%, without the intensity and illumination data augmentation 5. This is within 0.5% of the results
reported in the similar Caffe implementation6.

4 DISCUSSION

4.1 NATIVE THEANO MULTI-GPU SUPPORT

Native Theano multi-GPU support is under development7. Our present implementation is a tempo-
rary work-around before its release, and might also provide helpful communication components on
top of it.

4.2 RELATED WORK

Many multi-GPU frameworks has been proposed and implemented (Yadan et al., 2013; Zou et al.,
2014; Paine et al., 2013; Krizhevsky, 2014), usually adopting a mixed data and model parallelism.
This report only implements the data parallelism framework, but it could potentially, with a non-
trivial amount of effort, be extended to incorporate model parallelism.

3The same operation is performed for biases and momentum.
4Performance of Caffe is according to http://caffe.berkeleyvision.org/performance_
hardware.html, where timing information for CaffeNet is provided. As CaffeNet has similar structures,
we consider this as a rough reference.

5The

pretrained

parameters

are

available

for

downloading

at https://github.com/

uoguelph-mlrg/theano_alexnet/tree/master/pretrained/alexnet

6https://github.com/BVLC/caffe/tree/master/models/bvlc_reference_

caffenet

7https://groups.google.com/d/msg/theano-users/vtR_L0QltpE/Kp5hK1nFLtsJ

3

Accepted as a workshop contribution at ICLR 2015

4.3 CHALLENGES IN PYTHON-BASED PARALLELIZATION

The Global Interpreter Lock 8 (GIL) makes parallelization difﬁcult in CPython, by disabling concur-
rent threads within one process. Therefore, to parallelize, it is necessary to launch multiple processes
and communicate between these processes. Straightforward inter-process communication, using the
“multiprocessing” module, is very slow for 2 reasons: 1) it serializes Numpy arrays before passing
between processes; 2) communication is done through host memory. These problems lead us to
GPUDirect peer-to-peer memory copy, which also has many pitfalls under the multi-process set-
ting. For instance, there is no host-side synchronization performed with device-to-device memory
copy even when the sync API is called 9. This problem is dealt with by CUDA context syncing
and additional message communications between processes, however, this and similar issues are not
straightforward.

4.4 LIMITATIONS

To use the fast peer-to-peer GPU memory copy, GPUs have to be under the same PCI-E switch.
Otherwise, communication has to go through the host memory which results in longer latency. Sit-
uations involved with more GPUs are discussed in Krizhevsky (2014).

Due to our current hardware limitation, we have only proposed and experimented with a 2-GPU
implementation. This report and the code will be updated once experiments on more GPUs are
performed.

We acknowledge Lev Givon for giving helpful suggestions on how to use the PyCUDA library. We
also acknowledge NVIDIA for an Academic Hardware Grant.

ACKNOWLEDGMENTS

REFERENCES

Bastien, Fr´ed´eric, Lamblin, Pascal, Pascanu, Razvan, Bergstra, James, Goodfellow, Ian, Bergeron,
Arnaud, Bouchard, Nicolas, Warde-Farley, David, and Bengio, Yoshua. Theano: new features
and speed improvements. arXiv preprint arXiv:1211.5590, 2012.

Bergstra, James, Breuleux, Olivier, Bastien, Fr´ed´eric, Lamblin, Pascal, Pascanu, Razvan, Des-
jardins, Guillaume, Turian, Joseph, Warde-Farley, David, and Bengio, Yoshua. Theano: a cpu
and gpu math expression compiler. In Proceedings of the Python for scientiﬁc computing confer-
ence (SciPy), volume 4, pp. 3, 2010.

Chetlur, Sharan, Woolley, Cliff, Vandermersch, Philippe, Cohen, Jonathan, Tran, John, Catanzaro,
Bryan, and Shelhamer, Evan. cudnn: Efﬁcient primitives for deep learning. arXiv preprint
arXiv:1410.0759, 2014.

Collobert, Ronan, Kavukcuoglu, Koray, and Farabet, Cl´ement. Torch7: A matlab-like environment

for machine learning. In BigLearn, NIPS Workshop, number EPFL-CONF-192376, 2011.

Goodfellow, Ian J, Warde-Farley, David, Lamblin, Pascal, Dumoulin, Vincent, Mirza, Mehdi, Pas-
canu, Razvan, Bergstra, James, Bastien, Fr´ed´eric, and Bengio, Yoshua. Pylearn2: a machine
learning research library. arXiv preprint arXiv:1308.4214, 2013.

Jia, Yangqing, Shelhamer, Evan, Donahue, Jeff, Karayev, Sergey, Long, Jonathan, Girshick, Ross,
Guadarrama, Sergio, and Darrell, Trevor. Caffe: Convolutional architecture for fast feature em-
In Proceedings of the ACM International Conference on Multimedia, pp. 675–678.
bedding.
ACM, 2014.

Kl¨ockner, Andreas, Pinto, Nicolas, Lee, Yunsup, Catanzaro, Bryan, Ivanov, Paul, and Fasih, Ahmed.
Pycuda and pyopencl: A scripting-based approach to gpu run-time code generation. Parallel
Computing, 38(3):157–174, 2012.

8https://wiki.python.org/moin/GlobalInterpreterLock
9http://docs.nvidia.com/cuda/cuda-driver-api/api-sync-behavior.html

4

Accepted as a workshop contribution at ICLR 2015

Krizhevsky, Alex. One weird trick for parallelizing convolutional neural networks. arXiv preprint

arXiv:1404.5997, 2014.

Krizhevsky, Alex, Sutskever, Ilya, and Hinton, Geoffrey E. Imagenet classiﬁcation with deep convo-
lutional neural networks. In Advances in neural information processing systems, pp. 1097–1105,
2012.

LeCun, Yann, Bottou, L´eon, Bengio, Yoshua, and Haffner, Patrick. Gradient-based learning applied

to document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.

Paine, Thomas, Jin, Hailin, Yang, Jianchao, Lin, Zhe, and Huang, Thomas. Gpu asynchronous
stochastic gradient descent to speed up neural network training. arXiv preprint arXiv:1312.6186,
2013.

Russakovsky, Olga, Deng, Jia, Su, Hao, Krause, Jonathan, Satheesh, Sanjeev, Ma, Sean, Huang,
Zhiheng, Karpathy, Andrej, Khosla, Aditya, Bernstein, Michael, et al. Imagenet large scale visual
recognition challenge. arXiv preprint arXiv:1409.0575, 2014.

Yadan, Omry, Adams, Keith, Taigman, Yaniv, and Ranzato, MarcAurelio. Multi-gpu training of

convnets. arXiv preprint arXiv:1312.5853, 2013.

Zou, Yongqiang, Jin, Xing, Li, Yi, Guo, Zhimao, Wang, Eryu, and Xiao, Bin. Mariana: Tencent
deep learning platform and its applications. Proceedings of the VLDB Endowment, 7(13), 2014.

5

5
1
0
2
 
r
p
A
 
6
 
 
]

G
L
.
s
c
[
 
 
4
v
2
0
3
2
.
2
1
4
1
:
v
i
X
r
a

Accepted as a workshop contribution at ICLR 2015

THEANO-BASED LARGE-SCALE VISUAL RECOGNI-
TION WITH MULTIPLE GPUS

Weiguang Ding & Ruoyan Wang
School of Engineering, University of Guelph
{wding, ruoyanry}@uoguelph.ca

Fei Mao
Sharcnet, Compute Canada
feimao@sharcnet.ca

Graham Taylor
School of Engineering, University of Guelph
gwtaylor@uoguelph.ca

ABSTRACT

In this report, we describe a Theano-based AlexNet (Krizhevsky et al., 2012) im-
plementation and its naive data parallelism on multiple GPUs. Our performance
on 2 GPUs is comparable with the state-of-art Caffe library (Jia et al., 2014) run
on 1 GPU. To the best of our knowledge, this is the ﬁrst open-source Python-based
AlexNet implementation to-date.

1

INTRODUCTION

In particular, AlexNet
Deep neural networks have greatly impacted many application areas.
(Krizhevsky et al., 2012), a type of convolutional neural network (LeCun et al., 1998) (ConvNet),
has signiﬁcantly improved the performance of image classiﬁcation by winning the 2012 ImageNet
Large Scale Visual Recognition Challenge (Russakovsky et al., 2014) (ILSVRC 2012). With the
increasing popularity of deep learning, many open-source frameworks have emerged with the capa-
bility to train deep ConvNets on datasets with over 1M examples. These include Caffe (Jia et al.,
2014), Torch7 (Collobert et al., 2011) and cuda-convnet (Krizhevsky et al., 2012). However, the con-
venience of using them are limited to building “standard” architectures. To experiment with brand
new architectures, researchers have to derive and implement the corresponding gradient functions in
order to do backpropagation or other types of gradient descent optimizations.

Theano (Bergstra et al., 2010; Bastien et al., 2012), on the other hand, provides the automatic differ-
entiation feature, which saves researchers from tedious derivations and can help in avoiding errors
in such calculations. The other advantage of Theano is that it has a huge existing user and developer
base which leverages the comprehensive scientiﬁc Python stack (102 contributors at the time of writ-
ing). However, there is no previously reported work of using Theano to do large scale experiments,
such as the above mentioned ILSVRC 2012.

Here, we report a Theano-based AlexNet trained on ImageNet data1. We also introduce a naive data
parallelism implementation on multiple GPUs, to further accelerate training.

2 METHODS

“AlexNet” is a now a standard architecture known in the deep learning community and often used for
benchmarking. It contains 5 convolutional layers, 3 of which are followed by max pooling layers,

1The code is open sourced at https://github.com/uoguelph-mlrg/theano_alexnet. In ad-
dition, a toy example is provided at https://github.com/uoguelph-mlrg/theano_multi_gpu.

1

Accepted as a workshop contribution at ICLR 2015

Figure 1: Illustration of parallelized training and loading (1 or 2 GPUs)

Figure 2: Illustration of exchanging and averaging weights (2 GPUs)

2 fully connected layers, and 1 softmax layer (Krizhevsky et al., 2012). In our AlexNet implemen-
tation, we used 2 types of convolution and max pooling operators. The 1st is from the Pylearn2
(Goodfellow et al., 2013) wrapper of cuda-convnet, the original implementation of AlexNet. The
2nd is the recently developed Theano wrapper of cuDNN (Chetlur et al., 2014). We also use func-
tions in the PyCUDA library (Kl¨ockner et al., 2012) to transfer Theano shared variables between
different python processes for two tasks: 1. loading image mini-batches into GPUs during training;
and 2. exchanging weights between models trained on multiple-GPUs.

2.1 PARALLEL DATA LOADING

Figure 1 illustrates the process of parallelized training and data loading. Two processes run at the
same time, one is for training, and the other one is for loading image mini-batches. While the training
process is working on the current minibatch, the loading process is copying the next minibatch from
disk to host memory, preprocessing2 it and copying it from host memory to GPU memory. After
training on the current minibatch ﬁnishes, the data batch will be moved “instantly” from the loading
process to the training process, as they access the same GPU.

2.2 DATA PARALLELISM

In this implementation, 2 AlexNets are trained on 2 GPUs. They are initialized identically. At each
step, they are updated on different minibatches respectively, and then their parameters (weights,
biases) as well as momentum are exchanged and averaged.

2Preprocessing includes subtracting the mean image, randomly cropping and ﬂipping images (Krizhevsky

et al., 2012).

2

Accepted as a workshop contribution at ICLR 2015

Table 1: Training time per 20 iterations (sec)

Parallel
loading
Yes
No

cuda-convnet

cuDNN-R1
2-GPU 1-GPU 2-GPU 1-GPU 2-GPU 1-GPU
32.76
23.39
43.52
28.92

19.72
26.23

39.72
49.11

20.58
27.31

34.71
45.45

cuDNN-R2

Caffe

Caffe with
cuDNN

26.26

20.25

Figure 2 illustrates the steps involved in training on one minibatch. For each weight3 matrix in the
model, there are 2 shared variables allocated: one for updating, and one for storing weights copied
from the other GPU. The shared variables for updating on 2 GPUs start the same. In the 1st step,
they are updated separately on different data batches. In the 2nd step, weights are exchanged between
GPUs. In the 3rd step, these weights (no longer the same) are averaged on both GPUs. At this point,
2 AlexNets sharing the same parameters are ready for training on the next mini-batch.

3 RESULTS

Our experimental system contains 2 Intel Xeon E5-2620 CPUs (6-core each and 2.10GHz), and
3 Nvidia Titan Black GPUs. 2 of the GPUs are under the same PCI-E switch and are used for
the 2-GPU implementation. We did not use the third GPU. For the cuDNN library, we performed
experiments on both the version of R1 and R2.

For the experiments on a single GPU, we used batch size 256. Equivalently, we used batch size 128
for experiments on 2 GPUs. We recorded the time to train 20 batches (5,120 images) under different
settings and compared them with Caffe4 in Table 1.

We can see that both parallel loading and data parallelism on 2 GPUs bring signiﬁcant speed ups.
The 2-GPU & parallel loading implementation (cuDNN-R2) is on par with the “Caffe with cuDNN”
implementation.

After 65 epochs of training, the top-1 class validation error rate is 42.6%, and the top-5 error rate is
19.9%, without the intensity and illumination data augmentation 5. This is within 0.5% of the results
reported in the similar Caffe implementation6.

4 DISCUSSION

4.1 NATIVE THEANO MULTI-GPU SUPPORT

Native Theano multi-GPU support is under development7. Our present implementation is a tempo-
rary work-around before its release, and might also provide helpful communication components on
top of it.

4.2 RELATED WORK

Many multi-GPU frameworks has been proposed and implemented (Yadan et al., 2013; Zou et al.,
2014; Paine et al., 2013; Krizhevsky, 2014), usually adopting a mixed data and model parallelism.
This report only implements the data parallelism framework, but it could potentially, with a non-
trivial amount of effort, be extended to incorporate model parallelism.

3The same operation is performed for biases and momentum.
4Performance of Caffe is according to http://caffe.berkeleyvision.org/performance_
hardware.html, where timing information for CaffeNet is provided. As CaffeNet has similar structures,
we consider this as a rough reference.

5The

pretrained

parameters

are

available

for

downloading

at https://github.com/

uoguelph-mlrg/theano_alexnet/tree/master/pretrained/alexnet

6https://github.com/BVLC/caffe/tree/master/models/bvlc_reference_

caffenet

7https://groups.google.com/d/msg/theano-users/vtR_L0QltpE/Kp5hK1nFLtsJ

3

Accepted as a workshop contribution at ICLR 2015

4.3 CHALLENGES IN PYTHON-BASED PARALLELIZATION

The Global Interpreter Lock 8 (GIL) makes parallelization difﬁcult in CPython, by disabling concur-
rent threads within one process. Therefore, to parallelize, it is necessary to launch multiple processes
and communicate between these processes. Straightforward inter-process communication, using the
“multiprocessing” module, is very slow for 2 reasons: 1) it serializes Numpy arrays before passing
between processes; 2) communication is done through host memory. These problems lead us to
GPUDirect peer-to-peer memory copy, which also has many pitfalls under the multi-process set-
ting. For instance, there is no host-side synchronization performed with device-to-device memory
copy even when the sync API is called 9. This problem is dealt with by CUDA context syncing
and additional message communications between processes, however, this and similar issues are not
straightforward.

4.4 LIMITATIONS

To use the fast peer-to-peer GPU memory copy, GPUs have to be under the same PCI-E switch.
Otherwise, communication has to go through the host memory which results in longer latency. Sit-
uations involved with more GPUs are discussed in Krizhevsky (2014).

Due to our current hardware limitation, we have only proposed and experimented with a 2-GPU
implementation. This report and the code will be updated once experiments on more GPUs are
performed.

We acknowledge Lev Givon for giving helpful suggestions on how to use the PyCUDA library. We
also acknowledge NVIDIA for an Academic Hardware Grant.

ACKNOWLEDGMENTS

REFERENCES

Bastien, Fr´ed´eric, Lamblin, Pascal, Pascanu, Razvan, Bergstra, James, Goodfellow, Ian, Bergeron,
Arnaud, Bouchard, Nicolas, Warde-Farley, David, and Bengio, Yoshua. Theano: new features
and speed improvements. arXiv preprint arXiv:1211.5590, 2012.

Bergstra, James, Breuleux, Olivier, Bastien, Fr´ed´eric, Lamblin, Pascal, Pascanu, Razvan, Des-
jardins, Guillaume, Turian, Joseph, Warde-Farley, David, and Bengio, Yoshua. Theano: a cpu
and gpu math expression compiler. In Proceedings of the Python for scientiﬁc computing confer-
ence (SciPy), volume 4, pp. 3, 2010.

Chetlur, Sharan, Woolley, Cliff, Vandermersch, Philippe, Cohen, Jonathan, Tran, John, Catanzaro,
Bryan, and Shelhamer, Evan. cudnn: Efﬁcient primitives for deep learning. arXiv preprint
arXiv:1410.0759, 2014.

Collobert, Ronan, Kavukcuoglu, Koray, and Farabet, Cl´ement. Torch7: A matlab-like environment

for machine learning. In BigLearn, NIPS Workshop, number EPFL-CONF-192376, 2011.

Goodfellow, Ian J, Warde-Farley, David, Lamblin, Pascal, Dumoulin, Vincent, Mirza, Mehdi, Pas-
canu, Razvan, Bergstra, James, Bastien, Fr´ed´eric, and Bengio, Yoshua. Pylearn2: a machine
learning research library. arXiv preprint arXiv:1308.4214, 2013.

Jia, Yangqing, Shelhamer, Evan, Donahue, Jeff, Karayev, Sergey, Long, Jonathan, Girshick, Ross,
Guadarrama, Sergio, and Darrell, Trevor. Caffe: Convolutional architecture for fast feature em-
In Proceedings of the ACM International Conference on Multimedia, pp. 675–678.
bedding.
ACM, 2014.

Kl¨ockner, Andreas, Pinto, Nicolas, Lee, Yunsup, Catanzaro, Bryan, Ivanov, Paul, and Fasih, Ahmed.
Pycuda and pyopencl: A scripting-based approach to gpu run-time code generation. Parallel
Computing, 38(3):157–174, 2012.

8https://wiki.python.org/moin/GlobalInterpreterLock
9http://docs.nvidia.com/cuda/cuda-driver-api/api-sync-behavior.html

4

Accepted as a workshop contribution at ICLR 2015

Krizhevsky, Alex. One weird trick for parallelizing convolutional neural networks. arXiv preprint

arXiv:1404.5997, 2014.

Krizhevsky, Alex, Sutskever, Ilya, and Hinton, Geoffrey E. Imagenet classiﬁcation with deep convo-
lutional neural networks. In Advances in neural information processing systems, pp. 1097–1105,
2012.

LeCun, Yann, Bottou, L´eon, Bengio, Yoshua, and Haffner, Patrick. Gradient-based learning applied

to document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.

Paine, Thomas, Jin, Hailin, Yang, Jianchao, Lin, Zhe, and Huang, Thomas. Gpu asynchronous
stochastic gradient descent to speed up neural network training. arXiv preprint arXiv:1312.6186,
2013.

Russakovsky, Olga, Deng, Jia, Su, Hao, Krause, Jonathan, Satheesh, Sanjeev, Ma, Sean, Huang,
Zhiheng, Karpathy, Andrej, Khosla, Aditya, Bernstein, Michael, et al. Imagenet large scale visual
recognition challenge. arXiv preprint arXiv:1409.0575, 2014.

Yadan, Omry, Adams, Keith, Taigman, Yaniv, and Ranzato, MarcAurelio. Multi-gpu training of

convnets. arXiv preprint arXiv:1312.5853, 2013.

Zou, Yongqiang, Jin, Xing, Li, Yi, Guo, Zhimao, Wang, Eryu, and Xiao, Bin. Mariana: Tencent
deep learning platform and its applications. Proceedings of the VLDB Endowment, 7(13), 2014.

5

