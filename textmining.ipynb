{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the code, several dependant package need to be installed, skip if it already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3 in /Applications/anaconda3/lib/python3.7/site-packages (1.24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfminer.six\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/04/f62d5834c2bdf90afcaeb23bb5241033c44e27000de64ad8472253daa4a8/pdfminer.six-20200402-py3-none-any.whl (5.6MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6MB 5.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet; python_version > \"3.0\" in /Applications/anaconda3/lib/python3.7/site-packages (from pdfminer.six) (3.0.4)\n",
      "Requirement already satisfied: pycryptodome in /Applications/anaconda3/lib/python3.7/site-packages (from pdfminer.six) (3.9.7)\n",
      "Requirement already satisfied: sortedcontainers in /Applications/anaconda3/lib/python3.7/site-packages (from pdfminer.six) (2.1.0)\n",
      "Installing collected packages: pdfminer.six\n",
      "Successfully installed pdfminer.six-20200402\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in /Applications/anaconda3/lib/python3.7/site-packages (0.9.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we make connection with database with pymysql api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "#input basic info about database\n",
    "conn=pymysql.connect(host='mysql24.ezhostingserver.com', port=3306, user='krw',password='Y>!V@N_26@]cfJ7(')\n",
    "#cursor is the current point we focus on, which could execute sql command.\n",
    "cursor=conn.cursor()\n",
    "lst=[]\n",
    "#Here krw is the databse name and training_view is a view for requesting data. The execution should be around 30s.\n",
    "cursor.execute(\"SELECT * FROM krw.training_view limit 10;\")\n",
    "for r in cursor:\n",
    "    lst.append(list(r))\n",
    "lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After excution we obtained a 2-dimensional matrix with each row represents a paper. Next, we constract a url based on arXiv id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/pdf/1909.01807.pdf\n"
     ]
    }
   ],
   "source": [
    "name=lst[7][4]\n",
    "url=\"https://arxiv.org/pdf/\"+str(name)+\".pdf\"\n",
    "print(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By following command we could access pdf by url and convert pdf 2 txt file and store at local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'uint_value' from 'pdfminer.pdftypes' (/Applications/anaconda3/lib/python3.7/site-packages/pdfminer/pdftypes.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b362eb444956>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpdfminer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdfparser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPDFParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpdfminer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdfdocument\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPDFDocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpdfminer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdfpage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPDFPage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpdfminer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdfpage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPDFTextExtractionNotAllowed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pdfminer/pdfdocument.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpsparser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPSEOF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliteral_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKWD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpdftypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPDFException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muint_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPDFTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPDFStream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mPDFObjectNotFound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecipher_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdict_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'uint_value' from 'pdfminer.pdftypes' (/Applications/anaconda3/lib/python3.7/site-packages/pdfminer/pdftypes.py)"
     ]
    }
   ],
   "source": [
    "#https://cloud.tencent.com/developer/article/1395339\n",
    "import urllib\n",
    "import pdfminer\n",
    "from io import StringIO\n",
    "from io import BytesIO\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfpage import PDFTextExtractionNotAllowed\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "from pdfminer.layout import *\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from urllib.request import Request\n",
    "from urllib.request import urlopen\n",
    "# 定义解析函数\n",
    "\n",
    "def OnlinePdfToTxt(dataIo,new_path):\n",
    "    # 创建一个文档分析器\n",
    "    parser = PDFParser(dataIo)\n",
    "    # 创建一个PDF文档对象存储文档结构\n",
    "    document = PDFDocument(parser)\n",
    "    # 判断文件是否允许文本提取\n",
    "    if not document.is_extractable:\n",
    "        raise PDFTextExtractionNotAllowed\n",
    "    else:\n",
    "        # 创建一个PDF资源管理器对象来存储资源\n",
    "        resmag =PDFResourceManager()\n",
    "        # 设定参数进行分析\n",
    "        laparams=LAParams()\n",
    "        # 创建一个PDF设备对象\n",
    "        # device=PDFDevice(resmag )\n",
    "        device=PDFPageAggregator(resmag ,laparams=laparams)\n",
    "        # 创建一个PDF解释器对象\n",
    "        interpreter=PDFPageInterpreter(resmag ,device)\n",
    "        # 处理每一页\n",
    "        for page in PDFPage.create_pages(document):\n",
    "            interpreter.process_page(page)\n",
    "            # 接受该页面的LTPage对象\n",
    "            layout=device.get_result()\n",
    "            for y in layout:\n",
    "                try:\n",
    "                    if(isinstance(y,LTTextBoxHorizontal)):\n",
    "                        with open('%s'%(new_path),'a',encoding=\"utf-8\") as f:\n",
    "                            f.write(y.get_text()+'\\n')\n",
    "#                             print(\"读入成功！\")\n",
    "                except:\n",
    "                    print(\"读入失败!\")\n",
    "\n",
    "# 获取文件的路径\n",
    "#url = \"https://arxiv.org/pdf/2004.11055.pdf\"\n",
    "html = urllib.request.urlopen(urllib.request.Request(url)).read()\n",
    "dataIo = BytesIO(html)\n",
    "OnlinePdfToTxt(dataIo,'txt/'+str(name)+'.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the generated txt file, first we try to extract the email address by using regular experssion\n",
    "### TODO: Special format such as {aaa, bbb, ccc}@xxx.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ee205af37a96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0memailList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0memail_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'name' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "#open the generated file as input stream and store in the buffer\n",
    "def email_extraction(file_name):\n",
    "    file = open('txt/'+str(file_name)+'.txt',encoding=\"ISO-8859-1\")\n",
    "    strings=file.read()\n",
    "    matches = []\n",
    "    emailRegex = re.compile(r'''(\n",
    "        [a-zA-Z0-9._%+-]+      # username\n",
    "\n",
    "        @                      # @ symbol\n",
    "\n",
    "        [a-zA-Z0-9.-]+        # domain name\n",
    "\n",
    "        (\\.[a-zA-Z]{2,4}){1,2} # dot-something\n",
    "\n",
    "        )''', re.VERBOSE)\n",
    "    # using RE to match all the patterns in the txt\n",
    "    for groups in emailRegex.findall(strings):\n",
    "        matches.append(groups[0])\n",
    "    # reduced the same entities\n",
    "    list2 = list(set(matches))\n",
    "    list_nums = len(list2)\n",
    "    emailList=[]\n",
    "    for line in range(list_nums):\n",
    "        emailList.append(list2[line])\n",
    "    return emailList\n",
    "\n",
    "email_extraction(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly we match the author name list with the email list by token matching method (Levenshtein)\n",
    "### TODO: HOW can we access author list? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import *\n",
    "def author_email_matching(nameList, emailList):\n",
    "    if len(emailList)==0:\n",
    "        return\n",
    "    name_email={}\n",
    "    for name in nameList:\n",
    "        highest=0\n",
    "        index=0\n",
    "        for i in range(len(emailList)):\n",
    "            #using re to extract the first part of email\n",
    "            pat = re.compile(''+'(.*?)'+'@', re.S)\n",
    "            email = pat.findall(emailList[i])\n",
    "            #print(jaro(name, str(email)))\n",
    "            #using jaro to calculate the similarity between two strings\n",
    "            if jaro(name, emailList[i])>highest:\n",
    "                index=i\n",
    "                highest=jaro(name, emailList[i])\n",
    "        #set pair with the highest score\n",
    "        name_email[name]=emailList[index]\n",
    "        #If very sure, remove it from the list to reduce the uncertainty for other pairs\n",
    "        if highest>=0.6:\n",
    "            emailList.remove(emailList[index])\n",
    "    return name_email\n",
    "        \n",
    "\n",
    "nameList=['Michael Stewart', 'Majigsuren Enkhsaikhan', 'Wei Liu']\n",
    "author_email_matching(nameList, emailList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After matching email, we move to the section of acknowledgement, which is not certain for every paper. Here we use named entity recognition to classify orgnization which sponsred the study. Here we used Spacy classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Regular expression to locate the paragraph\n",
    "def ORG_recognition(strings):\n",
    "    keyStart = 'Acknowledg+'\n",
    "    keyEnd = 'References'\n",
    "    pat = re.compile(keyStart+'(.*?)'+keyEnd, re.S)\n",
    "    result = pat.findall(strings)\n",
    "    if len(result)<10:\n",
    "        return\n",
    "    #print(result)\n",
    "    file.close()\n",
    "    #format processing\n",
    "    txt=''\n",
    "    txt=txt.join(result)\n",
    "    txt=txt.replace('\\n', '').replace('\\r', '')\n",
    "    #print(txt)\n",
    "    #using the pretrained model\n",
    "    doc=nlp(txt)\n",
    "    ORG_list=[]\n",
    "    print([(X.text, X.label_) for X in doc.ents])\n",
    "    for X in doc.ents:\n",
    "        if X.label_=='ORG':\n",
    "            ORG_list.append(X.text)\n",
    "    return ORG_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
