{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the code, several dependant package need to be installed, skip if it already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3 in /Applications/anaconda3/lib/python3.7/site-packages (1.24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfminer.six\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/04/f62d5834c2bdf90afcaeb23bb5241033c44e27000de64ad8472253daa4a8/pdfminer.six-20200402-py3-none-any.whl (5.6MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6MB 5.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet; python_version > \"3.0\" in /Applications/anaconda3/lib/python3.7/site-packages (from pdfminer.six) (3.0.4)\n",
      "Requirement already satisfied: pycryptodome in /Applications/anaconda3/lib/python3.7/site-packages (from pdfminer.six) (3.9.7)\n",
      "Requirement already satisfied: sortedcontainers in /Applications/anaconda3/lib/python3.7/site-packages (from pdfminer.six) (2.1.0)\n",
      "Installing collected packages: pdfminer.six\n",
      "Successfully installed pdfminer.six-20200402\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in /Applications/anaconda3/lib/python3.7/site-packages (0.9.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we make connection with database with pymysql api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymysql\n",
    "#input basic info about database\n",
    "conn=pymysql.connect(host='mysql24.ezhostingserver.com', port=3306, user='krw',password='Y>!V@N_26@]cfJ7(')\n",
    "#cursor is the current point we focus on, which could execute sql command.\n",
    "cursor=conn.cursor()\n",
    "lst=[]\n",
    "#Here krw is the databse name and training_view is a view for requesting data. The execution should be around 30s.\n",
    "cursor.execute(\"SELECT * FROM krw.training_paper_view limit 100;\")\n",
    "for r in cursor:\n",
    "    lst.append(list(r))\n",
    "cursor.fetchall()\n",
    "#lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After excution we obtained a 2-dimensional matrix with each row represents a paper. Next, we constract a url based on arXiv id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1221706 http://arxiv.org/pdf/1606.01847v3.pdf\n"
     ]
    }
   ],
   "source": [
    "#NUM=25\n",
    "NUM=30\n",
    "resourceId=lst[NUM][0]\n",
    "authorNum=lst[NUM][3]\n",
    "url=lst[NUM][5]\n",
    "#name=lst[NUM][6]\n",
    "if \"acmweb\" in url:\n",
    "    #pattern = re.compile(ur'^((https|http|ftp|rtsp|mms)?:\\/\\/)[^\\s]+/')\n",
    "    #str = u''\n",
    "    url=url+\".pdf\"\n",
    "    #name=pattern.search(str)\n",
    "#url=\"https://arxiv.org/pdf/\"+str(name)+\".pdf\"\n",
    "print(resourceId,url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Akira Fukui',\n",
       " 'Anna Rohrbach',\n",
       " 'Daylen Yang',\n",
       " 'Dong Huk Park',\n",
       " 'Marcus Rohrbach',\n",
       " 'Trevor Darrell']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authorList0=[]\n",
    "authorList=[]\n",
    "#Here krw is the databse name and training_view is a view for requesting data. The execution should be around 30s.\n",
    "#conn=pymysql.connect(host='mysql24.ezhostingserver.com', port=3306, user='krw',password='Y>!V@N_26@]cfJ7(')\n",
    "cursor=conn.cursor()\n",
    "#Here krw is the databse name and training_view is a view for requesting data. The execution should be around 30s.\n",
    "cursor.execute(\"SELECT name FROM krw.training_author_view where paper_id=(%s) group by name;\",resourceId)\n",
    "for r in cursor:\n",
    "    authorList0.append(list(r))\n",
    "for name in authorList0:\n",
    "    authorList.append(name[0])\n",
    "authorList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By following command we could access pdf by url and convert pdf 2 txt file and store at local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://arxiv.org/pdf/1606.01847v3.pdf\n"
     ]
    }
   ],
   "source": [
    "#https://cloud.tencent.com/developer/article/1395339\n",
    "import urllib\n",
    "import pdfminer\n",
    "import copy\n",
    "from io import StringIO\n",
    "from io import BytesIO\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfpage import PDFTextExtractionNotAllowed\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "from pdfminer.layout import *\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from urllib.request import Request\n",
    "from urllib.request import urlopen\n",
    "\n",
    "def OnlinePdfToTxt(dataIo,new_path):\n",
    "    # Create PDF Parser\n",
    "    parser = PDFParser(dataIo)\n",
    "    # Create PDFDocument\n",
    "    document = PDFDocument(parser)\n",
    "    # Is it okay for extraction?\n",
    "    if not document.is_extractable:\n",
    "        raise PDFTextExtractionNotAllowed\n",
    "    else:\n",
    "        # Create PDF Manager\n",
    "        resmag =PDFResourceManager()\n",
    "        # Setting parameters\n",
    "        laparams=LAParams()\n",
    "        # Createing PDF device\n",
    "        # device=PDFDevice(resmag )\n",
    "        device=PDFPageAggregator(resmag ,laparams=laparams)\n",
    "        # Create PDF explainer\n",
    "        interpreter=PDFPageInterpreter(resmag ,device)\n",
    "        # For each page\n",
    "        for page in PDFPage.create_pages(document):\n",
    "            interpreter.process_page(page)\n",
    "            # accept this page's LTP object\n",
    "            layout=device.get_result()\n",
    "            for y in layout:\n",
    "                try:\n",
    "                    if(isinstance(y,LTTextBoxHorizontal)):\n",
    "                        with open('%s'%(new_path),'a',encoding=\"utf-8\") as f:\n",
    "                            f.write(y.get_text()+'\\n')\n",
    "                            #print(\"Success！\")\n",
    "                except:\n",
    "                    print(\"Failed\")\n",
    "\n",
    "#url = \"https://arxiv.org/pdf/2004.11055.pdf\"\n",
    "print(url)\n",
    "html = urllib.request.urlopen(urllib.request.Request(url)).read()\n",
    "dataIo = BytesIO(html)\n",
    "OnlinePdfToTxt(dataIo,'txt/'+str(resourceId)+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "import copy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "from Levenshtein import *\n",
    "#nlp = en_core_web_sm.load()\n",
    "class AuthorInfoExtract:\n",
    "    \n",
    "    def locateContext(self,file_name):\n",
    "        file = open('txt/'+str(file_name)+'.txt',encoding=\"ISO-8859-1\")\n",
    "        strings=file.read()\n",
    "        symbolList=[\"Abstract\",'Abstract.','ABSTRACT','ABSTRACT.']\n",
    "        for symbol in symbolList:\n",
    "            #if name in strings:\n",
    "            if strings.find(symbol):\n",
    "                output=strings[0:strings.find(symbol)]\n",
    "                break\n",
    "            else:\n",
    "                print(symbol+\" not found!\")\n",
    "                output==strings[0:500]\n",
    "        file.close()\n",
    "        output=output.replace('\\n', ' . ').replace('\\r', ' ')\n",
    "        output=output.split(\" \")\n",
    "        return output\n",
    "#     def judge(x):\n",
    "#         return bool(re.search(r'\\d', x))\n",
    "\n",
    "    def matchAuthor(self,roleList,authorList):\n",
    "        author_role=[]\n",
    "        for role in roleList:\n",
    "            highest=0\n",
    "            index=0\n",
    "            for i in range(len(authorList)):\n",
    "                if jaro(role, authorList[i])>highest:\n",
    "                    index=i\n",
    "                    highest=jaro(role, authorList[i])\n",
    "            if highest>0.8:\n",
    "                author_role.append(authorList[index])\n",
    "        return author_role\n",
    "    \n",
    "    def specialAuthors(self,output):\n",
    "        starAuthorList=[]\n",
    "        correspondingAuthorList=[]\n",
    "        for i in range(len(output)):\n",
    "            if '*' in output[i]:\n",
    "                starAuthorList.append(\" \".join(output[i-1:i+1]))\n",
    "            if 'â\\x80\\xa0' in output[i]:\n",
    "                correspondingAuthorList.append(\" \".join(output[i-1:i+1]))\n",
    "\n",
    "        star=matchAuthor(starAuthorList,authorList)\n",
    "        corre=matchAuthor(correspondingAuthorList,authorList) \n",
    "        return star,corre\n",
    "\n",
    "    def sequenceExtratcor(self,output,authorList):\n",
    "        author_sequence={}\n",
    "        #print(authorList)\n",
    "        authorListCopy=copy.copy(authorList)\n",
    "        num=1\n",
    "        for i in range(len(output)):\n",
    "            for name in authorListCopy:\n",
    "                if output[i] in name and len(output[i])>=2:\n",
    "                    #print(output[i],name)\n",
    "                    author_sequence[name]=num\n",
    "                    num+=1\n",
    "                    authorListCopy.remove(name)\n",
    "                    break\n",
    "        return author_sequence\n",
    "    \n",
    "    def main(self):\n",
    "        extractor=AuthorInfoExtract()\n",
    "        output=extractor.locateContext(resourceId)\n",
    "        author_sequence=extractor.sequenceExtratcor(output,authorList)\n",
    "        star,corre=extractor.specialAuthors(output)\n",
    "        try:\n",
    "            df=pd.DataFrame.from_dict(author_sequence,orient='index',columns=['sequence'])\n",
    "            df=df.reset_index().rename(columns={'index':'name'})\n",
    "            df['star']=0\n",
    "            for index, row in df.iterrows():\n",
    "                for author in star:\n",
    "                    print(row[\"name\"],author,index)\n",
    "                    if row[\"name\"]==author:\n",
    "                        df.loc[index,\"star\"] = 1\n",
    "            df['corre']=0\n",
    "            for index, row in df.iterrows():\n",
    "                for author in corre:\n",
    "                    #print(row[\"name\"],author,index)\n",
    "                    if row[\"name\"]==author:\n",
    "                        df.loc[index,\"corre\"] = 1\n",
    "        except:\n",
    "            print(\"error occured!\")\n",
    "            df=pd.DataFrame(columns=['name', 'sequence', 'star', 'corre'])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akira Fukui Akira Fukui 0\n",
      "Akira Fukui Anna Rohrbach 0\n",
      "Akira Fukui Daylen Yang 0\n",
      "Anna Rohrbach Akira Fukui 1\n",
      "Anna Rohrbach Anna Rohrbach 1\n",
      "Anna Rohrbach Daylen Yang 1\n",
      "Dong Huk Park Akira Fukui 2\n",
      "Dong Huk Park Anna Rohrbach 2\n",
      "Dong Huk Park Daylen Yang 2\n",
      "Trevor Darrell Akira Fukui 3\n",
      "Trevor Darrell Anna Rohrbach 3\n",
      "Trevor Darrell Daylen Yang 3\n",
      "Marcus Rohrbach Akira Fukui 4\n",
      "Marcus Rohrbach Anna Rohrbach 4\n",
      "Marcus Rohrbach Daylen Yang 4\n",
      "Daylen Yang Akira Fukui 5\n",
      "Daylen Yang Anna Rohrbach 5\n",
      "Daylen Yang Daylen Yang 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>star</th>\n",
       "      <th>corre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Akira Fukui</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Anna Rohrbach</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Dong Huk Park</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Trevor Darrell</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Marcus Rohrbach</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Daylen Yang</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  sequence  star  corre\n",
       "0      Akira Fukui         1     1      0\n",
       "1    Anna Rohrbach         2     1      0\n",
       "2    Dong Huk Park         3     0      0\n",
       "3   Trevor Darrell         4     0      0\n",
       "4  Marcus Rohrbach         5     0      0\n",
       "5      Daylen Yang         6     1      0"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor=AuthorInfoExtract()\n",
    "extractor.main()\n",
    "# output=extractor.locateContext(resourceId)\n",
    "# author_sequence=extractor.sequenceExtratcor(output,authorList)\n",
    "# star,corre=extractor.specialAuthors(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Daniel Sedra', 'Gao Huang', 'Kilian Weinberger', 'Yu Sun', 'Zhuang Liu']\n",
      "Gao Huang Gao Huang 0\n",
      "Gao Huang Yu Sun 0\n",
      "Yu Sun Gao Huang 1\n",
      "Yu Sun Yu Sun 1\n",
      "Zhuang Liu Gao Huang 2\n",
      "Zhuang Liu Yu Sun 2\n",
      "Daniel Sedra Gao Huang 3\n",
      "Daniel Sedra Yu Sun 3\n",
      "Kilian Weinberger Gao Huang 4\n",
      "Kilian Weinberger Yu Sun 4\n",
      "Gao Huang Zhuang Liu 0\n",
      "Yu Sun Zhuang Liu 1\n",
      "Zhuang Liu Zhuang Liu 2\n",
      "Daniel Sedra Zhuang Liu 3\n",
      "Kilian Weinberger Zhuang Liu 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>star</th>\n",
       "      <th>corre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Gao Huang</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Yu Sun</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Zhuang Liu</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Daniel Sedra</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Kilian Weinberger</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name  sequence  star  corre\n",
       "0          Gao Huang         1     1      0\n",
       "1             Yu Sun         2     1      0\n",
       "2         Zhuang Liu         3     0      1\n",
       "3       Daniel Sedra         4     0      0\n",
       "4  Kilian Weinberger         5     0      0"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "author_sequence,star,corre=author_extraction(resourceId)\n",
    "df=pd.DataFrame.from_dict(author_sequence,orient='index',columns=['sequence'])\n",
    "df=df.reset_index().rename(columns={'index':'name'})\n",
    "df['star']=0\n",
    "for index, row in df.iterrows():\n",
    "    for author in star:\n",
    "        print(row[\"name\"],author,index)\n",
    "        if row[\"name\"]==author:\n",
    "            df.loc[index,\"star\"] = 1\n",
    "df['corre']=0\n",
    "for index, row in df.iterrows():\n",
    "    for author in corre:\n",
    "        print(row[\"name\"],author,index)\n",
    "        if row[\"name\"]==author:\n",
    "            df.loc[index,\"corre\"] = 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "nothing to repeat at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-001bff0cc72a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'*@([A-Za-z0-9][-A-Za-z0-9]+\\.)+[A-Za-z]{2,14}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mu'jb51@163.com'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/re.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;34m\"Compile a regular expression pattern, returning a Pattern object.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpurge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/sre_parse.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(str, flags, pattern)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mSRE_FLAG_VERBOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mVerbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0;31m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0;32m--> 426\u001b[0;31m                            not nested and not items))\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mAT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m                 raise source.error(\"nothing to repeat\",\n\u001b[0;32m--> 651\u001b[0;31m                                    source.tell() - here + len(this))\n\u001b[0m\u001b[1;32m    652\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_REPEATCODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m                 raise source.error(\"multiple repeat\",\n",
      "\u001b[0;31merror\u001b[0m: nothing to repeat at position 0"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import re\n",
    "pattern = re.compile(r'*@([A-Za-z0-9][-A-Za-z0-9]+\\.)+[A-Za-z]{2,14}')\n",
    "str = u'jb51@163.com'\n",
    "print(pattern.search(str))\n",
    "#judge(\"...12.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the generated txt file, first we try to extract the email address by using regular experssion\n",
    "### TODO: Special format such as {aaa, bbb, ccc}@xxx.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gh349', ' ys646', ' dms422', ' kqw4']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['liuzhuang13@mails.tsinghua.edu.cn',\n",
       " 'gh349@cornell.edu',\n",
       " ' ys646@cornell.edu',\n",
       " ' dms422@cornell.edu',\n",
       " ' kqw4@cornell.edu']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "\n",
    "#open the generated file as input stream and store in the buffer\n",
    "def email_extraction(file_name):\n",
    "    file = open('txt/'+str(file_name)+'.txt',encoding=\"ISO-8859-1\")\n",
    "    strings=file.read()\n",
    "    matches = []\n",
    "    matchesGroup=[]\n",
    "    emailRegex = re.compile(r'''(\n",
    "        [a-zA-Z0-9._%+-]+      # username\n",
    "        @                      # @ symbol\n",
    "\n",
    "        [a-zA-Z0-9.-]+        # domain name\n",
    "\n",
    "        (\\.[a-zA-Z]{2,4}){1,2} # dot-something\n",
    "        )''', re.VERBOSE)\n",
    "    # using RE to match all the patterns in the txt\n",
    "    for groups in emailRegex.findall(strings):\n",
    "        matches.append(groups[0])\n",
    "    # reduced the same entities\n",
    "    list2 = list(set(matches))\n",
    "    list_nums = len(list2)\n",
    "    emailList=[]\n",
    "    for line in range(list_nums):\n",
    "        emailList.append(list2[line])\n",
    "        \n",
    "    emailRegex2 = re.compile(r'''(\n",
    "    \\{(.+?)\\}+\n",
    "    @                     # @ symbol\n",
    "    [a-zA-Z0-9.-]+        # domain name\n",
    "    (\\.[a-zA-Z]{2,4}){1,2} # dot-something\n",
    "    )''', re.VERBOSE)\n",
    "    for groups in emailRegex2.findall(strings):\n",
    "        #print(strings)\n",
    "        matchesGroup.append(groups[0])\n",
    "    if len(matchesGroup)>0:\n",
    "        stringGroup = matchesGroup[0]\n",
    "        index=stringGroup.find(\"@\", 0)\n",
    "        prefix=stringGroup[:index]\n",
    "        suffix=stringGroup[index:]\n",
    "        tempNameList=prefix[1:-1].split(\",\");\n",
    "        for name in tempNameList:\n",
    "            emailList.append(name+suffix)\n",
    "        print(tempNameList)\n",
    "    return emailList\n",
    "\n",
    "email_extraction(resourceId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly we match the author name list with the email list by token matching method (Levenshtein)\n",
    "### TODO: HOW can we access author list? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gh349', ' ys646', ' dms422', ' kqw4']\n",
      "['Daniel Sedra', 'Gao Huang', 'Kilian Weinberger', 'Yu Sun', 'Zhuang Liu']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Daniel Sedra': ' dms422@cornell.edu',\n",
       " 'Gao Huang': 'liuzhuang13@mails.tsinghua.edu.cn',\n",
       " 'Kilian Weinberger': 'liuzhuang13@mails.tsinghua.edu.cn',\n",
       " 'Yu Sun': 'liuzhuang13@mails.tsinghua.edu.cn',\n",
       " 'Zhuang Liu': 'liuzhuang13@mails.tsinghua.edu.cn'}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Levenshtein import *\n",
    "def author_email_matching(nameList, emailList):\n",
    "    if len(emailList)==0:\n",
    "        return\n",
    "    name_email={}\n",
    "    for name in nameList:\n",
    "        highest=0\n",
    "        index=0\n",
    "        for i in range(len(emailList)):\n",
    "            #using re to extract the first part of email\n",
    "            pat = re.compile(''+'(.*?)'+'@', re.S)\n",
    "            email = pat.findall(emailList[i])\n",
    "            #print(str(email))\n",
    "            #print(jaro(name, str(email)))\n",
    "            #using jaro to calculate the similarity between two strings\n",
    "            if jaro(name, str(email))>highest:\n",
    "                index=i\n",
    "                highest=jaro(name, str(email))\n",
    "        #set pair with the highest score\n",
    "        #print(name,highest,emailList[i])\n",
    "        name_email[name]=emailList[index]\n",
    "        #If very sure, remove it from the list to reduce the uncertainty for other pairs\n",
    "#         if highest>=0.6:\n",
    "#             emailList.remove(emailList[index])\n",
    "        if highest<=0.4:\n",
    "            name_email[name]=''\n",
    "    for email in emailList:\n",
    "        if email not in name_email:\n",
    "            for name in name_email:\n",
    "                if name_email[name]=='':\n",
    "                    name_email[name]=email\n",
    "                    print(jaro(name, str(email)))\n",
    "    return name_email\n",
    "        \n",
    "\n",
    "#nameList=['Michael Stewart', 'Majigsuren Enkhsaikhan', 'Wei Liu']\n",
    "emailList=email_extraction(resourceId)\n",
    "print(authorList)\n",
    "author_email_matching(authorList, emailList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After matching email, we move to the section of acknowledgement, which is not certain for every paper. Here we use named entity recognition to classify orgnization which sponsred the study. Here we used Spacy classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1169762\n",
      "1\n",
      "No Matching!\n"
     ]
    }
   ],
   "source": [
    "#using Regular expression to locate the paragraph\n",
    "def PER_recognition(file_name):\n",
    "    file = open('txt/'+str(file_name)+'.txt',encoding=\"ISO-8859-1\")\n",
    "    strings=file.read()\n",
    "    #print(strings)\n",
    "    keyStart = 'ABSTRACT'\n",
    "    keyEnd = '1'\n",
    "    pat = re.compile(keyStart+'(.*?)'+keyEnd, re.S)\n",
    "    result = pat.findall(strings)\n",
    "    #print(result)\n",
    "    print(1)\n",
    "    if len(result)<10:\n",
    "        keyStart1 = 'CONCLUSION'\n",
    "        keyEnd1 = 'Recurrent Neural Network'\n",
    "        pat = re.compile(keyStart1+'(.*?)'+keyEnd1, re.S)\n",
    "        result = pat.findall(strings)\n",
    "        if len(result)<10:\n",
    "            print(\"No Matching!\")\n",
    "            return\n",
    "\n",
    "    file.close()\n",
    "    #format processing\n",
    "    txt=''\n",
    "    txt=txt.join(result)\n",
    "    txt=txt.replace('\\n', '').replace('\\r', '')\n",
    "    #print(txt)\n",
    "    #using the pretrained model\n",
    "    \n",
    "    doc=nlp(txt)\n",
    "    PER_list=[]\n",
    "    print([(X.text, X.label_) for X in doc.ents])\n",
    "    for X in doc.ents:\n",
    "        if X.label_=='PER':\n",
    "            PER_list.append(X.text)\n",
    "    return PER_list\n",
    "print(resourceId)\n",
    "PER_recognition(resourceId)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
